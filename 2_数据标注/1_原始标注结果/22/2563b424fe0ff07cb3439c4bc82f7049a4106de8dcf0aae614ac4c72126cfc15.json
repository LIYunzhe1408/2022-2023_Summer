{"content": "Moreover, leveraging tem-poral and spatial structure of a CNN allows to learn com-plex input features [27]. Among Recurrent Neural Networks(RNNs), the LSTM architecture has been very successful with time series, and in particular with their long-term depen- dencies [28], [29]. Moreover, LSTM networks overcome the vanishing gradient problem, experienced by standard RNNs [30].", "records": [{"span": "Recurrent Neural Networks", "offset": [114, 138], "tag": "Characterization"}, {"span": "RNN", "offset": [140, 142], "tag": "Characterization"}]}