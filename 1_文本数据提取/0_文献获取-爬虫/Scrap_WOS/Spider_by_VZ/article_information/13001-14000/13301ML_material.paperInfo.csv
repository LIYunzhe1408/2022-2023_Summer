,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Impact of BGM Point Profiles on Glycemic Variability Prediction Accuracies,,,5774-5776,"Mell Julia Alyssa,Imanbayev Anuar","Mell JA,Imanbayev A",Mell JA,10.1109/BigData50022.2020.9377971,University of Washington,"This study investigates the effect that the number of blood glucose measurements taken per day has on a machine learning model's ability to predict three glycemic variations for the next day: the mean blood glucose value, the occurrence of a hypoglycemia event, and the time-in-range percentage. Blood glucose monitoring (BGM) data from Novo Nordisk clinical trials was used to assess the prediction performances of 1, 4, 7, and 9-point profiles (PP) in comparison to continuous glucose monitoring (CGM) data. The results showed that BGM data predictions can perform equivalently to CGM data, most consistently when using a 9-point profile, and competitively at the 7PP. However, a 9PP is not the most viable option, since it would require patients to prick their fingers 8 times per day. Further analysis of the deficiencies in lower point profiles such as 5PP and 6PP is required in order to understand optimal finger prick timings.","blood glucose monitoring,continuous glucose monitoring,point profiles,machine learning,prediction performance,patient experience",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
2,Rapid Antibiotic Susceptibility Analysis Using Microscopy and Machine Learning,,,5804-5806,"Pyayt Anna,Khan Rituparna,Brzozowski Robert,Eswara Prahathees,Gubanov Michael","Pyayt A,Khan R,Brzozowski R,Eswara P,Gubanov M",Pyayt A,10.1109/BigData50022.2020.9378005,State University System of Florida,"Here we present machine learning-based approach to automatic classify live and dead bacteria that can be used for rapid search for optimal antibiotics in case of bacterial infections. The patients must be promptly administered a most efficient medication because all delays significantly increase morbidity and mortality. We engineered a new technology allowing us to efficiently and rapidly capture bacterial cells from different biological samples and proceed with a rapid antibiotic susceptibility testing thereby bypassing the need to culture the bacterium. We developed a new machine learning and microscopy-based approach for rapid assessment of bacterial viability following tests with antibiotics. Also, we created a labeled dataset with similar to 100 images of live and dead bacteria stained with DAPI (DNA; blue) and FM4-64 (membrane; red) either treated with an antibiotic or untreated. We analyzed wild type (WT) and ampicillin-resistant (ampR) E. coli, WT and ampR S. aureus, and B. subtilis. For antibiotic susceptibility testing we used ampicillin, chloramphenicol and erythromycin. We extracted information about red and blue channels from the images and tried two machine learning classifiers for rapid assessment of viability of the bacteria. The classifiers Random Forest and J48 Decision Tree demonstrated precision 90.7% and 96%, recall 94.4% and 100%, and F-measure 92.5% and 95.2%, correspondingly, on 10-fold cross-validation.","bacteria,antibiotic susceptibility analysis,machine learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"SEVERE,SEPSIS,BLOOD,PATHOGENS,DIAGNOSIS,TRENDS",,,
3,Identification of Dynamic Functional Connectivity Pattern in Restingstate after Acute Mild Traumatic Brain Injury,11584,,,"Li Yuxiang,Xie Hongwei,Shen Hui","Li YX,Xie HW,Shen H",Shen H,10.1117/12.2581322,National University of Defense Technology - China,"As a major health problem, traumatic brain injury has received increasing attention in recent years. Mild traumatic brain injury (mTBI) is the representative of the vast majority of traumatic brain injury. However, most studies have focused on moderate to severe traumatic brain injury. According to reports, mTBI patients during the acute period have the most prominent cognitive disorders. Hence, we collected the functional magnetic resonance imaging data in resting-state (rsfMRI) of the acute-mTBI patients and the healthy controls to explore the differences of brain functional connectivity between them. We chose dynamic functional connectivity in resting-state as features and performed feature selection/extraction. Finally, the classifier based on machine learning methods achieved a good classification accuracy of 85.48%. Most of the extracted brain regions of interest (ROIs) with high identification power belong to the sensorimotor and functional connectivities extracted within the sensorimotor has the highest proportion which suggested the sensorimotor may be the most severely damaged part of mTBI patients in the acute stage.","mTBI,rs-fMRI,dynamic functional connectivity,feature selection,feature extraction,machine learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Optics,Imaging Science & Photographic Technology",,,MTBI,,,
4,Improving EEG-based Motor Imagery Classification with Conditional Wasserstein GAN,11584,,,"Li Zheng,Yu Yang","Li Z,Yu Y",Li Z,10.1117/12.2581328,National University of Defense Technology - China,"Deep learning based algorithms have made huge progress in the field of image classification and speech recognition. There is an increasing number of researchers beginning to use deep learning to process electroencephalographic(EEG) brain signals. However, at the same time, due to the complexity of the experimental device and the expensive collection cost, we cannot train a powerful deep learning model without enough satisfactory EEG data. Data augmentation has been considered as an effective method to eliminate this issue. We propose the Conditional Wasserstein Generative Adversarial Network with gradient penalty (CWGAN-GP) to synthesize EEG data for data augmentation. We use two public neural networks for a motor imagery task and combine the synthesized data with real EEG data to test the generated samples' data enhancement effect. The results indicate that our model can generate high-quality artificial EEG data, which can effectively learn the features from the original EEG data. Both neural networks have gained improved classification performance, and the more complex one has obtained more significant performance improvement. The experiment provides us with new ideas for improving the performance of EEG signal processing.","Brain-computer interface (BCI),EEG,Deep learning,Generative Adversarial Network(GAN),Data augment",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Optics,Imaging Science & Photographic Technology",,,COMMUNICATION,,,
5,Heart Rate Variability classification using Deep Learning with dimensional reduction,11584,,,"Lin Qinghua,Tsang Ken K. T.","Lin QH,Tsang KKT",Tsang KKT,10.1117/12.2579588,Beijing Normal University - Hong Kong Baptist University United International College,"Heart rate variability (HRV) refers to the variation of the heart rate cycles, which contains information of how the autonomic nerves system regulates the cardiovascular system. HRV is a valuable indicator to diagnose various cardiovascular diseases and predict arrhythmia events. This study is based on the standardized five-minute and ten-minute RR interval series from the open source Electrocardiogram (ECG) database website PhysioNet. Artificial Neural Networks (ANN) are used to distinguish patients with congestive heart failure or atrial fibrillation from normal sinus rhythm utilizing features calculated by time and frequency domains as well as nonlinear analysis. To eliminate redundancy and avoid overfitting, Principal Component Analysis (PCA) is performed to screen for the most efficient features. PCA not only improves the accuracy but also greatly reduces the number of nodes in the ANN model, thus, improves the efficiency. Overall, ANN classifiers achieved an accuracy of 79% for five-minute RR interval series and 84% for that of ten-minute series. The performance of Random Forest (RF) classifier is not as satisfactory. However, its list of most important features indicates nonlinear dynamics may play an important role and provide useful insights to the classification problem.","HRV,neural network,time domain,frequency domain,nonlinear,entropy,PCA",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Optics,Imaging Science & Photographic Technology",,,"APPROXIMATE,ENTROPY",,,
6,Application of machine learning algorithms for SCG signal classification,11584,,,"Natalia Konnova,Mikhail Basarab,Vera Khaperskaya","Natalia K,Mikhail B,Vera K",Natalia K,10.1117/12.2579578,Bauman Moscow State Technical University,"Recent studies demonstrated the clinical utility of seismocardiography (hereinafter SCG) signals for the detection and monitoring of cardiovascular conditions. Renewed interest in investigating the utility of SCG has been accelerated recently and benefited from new advances in low-cost lightweight sensors and machine learning methods. This article compares various machine learning algorithms (the method of nearest neighbors, the method of support vectors, decision trees, the ensemble of models) and neural networks: based on the architecture of long short-term memory and convolutional ones. An original numerical experiment was carried out using the developed mathematical software, where all of the mentioned methods and algorithms were implemented. During this study, much attention was paid to the preparation and preliminary processing of data. In particular, signal filtering is carried out using the Butterworth filter, and the issues of extracting features from the signal, which will become an input vector for machine learning algorithms, are also discussed. To compare the effectiveness of the considered models for solving the problem of diagnosing diseases, Accuracy, Recall, Sensitivity, Specificity, Precision, F1-measure, etc. are given. For each algorithm and data set, confusion matrices and ROC curves were constructed. Results of this research show that convolutional neural networks are very effective at diagnosing the states of the human cardiovascular system and supporting decision-making in cardiology and cardiac surgery.","decision support system,deep learning,digital signal processing,machine learning,neural networks,KNN,SVM,LSTM,CNN",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Optics,Imaging Science & Photographic Technology",,,,,,
7,A study of the effect of training sample size on a pre-trained model of CRNN EEG emotion recognition,11584,,,"Qiu Jinping,Zhao Jian,Cheng Xiankai","Qiu JP,Zhao J,Cheng XK",Cheng XK,10.1117/12.2583588,Chinese Academy of Sciences,"To address the time-consuming feature extraction and model training in the process of EEG emotion recognition, this paper proposes a method to rapidly train deep learning models for EEG emotion recognition with high accuracy and excellent performance. The DEAP EEG data set is used to quickly train and fit the deep learning model, so as to establish a new pre-trained model for EEG emotion recognition. In addition, it was found that the best training effect was achieved using a sample with a ratio of 25%, and the other test data could quickly fine-tune the original model. The experimental results proved the effectiveness of the method, and the accuracy of the pre-trained model could reach the highest 93.72% in the Valence emotion dimension.","electroencephalographic signals,deep learning,pre-trained model,emotion recognize",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Optics,Imaging Science & Photographic Technology",,,,,,
8,A Two-stage Urine Sediment Detection Method,11584,,,"Wang Qiang,Sun Qiming,Wang Yong","Wang Q,Sun QM,Wang Y",Wang Q,10.1117/12.2577493,Southeast University - China,"Urine sediment detection is of great significance as one of the routine testing items. The traditional urine sediment detection method is mainly manual microscopic examination. Thus, it incurs heavy human workload and complicated operation, while it is easy to miss the targets. To alleviate this problem, a two-stage urine sediment detection method is proposed in this paper. More specifically, the segmentation and classification tasks are transformed into object detection tasks, and the feature extraction is performed by Deep Convolutional Neural Networks (DCNN). In our method, HOG+SVM is used as region proposal, and Trimmed MobileNets is used for DCNN refining. The experimental results demonstrate that the proposed method achieves promising performance.","Urine Sediment Detection,HOG,SVM,Deep Convolutional Neural Networks",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Optics,Imaging Science & Photographic Technology",,,,,,
9,Deep Representation Learning For Multimodal Brain Networks.,12267,,613-624,",,,","Zhang Wen,Zhan Liang,Thompson Paul,Wang Yalin",,10.1007/978-3-030-59728-3_60,,"Applying network science approaches to investigate the functions and anatomy of the human brain is prevalent in modern medical imaging analysis. Due to the complex network topology, for an individual brain, mining a discriminative network representation from the multimodal brain networks is non-trivial. The recent success of deep learning techniques on graph-structured data suggests a new way to model the non-linear cross-modality relationship. However, current deep brain network methods either ignore the intrinsic graph topology or require a network basis shared within a group. To address these challenges, we propose a novel end-to-end deep graph representation learning (Deep Multimodal Brain Networks - DMBN) to fuse multimodal brain networks. Specifically, we decipher the cross-modality relationship through a graph encoding and decoding process. The higher-order network mappings from brain structural networks to functional networks are learned in the node domain. The learned network representation is a set of node features that are informative to induce brain saliency maps in a supervised manner. We test our framework in both synthetic and real image data. The experimental results show the superiority of the proposed method over some other state-of-the-art deep brain network models.",Brain networks; Deep learning; Graph topology; Multimodality; Network representation,Journal Article,,,,,,,,
10,Identification of the most informative wavelengths for non-invasive melanoma diagnostics in spectral region from 450 to 950 nm,11459,,,"Bliznuks Dmitrijs,Chizhov Yuriy,Bondarenko Andrey,Uteshev Dilshat,Lihachev Alexey,Lihacova Ilze","Bliznuks D,Chizhov Y,Bondarenko A,Uteshev D,Lihachev A,Lihacova I",Bliznuks D,10.1117/12.2564382,Riga Technical University,"In this study 300 skin lesion (including 32 skin melanomas) multispectral data cubes were analyzed. The multi-step and single step machine learning approaches were analyzed to find the wavebands that provide the most information that helps discriminate skin melanoma from other benign pigmented lesions. The multi-step machine learning approach assumed training several models but proved itself to be ineffective. The reason for that is a necessity to train a segmentation model on a very small dataset and utilization of standard machine learning classifier which have shown poor classification performance. The single-step approach is based on a deep learning neural network. We have conducted 2600 experiments on two neural network architectures: popular pre-trained image analysis ""InceptionV3"" and simple custom convolutional neural network (ConvNet) classifiers. Observing performance metrics of these two deep-learning (DL) based architectures allowed to determine combinations of three spectral wavebands allowing to train a classifier with the best classification results. It was found that a simple ConvNet classifier allowed us to get better classification results. ConvNet training results have shown that most informative wavebands are 450nm which is the most informative for melanin concentration on the skin surface, 590nm that represents integral information about melanin and hemoglobin distribution from epidermis-dermis layer, and 950 nm that provide information from deeper skin layers. As introduced the convolutional neural network (CNN) model was simple but has not shown great performance. Also, we have to explore alternative CNN architectures. AutoKeras framework was used to find an architecture of the image classifier using the found waveband triplets.","Skin melanoma diagnostics,multispectral imaging,convolutional neural network,lesion classification",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Neurosciences & Neurology,Physics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
11,Network structure of children's brain activity during cognitive load,11459,,,"Hramov Alexander E.,Grubov Vadim V.,Frolov Nikita S.,Pitsik Elena N.,Khramova Marina V.","Hramov AE,Grubov VV,Frolov NS,Pitsik EN,Khramova MV",Frolov NS,10.1117/12.2564343,Innopolis University,"We have analyzed the neuronal interactions in the children's brain cortex associated with the cognitive activity during simple cognitive task (Schulte table) evaluation in two distinct frequency bands - alpha (8-13 Hz) and beta (15-30 Hz) ranges using linear Pearsons correlation-based connectivity analysis. We observed the taskrelated suppression of the alpha-band connectivity in the frontal, temporal and central brain areas, while in the parietal and occipital brain regions connectivity exhibits increase. We also demonstrated significant task-related increase of functional connectivity in the beta frequency band all over the distributed cortical network.","Artificial neural network,machine learning,nonlinear dynamics,synchronization,functional connectivity",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Neurosciences & Neurology,Physics,Radiology, Nuclear Medicine & Medical Imaging",,,"CONNECTIVITY,NEUROSCIENCE,EDUCATION",,,
12,Using artificial neural networks for classification of kinesthetic and visual imaginary movements by MEG data,11459,,,"Kurkin Semen,Chholak Parth,Niso Guiomar,Frolov Nikita,Pisarchik Alexander","Kurkin S,Chholak P,Niso G,Frolov N,Pisarchik A",Kurkin S,10.1117/12.2563813,Innopolis University,"The analysis of neurophysiological mechanisms responsible for motor imagery is essential for the development of brain-computer interfaces. The carried out magnetoencephalographic (MEG) experiments with voluntary participants confirm the existence of two types of motor imagery: kinesthetic imagery (KI) and visual imagery (VI), distinguished by activation and inhibition of different brain areas. For classification of the brain states associated with motor imagery, we used the hierarchical cluster analysis and a popular type of artificial neural networks called multilayer perceptron. The application of machine learning techniques allows us to classify motor imagery in raising right and left arms with an average accuracy of 70% for both KI and VI using appropriate filtration of input signals. The same average accuracy is achieved by optimizing MEG channels and reducing their number to only 13.","MEG analysis,motor-related patterns,artificial neural network,motor imagery,kinesthetic imagery,visual imagery",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Neurosciences & Neurology,Physics,Radiology, Nuclear Medicine & Medical Imaging",,,"PATTERNS,BRAIN",,,
13,EMG-Based Interface Using Machine Learning,,,57-60,"Takahashi Shinto,Higa Hiroki","Takahashi S,Higa H",Takahashi S,10.1109/CIIBMS50712.2020.9336203,University of Ryukyus,"This paper presents an EMG (electromyogram)based input interface using machine learning for people with physical disabilities of the extremities. We have developed a virtual hand that can be operated in virtual environment using EMG signals. In this paper, we performed a lifting object task and box and block test task with the virtual hand. From the experimental results of the lifting object tasks, it was confirmed that six wrist joint movements were classified, and that an experimental subject appropriately lifted objects with the virtual hand in the virtual space. In the box and block tests task, it was confirmed that he moved block(s) to the opposite side of the box 9 times within 60 sec.","EMG Signal,Machine Learning,Myoelectric Prosthesis",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Medical Informatics",,,,,,
14,Comparison of CNN-Uni-LSTM and CNN-Bi-LSTM based on single-channel EEG for sleep staging,,,76-80,"Li Qianyu,Wang Bei,Jin Jing,Wang Xingyu","Li QY,Wang B,Jin J,Wang XY",Wang B,10.1109/ICIIBMS50712.2020.9336419,East China University of Science & Technology,"Sleep staging is an effective method for diagnosing sleep disorder and monitoring sleep quality. With the rapid development of machine learning technology, the automatic staging methods of sleep gradually replace the traditional manual interpretation which can improve the efficiency on sleep staging for medical research. LSTM networks can save the historical information as a reference for the current moment, which is undoubtedly a good way to improve sleep staging performance. In this paper, a convolutional neural network (CNN) is constructed to extract the features from a single-channel EEG. The Uni-directional Long Short-Term Memory (Uni-LSTM) network and Bi-directional Long Short-Term Memory (Bi-LSTM) network are combined with CNN to realize automatic sleep staging. The obtained results showed that the two presented network frameworks are effective and feasible on sleep staging. The Bi-LSTM which has more enriched sequence information got better classification performance than the Uni-LSTM.","Sleep staging,Convolutional Neural Network,Uni-directional Long Short-Term Memory,Bi-directional Long Short-Term Memory,Electroencephalogram",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Medical Informatics",,,CLASSIFICATION,,,
15,Retinal image synthesis through the least action principle,,,111-116,"Lo Castro Dario,Valenti Cesare,Tegolo Domenico","Lo Castro D,Valenti C,Tegolo D",Lo Castro D,10.1109/ICIIBMS50712.2020.9336421,University of Palermo,"Eye fundus image analysis is a fundamental approach in medical diagnosis and follow-up ophthalmic diagnostics. Manual annotation by experts needs hard work, thus only a small set of annotated vessel structures is available. Examples such as DRIVE and STARE include small sets for training images of fundus image benchmarks. Moreover, there is no vessel structure annotation for a number of fundus image datasets. Synthetic images have been generated by using appropriate parameters for the modeling of vascular networks or by methods developing deep learning techniques and supported by performance hardware. Our methodology aims to produce high-resolution synthetic fundus images alternative to the increasing use of generative adversarial networks, to overcome the problems that arise in producing slightly modified versions of the same real images, to simulate pathologies and for the prediction of eye-related diseases. Our approach is based on the principle of the least action to place vessels on the simulated eye fundus.","fundus image analysis,synthetic retinal image,data augmentation,statistical features,predictive evaluation diseases",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Medical Informatics",,,,,,
16,"Comparison of classification performance of handpicked, handcrafted and automated-features for fNIRS-BCI system",,,152-157,"Shibu Caleb Jones,Sreedharan Sujesh,Arun K. M.,Kesavadas Chandrasekharan","Shibu CJ,Sreedharan S,Arun KM,Kesavadas C",Shibu CJ,10.1109/ICIIBMS50712.2020.9336392,Department of Science & Technology (India),"In this paper, we have assessed and investigated the classification accuracies of three different techniques to classify functional near-infrared spectroscopy (tNIRS) signals. Signals were extracted from the motor cortex of the brain using a continuous wave multichannel imaging system. The acquired signals were filtered for noise and converted to oxygenated- and deoxygenated-hemoglobin using modified Beer-Lambert law. From the hemodynamic responses statistical features like slope, mean, skewness, kurtosis, peak and variance were extracted, this was trained on a machine learning classifier giving a classification accuracy of 60.66% for support vector machine (SYM) and 57.22% for k nearest neighbor (KNN), likewise from the hemodynamic response we extracted principal component analysis (PCA) vectors and independent component analysis (ICA) vectors, this along with statistical features were trained on the same SYM and KNN classifier yielding a classification accuracy of 71.4% and 71.8% respectively. Instead of handpicking or handcrafting features, if we let deep learning models, in our case, convolutional neural network (CNN) and long short-term memory (LSTM), choose the features and classify them, they gave a jump of 25% accuracy to over 95% for both architectures.","Functional near-infrared spectroscopy (fNIRS),support vector mac/line (SVM),k-nearest neighbors (KNN),convolutional neural network (CNN),long short-term memory (LSTM),neural network,principal component analysis (PCA),independent component analysis (ICA),brain computer interface (BCI)",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Medical Informatics",,,"NEAR-INFRARED,SPECTROSCOPY,LOCATION",,,
17,Contact Sensing via Active Oscillatory Actuation,,,99-104,"Mitra Rahul,Boyd Kirkland,Subedi Divas,Chitrakar Digesh,Aldrich Edwin,Swamy Ananya,Huang Kevin","Mitra R,Boyd K,Subedi D,Chitrakar D,Aldrich E,Swamy A,Huang K",Mitra R,10.1109/ICMRA51221.2020.9398364,Trinity College,"Collaborative robotic approaches seek to incorporate either direct human intervention in tasks previously suited for isolated robot devices, or to use precise machines (cobots) to assist in sensitive tasks. Cobots work alongside humans to extend the scope of robot assistance to spaces such as service and dynamic industrial or assembly tasks. With that said, the close proximity of humans with machines necessitates safe interaction, which can be achieved via lightweight materials and novel sensing capabilities. The inherent physical strength needed in some robot tasks, such as in assembly, make contact sensing of particular concern when introducing a human collaborator. A minimally intrusive method that can be seamlessly subsumed into extant devices is desired. In this paper, such a contact sensor is prototyped and tested. The sensor is bidirectional in that it actively provides an oscillatory actuation signal to a rigid link while simultaneously recording and analyzing the mechanical vibration of said link. Natural oscillation frequency shifts and energy concentration changes due to damping are congruent with different types of contact with the rigid link. The method is lightweight, low-cost and can be quickly incorporated into various manipulators. The developed configuration is advantageous as it does not require any delicate sensors on the robot body and relies primarily on actuated oscillations of the manipulator. Oscillatory acceleration data is collected and subsequently used to train and classify different contact locations using frequency-based features. Three separate classes are distinguished according to contact location. Results are promising and show excellent classification of both contact and contact location.","active sensing,sensors,collaborative robots,collision detection,machine learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Automation & Control Systems,Engineering,Robotics",,,,"2020 IEEE 3RD INTERNATIONAL CONFERENCE ON MECHATRONICS, ROBOTICS AND AUTOMATION (ICMRA 2020)",,
18,DeepPIRATES: Enabling Deployment-Independent Supervised PIR-Based Localization,,,151-156,"Yang Tianye,Guo Peng,Liu Wenyu,Liu Xuefeng","Yang TY,Guo P,Liu WY,Liu XF",Guo P,10.1109/ICMRA51221.2020.9398338,Huazhong University of Science & Technology,"Among existing device-free localization (DFL) methods, the methods based on pyroelectric infrared (PIR) sensor networks are much promising due to their advantages of low cost and privacy protection. Recently, we proposed a deep-learning-based method PIRNet which much decreases the deployment density of PIR-based DFL methods in multi-person scenarios. However, since PIRNet utilizes an end-to-end neural network that receives all the deployed PIR sensors' signals as input for localization, it has a defect of deployment-dependence: it assumes the PIR sensors' deployment in the testing environment is same to the training environment. Otherwise, it requires to be retrained. To address this problem, in this paper, we propose a deployment-independent method DeepPIRATES, which can be applied in environments of any deployments without retraining. DeepPIRATES has the character of deployment-independence because it divides the localization task into two steps and only utilizes deep learning in the first step. Especially, the first step aims at estimating the information about the persons' relative locations to a PIR sensor. Therefore, the utilized neural network only needs to receive a single PIR sensor's signal as input and is independent to the sensors' deployment. In the second step, DeepPIRATES further infers the persons' absolute locations by a particle filter which fuses the predicted information about the persons' relative locations to each sensor and does not require training data. Through DeepPIRATES, we achieve average localization errors of 0.55m, 0.73m, and 0.88m in scenarios of 1-person, 2-persons, and 3-persons with a deployment density of 0.08 sensors/m(2).","device-free localization,PIR sensor network,deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Automation & Control Systems,Engineering,Robotics",,,"TRACKING,SYSTEM","2020 IEEE 3RD INTERNATIONAL CONFERENCE ON MECHATRONICS, ROBOTICS AND AUTOMATION (ICMRA 2020)",,
19,An Investigation of Spectral Band Selection for Hyperspectral LiDAR Technique,9,1,,"Shao Hui,Chen Yuwei,Li Wei,Jiang Changhui,Wu Haohao,Chen Jie,Pan Banglong,Hyyppa Juha","Shao H,Chen YW,Li W,Jiang CH,Wu HH,Chen J,Pan BL,Hyyppa J",Chen YW,10.3390/electronics9010148,The National Land Survey of Finland,"Hyperspectral LiDAR (HSL) has been widely discussed in recent years, which attracts increasing attention of the researchers in the field of electronic information technology. With the application of supercontinuum laser source, it is now possible to develop an HSL system, which can collect spectral and spatial information of targets simultaneously. Meanwhile, eye-safety and miniature HSL device with multiple spectral bands are given more priorities in on-site applications. In this paper, we tempt to investigate how to select spectral bands with a selection method. The proposed method consists of three steps: first, the variances among the classes based on hyperspectral feature parameters, termed inter-class variances, are calculated; second, the channels are sorted based on corresponding variances in descending order, and those with the two highest values are adopted as the initial input of classification; finally, the channels are selected successively from the rest of the sorted sequence until the classification accuracy reaches 100%. To test the performance of the proposed method, we collect 91/71-channel hyperspectral measurements of four different categories of materials with 5 nm spectral resolution using an acousto-optic tunable filter (AOTF) based HSL. Experimental results demonstrate that the proposed method could achieve higher classification accuracy than a random band selection method with different classifiers (naive Bayes (NB) and support vector machine (SVM)) regardless of classification feature parameters (echo maximum and reflectance). To reach 100% accuracy, it demands 8-9 channels on average by echo maximum and 4-5 channels on average by reflectance based on NB classifier; these figures are 3-4 by echo maximum and 2-3 by reflectance with SVM classifier. The proposed method can complete classification task much faster than the random selection method. We further confirm the specific channels for the classification of different materials, and find that the optimal channels vary with different materials. The experimental results prove that the optimal band selection of HSL system for classification is reliable.","hyperspectral LiDAR,band selection,classification,inter-class variance",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"CLASSIFICATION,SYSTEM,FEASIBILITY,INTENSITY,FOREST",ELECTRONICS,http://ira.lib.polyu.edu.hk/bitstream/10397/82144/1/Shao_investigation_spectral_band.pdf,
20,Prediction of BLEVE mechanical energy by implementation of artificial neural network,63,,,"Hemmatian Behrouz,Casal Joaquim,Planas Eulalia,Hemmatian Behnam,Rashtchian Davood","Hemmatian B,Casal J,Planas E,Hemmatian B,Rashtchian D",Rashtchian D,10.1016/j.jlp.2019.104021,Sharif University of Technology,"In the event of a BLEVE, the overpressure wave can cause important effects over a certain area. Several thermodynamic assumptions have been proposed as the basis for developing methodologies to predict both the mechanical energy associated to such a wave and the peak overpressure. According to a recent comparative analysis, methods based on real gas behavior and adiabatic irreversible expansion assumptions can give a good estimation of this energy. In this communication, the Artificial Neural Network (ANN) approach has been implemented to predict the BLEVE mechanical energy for the case of propane and butane. Temperature and vessel filling degree at failure have been considered as input parameters (plus vessel volume), and the BLEVE blast energy has been estimated as output data by the ANN model. A Bayesian Regularization algorithm was chosen as the three-layer backpropagation training algorithm. Based on the neurons optimization process, the number of neurons at the hidden layer was five in the case of propane and four in the case of butane. The transfer function applied in this layer was a sigmoid, because it had an easy and straightforward differentiation for using in the backpropagation algorithm. For the output layer, the number of neurons had to be one in both cases, and the transfer function was purelin (linear). The model performance has been compared with experimental values, proving that the mechanical energy of a BLEVE explosion can be adequately predicted with the Artificial Neural Network approach.","BLEVE,Vessel explosion,Explosion energy,Blast overpressure,Pressure wave,Artificial neural network",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.723,"BLAST,WAVE,OVERPRESSURE",JOURNAL OF LOSS PREVENTION IN THE PROCESS INDUSTRIES,,
21,Convolutional Bayesian Models for Anatomical Landmarking on Multi-Dimensional Shapes.,12264,,786-796,",","Fan Yonghui,Wang Yalin",,10.1007/978-3-030-59719-1_76,,"The anatomical landmarking on statistical shape models is widely used in structural and morphometric analyses. The current study focuses on leveraging geometric features to realize an automatic and reliable landmarking. The existing implementations usually rely on classical geometric features and data-driven learning methods. However, such designs often have limitations to specific shape types. Additionally, calculating the features as a standalone step increases the computational cost. In this paper, we propose a convolutional Bayesian model for anatomical landmarking on multi-dimensional shapes. The main idea is to embed the convolutional filtering in a stationary kernel so that the geometric features are efficiently captured and implicitly encoded into the prior knowledge of a Gaussian process. In this way, the posterior inference is geometrically meaningful without entangling with extra features. By using a Gaussian process regression framework and the active learning strategy, our method is flexible and efficient in extracting arbitrary numbers of landmarks. We demonstrate extensive applications on various publicly available datasets, including one brain imaging cohort and three skeletal anatomy datasets. Both the visual and numerical evaluations verify the effectiveness of our method in extracting significant landmarks.",Anatomical landmarking; Gaussian process kernels,Journal Article,,,,,,,,
22,A Machine Learning-Based Design Rule for Improved Open-Circuit Voltage in Ternary Organic Solar Cells,2,1,,Lee Min-Hsuan,Lee MH,Lee MH,10.1002/aisy.201900108,Industrial Technology Research Institute - Taiwan,"Organic solar cells (OSCs) based on ternary blends are among the most promising photovoltaic technologies. To further improve the power conversion efficiency (PCE), the materials selection criteria must be focused on achieving high open-circuit voltage (V-oc) through the alignment of the energy levels of the ternary blends. Hence, machine-learning approaches are in high demand for extracting the complex correlation between V-oc and the energy levels of the ternary blends, which are crucial to facilitate device design. Herein, the data-driven strategies are used to generate a model based on the available experimental data, and the V-oc is then predicted using available machine-learning methods (the Random Forest regression and the Support Vector regression). In addition, the Random Forest regression is developed to find the appropriate energy-level alignment of ternary OSCs and to reveal the relationship between V-oc and electronic features. Finally, an analysis based on the ranking of variables in terms of importance by the Random Forest model is performed to identify the key feature governing the V-oc and the performance of ternary OSCs. From the perspective of device design, the machine-learning approach provides sufficient insights to improve the V-oc and advances the comprehensive understanding of ternary OSCs.","ternary organic solar cells,machine-learning,open-circuit voltage",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Automation & Control Systems,Computer Science,Robotics",,,"HIGH-PERFORMANCE,3RD,COMPONENTS,EFFICIENT,FULLERENES",ADVANCED INTELLIGENT SYSTEMS,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/aisy.201900108,
23,Cancer Classification Analysis for Microarray Gene Expression Data by Integrating Wavelet Transform and Visual Analysis,,,17-22,"Ji Soo-Yeon,Jeong Dong Hyun","Ji SY,Jeong DH",Ji SY,10.1109/BIBE50027.2020.00011,University System of Maryland,"Cancer classification using microarray gene expression data has received high interest because of its capability of performing cancer diagnosis computationally. However, researchers often faced difficulty in analyzing the data to achieve an accurate cancer diagnosis due to the size and noise issues in the microarray gene expression data. Therefore, it is important to perform feature extraction procedure to enhance the performance in cancer diagnosis. In this study, an approach is proposed by integrating wavelet-based feature extraction and visual analysis for cancer classification. Feature extraction is performed with wavelet transform and validates with a statistical test to determine only statistically valuable features. Visual analysis is also conducted to inspect not only the distribution of features but also the patterns of the cancer data. With cancer datasets, the performances of three machine learning (ML) algorithms for cancer classification are measured to show the effectiveness of the approach. From the performance evaluation study, we found that our approach has an ability to classifying cancers accurately.","cancer classification,microarray analysis,discrete wavelet transform,machine learning,feature selection,visual analysis",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,FEATURE-EXTRACTION,,,
24,Survival prediction and risk estimation of Glioma patients using mRNA expressions,,,35-42,"Wijethilake Navodini,Meedeniya Dulani,Chitraranjan Charith,Perera Indika","Wijethilake N,Meedeniya D,Chitraranjan C,Perera I",Wijethilake N,,University Moratuwa,"Gliomas are lethal type of central nervous system tumors with a poor prognosis. Recently, with the advancements in the micro-array technologies thousands of gene expression related data of glioma patients are acquired, leading for salient analysis in many aspects. Thus, genomics are been emerged into the field of prognosis analysis. In this work, we identify survival related 7 gene signature and explore two approaches for survival prediction and risk estimation. For survival prediction, we propose a novel probabilistic programming based approach, which outperforms the existing traditional machine learning algorithms. An average 4 fold accuracy of 74% is obtained with the proposed algorithm. Further, we construct a prognostic risk model for risk estimation of glioma patients. This model reflects the survival of glioma patients, with high risk for low survival patients.","Glioma,gene expression,risk score,probabilistic programming,bayesian neural networks",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"NEURAL-NETWORK,ANALYSIS,PROGNOSIS,TUMORS,MODEL",,http://arxiv.org/pdf/2011.00659,
25,Task Balanced Multimodal Feature Selection to Predict the Progression of Alzheimer's Disease,,,196-203,"Brand Lodewijk,O'Callaghan Braedon,Sun Anthony,Wang Hua","Brand L,O'Callaghan B,Sun A,Wang H",Brand L,10.1109/BIBE50027.2020.00040,Colorado School of Mines,"The social and financial costs associated with Alzheimer's disease (AD) result in significant burdens on our society. In order to understand the causes of this disease, public-private partnerships such as the Alzheimer's Disease Neuroimaging Initiative (ADNI) release data into the scientific community. These data are organized into various modalities (genetic, brain-imaging, cognitive scores, diagnoses, etc.) for analysis. Many statistical learning approaches used in medical image analysis do not explicitly take advantage of this multimodal data structure. In this work we propose a novel objective function and optimization algorithm that is designed to handle multimodal information for the prediction and analysis of AD. Our approach relies on robust matrix-factorization and row-wise sparsity provided by the l(2,1)-norm in order to integrate multimodal data provided by the ADNI. These techniques are jointly optimized with a classification task to guide the feature selection in our proposed Task Balanced Multimodal Feature Selection method. Our results, when compared against some widely used machine learning algorithms, show improved balanced accuracies, precision, and Matthew's correlation coefficients for identifying cognitive decline. In addition to the improved prediction performance, our method is able to identify brain and genetic biomarkers that are of interest to the clinical research community. Our experiments validate existing brain biomarkers and single nucleotide polymorphisms located on chromosome 11 and detail novel polymorphisms on chromosome 10 that, to the best of the authors' knowledge, have not previously been reported. We anticipate that our method will be of interest to the greater research community and have released our method's code online.","Alzheimer's disease,multimodal,classification,alternating direction method of multipliers,biomarker identification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"BIOMARKERS,REGRESSION",,,
26,Explainable Deep Learning for Biomarker Classification of OCT Images,,,204-210,"Wang Yiyang,Lucas Mirtha,Furst Jacob,Fawzi Amani A.,Raicu Daniela","Wang YY,Lucas M,Furst J,Fawzi AA,Raicu D",Wang YY,10.1109/BIBE50027.2020.00041,DePaul University,"Advanced form of age-related macular degeneration (AMD) is a major health burden that can lead to irreversible vision loss in the elderly population. The early signs of AMD are drusen, which appear as yellowish deposits under the retina. The end-stages of AMD include two forms: wet AMD (neovascular) and geographic atrophy (GA, non-neovascular). We propose a deep learning approach using a pre-trained VGG-19 neural network to classify the optical coherence tomography (OCT) images into wet AMD, GA, drusen, and healthy images. To explain the results, we quantify and present the prediction confidence and reliability as well as the regions of interest deemed to be important by the deep learning model when classifying OCT images. The sensitivity of classification for wet AMD, GA, drusen, and healthy images was 91.67%, 88.00%, 96.30% and 100% respectively, with the most confident predictions being for the drusen and healthy images. Visual inspection of the misclassified images using heatmaps using the Gradient-weighted Class Activation Mapping (Grad-CAM) algorithm revealed that, for most of the misclassified images that had high prediction confidence, the algorithm identified correctly more than one region of interest, each belonging to a different AMD category. We concluded that, rather than assigning just one label to an AMD image, algorithms for AMD classification should allow multi-labels as images generally show evidence of more than one stage of AMD simultaneously (e.g., drusen as the predominant region and GA as a small region of interest).","Age-related macular degeneration,Image Classification,Transfer Learning,Grad-CAM",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"DIABETIC,MACULAR,EDEMA",,,
27,"Determination of Image-based Biomarkers for the Diagnosis of Hypertrophic Cardiomyopathy, Hypertensive Cardiomyopathy and Amyloidosis From Texture Analysis in Cardiac MRI",,,230-235,"Vidal-Sospedra Ines,Ruiz-Espana Silvia,Pineiro-Vidal Tania,Manuel Santabarbara Jose,Maceira Alicia,Moratal David","Vidal-Sospedra I,Ruiz-Espana S,Pineiro-Vidal T,Santabarbara JM,Maceira A,Moratal D",Vidal-Sospedra I,10.1109/BIBE50027.2020.00045,Universitat Politecnica de Valencia,"Hypertrophic cardiomyopathy (HCM), hypertensive cardiomyopathy (HIP), and amyloidosis (AM) are pathologies in which a thickening of a portion of the myocardium occurs. All of them are manifested in a similar way on magnetic resonance images, which means that in most cases it is necessary to resort to the use of invasive diagnostic techniques. The objective of this work is to develop quantitative biomarkers that can differentiate between patients with these three pathologies using texture analysis on cardiac magnetic resonance imaging (MRI). In this study, a total of 103 patients underwent cine MRI. Two studies were carried out, one binary with patients with HCM and HIP and one multiclass considering the three pathologies. The left ventricular myocardium was segmented according to the standardized 17-segment model. A total of 43 features for each of the six segments were extracted using 5 different statistical methods. Four predictive models were implemented to evaluate the performance of the classification. Good precision results were obtained in both studies. For the binary study, a maximum AUC of 0.91 +/- 0.06 was obtained with the K-Nearest Neighbours model and for the multiclass study the best performance (AUC = 0.89 +/- 0.12) was achieved using the Support Vector Machine classifier.","hypertrophic cardiomyopathy,hypertensive cardiomyopathy,amyloidosis,magnetic resonance imaging,heart,texture analysis,classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
28,Automated Mortality Prediction in Critically-ill Patients with Thrombosis using Machine Learning,,,247-254,"Danilatou V,Antonakaki D.,Tzagkarakis C.,Kanterakis A.,Katos V,Kostoulas T.","Danilatou V,Antonakaki D,Tzagkarakis C,Kanterakis A,Katos V,Kostoulas T",Danilatou V,10.1109/BIBE50027.2020.00048,Bournemouth University,"Venous thromboembolism (VTE) is the third most common cardiovascular condition. Some high risk patients diagnosed with VTE need immediate treatment and monitoring in intensive care units (ICU) as the mortality rate is high. Most of the published predictive models for ICU mortality give information on in-hospital mortality using data recorded in the first day of ICU admission. The purpose of the current study is to predict in-hospital and after-discharge mortality in patients with VTE admitted to ICU using a machine learning (ML) framework.
We studied 2,468 patients from the Medical Information Mart for Intensive Care (MIMIC-III) database, admitted to ICU with a diagnosis of VTE. We formed ML classification tasks for early and late mortality prediction. In total, 1,471 features were extracted for each patient, grouped in seven categories each representing a different type of medical assessment. We used an automated ML platform, JADBIO, as well as a class balancing combined with a Random Forest classifier, in order to evaluate the importance of class imbalance. Both methods showed significant ability in prediction of early mortality (AUC=0.92). Nevertheless, the task of predicting late mortality was less efficient (AUC=0.82).
To the best of our knowledge, this is the first study in which ML is used to predict short-term and long-term mortality for ICU patients with VTE based on a multitude of clinical features collected over time.","MIMIC-III,ICU mortality prediction,thrombosis,machine learning,imbalanced classification,AutoML",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"VENOUS,THROMBOEMBOLISM,PULMONARY-EMBOLISM,ACUTE,PHYSIOLOGY,PROGNOSTICATION,VALIDATION,SEVERITY,INDEX",,http://eprints.bournemouth.ac.uk/34702/1/IEEE_BIBE_2020_paper_CameraReady.pdf,
29,Improved Automatic Bone Segmentation Using Large-Scale Simulated Ultrasound Data to Segment Real Ultrasound Bone Surface Data,,,288-294,"Patel Hridayi,Hacihaliloglu Ilker","Patel H,Hacihaliloglu I",Patel H,10.1109/BIBE50027.2020.00054,Rutgers State University New Brunswick,"Automatic segmentation of bone surfaces from ultrasound images is of great interest in the ultrasound-guided computer assisted orthopedic surgery field. These automatic segmentations help the system locate where the bone surface is in the image which can allow for proper surgical manipulation. Most recently, methods based on deep learning have achieved promising results. However, a drawback is that these methods require a large number of training dataset. Therefore, the main objective of this work is the investigation of how large-scale simulated ultrasound data can be used to improve the accuracy of deep learning-based segmentation methods. A transfer learning network and a mixed network approach were used to evaluate how well the large-scale simulated data worked to segment ultrasound bone surfaces. The Sorensen-Dice Coefficient and Average Euclidean Distance values were calculated to determine that by using simulated bone ultrasound data, the success of traditional deep learning methods increases compared to using small-scale real ultrasound data only. Initial results show improvements in segmentation performance can be obtained by combining simulated ultrasound data with in vivo ultrasound scans.","ultrasound bone segmentation,computer assisted surgery,neural networks,biomedical image segmentation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
30,Contour detection in synthetic bi-planar X-ray images of the scapula: Towards improved 3D reconstruction using deep learning,,,303-307,"Namayega Catherine,Malila Bessie,Douglas Tania S.,Mutsvangwa Tinashe E. M.","Namayega C,Malila B,Douglas TS,Mutsvangwa TEM",Namayega C,10.1109/BIBE50027.2020.00056,University of Cape Town,"Three-dimensional (3D) reconstruction of two-dimensional (2D) X-ray images using statistical shape models provides a cost-effective way of increasing diagnostic X-ray utility, especially in low-resource settings. Feature-constrained model fitting is one way to obtain patient-specific models from a statistical model. This approach requires an accurate selection of corresponding features, usually landmarks, from the bi-planar X-ray images. However, super-positioned structures in 2D X-ray images confound this approach. This paper reports on the use of a deep learning algorithm to detect the contour of the scapula in synthetic bi-planar X-ray images to address this limitation. Two independent U-net models were trained to learn the mapping between synthetic bi-planar X-ray images of the scapula. The first model was trained to learn the mapping of the scapula contour in the lateral image view given the anterior-posterior image view and the second to learn the mapping of the scapula contour in the anterior-posterior image view given the lateral image view. The predicted images, when compared to the ground-truth, gave Dice coefficient values of 0.93 and 0.96 for the first and second models, respectively. These results are comparable to those in literature. However, these trained models did not generalize to real data, suggesting a need for further training with manually segmented images.","Convolutional neural network,Deep learning,U-net model,Statistical shape model,3D from 2D reconstruction",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
31,Deep Multiview Learning to Identify Population Structure with Multimodal Imaging,,,308-314,"Feng Yixue,Kim Mansu,Yao Xiaohui,Liu Kefei,Long Qi,Shen Li","Feng YX,Kim MS,Yao XH,Liu KF,Long Q,Shen L",Feng YX,10.1109/BIBE50027.2020.00057,University of Pennsylvania,"We present an effective deep multiview learning framework to identify population structure using multimodal imaging data. Our approach is based on canonical correlation analysis (CCA). We propose to use deep generalized CCA (DGCCA) to learn a shared latent representation of non-linearly mapped and maximally correlated components from multiple imaging modalities with reduced dimensionality. In our empirical study, this representation is shown to effectively capture more variance in original data than conventional generalized CCA (GCCA) which applies only linear transformation to the multi-view data. Furthermore, subsequent cluster analysis on the new feature set learned from DGCCA is able to identify a promising population structure in an Alzheimer's disease (AD) cohort. Genetic association analyses of the clustering results demonstrate that the shared representation learned from DGCCA yields a population structure with a stronger genetic basis than several competing feature learning methods.","Deep learning,multiview learning,deep generalized canonical correlation analysis,multimodal imaging,image-driven population structure",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,PHENOTYPES,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7917002,
32,Estimating Hard-tissue Conditions from Dental Images via Machine Learning,,,315-322,"Bao Jingxuan,Kim Mansu,Sun Qing,Hara Anderson T.,Maupome Gerardo,Shen Li","Bao JX,Kim M,Sun Q,Hara AT,Maupome G,Shen L",Bao JX,10.1109/BIBE50027.2020.00058,University of Pennsylvania,"Despite the great success of machine learning in various biomedical domains, applications to dental hard tissue conditions (primarily on dental Caries, Erosive Tooth Wear (ETW), and Fluorosis) are under-explored, in particular for analyzing photographic images. The clinical diagnostics of these dental hard-tissue conditions is routinely performed by visual examination but is often limited by its subjectivity. To bridge this gap, we apply four categories of machine learning strategies including nine different methods with two different feature representations to estimate the probability and severity of dental hard-tissue conditions from photographic tooth images. Our first empirical study is performed on the real dataset containing both controls and cases, and the best probability estimation results are achieved by Extra Trees Regression (RMSE: 0.030, Pearson correlation: 0.600) for Caries, Decision Tree (RMSE: 0.183, Pearson correlation: 0.581) for ETW, and Bayesian ARD Regression (RMSE: 0.191, Pearson correlation: 0.745) for Fluorosis. Our second empirical study is performed on the case only datasets, and the best severity estimation results are achieved by Extra Trees Regression (RMSE: 0.029, Pearson correlation: 0.687) for Caries, Bayesian ARD Regression and Linear Regression (RMSE: 0.192, Pearson correlation: 0.490) for ETW, and Bayesian ARD Regression (RMSE: 0.238, Pearson correlation: 0.537) for Fluorosis.
These results indicate that machine learning models provide promising opportunities to help clinical evaluation and save resources in the management of these dental conditions.","photographic dental imaging,computer-aided estimation and diagnosis,machine learning,dental hard-tissue conditions",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
33,Learning Local Feature Descriptions in 3D Ultrasound,,,323-330,"Wulff Daniel,Hagenah Jannis,Ipsen Svenja,Ernst Floris","Wulff D,Hagenah J,Ipsen S,Ernst F",Wulff D,10.1109/BIBE50027.2020.00059,University of Lubeck,"Tools for automatic image analysis are gaining importance in the clinical workflow, ranging from time-saving tools in diagnostics to real-time methods in image-guided interventions. Over the last years, ultrasound (US) imaging has become a promising modality for image guidance due to its ability to provide volumetric images of soft tissue in real-time without using ionizing radiation. One key challenge in automatic US image analysis is the identification of suitable features to describe the image or regions within, e.g. for recognition, alignment or tracking tasks. In recent years, features that were learned data-drivenly provided promising results. Even though these approaches outperformed hand-crafted feature extractors in many applications, there is still a lack of feature learning for local description of three-dimensional US (3DUS) images. In this work, we present a completely data-driven feature learning approach for 3DUS images for usage in target tracking. To this end, we use a 3D convolutional autoencoder (AE) with a custom loss function to encode 3DUS image patches into a compact latent space that serves as a general feature description. For evaluation, we trained and tested the proposed architecture on 3DUS images of the liver and prostate of five different subjects and assessed the similarity between the decoded patches and the original ones. Subject- and organ-specific as well as general AEs are trained and evaluated. Specific AEs could reconstruct patches with a mean Normalized Cross Correlation of 0.85 and 0.81 at maximum in liver and prostate, respectively. It can also be shown that the AEs are transferable across subjects and organs, with a small accuracy decrease to 0.83 and 0.81 (liver, prostate) for general AEs. In addition, a first tracking study was performed to show feasibility of tracking in latent space. In this work, we could show that it is possible to train an AE that is transferable across two target regions and several subjects. Hence, convolutional AEs present a promising approach for creating a general feature extractor for 3DUS.","Deep learning,Feature learning,Convolutional autoencoder,Medical ultrasound analysis",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
34,Visualization for Histopathology Images using Graph Convolutional Neural Networks,,,331-335,"Sureka Mookund,Patil Abhijeet,Anand Deepak,Sethi Amit","Sureka M,Patil A,Anand D,Sethi A",Sureka M,10.1109/BIBE50027.2020.00060,Indian Institute of Technology System (IIT System),"With an increase in the use of deep learning for computer-aided diagnosis in medical images, the criticism of the black-box nature of the deep learning models is also on the rise. The medical community prefers interpretable models for its due diligence and advancing the understanding of disease and treatment mechanisms. For instance, in histology, while cells and their spatial relationships manifest in rich detail, it is difficult to modify convolutional neural networks to point out the relevant visual features. We adopt an approach to model the histology of a cancer tissue as a graph of its constituent nuclei. We analyze this graph using two novel graph convolutional network frameworks - one based on node occlusion, and another based on attention mechanism - for disease classification and visualization. The proposed methods highlight the relative contribution of each cell nucleus in the disease diagnosis. As proofs of concept, our frameworks not only distinguish accurately between IDC and DCIS breast cancers as well as Gleason 3 and 4 prostate cancers, but they also highlight important visual details, such as boundaries of tumor nests in DCIS and those of glands in Gleason 3.","Biomedical Image Processing & Analysis,deep learning,graph convolutional neural networks,visualization",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,http://arxiv.org/pdf/2006.09464,
35,Heatmap Template Generation for COVID-19 Biomarker Detection in Chest X-rays,,,438-445,"Lucas Mirtha,Lerma Miguel,Furst Jacob,Raicu Daniela","Lucas M,Lerma M,Furst J,Raicu D",Lucas M,10.1109/BIBE50027.2020.00077,DePaul University,"Detecting and identifying patterns in chest X-ray images of Covid-19 patients are important tasks for understanding the disease and for making differential diagnosis. Given the relatively small number of available Covid-19 X-ray images and the need to make progress in understanding the disease, we propose a transfer learning technique applied to a pretrained VGG19 neural network to build a deep convolutional model capable of detecting four possible conditions: normal (healthy), bacteria, virus (not Covid-19), and Covid-19. The transformation of the multi-class deep learning output into binary outputs and the detection of Covid-19 image patterns using Grad-CAM technique show promising results. The discovered patterns are consistent across images from a given class of disease and constitute explanations of how the deep learning model makes classification decisions. In the long run, the identified patterns can serve as biomarkers for a given disease in chest X-ray images.","Neural Networks,Biomarkers,Covid-19,Artificial Intelligence",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
36,OMAD: On-device Mental Anomaly Detection for Substance and Non-Substance Users,,,466-471,"Dey Emon,Roy Nirmalya","Dey E,Roy N",Dey E,10.1109/BIBE50027.2020.00081,University System of Maryland,"Stay at home order during the COVID-19 helps flatten the curve but ironically, instigate mental health problems among the people who have Substance Use Disorders. Measuring the electrical activity signals in brain using off-the-shelf consumer wearable devices such as smart wristwatch and mapping them in real time to underlying mood, behavioral and emotional changes play striking roles in postulating mental health anomalies. In this work, we propose to implement a wearable, On-device Mental Anomaly Detection (OMAD) system to detect anomalous behaviors and activities that render to mental health problems and help clinicians to design effective intervention strategies. We propose an intrinsic artifact removal model on Electroencephalogram (EEG) signal to better correlate the fine-grained behavioral changes. We design model compression technique on the artifact removal and activity recognition (main) modules. We implement a magnitude-based weight pruning technique both on convolutional neural network and Multilayer Perceptron to employ the inference phase on Nvidia Jetson Nano; one of the tightest resource-constrained devices for wearables. We experimented with three different combinations of feature extractions and artifact removal approaches. We evaluate the performance of OMAD in terms of accuracy, F1 score, memory usage and running time for both unpruned and compressed models using EEG data from both control and treatment (alcoholic) groups for different object recognition tasks. Our artifact removal model and main activity detection model achieved about approximate to 93% and 90% accuracy, respectively with significant reduction in model size (70%) and inference time (31%).","Substance Use Disorder,mental anomaly detection,EEG artifact,weight pruning,resource constrained devices",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"MOBILE,EEG",,https://mdsoar.org/bitstream/11603/20638/1/Paper_239_OMAD_E%20Dey_N%20Roy..pdf,
37,Fusion Learning on Multiple-Tag RFID Measurements for Respiratory Rate Monitoring,,,472-480,"Hansen Stephen,Schwartz Daniel,Stover Jesse,Tajin Md Abu Saleh,Mongan William M.,Dandekar Kapil R.","Hansen S,Schwartz D,Stover J,Tajin MA,Mongan WM,Dandekar KR",Hansen S,10.1109/BIBE50027.2020.00082,Drexel University,"Future advances in the medical Internet of Things (IoT) will require sensors that are unobtrusive and passively powered. With the use of wireless, wearable, and passive knitted smart garment sensors, we monitor infant respiratory activity. We improve the utility of multi-tag Radio Frequency Identification (RFID) measurements via fusion learning across various features from multiple tags to determine the magnitude and temporal information of the artifacts. In this paper, we develop an algorithm that classifies and separates respiratory activity via a Regime Hidden Markov Model compounded with higher-order features of Minkowski and Mahalanobis distances. Our algorithm improves respiratory rate detection by increasing the Signal to Noise Ratio (SNR) on average from 17.12 dB to 34.74 dB. The effectiveness of our algorithm in increasing SNR shows that higher-order features can improve signal strength detection in RFID systems. Our algorithm can be extended to include more feature sources and can be used in a variety of machine learning algorithms for respiratory data classification, and other applications. Further work on the algorithm will include accurate parameterization of the algorithm's window size.","Sensor fusion,Signal denoising",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8130190,
38,Stress Level Detection Using Physiological Sensors,,,509-512,"Gunaydin Ozge,Arslan Reis Burak","Gunaydin O,Arslan RB",Gunaydin O,10.1109/BIBE50027.2020.00088,Galatasaray University,"According to the World Health Report published in 2018, in every 24 seconds, someone dies on the road. One of the causes that lead to traffic accidents is drivers' mental workload and stress.
In this paper, ways of detecting drivers' stress are discussed, previous studies are examined, and an experimental setup for detecting stress is built. For experiments, a racing game is used. One subject played five different levels of a racing game while her face and play screen were recorded, together with EDA (Electrodermal Activity) and ECG (Electrocardiogram) signals acquired through sensors attached to her body. Recorded games are used for identifying hidden stressors that may cause stress on the subject. Statistical features were extracted and the Random Decision Forest (RDF) algorithm is used for classification. RDF yields an accuracy rate of 70.74% when all five level records are used and between 70% - 80% for individual records.","EDA,ECG,HR,SFS,RDF",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
39,Unsupervised EEG Cybersickness Prediction with Deep Embedded Self Organizing Map,,,538-542,"Lee Yonggun,Alamaniotis Miltiadis","Lee Y,Alamaniotis M",Lee Y,10.1109/BIBE50027.2020.00093,University of Texas System,"Cybersickness is a situation that may result from the overexpose to computer devices by a person. Symptoms associated with this sickness are dizziness, headache, nausea, or any kind of disoriented motion.Prediction of cybersickness is essential to avoid the aforementioned symptoms and subsequently secure people's health. In this work a Deep Embedded Self Organizing Map that is an unsupervised learning tool is jointly combined with an Auto-encoder implementing a clustering method. The Auto encoder is designed from EEGNET, which is a specialized CNN for EEG prediction, and is tailored to predict EEG based cybersickness. The proposed method is compared to KNN and SOM clustering methods and prediction accuracy was measured with the purity index and NMI. Test results give that KNN predicted cyberscikness by providing Purity equal to 0.9375 and NMI to 0.386519, while SOM had 0.9432 Purity and 0.403901 NMI. Lastly, DESOM provided the most efficient index values and more specifically: 0.96875 purity and 0.42561 NMI.","Unsupervised-Learning,Self Organizing Map,Auto-encoder,Cybersickness,EEG",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
40,Mitigating Patient-to-Patient Variation in EEG Seizure Detection using Meta Transfer Learning,,,548-555,"Zhu Yuanda,Saqib Mohammed,Ham Elizabeth,Belhareth Sami,Hoffman Ryan,Wang May Dongmei","Zhu YD,Saqib M,Ham E,Belhareth S,Hoffman R,Wang MD",Wang MD,10.1109/BIBE50027.2020.00095,University System of Georgia,"Electroencephalogram (EEG) signals can be used for seizure detection, but the seizure patterns found in between patient's EEGs can have significant variations. Specifically, focal spikes in patient-specific channels as well as other patient specific patterns can strongly indicate seizure activity. Manual diagnosis on these markers leads to inconsistent interrater agreement and poor detection accuracy. Previous automation attempts have ignored patient specific approaches but fail to generalize to previously unseen patients. To reduce subjectivity in manual diagnosis, we propose an automatic seizure detection pipeline that includes quality control, preprocessing, and meta transfer learning for both feature extraction and classification. To mitigate the inter-patient seizure pattern variation, we adapt Meta UPdate Strategy (MUPS) for four-class classification on the world's largest public seizure dataset of EEGs, Temple University Seizure Corpus (TUSZ). Different from existing works on binary seizure detection, we use the non-seizure samples and the top three most frequent seizure types for seizure detection. Our experiments show that the meta transfer learning approach achieves macro-F1 of 0.5103 and AUC of 0.6792, which outperforms the baseline learners (shallow and deep) by mitigating patient-topatient variations. We demonstrate the effectiveness of meta transfer learning in feature extraction and classification for multi-class seizure detection.",EPILEPSY,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,EPILEPSY,,,
41,"Semi-Supervised Classification of Noisy, Gigapixel Histology Images",,,563-568,"Pulido J. Vince,Guleria Shan,Ehsan Lubaina,Fasullo Matthew,Lippman Robert,Mutha Pritesh,Shah Tilak,Syed Sana,Brown Donald E.","Pulido JV,Guleria S,Ehsan L,Fasullo M,Lippman R,Mutha P,Shah T,Syed S,Brown DE",Pulido JV,10.1109/BIBE50027.2020.00097,Johns Hopkins University,"One of the greatest obstacles in the adoption of deep neural networks for new medical applications is that training these models typically require a large amount of manually labeled training samples. In this body of work, we investigate the semi-supervised scenario where one has access to large amounts of unlabeled data and only a few labeled samples. We study the performance of MixMatch and FixMatch-two popular semi-supervised learning methods-on a histology dataset. More specifically, we study these models' impact under a highly noisy and imbalanced setting. The findings here motivate the development of semi-supervised methods to ameliorate problems commonly encountered in medical data applications.","Histology,Machine Learning,Semi-supervised Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,SMOTE,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8144886,
42,Exploiting the Transferability of Deep Learning Systems Across Multi-modal Retinal Scans for Extracting Retinopathy Lesions,,,577-581,"Hassan Taimur,Akram Muhammad Usman,Werghi Naoufel","Hassan T,Akram MU,Werghi N",Hassan T,10.1109/BIBE50027.2020.00099,Khalifa University of Science & Technology,"Retinal lesions play a vital role in the accurate classification of retinal abnormalities. Many researchers have proposed deep lesion-aware screening systems that analyze and grade the progression of retinopathy. However, to the best of our knowledge, no literature exploits the tendency of these systems to generalize across multiple scanner specifications and multi-modal imagery. Towards this end, this paper presents a detailed evaluation of semantic segmentation, scene parsing and hybrid deep learning systems for extracting the retinal lesions such as intra-retinal fluid, sub-retinal fluid, hard exudates, drusen, and other chorioretinal anomalies from fused fundus and optical coherence tomography (OCT) imagery. Furthermore, we present a novel strategy exploiting the transferability of these models across multiple retinal scanner specifications. A total of 363 fundus and 173,915 OCT scans from seven publicly available datasets were used in this research (from which 297 fundus and 59,593 OCT scans were used for testing purposes). Overall, a hybrid retinal analysis and grading network (RAGNet), backboned through ResNet50, stood first for extracting the retinal lesions, achieving a mean dice coefficient score of 0.822.","Retinal Lesions,Ophthalmology,Convolutional Neural Networks,Fundus Photography,Optical Coherence Tomography.",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,SEGMENTATION,,http://arxiv.org/pdf/2006.02662,
43,Segmentation of Macular Edema Datasets with Small Residual 3D U-Net Architectures,,,582-587,"Frawley Jonathan,Willcocks Chris G.,Habib Maged,Geenen Caspar,Steel David H.,Obara Boguslaw","Frawley J,Willcocks CG,Habib M,Geenen C,Steel DH,Obara B",Frawley J,10.1109/BIBE50027.2020.00100,Durham University,"This paper investigates the application of deep convolutional neural networks with prohibitively small datasets to the problem of macular edema segmentation. In particular, we investigate several different heavily regularized architectures. We find that, contrary to popular belief, neural architectures within this application setting are able to achieve close to human-level performance on unseen test images without requiring large numbers of training examples. Annotating these 3D datasets is difficult, with multiple criteria required. It takes an experienced clinician two days to annotate a single 3D image, whereas our trained model achieves similar performance in less than a second. We found that an approach which uses targeted dataset augmentation, alongside architectural simplification with an emphasis on residual design, has acceptable generalization performance - despite relying on fewer than 15 training examples.","Machine learning,image processing and computer vision,medicine,segmentation,neural nets",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,http://arxiv.org/pdf/2005.04697,
44,A Thrifty Annotation Generation Approach for Semantic Segmentation of Biofilms,,,602-607,"Chakravarthy Adithi D.,Chundi Parvathi,Subramaniam Mahadevan,Ragi Shankarachary,Gadhamshetty Venkata R.","Chakravarthy AD,Chundi P,Subramaniam M,Ragi S,Gadhamshetty VR",Chakravarthy AD,10.1109/BIBE50027.2020.00103,University of Nebraska System,"Recent advances in semantic segmentation using deep learning methods have achieved promising results on several benchmark datasets. However, the primary challenge involved in such segmentation approaches is the availability of applicable training data. Since only experts are equipped to effectively annotate (or label) any available data for training semantic segmentation networks, the effort and cost involved can be considerable, especially for larger datasets. In this paper, we aim to address this problem by proposing a Thrifty Annotation Generation approach that records high performance on segmentation networks with minimal expert effort and cost (intervention). We present a deep active learning framework that combines the use of marker-controlled watershed (MC-WS) algorithm to generate pseudo labels for segmentation networks (U-Net) and active learning to significantly minimize effort and cost by selecting only the most impactful training data for labeling. We built the initial U-Net model by generating pseudo labels for the training data using MC-WS. We then make use of the uncertainty information (entropy) of each image provided by the U-Net to determine the most uncertain or effective images for expert labeling. We evaluated the TAG approach using the 2012 ISBI Challenge dataset for 2D segmentation and a novel Biofilm dataset. Our approach achieved promising segmentation accuracy (IoU) and classification accuracy with minimal expert intervention. The results of our experiments also indicate that the TAG approach can be generalized to achieve high-performance segmentation results on any dataset using minimal expert effort and cost.","Watershed algorithm,Semantic segmentation,Pseudo labels,Biofilms,and Active learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
45,Fully Automated End-to-End Neuroimaging Workflow for Mental Health Screening,,,642-647,"Thomas Nikita,Perumalla Akhila,Rao Srinivasa,Thangaraj Venkatesan,Ravi Keerthi Sravan,Geethanath Sairam,Kim Hansuk,Srinivasan Girish","Thomas N,Perumalla A,Rao S,Thangaraj V,Ravi KS,Geethanath S,Kim H,Srinivasan G",Thomas N,10.1109/BIBE50027.2020.00109,"PhenoMx Inc, New York, NY 10016 USA.","Growing research has proven that mental illnesses, such as depression and chronic stress, can be better understood through the use of medical imaging. However, these findings fail utilization in real-world clinical settings. The intention of this work is to demonstrate the ability to provide widespread access to medical imaging through computer-assisted technology across various community care providers, thus allowing meaningful use outcomes to population and public health. We have created an end-to-end fully automated approach to mental health screening leveraged by artificial intelligence. This workflow involves four core solutions: a voice-activated user interaction, rapid 3D T1-weighted contrast and a resting-state functional acquisition, deep learning-based image analysis, and 3D interactive visualization. Intelligent protocolling is used to obtain optimal pulse sequence parameters to satisfy any time constraint. Rigid registration, k-means tissue classification, and an augmented artificial neural network trained on a public database and Talairach atlas segments out over 60 brain structures with corresponding quantitative measures. Functional MR images are processed via seed-based connectivity to produce functional connectivity maps. Finally, a simplistic user experience implementing text-to-speech, speech-to-text technology coupled with a medical image viewer gives interactive passage to medical imaging results. While various tools have emerged to examine both structural and functional MRI within the research space, a simple straightforward, voice-activated interface to perform the scan, automatically process and retrieve meaningful results, that can be accomplished in less than 20 minutes, enables non-specialists to comprehend all relevant information. With this proposed method, insights on a patient's mental health beyond surveys and questionnaires can be determined, such as the quantitative phenotypic impact of stress on the brain, with minimal assistance. This pipeline allows medical imaging to expand beyond radiology for wider population health management protocol adoption.","MAJOR DEPRESSIVE DISORDER,IMPROVEMENT,PREDICTORS,PUTAMEN",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"MAJOR,DEPRESSIVE,DISORDER,IMPROVEMENT,PREDICTORS,PUTAMEN",,,
46,A Deep Learning Method for Intraoperative Age-agnostic and Disease-specific Cardiac Output Monitoring from Arterial Blood Pressure,,,662-666,"Yang Hyun-Lim,Lee Hyung-Chul,Jung Chul-Woo,Kim Min-Soo","Yang HL,Lee HC,Jung CW,Kim MS",Kim MS,10.1109/BIBE50027.2020.00112,Korea Advanced Institute of Science & Technology (KAIST),"Cardiac output monitoring plays an important role in intraoperative or intensive care medicine. Arterial pressure waveform derived cardiac output monitoring has been mainly used for real clinical fields despite its inexact output because gold standard thermodilution based cardiac output monitoring is too invasive to use it widely. In this study, we propose DLAPCO, the novel deep learning method for the more accurate and age-agnostic arterial pressure waveform derived cardiac output monitoring. DLAPCO exploits two attention mechanism to calibrate the model's output to medical procedure or overcome the locality of convolutional neural network in analyzing raw vital signs. Through the experiments using the real-world hospital intraoperative data, we have shown that DLAPCO significantly outperforms the commercial arterial pressure waveform derived cardiac output monitoring device which use demographic information.","Deep learning,Cardiac Output,Stroke Volume,Arterial Blood Pressure,Intraoperative",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
47,Improving ECG Classification Interpretability using Saliency Maps,,,675-682,"Jones Yola,Deligianni Fani,Dalton Jeff","Jones Y,Deligianni F,Dalton J",Jones Y,10.1109/BIBE50027.2020.00114,University of Glasgow,"Cardiovascular disease is a large worldwide healthcare issue; symptoms often present suddenly with minimal warning. The electrocardiogram (ECG) is a fast, simple and reliable method of evaluating the health of the heart, by measuring electrical activity recorded through electrodes placed on the skin. ECGs often need to be analyzed by a cardiologist, taking time which could be spent on improving patient care and outcomes.
Because of this, automatic ECG classification systems using machine learning have been proposed, which can learn complex interactions between ECG features and use this to detect abnormalities. However, algorithms built for this purpose often fail to generalize well to unseen data, reporting initially impressive results which drop dramatically when applied to new environments. Additionally, machine learning algorithms suffer a 'black-box' issue, in which it is difficult to determine how a decision has been made. This is vital for applications in healthcare, as clinicians need to be able to verify the process of evaluation in order to trust the algorithm.
This paper proposes a method for visualizing model decisions across each class in the MIT-BIH arrhythmia dataset, using adapted saliency maps averaged across complete classes to determine what patterns are being learned. We do this by building two algorithms based on state-of-the-art models. This paper highlights how these maps can be used to find problems in the model which could be affecting generalizability and model performance. Comparing saliency maps across complete classes gives an overall impression of confounding variables or other biases in the model, unlike what would be highlighted when comparing saliency maps on an ECG-by-ECG basis.","machine learning,ECG,classification,model interpretation,saliency maps,cardiovascular disease,MIT-BIH",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,IMPACT,,http://eprints.gla.ac.uk/223339/1/223339.pdf,
48,Selecting Feature Sets and Comparing Classification Methods for Cognitive State Estimation,,,683-690,"Pettersson Kati,Tervonen Jaakko,Narvainen Johanna,Henttonen Pentti,Maattanen Ilmari,Mantyjarvi Jani","Pettersson K,Tervonen J,Narvainen J,Henttonen P,Maattanen I,Mantyjarvi J",Pettersson K,10.1109/BIBE50027.2020.00115,VTT Technical Research Center Finland,"Acute stress and high workload are part of everyday work at safety critical fields (e.g. health care). Adaptive human computer interaction systems could support and guide a nurse or a doctor in these hectic situations. Seamless interaction between human and computer requires accurate cognitive state estimation of the person. Currently studies are mainly focused on detecting between two cognitive states with full set of physiologically inspired features. This study demonstrates a classification of different types of stress during Maastricht Acute Stress Test by using feature combinations from electro-oculogram (EOG) and electrocardiogram (ECG) signals in general and personalized approaches, comparing three different classifiers. The classification is evaluated for features extracted from both signals separately and together, and the most important features are selected and reported. Results indicate that the best performance is achieved when features from both EOG and ECG signals are used, and approximately twenty features from EOG and ECG signals are enough to distinguish the two/three states. A personalized approach together with feature selection and support vector machine classifier achieves accuracies of 96.9% and 86.3% in classifying between two states (relaxation and stress) and three states (relaxation, psycho-social stress, and physiological stress), respectively, which exceed state-of-the-art performance. Thus cognitive state estimation benefits from combining selected eye and heart parameters which suggests a promising basis for real-time estimation in the future.","classification,cognitive state,feature selection,electrocardiogram,electro-oculogram,machine learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
49,Fully Automated Mitral Inflow Doppler Analysis Using Deep Learning,,,691-696,"Elwazir Mohamed Y.,Akkus Zeynettin,Oguz Didem,Ye Zi,Oh Jae K.","Elwazir MY,Akkus Z,Oguz D,Ye Z,Oh JK",Elwazir MY,10.1109/BIBE50027.2020.00116,Mayo Clinic,"Echocardiography (echo) is an indispensable tool in a cardiologist's diagnostic armamentarium. To date, almost all echocardiographic parameters require time-consuming manual labeling and measurements by an experienced echocardiographer and exhibit significant variability, owing to the noisy and artifact-laden nature of echo images. For example, mitral inflow (MI) Doppler is used to assess left ventricular (LV) diastolic function, which is of paramount clinical importance to distinguish between different cardiac diseases. In the current work we present a fully automated workflow which leverages deep learning to a) label MI Doppler images acquired in an echo study, b) detect the envelope of MI Doppler signal, c) extract early and late filing (E- and A-wave) flow velocities and E-wave deceleration time from the envelope. We trained a variety of convolutional neural networks (CNN) models on 5544 images of 140 patients for predicting 24 image classes including MI Doppler images and obtained overall accuracy of 0.97 on 1737 images of 40 patients. Automated E and A wave velocity showed excellent correlation (Pearson R 0.99 and 0.98 respectively) and Bland-Altman agreement (mean difference 0.06 and 0.05 m/s respectively and SD 0.03 for both) with the operator measurements. Deceleration time also showed good but lower correlation (Pearson R 0.82) and Bland-Altman agreement ( mean difference: 34.1ms, SD: 30.9ms). These results demonstrate feasibility of Doppler echocardiography measurement automation and the promise of a fully automated echocardiography measurement package.","Doppler,Echocardiography,Machine learning,Automation,artificial intelligence",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"ECHOCARDIOGRAPHY,VELOCITIES",,http://arxiv.org/pdf/2011.12429,
50,DeepWave: Non-contact Acoustic Receiver Powered by Deep Learning to Detect Sleep Apnea,,,723-727,"Zhang Qingxue,Boente Ryan","Zhang QX,Boente R",Zhang QX,10.1109/BIBE50027.2020.00123,Indiana University System,"Sleep apnea impacts one billion people worldwide and if left untreated, increases risk for stroke by two times, and risk for cardiovascular mortality by five times. Traditional sleep measurement approaches are either too subjective due to relying on patients' retrospective report, or too expensive and inconvenient due to the bulky equipment like Polysomnography that requires an overnight stay in a sleep lab different from the patients' home sleep environment. To enable robust, long-term at-home daily sleep apnea monitoring, in this study we propose a non-contact acoustic receiver powered by artificial intelligence (AI) innovations named DeepWave. More specifically, we have customized an environmental acoustic receiver for remote, off-bed breath sound capturing, avoiding the need to wear devices on the body and the sensitivity of on-bed devices to posture variances. We have further developed a novel convolutional neural network to detect and discriminate even subtle changes in respiratory events even when the acoustic signal is weak. Evaluated through human experiments, DeepWave, powered by the customized acoustic receiver and deep learning, shows promising potential for reliable, long-term at-home sleep apnea measurement. DeepWave is expected to greatly advance big data-driven precision sleep medicine.","Smart Health,Deep Learning,Sleep Apnea,Acoustic Receiver,Big Data,Precision Medicine",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
51,CLASSIFICATION OF BENIGN AND METASTATIC LYMPH NODES IN LUNG CANCER WITH DEEP LEARNING,,,728-733,Pham Tuan D.,Pham TD,Pham TD,10.1109/BIBE50027.2020.00124,Prince Mohammad Bin Fahd University,"This paper presents the development of a non-invasive image-analysis method for improving the diagnostic accuracy of mediastinal lymph node metastasis in patients with lung cancer. The approach adopts pretrained deep learning models incorporated with the geostatistical simulation of texture of benign and metastatic lung lymph nodes in computed tomography (CT) images for classification. Using 271 CT samples of mediastinal lymph nodes collected from 148 patients with lung cancer, deep-learning models coupled with the stochastic simulated data augmentation provide the best classification results. The simulation of texture in these medical images was able to discover rich radiomic features to ascertain subtle difference between benign and metastatic lymph nodes and enhance the performance of the deep-learning models for complex pattern classification. The proposed approach is very promising to be utilized as a computerized tool for medical image analysis.","Lung cancer,metastasis,benign,computed tomography,geostatistical simulation,radiomic features,deep learning,convolutional neural networks,medical image classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"SEQUENTIAL,GAUSSIAN,SIMULATION,TEXTURE,ANALYSIS,MEDICAL,IMAGES,RISK-FACTORS,ADENOCARCINOMA,SIZE",,,
52,Unsupervised Learning of Deep-Learned Features from Breast Cancer Images,,,740-745,"Lee Sanghoon,Farley Colton,Shim Simon,Yoo Wook-Sung,Zhao Yanjun,Choi Wookjin","Lee S,Farley C,Shim S,Yoo WS,Zhao YJ,Choi W",Lee S,10.1109/BIBE50027.2020.00126,Marshall University,"Detecting cancer manually in whole slide images requires significant time and effort on the laborious process. Recent advances in whole slide image analysis have stimulated the growth and development of machine learning-based approaches that improve the efficiency and effectiveness in the diagnosis of cancer diseases. In this paper, we propose an unsupervised learning approach for detecting cancer in breast invasive carcinoma (BRCA) whole slide images. The proposed method is fully automated and does not require human involvement during the unsupervised learning procedure. We demonstrate the effectiveness of the proposed approach for cancer detection in BRCA and show how the machine can choose the most appropriate clusters during the unsupervised learning procedure. Moreover, we present a prototype application that enables users to select relevant groups mapping all regions related to the groups in whole slide images.","Breast cancer,whole slide images,machine learning,unsupervised learning,k-means clustering",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,http://arxiv.org/pdf/2006.11843,
53,Classification of oesophagic early-stage cancers: deep learning versus traditional learning approaches,,,746-751,"Ferreira Jorge,Domingues Ines,Sousa Olga,Sampaio Ines Lucena,Santos Joao A. M.","Ferreira J,Domingues I,Sousa O,Sampaio IL,Santos JAM",Ferreira J,10.1109/BIBE50027.2020.00127,"Univ Porto FCUP, Fac Ciencias, Porto, Portugal.","Esophageal cancer is a disease with a high prevalence which can be evaluated by a variety of imaging modalities. Computer vision techniques could provide a valuable help in the analysis of these images, for it would allow an enhancement in diagnostic and staging accuracies, a decrease in medical workflow time and preventing patients' loss of quality of life.
Traditional learning techniques are frequently used in the biomedical imaging field, and deep learning algorithms are starting to see their rise in usage in this field as well. In this paper, both traditional and deep learning algorithms are applied on a dataset provided by Instituto Portugues de Oncologia (IPO) consisting of CT and three PET scans acquired at different treatment phases of 14 patients with oesophageal cancer.
The main goal is to distinguish patients that need surgery from the ones that do not. The traditional learning method consisted of manually extracting the features and applying feature selection algorithms for further classification. Feature level and decision level fusion were also conducted. The deep learning method consisted of using convolutional neural networks to extract and classify the image features. Moreover, traditional and deep learning techniques were used simultaneously, where the features were extracted and selected by a pretrained network and classified using the traditional learning classifiers.
Traditional Learning methods achieved 92.86% accuracy, while for feature extraction with deep learning followed by classification with a traditional classifier was able to reach 100% accuracy. The difference has, however, proven not to be statistically significant. In this way, for this particular problem and conditions, it can be said that traditional techniques are capable of achieving results as good as with deep learning.","Oesophagic cancer,PET,CT,Classification,Deep Learning,Traditional Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"ESOPHAGEAL,CANCER,PREDICTION,FEATURES",,,
54,Directed Fine Tuning Using Feature Clustering for Instance Segmentation of Toxoplasmosis Fundus Images,,,767-772,"Abeyrathna Dilanga,Subramaniam Mahadevan,Chundi Parvathi,Hasanreisoglu Murat,Halim Muhammad Sohail,Ozdal Pinar Cakar,Quan Nguyen","Abeyrathna D,Subramaniam M,Chundi P,Hasanreisoglu M,Halim MS,Ozdal PC,Nguyen Q",Abeyrathna D,10.1109/BIBE50027.2020.00130,University of Nebraska System,"Medical image segmentation is a challenging problem for computer vision approaches where deep learning networks have achieved impressive successes in recent years. In this paper, we propose a directed, fine tuning approach for instance segmentation networks by using feature clustering of predictions along with labeled training instances to improve network performance. The approach directs and limits analyses of predicted instances by experts to similar training instances only and reduces manual overheads by managing the number of instances that need to be examined. Sub-optimal network predictions are handled either by retraining the networks on data augmented with the relevant training instances, correcting training labels, and/or by readjusting network inference parameters. We first develop a state-of-the-art Mask R-CNN based network for instance segmentation of fundus images with retinal lesions and scars caused by Ocular Toxoplasmosis. Then, we show how the proposed approach can be applied to fine tune this network in a directed manner using feature clustering using a pre-trained CNN network. We demonstrate the robustness of our proposed approach with the evaluation results - mask average IoU increased by 7% and mAP under 0.5 IoU threshold increased by 20%. Our experiments also show that fine tuning by analyzing 66% of the predicted instances achieves the same improvement as that obtained by all of the predicted instances, a significant reduction of the manual overheads for fine tuning.","Mask R-CNN,Medical Imaging,Ocular Toxoplasmosis,Instance segmentation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
55,Validation of the machine learning approach for 3D reconstruction of carotid artery from ultrasound imaging,,,789-794,"Djukic Tijana,Arsic Branko,Djorovic Smiljana,Filipovic Nenad,Koncar Igor","Djukic T,Arsic B,Djorovic S,Filipovic N,Koncar I",Djukic T,10.1109/BIBE50027.2020.00134,University of Kragujevac,"It is important to investigate the state of the arteries in order to detect atherosclerotic plaques in the early stage and then treat them appropriately. One of the diagnostic techniques is the ultrasound (US) examination. In order to obtain a more detailed and comprehensive overview of the state of the patient's carotid artery, 3D reconstruction using the available 2D cross-sections can be performed. In this paper, deep learning is used for the automatic segmentation of US images, and this data is then used to reconstruct the 3D model of the patient-specific carotid artery. The validation of the proposed approach is performed by comparing two relevant clinical parameters for accessing the severity of vessel stenosis - the plaque length and the percentage of stenosis. Good validation results demonstrate that this method is capable of accurately performing segmentation of the lumen of carotid artery from US images and thus it can be a useful tool for assessing the state of the arteries in clinical diagnostics.","finite element mesh generation,segment extraction,severity of stenosis,model validation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,FLOW,,https://zenodo.org/record/4563909/files/Paper%20BIBE%20final%20TDj.pdf,
56,Ensemble Learning for Prediction of Toxicity in Prostate Cancer Radiotherapy: Comparison Between Stacking and Genetic Algorithm Weighted Voting,,,884-889,"Filias Filippos,Mylona Eugenia,Blekos Kostas,Supiot Stephane,de Crevoisier Renaud,Acosta Oscar","Filias F,Mylona E,Blekos K,Supiot S,de Crevoisier R,Acosta O",Filias F,10.1109/BIBE50027.2020.00150,University of Patras,"Prediction of urinary toxicity after prostate cancer radiotherapy (RT) is remarkably challenging. Not only it is a multifaceted phenomenon, encompassing different symptoms (retention, dysuria, haematuria, etc.), but also a multifactorial problem, as it depends on both patient-specific clinical factors, individual biological parameters, and dosimetric patterns. Thus, there are a plethora of potential predictors compared to the paucity of available symptom-specific toxicity data. On top of that, in elder patients, urinary complications are not necessarily treatment-related which introduces important noise to the urinary toxicity assessment. In recent years, a growing interest in machine learning (ML) appears within the radiotherapy community. The goal of ML algorithms is to learn from existing data to recognize patterns in the population and make informed decisions. The purpose of this study was to implement two advanced heterogeneous ensemble methods, namely Stacking and Genetic Algorithm-based Weighted Average Voting for improving urinary toxicity prediction in the case of prostate cancer radiotherapy. Our analysis demonstrated that both GA-based Voting (AUC=0.66) and Stacking (AUC=0.80) outperformed the standard Weighted Voting classifier (AUC=0.66). In conclusion, Genetic Algorithm-based Weighted Average Voting may improve prediction performance compared to individual classifiers or conventional voting ensembles but at high computational cost. Stacking, on the other hand, appears significantly more powerful for predicting urinary toxicity at less computational cost.","machine learning,ensemble,prediction,prostate cancer,toxicity",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,MODELS,,,
57,ANN Classification of Female Breast Tumor Type Prediction Using EIM Parameters,,,890-893,"Kabir Shahriar,Ahad Mohammad","Kabir S,Ahad M",Kabir S,10.1109/BIBE50027.2020.00151,University System of Georgia,"Electrical Impedance Myography (EIM) is a painless, non-invasive electrical bio-impedance measurement technique for assessing neurological disease states. In this electro-physiological technique, the EIM parameters, namely resistance, reactance, and phase magnitude, depend on several anatomic factors such as muscle girth, skin thickness, fat thickness. EIM may also be affected by several non-anatomic factors like frequency, electrode size, and inter-electrode distance. This paper explores the female breast tumor type classification by extracting EIM parameters from a 3D model of the female breast. The extracted EIM parameters from the simulation employ an artificial neural network (ANN) to identify benign and malignant tumor types. A 3D finite element (FEM) model of a female breast with a rectangular shape of electrodes are developed with a base shape of an 80 mm outer radius. The subsequent shapes are designed as -20% and +20% of the base shape, as mentioned above. This paper presents the EIM parameters that can classify female breast tumor types with an accuracy of 96.2% using an ANN.","Artificial neural network,ANN,Benign tumor,Female breast cancer,Breast tumor,Electrical impedance myography,EIM,Finite element method,FEM,Machine learning,ML,Malignant tumor,Tumor type classification,Tumor location prediction",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,MUSCLE,,,
58,Breast Mass Detection and Classification based on Digital Temporal Subtraction of Mammogram Pairs,,,894-899,"Loizidou Kosmia,Skouroumouni Galateia,Nikolaou Christos,Pitris Costas","Loizidou K,Skouroumouni G,Nikolaou C,Pitris C",Loizidou K,10.1109/BIBE50027.2020.00152,University of Cyprus,"Breast cancer is one of the deadliest malignancies worldwide. In mammography, the most reliable screening tool for its diagnosis, expert radiologists review the mammograms to determine whether the patient has any signs of disease. Unfortunately, the evaluation of breast abnormalities is challenging, even for experienced radiologists. Computer-Aided Detection (CAD) systems can assist in the detection of breast cancer. In this work, an algorithm for the automatic detection and classification of masses, based on subtraction of sequential digital mammograms, image registration and machine learning, is presented. Previous studies assessed the use of sequential mammograms to perform temporal analysis by creating a new temporal feature vector. Temporal subtraction registers and subtracts the prior mammogram from the current one, prior to performing mass detection and classification. A new dataset, which includes sequential pairs from 40 patients (160 mammograms) with precisely annotated mass locations (benign and suspicious), was created to assess the performance of the algorithm. For the classification, various features were extracted and six classifiers were used in a leave-one-patient-out cross-validation. The accuracy of the classification of masses as benign or suspicious increased from 90.83% (with the previously described temporal analysis) to 96.51% (with temporal subtraction). The improvement was statistically significant with p < 0.05. These results demonstrate the effectiveness of the proposed technique of temporal subtraction of mammograms for the detection of masses.","Breast cancer,computer-aided diagnosis,digital mammography,breast mass,temporal subtraction",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,https://zenodo.org/record/4396017/files/BIBE2020_Final_Version.pdf,
59,A State-of-the-art Deep Transfer Learning-Based Model for Accurate Breast Cancer Recognition in Histology Images,,,900-905,"Yari Yasin,Hieu Nguyen","Yari Y,Nguyen H",Yari Y,10.1109/BIBE50027.2020.00153,University College of Southeast Norway,"Breast cancer is widely prevalent in women. To diagnose it, pathologists evaluate breast histopathology images under a microscope in various magnifications. However, the number of pathologists per population is low in many countries, and a mistake is probable. Nowadays, deep learning has become a popular artificial intelligence research trends. Even though deep neural networks have obtained promising results in image processing, the need for extensive training data avoids its use in medical image processing. After the evaluation of various state-of-the-art deep learning methods and algorithms in medical data processing, this study proposes an effective deep transfer learning-based model, relying on pre-trained DCNN using an extensive data of ImageNet dataset which improves state-of-the-art systems in both binary and multi-class classification. The weights of the pre-trained DesneNet121 on the Imagenet are transferred as initial weights first, and then the model is fine-tuned with a deep classifier along with data augmentation to distinguish various malignant and benign samples in the two categories of binary and multi-class classification. In the multi-class classification, the proposed model obtained up to 97% image-level accuracy. In binary classification, the model obtained up to 100% image-level accuracy. The achieved-results are outperforming previous studies accuracies in multiple performance metrics in breast cancer CAD systems. Moreover, the proposed method is both flexible and scalable, meaning it can be easily expanded to cover the detection of other types of diseases in the future and be integrated with more CNNs to increase its generalization capabilities.","Breast cancer,CNN,DensNet,BreakHis dataset,Medical image classification,Computer-Aided Diagnosis (CAD)",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,CLASSIFICATION,,,
60,Clinical grade SpO2 prediction through semi-supervised learning,,,914-921,"Priem Gurvan,Martinez Coralie,Bodinier Quentin,Carrault Guy","Priem G,Martinez C,Bodinier Q,Carrault G",Priem G,10.1109/BIBE50027.2020.00155,"Biosency, Cesson Sevigne, France.","We reuse photoplethysmography (PPG) datasets obtained during the clinical testing of a wrist-worn reflectance pulse oximeter and build a deep neural network (DNN) with the goal of achieving RMSE < 3.5% for SpO2 levels ranging from 70% to 100%, which is the required clinical accuracy. We show that, with supervised learning alone, the DNN does not achieve the required performance (RMSE = 4.4%). When pretraining the DNN in an unsupervised manner with a method based on contrastive representation learning to take advantage of a set of unlabelled PPG signals, the DNN achieves clinical-grade accuracy (RMSE = 2.91%). This work therefore highlights the importance of semi-supervised learning for the development of wearable medical devices, for which unlabelled data is abundant but labelled data is scarce.","photoplethysmography,SpO2,semi-supervised learning,few labelled data,wearable medical devices",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"HEART-RATE,ESTIMATION",,,
61,Smart Shoes for Temporal Identification and Corrections to Assist People with Abnormal Walking Patterns,,,929-933,"Sudharshan Johnson,Goodman Garrett,Bourbakis Nikolaos","Sudharshan J,Goodman G,Bourbakis N",Sudharshan J,10.1109/BIBE50027.2020.00157,Wright State University Dayton,"Arthritis is a very common medical issue which describes joint pain or joint disease. The most common type, being Osteoarthritis, is due to the cartilage in a joint wearing away over time which leaves the bones to rub against each other causing pain and discomfort. According to the Centers for Disease Control and Prevention (CDC), more than 50 million adults have been diagnosed with Arthritis in the United States of America which is 1 in 5 adults. This equates to a financial cost of $304 Billion in 2013 between direct medical cost and lost wages. Over a period of time, it has been observed that an uneven distribution of pressure (body weight) across the foot while walking increases wear and tear to knee cartilage and thus leads to Osteoarthritis. Therefore, we propose a novel smart shoe for temporal identification and correction for people with abnormal walking patterns consisting of uneven pressure distributions. Our smart shoes include five pressure sensors, four vibrators, memory storage, a processor, a Bluetooth transceiver, a power supply, and a Smart Software application on a Smartphone which houses a Decision Tree (DT) for walking pattern predictions. Our Machine Learning approach has a 91.68% accuracy and shows promise for assisting people with Arthritis.","Arthritis,Machine Learning,Gait,Walking Patterns,Smart Shoes,Smart Technology",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,GAIT,,,
62,A machine learning pipeline for predicting joint space narrowing in knee osteoarthritis patients,,,934-941,"Ntakolia Charis,Kokkotis Christos,Moustakidis Serafeim,Tsaopoulos Dimitris","Ntakolia C,Kokkotis C,Moustakidis S,Tsaopoulos D",Ntakolia C,10.1109/BIBE50027.2020.00158,"Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.","Osteoarthritis is the common form of arthritis in the knee (KOA). It is identified as one of the main causes of pain leading even to disability. To exploit the continuous increase in medical data concerning KOA, various studies employ big data and Artificial Intelligence analytics for KOA prognosis or treatment. However, most of the studies are limited to either specific groups of patients or specific groups of features, such as MRI, X-ray images or questionnaires. In this study, a machine learning pipeline is proposed to predict knee joint space narrowing (JSN) in KOA patients. The proposed methodology, that is based on multidisciplinary data from the osteoarthritis initiative (OAI) database, employs: (i) a clustering process to identify groups of people with progressing and non-progressing JSN; (ii) a robust feature selection process consisting of filter, wrapper and embedded techniques that identifies the most informative risk factors that contribute to JSN prediction; and (iii) a decision making process based on the evaluation and comparison of various classification algorithms towards the selection and development of the final prediction model for JSN. The evaluation was conducted with respect to model's overall performance, robustness and highest achieved accuracy. A 78.3% and 77.7% accuracy were achieved in left and right leg by Logistic Regression on the group of the 164 risk factors and SVM on the group of the 88 and 90 risk factors, respectively.","machine learning,knee osteoarthritis,joint space narrowing prediction,feature selection,interpretation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,IDENTIFICATION,,,
63,Visualizing functional network connectivity difference between middle adult and older subjects using an explainable machine-learning method,,,955-960,"Sendi Mohammad S. E.,Chun Ji Ye,Calhoun Vince D.","Sendi MSE,Chun JY,Calhoun VD",Sendi MSE,10.1109/BIBE50027.2020.00162,University System of Georgia,"In this study, we classified older (>= 63 years old) from middle adult (45-63 years old) subjects by estimating whole-brain functional network connectivity (FNC) including the connectivity among subcortical network (SCN), auditory network (ADN), sensorimotor network (SMN), visual sensory network (VSN), cognitive control network (CCN), default mode network (DMN), cerebellar network (CBN) from the adult subjects (n = 9394; 45-81 y). We used three tree-based classifiers, including random forest (RF), XGBoost, and CATBoost. Next, we leveraged the SHapley Additive exPlanations (SHAP) approach as an explainable feature learning method to model the difference between the brain connectivity of the old and middle adult subjects. Opposed to the conventional statistical learning, which typically assesses each feature separately, the explainable machine learning method used here offers a generalized model in the connectivity difference between older and middle adults. Based on this method, we found that all three models successfully differentiate middle adult adults from older adults based on whole-brain FNC. We also found that all brain networks contributed to the top 20 features selected by the SHAP method in all three models. We highlighted the role of the CCN and SNC in differentiating between these two groups.","resting-state fMRI,functional network connectivity",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"AGE-RELATED-CHANGES,DEFAULT,MEMORY",,,
64,Deep Learning based NAS Score and Fibrosis Stage Prediction from CT and Pathology Data,,,981-986,"Jana Ananya,Qu Hui,Rattan Puru,Minacapelli Carlos D.,Rustgi Vinod,Metaxas Dimitris","Jana A,Qu H,Rattan P,Minacapelli CD,Rustgi V,Metaxas D",Jana A,10.1109/BIBE50027.2020.00166,Rutgers State University New Brunswick,"Non-Alcoholic Fatty Liver Disease (NAFLD) is becoming increasingly prevalent in the world population. Without diagnosis at the right time, NAFLD can lead to non-alcoholic steatohepatitis (NASH) and subsequent liver damage. The diagnosis and treatment of NAFLD depend on the NAFLD activity score (NAS) and the liver fibrosis stage, which are usually evaluated from liver biopsies by pathologists. In this work, we propose a novel method to automatically predict NAS score and fibrosis stage from CT data that is non-invasive and inexpensive to obtain compared with liver biopsy. We also present a method to combine the information from CT and H&E stained pathology data to improve the performance of NAS score and fibrosis stage prediction, when both types of data are available. This is of great value to assist the pathologists in computer-aided diagnosis process. Experiments on a 30-patient dataset illustrate the effectiveness of our method.","NAFLD activity score,Liver fibrosis,Deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"MR-IMAGING,FEATURES,LIVER,DIAGNOSIS",,http://arxiv.org/pdf/2009.10687,
65,A prototype educational virtual assistant for diabetes management,,,999-+,"Anastasiadou Magdalini,Alexiadis Anastasios,Polychronidou Eleftheria,Votis Konstantinos,Tzovaras Dimitrios","Anastasiadou M,Alexiadis A,Polychronidou E,Votis K,Tzovaras D",Anastasiadou M,10.1109/BIBE50027.2020.00169,Centre for Research & Technology Hellas,"The global prevalence of diabetes is escalating. Several digital health strategies have recently risen to assist in optimal diabetes management and reduce clinical, economic, and humanistic implications. This paper describes the first prototype of an Educational Virtual Assistant (EVA) intended to increase people's engagement in diabetes management, through continuous education, interaction, and recommendations. Since the patient holds a pivotal role in his disease progression, the overall objective of EVA is to reduce the risk of critical events, by fostering them to adopt optimal diabetes management strategies and finally improving their daily quality of life. EVA was trained based on standardized educational material and implemented based on natural language processing (NLP) techniques that present an opportunity to use natural language understanding (NLU) through machine learning (ML). The assistant was integrated into a diabetes self-management application and tested within Chrodis Plus JA. Initial usability and acceptability results are presented here. Overall, this pilot study yielded a positive opinion, as well as suggestions for improvement. On-going work includes testing the first prototype with older people with T2D plus health professionals in primary care units in Greece and incorporating a ML-based context-sensitive dialogue manager, which is expected to convey a more flexible dialogue flow.","conversational assistant,chatbot,Diabetes Mellitus,patient education and information,natural language understanding",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
66,EMG Based Simultaneous Wrist Motion Prediction Using Reinforcement Learning,,,1016-1021,"Gardner Noah,Tekes Coskun,Weinberg Nate,Ray Nick,Duran Julian,Housley Stephen N.,Wu David,Hung Chih-Cheng","Gardner N,Tekes C,Weinberg N,Ray N,Duran J,Housley SN,Wu D,Hung CC",Gardner N,10.1109/BIBE50027.2020.00172,University System of Georgia,"Advanced robotic devices have the potential to improve both clinical and home-based rehabilitation procedures in stroke therapy. Having an active, intelligent device that can interact with the patient in both actuation and sensing feedback from the body would help improve the assessment of rehabilitation. Reliable signal detection and recognition of user intents are the key points of developing active robotic devices. Surface Electromyography (sEMG) technique is commonly used for non-invasive biological signal detection from muscle activations. This work presents a simple Convolutional Neural Network (CNN) model combined with A2C actor-critic algorithm-based reinforcement learning to predict simultaneous wrist motion intention direction. The proposed model was tested with experimental 2-channel sEMG datasets using both deep features extracted from CNN and hand-crafted features. We achieved an average accuracy of approximately 92% regardless of the instantaneous angular position of the wrist. We also presented generalization test results to demonstrate the performance of the model to a completely new subject's sEMG data.","EMG,Stroke Rehabilitation,CNN,Reinforcement Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"REHABILITATION,EXOSKELETON,MOTOR",,,
67,Extracting Explainable Assessments of Alzheimer's disease via Machine Learning on brain MRI imaging data,,,1036-1041,"Achilleos K. G.,Leandrou S.,Prentzas N.,Kyriacou P. A.,Kakas A. C.,Pattichis C. S.","Achilleos KG,Leandrou S,Prentzas N,Kyriacou PA,Kakas AC,Pattichis CS",Achilleos KG,10.1109/BIBE50027.2020.00175,University of Cyprus,"A plethora of machine learning and deep learning methods are used for the assessment of Alzheimer's Disease (AD) from brain structural changes as seen in Magnetic Resonance Imaging (MRI) with highly satisfactory results. However, these models are black-box and lack an explicit declarative knowledge representation and thus there is a difficulty in generating the underlying explanatory imaging structures. The objective of this study was to investigate the usefulness of rule extraction in the assessment of AD using decision trees (DT) and random forests (RF) algorithms and integrating the extracted rules within an argumentation- based reasoning framework in order to make the results easy to interpret and explain. The DT and RF algorithms were applied on brain MRI images acquired from normal controls (NC) and AD subjects. The KNIME analytics platform was used to compute the DT and the R project was used for the RF. The argumentation model implemented in the Gorgias framework achieved an average accuracy of 91%, exhibiting improved results compared to the models of DT and RF. The overall performance of all models in this study is in agreement with other studies. In addition, the explanations given by our approach for the various possible predictions provide a more useful and complete assessment of the state of the patient/case at hand. This study demonstrated the usefulness of rule extraction in the assessment of AD based on MRI features and the positive results of the use of the argumentation based symbolic reasoning for composing and interpreting the ML results.","Alzheimer's disease,decision trees,random forests,quantitative MRI,Explainable AI,Argumentation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
68,Varying Information Complexity in Functional Domain Interactions in Schizophrenia,,,1042-1047,"Batta Ishaan,Abrol Anees,Fu Zening,Calhoun Vince","Batta I,Abrol A,Fu ZN,Calhoun V",Batta I,10.1109/BIBE50027.2020.00176,University System of Georgia,"Understanding the associations of the structural and functional patterns of the brain is vital. Recent studies have focused on utilizing this information within and across the different functional and anatomical domains (i.e., groups of brain networks) using neuroimaging data. In this work, we use a Bayesian optimization-based method known as the Tree Parzen Estimator (TPE) to identify variation in the nature of information encoded by different functional magnetic resonance imaging (fMRI) sub-domains of the brain. We show by repeated cross-validation on a schizophrenia classification task that specific sub-domains may require more sophisticated learning architectures to contribute optimally to classification, while others require less complicated ones. Our findings reveal the need for adaptive, hierarchical learning frameworks catering to features from different sub-domains to optimally identify features enabling the prediction of the outcome of interest.","Schizophrenia,fMRI,Functional Connectivity,Sub-domain Analysis,Multilayer Perceptron,Bayesian Optimization,Hyperparameter Optimization",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
69,Comprehensive End-to-End Workflow for Visceral Adipose Tissue and Subcutaneous Adipose Tissue quantification: Use Case to improve MRI accessibility,,,1060-1064,"Nandakumar Gautham,Srinivasan Girish,Kim Hansuk,Pi Jaewoo","Nandakumar G,Srinivasan G,Kim H,Pi J",Nandakumar G,10.1109/BIBE50027.2020.00179,"PhenoMX Inc, Chicago, IL 60601 USA.","Studies prove the correlation between Body Fat distribution and insulin resistance which is a major risk factor for Type 2 diabetes and cardiovascular diseases (CVD). Educating individuals with more accurate measures of fat distribution outside fat percentage and body mass index (BMI) along with preventive solutions to susceptible conditions encourage better lifestyle choices and routines. Essential fat compartments that constitute the total fat distribution are visceral adipose tissue (VAT), superficial subcutaneous adipose tissue (SSAT) and deep subcutaneous adipose tissue (DSAT) which can be measured using whole-body MRI from head to foot. We propose a two-stage solution: rapid Dixon sequence acquisition, fat compartment segmentation. A clinically standard and predefined protocol is designed to automate the acquisition with optimal pulse sequence parameters to satisfy any time constraint. Two separate fully convolutional networks (UNet) with attention gates trained on our in-house dataset of 53 patients are used to segment VAT and SAT respectively. Further, the SAT segment is sub-classified into SSAT and DSAT by detecting the fascia superficialis using modified level sets. The models are capable of segmenting VAT, DSAT, and SSAT from head to foot without any manual intervention. Our method achieves a dice score of 0.868 for SAT segmentation and 0.9107 for VAT segmentation. The whole pipeline from data acquisition to reporting can be completed in under 20 minutes. Furthermore, our experiments show that our approach to estimating the segmentations are better than similar deep learning models trained on abdomen MRI. Our study demonstrates a use case of how MRI as a modality can be used outside of a typical clinical setting and set up as an upstream imaging solution to make it a more accessible tool for health evaluation/screening for the public.","INSULIN-RESISTANCE,SEGMENTATION",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,"INSULIN-RESISTANCE,SEGMENTATION",,,
70,BPARC: A novel spatio-temporal (4D) data-driven brain parcellation scheme based on deep residual networks,,,1071-1076,"Kazemivash Behnam,Calhoun Vince D.","Kazemivash B,Calhoun VD",Kazemivash B,10.1109/BIBE50027.2020.00181,University System of Georgia,"Brain parcellation plays a significant role in computational neuroimaging by dividing the brain into meaningful anatomical sub-regions which can be used to study broad brain functionalities and structures. Most ongoing brain parcellation research has focused on fixed regions that do not vary across individuals or over time. However, brain functional organization is by its very nature dynamic and ignoring this can lead to misleading results. In this work, we have tried to address this shortcoming in fMRI-based brain parcellation by proposing a novel 4D approach using a deep residual network structure, trained to predict probabilities of voxels in each volume belonging to independent components extracted from fMRI images. Results show that the presented approach not only provides informative 4D spatiotemporal networks which are individualized but also linked across subjects, providing an important tool for further study of the human brain.","Brain Parcellation,Independent Component Analysis,fMRI,Residual Deep Network,Neuroimaging",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Mathematical & Computational Biology,Medical Informatics",,,,,,
71,The microbial community in an alkaline saline sediment of a former maar lake bed,20,1,542-555,"Ibarra-Sanchez Claudia L.,Prince Laurette,Aguirre-Noyola Jose L.,Sanchez-Cerda Karla E.,Navaro-Noya Yendi E.,Luna-Guido Marco,Conde-Barajas Eloy,Dendooven Luc,Selene Gomez-Acata Elizabeth","Ibarra-Sanchez CL,Prince L,Aguirre-Noyola JL,Sanchez-Cerda KE,Navaro-Noya YE,Luna-Guido M,Conde-Barajas E,Dendooven L,Gomez-Acata ES",Gomez-Acata ES,10.1007/s11368-019-02371-x,"TNM Inst Tecnol Celaya, Lab Environm Biotechnol, Guanajuato 38010, Guanajuato, Mexico.","Purpose The ""Hoya del Rincon de Parangueo (HRP)"" is a maar that contained a perennial alkaline lake that drained in the 1980s so that a sediment with high pH and extreme salinity remained. The aim of this work was to determine how the bacterial and archaeal community was controlled by these extreme conditions.
Materials and methods Sediment samples were collected from the 0-20-cm layer along a crater-wide transect. Physicochemical characteristics and the archaeal and bacterial community were determined by analysis of the 16S rRNA through Illumina sequencing.
Results and discussion The sediment samples had a pH 10 and an electrolytic conductivity (EC) that ranged from 29.8 to 74.4 dSm(-1). Three archaeal and 37 bacterial phyla were detected with Euryarchaeota (relative abundance 62.7 +/- 17.6%) dominating the Archaea, and Proteobacteria (28.2 +/- 10.7%) and Actinobacteria (21.1 +/- 6.4%) the Bacteria. The most abundant archaeal genus was Candidatus Nitrososphaera while Euzebya, Halomonas, KSA1 and Planctomycetes dominated the bacterial gene. Thaumarchaeota were enriched in sediment samples with a higher Pb content and Euryarchaeota in sediment with a higher Mg content, while Crenarchaeota and Candidatus Nitrososphaera were enriched in sediment with a higher sand, total N and organic C content. Proteobacteria were enriched in sediment with a higher organic C and total N, Si and sand content, while Bacteroidetes and Planctomycetes in sediment with a higher water holding capacity and clay and Mg content. Members of KSA1 and Euzebya were enriched in sediment with a lower EC, organic C and total N content. Although a large number of bacterial and archaeal groups were correlated significantly with a range of sediment characteristics, the sediment characteristics explained the variation of only two bacterial groups > 50% (TM6 and Desulfonatronospira) using the machine learning tool random-Forest and none of the archaeal groups. Archaeal and bacterial functional guilds were dominated by ammonium oxidation and nitrite reduction.
Conclusions Although the different sediment samples were dominated often by similar bacterial and archaeal groups, the measured sediment characteristics explained little of the variation found between the sampling points. The high bacterial and archaeal diversity indicated that the site might be a source of unclassified species and phylotypes with specific metabolic capacities involved in the N and S cycles.","Alpha diversity,Diversity analysis,Illumina sequencing,Maar,Microbial communities,Transect",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Environmental Sciences & Ecology,Agriculture",,3.587,"SP,NOV.,DIVERSITY,ARCHAEA,SOIL,SEQUENCES",JOURNAL OF SOILS AND SEDIMENTS,,
72,,"35,","4,","615-629,",,,,"10.1590/0102-77863540067,",,"Resumo A precipitao  uma das variveis climticas mais importantes para o planejamento urbano e rural, para monitorar eventos extremos que possam causar impactos na sociedade e auxiliar em projetos de drenagem urbana, a fim de reduzir os riscos inerentes a inundaes e alagamentos, ou mesmo obras de engenharia, como dimensionamento de barragens. No entanto, as falhas em sries extensas prejudicam esses estudos, sendo necessrio utilizar modelos para o seu preenchimento. O presente estudo tem como objetivo revisar os mtodos de preenchimento de falhas e de interpolao espacial de dados de precipitao. A reviso dos mtodos foi realizada a partir da pesquisa e leitura de materiais bibliogrficos, de modo a conceituar as abordagens, identificar vantagens e desvantagens de cada mtodo e apresentar como estudos recentes, nacionais e internacionais, tm inovado ao comparar o desempenho em diferentes reas de estudo. Com base nessa reviso, os principais mtodos para o preenchimento de falhas so os seguintes: i) ponderao a partir de Regresso Linear Simples ou Mltipla; ii) modelos matemticos baseados em aprendizagem de mquinas, tais como as Redes Neurais Artificiais; iii) interpoladores espaciais para o preenchimento de falhas (Inverso da Distncia, Vizinho Natural, Krigagem). Por fim, foi verificada uma evoluo das tcnicas de interpolao e de preenchimento de falhas nas ltimas dcadas, em decorrncia da evoluo da capacidade computacional e tecnolgica.", precipitation; regression; spatial interpolation; geoprocessing , research-article ,,,,,,,http://www.scielo.br/j/rbmet/a/NJKZzyRfmcKGGd6cyDZqxFb/?format=pdf&lang=pt,
73,Data-Driven Optimal Tracking with Constrained Approximate Dynamic Programming for Servomotor Systems,,,352-357,"Chakrabarty Ankush,Danielson Claus,Wang Yebin","Chakrabarty A,Danielson C,Wang YB",Chakrabarty A,,"Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA.","We design real-time optimal tracking controllers for servomotor systems engaged in single-axis point-to-point positioning tasks. The design is challenging due to the presence of unmodeled dynamics, along with speed and acceleration constraints. As model-based optimal control design methods cannot be applied directly to this uncertain system, we propose a data-driven approximate dynamic programming approach to learn an optimal tracking controller that is constraint-enforcing. The potential of our proposed method is illustrated on a servomotor that positions the head of a laser drilling machine.","Safe reinforcement learning,data-driven methods,output tracking,constrained control,convex programming,invariant sets",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Automation & Control Systems,Engineering",,,,2020 IEEE CONFERENCE ON CONTROL TECHNOLOGY AND APPLICATIONS (CCTA),,
74,Adaptive Estimation of Near-Optimal Electrostatic Force in Micro Energy-Harvesters,,,782-786,"Roudneshin Masoud,Sayrafian Kamran,Aghdam Amir G.","Roudneshin M,Sayrafian K,Aghdam AG",Roudneshin M,,Concordia University - Canada,Recent advancements in micro-electronics have led to the development of miniature-sized wearable sensors that can be used for a variety of health monitoring applications. These sensors are typically powered by small batteries which could require frequent recharge. Energy harvesting can reduce the charging frequency of these sensors. Longer operational lifetime can simplify the everyday use of these wearable sensors in many applications. Our objective in this paper is to maximize the output power of a kinetic-based micro energy-harvester. A hybrid machine learning and analytical approach is proposed to adaptively adjust the electrostatic force in a harvester with Coulomb-Force Parametric Generator (CFPG) architecture. The results show considerable improvement in the output power.,"wearable sensors,energy harvesting,machine learning,microgenerator,CFPG",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Automation & Control Systems,Engineering",,,,2020 IEEE CONFERENCE ON CONTROL TECHNOLOGY AND APPLICATIONS (CCTA),,
75,3AU-Net: Triple Attention U-Net for Retinal Vessel Segmentation,,,612-615,Jin Logan,Jin LG,,10.1109/ICCASIT50869.2020.9368524,,"Retinal Vessel segmentation is an indispensable part of the task of the automatic detection of retinopathy through fundus images, while there are several challenges, such as lots of noise, low distinction between blood vessels and environment, and uneven distribution of thick and thin blood vessels. Deep learning-based methods represented by U-Net performs very well on the task of retinal vessel segmentation. As the attention mechanism has made breakthroughs in many computer vision tasks, it has attracted the attention from the researcher. This paper proposed a kind of U-Net network based on triple attention mechanism-3AU-Net to overcome the problems of retinal vessel segmentation. We follow the framework of U-Net 's full convolution and skip connection, integrating spatial attention mechanism with channel attention mechanism and context attention mechanism. Spatial attention allows the segmentation network to find the blood vessel region that needs attention, thereby suppressing noise. Channel attention can make the expression of features more diverse and highlight the feature channels with key information. The context attention can integrate the context information to make the network to focus on the key pixels. Experimental consequences have indicated that 3AU-Net can greatly improve the results of the segmentation of retinal blood vessels, and this method surpasses other deep learning-based methods in many indicators on the DRIVE and STARE fundus image data sets. On the DRIVE data set, the 3A-UNet model achieved excellent performance on multiple evaluation indicators, with an ACC score of 0.9592, an AUC score of 0.9770, and a sensitivity score of 0.8537.","deep learning,medical image,Fundus image processing,retinal vessel segmentation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Transportation",,,,PROCEEDINGS OF 2020 IEEE 2ND INTERNATIONAL CONFERENCE ON CIVIL AVIATION SAFETY AND INFORMATION TECHNOLOGY (ICCASIT),,
76,The development and evaluation of an augmented reality learning system for Japanese compound verbs using learning analytics,,,71-76,"Geng Xuewang,Yamada Masanori","Geng XW,Yamada M",Geng XW,10.1109/TALE48869.2020.9368345,Kyushu University,"Advances in mobile technology are providing new opportunities for mobile learning. Augmented reality (AR) technologies may be used on mobile devices and have the potential to facilitate improvements in learning performance. Meanwhile, the amount of data available about learners and their learning activities is rapidly increasing. Using learning analytics allows the collection of learning data to effectively analyze learning behaviors and processes. In this study, we designed and developed an AR learning system based on the temporal and spatial continuity principles of the multimedia learning theory to aid Japanese compound verb acquisition. We also employed the learner-to-learning materials interaction to analyze the relationship between learning behaviors and learning performance. The results showed that the use of an AR learning system assisted learners in improving their learning and retention of compound verbs, whereas repeated trials of the learning behavior enhanced the learning of compound verbs.","augmented reality,compound verbs,learning analytics,mobile learning,Japanese-language acquisition",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Education & Educational Research,Engineering",,,,,,
77,Mil based lung CT-image classification using CNN,10,1,271-279,"Renuka S.,Annadhason A.","Renuka S,Annadhason A",Renuka S,10.1007/s12553-019-00300-z,"St Johns Coll Arts & Sci, Dept CSE, Ammandivilai, India.","Tuberculosis (TB) is diagnosed using clinical settings through which the specimen taken as of the patient is examined. The availability of Mycobacterium tuberculosis bacteria (MTB) in that specimen confirms the existence of TB. The other examinations strongly recommend that, TB in the diagnosis, one cannot confirm it. A simple skin test is the most generally utilized diagnostic equipment for TB, though blood tests are becoming more common. A small quantity of a substance termed PPD (Post-Partum Depression) tuberculin is injected below the skin of one's inside forearm. Sometimes, false negative treatment may also results. Thus several upcoming techniques are introduced to cure the TB. It is based upon the CAD system that deals with the problem of TB detection on CXR. It is maintained by the training dataset. The drawback that occurs on the previous model is that its inherent features are uncertain. The novel 3 methods implemented in this research are i) Lung Segment, ii) Texture Feature Extraction as well as iii) Pixel classification. Along with these, miSVM+PEDD (multiple instances Support Vector Machine + Probability Estimation and Data Discarding) is used for the segmentation process. Thus the model should be evaluated by implementing some recent features of the Multiple Instance Learning (MIL). The Improved Algorithm is deployed by training a MIL classifier which builds from other machine learning (ML), Active Learning (AL) and 1-class classification approaches. Here, the uncertainty intrinsic to a MIL pixel classifier is diminished while minimizing the labeling exertions. The uses of AL are centered on the image and text categorization. The resulting lung likelihood map is post-processed to obtain binary segmentation. Here, the MIL is integrated with the AL Model. The results are analyzed by contrasting the proposed system with the other prevailing techniques to prove the dominance of the proposed one.","Tuberculosis,CAD,CNN,Bag of words,miSVM plus PEDD,MIL",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Medical Informatics,,,"COMPUTER-AIDED,DETECTION",HEALTH AND TECHNOLOGY,,
78,Trees' Condition Data Analysis Based on Drone Monitoring and Machine Learning Technology,2631,,,"Dmytriv Alina,Vysotska Victoria,Kravets Petro,Karpov Ihor,Emmerich Michael","Dmytriv A,Vysotska V,Kravets P,Karpov I,Emmerich M",Dmytriv A,,Ministry of Education & Science of Ukraine,"Goal is to create a system that will be analyze trees' condition using results from scanning and other obtained data and define options for damage detection. The project aim is the improvement of city management efficiency based on development of decision-making support systems according to the results of monitoring and analysis of urban environment parameters. This paper elaborates scientific and journalistic materials that include studies of tree monitoring, forest management and available statistics on the state of forests in Ukraine. A system of analogues (Znaydeno, LiDAR, and DJI drones) is searched and their strengths and weaknesses were described. In addition, there is a demonstration of implementation of the software and the application of machine learning. After that, an experimental approbation with data visualization is carried out and the analysis of the obtained research results was carried out, which performed the classification of trees according to their diseases.","Tree Monitoring,Drones,Classification,Decision tree,Computer Science",Proceedings Paper,"RWTH AACHEN, Ahornstr. 55, Aachen, *, GERMANY","Computer Science,Operations Research & Management Science",,,,,,
79,Development of Intelligent Information Technology of Computer Processing of Pedagogical Tests Open Tasks Based on Machine Learning Approach,2631,,,"Herasymova Arina,Chumachenko Dmytro,Padalko Halyna","Herasymova A,Chumachenko D,Padalko H",Chumachenko D,,Ministry of Education & Science of Ukraine,"Recently, such teaching methods as distance learning, e-learning and self-study have been actively developed. The widespread adoption of the Internet in all aspects of information technology has also affected the organization of the learning process. Now computer courses are very popular, which are electronic textbooks and provide for independent study. They are being replaced by distance and online learning.
Concerning, this paper presents the current development of methods for computer processing of open tasks to conduct an effective analysis of the learning of educational material.
Purpose of work was to analyze the methods and approaches used for computer processing of natural language, as well as tools to solve the problem of identifying test messages. The subject of research was mathematical models and methods of computer processing of natural language.","Machine learning,Supervised learning,Artificial neural network,Word embedding,Linear classifier,Gradient descent,Softmax,Maximum likelihood estimation",Proceedings Paper,"RWTH AACHEN, Ahornstr. 55, Aachen, *, GERMANY","Computer Science,Operations Research & Management Science",,,,,,
80,Property-based biomass feedstock grading using k-Nearest Neighbour technique,190,,,"Olatunji Obafemi O.,Akinlabi Stephen,Madushele Nkosinathi,Adedeji Paul A.","Olatunji OO,Akinlabi S,Madushele N,Adedeji PA",Olatunji OO,10.1016/j.energy.2019.116346,University of Johannesburg,"Energy generation from biomass requires a nexus of different sources irrespective of origin. A detailed and scientific understanding of the class to which a biomass resource belongs is therefore highly essential for energy generation. An intelligent classification of biomass resources based on properties offers a high prospect in analytical, operational and strategic decision-making. This study proposes the k-Nearest Neighbour (k-NN) classification model to classify biomass based on their properties. The study scientifically classified 214 biomass dataset obtained from several articles published in reputable journals. Four different values of k (k = 1, 2,3,4) were experimented for various self normalizing distance functions and their results compared for effectiveness and efficiency in order to determine the optimal model. The k-NN model based on Mahalanobis distance function revealed a great accuracy at k = 3 with Root Mean Squared Error (RMSE), Accuracy, Error, Sensitivity, Specificity, False positive rate, Kappa statistics and Computation time (in seconds) of 1.42, 0.703, 0.297, 0.580, 0.953, 0.047, 0.622, and 4.7 respectively. The authors concluded that k NN based classification model is feasible and reliable for biomass classification. The implementation of this classification models shows that k NN can serve as a handy tool for biomass resources classification irrespective of the sources and origins. (C) 2019 Elsevier Ltd. All rights reserved.","Biomass classification,Energy,k-NN classifier,Mahalanobis distance",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Thermodynamics,Energy & Fuels",,6.845,"CLASSIFICATION,PERFORMANCE,MULTICLASS,CLASSIFICATION,PROXIMATE,ANALYSIS,WASTE,BIOMASS,HEATING,VALUE,ENERGY,BIOENERGY,MODEL,ASSOCIATION,COMBUSTION",ENERGY,,
81,Application of learning algorithm for Diabetic Retinopathy Diagnosis,,,17-21,"Zaaboub Nihel,Douik Ali","Zaaboub N,Douik A",Zaaboub N,10.1109/SSD49366.2020.9364139,Universite de Sousse,"One of the causes of blindness among working-age adults is the diabetic retinopathy (DR). The DR raise the damage of the retina if it is not early diagnosed and treated. In the present paper, we are focusing on the detection of the primary signs of the diabetic retinopathy which is the exudate. The exudate appeared in white or yellow color with different shapes, sizes and positions. More its position is close to the optic disk, more the percentage of blindness is increased. That's why the position and the size are two important information for an ophthalmologist to distinguish or diagnose the severity of the disease. For those reasons, we aim in this paper to detect and segment the exudate using Random Forest classifier.. A DR database used with the application of a Random Forest classifier to segment these regions. The impact of varying the main parameter of the random forest algorithm is studied. We achieved the highest value of the specificity and the accuracy with 99.5% and 99.50% respectively. An area under curve (AUC) of 0.952 is obtained.","Fundus image,diabetic retinopathy,exudate,random forest",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"FUNDUS,IMAGES",,,
82,"EEG person identification using Facenet, LSTM-RNN and SVM",,,22-28,"Bouallegue Ghaith,Djemal Ridha","Bouallegue G,Djemal R",Bouallegue G,10.1109/SSD49366.2020.9364129,Universite de Sousse,"Electroencephalography (EEG) is the recording of electrical activity occurring in the brain, it represents the whole neural signal flow of the brain giving plenty of complex, yet abstract information. As many papers validated the individual identification using EEG Features for security purposes, we strongly believe that human EEG contains a fingerprint pattern that may identify each subject apart. In this paper, we have created a new Long Short-Term Memory (LSTM) based neural network that has learned pattern recognition from Google's, facial identification neural network, Facenet and forwarded by a Support Vector Machine (SVM) for final clustering. Our findings have shown, a pattern recognition with a loss of 0.137 and a final clustering accuracy of 97.84%.","Electroencephalography,Deep Learning,Clustering,Long-Short Term Memory,Support Vector Machine",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
83,Alzheimer's disease detection using convolutional neural networks and transfer learning based methods,,,939-943,"Zaabi Marwa,Smaoui Nadia,Derbel Houda,Hariri Walid","Zaabi M,Smaoui N,Derbel H,Hariri W",Zaabi M,10.1109/SSD49366.2020.9364155,Universite de Gabes,"Alzheimer's disease (AD) remains a major public health problem. This neurodegenerative pathology affects generally old people. Its symptoms are loss of memory followed over the years by more hard ability of expression and various handicaps. Therefore, early detection of AD is become an active research area in recent years. In this paper, we propose a deep based method for the detection of AD (i.e. classify brain images into normal brain or brain with AD). The proposed method contains two main steps. The first step is region of interest extraction; it is based on the partition of the image into separate blocks to extract only the part that contains the hippocampus of the brain. The second step is the classification of images using two deep based techniques namely convolutional neural network (CNN) and Transfer Learning. In one hand, CNN allows extracting the characteristics from brain images, then classifies them into normal brain or AD brain. Transfer Learning, in the other hand, consists of using features acquired from the Alexnet architecture to classify the images. We have assessed the proposed method on Oasis dataset (Open Access Series of Imaging Studies). The obtained results show that the classification of images using Transfer Learning with 92.86% outperformed the CNN's classification rate.","Alzheimer's disease,Region of interest,Classification,Convolutional neural network,Transfer Learning,Alexnet",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
84,A TCM Syndrome Differentiation Algorithm Based on Deep Belief Network,,,166-171,"Wang Yihao,Wu Qingtao,Zhu Junlong,Wang Lin,Zhang Mingchuan","Wang YH,Wu QT,Zhu JL,Wang L,Zhang MC",Wu QT,10.1109/YAC51587.2020.9337614,Henan University of Science & Technology,"The application of deep learning algorithm in the field of TCM diagnosis and treatment provides a reference for exploring the law of TCM syndrome differentiation. In view of the complicated relationship between symptoms and syndromes in TCM clinical syndrome differentiation model and the long training time of the model, etc. A deep belief network RBM mechanism is proposed to fit samples to obtain optimal weights and thresholds. Multi-label classification algorithms have been used in solve the one-to-many problem between symptoms and syndromes. The clinical syndrome differentiation model of traditional Chinese medicine is applied to the actual system to assist doctors to inquire and diagnose and improve the accuracy of diagnosis results.","TCM syndrome differentiation,Deep learning,DBN,Multi-label learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Automation & Control Systems,,,,2020 35TH YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC),,
85,MI-EEG Temporal Information Learning Based on One-Dimensional Convolutional Neural Network,,,499-504,"Zhou Yongtai,Ouyang Rui,Wu Xiaopei","Zhou YT,Ouyang R,Wu XP",Wu XP,10.1109/YAC51587.2020.9337703,Anhui University,"The rain-Computer Interface (BCI) is a special communication system that does not rely on the nerve and muscle tissue around the human body. it realizes the direct communication between the brain and the computer. The key to the realization of the BCI system is reasonable extraction and analysis of the characteristics for electroencephalogram (EEG) signals. Although deep learning has made initial progress in this field, only a few works have discussed the characteristics of EEG signals learned by deep learning. In this paper, an end-to-end network model for deep learning is designed to extract the time domain information of MI EEG signals. The model uses a one-dimensional convolution kernel to learn the time-domain information in the MI-EEG signal. Furthermore, we analyzed the frequency-dependent characteristics of the convolution kernel. We use the BCI competition dataset as a standard to measure the performance of this method. The experimental results show that the neural network tends to learn information in a specific frequency band, each person's specific frequency band is different. The classification result of the motor imagery obtained by the network is better than the competition's winner.","brain-computer interface,motor imagery(MI),electro-encephalogram(EEG),convolutional neural network(CNN),time-frequency domain",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Automation & Control Systems,,,"MOTOR,IMAGERY",2020 35TH YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC),,
86,Optimization of ultrasonic shock parameters after welding based on PSO-DWNN algorithm,,,673-679,"Fan Hui,Wu Qian,Jiang Ling,Hua Liang","Fan H,Wu Q,Jiang L,Hua L",Fan H,10.1109/YAC51587.2020.9337669,Nantong University,"Ultrasonic shock technology is a new type of welding residual weld stress treatment method, which can effectively improve the welding quality of welding parts, and is of great significance to the improvement of the quality of the national superior industry products. This paper presents a method for optimizing post-welding ultrasonic shock parameters based on particle swarm optimization and dual-weight neural network algorithm (PSO-DWNN). Based on the traditional particle swarm optimization algorithm (PSO), the dual-weight neural network (DWNN) is used as an auxiliary method to improve various defects existing in the PSO algorithm and enhance the final optimization effect. It has been verified that when this new type of network structure and algorithm is used to perform shock parameter fitting, the shock parameter fitting error can he effectively reduced. And through experimental comparison, it is proved that under the same network scale, using this new type of network structure and algorithm can obtain higher prediction accuracy than traditional BP neural network and RBF neural network, and provide better parameters for the ultrasonic shock technology of weldments.","ultrasonic shock,PSO-DWNN,parameter fitting,parameter prediction",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Automation & Control Systems,,,,2020 35TH YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC),,
87,Concomitant prediction of environmental fate and toxicity of chemical compounds,5,1,,"Antonio Garcia-Martin Juan,Chavarria Max,de Lorenzo Victor,Pazos Florencio","Garcia-Martin JA,Chavarria M,de Lorenzo V,Pazos F",de Lorenzo V; Pazos F,10.1093/biomethods/bpaa025,Consejo Superior de Investigaciones Cientificas (CSIC),"The environmental fate of many functional molecules that are produced on a large scale as precursors or as additives to specialty goods (plastics, fibers, construction materials, etc.), let alone those synthesized by the pharmaceutical industry, is generally unknown. Assessing their environmental fate is crucial when taking decisions on the manufacturing, handling, usage, and release of these substances, as is the evaluation of their toxicity in humans and other higher organisms. While this data are often hard to come by, the experimental data already available on the biodegradability and toxicity of many unusual compounds (including genuinely xenobiotic molecules) make it possible to develop machine learning systems to predict these features. As such, we have created a predictor of the ""risk"" associated with the use and release of any chemical. This new system merges computational methods to predict biodegradability with others that assess biological toxicity. The combined platform, named BiodegPred (https://sysbiol.cnb.csic.es/BiodegPred/), provides an informed prognosis of the chance a given molecule can eventually be catabolized in the biosphere, as well as of its eventual toxicity, all available through a simple web interface. While the platform described does not give much information about specific degradation kinetics or particular biodegradation pathways, BiodegPred has been instrumental in anticipating the probable behavior of a large number of new molecules (e.g. antiviral compounds) for which no biodegradation data previously existed.","biodegradation,prediction,web server",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND",Biochemistry & Molecular Biology,,,,BIOLOGY METHODS & PROTOCOLS,https://academic.oup.com/biomethods/advance-article-pdf/doi/10.1093/biomethods/bpaa025/34297909/bpaa025.pdf,
88,Assessing the Impact of Blood Pressure on Cardiac Function Using Interpretable Biomarkers and Variational Autoencoders,12009,,22-30,"Puyol-Anton Esther,Ruijsink Bram,Clough James R.,Oksuz Ilkay,Rueckert Daniel,Razavi Reza,King Andrew P.","Puyol-Anton E,Ruijsink B,Clough JR,Oksuz I,Rueckert D,Razavi R,King AP",Puyol-Anton E,10.1007/978-3-030-39074-7_3,University of London,"Maintaining good cardiac function for as long as possible is a major concern for healthcare systems worldwide and there is much interest in learning more about the impact of different risk factors on cardiac health. The aim of this study is to analyze the impact of systolic blood pressure (SBP) on cardiac function while preserving the interpretability of the model using known clinical biomarkers in a large cohort of the UK Biobank population. We propose a novel framework that combines deep learning based estimation of interpretable clinical biomarkers from cardiac cine MR data with a variational autoencoder (VAE). The VAE architecture integrates a regression loss in the latent space, which enables the progression of cardiac health with SBP to be learnt. Results on 3,600 subjects from the UK Biobank show that the proposed model allows us to gain important insight into the deterioration of cardiac function with increasing SBP, identify key interpretable factors involved in this process, and lastly exploit the model to understand patterns of positive and adverse adaptation of cardiac function.","Cardiac function,Variational autoencoder,Cardiac risk factors",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Cardiovascular System & Cardiology,Computer Science,Mathematical & Computational Biology,Radiology, Nuclear Medicine & Medical Imaging",,,,,https://kclpure.kcl.ac.uk/portal/files/126712926/Assessing_the_Impact_of_PUYOL_ANTON_Acc3Jan2020Epub23Jan2020_GREEN_AAM.pdf,
89,4D CNN for Semantic Segmentation of Cardiac Volumetric Sequences,12009,,72-80,"Myronenko Andriy,Yang Dong,Buch Varun,Xu Daguang,Ihsani Alvin,Doyle Sean,Michalski Mark,Tenenholtz Neil,Roth Holger","Myronenko A,Yang D,Buch V,Xu DG,Ihsani A,Doyle S,Michalski M,Tenenholtz N,Roth H",Myronenko A,10.1007/978-3-030-39074-7_8,Nvidia Corporation,"We propose a 4D convolutional neural network (CNN) for the segmentation of retrospective ECG-gated cardiac CT, a series of single-channel volumetric data over time. While only a small subset of volumes in the temporal sequence is annotated, we define a sparse loss function on available labels to allow the network to leverage unlabeled images during training and generate a fully segmented sequence. We investigate the accuracy of the proposed 4D network to predict temporally consistent segmentations and compare with traditional 3D segmentation approaches. We demonstrate the feasibility of the 4D CNN and establish its performance on cardiac 4D CCTA (video: https://drive.google.com/uc?id=1n-GJX5nviVs8R7tque2zy2uHFcN_Ogn1.).",,Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Cardiovascular System & Cardiology,Computer Science,Mathematical & Computational Biology,Radiology, Nuclear Medicine & Medical Imaging",,,,,http://arxiv.org/pdf/1906.07295,
90,Conditional Generative Adversarial Networks for the Prediction of Cardiac Contraction from Individual Frames,12009,,109-118,"Ossenberg-Engels Julius,Grau Vicente","Ossenberg-Engels J,Grau V",Ossenberg-Engels J,10.1007/978-3-030-39074-7_12,University of Oxford,"Cardiac anatomy and function are interrelated in many ways, and these relations can be affected by multiple pathologies. In particular, this applies to ventricular shape and mechanical deformation. We propose a machine learning approach to capture these interactions by using a conditional Generative Adversarial Network (cGAN) to predict cardiac deformation from individual Cardiac Magnetic Resonance (CMR) frames, learning a deterministic mapping between end-diastolic (ED) to end-systolic (ES) CMR short-axis frames. We validate the predicted images by quantifying the difference with real images using mean squared error (MSE) and structural similarity index (SSIM), as well as the Dice coefficient between their respective endo- and epicardial segmentations, obtained with an additional U-Net. We evaluate the ability of the network to learn ""healthy"" deformations by training it on similar to 33,500 image pairs from similar to 12,000 subjects, and testing on a separate test set of similar to 4,500 image pairs from the UK Biobank study. Mean MSE, SSIM and Dice scores were 0.0026 +/- 0.0013, 0.89 +/- 0.032 and 0.89 +/- 0.059 respectively. We subsequently re-trained the network on specific patient group data, showing that the network is capable of extracting physiologically meaningful differences between patient populations suggesting promising applications on pathological data.","cGANs,Image transformation,Cardiac contraction,UK Biobank",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Cardiovascular System & Cardiology,Computer Science,Mathematical & Computational Biology,Radiology, Nuclear Medicine & Medical Imaging",,,,,https://ora.ox.ac.uk/objects/uuid:4b743fcd-50d7-4705-8708-352b341e4a49/download_file?safe_filename=Work%2520%285%29.pdf&file_format=application%2Fpdf&type_of_work=Conference+item,
91,Multimodal Cardiac Segmentation Using Disentangled Representation Learning,12009,,128-137,"Chartsias Agisilaos,Papanastasiou Giorgos,Wang Chengjia,Stirrat Colin,Semple Scott,Newby David,Dharmakumar Rohan,Tsaftaris Sotirios A.","Chartsias A,Papanastasiou G,Wang CJ,Stirrat C,Semple S,Newby D,Dharmakumar R,Tsaftaris SA",Chartsias A,10.1007/978-3-030-39074-7_14,University of Edinburgh,"Magnetic Resonance (MR) protocols use several sequences to evaluate pathology and organ status. Yet, despite recent advances, the analysis of each sequence's images (modality hereafter) is treated in isolation. We propose a method suitable for multimodal and multi-input learning and analysis, that disentangles anatomical and imaging factors, and combines anatomical content across the modalities to extract more accurate segmentation masks. Mis-registrations between the inputs are handled with a Spatial Transformer Network, which non-linearly aligns the (now intensity-invariant) anatomical factors. We demonstrate applications in Late Gadolinium Enhanced (LGE) and cine MRI segmentation. We show that multi-input outperforms single-input models, and that we can train a (semi-supervised) model with few (or no) annotations for one of the modalities. Code is available at https://github.com/agis85/multimodal segmentation.","Multimodal segmentation,Disentanglement,Representation learning,Cardiac MR",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Cardiovascular System & Cardiology,Computer Science,Mathematical & Computational Biology,Radiology, Nuclear Medicine & Medical Imaging",,,"MAGNETIC-RESONANCE,SHAPE",,http://repository.essex.ac.uk/28208/1/Chartsias%2C%20Papanastasiou%2C%20et%20al.%20MICCAI%20%28LNCS%29%202019.pdf,
92,Non-invasive Pressure Estimation in Patients with Pulmonary Arterial Hypertension: Data-Driven or Model-Based?,12009,,147-156,"Yang Yingyu,Gillon Stephane,Banus Jaume,Moceri Pamela,Sermesant Maxime","Yang YY,Gillon S,Banus J,Moceri P,Sermesant M",Yang YY,10.1007/978-3-030-39074-7_16,Inria,"Right heart catheterisation is considered as the gold standard for the assessment of patients with suspected pulmonary hypertension. It provides clinicians with meaningful data, such as pulmonary capillary wedge pressure and pulmonary vascular resistance, however its usage is limited due to its invasive nature. Non-invasive alternatives, like Doppler echocardiography could present insightful measurements of right heart but lack detailed information related to pulmonary vasculature. In order to explore non-invasive means, we studied a dataset of 95 pulmonary hypertension patients, which includes measurements from echocardiography and from right-heart catheterisation. We used data extracted from echocardiography to conduct cardiac circulation model personalisation and tested its prediction power of catheter data. Standard machine learning methods were also investigated for pulmonary artery pressure prediction. Our preliminary results demonstrated the potential prediction power of both data-driven and model-based approaches.","Cardiac modelling,Machine learning,Pulmonary hypertension",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Cardiovascular System & Cardiology,Computer Science,Mathematical & Computational Biology,Radiology, Nuclear Medicine & Medical Imaging",,,CATHETERIZATION,,https://hal.inria.fr/hal-02382941/file/stacom_2019.pdf,
93,Deep Learning for Cardiac Motion Estimation: Supervised vs. Unsupervised Training,12009,,186-194,"Qiu Huaqi,Qin Chen,Le Folgoc Loic,Hou Benjamin,Schlemper Jo,Rueckert Daniel","Qiu HQ,Qin C,Le Folgoc L,Hou B,Schlemper J,Rueckert D",Qiu HQ,10.1007/978-3-030-39074-7_20,Imperial College London,"Deep learning based registration methods have emerged as alternatives to traditional registration methods, with competitive accuracy and significantly less runtime. Two different strategies have been proposed to train such deep learning registration networks: supervised training strategy where the model is trained to regress to generated ground truth deformation; and unsupervised training strategy where the model directly optimises the similarity between the registered images. In this work, we directly compare the performance of these two training strategies for cardiac motion estimation on cardiac cine MR sequences. Testing on real cardiac MRI data shows that while the supervised training yields more regular deformation, the unsupervised more accurately captures the deformation of anatomical structures in cardiac motion.","IMAGE,REGISTRATION,FRAMEWORK",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Cardiovascular System & Cardiology,Computer Science,Mathematical & Computational Biology,Radiology, Nuclear Medicine & Medical Imaging",,,"IMAGE,REGISTRATION,FRAMEWORK",,,
94,Unsupervised Multi-modal Style Transfer for Cardiac MR Segmentation,12009,,209-219,"Chen Chen,Ouyang Cheng,Tarroni Giacomo,Schlemper Jo,Qiu Huaqi,Bai Wenjia,Rueckert Daniel","Chen C,Ouyang C,Tarroni G,Schlemper J,Qiu HQ,Bai WJ,Rueckert D",Chen C; Ouyang C,10.1007/978-3-030-39074-7_22,Imperial College London,"In this work, we present a fully automatic method to segment cardiac structures from late-gadolinium enhanced (LGE) images without using labelled LGE data for training, but instead by transferring the anatomical knowledge and features learned on annotated balanced steady-state free precession (bSSFP) images, which are easier to acquire. Our framework mainly consists of two neural networks: a multi-modal image translation network for style transfer and a cascaded segmentation network for image segmentation. The multi-modal image translation network generates realistic and diverse synthetic LGE images conditioned on a single annotated bSSFP image, forming a synthetic LGE training set. This set is then utilized to fine-tune the segmentation network pre-trained on labelled bSSFP images, achieving the goal of unsupervised LGE image segmentation. In particular, the proposed cascaded segmentation network is able to produce accurate segmentation by taking both shape prior and image appearance into account, achieving an average Dice score of 0.92 for the left ventricle, 0.83 for the myocardium, and 0.88 for the right ventricle on the test set.",,Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Cardiovascular System & Cardiology,Computer Science,Mathematical & Computational Biology,Radiology, Nuclear Medicine & Medical Imaging",,,,,https://openaccess.city.ac.uk/id/eprint/23501/1/1908.07344v3.pdf,
95,Pseudo-3D Network for Multi-sequence Cardiac MR Segmentation,12009,,237-245,"Liu Tao,Tian Yun,Zhao Shifeng,Huang XiaoYing,Xu Yang,Jiang Gaoyuan,Wang Qingjun","Liu T,Tian Y,Zhao SF,Huang XY,Xu Y,Jiang GY,Wang QJ",Tian Y,10.1007/978-3-030-39074-7_25,Beijing Normal University,"Deep learning approaches have been regarded as a powerful model for cardiac magnetic resonance (CMR) image segmentation. However, most current deep learning approaches do not fully utilize the information from multi-sequence (MS) cardiac magnetic resonance. In this work, the deep learning method is used to fully-automatic segment the MS CMR data. The balanced-Steady State Free Precession (bSSFP) cine sequence is used to perform left ventricular positioning as a priori knowledge, and then the Late Gadolinium Enhancement (LGE) cine sequence is used for precise segmentation. This segmentation strategy makes full use of the complementary information from the MS CMR data. Moreover, to solve the anisotropy of volumetric medical images, we employ the Pseudo-3D convolution neural network structure to segment the LGE CMR data, which combines the advantage of 2D networks and preserving the spatial structure information in 3D data without compromising segmentation accuracy. Experimental results of the Multi-sequence Cardiac MR Segmentation Challenge (MS-CMRSeg 2019) show that our approach has achieved gratifying results even with limited GPU computing resources and small amounts of annotated data. The full implementation and configuration files in this article are available at https://github.com/liut969/Multi-sequence-Cardiac-MR-Segmentation.","Multi-sequence,Pseudo-3D network,Segmentation",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Cardiovascular System & Cardiology,Computer Science,Mathematical & Computational Biology,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
96,Multi-sequence Cardiac MR Segmentation with Adversarial Domain Adaptation Network,12009,,254-262,"Wang Jiexiang,Huang Hongyu,Chen Chaoqi,Ma Wenao,Huang Yue,Ding Xinghao","Wang JX,Huang HY,Chen CQ,Ma WA,Huang Y,Ding XH",Ding XH,10.1007/978-3-030-39074-7_27,Xiamen University,"Automatic and accurate segmentation of the ventricles and myocardium from multi-sequence cardiac MRI (CMR) is crucial for the diagnosis and treatment management for patients suffering from myocardial infarction (MI). However, due to the existence of domain shift among different modalities of datasets, the performance of deep neural networks drops significantly when the training and testing datasets are distinct. In this paper, we propose an unsupervised domain alignment method to explicitly alleviate the domain shifts among different modalities of CMR sequences, e.g., bSSFP, LGE, and T2-weighted. Our segmentation network is attention U-Net with pyramid pooling module, where multilevel feature space and output space adversarial learning are proposed to transfer discriminative domain knowledge across different datasets. Moreover, we further introduce a group-wise feature recalibration module to enforce the fine-grained semantic-level feature alignment that matching features from different networks but with the same class label. We evaluate our method on the multi-sequence cardiac MR Segmentation Challenge 2019 datasets, which contain three different modalities of MRI sequences. Extensive experimental results show that the proposed methods can obtain significant segmentation improvements compared with the baseline models.",,Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Cardiovascular System & Cardiology,Computer Science,Mathematical & Computational Biology,Radiology, Nuclear Medicine & Medical Imaging",,,,,http://arxiv.org/pdf/1910.12514,
97,Deep Learning Based Multi-modal Cardiac MR Image Segmentation,12009,,263-270,"Zheng Rencheng,Zhao Xingzhong,Zhao Xingming,Wang He","Zheng RC,Zhao XZ,Zhao XM,Wang H",Zhao XZ,10.1007/978-3-030-39074-7_28,Fudan University,"Accurate modelling and segmentation of the ventricles and myocardium in cardiac MR (CMR) image is crucial for diagnosis and treatment management for patients suffering from myocardial infarction (MI). As the infarcted myocardium can be enhanced in LGE CMR through appearing with distinctive brightness compared with the healthy tissues, it can help doctors better study the presence, location, and extent of MI in clinical diagnosis. Hence it is of great significance to delineate ventricles and myocardium from LGE CMR images. In this study, we proposed a multi-modal cardiac MR image segmentation strategy via combining the T2-weighted CMR and the balanced-Steady State Free Precession (bSSFP) CMR sequence. Specifically, the T2-weighted CMR and bSSFP are co-registered and set as the input of the convolution neural network to do the first stage segmentation in bSSFP space. By predicting all the labels, we further registered T2-weighted CMR, bSSFP and the corresponding labels into LGE space, and as an input to the convolution neural network to do the second stage segmentation. In the end, we post-processed the output masks to further ensure the accuracy of the segmentation results. The dice score of the proposed method in test set of Multi-sequence Cardiac MR (MS-CMR) Challenge 2019 achievers 0.8541, 0.7131 and 0.7924 for left ventricular (LV), left ventricular myocardium (LV myo), and right ventricular (RV).","Myocardial infarction,Multi-modal,Cardiac MR,Image segmentation,Convolution neural network",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Cardiovascular System & Cardiology,Computer Science,Mathematical & Computational Biology,Radiology, Nuclear Medicine & Medical Imaging",,,"MYOCARDIUM,VENTRICLE",,,
98,Automated Multi-sequence Cardiac MRI Segmentation Using Supervised Domain Adaptation,12009,,300-308,"Vesal Sulaiman,Ravikumar Nishant,Maier Andreas","Vesal S,Ravikumar N,Maier A",Vesal S,10.1007/978-3-030-39074-7_32,University of Erlangen Nuremberg,"Left ventricle segmentation and morphological assessment are essential for improving diagnosis and our understanding of cardiomyopathy, which in turn is imperative for reducing risk of myocardial infarctions in patients. Convolutional neural network (CNN) based methods for cardiac magnetic resonance (CMR) image segmentation rely on supervision with pixel-level annotations, and may not generalize well to images from a different domain. These methods are typically sensitive to variations in imaging protocols and data acquisition. Since annotating multi-sequence CMR images is tedious and subject to inter- and intra-observer variations, developing methods that can automatically adapt from one domain to the target domain is of great interest. In this paper, we propose an approach for domain adaptation in multi-sequence CMR segmentation task using transfer learning that combines multi-source image information. We first train an encoder-decoder CNN on T2-weighted and balanced-Steady State Free Precession (bSSFP) MR images with pixel-level annotation and fine-tune the same network with a limited number of Late Gadolinium Enhanced-MR (LGE-MR) subjects, to adapt the domain features. The domain-adapted network was trained with just four LGE-MR training samples and obtained an average Dice score of similar to 85.0% on the test set comprises of 40 LGE-MR subjects. The proposed method significantly outperformed a network without adaptation trained from scratch on the same set of LGE-MR training data.","Multi-sequence MRI,Deep learning,Domain adaptation,Myocardial infraction,MRI segmentation",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Cardiovascular System & Cardiology,Computer Science,Mathematical & Computational Biology,Radiology, Nuclear Medicine & Medical Imaging",,,,,http://eprints.whiterose.ac.uk/159510/1/1908.07726.pdf,
99,A Two-Stage Fully Automatic Segmentation Scheme Using Both 2D and 3D U-Net for Multi-sequence Cardiac MR,12009,,309-316,"Xu Haohao,Xu Zhuangwei,Gu Wenting,Zhang Qi","Xu HH,Xu ZW,Gu WT,Zhang Q",Zhang Q,10.1007/978-3-030-39074-7_33,Shanghai University,"Multi-sequence cardiac magnetic resonance (MR) segmentation is an important medical imaging technology that facilitates intelligent interpretation of clinical MR images. However, fully automatic segmentation of multi-sequence cardiac MR is a challenging task due to the complexity and variability of cardiac anatomy. In this study, we propose a two-stage deep learning scheme for automatic segmentation of volumetric multi-sequence MR images by leveraging both 2D and 3D U-Net. In the first stage, a 2D U-Net model coupled with the iterative randomized Hough transform is employed on the balanced-steady state free precession (bSSFP) MR sequences, so as to find the center coordinates of the left ventricles (LVs). The regions of interest (ROIs) are then localized around the center coordinates on the corresponding late gadolinium enhanced (LGE) MR sequences. In the second stage, a 3D probabilistic U-Net model is performed on the ROIs in the LGE data to segment the LV, right ventricle (RV) and left ventricular myocardium (MYO). Experimental results on the MICCAI 2019 Multi-Sequence Cardiac MR Segmentation (MS-CMRSeg) Challenge show that the proposed scheme performs well with average Dice similarity coefficients of LV, RV and MYO as 0.792, 0.697 and 0.611, respectively.","Multi-sequence Cardiac MR,U-Net,Iterative randomized Hough transform,Image segmentation",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Cardiovascular System & Cardiology,Computer Science,Mathematical & Computational Biology,Radiology, Nuclear Medicine & Medical Imaging",,,MAGNETIC-RESONANCE,,,
100,Adversarial Convolutional Networks with Weak Domain-Transfer for Multi-sequence Cardiac MR Images Segmentation,12009,,317-325,"Chen Jingkun,Li Hongwei,Zhang Jianguo,Menze Bjoern","Chen JK,Li HW,Zhang JG,Menze B",Zhang JG,10.1007/978-3-030-39074-7_34,Southern University of Science & Technology,"Analysis and modeling of the ventricles and myocardium are important in the diagnostic and treatment of heart diseases. Manual delineation of those tissues in cardiac MR (CMR) scans is laborious and time-consuming. The ambiguity of the boundaries makes the segmentation task rather challenging. Furthermore, the annotations on some modalities such as Late Gadolinium Enhancement (LGE) MRI, are often not available. We propose an end-to-end segmentation framework based on convolutional neural network (CNN) and adversarial learning. A dilated residual U-shape network is used as a segmentor to generate the prediction mask; meanwhile, a CNN is utilized as a discriminator model to judge the segmentation quality. To leverage the available annotations across modalities per patient, a new loss function named weak domain-transfer loss is introduced to the pipeline. The proposed model is evaluated on the public dataset released by the challenge organizer in MICCAI 2019, which consists of 45 sets of multi-sequence CMR images. We demonstrate that the proposed adversarial pipeline outperforms baseline deep-learning methods.","Adversarial convolutional network,Multi-sequence cardiac segmentation",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Cardiovascular System & Cardiology,Computer Science,Mathematical & Computational Biology,Radiology, Nuclear Medicine & Medical Imaging",,,VENTRICLE,,https://discovery.dundee.ac.uk/ws/files/48537974/1908.09298.pdf,
