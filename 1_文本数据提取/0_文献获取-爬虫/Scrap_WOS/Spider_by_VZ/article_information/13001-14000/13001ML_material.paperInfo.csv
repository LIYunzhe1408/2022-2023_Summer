,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,A Network of Simultaneous Segmentation and Registration for Right Ventricle MRI,,,657-662,"Lin Adan,Li Zhenzhen,Yang Xuan","Lin AD,Li ZZ,Yang X",Yang X,10.1109/BIBM49941.2020.9313411,Shenzhen University,"Short-axis MRI segmentation of the right ventricle plays an important role in assessing the structure and function of the right ventricle. However, RV segmentation is a challenge due to its complex crescent shape. In this paper, we propose a deep learning-based method for segmenting RV using the registration of the right ventricular shape model. The RV shape probability model is constructed using training samples. Next, a U-Net is trained using the shape prior probability by employing the registration technique. The shape model is registered to the network's predictive results to estimate a shape probability map, and a loss is defined as the Kullback-Leibler divergence between the prediction result and the shape probability map and the Kullback-Leibler divergence between the predictive result and the Ground-truth. The experimental results obtained from the cardiac automatic diagnosis challenge-medical imaging calculation and computer-aided intervention (ACDC-MICCAI) 2017 dataset show that the average 3D dice coefficient is 0.919, and the average 3D Hausdorff distance is 10.71mm. Our network has also been verified in the MICCAI2012 right ventricle segmentation challenge(RVSC) dataset. The average dice coefficient is 0.865, and the Hausdorff distance is 6.10mm. The evaluation results show that our network outperforms the state-of-art methods in several evaluation indicators.","RV segmentation,Shape prior probability,Registration,Convolutional Neural Network",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"CARDIAC,MRI",,,
2,Local Adaptive U-net for Medical Image Segmentation,,,670-674,"Liu Ning,Liu Liangliang,Wang Jianxin","Liu N,Liu LL,Wang JX",Wang JX,10.1109/BIBM49941.2020.9313515,Central South University,"Medical image segmentation is the primary measure of medical image analysis. With the development of deep learning, U-net based approaches have presented for different medical image segmentation tasks. However, the pooling and the simple convolution operation for deep feature maps in the U-shaped network would lead to the coarse segmentation result. In this paper, we design a local adaptive U-net (LA U-net) for medical image segmentation. There are two major modules: the Local Adaptive Module (LAM) and Multi-scale Convolution Module (MCM) in the network. The LAM get more feature maps from each down-sampling process. The MCM capture more global information for the encoding path. To validate the proposed network's performance, we verify it on two datasets: DRIVE dataset, and ISIC 2018 dataset; the results show that LA U-net achieves superior performance on two datasets.","medical image segmentation,deep convolution neural network,local adaptive,multi-scale",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,NETWORKS,,,
3,Lymph Node Metastasis Classification Based on Semi-Supervised Multi-View Network,,,675-680,"Luo Yiwen,Xin Jingmin,Liu Sijie,Feng Junqin,Ruan Litao,Cui Wei,Zheng Nanning","Luo YW,Xin JM,Liu SJ,Feng JQ,Ruan LT,Cui W,Zheng NN",Luo YW,10.1109/BIBM49941.2020.9313248,Xi'an Jiaotong University,"Lymphatic metastasis is one of the most common proliferation pathways of thyroid carcinoma. Accurate diagnosis of lymph nodes is of great significance to surgical planning and prognosis. Due to the continuous development of deep learning recently, computer-aided diagnosis (CAD) systems for thyroid cancer have made considerable progress, but the research on the effective diagnosis of lymphatic metastasis remains insufficient. Focusing on this issue, we propose a semi-supervised multi-view network to diagnose lymph node metastasis, which combines coarse-view and fine-view to obtain a more comprehensive description. This method consists of three parts as follows: 1) joint probabilistic labels of the nodule partition information are generated by fuzzy clustering and perform semi-supervised learning on coarse-view with real labels; 2) an attention mechanism based network for fine-view is designed to capture various differentiated local features in a pyramid manner; 3) the two parts are then combined to extract global and local features more effectively to derive more accurate diagnostic reasoning. Especially, the introduction of fuzzy logic greatly reduces the impact of the uncertainty of the generated labels, thereby ensuring the effectiveness of the pseudo-labels. Extensive experiments on our collected dataset demonstrate that the proposed method is more efficient than other state-of-the-art methods.","Semi-supervised learning,Pseudo-label,Multiview,Attention module,Lymph node diagnosis",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"FUZZY,C-MEANS,PAPILLARY,CARCINOMA",,,
4,DCE-MRI based Breast Intratumor Heterogeneity Analysis via Dual Attention Deep Clustering Network and its Application in Molecular Typing,,,681-686,"Lv Tianxu,Pan Xiang,Li Lihua","Lv TX,Pan X,Li LH",Pan X,10.1109/BIBM49941.2020.9313272,Jiangnan University,"More attention has been paid to the precision and personalized treatment of breast cancer, which is a primary risk factor that threatens the females lives. It is momentous for diagnosis, analysis and therapy of tumors to lucubrate breast intratumor heterogeneity. We propose a DCE-MRI dynamic mode based self-supervised dual attention deep clustering network (DADCN) which is utilized to achieve the individual precise segmentation of breast intratumor heterogeneity region in this paper. The specific representations learned by the graph attention network are consciously combined with the deep abstract features extracted from the deep convolutional neural network. Then the structural information of the voxel in breast tumor is mined by spreading on the graph. The model is self-supervised by dual relative loss and residual loss and the clustering graph is measured by graph cut loss. We also employ Pearson, Spearman and Kendall analysis to evaluate degree of correlation between clustering results and intratumor heterogeneity represented by molecular typing. We ultimately detect that the degree of intratumor heterogeneity is automatically determined via segmentation of the heterogeneity region, to accomplish the noninvasive individual molecular typing prediction of breast cancer. The number of clusters in breast intratumor heterogeneity region is an independent biomarker for the diagnosis of benign and malignant tumors and prediction of basal-like molecular typing.","Breast intratumor heterogeneity,molecular typing,DCE-MRI,dual attention,cluster",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,TUMOR,,,
5,Attention-Based Transformers for Instance Segmentation of Cells in Microstructures,,,700-707,"Prangemeier Tim,Reich Christoph,Koeppl Heinz","Prangemeier T,Reich C,Koeppl H",Koeppl H,10.1109/BIBM49941.2020.9313305,Technical University of Darmstadt,"Detecting and segmenting object instances is a common task in biomedical applications. Examples range from detecting lesions on functional magnetic resonance images, to the detection of tumours in histopathological images and extracting quantitative single-cell information from microscopy imagery, where cell segmentation is a major bottleneck. Attention-based transformers are state-of-the-art in a range of deep learning fields. They have recently been proposed for segmentation tasks where they are beginning to outperform other methods. We present a novel attention-based cell detection transformer (Cell-DETR) for direct end-to-end instance segmentation. While the segmentation performance is on par with a state-of-the-art instance segmentation method, Cell-DETR is simpler and faster. We showcase the method's contribution in a the typical use case of segmenting yeast in microstructured environments, commonly employed in systems or synthetic biology. For the specific use case, the proposed method surpasses the state-of-the-art tools for semantic segmentation and additionally predicts the individual object instances. The fast and accurate instance segmentation performance increases the experimental information yield for a posteriori data processing and makes online monitoring of experiments and closed-loop optimal experimental design feasible. Code and data sample is available at https://git.rwth-aachen.de/bcs/projects/cell-detr.git.","attention,instance segmentation,transformers,single-cell analysis,synthetic biology,microfluidics,deep learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,http://arxiv.org/pdf/2011.09763,
6,A Domain Adaptation Multi-instance Learning for Diabetic Retinopathy Grading on Retinal Images,,,743-750,"Song Ruoxian,Cao Peng,Yang Jinzhu,Zhao Dazhe,Zaiane Osmar R.","Song RX,Cao P,Yang JZ,Zhao DZ,Zaiane OR",Cao P,10.1109/BIBM49941.2020.9313398,Northeastern University - China,"Diabetic retinopathy (DR) is one of the most concerning, common and serious diseases in the ophthalmology community. Early detection and treatment of DR can significantly reduce the risk of vision loss in patients. Traditional DR automatic classification algorithms rely on the precise detection of microaneurysms (MA) and hemorrhage (H) lesions. Such lesion annotation is an expensive and time-consuming process, hence it is expected to develop automatic grading methods with only image-level annotations. The lack of the position of MA and H hinders the traditional supervised algorithms for the accurate identification. In our work, we formulate the weakly supervised DR grading as a multi-instance learning problem, and propose a domain adaptation multi-instance learning with attention mechanism for DR grading. Specifically, labeled instances are generated by cross-domain to filter irrelevant instances in the target domain. To model the relationship between the suspicious instances and bag label, a multi-instance learning with attention mechanism is developed to acquire the location information of highly suspected lesions and predict the grade of DR. We evaluate our proposed algorithm on the Messidor dataset, and the experimental results demonstrate that it achieves an average accuracy of 0.764 and an AUC value of 0.749 respectively, outperforming state-of-the-art approaches.","Diabetic retinopathy,Severity level grading,Multi-instance learning,Domain adaptation,Attention",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
7,Melanoma Classification in Dermoscopy Images via Ensemble Learning on Deep Neural Network,,,751-756,"Song Jie,Li Jiawei,Ma Shiqiang,Tang Jijun,Guo Fei","Song J,Li JW,Ma SQ,Tang JJ,Guo F",Tang JJ; Guo F,10.1109/BIBM49941.2020.9313451,Tianjin University,"Auotmatic melanoma classification in dermoscopy images is a very important task, which can help improve diagnostic accuracy and reduce mortality. Deep convolutional neural network (DCNN) has developed rapidly in recent years, but it is still a challenging task due to the intra-class variation and inter-class similarity of melanoma. We proposed a novel neural network integration model, which is composed of three parts: First, we use U-net segmentation network to generate masks and use the masks to crop original images; Second, we use five state-of-the-art DCNNs to extract features of cropped images, and add the squeeze-excitation block (SE block) to emphasize useful features; Finally, we construct a new neural network with local connection to integrate the classification results, extract features of different class of results, and integrate the results of each class separately. Local connection can integrate each class separately, maximizing the advantages of different networks in various classes. We evaluate our model on ISIC 2017 challenge dataset, and the result shows that our method has better performance compared with the existing methods.","Melanoma Classification,Dermoscopy Images,Ensemble Learning,Deep Convolutional Neural Network",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
8,Using Machine Learning to Automate Mammogram Images Analysis,,,757-764,"Tang Xuejiao,Zhang Liuhua,Zhang Wenbin,Huang Xin,Iosifidis Vasileios,Liu Zhen,Zhang Mingli,Messina Enza,Zhang Ji","Tang XJ,Zhang LH,Zhang WB,Huang X,Iosifidis V,Liu Z,Zhang ML,Messina E,Zhang J",Tang XJ,10.1109/BIBM49941.2020.9313247,University of Hannover,"Breast cancer is the second leading cause of cancer-related death after lung cancer in women. Early detection of breast cancer in X-ray mammography is believed to have effectively reduced the mortality rate since 1989. However, a relatively high false positive rate and a low specificity in mammography technology still exist. In this work, a computer-aided automatic mammogram analysis system is proposed to process the mammogram images and automatically discriminate them as either normal or cancerous, consisting of three consecutive image processing, feature selection, and image classification stages. In designing the system, the discrete wavelet transforms (Daubechies 2, Daubechies 4, and Biorthogonal 6.8) and the Fourier cosine transform were first used to parse the mammogram images and extract statistical features. Then, an entropy-based feature selection method was implemented to reduce the number of features. Finally, different pattern recognition methods (including the Back-propagation Network, the Linear Discriminant Analysis, and the Naive Bayes Classifier) and a voting classification scheme were employed. The performance of each classification strategy was evaluated for sensitivity, specificity, and accuracy and for general performance using the Receiver Operating Curve. Our method is validated on the dataset from the Eastern Health in Newfoundland and Labrador of Canada. The experimental results demonstrated that the proposed automatic mammogram analysis system could effectively improve the classification performances.","Breast cancer,automated diagnostic system",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,http://arxiv.org/pdf/2012.03151,
9,Multiview 3-D Echocardiography Image Fusion with Mutual Information Neural Estimation,,,765-771,"Ting Juiwen,Punithakumar Kumaradevan,Ray Nilanjan","Ting JW,Punithakumar K,Ray N",Ting JW,10.1109/BIBM49941.2020.9313219,University of Alberta,"Multiview three-dimensional echocardiography (M3DE) fuses volumetric datasets acquired from complementary acoustic windows to expand field-of-view and allow for visualization of the entire heart. This is of great importance for cardiac chamber quantification. The M3DE also allows for image quality improvement through fusion of single views on overlapping regions. However, shape variations and increase in noise stemming from the nature of ultrasound physics make fusion a challenging task. This study proposes a novel machine learning-based fusion method to combine ultrasound views that are spatially apart, namely, apical and parasternal. Our method jointly uses: 1) an autoencoder framework to generate the fused image; and 2) a mutual information neural estimation network to maximize the mutual information between source and fused images. The experimental evaluations show promising results and the fused image generated by the proposed method improves the signal-to-noise ratio by up to 18.23 dB and the contrast-to-noise ratio by up to 21.76 dB compared to the state-of-art approaches.","Echocardiography,mutual information neural estimation,image fusion",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
10,Texture and signal features from hippocampal T2 maps as biomarkers for MCI to AD progression,,,772-777,"Trejo-Castro Alejandro I,Caballero-Luna Ricardo A.,Garnica-Lopez Jose A.,Vega-Lara Fernando,Celaya-Padilla Jose M.,Tamez-Pena Jose G.,Martinez-Torteya Antonio","Trejo-Castro AI,Caballero-Luna RA,Garnica-Lopez JA,Vega-Lara F,Celaya-Padilla JM,Tamez-Pena JG,Martinez-Torteya A",Trejo-Castro AI,10.1109/BIBM49941.2020.9313538,Tecnologico de Monterrey,"Alzheimer's disease (AD) is the most common type of dementia and predicting who will convert from Mild Cognitive Impairment (MCI) to AD is crucial to patient benefits as well as medical research. To fulfill this purpose, in recent years it has been reported that the texture of magnetic resonance images can be an effective biomarker. In this study we used images from the Alzheimer's Disease Neuroimaging Initiative database to create T2 maps and identify features related to the texture and signal distribution for the prediction of AD. We extracted 38 features from the left and right hippocampus for 40 patients with MCI who either progressed to AD (18) or remained stable (22) and measured the mean and absolute difference of these contralateral features. We also kept the original volume of each region, yielding a total of 78 features. We used 7 machine learning methods to analyze whether by adding these imaging features to the neuropsychological studies currently used for diagnosis, we could more accurately identify who would develop the disease. We found 11 features significantly different between groups. Furthermore, all but one of the machine learning methods improved their accuracy by adding the signal- and texture-related features, and the volumetric information was non-significant. Our results suggest that these imaging features from hippocampal T2 maps should be further investigated as potential MRI biomarkers for the prediction of AD.","Alzheimer's Disease,MRI biomarker,hippocampus",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"COMPOSITE,SCORE,CORE",,,
11,A Diversified Supervised based U-shape Colorectal Lesion Segmentor with Meaningful Feature Supplement and Multi-Level Residual Attention Mechanism,,,799-806,"Wang Jinjie,Luo Xiongwen,Xie Linsen,Gao Ying","Wang JJ,Luo XW,Xie LS,Gao Y",Gao Y,10.1109/BIBM49941.2020.9313167,South China University of Technology,"Colorectal cancer is a commonly diagnosed cancer of digestive system. Automatic and accurate segmentation of colorectal tumors from medical images (e.g., CT) has great significance for diagnosis, staging and treatment planning. However, the blurred boundary of tumors, as well as variability of their location and shape, make most traditional methods ineffectual. In this paper, we propose a diversified supervised U-shape CNN colorectal lesion segmentor (DSUCLS) to overcome this challenge. Our model mainly contains three key components: 1) the weakly supervised transfer learning module for supplementing generic features, where the irrelevant ones are filtered out by extra convolutional layers and image-level label, 2) an encoder-decoder structure based on U-shape architecture for learning specific pathological representation from medical images, 3) the multi-level supervised attention module incorporated into decoder path for producing coarse-to-fine guidance and guaranteeing finer attention map. 4), the pre-processing and post-processing strategies are applied to further improve segmentation performance. The experimental results illustrate that the proposed model outperforms other state-of-the-art techniques for colorectal lesion segmentation on CT images, achieving Dice scores of 0.733 and dramatically decreasing Hausdorff distance to 17.62.","Colorectal lesion segmentation,multi-task learning,fully convolutional network,weakly supervised feature supplemental scheme,multi-level supervised attention mechanism",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"OPTIC,DISC,CT,NETWORKS,TUMORS,CNN",,,
12,Unlabeled Data Guided Semi-supervised Histopathology Image Segmentation,,,815-820,"Wang Hongxiao,Zheng Hao,Chen Jianxu,Yang Lin,Zhang Yizhe,Chen Danny Z.","Wang HX,Zheng H,Chen JX,Yang L,Zhang YZ,Chen DZ",Wang HX,10.1109/BIBM49941.2020.9313428,University of Notre Dame,"Automatic histopathology image segmentation is crucial to disease analysis. Limited available labeled data hinders the generalizability of trained models under the fully supervised setting. Semi-supervised learning (SSL) based on generative methods has been proven to be effective in utilizing diverse image characteristics. However, it has not been well explored what kinds of generated images would be more useful for model training and how to use such images. In this paper, we propose a new data guided generative method for histopathology image segmentation by leveraging the unlabeled data distributions. First, we design an image generation module. Image content and style are disentangled and embedded in a clustering-friendly space to utilize their distributions. New images are synthesized by sampling and cross-combining contents and styles. Second, we devise an effective data selection policy for judiciously sampling the generated images: (1) to make the generated training set better cover the dataset, the clusters that are underrepresented in the original training set are covered more; (2) to make the training process more effective, we identify and oversample the images of ""hard cases"" in the data for which annotated training data may be scarce. Our method is evaluated on glands and nuclei datasets. We show that under both the inductive and transductive settings, our SSL method consistently boosts the performance of common segmentation models and attains state-of-the-art results.","Image Segmentation,Semi-Supervised Learning,Image Generation",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,http://arxiv.org/pdf/2012.09373,
13,On the Effective Transfer Learning Strategy for Medical Image Analysis in Deep Learning,,,827-834,"Wen Yang,Chen Leiting,Zhou Chuan,Deng Yu,Zeng Huiru,Xi Shuo,Guo Rui","Wen Y,Chen LT,Zhou CA,Deng Y,Zeng HR,Xi S,Guo R",Zhou CA,10.1109/BIBM49941.2020.9313593,University of Electronic Science & Technology of China,"In this study, we focus on exploring different strategies of transfer learning for medical applications. Firstly, we report competitive results indicating that convolutional neural networks (CNNs) that were pre-trained with different annotations could have diverse effects on the performance of medical image analysis, especially for segmentation tasks. Then, we present our further explorations of transferring different components of the CNNs, which revealed the importance of the decoder on medical segmentation. Finally, we demonstrate the advantages and disadvantages of transfer learning methods based on model integration. These observations present novel aspects of transfer learning for visual tasks in the medical field, and we expect that these discoveries will encourage the exploration of more effective transfer learning strategies for CNN-based medical image analysis.","Transfer learning,Medical image analysis,Convolutional neural network",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"CONVOLUTIONAL,NEURAL-NETWORKS",,,
14,An Efficient Weakly-Supervised Learning Method for Optic Disc Segmentation,,,835-842,"Wen Yang,Chen Leiting,Qiao Lifeng,Zhou Chuan,Xi Shuo,Guo Rui,Deng Yu","Wen Y,Chen LT,Qiao LF,Zhou CA,Xi S,Guo R,Deng Y",Zhou CA,10.1109/BIBM49941.2020.9313558,University of Electronic Science & Technology of China,"Accurate optic disc segmentation plays an essential role in the early diagnosis of glaucoma, which has been a major cause of irreversible blindness for the past decade. Recently, U-shape Convolutional Neural Network (CNN) models have achieved favourable performance in optic disc segmentation. However, it is worth noting that these models require a large number of pixel-level annotations while these annotations are difficult to obtain in clinical practice. As a solution, weakly-supervised training methods are commonly implemented, but it will provoke U-shape CNN generating inaccurate, diluted, and grid-like segmentation results. In this paper, we propose a novel Hybrid Network (HyNet) to solve the issue above. HyNet consists of a U-shape backbone hybridized with a cross-scale connection structure, which makes better use of multi-scale visual semantics. Nevertheless, the generalization ability of HyNet is affected by the domain shift among different datasets. Therefore, we innovatively combine weakly- and fully-supervised training methods, namely Hybrid Process (HyProcess), to solve the domain shift problem. Experimental results on ONHSD, DRIONS-DB, and DRISHTIGS datasets show that our model outperforms the state-of-the-art, reaching Dice of 82.39(%), 93.72(%), and 95.34(%) respectively. Additionally, our ablation study validates the effectiveness of HyNet along with HyProcess, and further analysis reflects their value in clinical practice.","Segmentation,Optic disc,Convolutional neural network,Weakly supervision",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"NERVE,HEAD,FUNDUS,CUP",,,
15,Multi-scale Generative Adversarial Network for Automatic Sublingual Vein Segmentation,,,851-856,"Xiong Qingyue,Li Xinlei,Yang Dawei,Zhang Wei,Zhang Ye,Kong Yajie,Li Fufeng,Zhang Wenqiang","Xiong QY,Li XL,Yang DW,Zhang W,Zhang Y,Kong YJ,Li FF,Zhang WQ",Li XL; Zhang WQ,10.1109/BIBM49941.2020.9313105,Fudan University,"Sublingual vein segmentation is an essential yet challenging task in computer-aided Traditional Chinese Medicine (TCM) tongue diagnosis. The most intricate part of sublingual vein segmentation is the strong diversity of sublingual vein images (e.g., various exposure of vein and complex background) and the natural connectivity of veins. To this end, we propose a novel and effective approach based on generative adversarial networks (GANs). Specifically, the framework comprises two modules: a segmentation generator network with multi-scale outputs and a scale-consistent discriminator. The former segmentation generator learns the overall structure of the segmentation, which reduces the training difficulties of stride 1 output by multi-scale outputs. The latter scale-consistent discriminator regularizes the segmentation maps from different output strides, which keeps the natural connectivity of veins and avoids generated noise. Additionally, we have constructed and publicized a well-annotated sublingual vein dataset (FDU-SV) which we believe will promote the significant development of this area. Extensive experimental results confirm that our method outperforms other representative segmentation models with a remarkable margin, achieving the state-of-the-art performance of 64.53% mIoU score.","Tongue diagnosis,multi-scale context,generative adversarial network,semantic segmentation",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
16,Data-Efficient Histopathology Image Analysis with Deformation Representation Learning,,,857-864,"Xu Jilan,Hou Junlin,Zhang Yuejie,Feng Rui,Ruan Chunyang,Zhang Tao,Fan Weiguo","Xu JL,Hou JL,Zhang YJ,Feng R,Ruan CY,Zhang T,Fan WG",Zhang YJ; Feng R,10.1109/BIBM49941.2020.9313159,Fudan University,"Histopathological examination of tissue biopsies plays a fundamental role in disease assessment. Automatic histopathology image analysis requires substantial task-specific annotations, which are often expensive and laborious in real-world scenarios. This insufficient annotation of data limits the generalization ability of supervised learning models. To address this challenge, we propose a self-supervised Deformation Representation Learning (DRL) framework to learn semantic features from unlabeled data. As a novel paradigm, our approach utilizes deformation as supervisory signals based on two critical features, i.e., local structure heterogeneity and global context homogeneity. Given an original histopathology image and its deformed counterpart, there exists a moderate difference in local structures. In contrast, due to the transformation-invariance, both images share a similar global context compared with other images. Specifically, an encoder network is trained to distinguish the local inconsistency by measuring the mutual information and maintain the global consistency with noise contrastive estimation. Extensive experiments on public histopathology image datasets show that the learned representations are generalizable for various downstream tasks, such as transfer learning on segmentation and semi-supervised classification. Our approach achieves superior results over other self-supervised methods and the ImageNet pre-trained model, and it reveals the ability as a novel pre-training scheme in histopathology image analysis.","Deformation Representation Learning,Global Context Homogeneity,Histopathology Image Analysis,Local Structure Heterogeneity,Self-Supervised Learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
17,NANet: Nuclei-Aware Network for Grading of Breast Cancer in HE Stained Pathological Images,,,865-870,"Yan Rui,Li Jintao,Rao Xiaosong,Lv Zhilong,Zheng Chunhou,Dou Jinjin,Wang Xiaowen,Ren Fei,Zhang Fa","Yan R,Li JT,Rao XS,Lv ZL,Zheng CH,Dou JJ,Wang XW,Ren F,Zhang F",Ren F; Zhang F,10.1109/BIBM49941.2020.9313329,Chinese Academy of Sciences,"Automatic breast cancer grading methods based on HE stained pathological images can be summarized into two categories. The first category is to use learning-based methods to directly extract the features of the pathological image for breast cancer grading. However, unlike the coarse-grained problem of breast cancer classification, grading of breast Invasive Ductal Carcinoma (IDC) is a fine-grained classification problem. Only using general methods cannot classify IDC well. The second category is to conduct the three evaluation criteria of Nottingham Grading System (NGS) separately, and then integrate the results of the three criteria to obtain the final IDC grading result. However, NGS is only a semi-quantitative evaluation method. The inherent medical motivation of NGS is to grade IDC with the help of nuclei-related features. In this paper, we proposed a nuclei-aware network for IDC grading in pathological images. The entire network achieves an effect similar to the attention mechanism in end-to-end learning, so as to learn fine-grained and nuclei-related feature representations for IDC grading. It should to be pointed out that our method can emphasize custom areas, thus providing a way to model medical knowledge into the network structure. This is different from the general attention mechanism that cannot artificially control the area of attention. Experimental results show that the performance of proposed method is better than the state-of-the-art.","Breast cancer grading,Pathological image,Nuclei segmentation,Convolutional neural network,Attention mechanism",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"SEGMENTATION,ATYPIA",,,
18,MSDAN: Multi-Scale Self-Attention Unsupervised Domain Adaptation Network for Thyroid Ultrasound Images,,,871-876,"Ying Xiang,Zhang Yulin,Wei Xi,Yu Mei,Zhu Jialin,Gao Jie,Liu Zhiqiang,Li Xuewei,Yu Ruiguo","Ying X,Zhang YL,Wei X,Yu M,Zhu JL,Gao J,Liu ZQ,Li XW,Yu RG",Li XW,10.1109/BIBM49941.2020.9313202,Tianjin University,"With the maturity of artificial intelligence, AI-aided diagnosis technology is gradually widely applied in clinical medicine. However, for the same pathological tissue, medical images produced by different types of instruments usually possess different data distributions. Because of the domain shift phenomenon, AI-aided diagnosis cannot accurately diagnose medical images in other domains, which is a waste of precious medical images. This paper proposes a Multi-Scale Self-Attention Unsupervised Domain Adaptive framework (MSDAN), which consists of three modules. First, the multi-scale framework constrains the source domain features and target domain features by optimizing adversarial losses with different level features. Second, the mix-up discriminator extracts latent spatial features by mixing up source domain and target domain features. Finally, MSDAN learns the geometric information of the pathological tissues in medical images through the self-attention module, thereby improving the transfer effect of the semantic information in medical images. Extensive experiments prove that the proposed approach can achieve superior performance on tasks with various degrees of domain shift and data complexity, especially for thyroid ultrasound images.","Medical Imaging,Domain Adaptation,AI-Aided Detection",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"WHITE,PAPER,NODULES",,,
19,Attention U-net for Interpretable Classification on Chest X-ray Image,,,901-908,"Zhang Xuan,Chen Ting","Zhang X,Chen T",Zhang X,10.1109/BIBM49941.2020.9313354,Tsinghua University,"Convolutional neural network (CNN) plays a vital role in numerous classification tasks; however, its lack of interpretability limits its application in medical image diagnosis. To tackle this issue, we propose Attention U-net, an interpretable classification model that can generate high-resolution localization maps for the predicted class. The novelty of our model is to adopt an upsampling-concatenating-convolution structure to create a fine-grained segmentation map and use attention pooling over the prior mask for bridging segmentation with classification. Since the relationship between segmentation and classification is equivalent to the formulation of the multiple instance learning (MIL), the attention pooling can be viewed as a MIL pooling function. In the attention pooling, the attention weights can be seen as a localization map, and thus provide evidence of classification. We integrate our model with grad-CAM (class activation mapping), a widely used method for CNN localization, and we prove that our attention-based localization map is highly correlated to the grad-CAM-integrated localization map. We apply our proposed model to the automatic diagnosis of lung diseases with Chest X-ray. Experimental results show that our model can reach high performance on both classification and interpretability simultaneously.","Chest X-ray,Localization,Attention Pooling",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"DIAGNOSIS,SYSTEM",,,
20,Cross-Modal Self-Attention Distillation for Prostate Cancer Segmentation,,,909-914,"Zhang Guokai,Shen Xiaoang,Luo Ye,Luo Jihao,Wang Zeju,Wang Weigang,Zhao Binghui,Lu Jianwei","Zhang GK,Shen XA,Luo Y,Luo JH,Wang ZJ,Wang WG,Zhao BH,Lu JW",Luo Y; Lu JW,10.1109/BIBM49941.2020.9313365,Tongji University,"The automatic segmentation of prostate cancer (PCa) from the multi-modal magnetic resonance imaging (MRI) is of prime importance for the initial staging and prognosis of patients. Nevertheless, the challenge of how to utilize multi-modal image features more efficiently still needs resolving, especially in the segmentation scenario. In this paper, we propose a crossmodal self-attention distillation network that can fully exploit the encoded information of the intermediate layers from different modalities, and the learned attention maps of different modalities are then transferred among modalities to provide significant spatial information with more details incorporated. Furthermore, we propose a novel spatial correlated feature fusion module that is able to learn more complementary correlation and nonlinear information from different modality images. To evaluate the effectiveness of the proposed approach, we conduct extensive experiments on the PCa MRI dataset, and the experiment results demonstrate that our proposed approach could achieve state-of-the-art performance.","Cross-modal,prostate cancer segmentation,self-attention distillation,feature fusion",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,http://arxiv.org/pdf/2011.03908,
21,LIRNet: Local Integral Regression Network for Both Strongly and Weakly Supervised Nuclei Detection,,,945-951,"Zhou Xiao,Cheng Zhen,Gu Miao,Chang Fei","Zhou X,Cheng Z,Gu M,Chang F",Cheng Z,10.1109/BIBM49941.2020.9313265,Tsinghua University,"Nuclei detection is one of the most important issues in the field of histopathology image analysis. Recent studies exploit convolutional neural networks to either locate the centroids of nuclei (counting-based approaches) or isolate them with sophisticated boundaries (segmentation-based algorithms). However, the training of these two methods demands considerable and laborious pixel-wise annotations labeled by pathology experts. To reduce the annotation cost, we propose a novel local integral regression network (LIRNet) that allows both strongly and weakly supervised learning (SSL/WSL) frameworks on nuclei detection. In addition, the LIRNet is able to predict a refined density map of nuclei, in which locating each nucleus is barely affected by the post-processing algorithms. Quantitative experimental results demonstrate that the SSL version of the LIRNet achieves state-of-the-art performance compared with counterparts. Besides, the WSL version possesses a competitive detection performance and an effortless data annotation that dramatically reduces annotation cost by 74.3%.","Nuclei detection,convolutional neural network,weakly supervised learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"SPARSE,AUTOENCODER,SEGMENTATION,EFFICIENT",,,
22,Learning to Classify Skin Lesions via Self-Training and Self-Paced Learning,,,963-967,"Asare Sarpong Kwadwo,You Fei,Nartey Obed Tettey","Asare SK,You F,Nartey OT",Asare SK,10.1109/BIBM49941.2020.9313150,University of Electronic Science & Technology of China,"Automatically classifying skin lesion is a challenging task owing to reasons such as high intra class variations, similarities between inter-class images, occlusions in dermoscopy images that impede accurate lesion localization, not to mention data unavailability. Considering that unlabeled data is abundant and cheap, this work proposes a classification framework that integrates the semi-supervised learning concepts of self-training and self-paced learning to classifying skin lesions. First, accurate instance segmentation is performed using the Mask R-CNN model to effectively localize and preserve the appearance and size of the skin lesions in an image. Then, a semi-supervised self-training scheme that utilizes self-paced learning strategy is implemented to generate and select pseudo-labeled samples to augment the training data. The proposed framework ensures that; 1) the spatial locations of skin lesions are accurately localized and preserved, which is critical for extracting semantically meaningful information akin to classification; 2) sufficient data samples are generated to enlarge the training data to avoid overfitting; 3) a model learns both ""easy"" and ""hard"" samples during training without necessarily ignoring features from less represented classes. Extensive experiments are performed using the ISIC dataset and results obtained demonstrate the effectiveness of the proposed approach.","Skin lesions classification,instance segmentation,semi-supervised learning,self-training,self-paced learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"CLASSIFICATION,CANCER",,,
23,Attention-based Saliency Hashing for Ophthalmic Image Retrieval,,,990-995,"Fang Jiansheng,Xu Yanwu,Zhang Xiaoqing,Hu Yan,Liu Jiang","Fang JS,Xu YW,Zhang XQ,Hu Y,Liu J",Liu J,10.1109/BIBM49941.2020.9313536,Southern University of Science & Technology,"Deep hashing methods have been proved to be effective for the large-scale medical image search assisting reference-based diagnosis for clinicians. However, when the salient region plays a maximal discriminative role in ophthalmic image, existing deep hashing methods do not fully exploit the learning ability of the deep network to capture the features of salient regions pointedly. The different grades or classes of ophthalmic images may be share similar overall performance but have subtle differences that can be differentiated by mining salient regions. To address this issue, we propose a novel end-to-end network, named Attention-based Saliency Hashing (ASH), for learning compact hash-code to represent ophthalmic images. ASH embeds a spatial-attention module to focus more on the representation of salient regions and highlights their essential role in differentiating ophthalmic images. Benefiting from the spatial-attention module, the information of salient regions can be mapped into the hash-code for similarity calculation. Extensive experiments on two different modalities of ophthalmic image datasets demonstrate that the proposed ASH can further improve the retrieval performance compared to the state-of-the-art deep hashing methods due to the huge contributions of the spatial-attention module.","Content-based Image Retrieval,Ophthalmic Image,Deep Hashing Methods,Spatial Attention,Salient Region",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,http://arxiv.org/pdf/2012.03466,
24,Automatic Extraction of Skeletal Maturity from Whole Body Pediatric Scoliosis X-rays Using Regional Proposal and Compound Scaling Convolutional Neural Networks,,,996-1000,"Ha Audrey,Vorhies John,Campion Andrew,Fang Charles,Fadell Michael II,Dou Steve,Halabi Safwan,Larson David,Wang Emily,Lee YongJin","Ha A,Vorhies J,Campion A,Fang C,Fadell M,Dou S,Halabi S,Larson D,Wang E,Lee Y",Ha A,10.1109/BIBM49941.2020.9313251,"Menlo Atherton High Sch, Atherton, CA 94027 USA.","Skeletal maturity assessment plays an important role in the management of pediatric orthopedic conditions such as scoliosis, slipped capital femoral epiphysis (SCFE), and pectus. The most common methods to estimate bone age are the use of hand, shoulder, and pelvis x-rays; however, integrating multi-site data adds cost and ionizing radiation exposure. Whole body pediatric scoliosis x-rays, performed for measuring curvature of the spine, include in the field of view multiple development landmarks such as ossifications of the shoulder, pelvis, and proximal femurs in a single exam, potentially providing a comprehensive survey of skeletal maturity that can assist in surgical planning. Therefore, we propose a system to automatically extract multiple skeletal maturity classifications from a single whole body scoliosis x-ray exam. Since these anatomic regions of significance are as small as 2% of the image, we first apply a multi-class region proposal network to extract the humeral head and five pelvic regions based on the modified Oxford Bone Score. We then apply multiple compound scaling convolutional neural networks (EfficientNet) in parallel to clinically stage each region. Our regional detection achieved an F1-score of 0.99, and our staging models achieved an overall accuracy of 89% and intraclass correlation coefficient of 0.84. Our work holds promise for a skeletal maturity assessment system that uses a single image of the entire axial skeleton. This may enable more data points for surgical planning of orthopedic diseases in pediatric patients while minimizing exposure to harmful radiation.","scoliosis,convolutional neural networks,machine learning,skeletal maturity,modified Oxford Bone Score",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"CAPITAL,FEMORAL,EPIPHYSIS,IDIOPATHIC,SCOLIOSIS,HEIGHT,VELOCITY,PREDICTION,PROGRESSION,STANDARDS,SYSTEM,HEALTH",,,
25,Calibration-free Blood Pressure Assessment Using An Integrated Deep Learning Method,,,1001-1005,"Han Chuanqi,Gu Mengyin,Yu Fang,Huang Ruoran,Huang Xi,Cui Li","Han CAQ,Gu MY,Yu F,Huang RR,Huang X,Cui L",Cui L,10.1109/BIBM49941.2020.9313586,Chinese Academy of Sciences,"Blood pressure is a key indicator of personal health. In this paper, we propose a novel integrated deep learning method which can accurately determine blood pressure levels under inter-subject scenario without initial calibration. In detail, a convolutional neural network is first introduced to extract features from the raw photoplethysmogram signals. After that, we concatenate the obtained features with personal BMI information and use them as the input of two independent neural networks, which output the estimated blood pressure values and the predicted hypertension class, respectively. These two outputs, in the end, are integrated assessed to generate the final result. Comprehensive experiments demonstrate that our method achieves highly competitive performance compared with others.","blood pressure classification,calibration-free,inter-subject,integrated assessment",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
26,HMOE-Net: Hybrid Multi-scale Object Equalization Network for Intracerebral Hemorrhage Segmentation in CT Images,,,1006-1009,"He Xizhi,Chen Kai,Hu Kai,Chen Zhineng,Li Xuanya,Gao Xieping","He XZ,Chen K,Hu K,Chen ZN,Li XY,Gao XP",Hu K,10.1109/BIBM49941.2020.9313439,Xiangtan University,"In this paper, we propose a novel Hybrid Multi-scale Object Equalization Network (HMOE-Net) to segment intracerebral hemorrhage (ICH) regions. In particular, we design a shallow feature extraction network (SFENet) and a deep feature extraction network (DFENet) to solve the problem of equalization learning of hybrid multi-scale object features. The multi-level feature extraction (MLFE) blocks are presented in DFENet to explore multi-level semantic features more effectively. Furthermore, we adopt a progressive feature extraction strategy combining SFENet and DFENet to further consider the differences of various ICH regions and achieve the equalization feature learning of multi-scale objects. To verify the effectiveness of HMOE-Net, we collect a clinical ICH dataset with a total of 500 CT cases from three hospitals for the evaluation. The experimental results show that HMOE-Net is superior to six state-of-the-art methods and achieves accurate segmentation for multi-scale ICH regions.","ICH,Hybrid multi-scale object,Equalization,Segmentation,Progressive feature extraction",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
27,Label Generation Network based on Self-selected Historical Information for Multiple Disease Classification on Chest Radiography,,,1015-1019,"Hu Yuelin,Zhang Yuejie,Zhang Tao,Gao Shang,Fan Weiguo","Hu YL,Zhang YJ,Zhang T,Gao S,Fan WG",Zhang YJ,10.1109/BIBM49941.2020.9313507,Fudan University,"Deep learning has made significant breakthroughs in image classification, but accurate diagnosis on chest radiography remains challenging due to a variety of potential diseases contained in one scan. Complex relations among diseases have significant clinical meanings, but are always ignored in most of previous work. Thus in this paper, we propose a novel Label Generation Network (LGN) which treats the label sequence as the caption of a radiology image and utilizes RNN to generate the disease labels according to the semantic relations and co-occurrence dependency among them. However, the sequential generation process of RNN makes it hard to capture the complex topological relations among diseases. To mitigate this problem, a Historical Information Module (HIM) is especially introduced to LGN, in which all the generated labels are fully considered when generating a new label. Moreover, a specific self-attention mechanism is applied in HIM to learn the topological disease relations and utilize them to select useful historical information which can provide positive guidance to the prediction of new label. Very positive results have been obtained in our experiments on the benchmark dataset of Chest X-ray14, which significantly outperform the state-of-the-art methods.","Chest radiography,Multi-label classification,Label Generation Network,Historical information,Self-attention mechanism",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
28,DeepCOVIDExplainer: Explainable COVID-19 Diagnosis from Chest X-ray Images,,,1034-1037,"Karim Md Rezaul,Doehmen Till,Cochez Michael,Beyan Oya,Rebholz-Schuhmann Dietrich,Decker Stefan","Karim MR,Dohmen T,Cochez M,Beyan O,Rebholz-Schuhmann D,Decker S",Karim MR,10.1109/BIBM49941.2020.9313304,Fraunhofer Gesellschaft,"In this paper(1), we proposed an explainable deep neural networks (DNN)-based method for automatic detection of COVID-19 symptoms from chest radiography (CXR) images, which we call `DeepCOVIDExplainer'. We used 15,959 CXR images of 15,854 patients, covering normal, pneumonia, and COVID-19 cases. CXR images are first comprehensively preprocessed and augmented before classifying with a neural ensemble method, followed by highlighting class-discriminating regions using gradient-guided class activation maps (Grad-CAM++) and layer-wise relevance propagation (LRP). Further, we provide human-interpretable explanations for the diagnosis. Evaluation results show that our approach can identify COVID-19 cases with a positive predictive value (PPV) of 91.6%, 92.45%, and 96.12%, respectively for normal, pneumonia, and COVID-19 cases, respectively, outperforming recent approaches.","COVID-19,Biomedical imaging,Deep learning,Explainability,Grad-CAM,Layer-wise relevance propagation",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,https://ieeexplore.ieee.org/ielx7/9312958/9312977/09313304.pdf,
29,Identifying patch-level MSI from histological images of Colorectal Cancer by a Knowledge Distillation Model,,,1043-1046,"Ke Jing,Shen Yiqing,Wright Jason D.,Jing Naifeng,Liang Xiaoyao,Shen Dinggang","Ke J,Shen YQ,Wright JD,Jing NF,Liang XY,Shen DG",Ke J,10.1109/BIBM49941.2020.9313141,Shanghai Jiao Tong University,"Microsatellite instability (MSI) is the result of a defective DNA mismatch repair (MMR) system, and its presence occurs in a variety of cancers. The determination of MSI in colorectal cancer (CRC) will have a better prognosis and management of cancer patients. As the routine MSI identification via molecular testing is expensive, time-consuming, and region-restricted, novel methods to detect MSI are of great interest. In this work, we propose a multi-stage convolutional neural network (CNN) based framework to identify MSI status in colorectal cancer patients from histopathological images. A mislabel-aware module is designed to deal with the uncertainty problem in global-local labelling. An auto-grading model is proposed to discriminate patches by the degree of their histopathological correlation with recognizable MSI status, and subsequently aggregate the weights to make slide-level predictions. Our proposed methodology outperforms the existing models in the classification accuracy, and explicitly sorts out patches with representative features. The research outcome has the potential to assist in the interpretation of histopathology as a surrogate for MSI testing and also in the study of recognizable morphology of MSI-H/MSS tumors. Furthermore, this approach can be extended and applied to other cancer types.","Microsatellite instability,deep learning,convolutional neural network,distillation",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
30,A Dynamic Group Equivariant Convolutional Networks for Medical Image Analysis,,,1056-1062,"Li Yan,Cao Guitao,Cao Wenming","Li Y,Cao GT,Cao WM",Cao GT,10.1109/BIBM49941.2020.9313601,East China Normal University,"Group equivariant Convolutional Neural Networks (G-CNNs) has led to big empirical success in the medical domain, one fundamental assumption is that equivariance provides a powerful inductive bias for medical images. By leveraging concepts from group representation theory, we can generalize vanilla Convolutional Neural Networks (CNNs) to G-CNN. Currently, although embedding an arbitrary equivariance to CNNs can learn powerful disentangled representations in a higher dimensional domain, they lack explicit means to learn meaningful relationships among the equivariant convolutional kernels. In this paper, we propose a generalization of the dynamic convolutional method, named as dynamic group equivariant convolution, to strengthen the relationships and increase model capability by aggregating multiple group convolutional kernels via attention. Meanwhile, we generalize attention to an equivariant one to preserve equivariant of dynamic group convolution. In our approach, this leads to a flexible framework that enables a dynamic convolutional in G-CNNs by means of a dynamic routing layer expansions. We demonstrate that breast tumor classification is substantial improvements when compared to a recent baseline architecture.","Deep learning,Group Convolutional neural networks,Equivariance,Dynamic group convolution,Attention",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
31,Enhancing Automated COVID-19 Chest X-ray Diagnosis by Image-to-Image GAN Translation,,,1068-1071,"Liang Zhaohui,Huang Jimmy Xiangji,Li Jun,Chan Stephen","Liang ZH,Huang JX,Li J,Chan S",Liang ZH,10.1109/BIBM49941.2020.9313466,York University - Canada,"The severe pneumonia induced by the infection of the SARS-CoV-2 virus causes massive death in the ongoing COVID-19 pandemic. The early detection of the SARS-CoV-2 induced pneumonia relies on the unique patterns of the chest X-Ray images. Deep learning is a data-greedy algorithm to achieve high performance when adequately trained. A common challenge for machine learning in the medical domain is the accessibility to properly annotated data. In this study, we apply a conditional adversarial network (cGAN) to perform image to image (Pix2Pix) translation from the non-COVID-19 chest X-Ray domain to the COVID-19 chest X-Ray domain. The objective is to learn a mapping from the normal chest X-Ray visual patterns to the COVID-19 pneumonia chest X-ray patterns. The original dataset has a typical imbalanced issue because it contains only 219 COVID-19 positive images but has 1,341 images for normal chest X-Ray and 1,345 images for viral pneumonia. A U-Net based architecture is applied for the image-to-image translation to generate synthesized COVID-19 X-Ray chest images from the normal chest X-ray images. A 50-convolutional-layer residual net (ResNet) architecture is applied for the final classification task. After training the GAN model for 100 epochs, we use the GAN generator to translate 1,100 COVID-19 images from the normal X-Ray to form a balanced training dataset (3,762 images) for the classification task. The ResNet based classifier trained by the enhanced dataset achieves the classification accuracy of 97.8% compared to 96.1% in the transfer learning mode. When trained with the original imbalanced dataset, the model achieves an accuracy of 96.1% compared to 95.6% in the training from trainby-scratch model. In addition, the classifier trained by the enhanced dataset has more stable measures in precision, recall, and F1 scores across different image classes. We conclude that the GAN-based data enhancement strategy is applicable to most medical image pattern recognition tasks, and it provides an effective way to solve the common expertise dependence issue in the medical domain.","COVID-19,generative adversarial network,GAN,image classification,deep learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,https://ieeexplore.ieee.org/ielx7/9312958/9312977/09313466.pdf,
32,Learning Semi-Supervised Representation Enrichment Using Longitudinal Imaging-Genetic Data,,,1115-1118,"Seo Hoon,Brand Lodewijk,Wang Hua","Seo H,Brand L,Wang H",Wang H,10.1109/BIBM49941.2020.9313310,Colorado School of Mines,"Alzheimer's Disease (AD) is a progressive memory disorder that causes irreversible cognitive decline. Recently, many statistical learning methods have been presented to predict cognitive declines by using longitudinal imaging data. However, missing records that broadly exist in the longitudinal neuroimaging data have posed a critical challenge for effectively using these data in machine learning models. To tackle this difficulty, in this paper we propose a novel approach to integrate longitudinal (dynamic) phenotypic data and static genetic data to learn a fixed-length biomarker representation using the enrichment learned from the temporal data in multiple imaging modalities. Armed with this enriched biomarker representation, as a fixed-length vector per participant, conventional machine learning models can be used to predict clinical outcomes associated with AD. We have applied our new method on the Alzheimer's Disease Neruoimaging Initiative (ADNI) cohort and achieved promising experimental results that validate its effectiveness.","Alzheimer's Disease,Multi-Modal,Longitudinal,Imaging Data,Enrichment",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"QUANTITATIVE,TRAIT,LOCI,ASSOCIATION,BIOMARKERS",,,
33,Human gait model based on a machine learning and filtering noisy signals with recursive algorithm,,,1142-1145,"Teran P Diego,Dominguez Enrique","Teran D,Dominguez E",Teran D,10.1109/BIBM49941.2020.9313447,Universidad de Malaga,"Gait analysis is widely used by doctors to detect anomalies and conclude possible treatments to patient. Conventionally, the gait analysis has been considered subjectively and now is use the technology to improve the data information. The sensors noises, however, causes errors in kinematic data to analyze any waveform, and this analysis requires a large amount of noiseless data for using artificial intelligent. In contrast, this paper presents an initial study about acquiring human gait parameters and data to get a model using computer learning. Therefore, we developed a portable acquisition system non-invasive using an online recursive algorithm in a micro-controller for processing and filtering signals of wearable sensors. The Data Acquisition Signal (DAS) system utilizes a Force Sensitive Resistor (FSR) on the heel and two inertial sensors, one in the thigh and one in the leg, to measure the knee angle; such system calibrates automatically the inertial sensors in each experiment. DAS system has a user-interface that includes intelligent algorithms to normalize, interpolate, and obtain the model curve with fitting of the data showing the gait phases. Our experiments were tested on non-pathology patients with different ages (young, adult and elder) with normal gait pattern selected by a physiotherapist. To know the reliability of the kinematic model, we altered the gait of each patient by shifting the floor and footwear. The results and the gait models seen by the physiotherapist were displayed on an interface.","Human gait analysis,Gait datasets,Kinematic model,Inertial sensor,Data acquisition",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
34,Hierarchical Attention-Based Multiple Instance Learning Network for Patient-Level Lung Cancer Diagnosis,,,1156-1160,"Wang Qingfeng,Zhou Ying,Huang Jun,Liu Zhiqin,Li Ling,Xu Weiyun,Cheng Jie-Zhi","Wang QF,Zhou Y,Huang J,Liu ZQ,Li L,Xu WY,Cheng JZ",Huang J,10.1109/BIBM49941.2020.9313417,Southwest University of Science & Technology - China,"Lung cancer is the leading cause of cancer-related deaths worldwide, while the risk factors for lung cancer mortality can be significantly reduced if the accurate early diagnoses for small malignant lung nodules are possible. In this paper, we propose a hierarchical attention-based multiple instance learning (HA-MIL) framework for patient-level lung cancer diagnosis by introducing two-level cascaded attention mechanisms, one at nodule level and the other at attribute level. The proposed HA-MIL framework is constructed by aggregating important attribute representation into nodule representation and then aggregating important nodule representation into lung cancer representation. The experiments on the public Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) dataset showed that the HA-MIL model performed significantly better than the previous approaches such as the higher-order transfer learning, instance-space MIL and embedding-space MIL, which demonstrated the effectiveness of hierarchical multiple instance learning based on two-level attentions. The results analysis suggested that the HA-MIL model also found the key nodules and attributes by higher attention weights, which were more interpretable for the model decision making.","Multiple instance learning,hierarchical attention mechanism,attribute-level attention,nodule-level attention,patient-level lung cancer diagnosis",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
35,On Automatic Detection of Central Serous Chorioretinopathy and Central Exudative Chorioretinopathy in Fundus Images,,,1161-1165,"Wen Yang,Chen Leiting,Qiao Lifeng,Deng Yu,Dai Siying,Chen Junjing,Zhou Chuan","Wen Y,Chen LT,Qiao LF,Deng Y,Dai SY,Chen JJ,Zhou CA",Zhou CA,10.1109/BIBM49941.2020.9313274,University of Electronic Science & Technology of China,"Automatic detection of chorioretinopathy plays an important role in clinical practice, but the detection of a major chorioretinopathy of central serous chorioretinopathy based on fundus photography images has rarely been studied, let alone distinguishing it from another chorioretinopathy of central exudative chorioretinopathy. Due to the high degree of similarity between the two chorioretinopathies on fundus images, it is difficult for the latest automatic methods to accurately distinguish between them. In this study, we design a deep neural network with two branches for different classification tasks, where the first one is to distinguish the normal and abnormal while the other is to classify the two chorioretinopathies. We manage to improve the classification accuracy by combining focal loss and discriminative loss. Extensive experiments are conducted for comparison between our method and other universal classification models using a private retinal fundus dataset. The results demonstrate that our method achieves the best performance with 97.69%, 99.58% and 98.87% on the accuracy, precision and sensitivity, respectively.","Central Serous Chorioretinopathy,Central Exudative Chorioretinopathy,Automatic detection,Deep learning,Triplet loss,Center loss,Focal loss",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
36,Do Noises Bother Human and Neural Networks In the Same Way? A Medical Image Analysis Perspective,,,1166-1170,"Wen Shao-Cheng,Chen Yu-Jen,Liu Zihao,Wen Wujie,Xu Xiaowei,Shi Yiyu,Ho Tsung-Yi,Jia Qianjun,Huang Meiping,Zhuang Jian","Wen SC,Chen YJ,Liu ZH,Wen WJ,Xu XW,Shi YY,Ho TY,Jia QJ,Huang MP,Zhuang J",Wen SC,10.1109/BIBM49941.2020.9313560,National Tsing Hua University,"Deep learning had already demonstrated its power in medical images, including denoising, classification, segmentation, etc. All these applications are proposed to automatically analyze medical images beforehand, which brings more information to radiologists during clinical assessment for accuracy improvement. Recently, many medical denoising methods had shown their significant artifact reduction result and noise removal both quantitatively and qualitatively. However, those existing methods are developed around human-vision, i.e., they are designed to minimize the noise effect that can be perceived by human eyes. In this paper, we introduce an application-guided denoising framework, which focuses on denoising for the following neural networks. In our experiments, we apply the proposed framework to different datasets, models, and use cases. Experimental results show that our proposed framework can achieve a better result than human-vision denoising network.","Denoising,Deep Learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,http://arxiv.org/pdf/2011.02155,
37,On the Deep Learning-based Age Prediction of Color Fundus Images and Correlation with Ophthalmic Diseases,,,1171-1175,"Wen Yang,Chen Leiting,Qiao Lifeng,Deng Yu,Zhou Chuan","Wen Y,Chen LT,Qiao LF,Deng Y,Zhou CA",Zhou CA,10.1109/BIBM49941.2020.9313266,University of Electronic Science & Technology of China,"Color fundus imaging is an important modality used for ophthalmic disease screening and provides a non-invasive in-vivo method for assessing body condition. We aimed to assess deep learning models for age prediction from fundus images of normal patients and patients with ophthalmic diseases. In addition, we sought to investigate interpretable clues regarding the salient regions between normal and pathological changes as determined by deep learning models during age prediction. In this study, we used a convolutional neural network model for age prediction and evaluated it on an in-house database of fundus images of the Chinese population. The results of the experiment revealed some conclusions as follows: (1) deep learning-based classification models have better age prediction performance than deep learning-based regression models of fundus images; (2) deep learning-based models tend to use holistic information of the fundus for age prediction; (3) ophthalmic diseases that cause damage to the structure of the fundus and change its appearance will result in a decline in age prediction performance.","Age prediction,Deep learning,Color fundus images,Ophthalmic disease",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"MACULAR,DEGENERATION",,,
38,Cross-subject EEG Channel Optimization by Domain Adversarial Sparse Learning Model,,,1176-1179,"Wu Zhenhua,Zeng Hong,Zhao Yue,Li Xiufeng,Zhang Jiaming,Hattori Motonobu","Wu ZH,Zeng H,Zhao Y,Li XF,Zhang JM,Hattori M",Hattori M,10.1109/BIBM49941.2020.9313436,University of Yamanashi,"How to decrease the number of electroencephalogram (EEG) record channels, and acquire the optimal electrodes to perform EEG signals analysis, are of extremely importance in developing and promoting highly available Brain-Computer Interface (BCI). In this paper, we design an EEG channel optimization model, named Domain Adversarial Sparse Learning model (DASL), to perform fatigue state detection with minimal and optimal EEG electrodes. DASL composes of Sparse Learning (SL), Domain Adversarial Neural Networks (DANN) and Generative Adversarial Networks (GAN). Herein, SL is used to find the optimal EEG channels through selecting key features from the source domain, these key features are then used to determine fatigue state by DANN across subjects, GAN aims at improving the robustness for our proposed model. Experimental results show DASL outperforms other traditional machine learning methods in the classification performance of mental state tasks under the condition of optimal and minimal EEG electrodes.","domain adversarial,sparse learning,generate adversarial network,key channels",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"COMMON,SPATIAL-PATTERNS,BCI",,,
39,Ultrasound Image-Based Diagnosis of Cirrhosis with an End-to-End Deep Learning model,,,1193-1196,"Yang Hai,Sun Xiaohui,Sun Yang,Cui Ligang,Li Bingshan","Yang H,Sun XH,Sun Y,Cui LG,Li BS",Cui LG,10.1109/BIBM49941.2020.9313579,Peking University,"Cirrhosis is a chronic liver disease that seriously jeopardizes the life and health of patients. Currently, ultrasound (US) imaging is commonly used by the computer-aided diagnosis (CAD) system to diagnose cirrhosis. With the rapid development of artificial intelligence, deep learning methods for cirrhosis diagnosis using ultrasound image data have emerged. However, due to US images' complexity and variability, this input usually requires manual annotation. This study proposes LiverTL, an end-to-end deep learning approach for the automatic cirrhosis ultrasound image classification to overcome these limitations. LiverTL includes an automatic region of interest (ROI) detection module to support various ultrasound images' ROI extraction. Simultaneously, the classification module utilizes ROI areas and obtain the cirrhosis diagnosis results through the transfer learning network. We find that LiverTL achieves high classification accuracy on our evaluation data set. The cirrhosis data experiments suggest that a proper pre-training model for transfer learning is crucial for the classification results. These findings potentially pave the way to advance the diagnosis and therapy of cirrhosis.","cirrhosis,ultrasound,computer-aided diagnosis,deep learning,transfer learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
40,ECG Pattern Discovery Algorithm Based on Local Repeatability,,,1206-1209,"Yin Yunfei,Cheng Hui,Huang Faliang","Yin YF,Cheng H,Huang FL",Yin YF,10.1109/BIBM49941.2020.9313256,Chongqing University,"In view of the problems of supervised machine learning methods, such as low accuracy, long training time, complicated models, and poor versatility, this paper proposes a method for discovering ECG patterns based on local repeatability. By using the sliding window technique, the patterns contained in the ECG time series data are mined; by using the pattern matching technique, a method for improving the similarity of the ECG time series is explored. The paper implements an ECG pattern discovery algorithm based on local repeatability, accurately calculates the similarity between two ECG patterns, and performs clustering and labeling based on these similarities. Experimental results show that the method proposed in this paper is superior to the existing methods in terms of accuracy of pattern discovery and stability of pattern discovery.","Data Mining,ECG,Local Repeatability,Patterns,Time Series Data",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,CLASSIFICATION,,,
41,Tumor Classification Based on Approximate Symmetry Using Dual-Branch Complementary Fusion Network,,,1215-1215,"Yu Mei,Cheng Minyutong,Li Xubin,Liu Zhiqiang,Gao Jie,Fu Xuzhou,Li Xuewei,Yu Ruiguo","Yu M,Cheng MYT,Li XB,Liu ZQ,Gao J,Fu XZ,Li XW,Yu RG",Li XW,10.1109/BIBM49941.2020.9313100,Tianjin University,"MRI technology is usually used to distinguish the grade of the tumor in the patient. Due to technical limitations, the classification of tumors (high-grade gliomas and metastases) on MRI images has become a problem for doctors. At present, the widely used neural network is gradually applied to the tumor classification of MRI images, which not only reduces the burden of human resources, but also shows good classification accuracy. Although different good experimental data are obtained under various neural networks, there is still a problem in using these neural networks for tumor classification: the semantic information expressed on the image by the deep features of the neural network is too scattered, and it is difficult to concentrate the lesion area. In this article, we propose a new strategy that combines the approximate symmetry properties of the MRI image with neural network, then uses a dual-branch network instead of the basic network for feature extraction, and adds complementary learning to the network, different features fusion and attention mechanism to enrich detailed information. Our method performs multiple comparison and ablation experiments on the dataset of glioma and metastasis, which proves that the proposed method is effective for tumor classification assisted by MRI.","MRI,Tumor Classification,Dual-branch Network,Complementary Learning,Different Features Fusion,Attention Mechanism",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
42,Attention Based Detection for Central Serious Chorioretinopathy in Fundus Image,,,1221-1225,"Zhou Chuan,Zhang Tian,Chen Leiting,Wen Yang,Lei Ting,Chen Junjing","Zhou CA,Zhang T,Chen LT,Wen Y,Lei T,Chen JJ",Chen LT,10.1109/BIBM49941.2020.9313400,University of Electronic Science & Technology of China,"The detection of Central Serious Chorioretinopathy (CSCR) which is one of the main causes of vision loss so far still relies on manual evaluation of fundus images which requires experienced clinicians and is time-consuming. In this paper, we aim to utilize deep learning to overcome the difficulty of the absence of automated diagnostic methods for CSCR. However, there still exists two issues in general neural networks when applied to CSCR detection: 1) The lesion area that contributes the most for the final result cannot get adequate attention in one-stream networks. 2)Lesion regions become blurred when high-resolution fundus images are resized into lower resolution. Attention mechanism has been proved to be effective in addressing the problem of insufficient attention to significant regions, so we propose a Crop Attention Network (CA-Net) to screen CSCR automatically. CA-Net is based on attention framework and tackles the issues mentioned above by cropping the whole image into patches and adding weights on each patch. Experiment results on in-house database show that the proposed method outperforms all baseline methods.","Central Serious Chorioretinopathy,Deep convolutional neural networks,Attention mechanism,Fundus images",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
43,Identification of gene signature associated with type 2 diabetes mellitus by integrating mutation and expression data,,,1237-1244,"Zhu Zijun,Han Xudong,Cheng Liang","Zhu ZJ,Han XD,Cheng L",Zhu ZJ,10.1109/BIBM49941.2020.9313584,Harbin Medical University,"Type 2 diabetes mellitus (T2DM) is a frequency occurred chronic disease. The early diagnosis could be very helpful for the treatment of T2DM patients. With the development of sequencing technology, a large number of differentially expressed genes were identified from expression data. However, the method of machine learning can only identify the local optimal solution as the signature. The mutation information obtained by inheritance can better reflect the relationship between genes and diseases. Therefore, we need to integrate mutation information to more accurately identify the signature. To this end, we integrated genome-wide association study (GWAS) data and expression data, combined with expression quantitative trait loci (eQTL) technology to get T2DM predictive signature (T2DMSig-10). Firstly, we used GWAS data to obtain a list of T2DM susceptible loci. Then, we used eQTL technology to locate risk single nucleotide polymorphisms (SNPs) to genes, and combined with the pancreatic 13-cells gene expression data to obtain 10 protein-coding genes. Next, we combined these genes with equal weights. After receiving receiver operating characteristic (ROC), single gene removal method, gene ontology function enrichment and protein-protein interaction network were used to verify, the results showed that T2DMSig-10 had an excellent predictive effect on T2DM (AUC=0.99), and was highly robust. In short, we obtained the predictive signature of T2DM, and further analyzed and verified it.","type 2 diabetes mellitus,genome-wide association study,expression quantitative trait loci,predictive signature",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
44,"Year, Location, and Species Information In Predicting MIC Values with Beta-Lactamase Genes",,,1383-1390,"Kromer-Edwards Cory,Castanheira Mariana,Oliveira Suely","Kromer-Edwards C,Castanheira M,Oliveira S",Kromer-Edwards C,10.1109/BIBM49941.2020.9313331,University of Iowa,"Antibiotic resistance in bacteria is being recognized as a global health threat. Patients with infections caused by antibiotic resistant bacteria have higher mortality rates and use more hospital resources. The diagnostic of infections caused by antibiotic resistant bacteria is cumbersome and requires bacterial isolation, identification of the species, followed by antibiotic susceptibility testing. This process can take up to 72h. DNA sequencing methods are becoming more convenient and affordable, and the presence of different genes can help predict the susceptibility results of bacteria against antibiotics. We aim to use Machine Learning (ML) to predict the Minimum Inhibitory Concentration (MIC) for bacterial isolates from resistance genes present in their DNA. To do this, we will use information about the presence of beta-lactamase genes identified by whole genome sequencing and its correlation with the susceptibility results (MIC values) for beta-lactam antibiotics. The data was collected worldwide during the years 2016, 2017, and 2018. Species analyzed were Escherichia coli and Klebsiella pneumoniae. All models were trained on different datasets, but all predicted for 2018 data. The training data was split by separator of either year, species, or continent. The species and continent separators had 2016 and 2017 data combined while the year separator had the training datasets of 2016 data, 2017 data, or 2016 and 2017 combined data. It is found that K-Nearest Neighbors performs similarly to Random Forest with +/- 12-fold dilution MIC predictions. Random Forests had higher F1-micro scores when predicting the exact MIC value. Training data separated by year outperforms training data separated by continent or species.","continent,species,beta-lactamase,gene,acquisition,MIC,minimum,inhibitory,concentration,antibiotic,random forest,k-nearest-neighbors",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
45,Machine Learning Opportunities for Automatic Tongue Diagnosis Systems,,,1498-1502,"Vocaturo Eugenio,Zumpano Ester","Vocaturo E,Zumpano E",Vocaturo E,10.1109/BIBM49941.2020.9313321,University of Calabria,"Machine Learning approaches and the availability of digital data are favoring the rising of applications in biomedical field. Smartphones and wearable devices are facilitating the acquisition of images and audio files of the population and this is fueling patient-centric approaches as regards to the diagnosis of specific diseases. This trend is desired by the World Health Organization both for a view to monitoring and empowering the population and for encouraging the containment of medical costs. Tongue inspection is a clinical practice of Traditional Chinese Medicine (TCM) that has been existing for thousands of years, and allows to intercept diseases and severity of internal organs. While in the past, the traditional diagnosis of the tongue depended on the observation of the doctor, now the use of automatic computerized diagnosis systems is conceivable. In this paper, we focus on the topics of interest from which to start to prototype mobile solutions for tongue diagnosis based on artificial intelligence.","Tongue Imaging Analysis,Automatic Tongue Diagnosis System",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
46,The contribution of AI in the detection of the Diabetic Retinopathy,,,1516-1519,"Vocaturo Eugenio,Zumpano Ester","Vocaturo E,Zumpano E",Vocaturo E,10.1109/BIBM49941.2020.9313541,University of Calabria,"The prevalence of diabetes is rising worldwide and in the last two decades, blindness and low vision due to diabetic eye complications have greatly increased. International Diabetes Federation (IDF) [1] reports that in 2000, the global estimated number of of adults with diabetes was 151 million. By 2009 it had grown by 88% to 285 million and today, it is reported that 9.3% of adults aged 2079 years - corresponding more or less to 463 million people are living with diabetes. IDF estimates that there will be 600 million of person with diabetes by 2035, and 700 million by 2045 Diabetic retinopathy (DR) is a complication of diabetes that affects eyes. It originates from the damage to the blood vessels of the light-sensitive tissue of the retina and is the leading cause of cases of blindness. While the primary method for evaluating diabetic retinopathy involves direct and indirect ophthalmoscopy, Artificial Intelligent, deep learning and big data have been on the rise in the eye care sector. These tools provide low-cost, effective and potential solutions in supporting early and accurate diagnosis, both facilitating the work of specialists and allowing to select specific treatments. In this paper we analyze AI tools used in the screening of diabetic retinopathy.","Advanced 3D Visualization,AI tools,Health Data Management.",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
47,The Similar Sparse Domain Adaptation Illustrated by the case of TCM Tongue Inspection,,,1520-1525,"Chen Zhikui,Zhang Xu,Huang Wei","Chen ZK,Zhang X,Huang W",Chen ZK,10.1109/BIBM49941.2020.9313114,Dalian University of Technology,"More attention is paid to personal health accompanying by the development of society and the change of lifestyle. Not limited in disease, the sub-health is bedeviling humanity more generally. An increasing number of people go in quest of Traditional Chinese Medicine (TCM) for life quality, since TCM achieves the significant and curative effectiveness in recuperating certain sub-health conditions. However, the lack of clinical data poses a vast challenge on the emerging deeplearning-based methods in modeling TCM diagnosis. In this paper, a Similar Sparse Domain Adaptation (SSDA) method is proposed in modeling the tongue inspection, which is one of the four diagnostic methods and plays important roles in TCM primary diagnosis. First, a similar domain adaptation is introduced to transfer necessary knowledge efficiently and overcome insufficient data. Then, inspired by the Lottery Ticket hypothesis, the network is pruned to generate sparse subnet using in adaptation. Finally, the model with two combined sparse network is designed. Extensive experiments are conducted on the real clinical data set collected in Dalian, China. Proposed model uses fewer training data samples and parameters, while consuming less power and memory, which make it easier to store and run on low-power hardware systems for widely promoting.","Traditional Chinese Medicine,deep learning,tongue inspection,domain adaptation,sparse model",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
48,A Support Vector Machine Learning for the Upward and Downward Tendency Theory of Traditional Chinese Medicine,,,1526-1533,"Cheng Hongyan,Huang Zhongquan,Yu Xipeng,Liang Zhiwei","Cheng HY,Huang ZQ,Yu XP,Liang ZW",Cheng HY,10.1109/BIBM49941.2020.9313140,Guangzhou University of Chinese Medicine,"Objective: In order to study the traditional Chinese medicine (TCM) drug property theory based on machine learning (ML), the support vector machine (SVM) as a powerful model in ML is worthy of exploring for the distinguish on the TCM drug Upward and Downward Tendency in this theory. Methods: 1. To select and include the research materials and objects. From a TCM drug textbook applying for the state TCM university education (TBTCMUE), a total (t) of 135 TCM drug was selected, containing necessary features such as the main chemical structure among active ingredients, the botany Family, the Medicinal Part, and the TCM drug's features of Four-Qi or Cold-Heat, Five-Taste or Flavor, and Tendency, a known classification feature in the TBTCMUE. 2. To establish the TCM drug features' coding rules. TCM drug's features were digitized and coded with domain codevalues in different levels of extent. 3. To build template, training, and pattern vector data sets from TCM drug features. Each TCM drug's Tendency feature can suppose as a column vector in matrix T(:, 1), whereas the other features or their combinations could suppose as corresponding numbers column vectors in another matrix L(:, c). Meanwhile, extract r numbers (r < t) of drugs from the 135 TCM drugs (t=135) to create r rows matrix T (r, 1) for template set and the same rows matrix L (r, c) for a learning or training set. The left p (p=t-r) numbers of TCM drugs after the extraction could form a matrix P (p, c) for a pattern or testing set. 4. To create an SVM model for recognizing the TCM drug Tendency. By matching the template set T (r, 1), each TCM drug of the pattern set P (p, c), was recognized by the SVM model and the trained SVM rule from its the learning set L (r, c). Then, the matched rate expected, a value counted from the matched results, was counted divided by the total matching count and greater than a supposing threshold value (THV) of 0.75, referring to an acceptable result in the pattern recognition. Results: Based on the recognition with SVM and the SVM algorithm rule relative to each different pattern when parameters were specified by p=1 and r=tp=134, the Medicinal Parts, as one single feature vector of the TCM drug's features, showed that its matched rate of the Downward Tendency was 0.8 and referred to be an acceptable outcome. Another accepted at the matched rate of 0.75 was the Family-Flavor-Benzene-atom combination group of four-feature combination vectors for Downward Tendency. For Upward Tendency and Dual Tendency, the features had unacceptable results. Conclusion: The TCM drug's feature vectors composed of TCM drug Medical Parts, or TCM drug's features combination of the family, flavor, Benzene, and atom, can be helpfully utilized to reveal the contributing factors for the TCM drug's Downward Tendency.","Upward and Downward Tendency theory of,traditional Chinese medicine or Chinese herb,feature,support,vector machine",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
49,Summarizing Professor Lei Zhang's Therapeutic Experience of Dyspnea Disease Based on Machine Learning,,,1608-1612,"Wang Zhongyi,Liu Jialin,Wei Ningjing,Zhao Zhenying,Li Guo-Zhang,Gao Qing,Sun Yuxin,Yin Yating","Wang ZY,Liu JL,Wei NJ,Zhao ZY,Li GZ,Gao Q,Sun YX,Yin YT",Li GZ,10.1109/BIBM49941.2020.9313295,Henan University of Traditional Chinese Medicine,"Objective: To summarize Professor Lei Zhang's clinical experience in treating asthma. Technology or Method: The 11038 cases of Professor Zhang Lei from 2006 to 2017 were digitization, and the clinical case database of Professor Zhang was established. Three professional researchers extracted medical records of asthma syndrome from the database and established the prescription database of asthma syndrome. Finally, R Studio platform is used to apply association rules, hierarchical clustering and other machine learning methods to study prescription medical cases. Results: 260 medical cases, 238 related prescriptions and 323 kinds of Traditional Chinese medicine were excluded function. It is emphasized to grasp the physiological characteristics of the lung, pay attention to the characteristics of ""purge and purge"", and the identification and treatment of asthma syndrome are complex, especially the dosage and compatibility of drugs should be paid attention to in clinical practice. and included Ephedra, Bitter apricot seed and Perilla fruit are the three drugs with the highest frequency of use. Among them, 40 traditional Chinese medicines have higher than average frequency of use. Cluster analysis of 9 practical combinations of symptoms and Traditional Chinese medicine. Conclusion: Professor Zhang believes that lung diseases, weak lung Qi, sputum is the root of asthma syndrome. Asthma, oppression in Chest, cough and other diseases are commonly seen in the treatment of asthma syndrome due to evil Qi blocking lung, obstruction of Qi and loss of lung.","Traditional Chinese medicine,Asthma syndrome,treatment rules,machine learning,data mining",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
50,EEG-based mild depression recognition using multi-kernel convolutional and spatial-temporal Feature,,,1777-1784,"Fan Yongheng,Yu Ruilan,Li Jianxiu,Zhu Jing,Li Xiaowei","Fan YH,Yu RL,Li JX,Zhu J,Li XW",Zhu J; Li XW,10.1109/BIBM49941.2020.9313499,Lanzhou University,"Electroencephalography (EEG) have been proved to be effective in the field of depression recognition, however, the application of EEG-based mild depression detection is still in its infancy. Our work mainly focused on mild depression recognition of college students, based on high-density 128-channel EEG recordings from 24 mild depression individuals and 24 normal subjects using facial expression as experimental materials. In order to prevent individual performance differences on the convolution kernel, and to integrate time information and spatial information instead of simply combining, we proposed a new deep learning model with multiple convolution kernels and a Long Short-Term Memory (LSTM) strategy based on convolution. Batch normalization has been widely used and proved to be effective in some research areas, for example computer vision. Our findings show that for EEG data, batch normalization will reduce the accuracy due to the special data characteristics of EEG. It was found that the proposed model achieved an accuracy of 83.47% with the 8-fold cross-validation, and Batch Normalization will reduce the accuracy because it eliminated the difference between depression and normal. Our findings cast a new light to recognize mild depression accurately and quickly, it could be used as auxiliary tools to diagnose and predict mild depression in the future.","EEG,mild depression,CNN,LSTM,classification",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"FUNCTIONAL,CONNECTIVITY,UNIVERSITY-STUDENTS,PREVALENCE,SYMPTOMS",,,
51,Prediction of LncRNA-Disease Associations Based on Network Representation Learning,,,1805-1812,"Su Xiaorui,You Zhuhong,Yi Haicheng","Su XR,You ZH,Yi HC",Su XR,10.1109/BIBM49941.2020.9313139,Chinese Academy of Sciences,"Massive observations have indicated that long non-coding RNAs (lncRNAs) are crucial in a number of biological processes and associated with various human diseases. Developing an efficient calculation model to predict the associations between lncRNA and diseases is not only beneficial to disease diagnosis, treatment, prognosis and potential drug targets in drug discovery, but also avoid the waste of human and material resources brought by biological experiments. In this paper, we proposed a novel prediction of lncRNA-disease associations based on complex and comprehensive molecular associations network (MAN), which integrated nine kinds of interactions among five molecules, including lncRNA, miRNA, disease, drug and protein. Network embedding Node2vec method was applied to extract behavior feature from MAN to generate a low-dimension vector containing nodes and edges information. After implementing 5-fold cross validation, the proposed method yielded good prediction performance with an average Accuracy of 91.91%, Sensitivity of 94.05%, Specificity of 89.76%, Precision of 90.21%, MCC value of 83.91%, AUC value of 0.9746 and AUPR of 0.9693. Comparative experiment indicates the behavior feature extracted by Node2vec is more representative than attribute features of lncRNA adopted 3-mer and diseases extracted by semantic similarity. Moreover, breast cancer, colon cancer and lung cancer are explored in case study. As a results, more than half of top 5 interactions are successfully confirmed for each disease by other datasets. Based on these reliable results, it is anticipated that proposed model is feasible and effective to predict lncRNA-disease associations at a global molecules level, which is a new respective for future biomedical researches.","LncRNAs,Disease,Network Representation Learning,Node2vec,Molecular Associations Network",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"LONG,NONCODING,RNAS,BREAST-CANCER,HUMAN,GENOME,GENE,IDENTIFICATION,DATABASE,ANNOTATION,EXPRESSION,RESOURCE,GENCODE",,,
52,iVAE: An Improved Deep Learning Structure for EEG Signal Characterization and Reconstruction,,,1909-1913,"Chen Zheng,Ono Naoaki,Altaf-Ul-Amin Md,Kanaya Shigehiko,Huang Ming","Chen Z,Ono N,Altaf-Ul-Amin M,Kanaya S,Huang M",Chen Z,10.1109/BIBM49941.2020.9313107,Nara Institute of Science & Technology,"Due to the inherent variability such as inter-users anatomical variability and the inter-systems differences, the design of new EEG-based index and a reliable model for sleep stages classification is still the main topic in sleep science. The unsupervised deep learning framework-variational autoencoder (VAE) which can capture the major characteristics of the input by imposing a Gaussian prior distribution on the latent features is suitable in EEG characterization and reconstruction. Although vanilla VAE and convolutional autoencoder (CAE) have been tried, it has yet been discussed that whether a deep structure or a multi-scale structure is more appropriate. In this paper, we constructed a shallow iVAE model, which will capture the multi-scale features of the spectrogram of EEG by replacing the main structure in encoder and decoder with the inception-like structure. By comparing with the vanilla VAE and the CAE, a more accurate reconstruction and a better classification using the latent features of the iVAE can be confirmed.","EEG,spectrogram,VAE,Inception",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,REM-SLEEP,,,
53,Explanatory Analysis of a Machine Learning Model to Identify Hypertrophic Cardiomyopathy Patients from EHR Using Diagnostic Codes,,,1932-1937,"Farahani Nasibeh Zanjirani,Sundaram Divaakar Siva Baala,Enayati Moein,Arunachalam Shivaram Poigai,Pasupathy Kalyan,Arruda-Olson Adelaide M.","Farahani NZ,Sundaram DSB,Enayati M,Arunachalam SP,Pasupathy K,Arruda-Olson AM",Farahani NZ,10.1109/BIBM49941.2020.9313231,Mayo Clinic,"Hypertrophic cardiomyopathy (HCM) is a genetic heart disease that is the leading cause of sudden cardiac death (SCD) in young adults. Despite the well-known risk factors and existing clinical practice guidelines, HCM patients are underdiagnosed and sub-optimally managed. Developing machine learning models on electronic health record (EHR) data can help in better diagnosis of HCM and thus improve hundreds of patient lives. Automated phenotyping using HCM billing codes has received limited attention in the literature with a small number of prior publications. In this paper, we propose a novel predictive model that helps physicians in making diagnostic decisions, by means of information learned from historical data of similar patients.
We assembled a cohort of 11,562 patients with known or suspected HCM who have visited Mayo Clinic between the years 1995 to 2019. All existing billing codes of these patients were extracted from the EHR data warehouse. Target ground truth labeling for training the machine learning model was provided by confirmed HCM diagnosis using the gold standard imaging tests for HCM diagnosis echocardiography (echo), or cardiac magnetic resonance (CMR) imaging. As the result, patients were labeled into three categories of ""yes definite HCM"", ""no HCM phenotype"", and ""possible HCM"" after a manual review of medical records and imaging tests.
In this study, a random forest was adopted to investigate the predictive performance of billing codes for the identification of HCM patients due to its practical application and expected accuracy in a wide range of use cases. Our model performed well in finding patients with ""yes definite"", ""possible"" and ""no"" HCM with an accuracy of 71%, weighted recall of 70%, the precision of 75%, and weighted F1 score of 72%. Furthermore, we provided visualizations based on multi-dimensional scaling and the principal component analysis to provide insights for clinicians' interpretation. This model can be used for the identification of HCM patients using their EHR data, and help clinicians in their diagnosis decision making.","hypertrophic cardiomyopathy (HCM),billing code,machine learning,electronic health records (EHR),diagnostic codes,random forest,decision making,classification",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"TASK-FORCE,MANAGEMENT",,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8313105,
54,"A Framework for Analysis, Ontological Evaluation, and Visualization in Preparation to Predictive Analytics in Pediatric Brain Tumor Research",,,1943-1950,"Felmeister Alex S.,Waanders Angela J.,Mason Jennifer L.,Stevens Jeff,Bailey L. Charles,Ganesan Shiva,Helbig Ingo","Felmeister AS,Waanders AJ,Mason JL,Stevens J,Bailey LC,Ganesan S,Helbig I",Felmeister AS,10.1109/BIBM49941.2020.9313388,University of Pennsylvania,"We provide a generalizable framework for the systematic analysis of complicated, longitudinal clinical features in pediatric cancer. We use a threefold pipeline of exploratory data analysis, ontological categorization through a multi-modal data transformation process towards predictive analytics. We derive a data-driven phenotype from a subset of a sample of over 1900 brain tumor cases focused specifically on High-Grade Gliomas. We implement an analyst-friendly process to make machine learning-ready data sets based on domain ontologies ready for enumeration and vectorization. The results are clinical domain expert readable data points from 4.3 million observational events across 16,000 patient days. In this research, we address the gap in phenotypic data features by utilizing extensive harmonized observational clinical data and identify resources and specific processes for their use in rare tumor research.","data-driven phenotype,rare disease,biomedical research,biospecimen banking,electronic medical records",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"HEALTH,TRANSFORMATIONS,INFORMATICS,PEDSNET,KEY",,,
55,Predicting Neural Deterioration in Patients with Alzheimer's Disease Using a Convolutional Neural Network,,,1951-1958,"Tavakoli Maryam H.,Xie Tianyi,Shi Jingyi,Hadzikadic Mirsad,Ge Yaorong","Tavakoli HM,Xie TY,Shi JY,Hadzikadic M,Ge YR",Tavakoli HM,10.1109/BIBM49941.2020.9313561,University of North Carolina,"Alzheimer's disease causes neural damage, including brain atrophy in the patient. Consequently, ventricles that contain cerebral fluid a re expanded to filling those regions, which increases the proportional volume of ventricles in the brain. Therefore, abnormal growth of ventricle volume is an important indicator for estimating neural damage and, in turn, for the progression of Alzheimer's diseases. The rate of this volume-growth, i.e., neural damage, can be predicted by predictive and machine learning models using the patient's current status. These predictions help assess the effectiveness of a particular treatment for a patient, in addition to providing some expectation of the disease timeline.
In this work, we propose a convolutional neural network (CNN) model using region-level features for predicting ventricle volume biomarkers. The region-level representation with domain-driven features benefits from the CNN spatial pattern recognition capability. It also prevents learning irrelevant features and overfitting to the training data as a result of data scarcity. Our model is applied to the ADNI dataset in the TADPOLE competition and outperforms the best leaderboard results.","deep learning,Alzheimer's disease,disease progression model,convolutional neural network,small data",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,DIAGNOSIS,,,
56,A Comparison of Pre-trained Vision-and-Language Models for Multimodal Representation Learning across Medical Images and Reports,,,1999-2004,"Li Yikuan,Wang Hanyin,Luo Yuan","Li YK,Wang HY,Luo Y",Luo Y,10.11109/BIBM49941.2020.9313289,Northwestern University,"Joint image-text embedding extracted from medical images and associated contextual reports is the bedrock for most biomedical vision-and-language (V+L) tasks, including medical visual question answering, clinical image-text retrieval, clinical report auto-generation. In this study, we adopt four pre-trained V+L models: LXMERT, VisualBERT, UNIER and PixelBERT to learn multimodal representation from MIMIC-CXR images and associated reports. External evaluation using the OpenI dataset shows that the joint embedding learned by pre-trained V+L models demonstrates performance improvement of 1.4% in thoracic finding classification tasks compared to a pioneering CNN+RNN model. Ablation studies are conducted to further analyze the contribution of certain model components and validate the advantage of joint embedding over text-only embedding. Attention maps are also visualized to illustrate the attention mechanism of V+L models.","Vision-and-Language,Multi-modal Representation Learning,Thoracic Findings Classification",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
57,Prediction of patients with heart failure after myocardial infarction,,,2009-2014,"Liang Po-Yu,Wang Lee-Jyi,Wu Yang-Sheng,Pai Tun-Wen,Wang Chao-Hung,Liu Min-Hui","Liang PY,Wang LJ,Wu YS,Pai TW,Wang CH,Liu MH",Liang PY,10.1109/BIBM49941.2020.9313253,National Taipei University of Technology,"Heart failure is one of the most common causes of death for all different racial groups all over the world. It is noticed that a high proportion of patients diagnosed with heart failure (HF) within a short period of time after suffering from myocardial infarction (MI). This study is designed to translate existing real world data to real world evidence by exploring associations between historical comorbidities and heart failure diseases. Machine learning technologies were applied to predict whether patients with myocardial infarction would develop heart failure within a specific time period, and to remind patients how to strengthen personal self-care to avoid the transition towards heart failure or postpone the occurrence of the preceding events. In this study, patients with heart failure after myocardial infarction were divided into two groups according to a median age of 71 years old, and corresponding prediction models were constructed for two different age groups respectively. Three different machine learning technologies, namely logistic regression, random forest, and XGBoost were used to construct prediction models and a 5-fold cross-validation was applied to evaluate prediction accuracy and stability of prediction models. The results of our proposed method reveal that if a prediction model was constructed without age stratification, the constructed prediction model provided inferior performance compared to stratified groups by employing identical features. The analytical results from three different machine learning techniques consistently supported that the prediction models of myocardial infarction resulted in accelerated transition towards heart failure within a specific interval should be constructed by stratifying age groups first, and then training the corresponding data for better system performance.","National Health Insurance Research Database (NHIRD),ischemic heart disease,myocardial infarction,heart failure",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
58,Quantification of Brain Lesions in Multiple Sclerosis Patients using Segmentation by Convolutional Neural Networks,,,2045-2048,"de Oliveira Marcela,Santinelli Felipe Balistieri,Piacenti-Silva Marina,Gomes Rocha Fernando Coronetti,Barbieri Fabio Augusto,Lisboa-Filho Paulo Noronha,Santos Jorge Manuel,Cardoso Jaime dos Santos","de Oliveira M,Santinelli FB,Piacenti-Silva M,Rocha FCG,Barbieri FA,Lisboa PN,Santos JM,Cardoso JD",de Oliveira M,10.1109/BIBM49941.2020.9313244,Universidade Estadual Paulista,"Magnetic resonance imaging (MRI) is the most commonly used exam for diagnosis and follow-up of neurodegenerative diseases, such as multiple sclerosis (MS). MS is a neuroinflammatory and neurodegenerative disease characterized by demyelination of neuron axon. This demyelination process causes lesions in white matter that can be observed in vivo by MRI. Such lesions may provide quantitative assessments of the inflammatory activity of the disease. Quantitative measures based on various features of lesions have been shown to be useful in clinical trials for evaluating therapies. Although manual segmentations are considered as the gold standard, this process is time consuming and error prone. Therefore, automated lesion identification and quantification of the MRI are active areas in MS research. The purpose of this study was to perform the brain lesions volumetric quantification in MS patients, after segmentation via a convolutional neural network (CNN) model. Initially, MRI was rigidly registered, skullstripped and bias corrected. After, we use the CNN for brain lesions segmentation, which used training data to identify lesions within new test subjects. Finally, volume quantification was performed with a count of segmented voxels and represented by mm(3). We did not observe a statistical difference between the volume of brain lesion automatically identified and the volume manually segmented. The use of deep learning techniques in health is constantly developing. We observed that the use of these computational method for segmentation and quantification of brain lesions can be applied to aid in diagnosis and follow-up of MS.","brain lesions quantification,CNN,MRI,multiple sclerosis",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"AUTOMATIC,SEGMENTATION,MRI,VOLUMETRY,DIAGNOSIS,IMAGES",,,
59,"Diet, Weight loss, Fitness, and Health related Image Sharing using Twitter: an Observation Study",,,2049-2053,"Park Albert,Li Chuqin,Bowling Jessamyn,Ge Yaorong,Dulin Michael","Park A,Li CQ,Bowling J,Ge YR,Dulin M",Park A,10.1109/BIBM49941.2020.9313194,University of North Carolina,"Over 1.1 million tweets were collected using the four hashtags (#health, #fitness, #diet, #weightloss) from August 2018 to January 2019 for the purpose of understanding obesity-related image sharing practice in Twitter. Of these tweets, more than 200,000 (17.76%) had images, which were shared by more than 60,000 unique twitter users (22.13%). Over 130,000 unique images were computationally processed by applying a very deep VGG16 model (convolutional neural network) and 967 unique labels were used to describe objects within the images extracted from obesity related tweets. Informational content was most frequently re-shared, followed by images of individuals posing, comical content, commercial content, physical activities, and motivational quotes. Although a general deep learning model provided high level insights into the image sharing activity on Twitter, manual analysis revealed that a tailored model is needed to learn detailed information.","Obesity,image analysis,consumer health information,informatics,information science,communications media",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
60,EEG Based Depression Recognition by Combining Functional Brain Network and Traditional Biomarkers,,,2074-2081,"Sun Shuting,Chen Huayu,Shao Xuexiao,Liu Liangliang,Li Xiaowei,Hu Bin","Sun ST,Chen HY,Shao XX,Liu LL,Li XW,Hu B",Li XW; Hu B,10.1109/BIBM49941.2020.9313270,Lanzhou University,"This Electroencephalography (EEG)-based research is to explore the effective biomarkers for depression recognition. Resting-state EEG data were collected from 24 major depressive patients (MDD) and 29 normal controls using 128-electrode geodesic sensor net. To better identify depression, we extracted multi-type of EEG features including linear features (L), nonlinear features (NL), functional connectivity features phase lagging index (PLI) and network measures (NM) to comprehensively characterize the EEG signals in patients with MDD. And machine learning algorithms and statistical analysis were used to evaluate the EEG features. Combined multi-types features (All: L + NL + PLI + NM) outperformed single-type features for classifying depression. Analyzing the optimal features set we found that compared to other type features, PLI occupied the largest proportion of which functional connections in intra-hemisphere were much more than that of in inter-hemisphere. In addition, when using PLI features and All features, high frequency bands (alpha, beta) could achieve obviously higher classification accuracy than low frequency bands (delta, theta). Parietal-occipital lobe in the high frequency bands had great effect in depression identification. In conclusion, combined multi-types EEG features along with a robust classifier can better distinguish depressive patients from normal controls. And intra-hemispheric functional connections might be an effective biomarker to detect depression. Hence, this paper may provide objective and potential electrophysiological characteristics in depression recognition.","Depression recognition,EEG,Biomarker,Functional brain network",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"GRAPH-THEORETICAL,ANALYSIS,CLASSIFYING,DEPRESSION,FEATURE-SELECTION,MAJOR,DEPRESSION,ALPHA,ASYMMETRY,CHANNEL,EEG,CONNECTIVITY,DISORDERS,POWER",,,
61,3D Texture Feature-Based Lymph Node Automated Detection in Head and Neck Cancer Analysis,,,2113-2119,"Wang Yibin,Zamiela Christian,Thomas Toms V,Duggar William N.,Roberts P. Russell,Bian Linkan,Wang Haifeng","Wang YB,Zamiela C,Thomas TV,Duggar WN,Roberts PR,Bian LK,Wang HF",Wang HF,10.1109/BIBM49941.2020.9313482,Mississippi State University,"Lymph node extracapsular extension (ECE) is a decisive indication for treatment planning of patients with head and neck squamous cell carcinoma (HNSCC). Lymph node region identification and segmentation is crucial for computer-aided ECE diagnosis. In this research, we propose a systematic machine learning approach to detect lymph node region from computed tomography (CT) scans based on 3D texture features. The process includes three steps: 1) region of interests (ROI) segmentation, where the potential lymph node region is segmented based on morphological operation; 2) 3D Haralick texture features are collected for lymph node and non-lymph node samples, respectively; and 3) three machine learning models with feature extraction and selection approaches are employed for lymph node classification. Based on 5-fold cross-validation, the experimental results have demonstrated that gradient boosting model with feature agglomeration and low variance threshold achieves the test accuracy of 94.48%. To check the explainability of the models, feature analysis is also conducted. The outcome of this research is expected to promote the implementation of artificial intelligence for lymph node detection as well as head and neck cancer diagnosis in the radiology computer vision field.","Head and neck cancer,lymph node detection,3D texture features,machine learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
62,CSABlock-based Cascade RCNN for Breast Mass Detection in Mammogram,,,2120-2124,"Xiao He,Wang Qingfeng,Liu Zhiqin,Huang Jun,Zhou Yuwei,Zhou Ying,Xu Weiyun","Xiao H,Wang QF,Liu ZQ,Huang J,Zhou YW,Zhou Y,Xu WY",Liu ZQ,10.1109/BIBM49941.2020.9313473,Southwest University of Science & Technology - China,"Early screening and diagnosis of breast mass are essential for the prevention of breast cancer. There are some reasons to make mass detection be difficult and challenging. First, the resolution of mammography is very large and mass tissues are often subtle. Second, some mass overlap with the normal tissues which own similar texture. In this paper, we propose a novel attention module channel self-attention block (CSABlock), it can make better use of inter-layer features and strengthen the detection capability of the cascade R-CNN model. In order to further improve the detection quality, we also use a new domain-adaptive pre-training strategy. Experiments show that the proposed method achieves an average precision (AP) of 0.822 and average recall (AR) of 0.949, outperforms the state-of-the-art methods.","Mammography,Attention mechanism,Breast mass,Transfer learning,Computer-aided diagnosis",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
63,ST-MetaDiagnosis: Meta learning with Spatial Transform for rare skin disease Diagnosis,,,2153-2160,"Zhang Delong,Jin Mengqun,Cao Peng","Zhang DL,Jin MQ,Cao P",Cao P,10.1109/BIBM49941.2020.9313372,Northeastern University - China,"Skin conditions affect 1.9 billion people. Because of a shortage of dermatologists, most cases are seen instead by general practitioners with lower diagnostic accuracy. Current skin disease researches adopt the auto-classification system for improving the accuracy rate of skin disease classification. It is therefore an important task to develop Computer Aided Detection (CAD) systems that can aid/enhance dermatologists workflow and improve the classification performances. However, the long-tailed class distribution in the database and the limitation of ability to achieve a spatially invariant features make this problem challenging. We propose a ST-MetaDiagnosis, which utilizes meta-learning and spatial transform learning to facilitate quick adaptation and generalization of deep neural networks trained on the common diseases data for identification of rare diseases with much less annotated data. In particular, in order to predict the target risk where there are limited data samples, we train a meta-learner with spatial transforming from a set of related risk prediction tasks which learns how a good predictor is learned. The meta-learned can be directly used in target risk prediction, and the limited available samples can be used for further fine-tuning the model performance. Experiments on the recent ISIC 2018 skin lesion classification dataset show that our ST-MetaDiagnosis obtains 64.6% (accuracy) and 64.4% (F1-score) on the diagnosis of actinic keratosis, vascular lesion and dermatofibroma, demonstrating that ST-MetaDiagnosis can improve performance for predicting target risk with low resources comparing with the predictor trained on the limited samples available for this risk.","few-shot learning,skin disease,computer aided diagnosis,meta learning,spatial transforming",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
64,Classification of Cancer Types based on Gene Expression Data,,,2175-2182,"He Yinchao,Bockmon Ryan,Modey Miracle,Roscoe Sarah","He YC,Bockmon R,Modey M,Roscoe S",He YC,10.1109/BIBM49941.2020.9313559,University of Nebraska System,"With the rapid increase of genomic data, analyzing this huge bioinformatics data becomes a new challenge. Therefore, computer-based processes and algorithms are much more powerful to use. For analysis of across tumor types, John N Weinstein declares the uncertain feasibility of applying characterization based on molecular changes to complement pathological analysis for classification of cancers. Hence, for this limitation, we compared four deep learning methods, K-Means, Support Vector Machine, Formal Concept Analysis, and Association rules, to classify cancers based on the gene expression cancer RNA-Seq data set with 801 cases and 20531 genes for each case. The results show that SVM has the highest accuracy (99.8% and 99.2%) out of all our objectives, which is followed by K-Means with 91.75%. The third highest overall result (83.1%) is the Formal Concept Analysis algorithm. Association rules have the lowest accuracy with 72.25%. This comparison supplies a good guide for the classification of cancer types based RNA-seq.","Cancer,RNA-Seq gene expression,Molecular changes,Clustering,Classification,Association rules",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,DISCOVERY,,,
65,Automatic diagnosis of COVID-19 and pneumonia using FBD method,,,2257-2263,"Chaudhary Pradeep Kumar,Pachori Ram Bilas","Chaudhary PK,Pachori RB",Chaudhary PK,10.1109/BIBM49941.2020.9313252,Indian Institute of Technology System (IIT System),"Novel coronavirus (COVID-19) is spreading rapidly and has taken millions of lives worldwide. A medical study has shown that COVID-19 affects the lungs of patients and shows the symptoms of pneumonia. X-ray images with artificial intelligence (AI) can be useful for a fast and accurate diagnosis of COVID-19. It can also solve the problem of less testing kits and fewer doctors. In this paper, we have introduced the Fourier-Bessel series expansion-based dyadic decomposition (FBD) method for image decomposition. This FBD is used to decompose an X-ray image into subband images. Obtained subband images are then fed to ResNet50 pre-trained convolution neural network (CNN) individually. Deep features from each CNN are ensembled using operations, namely; maxima (max), minima (min), average (avg), and fusion (fus). Ensemble CNN features are then fed to the softmax classifier. In the study, a total of 750 X-ray images are collected. Out of 750 X-ray images, 250 images are of pneumonia patients, 250 of COVID-19 patients, and 250 healthy subjects. The proposed model has provided an overall accuracy of 98.6% using fus ensemble ResNet-50 CNN model.","Fourier-Bessel series expansion (FBSE),Image decomposition,Corona virus,Pneumonia,X-ray image",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,https://ieeexplore.ieee.org/ielx7/9312958/9312977/09313252.pdf,
66,Exploration of the Possibility of Early Diagnosis for Digestive Diseases Using Deep Learning Techniques,,,2343-2350,"Liao Rory,Qi Kevin,Che Daniel,Zeng Tingying Helen","Liao R,Qi K,Che D,Zeng TH",Zeng TH,10.1109/BIBM49941.2020.9313557,"Acad Adv Res & Dev, 14th Floor,One Broadway, Cambridge, MA 02142 USA.","Digestive Diseases are a commonality among Americans (almost one out of every five Americans are affected by digestive diseases). The most effective way of identifying such diseases is through Endoscopic Examinations. While patients normally have to wait for a long time to take high quality images from Endoscopic Examinations for diagnosis. This waiting period is problematic because some of these diseases can turn cancerous. This brings in the need for quick and accurate diagnosis of digestive diseases because the ability to identify diseases and the severity of the diseases vary from one doctor to another. This study analyzes the ability for our deep learning models to distinguish between the Z-Line, the Pylorus, the Cecum, Esophagitis, Ulcerative Colitis, Polyps, Dyed-Lifted Polyps and dyed resurrection margins. We developed a Convolutional Neural Network algorithm to distinguish between the anatomical landmarks to reach pathological findings. We also experimented with three transfer learning models to compare the final results, and ended up with 85 percent accuracy primarily with research optimization of the AlexNet type model. This indicates a significant impact of our artificial intelligence technology on making tremendous strides to be a tool that doctors may use in the near future, so as to improve the overall health of humanity.","Convolutional Neural Network,Endoscopic Examinations,Cancerous Transfer Learning,Digestive Diseases",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
67,Image-based early predictions of functional properties in cell manufacturing,,,2351-2356,"Lim Hong Seo,Smerchansky Madeline E.,Zhou Jingxuan,Chatterjee Paramita,Jimenez Angela C.,Yang Xingyu,Roy Krishnendu,Qiu Peng","Lim HS,Smerchansky ME,Zhou JX,Chatterjee P,Jimenez AC,Yang XY,Roy K,Qiu P",Lim HS,10.1109/BIBM49941.2020.9313297,University System of Georgia,"Effective cell manufacturing is essential to realizing the full potential of cell-based therapies but faces a multitude of challenges. One of the major challenges is the identification of critical quality attributes (CQAs), especially ones that enable early predictions of functional properties of the final products. The main goal of this study is to develop machine learning models for early predictions of the functional properties of mesenchymal stromal/stem cells(MSCs) in cell manufacturing. Deep learning models are trained and tested for image-based prediction of functional property-Collagen II expression after chondrogenic differentiation-of MSCs cells. During the MSC expansion, images of culturing wells were collected daily in the first six days, and the Collagen II level was assayed at the end of differentiation, following expansion. For each day, a deep learning model was trained with images from a specific experimental condition, and each model was tested with images from the same condition and also from other conditions. The trained neural network models showed 70-90 percent accuracy. Most of the models across different days and conditions show high consistency, especially models trained with images past day 2 of cell culture. Such consistency suggests that models are picking up similar features in predicting chondrogenesis capability. Our study highlighted the potential of deep neural network models used for early predictions of the functional properties of MSCs in cell manufacturing.","Cell-based therapies,Mesenchymal stromal/stem cells,Early prediction,Cell Manufacturing,Machine Learning,Deep Learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,DIFFERENTIATION,,,
68,LR-Net: A Multi-task Model Using Relationship-based Contour Information to Enhance the Semantic Segmentation of Cancer Regions,,,2371-2378,"Shi Baorong,Zhang Hong,Yan Rui,Jing Wang,Zang Jinfeng,Zhang Fa","Shi BR,Zhang H,Yan R,Jing W,Zang JF,Zhang F",Zhang F,10.1109/BIBM49941.2020.9313420,Chinese Academy of Sciences,"The segmentation of cancer regions is a key step in pathological image analysis. Although traditional methods (such as U-Net) have achieved good results in general medical image segmentation, the segmentation performance of the tumor region is still unsatisfactory because the boundary of the tumor is too blurred. Moreover, most tumor region segmentation methods focus on the learning of image content features while ignoring learning relationship among pixels on tumor contours. In this paper, we developed a multi-task learning technique to enhance the importance of contours and increase the weight of pixels relationship learning for the tumor segmentation. Different from the traditional single-decoder network, a parallel contour decoder with LRLM (location relationship learning module) is introduced as an auxiliary decoder to learn the relationship-based features of tumor contours, which forms a two-decoder network. To promote the information fusion of the two tasks, the two decoders share a same encoder with bidirectional skip connections between the auxiliary contour decoder and the main content decoder. Experimental results show that LR-Net is superior to many popular approaches, such as CE-Net and U-Net.","Pathological Image,Semantic Segmentation,Deep Learning,Pixel Relationship,Contour Decoder",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
69,Mut-Detecter : An EGFR activating mutation type classification method with a deep convolutional neural network,,,2386-2389,"Wang Yaojun,Hua Xinyu,Wang Yu,Zhang Chunming,Bu Dongbo,Sun Shiwei,Wang Xingce","Wang YJ,Hua XY,Wang Y,Zhang CM,Bu DB,Sun SW,Wang XC",Sun SW,10.1109/BIBM49941.2020.9313577,Chinese Academy of Sciences,"Epidermal growth factor receptor (EGFR) plays an essential role in tumor cell proliferation, angiogenesis and apoptosis inhibition; it is a crucial factor leading to cancer occurrence. For example, EGFR tyrosine kinase inhibitors in treating lung cancer patients have an excellent therapeutic effect. Targeted therapy based on EGFR gene mutation is one of the mainstream lung cancer treatment methods. Recent studies have shown that pulmonary nodules' characteristics are associated with the mutant status of EGFR, which provides the possibility of using CT images of patients with pulmonary nodules to predict the mutant status of EGFR. This study used the deep learning algorithm to establish the EGFR mutation type prediction model based on CT image recognition. The data sets used for model training and testing included 121 labeled CT images from hospital patients with pulmonary nodules. The research results showed that the model could be used for the non-invasive EGFR mutation type based on CT images.","mutation,computed tomography,lung nodules,convolutional neural network",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"LUNG,RADIOMICS,RECIST,IMAGES",,,
70,A General Endoscopic Image Enhancement Method Based on Pre-trained Generative Adversarial Networks,,,2403-2408,"Li Yating,Fan Jingfan,Ai Danni,Song Hong,Wang Yongtian,Yang Jian","Li YT,Fan JF,Ai DN,Song H,Wang YT,Yang J",Li YT,10.1109/BIBM49941.2020.9313443,Beijing Institute of Technology,"Endoscopic images frequently have image quality problems due to the limitations of surgical instruments and the impact of surgical operations, such as uneven illumination, smogginess and color deviation. For deep learning based on enhancement methods, independent training lacks sufficient defect images and generalization capability, and combined training with mixture of data cannot identify diverse specific tasks. To address these issues, we propose a general method based on pre-trained generative adversarial network with a specified transfer learning strategy to obtain high-quality images. Initially, we independently train a standard network based on a universal task, e.g., uneven illumination, where a pre-trained model is extracted as a backbone with partially shared generator. Then, we transfer the backbone to more potential image enhancement tasks. Experiments on uneven illumination, smogginess, and color deviation indicate that the model successfully shares common features of high-quality images and responds specifically to different defects as well.","Image enhancement,Endoscopic image,Transfer learning,Generative adversarial network",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
71,EEG Channel Interpolation Using Deep Encoder-decoder Networks,,,2432-2439,"Saba-Sadiya Sari,Alhanai Tuka,Liu Taosheng,Ghassemi Mohammad M.","Saba-Sadiya S,Alhanai T,Liu TS,Ghassemi MM",Saba-Sadiya S,10.1109/BIBM49941.2020.9312979,Michigan State University,"Electrode ""pop"" artifacts originate from the spontaneous loss of connectivity between a surface and an electrode. Electroencephalography (EEG) uses a dense array of electrodes, hence popped segments are among the most pervasive type of artifact seen during the collection of EEG data. In many cases, the continuity of EEG data is critical for downstream applications (e.g. brain machine interface) and requires that popped segments be accurately interpolated. In this paper we frame the interpolation problem as a self-learning task using a deep encoder-decoder network. We compare our approach against contemporary interpolation methods on a publicly available EEG data set. Our approach exhibited a minimum of similar to 15% improvement over contemporary approaches when tested on subjects and tasks not used during model training. We demonstrate how our model's performance can be enhanced further on novel subjects and tasks using transfer learning. All code and data associated with this study is open-source to enable ease of extension and practical use. To our knowledge, this work is the first solution to the EEG interpolation problem that uses deep learning.",SPHERICAL SPLINES,Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"SPHERICAL,SPLINES",,,
72,Detection of diabetic blindness with Deep-Learning,,,2440-2447,"Singh Anukriti,Kim Wooyoung","Singh A,Kim W",Singh A,10.1109/BIBM49941.2020.9313392,University of Washington,"Diabetes is one of the significant causes of blindness, especially among aged adults. As diabetes increases, the vision starts to deteriorate, which is called as diabetic retinopathy. The longer a person has diabetes and the less the blood sugar is controlled, the higher chance the person has diabetic retinopathy. 7.7 million people of age 40 or more have diabetic retinopathy. More than 90% of the cases causing vision loss can be avoided if detected early. Here, we use a deep-learning approach to automatically classify the fundus images into normal, mild, moderate, severe, and proliferative diabetic retinopathy. The dataset is collected from Aravind Eye Care System, and comprises of more than three thousand images. The images in the dataset are captured under diverse illumination conditions. We use a densely connected convolutional neural network architecture for the classification and detection of the severity level. Various pre-processing strategies are applied using OpenCV and Keras library to remove the noise from the image dataset. The model performs training for several epochs, and the hyperparameters are tuned to maximize the performance. Experimental results show that the model can successfully detect the severity of diabetic retinopathy.","Diabetic Retinopathy,Deep-Learning,Cohen's Kappa coefficient,Keras,OpenCV",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"NEURAL-NETWORKS,AGREEMENT,IMAGES,MODELS",,,
73,Accurate and adversarially robust classification of medical images and ECG time-series with gradient-free trained sign activation neural networks,,,2456-2460,"Yang Zhibo,Yang Yanan,Xue Yunzhe,Shih Frank Y.,Ady Justin,Roshan Usman","Yang ZB,Yang YA,Xue YZ,Shih FY,Ady J,Roshan U",Yang ZB,10.1109/BIBM49941.2020.9313442,New Jersey Institute of Technology,"Adversarial attacks in medical AI imaging systems can lead to misdiagnosis and insurance fraud as recently highlighted by Finlayson et. al. in Science 2019. They can also be carried out on widely used ECG time-series data as shown in Han et. al. in Nature Medicine 2020. At the heart of adversarial attacks are imperceptible distortions that are visually and statistically undetectable but cause the machine learning model to misclassify data. Recent empirical studies have shown that a gradient-free trained sign activation neural network ensemble model requires a larger distortion than state of the art models. We apply them on medical data in this study as a potential solution to detect and deter adversarial attacks. We show on chest X-ray and histopathology images, and on two ECG datasets that this model requires a greater distortion to be fooled than full-precision, binary, and convolutional neural networks, and random forests. We show that adversaries targeting the gradient-free sign networks are visually distinguishable from the original data and thus likely to be detected by human inspection. Since the sign network distortions are higher we expect an automated method could be developed to detect and deter attacks in advance. Our work here is a significant step towards safe and secure medical machine learning.","histopathology,X-ray,ECG,adversarial attack,robust classification,gradient-free trained sign activation neural networks",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
74,BioExpDNN: Bioinformatic Explainable Deep Neural Network,,,2461-2467,"Fang Hao,Shi Cheng,Chen Chi-Hua","Fang H,Shi C,Chen CH",Fang H,10.1109/BIBM49941.2020.9313113,Fuzhou University,"In recent years, machine learning is applied in the bioinformatics and medical fields to analyze relationships among biological features and behaviors. However, it is difficult to discover the significant features of large-scale datasets. A novel feature extraction method called bioinformatic explainable deep neural network (BioExpDNN) is proposed to filter the critical features with strong influences on the dataset and to explain the interaction of features. In the practical experiments, this study adopted three biomedical science datasets from the UCI (University of California, Irvine) Machine Learning Repository: (1). Cryotherapy Data Set (CDS) contains 6 attributes and 2 classes (i.e., recovery and non-recovery); (2). Cervical Cancer Behavior Risk Data Set (CCBRDS) consists of 18 attributes and 2 classes (i.e., cervical cancer patient and healthy body); (3). Heart Failure Clinical Records Data Set (HFCRDS) includes 12 clinical attributes and 2 classes (i.e., death and life). In comparison results, extracted features were considered as inputs of a classifier based on deep neural network for classification. The classification accuracy was selected as an evaluation factor to evaluate the performance of feature extraction methods. The experimental results showed that the classification accuracies of CDS, CCBRDS, and HFCRDS were 92.59%, 100%, and 78.9%, respectively.","bioinformatics explainable deep neural network,feature extraction,principal component analysis,Pearson correlation coefficient analysis",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"PRINCIPAL-COMPONENT-ANALYSIS,FEATURE-EXTRACTION,METHOD",,,
75,Analysis and Detection of Lung Sounds Anomalies Based on NMA-RNN,,,2498-2504,"Manzoor Arslan,Pan Qiao,Khan Hadiqa Jalil,Siddeeq Shahbaz,Bhatti Hafiz Muhammd Ali,Wedagu Mulubrhan Ayalew","Manzoor A,Pan Q,Khan HJ,Siddeeq S,Bhatti HMA,Wedagu MA",Manzoor A,10.1109/BIBM49941.2020.9313197,Donghua University,"Lung diseases are among the most widely recognized reasons for serious disease and passing around the world. The timely analysis is crucial to lessen the risk of any disease and if any disease is diagnosed, then precautions or medicines are immediately given. Therefore, for the diagnosis of lung sound auscultation, progressive computational tools are established and play a very vital role in the detection of disease-related anomalies. The aim of this study is the joint learning of the model that only extracts important breathing samples without generating redundant noise, and then uses this information to train lung sounds into four categories: normal, wheezes, crackles, and wheezes and crackles. This paper signified an unsupervised approach that depends on a Denoising Auto-Encoder (DAE). It utilizes the rebuild errors between the input and the output of the Auto-encoder as an activation audio signal to identify noisiness. A novel design of Recurrent Neural Network (RNN) called noise-masking anomalies recurrent neural network (NMA-RNN) for lung sound order is projected. ICBHI database used in this paper and some results of previous models were compared and achieved 95% accuracy.","Lungs Diseases,Unsupervised,Spectral Features,MFCC,DAE,BSLTM,ICBHI",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
76,Multimodal Lung Disease Classification using Deep Convolutional Neural Network,,,2530-2537,"Tariq Zeenat,Shah Sayed Khushal,Lee Yugyung","Tariq Z,Shah SK,Lee Y",Tariq Z,10.1109/BIBM49941.2020.9313208,University of Missouri System,"Lung disease is the most common cause of severe illness and death in the World. The early diagnosis and treatment of the disease are of great importance in the medical field. The computer-assisted systems for lung disease recognition are effective methods to help physicians diagnose the diseases effectively. Therefore, this paper studies the multimodal recognition of lung sound using spectrograms. Based on the classification of lung diseases by deep convolutional neural networks, an integrated network Multimodal Lung Disease Classification (MLDC) model was used with advanced pre-processing techniques to assess the classification accuracy acceptable in the medical field. The research has three main contributions. First, we have performed data pre-processing using two techniques Data Normalization and Data Augmentation. The data were normalized by removing the unwanted noise and adjusting the peak values in a sound signal.
For training purposes, the publicly available data was insufficient. Hence we applied advanced data augmentation techniques to generate some additional data without affecting the categories. Secondly, we have extracted the spectrograms from lung sound and used them as features and images for signal and image processing. Finally, we created an integrated model for the high-performance classification of lung diseases. We have compared the audio and spectrogram image-based results where we found the image-based approach is cost-effective, efficient, and reliable.","Spectrogram,Deep Learning,Image Classification,Audio Classification,Data Normalization,Data Augmentation,Convolutional Neural Network",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
77,Using nonlinear sparse Bayesian learning model to identify the correlation between multiple clinical cognitive scores and neuroimaging measurements,,,2548-2553,"Wu Jie,Hu Yibo,Fan Biyue,Chen Wei,Sun Deyan","Wu J,Hu YB,Fan BY,Chen W,Sun DY",Chen W,10.1109/BIBM49941.2020.9313366,China University of Mining & Technology,"Schizophrenia (SZ) is a complex human disease. It is a neurodegenerative disease characterized by the gradual loss of brain function, especially memory and cognitive ability. For many years, MRI has been widely used in schizophrenia studies because it can recognize structural and functional abnormalities in the brain region. In recent years, the most important research topic in the study of mental illness is to predict the cognitive performance of subjects from magnetic resonance imaging (MRI) measurements, and also include the recognition of related imaging biomarkers. Traditionally, this task has been a linear regression problem, but most existing studies cannot capture the relation-ship between the complex nonlinear cognitive properties and MRI measures. Inspired by these observations, we propose a Nonlinear Sparse Bayesian Learning (NSBL) model, and construct a sparse multivariate algorithm. Unlike the existing sparse algorithm, in our proposed model, the nonlinear function of the prediction matrix is responded by extending the block structure. The results show that the nonlinear sparse regression model can obtain better prediction ac-curacy. The model can use the correlation coefficient vector between vectors, it can also use the intra-block correlation in each regression coefficient.","Clinical cognitive scores,Schizophrenia,Neuroimaging measures,Sparse Bayesian learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
78,Predicting eye movement and fixation patterns on scenic images using Machine Learning for Children with Autism Spectrum Disorder,,,2563-2569,"Anden Raymond,Linstead Erik","Anden R,Linstead E",Anden R,10.1109/BIBM49941.2020.9313278,Chapman University System,"This study uses eye-tracking experiment data to predict the fixation points for children with Autism Spectrum Disorder (ASD) and Typically Developing (TD) for 14 ASD and 14 TD subjects for 300 scenic images [1]. Based on explanatory Logistic Regression models, it is evident that fixation patterns for both ASD and TD subjects focus on the center of each scenic image. Using gradient boosting the researchers successfully identify 31.7% and 39.5% of all fixation points in the top decile of predicted fixation points for ASD and TD subjects respectively. Results conclude that TD subjects have less variability in their eye movement and fixation points leading to increased accuracy in predicting where they will look.","Autism Spectrum Disorder,image recognition,Machine Learning,Random Forest,Gradient Boosting,Supervised Learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,https://digitalcommons.chapman.edu/cgi/viewcontent.cgi?article=1023&context=cads_dissertations,
79,Sequence-level Supervised Deep Neural Networks for Mitosis Event Detection in Time-Lapse Microscopy Images,,,2570-2571,"Chen Siteng,Li Ao,Roveda Janet","Chen ST,Li A,Roveda J",Chen ST,10.1109/BIBM49941.2020.9313500,University of Arizona,"Automatic mitosis detection is a key step in measuring cell proliferation and analyzing the responses to various stimuli. Current deep neural networks can learn complex visual features and capture long-range temporal dependencies. However, the state-of-the-art mitosis detection models require massive ground truth annotations which is labor intensive in biomedical experiments. Therefore, we propose a sequence-level supervised neural networks model to detect mitosis events at pixel-and-frame level. By using binary labels, the proposed network is trained to predict the presence of mitosis for the input microscopy sequences. Then we leverage the feature map produced by the proposed network to localize the cell division. The proposed model achieved a detection F1-score 0.881.With significantly less amount of ground truth in the training data, our method achieved competitive performance compared with the state-of-art fully supervised mitosis detection methods.","mitosis detection,weakly-supervise,microscopy imaging,convolutional long-short-term memory,deep learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
80,A Convolutional Gated Recurrent Neural Network for Seizure Onset Localization,,,2572-2576,"Daoud Hisham,Bayoumi Magdy","Daoud H,Bayoumi M",Daoud H,10.1109/BIBM49941.2020.9313480,University of Louisiana Lafayette,"The success of epileptic surgery highly depends on the accurate localization of the epileptic seizure. Seizure onset localization process is done using the intracranial Electroencephalogram (iEEG) recording which helps the physicians to determine the epileptogenic source in the brain. In this paper, we propose a supervised learning method based on a convolutional gated recurrent neural network to accurately analyze the non-stationary and nonlinear EEG signals. We study the effect of different hyperparameters like the number of convolutional layers and the number of kernels on the accuracy of such a difficult classification task. Discriminative spatio-temporal features are automatically extracted from the EEG signals by the convolutional neural network and the recurrent neural network. EEG feature extraction and classification applied to raw data are performed in a single automated system rather than extracting handcrafted features as in the previous work. High classification accuracy of 95.1% using ten-fold cross-validation testing strategy, makes the proposed method the most efficient among the state of the art.","EEG,seizure onset localization,classification,convolutional neural network,gated recurrent unit",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,IDENTIFICATION,,,
81,FOIT: Fast Online Instance Transfer for Improved EEG Emotion Recognition,,,2618-2625,"Li Jinpeng,Chen Hao,Cai Ting","Li JP,Chen H,Cai T",Li JP; Cai T,10.1109/BIBM49941.2020.9312984,Chinese Academy of Sciences,"The Electroencephalogram (EEG)-based emotion recognition is promising yet limited by the requirement of a large number of training data. Collecting substantial labeled samples in the training trials is the key to the generalization on the test trials. This process is time-consuming and laborious. In recent years, several studies have proposed various semi-supervised learning (e.g., active learning) and transfer learning (e.g., domain adaptation, style transfer mapping) methods to alleviate the requirement on training data. However, most of them are iterative methods, which need considerable training time and are unfeasible in practice. To tackle this problem, we present the Fast Online Instance Transfer (FOIT) for improved affective Brain-computer Interface (aBCI). FOIT selects auxiliary data from historical sessions and (or) other subjects heuristically, which are then combined with the training data for supervised training. The predictions on the test trials are made by an ensemble classifier. As a one-shot algorithm, FOIT avoids the time-consuming iterations. Experimental results show that FOIT brings significant improvement in accuracy for the three-category classification (1%-8%) on the SEED dataset and four-category classification (1%-14%) on the SEED-IV dataset in the cross-subject, cross-session and cross-all scenarios. The time cost over the baselines is moderate (similar to 35s on average for our machine). In contrast, to achieve comparative accuracies, the iterative methods require much more time (similar to 45s-similar to 900s). FOIT provides a simple, fast and practically feasible solution to improve the generalization of aBCIs and allows various choices of classifiers without constraints. Our codes are available online.","brain-computer interface,emotion recognition,transfer learning,instance transfer",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
82,Cross-Modality Medical Image Retrieval with Deep Features,,,2632-2639,"Mbilinyi Ashery,Schuldt Heiko","Mbilinyi A,Schuldt H",Mbilinyi A,10.1109/BIBM49941.2020.9313211,University of Basel,"In medical imaging, modality refers to the technique and process used to create visual representations of a particular part of the body, organs, or tissues. Conventional modalities include X-ray, CT-scan, Magnetic Resonance Imaging (MRI), Ultrasound, and Positron Emission Tomography (PET). Depending on the modality used, the same disease can be detected differently, making a modality an essential filter in evaluating the relevance of search results when retrieving similar medical images. Traditionally, texture features have been used for content-based medical image retrieval. However, texture features are limited in capturing the semantic similarity between medical images, let alone their modalities. This paper explores deep features (features extracted by deep convolutional neural networks (CNN)) and analyzes their effectiveness in retrieving similar medical images, semantic-wise and modality-wise, from a collection with different medical image modalities. We have examined CNNs of different architectures pre-trained in natural images and CNNs we fine-tuned and fully-trained from scratch in medical images to extract deep features. Based on retrieval performance evaluation, we show that deep features, even though extracted by CNN pre-trained in natural images, still outperform texture features. On the other end, we show that deep features extracted by a smaller, simpler, and yet computationally efficient CNN we trained in medical images can compete with large and complex ImageNet CNNs fine-tuned or fully trained in medical images.","Content-Based Medical Image Retrieval,Cross-Modality,Deep Features",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"PATTERN,SCALE",,,
83,Weakly Supervised Instance Segmentation of SEM Image via Synthetic Data,,,2672-2679,"Wang Yunfeng,Tang Xiaoqin,Fan Jingchuan,Xiao GuoQiang","Wang YF,Tang XQ,Fan JCA,Xiao GQ",Xiao GQ,10.1109/BIBM49941.2020.9312978,Southwest University - China,"Instance segmentation of scanning electron microscope images provides useful information for quantitative analysis of particle morphometry and distribution that contributes to various biomedical research such as the phenotyping of drug delivery systems. Compared to the conventional segmentation methodologies, the learning-based approaches stand out, benefiting from the prosperous development of artificial intelligence. However, most of the current learning-based segmentation methods require sufficient manually annotated training data, which is considered to be laborious. To alleviate this problem, we present a novel weakly supervised framework for instance segmentation on scanning electron microscope images. In the proposed framework, only one instance from each raw image is manually labeled to generate a synthesized dataset, which will be further used to select the training set. With the weakly annotated training dataset, the instance segmentation network is trained and applied to segment the particles of raw testing images. Based on our experimental results, the trained network gains 75% recall and 74% average precision on the tested images, which is seen as a reasonable performance considering the data complexity in our research. The overall experiments demonstrate that the proposed weakly supervised framework is able to provide an efficient solution to the instance segmentation of biomedical images.","instance segmentation,weakly supervised,SEM dataset,CNN",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
84,SE-ECGNet: A Multi-scale Deep Residual Network with Squeeze-and-Excitation Module for ECG Signal Classification,,,2685-2691,"Zhang Haozhen,Zhao Wei,Liu Shuang","Zhang HZ,Zhao W,Liu S",Liu S,10.1109/BIBM49941.2020.9313548,Tianjin University,"The classification of electrocardiogram (ECG) signals, which takes much time and suffers from a high rate of misjudgment, is recognized as an extremely challenging task for cardiologists. The major difficulty of the ECG signals classification is caused by the long-term sequence dependencies. Most existing approaches for ECG signal classification use Recurrent Neural Network models, e.g., LSTM and GRU, which are unable to extract accurate features for such long sequences. Other approaches utilize 1-Dimensional Convolutional Neural Network (CNN), such as ResNet or its variant, and they can not make good use of the multi-lead information from ECG signals. Based on the above observations, we develop a multi-scale deep residual network for the ECG signal classification task. We are the first to propose to treat the multi-lead signal as a 2-dimensional matrix and combines multi-scale 2-D convolution blocks with 1-D convolution blocks for feature extraction. Our proposed model achieves 99.2% F1-score in the MIT-BIH dataset and 89.4% F1-score in Alibaba dataset and outperforms the state-of-the-art performance by 2% and 3%, respectively, view related code and data at https://github.com/Amadeuszhao/SE-ECGNet","ECG signal classification,cardiovascular diseases,Convolutional Neural Network,Deep Learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"ARRHYTHMIA,DETECTION,SEQUENCE",,http://arxiv.org/pdf/2012.05510,
85,Multi-detection and Segmentation of Breast Lesions Based on Mask RCNN-FPN,,,2698-2704,"Bhatti Hafiz Muhammd Ali,Li Jiyun,Siddeeq Shahbaz,Rehman Abdul,Manzoor Arslan","Bhatti HMA,Li JY,Siddeeq S,Rehman A,Manzoor A",Li JY,10.1109/BIBM49941.2020.9313170,Donghua University,"The presence of different malicious regions on a single breast reveal some necessary information for breast cancer early detection. In current computer-aided diagnosis models, different lesions contained in a single mammogram are not detected and segmented individually. Therefore, the multi-detection and segmentation of the breast lesions can help the radiologists for an accurate diagnosis. This study aims to develop a model based on regional learning technique and RoI-based Convolutional neural network (CNN), which is known as Masked Regional Convolutional Neural Network embedded with Feature Pyramid Network. By using Mask RCNN-FPN, we can handle multi-detection, instance segmentation, and classification simultaneously. FPN extracts semantic features at different resolution scales and it can exhibit lesions at multiple scales. The training and testing of the model are performed on the DDSM and Inbreast respectively. In comparison, this model achieved mean average precision 0.84 for multi-detection and segmentation and 91% overall accuracy performance over SegNet and U-Net CNN encoder and decoder segmentation architecture.","convolutional neural network,mask RCNN,feature pyramid network,multi-detection,instance segmentation",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"COMPUTER-AIDED,DETECTION,MASSES,CLASSIFICATION,MAMMOGRAMS,ULTRASOUND",,,
86,"Selection of CNN, Haralick and Fractal Features Based on Evolutionary Algorithms for Classification of Histological Images",,,2709-2716,"Candelero David,Roberto Guilherme Freire,do Nascimento Marcelo Zanchetta,Rozendo Guilherme Botazzo,Neves Leandro Alves","Candelero D,Roberto GF,do Nascimento MZ,Rozendo GB,Neves LA",Candelero D,10.1109/BIBM49941.2020.9313328,Universidade Estadual Paulista,"The analysis of histological image features for automatic detection of pathologies plays an important role in medicine. Considering that, we proposed a method based on the association of features extracted by multiscale and multi-dimensional fractal techniques, Haralick descriptors, and CNN for pattern recognition of colorectal cancer, breast cancer, and non-Hodgkin lymphomas. For feature selection, we applied the ReliefF algorithm to rank the best 50 features and then applied the evolutionary algorithms GWO, PSO, and GA. The classification was made with SVM, K*, and Random Forest algorithms. This strategy allows classifying plenty of feature vectors selected by different algorithms, and consequently, improves the accuracy of the interpretations about the class distinction of histological images. The best combination found was composed of GA and K* algorithms, resulting in 91.06%, 90.52% e 82.01% accuracy for colorectal cancer, breast cancer, and non-Hodgkin lymphomas respectively. The performance obtained by the method indicates that the feature association extracted by different approaches and their subsequent selection and classification presents a potential field for further studies with a high degree of contribution to science.","histological images,feature selection,fractal geometry,Haralick descriptors,CNN",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"COLORECTAL-CANCER,PERCOLATION,BREAST",,,
87,Unsupervised Identification of SARS-CoV-2 Target Cell Groups via Nonlinear Dimensionality Reduction on Single-cell RNA-Seq Data,,,2737-2744,"Danda Saiteja,Vasighizaker Akram,Rueda Luis","Danda S,Vasighizaker A,Rueda L",Danda S,10.1109/BIBM49941.2020.9313378,University of Windsor,"Recent emergence of a new coronavirus, SARS-CoV-2, has caused the disease COVID-19 and has been declared a worldwide pandemic. Identification of relevant modules such as target cells is a significant step for characterizing diseases and consequently leads to better diagnosis, treatment and prognosis. High-throughput single-cell RNA-Seq (scRNA-seq) technologies have advanced in recent years, enabling researchers to investigate cells individually and understand their biological mechanisms. Computational techniques such as data clustering, which are categorized via unsupervised learning methods, are the more suitable for the pre-processing step in scRNA-seq data analysis. They can be used to identify a group of genes that belong to a specific cell type based on similar gene expression patterns. However, due to the sparsity and high-dimensional nature of this type of data, classical clustering methods are not efficient. Therefore, the use of nonlinear dimensionality reduction techniques to improve clustering results is crucial. In this work, we aim to find representative clusters of SARS-CoV-2 target cell lung by combining dimensionality reduction and clustering techniques. We first perform upstream analysis on data, including normalization and filtering using quality control metrics. We then assess the impact of different dimensionality reduction techniques on the clustering results. Our results show that modified Locally Linear Embedding combined with Independent Component Analysis have a very positive impact on clustering large-scale COVID-19 scRNA-seq data. To validate our findings, we identified target cell types involved in immune system functionality and a list of overlapping marker genes among COVID-19, Influenza A and HSV-1 infection.","non-linear dimensionality reduction,clustering,single-cell RNA sequencing,SARS-CoV-2 target cells,COVID-19",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,https://ieeexplore.ieee.org/ielx7/9312958/9312977/09313378.pdf,
88,An Effective and Automatic Method to Aid the Diagnosis of Amyotrophic Lateral Sclerosis Using One Minute of Gait Signal,,,2745-2751,"Felix Juliana Paula,Dantas do Nascimento Hugo Alexandre,Guimaraes Nilza Nascimento,Pires Eduardo Di Oliveira,Vieira Gabriel da Silva,Alencar Wanderley de Souza","Felix JP,do Nascimento HAD,Guimaraes NN,Pires ED,Vieira GD,Alencar WD",Felix JP,10.1109/BIBM49941.2020.9313308,Universidade Federal de Goias,"Amyotrophic Lateral Sclerosis (ALS) is a neurodegenerative disease that affects the nervous system responsible for muscle movement and eventually compromising one's ability to walk. Diagnosing ALS is a difficult task since no test can provide a definite diagnosis. In this sense, automatic methods that aid the diagnosis of ALS have an essential role in helping to reach a diagnose. However, most of the existing approaches that use gait dynamics are based on a 5-minute observation, which can be exhausting and demanding for a patient with ALS seeking the diagnosis. This paper proposes an automated method to aid the diagnosis of ALS using information obtained from one-minute gait observation. The Gait NDD database, which provides gait data recorded for 5 minutes from people with ALS and from healthy subjects, was used to support and validate this study. Results are reported and evaluated for different machine learning classifiers. Features extracted from either 1-min or 5-min observations are evaluated. Our results show that 96.6% of accuracy was achieved for data derived from either the first or the 5-minute walking, with excellent sensitivity and specificity, thus showing that our method can help aid the diagnosis of ALS while reducing the time required for the walking experiment.","Amyotrophic Lateral Sclerosis,Machine Learning,Gait,Diagnosis",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,DYNAMICS,,,
89,Depression severity prediction from facial expression based on the DRR_DepressionNet network,,,2757-2764,"Li Xiangguo,Guo Weitong,Yang Hongwu","Li XG,Guo WT,Yang HW",Yang HW,10.1109/BIBM49941.2020.9313597,Northwest Normal University - China,"Depression has become one of the serious mental health diseases in the world. The computer vision-based methods are expected to assist the clinical diagnosis of depression more efficiently and objectively, but the lack of clinical data and the low accuracy of recognition have hindered the broad application of automatic depression diagnosis. Given the shortcomings in predicting depression, this paper proposed a deep network based on the deep residual regression network to predict the severity of depression from facial expressions, named Deep Residual Regression Convolutional Neural Networks (DRR DepressionNet). We firstly enhanced the original facial images to expanse the training data. Then we use these training data, which carry different feature information, to train a deep regression residual network (ResNet). Unlike the traditional ResNet network, we divided the network into three major modules, namely C_M block, Resblock, and GAP. We also replaced the cross-entropy loss function in the traditional structure by the Euclidean loss function as the basis for training the network. Finally, we applied the trained network to predict the Beck Depression Inventory (BDI) score of new subjects to reflect the severity of depression. The experiments were validated on AVEC2013 and AVEC2014 depression data, respectively. The experimental results showed that compared with the state-of-the-art performance, the proposed method could improve the RMSE and MAE by 2.4% and 0.3% respectively on the AVCE2013 data set, and improve the RMSE and MAE by 0.3% and 1.1% respectively on AVCE2014 data set.","image enhancement,depression recognition,convolutional neural network,deep residual regression network",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
90,"Deep Learning for Automatic Tracking of Tongue Surface in Real-time Ultrasound Videos, Landmarks instead of Contours",,,2785-2792,"Mozaffari M. Hamed,Yamane Noriko,Lee Won-Sook","Mozaffari MH,Yamane N,Lee WS",Mozaffari MH,10.1109/BIBM49941.2020.9313262,University of Ottawa,"One usage of medical ultrasound imaging is to visualize and characterize human tongue shape and motion during a real-time speech to study healthy or impaired speech production. Due to the low-contrast characteristic and noisy nature of ultrasound images, it might require expertise for non-expert users to recognize tongue gestures in applications such as visual training of a second language. Moreover, quantitative analysis of tongue motion needs the tongue dorsum contour to be extracted, tracked, and visualized. Manual tongue contour extraction is a cumbersome, subjective, and error-prone task. Furthermore, it is not a feasible solution for real-time applications.
The growth of deep learning has been vigorously exploited in various computer vision tasks, including ultrasound tongue contour tracking. In the current methods, the process of tongue contour extraction comprises two steps of image segmentation and post-processing. This paper presents a new novel approach of automatic and real-time tongue contour tracking using deep neural networks. In the proposed method, instead of the two-step procedure, landmarks of the tongue surface are tracked. This novel idea enables researchers in this filed to benefits from available previously annotated databases to achieve high accuracy results. Our experiment disclosed the outstanding performances of the proposed technique in terms of generalization, performance, and accuracy.","TongueNet network,Deep learning,Landmark tracking for Tongue,Real-time object tracking,Convolutional Neural Networks,Ultrasound tongue contour extraction",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,http://arxiv.org/pdf/2003.08808,
91,Prediction of Patients Severity at Emergency Department Using NARX and Ensemble Learning,,,2793-2799,"Naemi Amin,Schmidt Thomas,Mansourvar Marjan,Wiil Uffe Kock","Naemi A,Schmidt T,Mansourvar M,Wiil UK",Naemi A,10.1109/BIBM49941.2020.9313462,University of Southern Denmark,"Early detection of adverse events at hospitals could be useful in terms of reducing costs, morbidity, and mortality. Therefore, in this paper, we present a personalized real-time hybrid model based on Nonlinear Autoregressive Exogenous (NARX) model and Ensemble Learning (EL) to predict patients' severity during hospitalization at Emergency Departments (ED). This model utilizes vital signs of patients, including Pulse Rate (PR), Respiratory Rate (RR), Arterial Blood Oxygen Saturation (SpO(2)) and Systolic Blood Pressure (SBP), which are collected automatically during the treatment to predict the illness severity of hospitalized patients at ED in the next hour based on their vital signs of the previous two hours. Two EL algorithms, including Random Forest (RF) and Adaptive Boosting (AdaBoost) are considered to build hybrid models. The performance of NARX-EL models is compared with Auto Regressive Integrated Moving Average (ARIMA), combination of NARX and Linear Regression (LR), Support Vector Regression (SVR) and K-Nearest Neighbors Regression (KNN). The results show that our proposed hybrid models can predict patients' severity with significantly higher accuracy. It is also found that NARX-RF has the best performance in the prediction of sudden changes and unexpected adverse events in patients' vital signs (R-2 score = 0.978, NRMSE = 6.16%).","Patient Severity,Machine Learning,Ensemble Learning,NARX,Time Series,Health Informatics",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"EARLY,WARNING,SCORE,REGRESSION",,https://findresearcher.sdu.dk:8443/ws/files/179482732/09313462.pdf,
92,Brain Functional Connectivity Pattern Recognition for Attention-deficit/hyperactivity Disorder Diagnosis,,,2806-2811,"Pirimy Harun,Fan Miaolin,Wang Haifeng","Pirimy H,Fan ML,Wang HF",Wang HF,10.1109/BIBM49941.2020.9313121,Mississippi State University,"This research proposes a descriptive network analysis approach to recognize brain functional connectivity patterns for Attention-deficit/hyperactivity Disorder (ADHD) Diagnosis. We apply network analysis to reveal changes at different time points and distinguish between ADHD and Contol states by constructing binary networks from correlation matrices. Network metrics are computed and compared across different time points. Based on our study, significant changes of the network features are observed after a certain time point. Density and median of triangles are the most distinguished features. In distinguishing ADHD and Control, the average shortest path distance and the average number of neighbors are the most significant features. We also tested the collected network metrics using machine learning models. Our results indicate that using network metrics can enhance the knowledge representation of brain functional connectivity and improve machine learning model performance.","Attention-deficit/hyperactivity disorder,network science,descriptive network analysis,connectivity pattern recognition",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"NETWORKS,FMRI,CHILDREN",,,
93,Segmentation of Oral Epithelial Dysplasias Employing Mask R-CNN and Color Normalization,,,2818-2824,"Silva Adriano B.,dos Santos Dali F. D.,Tosta Thaina A. A.,Martins Alessandro S.,Neves Leandro A.,Travenclo Bruno A. N.,de Faria Paulo R.,do Nascimento Marcelo Z.","Silva AB,dos Santos DFD,Tosta TAA,Martins AS,Neves LA,Travenclo BAN,de Faria PR,do Nascimento MZ",Silva AB,10.1109/BIBM49941.2020.9313101,Universidade Federal de Uberlandia,"Oral epithelial dysplasia is a common type of precancerous lesion that can be categorized as mild, moderate and severe. The manual diagnosis of this type of lesion is a time consuming and complex task. The use of digital systems applied to microscopic image analysis can aid the decision making of specialists. In recent years, deep learning-based methods are getting more attention due to its improved results in nuclei segmentation tasks. In this paper, we propose a methodology for nuclei segmentation on images of dysplastic tissues using neural networks. Several optimization algorithms and color normalization methods were evaluated. The methodology was performed on a dataset of mice tongue images. The experimental evaluations showed that the Nadam optimizer in combination with images without the use of color normalization obtained the best results. The method was able to segment the images with an average accuracy of 0.887, the sensitivity of 0.762 and specificity of 0.942. The algorithm was compared to other segmentation methods and showed relevant results. These values indicate that the proposed method can be used as a tool to aid specialists in the nuclei analysis of histological images of the buccal cavity.","Dysplasia,color normalization,convolutional neural network,nuclei segmentation",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
94,Joint Multiclass Classification of the subjects of Alzheimer's and Parkinson's Diseases through Neuroimaging Modalities and Convolutional Neural Networks,,,2840-2846,"Bin Tufail Ahsan,Ma Yong-Kui,Zhang Qiu-Na,Zhao Lei","Bin Tufail A,Ma YK,Zhang QN,Zhao L",Ma YK,10.1109/BIBM49941.2020.9313341,Harbin Institute of Technology,"Alzheimer's disease (AD) is the most widespread type of dementia defined by an accumulation of amyloid-beta proteins, the formation of tau plaques as well as the loss of neurons. On the other hand, Parkinson's disease (PD) is defined by the loss of dopaminergic neurons in the substantia nigra pars compacta within the midbrain. AD and PD are affecting millions of elderly people worldwide which highlights the need for their early diagnosis for the welfare of subjects diagnosed with these neurodegenerative disorders. A large number of autopsy confirmed PD subjects have sufficient postmortem plaque and tangle pathology to meet criteria for a second diagnosis of AD. Neuroimaging modalities such as Positron Emission Tomography (PET) and Single Photon Emission Computed Tomography (SPECT) are routinely used by clinicians to diagnose the initial stages of these two diseases. Together with these neuroimaging modalities, deep learning techniques are widely used in medical settings and have the potential to aid clinicians in the early diagnosis of these two diseases. In this work, we deployed a 3D Convolutional Neural Network (CNN) for joint feature extraction and multiclass classification of both AD and PD brain images in the spatial and frequency domains using PET and SPECT imaging modalities discriminating between AD, PD and Normal Control (NC) classes. We used Discrete Cosine Transform (DCT) as the frequency domain method and deployed random weak Gaussian blurring and random zooming in/out augmentation methods in both spatial and frequency domains. Based on our experiments and deployment of cross-validation approach for optimal hyperparameters selection, we found the performance of AD/NC(SPECT)/PD classification with random weak Gaussian blurred augmentation in the spatial domain to be the best and that of AD/NC(SPECT)/PD classification with combined augmentations in the frequency domain to be the worst while spatial domain methods outperformed their frequency domain counterparts.","Multiclass Classification,Convolutional Neural Networks,Alzheimer's Disease,Parkinson's Disease,Positron Emission Tomography,Single Photon Emission Computed Tomography",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"GLOBAL,PREVALENCE,DIAGNOSIS,DEMENTIA,PET",,,
95,Feature-level Fusion for Depression Recognition Based on fNIRS Data,,,2898-2905,"Zheng Shuzhen,Lei Chang,Wang Tao,Wu Chunyun,Sun Jieqiong,Peng Hong","Zheng SZ,Lei C,Wang T,Wu CY,Sun JQ,Peng H",Peng H,10.1109/BIBM49941.2020.9313364,Lanzhou University,"Tens of millions of people suffer from depression worldwide. It is urgent to explore an effective method for diagnosing depression. This study developed a novel of multi-modal feature fusion depression recognition method based on functional near-infrared spectroscopy (fNIRS). Sixty volunteers, including thirty patients with depression and thirty healthy controls, participated in the study. The 22-channel fNIRS device recorded the participants' brain oxyhemoglobin (HbO) and deoxyhemoglobin (HbR) concentration changes in the positive, neutral and negative affective words' stimulation. K-nearest neighbors (KNN) and support vector machine (SVM) classifiers were used to recognize depressed patients from normal people, and 10-fold cross-validation was used to verify the classification result. Under the three single-mode features, the accuracy rates were 85.69%, 88.32% and 86.77%, corresponding to the positive condition, neutral condition and negative condition. Then, we used concatenation and linear combination for feature fusion. For the concatenation fusion method, the principal component analysis (PCA) was used to reduce the dimension. The result showed that feature fusion can relatively improve the recognition rate of people with depression, compared with single-model features. The optimal feature fusion method is to concatenate the neutral features and negative features, and the best accuracy reaches 94.45%. The study may provide a more accurate and convenient method for depression detection.","depression,functional near-infrared spectroscopy (fNIRS),feature fusion,support vector machine (SVM),k-nearest neighbor (KNN)",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,DIAGNOSIS,,,
96,Recognition of Hyperparathyroidism based on Transfer Learning,,,2959-2961,"Chen Jiabo,Guo Qing,Jiang Zixun,Wang Huaqing,Yu Mingan,Wei Ying","Chen JB,Guo Q,Jiang ZX,Wang HQ,Yu MG,Wei Y",Wang HQ,10.1109/BIBM49941.2020.9313516,Beijing University of Chemical Technology,"Hyperparathyroidism (HPT) is a disorder in which the parathyroid glands produce too much parathyroid hormone (PTH), which may lead to hypocalcemic convulsions, cardiomyopathy, hypertension and other diseases, even threaten the lives of patients under certain severe conditions. Since HPT is usually multiple and ectopic with variable symptoms, the diagnosis and location of HPT is a difficult task even for senior radiologists. A transfer learning-based computer-aided diagnosis (CAD) approach is proposed for automated recognition of HPT in this paper. A dataset of the brightness-mode ultrasound images is developed for the HPT recognition, which is usually annotated by senior radiologists. We addressed the HPT recognition using the various computer vision algorithms on the HPT dataset and obtained good performances for all the algorithms. The experimental results demonstrated that the dataset is effective in aiding the diagnosis of HPT.","parathyroid,hyperparathyroidism,transfer learning,dataset,computer-aided diagnosis",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
97,Human ability enhancement for reading mammographic masses by a deep learning technique,,,2962-2964,"Homma Noriyasu,Noro Kyohei,Zhang Xiaoyong,Kon Yutaro,Ichiji Kei,Bukovsky Ivo,Sato Akiko,Mori Naoko","Homma N,Noro K,Zhang XY,Kon Y,Ichiji K,Bukovsky I,Sato A,Mori N",Homma N,10.1109/BIBM49941.2020.9313564,Tohoku University,"The usefulness of taking mammography has widely been recognized, but screening mammography occasionally results in an excessive recommendation for subsequent biopsy causing many women inconvenience and severe anxiety. Especially, there is a high chance of unnecessary biopsy recommendation for those findings which are difficult to be classified into malignancy and benignancy. However, few have focused on the computer-aided diagnosis (CAD) performance for such difficult cases. To address this problem, we developed a deep learning based classification technique to aid the difficult diagnosis. We evaluated 100 benign and malignant masses of the breast imaging-reporting and data system (BI-RADS) Category 4 that are generally difficult to be classified into malignant and benign. Five certificated doctors participated in the experiments where each doctor reads the 100 images alone first and a week later reads again with the proposed CAD system. The area under the receiver operating characteristic curve (AUC-ROC) for the CAD system was 0.79. This is greater than 0.65, the average value of the human readers' AUC-ROCs, while the average value of the human readers' AUC-ROCs reached the best value of 0.8 when they used the CAD system. These results suggest that the proposed CAD system is able to not only outperform human readers in classifying the masses, but also enhance the human performance in this difficult task.","computer aided diagnosis,breast cancer, and deep learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
98,Colorectal Cancer Image Segmentation and Classification with Deep Neural Network Based on Information Theory,,,2968-2970,"Kim Hwa-Rang,Kim Kwang-Ju,Lim Kil-Taek,Choi Doo-Hyun","Kim HR,Kim KJ,Lim KT,Choi DH",Kim HR,10.1109/BIBM49941.2020.9313157,Kyungpook National University,"Colorectal cancer (CRC) is the development of cancer from the colon or rectum. Microsatellite instability (MSI) status can be considered as an indicator to predict the prognosis of CRC. We employ MSI prediction of CRC image by designing a neural network model of which base network is DeepLabv3+ with OctaveResNet. Additionally, we add a channel sort module to divide a feature map along with channel intensity. Then each feature map goes through distinct convolution paths. Each convolution path is designed based on information theory: the most important feature goes through the lightest convolution path, vice versa. By dividing feature map and applying different amount of convolutional operation, the model can extract features efficiently. In the experiment, total model weight is reduced but accuracy increases.","CRC,MSI,DeepLabv3+,OctaveResNet,Information theory",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
99,The effect of blurring on lung cancer subtype classification accuracy of convolutional neural networks,,,2987-2989,"Nair Tejal,Pour Ali Foroughi,Chuang Jeffrey H.","Nair T,Pour AF,Chuang JH",Nair T,10.1109/BIBM49941.2020.9313192,"Jackson Lab Genom Med, Farmington, CT 06032 USA.","Deep learning models are extensively used for analyzing hematoxylin and eosin stained whole slide images. They enjoy high prediction accuracies, but may suffer large performance drops when applied to out-of-sample data. Here we systematically investigate how resolution differences between train and test sets may affect lung cancer subtype predictions from whole slide images using a transfer learning model based on the Inception V3 network. We observe models trained on blurred images perform well when applied to test sets with similar blurrings, but suffer poor predictions when applied to images with large blurring differences. In particular, we observed low area under curve values when models trained on blurred images were applied to non-blurred images.","deep learning,convolutional neural networks,digital pathology,image analysis",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
100,Additional Value of Augmenting Current Subscales in Braden Scale with Advanced Machine Learning Technique for Pressure Injury Risk Assessment,,,2993-2995,"Vyas Kathan,Samadani Ali,Milosevic Mladen,Ostadabbas Sarah,Parvaneh Samar","Vyas K,Samadani A,Milosevic M,Ostadabbas S,Parvaneh S",Vyas K,10.1109/BIBM49941.2020.9313401,"Philips Res North Amer, Cambridge, England.","Hospital-acquired pressure injuries (PI) are associated with longer hospital stays, pain, infection, and higher care costs. The traditional assessment techniques such as Braden scale, the most widely used PI risk assessment tool, lack predictive power. This study implements a machine learning algorithm using XGBoost and Braden subscales as its input features for PI risk assessment in intensive unit care (ICU) patients. We have evaluated our proposed PI risk assessment algorithm on a test dataset of 2,657 patients (PI prevalence equals to 17.57%) and have obtained 5.9% and 3.1% improvement in sensitivity and specificity respectively for our machine learning-based approach compared to the Braden scale.","Pressure Injury,Pressure Ulcer,Risk Assessment",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"CARE,ULCERS,UNIT",,,
