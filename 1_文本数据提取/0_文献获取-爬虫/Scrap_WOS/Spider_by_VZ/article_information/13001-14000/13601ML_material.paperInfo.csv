,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Optimization method of diffuse optical tomography reconstruction based on neural network,11553,,,"Cao Bin,Zhang Limin,Shi Ke,Zhao Zhichao,Sun Zhilong,Li Jiao,Zhou Zhongxing,Gao Feng","Cao B,Zhang LM,Shi K,Zhao ZC,Sun ZL,Li J,Zhou ZX,Gao F",Zhang LM,10.1117/12.2573994,Tianjin University,"Diffuse Optical Tomography (DOT) is a promising non-invasive optical imaging technology that can provide structural and functional information of biological tissues. Since the diffused light undergoes multiple scattering in biological tissues, and the boundary measurements are limited, the reverse problem of DOT is ill-posed and ill-conditioned. In order to overcome these limitations, two types of neural networks, back-propagation neural network (BPNN) and stacked autoencoder (SAE) were applied in DOT image reconstruction, which use the internal optical properties distribution and the boundary measurement of biological tissues as the input and output data sets respectively to adjust the neural network parameters, and directly establish a nonlinear mapping of the input and output. To verify the effectiveness of the methods, a series of numerical simulation experiments were conducted, and the experimental results were quantitatively assessed, which demonstrated that both methods can accurately predict the position and size of the inclusion, especially in the case of higher absorption contrast. As a whole, SAE can get better reconstructed image results than BPNN and the training time was only a quarter of BPNN.","diffuse optical tomography,back-propagation neural network,image reconstruction,stacked autoencoder",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Biochemistry & Molecular Biology,Engineering,Optics",,,"STATISTICAL-ANALYSIS,IMAGES",,,
2,Assessing structural features of tuberculosis using Mueller matrix derived parameters: a quantitative method to distinguish between Crohn's disease and gastrointestinal luminal tuberculosis,11553,,,"Chen Binguo,He Honghui,Zhu Hongyi,Shen Yuanxing,Ma Hui","Chen BG,He HH,Zhu HY,Shen YX,Ma H",He HH,10.1117/12.2575164,Tsinghua University,"Crohn's disease (CD) and gastrointestinal luminal tuberculosis (ITB) are two kinds of similar inflammatory bowel diseases, whose incidences are growing rapidly worldwide. Due to the lack of a general gold standard to distinguish between CD and ITB samples, misdiagnosis often occurs in clinical detections, leading to inappropriate treatments and side-effects. The characteristic features of both CD and ITB tissues include tuberculosis and surrounding fibrous structures, which can be quantitatively evaluated by polarimetric techniques. In this study, we apply the transmission Mueller matrix microscope developed in our previous study on the CD and ITB tissue samples to attain their 2D Mueller matrix images. We calculate the Mueller matrix polar decomposition and transformation parameters, which can provide information about the location, density and distribution behavior of the tuberculosis areas surrounded by fibrous structures. In order to evaluate the different distribution behaviors of the fibrous structures quantitatively, we analyzed the retardance related Mueller matrix derived parameters images, which show different features between the CD and ITB tissues, using the Tamura images processing method (TIPM). The preliminary results show that the TIPM analysis of the retardance related parameters can provide some quantitative parameters to describe the different textures of fibers in the CD and ITB tissues. Moreover, we use the machine learning method based on Mueller matrix derived parameters to distinguish between CD and ITB tissues. It is demonstrated that the Mueller matrix derived parameters combined with machine learning methods can be helpful for clinical diagnosis.","Mueller matrix,polarization imaging,biomedical diagnosis,pathology,inflammatory bowel diseases",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Biochemistry & Molecular Biology,Engineering,Optics",,,"TISSUES,MICROSTRUCTURES",,,
3,Quantitatively distinguishing typical pathological features between different breast tissues using polarimetry feature parameters,11553,,,"Dong Yang,Hou Anli,Wang Xingjian,Ma Hui","Dong Y,Hou AL,Wang XJ,Ma H",Ma H,10.1117/12.2575162,Tsinghua University,"Breast diseases with many distinct histopathological types are showing a rising trend in incidence for decades worldwide. The proliferation of cells and the remodeling of collagen fibers in breast carcinoma tissues may be used to predict breast disease diagnosis, prognosis of treatment, and patient survival. Pathologists can label related typical pathological features as cell nuclei, aligned collagen, and disorganized collagen in hematoxylin and eosin (H&E) sections of breast tissues. In this study, we apply the Mueller matrix microscopic imaging to various breast pathological section samples, and calculate corresponding polarimetry basis parameters (PBPs). A pixel-based extraction approach of polarimetry feature parameters (PFPs) is proposed using a mutual information (MI) method and a linear discriminant analysis (LDA) classifier. The three PFPs derived by the proposed learning algorithm are the simplified linear combinations of PBPs with physical meanings, and provide quantitative characterization of the three pathological features in different breast tissues respectively. We present results of the three PFPs of tissue samples from a cohort of 32 clinical patients diagnosed as normal, breast fibroma, breast ductal carcinoma in situ, invasive ductal carcinoma, and breast mucinous carcinoma with analysis of 210 regions-of-interest (ROI). The results demonstrate that the three PFPs of each breast disease tissue have specific value ranges, which has a potential to quantitatively distinguish typical pathological features between different breast tissues. This technique has good prospects for automation of the microstructure identification and prediction of breast disease diagnosis, resulting in the reduction of pathologists' workload.","Polarimetry feature parameters,MI,LDA classifier,quantitative diagnosis,breast pathological features",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Biochemistry & Molecular Biology,Engineering,Optics",,,"CANCEROUS,TISSUES",,,
4,Machine learning applications for spectral analysis of human exhaled breath for early diagnosis of diseases,11553,,,"Fufurin Igor L.,Golyak Igor S.,Anfimov Dmitriy R.,Tabalina Anastasiya S.,Kareva Elizaveta R.,Morozov Andrey N.,Demkin Pavel P.","Fufurin IL,Golyak IS,Anfimov DR,Tabalina AS,Kareva ER,Morozov AN,Demkin PP",Fufurin IL,10.1117/12.2584043,Bauman Moscow State Technical University,"In this work, the possibility of using machine learning in the spectral analysis of exhaled breath for early diagnosis of diseases is considered. Experimental setup consists of a quantum cascade laser with a tuning range of 5.4-12.8 mu m and Herriot astigmatic gas cell. A shallow convolutional neutral network and principal component analysis is used to identify biomarkers and its mixtures. A minimum detectable concentration for acetone and ethanol at sub-ppm level is obtained for optical path length up to 6 m and signal-to-noise less than 3. It is shown that neural networks in comparison with statistical methods give a lower detection limits for the same signal-to-noise ratio in the measured spectrum.","human breath analysis,quantum cascade laser,convolutional neural network,infrared spectroscopy,biomarker,machine learning,biomedical spectroscopy",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Biochemistry & Molecular Biology,Engineering,Optics",,,VAPOR,,,
5,Application of convolutional neural network in signal classification for in vivo photoacoustic flow cytometry,11553,,,"Song Ziran,Fu Yuting,Qu Jiaqi,Liu Qi,Wei Xunbin","Song ZR,Fu YT,Qu JQ,Liu Q,Wei XB",Wei XB,10.1117/12.2576784,Shanghai Jiao Tong University,"Melanoma is one of the most serious skin cancers in the world. As circulating tumor cells have been proved to be an important marker of early metastasis of cancer, the detection of circulating tumor cells of melanoma is of great significance for early diagnosis and the monitoring of tumor progression. In vivo photoacoustic flow cytometry (PAFC) is constructed to achieve real-time and non-invasive detection of circulating melanoma cells in vivo. However, as the photoacoustic signals acquired in the detection process are disturbed by various kinds of noise, it is difficult to accurately distinguish the photoacoustic signals of background and circulating tumor cells by the traditional triple mean square deviation method. Therefore, a photoacoustic signal classification method is proposed based on convolutional neural network, which can greatly improve the accuracy of detection. Features of signals are extracted by the convolutional neural network to distinguish photoacoustic signals of melanoma cells and background. We construct a convolutional neural network based on one-dimensional input signals. For training the classifier, a large number of samples are selected. The accuracy rate in the test set can reach 95%. Besides, a neural network is built based on VGG16 model and transfer learning, and the trained classifier can realize the accuracy of 98% in the test set. Experiments show that the method of photoacoustic signal classification based on convolutional neural network greatly improves the accuracy of signal classification, and realizes the rapid and accurate analysis of a large number of data.","melanoma,circulating tumor cells,in vivo photoacoustic flow cytometry,convolutional neural network,deep learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Biochemistry & Molecular Biology,Engineering,Optics",,,,,,
6,Classification of skin cancer based on fluorescence lifetime imaging and machine learning,11553,,,"Yang Qianqian,Qi Meijie,Wu Zhaoqing,Liu Lixin,Gao Peng,Qu Junle","Yang QQ,Qi MJ,Wu ZQ,Liu LX,Gao P,Qu JL",Liu LX,10.1117/12.2573851,Xidian University,"To evaluate the development stage of skin cancer accurately is very important for prompt treatment and clinical prognosis. In this paper, we used the FLIM system based on time-correlated single-photon counting (TCSPC) to acquire fluorescence lifetime images of skin tissues. In the cases of full sample data, three kinds of sample set partitioning methods, including bootstrapping method, hold-out method and K-fold cross-validation method, were used to divide the samples into calibration set and prediction set, respectively. Then the binary classification models for skin cancer were established based on random forest (RF), K-nearest neighbor (KNN), support vector machine (SVM) and linear discriminant analysis (LDA) respectively. The results showed that FLIM combining with appropriate machine learning algorithms can achieve early and advanced canceration classification of skin cancer, which could provide reference for the multi-classification, clinical staging and diagnosis of skin cancer.","skin cancer,fluorescence lifetime,machine learning,binary classification",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Biochemistry & Molecular Biology,Engineering,Optics",,,,,,
7,Integrating Machine Learning with HPC-driven Simulations for Enhanced Student Learning,,,25-34,"Jadhao Vikram,Kadupitiya J. C. S.","Jadhao V,Kadupitiya JCS",Jadhao V,10.1109/EduHPC51895.2020.00009,Indiana University System,"We explore the idea of integrating machine learning (ML) with high performance computing (HPC)-driven simulations to address challenges in using simulations to teach computational science and engineering courses. We demonstrate that a ML surrogate, designed using artificial neural networks, yields predictions in excellent agreement with explicit simulation, but at far less time and computing costs. We develop a web application on nanoHUB that supports both HPC-driven simulation and the ML surrogate methods to produce simulation outputs. This tool is used for both in-classroom instruction and for solving homework problems associated with two courses covering topics in the broad areas of computational materials science, modeling and simulation, and engineering applications of HPC-enabled simulations. The evaluation of the tool via in-classroom student feedback and surveys shows that the ML-enhanced tool provides a dynamic and responsive simulation environment that enhances student learning. The improvement in the interactivity with the simulation framework in terms of real-time engagement and anytime access enables students to develop intuition for the physical system behavior through rapid visualization of variations in output quantities with changes in inputs.","Machine Learning,HPC-driven Simulations,Computational Science,Scientific Computing",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Computer Science,Education & Educational Research",,,PARALLEL,,http://arxiv.org/pdf/2008.13518,
8,"Fusing of Deep Learning, Transfer Learning and GAN for Breast Cancer Histopathological Image Classification",1121,,255-266,"Mai Bui Huynh Thuy,Vinh Truong Hoang","Thuy MBH,Hoang VT",Hoang VT,10.1007/978-3-030-38364-0_23,"Ho Chi Minh City Open Univ, Fac Informat Technol, Ho Chi Minh City, Vietnam.","Biomedical image classification often deals with limited training sample due to the cost of labeling data. In this paper, we propose to combine deep learning, transfer learning and generative adversarial network to improve the classification performance. Fine-tuning on VGG16 and VGG19 network are used to extract the good discriminated cancer features from histopathological image before feeding into neuron network for classification. Experimental results show that the proposed approaches outperform the previous works in the state-of-the-art on breast cancer images dataset (BreaKHis).","Deep learning,Transfer learning,BreaKHis dataset,Breast cancer,Histopathological image classification,GAN",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Operations Research & Management Science,Mathematics",,,"DIAGNOSIS,NETWORKS",,,
9,WAVELET-BASED COUGH SIGNAL DECOMPOSITION FOR MULTIMODAL CLASSIFICATION,,,5-9,"Agbley Bless Lord Y.,Li Jianping,ul Haq Aminul,Cobbinah Bernard,Kulevome Delanyo,Agbefu Priscilla A.,Eleeza Bright","Agbley BLY,Li JP,ul Haq A,Cobbinah B,Kulevome D,Agbefu PA,Eleeza B",Agbley BLY,10.1109/ICCWAMTIP51612.2020.9317337,University of Electronic Science & Technology of China,"Signal classifications have benefited from the successes of ML and DNN architectures. Cough classification techniques mainly extract features such as the Mel Frequency Cepstral Coefficients for training. Most of these works also focus on obtaining information from single data modalities. However, multimodal analysis has been shown to aggregate useful information from different modalities thereby improving the internal capacity of ML models at data analysis. In this research, we propose a multimodal cough data classification approach with scalograms images obtained by decomposing cough signals using continuous wavelet transform and clinical information of subjects obtained from the COUGHVID dataset. Our result shows improved precision as compared to expert analysis.","Multimodal analysis,Wavelet transform,Deep learning,Transfer learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,https://ieeexplore.ieee.org/ielx7/9317007/9317311/09317337.pdf,
10,EFFICIENT TRANSFER LAERNING USED IN THE CLASSIFICATION OF GASTROSCOPIC IMAGES WITH SMALL DATASET,,,73-76,"Du Wenju,Rao Nini,Wang Yingchun,Hu Dingcan,Yong Jiaha","Du WJ,Rao NN,Wang YC,Hu DC,Yong JH",Du WJ,10.1109/ICCWAMTIP51612.2020.9317450,University of Electronic Science & Technology of China,"Deep learning (DL) has gained success in image classification. However, DL always needs a large number of labeled training data which are not usually available for gastroscopic image analysis. Therefore, the pre-trained convolutional neural networks (CNNs) models are important. The transfer learning (TL) method could leverage the pre-trained model in natural images to gastroscopic images. In this paper, we have studied different TL methods on small dataset of gastroscopic images. We have fine-tuned the current deep CNNs: EfficientNet, ResNet and DenseNet on three kinds of gastroscopic images from kvasirv2 dataset. The results demonstrated that the pre-trained models of current deep CNNs can get considerable classification results on gastroscopic images with small dataset.","Gastroscopic image,Classification,Deep learning,Transfer learning,Lesion",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
11,3DCNN: THREE-LAYERS DEEP CONVOLUTIONAL NEURAL NETWORK ARCHITECTURE FOR BREAST CANCER DETECTION USING CLINICAL IMAGE DATA,,,83-88,"Ul Haq Amin,Li Jian Ping,Saboor Abdus,Khan Jalaluddin,Zhou Wang,Jiang Tao,Rao Mordecai F.,Wali Samad","Ul Haq A,Li JP,Saboor A,Khan J,Zhou W,Jiang T,Rao MF,Wali S",Ul Haq A,10.1109/ICCWAMTIP51612.2020.9317312,University of Electronic Science & Technology of China,"The breast cancer is a critical female disease and its proper identification is very essential for better cure and recovery. The diagnosis of BC is a critical issue for clinical specialists and scholars. Different researchers proposed breast cancer diagnosis methods using deep learning techniques. However, these proposed methods not diagnosis breast cancer accurately. In order to tackle the issue of accurate detection of breast cancer we proposed a 3-layers CNN architecture for accurate detection of breast cancer. The proposed model has been trained and tested on Breast histology images data set. The cross validation method Hold out has been applied for best model selection and hyper parameters tuning. Furthermore, different model evaluation metrics have been used for model performance evaluation. The experimental results demonstrated that propped method is more suitable for breast cancer and it would be incorporated in health care successfully.","Breast cancer,Classification,Deep Learning,Convolutional neural network,Image data set,Prediction accuracy",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
12,EFFECT OF MAHA MRITYUNJAYA HYMN RECITATION ON HUMAN BRAIN FOR THE ANALYSIS OF SINGLE EEG CHANNEL C4-A1 USING MACHINE LEARNING CLASSIFIERS ON YOGA PRACTITIONER,,,89-92,"Rishipal,Bin Heyat Md Belal,You Zili,Pardhan Balaram,Akhtar Faijan,Abbas Syed Jafar,Guragai Bishal,Acharya Kadambini","Rishipal,Bin Heyat MB,You ZL,Pardhan B,Akhtar F,Abbas SJ,Guragai B,Acharya K",You ZL,10.1109/ICCWAMTIP51612.2020.9317384,University of Electronic Science & Technology of China,"Maha mrityunjaya hymn is Hindu religious belief to control the mind to dedicate Lord Shiva. Many seers have been practicing it since ancient time. The main aim of this paper is to find the changes in brain signal using C4-A1 channel of the Electroencephalogram (EEG) signal during recitation of this hymn. This study was completed in some steps such as real time EEG recording, extraction of the C4-A1 channel, preprocessing, calculation of the power spectral density, and classification using Decision Tree (DT) and K-Nearest Neighbor (KNN) on five yoga practitioners. The KNN classifier having 5-fold cross validation model achieved the highest recall (97.4%) and accuracy (97.4%) of the system. We obtained that the average frequency of the EEG wave increased prominently. This study will be helpful for the people to understand in the scientific way for the recitation of the religious hymn.","Brain,Maha mrityunjaya hymn,Hinduism,Decision tree,KNN,EEG,Yoga",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
13,CONTRASTIVE REPRESENTATION FOR DERMOSCOPY IMAGE FEW-SHOT CLASSIFICATION,,,134-137,"Mo Xuan,Yang Qiang,Zhang Xiyi,Chen Juan,Wen Quan","Mo X,Yang Q,Zhang XY,Chen J,Wen Q",Chen J,10.1109/ICCWAMTIP51612.2020.9317490,University of Electronic Science & Technology of China,"In the field of few-shot learning, different methods are proposed to optimize the model by changing the network structure or optimizing the algorithm. Although, by designing the end-to-end algorithms, the classification performance on a specific task can be improved. But when the amount of data is limited, it is still difficult to obtain generalization ability for different tasks. At the same time, a single loss function in the end-to-end training is always ineffective,because it is difficult for a shallow network to learn an effective image feature representation from complex natural images. In this paper, a constructive representation algorithm for few-shot learning without end-to-end training is proposed, which is suitable for few-shot learning in the natural images classification task. Through self-supervised representation learning, the proposed encoding model generates an effective feature representation. Then, a few-shot learning model is further constructed and trained for supervised classification tasks. Without the end-to-end training, the proposed learning method at different training stages use different loss functions. In the experiments, on the classification task of the public competition data set ISIC2018[11], our method has a 30% performance improvement over the state-of-the-art methods.","Few-shot learning,Self-supervised learning,Dermoscopy image classification,Skin lesion analysis",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
14,EARLY DETECTION OF COVID-19 DISEASE USING COMPUTED TOMOGRAPHY IMAGES AND OPTIMIZED CNN-LSTM,,,161-165,"Memon Muhammad Hammad,Golilarz Noorbakhsh Amiri,Li Jianping,Yazdi Mohammad,Addeh Abdoljalil","Memon MH,Golilarz NA,Li JP,Yazdi M,Addeh A",Memon MH,10.1109/ICCWAMTIP51612.2020.9317334,Yibin University,"Since the novel Coronavirus (COVID-19) pandemic showed up in China, it became a big problem for health authorities to counter this life-threatening disease. Early light signs such as fever and nonproductive cough give a chance for early detection of disease and appropriate treatment. Imaging features that can be obtained using computed tomography (CT) images are of the most significant aspects of COVID-19 for screening, examination, therapy evaluation, and follow-up. This paper proposes an intelligent method for early detection of COVID-19 based on CT images and deep neural networks. In the developed method, the convolutional neural network (CNN) is used for automatic feature extraction from CT images and long-short term memory (LSTM) is used for final classification. Moreover, the Harris hawk optimization (HHO) algorithm is implemented for finding the best possible value of internal parameters of CNN and LSTM, such as the number of convolution/pooling layers, size, and the number of convolution kernels with the aim of increasing the classification accuracy. The developed method tested on data collected in Mashi Daneshvari Hospital in Iran. The obtained results showed that the developed method could detect the COVID-19 with high accuracy without needing radiologist experts.","CNN,LSTM,Biomedical image processing,Optimization",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,RECOGNITION,,https://ieeexplore.ieee.org/ielx7/9317007/9317311/09317334.pdf,
15,H3DNN: 3D DEEP LEARNING BASED DETECTION OF COVID-19 VIRUS USING LUNGS COMPUTED TOMOGRAPHY,,,183-186,"Khan Abdullah Aman,Shafiq Sidra,Kumar Rajesh,Kumar Jay,Ul Haq Amin","Khan AA,Shafiq S,Kumar R,Kumar J,Ul Haq A",Khan AA,10.1109/ICCWAMTIP51612.2020.9317357,University of Electronic Science & Technology of China,"With the rapid spread of the novel COVID-19 virus, there is an increasing demand for screening COVID-19 patients. Typical methods for screening coronavirus patients have a large false detection rate. An effective and reliable screening method for detecting coronavirus is required. For this reason, some other reliable methods such as Computed Tomography (CT) imaging is employed to detect coronavirus accurately. In this paper, we present a 3D-Deep learning based method that automatically screens coronavirus patients using 3D volumetric CT image data. Our proposed system assists medical practitioners to effectively screen out COVID-19 patients. We performed extensive experiments on two datasets i.e., CC-19 and COVID-CT using various state-of-the-art 3D Deep learning based methods including 3D ResNets, C3D, 3D DenseNets, I3D, and LRCN. The results of the experiments show the competitive effectiveness of our proposed approach.","COVID-19,Coronavirus,3D deep learning,Deep learning,Artificial intelligence",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,https://ieeexplore.ieee.org/ielx7/9317007/9317311/09317357.pdf,
16,BREAST CANCER DIAGNOSIS USING DIGITIZED IMAGES OF FNA BREAST BIOPSY AND OPTIMIZED NEUROFUZZY SYSTEM,,,286-290,"Khan Jalaluddin,Golilarz Noorbakhsh Amiri,Li Jian Ping,Kuzeli Paidar,Addeh Abdoljalil,Ul Haw Amin","Khan J,Golilarz NA,Li JP,Kuzeli P,Addeh A,Ul Haw A",Khan J; Golilarz NA; Li JP,10.1109/ICCWAMTIP51612.2020.9317387,University of Electronic Science & Technology of China,"Breast cancer is the second highest cause of cancer death among women all around the world, especially between the ages of 40 and 65. Early detection of breast cancer tumor type, benign or malignant, has remained a big challenge for physicians and radiologists. By timely identifying the tumor and knowing its type, it can allow physicians to conduct the treatment in the right direction and to take appropriate medications for that type of tumor. Therefore, it is highly important to know the type of tumor accurately to save the patient's life. This paper proposes an intelligent diagnosis method for breast cancer tumor type detection and classification based on fine needle aspirate (FNA) of a breast mass and optimized fuzzy sets. The developed method applied image processing and feature selection techniques to analyze the digitized image of a FNA. In the developed method, nine features computed from a digitized image of a FNA of a breast mass are uses as the initial input of neuro-fuzzy system. In the proposed method, we applied the Association Rules (AR) to find the most informative and effective features of the extracted features. Moreover, in order to advance the act of neuro-fuzzy system, Chaotic Bat Optimization Algorithm (CBOA) is used as learning algorithm. The proposed method is tested on Breast Cancer Wisconsin (Diagnostic) data set. The obtained numerical analysis showed that the developed diagnostic system has excellent performance and high degree of precision.","ANFIS,Breast cancer,FNA,Training algorithm,Tumor type",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,NETWORKS,,,
17,BRAIN TUMOR CLASSIFICATION USING EFFICIENT DEEP FEATURES OF MRI SCANS AND SUPPORT VECTOR MACHINE,,,314-318,"Khan Ahmad Neyaz,Nazarian Habibeh,Golilarz Noorbakhsh Amiri,Addeh Abdoljalil,Li Jian Ping,Khan Ghufran Ahmad","Khan AN,Nazarian H,Golilarz NA,Addeh A,Li JP,Khan GA",Khan AN,10.1109/ICCWAMTIP51612.2020.9317509,University of Electronic Science & Technology of China,"Brain cancer is a life-threatening disease and hampers the normal operation of the human body. For correct diagnosis and methodical treatment planning, it is essential to detect the brain tumor in initial stages of development. This study proposes an intelligent diagnostic method for early detection of brain tumor. In the developed method, the deep features of magnetic resonance imaging (MRI) scans are used as the input of support vector machine (SVM). In the first step of the proposed method, Grab cut method is applied for segmenting tumor region, then the segmented images are fed to convolutional neural network (CNN) for deep feature extraction. Following feature extraction module, minimum Redundancy Maximum Relevance (mRMR) algorithm is used to select the most efficient deep features. Finally, the selected deep features are fed into SVM in the classification module. In addition, we applied the black widow optimization algorithm (BWOA) for optimal tuning of hyper-parameters of CNN and SVM. The developed method applied on BraTS 2015 datasets and the obtained results showed that the developed method is effective and may be employed in computer-aided diagnosis systems to classify the type of tumor.","MRI,Brain tumor,Feature extraction,mRMR,Deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
18,GAN-BASED SYNTHETIC GASTROINTESTINAL IMAGE GENERATION,,,338-342,"Adjei Prince E.,Lonsek Zenebe M.,Rao Nini","Adjei PE,Lonsek ZM,Rao NN",Rao NN,10.1109/ICCWAMTIP51612.2020.9317341,University of Electronic Science & Technology of China,"As with several medical image analysis tasks based on deep learning, gastrointestinal image analysis is plagued with data scarcity, privacy concerns and insufficient number of pathology samples. This paper frames the task of generating new and plausible samples of oesophageal cancer images as an image-to-image translation task. We evaluate two adversarial trained fully convolutional network architectures to generate synthetic diseased gastrointestinal images from segmentation maps prepared by expert clinicians. The synthetic images are evaluated both qualitatively and quantitively and the experimental results indicate that they are comparable to the original images. This potentially addresses the challenge of data scarcity and the need for heavy data augmentation in automated gastrointestinal image analysis.","Generative Adversarial Networks,Gastrointestinal Imaging,Pix2Pix",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
19,Teaching Software Engineering for AI-Enabled Systems,,,45-48,"Kastner Christian,Kang Eunsuk","Kastner C,Kang E",Kastner C,10.1145/3377814.3381714,Carnegie Mellon University,"Software engineers have significant expertise to offer when building intelligent systems, drawing on decades of experience and methods for building systems that are scalable, responsive and robust, even when built on unreliable components. Systems with artificial-intelligence or machine-learning (ML) components raise new challenges and require careful engineering. We designed a new course to teach software-engineering skills to students with a background in ML. We specifically go beyond traditional ML courses that teach modeling techniques under artificial conditions and focus, in lecture and assignments, on realism with large and changing datasets, robust and evolvable infrastructure, and purposeful requirements engineering that considers ethics and fairness as well. We describe the course and our infrastructure and share experience and all material from teaching the course for the first time.",,Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Computer Science,Education & Educational Research",,,,2020 ACM/IEEE 42ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING EDUCATION AND TRAINING (ICSE-SEET 2020),http://arxiv.org/pdf/2001.06691,
20,ADAPTIVE MULTI-REGION NETWORK FOR MEDICAL IMAGE ANALYSIS,,,71-75,"Tao Hemeng,Wang Zhuoyi,Gao Yang,Wang Yigong,Khan Latifur","Tao HM,Wang ZY,Gao Y,Wang YG,Khan L",Tao HM,,University of Texas System,"Automated diagnosis of significant abnormalities (or lesions) from radiology images has been well exploited in Deep Learning (DL) because of the ability to model sophisticated features. However, a deep neural network should be trained on a huge amount of data to infer the parameter values. Unfortunately, for the problems in lesion diagnosis, there is only a limited amount of data annotated in a manner that is suitable to learn powerful deep models. Moreover, the lesion in the radiology image is often vague and hard to identify without expert knowledge. In this paper, we focus on previous challenges in the automated diagnosis and propose the approach named Adaptive Multi-region Network (AdapNet). The key idea is that we adaptively encode the similarity of lesions in different context regions through margin-max learning strategy, which incorporates the metrics learned on those regions to enhance the effectiveness of the model. Our experiments show that the proposed method can effectively obtain superior performance compared to the existing methods, on the DeepLesion data sets.","Adaptive metric learning,medical image analysis,lesion classification,automated diagnosis",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
21,RESIDUAL NETWORKS BASED DISTORTION CLASSIFICATION AND RANKING FOR LAPAROSCOPIC IMAGE QUALITY ASSESSMENT,,,176-180,"Khan Zohaib Amjad,Beghdadi Azeddine,Kaaniche Mounir,Cheikh Faouzi Alaya","Khan ZA,Beghdadi A,Kaaniche M,Cheikh FA",Khan ZA,,"Univ Sorbonne Paris Nord, L2TI, UR 3043, F-93430 Villetaneuse, France.","Laparoscopic images and videos are often affected by different types of distortion like noise, smoke, blur and nonuniform illumination. Automatic detection of these distortions, followed generally by application of appropriate image quality enhancement methods, is critical to avoid errors during surgery. In this context, a crucial step involves an objective assessment of the image quality, which is a two-fold problem requiring both the classification of the distortion type affecting the image and the estimation of the severity level of that distortion. Unlike existing image quality measures which focus mainly on estimating a quality score, we propose in this paper to formulate the image quality assessment task as a multi-label classification problem taking into account both the type as well as the severity level (or rank) of distortions. Here, this problem is then solved by resorting to a deep neural networks based approach. The obtained results on a laparoscopic image dataset show the efficiency of the proposed approach.","Laparoscopic video,image quality assessment,multi-label classification,distortion classification,deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,http://arxiv.org/pdf/2106.06784,
22,ENSEMBLE OF DEEP CASCADES FOR DETECTION OF LARYNGEAL ADDUCTOR REFLEX EVENTS IN ENDOSCOPY VIDEOS,,,300-304,"Hamad Ali S.,Wang Yang Y.,Lever Teresa E.,Bunyak Filiz","Hamad AS,Wang YY,Lever TE,Bunyak F",Bunyak F,,University of Missouri System,"Vocal fold motion plays a critical role in life-sustaining functions of breathing and swallowing. Multiple muscles, nerves, and other anatomical structures are involved in coordinated motion of the vocal folds. Vocal fold function is affected by a wide range of disorders. Laryngeal endoscopy is used in clinical practice to inspect the larynx and to assess vocal fold function. In this paper we propose a deep learning based system for analysis of laryngeal endoscopy videos and for automated detection of laryngeal adductor reflex (LAR) events which are an airway protective mechanism causing brief closure of the vocal folds to prevent aspiration. The proposed system consists of a two-stage solution that combines a vocal fold and glottal region segmentation stage, with a segmentation aided LAR event detection stage. Experimental results show promising LAR detection results robust to many challenges caused by imaging, anatomical, and behavioral variations.","deep learning,laryngeal adductor reflex,automated detection,endoscopy video analysis",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
23,SOFT-LABEL ANONYMOUS GASTRIC X-RAY IMAGE DISTILLATION,,,305-309,"Li Guang,Togo Ren,Ogawa Takahiro,Haseyama Miki","Li G,Togo R,Ogawa T,Haseyama M",Li G,,Hokkaido University,"This paper presents a soft-label anonymous gastric X-ray image distillation method based on a gradient descent approach. The sharing of medical data is demanded to construct high-accuracy computer-aided diagnosis (CAD) systems. However, the large size of the medical dataset and privacy protection are remaining problems in medical data sharing, which hindered the research of CAD systems. The idea of our distillation method is to extract the valid information of the medical dataset and generate a tiny distilled dataset that has a different data distribution. Different from model distillation, our method aims to find the optimal distilled images, distilled labels and the optimized learning rate. Experimental results show that the proposed method can not only effectively compress the medical dataset but also anonymize medical images to protect the patient's private information. The proposed approach can improve the efficiency and security of medical data sharing.","Medical image distillation,medical data sharing,anonymization,gastric X-ray images",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,PRIVACY,,http://arxiv.org/pdf/2104.02857,
24,KNOWLEDGE-GUIDED AND HYPER-ATTENTION AWARE JOINT NETWORK FOR BENIGN-MALIGNANT LUNG NODULE CLASSIFICATION,,,310-314,"Xu Weixin,Wang Kun,Lin Jingkai,Lu Yuting,Huang Sheng,Zhang Xiaohong","Xu WX,Wang K,Lin JK,Lu YT,Huang S,Zhang XH",Zhang XH,,Chongqing University,"Accurate identification and early diagnosis of malignant lung nodules are crucial for improving the survival rate of patients with lung cancer. Deep learning methods have recently been proven success in computer-aided diagnostic tasks. However, to the best of our knowledge, the features of tissues and vessels will disturb the model resulting in inaccurate classification of the nodules. To reduce the interference and capture crucial contextual information from different channels in a more efficient way, we introduce a Hyper-Attention Mechanism(HAM) that can be easily integrated into convolutional neural networks(CNNs). Moreover, without incorporating prior-domain knowledge, traditional methods lack interpretability, which is difficult to understand and utilize them in the clinic by radiologists. Based on this, we propose a novel Knowledge-Guided model to predict malignant pulmonary nodules from chest CT data, which inject external medical knowledge into CNNs to guide the training process. We evaluate the proposed model on the LIDC-IDRI dataset and demonstrate its effectiveness by achieving comparable state-of-the-art performance.","Lung nodule classification,Lung cancer diagnosis,Deep learning,Attention mechanism,Prior-domain knowledge",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
25,AUTOMATED DETECTION OF HIGHLY AGGREGATED NEURONS IN MICROSCOPIC IMAGES OF MACAQUE BRAIN,,,315-319,"You Zhenzhen,Jiang Ming,Shi Zhenghao,Shi Cheng,Du Shuangli,Liang Jimin,Herard Anne-Sophie,Jan Caroline,Souedet Nicolas,Delzescaux Thierry","You ZZ,Jiang M,Shi ZH,Shi C,Du SL,Liang JM,Herard AS,Jan C,Souedet N,Delzescaux T",You ZZ,,Xi'an University of Technology,"Neuron detection is a key step in individualizing and counting neurons which are important for assessing physiological and pathophysiological information. A large number of methods including deep learning networks have been proposed but mainly targeting regions with few aggregated neurons. The objective of this paper is to address an automated neuron detection problem in heterogeneous hippocampus region with different degrees of neuron aggregation. Since deep learning networks require a lot of ground truths hut neuron instance annotation is impossible in regions where numerous neurons are clustered, ground truth of centroids marked at the center of neurons is created for training. We propose a multiscale convolutional neural network (CNN) to regress neuron centroid mapping across image. Using multiscale information makes the proposed network applicable not only for single individual neurons, but also for a large number of aggregated neurons. Experimental results show that our method is superior to state-of-the-art deep learning -based algorithms. To our knowledge, this is the first deep learning study to detect neurons in regions of highly clustered neurons.","Neuron detection,point annotation,multiscale CNN,hippocampus region,microscopic image",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,"TOTAL,NUMBER,GLIAL-CELLS,CORTEX",,,
26,VESSEL-NET: A VESSEL-AWARE ENSEMBLE NETWORK FOR RETINOPATHY SCREENING FROM FUNDUS IMAGE,,,320-324,"Luo Dihao,Shen Liping","Luo DH,Shen LP",Luo DH,,Shanghai Jiao Tong University,"Retinal diseases are one of the most popular malady in modern world with increasingly use of electronic screens. Previous studies on deep learning based automatic screening generally used global image of fundus. However, due to limited size of input image, global image lacks in information of medical-related region and has poor resolution in local details. This paper proposes a novel vessel-aware ensemble network for retinal disease detection. Specifically, the proposed network consists of three aspect of information which integrates deep diverse context of the global fundus image and the local medical-related regions, i.e. local disc-region and local vessel-related region. Finally, the output probabilities of different streams are fused as the final screening result. The experiment results on the AMD data of ODIR dataset show that our method outperforms other state-of-the-art algorithms and shows the significance of vessel-related regions.","Deep learning,fundus images,retinopathy screening,retinal vessel segmentation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
27,"A DEEP LEARNING-BASED CAD SYSTEM FOR RENAL ALLOGRAFT ASSESSMENT: DIFFUSION, BOLD, AND CLINICAL BIOMARKERS",,,355-359,"Shehata Mohamed,Ghazal Mohammed,Abu Khalifeh Hadil,Khalil Ashraf,Shalaby Ahmed,Dwyer Amy C.,Bakr Ashraf M.,Keynton Robert,El-Baz Ayman","Shehata M,Ghazal M,Abu Khalifeh H,Khalil A,Shalaby A,Dwyer AC,Bakr AM,Keynton R,El-Baz A",Shehata M,,University of Louisville,"Recently, studies for non-invasive renal transplant evaluation have been explored to control allograft rejection. In this paper, a computer-aided diagnostic system has been developed to accommodate with an early-stage renal transplant status assessment, called RT-CAD. Our model of this system integrated multiple sources for a more accurate diagnosis: two image-based sources and two clinical-based sources. The image-based sources included apparent diffusion coefficients (ADCs) and the amount of deoxygenated hemoglobin (R2*). More specifically, these ADCs were extracted from 47 diffusion weighted magnetic resonance imaging (DW-MRI) scans at 11 different b-values (b0, b50, b100, ... , b1000 s/mm(2)), while the R2* values were extracted from 30 blood oxygen level-dependent MRI (BOLD-MRI) scans at 5 different echo times (2ms, 7ms, 12ms, 17ms, and 22ms). The clinical sources included serum creatinine (SCr) and creatinine clearance (CrCl). First, the kidney was segmented through the RT-CAD system using a geometric deformable model called a level-set method. Second, both ADCs and R2* were estimated for common patients (N = 30) and then were integrated with the corresponding SCr and CrCl. Last, these integrated biomarkers were considered the discriminatory features to be used as trainers and testers for future deep learning-based classifiers such as stacked auto-encoders (SAEs). We used a k-fold cross-validation criteria to evaluate the RT-CAD system diagnostic performance, which achieved the following scores: 93.3%, 90.0%, and 95.0% in terms of accuracy, sensitivity, and specificity in differentiating between acute renal rejection (AR) and non-rejection (NR). The reliability and completeness of the RT-CAD system was further accepted by the area under the curve score of 0.92. The conclusions ensured that the presented RT-CAD system has a high reliability to diagnose the status of the renal transplant in a non-invasive way.","RT-CAD,DW-MRI,BOLD-MRI,SAEs",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,"TRANSPLANTED,KIDNEYS,FOLLOW-UP,MRI,REPRESENTATION,DYSFUNCTION",,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8553095,
28,DISENTANGLED REPRESENTATION LEARNING BASED MULTIDOMAIN STAIN NORMALIZATION FOR HISTOLOGICAL IMAGES,,,360-364,"Xiang Yao,Chen Jialin,Liu Qing,Liang Yixiong","Xiang Y,Chen JL,Liu Q,Liang YX",Liang YX,,Central South University,"Color variations of histological images due to multi-factor hinder the performance of computer-aided diagnosis (CAD) systems. Previous stain normalization methods have achieved excellent results. While in practice, a multidomain stain normalization method is still be needed when more than two color variations exist in dataset. In this paper, we propose a multidomain stain normalization model inspired by MUNIT[1], with the idea of disentangling the representations of content and style. We assume that the latent space of histological images can be decomposed into domain-shared content space and domain-specific style space. The stain normalization aims to transfer the styles cross domains and maintain the contents. In addition, we propose to use the earth mover's distance(EMD) to evaluate the effectiveness of stain normalization. We evaluate our approach against the state-of-the-art methods quantitatively and qualitatively.","Histological Images,Stain Normalization,Generative Adversarial Networks,Deep Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
29,ENHANCE CATEGORISATION OF MULTILEVEL HIGH-SENSITIVITY CARDIOVASCULAR BIOMARKERS FROM LATERAL FLOW IMMUNOASSAY IMAGES VIA NEURAL NETWORKS AND DYNAMIC TIME WARPING,,,365-369,"Jing Min,Mac Namee Brian,McLaughlin Donal,Steele David,McNamee Sara,Cullen Patrick,Finlay Dewar,McLaughlin James","Jing M,Mac Namee B,McLaughlin D,Steele D,McNamee S,Cullen P,Finlay D,McLaughlin J",Jing M,,Ulster University,"Lateral Flow Immunoassays (LFA) are low cost, rapid and highly efficacious Point-of-Care devices. Traditional LFA testing faces challenges to detect high-sensitivity biomarkers due to low sensitivity. Unlike most approaches based on averaging image intensity from a region-of-interest (ROI), this paper presents a novel system that considers each row of an LFA image as a time series signal and, consequently, does not require the detection of ROI. Long Short-Term Memory (LSTM) networks are used to classify LFA data obtained from multilevel high-sensitivity cardiovascular biomarkers. Dynamic Time Warping (DTW) was incorporated with LSTM to align the LFA data from different concentration levels to a common reference before feeding the distance maps into an LSTM network. The LSTM network outperforms other classifiers with or without DTW. Furthermore, performance of all classifiers is improved after incorporating DTW. The positive outcomes suggest the potential of the proposed methods for early risk assessment of cardiovascular diseases.","Lateral Flow Immunoassays,Long Short-Term Memory,Dynamic Time Warping,high-sensitivity cardiovascular biomarkers,classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,https://pure.ulster.ac.uk/ws/files/79479326/Jing_final.pdf,
30,CYCLE GAN-BASED DATA AUGMENTATION FOR MULTI-ORGAN DETECTION IN CT IMAGES VIA YOLO,,,390-393,"Hammami Maryam,Friboulet Denis,Kechichian Razmig","Hammami M,Friboulet D,Kechichian R",Hammami M,,Centre National de la Recherche Scientifique (CNRS),"We propose a deep learning solution to the problem of object detection in 3D CT images, i.e. the localization and classification of multiple structures. Supervised learning methods require large annotated datasets that are usually difficult to acquire. We thus develop a Cycle Generative Adversarial Network (CycleGAN) + You Only Look Once (YOLO) combined method for CT data augmentation using MRI source images to train a YOLO detector. This results in a fast and accurate detection with a mean average distance of 7.95 +/- 6.2 mm, which is significantly better than detection without data augmentation. We show that the approach compares favorably to state-of-the-art detection methods for medical images.","multi-organ detection,image synthesis,data augmentation,medical imaging",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,"LOCALIZATION,REGRESSION",,https://hal.archives-ouvertes.fr/hal-03345927/document,
31,RBVS-NET: A ROBUST CONVOLUTIONAL NEURAL NETWORK FOR RETINAL BLOOD VESSEL SEGMENTATION,,,398-402,"Kushol Rafsanjany,Salekin Md Sirajus","Kushol R,Salekin MS",Kushol R,,University of Alberta,"Retinal vascular diseases are the utmost cause of visibility loss and blindness where the blood vessels in the eyes somehow fail to circulate the appropriate level of blood flow. Early and correct detection of retinal blood vessels facilitates humans to take expedient remedy against most of the ophthalmic diseases which can significantly reduce possible vision loss. This paper presents a robust RBVS-Net (Retinal Blood Vessel Segmentation Network) which is inspired by the popular U-Net architecture. Proper utilization of transfer learning and data augmentation lead RBVS-Net to achieve to outperform the state-of-the-art accuracy. Extensive experiments have been conducted on three benchmark retinal fundus image datasets, where the proposed approach achieves more than 96% average accuracy for vessel segmentation. A comparison with other recent works also demonstrates the efficiency of the proposed approach to segment the blood vessel from the retinal color fundus image.","Deep learning,medical image segmentation,retinal blood vessel,U-Net,transfer learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,IMAGES,,,
32,RETINAL VESSEL SEGMENTATION UNDER EXTREME LOW ANNOTATION: A GAN BASED SEMI-SUPERVISED APPROACH,,,418-422,"Lahiri Avisek,Jain Vineet,Mondal Arnab,Biswas Prabir Kumar","Lahiri A,Jain V,Mondal A,Biswas PK",Lahiri A,,Indian Institute of Technology System (IIT System),"Contemporary deep learning based medical image segmentation algorithms require hours of annotation labor by domain experts. These data hungry deep models perform sub-optimally in the presence of limited amount of labeled data. In this paper, we present a data efficient learning framework using the recent concept of Generative Adversarial Networks; this allows a deep neural network to perform significantly better than its fully supervised counterpart in low annotation regime. The proposed method is an extension of our previous work with the addition of a new unsupervised adversarial loss and a structured prediction based architecture. Though generic, we demonstrate the efficacy of our approach for retinal blood vessels segmentation from fundus images on DRIVE and STARE datasets. We experiment with extreme low annotation budget and we show, that under this constrained data setting, the proposed method outperforms our previous method and other fully supervised benchmark models. In addition, our systematic ablation studies suggest some key observations for successfully training GAN based semi-supervised algorithms with an encoder-decoder style network architecture.","GAN,fundus image,segmentation,adversarial learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
33,IDENTIFYING CHILDREN WITH AUTISM SPECTRUM DISORDER BASED ON GAZE-FOLLOWING,,,423-427,"Fang Yi,Duan Huiyu,Shi Fangyu,Min Xiongkuo,Zhai Guangtao","Fang Y,Duan HY,Shi FY,Min XK,Zhai GT",Zhai GT,,Shanghai Jiao Tong University,"This paper presents a novel method to identify children with Autism Spectrum Disorder (ASD) based on the stimuli with gaze-following. Individuals with ASD are characterized by having atypical visual attention patterns, especially in social scenes. Gaze-following is considered to be a key element in understanding social scenarios, and it is reasonable to use stimuli with gaze-following to identify the children with ASD. Thus in this paper, we first construct a dataset of eye movements in gaze-following scenes for children with ASD (i.e., GazeFollow4ASD dataset), including 300 images with gaze-following information inside them and the corresponding eye movement data collected from 8 children with ASD and 10 healthy controls. We propose a novel deep neural network (DNN) model to extract discriminative features and classify children with ASD and healthy controls on single images. The proposed model shows the best performance among all compared methods on all datasets.","Autism Spectrum Disorder identifying,visual attention,gaze-following,deep neural network",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
34,HYBRID DEEP REINFORCED REGRESSION FRAMEWORK FOR CARDIO-THORACIC RATIO MEASUREMENT,,,433-437,"Singh Pranshu Ranjan,Gopalakrishnan Saisubramaniam,Mien Ivan Ho,Ambikapathi ArulMurugan","Singh PR,Gopalakrishnan S,Mien IH,Ambikapathi A",Singh PR,,Agency for Science Technology & Research (ASTAR),"Quantitative measurements obtained from medical images guide clinicians in several use cases but manually obtaining such measurements are both laborious and subject to inter-observer variations. We develop a hybrid deep reinforced regression framework to robustly measure the Cardio-Thoracic ratio (CTR) from Chest X-ray (CXR) images, thereby directly identifying the presence of Cardiomegaly. The proposed hybrid framework initially employs a CNN based Regressor on pre-processed images to obtain approximate critical points. As the actual critical points are based on human expert's experience and subject to labeling uncertainties, a deep reinforcement learning (deep RL) approach is specifically designed to fine-tune estimated regression points from the CNN Regressor. The final regressed points are then used to measure CTR. Wingspan and ChestX-ray8 datasets are used for validating the proposed framework. The proposed framework shows generalization ability on ChestX-ray8 and outperforms the state-of-the-art results on Wingspan.","Deep Reinforcement Learning,Convolutional Neural Networks,Chest X-ray,Cardio-Thoracic Ratio",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
35,DIAGNOSING AUTISM USING T1-W MRI WITH MULTI-KERNEL LEARNING AND HYPERGRAPH NEURAL NETWORK,,,438-442,"Madine Mohammad,Rekik Islem,Werghi Naoufel","Madine M,Rekik I,Werghi N",Madine M,,Khalifa University of Science & Technology,"The field of network neuroscience provided unprecedented insights into how brain connectivity gets altered by autism spectrum disorder (ASD) on functional, structural, and morphological levels. However, a few studies have looked to design a framework that captures the complex network structure of the brain and disentangles the heterogeneity of ASD. In this paper, we leverage multi-kernel unsupervised learning in the construction of multiview hypergraph neural networks (HGNN), each capturing a particular view of the brain connectome, to eventually distinguish between ASD and normal control (NC) subjects. Additionally, we tested and measured how our proposed framework compares to other variants based on previous baseline methods. Our classification results outperformed comparison methods and agreed with the literature in the sense that the right hemisphere connectivity was more discriminative in ASD diagnosis than the left hemisphere.","autism spectrum disorder,hypergraph neural network,multi-kernel learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,"SPECTRUM,DISORDER,CONNECTIVITY,CHILDREN,IDENTIFICATION",,,
36,MULTI-SCALE EXPLAINABLE FEATURE LEARNING FOR PATHOLOGICAL IMAGE ANALYSIS USING CONVOLUTIONAL NEURAL NETWORKS,,,1931-1935,"Uehara Kazuki,Murakawa Masahiro,Nosato Hirokazu,Sakanashi Hidenori","Uehara K,Murakawa M,Nosato H,Sakanashi H",Uehara K,,National Institute of Advanced Industrial Science & Technology (AIST),"The use of computer-assisted diagnosis (CAD) systems for pathological image analysis constitutes an important research topic. Such systems should be accurate, and their decisions should be explainable to ensure reliability. In this paper, we present an explainable diagnosis method based on convolutional neural networks (CNNs). This method allows us to interpret the basis of the decisions made by the CNN from two perspectives, namely statistics and visualization. For the statistical explanation, the method constructs dictionaries of representative pathological features over multiple scales in training data. It performs diagnoses based on the occurrence and importance of items in the dictionaries to rationalize its decisions. We introduce a vector quantization scheme to the CNN to enable it to construct the feature dictionary. For the visual interpretation, the method provides images of learned features in the dictionary by decoding them from a high-dimensional feature space to a pathological image space. The experimental results showed that the proposed network learned pathological features, which contributed to the diagnosis, and the method yielded approximately an area under the receiver operating curve (AUC) of 0.89 for detecting atypical tissues in pathological images of a uterine cervix by using these features.","Explainable AI,Pathological images,Convolutional neural networks",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
37,BAE-NET: A BAND ATTENTION AWARE ENSEMBLE NETWORK FOR HYPERSPECTRAL OBJECT TRACKING,,,2106-2110,"Li Zhuanfeng,Xiong Fengchao,Zhou Jun,Wang Jing,Lu Jianfeng,Qian Yuntao","Li ZAF,Xiong FC,Zhou J,Wang J,Lu JF,Qian YT",Xiong FC,,Nanjing University of Science & Technology,"Hyperspectral videos contain images with a large number of light wavelength indexed bands that can facilitate material identification for object tracking. Most hyperspectral trackers use hand-crafted features rather than deep learning generated features for image representation due to limited training samples. To fill this gap, this paper introduces a band attention aware ensemble network (BAE-Net) for deep hyperspectral object tracking, which takes advantages of deep models trained on color videos for feature representation. Specifically, an autoencoder-like band attention block is introduced to learn the dependencies among bands and generate band-wise weights. Guided by these weights, hyperspectral images are then divided into a number of three-channel images. These three-channel images are fed into a deep color tracking network, producing several weak trackers. Finally, weak trackers are fused using ensemble learning for target location. Experimental results on hyperspectral datasets show the effectiveness and advantages of the proposed deep hyperspectral tracker.","deep learning,hyperspectral tracking,band selection,ensemble learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,SELECTION,,,
38,NDDR-LCS: A MULTI-TASK LEARNING METHOD FOR CLASSIFICATION OF CAROTID PLAQUES,,,2461-2465,"Shen Huayu,Zhang Wu,Wang Haiya,Ding Guangtai,Xie Jiang","Shen HY,Zhang W,Wang HY,Ding GT,Xie J",Xie J,,Shanghai University,"Carotid plaque classification plays a critical role in the identification of vulnerable plaques, so it is crucial for early risk estimation of cardiovascular and cerebrovascular events. Carotid ultrasound examination with ultrasound images and reports produced by professional doctors is the most common way to assess atherosclerotic plaques in clinical practice. However, existing deep learning methods for carotid ultrasound image analysis ignore the information in the ultrasound report. In this paper, we propose a multi-task learning (MTL) method named NDDR-LCS based on convolutional neural network (CNN) that leverages auxiliary information from ultrasound reports to assist the carotid plaque classification task. NDDR-LCS utilizes dense blocks as feature descriptors and organically combines three novel MTL mechanisms that are Neural Discriminative Dimensionality Reduction (NDDR), Learning Mixtures, and Cross-Stitch, to learn dependencies between ultrasound images and ultrasound reports. Based on carotid ultrasound images and their corresponding diagnostic reports, we conduct sufficient experiments to prove that NDDR-LCS outperforms state-of-the-art CNN methods for carotid plaque classification.","Carotid Plaque Classification,Multi Task Learning,Auxiliary Task,Carotid Ultrasound,Ultrasound Reports",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
39,MULTIMODAL IMAGE-TO-IMAGE TRANSLATION FOR GENERATION OF GASTRITIS IMAGES,,,2466-2470,"Togo Ren,Ogawa Takahiro,Haseyama Miki","Togo R,Ogawa T,Haseyama M",Togo R,,Hokkaido University,"We present a new multimodal image-to-image translation model for the generation of gastritis images using X-ray and blood inspection results. In clinical situations, clinicians estimate the prognosis of the target disease by considering multiple inspection results. Similarly, we take a multimodal approach in the task of gastric cancer risk prediction. Visual characteristics of the gastric X-ray image and blood index values are highly related in the evaluation of gastric cancer risk. If we can generate a prediction image from blood index values, it contributes to the clinicians' sophisticated and integrated diagnosis. Hence, we learn a model that can map non-gastritis images to gastritis images based on the blood index values. Although this is a challenging multimodal task in medical image analysis, experimental results showed the effectiveness of our model.","Image-to-image translation,deep learning,adversarial learning,medical image analysis,gastritis",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,"ADVERSARIAL,NETWORKS,CLASSIFICATION",,,
40,FAST TUMOR DETECTOR IN WHOLE-SLIDE IMAGE WITH DYNAMIC PROGRAMING BASED MONTE CARLO SAMPLING,,,2471-2475,"Ke Jing,Shen Yiqing,Guo Yi,Liang Xiaoyao","Ke J,Shen YQ,Guo Y,Liang XY",Liang XY,,Shanghai Jiao Tong University,"In the last decade, computational pathology has attracted notable attention in the deep learning domain. However, even on the state-of-the-art deep learning computing platforms, a high-resolution scanned whole slide image (WSI) still requires reducing into massive patches to be processed, which is very time consuming in real-time diagnosis. In this paper, we propose a high-throughput tumor location system with Monte Carlo adaptive sampling to accelerate WSI analysis. Additionally, we design a dynamic programming framework to incorporate spatial correlation, which can iteratively eliminate false positives or false negatives in the identification or tumor tissues. We use three datasets of colorectal cancer from The Cancer Genome Atlas (TCGA) for performance evaluation. The designed computer-aided system can reduce more than 50% of the diagnostic time on average in the tumor location task, along with a slight increase in accuracy.","Tumor location,Colorectal cancer,High-throughput WSI diagnosis,Monte Carlo adaptive sampling,Deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
41,IMPROVING ROBUSTNESS USING JOINT ATTENTION NETWORK FOR DETECTING RETINAL DEGENERATION FROM OPTICAL COHERENCE TOMOGRAPHY IMAGES,,,2476-2480,"Kamran Sharif Amit,Tavakkoli Alireza,Zuckerbrod Stewart Lee","Kamran SA,Tavakkoli A,Zuckerbrod SL",Kamran SA,,Nevada System of Higher Education (NSHE),"Noisy data and the similarity in the ocular appearances caused by different ophthalmic pathologies pose significant challenges for an automated expert system to accurately detect retinal diseases. In addition, the lack of knowledge transferability and the need for unreasonably large datasets limit clinical application of current machine learning systems. To increase robustness, a better understanding of how the retinal subspace deformations lead to various levels of disease severity needs to be utilized for prioritizing disease-specific model details. In this paper we propose the use of disease-specific feature representation as a novel architecture comprised of two joint networks - one for supervised encoding of disease model and the other for producing attention maps in an unsupervised manner to retain disease specific spatial information. Our experimental results on publicly available datasets show the proposed joint-network significantly improves the accuracy and robustness of state-of-the-art retinal disease classification networks on unseen datasets.","Retinal Degeneration,SD-OCT,Robust Convolutional Neural Networks,Attention Map",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,"AUTOMATIC,SEGMENTATION,MACULAR,DEGENERATION,GLOBAL,PREVALENCE",,http://arxiv.org/pdf/2005.08094,
42,MULTI-SCALE FEATURE PYRAMIDS FOR WEAKLY SUPERVISED THORACIC DISEASE LOCALIZATION,,,2481-2485,"Ma Yang,Ma Andy J.,Pan Youngsun,Chen Xi","Ma Y,Ma AJ,Pan YS,Chen X",Ma AJ,,Sun Yat Sen University,"Automatic localization of thoracic diseases has a wide range of applications which can assist radiologists for more efficient and better diagnosis. However, it is still a challenging task to locate the diseases accurately since strong location annotation may not be available and different thoracic diseases may vary in size greatly. In this paper, we propose a novel multi-scale feature pyramids model for weakly supervised disease localization on chest X-ray images. Our model leverages the multi-scale feature maps to learn location representation of lesions by fusing heatmaps generated from all these feature maps. Instead of linear combination of heatmaps, we reconfigure multi-scale feature maps with an Feature Pyramids Network (fpn) structure first. The FPN we conducted is a nonlinear combination of feature hierarchy, adding highly-nonlinear patterns in feature maps, enriching the representation space of heatmaps. Experiments on the ChestXray14 dataset show that the proposed method can significantly improve the localization performance of small-sized diseases (nodules and masses) with competitive localization performance of largesized diseases (cardiomegaly and pneumonia). Averagely, our method is superior to the state-of-the-art weakly supervised localization algorithms on the dataset, ChestXray14.","Weakly Supervised Localization,Multi-Scale Feature Pyramids,Chest X-ray Image",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
43,AN ENHANCED DEEP LEARNING ARCHITECTURE FOR CLASSIFICATION OF TUBERCULOSIS TYPES FROM CT LUNG IMAGES,,,2486-2490,"Gao Xiaohong,Comley Richard,Khan Maleika Heenaye-Mamode","Gao XH,Comley R,Khan MHM",Gao XH,,Middlesex University,"In this work, an enhanced ResNet deep learning network, depth-ResNet, has been developed to classify the five types of Tuberculosis (TB) lung CT images. Depth-ResNet takes 3D CT images as a whole and processes the volumatic blocks along depth directions. It builds on the ResNet-50 model to obtain 2D features on each frame and injects depth information at each process block. As a result, the averaged accuracy for classification is 71.60% for depth-ResNet and 68.59% for ResNet. The datasets are collected from the ImagcCLEF 2018 competition with 1008 training data in total, where the top reported accuracy was 42.27%.","deep learning,Tuberculosis classification,CT lung images,3D image analysis",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,https://eprints.mdx.ac.uk/30256/1/ICIP2020_Final-Paper1454.pdf,
44,SEA-NET: SQUEEZE-AND-EXCITATION ATTENTION NET FOR DIABETIC RETINOPATHY GRADING,,,2496-2500,"Zhao Ziyuan,Chopra Kartik,Zeng Zeng,Li Xiaoli","Zhao ZY,Chopra K,Zeng Z,Li XL",Zeng Z,,Agency for Science Technology & Research (ASTAR),"Diabetes is one of the most common disease in individuals. Diabetic retinopathy (DR) is a complication of diabetes, which could lead to blindness. Automatic DR grading based on retinal images provides a great diagnostic and prognostic value for treatment planning. However, the subtle differences among severity levels make it difficult to capture important features using conventional methods. To alleviate the problems, a new deep learning architecture for robust DR grading is proposed, referred to as SEA-Net, in which, spatial attention and channel attention are alternatively carried out and boosted with each other, improving the classification performance. In addition, a hybrid loss function is proposed to further maximize the inter-class distance and reduce the intra-class variability. Experimental results have shown the effectiveness of the proposed architecture.","Convolutional neural network,Squeeze-and-Excitation net,Diabetic retinopathy grading,Attention mechanism",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,http://arxiv.org/pdf/2010.15344,
45,GENERATION OF VIEWED IMAGE CAPTIONS FROM HUMAN BRAIN ACTIVITY VIA UNSUPERVISED TEXT LATENT SPACE,,,2521-2525,"Takada Saya,Togo Ren,Ogawa Takahiro,Haseyama Miki","Takada S,Togo R,Ogawa T,Haseyama M",Takada S,,Hokkaido University,"Generation of human cognitive contents based on the analysis of functional magnetic resonance imaging (fMRI) data has been actively researched. Cognitive contents such as viewed images can be estimated by analyzing the relationship between fMRI data and semantic information of viewed images. In this paper, we propose a new method generating captions for viewed images from human brain activity via a novel robust regression scheme. Unlike conventional generation methods using image feature representations, the proposed method makes use of more semantic text feature representations, which are more suitable for the caption generation. We construct a text latent space with unlabeled images not used for the training, and the fMRI data are regressed to the text latent space. Besides, we newly make use of unlabeled images not used for the training phase to improve caption generation performance. Finally, the proposed method can generate captions from the fMRI data measured while subjects are viewing images. Experimental results show that the proposed method enables accurate caption generation for viewed images.","Image captioning,deep neural network (DNN),neuroscience,functional magnetic resonance imaging (fMRI)",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,"CATEGORIES,REPRESENTATIONS,OBJECTS",,,
46,GLAUCOMA DETECTION FROM RAW CIRCUMPAPILLARY OCT IMAGES USING FULLY CONVOLUTIONAL NEURAL NETWORKS,,,2526-2530,"Garcia Gabriel,del Amor Rocio,Colomer Adrian,Naranjo Valery","Garcia G,del Amor R,Colomer A,Naranjo V",Garcia G,,Universitat Politecnica de Valencia,"Nowadays, glaucoma is the leading cause of blindness worldwide. We propose in this paper two different deep-learning-based approaches to address glaucoma detection just from raw circumpapillary OCT images. The first one is based on the development of convolutional neural networks (CNNs) trained from scratch. The second one lies in fine-tuning some of the most common state-of-the-art CNNs architectures. The experiments were performed on a private database composed of 93 glaucomatous and 156 normal B-scans around the optic nerve head of the retina, which were diagnosed by expert ophthalmologists. The validation results evidence that fine-tuned CNNs outperform the networks trained from scratch when small databases are addressed. Additionally, the VGG family of networks reports the most promising results, with an area under the ROC curve of 0.96 and an accuracy of 0.92, during the prediction of the independent test set.","Glaucoma detection,deep learning,circumpapillary OCT,fine tuning,class activation maps",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
47,A GAN BASED MULTI-CONTRAST MODALITIES MEDICAL IMAGE REGISTRATION APPROACH,,,3000-3004,"Qiao Jinhao,Lai Qirong,Li Ying,Lan Ling,Yu Chunyan,Wang Xiu","Qiao JH,Lai QR,Li Y,Lan L,Yu CY,Wang X",Yu CY; Wang X,,Fuzhou University,"Most current multi modalities medical image registration approaches are concerned about registering one modality image to another. However, in the real world, medical image registration may be involved in multiple modes, not just two specific modalities. To this end, we propose a multi-contrast modalities medical image registration modal (Star-Reg net). It uses a single generator and discriminator for all contrasts of registrations amount several modalities. Furthermore, the proposed approach is trained in an unsupervised way, which alleviates the requirement of manual annotation data. The experiment on the IXI dataset demonstrates the Star-Reg net effectiveness in multi-contrast modalities medical image registration.","Medical image registration,Multi-contrast,Multi-modalities,Star-Reg net",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
48,OPENCC - AN OPEN BENCHMARK DATASET FOR CORPUS CALLOSUM SEGMENTATION AND EVALUATION,,,3020-3024,"Yang Xulei,Zhao Xin,Tjio Gabriel,Chen Cen,Wang Li,Wen Bihan,Su Yi","Yang XL,Zhao X,Tjio G,Chen C,Wang L,Wen BH,Su Y",Yang XL,,"YITU Technol, Singapore, Singapore.","Neuroimaging studies have revealed that the structural changes of the corpus callosum (CC) are evident in a variety of neurological diseases, such as epilepsy and autism. Segmentation of the CC from magnetic resonance images (MRI) of the brain is a crucial step in the diagnosis of various brain disorders. However, the lack of open benchmark CC datasets has hindered development of CC segmentation techniques. In this work, we present an open benchmark dataset - OpenCC - for CC segmentation and evaluation. The dataset was built through alternative application of automatic segmentation and manual refinement. The automatic segmentation is based on recent advances in deep learning - fully convolutional networks, specifically U-Net, while the manual refinement is done by domain radiologists. The resulting dataset consists of 4643 mid-sagittal (or near mid-sagittal) slices and their corresponding CC masks. Furthermore, we provided some baseline segmentation results on the OpenCC dataset by using two latest deep learning segmentation approaches. The OpenCC dataset can be used for comparison and evaluation of newly developed CC segmentation algorithms. We endeavor that, through the publishing of the OpenCC dataset and baseline segmentation results, we could promote further development of CC segmentation techniques.","Image Segmentation,Corpus Callosum,Deep Learning,Open Benchmark Dataset,Fully Convolutional Networks",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Imaging Science & Photographic Technology,,,,,,
49,Deep supervised learning with mixture of neural networks,102,,,"Hu Yaxian,Luo Senlin,Han Longfei,Pan Limin,Zhang Tiemei","Hu YX,Luo SL,Han LF,Pan LM,Zhang TM",Pan LM,10.1016/j.artmed.2019.101764,Beijing Institute of Technology,"Deep Neural Network (DNN), as a deep architectures, has shown excellent performance in classification tasks. However, when the data has different distributions or contains some latent non-observed factors, it is difficult for DNN to train a single model to perform well on the classification tasks. In this paper, we propose mixture model based on DNNs (MoNNs), a supervised approach to perform classification tasks with a gating network and multiple local expert models. We use a neural network as a gating function and use DNNs as local expert models. The gating network split the heterogeneous data into several homogeneous components. DNNs are combined to perform classification tasks in each component. Moreover, we use EM (Expectation Maximization) as an optimization algorithm. Experiments proved that our MoNNs outperformed the other compared methods on determination of diabetes, determination of benign or malignant breast cancer, and handwriting recognition. Therefore, the MoNNs can solve the problem of data heterogeneity and have a good effect on classification tasks.","Deep neural network,Mixture model,Expectation maximization,Diabetes determination",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Medical Informatics",,5.602,"MODELS,CLASSIFICATION",ARTIFICIAL INTELLIGENCE IN MEDICINE,,
50,Artificial plant optimization algorithm to detect heart rate & presence of heart disease using machine learning,102,,,"Sharma Prerna,Choudhary Krishna,Gupta Kshitij,Chawla Rahul,Gupt Deepak,Sharma Arun","Sharma P,Choudhary K,Gupta K,Chawla R,Gupt D,Sharma A",Gupt D,10.1016/j.artmed.2019.101752,Maharaja Agrasen Institute of Technology,"In today's world, cardiovascular diseases are prevalent becoming the leading cause of death; more than half of the cardiovascular diseases are due to Coronary Heart Disease (CHD) which generates the demand of predicting them timely so that people can take precautions or treatment before it becomes fatal. For serving this purpose a Modified Artificial Plant Optimization (MAPO) algorithm has been proposed which can be used as an optimal feature selector along with other machine learning algorithms to predict the heart rate using the fingertip video dataset which further predicts the presence or absence of Coronary Heart Disease in an individual at the moment. Initially, the video dataset has been pre-processed, noise is filtered and then MAPO is applied to predict the heart rate with a Pearson correlation and Standard Error Estimate of 0.9541 and 2.418 respectively. The predicted heart rate is used as a feature in other two datasets and MAPO is again applied to optimize the features of both datasets. Different machine learning algorithms are then applied to the optimized dataset to predict values for presence of current heart disease. The result shows that MAPO reduces the dimensionality to the most significant information with comparable accuracies for different machine learning models with maximum dimensionality reduction of 81.25%. MAPO has been compared with other optimizers and outperforms them with better accuracy.","Modified artificial plant optimization algorithm,Machine learning,Savitzky-Golay filter,Extreme gradient boosting,Artificial neural network",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Medical Informatics",,5.602,"SOLVE,TOY,MODEL",ARTIFICIAL INTELLIGENCE IN MEDICINE,,
51,Weighted Random Forests to Improve Arrhythmia Classification,9,1,,"Gajowniczek Krzysztof,Grzegorczyk Iga,Zabkowski Tomasz,Bajaj Chandrajit","Gajowniczek K,Grzegorczyk I,Zabkowski T,Bajaj C",Gajowniczek K,10.3390/electronics9010099,Warsaw University of Life Sciences,"Construction of an ensemble model is a process of combining many diverse base predictive learners. It arises questions of how to weight each model and how to tune the parameters of the weighting process. The most straightforward approach is simply to average the base models. However, numerous studies have shown that a weighted ensemble can provide superior prediction results to a simple average of models. The main goals of this article are to propose a new weighting algorithm applicable for each tree in the Random Forest model and the comprehensive examination of the optimal parameter tuning. Importantly, the approach is motivated by its flexibility, good performance, stability, and resistance to overfitting. The proposed scheme is examined and evaluated on the Physionet/Computing in Cardiology Challenge 2015 data set. It consists of signals (electrocardiograms and pulsatory waveforms) from intensive care patients which triggered an alarm for five cardiac arrhythmia types (Asystole, Bradycardia, Tachycardia, Ventricular Tachycardia, and Ventricular Fultter/Fibrillation). The classification problem regards whether the alarm should or should not have been generated. It was proved that the proposed weighting approach improved classification accuracy for the three most challenging out of the five investigated arrhythmias comparing to the standard Random Forest model.","arrhythmia,false alarm,weighted random forest,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"REDUCING,FALSE,ALARMS,VENTRICULAR-FIBRILLATION,FEATURE-SELECTION,EXTRACTION,ICU",ELECTRONICS,https://www.mdpi.com/2079-9292/9/1/99/pdf,
52,Fusion High-Resolution Network for Diagnosing ChestX-ray Images,9,1,,"Huang Zhiwei,Lin Jinzhao,Xu Liming,Wang Huiqian,Bai Tong,Pang Yu,Meen Teen-Hang","Huang ZW,Lin JZ,Xu LM,Wang HQ,Bai T,Pang Y,Meen TH",Lin JZ; Pang Y,10.3390/electronics9010190,Chongqing University of Posts & Telecommunications,"The application of deep convolutional neural networks (CNN) in the field of medical image processing has attracted extensive attention and demonstrated remarkable progress. An increasing number of deep learning methods have been devoted to classifying ChestX-ray (CXR) images, and most of the existing deep learning methods are based on classic pretrained models, trained by global ChestX-ray images. In this paper, we are interested in diagnosing ChestX-ray images using our proposed Fusion High-Resolution Network (FHRNet). The FHRNet concatenates the global average pooling layers of the global and local feature extractors-it consists of three branch convolutional neural networks and is fine-tuned for thorax disease classification. Compared with the results of other available methods, our experimental results showed that the proposed model yields a better disease classification performance for the ChestX-ray 14 dataset, according to the receiver operating characteristic curve and area-under-the-curve score. An ablation study further confirmed the effectiveness of the global and local branch networks in improving the classification accuracy of thorax diseases.","thorax disease classification,deep learning,ChestX-ray 14 dataset,feature fusion",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,,ELECTRONICS,https://www.mdpi.com/2079-9292/9/1/190/pdf,
53,Leukemia Image Segmentation Using a Hybrid Histogram-Based Soft Covering Rough K-Means Clustering Algorithm,9,1,,"Inbarani Hannah H.,Azar Ahmad Taher,Jothi G.","Inbarani HH,Azar AT,Jothi G",Azar AT,10.3390/electronics9010188,Prince Sultan University,"Segmenting an image of a nucleus is one of the most essential tasks in a leukemia diagnostic system. Accurate and rapid segmentation methods help the physicians identify the diseases and provide better treatment at the appropriate time. Recently, hybrid clustering algorithms have started being widely used for image segmentation in medical image processing. In this article, a novel hybrid histogram-based soft covering rough k-means clustering (HSCRKM) algorithm for leukemia nucleus image segmentation is discussed. This algorithm combines the strengths of a soft covering rough set and rough k-means clustering. The histogram method was utilized to identify the number of clusters to avoid random initialization. Different types of features such as gray level co-occurrence matrix (GLCM), color, and shape-based features were extracted from the segmented image of the nucleus. Machine learning prediction algorithms were applied to classify the cancerous and non-cancerous cells. The proposed strategy is compared with an existing clustering algorithm, and the efficiency is evaluated based on the prediction metrics. The experimental results show that the HSCRKM method efficiently segments the nucleus, and it is also inferred that logistic regression and neural network perform better than other prediction algorithms.","leukemia nucleus image,segmentation,soft covering rough set,clustering,soft computing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"FEATURE-SELECTION,CLASSIFICATION,AGREEMENT,DIAGNOSIS,PSO",ELECTRONICS,https://www.mdpi.com/2079-9292/9/1/188/pdf,
54,Deep Learning-Based Stacked Denoising and Autoencoder for ECG Heartbeat Classification,9,1,,"Nurmaini Siti,Darmawahyuni Annisa,Mukti Akhmad Noviar Sakti,Rachmatullah Muhammad Naufal,Firdaus Firdaus,Tutuko Bambang","Nurmaini S,Darmawahyuni A,Mukti ANS,Rachmatullah MN,Firdaus F,Tutuko B",Nurmaini S,10.3390/electronics9010135,Universitas Sriwijaya,"The electrocardiogram (ECG) is a widely used, noninvasive test for analyzing arrhythmia. However, the ECG signal is prone to contamination by different kinds of noise. Such noise may cause deformation on the ECG heartbeat waveform, leading to cardiologists' mislabeling or misinterpreting heartbeats due to varying types of artifacts and interference. To address this problem, some previous studies propose a computerized technique based on machine learning (ML) to distinguish between normal and abnormal heartbeats. Unfortunately, ML works on a handcrafted, feature-based approach and lacks feature representation. To overcome such drawbacks, deep learning (DL) is proposed in the pre-training and fine-tuning phases to produce an automated feature representation for multi-class classification of arrhythmia conditions. In the pre-training phase, stacked denoising autoencoders (DAEs) and autoencoders (AEs) are used for feature learning; in the fine-tuning phase, deep neural networks (DNNs) are implemented as a classifier. To the best of our knowledge, this research is the first to implement stacked autoencoders by using DAEs and AEs for feature learning in DL. Physionet's well-known MIT-BIH Arrhythmia Database, as well as the MIT-BIH Noise Stress Test Database (NSTDB). Only four records are used from the NSTDB dataset: 118 24 dB, 118 -6 dB, 119 24 dB, and 119 -6 dB, with two levels of signal-to-noise ratio (SNRs) at 24 dB and -6 dB. In the validation process, six models are compared to select the best DL model. For all fine-tuned hyperparameters, the best model of ECG heartbeat classification achieves an accuracy, sensitivity, specificity, precision, and F1-score of 99.34%, 93.83%, 99.57%, 89.81%, and 91.44%, respectively. As the results demonstrate, the proposed DL model can extract high-level features not only from the training data but also from unseen data. Such a model has good application prospects in clinical practice.","heartbeat classification,arrhythmia,denoising autoencoder,autoencoder,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"SUPPORT,VECTOR,MACHINES",ELECTRONICS,https://www.mdpi.com/2079-9292/9/1/135/pdf,
55,Diagnostic Classification of Undifferentiated Fevers Using Artificial Neural Network,2236,,,"Vasudeva Shrivathsa Thokur,Rao Shrikantha Sasihithlu,Panambur Navin Karanth,Mahabala Chakrapani,Dakappa Pradeepa Hoskere,Prasad Keerthana","Vasudeva ST,Rao SS,Panambur NK,Mahabala C,Dakappa PH,Prasad K",Rao SS,10.1063/5.0007749,National Institute of Technology (NIT System),"Accurate diagnosis of undifferentiated fever case at the earliest is a challenging effort, which needs extensive diagnostic tests. Prediction of undifferentiated fever cases at an early stage will help in diagnosing the disease in comparatively lesser time and more effectively. The aim of the present study was to apply Artificial Intelligence (AI) algorithm using temperature information for the prediction of major categories of diseases among undifferentiated fever cases. This was an observational study carried out in tertiary care hospital. Total of 103 patients were involved in the study and 24-hour continuous temperature recording was done. Analysis was done using Artificial Neural Network (ANN) model based on the temperature data of each patients and its statistical parameters. Temperature datasets were labeled with the help of experienced physicians. Levenberg Marquardt error back-propagation algorithm was used to train the network. A good relation was found between the target data set and output data set, purely based on the observed 24 hr continuous tympanic temperature of the patients. An accuracy of 98.1% was obtained from ANN prediction model. The study concluded that a single noninvasive temperature parameter is sufficient to predict the major categories of diseases using ANN algorithms, from the undifferentiated fever cases.","Diseases,Prediction,Fever,Artificial Intelligence,Neural network",Proceedings Paper,"AMER INST PHYSICS, 2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA",Engineering,,,,,,
56,Using the Convolution Neural Network Attempts to Match Japanese Women's Kimono and Obi,11,1,66-71,"Komizo Kumiko,Kuwahara Noriaki","Komizo K,Kuwahara N",Komizo K,,Kyoto Institute of Technology,"Currently, the decline in kimono usage in Japan is serious. This has become an important problem for the kimono industry and kimono culture. The reason behind this lack of usage is that Japanese clothing has many strict rules attached to it. One of those difficult rules is that kimonos have status, and one must consider the proper kimono to wear depending on the place and type of event. At the same time, the obi (sash) also has status, and the status of the kimono and obi must match. The matching of the kimono and obi is called ""obiawase"" in Japanese, and it is not just a matter of the person wearing the kimono selecting a pair that she likes. Instead, the first place you wear a kimono determines its status, and the obi must match that status and kimono. In other words, the color, material, meaning behind the pattern must be matched with obi. Kimono patterns may evoke the seasons or a celebratory event. All this must be considered. The kimono was originally everyday wear, and people were taught these things in their households, but with today's increasingly nuclear families, that person who could teach these things isn't nearby, adding to the lack of use of kimonos. Because of this, there has been interest in using CNN (Convolution Neural Network) from the digital fashion industry. We are attempting to use machine learning to tackle the difficult task of matching an obi to a kimono, using the CNN machines drawing the most attention today.","Digital fashion,kimono,obi,convolution neural network",Article,"SCIENCE & INFORMATION SAI ORGANIZATION LTD, 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND",Computer Science,,,,INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS,,
57,Maternal ECG removal using short time Fourier transform and convolutional auto-encoder,23,2,160-175,"Zhong Wei,Guo Xuemei,Wang Guoli","Zhong W,Guo XM,Wang GL",Wang GL,,Sun Yat Sen University,"Foetal electrocardiography (FECG) plays an important role in prenatal monitoring. However, the abdominal electrocardiography (AECG) recorded at the maternal abdomen is significantly affected by the maternal electrocardiography (MECG), making the extraction of FECG a challenging task. This paper presents a deep learning method for MECG removal from single-channel AECG. Firstly, the short time Fourier transform (STFT) is applied to obtain the two-dimensional (2D) features of AECG in time-frequency domain. Secondly, the Convolutional Auto-encoder (CAE) is used to estimate the 2D features of MECG. Finally, after subtracting the estimated MECG, the FECG can be extracted from the AECG. Unlike the methods eliminated the MECG in the 1D time domain, the proposed method focuses on estimating the MECG in the 2D time-frequency domain, where we can take advantage of the structured information in the ECG data. Experimental results on two FECG databases show that the proposed method is effective in eliminating the features of MECG. This study facilitates the clinical applications of FECG in the foetal monitoring.","foetal monitoring,convolutional auto-encoder,FECG extraction,MECG removal,short time Fourier transform",Article,"INDERSCIENCE ENTERPRISES LTD, WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 856, CH-1215 GENEVA, SWITZERLAND",Mathematical & Computational Biology,,0.743,"FETAL,ELECTROCARDIOGRAM,EXTRACTION",INTERNATIONAL JOURNAL OF DATA MINING AND BIOINFORMATICS,,
58,"Estimation of centroid, ensembles, anomaly and association for the uniqueness of human footprint features",8,2,117-137,"Nagwanshi Kapil Kumar,Dubey Sipi","Nagwanshi KK,Dubey S",Nagwanshi KK,,SVKM's NMIMS (Deemed to be University),"Present study proposes an approach for the estimation of the distinctiveness of human footprints under the machine learning environment. In this system, a sum of 880 raw footprints have been segmented to get the 21 features for ensemble learning. All the features have been analysed for computation of minimum, mean grey value, median, maximum, standard deviation, kurtosis, and skewness for footprint dataset. The G-means clustering offers centroid information of footprint features. A set of 10 ensembles has analysed for surrogate footprint attributes. Ten anomaly models were created for anomaly scores among these features. The association of features gives the uniqueness of the human footprints for personal identification through fuzzy rules for every set of ensembles. As a consequence, centroid, ensembles, anomaly, and affiliation proved the individuality of human footprints.","anomaly score,association,centroid,ensemble,footprint,G-means cluster,machine learning,recognition,rule-base,segmentation",Article,"INDERSCIENCE ENTERPRISES LTD, WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 856, CH-1215 GENEVA, SWITZERLAND",Computer Science,,,"GAIT,RECOGNITION,IDENTIFICATION,SHAPE",INTERNATIONAL JOURNAL OF INTELLIGENT ENGINEERING INFORMATICS,,
59,Artificial neural network modeling and genetic algorithm optimization of process parameters in fluidized bed drying of green tea leaves,43,1,,"Kalathingal Muhammed Sirajul Huda,Basak Suradeep,Mitra Jayeeta","Kalathingal MSH,Basak S,Mitra J",Mitra J,10.1111/jfpe.13128,Indian Institute of Technology System (IIT System),"The present study involved integration of artificial neural network (ANN) with genetic algorithm (GA) for predicting the optimized process parameters required for fluidized bed drying of green tea leaves. It had a layer each for input and output with linear activation function and two hidden layers with a sigmoid function. The feed forward back propagation method was used to train the developed model. The input parameters used by ANN for generalizing the drying process were temperature (50-80 degrees C) and air flow velocity (7-9.5 m/s), and the output parameters were drying time, total color difference (TCD), and total phenolic content (TPC). The weights and bias values of trained ANN were used by GA to estimate the fitness function, which maximizes the TPC and minimizes the drying time and TCD. The optimum process condition of independent variables (80 degrees C and 9 m/s) obtained from the hybrid ANN/GA was validated, and agreeable relationship between actual and predicted values with relative standard deviation (SD) of 5.7, 0.46, and 0.22 was found for drying time, TCD and TPC of dried leaves, respectively. Hence, under this optimal drying condition, best quality green tea can be obtained within the limits defined.","PREDICTION,QUALITY,COLOR,TECHNOLOGY,APPLES,ANN",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Food Science & Technology",,2.417,"PREDICTION,QUALITY,COLOR,TECHNOLOGY,APPLES,ANN",JOURNAL OF FOOD PROCESS ENGINEERING,,
60,Optimization of architectural art teaching model based on Naive Bayesian classification algorithm and fuzzy model,39,2,1965-1976,Liu Ying,Liu Y,Liu Y,10.3233/JIFS-179966,Inner Mongolia University of Technology,"At present, the teaching of architectural art in China is still relatively traditional, and there are still some problems in the actual teaching. Based on this, this study combines the Naive Bayesian classification algorithm with the fuzzy model to construct a new architectural art teaching model. In teaching, the Naive Bayesian classification algorithm generates only a small number of features for each item in the training set, and it only uses the probability calculated in the mathematical operation to train and classify the item. Moreover, by combining the fuzzy model, the materials needed for architectural art teaching can be quickly generated, and the teaching principles and implementation strategies of architectural art are summarized. In addition, this paper proposes an attribute weighted classification algorithm combining differential evolution algorithm with Naive Bayes. The algorithm assigns weights to each attribute based on the Naive Bayesian classification algorithm and uses differential evolution algorithm to optimize the weights. The research shows that the method proposed in this paper has certain effect on the optimization of architectural art teaching mode.","Bayesian classification algorithm,fuzzy model,architectural art,differential evolution algorithm",Article,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS",Computer Science,,1.797,"ENERGY,SIMULATION",JOURNAL OF INTELLIGENT & FUZZY SYSTEMS,,
61,Prediction of epileptic seizures using fNIRS and machine learning,38,2,2055-2068,"Guevara Edgar,Flores-Castro Jorge-Arturo,Peng Ke,Dang Khoa Nguyen,Lesage Frederic,Pouliot Philippe,Rosas-Romero Roberto","Guevara E,Flores-Castro JA,Peng K,Nguyen DK,Lesage F,Pouliot P,Rosas-Romero R",Rosas-Romero R,10.3233/JIFS-190738,Universidad Americas Puebla (UDLAP),"Research to predict epileptic seizures has been mainly focused on the analysis of electroencephalography (EEG) signals; however, recent research efforts have encouraged the use of a relatively new optical signal modality, called functional Near-Infrared Spectroscopy (fNIRS). In fNIRS, near-infrared light is injected into the scalp and the intensity of the reflected light is registered in optodes. Light absorption in hemoglobin depends on the level of blood oxygenation, which is related to brain activity. In this technique, two parameters are measured at each optode, the relative level of oxygenated hemoglobin (HbO) and the relative level of deoxygenated hemoglobin (HbR).
In this work we investigated the feasibility of predicting epileptic seizures, using either fNIRS, EEG, or a combination of both signals. In one set of experiments, different implementations for epileptic seizure prediction are tested by using (1) different combinations of electrical and optical signals (EEG, HbO, HbR, EEG+HbO, EEG+HbR, HbO+HbR, EEG+HbO+HbR) and (2) two different classifiers, (Support Vector Machine - SVM and Multi-Layer Perceptron - MLP). In the second set of experiments, seizures are predicted within a five-minute window that is moved up to 15 minutes before the start of the epileptic seizure.
By computing the Positive Predictive Value (PPV) and the accuracy, it is demonstrated that fNIRS -based epileptic prediction outperforms EEG-based epileptic prediction. By using optical signals and the SVM classifier, a PPV greater than 99% and an accuracy of 100% were obtained. PPV values of 100% are also obtained when seizures are predicted up to 15 minutes in advance. Furthermore, Kernel Discriminant Analysis (KDA) is used to demonstrate that the highest separability among the classes, corresponding to different epileptic signal phases (pre-ictal, ictal, and inter-ictal), is achieved when fNIRS recordings are used as features for prediction. Finally, fNIRS-based epileptic seizure prediction is tested with Random Chance classifiers.
In this study, we showed that fNIRS signals are an effective tool to predict epileptic seizures, even without the use of EEG signals, which are the current standard for seizure prediction.","Epileptic seizure,seizure prediction,functional near infrared spectroscopy (fNIRS),electroencephalogram (EEG),multi-layer perceptron (MLP),support vector machine (SVM)",Article,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS",Computer Science,,1.797,"NEAR-INFRARED,SPECTROSCOPY,EEG,FMRI,NIRS,ALGORITHM,FEATURES,MODEL",JOURNAL OF INTELLIGENT & FUZZY SYSTEMS,,
62,Quantification of sheet nacre morphogenesis using X-ray nanotomography and deep learning,209,1,,"Beliaev Maksim,Zollner Dana,Pacureanu Alexandra,Zaslansky Paul,Bertinetti Luca,Zlotnikov Igor","Beliaev M,Zollner D,Pacureanu A,Zaslansky P,Bertinetti L,Zlotnikov I",Zlotnikov I,10.1016/j.jsb.2019.107432,Technische Universitat Dresden,"High-resolution three-dimensional imaging is key to our understanding of biological tissue formation and function. Recent developments in synchrotron-based X-Ray tomography techniques provide unprecedented morphological information on relatively large sample volumes with a spatial resolution better than 50 nm. However, the analysis of the generated data, in particular image segmentation - separation into structure and background - still presents a significant challenge, especially when considering complex biomineralized structures that exhibit hierarchical arrangement of their constituents across many length scales - from millimeters down to nanometers. In the present work, synchrotron-based holographic nano-tomography data are combined with state-of-the-art machine learning methods to image and analyze the nacreous architecture in the bivalve Unio pictortun in 3D. Using kinetic and thermodynamic considerations known from physics of materials, the obtained spatial information is then used to provide a quantitative description of the structural and topological evolution of nacre during shell formation. Ultimately, this study establishes a workflow for high-resolution three-dimensional analysis of fine highly-mineralized biological tissues while providing a detailed analytical view on nacre morphogenesis.","Tomography,Machine learning,Biomineralization,Grain growth,Nacre",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Biochemistry & Molecular Biology,Biophysics,Cell Biology",,4.474,"MECHANICAL-PROPERTIES,SHELL,GROWTH,LAYER,ARRANGEMENT,NUCLEATION,BIVALVIA,MOLLUSCA,MATRIX",JOURNAL OF STRUCTURAL BIOLOGY,,
63,Deep learning-based CAD schemes for the detection and classification of lung nodules from CT images: A survey,28,4,591-617,"Mastouri Rekka,Khlifa Nawres,Neji Henda,Hantous-Zannad Saoussen","Mastouri R,Khlifa N,Neji H,Hantous-Zannad S",Mastouri R,10.3233/XST-200660,Universite de Tunis-El-Manar,"BACKGROUND: Lung cancer is the most common cancer in the world. Computed tomography (CT) is the standard medical imaging modality for early lung nodule detection and diagnosis that improves patient's survival rate. Recently, deep learning algorithms, especially convolutional neural networks (CNNs), have become a preferred methodology for developing computer-aided detection and diagnosis (CAD) schemes of lung CT images.
OBJECTIVE: Several CNN-based research projects have been initiated to design robust and efficient CAD schemes for the detection and classification of lung nodules. This paper reviews the recent works in this area and gives an insight into technical progress.
METHODS: First, a brief overview of CNN models and their basic structures is presented in this investigation. Then, we provide an analytic comparison of the existing approaches to discover recent trend and upcoming challenges. We also introduce an objective description of both handcrafted and deep learning features, as well as the types of nodules, the medical imaging modalities, the widely used databases, and related works in the last three years. The articles presented in this work were selected from various databases. About 57% of reviewed articles published in the last year.
RESULTS: Our analysis reveals that several methods achieved promising performance with high sensitivity rates ranging from 66% to 100% under the false-positive rates ranging from 1 to 15 per CT scan. It can be noted that CNN models have contributed to the accurate detection and early diagnosis of lung nodules.
CONCLUSIONS: From the critical discussion and an outline for prospective directions, this survey provide researchers valuable information to master the deep learning concepts and to deepen their knowledge of the trend and latest techniques in developing CAD schemes of lung CT images.","CAD of CT images,deep learning,lung cancer screening,lung nodule detection,lung nodule classification",Article,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Optics,Physics",,1.159,"FALSE-POSITIVE,REDUCTION,CONVOLUTIONAL,NEURAL-NETWORKS,COMPUTER-AIDED,DETECTION,PULMONARY,NODULES,AUTOMATIC,DETECTION,DATABASE,CONSORTIUM,TOMOGRAPHY,ENSEMBLE,CANCER,VALIDATION",JOURNAL OF X-RAY SCIENCE AND TECHNOLOGY,,
64,Detection of coronavirus disease from X-ray images using deep learning and transfer learning algorithms,28,5,841-850,"Albahli Saleh,Albattah Waleed","Albahli S,Albattah W",Albahli S,10.3233/XST-200720,Qassim University,"OBJECTIVE: This study aims to employ the advantages of computer vision and medical image analysis to develop an automated model that has the clinical potential for early detection of novel coronavirus (COVID-19) infected disease.
METHOD: This study applied transfer learning method to develop deep learning models for detecting COVID-19 disease. Three existing state-of-the-art deep learning models namely, Inception ResNetV2, InceptionNetV3 and NASNetLarge, were selected and fine-tuned to automatically detect and diagnose COVID-19 disease using chest X-ray images. A dataset involving 850 images with the confirmed COVID-19 disease, 500 images of community-acquired (non-COVID-19) pneumonia cases and 915 normal chest X-ray images was used in this study.
RESULTS: Among the three models, InceptionNetV3 yielded the best performance with accuracy levels of 98.63% and 99.02% with and without using data augmentation in model training, respectively. All the performed networks tend to overfitting (with high training accuracy) when data augmentation is not used, this is due to the limited amount of image data used for training and validation.
CONCLUSION: This study demonstrated that a deep transfer learning is feasible to detect COVID-19 disease automatically from chest X-ray by training the learning model with chest X-ray images mixed with COVID-19 patients, other pneumonia affected patients and people with healthy lungs, which may help doctors more effectively make their clinical decisions. The study also gives an insight to how transfer learning was used to automatically detect the COVID-19 disease. In future studies, as the amount of available dataset increases, different convolution neutral network models could be designed to achieve the goal more efficiently.","Deep learning,novel coronavirus,detection of COVID-19,chest X-ray images,automatic detections,transfer learning,InceptioNetV3,NASNetlarge",Article,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Optics,Physics",,1.159,"CHEST,RADIOGRAPHS,COMPUTERIZED,METHOD,POSTEROANTERIOR,VIEWS",JOURNAL OF X-RAY SCIENCE AND TECHNOLOGY,https://europepmc.org/articles/pmc7592683?pdf=render,
65,An enhanced OCT image captioning system to assist ophthalmologists in detecting and classifying eye diseases,28,5,975-988,"Vellakani Sivamurugan,Pushbam Indumathi","Vellakani S,Pushbam I",Vellakani S,10.3233/XST-200697,Anna University,"Human eye is affected by the different eye diseases including choroidal neovascularization (CNV), diabetic macular edema (DME) and age-related macular degeneration (AMD). This work aims to design an artificial intelligence (AI) based clinical decision support system for eye disease detection and classification to assist the ophthalmologists more effectively detecting and classifying CNV, DME and drusen by using the Optical Coherence Tomography (OCT) images depicting different tissues. The methodology used for designing this system involves different deep learning convolutional neural network (CNN) models and long short-term memory networks (LSTM). The best image captioning model is selected after performance analysis by comparing nine different image captioning systems for assisting ophthalmologists to detect and classify eye diseases. The quantitative data analysis results obtained for the image captioning models designed using DenseNet201 with LSTM have superior performance in terms of overall accuracy of 0.969, positive predictive value of 0.972 and true-positive rate of 0.969using OCT images enhanced by the generative adversarial network (GAN). The corresponding performance values for the Xception with LSTM image captioning models are 0.969, 0.969 and 0.938, respectively. Thus, these two models yield superior performance and have potential to assist ophthalmologists in making optimal diagnostic decision.","Age-related macular degeneration (AMD),connective tissue,choroidal neovascularization (CNV),light sensitive tissue,Optical Coherence Tomography (OCT),deep learning,convolution neural network (CNN),long short term memory (LSTM),neovascular tissue,surrounding tissue",Article,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Optics,Physics",,1.159,,JOURNAL OF X-RAY SCIENCE AND TECHNOLOGY,,
66,Interpretable Deep Models for Cardiac Resynchronisation Therapy Response Prediction.,2020,,284-293,,,,10.1007/978-3-030-59710-8_28,,"Advances in deep learning (DL) have resulted in impressive accuracy in some medical image classification tasks, but often deep models lack interpretability. The ability of these models to explain their decisions is important for fostering clinical trust and facilitating clinical translation. Furthermore, for many problems in medicine there is a wealth of existing clinical knowledge to draw upon, which may be useful in generating explanations, but it is not obvious how this knowledge can be encoded into DL models - most models are learnt either from scratch or using transfer learning from a different domain. In this paper we address both of these issues. We propose a novel DL framework for image-based classification based on a variational autoencoder (VAE). The framework allows prediction of the output of interest from the latent space of the autoencoder, as well as visualisation (in the image domain) of the effects of crossing the decision boundary, thus enhancing the interpretability of the classifier. Our key contribution is that the VAE disentangles the latent space based on 'explanations' drawn from existing clinical knowledge. The framework can predict outputs as well as explanations for these outputs, and also raises the possibility of discovering new biomarkers that are separate (or disentangled) from the existing knowledge. We demonstrate our framework on the problem of predicting response of patients with cardiomyopathy to cardiac resynchronization therapy (CRT) from cine cardiac magnetic resonance images. The sensitivity and specificity of the proposed model on the task of CRT response prediction are 88.43% and 84.39% respectively, and we showcase the potential of our model in enhancing understanding of the factors contributing to CRT response.",Cardiac MRI; Cardiac resynchronization therapy; Interpretable ML; Variational autoencoder,Journal Article,,,,,,,,
67,Application of Supervised Machine-Learning Methods for Attesting Provenance in Catalan Traditional Pottery Industry,10,1,,"Anglisano Anna,Casas Lluis,Anglisano Marc);,Queralt Ignasi","Anglisano A,Casas L,Anglisano M,Queralt I",Casas L,10.3390/min10010008,Autonomous University of Barcelona,"The traditional pottery industry was an important activity in Catalonia (NE Spain) up to the 20th century. However, nowadays only few workshops persist in small villages were the activity is promoted as a touristic attraction. The preservation and promotion of traditional pottery in Catalonia is part of an ongoing strategy of tourism diversification that is revitalizing the sector. The production of authenticable local pottery handicrafts aims at attracting cultivated and high-purchasing power tourists. The present paper inspects several approaches to set up a scientific protocol based on the chemical composition of both raw materials and pottery. These could be used to develop a seal of quality and provenance to regulate the sector. Six Catalan villages with a renowned tradition of local pottery production have been selected. The chemical composition of their clays and the corresponding fired products has been obtained by Energy dispersive X-ray fluorescence (EDXRF). Using the obtained geochemical dataset, a number of unsupervised and supervised machine learning methods have been applied to test their applicability to define geochemical fingerprints that could allow inter-site discrimination. The unsupervised approach fails to distinguish samples from different provenances. These methods are only roughly able to divide the different provenances in two large groups defined by their different SiO2 and CaCO3 concentrations. In contrast, almost all the tested supervised methods allow inter-site discrimination with accuracy levels above 80%, and accuracies above 85% were obtained using a meta-model combining all the predictive supervised methods. The obtained results can be taken as encouraging and demonstrative of the potential of the supervised approach as a way to define geochemical fingerprints to track or attest the provenance of samples.","pottery industry,local products,clay,provenance,predictive modeling,supervised methods,geochemistry,XRF",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Geochemistry & Geophysics,Mineralogy,Mining & Mineral Processing",,2.737,"ARTIFICIAL,NEURAL-NETWORKS,CLAY,XRD,CLASSIFICATION,DESIGN",MINERALS,https://digital.csic.es/bitstream/10261/213919/1/Application%20of%20Supervised%20Machine-Learning%20Methods%20for%20Attesting%20Provenance%20in%20Catalan%20Traditional%20Pottery%20Industry.pdf,
68,Posture transition analysis with barometers: contribution to accelerometer-based algorithms,32,2,335-349,"Rodriguez-Martin Daniel,Sama Albert,Perez-Lopez Carlos,Catala Andreu,Cabestany Joan","Rodriguez-Martin D,Sama A,Perez-Lopez C,Catala A,Cabestany J",Rodriguez-Martin D,10.1007/s00521-018-3759-8,Polytechnic University of Catalonia,"Posture transitions are one of the most mechanically demanding tasks and are useful to evaluate the motor status of patients with motor impairments, frail individuals or the elderly, among others. So far, wearable inertial systems have been one of the most employed tools in the study of these movements due to their suitable size and weight, being non-invasive systems. These devices are mainly composed of accelerometers and, to a lesser extent, gyroscopes, magnetometers or barometers. Although accelerometers provide the most reliable measurement, detecting activities where a change of altitude is observed, such as some posture transitions, may require additional sensors to reliably detect these activities. In this work, we present an algorithm that combines the information of a barometer and an accelerometer to detect posture transitions and falls. In contrast to other works, we test different activities (where altitude is involved) in order to achieve a reliable classifier against false positives. Furthermore, by means of feature selection methods, we obtain optimal subsets of features for the accelerometer and barometer sensors to contextualise these activities. The selected features are tested through several machine learning classifiers, which are assessed with an evaluation data set. Results show that the inclusion of barometer features in addition to those obtained for an accelerometer clearly enhances the detection accuracy up to a 11%, in terms of geometric mean between sensitivity and specificity, compared to algorithms where only the accelerometer is used. Finally, we have also analysed the computer burden; in this sense, the usage of barometers, in addition to increase the accuracy, also reduces the computational resources required to classify a new pattern, as shown by a reduction in the number of support vectors.","Accelerometer,Barometer,Human activity recognition",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"PHYSICAL-ACTIVITY,PRESSURE,SENSORS,RECOGNITION,GAIT,IDENTIFICATION,MOVEMENT,DISEASE,SYSTEM",NEURAL COMPUTING & APPLICATIONS,,
69,Machine-Learning-Assisted De Novo Design of Organic Molecules and Polymers: Opportunities and Challenges,12,1,,"Chen Guang,Shen Zhiqiang,Iyer Akshay,Ghumman Umar Farooq,Tang Shan,Bi Jinbo,Chen Wei,Li Ying","Chen G,Shen ZQ,Iyer A,Ghumman UF,Tang S,Bi JB,Chen W,Li Y",Li Y,10.3390/polym12010163,University of Connecticut,"Organic molecules and polymers have a broad range of applications in biomedical, chemical, and materials science fields. Traditional design approaches for organic molecules and polymers are mainly experimentally-driven, guided by experience, intuition, and conceptual insights. Though they have been successfully applied to discover many important materials, these methods are facing significant challenges due to the tremendous demand of new materials and vast design space of organic molecules and polymers. Accelerated and inverse materials design is an ideal solution to these challenges. With advancements in high-throughput computation, artificial intelligence (especially machining learning, ML), and the growth of materials databases, ML-assisted materials design is emerging as a promising tool to flourish breakthroughs in many areas of materials science and engineering. To date, using ML-assisted approaches, the quantitative structure property/activity relation for material property prediction can be established more accurately and efficiently. In addition, materials design can be revolutionized and accelerated much faster than ever, through ML-enabled molecular generation and inverse molecular design. In this perspective, we review the recent progresses in ML-guided design of organic molecules and polymers, highlight several successful examples, and examine future opportunities in biomedical, chemical, and materials science fields. We further discuss the relevant challenges to solve in order to fully realize the potential of ML-assisted materials design for organic molecules and polymers. In particular, this study summarizes publicly available materials databases, feature representations for organic molecules, open-source tools for feature generation, methods for molecular generation, and ML models for prediction of material properties, which serve as a tutorial for researchers who have little experience with ML before and want to apply ML for various applications. Last but not least, it draws insights into the current limitations of ML-guided design of organic molecules and polymers. We anticipate that ML-assisted materials design for organic molecules and polymers will be the driving force in the near future, to meet the tremendous demand of new materials with tailored properties in different fields.","de novo materials design,machine learning,data-driven algorithm,organic molecules,polymers,materials database",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Polymer Science,,4.493,"LIGHT-EMITTING-DIODES,FIELD-EFFECT,TRANSISTORS,DEVELOPMENT,KIT,CDK,SOURCE,JAVA,LIBRARY,CHEMICAL,UNIVERSE,INFORMATION-SYSTEM,NEURAL-NETWORKS,DRUG,DISCOVERY,PERFORMANCE,PHOTOVOLTAICS",POLYMERS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7023065,
70,An Investigation of Various Machine and Deep Learning Techniques Applied in Automatic Fear Level Detection and Acrophobia Virtual Therapy,20,2,,"Balan Oana,Moise Gabriela,Moldoveanu Alin,Leordeanu Marius,Moldoveanu Florica","Balan O,Moise G,Moldoveanu A,Leordeanu M,Moldoveanu F",Balan O,10.3390/s20020496,Polytechnic University of Bucharest,"In this paper, we investigate various machine learning classifiers used in our Virtual Reality (VR) system for treating acrophobia. The system automatically estimates fear level based on multimodal sensory data and a self-reported emotion assessment. There are two modalities of expressing fear ratings: the 2-choice scale, where 0 represents relaxation and 1 stands for fear; and the 4-choice scale, with the following correspondence: 0-relaxation, 1-low fear, 2-medium fear and 3-high fear. A set of features was extracted from the sensory signals using various metrics that quantify brain (electroencephalogram-EEG) and physiological linear and non-linear dynamics (Heart Rate-HR and Galvanic Skin Response-GSR). The novelty consists in the automatic adaptation of exposure scenario according to the subject's affective state. We acquired data from acrophobic subjects who had undergone an in vivo pre-therapy exposure session, followed by a Virtual Reality therapy and an in vivo evaluation procedure. Various machine and deep learning classifiers were implemented and tested, with and without feature selection, in both a user-dependent and user-independent fashion. The results showed a very high cross-validation accuracy on the training set and good test accuracies, ranging from 42.5% to 89.5%. The most important features of fear level classification were GSR, HR and the values of the EEG in the beta frequency range. For determining the next exposure scenario, a dominant role was played by the target fear level, a parameter computed by taking into account the patient's estimated fear level.","fear classification,emotional assessment,feature selection,affective computing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"EMOTION,RECOGNITION,REALITY,DISORDERS,ASYMMETRY",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7013944,
71,Investigation of Relationship Between Eye Gaze and Brain Waves towards Smart Sensing for E-learning,32,2,735-743,"Shimoda Koichi,Tanabe Shun,Tobe Yoshito","Shimoda K,Tanabe S,Tobe Y",Tobe Y,10.18494/SAM.2020.2621,Aoyama Gakuin University,"In recent years, we have witnessed a new trend of learning called e-learning where learners can take courses using electronic devices with Internet connection. Although e-learning is convenient because it removes temporal and spatial limitations, it is difficult to know whether the learner is really paying attention to the learning materials. To address this problem, we tried to use electroencephalography (EEG) to investigate a learner's concentration in our previous study. However, our previous study relied on subjective evaluation, and there was no objective observation to relate the EEG signals to the learner's concentration. Given this background, we compared eye gaze and EEG results to find the appropriate position and frequency band of EEG in e-learning in this study. We compared the EEG result obtained during a period when the subjects were watching a video lecture and that obtained during a period when the subjects were not watching, and determined that the viewing state could be predicted from EEG logistic regression and a support vector machine (SVM). The results suggested that measuring beta and gamma waves and examining the parietal and occipital regions are both effective.","electroencephalography,e-learning,eye gaze",Article,"MYU, SCIENTIFIC PUBLISHING DIVISION, 1-23-3-303 SENDAGI, TOKYO, 113-0022, JAPAN","Instruments & Instrumentation,Materials Science",,0.71,,SENSORS AND MATERIALS,https://myukk.org/SM2017/sm_pdf/SM2133.pdf,
72,Applying machine learning to predict the tensile shear strength of bonded beech wood as a function of the composition of polyurethane prepolymers and various pretreatments,54,1,19-29,"Schubert Mark,Klaeusler Oliver","Schubert M,Klaeusler O",Schubert M,10.1007/s00226-019-01144-6,Swiss Federal Laboratories for Materials Science & Technology (EMPA),"The present study showed that machine learning can be used to predict the tensile shear strength of bonded beech wood as a function of the composition of polyurethane prepolymers and various pretreatments. A comprehensive experimental data set was used for training and testing the algorithms support vector machines, random forest and artificial neural networks. Within the framework of the experiments, the structure-property relationships of 1C PUR prepolymers were analyzed by systematical variation of the structural parameters urea and urethane group content, cross-link density, ethylene oxide content, and the functionality via isocyanate (NCO) or polyether component. The bonded wood joints were tested according to DIN EN 302-1. Prior to testing, the shear test specimens were pretreated according to procedures A1 and A4, five temperature steps (5, 40, 70, 150 and 200 degrees C) and two alternating climates. The complete data set (N = 2840) was preprocessed and split into a training set and a test set using tenfold cross-validation. The performance of the algorithms was evaluated with the coefficient of determination (R-2), root-mean-square error (RMSE) and mean absolute percentage error (MAPE). All machine learning algorithms revealed a high accuracy, but the artificial neural network showed the best performance with R-2= 0.92, RMSE = 0.948 and a MAPE of 9.21. The work paves the way for future machine learning applications in the field of adhesive bonding technology and may enable a fast and effective development of new adhesives and enhance the efficiency of their application.","NEURAL-NETWORK PREDICTION,THERMAL-STABILITY,SOFT",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Forestry,Materials Science",,2.81,"NEURAL-NETWORK,PREDICTION,THERMAL-STABILITY,SOFT",WOOD SCIENCE AND TECHNOLOGY,,
73,Automatic Classification of Erythrocytes Using Artificial Neural Networks and Integral Geometry-Based Functions,,,156-163,"Paz-Soto Yaima,Herold-Garcia Silena,Fernandes Leandro A. F.,Diaz-Matos Saul","Paz-Soto Y,Herold-Garcia S,Fernandes LAF,Diaz-Matos S",Paz-Soto Y,10.1109/SIBGRAPI51738.2020.00029,"Univ Guantanamo, Engn & Thecn Sci Fac, Guantanamo, Cuba.","The red blood cell deformation caused by disorders like sickle cell disease can be assessed by observing blood samples under a microscope. This manual process is cumbersome and prone to errors but can be supported by automated techniques that allow red blood cells to be classified according to the shape they present. There are proposals in the literature that use functions based on integral geometry to obtain a description of the cells' contour before performing classification, reaching 96.16% accuracy with the use of the k-Nearest Neighbor (KNN) classifier. In those approaches, the classification-confusion cases persist mainly in the classes of most significant interest, which are those related to the detection of deformed cells. In this work, we use artificial neural networks-based classifiers, trained with the characteristics obtained from integral geometry-based functions, to classify erythrocytes into normal, sickle, and other deformations classes. Our proposal achieves accuracy of 98.40%. This result is superior to those of previous studies concerning the classes of greatest interest. Also, our approach is computationally more efficient than previous works, making it suitable for supporting medical follow-up diagnosis of sickle cell disease.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Imaging Science & Photographic Technology",,,,,,
74,A study on tooth segmentation and numbering using end-to-end deep neural networks,,,164-171,"Silva Bernardo,Pinheiro Lais,Oliveira Luciano,Pithon Matheus","Silva B,Pinheiro L,Oliveira L,Pithon M",Pithon M,10.1109/SIBGRAPI51738.2020.00030,Universidade Estadual do Sudoeste da Bahia,"Shape, number, and position of teeth are the main targets of a dentist when screening for patient's problems on X-rays. Rather than solely relying on the trained eyes of the dentists, computational tools have been proposed to aid specialists as decision supporter for better diagnoses. When applied to Xrays, these tools are specially grounded on object segmentation and detection. In fact, the very first goal of segmenting and detecting the teeth in the images is to facilitate other automatic methods in further processing steps. Although researches over tooth segmentation and detection are not recent, the application of deep learning techniques in the field is new and has not reached maturity yet. To fill some gaps in the area of dental image analysis, we bring a thorough study on tooth segmentation and numbering on panoramic X-ray images by means of end-to-end deep neural networks. For that, we analyze the performance of four network architectures, namely, Mask R-CNN, PANet, HTC, and ResNeSt, over a challenging data set. The choice of these networks was made upon their high performance over other data sets for instance segmentation and detection. To the best of our knowledge, this is the first study on instance segmentation, detection, and numbering of teeth on panoramic dental X-rays. We found that (i) it is completely feasible to detect, to segment, and to number teeth by through any of the analyzed architectures, (ii) performance can be significantly boosted with the proper choice of neural network architecture, and (iii) the PANet had the best results on our evaluations with an mAP of 71.3% on segmentation and 74.0% on numbering, raising 4.9 and 3.5 percentage points the results obtained with Mask R-CNN.","deep neural networks,instance segmentation and numbering,panoramic dental X-rays",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Imaging Science & Photographic Technology",,,"X-RAY,IMAGES,SYSTEM,TEETH",,,
75,MyFood: A Food Segmentation and Classification System to Aid Nutritional Monitoring,,,234-239,"Freitas Charles N. C.,Cordeiro Filipe R.,Macario Valmir","Freitas CNC,Cordeiro FR,Macario V",Freitas CNC,10.1109/SIBGRAPI51738.2020.00039,Universidade Federal Rural de Pernambuco (UFRPE),"The absence of food monitoring has contributed significantly to the increase in the population's weight. Due to the lack of time and busy routines, most people do not control and record what is consumed in their diet. Some solutions have been proposed in computer vision to recognize food images, but few are specialized in nutritional monitoring. This work presents the development of an intelligent system that classifies and segments food presented in images to help the automatic monitoring of user diet and nutritional intake. This work shows a comparative study of state-of-the-art methods for image classification and segmentation, applied to food recognition. In our methodology, we compare the FCN, ENet, SegNet, DeepLabV3+, and Mask RCNN algorithms. We build a dataset composed of the most consumed Brazilian food types, containing nine classes and a total of 1250 images. The models were evaluated using the following metrics: Intersection over Union, Sensitivity, Specificity, Balanced Precision, and Positive Predefined Value. We also propose an system integrated into a mobile application that automatically recognizes and estimates the nutrients in a meal, assisting people with better nutritional monitoring. The proposed solution showed better results than the existing ones in the market. The dataset is publicly available at the following link http://doi.org/10.5281/zenodo.4041488.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Imaging Science & Photographic Technology",,,,,http://arxiv.org/pdf/2012.03087,
76,Application of Machine Learning to Lightning Strike Probability Estimation,,,82-90,"Adekitan Aderibigbe,Rock Michael","Adekitan A,Rock M",Adekitan A,,Technische Universitat Ilmenau,"The risk of a lightning strike to a structure is influenced by geometry, the type of material of the structure, and proximity to other structures. The probability of lightning strike to different points on an object can be determined by applying the concept of probability modulated collection volume using the dynamic electro-geometrical model (DEGM). The numerical computation of the DEGM is computer resource-intensive and requires extensive programming and analysis to implement, which may be difficult to apply by engineers setting up lightning protection systems in the field. This study explores the feasibility of applying an artificial neural network (ANN) using a network with 18 hidden neurons and the Levenberg-Marquardt algorithm for training the model. The strike probability predictions by the neural network give close values to the numerical results. The ANN approach is further supported by predictive equation-based models developed using data pattern recognition and curve fitting techniques, as easy to use alternatives to the numerical DEGM simulations. The ANN model had an overall regression R-2 of 1, and it performed better than the equation-based model.","dynamic electro-geometrical model,interception efficiency,lightning current distribution,lightning protection system,artificial neural network,pattern recognition",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"DISTANCE,ROD",,,
77,Methods for the Prediction and Specification of Functionally Graded Multi-Grain Responsive Timber Composites,,,585-594,"Fragkia Vasiliki,Foged Isak Worre","Fragkia V,Foged IW",Fragkia V,,Aalborg University,"The paper presents design-integrated methods for high-resolution specification and prediction of functionally graded wood-based thermal responsive composites, using machine learning. The objective is the development of new circular design workflow, employing robotic fabrication, in order to predict fabrication files linked to material performance and design requirements, focused on application for intrinsic responsive and adaptive architectural surfaces. Through an experimental case study, the paper explores how machine learning can form a predictive design framework where low-resolution data can solve material systems at high resolution. The experimental computational and prototyping studies show that the presented image-based machine learning method can be adopted and adapted across various stages and scales of architectural design and fabrication. This in turn allows for a design-per-requirement approach that optimizes material distribution and promotes material economy.","responsive timber composites,machine learning,robotic fabrication,building envelopes",Proceedings Paper,"ECAADE-EDUCATION & RESEARCH COMPUTER AIDED ARCHITECTURAL DESIGN EUROPE, DEPT ARCHITECTURE SINT-LUCAS BRUSSELS-GHENT, HOGESCHOOL VOOR WETENSCHAP & KUNST, PALEIZENSTRAAT 65, BRUSSELS, 1030, BELGIUM","Architecture,Urban Studies",,,,,,
78,Designing with a Robot Interactive methods for brick wall design using computer vision,,,605-612,"Das Avishek,Foged Isak Worre,Jensen Mads Brath","Das A,Foged IW,Jensen MB",Das A,,Aalborg University,"The deterministic and linear nature of robotic processes in architectural construction often allows no or very little adjustments during the fabrication process. If any need for modification arise the process is usually interrupted, changes are accommodated, and the process is resumed or restarted. The rigidity in this fabrication process leaves little room for creative intervention and human activities and robotic process are often considered as two segregated processes.The paper will present and discuss the methodological and design challenges of interactive robotic fabrication of brickwork with an industrial robotic arm, a webcam and bricks with varying color tones. Emphasis will be on the integration of external computer vision libraries within Rhino Grasshopper to augment the interactive robotic process. The paper will describe and demonstrate a framework comprising (1) robotic pick and place, material selection and evaluation using computer vision, (2) interactive robotic actuation and (3) the role of human input during a probabilistic fabrication-based design process.","interactive robotic fabrication,human robot collaboration,computer vision,masonry,machine learning",Proceedings Paper,"ECAADE-EDUCATION & RESEARCH COMPUTER AIDED ARCHITECTURAL DESIGN EUROPE, DEPT ARCHITECTURE SINT-LUCAS BRUSSELS-GHENT, HOGESCHOOL VOOR WETENSCHAP & KUNST, PALEIZENSTRAAT 65, BRUSSELS, 1030, BELGIUM","Architecture,Urban Studies",,,,,,
79,Machine learning methods for the in-vitro analysis of preimplantation embryo Raman micro-spectroscopy,11582,,,"Karmenyan A. V,Kistenev Y. V,Perevedentseva E. V,Krivokharchenko A. S.,Sarmiento M. N.,Barus E. L.,Cheng C-L,Vrazhnov D. A.","Karmenyan AV,Kistenev YV,Perevedentseva EV,Krivokharchenko AS,Sarmiento MN,Barus EL,Cheng CL,Vrazhnov DA",Vrazhnov DA,10.1117/12.2580485,Tomsk State University,"The paper presents an analysis of the Raman spectra of mouse preimplantation embryos using machine learning for visualization, assessing the separability of classes, and highlighting informative areas of the spectrum. Separation of lipid reach areas and nucleus spectra was shown by principal component analysis coupled with a linear support vector machine.","Raman micro-spectroscopy,machine learning,PCA,early mammalian embryos",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Microscopy,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
80,"Classification of exhaled air IR spectra using combination support vector machine, decision tree, and k-nearest neighbor",11582,,,"Nikolaev V. V.,Kuzmin D. A.,Zasedatel V. S.","Nikolaev VV,Kuzmin DA,Zasedatel VS",Nikolaev VV,10.1117/12.2581563,"Institute of Strength Physics & Materials Science, Siberian Branch of the RAS","Non-invasive diagnosis of diseases using analysis of exhaled air are actively developing in medical practice. The aim of work is to compare a specifics groups of patients with pulmonary diseases. As features of the participants' state, absorption spectra of exhaled air samples were used. The analyzed spectrum is a bar chart which describes the dependence of the absorption coefficient on the wavelength. The problem to be solved is the choice of informative sub-ranges of spectra to improve the classification of the studied groups and the subsequent classification of several spectra for one person by voting methods. An integrated approach was used to solve this problem using the principal component analysis, support vector machine with RBF core and the subsequent voting technique.","absorption spectra,classification,support vector machine,decision tree,k-nearest neighbor",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Microscopy,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"OPTICAL,PARAMETRIC,OSCILLATOR,LUNG-CANCER,SPECTROSCOPY",,,
81,Breast cancer diagnosis and prediction model based on improved PSO-SVM based on gray relational analysis,,,231-234,"Chang Shuran,Liu Yian","Chang SR,Liu YA",Chang SR,10.1109/DCABES50732.2020.00067,Jiangnan University,"Early breast cancer diagnosis and prediction models use image data as input, which is likely to cause a large possibility of error in the conversion process of image data. Therefore, this paper proposes a PSO-SVM diagnostic prediction model called GP-SVM based on gray relational analysis (GRA) of a data set consisting of conventional sign data and blood analysis data. First of all, the original data set is optimized by gray relational analysis (GRA) to obtain a new data set. Secondly,the GP-SVM model composed of improved PSO and SVM,and uses the obtained data set as its input. The improvement point of its PSO algorithm is to dynamically adjust the inertial weights and learning factors to make the improved PSO The algorithm optimizes the parameters of SVM and balances the globality and speed of PSO algorithm convergence. On the breast cancer Coimbra data set in UCI, compared with other prediction models, the performance of the GP-SVM prediction model has better.","gray relational analysis,feature selection,improved PSO,GP-SVM model",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Computer Science,Engineering",,,,,,
82,Patching as Translation: the Data and the Metaphor,,,275-286,"Ding Yangruibo,Ray Baishakhi,Devanbu Premkumar,Hellendoorn Vincent J.","Ding YRB,Ray B,Devanbu P,Hellendoorn VJ",Ding YRB,10.1145/3324884.3416587,Columbia University,"Machine Learning models from other fields, like Computational Linguistics, have been transplanted to Software Engineering tasks, often quite successfully. Yet a transplanted model's initial success at a given task does not necessarily mean it is well-suited for the task. In this work, we examine a common example of this phenomenon: the conceit that ""software patching is like language translation"". We demonstrate empirically that there are subtle, but critical distinctions between sequence-to-sequence models and translation model: while program repair benefits greatly from the former, general modeling architecture, it actually suffers from design decisions built into the latter, both in terms of translation accuracy and diversity. Given these findings, we demonstrate how a more principled approach to model design, based on our empirical findings and general knowledge of software development, can lead to better solutions. Our findings also lend strong support to the recent trend towards synthesizing edits of code conditional on the buggy context, to repair bugs. We implement such models ourselves as ""proof-of-concept"" tools and empirically confirm that they behave in a fundamentally different, more effective way than the studied translation-based architectures. Overall, our results demonstrate the merit of studying the intricacies of machine learned models in software engineering: not only can this help elucidate potential issues that may be overshadowed by increases in accuracy; it can also help innovate on these models to raise the state-of-the-art further. We will publicly release our replication data and materials at https://github.com/ARiSE- Lab/Patch-as-translation.","neural machine translation,big code,sequence-to-sequence model,automated program repair",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Automation & Control Systems,Computer Science,Engineering",,,,,http://arxiv.org/pdf/2008.10707,
83,Lung CT image aided detection COVID-19 based on Alexnet network,,,199-203,"Wang Tao,Zhao Yongguo,Zhu Lin,Liu Guangliang,Ma Zhengguang,Zheng Jianghua","Wang T,Zhao YG,Zhu L,Liu GL,Ma ZG,Zheng JH",Zhao YG,,Qilu University of Technology,"In this article, we use the Alexnet network in deep learning to determine whether the lung CT images are infected with covid-19. First of all, in the data preprocessing stage, the original CT image data is scaled and normalized to reduce noise interference. The batch operation of training set and test set can increase the training speed;Secondly, build an eight-layer Alexnet network model, set reasonable hyperparameters for each layer of the network, define the loss function and optimizer, and use the processed data to train the weight parameters of each layer in the network model. Finally, three indicators of accuracy, accuracy and recall are used to quantify the effect of model classification, and the impact of different training times on these three indicators is compared to select the best classification model. At the same time, use pyqt5 to write the corresponding auxiliary detection interface to facilitate the display of test results and the selection of classification models. The construction of the network model, the definition of the loss function and the definition of the optimizer are all based on the Pytorch deep learning framework.","Deep learning,Alexnet neural network,Medical image",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Telecommunications",,,,"2020 5TH INTERNATIONAL CONFERENCE ON COMMUNICATION, IMAGE AND SIGNAL PROCESSING (CCISP 2020)",,
84,Para-sagittal Midclavicular Plane Localization in 3DCT Using Multi-Agent Dueling Network,,,219-223,"Li Yi,Zhou Guangquan,Wen Tiexiang,Zhou Shoujun","Li Y,Zhou GQ,Wen TX,Zhou SJ",Li Y,,Southeast University - China,"Locating the para-sagittal on the left portal vein in the abdominal enhanced 3DCT data is a critical step in clinical diagnosis and multi-modality fusion. The process of manually annotating landmarks on the anatomical structure is time-consuming, laborious, and requires a wealth of professional knowledge. In recent years, reinforcement learning (RL) has developed rapidly, making it possible to deal with complex medical data. This paper is based on model-free RL to train a joint multi-agent detection system. The sharing part of the network provides implicit communication for collaborative work between agents, and independent output helps each agent achieve the purpose of locating specific critical points, respectively. Results show that this method can identify three anatomical landmarks simultaneously on the para-sagittal on the left portal vein correctly, introducing a novel formulation for locating the standard plane of volumes and can deal with complex situations such as intraoperative image fusion. Also, the multi-model convergence time is 30% shorter than that of the single-agent model.","Multi-agent reinforcement learning,Para-sagittal Midclavicular Plane,Landmark detection,Medical image",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Telecommunications",,,,"2020 5TH INTERNATIONAL CONFERENCE ON COMMUNICATION, IMAGE AND SIGNAL PROCESSING (CCISP 2020)",,
85,Multi-Modal Depth Estimation Using Convolutional Neural Networks,,,354-359,"Siddiqui Sadique Adnan,Vierling Axel,Berns Karsten","Siddiqui SA,Vierling A,Berns K",Siddiqui SA,,University of Kaiserslautern,"This paper addresses the problem of dense depth predictions from sparse distance sensor data and a single camera image on challenging weather conditions. This work explores the significance of different sensor modalities such as camera, Radar, and Lidar for estimating depth by applying Deep Learning approaches. Although Lidar has higher depth-sensing abilities than Radar and has been integrated with camera images in lots of previous works, depth estimation using CNN's on the fusion of robust Radar distance data and camera images has not been explored much. In this work, a deep regression network is proposed utilizing a transfer learning approach consisting of an encoder where a high performing pre-trained model has been used to initialize it for extracting dense features and a decoder for upsampling and predicting desired depth. The results are demonstrated on Nuscenes, KITTI, and a Synthetic dataset which was created using the CARLA simulator. Also, top-view zoom-camera images captured from the crane on a construction site are evaluated to estimate the distance of the crane boom carrying heavy loads from the ground to show the usability in safety-critical applications.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Robotics",,,,,,
86,The Sailport Project: A Trilateral Approach to the Improvement of Workers' Safety and Health in Ports,969,,69-80,"Filippeschi Alessandro,Pellicci Mauro,Vanni Federico,Forte Giulia,Bassani Giulia,Landolfi Lorenzo,De Merich Diego,Campo Giuseppe,Avizzano Carlo Alberto,Bergamasco Massimo","Filippeschi A,Pellicci M,Vanni F,Forte G,Bassani G,Landolfi L,De Merich D,Campo G,Avizzano CA,Bergamasco M",Filippeschi A,10.1007/978-3-030-20497-6_7,Scuola Superiore Sant'Anna,"This work presents a novel method for the improvement of safety and health in ports. Traditional and consolidated approaches to this goal are based on questionnaires and training activities that Local Health Authorities and the National Institute for Insurance against Accidents offer to the personnel of the companies that work in the port. We propose to complement this method by means of quantitative and pervasive measuring of risks related to safety and health. For the former, we propose a system that measures the collision risk in relevant areas of the port by means of cameras. For the latter, workers wear inertial measurement units and EMG electrodes to estimate the biomechanical overload. The results of these three actions are then merged and presented to the selected companies to make corrective actions, in order to reduce the safety and health risks for the port workers.","Workers safety,Work-related musculoskeletal disorders,Biomechanical overload,Machine learning,Surveillance",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Engineering,,,,,,
87,Deep learning model deploying on embedded skin cancer diagnostic device,11585,,,"Bliznuks Dmitrijs,Cibulska Evija,Bondarenko Andrey,Chizhov Yuriy,Lihacova Ilze","Bliznuks D,Cibulska E,Bondarenko A,Chizhov Y,Lihacova I",Bliznuks D,10.1117/12.2582108,Riga Technical University,"The number of research papers, where neural networks are applied in medical image analysis is growing. There is a proof that Convolutional Neural Networks (CNN) are able to differentiate skin cancer from nevi with greater accuracy than experienced specialists on average (sensitivity 82% and 73% accordingly).(1) Team's latest research(2) allows achieving even greater accuracy, by using specific narrow-band illumination. Nevertheless, the overall probability of early skin cancer detection depends on the availability of diagnostic tools. If screening tools will be available to a high number of general practices, the chance of disease detection will increase. The previous research(3) shows that scalable cloud service is able to process a high number of users. After a certain number of users, the overall cost of the system, including cloud processing expenses and cost of high computational power portable device, might be higher if compared to an on-premises solution, where each device is capable of diagnosing without Internet access. It might be cheaper to equip devices with additional neural processing unit (NPU) and exclude cloud processing. Another option is to make screening available by using the newest smartphones that are equipped with NPU.(4)
The problem of using the NPU is that they are limited in storage space, accuracy, and features. Therefore, a full-size CNN model should be adapted and minimized to fit in a limited NPU. Research reviews existing CNN optimization methods and proposes the most accurate for skin cancer diagnostics. The paper evaluates CNN prediction losses when the model's elements' precision is reduced from 32 bits to 8 and rounded to integer values.","Skin cancer,biophotonics,convolutional neural network",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics",,,,,,
88,Multi-Level Assessment of Occupational Stress in the Field Using a Wearable EEG Headset,,,140-148,"Jebelli Houtan,Habibnezhad Mahmoud,Khalili Mohammad Mandi,Fardhosseini Mohammad Sadra,Lee Sanghyun","Jebelli H,Habibnezhad M,Khalili MM,Fardhosseini MS,Lee S",Jebelli H,10.1061/9780784482872.016,Pennsylvania Commonwealth System of Higher Education (PCSHE),"The construction industry is among the most stressful of occupations. Traditional techniques to evaluate worker stress (e.g., self-assessment and observational checklists) may not be effective in the field because of their potential to interrupt workers' ongoing tasks. Additionally, these methods are subject to biases. Research in neuroscience confirms that the human brain responds to various stressors, so studying patterns of brainwave activity can lead to strong assessments of subjects' stress. The authors' earlier research has monitored worker stress using a wearable electroencephalography (EEG) headset by applying supervised learning algorithms in a binary stress level (i.e., low and high). Despite the success of earlier work identifying excessive stress, there is a gap in knowledge in assessing medium-level stresses. It has been proven that intermittent exposure to medium-level stress decreases not only performance but also concentration and focus. This research attempts to identify multiple levels of worker stress using signals recorded from a wearable EEG headset by applying two supervised learning algorithms, multi-class support vector machines (SVM) and fully connected neural network (FCNN). A stress-related hormone, cortisol, was used as a baseline to label subjects' stress levels. In classifying three levels of stress, the FCNN yielded a prediction accuracy of 79.26%, which is competitive with previous EEG-based stress recognition methods in a binary setting. This research should help in identifying multiple levels of stress at construction sites and aid early detection and mitigation of high stress in the field.","ARTIFACT,REMOVAL,RECOGNITION",Proceedings Paper,"AMER SOC CIVIL ENGINEERS, UNITED ENGINEERING CENTER, 345 E 47TH ST, NEW YORK, NY 10017-2398 USA","Construction & Building Technology,Engineering",,,"ARTIFACT,REMOVAL,RECOGNITION","CONSTRUCTION RESEARCH CONGRESS 2020: SAFETY, WORKFORCE, AND EDUCATION",,
89,Work-Related Fatalities Analysis through Energy Source Recognition,,,279-288,"Song Siyuan,Awolusi Ibukun,Jiang Zhehan","Song SY,Awolusi I,Jiang ZH",Song SY,,University of Southern Mississippi,"Identification of hazards is the first step in accidents prevention. As hazards can be caused by different energy sources, the awareness of all the energy sources is key to identifying potential hazards and creating a safe environment. Accidents result from the interaction of energy, equipment, or materials, and one or more people, and the potential hazards associated with such interaction can be identified based on the energy sources recognition. A lack of understanding of the presence and magnitude of an energy source often results in an accident. As a result, it is important to identify highly innovative and effective hazard recognition strategies such as implementing techniques to avoid future accidents. This study analyzes fatalities and catastrophes data inspected by federal or state OSHA in the past 5 years. Modern machine learning techniques are deployed to power this study: 1) text mining for hazard report extraction and 2) multidimensional visualization for geospatial analysis. The outcome can assist personnel involved in high-risk activities to identify and control the potential hazards unique to each activity and job. As a result, energy sources posing dangers would be effectively managed and eliminated.","HAZARD IDENTIFICATION,CONSTRUCTION",Proceedings Paper,"AMER SOC CIVIL ENGINEERS, UNITED ENGINEERING CENTER, 345 E 47TH ST, NEW YORK, NY 10017-2398 USA","Construction & Building Technology,Engineering",,,"HAZARD,IDENTIFICATION,CONSTRUCTION","CONSTRUCTION RESEARCH CONGRESS 2020: SAFETY, WORKFORCE, AND EDUCATION",,
90,"A machine-learning model driven by geometry, material and structural performance data in architectural design process",,,411-418,Yazici Sevil,Yazici S,Yazici S,,Istanbul Technical University,"Artificial Intelligence (AI), based on interpretation of data, influences various professions including architectural design today. Although research on integrating conceptual design with Machine Learning (ML) algorithms as a subset of the AI has been investigated previously, there is not a framework towards integration of architectural geometry with material properties and structural performance data towards decision making in the early-design phase. Undertaking performance simulations require significant amount of computation power and time. The aim of this research is to integrate ML algorithms into design process to achieve time efficiency and improve design results. The proposed workflow consists of three stages, including generation of the parametric model; running structural performance simulations to collect the data, and operating the ML algorithms, including Artificial Neural Network (ANN), Non-Linear Regression (NLR) and Gaussian Mixture (GM) for undertaking different tasks. The results underlined that the system generates relatively fast solutions with accuracy. Additionally, ML algorithms can assist generative design processes.","Machine-learning,performance simulation,data-driven design,early-design phase",Proceedings Paper,"ECAADE-EDUCATION & RESEARCH COMPUTER AIDED ARCHITECTURAL DESIGN EUROPE, DEPT ARCHITECTURE SINT-LUCAS BRUSSELS-GHENT, HOGESCHOOL VOOR WETENSCHAP & KUNST, PALEIZENSTRAAT 65, BRUSSELS, 1030, BELGIUM","Architecture,Urban Studies",,,APPROXIMATION,,,
91,Experimental analysis of colour constancy and colour augmentation for painting classification by artistic genre: preliminary results,949,,,Bianconi Francesco,Bianconi F,Bianconi F,10.1088/1757-899X/949/1/012065,University of Perugia,"Automatic painting classification by author, artistic genre and/or other attributes has generated considerable research interest in recent years. Being one of the visual features that mark the difference between artists and artistic genres, colour plays a fundamental role in this process. Colour is the result of the interaction among the intrinsic properties of the material, the illumination conditions and the response of the imaging device. Consequently, the same painting/artwork will look significantly different when imaged under varied conditions, which can be a potential source of bias for automated recognition procedures. One can compensate for such variations either via colour calibration or colour pre-processing. In this work we investigate the latter, and, in particular, evaluate the effectiveness of colour constancy and colour augmentation when coupled with hand-crafted and deep learning features for painting classification by artistic genre. In our experiments neither approach showed a clear advantage compared with no pre-processing at all. Colour constancy brought some improvement in certain cases, whereas colour augmentation virtually provided no benefit despite its adding a significant computational overload to the procedure.",,Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Archaeology,Architecture,Materials Science,Physics,Imaging Science & Photographic Technology",,,,,https://doi.org/10.1088/1757-899x/949/1/012065,
92,Using Multimodal Methods in L2 Intonation Teaching for Chinese EFL Learners,,,100-105,"Zhao Chenyang,Xiong Ziyu,Li Aijun","Zhao CY,Xiong ZY,Li AJ",Zhao CY,,University of Chinese Academy of Social Sciences,"The present study aims to investigate how multimodal training method contribute to the improvement of the L2 intonation produced by Chinese EFL learners. Altogether 75 learners with an English major background from 3 different dialectal regions of China are recruited. They are divided into 5 groups which differ from each other in training methods, which specifically are the control group (G1), group with sound for training only (G2), group with sound and after-training feedback (G3), group with both audio and visual material for training (G4), and the audiovisual training group with feedback (G5). The results show that although no significant improvement between learners' pretest and posttest for each group, still we observe that some of the learners in experiment groups score significantly higher in posttest than those in the control group, and among them, G5 is the best as the most cases of intonation are improved through the training. This indicates that multimodal + supervised training method is the most effective way in L2 intonation teaching in this experiment. Unobvious improvement of in the rest cases might due to the limited training time, which will be further ameliorated by a supplementary intensive training in this method.","multimodal training method,feedback,English L2 intonation,Chinese EFL learners",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
93,VOIS: The First Speech Therapy App Specifically Designed for Myanmar Hearing-Impaired Children,,,151-154,"Thida Aye,Han Nway Nway,Oo Sheinn Thawtar,Li Sheng,Ding Chenchen","Thida A,Han NN,Oo ST,Li S,Ding CC",Thida A,,"Univ Comp Studies, AI Res Lab, Mandalay, Mandalay, Myanmar.","The hearing-impaired children's education is challenging because they are unlikely to develop normal speech and language ability. We propose a mobile application VOIS, which is the first speech therapy application for hearing-impaired children in Myanmar. This mobile application uses a Convolutional Neural Network (CNN) based offline Burmese speech recognition system. It can help hearing-impaired children to train with the language pre-requisites at their own pace. To effectively help the hearing-impaired children to understand the basics of the language, this system provides one-syllable and two-syllable structured Myanmar words collected in real-life educational and communication materials. The experimental result shows that the prediction rate of this system is nearly 60%. Experiments also show the hearing-impaired children can learn and operate the language freely through a simple practice using this application. The expectation is that this application can bring both opportunities and life-quality improvements for children with hearing loss in Myanmar.","Hearing-impaired children,Myanmar language,speech therapy app",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
94,A Multi-Stage Curriculum Development Model to Address Knowledge Gaps Between Academia and Industry,,,,"Douglass Heidi,Schwebach Gary","Douglass H,Schwebach G",Douglass H,,Indiana University System,"This innovate practice research is a work in Progress. Curriculum for technology programs must remain current with the recent developments and present needs of industry to ensure their continued success. Identifying and incorporating the newer developments requires a knowledge of those things that are important to the commercial users of technology. We have proposed and are testing a methodology that can easily allow educational programs to remain current using natural language processing followed up with confirmatory surveys. Our research used employment postings and website descriptions of ongoing research/ product development from technology companies to identify current interests. This data provided a window into where companies have invested their resources for future growth, which we used to understand where their technology needs were. The findings will then be used to determine what changes a program should make in their curriculum to address these needs.
The information from these different sources was collected from the websites of selected technology companies as well as from technology related job listings. We then programmatically determined the ten most frequent words found in each subsection of the job listings search parameters. A correlation analysis for each word was obtained to give a context to the words in the resulting corpora. Our next step in developing this process was to extract more focused topics in our data from the correlations using focus topics extracted from the information available in the technology companies' sites.
The process used to focus the topics in our data was started by capturing research and services related to health informatics and bioscience informatics. These research and services were obtained from a sample of 34 local and 39 national companies. The University of Massachusetts' (Amherst) free and open source machine learning toolkit, MALLET, was used to discover the topics present in the datasets via Latent Dirichlet Allocation (LDA) and then compare and interpret each topic present in the job posting frequent word correlations. This allowed us to determine more specific informatic subjects of interest along with the importance of these subjects to industry.
Immediately following the analysis, we will incorporate our results into a survey, which will be sent to the companies that we identified in our data search. This will be used to validate our findings as well as obtain more specific information on their needs related to the curriculum. This second component will allow us to obtain more actionable information for making and incorporating new information and materials into the curriculum.","Natural Language Processing,Curriculum Development",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Education & Educational Research,Engineering",,,"DRUG,DISCOVERY",,,
95,Teaching Practical Machine Learning Concepts to Professionals and Students: An Integrated and Interdisciplinary Qualification Project,,,,"Hagen Tobias,Lauer Tobias,Saenger Volker,Dorer Klaus,Trahasch Stephan","Hagen T,Lauer T,Sanger V,Dorer K,Trahasch S",Hagen T,,Hochschule Offenburg,"Machine learning (ML) has become highly relevant in applications across all industries, and specialists in the field are sought urgently. As it is a highly interdisciplinary field, requiring knowledge in computer science, statistics and the relevant application domain, experts are hard to find. Large corporations can sweep the job market by offering high salaries, which makes the situation for small and medium enterprises (SME) even worse, as they usually lack the capacities both for attracting specialists and for qualifying their own personnel. In order to meet the enormous demand in ML specialists, universities now teach ML in specifically designed degree programs as well as within established programs in science and engineering. While the teaching almost always uses practical examples, these are somewhat artificial or outdated, as real data from real companies is usually not available. The approach reported in this contribution aims to tackle the above challenges in an integrated course, combining three independent aspects: first, teaching key ML concepts to graduate students from a variety of existing degree programs; second, qualifying working professionals from SME for ML; and third, applying ML to real-world problems faced by those SME. The course was carried out in two trial periods within a government-funded project at a university of applied sciences in south-west Germany. The region is dominated by SME many of which are world leaders in their industries. Participants were students from different graduate programs as well as working professionals from several SME based in the region. The first phase of the course (one semester) consists of the fundamental concepts of ML, such as exploratory data analysis, regression, classification, clustering, and deep learning. In this phase, student participants and working professionals were taught in separate tracks. Students attended regular classes and lab sessions (but were also given access to e-learning materials), whereas the professionals learned exclusively in a flipped classroom scenario: they were given access to e-learning units (video lectures and accompanying quizzes) for preparation, while face-to-face sessions were dominated by lab experiments applying the concepts. Prior to the start of the second phase, participating companies were invited to submit real-world problems that they wanted to solve with the help of ML. The second phase consisted of practical ML projects, each tackling one of the problems and worked on by a mixed team of both students and professionals for the period of one semester. The teams were self-organized in the ways they preferred to work (e.g. remote vs. face-to-face collaboration), but also coached by one of the teaching staff. In several plenary meetings, the teams reported on their status as well as challenges and solutions. In both periods, the course was monitored and extensive surveys were carried out. We report on the findings as well as the lessons learned. For instance, while the program was very well-received, professional participants wished for more detailed coverage of theoretical concepts. A challenge faced by several teams during the second phase was a dropout of student members due to upcoming exams in other subjects.","Machine learning,qualification,interdisciplinary",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Education & Educational Research,Engineering",,,,,,
96,Autonomous Procurement System (APS): Pro Forma Development,,,,"Al-Sinan Mazen A.,Aljaroudi Zainab","Al-Sinan MA,Aljaroudi Z",Al-Sinan MA,,Saudi Aramco,"The paper discloses a pending patent that was filed to the United States Patent and Trademark Office (USPTO) in March 2020. The proposed patent provides an autonomous solution for conducting the procurement process for services as well as materials. This paper focuses only on one activity of the autonomous procurement system (APS), namely, pro forma development. The paper also provides a brief description of a typical procurement process for services as an introduction.","Contract pro forma,Artificial intelligence,Machine learning,Natural language processing",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,2020 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE & MODERN ASSISTIVE TECHNOLOGY (ICAIMAT),,
97,An investigation of Deep Learning Algorithms applied to automated diagnosis for Diabetic Retinopathy,11525,,,"Do Cuong,Lan Vu","Do C,Vu L",Do C,10.1117/12.2579608,University of Connecticut,"Diabetic retinopathy is one of the leading causes of blindness among the working age population world-wide due to late detection and intervention. This study pilots the application of deep learning models to automatically diagnose the occurrence and severity of diabetic retinopathy. With color fundus photography as input, this study tested the performance of transfer learning based on the most recent architectures of Convolutional Neural Network (CNN) models, the EfficientNets, claimed to be superior than many current well-performing network architectures.","Deep Learning,Convolutional Neural Networks,classification,Transfer Learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Engineering,Remote Sensing,Optics",,,VALIDATION,,,
98,Anomaly Detection using 1D Convolutional Neural Networks for Surface Enhanced Raman Scattering,11525,,,"Mozaffari M. Hamed,Tay Li-Lin","Mozaffari MH,Tay LL",Mozaffari MH,10.1117/12.2576447,National Research Council Canada,"An accurate supervised classification technique requires a large training database with an equal number of samples in each category. However, in practice, data class imbalance is naturally inherent in detection and identification tasks. In an extreme case, one category of data has a majority of training samples (positive class), causing over-classifying. In these circumstances, the negative classes are either absent, poorly sampled or not well defined. Deep one-class classifiers are artificial neural networks developed to overfit the positive class samples. This unique situation constrains the network model to be trained data features just with the knowledge of the positive class. One well-known application of one-class classifiers is for anomaly detection problem, where the model stands out outliers. Recently, convolutional neural networks (CNNs) have outperformed previous machine learning methods in pattern recognition tasks. In this study, we proposed using a one-dimensional CNN model for anomaly detection in surface-enhanced Raman scattering (SERS) data acquired by portable Raman spectrometers. Raman spectroscopy technique has been widely adopted by first responders and military forces for the field analysis and identification of unknown hazardous materials. The performance and accuracy of the recognition method might compromise the success rate of an interrogation operation. Our experimental results revealed that a 1D CNN model could be used as a one-class classifier to distinguish anomalies in SERS data with a successful detection rate of 100 percent.","Surface-enhanced Raman scattering,Convolutional neural networks,Raman spectroscopy,Anomaly detection,One-class classification,Deep learning,Pattern recognition",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Engineering,Remote Sensing,Optics",,,"SPECTROSCOPY,RECOGNITION",,,
99,Denoising method for photoacoustic microscopy using deep learning,11525,,,"Tang Kanggao,Li Bo,Zhang Jinhong,Wei Jianshuang,Song Lingfang,Song Xianlin","Tang KG,Li B,Zhang JH,Wei JS,Song LF,Song XL",Song XL,10.1117/12.2584879,Nanchang University,"Photoacoustic imaging is a new imaging technology in recent years, which combines the advantages of high resolution and rich contrast of optical imaging with the advantages of high penetration depth of acoustic imaging. Photoacoustic imaging has been widely used in biomedical fields, such as brain imaging, tumor detection and so on. The signal-to-noise ratio (SNR) of image signals in photoacoustic imaging is generally low due to the limitation of laser pulse energy, electromagnetic interference in the external environment and system noise. In order to solve the problem of low SNR of photoacoustic images, we use feedforward denoising convolutional neural network to further process the obtained images, so as to obtain higher SNR images and improve image quality. We use Python language to manage the referenced Python external library through Anaconda, and build a feedforward noise-reducing convolutional neural network on Pycharm platform. We first processed and segmated a training set containing 400 images, and then used it for network training. Finally, we tested it with a series of cerebrovascular photoacoustic microscopy images. The results show that the peak signal-to-noise ratio (PSNR) of the image increases significantly before and after denoising. The experimental results verify that the feed-forward noise reduction convolutional neural network can effectively improve the quality of photoacoustic microscopic images, which provides a good foundation for the subsequent biomedical research.","Photoacoustic microscopy,deep learning,image denoising,denoising convolutional neural networks",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Engineering,Remote Sensing,Optics",,,,,,
100,A Fault-Tolerant Algorithm to Enhance Generalization of EMG-based Pattern Recognition for Lower Limb Movement,,,332-337,"Sun Qinyi,Zhang Xiaodong,Li Hanzhe,Dong Runlin,Wang Yabin,Liu Guangyue","Sun QY,Zhang XD,Li HZ,Dong RL,Wang YB,Liu GY",Zhang XD,,Xi'an Jiaotong University,"Real-time application of exoskeleton remains a challenge due to the limited stability of electromyogram (EMG) collected on lower limb. To enhance generalization of EMG based pattern recognition (PR), this work proposed a novel fault-tolerant algorithm based on conventional liner discriminant analysis (LDA). Based on two patterns of EMG collection (static data and dynamic data), the most accurate feature set was first selected in static data to guarantee basic performance of LDA. Detections of LDA formed a decision stream, and provided later analysis with information of movement and muscle activity of lower limb. A BP classifier was trained based on the decision stream and features set to recover misclassification of LDA when interference occurred. Both LDA and BP were trained on static data. Dynamic data were set to imitate instability of EMG in realistic application such as different force intensity and muscle fatigue. The proposed algorithm was tested on a EMG based PR system. 4 able-bodied subjects participated in the experiment. The enhancement in classification accuracy ranged from 7.52% to 13.94% over subjects compared with unoptimized system. After EMG channels reduced, this enhancement ranged from 9.01% to 27.35%, which significantly improved classification performance under limited condition. These results suggested that the proposed algorithm yield excellent performance in improving the generalization of EMG based PR.","electromyography,pattern recognition,lower limb,generalization",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Automation & Control Systems,Computer Science,Robotics",,,"CLASSIFICATION,ROBUST",,,
