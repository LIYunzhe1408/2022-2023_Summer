,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Decision Support System for Black Classification of Dental Images Using GIST Descriptors,1082,,343-352,"Singh Prerna,Sehgal Priti","Singh P,Sehgal P",Singh P,10.1007/978-981-15-1081-6_29,University of Delhi,"One of the well-known pathology in the world is dental caries. Dental caries is also called as dental cavities. The prior detection of dental caries helps in decreasing the dental disease rate. Patient care has been improved due to medical image mining. In this paper, abnormal dental images have been classified into various classes based on Black's classification. Graphics and intelligence-based script technology (GIST) descriptor has been used to extract significant information from the dental images. Feature reduction is done using marginal Fisher analysis and then Wilcoxon signed-rank test is used as feature selection method. The classification techniques such as decision tree, fuzzy Sugeno, probabilistic neural network, K-nearest neighbor, AdaBoost and naive Bayes are used for classifying the major and reduced features. According to the results, AdaBoost classifier can best diagnose infected tooth using Black's classification with the classification accuracy of 90, 92% sensitivity and 90% specificity.","Marginal Fisher analysis,Decision tree,AdaBoost,Gist descriptors",Proceedings Paper,"SPRINGER-VERLAG SINGAPORE PTE LTD, 152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE",Computer Science,,,FRAMEWORK,,,
2,EEG-Based Emotion Estimate Using Shallow Fully Convolutional Neural Network with Boost Training Strategy,11691,,55-64,"Yao Yuehan,Qing Chunmei,Xu Xiangmin,Wang Yang","Yao YA,Qing CM,Xu XM,Wang Y",Qing CM,10.1007/978-3-030-39431-8_6,South China University of Technology,"Emotion recognition using Electroencephalogram (EEG) has drawn the attention of many scholars. However, there are few studies looking into regressive approach. Actually, human affective states are continuous rather than discrete. This paper focuses on how to estimate continuous affective status from EEG recordings. A Shallow Fully Convolutional Network (SFCN) with Boost Training Strategy is proposed to estimate affective status, including Valence, Arousal, Dominance, and Liking. SFCN is presented to extract the emotional relative features automatically from preprocessed EEG instead of using hand-crafted features. With Global Average Pooling (GAP) layer, SFCN can solve the effect of unreliability of label introduced by segmented-augmentation method. Moreover, Boost Training Strategy is designed to train model with low memory cost and further improves the performance of SFCN. Experiments on DEAP dataset demonstrate the effectiveness of proposed approaches. Results show that Mean Square Error (MSE) for Valence, Arousal, Dominance, Liking are 3.9181, 3.6009, 3.4441 and 4.806, respectively.","Emotion Estimate,Shallow Fully Convolutional Neural Network,Global Average Pooling,Boost Training Strategy",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Imaging Science & Photographic Technology",,,"CLASSIFICATION,SVM",,,
3,Height Prediction for Growth Hormone Deficiency Treatment Planning Using Deep Learning,11691,,76-85,"Ilyas Muhammad,Ahmad Jawad,Lawson Alistair,Khan Jan Sher,Tahir Ahsen,Adeel Ahsan,Larijani Hadi,Kerrouche Abdelfateh,Shaikh M. Guftar,Buchanan William","Ilyas M,Ahmad J,Lawson A,Khan JS,Tahir A,Adeel A,Larijani H,Kerrouche A,Shaikh MG,Buchanan W",Ahmad J,10.1007/978-3-030-39431-8_8,Edinburgh Napier University,"Prospective studies using longitudinal patient data can be used to help to predict responsiveness to Growth Hormone (GH) therapy and assess any suspected risks. In this paper, a novel Clinical Decision Support System (CDSS) is developed to predict growth (in terms of height) in children with Growth Hormone Deficiency (GHD) just before the start of GH therapy. A Deep Feed-Forward Neural Network (DFFNN) model is proposed, developed and evaluated for height prediction with seven input parameters. The essential input parameters to the DFFNN are gender, mother's height, father's height, current weight, chronological age, bone age, and GHD. The proposed model is trained using the Levenberg Marquardt (LM) learning algorithm. Experimental results are evaluated and compared for different learning rates. Measures of the quality of the fit of the model such as Root Mean Square (RMSE), Normalized Root Mean Square (N-RMSE), and Mean Absolute Percentage Error (MAPE) show that the proposed deep learning model is robust in terms of accuracy and can effectively predict growth (in terms of height) in children.","Growth Hormone Deficiency,Deep learning,Levenberg Marquardt (LM) learning,Root Mean Square,Normalized Root,Mean Square,Height prediction",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Imaging Science & Photographic Technology",,,,,,
4,MSA-Net: Multiscale Spatial Attention Network for the Classification of Breast Histology Images,11691,,273-282,"Yang Zhanbo,Ran Lingyan,Xia Yong,Zhang Yanning","Yang ZB,Ran LY,Xia Y,Zhang YN",Xia Y,10.1007/978-3-030-39431-8_26,"Northwestern Polytech Univ Shenzhen, Res & Dev Inst, Shenzhen 518057, Peoples R China.","Breast histology images classification is a time- and labor-intensive task due to the complicated structural and textural information contained. Recent deep learning-based methods are less accurate due to the ignorance of the interfering multiscale contextual information in histology images. In this paper, we propose the multiscale spatial attention network (MSA-Net) to deal with these challenges. We first perform adaptive spatial transformation on histology microscopy images at multiple scales using a spatial attention (SA) module to make the model focus on discriminative content. Then we employ a classification network to categorize the transformed images and use the ensemble of the predictions obtained at multiple scales as the classification result. We evaluated our MSA-Net against four state-of-the-art methods on the BACH challenge dataset. Our results show that the proposed MSA-Net achieves a higher accuracy than the rest methods in the five-fold cross validation on training data, and reaches the 2nd place in the online verification.","Breast cancer,Histology image classification,Multiscale,Spatial attention,Convolutional neural networks",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Imaging Science & Photographic Technology",,,"SALIENCY,DETECTION,OBJECT,DETECTION",,,
5,Automated Drug Suggestion Using Machine Learning,1130,,571-589,"Doma Vikrant,Singh Sahil,Arora Nikita,Ortiz Gabriel,Saran Parneet Kaur,Chavarin Salvador,Pirouz Matin","Doma V,Singh S,Arora N,Ortiz G,Saran PK,Chavarin S,Pirouz M",Pirouz M,10.1007/978-3-030-39442-4_42,California State University System,"The growing healthcare industry generates a large amount of data on patient health conditions, demographic plans, and drugs required for such conditions. These attract the attention of the medical professionals and the data scientists alike. In this paper, we propose a drug recommendation assistant built using machine learning techniques and natural language processing, which draws its accuracy from several major datasets. The proposed system makes it possible to manifest the contrasting effects, reviews, ratings, and then recommend the most ""effective"" drug for a given individual. The results of the predictive analysis were that from 2005-2015, between the ages 55 and 80, the death rates of the top deadliest diseases in the U.S. all increased drastically. Based on the current trends, with some level of accuracy, it is possible to predict the next top five medical conditions (Birth Control, Depression, Pain, Anxiety, Acne) which will be prevalent in the near future and the top five drugs for used to treat them.","Drug recommendation,Confusion matrix,Data visualization,Data manipulation",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Telecommunications",,,,,,
6,Classification of Diabetic Retinopathy and Retinal Vein Occlusion in Human Eye Fundus Images by Transfer Learning,1130,,642-653,"Usman Ali,Muhammad Aslam,Martinez-Enriquez A. M.,Muhammad Adrees","Usman A,Muhammad A,Martinez-Enriquez AM,Muhammad A",Muhammad A,10.1007/978-3-030-39412-4_47,"UET, Dept Comp Sci & Engn, Lahore, Pakistan.","Sight threatening diseases are viral these days. Some of these are so harmful that it may cause complete vision loss. Diabetic Retinopathy (DR) and Retinal Vein Occlusion (RVO) are from this category. The first step to cure such diseases is to accurately predict it. For prediction of these diseases there is a large number of machine/deep learning algorithms employed. In this research, we have proposed a DR&RVO prediction system, which may help eye specialists for the prediction of these diseases. The proposed methodology shows that a retinal image undergoes through three main steps in a Deep Neural Network (DNN) like, preprocessing, image segmentation, and feature extraction and classification. For classification of this processed image into DR and RVO, and normal labels, pre-trained deep neural networks (DNNs) are used. More than 2680 eye fundus images are collected from 7 online available datasets, all images are converted to jpg file format during preprocessing step, after class labels distribution into three categories, the proposed model is firstly trained and then tested randomly on Inception v3, ResNet50 and Alex Net. This is done by using a deep learning technique named as 'Transfer Learning'. The accuracy obtained from these models shows that Inception v3 (85.2%) outperformed than other two state of the art models.","Diabetic Retinopathy (DR),Retinal Vein Occlusion (RVO),Transfer Learning (TL),Deep Neural Networks (DNNs)",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Computer Science,Telecommunications",,,,,,
7,Car-Driver Drowsiness Monitoring by Multi-layers Deep Learning Framework and Motion Analysis,629,,169-175,"Rundo Francesco,Conoci Sabrina,Trenta Francesca,Battiato Sebastiano","Rundo F,Conoci S,Trenta F,Battiato S",Rundo F,10.1007/978-3-030-37558-4_25,STMicroelectronics,"Recent developments in the automotive industry have led to an interest in monitoring car driver drowsiness. The purpose is to develop an efficient system for the detection of bad psychophysical states in order to reduce the number of fatigue-related car accidents. Much of the current literature pays particular attention to the study of physiological signals to obtain information about cardiac activity by measuring the Heart Rate Variability (HRV). In fact, the HRV represents a useful indicator for evaluating physiological stress because it provides information about the cardiovascular system activity controlled by the Autonomic Nervous system. The present study is designed to analyze the skin micro-movements caused by blood pressure by extracting facial landmarks in order to reconstruct the photoplethysmogram (PPG) signal in a robust way. To conclude, we obtained evidence from the validation results to support the idea that the PPG signal detected by sensors and the reconstructed PPG by using facial landmarks are strongly correlated.","Machine learning,LSTM,Driver-drowsiness",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Engineering,,,,,,
8,The Best Approach for Early Detection of Fungi in Tomato Sauce,629,,239-246,"Palumbo Domenico,Quercia Luigi,Del Fiore Antonella,De Rossi Patrizia,Bevivino Annamaria","Palumbo D,Quercia L,Del Fiore A,De Rossi P,Bevivino A",Palumbo D,10.1007/978-3-030-37558-4_36,Italian National Agency New Technical Energy & Sustainable Economics Development,"The detection of fungal contaminations, specifically moulds, in tomato sauce stored in the refrigerator is of great importance and very attractive in smart emerging applications. Using an electronic nose (e-nose) and a Fourier transform infrared (FTIR) spectrometer, we examined two sampling methods to early detect fungal contamination: the first method looks at the accumulated headspace while the second one at the actual headspace. Interestingly, we found that we can use only one sensor to detect the moulds even before their visual development.","Mould early detection,E-nose,Machine learning",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Engineering,,,ELECTRONIC-NOSE,,,
9,Big Data Analysis in Crisis Management - Improving the Development Process of Hydrological and Meteorological Hazard Alerts in The Polish Hydrological and Meteorological Service,,,14906-14919,"Derek Pawel,Dobrowolska Agnieszka","Derek P,Dobrowolska A",Derek P,,Wroclaw University of Economics & Business,"Natural hazards have significant results in material and human losses. Due to the increasing intensity of weather phenomena, the national hydrological and meteorological services, which play an important role in national crisis management structures, are obliged to provide rapid and precise warnings about extreme phenomena in the hydrosphere and atmosphere. Based on this information, other participants involved in the functioning of the national crisis management system plan and implement tasks having a direct effect on the level of health, life and property protection. To meet growing demands, national services must boldly reach for solutions related to Big Data analysis, artificial intelligence (AI) and machine learning (ML) more often. The article presents a general concept of an IT system aimed at comprehensive support for the process related to issuing and distributing warnings about hydrological and meteorological hazards at the Institute of Meteorology and Water Management - National Research Institute (Polish - IMGW-PIB), acting as the national hydrological and meteorological service in Poland.","Big Data,crisis management,hydrological warnings,meteorological warnings",Proceedings Paper,"INT BUSINESS INFORMATION MANAGEMENT ASSOC-IBIMA, 34 E GERMANTOWN PIKE, NO. 327, NORRISTOWN, PA 19401 USA","Business & Economics,Science & Technology - Other Topics",,,,EDUCATION EXCELLENCE AND INNOVATION MANAGEMENT: A 2025 VISION TO SUSTAIN ECONOMIC DEVELOPMENT DURING GLOBAL CHALLENGES,,
10,A Deep Framework for Cell Mitosis Detection in Microscopy Images,,,100-103,"Shi Jian,Xin Yi,Xu Benlian,Lu Mingli,Cong Jinliang","Shi J,Xin Y,Xu BL,Lu ML,Cong JL",Xu BL,10.1109/CIS52066.2020.00030,Changshu Institute of Technology,"Detection and tracking of multiple cells is critical in biomedical research and computer vision. Resolving lineage relationships between mitotic cells has been of fundamental interest in this filed recently. Microscopy images with cells at poor imagining conditions are difficult to detect and manual operation still remains standard procedure. This paper proposed a cell detection framework consisting of a convolution neural network (CNN) cell detector and a convolutional long short-term memory (LSTM) model. The detector is modeled by a well-trained Faster RCNN network to learn various cell features, and the convolutional LSTM network is employed to capture cell mitotic events, which utilizes both appearance and motion information from candidate sequences. Experimental results on realistic low contrast cell images are presented to demonstrate the robustness and validation of the proposed method.","Convolutional LSTM,Faster RCNN,Cell Detection,Cell Division",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Computer Science,Engineering,Mathematics",,,"SEGMENTATION,TRACKING",2020 16TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS 2020),,
11,Cross-subject MEG Transfer Learning by Riemannian Manifold and Feature Subspace Alignment,,,12-16,"Liu Shihao,Yu Tianyou,Huang Zebin,Ye Hengfeng","Liu SA,Yu TY,Huang ZB,Ye HF",Yu TY,10.1109/ISAS49493.2020.9378879,South China University of Technology,"Single-subject oriented analyses have capacity to discover the individual neurocognitive model in neuroscience researches. However, individual discrepancies and spatial instability impede the group level inference. In this paper, we focus on transfer learning methods to cope with magnetoencephalographic (MEG) decoding across subjects within which the individual differences exist. First, a general and effective framework allows us to extract features in Riemannian manifold. Then, an improved subspace alignment technique is proposed to adapt two different domains. We test our method on MEG decoding challenge and find that it outperforms most state of the art methods both in cross-subject validation and new testing data.","brain-computer interface,transfer learning,feature subspace alignment,Riemannian manifold",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,2020 INTERNATIONAL SYMPOSIUM ON AUTONOMOUS SYSTEMS (ISAS),,
12,An EEG-based Brain-Computer Interface for Attention State Recognition,,,100-104,"Tang Yongchao,Huang Haiyun","Tang YC,Huang HY",Tang YC,10.1109/ISAS49493.2020.9378873,South China University of Technology,"When people are in different attention states, electroencephalogram(EEG) signals will be different. Most of researchers used the power of brain waves in different frequency bands or their power ratio as features for classification. However, the accuracy of recognition needs further improvement. In this paper, we proposed a BCI system used for attention state classification. Firstly, we used a band-pass filter to filtered the raw EEG data. After preprocessing, eight candidate features were extracted based on the power spectral density (PSD). Then we used a genetic algorithm(GA) based on probability distribution to select eight-dimensional features from the twenty-four-dimensional candidate features. Finally, we chose support vector machine (SVM) as classifier. The average accuracy of the ten subjects achieved 86.99% for the frontal(the central area and parietal area achieved 84.94% and 84.66%, respectively). Further analysis, the classifier was changed to a back-propagation neural network (BP). Output of the bp classifier was classified using the k-means. The final average accuracy of the ten subjects achieved 9030% for the frontal(the central area and parietal area achieved 89.66% and 88.99%, respectively). We also used the 24dimensional PSD feature to calculate the accuracy, the proposed method can greatly improve the accuracy, which showed the feasibility of this method in attentional EEG analysis.","Electroencephalogram (EEG),attention,genetic algorithm(GA),bp neural network(BP),k-means",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"THETA%2FBETA,RATIO",2020 INTERNATIONAL SYMPOSIUM ON AUTONOMOUS SYSTEMS (ISAS),,
13,A Wavelet Compression based Multi-resolution Bidirectional LSTM Network for Electrocardiogram Biometric Classification in constructing Biometric Ontology,,,65-70,"Lynn Htet Myet,Hong Taekeun,Kim Hyoungju,Kim Sung Hwan,Kim Pankoo","Lynn HM,Hong T,Kim H,Kim SH,Kim P",Lynn HM,,Chosun University,"In this study, we explore the use of deep learning approaches for the task of classifying electrocardiogram(ECG) recordings for biometric human identification in developing biometric ontology. Deep learning techniques such as traditional recurrent neural network with long-short term memory unit gate (RNN-LSTM), RNN with GRU cell unit(RNN-GRU), and multi-resolution bidirectional LSTM network are applied for identification task in terms non-fiducial approach. The idea of investigating proposed architectures is to study the accuracy and performance for non-fiducial approach, and to expand the concepts in the domain of biometrics in order to build more precise ontology. In addition, By applying wavelet compression version of the data, to enrich the time-frequency representation of original ECG signal, and to increase the performance of learning procedure compared to other RNN based methods, wavelet compression technique is applied to normalized ECG signals. From the experiment, the proposed method surpassed RNN based networks and recent state-of-the-art studies in generalization performance in terms of accuracy and F1 score. This paper demonstrates the effectiveness of applying wavelet compression and multi-resolution bidirectional LSTM learning method for a high classification capability.","wavelet compression,ECG signal,signal processing,classification,LSTM,RNN,deep learning,biometric ontology",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Telecommunications",,,"NEURAL-NETWORK,TRANSFORM",2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC),,
14,On-device Training for Breast Ultrasound Image Classification,,,78-82,"Hou Dennis,Hou Raymond,Hou Janpu","Hou D,Hou R,Hou JP",Hou D,,"Res & Dev Caloudi Corp, San Francisco, CA 94131 USA.","Most on -device AI pre -trained a neural network model in cloud -based server then deployed to edge device for inference. On-device training not only can build personalized model, but also can do distributed training like federated learning to train accurate models from scratch using small updates from many devices. In this work, we implement the semi-supervised convolutional neural network based on successive subspace learning and use a dataset of breast ultrasound (BUS) images to demonstrate a proof of concept of true on -device training. An important advantage of such network is that we can extract the key feature vectors with CNN network architectures without the need of backpropagation computation made it suitable for portable ultrasound. So it can acquire the ultrasound image and train the CNN classifier on the portable device without cloud -based server. We evaluate the model by using a set of BUS images that includes benign and malignant breast tumors. We obtain 94.8% accuracy with this study and demonstrate the applicablility of the proposed on -device training model to improve the diagnosis of BUS images.","Ultrasound Classifier,Breast Ultrasound,Saab Transform,Medical Image",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Telecommunications",,,,2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC),,
15,Machine Learning Techniques for Motion Analysis of Fatigue from Manual Material Handling Operations Using 3D Motion Capture Data,,,300-305,"Hernandez Geovanni,Valles Damian,Wierschem David C.,Koldenhoven Rachel M.,Koutitas George,Mendez Francis A.,Aslan Semih,Jimenez Jesus","Hernandez G,Valles D,Wierschem DC,Koldenhoven RM,Koutitas G,Mendez FA,Aslan S,Jimenez J",Hernandez G,,Texas State University System,"Industrial Revolution 4.0 is defined as the interconnection of Information, Communications Technologies (ICT), and factory floor workers. Workers in the material handling industry are often subject to repetitive motions that cause exhaustion (or fatigue) which leads to work-related musculoskeletal disorders (WMSDs). The most common repetitive motions are lifting, pulling, pushing, carrying and walking with load. In this research data is collected as time-stamped motion data using infrared cameras at a rate of 100Hz while a subject performs one of the repetitive motions (i.e. lifting). The data is a combination of xyz-coordinates of 39 reflective markers. This results in 117 data points for each frame captured. Since these motions occur over time for a duration of time, this data is used as input to a time-series machine learning (ML) model such as Recurrent Neural Network (RNN). Using this model, this paper evaluates machine learning techniques, based on RNN, to evaluate the fatigue factor caused by repetitive motions.","industrial revolution 4.0,fatigue,machine learning,recurrent neural network,motion capture",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Telecommunications",,,,2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC),,
16,A Comparative Study of Machine Learning Algorithms for Use in Breast Cancer Studies,,,412-416,"Easttom Chuck,Thapa Sudip,Lawson Justin","Easttom C,Thapa S,Lawson J",Easttom C,,"CEC Secur LLC, Plano, TX 75093 USA.","This current study examines a range of machine learning algorithms efficacy at determining malignancy from breast cancer imagery. The study uses the Wisconsin data set (diagnostic) to evaluate the algorithms performance. While there are a number of published studies regarding machine learning and breast cancer imagery data, there are gaps in the current literature. One gap is that several studies focus on a single algorithm. Another gap is that comparative studies often focus on only a few algorithms. The current study addresses these specific gaps in the existing literature. The current study looks at 5 different algorithms, then compares those to 8 algorithms from the literature. This provides a broad comparative study of the efficacy of machine learning algorithms in detecting breast cancer.","machine learning,breast cancer,cancer detection,Wisconsin Data Set",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Telecommunications",,,CLASSIFICATION,2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC),,
17,Focus Detection Using Spatial Release From Masking,,,913-917,"Shah Urmil,Hoang Brandon,Villanueva Ryan,George Kiran","Shah U,Hoang B,Villanueva R,George K",Shah U,,California State University System,"Individuals are often subjected to environments where multiple conversations occur simultaneously. In these situations, most hearing-a bled individuals are able to focus on the auditory stimulus of their choice by filtering out other present auditory stimuli. This ability is also referred to as 'The Cocktail Party Effect'. Unfortunately, this ability is not yet applicable for people who use assistive listening devices or digital communications devices to communicate with more than one individual [I]. In this study, Spatial Release from Masking techniques are used within the context of its influence on Speech Intelligibility. A Brain-Computer Interface (BCI) system was used to take electroencephalogram (EEG) signals, through noninvasive methods, for machine learning classification training. The goal of using EEG signals to train a machine learning classifier is to find a model that can accurately predict if a subject is listening to a particular auditory stimulus in the presence of multiple auditory stimuli. A similar study has been conducted before but without the use of machine learning for data processing [2].","Spatial Release from Masking (SRM),Speech Intelligibility,Brain-Computer Interface (BCI),Electroencephalogram (EEG),Machine Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Telecommunications",,,,2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC),,
18,The Future of Work: Towards Service Robot Control through Brain-Computer Interface,,,932-937,"Georgescu Leonardo,Wallace Dylan,Kyong Daniel,Chun Alex,Chun Kathy,Oh Paul","Georgescu L,Wallace D,Kyong D,Chun A,Chun K,Oh P",Georgescu L,,Nevada System of Higher Education (NSHE),"Methods for brain-computer interfaces (BCI) have undergone major advancements in the past decade, providing mobility for disabled individuals through the control of wheelchairs and prosthetic devices. However, not many advancements have been made in allowing people with disabilities to control a robot in a remote location. Currently, people with disabilities are heavily underrepresented in the labor force. This paper presents the idea of using telepresence robots controlled by BCI in the workforce, providing the ability for a disabled individual to work in a wide variety of scenarios. This can be achieved by developing a system with 4 major components: Data Acquisition, Digital Signal Processing, Feature Extraction, and Classification. This work presents the preliminary results toward using traditional data acquisition, signal processing, feature extraction, and classification methods in order to control the primitive movements of a wheeled telepresence robot. The results show a promising classification accuracy of navigational direction for the telepresence robot. Future work will explore using state-of-the-art methods in data acquisition, signal processing, feature extraction, and classification to control a telepresence robot using a BCI headset, and other future work will also demonstrate the near real-time classification of BCI signals for robot control.","brain-computer interface (BCI),Service Robots,Machine Learning,Signal Processing,Data Acquisition,EEG,ERD,ERS",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Telecommunications",,,,2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC),,
19,Segregating Hazardous Waste Using Deep Neural Networks in Real-Time Video,,,1016-1022,"Hua Dorothy,Gao Julia,Mayo Roger,Smedley Albert,Puranik Piyush,Zhan Justin","Hua D,Gao JL,Mayo R,Smedley A,Puranik P,Zhan J",Hua D,,Nevada System of Higher Education (NSHE),"Sustaining a society requires reusing, reducing, and recycling waste. Waste disposal has always been a problem in developing countries because of inadequate infrastructure. By utilizing artificial intelligence to detect hazardous waste, more individuals will be protected from the negative effects of it. To help mitigate this problem, we experimented with Keras, to create a convolutional neural network, and OpenCV, to create real-time videos, that identifies hazardous waste from other recyclable materials. Through the use of machine learning, our model is able to categorize different recyclable materials with about 90% accuracy. Objects within the video receive a prediction for 3 classifications which includes batteries, syringes, and nonhazardous waste. Then, the category with the highest category is what the network will classify it as. In conclusion, the model is able to identify hazardous objects and recyclable items within a pile of trash to help protect all individuals.","Deep Neural Networks,Segregating Hazardous Waste,Real-Time",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Telecommunications",,,,2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC),,
20,Point Cloud Information Modeling (PCIM): An Innovative Framework for As-Is Information Modeling of Construction Sites,,,1319-1326,"Park Jisoo,Chen Jingdao,Cho Yong K.","Park J,Chen JD,Cho Y",Cho Y,,University System of Georgia,"Point clouds constitute a high fidelity representation of the 3D geometry of physical objects; thus, point cloud technology is often used to create an as-built building information modeling (BIM) of a building construction site. However, the conventional scan-to-BIM pipeline still requires significant time and manual efforts to complete. To address this problem, this study proposes a novel point cloud information management format, called point cloud information modeling (PCIM), where semantic information of building elements is captured from the laser scanner and camera data and directly encoded in a combined point cloud data structure. PCIM is a concise representation of the as-is condition of building elements on a construction site, including building object information such as type of building element, material, and geometry. PCIM has an object-oriented hierarchical structure, and the definition of building objects are derived from the industry foundation classes (IFC). The process of creating PCIM can be automated since the underlying semantic structures such as class and material information can be directly extracted from raw sensor data with machine learning technology. Under the machine learning framework, an automated classifier can be trained to recognize relevant entities from point cloud data based on a pre-built library of 3D building computer-aided design (CAD) objects. To validate the overall PCIM framework, this research conducted a case study at an actual building under construction. The test results demonstrate that PCIM can be an effective tool for as-is information modeling of structures and facilities during construction.","RECOGNITION,PROGRESS,BIM",Proceedings Paper,"AMER SOC CIVIL ENGINEERS, UNITED ENGINEERING CENTER, 345 E 47TH ST, NEW YORK, NY 10017-2398 USA","Computer Science,Construction & Building Technology,Engineering",,,"RECOGNITION,PROGRESS,BIM",CONSTRUCTION RESEARCH CONGRESS 2020: COMPUTER APPLICATIONS,,
21,EEG-based tonic cold pain assessment using extreme learning machine,24,1,163-182,"Yu Mingxin,Dong Mingli,Han Jing,Lin Yingzi,Zhu Lianqing,Tang Xiaoying,Sun Guangkai,He Yanlin,Guo Yikang","Yu MX,Dong ML,Han J,Lin YZ,Zhu LQ,Tang XY,Sun GK,He YL,Guo YK",Zhu LQ,10.3233/IDA-184388,Beijing Information Science & Technology University,"The purpose of this study is to present a novel method which can objectively identify the subjective perception of tonic pain. To achieve this goal, scalp EEG data are recorded from 16 subjects under the cold stimuli condition. The proposed method is capable of classifying four classes of tonic pain states, which include No pain, Minor Pain, Moderate Pain, and Severe Pain. Due to multi-class problem of our research an extended Common Spatial Pattern (ECSP) method is first proposed for accurately extracting features of tonic pain from captured EEG data. Then, a single-hidden-layer feedforward network is used as a classifier for pain identification. With the aid of extreme learning machine (ELM) algorithm, the classifier is trained here. The advantages of ELM-based classifier can obtain an optimal and generalized solution for multi-class tonic cold pain. Experimental results demonstrate that the proposed method discriminates the tonic pain successfully. Additionally, to show the superiority for the ELM-based classifier, compared results with the well-known support vector machine (SVM) method show the ELM-based classifier outperform than the SVM-based classifier. These findings may pay the way for providing a direct and objective measure of the subjective perception of tonic pain.","Common spatial pattern (CSP),electroencephalogram (EEG),extreme learning machine (ELM),tonic cold pain",Article,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS",Computer Science,,,"ELECTROENCEPHALOGRAM,POWER,CLASSIFICATION,QUESTIONNAIRE,STIMULATION,PERCEPTION,ACTIVATION,MECHANISMS,RESPONSES,INDEXES",INTELLIGENT DATA ANALYSIS,,
22,Application of back-propagation neural networks to defect characterization using eddy current testing,64,1-4,817-825,"Zhou Xinwu,Urayama Ryoichi,Uchimoto Tetsuya,Takagi Toshiyuki","Zhou XW,Urayama R,Uchimoto T,Takagi T",Takagi T,10.3233/JAE-209394,Centre National de la Recherche Scientifique (CNRS),"Eddy current testing is widely used for the automatic detection of defects in conductive materials. However, this method is strongly affected by probe scanning conditions and requires signal analysis to be carried out by experienced inspectors. In this study, back-propagation neural networks were used to predict the depth and length of unknown slits by analyzing eddy current signals in the presence of noise caused by probe lift-off and tilting. The constructed neural networks were shown to predict the depth and length of defects with relative errors of 4.6% and 6.2%, respectively.","Eddy current testing,artificial intelligence,back-propagation neural network",Article; Proceedings Paper,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS","Engineering,Mechanics,Physics",,0.698,,INTERNATIONAL JOURNAL OF APPLIED ELECTROMAGNETICS AND MECHANICS,,
23,Metallographic image segmentation of GCr15 bearing steel based on CGAN,64,1-4,1237-1243,"Chen Yuanyuan,Jin Wuyin,Wang Meng","Chen YY,Jin WY,Wang M",Jin WY,10.3233/JAE-209441,Lanzhou University of Technology,"A novel deep learning segmentation method based on Conditional Generative Adversarial Nets (CGAN) is proposed, being U-GAN in this paper to overtake shortcomings of the metallographic images of GCr15 bearing steel, such as multi-noise, low contrast and difficult to segment. The results of experiment indicate that the proposed model is the most accurate comparing with the digital image processing methods and deep learning methods on carbide particle segmentation. The average Dice's coefficient of similarity measure function is 0.9158, which is the state-of-the-art performance on dataset.","Metallographic image,image processing,carbide particle segmentation,deep learning,CGAN",Article; Proceedings Paper,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS","Engineering,Mechanics,Physics",,0.698,,INTERNATIONAL JOURNAL OF APPLIED ELECTROMAGNETICS AND MECHANICS,,
24,Improving brain tumor segmentation on MRI based on the deep U-net and residual units,28,1,95-110,"Yang Tiejun,Song Jikun,Li Lei,Tang Qi","Yang TJ,Song JK,Li L,Tang Q",Song JK,10.3233/XST-190552,Henan University of Technology,"BACKGROUND: Accurate segmentation of brain tumor depicting on magnetic resonance imaging (MRI) is an important step for doctors to determine optimal treatment plan of Gliomas, which are the common malignant brain tumors that seriously damage patients' health and life.
OBJECT: This study aims to improve accuracy and efficiency of brain tumor segmentation on MRI using the advanced deep learning model.
METHOD: In this study, an improved model based on the U-net for accurate segmentation of brain tumor MRI images, called Deeper ResU-net, is proposed. First, a deep Deeper U-net is built, which has deeper network depth compared with U-net, uses Squeeze Operator to control network parameters and attempts to enhance the feature extraction ability. Then, Deeper ResU-net is formed to eliminate degradation phenomenon of the deep network, in which residual unit is designed and integrated into the Deeper U-net to keep the number of parameters unchanged.
RESULT: Deeper ResU-net makes the deep network conduct stable training without degrading. Evaluation result shows that the Deeper ResU-net has achieved competitive result with average DSC metrics of 0.9, 0.82, 0.88 for Complete tumor region, Core tumor region and Enhanced tumor region, respectively.
CONCLUSION: By extending the U-net model to a deeper layer and adding the residual structure to ensure effective and stable training of the model, the experiment results demonstrate that applying the improved Deeper ResU-net can effectively eliminate the degradation phenomenon of deep network and improve segmentation performance.","Brain tumor MRI,image segmentation,U-net,residual units,CNN",Article,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Optics,Physics",,1.159,"NETWORKS,FEATURES,CRF",JOURNAL OF X-RAY SCIENCE AND TECHNOLOGY,,
25,A Transfer Learning Based Approach for Skin Lesion Classification from Imbalanced Data,,,65-68,"Rahman Zillur,Ami Amit Mazumder","Rahman Z,Ami AM",Rahman Z,10.1109/ICECE51571.2020.9393155,Chittagong University of Engineering & Technology (CUET),"Skin cancer is the most common kind of cancer across the world and some types of skin cancer are deadly if not identified at the early stage. Therefore, it is crucial to detect the lesion class as early as possible. But skin lesion classification is a very challenging task and many automated systems have been developed so far based on different deep learning algorithms. In this study, we have used ResNet, Xception, and DenseNet three state-of-the-art deep learning pre-trained models to classify the skin lesions. For the training and evaluation of our models, we used the HAM10000 dataset and obtained balanced accuracy of 78%, 82%, and 82% for the three models respectively. We then combined the three models using the weighted ensemble technique without any further training and got 85.8% balanced accuracy and this improved other evaluation parameters as well by a significant amount.","CNN,Deep learning,Fine-tuning,Skin cancer,Lesion classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,CANCER,PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE),,
26,A Robust CNN Framework with Dual Feedback Feature Accumulation for Detecting Pneumonia Opacity from Chest X-ray Images,,,77-80,"Alam Md Jahin,Ali Shams Nafisa,Hasan Md Zubair","Alam MJ,Ali SN,Hasan MZ",Alam MJ,10.1109/ICECE51571.2020.9393157,Bangladesh University of Engineering & Technology (BUET),"Pneumonia is one of the most acute respiratory diseases having remarkably high prevalence and mortality rate. Chest X-ray (CXR) has been widely utilized for the diagnosis of this disease owing to its availability, diagnostic speed and accuracy. However, even for an expert radiologist, it is quite challenging to readily determine pneumonia opacity by examining CXRs. Therefore, this study has been structured to automate the pneumonia detection process by introducing a robust deep learning framework. The proposed network comprises of Process Convolution (Pro_Conv) blocks for feature accumulation inside Dual Feedback (DF) blocks to propagate the feature maps towards a viable detection. Experimental analysis showcase: (1) the proposed network proficiently distinguishes between normal and pneumonia opacity containing CXRs with the mean accuracy, sensitivity and specificity of 97.78%, 98.84% and 95.04%, respectively; (2) the network is constructed with significantly low parameters than the traditional ImageNets to reduce memory consumption for deployment in memory constrained mobile platforms; (3) the trade-off between accuracy and number of parameters of the model outperforms the considered classical networks by a remarkable margin; and (4) the false-negatives are lower than the false-positives (both of which are low in count) which prove the model's low-fatality prediction. Hence, the proposed network can be deployed for a rapid screening of pneumonia and can act as a great assistive tool for the radiologists in the diagnosis process.","Chest X-Ray,Pneumonia detection,Computer-aided diagnosis,Deep learning,Hybrid features",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,"NEURAL-NETWORK,CLASSIFICATION",PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE),http://arxiv.org/pdf/2103.14461,
27,S-Parameters Based Channel Characterization Using Ultra-Wideband Pulse Signal,,,81-84,"Hossain Md Kamal,Haider Mohammad R.","Hossain MK,Haider MR",Hossain MK,10.1109/ICECE51571.2020.9393063,University of Alabama System,"Ultra-Wideband has recently become a powerful technology that involves wireless communication, digital signal processing, machine learning, and even hardware design for ubiquitous sensing applications. This paper presents a straight forward signal processing method to characterize the wireless communication channel using the UWB pulse signal. This proposed method uses a narrow width based modified Hermitian pulse (MHP) for calculating the output signal at the receiver end from measured network parameters. Magnitude attenuation, wave shape distortion, and phase shift of the output signal indicate the impact of the communication channel on the traveling wave. A neural network-based deep learning algorithm uses to classify the obstacle types from the measured output signal using the MATLAB tool. Measurement results demonstrate the real scenario of channel effects on the high-frequency UWB signal and select a suitable modulation scheme for data encoding. It also helps design the receiver compensation, reconstruct the distorted signal, and channel access to use the MHP pulse signal for high-density data communication. This method can also be used other sensing applications such as damage localization, detection, displacement measurement, material identification, etc.","S-parameters,orthogonal pulse,composite pulse,communication systems,signal processing",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,RADAR,PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE),,
28,Identification and Analysis of Risk Factors of Lower Back Pain Using Machine Learning Approaches,,,129-132,"Hasan Kazi Amit,Hasan Md Al Mehedi","Hasan KA,Hasan MA",Hasan KA,10.1109/ICECE51571.2020.9393098,Rajshahi University of Engineering & Technology (RUET),"Lower Back Pain (LBP) is acknowledged as one of the most conventional and frequent physical disability, LBP is influencing a large number of people each year that diminishes work efficiency, productivity significantly and also influences daily activities. Possessing high influencing rate, it raises the importance of early diagnosis. Early diagnosis of LBP depreciates the likelihood of transforming it towards a chronic phase. The interpretation of clinical risk factors of various spinal attributes benefits to determine the prevalence of LBP in medical diagnosis. Measuring the prevalence of LBP in the primary stages diminishes the odds of surgical treatments and enhance the cure rate with the least medications and proper physical therapy. The objectives of this study were to examine and discover the clinical risk factors correlated with LBP by using Statistical Logistic Regression and also identify the irregularities using various predictive algorithms. Experimental outcomes reveal that degree spondylolisthesis, pelvic radius, lumbar lordosis angle, sacral slope and pelvic tilt are the most significant risk factors associated with LBP. Accompanying this, the highest accuracy score .92 was obtained with the K-Nearest Neighbors classification method and the proposed method was also compared with other existing state of art techniques.","Lower Back Pain (LBP),Logistic Regression,K-Nearest Neighbors Clinical Risk Factors,Machine Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE),,
29,An improved deep learning based classification of human white blood cell images,,,149-152,"Siddique Md Abu Ismail,Bin Aziz Abu Zahid,Matin Abdul","Siddique MA,Bin Aziz A,Matin A",Siddique MA,10.1109/ICECE51571.2020.9393156,Rajshahi University of Engineering & Technology (RUET),"White blood cells (WBC) are part of the immune systems which defend both infectious diseases and foreign invaders. There are various types of white blood cells in our body and each of these blood cells has a specific function in our body. The differential test is the traditional way to classify white blood cells in that it calculates the percentage of different types of white blood cells. In this test, the efficiency is low and time-consuming. Various machine learning and deep learning methods have been developed over the years that produced good results. In this work, we applied a deep learning based convolutional neural network (CNN) called ""SqueezeNet"" to classify white blood cells. After fine-tuning the hyperparameters, we trained our model and tested its performance in the testing dataset. Our method achieved 93.8% accuracy in the test data which is better than the existing classifiers. This proves that our method can be a useful approach for this task.","white blood cell,""SqueezeNet"",CNN,multiclass classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE),,
30,Lung Opacity Classification With Convolutional Neural Networks Using Chest X-rays,,,169-172,"Monowar Khan Fashee,Hasan Md Al Mehedi,Shin Jungpil","Monowar KF,Hasan MA,Shin J",Monowar KF,10.1109/ICECE51571.2020.9393135,Rajshahi University of Engineering & Technology (RUET),"Chest X-ray interpretation is very crucial to detect cardiothoracic and pulmonary abnormalities. This time-consuming and tedious task should be error-free, fast, and reliable otherwise a single mistake may cause serious harm to patients. Recently, deep learning achieves radiologist-level performance in chest X-ray interpretation. A CAD (Computer-aided detection system) can help radiologists to review chest X-rays fast and accurately. In our research, we trained and evaluated various deep convolutional neural networks (CNN) architectures to detect potential lung opacity from chest X-rays. We observed how strongly architectures could differentiate lung opacity from normal and other abnormal chest X-rays. In these circumstances, A CNN based model (Xception) achieved 91.0% AUC along with 83.95% accuracy. Moreover, we also observed models achieved a better performance on lung opacity vs normal chest X-ray classification (excluding abnormal class) where Xception achieved 99.1% AUC, 97.19% sensitivity, and 95.71%accuracy. Therefore, the purpose of this study is to investigate the classification ability of deep CNN architectures which helps to develop an automatic lung opacity detection system.","Chest X-ray,Deep Learning,CNN,AUC,Bioinformatics,Lung Opacity,RSNA,Computer Vision",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,PNEUMONIA,PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE),,
31,A Comparative Study of CNN Transfer Learning Classification Algorithms with Segmentation for COVID-19 Detection from CT Scan Images,,,234-237,"Seum Ashek,Raj Amir Hossain,Sakib Shadman,Hossain Tonmoy","Seum A,Raj AH,Sakib S,Hossain T",Seum A,10.1109/ICECE51571.2020.9393129,Ahsanullah University of Science & Technology (AUST),"After it's inception, COVID-19 has spread rapidly all across the globe. Considering this outbreak, by far, it is the most decisive task to detect early and isolate the patients quickly to contain the spread of this virus. In such cases, artificial intelligence and machine learning or deep learning methods can come to aid. For that purpose, we have conducted a qualitative investigation to inspect 12 off-the-shelf Convolution Neural Network (CNN) architectures in classifying COVID-19 from CT scan images. Furthermore, a segmentation algorithm for biomedical images - U-Net, is analyzed to evaluate the performance of the CNN models. A publicly available dataset (SARS-COV-2 CT-Scan) containing a total of 2481 CT scan images is employed for the performance evaluation. In terms of feature extraction by excluding the segmentation technique, a performance of 88.60% as the F1 Score and 89.31% as accuracy is achieved by training DenseNet169 architecture. Adopting the U-Net segmentation method, we accomplished the most optimal accuracy and F1 Scores as 89.92% and 89.67% respectively on DenseNet201 model. Furthermore, evaluating the performances, we can affirm that a combination of a Transfer Learning architecture with a segmentation technique (U-Net) enhances the performance of the classification model.","COVID-19,Transfer learning,CNN,CT scan,DenseNet,U-Net",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE),https://ieeexplore.ieee.org/ielx7/9393009/9393029/09393129.pdf,
32,Breast Cancer Classification Using Ensemble Hard Voting with Random Under-Sampling,,,379-382,"Bin Habib Al-Zadid Sultan,Islam Kazi Tanvir,Pranto Md Munimul Hasan,Nooruddin Mohammad","Bin Habib AZS,Islam KT,Pranto MMH,Nooruddin M",Bin Habib AZS,10.1109/ICECE51571.2020.9393080,Jahangirnagar University,"Breast cancers emerged as one of the fatal diseases among women. Particular efforts are being taken continuously around the globe to help this cause. Taking advantage of Machine Learning (ML) technology is a measure to lessen the death toll of this disease. This paper has emphasized breast cancer classification to expedite the diagnostic process by identifying whether the tumor is benign or malignant. Moreover, in this process, we have combined the ensemble learning-based Hard Voting (HV) technique with random under-sampling using the Wisconsin Diagnostic Breast Cancer (WDBC) dataset. This dataset provides several features upon performing Fine Needle Aspirate (FNA) test to each affected individual, and five features have been chosen to accomplish the classification task. These features have been further scaled using RobustScaler, and the classes (benign or malignant) were balanced using random under-sampling to achieve an accurate outcome. Four distinguished ML classifiers, e.g., Decision Tree Classifier (DTC), k-Nearest Neighbor (KNN), Random Forest (RF), and Support Vector Machine (SVM), have been applied to form an HV meta-classifier. The HV meta-classifier has obtained 99.42% test accuracy in classifying breast cancer incidents. This result has been further verified by considering other distinct parameters.","Breast Cancer,Health Informatics,Machine Learning,Ensemble Hard Voting,Random Under-Sampling",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE),,
33,Detection of Myocardial Infarction from ECG Signal Through Combining CNN and Bi-LSTM,,,395-398,"Omar Nuzaer,Dey Monisha,Ullah Muhammad Ahsan","Omar N,Dey M,Ullah MA",Omar N,10.1109/ICECE51571.2020.9393090,Chittagong University of Engineering & Technology (CUET),"Myocardia infarction (MI) otherwise known as heart attack, is one of the prime causes of death of individuals worldwide. The electrocardiogram (ECG) signal is clinically used by cardiologists as a screening tool to precisely detect MI. This paper presents a detection approach for MI using 21 time-domain features that are extracted from 12-lead ECG signals. The 12-lead ECG signal facilitates the diversification of features and supports the integrity of machine learning. The features are inserted into a deep learning model based on the combination of a one-dimensional convolutional neural network (1D-CNN) and bidirectional long short-term memory (Bi-LSTM). The 1D-CNN is used for extracting the spatial information of each lead and the Bi-LSTM is used to process the information sequentially in the subsequent leads along with classifying into two distinct classes: healthy and MI. In this paper, the Physikalisch Technische Bundesanstalt (PTB) database is used for evaluation in which 549 patient records are available. The CNN combination with the Bi-LSTM model shows a training accuracy of 99.05% and testing accuracy of 98.50% with 20% data being validated.","Myocardial Infarction,ECG,deep-learning,CNN,Bi-LSTM",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,NETWORK,PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE),,
34,Machine Learning to Predict COVID-19 and ICU Requirement,,,483-486,"Podder Prajoy,Mondal M. Rubaiyat Hossain","Podder P,Mondal MRH",Podder P,10.1109/ICECE51571.2020.9393123,Bangladesh University of Engineering & Technology (BUET),"This paper focuses on the application of machine learning (ML) algorithms to manage novel coronavirus disease (COVID-19). For this, different ML classifiers are used for two cases, one for the prediction of COVID-19 patients, and another for the prediction of the intensive care unit (ICU) requirement. A dataset of 5644 samples and 111 attributes collected at Hospital Israelita Albert Einstein, Brazil is considered in this paper. After necessary preprocessing 57 attributes are used for COVID-19 detection, while 67 attributes are considered for ICU requirement prediction. Using scikit-learn library of Python programming language, the most important features for both cases are found out. A number of base as well as ensemble classifiers are applied to the resultant datasets for the two cases. Results show that COVID-19 detection can be predicted with an accuracy of 94.39% and recall of 92% using stacking ensemble with random forest (RF), XGBoost (XGB) and logistic regression (LR). Results also show that ICU requirement can be predicted with an accuracy of 98.13% and recall of 99% using stacking ensemble with RF, extra trees and LR.","COVID-19,machine learning,recall,classification accuracy,feature selection",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE),https://ieeexplore.ieee.org/ielx7/9393009/9393029/09393123.pdf,
35,An Automatic Ocular Disease Detection Scheme from Enhanced Fundus Images Based on Ensembling Deep CNN Networks,,,491-494,"Khan Ishtiaque Ahmed,Sajeeb Asaduzzaman,Fattah Shaikh Anowarul","Khan IA,Sajeeb A,Fattah SA",Khan IA,10.1109/ICECE51571.2020.9393050,Bangladesh University of Engineering & Technology (BUET),"Millions of people around the world suffer from various ocular diseases often leading to blindness due to delayed detection and treatment. This has led to a demand for quick automated detection process from medical images including retinal fundus images. In this paper, an automatic approach for classifying normal and diseased cases from given retinal fundus images is developed based on ensembling of some suitable deep learning architectures in a transfer learning platform. Instead of directly using the raw images, it is shown that use of an enhancement technique based on adaptive histogram equalization followed by morphological operations can offer better class separation between the normal and diseased images. Some efficient deep convolutional neural network (CNN) based architectures are implemented utilizing the pre-trained weights obtained via transfer learning. In order to achieve significant improvement in the classification performance, the predictions obtained from some selected deep CNN architectures, namely ResNet50, InceptionResNetV2, EfficientNetB0 and EfficientNetB2 are combined. Comprehensive experimentation carried out on an extensive ophthalmic database show promising performance. The wide range of disease and diverse collection conditions of the fundus images affirm the suitability of the method for practical implementation.","Retinal Fundus,Ocular,CNN,Transfer Learning,Ensemble Network,Classifier",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE),,
36,Classification of Epileptic Activity Through Temporal and Spatial Characterization of Intracranial Recordings,11925,,69-79,"D'Amario Vanessa,Arnulfo Gabriele,Nobili Lino,Barla Annalisa","D'Amario V,Arnulfo G,Nobili L,Barla A",D'Amario V,10.1007/978-3-030-34585-3_6,University of Genoa,"Focal epilepsy is a chronic condition characterized by hyperactivity and abnormal synchronization of a specific brain region. For pharmacoresistant patients, the surgical resection of the critical area is considered a valid clinical solution, therefore, an accurate localization is crucial to minimize neurological damage. In current clinical routine the characterization of the Epileptogenic Zone (EZ) is performed using invasive methods, such as Stereo-ElectroEncephaloGraphy (SEEG). Medical experts perform the tag of neural electrophysiological recordings by visually inspecting the acquired data, a highly time consuming and subjective procedure. Here we show the results of an automatic multi-modal classification method for the evaluation of critical areas in focal epileptic patients. The proposed method represents an attempt in the characterization of brain areas which integrates the anatomical information on neural tissue, inferred using Magnetic Resonance Imaging (MRI) in combination with spectral features extracted from SEEG recordings.","Focal epilepsy,Machine learning,Spectral analysis,Signal processing,Multi-modal data analysis",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"FREQUENCY,HZ",,https://iris.unige.it/bitstream/11567/1007648/4/seeg_ptd.pdf,
37,Neural Models for Brain Networks Connectivity Analysis,11925,,212-226,"Kusztos Razvan,Dimitri Giovanna Maria,Lio Pietro","Kusztos R,Dimitri GM,Lio P",Dimitri GM,10.1007/978-3-030-34585-3_19,University of Cambridge,"Functional MRI (fMRI) attracts huge interest for the machine learning community nowadays. In this work we propose a novel data augmentation procedure through analysing the inherent noise in fMRI. We then use the novel augmented dataset for the classification of subjects by age and gender, showing a significant improvement in the accuracy performance of Recurrent Neural Networks. We test the new data augmentation procedure in the fMRI dataset belonging to one international consortium of neuroimaging data for healthy controls: the Human Connectome Projects (HCP).
From the analysis of this dataset, we also show how the differences in acquisition habits and preprocessing pipelines require the development of representation learning tools. In the present paper we apply autoencoder deep learning architectures and we present their uses in resting state fMRI, using the novel data augmentation technique proposed.
This research field, appears to be unexpectedly undeveloped so far, and could potentially open new important and interesting directions for future analysis.","fMRI,Deep learning,Data augmentation",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,,,,
38,Unravelling Breast and Prostate Common Gene Signatures by Bayesian Network Learning,11925,,285-292,"Villa-Brito Joao,Lopes Marta B.,Carvalho Alexandra M.,Vinga Susana","Villa-Brito J,Lopes MB,Carvalho AM,Vinga S",Villa-Brito J,10.1007/978-3-030-34585-3_25,Universidade de Lisboa,"Breast invasive carcinoma (BRCA) and prostate adenocarcinoma (PRAD) are two of the most common types of cancer in women and men, respectively. As hormone-dependent tumours, BRCA and PRAD share considerable underlying biological similarities worth being exploited. The disclosure of gene networks regulating both types of cancers would potentially allow the development of common therapies, greatly contributing to disease management and health economics. A methodology based on Bayesian network learning is proposed to unravel breast and prostate common gene signatures. BRCA and PRAD RNASeq data from The Cancer Genome Atlas (TCGA) measured over similar to 20000 genes were used. A prior dimensionality reduction step based on sparse logistic regression with elastic net penalisation was employed to select a set of relevant genes and provide more interpretable results. The Bayesian networks obtained were validated against information from STRING, a database containing known gene interactions, showing high concordance.","Sparse logistic regression,Gene expression,Machine learning",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Biochemistry & Molecular Biology,Computer Science,Mathematical & Computational Biology",,,"REGRESSION,SELECTION",,,
39,Intelligent Sensor Array Based on Machine Learning,11617,,,"Chen Jinming,He Qingguo,Cheng Jiangong","Chen JM,He QG,Cheng JG",Cheng JG,10.1117/12.2585241,Chinese Academy of Sciences,"With the development of Internet and IoT (Internet of Things), the specificity and sensitivity of traditional sensors cannot meet the multi-task requirements in complex environments. The sensor array can solve the limitation that a single sensor can only detect one target to a certain extent. However, the sensor array still cannot solve the recognition of cross-sensitive similar target. This work proposes a solution based on machine learning that can greatly improve the specificity of traditional sensors. It can potentially be used in non-contact breathing diagnosis. Firstly, carbon nanotube materials were chose as electrical carriers, taking advantage of its high specific surface area and high electron mobility characteristics. Secondly, a series of organic molecules are designed to modify carbon nanotubes. The ability of organic materials to capture amines enables response output to amine gases. In order to meet the needs of exhaled breath diagnosis, we need to further distinguish amines with high similarity (ammonia, n-propylamine, diethylamine, triethylamine). Therefore, we have adopted the method of machine learning. The data of resistance with time collected by the sensor array are input as eigenvalues into a pre-designed neural network model for training. The trained model can achieve over 80% recognition accuracy in testing data. The purpose of this work is to propose a new and better solution to the detection of targets with cross-sensitivity, thereby improving the selectivity of the sensor. It provides the possibility to use it under different requirements to achieve intelligent detection.","intelligent sensor,machine learning,IoT,breath analyzer",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Science & Technology - Other Topics,Optics",,,BREATH,,,
40,Structured illumination microscopy under low modulation-depth based on U-net learning,11617,,,"Deng Jiawei);,Wang Mingqun);,Lu Xin);,Fang Hui","Deng JW,Wang MQ,Lu X,Fang H",Fang H,10.1117/12.2585412,Shenzhen University,"Structure Illumination Microscopy (SIM) is a wide-field super-resolution fluorescence imaging technology with characteristics such as fast imaging speed and low phototoxicity. By projecting sinusoidal patterns at the sample plane, the high-frequency infounation in Fourier space which is out of the optical transfer function of the optical system is loaded into the low-frequency infounation and collected by the objective lens. However, due to the mechanical error of the system, the fringes in the collected data often have some deviation from the presupposed initial values. These systemic errors of fringe will directly affect the quality of the reconstructed SIM image, among which Fringe modulation depth is a very important parameter. Here, we explored the SIM reconstruction method based on the U-net neural network architecture recently reported by Luhong Jin et al. We performed a simulation to validate the method. Specifically, we use an open source fluorescent-bead images for the training and testing. We found that after training, the output of the trained neural network is very close to the ground truth, and then the super-resolution infounation can be well recovered from the low-modulation SIM raw images. We then further performed the similar study on the images of real biological structures which are also available as an open source dataset. Our study thus demonstrates that the deep learning neural network algorithm can significantly relax the requirement on the fringe modulation depth.Therefore, the simplified SIM system without any polarization modulation can be expected.","Structure Illumination Microscopy,Super-Resolution,Fringe Modulation Depth,U-net",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Science & Technology - Other Topics,Optics",,,,,,
41,CNN-assisted inverse design of wavelength demultiplexer with digital metamaterials,11617,,,"Huang Jie,Shi Ruiyang,Niu Lingfeng,Yang Junbo,Jiang Xinpeng","Huang J,Shi RY,Niu LF,Yang JB,Jiang XP",Yang JB,10.1117/12.2585385,National University of Defense Technology - China,"Inverse design is one of the most important design methods of nanophotonic devices. In recent years, with the rapid development of deep learning technique and applications, deep learning assisted inverse design method has been introduced into the field of nanophotonic device design. In this work, by combining the direct binary search method with multilayer convolutional neural networks, we present the inverse design of a wavelength demultiplexer which has 1352 design variables. The dropout strategy has been employed to avoid overfitting in training the inverse design model. The simulation results indicate that the trained CNN can both efficiently forward predict the spectrum and inverse design the structure.","inverse design,convolutional neural networks,wavelength demultiplexer,digital metamaterials",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Science & Technology - Other Topics,Optics",,,ULTRA-COMPACT,,,
42,Medical image reconstruction with image-adaptive priors learned by use of generative adversarial networks,11312,,,"Bhadra Sayantan,Zhou Weimin,Anastasio Mark A.","Bhadra S,Zhou WM,Anastasio MA",Anastasio MA,10.1117/12.2549750,University of Illinois System,"Medical image reconstruction is often an ill-posed inverse problem. In order to address such ill-posed inverse problems, prior knowledge of the sought after object property is usually incorporated by means of regularization. For example, sparsity-promoting regularization in a suitable transform domain is widely used to reconstruct images with diagnostic quality from noisy and/or incomplete medical data. However, sparsity-promoting regularization may not be able to comprehensively describe the actual prior information of the objects being imaged. Deep generative models, such as generative adversarial networks (GANs) have shown great promise in learning the underlying distribution of images. Prior distributions for images estimated using GANs have been employed as a means of regularization with impressive results in several linear inverse problems in computer vision that are also relevant to medical imaging. However, in practice, it can be difficult for a GAN to comprehensively describe prior distributions, which can potentially lead to a lack of fidelity between the reconstructed image and the observed data. Recently, an image-adaptive GAN-based reconstruction method (IAGAN) was proposed to guarantee stronger data consistency by adapting the trained generative model parameters to the observed measurements. In this work, for the first time, we apply the IAGAN method to reconstruct images from undersampled magnetic resonance imaging (MRI) measurements. A state-of-the-art GAN model called Progressive Growing of GANs (ProGAN) was trained on a large number of ground truth images from the NYU fastMRI dataset, and the learned generator was subsequently employed in the IAGAN framework to reconstruct high fidelity images from retrospectively undersampled experimental k-space data in the validation dataset. It is demonstrated that by use of the GAN-based reconstruction method with noisy and/or incomplete measurements, we can potentially recover fine structures in the object that are relevant for medical diagnosis that may be difficult to achieve using traditional reconstruction methods relying on sparsity-promoting penalties.","medical image reconstruction,inverse problems,regularization,deep learning,generative adversarial networks,compressed sensing,magnetic resonance imaging",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,MRI,,http://arxiv.org/pdf/2001.10830,
43,"Fast spectral x-ray CT reconstruction with data-adaptive, convolutional regularization",11312,,,"Clark D. P.,Badea C. T.","Clark DP,Badea CT",Badea CT,10.1117/12.2549615,Duke University,"Advancements in deep learning and GPU computing have exponentially driven the application of neural networks to classic medical imaging problems: denoising, segmentation, artifact removal, etc. Deep learning solutions are particularly attractive for processing multi-channel, volumetric image data, where processing and reconstruction methods are often computationally expensive. Convolutional neural networks (CNNs) are commonly applied to multi-channel image data by matching the number of network input channels to the number of data channels, learning explicit relationships between channels. This provides a high degree of specificity to a particular problem, but may fail to generalize to a broader class of closely related problems. We propose a solution to this generalization problem in the context of spectral x-ray CT, where the scanning kVps (energy bins) and contrast are often variable. Specifically, we propose a novel CNN architecture which handles variable numbers of input channels, variable noise levels between channels, and variable modes of spectral contrast. We demonstrate our architecture in the application of preclinical, photon-counting, micro-CT, effectively replacing 1-2 hours of iterative reconstruction, with <10 minutes of analytical reconstruction and CNN regularization. Experimental validation shows the effectiveness of our approach when applied to both in vivo photon-counting validation data (4 energy thresholds) and to simulated, dual-energy CT data virtually acquired with an energy integrating detector. In both cases, the results output by the CNN provide greater spectral accuracy than analytical reconstruction alone, but suffer from some degradation of spatial resolution. We conclude by proposing several extensions of our work to better preserve spatial resolution.","x-ray CT (CT),photon counting imaging (PCI),image reconstruction (RECON),small animal imaging (SMAX)",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
44,Deep learning-aided CBCT image reconstruction of interventional material from four x-ray projections,11312,,,"Eulig Elias,Maier Joscha,Bennett N. Robert,Knaup Michael,Hoerndler Klaus,Wang Adam,Kachelriess Marc","Eulig E,Maier J,Bennett NR,Knaup M,Horndler K,Wang A,Kachelriess M",Eulig E,10.1117/12.2548662,Helmholtz Association,"Interventional guidance aims at providing the radiologist with detailed information about the location and orientation of interventional tools such as guide wires and stents. Most commonly, this is done by acquiring flouroscopic images using an interventional C-arm system. Due to its projective nature, fluoroscopy is restricted to provide information from two spatial dimensions, preventing an exact 3D localization of the interventional tools. Analogous to computed tomography for diagnostic imaging, four-dimensional (three spatial dimensions plus the temporal dimension) interventional guidance has the potential to drastically improve both the speed and accuracy of such interventions, but is currently impractical due to the excessively high dose that would be necessary for continuous cone-beam CT (CBCT) scanning at high frame rates.
In this work we develop a novel deep learning-based approach to reconstruct interventional tools from only four x-ray projections. We train and test this deep tool reconstruction (DTR) network on simulated data. Only small deviations from the ground truth (GT) reconstruction of the tools were observed, both quantitatively and qualitatively, showing that deep learning-based four-dimensional interventional guidance has the potential to overcome the drawbacks of conventional interventional guidance in the future.","Interventional Imaging,C-Arm CT,CBCT,Sparse Projections,Deep Learning,Convolutional Neural Network",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
45,Development of a denoising convolutional neural network-based algorithm for metal artifact reduction in digital tomosynthesis,11312,,,"Gomi Tsutomu,Hara Hidetake,Watanabe Yusuke,Mizukami Shinya","Gomi T,Hara H,Watanabe Y,Mizukami S",Gomi T,10.1117/12.2541841,Kitasato University,"This study aimed to evaluate a denoising convolutional neural network reconstruction (DnCNNR) algorithm for reducing metal objects on digital tomosynthesis when using projection data for arthroplasty. For metal artifact reduction (MAR), we implemented a DnCNNR algorithm based on a training network (i.e., mini-batch stochastic gradient-descent algorithm with momentum) to estimate residual reference (140 keV virtual monochromatic [VM]) and object (70 kV with metal artifacts) images using projection data, and subtracted the estimated residual images from the object images using hybrid and subjectively reconstructed images (back projection and maximum likelihood expectation maximization [MLEM]). This DnCNNR algorithm was compared with a dual-energy material decomposition reconstruction algorithm (DEMDRA), VM, MLEM, established and commonly used filtered back projection (FBP) methods, and simultaneous algebraic reconstruction technique-total variation (SART-TV) with MAR processing. MAR was then compared using artifact index (AI) and texture analyses. For images that were in-focus were evaluated using a prosthesis phantom. The derived images yielded better results that were not influenced by the metal type (e.g., the AI was almost equal to the best value for the DEMDRA). The DnCNNR algorithm also yielded the best performance with regard in the texture analysis. The proposed algorithm is particularly useful for not affected by tissue misclassification.","tomosynthesis,metal artifact reduction,convolutional neural network,arthroplasty",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,"RECONSTRUCTION,ALGORITHMS,ARTHROPLASTY",,,
46,Quality Assessment of Brain MRI Scans using a Dense Neural Network Model and Image Metrics,11312,,,"Gupta Ashish,Sadri Amir Reza,Viswanath Satish E.,Tiwari Pallavi","Gupta A,Sadri AR,Viswanath SE,Tiwari P",Viswanath SE,10.1117/12.2551348,Case Western Reserve University,"Structural MRI is the standard-of-care imaging modality for screening and diagnosis of most neurological conditions. However, the ability to reliably evaluate brain MRIs for disease characterization (whether by machines or experts) is often hampered by the presence of artifacts such as magnetic field inhomogeneity, aliasing, or patient motion; some of which may not be visually apparent. Reliable quality assessment of brain MRI scans would allow for excluding noisy acquisitions and reducing errors in subsequent downstream analyses. Since visual inspection is impractical for large volumes of data and subject to inter-observer variability, there is a need for accurate, automated Quality Assessment (QA) of MR images. Previous studies have investigated image quality metrics (IQMs) in order to quantify the effect of specific artifacts and quality degradation in an MR image. There has also been some recent work in developing machine learning models which use IQMs to enable robust QA across multiple sites. We build on this approach by leveraging a total of 64 IQMs (quantifying noise, artifacts, information, and general brain measurements) within a Dense Neural Network (DNN) model for QA of brain MRI scans using the publicly available multi-site ABIDE-I cohort (17 sites, 1102 subjects). In attempting to predict the ""mean opinion score"" of MR image quality (as assessed by expert radiologists), the DNN model yielded an accuracy of 87.3 +/- 2.1% in training (15 sites, 885 subjects) which generalized to a 79.5 +/- 1.9% accuracy in validation (2 sites, 246 subjects). This initial DNN model suggests the promise of deep learning to improve automated QA of MRI scans in large multi-site, multi-scanner cohorts.","MRI,quality assessment,deep learning,ABIDE,quality control",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
47,Pixel-Defect Corrections for Radiography Detectors Based on Deep Learning,11312,,,"Hong Eunyeong,Kang Songhee,Lee Eunae,Yoo Namjo,Choi Jae Young,Kim Dong Sik","Hong E,Kang S,Lee E,Yoo N,Choi JY,Kim DS",Hong E,10.1117/12.2549684,Hankuk University Foreign Studies,"Flat-panel radiography detectors employ the thin film transistor (TFT) panels to acquire high-quality x-ray images. Pixel defects in the TFT panel can degrade the image quality and lower the production yield of the panel, and ultimately increase the production cost. Hence, developing an appropriate defect correction algorithm for acquired images is important. Conventional algorithms are based on statistical learning and hence optimizing their performances is difficult especially for image edge parts. To alleviate this problem, a template matching technique can be used. In this paper, we considered various pixel-defect correction algorithms based on deep learning techniques, such as the artificial neural network (ANN), convolutional neural network (CNN), and generative adversarial networks, and compared their performances. The defect-correction performances are compared using practical x-ray images acquired from general radiography detectors. A concatenate CNN showed the best defect-correction performance. We also showed that a single-layer ANN could conduct an efficient defect correction in terms of both correction and computational complexity performances.","Deep learning,flat-panel detectors,pixel-defect correction,radiography imaging",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
48,PET Attenuation Correction Using Non-AC PET-based Synthetic CT,11312,,,"Lei Yang,Wang Tonghe,Dong Xue,Higgins Kristin,Liu Tian,Curran Walter J.,Mao Hui,Nye Jonathon A.,Yang Xiaofeng","Lei Y,Wang TH,Dong X,Higgins K,Liu T,Curran WJ,Mao H,Nye JA,Yang XF",Yang XF,10.1117/12.2548468,Emory University,"The accuracy of attenuation correction on whole-body PET images is subject to inter-scan motion, image artifacts such as truncation and distortion, and erroneous transformation of structural voxel-intensities to PET mu-map values. We proposed a deep-learning-based method to derive synthetic CT (sCT) images from non-attenuation corrected PET (NAC PET) images for AC on whole-body PET imaging. We utilized a 3D cycle-consistent generative adversarial networks (CycleGAN) to synthesize CT images from NAC PET. The model learns a transformation that minimizes the difference between sCT, generated from NAC PET, and true CT. It also learns an inverse transformation such that cycle NAC PET image generated from the sCT is close to true NAC PET image. Both generators are implemented by a fully convolutional attention network (FCAN), and followed by a discriminator which is structured as a fully convolutional network. A retrospective study was performed with a total of 60 sets of whole-body PET/CT, 40 sets for training and 20 sets for testing. The sCT images generated with proposed method show great contrast on lung, soft tissue and bony structures. The mean absolute error of sCT over true CT is less than 110 HU. Using sCT for whole-body PET AC, the mean error of PET quantification is less than 1% and normalized mean square error is less than 1.4%. We proposed a deep learning-based approach to generate synthetic CT from whole-body NAC PET for PET AC, which demonstrates excellent synthetic CT estimation accuracy and PET quantification accuracy.","Positron emission tomography,attenuation correction,synthetic CT,cycle consistent generative adversarial network",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,"MRI,ATLAS,SEGMENTATION,PET%2FMRI,REGISTRATION",,,
49,Unsupervised Data Fidelity Enhancement Network for Spectral CT Reconstruction,11312,,,"Li Danyang,Li Sui,Zhu Manman,Gao Qi,Bian Zhaoying,Huang Haiyun,Zhang Shanli,Huang Jing,Zeng Dong,Ma Jianhua","Li DY,Li S,Zhu MM,Gao Q,Bian ZY,Huang HY,Zhang SL,Huang J,Zeng D,Ma JH",Ma JH,10.1117/12.2548893,Southern Medical University - China,"Deep learning (DL) networks show a great potential in computed tomography (CT) imaging field. Most of them are supervised DL network greatly based on their capability and the amount of CT training data (i.e., low-dose CT measurements/high-quality ones). However, collection of large-scale CT datasets are time-consuming and expensive. In addition, the training and testing CT datasets used for supervised DL network are highly desired similarities in CT scan protocol (i.e., similar anatomical structure, and same kVp setting). These two issues are particularly critical in spectral CT imaging. In this work, to address the issues, we presents an unsupervised data fidelity enhancement network (USENet) to produce high-quality spectral CT images. Specifically, the presented USENet consists of two parts, i.e., supervised network and unsupervised network. In the supervised network, the spectral CT image pairs at 140 kVp (low-dose CT images/high-dose ones) are used for network training. It should be noted that there is a great difference of CT value between spectral CT images at 140 kVp and 80 kVp, and the supervised network trained with CT images at 140 kVp cannot be directly used for CT image reconstruction at 80 kVp. Then unsupervised network enrolls physical model and the spectral CT measurements at 80 kVp for fine-tuning the supervised network, which is the major contribution of the presented USENet method. Finally, accurate spectral CT reconstructions are achieved for the sparse-view and low-dose cases, which fully demonstrate the effectiveness of the presented USENet method.","Supervised learning,Unsupervised learning,Spectral CT,CT reconstruction",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
50,Non-Local Texture Learning Approach for CT Imaging Problems using Convolutional Neural Network,11312,,,"Li Sui,Yao Lisha,Zhu Manman,Li Danyang,Gao Qi,Zhang Xinyu,Zhong Rikui,Bian Zhaoying,Zeng Dong,Ma Jianhua","Li S,Yao LS,Zhu MM,Li DY,Gao Q,Zhang XY,Zhong RK,Bian ZY,Zeng D,Ma JH",Ma JH,10.1117/12.2548949,Southern Medical University - China,"Deep learning-based algorithms have been widely used in the low-dose CT imaging field, and have achieved promising results. However, most of these algorithms only consider the information of the desired CT image itself, ignoring the external information that can help improve the imaging performance. Therefore, in this study, we present a convolutional neural network for low-dose CT reconstruction with non-local texture learning (NTL-CNN) approach. Specifically, different from the traditional network in CT imaging, the presented NTLCNN approach takes into consideration the non-local features within the adjacent slices in 3D CT images. Then, both low-dose target CT images and the non-local features feed into the residual network to produce desired high-quality CT images. Real patient datasets are used to evaluate the performance of the presented NTL-CNN. The corresponding experiment results demonstrate that the presented NTL-CNN approach can obtain better CT images compared with the competing approaches, in terms of noise-induced artifacts reduction and structure details preservation.","Low-dose CT,Non-local texture,Convolution neural network,Deep learning,CT restoration",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
51,Feasibility of Achieving Spectral CT Imaging from A Single KV Acquisition and Deep Learning Method,11312,,,"Li Yinsheng,Cruz-Bastida Juan Pablo,Li Ke,Bushe Daniel,Francois Christopher,Lubner Meghan,Chen Guang-Hong","Li YS,Cruz-Bastida JP,Li K,Bushe D,Francois C,Lubner M,Chen GH",Li YS,10.1117/12.2549611,University of Wisconsin System,"CT imaging is one of the primary diagnostic tools utilized in modern radiology departments. Current state-of-the-art spectral CT imaging systems have been implemented using advanced x-ray source and/or detector technologies that have enabled image objects to be rapidly scanned using two distinct x-ray spectra (i.e., different effective beam energies). In this paper, we study the possibility to extract the encoded spectral information from the measured data when a single polychromatic x-ray spectrum is used to acquire data using an energy integration detector. Based upon our physical analysis, a physics-based deep neural network architecture, termed the Deep Spectral Imaging Network, was trained to demonstrate the feasibility of achieving spectral CT imaging using an energy integration detector and a single-kV acquisition.",,Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
52,Prior knowledge driven machine learning approach for PET sinogram data denoising,11312,,,"Lu Siming,Tan Jiaxing,Gao Yongfeng,Shi Yongyi,Liang Zhengrong","Lu SM,Tan JX,Gao YF,Shi YY,Liang ZR",Liang ZR,10.1117/12.2549900,State University of New York (SUNY) System,"Machine learning, especially convolutional neural network (CNN) approach has been successfully applied in noise suppression in natural image. However, shifting from natural image to medical image filed remains challenging due to specific difficulties such as training samples limitation, clinically meaningful image quality requirement and so on. To address this challenge, one possible solution is to incorporate our human prior knowledge into the machine learning model to better benefit its power. Therefore, in this work, we propose one prior knowledge driven machine learning based approach for positron emission tomography (PET) sinogram data denoising. Two main properties of PET sinogram data were considered in CNN architecture design, which are the Poisson statistics of the data and different correlation strength in the detector and view directions. Specially, for the statistical property, the sparse non-local method was used. For the correlation property, separate convolution was applied in two directions respectively. Experimental results showed the proposed model outperform the CNN model without prior knowledge. Results also demonstrate our insight of applying human knowledge strength the power of machine learning in medical imaging field.","Positron Emission Tomography,Sinogram Denoising,Machine Learning,Prior Knowledge",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
53,Progressive Transfer Learning Strategy for Low-dose CT Image Reconstruction with Limited Annotated Data,11312,,,"Meng Mingqiang,Li Danyang,Li Sui,Zhu Manman,Wang Lei,Gao Qi,Bian Zhaoying,Zhang Xinyu,Huang Jing,Zeng Dong","Meng MQ,Li DY,Li S,Zhu MM,Wang L,Gao Q,Bian ZY,Zhang XY,Huang J,Zeng D",Ma JH,10.1117/12.2548946,Southern Medical University - China,"Low-dose computed tomography (LDCT) examinations are of essential usages in clinical applications due to the lower radiation-associated cancer risks in CT imaging. Reductions in radiation dose can produce severe noise and artifacts that can affect the diagnostic accuracy of radiologists. Although deep learning networks have been widely proposed, most of these networks rely on a large number of annotated CT image pairs (LDCT images/high-dose CT (HDCT) images). Moreover, it is challenging for these networks to cope with the growing amount of CT images, especially large amount of medium-dose CT (MDCT) images that are easily to collect and have lower radiation dose than the HDCT images and higher radiation dose than the LDCT images. Therefore, in this work, we propose a progressive transfer-learning network (PETNet) for low-dose CT image reconstruction with limited annotated CT data and abundant corrupted CT data. The presented PETNet consists of two phases. In the first phase, a network is trained on a large amount of LDCT/MDCT image pairs, similar to the Noise2Noise network that has shown potential in yielding promising results with corrupted data for network training. It should be noted that this network would inevitably introduce undesired bias in the results due to the complex noise distribution in CT images. Then, in the second phase, we combined the pre-trained network and another simple network to construct the presented PETNet. In particular, the parameters of the pre-trained network are frozen and transferred directly to the presented PETNet, and the presented PETNet is trained on a small amount of LDCT/HDCT image pairs. Experimental results on Mayo clinic data demonstrate the superiority of the presented PETNet method both qualitatively and quantitatively compared with the network trained on LDCT/HDCT images pairs, and Noise2Noise method trained on LDCT/MDCT image pairs.","Low-dose CT,Deep learning,Transfer learning,Image reconstruction,Medium dose CT image",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,NETWORK,,,
54,Semi-supervised Learned Sinogram Restoration Network for Low-Dose CT Image Reconstruction,11312,,,"Meng Mingqiang,Li Sui,Yao Lisha,Li Danyang,Zhu Manman,Gao Qi,Xie Qi,Zhao Qian,Bian Zhaoying,Huang Jing","Meng MQ,Li S,Yao LS,Li DY,Zhu MM,Gao Q,Xie Q,Zhao Q,Bian ZY,Huang J",Ma JH,10.1117/12.2548985,Southern Medical University - China,"With the development of deep learning (DL), many deep learning (DL) based algorithms have been widely used in the low-dose CT imaging and achieved promising reconstruction performance. However, most DL-based algorithms need to pre-collect a large set of image pairs (low-dose/high-dose image pairs) and trains networks in a supervised end-to-end manner. Actually, it is not feasible in clinical to obtain such a large amount of paired training data, especially for high-dose ones. Therefore, in this work, we present a semi-supervised learned sinogram restoration network (SLSR-Net) for low-dose CT image reconstruction. The presented SLSR-Net consists of supervised sub-network and unsupervised sub-network. Specifically, different from the traditional supervised DL networks which only use low-dose/high-dose sinogram pairs, the presented SLSR-Net method is capable of feeding only a few supervised sinogram pairs and massive unsupervised low-dose sinograms into the network training procedure. The supervised pairs are used to capture critical features (i.e., noise distribution, and tissue characteristics) latent in a supervised way and the unsupervised sub-network efficiently learns these features using a conventional weighted least-squares model with a regularization term. Moreover, another contribution of the presented SLSR-Net method is to adaptively transfer learned feature distribution from supervised sub-network with the paired sinograms to unsupervised sub-network with unlabeled low-dose sinograms to obtain high-fidelity sinogram with a Kullback-Leibler divergence. Finally, the filtered backprojection algorithm is used to reconstruct CT images from the obtained sinograms. Real patient datasets are used to evaluate the performance of the presented SLSR-Net method and the corresponding experimental results show that compared with the traditional supervised learning method, the presented SLSR-Net method achieves competitive performance in terms of noise reduction and structure preservation in low-dose CT imaging.","low-dose CT,semi-supervised learning,convolution neural network,sinogram recovery",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
55,"Evaluation of deep learning segmentation for rapid, patient-specific CT organ dose estimation using an LBTE solver",11312,,,"Offe Michael,Fraley David,Adamson Philip M.,Principi Sara,Wang Adam S.,Jordan Petr,Schmidt Taly Gilat","Offe M,Fraley D,Adamson PM,Principi S,Wang AS,Jordan P,Schmidt TG",Offe M,10.1117/12.2550314,Marquette University,"The overall goal of this work is to develop a rapid, accurate and fully automated software tool to estimate patient-specific organ doses from CT scans using a deterministic Linear Boltzmann Transport Equation (LBTE) solver (Acuros CTD) and deep-learning CT segmentation algorithms. This study evaluated the accuracy of deep learning segmentation for estimating organ dose from dose maps generated by Acuros. The study focused on pediatric CT due to increased radiation concerns and segmentation challenges for the pediatric population. Organs relevant to CT dosimetry were manually contoured by experts in 246 pediatric chest-abdomen-pelvis CT datasets to serve as ground truth. A fully convolutional network based on a modified V-net architecture was trained and tuned using 226 pediatric datasets ranging in age from 1 to 16 years. An additional twenty datasets were used for preliminary evaluation. The accuracy of organ dose estimates obtained from deep learning segmentation was evaluated relative to doses obtained from the ground truth contours. The deep learning segmentation algorithm resulted in low dose errors for all organs, with a mean absolute error across test patients of 1% or less and a maximum error of 3.5% for the heart. There was high similarity between deep learning and expert contours, with mean Dice coefficients across patients greater than or equal to 0.95. There was no correlation between organ dose error or Dice coefficient with the patient age. Based on statistical analysis of students paired T-test, there was no statistically significant difference between organ doses estimated using the deep learning contours as compared to the expert ground truth contours (p>0.2). Overall, the deep learning segmentation models applied to dose maps generated by the LBTE solver ( Acuros CTD) resulted in high organ dose accuracy. Additional evaluation is planned for more organ structures and patient datasets.",,Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
56,Benefit of Dual Energy CT for Lesion Localization and Classification with Convolutional Neural Networks,11312,,,"Shapira Nadav,Fokuhl Julia,Schultheiss Manuel,Beck Stefanie,Kopp Felix K.,Pfeiffer Daniela,Dangelmaier Julia,Pahn Gregor,Sauter Andreas P.,Renger Bernhard","Shapira N,Fokuhl J,Schultheiss M,Beck S,Kopp FK,Pfeiffer D,Dangelmaier J,Pahn G,Sauter AP,Renger B",Shapira N,10.1117/12.2549291,University of Pennsylvania,"Dual Energy CT is a modern imaging technique that is utilized in clinical practice to acquire spectral information for various diagnostic purposes including the identification, classification, and characterization of different liver lesions. It provides additional information that, when compared to the information available from conventional CT datasets, has the potential to benefit existing computer vision techniques by improving their accuracy and reliability. In order to evaluate the additional value of spectral versus conventional datasets when being used as input for machine learning algorithms, we implemented a weakly-supervised Convolutional Neural Network (CNN) that learns liver lesion localization and classification without pixel-level ground truth annotations. We evaluated the lesion classification (healthy, cyst, hypodense metastasis) and localization performance of the network for various conventional and spectral input datasets obtained from the same CT scan. The best results for lesion localization were found for the spectral datasets with distances of 8.22 +/- 10.72 mm, 8.78 +/- 15.21 mm and 8.29 +/- 12.97 mm for iodine maps, 40 keV and 70 keV virtual mono-energetic images, respectively, while lesion localization distances of 10.58 +/- 17.65 mm were measured for the conventional dataset. In addition, the 40 keV virtual mono-energetic datasets achieved the highest overall lesion classification accuracy of 0.899 compared to 0.854 measured for the conventional datasets. The enhanced localization and classification results that we observed for spectral CT data demonstrates that combining machine-learning technology with spectral CT information may improve the clinical workflow as well as the diagnostic accuracy.","Dual Energy CT (DECT),Convolutional Neural Networks (CNN),Hepatic imaging,Liver lesion localization,Liver lesion classification",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,"HEPATIC,METASTASES,SPECTRAL,CT,PRINCIPLES",,,
57,Tensor Convolutional Neural Network Architecture for Spectral CT Reconstruction,11312,,,"Shi Yongyi,Gao Yongfeng,Mou Xuanqin,Liang Zhengrong","Shi YY,Gao YF,Mou XQ,Liang ZR",Mou XQ,10.1117/12.2549289,Xi'an Jiaotong University,"Photon-counting spectral computed tomography (PCCT) reconstructs multiple energy-channel images to describe the same object, where there exists a strong correlation among all channels. In addition, reconstruction of each energy-channel image suffers photon count starving problem. To make full use of the correlation among different channels to suppress the data noise and enhance the tissue texture in reconstructing each energy-channel image, this paper proposed a tensor convolutional neural network (TCNN) architecture to learn a tissue-specific texture prior for PCCT reconstruction. Specifically, we first model the spatial texture prior information in each individual channel using a convolution neural network, and then extract the correlation information among different energy channels by merging the multi-channel networks. Finally, we integrate the TCNN as a prior into Bayesian reconstruction framework. To evaluate the tissue texture preserving performance of the proposed method for each channel, a vivid clinical phantom which can simulate the real tissue textures was employed. The improvement associated with TCNN is remarkable relative to simultaneous algebraic reconstruction technique (SART) and tensor dictionary learning (TDL) based reconstruction. The proposed method produced promising results in terms of not only preserving texture feature but also suppressing image noise in each channel. The proposed method outperforms the competing methods in both visual inspection and quantitative indexes of root mean square error (RMSE), peak signal to noise ratio (PSNR), structural similarity (SSIM) and feature similarity (FSIM).","Photon-counting Spectral CT,Tensor Convolutional Neural Network,Texture Information",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,IMAGE-RECONSTRUCTION,,,
58,Estimation of Local Deformable Motion in Image-Based Motion Compensation for Interventional Cone-Beam CT,11312,,,"Sisniega A.,Capostagno S.,Zbijewski W.,Stayman J. W.,Weiss C. R.,Ehtiati T.,Siewerdsen J. H.","Sisniega A,Capostagno S,Zbijewski W,Stayman JW,Weiss CR,Ehtiati T,Siewerdsen JH",Siewerdsen JH,10.1117/12.2549753,Johns Hopkins University,"Purpose: Cone-beam CT is increasingly used for 3D guidance in interventional radiology (IR), but long image acquisition time results in degradation from complex deformable motion of soft-tissue structures. Deformable motion compensation with multi-region autofocus optimization was shown to improve image quality. However, the high dimensionality and non-convexity of the optimization problem challenge its convergence. This work presents preliminary development and early results obtained from an automatic learning-based decision framework to obtain local estimates of basic properties of the deformable motion field, coupled to a preconditioning strategy to simplify the optimization.
Methods: Deformable motion properties are estimated with a deep convolutional neural network (CNN) consisting of a concatenation of custom-designed residual blocks. The preliminary design provided an estimate of the local motion amplitude on an 8x8 grid covering an axial slice of a motion-contaminated CBCT volume. The decision framework is coupled to a preconditioning strategy that effectively favors more likely solutions through motion amplitude-driven spatially-varying regularization of the motion trajectory and spatially varying selection of the search range for the optimization problem. The network was trained on simulated data generated from publicly available CT datasets, including simple motion fields.
Results: Predictions of local motion amplitude showed good agreement with the true values, with root mean squared error (RMSE) < 10 mm for the complete range of motion distributions explored (sufficient for the intended purpose of initialization). Combination of amplitude prediction with spatially varying regularization and search range setting resulted in improved motion compensation after 1000 iterations of the preconditioned multi-motion autofocus in an example case with complex deformable motion. Extensive validation in a large dataset of complex, multi-motion patterns is underway.
Conclusion: The proposed approach shows promising initial results and the potential for automatic local motion estimation with learning-based methods. Pending ongoing development to extend this initial development, the method could simplify and accelerate complex deformable motion compensation with spatially varying preconditioning of the motion estimation.","motion compensation,motion correction,cone-beam CT,intraoperative imaging,neural network",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,CHEMOEMBOLIZATION,,,
59,Methods for object tracking and shadowing in a top-down view virtual reality scattered radiation display system (SDS) for fluoroscopically-guided procedures,11312,,,"Troville J.,Guo C.,Rudin S.,Bednarek D. R.","Troville J,Guo C,Rudin S,Bednarek DR",Troville J,10.1117/12.2548469,State University of New York (SUNY) System,"We have developed a prototype scatter-display system (SDS) which includes a top-down view, virtual reality (VR) representation of an interventional room containing a color-coded scatter dose rate distribution in real-time. To represent various attenuating objects of interest in the room, such as the C-Arm gantry and ceiling mounted shield, the STL toolbox in Matlab was implemented to produce a 3D VR description of theobjects. Attenuation by objects in the room will alter the dose distribution and may lead to shielding of individual staff members, and thus representation of those objects in the software is needed for precise dose rate estimations. Determination of the spatial regions of attenuation requires accurate specification of object position. To retain identification of a ceiling mounted shield, we implemented an open-source package which maintains object recognition using the depth camera feed of a Microsoft Kinect V2 and the features-from-accelerated-segment- test (FAST) algorithm in OpenCV for a dense sampling of salient features. The depth information from the identified object is transferred to an open-source robot operating system (ROS) wrapper for specification of the 3D position to be fed into the SDS. To compute the C-Arm gantry position, we take advantage of a controller area network (CAN) bus interfaced with the angiography system's application programming interface (API). Methods for computing gantry and ceiling mounted shield shadow regions are discussed and demonstrated. FAST was applied to the ceiling-shield assembly's flange with reliable recognition. Including object attenuation of room scatter in the SDS will facilitate accurate dose rate computation.","Robot Operating System (ROS),Microsoft Kinect V2,Object Recognition,Machine Learning,OpenCV,Fluoroscopically Guided Interventions (FGI),Compton Scatter Radiation,X-Ray Scatter Attenuation",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,"INTERVENTIONAL,RADIOLOGY",,,
60,Semi-Supervised Noise Distribution Learning for Low-dose CT Restoration,11312,,,"Wang Lei,Gao Qi,Meng Mingqiang,Li Sui,Zhu Manman,Li Danyang,Chen Gaofeng,Zeng Dong,Xie Qi,Zhao Qian","Wang L,Gao Q,Meng MQ,Li S,Zhu MM,Li DY,Chen GF,Zeng D,Xie Q,Zhao Q",Ma JH,10.1117/12.2548944,Southern Medical University - China,"Fully supervised deep learning (DL) methods have been widely used in low-dose CT (LDCT) imaging field and can usually achieve high accuracy results. These methods require a large labeled training set which consists of pairs of LDCT images as well as their corresponding high-dose CT (HDCT) ones. They successfully learn intermediate concept of features describing important components in CT images, such as noise distribution, and structure details, which is important to capture dependencies from LDCT image to HDCT ones. However, it should be noted that it is quite time-consuming and costly to obtain such a large of labeled CT images especially the HDCT images are limited in clinics. In comparison, lots of unlabeled LDCT images are usually easily accessible and massive critical information latent in the unlabeled LDCT can be leveraged to further boost restoration performance. Therefore, in this work, we present a semi-supervised noise distribution learning network to suppress noise-induced artifacts in the LDCT images. For simplicity, the presented network in termed as ""SNDL-Net"". The presented SNDL-Net consists of two sub-networks, i.e., supervised network, and unsupervised network. In the supervised network, the LDCT/HDCT image pairs are used for network training. And the unsupervised network considers the complex noise distribution in the LDCT images, and model the noise with a Gaussian mixture framework, then learns the proper gradient of LDCT images in a purely unsupervised manner. Similar with the supervised network training, the gradient information in a large of unlabeled LDCT images can be used for unsupervised network training. Moreover, to learn the noise distribution accurately, the discrepancy between the learned noise distribution in the supervised network and learned noise distribution in the unsupervised network can be modeled by a Kullback-Leibler (KL) divergence. Experiments on the Mayo clinic dataset verify the method is effective in low-dose CT image restoration with only a small amount of labeled data compared to previous supervised deep learning methods.","Low-dose CT,image restoration,noise distribution,deep learning,unsupervised network",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,NETWORK,,,
61,Attenuation Correction for PET/MRI Using MRI-based Pseudo CT,11312,,,"Wang Tonghe,Lei Yang,Dong Xue,Higgins Kristin,Liu Tian,Curran Walter J.,Mao Hui,Nye Jonathon A.,Yang Xiaofeng","Wang TH,Lei Y,Dong X,Higgins K,Liu T,Curran WJ,Mao H,Nye JA,Yang XF",Yang XF,10.1117/12.2548158,Emory University,"Deriving accurate attenuation maps for PET/MRI remains a challenging problem because MRI voxel intensities are not related to properties of photon attenuation and bone/air interfaces have similarly low signal. This work presents a learning-based method to derive patient-specific pseudo computed tomography (PCT) maps from routine T1-weighted MRI in their native space for attenuation correction of brain PET. We developed a machine-learning-based method using a sequence of alternating random forests under the framework of an iterative refinement model. Anatomical feature selection is included in both training and predication stages to achieve excellent performance. To evaluate its accuracy, we retrospectively investigated 17 patients, each of which has been scanned by PET/CT and MR for brain. The PET images were corrected for attenuation on CT images as ground truth, as well as on PCT images generated from MR images. The side-by-side image comparisons and joint histograms demonstrated very good agreement of PET images after correction by PCT and CT. The mean differences of voxel values in selected VOIs were less than 4%, the mean absolute difference of all active area is around 2.5%. This work demonstrates a novel learning-based approach to automatically generate CT images from routine T1-weighted MR images based on a random forest regression with patch-based anatomical signatures to effectively capture the relationship between the CT and MR images. Reconstructed PET images using the PCT exhibit errors well below accepted test/retest reliability of PET/CT indicating high quantitative equivalence.","PET,MR,attenuation correction,machine learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,"IMAGES,CLASSIFICATION,SEGMENTATION,REGISTRATION",,,
62,Deep Learning-based Low Dose CT Imaging,11312,,,"Wang Tonghe,Lei Yang,Dong Xue,Tian Zhen,Tang Xiangyang,Liu Yingzi,Jiang Xiaojun,Curran Walter J.,Liu Tian,Shu Hui-Kuo","Wang T,Lei Y,Dong X,Tian Z,Tang XY,Liu YZ,Jiang XJ,Curran WJ,Liu T,Shu HK",Yang XF,10.1117/12.2548142,Emory University,"We developed a machine-learning-based method generate good quality low dose CT using a residual block concept and a self-attention strategy with a cycle-consistent adversarial network framework. A fully convolution neural network with residual blocks and attention gates is used in the generator to enable end-to-end transformation. We have collected CT images from 30 patients treated with frameless brain stereotactic radiosurgery (SRS) for this study. These full dose images were used to generate projection data, which were then added with noise to simulate the low mAs scanning scenario. Low dose CT images were reconstructed from this noise-contaminated projection data, and were fed into our network along with the original full dose CT images for training. The performance of our network was evaluated by quantitatively comparing the high quality CT images generated by our method with the original full dose images. When mAs is reduced to 0.5% of the original CT scan, the mean square error of the CT images obtained by our method is similar to 1.6%, with respective to the original full dose images. The proposed method successfully improved the noise, CNR and non-uniformity level to be close to those of full dose CT images, and outperforms a state-of-art iterative reconstruction method. Dosimetric studies shows that the average differences of DVH metrics are less than 0.1 Gy (p>0.05). These quantitative results strongly indicate that the denoised low dose CT images using our method maintains image accuracy and quality, and are accurate enough for dose calculation in current CT simulation of brain SRS treatment. This study also demonstrates the great potential for low dose CT in the process of simulation and treatment planning.","PET,MR,attenuation correction,machine learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,"ITERATIVE,RECONSTRUCTION,RADIATION,OPTIMIZATION,CANCER,MRI",,,
63,Deep Learning-Based Relative Stopping Power Mapping Generation with Cone-Beam CT in Proton Radiation Therapy,11312,,,"Wang Tonghe);,Harms Joseph);,Lei Yang);,Ghavidel Beth);,Stokes William);,Liu Tian);,Curran Walter J.);,McDonald Mark);,Zhou Jun);,Yang Xiaofeng","Wang T,Harms J,Lei Y,Ghavidel B,Stokes W,Liu TA,Curran WJ,McDonald M,Zhou J,Yang XF",Yang XF,10.1117/12.2549275,Emory University,"Proton radiation therapy has shown highly conformal distribution of prescribed dose in target with outstanding normal tissue sparing stemming from its steep dose gradient at the distal end of the beam. However, the uncertainty in everyday patient setup can lead to a discrepancy between treatment dose distribution and the planning dose distribution. Conebeam CT (CBCT) can be acquired daily before treatment to evaluate such inter-fraction setup error, while a further evaluation on resulted dose distribution error is currently not available. In this study, we developed a novel deep-learning based method to predict the relative stopping power maps from daily CBCT images to allow for online dose calculation in a step towards adaptive proton radiation therapy. 20 head-and-neck patients with CT and CBCT images are included for training and testing. Our CBCT RSP results were evaluated with RSP maps created from CT images as the ground truth. Among all the 20 patients, the averaged mean absolute error between CT-based and CBCT-based RSP was 0.04 +/- 0.02, the averaged mean error was -0.01 +/- 0.03 and the averaged normalized correlation coefficient was 0.97 +/- 0.01. The proposed method provides sufficiently accurate RSP map generation from CBCT images, possibly allowing for CBCT-guided adaptive treatment planning for proton radiation therapy.","CBCT,proton,stopping power,machine learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,"DUAL-ENERGY,CT,SCATTER,CORRECTION,RADIOTHERAPY,HEAD,SINGLE",,,
64,Simulation of Hepatic Arteries and Synthesis of 2D Fluoroscopic Images for Interventional Imaging Studies,11312,,,"Whitehead Joseph F.,Nikolau Ethan P.,Periyasamy Sarvesh,Torres Luis A.,Laeseke Paul F.,Speidel Michael A.,Wagner Martin G.","Whitehead JF,Nikolau EP,Periyasamy S,Torres LA,Laeseke PF,Speidel MA,Wagner MG",Whitehead JF,10.1117/12.2549570,University of Wisconsin System,"Training of deep learning-based segmentation algorithms requires large datasets of annotated images. Obtaining large clinical datasets, particularly for interventional imaging, is difficult and annotating vessels manually in the images is very time-consuming. Simulated images can be used to supplement clinical datasets. We developed a technique for the simulation of realistic, anatomically- and physiologically-motivated hepatic artery trees and subsequent synthesis of fluoroscopic images. The proposed approach creates a network of main feeding arteries for each of the eight liver segments as defined by the Couinaud classification system. A constrained constructive optimization based approach was then used to connect a set of randomly generated endpoints within each segment to the corresponding feeding artery. Vessel curvature was created using cubic splines and the generated vasculature was inserted into the digital XCAT phantom. The simulated 2D fluoroscopic images were generated using ray tracing and included focal spot blur, detector blur and Poisson noise. The length ratio (1.1 +/- 1.7) and two parameters from Murray's law, branching angles (7.9 +/- 7.7 degrees mean absolute difference from Murray's law) and radius ratio (1.0 +/- 0.1) of the generated vasculature were in accordance with values reported in literature (1.3, Murray's law applied to branching angles, and 1.0 respectively). Simulated vasculature included main branches for each of the eight Couinaud segments, where 87% of all connected endpoints terminated in the same segment. Simulated 2D projection images were analyzed using a vessel phantom study with contrast-enhanced tubes (0.305-3.353 mm diameter). The normalized root mean squared difference between the measured and simulated vessel profiles averaged 3.5%. In conclusion, the proposed method provides realistic simulated fluoroscopic images of the liver vasculature and could prove useful for the training of machine learning based algorithms for vessel segmentation.","VESSEL SEGMENTATION,VASCULATURE,TREES,CT",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,"VESSEL,SEGMENTATION,VASCULATURE,TREES,CT",,,
65,Combined spatial and temporal deep learning for image noise reduction of fluoroscopic x-ray sequences,11312,,,"Wu Chengyang,Zhang Pu,Xu Yan,Yao Jingwu","Wu CY,Zhang P,Xu Y,Yao JW",Yao JW,10.1117/12.2549693,"Neusoft Med Syst USA Inc, 14425 Torrey Chase Blvd, Houston, TX 77014 USA.","Radiation dose is of an important consideration for x-ray fluoroscopy imaging of interventional C-arm systems. Low-dose imaging is always expected, but it also results in noisy images. Noise reduction is one of the important topics for fluoroscopic images. Recently, the advances in deep learning have achieved outstanding denoising results for x-ray images. However, most existing methods in the field focus only on 2D image denoising from frame-by-frame independently, and removing temporal noise in image sequence remains a challenging problem. Our goal is simultaneously to reduce both spatial and temporal noises for fluoroscopic image sequences in a unified framework. In this paper, we propose a deep learning algorithm that extensively utilizes temporal information to maximize the efficiency of noise reduction. The proposed convolutional neural network (CNN) is based on DenseNet(1) and DnCNN(2) but with improved multi-channel input layers for image sequence. That network architecture not only enables spatial domain deep learning from the input of every individual frame, but also is able to make full use of temporally correlative information among adjacent frames for temporal domain learning. In order to further suppress temporal noise resulting in visual flickers of image sequence, an additional term is introduced to the network loss function. Besides two conventional terms of L2 and perceptual losses, the new proposed loss calculates the statistical variance of the network performance caused by random influence of temporal imaging. The developed algorithm is evaluated with fluoroscopic phantom images and clinical patient data, showing superior performance for spatio-temporal denoising.","Spatio-temporal denoising,fluoroscopic x-ray imaging,interventional C-arm systems,deep learning,DnCNN,DenseNet",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
66,Leveraging Deep Generative Model for Direct Energy-resolving CT Imaging via Existing Energy-integrating CT Images,11312,,,"Yao Lisha,Li Sui,Li Danyang,Zhu Manman,Gao Qi,Zhang Shanli,Bian Zhaoying,Huang Jing,Zeng Dong,Ma Jianhua","Yao LS,Li S,Li DY,Zhu MM,Gao Q,Zhang SL,Bian ZY,Huang J,Zeng D,Ma JH",Ma JH,10.1117/12.2548992,Southern Medical University - China,"Energy-resolving CT (ErCT) with a photon counting detector (PCD) is able to generate multi-energy data with high spatial resolution, and it can be used to improve contrast-to-noise ratio (CNR) of iodinated tissues and to reduce beam hardening artifacts. In addition, ErCT allows for generating virtual mono-energetic CT images with improved CNR. However, most of ErCT scanners are lab-built, but little used in clinical research. Deep learning based methods can help to generate ErCT images from energy-integrating CT (EiCT) images via convolution neural networks (CNNs) because of its capability in learning features of the EiCT images and ErCT images. Nevertheless, current CNNs usually generate ErCT images at one energy bin at a time, and there is large room for improvement, such as, generating multi-energy ErCT images at a time. Therefore, in this work, we investigate to leverage a deep generative model (IuGAN-ErCT) to simultaneously generate ErCT images at multiple energy bins from existing EiCT images. Specifically, a unified generative adversarial network (GAN) is employed. With a single generator, the generative network learns the latent correlation between the EiCT images and ErCT images to estimate ErCT images from EiCT images. Moreover, to maintain the value accuracy of different ErCT images, we introduced a fidelity loss function. In the experiment, 1384 abdomen and chest images collected from 22 patients were utilized to train the proposed IuGAN-ErCT method and 130 slices were used for test. Result shows that the IuGAN-ErCT method can generate more accurate ErCT images than the uGAN-ErCT method both in quantitative and qualitative evaluation.","energy-resolving CT imaging,deep learning,energy-integrating CT images,uGAN,fidelity loss",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
67,Simultaneous denoising and spatial resolution enhancement using convolutional neural network-based linear model in diagnostic CT images,11312,,,"Yim Dobin,Kim Burnyoung,Lee Seungwan","Yim D,Kim B,Lee S",Lee S,10.1117/12.2548378,Konyang University,"According to an increased use of computed tomography (CT) in medicine, the risk caused by radiation exposure has been considered as one of the major issues. In order to reduce the risk, low-dose CT imaging has attracted attention. However, the low-dose CT imaging causes low spatial resolution (LR) and high noise in reconstructed images. Recently, deep learning-based models have shown a feasibility for reducing noise and improving spatial resolution. However, these models have the drawbacks such as complex structures, large sample size and computational costs. In this study, a simple denoising and super-resolution convolutional neural network (SDSRCNN) was proposed to overcome the limitations of conventional methods. Two networks were trained for the denoising and super-resolution imaging separately, and the trained networks were linearly combined as a single network with a simple architecture. In comparison with conventional methods, denoise-autoencoder (DAE) and super-resolution convolutional neural network (SRCNN) were also implemented. We evaluated the performance of the SDSRCNN in terms of peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM). The results showed that the proposed model could efficiently reduce noise and preserve spatial resolution information comparing the conventional methods. Therefore, the proposed model has the potential for improving the quality of CT images and rejecting the complexity of the conventional methods.","Deep learning,convolutional neural network,super-resolution,denoising",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
68,Deep learning enabled prior image constrained compressed sensing (DL-PICCS) reconstruction framework for sparse-view reconstruction,11312,,,"Zhang Chengzhu,Li Yinsheng,Chen Guang-Hong","Zhang CZ,Li YS,Chen GH",Zhang CZ,10.1117/12.2549444,University of Wisconsin System,"This work aims to combine compressed sensing reconstruction with a deep learning framework to leverage their individual strengths and enable 123-view moderate-dose sparse-view reconstruction for diagnostic CT imaging systems. Specifically, linear FBP reconstruction was applied to reconstruct sparse data, followed by a trained U-Net to remove artifacts resulting from undersampling. This methodology has been exploited in many other deep learning applications for CT imaging. However, this approach may be subjected to the generalizability issue in which the reconstruction can either remove real lesions or add lesions that may not exist. This will be demonstrated in our results. In our proposed work, the output of the network is used as the prior image for a prior image constrained compressed sensing (PICCS) reconstruction. This step helps to ensure the reconstructed image is consistent with the measured data. Finally, the PICCS reconstructed image is further cleaned up by a trained light duty U-Net to improve noise texture and reduce noise to generate the final reconstructed image. Both simulation data and human subject data were used to validate the proposed image reconstruction framework. In simulation studies, it is demonstrated that the final output corrected the distorted structures in the deep learning-only reconstruction with respect to the shape, size and contrast of the structures. The final images also appeared streak-free with more natural noise texture when compared with the PICCS-only reconstruction. In human subject validation, the false positive lesion-like structures in the deep learning prior image were eliminated in the final output.",,Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
69,A Deep RNN for CT Image Reconstruction,11312,,,"Zhang Jun,Zuo Hongquan","Zhang J,Zuo HQ",Zhang J,10.1117/12.2549809,University of Wisconsin System,"Filtered back projection (FBP) reconstruction is simple and computationally efficient and is used in many commercial CT (tomography) imaging products. However, higher Poisson noise levels or metal objects in the imaged area can lead to severe artifacts. Iterative reconstruction employs stochastic models for the imaging process and the characteristics of the medical images and can reduce Poisson noise and metal related artifacts. But it is computation-intensive and furthermore, its image models are relatively simple and cannot quite capture the highly complex nature of the medical images, leaving rooms for further improvement. Recent advances in neural networks and deep learning could offer potential solutions to overcome these two problems. Towards that end, most of the neural networks proposed so far for CT image reconstruction are feed-forward networks with CNN (convolutional neural network) and fully connected layers, attempting to learn the mapping from the projections or the FBP output to the reconstructed image. While these networks have demonstrated some promising reconstruction or post-processing results, their architectures are somewhat arbitrary and the question remains as to what would be a more principled way to find a good architecture, thereby further improving reconstruction results. One promising idea is to design the network structure based on signal processing principles such as MAP (maximum a posteriori) estimation and iterative optimization. In this work, we developed a novel RNN (recurrent neural network) based on an accelerated iterative MAP estimation algorithm. This network makes use of, rather than learn, the forward image model such that the learning can be focused on the image or prior model and acceleration. This has led to good reconstruction results where Poisson noise and metal artifacts are greatly reduced.","CT,image reconstruction,RNN,iterative reconstruction",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
70,Dual-energy CT reconstruction using deep mutual-domain knowledge for basis decomposition and denoising,11312,,,"Zhang Yikun,Su Ting,Zhu Jiongtao,Chen Yang,Zheng Hairong,Liang Dong,Ge Yongshuai","Zhang YK,Su T,Zhu JT,Chen Y,Zheng HR,Liang D,Ge YS",Zhang YK,10.1117/12.2547736,Chinese Academy of Sciences,"As a quantitative CT imaging technique, the dual-energy CT (DECT) imaging method attracts a lot of research interests. However, material decomposition from high energy (HE) and low energy (LE) data may suffer from magnified noise, resulting in severe degradation of image quality and decomposition accuracy. To overcome these challenges, this study presents a novel DECT material decomposition method based on deep neural network (DNN). In particular, this new DNN integrates the CT image reconstruction task and the nonlinear material decomposition procedures into one single network. This end-to-end network consists of three compartments: the sinogram domain decomposition compartment, the user-defined analytical domain transformation operation (OP) compartment, and the image domain decomposition compartment. By design, both the first and third compartments are responsible for complicated nonlinear material decomposition, while denoising the DECT images. Natural images are used to synthesized the dual-energy data with assumed certain volume fractions and density distributions. By doing so, the burden of collecting clinical DECT data can be significantly reduced, therefore the new DECT reconstruction framework becomes more easy to be implemented. Both numerical and experimental validation results demonstrate that the proposed DNN based DECT reconstruction algorithm can generate high quality basis images with improved accuracy.","Dual-energy CT,Deep neural network",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
71,A deep learning reconstruction method for sparsely spaced multidetector helical CT using cascaded dual-domain CNN,11312,,,"Zheng Ao,Gao Hewei,Zhang Li,Xing Yuxiang","Zheng A,Gao HW,Zhang L,Xing YX",Xing YX,10.1117/12.2548774,Tsinghua University,"Helical CT has been widely used in clinical diagnosis. Sparsely spaced multidetector in z direction can increase the coverage of the detector provided limited detector rows. It can speed up volumetric CT scan, lower the radiation dose and reduce motion artifacts. However, it leads to insufficient data for reconstruction. That means reconstructions from general analytical methods will have severe artifacts. Iterative reconstruction methods might be able to deal with this situation but with the cost of huge computational load. In this work, we propose a cascaded dual-domain deep learning method that completes both data transformation in projection domain and error reduction in image domain. First, a convolutional neural network (CNN) in projection domain is constructed to estimate missing helical projection data and converting helical projection data to 2D fan-beam projection data. This step is to suppress helical artifacts and reduce the following computational cost. Then, an analytical linear operator is followed to transfer the data from projection domain to image domain. Finally, an image domain CNN is added to improve image quality further. These three steps work as an entirety and can be trained end to end. The overall network is trained using a simulated lung CT dataset with Poisson noise from 25 patients. We evaluate the trained network on another three patients and obtain very encouraging results with both visual examination and quantitative comparison. The resulting RRMSE is 6.56% and the SSIM is 99.60%. In addition, we test the trained network on the lung CT dataset with different noise level and a new dental CT dataset to demonstrate the generalization and robustness of our method.","Sparsely spaced multidetector,Helical CT,Cascaded CNN,Dual-domain",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,"IMAGE-RECONSTRUCTION,BACKPROJECTION,ALGORITHM",,,
72,Deep Neural Networks for Low-dose CT Image Reconstruction via Cooperative Meta-learning Strategy,11312,,,"Zhu Manman,Li Sui,Li Danyang,Gao Qi,Zhang Shanli,Huang Haiyun,Bian Zhaoying,Huang Jing,Zeng Dong,Ma Jianhua","Zhu MM,Li S,Li DY,Gao Q,Zhang SL,Huang HY,Bian ZY,Huang J,Zeng D,Ma JH",Ma JH,10.1117/12.2548950,Southern Medical University - China,"Recently, deep neural networks (DNNs) have been widely applied in low-dose computed tomography (LDCT) imaging field. Their performances are highly related to the number of the pre-collected training data. Meanwhile, the training data is usually hard to obtain, especially for the high-dose CT (HDCT) images. And HDCT images sometimes contain undesired noises, which easily result in network overfitting. To address the two issues, we proposed a cooperative meta-learning strategy for CT image reconstruction (CmetaCT) combining the meta-learning strategy and Co-teaching strategy. The meta-learning (teacher/student model) strategy allows for training network with a large number of LDCT images without the corresponding HDCT images and only a small number of labeled CT data in a semi-supervised learning manner. And the Co-teaching strategy is able to make a trade-off between overfitting and introducing extra errors, which includes a part of samples in every mini-batch for updating model parameters. Due to the capacity of meta-learning, the presented CmetaCT method is flexible enough to utilize any existing CT restoration/reconstruction network in meta-learning framework. Finally, both quantitative and visual results indicated that the proposed CmetaCT method achieves a superior performance on low-dose CT imaging compared with the DnCNN method.","Low-dose CT,image reconstruction,deep neural network,meta-learning,Co-teaching",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Imaging Science & Photographic Technology",,,,,,
73,Efficient Shapley Explanation For Features Importance Estimation Under Uncertainty.,12261,,792-801,",,,,,","Li Xiaoxiao,Zhou Yuan,Dvornek Nicha C,Gu Yufeng,Ventola Pamela,Duncan James S",,10.1007/978-3-030-59710-8_77,,"Complex deep learning models have shown their impressive power in analyzing high-dimensional medical image data. To increase the trust of applying deep learning models in medical field, it is essential to understand why a particular prediction was reached. Data feature importance estimation is an important approach to understand both the model and the underlying properties of data. Shapley value explanation (SHAP) is a technique to fairly evaluate input feature importance of a given model. However, the existing SHAP-based explanation works have limitations such as 1) computational complexity, which hinders their applications on high-dimensional medical image data; 2) being sensitive to noise, which can lead to serious errors. Therefore, we propose an uncertainty estimation method for the feature importance results calculated by SHAP. Then we theoretically justify the methods under a Shapley value framework. Finally we evaluate our methods on MNIST and a public neuroimaging dataset. We show the potential of our method to discover disease related biomarkers from neuroimaging data.",,Journal Article,,,,,,,,
74,Efficient Learning of Big ECG Data for Ventricular Fibrillation Warning,,,1370-1375,"He Yao,Bi Xin,Zhao Xiangguo,Zhang Chao,Liu Zhixun,Ma Yuliang","He Y,Bi X,Zhao XG,Zhang C,Liu ZX,Ma YL",Bi X,10.1109/ICDCS47774.2020.00180,Northeastern University - China,"Ventricular fibrillation is the most lethal arrhythmia. At present, the treatment of ventricular fibrillation is commonly received after the onset of the disease, which mainly depends on external defibrillation and drug-assisted therapy. Although activity of heartbeats can be described and analyzed using the most popular technique ECG (electrocardiogram), there is still no widely recognized prediction methods for ventricular fibrillation. Therefore, in this paper, in order to realize warning of ventricular fibrillation, we focus on the detection of atrial fibrillation and ventricular flutter, which are the arrhythmias often occurring before ventricular fibrillation. We propose a frequency-domain LSTM (Long Short-Term Memory), which uses heartbeat waves transformed from the original time domain into the frequency domain as input. Furthermore, to address the problem of big ECG data training efficiency and scalability, we also provide an implementation of our method under the distributed computing framework MapReduce in the Spark cluster. Experimental results indicate that our method achieves excellent classification performance compared with rival methods.","big ECG data,ventricular fibrillation,long short-term memory,MapReduce",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA",Computer Science,,,,,,
75,Deep Learning-based Low-dose Tomography Reconstruction with Hybrid-dose Measurements,,,88-95,"Wu Ziling,Bicer Tekin,Liu Zhengchun,De Andrade Vincent,Zhu Yunhui,Foster Ian T.","Wu ZL,Bicer T,Liu ZC,De Andrade V,Zhu YH,Foster IT",Wu ZL,10.1109/MLHPCAI4S51975.2020.00017,Virginia Polytechnic Institute & State University,"Synchrotron-based X-ray computed tomography is widely used for investigating inner structures of specimens at high spatial resolutions. However, potential beam damage to samples often limits the X-ray exposure during tomography experiments. Proposed strategies for eliminating beam damage also decrease reconstruction quality. Here we present a deep learning-based method to enhance low-dose tomography reconstruction via a hybrid-dose acquisition strategy composed of extremely sparse-view normal-dose projections and full-view low-dose projections. Corresponding image pairs are extracted from low-/normal-dose projections to train a deep convolutional neural network, which is then applied to enhance full-view noisy low-dose projections. Evaluation on two experimental datasets under different hybrid-dose acquisition conditions show significantly improved structural details and reduced noise levels compared to uniformly distributed acquisitions with the same number of total dosage. The resulting reconstructions also preserve more structural information than reconstructions processed with traditional analytical and regularization-based iterative reconstruction methods from uniform acquisitions. Our performance comparisons show that our implementation, HDrec, can perform denoising of a real-world experimental data 410x faster than the state-of-the-art Xlearn method while providing better quality. This framework can be applied to other tomographic or scanning based X-ray imaging techniques for enhanced analysis of dose-sensitive samples and has great potential for studying fast dynamic processes.","low-dose tomography,image reconstruction,hybrid-dose measurement,projection denoising,deep learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA",Computer Science,,,"CONVOLUTIONAL,NEURAL-NETWORK,COMPUTED-TOMOGRAPHY,IMAGE-RECONSTRUCTION,SPARSE-DATA",2020 IEEE/ACM WORKSHOP ON MACHINE LEARNING IN HIGH PERFORMANCE COMPUTING ENVIRONMENTS (MLHPC 2020) AND WORKSHOP ON ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR SCIENTIFIC APPLICATIONS (AI4S 2020),,
76,An Adversarial Domain Separation Framework for Septic Shock Early Prediction Across EHR Systems,,,64-73,"Khoshnevisan Farzaneh,Chi Min","Khoshnevisan F,Chi M",Khoshnevisan F,10.1109/BigData50022.2020.9378058,University of North Carolina,"Modeling patient disease progression using Electronic Health Records (EHRs) is critical to assist clinical decision making. While most of prior work has mainly focused on developing effective disease progression models using EHRs collected from an individual medical system, relatively little work has investigated building robust yet generalizable diagnosis models across different systems. In this work, we propose a general domain adaptation (DA) framework that tackles two categories of discrepancies in EHRs collected from different medical systems: one is caused by heterogeneous patient populations (covariate shift) and the other is caused by variations in data collection procedures (systematic bias). Prior research in DA has mainly focused on addressing covariate shift but not systematic bias. In this work, we propose an adversarial domain separation framework that addresses both categories of discrepancies by maintaining one globally -shared invariant latent representation across all systems through an adversarial learning process, while also allocating a domain-specific model for each system to extract local latent representations that cannot and should not he unified across systems. Moreover, our proposed framework is based on variational recurrent neural network (VRNN) because of its ability to capture complex temporal dependencies and handling missing values in time-series data. We evaluate our framework for early diagnosis of an extremely challenging condition, septic shock, using two real-world EIIRs from distinct medical systems in the U.S. The results show that by separating globally -shared from domain-specific representations. our framework significantly improves septic shock early prediction performance in both EHRs and outperforms the current state-of-the-art DA models.","adversarial domain adaptation variational RNN,Electronic health Record,septic shock,early prediction",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,SEPSIS,,http://arxiv.org/pdf/2010.13952,
77,NeuroKube: An Automated and Autoscaling Neuroimaging Reconstruction Framework using Cloud Native Computing and A.I,,,320-330,"Madany Matthew,Marcus Kyle,Peltier Steven,Ellisman Mark H.,Altintas Ilkay","Madany M,Marcus K,Peltier S,Ellisman MH,Altintas I",Madany M,10.1109/BigData50022.2020.9378053,University of California System,"The Neuroscience domain stands out from the field of sciences for its dependence on the study and characterization of complex, intertwining structures. Understanding the complexity of the brain has led to widespread advances in the structure of large-scale computing resources and the design of artificially intelligent analysis systems. However, the scale of problems and data generated continues to grow and outpace the standards and practices of neuroscience. In this paper, we present an automated neuroscience reconstruction framework, called NeuraKube, for large-scale processing and labeling of neuroimage volumes. Automated labels are generated through a machine-learning (ML) workflow, with data-intensive steps feeding through multiple GPU stages and distributed data locations leveraging autoscalable cloud-native deployments on a multi-institution Kubernetes system. Leading-edge hardware and storage empower multiple stages of machine-learning, GPU-accelerated solutions. This demonstrates an abstract approach to allocating the resources and algorithms needed to elucidate the highly complex structures of the brain. We summarize an integrated gateway architecture, and a scalable workflow driven segmentation and reconstruction environment that brings together image big data with state-of-the-art, extensible machine learning methods.","Neuroscience,Segmentation,Superresolution,Machine Learning,Workflow,G ateway,B ig D ata,Kubernetes",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
78,Structure Prediction from Neutron Scattering Profiles: A Data Sciences Approach,,,1147-1155,"Garcia-Cardona Cristina,Kannan Ramakrishnan,Johnston Travis,Proffen Thomas,Seal Sudip K.","Garcia-Cardona C,Kannan R,Johnston T,Proffen T,Seal SK",Garcia-Cardona C,10.1109/BigData50022.2020.9377853,United States Department of Energy (DOE),"One of the main goals of neutron data analysis is to determine the internal structure of materials from their neutron scattering profiles. These structures are defined by a crystallographic class label and a set of real-valued parameters specific to that class. Existing structure analysis approaches use computationally expensive loop refinements methods that routinely take days, and even weeks, to complete. Additionally, the outcomes often rely on the fidelity of physical models that are computed during the refinement process.
Here, we evaluate the feasibility of using trained data-driven machine learning models as fast and accurate substitutes for these expensive methods. We report on the efficacies of a variety of ML models, including convolutional neural networks, auto-encoders, random forests and combinations thereof, in addition to techniques such as transfer learning in predicting these structural parameters. Specifically, we evaluate two categories of models which we call class-conditional and integrated. The first relies on a two-stage inference pipeline in which a crystallographic class label is first predicted followed by regression to predict the length/angle parameters. In the second category, the classification and regression tasks are performed as a single learning task. We train these models on synthetically generated data, validate them against experimental observations and show that integrated models outperform their class-conditional counterparts opening up the possibility of deep learning models as a viable alternative to existing resource-intensive loop refinement methods in neutron data analysis.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,https://permalink.lanl.gov/object/tr?what=info:lanl-repo/lareport/LA-UR-21-30158,
79,Automated Machine Learning for the Classification of Normal and Abnormal Electromyography Data,,,1176-1185,"Kefalas Marios,Koch Milan,Geraedts Victor,Wang Hao,Tannemaat Martijn,Back Thomas","Kefalas M,Koch M,Geraedts V,Wang H,Tannemaat M,Back T",Kefalas M,10.1109/BigData50022.2020.9377780,Leiden University,"Needle electromyography (EMG) is a common technique used in clinical neurophysiology to record the electrical activity of muscles at different levels of activation. It can be used to diagnose various neurological/muscular disorders, as the EMG signals of patients with both nerve diseases (neuropathies) and muscle diseases (myopathies) differ from the signal in healthy controls. A major drawback of this examination is that it relies on visual inspection and as such, it is highly subjective and prone to errors. Based on EMG time series of 65 individuals (40 with ALS/IBM and 25 healthy), we aim to develop an automated machine-learning pipeline for the classification of EMG recordings of muscles in either disease or healthy (muscle-level). The automated pipeline consists of feature extraction, feature selection, modelling algorithm, and optimization, in which the most significant features are automatically selected from the feature space and the hyperparameters of the model are optimized by a Bayesian technique as part of the automated approach. Aside from the muscle-level approach, we also explore a patient-level approach, which uses the output of the muscle-level automated pipeline in a post-processing manner to classify patients in being either disease or healthy, based on their muscle recordings. The resulting two approaches yield an AUC score of 81.7% (muscle-level) and 81.5% (patient-level), indicating that such approaches can assist clinicians in diagnosing if a patient has a neuropathy/myopathy or is healthy.","EMG,ALS,IBM,Neuromuscular,Time Series Classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"INCLUSION-BODY,MYOSITIS,DIAGNOSIS,DWT",,,
80,Generating Realistic COVID-19 x-rays with a Mean Teacher plus Transfer Learning GAN,,,1216-1225,"Menon Sumeet,Galita Joshua,Chapman David,Gangopadhyay Aryya,Mangalagiri Jayalakshmi,Nguyen Phuong,Yesha Yaacov,Yesha Yelena,Saboury Babak,Morris Michael","Menon S,Galita J,Chapman D,Gangopadhyay A,Mangalagiri J,Nguyen P,Yesha Y,Yesha Y,Saboury B,Morris M",Menon S,10.1109/BigData50022.2020.9377878,University System of Maryland,"COVID-19 is a novel infectious disease responsible for over 1.2 million deaths worldwide as of November 2020. The need for rapid testing is a high priority and alternative testing strategies including x-ray image classification are a promising area of research. However, at present, public datasets for COVID-19 x-ray images have low data volumes, making it challenging to develop accurate image classifiers. Several recent papers have made use of Generative Adversarial Networks (GANs) in order to increase the training data volumes. But realistic synthetic COVID-19 x-rays remain challenging to generate. We present a novel Mean Teacher + Transfer GAN (MTT-GAN) that generates COVID-19 chest x-ray images of high quality. In order to create a more accurate GAN, we employ transfer learning from the Kaggle pneumonia x-ray dataset, a highly relevant data source orders of magnitude larger than public COVID-19 datasets. Furthermore, we employ the Mean Teacher algorithm as a constraint to improve stability of training. Our qualitative analysis shows that the MTT-GAN generates x-ray images that are greatly superior to a baseline GAN and visually comparable to real x-rays. Although board-certified radiologists can distinguish MTT-GAN fakes from real COVID-19 x-rays, quantitative analysis shows that MTT-GAN greatly improves the accuracy of both a binary COVID-19 classifier as well as a multi-class pneumonia classifier as compared to a baseline GAN. Our classification accuracy is favorable as compared to recently reported results in the literature for similar binary and multi-class COVID-19 screening tasks.","Coronavirus,deep transfer learning,mean teacher,artificial intelligence,diagnostic radiology,x-ray",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,http://arxiv.org/pdf/2009.12478,
81,Deep Learning for Surface Wave Identification in Distributed Acoustic Sensing Data,,,1293-1300,"Dumont Vincent,Tribaldos Veronica Rodriguez,Ajo-Franklin Jonathan,Wu Kesheng","Dumont V,Tribaldos VR,Ajo-Franklin J,Wu KS",Dumont V,10.1109/BigData50022.2020.9378084,United States Department of Energy (DOE),"Moving loads such as cars and trains are very useful sources of seismic waves, which can be analyzed to retrieve information on the seismic velocity of subsurface materials using the techniques of ambient noise seismology. This information is valuable for a variety of applications such as geotechnical characterization of the near-surface, seismic hazard evaluation, and groundwater monitoring. However, for such processes to converge quickly, data segments with appropriate noise energy should be selected. Distributed Acoustic Sensing (DAS) is a novel sensing technique that enables acquisition of these data at very high spatial and temporal resolution for tens of kilometers. One major challenge when utilizing the DAS technology is the large volume of data that is produced, thereby presenting a significant Big Data challenge to find regions of useful energy. In this work, we present a highly scalable and efficient approach to process real, complex DAS data by integrating physics knowledge acquired during a data exploration phase followed by deep supervised learning to identify ""useful"" coherent surface waves generated by anthropogenic activity, a class of seismic waves that is abundant on these recordings and is useful for geophysical imaging. Data exploration and training were done on 130 Gigabytes (GB) of DAS measurements. Using parallel computing, we were able to do inference on an additional 170 GB of data (or the equivalent of 10 days' worth of recordings) in less than 30 minutes. Our method provides interpretable patterns describing the interaction of ground-based human activities with the buried sensors.","Big Data,Deep Learning,Distributed Acoustic Sensing,Distributed Training,Sensor Network Technology",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"MAGNETOMETERS,NETWORK",,http://arxiv.org/pdf/2010.10352,
82,Segmentation and Recognition of Eating Gestures from Wrist Motion using Deep Learning,,,1368-1373,"Luktuke Yadnyesh Y.,Hoover Adam","Luktuke YY,Hoover A",Luktuke YY,10.1109/BigData50022.2020.9378382,Clemson University,"This paper describes a novel approach of segmenting and classifying eating gestures from wrist motion using a deep learning neural network. It is inspired by the approach of fully-convolutional neural networks in the task of image segmentation. Our idea is to segment 1D gestures the same way 2D image regions are segmented, by treating each inertial measurement unit (IMU) datum like a pixel. The novelty of our approach lies in training a neural network to recognize data points that describe an eating gesture just like it would be trained to recognize pixels describing an image region. The data for this research is known as the Clemson Cafeteria Dataset. It was collected from 276 participants that ate an unscripted meal at the Harcombe Dining Hall at Clemson University. Each meal consisted of 1 - 4 courses, and 488 such recordings were used for the experiments described in this paper. Sensor readings consist of measurements taken by an accelerometer (x, y, z) and a gyroscope (yaw, pitch, roll). A total of 51,614 unique gestures associated with different activities commonly seen during a meal were identified by 18 trained raters. Our neural network classifier recognized an average of 79.7% of 'bite' and 84.7% of 'drink' gestures correctly per meal. Overall 77.7% of all gestures were recognized correctly on average per meal. This indicates that a deep learning model can successfully be used to segment eating gestures from a time series recording of IMU data using a technique similar to pixel segmentation within an image.","Deep learning,eating gestures,energy intake,IMU sensors,segmentation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,GLASSES,,https://tigerprints.clemson.edu/cgi/viewcontent.cgi?article=4307&context=all_theses,
83,Gaussian Mixture Graphical Lasso with Application to Edge Detection in Brain Networks,,,1430-1435,"Yin Hang,Liu Xinyue,Kong Xiangnan","Yin H,Liu XY,Kong XN",Yin H,10.1109/BigData50022.2020.9377809,Worcester Polytechnic Institute,"Sparse inverse covariance estimation (i.e., edge detection) is an important research problem in recent years, where the goal is to discover the direct connections between a set of nodes in a networked system based upon the observed node activities. Existing works mainly focus on unimodal distributions, where it is usually assumed that the observed activities are generated from a single Gaussian distribution (i.e., one graph). However, this assumption is too strong for many real-world applications. In many real-world applications (e.g., brain networks), the node activities usually exhibit much more complex patterns that are difficult to be captured by one single Gaussian distribution. In this work, we are inspired by Latent Dirichlet Allocation (LDA) [4] and consider modeling the edge detection problem as estimating a mixture of multiple Gaussian distributions, where each corresponds to a separate sub-network. To address this problem, we propose a novel model called Gaussian Mixture Graphical Lasso (MGL). It learns the proportions of signals generated by each mixture component and their parameters iteratively via an EM framework. To obtain more interpretable networks, MGL imposes a special regularization, called Mutual Exclusivity Regularization (MER), to minimize the overlap between different sub-networks. MER also addresses the common issues in read-world data sets, i.e., noisy observations and small sample size. Through the extensive experiments on synthetic and real brain data sets, the results demonstrate that MGL can effectively discover multiple connectivity structures from the observed node activities.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,http://arxiv.org/pdf/2101.05348,
84,CNN Application in Detection of Privileged Documents in Legal Document Review,,,1485-1492,"Chhatwal Rishi,Keeling Robert,Gronvall Peter,Huber-Fliflet Nathaniel,Zhang Jianping,Zhao Haozhen","Chhatwal R,Keeling R,Gronvall P,Huber-Fliflet N,Zhang JP,Zhao HZ",Chhatwal R,10.1109/BigData50022.2020.9378182,AT&T,"Protecting privileged communications and data from disclosure is paramount for legal teams. Legal advice, such as attorney-client communications or litigation strategy are typically exempt from disclosure in litigations or regulatory events and are vital to the attorney-client relationship. To protect this information from disclosure, companies and outside counsel often review vast amounts of documents to determine those that contain privileged material. This process is extremely costly and time consuming. As data volumes increase, legal counsel normally employs methods to reduce the number of documents requiring review while balancing the need to ensure the protection of privileged information. Keyword searching is relied upon as a method to target privileged information and reduce document review populations. Keyword searches are effective at casting a wide net but often return overly inclusive results - most of which do not contain privileged information. To overcome the weaknesses of keyword searching, legal teams increasingly are using machine learning techniques to target privileged information. In these studies, classic text classification techniques are applied to build classification models to identify privileged documents. In this paper, the authors propose a different method by applying machine learning / convolutional neural network techniques (CNN) to identify privileged documents. Our proposed method combines keyword searching with CNN. For each keyword term, a CNN model is created using the context of the occurrences of the keyword. In addition, a method was proposed to select reliable privileged (positive) training keyword occurrences from labeled positive training documents. Extensive experiments were conducted, and the results show that the proposed methods can significantly reduce false positives while still capturing most of the true positives.","Text classification,Convolutional Neural,Networks Keyword search,E-Discovery,Legal document review",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,http://arxiv.org/pdf/2102.04845,
85,An Approach to Developing EEG-Based Person Authentication System,,,2619-2625,"Patel Meetkumar J.,Husain Mohammad I","Patel MJ,Husain MI",Patel MJ,10.1109/BigData50022.2020.9377861,California State University System,"The need for a new authentication method such as biometrics becomes apparent as the data breaches on password-based authentication increase. However, current biometric forms of authentication become unusable once compromised. Additional limits are realized when an attacker coerces an authorized user into a forced authentication. To resolve both issues, we propose creating an authentication mechanism that depends on the user's neurophysiological responses to chosen pieces of music (non-lyrical) measured using electroencephalographic (EEG) signals. This research paper provides a guide for creating and presenting a system that incorporates such idea for person classification and authentication. In a group study, the aim is that participant listen to individually selected music and music selected by other participants during an EEG reading. The change in the Alpha and Beta band frequencies across eight electrode EEG sensors serves as the input feature vector for a supervised machine learning algorithm that trains on the user and attacker EEG readings. Ultimately, the goal of the algorithm is to create a user-specific model to uniquely identify the respective user based on the corresponding EEG response to music and grant authentication. Our study lays a solid foundation for creating a promising EEG-based authentication system by solving the drawbacks of current biometric authentication methods.","EEG,biometrics,machine learning,authentication,security",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
86,Enhanced Data Augmentation using GANs for Raman Spectra Classification,,,2891-2898,"Di Frischia Stefano,Giammatteo Paolo,Angelini Federico,Spizzichino Valeria,De Santis Elena,Pomante Luigi","Di Frischia S,Giammatteo P,Angelini F,Spizzichino V,De Santis E,Pomante L",Di Frischia S,10.1109/BigData50022.2020.9377977,University of L'Aquila,"Raman spectroscopy is a well-established technique for rapid analysis for Cultural Heritage characterization. It represents one of the most used and reliable technique because non invasive and usable, even on-site, without any sample preparation. Overall in the last decade, several methods have been tested with the purpose of obtaining an automatic classification process of spectra of unknown materials. Machine learning methods and in particular Neural Networks are the most recently exploited on this topic. Unfortunately, the availability of real Raman spectra is often limited considering the amount of data necessary for the use of these approaches. In this work we propose a pipeline for augmenting data with a GAN reinforcement, with the aim of creating a dataset large enough to take advantage of such. Furthermore, three types of neural networks (binary-NN, categorical-NN and CNN) are trained with the aforementioned dataset and compared with each other, taking into consideration their accuracy. The results show that the enhanced data augmentation with GANs significantly increases the accuracy of the networks.","Deep Learning,Generative Adversarial Network,Data Augmentation,Raman Spectroscopy,Signal Processing",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
87,Residual Neural Network Architectures to Improve Prediction Accuracy of Properties of Materials,,,2915-2918,"Tatis David,Sierra Heidy,Arzuaga Emmanuel","Tatis D,Sierra H,Arzuaga E",Tatis D,10.1109/BigData50022.2020.9377934,University of Puerto Rico,"Properties in material composition and crystal structures have been explored by density functional theory (DFT) calculations, using databases such as the Open Quantum Materials Database (OQMD). Databases like these have been used currently for the training of advanced machine learning and deep neural network models, the latter providing higher performance when predicting properties of materials. However, current alternatives have shown a deterioration in accuracy when increasing the number of layers in their architecture (over-fitting problem). As an alternative method to address this problem, we have implemented residual neural network architectures based on Merge and Run Networks, IRNet and UNet to improve performance while relaxing the observed network depth limitation. The evaluation of the proposed architectures include a 9:1 ratio to train and test as well as 10 fold cross validation. In the experiments we found that our proposed architectures based on IRNet and UNet are able to obtain a lower Mean Absolute Error (MAE) than current strategies. The full implementation (Python, Tensorflow and Keras) and the trained networks will be available online for community validation and advancing the state of the art from our findings.","elemental compositions,residual neural networks",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
88,0 Classifying Powder Flowability for Cold Spray Additive Manufacturing Using Machine Learning,,,2919-2928,"Valente Richard,Ostapenko Alissa,Sousa Bryer C.,Grubbs Jack,Massar Christopher J.,Cote Danielle L.,Neamtu Rodica","Valente R,Ostapenko A,Sousa BC,Grubbs J,Massar CJ,Cote DL,Neamtu R",Valente R,10.1109/BigData50022.2020.9377948,Worcester Polytechnic Institute,"Metal powders are used as feedstock in a variety of manufacturing methods, wherein the metallic particulates may be deposited upon a substrate, spread upon a build plate, or melted layer-by-layer. Regardless of how the powder is consumed during a given manufacturing process, the ease with which a powder flows maintains a significant impact on the properties and behavior of the resultant component procured. This is especially true for cold spray additive manufacturing, which is a solid-state metallic particulate deposition process that requires suitable flowability to prevent component waviness as well as prevent nozzle clogging.
That being said, particle-level geometrical properties, such as size and shape features, greatly impact the capacity of a powder to flow, or its flowability. Existing techniques for measuring a particle's flowability require manual powder processing which can be both time-consuming and vulnerable to man-made error. Both of these setbacks can be addressed through automatic, data-driven techniques trained to classify flowability from particle property measurements and expertly procured powder Hall Flow rates for training and testing.
To our knowledge, we present the first computational model for classifying flowability (when captured in terms of the industrially standardized Hall Flow rates) of a metal powder given its particle-level physical property measurements. After obtaining twenty-one metal powder samples from manufacturers, particle-level physical property measurements of each powder were measured. We used these particle measurements to train a Decision Tree model to classify whether a particle's Hall Flow rate was fast or slow. With an achieved accuracy 98.04%, our work illustrates that powder flowability, through the lens of Hall Flow rates, can be accurately classified using data-driven techniques. This work lays a promising foundation for further exploration into predictive models for this cutting-edge domain.","Powder Flowability,Cold Spray,Particle Size/Shape Distribution,Classification,Decision Trees",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"PARTICLE-SIZE,PREDICTION,MORPHOLOGY",,,
89,Not All Areas Are Equal: Detecting Thoracic Disease With ChestWNet,,,3447-3452,"Yang Zhou,Pan Zhenhe,Liang Sisheng,Jin Fang","Yang Z,Pan ZH,Liang SS,Jin F",Yang Z,10.1109/BigData50022.2020.9377793,George Washington University,"Automating pneumonia diagnosis from X-ray images could significantly improve patient diagnosing outcomes. A major challenge is that disease information (features) must be extracted directly from the image backgrounds. Motivated by recent advances in Convolutional Neural Network (CNN), we propose a hierarchical weighting deep learning model, Chest-WNet, that combines DenseNet and transfer learning to detect and localize thoracic diseases from chest x-rays. Hierarchical weighting networks are designed to assign scores reflecting the importance of specific pixels (regions), and learning weights at pixel-, region-, and image-levels, jointly learning these hierarchical weighting networks and the image classification network in an end-to-end manner. Chest X-ray datasets are customized to solve the unbalancing label problem in these datasets. Extensive experiments show that ChestWNet significantly outperforms other established prediction methods, and can also be applied to similar scenarios with fixed point-of-interest regions in images.",SYSTEM,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,SYSTEM,,,
90,Comparison of Feature Selection Algorithms for Minimization of Target Specific FFQs,,,3592-3595,"Rescic Nina,Eftimov Tome,Seljak Barbara Korousic","Rescic N,Eftimov T,Seljak BK",Rescic N,10.1109/BigData50022.2020.9378246,Slovenian Academy of Sciences & Arts (SASA),"Food Frequency Questionnaires (FFQs) are inexpensive dietary assessment tools used in large epidemiological studies of diet and health. In the WellCo project, we developed the Extended Short Form Food Frequency Questionnaire (ESFFFQ) in order to monitor quality of users' nutrition. The developed questionnaire returns diet quality scores for eight targets - fruit intake, vegetable intake, fish intake, salt intake, sugar intake, fat intake, fibre intake and protein intake. In this paper we explored different feature selection methods in order to find the subset of the most important questions for five of the above-mentioned targets. This would help us monitor the most problematic areas of users' nutrition during a longer period of time without losing too much information and at the same time without overwhelming the user by asking the whole questionnaire. We were able to see that some of the feature selection methods found minimal subsets of questions (one or two questions), on which different machine-learning algorithms had better performance than on much bigger subsets.","FFQ,machine learning,feature selection,nutrition monitoring",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"FOOD,REPRODUCIBILITY,VALIDITY",,,
91,A Machine Learning fMRI Approach in the Diagnosis of Autism,,,3628-3631,"Karampasi Aikaterini,Kakkos Ioannis,Miloulis Stavros-Theofanis,Zorzos Ioannis,Dimitrakopoulos Georgios N.,Gkiatis Kostakis,Asvestas Panteleimon,Matsopoulos George","Karampasi A,Kakkos I,Miloulis ST,Zorzos I,Dimitrakopoulos GN,Gkiatis K,Asvestas P,Matsopoulos G",Karampasi A,10.1109/BigData50022.2020.9378453,National Technical University of Athens,"Diagnosis of Autism Spectrum Disorder (ASD) is a complex task that typically relies on the expertise of the clinician due to the lack of specific quantitative biomarkers. As a consequence, automatic categorization of an individual within the ASD taxonomy poses many challenges, usually with controversial results. The implementation of Machine Learning approaches as a diagnostic tool for ASD classification is rapidly growing in the field of neuroscience, holding the potential to enhance discrimination validity among ASD and Typically Developed (TD) individuals, while providing indications in regard to ASD differentiating factors. In this study, various feature selection and classification techniques were employed in order to successfully discern between ASD and TD, using data from large resting-state functional Magnetic Resonance Imaging (rs-fMRI) database. Moreover, we adopt novel features, namely the Haralick texture features and the Kullback-Leibler divergence, combined with already established ones (i.e. static Functional Connectivity and demographics), assessing the most informative global attributes. Our framework succeeded in the identification of a small number of discriminative features, leading to high performance relative to previous works with optimal classification accuracy of 0.725.","ASD,fMRI,feature selection,classification,functional connectivity",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"FUNCTIONAL,CONNECTIVITY,PATTERNS",,,
92,Lung Pattern Classification Via DCNN,,,3737-3743,"He Jing (Selena),Han Meng,Yu Lei,Mei Chao","He J,Han M,Yu L,Mei C",He J,10.1109/BigData50022.2020.9378090,University System of Georgia,"Interstitial lung disease (ILD) causes pulmonary fibrosis. The correct classification of ILD plays a crucial role in the diagnosis and treatment process. In this research work, we propose a lung nodules recognition method based on a deep convolutional neural network (DCNN) and global features, which can be used for computer-aided diagnosis (CAD) of global features of lung nodules. Firstly, a DCNN is constructed based on the characteristics and complexity of lung computerized tomography (CT) images. Then we discussed the effects of different iterations on the recognition results and influence of different model structures on the global features of lung nodules. We also incorporated the improvement of convolution kernel size, feature dimension, and network depth. Thirdly, the effects of different pooling methods, activation functions and training algorithms we proposed has been analyzed to demonstrate the advantages of the new strategy. Finally, the experimental results verify the feasibility of the proposed DCNN for CAD of global features of lung nodules, and the evaluation shown that our proposed method could achieve an outstanding results compare to state-of-arts.","Interstitial lung disease (ILD),Lung nodules classification,deep convolutional neural network (DCNN)",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
93,Attention-Based LSTM Network for COVID-19 Clinical Trial Parsing,,,3761-3766,"Liu Xiong,Finelli Luca A.,Hersch Greg L.,Khalil Iya","Liu X,Finelli LA,Hersch GL,Khalil I",Liu X,10.1109/BigData50022.2020.9378451,Novartis,"COVID-19 clinical trial design is a critical task in developing therapeutics for the prevention and treatment of COVID-19. In this study, we apply a deep learning approach to extract eligibility criteria variables from COVID-19 trials to enable quantitative analysis of trial design and optimization. Specifically, we train attention-based bidirectional Long Short-Term Memory (Att-BiLSTM) models and use the optimal model to extract entities (i.e., variables) from the eligibility criteria of COVID-19 trials. We compare the performance of Att-BiLSTM with traditional ontology-based method. The result on a benchmark dataset shows that Att-BiLSTM outperforms the ontology model. Att-BiLSTM achieves a precision of 0.942, recall of 0.810, and F1 of 0.871, while the ontology model only achieves a precision of 0.715, recall of 0.659, and F1 of 0.686. The extracted variables can help characterize patient populations eligible for COVID-19 trials. Our analyses demonstrate that Att-BiLSTM is an effective approach for eligibility criteria parsing.","COVID-19,clinical trials,eligibility criteria,natural language processing,deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"ELIGIBILITY,CRITERIA,REPRESENTATION",,http://arxiv.org/pdf/2012.10063,
94,Features Importance to Improve Interpretability of Chronic Kidney Disease Early Diagnosis,,,3786-3792,Moreno-Sanchez Pedro A.,Moreno-Sanchez PA,Moreno-Sanchez PA,10.1109/BigData50022.2020.9377903,Seinajoki University of Applied Sciences,"Chronic Kidney Disease (CKD) is a worldwide chronic disease that, if it is recognized late, leads a vast majority of patients to suffer premature mortality and quality of life decline due to a progressive loss of kidney function. Data mining classifiers would contribute to an early diagnosis and hence preventing kidney severe damage since subtle patterns in CKD indicators can be discovered. By employing Cross Industry Standard Process of Data Mining (CRISP-DM) methodology along with features importance techniques, this work develops a classifier model that would support healthcare professionals in early diagnosis of CKD patients. By means of a data workflow pipeline, an automated data transformation, modelling and evaluation is applied to the CKD dataset extracted from the University of California Irvine-Machine Learning (UCI-ML) repository. The pipeline developed is used to carry out an exhaustive search of the best data mining classifier and the different parameters of the data preparation's sub-stages like data missing and feature selection. As a result, AdaBoost is selected as the best classifier with a 100% in terms of accuracy, precision, sensivity, specificity, and f1-score; outperforming the classification results obtained by the related works even with unseen data from a test set. Regarding model's interpretability, the application of feature selection reduces from 24 to 12 the group of features to be employed in the classifier model developed, achieving more explainable model's outputs. Furthermore, an analysis of the importance of features selected is carried out to explore the relevance of each selected feature.","Chronic Kidney Disease,Early Diagnosis,Classification,Features Selection,Features Importance",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
95,Multi-label Detection and Classification of Red Blood Cells in Microscopic Images,,,4257-4263,"Qiu Wei,Guo Jiaming,Li Xiang,Xu Mengjia,Zhang Mo,Guo Ning,Li Quanzheng","Qiu W,Guo JM,Li X,Xu MJ,Zhang M,Guo N,Li QZ",Qiu W,10.1109/BigData50022.2020.9377782,Peking University,"Cell detection and cell type classification from biomedical images play an important role for high-throughput imaging and various clinical application. While classification of single cell sample can be performed with standard computer vision and machine learning methods, analysis of multilabel samples (region containing congregating cells) is more challenging, as separation of individual cells can be difficult (e.g. touching cells) or even impossible (e.g. overlapping cells). As multi-instance images are common in analyzing Red Blood Cell (RBC) for Sickle Cell Disease (SCD) diagnosis, we develop and implement a multi-instance cell detection and classification framework to address this challenge. The framework firstly trains a region proposal model based on Region-based Convolutional Network (RCNN) to obtain bounding-boxes of regions potentially containing single or multiple cells from input microscopic images, which are extracted as image patches. High-level image features are then calculated from image patches through a pre-trained Convolutional Neural Network (CNN) with ResNet-50 structure. Using these image features inputs, six networks are then trained to make multi-label prediction of whether a given patch contains cells belonging to a specific cell type. As the six networks are trained with image patches consisting of both individual cells and touching/overlapping cells, they can effectively recognize cell types that are presented in multi-instance image samples. Finally, for the purpose of SCD testing, we train another machine learning classifier to predict whether the given image patch contains abnormal cell type based on outputs from the six networks. Testing result of the proposed framework shows that it can achieve good performance in automatic cell detection and classification.","sickle cell disease,multi-instance object detection,cell classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"CONVOLUTIONAL,NEURAL-NETWORKS",,http://arxiv.org/pdf/1910.02672,
96,Hydra: Cancer Detection Leveraging Multiple Heads and Heterogeneous Datasets,,,4842-4849,"Cuccu Giuseppe,Jobin Johan,Clement Julien,Bhardwaj Akansha,Reischauer Carolin,Thony Harriet,Cudre-Mauroux Philippe","Cuccu G,Jobin J,Cleement J,Bhardwaj A,Reischauer C,Thoeny H,Cudre-Mauroux P",Cuccu G,10.1109/BigData50022.2020.9378042,University of Fribourg,"We propose an approach combining layer freezing and fine-tuning steps alternatively to train a neural network over multiple and diverse datasets in the context of cancer detection from medical images. Our method explicitly splits the network into two distinct but complementary components: the feature extractor and the decision maker. While the former remains constant throughout training, a different decision maker is used on each new dataset. This enables end-to-end training of the feature extractor on heterogeneous datasets (here MRIs and CT scans) and organs (here prostate, lung and brain). The feature extractor learns features across all images, with two major benefits: (i) extended training data pool, and (ii) enforced generalization across different data. We show the effectiveness of our method by detecting cancerous masses in the SPIE-AAPM-NCI Prostate MR Classification data. Our training process integrates the SPIE-AAPM-NCI Lung CT Classification dataset as well as the Kaggle Brain MRI dataset, each paired with a separate decision maker, improving the AUC of the base network architecture on the Prostate MR dataset by 0.12 (18% relative increase) versus training on the prostate dataset alone. We also compare against standard end-to-end Transfer Learning over the same datasets for reference, which only improves the results by 0.04 (6% relative increase).","Deep Learning,Transfer Learning,Prostate Cancer Detection",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"COMPUTER-AIDED,DETECTION",,,
97,Transfer learning for decision support in Covid-19 detection from a few images in big data,,,4873-4881,"Karthikeyan Divydharshini,Varde Aparna S.,Wang Weitian","Karthikeyan D,Varde AS,Wang WT",Karthikeyan D,10.1109/BigData50022.2020.9377886,Montclair State University,"The novel coronavirus (Covid-19) has spread rapidly amongst countries all around the globe. Compared to the rise in cases, there are few Covid-19 testing kits available. Due to the lack of testing kits for the public, it is useful to implement an automated AI-based E-health decision support system as a potential alternative method for Covid-19 detection. As per medical examinations, the symptoms of Covid-19 could be somewhat analogous to those of pneumonia, though certainly not identical. Considering the enormous number of cases of Covid-19 and pneumonia, and the complexity of the related images stored, the data pertaining to this problem of automated detection constitutes big data. With rapid advancements in medical imaging, the development of intelligent predictive and diagnostic tools have also increased at a rapid rate. Data mining and machine learning techniques are widely accepted to aid medical diagnosis. In this paper, a huge data set of X-ray images from patients with common bacterial pneumonia, confirmed Covid-19 disease, and normal healthy cases are utilized for AI-based decision support in detecting the Coronavirus disease. The transfer learning approach, which enables us to learn from a smaller set of samples in a problem and transfer the discovered knowledge to a larger data set, is employed in this study. We consider transfer learning using three different models that are pre-trained on several images from the ImageNet source. The models deployed here are VGG16, VGG19, and ResNet101. The dataset is generated by gathering different classes of images. We present our approach and preliminary evaluation results in this paper. We also discuss applications and open issues.","AI,big data mining,Covid-19,decision support,E-health,image recognition,transfer learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,https://ieeexplore.ieee.org/ielx7/9377717/9377728/09377886.pdf,
98,Development of an Explainable Prediction Model of Heart Failure Survival by Using Ensemble Trees,,,4902-4910,Moreno-Sanchez Pedro A.,Moreno-Sanchez PA,Moreno-Sanchez PA,10.1109/BigData50022.2020.9378460,Seinajoki University of Applied Sciences,"Cardiovascular diseases (CVD) are the leading cause of death globally. Heart failure prediction, one of the CVD manifestations, has become a priority for doctors, however, up to date clinical practice usually has failed to reach high accuracy in such tasks. Machine learning offers advantages not only for clinical prediction but also for feature ranking improving the interpretation of the outputs by clinical professionals. Thus, the concept of eXplainable Artificial Intelligence (XAI) is aimed to cope with the lack of explainability of machine learning models in the healthcare domain, in this case, and provide healthcare professionals with patient-tailored decision-making tools that improve treatments and diagnostics. This paper presents a heart failure survival prediction model development by using ensemble trees machine learning techniques. Extreme Gradient Boosting (XGBoost) is demonstrated as the classifier with most accurate results (83% accuracy with unseen data) over the other ensemble trees options. Moreover, a features selection preprocessing is made in order to assess which relevant features contribute to the model's results. Next, in terms of improving the explainability of the model developed, a study of features importance is carried out showing the ""follow up time period"" feature as the most relevant. Finally, a quantitative evaluation of the interpretability and fidelity of the model developed is performed obtaining a balanced ratio between these two indicators.","Heart failure survival prediction,explainable artificial intelligence,machine learning,ensemble trees,features importance",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"ALGORITHMS,MORTALITY",,,
99,Deep Pose Alignment,,,5366-5372,"Le Linh,Xie Ying,Alagapan Saisangararamaleengam,Chakravarty Sumit,Ordonez Pablo,Hales Michael,Johnson John","Le L,Xie Y,Alagapan S,Chakravarty S,Ordonez P,Hales M,Johnson J",Le L,10.1109/BigData50022.2020.9378321,University System of Georgia,"This paper proposes a new deep learning architecture that aligns human poses to be used in an exercise/rehabilitation assistant system. In short, the assistant system aims to provide users with visual feedback for their physical exercises. The feedback is generated by first extracting a user's poses while they are performing an exercise through the video feed of the session. The extracted poses are then overlaid with the correct poses and display for the user to observe and fix their errors. This paper focuses on the task of aligning the user's pose with the correct pose so that they can be overlaid on each other with minimal differences, including scales, locations, and perspectives. We design a new deep architecture to accomplish this task, and show that our methods can effectively reduce alignment errors by 70% on average.","physical exercise assistant,motion intelligence,pose alignment,health science,deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
100,An Efficient and Scalable Deep Learning Approach for Road Damage Detection,,,5602-5608,"Naddaf-Sh Sadra,Naddaf-Sh M-Mahdi,Kashani Amir R.,Zargarzadeh Hassan","Naddaf-Sh S,Naddaf-Sh MM,Kashani AR,Zargarzadeh H",Zargarzadeh H,10.1109/BigData50022.2020.9377751,Texas State University System,"Pavement condition evaluation is essential to time the preventative or rehabilitative actions and control distress propagation. Failing to conduct timely evaluations can lead to severe structural and financial loss of the infrastructure and complete reconstructions. Automated computer-aided surveying measures can provide a database of road damage patterns and their locations. This database can be utilized for timely road repairs to gain the minimum cost of maintenance and the asphalt's maximum durability. This paper introduces a deep learning-based surveying scheme to analyze the image-based distress data in real-time. A database consisting of a diverse population of crack distress types such as longitudinal, transverse, and alligator cracks, photographed using mobile-device is used. Then, a family of efficient and scalable models that are tuned for pavement crack detection is trained. Proposed models, resulted in F1-scores, ranging from 52% to 56%, and average inference time from 178-10 images per second. Finally, the performance of the object detectors are examined, and error analysis is reported against various images. The source code is available at https://github.com/mahdi65/roadDamageDetection2020.","Crack Detection,Object Detection,Deep Learning,Deep Convolutional Neural Network,EfficientDet",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,http://arxiv.org/pdf/2011.09577,
