,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Cuneate spiking neural network learning to classify naturalistic texture stimuli under varying sensing conditions,123,,273-287,"Rongala Udaya B.,Mazzoni Alberto,Spanne Anton,Jorntell Henrik,Oddo Calogero M.","Rongala UB,Mazzoni A,Spanne A,Jorntell H,Oddo CM",Rongala UB; Oddo CM,10.1016/j.neunet.2019.11.020,Scuola Superiore Sant'Anna,"We implemented a functional neuronal network that was able to learn and discriminate haptic features from biomimetic tactile sensor inputs using a two-layer spiking neuron model and homeostatic synaptic learning mechanism. The first order neuron model was used to emulate biological tactile afferents and the second order neuron model was used to emulate biological cuneate neurons. We have evaluated 10 naturalistic textures using a passive touch protocol, under varying sensing conditions. Tactile sensor data acquired with five textures under five sensing conditions were used for a synaptic learning process, to tune the synaptic weights between tactile afferents and cuneate neurons. Using post-learning synaptic weights, we evaluated the individual and population cuneate neuron responses by decoding across 10 stimuli, under varying sensing conditions. This resulted in a high decoding performance. We further validated the decoding performance across stimuli, irrespective of sensing velocities using a set of 25 cuneate neuron responses. This resulted in a median decoding performance of 96% across the set of cuneate neurons. Being able to learn and perform generalized discrimination across tactile stimuli, makes this functional spiking tactile system effective and suitable for further robotic applications. (C) 2019 Elsevier Ltd. All rights reserved.","Spiking neural network,Neurorobotics,Cuneate neurons,Primary afferents,Tactile sensing,Synaptic weight learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,9.171,"TACTILE,SIGNALS,ORIENTATION,NEURONS,SYSTEM,MODEL",NEURAL NETWORKS,https://www.iris.sssup.it/bitstream/11382/531681/2/Rongala_NN_2020.pdf,
2,Automated ECG Analysis for Localizing Thrombus in Culprit Artery Using Rule Based Information Fuzzy Network,6,1,16-25,"Roopa C. K.,Harish B. S.","Roopa CK,Harish BS",Roopa CK,10.9781/ijimai.2019.02.001,"JSS Res Fdn, JSS TI Campus, Mysuru, Karnataka, India.","Cardio-vascular diseases are one of the foremost causes of mortality in today's world. The prognosis for cardiovascular diseases is usually done by ECG signal, which is a simple 12-lead Electrocardiogram (ECG) that gives complete information about the function of the heart including the amplitude and time interval of P-QRS-T-U segment. This article recommends a novel approach to identify the location of thrombus in culprit artery using the Information Fuzzy Network (IFN). Information Fuzzy Network, being a supervised machine learning technique, takes known evidences based on rules to create a predicted classification model with thrombus location obtained from the vast input ECG data. These rules are well-defined procedures for selecting hypothesis that best fits a set of observations. Results illustrate that the recommended approach yields an accurateness of 92.30%. This novel approach is shown to be a viable ECG analysis approach for identifying the culprit artery and thus localizing the thrombus.","Cardio-Vascular Diseases,ECG,Identification,Classification,Information Fuzzy Network",Article,"UNIV INT RIOJA-UNIR, RECTORADO, AVENIDA DE LA PAZ, 137, LOGRONO, 26006, SPAIN",Computer Science,,2.467,"MYOCARDIAL-INFARCTION,MULTILEAD,ECG,CLASSIFICATION,DISEASE,DIAGNOSIS,SIGNALS,ENERGY",INTERNATIONAL JOURNAL OF INTERACTIVE MULTIMEDIA AND ARTIFICIAL INTELLIGENCE,https://www.ijimai.org/journal/sites/default/files/files/2019/02/ijimai20206_1_2_pdf_13999.pdf,
3,Dilated Deep Neural Network for Segmentation of Retinal Blood Vessels in Fundus Images,44,1,505-518,"Biswas Raj,Vasan Ashwin,Roy Sanjiban Sekhar","Biswas R,Vasan A,Roy SS",Roy SS,10.1007/s40998-019-00213-7,Vellore Institute of Technology,"Medical diagnosis is being assisted by numerous expert systems that have been developed to increase the accuracy of such diagnoses. The development of image processing techniques along with the rapid development in areas like machine learning and computer vision help in creating such expert systems that almost nearly match the accuracy of the expert human eye. The medical condition of diabetic retinopathy is diagnosed by analyzing the retinal blood vessels for damages, abnormal new growths and ruptures. Various techniques using convolutional neural networks have been used to segment retinal blood vessels from fundus images, but these techniques often do not segment the retinal blood vessels accurately and add additional noise due to the limited receptive field of the convolutional filters. The limited receptive field of the convolutional layer prevents the convolutional neural network from getting an accurate context of objects that extend beyond the size of the filter. The proposed architecture uses a dilated convolutional filter to obtain a larger receptive field which leads to a greater accuracy in segmenting the retinal blood vessels with near human accuracy. The convolutional neural networks were trained using the popular datasets. The proposed architecture produced an area under ROC curve (AUC) of 0.9794 and an accuracy of 95.61% and required very few iterations to train the network.","Deep neural network,Dilated convolution,Blood vessel segmentation,Medical imaging",Article,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Engineering,,,"DIABETIC-RETINOPATHY,COLOR,IMAGES",IRANIAN JOURNAL OF SCIENCE AND TECHNOLOGY-TRANSACTIONS OF ELECTRICAL ENGINEERING,,
4,Mapping marine litter using UAS on a beach-dune system: a multidisciplinary approach,706,,,"Goncalves Gil,Andriolo Umberto,Pinto Luis,Bessa Filipa","Goncalves G,Andriolo U,Pinto L,Bessa F",Andriolo U,10.1016/j.scitotenv.2019.135742,INESC,"The amount of marine litter, mainly composed by plastic materials, has become a global environmental issue in coastal environments.Traditional monitoring programs are based on in-situ visual census, which require human effort and are time-demanding. Therefore, it is crucial to implement innovative mapping strategies to improve the environmental monitoring of marine litter on the coast.
This work presents a procedure for an automated Unmanned Aerial System (UAS)-based marine litter mapping on a beach-dune system. A multidisciplinary framework, which comprises photogrammetry, geomorphology, machine learning and hydrodynamic modelling, was developed to process a block of UAS images. The work shows how each of these scientific methodologies can be complementary to improve and making more efficient the mapping of marine litter items with UAS on coastal environment. The very high-resolution orthophoto produced from UAS images was automatically screened by random forest machine learning method, in order to characterize the marine litter load on beach and dune areas, distinctively. The marine litter objects were identified with a F-test score of 75% when compared to manual procedure. The location of major marine litter loads within the monitored area was found related to beach slope and water level dynamics on the beach profiles, suggesting that UAS flight deployment and post-processing for beach litter mapping can be optimized based on these environmental parameters. The described UAS-based marine litter detection framework is intended to support scientists, engineers and decision makers aiming at monitoring marine and coastal pollution, with the additional aim of optimizing and automating beach clean-up operations. (C) 2019 Elsevier B.V. All rights reserved.","Coastal pollution,Plastic,Drones,Machine learning,Wave runup",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Environmental Sciences & Ecology,,,"RANDOM,FOREST,SEA-LEVEL,SEGMENTATION,RUNUP,PARAMETERIZATION,EXTRACTION,FOREDUNES,SOFTWARE,MODELS,IMAGES",SCIENCE OF THE TOTAL ENVIRONMENT,,
5,The potential for student performance prediction in small cohorts with minimal available attributes,51,2,347-370,"Wakelam Edward,Jefferies Amanda,Davey Neil,Sun Yi","Wakelam E,Jefferies A,Davey N,Sun Y",Wakelam E,10.1111/bjet.12836,University of Hertfordshire,"The measurement of student performance during their progress through university study provides academic leadership with critical information on each student's likelihood of success. Academics have traditionally used their interactions with individual students through class activities and interim assessments to identify those ""at risk"" of failure/withdrawal. However, modern university environments, offering easy on-line availability of course material, may see reduced lecture/tutorial attendance, making such identification more challenging. Modern data mining and machine learning techniques provide increasingly accurate predictions of student examination assessment marks, although these approaches have focussed upon large student populations and wide ranges of data attributes per student. However, many university modules comprise relatively small student cohorts, with institutional protocols limiting the student attributes available for analysis. It appears that very little research attention has been devoted to this area of analysis and prediction. We describe an experiment conducted on a final-year university module student cohort of 23, where individual student data are limited to lecture/tutorial attendance, virtual learning environment accesses and intermediate assessments. We found potential for predicting individual student interim and final assessment marks in small student cohorts with very limited attributes and that these predictions could be useful to support module leaders in identifying students potentially ""at risk.""","LEARNING ANALYTICS,DESIGN,SATISFACTION,PRINCIPLES,EDUCATION",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Education & Educational Research,,5.03,"LEARNING,ANALYTICS,DESIGN,SATISFACTION,PRINCIPLES,EDUCATION",BRITISH JOURNAL OF EDUCATIONAL TECHNOLOGY,http://uhra.herts.ac.uk/bitstream/2299/21474/1/The_potential_for_student_performance_prediction_in_small_cohorts.pdf,
6,Machine learning maximized Anderson localization of phonons in aperiodic superlattices,69,,,"Chowdhury Prabudhya Roy,Reynolds Colleen,Garrett Adam,Feng Tianli,Adiga Shashishekar P.,Ruan Xiulin","Chowdhury PR,Reynolds C,Garrett A,Feng TL,Adiga SP,Ruan XL",Ruan XL,10.1016/j.nanoen.2019.104428,Purdue University System,"Nanostructuring materials to achieve ultra-low lattice thermal conductivity has proven to be extremely attractive for numerous applications such as thermoelectric energy conversion. Anderson localization of phonons due to aperiodicity can reduce thermal conductivity in superlattices, but the lower limit of thermal conductivity remains elusive due to the prohibitively large design space. In this work, we demonstrate that an intuition-based manual search for aperiodic superlattice structures (random multilayers or RMLs) with the lowest thermal conductivity yields only a local minimum, while a genetic algorithm (GA) based approach can efficiently identify the globally minimum thermal conductivity by only exploring a small fraction of the design space. Our results show that this minimum value occurs at an average RML period that is, surprisingly, smaller than the period corresponding to the minimum SL thermal conductivity. Above this critical period, scattering of incoherent phonons at interfaces is less, whereas below this period, the room for randomization becomes less, thus putting more coherent phonons out of Anderson localization and causing increased thermal conductivity. Moreover, the lower limit of the thermal conductivity occurs at a moderate rather than maximum randomness of the layer thickness. Our machine learning approach demonstrates a general process of exploring an otherwise prohibitively large design space to gain non-intuitive physical insights.","Random multilayer,Anderson localization,Thermal conductivity,Machine learning,Molecular dynamics",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,17.631,"THERMAL-CONDUCTIVITY,THERMOELECTRIC-MATERIALS,SI%2FGE,SUPERLATTICES,MATERIALS,DESIGN,MANAGEMENT",NANO ENERGY,https://www.sciencedirect.com/science/article/am/pii/S2211285519311449,
7,Genetic algorithm based on support vector machines for computer vision syndrome classification in health personnel,32,5,1239-1248,"Artime Rios Eva Maria,Suarez Sanchez Ana,Sanchez Lasheras Fernando,Segui Crespo Maria del Mar","Rios EMA,Sanchez AS,Lasheras FS,Crespo MDS",Sanchez AS,10.1007/s00521-018-3581-3,University of Oviedo,"The inclusion in workplaces of video display terminals has brought multiple benefits for the organization of work. Nevertheless, it also implies a series of risks for the health of the workers, since it can cause ocular and visual disorders, among others. In this research, a group of eye and vision-related problems associated with prolonged computer use (known as computer vision syndrome) are studied. The aim is to select the characteristics of the subject that are most relevant for the occurrence of this syndrome, and then, to develop a classification model for its prediction. The estimate of this problem is made by means of support vector machines for classification. This machine learning technique will be trained with the support of a genetic algorithm. This provides the training of the support vector machine with different patterns of parameters, improving its performance. The model performance is verified in terms of the area under the ROC curve, which leads to a model with high accuracy in the classification of the syndrome.","Support vector machines,Genetic algorithms,Computer vision syndrome,Health personnel",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"ARTIFICIAL,NEURAL-NETWORKS,SURFACE,DISEASE,INDEX,OCULAR-SURFACE,RISK-FACTORS,SHIFT,WORK,MODEL,DISCOMFORT,MARKERS,DESIGN,USERS",NEURAL COMPUTING & APPLICATIONS,,
8,An artificial neural network model for the prediction of bruxism by means of occlusal variables,32,5,1259-1267,"Alvarez-Arenal Angel,Dellanos-Lanchares Hector,Martin-Fernandez Elena,Mauvezin Mario,Sanchez Maria Luisa,de Cos Juez Francisco Javier","Alvarez-Arenal A,Dellanos-Lanchares H,Martin-Fernandez E,Mauvezin M,Sanchez ML,Juez FJD",Sanchez ML,10.1007/s00521-018-3715-7,University of Oviedo,"Patients suspected of bruxism represent a very heterogeneous group. Some require immediate treatment while others, with only minor disorders, may not need treatment at all. In this work, artificial neural network ensembles models were trained on with data from 325 bruxist patients examined at the Department of Prosthodontics and Occlusion (Craniomandibular Dysfunction Unit) of Oviedo University. The information retrieved from each patient included some occlusal variables and other information such as their gender and age. The aim of the model is to classify individuals suffering from bruxism in clenching and grinding patients. The models were analyzed using receiver operating characteristics curve analysis, calibration assessments, inter- and intra-method variations. Effective odds ratios for the artificial neural network ensembles were compared. The model resulted in an area under the receiver operation characteristics curve of 86%. At 95% sensitivity, the specificity was 84.1%, for the existence of 43.5% of bruxists clenching patients in the population of this study. This population corresponds to a grinding patients' best predictive value of 97.2% and a clenching patients' best predictive value of 89.5% both using the bagging method. The artificial neural network model obtained can distinguish between clenching and grinding patients requiring the analysis of a few variables and with a high rate of success.","Artificial neural networks,Bruxism,Clenching patient,Grinding patient",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,,"SYSTEM,AGREEMENT,DIAGNOSIS,SYMPTOMS,SPLINTS,BRUXERS,PAIN",NEURAL COMPUTING & APPLICATIONS,,
9,Application of Machine Learning Method to Quantitatively Evaluate the Droplet Size and Deposition Distribution of the UAV Spray Nozzle,10,5,,"Guo Han,Zhou Jun,Liu Fei,He Yong,Huang He,Wang Hongyan","Guo H,Zhou J,Liu F,He Y,Huang H,Wang HY",Liu F,10.3390/app10051759,Zhejiang University,"Featured Application Progress in Spray Science and Technology.
Abstract Unmanned Aerial Vehicle (UAV) spray has been used for efficient and adaptive pesticide applications with its low costs. However, droplet drift is the main problem for UAV spray and will induce pesticide waste and safety concerns. Droplet size and deposition distribution are both highly related to droplet drift and spray effect, which are determined by the nozzle. Therefore, it is necessary to propose an evaluating method for a specific UAV spray nozzles. In this paper, four machine learning methods (REGRESS, least squares support vector machines (LS-SVM), extreme learning machine, and radial basis function neural network (RBFNN)) were applied for quantitatively evaluating one type of UAV spray nozzle (TEEJET XR110015VS), and the case of twin nozzles was investigated. The results showed REGRESS and LS-SVM are good candidates for droplet size evaluation with the coefficient of determination in the calibration set above 0.9 and root means square errors of the prediction set around 2 mu m. RBFNN achieved the best performance for the evaluation of deposition distribution and showed its potential for determining the droplet size of overlapping area. Overall, this study proved the accuracy and efficiency of using the machine learning method for UAV spray nozzle evaluation. Additionally, the study demonstrated the feasibility of using machine learning model to predict the droplet size in the overlapping area of twin nozzles.","UAV spray nozzle,spray characteristics,machine learning,quantitative modeling",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"UNMANNED,AERIAL,VEHICLE,DRIFT,ATOMIZATION,PREDICTION,REGRESSION,PRESSURE,SYSTEM",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/5/1759/pdf,
10,Bayesian inference of non-linear multiscale model parameters accelerated by a Deep Neural Network,360,,,"Wu Ling,Zulueta Kepa,Major Zoltan,Arriaga Aitor,Noels Ludovic","Wu L,Zulueta K,Major Z,Arriaga A,Noels L",Wu L,10.1016/j.cma.2019.112693,University of Liege,"We develop a Bayesian Inference (BI) of the parameters of a non-linear multiscale model and of its material constitutive laws using experimental composite coupon tests as observation data. In particular we consider non-aligned Short Fibers Reinforced Polymer (SFRP) as a composite material system and Mean-Field Homogenization (MFH) as a multiscale model. Although MFH is computationally efficient, when considering non-aligned inclusions, the evaluation cost of a non-linear response for a given set of model and material parameters remains too prohibitive to be coupled with the sampling process required by the BI. Therefore, a Neural-Network (NNW) is first trained using the MFH model, and is then used as a surrogate model during the BI process, making the identification process affordable. (C) 2019 Elsevier B.V. All rights reserved.","Multiscale,Composites,Bayesian inference,Neural Network,Non-linear",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Engineering,Mathematics,Mechanics",,6.828,"HOMOGENIZATION,DISTRIBUTIONS,PLATES,FIELD",COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING,https://orbi.uliege.be/bitstream/2268/240110/1/2020_CMAME_BI.pdf,
11,Increasing the robustness of material-specific deep learning models for crack detection across different materials,206,,,"Alipour Mohamad,Harris Devin K.","Alipour M,Harris DK",Alipour M,10.1016/j.engstruct.2019.110157,University of Virginia,"Infrastructure defect detection solutions based on computer vision have recently emerged as powerful tools with applications in both traditional inspection practices, as well as robotic inspections. These applications involve the collection of images from a wide range of infrastructure systems with heterogeneous characteristics such as conditions, materials, surface appearances and textures. Consequently, defect detection models need to be sufficiently robust to accommodate this type of heterogeneity. Existing image-based crack detection literature almost entirely focuses on models tailored to crack detection in either concrete or asphalt surfaces with prior knowledge of the material involved and studies on crack detection in more than one material are needed for truly automated inspection systems. This paper focuses on the adaptability of deep learning-based crack detection models across common construction materials. To investigate this problem, a residual convolutional neural network architecture was trained and tested on two separate concrete and asphalt crack image data sets and compared with existing baselines. These tests demonstrated that the change of material significantly reduces crack detection accuracy of a tailored model. In response, three domain adaptation techniques, namely joint training, sequential training, and ensemble learning are proposed and implemented to develop robust crack detection models that work on both datasets regardless of the material environment. Results demonstrate that the proposed techniques are able to successfully produce accuracies comparable to those of the material-specific models, without prior knowledge of the material.","Computer vision,Deep learning,Transportation infrastructure,Inspection,Convolutional neural networks,Crack detection",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,4.795,"NEURAL-NETWORK,INSPECTION,DAMAGE,RECOGNITION",ENGINEERING STRUCTURES,,
12,Neural network based non-invasive method to detect anemia from images of eye conjunctiva,30,1,112-125,"Jain Prakhar,Bauskar Shubham,Gyanchandani Manasi","Jain P,Bauskar S,Gyanchandani M",Jain P,10.1002/ima.22359,National Institute of Technology (NIT System),"Detection of anemia can be done by examining the hemoglobin concentration level in the blood using complete blood count, which is an invasive, time-consuming, and costly technique. Preliminary methods for detecting anemia include examining the color of the palpebral conjunctiva, which is a non-invasive method, but color perception may vary from person to person. This study aims to develop a computerized non-invasive technique for anemia detection. We propose a novel machine learning model using the artificial neural network to detect anemic patients from the images of eye conjunctiva. Since limited and small dataset has been used in the earlier approaches, this may cause over fitting of the model. We have improved the number of available training images using image augmentation techniques. To standardize a non-invasive method, we have used computer vision algorithms for preprocessing and feature extraction. This article derives the backpropagation rules mathematically for adjusting the weights for the proposed neural network model. After hyper parameter tuning and using the mathematically derived backpropagation rules, the model was able to achieve the best accuracy of 97.00% with sensitivity 99.21% and specificity 95.42% on the created dataset.","anemia detection,artificial neural network,backpropagation rules,hyper parameters tuning,image augmentation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,PALLOR,INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
13,An online compressor liquid floodback fault diagnosis method for variable refrigerant flow air conditioning system,111,,9-19,"Zhou Zhenxin,Wang Jiangyu,Chen Huanxin,Wei Wentian,Xu Chengliang","Zhou ZX,Wang JY,Chen HX,Wei WT,Xu CL",Chen HX,10.1016/j.ijrefrig.2019.11.024,Huazhong University of Science & Technology,"Compressor liquid floodback not only can drop the performance of the variable refrigerant flow (VRF) system, but also may cause mechanical failure. Therefore, this is necessary to perform a timely online diagnosis of that fault. The present paper proposes an online compressor liquid floodback fault diagnosis method for VRF system based on back-propagation neural network (BPNN), which fills the online compressor liquid floodback fault diagnosis knowledge gap. The proposed method main article context as follow: Firstly, the sensors in VRF system record and save the data every three seconds to form the raw dataset. Secondly, after preprocessing the raw dataset, the correlation analysis is used to filter the data variables. Thirdly, the BPNN model is established by using back-propagation neural network algorithm. The testing dataset was used to verify the reliability of the model. The online dataset was used to test the model's online diagnostic capability, and its results were also compared and analyzed to the Classification and Regression Tree (CART) model. This result indicates that the BPNN method has a low degree of over-fitting and high reliability, and its online diagnostic accuracy is up to 99.48%. By comparing results of the method BPNN and CART, it shows that the former is superior to the latter, regardless of the diagnostic accuracy or the online diagnostic stability. (C) 2019 Elsevier Ltd and IIR. All rights reserved.","Back-propagation neural network,Variable refrigerant flow,Compressor liquid floodback,Online diagnosis,Classification and Regression Tree",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Thermodynamics,Engineering",,3.853,"DECISION,TREE,PERFORMANCE,STRATEGY,FDD",INTERNATIONAL JOURNAL OF REFRIGERATION,,
14,Solving electrical impedance tomography with deep learning,404,,,"Fan Yuwei,Ying Lexing","Fan YW,Ying LX",Fan YW,10.1016/j.jcp.2019.109119,Stanford University,"This paper introduces a new approach for solving electrical impedance tomography (EIT) problems using deep neural networks. The mathematical problem of EIT is to invert the electrical conductivity from the Dirichlet-to-Neumann (DtN) map. Both the forward map from the electrical conductivity to the DtN map and the inverse map are high-dimensional and nonlinear. Motivated by the linear perturbative analysis of the forward map and based on a numerically low-rank property, we propose compact neural network architectures for the forward and inverse maps for both 2D and 3D problems. Numerical results demonstrate the efficiency of the proposed neural networks. (C) 2019 Elsevier Inc. All rights reserved.","Dirichlet-to-Neumann map,Electrical impedance tomography,Inverse problem,Neural networks,BCR-Net,Convolutional neural network",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Computer Science,Physics",,3.81,"NEURAL-NETWORKS,VENTILATION,ALGORITHM",JOURNAL OF COMPUTATIONAL PHYSICS,http://arxiv.org/pdf/1906.03944,
15,Blood Glucose Prediction with Variance Estimation Using Recurrent Neural Networks,4,1,1-18,"Martinsson John,Schliep Alexander,Eliasson Bjorn,Mogren Olof","Martinsson J,Schliep A,Eliasson B,Mogren O",Martinsson J,10.1007/s41666-019-00059-y,RISE Research Institutes of Sweden,"Many factors affect blood glucose levels in type 1 diabetics, several of which vary largely both in magnitude and delay of the effect. Modern rapid-acting insulins generally have a peak time after 60-90 min, while carbohydrate intake can affect blood glucose levels more rapidly for high glycemic index foods, or slower for other carbohydrate sources. It is important to have good estimates of the development of glucose levels in the near future both for diabetic patients managing their insulin distribution manually, as well as for closed-loop systems making decisions about the distribution. Modern continuous glucose monitoring systems provide excellent sources of data to train machine learning models to predict future glucose levels. In this paper, we present an approach for predicting blood glucose levels for diabetics up to 1 h into the future. The approach is based on recurrent neural networks trained in an end-to-end fashion, requiring nothing but the glucose level history for the patient. Our approach obtains results that are comparable to the state of the art on the Ohio T1DM dataset for blood glucose level prediction. In addition to predicting the future glucose value, our model provides an estimate of its certainty, helping users to interpret the predicted levels. This is realized by training the recurrent neural network to parameterize a univariate Gaussian distribution over the output. The approach needs no feature engineering or data preprocessing and is computationally inexpensive. We evaluate our method using the standard root-mean-squared error (RMSE) metric, along with a blood glucose-specific metric called the surveillance error grid (SEG). We further study the properties of the distribution that is learned by the model, using experiments that determine the nature of the certainty estimate that the model is able to capture.","Recurrent neural networks,Blood glucose prediction,Type 1 diabetes",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND","Computer Science,Health Care Sciences & Services,Medical Informatics",,,TIME,JOURNAL OF HEALTHCARE INFORMATICS RESEARCH,https://link.springer.com/content/pdf/10.1007/s41666-019-00059-y.pdf,
16,Predicting Glycaemia in Type 1 Diabetes Patients: Experiments in Feature Engineering and Data Imputation,4,1,71-90,"Jeon Jouhyun,Leimbigler Peter J.,Baruah Gaurav,Li Michael H.,Fossat Yan,Whitehead Alfred J.","Jeon J,Leimbigler PJ,Baruah G,Li MH,Fossat Y,Whitehead AJ",Jeon J; Whitehead AJ,10.1007/s41666-019-00063-2,"Klick Inc, 175 Bloor St East, Toronto, ON, Canada.","Patients with type 1 diabetes manually regulate blood glucose concentration by adjusting insulin dosage in response to factors such as carbohydrate intake and exercise intensity. Automated near-term prediction of blood glucose concentration is essential to prevent hyper- and hypoglycaemic events in type 1 diabetes patients and to improve control of blood glucose levels by physicians and patients. The imperfect nature of patient monitoring introduces missing values into all variables that play important roles to predict blood glucose level, necessitating data imputation. In this paper, we investigated the importance of variables and explored various feature engineering methods to predict blood glucose level. Next, we extended our work by developing a new empirical imputation method and investigating the predictive accuracy achieved under different methods to impute missing data. Also, we examined the influence of past signal values on the prediction of blood glucose levels. We reported the relative performance of predictive models in different testing scenarios and different imputation methods. Finally, we found an optimal combination of data imputation methods and built an ensemble model for the reliable prediction of blood glucose levels on a 30-minute horizon.","Missing data imputation,Type 1 diabetes,Blood glucose level,Machine learning,Gradient boosted trees",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND","Computer Science,Health Care Sciences & Services,Medical Informatics",,,,JOURNAL OF HEALTHCARE INFORMATICS RESEARCH,,
17,Individualized Modeling to Distinguish Between High and Low Arousal States Using Physiological Data,4,1,91-109,"Osotsi Ame,Oravecz Zita,Li Qunhua,Smyth Joshua,Brick Timothy R.","Osotsi A,Oravecz Z,Li QH,Smyth J,Brick TR",Osotsi A,10.1007/s41666-019-00064-1,Pennsylvania Commonwealth System of Higher Education (PCSHE),"With wearable, relatively unobtrusive health monitors and smartphone sensors, it is increasingly easy to collect continuously streaming physiological data in a passive mode without placing much burden on participants. At the same time, smartphones provide the ability to survey participants to provide ""ground-truth"" reporting on psychological states, although this comes at an increased cost in participant burden. In this paper, we examined how analytical approaches from the field of machine learning could allow us to distill the collected physiological data into actionable decision rules about each individual's psychological state, with the eventual goal of identifying important psychological states (e.g., risk moments) without the need for ongoing burdensome active assessment (e.g., self-report). As a first step towards this goal, we compared two methods: (1) a k-nearest neighbor classifier that uses dynamic time warping distance, and (2) a random forests classifier to predict low and high states of affective arousal states based on features extracted using the tsfresh python package. Then, we compared random-forest-based predictive models tailored for the individual with individual-general models. Results showed that the individual-specific model outperformed the general one. Our results support the feasibility of using passively collected wearable data to predict psychological states, suggesting that by relying on both types of data, the active collection can be reduced or eliminated.","Machine learning,Wearable health monitors,Individual-specific modeling,Ambulatory assessment",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND","Computer Science,Health Care Sciences & Services,Medical Informatics",,,DYNAMICS,JOURNAL OF HEALTHCARE INFORMATICS RESEARCH,,
18,Introducing Machine Learning: Science and Technology,1,1,,von Lilienfeld O. Anatole,von Lilienfeld OA,von Lilienfeld OA,10.1088/2632-2153/ab6d5d,University of Basel,"Due to the remarkable progress of ever-growing digitalisation and computing capabilities, data has become increasingly abundant, and machine learning has emerged as a key ingredient in many enabling technologies within modern society. Its potential for pushing the frontiers of science is now also clear and has been demonstrated in various domains extending from novel materials design, quantum physics and the simulation of molecules and chemical systems, to particle physics, medical imaging, space science, climate science and drug discovery. Conceived in close consultation with the community, Machine Learning: Science and Technology has been launched as a unique multidisciplinary, open access journal that will bridge the application of machine learning across the natural sciences with new conceptual advances in machine learning methods as motivated by physical insights.",,Editorial Material,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Computer Science,Science & Technology - Other Topics",,,,MACHINE LEARNING-SCIENCE AND TECHNOLOGY,https://doi.org/10.1088/2632-2153/ab6d5d,
19,A data-driven framework for near real-time and robust damage diagnosis of building structures,27,3,,"Sajedi Seyed Omid,Liang Xiao","Sajedi SO,Liang X",Liang X,10.1002/stc.2488,State University of New York (SUNY) System,"Rapid condition monitoring of structural health is essential for post-earthquake safety assessment. Therefore, information about damage after extreme events could be of great value in resilient communities. This paper proposes a robust framework for the identification of the existence, probable location, and severity of damage using cumulative intensity-based damage features. Taken into account the seismic hazard uncertainties and the undesirable consequences of misclassification in data-driven methods, an objective function based on the confusion score matrix is optimized. This process can enhance the reliability of the prediction model in terms of two conflicting criteria, namely, the general accuracy and conservativeness. Support vector machines are utilized for the task of damage classification where Bayesian optimization is used to select the proper damage-sensitive input features and hyperparameters. A three-story reinforced concrete (RC) moment frame is designed and modeled in OpenSees to examine the performance of the proposed framework. For this purpose, 5,400 incrementally scaled nonlinear time history analyses are conducted considering 180 ground motions. Two different approaches are introduced to distort signals to simulate measurement noise. The robustness of models is also investigated with respect to different objective functions. Furthermore, in an independent experimental case study, the framework is evaluated on a dataset obtained from 44 shake table trials on a three-story RC frame with masonry infill. Given the results obtained from the two case studies, it is shown that the proposed framework is capable of robust and reliable identification of damage in near real-time whereas the concepts of hazard uncertainty and misclassification consequences are properly considered.","damage diagnosis,damage feature extraction,misclassification consequences,pattern recognition in SHM,seismic hazard,structural health monitoring",Article,"JOHN WILEY & SONS LTD, THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND","Construction & Building Technology,Engineering,Instruments & Instrumentation",,4.76,"CUMULATIVE,ABSOLUTE,VELOCITY,MACHINE,LEARNING,ALGORITHMS,SUPPORT,VECTOR,MACHINE,OPTIMIZATION,CLASSIFICATION,IDENTIFICATION,SYSTEM",STRUCTURAL CONTROL & HEALTH MONITORING,,
20,Users' domain knowledge prediction in e-learning with speech-interfaced augmented and virtual reality contents,24,1,163-173,"Sathia Bhama Ponsy R. K.,Hariharasubramanian Vigneshwaran,Mythili O. P.,Ramachandran Murugesh","Bhama PRKS,Hariharasubramanian V,Mythili OP,Ramachandran M",Bhama PRKS,10.1007/s10055-017-0321-4,Anna University,"E-learning provides an individualized course path which provides a user the convenience of pacing ones way through a particular course. One of the key privileges it offers is the flexibility of the course and consistent delivery of the material. The proposed system predicts the user's domain knowledge with the help of the lectures knowledge that a particular user completes and also a lecture's knowledge gets updated with respect to the users' knowledge who searches for it. The dependency among the domains also plays a vital role in updating ones' domain knowledge. The dependencies can be determined by constructing a fuzzy cognitive map. This helps in determining the user's knowledge in other domains also. The lectures of the proposed system include Augmented Reality and Virtual Reality contents which give an interactive learning experience to the users. The user commands are accepted as audio signals, processed, classified and mapped to the system commands to make it to respond. This proposed work uses the combination of discrete wavelet transform and wavelet packet decomposition for feature extraction and artificial neural network for classification.","Augmented reality,Virtual reality,Neural network,Wavelet transformation,Fuzzy cognitive maps,Signal processing",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND","Computer Science,Imaging Science & Photographic Technology",,5.521,FUZZY-LOGIC,VIRTUAL REALITY,,
21,Properties and material models for construction materials post exposure to elevated temperatures,142,,,"Naser M. Z.,Uppala V. A.","Naser MZ,Uppala VA",Naser MZ,10.1016/j.mechmat.2019.103293,Clemson University,"Temperature rise, as in the case of fire, severely damages the properties of construction materials and imposes temperature-induced degradations that alter their microstructure and characteristics. As such, practitioners often struggle when assessing residual state of a fire-damaged structure especially due to the lack of insights into residual (post-fire) properties of construction materials. With the hope of narrowing this knowledge gap, this study presents an approach to derive residual material models for a variety of construction materials such as normal strength concrete (NSC), high strength concrete (HSC), ultra-high performance concrete (UHPC), mild steel (MS), high strength steel (HSS), cold formed steel (CFS), stainless steel (SS), glass fiber reinforced polymer (GFRP) and carbon fiber reinforced polymer (CFRP). This approach leverages a hybrid combination of two machine learning (ML) techniques (artificial neural networks (ANN) and genetic algorithms (GA)) to derive specifically tailored material models capable of tracing the post-fire behavior of construction materials. When implemented, the proposed material models could enable proper and unified assessment of fire-damaged structures.","Residual properties,Post-fire conditions,Artificial neural network (ANN),Genetic algorithm (GA)",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Materials Science,Mechanics",,3.585,"AUSTENITIC,STAINLESS-STEEL,REACTIVE,POWDER,CONCRETE,OF-THE-ART,MECHANICAL-PROPERTIES,NORMAL-STRENGTH,BEHAVIOR,PERFORMANCE,CAPACITY,GLASS",MECHANICS OF MATERIALS,,
22,Optical analog computing devices designed by deep neural network,458,,,"Zhou Yi,Chen Rui,Chen Wenjie,Chen Rui-Pin,Ma Yungui","Zhou Y,Chen R,Chen WJ,Chen RP,Ma YG",Ma YG,10.1016/j.optcom.2019.124674,Zhejiang University,"We proposed a multilayered spatial optical differentiator designing method by use of the deep neural network (DNN). After trained for approximately 30 h, the DNN is able to predict the reflection coefficient of a 12-layer multilayer film with high fidelity (validation mean squared error < 2.4x10(-4)). As a useful example, a second-order spatial optical differentiator was then designed. Compared with the general optimization method, the machine learning could help to quickly generate a wavefront computing device at an about 6-times faster speed. The performance of the designed device is confirmed from the comparison with the theoretical ideal operation output. Another first-order spatial optical differentiator was also designed to validate the generality of the method. The results indicate that the DNN may have a bright future in designing devices capable of all kinds of complex time-space wavefront mathematical operation, in particular based on the multilayer material systems.","Neural networks,Optics in computing,Analog optical signal processing,Multilayer design",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Optics,,1.945,"INVERSE,DESIGN,ALGORITHM",OPTICS COMMUNICATIONS,,
23,"Machine learning models for the prediction of energy, forces, and stresses for Platinum",174,,,"Chapman J.,Batra R.,Ramprasad R.","Chapman J,Batra R,Ramprasad R",Ramprasad R,10.1016/j.commatsci.2019.109483,University System of Georgia,"Materials properties such as defect diffusion and/or dissociation, mechanical fracture and void nucleation, under extreme temperatures and pressures, are all governed by the interactions between individual and/or groups of atoms. Computational tools have been instrumental in understanding the atomistic properties of materials at these length scales. Over the past few decades, these tools have been dominated by two levels of theory: quantum mechanics (QM) based methods and semi-empirical/classical methods. The former are time-intensive, but accurate and versatile, while the latter methods are fast but are significantly limited in veracity, versatility and transferability. Machine learning (ML) algorithms, in tandem with quantum mechanical methods such as density functional theory, have the potential to bridge the gap between these two chasms due to their (i) low cost, (ii) accuracy, (iii) transferability, and (iv) ability to be iteratively improved. In this work, we prescribe a new paradigm in which potential energy, atomic forces, and stresses are rapidly predicted by independent machine learning models, all while retaining the accuracy of quantum mechanics. This platform has been used to study thermal, vibrational, and diffusive properties of bulk Platinum, highlighting the framework's ability to reliably predict materials properties under dynamic conditions. We then compare our ML framework to both QM, where applicable, and several Embedded Atom Method (EAM) potentials. We conclude this work by reflecting upon the current state of ML in materials science for atomistic simulations.","Platinum,Machine learning,Density functional theory,Force field,Vacancy kinetics,Stress-strain behavior",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"EMBEDDED-ATOM,METHOD,DENSITY-FUNCTIONAL,THEORY,METAL-CATALYSTS,APPROXIMATION,SURFACES,KINETICS,FIELDS",COMPUTATIONAL MATERIALS SCIENCE,https://www.sciencedirect.com/science/article/am/pii/S0927025619307827,
24,Can machine learning find extraordinary materials?,174,,,"Kauwe Steven K.,Graser Jake,Murdock Ryan,Sparks Taylor D.","Kauwe SK,Graser J,Murdock R,Sparks TD",Sparks TD,10.1016/j.commatsci.2019.109498,Utah System of Higher Education,"One of the most common criticisms of machine learning is an assumed inability for models to extrapolate, i.e. to identify extraordinary materials with properties beyond those present in the training data set. To investigate whether this is indeed the case, this work takes advantage of density functional theory calculated properties (bulk modulus, shear modulus, thermal conductivity, thermal expansion, band gap, and Debye temperature) to investigate whether machine learning is truly capable of predicting materials with properties that extend beyond previously seen values. We refer to these materials as extraordinary, meaning they represent the top 1% of values in the available data set. Interestingly, we show that even when machine learning is trained on a fraction of the bottom 99% we can consistently identify 3/4 of the highest performing compositions for all considered properties with a precision that is typically above 0.5. We explore model performance as the extrapolation distance is increased in various ways including, introduction of a gap, removal of certain elements, and removal of certain structure types. Moreover, we investigate a few different modeling choices and demonstrate how a classification approach can identify an equivalent amount of extraordinary compounds but with significantly fewer false positives than a regression approach. Finally, we discuss cautions and potential limitations in implementing such an approach to discover new record-breaking materials.","Machine learning,Extrapolation,Materials discovery,Chemical whitespace,High-throughput screening,Regression,Classification",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,,COMPUTATIONAL MATERIALS SCIENCE,,
25,Catalytic materials and chemistry development using a synergistic combination of machine learning and ab initio methods,174,,,"Orupattur Nilesh Varadan,Mushrif Samir H.,Prasad Vinay","Orupattur NV,Mushrif SH,Prasad V",Prasad V,10.1016/j.commatsci.2019.109474,University of Alberta,"First principles-based molecular modelling plays a crucial role in the development of novel catalytic materials and in the investigation of catalytic chemical reactions. However, the computational cost and/or the accuracy of these models remains a bottleneck in carrying out these simulations for complex or large scale systems, as in the case of catalysis. Over the past two decades, machine learning (ML) has made an impact in the field of computational catalysis. Modern-day researchers have started using machine learning-based data-driven techniques to overcome the limitations of these molecular simulations. In this review, we summarize the recent progress in the utilization of ML algorithms to assist molecular simulations, followed by its applications in the field of catalysis. Furthermore, we provide our perspective on promising avenues for research in the future regarding the incorporation of ML in molecular simulations in catalysis.","Catalysis,Machine learning,Molecular modelling,Computational catalysis,Ab initio,Molecular dynamics,Surface science",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"MOLECULAR-DYNAMICS,SIMULATIONS,NEURAL-NETWORK,POTENTIALS,DENSITY-FUNCTIONAL,THEORY,CHEMICAL-REACTIONS,QUANTUM-MECHANICS,SCALING,RELATIONS,SURFACE,SCIENCE,DISCOVERY,ENERGY,DESIGN",COMPUTATIONAL MATERIALS SCIENCE,,
26,A steel property optimization model based on the XGBoost algorithm and improved PSO,174,,,"Song Kai,Yan Feng,Ding Ting,Gao Liang,Lu Songbao","Song K,Yan F,Ding T,Gao L,Lu SB",Yan F,10.1016/j.commatsci.2019.109472,Hunan University,"Exploring the relationships between the properties of steels and their compositions and manufacturing parameters is extremely crucial and indispensable to understanding the science of materials, and subsequently developing new materials. Tensile strength and plasticity, as two important properties of steels, are key to the improvement and optimization of the mechanical properties of steels. In the present paper, we propose an optimization model combining XGBoost algorithm with improved PSO to address the continuous multivariable optimization problem. The main goal is to determine the mapping functions between the tensile strength and plasticity and their influencing factors, based on a diversity of machine learning models such as Linear Regression, SVM, XGBoost, etc. After evaluating the performance these models, we then select the XGBoost model with highest accuracy as the mapping function, which has not been done in previous studies. Moreover, the determined mapping function serves as the fitness value of particle swarm optimization, after which the tensile strength and plasticity optimization with many variables is realized. Finally, the experimental results are analyzed theoretically, and proven to be effective and reliable.","Tensile strength,Plasticity,XGBoost,Particle swarm optimization",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"PARTICLE,SWARM,OPTIMIZATION,MODIFIED,FIREFLY,ALGORITHM,PERFORMANCE,REGRESSION",COMPUTATIONAL MATERIALS SCIENCE,,
27,Automated left ventricular myocardium segmentation using 3D deeply supervised attention U-net for coronary computed tomography angiography; CT myocardium segmentation,47,4,1775-1785,"Jun Guo Bang,He Xiuxiu,Lei Yang,Harms Joseph,Wang Tonghe,Curran Walter J.,Liu Tian,Jiang Zhang Long,Yang Xiaofeng","Guo BJ,He XX,Lei Y,Harms J,Wang TH,Curran WJ,Liu T,Zhang LJ,Yang XF",Liu T; Yang XF,10.1002/mp.14066,Emory University,"Purpose Segmentation of left ventricular myocardium (LVM) in coronary computed tomography angiography (CCTA) is important for diagnosis of cardiovascular diseases. Due to poor image contrast and large variation in intensity and shapes, LVM segmentation for CCTA is a challenging task. The purpose of this work is to develop a region-based deep learning method to automatically detect and segment the LVM solely based on CCTA images.
Methods We developed a 3D deeply supervised U-Net, which incorporates attention gates (AGs) to focus on the myocardial boundary structures, to segment LVM contours from CCTA. The deep attention U-Net (DAU-Net) was trained on the patients' CCTA images, with a manual contour-derived binary mask used as the learning-based target. The network was supervised by a hybrid loss function, which combined logistic loss and Dice loss to simultaneously measure the similarities and discrepancies between the prediction and training datasets. To evaluate the accuracy of the segmentation, we retrospectively investigated 100 patients with suspected or confirmed coronary artery disease (CAD). The LVM volume was segmented by the proposed method and compared with physician-approved clinical contours. Quantitative metrics used were Dice similarity coefficient (DSC), Hausdorff distance (HD), mean surface distance (MSD), residual mean square distance (RMSD), the center of mass distance (CMD), and volume difference (VOD).
Results The proposed method created contours with very good agreement to the ground truth contours. Our proposed segmentation approach is benchmarked primarily using fivefold cross validation. Model prediction correlated and agreed well with manual contour. The mean DSC of the contours delineated by our method was 91.6% among all patients. The resultant HD was 6.840 +/- 4.410 mm. The proposed method also resulted in a small CMD (1.058 +/- 1.245 mm) and VOD (1.640 +/- 1.777 cc). Among all patients, the MSD and RMSD were 0.433 +/- 0.209 mm and 0.724 +/- 0.375 mm, respectively, between ground truth and LVM volume resulting from the proposed method.
Conclusions We developed a novel deep learning-based approach for the automated segmentation of the LVM on CCTA images. We demonstrated the high accuracy of the proposed learning-based segmentation method through comparison with ground truth contour of 100 clinical patient cases using six quantitative metrics. These results show the potential of using automated LVM segmentation for computer-aided delineation of CADs in the clinical setting.","coronary computed tomography angiography,deep attention U-Net,left ventricular myocardium,segmentation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"WHOLE,HEART,SEGMENTATION,DISEASE,QUANTIFICATION,INTEROBSERVER,VARIABILITY,SEARCH,UPDATE",MEDICAL PHYSICS,,
28,Partial Observer Decision Process Model for Crane-Robot Action,2020,,,"Khan Asif,Li Jian Ping,Haq Amin ul,Nazir Shah,Ahmad Naeem,Varish Naushad,Malik Asad,Patel Sarosh H.","Khan A,Li JP,ul Haq A,Nazir S,Ahmad N,Varish N,Malik A,Patel SH",Khan A; Li JP,10.1155/2020/6349342,University of Electronic Science & Technology of China,"The most common use of robots is to effectively decrease the human's effort with desirable output. In the human-robot interaction, it is essential for both parties to predict subsequent actions based on their present actions so as to well complete the cooperative work. A lot of effort has been devoted in order to attain cooperative work between human and robot precisely. In case of decision making , it is observed from the previous studies that short-term or midterm forecasting have long time horizon to adjust and react. To address this problem, we suggested a new vision-based interaction model. The suggested model reduces the error amplification problem by applying the prior inputs through their features, which are repossessed by a deep belief network (DBN) though Boltzmann machine (BM) mechanism. Additionally, we present a mechanism to decide the possible outcome (accept or reject). The said mechanism evaluates the model on several datasets. Hence, the systems would be able to capture the related information using the motion of the objects. And it updates this information for verification, tracking, acquisition, and extractions of images in order to adapt the situation. Furthermore, we have suggested an intelligent purifier filter (IPF) and learning algorithm based on vision theories in order to make the proposed approach stronger. Experiments show the higher performance of the proposed model compared to the state-of-the-art methods.","COMPUTATIONAL MODEL,VISUAL-ATTENTION,OBJECTS,SEARCH",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Computer Science,,1.269,"COMPUTATIONAL,MODEL,VISUAL-ATTENTION,OBJECTS,SEARCH",SCIENTIFIC PROGRAMMING,https://scholarworks.bridgeport.edu/xmlui/bitstream/123456789/4349/1/Partial%20Observer%20Decision%20Process%20Model%20for%20Crane-Robot%20Action.pdf,
29,Level Control of Quadruple Tank System Based on Adaptive Inverse Evolutionary Neural Controller,18,9,2386-2397,Son Nguyen Ngoc,Son NN,Son NN,10.1007/s12555-019-0504-8,Industrial University of Ho Chi Minh City,"This article proposes an adaptive inverse evolutionary neural (AIEN) controller for liquid level control of the quadruple tank system. Firstly, an inverse evolutionary neural model (IEN) that is utilized for offline identifying a dynamics of quadruple tank system, provides a feed-forward control signal from the reference liquid level. In which, the evolutionary neural model is a 3-layers neural network that is optimized by a hybrid method of modified differential evolution and backpropagation algorithm. Then, a hybrid feedforward and PID feedback control is realized to eliminate the steady-state error. Finally, to solve an uncertainty and disturbance characteristic, an adaptive law is proposed to adopt online in its operation. Simulation and real-time control experimental results demonstrated the feasibility and effectiveness of the proposed approach for the quadruple-tank system.","Adaptive feedforward controller,adaptive neural control,differential evolution,level control",Article,"INST CONTROL ROBOTICS & SYSTEMS, KOREAN INST ELECTRICAL ENGINEERS, SUSEO HYUNDAI-VENTUREVILLE 723, BAMGOGAE-RO 1-GIL 10, GANGNAM-GU, SEOUL, SOUTH KOREA",Automation & Control Systems,,2.817,"ANT,COLONY,OPTIMIZATION,FUZZY,PREDICTIVE,CONTROL,DIFFERENTIAL,EVOLUTION,NETWORK",INTERNATIONAL JOURNAL OF CONTROL AUTOMATION AND SYSTEMS,,
30,Towards the automatic detection of social biomarkers in autism spectrum disorder: introducing the simulated interaction task (SIT),3,1,,"Drimalla Hanna,Scheffer Tobias,Landwehr Niels,Baskow Irina,Roepke Stefan,Behnia Behnoush,Dziobek Isabel","Drimalla H,Scheffer T,Landwehr N,Baskow I,Roepke S,Behnia B,Dziobek I",Drimalla H,10.1038/s41746-020-0227-5,Humboldt University of Berlin,"Social interaction deficits are evident in many psychiatric conditions and specifically in autism spectrum disorder (ASD), but hard to assess objectively. We present a digital tool to automatically quantify biomarkers of social interaction deficits: the simulated interaction task (SIT), which entails a standardized 7-min simulated dialog via video and the automated analysis of facial expressions, gaze behavior, and voice characteristics. In a study with 37 adults with ASD without intellectual disability and 43 healthy controls, we show the potential of the tool as a diagnostic instrument and for better description of ASD-associated social phenotypes. Using machine-learning tools, we detected individuals with ASD with an accuracy of 73%, sensitivity of 67%, and specificity of 79%, based on their facial expressions and vocal characteristics alone. Especially reduced social smiling and facial mimicry as well as a higher voice fundamental frequency and harmony-to-noise-ratio were characteristic for individuals with ASD. The time-effective and cost-effective computer-based analysis outperformed a majority vote and performed equal to clinical expert ratings.","FACIAL EMOTION RECOGNITION,HIGH-FUNCTIONING AUTISM,CHILDREN,MIMICRY,INDIVIDUALS,EXPRESSIONS,IDENTIFICATION,VOLUNTARY,DEFICITS,SPEECH",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Health Care Sciences & Services,Medical Informatics",,11.665,"FACIAL,EMOTION,RECOGNITION,HIGH-FUNCTIONING,AUTISM,CHILDREN,MIMICRY,INDIVIDUALS,EXPRESSIONS,IDENTIFICATION,VOLUNTARY,DEFICITS,SPEECH",NPJ DIGITAL MEDICINE,https://europepmc.org/articles/pmc7048784?pdf=render,
31,Editorial: Machine Learning and Data Mining in Materials Science,7,,,"Huber Norbert,Kalidindi Surya R.,Klusemann Benjamin,Cyron Christian J.","Huber N,Kalidindi SR,Klusemann B,Cyron CJ",Huber N,10.3389/fmats.2020.00051,Helmholtz Association,,"machining of data,machine learning,data mining,materials design,materials processing,scale bridging",Editorial Material,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Materials Science,,3.536,,FRONTIERS IN MATERIALS,https://www.frontiersin.org/articles/10.3389/fmats.2020.00051/pdf,
32,Magnetic resonance radiomics for prediction of extraprostatic extension in non-favorable intermediate- and high-risk prostate cancer patients,61,11,1570-1579,"Losnegard Are,Reisaeter Lars A. R.,Halvorsen Ole J.,Jurek Jakub,Assmus Jorg,Arnes Jarle B.,Honore Alfred,Monssen Jan A.,Andersen Erling,Haldorsen Ingfrid S.","Losnegard A,Reisaeter LAR,Halvorsen OJ,Jurek J,Assmus J,Arnes JB,Honore A,Monssen JA,Andersen E,Haldorsen IS",Reisaeter LAR,10.1177/0284185120905066,University of Bergen,"Background
To investigate whether magnetic resonance (MR) radiomic features combined with machine learning may aid in predicting extraprostatic extension (EPE) in high- and non-favorable intermediate-risk patients with prostate cancer.
Purpose
To investigate the diagnostic performance of radiomics to detect EPE.
Material and Methods
MR radiomic features were extracted from 228 patients, of whom 86 were diagnosed with EPE, using prostate and lesion segmentations. Prediction models were built using Random Forest. Further, EPE was also predicted using a clinical nomogram and routine radiological interpretation and diagnostic performance was assessed for individual and combined models.
Results
The MR radiomic model with features extracted from the manually delineated lesions performed best among the radiomic models with an area under the curve (AUC) of 0.74. Radiology interpretation yielded an AUC of 0.75 and the clinical nomogram (MSKCC) an AUC of 0.67. A combination of the three prediction models gave the highest AUC of 0.79.
Conclusion
Radiomic analysis combined with radiology interpretation aid the MSKCC nomogram in predicting EPE in high- and non-favorable intermediate-risk patients.","Prostate,neoplasms primary,magnetic resonance imaging,computer applications - detection,diagnosis",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Radiology, Nuclear Medicine & Medical Imaging",,1.92,"RADICAL,PROSTATECTOMY,PARTIN,TABLES,MRI,NOMOGRAM,FEATURES,RECURRENCE,ADENOCARCINOMA,PERFORMANCE,VALIDATION,DIAGNOSIS",ACTA RADIOLOGICA,,
33,Anatomical context protects deep learning from adversarial perturbations in medical imaging,379,,370-378,"Li Yi,Zhang Huahong,Bermudez Camilo,Chen Yifan,Landman Bennett A.,Vorobeychik Yevgeniy","Li Y,Zhang HH,Bermudez C,Chen YF,Landman BA,Vorobeychik Y",Vorobeychik Y,10.1016/j.neucom.2019.10.085,Washington University (WUSTL),"Deep learning has achieved impressive performance across a variety of tasks, including medical image processing. However, recent research has shown that deep neural networks are susceptible to small adversarial perturbations in the image. We study the impact of such adversarial perturbations in medical image processing where the goal is to predict an individual's age based on a 3D MRI brain image. We consider two models: a conventional deep neural network, and a hybrid deep learning model which additionally uses features informed by anatomical context. We find that we can introduce significant errors in predicted age by adding imperceptible noise to an image, can accomplish this even for large batches of images using a single perturbation, and that the hybrid model is much more robust to adversarial perturbations than the conventional deep neural network. Our work highlights limitations of current deep learning techniques in clinical applications, and suggests a path forward. (C) 2019 Elsevier B.V. All rights reserved.","Medical image processing,Adversarial deep learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,,NEUROCOMPUTING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7450534,
34,CT-based radiomics and machine learning to predict spread through air space in lung adenocarcinoma,30,7,4050-4057,"Jiang Changsi,Luo Yan,Yuan Jialin,You Shuyuan,Chen Zhiqiang,Wu Mingxiang,Wang Guangsuo,Gong Jingshan","Jiang CS,Luo Y,Yuan JL,You SY,Chen ZQ,Wu MX,Wang GS,Gong JS",Gong JS,10.1007/s00330-020-06694-z,Jinan University,"Purpose Spread through air space (STAS) is a novel invasive pattern of lung adenocarcinoma and is also a risk factor for recurrence and worse prognosis of lung adenocarcinoma. The aims of this study are to develop and validate a computed tomography (CT)-based radiomics model for preoperative prediction of STAS in lung adenocarcinoma. Methods and materials This retrospective study was approved by an institutional review board and included 462 (mean age, 58.06 years) patients with pathologically confirmed lung adenocarcinoma. STAS was identified in 90 patients (19.5%). Two experienced radiologists segmented and extracted radiomics features on preoperative thin-slice CT images with radiomics extension independently. Intraclass correlation coefficients (ICC) and Pearson's correlation were used to rule out those low reliable (ICC < 0.75) and redundant (r > 0.9) features. Univariate logistic regression was applied to select radiomics features which were associated with STAS. A radiomics-based machine learning predictive model using a random forest (RF) was developed and calibrated with fivefold cross-validation. The diagnostic performance of the model was measured by the area under the curve (AUC) of receiver operating characteristic (ROC). Results With univariate analysis, 12 radiomics features and age were found to be associated with STAS significantly. The RF model achieved an AUC of 0.754 (a sensitivity of 0.880 and a specificity of 0.588) for predicting STAS. Conclusion CT-based radiomics model can preoperatively predict STAS in lung adenocarcinoma with good diagnosis performance.","Lung,Adenocarcinoma,Metastasis,Radiomics,Machine learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,4.87,"TUMOR,SPREAD,RECURRENCE,RESECTION,MODEL",EUROPEAN RADIOLOGY,,
35,Fully automated scheme for computer-aided detection and breast cancer diagnosis using digitised mammograms,14,3,495-505,"Eltrass Ahmed S.,Salama Mohamed S.","Eltrass AS,Salama MS",Eltrass AS,10.1049/iet-ipr.2018.5953,Egyptian Knowledge Bank (EKB),"Breast cancer becomes a significant public health problem in the world. During the early detection of breast cancer, it is a very challenging task to classify accurately the benign-malignant patterns in digital mammograms. This study proposes a new fully automated computer-aided diagnosis (CAD) system for breast cancer diagnosis with high-accuracy and low-computational requirements. The expectation-maximisation algorithm is investigated to extract automatically the region of interests (ROIs) within mammograms. The standard shape, statistical, and textural features of ROIs are extracted and combined with multi-resolution and multi-orientation features derived from a new feature extraction technique based on wavelet-based contourlet transform. A hybrid feature selection approach based on combining the support vector machine recursive feature elimination with correlation bias reduction algorithm is proposed. Also, the authors investigate a new similarity-based learning algorithm, called Q, for benign-malignant classification. The proposed CAD system is applied to real clinical mammograms, and the experimental results demonstrate the superior performance of the proposed CAD system over other existing CAD systems in terms of accuracy 98.16%, sensitivity 98.63%, specificity 97.80%, and computational time 2.2 s. This reveals the effectiveness of the proposed CAD system in improving the accuracy of breast cancer diagnosis in real-time systems.","medical image processing,image texture,support vector machines,learning (artificial intelligence),wavelet transforms,mammography,image classification,cancer,feature extraction,object detection,expectation-maximisation algorithm,image resolution,statistical analysis,feature selection,correlation methods,computer-aided detection,breast cancer diagnosis,public health problem,benign-malignant patterns,digital mammograms,fully automated computer-aided diagnosis system,low-computational requirements,textural features,multiorientation features,feature extraction technique,hybrid feature selection approach,support vector machine recursive feature elimination,CAD system,breast cance early detection,expectation-maximisation algorithm,region of interest extraction,ROIs,multiresolution features,wavelet-based contourlet transform,correlation bias reduction algorithm,Q similarity-based learning algorithm,benign-malignant classification,real-time systems,real clinical mammograms,time 2,2 s",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"FEATURE-SELECTION,CLASSIFICATION,SEGMENTATION,STATISTICS",IET IMAGE PROCESSING,,
36,Design of fuzzy inference system for apple ripeness estimation using gradient method,14,3,561-569,"Hamza Raja,Chtourou Mohamed","Hamza R,Chtourou M",Hamza R,10.1049/iet-ipr.2018.6524,Universite de Sfax,"In this study, a fuzzy classification approach based on colour features has been investigated to estimate the ripeness of apple fruits according to three maturity stages; unripe, turning-ripe and ripe. The K nearest neighbour algorithm was applied in order to segment the fruit image into four regions namely background, green area, yellow area and red area. The last three regions represent the colour features and were subsequently given as inputs to the fuzzy classifier. Gradient method has been used for tuning the fuzzy classifier in order to obtain the best performance. Image database used for simulation has been collected and exploited for the training and testing phases using cross-validation. Simulation results indicate that the best classifier parameters can be obtained. The efficiency of the proposed system compared with the non-use of the gradient method has been proved by the confusion matrix and the most known classification evaluation metrics. Moreover, the trained fuzzy classifier demonstrates its outperformance in terms of accuracy and execution time compared with other existing methods.","agricultural products,learning (artificial intelligence),image colour analysis,gradient methods,image classification,food products,fuzzy neural nets,fuzzy set theory,nearest neighbour methods,fuzzy reasoning,fuzzy inference system,apple ripeness estimation,gradient method,fuzzy classification approach,colour features,apple fruits,maturity stages,k nearest neighbour algorithm,fruit image,green area,yellow area,red area,image database,testing phases,classifier parameters,classification evaluation metrics,trained fuzzy classifier",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"MACHINE,VISION,RIPENING,STAGES,MATURITY",IET IMAGE PROCESSING,,
37,An analysis of the influence of hand hole and ventilation hole design on compressive strength of corrugated fiberboard boxes by an artificial neural network model,33,4-5,171-181,"Archaviboonyobul Tita,Chaveesuk Ravipim,Singh Jay,Jinkarn Tunyarut","Archaviboonyobul T,Chaveesuk R,Singh J,Jinkarn T",Jinkarn T,10.1002/pts.2495,Kasetsart University,"This research aimed at developing a high-performing corrugated fiberboard box compression strength prediction model and to analyze the influences of ventilation and hand hole designs for these containers on the box compression test (BCT) by applying artificial neural network (ANN) modeling. The input variables considered in this study are composed of nine parameters including box dimension as well as shapes, sizes, positions, and locations of ventilations and hand holes of a regular slotted container (RSC, FEFCO 0201). Back propagation algorithms (BPNs) of ANN models were developed from 970 BCT testing data points (single wall boards, C flute, 205/112/205 g/m(2)). Tested data was randomly broken into three groups for the model development as 80:10:10 for the training set, testing set, and validating set. According to the analysis performed, a BPN 9-13-1 model reflected the highest prediction performance with R-2 = 0.97. According to the analysis, BCT was significantly affected by the hand hole location followed by the geometrical dimensions of the box (height, length, and width) and the ventilation factors (shape, number, and location) in that order. Hand holes at the top flaps caused a lower BCT reduction compared with those at the vertical locations of the box. Slight changes to the eliminated board area for both hand holes and ventilation (+/- 5%) contributed to less BCT reduction compared with its locations and shapes. Interestingly, increasing the box height significantly increased the BCT, and this was found to be limited only to shorter boxes fabricated from a high stiffness corrugated board.","artificial neural network,compression strength,corrugated fiberboard box,hand hole,ventilation hole",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Food Science & Technology",,2.179,"MULTIPLE,LINEAR-REGRESSION,FINITE-ELEMENT-ANALYSIS,SYSTEMS,PERFORMANCE,STRESS,FIELDS,STRAIN,PANELS",PACKAGING TECHNOLOGY AND SCIENCE,,
38,Artificial Intelligence: A New Paradigm in Obstetrics and Gynecology Research and Clinical Practice,12,2,,"Iftikhar Pulwasha,Kuijpers Marcela V,Khayyat Azadeh,Iftikhar Aqsa,De Sa Maribel DeGouvia","Iftikhar P,Kuijpers MV,Khayyat A,Iftikhar A,De Sa MD",Iftikhar P,10.7759/cureus.7124,Saint John's University,"Artificial intelligence (AI) is growing exponentially in various fields, including medicine. This paper reviews the pertinent aspects of AI in obstetrics and gynecology (OB/GYN) and how these can be applied to improve patient outcomes and reduce the healthcare costs and workload for clinicians.
Herein, we will address current AI uses in OB/GYN, and the use of AI as a tool to interpret fetal heart rate (FHR) and cardiotocography (CTG) to aid in the detection of preterm labor, pregnancy complications, and review discrepancies in its interpretation between clinicians to reduce maternal and infant morbidity and mortality. AI systems can be used as tools to create algorithms identifying asymptomatic women with short cervical length who are at risk of preterm birth. Additionally, the benefits of using the vast data capacity of AI storage can assist in determining the risk factors for preterm labor using multiomics and extensive genomic data. In the field of gynecological surgery, the use of augmented reality helps surgeons detect vital structures, thus decreasing complications, reducing operative time, and helping surgeons in training to practice in a realistic setting. Using three-dimensional (3D) printers can provide materials that mimic real tissues and also helps trainees to practice on a realistic model. Furthermore, 3D imaging allows better depth perception than its two-dimensional (2D) counterpart, allowing the surgeon to create preoperative plans according to tissue depth and dimensions. Although AI has some limitations, this new technology can improve the prognosis and management of patients, reduce healthcare costs, and help OB/GYN practitioners to reduce their workload and increase their efficiency and accuracy by incorporating Al systems into their daily practice.
AI has the potential to guide practitioners in decision-making, reaching a diagnosis, and improving case management. It can reduce healthcare costs by decreasing medical errors and providing more dependable predictions. Al systems can accurately provide information on the large array of patients in clinical settings, although more robust data is required.","artificial intelligence,obstetrics,gynecology,cost effectiveness,machine learning,pregnancy surveillance,preterm labor,fetal heart rate,in vitro fertilization,cancer screening",Review,"CUREUS INC, PO BOX 61002, PALO ALTO, CA 94306 USA",General & Internal Medicine,,,TECHNOLOGY,CUREUS,https://europepmc.org/articles/pmc7105008?pdf=render,
39,Emerging neuromorphic devices,31,9,,"Ielmini Daniele,Ambrogio Stefano","Ielmini D,Ambrogio S",Ielmini D,10.1088/1361-6528/ab554b,Polytechnic University of Milan,"Artificial intelligence (AI) has the ability of revolutionizing our lives and society in a radical way, by enabling machine learning in the industry, business, health, transportation, and many other fields. The ability to recognize objects, faces, and speech, requires, however, exceptional computational power and time, which is conflicting with the current difficulties in transistor scaling due to physical and architectural limitations. As a result, to accelerate the progress of AI, it is necessary to develop materials, devices, and systems that closely mimic the human brain. In this work, we review the current status and challenges on the emerging neuromorphic devices for brain-inspired computing. First, we provide an overview of the memory device technologies which have been proposed for synapse and neuron circuits in neuromorphic systems. Then, we describe the implementation of synaptic learning in the two main types of neural networks, namely the deep neural network and the spiking neural network (SNN). Bio-inspired learning, such as the spike-timing dependent plasticity scheme, is shown to enable unsupervised learning processes which are typical of the human brain. Hardware implementations of SNNs for the recognition of spatial and spatio-temporal patterns are also shown to support the cognitive computation in silico. Finally, we explore the recent advances in reproducing bio-neural processes via device physics, such as insulating-metal transitions, nanoionics drift/diffusion, and magnetization flipping in spintronic devices. By harnessing the device physics in emerging materials, neuromorphic engineering with advanced functionality, higher density and better energy efficiency can be developed.","neuromorphic devices,resistive switching,synaptic plasticity",Review,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Science & Technology - Other Topics,Materials Science,Physics",,3.618,"RESISTIVE-SWITCHING,MEMORY,PHASE-CHANGE,MATERIALS,DEEP,NEURAL-NETWORKS,SYNAPSE,DEVICE,SILICON-OXIDE,SPIN,TECHNOLOGY,PLASTICITY,RATIO,RRAM",NANOTECHNOLOGY,https://doi.org/10.1088/1361-6528/ab554b,
40,,,,,,,,,,,,,,,,,,,,
41,Mathematical and Visual Understanding of a Deep Learning Model Towards m-Agriculture for Disease Diagnosis,28,3,1129-1145,"Francis Mercelin,Deisy C.","Francis M,Deisy C",Francis M,10.1007/s11831-020-09407-3,Thiagarajar College of Engineering,"Disease detection and classification based on the disease spot found on the leaves is of great importance in improving the agricultural productivity. This paper provides a comprehensive overview of the prevailing applications of computer vision and deep learning techniques in the field of agriculture highlighting the necessity of disease identification and classification using leaf image dataset. A novel classification framework is proposed explaining its working principle. The proposed framework is applied on the multispace image reconstruction inputs. The multispace image reconstruction inputs are used to generate a new set of images containing its gradient images. Then high level semantic features are extracted from the original and reconstructed images, via. convolutional and depthwise separable convolutional layers. Finally, softmax classifier is used for classification. The hyperparameters and computational cost are computed mathematically which provides an insight of creativeness to the researchers. The framework performance is evaluated and compared with the related works on publicly available apple leaf image dataset.",,Review,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering,Mathematics",,8.169,,ARCHIVES OF COMPUTATIONAL METHODS IN ENGINEERING,,
42,Inhibitors of Calcium Oxalate Crystallization for the Treatment of Oxalate Nephropathies,7,8,,"Kletzmayr Anna,Mulay Shrikant R.,Motrapu Manga,Luo Zhi,Anders Hans-Joachim,Ivarsson Mattias E.,Leroux Jean-Christophe","Kletzmayr A,Mulay SR,Motrapu M,Luo Z,Anders HJ,Ivarsson ME,Leroux JC",Leroux JC,10.1002/advs.201903337,ETH Zurich,"Calcium oxalate (CaOx) crystal-induced nephropathies comprise a range of kidney disorders, for which there are no efficient pharmacological treatments. Although CaOx crystallization inhibitors have been suggested as a therapeutic modality already decades ago, limited progress has been made in the discovery of potent molecules with efficacy in animal disease models. Herein, an image-based machine learning approach to systematically screen chemically modified myo-inositol hexakisphosphate (IP6) analogues is utilized, which enables the identification of a highly active divalent inositol phosphate molecule. To date, this is the first molecule shown to completely inhibit the crystallization process in the nanomolar range, reduce crystal-cell interactions, thereby preventing CaOx-induced transcriptomic changes, and decrease renal CaOx deposition and kidney injury in a mouse model of hyperoxaluria. In conclusion, IP6 analogues based on such a scaffold may represent a new treatment option for CaOx nephropathies.","calcium oxalate crystallization inhibitors,chronic kidney disease,image-based drug screening,kidney calcification,kidney stones",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Chemistry,Science & Technology - Other Topics,Materials Science",,17.835,"TUBULAR,EPITHELIAL-CELLS,MOLECULAR,MODIFIERS,CRYSTAL-GROWTH,MONOHYDRATE,HYPEROXALURIA,ADHESION,CITRATE,STONES,INDUCE",ADVANCED SCIENCE,https://www.research-collection.ethz.ch/bitstream/20.500.11850/404454/3/advs.201903337.pdf,
43,Radiomics of Coronary Artery Calcium in the Framingham Heart Study.,2,1,e190119,,,,10.1148/ryct.2020190119,,"Purpose: To extract radiomic features from coronary artery calcium (CAC) on CT images and to determine whether this approach could improve the ability to identify individuals at risk for a composite endpoint of clinical events.Results: The RS had a median value of 0.08 (interquartile range, 0.007-0.71) and a weak and modest correlation with Framingham risk score (FRS) (r = 0.2) and AS (r = 0.39), respectively. The continuous RS unadjusted, adjusted for age and sex, FRS, AS, and FRS plus AS were significantly associated with events (hazard ratio [HR] = 2.2, P < .001; HR = 1.8, P = .002; HR = 2.0, P < .001; HR = 1.7, P = .02; and HR = 1.8, P = .01, respectively). In participants with AS of less than 300, RS association with events remained significant when unadjusted and adjusted for age and sex, FRS, AS, and FRS plus AS (HR = 2.4, 2.8, 2.8, 2.3, and 2.6; P < .001, respectively). In the same subgroup of participants, adding the RS to AS resulted in a significant improvement in the discriminatory ability for events as compared with the AS (area under the receiver operating curve: 0.80 vs 0.68, respectively; P = .03). 2020 by the Radiological Society of North America, Inc.",,Journal Article,,,,,,,,
44,Analysis of electronic health records based on long short-term memory,32,14,,"Shi Peiying,Hou Feng,Zheng Xiangwei,Yuan Feng","Shi PY,Hou F,Zheng XW,Yuan F",Zheng XW,10.1002/cpe.5684,Shandong Normal University,"There is a large amount of historical data of the patient's hospitalization named the electronic health records (EHRs), but the data are not fully utilized for great challenges as poor quality, high dimension, and so on. Previous studies have primarily used machine learning methods that rely heavily on manual extraction of features. Recently, many deep learning approaches are applied to predictive model of EHRs. Recurrent neural networks (RNN) are often used to model EHR data, but RNN performance degrades in the face of large sequence lengths. To solve these challenges, we develop a long short-term memory with attention mechanism for mortality prediction. The dataset used in this article is the Medical Information Mart for Intensive Care III, which contains comprehensive clinical data for the patients. The experimental results demonstrate that the predicted results can be effectively interpreted using the attention mechanism. Compared with other baseline models, our model improves the accuracy of prediction, and helps doctors reduce the average diagnostic time.","attention mechanism,deep learning,electronic health records,long short-term memory networks,recurrent neural network",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Computer Science,,1.471,"TECHNOLOGY,ALGORITHM,NETWORKS",CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE,,
45,"Correlation analysis of strongly fluctuating atomic volumes, charges, and stresses in body-centered cubic refractory high-entropy alloys",4,2,,"Ishibashi Shoji,Ikeda Yuji,Koermann Fritz,Grabowski Blazej,Neugebauer Joerg","Ishibashi S,Ikeda Y,Kormann F,Grabowski B,Neugebauer J",Ishibashi S,10.1103/PhysRevMaterials.4.023608,Max Planck Society,"Local lattice distortions in a series of body-centered cubic alloys, including refractory high-entropy alloys, are investigated by means of atomic volumes, atomic charges, and atomic stresses defined by the Bader charge analysis based on first-principles calculations. Analyzing the extensive data sets, we find large distributions of these atomic properties for each element in each alloy, indicating a large impact of the varying local chemical environments. We show that these local-environment effects can be well understood and captured already by the first and the second nearest neighbor shells. Based on this insight, we employ linear regression models up to the second nearest neighbor shell to accurately predict these atomic properties. Finally, we find that the elementwise-averaged values of the atomic properties correlate linearly with the averaged valence-electron concentration of the considered alloys.","MECHANICAL-PROPERTIES,CONFIGURATION ENERGIES,MOLECULAR-DYNAMICS,TRANSITION-METALS,GRAIN-BOUNDARIES,TENSOR ANALYSIS,LOCAL-ENERGY,PHASE,STATE,NB",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Materials Science,,4.034,"MECHANICAL-PROPERTIES,CONFIGURATION,ENERGIES,MOLECULAR-DYNAMICS,TRANSITION-METALS,GRAIN-BOUNDARIES,TENSOR,ANALYSIS,LOCAL-ENERGY,PHASE,STATE,NB",PHYSICAL REVIEW MATERIALS,http://link.aps.org/pdf/10.1103/PhysRevMaterials.4.023608,
46,Impact of Chemical Features on Methane Adsorption by Porous Materials at Varying Pressures,124,8,4534-4544,"Pardakhti Maryam,Nanda Pariksheet,Srivastava Ranjan","Pardakhti M,Nanda P,Srivastava R",Srivastava R,10.1021/acs.jpcc.9b09319,University of Connecticut,"Superior performance in methane uptake capacity prediction by hypothetical metal organic frameworks has previously been accomplished using a novel combination of structural and chemical features with machine learning (ML) algorithms. This concept is extended for additional microcrystalline materials, focusing on 69 839 covalent organic frameworks (COFs) and 17 846 porous polymer networks (PPNs). For each material category, data was divided into train (80%) and test (20%) sets. Using the random forest (RF) algorithm, 10-fold cross-validation was carried out to evaluate the robustness of prediction for structural and chemical descriptors. Structural features included surface area, density, and void fraction. Chemical descriptors included the number and type of each atom, electronegativity, and degree of unsaturation among others. When chemical descriptors for adsorption at low pressures were included, significant improvements for predictions were observed compared to solely using structural descriptors. Specifically, adding chemical features increased the R-2 value from 0.66 to 0.87 for COFs and from results indicate that inclusion of chemical descriptors improves prediction across materials and pressures. While physisorption is the main driver for adsorption at these pressures, these results also imply contribution of surface chemical motifs on adsorption phenomena.","METAL-ORGANIC FRAMEWORKS,IN-SILICO DESIGN,NANOPOROUS MATERIALS,STORAGE,PREDICTION,SEPARATION,CAPACITY,CARBON,MOF,CO2",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,4.467,"METAL-ORGANIC,FRAMEWORKS,IN-SILICO,DESIGN,NANOPOROUS,MATERIALS,STORAGE,PREDICTION,SEPARATION,CAPACITY,CARBON,MOF,CO2",JOURNAL OF PHYSICAL CHEMISTRY C,,
47,Impact of a deep learning assistant on the histopathologic classification of liver cancer,3,1,,"Kiani Amirhossein,Uyumazturk Bora,Rajpurkar Pranav,Wang Alex,Gao Rebecca,Jones Erik,Yu Yifan,Langlotz Curtis P.,Ball Robyn L.,Montine Thomas J.","Kiani A,Uyumazturk B,Rajpurkar P,Wang A,Gao R,Jones E,Yu Y,Langlotz CP,Ball RL,Montine TJ",Ng AY,10.1038/s41746-020-0232-8,Stanford University,"Artificial intelligence (AI) algorithms continue to rival human performance on a variety of clinical tasks, while their actual impact on human diagnosticians, when incorporated into clinical workflows, remains relatively unexplored. In this study, we developed a deep learning-based assistant to help pathologists differentiate between two subtypes of primary liver cancer, hepatocellular carcinoma and cholangiocarcinoma, on hematoxylin and eosin-stained whole-slide images (WSI), and evaluated its effect on the diagnostic performance of 11 pathologists with varying levels of expertise. Our model achieved accuracies of 0.885 on a validation set of 26 WSI, and 0.842 on an independent test set of 80 WSI. Although use of the assistant did not change the mean accuracy of the 11 pathologists (p = 0.184, OR = 1.281), it significantly improved the accuracy (p = 0.045, OR = 1.499) of a subset of nine pathologists who fell within well-defined experience levels (GI subspecialists, non-GI subspecialists, and trainees). In the assisted state, model accuracy significantly impacted the diagnostic decisions of all 11 pathologists. As expected, when the model's prediction was correct, assistance significantly improved accuracy (p = 0.000, OR = 4.289), whereas when the model's prediction was incorrect, assistance significantly decreased accuracy (p = 0.000, OR = 0.253), with both effects holding across all pathologist experience levels and case difficulty levels. Our results highlight the challenges of translating AI models into the clinical setting, and emphasize the importance of taking into account potential unintended negative consequences of model assistance when designing and testing medical AI-assistance tools.","HEPATOCELLULAR-CARCINOMA,PATHOLOGY,CHOLANGIOCARCINOMA,REPRODUCIBILITY,NEED",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Health Care Sciences & Services,Medical Informatics",,11.665,"HEPATOCELLULAR-CARCINOMA,PATHOLOGY,CHOLANGIOCARCINOMA,REPRODUCIBILITY,NEED",NPJ DIGITAL MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7044422,
48,A one-class peeling method for multivariate outlier detection with applications in phase I SPC,36,4,1272-1295,"Martinez Waldyn G.,Weese Maria L.,Jones-Farmer L. Allison","Martinez WG,Weese ML,Jones-Farmer LA",Martinez WG,10.1002/qre.2629,Miami University,"In phase I of statistical process control (SPC), control charts are often used as outlier detection methods to assess process stability. Many of these methods require estimation of the covariance matrix, are computationally infeasible, or have not been studied when the dimension of the data, p, is large. We propose the one-class peeling (OCP) method, a flexible framework that combines statistical and machine learning methods to detect multiple outliers in multivariate data. The OCP method can be applied to phase I of SPC, does not require covariance estimation, and is well suited to high-dimensional data sets with a high percentage of outliers. Our empirical evaluation suggests that the OCP method performs well in high dimensions and is computationally more efficient and robust than existing methodologies. We motivate and illustrate the use of the OCP method in a phase I SPC application on a N=354, p=1917 dimensional data set containing Wikipedia search results for National Football League (NFL) players, teams, coaches, and managers. The example data set and R functions, OCP.R and OCPLimit.R, to compute the respective OCP distances and thresholds are available in the supplementary materials.","control chart,Gaussian kernel,high-dimensional data,kernel distance,one-class methods,support vector data description",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Operations Research & Management Science",,2.77,"KERNEL-PCA,ALGORITHMS,CONTROL,CHARTS,WIDE,DATA,CLASSIFICATION,SELECTION",QUALITY AND RELIABILITY ENGINEERING INTERNATIONAL,https://doi.org/10.1002/qre.2629,
49,Feature-shared adaptive-boost deep learning for invasiveness classification of pulmonary subsolid nodules in CT images,47,4,1738-1749,"Wang Jun,Chen Xiaorong,Lu Hongbing,Zhang Lichi,Pan Jianfeng,Bao Yong,Su Jiner,Qian Dahong","Wang J,Chen XR,Lu HB,Zhang LC,Pan JF,Bao Y,Su JN,Qian DH",Qian DH,10.1002/mp.14068,Shanghai Jiao Tong University,"Purpose In clinical practice, invasiveness is an important reference indicator for differentiating the malignant degree of subsolid pulmonary nodules. These nodules can be classified as atypical adenomatous hyperplasia (AAH), adenocarcinoma in situ (AIS), minimally invasive adenocarcinoma (MIA), or invasive adenocarcinoma (IAC). The automatic determination of a nodule's invasiveness based on chest CT scans can guide treatment planning. However, it is challenging, owing to the insufficiency of training data and their interclass similarity and intraclass variation. To address these challenges, we propose a two-stage deep learning strategy for this task: prior-feature learning followed by adaptive-boost deep learning.
Methods The adaptive-boost deep learning is proposed to train a strong classifier for invasiveness classification of subsolid nodules in chest CT images, using multiple 3D convolutional neural network (CNN)-based weak classifiers. Because ensembles of multiple deep 3D CNN models have a huge number of parameters and require large computing resources along with more training and testing time, the prior-feature learning is proposed to reduce the computations by sharing the CNN layers between all weak classifiers. Using this strategy, all weak classifiers can be integrated into a single network.
Results Tenfold cross validation of binary classification was conducted on a total of 1357 nodules, including 765 noninvasive (AAH and AIS) and 592 invasive nodules (MIA and IAC). Ablation experimental results indicated that the proposed binary classifier achieved an accuracy of 73.4\%+/- 1.4 with an AUC of 81.3\%+/- 2.2. These results are superior compared to those achieved by three experienced chest imaging specialists who achieved an accuracy of 69.1\%, 69.3\%, and 67.9\%, respectively. About 200 additional nodules were also collected. These nodules covered 50 cases for each category (AAH, AIS, MIA, and IAC, respectively). Both binary and multiple classifications were performed on these data and the results demonstrated that the proposed method definitely achieves better performance than the performance achieved by nonensemble deep learning methods.
Conclusions It can be concluded that the proposed adaptive-boost deep learning can significantly improve the performance of invasiveness classification of pulmonary subsolid nodules in CT images, while the prior-feature learning can significantly reduce the total size of deep models. The promising results on clinical data show that the trained models can be used as an effective lung cancer screening tool in hospitals. Moreover, the proposed strategy can be easily extended to other similar classification tasks in 3D medical images.","computed tomography,deep learning,invasiveness classification,pulmonary nodule",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"CONVOLUTIONAL,NEURAL-NETWORK,COMPUTER-AIDED,DIAGNOSIS,GROUND-GLASS,NODULES,LUNG,NODULES,PREINVASIVE,LESIONS,SEGMENTATION,SHAPE,ADENOCARCINOMAS,ENSEMBLE,TEXTURE",MEDICAL PHYSICS,https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/mp.14068,
50,LungRegNet: An unsupervised deformable image registration method for 4D-CT lung,47,4,1763-1774,"Fu Yabo);,Lei Yang);,Wang Tonghe);,Higgins Kristin);,Bradley Jeffrey D.);,Curran Walter J.);,Liu Tian);,Yang Xiaofeng","Fu YB,Lei Y,Wang TH,Higgins K,Bradley JD,Curran WJ,Liu T,Yang XF",Yang XF,10.1002/mp.14065,Emory University,"Purpose To develop an accurate and fast deformable image registration (DIR) method for four-dimensional computed tomography (4D-CT) lung images. Deep learning-based methods have the potential to quickly predict the deformation vector field (DVF) in a few forward predictions. We have developed an unsupervised deep learning method for 4D-CT lung DIR with excellent performances in terms of registration accuracies, robustness, and computational speed.
Methods A fast and accurate 4D-CT lung DIR method, namely LungRegNet, was proposed using deep learning. LungRegNet consists of two subnetworks which are CoarseNet and FineNet. As the name suggests, CoarseNet predicts large lung motion on a coarse scale image while FineNet predicts local lung motion on a fine scale image. Both the CoarseNet and FineNet include a generator and a discriminator. The generator was trained to directly predict the DVF to deform the moving image. The discriminator was trained to distinguish the deformed images from the original images. CoarseNet was first trained to deform the moving images. The deformed images were then used by the FineNet for FineNet training. To increase the registration accuracy of the LungRegNet, we generated vessel-enhanced images by generating pulmonary vasculature probability maps prior to the network prediction.
Results We performed fivefold cross validation on ten 4D-CT datasets from our department. To compare with other methods, we also tested our method using separate 10 DIRLAB datasets that provide 300 manual landmark pairs per case for target registration error (TRE) calculation. Our results suggested that LungRegNet has achieved better registration accuracy in terms of TRE than other deep learning-based methods available in the literature on DIRLAB datasets. Compared to conventional DIR methods, LungRegNet could generate comparable registration accuracy with TRE smaller than 2 mm. The integration of both the discriminator and pulmonary vessel enhancements into the network was crucial to obtain high registration accuracy for 4D-CT lung DIR. The mean and standard deviation of TRE were 1.00 +/- 0.53 mm and 1.59 +/- 1.58 mm on our datasets and DIRLAB datasets respectively.
Conclusions An unsupervised deep learning-based method has been developed to rapidly and accurately register 4D-CT lung images. LungRegNet has outperformed its deep-learning-based peers and achieved excellent registration accuracy in terms of TRE.","4D-CT lung,deep learning,deformable image registration,unsupervised learning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"MOTION,ESTIMATION,REGULARIZATION,ALGORITHMS",MEDICAL PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7165051,
51,Multi-sequence MR image-based synthetic CT generation using a generative adversarial network for head and neck MRI-only radiotherapy,47,4,1880-1894,"Qi Mengke,Li Yongbao,Wu Aiqian,Jia Qiyuan,Li Bin,Sun Wenzhao,Dai Zhenhui,Lu Xingyu,Zhou Linghong,Deng Xiaowu","Qi MK,Li YB,Wu AQ,Jia QY,Li B,Sun WH,Dai ZH,Lu XY,Zhou LH,Deng XW",Zhou LH; Song T,10.1002/mp.14075,Southern Medical University - China,"Purpose The purpose of this study is to investigate the effect of different magnetic resonance (MR) sequences on the accuracy of deep learning-based synthetic computed tomography (sCT) generation in the complex head and neck region.
Methods Four sequences of MR images (T1, T2, T1C, and T1DixonC-water) were collected from 45 patients with nasopharyngeal carcinoma. Seven conditional generative adversarial network (cGAN) models were trained with different sequences (single channel) and different combinations (multi-channel) as inputs. To further verify the cGAN performance, we also used a U-net network as a comparison. Mean absolute error, structural similarity index, peak signal-to-noise ratio, dice similarity coefficient, and dose distribution were evaluated between the actual CTs and sCTs generated from different models.
Results The results show that the cGAN model with multi-channel (i.e., T1 + T2 + T1C + T1DixonC-water) as input to predict sCT achieves higher accuracy than any single MR sequence model. The T1-weighted MR model achieves better results than T2, T1C, and T1DixonC-water models. The comparison between cGAN and U-net shows that the sCTs predicted by cGAN retains additional image details are less blurred and more similar to the actual CT.
Conclusions Conditional generative adversarial network with multiple MR sequences as model input shows the best accuracy. The T1-weighted MR images provide sufficient image information and are suitable for sCT prediction in clinical scenarios with limited acquisition sequences or limited acquisition time.","conditional generative adversarial network,MRI-only radiotherapy,multi-MR sequence,sCT generation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"TARGET,VOLUME,DELINEATION,REGISTRATION,SIMULATION,CANCER",MEDICAL PHYSICS,,
52,High-Speed Piezoresponse Force Microscopy and Machine Learning Approaches for Dynamic Domain Growth in Ferroelectric Materials,12,8,9944-9952,"Liu Yue,Yu Bingxue,Liu Zhiwen,Beck David,Zeng Kaiyang","Liu Y,Yu BX,Liu ZW,Beck D,Zeng KY",Zeng KY,10.1021/acsami.9b21306,National University of Singapore,"Domain dynamics has been one of the hottest research topics for ferroelectric materials in order to understand the ferroelectric mechanisms and to develop the related applications. By using high-speed piezoresponse force microscopy (HSPFM), it is possible to observe the dynamic domain evolution in an ultrashort time increment. This paper combines the HSPFM experiments and machine learning to study the domain growth under a weak AC field in ferroelectric materials. Here, the Bayesian optimized support vector machine is employed to classify the switching domain and stable domain. The results indicate that the machine learning classifier is capable of discerning the switching area. In addition, the domain associated characteristics, such as domain pinning and domain wall pinning, can also be observed and analyzed by combining experiments and machine learning. The machine learning approach can fast and deeply extract the complicated features related to free energy from the multidimensional signals obtained by HSPFM.","ferroelectricity,high-speed piezoresponse force microscopy,support vector machine,domain dynamics,machine learning,polarization switching",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science",,9.57,"SUPPORT,VECTOR,MACHINES,NUCLEATION,NANOSCALE,MECHANISM",ACS APPLIED MATERIALS & INTERFACES,,
53,Cough Expired Volume and Cough Peak Flow Rate Estimation Based on GA-BP Method,2020,,,"Ren Shuai,Niu Jinglong,Luo Zihao,Shi Yan,Cai Maolin,Luo Zujin,Yu Qihui","Ren S,Niu JL,Luo ZH,Shi Y,Cai ML,Luo ZJ,Yu QH",Ren S; Shi Y,10.1155/2020/9036369,Beihang University,"Cough is a respiratory protective behavior for clearing the secretion. The cough process can be characterized by three features which are cough peak flow rate, peak velocity time, and cough expired volume. The cough expired volume (CEV) and the cough peak flow rate (CPFR) are important for medical diagnosis and cough effectiveness assessment. In this study, the CEV and CPFR values of 700 healthy participants were measured and collected by using a portable pulmonary function device. The gender, age, height, weight, and smoking status information of the 700 participants were also collected. Meanwhile, the integration of backpropagation neural network and genetic algorithm (GA-BP) method was developed to estimate CEV and CPFR values. The results showed that the estimation accuracy of GA-BP method exceeds 90%, which indicates that the GA-BP method could be effectively used for CEV and CPFR value estimation. Furthermore, the method proposed in this paper could be useful for medical diagnosis and medical device development.","ARTIFICIAL NEURAL-NETWORK,VOLUNTARY COUGH,VELOCITY TIME,POWER,CLASSIFICATION,OPTIMIZATION",Article,"WILEY-HINDAWI, ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND","Mathematics,Science & Technology - Other Topics",,2.8,"ARTIFICIAL,NEURAL-NETWORK,VOLUNTARY,COUGH,VELOCITY,TIME,POWER,CLASSIFICATION,OPTIMIZATION",COMPLEXITY,https://downloads.hindawi.com/journals/complexity/2020/9036369.pdf,
54,Data-driven prediction of diamond-like infrared nonlinear optical crystals with targeting performances,10,1,,"Wang Rui,Liang Fei,Lin Zheshuai","Wang R,Liang F,Lin ZS",Lin ZS,10.1038/s41598-020-60410-x,Chinese Academy of Sciences,"Combining high-throughput screening and machine learning models is a rapidly developed direction for the exploration of novel optoelectronic functional materials. Here, we employ random forests regression (RFR) model to investigate the second harmonic generation (SHG) coefficients of nonlinear optical crystals with distinct diamond-like (DL) structures. 61 DL structures in Inorganic Crystallographic Structure Database (ICSD) are selected, and four distinctive descriptors, including band gap, electronegativity, group volume and bond flexibility, are used to model and predict second-order nonlinearity. It is demonstrated that the RFR model has reached the first-principles calculation accuracy, and gives validated predictions for a variety of representative DL crystals. Additionally, this model shows promising applications to explore new crystal materials of quaternary DL system with superior mid-IR NLO performances. Two new potential NLO crystals, Li2CuPS4 with ultrawide bandgap and Cu2CdSnTe4 with giant SHG response, are identified by this model.","AB-INITIO,FREQUENCY-GENERATION,LASER,SE,SEMICONDUCTOR,GROWTH,GAP,X=S",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,5.134,"AB-INITIO,FREQUENCY-GENERATION,LASER,SE,SEMICONDUCTOR,GROWTH,GAP,X%3DS",SCIENTIFIC REPORTS,https://www.nature.com/articles/s41598-020-60410-x.pdf,
55,Artificial Neural Network-Based Automatic Detection of Food Intake for Neuromodulation in Treating Obesity and Diabetes,30,7,2547-2557,"Heremans Elisabeth R. M.,Chen Amy S.,Wang Ximeng,Cheng Jiafei,Xu Feng,Martinez Agustin E.,Lazaridis Georgios,Van Huffel Sabine,Chen Jiande D. Z.","Heremans ERM,Chen AS,Wang XM,Cheng JF,Xu F,Martinez AE,Lazaridis G,Van Huffel S,Chen JDZ",Chen JDZ,10.1007/s11695-020-04511-6,Johns Hopkins University,"Purpose Neuromodulation, such as vagal nerve stimulation and intestinal electrical stimulation, has been introduced for the treatment of obesity and diabetes. Ideally, neuromodulation should be applied automatically after food intake. The purpose of this study was to develop a method of automatic food intake detection through dynamic analysis of heart rate variability (HRV). Materials and Methods Two experiments were conducted: (1) a small sample series with a standard test meal and (2) a large sample series with varying meal size. Electrocardiograms (ECGs) were collected in the fasting and postprandial states. Each ECG was processed to compute the HRV. For each HRV segment, time- and frequency-domain features were derived and used as inputs to train and test an artificial neural network (ANN). The ANN was trained and tested with different cross-validation methods. Results The highest classification accuracy reached with leave-one-subject-out-leave-one-sample-out cross-validation was 0.93 in experiment 1 and 0.88 in experiment 2. Retraining the ANN on recordings of a subject drastically increased the achieved accuracy for that subject to values of 0.995 and 0.95 in experiments 1 and 2, respectively. Conclusions Automatic food intake detection by ANNs, using features from the HRV, is feasible and may have a great potential for neuromodulation-based treatments of meal-related disorders.","Food intake detection,Obesity,Diabetes,Neuromodulation,Machine learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Surgery,,4.653,"FUNCTIONAL,GASTROINTESTINAL,DISORDERS,INTESTINAL,ELECTRICAL-STIMULATION,ABDOMINAL-PAIN,MOTILITY,SYSTEM",OBESITY SURGERY,https://lirias.kuleuven.be/bitstream/123456789/652297/2/20-23.pdf,
56,"Use of a K-nearest neighbors model to predict the development of type 2 diabetes within 2 years in an obese, hypertensive population",58,5,991-1002,"Garcia-Carretero Rafael,Vigil-Medina Luis,Mora-Jimenez Inmaculada,Soguero-Ruiz Cristina,Barquero-Perez Oscar,Ramos-Lopez Javier","Garcia-Carretero R,Vigil-Medina L,Mora-Jimenez I,Soguero-Ruiz C,Barquero-Perez O,Ramos-Lopez J",Garcia-Carretero R,10.1007/s11517-020-02132-w,Universidad Rey Juan Carlos,"Prediabetes is a type of hyperglycemia in which patients have blood glucose levels above normal but below the threshold for type 2 diabetes mellitus (T2DM). Prediabetic patients are considered to be at high risk for developing T2DM, but not all will eventually do so. Because it is difficult to identify which patients have an increased risk of developing T2DM, we developed a model of several clinical and laboratory features to predict the development of T2DM within a 2-year period. We used a supervised machine learning algorithm to identify at-risk patients from among 1647 obese, hypertensive patients. The study period began in 2005 and ended in 2018. We constrained data up to 2 years before the development of T2DM. Then, using a time series analysis with the features of every patient, we calculated one linear regression line and one slope per feature. Features were then included in a K-nearest neighbors classification model. Feature importance was assessed using the random forest algorithm. The K-nearest neighbors model accurately classified patients in 96% of cases, with a sensitivity of 99%, specificity of 78%, positive predictive value of 96%, and negative predictive value of 94%. The random forest algorithm selected the homeostatic model assessment-estimated insulin resistance, insulin levels, and body mass index as the most important factors, which in combination with KNN had an accuracy of 99% with a sensitivity of 99% and specificity of 97%. We built a prognostic model that accurately identified obese, hypertensive patients at risk for developing T2DM within a 2-year period. Clinicians may use machine learning approaches to better assess risk for T2DM and better manage hypertensive patients. Machine learning algorithms may help health care providers make more informed decisions.","Type 2 diabetes mellitus,K-nearest neighbors,Random forest,Cardiovascular risk assessment",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,,"INSULIN-RESISTANCE,PREVENTION,PROGRAM,LIFE-STYLE,RISK,MELLITUS,HEALTH,METAANALYSIS,PROGRESSION,DISEASE,ADULTS",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
57,Properties Prediction and Design of Tire Tread Composites Using Machine Learning,29,3,,"Pang Song,Luo Jinlian,Wu Youping","Pang S,Luo JL,Wu YP",Wu YP,10.1002/mats.201900063,Beijing University of Chemical Technology,"The present study focuses on exploring the relationship between various properties of tire tread composites and filler system using machine learning. Four different types of machine learning algorithms, such as multiple linear regression (MLR), artificial neural network (ANN), support vector machine regression (SVR), and classification and regression tree, are used for predicting 0 degrees C tan delta, 60 degrees C tan delta, tensile strength, and Shore A hardness of natural rubber nanocomposites from carbon nanotubes dosage, silica dosage, and total filler equivalent. The results showed that the introduction of interaction terms and square terms into the inputs evidently improved the prediction capability of MLR, ANN and SVR, and MLR possessed the smallest prediction errors (<5%). The established MLR models are further used to design tire tread composites with high 0 degrees C tan delta, low 60 degrees C tan delta, and appropriate Shore A hardness and tensile strength. The predicted values are in good agreement with the experimental results, indicating that the established MLR models can be used for properties prediction and design of tire tread composites effectively. Moreover, k-fold cross-validation is proved to be a reliable technique to evaluate the predictive capability of the MLR models.","machine learning,multiple linear regression,rubber materials,tire treads",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Polymer Science,,1.577,"ARTIFICIAL,NEURAL-NETWORK,SUPPORT,VECTOR,MACHINE,NATURAL-RUBBER,CARBON,NANOTUBES,REGRESSION-MODEL,HYBRID,REINFORCEMENT,CONSUMPTION,MANAGEMENT,RESISTANCE",MACROMOLECULAR THEORY AND SIMULATIONS,,
58,Segmentation and visualization of left atrium through a unified deep learning framework,15,4,589-600,"Du Xiuquan,Yin Susu,Tang Renjun,Liu Yueguo,Song Yuhui,Zhang Yanping,Liu Heng,Li Shuo","Du XQ,Yin SS,Tang RJ,Liu YG,Song YH,Zhang YP,Liu H,Li S",Du XQ,10.1007/s11548-020-02128-9,Anhui University,"Purpose Left atrium segmentation and visualization serve as a fundamental and crucial role in clinical analysis and understanding of atrial fibrillation. However, most of the existing methods are directly transmitting information, which may cause redundant information to be passed to affect segmentation performance. Moreover, they did not further consider atrial visualization after segmentation, which leads to a lack of understanding of the essential atrial anatomy. Methods We propose a novel unified deep learning framework for left atrium segmentation and visualization simultaneously. At first, a novel dual-path module is used to enhance the expressiveness of cardiac image representation. Then a multi-scale context-aware module is designed to effectively handle complex appearance and shape variations of the left atrium and associated pulmonary veins. The generated multi-scale features are feed to gated bidirectional message passing module to remove irrelevant information and extract discriminative features. Finally, the features after message passing are efficiently combined via a deep supervision mechanism to produce the final segmentation result and reconstruct 3D volumes. Results Our approach primarily against the 2018 left atrium segmentation challenge dataset, which consists of 100 3D gadolinium-enhanced magnetic resonance images. Our method achieves an average dice of 0.936 in segmenting the left atrium via fivefold cross-validation, which outperforms state-of-the-art methods. Conclusions The performance demonstrates the effectiveness and advantages of our network for the left atrium segmentation and visualization. Therefore, our proposed network could potentially improve the clinical diagnosis and treatment of atrial fibrillation.","Left atrium,Gadolinium-enhanced magnetic resonance image,Segmentation,Visualization",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,,"AUTOMATIC,SEGMENTATION,IMAGES",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
59,A novel respiration pattern biometric prediction system based on artificial neural network,40,1,8-16,"Raji Rafiu King,Adjeisah Michael,Miao Xuhong,Wan Ailan","Raji RK,Adjeisah M,Miao XH,Wan AL",Raji RK,10.1108/SR-10-2019-0235,Huizhou University,"Purpose
The purpose of this paper is to introduce a novel respiration pattern-based biometric prediction system (BPS) by using artificial neural network (ANN).
Design/methodology/approach
Respiration patterns were obtained using a knitted piezoresistive smart chest band. The ANN model was implemented by using four hidden layers to help achieve the best complexity to produce an adequate fit for the data. Not only did this study give a detailed distribution of an ANN model construction including the scheme of parameters and network layers, ablation of the architecture and the derivation of back-propagation during the iterations but also engaged a step-based decay to systematically drop the learning rate after specific epochs during training to minimize the loss and increase the model's accuracy as well as to limit the risk of overfitting.
Findings
Findings establish the feasibility of using respiratory patterns for biometric identification. Experimental results show that, with a learning rate drop factor = 0.5, the network is able to continue to learn past epoch 40 until stagnation occurs which yielded a classification accuracy of 98 per cent. Out of 51,338 test set, the model achieved 51,557 correctly classified instances and 169 misclassified instances.
Practical implications - The findings provide an impetus for possible studies into the application of chest breathing sensors for human machine interfaces in the area of entertainment.
Originality/value
This is the first time respiratory patterns have been applied in biometric prediction system design.","Sensors,Biometrics,Machine intelligence,Neural networks,Force sensing,Artificial neural network,Biometric prediction system,Knitting,Strain sensor,Smart wear",Article,"EMERALD GROUP PUBLISHING LTD, HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND",Instruments & Instrumentation,,1.674,,SENSOR REVIEW,,
60,A Universal Machine Learning Algorithm for Large-Scale Screening of Materials,142,8,3814-3822,"Fanourgakis George S.,Gkagkas Konstantinos,Tylianakis Emmanuel,Froudakis George E.","Fanourgakis GS,Gkagkas K,Tylianakis E,Froudakis GE",Froudakis GE,10.1021/jacs.9b11084,University of Crete,"Application of machine learning (ML) methods for the determination of the gas adsorption capacities of nanomaterials, such as metal-organic frameworks (MOF), has been extensively investigated over the past few years as a computationally efficient alternative to time-consuming and computationally demanding molecular simulations. Depending on the thermodynamic conditions and the adsorbed gas, ML has been found to provide very accurate results. In this work, we go one step further and we introduce chemical intuition in our descriptors by using the ""type"" of the atoms in the structure, instead of the previously used building blocks, to account for the chemical character of the MOF. ML predictions for the methane and carbon dioxide adsorption capacities of several tens of thousands of hypothetical MOFs are evaluated at various thermodynamic conditions using the random forest algorithm. For all cases examined, the use of atom types instead of building blocks leads to significantly more accurate predictions, while the number of MOFs needed for the training of the ML algorithm in order to achieve a specified accuracy can be reduced by an order of magnitude. More importantly, since practically there are an unlimited number of building blocks that materials can be made of but a limited number of atom types, the proposed approach is more general and can be considered as universal. The universality and transferability was proved by predicting the adsorption properties of a completely different family of materials after the training of the ML algorithm in MOFs.","METAL-ORGANIC FRAMEWORKS,FORCE-FIELD,METHANE STORAGE,ADSORPTION,PREDICTION,EXTENSION,SITES",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,15.801,"METAL-ORGANIC,FRAMEWORKS,FORCE-FIELD,METHANE,STORAGE,ADSORPTION,PREDICTION,EXTENSION,SITES",JOURNAL OF THE AMERICAN CHEMICAL SOCIETY,,
61,SBS Content Detection for Modified Asphalt Using Deep Neural Network,2020,,,"Wang Zhixiang,Li Jiange,Zhang Zhengqi,Zuo Youxiang","Wang ZX,Li JG,Zhang ZQ,Zuo YX",Li JG,10.1155/2020/2513147,Chang'an University,"This study proposes a prediction model for accurately detecting styrene-butadiene-styrene (SBS) content in modified asphalt using the deep neural network (DNN). Traditional methods used for evaluating the SBS content are inaccurate and complicated because they are prone to produce errors by manual computation. Feature data of SBS content are derived from the spectra, which are obtained by the Fourier-transform infrared spectroscopy test. After designing DNN, preprocessed feature data are utilized as training and testing data and are fed into the DNN via a feature matrix. Furthermore, comparative studies are conducted to verify the accuracy of the proposed model. Results show that the mean square error value decreased by 68% for DNN with noise and dimension reduction. The DNN-based prediction model showed that the correlation coefficient between the target value and the mean predicted value is 0.9978 and 0.9992 for training and testing samples, respectively, indicating its remarkable accuracy and applicability after training. In comparison with the standard curve method and the random forest method, the precision of DNN is greater than 98% for the same test conditions, achieving the best predicting performance.","DAMAGE DETECTION,PAVEMENT,FTIR,PERFORMANCE,PREDICTION,STABILITY,BITUMENS,SULFUR",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Materials Science,,1.94,"DAMAGE,DETECTION,PAVEMENT,FTIR,PERFORMANCE,PREDICTION,STABILITY,BITUMENS,SULFUR",ADVANCES IN MATERIALS SCIENCE AND ENGINEERING,https://doi.org/10.1155/2020/2513147,
62,Machine Learning-Based Prediction of Crystal Systems and Space Groups from Inorganic Materials Compositions,5,7,3596-3606,"Zhao Yong,Cui Yuxin,Xiong Zheng,Jin Jing,Liu Zhonghao,Dong Rongzhi,Hu Jianjun","Zhao Y,Cui YX,Xiong Z,Jin J,Liu ZH,Dong RZ,Hu JJ",Hu JJ,10.1021/acsomega.9b04012,University of South Carolina System,"Structural information of materials such as the crystal systems and space groups are highly useful for analyzing their physical properties. However, the enormous composition space of materials makes experimental X-ray diffraction (XRD) or first-principle-based structure determination methods infeasible for large-scale material screening in the composition space. Herein, we propose and evaluate machine-learning algorithms for determining the structure type of materials, given only their compositions. We couple random forest (RF) and multiple layer perceptron (MLP) neural network models with three types of features: Magpie, atom vector, and one-hot encoding (atom frequency) for the crystal system and space group prediction of materials. Four types of models for predicting crystal systems and space groups are proposed, trained, and evaluated including one-versus-all binary classifiers, multiclass classifiers, polymorphism predictors, and multilabel classifiers. The synthetic minority over-sampling technique (SMOTE) is conducted to mitigate the effects of imbalanced data sets. Our results demonstrate that RF with Magpie features generally outperforms other algorithms for binary and multiclass prediction of crystal systems and space groups, while MLP with atom frequency features is the best one for structural polymorphism prediction. For multilabel prediction, MLP with atom frequency and binary relevance with Magpie models are the best for predicting crystal systems and space groups, respectively. Our analysis of the related descriptors identifies a few key contributing features for structural-type prediction such as electronegativity, covalent radius, and Mendeleev number. Our work thus paves a way for fast composition-based structural screening of inorganic materials via predicted material structural properties.",,Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,3.613,,ACS OMEGA,https://pubs.acs.org/doi/pdf/10.1021/acsomega.9b04012,
63,Early diagnosis of glaucoma using multi-feature analysis and DBN based classification,12,3,4027-4036,"Ajesh F.,Ravi R.,Rajakumar G.","Ajesh F,Ravi R,Rajakumar G",Ajesh F,10.1007/s12652-020-01771-z,Anna University,"In this new era, the advancement towards the diagnosis of disease in its early-stage has improved. The medical field is not only equipped with the new generation devices but also the approach. The ultimate aim of this research is to diagnose a Glaucoma disorder in the optical never of the eye. Glaucoma diagnosis is a complex process as it produces no sign until it affects the eye and causes a loss of vision partially or entirely. This research provides a solution to find this disorder at the early stage by analysis the retinal parameters or features extracted using high-resolution imaging process. In this screening process, the hunt for diseases such as retinal detachment, retinopathy, retinoblastoma, and age-related molecular degeneration is processed. The classification of these diseases is complicated as many of these diseases share identical characteristics which cause the doctors to confuse in identifying the particular illness for the treatment. In this research, the multi-feature analysis methodology of classification is introduced enhanced with the machine learning algorithm and a DWT (discrete wavelet transform) to classify the diseases for the unique treatment procedures. This research shows promising results as the methodology provides more than 95 percentage of Accuracy for the Glaucoma identification.","Deep learning,Deep belief network,Glaucoma early detection,Multi-feature analysis",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Telecommunications",,6.163,,JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING,,
64,An Embedded Multi-branch 3D Convolution Neural Network for False Positive Reduction in Lung Nodule Detection,33,4,846-857,"Zuo Wangxia,Zhou Fuqiang,He Yuzhu","Zuo WX,Zhou FQ,He YZ",Zhou FQ,10.1007/s10278-020-00326-0,Beihang University,"Numerous lung nodule candidates can be produced through an automated lung nodule detection system. Classifying these candidates to reduce false positives is an important step in the detection process. The objective during this paper is to predict real nodules from a large number of pulmonary nodule candidates. Facing the challenge of the classification task, we propose a novel 3D convolution neural network (CNN) to reduce false positives in lung nodule detection. The novel 3D CNN includes embedded multiple branches in its structure. Each branch processes a feature map from a layer with different depths. All of these branches are cascaded at their ends; thus, features from different depth layers are combined to predict the categories of candidates. The proposed method obtains a competitive score in lung nodule candidate classification on LUNA16 dataset with an accuracy of 0.9783, a sensitivity of 0.8771, a precision of 0.9426, and a specificity of 0.9925. Moreover, a good performance on the competition performance metric (CPM) is also obtained with a score of 0.830. As a 3D CNN, the proposed model can learn complete and three-dimensional discriminative information about nodules and non-nodules to avoid some misidentification problems caused due to lack of spatial correlation information extracted from traditional methods or 2D networks. As an embedded multi-branch structure, the model is also more effective in recognizing the nodules of various shapes and sizes. As a result, the proposed method gains a competitive score on the false positive reduction in lung nodule detection and can be used as a reference for classifying nodule candidates.","Embedded,Multi-branch,3D CNN,False positive reduction,Lung nodule detection",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"PULMONARY,NODULES,AUTOMATIC,DETECTION,IMAGES",JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7522146,
65,Second-Generation Sequencing with Deep Reinforcement Learning for Lung Infection Detection,2020,,,"Liu Zhuo,Zhang Gerui,Zhao Jingyuan,Yu Liyan,Sheng Junxiu,Zhang Na,Yuan Hong","Liu Z,Zhang GR,Jingyuan Y,Yu LY,Sheng JX,Zhang N,Yuan H",Yuan H,10.1155/2020/3264801,Dalian Medical University,"Recently, deep reinforcement learning, associated with medical big data generated and collected from medical Internet of Things, is prospective for computer-aided diagnosis and therapy. In this paper, we focus on the application value of the second-generation sequencing technology in the diagnosis and treatment of pulmonary infectious diseases with the aid of the deep reinforcement learning. Specifically, the rapid, comprehensive, and accurate identification of pathogens is a prerequisite for clinicians to choose timely and targeted treatment. Thus, in this work, we present representative deep reinforcement learning methods that are potential to identify pathogens for lung infection treatment. After that, current status of pathogenic diagnosis of pulmonary infectious diseases and their main characteristics are summarized. Furthermore, we analyze the common types of second-generation sequencing technology, which can be used to diagnose lung infection as well. Finally, we point out the challenges and possible future research directions in integrating deep reinforcement learning with second-generation sequencing technology to diagnose and treat lung infection, which is prospective to accelerate the evolution of smart healthcare with medical Internet of Things and big data.","GENOME,IDENTIFICATION,MRSA",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Health Care Sciences & Services,,3.188,"GENOME,IDENTIFICATION,MRSA",JOURNAL OF HEALTHCARE ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7060411,
66,Foam mat drying of papaya using microwaves: Machine learning modeling,43,6,,"Qadri Ovais S.,Osama Khwaja,Srivastava Abhaya K.","Qadri OS,Osama K,Srivastava AK",Osama K,10.1111/jfpe.13394,Integral University,"The aim of this article is to study the microwave-assisted foam mat drying of papaya to form papaya powder. The process of foam mat drying of papaya using microwaves was modeled by machine learning approaches like artificial neural network (ANN), support vector regression (SVR), and Gaussian process regression (GPR). Effect of microwave power (480-640 W), inlet air temperature (40-50 degrees C), and thickness of foam (2-4 mm) on the rate of drying were studied. The performance of the models was evaluated on the basis of different performance matrices including root mean square error (RMSE), coefficient of determination (R-2), model predictive error, and Chi-square (chi(2)). The microwave heating of the papaya foam reduced the drying time manifold. All three machine learning approaches were able to predict the drying process efficiently. SVR showed the best performance (R-2 = 0.96; RMSE = 0.03) followed by GPR (R-2 = 0.92; RMSE = 0.04) and ANN (R-2 = 0.91; RMSE = 0.04). SVR-based model was simulated to predict the effect of power, temperature, and thickness on drying rate. Machine learning approaches can be efficiently used for modeling and microwave-assisted foam mat drying. SVR-based model proves to be a good alternative of ANN.
Practical Applications Foam mat drying is the method of dehydrating for heat-sensitive and viscous materials which cannot be dried by other conventional methods. It is cost-effective, simple, and provides high product quality. The use of microwave-assisted drying decreases the drying time manifold. Modeling of the drying process is significant for its scale-up to industrial scale. Machine learning techniques have the capability of learning the hidden factors involved in the process and thus provide better predictions as compared with statistical regression methods. In this study, three machine learning methods (artificial neural network [ANN], support vector regression [SVR], and Gaussian process regression [GPR]) were compared for their efficiency in modeling the foam-mat drying of papaya pulp using microwaves. SVR showed the best performance as compared with ANN and GPR.","HOT AIR,OPTIMIZATION,PARAMETERS,QUALITY,PREDICTION",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Food Science & Technology",,2.417,"HOT,AIR,OPTIMIZATION,PARAMETERS,QUALITY,PREDICTION",JOURNAL OF FOOD PROCESS ENGINEERING,,
67,Fractionation of ultrafine particles: Evaluation of separation efficiency by UV-vis spectroscopy,213,,,"Winkler Marvin,Sonner Heiko,Gleiss Marco,Nirschl Hermann","Winkler M,Sonner H,Gleiss M,Nirschl H",Winkler M,10.1016/j.ces.2019.115374,Helmholtz Association,"Centrifugation is an established tool in solids process technology to handle classification of particulate products. However, dispersions with strict specifications for product-relevant properties often require a different approach. Fractionation is necessary when both geometric and material properties matter. Due to their high throughput and centrifugal acceleration, semi-continuous tubular centrifuges are suitable for the effective performance of such tasks. In order to monitor this mechanism for several size and density fractions, the separation efficiency is correlated with optical properties. Titanium dioxide and pigment particles serve as experimental products. Coarser size fractions are separated and overflow samples are analysed with analytical centrifugation and UV-vis spectroscopy. Each extinction spectrum is labeled with distinctive target values and a regression model is build. Finally, mixtures are processed and targets determined using the machine learning algorithm. It is discussed to what extent the advanced methodology can be applied to multidimensional unit operations such as density fractionation. (C) 2019 Elsevier Ltd. All rights reserved.","Solid-liquid separation,Centrifugation,Fractionation,Colloidal particles,UV-vis spectroscopy,Machine learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Engineering,,4.216,"OPTICAL-PROPERTIES,SIZE,GOLD,NANOPARTICLES",CHEMICAL ENGINEERING SCIENCE,,
68,Shallow Foundation Settlement Quantification: Application of Hybridized Adaptive Neuro-Fuzzy Inference System Model,2020,,,"Mohammed Mariamme,Sharafati Ahmad,Al-Ansari Nadhir,Yaseen Zaher Mundher","Mohammed M,Sharafati A,Al-Ansari N,Yaseen ZM",Yaseen ZM,10.1155/2020/7381617,Ton Duc Thang University,"Settlement simulating in cohesion materials is a crucial issue due to complexity of cohesion soil texture. This research emphasis on the implementation of newly developed machine learning models called hybridized Adaptive Neuro-Fuzzy Inference System (ANFIS) with Particle Swarm Optimization (PSO) algorithm, Ant Colony optimizer (ACO), Differential Evolution (DE), and Genetic Algorithm (GA) as efficient approaches to predict settlement of shallow foundation over cohesion soil properties. The width of footing (B), pressure of footing (q(a)), geometry of footing (L/B), count of SPT blow (N), and ratio of footing embedment (Df/B) are considered as predictive variables. Nonhomogeneity and inconsistency of employed dataset is a major concern during prediction modeling. Hence, two different modeling scenarios (i) preprocessed dataset (PP) and (ii) nonprocessed (initial) dataset (NP) were inspected. To assess the accuracy of the applied hybrid models and standalone one, multiple statistical metrics were computed and analyzed over the training and testing phases. Results indicated ANFIS-PSO model exhibited an accurate and reliable prediction data intelligent and had the highest predictability performance against all employed models. In addition, results demonstrated that data preprocessing is highly essential to be performed prior to building the predictive models. Overall, ANFIS-PSO model showed a robust machine learning for settlement prediction.","BEARING CAPACITY,SHEAR-STRENGTH,ANFIS-PSO,PREDICTION,OPTIMIZATION,SIMULATION,NETWORK,COLONY,IMPLEMENTATION,ALGORITHMS",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Construction & Building Technology,Engineering",,1.923,"BEARING,CAPACITY,SHEAR-STRENGTH,ANFIS-PSO,PREDICTION,OPTIMIZATION,SIMULATION,NETWORK,COLONY,IMPLEMENTATION,ALGORITHMS",ADVANCES IN CIVIL ENGINEERING,https://downloads.hindawi.com/journals/ace/2020/7381617.pdf,
69,Diverse frequency band-based convolutional neural networks for tonic cold pain assessment using EEG,378,,270-282,"Yu Mingxin,Sun Yichen,Zhu Bofei,Zhu Lianqing,Lin Yingzi,Tang Xiaoying,Guo Yikang,Sun Guangkai,Dong Mingli","Yu MX,Sun YC,Zhu BF,Zhu LQ,Lin YZ,Tang XY,Guo YK,Sun GK,Dong ML",Zhu LQ,10.1016/j.neucom.2019.10.023,Beijing Information Science & Technology University,"The purpose of this study is to present a novel classification framework, called diverse frequency band-based Convolutional Neural Networks (DFB-based ConvNets), which can objectively identify tonic cold pain states. To achieve this goal, scalp EEG data were recorded from 32 subjects under cold stimuli conditions. The proposed DFB-based ConvNets model is capable of classifying three classes of tonic pain: No pain, Moderate Pain, and Severe Pain. Firstly, the proposed method utilizes diverse frequency band-based inputs to learn temporal representations from different frequency bands of Electroencephalogram (EEG) which are expected to have more discriminative power. Then the derived features are concatenated to form a feature vector, which is fed into a fully-connected network for performing the classification task. Experimental results demonstrate that the proposed method successfully discriminates the tonic cold pain states. To show the superiority of the DFB-based ConvNets classifier, we compare our results with the state-of-the-art classifiers and show it has a competitive classification accuracy (97.37%). Moreover, these promising results may pave the way to use DFB-based ConvNets in clinical pain research. (C) 2019 Elsevier B.V. All rights reserved.","Tonic cold pain classification,EEG Convolutional Neural Networks (ConvNets),Deep learning,Pattern recognition",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"MECHANISMS,POWER,STIMULATION,PREDICTION,RESPONSES,HAND",NEUROCOMPUTING,https://www.sciencedirect.com/science/article/am/pii/S0925231219313980,
70,Automatic fetal brain extraction from 2D in utero fetal MRI slices using deep neural network,378,,335-349,"Li Jinpeng,Luo Yishan,Shi Lin,Zhang Xin,Li Ming,Zhang Bing,Wang Defeng","Li JP,Luo YS,Shi L,Zhang X,Li M,Zhang B,Wang DF",Wang DF,10.1016/j.neucom.2019.10.032,Chinese University of Hong Kong,"Background: In utero fetal MRI has been developing in common medical prenatal practice for nearly two decades. But the applications and research on fetal MRI still lag behind due to the lack of specialized image processing and analysis tools. Brain extraction, as an initial preprocessing step for many brain MRI-based processing methods, is an important basis for accurate fetal MRI analysis. However, it is very challenging to automatically extract fetal brains from fetal MRI due to the large variation in fetal brains across different gestational weeks and complex maternal tissues surrounding the fetal brains.
Method: We proposed a novel two-step framework using the deep learning method for solving the challenging problem of automatic fetal brain extraction in 2D in utero fetal MRI slices. The proposed framework consisted of two fully convolutional network (FCN) models, i.e., a shallow FCN and an extra deep multi-scale FCN (M-FCN). The first shallow FCN rapidly located the fetal brain and extracted the region of interest (ROI) containing the brain. Then, within the brain ROI, the M-FCN further refined the segmentation and produced the final brain mask by leveraging the multi-scale information and residual learning blocks. Dilated convolutional layers were employed in both FCNs to control the size of feature maps and increase the field of view.
Result: Eighty-eight 2D fetal MRIs were collected for experiments. We compared our method with the state-of-the-art methods on extracting fetal brains. It has been evaluated that our proposed framework outperformed the other methods in both fetal brain localization and segmentation tasks. With the proposed method, we located the fetal brain with an accuracy of 100%. The brain segmentation performance was measured based on the overlap between the automatic segmentations and the manual segmentations. Our proposed method achieved an average of 0.958 Dice score, 0.950 sensitivity rate, and 0.968 precision on the testing dataset, and it took an average of 6 s to process one fetal MRI stack on a work-station with TITAN X GPU and i7-6700 CPU.
Conclusion: In this paper, we proposed an effective and efficient deep learning framework for automatic fetal brain extraction from fetal MRI. It has been validated with solid experiments that the proposed method can be used as a practical and useful tool in clinical practice and neuroscience research. (C) 2019 Published by Elsevier B.V.","Fetal MRI,Brain extraction,Fully connected network,Deep learning,Residual learning block,Segmentation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"SEGMENTATION,IMAGES,ATLAS,HASTE",NEUROCOMPUTING,,
71,Streaking artifacts suppression for cone-beam computed tomography with the residual learning in neural network,378,,65-78,"Yang Fuqiang,Zhang Dinghua,Zhang Hua,Huang Kuidong,Du You,Teng Mingxuan","Yang FQ,Zhang DH,Zhang H,Huang KD,Du Y,Teng MX",Yang FQ; Huang KD,10.1016/j.neucom.2019.09.087,Northwestern Polytechnical University,"This study aims to address and test a new residual learning algorithm in neural network applied to the projection data to generate high qualified imaging by reducing the streaking artifacts in cone-beam computed tomography (CBCT). Since the streaking artifacts have a large relationship with the noise on the projection, a residual objective upon Poisson noise corresponding to the image was proposed. As the prior, the convolution neural network (CNN) was constructed to residual learning based on the simulated label and exploited to eliminate the artifacts in the slice. To illustrate the robustness and applicability of CNN, the proposed method is evaluated using CBCT images. For the simulated projection, the PSNR and SSIM of the proposed method were dramatically increased by 15.4% and 85.9% of that with raw projection; for the true projection, the PSNR and SSIM were increased by 14.9% and 56.2%, respectively. Study results show effective results, and the proposed method is practical and attractive as a preferred solution to CT streaking artifacts suppression. (C) 2019 Elsevier B.V. All rights reserved.","Streaking artifact,Convolution neural network,Residual learning,Computed tomography",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"VIEW,IMAGE-RECONSTRUCTION,RAY,CT,RECONSTRUCTION,LOW-DOSE,CT,DEEP,PICCS",NEUROCOMPUTING,,
72,,,,,,,,,,,,,,,,,,,,
73,,,,,,,,,,,,,,,,,,,,
74,Establish an In Vitro Cell Model to Explore the Impacts of UVA on Human Corneal Endothelial Wound Healing,45,9,1065-1073,"Jiang Guo-Jian,Li Ying,You Xin-Guo,Fan Ting-Jun","Jiang GJ,Li Y,You XG,Fan TJ",Fan TJ,10.1080/02713683.2020.1718166,Ocean University of China,"Purpose: To provide scientific data for clinical practice in making strategies for accelerating corneal endothelial wound healing, we investigated the impact of UVA on the corneal endothelial wound healing process and the underlying mechanism using an in vitro cell model. Materials and methods: An in vitro cell model for corneal endothelial wound healing was established by scratching the in vitro cultured human corneal endothelial cell (HCEnC) confluent layer. Then, we investigated the impacts of UVA irradiation and Ascorbic acid-2-phosphate (Asc-2p) on the wound healing process of the in vitro HCEnC model by examining wound-healing index, F-actin(+) rate, Ki-67(+) rate, and ROS production. Results: After scratching, the Ki-67(+) and F-actin(+) HCEnCs occupied the scratching gap. Furthermore, the F-actin(+) rates were significantly higher than Ki-67(+) rates in the wound closure area. After irradiated with UVA, the wound-healing indexes, Ki-67(+) rates and F-actin(+) rates of the wound-healing model significantly reduced, whereas the ROS production significantly increased in a dose-dependent manner. Pretreatment with Asc-2p significantly reduced the ROS production as well as increased the wound-healing indexes, Ki-67(+)rates and F-actin(+) rates of the UVA irradiated wound-healing model. Conclusion: The migration of HCEnC plays a major role in the wound healing process of the established cell model, which is like the wound healing process in vivo. UVA decreases the wound closure of the in vitro HCEnC model dose-dependently, while antioxidant Asc-2p can attenuate the damage to UVA to HCEnCs probably via reducing ROS to improve their migration.","Human corneal endothelial cell,wound healing,UVA,ascorbic acid-2-phosphate,In vitro cell model",Article,"TAYLOR & FRANCIS INC, 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA",Ophthalmology,,2.439,"HEPATOCYTE,GROWTH-FACTOR,ASCORBIC-ACID,REDOX,REGULATION,MIGRATION,PROLIFERATION,ROS,KERATOPLASTY,DEATH",CURRENT EYE RESEARCH,,
75,Detecting self-paced walking intention based on fNIRS technology for the development of BCI,58,5,933-941,"Li Chunguang,Xu Jiacheng,Zhu Yufei,Kuang Shaolong,Qu Wei,Sun Lining","Li CG,Xu JC,Zhu YF,Kuang SL,Qu W,Sun LN",Zhu YF; Kuang SL,10.1007/s11517-020-02140-w,Suzhou University,"Since more and more elderly people suffer from lower extremity movement problems, it is of great social significance to assist persons with motor dysfunction to walk independently again and reduce the burden on caregivers. The self-paced walking intention, which could increase the ability of self-control on the start and stop of motion, was studied by applying brain-computer interface (BCI) technology, a novel research field. The cerebral hemoglobin signal, which was obtained from 30 subjects by applying functional near-infrared spectroscopy (fNIRS) technology, was processed to detect self-paced walking intention in this paper. Teager-Kaiser energy was extracted at each sampling point for five sub-bands (0.0095 similar to 0.021 Hz, 0.021 similar to 0.052 Hz, 0.052 similar to 0.145 Hz, 0.145 similar to 0.6 Hz, and 0.6 similar to 2.0 Hz). Gradient boosting decision tree (GBDT) was then utilized to establish the detecting model in real-time. The proposed method had a good performance to detect the walking intention and passed the pseudo-online test with a true positive rate of 100% (80/80), a false positive rate of 2.91% (4822/165171), and a detection latency of 0.39 +/- 1.06 s. GBDT method had an area under the curve value of 0.944 and was 0.125 (p < 0.001) higher than linear discriminant analysis (LDA). The results reflected that it is feasible to decode self-paced walking intention by applying fNIRS technology. This study lays a foundation for applying fNIRS-based BCI technology to control walking assistive devices practically.","Brain-computer interface,Functional near-infrared spectroscopy,Self-paced walking intention,Gradient boosting decision tree",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"CLASSIFICATION,ATTENTION,MOVEMENT",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
76,A combination of 3-D discrete wavelet transform and 3-D local binary pattern for classification of mild cognitive impairment,20,1,,"Bhasin Harsh,Agrawal Ramesh Kumar","Bhasin H,Agrawal RK",Bhasin H,10.1186/s12911-020-1055-x,"Jawaharlal Nehru University, New Delhi","Background The detection of Alzheimer's Disease (AD) in its formative stages, especially in Mild Cognitive Impairments (MCI), has the potential of helping the clinicians in understanding the condition. The literature review shows that the classification of MCI-converts and MCI-non-converts has not been explored profusely and the maximum classification accuracy reported is rather low. Thus, this paper proposes a Machine Learning approach for classifying patients of MCI into two groups one who converted to AD and the others who are not diagnosed with any signs of AD. The proposed algorithm is also used to distinguish MCI patients from controls (CN). This work uses the Structural Magnetic Resonance Imaging data. Methods This work proposes a 3-D variant of Local Binary Pattern (LBP), called LBP-20 for extracting features. The method has been compared with 3D-Discrete Wavelet Transform (3D-DWT). Subsequently, a combination of 3D-DWT and LBP-20 has been used for extracting features. The relevant features are selected using the Fisher Discriminant Ratio (FDR) and finally the classification has been carried out using the Support Vector Machine. Results The combination of 3D-DWT with LBP-20 results in a maximum accuracy of 88.77. Similarly, the proposed combination of methods is also applied to distinguish MCI from CN. The proposed method results in the classification accuracy of 90.31 in this data. Conclusion The proposed combination is able to extract relevant distribution of microstructures from each component, obtained with the use of DWT and thereby improving the classification accuracy. Moreover, the number of features used for classification is significantly less as compared to those obtained by 3D-DWT. The performance of the proposed method is measured in terms of accuracy, specificity and sensitivity and is found superior in comparison to the existing methods. Thus, the proposed method may contribute to effective diagnosis of MCI and may prove advantageous in clinical settings.","Mild cognitive impairments,Machine learning,3D discrete wavelet transform,3D local binary pattern,Magnetic resonance imaging",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Medical Informatics,,3.394,"ALZHEIMERS-DISEASE,FEATURE,REPRESENTATION,FEATURE-SELECTION,MRI,TEXTURE,SEGMENTATION,HIPPOCAMPUS,PREDICTION,DIAGNOSIS,DEMENTIA",BMC MEDICAL INFORMATICS AND DECISION MAKING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7035729,
77,Image denoising with conditional generative adversarial networks (CGAN) in low dose chest images,954,,,"Kim Hee-Joung,Lee Donghoon","Kim HJ,Lee D",Kim HJ,10.1016/j.nima.2019.02.041,Yonsei University,"Recently, low-dose medical imaging attracts a significant interest owing to the harmfulness of ionized radiations including X-rays. However, when the radiation dose is reduced during the medical image acquisition process, a significant quantum noise is commonly generated. The purpose of this study is to develop a deep-learning-based image-denoising method for low-dose chest imaging, which is a commonly performed medical imaging for diagnosis. Conditional generative adversarial networks (CGANs) were used in the development of the denoising algorithm. In order to train the deep-learning model, we used the SPIE American-Association-of-Physicists-in-Medicine lung-CT-challenge, and Lung-Image-Database-Consortium and Image-Database-Resource-Initiative databases. The obtained image demonstrated that the proposed method achieved an excellent image quality by removing the noise component. Compared with conventional denoising algorithms such as the total-variation (TV) minimization and non-local means (NLM), the proposed method exhibited a superior quality of the obtained images. Losses of image information, detrimental in medical diagnoses, occurred in the medical images obtained using conventional denoising algorithms. Unlike the conventional denoising algorithms, the proposed algorithm restored the corrupted image resolution owing to image noise. The quantitative evaluation through structure similarity index measure (SSIM) demonstrated the superiority of the proposed method over the conventional methods. The SSIM of the proposed method was improved by 1.5 and 2.5 times, compared to those of the NLM and TV methods, respectively. Therefore, we developed a denoising algorithm for medical imaging with CGAN, which is one of the latest deep-learning structures, for low-dose chest images. The proposed denoising method is expected to contribute to the improvement of image quality and reduction of the patient dose.","Conditional generative adversarial network,Medical imaging,Image noise",Article; Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Nuclear Science & Technology,Physics",,1.502,"RADIATION,CT,QUALITY,TOMOSYNTHESIS,ANGIOGRAPHY,ALGORITHM,FILTER,NOISE",NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT,,
78,,,,,,,,,,,,,,,,,,,,
79,An artificial neural network-based non-destructive microwave technique for monitoring fluoride contamination in water,34,5,612-622,"Mathur Parul,Thakur Amrita,Kurup Dhanesh G.","Mathur P,Thakur A,Kurup DG",Mathur P,10.1080/09205071.2020.1729253,Amrita Vishwa Vidyapeetham,"This article presents a novel non-destructive microwave technique for predicting fluoride contamination in pure water. The proposed microwave-based sensing technique uses an open-ended coaxial probe (OECP) microwave sensor for monitoring fluoride concentration in water. The sensor output is the input of Artificial Neural Network (ANN) for predicting the complex dielectric constant of contaminated water, which has direct correlation with fluoride contamination in water. The ANN is trained through analytically generated sensor output for various lossy liquid materials and tested for experimental data obtained through laboratory prepared samples. Hence, the proposed technique has the capability to compute the amount of fluoride contamination faster, when compared to analysis only method. The results shows that a well-trained ANN is computationally efficient and capable of predicting the amount of fluoride level in the pure water. The results also has good agreement with the data published in the literature at room temperature.","Artificial neural network,fluoride contamination,open-ended coaxial probe sensor,near-field plane wave spectrum theory",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Engineering,Physics",,1.193,"LOW-COST,PERMITTIVITY,SENSOR,CALIBRATION,CRACKS",JOURNAL OF ELECTROMAGNETIC WAVES AND APPLICATIONS,,
80,Multi-view convolutional neural network with leader and long-tail particle swarm optimizer for enhancing heart disease and breast cancer detection,32,19,15469-15488,"Lan Kun,Liu Liansheng,Li Tengyue,Chen Yuhao,Fong Simon,Marques Joao Alexandre Lobo,Wong Raymond K.,Tang Rui","Lan K,Liu LS,Li TY,Chen YH,Fong S,Marques JAL,Wong RK,Tang R",Tang R,10.1007/s00521-020-04769-y,Kunming University of Science & Technology,"As the core of deep learning methodologies, convolutional neural network (CNN) has received wide attention in the area of image recognition. In particular, it requires very precise, accurate and fine recognition power for medical imaging processing. Numerous promising prospects of CNN applications with medical prognosis and diagnosis have been reported in the related works, and the common goal among the literature is mainly to analyze the insights from the finest details of medical images and build a more suitable model with maximum accuracy and minimum error. Thus, a novel CNN model is proposed with the characteristics of multi-view feature preprocessing and swarm-based parameter optimization. Additional information of extra features from multi-view is discovered potentially for training, and simultaneously, the most optimal set of CNN parameters are provided by our proposed leader and long-tail-based particle swarm optimization. The purpose of such a hybrid method is to achieve the highest possibility of target recognition in medical images. Preliminary experiments over cardiovascular and mammogram datasets related to heart disease prediction and breast cancer classification, respectively, are designed and conducted, and the results indicate encouraging performance compared to other existing CNN model optimization methods.","Convolutional neural network,Leader and long-tail,Particle swarm optimization,Parameter optimization,Heart disease,Breast cancer",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"LEFT-VENTRICLE,SEGMENTATION,COMPUTER-AIDED,DETECTION,CLASSIFICATION,MASS",NEURAL COMPUTING & APPLICATIONS,,
81,Towards enhanced information transfer rate: a comparative study based on classification techniques,8,4,446-457,"Katyal Akshay,Singla Rajesh","Katyal A,Singla R",Katyal A,10.1080/21681163.2020.1727775,National Institute of Technology (NIT System),"One of the most important performance parameters for Assistive Devices (AD's) based on Brain Computer Interfaces (BCIs) is the Information Transfer Rate (ITR). This study compares a hybrid BCI to a Steady State Visually Evoked Potential (SSVEP) based BCI, along with a comparison of classification techniques used for translation of user intentions. The hybrid BCI paradigm combined SSVEP & P300, where SSVEP decodes user intentions and P300 is used for Time Division Multiplexing (TDM). The classification protocols were categorised as single-step supervised classifiers and two-step unsupervised classifier. It was observed that the classification accuracy for translation of human intentions for the traditional SSVEP paradigm (93.78%) was higher than the hybrid BCI (90.76%) proposed, but still the hybrid BCI is paradigm option for development of ADs (high ITR of 81.10 bits/minute). The study compared the two classification protocols using the statistical t-value test, which concluded that (99.9% confidence level) the mean classification accuracy and mean ITR were greater for the single-step supervised classification and also that the mean FAR was lower for the single-step supervised classification. The proposed hybrid BCI with single-step supervised learning classification protocol emerged as best BCI option for the development of AD's.","BCI,P300,SSVEP,hybrid BCI,ITR,SVM",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,,"BRAIN-COMPUTER,INTERFACE,COMMUNICATION,PARADIGM",COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION,,
82,A combination of CSP-based method with soft margin SVM classifier and generalized RBF kernel for imagery-based brain computer interface applications,79,25-26,17521-17549,"Hekmatmanesh Amin,Wu Huapeng,Jamaloo Fatemeh,Li Ming,Handroos Heikki","Hekmatmanesh A,Wu HP,Jamaloo F,Li M,Handroos H",Hekmatmanesh A,10.1007/s11042-020-08675-2,Lappeenranta University of Technology,"Several methods utilizing common spatial pattern (CSP) algorithm have been presented for improving the identification of imagery movement patterns for brain computer interface applications. The present study focuses on improving a CSP-based algorithm for detecting the motor imagery movement patterns. A discriminative filter bank of CSP method using a discriminative sensitive learning vector quantization (DFBCSP-DSLVQ) system is implemented. Four algorithms are then combined to form three methods for improving the efficiency of the DFBCSP-DSLVQ method, namely the kernel linear discriminant analysis (KLDA), the kernel principal component analysis (KPCA), the soft margin support vector machine (SSVM) classifier and the generalized radial bases functions (GRBF) kernel. The GRBF is used as a kernel for the KLDA, the KPCA feature selection algorithms and the SSVM classifier. In addition, three types of classifiers, namely K-nearest neighbor (K-NN), neural network (NN) and traditional support vector machine (SVM), are employed to evaluate the efficiency of the classifiers. Results show that the best algorithm is the combination of the DFBCSP-DSLVQ method using the SSVM classifier with GRBF kernel (SSVM-GRBF), in which the best average accuracy, attained are 92.70% and 83.21%, respectively. Results of the Repeated Measures ANOVA shows the statistically significant dominance of this method at p < 0.05. The presented algorithms are then compared with the base algorithm of this study i.e. the DFBCSP-DSLVQ with the SVM-RBF classifier. It is concluded that the algorithms, which are based on the SSVM-GRBF classifier and the KLDA with the SSVM-GRBF classifiers give sufficient accuracy and reliable results.","Brain computer interface,Common spacial pattern (CSP),Kernel linear discriminator analysis (KLDA),Kernel principal component analysis (KPCA),Generalized radial basis function (GRBF),Soft margin support vector machine (SSVM)",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"SPATIAL-PATTERN,METHOD,DISCRIMINANT-ANALYSIS,PCA,EEG,MACHINE,FILTERS",MULTIMEDIA TOOLS AND APPLICATIONS,https://link.springer.com/content/pdf/10.1007/s11042-020-08675-2.pdf,
83,Closed-loop optimization of fast-charging protocols for batteries with machine learning,578,7795,397-+,"Attia Peter M.,Grover Aditya,Jin Norman,Severson Kristen A.,Markov Todor M.,Liao Yang-Hung,Chen Michael H.,Cheong Bryan,Perkins Nicholas,Yang Zi","Attia PM,Grover A,Jin N,Severson KA,Markov TM,Liao YH,Chen MH,Cheong B,Perkins N,Yang Z",Chueh WC,10.1038/s41586-020-1994-5,Stanford University,"Simultaneously optimizing many design parameters in time-consuming experiments causes bottlenecks in a broad range of scientific and engineering disciplines(1,2). One such example is process and control optimization for lithium-ion batteries during materials selection, cell manufacturing and operation. A typical objective is to maximize battery lifetime; however, conducting even a single experiment to evaluate lifetime can take months to years(3-5). Furthermore, both large parameter spaces and high sampling variability(3,6,7) necessitate a large number of experiments. Hence, the key challenge is to reduce both the number and the duration of the experiments required. Here we develop and demonstrate a machine learning methodology to efficiently optimize a parameter space specifying the current and voltage profiles of six-step, ten-minute fast-charging protocols for maximizing battery cycle life, which can alleviate range anxiety for electric-vehicle users(8,9). We combine two key elements to reduce the optimization cost: an early-prediction model(5), which reduces the time per experiment by predicting the final cycle life using data from the first few cycles, and a Bayesian optimization algorithm(10,11), which reduces the number of experiments by balancing exploration and exploitation to efficiently probe the parameter space of charging protocols. Using this methodology, we rapidly identify high-cycle-life charging protocols among 224 candidates in 16 days (compared with over 500 days using exhaustive search without early prediction), and subsequently validate the accuracy and efficiency of our optimization approach. Our closed-loop methodology automatically incorporates feedback from past experiments to inform future decisions and can be generalized to other applications in battery design and, more broadly, other scientific domains that involve time-intensive experiments and multi-dimensional design spaces.","LITHIUM-ION BATTERIES,EXPERIMENTAL-DESIGN,CYCLE LIFE,IMPACT",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,54.637,"LITHIUM-ION,BATTERIES,EXPERIMENTAL-DESIGN,CYCLE,LIFE,IMPACT",NATURE,https://www.osti.gov/biblio/1647088,
84,Automatic corneal nerve fiber segmentation and geometric biomarker quantification,135,2,,"Zhang Dan,Huang Fan,Khansari Maziyar,Berendschot Tos T. J. M.,Xu Xiayu,Dashtbozorg Behdad,Sun Yue,Zhang Jiong,Tan Tao","Zhang D,Huang F,Khansari M,Berendschot TTJM,Xu XY,Dashtbozorg B,Sun Y,Zhang J,Tan T",Tan T,10.1140/epjp/s13360-020-00127-y,Eindhoven University of Technology,"Geometric and topological features of corneal nerve fibers in confocal microscopy images are important indicators for the diagnosis of common diseases such as diabetic neuropathy. Quantitative analysis of these important biomarkers requires an accurate segmentation of the nerve fiber network. Currently, most of the analysis are performed based on manual annotations of the nerve fiber segments, while a fully automatic corneal nerve fiber extraction and analysis framework is still needed. In this paper, we establish a fully convolutional network method to precisely enhance and segment corneal nerve fibers in microscopy images. Based on the segmentation results, automatic tortuosity measurement and branching detection modules are established to extract valuable geometric and topological biomarkers. The proposed segmentation method is validated on a dataset with 142 images. The experimental results show that our deep learning-based framework outperforms state-of-the-art segmentation approaches. The biomarker extraction methods are validated on two different datasets, demonstrating high effectiveness and reliability of the proposed methods.","CONFOCAL-MICROSCOPY,DIABETIC-RETINOPATHY,DIAGNOSIS,TORTUOSITY,IMAGES,DAMAGE",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Physics,,3.304,"CONFOCAL-MICROSCOPY,DIABETIC-RETINOPATHY,DIAGNOSIS,TORTUOSITY,IMAGES,DAMAGE",EUROPEAN PHYSICAL JOURNAL PLUS,https://pure.tue.nl/ws/files/148162914/Zhang2020_Article_AutomaticCornealNerveFiberSegm.pdf,
85,"Machine hermeneutics, postphenomenology, and facial recognition technology",,,,Hongladarom Soraj,Hongladarom S,Hongladarom S,10.1007/s00146-020-00951-x,Chulalongkorn University,"I would like to introduce the notion of machine hermeneutics in this paper. The notion refers to hermeneutical activity performed by machines. Machines are now capable of making the very interpretive tasks, using artificial intelligence algorithms based on the technology of machine learning that used to be the exclusive domain of human beings. In making this claim, I am not talking about possible conscious machines of the future, but those existing here and now. With facial recognition algorithms, for example, machines are now performing routinely what must be regarded as hermeneutical analyses with astounding accuracy and power. Thus, machine hermeneutics supplements Don Ihde's notion of material hermeneutics. In the latter, it is still human beings who do the interpretation, through the lenses provided the natural sciences; in this case, the natural sciences, or the technology afforded by the sciences, intervene between the human being and the world. In machine hermeneutics, on the contrary, the intervening comes in two layers. On the one hand, there is the usual intervention that Ihde talks about, but on the other, the artificial intelligence algorithm performs its own kind of intervention and interpretation, presenting an already interpreted result to the human beings, who then perceive it through the aid of the usual intervention such as the normal eyeglasses. Then the paper discusses the problem of how to justify the kind of perception that undergoes this process. In what sense can it be said that the algorithm is performing the right action, i.e., one such that the process comes up with a right picture of the world? I contend that this does not merely consist of technical excellence for the technology involved, but also ethical excellence. The two cannot be considered one apart from the other.","Machine hermeneutics,Perception,Don Ihde,Artificial intelligence",Article; Early Access,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,,,AI & SOCIETY,,
86,An Optimized Integrated Framework of Big Data Analytics Managing Security and Privacy in Healthcare Data,117,1,87-108,"Chauhan Ritu,Kaur Harleen,Chang Victor","Chauhan R,Kaur H,Chang V",Kaur H,10.1007/s11277-020-07040-8,Jamia Hamdard University,"Big data analytics has anonymously changed the overall global scenario to discover knowledge trends for future decision making. In general, potential area of big data application tends to be healthcare, where the global burden is to improve patient diagnostic system and providing patterns to assure the privacy of the end users. However, data constraints exists on real data which needs to be accessed while preserving the security of patients for further diagnostic analysis. This advancement in big data needs to addressed where the patient right needs to maintained while the disclosure of knowledge discovery for future needs are also addressed. To, embark and acknowledge the big data environment its adherently important to determine the cutting-edge research which can benefit end users and healthcare practioners to discover overall prognosis and diagnosis of disease while maintaining the concerns for privacy and security of patient data. In current state of art, we tried to address the big data analytics approach while maintain privacy of healthcare databases for future knowledge discovery. The current objective was to design and develop a novel framework which can integrate the big data with privacy and security concerns and determine knowledgably patterns for future decision making. In the current study we have utilized big data analytical technique for patients suffering from Human Immunodeficiency Virus (HIV) and Tuberculosis (TB) coinfection to develop trends and detect patterns with socio economic factors. Further, a novel framework was implemented using unsupervised learning technique in STATA and MATLAB 7.1 to develop patterns for knowledge discovery process while maintain the privacy and security of data. The study overall can benefit end users to predict future prognosis of disease and combinatorial effects to determining varied policies which can assist patients with needs.","Big data,Big data analytics,Security and privacy,Healthcare databases",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Telecommunications,,1.369,DECISION-SUPPORT-SYSTEMS,WIRELESS PERSONAL COMMUNICATIONS,,
87,,,,,,,,,,,,,,,,,,,,
88,Comparison of statistical machine learning models for rectal protocol compliance in prostate external beam radiation therapy,47,4,1452-1459,"Jones Scott,Hargrave Catriona,Deegan Timothy,Holt Tanya,Mengersen Kerrie","Jones S,Hargrave C,Deegan T,Holt T,Mengersen K",Jones S,10.1002/mp.14044,"Radiat Oncol Princess Alexandra Hosp, Raymond Terrace, Brisbane, Qld 4101, Australia.","Purpose Limiting the dose to the rectum can be one of the most challenging aspects of creating a dosimetric external beam radiation therapy (EBRT) plan for prostate cancer treatment. Rectal sparing devices such as hydrogel spacers offer the prospect of increased space between the prostate and rectum, causing reduced rectal dose and potentially reduced injury. This study sought to help identify patients at higher risk of developing rectal injury based on estimated rectal dosimetry compliance prior to the EBRT simulation and planning procedure. Three statistical machine learning methods were compared for their ability to predict rectal dose outcomes with varied classification thresholds applied.
Methods Prostate cancer patients treated with conventionally fractionated EBRT to a reference dose of 74-78 Gy were invited to participate in the study. The dose volume histogram data from each dosimetric plan was used to quantify planned rectal volume receiving 50%, 83% 96%, and 102% of the reference dose. Patients were classified into two groups for each of these dose levels: either meeting tolerance by having a rectal volume less than a clinically acceptable threshold for the dose level (Y) or violating the tolerance by having a rectal volume greater than the threshold for the dose level (N). Logistic regression, classification and regression tree, and random forest models were compared for their ability to discriminate between class outcomes. Performance metrics included area under the receiver operator characteristic curve (AUC), sensitivity, specificity, positive predictive value and negative predictive value. Finally, three classification threshold levels were evaluated for their impact on model performance.
Results A total of 176 eligible participants were recruited. Variable importance differed between model methods. Area under the receiver operator characteristic curve performance varied greatly across the different rectal dose levels and between models. Logistic regression performed best at the 83% reference dose level with an AUC value of 0.844, while random forest demonstrated best discrimination at the 96% reference dose level with an AUC value of 0.733. In addition to the standard classification probability threshold of 50%, the clinically representative threshold of 10%, and the best threshold from each AUC plot was applied to compare metrics. This showed that using a 50% threshold and the best threshold from the AUC plots yields similar results. Conversely, applying the more conservative clinical threshold of 10% maximized the sensitivity at V83_RD and V96_RD for all model types. Based on the combination of the metrics, logistic regression would be the recommendation for rectal protocol compliance prediction at the 83% reference dose level, and random forest for the 96% reference dose level, particularly when using the clinical probability threshold of 10%.
Conclusions This study demonstrated the efficacy of statistical machine learning models on rectal protocol compliance prediction for prostate cancer EBRT dosimetric planning. Both logistic regression and random forest modeling approaches demonstrated good discriminative ability for predicting class outcomes in the upper dose levels. Application of a conservative clinical classification threshold maximized sensitivity and further confirmed the value of logistic regression and random forest models over classification and regression tree.","machine learning,prostate cancer,radiation therapy,rectal dose",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"CANCER,RADIOTHERAPY,HYDROGEL,INJECTION,PREDICTION,MODELS,TOXICITY,DECISION,SPACER,DOSIMETRY",MEDICAL PHYSICS,,
89,GAN and dual-input two-compartment model-based training of a neural network for robust quantification of contrast uptake rate in gadoxetic acid-enhanced MRI,47,4,1702-1712,"Simeth Josiah,Cao Yue","Simeth J,Cao Y",Simeth J,10.1002/mp.14055,University of Michigan System,"Purpose Gadoxetic acid uptake rate (k(1)) obtained from dynamic, contrast-enhanced (DCE) magnetic resonance imaging (MRI) is a promising measure of regional liver function. Clinical exams are typically poorly temporally characterized, as seen in a low temporal resolution (LTR) compared to high temporal resolution (HTR) experimental acquisitions. Meanwhile, clinical demands incentivize shortening these exams. This study develops a neural network-based approach to quantitation of k(1), for increased robustness over current models such as the linearized single-input, two-compartment (LSITC) model.
Methods Thirty Liver HTR DCE MRI exams were acquired in 22 patients with at least 16 min of postcontrast data sampled at least every 13 s. A simple neural network (NN) with four hidden layers was trained on voxel-wise LTR data to predict k(1). Low temporal resolution data were created by subsampling HTR data to contain six time points, replicating the characteristics of clinical LTR data. Both the total length and the placement of points in the training data were varied considerably to encourage robustness to variation. A generative adversarial network (GAN) was used to generate arterial and portal venous inputs for use in data augmentation based on the dual-input, two-compartment, pharmacokinetic model of gadoxetic acid in the liver. The performance of the NN was compared to direct application of LSITC on both LTR and HTR data. The error was assessed when subsampling lengths from 16 to 4 min, enabling assessment of robustness to acquisition length.
Results For acquisition lengths of 16 min NRMSE (Normalized Root-Mean-Squared Error) in k(1) was 0.60, 1.77, and 1.21, for LSITC applied to HTR data, LSITC applied to LTR data, and GAN-augmented NN applied to LTR data, respectively. As the acquisition length was shortened, errors greatly increased for LSITC approaches by several folds. For acquisitions shorter than 12 min the GAN-augmented NN approach outperformed the LSITC approach to a statistically significant extent, even with HTR data.
Conclusions The study indicates that data length is significant for LSITC analysis as applied to DCE data for standard temporal sampling, and that machine learning methods, such as the implemented NN, have potential for much greater resilience to shortened acquisition time than directly fitting to the LSITC model.","GAN,liver function,quantitative imaging",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"GD-EOB-DTPA,LIVER-FUNCTION,HEPATOCELLULAR-CARCINOMA,PERFUSION,PREDICTION,DIAGNOSIS",MEDICAL PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7337040,
90,Quenching Thermal Transport in Aperiodic Superlattices: A Molecular Dynamics and Machine Learning Study,12,7,8795-8804,"Chakraborty Pranay,Liu Yida,Ma Tengfei,Guo Xixi,Cao Lei,Hu Run,Wang Yan","Chakraborty P,Liu YD,Ma TF,Guo XX,Cao L,Hu R,Wang Y",Hu R,10.1021/acsami.9b18084,Huazhong University of Science & Technology,"Random multilayer (RML) structures, or aperiodic superlattices, can localize coherent phonons and therefore exhibit drastically reduced lattice thermal conductivity compared to their superlattice counterparts. The optimization of RML structures is essential for obtaining ultralow thermal conductivity, which is critical for various applications such as thermoelectrics and thermal barrier coatings. A higher degree of disorder in RMLs will lead to stronger phonon localization and, correspondingly, a lower lattice thermal conductivity. In this work, we identified several essential parameters for quantifying the disorder in layer thicknesses of RMLs. We were able to correlate these disorder parameters with thermal conductivity, as confirmed by classical molecular dynamics simulations of conceptual Lennard-Jones RMLs. Moreover, we have shown that these parameters are effective as features for physics-based machine learning models to predict the lattice thermal conductivity of RMLs with improved accuracy and efficiency.","superlattice,random multilayer,localization,disorder,lattice thermal conductivity,molecular dynamics,machine learning",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science",,9.57,"THERMOELECTRIC-MATERIALS,CONDUCTIVITY,FIGURE,LOCALIZATION,ENHANCEMENT,PERFORMANCE,MERIT,BULK",ACS APPLIED MATERIALS & INTERFACES,,
91,"Assessment of Reproducibility, Hysteresis, and Stability Relations in Perovskite Solar Cells Using Machine Learning",8,12,,"Odabasi Cagla,Yildirim Ramazan","Odabasi C,Yildirim R",Yildirim R,10.1002/ente.201901449,Bogazici University,"Herein, the hysteresis and reproducibility of perovskite solar cells and their relations with power conversion efficiency and long-term stability are analyzed using machine learning tools. A hysteresis dataset containing 387 cells from 194 articles in the literature is constructed and analyzed using association rule mining, while the reproducibility is analyzed using the pooled variance of 24 142 cells from 438 articles. It is found that mixed cation perovskites, two-step spin coating or multiple spin coating in one step, dimethylformamide + dimethyl sulfoxide as precursor solution, poly[bis(4-phenyl)(2,4,6-trimethylphenyl)amine as hole transport layer (HTL), lithium bis(trifluoromethanesulfonyl)imide + 4-tert-butylpyridine + tris(2-(1H-pyrazol-1-yl)-4-tert-butylpyridine) cobalt(III) as HTL dopant, and carbon as back contact are found to be beneficial for both low hysteresis and high reproducibility in regular (n-i-p) cells. In addition to the perovskite material and deposition techniques mentioned earlier, the toluene as antisolvent, bathocuproine as electron transport layer interlayer, and Ag as back contact are found to have positive impacts in inverted (p-i-n) cells. It is also found that those factors are also highly relevant for power conversion efficiency and stability, clearly relating these four most commonly discussed performance measures for perovskite cells.","hysteresis,long-term stability,machine learning,perovskite solar cells,reproducibility",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Energy & Fuels,,3.727,"HIGH-PERFORMANCE,V,HYSTERESIS,EFFICIENCY,CH3NH3PBI3,DEPOSITION,LAYER,TIO2",ENERGY TECHNOLOGY,,
92,Al-Assisted Exploration of Superionic Glass-Type Li+ Conductors with Aromatic Structures,142,7,3301-3305,"Hatakeyama-Sato Kan,Tezuka Toshiki,Umeki Momoka,Oyaizu Kenichi","Hatakeyama-Sato K,Tezuka T,Umeki M,Oyaizu K",Oyaizu K,10.1021/jacs.9b11442,Waseda University,"It has long remained challenging to predict the properties of complex chemical systems, such as polymer-based materials and their composites. We have constructed the largest database of lithium-conducting solid polymer electrolytes (10(4) entries) and employed a transfer-learned graph neural network to accurately predict their conductivity (mean absolute error of less than 1 on a logarithmic scale). The bias-free prediction by the network helped us to find superionic conductors composed of charge-transfer complexes of aromatic polymers (ionic conductivity of around 10(-3) S/cm at room temperature). The glassy design was contrary to the traditional concept of rubbery polymer electrolytes, but it was found to be appropriate to achieve fast, decoupled motion of ionic species from polymer chains and to enhance thermal and mechanical stability. The unbiased suggestions generated by machine learning models can help researches to discover unexpected chemical phenomena, which could also induce a paradigm shift of energy-related functional materials.","ELECTROLYTES,CONDUCTIVITY,TRANSPORT",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,15.801,"ELECTROLYTES,CONDUCTIVITY,TRANSPORT",JOURNAL OF THE AMERICAN CHEMICAL SOCIETY,,
93,"Atomic structures and orbital energies of 61,489 crystal-forming organic molecules",7,1,,"Stuke Annika,Kunkel Christian,Golze Dorothea,Todorovic Milica,Margraf Johannes T.,Reuter Karsten,Rinke Patrick,Oberhofer Harald","Stuke A,Kunkel C,Golze D,Todorovic M,Margraf JT,Reuter K,Rinke P,Oberhofer H",Stuke A,10.1038/s41597-020-0385-y,Aalto University,"Measurement(s)organic moleculeTechnology Type(s)digital curation center dot spectroscopyFactor Type(s)computational method Machine-accessible metadata file describing the reported data: 10.6084/m9.figshare.11689347
Data science and machine learning in materials science require large datasets of technologically relevant molecules or materials. Currently, publicly available molecular datasets with realistic molecular geometries and spectral properties are rare. We here supply a diverse benchmark spectroscopy dataset of 61,489 molecules extracted from organic crystals in the Cambridge Structural Database (CSD), denoted OE62. Molecular equilibrium geometries are reported at the Perdew-Burke-Ernzerhof (PBE) level of density functional theory (DFT) including van der Waals corrections for all 62 k molecules. For these geometries, OE62 supplies total energies and orbital eigenvalues at the PBE and the PBE hybrid (PBE0) functional level of DFT for all 62 k molecules in vacuum as well as at the PBE0 level for a subset of 30,876 molecules in (implicit) water. For 5,239 molecules in vacuum, the dataset provides quasiparticle energies computed with many-body perturbation theory in the G(0)W(0) approximation with a PBE0 starting point (denoted GW5000 in analogy to the GW100 benchmark set (M. van Setten et al. J. Chem. Theory Comput. 12, 5076 (2016))).","DENSITY-FUNCTIONAL THEORY,COMPUTATIONAL CHEMISTRY,DATABASE,DESIGN,EXCHANGE",Article; Data Paper,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,9.051,"DENSITY-FUNCTIONAL,THEORY,COMPUTATIONAL,CHEMISTRY,DATABASE,DESIGN,EXCHANGE",SCIENTIFIC DATA,https://research.aalto.fi/files/41441228/s41597_020_0385_y.pdf,
94,Whole-Genome Promoter Profiling of Plasma DNA Exhibits Diagnostic Value for Placenta-Origin Pregnancy Complications,7,7,,"Guo Zhiwei,Yang Fang,Zhang Jun,Zhang Zhigang,Li Kun,Tian Qi,Hou Hongying,Xu Cailing,Lu Qianwen,Ren Zhonglu","Guo ZW,Yang F,Zhang J,Zhang ZG,Li K,Tian Q,Hou HY,Xu CL,Lu QW,Ren ZL",Wu YS; Yang XX,10.1002/advs.201901819,Southern Medical University - China,"Placenta-origin pregnancy complications, including preeclampsia (PE), gestational diabetes mellitus (GDM), fetal growth restriction (FGR), and macrosomia (MA) are common occurrences in pregnancy, resulting in significant morbidity and mortality for both mother and fetus. However, despite their frequency, there are no reliable methods for the early diagnosis of these complications. Since cfDNA is mainly derived from placental trophoblasts and maternal hematopoietic cells, it might have information for gene expression which can be used for disease prediction. Here, low coverage whole-genome sequencing on plasma DNA from 2,199 pregnancies is performed based on retrospective cohorts of 3,200 pregnant women. Read depth in the promoter regions is examined to define read-depth distribution patterns of promoters for pregnancy complications and controls. Using machine learning methods, classifiers for predicting pregnancy complications are developed. Using these classifiers, complications are successfully predicted with an accuracy of 80.3%, 78.9%, 72.1%, and 83.0% for MA, FGR, GDM, and PE, respectively. The findings suggest that promoter profiling of cfDNA may be used as a biological biomarker for predicting pregnancy complications at early gestational age.","cell-free DNA,early prediction,pregnancy complications,promoter profiling,whole-genome sequencing",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Chemistry,Science & Technology - Other Topics,Materials Science",,17.835,"CELL-FREE,DNA,GESTATIONAL,DIABETES-MELLITUS,TRANSCRIPTION,FACTOR,RISK-FACTORS,FETAL,DNA,SERUM,PREVALENCE,MACROSOMIA,PREDICTION",ADVANCED SCIENCE,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/advs.201901819,
95,Prediction of transient tumor enlargement using MRI tumor texture after radiosurgery on vestibular schwannoma,47,4,1692-1701,"Langenhuizen Patrick P. J. H.,Sebregts Sander H. P.,Zinger Svetlana,Leenstra Sieger,Verheul Jeroen B.,de With Peter H. N.","Langenhuizen PPJH,Sebregts SHP,Zinger S,Leenstra S,Verheul JB,de With PHN",Langenhuizen PPJH,10.1002/mp.14042,Eindhoven University of Technology,"Purpose Vestibular schwannomas (VSs) are uncommon benign brain tumors, generally treated using Gamma Knife radiosurgery (GKRS). However, due to the possible adverse effect of transient tumor enlargement (TTE), large VS tumors are often surgically removed instead of treated radiosurgically. Since microsurgery is highly invasive and results in a significant increased risk of complications, GKRS is generally preferred. Therefore, prediction of TTE for large VS tumors can improve overall VS treatment and enable physicians to select the most optimal treatment strategy on an individual basis. Currently, there are no clinical factors known to be predictive for TTE. In this research, we aim at predicting TTE following GKRS using texture features extracted from MRI scans.
Methods We analyzed clinical data of patients with VSs treated at our Gamma Knife center. The data was collected prospectively and included patient- and treatment-related characteristics and MRI scans obtained at day of treatment and at follow-up visits, 6, 12, 24 and 36 months after treatment. The correlations of the patient- and treatment-related characteristics to TTE were investigated using statistical tests. From the treatment scans, we extracted the following MRI image features: first-order statistics, Minkowski functionals (MFs), and three-dimensional gray-level co-occurrence matrices (GLCMs). These features were applied in a machine learning environment for classification of TTE, using support vector machines.
Results In a clinical data set, containing 61 patients presenting obvious non-TTE and 38 patients presenting obvious TTE, we determined that patient- and treatment-related characteristics do not show any correlation to TTE. Furthermore, first-order statistical MRI features and MFs did not significantly show prognostic values using support vector machine classification. However, utilizing a set of 4 GLCM features, we achieved a sensitivity of 0.82 and a specificity of 0.69, showing their prognostic value of TTE. Moreover, these results increased for larger tumor volumes obtaining a sensitivity of 0.77 and a specificity of 0.89 for tumors larger than 6 cm(3).
Conclusions The results found in this research clearly show that MRI tumor texture provides information that can be employed for predicting TTE. This can form a basis for individual VS treatment selection, further improving overall treatment results. Particularly in patients with large VSs, where the phenomenon of TTE is most relevant and our predictive model performs best, these findings can be implemented in a clinical workflow such that for each patient, the most optimal treatment strategy can be determined.","Gamma Knife radiosurgery,MRI tumor texture,pseudoprogression,transient tumor enlargement,vestibular schwannomas",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"GAMMA-KNIFE,RADIOSURGERY,STEREOTACTIC,RADIATION-THERAPY,VOLUME,CHANGES,SURGERY,MANAGEMENT,OUTCOMES,FEATURES,GROWTH,BRAIN,PSEUDOPROGRESSION",MEDICAL PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7217023,
96,Controlling the Properties of Additively Manufactured Cellular Structures Using Machine Learning Approaches,22,3,,"Hassanin Hany,Alkendi Yusra,Elsayed Mahmoud,Essa Khamis,Zweiri Yahya","Hassanin H,Alkendi Y,Elsayed M,Essa K,Zweiri Y",Hassanin H,10.1002/adem.201901338,University of Liverpool,"Cellular structures are lightweight-engineered materials that have gained much attention with the development of additive manufacturing technologies. This article introduces a precise approach to predict the mechanical properties of additively manufactured lattice structures using deep-learning approaches. Diamond-shaped nodal lattice structures are designed by varying strut length, strut diameter, and strut orientation angle. The samples are manufactured using laser powder bed fusion (LPBF) of Ti-64 alloy and subjected to compression testing to measure the ultimate strength, elastic modulus, and specific strength. Machine learning approaches such as shallow neural network (SNN), deep neural network (DNN), and deep learning neural network (DLNN) are developed and compared to the statistical design of experiment (DoE) approach. The trained DLNN model show the highest performance when compared with DNN, DoE, and SNN with a mean percentage error of 5.26%, 14.60%, and 9.39% for the ultimate strength, elastic modulus, and specific strength, respectively. The DLNN model is used to create process maps, and is further validated. The results show that although deep learning is preferred for big data, the optimized DLNN model outperform the statistical DoE approach and can be a favorable tool for lattice structure prediction with limited data.","deep learning,lattices,laser powder bed fusion",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Materials Science,,3.746,"LATTICE,STRUCTURES,DESIGN,LITHOGRAPHY,BED",ADVANCED ENGINEERING MATERIALS,https://eprints.kingston.ac.uk/id/eprint/44849/1/Zweiri-Y-44849-AAM-1.pdf,
97,Design of a Machine Learning-Assisted Wearable Accelerometer-Based Automated System for Studying the Effect of Dopaminergic Medicine on Gait Characteristics of Parkinson's Patients,2020,,,"Aich Satyabrata,Pradhan Pyari Mohan,Chakraborty Sabyasachi,Kim Hee-Cheol,Kim Hee-Tae,Lee Hae-Gu,Kim Il Hwan,Joo Moon-il,Jong Seong Sim,Park Jinse","Aich S,Pradhan PM,Chakraborty S,Kim HC,Kim HT,Lee HG,Kim IH,Joo MI,Seong SJ,Park J",Park J,10.1155/2020/1823268,Inje University,"In the last few years, the importance of measuring gait characteristics has increased tenfold due to their direct relationship with various neurological diseases. As patients suffering from Parkinson's disease (PD) are more prone to a movement disorder, the quantification of gait characteristics helps in personalizing the treatment. The wearable sensors make the measurement process more convenient as well as feasible in a practical environment. However, the question remains to be answered about the validation of the wearable sensor-based measurement system in a real-world scenario. This paper proposes a study that includes an algorithmic approach based on collected data from the wearable accelerometers for the estimation of the gait characteristics and its validation using the Tinetti mobility test and 3D motion capture system. It also proposes a machine learning-based approach to classify the PD patients from the healthy older group (HOG) based on the estimated gait characteristics. The results show a good correlation between the proposed approach, the Tinetti mobility test, and the 3D motion capture system. It was found that decision tree classifiers outperformed other classifiers with a classification accuracy of 88.46%. The obtained results showed enough evidence about the proposed approach that could be suitable for assessing PD in a home-based free-living real-time environment.","DISEASE,SENSORS,CLASSIFICATION,RELIABILITY,PARAMETERS",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Health Care Sciences & Services,,,"DISEASE,SENSORS,CLASSIFICATION,RELIABILITY,PARAMETERS",JOURNAL OF HEALTHCARE ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7049429,
98,A review of mammographic region of interest classification,10,5,,"Yengec Tasdemir Sena B.,Tasdemir Kasim,Aydin Zafer","Tasdemir SBY,Tasdemir K,Aydin Z",Aydin Z,10.1002/widm.1357,Abdullah Gul University,"Early detection of breast cancer is important and highly valuable in clinical practice. X-ray mammography is broadly used for prescreening the breast and is also attractive due to its noninvasive nature. However, experts can misdiagnose a significant proportion of the cases, which may either cause redundant examinations or cancer. In order to reduce false positive and negative rates of mammography screening, computer-aided breast cancer detection has been studied for more than 30 years and many methods have been proposed by the researchers. In this review, region of interest (ROI) classification methods, which operate on a predefined or segmented ROIs with a focus on mass classification are surveyed. A total of 72 high quality journal and conference papers are selected from the Web of Science (WOS) database that meet several inclusion criteria. A comparative analysis is provided based on ROI extraction methods, data sets and machine learning techniques employed, the prediction accuracies, and usage frequency statistics. Based on the performances obtained on publicly available data sets, the ROI classification problem from mammogram images can be considered as approaching to be solved. Nonetheless, it can still be used as complementary information in breast cancer detection from the whole mammograms, which has room for improvement.
This article is categorized under:
Application Areas > Science and Technology
Technologies > Machine LearningTechnologies > Classification","breast cancer,computer-aided diagnosis,deep learning,mammogram,region of interest",Review,"WILEY PERIODICALS, INC, ONE MONTGOMERY ST, SUITE 1200, SAN FRANCISCO, CA 94104 USA",Computer Science,,6.686,"FALSE-POSITIVE,REDUCTION,BREAST-CANCER,DIAGNOSIS,COMPUTER-AIDED,DETECTION,DIGITAL,MAMMOGRAMS,DETECTION,SYSTEM,TEXTURE,ANALYSIS,MASSES,FEATURES,IMAGES,MICROCALCIFICATIONS",WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY,,
99,Initial classification of low back and leg pain based on objective functional testing: a pilot study of machine learning applied to diagnostics,29,7,1702-1708,"Staartjes Victor E.,Quddusi Ayesha,Klukowska Anita M.,Schroder Marc L.","Staartjes VE,Quddusi A,Klukowska AM,Schroder ML",Staartjes VE,10.1007/s00586-020-06343-5,University of Zurich,"Objective The five-repetition sit-to-stand (5R-STS) test was designed to capture objective functional impairment and thus provided an adjunctive dimension in patient assessment. The clinical interpretability and confounders of the 5R-STS remain poorly understood. In clinical use, it became apparent that 5R-STS performance may differ between patients with lumbar disk herniation (LDH), lumbar spinal stenosis (LSS) with or without low-grade spondylolisthesis, and chronic low back pain (CLBP). We seek to evaluate the extent of diagnostic information contained within 5R-STS testing. Methods Patients were classified into gold standard diagnostic categories based on history, physical examination, and imaging. Crude and adjusted comparisons of 5R-STS performance were carried out among the three diagnostic categories. Subsequently, a machine learning algorithm was trained to classify patients into the three categories using only 5R-STS test time and patient age, gender, height, and weight. Results From two prospective studies, 262 patients were included. Significant differences in crude and adjusted test times were observed among the three diagnostic categories. At internal validation, classification accuracy was 96.2% (95% CI 87.099.5%). Classification sensitivity was 95.7%, 100%, and 100% for LDH, LSS, and CLBP, respectively. Similarly, classification specificity was 100%, 95.7%, and 100% for the three diagnostic categories. Conclusion 5R-STS performance differs according to the etiology of back and leg pain, even after adjustment for demographic covariates. In combination with machine learning algorithms, OFI can be used to infer the etiology of spinal back and leg pain with accuracy comparable to other diagnostic tests used in clinical examination. Graphic abstract These slides can be retrieved under Electronic Supplementary Material.
[GRAPHICS]
.","Objective functional testing,Functional impairment,Diagnostics,Classification,Machine learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Neurosciences & Neurology,Orthopedics",,3.302,"REPORTED,OUTCOME,MEASURES,SURGERY",EUROPEAN SPINE JOURNAL,,
100,Prediction of Ankle Brachial Index with Photoplethysmography Using Convolutional Long Short Term Memory,40,2,282-291,"Lee Jeong Jik,Heo Jeong Hyun,Han Ji Ho,Kim Bo Ram,Gwon Hyeok Yong,Yoon Young Ro","Lee JJ,Heo JH,Han JH,Kim BR,Gwon HY,Yoon YR",Yoon YR,10.1007/s40846-020-00507-w,Yonsei University,"Purpose Early detection is critical for effective prevention of cardiovascular disease. One of the representative indicators of cardiovascular disease is the ankle-brachial index (ABI). It is mainly used to measure artery disease in primary care. However, the ABI measurement is difficult because the patient must wear cuffs on four limbs. The purpose of this study is to predict ABI using photoplethysmography (PPG), to overcome this difficulty. PPG is known to be closely correlated with cardiovascular conditions. Methods An ABI prediction model based on deep learning is proposed, as it does not require feature extraction from the PPG signals. The ABI values are classified into six classes depending on the cardiovascular disease severity, and the ABI class is predicted by the designed deep learning model. In this study, a convolutional long short term memory (C-LSTM) model consisting of five convolutional layers, five pooling layers, and one LSTM layer was designed. Results As a result of evaluating the performance of the C-LSTM model, the accuracy was 98.3429% and the F1 score was 97.4293%. Therefore, this model achieves high performance. Conclusions The method proposed in this study is a novel method for predicting the ABI class using PPG signals that can be easily measured. The proposed model can classify ABI class automatically without feature extraction. The proposed model enables fast and simple evaluation of the cardiovascular disease in primary care without requiring an ABI measuring instrument.","Cardiovascular disease,Ankle Brachial Index (ABI),Photoplethysmography (PPG),Second derivative PPG (SDPPG),Deep learning,Convolutional long short term memory (C-LSTM)",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Engineering,,1.733,"CORONARY-HEART-DISEASE,PULSE-WAVE,VELOCITY,ARTERIAL,STIFFNESS,AUGMENTATION,INDEX,RISK,ATHEROSCLEROSIS,MORTALITY,STROKE",JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING,,
