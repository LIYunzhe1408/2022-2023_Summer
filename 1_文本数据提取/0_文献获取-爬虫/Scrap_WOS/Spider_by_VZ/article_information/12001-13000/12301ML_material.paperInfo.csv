,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Atrial scar quantification via multi-scale CNN in the graph-cuts framework,60,,,"Li Lei,Wu Fuping,Yang Guang,Xu Lingchao,Wong Tom,Mohiaddin Raad,Firmin David,Keegan Jennifer,Zhuang Xiahai","Li L,Wu FP,Yang G,Xu LC,Wong T,Mohiaddin R,Firmin D,Keegan J,Zhuang XH",Zhuang XH,10.1016/j.media.2019.101595,Fudan University,"Late gadolinium enhancement magnetic resonance imaging (LGE MRI) appears to be a promising alternative for scar assessment in patients with atrial fibrillation (AF). Automating the quantification and analysis of atrial scars can be challenging due to the low image quality. In this work, we propose a fully automated method based on the graph-cuts framework, where the potentials of the graph are learned on a surface mesh of the left atrium (LA) using a multi-scale convolutional neural network (MS-CNN). For validation, we have included fifty-eight images with manual delineations. MS-CNN, which can efficiently incorporate both the local and global texture information of the images, has been shown to evidently improve the segmentation accuracy of the proposed graph-cuts based method. The segmentation could be further improved when the contribution between the t-link and n-link weights of the graph is balanced. The proposed method achieves a mean accuracy of 0.856 +/- 0.033 and mean Dice score of 0.702 +/- 0.071 for LA scar quantification. Compared to the conventional methods, which are based on the manual delineation of LA for initialization, our method is fully automatic and has demonstrated significantly better Dice score and accuracy (p < 0.01). The method is promising and can be potentially useful in diagnosis and prognosis of AF. (C) 2019 The Author(s). Published by Elsevier B.V.","Atrial fibrillation,Left atrium,LGE MRI,Scar segmentation,Graph learning,Multi-scale CNN",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"WHOLE,HEART,SEGMENTATION,CATHETER,ABLATION,PULMONARY,VEIN,FIBRILLATION,MRI,MANAGEMENT,THICKNESS,SELECTION,MODEL,CT",MEDICAL IMAGE ANALYSIS,https://europepmc.org/articles/pmc6988106?pdf=render,
2,Analysis of nonstandardized stress echocardiography sequences using multiview dimensionality reduction,60,,,"Nogueira Mariana,De Craene Mathieu,Sanchez-Martinez Sergio,Chowdhury Devyani,Bijnens Bart,Piella Gemma","Nogueira M,De Craene M,Sanchez-Martinez S,Chowdhury D,Bijnens B,Piella G",Nogueira M,10.1016/j.media.2019.101594,Pompeu Fabra University,"Alternative stress echocardiography protocols such as handgrip exercise are potentially more favorable towards large-scale screening scenarios than those currently adopted in clinical practice. However, these are still underexplored because the maximal exercise levels are not easily quantified and regulated, requiring the analysis of the complete data sequences (thousands of images), which represents a challenging task for the clinician. We propose a framework for the analysis of these complex datasets, and illustrate it on a handgrip exercise dataset including complete acquisitions of 10 healthy controls and 5 ANT1 mutation patients (1377 cardiac cycles). The framework is based on an unsupervised formulation of multiple kernel learning, which is used to integrate information coming from myocardial velocity traces and heart rate to obtain a lower-dimensional representation of the data. Such simplified representation is then explored to discriminate groups of response and understand the underlying pathophysiological mechanisms. The analysis pipeline involves the reconstruction of population-specific signatures using multiscale kernel regression, and the clustering of subjects based on the trajectories defined by their projected sequences. The results confirm that the proposed framework is able to detect distinctive clusters of response and to provide insight regarding the underlying pathophysiology. (C) 2019 Elsevier B.V. All rights reserved.","Multiview dimensionality reduction,Multiple kernel learning,Stress echocardiography,Pattern analysis",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"EXERCISE,DOBUTAMINE,STRAIN",MEDICAL IMAGE ANALYSIS,,
3,Graph temporal ensembling based semi-supervised convolutional neural network with noisy labels for histopathology image analysis,60,,,"Shi Xiaoshuang,Su Hai,Xing Fuyong,Liang Yun,Qu Gang,Yang Lin","Shi XS,Su H,Xing FY,Liang Y,Qu G,Yang L",Shi XS; Yang L,10.1016/j.media.2019.101624,State University System of Florida,"Although convolutional neural networks have achieved tremendous success on histopathology image classification, they usually require large-scale clean annotated data and are sensitive to noisy labels. Unfortunately, labeling large-scale images is laborious, expensive and lowly reliable for pathologists. To address these problems, in this paper, we propose a novel self-ensembling based deep architecture to leverage the semantic information of annotated images and explore the information hidden in unlabeled data, and meanwhile being robust to noisy labels. Specifically, the proposed architecture first creates ensemble targets for feature and label predictions of training samples, by using exponential moving average (EMA) to aggregate feature and label predictions within multiple previous training epochs. Then, the ensemble targets within the same class are mapped into a cluster so that they are further enhanced. Next, a consistency cost is utilized to form consensus predictions under different configurations. Finally, we validate the proposed method with extensive experiments on lung and breast cancer datasets that contain thousands of images. It can achieve 90.5% and 89.5% image classification accuracy using only 20% labeled patients on the two datasets, respectively. This performance is comparable to that of the baseline method with all labeled patients. Experiments also demonstrate its robustness to small percentage of noisy labels. (C) 2019 Elsevier B.V. All rights reserved.","Semi-supervised,Noisy labels,Convolutional neural network,Histopathology image classification",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,,MEDICAL IMAGE ANALYSIS,,
4,In-flight and wireless damage detection in a UAV composite wing using fiber optic sensors and strain field pattern recognition,136,,,"Alvarez-Montoya Joham,Carvajal-Castrillon Alejandro,Sierra-Perez Julian","Alvarez-Montoya J,Carvajal-Castrillon A,Sierra-Perez J",Alvarez-Montoya J,10.1016/j.ymssp.2019.106526,Universidad Pontificia Bolivariana,"Aiming to provide more efficient, lightweight structures, composite materials are being extensively used in aerospace vehicles. As the failure mechanisms of these materials are complex, damage detection becomes challenging, requiring advanced techniques for assessing structural integrity and maintaining aircraft safety. In this context, Structural Health Monitoring (SHM) seeks for integrating sensors into the structures in a way that Nondestructive Testing (NDT) is implemented continuously. One promising approach is to use Fiber Optic Sensors (FOS) to acquire strain signals, taking advantages of their capabilities over conventional sensors. Despite several works have developed Health and Usage Monitoring Systems (HUMS) using FOS for performing in-flight SHM in aircraft structures, automatic damage detection using the acquired signals has not been achieved in a robust way against environmental and operational variability, in all flight stages or considering different types of damages. In this work, a HUMS was developed and implemented in an Unmanned Aerial Vehicle (UAV) based on 20 Fiber Bragg Gratings (FBGs) embedded into the composite front spar of the aircraft's wing, a miniaturized data acquisition subsystem for gathering strain signals and a wireless transmission subsystem for remote sensing. The HUMS was tested in 16 flights, six of them were carried out with the pristine structure and the remaining after inducing different artificial damages. The in-flight data were used to validate a previously developed damage detection methodology based on strain field pattern recognition, or strain mapping, which utilizes machine learning algorithms, specifically a Self-Organizing Map (SOM)-based procedure for clustering operational conditions and Principal Component Analysis (PCA) in conjunction with damage indices for final classification. The performance of the damage detection demonstrated a highest accuracy of 0.981 and a highest F-1 score of 0.978. As a main contribution, this work implements in-flight strain monitoring, remote sensing and automatic damage detection in an operating composite aircraft structure. (C) 2019 Elsevier Ltd. All rights reserved.","Structural health monitoring,Damage detection,Composite materials,Aerospace structures,Machine learning,Remote sensing",Article,"ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD, 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND",Engineering,,6.662,"PRINCIPAL,COMPONENT,ANALYSIS,KERNEL,DENSITY-ESTIMATION,MONITORING-SYSTEM,IDENTIFICATION,VALIDATION,ALGORITHMS",MECHANICAL SYSTEMS AND SIGNAL PROCESSING,,
5,Multimodal Sparse Classifier for Adolescent Brain Age Prediction,24,2,336-344,"Kassani Peyman Hosseinzadeh,Gossmann Alexej,Wang Yu-Ping","Kassani PH,Gossmann A,Wang YP",Wang YP,10.1109/JBHI.2019.2925710,Tulane University,"The study of healthy brain development helps to better understand both brain transformation and connectivity patterns, which happen during childhood to adulthood. This study presents a sparse machine learning solution across whole-brain functional connectivity measures of three datasets, derived from resting state functional magnetic resonance imaging (rs-fMRI) and two task fMRI data including a working memory n-back task (nb-fMRI) and an emotion identification task (em-fMRI). The fMRI data are collected from the Philadelphia Neurodevelopmental Cohort (PNC) for the prediction of brain age in adolescents. Due to extremely large variable-to-instance ratio of PNC data, a high-dimensional matrix with several irrelevant and highly correlated features is generated, and hence a sparse learning approach is necessary to extract effective features from fMRI data. We propose a sparse learner based on the residual errors along the estimation of an inverse problem for extreme learning machine (ELM). Our proposed method is able to overcome the overlearning problem by pruning several redundant features and their corresponding output weights. The proposed multimodal sparse ELM classifier based on residual errors is highly competitive in terms of classification accuracy compared to its counterparts such as conventional ELM, and sparse Bayesian learning ELM.","Brain age prediction,extreme learning machine,neuroimaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"EXTREME,LEARNING-MACHINE,HIDDEN,MRI,GROWTH",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://arxiv.org/pdf/1904.01070,
6,Progressive Sub-Band Residual-Learning Network for MR Image Super Resolution,24,2,377-386,"Xue Xuetong,Wang Ying,Li Jie,Jiao Zhicheng,Ren Ziqi,Gao Xinbo","Xue XT,Wang Y,Li J,Jiao ZC,Ren ZQ,Gao XB",Gao XB,10.1109/JBHI.2019.2945373,Xidian University,"High-resolution (HR) magnetic resonance images (MRI) provide more detailed information for clinical application. However, HR MRI is less available because of the longer scan time and lower signal-to-noise ratio. Spatial resolution is one of the key parameters of MRI. The image post-processing technique super-resolution (SR) is an alternative approach to improve the spatial resolution of MR images. Inspired by advanced deep learning based SR methods, we propose an MRI SR model named progressive sub-band residual learning SR network (PSR-SRN). The proposed model contains two parallel progressive learning streams, where one stream learns on missed high-frequency residuals by sub-band residual learning unit (ISRL) and the other focuses on reconstructing refined MR image. These two streams complement each other and enable to learn complex mappings between ""Low-"" and ""High-"" resolution MR images. Besides, we introduce brain-like mechanisms (in-depth supervision and local feedback mechanism) and progressive sub-band learning strategy to emphasize variant textures of MRI. Compared with traditional and deep learning MRI SR methods, our PSR-SRN model shows superior performance.","Magnetic resonance imaging (MRI),Super resolution (SR),CNN,Local feedback,Residual learning network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"SUPERRESOLUTION,RECONSTRUCTION,7T-LIKE,IMAGES",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
7,GluNet: A Deep Learning Framework for Accurate Glucose Forecasting,24,2,414-423,"Li Kezhi,Liu Chengyuan,Zhu Taiyu,Herrero Pau,Georgiou Pantelis","Li KZ,Liu CY,Zhu TY,Herrero P,Georgiou P",Li KZ,10.1109/JBHI.2019.2931842,Imperial College London,"For people with Type 1 diabetes (T1D), forecasting of blood glucose (BG) can be used to effectively avoid hyperglycemia, hypoglycemia and associated complications. The latest continuous glucosemonitoring (CGM) technology allows people to observe glucose in real-time. However, an accurate glucose forecast remains a challenge. In this work, we introduce GluNet, a framework that leverages on a personalized deep neural network to predict the probabilistic distribution of short-term (30-60 minutes) future CGM measurements for subjects with T1D based on their historical data including glucose measurements, meal information, insulin doses, and other factors. It adopts the latest deep learning techniques consisting of four components: data pre-processing, label transform/recover, multilayers of dilated convolution neural network (CNN), and post-processing. The method is evaluated in-silico for both adult and adolescent subjects. The results show significant improvements over existing methods in the literature through a comprehensive comparison in terms of root mean square error (RMSE) (8.88 +/- 0.77 mg/dL) with short time lag (0.83 +/- 0.40 minutes) for prediction horizons (PH) = 30 mins (minutes), and RMSE (19.90 +/- 3.17 mg/dL) with time lag (16.43 +/- 4.07 mins) for PH = 60 mins for virtual adult subjects. In addition, GluNet is also tested on two clinical data sets. Results show that it achieves an RMSE (19.28 +/- 2.76 mg/dL) with time lag (8.03 +/- 4.07 mins) for PH = 30 mins and an RMSE (31.83 +/- 3.49 mg/dL) with time lag (17.78 +/- 8.00 mins) for PH = 60 mins. These are the best reported results for glucose forecasting when compared with other methods including the neural network for predicting glucose (NNPG), the support vector regression (SVR), the latent variable with exogenous input (LVX), and the auto regression with exogenous input (ARX) algorithm.","Deep learning,dilated convolutions,glucose forecasting,continuous glucose monitoring (CGM),diabetes",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"ADVANCED,BOLUS,CALCULATOR,PREDICTION,ARCHITECTURE,ALGORITHM,SENSORS,MODEL",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://nottingham-repository.worktribe.com/2361380/1/GluNet  A Deep Learning Framework For Accurate Blood Glucose Forecasting,
8,Knowledge-Based Analysis for Mortality Prediction From CT Images,24,2,457-464,"Guo Hengtao,Kruger Uwe,Wang Ge,Kalra Mannudeep K.,Yan Pingkun","Guo HT,Kruger U,Wang G,Kalra MK,Yan PK",Yan PK,10.1109/JBHI.2019.2946066,Rensselaer Polytechnic Institute,"Low-Dose CT (LDCT) can significantly improve the accuracy of lung cancer diagnosis and thus reduce cancer deaths compared to chest X-ray. The lung cancer risk population is also at high risk of other deadly diseases, for instance, cardiovascular diseases. Therefore, predicting the all-cause mortality risks of this population is of great importance. This paper introduces a knowledge-based analytical method using deep convolutional neural network (CNN) for all-cause mortality prediction. The underlying approach combines structural image features extracted from CNNs, based on LDCT volume at different scales, and clinical knowledge obtained from quantitative measurements, to predict the mortality risk of lung cancer screening subjects. The proposed method is referred as Knowledge-based Analysis of Mortality Prediction Network (KAMP-Net). It constitutes a collaborative framework that utilizes both imaging features and anatomical information, instead of completely relying on automatic feature extraction. Our work demonstrates the feasibility of incorporating quantitative clinical measurements to assist CNNs in all-cause mortality prediction from chest LDCT images. The results of this study confirm that radiologist defined features can complement CNNs in performance improvement. The experiments demonstrate that KAMP-Net can achieve a superior performance when compared to other methods.","Lung cancer,low-dose CT,mortality risk,convolutional neural network,clinical knowledge",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"CORONARY-ARTERY,CALCIUM,LOW-DOSE,CT,LUNG-CANCER,DISEASE",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://arxiv.org/pdf/1902.07687,
9,Epilepsy Seizure Prediction on EEG Using Common Spatial Pattern and Convolutional Neural Network,24,2,465-474,"Zhang Yuan,Guo Yao,Yang Po,Chen Wei,Lo Benny","Zhang Y,Guo Y,Yang P,Chen W,Lo B",Guo Y; Chen W,10.1109/JBHI.2019.2933046,Fudan University,"Epilepsy seizure prediction paves the way of timely warning for patients to take more active and effective intervention measures. Compared to seizure detection that only identifies the inter-ictal state and the ictal state, far fewer researches have been conducted on seizure prediction because the high similarity makes it challenging to distinguish between the pre-ictal state and the inter-ictal state. In this paper, a novel solution on seizure prediction is proposed using common spatial pattern (CSP) and convolutional neural network (CNN). Firstly, artificial pre-ictal EEG signals based on the original ones are generated by combining the segmented pre-ictal signals to solve the trial imbalance problem between the two states. Secondly, a feature extractor employing wavelet packet decomposition and CSP is designed to extract the distinguishing features in both the time domain and the frequency domain. It can improve overall accuracy while reducing the training time. Finally, a shallow CNN is applied to discriminate between the pre-ictal state and the inter-ictal state. Our proposed solution is evaluated on 23 patients' data from Boston Children's Hospital-MIT scalp EEG dataset by employing a leave-one-out cross-validation, and it achieves a sensitivity of 92.2% and false prediction rate of 0.12/h. Experimental result demonstrates that the proposed approach outperforms most state-of-the-art methods.","Seizure prediction,EEG,common spatial patterns,convolutional neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"SPECTRAL,POWER,TIME,CLASSIFICATION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://eprints.whiterose.ac.uk/151225/15/JBHI__1_.pdf,
10,MFB-CBRNN: A Hybrid Network for MI Detection Using 12-Lead ECGs,24,2,503-514,"Liu Wenhan,Wang Fei,Huang Qijun,Chang Sheng,Wang Hao,He Jin","Liu WH,Wang F,Huang QJ,Chang S,Wang H,He J",Huang QJ,10.1109/JBHI.2019.2910082,Wuhan University,"This paper proposes a novel hybrid network named multiple-feature-branch convolutional bidirectional recurrent neural network (MFB-CBRNN) for myocardial infarction (MI) detection using 12-lead ECGs. The model efficiently combines convolutional neural network-based and recurrent neural network-based structures. Each feature branch consists of several one-dimensional convolutional and pooling layers, corresponding to a certain lead. All the feature branches are independent from each other, which are utilized to learn the diverse features from different leads. Moreover, a bidirectional long short term memory network is employed to summarize all the feature branches. Its good ability of feature aggregation has been proved by the experiments. Furthermore, the paper develops a novel optimization method, lead random mask (LRM), to alleviate overfitting and implement an implicit ensemble like dropout. The model with LRM can achieve a more accurate MI detection. Class-based and subject-based fivefold cross validations are both carried out using Physikalisch-Technische Bundesanstalt diagnostic database. Totally, there are 148 MI and 52 healthy control subjects involved in the experiments. The MFB-CBRNN achieves an overall accuracy of 99.90% in class-based experiments, and an overall accuracy of 93.08% in subject-based experiments. Compared with other related studies, our algorithm achieves a comparable or even better result on MI detection. Therefore, the MFB-CBRNN has a good generalization capacity and is suitable for MI detection using 12-lead ECGs. It has a potential to assist the real-world MI diagnostics and reduce the burden of cardiologists.","Convolutional neural network (CNN),bidirectional long short term memory (BLSTM),electrocardiogram (ECG),myocardial infarction (MI),automated diagnosis,lead random mask (LRM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"CONVOLUTIONAL,NEURAL-NETWORK,MYOCARDIAL-INFARCTION,COMPLEX,CLASSIFICATION,LOCALIZATION,MACHINE",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
11,Convolutional Recurrent Neural Networks for Glucose Prediction,24,2,603-613,"Li Kezhi,Daniels John,Liu Chengyuan,Herrero Pau,Georgiou Pantelis","Li KZ,Daniels J,Liu CY,Herrero P,Georgiou P",Li KZ,10.1109/JBHI.2019.2908488,Imperial College London,"Control of blood glucose is essential for diabetes management. Current digital therapeutic approaches for subjects with type 1 diabetes mellitus such as the artificial pancreas and insulin bolus calculators leverage machine learning techniques for predicting subcutaneous glucose for improved control. Deep learning has recently been applied in healthcare and medical research to achieve state-of-the-art results in a range of tasks including disease diagnosis, and patient state prediction among others. In this paper, we present a deep learning model that is capable of forecasting glucose levels with leading accuracy for simulated patient cases (root-mean-square error (RMSE) = 9.38 +/- 0.71 [mg/dL] over a 30-min horizon, RMSE = 18.87 +/- 2.25 [mg/dL] over a 60-min horizon) and real patient cases (RMSE = 21.07 +/- 2.35 [mg/dL] for 30 min, RMSE = 33.27 +/- 4.79% for 60 min). In addition, the model provides competitive performance in providing effective prediction horizon (PHeff) with minimal time lag both in a simulated patient dataset (PHeff = 29.0 +/- 0.7 for 30 min and PHeff = 49.8 +/- 2.9 for 60 min) and in a real patient dataset (PHeff = 19.3 +/- 3.1 for 30 min and PHeff = 29.3 +/- 9.4 for 60 min). This approach is evaluated on a dataset of ten simulated cases generated from the UVA/Padova simulator and a clinical dataset of ten real cases each containing glucose readings, insulin bolus, and meal (carbohydrate) data. Performance of the recurrent convolutional neural network is benchmarked against four algorithms. The proposed algorithm is implemented on an Android mobile phone, with an execution time of 6 ms on a phone compared to an execution time of 780 ms on a laptop.","Type 1 diabetes,continuous glucose monitor (CGM),glucose prediction,deep learning,long short term memory (LSTM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"ADVANCED,BOLUS,CALCULATOR,SYSTEM,CLASSIFICATION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://nottingham-repository.worktribe.com/preview/2302710/CRNN_Paper_Manuscript.pdf,
12,Non-Contact Sleep Stage Detection Using Canonical Correlation Analysis of Respiratory Sound,24,2,614-625,"Xue Biao,Deng Boya,Hong Hong,Wang Zhiyong,Zhu Xiaohua,Feng David Dagan","Xue B,Deng BY,Hong H,Wang ZY,Zhu XH,Feng DD",Hong H,10.1109/JBHI.2019.2910566,Nanjing University of Science & Technology,"Respiratory sound is able to differentiate sleep stages and provide a non-contact and cost-effective solution for the diagnosis and treatment monitoring of sleep-related diseases. While most of the existing respiratory sound-based methods focus on a limited number of sleep stages such as sleep/wake and wake/rapid eye movement (REM)/non-REM, it is essential to detect sleep stages at a finer level for sleep quality evaluation. In this paper, we for the first time study a sleep stage detection method aiming at classifying sleep states into four sleep stages: wake, REM, light sleep, and deep sleep from the respiratory sound. In addition to extracting time-domain features, frequency-domain features of respiratory sound, non-linear features of snoring sound are devised to better characterize snoring-related signals of respiratory sound. To effectively fuse the three sets of features, a novel feature fusion technique combining the generalized canonical correlation analysis with the ReliefF algorithm is proposed for discriminative feature selection. Final stage detection is achieved with popular classifiers including decision tree, support vector machines, K-nearest neighbor, and the ensemble classifier. To evaluate our proposed method, we built an in-house dataset, which is comprised of 13 nights of sleep audio data from a sleep laboratory. Experimental results indicate that our proposed method outperforms the existing related ones and is promising for large-scale non-contact sleep monitoring.","Sleep stage detection,nonlinear features,respiratory sound,canonical correlation analysis,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"SNORE,SOUND,CLASSIFICATION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
13,A Multimodal Interlocutor-Modulated Attentional BLSTM for Classifying Autism Subgroups During Clinical Interviews,14,2,299-311,"Lin Yun-Shao,Gau Susan Shur-Fen,Lee Chi-Chun","Lin YS,Gau SSF,Lee CC",Lin YS,10.1109/JSTSP.2020.2970578,National Tsing Hua University,"The heterogeneity in Autism Spectrum Disorder (ASD) remains a challenging and unsolved issue in the current clinical practice. The behavioral differences between ASD subgroups are subtle and can be hard to be manually discerned by experts. Here, we propose a computational framework that is capable of modeling both vocal behaviors and body gestural movements of the interlocutors with their intricate dependency captured through a learnable interlocutor-modulated (IM) attention mechanism during dyadic clinical interviews of Autism Diagnostic Observation Schedule (ADOS). Specifically, our multimodal network architecture includes two modality-specific networks, a speech-IM-aBLSTM and a motion-IM-aBLSTM, that are combined in a fusion network to perform the final three ASD subgroups differentiation, i.e., Autistic Disorder (AD) vs. High-Functioning Autism (HFA) vs. Asperger Syndrome (AS). Our model uniquely introduces the IM attention mechanism to capture the non-linear behavior dependency between interlocutors, which is essential in providing improved discriminability in classifying the three subgroups. We evaluate our framework on a large ADOS collection, and we obtain a 66.8% unweighted average recall (UAR) that is 14.3% better than the previous work on the same dataset. Furthermore, based on the learned attention weights, we analyze essential behavior descriptors in differentiating subgroup pairs. We further identify the most critical self-disclosure emotion topics within the ADOS interview sessions, and it shows that anger and fear are the most informative interaction segments for observing the subtle interactive behavior differences between these three sub-types of ASD.","Behavioral signal processing,autism spectrum disorder,multimodal BLSTM,attention mechanism",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,"SPECTRUM,DISORDER,SELF-DISCLOSURE,EMOTION,REGULATION,DIAGNOSTIC,INTERVIEW,ASPERGER-SYNDROME,CHILDREN,BEHAVIOR,DEFICITS,CLASSIFICATION,ANGER",IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,,
14,Automatic Assessment of Depression From Speech via a Hierarchical Attention Transfer Network and Attention Autoencoders,14,2,423-434,"Zhao Ziping,Bao Zhongtian,Zhang Zixing,Deng Jun,Cummins Nicholas,Wang Haishuai,Tao Jianhua,Schuller Bjoern","Zhao ZP,Bao ZT,Zhang ZX,Deng J,Cummins N,Wang HS,Tao JH,Schuller B",Tao JH,10.1109/JSTSP.2019.2955012,Chinese Academy of Sciences,"Early interventions in mental health conditions such as Major Depressive Disorder (MDD) are critical to improved health outcomes, as they can help reduce the burden of the disease. As the efficient diagnosis of depression severity is therefore highly desirable, the use of behavioural cues such as speech characteristics in diagnosis is attracting increasing interest in the field of quantitative mental health research. However, despite the widespread use of machine learning methods in the depression analysis community, the lack of adequate labelled data has become a bottleneck preventing the broader application of techniques such as deep learning. Accordingly, we herein describe a deep learning approach that combines unsupervised learning, knowledge transfer and hierarchical attention for the task of speech-based depression severity measurement. Our novel approach, a Hierarchical Attention Transfer Network (HATN), uses hierarchical attention autoencoders to learn attention from a source task, followed by speech recognition, and then transfers this knowledge into a depression analysis system. Experiments based on the depression sub-challenge dataset of the Audio/Visual Emotion Challenge (AVEC) 2017 demonstrate the effectiveness of our proposed model. On the test set, our technique outperformed other speech-based systems presented in the literature, achieving a Root Mean Square Error (RMSE) of 5.51 and a Mean Absolute Error (MAE) of 4.20 on a Patient Health Questionnaire (PHQ)-8 scale [0, 24]. To the best of our knowledge, these scores represent the best-known speech results on the AVEC 2017 depression corpus to date.","Task analysis,Deep learning,Speech recognition,Training,Feature extraction,Depression,attention transfer,hierarchical attention,monotonic attention",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,SPACE,IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,,
15,A Deep Transfer Learning Approach to Reducing the Effect of Electrode Shift in EMG Pattern Recognition-Based Control,28,2,370-379,"Ameri Ali,Akhaee Mohammad Ali,Scheme Erik,Englehart Kevin","Ameri A,Akhaee MA,Scheme E,Englehart K",Ameri A,10.1109/TNSRE.2019.2962189,Shahid Beheshti University Medical Sciences,"An important barrier to commercialization of pattern recognition myoelectric control of prostheses is the lack of robustness to confounding factors such as electrode shift, skin impedance variations, and learning effects. To overcome this challenge, a novel supervised adaptation approach based on transfer learning (TL) with convolutional neural networks (CNNs) is proposed which requires only a short training session (a few seconds for each class) to recalibrate the system. TL is proposed as a solution to the problem of insufficient calibration data due to short training times for both classification and regression-based control schemes. This approach was validated for electrode shift of roughly 2.5cm with 13 able-bodied subjects to estimate individual and combined wrist motions. With this method, the original CNN (trained before the shift) was fine-tuned with the calibration data from after shifting. The results show that the proposed technique outperforms training a CNN from scratch (random initialization of weights) or a support vector machine (SVM) using the minimal calibration data. Moreover, it demonstrates superior performance than previous LDA and QDA-based adaptation approaches. As the outcomes confirm, the proposed CNN TL method provides a practical solution for adaptation to external factors, improving the robustness of electromyogram (EMG) pattern recognition systems.","Myoelectric control,EMG,deep learning,transfer learning,convolutional neural network,electrode shift",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"UPPER-LIMB,PROSTHESES,MYOELECTRIC,CONTROL,SURFACE,EMG,REAL-TIME,SIGNALS,ROBUST,CLASSIFICATION,FEATURES,STRATEGY,NUMBER",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
16,Sleep Spindle Detection Using RUSBoost and Synchrosqueezed Wavelet Transform,28,2,390-398,"Kinoshita Takafumi,Fujiwara Koichi,Kano Manabu,Ogawa Keiko,Sumi Yukiyoshi,Matsuo Masahiro,Kadotani Hiroshi","Kinoshita T,Fujiwara K,Kano M,Ogawa K,Sumi Y,Matsuo M,Kadotani H",Fujiwara K,10.1109/TNSRE.2020.2964597,Nagoya University,"Sleep spindles are important electroencephalographic (EEG) waveforms in sleep medicine; however, it is burdensome even for experts to detect spindles, so automatic spindle detection methodologies have been investigated. Conventional methods utilize waveforms template matching or machine learning for detecting spindles. In the former approach, it is necessary to tune thresholds for individual adaptation, while the latter approach has the problem of imbalanced data because the amount of sleep spindles is small compared with the entire EEG data. The present work proposes a sleep spindle detection method that combines wavelet synchrosqueezed transform (SST) and random under-sampling boosting (RUSBoost). SST is a time-frequency analysis method suitable for extracting features of spindle waveforms. RUSBoost is a framework for coping with the imbalanced data problem. The proposed SST-RUS can deal with the imbalanced data in spindle detection and does not require threshold tuning because RUSBoost uses majority voting of weak classifiers for discrimination. The performance of SST-RUS was validated using an open-access database called the Montreal archives of sleep studies cohort 1 (MASS-C1), which showed an F-measure of 0.70 with a sensitivity of 76.9% and a positive predictive value of 61.2%. The proposed method can reduce the burden of PSG scoring.","Sleep spindle detection,electroencephalography,polysomnography,synchrosqueezed wavelet transform,random under sampling boosting",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"ALGORITHM,EEG,CLASSIFICATION",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
17,Closed-Loop Multi-Amplitude Control for Robust and Dexterous Performance of Myoelectric Prosthesis,28,2,498-507,"Markovic Marko,Varel Marc,Schweisfurth Meike A.,Schilling Arndt F.,Dosen Strahinja","Markovic M,Varel M,Schweisfurth MA,Schilling AF,Dosen S",Markovic M,10.1109/TNSRE.2019.2959714,University of Gottingen,"In the case of a hand amputation, the affected person can use a myoelectric prosthesis to substitute the missing limb and regain motor functions. Unfortunately, commercial methods for myoelectric control, although robust and simple, are unintuitive and cognitively taxing when applied to an advanced multi-functional prosthesis. The state-of-the-art methods developed in academia are based on machine learning and therefore require long training and suffer from a lack of robustness. This work presents a novel closed-loop multi-level amplitude controller (CMAC), which aims at overcoming these drawbacks. The CMAC implements three degrees-of-freedom (DoF) control by thresholding the muscle contraction intensity during wrist flexion and extension movements. Unique features of the controller are the vibrotactile feedback that communicates the state of the controller to the user and a scheme for proportional control. These components allow exploiting the full dexterity of the prosthesis using a simple two-channel myoelectric interface. The CMAC was compared to a commonly implemented pattern-recognition method (linear discriminant analysis - LDA) using clinically relevant tests in 12 able-bodied and 2 amputee subjects. The experimental assessment demonstrated that CMAC was similarly fast as LDA in dexterous tests (clothespin and cube manipulation), while it was somewhat slower than LDA during a simple, single DoF task (box and blocks). In addition, in all the tasks, LDA and CMAC resulted in a similarly low error rate. On the other hand, to an amputee that could not generate six distinguishable classes using LDA, the CMAC still enabled the control of all the prosthesis DoFs. Importantly, the overall setup and training time in CMAC were significantly lower compared to LDA. In conclusion, the novel method is convenient for clinical applications, and allows substantially higher control dexterity compared to what can be normally achieved using conventional two channel EMG. Therefore, CMAC provides performance comparable to advanced machine-learning algorithms and the robustness and ease of use that is characteristic for the simple two-channel myoelectric interface.","Myoelectric control,pattern classification,multi-amplitude control,vibrotactile feedback,functional tasks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"NONINVASIVE,SENSORY,FEEDBACK,OF-THE-ART,PATTERN-RECOGNITION,REAL-TIME,HAND,REGRESSION",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
18,Multi-Grip Classification-Based Prosthesis Control With Two EMG-IMU Sensors,28,2,508-518,"Krasoulis Agamemnon,Vijayakumar Sethu,Nazarpour Kianoush","Krasoulis A,Vijayakumar S,Nazarpour K",Krasoulis A,10.1109/TNSRE.2019.2959243,Newcastle University - UK,"In the field of upper-limb myoelectric prosthesis control, the use of statistical and machine learning methods has been long proposed as a means of enabling intuitive grip selection and actuation. Recently, this paradigm has found its way toward commercial adoption. Machine learning-based prosthesis control typically relies on the use of a large number of electrodes. Here, we propose an end-to-end strategy for multi-grip, classification-based prosthesis control using only two sensors, comprising electromyography (EMG) electrodes and inertial measurement units (IMUs). We emphasize the importance of accurately estimating posterior class probabilities and rejecting predictions made with low confidence, so as to minimize the rate of unintended prosthesis activations. To that end, we propose a confidence-based error rejection strategy using grip-specific thresholds. We evaluate the efficacy of the proposed system with real-time pick and place experiments using a commercial multi-articulated prosthetic hand and involving 12 able-bodied and two transradial (i.e., below-elbow) amputee participants. Results promise the potential for deploying intuitive, classification-based multi-grip control in existing upper-limb prosthetic systems subject to small modifications.","Classification,electromyography,inertial measurement unit,myoelectric control,sensor minimization,upper-limb prosthesis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,,"REAL-TIME,SURFACE,EMG,NUMBER,SIGNALS,ROBUST",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,https://eprints.ncl.ac.uk/file_store/production/255900/872B8A44-9C3B-4200-A795-E5F3DECAC485.pdf,
19,Detection of microcytic hypochromia using cbc and blood film features extracted from convolution neural network by different classifiers,79,7-8,4573-4595,"Purwar Shikha,Tripathi Rajiv Kumar,Ranjan Ravi,Saxena Renu","Purwar S,Tripathi RK,Ranjan R,Saxena R",Purwar S,10.1007/s11042-019-07927-0,National Institute of Technology (NIT System),"Diagnosis of microcytic hypochromia is done by measuring certain characteristics changes in the count of blood cell and related indices. Complete blood count test (CBC) is the common process for measuring these characteristic changes. However, the CBC test cannot be completely relied upon since there are chances of false diagnosis as these characteristics are also related to other disorders. In order to rectify the same, other expensive and lengthy tests need to be done which leads to further delay in accurate diagnosis and which may prove detrimental. In an attempt to find the solution to this problem, this paper proposes a method that uses feature fusion for classification of microcytic hypochromia. Feature fusion means combining blood smear image features extracted by the deep convolutional neural network (CNN) and clinical features from CBC test. This fused data-set is further used to predict microcytic hypochromia. After obtaining fused data set we use linear discriminant analysis (LDA) and principal component analysis (PCA) to reduce data set dimensions which further results in less computational overhead. To differentiate between microcytic hypochromia patients and normal persons, k-nearest neighbors (k-NN), support vector machine (SVM), and neural network classification models are used. In order to check the performance of the above model, various evaluation metrics are used. Results achieved from the proposed method reflect that fused data set can effectively improve the identification ratio with a very limited number of patients diagnostic images and clinical data (10 for normal and 10 for beta-thalassemia) and feed-forward back-propagation neural network on this data set achieved accuracy, sensitivity, and specificity of 99%, 1.00, and 0.98, respectively. The limited number of patients reduces the system complexity and researcher's time for getting data from different hospital to train the network.","Artificial neural network,Convolution neural network,K-nearest neighbors,Linear discriminant analysis,Principal component analysis,Support vector machine",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"MULTILAYER,PERCEPTRON,CLASSIFICATION",MULTIMEDIA TOOLS AND APPLICATIONS,,
20,Cybernetic microbial detection system using transfer learning,79,7-8,5225-5242,"Samuel Dinesh Jackson R.,Kanna Rajesh B.","Samuel RDJ,Kanna BR",Samuel RDJ,10.1007/s11042-018-6356-z,VIT Chennai,"Microorganisms are single or multi-cellular living organism viewed under a microscope. For pathological study, the images of these microbes are captured using microscopes and image processing is done for further analysis. The World Health Organization (WHO) recommends to view at least 300 Field-of-Views (FOV) manually, for diagnosing and reporting the level of infection. These operation involved for analysis requires skilled technician for error free results. When the number of images for diagnosis increases, it becomes cumbersome for the technicians as there is a chance of ambiguity in results, which hampers the sensitivity of the study. In this work, a Cybernetic Microbial Detection System (CMDS) has been proposed. As in the first stage, all field of views are acquired from the specimen using a programmable microscopic stage coupled with an acquisition system. Herein, the user defines a scanning pattern for the microscopic stage movement, which facilitates the data acquisition during specimen screening. In the second stage microbial recognition system is proposed, wherein a transfer learning technique is implemented by customizing Visual Geometry Group (VGG16/19) layered convolution neural network coupled to the Support Vector Machine (SVM). These modified stack layers (VGG + SVM) has been trained/tested with microscopy images of ZN stained Tuberculosis (TB) specimem obtained from a open source database [3] and also acquired microscopy images from several patients sputum smear specimen. The accuracy obtained from the TB recognition system is 83.404 and 86.6% for VGG16-SVM, VGG19-SVM respectively. Thus the proposed screening process reduces the reliance on skilled technicians and facilitates the humanitarian nursing. Hence, the proposed cybernetic system might be useful to human community in remote regions for rapid diagnosis and detection of infectious diseases.","Motorized microscopic stage,Microbial recognition system,CNN-SVM,Humanitarian nursing,TB bacilli detection",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"SERVICES,MODEL",MULTIMEDIA TOOLS AND APPLICATIONS,,
21,A fusion approach to classify hyperspectral oil spill data,79,7-8,5399-5418,"Menezes Jacintha,Poojary Nagesh","Menezes J,Poojary N",Menezes J,10.1007/s11042-018-6709-7,Bharathiar University,"Oil spills in the ocean are one of the major environmental concerns as they pose significant threat to the ecosystem. In the recent year's hyperspectral sensors have been used to detect oil spills due to their ability to capture reflected solar signal with very narrow bandwidth, that enables to differentiate materials even with subtle signature differences. However high spectral dimensionality affects classification accuracy due to insufficient training samples. Conventional methods have dealt with this problem through band (or feature) selection or feature extraction (or transformation) approaches. In the case of an oil emulsion signal, as evident from the literature the oil characteristics are present only in certain bands of a spectral signature. Hence feature selection without focusing on right bands may lead to selecting features of less significance for target identification. Moreover, in feature extraction approaches during transformation from high dimensional space to low dimension space some of the important features could be lost. Hence, the proposed research takes advantage of different but complimentary benefits of both feature selection and feature extraction methods to obtain final features effectively. In the proposed research, features are selected by modelling the oil emulsion signal using derivative spectrum and calculation of partial sum of energies. Derivative spectrum represents variation in signal energies and calculation of partial sum of signal energies for each band facilitates the application of filters bank to capture oil sensitive signal characteristics. Feature extraction is done through wavelet transform by gradual multi-scale zooming of signals through partial analysis of time (space) frequencies. The obtained features are fused together and fed to Gaussian Mixture Model (GMM) classifier to classify oil emulsions. The proposed approach gives 5% to-10% higher classification accuracy as compared to some of the conventional techniques.","Oil emulsion,Spectral signature,Hyperspectral imaging,Derivative spectrum,Spectral filtering",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"SIGNAL,SATELLITE",MULTIMEDIA TOOLS AND APPLICATIONS,,
22,Machine learning for imaging Cherenkov detectors,15,2,,Fanelli C.,Fanelli C,Fanelli C,10.1088/1748-0221/15/02/C02012,Massachusetts Institute of Technology (MIT),"Imaging Cherenkov detectors are largely used in modern nuclear and particle physics experiments where cutting-edge solutions are needed to face always more growing computing demands.
This is a fertile ground for AI-based approaches and at present we are witnessing the onset of new highly efficient and fast applications. This paper focuses on novel directions with applications to Cherenkov detectors. In particular, recent advances on detector design and calibration, as well as particle identification are presented.","Cherenkov detectors,Detector design and construction technologies and materials,Particle identification methods,Pattern recognition, cluster finding, calibration and fitting methods",Article; Proceedings Paper,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Instruments & Instrumentation,,1.328,,JOURNAL OF INSTRUMENTATION,http://arxiv.org/pdf/2006.05543,
23,Data augmentation for self-paced motor imagery classification with C-LSTM,17,1,,"Freer Daniel,Yang Guang-Zhong","Freer D,Yang GZ",Freer D,10.1088/1741-2552/ab57c0,Imperial College London,"Objective. Brain-computer interfaces (BCI) are becoming important tools for assistive technology, particularly through the use of motor imagery (MI) for aiding task completion. However, most existing methods of MI classification have been applied in a trial-wise fashion, with window sizes of approximately 2 s or more. Application of this type of classifier could cause a delay when switching between MI events. Approach. In this study, state-of-the-art classification methods for motor imagery are assessed offline with considerations for real-time and self-paced control, and a convolutional long-short term memory (C-LSTM) network based on filter bank common spatial patterns (FBCSP) is proposed. In addition, the effects of several methods of data augmentation on different classifiers are explored. Main results. The results of this study show that the proposed network achieves adequate results in distinguishing between different control classes, but both considered deep learning models are still less reliable than a Riemannian MDM classifier. In addition, controlled skewing of the data and the explored data augmentation methods improved the average overall accuracy of the classifiers by 14.0% and 5.3%, respectively. Significance. This manuscript is among the first to attempt combining convolutional and recurrent neural network layers for the purpose of MI classification, and is also one of the first to provide an in-depth comparison of various data augmentation methods for MI classification. In addition, all of these methods are applied on smaller windows of data and with consideration to ambient data, which provides a more realistic test bed for real-time and self-paced control.","brain-computer interface,electroencephalography,deep learning,motor imagery,data augmentation",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"EEG,NETWORKS",JOURNAL OF NEURAL ENGINEERING,,
24,Selective peripheral nerve recordings from nerve cuff electrodes using convolutional neural networks,17,1,,"Koh Ryan G. L.,Balas Michael,Nachman Adrian I,Zariffa Jose","Koh RGL,Balas M,Nachman AI,Zariffa J",Zariffa J,10.1088/1741-2552/ab4ac4,University of Toronto,"Objective. Recording and stimulating from the peripheral nervous system are becoming important components in a new generation of bioelectronics systems. Although neurostimulation has seen a history of successful chronic applications in humans, peripheral nerve recording in humans chronically remains a challenge. Multi-contact nerve cuff electrode configurations have the potential to improve recording selectivity. We introduce the idea of using a convolutional neural network (CNN) to associate recordings of individual naturally evoked compound action potentials (CAPs) with neural pathways of interest, by exploiting the spatiotemporal patterns in multi-contact nerve cuff recordings. Approach. Nine Long-Evan rats were implanted with a 56-channel nerve cuff electrode on the sciatic nerve and afferent activity was selectively evoked in different fascicles (tibial, peroneal, sural) using mechanical stimuli. A recurrent neural network was then used to predict joint angles based on the predicted firing patterns from the CNN. Performance was measured based on the classification accuracy, F-1-score and the ability to track the ankle joint angle. Main results. Classification accuracy and F-1-score of the best CNN configuration were and 0.747 +/- 0.114, respectively. The mean Pearson correlation coefficient between the manually measured ankle angle and the angle predicted from the estimated firing rate was Significance. The proposed method demonstrates that CAP-based classification can be achieved with high accuracy and can be used to track a physiological meaningful measure (e.g. joint angle). These results provide a promising direction for realizing more effective and intuitive neuroprosthetic systems.","spatiotemporal signatures,nerve cuff electrode,peripheral nerve interfaces,peripheral nerve recording,rat sciatic nerve,compound action potential,machine learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"STIMULATION,CLASSIFICATION,EXTRACTION",JOURNAL OF NEURAL ENGINEERING,,
25,Mental state space visualization for interactive modeling of personalized BCI control strategies,17,1,,"Kuzovkin Ilya,Tretyakov Konstantin,Uusberg Andero,Vicente Raul","Kuzovkin I,Tretyakov K,Uusberg A,Vicente R",Kuzovkin I,10.1088/1741-2552/ab6d0b,University of Tartu,"Objective. Numerous studies in the area of BCI are focused on the search for a better experimental paradigm-a set of mental actions that a user can evoke consistently and a machine can discriminate reliably. Examples of such mental activities are motor imagery, mental computations, etc. We propose a technique that instead allows the user to try different mental actions in the search for the ones that will work best. Approach. The system is based on a modification of the self-organizing map (SOM) algorithm and enables interactive communication between the user and the learning system through a visualization of user's mental state space. During the interaction with the system the user converges on the paradigm that is most efficient and intuitive for that particular user. Main results. Results of the two experiments, one allowing muscular activity, another permitting mental activity only, demonstrate soundness of the proposed method and offer preliminary validation of the performance improvement over the traditional closed-loop feedback approach. Significance. The proposed method allows a user to visually explore their mental state space in real time, opening new opportunities for scientific inquiry. The application of this method to the area of brain-computer interfaces enables more efficient search for the mental states that will allow a user to reliably control a BCI system.","brain-computer interface,experimental paradigm,self-organizing map,closed loop feedback,visualization",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,,"BRAIN-COMPUTER,INTERFACE,SELF-ORGANIZING,MAP,INDIVIDUAL-DIFFERENCES,MOTOR,IMAGERY,CLASSIFICATION,PATTERNS,PERFORMANCE,ALGORITHM,PEOPLE",JOURNAL OF NEURAL ENGINEERING,https://doi.org/10.1101/867119,
26,Predicting functional force production capabilities of upper extremity functional electrical stimulation neuroprostheses: a proof of concept study,17,1,,"Schearer Eric M.,Wolf Derek N.","Schearer EM,Wolf DN",Schearer EM,10.1088/1741-2552/ab68b3,Cleveland State University,"Objective. This study's goal was to demonstrate person-specific predictions of the force production capabilities of a paralyzed arm when actuated with a functional electrical stimulation (FES) neuroprosthesis. These predictions allow us to determine, for each hand position in a person's workspace, if FES activated muscles can produce enough force to hold the arm against gravity and other passive forces, the amount of force the arm can potentially exert on external objects, and in which directions FES can move the arm. Approach. We computed force production predictions for a person with high tetraplegia and an FES neuroprosthesis used to activate muscles in her shoulder and arm. We developed Gaussian process regression models of the force produced at the end of the forearm when stimulating individual muscles at different wrist positions in the person's workspace. For any given wrist position, we predicted all possible forces a person can produce by any combination of individual muscles. Based on the force predictions, we determined if FES could produce force sufficient to overcome passive forces to hold a wrist position, the maximum force FES could produce in all directions, and the set of directions in which FES could move the arm. To estimate the error in our predictions, we then compared our force predictions based on single-muscle models to the actual forces produced when stimulating combinations of the person's muscles. Main results. Our models classified the person's ability to hold static arm positions correctly for 83% (Session #1) and 69% (Session #2) for 39 wrist positions over two sessions. We predicted this person's ability to produce force at the end of her arm with an RMS error of 5.5 N and the percent of directions for which FES could achieve motion with RMS error of 10%. The accuracy of these predictions is similar to that found in the literature for FES systems with fewer degrees of freedom and fewer muscles. Significance. These person and device-specific predictions of functional capabilities of the arm allow neuroprosthesis developers to set achievable functional objectives for the systems they develop. These predictions can potentially serve as a screening tool for clinicians to use in planning neuroprosthetic interventions, greatly reducing the risk and uncertainty in such interventions.","spinal cord injury,machine learning,muscle strength,rehabilitation outcome assessment,assistive technology",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"NERVE-CUFF,ELECTRODES,MUSCLE,STRENGTH,IMPLANTED,NEUROPROSTHESIS,TORQUE,CONTROL,HUMAN,ARM,TETRAPLEGIA,MULTICHANNEL,RESTORATION,MOVEMENTS,CAPACITY",JOURNAL OF NEURAL ENGINEERING,,
27,A prognostic analysis method for non-small cell lung cancer based on the computed tomography radiomics,65,4,,"Wang Xu,Duan Huihong,Li Xiaobing,Ye Xiaodan,Huang Gang,Nie Shengdong","Wang X,Duan HH,Li XB,Ye XD,Huang G,Nie SD",Nie SD,10.1088/1361-6560/ab6e51,University of Shanghai for Science & Technology,"In order to assist doctors in arranging the postoperative treatments and re-examinations for non-small cell lung cancer (NSCLC) patients, this study was initiated to explore a prognostic analysis method for NSCLC based on computed tomography (CT) radiomics.
The data of 173 NSCLC patients were collected retrospectively and the clinically meaningful 3-year survival was used as the predictive limit to predict the patient's prognosis survival time range. Firstly, lung tumors were segmented and the radiomics features were extracted. Secondly, the feature weighting algorithm was used to screen and optimize the extracted original feature data. Then, the selected feature data combining with the prognosis survival of patients were used to train machine learning classification models. Finally, a prognostic survival prediction model and radiomics prognostic factors were obtained to predict the prognosis survival time range of NSCLC patients.
The classification accuracy rate under cross-validation was up to 88.7% in the prognosis survival analysis model. When verifying on an independent data set, the model also yielded a high prediction accuracy which is up to 79.6%. Inverse different moment, lobulation sign and angular second moment were NSCLC prognostic factors based on radiomics.
This study proved that CT radiomics features could effectively assist doctors to make more accurate prognosis survival prediction for NSCLC patients, so as to help doctors to optimize treatment and re-examination for NSCLC patients to extend their survival time.","non-small cell lung cancer,CT radiomics features,prognostic survival prediction model,prognostic factors",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"PULMONARY,NODULES,AIDED,DIAGNOSIS,FEATURE-SELECTION,FEATURES,CLASSIFICATION,SEGMENTATION,TEXTURE,COMBINATION,SURVIVAL,ENTROPY",PHYSICS IN MEDICINE AND BIOLOGY,,
28,"Coupling in situ experiments and modeling - Opportunities for data fusion, machine learning, and discovery of emergent behavior",24,1,,Sangid Michael D.,Sangid MD,Sangid MD,10.1016/j.cossms.2019.100797,Purdue University System,"This paper reviews recent studies, that not only includes both experiments and modeling components, but celebrates a close coupling between these techniques, in order to provide insights into the plasticity and failure of polycrystalline metals. Examples are provided of studies across multiple-scales, including, but not limited to, density functional theory combined with atom probe tomography, molecular dynamics combined with in situ transmission electron miscopy, discrete dislocation dynamics combined with nanopillars experiments, crystal plasticity combined with digital image correlation, and crystal plasticity combined with in situ high energy X-ray diffraction. The close synergy between in situ experiments and modeling provides new opportunities for model calibration, verification, and validation, by providing direct means of comparison, thus removing aspects of epistemic uncertainty in the approach. Further, data fusion between in situ experimental and model-based data, along with data driven approaches, provides a paradigm shift for determining the emergent behavior of deformation and failure, which is the foundation that underpins the mechanical behavior of polycrystalline materials.","Microstructure modeling,Molecular dynamics,In situ transmission electron microscopy,Dislocation dynamics,Crystal plasticity,Digital image correlation,In situ high energy X-ray diffraction microscopy,Artificial intelligence,Data driven approaches",Review,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Materials Science,Physics",,10.362,"DISCRETE,DISLOCATION,DYNAMICS,ENERGY,DIFFRACTION,MICROSCOPY,X-RAY-DIFFRACTION,SCANNING-ELECTRON-MICROSCOPY,CRYSTAL,PLASTICITY,PARAMETERS,FINITE-ELEMENT,SIMULATIONS,DIGITAL,IMAGE,CORRELATION,FATIGUE-CRACK,INITIATION,MATERIALS,DATA,SCIENCE,SINGLE-CRYSTAL",CURRENT OPINION IN SOLID STATE & MATERIALS SCIENCE,https://www.sciencedirect.com/science/article/am/pii/S1359028619301214,
29,Real-Time Localization of Epileptogenic Foci EEG Signals: An FPGA-Based Implementation,10,3,,"Frances-Villora Jose V.,Bataller-Mompean Manuel,Mjahad Azeddine,Rosado-Munoz Alfredo,Gutierrez Martin Antonio,Teruel-Marti Vicent,Villanueva Vicente,Hampel Kevin G.,Guerrero-Martinez Juan F.","Frances-Villora JV,Bataller-Mompean M,Mjahad A,Rosado-Munoz A,Martin AG,Teruel-Marti V,Villanueva V,Hampel KG,Guerrero-Martinez JF",Frances-Villora JV,10.3390/app10030827,University of Valencia,"The epileptogenic focus is a brain area that may be surgically removed to control of epileptic seizures. Locating it is an essential and crucial step prior to the surgical treatment. However, given the difficulty of determining the localization of this brain region responsible of the initial seizure discharge, many works have proposed machine learning methods for the automatic classification of focal and non-focal electroencephalographic (EEG) signals. These works use automatic classification as an analysis tool for helping neurosurgeons to identify focal areas off-line, out of surgery, during the processing of the huge amount of information collected during several days of patient monitoring. In turn, this paper proposes an automatic classification procedure capable of assisting neurosurgeons online, during the resective epilepsy surgery, to refine the localization of the epileptogenic area to be resected, if they have doubts. This goal requires a real-time implementation with as low a computational cost as possible. For that reason, this work proposes both a feature set and a classifier model that minimizes the computational load while preserving the classification accuracy at 95.5%, a level similar to previous works. In addition, the classification procedure has been implemented on a FPGA device to determine its resource needs and throughput. Thus, it can be concluded that such a device can embed the whole classification process, from accepting raw signals to the delivery of the classification results in a cost-effective Xilinx Spartan-6 FPGA device. This real-time implementation begins providing results after a 5 s latency, and later, can deliver floating-point classification results at 3.5 Hz rate, using overlapped time-windows.","electroencephalogram,epileptic EEG signal classification,epilepsy,epileptogenic focus,real-time implementation,FPGA",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"AUTOMATIC,DETECTION,SEIZURE,DETECTION,INTERICTAL,EEG,LOG,ENERGY,CLASSIFICATION,DEFINITION,FEATURES,SPIKES,SYSTEM,EMD",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/3/827/pdf,
30,Rapid and Nondestructive Discrimination of Geographical Origins of Longjing Tea using Hyperspectral Imaging at Two Spectral Ranges Coupled with Machine Learning Methods,10,3,,"Hong Zhiqi,He Yong","Hong ZQ,He Y",He Y,10.3390/app10031173,Zhejiang University,"Longjing tea is one of China's protected geographical indication products with high commercial and nutritional value. The geographical origin of Longjing tea is an important factor influencing its commercial and nutritional value. Hyperspectral imaging systems covering the two spectral ranges of 380-1030 nm and 874-1734 nm were used to identify a single tea leaf of Longjing tea from six geographical origins. Principal component analysis (PCA) was conducted on hyperspectral images to form PCA score images. Differences among samples from different geographical origins were visually observed from the PCA score images. Support vector machine (SVM) and partial least squares discriminant analysis (PLS-DA) models were built using the full spectra at the two spectral ranges. Decent classification performances were obtained at the two spectral ranges, with the overall classification accuracy of the calibration and prediction sets over 84%. Furthermore, prediction maps for geographical origins identification of Longjing tea were obtained by applying the SVM models on the hyperspectral images. The overall results illustrate that hyperspectral imaging at both spectral ranges can be applied to identify the geographical origin of single tea leaves of Longjing tea. This study provides a new, rapid, and non-destructive alternative for Longjing tea geographical origins identification.","hyperspectral imaging,Longjing tea,geographical origins,support vector machine,prediction maps",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"NEAR-INFRARED,SPECTROSCOPY,GREEN,TEA,COMPONENTS,QUALITY",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/3/1173/pdf,
31,Cross-Domain Data Augmentation for Deep-Learning-Based Male Pelvic Organ Segmentation in Cone Beam CT,10,3,,"Leger Jean,Brion Eliott,Desbordes Paul,De Vleeschouwer Christophe,Lee John A.,Macq Benoit","Leger J,Brion E,Desbordes P,De Vleeschouwer C,Lee JA,Macq B",Leger J; Macq B,10.3390/app10031154,Universite Catholique Louvain,"For prostate cancer patients, large organ deformations occurring between radiotherapy treatment sessions create uncertainty about the doses delivered to the tumor and surrounding healthy organs. Segmenting those regions on cone beam CT (CBCT) scans acquired on treatment day would reduce such uncertainties. In this work, a 3D U-net deep-learning architecture was trained to segment bladder, rectum, and prostate on CBCT scans. Due to the scarcity of contoured CBCT scans, the training set was augmented with CT scans already contoured in the current clinical workflow. Our network was then tested on 63 CBCT scans. The Dice similarity coefficient (DSC) increased significantly with the number of CBCT and CT scans in the training set, reaching 0.874 +/- 0.096, 0.814 +/- 0.055, and 0.758 +/- 0.101 for bladder, rectum, and prostate, respectively. This was about 10% better than conventional approaches based on deformable image registration between planning CT and treatment CBCT scans, except for prostate. Interestingly, adding 74 CT scans to the CBCT training set allowed maintaining high DSCs, while halving the number of CBCT scans. Hence, our work showed that although CBCT scans included artifacts, cross-domain augmentation of the training set was effective and could rely on large datasets available for planning CT scans.","segmentation,deep-learning,deformable image registration,cone beam CT,pelvis,prostate cancer,radiotherapy,CNN,U-net",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"DEFORMABLE,IMAGE,REGISTRATION,BLADDER,SEGMENTATION,CONTOUR,PROPAGATION,PROTON,THERAPY,PLANNING,CT,CANCER,CBCT,HYBRID",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/3/1154/pdf,
32,Machine Learning and DWI Brain Communicability Networks for Alzheimer's Disease Detection,10,3,,"Lella Eufemia,Lombardi Angela,Amoroso Nicola,Diacono Domenico,Maggipinto Tommaso,Monaco Alfonso,Bellotti Roberto,Tangaro Sabina","Lella E,Lombardi A,Amoroso N,Diacono D,Maggipinto T,Monaco A,Bellotti R,Tangaro S",Lombardi A,10.3390/app10030934,Istituto Nazionale di Fisica Nucleare (INFN),"Signal processing and machine learning techniques are changing the clinical practice based on medical imaging from many perspectives. A major topic is related to (i) the development of computer aided diagnosis systems to provide clinicians with novel, non-invasive and low-cost support-tools, and (ii) to the development of new methodologies for the analysis of biomedical data for finding new disease biomarkers. Advancements have been recently achieved in the context of Alzheimer's disease (AD) diagnosis through the use of diffusionweighted imaging (DWI) data. When combined with tractography algorithms, this imaging modality enables the reconstruction of the physical connections of the brain that can be subsequently investigated through a complex network-based approach. A graph metric particularly suited to describe the disruption of the brain connectivity due to AD is communicability. In this work, we develop a machine learning framework for the classification and feature importance analysis of AD based on communicability at the whole brain level. We fairly compare the performance of three state-of-the-art classification models, namely support vector machines, random forests and artificial neural networks, on the connectivity networks of a balanced cohort of healthy control subjects and AD patients from the ADNI database. Moreover, we clinically validate the information content of the communicability metric by performing a feature importance analysis. Both performance comparison and feature importance analysis provide evidence of the robustness of the method. The results obtained confirm that the whole brain structural communicability alterations due to AD are a valuable biomarker for the characterization and investigation of pathological conditions.","computer aided diagnosis,Alzheimer's disease,machine learning,brain connectivity",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"CONNECTIVITY,CLASSIFICATION,TRACTOGRAPHY,SCALE,SEGMENTATION,THALAMUS,CORTEX,ONSET",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/3/934/pdf,
33,A Deep-Learning Approach for Diagnosis of Metastatic Breast Cancer in Bones from Whole-Body Scans,10,3,,"Papandrianos Nikolaos,Papageorgiou Elpiniki,Anagnostis Athanasios,Feleki Anna","Papandrianos N,Papageorgiou E,Anagnostis A,Feleki A",Papandrianos N,10.3390/app10030997,"Univ Thessaly, Nursing Dept, Lamia 35100, Greece.","(1) Background: Bone metastasis is one of the most frequent diseases in breast, lung and prostate cancer; bone scintigraphy is the primary imaging method of screening that offers the highest sensitivity (95%) regarding metastases. To address the considerable problem of bone metastasis diagnosis, focused on breast cancer patients, artificial intelligence methods devoted to deep-learning algorithms for medical image analysis are investigated in this research work; (2) Methods: Deep learning is a powerful algorithm for automatic classification and diagnosis of medical images whereas its implementation is achieved by the use of convolutional neural networks (CNNs). The purpose of this study is to build a robust CNN model that will be able to classify images of whole-body scans in patients suffering from breast cancer, depending on whether or not they are infected by metastasis of breast cancer; (3) Results: A robust CNN architecture is selected based on CNN exploration performance for bone metastasis diagnosis using whole-body scan images, achieving a high classification accuracy of 92.50%. The best-performing CNN method is compared with other popular and well-known CNN architectures for medical imaging like ResNet50, VGG16, MobileNet, and DenseNet, reported in the literature, providing superior classification accuracy; and (4) Conclusions: Prediction results show the efficacy of the proposed deep learning approach in bone metastasis diagnosis for breast cancer patients in nuclear medicine.","bone metastasis,breast cancer,whole body,scintigraphy,deep learning,image classification,convolutional neural networks",Article; Proceedings Paper,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"COMPUTER-AIDED,DIAGNOSIS,CONVOLUTIONAL,NEURAL-NETWORKS,EMISSION-TOMOGRAPHY,PROSTATE-CANCER,SCINTIGRAPHY,PET,CLASSIFICATION,SYSTEM,DISEASE,DETECT",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/3/997/pdf,
34,Gait Recognition via Deep Learning of the Center-of-Pressure Trajectory,10,3,,Terrier Philippe,Terrier P,Terrier P,10.3390/app10030774,"HES SO Univ Appl Sci & Arts Western Switzerland, Haute Ecole Arc Sante, CH-2000 Neuchatel, Switzerland.","The fact that every human has a distinctive walking style has prompted a proposal to use gait recognition as an identification criterion. Using end-to-end learning, I investigated whether the center-of-pressure (COP) trajectory is sufficiently unique to identify a person with high certainty. Thirty-six adults walked for 30 min on a treadmill equipped with a force platform that continuously recorded the positions of the COP. The raw two-dimensional signals were sliced into segments of two gait cycles. A set of 20,250 segments from 30 subjects was used to configure and train convolutional neural networks (CNNs). The best CNN classified a separate set containing 2250 segments with an overall accuracy of 99.9%. A second set of 4500 segments from the six remaining subjects was then used for transfer learning. Several small subsamples of this set were selected randomly and used to fine tune the pretrained CNNs. Training with two segments per subject was sufficient to achieve 100% accuracy. The results suggest that every person produces a unique trajectory of underfoot pressures while walking and that CNNs can learn the distinctive features of these trajectories. By applying a pretrained CNN (transfer learning), a couple of strides seem enough to learn and identify new gaits. However, these promising results should be confirmed in a larger sample under realistic conditions.","biometric recognition,footstep recognition,user verification,force platform,neural networks,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"TREADMILL,WALKING,PLANTAR,PRESSURE,PARAMETERS,IDENTIFICATION,REPEATABILITY,FLUCTUATIONS,CHILDREN",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/3/774/pdf,
35,Smart Multi-Sensor Monitoring in Drilling of CFRP/CFRP Composite Material Stacks for Aerospace Assembly Applications,10,3,,"Teti Roberto,Segreto Tiziana,Caggiano Alessandra,Nele Luigi","Teti R,Segreto T,Caggiano A,Nele L",Teti R,10.3390/app10030758,University of Naples Federico II,"Composite material parts are typically laid out in near-net-shape, i.e., very close to the finished product configuration. However, further machining processes are often required to meet dimensional and tolerance requirements. Drilling, edge trimming and slotting are the main cutting processes employed for carbon fiber-reinforced plastic (CFRP) composite materials. In particular, drilling stands out as the most widespread machining process of CFRP composite parts, chiefly in the aerospace industrial sector, due to the extensive use of mechanical joints, such as rivets, rather than welded or bonded joints. However, CFRP drilling is markedly challenging: due to CFRP abrasiveness, inhomogeneity and anisotropic properties, tool wear rates are inherently high leading to superior cutting forces and detrimental effects on workpiece surface quality and material integrity. Damage such as delamination, cracks or matrix thermal degradation is often observed as the result of uncontrolled tool wear or improper machining conditions. Sensor monitoring of drilling operations is, therefore, highly desirable for process conditions' optimization and tool life maximization. The development of this kind of automated control technologies for process and tool state evaluation can notably contribute to the reduction of scraps and tool costs as well as to the improvement of process productivity in the drilling of CFRP composite material parts. In this paper, multi-sensor process monitoring based on thrust force and torque signal detection and analysis was applied during drilling of CFRP/CFRP laminate stacks for the assembly of aircraft fuselage panels with the scope to evaluate the tool wear state. Different signal-processing methods were utilised to extract diverse types of features from the detected sensor signals. A machine-learning approach based on an artificial neural network (ANN) was implemented to make smart decisions on the timely execution of tool change, which is highly functional for CFRP drilling process automation.","stack drilling,CFRP/CFRP laminates,multiple sensor monitoring,tool wear evaluation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"THRUST,FORCE,CFRP,DELAMINATION,PERFORMANCE",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/3/758/pdf,
36,A High-Performance Deep Learning Algorithm for the Automated Optical Inspection of Laser Welding,10,3,,"Yang Yatao,Pan Longhui,Ma Junxian,Yang Runze,Zhu Yishuang,Yang Yanzhao,Zhang Li","Yang YT,Pan LH,Ma JX,Yang RZ,Zhu YS,Yang YZ,Zhang L",Zhang L,10.3390/app10030933,Shenzhen University,"The battery industry has been growing fast because of strong demand from electric vehicle and power storage applications. Laser welding is a key process in battery manufacturing. To control the production quality, the industry has a great desire for defect inspection of automated laser welding. Recently, Convolutional Neural Networks (CNNs) have been applied with great success for detection, recognition, and classification. In this paper, using transfer learning theory and pre-training approach in Visual Geometry Group (VGG) model, we proposed the optimized VGG model to improve the efficiency of defect classification. Our model was applied on an industrial computer with images taken from a battery manufacturing production line and achieved a testing accuracy of 99.87%. The main contributions of this study are as follows: (1) Proved that the optimized VGG model, which was trained on a large image database, can be used for the defect classification of laser welding. (2) Demonstrated that the pre-trained VGG model has small model size, lower fault positive rate, shorter training time, and prediction time; so, it is more suitable for quality inspection in an industrial environment. Additionally, we visualized the convolutional layer and max-pooling layer to make it easy to view and optimize the model.","automatic optical inspection,defect classification,optimized VGG model,laser welding,convolutional neural networks (CNNs)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,CLASSIFICATION,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/3/933/pdf,
37,An Intelligent Classification Model for Surface Defects on Cement Concrete Bridges,10,3,,"Zhu Jinsong,Song Jinbo","Zhu JS,Song JB",Zhu JS,10.3390/app10030972,Tianjin University,"This paper mainly improves the visual geometry group network-16 (VGG-16), which is a classic convolutional neural network (CNN), to classify the surface defects on cement concrete bridges in an accurate manner. Specifically, the number of fully connected layers was reduced by one, and the Softmax classifier was replaced with a Softmax classification layer with seven defect tags. The weight parameters of convolutional and pooling layers were shared in the pre-trained model, and the rectified linear unit (ReLU) function was taken as the activation function. The original images were collected by a road inspection vehicle driving across bridges on national and provincial highways in Jiangxi Province, China. The images on surface defects of cement concrete bridges were selected, and divided into a training set and a test set, and preprocessed through morphology-based weight adaptive denoising. To verify its performance, the improved VGG-16 was compared with traditional shallow neural networks (NNs) like the backpropagation neural network (BPNN), support vector machine (SVM), and deep CNNs like AlexNet, GoogLeNet, and ResNet on the same sample dataset of surface defects on cement concrete bridges. Judging by mean detection accuracy and top-5 accuracy, our model outperformed all the contrastive methods, and accurately differentiated between images with seven classes of defects such as normal, cracks, fracturing, plate fracturing, corner rupturing, edge/corner exfoliation, skeleton exposure, and repairs. The results indicate that our model can effectively extract the multi-layer features from surface defect images, which highlights the edges and textures. The research findings shed important new light on the detection of surface defects and classification of defect images.","transfer learning,bridge defects,convolutional neural network (CNN),intelligent classification",Article; Proceedings Paper,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"NEURAL-NETWORK,CRACK,DETECTION,RECOGNITION,VISION",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/3/972/pdf,
38,Monitoring of Huntington's Disease Based on Wireless Sensing Technology,10,3,,"Zhu Qiyu,Guan Lei,Khan Muhammad Bilal,Yang Xiaodong","Zhu QY,Guan L,Khan MB,Yang XD",Yang XD,10.3390/app10030870,Xidian University,"Huntington's disease (HD) is a rare genetic disorder that cannot be cured by current medical techniques. With the development of the disease, the life of patients will become more and more difficult. It is necessary to timely and effectively evaluate the development of the patient's condition based on the patient's clinical symptoms to help doctors to formulate a reasonable and effective treatment plan, alleviate the condition, and improve the quality of life, which reflects humane care. Currently, wearable devices or video surveillance are generally used to monitor the patients, and these schemes have some disadvantages. This paper presents a new method to monitor patients with HD using wireless sensing technology. Firstly, experimental data were collected by the self-developed microwave sensing platform (MSP), and then the data were preprocessed. Finally, support vector machine (SVM) and random forest (RF) algorithms were used to train the model. The MSP system continuously monitors patients in a non-contact way, which will not bring inconvenience to patients' lives, and will not involve privacy issues. The experimental results show that the prediction accuracy of SVM can be as high as 98.0% and that of RF can be as high as 96.7%, which proves the feasibility of the technical scheme described in this paper.","HD,MSP,RF,SVM,wireless sensing technology",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/3/870/pdf,
39,Machine-Learning Assisted Prediction of Spectral Power Distribution for Full-Spectrum White Light-Emitting Diode,12,1,,"Fan Jiajie,Li Yutong,Fryc Irena,Qian Cheng,Fan Xuejun,Zhang Guoqi","Fan JJ,Li YT,Fryc I,Qian C,Fan XJ,Zhang GQ",Fan JJ,10.1109/JPHOT.2019.2962818,Hohai University,"The full-spectrum white light-emitting diode (LED) emits light with a broad wavelength range by mixing all lights from multiple LED chips and phosphors. Thus, it has great potentials to be used in healthy lighting, high resolution displays, plant lighting with higher color rendering index close to sunlight and higher color fidelity index. The spectral power distribution (SPD) of light source, representing its light quality, is always dynamically controlled by complex electrical and thermal loadings when the light source operates under usage conditions. Therefore, a dynamic prediction of SPD for the full-spectrum white LED has become a hot but challenging research topic in the high quality lighting design and application. This paper proposes a dynamic SPD prediction method for the full-spectrum white LED by integrating the SPD decomposition approach with the artificial neural network (ANN) based machine learning method. Firstly, the continuous SPDs of a full-spectrum white LED driven by an electrical-thermal loading matrix are discretized by the multi-peak fitting with Gaussian model as the relevant spectral characteristic parameters. Then, the Back Propagation (BP) and Genetic Algorithm-Back Propagation (GA-BP) NNs are proposed to predict the spectral characteristic parameters of LEDs operated under any usage conditions. Finally, the dynamically predicted spectral characteristic parameters are used to reconstruct the SPDs. The results show that: (1) The spectral characteristic parameters obtained by fitting with the Gaussian model can be used to represent the emission lights from multiple chips and phosphors in a full-spectrum white LED; (2) The prediction errors of both BP NN and GA-BP NN can be controlled at low level, that is to say, our proposed method can achieve a highly accurate SPD dynamic prediction for the full-spectrum white LED when it operates under different operation mission profiles.","Full-spectrum white LED,spectral power distribution,BP neural network,genetic algorithm,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Optics,Physics",,2.602,"ARTIFICIAL,NEURAL-NETWORK,CLASSIFICATION,CANCER",IEEE PHOTONICS JOURNAL,https://ieeexplore.ieee.org/ielx7/4563994/8951187/08945382.pdf,
40,Towards large-scale mapping of local climate zones using multitemporal Sentinel 2 data and convolutional neural networks,237,,,"Rosentreter Johannes,Hagensieker Ron,Waske Bjoern","Rosentreter J,Hagensieker R,Waske B",Rosentreter J,10.1016/j.rse.2019.111472,University Osnabruck,"In recent years, the concept of Local Climate Zones (LCZs) has become a new standard in the research of urban landscapes. LCZs outline a classification scheme, which is designed to categorize urban and rural surfaces according to their climate-relevant properties, irrespective of local building materials or cultural background. We present a novel workflow for a high-resolution derivation of LCZs using multi-temporal Sentinel 2 (S2) composites and supervised Convolutional Neural Networks (CNNs). We assume that CNNs, due to their potential invariance to size and illumination of objects, are best suited to predict the highly context-based LCZs on a large scale. As a first step, the proposed workflow includes a fully automated generation of cloud-free S2 composites. These composites serve as training data basis for the LCZ classifications carried out over eight German cities. Results show that by using a CNN, overall accuracies can be increased by an average of 16.5 and 4.8 percentage points when compared to a pixel-based and a texture-based Random Forest approach, respectively. If sufficient training data is available, CNN models proved to be robust in classifying unknown cities and achieved overall accuracies of up to 86.5%. The proposed method constitutes a feasible approach for automated, large scale mapping of LCZs, and could be the preferred alternative for LCZ classifications in upcoming studies.","Local climate zones,Convolutional neural network,Sentinel 2",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Environmental Sciences & Ecology,Remote Sensing,Imaging Science & Photographic Technology",,11.057,"URBAN,HEAT-ISLAND,LAND-USE,TIME-SERIES,CLASSIFICATION,TEMPERATURE,WUDAPT,COVER,VARIABILITY,DESIGN,ENERGY",REMOTE SENSING OF ENVIRONMENT,,
41,Designing a multi-quantum-dot-doped wavelength down-shifting model of c-Si solar cells by using machine learning,59,4,985-990,"Ren Binjie,Jiang Chun","Ren BJ,Jiang C",Jiang C,10.1364/AO.381558,Shanghai Jiao Tong University,"The efficiency of solar cell energy conversion may be significantly improved by better exploitation of the original solar spectrum. In this paper, we propose a multi-quantum-dot-doped wavelength down-shifting (WDS) model that can reduce the energy loss resulting from the mismatch between the solar spectrum and the solar cell material's responsivity. The WDS layer can nearly perfectly absorb the photons in the range of 300 to 700 nm and then re-emit them at a longer wavelength. The distribution of quantum dots in the WDS layer is provided based on analysis of its spectral properties with a machine learning regression algorithm. Finally, the relationship between the optimizing ability of the model and the Stokes shift of the quantum dots is also discussed. Ideally, our model can provide up to 29% improvement to the external quantum efficiency of c-Si solar cells, which fully demonstrates the potential of our model. (C) 2020 Optical Society of America","EFFICIENCY,SPECTRUM,INCIDENT,LAYERS",Article,"OPTICAL SOC AMER, 2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA",Optics,,1.943,"EFFICIENCY,SPECTRUM,INCIDENT,LAYERS",APPLIED OPTICS,,
42,Computational Design of Rare-Earth Reduced Permanent Magnets,6,2,148-153,"Kovacs Alexander,Fischbacher Johann,Gusenbauer Markus,Oezelt Harald,Herper Heike C.,Vekilova Olga Yu,Nieves Pablo,Arapan Sergiu,Schrefl Thomas","Kovacs A,Fischbacher J,Gusenbauer M,Oezelt H,Herper HC,Vekilova OY,Nieves P,Arapan S,Schrefl T",Schrefl T,10.1016/j.eng.2019.11.006,Danube University Krems,"Multiscale simulation is a key research tool in the quest for new permanent magnets. Starting with first principles methods, a sequence of simulation methods can be applied to calculate the maximum possible coercive field and expected energy density product of a magnet made from a novel magnetic material composition. Iron (Fe)-rich magnetic phases suitable for permanent magnets can be found by means of adaptive genetic algorithms. The intrinsic properties computed by ab intro simulations are used as input for micromagnetic simulations of the hysteresis properties of permanent magnets with a realistic structure. Using machine learning techniques, the magnet's structure can be optimized so that the upper limits for coercivity and energy density product for a given phase can be estimated. Structure property relations of synthetic permanent magnets were computed for several candidate hard magnetic phases. The following pairs (coercive field (T), energy density product (kJ.m(-3))) were obtained for iron-tin-antimony (Fe3Sn0.75Sb0.25): (0.49, 290), L1(0) -ordered iron-nickel (L1(0) FeNi): (1, 400), cobalt-iron-tantalum (CoFe6Ta): (0.87, 425), and manganese-aluminum (MnAl): (0.53, 80). (C) 2020 THE AUTHORS. Published by Elsevier LTD on behalf of Chinese Academy of Engineering and Higher Education Press Limited Company.","Rare-earth,Permanent magnets,Micromagnetics",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Engineering,,8.977,,ENGINEERING,http://arxiv.org/pdf/1903.11995,
43,Ensemble of fine-tuned convolutional neural networks for urine sediment microscopic image classification,14,1,18-25,"Liu Wenqian,Li Weihong,Gong Weiguo","Liu WQ,Li WH,Gong WG",Li WH,10.1049/iet-cvi.2018.5829,Chongqing University,"In this study, an ensemble of fine-tuned convolutional neural networks (CNNs) is proposed. As CNN training requires large annotated data, which are lacking in the field of urine sediment microscopic image processing, the authors first pre-trained the CNNs, including ResNet50 and GoogLeNet, and developed AlexNet on an ImageNet dataset. Thereafter, some of the weights of the pre-trained CNNs were transferred to the urine sediment microscopic image dataset. To guide fine-tuning of the learning rate and cascading features, the hierarchical nature of features in different convolutional layers was investigated by visualising the CNN. Then, they combined three CNNs as an ensemble of CNNs to decrease the differences and impurity interference among features of urine sediment microscopic image. These fusion features were employed to train the fully connected neural network for classification. In this study, they improved the accuracy of each CNN by an average of 2.2% through fine-tuning of the learning rate and cascading features. Moreover, the better experimental results were achieved compared with other state-of-the-art methods and indicated that a 97% classification accuracy can be attained.","image classification,medical image processing,feature extraction,learning (artificial intelligence),convolutional neural nets,urine sediment microscopic image processing,pre-trained CNNs,urine sediment microscopic image dataset,learning rate,cascading features,convolutional layers,fully connected neural network,fine-tuned convolutional neural networks,urine sediment microscopic image classification,CNN training,impurity interference,classification accuracy",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Computer Science,Engineering",,1.911,DIAGNOSIS,IET COMPUTER VISION,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-cvi.2018.5829,
44,Deep Learning for EEG-Based Preference Classification in Neuromarketing,10,4,,"Aldayel Mashael,Ykhlef Mourad,Al-Nafjan Abeer","Aldayel M,Ykhlef M,Al-Nafjan A",Aldayel M,10.3390/app10041525,King Saud University,"The traditional marketing methodologies (e.g., television commercials and newspaper advertisements) may be unsuccessful at selling products because they do not robustly stimulate the consumers to purchase a particular product. Such conventional marketing methods attempt to determine the attitude of the consumers toward a product, which may not represent the real behavior at the point of purchase. It is likely that the marketers misunderstand the consumer behavior because the predicted attitude does not always reflect the real purchasing behaviors of the consumers. This research study was aimed at bridging the gap between traditional market research, which relies on explicit consumer responses, and neuromarketing research, which reflects the implicit consumer responses. The EEG-based preference recognition in neuromarketing was extensively reviewed. Another gap in neuromarketing research is the lack of extensive data-mining approaches for the prediction and classification of the consumer preferences. Therefore, in this work, a deep-learning approach is adopted to detect the consumer preferences by using EEG signals from the DEAP dataset by considering the power spectral density and valence features. The results demonstrated that, although the proposed deep-learning exhibits a higher accuracy, recall, and precision compared with the k-nearest neighbor and support vector machine algorithms, random forest reaches similar results to deep learning on the same dataset.","neuromarketing,brain computer interface (BCI),consumer preferences,EEG signal,deep learning,deep neural network (DNN)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"ELECTROENCEPHALOGRAM,EEG,BUYING,DECISIONS,BRAIN,RESPONSES,NEUROSCIENCE,CATEGORIZATION,ASYMMETRY,AROUSAL,SIGNALS,PATTERN,IMPACT",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/4/1525/pdf,
45,Spinal Cord Segmentation in Ultrasound Medical Imagery,10,4,,"Benjdira Bilel,Ouni Kais,Al Rahhal Mohamad M.,Albakr Abdulrahman,Al-Habib Amro,Mahrous Emad","Benjdira B,Ouni K,Al Rahhal MM,Albakr A,Al-Habib A,Mahrous E",Benjdira B,10.3390/app10041370,Prince Sultan University,"In this paper, we study and evaluate the task of semantic segmentation of the spinal cord in ultrasound medical imagery. This task is useful for neurosurgeons to analyze the spinal cord movement during and after the laminectomy surgical operation. Laminectomy is performed on patients that suffer from an abnormal pressure made on the spinal cord. The surgeon operates by cutting the bones of the laminae and the intervening ligaments to relieve this pressure. During the surgery, ultrasound waves can pass through the laminectomy area to give real-time exploitable images of the spinal cord. The surgeon uses them to confirm spinal cord decompression or, occasionally, to assess a tumor adjacent to the spinal cord. The Freely pulsating spinal cord is a sign of adequate decompression. To evaluate the semantic segmentation approaches chosen in this study, we constructed two datasets using images collected from 10 different patients performing the laminectomy surgery. We found that the best solution for this task is Fully Convolutional DenseNets if the spinal cord is already in the train set. If the spinal cord does not exist in the train set, U-Net is the best. We also studied the effect of integrating inside both models some deep learning components like Atrous Spatial Pyramid Pooling (ASPP) and Depthwise Separable Convolution (DSC). We added a post-processing step and detailed the configurations to set for both models.","ultrasound,deep learning,laminectomy,spinal cord,spinal cord pulsation,Convolutional Neural Networks (CNN),Densenet,semantic segmentation,medical image segmentation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,NETWORKS,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/4/1370/pdf,
46,Comparative Study on Supervised Learning Models for Productivity Forecasting of Shale Reservoirs Based on a Data-Driven Approach,10,4,,"Han Dongkwon,Jung Jihun,Kwon Sunil","Han D,Jung J,Kwon S",Kwon S,10.3390/app10041267,Dong A University,"Due to the rapid development of shale gas, a system has been established that can utilize a considerable amount of data using the database system. As a result, many studies using various machine learning techniques were carried out to predict the productivity of shale gas reservoirs. In this study, a comprehensive analysis is performed for a machine learning method based on data-driven approaches that evaluates productivity for shale gas wells by using various parameters such as hydraulic fracturing and well completion in Eagle Ford shale gas field. Two techniques are used to improve the performance of the productivity prediction machine learning model developed in this study. First, the optimal input variables were selected by using the variables importance method (VIM). Second, cluster analysis was used to analyze the similarities in the datasets and recreate the machine learning models for each cluster to compare the training and test results. To predict productivity, we used random forest (RF), gradient boosting tree (GBM), and support vector machine (SVM) supervised learning models. Compared to other supervised learning models, RF, which is applied with the VIM, has the best prediction performance. The retraining model through cluster analysis has excellent predictive performance. The developed model and prediction workflow are considered useful for reservoir engineers planning of field development plan.","shale gas,machine learning,data-driven,variables importance method,clustering analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"GAS,WELL",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/4/1267/pdf,
47,"Algorithm for Detecting Characteristic Points on a Three-Dimensional, Whole-Body Human Scan",10,4,,"Kozbial Michal,Markiewicz Lukasz,Sitnik Robert","Kozbial M,Markiewicz L,Sitnik R",Sitnik R,10.3390/app10041342,Warsaw University of Technology,"Anthropometric landmarks obtained from three-dimensional (3D) body scans are widely used in medicine, civil engineering, and virtual reality. For all those fields, an acquisition of certain and accurate landmark positions is crucial for obtaining satisfying results. Manual marking is time-consuming and is affected by the subjectivity of the human operator. Therefore, an automatic approach has become increasingly popular. This paper provides a short survey of different attempts for automatic landmark localization, from which one machine learning-based method was further analyzed and extended in the case of input data preparation for a convolutional neural network (CNN). A novel method of data processing is presented which utilize a mid-surface projection followed by further unwrapping. The article emphasizes its significance and the way it affects the outcome of a deep neural network. The workflow and the detailed description of algorithms used are included in this paper. To validate the method, it was compared with the orthogonal projection used for the state-of-the-art approach. Datasets consisting of 200 specimens, acquired using both methods, were used for convolutional neural networks training and 20 for validation. In this paper, we used YOLO v.3 architecture for detection and ResNet-152 for classification. For each approach, localizations of 22 normalized body landmarks for 10 male and 10 female subjects of different ages and various postures were obtained. To compare the accuracy of approaches, errors and their distribution were measured for each characteristic point. Experiments confirmed that the mid-surface projections resulted, on average, in a 14% accuracy improvement and up to 15% enhancement of resistance on errors related to scan imperfections.","landmark,detection,localization,mid surface,characteristic point,3D scan,convolutional neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"3D,LANDMARKING",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/4/1342/pdf,
48,Unrepeatered 240-km 64-QAM Transmission Using Distributed Raman Amplification over SMF Fiber,10,4,,"Rosa P.,Rizzelli G.,Pang X.,Ozolins O.,Udalcovs A.,Tan M.,Jaworski M.,Marciniak M.,Sergeyev S.,Schatz R.","Rosa P,Rizzelli G,Pang X,Ozolins O,Udalcovs A,Tan M,Jaworski M,Marciniak M,Sergeyev S,Schatz R",Rosa P,10.3390/app10041433,National Institute of Telecommunications - Poland,"We present a theoretical and experimental investigation of unrepeatered transmission over standard single-mode fiber (SMF-28) using several schemes of distributed Raman amplification, including first, second, and dual order. In order to further extend the transmission distance, we utilize advanced bidirectional higher-order ultra-long Raman fiber laser-based amplification, where we use fiber Bragg gratings (FBGs) to reflect Stokes-shifted light from the secondary pumps. Our work demonstrates the possibility of transmission up to 240-km span length with a total span loss of 52.7 dB. Here, we use a 28-Gbaud signal using a 64-quadrature amplitude modulation (QAM) modulation format. Our results highlight the contribution of nonlinear compensation using digital back propagation in a digital signal processor (DSP) code at the receiver.","distributed Raman amplification,digital backpropagation,unrepeatered 64-QAM transmission",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://publications.aston.ac.uk/id/eprint/41363/1/applsci_10_01433_v2.pdf,
49,X-Ray Bone Fracture Classification Using Deep Learning: A Baseline for Designing a Reliable Approach,10,4,,"Tanzi Leonardo,Vezzetti Enrico,Moreno Rodrigo,Moos Sandro","Tanzi L,Vezzetti E,Moreno R,Moos S",Tanzi L,10.3390/app10041507,Polytechnic University of Turin,"In recent years, bone fracture detection and classification has been a widely discussed topic and many researchers have proposed different methods to tackle this problem. Despite this, a universal approach able to classify all the fractures in the human body has not yet been defined. We aim to analyze and evaluate a selection of papers, chosen according to their representative approach, where the authors applied different deep learning techniques to classify bone fractures, in order to select the strengths of each of them and try to delineate a generalized strategy. Each study is summarized and evaluated using a radar graph with six values: area under the curve (AUC), test accuracy, sensitivity, specificity, dataset size and labelling reliability. Plus, we defined the key points which should be taken into account when trying to accomplish this purpose and we compared each study with our baseline. In recent years, deep learning and, in particular, the convolution neural network (CNN), has achieved results comparable to those of humans in bone fracture classification. Adopting a correct generalization, we are reasonably sure that a computer-aided diagnosis (CAD) system, correctly designed to assist doctors, would save a considerable amount of time and would limit the number of wrong diagnoses.","deep learning,X-ray,neural network,bone fracture,orthopedics,CAD system",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"ARTIFICIAL-INTELLIGENCE,RELIABILITY",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/4/1507/pdf,
50,Developing a Novel Machine Learning-Based Classification Scheme for Predicting SPCs in Colorectal Cancer Survivors,10,4,,"Ting Wen-Chien,Chang Horng-Rong,Chang Chi-Chang,Lu Chi-Jie","Ting WC,Chang HR,Chang CC,Lu CJ",Chang HR,10.3390/app10041355,Chung Shan Medical University,"Colorectal cancer is ranked third and fourth in terms of mortality and cancer incidence in the world. While advances in treatment strategies have provided cancer patients with longer survival, potentially harmful second primary cancers can occur. Therefore, second primary colorectal cancer analysis is an important issue with regard to clinical management. In this study, a novel predictive scheme was developed for predicting the risk factors associated with second colorectal cancer in patients with colorectal cancer by integrating five machine learning classification techniques, including support vector machine, random forest, multivariate adaptive regression splines, extreme learning machine, and extreme gradient boosting. A total of 4287 patients in the datasets provided by three hospital tumor registries were used. Our empirical results revealed that this proposed predictive scheme provided promising classification results and the identification of important risk factors for predicting second colorectal cancer based on accuracy, sensitivity, specificity, and area under the curve metrics. Collectively, our clinical findings suggested that the most important risk factors were the combined stage, age at diagnosis, BMI, surgical margins of the primary site, tumor size, sex, regional lymph nodes positive, grade/differentiation, primary site, and drinking behavior. Accordingly, these risk factors should be monitored for the early detection of second primary tumors in order to improve treatment and intervention strategies.","risk factors,second primary cancer (SPC),colorectal cancer,machine learning,classification techniques,extreme gradient boosting",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,RECURRENCE,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/4/1355/pdf,
51,A Comprehensive Peach Fruit Quality Evaluation Method for Grading and Consumption,10,4,,"Zhang Guoxiang,Fu Qiqi,Fu Zetian,Li Xinxing,Matetic Maja,Bakaric Marija Brkic,Jemric Tomislav","Zhang GX,Fu QQ,Fu ZT,Li XX,Matetic M,Bakaric MB,Jemric T",Fu ZT,10.3390/app10041348,China Agricultural University,"Peaches are a popular fruit appreciated by consumers due to their eating quality. Quality evaluation of peaches is important for their processing, inventory control, and marketing. Eleven quality indicators (shape index, volume, mass, density, firmness, color, impedance, phase angle, soluble solid concentration, titratable acidity, and sugar-acid ratio) of 200 peach fruits (Prunus persica (L.) Batsch ""Spring Belle"") were measured within 48 h. Quality indicator data were normalized, outliers were excluded, and correlation analysis showed that the correlation coefficients between dielectric properties and firmness were the highest. A back propagation (BP) neural network was used to predict the firmness of fresh peaches based on their dielectric properties, with an overall fitting ratio of 86.9%. The results of principal component analysis indicated that the cumulative variance of the first five principal components was 85%. Based on k-means clustering analysis, normalized data from eleven quality indicators in 190 peaches were classified into five clusters. The proportion of red surface area was shown to be a poor basis for picking fresh peaches for the consumer market, as it bore little relationship with the comprehensive quality scores calculated using the new grading model.","peaches,dielectric property,BP neural network model,principal component analysis,comprehensive evaluation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"ELECTRICAL-IMPEDANCE,IMPLEMENTATION,SPECTROSCOPY,MATURITY,VISION,SYSTEM",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/4/1348/pdf,
52,Monitoring of cellulose oxidation level by electrokinetic phenomena and numeric prediction model,27,6,3107-3119,"Tarbuk Anita,Grgic Katia,Toshikj Emilija,Domovic Daniel,Dimitrovski Dejan,Dimova Vesna,Jordanov Igor","Tarbuk A,Grgic K,Toshikj E,Domovic D,Dimitrovski D,Dimova V,Jordanov I",Tarbuk A,10.1007/s10570-020-03028-6,University of Zagreb,"Cellulose with a low level of oxidation is suitable for producing stable long-lasting materials with high added value, while extensively oxidized once is applicable for disposable products. In our previous comprehensive research, the fundamental behavior of the cotton under the action of different oxidants has been explored. Different levels of oxidation, as well as the type of functional groups, have been achieved by properly selected oxidants while controlling their concentration and treatment time. In this research, the electrokinetic zeta-potential of KIO4 and TEMPO-oxidized cotton and the isoelectric point are measured by the streaming potential method, while the surface charge is calculated from the adsorbed cationic surfactant by the back-titration method. The results of electrokinetic phenomena are compared with the amount of created carboxyl groups determined by the calcium acetate method. The machine learning algorithms Waikato Environment for Knowledge Analysis for regression analysis is employed to develop models that make numeric predictions of the zeta-potential values based on the known number of carboxyl groups. The model with the correlation coefficient between the actual and the predicted value of zeta-potential is given for the first time. Graphic abstract","Cotton,Oxidation system,Electrokinetic phenomena,Machine learning",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Materials Science,Polymer Science",,5.271,"TEMPO-MEDIATED,OXIDATION,NATIVE,CELLULOSE,COTTON,CELLULOSE,OXIDIZED,COTTON,CATIONIZATION,ACCESSIBILITY,FIBERS",CELLULOSE,,
53,Dynamic Prediction in Clinical Survival Analysis Using Temporal Convolutional Networks,24,2,424-436,"Jarrett Daniel,Yoon Jinsung,van der Schaar Mihaela","Jarrett D,Yoon J,van der Schaar M",Jarrett D,10.1109/JBHI.2019.2929264,University of Oxford,"Accurate prediction of disease trajectories is critical for early identification and timely treatment of patients at risk. Conventional methods in survival analysis are often constrained by strong parametric assumptions and limited in their ability to learn from high-dimensional data. This paper develops a novel convolutional approach that addresses the drawbacks of both traditional statistical approaches as well as recent neural network models for survival. We present Match-Net: a missingness-aware temporal convolutional hitting-time network, designed to capture temporal dependencies and heterogeneous interactions in covariate trajectories and patterns of missingness. To the best of our knowledge, this is the first investigation of temporal convolutions in the context of dynamic prediction for personalized risk prognosis. Using real-world data from the Alzheimer's disease neuroimaging initiative, we demonstrate state-of-the-art performance without making any assumptions regarding underlying longitudinal or time-to-event processes-attesting to the model's potential utility in clinical decision support.","Alzheimer's disease neuroimaging initiative,dynamic prediction,survival analysis,temporal convolutions",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"ALZHEIMERS-DISEASE,COX,REGRESSION,MODELS,PROGRESSION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
54,Thorax-Net: An Attention Regularized Deep Neural Network for Classification of Thoracic Diseases on Chest Radiography,24,2,475-485,"Wang Hongyu,Jia Haozhe,Lu Le,Xia Yong","Wang HY,Jia HZ,Lu L,Xia Y",Xia Y,10.1109/JBHI.2019.2928369,Northwestern Polytechnical University,"Deep learning techniques have been increasingly used to provide more accurate and more accessible diagnosis of thorax diseases on chest radiographs. However, due to the lack of dense annotation of large-scale chest radiograph data, this computer-aided diagnosis task is intrinsically a weakly supervised learning problem and remains challenging. In this paper, we propose a novel deep convolutional neural network called Thorax-Net to diagnose 14 thorax diseases using chest radiography. Thorax-Net consists of a classification branch and an attention branch. The classification branch serves as a uniform feature extraction-classification network to free users from the troublesome hand-crafted feature extraction and classifier construction. The attention branch exploits the correlation between class labels and the locations of pathological abnormalities via analyzing the feature maps learned by the classification branch. Feeding a chest radiograph to the trained Thorax-Net, a diagnosis is obtained by averaging and binarizing the outputs of two branches. The proposed Thorax-Net model has been evaluated against three state-of-the-art deep learning models using the patientwise official split of the ChestX-ray14 dataset and against other five deep learning models using the imagewise random data split. Our results show that Thorax-Net achieves an average per-class area under the receiver operating characteristic curve (AUC) of 0.7876 and 0.896 in both experiments, respectively, which are higher than the AUC values obtained by other deep models when they were all trained with no external data.","Thorax disease classification,deep learning,attention mechanism,weakly supervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
55,LSTM-Based ECG Classification for Continuous Monitoring on Personal Wearable Devices,24,2,515-523,"Saadatnejad Saeed,Oveisi Mohammadhosein,Hashemi Matin","Saadatnejad S,Oveisi M,Hashemi M",Hashemi M,10.1109/JBHI.2019.2911367,Sharif University of Technology,"A novel electrocardiogram (ECG) classification algorithm is proposed for continuous cardiac monitoring on wearable devices with limited processing capacity. The proposed solution employs a novel architecture consisting of wavelet transform and multiple long short-term memory (LSTM) recurrent neural networks. Experimental evaluations show superior ECG classification performance compared to previous works. Measurements on different hardware platforms show the proposed algorithm meets timing requirements for continuous and real-time execution on wearable devices. In contrast to many compute-intensive deep-learning based approaches, the proposed algorithm is lightweight, and therefore, brings continuous monitoring with accurate LSTM-based ECG classification to wearable devices. The proposed algorithm is both accurate and lightweight. The source code is available online at http://lis.ee.sharif.edu.","Continuous cardiac monitoring,electrocardiogram (ECG) classification,machine learning,long short-term memory (LSTM),embedded and wearable devices",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"RECURRENT,NEURAL-NETWORKS,WAVELET,TRANSFORM,TIME,DISCRIMINATION,MORPHOLOGY,MODEL",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://arxiv.org/pdf/1812.04818,
56,A Hybrid Global-Local Representation CNN Model for Automatic Cataract Grading,24,2,556-567,"Xu Xi,Zhang Linglin,Li Jianqiang,Guan Yu,Zhang Li","Xu X,Zhang LL,Li JQ,Guan Y,Zhang L",Li JQ,10.1109/JBHI.2019.2914690,Beijing University of Technology,"Cataract is one of the most serious eye diseases leading to blindness. Early detection and treatment can reduce the rate of blindness in cataract patients. However, the professional knowledge of ophthalmologists is necessary for the clinical cataract detection. Therefore, the potential costs may make it difficult for the widespread use of cataract detection to prevent blindness. Artificial intelligence assisted diagnosis based on medical images has attracted more and more attention of researchers. Many studies have focused on the use of pre-defined feature sets for cataract classification, but the predefined feature sets may be incomplete or redundant. On account of the aforementioned issues, some studies have proposed deep learning methods to automatically extract image features, but all based on global features and none has analyzed the layer-by-layer transformation process of the middle-tier features. This paper uses convolutional neural networks (CNN) to learn useful features directly from input data, and deconvolution network method is employed to investigate how CNN characterizes cataract layer-by-layer. We found that compared to the global feature set, the detail vascular information, which is lost after multi-layer convolution calculation also plays an important role in cataract grading task. And this finding fits with the morphological definition of fundus image. Through the finding, we gained insights into the design of hybrid global-local feature representation model to improve the recognition performance of automatic cataract grading.","Cataract grading,convolutional neural network,deconvolution network,hybrid global-local representation model",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"DIAGNOSIS,FEATURES,SYSTEM",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
57,Automatic Scale Severity Assessment Method in Psoriasis Skin Images Using Local Descriptors,24,2,577-585,"George Yasmeen,Aldeen Mohammad,Garnavi Rahil","George Y,Aldeen M,Garnavi R",George Y,10.1109/JBHI.2019.2910883,University of Melbourne,"Psoriasis is a chronic skin condition. Its clinical assessment involves four measures: erythema, scales, induration, and area. In this paper, we introduce a scale severity scoring framework for two-dimensional psoriasis skin images. Specifically, we leverage the bag-of-visual words (BoVWs) model for lesion feature extraction using superpixels as key points. BoVWs model is based on building a vocabulary with specific number of words (i.e., codebook size) by using a clustering algorithm with some local features extracted from a constructed set of key points. This is followed by three-class machine learning classifiers for scale scoring using support vector machine (SVM) and random forest. Besides, we examine eight different local color and texture descriptors, namely color histogram, local binary patterns, edge histogram descriptor, color layout descriptor, scalable color descriptor, color and edge directivity descriptor (CEDD), fuzzy color and texture histogram, and brightness and texture directionality histogram. Further, the selection of codebook and superpixel sizes are studied intensively. A psoriasis image set, consisting of 96 images, is used in this study. The conducted experiments show that color descriptors have the highest performance measures for scale severity scoring. This is followed by the combined color and texture descriptors, whereas texture-based descriptors come last. Moreover-means algorithm shows better results in vocabulary building than Gaussian mixed model, in terms of accuracy and computations time. Finally, the proposed method yields a scale severity scoring accuracy of using the following setup: a superpixel of size , a combined color and texture descriptor (i.e., CEDD), a constructed codebook of size 128 using means, and SVM for scale scoring.","Psoriasis image analysis,PASI assessment,scale severity scoring,local feature extraction,bag of visual words",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"CLASSIFICATION,COLOR",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
58,Use of a Tracer-Specific Deep Artificial Neural Net to Denoise Dynamic PET Images,39,2,366-376,"Klyuzhin Ivan S.,Cheng Ju-Chieh,Bevington Connor,Sossi Vesna","Klyuzhin IS,Cheng JC,Bevington C,Sossi V",Klyuzhin IS,10.1109/TMI.2019.2927199,University of British Columbia,"Application of kinetic modeling (KM) on a voxel level in dynamic PET images frequently suffers from high levels of noise, drastically reducing the precision of parametric image analysis. In this paper, we investigate the use of machine learning and artificial neural networks to denoise dynamic PET images. We train a deep denoising autoencoder (DAE) using noisy and noise-free spatiotemporal image patches, extracted from the simulated images of [C-11]raclopride, a dopamine D-2 receptor agonist. The DAE-processed dynamic and corresponding parametric images (simulated and acquired) are compared with those obtained with conventional denoising techniques, including temporal and spatial Gaussian smoothing, iterative spatiotemporal smoothing/deconvolution, and the highly constrained wbackprojection processing (HYPR). The simulated (acquired) parametric image non-uniformity was 7.75% (19.49%) with temporal and 5.90% (14.50%) with spatial smoothing, 5.82% (16.21%) with smoothing/deconvolution, 5.49% (13.38%) with HYPR, and 3.52% (11.41%) with DAE. The DAE also produced the best results in terms of the coefficient of variation of voxel values and structural similarity index. Denoising- induced bias in the regionalmean binding potential was 7.8% with temporal and 26.31% with spatial smoothing, 28.61% with smoothing/deconvolution, 27.63% with HYPR, and 14.8% with DAE. When the test data did not match the training data, erroneousoutcomeswere obtained. Our results demonstrate that a deep DAE can provide a substantial reduction in the voxel-level noise compared with the conventional spatiotemporal denoising methods while introducing a similar or lower amount of bias. The better DAE performance comes at the cost of lower generality and requiring appropriate training data.","Dynamic PET,denoising,neural network,machine learning,deep learning,kinetic modeling",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"RECONSTRUCTION,NETWORK",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
59,k-Space Deep Learning for Accelerated MRI,39,2,377-386,"Han Yoseob,Sunwoo Leonard,Ye Jong Chul","Han Y,Sunwoo L,Ye JC",Ye JC,10.1109/TMI.2019.2927101,Korea Advanced Institute of Science & Technology (KAIST),"The annihilating filter-based low-rank Hankel matrix approach (ALOHA) is one of the state-of-the-art compressed sensing approaches that directly interpolates the missing k-space data using low-rank Hankelmatrix completion. The success of ALOHA is due to the concise signal representation in the k-space domain, thanks to the duality between structured low-rankness in the k-space domain and the image domain sparsity. Inspired by the recent mathematical discovery that links convolutional neural networks to Hankel matrix decomposition using data-driven framelet basis, here we propose a fully data-driven deep learning algorithm for k-space interpolation. Our network can be also easily applied to non-Cartesian k-space trajectories by simply adding an additional regridding layer. Extensive numerical experiments show that the proposed deep learningmethod consistently outperforms the existing image-domain deep learning approaches.","Compressed sensing MRI,deep learning,Hankel structured low-rank completion,convolution framelets",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"RECONSTRUCTION,FRAMEWORK,NETWORK",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1805.03779,
60,Vertebrae Identification and Localization Utilizing Fully Convolutional Networks and a Hidden Markov Model,39,2,387-399,"Chen Yizhi,Gao Yunhe,Li Kang,Zhao Liang,Zhao Jun","Chen YZ,Gao YH,Li K,Zhao L,Zhao J",Zhao J,10.1109/TMI.2019.2927289,Shanghai Jiao Tong University,"Automated identification and localization of vertebrae in spinal computed tomography (CT) imaging is a complicated hybrid task. This task requires detecting and indexing a long sequence in a 3-D image, and both image feature extraction and sequence modeling are needed to address the problem. In this paper, the powerful fully convolutional neural network (FCN) technique performs both of these tasks simultaneously because FCNs directly encode and decode the spatial interdependence of different components in images. The key module of our proposed framework is a 3-D FCN trained in an end-to-end manner at the spine level to capture the long-range contextual information in CT volumes. The large increase in the calculation due to the full-size image inputs is alleviated by the scale-down of the inputs and the use of an auxiliary FCN to compensate for the loss of details. The composite network pipeline design enables the integration of local image details and global image patterns. Furthermore, explicit spatial and sequential constraints are imposed by the hidden Markov model (HMM) for a higher robustness and a clearer interpretation of network outputs. The proposed framework is quantitatively evaluated on the public dataset from the MICCAI 2014 Computational Challenge on Vertebrae Localization and Identification and demonstrates an identification rate (within 20 mm) of 94.67 a mean identification rate of 87.97 and a mean error distance of 2.56 mm on the test set, thus achieving the highest performance reported on this dataset.","Automatic vertebrae identification and localization,CT image,deep learning,convolutional neural network,fully convolutional network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"SEGMENTATION,IMAGE",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
61,A Large-Scale Database and a CNN Model for Attention-Based Glaucoma Detection,39,2,413-424,"Li Liu,Xu Mai,Liu Hanruo,Li Yang,Wang Xiaofei,Jiang Lai,Wang Zulin,Fan Xiang,Wang Ningli","Li L,Xu M,Liu HR,Li Y,Wang XF,Jiang L,Wang ZL,Fan X,Wang NL",Xu M,10.1109/TMI.2019.2927226,Beihang University,"Glaucoma is one of the leading causes of irreversible vision loss. Many approaches have recently been proposed for automatic glaucoma detection based on fundus images. However, none of the existing approaches can efficiently remove high redundancy in fundus images for glaucoma detection, which may reduce the reliability and accuracy of glaucoma detection. To avoid this disadvantage, this paper proposes an attention-based convolutional neural network (CNN) for glaucoma detection, called AG-CNN. Specifically, we first establish a large-scale attention-based glaucoma (LAG) database, which includes 11 760 fundus images labeled as either positive glaucoma (4878) or negative glaucoma (6882). Among the 11 760 fundus images, the attention maps of 5824 images are further obtained from ophthalmologists through a simulated eye-tracking experiment. Then, a new structure of AG-CNN is designed, including an attention prediction subnet, a pathological area localization subnet, and a glaucoma classification subnet. The attention maps are predicted in the attention prediction subnet to highlight the salient regions for glaucoma detection, under a weakly supervised training manner. In contrast to other attention-based CNN methods, the features are also visualized as the localized pathological area, which are further added in our AG-CNN structure to enhance the glaucoma detection performance. Finally, the experiment results from testing over our LAG database and another public glaucoma database show that the proposed AG-CNN approach significantly advances the state-of-the-art in glaucoma detection.","Glaucoma detection,attention mechanism,pathological area detection,weakly supervised",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"DIABETIC-RETINOPATHY,LEARNING,ALGORITHM,DEEP,DIAGNOSIS,VALIDATION,DISEASES,VISION,BURDEN",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
62,Automatic Cataract Classification Using Deep Neural Network With Discrete State Transition,39,2,436-446,"Zhou Yue,Li Guoqi,Li Huiqi","Zhou Y,Li GQ,Li HQ",Li HQ,10.1109/TMI.2019.2928229,Beijing Institute of Technology,"Cataract is the clouding of lens, which affects vision and it is the leading cause of blindness in the world's population. Accurate and convenient cataract detection and cataract severity evaluation will improve the situation. Automatic cataract detection and grading methods are proposed in this paper. With prior knowledge, the improved Haar features and visible structure features are combined as features, and multilayer perceptron with discrete state transition (DST-MLP) or exponential DST (EDST-MLP) are designed as classifiers. Without prior knowledge, residual neural networks with DST (DST-ResNet) or EDST (EDST-ResNet) are proposed. Whether with prior knowledge or not, our proposed DST and EDST strategy can prevent overfitting and reduce storage memory during network training and implementation, and neural networks with these strategies achieve state-of-the-art accuracy in cataract detection and grading. The experimental results indicate that combined features always achieve better performance than a single type of feature, and classification methods with feature extraction based on prior knowledge are more suitable for complicated medical image classification task. These analyses can provide constructive advice for other medical image processing applications.","Cataract classification,discrete ResNet,exponential discrete state transition (EDST),retinal image",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"RETINAL,IMAGES,FUNDUS,IMAGES,DIAGNOSIS,VESSELS,SYSTEM",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
63,3D APA-Net: 3D Adversarial Pyramid Anisotropic Convolutional Network for Prostate Segmentation in MR Images,39,2,447-457,"Jia Haozhe,Xia Yong,Song Yang,Zhang Donghao,Huang Heng,Zhang Yanning,Cai Weidong","Jia HZ,Xia Y,Song Y,Zhang DH,Huang H,Zhang YN,Cai WD",Xia Y,10.1109/TMI.2019.2928056,Northwestern Polytechnical University,"Accurate and reliable segmentation of the prostate gland using magnetic resonance (MR) imaging has critical importance for the diagnosis and treatment of prostate diseases, especially prostate cancer. Although many automated segmentation approaches, including those based on deep learning have been proposed, the segmentation performance still has room for improvement due to the large variability in image appearance, imaging interference, and anisotropic spatial resolution. In this paper, we propose the 3D adversarial pyramid anisotropic convolutional deep neural network (3D APA-Net) for prostate segmentation in MR images. This model is composed of a generator (i.e., 3D PA-Net) that performs image segmentation and a discriminator (i.e., a six-layer convolutional neural network) that differentiates between a segmentation result and its corresponding ground truth. The 3D PA-Net has an encoder-decoder architecture, which consists of a 3D ResNet encoder, an anisotropic convolutional decoder, and multi-level pyramid convolutional skip connections. The anisotropic convolutional blocks can exploit the 3D context information of the MR images with anisotropic resolution, the pyramid convolutional blocks address both voxel classification and gland localization issues, and the adversarial training regularizes 3D PA-Net and thus enables it to generate spatially consistent and continuous segmentation results. We evaluated the proposed 3D APA-Net against several state-of-the-art deep learning-based segmentation approaches on two public databases and the hybrid of the two. Our results suggest that the proposed model outperforms the compared approaches on three databases and could be used in a routine clinical workflow.","Prostate segmentation,deep learning,adversarial training,magnetic resonance imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"LEVEL,FIELD,SHAPE",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
64,Deep Learning of Static and Dynamic Brain Functional Networks for Early MCI Detection,39,2,478-487,"Kam Tae-Eui,Zhang Han,Jiao Zhicheng,Shen Dinggang","Kam TE,Zhang H,Jiao ZC,Shen DG",Zhang H; Shen DG,10.1109/TMI.2019.2928790,University of North Carolina,"While convolutional neural network (CNN) has been demonstrating powerful ability to learn hierarchical spatial features from medical images, it is still difficult to apply it directly to resting-state functional MRI (rs-fMRI) and the derived brain functional networks (BFNs). We propose a novel CNN framework to simultaneously learn embedded features from BFNs for brain disease diagnosis. Since BFNs can be built by considering both static and dynamic functional connectivity (FC), we first decompose rs-fMRI into multiple static BFNs with modified independent component analysis. Then, the voxel-wise variability in dynamic FC is used to quantify BFN dynamics. A set of paired 3D images representing static/dynamic BFNs can be fed into 3D CNNs, from which we can hierarchically and simultaneously learn static/dynamic BFN features. As a result, the dynamic BFN features can complement static BFN features and, at the meantime, different BFNs can help each other toward a joint and better classification. We validate our method with a publicly accessible, large cohort of rs-fMRI dataset in early-stage mild cognitive impairment (eMCI) diagnosis, which is one of the most challenging problems to the clinicians. By comparing with a conventional method, our method shows significant diagnostic performance improvement by almost. This result demonstrates the effectiveness of deep learning in preclinical Alzheimers disease diagnosis, based on the complex and high-dimensional voxel-wise spatiotemporal patterns of the resting-state brain functional connectomics. The framework provides a new but intuitive way to fully exploit deeply embedded diagnostic features from rs-fMRI for a better-individualized diagnosis of various neurological diseases.","Diagnosis,convolutional neural networks,brain network,independent component analysis,mild cognitive impairment,deep learning,resting state,functional MRI",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"MILD,COGNITIVE,IMPAIRMENT,ALZHEIMERS-DISEASE,PREFRONTAL,CORTEX,CONNECTIVITY,CLASSIFICATION,THALAMUS,ATROPHY,MODEL,ICA",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7122732,
65,Reducing the Hausdorff Distance in Medical Image Segmentation With Convolutional Neural Networks,39,2,499-513,"Karimi Davood,Salcudean Septimiu E.","Karimi D,Salcudean SE",Karimi D,10.1109/TMI.2019.2930068,University of British Columbia,"The Hausdorff Distance (HD) is widely used in evaluating medical image segmentation methods. However, the existing segmentation methods do not attempt to reduce HD directly. In this paper, we present novel loss functions for training convolutional neural network (CNN)-based segmentation methods with the goal of reducing HD directly. We propose three methods to estimate HD from the segmentation probability map produced by a CNN. One method makes use of the distance transform of the segmentation boundary. Another method is based on applying morphological erosion on the difference between the true and estimated segmentation maps. The third method works by applying circular/spherical convolution kernels of different radii on the segmentation probability maps. Based on these three methods for estimating HD, we suggest three loss functions that can be used for training to reduce HD. We use these loss functions to train CNNs for segmentation of the prostate, liver, and pancreas in ultrasound, magnetic resonance, and computed tomography images and compare the results with commonly-used loss functions. Our results show that the proposed loss functions can lead to approximately reduction in HD without degrading other segmentation performance criteria such as the Dice similarity coefficient. The proposed loss functions can be used for training medical image segmentation methods in order to reduce the large segmentation errors.","Hausdorff distance,loss functions,medical image segmentation,convolutional neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"ALGORITHMS,ATLAS",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1904.10030,
66,Recurrent Saliency Transformation Network for Tiny Target Segmentation in Abdominal CT Scans,39,2,514-525,"Xie Lingxi,Yu Qihang,Zhou Yuyin,Wang Yan,Fishman Elliot K.,Yuille Alan L.","Xie LX,Yu QH,Zhou YY,Wang Y,Fishman EK,Yuille AL",Wang Y,10.1109/TMI.2019.2930679,Johns Hopkins University,"We aim at segmenting a wide variety of organs, including tiny targets (e.g., adrenal gland), and neoplasms (e.g., pancreatic cyst), from abdominal CT scans. This is a challenging task in two aspects. First, some organs (e.g., the pancreas), are highly variable in both anatomy and geometry, and thus very difficult to depict. Second, the neoplasms often vary a lot in its size, shape, as well as its location within the organ. Third, the targets (organs and neoplasms) can be considerably small compared to the human body, and so standard deep networks for segmentation are often less sensitive to these targets and thus predict less accurately especially around their boundaries. In this paper, we present an end-to-end framework named recurrent saliency transformation network (RSTN) for segmenting tiny and/or variable targets. The RSTN is a coarse-to-fine approach that uses prediction from the first (coarse) stage to shrink the input region for the second (fine) stage. A saliency transformation module is inserted between these two stages so that 1) the coarse-scaled segmentation mask can be transferred as spatial weights and applied to the fine stage and 2) the gradients can be back-propagated from the loss layer to the entire network so that the two stages are optimized in a joint manner. In the testing stage, we perform segmentation iteratively to improve accuracy. In this extended journal paper, we allow a gradual optimization to improve the stability of the RSTN, and introduce a hierarchical version named H-RSTN to segment tiny and variable neoplasms such as pancreatic cysts. Experiments are performed on several CT datasets including a public pancreas segmentation dataset, our own multi-organ dataset, and a cystic pancreas dataset. In all these cases, the RSTN outperforms the baseline (a stage-wise coarse-to-fine approach) significantly. Confirmed by the radiologists in our team, these promising segmentation results can help early diagnosis of pancreatic cancer. The code and pre-trained models of our project were made available at https:// github.com/198808xc/OrganSegRSTN.","Semantic segmentation,abdominal CT scan,deep neural network,coarse-to-fine,saliency transformation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"KIDNEY,SEGMENTATION,LIVER",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
67,"Cytokeratin-Supervised Deep Learning for Automatic Recognition of Epithelial Cells in Breast Cancers Stained for ER, PR, and Ki-67",39,2,534-542,"Valkonen Mira,Isola Jorma,Ylinen Onni,Muhonen Ville,Saxlin Anna,Tolonen Teemu,Nykter Matti,Ruusuvuori Pekka","Valkonen M,Isola J,Ylinen O,Muhonen V,Saxlin A,Tolonen T,Nykter M,Ruusuvuori P",Ruusuvuori P,10.1109/TMI.2019.2933656,Tampere University,"Immunohistochemistry (IHC) of ER, PR, and Ki-67 are routinely used assays in breast cancer diagnostics. Determination of the proportion of stained cells (labeling index) should be restricted on malignant epithelial cells, carefully avoiding tumor infiltrating stroma and inflammatory cells. Here, we developed a deep learning based digital mask for automated epithelial cell detection using fluoro-chromogenic cytokeratin-Ki-67 double staining and sequential hematoxylin-IHC staining as training material. A partially pre-trained deep convolutional neural network was fine-tuned using image batches from 152 patient samples of invasive breast tumors. Validity of the trained digital epithelial cell masks was studied with 366 images captured from 98 unseen samples, by comparing the epithelial cell masks to cytokeratin images and by visual evaluation of the brightfield images performed by two pathologists. A good discrimination of epithelial cells was achieved (AUC of mean ROC = 0.93; defined as the area under mean receiver operating characteristics), and well in concordance with pathologists' visual assessment (4.01/5 and 4.67/5). The effect of epithelial cell masking on the Ki-67 labeling index was substantial. 52 tumor images initially classified as low proliferation (Ki-67 < 14%) without epithelial cell masking were re-classified as high proliferation (Ki-67 < 14%) after applying the deep learning based epithelial cell mask. The digital epithelial cell masks were found applicable also to IHC of ER and PR. We conclude that deep learning can be applied to detect carcinoma cells in breast cancer samples stained with conventional brightfield IHC.","Training,Deep learning,Breast cancer,Tumors,Immune system,Indexes,Convolutional neural networks,Deep learning,image segmentation,breast cancer,histopathology,digital pathology",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"IMAGE,CLASSIFICATION",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
68,AI-Skin: Skin disease recognition based on self-learning and wide data collection through a closed-loop framework,54,,1-9,"Chen Min,Zhou Ping,Wu Di,Hu Long,Hassan Mohammad Mehedi,Alamri Atif","Chen M,Zhou P,Wu D,Hu L,Hassan MM,Alamri A",Hu L,10.1016/j.inffus.2019.06.005,Huazhong University of Science & Technology,"There are a lot of hidden dangers in the change of human skin conditions, such as the sunburn caused by long-time exposure to ultraviolet radiation, which not only has aesthetic impact causing psychological depression and lack of self-confidence, but also may even be life-threatening due to skin canceration. Current skin disease researches adopt the auto-classification system for improving the accuracy rate of skin disease classification. However, the excessive dependence on the image sample database is unable to provide individualized diagnosis service for different population groups. To overcome this problem, a medical AI framework based on data width evolution and self-learning is put forward in this paper to provide skin disease medical service meeting the requirement of real time, extendibility and individualization. First, the wide collection of data in the close-loop information flow of user and remote medical data center is discussed. Next, a data set filter algorithm based on information entropy is given, to lighten the load of edge node and meanwhile improve the learning ability of remote cloud analysis model. In addition, the framework provides an external algorithm load module, which can be compatible with the application requirements according to the model selected. Three kinds of deep learning model, i.e., LeNet-5, AlexNet and VGG16, are loaded and compared, which have verified the universality of the algorithm load module. The experiment platform for the proposed real-time, individualized and extensible skin disease recognition system is built. And the system's computation and communication delay under the interaction scenario between tester and remote data center are analyzed. It is demonstrated that the system we put forward is reliable and effective.","Skin disease recognition,Data width evolution,Self-learning process,Deep learning model",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,12.707,"HEALTH-CARE-SYSTEM,DATA,FUSION,CLOUD,BODY,OPTIMIZATION,NETWORKS,COMPUTATION,DESIGN,STATE",INFORMATION FUSION,http://arxiv.org/pdf/1906.01895,
69,Integrating model- and data-driven methods for synchronous adaptive multi-band image fusion,54,,145-160,"Lin Suzhen,Han Ze,Li Dawei,Zeng Jianchao,Yang Xiaoli,Liu Xinwen,Liu Feng","Lin SZ,Han Z,Li DW,Zeng JC,Yang XL,Liu XW,Liu F",Lin SZ; Zeng JC,10.1016/j.inffus.2019.07.009,North University of China,"A novel synchronous adaptive framework for multi-band image fusion is proposed, based on integrated model-and data-driven (MDDR) techniques. This approach includes a deep stack convolutional neural network (DSCNN) for multi-band images, established by redefining convolutional kernels in the first layer using Gaussian and Gaussian-Laplace filters. The structure of the convolutional neural network (CNN) was improved by removing a sample CNN layer to reduce information loss, prior to decomposing and reconstructing input images in an adaptive framework. A deep gate convolution neural network (DGCNN) was then established using a gate structure principle common in long short-term memory (LSTM) techniques. As a result, the network can adaptively fuse high- and low-frequency components, similar to conventional image fusion rules in model-driven algorithms. Finally, a synchronous adaptive multi-band image fusion neural network (SAMIFNN) was constructed by embedding the DGCNN into decompose- and reconstruct-subnets in the DSCNN. Data from ImageNet IL SVRC2013 and TNO image fusion datasets were used for training (80%) and testing (20%). SAMIFNN was then compared with seven state-of-the-art methods applied to eight groups of representative images, the TRICLOBS dynamic multiband image dataset, and a series of medical CT, MR, and PET scans. The proposed network required significantly lower runtimes than conventional algorithms, producing satisfactory results across 21 different evaluation metrics (compared with a maximum of 15 achieved by conventional techniques). These experimental results demonstrate that the proposed algorithm can successfully implement synchronous adaptive multi-band image fusion with higher contrast, better visual perception, and less distortion, without requiring a priori knowledge or manual intervention.","Image fusion,Multi-band images,Deep learning,Model-driven,Data-driven,Adaptive fusion algorithm",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,12.707,"SIMILARITY,INDEX,VISUAL,TRACKING,FOCUS,NETWORKS,ENHANCEMENT,CONSTRAINT,TRANSFORM,ATTENTION,FRAMEWORK,LSTM",INFORMATION FUSION,,
70,Machine learning validation of EEG plus tACS artefact removal,17,1,,"Kohli Siddharth,Casson Alexander J.","Kohli S,Casson AJ",Casson AJ,10.1088/1741-2552/ab58a3,University of Manchester,"Objective. Electroencephalography (EEG) recorded during transcranial alternating current simulation (tACS) is highly desirable in order to investigate brain dynamics during stimulation, but is corrupted by large amplitude stimulation artefacts. Artefact removal algorithms have been presented previously, but with substantial debates on their performance, utility, and the presence of any residual artefacts. This paper investigates whether machine learning can be used to validate artefact removal algorithms. The postulation is that residual artefacts in the EEG after cleaning would be independent of the experiment performed, making it impossible to differentiate between different parts of an EEG+tACS experiment, or between different behavioural tasks performed. Approach. Ten participates undertook two tasks (nBack and backwards digital recall) during simultaneous EEG+tACS, exercising different aspects of working memory. Stimulations during no task and sham conditions were also performed. A previously reported tACS artefact removal algorithm from our group was used to clean the EEG and a linear discriminant analysis was trained on the cleaned EEG to differentiate different parts of the experiment. Main results. Baseline, baseline during tACS, working memory task without tACS, and working memory task with tACS data segments could be differentiated with accuracies ranging from 65%-94%, far exceeding chance levels. EEG from the nBack and backwards digital recall tasks could be separated during stimulation, with an accuracy exceeding 72%. If residual tACS artefacts remained after the EEG cleaning these did not dominate the classification process. Significance. This helps in building confidence that true EEG information is present after artefact removal. Our methodology presents a new approach to validating tACS artefact removal approaches.","EEG,tACS,artefact removal",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"CURRENT,STIMULATION,OSCILLATIONS,PERFORMANCE,SIGNALS",JOURNAL OF NEURAL ENGINEERING,https://www.research.manchester.ac.uk/portal/files/149709401/2019_machine_learning_validation.pdf,
71,Hidden Markov model-based activity recognition for toddlers,41,2,,"Albert Mark V,Sugianto Albert,Nickele Katherine,Zavos Patricia,Sindu Pinky,Ali Munazza,Kwon Soyang","Albert MV,Sugianto A,Nickele K,Zavos P,Sindu P,Ali M,Kwon S",Albert MV,10.1088/1361-6579/ab6ebb,University of North Texas System,"Objective: Physical activity has been shown to impact future health outcomes in adults, but little is known about the long-term impact of physical activity in toddlers. Accurately measuring the specific types and amounts of physical activity in toddlers will help us to understand, predict, and better affect their future health outcomes. Although activity recognition has been extensively developed for adults as well as older children, toddlers move in ways that are significantly different from older children, indicating the need for a more tailored approach. Approach: In this study, 22 toddlers wore Actigraph waist-worn accelerometers which recorded their movements during guided play. The toddlers were videotaped and their activities were later annotated for the following eight distinct activity classes: lying down, being carried, riding in a stroller, sitting, standing, running/walking, crawling, and climbing up/down. Accelerometer data were extracted in 2 s signal windows and paired with the activities the toddlers were performing during that time interval. Main results: A variety of classifiers were tuned to a validation set. A random forest classifier was found to achieve the highest accuracy of 63.8% in a test set. To improve the accuracy, a hidden Markov model (HMM) was applied by providing the predictions of the static classifiers as observations. The HMM was able to improve the accuracy to 64.8% with all five classifiers increasing the accuracy an average of 1.3% points (95% confidence interval = 0.7-1.9, p < 0.01). When the three most misclassified activities (sitting, standing, and riding in a stroller) were collapsed together, the accuracy increased to 79.3%. Significance: Further refinement of the toddler activity recognition classifier will enable more accurate measurements of toddler activity and improve future health outcomes of toddlers.","activity recognition,HMM,toddler",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"PHYSICAL-ACTIVITY,ACCELEROMETER,HIP,OBESITY",PHYSIOLOGICAL MEASUREMENT,https://doi.org/10.1088/1361-6579/ab6ebb,
72,Association between circadian Holter ECG changes and sudden cardiac death in patients with Chagas heart disease,41,2,,"Alberto Alex Chaves,Pedrosa Roberto Coury,Zarzoso Vicente,Nadal Jurandir","Alberto AC,Pedrosa RC,Zarzoso V,Nadal J",Nadal J,10.1088/1361-6579/ab6ebc,Universidade Federal do Rio de Janeiro,"Objective: Chagas disease (ChD) is a parasitic illness, largely spread over South America. ChD usually causes progressive myocardium damage, either by direct parasite action or through autoimmune response. Sudden cardiac death (SCD) is prevalent in the early disease stages, being associated with a high variety of ectopic cardiac beats. This study aims at applying heart rate variability (HRV) and heart rate turbulence (HRT) techniques over Holter electrocardiogram (ECG) records to investigate the association with SCD in Chagas heart disease (ChHD). Approach: From a retrospective evaluation of a local database, the Holter records from 78 outpatients (34 female) were divided into groups: SCD deaths (20) and alive patients (56). To consider circadian autonomic changes, the analysis was performed in three periods: (a) entire 24 h record, (b) 12 h daylight period, and (c) the remaining 12 h including night rest. Eight variables were extracted using HRV and HRT approaches from each record and analysed together with the left ventricular ejection fraction (LVEF) estimated by echocardiography. Main results: The set of parameters was reduced by both the forward- and backward-stepwise approach and classification was performed using the k-nearest neighbours method and a leave-one-out cross-validation in a set of ten bootstrap trials, where SCD data were randomly taken and repositioned to balance the groups. The best 24 h model predicted SCD with 89.9% +/- 0.9% accuracy using three HRV variables. The use of 12 h segments increased the accuracy up to 91.0% +/- 1.2% in a model with the standard deviation parameter measured during the day (SDNNday) and night (SDNNnight). Although considered as playing a major role in SCD, LVEF did not show an association with SCD in this sample. Significance: The degree of HRV and its circadian changes are associated with SCD in ChHD patients.","Holter ECG,Chagas heart disease,sudden cardiac death,heart rate variability,heart rate turbulence",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"RISK,STRATIFICATION,RATE,TURBULENCE,MORTALITY",PHYSIOLOGICAL MEASUREMENT,,
73,Identification of patients with atrial fibrillation: a big data exploratory analysis of the UK Biobank,41,2,,"Oster Julien,Hopewell Jemma C.,Ziberna Klemen,Wijesurendra Rohan,Camm Christian F.,Casadei Barbara,Tarassenko Lionel","Oster J,Hopewell JC,Ziberna K,Wijesurendra R,Camm CF,Casadei B,Tarassenko L",Tarassenko L,10.1088/1361-6579/ab6f9a,University of Oxford,"Objective: Atrial fibrillation (AF) is the most common cardiac arrhythmia, with an estimated prevalence of around 1.6% in the adult population. The analysis of the electrocardiogram (ECG) data acquired in the UK Biobank represents an opportunity to screen for AF in a large sub-population in the UK.
The main objective of this paper is to assess ten machine-learning methods for automated detection of subjects with AF in the UK Biobank dataset. Approach: Six classical machine-learning methods based on support vector machines are proposed and compared with state-of-the-art techniques (including a deep-learning algorithm), and finally a combination of a classical machine-learning and deep learning approaches. Evaluation is carried out on a subset of the UK Biobank dataset, manually annotated by human experts.
Main results: The combined classical machine-learning and deep learning method achieved an F1 score of 84.8% on the test subset, and a Cohen's kappa coefficient of 0.83, which is similar to the inter-observer agreement of two human experts.
Significance: The level of performance indicates that the automated detection of AF in patients whose data have been stored in a large database, such as the UK Biobank, is possible. Such automated identification of AF patients would enable further investigations aimed at identifying the different phenotypes associated with AF.","electrocardiogram,atrial fibrillation,biobank,big data,machine learning,signal processing",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"CARDIOVASCULAR-DISEASE,CLASSIFICATION",PHYSIOLOGICAL MEASUREMENT,https://ora.ox.ac.uk/objects/uuid:d3b3924a-4f23-43fd-a455-236a2156ceb2/download_file?safe_filename=AF_detection_UKBiobank_rev1b%2520%28002%29.pdf&type_of_work=Journal+article,
74,LUNG CANCER DETECTION FROM CT IMAGES USING SALP-ELEPHANT OPTIMIZATION-BASED DEEP LEARNING,32,1,,"Shanid Malayil,Anitha A.","Shanid M,Anitha A",Shanid M,10.4015/S1016237220500015,"Noorul Islam Ctr Higher Educ, Kumarakovil, Tamil Nadu, India.","Lung cancer detection has been a trending research area, as automating the medical diagnosis has significant benefits. Automatic identification of lung cancer from the CT images is considered as a significant technique in recent years. Even though various techniques are developed in the literature for lung cancer detection, designing an effective technique that can automatically detect lung cancer is challenging. Hence, this research aims to develop an automated lung cancer detection scheme through deep learning and hybrid optimization algorithm. Here, the CT images from the lung cancer database are pre-processed and provided to the lung segmentation, which is carried out by active contour. Then, the nodules in the segmented image are identified using the grid-based scheme. Several features, like intensity, wavelet, and scattering transform, are mined from the segmented image and given to the proposed salp-elephant herding optimization algorithm-based deep belief network (SEOA-DBN), for the classification. Here, SEOA is newly developed by considering the qualities of salp swarm algorithm (SSA) and elephant herding optimization (EHO). For the experimentation, lung CT images are considered from the standard database and compared with the various states of art techniques. From the results, it is evident that the proposed SEOA-based DBN achieved significant performance with 96% accuracy.","Lung cancer detection,Lung segmentation,Active contour,Deep learning,Salp swarm algorithm",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Engineering,,,"PULMONARY,NODULE,DETECTION,ALGORITHM,SYSTEM,CLASSIFICATION",BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS,,
75,Estimation of in-situ maximum horizontal principal stress magnitudes from borehole breakout data using machine learning,126,,,"Lin H.,Kang W. -H.,Oh J.,Canbulat I.","Lin H,Kang WH,Oh J,Canbulat I",Oh J,10.1016/j.ijrmms.2019.104199,University of New South Wales Sydney,"This paper presents a technique for in-situ horizontal stress prediction in vertical boreholes based on borehole breakout data using a machine learning-based meta-modelling technique, i.e. Kriging. This model is generated based on the deterministic mean function and a stationary Gaussian process function derived from the 106 data points from published experimental studies. To examine the reliability of the model, a leave-one-out cross-validation process is conducted against the published experimental results. The Kriging prediction gives an average error of 10.59% on maximum horizontal principal stress (sigma(H)). A total of 23 field data were also extracted from both literature and mine site A with stress measurements conducted at the similar depth. The model yields an average prediction error of 8.4% in comparison with field stress measurement results on sigma(H), which is remarkable considering its simplicity, reliability and low cost. This study limits the scope to sigma(H) estimation only due to the nature of the experimental setup, in which minimum horizontal principal stress (sigma(h)) values are often kept constant while changing sigma(H). This results in a lot of repetition sigma(h) values in training data and it makes the prediction of sigma(h) unreliable. By collecting a broader range of data on breakout geometries, stress magnitudes and the rock strength, it is expected that the accuracy and the parameter coverage of this technique can be further improved in practical conditions.","Borehole breakout,In-situ stress,Borehole wall strength,Machine learning,Kriging",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Engineering,Mining & Mineral Processing",,,"UNIAXIAL,COMPRESSIVE,STRENGTH,ROCK,STRENGTH,ORIENTATION,TELEVIEWER,VELOCITY,OFFSHORE,POROSITY,FRACTURE,FAILURE,PROJECT",INTERNATIONAL JOURNAL OF ROCK MECHANICS AND MINING SCIENCES,,
76,Ab lnitio Simulations and Materials Chemistry in the Age of Big Data,60,2,452-459,"Schleder Gabriel Ravanhani,Padilha Antonio Claudio M.,Rocha Alexandre Reily,Dalpian Gustavo Martini,Fazzio Adalberto","Schleder GR,Padilha ACM,Rocha AR,Dalpian GM,Fazzio A",Schleder GR; Fazzio A,10.1021/acs.jcim.9b00781,Universidade Federal do ABC (UFABC),"In this perspective, we discuss computational advances in the last decades, both in algorithms as well as in technologies, that enabled the development, widespread use, and maturity of simulation methods for molecular and materials systems. Such advances led to the generation of large amounts of data, which required the creation of several computational databases. Within this scenario, with the democratization of data access, the field now encounters several opportunities for data-driven approaches toward chemical and materials problems. Specifically, machine learning methods for predictions of novel materials or properties are being increasingly used with great success. However, black box usage fails in many instances; several technical details require expert knowledge in order for the predictions to be useful, such as with descriptors and algorithm selection. These approaches represent a direction for further developments, notably allowing advances for both developed and emerging countries with modest computational infrastructures.","DENSITY-FUNCTIONAL THEORY,TOTAL-ENERGY,ELECTRON,APPROXIMATIONS,DISCOVERY,QUANTUM,MODEL",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Pharmacology & Pharmacy,Chemistry,Computer Science",,5.39,"DENSITY-FUNCTIONAL,THEORY,TOTAL-ENERGY,ELECTRON,APPROXIMATIONS,DISCOVERY,QUANTUM,MODEL",JOURNAL OF CHEMICAL INFORMATION AND MODELING,,
77,Prediction of Individual User's Dynamic Ranges of EEG Features from Resting-State EEG Data for Evaluating Their Suitability for Passive Brain-Computer Interface Applications,20,4,,"Cha Ho-Seung,Han Chang-Hee,Im Chang-Hwan","Cha HS,Han CH,Im CH",Im CH,10.3390/s20040988,Hanyang University,"With the recent development of low-cost wearable electroencephalogram (EEG) recording systems, passive brain-computer interface (pBCI) applications are being actively studied for a variety of application areas, such as education, entertainment, and healthcare. Various EEG features have been employed for the implementation of pBCI applications; however, it is frequently reported that some individuals have difficulty fully enjoying the pBCI applications because the dynamic ranges of their EEG features (i.e., its amplitude variability over time) were too small to be used in the practical applications. Conducting preliminary experiments to search for the individualized EEG features associated with different mental states can partly circumvent this issue; however, these time-consuming experiments were not necessary for the majority of users whose dynamic ranges of EEG features are large enough to be used for pBCI applications. In this study, we tried to predict an individual user's dynamic ranges of the EEG features that are most widely employed for pBCI applications from resting-state EEG (RS-EEG), with the ultimate goal of identifying individuals who might need additional calibration to become suitable for the pBCI applications. We employed a machine learning-based regression model to predict the dynamic ranges of three widely used EEG features known to be associated with the brain states of valence, relaxation, and concentration. Our results showed that the dynamic ranges of EEG features could be predicted with normalized root mean squared errors of 0.2323, 0.1820, and 0.1562, respectively, demonstrating the possibility of predicting the dynamic ranges of the EEG features for pBCI applications using short resting EEG data.","electroencephalography (EEG),interindividual variability,resting state EEG,passive brain-computer interfaces,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"NEUROFEEDBACK,RECOGNITION,ATTENTION,ARTIFACTS",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7071472,
78,Detection of Early Signs of Diabetic Retinopathy Based on Textural and Morphological Information in Fundus Images,20,4,,"Colomer Adrian,Igual Jorge,Naranjo Valery","Colomer A,Igual J,Naranjo V",Igual J,10.3390/s20041005,Universitat Politecnica de Valencia,"Estimated blind people in the world will exceed 40 million by 2025. To develop novel algorithms based on fundus image descriptors that allow the automatic classification of retinal tissue into healthy and pathological in early stages is necessary. In this paper, we focus on one of the most common pathologies in the current society: diabetic retinopathy. The proposed method avoids the necessity of lesion segmentation or candidate map generation before the classification stage. Local binary patterns and granulometric profiles are locally computed to extract texture and morphological information from retinal images. Different combinations of this information feed classification algorithms to optimally discriminate bright and dark lesions from healthy tissues. Through several experiments, the ability of the proposed system to identify diabetic retinopathy signs is validated using different public databases with a large degree of variability and without image exclusion.","biomedical image processing,diabetic retinopathy,classification,granulometry-based descriptor,LBP,hand-driven learning,exudates,microaneurysms",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"RETINAL,IMAGES,AUTOMATIC,DETECTION,OPTIC,DISC,CLASSIFICATION,ALGORITHM,DIAGNOSIS",SENSORS,https://riunet.upv.es/bitstream/10251/171678/1/ColomerIgualNaranjo%20-%20Detection%20of%20Early%20Signs%20of%20Diabetic%20Retinopathy%20Based%20on%20Textural%20and%20Morp....pdf,
79,Grasping Force Control of Multi-Fingered Robotic Hands through Tactile Sensing for Object Stabilization,20,4,,"Deng Zhen,Jonetzko Yannick,Zhang Liwei,Zhang Jianwei","Deng Z,Jonetzko Y,Zhang LW,Zhang JW",Zhang LW,10.3390/s20041050,Fuzhou University,"Grasping force control is important for multi-fingered robotic hands to stabilize the grasped object. Humans are able to adjust their grasping force and react quickly to instabilities through tactile sensing. However, grasping force control through tactile sensing with robotic hands is still relatively unexplored. In this paper, we make use of tactile sensing for multi-fingered robot hands to adjust the grasping force to stabilize unknown objects without prior knowledge of their shape or physical properties. In particular, an online detection module based on Deep Neural Network (DNN) is designed to detect contact events and object material simultaneously from tactile data. In addition, a force estimation method based on Gaussian Mixture Model (GMM) is proposed to compute the contact information (i.e., contact force and contact location) from tactile data. According to the results of tactile sensing, an object stabilization controller is then employed for a robotic hand to adjust the contact configuration for object stabilization. The spatio-temporal property of tactile data is exploited during tactile sensing. Finally, the effectiveness of the proposed framework is evaluated in a real-world experiment with a five-fingered Shadow Dexterous Hand equipped with BioTac sensors.","grasping force control,force estimation,slip detection,multi-fingered robotic hands",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"MANIPULATION,EXPERIENCE",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7070334,
80,Hybrid Network with Attention Mechanism for Detection and Location of Myocardial Infarction Based on 12-Lead Electrocardiogram Signals,20,4,,"Fu Lidan,Lu Binchun,Nie Bo,Peng Zhiyun,Liu Hongying,Pi Xitian","Fu LD,Lu BC,Nie B,Peng ZY,Liu HY,Pi XT",Liu HY; Pi XT,10.3390/s20041020,Chongqing University,"The electrocardiogram (ECG) is a non-invasive, inexpensive, and effective tool for myocardial infarction (MI) diagnosis. Conventional detection algorithms require solid domain expertise and rely heavily on handcrafted features. Although previous works have studied deep learning methods for extracting features, these methods still neglect the relationships between different leads and the temporal characteristics of ECG signals. To handle the issues, a novel multi-lead attention (MLA) mechanism integrated with convolutional neural network (CNN) and bidirectional gated recurrent unit (BiGRU) framework (MLA-CNN-BiGRU) is therefore proposed to detect and locate MI via 12-lead ECG records. Specifically, the MLA mechanism automatically measures and assigns the weights to different leads according to their contribution. The two-dimensional CNN module exploits the interrelated characteristics between leads and extracts discriminative spatial features. Moreover, the BiGRU module extracts essential temporal features inside each lead. The spatial and temporal features from these two modules are fused together as global features for classification. In experiments, MI location and detection were performed under both intra-patient scheme and inter-patient scheme to test the robustness of the proposed framework. Experimental results indicate that our intelligent framework achieved satisfactory performance and demonstrated vital clinical significance.","myocardial infarction,electrocardiogram,attention mechanism,convolutional neural network,bidirectional gated recurrent unit",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"CONVOLUTIONAL,NEURAL-NETWORK,ECG,SIGNALS,CLASSIFICATION,LOCALIZATION,DISEASE,PATTERN,ENERGY",SENSORS,https://www.mdpi.com/1424-8220/20/4/1020/pdf,
81,Detecting Pneumonia Using Convolutions and Dynamic Capsule Routing for Chest X-ray Images,20,4,,"Mittal Ansh,Kumar Deepika,Mittal Mamta,Saba Tanzila,Abunadi Ibrahim,Rehman Amjad,Roy Sudipta","Mittal A,Kumar D,Mittal M,Saba T,Abunadi I,Rehman A,Roy S",Saba T,10.3390/s20041068,Prince Sultan University,"An entity's existence in an image can be depicted by the activity instantiation vector from a group of neurons (called capsule). Recently, multi-layered capsules, called CapsNet, have proven to be state-of-the-art for image classification tasks. This research utilizes the prowess of this algorithm to detect pneumonia from chest X-ray (CXR) images. Here, an entity in the CXR image can help determine if the patient (whose CXR is used) is suffering from pneumonia or not. A simple model of capsules (also known as Simple CapsNet) has provided results comparable to best Deep Learning models that had been used earlier. Subsequently, a combination of convolutions and capsules is used to obtain two models that outperform all models previously proposed. These models-Integration of convolutions with capsules (ICC) and Ensemble of convolutions with capsules (ECC)-detect pneumonia with a test accuracy of 95.33% and 95.90%, respectively. The latter model is studied in detail to obtain a variant called EnCC, where n = 3, 4, 8, 16. Here, the E4CC model works optimally and gives test accuracy of 96.36%. All these models had been trained, validated, and tested on 5857 images from Mendeley.","pneumonia,chest X-ray (CXR),simple CapsNet,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"COMPUTER-AIDED,DIAGNOSIS,INTERSTITIAL,DISEASE,CLASSIFICATION,RADIOGRAPHY",SENSORS,https://res.mdpi.com/d_attachment/sensors/sensors-20-01068/article_deploy/sensors-20-01068-v2.pdf,
82,Deep Learning in Physiological Signal Data: A Survey,20,4,,"Rim Beanbonyka,Sung Nak-Jun,Min Sedong,Hong Min","Rim B,Sung NJ,Min S,Hong M",Hong M,10.3390/s20040969,Soonchunhyang University,"Deep Learning (DL), a successful promising approach for discriminative and generative tasks, has recently proved its high potential in 2D medical imaging analysis; however, physiological data in the form of 1D signals have yet to be beneficially exploited from this novel approach to fulfil the desired medical tasks. Therefore, in this paper we survey the latest scientific research on deep learning in physiological signal data such as electromyogram (EMG), electrocardiogram (ECG), electroencephalogram (EEG), and electrooculogram (EOG). We found 147 papers published between January 2018 and October 2019 inclusive from various journals and publishers. The objective of this paper is to conduct a detailed study to comprehend, categorize, and compare the key parameters of the deep-learning approaches that have been used in physiological signal analysis for various medical applications. The key parameters of deep-learning approach that we review are the input data type, deep-learning task, deep-learning model, training architecture, and dataset sources. Those are the main key parameters that affect system performance. We taxonomize the research works using deep-learning method in physiological signal analysis based on: (1) physiological signal data perspective, such as data modality and medical application; and (2) deep-learning concept perspective such as training architecture and dataset sources.","deep-learning,machine learning,physiological signals,1D signal data analysis",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"SHORT-TERM-MEMORY,NETWORK,CLASSIFICATION,PREDICTION,IDENTIFICATION,ARCHITECTURE,RECORDINGS,FEATURES,MODEL",SENSORS,https://www.mdpi.com/1424-8220/20/4/969/pdf,
83,Automated Home Oxygen Delivery for Patients with COPD and Respiratory Failure: A New Approach,20,4,,"Sanchez-Morillo Daniel,Munoz-Zara Pilar,Lara-Dona Alejandro,Leon-Jimenez Antonio","Sanchez-Morillo D,Munoz-Zara P,Lara-Dona A,Leon-Jimenez A",Sanchez-Morillo D,10.3390/s20041178,"Biomed Res & Innovat Inst Cadiz INiBICA, Cadiz 11009, Spain.","Long-term oxygen therapy (LTOT) has become standard care for the treatment of patients with chronic obstructive pulmonary disease (COPD) and other severe hypoxemic lung diseases. The use of new portable O-2 concentrators (POC) in LTOT is being expanded. However, the issue of oxygen titration is not always properly addressed, since POCs rely on proper use by patients. The robustness of algorithms and the limited reliability of current oximetry sensors are hindering the effectiveness of new approaches to closed-loop POCs based on the feedback of blood oxygen saturation. In this study, a novel intelligent portable oxygen concentrator (iPOC) is described. The presented iPOC is capable of adjusting the O-2 flow automatically by real-time classifying the intensity of a patient's physical activity (PA). It was designed with a group of patients with COPD and stable chronic respiratory failure. The technical pilot test showed a weighted accuracy of 91.1% in updating the O-2 flow automatically according to medical prescriptions, and a general improvement in oxygenation compared to conventional POCs. In addition, the usability achieved was high, which indicated a significant degree of user satisfaction. This iPOC may have important benefits, including improved oxygenation, increased compliance with therapy recommendations, and the promotion of PA.","COPD,oxygen concentrator,oxygen therapy,automatic oxygen concentrator,physical activity,machine learning,respiratory medicine,portable oxygen concentrator,oxygen delivery",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"OBSTRUCTIVE,PULMONARY-DISEASE,CLOSED-LOOP,CONTROL,ACUTE,EXACERBATIONS,THERAPY,TITRATION,DEVICES,FLOW",SENSORS,https://europepmc.org/articles/pmc7070269?pdf=render,
84,Detecting Respiratory Pathologies Using Convolutional Neural Networks and Variational Autoencoders for Unbalancing Data,20,4,,"Teresa Garcia-Ordas Maria,Alberto Benitez-Andrades Jose,Garcia-Rodriguez Isaias,Benavides Carmen,Alaiz-Moreton Hector","Garcia-Ordas MT,Benitez-Andrades JA,Garcia-Rodriguez I,Benavides C,Alaiz-Moreton H",Garcia-Ordas MT,10.3390/s20041214,Universidad de Leon,"The aim of this paper was the detection of pathologies through respiratory sounds. The ICBHI (International Conference on Biomedical and Health Informatics) Benchmark was used. This dataset is composed of 920 sounds of which 810 are of chronic diseases, 75 of non-chronic diseases and only 35 of healthy individuals. As more than 88% of the samples of the dataset are from the same class (Chronic), the use of a Variational Convolutional Autoencoder was proposed to generate new labeled data and other well known oversampling techniques after determining that the dataset classes are unbalanced. Once the preprocessing step was carried out, a Convolutional Neural Network (CNN) was used to classify the respiratory sounds into healthy, chronic, and non-chronic disease. In addition, we carried out a more challenging classification trying to distinguish between the different types of pathologies or healthy: URTI, COPD, Bronchiectasis, Pneumonia, and Bronchiolitis. We achieved results up to 0.993 F-Score in the three-label classification and 0.990 F-Score in the more challenging six-class classification.","CNN,variational autoencoder,respiratory,lungs,pathologies",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://europepmc.org/articles/pmc7070339?pdf=render,
85,Classification of Wood Chips Using Electrical Impedance Spectroscopy and Machine Learning,20,4,,"Tiitta Markku,Tiitta Valtteri,Heikkinen Jorma,Lappalainen Reijo,Tomppo Laura","Tiitta M,Tiitta V,Heikkinen J,Lappalainen R,Tomppo L",Tiitta M,10.3390/s20041076,University of Eastern Finland,"Wood chips are extensively utilised as raw material for the pulp and bio-fuel industry, and advanced material analyses may improve the processes in utilizing these products. Electrical impedance spectroscopy (EIS) combined with machine learning was used in order to analyse heartwood content of pine chips and bark content of birch chips. A novel electrode system integrated in a sampling container was developed for the testing using frequency range 42 Hz-5 MHz. Three electrode pairs were used to measure the samples in x-, y- and z-direction. Three machine learning methods were used: K-nearest neighbor (KNN), decision tree (DT) and support vector machines (SVM). The heartwood content of pine chips and bark content of birch chips were classified with an accuracy of 91% using EIS from pure materials combined with a k-nearest neighbour classifier. When using mixed materials and multiple classes, 73% correct classification for pine heartwood content (four groups) and 64% for birch bark content (five groups) were achieved.","wood chips,machine learning,electrical impedance spectroscopy,scots pine,birch",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"ARTIFICIAL,NEURAL-NETWORKS,SCOTS,PINE-SEEDLINGS,MOISTURE-CONTENT,PHYSICAL-PROPERTIES,TISSUES,DAMAGE",SENSORS,https://europepmc.org/articles/pmc7070823?pdf=render,
86,A Comprehensive Machine-Learning-Based Software Pipeline to Classify EEG Signals: A Case Study on PNES vs. Control Subjects,20,4,,"Varone Giuseppe,Gasparini Sara,Ferlazzo Edoardo,Ascoli Michele,Tripodi Giovanbattista Gaspare,Zucco Chiara,Calabrese Barbara,Cannataro Mario,Aguglia Umberto","Varone G,Gasparini S,Ferlazzo E,Ascoli M,Tripodi GG,Zucco C,Calabrese B,Cannataro M,Aguglia U",Aguglia U,10.3390/s20041235,Magna Graecia University of Catanzaro,"The diagnosis of psychogenic nonepileptic seizures (PNES) by means of electroencephalography (EEG) is not a trivial task during clinical practice for neurologists. No clear PNES electrophysiological biomarker has yet been found, and the only tool available for diagnosis is video EEG monitoring with recording of a typical episode and clinical history of the subject. In this paper, a data-driven machine learning (ML) pipeline for classifying EEG segments (i.e., epochs) of PNES and healthy controls (CNT) is introduced. This software pipeline consists of a semiautomatic signal processing technique and a supervised ML classifier to aid clinical discriminative diagnosis of PNES by means of an EEG time series. In our ML pipeline, statistical features like the mean, standard deviation, kurtosis, and skewness are extracted in a power spectral density (PSD) map split up in five conventional EEG rhythms (delta, theta, alpha, beta, and the whole band, i.e., 1-32 Hz). Then, the feature vector is fed into three different supervised ML algorithms, namely, the support vector machine (SVM), linear discriminant analysis (LDA), and Bayesian network (BN), to perform EEG segment classification tasks for CNT vs. PNES. The performance of the pipeline algorithm was evaluated on a dataset of 20 EEG signals (10 PNES and 10 CNT) that was recorded in eyes-closed resting condition at the Regional Epilepsy Centre, Great Metropolitan Hospital of Reggio Calabria, University of Catanzaro, Italy. The experimental results showed that PNES vs. CNT discrimination tasks performed via the ML algorithm and validated with random split (RS) achieved an average accuracy of 0.97 +/- 0.013 (RS-SVM), 0.99 +/- 0.02 (RS-LDA), and 0.82 +/- 0.109 (RS-BN). Meanwhile, with leave-one-out (LOO) validation, an average accuracy of 0.98 +/- 0.0233 (LOO-SVM), 0.98 +/- 0.124 (LOO-LDA), and 0.81 +/- 0.109 (LOO-BN) was achieved. Our findings showed that BN was outperformed by SVM and LDA. The promising results of the proposed software pipeline suggest that it may be a valuable tool to support existing clinical diagnosis.","EEG,psychogenic nonepileptic seizures,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"PSYCHOGENIC,SEIZURES,NONEPILEPTIC,SEIZURES",SENSORS,https://europepmc.org/articles/pmc7071461?pdf=render,
87,Prediction of Limb Joint Angles Based on Multi-Source Signals by GS-GRNN for Exoskeleton Wearer,20,4,,"Xie Hualong,Li Guanchao,Zhao Xiaofei,Li Fei","Xie HL,Li GC,Zhao XF,Li F",Xie HL,10.3390/s20041104,Northeastern University - China,"To enable exoskeleton wearers to walk on level ground, estimation of lower limb movement is particularly indispensable. In fact, it allows the exoskeleton to follow the human movement in real time. In this paper, the general regression neural network optimized by golden section algorithm (GS-GRNN) is used to realize prediction of the human lower limb joint angle. The human body hip joint angle and the surface electromyographic (sEMG) signals of the thigh muscles are taken as the inputs of a neural network to predict joint angles of lower limbs. To improve the prediction accuracy in different gait phases, the plantar pressure signals are also added into the input. After that, the error between the prediction result and the actual data decreases significantly. Finally, compared with the prediction result of the BP neural network, GRNN shows splendid prediction performance for its less processing time and higher prediction accuracy.","GS-GRNN,walking on level ground,joint angle prediction,sEMG signal,plantar pressure signal,error analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7070277,
88,A Deep-Learning-based 3D Defect Quantitative Inspection System in CC Products Surface,20,4,,"Zhao Liming,Li Fangfang,Zhang Yi,Xu Xiaodong,Xiao Hong,Feng Yang","Zhao LM,Li FF,Zhang Y,Xu XD,Xiao H,Feng Y",Zhang Y,10.3390/s20040980,Chongqing University of Posts & Telecommunications,"To create an intelligent surface region of interests (ROI) 3D quantitative inspection strategy a reality in the continuous casting (CC) production line, an improved 3D laser image scanning system (3D-LDS) was established based on binocular imaging and deep-learning techniques. In 3D-LDS, firstly, to meet the requirements of the industrial application, the CCD laser image scanning method was optimized in high-temperature experiments and secondly, we proposed a novel region proposal method based on 3D ROI initial depth location for effectively suppressing redundant candidate bounding boxes generated by pseudo-defects in a real-time inspection process. Thirdly, a novel two-step defects inspection strategy was presented by devising a fusion deep CNN model which combined fully connected networks (for defects classification/recognition) and fully convolutional networks (for defects delineation). The 3D-LDS' dichotomous inspection method of defects classification and delineation processes are helpful in understanding and addressing challenges for defects inspection in CC product surfaces. The applicability of the presented methods is mainly tied to the surface quality inspection for slab, strip and billet products.","continuous casting,surface defects,3D imaging,neural network,deep learning,defect detection",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://www.mdpi.com/1424-8220/20/4/980/pdf,
89,A New Method of Lithology Classification Based on Convolutional Neural Network Algorithm by Utilizing Drilling String Vibration Data,13,4,,"Chen Gang,Chen Mian,Hong Guobin,Lu Yunhu,Zhou Bo,Gao Yanfang","Chen G,Chen M,Hong GB,Lu YH,Zhou B,Gao YF",Chen M; Lu YH,10.3390/en13040888,"State Key Lab Petr Resources & Prospecting, Beijing 102249, Peoples R China.","Formation lithology identification is of great importance for reservoir characterization and petroleum exploration. Previous methods are based on cutting logging and well-logging data and have a significant time lag. In recent years, many machine learning methods have been applied to lithology identification by utilizing well-logging data, which may be affected by drilling fluid. Drilling string vibration data is a high-density ancillary data, and it has the advantages of low-latency, which can be acquired in real-time. Drilling string vibration data is more accessible and available compared to well-logging data in ultra-deep well drilling. Machine learning algorithms enable us to develop new lithology identification models based on these vibration data. In this study, a vibration dataset is used as the signal source, and the original vibration signal is filtered by Butterworth (BHPF). Vibration time-frequency characteristics were extracted into time-frequency images with the application of short-time Fourier transform (STFT). This paper develops lithology classification models using new data sources based on a convolutional neural network (CNN) combined with Mobilenet and ResNet. This model is used for complex formation lithology, including fine gravel sandstone, fine sandstone, and mudstone. This study also carries out related model accuracy verification and model prediction results interpretation. In order to improve the trustworthiness of decision-making results, the gradient-weighted class-activated thermal localization map is applied to interpret the results of the model. The final verification test shows that the single-sample decision time of the model is 10 ms, the test macro precision rate is 90.0%, and the macro recall rate is 89.3%. The lithology identification model based on vibration data is more efficient and accessible than others. In conclusion, the CNN model using drill string vibration supplies a superior method of lithology identification. This study provides low-latency lithology classification methods to ensure safe and fast drilling.","lithology identification model,convolutional neural network,drill string vibration data,class activation heatmap",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"IDENTIFICATION,FACIES,LITHOFACIES,PREDICTION,FIELD,LOGS",ENERGIES,https://www.mdpi.com/1996-1073/13/4/888/pdf,
90,Quantifying Mechanical Properties of Automotive Steels with Deep Learning Based Computer Vision Algorithms,10,2,,"Javaheri Ehsan,Kumala Verdiana,Javaheri Alireza);,Rawassizadeh Reza,Lubritz Janot,Graf Benjamin,Rethmeier Michael","Javaheri E,Kumala V,Javaheri A,Rawassizadeh R,Lubritz J,Graf B,Rethmeier M",Javaheri E; Graf B,10.3390/met10020163,Fraunhofer Gesellschaft,"This paper demonstrates that the instrumented indentation test (IIT), together with a trained artificial neural network (ANN), has the capability to characterize the mechanical properties of the local parts of a welded steel structure such as a weld nugget or heat affected zone. Aside from force-indentation depth curves generated from the IIT, the profile of the indented surface deformed after the indentation test also has a strong correlation with the materials' plastic behavior. The profile of the indented surface was used as the training dataset to design an ANN to determine the material parameters of the welded zones. The deformation of the indented surface in three dimensions shown in images were analyzed with the computer vision algorithms and the obtained data were employed to train the ANN for the characterization of the mechanical properties. Moreover, this method was applied to the images taken with a simple light microscope from the surface of a specimen. Therefore, it is possible to quantify the mechanical properties of the automotive steels with the four independent methods: (1) force-indentation depth curve; (2) profile of the indented surface; (3) analyzing of the 3D-measurement image; and (4) evaluation of the images taken by a simple light microscope. The results show that there is a very good agreement between the material parameters obtained from the trained ANN and the experimental uniaxial tensile test. The results present that the mechanical properties of an unknown steel can be determined by only analyzing the images taken from its surface after pushing a simple indenter into its surface.","deep learning,computer vision,artificial neural network,clustering,mechanical properties,high strength steels,instrumented indentation test",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Materials Science,Metallurgy & Metallurgical Engineering",,2.487,"SPHERICAL,INDENTATION,DATA,VISCOPLASTIC,MATERIAL,PARAMETERS,STRESS-STRAIN,PROPERTIES,SPOT-WELDED,JOINTS,NEURAL-NETWORKS,INSTRUMENTED,INDENTATION,PART,II,CONSTITUTIVE,PROPERTIES,POISSONS,RATIO,IDENTIFICATION",METALS,https://depositonce.tu-berlin.de/bitstream/11303/11057/1/metals-10-00163-v2.pdf,
91,Modeling Mechanical Properties of 25Cr-20Ni-0.4C Steels over a Wide Range of Temperatures by Neural Networks,10,2,,"Narayana P. L.,Kim Jae H.,Maurya A. K.,Park Chan Hee,Hong Jae-Keun,Yeom Jong-Taek,Reddy N. S.","Narayana PL,Kim JH,Maurya AK,Park CH,Hong JK,Yeom JT,Reddy NS",Yeom JT,10.3390/met10020256,Korea Institute of Materials Science (KIMS),"From the point of view of designing materials, it is important to study the complex correlational research that involves measuring several variables and assessing the relation among them. Hence, the notion of machine-oriented data modeling is explored. Among various machine-learning tools, artificial neural networks (ANN) have been used as a stimulating tool to solve engineering-related issues. In this study, the ANN model is designed and trained to correlate the complex relations among composition, temperature and mechanical properties of 25Cr-20Ni-0.4C austenitic stainless steel. The developed model was exploited to estimate the composition-property and temperature-property correlations. The ANN predictions are well suitable for experimental results. The model was able to correlate the complex nature among input and output variables. The model was used to investigate the effect of service temperature on the mechanical properties of 25Cr-20Ni-0.4C steels over a wide temperature range. The effective response of the alloying elements on the mechanical properties of ambient as well as elevated temperatures was quantitatively estimated with the help of the index of relative importance (IRI) method. Hence, this handy technique is the best tool to overcome the designing complications and to develop the components having remarkable properties.","25Cr-20Ni-0.4C steels,mechanical properties,artificial neural networks,simulation and modeling,index of the relative importance",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Materials Science,Metallurgy & Metallurgical Engineering",,,"HOT,DEFORMATION-BEHAVIOR",METALS,https://www.mdpi.com/2075-4701/10/2/256/pdf,
92,Random Forests Algorithm-Based Fault Diagnosis for Refrigerant Charge,48,2,16-24,",,,","Zhou Xuan,Wang Xiaopei,Liang Liequan,Yan Junwei",,,Zhou Xuan,"The refrigerant charge ( RC) breakdown of chiller is a high-risk fault that directly affects the operational efficiency of air conditioning system. Due to the mass representative parameters,it is difficult to detect the fault online effectively,quickly and accurately. Aiming at these problems,a fault diagnosis method based on random forests ( RF) algorithm was proposed for the RC breakdown by using the fault database of refrigeration provided by ASHRAE in 1999. Directly measured feature parameters related to RC were analyzed. Under the premise of retaining the physical meaning,contribution rate of each fault feature was studied with RF algorithm. Then the detection accuracy of RC fault diagnosis based on RF,support vector machines ( SVM) and decision tree ( DT) algorithms were compared under the condition of different dimensions and sample size. The results show that the RF algorithm has the best recognition efficiency and highest classification accuracy. Compared with DT and SVM,the average detection accuracy of RF increases by 3. 3% and 2. 9%,respectively. Furthermore,three important fault characteristics which have a high impact on the diagnosis of RC were analyzed. This can provide a theoretical basis for ensuring operating performance and safe operation of refrigeration system.",fault diagnosis; refrigerant charge; random forests algorithm; air conditioning system,Article,,,,,,,,
93,Random forest-based classsification and analysis of hemiplegia gait using low-cost depth cameras,58,2,373-382,"Luo Guoliang,Zhu Yean,Wang Rui,Tong Yang,Lu Wei,Wang Haolun","Luo GL,Zhu Y,Wang R,Tong Y,Lu W,Wang HL",Wang HL,10.1007/s11517-019-02079-7,East China Jiaotong University,"Hemiplegia is a form of paralysis that typically has the symptom of dysbasia. In current clinical rehabilitations, to measure the level of hemiplegia gaits, clinicians often conduct subject evaluations through observations, which is unreliable and inaccurate. The Microsoft Kinect sensor (MS Kinect) is a widely used, low-cost depth sensor that can be used to detect human behaviors in real time. The purpose of this study is to investigate the usage of the Kinect data for the classification and analysis of hemiplegia gait. We first acquire the gait data by using a MS Kinect and extract a set of gait features including the stride length, gait speed, left/right moving distances, and up/down moving distances. With the gait data of 60 subjects including 20 hemiplegia patients and 40 healthy subjects, we employ a random forest-based classification approach to analyze the importances of different gait features for hemiplegia classification. Thanks to the over-fitting avoidance nature of the random forest approach, we do not need to have a careful control over the percentage of patients in the training data. In our experiments, our approach obtained the averaged classification accuracy of 90.65% among all the combinations of the gait features, which substantially outperformed state-of-the-art methods. The best classification accuracy of our approach is 95.45%, which is superior than all existing methods. Additionally, our approach also correctly reveals the importance of different gait features for hemiplegia classification. Our random forest-based approach outperforms support vector machine-based method and the Bayesian-based method, and can effectively extract gait features of subjects with hemiplegia for the classification and analysis of hemiplegia.
Random Forest based Classsification and Analysis of Hemiplegia Gait using Low-cost Depth Cameras. Left: Motion capture with MS Kinect; Top-right: Random Forest Classsification based on the extracted gait features; Bottom-right: Sensitivity and specificity evaluation of the proposed classification approach.","Depth cameras,Microsoft Kinect,Hemiplegia,Gait analysis,Random forest,Motion classification",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"MICROSOFT,KINECT,CONCURRENT,VALIDITY,CLASSIFICATION,STROKE",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
94,A human-in-the-loop deep learning paradigm for synergic visual evaluation in children,122,,163-173,"Zhang Kai,Li Xiaoyan,He Lin,Guo Chong,Yang Yahan,Dong Zhou,Yang Haoqing,Zhu Yi,Chen Chuan,Zhou Xiaojing","Zhang K,Li XY,He L,Guo C,Yang YH,Dong Z,Yang HQ,Zhu Y,Chen C,Zhou XJ",Liu XY,10.1016/j.neunet.2019.10.003,Xidian University,"Visual development during early childhood is a vital process. Examining the visual acuity of children is essential for early detection of visual abnormalities, but performing visual examination in children is challenging. Here, we developed a human-in-the-loop deep learning (DL) paradigm that combines traditional vision examination and DL with integration of software and hardware, thus facilitating the execution of vision examinations, offsetting the shortcomings of human doctors, and improving the abilities of both DL and doctors to evaluate the vision of children. Because this paradigm contains two rounds (a human round and DL round), doctors can learn from DL and the two can mutually supervise each other such that the precision of the DL system in evaluating the visual acuity of children is improved. Based on DL-based object localization and image identification, the experiences of doctors and the videos captured in the first round, the DL system in the second round can simulate doctors in evaluating the visual acuity of children with a final accuracy of 75.54%. For comparison, we also assessed an automatic deep learning method that did not consider the experiences of doctors, but its performance was not satisfactory. This entire paradigm can evaluate the visual acuity of children more accurately than humans alone. Furthermore, the paradigm facilitates automatic evaluation of the vision of children with a wearable device. (c) 2019 Elsevier Ltd. All rights reserved.","Evaluating the visual acuity of children,Human-in-the-loop,Deep learning,Object localization,Image identification,Integration of software and hardware",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,9.171,"INFANTS,CLASSIFICATION,ACUITY,SYSTEM",NEURAL NETWORKS,,
95,Unsupervised Clustering for Hyperspectral Images,12,2,,"Bilius Laura Bianca,Pentiuc Stefan Gheorghe","Bilius LB,Pentiuc SG",Bilius LB; Pentiuc SG,10.3390/sym12020277,Stefan cel Mare University of Suceava,"Hyperspectral images are becoming a valuable tool much used in agriculture, mineralogy, and so on. The challenge is to successfully classify the materials founded in the field relevant for different applications. Due to a large amount of data corresponding to a big number of spectral bands, the classification programs require a long time to analyze and classify the data. The purpose is to find a better method for reducing the classification time. We exploit various algorithms on real hyperspectral data sets to find out which algorithm is more effective. This paper presents a comparison of unsupervised hyperspectral image classification such as K-means, Hierarchical clustering, and Parafac decomposition, which allows the performance of the model reduction and feature extraction. The results showed that the method useful for big data is the classification of data after Parafac Decomposition.","tensor decomposition,parafac decomposition,hyperspectral images,block term decomposition,k-means,hierarchical clustering",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"CANONICAL,POLYADIC,DECOMPOSITION,CLASSIFICATION,ALGORITHMS",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/2/277/pdf,
96,Artificial Neural Network and Adaptive Neuro-Fuzzy Interface System Modelling to Predict Thermal Performances of Thermoelectric Generator for Waste Heat Recovery,12,2,,"Garud Kunal Sandip,Seo Jae-Hyeong,Cho Chong-Pyo,Lee Moo-Yeon","Garud KS,Seo JH,Cho CP,Lee MY",Lee MY,10.3390/sym12020259,Dong A University,"The present study elaborates the suitability of the artificial neural network (ANN) and adaptive neuro-fuzzy interface system (ANFIS) to predict the thermal performances of the thermoelectric generator system for waste heat recovery. Six ANN models and seven ANFIS models are formulated by considering hot gas temperatures and voltage load conditions as the inputs to predict current, power, and thermal efficiency of the thermoelectric generator system for waste heat recovery. The ANN model with the back-propagation algorithm, the Levenberg-Marquardt variant, Tan-Sigmoidal transfer function and 25 number of hidden neurons is found to be an optimum model to accurately predict current, power and thermal efficiency. For current, power and thermal efficiency, the ANFIS model with pi-5 or gauss-5-membership function is recommended as the optimum model when the prediction accuracy is important while the ANFIS model with gbell-3-membership function is suggested as the optimum model when the prediction cost plays a crucial role along with the prediction accuracy. The proposed optimal ANN and ANFIS models present higher prediction accuracy than the coupled numerical approach.","adaptive neuro-fuzzy interface system,artificial neural network,current,power,thermal efficiency,thermoelectric generator system,waste heat recovery",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"POWER-GENERATION,DESIGN,OPTIMIZATION,EXCHANGER,MODULES,ANN",SYMMETRY-BASEL,https://res.mdpi.com/d_attachment/symmetry/symmetry-12-00259/article_deploy/symmetry-12-00259.pdf,
97,Applying Educational Data Mining to Explore Students' Learning Patterns in the Flipped Learning Approach for Coding Education,12,2,,"Hung Hui-Chun,Liu I-Fan,Liang Che-Tien,Su Yu-Sheng","Hung HC,Liu IF,Liang CT,Su YS",Su YS,10.3390/sym12020213,National Taiwan Ocean University,"From traditional face-to-face courses, asynchronous distance learning, synchronous live learning, to even blended learning approaches, the learning approach can be more learner-centralized, enabling students to learn anytime and anywhere. In this study, we applied educational data mining to explore the learning behaviors in data generated by students in a blended learning course. The experimental data were collected from two classes of Python programming related courses for first-year students in a university in northern Taiwan. During the semester, high-risk learners could be predicted accurately by data generated from the blended educational environment. The f1-score of the random forest model was 0.83, which was higher than the f1-score of logistic regression and decision tree. The model built in this study could be extrapolated to other courses to predict students' learning performance, where the F1-score was 0.77. Furthermore, we used machine learning and symmetry-based learning algorithms to explore learning behaviors. By using the hierarchical clustering heat map, this study could define the students' learning patterns including the positive interactive group, stable learning group, positive teaching material group, and negative learning group. These groups also corresponded with the student conscious questionnaire. With the results of this research, teachers can use the mid-term forecasting system to find high-risk groups during the semester and remedy their learning behaviors in the future.","blended learning,learning behaviors,learning performance,machine learning,online programming course",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"ONLINE,PARTICIPATION,PERFORMANCE",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/2/213/pdf,
98,Critical Temperature Prediction of Superconductors Based on Atomic Vectors and Deep Learning,12,2,,"Li Shaobo,Dan Yabo,Li Xiang,Hu Tiantian,Dong Rongzhi,Cao Zhuo,Hu Jianjun","Li SB,Dan YB,Li X,Hu TT,Dong RZ,Cao Z,Hu JJ",Dan YB; Hu JJ,10.3390/sym12020262,Guizhou University,"In this paper, a hybrid neural network (HNN) that combines a convolutional neural network (CNN) and long short-term memory neural network (LSTM) is proposed to extract the high-level characteristics of materials for critical temperature (Tc) prediction of superconductors. Firstly, by obtaining 73,452 inorganic compounds from the Materials Project (MP) database and building an atomic environment matrix, we obtained a vector representation (atomic vector) of 87 atoms by singular value decomposition (SVD) of the atomic environment matrix. Then, the obtained atom vector was used to implement the coded representation of the superconductors in the order of the atoms in the chemical formula of the superconductor. The experimental results of the HNN model trained with 12,413 superconductors were compared with three benchmark neural network algorithms and multiple machine learning algorithms using two commonly used material characterization methods. The experimental results show that the HNN method proposed in this paper can effectively extract the characteristic relationships between the atoms of superconductors, and it has high accuracy in predicting the Tc.","superconductivity,machine learning,CNN,LSTM,materials informatics",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"MATERIALS,INFORMATICS,APPROXIMATION,PENETRATION,MEISSNER,SCIENCE",SYMMETRY-BASEL,https://res.mdpi.com/d_attachment/symmetry/symmetry-12-00262/article_deploy/symmetry-12-00262-v2.pdf,
99,A Novel Identification Method for Apple (Malus domestica Borkh.) Cultivars Based on a Deep Convolutional Neural Network with Leaf Image Input,12,2,,"Liu Chengzhong,Han Junying,Chen Baihong,Mao Juan,Xue Zhengxu,Li Shunqiang","Liu CZ,Han JY,Chen BH,Mao J,Xue ZX,Li SQ",Han JY,10.3390/sym12020217,Gansu Agricultural University,"The innovation of germplasm resources and the continuous breeding of new varieties of apples (Malus domestica Borkh.) have yielded more than 8000 apple cultivars. The ability to identify apple cultivars with ease and accuracy can solve problems in apple breeding related to property rights protection to promote the healthy development of the global apple industry. However, the existing methods are inconsistent and time-consuming. This paper proposes an efficient and convenient method for the classification of apple cultivars using a deep convolutional neural network with leaf image input, which is the delicate symmetry of a human brain learning. The model was constructed using the TensorFlow framework and trained on a dataset of 12,435 leaf images for the identification of 14 apple cultivars. The proposed method achieved an overall accuracy of 0.9711 and could successfully avoid the over-fitting problem. Tests on an unknown independent testing set resulted in a mean accuracy, mean error, and variance of mu acc=0.9685, mu epsilon=0.0315, and sigma 2=1.89025E-4, respectively, indicating that the generalization accuracy and stability of the model were very good. Finally, the classification performance for each cultivar was tested. The results show that model had an accuracy of 1.0000 for Ace, Hongrouyouxi, Jazz, and Honey Crisp cultivars, and only one leaf was incorrectly identified for 2001, Ada Red, Jonagold, and Gold Spur cultivars, with accuracies of 0.9787, 0.9800, 0.9773, and 0.9737, respectively. Jingning1 and Pinova cultivars were classified with the lowest accuracies, with 0.8780 and 0.8864, respectively. The results also show that the genetic relationship between cultivars Shoufu 3 and Yanfu 3 is very high, which is mainly because they were both selected from a red mutation of Fuji and bred in Yantai City, Shandong Province, China. Generally, this study indicates that the proposed deep learning model is a novel and improved solution for apple cultivar identification, with high generalization accuracy, stable convergence, and high specificity.","Malus domestica Borkh,deep learning,convolutional neural networks,cultivars identification,leaves images",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,,SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/2/217/pdf,
100,"Emphasis Learning, Features Repetition in Width Instead of Length to Improve Classification Performance: Case Study-Alzheimer's Disease Diagnosis",20,3,,"Akramifard Hamid,Balafar MohammadAli,Razavi SeyedNaser,Ramli Abd Rahman","Akramifard H,Balafar M,Razavi S,Ramli A",Balafar M,10.3390/s20030941,University of Tabriz,"In the past decade, many studies have been conducted to advance computer-aided systems for Alzheimer's disease (AD) diagnosis. Most of them have recently developed systems concentrated on extracting and combining features from MRI, PET, and CSF. For the most part, they have obtained very high performance. However, improving the performance of a classification problem is complicated, specifically when the model's accuracy or other performance measurements are higher than 90%. In this study, a novel methodology is proposed to address this problem, specifically in Alzheimer's disease diagnosis classification. This methodology is the first of its kind in the literature, based on the notion of replication on the feature space instead of the traditional sample space. Briefly, the main steps of the proposed method include extracting, embedding, and exploring the best subset of features. For feature extraction, we adopt VBM-SPM; for embedding features, a concatenation strategy is used on the features to ultimately create one feature vector for each subject. Principal component analysis is applied to extract new features, forming a low-dimensional compact space. A novel process is applied by replicating selected components, assessing the classification model, and repeating the replication until performance divergence or convergence. The proposed method aims to explore most significant features and highest-preforming model at the same time, to classify normal subjects from AD and mild cognitive impairment (MCI) patients. In each epoch, a small subset of candidate features is assessed by support vector machine (SVM) classifier. This repeating procedure is continued until the highest performance is achieved. Experimental results reveal the highest performance reported in the literature for this specific classification problem. We obtained a model with accuracies of 98.81%, 81.61%, and 81.40% for AD vs. normal control (NC), MCI vs. NC, and AD vs. MCI classification, respectively.","Alzheimer's disease,Emphasis Learning,multi-modal classification,SVM,PCA",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"MILD,COGNITIVE,IMPAIRMENT,SUPPORT,VECTOR,MACHINE,GENE,SELECTION,PREDICTION,ATROPHY,PET",SENSORS,https://europepmc.org/articles/pmc7039233?pdf=render,
