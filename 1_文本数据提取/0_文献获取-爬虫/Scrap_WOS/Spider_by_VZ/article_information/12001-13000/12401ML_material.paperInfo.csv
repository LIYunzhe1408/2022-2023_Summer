,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,How Laboratory Experiments Can Be Exploited for Monitoring Stress in the Wild: A Bridge Between Laboratory and Daily Life,20,3,,"Can Yekta Said,Gokay Dilara,Kilic Dilruba Reyyan,Ekiz Deniz,Chalabianloo Niaz,Ersoy Cem","Can YS,Gokay D,Kilic DR,Ekiz D,Chalabianloo N,Ersoy C",Can YS,10.3390/s20030838,Bogazici University,"Chronic stress leads to poor well-being, and it has effects on life quality and health. Society may have significant benefits from an automatic daily life stress detection system using unobtrusive wearable devices using physiological signals. However, the performance of these systems is not sufficiently accurate when they are used in unrestricted daily life compared to the systems tested in controlled real-life and laboratory conditions. To test our stress level detection system that preprocesses noisy physiological signals, extracts features, and applies machine learning classification techniques, we used a laboratory experiment and ecological momentary assessment based data collection with smartwatches in daily life. We investigated the effect of different labeling techniques and different training and test environments. In the laboratory environments, we had more controlled situations, and we could validate the perceived stress from self-reports. When machine learning models were trained in the laboratory instead of training them with the data coming from daily life, the accuracy of the system when tested in daily life improved significantly. The subjectivity effect coming from the self-reports in daily life could be eliminated. Our system obtained higher stress level detection accuracy results compared to most of the previous daily life studies.","smart band,stress recognition,physiological signal processing,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,"HEART-RATE-VARIABILITY,RECOGNITION,RESPONSES,EMOTION,SENSORS,SYSTEM",SENSORS,https://res.mdpi.com/d_attachment/sensors/sensors-20-00838/article_deploy/sensors-20-00838-v3.pdf,
2,Hand Gesture Recognition Using Compact CNN via Surface Electromyography Signals,20,3,,"Chen Lin,Fu Jianting,Wu Yuheng,Li Haochen,Zheng Bin","Chen L,Fu JT,Wu YH,Li HC,Zheng B",Zheng B,10.3390/s20030672,Chinese Academy of Sciences,"By training the deep neural network model, the hidden features in Surface Electromyography(sEMG) signals can be extracted. The motion intention of the human can be predicted by analysis of sEMG. However, the models recently proposed by researchers often have a large number of parameters. Therefore, we designed a compact Convolution Neural Network (CNN) model, which not only improves the classification accuracy but also reduces the number of parameters in the model. Our proposed model was validated on the Ninapro DB5 Dataset and the Myo Dataset. The classification accuracy of gesture recognition achieved good results.","surface electromyography (sEMG),convolution neural networks (CNNs),hand gesture recognition",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,EMG,SENSORS,https://www.mdpi.com/1424-8220/20/3/672/pdf,
3,An Exploration of Machine-Learning Estimation of Ground Reaction Force from Wearable Sensor Data,20,3,,"Hendry Danica,Leadbetter Ryan,McKee Kristoffer,Hopper Luke,Wild Catherine,O'Sullivan Peter,Straker Leon,Campbell Amity","Hendry D,Leadbetter R,McKee K,Hopper L,Wild C,O'Sullivan P,Straker L,Campbell A",Hendry D,10.3390/s20030740,Curtin University,"This study aimed to develop a wearable sensor system, using machine-learning models, capable of accurately estimating peak ground reaction force (GRF) during ballet jumps in the field. Female dancers (n = 30) performed a series of bilateral and unilateral ballet jumps. Dancers wore six ActiGraph Link wearable sensors (100 Hz). Data were collected simultaneously from two AMTI force platforms and synchronised with the ActiGraph data. Due to sensor hardware malfunctions and synchronisation issues, a multistage approach to model development, using a reduced data set, was taken. Using data from the 14 dancers with complete multi-sensor synchronised data, the best single sensor was determined. Subsequently, the best single sensor model was refined and validated using all available data for that sensor (23 dancers). Root mean square error (RMSE) in body weight (BW) and correlation coefficients (r) were used to assess the GRF profile, and Bland-Altman plots were used to assess model peak GRF accuracy. The model based on sacrum data was the most accurate single sensor model (unilateral landings: RMSE = 0.24 BW, r = 0.95; bilateral landings: RMSE = 0.21 BW, r = 0.98) with the refined model still showing good accuracy (unilateral: RMSE = 0.42 BW, r = 0.80; bilateral: RMSE = 0.39 BW, r = 0.92). Machine-learning models applied to wearable sensor data can provide a field-based system for GRF estimation during ballet jumps.","machine learning,inertial sensor,ballet,ground reaction force",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"LANDING,BIOMECHANICS,DANCERS,MICROSENSORS,KINEMATICS,FATIGUE,EVENTS",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7038404,
4,Multi-Parameter Sensing in a Multimode Self-Interference Micro-Ring Resonator by Machine Learning,20,3,,"Hu Dong,Zou Chang-ling,Ren Hongliang,Lu Jin,Le Zichun,Qin Yali,Guo Shunqin,Dong Chunhua,Hu Weisheng","Hu D,Zou CL,Ren HL,Lu J,Le ZC,Qin YL,Guo SQ,Dong CH,Hu WS",Ren HL,10.3390/s20030709,Zhejiang University of Technology,"A universal multi-parameter sensing scheme based on a self-interference micro-ring resonator (SIMRR) is proposed. Benefit from the special intensity sensing mechanism, the SIMRR allows multimode sensing in a wide range of wavelengths but immune from frequency noise. To process the multiple mode spectra that are dependent on multiple parameters, we adopt the machine learning algorithm instead of massive asymptotic solutions of resonators. Employing the proposed multi-mode sensing approach, a two-parameter SIMRR sensor is designed. Assuming that two gases have different wavelength dependence of refractive indices, the feasibility and effectiveness of the two-parameter sensing strategy are verified numerically. Moreover, the dependence of parameter estimation accuracy on the laser intensity noises is also investigated. The numerical results indicate that our scheme of multi-parameter sensing in a multimode SIMRR holds great potential for practical high-sensitive sensing platforms compared with the single-mode sensing based on whispering gallery mode (WGM) resonators.","self-interference micro-ring resonator (SIMRR),dissipative sensing,multimode sensing,multiparameter sensing,machine learning,artificial neuron network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"LABEL-FREE,BIOSENSOR,NEURAL-NETWORKS,SENSOR,INTERROGATION,PERFORMANCE,BOTDA,GAS",SENSORS,https://www.mdpi.com/1424-8220/20/3/709/pdf,
5,The Design of CNN Architectures for Optimal Six Basic Emotion Classification Using Multiple Physiological Signals,20,3,,"Oh SeungJun,Lee Jun-Young,Kim Dong Keun","Oh S,Lee JY,Kim DK",Kim DK,10.3390/s20030866,Sang Myung University,"This study aimed to design an optimal emotion recognition method using multiple physiological signal parameters acquired by bio-signal sensors for improving the accuracy of classifying individual emotional responses. Multiple physiological signals such as respiration (RSP) and heart rate variability (HRV) were acquired in an experiment from 53 participants when six basic emotion states were induced. Two RSP parameters were acquired from a chest-band respiration sensor, and five HRV parameters were acquired from a finger-clip blood volume pulse (BVP) sensor. A newly designed deep-learning model based on a convolutional neural network (CNN) was adopted for detecting the identification accuracy of individual emotions. Additionally, the signal combination of the acquired parameters was proposed to obtain high classification accuracy. Furthermore, a dominant factor influencing the accuracy was found by comparing the relativeness of the parameters, providing a basis for supporting the results of emotion classification. The users of this proposed model will soon be able to improve the emotion recognition model further based on CNN using multimodal physiological signals and their sensors.","emotion classification,physiological signals,machine learning,deep learning,principal components analysis,convolution neural networks",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,RECOGNITION,SENSORS,https://www.mdpi.com/1424-8220/20/3/866/pdf,
6,A Wearable Electrocardiogram Telemonitoring System for Atrial Fibrillation Detection,20,3,,"Shao Minggang,Zhou Zhuhuang,Bin Guangyu,Bai Yanping,Wu Shuicai","Shao MG,Zhou ZH,Bin GY,Bai YP,Wu SC",Wu SC,10.3390/s20030606,Beijing University of Technology,"In this paper we proposed a wearable electrocardiogram (ECG) telemonitoring system for atrial fibrillation (AF) detection based on a smartphone and cloud computing. A wearable ECG patch was designed to collect ECG signals and send the signals to an Android smartphone via Bluetooth. An Android APP was developed to display the ECG waveforms in real time and transmit every 30 s ECG data to a remote cloud server. A machine learning (CatBoost)-based ECG classification method was proposed to detect AF in the cloud server. In case of detected AF, the cloud server pushed the ECG data and classification results to the web browser of a doctor. Finally, the Android APP displayed the doctor's diagnosis for the ECG signals. Experimental results showed the proposed CatBoost classifier trained with 17 selected features achieved an overall F-1 score of 0.92 on the test set (n = 7270). The proposed wearable ECG monitoring system may potentially be useful for long-term ECG telemonitoring for AF detection.","electrocardiogram (ECG) monitoring,wearable ECG patch,atrial fibrillation detection,Android smartphone,cloud computing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"AUTOMATIC,DETECTION,RR",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7038204,
7,Wearable Emotion Recognition Using Heart Rate Data from a Smart Bracelet,20,3,,"Shu Lin);,Yu Yang);,Chen Wenzhuo);,Hua Haoqiang);,Li Qin);,Jin Jianxiu);,Xu Xiangmin","Shu L,Yu Y,Chen WZ,Hua HQ,Li Q,Jin JX,Xu XM",,10.3390/s20030718,,"Emotion recognition and monitoring based on commonly used wearable devices can play an important role in psychological health monitoring and human-computer interaction. However, the existing methods cannot rely on the common smart bracelets or watches for emotion monitoring in daily life. To address this issue, our study proposes a method for emotional recognition using heart rate data from a wearable smart bracelet. A 'neutral + target' pair emotion stimulation experimental paradigm was presented, and a dataset of heart rate from 25 subjects was established, where neutral plus target emotion (neutral, happy, and sad) stimulation video pairs from China's standard Emotional Video Stimuli materials (CEVS) were applied to the recruited subjects. Normalized features from the data of target emotions normalized by the baseline data of neutral mood were adopted. Emotion recognition experiment results approved the effectiveness of 'neutral + target' video pair simulation experimental paradigm, the baseline setting using neutral mood data, and the normalized features, as well as the classifiers of Adaboost and GBDT on this dataset. This method will promote the development of wearable consumer electronic devices for monitoring human emotional moods.","emotion recognition,smart bracelet,heart rate,wearable",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"CLASSIFICATION,TIME",SENSORS,https://res.mdpi.com/d_attachment/sensors/sensors-20-00718/article_deploy/sensors-20-00718-v2.pdf,
8,Two-Stream Attention Network for Pain Recognition from Video Sequences,20,3,,"Thiam Patrick,Kestler Hans A.,Schwenker Friedhelm","Thiam P,Kestler HA,Schwenker F",Schwenker F,10.3390/s20030839,Ulm University,"Several approaches have been proposed for the analysis of pain-related facial expressions. These approaches range from common classification architectures based on a set of carefully designed handcrafted features, to deep neural networks characterised by an autonomous extraction of relevant facial descriptors and simultaneous optimisation of a classification architecture. In the current work, an end-to-end approach based on attention networks for the analysis and recognition of pain-related facial expressions is proposed. The method combines both spatial and temporal aspects of facial expressions through a weighted aggregation of attention-based neural networks' outputs, based on sequences of Motion History Images (MHIs) and Optical Flow Images (OFIs). Each input stream is fed into a specific attention network consisting of a Convolutional Neural Network (CNN) coupled to a Bidirectional Long Short-Term Memory (BiLSTM) Recurrent Neural Network (RNN). An attention mechanism generates a single weighted representation of each input stream (MHI sequence and OFI sequence), which is subsequently used to perform specific classification tasks. Simultaneously, a weighted aggregation of the classification scores specific to each input stream is performed to generate a final classification output. The assessment conducted on both the BioVid Heat Pain Database (Part A) and SenseEmotion Database points at the relevance of the proposed approach, as its classification performance is on par with state-of-the-art classification approaches proposed in the literature.","convolutional neural networks,long short-term memory recurrent neural networks,information fusion,pain recognition",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7038688,
9,Improved Deep CNN with Parameter Initialization for Data Analysis of Near-Infrared Spectroscopy Sensors,20,3,,"Wang Di,Tian Fengchun,Yang Simon X.,Zhu Zhiqin,Jiang Daiyu,Cai Bin","Wang D,Tian FC,Yang SX,Zhu ZQ,Jiang DY,Cai B",Tian FC,10.3390/s20030874,Chongqing University,"Near-infrared (NIR) spectral sensors can deliver the spectral response of light absorbed by materials. Data analysis technology based on NIR sensors has been a useful tool for quality identification. In this paper, an improved deep convolutional neural network (CNN) with batch normalization and MSRA (Microsoft Research Asia) initialization is proposed to discriminate the tobacco cultivation regions using data collected from NIR sensors. The network structure is created with six convolutional layers and three full connection layers, and the learning rate is controlled by exponential attenuation method. One-dimensional kernel is applied as the convolution kernel to extract features. Meanwhile, the methods of L2 regularization and dropout are used to avoid the overfitting problem, which improve the generalization ability of the network. Experimental results show that the proposed deep network structure can effectively extract the complex characteristics inside the spectrum, which proves that it has excellent recognition performance on tobacco cultivation region discrimination, and it also demonstrates that the deep CNN is more suitable for information mining and analysis of big data.","NIR sensor,data analysis,convolutional neural network,cultivation region discrimination",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"CONVOLUTIONAL,NEURAL-NETWORKS,TOBACCO,QUALITY,ANALYSIS,SUPPORT,VECTOR,MACHINE,NIR,CLASSIFICATION",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7038673,
10,Advancing Semantic Interoperability of Image Annotations: Automated Conversion of Non-standard Image Annotations in a Commercial PACS to the Annotation and Image Markup,33,1,49-53,"Swinburne Nathaniel C.,Mendelson David,Rubin Daniel L.","Swinburne NC,Mendelson D,Rubin DL",Swinburne NC,10.1007/s10278-019-00191-6,Memorial Sloan Kettering Cancer Center,"Sharing radiologic image annotations among multiple institutions is important in many clinical scenarios; however, interoperability is prevented because different vendors' PACS store annotations in non-standardized formats that lack semantic interoperability. Our goal was to develop software to automate the conversion of image annotations in a commercial PACS to the Annotation and Image Markup (AIM) standardized format and demonstrate the utility of this conversion for automated matching of lesion measurements across time points for cancer lesion tracking. We created a software module in Java to parse the DICOM presentation state (DICOM-PS) objects (that contain the image annotations) for imaging studies exported from a commercial PACS (GE Centricity v3.x). Our software identifies line annotations encoded within the DICOM-PS objects and exports the annotations in the AIM format. A separate Python script processes the AIM annotation files to match line measurements (on lesions) across time points by tracking the 3D coordinates of annotated lesions. To validate the interoperability of our approach, we exported annotations from Centricity PACS into ePAD () (Rubin et al., Transl Oncol 7(1):23-35, 2014), a freely available AIM-compliant workstation, and the lesion measurement annotations were correctly linked by ePAD across sequential imaging studies. As quantitative imaging becomes more prevalent in radiology, interoperability of image annotations gains increasing importance. Our work demonstrates that image annotations in a vendor system lacking standard semantics can be automatically converted to a standardized metadata format such as AIM, enabling interoperability and potentially facilitating large-scale analysis of image annotations and the generation of high-quality labels for deep learning initiatives. This effort could be extended for use with other vendors' PACS.","Lesion tracking,Annotation and Image Markup (AIM),Data mining,Supervised training,Deep learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,,TRACKING,JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7064644,
11,Automated Detection of Radiology Reports that Require Follow-up Imaging Using Natural Language Processing Feature Engineering and Machine Learning Classification,33,1,131-136,"Lou Robert,Lalevic Darco,Chambers Charles,Zafar Hanna M.,Cook Tessa S.","Lou R,Lalevic D,Chambers C,Zafar HM,Cook TS",Lou R,10.1007/s10278-019-00271-7,University of Pennsylvania,"While radiologists regularly issue follow-up recommendations, our preliminary research has shown that anywhere from 35 to 50% of patients who receive follow-up recommendations for findings of possible cancer on abdominopelvic imaging do not return for follow-up. As such, they remain at risk for adverse outcomes related to missed or delayed cancer diagnosis. In this study, we develop an algorithm to automatically detect free text radiology reports that have a follow-up recommendation using natural language processing (NLP) techniques and machine learning models. The data set used in this study consists of 6000 free text reports from the author's institution. NLP techniques are used to engineer 1500 features, which include the most informative unigrams, bigrams, and trigrams in the training corpus after performing tokenization and Porter stemming. On this data set, we train naive Bayes, decision tree, and maximum entropy models. The decision tree model, with an F1 score of 0.458 and accuracy of 0.862, outperforms both the naive Bayes (F1 score of 0.381) and maximum entropy (F1 score of 0.387) models. The models were analyzed to determine predictive features, with term frequency of n-grams such as ""renal neoplasm"" and ""evalu with enhanc"" being most predictive of a follow-up recommendation. Key to maximizing performance was feature engineering that extracts predictive information and appropriate selection of machine learning algorithms based on the feature set.","Artificial intelligence,Binary classification,Follow-up,Machine learning,Natural language processing,Structured reporting",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"RECOMMENDATIONS,INFORMATION",JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7064732,
12,Automatic Catheter and Tube Detection in Pediatric X-ray Images Using a Scale-Recurrent Network and Synthetic Data,33,1,181-190,"Yi X.,Adams Scott,Babyn Paul,Elnajmi Abdul","Yi X,Adams S,Babyn P,Elnajmi A",Yi X,10.1007/s10278-019-00201-7,University of Saskatchewan,"Catheters are commonly inserted life supporting devices. Because serious complications can arise from malpositioned catheters, X-ray images are used to assess the position of a catheter immediately after placement. Previous computer vision approaches to detect catheters on X-ray images were either rule-based or only capable of processing a limited number or type of catheters projecting over the chest. With the resurgence of deep learning, supervised training approaches are beginning to show promising results. However, dense annotation maps are required, and the work of a human annotator is difficult to scale. In this work, we propose an automatic approach for detection of catheters and tubes on pediatric X-ray images. We propose a simple way of synthesizing catheters on X-ray images to generate a training dataset by exploiting the fact that catheters are essentially tubular structures with various cross sectional profiles. Further, we develop a UNet-style segmentation network with a recurrent module that can process inputs at multiple scales and iteratively refine the detection result. By training on adult chest X-rays, the proposed network exhibits promising detection results on pediatric chest/abdomen X-rays in terms of both precision and recall, with F-beta = 0.8. The approach described in this work may contribute to the development of clinical systems to detect and assess the placement of catheters on X-ray images. This may provide a solution to triage and prioritize X-ray images with potentially malpositioned catheters for a radiologist's urgent review and help automate radiology reporting.","X-ray,Catheter detection,Multi-scale,Deep learning,Recurrent network,Pediatric",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"VESSEL,SEGMENTATION,CHEST",JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7064683,
13,A Region-Based Deep Level Set Formulation for Vertebral Bone Segmentation of Osteoporotic Fractures,33,1,191-203,"Rehman Faisal,Shah Syed Irtiza,Riaz M. Naveed,Gilani S. Omer,Faiza R.","Rehman F,Shah SIA,Riaz MN,Gilani SO,Faiza R",Rehman F,10.1007/s10278-019-00216-0,National University of Sciences & Technology - Pakistan,"Accurate segmentation of the vertebrae from medical images plays an important role in computer-aided diagnoses (CADs). It provides an initial and early diagnosis of various vertebral abnormalities to doctors and radiologists. Vertebrae segmentation is very important but difficult task in medical imaging due to low-contrast imaging and noise. It becomes more challenging when dealing with fractured (osteoporotic) cases. This work is dedicated to address the challenging problem of vertebra segmentation. In the past, various segmentation techniques of vertebrae have been proposed. Recently, deep learning techniques have been introduced in biomedical image processing for segmentation and characterization of several abnormalities. These techniques are becoming popular for segmentation purposes due to their robustness and accuracy. In this paper, we present a novel combination of traditional region-based level set with deep learning framework in order to predict shape of vertebral bones accurately; thus, it would be able to handle the fractured cases efficiently. We termed this novel Framework as ""FU-Net"" which is a powerful and practical framework to handle fractured vertebrae segmentation efficiently. The proposed method was successfully evaluated on two different challenging datasets: (1) 20 CT scans, 15 healthy cases, and 5 fractured cases provided at spine segmentation challenge CSI 2014; (2) 25 CT image data (both healthy and fractured cases) provided at spine segmentation challenge CSI 2016 or xVertSeg.v1 challenge. We have achieved promising results on our proposed technique especially on fractured cases. Dice score was found to be 96.4 +/- 0.8% without fractured cases and 92.8 +/- 1.9% with fractured cases in CSI 2014 dataset (lumber and thoracic). Similarly, dice score was 95.2 +/- 1.9% on 15 CT dataset (with given ground truths) and 95.4 +/- 2.1% on total 25 CT dataset for CSI 2016 datasets (with 10 annotated CT datasets). The proposed technique outperformed other state-of-the-art techniques and handled the fractured cases for the first time efficiently.","Vertebral osteoporotic fracture,Vertebrae segmentation,Computer-aided diagnosis,Medical image analysis,Deep learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,,JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7064662,
14,Computer-Aided Detection of Incidental Lumbar Spine Fractures from Routine Dual-Energy X-Ray Absorptiometry (DEXA) Studies Using a Support Vector Machine (SVM) Classifier,33,1,204-210,"Mehta Samir D.,Sebro Ronnie","Mehta SD,Sebro R",Sebro R,10.1007/s10278-019-00224-0,University of Pennsylvania,"To assess whether application of a support vector machine learning algorithm to ancillary data obtained from posterior-anterior dual-energy X-ray absorptiometry (DEXA) studies could identify patients with lumbar spine (L1-L4) vertebral body fractures without additional DEXA imaging or radiation. Three hundred seven patients (199 without any fractures of the spine, and 108 patients with at least one fracture of the L1, L2, L3, or L4 vertebral bodies) who had DEXA studies were evaluated. Ancillary data from DEXA output was analyzed. The dataset was split into training (80%) and test (20%) datasets. Support vector machines (SVMs) with 10-fold cross-validation and different kernels were used to identify the best kernel based on the greatest area under the curve (AUC) and the best training vectors in the training dataset. The SVM with the best kernel was then applied to the test dataset to assess the accuracy of the SVM. Receiver operating characteristic (ROC) curves of the SVMs using different kernels in the test dataset were compared using DeLong's test. The SVM classifier with the linear kernel had the greatest AUC in the training dataset (AUC = 0.9258). The AUC of the SVM classifier with the linear kernel in the test dataset was 0.8963. The SVM classifier with the linear kernel had an overall average accuracy of 91.8% in the test dataset. The sensitivity, specificity, positive predictive value, and negative predictive of the SVM classifier with the linear kernel to detect lumbar spine fractures were 81.8%, 97.4%, 94.7%, and 90.5%, respectively. The SVM classifier with the linear kernel ROC curve had a significantly better AUC than the SVM classifier with the cubic polynomial kernel (P = 0.034) for discriminating between patients with lumbar spine fractures and control patients, but not significantly different from the SVM classifier with a radial basis function (RBF) kernel (P = 0.317) or the SVM classifier with a sigmoid kernel (P = 0.729). All fractures identified by the SVM classifiers were not prospectively identified by the radiologist. SVM analysis of ancillary data obtained from routine DEXA studies can identify lumbar spine fractures without the use of vertebral fracture assessment (VFA) DEXA imaging or radiation, and identify fractures missed by radiologists.","Support vector machine,Osteoporosis,DEXA,Lumbar spine fracture",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"BONE-MINERAL,DENSITY,HIP,FRACTURE,UNIVERSAL,STANDARDIZATION,PAGETS-DISEASE,CALIBRATION,MORTALITY,WEIGHT,RISK,MASS,DXA",JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7064727,
15,Fully Automated Lung Lobe Segmentation in Volumetric Chest CT with 3D U-Net: Validation with Intra- and Extra-Datasets,33,1,221-230,"Park Jongha,Yun Jihye,Kim Namkug,Park Beomhee,Cho Yongwon,Park Hee Jun,Song Mijeong,Lee Minho,Seo Joon Beom","Park J,Yun J,Kim N,Park B,Cho Y,Park HJ,Song M,Lee M,Seo JB",Kim N,10.1007/s10278-019-00223-1,University of Ulsan,"Lung lobe segmentation in chest CT has been used for the analysis of lung functions and surgical planning. However, accurate lobe segmentation is difficult as 80% of patients have incomplete and/or fake fissures. Furthermore, lung diseases such as chronic obstructive pulmonary disease (COPD) can increase the difficulty of differentiating the lobar fissures. Lobar fissures have similar intensities to those of the vessels and airway wall, which could lead to segmentation error in automated segmentation. In this study, a fully automated lung lobe segmentation method with 3D U-Net was developed and validated with internal and external datasets. The volumetric chest CT scans of 196 normal and mild-to-moderate COPD patients from three centers were obtained. Each scan was segmented using a conventional image processing method and manually corrected by an expert thoracic radiologist to create gold standards. The lobe regions in the CT images were then segmented using a 3D U-Net architecture with a deep convolutional neural network (CNN) using separate training, validation, and test datasets. In addition, 40 independent external CT images were used to evaluate the model. The segmentation results for both the conventional and deep learning methods were compared quantitatively to the gold standards using four accuracy metrics including the Dice similarity coefficient (DSC), Jaccard similarity coefficient (JSC), mean surface distance (MSD), and Hausdorff surface distance (HSD). In internal validation, the segmentation method achieved high accuracy for the DSC, JSC, MSD, and HSD (0.97 +/- 0.02, 0.94 +/- 0.03, 0.69 +/- 0.36, and 17.12 +/- 11.07, respectively). In external validation, high accuracy was also obtained for the DSC, JSC, MSD, and HSD (0.96 +/- 0.02, 0.92 +/- 0.04, 1.31 +/- 0.56, and 27.89 +/- 7.50, respectively). This method took 6.49 +/- 1.19 s and 8.61 +/- 1.08 s for lobe segmentation of the left and right lungs, respectively. Although various automatic lung lobe segmentation methods have been developed, it is difficult to develop a robust segmentation method. However, the deep learning-based 3D U-Net method showed reasonable segmentation accuracy and computational time. In addition, this method could be adapted and applied to severe lung diseases in a clinical workflow.","3D U-net,Convolutional neural network,Deep learning,Lung lobe segmentation",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,,JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7064651,
16,Performance of a Deep Learning Algorithm for Automated Segmentation and Quantification of Traumatic Pelvic Hematomas on CT,33,1,243-251,"Dreizin David,Zhou Yuyin,Zhang Yixiao,Tirada Nikki,Yuille Alan L.","Dreizin D,Zhou YY,Zhang YX,Tirada N,Yuille AL",Dreizin D,10.1007/s10278-019-00207-1,University System of Maryland,"The volume of pelvic hematoma at CT has been shown to be the strongest independent predictor of major arterial injury requiring angioembolization in trauma victims with pelvic fractures, and also correlates with transfusion requirement and mortality. Measurement of pelvic hematomas (unopacified extraperitoneal blood accumulated from time of injury) using semi-automated seeded region growing is time-consuming and requires trained experts, precluding routine measurement at the point of care. Pelvic hematomas are markedly variable in shape and location, have irregular ill-defined margins, have low contrast with respect to viscera and muscle, and reside within anatomically distorted pelvises. Furthermore, pelvic hematomas occupy a small proportion of the entire volume of a chest, abdomen, and pelvis (C/A/P) trauma CT. The challenges are many, and no automated methods for segmentation and volumetric analysis have been described to date. Traditional approaches using fully convolutional networks result in coarse segmentations and class imbalance with suboptimal convergence. In this study, we implement a modified coarse-to-fine deep learning approach-the Recurrent Saliency Transformation Network (RSTN) for pelvic hematoma volume segmentation. RSTN previously yielded excellent results in pancreas segmentation, where low contrast with adjacent structures, small target volume, variable location, and fine contours are also problematic. We have curated a unique single-institution corpus of 253 C/A/P admission trauma CT studies in patients with bleeding pelvic fractures with manually labeled pelvic hematomas. We hypothesized that RSTN would result in sufficiently high Dice similarity coefficients to facilitate accurate and objective volumetric measurements for outcome prediction (arterial injury requiring angioembolization). Cases were separated into five combinations of training and test sets in an 80/20 split and fivefold cross-validation was performed. Dice scores in the test set were 0.71 (SD +/- 0.10) using RSTN, compared to 0.49 (SD +/- 0.16) using a baseline Deep Learning Tool Kit (DLTK) reference 3D U-Net architecture. Mean inference segmentation time for RSTN was 0.90 min (+/- 0.26). Pearson correlation between predicted and manual labels was 0.95 with p < 0.0001. Measurement bias was within 10 mL. AUC of hematoma volumes for predicting need for angioembolization was 0.81 (predicted) versus 0.80 (manual). Qualitatively, predicted labels closely followed hematoma contours and avoided muscle and displaced viscera. Further work will involve validation using a federated dataset and incorporation into a predictive model using multiple segmented features.","Pelvic fractures,Pelvic ring disruptions,Computed tomography (CT),Hematoma volume,Segmentation,Deep learning,Artificial intelligence (AI),Computer-aided diagnosis (CAD),Convolutional neural network (CNN),Fully convolutional network (FCN),Recurrent saliency transformation network (RSTN)",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"HEMORRHAGE,PREDICTORS,FRACTURES,MORTALITY,NETWORK,VOLUME",JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7064706,
17,Inconsistency Calibrating Algorithms for Large Scale Piezoresistive Electronic Skin,11,2,,"Ye Jinhua,Lin Zhengkang,You Jinyan,Huang Shuheng,Wu Haibin","Ye JH,Lin ZK,You JY,Huang SH,Wu HB",Wu HB,10.3390/mi11020162,Fuzhou University,"In the field of safety and communication of human-robot interaction (HRI), using large-scale electronic skin will be the tendency in the future. The force-sensitive piezoresistive material is the key for piezoresistive electronic skin. In this paper, a non-array large scale piezoresistive tactile sensor and its corresponding calibration methods were presented. Because of the creep inconsistency of large scale piezoresistive material, a creep tracking compensation method based on K-means clustering and fuzzy pattern recognition was proposed to improve the detection accuracy. With the compensated data, the inconsistency and nonlinearity of the sensor was calibrated. The calibration process was divided into two parts. The hierarchical clustering algorithm was utilized firstly to classify and fuse piezoresistive property of different regions over the whole sensor. Then, combining the position information, the force detection model was constructed by Back-Propagation (BP) neural network. At last, a novel flexible tactile sensor for detecting contact position and force was designed as an example and tested after being calibrated. The experimental results showed that the calibration methods proposed were effective in detecting force, and the detection accuracy was improved.","calibration,electronic skin,inconsistency,large scale,piezoresistive",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Science & Technology - Other Topics,Instruments & Instrumentation,Physics",,2.943,"TACTILE,SENSOR,PERCEPTION,RUBBER",MICROMACHINES,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7074581,
18,An efficient automatic segmentation of spinal cord in MRI images using interactive random walker (RW) with artificial bee colony (ABC) algorithm,79,5-6,3623-3644,"Brindha D.,Nagarajan N.","Brindha D,Nagarajan N",Brindha D,10.1007/s11042-018-6331-8,"Coimbatore Inst Engn & Technol, ECE Dept, Coimbatore, Tamil Nadu, India.","Spinal cord Magnetic Resonance Images (MRI) have a remarkable role to play in the learning of neurological diseases such as Multiple Sclerosis (MS) affecting the Central Nervous System (CNS), in which spinal cord atrophy can help in the measurement of disease advancement and the changes in shape. Spinal cord segmentation plays a significant part in analyzing the neurological disease. In this paper here, an approach on the basis of the automatic spinal cord segmentation is proposed. This automatic technique presented performs the segmentation of the spinal cord with the help of MRI datasets. This new segmentation follows the interactive Random-Walk solvers (RW) along with Artificial Bee Colony (ABC) optimization algorithm in order to be an entirely automatic flow pipeline. The initialization of the automatic segmentation pipeline is then done with a reliable voxel-wise classification employing features similar to Haar and supervised machine learning technique i.e. Probabilistic Boosting Tree (PBT) along with Support Vector Machine (SVM) so named as PBTSVM. Thereafter, the extraction of the refinement topology of the spinal cord is then done from the temporary segmentation and it is fine-tuned for the further next random-walk solver with ABC. The refined topology results in the spinal cord's boundary conditions from the MRI that permits the following random-walk solver with ABC for improving the segmentation result. The experimental outcomes of the novel segmentation approach depending on the MRI images indicate that the system proposed PBT-SVM algorithm provides better accuracy when compared to the other existing Active Contour Model, Multi-Resolution Propagation algorithms. Experimentation results of the proposed PBT-SVM algorithm produces higher accuracy results of 93% which is 2.5 and 3.233% higher when compared to Active Contour Model and Multi-Resolution Propagation methods respectively.","Central nervous system (CNS),Spinal cord segmentation,Magnetic resonance images (MRI),Random-walk solvers (RW),Artificial bee Colony (ABC),Probabilistic boosting tree (PBT),Support vector machine (SVM)",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,CT,MULTIMEDIA TOOLS AND APPLICATIONS,,
19,Classification of melanoma from Dermoscopic data using machine learning techniques,79,5-6,3713-3728,"Janney J Bethanney,Roslin S. Emalda","Janney B,Roslin SE",Janney B,10.1007/s11042-018-6927-z,Sathyabama Institute of Science & Technology,"Melanoma is a skin disorder, occurring in melanocytes. They are classified as Benign and Malignant. The cure of melanoma is effective, if it can be recognized early. The most crucial part in the cure of melanoma is the exact classification and determining the group of melanoma. A comparative study for classifying the group of melanoma using the supervised machine learning algorithms is discussed in this proposed work. Classification of melanoma from dermoscopic data is proposed to help the clinical utilization of dermatoscopy imaging methods for skin sores classification. The images were enhanced using anisotropic diffusion filter and unsharp masking. The melanoma was segmented from the background using adaptive k-means clustering algorithm with two clusters followed by feature extraction methods are based on intensity and texture features from the segmented data, which is followed by training of classifier and finally testing on unknown dermoscopic data. Classifiers such as k-nearest neighbour, support vector machine, multi-layer perceptron, decision tree and random forest were used. To test the performance of the classifiers, the area under the receiver operating characteristics curve (ROC) is utilized. The Random forest method is found to achieve 93% accuracy and classifies melanoma significantly good as compared to other classifiers.","Melanoma,Image enhancement,Segmentation,Feature extraction,Machine learning",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"SKIN-CANCER,SEGMENTATION",MULTIMEDIA TOOLS AND APPLICATIONS,,
20,A new expert system based on hybrid colour and structure descriptor and machine learning algorithms for early glaucoma diagnosis,79,7-8,5213-5224,"David D. Stalin,Jayachandran A.","David DS,Jayachandran A",David DS,10.1007/s11042-018-6265-1,"PSN Coll Engn & Technol, Dept CSE, Tirunelveli, India.","Medical image classification system is widely used by the radiologists to segment the medical images into meaningful regions. Glaucoma is an optic neuropathy defined by characteristic damage to the optic nerve and accompanying visual field deficits. Early diagnosis and treatment are critical to prevent irreversible vision loss and ultimate blindness. Automatic detection of diabetic retinopathy in retinal image is vital as it delivers data about unusual tissues which is essential for planning treatment. Automating, this method is challenging due to the high variabiity in the appearance of tissue among dissimilar patients and in many circumstances, the comparison between abnormal and normal tissue. This paper presents a new methodology and a computerized diagnostic system for diabetic retinopathy. In this article, adaptive histogram equalization is used to convert colour images to gray scale images followed by significant features are selected using hybrid colour and structure descriptor (HCSD). Finally, various classifiers are used for classification of images into normal and glaucomatous classes. The overall classification accuracy of HCSD with Hybrid Radial Basis Kernel based Support vector Machine (HRKSVM) is 97.55%, HCSD with Support vector Machine (SVM) is 94.77% and HCSD with Hybrid Kernel Support Vector Machine (HKSVM) is 95.71%.","Classification,Feature extraction,Texture,Segmentation,Retinal images",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,,"LEVEL,SET,ACTIVE,CONTOURS,BRAIN-TUMOR,CLASSIFICATION,MODEL",MULTIMEDIA TOOLS AND APPLICATIONS,,
21,A deep neural network for classification of melt-pool images in metal additive manufacturing,31,2,375-386,"Kwon Ohyung,Kim Hyung Giun,Ham Min Ji,Kim Wonrae,Kim Gun-Hee,Cho Jae-Hyung,Kim Nam Il,Kim Kangil","Kwon O,Kim HG,Ham MJ,Kim W,Kim GH,Cho JH,Kim NI,Kim K",Kim K,10.1007/s10845-018-1451-6,Konkuk University,"By applying a deep neural network to selective laser melting, we studied a classification model of melt-pool images with respect to 6 laser power labels. Laser power influenced to form pores or cracks determining the part quality and was positively-linearly dependent to the density of the part. Using the neural network of which the number of nodes is dropped with increasing the layer number achieved satisfactory inference when melt-pool images had blurred edges. The proposed neural network showed the classification failure rate under 1.1% for 13,200 test images and was more effective to monitor melt-pool images because it simultaneously handled various shapes, comparing with a simple calculation such as the sum of pixel intensity in melt-pool images. The classification model could be utilized to infer the location to cause the unexpected alteration of microstructures or separate the defective products non-destructively.","Additive manufacturing,Powder bed fusion,Selective laser melting,Melt-pool classification,Deep neural network",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,5.829,"PROCESSING,PARAMETERS,LASER,MECHANISM,BEHAVIOR",JOURNAL OF INTELLIGENT MANUFACTURING,,
22,Deep Learning for the Inverse Design of Mid-Infrared Graphene Plasmons,10,2,,"Phan Anh D.,Nguyen Cuong V.,Linh Pham T.,Huynh Tran V.,Lam Vu D.,Le Anh-Tuan,Wakabayashi Katsunori","Phan AD,Nguyen CV,Linh PT,Huynh TV,Lam VD,Le AT,Wakabayashi K",Phan AD,10.3390/cryst10020125,"Phenikaa Univ, Phenikaa Inst Adv Study, Fac Informat Technol Mat Sci & Engn, Hanoi 12116, Vietnam.","We theoretically investigate the plasmonic properties of mid-infrared graphene-based metamaterials and apply deep learning of a neural network for the inverse design. These artificial structures have square periodic arrays of graphene plasmonic resonators deposited on dielectric thin films. Optical spectra vary significantly with changes in structural parameters. To validate our theoretical approach, we carry out finite difference time domain simulations and compare computational results with theoretical calculations. Quantitatively good agreements among theoretical predictions, simulations, and previous experiments allow us to employ this proposed theoretical model to generate reliable data for training and testing deep neural networks. By merging the pre-trained neural network with the inverse network, we implement calculations for inverse design of the graphene-based metameterials. We also discuss the limitation of the data-driven approach.","graphene,metamaterials,deep learning,inverse design,plasmonics",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Crystallography,Materials Science",,2.615,FREQUENCY,CRYSTALS,http://arxiv.org/pdf/1911.12566,
23,Estimating Coarse Woody Debris Volume Using Image Analysis and Multispectral LiDAR,11,2,,"Lopes Queiroz Gustavo,McDermid Gregory J.,Linke Julia,Hopkinson Christopher,Kariyeva Jahan","Queiroz GL,McDermid GJ,Linke J,Hopkinson C,Kariyeva J",Queiroz GL,10.3390/f11020141,University of Calgary,"Coarse woody debris (CWD, parts of dead trees) is an important factor in forest management, given its roles in promoting local biodiversity and unique microhabitats, as well as providing carbon storage and fire fuel. However, parties interested in monitoring CWD abundance lack accurate methods to measure CWD accurately and extensively. Here, we demonstrate a novel strategy for mapping CWD volume (m(3)) across a 4300-hectare study area in the boreal forest of Alberta, Canada using optical imagery and an infra-canopy vegetation-index layer derived from multispectral aerial LiDAR. Our models predicted CWD volume with a coefficient of determination (R2) value of 0.62 compared to field data, and a root-mean square error (RMSE) of 0.224 m(3)/100 m(2). Models using multispectral LiDAR data in addition to image-analysis data performed with up to 12% lower RMSE than models using exclusively image-analysis layers. Site managers and researchers requiring reliable and comprehensive maps of CWD volume may benefit from the presented workflow, which aims to streamline the process of CWD measurement. As multispectral LiDAR radiometric calibration routines are developed and standardized, we expect future studies to benefit increasingly more from such products for CWD detection underneath canopy cover.","woody debris,boreal forest,remote sensing,GEOBIA,random forest,machine learning,LiDAR",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Forestry,,2.804,"GENERALIZED,ADDITIVE-MODELS,STAND,STRUCTURE,BOREAL,TREES,DISTURBANCE",FORESTS,https://www.mdpi.com/1999-4907/11/2/141/pdf,
24,"Potential of Genome-Wide Association Studies and Genomic Selection to Improve Productivity and Quality of Commercial Timber Species in Tropical Rainforest, a Case Study of Shorea platyclados",11,2,,"Sawitri,Tani Naoki,Na'iem Mohammad,Widiyatno,Indrioko Sapto,Uchiyama Kentaro,Suwa Rempei,Ng Kevin Kit Siong,Lee Soon Leong,Tsumura Yoshihiko","Sawitri,Tani N,Na'iem M,Widiyatno,Indrioko S,Uchiyama K,Suwa R,Ng KKS,Lee SL,Tsumura Y",Tani N,10.3390/f11020239,Japan International Research Center for Agricultural Sciences,"Shorea platyclados (Dark Red Meranti) is a commercially important timber tree species in Southeast Asia. However, its stocks have dramatically declined due, inter alia, to excessive logging, insufficient natural regeneration and a slow recovery rate. Thus, there is a need to promote enrichment planting and develop effective technique to support its rehabilitation and improve timber production through implementation of Genome-Wide Association Studies (GWAS) and Genomic Selection (GS). To assist such efforts, plant materials were collected from a half-sib progeny population in Sari Bumi Kusuma forest concession, Kalimantan, Indonesia. Using 5900 markers in sequences obtained from 356 individuals, we detected high linkage disequilibrium (LD) extending up to >145 kb, suggesting that associations between phenotypic traits and markers in LD can be more easily and feasibly detected with GWAS than with analysis of quantitative trait loci (QTLs). However, the detection power of GWAS seems low, since few single nucleotide polymorphisms linked to any focal traits were detected with a stringent false discovery rate, indicating that the species' phenotypic traits are mostly under polygenic quantitative control. Furthermore, Machine Learning provided higher prediction accuracies than Bayesian methods. We also found that stem diameter, branch diameter ratio and wood density were more predictable than height, clear bole, branch angle and wood stiffness traits. Our study suggests that GS has potential for improving the productivity and quality of S. platyclados, and our genomic heritability estimates may improve the selection of traits to target in future breeding of this species.","Shorea platyclados,GWAS,GS,growth,wood quality traits,genomic heritability",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Forestry,,2.804,"LINKAGE,DISEQUILIBRIUM,DEMOGRAPHIC,HISTORY,STATISTICAL-METHODS,TRAITS,PREDICTION,POPULATION,REGRESSION,MODELS,PLANT,DIPTEROCARPACEAE",FORESTS,https://tsukuba.repo.nii.ac.jp/?action=repository_action_common_download&item_id=55927&item_no=1&attribute_id=17&file_no=1,
25,Improved VIV Response Prediction Using Adaptive Parameters and Data Clustering,8,2,,"Wu Jie,Yin Decao,Lie Halvor,Riemer-Sorensen Signe,Saevik Svein,Triantafyllou Michael","Wu J,Yin DC,Lie H,Riemer-Sorensen S,Saevik S,Triantafyllou M",Wu J,10.3390/jmse8020127,SINTEF,"Slender marine structures such as deep-water riser systems are continuously exposed to currents, leading to vortex-induced vibrations (VIV) of the structure. This may result in amplified drag loads and fast accumulation of fatigue damage. Consequently, accurate prediction of VIV responses is of great importance for the safe design and operation of marine risers. Model tests with elastic pipes have shown that VIV responses are influenced by many structural and hydrodynamic parameters, which have not been fully modelled in present frequency domain VIV prediction tools. Traditionally, predictions have been computed using a single set of hydrodynamic parameters, often leading to inconsistent prediction accuracy when compared with observed field measurements and experimental data. Hence, it is necessary to implement a high safety factor of 10-20 in the riser design, which increases development costs and adds extra constraints in the field operation. One way to compensate for the simplifications in the mathematical prediction model is to apply adaptive parameters to describe different riser responses. The objective of this work is to demonstrate a new method to improve the prediction consistency and accuracy by applying adaptive hydrodynamic parameters. In the present work, a four-step approach has been proposed: First, the measured VIV response will be analysed to identify key parameters to represent the response characteristics. These parameters will be grouped by using data clustering algorithms. Secondly, optimal hydrodynamic parameters will be identified for each data group by optimisation against measured data. Thirdly, the VIV response using the obtained parameters will be calculated and the prediction accuracy evaluated. Last but not least, classification algorithms will be applied to determine the correct hydrodynamic parameters to be used for new cases. An iteration of the previous steps may be needed if the prediction accuracy of the new case is not satisfactory. This concept has been demonstrated with examples from experimental data.","vortex-induced vibrations,model test,hydrodynamics,machine learning,data clustering,data classification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Engineering,Oceanography",,2.455,"VORTEX-INDUCED,VIBRATIONS,FLEXIBLE,CYLINDER",JOURNAL OF MARINE SCIENCE AND ENGINEERING,https://dspace.mit.edu/bitstream/1721.1/125575/1/jmse-08-00127.pdf,
26,Optimizing convolutional neural networks to perform semantic segmentation on large materials imaging datasets: X-ray tomography and serial sectioning,160,,,"Stan Tiberiu,Thompson Zachary T.,Voorhees Peter W.","Stan T,Thompson ZT,Voorhees PW",Stan T,10.1016/j.matchar.2020.110119,Northwestern University,"Machine learning was used to segment large materials science datasets resulting from synchrotron-based x-ray computed tomography (XCT) images of dendrite growth, and serial sectioning (SS) images of dendrite coarsening. Both neural networks (NNs) yielded quantitatively more accurate outputs than conventional segmentation techniques using only 30 XCT or 6 SS training images. We show that performance can be improved if NNs are trained using a large number of small images that are sampled from the fixed amount of training data. The optimal image size and number of training images was identified for the XCT and SS datasets. NN transferability was also tested by applying the highest performing XCT and SS NNs to related datasets. While the initial segmentations were successful, applying simple transformations to the raw images further improved NN performance. These results show the great predictive ability and promising future of using machine learning for segmentation of large materials science datasets.","Machine learning,Convolutional neural network,Semantic segmentation,X-ray tomography,Serial sectioning,Solidification",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Materials Science,Metallurgy & Metallurgical Engineering",,4.256,"EVOLUTION,TEXTURE",MATERIALS CHARACTERIZATION,https://www.sciencedirect.com/science/article/am/pii/S1044580319304930,
27,Non-contact physical stress measurement using thermal imaging and blind source separation,27,1,116-125,Hong Kan,Hong K,Hong K,10.1007/s10043-019-00573-9,Jiangxi University of Finance & Economics,"The non-contact method is used to detect the physical stress of the human body, thereby providing a good model for practical application. However, the existing method is highly inaccurate and requires people's background information. This study introduces a new method to detect the physical stress of the human body by maximizing thermal infrared imaging. First, the method of multi-object correlation is used to determine the region of interest that the face is sensitive to physical stress. Furthermore, the stress signal is extracted through the thermal signal and the method based on blind source separation is adopted to convert the thermal signal into an independent component that is sensitive to stress. Second, the independent component signal is amplified to extract the peak frequency. Lastly, the baseline and physical stress states are classified and identified using the deep learning algorithm model. The algorithm model was verified with respect to the physical stress ground truth to classify the baseline and physical stress status. The algorithm achieved improved results in the experiment with an accuracy rate of 90%, thereby providing a foundation for future industrialization. Experimental results demonstrated that thermal imaging, as a non-invasive method without background information, has the potential to detect physical stress among humans. This demonstration is the first thermal imaging-based method for contact-free physical stress detection.","Thermal imaging,Physical stress",Article,"OPTICAL SOC JAPAN, KUDAN-KITA BLDG 5F, 1-12-3, KUDAN-KITA CHIYODA-KU, TOKYO, 102, JAPAN",Optics,,0.789,"EMOTIONAL-STRESS,CLASSIFICATION,PREDICTION,FACE",OPTICAL REVIEW,,
28,Human Visual System vs Convolution Neural Networks in food recognition task: An empirical comparison,191,,,"Furtado Pedro,Caldeira Manuel,Martins Pedro","Furtado P,Caldeira M,Martins P",Furtado P,10.1016/j.cviu.2019.102878,Universidade de Coimbra,"Automated food recognition from food plate is useful for smartphone-based applications promoting healthy lifestyles and for automated carbohydrate counting, e.g. targeted at type I diabetic patients, but the variation of appearance of food items makes it a difficult task. Convolution Neural Networks (CNNs) raised to prominence in recent years, and they will enable those applications if they are able to match HVS accuracy at least in meal classification. In this work we run an experimental comparison of accuracy between CNNs and HVS based on a simple meal recognition task. We set up a survey for humans with two phases, training and testing, and also give the food dataset to state-of-the-art CNNs. The results, considering some relevant variations in the setup, allow us to reach conclusions regarding the comparison, characteristics and limitations of CNNs, which are relevant for future improvements.","Deep learning,Machine learning,Food recognition",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Computer Science,Engineering",,3.532,,COMPUTER VISION AND IMAGE UNDERSTANDING,,
29,Ultrasensitive and ultrathin phototransistors and photonic synapses using perovskite quantum dots grown from graphene lattice,6,7,,"Pradhan Basudev,Das Sonali,Li Jinxin,Chowdhury Farzana,Cherusseri Jayesh,Pandey Deepak,Dev Durjoy,Krishnaprasad Adithi,Barrios Elizabeth,Towers Andrew","Pradhan B,Das S,Li JX,Chowdhury F,Cherusseri J,Pandey D,Dev D,Krishnaprasad A,Barrios E,Towers A",Roy T; Thomas J,10.1126/sciadv.aay5225,State University System of Florida,"Organic-inorganic halide perovskite quantum dots (PQDs) constitute an attractive class of materials for many opto-electronic applications. However, their charge transport properties are inferior to materials like graphene. On the other hand, the charge generation efficiency of graphene is too low to be used in many optoelectronic applications. Here, we demonstrate the development of ultrathin phototransistors and photonic synapses using a graphene-PQD (G-PQD) superstructure prepared by growing PQDs directly from a graphene lattice. We show that the G-PQDs superstructure synchronizes efficient charge generation and transport on a single platform. G-PQD phototransistors exhibit excellent responsivity of 1.4 x 10(8) AW(-1) and specific detectivity of 4.72 x 10(15) Jones at 430 nm. Moreover, the light-assisted memory effect of these superstructures enables photonic synaptic behavior, where neuromorphic computing is demonstrated by facial recognition with the assistance of machine learning. We anticipate that the G-PQD superstructures will bolster new directions in the development of highly efficient optoelectronic devices.",CRYSTALS,Article,"AMER ASSOC ADVANCEMENT SCIENCE, 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA",Science & Technology - Other Topics,,16.45,CRYSTALS,SCIENCE ADVANCES,https://europepmc.org/articles/pmc7015692?pdf=render,
30,Machine learning empowers phosphoproteome prediction in cancers,36,3,859-864,"Li Hongyang,Guan Yuanfang","Li HY,Guan YF",Li HY; Guan YF,10.1093/bioinformatics/btz639,University of Michigan System,"Motivation: Reversible protein phosphorylation is an essential post-translational modification regulating protein functions and signaling pathways in many cellular processes. Aberrant activation of signaling pathways often contributes to cancer development and progression. The mass spectrometry-based phosphoproteomics technique is a powerful tool to investigate the site-level phosphorylation of the proteome in a global fashion, paving the way for understanding the regulatory mechanisms underlying cancers. However, this approach is time-consuming and requires expensive instruments, specialized expertise and a large amount of starting material. An alternative in silico approach is predicting the phosphoproteomic profiles of cancer patients from the available proteomic, transcriptomic and genomic data.
Results: Here, we present a winning algorithm in the 2017 NCI-CPTAC DREAM Proteogenomics Challenge for predicting phosphorylation levels of the proteome across cancer patients. We integrate four components into our algorithm, including (i) baseline correlations between protein and phosphoprotein abundances, (ii) universal protein-protein interactions, (iii) shareable regulatory information across cancer tissues and (iv) associations among multi-phosphorylation sites of the same protein. When tested on a large held-out testing dataset of 108 breast and 62 ovarian cancer samples, our method ranked first in both cancer tissues, demonstrating its robustness and generalization ability.","PROTEIN-PHOSPHORYLATION,PROTEOGENOMIC CHARACTERIZATION,PROTEOMICS,BIOLOGY,GUIDE,OMICS",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Computer Science,Mathematical & Computational Biology,Mathematics",,,"PROTEIN-PHOSPHORYLATION,PROTEOGENOMIC,CHARACTERIZATION,PROTEOMICS,BIOLOGY,GUIDE,OMICS",BIOINFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7868059,
31,Fast location and classification of small targets using region segmentation and a convolutional neural network,169,,,"Wu Zhengmin,Luo Kun,Cao Chengmao,Liu Guangzong,Wang Errui,Li Wenbao","Wu ZM,Luo K,Cao CM,Liu GZ,Wang ER,Li WB",Cao CM,10.1016/j.compag.2019.105207,Anhui Agricultural University,"The hickory nut has rich nutritional and high economic value, but its inner wall structure is complex, making it inconvenient to separate the kernel from the hickory nut fragments for consumption. In this study, we apply a deep convolutional neural network algorithm to hickory nut fragments after shell breaking, to accurately sort kernels, shells, and unseparated bodies. Region segmentation is used to eliminate interference when locating multiple small targets of different sizes, and a custom dataset of 15,000 target images after shell breaking is created. Then, three different loss function optimization methods are evaluated for model optimization. Results revealed that the model only minimizes the average cross-entropy loss, and that using dropout at the first fully connected layer with a dropout rate 0.1 provides the best shell, kernel, and unseparated body identification accuracy of 97.14%, 99.66%, and 96.48%, respectively. Notably, the kernel and unseparated body recognition rates are considerably improved over other methods. Finally, a total of 450 hickory nut fragments were divided into 30 batches for a sorting experiment. The resulting shell, kernel, and unseparated body identification accuracy is 94.00%, 98.67%, and 95.33%, respectively. These results demonstrate that the proposed method provides excellent classification of hickory nut fragments according to the material. This approach can be easily applied to any small target sorting application.","Region segmentation,Convolutional neural network,Classification,Hickory nut",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Agriculture,Computer Science",,5.494,"PISTACHIO,NUTS,SEPARATION,SELECTION,FRUIT",COMPUTERS AND ELECTRONICS IN AGRICULTURE,,
32,Sparse Ensemble Machine Learning to Improve Robustness of Long-Term Decoding in iBMIs,28,2,380-389,"Shaikh Shoeb,So Rosa,Sibindi Tafadzwa,Libedinsky Camilo,Basu Arindam","Shaikh S,So RS,Sibindi T,Libedinsky C,Basu A",Shaikh S,10.1109/TNSRE.2019.2962708,Nanyang Technological University & National Institute of Education (NIE) Singapore,"This paper presents a novel sparse ensemble based machine learning approach to enhance robustness of intracortical Brain Machine Interfaces (iBMIs) in the face of non-stationary distribution of input neural data across time. Each classifier in the ensemble is trained on a randomly sampled (with replacement) set of input channels. These sparse connections ensure that with a high chance, few of the base classifiers should be less affected by the variations in some of the recording channels. We have tested the generality of this technique on different base classifiers - linear discriminant analysis (LDA), support vector machine (SVM), extreme learning machine (ELM) and multilayer perceptron (MLP). Results show decoding accuracy improvements of up to approximate to 21 %, 13%, 19%, 10% in non-human primate (NHP) A and 7%, 9%, 7%, 9% in NHP B across test days while using the sparse ensemble approach over a single classifier model for LDA, SVM, ELM and MLP algorithms respectively. Furthermore, improvements of up to approximate to 7(14)%, 8(15)%, 9(19)%, 7(15)% in NHP A and 8(15)%, 12(20)%, 15(23)%, 12(19)% in NHP B over Random Forest (Long-short Term Memory) have been obtained by sparse ensemble LDA, SVM, ELM, MLP respectively.","Intra-cortical brain machine interface (iBMI),nonstationarity,sparse connections",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,,"ARM,MOVEMENTS,BRAIN,DIRECTION,CORTEX",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,https://www.biorxiv.org/content/biorxiv/early/2019/11/07/834028.full.pdf,
33,A Between-Subject fNIRS-BCI Study on Detecting Self-Regulated Intention During Walking,28,2,531-540,"Li Chunguang,Su Min,Xu Jiacheng,Jin Hedian,Sun Lining","Li CG,Su M,Xu JC,Jin HD,Sun LN",Xu JC,10.1109/TNSRE.2020.2965628,Suzhou University,"Objective: Most BCI (brain-computer interface) studies have focused on detecting motion intention from a resting state. However, the dynamic regulation of two motion states, which usually happens in real life, is rarely studied. Besides, popular within-subject methods also require an extensive and time-consuming learning stage when testing on a new subject. This paper proposed a method to discriminate dynamic gait- adjustment intention with strong adaptability for different subjects. Methods: Cerebral hemoglobin signals obtained from 30 subjects were studied to decode gait-adjustment intention. Cerebral hemoglobin information was recorded by using fNIRS (functional near infrared spectroscopy) technology. Mathematical morphology filtering was applied to remove zero drift and EWM (Entropy Weight Method) was used to calculate the average hemoglobin values over Regions of Interest (ROIs). The gradient boosting decision tree (GBDT) was utilized to detect the onset of self-regulated intention. A 2-layer-GA-SVM (Genetic Algorithm-Support Vector Machine) model based on stacking algorithm was further proposed to identify the four types of self-regulated intention (speed increase, speed reduction, step increase, and step reduction). Results: It was found that GBDT had a good performance to detect the onset intention with an average AUC (Area Under Curve) of 0.894. The 2-layer-GA-SVM model boosted the average ACC (accuracy) of four types of intention from 70.6% to 84.4% (p =0.005) from the single GA-SVM model. Furthermore, the proposed method passed pseudo-online test with the average results as following: AUC = 0.883, TPR (True Positive Rate) = 97.5%, FPR (False Positive Rate) = 0.11%, and LAY (Detection Latency) = -0.52 +/- 2.57 seconds for the recognition of gait-adjustment intention; ACC = 80% for the recognition of adjusted gait. Conclusion: The results indicate that it is feasible to decode dynamic gait-adjustment intentions from a motion state for different subjects based on fNIRS technology. It has a potential to realize the practical application of fNIRS-based brain-computer interface technology in controlling walking-assistive devices.","Brain-computer interface,functional near infrared spectroscopy,self-regulated intention,ensemble learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"BRAIN-COMPUTER-INTERFACE,PREFRONTAL,CORTEX,CORTICAL,CONTROL,GAIT,CLASSIFICATION,SYSTEM,SELECTION,FMRI",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
34,Learning Manifolds from Dynamic Process Data,13,2,,"Schoeneman Frank,Chandola Varun,Napp Nils,Wodo Olga,Zola Jaroslaw","Schoeneman F,Chandola V,Napp N,Wodo O,Zola J",Zola J,10.3390/a13020030,State University of New York (SUNY) System,"Scientific data, generated by computational models or from experiments, are typically results of nonlinear interactions among several latent processes. Such datasets are typically high-dimensional and exhibit strong temporal correlations. Better understanding of the underlying processes requires mapping such data to a low-dimensional manifold where the dynamics of the latent processes are evident. While nonlinear spectral dimensionality reduction methods, e.g., Isomap, and their scalable variants, are conceptually fit candidates for obtaining such a mapping, the presence of the strong temporal correlation in the data can significantly impact these methods. In this paper, we first show why such methods fail when dealing with dynamic process data. A novel method, Entropy-Isomap, is proposed to handle this shortcoming. We demonstrate the effectiveness of the proposed method in the context of understanding the fabrication process of organic materials. The resulting low-dimensional representation correctly characterizes the process control variables and allows for informative visualization of the material morphology evolution.","manifold learning,time series,dynamic processes",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"REDUCTION,TRANSISTORS,CELLS",ALGORITHMS,https://www.mdpi.com/1999-4893/13/2/30/pdf,
35,A Low-Cost Cognitive Assistant,9,2,,"Costa Angelo,Rincon Jaime A.,Julian Vicente,Novais Paulo,Carrascosa Carlos","Costa A,Rincon JA,Julian V,Novais P,Carrascosa C",Costa A,10.3390/electronics9020310,Universidade do Minho,"In this paper, we present in depth the hardware components of a low-cost cognitive assistant. The aim is to detect the performance and the emotional state that elderly people present when performing exercises. Physical and cognitive exercises are a proven way of keeping elderly people active, healthy, and happy. Our goal is to bring to people that are at their homes (or in unsupervised places) an assistant that motivates them to perform exercises and, concurrently, monitor them, observing their physical and emotional responses. We focus on the hardware parts and the deep learning models so that they can be reproduced by others. The platform is being tested at an elderly people care facility, and validation is in process.","cognitive assistants,aging,emotion recognition",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,,"HUMAN,ACTIVITY,RECOGNITION,ACCURATE",ELECTRONICS,http://repositorium.sdum.uminho.pt/bitstream/1822/64176/1/electronics-09-00310-v2.pdf,
36,Recognition of Gait Phases with a Single Knee Electrogoniometer: A Deep Learning Approach,9,2,,"Di Nardo Francesco,Morbidoni Christian,Cucchiarelli Alessandro,Fioretti Sandro","Di Nardo F,Morbidoni C,Cucchiarelli A,Fioretti S",Di Nardo F; Morbidoni C,10.3390/electronics9020355,Marche Polytechnic University,"Artificial neural networks were satisfactorily implemented for assessing gait events from different walking data. This study aims to propose a novel approach for recognizing gait phases and events, based on deep-learning analysis of only sagittal knee-joint angle measured by a single electrogoniometer per leg. Promising classification/prediction performances have been previously achieved by surface-EMG studies; thus, a further aim is to test if adding electrogoniometer data could improve classification performances of state-of-the-art methods. Gait data are measured in about 10,000 strides from 23 healthy adults, during ground walking. A multi-layer perceptron model is implemented, composed of three hidden layers and a one-dimensional output. Classification/prediction accuracy is tested vs. ground truth represented by foot-floor-contact signals, through samples acquired from subjects not seen during training phase. Average classification-accuracy of 90.6 +/- 2.9% and mean absolute value (MAE) of 29.4 +/- 13.7 and 99.5 +/- 28.9 ms in assessing heel-strike and toe-off timing are achieved in unseen subjects. Improvement of classification-accuracy (four points) and reduction of MAE (at least 35%) are achieved when knee-angle data are used to enhance sEMG-data prediction. Comparison of the two approaches shows as the reduction of set-up complexity implies a worsening of mainly toe-off prediction. Thus, the present electrogoniometer approach is particularly suitable for the classification tasks where only heel-strike event is involved, such as stride recognition, stride-time computation, and identification of toe walking.","knee angle,deep learning,neural networks,gait-phase classification,electrogoniometer,EMG sensors,walking,gait-event detection",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"SYSTEM,CLASSIFICATION,WALKING,EVENTS",ELECTRONICS,https://www.mdpi.com/2079-9292/9/2/355/pdf,
37,Early Detection of Diabetic Retinopathy Using PCA-Firefly Based Deep Learning Model,9,2,,"Gadekallu Thippa Reddy,Khare Neelu,Bhattacharya Sweta,Singh Saurabh,Maddikunta Praveen Kumar Reddy,Ra In-Ho,Alazab Mamoun","Gadekallu TR,Khare N,Bhattacharya S,Singh S,Maddikunta PKR,Ra IH,Alazab M",Ra IH,10.3390/electronics9020274,Kunsan National University,"Diabetic Retinopathy is a major cause of vision loss and blindness affecting millions of people across the globe. Although there are established screening methods - fluorescein angiography and optical coherence tomography for detection of the disease but in majority of the cases, the patients remain ignorant and fail to undertake such tests at an appropriate time. The early detection of the disease plays an extremely important role in preventing vision loss which is the consequence of diabetes mellitus remaining untreated among patients for a prolonged time period. Various machine learning and deep learning approaches have been implemented on diabetic retinopathy dataset for classification and prediction of the disease but majority of them have neglected the aspect of data pre-processing and dimensionality reduction, leading to biased results. The dataset used in the present study is a diabetes retinopathy dataset collected from the UCI machine learning repository. At its inceptions, the raw dataset is normalized using the Standardscalar technique and then Principal Component Analysis (PCA) is used to extract the most significant features in the dataset. Further, Firefly algorithm is implemented for dimensionality reduction. This reduced dataset is fed into a Deep Neural Network Model for classification. The results generated from the model is evaluated against the prevalent machine learning models and the results justify the superiority of the proposed model in terms of Accuracy, Precision, Recall, Sensitivity and Specificity.","diabetic retinopathy,deep neural networks (DNN),dimensionality reduction,principal component analysis (PCA),Firefly",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"CLASSIFICATION,ALGORITHM,SYSTEM,OPTIMIZATION,FEATURES",ELECTRONICS,https://www.mdpi.com/2079-9292/9/2/274/pdf,
38,Material Identification Using a Microwave Sensor Array and Machine Learning,9,2,,"Harrsion Luke,Ravan Maryam,Tandel Dhara,Zhang Kunyi,Patel Tanvi,Amineh Reza K.","Harrsion L,Ravan M,Tandel D,Zhang KY,Patel T,Amineh RK",Amineh RK,10.3390/electronics9020288,"New York Inst Technol, Dept Elect & Comp Engn, New York, NY 10023 USA.","In this paper, a novel methodology is proposed for material identification. It is based on the use of a microwave sensor array with the elements of the array resonating at various frequencies within a wide range and applying machine learning algorithms on the collected data. Unlike the previous microwave sensing systems which are mainly based on a single resonating sensor, the proposed methodology allows for material characterization over a wide frequency range which, in turn, improves the accuracy of the material identification procedure. The performance of the proposed methodology is tested via the use of easily available materials such as woods, cardboards, and plastics. However, the proposed methodology can be extended to other applications such as industrial liquid identification and composite material identification, among others.","machine learning,microwave sensor array",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,,ELECTRONICS,https://www.mdpi.com/2079-9292/9/2/288/pdf,
39,Hybrid model for prediction of heart disease,24,3,1903-1925,Sarkar Bikash Kanti,Sarkar BK,Sarkar BK,10.1007/s00500-019-04022-2,Birla Institute of Technology Mesra,"Heart disease is a leading cause of death in the world. In order to drop its rate, effective and timely diagnosis of the disease is very essential. Numerous automated decision support systems have been developed for this purpose. In the present research, a predictive model consisting of two-level optimization is introduced, to save lives and cost via effective diagnosis of the disease. Level-1 optimization of the model first identifies parallelly an optimal proportion (P-opt) for training and test sets for each dataset on parallel machine. Next, the best training set (T-best) for P-opt is again searched parallelly. On the other hand, level-2 optimization refines the rule set (R) generated by the Perfect Rule Induction by Sequential Method (PRISM) learner on T-best employing parallel genetic algorithm. The experimental results obtained by the model over the heart disease datasets (collected from https://archive.ics.uci.edu/ml) are compared and analysed with its base learner and four state-of-the-art learners, namely C4.5 (decision tree-based classifier), Naive Bayes, neural network and support vector machine. The empirical outcomes (based on the top performance metrics-prediction accuracy, precision, recall, area under curve values, true positive and false positive rates) positively demonstrate that the new model is proficient in undertaking heart disease treatment. Importantly, the prediction accuracy of the presented hybrid model exceeds around 6% than that of the sequential GA-based hybrid model over almost all the chosen datasets. After all, the proposed system may work as an e-doctor to predict heart attack and assist clinicians to take precautionary steps.","Heart disease,Hybrid model,Parallel GA,Effective diagnosis,e-doctor",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,,"DIAGNOSIS,CLASSIFICATION,ALGORITHM,NETWORKS",SOFT COMPUTING,,
40,Automatic classification of common building materials from 3D terrestrial laser scan data,110,,,"Yuan Liang,Guo Jingjing,Wang Qian","Yuan L,Guo JJ,Wang Q",Wang Q,10.1016/j.autcon.2019.103017,National University of Singapore,"Automatic building material classification has been a popular research interest over the past decades because it is useful for construction management and facility management. Currently, the proposed methods for automatic material classification are mainly based on 2D images by using the visual features of building materials. A terrestrial laser scanner (TLS) with a built-in camera can generate a set of coloured laser scan data that contain the surface geometries of building materials. The laser scan data include not only the visual features of building materials but also other attributes such as material reflectance and surface roughness. With more attributes provided, laser scan data have the potential to improve the accuracy of building material classification. Therefore, this research aims to develop a TLS data-based classification method for common building materials using machine learning techniques. The developed technique uses material reflectance, HSV colour values, and surface roughness as the features for material classification. A database containing the laser scan data of ten common building materials was created and used for model training and validation with machine learning techniques. Different machine learning algorithms were compared, and the best algorithm showed an average classification accuracy of 96.7%, which demonstrated the feasibility of the developed method.","Terrestrial laser scanning,Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Construction & Building Technology,Engineering",,8.0,"INTENSITY,DATA,CONSTRUCTION,PROGRESS,MASONRY,WALLS,CALIBRATION,SUPPORT,MODELS,BIM",AUTOMATION IN CONSTRUCTION,,
41,Incorporating prior knowledge via volumetric deep residual network to optimize the reconstruction of sparsely sampled MRI,66,,93-103,"Wu Yan,Ma Yajun,Capaldi Dante Pietro,Liu Jing,Zhao Wei,Du Jiang,Xing Lei","Wu Y,Ma YJ,Capaldi DP,Liu J,Zhao W,Du J,Xing L",Xing L,10.1016/j.mri.2019.03.012,"875 Blake Wilbur Dr Room G204, Stanford, CA 94305 USA.","For sparse sampling that accelerates magnetic resonance (MR) image acquisition, non-linear reconstruction algorithms have been developed, which incorporated patient specific a prior information. More generic a prior information could be acquired via deep learning and utilized for image reconstruction. In this study, we developed a volumetric hierarchical deep residual convolutional neural network, referred to as T-Net, to provide a data-driven end-to-end mapping from sparsely sampled MR images to fully sampled MR images, where cartilage MR images were acquired using an Ultra-short TE sequence and retrospectively undersampled using pseudo-random Cartesian and radial acquisition schemes. The network had a hierarchical architecture that promoted the sparsity of feature maps and increased the receptive field, which were valuable for signal synthesis and artifact suppression. Relatively dense local connections and global shortcuts were established to facilitate residual learning and compensate for details lost in hierarchical processing. Additionally, volumetric processing was adopted to fully exploit spatial continuity in three-dimensional space. Data consistency was further enforced. The network was trained with 336 three-dimensional images (each consisting of 32 slices) and tested by 24 images. The incorporation of a priori information acquired via deep learning facilitated high acceleration factors (as high as 8) while maintaining high image fidelity (quantitatively evaluated using the structural similarity index measurement). The proposed T-Net had an improved performance as compared to several state-of-the-art networks.","IMAGE-RECONSTRUCTION,ACCELERATED MRI,COMBINATION",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.608,"IMAGE-RECONSTRUCTION,ACCELERATED,MRI,COMBINATION",MAGNETIC RESONANCE IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6745016,
42,Dynamic pixel-wise weighting-based fully convolutional neural networks for left ventricle segmentation in short-axis MRI,66,,131-140,"Wang Zhongrong,Xie Lipeng,Qi Jin","Wang ZR,Xie LP,Qi J",Xie LP,10.1016/j.mri.2019.08.021,University of Electronic Science & Technology of China,"Left ventricle (LV) segmentation in cardiac MRI is an essential procedure for quantitative diagnosis of various cardiovascular diseases. In this paper, we present a novel fully automatic left ventricle segmentation approach based on convolutional neural networks. The proposed network fully takes advantages of the hierarchical architecture and integrate the multi-scale feature together for segmenting the myocardial region of LV. Moreover, we put forward a dynamic pixel-wise weighting strategy, which can dynamically adjust the weight of each pixel according to the segmentation accuracy of upper layer and force the pixel classifier to take more attention on the misclassified ones. By this way, the LV segmentation performance of our method can be improved a lot especially for the apical and basal slices in cine MR images. The experiments on the CAP database demonstrate that our method achieves a substantial improvement compared with other well-know deep learning methods. Beside these, we discussed two major limitations in convolutional neural networks-based semantic segmentation methods for LV segmentation.","Cardiac MRI,Left ventricle segmentation,Convolutional neural networks,Semantic segmentation,Dynamic pixel-wise weighting strategy",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.608,,MAGNETIC RESONANCE IMAGING,,
43,Artificial neural networks and adaptive neuro-fuzzy models for predicting WEDM machining responses of Nitinol alloy: comparative study,2,2,,"Naresh C.,Bose P. S. C.,Rao C. S. P.","Naresh C,Bose PSC,Rao CSP",Naresh C,10.1007/s42452-020-2083-y,National Institute of Technology (NIT System),"This article reports a comparative study of artificial neural network (ANN) and adaptive neuro-fuzzy inference system (ANFIS) models for better prediction of wire electro-discharge machining (WEDM) responses like material removal rate and surface roughness of a Nitinol alloy. Pulse on time (T-on), pulse off time (T-off), peak current (I-peak) and gap voltage (V) were selected as input attributes. Experimental results were performed to verify the results from ANN and ANFIS models. ANN model, back-propagation with three different algorithms Levenberg-Marquardt (LM), Elman regression neural network and generalized regression neural network and ANFIS model, were developed using the same input variables. The most suitable algorithm and neuron number in the hidden layer were found as LM with 10 neurons for ANN models whereas the most suitable membership functions and number of membership functions are found to be gauss and two, respectively. The statistical validation measures such as root mean square error, mean square error and mean absolute percentage error are obtained through ANN and ANFIS models. The statistical values are given in the tables. As per the statistical measures perspective, the ANFIS model will have better accuracy for anticipation of WEDM attributes of a Nitinol alloy.","ANN,ANFIS,Nitinol,MRR,Surface roughness,WEDM",Article,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Science & Technology - Other Topics,,,"SURFACE-ROUGHNESS,PREDICTION,MATERIAL,REMOVAL,RATE,ANFIS,MODELS,INFERENCE,SYSTEM,TOOL,WEAR,PERFORMANCE,OPTIMIZATION,ANN,MACHINABILITY,PARAMETERS",SN APPLIED SCIENCES,https://link.springer.com/content/pdf/10.1007/s42452-020-2083-y.pdf,
44,Electrocorticography based motor imagery movements classification using long short-term memory (LSTM) based on deep learning approach,2,2,,"Rashid Mamunur,Islam Minarul,Sulaiman Norizam,Bari Bifta Sama,Saha Ripon Kumar,Hasan Md Jahid","Rashid M,Islam M,Sulaiman N,Bari BS,Saha RK,Hasan MJ",Rashid M,10.1007/s42452-020-2023-x,Universiti Malaysia Pahang,"Brain-computer interface (BCI) is an important alternative for disabled people that enables the innovative communication pathway among individual thoughts and different assistive appliances. In order to make an efficient BCI system, different physiological signals from the brain have been utilized for instances, steady-state visual evoked potential, motor imagery, P300, movement-related potential and error-related potential. Among these physiological signals, motor imagery is widely used in almost all BCI applications. In this paper, Electrocorticography (ECoG) based motor imagery signal has been classified using long short-term memory (LSTM). ECoG based motor imagery data has been taken from BCI competition III, dataset I. The proposed LSTM approach has achieved the classification accuracy of 99.64%, which is the utmost accuracy in comparison with other state-of-art methods that have employed the same data set.","Electrocorticography (ECoG),Motor imagery (MI),Long short-term memory (LSTM),Brain computer interfaces (BCI),Deep learning",Article,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Science & Technology - Other Topics,,,,SN APPLIED SCIENCES,https://link.springer.com/content/pdf/10.1007/s42452-020-2023-x.pdf,
45,An innovative approach to integrate unequal protection-based steganography and progressive transmission of physiological data,2,2,,"Sahu Neerja,Peng Dongming,Sharif Hamid","Sahu N,Peng DM,Sharif H",Sahu N,10.1007/s42452-020-1992-0,University of Nebraska System,"Evolving digital technologies in remote health monitoring require an energy-efficient method for secure and reliable transmission of patient's/user's confidential information from the sensor nodes to the cloud/medical server. Thus, a united scheme of the physiological signal steganography and its communication by benefitting from the unequal significance between different parts of the physiological data are emphasized. We believe higher steganography coding strength and more robust source-channel coding would protect extremely vital parts of the physiological data. Therefore, data integrity and transmission efficiency of packet information achieved in a resilient way. We formulate our idea of joint steganography-source-channel coding (JS(2)C(2)) as an optimization problem to simultaneously securing and minimizing the transmission energy consumption. A low-complexity deep learning-based ECG classification algorithm along with its secure and energy-efficient neural JS(2)C(2) transmission for real-time monitoring has been realized. The optimal parameters for our united framework have been calculated by JS(2)C(2) optimization method. Our steganography algorithm unequal steganography embedding (USE) achieves very low wavelet-based weighted percent root-mean-squared difference lower than 0.5%. Furthermore, the high correlation between cover and stego and low end-to-end mean-square error (MSE) indicates resilient imperceptibility and maintains the diagnosability of the physiological signal. Moreover, low MSE between embedded and extracted data validates that embedded confidential data has been extracted with negligible distortion. In addition, for the given distortion, the USE-based framework's energy consumption is much smaller (by 55% in typical application scenario) as compared with the equal steganography embedding-based approach's energy consumption.","Electrocardiography (ECG),Unequal error protection (UEP),Unequal steganography embedding (USE),Joint steganography source coding (JS(2)),Joint source-channel coding (JSC(2)),Joint steganography-source-channel coding (JS(2)C(2)),Deep learning (DL),Security,Correlation,End-to-end distortion,Energy efficiency",Article,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Science & Technology - Other Topics,,,"CONVOLUTIONAL,NEURAL-NETWORK,ERROR,PROTECTION,IMAGE,TRANSMISSION,ECG,STEGANOGRAPHY,MYOCARDIAL-INFARCTION,AUTOMATED,DETECTION,FAST,ALGORITHM,INTERNET,IOT,IDENTIFICATION",SN APPLIED SCIENCES,https://link.springer.com/content/pdf/10.1007/s42452-020-1992-0.pdf,
46,A material handling scheduling method for mixed-model automotive assembly lines based on an improved static kitting strategy,140,,,"Zhou Binghai,He Zhaoxu","Zhou BH,He ZX",Zhou BH,10.1016/j.cie.2020.106268,"Caoan Rd 4800,Mech Bldg A444, Shanghai 201804, Peoples R China.","Since the diversification of customer demands poses a great challenge for manufacturing enterprises and the scheduling problem of material handling affects the efficiency of assembly lines, this paper proposes a novel scheduling method, an improved static kitting strategy, to solve the scheduling problems of the material handling for automotive mixed-model assembly lines (MMALs) based on line-integrated supermarkets. Firstly, an integer programming mathematical model is established with the objective of minimizing the number of logistic workers. Then, an improved static kitting strategy is presented to solve the problem and a model based on graph theories is constructed to transform the scheduling problem to a mathematical one. Afterwards, a Kuhn-Munkres algorithm and an elite opposition-based learning adaptive dynamic differential evolution algorithm, named EOADDE algorithm, is developed to solve the scheduling problem. The elite opposition-based learning (EOL) and self-adaptive operators are applied to the proposed EOADDE algorithm to enhance the local search ability and the convergence speed. Finally, computational experiments of the proposed algorithm are carried out compared with benchmark algorithms, and the feasibility and effectiveness of proposed methods are verified by results.","Mixed-model assembly lines,Improved static kitting strategy,Line-integrated supermarkets,Scheduling",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering",,5.518,"DIFFERENTIAL,EVOLUTION,OPTIMIZATION,ALLOCATION,STOCKING,DESIGN",COMPUTERS & INDUSTRIAL ENGINEERING,,
47,SEHC: A high-throughput materials computing framework with automatic self-evaluation filtering,252,,,"Zhu Wenhao,Xu Yonglin,Ni Jianyue,Hu Guannan,Wang Xiangmeng,Zhang Wu","Zhu WH,Xu YL,Ni JY,Hu GN,Wang XM,Zhang W",Xu YL,10.1016/j.mseb.2019.114474,Shanghai University,"Efficiency is one of the key problems in the design of high-throughput materials computing. In this paper, we provide a Self-Evaluation High-throughput Computing framework (SEHC). The framework introduces an automatic self-evaluation filtering mechanism, which is based on machine learning, for high-throughput computing architectures to stop unexpected materials calculation tasks in advance during high-throughput calculation. The time-consuming high-throughput computing process is disassembled into several finer-grained high-throughput Stages. Multiple high -throughput Stages with the same standard design specifications can be assembled into a Pipeline model. Combined with the public service like data storage and system monitoring, the SEHC with a ""Stage-Pipeline-Framework"" three-tier structure is formed. To search for diamond-like structures with higher group velocity in a space of 254 compounds, a SEHC-based prototype was implemented. The experiment result shows that this prototype achieved a significant improvement in efficiency by reducing the amount of invalid computation remarkably.","Diamond-like structures,High-throughput,Machine learning,High-throughput Stage,SEHC",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Materials Science,Physics",,4.316,"TOTAL-ENERGY,CALCULATIONS,MOLECULAR-DYNAMICS,CRYSTAL-STRUCTURES,INITIO,DISCOVERY,TRANSPORT,DATABASE,MODEL",MATERIALS SCIENCE AND ENGINEERING B-ADVANCED FUNCTIONAL SOLID-STATE MATERIALS,,
48,An optimized technique for brain tumor classification and detection with radiation dosage calculation in MR image,72,,,"Kalpana R.,Chandrasekar P.","Kalpana R,Chandrasekar P",Kalpana R,10.1016/j.micpro.2019.102903,Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology,"The tumor cell leads brain to abnormal growth birth. The Brain Tumors (BT) leads to damage or affected brain if it is not predicted early stage and rectified properly with proper treatment. The proper treatment as advised by the physician need to be followed based on the size of the tumor and its position. The accurate finding of tumor position and size is the difficult task. In recent years to structures of the body in internal position had seen detailed, the Magnetic Resonance (MR) technique if the radiology used in medical imaging. This paper describes a novel approach for BT MLTS-HSO segmentation and extracts the features then classified with different classifiers (KNN, DSVM, NB, and RBFN) for MR BT images. The present approach is SVM, NN, and ANFIS where the seed point is selected on a scale based and detected the tumor region and also compute the performance metrics and radiation dosage. Thus the proposed system is the ability of the calculate size and position of the tumor. It has more accurate prediction of the required surgery and other therapy procedures. (C) 2019 Elsevier B.V. All rights reserved.","MLTS-HSO,Features extraction,Classifiers,Radiation dosage",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering",,,SEGMENTATION,MICROPROCESSORS AND MICROSYSTEMS,,
49,Architecture and implementation of a smart-pregnancy monitoring system using web-based application,37,1,,"Santur Yunus,Santur Sinem Guven,Karakose Mehmet","Santur Y,Santur SG,Karakose M",Santur Y,10.1111/exsy.12379,Firat University,"Today, people use web-based technologies to meet their information needs, socialise, communicate, and deal with formal and informal processes. At the same time, mobile versions of these applications provide people with great convenience in daily life. These applications include blood-pressure monitors, blood-glucose monitors, body-analysis scales, pulse oximeters, and activity and sleep trackers. Many of these products sync directly with a free mobile app that makes monitoring, viewing, storing, and sharing of health vitals simple and comprehensive. The data collected from the user is stored in a cloud-based application, then trained by intelligent algorithms that use machine learning for health aims so that the user can instantly see his or her status and development. In this study, the aim was to construct a cloud-based application specific to women for monitoring pregnancy. In the web-based application working with membership logic, members can access machine learning assisted calculators of the baby percentile, period tracker, pregnancy calendar, and baby vaccination schedule. Moreover, they can access augmented/virtual-reality-assisted visual training.","big data,e-health,pregnancy monitoring",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Computer Science,,2.457,,EXPERT SYSTEMS,,
50,"Machine learning-based optimal design of a phase change material integrated renewable system with on-site PV, radiative cooling and hybrid ventilations-study of modelling and application in five climatic regions",192,,,"Zhou Yuekuan,Zheng Siqian,Zhang Guoqiang","Zhou YK,Zheng SQ,Zhang GQ",Zheng SQ,10.1016/j.energy.2019.116608,City University of Hong Kong,"The widespread application of advanced renewable systems with optimal design can promote the cleaner production, reduce the carbon dioxide emission and realise the renewable and sustainable development. In this study, a phase change material integrated hybrid system was demonstrated, involving with advanced energy conversions and multi-diversified energy forms, including solar-to-electricity conversion, active water-based and air-based cooling, and distributed storages. A generic optimization methodology was developed by integrating supervised machine learning and heuristic optimization algorithms. Multivariable optimizations were systematically conducted for widespread application purpose in five climatic regions in China. Results showed that, the energy performance is highly dependent on mass flow rate and inlet cooling water temperature with contribution ratios at around 90% and 7%. Furthermore, compared to Taguchi standard orthogonal array, the machine-learning based optimization can improve the annual equivalent overall output energy from 86934.36 to 90597.32 kWh (by 4.2%) in ShangHai, from 86335.35 to 92719.07 (by 7.4%) in KunMing, from 87445.1 to 912183 (by 4.3%) in GuangZhou, from 87278.24 to 88212.83 (by 1.1%) in HongKong, and from 87611.95 to 92376.46 (by 5.4%) in HaiKou. This study presents optimal design and operation of a renewable system in different climatic regions, which are important to realise renewable and sustainable buildings. (C) 2019 Published by Elsevier Ltd.","Phase change materials (PCMs),Latent heat storage,Optimal design,Robust operation,Machine learning,Climate-adaptive operation",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Thermodynamics,Energy & Fuels",,6.845,"PERFORMANCE,ENHANCEMENT,THERMAL,PERFORMANCE,ENERGY,PERFORMANCE,PCM,OPTIMIZATION,BUILDINGS,WALL",ENERGY,,
51,Remaining-useful-life prediction via multiple linear regression and recurrent neural network reflecting degradation information of 20Ah LiNixMnyCo1-x-yO2 pouch cell,858,,,"Kwon Soon-Jong,Han Dongho,Choi Jin Hyeok,Lim Ji-Hun,Lee Sung-Eun,Kim Jonghoon","Kwon SJ,Han D,Choi JH,Lim JH,Lee SE,Kim J",Kim J,10.1016/j.jelechem.2019.113729,Chungnam National University,"This paper presents the results of various experiments and analyses pertaining to lithium-nickel-cobalt-manganese oxide (NCM) batteries having a nominal capacity of 20 Ah. This pouch type battery is characterized by high power rating and high energy density. The batteries used in the experiments were manufactured by varying the design ratios of nickel, cobalt, and manganese (5:2:3 and 6:2:2) in the NCM cathode materials. An accelerated deterioration test was carried out by applying a current of 80 A at 4C-rate (C-rate is the charge-discharge rate of a battery relative to its nominal capacity). The characteristics of the differential capacity were analyzed under varying deterioration conditions. The impedance characteristics for a given state of charge (SOC) and deterioration level were analyzed through electrochemical impedance spectroscopy (EIS) tests. In addition, the battery-equivalent circuit model was designed to estimate the model parameters of the alternating current (AC) impedance. The model parameters of the direct current (DC) impedance were estimated and compared through the direct current internal resistance (DCIR) test. Machine learning was performed by using the data extracted from the accelerated deterioration test as learning data, and by applying it to the multiple linear regression and the recurrent neural network methods. Finally, a study was carried out to estimate and analyze the remaining useful life (RUL) of the NCM lithium-ion batteries with machine learning. (C) 2019 Elsevier B.V. All rights reserved.","LiNixCoyMn1-x-yO2 pouch cell,Accelerated deterioration experiment,Equivalent circuit model,Multiple linear regression,Recurrent neural network (RNN),Remaining useful life prediction",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Chemistry,Electrochemistry",,4.058,"LITHIUM-ION,BATTERY,STATE-OF-HEALTH,INTERNAL,RESISTANCE,AGING,MECHANISMS,ELECTRODE,MODELS,CHARGE",JOURNAL OF ELECTROANALYTICAL CHEMISTRY,,
52,Decision-level fusion scheme for nasopharyngeal carcinoma identification using machine learning techniques,32,3,625-638,"Abd Ghani Mohd Khanapi,Mohammed Mazin Abed,Arunkumar N.,Mostafa Salama A.,Ibrahim Dheyaa Ahmed,Abdullah Mohamad Khir,Jaber Mustafa Musa,Abdulhay Enas,Ramirez-Gonzalez Gustavo,Burhanuddin M. A.","Abd Ghani MK,Mohammed MA,Arunkumar N,Mostafa SA,Ibrahim DA,Abdullah MK,Jaber MM,Abdulhay E,Ramirez-Gonzalez G,Burhanuddin MA",Mohammed MA,10.1007/s00521-018-3882-6,University Teknikal Malaysia Melaka,"Making an accurate diagnosis of nasopharyngeal carcinoma (NPC) disease is a challenging task that involves many parties such as radiology specialists often times need to delineate NPC boundaries on various tumor-bearing endoscopic images. It is a tedious and time-consuming operation exceedingly based on doctors and experience of radiologist. NPC has complex and irregular structures which makes it difficult to diagnose even by an expert physician. However, the diagnosis accuracy results of such methods are still insignificant and need improvement in order to manifest robust solution. The study aim is to develop and propose a new automatic classification of NPC tumor using machine learning techniques and feature-based decision-level fusion scheme from endoscopic images. We have implemented the fusion of the three image texture-based schemes (local binary patterns, the first-order statistics histogram properties, and histogram of gray scale) at the decision level and tested the performance of this scheme using the same experimental setup in the previous section for simple score-level fusion, but for comparison, We used the classifiers methods which are support vector machines (SVM), k-nearest neighbors' algorithm, and artificial neural network (ANN). The results demonstrate that the majority rule for decision-based fusion is outperformed considerably by the single best performing feature scheme (FFGF) for the SVM classifier, but for the ANN and KNN classifier it is significantly outperformed by each of the components features. The classifiers approaches were listed a high accuracy of 94.07%, the sensitivity of 92.05%, and specificity of 93.07%.","Nasopharyngeal carcinoma,Feature-based decision-level fusion,Endoscopic images,Local binary patterns,Support vector machines,k-nearest neighbors' algorithm,Artificial neural network",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"NEURAL-NETWORK,CLASSIFICATION,SEGMENTATION,PREDICTION,FEATURES",NEURAL COMPUTING & APPLICATIONS,,
53,An enhanced diabetic retinopathy detection and classification approach using deep convolutional neural network,32,3,707-721,"Hemanth D. Jude,Deperlioglu Omer,Kose Utku","Hemanth DJ,Deperlioglu O,Kose U",Kose U,10.1007/s00521-018-03974-0,Suleyman Demirel University,"The objective of this study is to propose an alternative, hybrid solution method for diagnosing diabetic retinopathy from retinal fundus images. In detail, the hybrid method is based on using both image processing and deep learning for improved results. In medical image processing, reliable diabetic retinopathy detection from digital fundus images is known as an open problem and needs alternative solutions to be developed. In this context, manual interpretation of retinal fundus images requires the magnitude of work, expertise, and over-processing time. So, doctors need support from imaging and computer vision systems and the next step is widely associated with use of intelligent diagnosis systems. The solution method proposed in this study includes employment of image processing with histogram equalization, and the contrast limited adaptive histogram equalization techniques. Next, the diagnosis is performed by the classification of a convolutional neural network. The method was validated using 400 retinal fundus images within the MESSIDOR database, and average values for different performance evaluation parameters were obtained as accuracy 97%, sensitivity (recall) 94%, specificity 98%, precision 94%, FScore 94%, and GMean 95%. In addition to those results, a general comparison of with some previously carried out studies has also shown that the introduced method is efficient and successful enough at diagnosing diabetic retinopathy from retinal fundus images. By employing the related image processing techniques and deep learning for diagnosing diabetic retinopathy, the proposed method and the research results are valuable contributions to the associated literature.","Diabetic retinopathy,Image processing,Deep learning,Convolutional neural network",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"ARTIFICIAL-INTELLIGENCE,OPTIMIZATION,SYSTEM,DIAGNOSIS,FEATURES,HEALTH",NEURAL COMPUTING & APPLICATIONS,,
54,Learning visual representations with optimum-path forest and its applications to Barrett's esophagus and adenocarcinoma diagnosis,32,3,759-775,"de Souza Luis A. Jr.,Afonso Luis C. S.,Ebigbo Alanna,Probst Andreas,Messmann Helmut,Mendel Robert,Hook Christian,Palm Christoph,Papa Joao P.","de Souza LA,Afonso LCS,Ebigbo A,Probst A,Messmann H,Mendel R,Hook C,Palm C,Papa JP",Papa JP,10.1007/s00521-018-03982-0,Universidade Estadual Paulista,"Considering the increase in the number of the Barrett's esophagus (BE) in the last decade, and its expected continuous increase, methods that can provide an early diagnosis of dysplasia in BE-diagnosed patients may provide a high probability of cancer remission. The limitations related to traditional methods of BE detection and management encourage the creation of computer-aided tools to assist in this problem. In this work, we introduce the unsupervised Optimum-Path Forest (OPF) classifier for learning visual dictionaries in the context of Barrett's esophagus (BE) and automatic adenocarcinoma diagnosis. The proposed approach was validated in two datasets (MICCAI 2015 and Augsburg) using three different feature extractors (SIFT, SURF, and the not yet applied to the BE context A-KAZE), as well as five supervised classifiers, including two variants of the OPF, Support Vector Machines with Radial Basis Function and Linear kernels, and a Bayesian classifier. Concerning MICCAI 2015 dataset, the best results were obtained using unsupervised OPF for dictionary generation using supervised OPF for classification purposes and using SURF feature extractor with accuracy nearly to 78% for distinguishing BE patients from adenocarcinoma ones. Regarding the Augsburg dataset, the most accurate results were also obtained using both OPF classifiers but with A-KAZE as the feature extractor with accuracy close to 73%. The combination of feature extraction and bag-of-visual-words techniques showed results that outperformed others obtained recently in the literature, as well as we highlight new advances in the related research area. Reinforcing the significance of this work, to the best of our knowledge, this is the first one that aimed at addressing computer-aided BE identification using bag-of-visual-words and OPF classifiers, being the application of unsupervised technique in the BE feature calculation the major contribution of this work. It is also proposed a new BE and adenocarcinoma description using the A-KAZE features, not yet applied in the literature.","Barrett's esophagus,Optimum-path forest,Machine learning,Adenocarcinoma,Image processing",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"CAPSULE,ENDOSCOPY,CLASSIFICATION",NEURAL COMPUTING & APPLICATIONS,http://arxiv.org/pdf/2101.07209,
55,Analyzing genetic diseases using multimedia processing techniques associative decision tree-based learning and Hopfield dynamic neural networks from medical images,32,3,791-803,Al-Maitah Mohammed,Al-Maitah M,Al-Maitah M,10.1007/s00521-018-04004-9,King Saud University,"Genetic diseases are the most common next-generation diseases because of the improper mutation of the genes and DNA. These genetic diseases are failed to predict with an accurate manner in the beginning stage by using the particular genes and related information. So, the genetic diseases are identified in the medical systems by utilizing the hybridization of multimedia techniques such as big data and related soft computing techniques.Initially, the genetic disease-related medical images are collected from healthcare sectors, and from the genetic image, various genetic data are collected from the large amount of datasets in which the major challenge is too high dimensionality that increases the complexity of the genetic disease prediction system. So, in this paper the complexity of the system is reduced by using the associative decision tree-based learning and Hopfield dynamic neural networks (HDNN). After collecting the data from the various resources, the immune clonal selection algorithm approach is used to remove inconsistent data and minimize the dimensionality of data. The selected features are trained by the proposed associative decision tree approach which helps to compare with the testing features using the HDNN that successfully recognize the genetic disease-based features effectively. The excellence of the system is measured with the aid of the experimental outcomes that are corresponding to the forecasting methods such as greedy algorithm, rough set method and artificial bee colony, and the comparison is made with the avail of the accuracy, sensitivity and specificity.","Medical image,Multimedia tool,Genetic diseases,Artificial bee colony,Associative decision tree-based learning,Greedy forward selection,Scatter search,Hopfield dynamic neural networks",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"FEATURE,SUBSET-SELECTION,CLASSIFICATION,DIAGNOSIS",NEURAL COMPUTING & APPLICATIONS,,
56,Fuzzy rank correlation-based segmentation method and deep neural network for bone cancer identification,32,3,805-815,Altameem Torki,Altameem T,Altameem T,10.1007/s00521-018-04005-8,King Saud University,"Bone malignant tumors are one of the important health problems because tumors are formed due to the affectedness of the healthiest bone tissues. This serious bone cancer has been identified with the help of the different risk factors such as chills, swear symptoms, swelling, bones weaken risk, and night swears symptoms. These symptoms are not easy to predict in beginning stage with accurate manner. So, automatic bone cancer detection system has been developed to predict the cancer in earlier sate. Initially, the bone images are collected from patient, and noise in the images is eliminated using median filter. After eliminating the noise, affected tumor part is detected by applying the intuitionistic fuzzy rank correlation. From the detected intuitionistic fuzzy-based clustered images, different statistical features are extracted. The derived features are processed by applying the deep neural networks layers that successfully examines each features using Levenberg-Marquardt learning algorithm. The successful learning process predicts bone cancer-related features with accurate manner (99.1%). Finally, excellence of bone cancer prediction system is analyzed using MATLAB-based experimental setup and performance metrics such as F1 score, accuracy, error rate and so on.","Deep neural networks,Intuitionistic fuzzy rank correlation,Bone malignant,Swear symptoms,Swelling,Bones weaken risk,Median filter",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,,"DIAGNOSIS,CLASSIFICATION",NEURAL COMPUTING & APPLICATIONS,,
57,Refining Parkinson's neurological disorder identification through deep transfer learning,32,3,839-854,"Naseer Amina,Rani Monail,Naz Saeeda,Razzak Muhammad Imran,Imran Muhammad,Xu Guandong","Naseer A,Rani M,Naz S,Razzak MI,Imran M,Xu GD",Razzak MI,10.1007/s00521-019-04069-0,University of Technology Sydney,"Parkinson's disease (PD), a multi-system neurodegenerative disorder which affects the brain slowly, is characterized by symptoms such as muscle stiffness, tremor in the limbs and impaired balance, all of which tend to worsen with the passage of time. Available treatments target its symptoms, aiming to improve the quality of life. However, automatic diagnosis at early stages is still a challenging medicine-related task to date, since a patient may have an identical behavior to that of a healthy individual at the very early stage of the disease. Parkinson's disease detection through handwriting data is a significant classification problem for identification of PD at the infancy stage. In this paper, a PD identification is realized with help of handwriting images that help as one of the earliest indicators for PD. For this purpose, we proposed a deep convolutional neural network classifier with transfer learning and data augmentation techniques to improve the identification. Two approaches like freeze and fine-tuning of transfer learning are investigated using ImageNet and MNIST dataset as source task independently. A trained network achieved 98.28% accuracy using fine-tuning-based approach using ImageNet and PaHaW dataset. Experimental results on benchmark dataset reveal that the proposed approach provides better detection of Parkinson's disease as compared to state-of-the-art work.","Parkinson disease,Handwriting analysis,Neurodegenerative disorder",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"DISEASE,DIAGNOSIS,TREMOR,MICROGRAPHIA,MARKER,GAIT",NEURAL COMPUTING & APPLICATIONS,https://opus.lib.uts.edu.au/bitstream/10453/134902/1/Final_Parkinsons_NCA_Published.pdf,
58,Diagnosis of the Hypopnea syndrome in the early stage,32,3,855-866,"Yang Xiaodong,Fan Dou,Ren Aifeng,Zhao Nan,Shah Syed Aziz,Alomainy Akram,Ur-Rehman Masood,Abbasi Qammer H.","Yang XD,Fan D,Ren AF,Zhao N,Shah SA,Alomainy A,Ur-Rehman M,Abbasi QH",Yang XD,10.1007/s00521-019-04037-8,Xidian University,"Hypopnea syndrome is a chronic respiratory disease that is characterized by repetitive episodes of breathing disruptions during sleep. Hypopnea syndrome is a systemic disease that manifests respiratory problems; however, more than 80% of Hypopnea syndrome patients remain undiagnosed due to complicated polysomnography. Objective assessment of breathing patterns of an individual can provide useful insight into the respiratory function unearthing severity of Hypopnea syndrome. This paper explores a novel approach to detect incognito Hypopnea syndrome as well as provide a contactless alternative to traditional medical tests. The proposed method is based on S-Band sensing technique (including a spectrum analyzer, vector network analyzer, antennas, software-defined radio, RF generator, etc.), peak detection algorithm and Sine function fitting for the observation of breathing patterns and characterization of normal or disruptive breathing patterns for Hypopnea syndrome detection. The proposed system observes the human subject and changes in the channel frequency response caused by Hypopnea syndrome utilizing a wireless link between two monopole antennas, placed 3 m apart. Commercial respiratory sensors were used to verify the experimental results. By comparing the results, it is found that for both cases, the pause time is more than 10 s with 14 peaks. The experimental results show that this technique has the potential to open up new clinical opportunities for contactless and accurate Hypopnea syndrome monitoring in a patient-friendly and flexible environment.","Hypopnea syndrome,Respiration sensor,Early warning,Biomedical engineering,Machine learning",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"OBSTRUCTIVE,SLEEP-APNEA,VALIDATION",NEURAL COMPUTING & APPLICATIONS,https://e-space.mmu.ac.uk/624435/1/11.pdf,
59,Advanced Quality Control Models for Concrete Admixtures,32,2,,"Choi Hyungjoo,Venkiteela Giri,Gregori Amedeo,Najm Husam","Choi H,Venkiteela G,Gregori A,Najm H",Choi H,10.1061/(ASCE)MT.1943-5533.0003024,"Titan Engineers PC, Struct Engn Div, 1331 Stuyvesant Ave, Union, NJ 07083 USA.","Concrete admixtures are constantly used in construction projects, and these admixtures can be used to increase/decrease the setting time, improve workability, enhance frost and sulfate resistance, and to help control strength development. The quality of admixtures play a crucial role in altering fresh concrete properties. To streamline such quality control process for regular inspections, two key procedures are necessary: (1) collection and maintenance of the baseline approved admixtures quality, and (2) usage of sound analysis tools and procedures for quality verification of newly supplied materials. However, relying on manual comparison by the naked eye makes the identification process very tedious and inaccurate due to similar patterns of admixture infrared spectrophotometry (IR) signatures. Therefore, an efficient and standardized system is necessary for an accurate quality control process. In this study, advanced quality control models are investigated and proposed by utilizing the pattern-recognition methodology using artificial neural networks (ANNs) by utilizing data-driven and self-adaptive functions and other advanced machine-learning techniques for the pattern classification function. The feasibility of the proposed models were evaluated for the automatic quality control process. To identify a mixture's chemical and physical properties, energy absorption is measured at each wave number through the amount of transmitted infrared light. Developed pattern-recognition ANNs and other machine-learning models have shown their efficiency in learning and identifying the admixtures' IR signature spectra. Hence, the proposed advanced quality control models can be a very useful tool to determine the admixtures' quality accurately and quickly and eventually to guarantee their intended performance in altering the concrete's properties. (C) 2019 American Society of Civil Engineers.","NEURAL-NETWORKS,PRINCIPLES,PREDICTION,STRENGTH,COARSE",Article,"ASCE-AMER SOC CIVIL ENGINEERS, 1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA","Construction & Building Technology,Engineering,Materials Science",,3.501,"NEURAL-NETWORKS,PRINCIPLES,PREDICTION,STRENGTH,COARSE",JOURNAL OF MATERIALS IN CIVIL ENGINEERING,,
60,Consumer health information and question answering: helping consumers find answers to their health-related information needs,27,2,194-201,"Demner-Fushman Dina,Mrabet Yassine,Ben Abacha Asma","Demner-Fushman D,Mrabet Y,Ben Abacha A",Demner-Fushman D,10.1093/jamia/ocz152,National Institutes of Health (NIH) - USA,"Objective: Consumers increasingly turn to the internet in search of health-related information; and they want their questions answered with short and precise passages, rather than needing to analyze lists of relevant documents returned by search engines and reading each document to find an answer. We aim to answer consumer health questions with information from reliable sources.
Materials and Methods: We combine knowledge-based, traditional machine and deep learning approaches to understand consumers' questions and select the best answers from consumer-oriented sources. We evaluate the end-to-end system and its components on simple questions generated in a pilot development of MedlinePlus Alexa skill, as well as the short and long real-life questions submitted to the National Library of Medicine by consumers.
Results: Our system achieves 78.7% mean average precision and 87.9% mean reciprocal rank on simple Alexa questions, and 44.5% mean average precision and 51.6% mean reciprocal rank on real-life questions submitted by National Library of Medicine consumers.
Discussion: The ensemble of deep learning, domain knowledge, and traditional approaches recognizes question type and focus well in the simple questions, but it leaves room for improvement on the real-life consumers' questions. Information retrieval approaches alone are sufficient for finding answers to simple Alexa questions. Answering real-life questions, however, benefits from a combination of information retrieval and inference approaches.
Conclusion: A pilot practical implementation of research needed to help consumers find reliable answers to their health-related questions demonstrates that for most questions the reliable answers exist and can be found automatically with acceptable accuracy.","consumer health questions,question answering,natural language processing,deep learning,artificial intelligence",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7025352,
61,Mining Twitter to assess the determinants of health behavior toward human papillomavirus vaccination in the United States,27,2,225-235,"Zhang Hansi,Wheldon Christopher,Dunn Adam G.,Tao Cui,Huo Jinhai,Zhang Rui,Prosperi Mattia,Guo Yi,Bian Jiang","Zhang HS,Wheldon C,Dunn AG,Tao C,Huo JH,Zhang R,Prosperi M,Guo Y,Bian J",Bian J,10.1093/jamia/ocz191,State University System of Florida,"Objectives: The study sought to test the feasibility of using Twitter data to assess determinants of consumers' health behavior toward human papillomavirus (HPV) vaccination informed by the Integrated Behavior Model (IBM).
Materials and Methods: We used 3 Twitter datasets spanning from 2014 to 2018. We preprocessed and geocoded the tweets, and then built a rule-based model that classified each tweet into either promotional information or consumers' discussions. We applied topic modeling to discover major themes and subsequently explored the associations between the topics learned from consumers' discussions and the responses of HPV-related questions in the Health Information National Trends Survey (HINTS).
Results: We collected 2 846 495 tweets and analyzed 335 681 geocoded tweets. Through topic modeling, we identified 122 high-quality topics. The most discussed consumer topic is ""cervical cancer screening""; while in promotional tweets, the most popular topic is to increase awareness of ""HPV causes cancer."" A total of 87 of the 122 topics are correlated between promotional information and consumers' discussions. Guided by IBM, we examined the alignment between our Twitter findings and the results obtained from HINTS. Thirty-five topics can be mapped to HINTS questions by keywords, 112 topics can be mapped to IBM constructs, and 45 topics have statistically significant correlations with HINTS responses in terms of geographic distributions.
Conclusions: Mining Twitter to assess consumers' health behaviors can not only obtain results comparable to surveys, but also yield additional insights via a theory-driven approach. Limitations exist; nevertheless, these encouraging results impel us to develop innovative ways of leveraging social media in the changing health communication landscape.","Twitter,social media,human papillomavirus vaccine,topic modeling,integrated behavior model",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,,COVERAGE,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7025367,
62,Mining social media for prescription medication abuse monitoring: a review and proposal for a data-centric framework,27,2,315-329,"Sarker Abeed,DeRoos Annika,Perrone Jeanmarie","Sarker A,DeRoos A,Perrone J",Sarker A,10.1093/jamia/ocz162,Emory University,"Objective: Prescription medication (PM) misuse and abuse is a major health problem globally, and a number of recent studies have focused on exploring social media as a resource for monitoring nonmedical PM use. Our objectives are to present a methodological review of social media-based PM abuse or misuse monitoring studies, and to propose a potential generalizable, data-centric processing pipeline for the curation of data from this resource.
Materials and Methods: We identified studies involving social media, PMs, and misuse or abuse (inclusion criteria) from Medline, Embase, Scopus, Web of Science, and Google Scholar. We categorized studies based on multiple characteristics including but not limited to data size; social media source(s); medications studied; and primary objectives, methods, and findings.
Results: A total of 39 studies met our inclusion criteria, with 31 (similar to 79.5%) published since 2015. Twitter has been the most popular resource, with Reddit and Instagram gaining popularity recently. Early studies focused mostly on manual, qualitative analyses, with a growing trend toward the use of data-centric methods involving natural language processing and machine learning.
Discussion: There is a paucity of standardized, data-centric frameworks for curating social media data for task-specific analyses and near real-time surveillance of nonmedical PM use. Many existing studies do not quantify human agreements for manual annotation tasks or take into account the presence of noise in data.
Conclusion: The development of reproducible and standardized data-centric frameworks that build on the current state-of-the-art methods in data and text mining may enable effective utilization of social media data for understanding and monitoring nonmedical PM use.","social media,prescription drug misuse,substance abuse detection,natural language processing,text mining",Review,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"UNITED-STATES,DRUG-ABUSE,OPIOID,ABUSE,ONLINE,WEB,TWITTERSPHERE,EPIDEMIOLOGY,DEPENDENCE,INTERNET,OVERDOSE",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://europepmc.org/articles/pmc7025330?pdf=render,
63,Mechano-acoustic sensing of physiological processes and body motions via a soft wireless device placed at the suprasternal notch,4,2,148-158,"Lee KunHyuck,Ni Xiaoyue,Lee Jong Yoon,Arafa Hany,Pe David J.,Xu Shuai,Avila Raudel,Irie Masahiro,Lee Joo Hee,Easterlin Ryder L.","Lee K,Ni XY,Lee JY,Arafa H,Pe DJ,Xu S,Avila R,Irie M,Lee JH,Easterlin RL",Rogers JA,10.1038/s41551-019-0480-6,Northwestern University,"Skin-mounted soft electronics that incorporate high-bandwidth triaxial accelerometers can capture broad classes of physiologically relevant information, including mechano-acoustic signatures of underlying body processes (such as those measured by a stethoscope) and precision kinematics of core-body motions. Here, we describe a wireless device designed to be conformally placed on the suprasternal notch for the continuous measurement of mechano-acoustic signals, from subtle vibrations of the skin at accelerations of around 10(-3)ms(-2) to large motions of the entire body at about 10ms(-2), and at frequencies up to around 800Hz. Because the measurements are a complex superposition of signals that arise from locomotion, body orientation, swallowing, respiration, cardiac activity, vocal-fold vibrations and other sources, we exploited frequency-domain analysis and machine learning to obtain-from human subjects during natural daily activities and exercise-real-time recordings of heart rate, respiration rate, energy intensity and other essential vital signs, as well as talking time and cadence, swallow counts and patterns, and other unconventional biomarkers. We also used the device in sleep laboratories and validated the measurements using polysomnography. A wireless device designed to be conformally placed on the suprasternal notch can continuously provide real-time information of essential vital signs as well as talking time, swallow counts and sleep patterns.","RESPIRATORY RATE,TIME,SIGNALS,SENSOR,PHOTOPLETHYSMOGRAM,POSITION,PRONE",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Engineering,,26.355,"RESPIRATORY,RATE,TIME,SIGNALS,SENSOR,PHOTOPLETHYSMOGRAM,POSITION,PRONE",NATURE BIOMEDICAL ENGINEERING,https://europepmc.org/articles/pmc7035153?pdf=render,
64,A 1.9-mW SVM Processor With On-Chip Active Learning for Epileptic Seizure Control,55,2,452-464,"Huang Shuo-An,Chang Kai-Chieh,Liou Horng-Huei,Yang Chia-Hsiang","Huang SA,Chang KC,Liou HH,Yang CH",Yang CH,10.1109/JSSC.2019.2954775,National Taiwan University,"This article presents a support vector machine (SVM) processor that supports both seizure detection and on-chip model adaptation for epileptic seizure control. Alternating direction method of multipliers (ADMM) is utilized for highly parallel computing for SVM training. From the algorithm aspect, minimum redundancy maximum relevance (mRMR) and low-rank approximation are exploited to reduce overall computational complexity by 99.4 while also reducing memory storage by 90.4. For hardware optimization, overall hardware complexity is reduced by 87 through a hardware-shared configurable coordinate rotation digital computer (CORDIC)-based processing element array. Parallel rotations and folded structure for the approximate Jacobi method reduce overall training latency by 98.6. The chip achieves a detection performance with a 96.6 accuracy and a 0.28/h false alarm rate within 0.71 s with the power dissipation of 1.9 mW. The proposed SVM processor achieves the shortest detection latency compared with the state-of-the-art seizure detectors. It also supports real-time model adaptation with a latency of 0.78 s. Compared with previous designs, this work achieves a $22\times $ higher throughput and a $162\times $ higher energy efficiency for SVM training.","Support vector machines,Training,Feature extraction,Brain modeling,Computational complexity,Adaptation models,Hardware,CMOS digital-integrated circuits,electroencephalogram (EEG),model adaptation,on-chip training,seizure detection,support vector machine (SVM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.434,"SUPPORT,VECTOR,MACHINE,REAL-TIME,EEG,CLASSIFICATION,ARCHITECTURES,ALGORITHMS,PREDICTION,SOC",IEEE JOURNAL OF SOLID-STATE CIRCUITS,,
65,Improving realism in patient-specific abdominal ultrasound simulation using CycleGANs,15,2,183-192,"Vitale Santiago,Orlando Jose Ignacio,Iarussi Emmanuel,Larrabide Ignacio","Vitale S,Orlando JI,Iarussi E,Larrabide I",Vitale S,10.1007/s11548-019-02046-5,"UNICEN, Pladema, Tandil, Argentina.","Purpose In this paper, we propose to apply generative adversarial neural networks trained with a cycle consistency loss, or CycleGANs, to improve realism in ultrasound (US) simulation from computed tomography (CT) scans. Methods A ray-casting US simulation approach is used to generate intermediate synthetic images from abdominal CT scans. Then, an unpaired set of these synthetic and real US images is used to train CycleGANs with two alternative architectures for the generator, a U-Net and a ResNet. These networks are finally used to translate ray-casting based simulations into more realistic synthetic US images. Results Our approachwas evaluated both qualitatively and quantitatively. Auser study performed by 21 experts inUSimaging shows that both networks significantly improve realism with respect to the original ray-casting algorithm ( p 0.0001), with the ResNet model performing better than the U-Net ( p 0.0001). Conclusion Applying CycleGANs allows to obtain better synthetic US images of the abdomen. These results can contribute to reduce the gap between artificially generated and real US scans, which might positively impact in applications such as semi-supervised training of machine learning algorithms and low-cost training of medical doctors and radiologists in US image interpretation.","Ultrasound,Image simulation,Deep learning",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,"MEDICAL,ULTRASOUND",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
66,Multimodal 3D medical image registration guided by shape encoder-decoder networks,15,2,269-276,"Blendowski Max,Bouteldja Nassim,Heinrich Mattias P.","Blendowski M,Bouteldja N,Heinrich MP",Blendowski M,10.1007/s11548-019-02089-8,University of Lubeck,"Purpose Nonlinear multimodal image registration, for example, the fusion of computed tomography (CT) and magnetic resonance imaging (MRI), fundamentally depends on a definition of image similarity. Previous methods that derived modality-invariant representations focused on either global statistical grayscale relations or local structural similarity, both of which are prone to local optima. In contrast to most learning-based methods that rely on strong supervision of aligned multimodal image pairs, we aim to overcome this limitation for further practical use cases. Methods We propose a new concept that exploits anatomical shape information and requires only segmentation labels for both modalities individually. First, a shape-constrained encoder-decoder segmentation network without skip connections is jointly trained on labeled CT and MRI inputs. Second, an iterative energy-based minimization scheme is introduced that relies on the capability of the network to generate intermediate nonlinear shape representations. This further eases the multimodal alignment in the case of large deformations. Results Our novel approach robustly and accurately aligns 3D scans from the multimodal whole-heart segmentation dataset, outperforming classical unsupervised frameworks. Since both parts of our method rely on (stochastic) gradient optimization, it can be easily integrated in deep learning frameworks and executed on GPUs. Conclusions We present an integrated approach for weakly supervised multimodal image registration. Achieving promising results due to the exploration of intermediate shape features as registration guidance encourages further research in this direction.","Multimodal fusion,Guided image registration,Encoder-decoder network,Nonlinear shape interpolation",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,,INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
67,A manifold learning regularization approach to enhance 3D CT image-based lung nodule classification,15,2,287-295,"Ren Ying,Tsai Min-Yu,Chen Liyuan,Wang Jing,Li Shulong,Liu Yufei,Jia Xun,Shen Chenyang","Ren Y,Tsai MY,Chen LY,Wang J,Li SL,Liu YF,Jia X,Shen CY",Jia X; Shen CY,10.1007/s11548-019-02097-8,University of Texas System,"Purpose Diagnosis of lung cancer requires radiologists to review every lung nodule in CT images. Such a process can be very time-consuming, and the accuracy is affected by many factors, such as experience of radiologists and available diagnosis time. To address this problem, we proposed to develop a deep learning-based system to automatically classify benign and malignant lung nodules. Methods The proposed method automatically determines benignity or malignancy given the 3D CT image patch of a lung nodule to assist diagnosis process. Motivated by the fact that real structure among data is often embedded on a low-dimensional manifold, we developed a novel manifold regularized classification deep neural network (MRC-DNN) to perform classification directly based on the manifold representation of lung nodule images. The concise manifold representation revealing important data structure is expected to benefit the classification, while the manifold regularization enforces strong, but natural constraints on network training, preventing over-fitting. Results The proposed method achieves accurate manifold learning with reconstruction error of ~ 30 HU on real lung nodule CT image data. In addition, the classification accuracy on testing data is 0.90 with sensitivity of 0.81 and specificity of 0.95, which outperforms state-of-the-art deep learning methods. Conclusion The proposed MRC-DNN facilitates an accurate manifold learning approach for lung nodule classification based on 3D CT images. More importantly, MRC-DNN suggests a new and effective idea of enforcing regularization for network training, possessing the potential impact to a board range of applications.","Diagnosis,Lung nodule classification,Deep learning,Regularization,Manifold learning",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,,INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
68,Automatic cancer tissue detection using multispectral photoacoustic imaging,15,2,309-320,"Jnawali Kamal,Chinni Bhargava,Dogra Vikram,Rao Navalgund","Jnawali K,Chinni B,Dogra V,Rao NV",Jnawali K,10.1007/s11548-019-02101-1,Rochester Institute of Technology,"Purpose
In the case of multispecimen study to locate cancer regions, such as in thyroidectomy and prostatectomy, a significant labor-intensive processing is required at a high cost. Pathology diagnosis is usually done by a pathologist observing tissue-stained glass slide under a microscope. Method
Multispectral photoacoustic (MPA) specimen imaging has proven successful in differentiating photoacoustic (PA) signal characteristics between a histopathology-defined cancer region and normal tissue. This is mainly due to its ability to efficiently map oxyhemoglobin and deoxyhemoglobin contents from MPA images and key features for cancer detection. A fully automated deep learning algorithm is purposed, which learns to detect the presence of malignant tissue in freshly excised ex vivo human thyroid and prostate tissue specimens using the three-dimensional MPA dataset. The proposed automated deep learning model consisted of the convolutional neural network architecture, which extracts spatially colocated features, and a softmax function, which detects thyroid and prostate cancer tissue at once. This is one of the first deep learning models, to the best of our knowledge, to detect the presence of cancer in excised thyroid and prostate tissue of humans at once based on PA imaging. Result The area under the curve (AUC) was used as a metric to evaluate the predictive performance of the classifier. The proposed model detected the cancer tissue with the AUC of 0.96, which is very promising. Conclusion This model is an improvement over the previous work using machine learning and deep learning algorithms. This model may have immediate application in cancer screening of the numerous sliced specimens that result from thyroidectomy and prostatectomy. Since the instrument that was used to capture the ex vivo PA images is now being developed for in vivo use, this model may also prove to be a starting point for in vivo PA image analysis for cancer diagnosis.","Cancer tissue detection,Classification,Deep learning,Machine learning,3D CNN,Transfer learning,Computer-aided diagnosis,Prostate,Thyroid",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,"NEURAL-NETWORKS,EX-VIVO",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
69,Robot-assisted flexible needle insertion using universal distributional deep reinforcement learning,15,2,341-349,"Tan Xiaoyu,Lee Yonggu,Chng Chin-Boon,Lim Kah-Bin,Chui Chee-Kong","Tan XY,Lee YG,Chng CB,Lim KB,Chui CK",Tan XY,10.1007/s11548-019-02098-7,National University of Singapore,"Purpose Flexible needle insertion is an important minimally invasive surgery approach for biopsy and radio-frequency ablation. This approach can minimize intraoperative trauma and improve postoperative recovery. We propose a new path planning framework using multi-goal deep reinforcement learning to overcome the difficulties in uncertain needle-tissue interactions and enhance the robustness of robot-assisted insertion process. Methods This framework utilizes a new algorithm called universal distributional Q-learning (UDQL) to learn a stable steering policy and perform risk management by visualizing the learned Q-value distribution. To further improve the robustness, universal value function approximation is leveraged in the training process of UDQL to maximize generalization and connect to diagnosis by adapting fast re-planning and transfer learning. Results Computer simulation and phantom experimental results show our proposed framework can securely steer flexible needles with high insertion accuracy and robustness. The framework also improves robustness by providing distribution information to clinicians for diagnosis and decision making during surgery. Conclusions Compared with previous methods, the proposed framework can perform multi-target needle insertion through single insertion point qunder continuous state space model with higher accuracy and robustness.","Deep learning,Deep reinforcement learning,Needle steering,Tool-tissue interaction,Uncertainty",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,"LIVER-TISSUE,MANIPULATOR",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
70,Boosting for Mineral Prospectivity Modeling: A New GIS Toolbox,29,1,71-88,"Brandmeier Melanie,Zamora Irving Gibran Cabrera,Nykaenen Vesa,Middleton Maarit","Brandmeier M,Zamora IGC,Nykanen V,Middleton M",Brandmeier M,10.1007/s11053-019-09483-8,"Esri Deutschland GmbH, Ringstr 7, D-85402 Kranzberg, Germany.","With an increasing demand for raw materials, predictive models that support successful mineral exploration targeting are of great importance. We evaluated different machine learning techniques with an emphasis on boosting algorithms and implemented them in an ArcGIS toolbox. Performance was tested on an exploration dataset from the Iberian Pyrite Belt (IPB) with respect to accuracy, performance, stability, and robustness. Boosting algorithms are ensemble methods used in supervised learning for regression and classification. They combine weak classifiers, i.e., classifiers that perform slightly better than random guessing to obtain robust classifiers. Each time a weak learner is added; the learning set is reweighted to give more importance to misclassified samples. Our test area, the IPB, is one of the oldest mining districts in the world and hosts giant volcanic-hosted massive sulfide (VMS) deposits. The spatial density of ore deposits, as well as the size and tonnage, makes the area unique, and due to the high data availability and number of known deposits, well-suited for testing machine learning algorithms. We combined several geophysical datasets, as well as layers derived from geological maps as predictors of the presence or absence of VMS deposits. Boosting algorithms such as BrownBoost and Adaboost were tested and compared to Logistic Regression (LR), Random Forests (RF) and Support Vector machines (SVM) in several experiments. We found performance results relatively similar, especially to BrownBoost, which slightly outperformed LR and SVM with respective accuracies of 0.96 compared to 0.89 and 0.93. Data augmentation by perturbing deposit location led to a 7% improvement in results. Variations in the split ratio of training and test data led to a reduction in the accuracy of the prediction result with relative stability occurring at a critical point at around 26 training samples out of 130 total samples. When lower numbers of training data were introduced accuracy dropped significantly. In comparison with other machine learning methods, Adaboost is user-friendly due to relatively short training and prediction times, the low likelihood of overfitting and the reduced number of hyperparameters for optimization. Boosting algorithms gave high predictive accuracies, making them a potential data-driven alternative for regional scale and/or brownfields mineral exploration.","Boosting,Machine Learning,Prospectivity Mapping,Iberian Pyrite Belt,Exploration",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Geology,,4.269,"IBERIAN,PYRITE,BELT,EVIDENTIAL,BELIEF,FUNCTIONS,MASSIVE,SULFIDE,DEPOSITS,SUPPORT,VECTOR,MACHINE,GOLD-SILVER,DEPOSITS,WEIGHTS-OF-EVIDENCE,RANDOM,FOREST,FUZZY-LOGIC,GEOLOGICAL,CONSTRAINTS,NEURAL-NETWORKS",NATURAL RESOURCES RESEARCH,https://link.springer.com/content/pdf/10.1007/s11053-019-09483-8.pdf,
71,Single-shot spatially-localized NQR using field-dependent relaxation rates,311,,,"Chen Cheng,Tang Xinyao,Masna Naren Vikram Raj,Bhunia Swarup,Mandal Soumyajit","Chen C,Tang XY,Masna NVR,Bhunia S,Mandal S",Chen C,10.1016/j.jmr.2019.106660,Case Western Reserve University,"Nuclear quadrupole resonance (NQR) is commonly used to characterize solid materials containing quadrupolar nuclei. For example, NQR is a promising technique for detecting plastic explosives and other forbidden substances as well as for authenticating pharmaceutical products. Spatially-resolved NQR measurements are of particular interest for enabling automated sample positioning, evaluation of sample heterogeneity, and chemometric authentication of objects. This paper proposes a rapid ""single-shot"" method for spatially-resolved NQR with the potential to benefit such applications. The proposed method takes advantage of the fact that certain NQR relaxation rates are field-dependent: the observed field dependence is used to convert relaxation time distributions measured in a static field gradient (estimated via Laplace inversion of time-domain data) into spatial distributions. The method was validated using Cl-35 and (37)Cl( )NQR of sodium chlorate and other compounds. Effective spatial resolution was also improved by using machine learning (ML) to classify the measured spatial distributions. In particular, experimental results demonstrate accurate ML-based classification of 3D-printed objects containing arbitrary binary distributions of sodium chlorate. Such distributions can thus be used as NQR-based ""embedded barcodes"" for authenticating high-value objects. (C) 2019 Elsevier Inc. All rights reserved.","NQR imaging,Zeeman splitting,Laplace inversion,Classification,Authentication",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Biochemistry & Molecular Biology,Physics,Spectroscopy",,2.208,"NUCLEAR-QUADRUPOLE,RESONANCE,TEMPERATURE,MEDICINES,AUTHENTICATION,PRESSURE,GRADIENT,COILS,STATE",JOURNAL OF MAGNETIC RESONANCE,,
72,Machine learning analysis on stability of perovskite solar cells,205,,,"Odabasi Cagla,Yildirim Ramazan","Odabasi C,Yildirim R",Yildirim R,10.1016/j.solmat.2019.110284,Bogazici University,"In this work, a dataset containing long-term stability data for 404 organolead halide perovskite cells was constructed from 181 published papers and analyzed using machine-learning tools of association rule mining and decision trees; the effects of cell manufacturing materials, deposition methods and storage conditions on cell stability were investigated. For regular cells, mixed cation perovskites, multi-spin coating as one-step deposition, DMF + DMSO as precursor solution and chlorobenzene as anti-solvent were found to have positive effects on stability; SnO2 as ETL compact layer, PCBM as second ETL, inorganic HTLs or HTL-free cells, LiTFSI + TBP + FK209 and F4TCNQ as HTL additives and carbon as back contact were also found to improve stability. The cells stored under low humidity were found to be more stable as expected. The degradation was slightly faster in inverted cells under humid condition; the use of some materials (like mixed cation perovskites, PTAA and NiOx as HTL, PCBM + C60 as ETL, and BCP interlayer) were found to result in more stable cells.","Perovskite solar cells,Data mining,Machine learning,Association rule mining,Stability,Knowledge extraction",Article; Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Energy & Fuels,Materials Science,Physics",,6.363,"IMPROVED,AIR,STABILITY,HIGH-PERFORMANCE,DEVICE,STABILITY,EFFICIENT,DEGRADATION,TEMPERATURE,MORPHOLOGY,FILMS,LAYER",SOLAR ENERGY MATERIALS AND SOLAR CELLS,,
73,Grading of Clear Cell Renal Cell Carcinomas by Using Machine Learning Based on Artificial Neural Networks and Radiomic Signatures Extracted From Multidetector Computed Tomography Images,27,2,157-168,"He Xiaopeng,Wei Yi,Zhang Hanmei,Zhang Tong,Yuan Fang,Huang Zixing,Han Fugang,Song Bin","He XP,Wei Y,Zhang HM,Zhang T,Yuan F,Huang ZX,Han FG,Song B",Song B,10.1016/j.acra.2019.05.004,Sichuan University,"Rationale and Objectives: To evaluate the ability of artificial neural networks (ANN) fed with radiomic signatures (RSs) extracted from multidetector computed tomography images in differentiating the histopathological grades of clear cell renal cell carcinomas (ccRCCs).
Materials and Methods: The multidetector computed tomography images of 227 ccRCCs were retrospectively analyzed. For each ccRCC, 14 conventional image features (CIFs) were extracted manually by two radiologists, and 556 texture features (TFs) were extracted by a free software application, MaZda (version 4.6). The high-dimensional dataset of these RSs was reduced using the least absolute shrinkage and selection operator. Five minimum mean squared error models (minMSEMs) for predicting the ccRCC histopathological grades were constructed from the CIFs, the TFs of the corticomedullary phase images (CMP), and the TFs of the parenchyma phase (PP) images and their combinations, respectively abbreviated as CIF-minMSEM, CMP-minMSEM, PP-minMSEM, CIF+CMP-minMSEM, and CIF+PP-minMSEM. The RSs of each model were fed 30 times consecutively into an ANN for machine learning, and the predictive accuracy of each time ML was recorded for the statistical analysis.
Results: The five predictive models were constructed from 12, 19, and 10 features selected from the CIFs, the TFs of the CMP images, and that of PP images, respectively. On the basis of their accuracy across the whole cohort, the five models were ranked as follows: CIF+CMP-minMSEM (accuracy: 94.06% +/- 1.14%), CIF + PP-minMSEM (accuracy: 93.32% +/- 1.23%), CIF-minMSEM (accuracy: 92.26% +/- 1.65%), CMP-minMSEM (accuracy: 91.76% +/- 1.74%), and PP-minMSEM (accuracy: 90.89% +/- 1.47%).
Conclusion: Machine teaming based on ANN helped establish an optimal predictive model, and TFs contributed to the development of high accuracy predictive models. The CIF+CMP-minMSEM showed the greatest accuracy for differentiating low- and high-grade ccRCCs.","Machine learning,Artificial neural networks,Radiomic signature,Texture feature,Computed tomography,Clear cell renal cell carcinoma",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.751,"TEXTURE,ANALYSIS,FUHRMAN,GRADE,CLASSIFICATION,ANGIOMYOLIPOMA,PREDICTION,FAT,DIFFERENTIATION,FEATURES,DISEASE,SYSTEM",ACADEMIC RADIOLOGY,,
74,Deep Learning in the Prediction of Ischaemic Stroke Thrombolysis Functional Outcomes: A Pilot Study,27,2,E19-E23,"Bacchi Stephen,Zerner Toby,Oakden-Rayner Luke,Kleinig Timothy,Patel Sandy,Jannes Jim","Bacchi S,Zerner T,Oakden-Rayner L,Kleinig T,Patel S,Jannes J",Bacchi S,10.1016/j.acra.2019.03.015,Royal Adelaide Hospital,"Rationale and Objectives: Intravenous thrombolysis decision-making and obtaining of consent would be assisted by an individualized risk-benefit ratio. Deep learning (DL) models may be able to assist with this patient selection.
Materials and Methods: Clinical data regarding consecutive patients who received intravenous thrombolysis across two tertiary hospitals over a 7-year period were extracted from existing databases. The noncontrast computed tomography brain scans for these patients were then retrieved with hospital picture archiving and communication systems. Using a combination of convolutional neural networks (CNN) and artificial neural networks (ANN) several models were developed to predict either improvement in the National Institutes of Health Stroke Scale of >= 4 points at 24 hours (""NIHSS24""), or modified Rankin Scale 0-1 at 90 days (""mRS90""). The developed CNN and ANN were then applied to a test set. The THRIVE, HIAT, and SPAN-100 scores were also calculated for the patients in the test set and used to predict NIHSS24 and mRS90.
Results: Data from 204 individuals were included in the project. The best performing DL model for prediction of mRS90 was a combination CNN + ANN based on clinical data and computed tomography brain (accuracy = 0.74, F1 score = 0.69). The best performing model for NIHSS24 prediction was also the combination CNN + ANN (accuracy = 0.71, F1 score = 0.74).
Conclusion: DL models may aid in the prediction of functional thrombolysis outcomes. Further investigation with larger datasets and additional imaging sequences is indicated.","Prognostication,Machine learning,Artificial intelligence,Convolutional neural network",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.751,RISK,ACADEMIC RADIOLOGY,,
75,Electrochemical discharge machining modeling through different soft computing approaches,106,7-8,3587-3596,"Leyva-Bravo Jansel,Chinas-Sanchez Pamela,Hernandez-Rodriguez Alejandra,Hernandez-Alba Gerardo G.","Leyva-Bravo J,Chinas-Sanchez P,Hernandez-Rodriguez A,Hernandez-Alba GG",Chinas-Sanchez P,10.1007/s00170-019-04766-z,"Inst Tecnol Saltillo, Blvd Venustiano Carranza,Tecnol 2400, Saltillo 25280, Coah, Mexico.","The processes' modeling is an important aspect in the industry since it allows to obtain high productivity with energy and material savings. The hybrid process electrochemical discharge machining (ECDM) is subject to uncertainty and inaccuracy levels in the parameters, so a viable option to model this process is through soft computing techniques such as fuzzy logic and artificial neural networks. In this work, we present three models using fuzzy logic, backpropagation network, and radial basis function network for the prediction of the material removal rate (MRR). The gap voltage (Vg), peak current (Ip), and frequency (f) were taken as input parameters. A 3-factor full factorial design was developed with 2 levels (2(3)), two replicas, and four central points. The model with the higher accuracy according to experimental result was radial basis function artificial neural network with 97.25% of accuracy.","ECDM process,Soft computing,Fuzzy logic,Backpropagation network,Radial basis function (RBF)",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND","Automation & Control Systems,Engineering",,3.32,"SURFACE-ROUGHNESS,EDM,PARAMETERS,PREDICTION,ALLOY",INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY,,
76,,,,,,,,,,,,,,,,,,,,
77,Deep learning-based virtual noncontrast CT for volumetric modulated arc therapy planning: Comparison with a dual-energy CT-based approach,47,2,371-379,"Koike Yuhei,Ohira Shingo,Akino Yuichi,Sagawa Tomohiro,Yagi Masashi,Ueda Yoshihiro,Miyazaki Masayoshi,Sumida Iori,Teshima Teruki,Ogawa Kazuhiko","Koike Y,Ohira S,Akino Y,Sagawa T,Yagi M,Ueda Y,Miyazaki M,Sumida I,Teshima T,Ogawa K",Akino Y,10.1002/mp.13925,Osaka University,"Purpose The aim of this study was to develop a deep learning (DL) method for generating virtual noncontrast (VNC) computed tomography (CT) images from contrast-enhanced (CE) CT images (VNCDL) and to evaluate its performance in dose calculations for head and neck radiotherapy in comparison with VNC images derived from a dual-energy CT (DECT) scanner (VNCDECT).
Methods This retrospective study included data for 61 patients who underwent head and neck radiotherapy. All planning CT images were obtained with a single-source DECT scanner (80 and 140 kVp) with rapid kVp switching. The DL-based method used a pair of virtual monochromatic images (VMIs) at 70 keV with and without contrast materials. VMIs without contrast materials were used as reference true noncontrast (TNC) images. Deformable image registration was used between the TNC and CE images. We used the data of 45 patients, chosen randomly, for training (7922 paired images), and data from the other 16 patients as test data. We generated the VNCDL images with a densely connected convolutional network. As the VNCDECT images, we used VMIs with the iodine signal suppressed, reconstructed from the CE images of the 16 test patients. The CT numbers of the tumor, common carotid artery, internal jugular vein, muscle, fat, bone marrow, cortical bone, and mandible of each VNC image were compared with those of the TNC image. The dose of the reference TNC plan was recalculated using the CE, VNCDL, and VNCDECT images. Difference maps of the dose distributions and dose-volume histograms were evaluated.
Results The mean prediction time for the VNCDL images was 3.4 s per patient, and the mean number of slices was 204. The absolute differences in CT numbers of the VNCDL images were significantly smaller than those of the VNCDECT images for the bone marrow (8.0 +/- 6.5 vs 175.1 +/- 40.9 HU; P < 0.001) and mandible (20.3 +/- 19.3 vs 106.2 +/- 80.5 HU; P = 0.002). The DL-based model provided the dose distribution most similar to that of the TNC plan. With the VNCDECT plans, dose errors >1.0% were observed in bone regions. The dose-volume histogram analysis showed that the VNCDL plans yielded the smallest errors for the primary target, although dose differences were <1.0% for all the approaches. For the maximum dose to the mandible, the mean +/- SD errors for the CE, VNCDL, and VNCDECT plans were -0.13% +/- 0.23% (range: -0.46% to 0.31%; P = 0.037), -0.01% +/- 0.22% (range: -0.40% to 0.36%; P = 1.0), and 0.53% +/- 0.47% (range: -0.21% to 1.41%; P < 0.001), respectively.
Conclusions In this study, we developed a method based on DL that can rapidly generate VNC images from CE images without a DECT scanner. Compared with the DECT approach, the DL-based method improved the prediction accuracy of CT numbers in bone regions. Consequently, there was greater agreement between the VNCDL and TNC plan dose distributions than with the CE and VNCDECT plans, achieved by suppressing the contrast material signals while retaining the CT numbers of bone structures.","deep learning,dose calculation,dual-energy CT,treatment planning,virtual noncontrast CT",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"MULTIMATERIAL,DECOMPOSITION,COMPUTED-TOMOGRAPHY,DOSE,CALCULATION,QUALITY,IMPLEMENTATION,RADIOTHERAPY,DELINEATION,ACCURACY,NUMBERS,HEAD",MEDICAL PHYSICS,,
78,Towards a Deep Improviser: a prototype deep learning post-tonal free music generator,32,4,969-979,"Dean Roger T.,Forth Jamie","Dean RT,Forth J",Dean RT,10.1007/s00521-018-3765-x,Western Sydney University,"Two modest-sized symbolic corpora of post-tonal and post-metrical keyboard music have been constructed: one algorithmic and the other improvised. Deep learning models of each have been trained. The purpose was to obtain models with sufficient generalisation capacity that in response to separate fresh input seed material, they can generate outputs that are statistically distinctive, neither random nor recreative of the learned corpora or the seed material. This objective has been achieved, as judged by k-sample Anderson-Darling and Cramer tests. Music has been generated using the approach, and preliminary informal judgements place it roughly on a par with an example of composed music in a related form. Future work will aim to enhance the model such that it deserves to be fully evaluated in relation to expression, meaning and utility in real-time performance.","Deep learning,Music,Post-tonal,Post-metrical,Improvisation",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,,"ALGORITHMIC,COMPOSITION,SEGMENTATION,EXPECTATION,CONTEXT",NEURAL COMPUTING & APPLICATIONS,https://research.gold.ac.uk/24157/1/DeepL-Impro-2ndRevision-v1.pdf,
79,Automated quality classification of colour fundus images based on a modified residual dense block network,14,1,215-223,"Zhang Fang,Xu Xu,Xiao Zhitao,Wu Jun,Geng Lei,Wang Wen,Liu Yanbei","Zhang F,Xu X,Xiao ZT,Wu J,Geng L,Wang W,Liu YB",Xiao ZT,10.1007/s11760-019-01544-y,Tiangong University,"Fundus image-assisted diagnosis has become an intuitive and standard diagnostic technique in recent years. In hospital treatment and telemedicine, experts conduct pathological analysis and treat patients with fundus diseases using retinal images that are captured by fundus cameras. The quality of fundus images is therefore crucial for doctors to provide timely and accurate diagnoses of the diseases. However, the different experiences of fundus photographers result in different image qualities, and some images are marked as unreadable by the diagnostician, seriously delaying the treatment of patients. To solve the quality classification problem, a modified residual dense block convolution neural network (MRDB-CNN) is proposed in this paper. The two categories of images, ""good quality"" and ""poor quality"", are used as the training data set and testing data set to train the CNNs and verify the classification results. The experimental results show that, compared with other existing network structures, the network proposed in this paper can classify the ""good-quality"" and ""poor-quality"" fundus images more accurately with an accuracy rate of 99.90%. In addition, the tests for the ""ambiguous-quality"" category further demonstrate that our method can obtain more detailed features of the fundus images and give an objective score to the image quality. In short, the MRDB-CNN can accurately classify the quality of fundus images while avoiding the complex preprocessing of traditional algorithms, and it satisfies the needs of hospital treatment and telemedicine for the real-time quality judgement of fundus images.","Colour fundus image,Quality classification,Deep learning,MRDB-CNN",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND","Engineering,Imaging Science & Photographic Technology",,,SEGMENTATION,SIGNAL IMAGE AND VIDEO PROCESSING,,
80,Sleep Apnea Detection Using Artificial Bee Colony Optimize Hermite Basis Functions for EEG Signals,69,2,608-616,"Taran Sachin,Bajaj Varun","Taran S,Bajaj V",Taran S,10.1109/TIM.2019.2902809,"Indian Institute of Information Technology Design & Manufacturing, Jabalpur","Sleep apnea is a sleeping disorder, which adversely affects the health of humans. The diagnosis of sleep apnea is possible by the detection of apnea events using electroencephalogram (EEG) recordings. This paper introduces an adaptive decomposition for the detection of apnea events using EEG signals. In introduced decomposition, the evolutionary techniques (ETs) optimized Hermite functions (HFs) represent the EEG signals. In tested ETs, the artificial bee colony (ABC) algorithm provides the least reconstruction error for the representation of EEG signals. The ABC is considered for Hermite coefficients-based feature extraction. From the extracted features, a highly discriminative feature set is obtained using the Fisher-score ranking test. The apnea detection performance of ranking-based selected features is evaluated using the extreme learning machine and least-squares support vector machine classifiers. The proposed method obtained performance measures, sensitivity 99.47, specificity 99.58, and accuracy 99.53, are better as compared to the state-of-the-art methods.","Electroencephalography,Feature extraction,Sleep apnea,Hafnium,Support vector machines,Biological cells,Electroencephalogram (EEG) signal,evolutionary techniques,extreme learning machine (ELM),Hermite functions (HFs),sleep apnea",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"RECOGNITION,ECG,ALGORITHMS,TRANSFORM,MACHINE,MODEL",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
81,Deep Learning-Based Dynamic Scheduling for Semiconductor Manufacturing With High Uncertainty of Automated Material Handling System Capability,33,1,13-22,"Kim Haejoong,Lim Dae-Eun,Lee Sangmin","Kim H,Lim DE,Lee S",Lee S,10.1109/TSM.2020.2965293,Samsung,"Recently, the transportation capability of the automated material handling system (AMHS) has emerged as a major barrier to the semiconductor fabrication facility (FAB), because it can limit the FAB production capacity. In this study, we propose a prediction method for a machine allocation problem of production scheduling in consideration with the AMHS's constraints. The proposed method dynamically targets a machine for the next process by identifying diverse production conditions. We use a deep neural network-based dynamic scheduling method considering the overall production environment, which includes the remaining processing time, facility states, transportation time and traffic congestion, work-in-process distribution, and intermediate buffer states. To demonstrate the superiority and efficiency of the proposed method, we conducted experimental studies to compare the proposed model with the existing priority rule-based and analytic models under the static and dynamic environments. From the results, we verify that the proposed dynamic scheduling system can enhance the performance of existing AMHS and reduce machine starvation and production losses.","manufacturing scheduling,artificial intelligence,adaptive control,production systems,uncertainty",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Physics",,2.479,"INTELLIGENT,MULTI-CONTROLLER,DISPATCHING,RULES,SELECTION,OPTIMIZATION,CELL",IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING,,
82,Optimization of back projection with different geometry configurations of X-ray sources in digital breast tomosynthesis: A Monte Carlo simulation study,202,,,"Zhu Fubao,Liu Yanyun,Wen Haixing,Wang Tianquan,Fang Jian,Tang Shaojie","Zhu FB,Liu YY,Wen HX,Wang TQ,Fang J,Tang SJ",Tang SJ,10.1016/j.ijleo.2019.163604,Xi'an University of Posts & Telecommunications,"Breast cancer is the second leading cause of cancer-related mortality among women all over the world. The earlier the breast cancer is detected, the higher the possibility of cure. Digital breast tomosynthesis (DBT) is an effective technique for early breast cancer diagnosis. The DBT system obtains several projection images at a limited range of view angle and thus reduces the radiation dose delivered to patient effectively. Back projection (BP) is a classic algorithm for image reconstruction. In this work, 25 projection images were acquired by simulating seven different geometry configurations of X-ray sources on GATE (Geant4 Application for Tomographic Emission) platform. BP algorithm and its two variants (i.e., alpha-trimmed BP and PCA-based BP) were used for image reconstruction. Our experimental results demonstrated that among the seven geometry configurations of X-ray sources, the rectangular non-uniform configuration performed the best; it showed a better capability in eliminating out-of-plane artifacts and resolving spatial details than others. In addition, the a-trimmed BP had a better image quality among all of the three algorithms in the modulation transfer function analysis.","Breast cancer,Digital breast tomosynthesis,Image reconstruction,Image quality,Back projection",Article,"ELSEVIER GMBH, HACKERBRUCKE 6, 80335 MUNICH, GERMANY",Optics,,1.955,,OPTIK,,
83,Machine learning-based quantitative texture analysis of conventional MRI combined with ADC maps for assessment of IDH1 mutation in high-grade gliomas,38,2,135-143,"Alis Deniz,Bagcilar Omer,Senli Yeseren Deniz,Yergin Mert,Isler Cihan,Kocer Naci,Islak Civan,Kizilkilic Osman","Alis D,Bagcilar O,Senli YD,Yergin M,Isler C,Kocer N,Islak C,Kizilkilic O",Alis D,10.1007/s11604-019-00902-7,"Res Hosp, Dept Radiol, Istanbul Mehmet Akif Ersoy Thorac, Cardiovascular Surg Training, Halkali/istanbul, Turkey.","Purpose To assess the performance of texture analysis of conventional magnetic resonance imaging (MRI) and apparent diffusion coefficient (ADC) maps in predicting IDH1 status in high-grade gliomas (HGG). Materials and methods A total of 142 patients with HGG were included in the study. IDH1 mutation was present in 48 of 142 HGG (33.8%). Patients were randomly divided into the training cohort (n = 96) and the validation cohort (n = 46). Texture features were extracted via regions of interest on axial T2WI FLAIR, post-contrast T1WI, and ADC maps covering the whole volume of the tumors. The training cohort was used to train the random forest classifier, and the diagnostic performance of the pre-trained model was tested on the validation cohort. Results The random forest model of conventional MRI sequences and ADC images achieved diagnostic accuracy of 82.2% and 80.4% in predicting IDH1 status in the validation cohorts, respectively. The combined model of T2WI FLAIR, post-contrast T1WI, and ADC images exhibited the highest diagnostic accuracy equating 86.94% in the validation cohort. Conclusion Texture analysis of conventional MRI sequences enhanced by ML analysis can accurately predict the IDH1 status of HGG. Adding textural analysis of ADC maps to conventional MRI results in incremental diagnostic performance.","Artificial intelligence,IDH1,Gliomas,Machine-learning,Texture analysis",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,1.857,"CLASSIFICATION,NEUROONCOLOGY,ASSOCIATION,PREDICTION,FEATURES,SYSTEM,NUMBER",JAPANESE JOURNAL OF RADIOLOGY,,
84,Online discrimination of chemical substances using standoff laser-induced fluorescence signals,34,2,,"Kraus Marian,Gebert Florian,Walter Arne,Pargmann Carsten,Duschek Frank","Kraus M,Gebert F,Walter A,Pargmann C,Duschek F",Kraus M,10.1002/cem.3121,Helmholtz Association,"Chemical contamination of objects and surfaces, caused by accident or on purpose, is a common security issue. Immediate countermeasures depend on the class of risk and consequently on the characteristics of the substances. Laser-based standoff detection techniques can help to provide information about the thread without direct contact of humans to the hazardous materials. This article explains a data acquisition and classification procedure for laser-induced fluorescence spectra of several chemical agents. The substances are excited from a distance of 3.5 m by laser pulses of two UV wavelengths (266 and 355 nm) with less than 0.1 mJ per laser pulse and a repetition rate of 100 Hz. Each pair of simultaneously emitted laser pulses is separated using an optical delay line. Every measurement consists of a dataset of 100 spectra per wavelength containing the signal intensities in the spectral range from 250 to 680 nm, recorded by a 32-channel photo multiplying tube array. Based on this dataset, three classification algorithms are trained which can distinguish the samples by their single spectra with an accuracy of over 98%. These predictive models, generated with decision trees, support vector machines, and neural networks, can identify all agents (eg, benzaldehyde, isoproturon, and piperine) within the current set of substances.","chemical agents,classification algorithms,laser-induced fluorescence,machine learning,standoff detection",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Automation & Control Systems,Chemistry,Computer Science,Instruments & Instrumentation,Mathematics",,,,JOURNAL OF CHEMOMETRICS,https://elib.dlr.de/127324/1/Kraus_et_al-2019-Journal_of_Chemometrics.pdf,
85,Identifying bladder rupture following traumatic pelvic fracture: A machine learning approach,51,2,334-339,"Hertz Alexandria M.,Hertz Nicholas M.,Johnsen Niels V","Hertz AM,Hertz NM,Johnsen NV",Hertz AM,,Madigan Army Medical Center,"Introduction: Bladder rupture following blunt pelvic trauma is rare though can have significant sequelae. We sought to determine whether machine learning could help predict the presence of bladder injury using certain factors at the time of presentation of blunt pelvic trauma.
Materials and methods: Adult patients at a Level I trauma center with blunt trauma pelvic fractures from January 1, 2005 to December 31, 2017 were identified. Patients with admission urinalysis data, fracture ICD 9 codes, and mechanism of injury available in the trauma registry were included. Patients with bladder rupture and pelvic fracture were compared to those with pelvic fracture alone. The classification of results was performed using the MATLAB Classification Learner Tool. The classification performances were tested by machine learning algorithms in the domains of Decision Tree, Logistic Regression, Naive Bayes, Support Vector Machine (SVM), Nearest Neighbor (KNN), and Ensemble classifiers.
Results: Of the 3063 eligible pelvic fracture patients identified, 208 (6.8%) had concomitant bladder ruptures. Twenty machine learning algorithms were then tested based on pelvic fracture ICD-9 code, admission urinalysis, and mechanism of injury. The best classification results were obtained using the Gaussian Naive Bayes and Kernel Naive Bayes classifiers, both with accuracy of 97.8%, specificity of 99%, sensitivity of 83%, and area under the curve (AUC) of the ROC curve of 0.99.
Conclusion: Machine learning algorithms can be used to help predict with a high level of accuracy the presence of bladder rupture with blunt pelvic trauma using readily available information at the time of presentation. This has the potential to improve selection of patients for additional imaging, while also more appropriately allocating hospital resources and reducing patient risks. Published by Elsevier Ltd.","Pelvic trauma,Bladder rupture,Machine learning,Urotrauma,Pelvic fracture",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","General & Internal Medicine,Emergency Medicine,Orthopedics,Surgery",,,"CLINICAL,PREDICTORS,INJURIES,EPIDEMIOLOGY,MANAGEMENT,MORBIDITY",INJURY-INTERNATIONAL JOURNAL OF THE CARE OF THE INJURED,,
86,Transfer Learning for Brain-Computer Interfaces: A Euclidean Space Data Alignment Approach,67,2,399-410,"He He,Wu Dongrui","He H,Wu DR",Wu DR,10.1109/TBME.2019.2913914,Huazhong University of Science & Technology,"Objective: This paper targets a major challenge in developing practical electroencephalogram (EEG)-based brain-computer interfaces (BCIs): how to cope with individual differences so that better learning performance can be obtained for a new subject, with minimum or even no subject-specific data? Methods: We propose a novel approach to align EEG trials from different subjects in the Euclidean space to make them more similar, and hence improve the learning performance for a new subject. Our approach has three desirable properties: first, it aligns the EEG trials directly in the Euclidean space, and any signal processing, feature extraction, and machine learning algorithms can then be applied to the aligned trials; second, its computational cost is very low; and third, it is unsupervised and does not need any label information from the new subject. Results: Both offline and simulated online experiments on motor imagery classification and event-related potential classification verified that our proposed approach outperformed a state-of-the-art Riemannian space data alignment approach, and several approaches without data alignment. Conclusion: The proposed Euclidean space EEG data alignment approach can greatly facilitate transfer learning in BCIs. Significance: Our proposed approach is effective, efficient, and easy to implement. It could be an essential pre-processing step for EEG-based BCIs.","Covariance matrices,Electroencephalography,Task analysis,Signal processing,Microsoft Windows,Brain-computer interfaces,Brain-computer interface,data alignment,EEG,Riemannian geometry,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"SINGLE-TRIAL,EEG,SPATIAL,FILTERS",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,http://arxiv.org/pdf/1808.05464,
87,Detection and Prediction of Ovulation From Body Temperature Measured by an In-Ear Wearable Thermometer,67,2,512-522,"Luo Lan,She Xichen,Cao Jiexuan,Zhang Yunlong,Li Yijiang,Song Peter X. K.","Luo L,She XC,Cao JX,Zhang YL,Li YJ,Song PXK",Song PXK,10.1109/TBME.2019.2916823,University of Michigan System,"Objective: We present a non-invasive wearable device for fertility monitoring and propose an effective and flexible statistical learning algorithm to detect and predict ovulation using data captured by this device. Methods: The system consists of an earpiece, which measures the ear canal temperature every 5& x00A0;min during night sleep hours, and a base station that transmits data to a smartphone application for analysis. We establish a data-cleaning protocol for data preprocessing and then fit a Hidden Markov Model (HMM) with two hidden states of high and low temperature to identify the more probable state of each time point via the predicted probabilities. Finally, a post-processing procedure is developed to incorporate biorhythm information to form a time-course biphasic profile for each subject. Results: The performance of the proposed algorithms applied to data collected by the device are compared with traditional methods in terms of match rate with self-reported ovulation days confirmed with an ovulation test kit. Empirical study results from a group of 34 users yielded significant improvements over the traditional methods in terms of detection accuracy (with sensitivity 92.31& x0025;) and prediction power (23.07-31.55& x0025; higher). Conclusion: We demonstrated the feasibility for reliable ovulation detection and prediction with high-frequency temperature data collected by a non-invasive wearable device. Significance: Traditional fertility monitoring methods are often either inaccurate or inconvenient. The wearable device and learning algorithm presented in this paper provide a user friendly and reliable platform for tracking ovulation, which may have a broad impact on both fertility research and real-world family planning.","Temperature measurement,Temperature distribution,Hidden Markov models,Biomedical monitoring,Temperature sensors,Prediction algorithms,Basal body temperature,Hidden Markov Model (HMM),prediction,ovulation,tracking data,wearable",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"TIME,FERTILITY",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
88,Hyperdimensional Computing With Local Binary Patterns: One-Shot Learning of Seizure Onset and Identification of Ictogenic Brain Regions Using Short-Time iEEG Recordings,67,2,601-613,"Burrello Alessio,Schindler Kaspar,Benini Luca,Rahimi Abbas","Burrello A,Schindler K,Benini L,Rahimi A",Burrello A,10.1109/TBME.2019.2919137,ETH Zurich,"Objective: We develop a fast learning algorithm combining symbolic dynamics and brain-inspired hyperdimensional computing for both seizure onset detection and identification of ictogenic (seizure generating) brain regions from intracranial electroencephalography (iEEG). Methods: Our algorithm first transforms iEEG time series from each electrode into symbolic local binary pattern codes, from which a holographic distributed representation of the brain state of interest is constructed across all the electrodes and over time in a hyperdimensional space. The representation is used to quickly learn from few seizures, detect their onset, and identify the spatial brain regions that generated them. Results: We assess our algorithm on our dataset that contains 99 short-time iEEG recordings from 16 drug-resistant epilepsy patients being implanted with 36-100 electrodes. For the majority of the patients (ten out of 16), our algorithm quickly learns from one or two seizures and perfectly (100%) generalizes on novel seizures using k-fold cross-validation. For the remaining six patients, the algorithm requires three to six seizures for learning. Our algorithm surpasses the state-of-the-art including deep learning algorithms by achieving higher specificity (94.84% versus 94.77%) and macroaveraging accuracy (95.42% versus 94.96%), and 74x lower memory footprint, but slightly higher average latency in detection (15.9 s versus 14.7 s). Moreover, the algorithm can reliably identify (with a p-value < 0.01) the relevant electrodes covering an ictogenic brain region at two levels of granularity: cerebral hemispheres and lobes. Conclusion and significance: Our algorithm provides: 1) a unified method for both learning and classification tasks with end-to-end binary operations; 2) one-shot learning from seizure examples; 3) linear computational scalability for increasing number of electrodes; and 4) generation of transparent codes that enables post-translational support for clinical decision making. Our source code and anonymized iEEG dataset are freely available at http://ieegswez.ethz.ch.","iEEG,one-shot learning,local binary patterns,symbolic dynamics,hyperdimensional computing,seizure detection,localization of seizure onset zone",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"FEATURE-EXTRACTION,EEG,SIGNALS,CLASSIFICATION,DYNAMICS,OUTCOMES,SURGERY",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,https://www.research-collection.ethz.ch/bitstream/20.500.11850/350002/1/iEEG_TBME2019.pdf,
89,Microplastic Identification via Holographic Imaging and Machine Learning,2,2,,"Bianco Vittorio,Memmolo Pasquale,Carcagni Pierluigi,Merola Francesco,Paturzo Melania,Distante Cosimo,Ferraro Pietro","Bianco V,Memmolo P,Carcagni P,Merola F,Paturzo M,Distante C,Ferraro P",Ferraro P,10.1002/aisy.201900153,Consiglio Nazionale delle Ricerche (CNR),"Microplastics (MPs) are a major environmental concern due to their possible impact on water pollution, wildlife, and the food chain. Reliable, rapid, and high-throughput screening of MPs from other components of a water sample after sieving and/or digestion is still a highly desirable goal to avoid cumbersome visual analysis by expert users under the optical microscope. Here, a new approach is presented that combines 3D coherent imaging with machine learning (ML) to achieve accurate and automatic detection of MPs in filtered water samples in a wide range at microscale. The water pretreatment process eliminates sediments and aggregates that fall out of the analyzed range. However, it is still necessary to clearly distinguish MPs from marine microalgae. Here, it is shown that, by defining a novel set of distinctive ""holographic features,"" it is possible to accurately identify MPs within the defined analysis range. The process is specifically tailored for characterizing the MPs' ""holographic signatures,"" thus boosting the classification performance and reaching accuracy higher than 99% in classifying thousands of items. The ML approach in conjunction with holographic coherent imaging is able to identify MPs independently from their morphology, size, and different types of plastic materials.","detection,digital holography,environmental monitoring,machine learning,microplastics",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Automation & Control Systems,Computer Science,Robotics",,,"WASTE,PARTICLES,POLLUTION,EXPOSURE",ADVANCED INTELLIGENT SYSTEMS,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/aisy.201900153,
90,,"88,","1,","9-13,",,,,"10.7775/rac.es.v88.i1.17193,",,"RESUMEN  Introduccin: Las consultas por dolor torcico son frecuentes en los servicios de emergencias mdicas (SEM). An no se ha identificado una estrategia diagnstica que utilice tanto los datos objetivos como los subjetivos del dolor.  Objetivos: Evaluar un clasificador de machine learning para predecir el riesgo de presentar un sndrome coronario agudo (SCA) sin elevacin del segmento ST, en pacientes que consultan a un SEM con dolor torcico.  Material y mtodos: Se analizaron 161 pacientes que consultaron al SEM con dolor torcico. Se registr mediante un clasificador de machine learning las variables objetivas y subjetivas de caracterizacin del dolor.  Resultados: La edad promedio fue de 57 mas/menos 12, 72,7% masculinos eran de sexo masculino y 17,4 % presentaban evento coronario previo. El 57,8% presentaba un sndrome coronario agudo con una incidencia de IAM de 29,8%, de los cuales requirieron revascularizacin por ATC el 35%, y CRM el 9,9% en el perodo de seguimiento a 30 das. Como modelo de clasificacin se utiliz un Random Forest Classifier que present un rea bajo la curva ROC de 0,8991, sensibilidad de 0,8552, especificidad de 0,8588 y una precisin de 0,8441. Las variables predictoras ms influyentes fueron peso (p = 0,002), edad (p = 5,011e-07), intensidad del dolor (p = 3,0679e-05), tensin arterial sistlica (p = 0,6068) y caractersticas subjetivas del dolor (p = 1,590e-04).  Conclusiones: Los clasificadores de machine learning son una herramienta til a fin de predecir el riesgo de sufrir un sndrome coronario agudo a 30 das de seguimiento."," ,Machine learning,; Myocardial infarction; Technology ", research-article ,,,,,,,,
91,Integrating deep convolutional neural networks with marker-controlled watershed for overlapping nuclei segmentation in histopathology images,376,,166-179,"Xie Lipeng,Qi Jin,Pan Lili,Wali Samad","Xie LP,Qi J,Pan LL,Wali S",Qi J,10.1016/j.neucom.2019.09.083,University of Electronic Science & Technology of China,"Nuclei segmentation in histopathology images plays a crucial role in the morphological quantitative analysis of tissue structure and has become a hot research topic. Though numerous efforts have been tried in this research area, the overlapping and touching nuclei segmentation remains a challenging problem. In this paper, we present a novel and effective instance segmentation method for tackling this challenge by integrating Deep Convolutional Neural Networks with Marker-controlled Watershed. Firstly, we design a novel network architecture with multiple segmentation tasks, called Deep Interval-Marker-Aware Network, for learning the foreground, marker, and interval of nuclei, simultaneously. Then the learned interval between overlapping nuclei is used to refine the foreground result of nuclei by using the logical operators. Finally, the learned marker result and the nuclei segmentation result refined by interval are transmitted into the Marker-controlled Watershed for splitting the touching nuclei. The experiments on the standard public datasets demonstrate that our method achieves a substantial improvement compared with state-of-the-art methods. Source codes are available at . https://github.com/appiek/Nuclei_Segmentation_Experiments_Demo. (C) 2019 Elsevier B.V. All rights reserved.","Histopathology images,Overlapping nuclei segmentation,Convolutional neural networks,Marker extraction,Watershed transformation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"CELL-NUCLEI,CANCER,TRACKING",NEUROCOMPUTING,,
92,A nonlinear data-driven reduced order model for computational homogenization with physics/pattern-guided sampling,359,,,"Bhattacharjee Satyaki,Matous Karel","Bhattacharjee S,Matous K",Matous K,10.1016/j.cma.2019.112657,University of Notre Dame,"Developing an accurate nonlinear reduced order model from simulation data has been an outstanding research topic for many years. For many physical systems, data collection is very expensive and the optimal data distribution is not known in advance. Thus, maximizing the information gain remains a grand challenge. In a recent paper, Bhattacharjee and Matous (2016) proposed a manifold-based nonlinear reduced order model for multiscale problems in mechanics of materials. Expanding this work here, we develop a novel sampling strategy based on the physics/pattern-guided data distribution. Our adaptive sampling strategy relies on enrichment of sub-manifolds based on the principal stretches and rotational sensitivity analysis. This novel sampling strategy substantially decreases the number of snapshots needed for accurate reduced order model construction (i.e., similar to 5x reduction of snapshots over Bhattacharjee and Matous (2016)). Moreover, we build the nonlinear manifold using the displacement rather than deformation gradient data. We provide rigorous verification and error assessment. Finally, we demonstrate both localization and homogenization of the multiscale solution on a large particulate composite unit cell. (C) 2019 Elsevier B.V. All rights reserved.","Computational homogenization,Nonlinear manifold,Reduced order model,Machine learning,Parallel computing,Big data",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Engineering,Mathematics,Mechanics",,6.828,"REDUCTION,NETWORKS,BEHAVIOR,DESIGN,ISOMAP",COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING,https://www.sciencedirect.com/science/article/am/pii/S0045782519305420,
93,Noninvasive Detection of Colorectal Carcinomas Using Serum Protein Biomarkers,246,,160-169,"Ivancic Melanie M.,Megna Bryant W.,Sverchkov Yuriy,Craven Mark,Reichelderfer Mark,Pickhardt Perry J.,Sussman Michael R.,Kennedy Gregory D.","Ivancic MM,Megna BW,Sverchkov Y,Craven M,Reichelderfer M,Pickhardt PJ,Sussman MR,Kennedy GD",Kennedy GD,10.1016/j.jss.2019.08.004,University of Alabama System,"Background: A major roadblock to reducing the mortality of colorectal cancer (CRC) is prompt detection and treatment, and a simple blood test is likely to have higher compliance than all of the current methods. The purpose of this report is to examine the utility of a mass spectrometry-based blood serum protein biomarker test for detection of CRC.
Materials and methods: Blood was drawn from individuals (n = 213) before colonoscopy or from patients with nonmetastatic CRC (n = 50) before surgery. Proteins were isolated from the serum of patients using targeted liquid chromatography-tandem mass spectrometry. We designed a machine-learning statistical model to assess these proteins.
Results: When considered individually, over 70% of the selected biomarkers showed significance by Mann-Whitney testing for distinguishing cancer-bearing cases from cancer-free cases. Using machine-learning methods, peptides derived from epidermal growth factor receptor and leucine-rich alpha-2-glycoprotein 1 were consistently identified as highly predictive for detecting CRC from cancer-free cases. A five-marker panel consisting of leucine-rich alpha-2-glycoprotein 1, epidermal growth factor receptor, inter-alpha-trypsin inhibitor heavy-chain family member 4, hemopexin, and superoxide dismutase 3 performed the best with 70% specificity at over 89% sensitivity (area under the curve = 0.86) in the validation set. For distinguishing regional from localized cancers, cross-validation within the training set showed that a panel of four proteins consisting of CD44 molecule, GC-vitamin D-binding protein, C-reactive protein, and inter-alpha-trypsin inhibitor heavy-chain family member 3 yielded the highest performance (area under the curve = 0.75).
Conclusions: The minimally invasive blood biomarker panels identified here could serve as screening/detection alternatives for CRC in a human population and potentially useful for staging of existing cancer. (C) 2019 Elsevier Inc. All rights reserved.","Colorectal neoplasms,Biomarkers,Proteomic",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA",Surgery,,2.442,"C-REACTIVE,PROTEIN,CANCER,STATISTICS,VITAMIN-D,COLONOSCOPY,PROTEOMICS,TESTS,PHASE,RISK",JOURNAL OF SURGICAL RESEARCH,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6957232,
94,Prediction of Alzheimer's disease based on deep neural network by integrating gene expression and DNA methylation dataset,140,,,"Park Chihyun,Ha Jihwan,Park Sanghyun","Park C,Ha J,Park S",Park S,10.1016/j.eswa.2019.112873,Yonsei University,"Motivation: The molecular mechanism of Alzheimer's disease (AD) has not been clearly revealed and there is no clinically reliable genetic risk factor. Therefore, diagnosis of AD has been mostly performed by analyzing brain images such as magnetic resonance imaging and neuropsychological tests. Identifying the molecular-level mechanism of AD has been lacking data owing to the difficulty of sampling in the posterior brains of normal and AD patients; however, recent studies have produced and analyzed large-scale omics data for brain areas such as prefrontal cortex. Therefore, it is necessary to develop AD diagnosis or prediction methods based on these data.
Results: This paper proposed a deep learning-based model that can predict AD using large-scale gene expression and DNA methylation data. The most challenging problem in constructing a model to diagnose AD based on the multi-omics dataset is how to integrate different omics data and how to deal with high-dimensional and low-sample-size data. To solve this problem, we proposed a novel but simple approach to reduce the number of features based on a differentially expressed gene and a differentially methylated position in the multi-omics dataset. Moreover, we developed a deep neural network-based prediction model that improves performance compared to that of conventional machine learning algorithms. The feature selection method and the prediction model presented in this paper outperformed conventional machine learning algorithms, which utilize typical dimension reduction methods. In addition, we demonstrated that integrating gene expression and DNA methylation data could improve the prediction accuracy. (C) 2019 Elsevier Ltd. All rights reserved.","Alzheimer's disease,Omics data integration,Biological feature selection,Deep neural network,Machine learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,,EXPERT SYSTEMS WITH APPLICATIONS,,
95,Predicting degradation rate of genipin cross-linked gelatin scaffolds with machine learning,107,,,"Entekhabi Elahe,Nazarpak Masoumeh Haghbin,Sedighi Mehdi,Kazemzadeh Arghavan","Entekhabi E,Nazarpak MH,Sedighi M,Kazemzadeh A",Nazarpak MH,10.1016/j.msec.2019.110362,Amirkabir University of Technology,"Genipin can improve weak mechanical properties and control high degradation rate of gelatin, as a cross-linker of gelatin which is widely used in tissue engineering. In this study, genipin cross-linked gelatin biodegradable porous scaffolds with different weight percentages of gelatin and genipin were prepared for tissue regeneration and measurement of their various properties including morphological characteristics, mechanical properties, swelling, degree of crosslinking and degradation rate. Results indicated that the sample containing the highest amount of gelatin and genipin had the highest degree of crosslinking and increasing the percentage of genipin from 0.125% to 0.5% enhances ultimate tensile strength (UTS) up to 113% and 92%, for samples with 2.5% and 10% gelatin, respectively. For these samples, increasing the percentage of genipin, reduce their degradation rate significantly with an average value of 124%. Furthermore, experimental data are used to develop a machine learning model, which compares artificial neural networks (ANN) and kernel ridge regression (KRR) to predict degradation rate of genipin-cross-linked gelatin scaffolds as a property of interest. The predicted degradation rate demonstrates that the ANN, with mean squared error (MSE) of 2.68%, outperforms the KRR with MSE = 4.78% in terms of accuracy. These results suggest that machine learning models offer an excellent prediction accuracy to estimate the degradation rate which will significantly help reducing experimental costs needed to carry out scaffold design.","Tissue engineering,Engineering scaffolds,Degradation rate,Prediction accuracy",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,6.654,"IN-VITRO,TRICALCIUM,PHOSPHATE,DESIGN,NETWORKS,DELIVERY,MICROSPHERES",MATERIALS SCIENCE & ENGINEERING C-MATERIALS FOR BIOLOGICAL APPLICATIONS,,
96,Stochastic chemo-physical-mechanical degradation analysis on hydrated cement under acidic environments,78,,75-97,"Yu Yuguo,Wu Di,Gao Wei","Yu YG,Wu D,Gao W",Gao W,10.1016/j.apm.2019.10.012,University of New South Wales Sydney,"The accumulation of material degradation under contact with aggressive aqueous environments could lead to reduced structural reliability. In terms of hydrated cementitious materials, such interactions often result in the chemo-physical-mechanical (CPM) degradation, which represents a multiphysics process of high non-linearity and complexity. By further considering the inevitable uncertainties associated with both the materials and the serving conditions, solving such a process requires novel probabilistic approaches. This paper presents a stochastic chemo-physical-mechanical (SCPM) degradation analysis on the hydrated cement under acidic environment. The SCPM analysis consists of modelling the stochastic chemophysical degradation by finite element method, and assessing the mechanical deterioration through analytical micromechanics. The proposed modelling framework couples the conventional Monte Carlo Simulation with a novel support vector regression algorithm. The present method is able to not only address the detailed degradation mechanisms, but also ensure low computational costs for an accurate SCPM degradation assessment. (C) 2019 Elsevier Inc. All rights reserved.","Accelerated leaching,Chemo-physical-mechanical analysis,Machine learning,Uncertainty quantification",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Engineering,Mathematics,Mechanics",,,"UNCERTAINTY,ANALYSIS,CALCIUM,PASTE,DETERIORATION,OPTIMIZATION,DURABILITY,EQUATION,DESIGN,MODEL",APPLIED MATHEMATICAL MODELLING,,
97,Machine learning aided static structural reliability analysis for functionally graded frame structures,78,,792-815,"Wang Qihan,Li Qingya,Wu Di,Yu Yuguo,Tin-Loi Francis,Ma Juan,Gao Wei","Wang QH,Li QY,Wu D,Yu YG,Tin-Loi F,Ma J,Gao W",Gao W,10.1016/j.apm.2019.10.007,University of New South Wales Sydney,"A novel machine learning aided structural reliability analysis for functionally graded frame structures against static loading is proposed. The uncertain system parameters, which include the material properties, dimensions of structural members, applied loads, as well as the degree of gradation of the functionally graded material (FGM), can be incorporated within a unified structural reliability analysis framework. A 3D finite element method (FEM) for static analysis of bar-type engineering structures involving FGM is presented. By extending the traditional support vector regression (SVR) method, a new kernel-based machine learning technique, namely the extended support vector regression (X-SVR), is proposed for modelling the underpinned relationship between the structural behaviours and the uncertain system inputs. The proposed structural reliability analysis inherits the advantages of the traditional sampling method (i.e., Monte-Carlo Simulation) on providing the information regarding the statistical characteristics (i.e., mean, standard deviations, probability density functions and cumulative distribution functions etc.) of any concerned structural outputs, but with significantly reduced computational efforts. Five numerical examples are investigated to illustrate the accuracy, applicability, and computational efficiency of the proposed computational scheme. (C) 2019 Elsevier Inc. All rights reserved.","Machine learning,Structural reliability analysis,Uncertainty analysis",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Engineering,Mathematics,Mechanics",,4.162,"SUPPORT,VECTOR,REGRESSION,FREE-VIBRATION,ANALYSIS,FINITE-ELEMENT,DYNAMIC-ANALYSIS,STABILITY,ANALYSIS,SYSTEM,RANDOMNESS,DESIGN,KERNEL,PLATES,FABRICATION",APPLIED MATHEMATICAL MODELLING,,
98,Machine learning to predict 30-day quality-adjusted survival in critically ill patients with cancer,55,,73-78,"dos Santos Hellen Geremias,Zampieri Fernando Godinho,Normilio-Silva Karina,da Silva Gisela Tunes,Pedroso de Lima Antonio Carlos,Cavalcanti Alexandre Biasi,Porto Chiavegatto Filho Alexandre Dias","dos Santos HG,Zampieri FG,Normilio-Silva K,da Silva GT,de Lima ACP,Cavalcanti AB,Chiavegatto ADP",dos Santos HG,10.1016/j.jcrc.2019.10.015,Fundacao Oswaldo Cruz,"Purpose: To develop and compare the predictive performance ofmachine-learning algorithms to estimate the risk of quality-adjusted life year (QALY) lower than or equal to 30 days (30-day QALY).
Material and methods: Six machine-learning algorithms were applied to predict 30-day QALY for 777 patients admitted in a prospective cohort study conducted in Intensive Care Units (ICUs) of two public Brazilian hospitals specialized in cancer care. The predictors were 37 characteristics collected at ICU admission. Discrimination was evaluated using the area under the receiver operating characteristic (AUROC) curve. Sensitivity, 1-specificity, true/false positive and negative cases were measured for different estimated probability cutoff points (30%, 20% and 10%). Calibration was evaluated with GiViTI calibration belt and test.
Results: Except for basic decision trees, the adjusted predictive models were nearly equivalent, presenting good results for discrimination (AUROC curves over 0.80). Artificial neural networks and gradient boosted trees achieved the overall best calibration, implying an accurately predicted probability for 30-day QALY.
Conclusions: Except for basic decision trees, predictive models derived from different machine-learning algorithms discriminated the QALY risk at 30 days well. Regarding calibration, artificial neural network model presented the best ability to estimate 30-day QALY in critically ill oncologic patients admitted to ICUs. (C) 2019 Published by Elsevier Inc.","Quality of life,Prognosis,Machine learning,Clinical decision-making,Intensive care unit,Critically ill patients",Article,"W B SAUNDERS CO-ELSEVIER INC, 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA",General & Internal Medicine,,3.759,"INTENSIVE-CARE,UNITS,OF-LIFE,OUTCOMES,MORTALITY,MODELS,DISEASE",JOURNAL OF CRITICAL CARE,,
99,Unbalanced breast cancer data classification using novel fitness functions in genetic programming,140,,,"Devarriya Divyaansh,Gulati Cairo,Mansharamani Vidhi,Sakalle Aditi,Bhardwaj Arpit","Devarriya D,Gulati C,Mansharamani V,Sakalle A,Bhardwaj A",Bhardwaj A,10.1016/j.eswa.2019.112866,"Bennett Univ, Comp Sci Engn Dept, Greater Noida, India.","Breast Cancer is a common disease and to prevent it, the disease must be identified at earlier stages. Available breast cancer datasets are unbalanced in nature, i.e. there are more instances of benign (non-cancerous) cases then malignant (cancerous) ones. Therefore, it is a challenging task for most machine learning (ML) models to classify between benign and malignant cases properly, even though they have high accuracy. Accuracy is not a good metric to assess the results of ML models on breast cancer dataset because of biased results. To address this issue, we use Genetic Programming (GP) and propose two fitness functions. First one is F2 score which focuses on learning more about the minority class, which contains more relevant information, the second one is a novel fitness function known as Distance score (D score) which learns about both the classes by giving them equal importance and being unbiased. The GP framework in which we implemented D score is named as D-score GP (DGP) and the framework implemented with F2 score is named as F2GP. The proposed F2GP achieved a maximum accuracy of 99.63%, 99.51% and 100% for 60-40, 70-30 partition schemes and 10 fold cross validation scheme respectively and DGP achieves a maximum accuracy of 99.63%, 98.5% and 100% in 60-40, 70-30 partition schemes and 10 fold cross validation scheme respectively. The proposed models also achieves a recall of 100% for all the test cases. This shows that using a new fitness function for unbalanced data classification improves the performance of a classifier. (C) 2019 Elsevier Ltd. All rights reserved.","Breast cancer,Unbalanced data,Genetic programming,Fitness function",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,,"DIAGNOSIS,EVOLUTION,SELECTION,NETWORK,SYSTEM",EXPERT SYSTEMS WITH APPLICATIONS,,
100,Semi-Supervised Hybrid Local Kernel Regression for Soft Sensor Modelling of Rubber-Mixing Process,2020,,,"Yu Haiqing,Ji Jun,Li Ping,Shao Fengjing,Wu Shunyao,Sui Yi,Li Shujing,He Fengjiao,Liu Jhuning","Yu HQ,Ji J,Li P,Shao FJ,Wu SY,Sui Y,Li SJ,He FJ,Liu HN",Ji J,10.1155/2020/6981302,Qingdao University,"Soft sensor techniques have been widely adopted in chemical industry to estimate important indices that cannot be online measured by hardware sensors. Unfortunately, due to the instinct time-variation, the small-sample condition and the uncertainty caused by the drifting of raw materials, it is exceedingly difficult to model the fed-batch processes, for instance, rubber internal mixing processing. Meanwhile, traditional global learning algorithms suffer from the outdated samples while online learning algorithms lack practicality since too many labelled samples of current batch are required to build the soft sensor. In this paper, semi-supervised hybrid local kernel regression (SHLKR) is presented to leverage both historical and online samples to semi-supervised model the soft sensor using proposed time-windows series. Moreover, the recursive formulas are deduced to improve its adaptability and feasibility. Additionally, the rubber Mooney soft sensor of internal mixing processing is implemented using real onsite data to validate proposed method. Compared with classical algorithms, the performance of SHLKR is evaluated and the contribution of unlabelled samples is discussed.","SUPPORT VECTOR REGRESSION,QUALITY PREDICTION,LEAST-SQUARES,SELECTION",Article,"WILEY-HINDAWI, ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND","Engineering,Polymer Science",,2.368,"SUPPORT,VECTOR,REGRESSION,QUALITY,PREDICTION,LEAST-SQUARES,SELECTION",ADVANCES IN POLYMER TECHNOLOGY,https://doi.org/10.1155/2020/6981302,
