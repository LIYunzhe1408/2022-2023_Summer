,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Combining retrosynthesis and mixed-integer optimization for minimizing the chemical inventory needed to realize a WHO essential medicines list,5,2,367-376,"Gao Hanyu,Coley Connor W.,Struble Thomas J.,Li Linyan,Qian Yujie,Green William H.,Jensen Klays F.","Gao HY,Coley CW,Struble TJ,Li LY,Qian YJ,Green WH,Jensen KF",Jensen KF,10.1039/c9re00348g,Massachusetts Institute of Technology (MIT),"The access to essential medicines remains a problem in many low-income countries for logistic and expiration limits, among other factors. Enabling flexible replenishment and easier supply chain management by on demand manufacturing from stored starting materials provides a solution to this challenge. Recent developments in computer-aided chemical synthesis planning have benefited from machine learning in different aspects. In this manuscript, we use those techniques to perform a combined analysis of a WHO essential medicines list to identify synthetic routes that minimize chemical inventory that would be required to synthesize the all the active pharmaceutical ingredients. We use a synthesis planning tool to perform retrosynthetic analyses for 99 targets and solve a mixed-integer programming problem to select a combination of pathways that uses the minimal number of chemicals. This work demonstrates the technical feasibility of reducing storage of active pharmaceutical ingredients to a minimal inventory of starting materials.","NEURAL-NETWORKS,PREDICTION,OUTCOMES,DESIGN",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Engineering",,4.502,"NEURAL-NETWORKS,PREDICTION,OUTCOMES,DESIGN",REACTION CHEMISTRY & ENGINEERING,https://pubs.rsc.org/en/content/articlepdf/2020/re/c9re00348g,
2,Unsupervised learning for characterization of Arabic online handwriting of Parkinson's disease patients,2,2,,"Aouraghe Ibtissame,Ammour Alae,Khaissidi Ghizlane,Mrabti Mostafa,Aboulem Ghita,Belahsen Faouzi","Aouraghe I,Ammour A,Khaissidi G,Mrabti M,Aboulem G,Belahsen F",Aouraghe I,10.1007/s42452-019-1923-0,Sidi Mohamed Ben Abdellah University of Fez,"In this paper, we propose to characterize the on-line handwriting for the early detection of Parkinson's disease. Thus, using kinematics, mechanical, and spatial features of handwriting, we are looking for the characterization of Parkinson's disease. This paper describes the phase of the data acquisition which is currently carried out with in the Neurological department of UHC Hassan II of Fez. Following this paper, we have proposed an approach based on unsupervised learning techniques for analyzing on-line handwriting of 34 Parkinson's disease patients and 34 Healthy Controls according to quantitative and qualitative features. Based on 230 computed features for each participant, our study has uncovered three different types of writers. The results show that the complications of fine motor abilities in Parkinson's disease patients is especially characterized by a significant degradation in handwriting kinematic features.","Online handwriting,Parkinson's disease,Principal component analysis,K-means clustering",Article,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Science & Technology - Other Topics,,,"MILD,COGNITIVE,IMPAIRMENT,DEEP,BRAIN-STIMULATION,ALZHEIMERS-DISEASE,DISCRIMINATION,MOVEMENT",SN APPLIED SCIENCES,https://link.springer.com/content/pdf/10.1007/s42452-019-1923-0.pdf,
3,Asbestos-Cement Roofing Identification Using Remote Sensing and Convolutional Neural Networks (CNNs),12,3,,"Krowczynska Malgorzata,Raczko Edwin,Staniszewska Natalia);,Wilk Ewa","Krowczynska M,Raczko E,Staniszewska N,Wilk E",Krowczynska M,10.3390/rs12030408,University of Warsaw,"Due to the pathogenic nature of asbestos, a statutory ban on asbestos-containing products has been in place in Poland since 1997. In order to protect human health and the environment, it is crucial to estimate the quantity of asbestos-cement products in use. It has been evaluated that about 90% of them are roof coverings. Different methods are used to estimate the amount of asbestos-cement products, such as the use of indicators, field inventory, remote sensing data, and multi- and hyperspectral images; the latter are used for relatively small areas. Other methods are sought for the reliable estimation of the quantity of asbestos-containing products, as well as their spatial distribution. The objective of this paper is to present the use of convolutional neural networks for the identification of asbestos-cement roofing on aerial photographs in natural color (RGB) and color infrared (CIR) compositions. The study was conducted for the Chciny commune. Aerial photographs, each with the spatial resolution of 25 cm in RGB and CIR compositions, were used, and field studies were conducted to verify data and to develop a database for Convolutional Neural Networks (CNNs) training. Network training was carried out using the TensorFlow and R-Keras libraries in the R programming environment. The classification was carried out using a convolutional neural network consisting of two convolutional blocks, a spatial dropout layer, and two blocks of fully connected perceptrons. Asbestos-cement roofing products were classified with the producer's accuracy of 89% and overall accuracy of 87% and 89%, depending on the image composition used. Attempts have been made at the identification of asbestos-cement roofing. They focus primarily on the use of hyperspectral data and multispectral imagery. The following classification algorithms were usually employed: Spectral Angle Mapper, Support Vector Machine, object classification, Spectral Feature Fitting, and decision trees. Previous studies undertaken by other researchers showed that low spectral resolution only allowed for a rough classification of roofing materials. The use of one coherent method would allow data comparison between regions. Determining the amount of asbestos-cement products in use is important for assessing environmental exposure to asbestos fibres, determining patterns of disease, and ultimately modelling potential solutions to counteract threats.","Convolutional Neural Networks,asbestos identification,image recognition,remote sensing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Geology,Remote Sensing,Imaging Science & Photographic Technology",,5.353,,REMOTE SENSING,https://www.mdpi.com/2072-4292/12/3/408/pdf,
4,Wink based facial expression classification using machine learning approach,2,2,,"Rashid Mamunur,Sulaiman Norizam,Mustafa Mahfuzah,Bari Bifta Sama,Sadeque Md Golam,Hasan Md Jahid","Rashid M,Sulaiman N,Mustafa M,Bari BS,Sadeque MG,Hasan MJ",Rashid M,10.1007/s42452-020-1963-5,Universiti Malaysia Pahang,"Facial expression may establish communication between physically disabled people and assistive devices. Different types of facial expression including eye wink, smile, eye blink, looking up and looking down can be extracted from the brain signal. In this study, the possibility of controlling assistive devices using the individual's wink has been investigated. Brain signals from the five subjects have been captured to recognize the left wink, right wink, and no wink. The brain signals have been captured using Emotiv Insight which consists of five channels. Fast Fourier transform and the sample range have been computed to extract the features. The extracted features have been classified with the help of different machine learning algorithms. Here, support vector machine (SVM), linear discriminant analysis (LDA) and K-nearest neighbor (K-NN) have been employed to classify the features sets. The performance of the classifier in terms of accuracy, confusion matrix, true positive and false positive rate and the area under curve (AUC)-receiver operating characteristics (ROC) have been evaluated. In the case of sample range, the highest training and testing accuracies are 98.9% and 96.7% respectively which have been achieved by two classifiers namely, SVM and K-NN. The achieved results indicate that the person's wink can be utilized in controlling assistive devices.","Wink,Facial expression,Electroencephalography (EEG),Brain-computer interface (BCI),Machine learning",Article,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Science & Technology - Other Topics,,,"BRAIN-COMPUTER,INTERFACES",SN APPLIED SCIENCES,https://link.springer.com/content/pdf/10.1007/s42452-020-1963-5.pdf,
5,Epileptic seizure detection on EEG signals using machine learning techniques and advanced preprocessing methods,65,1,33-50,"Mahjoub Chahira,Jeannes Regine Le Bouquin,Lajnef Tarek,Kachouri Abdennaceur","Mahjoub C,Jeannes RL,Lajnef T,Kachouri A",Mahjoub C,10.1515/bmt-2019-0001,Universite de Sfax,"Electroencephalography (EEG) is a common tool used for the detection of epileptic seizures. However, the visual analysis of long-term EEG recordings is characterized by its subjectivity, time-consuming procedure and its erroneous detection. Various epileptic seizure detection algorithms have been proposed to deal with such issues. In this study, a novel automatic seizure-detection approach is proposed. Three different strategies are suggested to the user whereby he/she could choose the appropriate one for a given classification problem. Indeed, the feature extraction step, including both linear and nonlinear measures, is performed either directly from the EEG signals, or from the derived sub-bands of tunable-Q wavelet transform (TQWT), or even from the intrinsic mode functions (IMFs) of multivariate empirical mode decomposition (MEMD). The classification procedure is executed using a support vector machine (SVM). The performance of the proposed method is evaluated through a publicly available database from which six binary classification cases are formulated to discriminate between healthy, seizure and non-seizure EEG signals. Our results show high performance in terms of accuracy (ACC), sensitivity (SEN) and specificity (SPE) compared to the state-of-the-art approaches. Thus, the proposed approach for automatic seizure detection can be considered as a valuable alternative to existing methods, able to alleviate the overload of visual analysis and accelerate the seizure detection.","electroencephalography,epilepsy,multivariate empirical mode decomposition,support vector machine,tunable-Q wavelet transform",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY","Engineering,Medical Informatics",,1.404,"EMPIRICAL,MODE,DECOMPOSITION,INVERSE,GAUSSIAN,PARAMETERS,FACTOR,WAVELET,TRANSFORM,DECISION-SUPPORT-SYSTEM,OBSTRUCTIVE,SLEEP-APNEA,AUTOMATED,IDENTIFICATION,FEATURE-EXTRACTION,BINARY,PATTERN,CLASSIFICATION,ENTROPY",BIOMEDICAL ENGINEERING-BIOMEDIZINISCHE TECHNIK,,
6,A novel approach to the diagnostic assessment of carpal tunnel syndrome based on the frequency domain of the compound muscle action potential,65,1,61-71,"Alcan Veysel,Kaya Hilal,Zinnuroglu Murat,Karatas Gulcin Kaymak,Canal Mehmet Rahmi","Alcan V,Kaya H,Zinnuroglu M,Karatas GK,Canal MR",Alcan V,10.1515/bmt-2018-0077,Tarsus University,"Conventional electrophysiological (EP) tests may yield ambiguous or false-negative results in some patients with signs and symptoms of carpal tunnel syndrome (CTS). Therefore, researchers tend to investigate new parameters to improve the sensitivity and specificity of EP tests. We aimed to investigate the mean and maximum power of the compound muscle action potential (CMAP) as a novel diagnostic parameter, by evaluating diagnosis and classification performance using the supervised Kohonen self-organizing map (SOM) network models. The CMAPs were analyzed using the fast Fourier transform (FFT). The mean and maximum power parameters were calculated from the power spectrum. A counter-propagation artificial neural network (CPANN), supervised Kohonen network (SKN) and XY-fused network (XYF) were compared to evaluate the classification and diagnostic performance of the parameters using the confusion matrix. The mean and maximum power of the CMAP were significantly lower in patients with CTS than in the normal group (p < 0.05), and the XYF network had the best total performance of classification with 91.4%. This study suggests that the mean and maximum power of the CMAP can be considered as less time-consuming parameters for the diagnosis of CTS without using additional EP tests which can be uncomfortable for the patient due to poor tolerance to electrical stimulation.","carpal tunnel syndrome,electrophysiology,Fourier analysis,neural network model",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY","Engineering,Medical Informatics",,1.404,"CONDUCTION-VELOCITY,NERVE-CONDUCTION,NEURAL-NETWORKS,CLASSIFICATION,SENSITIVITY,KOHONEN",BIOMEDICAL ENGINEERING-BIOMEDIZINISCHE TECHNIK,,
7,Label-Free Tomographic Imaging of Lipid Droplets in Foam Cells for Machine-Learning-Assisted Therapeutic Evaluation of Targeted Nanodrugs,14,2,1856-1865,"Park Sangwoo,Ahn Jae Won,Jo YoungJu,Kang Ha-Young,Kim Hyun Jung,Cheon Yeongmi,Kim Jin Won,Park YongKeun,Lee Seongsoo,Park Kyeongsoon","Park S,Ahn JW,Jo Y,Kang HY,Kim HJ,Cheon Y,Kim JW,Park Y,Lee S,Park K",Lee S,10.1021/acsnano.9b07993,Korea Basic Science Institute (KBSI),"Lipid droplet (LD) accumulation, a key feature of foam cells, constitutes an attractive target for therapeutic intervention in atherosclerosis. However, despite advances in cellular imaging techniques, current noninvasive and quantitative methods have limited application in living foam cells. Here, using optical diffraction tomography (ODT), we performed quantitative morphological and biophysical analysis of living foam cells in a label-free manner. We identified LDs in foam cells by verifying the specific refractive index using correlative imaging comprising ODT integrated with three-dimensional fluorescence imaging. Through time-lapse monitoring of three-dimensional dynamics of label-free living foam cells, we precisely and quantitatively evaluated the therapeutic effects of a nanodrug (mannose-polyethylene glycol-glycol chitosan-fluorescein isothiocyanate-lobeglitazone; MMR-Lobe) designed to affect the targeted delivery of lobeglitazone to foam cells based on high mannose receptor specificity. Furthermore, by exploiting machine-learning-based image analysis, we further demonstrated therapeutic evaluation at the single-cell level. These findings suggest that refractive index measurement is a promising tool to explore new drugs against LD-related metabolic diseases.","atherosclerosis,foam cell,lipid droplet,3-D holotomography,refractive index,machine learning",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,16.207,"REFRACTIVE-INDEX,RAMAN-SPECTROSCOPY,PPAR-ALPHA,ATHEROSCLEROSIS,MICE,SEGMENTATION,ACCUMULATION,MECHANISMS,REDUCTION,NUCLEI",ACS NANO,,
8,Thermal-wet model of knitted double jersey based on backpropagation algorithm of neural network,15,,,"Li Xintong,Cong Honglian,Gao Zhe,Dong Zhijia","Li XT,Cong HL,Gao Z,Dong ZJ",Cong HL,10.1177/1558925019900837,Jiangnan University,"In this article, thermal resistance test and water vapor resistance test were experimented to obtain data of heat and humidity performance. Canonical correlation analysis was used on determining influence of basic fabric parameters on heat and humidity performance. Thermal resistance model and water vapor resistance model were established with a three-layered feedforward-type neural network. For the generalization of the network and the difficulty of determining the optimal network structure, trainbr was chosen as training algorithm to find the relationship between input factors and output data. After training and verification, the number of hidden layer neurons in the thermal resistance model was 12, and the error reached 10(-3). In the water vapor resistance model, the number of hidden layer neurons was 10, and the error reached 10(-3).","Knitted double jersey,thermal comfort,canonical correlation analysis,artificial neural network",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Materials Science,,1.516,"WATER-VAPOR,PERMEABILITY,FABRICS,COTTON,AIR",JOURNAL OF ENGINEERED FIBERS AND FABRICS,https://journals.sagepub.com/doi/pdf/10.1177/1558925019900837,
9,Biodiesel synthesis from Ceiba pentandra oil by microwave irradiation-assisted transesterification: ELM modeling and optimization,146,,1278-1291,"Silitonga A. S.,Shamsuddin A. H.,Mahlia T. M. I,Milano Jassinne,Kusumo F.,Siswantoro Joko,Dharma S.,Sebayang A. H.,Masjuki H. H.,Ong Hwai Chyuan","Silitonga AS,Shamsuddin AH,Mahlia TMI,Milano J,Kusumo F,Siswantoro J,Dharma S,Sebayang AH,Masjuki HH,Ong HC",Silitonga AS,10.1016/j.renene.2019.07.065,State Polytechnic of Medan,"In this study, microwave irradiation-assisted transesterification was used to produce Ceiba pentandra biodiesel, which accelerates the rate of reaction and temperature within a shorter period. The improvement of biodiesel production requires a reliable model that accurately reflects the effects of input variables on output variables. In this study, an extreme learning machine integrated with cuckoo search algorithm was developed to predict and optimize the process parameters. This model will be useful for virtual experimentations in order to enhance biodiesel research and development. The optimum parameters of the microwave irradiation-assisted transesterification process conditions were obtained as follows: (1) methanol/oil ratio: 60%, (2) potassium hydroxide catalyst concentration: 0.84%(w/w), (3) stirring speed: 800 rpm, and (4) reaction time: 388 s. The corresponding Ceiba pentandra biodiesel yield was 96.19%. Three independent experiments were conducted using the optimum process parameters and the average biodiesel yield was found to be 95.42%. In conclusion, microwave irradiation-assisted transesterification is an effective method for biodiesel production because it is more energy-efficient, which will reduce the overall cost of biodiesel production. (C) 2019 Elsevier Ltd. All rights reserved.","Ceiba pentandra biodiesel,Extreme learning machine,Cuckoo search algorithm,Microwave irradiation-assisted transesterification,Alternative fuel",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Science & Technology - Other Topics,Energy & Fuels",,7.435,"EXTREME,LEARNING-MACHINE,WASTE,COOKING,OIL,RESPONSE-SURFACE,METHODOLOGY,CALOPHYLLUM-INOPHYLLUM,OIL,ARTIFICIAL,NEURAL-NETWORKS,ENGINE,PERFORMANCE,OXIDATIVE,STABILITY,EMISSION,CHARACTERISTICS,PROCESS,PARAMETERS,DIESEL,BLENDS",RENEWABLE ENERGY,,
10,Comment on ,5,2,589-591,"Hattrick-Simpers Jason,DeCost Brian","Hattrick-Simpers J,DeCost B",DeCost B,10.1039/c9me00138g,National Institute of Standards & Technology (NIST) - USA,"In this short comment we present a reproducibility study for our recent manuscript ""A simple constrained machine learning model for predicting high-pressure-hydrogen-compressor materials"" by Hattrick-Simpers, et al., Mol. Syst. Des. Eng., 2018, 3, 509"" using a suite of open source materials data science tools. The principal goal of this study is to provide the interested reader the ability to reproduce our previous machine learning model with minimal effort and then perform predictions upon the holdout set used in that manuscript. In transcribing our model from the Java-based Magpie/Weka framework to the Python-based Matminer/scikit-learn framework we noticed an unexpected discrepancy in the predictions between the two platforms. To compare the performance of nominally equivalent random forest regression models across these two platforms, we trained and evaluated 50 replicate models for each platform using random 90% subsets of the full hydride training set for each replicate. The Magpie/Weka models showed somewhat higher predicted mean absolute error (5.6 +/- 0.4) than the Matminer/scikit-learn models (4.2 +/- 0.4) on the holdout set, although the validation statistics were within error of one another. It is beyond the scope of this comment to fully analyze the ultimate source of the variance in these predictions, but we speculate that some contribution results from differences in how Magpie treats duplicate compositions in the training set and/or differences in RF implementation between Weka and scikit-learn.
Design, System, Application Using machine learning techniques to predict chemistries of materials with novel properties has been of great interest to the materials community over the past few years. Unfortunately, many of these approaches will predict the figure of merit for any combination of materials with no insight as to the potential stability of the material or its engineering feasibility. While evaluation of material stability can be challenging, the application of techno-economic constraints to materials design is relatively straightforward and can be implemented early in the prediction process. In this manuscript, we used a free open source materials machine learning platform on a free open source experimental database to generate thousands of new alloy combinations with favorable enthalpies of formation for high pressure compressors. We then whittled down our list of potential alloys using a series of engineering constraints such as enthalpy values, cost, and simple stoichiometric rules. This enabled us to focus our stability check to the Fe-Mn-Ti-X system. Comparison of the Fe-Mn-Ti to CALPHAD, previous experimental studies, and multiple DFT studies resulted in contradictory predictions of stability indicating that it is a system with the potential to provide insights to materials scientists and engineers. This time we provided the code to run the machine learning model.",,Editorial Material,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Engineering,Science & Technology - Other Topics,Materials Science",,4.667,,MOLECULAR SYSTEMS DESIGN & ENGINEERING,,
11,Quantitative scoring of epithelial and mesenchymal qualities of cancer cells using machine learning and quantitative phase imaging,25,2,,"Lam Van K.,Thanh Nguyen,Vy Bui,Byung Min Chung,Chang Lin-Ching,Nehmetallah George,Raub Christopher B.","Lam VK,Nguyen T,Bui V,Chung BM,Chang LC,Nehmetallah G,Raub CB",Raub CB,10.1117/1.JBO.25.2.026002,Catholic University of America,"Significance: We introduce an application of machine learning trained on optical phase features of epithelial and mesenchymal cells to grade cancer cells' morphologies, relevant to evaluation of cancer phenotype in screening assays and clinical biopsies.
Aim: Our objective was to determine quantitative epithelial and mesenchymal qualities of breast cancer cells through an unbiased, generalizable, and linear score covering the range of observed morphologies.
Approach: Digital holographic microscopy was used to generate phase height maps of noncancerous epithelial (Gie-No3B11) and fibroblast (human gingival) cell lines, as well as MDA-MB-231 and MCF-7 breast cancer cell lines. Several machine learning algorithms were evaluated as binary classifiers of the noncancerous cells that graded the cancer cells by transfer learning.
Results: Epithelial and mesenchymal cells were classified with 96% to 100% accuracy. Breast cancer cells had scores in between the noncancer scores, indicating both epithelial and mesenchymal morphological qualities. The MCF-7 cells skewed toward epithelial scores, while MDA-MB-231 cells skewed toward mesenchymal scores. Linear support vector machines (SVMs) produced the most distinct score distributions for each cell line.
Conclusions: The proposed epithelial-mesenchymal score, derived from linear SVM learning, is a sensitive and quantitative approach for detecting epithelial and mesenchymal characteristics of unknown cells based on well-characterized cell lines. We establish a framework for rapid and accurate morphological evaluation of single cells and subtle phenotypic shifts in imaged cell populations. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","holography,quantitative phase,machine learning,epithelial,mesenchymal,cancer cells,support vector machine",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,"DIGITAL,HOLOGRAPHIC,MICROSCOPY,BREAST-CANCER,GINGIVAL,FIBROBLASTS,LINE,MORPHOLOGY,CLASSIFICATION,TRANSITION,SIGNATURES",JOURNAL OF BIOMEDICAL OPTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7026523,
12,Entropy-Based Measures of Hypnopompic Heart Rate Variability Contribute to the Automatic Prediction of Cardiovascular Events,22,2,,"Yan Xueya,Zhang Lulu,Li Jinlian,Du Ding,Hou Fengzhen","Yan XY,Zhang LL,Li JL,Du D,Hou FZ",Hou FZ,10.3390/e22020241,China Pharmaceutical University,"Surges in sympathetic activity should be a major contributor to the frequent occurrence of cardiovascular events towards the end of nocturnal sleep. We aimed to investigate whether the analysis of hypnopompic heart rate variability (HRV) could assist in the prediction of cardiovascular disease (CVD). 2217 baseline CVD-free subjects were identified and divided into CVD group and non-CVD group, according to the presence of CVD during a follow-up visit. HRV measures derived from time domain analysis, frequency domain analysis and nonlinear analysis were employed to characterize cardiac functioning. Machine learning models for both long-term and short-term CVD prediction were then constructed, based on hypnopompic HRV metrics and other typical CVD risk factors. CVD was associated with significant alterations in hypnopompic HRV. An accuracy of 81.4% was achieved in short-term prediction of CVD, demonstrating a 10.7% increase compared with long-term prediction. There was a decline of more than 6% in the predictive performance of short-term CVD outcomes without HRV metrics. The complexity of hypnopompic HRV, measured by entropy-based indices, contributed considerably to the prediction and achieved greater importance in the proposed models than conventional HRV measures. Our findings suggest that Hypnopompic HRV assists the prediction of CVD outcomes, especially the occurrence of CVD event within two years.","heart rate variability,cardiovascular disease,sleep,machine learning,XGBoost",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,2.587,"BODY-MASS,INDEX,SLEEP,RISK,MORTALITY,DEPRESSION,PRESSURE,FAILURE,DISEASE",ENTROPY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7516674,
13,A Novel Bio-Inspired Deep Learning Approach for Liver Cancer Diagnosis,11,2,,Ghoniem Rania M.,Ghoniem RM,Ghoniem RM,10.3390/info11020080,Princess Nourah bint Abdulrahman University,"Current research on computer-aided diagnosis (CAD) of liver cancer is based on traditional feature engineering methods, which have several drawbacks including redundant features and high computational cost. Recent deep learning models overcome these problems by implicitly capturing intricate structures from large-scale medical image data. However, they are still affected by network hyperparameters and topology. Hence, the state of the art in this area can be further optimized by integrating bio-inspired concepts into deep learning models. This work proposes a novel bio-inspired deep learning approach for optimizing predictive results of liver cancer. This approach contributes to the literature in two ways. Firstly, a novel hybrid segmentation algorithm is proposed to extract liver lesions from computed tomography (CT) images using SegNet network, UNet network, and artificial bee colony optimization (ABC), namely, SegNet-UNet-ABC. This algorithm uses the SegNet for separating liver from the abdominal CT scan, then the UNet is used to extract lesions from the liver. In parallel, the ABC algorithm is hybridized with each network to tune its hyperparameters, as they highly affect the segmentation performance. Secondly, a hybrid algorithm of the LeNet-5 model and ABC algorithm, namely, LeNet-5/ABC, is proposed as feature extractor and classifier of liver lesions. The LeNet-5/ABC algorithm uses the ABC to select the optimal topology for constructing the LeNet-5 network, as network structure affects learning time and classification accuracy. For assessing performance of the two proposed algorithms, comparisons have been made to the state-of-the-art algorithms on liver lesion segmentation and classification. The results reveal that the SegNet-UNet-ABC is superior to other compared algorithms regarding Jaccard index, Dice index, correlation coefficient, and convergence time. Moreover, the LeNet-5/ABC algorithm outperforms other algorithms regarding specificity, F1-score, accuracy, and computational time.","deep learning,bio-inspired optimization,SegNet,UNet,LeNet-5,artificial bee colony",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"CONVOLUTIONAL,NEURAL-NETWORKS,COMPUTER-AIDED,DIAGNOSIS,FUZZY,C-MEANS,HEURISTIC,OPTIMIZATION,CLASSIFICATION,SYSTEM,SEGMENTATION,RECOGNITION,ALGORITHM,SELECTION",INFORMATION,https://www.mdpi.com/2078-2489/11/2/80/pdf,
14,Non-Newtonian fluid flow dynamics in rotating annular media: Physics-based and data-driven modeling,185,,,"Ershadnia Reza,Amooie Mohammad Amin,Shams Reza,Hajirezaie Sassan,Liu Yuanhong,Jamshidi Saeid,Soltanian Mohamad Reza","Ershadnia R,Amooie MA,Shams R,Hajirezaie S,Liu YH,Jamshidi S,Soltanian MR",Amooie MA,10.1016/j.petrol.2019.106641,Massachusetts Institute of Technology (MIT),"A thorough understanding and accurate prediction of non-Newtonian fluid flow dynamics in rotating annular media are of paramount importance to numerous engineering applications. This is in particular relevant to oil and gas industry where this type of flow could occur during, e.g., drilling, well completion, and enhanced oil recovery scenarios. Here, mathematically we report on physical-based (numerical) and data-driven (intelligent) modeling of three-dimensional laminar flow of non-Newtonian fluids driven by axial pressure gradient in annular media that consist of a coaxially rotating inner cylinder. We focus on the dynamics of pressure loss ratio (PLR)-the ratio of total pressure loss in presence of rotation to that in stationary condition. We develop a novel and computationally efficient machine-learning based predictive model based on a Least Square Support Vector Machine (LSSVM) optimized with a Coupled Simulated Annealing (CSA) algorithm, which is trained and tested by 730 experimental data collected for this study. We then perform numerous CFD simulations governed by Navier-Stokes set of equations, which correspond to each of the experimental cases. Comparing the results with those obtained from a widely used empirical correlation for PLR, we find that the both of our numerical and machine-learning based models are more accurate and present a larger applicability domain. The predictive LSSVM model enjoys a supervised learning paradigm and leads to the highest accuracy, while the physically originated CFD approach captures more consistently the nonlinear behavior of PLR versus key system features. Following the validation of our models, we study the less understood effects of fluid viscosity, axial velocity and rotational velocity on PLR dynamics. We employ a dimensionless parameter analogous to Strouhal number and identify specific regimes where PLR shows a distinct behavior. Our study elucidates the role of shear-thinning effect and its interplay with inertial forces on the dynamical behavior of pressure loss (ratio) in rotating yield-power-law fluids.","Pressure loss ratio,Non-Newtonian fluid,CFD,LSSVM,Rotating Couette flow",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Energy & Fuels,Engineering",,4.376,"SHEAR-THINNING,FLUIDS,LAMINAR-FLOW,ECCENTRIC,ANNULI,STROUHAL,NUMBERS,PRESSURE,LOSSES,OIL,CYLINDER,CFD,OPTIMIZATION,TRANSPORT",JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING,,
15,Regularized siamese neural network for unsupervised outlier detection on brain multiparametric magnetic resonance imaging: Application to epilepsy lesion screening,60,,,"Alaverdyan Zaruhi,Jung Julien,Bouet Romain,Lartizien Carole","Alaverdyan Z,Jung JL,Bouet R,Lartizien C",Lartizien C,10.1016/j.media.2019.101618,Centre National de la Recherche Scientifique (CNRS),"In this study, we propose a novel anomaly detection model targeting subtle brain lesions in multiparametric MRI. To compensate for the lack of annotated data adequately sampling the heterogeneity of such pathologies, we cast this problem as an outlier detection problem and introduce a novel configuration of unsupervised deep siamese networks to learn normal brain representations using a series of non-pathological brain scans. The proposed siamese network, composed of stacked convolutional autoencoders as subnetworks is designed to map patches extracted from healthy control scans only and centered at the same spatial localization to 'close' representations with respect to the chosen metric in a latent space. It is based on a novel loss function combining a similarity term and a regularization term compensating for the lack of dissimilar pairs. These latent representations are then fed into oc-SVM models at voxel-level to produce anomaly score maps. We evaluate the performance of our brain anomaly detection model to detect subtle epilepsy lesions in multiparametric (T1-weighted, FLAIR) MRI exams considered as normal (MRI-negative). Our detection model trained on 75 healthy subjects and validated on 21 epilepsy patients (with 18 MRI-negatives) achieves a maximum sensitivity of 61% on the MRI-negative lesions, identified among the 5 most suspicious detections on average. It is shown to outperform detection models based on the same architecture but with stacked convolutional or Wasserstein autoencoders as unsupervised feature extraction mechanisms. (C) 2019 Elsevier B.V. All rights reserved.","Regularized siamese network,Wasserstein autoencoder,Unsupervised representation learning,Brain lesions,Anomaly detection,Deep learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"FOCAL,CORTICAL,DYSPLASIA,IMPROVES,DETECTION,MRI,SURGERY,MALFORMATIONS,SEGMENTATION,OUTCOMES,ATLAS",MEDICAL IMAGE ANALYSIS,https://hal.archives-ouvertes.fr/hal-02995591/document,
16,Siam-U-Net: encoder-decoder siamese network for knee cartilage tracking in ultrasound images,60,,,"Dunnhofer Matteo,Antico Maria,Sasazawa Fumio,Takeda Yu,Camps Saskia,Martinel Niki,Micheloni Christian,Carneiro Gustavo,Fontanarosa Davide","Dunnhofer M,Antico M,Sasazawa F,Takeda Y,Camps S,Martinel N,Micheloni C,Carneiro G,Fontanarosa D",Dunnhofer M,10.1016/j.media.2019.101631,University of Udine,"The tracking of the knee femoral condyle cartilage during ultrasound-guided minimally invasive procedures is important to avoid damaging this structure during such interventions. In this study, we propose a new deep learning method to track, accurately and efficiently, the femoral condyle cartilage in ultrasound sequences, which were acquired under several clinical conditions, mimicking realistic surgical setups. Our solution, that we name Siam-U-Net, requires minimal user initialization and combines a deep learning segmentation method with a siamese framework for tracking the cartilage in temporal and spatio-temporal sequences of 2D ultrasound images. Through extensive performance validation given by the Dice Similarity Coefficient, we demonstrate that our algorithm is able to track the femoral condyle cartilage with an accuracy which is comparable to experienced surgeons. It is additionally shown that the proposed method outperforms state-of-the-art segmentation models and trackers in the localization of the cartilage. We claim that the proposed solution has the potential for ultrasound guidance in minimally invasive knee procedures. Crown Copyright (C) 2019 Published by Elsevier B.V. All rights reserved.","Knee arthroscopy,Knee cartilage,Ultrasound,Ultrasound guidance,Visual tracking,Fully convolutional siamese networks,Deep learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,SEGMENTATION,MEDICAL IMAGE ANALYSIS,,
17,Multi-resolution convolutional neural networks for fully automated segmentation of acutely injured lungs in multiple species,60,,,"Gerard Sarah E.,Herrmann Jacob,Kaczka David W.,Musch Guido,Fernandez-Bustamante Ana,Reinhardt Joseph M.","Gerard SE,Herrmann J,Kaczka DW,Musch G,Fernandez-Bustamante A,Reinhardt JM",Reinhardt JM,10.1016/j.media.2019.101592,University of Iowa,"Segmentation of lungs with acute respiratory distress syndrome (ARDS) is a challenging task due to diffuse opacification in dependent regions which results in little to no contrast at the lung boundary. For segmentation of severely injured lungs, local intensity and texture information, as well as global contextual information, are important factors for consistent inclusion of intrapulmonary structures. In this study, we propose a deep learning framework which uses a novel multi-resolution convolutional neural network (ConvNet) for automated segmentation of lungs in multiple mammalian species with injury models similar to ARDS. The multi-resolution model eliminates the need to tradeoffbetween high-resolution and global context by using a cascade of low-resolution to high-resolution networks. Transfer learning is used to accommodate the limited number of training datasets. The model was initially pre-trained on human CT images, and subsequently fine-tuned on canine, porcine, and ovine CT images with lung injuries similar to ARDS. The multi-resolution model was compared to both high-resolution and low-resolution networks alone. The multi-resolution model outperformed both the low- and high-resolution models, achieving an overall mean Jacaard index of 0.963 +/- 0.025 compared to 0.919 +/- 0.027 and 0.950 +/- 0.036, respectively, for the animal dataset (N = 287). The multi-resolution model achieves an overall average symmetric surface distance of 0.438 +/- 0.315 mm, compared to 0.971 +/- 0.368 mm and 0.657 +/- 0.519 mm for the low-resolution and high-resolution models, respectively. We conclude that the multi-resolution model produces accurate segmentations in severely injured lungs, which is attributed to the inclusion of both local and global features. (C) 2019 Elsevier B.V. All rights reserved.","Computed tomography,Segmentation,Deep learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"QUANTITATIVE,COMPUTED-TOMOGRAPHY,END-EXPIRATORY,PRESSURE,CT,ACETYLCYSTEINE,CLASSIFICATION,STRAIN,CANCER,IMAGES,MODEL,SCANS",MEDICAL IMAGE ANALYSIS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6980773,
18,Multi-modal neuroimaging feature selection with consistent metric constraint for diagnosis of Alzheimer's disease,60,,,"Hao Xiaoke,Bao Yongjin,Guo Yingchun,Yu Ming,Zhang Daoqiang,Risacher Shannon L.,Saykin Andrew J.,Yao Xiaohui,Shen Li","Hao XK,Bao YJ,Guo YC,Yu M,Zhang DQ,Risacher SL,Saykin AJ,Yao XH,Shen L",Guo YC,10.1016/j.media.2019.101625,Hebei University of Technology,"The accurate diagnosis of Alzheimer's disease (AD) and its early stage, e.g., mild cognitive impairment (MCI), is essential for timely treatment or possible intervention to slow down AD progression. Recent studies have demonstrated that multiple neuroimaging and biological measures contain complementary information for diagnosis and prognosis. Therefore, information fusion strategies with multi-modal neuroimaging data, such as voxel-based measures extracted from structural MRI (VBM-MRI) and fluorodeoxyglucose positron emission tomography (FDG-PET), have shown their effectiveness for AD diagnosis. However, most existing methods are proposed to simply integrate the multi-modal data, but do not make full use of structure information across the different modalities. In this paper, we propose a novel multi-modal neuroimaging feature selection method with consistent metric constraint (MFCC) for AD analysis. First, the similarity is calculated for each modality (i.e. VBM-MRI or FDG-PET) individually by random forest strategy, which can extract pairwise similarity measures for multiple modalities. Then the group sparsity regularization term and the sample similarity constraint regularization term are used to constrain the objective function to conduct feature selection from multiple modalities. Finally, the multi-kernel support vector machine (MK-SVM) is used to fuse the features selected from different models for final classification. The experimental results on the Alzheimer's Disease Neuroimaging Initiative (ADNI) show that the proposed method has better classification performance than the startof-the-art multimodality-based methods. Specifically, we achieved higher accuracy and area under the curve (AUC) for AD versus normal controls (NC), MCI versus NC, and MCI converters (MCI-C) versus MCI non-converters (MCI-NC) on ADNI datasets. Therefore, the proposed model not only outperforms the traditional method in terms of AD/MCI classification, but also discovers the characteristics associated with the disease, demonstrating its promise for improving disease-related mechanistic understanding. (C) 2019 Elsevier B.V. All rights reserved.","Similarity measures,Multi-modal neuroimaging,Feature selection,Alzheimer's disease,Mild cognitive impairment",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"MILD,COGNITIVE,IMPAIRMENT,FEATURE,REPRESENTATION,CLASSIFICATION,MRI,MEMORY,SEGMENTATION,MORPHOMETRY,BIOMARKERS,FUSION,MODEL",MEDICAL IMAGE ANALYSIS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6980345,
19,Joint functional brain network atlas estimation and feature selection for neurological disorder diagnosis with application to autism,60,,,"Mhiri Islem,Rekik Islem","Mhiri I,Rekik I",Rekik I,10.1016/j.media.2019.101596,Istanbul Technical University,"Image-based brain maps, generally coined as `intensity or image atlases', have led the field of brain mapping in health and disease for decades, while investigating a wide spectrum of neurological disorders. Estimating representative brain atlases constitute a fundamental step in several MRI-based neurological disorder mapping, diagnosis, and prognosis. However, these are strikingly lacking in the field of brain connectomics, where connectional brain atlases derived from functional MRI (fRMI) or diffusion MRI (dMRI) are almost absent. On the other hand, conventional connectomic-based classification methods traditionally resort to feature selection methods to decrease the high-dimensionality of connectomic data for learning how to diagnose new patients. However, these are generally limited by high computational cost and a large variability in performance across different datasets, which might hinder the identification of reproducible biomarkers. To address both limitations, we unprecedentedly propose a brain network atlas-guided feature selection (NAG-FS) method to disentangle the healthy from the disordered connectome. To this aim, given a population of brain connectomes, we propose to learn how estimate a centered and representative functional brain network atlas (i.e., a population center) to reliably map the functional connectome and its variability across training individuals, thereby capturing their shared traits (i.e., connectional fingerprint of a population). Essentially, we first learn the pairwise similarities between connectomes in the population to map them into different subspaces. Next, we non-linearly diffuse and fuse connectomes living in each subspace, respectively. By integrating the produced subspace-specific network atlases we ultimately estimate the population network atlas. Last, we compute the difference between healthy and disordered network atlases to identify the most discriminative features, which are then used to train a predictive learner. Our method boosted the classification performance by 6% in comparison to state-of-the-art FS methods when classifying autistic and healthy subjects. (C) 2019 Elsevier B.V. All rights reserved.","Functional network atlas estimation,Brain network fusion,Connectomic feature selection,Multi-kernel network manifold learning,Discriminative biomarker identification,Brain connectome,Autism spectrum disorder,Classification",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"SPECTRUM,DISORDERS,IMAGE,REGISTRATION,FRONTAL-LOBE,CHILDREN,CLASSIFICATION,CONNECTIVITY,PREDICTION",MEDICAL IMAGE ANALYSIS,https://discovery.dundee.ac.uk/ws/files/40201504/Mhirietal.2019MEDIAaccepted.pdf,
20,Automatic kidney segmentation in ultrasound images using subsequent boundary distance regression and pixelwise classification networks,60,,,"Yin Shi,Peng Qinmu,Li Hongming,Zhang Zhengqiang,You Xinge,Fischer Katherine,Furth Susan L.,Tasian Gregory E.,Fan Yong","Yin S,Peng QM,Li HM,Zhang ZQ,You XG,Fischer K,Furth SL,Tasian GE,Fan Y",Peng QM,10.1016/j.media.2019.101602,Huazhong University of Science & Technology,"It remains challenging to automatically segment kidneys in clinical ultrasound (US) images due to the kidneys' varied shapes and image intensity distributions, although semi-automatic methods have achieved promising performance. In this study, we propose subsequent boundary distance regression and pixel classification networks to segment the kidneys automatically. Particularly, we first use deep neural networks pre-trained for classification of natural images to extract high-level image features from US images. These features are used as input to learn kidney boundary distance maps using a boundary distance regression network and the predicted boundary distance maps are classified as kidney pixels or non-kidney pixels using a pixelwise classification network in an end-to-end learning fashion. We also adopted a data-augmentation method based on kidney shape registration to generate enriched training data from a small number of US images with manually segmented kidney labels. Experimental results have demonstrated that our method could automatically segment the kidney with promising performance, significantly better than deep learning-based pixel classification networks. (C) 2019 Elsevier B.V. All rights reserved.","Ultrasound images,Boundary detection,Boundary distance regression,Pixelwise classification",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,,MEDICAL IMAGE ANALYSIS,https://europepmc.org/articles/pmc6980346?pdf=render,
21,Multi-indices quantification of optic nerve head in fundus image via multitask collaborative learning,60,,,"Zhao Rongchang,Li Shuo","Zhao RC,Li S",Li S,10.1016/j.media.2019.101593,Western University (University of Western Ontario),"Multi-indices quantification of optic nerve head (ONH), measuring ONH appearance with multiple types of indices simultaneously from fundus images, is the most clinically significant tasks for accurate ONH assessment and ophthalmic disease diagnosis. However, no attempt has been reported due to its challenges of the large variation of fundus appearance across patients, heavy overlap and extremely weak contrast between optic nerve head areas. In this paper, we propose a multitask collaborative learning framework (MCL-Net) for multi-indices ONH quantification. The proposed MCL-Net, a two-branch neural network, first obtains expressive shared and task-specific representations with the backbone network and its two branches; then models the feature exchanges and aggregations between two branches with a well-designed feature interaction module (FIM) to promote each other collaboratively. After that, it estimates multiple types of ONH indices under a multitask ensemble module (MEM) that is capable of learning aggregation of multiple outputs automatically. Therefore, the proposed MCL-Net is consisted of the feature representation, inter-task feature interaction, dual-branch task-specific prediction, and multitask quantification ensemble, which establish an effective framework which takes full advantages of segmentation and estimation tasks for multi-indices ONH quantification. Rather than the low-level feature sharing and individual prediction, the proposed MCL-Net collaboratively learns an optimal combination of shared and task-specific representation, as well as the aggregated prediction, therefore leads to accurate quantification of ONH with multiple types of indices.
Experimental results on the dataset of 650 fundus images show that MCL-Net successfully delivers accurate quantification of all the three types of ONH indices, with average mean absolute error of 0.98 +/- 0.20, 0.97 +/- 0.16, 1.19 +/- 0.18, as well as average correlation coefficient of 0.699, 0.708 and 0.691, for diameters, whole areas and regional areas, respectively. In addition, the experiments demonstrate that quantitative indices obtained by our method provide more effective glaucoma diagnosis with AUC of 0.8698. This endows our proposed MCL-Net a great potential in clinical assessment from focal to global for ophthalmic disease diagnosis. (C) 2019 Elsevier B.V. All rights reserved.","Multi-indices quantification,Optic nerve head assessment,Collaborative learning,Glaucoma diagnosis",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"CUP,SEGMENTATION,DISC",MEDICAL IMAGE ANALYSIS,,
22,Multi-modal latent space inducing ensemble SVM classifier for early dementia diagnosis with neuroimaging data,60,,,"Zhou Tao,Thung Kim-Han,Liu Mingxia,Shi Feng,Zhang Changqing,Shen Dinggang","Zhou T,Thung KH,Liu MX,Shi F,Zhang CQ,Shen DG",Shen DG,10.1016/j.media.2019.101630,University of North Carolina,"Fusing multi-modality data is crucial for accurate identification of brain disorder as different modalities can provide complementary perspectives of complex neurodegenerative disease. However, there are at least four common issues associated with the existing fusion methods. First, many existing fusion methods simply concatenate features from each modality without considering the correlations among different modalities. Second, most existing methods often make prediction based on a single classifier, which might not be able to address the heterogeneity of the Alzheimer's disease (AD) progression. Third, many existing methods often employ feature selection (or reduction) and classifier training in two independent steps, without considering the fact that the two pipelined steps are highly related to each other. Forth, there are missing neuroimaging data for some of the participants (e.g., missing PET data), due to the participants' ""no-show"" or dropout. In this paper, to address the above issues, we propose an early AD diagnosis framework via novel multi-modality latent space inducing ensemble SVM classifier. Specifically, we first project the neuroimaging data from different modalities into a latent space, and then map the learned latent representations into the label space to learn multiple diversified classifiers. Finally, we obtain the more reliable classification results by using an ensemble strategy. More importantly, we present a Complete Multi-modality Latent Space (CMLS) learning model for complete multi-modality data and also an Incomplete Multi-modality Latent Space (IMLS) learning model for incomplete multi-modality data. Extensive experiments using the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset have demonstrated that our proposed models outperform other state-of-the-art methods. (C) 2020 Elsevier B.V. All rights reserved.","Alzheimer's disease (AD),Multi-modality data,Missing modality,Latent space,Multiple diversified classifiers",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"MILD,COGNITIVE,IMPAIRMENT,ALZHEIMERS-DISEASE,DIAGNOSIS,FEATURE-SELECTION,BRAIN,ATROPHY,MR-IMAGES,SEGMENTATION,CONVERSION",MEDICAL IMAGE ANALYSIS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8260095,
23,Deep learning robotic guidance for autonomous vascular access,2,2,104-+,"Chen Alvin I.,Balter Max L.,Maguire Timothy J.,Yarmush Martin L.","Chen AI,Balter ML,Maguire TJ,Yarmush ML",Chen AI,10.1038/s42256-020-0148-7,Rutgers State University New Brunswick,"Medical robots have demonstrated the ability to manipulate percutaneous instruments into soft tissue anatomy while working beyond the limits of human perception and dexterity. Robotic technologies further offer the promise of autonomy in carrying out critical tasks with minimal supervision when resources are limited. Here, we present a portable robotic device capable of introducing needles and catheters into deformable tissues such as blood vessels to draw blood or deliver fluids autonomously. Robotic cannulation is driven by predictions from a series of deep convolutional neural networks that encode spatiotemporal information from multimodal image sequences to guide real-time servoing. We demonstrate, through imaging and robotic tracking studies in volunteers, the ability of the device to segment, classify, localize and track peripheral vessels in the presence of anatomical variability and motion. We then evaluate robotic performance in phantom and animal models of difficult vascular access and show that the device can improve success rates and procedure times compared to manual cannulations by trained operators, particularly in challenging physiological conditions. These results suggest the potential for autonomous systems to outperform humans on complex visuomotor tasks, and demonstrate a step in the translation of such capabilities into clinical use. Getting safe and fast access to blood vessels is vital to many methods of treatment and diagnosis in medicine. Robot-assisted or even fully autonomous methods can potentially do the task more reliably than humans, especially when veins are hard to detect. In this work, a method is tested that uses deep learning to find blood vessels and track the movement of a patient's arm.","PERIPHERAL VENOUS ACCESS,ULTRASOUND GUIDANCE,COMPLICATIONS,CARE,3D,DEVICE,LEVEL,TIME,SKIN",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Computer Science,,15.508,"PERIPHERAL,VENOUS,ACCESS,ULTRASOUND,GUIDANCE,COMPLICATIONS,CARE,3D,DEVICE,LEVEL,TIME,SKIN",NATURE MACHINE INTELLIGENCE,,
24,Deep learning of circulating tumour cells,2,2,124-+,"Zeune Leonie L.,Boink Yoeri E.,van Dalum Guus,Nanou Afroditi,de Wit Sanne,Andree Kiki C.,Swennenhuis Joost F.,van Gils Stephan A.,Terstappen Leon W. M. M.,Brune Christoph","Zeune LL,Boink YE,van Dalum G,Nanou A,de Wit S,Andree KC,Swennenhuis JF,van Gils SA,Terstappen LWMM,Brune C",Brune C,10.1038/s42256-020-0153-x,University of Twente,"Circulating tumour cells (CTCs) found in the blood of cancer patients are a promising biomarker in precision medicine. However, their use is currently hindered by their low frequency, tedious manual scoring and extensive cell heterogeneities. Those challenges limit the effectiveness of classical machine-learning methods for automated CTC analysis. Here, we combine autoencoding convolutional neural networks with advanced visualization techniques. This provides a very informative view on the data that opens the way for new biomedical research questions. We unravel hidden information in the raw image data of fluorescent images of blood samples enriched for CTCs. Our network classifies fluorescent images of single cells in five different classes with an accuracy, sensitivity and specificity of over 96%, and the obtained CTC counts predict the overall survival of cancer patients as well as state-of-the-art manual counts. Moreover, our network excelled in identifying different important subclasses of objects. Deep learning was faster and superior to classical image analysis approaches and enabled the identification of new biological phenomena. Counting different types of circulating tumour cells can give valuable information on the severity of the disease and on whether treatments are effective for a specific patient. In this work, the authors show that their method based on autoencoders can identify and count cells more accurately and faster than human experts.","METASTATIC BREAST-CANCER,PREDICT PROGRESSION-FREE,SURVIVAL,CHEMOTHERAPY,BEVERLY-2,DISEASE",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Computer Science,,15.508,"METASTATIC,BREAST-CANCER,PREDICT,PROGRESSION-FREE,SURVIVAL,CHEMOTHERAPY,BEVERLY-2,DISEASE",NATURE MACHINE INTELLIGENCE,,
25,Deep-learning-based prediction of late age-related macular degeneration progression,2,2,141-+,"Yan Qi,Weeks Daniel E.,Xin Hongyi,Swaroop Anand,Chew Emily Y.,Huang Heng,Ding Ying,Chen Wei","Yan Q,Weeks DE,Xin HY,Swaroop A,Chew EY,Huang H,Ding Y,Chen W",Yan Q; Chen W,10.1038/s42256-020-0154-9,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Both genetic and environmental factors influence the etiology of age-related macular degeneration (AMD), a leading cause of blindness. AMD severity is primarily measured by images of the fundus of the retina and recently developed machine learning methods can successfully predict AMD progression using image data. However, none of these methods have used both genetic and image data for predicting AMD progression. Here we used both genotypes and fundus images to predict whether an eye had progressed to late AMD with a modified deep convolutional neural network. In total, we used 31,262 fundus images and 52 AMD-associated genetic variants from 1,351 subjects from the Age-Related Eye Disease Study, which provided disease severity phenotypes and fundus images available at baseline and follow-up visits over a period of 12 years. Our results showed that fundus images coupled with genotypes could predict late AMD progression with an averaged area-under-the-curve value of 0.85 (95%confidence interval 0.83-0.86). The results using fundus images alone showed an averaged area under the receiver operating characteristic curve value of 0.81 (95%confidence interval 0.80-0.83). We implemented our model in a cloud-based application for individual risk assessment. Age-related macular degeneration is a serious eye disease which should be detected as early as possible. Using both fundus images and genetic information, a deep neural network is able to detect the severity of the disease and predict its progression seven years into the future.","GENETIC SUSCEPTIBILITY,DIABETIC-RETINOPATHY,EYE DISEASE,IMAGES,CLASSIFICATION,PATTERNS,AREDS,AMD",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Computer Science,,15.508,"GENETIC,SUSCEPTIBILITY,DIABETIC-RETINOPATHY,EYE,DISEASE,IMAGES,CLASSIFICATION,PATTERNS,AREDS,AMD",NATURE MACHINE INTELLIGENCE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7153739,
26,A machine-learning approach to predicting and understanding the properties of amorphous metallic alloys,187,,,"Xiong Jie,Shi San-Qiang,Zhang Tong-Yi","Xiong J,Shi SQ,Zhang TY",Zhang TY,10.1016/j.matdes.2019.108378,Shanghai University,"There is a pressing need to shorten the development period for new materials possessing desired properties. For example, bulk metallic glasses (BMGs) are a unique class of alloy materials utilized in a wide variety of applications due to their attractive physical properties. However, the lack of predictive tools for uncovering the relationships between BMGs' alloy composition and desired properties limits the further application of these materials. In this study, a machine-learning (ML) approach was developed, based on a dataset of 6471 alloys, to enable the construction of a predictive ML model to describe the glass-forming ability and elastic moduli of BMGs. The model's predictions of unseen data were found to be in good agreement with most experimental values. Consequently, we determined that an alloy with a large critical-casting diameter would likely have a high mixing entropy, a high thermal conductivity, and a mixing enthalpy of approximately -28 kJ/mol, and that a BMG with a small average atomic volume would likely have a high elastic modulus. The efficacy of ML was demonstrated in furnishing a mechanistic understanding and enabling the prediction of metallic-glass properties. (C) 2019 Brunel Centre for Advanced Solidification Tecnhnology, Brunel University London. Published by Elsevier Ltd.","Metallic glasses,Machine learning,Symbolic regression,Glassforming ability",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Materials Science,,7.097,"GLASS-FORMING,ABILITY,HIGH,ENTROPY,ALLOYS,SUPERCOOLED,LIQUID,ELASTIC,PROPERTIES,THERMAL-STABILITY,CRITERION,CLASSIFICATION,PARAMETERS",MATERIALS & DESIGN,https://doi.org/10.1016/j.matdes.2019.108378,
27,A novel approach based on wavelet analysis and arithmetic coding for automated detection and diagnosis of epileptic seizure in EEG signals using machine learning techniques,56,,,"Amin Hafeez Ullah,Yusoff Mohd Zuki,Ahmad Rana Fayyaz","Amin HU,Yusoff MZ,Ahmad RF",Yusoff MZ,10.1016/j.bspc.2019.101707,Universiti Teknologi Petronas,"Epilepsy, a common neurological disorder, is generally detected by electroencephalogram (EEG) signals. Visual inspection and interpretation of EEGs is a slow, time consuming process that is vulnerable to error and subjective variability. Consequently, several efforts to develop automatic epileptic seizure detection and classification methods have been made. The present study proposes a novel computer aided diagnostic technique (CAD) based on the discrete wavelet transform (DWT) and arithmetic coding to differentiate epileptic seizure signals from normal (seizure-free) signals. The proposed CAD technique comprises three steps. The first step decomposes EEG signals into approximations and detail coefficients using DWT while discarding non-significant coefficients in view of threshold criteria; thus, limiting the number of significant wavelet coefficients. The second step converts significant wavelet coefficients to bit streams using arithmetic coding to compute the compression ratio. In the final step, the compression feature set is standardized, whereupon machine-learning classifiers detect seizure activity from seizure-free signals. We employed the widely used benchmark database from Bonn University to compare and validate the technique with results from prior approaches. The proposed method achieved a perfect classification performance (100% accuracy) for the detection of epileptic seizure activity from EEG data, using both linear and non-liner machine-learning classifiers. This CAD technique can thus be considered robust with an extraordinary detection capability that discriminates epileptic seizure activity from seizure-free and normal EEG activity with simple linear classifiers. The method has the potential for efficient application as an adjunct for the clinical diagnosis of epilepsy. (C) 2019 Elsevier Ltd. All rights reserved.","Electroencephalography (EEG),Epileptic seizure,Discrete wavelet transform (DWT),Arithmetic coding,Computer-aided diagnostic",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,"NEURAL-NETWORK,APPROXIMATE,ENTROPY,FEATURE-EXTRACTION,BINARY,PATTERN,CLASSIFICATION,IDENTIFICATION,STATISTICS,ALGORITHMS,TRANSFORM,SYSTEM",BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
28,Prediction of wear loss quantities of ferro-alloy coating using different machine learning algorithms,8,1,107-114,"Altay Osman,Gurgenc Turan,Ulas Mustafa,Ozel Cihan","Altay O,Gurgenc T,Ulas M,Ozel C",Gurgenc T,10.1007/s40544-018-0249-z,Firat University,"In this study, experimental wear losses under different loads and sliding distances of AISI 1020 steel surfaces coated with (wt.%) 50FeCrC-20FeW-30FeB and 70FeCrC-30FeB powder mixtures by plasma transfer arc welding were determined. The dataset comprised 99 different wear amount measurements obtained experimentally in the laboratory. The linear regression (LR), support vector machine (SVM), and Gaussian process regression (GPR) algorithms are used for predicting wear quantities. A success rate of 0.93 was obtained from the LR algorithm and 0.96 from the SVM and GPR algorithms.","surface coating,plasma transfer arc (PTA) welding,wear,prediction",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Engineering,,6.14,"GAUSSIAN,PROCESS,REGRESSION,NEURAL-NETWORK,PREDICTION,MICROSTRUCTURE,RESISTANCE,MODEL",FRICTION,https://link.springer.com/content/pdf/10.1007/s40544-018-0249-z.pdf,
29,Automatic facade recovery from single nighttime image,14,1,95-104,"Zhou Yi,Geng Qichuan,Zhou Zhong,Wu Wei","Zhou Y,Geng QC,Zhou Z,Wu W",Geng QC; Zhou Z,10.1007/s11704-017-6457-2,Beihang University,"Nighttime images are difficult to process due to insufficient brightness, lots of noise, and lack of details. Therefore, they are always removed from time-lapsed image analysis. It is interesting that nighttime images have a unique and wonderful building features that have robust and salient lighting cues from human activities. Lighting variation depicts both the statistical and individual habitation, and it has an inherent man-made repetitive structure from architectural theory. Inspired by this, we propose an automatic nighttime facade recovery method that exploits the lattice structures of window lighting. First, a simple but efficient classification method is employed to determine the salient bright regions, which may be lit windows. Then we group windows into multiple lattice proposals with respect to facades by patch matching, followed by greedily removing overlapping lattices. Using the horizon constraint, we solve the ambiguous proposals problem and obtain the correct orientation. Finally, we complete the generated facades by filling in the missing windows. This method is well suited for use in urban environments, and the results can be used as a good single-view compensation method for daytime images. The method also acts as a semantic input to other learning-based 3D image reconstruction techniques. The experiment demonstrates that our method works well in nighttime image datasets, and we obtain a high lattice detection rate of 82.1% of 82 challenging images with a low mean orientation error of 12.1 +/- 4.5 degrees.","facade recovery,nighttime images,lattice detection",Article,"HIGHER EDUCATION PRESS, CHAOYANG DIST, 4, HUIXINDONGJIE, FUSHENG BLDG, BEIJING 100029, PEOPLES R CHINA",Computer Science,,1.962,"REGULARITY,CONTEXT",FRONTIERS OF COMPUTER SCIENCE,,
30,Computer vision based detection of external defects on tomatoes using deep learning,190,,131-144,"da Costa Arthur Z.,Figueroa Hugo E. H.,Fracarolli Juliana A.","da Costa AZ,Figueroa HEH,Fracarolli JA",da Costa AZ,10.1016/j.biosystemseng.2019.12.003,Universidade Estadual de Campinas,"Sorting machines use computer vision (CV) to separate food items based on various attributes. For instance, sorting based on size and colour are commonly used in commercial machines. However, detecting external defects using CV remains an open problem. This paper presents an experimental contribution to external defect detection using deep learning. An uncensored dataset with 43,843 images including external defects was built during this study. The dataset is heavily imbalanced towards the healthy class, and it is available online. Deep residual neural network (ResNet) classifiers were trained that are capable of detecting external defects using feature extraction and fine-tuning. The results show that fine-tuning outperformed feature extraction, revealing the benefit of training additional layers when sufficient data samples are available. The best model was a ResNet50 with all its layers fine-tuned. This model achieved an average precision of 94.6% on the test set. The optimal classifier had a recall of 86.6% while maintaining a precision of 91.7%. The posterior class-conditional distributions of the classifier scores showed that the key to classifier success lies in its almost ideal healthy class distribution. The results also explain why the model does not confuse stems/calyxes with external defects. The best model constitutes a milestone for detecting external defects using CV. Because deep learning does not require feature engineering or prior knowledge about the dataset content, the methodology may also work well with other foods. (C) 2019 IAgrE. Published by Elsevier Ltd. All rights reserved.","Defect sorting,Deep learning,Sorting machines,Computer vision",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA",Agriculture,,4.508,"QUALITY,INSPECTION,CITRUS,CLASSIFICATION,SYSTEMS,FRUITS",BIOSYSTEMS ENGINEERING,,
31,Lattice dynamics simulation using machine learning interatomic potentials,172,,,"Ladygin V. V.,Korotaev P. Yu,Yanilkin A. V,Shapeev A. V","Ladygin VV,Korotaev PY,Yanilkin AV,Shapeev AV",Ladygin VV,10.1016/j.commatsci.2019.109333,Skolkovo Institute of Science & Technology,"In this work, a machine-learning approach was applied to obtaining an interatomic potential for lattice dynamics properties calculation with accuracy close to the one of density functional theory (DFT). The computational efficiency of the potential allows one to access large time and length scales through molecular dynamics simulations. The use of active learning and an automatic training procedure greatly reduces the number of quantum-mechanical calculations for the training set. In order to estimate the accuracy of the obtained potentials, four materials Al, Mo, Ti and U with different phonon and thermodynamic properties were investigated. Phonon properties were calculated using the temperature dependent effective potential method. The potentials reproduce not only harmonic behavior but also anharmonic effects, as shown by the calculation of the third-order force constants. We found that machine-learning potentials reproduce quantum-mechanical data with high accuracy. Furthermore, the vibrational density of states was obtained via velocity autocorrelation function integration, which would be infeasible in direct quantum-mechanical simulations.","Lattice dynamics,Anharmonicity,Machine learning,Moment tensor potentials",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"TOTAL-ENERGY,CALCULATIONS,PATTERN-RECOGNITION,NEURAL-NETWORKS,PREDICTION,DISPERSION,SURFACES,METALS",COMPUTATIONAL MATERIALS SCIENCE,,
32,Adsorptive removal of cobalt(II) from aqueous solutions using multi-walled carbon nanotubes and gamma-alumina as novel adsorbents: Modelling and optimization based on response surface methodology and artificial neural network,299,,,"Dehghani Mohammad Hadi,Yetilmezsoy Kaan,Salari Mehdi,Heidarinejad Zoha,Yousefi Mahmood,Sillanpaa Mika","Dehghani MH,Yetilmezsoy K,Salari M,Heidarinejad Z,Yousefi M,Sillanpaa M",Dehghani MH,10.1016/j.molliq.2019.112154,Tehran University of Medical Sciences,"The efficiency of new and nano-scale adsorbents including multi-walled carbon nanotubes (MWCNTs) and gamma-alumina in the removal of cobalt(II) from aqueous solutions was experimentally evaluated in a batch-system reactor. To the best of our knowledge, no previous study has specifically attempted to introduce a hybrid strategy based on artificial neural network and genetic algorithm techniques for modelling and optimizing adsorptive removal of cobalt(II) from aqueous solutions via the proposed nanoparticles. The analyses of SEM, TEM, and FTIR were used to characterize both adsorbents. The response surface methodology (RSM) approach suggested a second-order polynomial model with a p-value < 0.0001 and R-2 of 0.9980 for MWCNTs adsorbent and a p-value < 0.0001 and R-2 of 0.9992 for gamma-alumina adsorbent. The artificial neural network (ANN) approach suggested a three-layered feed-forward backpropagation model with R-2 of 0.9794 for MWCNTs adsorbent and R-2 of 0.9823 for gamma-alumina adsorbent. The results linked to optimization by RSM showed that the maximum cobalt(II) removal efficiency of about 90% was achieved in the case of the MWCNTs adsorbent under the conditions of pH = 10, contact time = 38.6 min, MWCNTs dosage = 1.57 mg/L, and initial cobalt(II) concentration = 56.57 mg/L. About 93% of cobalt(II) removal could be obtained in the case of gamma-alumina adsorbent under the conditions of pH = 10, contact time = 35.5 min, gamma-alumina dosage = 1.63 g/L, and initial cobalt(II) concentration = 52.15 mg/L. The optimization values using the genetic algorithm (GA) technique were almost the same as those obtained from the RSM method. The kinetic model of Ho and McKay's pseudo-second order (PSO) and the isotherm model of Dubinin-Radushkevich were found to be the best-fitted to the experimental for both MWCNTs and gamma-alumina. In addition, the maximum monolayer adsorption capacity of MWCNTs and gamma-alumina adsorbents for the adsorption of cobalt(II) was 78.94 mg/g and 75.78 mg/g, respectively. Also, a thermodynamic study exhibited a favorable and spontaneous adsorption process for both materials. The present study clearly concluded that the proposed adsorbents could be effectively used for the removal of cobalt(II) from aqueous solutions at lower adsorbent dose and shorter contact times than various adsorbents reported in literature. (C) 2019 Elsevier B.V. All rights reserved.","Adsorption,Cobalt(II),Multi-walled carbon nanotube,gamma-Alumina,Artificial neural network,Genetic algorithm",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Chemistry,Physics",,5.642,"FACILE,HYDROTHERMAL,METHOD,WASTE-WATER,METAL-IONS,NANOPARTICLES,EQUILIBRIUM,COMPOSITE,PHOSPHATE,SORPTION,KINETICS,CO%28II%29",JOURNAL OF MOLECULAR LIQUIDS,,
33,Prediction of Permeability Using Group Method of Data Handling (GMDH) Neural Network from Well Log Data,13,3,,"Mathew Nkurlu Baraka,Shen Chuanbo,Asante-Okyere Solomon,Mulashani Alvin K.,Chungu Jacqueline,Wang Liang","Nkurlu BM,Shen CB,Asante-Okyere S,Mulashani AK,Chungu J,Wang L",Shen CB,10.3390/en13030551,China University of Geosciences,"Permeability is an important petrophysical parameter that controls the fluid flow within the reservoir. Estimating permeability presents several challenges due to the conventional approach of core analysis or well testing, which are expensive and time-consuming. On the contrary, artificial intelligence has been adopted in recent years in predicting reliable permeability data. Despite its shortcomings of overfitting and low convergence speed, artificial neural network (ANN) has been the widely used artificial intelligent method. Based on this, the present study conducted permeability prediction using the group method of data handling (GMDH) neural network from well log data of the West arm of the East African Rift Valley. Comparative analysis of GMDH permeability model and ANN methods of the back propagation neural network (BPNN) and radial basis function neural network (RBFNN) were further explored. The results of the study showed that the proposed GMDH model outperformed BPNN and RBFNN as it achieved R/root mean square error (RMSE) value of 0.989/0.0241 for training and 0.868/0.204 for predicting, respectively. Sensitivity analysis carried out revealed that shale volume, standard resolution formation density, and thermal neutron porosity were the most influential well log parameters when developing the GMDH permeability model.","permeability,group method of data handling,artificial neural network,well logs,sensitivity analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"GENETIC,ALGORITHM,RESERVOIR,POROSITY,HYBRID",ENERGIES,https://www.mdpi.com/1996-1073/13/3/551/pdf,
34,A novel method for identifying electrocardiograms using an independent component analysis and principal component analysis network,152,,,"Yang Weiyi,Si Yujuan,Wang Di,Zhang Gong","Yang WY,Si YJ,Wang D,Zhang G",Si YJ,10.1016/j.measurement.2019.107363,Jilin University,"Electrocardiograms (ECGs) have been extensively utilized for diagnosing cardiovascular abnormalities. However, due to the mixed noise and the subtle differences between ECGs, it is generally arduous to spot the ECG abnormalities with satisfactory efficiency with the naked eye. To address these issues, we proposed a novel automatic system for diagnosing arrhythmia. In this paper, several independent component analysis and principal component analysis networks (ICA-PCANets) were developed as the ECG feature extraction methods. To verify their effectiveness, linear support vector machine (SVM), K-nearest neighbors (KNN) and random forest (RF) were adopted as the classifier models in this work. Among them, the combination of ICA-PCANet and linear SVM achieved the highest accuracies of 98.01%, 98.63%, and 91.77% by classifying 2 classes, 5 classes (AAMI standard), and 14 detailed categories, respectively, on the MIT-BIH database. Based on the above comprehensive performances, the proposed system can be applied to clinical monitoring of heart conditions. (C) 2019 Elsevier Ltd. All rights reserved.","Electrocardiogram (ECG),ICA-PCANet,Support vector machines,Arrhythmia,MIT-BIH database,AAMI standard",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Instruments & Instrumentation",,3.778,"CLASSIFICATION,CLASSIFIERS,MULTICLASS,SIGNALS,SYSTEM,MODEL",MEASUREMENT,,
35,Multi-scale classification of single-cell gel electrophoresis assay using deep learning algorithm,56,,,"Erdamar Aykut,Aksahin Mehmet Feyzi","Erdamar A,Aksahin MF",Aksahin MF,10.1016/j.bspc.2019.101672,Baskent University,"Structural and functional integrity of deoxyribonucleic acid (DNA) is crucial for the maintenance of hereditary information. However, by-products of cellular metabolism and physical or chemical factors may cause spontaneous DNA damage. The alkaline single-cell gel electrophoresis or comet assay analysis is an easy and reliable method for the determination genotoxic effects of chemical and physical factors. Simply, it is the electrophoretic analysis of intact damaged DNA of a single cell on in a thin layer of agarose gel. The quantitative analysis of the comet assay images is performed manually by an expert researcher. In visual scoring, DNA nuclei are scored as 0, 1, 2, 3, and 4; and the correct scoring is crucial for the determination of the DNA damage. However, visual scoring depends on the professional experience of the researcher and it is a time consuming and exhausting task. Therefore, this evaluation is inevitable to have subjective results. To avoid this subjectivity and to show the effectiveness of deep learning algorithm on cell images, a Convolution Neural Network (CNN) based deep learning method is proposed to classify comet assay images. According to the results, CNN is trained and tested with high accuracy. The results show that CNN algorithm can successfully classify five different scores of comet assay images, and these results can also reduce the subjectivity. (C) 2019 Elsevier Ltd. All rights reserved.","Comet assay,Image classification,Convolution neural network",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,"IMAGE-ANALYSIS,PROGRAM,DNA-DAMAGE,COMET,ASSAY,AUTOMATED,TOOL,QUANTIFICATION",BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
36,MoDTRAP: Improved heart rate tracking and preprocessing of motion-corrupted photoplethysmographic data for personalized healthcare,56,,,"Roy Biplab,Gupta Rajarshi","Roy B,Gupta R",Gupta R,10.1016/j.bspc.2019.101676,University of Calcutta,"Objective: A new joint framework for heart rate (HR) tracking and preprocessing of motion artifact (MA) corrupted photoplethysmogram (PPG) data is presented.
Methods: Two popular signal decomposition techniques, viz., variational mode decomposition (VMD) to track HR, and ensemble empirical mode decomposition (EEMD) in conjunction with an artificial neural network (NN) model was utilized for preprocessing. The HR frequency was estimated from the signal strengths of VMD decomposed mode functions and tracked with an indigenous algorithm utilizing the fact that the PPG signal normally comprises base HR frequency along with its harmonics. For MA reduction, The HR synchronous signal component was extracted from the appropriate mode functions of VMD decomposition and reconstructed to minimize MA using a template matching technique utilizing an autoencoder and pre-trained multilayer feedforward neural network model. A combination of EEMD followed by a LSTM binary classifier was used to generate and update the reference PPG template beat for the above purpose.
Results: With 2015 IEEE signal processing cup challenge database, an average absolute error and percent absolute error of 1.02 and 0.86 respectively compared to the ground truth HR were obtained for all 22 subjects. For MA reduction, we used wrist PPG data collected from 30 human subjects (normal and cardiovascular patients), achieving an average root mean squared error (RMSE) of 031 and SNR improvement of 21.23 dB.
Conclusion: Proposed MoDTRAP technique provides noticeable improvements, separately, over existing methods on HR tracking and MA reduction.
Significance: The proposed technique can be utilized for ambulatory healthcare monitoring. (C) 2019 Elsevier Ltd. All rights reserved.","Empirical ensemble mode decomposition,Heart rate estimation,Motion artifact,Photoplethysmogram,Variational mode decomposition,Neural network",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,"MODE,DECOMPOSITION,SIGNALS,FRAMEWORK,TIME",BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
37,Machine learning on density and elastic property of oxide glasses driven by large dataset,529,,,Deng Binghui,Deng BH,Deng BH,10.1016/j.jnoncrysol.2019.119768,Corning Inc,"We conduct a comprehensive machine learning study on predicting the oxide glasses density, Young's modulus, shear modulus, and Poisson's ratio given compositions, by leveraging the large dataset collected at Corning Incorporated. The density and elastic property datasets have the size of 24,858 and 8519, respectively. Our results show that random forest, K-Nearest neighbor, and neural networks consistently deliver good performance, while support vector machine consistently underperforms. Lasso linear regression works best for density prediction, while Poisson's ratio is extremely challenging to predict with the best R-2 score achieved to be around 0.7 by random forest. Additionally, feature importance analysis shows that La2O3 and BaO are the top two features for density prediction, while Na2O and B2O3 for Young's modulus and shear modulus prediction, and CaO and SiO2 for Poisson's ratio prediction. The study could be potentially leveraged as the baseline by future studies given the large dataset we trained on.","Machine learning,Oxide glasses,Property prediction,Composition,Large dataset",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.208,,JOURNAL OF NON-CRYSTALLINE SOLIDS,,
38,Uncertainty and interpretability in convolutional neural networks for semantic segmentation of colorectal polyps,60,,,"Wickstrom Kristoffer,Kampffmeyer Michael,Jenssen Robert","Wickstrom K,Kampffmeyer M,Jenssen R",Wickstrom K,10.1016/j.media.2019.101619,UiT The Arctic University of Tromso,"Colorectal polyps are known to be potential precursors to colorectal cancer, which is one of the leading causes of cancer-related deaths on a global scale. Early detection and prevention of colorectal cancer is primarily enabled through manual screenings, where the intestines of a patient is visually examined. Such a procedure can be challenging and exhausting for the person performing the screening. This has resulted in numerous studies on designing automatic systems aimed at supporting physicians during the examination. Recently, such automatic systems have seen a significant improvement as a result of an increasing amount of publicly available colorectal imagery and advances in deep learning research for object image recognition. Specifically, decision support systems based on Convolutional Neural Networks (CNNs) have demonstrated state-of-the-art performance on both detection and segmentation of colorectal polyps. However, CNN-based models need to not only be precise in order to be helpful in a medical context. In addition, interpretability and uncertainty in predictions must be well understood. In this paper, we develop and evaluate recent advances in uncertainty estimation and model interpretability in the context of semantic segmentation of polyps from colonoscopy images. Furthermore, we propose a novel method for estimating the uncertainty associated with important features in the input and demonstrate how interpretability and uncertainty can be modeled in DSSs for semantic segmentation of colorectal polyps. Results indicate that deep models are utilizing the shape and edge information of polyps to make their prediction. Moreover, inaccurate predictions show a higher degree of uncertainty compared to precise predictions. (C) 2019 The Authors. Published by Elsevier B.V.","Polyp segmentation,Decision support systems,Fully convolutional networks,Monte carlo dropout,Guided backpropagation,Monte carlo guided backpropagation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"CANCER,STATISTICS,COLONOSCOPY,VALIDATION",MEDICAL IMAGE ANALYSIS,https://doi.org/10.1016/j.media.2019.101619,
39,Automated segmentation of fluid regions in optical coherence tomography B-scan images of age-related macular degeneration,122,,,"Chen Zailiang,Li Dabao,Shen Hailan,Mo Hailan,Zeng Ziyang,Wei Hao","Chen ZL,Li DB,Shen HL,Mo HL,Zeng ZY,Wei H",Shen HL,10.1016/j.optlastec.2019.105830,Central South University,"Age-related macular degeneration (AMD) is a common eye disease that causes progressive vision loss in people older than 50 years. Fluid regions in retina are the most characteristic of AMD. Accurately segmenting fluid regions is crucial for the early diagnosis of AMD, and assessment of treatment efficacy. In this paper, we propose an automatic deep learning method constructed by integrating Squeeze-and-Excitation blocks with U-Net named SEUNet to segment fluid regions and classify OCT B-scan images to AMD or normal image. The proposed method comprises three stages: (1) preprocessing stage that includes image noise removal, locating the image on the area of interest, and image color-reversing; (2) fluid region segmentation stage which is based on U-Net and constructed by integrating Squeeze-and-Excitation block to segment fluid region; and (3) image classification stage that classifies image to AMD or normal image. Experimental results show that the proposed method have an average IOU coefficient of 0.9035, an average Dice coefficient of 0.9421, an average precision of 0.9446, and an average recall of 0.9464. Therefore, the proposed method can effectively segment fluid regions in OCT B-scan images.","SEUNet,AMD,OCT image,Fluid regions,Segmentation",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Optics,Physics",,3.566,"EDEMA,QUANTIFICATION",OPTICS AND LASER TECHNOLOGY,,
40,Detection of Pulmonary Nodules Based on C-3D Deformable Convolutional Neural Network Model,57,4,,"Ruan Hongyang,Chen Zhilan,Cheng Yingsheng,Kai Yang","Ruan HY,Chen ZL,Cheng YS,Kai Y",Chen ZL,10.3788/LOP57.041013,"Shanghai Jian Qiao Univ, Coll Mech & Elect Engn, Shanghai 210306, Peoples R China.","A three-dimensional (3D) deformable convolutional neural network is proposed based on the C-3D convolutional neural network for realizing detection of pulmonary nodules. A 3D deformable convolution and pooling is used in the main structure of the model. It solves the problem that the traditional square convolution and pooling cannot collect the pixels of pulmonary nodules efficiently when dealing with irregular pulmonary nodules. By adjusting the input of the 3D convolutional neural network, the scanning and recognition of 32 X 32 X 32 pixels of a sample image arc realized step by step by using a convolutional neural network, thereby realizing pulmonary nodule localization. As for the output of the model, the first full connection layer of the C-3D network is replaced by the convolution layer based on a full convolution neural network, to solve the problem of memory overflow during training. In terms of model parameters, three different learning rates and optimization functions arc designed for experimental comparison, and the parametric comparison diagrams of three different learning rates and optimization functions arc drawn. According to the experimental results, the optimal learning rate and parameters of optimization functions of the convolutional neural network arc selected. The experimental results show that the area under the receiver operating curve, classification accuracy, recall, and F1 value of the proposed method have been significantly improved.","image processing,deformable convolutional neural network,pulmonary nodules,pooling layer",Article,"SHANGHAI INST OPTICS & FINE MECHANICS, CHINESE ACAD SCIENCE,  390, QINGHE LU, SHANGHAI, JIADING-QU, PEOPLES R CHINA","Engineering,Optics",,,,LASER & OPTOELECTRONICS PROGRESS,,
41,Diffuse Optical Tomography Reconstruction Based on Deep Learning,57,4,,"Wang Huiquan,Wu Nian,Zhao Zhe,Han Guang,Wang Jinhai","Wang HQ,Wu N,Zhao Z,Han G,Wang JH",Wang JH,10.3788/LOP57.040003,Tiangong University,"Diffuse optical tomography (DOT) is a low-cost, non-radiative damage, deep detection in vivo optical functional imaging technology that uses near-infrared light to detect biological tissue optical structures. Due to the strong scattering, low absorption characteristics, and high spatial resolution of the biological tissue itself, the inverse problem of DOT reconstruction has serious ill-conditioned characteristics. The traditional inverse problem solution is mainly based on the algebraic iterative reconstruction method. With the development of artificial intelligence and the arrival of the era of big data, deep learning research has set off to reach another new climax. The inverse problem-solving method based on a deep learning network model is gradually used in the DOT reconstruction process. On the basis of combing the traditional DOT reconstruction algorithm, this manuscript focuses on the research progress of the latest deep learning for DOT reconstruction and provides reference for relevant research teams in this field.","medical optics,diffuse optical tomography,inverse problem,deep learning",Review,"SHANGHAI INST OPTICS & FINE MECHANICS, CHINESE ACAD SCIENCE,  390, QINGHE LU, SHANGHAI, JIADING-QU, PEOPLES R CHINA","Engineering,Optics",,,NEURAL-NETWORK,LASER & OPTOELECTRONICS PROGRESS,,
42,A comparative analysis of bubble point pressure prediction using advanced machine learning algorithms and classical correlations,185,,,"Yang Xi,Dindoruk Birol,Lu Ligang","Yang X,Dindoruk B,Lu LG",Dindoruk B,10.1016/j.petrol.2019.106598,Royal Dutch Shell,"The need for fluid properties or PVT (Pressure-Volume-Temperature) properties, is part of the entire Exploration and Production (E&P) lifecycle from exploration to mature asset management to the typical later life events such as, Improved Oil Recovery (IOR). As the projects mature, the need for such data and its integration for various discipline-specific workflows and its interpretation in the light of reservoir performance varies. Among all the key PVT properties, bubble point pressure is probably the most important parameter. Bubble point pressure is important because it is the point at which constant composition and variable composition portions of the depletion paths merge. Geometrically, bubble point pressure appears to be a discontinuity. In addition, it dictates the existence (or not) of the incipient phase (i.e., gas phase) leading to the changes in the flow characteristics both in porous media and as well as within the wellbore and the facilities. Furthermore, it is also a good indicative of a possible gas cap when the reservoir is at saturation (reservoir pressure is equal to the bubble point pressure) or near-saturated. Among the highlighted uses, there are many more used such as the determination of the elements of miscibility, gas lift design, etc. Therefore, it is very important to estimate the bubble point pressure accurately.
In this study, tree-based advanced machine learning algorithm including XGBoost, LightGBM, and random forest regressor, and multi-layer perceptron (neural network) regressor are implemented to predict bubble point pressure (P-bp). A novel super learner model which is also known as stacking ensemble is used to enhance base machine learning model performance on predicting bubble point pressure. Three datasets with different predictors are prepared to study machine learning algorithms' performance for three situations: only compositional data are available; only bulk properties (Gas-Oil-Ratio, gas gravity, API gravity and reservoir Temperature) are available; both compositional data and bulk properties are available. Through literature review, there is no research on using only compositional data and temperature to predict bubble point pressure. Our super learner model offers an accurate solution for oil bubble point pressure when only compositional data and temperature are available. Machine learning models perform better than empirical correlations with limited input data (i.e., bulk properties). When compositional data and bulk properties are all used as predictors, super learner reaches about 5.146% mean absolute relative error on predicting the bubble point pressure from global samples with bubble point pressures in the range of 100 to 10,000 psi, which is a wider range compared to most ANN models published in literature.","Bubble point pressure,PVT,Fluid properties,Correlations",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Energy & Fuels,Engineering",,4.376,"PVT,PROPERTIES,SUPER,LEARNER,MODEL",JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING,,
43,Classification of Motor-Imagery-Based Brain Computer Interface of Semi-Supervised Learning,56,3,139-145,",","Tan Xuemin,Guo Chao",,,Tan Xuemin,"In order to reduce the boring and time-consuming training process and improve the classification accuracy of brain-computer interface system,this paper proposes a self-training algorithm with segmented overlapping common spatial pattern algorithm which applies a semi-supervised learning to motor imagination classification.The new algorithm uses segmented overlapping common spatial pattern as feature extraction method and learns from a small pool of labeled data.In addition,a confidence criterion is proposed to select the most informative samples from the unlabeled samples to improve the classifier.With the help of small labeled data and large unlabeled data,the proposed algorithm achieves better classification performance than self-training algorithm with common spatial pattern and self-training algorithm with filter bank common spatial pattern.The dataset Iva of BCI competition III has been used to demonstrate the validity of the method,and the results show the proposed algorithm can effectively improve the classification accuracy of motor imagination.",Brain Computer Interface(BCI); self-training; Segmented overlapping Common Spatial Pattern(SCSP); confidence criterion,Article,,,,,,,,
44,Application of Fuzzy Entropy and Deep Learning in Schizophrenia,56,3,152-158,",,,","Tian Cheng,Hu Ting,Cao Rui,Xiang Jie",,,Tian Cheng,"Schizophrenia is a common serious mental disease,which has seriously affected the quality of human life for many years.Therefore,accurate diagnosis is a prerequisite for the treatment of the disease.To solve the problem,this paper proposes a classification method of schizophrenia electroencephalogram(EEG)signals based on brain complexity and deep learning,aiming at discovering hidden distributed features in data.Contrary to the standard EEG data analysis technology that ignores spatial information,the time series of EEG signals are firstly divided into different frequencies,and fuzzy entropy(FuzzyEn)is used to extract the complexity features of each frequency band,then the feature vectors are constructed according to the spatial position of the electrode and input into the Convolution Neural Network(CNN)to train the classification model,so as to automatically identify whether the subject is diseased.The results show that the experimental method is effective,and the classification accuracy reaches 99.16%.",schizophrenia; fuzzy entropy; Convolution Neural Network(CNN); classification,Article,,,,,,,,
45,Edible Oil Terahertz Spectral Feature Extraction Method Combining Radial Basis Function and KPCA,40,2,391-396,"Wang Zhuo-wei,Luo Jian-peng,Li Xue-shi,Cheng Liang-lun","Wang ZW,Luo JP,Li XS,Cheng LL",Li XS,10.3964/j.issn.1000-0593(2020)02-0391-06,Guangdong University of Technology,"In order to deal with the case where the terahertz spectrums are linearly inseparable, this paper proposes a method combining the radial basis function and the kernel principal component analysis (KPCA) to extract the terahertz spectral features of edible oils. By using this method, the extracted inner-class distance of features is small, meanwhile the extracted inter-class distance is large. An accurate classification model can be established in most support vector machine classifiers. Terahertz spectroscopy is an important method to detect the type and quality of edible oils. The research on the feature extraction technology of terahertz spectroscopy is of great significance for the rapid detection of edible oil types and quality. Although there have been a theoretical basis on how to use the terahertz spectroscopy to detect the type and quality of edible oils, it is still difficult to accurately extract the terahertz spectral features of edible oils and establish an accurate classification mode accordingly. Recently, researchers often use principal component analysis (PCA) in the field of chemometrics to extract features and use machine learning algorithms to establish a material classification model. However, the linear separability of the terahertz spectrum of edible oils has different characteristics in different frequency bands. When the terahertz spectrums of edible oils are linearly separable, it is feasible to extract features using PCA, and thus establish an accurate classification model. However, when the terahertz spectrums of edible oils are linearly inseparable, the features extracted using PCA are often not accurate enough, and an appropriate classifier is demanded to establish an accurate classification model. The method combining the radial basis function and KPCA feature extraction can be described as follows : the linear space-inseparable terahertz spectral data are mapped to the radial basis space by the radial basis function, then the features are extracted by KPCA which become linearly separable. As a result, a more accurate classification model can be established. For the experiment, firstly the sliding window average filtering algorithm is used to filter the terahertz spectral data of three edible oils. Then, the radial basis function is employed to nonlinearly map the terahertz spectrum. After that, KPCA is utilized for data dimensionality reduction. Finally, the support vector machine (SVM) is used to establish a classification model for edible oils and the feature extraction effect is verified. The calculated results of inter-class separability show that the inner-class distance of features extracted by the method is smaller, and the inter-class distance is larger. Thus, the overall feature extraction effect presented in this paper is better than those of PCA and KPCA. The experimental results of classification verification show that based on certain classification models the features extracted by PCA and KPCA cannot distinguish the type of edible oils very accurately. However, based on every classification model the feature extraction method proposed in this paper can distinguish the type of edible oils accurately. The method proposed in this paper has a better effect on the extraction of terahertz spectral features of edible oils, which makes it of great value in the detection and analysis of the quality of edible oils.","Terahertz spectroscopy,Radial basis function,Kernel principal component analysis,Support vector machine",Article,"OFFICE SPECTROSCOPY & SPECTRAL ANALYSIS, NO 76 COLLAGE SOUTH RD BEIJING, BEIJING 100081, PEOPLES R CHINA",Spectroscopy,,0.504,,SPECTROSCOPY AND SPECTRAL ANALYSIS,,
46,Uncertainty quantification using Bayesian neural networks in classification: Application to biomedical image segmentation,142,,,"Kwon Yongchan,Won Joong-Ho,Kim Beom Joon,Paik Myunghee Cho","Kwon Y,Won JH,Kim BJ,Paik MC",Paik MC,10.1016/j.csda.2019.106816,Seoul National University (SNU),"Most recent research of deep neural networks in the field of computer vision has focused on improving performances of point predictions by developing network architectures or learning algorithms. Reliable uncertainty quantification accompanied by point estimation can lead to a more informed decision, and the quality of prediction can be improved. In this paper, we invoke a Bayesian neural network and propose a natural way of quantifying uncertainties in classification problems by decomposing the moment-based predictive uncertainty into two parts: aleatoric and epistemic uncertainty. The proposed method takes into account the discrete nature of the outcome, yielding the correct interpretation of each uncertainty. We demonstrate that the proposed uncertainty quantification method provides additional insights into the point prediction using two Ischemic Stroke Lesion Segmentation Challenge datasets and the Digital Retinal Images for Vessel Extraction dataset. (C) 2019 Elsevier B.V. All rights reserved.","Aleatoric and epistemic uncertainty,Bayesian neural network,Ischemic stroke lesion segmentation,Retinal blood vessel segmentation,Uncertainty quantification",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Mathematics",,1.923,"VESSEL,SEGMENTATION",COMPUTATIONAL STATISTICS & DATA ANALYSIS,,
47,Research on laser processing technology of instrument panel implicit weakening line based on neural network and genetic algorithm,203,,,"Ding Hua,Wang Zongcheng,Guo Yicheng,Yin Xiao","Ding H,Wang ZC,Guo YC,Yin X",Wang ZC,10.1016/j.ijleo.2019.163970,Jiangsu University,"Laser weakening technology has been found to be widely used in the processing of automobile instrument panel implicit weakening line. Pulse width, defocusing amount and processing speed were selected as the influencing factors of the experiment, and residual thickness was taken as the evaluation index. Orthogonal experiments were designed to explore the influence of process parameters on residual thickness. The Back propagation (BP) neural network residual thickness prediction model is constructed, and the results show that the maximum relative error is 10.96 % and the minimum error is 2.21 %. The weight and threshold of BP network are optimized by genetic algorithm to improve prediction accuracy, stability and convergence speed in training. The convergence speed of the optimized neural network is faster, and the maximum prediction error is less than 2.5 % and the minimum is 0.12 %. Finally, the optimized GA-BP neural network is used to predict the processing results under different process parameters. According to the requirement of energy consumption, processing efficiency and error, appropriate process parameters are formulated.","Laser technology,Laser weakening,BP neural network,Genetic algorithm",Article,"ELSEVIER GMBH, HACKERBRUCKE 6, 80335 MUNICH, GERMANY",Optics,,1.955,PARAMETERS,OPTIK,,
48,Investigating single image super-resolution algorithm with deep learning using convolutional neural network for chest digital tomosynthesis,203,,,"Kim Tae-Hyung,Oh Heekyung,Kim Kyuseok,Lee Youngjin","Kim TH,Oh H,Kim K,Lee Y",Lee Y,10.1016/j.ijleo.2019.164070,Gachon University,"Numerous efforts have been continuously made toward the realization of high spatial resolution images for medical imaging devices. Specifically, the image super-resolution technique with deep learning using convolutional neural network (CNN) has been making excellent advancements recently. Accordingly, this study is focused on developing a single image super-resolution (SISR) algorithm using deep CNN (DCNN) with supervised learning that can drastically improve the spatial resolution of chest digital tomosynthesis (CDT) images. In addition, we attempt to demonstrate the superiority of the SISR algorithm by a quantitative analysis. The proposed SISR algorithm uses a total of 5000 training CDT images (low-resolution and high-resolution) and a fully CNN based on residual structure. The image performance was analyzed using various parameters, such as intensity profile (full width at half maximum), contrast to noise ratio, coefficient of variation, and normalized noise power spectrum parameters, and the results demonstrated that the proposed SISR algorithm significantly improves the spatial resolution of the images. Further, the noise properties of the images obtained with the SISR algorithm were similar to those of the low-resolution images with up-sampling. Thus, we successfully developed the deep learning architectures in this study to improve the spatial resolution of the CDT reconstructed images.","Single image super-resolution algorithm,Deep learning,Deep convolutional neural network,Chest digital tomosynthesis,Quantitative evaluation of image performance",Article,"ELSEVIER GMBH, HACKERBRUCKE 6, 80335 MUNICH, GERMANY",Optics,,,"RECONSTRUCTION,ALGORITHMS,RADIATION,CT",OPTIK,,
49,Dynamic time warping-based transfer learning for improving common spatial patterns in brain-computer interface,17,1,,"Azab Ahmed M.,Ahmadi Hamed,Mihaylova Lyudmila,Arvaneh Mahnaz","Azab AM,Ahmadi H,Mihaylova L,Arvaneh M",Azab AM,10.1088/1741-2552/ab64a0,University of Sheffield,"Objective. Common spatial patterns (CSP) is a prominent feature extraction algorithm in motor imagery (MI)-based brain-computer interfaces (BCIs). However, CSP is computed using sample-based covariance-matrix estimation. Hence, its performance deteriorates if the number of training trials is small. To address this problem, this paper proposes a novel regularized covariance matrix estimation framework for CSP (i.e. DTW-RCSP) based on dynamic time warping (DTW) and transfer learning. Approach. The proposed framework combines the subject-specific covariance matrix (Sigma(ss)) estimated using the available trials from the new subject, with a novel DTW-based transferred covariance matrix (Sigma(DTW)) estimated using previous subjects' trials. In the proposed Sigma(DTW), the available labelled trials from the previous subjects are temporally aligned to the average of the available trials of the new subject from the same class using DTW. This alignment aims to reduce temporal variations and non-stationarities between previous subjects' trials and the available trials from the new subjects. Moreover, to tackle the problem of regularization parameter selection when only a few trials are available for training, an online method is proposed, where the best regularization parameter is selected based on the confidence scores of the trained classifier on the upcoming first few labelled testing trials. Main results. The proposed framework is evaluated on two datasets against two baseline algorithms. The obtained results reveal that DTW-RCSP significantly outperformed the baseline algorithms at various testing scenarios, particularly, when only a few trials are available for training. Significance. Impressively, our results show that successful BCI interactions could be achieved with a calibration session as small as only one trial per class.","brain-computer interface,common spatial pattern,transfer learning,calibration time",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"EEG,FILTERS",JOURNAL OF NEURAL ENGINEERING,https://eprints.whiterose.ac.uk/155443/1/Azab%2Bet%2Bal_2019_J._Neural_Eng._10.1088_1741-2552_ab64a0.pdf,
50,Hyperparameter-tuned prediction of somatic symptom disorder using functional near-infrared spectroscopy-based dynamic functional connectivity,17,1,,"Eken Aykut,Colak Burcin,Bal Nese Burcu,Kusman Adnan,Kizilpinar Selma Cilem,Akaslan Damla Sayar,Baskak Bora","Eken A,Colak B,Bal NB,Kusman A,Kizilpinar SC,Akaslan DS,Baskak B",Eken A,10.1088/1741-2552/ab50b2,Barcelona Institute of Science & Technology,"Objective. Somatic symptom disorder (SSD) is a reflection of medically unexplained physical symptoms that lead to distress and impairment in social and occupational functioning. SSD is phenomenologically diagnosed and its neurobiology remains unsolved. Approach. In this study, we performed hyper-parameter optimized classification to distinguish 19 persistent SSD patients and 21 healthy controls by utilizing functional near-infrared spectroscopy via performing two painful stimulation experiments, individual pain threshold (IND) and constant sub-threshold (SUB) that include conditions with different levels of pain (INDc and SUBc) and brush stimulation. We estimated a dynamic functional connectivity time series by using sliding window correlation method and extracted features from these time series for these conditions and different cortical regions. Main results. Our results showed that we found highest specificity (85%) with highest accuracy (82%) and 81% sensitivity using an SVM classifier by utilizing connections between right superior temporal-left angular gyri, right middle frontal (MFG)-left supramarginal gyri and right middle temporal- left middle frontal gyri from the INDc condition. Significance. Our results suggest that fNIRS may distinguish subjects with SSD from healthy controls by applying pain in levels of individual pain-threshold and bilateral MFG, left inferior parietal and right temporal gyrus might be robust biomarkers to be considered for SSD neurobiology.","somatic symptom disorder,fNIRS,machine learning,dynamic functional connectivity,hyperparameter optimization",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"SOMATOFORM,PAIN,DISORDER,MEDIAL,PREFRONTAL,CORTEX,VERBAL,FLUENCY,TASK,SOMATIZATION,DISORDER,CORTISOL,RESPONSES,EEG,SYSTEM,VON-FREY,ANXIETY,CLASSIFICATION,FIBROMYALGIA",JOURNAL OF NEURAL ENGINEERING,http://repositori.upf.edu/bitstream/10230/43925/1/eken_jneutraleng_hyper.pdf,
51,fNIRS-GANs: data augmentation using generative adversarial networks for classifying motor tasks from functional near-infrared spectroscopy,17,1,,"Nagasawa Tomoyuki,Sato Takanori,Nambu Isao,Wada Yasuhiro","Nagasawa T,Sato T,Nambu I,Wada Y",Nambu I,10.1088/1741-2552/ab6cb9,Nagaoka University of Technology,"Objective. Functional near-infrared spectroscopy (fNIRS) is expected to be applied to brain-computer interface (BCI) technologies. Since lengthy fNIRS measurements are uncomfortable for participants, it is difficult to obtain enough data to train classification models; hence, the fNIRS-BCI accuracy decreases. Approach. In this study, to improve the fNIRS-BCI accuracy, we examined an fNIRS data augmentation method using Wasserstein generative adversarial networks (WGANs). Using fNIRS data during hand-grasping tasks, we evaluated whether the proposed data augmentation method could generate artificial fNIRS data and improve the classification performance using support vector machines and simple neural networks. Main results. Trialaveraged temporal profiles of WGAN-generated fNIRS data were similar to those of the measured data except that they contained an extra noise component. By augmenting the generated data to training data, the accuracies for classifying four different task types were improved irrespective of the classifiers. Significance. This result suggests that the artificial fNIRS data generated by the proposed data augmentation method is useful for improving BCI performance.","data augmentation,functional near-infrared spectroscopy,brain-computer interface,Wasserstein generative adversarial networks,support vector machine,neural networks",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"CLASSIFICATION,IMAGERY,SIGNALS",JOURNAL OF NEURAL ENGINEERING,https://doi.org/10.1088/1741-2552/ab6cb9,
52,Deep DoseNet: a deep neural network for accurate dosimetric transformation between different spatial resolutions and/or different dose calculation algorithms for precision radiation therapy,65,3,,"Dong Peng,Xing Lei","Dong P,Xing L",Xing L,10.1088/1361-6560/ab652d,Stanford University,"The purpose of this work is to introduce a novel deep learning strategy to obtain highly accurate dose plan by transforming from a dose distribution calculated using a low-cost algorithm (or algorithmic settings).
25 168 slices of dose distribution are calculated using Eclipse treatment planning system V15.6 (Varian Medical Systems, Palo Alto, CA) on ten patient CTs whose treatment sites ranging from lung, brain, abdomen and pelvis, with a grid size of 1.25 x 1.25 x 1.25 mm using both anisotropic analytical algorithm (AAA) in 5 mm resolution and Acuros XB algorithm (AXB) in 1.25 mm resolution. The AAA dose slices, and the corresponding down sampled CT slices are combined to form a tensor with a size of 2 x 64 x 64, working as the input to the deep learning-based dose calculation network (deep DoseNet), which outputs the calculated Acuros dose with a size of 256 x 256. The deep DoseNet (DDN) consists of a feature extraction component and an upscaling part. The DDN converges after similar to 100 epochs with a learning rate of 10(-4), using ADAM.
We compared up sampled AAA dose and DDN output with that of AXB. For the evaluation set, the average mean-square-error decreased from 4.7 x 10(-4) between AAA and AXB to 7.0 x 10(-5) between DDN and AXB, with an average improvement of similar to 12 times. The average Gamma index passing rate at 3mm3% improved from 76% between AAA and AXB to 91% between DDN and AXB. The average calculation time is less than 1 ms for a single slice on a NVIDIA DGX workstation.
DDN, trained with a large amount of dosimetric data, can be employed as a general-purpose dose calculation acceleration engine across various dose calculation algorithms.","deep learning,dose calculation,image super resolution,dose super resolution,treatment planning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,,"MONTE-CARLO,RADIOTHERAPY,TREATMENT,ACUROS,XB,SYSTEM,MODEL",PHYSICS IN MEDICINE AND BIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7115345,
53,A deep learning approach to radiation dose estimation,65,3,,"Goetz Th I,Schmidkonz C.,Chen S.,Al-Baddai S.,Kuwert T.,Lang E. W.","Gotz TI,Schmidkonz C,Chen S,Al-Baddai S,Kuwert T,Lang EW",Gotz TI,10.1088/1361-6560/ab65dc,University of Erlangen Nuremberg,"Currently methods for predicting absorbed dose after administering a radiopharmaceutical are rather crude in daily clinical practice. Most importantly, individual tissue density distributions as well as local variations of the concentration of the radiopharmaceutical are commonly neglected. The current study proposes machine learning techniques like Green's function-based empirical mode decomposition and deep learning methods on U-net architectures in conjunction with soft tissue kernel Monte Carlo (MC) simulations to overcome current limitations in precision and reliability of dose estimations for clinical dosimetric applications. We present a hybrid method (DNN-EMD) based on deep neural networks (DNN) in combination with empirical mode decomposition (EMD) techniques. The algorithm receives x-ray computed tomography (CT) tissue density maps and dose maps, estimated according to the MIRD protocol, i.e. employing whole organ S-values and related time-integrated activities (TIAs), and from measured SPECT distributions of Lu-177 radionuclei, and learns to predict individual absorbed dose distributions. In a second step, density maps are replaced by their intrinsic modes as deduced from an EMD analysis. The system is trained using individual full MC simulation results as reference. Data from a patient cohort of 26 subjects are reported in this study. The proposed methods were validated employing a leave-one-out cross-validation technique. Deviations of estimated dose from corresponding MC results corroborate a superior performance of the newly proposed hybrid DNN-EMD method compared to its related MIRD DVK dose calculation. Not only are the mean deviations much smaller with the new method, but also the related variances are much reduced. If intrinsic modes of the tissue density maps are input to the algorithm, variances become even further reduced though the mean deviations are less affected. The newly proposed hybrid DNN-EMD method for individualized radiation dose prediction outperforms the MIRD DVK dose calculation method. It is fast enough to be of use in daily clinical practice.","Monte Carlo simulation,dosimetry,Lu-therapy,neural network",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"S-VALUES,SIMULATIONS,FRAMEWORK",PHYSICS IN MEDICINE AND BIOLOGY,,
54,Automatic detection of brachytherapy seeds in 3D ultrasound images using a convolutional neural network,65,3,,"Golshan Maryam,Karimi Davood,Mahdavi Sara,Lobo Julio,Peacock Michael,Salcudean Septimiu E.,Spadinger Ingrid","Golshan M,Karimi D,Mahdavi S,Lobo J,Peacock M,Salcudean SE,Spadinger I",Golshan M,10.1088/1361-6560/ab64b5,University of British Columbia,"A novel approach for automatic localization of brachytherapy seeds in 3D transrectal ultrasound (TRUS) images, using machine learning based algorithm, is presented.
3D radiofrequency ultrasound signals were collected from 13 patients using the linear array of the TRUS probe during the brachytherapy procedure in which needles are used for insertion of stranded seeds. Gold standard for the location of seeds on TRUS data were obtained with the guidance of the complete reconstruction of the seed locations from multiple C-arm fluoroscopy views and used in the creation of the training set. We designed and trained a convolutional neural network (CNN) model that worked on 3D cubical sub-regions of the TRUS images, that will be referred to as patches, representing seed, non-seed within a needle track and non-seed elsewhere in the images. The models were trained with these patches to detect the needle track first and then the individual seeds within the needle track. A leave-one-out cross validation approach was used to test the model on the data from eight of the patients, for whom accurate seed locations were available from fluoroscopic imaging.
The total inference time was about 7 min for needle track detection in each patient's image and approximately 1 min for seed detection in each needle, leading to a total seed detection time of less than 15 min. Our seed detection algorithm achieved 78% +/- 8% precision, 64% +/- 10% recall and 70% +/- 8% F1_score.
The results from our CNN-based method were compared to manual seed localization performed by an expert. The CNN model yielded higher precision (lower false discovery rate) compared to the manual method. The automated approach requires little modification to the current clinical setups and offers the prospect of application in real time intraoperative dosimetric analysis of the implant.","convolutional neural network (CNN),prostate brachytherapy,3D ultrasound imaging,brachytherapy seed",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"TRUS,IMAGES,PROSTATE,LOCALIZATION,RECONSTRUCTION",PHYSICS IN MEDICINE AND BIOLOGY,,
55,Male pelvic multi-organ segmentation aided by CBCT-based synthetic MRI,65,3,,"Lei Yang,Wang Tonghe,Tian Sibo,Dong Xue,Jani Ashesh B.,Schuster David,Curran Walter J.,Patel Pretesh,Liu Tian,Yang Xiaofeng","Lei Y,Wang TH,Tian SB,Dong X,Jani AB,Schuster D,Curran WJ,Patel P,Liu T,Yang XF",Yang XF,10.1088/1361-6560/ab63bb,Emory University,"To develop an automated cone-beam computed tomography (CBCT) multi-organ segmentation method for potential CBCT-guided adaptive radiation therapy workflow.
The proposed method combines the deep leaning-based image synthesis method, which generates magnetic resonance images (MRIs) with superior soft-tissue contrast from on-board setup CBCT images to aid CBCT segmentation, with a deep attention strategy, which focuses on learning discriminative features for differentiating organ margins. The whole segmentation method consists of 3 major steps. First, a cycle-consistent adversarial network (CycleGAN) was used to estimate a synthetic MRI (sMRI) from CBCT images. Second, a deep attention network was trained based on sMRI and its corresponding manual contours. Third, the segmented contours for a query patient was obtained by feeding the patient's CBCT images into the trained sMRI estimation and segmentation model. In our retrospective study, we included 100 prostate cancer patients, each of whom has CBCT acquired with prostate, bladder and rectum contoured by physicians with MRI guidance as ground truth. We trained and tested our model with separate datasets among these patients. The resulting segmentations were compared with physicians' manual contours.
The Dice similarity coefficient and mean surface distance indices between our segmented and physicians' manual contours (bladder, prostate, and rectum) were 0.95 +/- 0.02, 0.44 +/- 0.22 mm, 0.86 +/- 0.06, 0.73 +/- 0.37 mm, and 0.91 +/- 0.04, 0.72 +/- 0.65 mm, respectively.
We have proposed a novel CBCT-only pelvic multi-organ segmentation strategy using CBCT-based sMRI and validated its accuracy against manual contours. This technique could provide accurate organ volume for treatment planning without requiring MR images acquisition, greatly facilitating routine clinical workflow.","CBCT,deep learning,segmentation,adaptive radiotherapy",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"DEFORMABLE,IMAGE,REGISTRATION,CONTOUR,PROPAGATION,RADIATION-THERAPY,PLANNING,CT,RADIOTHERAPY",PHYSICS IN MEDICINE AND BIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7042793,
56,External validation and transfer learning of convolutional neural networks for computed tomography dental artifact classification,65,3,,"Welch Mattea L.,McIntosh Chris,Traverso Alberto,Wee Leonard,Purdie Tom G.,Dekker Andre,Haibe-Kains Benjamin,Jaffray David A.","Welch ML,McIntosh C,Traverso A,Wee L,Purdie TG,Dekker A,Haibe-Kains B,Jaffray DA",Welch ML,10.1088/1361-6560/ab63ba,University of Toronto,"Quality assurance of data prior to use in automated pipelines and image analysis would assist in safeguarding against biases and incorrect interpretation of results. Automation of quality assurance steps would further improve robustness and efficiency of these methods, motivating widespread adoption of techniques. Previous work by our group demonstrated the ability of convolutional neural networks (CNN) to efficiently classify head and neck (H& N) computed-tomography (CT) images for the presence of dental artifacts (DA) that obscure visualization of structures and the accuracy of Hounsfield units. In this work we demonstrate the generalizability of our previous methodology by validating CNNs on six external datasets, and the potential benefits of transfer learning with fine-tuning on CNN performance. 2112 H& N CT images from seven institutions were scored as DA positive or negative. 153(8) images from a single institution were used to train three CNNs with resampling grid sizes of 64(3), 128(3) and 256(3). The remaining six external datasets were used in five-fold cross-validation with a data split of 20% training/fine-tuning and 80% validation. The three pre-trained models were each validated using the five-folds of the six external datasets. The pre-trained models also underwent transfer learning with fine-tuning using the 20% training/finetuning data, and validated using the corresponding validation datasets. The highest micro-averaged AUC for our pre-trained models across all external datasets occurred with a resampling grid of 256(3) (AUC = 0.91 +/- 0.01). Transfer learning with fine-tuning improved generalizability when utilizing a resampling grid of 256(3) to a micro-averaged AUC of 0.92 +/- 0.01. Despite these promising results, transfer learning did not improve AUC when utilizing small resampling grids or small datasets. Our work demonstrates the potential of our previously developed automated quality assurance methods to generalize to external datasets. Additionally, we showed that transfer learning with fine-tuning using small portions of external datasets can be used to fine-tune models for improved performance when large variations in images are present.","computed tomography,dental artifacts,quality assurance,deep learning,external validation",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"RADIATION-THERAPY,HEAD,SEGMENTATION,CANCER,RADIOTHERAPY,REDUCTION",PHYSICS IN MEDICINE AND BIOLOGY,https://cris.maastrichtuniversity.nl/ws/files/74763253/Dekker_2020_External_validation_and_transfer_learning.pdf,
57,A novel deep learning model using dosimetric and clinical information for grade 4 radiotherapy-induced lymphopenia prediction,65,3,,"Zhu Cong,Lin Steven H.,Jiang Xiaoqian,Xiang Yang,Belal Zayne,Jun Goo,Mohan Radhe","Zhu C,Lin SH,Jiang XQ,Xiang Y,Belal Z,Jun G,Mohan R",Zhu C; Mohan R,10.1088/1361-6560/ab63b6,University of Texas System,"Radiotherapy-induced lymphopenia has increasingly been shown to reduce cancer survivorship. We developed a novel hybrid deep learning model to efficiently integrate an entire set of dosimetric parameters of a radiation treatment plan with a patient's pre- and mid-treatment information to improve the prediction of grade 4 radiotherapy-induced lymphopenia.
We proposed a two-input channel hybrid deep learning model to process dosimetric information using a stacked bi-directional long-short term memory structure and non-dosimetric information using a multilayer perceptron structure independently before integrating the dosimetric and non-dosimetric information for final prediction. The model was trained from 505 patients and tested in 216 patients. We compared our model with other popular predictive models, including logistic regression (with and without elastic-net regularization) random forest, support vector machines, and artificial neural network.
Our hybrid deep learning model out-performed other predictive models in various evaluation metrics. It achieved the highest area under the curve at 0.831, accuracy at 0.769, F1 score at 0.631, precision at 0.670, and recall at 0.610. The hybrid deep learning model also demonstrated robustness in exploiting the value of dosimetric parameters in predictive modeling.
We demonstrated that our hybrid deep learning model with a two-input channel structure, which addressed the sequential and inter-correlated nature of dosimetric parameters, could potentially improve the prediction of radiotherapy-induced lymphopenia. Our proposed deep learning framework is flexible and transferable to other related radiotherapy-induced toxicities.","deep learning,recurrent neural network,radiotherapy,lymphopenia,dose volume histogram,esophageal cancer",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"IONIZING-RADIATION,SURVIVAL,OUTCOMES,VOLUME,REGULARIZATION,THERAPY",PHYSICS IN MEDICINE AND BIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7501732,
58,Insights from machine learning of carbon electrodes for electric double layer capacitors,157,,147-152,"Zhou Musen,Gallegos Alejandro,Liu Kun,Dai Sheng,Wu Jianzhong","Zhou MS,Gallegos A,Liu K,Dai S,Wu JZ",Wu JZ,10.1016/j.carbon.2019.08.090,University of California System,"Recent years have witnessed the broad use of carbon electrodes for electric double layer capacitors (EDLCs) because of large surface area, high porosity and low cost. Whereas experimental investigations are mostly focused on the device performance, computational studies have been rarely concerned with electrochemical properties at conditions remote from equilibrium, limiting their direct applications to materials design. Through a comprehensive analysis of extensive experimental data with various machine-learning methods, we report herein quantitative correlations between the structural features of carbon electrodes and the in-operando behavior of EDLCs including energy and power density. Machine learning allows us to identify important characteristics of activated carbons useful to optimize their efficiency in energy storage. (C) 2019 Elsevier Ltd. All rights reserved.","METAL-ORGANIC FRAMEWORKS,ACTIVATED CARBONS,SURFACE-AREA,PREDICTION,PERFORMANCE,ADSORPTION,LIMITS,SIZES,SHELL",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Chemistry,Materials Science",,8.719,"METAL-ORGANIC,FRAMEWORKS,ACTIVATED,CARBONS,SURFACE-AREA,PREDICTION,PERFORMANCE,ADSORPTION,LIMITS,SIZES,SHELL",CARBON,https://www.sciencedirect.com/science/article/am/pii/S0008622319308723,
59,Machine learning-based design of porous graphene with low thermal conductivity,157,,262-269,"Wan Jing,Jiang Jin-Wu,Park Harold S.","Wan J,Jiang JW,Park HS",Jiang JW,10.1016/j.carbon.2019.10.037,Shanghai University,"The thermal conductivity of two-dimensional materials like graphene can efficiently be tuned by introducing holes, in which the density and distribution of the holes are the key parameters. Furthermore, the distribution of holes can induce a variation as high as 74% in the thermal conductivity for porous graphene with a given density of holes. Therefore, an existing challenge is to find the optimal distribution of holes that can minimize or maximize the thermal conductivity of porous graphene as the design space expands dramatically with increasing hole density. We therefore apply an inverse design methodology based on machine learning to reveal the relationship between hole distribution and thermal conductivity reduction in monolayer graphene. The methodology reveals that holes that are randomly distributed transverse to the direction of heat flow, but that exhibit some periodicity along the direction of heat flow, represent the optimal distribution to minimizing the thermal conductivity for porous graphene. Lattice dynamics calculations and wave packet simulations reveal that this spatial distribution effectively causes localization of the phonon modes in porous graphene, which reduces the thermal conductivity. Overall, this work demonstrates the power of machine learning-based design approaches to efficiently obtain new physical insights for scientific problems of interest. (C) 2019 Elsevier Ltd. All rights reserved.","THERMOELECTRIC PROPERTIES,DYNAMICS,ALGORITHMS",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Chemistry,Materials Science",,8.719,"THERMOELECTRIC,PROPERTIES,DYNAMICS,ALGORITHMS",CARBON,,
60,Intelligent-ReaxFF: Evaluating the reactive force field parameters with machine learning,172,,,"Guo Feng,Wen Yu-Shi,Feng Shi-Quan,Li Xiao-Dong,Li Heng-Shuai,Cui Shou-Xin,Zhang Zhen-Rong,Hu Hai-Quan,Zhang Gui-Qing,Cheng Xin-Lu","Guo F,Wen YS,Feng SQ,Li XD,Li HS,Cui SX,Zhang ZR,Hu HQ,Zhang GQ,Cheng XL",Wen YS,10.1016/j.commatsci.2019.109393,Chinese Academy of Engineering Physics,"Machine learning has been widely used in quantum chemistries, such as data mining in quantum mechanics calculation and representations of potential energy surface by neural networks. In this study, we report our efforts on the optimization of the ReaxFF parameters with machine learning frameworks. Although deep neural network potentials like High-Dimensional Neural Network Potentials (HDNNP) have achieved much success in applications such as materials modeling, factors like the memory usage, training time, and accuracies are still problems when the training data set is big. On the other hand, classical potentials like ReaxFF and REBO does not have these problems, and a combination of two is an ideal solution. Machine learning has generated techniques such as automatic differentiation and backpropagation, with which we can optimize deep neural networks or complexed interatomic potentials like ReaxFF. With the TensorFlow coding platform, we have constructed an Intelligent ReaxFF (I-ReaxFF) model with terms of matrix (or tensor) operations that can optimize ReaxFF parameters automatically with gradient-based optimizers like adaptive moment solver (Adam) and back-propagations. As inherited from TensorFlow, one significant feature of our code is the GPU acceleration. The training speed can be five times faster with GPU acceleration than pure CPU calculation. Another feather is that it can directly use the ab initio molecular dynamics trajectories with surrounding periodic images as training data, therefore, allowing the data set can be prepared with ease.","Neural network,Parameterization,ReaxFF,Materials modeling,Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"NEURAL-NETWORK,POTENTIALS,OPTIMIZATION,ENERGY,TRANSFERABILITY,SIMULATIONS,MECHANICS,FRAMEWORK",COMPUTATIONAL MATERIALS SCIENCE,,
61,A multi-fidelity information-fusion approach to machine learn and predict polymer bandgap,172,,,"Patra Abhirup,Batra Rohit,Chandrasekaran Anand,Kim Chiho,Tran Doan Huan,Ramprasad Rampi","Patra A,Batra R,Chandrasekaran A,Kim C,Huan TD,Ramprasad R",Ramprasad R,10.1016/j.commatsci.2019.109286,University System of Georgia,"The fidelity of data is of paramount importance in the construction of reliable and accurate machine learning (ML) models. Low-fidelity data, although noisy, can usually be obtained for a large number of material samples. High-fidelity data, on the other hand, is time-consuming and oftentimes, only available for a limited number of target samples. While the former can provide useful information to help generalize the ML models over large materials space, the latter is useful to build more accurate surrogate models. Information fusion schemes that utilize the data available at multiple levels of fidelity can outperform traditional single fidelity based ML methods, such as Gaussian process regression. In this work, a variant of the multi-fidelity information fusion scheme, namely multi-fidelity co-kriging, is used to build powerful prediction models of polymer bandgaps. To benchmark this strategy, we utilize a bandgap dataset of 382 polymers, obtained at two levels of fidelity: using the Perdew-Burke-Ernzerhof (PBE) exchange-correlational functional (""low-fidelity"") and the Heyd-Scuseria-Ernzerhof (HSE06) functional(""high-fidelity"") of density functional theory. The multi-fidelity model, trained on both PBE and HSE06 data, outperforms a single-fidelity Gaussian process regression model trained on just HSE06 band-gaps in a number of scenarios and is also able to generalize better to a more diverse chemical space.","Density functional theory,Machine learning,Multi-fidelity learning,Polymers,Bandgap",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"APPROXIMATION,POTENTIALS",COMPUTATIONAL MATERIALS SCIENCE,,
62,Application of fuzzy learning in the research of binary alloys: Revisit and validation,172,,,"Zhang Huiran,Zhou Gaofeng,Li Shengzhou,Fan Xingyue,Guo Zhiting,Xu Tao,Xu Yan,Chen Xue,Dai Dongbo,Qian Quan","Zhang HR,Zhou GF,Li SZ,Fan XY,Guo ZT,Xu T,Xu Y,Chen X,Dai DB,Qian Q",Zhang HR,10.1016/j.commatsci.2019.109350,Shanghai University,"Hume-Rothery rules, occupying a central space at the heart of metallurgy, are one of the most important rules in materials science. One limitation to the binary alloys is the lack of predictable tools for understanding the relationship between alloy structure and solid solubility. In this paper, with Hume-Rothery rules, we demonstrated the proposed method could be used to give quantitative analysis of solid solubility. Then a hybrid Fuzzy-SVM (Support Vector Machines) method is proposed to predict solid solubility of binary alloy systems. In the study of silver and copper alloy, our methods successfully revealed the understandable relationship between structures (atom size, valency, and electronegativity) and properties (solid solubility). A similar fuzzy rule like H-R's 15% rule was found and an estimation to the solid solubility was given.","Binary alloys,Hume-rothery rules,Fuzzy learning,Fuzzy rules,Support vector machines",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"HUME-ROTHERY,RULES,SOLID,SOLUBILITY,CLASSIFICATION,PREDICTION,SILVER",COMPUTATIONAL MATERIALS SCIENCE,,
63,"An inventory-driven rock glacier status model (intact vs. relict) for South Tyrol, Eastern Italian Alps",350,,,"Kofler Christian,Steger Stefan,Mair Volkmar,Zebisch Marc,Comiti Francesco,Schneiderbauer Stefan","Kofler C,Steger S,Mair V,Zebisch M,Comiti F,Schneiderbauer S",Kofler C,10.1016/j.geomorph.2019.106887,European Academy of Bozen-Bolzano,"Ice presence in rock glaciers is a topic that is likely to gain importance in the future due to the expected decrease in water supply from glaciers and the increase of mass movements originating in periglacial areas. This makes it important to have at ones disposal inventories with complete information on the state of rock glaciers. This study presents a method to overcome incomplete information on the status of rock glaciers (i.e. intact vs. relict) recorded in regional scale inventories. The proposed data-driven modelling framework can be used to estimate the likelihood that rock glaciers contain frozen material. Potential predictor variables related to topography, environmental controls or the rock glacier appearance were derived from a digital terrain model (DTM), satellite data and gathered from existing data sets. An initial exploratory data analysis supported the heuristic selection of predictor variables. Three classification algorithms, namely logistic regression (GLM), support vector machine (SVM) and random forest (RF), were trained on the basis of the available information on the status of rock glaciers within the territory of South Tyrol (Eastern Italian Alps). The resulting classification rules led to assign a binary label - intact or relict - to 235 unclassified rock glaciers present in the inventory. All models were validated quantitatively on spatially-independent test samples (spatial cross validation) and achieved highly satisfactory performance scores. Hereby, the less flexible statistically-based classifier (GLM) performed slightly better than the more flexible machine learning algorithms (SVM and RF). Spatial permutation-based variable importance assessment revealed that elevation and vegetation cover (based on NDVI) were the most relevant predictors. For more than 80% of the unclassified rock glaciers, all of the three models agreed on the spatially predicted rock glacier status. Only for a minor portion (12.3%), one model differed from the remaining two. (C) 2019 The Authors. Published by Elsevier B.V.","Machine learning,Probabilistic modelling,Permafrost,Classification algorithms,Rock glacier inventory,Rock glacier activity",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Physical Geography,Geology",,4.623,"PERMAFROST,DISTRIBUTION,REGIONAL,INVENTORY,PROTALUS,RAMPARTS,RANDOM,FORESTS,R,PACKAGE,CLASSIFICATION,VALIDATION,TOPOGRAPHY,MORPHOLOGY,RESOLUTION",GEOMORPHOLOGY,http://collections.unu.edu/eserv/UNU:7750/Journal_Article_GLOMOS_ScS_October2019_META.pdf,
64,Smoothed self-organizing map for robust clustering,512,,381-401,"D'Urso Pierpaolo,De Giovanni Livia,Massari Riccardo","D'Urso P,De Giovanni L,Massari R",De Giovanni L,10.1016/j.ins.2019.06.038,Luiss Guido Carli University,"In this paper a Self-Organizing Map (SOM) robust to the presence of outliers, the Smoothed SOM (S-SOM), is proposed. S-SOM improves the properties of input density mapping, vector quantization, and clustering of the standard SOM in the presence of outliers by upgrading the learning rule in order to smooth the representation of outlying input vectors onto the map. The upgrade of the learning rule is based on the complementary exponential distance between the input vector and its closest codebook. The convergence of the S-SOM to a stable state is proved. Three comparative simulation studies and a suggestive application to digital innovation data show the robustness and effectiveness of the proposed S-SOM. Supplementary materials for this article are available. (C) 2019 Published by Elsevier Inc.","Robust SOM,Outliers,Clustering,Exponential distance,Robust learning rule,Digital innovation,Social network analysis,Twitter",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA",Computer Science,,6.524,"VECTOR,QUANTIZATION,ALGORITHM,DENSITY",INFORMATION SCIENCES,,
65,A novel scalable method for machine degradation assessment using deep convolutional neural network,151,,,"Li Pin,Jia Xiaodong,Feng Jianshe,Zhu Feng,Miller Marcella,Chen Liang-Yu,Lee Jay","Li P,Jia XD,Feng JS,Zhu F,Miller M,Chen LY,Lee J",Li P; Jia XD,10.1016/j.measurement.2019.107106,University of Cincinnati,"Bandsaw machines are widely used in the rough machining stage to cut various materials into required dimensions. Deterioration on the blade, which is a critical component of the bandsaw machine, not only causes a waste of cutting material but also represents a major portion of the operation & maintenance cost for the machine user. Although non-high-end manufactures put as much emphasis on the accuracy of the cuts as high-end manufacturers, non-high-end bandsaw machine users are not as easily able to justify the high cost associated with the blade wear monitoring solution. Therefore, this paper proposes a methodology to develop a scalable blade degradation model that is suitable for massive deployment at an affordable cost. A 4-stage roadmap is proposed to provide step by step guidance in the development and deployment of the scalable blade degradation model. As the core issue of the roadmap, the degradation model development is solved by the proposed dual-phase modeling methodology. In phase I, a physics informed model (which relies on physical analysis to extract effective features) is established to generate a reliable health indicator (HI) to monitor the blade wear condition utilizing the critical vibration and acoustic signals. Phase II proposes to develop a deep convolutional neural network (DCNN) based surrogate model to replace the physics informed model. The DCNN based surrogate model will use only alternative low-cost sensor data. By eliminating the usage of the high-cost vibration and acoustic sensors, the developed surrogate model is expected to cost much less than the physics informed model. Finally, the effectiveness of the proposed methodology is validated using data from different bandsaw machines and blades, and the superior performance of the DCNN is observed as compared to traditional machine learning algorithms. (C) 2019 Elsevier Ltd. All rights reserved.","Degradation assessment,Deep convolutional neural network,Prognostics and health management,Bandsaw machine,Blade wear",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Instruments & Instrumentation",,3.778,"CUTTING-TOOL,WEAR,TEETH",MEASUREMENT,,
66,Research on the damage prediction method of offshore wind turbine tower structure based on improved neural network,151,,,"Qiu Binbin,Lu Yang,Sun Liping,Qu Xianqiang,Xue Yanzhuo,Tong Fushan","Qiu BB,Lu Y,Sun LP,Qu XQ,Xue YZ,Tong FS",Lu Y,10.1016/j.measurement.2019.107141,Harbin Engineering University,"Tower structure is a basic part of offshore wind power system, and how to ensure the stability and safety of tower structure in wind turbine operation and develop the efficient and accurate damage prediction method to judge the damage location and degree of tower structure has become an important research topic in the offshore wind power industry. With high adaptability, nonlinearity and strong function approximation ability, Artificial neural network (ANN) has been widely used in structural damage prediction and showed better performance than other diagnostic methods, however, traditional Back Propagation neural network (BPNN) has shortcomings of complex training parameters and low accuracy. To address this issue, this paper considered an improved neural network damage prediction method based on step-by-step identification for offshore wind turbine tower structure, an experimental research was carried out to simplify wind turbine model and experimentally measure the intact steel cylinders with different damage locations and different damage degrees. Then, the modal analysis was carried out by using the numerical analysis method and the results were compared with those of experimental measurement to modify the model. The training data are generated by Abaqus software to verify the proposed method. Results showed that the step-by-step prediction method could effectively reduce the complexity of the network, improve the prediction accuracy of the neural network, and save the training time. (C) 2019 Elsevier Ltd. All rights reserved.","Offshore wind turbine,Damage prediction,ANN,Generalized regression neural network,Genetic algorithm",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Instruments & Instrumentation",,3.778,"OPERATIONAL,MODAL-ANALYSIS,VIBRATION,SIGNALS,FAULT-DIAGNOSIS,RELIABILITY,SUPPORT",MEASUREMENT,,
67,DScribe: Library of descriptors for machine learning in materials science,247,,,"Himanen Lauri,Jager Marc O. J.,Morooka Eiaki V,Canova Filippo Federici,Ranawat Yashasvi S.,Gao David Z.,Rinke Patrick,Foster Adam S.","Himanen L,Jager MOJ,Morooka EV,Canova FF,Ranawat YS,Gao DZ,Rinke P,Foster AS",Himanen L,10.1016/j.cpc.2019.106949,Aalto University,"DScribe is a software package for machine learning that provides popular feature transformations (""descriptors"") for atomistic materials simulations. DScribe accelerates the application of machine learning for atomistic property prediction by providing user-friendly, off-the-shelf descriptor implementations. The package currently contains implementations for Coulomb matrix, Ewald sum matrix, sine matrix, Many-body Tensor Representation (MBTR), Atom-centered Symmetry Function (ACSF) and Smooth Overlap of Atomic Positions (SOAP). Usage of the package is illustrated for two different applications: formation energy prediction for solids and ionic charge prediction for atoms in organic molecules. The package is freely available under the open-source Apache License 2.0.
Program summary
Program Title: DScribe
Program Files doi: http://dx.doLorg/10.17632/vzrs8n8pk6.1
Licensing provisions: Apache-2.0
Programming language: Python/C/C++
Supplementary material: Supplementary Information as PDF
Nature of problem: The application of machine learning for materials science is hindered by the lack of consistent software implementations for feature transformations. These feature transformations, also called descriptors, are a key step in building machine learning models for property prediction in materials science.
Solution method: We have developed a library for creating common descriptors used in machine learning applied to materials science. We provide an implementation the following descriptors: Coulomb matrix, Ewald sum matrix, sine matrix, Many-body Tensor Representation (MBTR), Atom centered Symmetry Functions (ACSF) and Smooth Overlap of Atomic Positions (SOAP). The library has a python interface with computationally intensive routines written in C or C++. The source code, tutorials and documentation are provided online. A continuous integration mechanism is set up to automatically run a series of regression tests and check code coverage when the codebase is updated. (C) 2019 The Authors. Published by Elsevier B.V.","Machine learning,Materials science,Descriptor,Python,Open source",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Physics",,4.722,"SIMULATIONS,POTENTIALS,MOLECULES,DESIGN",COMPUTER PHYSICS COMMUNICATIONS,https://mediatum.ub.tum.de/doc/1553866/document.pdf,
68,Ultrafast magnetic resonance spectroscopic imaging using SPICE with learned subspaces,83,2,377-390,"Lam Fan,Li Yudu,Guo Rong,Clifford Bryan,Liang Zhi-Pei","Lam F,Li YD,Guo R,Clifford B,Liang ZP",Liang ZP,10.1002/mrm.27980,University of Illinois System,"Purpose: To develop a subspace learning method for the recently proposed subspace-based MRSI approach known as SPICE, and achieve ultrafast H-1-MRSI of the brain.
Theory and Methods: A novel strategy is formulated to learn a low-dimensional subspace representation of MR spectra from specially acquired training data and use the learned subspace for general MRSI experiments. Specifically, the subspace learning problem is formulated as learning ""empirical"" distributions of molecule-specific spectral parameters (e.g., concentrations, lineshapes, and frequency shifts) by integrating physics-based model and the training data. The learned spectral parameters and quantum mechanical simulation basis can then be combined to construct acquisition-specific subspace for spatiospectral encoding and processing. High-resolution MRSI acquisitions combining ultrashort-TE/short-TR excitation, sparse sampling, and the elimination of water suppression have been performed to evaluate the feasibility of the proposed method.
Results: The accuracy of the learned subspace and the capability of the proposed method in producing high-resolution 3D H-1 metabolite maps and high-quality spatially resolved spectra (with a nominal resolution of similar to 2.4 x 2.4 x 3 mm(3) in 5 minutes) were demonstrated using phantom and in vivo studies. By eliminating water suppression, we are also able to extract valuable information from the water signals for data processing (B-0 map, frequency drift, and coil sensitivity) as well as for mapping tissue susceptibility and relaxation parameters.
Conclusions: The proposed method enables ultrafast H-1-MRSI of the brain using a learned subspace, eliminating the need of acquiring subject-dependent navigator data (known as D-1) in the original SPICE technique. It represents a new way to perform MRSI experiments and an important step toward practical applications of high-resolution MRSI.","MR spectroscopic imaging,no water suppression,rapid spatiospectral encoding,subspace learning,union-of-subspaces model",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"HIGH-RESOLUTION,H-1-MRSI,CHEMICAL-SHIFT,HUMAN,BRAIN,ACQUISITION,H-1-NMR,MODEL,MRSI,RECONSTRUCTION,REMOVAL,SPEED",MAGNETIC RESONANCE IN MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6824949,
69,A deep learning method for image-based subject-specific local SAR assessment,83,2,695-711,"Meliado E. F.,Raaijmakers A. J. E.,Sbrizzi A.,Steens B. R.,Maspero M.,Savenije M. H. F.,Luijten P. R.,van den Berg C. A. T.","Meliado EF,Raaijmakers AJE,Sbrizzi A,Steens BR,Maspero M,Savenije MHF,Luijten PR,van den Berg CAT",Meliado EF,10.1002/mrm.27948,Utrecht University,"Purpose: Local specific absorption rate (SAR) cannot be measured and is usually evaluated by offline numerical simulations using generic body models that of course will differ from the patient's anatomy. An additional safety margin is needed to include this intersubject variability. In this work, we present a deep learning-based method for image-based subject-specific local SAR assessment. We propose to train a convolutional neural network to learn a ""surrogate SAR model"" to map the relation between subject-specific B-1(+) maps and the corresponding local SAR.
Method: Our database of 23 subject-specific models with an 8-transmit channel body array for prostate imaging at 7 T was used to build 5750 training samples. These synthetic complex B-1(+) maps and local SAR distributions were used to train a conditional generative adversarial network. Extra penalization for local SAR underestimation errors was included in the loss function. In silico and in vivo validation were performed.
Results: In silico cross-validation shows a good qualitative and quantitative match between predicted and ground-truth local SAR distributions. The peak local SAR estimation error distribution shows a mean overestimation error of 15% with 13% probability of underestimation. The higher accuracy of the proposed method allows the use of less conservative safety factors compared with standard procedures. In vivo validation shows that the method is applicable with realistic measurement data with impressively good qualitative and quantitative agreement to simulations.
Conclusion: The proposed deep learning method allows online image-based subject-specific local SAR assessment. It greatly reduces the uncertainty in current state-of-the-art SAR assessment methods, reducing the time in the examination protocol by almost 25%.","convolutional neural network,deep learning,parallel transmit,specific absorption rate,subject-specific,SAR assessment,ultrahigh-field MRI",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"RATE,INTERSUBJECT,VARIABILITY,PARALLEL,TRANSMISSION,MRI,EXCITATION,DESIGN,POWER",MAGNETIC RESONANCE IN MEDICINE,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mrm.27948,
70,Diagnosis of Obstructive Sleep Apnea Using Speech Signals From Awake Subjects,14,2,251-260,"Simply Ruby Melody,Dafna Eliran,Zigel Yaniv","Simply RM,Dafna E,Zigel Y",Simply RM,10.1109/JSTSP.2019.2955019,Ben Gurion University,"Obstructive sleep apnea (OSA) is a sleep disorder in which pharyngeal collapse during sleep causes complete (apnea) or partial (hypopnea) airway obstruction. OSA is common and can have severe implications, but often remains undiagnosed. The most widely used objective measure of OSA severity is the number of obstructive events per hour of sleep, known as the apnea-hypopnea index (AHI). This study reports an innovative system to identify OSA subjects while they are awake, not asleep, using speech signal processing techniques. The assumption is that OSA affects the acoustic parameters of speech because it is associated with anatomical and functional abnormalities of the upper airway. The system associates three different sub-systems based on features extracted from breathing segments within continuous speech signals, information acquired from sustained vowels using a convolutional neural network, and inherent information in continuous speech signals using a recurrent neural network. Each of these sub-systems provided an AHI estimation and were combined with age and body mass index (BMI) to produce a composite system that estimates AHI using a linear regression. The sample was composed of 398 subjects (men and women). The performance of each sub-system was examined separately, in addition to the composite system. As expected, the composite AHI estimation yielded the superior results, with a Pearson correlation coefficient of 0.61 between the estimated and diagnosed AHI. To distinguish between OSA and non-OSA subjects, a classification decision was made using an AHI threshold of 15 events per hour. The system achieved an average accuracy of 77.14%, a sensitivity of 75%, and a specificity of 79%.","Feature extraction,Sleep apnea,Speech processing,Noise measurement,Indexes,Mel frequency cepstral coefficient,Breath signals,classification,machine learning,neural network,Obstructive sleep apnea (OSA),speech signals,regression,signal processing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,ACCURACY,IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,,
71,Decoding of single-trial EEG reveals unique states of functional brain connectivity that drive rapid speech categorization decisions,17,1,,"Al-Fahad Rakib,Yeasin Mohammed,Bidelman Gavin M.","Al-Fahad R,Yeasin M,Bidelman GM",Bidelman GM,10.1088/1741-2552/ab6040,University of Memphis,"Objective. Categorical perception (CP) is an inherent property of speech perception. The response time (RT) of listeners' perceptual speech identification is highly sensitive to individual differences. While the neural correlates of CP have been well studied in terms of the regional contributions of the brain to behavior, functional connectivity patterns that signify individual differences in listeners' speed (RT) for speech categorization is less clear. In this study, we introduce a novel approach to address these questions. Approach. We applied several computational approaches to the EEG, including graph mining, machine learning (i.e., support vector machine), and stability selection to investigate the unique brain states (functional neural connectivity) that predict the speed of listeners' behavioral decisions. Main results. We infer that (i) the listeners' perceptual speed is directly related to dynamic variations in their brain connectomics, (ii) global network assortativity and efficiency distinguished fast, medium, and slow RTs, (iii) the functional network underlying speeded decisions increases in negative assortativity (i.e., became disassortative) for slower RTs, (iv) slower categorical speech decisions cause excessive use of neural resources and more aberrant information flow within the CP circuitry, (v) slower responders tended to utilize functional brain networks excessively (or inappropriately) whereas fast responders (with lower global efficiency) utilized the same neural pathways but with more restricted organization. Significance. Findings show that neural classifiers (SVM) coupled with stability selection correctly classify behavioral RTs from functional connectivity alone with over 92% accuracy (AUC = 0.9). Our results corroborate previous studies by supporting the engagement of similar temporal (STG), parietal, motor, and prefrontal regions in CP using an entirely data-driven approach.","categorical speech perception,machine learning,speech processing,stability selection,functional connectivity",Article,"IOP Publishing Ltd, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,,"BOUNDARY-ELEMENT,METHOD,AGE-RELATED-CHANGES,CATEGORICAL,PERCEPTION,NEURAL,ORGANIZATION,VARIABLE,SELECTION,CEREBRAL-CORTEX,SEX-DIFFERENCES,REPRESENTATIONS,NETWORKS,REGIONS",JOURNAL OF NEURAL ENGINEERING,https://www.biorxiv.org/content/biorxiv/early/2019/06/28/686048.full.pdf,
72,Determination of material optical properties from diffusive reflection light intensity profiles at multiple distances,7,2,,"Liu Lili,Yin Daheng,Zhu Nanyang,Tan Jinglu,Guo Ya","Liu LL,Yin DH,Zhu NY,Tan JL,Guo Y",Guo Y,10.1088/2053-1591/ab5ef0,Jiangnan University,"Optical absorption and scattering properties are often estimated from the diffusive reflection light intensity at only one distance from the material surface, which often encounters accuracy and convergence issues. In this work, a method was proposed to determine optical properties by using diffusive reflection light intensity profiles at multiple distances, which enhanced data richness as a result of the intensity profiles are linearly independent. In this method, five features of light intensity profiles (contrast, correlation, energy, homogeneity, and second moment) were used to reduce the data dimensions. To demonstrate the effectiveness of the proposed method, Monte Carlo (MC) simulations were used to generate diffusive reflection light intensity profiles with noise at different distances for various combinations of four optical properties (absorption coefficient mu(a), scattering coefficient mu(s), isotropic coefficient g, and refractive index n). The five profile feature vectors were used as inputs and the four optical parameters were used as outputs to train and test a backpropagation (BP) neural network. The influences of noise levels and the number of diffusive light intensity profiles on parameter estimation accuracy were investigated. The four optical parameters estimated by the BP network were compared with the results estimated by the traditional least squares method, which shows that the proposed method can estimate the optical properties with higher accuracy and better convergence.","scattering coefficient,absorption coefficient,isotropic coefficient,refractive index,optical measurement,optical property,neural network",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Materials Science,,1.618,"NEURAL-NETWORK,ABSORPTION,MODEL",MATERIALS RESEARCH EXPRESS,https://doi.org/10.1088/2053-1591/ab5ef0,
73,Classification of Lentigo Maligna at Patient-Level by Means of Reflectance Confocal Microscopy Data,10,8,,"Cendre Romain,Mansouri Alamin,Perrot Jean-Luc,Cinotti Elisa,Marzani Franck","Cendre R,Mansouri A,Perrot JL,Cinotti E,Marzani F",Cendre R,10.3390/app10082830,"Univ Bourgogne Franche Comte, ImViA EA 7535, Dijon 21078, France.","Featured Application This paper focuses on improvement in patient care and it also helps practitioners optimize their dermatology services by means of computer-assisted diagnostic software using data from reflectance confocal microscopy devices.
Abstract Reflectance confocal microscopy is an appropriate tool for the diagnosis of lentigo maligna. Compared with dermoscopy, this device can provide abundant information as a mosaic and/or a stack of images. In this particular context, the number of images per patient varied between 2 and 833 images and the objective, ultimately, is to be able to discern between benign and malignant classes. First, this paper evaluated classification at the image level, with the help of handcrafted methods derived from the literature and transfer learning methods. The transfer learning feature extraction methods outperformed the handcrafted feature extraction methods from literature, with a F-1 score value of 0.82. Secondly, this work proposed patient-level supervised methods based on image decisions and a comparison of these with multi-instance learning methods. This study achieved comparable results to those of the dermatologists, with an auc score of 0.87 for supervised patient diagnosis and an auc score of 0.88 for multi-instance learning patient diagnosis. According to these results, computer-aided diagnosis methods presented in this paper could be easily used in a clinical context to save time or confirm a diagnosis and can be oriented to detect images of interest. Also, this methodology can be used to serve future works based on multimodality.","computer-assisted diagnosis,classification,transfer learning,reflectance confocal microscopy,dermatology,lentigo",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"SKIN-CANCER,DIAGNOSIS,RECOGNITION",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/8/2830/pdf,
74,Optimized Erosion Prediction with MAGA Algorithm Based on BP Neural Network for Submerged Low-Pressure Water Jet,10,8,,"Chen Yanzhen,Hu Yihuai,Zhang Shenglong,Mei Xiaojun,Shi Qingguo","Chen YZ,Hu YH,Zhang SL,Mei XJ,Shi QG",Hu YH,10.3390/app10082926,Shanghai Maritime University,"Featured Application
Underwater cleaning and rock breaking operations of ocean engineering.
Abstract In order to accurately predict the erosion effect of underwater cleaning with an angle nozzle under different working conditions, this paper uses refractory bricks to simulate marine fouling as the erosion target, and studies the optimized erosion prediction model by erosion test based on the submerged low-pressure water jet. The erosion test is conducted by orthogonal experimental design, and experimental data are used for the prediction model. By combining with statistical range and variance analysis methods, the jet pressure, impact time and jet angle are determined as three inputs of the prediction model, and erosion depth is the output index of the prediction model. A virtual data generation method is used to increase the amount of input data for the prediction model. This paper also proposes a Mind-evolved Advanced Genetic Algorithm (MAGA), which has a reliable optimization effect in the verification of four stand test functions. Then, the improved back-propagating (BP) neural network prediction models are established by respectively using Genetic Algorithm (GA) and MAGA optimization algorithms to optimize the initial thresholds and weights of the BP neural network. Compared to the prediction results of the BP and GA-BP models, the R-2 of the MAGA-BP model is the highest, reaching 0.9954; the total error is reduced by 47.31% and 35.01%; the root mean square error decreases by 51.05% and 31.80%; and the maximum absolute percentage error decreases by 65.79% and 64.01%, respectively. The average prediction accuracy of the MAGA-BP model is controlled within 3%, which has been significantly improved. The results show that the prediction accuracy of the MAGA-BP prediction model is higher and more reliable, and the MAGA algorithm has a good optimization effect. This optimized erosion prediction method is feasible.","submerged water jet,genetic algorithm,mind evolutionary,BP neural network prediction,orthogonal experimental design,cavitation erosion",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"CAVITATION,SIMULATION,IMPACT,NOZZLE,FIELD",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/8/2926/pdf,
75,Development of Equipment and Application of Machine Learning Techniques Using Frequency Response Data for Cap Damage Detection of Porcelain Insulators,10,8,,"Choi In Hyuk,Koo Ja Bin,Son Ju Am,Yi Jun Sin,Yoon Young Geun,Oh Tae Keun","Choi IH,Koo JB,Son JA,Yi JS,Yoon YG,Oh TK",Yoon YG; Oh TK,10.3390/app10082820,Incheon National University,"The most common method for inspection of insulators is to measure the change of electrical characteristics such as electric resistance and partial discharge. However, even if there is no physical damage, these values vary depending on the temperature, humidity, and chloride content of the atmosphere. In this respect, an alternative to such methods can be the impact response test, and a frequency response function (FRF) obtained from the test has been widely used as a tool for damage detection. In this study the FRF was applied to identify the cap damage of porcelain insulators. In addition, to solve the danger of high voltage and poor field accessibility near the insulator, a device with high field applicability was developed to measure FRF from a long distance using an auto impact hammer and Micro Electro Mechanical Systems (MEMS) technology. Even though the FRF is most suitable for inspection of porcelain insulators, dynamic characteristics such as natural frequencies may vary depending on manufacturing errors, installation conditions, etc., which may cause difficulties in damage identification. To overcome this limitation, the machine learning (ML) method was applied in this study to provide a diagnostic method that ensured consistent and accurate judgment. As a result of predicting the normal and the cap damage data using the support vector machine (SVM), bagging, k-nearest neighbor (kNN), and discriminant analysis (DA) methods, the overall F1 score was over 87% and the bagging method achieved the highest accuracy. In this study, the frequency range and dynamic characteristics that are sensitive to the physical damage of the insulator were derived and, based on this, the optimum ML methods with improved equipment could provide analysis with higher accuracy and consistency than general analysis using the FRF.","frequency response function,porcelain insulator,cap,auto impact hammer,MEMS,non-destructive method,damage detection,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"SILICONE-RUBBER,CLASSIFICATION,DENSITY",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/8/2820/pdf,
76,A Transfer Learning Method for Pneumonia Classification and Visualization,10,8,,"Eduardo Lujan-Garcia Juan,Yanez-Marquez Cornelio,Villuendas-Rey Yenny,Camacho-Nieto Oscar","Lujan-Garcia JE,Yanez-Marquez C,Villuendas-Rey Y,Camacho-Nieto O",Yanez-Marquez C,10.3390/app10082908,Instituto Politecnico Nacional - Mexico,"Featured Application
We aim to present an automatic tool to classify between chest diseases such as pneumonia and healthy patients to assist a medical diagnosis even when there are not available expert radiologists.
Abstract Pneumonia is an infectious disease that affects the lungs and is one of the principal causes of death in children under five years old. The Chest X-ray images technique is one of the most used for diagnosing pneumonia. Several Machine Learning algorithms have been successfully used in order to provide computer-aided diagnosis by automatic classification of medical images. For its remarkable results, the Convolutional Neural Networks (models based on Deep Learning) that are widely used in Computer Vision tasks, such as classification of injuries and brain abnormalities, among others, stand out. In this paper, we present a transfer learning method that automatically classifies between 3883 chest X-ray images characterized as depicting pneumonia and 1349 labeled as normal. The proposed method uses the Xception Network pre-trained weights on ImageNet as an initialization. Our model is competitive with respect to state-of-the-art proposals. To make comparisons with other models, we have used four well-known performance measures, obtaining the following results: precision (0.84), recall (0.99), F1-score (0.91) and area under the ROC curve (0.97). These positive results allow us to consider our proposal as an alternative that can be useful in countries with a lack of equipment and specialized radiologists.","transfer learning,pneumonia,classification,X-ray,convolutional,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"COMPUTER-AIDED,DIAGNOSIS,DEEP",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/8/2908/pdf,
77,"A Smart Terrain Identification Technique Based on Electromyography, Ground Reaction Force, and Machine Learning for Lower Limb Rehabilitation",10,8,,"Gao Shuo,Wang Yixuan,Fang Chaoming,Xu Lijun","Gao S,Wang YX,Fang CM,Xu LJ",Fang CM,10.3390/app10082638,Beihang University,"Automatic terrain classification in lower limb rehabilitation systems has gained worldwide attention. In this field, a simple system architecture and high classification accuracy are two desired attributes. In this article, a smart neuromuscular-mechanical fusion and machine learning-based terrain classification technique utilizing only two electromyography (EMG) sensors and two ground reaction force (GRF) sensors is reported for classifying three different terrains (downhill, level, and uphill). The EMG and GRF signals from ten healthy subjects were collected, preprocessed and segmented to obtain the EMG and GRF profiles in each stride, based on which twenty-one statistical features, including 9 GRF features and 12 EMG features, were extracted. A support vector machine (SVM) machine learning model is established and trained by the extracted EMG features, GRF features and the fusion of them, respectively. Several methods or statistical metrics were used to evaluate the goodness of the proposed technique, including a paired-t-test and Kruskal-Wallis test for correlation analysis of the selected features and ten-fold cross-validation accuracy, confusion matrix, sensitivity and specificity for the performance of the SVM model. The results show that the extracted features are highly correlated with the terrain changes and the fusion of the EMG and GRF features produces the highest accuracy of 96.8%. The presented technique allows simple system construction to achieve the precise detection of outcomes, potentially advancing the development of terrain classification techniques for rehabilitation.","terrain classification,electromyography,ground reaction force,feature extraction,multi-sensor fusion",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"WALKING,LOCOMOTION,EXOSKELETON,CLASSIFICATION,NORMALIZATION,RECOGNITION,RELIABILITY,TECHNOLOGY,PARAMETERS,STRATEGIES",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/8/2638/pdf,
78,Machine Learning Classifiers Evaluation for Automatic Karyogram Generation from G-Banded Metaphase Images,10,8,,"Hernandez-Mier Yahir,Aurelio Nuno-Maganda Marco,Polanco-Martagon Said,del Refugio Garcia-Chavez Maria","Hernandez-Mier Y,Nuno-Maganda MA,Polanco-Martagon S,Garcia-Chavez MD",Hernandez-Mier Y,10.3390/app10082758,"Polytech Univ Victoria, Intelligent Syst Dept, Victoria 87138, Tamaulipas, Mexico.","Featured Application
Results of the methodology described in this work are part of an automatic system to generate a cytogenetic report for the Laboratory of Cytogenetics of the Children's Hospital of Tamaulipas.
Abstract This work proposes the evaluation of a set of algorithms of machine learning and the selection of the most appropriate one for the classification of segmented chromosomes images acquired using the Giemsa staining technique (G-banding). The evaluation and selection of the best classification algorithms was carried out over a dataset of 119 Q-banding chromosomes images, and the obtained results were then applied to a dataset of 24 G-band chromosomes images, manually classified by an expert of the Laboratory of Cytogenetic of the Children's Hospital of Tamaulipas. The results of evaluation of 51 classifiers yielded that the best classification accuracy for the selected features was obtained by a backpropagation neural network. One of the main contributions of this study is the proposal of a two-stage classification scheme based on the best classifier found by the initial evaluation. In stage 1, chromosome images are classified into three major groups. In stage 2, the output of phase 1 is used as the input of a multiclass classifier. Using this scheme, 82% of the IGB bank samples and 88% of the samples of a bank of images obtained with a Q-band available in the literature consisting of 119 chromosome studies were successfully classified. The proposed work is a part of an desktop application that allows cytogeneticist to automatically generate cytogenetic reports.","machine learning,karyotype,image processing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"CLASSIFICATION,CHROMOSOMES,SEGMENTATION",APPLIED SCIENCES-BASEL,https://res.mdpi.com/d_attachment/applsci/applsci-10-02758/article_deploy/applsci-10-02758-v2.pdf,
79,A Novel Architecture to Classify Histopathology Images Using Convolutional Neural Networks,10,8,,"Kandel Ibrahem,Castelli Mauro","Kandel I,Castelli M",Kandel I,10.3390/app10082929,Universidade Nova de Lisboa,"Histopathology is the study of tissue structure under the microscope to determine if the cells are normal or abnormal. Histopathology is a very important exam that is used to determine the patients' treatment plan. The classification of histopathology images is very difficult to even an experienced pathologist, and a second opinion is often needed. Convolutional neural network (CNN), a particular type of deep learning architecture, obtained outstanding results in computer vision tasks like image classification. In this paper, we propose a novel CNN architecture to classify histopathology images. The proposed model consists of 15 convolution layers and two fully connected layers. A comparison between different activation functions was performed to detect the most efficient one, taking into account two different optimizers. To train and evaluate the proposed model, the publicly available PatchCamelyon dataset was used. The dataset consists of 220,000 annotated images for training and 57,000 unannotated images for testing. The proposed model achieved higher performance compared to the state-of-the-art architectures with an AUC of 95.46%.","histopathology images,deep learning,convolutional neural networks,image classification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/8/2929/pdf,
80,Intelligent Computer-Aided Diagnostic System for Magnifying Endoscopy Images of Superficial Esophageal Squamous Cell Carcinoma,10,8,,"Kim Kwang Baek,Yi Gyeong Yun,Kim Gwang Ha,Song Doo Heon,Jeon Hye Kyung","Kim KB,Yi GY,Kim GH,Song DH,Jeon HK",Kim GH,10.3390/app10082771,Pusan National University,"Predicting the depth of invasion of superficial esophageal squamous cell carcinomas (SESCCs) is important when selecting treatment modalities such as endoscopic or surgical resections. Recently, the Japanese Esophageal Society (JES) proposed a new simplified classification for magnifying endoscopy findings of SESCCs to predict the depth of tumor invasion based on intrapapillary capillary loops with the SESCC microvessels classified into the B1, B2, and B3 types. In this study, a four-step classification method for SESCCs is proposed. First, Niblack's method was applied to endoscopy images to select a candidate region of microvessels. Second, the background regions were delineated from the vessel area using the high-speed fast Fourier transform and adaptive resonance theory 2 algorithm. Third, the morphological characteristics of the vessels were extracted. Based on the extracted features, the support vector machine algorithm was employed to classify the microvessels into the B1 and non-B1 types. Finally, following the automatic measurement of the microvessel caliber using the proposed method, the non-B1 types were sub-classified into the B2 and B3 types via comparisons with the caliber of the surrounding microvessels. In the experiments, 114 magnifying endoscopy images (47 B1-type, 48 B2-type, and 19 B3-type images) were used to classify the characteristics of SESCCs. The accuracy, sensitivity, and specificity of the classification into the B1 and non-B1 types were 83.3%, 74.5%, and 89.6%, respectively, while those for the classification of the B2 and B3 types in the non-B1 types were 73.1%, 73.7%, and 72.9%, respectively. The proposed machine learning based computer-aided diagnostic system could obtain the objective data by analyzing the pattern and caliber of the microvessels with acceptable performance. Further studies are necessary to carefully validate the clinical utility of the proposed system.","computer-aided diagnosis,esophageal cancer,magnifying endoscopy,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"CLASSIFICATION,DEPTH,SVM",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/8/2771/pdf,
81,Remaining Useful Strength (RUS) Prediction of SiCf-SiCm Composite Materials Using Deep Learning and Acoustic Emission,10,8,,"Louis Steph-Yves M.,Nasiri Alireza,Bao Jingjing,Cui Yuxin,Zhao Yong,Jin Jing,Huang Xinyu,Hu Jianjun","Louis SYM,Nasiri A,Bao JJ,Cui YX,Zhao Y,Jin J,Huang XY,Hu JJ",Hu JJ,10.3390/app10082680,University of South Carolina System,"Prognosis techniques for prediction of remaining useful life (RUL) are of crucial importance to the management of complex systems for they can lead to appropriate maintenance interventions and improvements in reliability. While various data-driven methods have been introduced to predict the remaining useful life (RUL) of machinery systems or batteries, no research has been reported on the remaining useful strength (RUS) prediction of silicon carbide fiber reinforced silicon carbide matrix (SiCf-SiCm) materials with pivotal role in its potential usage as a structural material in nuclear reactors and turbine engines. Knowledge of its degradation process is of the utmost importance to the manufacturers. For this purpose, two approaches based on the machine-learning techniques of random-forest (RF) and convolutional neural network (CNN) are proposed to predict the RUS of SiCf-SiCm using only acoustic emission (AE) signals generated during the material's stress applying process. Experimental results show that the CNN models achieved better predictive performance than the RF models but the latter with expert-engineered features achieves better prediction for AE signals in the early stage of degradation. Additionally, our results demonstrate that both models can correctly predict the SiCf-SiCm RUS as evaluated by our robust testing method from which the best average root mean square error (RMSE) and Pearson correlation coefficient of 3.55 ksi units and 0.85 were obtained.","remaining useful strength,remaining useful life,silicon carbide fiber reinforced silicon carbide matrix,acoustic emission,random-forest,convolutional neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"INDENTATION,PROGNOSTICS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/8/2680/pdf,
82,An Unsupervised Regularization and Dropout based Deep Neural Network and Its Application for Thermal Error Prediction,10,8,,"Tian Yang,Pan Guangyuan","Tian Y,Pan GY",Pan GY,10.3390/app10082870,University of Waterloo,"Due to the large size of the heavy duty machine tool-foundation systems, space temperature difference is high related to thermal error, which affects to system's accuracy greatly. The recent highly focused deep learning technology could be an alternative in thermal error prediction. In this paper, a thermal prediction model based on a self-organizing deep neural network (DNN) is developed to facilitate accurate-based training for thermal error modeling of heavy-duty machine tool-foundation systems. The proposed model is improved in two ways. Firstly, a dropout self-organizing mechanism for unsupervised training is developed to prevent co-adaptation of the feature detectors. In addition, a regularization enhanced transfer function is proposed to further reduce the less important weights of the process and improve the network feature extraction capability and generalization ability. Furthermore, temperature sensors are used to acquire temperature data from the heavy-duty machine tool and concrete foundation. In this way, sample data of thermal error predictive model are repeatedly collected from the same locations at different times. Finally, accuracy of the thermal error prediction model was validated by thermal error experiments, thus laying the foundation for subsequent studies on thermal error compensation.","heavy duty machine tool,foundation,thermal error,self-organizing deep belief network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"LARGE,MACHINE-TOOLS,COMPENSATION,DISTORTION,DEFORMATION",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/8/2870/pdf,
83,A risk prediction model of DNA methylation improves prognosis evaluation and indicates gene targets in prostate cancer,12,4,333-352,"Zhang Enchong,Hou Xueying,Hou Baoxian,Zhang Mo,Song Yongsheng","Zhang EC,Hou XY,Hou BX,Zhang M,Song YS",Zhang M; Song YS,10.2217/epi-2019-0349,China Medical University,"Aim: Prostate cancer (PCa) is the most common malignancy found in males worldwide. Although it is mostly indolent, PCa still poses a serious threat to long-term health. Materials & methods: The Cancer Genome Atlas data were randomly divided into training and validation groups. Least absolute shrinkage and selection operator regression on DNA methylation data in the training group was conducted to build the model, which was validated in the validation group. Weighted correlation network analysis was conducted on RNA-seq data to identify the therapy target. Functional validation (western blot, quantitative real-time PCR, cell transfection, Cell Counting Kit-8 assay, colony formation assay, wound healing assay and transwell invasion assay) for the target was conducted. Results: The model is an independent predictor of prognosis. The knockdown of FOXD1 inhibits cell proliferation, migration and invasion of PCa. Conclusion: The risk of patients could be evaluated by the model, which revealed that FOXD1 might promote poor prognosis.","DNA methylation,LASSO,prognosis,prostate cancer,TCGA,WGCNA",Article,"FUTURE MEDICINE LTD, UNITEC HOUSE, 3RD FLOOR, 2 ALBERT PLACE, FINCHLEY CENTRAL, LONDON, N3 1QB, ENGLAND",Genetics & Heredity,,5.53,"SURVIVAL,ANALYSIS,EVENT,OSTEOSARCOMA,INHIBITION,REGIONS,PLA2G7",EPIGENOMICS,https://www.futuremedicine.com/doi/pdf/10.2217/epi-2019-0349,
84,Convolutional neural network approach for automatic tympanic membrane detection and classification,56,,,"Basaran Erdal,Comert Zafer,Celik Yuksel","Basaran E,Comert Z,Celik Y",Comert Z,10.1016/j.bspc.2019.101734,"Merkez Sokak 40-2-1, TR-55080 Canik Samsun, Turkey.","Otitis media (OM) is a term used to describe the inflammation of the middle ear. The clinical inspection of the tympanic membrane is conducted visually by experts. Visual inspection leads to limited variability among the observers and includes human-induced errors. In this study, we sought to solve these problems using a novel diagnostic model based on a faster regional convolutional neural network (Faster R-CNN) for tympanic membrane detection, and pre-trained CNNs for tympanic membrane classification. The experimental study was conducted on a new eardrum dataset. The Faster R-CNN was initially applied to the original images. The number of images in the dataset was subsequently increased using basic image augmentation techniques such as flip and rotation. We also evaluated the success of the model in the presence of various noise effects. The original and automatically extracted tympanic membrane patches were finally input separately to the CNNs. The AlexNet, VGGNets, GoogLeNet, and ResNets models were employed. This resulted in an average precision of 75.85% in the tympanic membrane detection. All CNNs in the classification produced satisfactory results, with the proposed approach achieving an accuracy of 90.48% with the VGG-16 model. This approach can potentially be used in future otological clinical decision support systems to increase the diagnostic accuracy of the physicians and reduce the overall rate of misdiagnosis. Future studies will focus on increasing the number of samples in the eardrum dataset to cover a full range of ontological conditions. This would enable us to realize a multi-class classification in OM diagnosis. (C) 2019 Elsevier Ltd. All rights reserved.","Biomedical signal processing,Clinical decision support system,Otitis media,Tympanic membrane detection,Convolutional neural network,Classification",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,"ACUTE,OTITIS-MEDIA,DIAGNOSIS,CHILDREN,MANAGEMENT,PEDIATRICIANS",BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
85,A novel data augmentation method to enhance deep neural networks for detection of atrial fibrillation,56,,,"Cao Ping,Li Xinyi,Mao Kedong,Lu Fei,Ning Gangmin,Fang Luping,Pan Qing","Cao P,Li XY,Mao KD,Lu F,Ning GM,Fang LP,Pan Q",Pan Q,10.1016/j.bspc.2019.101675,Zhejiang University of Technology,"Automated detection of atrial fibrillation (AF) from electrocardiogram (ECG) recordings remains challenging in real clinical settings. Deep neural networks (DNN) emerge as a promising tool for the task of AF detection. However, the success of DNN for AF detection is hampered by limited size and imbalanced number of samples in datasets. We propose a novel data augmentation strategy based on duplication, concatenation and resampling of ECG episodes to balance the number of samples among different categories as well as to increase the diversity of samples. The performance of the data augmentation method was examined on an AF database from Computing in Cardiology (CinC) challenge 2017. A 2-layer long short-term memory (LSTM) network was trained with the augmented dataset. Its ability of AF detection was evaluated using a 10-fold cross validation approach. And F1 score was adopted as the metrics. The AF detection results show that the proposed method was superior to two conventional data augmentation methods: window slicing and permutation. The network was also submitted to the evaluation system of the CinC challenge 2017. The F1 score obtained by the network using the proposed data augmentation method was close to the winner (0.82 vs. 0.83). In summary, the proposed data augmentation method provides an effective solution to enhance the dataset for improving the performance of DNN in ECG analysis. Such a method promotes the application of deep learning in the analysis of ECG, particularly when the dataset is small and imbalanced. (C) 2019 Elsevier Ltd. All rights reserved.","Atrial fibrillation,Electrocardiogram,Deep neural networks,Data augmentation",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,"ELECTROCARDIOGRAM,PREVALENCE,RISK",BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
86,Differential diagnosis of Parkinson and essential tremor with convolutional LSTM networks,56,,,"Oktay Ayse Betul,Kocer Abdulkadir","Oktay AB,Kocer A",Oktay AB,10.1016/j.bspc.2019.101683,Istanbul Medeniyet University,This study aims to present a novel method for differentiation of Parkinsonian tremor (PT) and essential tremor (ET) using both postural and resting tremor. A convolutional long short-term memory (LSTM) that learns hand tremor recorded at both postural and resting positions is proposed for differentiation of PT and ET. 3D landmark points of hands at resting and postural positions are gathered using a Leap Motion Controller. A convolutional LSTM is trained for differentiation of ET and PT after preprocessing tremor data. The method is evaluated and tested on a dataset containing 40 subjects where 23 of them had PT and 17 of them had ET. The experiments showed that the accuracy of combined positions using both resting and postural tremor was higher than using single kind of positional tremor. The accuracy of tremor classification is 90% for the combined positions. (C) 2019 Elsevier Ltd. All rights reserved.,"LSTM,Leap motion controller,Deep learning,Essential tremor,Parkinson's tremor,CNN",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,"NEURAL-NETWORKS,RESTING,TREMOR,DISEASE,PREVALENCE",BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
87,Deep learning approach for ECG-based automatic sleep state classification in preterm infants,56,,,"Werth Jan,Radha Mustafa,Andriessen Peter,Aarts Ronald M.,Long Xi","Werth J,Radha M,Andriessen P,Aarts RM,Long X",Long X,10.1016/j.bspc.2019.101663,Philips,"Preterm infant neuronal development is related to the distribution of their sleep states. The distribution changes throughout development. Automated sleep state monitoring can become a powerful aid for development monitoring in preterm infants. Three datasets including 34 preterm infants and a total of 18,018 30s manually annotated sleep intervals (sleep-epochs) were analyzed in this study. The annotation of sleep states includes active sleep, quiet sleep, intermediate sleep, wake, and caretaking. Four different recurrent neuronal network architectures were compared for two-state, three-state, and allstate analysis. A sequential network was used to compare long- and short-term memory and gated recurrent unit models. The other network architectures were based on the popular ResNet and ResNext architectures utilizing residual connection for more depth. The most essential sleep states, active and quiet sleep, could be separated with a kappa of 0.43 +/- 0.08. Quiet versus caretaking and wake showed a kappa of 0.44 +/- 0.01. The three state classifications of active versus quiet versus intermediate sleep resulted in a kappa of 0.35 +/- 0.07 and active versus quiet versus wake and caretaking resulted in a kappa of 0.33 +/- 0.04. The all-state classification was underperforming with probably due to difficulty in separating subtle differences between all states and a lack of sufficient training data for the minority classes. (C) 2019 Elsevier Ltd. All rights reserved.","Preterm infants,Sleep,Automated sleep state classification,Electrocardiography,Deep learning,Recurrent neural networks,Long short-term memory,Gated recurrent unit",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,"INTERRATER,RELIABILITY,ARCHITECTURE,MODEL",BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
88,Decoding human brain activity with deep learning,56,,,"Zheng Xiao,Chen Wanzhong,Li Mingyang,Zhang Tao,You Yang,Jiang Yun","Zheng X,Chen WZ,Li MY,Zhang T,You Y,Jiang Y",Chen WZ,10.1016/j.bspc.2019.101730,Jilin University,"Building a brain-computer fusion system that would integrate biological intelligence and machine intelligence became a research topic of great concern. Recent research has proved that human brain activity can be decoded from neurological data. Meanwhile, deep learning has become an effective way to solve practical problems.
Taking advantage of these trends, in this paper, we propose a novel method of decoding brain activity evoked by visual stimuli. To achieve this goal, we first introduce a combined long short-term memory-convolutional neural network (LSTM-CNN) architecture to extract the compact category-dependent representations of electroencephalograms (EEG). Our approach combines the ability of LSTM to extract sequential features and the capability of CNN to distil local features. Next, we employ an improved spectral normalization generative adversarial network (SNGAN) to conditionally generate images using the learned EEG features. We evaluate our approach in terms of the classification accuracy of EEG and the quality of the generated images.
The results show that the proposed LSTM-CNN algorithm that discriminates the object classes by using EEG can be more accurate than the existing methods. In qualitative and quantitative tests, the improved SNGAN performs better in the task of generating conditional images from the learned EEG representations; the produced images are realistic and highly resemble the original images.
Our method can reconstruct the content of visual stimuli according to the brain's response. Therefore, it helps to decode the human brain activity by using an image-EEG-image transformation. (C) 2019 Elsevier Ltd. All rights reserved.","Brain-computer fusion,Deep learning,EEG,Brain decoding",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,"EEG,CLASSIFICATION",BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
89,A robust time-dependent model of alkali-silica reaction at different temperatures,106,,,"Allahyari Hamed,Heidarpour Amin,Shayan Ahmad,Vinh Phu Nguyen","Allahyari H,Heidarpour A,Shayan A,Nguyen VP",Heidarpour A,10.1016/j.cemconcomp.2019.103460,Monash University,"Alkali-Silica-Reaction (ASR) is one of the most deteriorating phenomena in concrete structures. This study uses a machine learning approach (i.e. Artificial Neural Network) to provide further insight into ASR. The approach combines chemo-mechanical and kinetics-based approaches to develop a time- and temperature-dependent model of ASR, which is eventually used in generating user-friendly charts to conveniently assess existing concrete structures. To reach a higher degree of confidence in the precision of the model, an experimental dataset was developed from the laboratory and was combined with a dataset from the literature. A comparison between the developed model and a chemo-mechanical one (Gao's model) showed higher accuracy for the developed model. This higher accuracy was more obvious regarding the specimen with fine single-size aggregate grading. This study also reveals a varying thickness of connected porosity (t(c)) for fine single-size aggregate. Based on the results, aggregate size and t(c) have a coupled effect on the ASR-induced expansion.","Alkali-silica reaction,Concrete,Expansion,Accelerated test,Neural network",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Construction & Building Technology,Materials Science",,8.642,"AGGREGATE,SIZE,COMPRESSIVE,STRENGTH,NEURAL-NETWORK,ASR,EXPANSION,CONCRETE,SYSTEM,PREDICTION,STRAIN,DAMAGE",CEMENT & CONCRETE COMPOSITES,,
90,Industry 4.0 based process data analytics platform: A waste-to-energy plant case study,115,,,"Kabugo James Clovis,Jamsa-Jounela Sirkka-Liisa,Schiemann Robert,Binder Christian","Kabugo JC,Jamsa-Jounela SL,Schiemann R,Binder C",Jamsa-Jounela SL,10.1016/j.ijepes.2019.105508,Aalto University,"Industry 4.0 and Industrial Internet of Things (IIoT) technologies are rapidly fueling data and software solutions driven digitalization in many fields notably in industrial automation and manufacturing systems. Among the several benefits offered by these technologies, is the infrastructure for harnessing big-data, machine learning (ML) and cloud computing software tools, for instance in designing advanced data analytics platforms. Although, this is an area of increased interest, the information concerning the implementation of data analytics in the context of Industry 4.0 is scarcely available in scientific literature. Therefore, this work presents a process data analytics platform built around the concept of industry 4.0. The platform utilizes the state-of-the-art IIoT platforms, ML algorithms and big-data software tools. The platform emphasizes the use of ML methods for process data analytics while leveraging big-data processing tools and taking advantage of the currently available industrial grade cloud computing platforms. The industrial applicability of the platform was demonstrated by the development of soft sensors for use in a waste-to-energy (WTE) plant. In the case study, the work studied data-driven soft sensors to predict syngas heating value and hot flue gas temperature. Among the studied data-driven methods, the neural network-based NARX model demonstrated better performance in the prediction of both syngas heating value and flue gas temperature. The modeling results showed that, in cases where process knowledge about the process phenomena at hand is limited, data-driven soft sensors are useful tools for predictive data analytics.","Data analytics platform,Industrial internet of things platform,Machine learning,Waste-to-energy,Soft sensor",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,4.854,"MUNICIPAL,SOLID-WASTE,SOFT-SENSOR,BIOMASS,GASIFICATION,NOX,EMISSIONS,PREDICTION,MACHINE,OUTPUT,INCINERATION,MODELS",INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS,https://research.aalto.fi/files/36595757/CHEM_Kabugo_et_al_Industry_2020_ElePowEnrSyst.pdf,
91,Logistic regression paradigm for training a single-hidden layer feedforward neural network. Application to gene expression datasets for cancer research,102,,,Belciug Smaranda,Belciug S,Belciug S,10.1016/j.jbi.2019.103373,University of Craiova,"Objective: The speed of the diagnosis process is vital in pursuing the trial of curing cancer. During the last decade, precision medicine evolved by detecting different types of cancer through microarrays (MA) of deoxyribonucleic acid (DNA) processed by machine learning (ML) algorithms. Personalized diagnosis, followed by personalized treatment, should imply personalized hyperparameters of the ML. The goal of this paper is to propose a novel adaptive ML method that embeds knowledge into the architecture of the algorithm and also filters the features in order to reduce their number, increase computational speed, and decrease computational cost and time.
Materials and methods: fLogSLFN is a novel two-fold theoretically effective ML that can be used in two-class decision problems that embeds the logistic regression in such a manner that the hidden nodes of a single-hidden layer feedforward neural network (SLFN) are problem dependent. A filtering module based on the significance of each attribute is embedded in order to avoid the 'curse of dimensionality phenomenon. The proposed model has been tested on three publicly available high-dimensional cancer datasets that contain gene expressions provided by complementary DNA (cDNA) array, and DNA microarray. The proposed novel method filtered logistic SLFN (fLogSLFN) has been also compared and statistically benchmarked to four ML algorithms: extreme learning machine (ELM), radial basis function network (RBF), single-hidden layer feedforward neural network trained by the backpropagation algorithm (BPNN), logistic regression with the LASSO penalty, and the adaptive single-hidden layer feedforward network (aSLFN).
Main findings: The experimental results showed that the fLogSLFN is competitive to the other state-of-the-art models, obtaining accuracies between 64.70% and 98.66% depending on the dataset it had been applied on.
Conclusions: In contrast to other state-of-the-art ML algorithms, the fLogSLFN is capable to embed the knowledge extracted from the data into its architecture, making it problem dependent. The filtering module increases its computational speed, while decreasing computational cost and time. The statistical analysis revealed the fact that by filtering the features the performance is kept, making the algorithm more efficient.","Logistic regression,Single-hidden layer feedforward neural network,Gene expression,Targeted hidden nodes initialization",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Computer Science,Medical Informatics",,5.221,"EXTREME,LEARNING-MACHINE,DIAGNOSIS,ALGORITHM,INITIALIZATION,PROFILES,PANEL,LUNG",JOURNAL OF BIOMEDICAL INFORMATICS,https://doi.org/10.1016/j.jbi.2019.103373,
92,"Task definition, annotated dataset, and supervised natural language processing models for symptom extraction from unstructured clinical notes",102,,,"Steinkamp Jackson M.,Bala Wasif,Sharma Abhinav,Kantrowitz Jacob J.","Steinkamp JM,Bala W,Sharma A,Kantrowitz JJ",Steinkamp JM,10.1016/j.jbi.2019.103354,"25 Dalrymple St 3, Boston, MA 02130 USA.","Introduction: Machine learning (ML) and natural language processing have great potential to improve information extraction (IE) within electronic medical records (EMRs) for a wide variety of clinical search and summarization tools. Despite ML advancements, clinical adoption of real time IE tools for patient care remains low. Clinically motivated IE task definitions, publicly available annotated clinical datasets, and inclusion of subtasks such as coreference resolution and named entity normalization are critical for the development of useful clinical tools.
Materials and methods: We provide a task definition and comprehensive annotation requirements for a clinically motivated symptom extraction task. Four annotators labeled symptom mentions within 1108 discharge summaries from two public clinical note datasets for the tasks of named entity recognition, coreference resolution, and named entity normalization; these annotations will be released to the public. Baseline human performance was assessed and two ML models were evaluated on the symptom extraction task.
Results: 16,922 symptom mentions were identified within the discharge summaries, with 11,944 symptom instances after coreference resolution and 1255 unique normalized answer forms. Human annotator performance averaged 92.2% FI. Recurrent network model performance was 85.6% FI (recall 85.8%, precision 85.4%), and Transformer-based model performance was 86.3% FI (recall 86.6%, precision 86.1%). Our models extracted vague symptoms, acronyms, typographical errors, and grouping statements. The models generalized effectively to a separate clinical note corpus and can run in real time.
Conclusion: To our knowledge, this dataset will be the largest and most comprehensive publicly released, annotated dataset for clinically motivated symptom extraction, as it includes annotations for named entity recognition, coreference, and normalization for more than 1000 clinical documents. Our neural network models extracted symptoms from unstructured clinical free text at near human performance in real time. In this paper, we present a clinically motivated task definition, dataset, and simple supervised natural language processing models to demonstrate the feasibility of building clinically applicable information extraction tools.","Machine learning,Natural language processing,Electronic medical record,Information extraction",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Computer Science,Medical Informatics",,5.221,"ELECTRONIC,HEALTH,RECORD,NAVIGATION,QUALITY",JOURNAL OF BIOMEDICAL INFORMATICS,https://doi.org/10.1016/j.jbi.2019.103354,
93,Deep learning-driven particle swarm optimisation for additive manufacturing energy optimisation,245,,,"Qin Jian,Liu Ying,Grosvenor Roger,Lacan Franck,Jiang Zhigang","Qin J,Liu Y,Grosvenor R,Lacan F,Jiang ZG",Liu Y,10.1016/j.jclepro.2019.118702,Cardiff University,"The additive manufacturing (AM) process is characterised as a high energy-consuming process, which has a significant impact on the environment and sustainability. The topic of AM energy consumption modelling, prediction, and optimisation has then become a research focus in both industry and academia. This issue involves many relevant features, such as material condition, process operation, part and process design, working environment, and so on. While existing studies reveal that AM energy consumption modelling largely depends on the design-relevant features in practice, it has not been given sufficient attention. Therefore, in this study, design-relevant features are firstly examined with respect to energy modelling. These features are typically determined by part designers and process operators before production. The AM energy consumption knowledge, hidden in the design-relevant features, is exploited for prediction modelling through a design-relevant data analytics approach. Based on the new modelling approach, a novel deep learning-driven particle swarm optimisation (DLD-PSO) method is proposed to optimise the energy utility. Deep learning is introduced to address several issues, in terms of increasing the search speed and enhancing the global best of PSO. Finally, using the design-relevant data collected from a real-world AM system in production, a case study is presented to validate the proposed modelling approach, and the results reveal its merits. Meanwhile, optimisation has also been carried out to guide part designers and process operators to revise their designs and decisions in order to reduce the energy consumption of the designated AM system under study. (C) 2019 Elsevier Ltd. All rights reserved.","Additive manufacturing,Energy consumption modelling,Prediction and optimisation,Deep learning,Particle swarm optimisation",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Science & Technology - Other Topics,Engineering,Environmental Sciences & Ecology",,9.444,"GENETIC,ALGORITHM,SUSTAINABILITY,CONSUMPTION,DESIGN,DEMAND,HYBRID,IMPACT,PSO",JOURNAL OF CLEANER PRODUCTION,https://orca.cardiff.ac.uk/125976/1/Liu%20Y%20-%20Deep%20learning-driven%20particle%20swarm%20....pdf,
94,Modelling viscosity of liquid dropout near wellbore region in gas condensate reservoirs using modern numerical approaches,185,,,"Faraji Foad,Ugwu Johnson Obunwa,Chong Perk Lin,Nabhani Farhad","Faraji F,Ugwu JO,Chong PL,Nabhani F",Faraji F,10.1016/j.petrol.2019.106604,University of Teesside,"Liquid dropout occurs in gas condensate reservoirs below the dew point pressure around near wellbore region as a result of depletion from production of such reservoirs. Forecasting production as well as optimizing future recoveries of gas condensate reservoirs are highly desirable. This is not possible to achieve without accurate determination of liquid dropout viscosity (mu(c)) below the dew point. The focus of research in past decades has been on the development of accurate viscosity prediction models below the dew point pressure to ensure accurate condensate production forecast. Gas condensate production forecast and optimization around wellbore region and condition are complicated due to unique gas condensate behaviour that violates thermodynamic laws.
Current methods are based on correlation estimation, however the accuracy of these correlations are less than satisfactory, and root cause is due to the miscapturing of complex behaviour of gas condensate reservoir near the wellbore region. These motivated the consideration of modern numerical approaches such as the Least Square Support Vector Machine (LSSVM) and Artificial Neural Network (ANN) used in this paper. These methods are considered as more data behaviour oriented, with the capability of capturing the fluid complexity of gas condensate in such conditions.
In this study viscosity of condensate phase near the wellbore region was modelled using machine learning techniques including ANN and LSSVM. For this purpose, over 300 viscosity data sets were collected from published literature and experimental studies worldwide. This databank includes API gravity, reservoir temperature, solution gas to oil ratio (Rs), specific gas gravity, fluid compositions and reservoir pressure.
Six well known previously published viscosity correlations refined using least-square approach to match the experimental data. Qualitative and quantitative error analysis of developed LSSVM and ANN showed their performance superiority over refined literature correlations. The new proposed models can be embedded as an extra feature of commercial reservoir simulation packages for optimization and future recoveries of gas condensate reservoirs.","Condensate viscosity,Gas condensate,Least Square Support Vector Machine (LSSVM),Artificial Neural Network (ANN),Correlations",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Energy & Fuels,Engineering",,4.376,"DEW-POINT,PRESSURE,HIGH-TEMPERATURE,NEURAL-NETWORK,PREDICTION,DENSITY,METHANE,CONDUCTIVITY,ALGORITHMS,MIXTURES,SYSTEMS",JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING,https://research.tees.ac.uk/ws/files/8683991/Modelling_viscosity_of_liquid_dropout_near_wellbore_region_in_gas_condensate_reservoirs_using_modern_numerical_approaches.pdf,
95,Permeability prediction and diagenesis in tight carbonates using machine learning techniques,112,,,"Al Khalifah H.,Glover P. W. J.,Lorinczi P.","Al Khalifah H,Glover PWJ,Lorinczi P",Glover PWJ,10.1016/j.marpetgeo.2019.104096,University of Leeds,"Machine learning techniques have found their way into many problems in geoscience but have not been used significantly in the analysis of tight rocks. We present a case study testing the effectiveness of artificial neural networks and genetic algorithms for the prediction of permeability in tight carbonate rocks. The dataset consists of 130 core plugs from the Portland Formation in southern England, all of which have measurements of Klinkenberg-corrected permeability, helium porosity, characteristic pore throat diameter, and formation resistivity. Permeability has been predicted using genetic algorithms and artificial neural networks, as well as seven conventional 'benchmark' models with which the machine learning techniques have been compared. The genetic algorithm technique has provided a new empirical equation that fits the measured permeability better than any of the seven conventional benchmark models. However, the artificial neural network technique provided the best overall prediction method, quantified by the lowest root-mean-square error (RMSE) and highest coefficient of determination value (R-2). The lowest RMSE from the conventional permeability equations was from the RGPZ equation, which predicted the test dataset with an RMSE of 0.458, while the highest RMSE came from the Berg equation, with an RMSE of 2.368. By comparison, the RMSE for the genetic algorithm and artificial neural network methods were 0.433 and 0.38, respectively. We attribute the better performance of machine learning techniques over conventional approaches to their enhanced capability to model the connectivity of pore microstructures caused by codependent and competing diagenetic processes. We also provide a qualitative model for the poroperm characteristics of tight carbonate rocks modified by each of eight diagenetic processes. We conclude that, for tight carbonate reservoirs, both machine learning techniques predict permeability more reliably and more accurately than conventional models and may be capable of distinguishing quantitatively between pore microstructures caused by different diagenetic processes.","Permeability,Neural networks,Genetic algorithms,Machine learning,Tight carbonates,MICP,Porosity,Diagenesis",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Geology,,4.973,"RESERVOIR,MODEL,LOG,CO2",MARINE AND PETROLEUM GEOLOGY,http://eprints.whiterose.ac.uk/152231/1/Machine%20Learning_rev8_unmarked.pdf,
96,Tracing in 2D to reduce the annotation effort for 3D deep delineation of linear structures,60,,,"Kozinski Mateusz,Mosinska Agata,Salzmann Mathieu,Fua Pascal","Kozinski M,Mosinska A,Salzmann M,Fua P",Kozinski M,10.1016/j.media.2019.101590,Ecole Polytechnique Federale de Lausanne,"The difficulty of obtaining annotations to build training databases still slows down the adoption of recent deep learning approaches for biomedical image analysis. In this paper, we show that we can train a Deep Net to perform 3D volumetric delineation given only 2D annotations in Maximum Intensity Projections (MIP) of the training volumes. This significantly reduces the annotation time: We conducted a user study that suggests that annotating 2D projections is on average twice as fast as annotating the original 3D volumes. Our technical contribution is a loss function that evaluates a 3D prediction against annotations of 2D projections. It is inspired by space carving, a classical approach to reconstructing complex 3D shapes from arbitrarily-positioned cameras. It can be used to train any deep network with volumetric output, without the need to change the network's architecture. Substituting the loss is all it takes to enable 2D annotations in an existing training setup. In extensive experiments on 3D light microscopy images of neurons and retinal blood vessels, and on Magnetic Resonance Angiography (MRA) brain scans, we show that, when trained on projection annotations, deep delineation networks perform as well as when they are trained using costlier 3D annotations. (C) 2019 Elsevier B.V. All rights reserved.","Delineation,Segmentation,Deep learning,Nerves,Vessels,Microscopy,Angiography",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,,MEDICAL IMAGE ANALYSIS,,
97,Atrial scar quantification via multi-scale CNN in the graph-cuts framework,60,,,"Li Lei,Wu Fuping,Yang Guang,Xu Lingchao,Wong Tom,Mohiaddin Raad,Firmin David,Keegan Jennifer,Zhuang Xiahai","Li L,Wu FP,Yang G,Xu LC,Wong T,Mohiaddin R,Firmin D,Keegan J,Zhuang XH",Zhuang XH,10.1016/j.media.2019.101595,Fudan University,"Late gadolinium enhancement magnetic resonance imaging (LGE MRI) appears to be a promising alternative for scar assessment in patients with atrial fibrillation (AF). Automating the quantification and analysis of atrial scars can be challenging due to the low image quality. In this work, we propose a fully automated method based on the graph-cuts framework, where the potentials of the graph are learned on a surface mesh of the left atrium (LA) using a multi-scale convolutional neural network (MS-CNN). For validation, we have included fifty-eight images with manual delineations. MS-CNN, which can efficiently incorporate both the local and global texture information of the images, has been shown to evidently improve the segmentation accuracy of the proposed graph-cuts based method. The segmentation could be further improved when the contribution between the t-link and n-link weights of the graph is balanced. The proposed method achieves a mean accuracy of 0.856 +/- 0.033 and mean Dice score of 0.702 +/- 0.071 for LA scar quantification. Compared to the conventional methods, which are based on the manual delineation of LA for initialization, our method is fully automatic and has demonstrated significantly better Dice score and accuracy (p < 0.01). The method is promising and can be potentially useful in diagnosis and prognosis of AF. (C) 2019 The Author(s). Published by Elsevier B.V.","Atrial fibrillation,Left atrium,LGE MRI,Scar segmentation,Graph learning,Multi-scale CNN",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"WHOLE,HEART,SEGMENTATION,CATHETER,ABLATION,PULMONARY,VEIN,FIBRILLATION,MRI,MANAGEMENT,THICKNESS,SELECTION,MODEL,CT",MEDICAL IMAGE ANALYSIS,https://europepmc.org/articles/pmc6988106?pdf=render,
98,Analysis of nonstandardized stress echocardiography sequences using multiview dimensionality reduction,60,,,"Nogueira Mariana,De Craene Mathieu,Sanchez-Martinez Sergio,Chowdhury Devyani,Bijnens Bart,Piella Gemma","Nogueira M,De Craene M,Sanchez-Martinez S,Chowdhury D,Bijnens B,Piella G",Nogueira M,10.1016/j.media.2019.101594,Pompeu Fabra University,"Alternative stress echocardiography protocols such as handgrip exercise are potentially more favorable towards large-scale screening scenarios than those currently adopted in clinical practice. However, these are still underexplored because the maximal exercise levels are not easily quantified and regulated, requiring the analysis of the complete data sequences (thousands of images), which represents a challenging task for the clinician. We propose a framework for the analysis of these complex datasets, and illustrate it on a handgrip exercise dataset including complete acquisitions of 10 healthy controls and 5 ANT1 mutation patients (1377 cardiac cycles). The framework is based on an unsupervised formulation of multiple kernel learning, which is used to integrate information coming from myocardial velocity traces and heart rate to obtain a lower-dimensional representation of the data. Such simplified representation is then explored to discriminate groups of response and understand the underlying pathophysiological mechanisms. The analysis pipeline involves the reconstruction of population-specific signatures using multiscale kernel regression, and the clustering of subjects based on the trajectories defined by their projected sequences. The results confirm that the proposed framework is able to detect distinctive clusters of response and to provide insight regarding the underlying pathophysiology. (C) 2019 Elsevier B.V. All rights reserved.","Multiview dimensionality reduction,Multiple kernel learning,Stress echocardiography,Pattern analysis",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"EXERCISE,DOBUTAMINE,STRAIN",MEDICAL IMAGE ANALYSIS,,
99,Graph temporal ensembling based semi-supervised convolutional neural network with noisy labels for histopathology image analysis,60,,,"Shi Xiaoshuang,Su Hai,Xing Fuyong,Liang Yun,Qu Gang,Yang Lin","Shi XS,Su H,Xing FY,Liang Y,Qu G,Yang L",Shi XS; Yang L,10.1016/j.media.2019.101624,State University System of Florida,"Although convolutional neural networks have achieved tremendous success on histopathology image classification, they usually require large-scale clean annotated data and are sensitive to noisy labels. Unfortunately, labeling large-scale images is laborious, expensive and lowly reliable for pathologists. To address these problems, in this paper, we propose a novel self-ensembling based deep architecture to leverage the semantic information of annotated images and explore the information hidden in unlabeled data, and meanwhile being robust to noisy labels. Specifically, the proposed architecture first creates ensemble targets for feature and label predictions of training samples, by using exponential moving average (EMA) to aggregate feature and label predictions within multiple previous training epochs. Then, the ensemble targets within the same class are mapped into a cluster so that they are further enhanced. Next, a consistency cost is utilized to form consensus predictions under different configurations. Finally, we validate the proposed method with extensive experiments on lung and breast cancer datasets that contain thousands of images. It can achieve 90.5% and 89.5% image classification accuracy using only 20% labeled patients on the two datasets, respectively. This performance is comparable to that of the baseline method with all labeled patients. Experiments also demonstrate its robustness to small percentage of noisy labels. (C) 2019 Elsevier B.V. All rights reserved.","Semi-supervised,Noisy labels,Convolutional neural network,Histopathology image classification",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,,MEDICAL IMAGE ANALYSIS,,
100,In-flight and wireless damage detection in a UAV composite wing using fiber optic sensors and strain field pattern recognition,136,,,"Alvarez-Montoya Joham,Carvajal-Castrillon Alejandro,Sierra-Perez Julian","Alvarez-Montoya J,Carvajal-Castrillon A,Sierra-Perez J",Alvarez-Montoya J,10.1016/j.ymssp.2019.106526,Universidad Pontificia Bolivariana,"Aiming to provide more efficient, lightweight structures, composite materials are being extensively used in aerospace vehicles. As the failure mechanisms of these materials are complex, damage detection becomes challenging, requiring advanced techniques for assessing structural integrity and maintaining aircraft safety. In this context, Structural Health Monitoring (SHM) seeks for integrating sensors into the structures in a way that Nondestructive Testing (NDT) is implemented continuously. One promising approach is to use Fiber Optic Sensors (FOS) to acquire strain signals, taking advantages of their capabilities over conventional sensors. Despite several works have developed Health and Usage Monitoring Systems (HUMS) using FOS for performing in-flight SHM in aircraft structures, automatic damage detection using the acquired signals has not been achieved in a robust way against environmental and operational variability, in all flight stages or considering different types of damages. In this work, a HUMS was developed and implemented in an Unmanned Aerial Vehicle (UAV) based on 20 Fiber Bragg Gratings (FBGs) embedded into the composite front spar of the aircraft's wing, a miniaturized data acquisition subsystem for gathering strain signals and a wireless transmission subsystem for remote sensing. The HUMS was tested in 16 flights, six of them were carried out with the pristine structure and the remaining after inducing different artificial damages. The in-flight data were used to validate a previously developed damage detection methodology based on strain field pattern recognition, or strain mapping, which utilizes machine learning algorithms, specifically a Self-Organizing Map (SOM)-based procedure for clustering operational conditions and Principal Component Analysis (PCA) in conjunction with damage indices for final classification. The performance of the damage detection demonstrated a highest accuracy of 0.981 and a highest F-1 score of 0.978. As a main contribution, this work implements in-flight strain monitoring, remote sensing and automatic damage detection in an operating composite aircraft structure. (C) 2019 Elsevier Ltd. All rights reserved.","Structural health monitoring,Damage detection,Composite materials,Aerospace structures,Machine learning,Remote sensing",Article,"ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD, 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND",Engineering,,6.662,"PRINCIPAL,COMPONENT,ANALYSIS,KERNEL,DENSITY-ESTIMATION,MONITORING-SYSTEM,IDENTIFICATION,VALIDATION,ALGORITHMS",MECHANICAL SYSTEMS AND SIGNAL PROCESSING,,
