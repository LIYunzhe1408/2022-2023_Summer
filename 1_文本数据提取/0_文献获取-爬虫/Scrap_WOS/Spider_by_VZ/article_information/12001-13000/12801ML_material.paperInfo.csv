,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Machine learning for quantum matter,5,1,,Carrasquilla Juan,Carrasquilla J,Carrasquilla J,10.1080/23746149.2020.1797528,University of Toronto,"Quantum matter, the research field studying phases of matter whose properties are intrinsically quantum mechanical, draws from areas as diverse as hard condensed matter physics, materials science, statistical mechanics, quantum information, quantum gravity, and large-scale numerical simulations. Recently, researchers interested in quantum matter and strongly correlated quantum systems have turned their attention to the algorithms underlying modern machine learning with an eye on making progress in their fields. Here we provide a short review on the recent development and adaptation of machine learning ideas for the purpose advancing research in quantum matter, including ideas ranging from algorithms that recognize conventional and topological states of matter in synthetic experimental data, to representations of quantum states in terms of neural networks and their applications to the simulation and control of quantum systems. We discuss the outlook for future developments in areas at the intersection between machine learning and quantum many-body physics.
[GRAPHICS]","Strongly correlated quantum systems,machine learning",Review,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Physics,,7.369,"RESTRICTED,BOLTZMANN,MACHINES,COMPLEX,PHYSICAL,SYSTEMS,NEURAL-NETWORK,SCHRODINGER-EQUATION,PHASE-TRANSITIONS,COMPUTATION,STATES,MODEL,POWER",ADVANCES IN PHYSICS-X,http://arxiv.org/pdf/2003.11040,
2,Computer-Aided Design of Microfluidic Circuits,22,,285-307,Tsur Elishai Ezra,Tsur EE,Tsur EE,10.1146/annurev-bioeng-082219-033358,Open University Israel,"Microfluidic devices developed over the past decade feature greater intricacy, increased performance requirements, new materials, and innovative fabrication methods. Consequentially, new algorithmic and design approaches have been developed to introduce optimization and computer-aided design to microfluidic circuits: from conceptualization to specification, synthesis, realization, and refinement. The field includes the development of new description languages, optimization methods, benchmarks, and integrated design tools. Here, recent advancements are reviewed in the computer-aided design of flow-, droplet-, and paper-based microfluidics. A case study of the design of resistive microfluidic networks is discussed in detail. The review concludes with perspectives on the future of computer-aided microfluidics design, including the introduction of cloud computing, machine learning, new ideation processes, and hybrid optimization.","microfluidics,continuous flow-based microfluidics,design automation,optimization algorithms,resistive microfluidic networks",Review; Book Chapter,"ANNUAL REVIEWS, 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA",Engineering,,16.604,"LARGE-SCALE,INTEGRATION,IMPACT,PAPER,OPTIMIZATION,GENERATION,SYSTEMS,TOOLS,CLOUD",,,
3,CardioLearn: A Cloud Deep Learning Service for Cardiac Disease Detection from Electrocardiogram,,,148-152,"Hong Shenda,Fu Zhaoji,Zhou Rongbo,Yu Jie,Li Yongkui,Wang Kai,Cheng Guanlin","Hong SD,Fu ZJ,Zhou RB,Yu J,Li YK,Wang K,Cheng GL",Hong SD,10.1145/3366424.3383529,"HeartVoice Med Technol, Hefei, Peoples R China.","Electrocardiogram (ECG) is one of the most convenient and non-invasive tools for monitoring peoples' heart condition, which can use for diagnosing a wide range of heart diseases, including Cardiac Arrhythmia, Acute Coronary Syndrome, et al. However, traditional ECG disease detection models show substantial rates of misdiagnosis due to the limitations of the abilities of extracted features. Recent deep learning methods have shown significant advantages, but they do not provide publicly available services for those who have no training data or computational resources.
In this paper, we demonstrate our work on building, training, and serving such out-of-the-box cloud deep learning service for cardiac disease detection from ECG named CardioLearn. The analytic ability of any other ECG recording devices can be enhanced by connecting to the Internet and invoke our open API. As a practical example, we also design a portable smart hardware device along with an interactive mobile program, which can collect ECG and detect potential cardiac diseases anytime and anywhere.","Deep learning,Healthcare,Electrocardiogram",Proceedings Paper,"ASSOC COMPUTING MACHINERY, 1515 BROADWAY, NEW YORK, NY 10036-9998 USA","Computer Science,Telecommunications",,,"ERRORS,RHYTHM",WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020,http://arxiv.org/pdf/2007.02165,
4,"FIMS: Identifying, Predicting and Visualising Food Insecurity",,,190-193,"Nica-Avram Georgiana,Harvey John,Goulding James,Lucas Benjamin,Smith Andrew,Smith Gavin,Perrat Bertrand","Nica-Avram G,Harvey J,Goulding J,Lucas B,Smith A,Smith G,Perrat B",Nica-Avram G,10.1145/3366424.3383538,University of Nottingham,"Food insecurity is a persistent and pernicious problem in the UK. Due to logistical challenges, national food insecurity statistics are unmeasured by government bodies - and this lack of data leads to any local estimates that do exist being routinely questioned by policymakers. We demonstrate a data-driven approach to address this issue, deriving national estimates of food insecurity via combination of supervised machine learning with network analysis of user behaviour, extracted from the world's most popular peer-to-peer food sharing application (OLIO). Despite long-standing theoretical links between social graph topologies and physical neighbourhoods, prior research has not considered dimensions of geography, network interactions and behaviours in the digital/analogue space simultaneously. In addressing this oversight, we produce a browser-based, interactive and rapidly updateable visualisation, which can be used to analyse the spatial distribution of food insecurity across the UK, and provide new perspective for policy research.","Food Insecurity,Hunger,Poverty,Geospatial,Data,Visualization,Computational Social Science",Proceedings Paper,"ASSOC COMPUTING MACHINERY, 1515 BROADWAY, NEW YORK, NY 10036-9998 USA","Computer Science,Telecommunications",,,ACHIEVE,WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020,https://nottingham-repository.worktribe.com/preview/4607560/WWW_final.pdf,
5,Rigorous Connectionist Models to Predict Carbon Dioxide Solubility in Various Ionic Liquids,10,1,,"Ouaer Hocine,Hosseini Amir Hossein,Amar Menad Nait,Ben Seghier Mohamed El Amine,Ghriga Mohammed Abdelfetah,Nabipour Narjes,Andersen Pal Ostebo,Mosavi Amir,Shamshirband Shahaboddin","Ouaer H,Hosseini AH,Amar MN,Ben Seghier ME,Ghriga MA,Nabipour N,Andersen PO,Mosavi A,Shamshirband S",Nabipour N,10.3390/app10010304,Duy Tan University,"Estimating the solubility of carbon dioxide in ionic liquids, using reliable models, is of paramount importance from both environmental and economic points of view. In this regard, the current research aims at evaluating the performance of two data-driven techniques, namely multilayer perceptron (MLP) and gene expression programming (GEP), for predicting the solubility of carbon dioxide (CO2) in ionic liquids (ILs) as the function of pressure, temperature, and four thermodynamical parameters of the ionic liquid. To develop the above techniques, 744 experimental data points derived from the literature including 13 ILs were used (80% of the points for training and 20% for validation). Two backpropagation-based methods, namely Levenberg-Marquardt (LM) and Bayesian Regularization (BR), were applied to optimize the MLP algorithm. Various statistical and graphical assessments were applied to check the credibility of the developed techniques. The results were then compared with those calculated using Peng-Robinson (PR) or Soave-Redlich-Kwong (SRK) equations of state (EoS). The highest coefficient of determination (R-2 = 0.9965) and the lowest root mean square error (RMSE = 0.0116) were recorded for the MLP-LMA model on the full dataset (with a negligible difference to the MLP-BR model). The comparison of results from this model with the vastly applied thermodynamic equation of state models revealed slightly better performance, but the EoS approaches also performed well with R-2 from 0.984 up to 0.996. Lastly, the newly established correlation based on the GEP model exhibited very satisfactory results with overall values of R-2 = 0.9896 and RMSE = 0.0201.","CO2 solubility,ionic liquids,carbon dioxide,multilayer perceptron,gene expression programming,prediction,equation of state,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,,"PRESSURE,PHASE-BEHAVIOR,CO2,SOLUBILITY,CRUDE-OIL,H2S,TEMPERATURE,CAPTURE,DIFFUSION,EQUATION,GASES",APPLIED SCIENCES-BASEL,https://e-pub.uni-weimar.de/opus4/files/4055/Mosavi_Rigorous_applsci-10-00304-v2.pdf,
6,Deep Learning-Based Template Matching Spike Classification for Extracellular Recordings,10,1,,"Park In Yong,Eom Junsik,Jang Hanbyol,Kim Sewon,Park Sanggeon,Huh Yeowool,Hwang Dosik","Park IY,Eom J,Jang H,Kim S,Park S,Huh Y,Hwang D",Hwang D,10.3390/app10010301,Yonsei University,"We propose a deep learning-based spike sorting method for extracellular recordings. For analysis of extracellular single unit activity, the process of detecting and classifying action potentials called ""spike sorting"" has become essential. This is achieved through distinguishing the morphological differences of the spikes from each neuron, which arises from the differences of the surrounding environment and characteristics of the neurons. However, cases of high structural similarity and noise make the task difficult. And for manual spike sorting, it requires professional knowledge along with extensive time cost and suffers from human bias. We propose a deep learning-based spike sorting method on extracellular recordings from a single electrode that is efficient, robust to noise, and accurate. In circumstances where labelled data does not exist, we created pseudo-labels through principal component analysis and K-means clustering to be used for multi-layer perceptron training and built high performing spike classification model. When tested, our model outperformed conventional methods by 2.1% on simulation data of various noise levels, by 6.0% on simulation data of various clusters count, and by 1.7% on in-vivo data. As a result, we showed that the deep learning-based classification can classify spikes from extracellular recordings, even showing high classification accuracy on spikes that are difficult even for manual classification.","spike classification,extracellular recordings,deep learning,multi-layer perceptron,template matching,clustering",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"WAVE-FORM,RECOGNITION,QUALITY",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/1/301/pdf,
7,Dimension Measurement and Key Point Detection of Boxes through Laser-Triangulation and Deep Learning-Based Techniques,10,1,,"Peng Tao,Zhang Zhijiang,Chen Fansheng,Zeng Dan","Peng T,Zhang ZJ,Chen FS,Zeng D",Zeng D,10.3390/app10010026,Shanghai University,Dimension measurement is of utmost importance in the logistics industry. This work studies a hand-held structured light vision system for boxes. This system measures dimension information through laser triangulation and deep learning using only two laser-box images from a camera and a cross-line laser projector. The structured edge maps of the boxes are detected by a novel end-to-end deep learning model based on a trimmed-holistically nested edge detection network. The precise geometry of the box is calculated by the 3D coordinates of the key points in the laser-box image through laser triangulation. An optimization method for effectively calibrating the system through the maximum likelihood estimation is then proposed. Results show that the proposed key point detection algorithm and the designed laser-vision-based visual system can locate and perform dimension measurement of measured boxes with high accuracy and reliability. The experimental outcomes show that the system is suitable for portable automatic box dimension online measurement.,"dimension measurement,laser triangulation,deep learning,calibration,key point detection,online measurement",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,CALIBRATION,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/1/26/pdf,
8,"A Back Propagation Neural Network Model Optimized by Mind Evolutionary Algorithm for Estimating Cd, Cr, and Pb Concentrations in Soils Using Vis-NIR Diffuse Reflectance Spectroscopy",10,1,,"Wang Xi,An Shi,Xu Yaqing,Hou Huping,Chen Fuyao,Yang Yongjun,Zhang Shaoliang,Liu Run","Wang X,An S,Xu YQ,Hou HP,Chen FY,Yang YJ,Zhang SL,Liu R",Hou HP,10.3390/app10010051,China University of Mining & Technology,"Visible and near infrared spectroscopy is an effective method for monitoring the content of heavy metals in soil. However, due to the difference between polluted soil with phytoremediation and without phytoremediation, the common estimation model cannot meet accuracy requirements. To solve this problem, combined with an ecological restoration experiment for soil contamination using the plant Neyraudia reynaudiana, this study explored the feasibility of using a hyperspectral technology to estimate the heavy metal content (Cd, Cr, and Pb) of soil under phytoremediation. A total of 108 surface soil samples (from depths of 0-20 cm) were collected. Inversion models were established using partial least squares regression (PLSR) and the back propagation neural network optimized by a mind evolutionary algorithm (MEA-BPNN). The results revealed that: (1) modeling with derivative-transformed spectra can effectively enhance the correlation between soil spectral reflectance and heavy metal content. (2) Compared with the BP neural network model, the estimation accuracy (R-2) was improved from 0.728, 0.737, and 0.675 to 0.873, 0.884, and 0.857 using the MEA-BP neural network model. The residual prediction deviation (RPD) values for the three heavy metals Cd, Cr, and Pb using the MEA-BPNN model were 2.114, 3.000, and 2.560, respectively. Among them, the estimated model of Cd was an excellent prediction. (3) Compared with PLSR, the model prediction results established by the MEA-BP neural network had higher estimation accuracy. In summary, the use of diffuse reflectance spectroscopy to predict heavy metal content provides a theoretical basis for further study of the large-scale monitoring of soil heavy-metal pollution and its remediation evaluation in the polluted area, which is of great significance.","heavy metal,soil remediation,reflectance spectroscopy,MEA-BP neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"NEAR-INFRARED,SPECTROSCOPY,HEAVY-METAL,CONCENTRATIONS,AGRICULTURAL,SOILS,ORGANIC-MATTER,ARSENIC,CONTAMINATION,ZINC,CONCENTRATIONS,MINING,AREA,LEAN,RIVER,PREDICTION,PHYTOREMEDIATION",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/1/51/pdf,
9,Breast Cancer Computer-Aided Detection System based on Simple Statistical Features and SVM Classification,11,1,430-433,"Osman Yahia,Alqasemi Umar","Osman Y,Alqasemi U",Osman Y,,King Abdulaziz University,"Computer-Aided Detection (CADe) systems are becoming very helpful and useful in supporting physicians for early detection of breast cancer. In this paper, a CADe system that is able to detect abnormal clusters in mammographic images will be implemented using different classifiers and features. The CADe system will utilize a Support Vector Machine (SVM) and K-Nearest Neighbor (KNN) as classifiers. Adopting mammographic database from Mammographic Image Analysis Society (MIAS), for training and testing, the performance of the two types of classifiers are compared in terms of sensitivity, specificity, and accuracy. The obtained values for the previous parameters show the efficiency of the CADe system to be used as a secondary screening method in detecting abnormal clusters given the Region of Interest (ROI). The best classifier is found to be SVM showed 96% accuracy, 92% sensitivity and 100% specificity.","Breast cancer,MIAS,features extraction,SVM,mammogram,clusters,computer-aided detection systems,KNN,ROI",Article,"SCIENCE & INFORMATION SAI ORGANIZATION LTD, 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND",Computer Science,,,,INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS,,
10,EEG Emotion Signal of Artificial Neural Network by using Capsule Network,11,1,434-443,"Ali Usman,Li Haifang,Yao Rong,Wang Qianshan,Hussain Waqar,Duja Syed Badar Ud,Amjad Muhammad,Ahmed Bilal","Ali U,Li HF,Yao R,Wang QS,Hussain W,Duja SBU,Amjad M,Ahmed B",Li HF,,Taiyuan University of Technology,"Human emotion recognition through electroencephalographic (EEG) signals is becoming attractive. Several evolutions used for our research mechanism technology to describe two different primaries: one used for combining the vital attribute, frequency sphere, and physical element of the EEG signals, and the architecture describes the two-dimensional image. Emotion realization is imposing effort in the computer brain interface field, which is mostly used to understand the field of education, medical military, and many others. The allocation issue arises in the required area of emotion recognition. In this paper, the allocation structure based on Caps Net neural network is described. The heder factor shows that the best point to classified the original EEG signals scarce group to using many of the algorithms like Lasso for a better function to used and other than occupy the heights.Furthermore, essential features like tiny subset take by input for the computer network attain for many ultimate emotional classifications. Many of the results show to alternate the best parameters model use and other network formats to making the Caps Net and another neural network act as the emotional valuation on EEG signals. It attains almost 80.22% and 85.41% average allocation efficiency under demeanor and view of the emotion pathway as compared to the Support Vector Machine (SVM) and convolutional neural network(CNN or ConvNet). A significant allocation edge attains the best conclusion and automatically enhances the performance of the EEG emotional classification. Deep learning access, such as CNN has widely used to improve primary allocation performance of motor symbolism-based brain-computer interfaces (BCI). As we know that CNN's limited allocation achievement degraded when an essential point data is distorted. Basically, in the electroencephalography (EEG) case, the signals consist of the same user are not measure. So we implement the Capsule networks (CapsNet), which is essential to extract many features. By that, it attains a much more powerful and positive performance than the old CNN approaches.","Emotion recognition,caps net,EEG signal,multidimensional feature,hybrid neural networks,CNN,Granger,motor imagery classification,deep learning",Article,"SCIENCE & INFORMATION SAI ORGANIZATION LTD, 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND",Computer Science,,,"NET,NEUTRALITY",INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS,,
11,Fine-tuning of pre-trained convolutional neural networks for diabetic retinopathy screening: a clinical study,21,4,564-573,"Roshan Saboora M.,Karsaz Ali,Vejdani Amir Hossein,Roshan Yaser M.","Roshan SM,Karsaz A,Vejdani AH,Roshan YM",Roshan SM,,"Khorasan Inst Higher Educ, 77 Moalem Blvd, Mashhad, Razavi Khorasan, Iran.","Diabetic retinopathy is a serious complication of diabetes, and if not controlled, may cause blindness. Automated screening of diabetic retinopathy helps physicians to diagnose and control the disease in early stages. In this paper, two case studies are proposed, each on a different dataset. Firstly, automatic screening of diabetic retinopathy utilising pre-trained convolutional neural networks was employed on the Kaggle dataset. The reason for using pre-trained networks is to save time and resources during training compared to fully training a convolutional neural network. The proposed networks were fine-tuned for the pre-processed dataset, and the selectable parameters of the fine-tuning approach were optimised. At the end, the performance of the fine-tuned network was evaluated using a clinical dataset comprising 101 images. The clinical dataset is completely independent from the fine-tuning dataset and is taken by a different device with different image quality and size.","deep learning,convolutional neural network,diabetic retinopathy,inception model,clinical study",Article,"INDERSCIENCE ENTERPRISES LTD, WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 856, CH-1215 GENEVA, SWITZERLAND",Computer Science,,,,INTERNATIONAL JOURNAL OF COMPUTATIONAL SCIENCE AND ENGINEERING,,
12,Automatic segmentation of liver/kidney area with double-layered fuzzy C-means and the utility of hepatorenal index for fatty liver severity classification,39,1,925-936,"Kim Kwang Baek,Kim Gwang Ha,Song Doo Heon,Park Hyun Jun,Kim Chang Won","Kim KB,Kim GH,Song DH,Park HJ,Kim CW",Kim KB,10.3233/JIFS-191850,Silla University,"BACKGROUND: Hepatorenal index (HRI) has been an efficient and simple quantified measure in distinction between normal and abnormalities of diagnosing fatty liver. However, considering the clinical significance, the diagnosis of severity stage is more important and single HRI cutoff may not be enough. Also, the segmentation of Liver/Kidney area should be automatic to get rid of operator subjectivity from ultrasonography analysis.
METHOD: Double-layered Fuzzy C-Means (DFCM) pixel clustering method is proposed to extract the target area of analysis automatically. HRI and other shape related variables of Liver intensity distribution such as the skewness, the kurtosis, and the coefficient of variance (CV) are automatically computed for the fatty liver severity stage classification.
RESULT: From fifty ultrasound images obtained from regular health checkup with 24 normal, 12 mild, 11 moderate, 3 severe stage determined by three different radiologists, the proposed DFCM automatically extracts the region of interests(ROI) and generates a set of statistically significant variables including HRI, the skewness, the kurtosis, the coefficient of variance of liver intensity distribution as well as liver echogenicity. In severity stage classification, the echogenicity of the liver and distribution shape variables such as the skewness and the kurtosis are better predictors than HRI based on our simple decision tree learning analysis.
CONCLUSION: For better diagnosis of fatty liver severity stages, we need better set of features than the single HRI cutoff. Better machine learning structures are necessary in this severity stage classification problem with automatic segmentation method proposed in this paper.","Fatty liver severity classification,Fuzzy c-means,Self-organizing map,Hepatorenal index,Decision tree",Article,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS",Computer Science,,1.797,"DIAGNOSTIC-ACCURACY,ULTRASOUND,DISEASE,EXTRACTION,ULTRASONOGRAPHY,ASSOCIATION,ATTENUATION,PROGRESSION,IMAGES,RISK",JOURNAL OF INTELLIGENT & FUZZY SYSTEMS,https://content.iospress.com:443/download/journal-of-intelligent-and-fuzzy-systems/ifs191850?id=journal-of-intelligent-and-fuzzy-systems%2Fifs191850,
13,Digital image processing and recognition technology for classification and recognition of hydrothorax cancer cells,38,4,3859-3866,Zhang Yihong,Zhang YH,Zhang YH,10.3233/JIFS-179609,"Anyang Tumor Hosp Henan Prov, Dept Nursing, Anyang 455000, Henan, Peoples R China.","Pathological diagnosis is the most common and reliable method of cancer diagnosis, but the technology of pathological diagnosis is relatively backward. It is an urgent problem to identify and classify the pathological pictures of cancer cells. Based on this, the digital image processing and recognition technology are analyzed for the classification and recognition of hydrothorax cancer cells. There is a big difference in the morphology of pleural effusion cancer cells, and uncertainty, so the edge detection algorithm is improved, with the simulated edge detection method used to extract information. After image segmentation, feature extraction is of vital importance for cell image classification. A method of block statistics based on Gabor coefficient is proposed. Firstly, the cell image is filtered by multi-scale and multi-directional filtering, then the average and variance are calculated, and the image is divided into several blocks to solve the problem of large amount of data. Finally, BP neural network is established to input the morphological characteristics of hydrothorax cells, and the results are classified directly. After the experiment, the proposed classification method can improve the classification effectiveness; the design model can accurately identify the breast water cancer cells, and can be effectively applied to the early diagnosis of breast water cancer cells.","Hydrothorax cancer cell,image segmentation,image recognition,feature extraction",Article,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS",Computer Science,,,,JOURNAL OF INTELLIGENT & FUZZY SYSTEMS,,
14,"The Effect of Light Intensity, Sensor Height, and Spectral Pre-Processing Methods When Using NIR Spectroscopy to Identify Different Allergen-Containing Powdered Foods",20,1,,"Rady Ahmed,Fischer Joel,Reeves Stuart,Logan Brian,Watson Nicholas James","Rady A,Fischer J,Reeves S,Logan B,Watson NJ",Watson NJ,10.3390/s20010230,University of Nottingham,"Food allergens present a significant health risk to the human population, so their presence must be monitored and controlled within food production environments. This is especially important for powdered food, which can contain nearly all known food allergens. Manufacturing is experiencing the fourth industrial revolution (Industry 4.0), which is the use of digital technologies, such as sensors, Internet of Things (IoT), artificial intelligence, and cloud computing, to improve the productivity, efficiency, and safety of manufacturing processes. This work studied the potential of small low-cost sensors and machine learning to identify different powdered foods which naturally contain allergens. The research utilised a near-infrared (NIR) sensor and measurements were performed on over 50 different powdered food materials. This work focussed on several measurement and data processing parameters, which must be determined when using these sensors. These included sensor light intensity, height between sensor and food sample, and the most suitable spectra pre-processing method. It was found that the K-nearest neighbour and linear discriminant analysis machine learning methods had the highest classification prediction accuracy for identifying samples containing allergens of all methods studied. The height between the sensor and the sample had a greater effect than the sensor light intensity and the classification models performed much better when the sensor was positioned closer to the sample with the highest light intensity. The spectra pre-processing methods, which had the largest positive impact on the classification prediction accuracy, were the standard normal variate (SNV) and multiplicative scattering correction (MSC) methods. It was found that with the optimal combination of sensor height, light intensity, and spectra pre-processing, a classification prediction accuracy of 100% could be achieved, making the technique suitable for use within production environments.","NIR spectroscopy,machine learning,allergen detection,powdered food,industry 4.0,digital manufacturing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"INFRARED,REFLECTANCE,SPECTROSCOPY,QUALITY,EVALUATION,DISCRIMINATION,ADULTERATION,FLOUR,PROTEIN,FRUIT",SENSORS,https://europepmc.org/articles/pmc6982964?pdf=render,
15,Development of Rheumatoid Arthritis Classification from Electronic Image Sensor Using Ensemble Method,20,1,,"Sharon Ho,Elamvazuthi Irraivan,Lu Cheng-Kai,Parasuraman S.,Natarajan Elango","Sharon H,Elamvazuthi I,Lu CK,Parasuraman S,Natarajan E",Elamvazuthi I,10.3390/s20010167,Universiti Teknologi Petronas,"Rheumatoid arthritis (RA) is an autoimmune illness that impacts the musculoskeletal system by causing chronic, inflammatory, and systemic effects. The disease often becomes progressive and reduces physical function, causes suffering, fatigue, and articular damage. Over a long period of time, RA causes harm to the bone and cartilage of the joints, weakens the joints' muscles and tendons, eventually causing joint destruction. Sensors such as accelerometer, wearable sensors, and thermal infrared camera sensor are widely used to gather data for RA. In this paper, the classification of medical disorders based on RA and orthopaedics datasets using Ensemble methods are discussed. The RA dataset was gathered from the analysis of white blood cell classification using features extracted from the image of lymphocytes acquired from a digital microscope with an electronic image sensor. The orthopaedic dataset is a benchmark dataset for this study, as it posed a similar classification problem with several numerical features. Three ensemble algorithms such as bagging, Adaboost, and random subspace were used in the study. These ensemble classifiers use k-NN (K-nearest neighbours) and Random forest (RF) as the base learners of the ensemble classifiers. The data classification is accessed using holdout and 10-fold cross-validation evaluation methods. The assessment was based on set of performance measures such as precision, recall, F-measure, and receiver operating characteristic (ROC) curve. The performance was also measured based on the comparison of the overall classification accuracy rate between different ensembles classifiers and the base learners. Overall, it was found that for Dataset 1, random subspace classifier with k-NN shows the best results in terms of overall accuracy rate of 97.50% and for Dataset 2, bagging-RF shows the highest overall accuracy rate of 94.84% over different ensemble classifiers. The findings indicate that the efficiency of the base classifiers with ensemble classifier have substantially improved.","wearable sensor,image sensor,machine learning,medical datasets,ensemble method,classification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"RANDOM,SUBSPACE,METHOD",SENSORS,https://europepmc.org/articles/pmc6983017?pdf=render,
16,Non-contact home-adapted device estimates sleep stages in middle-aged men: A preliminary study,28,4,439-446,"Yoon Yeong Sook,Hahm Jarang,Kim Kwang Ki,Park Su Kyung,Oh Sang Woo","Yoon YS,Hahm J,Kim KK,Park SK,Oh SW",Oh SW,10.3233/THC-192036,Dongguk University,"BACKGROUND: Sleep monitoring is essential to maintain a healthy life, especially for the elderly who want to age well. Among various forms of sleep devices, the non-wearable and home-adapted device might be preferred because it can be easily used.
OBJECTIVE: In this study, we evaluated the performance of a non-contact home-adapted device compared to polysomnography (PSG), a gold standard method.
METHODS: As a preliminary study, eight subjects were recorded over fourteen nights through PSG. The non-contact home-adapted device comprised a microwave sensor, passive infrared sensor, and smartphone application. Through the device, heart rate, respiratory rate, and body movement were collected and used to estimate sleep stages. Sleep structure was labeled in four classes: wake, REM, light, and deep sleep, and were classified using a weighted k-nearest neighbor algorithm.
RESULTS: The device correctly estimated sleep structures with an overall epoch-by-epoch accuracy of 98.65% +/- 0.05% based on leave-one-out cross-validation. The device showed significantly positive correlations with PSG in sleep indices including total sleep time, sleep efficiency, and wake after sleep onset.
CONCLUSIONS: Our findings demonstrate a good performance of this non-contact and home-adapted device and suggest its suitability for sleep monitoring.","Healthy aging,home sleep monitoring,polysomnography,sleep architecture,smart home",Article,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS","Health Care Sciences & Services,Engineering",,1.116,,TECHNOLOGY AND HEALTH CARE,,
17,Crowdsourcing the Perception of Machine Teaching,,,,"Hong Jonggi,Lee Kyungjun,Xu June,Kacorri Hernisa","Hong J,Lee K,Xu J,Kacorri H",Hong J,10.1145/3313831.3376428,University System of Maryland,"Teachable interfaces can empower end-users to attune machine learning systems to their idiosyncratic characteristics and environment by explicitly providing pertinent training examples. While facilitating control, their effectiveness can be hindered by the lack of expertise or misconceptions. We investigate how users may conceptualize, experience, and reflect on their engagement in machine teaching by deploying a mobile teachable testbed in Amazon Mechanical Turk. Using a performance-based payment scheme, Mechanical Turkers (N = 100) are called to train, test, and re-train a robust recognition model in real-time with a few snapshots taken in their environment. We find that participants incorporate diversity in their examples drawing from parallels to how humans recognize objects independent of size, viewpoint, location, and illumination. Many of their misconceptions relate to consistency and model capabilities for reasoning. With limited variation and edge cases in testing, the majority of them do not change strategies on a second training attempt.","teachable interfaces,object recognition,crowdsourcing,personalization",Proceedings Paper,"ASSOC COMPUTING MACHINERY, 1515 BROADWAY, NEW YORK, NY 10036-9998 USA",Computer Science,,,"POWER,TURK",PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20),http://arxiv.org/pdf/2002.01618,
18,Two-shot Spatially-varying BRDF and Shape Estimation,,,3981-3990,"Boss Mark,Jampani Varun,Kim Kihwan,Lensch Hendrik P. A.,Kautz Jan","Boss M,Jampani V,Kim K,Lensch HPA,Kautz J",Boss M,10.1109/CVPR42600.2020.00404,Eberhard Karls University of Tubingen,"Capturing the shape and spatially-varying appearance (SVBRDF) of an object from images is a challenging task that has applications in both computer vision and graphics. Traditional optimization-based approaches often need a large number of images taken from multiple views in a controlled environment. Newer deep learning-based approaches require only a few input images, but the reconstruction quality is not on par with optimization techniques. We propose a novel deep learning architecture with a stage-wise estimation of shape and SVBRDF The earlier predictions guide each estimation, and a joint refinement network later refines both SVBRDF and shape. We follow a practical mobile image capture setting and use unaligned twoshot flash and no flash images as input. Both our two-shot image capture and network inference can run on mobile hardware. We also create a large-scale synthetic training dataset with domain-randomized geometry and realistic materials. Extensive experiments on both synthetic and real-world datasets show that our networks trained on a synthetic dataset can generalize well to real-world images. Comparisons with recent approaches demonstrate the superior performance of the proposed approach.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,http://arxiv.org/pdf/2004.00403,
19,Attention Patterns Detection using Brain Computer Interfaces,,,303-304,"Hamza-Lup Felix G.,Suri Aditya,Iacob Ionut E.,Goldbach Ioana R.,Rasheed Lateef,Borza Paul N.","Hamza-Lup FG,Suri A,Iacob IE,Goldbach IR,Rasheed L,Borza PN",Hamza-Lup FG,10.1145/3374135.3385322,"Georgia Southern Univ, Savannah, GA 31419 USA.","The human brain provides a range of functions such as expressing emotions, controlling the rate of breathing, etc., and its study has attracted the interest of scientists for many years. As machine learning models become more sophisticated, and biometric data becomes more readily available through new noninvasive technologies, it becomes increasingly possible to gain access to interesting biometric data that could revolutionize Human-Computer Interaction. In this research, we propose a method to assess and quantify human attention levels and their effects on learning. In our study, we employ a brain computer interface (BCI) capable of detecting brain wave activity and displaying the corresponding electroencephalograms (EEG). We train recurrent neural networks (RNNS) to identify the type of activity an individual is performing.","Emotion Identification,Brain Computer Interface,Recurrent Neural Networks,Human-Computer Interaction",Proceedings Paper,"ASSOC COMPUTING MACHINERY, 1515 BROADWAY, NEW YORK, NY 10036-9998 USA",Computer Science,,,,ACMSE 2020: PROCEEDINGS OF THE 2020 ACM SOUTHEAST CONFERENCE,http://arxiv.org/pdf/2005.11151,
20,Machine Learning model for robot polishing cell,11478,,,"Schneckenburger M.,Garcia-Barth L.,Boerret R.","Schneckenburger M,Garcia-Barth L,Borret R",Schneckenburger M,10.1117/12.2564633,"Ctr Opt Technol, Beethovenstr 1, D-73430 Aalen, BW, Germany.","The quality of optical components such as lenses or mirrors can be described by shape errors and surface roughness. With increasing optic sizes, the stability of the polishing process becomes more and more important. If not empirically known, the optical surface must be measured after each polishing step. One approach is to mount sensors on the polishing head in order to measure process relevant quantities. On the basis of these data, Machine Learning algorithms can be applied for surface value prediction. The aim of this work is the stepwise development of an artificial neural network (ANN) in order to improve the accuracy of the models' prediction. The ANN is developed in the Python programming language using the Keras deep learning library. Beginning with simple network architecture and common training parameters. The model will then be optimized step-by-step through the implementation of different methods and Hyperparameter optimization (HPO). Data, which is generated by the sensor-integrated glass polishing head, is used to train the ANN-model. A representative part of these data is held back before, in order to validate the models' prediction. The so-called dataset contains measured values from multiple polishing runs, preceded by a design of experiment. After the model is trained on the dataset, it is able to predict the result of not yet performed polishing runs, with given polishing parameters. Concrete, the ANN is used to predict the resulting glass-surface quality, which includes the surface roughness and the shape accuracy, calculated by the material removal over time. The prediction by artificial neural networks reduces the polishing iterations and thus the production time.","Machine Learning,Glass Polishing,Surface Prediction,Pad Polishing,Precision Manufacturing",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics",,,,,,
21,MAST: Myo Armband Sign-Language Translator for Human Hand Activity Classification,,,494-499,"Shakeel Zuhaib Muhammad,So Soonhyuk,Lingga Patrick,Jeong Jaehoon Paul","Shakeel ZM,So S,Lingga P,Jeong JP",Shakeel ZM,,Sungkyunkwan University (SKKU),"As Computer Science has grown into an encompassed field in various scientific areas, the need for developing a computer aided and artificially intelligent device has become more important especially in the medical field. Artificial Intelligence (AI) plays a vital role not only in accelerating and optimizing common tasks but also in performing tasks that humans are incapable of. This paper presents a Myo Armband Sign-Language Translator (MAST), which is a novel algorithm to translate a hand's gestures into medical sign language using a Myo armband sensor which collects muscles' electromyography signals and then to classify them using an enhanced version of a dynamic random forest. Our experimental results indicate that a systematic fine tuning of MAST parameters leads to an accuracy improvement of 13% over the state-of-the-art scheme such as SCIKIT's random forest. Other comparison results show an improvement of over 20% compared to a popular classification scheme such as Support Vector Machines (SVM) and a deep learning technique such as Convolutional Neural Network (CNN).","Electromyography,Myo Armband,Sign-language Translator,Random Forest,Support Vector Machine,Convolutional Neural Network",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
22,Application of Deep Learning in Automated Meal Recognition,,,58-63,"Mao Jiaxiang,Tran Dat,Ma Wanli,Naumovski Nenad,Kellett Jane,Martinez-marroquin Elisa,Slattery Andrew","Mao JX,Tran D,Ma WL,Naumovski N,Kellett J,Martinez-marroquin E,Slattery A",Mao JX,,University of Canberra,"Deep learning is a widely used data analysis tool and has its proven value in solving problems and challenges in data science. In the nutrition domain, automated recognition of meals is an essential task within the food quality control and diet management. Adequate food supply and precise distribution of nutrients are extremely important. The availability of deep learning to facilitate these tasks would improve a critical step of the meal service process. Therefore, the aim of this research is to study deep learning applications as automated meal recognition for patients at the Canberra Hospital. specifically using convolutional neural networks (CNN). The application of applying deep learning to food quality control are important in reducing human mistakes that may result to providing wrong foods to patients in the current food service at Canberra hospital.","Food science,Food quality control,CNN,Deep Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
23,Early Prediction of Hemoglobin A1c: A novel Framework for better Diabetes Management,,,542-547,"Islam Md Shafiqul,Qaraqe Marwa K.,Belhaouari Samir B.","Islam MS,Qaraqe MK,Belhaouari SB",Islam MS,,Hamad Bin Khalifa University-Qatar,"The Hemoglobin Ale (HbA1c) test reflects the average amount of glucose accumulated in the blood over the last 2-3 months. The HbA1c is considered as one of the fundamental indexes for diabetes management. It is used to monitor long-term glycemic control, adjust therapy, assess the quality of diabetes care, and predict the future risk of complications. Predicting levels of HbA1c in advance holds a critical significance for maintaining long term health of diabetes patients. A higher than the normal value of the HbA1c increases the likelihood of diabetes-related complications. This study aims to predict the HbA1c levels 2-3 months in advance, which will facilitate early intervention and avoiding complications arise from diabetes. We propose novel feature extraction from continuous glucose monitoring (CGM) data using the fractional derivative, glucose variability, time in range, and wavelet decomposition methods. The highly correlated features were identified and used while developing the HbA1c prediction models. The developed framework was evaluated using the CGM data sourced from the Diabetes Research in Children Network (DirecNet). The ensembling of the random forest and extreme gradient boosting models coupled with the feature fusion obtained the best performance of low mean absolute error (MAE) 339 mmol/mol and a high coefficient of determination (R-squared) score of 0.81.","HbA1c Prediction,Fractional Derivative,Wavelet Decomposition,CGM,Ensemble Regression,Diabetes Management",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,"PLASMA-GLUCOSE,TRANSFORM",2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
24,Multi-view Learning for 3D LGE-MRI Left Atrial Cavity Segmentation,,,84-87,"Xiao Jingjing,Si Dongyue,Wu Yanfang,Li Meng,Yin Jie,Ding Haiyan","Xiao JJ,Si DY,Wu YF,Li M,Yin J,Ding HY",Xiao JJ,10.1145/3430199.3430203,Army Medical University,"This paper presents a multi-view learning based method for left atrial cavity segmentation in 3D Late Gadolinium Enhanced Magnetic Resonance Imaging (LGE-MRI). Segmenting left atrium is challenging due to the low intensity contrast, motion artifacts, and extremely thin atrial walls. Since the spatial consistency of the atrium could help to alleviate the segmentation ambiguity caused by those problems, the proposed method consists of three deep convolutional streams which construct 3D segmentation likelihood maps from different views, i.e., axial view, coronal view, and sagittal view. Then, those likelihood maps will be fused and contribute to a final 3D segmentation map, where the method further inspects the 3D connectivity of the labeled pixels and discards the disconnected regions that don't belong to the atrium. The proposed method is tested on a publicly available dataset, where 80 scans are for training and 20 scans are for testing. Compared to the other state-of-the-art algorithms, the proposed method demonstrates a considerable improvement, which shows the advantages of using multi-view information.","Left atrial cavity segmentation,Multi-view learning,3D LGE-MRI",Proceedings Paper,"ASSOC COMPUTING MACHINERY, 1515 BROADWAY, NEW YORK, NY 10036-9998 USA","Computer Science,Imaging Science & Photographic Technology",,,,AIPR 2020: 2020 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION,,
25,A Comparison of Oversampling Methods for Constructing a Prognostic Model in the Patient with Heart Failure,,,379-383,"Kim Young-Tak,Kim Dong-Kyu,Kim Hakseung,Kim Dong-Joo","Kim YT,Kim DK,Kim H,Kim DJ",Kim DJ,,Korea University,"Heart failure (HF) is the terminal stage of all heart disease and the leading cause of mortality. A reliable prognostic model for predicting mortality in patients with HF can help to support better decisions in clinical practice. Many attempts have been made to increase the reliability of the prognostic model using electronic health record (EHR), but it is still not known which oversampling method is efficient in imbalanced and insufficient EHR dataset. This study performed a comparative analysis of renowned oversampling methods (i.e., synthetic minority oversampling technique (SMOTE), borderline-SMOTE, and adaptive synthetic (ADASYN) sampling techniques) in constructing prognostic models for HF patients. All 299 patients had left ventricular systolic dysfunction, belonging to New York Heart Association class III and IV (Survival = 203, Deceased = 96). Follow up time was 4285 days with an average of 130 days. The above three oversampling methods were compared in the case where the prognostic models were constructed by the random forest to predict mortality of patients with HF. The baseline model without oversampling method showed an F-score of 0.55. The oversampling method improved the F-score by 0.05 or more compared to the baseline model. SMOTE showed the highest prognostic capacity (F-score = 0.63) among the oversampling methods (F-score of borderline SMOTE = 0.60, ADASYN = 0.62). In all three oversampling methods, ejection fraction, serum creatinine, and age were consistently observed with high importance. Consequently, SMOTE is the most adequate algorithm for oversampling EHR data to predict mortality in HF patients.","Oversampling,Prognostic Model,Electronic Health Record,Heart Failure",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"SERUM,CREATININE,HOSPITALIZATION,MORTALITY,SMOTE",,,
26,An Ensemble Deep Learning Approach for Sleep Stage Classification via Single-channel EEG and EOG,,,394-398,"Wang In-Nea,Lee Choel-Hui,Kim Hyun-Ji,Kim Hakseung,Kim Dong-Joo","Wang IN,Lee CH,Kim HJ,Kim H,Kim DJ",Kim DJ,,Korea University,"Classification of sleep stages is important for diagnosis and treatment of sleep disorder. Manual classification performed by sleep experts is burdensome and time-consuming. This study proposes a novel model for sleep stage classification. EEG and EOG signals of 153 healthy subjects was used. The proposed model ensembles two EEGNet-BiLSTM models which learn EEG and EOG respectively. Compared to the existing models, the two models yielded approximately 82% accuracy and 0.78 k-value, whereas the proposed ensemble model showed 90% accuracy and 0.80 k-value. The proposed ensemble model is superior in terms of accuracy and consistency compared to the conventional models.","Sleep stages,classification,ensemble,deep learning,electroencephalography,electrocardiogram",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
27,Low channel electroencephalogram based deep learning method to pre-screening depression,,,449-451,"Kang Min,Park Jinhyeok,Kang Seokhwan,Lee Youngho","Kang M,Park J,Kang S,Lee Y",Kang M,,Gachon University,"Major depressive disorder (MDD) is a serious disease that negatively affects mood, thought, and behavior, and in severe cases, even suicide. many studies have been conducted to diagnose depression based on physiological data such as EEG (electroencephalogram) signals. There are many studies conducted by measuring EEG signals with a professional multi-channel device for the diagnosis of depression, but it is difficult to apply this method in a low-channel EEG signals measurement environment that individuals can easily access. Therefore, this study proposes a deep learning method to detect depression in advance based on low-channel EEG signals. Four frontal channels were separated into delta, theta, alpha, and beta band frequencies and trained in a two-dimensional deep learning model based on a convolution layer. And, the result was 96.97% accuracy, 90.97% sensitivity, and 99.00% specificity.","Electroencephalogram,Deep learning,Low channel,CNN,Major depressive disorder,pre-screening model,Band wave,Conv2D",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
28,Feature Extraction Model Based on Inception V3 to Distinguish Normal Heart Sound from Systolic Murmur,,,460-463,"Bae Jinhee,Kim Minwoo,Lim Joon S.","Bae J,Kim M,Lim JS",Bae J,,Gachon University,"In this study, we propose a model for classifying normal and abnormal sounds by extracting characteristics from abnormal heart sounds in which normal and symbolic murmurs appear. Heart sound data obtained through an electronic stethoscope are converted into mel-spectrogram images. The pre-trained Inception V3 model that carries out fine-tuning uses the mel-spectrogram image as input. Convolutional layers of fine-tuning completed Inception V3 models were used as feature extractors. A point-binary correlation analysis technique was used to select effective features for classification from the features extracted through the feature extractor. A crystal coefficient value, which is the square of the correlation coefficient value, is used for an accurate comparison between the features. We used an artificial neural network as a classifier in this experiment. Fine-tuned Inception V3 has an average accuracy of 87.7%. When 5-fold class validation is advanced by selecting the top 30 characteristics with high crystal coefficient values, the accuracy is 97.5%. These results can greatly assist physicians trying to detect a systolic murmur.","mel-spectrogram,inception v3,point-biserial coefficient correlation,feature extractor",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
29,In-Vivo Estimation of Glucose Level Using PPG Signal,,,733-736,"Sen Gupta Shantanu,Hossain Shifat,Haque Chowdhury Azimul,Kim Ki-Doo","Sen Gupta S,Hossain S,Haque CA,Kim KD",Kim KD,,Kookmin University,"Despite being at the start of the 21st-century, the non-invasive measurement of blood glucose still remains a challenging task in the scientific world. In recent times, several studies have been carried out based on the optical properties of light to measure the changes in blood volume and tried to calculate various physiological parameters including blood glucose using PPG signal. In our study, we try to develop a non-invasive method for blood glucose estimation by transmissive and reflective PPG signals of the subjects. We also develop a hardware system to collect PPG. In our proposed method, we accurately relate the features that are obtained from PPG to the original blood glucose values from a glucometer. Our proposed methodology has maximum correlation value of 0.91.","PPG,blood glucose,features,machine learning,regression",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
30,Evaluation of Different Machine Learning Models for Photoplethysmogram Signal Artifact Detection,,,1206-1208,"Athaya Tasbiraha,Choi Sunwoong","Athaya T,Choi S",Athaya T,,Kookmin University,"Photoplethysmography (PPG) is a convenient as well as a simple method to detect the change in blood volume level. It is recently in wide use for noninvasive measurement using optical technique. But PPG signals are very sensitive to various artifacts. These artifacts impact measurement accuracy in negative way which can provide a significant number of inaccurate diagnoses. Thus in this paper, we propose to build a system to detect PPG signal artifacts of the MIMIC database and divide them into two classes, one is acceptable and another is anomalous. Different machine learning algorithms were applied to see the classification accuracy. Among them, Random Forest (RF) performed the best with the accuracy +/- standard deviation of 84.00 +/- 2.89%.","photoplethysmography,PPG,signal,artifact,noise,machine learning,detection",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,REAL-TIME,,,
31,Creating Value from in-Vehicle Data: Detecting Road Surfaces and Road Hazards,,,,"Kortmann Felix,Hsu Yi-Chen,Warnecke Alexander,Meier Nicolas,Heger Jens,Funk Burkhardt,Drews Paul","Kortmann F,Hsu YC,Warnecke A,Meier N,Heger J,Funk B,Drews P",Kortmann F,,Leuphana University Luneburg,"An important component for the realization of the automated driving task is a holistic environment model. Connected and Autonomous Vehicles (CAVs) must be capable of detecting other vehicles, road markings, dangerous obstacles and upcoming road conditions. Apart from the comfort dependency on the road condition, friction values are calculated on the basis of road properties, which in turn are relevant for e.g. breaking and safety distances of CAVs. Due to the substitution of the human control task by the machine, this information must in future be detected by the vehicle itself. Based on the existing Vehicle Level Sensors (VLSs) and Acceleration Sensors (ASs) data, which are standard components in modern vehicles, a machine-learning approach of determining road surface materials and road hazards is presented. Our software solution of determining different road surface materials as asphalt, concrete, cobblestone or gravel with a total accuracy of 9236 % is presented. Furthermore, the results of the road hazards detection as potholes and speed bumps with a total accuracy of 92.39 % is stated. Additionally to the edge calculations in the vehicle, our idea resolves in connected vehicles being capable of classifying road conditions enabling them to provide road analyses to a cloud platform. The goal is to establish a holistic cloud solution for road conditions to enable CAVs for the consumption of road condition data of upcoming road segments and empower them to adjust to those.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Transportation",,,,,,
32,An Interpretable Deep Learning Framework for Health Monitoring Systems: A Case Study of Eye State Detection using EEG Signals,,,211-218,"Tahmassebi Amirhessam,Martin Jennifer,Meyer-Baese Anke,Gandomi Amir H.","Tahmassebi A,Martin J,Meyer-Baese A,Gandomi AH",Tahmassebi A,,State University System of Florida,"Effective monitoring and early detection of deterioration in patients play an essential role in healthcare. This includes minimizing the number of emergency encounters, reducing the length of hospitalization stay, re-admission rates of the patients, and etc. Cutting-edge methods in artificial intelligence (AI) have the ability to significantly improve outcomes. However, the struggle to interpret these black box models presents a serious problem to the healthcare industry. When selecting a model, the decision to sacrifice accuracy for interpretability must be made. In this paper, we propose an interpretable framework with the ability of real-time prediction. To demonstrate the predictive power of the framework, a case study on eye state detection using electroencephalogram (EEG) signals was employed to investigate how a deep neural network (DNN) model makes a prediction, and how that prediction can be interpreted. The promising results can he used to employ more advanced models in healthcare solutions without any concern of sacrificing the interpretation.",REGRESSION,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,REGRESSION,2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
33,Multichannel Symbolic Aggregate Approximation Intelligent Icons: Application for Activity Recognition,,,505-512,"Pappa Lamprini,Karvelis Petros,Georgoulas George,Stylios Chrysostomos","Pappa L,Karvelis P,Georgoulas G,Stylios C",Pappa L,,University of Ioannina,"In this work, we introduce the Multichannel Intelligent Icons, a novel method for producing and presenting essential patterns of multidimensional bio-signals. The proposed approach is an extension of Symbolic Aggregate Approximation (SAX) along with an innovative variation of Intelligent Icons. The innovation on the approach stands on the grounds of creating a spatial correlation of the inherited information in all dimensions and so it provides extra features for distinguishing the human activities. The proposed model is testing on Human Activity recorded data and for the classification purposes a Nearest Neighbour classifier is applied. The achieved results are compared with the case of applying single-channel intelligent icons approach and it is inferred a noteworthy increase in terms of accuracy and sensitivity with the proposed approach.","Human Activity Recognition,Symbolic Aggregate Approximation,Multichannel Intelligent Icons,Classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,"REPRESENTATION,ACCELEROMETER,SAX",2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
34,Estimating the cognitive load in physical spatial navigation,,,568-575,"Do Tien-Thong Nguyen,Singh Avinash Kumar,Cortes Carlos A. Tirado,Lin Chin-Teng","Do TTN,Singh AK,Cortes CAT,Lin CT",Do TTN,,University of Technology Sydney,"Navigation is an essential skill that helps one to be aware of where they are in space and ambulate from a location to others. Many cognitive processes are involved in navigation tasks, even in the simplest scenario, such as landmarks encoding, cognitive map anchoring, goal-oriented planning, and motor executing. Engaging multiple tasks simultaneously could lead to higher cognitive load and attenuated navigation performance. In this study, we investigate the cognitive load of participants while they perform a navigation task.
We demonstrated the ability to extract neural features from complex physical movement tasks, such as navigation. We found that retrosplenial complex (RSC) shows a distinct features for mental workload related task. We further evaluated participant's cognitive load with different machine learning algorithm and found that CNN is able to classify with 93% accuracy. The results provided a potential approach to study cognitive load in a more naturalistic scenario.","Spatial navigation,EEG,deep-learning,MoBI,brain-computer interfaces,CNN",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,"RETROSPLENIAL,CORTEX,TOPOGRAPHIC,DISORIENTATION,EEG,DYNAMICS,BRAIN,WALKING,MEMORY",2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
35,Multi-label Classification for Epileptic Seizure Recognition: Deep Neural Network Ensemble versus Choquet Fuzzy Integral Fusion,,,836-841,Ludwig Simone A.,Ludwig SA,Ludwig SA,,North Dakota State University Fargo,"Epilepsy is a chronic neurological disorder. The cause are unprovoked recurrent seizures that patients experience. The most commonly used tool for the diagnosis of epilepsy is the electroencephalogram (EEG). The EEG measures the electrical activity of the brain. The patients have to be monitored as to detect an epileptic episode early on in order to prevent associate risks. Research in the past has used a combination of time and frequency features for the automatic recognition of epileptic seizures. An classification approach has been used to automatically detect epileptic seizures. In this paper, the epileptic seizure recognition data set is used for the investigation. Two fusion methods, ensemble and Choquet fuzzy integral, are compared using different deep neural network architectures. To aid the comparison, evaluation measures such as confusion matrix, AUC and accuracy are used in conjunction with MSE and RMSE. The results of the experiments show that the Choquet fuzzy integral fusion method outperforms the ensemble method. In addition, other state-of-the-art classification methods are also outperformed by the Cloquet fuzzy integral fusion method.",DRY ELECTRODES,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,"DRY,ELECTRODES",2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
36,Unsupervised Anomaly Detection on Temporal Multiway Data,,,1059-1066,"Duc Nguyen,Phuoc Nguyen,Kien Do,Rana Santu,Gupta Sunil,Truyen Tran","Nguyen D,Nguyen P,Do K,Rana S,Gupta S,Tran T",Nguyen D,,Deakin University,"Temporal anomaly detection looks for irregularities over space-time. Unsupervised temporal models employed thus far typically work on sequences of feature vectors, and much less on temporal multiway data. We focus our investigation on two-way data, in which a data matrix is observed at each time step. Leveraging recent advances in matrix-native recurrent neural networks, we investigated strategies for data arrangement and unsupervised training for temporal multiway anomaly detection. These include compressing-decompressing, encoding-predicting, and temporal data differencing. We conducted a comprehensive suite of experiments to evaluate model behaviors under various settings on synthetic data, moving digits, and ECG recordings. We found interesting phenomena not previously reported. These include the capacity of the compact matrix LSTM to compress noisy data near perfectly, making the strategy of compressing-decompressing data ill-suited for anomaly detection under the noise. Also, long sequence of vectors can be addressed directly by matrix models that allow very long context and multiple step prediction. Overall, the encoding-predicting strategy works very well for the matrix LSTMs in the conducted experiments, thanks to its compactness and better tit to the data dynamics.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),http://arxiv.org/pdf/2009.09443,
37,Automated Pain Assessment: Is it Useful to Combine Person-Specific Data Samples?,,,1588-1593,"Bellmann Peter,Schwenker Friedhelm","Bellmann P,Schwenker F",Bellmann P,,Ulm University,"Many classification tasks, from the field of automated pain assessment, include a special type of human-centred data sets. Often, the data is organised in person-specific data subsets. In the current work, we introduce a heuristic classification approach, which aims at explicitly making use of the particular structure of such databases. More precise, during the training phase, different person- and class-specific data samples are aggregated to form overlapping sample sets. The sample sets are fed to the classification models, which use the combined information. The aim is to improve each model's generalisation ability, by exploring the variety (sample combinations) of each participant's data distribution. We evaluate our proposed method, in combination with the publicly available pain-related BioVid Heat Pain Database. Moreover, we analyse our proposed approach in combination with three types of basic classification models, namely a nearest neighbour classifier, a support vector machine, and an ensemble of decision trees. The presented results show that our proposed approach is able to significantly improve the baseline classification performance, in combination with the decision tree based ensemble and the nearest neighbour classification model. Based on the presented outcomes, we discuss the effectiveness and potential of our proposed heuristic method, and provide promising approaches for future research directions.","information fusion based classifier training,automated pain detection systems,physiological signals",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,SYSTEMS,2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
38,Synchronicity Identification in Hippocampal Neurons using Artificial Neural Network assisted Fuzzy C-means Clustering,,,1594-1600,"Pantula Priyanka D.,Miriyala Srinivas S.,Giri Lopamudra,Mitra Kishalay","Pantula PD,Miriyala SS,Giri L,Mitra K",Pantula PD,,Indian Institute of Technology System (IIT System),"Neural synchronicity plays a vital role in monitoring the functions that are cognitive. Any disturbance identified in the neural synchrony might lead to a diseased state. In the case of in vitro cell recordings, the neurons demonstrate significant heterogeneity in the firing pattern. Thus, the task of automated identification of synchronous and asynchronous neurons from a large population of neuronal cells remains challenging. To address this issue, an efficient unsupervised machine learning approach has been proposed for a system of primary cultures of hippocampal neurons. Here, a confocal microscope is used for imaging of intracellular calcium using Fluo-4 as the fluorescent indicator. The obtained static images are transformed into time-varying data of cytosolic calcium. Subsequently, an intelligent artificial neural network (ANN) assisted fuzzy clustering algorithm is proposed for grouping the synchronous neurons from a heterogeneous set of calcium data that are spiking in nature. This novel algorithm enables a drastic variable reduction followed by the implementation of a global optimization algorithm to solve the problem in Fuzzy C-means (FCM) clustering. Additionally, the proposed technique computes the optimal cluster number and the hyper-parameters involved in ANNs. To validate the result obtained from ANN assisted FCM, a correlation coefficient, and a spiking pattern plot is analyzed for both the synchronous and asynchronous neuronal cells. Besides this, the proposed algorithm is compared with the traditional FCM, where the solution quality is found to be improved along-with an 88% reduction in decision variable count. The complete novel framework combines the aspects of calcium imaging, ANN-assisted FCM, validation, and comparison, which as a whole, can be used for quick and effective quantification of synchronicity.","Hippocampal neurons,Neuronal Synchronicity,Calcium imaging,Time-series data,Fuzzy clustering,Artificial Neural Network",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
39,Motion Identification of fingerspelling by Wrist EMG Analysis,,,1739-1744,"Fukui Tsubasa,Ito Momoyo,Ito Shin-ichi,Fukumi Minoru","Fukui T,Ito M,Ito SI,Fukumi M",Fukui T,,Tokushima University,"Recent years, interfaces using biometric information are progressing. Electromyogram(EMG) has been used in a variety of situations. Many studies have measured EMG in the shoulders and arms, where there is a lot of muscle mass. In addition, wet type sensors have been often used. However, those are inconvenient to use in everyday life and high cost. In this research, we measure wrist EMG for convenience and cost. Currently, researches have been done on the wrist EMG motion identification and personal identification. These studies have conducted simple movements and a large number of electrodes for discrimination. Furthermore, authentication by password sequence with gestures has not been done. In this paper, we propose to realize motion identification and personal authentication with complex movements using a small number of electrodes. The measured data was preprocessed such as removing noise and smoothing. We compared the accuracies obtained using Support Vector Machine(SVM) and Long Short-term memory(LSTM) for motion identification and authentication. The accuracies obtained using SVM and LSTM were 60.4% and 62.4%, respectively. In this case, the number of data was small. It is therefore necessary for increasing the number of data to perform deep learning.","Biometrics,LSTM,Deep learning,wrist EMG,Hand motion recognition",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
40,Nonlinear Model Predictive Control of Industrial Grinding Circuits using Machine Learning,,,1921-1927,"Inapakurthi Ravi Kiran,Miriyala Srinivas Soumitri,Kolluri Suryanarayana,Mitra Kishalay","Inapakurthi RK,Miriyala SS,Kolluri S,Mitra K",Inapakurthi RK,,Indian Institute of Technology System (IIT System),"Control problems of engineering interest such as industrial grinding circuit (IGC) are essential for minimizing the energy consumption, maximizing throughput or maintaining product quality to make these processes energy sustainable in future. Detailed physics based models, although provide more insight into the process and yield accurate results, often cannot be used for control purposes owing to the high computational time involved in solving the complicated mass, momentum, energy balance equations used to describe the process. In the current study, the aim is to use optimally designed Recurrent Neural Networks, a type of data-based modeling technique popularly used in the machine learning domain, for modeling transients involved in the IGC and test its effectiveness in set point (SP) tracking under the nonlinear model predictive control (NMPC) framework. SP tracking of throughput (related to the amount of raw materials processed to give products) and recirculation load (related to the energy consumption) is performed. We observe that the developed machine learning based models could effectively perform the SP tracking for nonlinear industrial process like grinding.","model predictive control,optimization,data based models,process system engineering",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,PLANTS,2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
41,Consumer Behavior Analysis using EEG Signals for Neuromarketing Application,,,2061-2066,"Amin Chowdhury Rabith,Hasin Mirza Farhan,Leon Tasin Shafi,Aurko Abrar Bareque,Tamanna Tasmi,Rahman Md Anisur,Parvez Mohammad Zavid","Amin CR,Hasin MF,Leon TS,Aurko AB,Tamanna T,Rahman MA,Parvez MZ",Amin CR,,Bangladesh Rural Advancement Committee BRAC,"Neuromarketing is applying neuropsychology in marketing research studying consumer sensory-motor actions such as cognitive and affective responses to marketing stimuli with the help of modern technologies. It is one of the most recent marketing research strategies and may become the future of marketing research. Many research works have been carried out in this area to obtain better outcomes. However, literature shows that there is an opportunity for further improvement. Hence, in this study, a model is presented using data mining and machine learning algorithms for consumer behavior analysis from EEG signals. Time-frequency distribution features are extracted from EEG signals on which different classification algorithms are applied. Consumer's responses toward marketing strategies and their behavior towards purchasing or selecting goods can he studied and analyzed to understand the producer-consumer relationship. EEG signals from 25 people are collected where the participants varied in age and gender for a better understanding of consumer behavior towards a marketing policy. By analyzing the data, the reason behind how and why they like certain marketing policies was uncovered. The performance of our proposed model with an existing technique is compared. The accuracy of our model on the dataset is 95%, whereas the accuracy of the existing technique on the same dataset is 70%. We also evaluated whether neuropsychological measures can capture differences in consumer's actions according to different marketing stimuli. The experimental results on our model indicate that studies in this field can bring a change and improve marketing strategies for the betterment of both the producer and the consumer, resulting in an eventual mutual benefit.","Neuromarketing,EEG,Neuropsychology,Marketing Strategy,Consumer,Decision Tree",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,"EPILEPTIC,SEIZURE,DETECTION",2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
42,Deep Learning based Segmentation for Multi MR Imaging Protocols using Transfer Learning for PET Attenuation Correction,,,2516-2520,"Mecheter Imene,Amira Abbes,Abbod Maysam,Zaidi Habib","Mecheter I,Amira A,Abbod M,Zaidi H",Mecheter I,,Brunel University,"Magnetic resonance (MR) image segmentation is a robust technique used for PET attenuation correction. However, the segmentation of the brain into different tissue classes is a challenging task because of the similarity of pixel intensity values. The objective of this work is to propose a deep learning network to segment T1-weighted MR images of a dataset consists of 50 patients. Additionally, transfer learning is applied to segment another MR image protocol which is T2-weighted. The pretrained network with T1-weighted images is finetuned then tested with a dataset of 14 patients only. The Dice coefficients of air, soft tissue, and bone classes for T1-weighted MR images are 0.98, 0.92 , and 0.79 respectively. The results of transfer learning show the feasibility of finetuning a deep network trained with T1-weighted images to segment T2-weighted images.","Magnetic Resonance Imaging,Segmentation,PET Attenuation Correction,Deep Learning,Transfer Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),http://bura.brunel.ac.uk/bitstream/2438/22251/3/FullText.pdf,
43,Brain Magnetic Resonance Imaging Generation using Generative Adversarial Networks,,,2528-2535,"Alogna Emanuel,Giacomello Edoardo,Loiacono Daniele","Alogna E,Giacomello E,Loiacono D",Alogna E,,Polytechnic University of Milan,"Magnetic Resonance Imaging (MRI) is nowadays one of the most common medical imaging technology, due to its non-invasive nature and the many kind of supported sequences (modalities), that provide unique insights about a particular disease. However, it is not always possible to acquire all the sequences required, for several reasons such as prohibitive scan times or allergies to contrast agents. To overcome this problem and thanks to the recent improvements in Deep Learning, in the last few years researchers have been studying the application of Generative Adversarial Networks, a promising paradigm in deep learning, to generate the missing modalities. In this work we developed and trained two models of Generative Adversarial Networks, called MI-pix2pix and MI-GAN, to solve the problem of generating missing modalities for brain MRIs. In particular, our approaches are multi-input generative models, as they exploit as input several MRI modalities to generate the missing one. Our results are promising and show that the developed models are able to generate rather realistic and good quality images.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
44,Unsupervised Patterns of Driver Mental Fatigue State Based on Head Posture Using Gaussian Mixture Model,,,2699-2704,"Ansari Shahzeb,Du Haiping,Naghdy Fazel,Stirling David","Ansari S,Du HP,Naghdy F,Stirling D",Ansari S,,University of Wollongong,"Monitoring and interpreting of the Driver behaviour is a challenging area of research as the driver behaves unpredictably under the influence of factors such as fatigue, drowsiness, inattention, weather, traffic, and roads variations. In the studies reported in the literature, the activities of the driver are monitored through longitudinal and lateral behaviours using physiological characteristics and computer vision. However, an effective method to understand and monitor the sudden changes in the postural behaviour of the driver leading to catastrophic conditions is still outstanding. Towards developing such method, the driver head posture under different driving states is monitored in this study using inertial sensors. The data produced by the sensors is modelled using Gaussian Mixture unsupervised clustering approach. The experiments were conducted on a total of 10 young healthy subjects on MATHWORKS driver-in-loop simulator, interfaced with a virtual environment designed in Unreal Engine studio. A criteria of minimum abundance range between 0.5-1% is deployed to identify the most optimum clusters. The information contained in the clusters are analyzed to find the maximum magnitude and standard deviation of each cluster and then organized in descending order for assignment the symbols. Finally, the patterns of each driver state are validated. The results indicate that the proposed approach is effective in identifying the driver state in an unsupervised manner. Moreover, the patterns identified can be deployed in a smart early intervention system to correct the mistakes made during driving. The limitations of the current work and directions for future work are discussed.","Driver behaviour,driver states,head posture,pattern recognition,unsupervised clustering,GMM",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,"SYSTEM,POSE",2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
45,A GPHH with Surrogate-assisted Knowledge Transfer for Uncertain Capacitated Arc Routing Problem,,,2786-2793,"Ardeh Mazhar Ansari,Mei Yi,Zhang Mengjie","Ardeh MA,Mei Y,Zhang MJ",Ardeh MA,,Victoria University Wellington,"The Uncertain Capacited Arc Routing Problem is an important and challenging problem that has many real-world applications. Genetic Programming is utilised to evolve routing policies for vehicles to make real-time decisions and handle uncertain environments efficiently. However, when the problem scenario changes (e.g. a new vehicle is bought or an existing vehicle breaks down), the previously trained routing policy becomes ineffective and a new routing policy needs to be retrained. The retraining process is time-consuming. On the other hand, by extraction and transfer of some knowledge learned from the previous similar problems, the efficiency and effectiveness of the retraining process can be improved. Previous studies have found that the lack of diversity in the transferred materials (e.g. sub-trees) could hurt the effectiveness of transfer learning. As a result, instead of using the genetic materials from a source domain directly, in this work, we utilise the knowledge from the source domain to create a surrogate model. This surrogate is used on a large number of randomly generated individuals by GP in the target domain to select the promising initial individuals. This way, the diversity of the initial population can be maintained by randomly generated individuals, but also guided by the transferred surrogate model. Our experiments demonstrate that the proposed surrogate-assisted transfer learning method is superior to existing methods and can improve training efficiency and final performance of GP in the target domain.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
46,A Novel Method Based on Convolutional Features with Non-Iterative Learning for Brain Tumor Classification,,,2799-2805,"Sinha Toshi,Verma Brijesh","Sinha T,Verma B",Sinha T,,Central Queensland University,"Brain tumor is a cluster of abnormal and uncontrolled cells growth, leading to a short life expectancy in their highest grade. Accurately and timely clinical diagnosis of such tumors play critical role in treatment planning and patient care. Various image techniques such as Computed Tomography (CT), Ultra-Sound image, Magnetic Resonance Imaging (MRI) and biopsy are used to evaluate brain tumors. Among stated four, MRI is most common used non-invasive technique, however the key challenge with these images is the low-level visual information captured by MRI machines, that needs high-level interpretation by experienced radiologist. The manual interpretation is a tedious, challenging. and erroneous task. In this paper. we propose a novel Convolutional Feature based Euclidean Distance (ConFED) method for faster and more accurate tumor classification. The method consists of convolutional features and Euclidean distance based one step learning. The proposed method is evaluated on Contrast-Enhanced Magnetic Resonance Images (CE-MRI) benchmark dataset. Proposed method is more generic as it does not use any handcrafted features, requires minimal preprocessing, and can achieve average accuracy of 97.02% using five-fold cross-validation. Extensive experiments, along with statistical tests, revealed that the proposed method has outperformed state-of-the-art classification methods on the CE-MW dataset.","Brain Tumor Classification,Convolutional Neural Networks,Image Classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,NEURAL-NETWORKS,2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI),,
47,Transfer Learning Vs. Fine-Tuning in Bilinear CNN for Lung Nodules Classification on CT Scans,,,99-103,"Mastouri Rekka,Khlifa Nawres,Neji Henda,Hantous-Zannad Saoussen","Mastouri R,Khlifa N,Neji H,Hantous-Zannad S",Mastouri R,10.1145/3430199.3430211,Universite de Tunis-El-Manar,"Lung cancer is one of the leading causes of death worldwide. Its early detection in its nodular form is extremely effective in improving patient survival rate. Deep learning (DL) and especially Convolutional Neural Network (CNN) have an important development over the past decade and were largely explored in medical imaging analysis. In this paper, a trending DL model composed of two CNN streams, named Bilinear CNN (B-CNN), was proposed for lung nodules classification on CT scans. In the developed B-CNN model, the pre-trained VGG16 architecture was trained as a feature extractor. It is the most important part of the proposed model in which its effectiveness depends stringently on its performances. Aiming to improve these performances, we address this question: what process leads with the performance improvement of the feature extractors? Transfer learning or Fine-tuning? To answer this question, two B-CNN models were implemented, in which the first one was based on transfer learning process and the second was based on fine-tuning, using VGG16 networks. A set of experiments was conducted and the results have shown the outperformance of the fine-tuned B-CNN model compared to the transfer learning-based model. Moreover, the proposed B-CNN model was demonstrating its efficiency and viability for the classification of lung nodules in terms of accuracy and AUC compared to existing works.","Transfer learning,Fine-tuning,Bilinear CNN,Lung nodules,Classification",Proceedings Paper,"ASSOC COMPUTING MACHINERY, 1515 BROADWAY, NEW YORK, NY 10036-9998 USA","Computer Science,Imaging Science & Photographic Technology",,,IMAGES,AIPR 2020: 2020 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION,,
48,CycleGAN Based Data Augmentation For Melanoma images Classification,,,115-119,"Chen Yixin,Zhu Yifan,Chang Yanfeng","Chen YX,Zhu YF,Chang YF",Chen YX,10.1145/3430199.3430217,University of London,"It is widely-known that melanoma is one of the deadliest skin cancers with a very high mortality rate, while it is curable with early identification. Therefore, early detection of melanoma is extremely necessary for the treatment of this disease. In recent decades, Convolutional Neural Networks (CNN) have achieved state-of-the-art performance in many different visual classification tasks, so they have also been employed in melanoma recognition tasks. Due to the complexity of the deep learning model and huge numbers of parameters, a large amount of labelled data is required to achieve a better training performance. However, in practical settings, it is difficult for many applications to obtain enough labelled sample data. This paper explore to solve this problems based on data augmentation strategy. In the experiment conducted in our paper, the training data is augmented through CycleGAN-based approaches to generate more training samples with detailed information, and then the CNN model can be trained using the artificially enlarged dataset. The experimental results show that the combination of CycleGAN data augmentation method and EfficientNet B1 can effectively saves the cost of manual annotation, while dramatically improves classification accuracy.","CycleGAN,data augmentation,Melanoma,images Classification,deep convolutional neural network",Proceedings Paper,"ASSOC COMPUTING MACHINERY, 1515 BROADWAY, NEW YORK, NY 10036-9998 USA","Computer Science,Imaging Science & Photographic Technology",,,,AIPR 2020: 2020 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION,,
49,Mammography Registration for Unsupervised Learning Based on CC and MLO Views,,,157-162,"Li Jiyun,Wang Xiaomeng,Qian Chen","Li JY,Wang XM,Qian C",Li JY,10.1145/3430199.3430238,Donghua University,"Mammography image usually contains two views in different orientations-Cranial Caudal (CC) and Mediolateral Oblique (MLO). In clinical decision making, the location of the lesions on the CC and MLO views are usually different. And the shape of breast varies greatly among patients, therefore, two views are necessary for evaluating the information in a comprehensively manner. In this paper, we propose an unsupervised registration algorithm based on CC and MLO views of mammography, which learns the deformation function through a Convolutional Neural Network (CNN). This function maps the input image to the corresponding deformation field and generates an image with the same shape as the template image after deformation, so that the doctor can better observe the two views. According to the radiologist's assessment, our work can contribute to medical image analysis and processing while providing novel guidance in learning-based registration and its applications.","Mammography,Registration,Deformation,Unsupervised",Proceedings Paper,"ASSOC COMPUTING MACHINERY, 1515 BROADWAY, NEW YORK, NY 10036-9998 USA","Computer Science,Imaging Science & Photographic Technology",,,"IMAGE,REGISTRATION",AIPR 2020: 2020 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION,,
50,An optimised pixel-based classification approach for automatic white blood cells segmentation,32,2,144-160,"Settouti Nesma,Bechar Mohammed El Amine,Daho Mostafa El Habib,Chikh Mohammed Amine","Settouti N,Bechar ME,Daho ME,Chikh MA",Settouti N,10.1504/IJBET.2020.105651,Universite Abou Bekr Belkaid,"The pixel-based classification is an automatic approach for classifying all pixels in the image but does not take into account the spatial information for the region of interest. On the other hand, region-growing methods take into account the neighbourhood pixels information. However, in region-growing methods, a pixel-group called 'points of interest' are needed to initialise the growing process. In this paper, we proposed an optimised pixel-based classification by the cooperation of region growing strategy. This original segmentation scheme is performed in two phases for the automatic recognition of white blood cells (WBC): the first is a learning step with colour characteristics of each pixel in the image. The second is a region growing application by classifying neighbouring pixels from pixels of interest extracted by the ultimate erosion technique. This process has proved that the cooperation allows obtaining a nucleus and cytoplasm segmentation as closer to what as expected in the reference images.","automatic segmentation,region growing approach,pixel-based classification,mathematical morphology,random forest,white blood cells",Article,"INDERSCIENCE ENTERPRISES LTD, WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 856, CH-1215 GENEVA, SWITZERLAND",Engineering,,,RECOGNITION,INTERNATIONAL JOURNAL OF BIOMEDICAL ENGINEERING AND TECHNOLOGY,,
51,A fully convolutional neural network approach for the localization of optic disc in retinopathy of prematurity diagnosis,38,5,6269-6278,"Ramachandran Sivakumar,Kochitty Shymol,Vinekar Anand,John Renu","Ramachandran S,Kochitty S,Vinekar A,John R",John R,10.3233/JIFS-179708,Indian Institute of Technology System (IIT System),"The identification of landmark features such as optic disc is of high prognostic significance in diagnosing various ophthalmic diseases. A retinal fundus photograph provides a non-invasive observation of the optic disc. The wide variability present in fundus images poses difficulties in its detection and further analysis. The reported work is a part of the fundus image screening for the diagnosis of Retinopathy of Prematurity (ROP), a sight threatening disorder seen in preterm infants. The diagnostic procedure for this disease estimates blood vessel tortuosity in a pre-defined area around the optic disc. Hence accurate optic disc localization is very important for the disease diagnosis. In this paper, we present an optic disc localization technique using a deep neural network based framework. The proposed system relies on the underlying architecture of YOLOv3, a fully convolutional neural network pipeline for object detection and localization. The new approach is tested in 10 different data sets and has achieved an overall accuracy of 99.25%, outperforming other deep learning-based OD detection methods. The test results guarantees the robustness of the proposed technique, and hence may be deployed to assist medical experts for disease diagnosis.","Optic disc,deep learning,convolutional neural network,retinal images,ROP diagnosis",Article; Proceedings Paper,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS",Computer Science,,1.797,"RETINAL,IMAGES,FUNDUS,IMAGES,CLASSIFICATION,SEGMENTATION,NERVE,CUP",JOURNAL OF INTELLIGENT & FUZZY SYSTEMS,,
52,Prediction of machining characteristics of finish cut WEDM process for pure titanium using feed forward back propagation neural network,25,,592-601,"Chalisgaonkar Rupesh,Kumar Jatinder,Pant Piyush","Chalisgaonkar R,Kumar J,Pant P",Chalisgaonkar R,10.1016/j.matpr.2019.07.260,KIET Group of Institutions,,"SURFACE-ROUGHNESS,OPTIMIZATION,EDM,MACHINABILITY,MODEL",Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,,"SURFACE-ROUGHNESS,OPTIMIZATION,EDM,MACHINABILITY,MODEL",MATERIALS TODAY-PROCEEDINGS,,
53,A method to reduce model uncertainty by fusing the output from multiple stochastic simulators,1618,,,"Abdallah Imad,Tatsis Konstantinos,Mylonas Charilaos,Ntertimanis Vasilis,Chatzi Eleni","Abdallah I,Tatsis K,Mylonas C,Ntertimanis V,Chatzi E",Abdallah I,10.1088/1742-6596/1618/4/042019,ETH Zurich,"In virtualizing engineered systems, it is essential to come up with simulators that are essentially capable of representing the system in its ""as-deployed"" state. Any attempt to this end may only be approximate given the inherent uncertainties present in the loadings and operational conditions of the system, as well as the configuration of the system itself (geometry, materials, control systems, boundary conditions, etc.). This is especially true for complex systems, such as wind turbines, where often a number of assumptions govern the setup of the engineering models. Such models are often made available at different granularities with each one offering a diversified level of precision depending on the quantity of interest (e.g. macroscopic displacements or microscopic strains) and the properties of the acting loads (e.g. amplitude and frequency content). This implies that the predictive capabilities are severely hampered when a single so-deemed best model is chosen for simulation. Building on this idea, we here present a method for fusing the outputs from multiple simulators (e.g. aero-servo-hydro-elastic simulators) for estimating a quantity of interest (QoI) with higher precision. The proposed ensemble learning approach comprises two main building blocks. Firstly, a clustering step by means of a Variational Bayesian Gaussian mixture model, employed for the weighing of each available simulator. Clustering is performed on the basis of the binned input space, which allows for extraction of a probability map for each local region of the binned input space. This delivers an adaptive scheme, which allows different simulators to more or less prominently contribute to the prediction of the QoI, depending on the range of the input parameters. Local weighted Bootstrap Aggregation is then executed in a second step for combining the clustered ensemble of outputs from the individual simulators. A simulated toy example and a wind turbine blade fatigue case study are herein exploited to demonstrate the efficacy of the suggested ensemble learning scheme. The approach is compared against alternatives typically adopted in existing literature, such as Stacking, classical Bagging, and Bayesian Model Averaging. The results confirm an improvement in predictive capabilities as expressed via the reduction in the generalization error and the narrowing of the associated confidence interval.",,Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Science & Technology - Other Topics,Energy & Fuels,Engineering,Physics",,,,,https://doi.org/10.1088/1742-6596/1618/4/042019,
54,SCADA-based neural network thrust load model for fatigue assessment: cross validation with in-situ measurements,1618,,,"Santos Francisco d N.,Noppe Nymfa,Weijtjens Wout,Devriendt Christof","Santos FDN,Noppe N,Weijtjens W,Devriendt C",Santos FDN,10.1088/1742-6596/1618/2/022020,Vrije Universiteit Brussel,"In this contribution SCADA data and thrust attained through strain measurements are used to train a neural network model which predicts the thrust load of an offshore wind turbine. The model is subsequently cross-validated for different turbines with SCADA data outside of the training period as input and the thrust load from strain measurements as the expected output, and the impact of wind speed and different operating conditions studied. The results for the model, such as MAE, are kept generally under 2 %. The estimated thrust load signal is then converted into the damage equivalent stress caused by the quasi-static load, allowing to quantify the damage induced by the thrust load. The model performed, in general, well, but some over-/underpredictions are severely amplified when converting the loads into the damage equivalent stress.",,Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Science & Technology - Other Topics,Energy & Fuels,Engineering,Physics",,,,,https://doi.org/10.1088/1742-6596/1618/2/022020,
55,A Novel Methodology for Series Arc Fault Detection by Temporal Domain Visualization and Convolutional Neural Network,20,1,,"Yang Kai,Chu Ruobo,Zhang Rencheng,Xiao Jinchao,Tu Ran","Yang K,Chu RB,Zhang RC,Xiao JC,Tu R",Zhang RC,10.3390/s20010162,Fuzhou University,"AC arc faults are one of the most important causes of residential electrical wiring fires, which may produce extremely high temperatures and easily ignite surrounding combustible materials. The global interest in machine learning-based methods for arc fault diagnosis applications is increasing due to continuous challenges in efficiency and accuracy. In this paper, a temporal domain visualization convolutional neural network (TDV-CNN) methodology is proposed. The current transformer and high-speed data acquisition system are used to collect the current of a series of arc faults, then the signal is filtered by a digital filter and converted into a gray image in time sequence before being fed into TDV-CNN. Five different electric loads were selected for experimental validation with various signal characteristics, including vacuum cleaner, fluorescent lamp, dimmer, heater, and desktop computer. The experimental results confirm that the classification accuracy of the five loads' work states in the ten categories could reach 98.7% or even higher by adjusting parameters perfectly. The methodology is believed to be reliable for series arc detection with relatively high accuracy and also has important potential applications in other fault diagnosis fields.","series arc fault,convolutional neural network,temporal domain visualization,gray image",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://www.mdpi.com/1424-8220/20/1/162/pdf,
56,Alertness-based subject-dependent and subject-independent filter optimization for improving classification efficiency of SSVEP detection,28,,S173-S180,"Cao Lei,Fan Chunjiang,Wang Zijian,Hou Lusong,Wang Haoran,Li Gang","Cao L,Fan CJ,Wang ZJ,Hou LS,Wang HR,Li G",Fan CJ,10.3233/THC-209017,"Wuxi Rehabil Hosp, Wuxi 214181, Jiangsu, Peoples R China.","BACKGROUND: Mental task-based brain computer interface (BCI) systems are usually developed for neural prostheses technologies and medical rehabilitation. The mental workload was too heavy for the user to manipulate BCI effectively. Fortunately, electroencephalography (EEG) signal is not only used for BCI control but also relates to the changes of mental states.
OBJECTIVE: We proposed a novel method for identifying non-effective trials of Steady State Visual Evoked Potential (SSVEP)-based BCI.
METHODS: We used the subject-dependent and subject-independent alertness models identifying non-effective trials of SSVEP-BCI systems.
RESULTS: The result implied that the subject-dependent alertness model was most useful for improving the classification accuracy in the task. However, the subject-independent alertness model could enhance the prediction ability of SSVEP-based BCI system.
CONCLUSION: In comparison to the conventional canonical correlation analysis (CCA) method without alertness-model filtering, the raise of precision was valuable for the technical development of BCI works. It demonstrated the effectiveness of our proposed subject-dependent and subject-independent methods.","Alertness,SSVEP,sleepiness,CCA",Article,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS","Health Care Sciences & Services,Engineering",,1.116,"BRAIN-COMPUTER,INTERFACES,EEG,COMMUNICATION,FATIGUE,POWER,BCI",TECHNOLOGY AND HEALTH CARE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7369106,
57,Predictive models of hypertensive disorders in pregnancy based on support vector machine algorithm,28,,S181-S186,"Yang Lin,Sun Ge,Wang Anran,Jiang Hongqing,Zhang Song,Yang Yimin,Li Xuwen,Hao Dongmei,Xu Mingzhou,Shao Jing","Yang L,Sun G,Wang AR,Jiang HQ,Zhang S,Yang YM,Li XW,Hao DM,Xu MZ,Shao J",Yang L; Zhang S,10.3233/THC-209018,"Beijing Univ Technol, Coll Life Sci & Bioengn, Intelligent Physiol Measurement & Clin Translat, Beijing Int Base Sci & Technol Cooperat, Beijing 100024, Beijing, Peoples R China.","BACKGROUND: The risk factors of hypertensive disorders in pregnancy (HDP) could be summarized into three categories: clinical epidemiological factors, hemodynamic factors and biochemical factors.
OBJECTIVE: To establish models for early prediction and intervention of HDP.
METHODS: This study used the three types of risk factors and support vector machine (SVM) to establish prediction models of HDP at different gestational weeks.
RESULTS: The average accuracy of the model was gradually increased when the pregnancy progressed, especially in the late pregnancy 28-34 weeks and >= 35 weeks, it reached more than 92%.
CONCLUSION: Multi-risk factors combined with dynamic gestational weeks' prediction of HDP based on machine learning was superior to static and single-class conventional prediction methods. Multiple continuous tests could be performed from early pregnancy to late pregnancy.","Support vector machine algorithm,machine learning,model research",Article,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS","Health Care Sciences & Services,Engineering",,1.116,PREECLAMPSIA,TECHNOLOGY AND HEALTH CARE,https://europepmc.org/articles/pmc7369093?pdf=render,
58,Multiple answers to a question: a new approach for visual question answering,37,1,119-131,"Hosseinabad Sayedshayan Hashemi,Safayani Mehran,Mirzaei Abdolreza","Hosseinabad SH,Safayani M,Mirzaei A",Safayani M,10.1007/s00371-019-01786-4,Isfahan University of Technology,"With the advent of deep learning, multi-modal data have been of great interest. One of the multi-modal tasks which can be included in the computer vision domain is visual question answering (VQA). In VQA, a question and an image are entered into the model and the model tries to answer the question according to the image. To the best of our knowledge, the current techniques look at the image and only give one answer to the question asked. However, in some situations, there are several answers to the asked question. In this paper, we address this problem and define a new domain in the task of VQA as well as a new computationally efficient approach to cope with multiple-answer VQA. In this approach, we use a sliding window in an efficient manner to examine the answer to the question in different parts of the image. Due to the fact that so far no proper dataset is available for multiple-answer VQA, we provide a new dataset for evaluating our proposed model. The experiments express that our model uses 94% less operation than other models, making it very suitable for real-time applications.","Visual question answering,Deep learning,Convolution neural network,Multiple answers,Recurrent neural network",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,2.081,,VISUAL COMPUTER,,
59,Interpretable Deep Learning Models for Single Trial Prediction of Balance Loss,,,268-273,"Ravindran Akshay Sujatha,Cestari Manuel,Malaya Christopher,John Isaac,Francisco Gerard E.,Layne Charles,Vidal Jose L. Contreras","Ravindran AS,Cestari M,Malaya C,John I,Francisco GE,Layne C,Vidal JLC",Ravindran AS,,University of Houston System,"Wearable robotic devices are being designed to assist the elderly population and other patients with locomotion disabilities. However, wearable robotics increases the risk from falling. Neuroimaging studies have provided evidence for the involvement of frontocentral and parietal cortices in postural control and this opens up the possibility of using decoders for early detection of balance loss by using electroencephalography (EEG). This study investigates the presence of commonly identified components of the perturbation evoked responses (PEP) when a person is in an exoskeleton. We also evaluated the feasibility of using single-trial EEG to predict the loss of balance using a convolution neural network. Overall, the model achieved a mean 5-fold cross-validation test accuracy of 75.2 % across six subjects with 50% as the chance level. We employed a gradient class activation map-based visualization technique for interpreting the decisions of the CNN and demonstrated that the network learns from PEP components present in these single trials. The high localization ability of Grad-CAM demonstrated here, opens up the possibilities for deploying CNN for ERP/PEP analysis while emphasizing on model interpretability.",NEURAL-NETWORKS,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,NEURAL-NETWORKS,,,
60,A Novel Deep Learning Method for Nuclear Cataract Classification Based on Anterior Segment Optical Coherence Tomography Images,,,662-668,"Zhang Xiaoqing,Xiao Zunjie,Higashita Risa,Chen Wan,Yuan Jin,Fang Jiansheng,Hu Yan,Liu Jiang","Zhang XQ,Xiao ZJ,Higashita R,Chen W,Yuan J,Fang JS,Hu Y,Liu J",Liu J,,Southern University of Science & Technology,"Nuclear cataract is one of the most common types of cataract. In the recent, ophthalmologists are increasingly using anterior segment optical coherence tomography (AS-OCT) images to diagnose many ocular diseases including cataract. The relationship between cataract and the lens opacity based on AS-OCT images has been being studied in clinical pioneer research. However, using AS-OCT images to classify cataract automatically based on computer-aided diagnosis (CAD) technique has not been seriously studied. This paper proposes a novel Convolutional Neural Network (CNN) model named GraNet for nuclear cataract classification based on AS-OCT images. In the GraNet, we introduce a grading block to learn high-level feature representations based on the pointwise convolution method. To further improve the classification performance, we propose a simple and efficient cross-training method is comprised of focal loss and cross-entropy loss. Extensive experiments are conducted on the AS-OCT image dataset, the results demonstrate that the proposed methods achieve better nuclear cataract classification results than baselines.","AS-OCT image,nuclear cataract,GraNet,cross-training method",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
61,Multi-scene citrus detection based on multi-task deep learning network,,,912-919,"Wen Chenxin,Zhang Hui,Li Honghao,Li Hongwen,Chen Jinhai,Guo Hangge,Cheng Shihui","Wen CX,Zhang H,Li HH,Li HW,Chen JH,Guo HG,Cheng SH",Wen CX,,Changsha University of Science & Technology,"Citrus detection is an essential component of the citrus industry. In order to realize the identification, positioning, segmentation, maturity estimation, and quality evaluation of citrus in complex environments, this paper proposes a multi-task deep learning network that can be applied to multiple scenes for citrus detection. The system is based on the Mask R-CNN network framework. By adding multi-task branches, modifying model parameters, and designing multi-task loss function, it can realize multi-task detection of citrus in a complex environment. The mAP on the validation set of the model obtained after training is 91.56%, and it takes an average of 0.35s to detect a citrus image using GeForce GTX 1080 Ti. Through the comparative analysis of the detection effect and performance evaluation index F value of multi-task citrus under different maturity, quality, citrus quantity, and light angle, the experimental results show that the model can effectively and accurately detect the citrus with different maturity and quality in the environment of citrus fruit overlap, tree branch and leaf occlusion, light change and surface shadow. The code is available at https://github.com/wxx-gan/Multitask.","Multi-task deep learning,multi-scene citrus detection,Mask R-CNN,maturity and quality assessment,multi-task loss design,multi-task performance evaluation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,AGRICULTURE,,,
62,Predicting primary site of secondary liver cancer with a neural estimator of metastatic origin,7,1,,"Schau Geoffrey F.,Burlingame Erik A.,Thibault Guillaume,Anekpuritanang Tauangtham,Wang Ying,Gray Joe W.,Corless Christopher,Chang Young H.","Schau GF,Burlingame EA,Thibault G,Anekpuritanang T,Wang Y,Gray JW,Corless C,Chang YH",Chang YH,10.1117/1.JMI.7.1.012706,Oregon Health & Science University,"Purpose: Pathologists rely on relevant clinical information, visual inspection of stained tissue slide morphology, and sophisticated molecular diagnostics to accurately infer the biological origin of secondary metastatic cancer. While highly effective, this process is expensive in terms of time and clinical resources. We seek to develop and evaluate a computer vision system designed to reasonably infer metastatic origin of secondary liver cancer directly from digitized histopathological whole slide images of liver biopsy.
Approach: We illustrate a two-stage deep learning approach to accomplish this task. We first train a model to identify spatially localized regions of cancerous tumor within digitized hematoxylin and eosin (H&E)-stained tissue sections of secondary liver cancer based on a pathologist's annotation of several whole slide images. Then, a second model is trained to generate predictions of the cancers' metastatic origin belonging to one of three distinct clinically relevant classes as confirmed by immunohistochemistry.
Results: Our approach achieves a classification accuracy of 90.2% in determining metastatic origin of whole slide images from a held-out test set, which compares favorably to an established clinical benchmark by three board-certified pathologists whose accuracies ranged from 90.2% to 94.1% on the same prediction task.
Conclusions: We illustrate the potential impact of deep learning systems to leverage morphological and structural features of H&E-stained tissue sections to guide pathological and clinical determination of the metastatic origin of secondary liver cancers. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","deep learning,digital pathology,cancer,liver,metastasis",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,,JOURNAL OF MEDICAL IMAGING,https://www.biorxiv.org/content/biorxiv/early/2019/07/02/689828.full.pdf,
63,Impact of Physiological Sensor Variance on Machine Learning Algorithms,,,241-247,"Simons Ama,Doyle Thomas,Musson David,Reilly James","Simons A,Doyle T,Musson D,Reilly J",Simons A,,McMaster University,"Machine learning based acute stress detection systems use physiological sensor data to objectively predict acute stress. However, machine learning algorithms developed for stress detection do not consider how machine learning algorithm performance may be affected based on a change(s) in the deployment environment. In this study, the deployment environment changes that are investigated are sensor type and sensor placement. Electrodermal activity (EDA) and skin temperature (TEMP) data from two different sensors, the RespiBAN Professional (RespiBAN) and the Empatica E4 are used to train three different machine learning models. The RespiBAN records the EDA data from the rectus abdominis and records the skin TEMP data from the sternum. The Empatica E4 sensor records both EDA and skin TEMP data from the wrist. Three different support vector machine (SVM) models were trained to classify no-stress versus stress states using EDA and skin TEMP data. The first model was trained using data from the RespiBAN wearable sensor (SVM-R), the second model was trained using data from the Empatica E4 sensor (SVM-E) and third model was trained using data from both sensors (SVM-RE). The accuracy of SVM-R on a test set recorded by the RespiBAN sensor was 100%. The accuracy of SVM-E on a test set recorded by the Empatica E4 sensor was 99%. The accuracy of SVM-RE on a test set recorded by both the RespiBAN and Empatica E4 sensor was 82%. The accuracy of the SVM-R on a test set recorded by the Empatica E4 was 64%. These results suggest that research and development cannot be hardware or placement agnostic with wearable sensing data. Sensor type and placement must be taken into consideration when reporting performance metrics of physiological based stress detection machine learning algorithms.","wearable physiological sensors,stress detection,support vector machine",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
64,Tissue Discrimination from Impedance Spectroscopy as a Multi-objective Optimisation Problem with Weighted Naive Bayes Classification,,,321-327,"Kent Brayden,Rossa Carlos","Kent B,Rossa C",Kent B,,"Ontario Tech Univ, Fac Engn & Appl Sci, Oshawa, ON, Canada.","Tissue classification from electrical impedance spectroscopy has several applications in diagnosis, surgical planning, and minimally invasive surgery. The method involves applying an alternating current to the sample and measuring its electric impedance at various frequencies. The spectrum is fit to a equivalent electric circuit that mimics the shape of the tissue's impedance spectrum. The model parameters are then used for classification.
This paper proposes a new solution to decompose the model fitting problem into a form suitable for multi-objective optimisation, from which all the non-dominated solutions are used to form the database of parameters for a given tissue, as opposed to a single solution that is typically seen in impedance spectroscopy. The solution explores the use of the reference point dominance condition within Non-dominated Sorting Genetic Algorithm II to fit the data to the double dispersion Cole model. Each non-dominated solution contain values for the dispersion model elements. The multiple parameter value solutions from the optimiser are used as features in a weighted Naive Bayes classifier to identify a new tissue sample. Experiments results in 3 different tissue samples shows that the method is successful in correctly labelling the data with an average accuracy of 89%.","Electric Impedance Spectroscopy,Weighted Naive Bayes Classifier,Multi-objective Optimisation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
65,Driver Drowsiness Classification Using Data Fusion of Vehicle-based Measures and ECG Signals,,,451-456,"Arefnezhad Sadegh,Eichberger Arno,Fruehwirth Matthias,Kaufmann Clemens,Moser Maximilian","Arefnezhad S,Eichberger A,Fruhwirth M,Kaufmann C,Moser M",Arefnezhad S,,Graz University of Technology,"Reduced alertness due to the drowsy state that impairs driving performance has been reported to be one of the significant causes of road accidents. This paper aims to present a data fusion of vehicle-based and ECG signals for classifying three levels of driver drowsiness, including alert, moderately drowsy, and extremely drowsy. Lateral deviation from the road centerline, steering wheel angle, and lateral acceleration are employed as vehicle-based signals. Two ECG leads are also exploited to collect heart rate variability of drivers. Thirty-nine features from vehicle-based data and ten features from heart rate variability signals are extracted. Finally, k-nearest neighbors and random forest are used as classifiers to classify the level of drowsiness using selected features by the sequential feature selector. Age and gender, as the two most effective human factors, are considered to assess the performance of the method in different age/gender groups. The proposed method is evaluated on experimental data that were collected from 93 manual driving tests using 47 different human volunteers in a driving simulator. Results show that hyperparameter-optimized random forests obtain an accuracy of 82.8% for the detection of drowsiness levels based on vehicle signals only, and an accuracy of 88.5% based on ECG derived data only. Data fusion of ECG signals and vehicle data improves the accuracy of classification to 91.2%. The model performs slightly better on older than on younger drivers, but no gender difference was found.","Drowsy driving,ECG signals,vehicle-based measures,drowsiness classification,human factors",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,SYSTEM,,,
66,Shining Light on the Human Brain: An Optical BCI for Communicating with Patients with Brain Injuries,,,502-507,"Abdalmalak Androu,Laforge Geoffrey,Yip Lawrence C. M.,Milej Daniel,Gonzalez-Lara Laura E.,Anazodo Udunna,Owen Adrian M.,St Lawrence Keith","Abdalmalak A,Laforge G,Yip LCM,Milej D,Gonzalez-Lara LE,Anazodo U,Owen AM,St Lawrence K",Abdalmalak A,,Western University (University of Western Ontario),"Functional near-infrared spectroscopy (fNIRS) is an emerging optical technology that can be used to monitor brain function at the bedside. Recently, there has been a great interest in using fNIRS as a tool to assess command-driven brain activity in patients with severe brain injuries to infer residual awareness. In this study, time-resolved (TR) fNIRS, a variant of fNIRS with enhanced sensitivity to the brain, was used to assess brain function in patients with prolonged disorders of consciousness (DOC). A portable system was developed in-house, and patients were assessed in their homes or long-term care facilities across London and the Greater Toronto Area, Canada. Five DOC patients and one locked-in patient were recruited in this study, and motor imagery was used to elicit command-driven brain activity. TR-fNIRS data were analyzed using the general linear modelling (GLM) approach, as well as with basic machine learning. Three patients showed activity with GLM, four with machine learning, and two with both techniques. Interestingly, the two patients that showed activity by both approaches also had detectable motor imagery activity by functional magnetic resonance imaging. These promising preliminary results highlight the potential of TR fNIRS as a tool to probe consciousness and map brain activity at the bedside.","disorders of consciousness,time-resolved functional near-infrared spectroscopy,motor imagery,functional magnetic resonance imaging",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"NEAR-INFRARED,SPECTROSCOPY,SENSITIVITY,DISORDERS",,,
67,Modeling Disease Progression via Weakly Supervised Temporal Multitask Matrix Completion,,,1141-1148,"Wang Lingsheng,Xu Lei,Li Ping,Zha Siming,Chen Lei","Wang LS,Xu L,Li P,Zha SM,Chen L",Chen L,,Nanjing University of Posts & Telecommunications,"Alzheimer's disease (AD) is one of the most common neurodegenerative diseases. Understanding AD progression can empower the patients in taking proactive care. Mini Mental State Examination (MMSE) and AD Assessment Scale Cognitive subscale (ADAS-Cog) are two prevailing clinical measures designed to evaluate the AD progression. In this paper, we propose a weakly supervised Temporal Multitask Matrix Completion (TMMC) framework, which combines a novel transductive multitask feature selection scheme, to simultaneously predict AD progression measured by MMSE and ADAS-Cog, and identify related biomarkers trackable of AD progression. Specifically, by treating the prediction of cognitive scores at each time point as a regression task, we first formulate AD progression problem as a standard Multitask Matrix Completion (MMC) model. Secondly, considering the limited number of samples available in this study, we introduce a transductive feature selection scheme to jointly select the task-shared features for multiple time points and the task-specific features for different time points, and thus alleviate the over-fitting defect caused by Small-Sample-Size issue. Thirdly, aiming at the small change of cognitive scores between successive time points for a patient, we employ a temporal regularization scheme to capture the temporal smoothness of cognitive scores. Furthermore, we design an efficient optimization algorithm based on Alternative Minimization and Difference of Convex Programming techniques to solve the proposed TMMC framework. Finally, the extensive experiments performed on real-world Alzheimer's disease dataset demonstrate the effectiveness of our TMMC framework.","Matrix completion,Weakly supervised learning,Transductive feature selection,Disease progression prediction",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"MILD,COGNITIVE,IMPAIRMENT,ALGORITHM",,,
68,FBCSP and Adaptive Boosting for Multiclass Motor Imagery BCI Data Classification: A Machine Learning Approach,,,1275-1279,"Das Rig,Lopez Paula S.,Khan Muhammad Ahmed,Iversen Helle K.,Puthusserypady Sadasivan","Das R,Lopez PS,Khan MA,Iversen HK,Puthusserypady S",Das R,,Technical University of Denmark,"Classification of non-stationary electroencephalogram (EEG) data are of utmost importance for brain-computer interface (BCI) technology. This paper proposes a robust multiclass motor imagery (MI) BCI data classification technique. It is based on filter bank common spatial patterns (FBCSP) and AdaBoost classification technique. The method is tested on the 4-class MI BCI competition IV dataset 2a and the results show superior performance compared to the current state-of-the-art performances. This paper also analyzes different frequency subbands for the MI EEG data, in order to find the best sub-band which contains the most significant features for distinguishing different MI tasks.","Brain computer interface (BCI),filter-bank common spatial patterns (FBCSP),motor imagery (MI),Adaptive boosting (AdaBoost)",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
69,Deep Multi-Task Learning for SSVEP Detection and Visual Response Mapping,,,1280-1285,"Khok Hong Jing,Koh Victor Teck Chang,Guan Cuntai","Khok HJ,Koh VTC,Guan CT",Khok HJ,,Alibaba Group,"Glaucoma is an eye disease that occurs without the onset of symptoms at initial, and late diagnosis results in irreversible degeneration of retinal ganglion cells. Standard automated perimetry is the gold standard for assessing glaucoma; however, the examination is subjective, where responses can fluctuate each time the test is performed, significantly confounding the test's interpretation. In this study, we present our approach that aims to provide a rapid point-of-care diagnostics for glaucoma patients by eliminating the cognitive aspect in existing visual field assessment. Unlike existing methods that mostly report the foveal target detection's accuracy, we employed a multi-task learning architecture that efficiently captures signals simultaneously from the fovea and the neighboring targets in the peripheral vision, generating a visual response map. Furthermore, we designed a multi-task learning module that learns multiple tasks in parallel efficiently. We evaluated our model classification on a 40-classes dataset, with yields 92% and 95% in accuracy and F1 score respectively. Our model is able to perform on a calibration-free user-independent scenario, which is desirable for clinical diagnostics. Our proposed approach could be a stepping stone for an objective assessment of glaucoma patients' visual field.","SSVEP,Multi-task Learning,Convolutional Neural Network",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"STANDARD,AUTOMATED,PERIMETRY,GLAUCOMA,PREVALENCE",,,
70,Examining the Relationship between EEG Dynamics and Emotion Ratings during Video Watching using Adaptive Mixture Independent Component Analysis,,,1491-1497,"Ran Shihan,Hsu Sheng-Hsiou,Jung Tzyy-Ping","Ran SH,Hsu SH,Jung TP",Ran SH,,"Univ Calif San Diego UCSD, Swartz Ctr Computat Neurosci, San Diego, CA 92093 USA.","Electroencephalography (EEG)-based emotion recognition has advanced the field in affective computing and has enabled applications in human-computer interactions. Despite significant progress has been made in decoding emotion using supervised machine-learning methods, few studies applied data-driven, unsupervised approaches to explore the underlying EEG dynamics during an emotion experiment and examine how such dynamics correlate with subjective reports of emotion. This study employs the adaptive mixture independent component analysis (AMICA), an unsupervised approach, to EEG data from the DEAP dataset where 32 subjects watched emotional videos. Empirical results showed that AMICA could learn distinct models that separated EEG date collected in the emotion experiment. The identified changes in EEG patterns were weakly-correlated with the four reported emotion scales, indicating the underlying EEG dynamics partially reflected the emotional activities as well as the emotion-irrelevant brain dynamics. Further, the correlations between EEG dynamics and individuals' subjective emotional ratings were significantly higher than those between the EEG and the average ratings from online raters. Finally, building an emotion-decoding model based on the EEG dynamics revealed a significantly better classification performance for valence ratings compared to arousal. This study demonstrated the use of AMICA in characterizing the EEG dynamics in emotion experiments and provided insight into the relationship between EEG and the reported emotional experiences. The unsupervised learning approach can be applied to studying emotion and other confounding factors such as emotion irrelevant EEG artifacts, thereby improving the performance of emotion decoding for EEG-based affective computing.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
71,Automatic Classification of Turner Syndrome Using Unsupervised Feature Learning,,,1578-1583,"Liu Lu,Sun Jingchao,Li Jianqiang,Pei Yan","Liu L,Sun JC,Li JQ,Pei Y",Pei Y,,University of Aizu,"Recently, the automatic diagnosis of Turner syndrome (TS) has been paid more attention. However, existing methods relied on handcrafted image features. Therefore, we propose a TS classification method using unsupervised feature learning. Specifically, first, the TS facial images are preprocessed including aligning faces, facial area recognition and processing of image intensities. Second, pre-trained convolution filters are obtained by K-means based on image patches from TS facial images, which are used in a convolutional neural network (CNN); then, multiple recursive neural networks are applied to process the feature maps from the CNN to generate image features. Finally, with the extracted features, support vector machine is trained to classify TS facial images. The results demonstrate the proposed method is more effective for the classification of TS facial images, which achieves the highest accuracy of 84.95%.","Turner syndrome,unsupervised feature learning,convolutional neural network,support vector machine,image processing",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"DIAGNOSIS,CARE",,,
72,A Deep Bayesian Ensembling Framework for COVID-19 Detection using Chest CT Images,,,1584-1589,"Tabarisaadi Pegah,Khosravi Abbas,Nahavandi Saeid","Tabarisaadi P,Khosravi A,Nahavandi S",Khosravi A,,Deakin University,"The chest computed tomography (CT) images have been used for COVID-19 detection. Automating the process of analyzing can save great amount of time and energy. In this paper a deep bayesian ensembling framework is proposed for automatic detection of COVID-19 cases using the chest CT scans. Data augmentation is applied to increase the size and quality of training data available. Transfer learning is utilized to extract informative features. The extracted features are used to train the three different bayesian classifiers. The uncertainty of the neural network predictions is estimated by anchored, unconstrained and regularized bayesian ensembling methods. The reliability of predictions is then delineated. The epistemic and aleatoric uncertainties are estimated and different bayesian classifiers are compared from different perspectives. We use a small dataset containing only 275 CT images of positive COVID-19 cases. The results sounds promising and they can be improved in the future, as the performance of deep neural networks is reliant to big datasets. Prediction accuracy and predictive uncertainty estimates for unseen chest CT images indicate that the deep bayesian ensembling is a promising framework for COVID-19 detection.","Bayesian Ensembling,Uncertainty quantification,Deep Neural Networks,COVID-19,CT images",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
73,Brain Tumor Segmentation from Multi-Spectral Magnetic Resonance Image Data Using an Ensemble Learning Approach,,,1699-1704,"Gyorfi Agnes,Csaholczi Szabolcs,Fulop Timea,Kovacs Levente,Szilagyi Laszlo","Gyorfi A,Csaholczi S,Fulop T,Kovacs L,Szilagyi L",Gyorfi A,,Obuda University,"The automatic segmentation of medical images represents a research domain of high interest. This paper proposes an automatic procedure for the detection and segmentation of gliomas from multi-spectral MRI data. The procedure is based on a machine learning approach: it uses ensembles of binary decision trees trained to distinguish pixels belonging to gliomas to those that represent normal tissues. The classification employs 100 computed features beside the four observed ones, including morphological, gradients and Gabor wavelet features. The output of the decision ensemble is fed to morphological and structural post-processing, which regularize the shape of the detected tumors and improve the segmentation quality. The proposed procedure was evaluated using the BraTS 2015 train data, both the high-grade (HG) and the low-grade (LG) glioma records. The highest overall Dice scores achieved were 86.5% for HG and 84.6% for LG glioma volumes.","magnetic resonance imaging,brain tumor,tumor detection,image segmentation,ensemble learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"CONVOLUTIONAL,NEURAL-NETWORKS,INTENSITY,INHOMOGENEITY,MODEL,FEATURES",,http://real.mtak.hu/114326/1/bdtsmc.pdf,
74,Discrimination of Walking and Standing from Entropy of EEG Signals and Common Spatial Patterns,,,2008-2013,"Tortora Stefano,Artoni Fiorenzo,Tonin Luca,Chisari Carmelo,Menegatti Emanuele,Micera Silvestro","Tortora S,Artoni F,Tonin L,Chisari C,Menegatti E,Micera S",Tortora S,,University of Padua,"Recently, the complexity analysis of brain activity has shown the possibility to provide additional information to discriminate between rest and motion in real-time. In this work, we propose a novel entropy-based machine learning method to classify between standing and walking conditions from the sole brain activity. The Shannon entropy has been used as a complexity measure of electroencephalography (EEG) signals and subject-specific features for classification have been selected by Common Spatial Patterns (CSP) filter. Exploiting these features with a linear classifier, we achieved > 85% of classification accuracy over a long period (approximate to 25 min) of standing and treadmill walking on 11 healthy subjects. Moreover, we implemented the proposed approach to successfully discriminate in real-time between standing and over-ground walking on one healthy subject. We suggest that the reliable discrimination of rest against walking conditions achieved by the proposed method may be exploited to have more stable control of devices to restore locomotion, avoiding unpredictable and dangerous behaviors due to the delivery of undesired control commands.","BRAIN,CLASSIFICATION,BCI",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"BRAIN,CLASSIFICATION,BCI",,,
75,ROS-Neuro Integration of Deep Convolutional Autoencoders for EEG Signal Compression in Real-time BCIs,,,2019-2024,"Valenti Andrea,Barsotti Michele,Brondi Raffaello,Bacciu Davide,Ascari Luca","Valenti A,Barsotti M,Brondi R,Bacciu D,Ascari L",Valenti A,,University of Pisa,"Typical EEG-based BCI applications require the computation of complex functions over the noisy EEG channels to be carried out in an efficient way. Deep learning algorithms are capable of learning flexible nonlinear functions directly from data, and their constant processing latency is perfect for their deployment into online BCI systems. However, it is crucial for the jitter of the processing system to be as low as possible, in order to avoid unpredictable behaviour that can ruin the system's overall usability. In this paper, we present a novel encoding method, based on on deep convolutional autoencoders, that is able to perform efficient compression of the raw EEG inputs. We deploy our model in a ROS-Neuro node, thus making it suitable for the integration in ROS-based BCI and robotic systems in real world scenarios. The experimental results show that our system is capable to generate meaningful compressed encoding preserving to original information contained in the raw input. They also show that the ROS-Neuro node is able to produce such encodings at a steady rate, with minimal jitter. We believe that our system can represent an important step towards the development of an effective BCI processing pipeline fully standardized in ROS-Neuro framework.","ROS-Neuro,Deep Learning,Brain-Computer Interface",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,http://arxiv.org/pdf/2008.13485,
76,Vegetable Mass Estimation based on Monocular Camera using Convolutional Neural Network,,,2106-2112,"Miura Yasuhiro,Sawamura Yuki,Shinomiya Yuki,Yoshida Shinichi","Miura Y,Sawamura Y,Shinomiya Y,Yoshida S",Miura Y,,Kochi University Technology,"Vegetable mass estimation from monocular RGB camera images is proposed. Vegetables are fragmented and placed on a conveyor belt of food processing machine and the monocular camera placed over the belt take pictures of vegetables on the belt. The proposed system does not employ any scale, load cell, and other mass scaling equipment. We apply pre-trained convolutional neural networks to estimate the mass of vegetables. Transfer learning including various levels of fine-tuning is also applied. For pre-trained network, we use Xception, VGG16, ResNet50, and Inception_v3, which are pre-trained using ImageNet. The result shows that the best estimation accuracy is achieved by VGG16, whose MAPE (mean average percentage error) is 11.1%. Additionally, we fine-tune VGG16 and the accuracy reduces to 7.9% for MAPE. From this result, the performance of CNN model can improve by fine-tuning. The proposed system can be applied to low-cost, high-speed, and efficient measurement of foods replaced to load cells.","Measurement System,Monocular Camera,CNN,Transfer Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
77,Multi-Channel EEG Based Emotion Recognition Using Temporal Convolutional Network and Broad Learning System,,,2452-2457,"Jia Xue,Zhang Tong,Chen C. L. Philip,Liu Zhulin,Chen Long,Wen Guihua,Hu Bin","Jia X,Zhang T,Chen CLP,Liu ZL,Chen L,Wen GH,Hu B",Zhang T,,South China University of Technology,"Automatic real-time emotion recognition based on multi-channel EEG signals is a significant and challenging task in neurology and psychiatry. In recent years, deep learning has been used in EEG emotion recognition. However, many existing deep learning based methods still require complex pre-processing or additional feature extraction, which make it difficult to achieve real-time emotion recognition. In this paper, an end-to-end model named Temporal Convolutional Broad Learning System (TCBLS) was designed for multi-channel EEG based emotion recognition. The TCBLS takes one-dimensional EEG signals as input, then extracts emotion-related features of EEG automatically. In this model, the Temporal Convolutional Network (TCN) is designed to extract EEG temporal features and deep abstract features simultaneously, then Broad Learning System (BLS) is used to map the features to a more discriminative space and further enhance the features. We evaluated our method on DEAP database, performing 10-fold cross-validation on each subject to obtain the classification accuracy. Experimental results indicate that the performance of TCBLS is better than other comparison methods, and the mean accuracy of TCBLS is 99.5755% and 99.5781% on valence and arousal classification task respectively. The results demonstrate the effectiveness and robustness of TCBLS in EEG emotion recognition.","EEG,emotion recognition,temporal convolutional network (TCN),broad learning system (BLS),temporal convolutional broad learning system (TCBLS)",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
78,Learning How to Generate Kinesthetic Motor Imagery Using a BCI-based Learning Environment: a Comparative Study Based on Guided or Trial-and-Error Approaches,,,2483-2489,"Rimbert Sebastien,Bougrain Laurent,Fleck Stephanie","Rimbert S,Bougrain L,Fleck S",Rimbert S,,Centre National de la Recherche Scientifique (CNRS),"Kinesthetic Motor Imagery (KMI) is a mental task which, if performed properly, can be very relevant in sports training or rehabilitation with a Brain-Computer Interface (BCI). Unfortunately, this mental task is generally complex to perform and can lead to a high degree of variability in its execution, reducing its potential benefits. The reason why the task of KMI is so difficult to perform is because there is no standardized way of instructing the subject in this mental task. This study presents an innovative BCI called Grasp-IT thought to support the learning of the KMI task, and the evaluation of two different learning methods: (i) a first one guided by an experimenter and based on the notion of progressiveness and (ii) a second one where the learners are alone and practice by trial and error. Our findings based on EEG analyses and subjective questionnaires validate the design of the Grasp-IT BCI and opens up perspectives on KMI learning modalities.","Kinesthetic Motor Imagery,Brain-Computer Interface,Grasp-IT,Stroke Rehabilitation,BCI learning environment,Human-Computer Interaction",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,https://hal.inria.fr/hal-02920306/file/SMC2020Rimbert.pdf,
79,Assessing The Relevance Of Neurophysiological Patterns To Predict Motor Imagery-based BCI Users' Performance,,,2490-2495,"Tzdaka Eidan,Benaroch Camille,Jeunet Camille,Lotte Fabien","Tzdaka E,Benaroch C,Jeunet C,Lotte F",Tzdaka E,,"Inria Bordeaux Sud Ouest, Talence, France.","Motor Imagery-based Brain-Computer Interfaces (MI-BCI) allow users to control a computer for various applications using their brain activity alone, which is usually recorded by an electroencephalogram (EEG). Although BCI applications are numerous, their use outside laboratories is still scarce due to their poor accuracy. Some users cannot use BCIs, a phenomenon sometimes called ""BCI illiteracy"", which impacts around 10% to 30% of BCI users, who cannot produce discriminable EEG patterns. By performing neurophysiological analyses, and notably by identifying neurophysiological predictors of BCI performance, we may understand this phenomenon and its causes better. In turn, this may also help us to better understand and thus possibly improve, BCI user training. Therefore, this paper presents statistical models dedicated to the prediction of MI-BCI user performance, based on neurophysiological users' features extracted from a two minute EEG recording of a ""relax with eyes open"" condition. We consider data from 56 subjects that were recorded in a 'relax with eyes open' condition before performing a MI-BCI experiment. We used machine learning regression algorithm with leave-one-subject-out cross-validation to build our model of prediction. We also computed different correlations between those features (neurophysiological predictors) and users' MI-BCI performances. Our results suggest such models could predict user performances significantly better than chance (p <= 0.01) but with a relatively high mean absolute error of 12.43%. We also found significant correlations between a few of our features and the performance, including the previously explored mu-band predictor, as well as a new one proposed here: the mu-peak location variability. These results are thus encouraging to better understand and predict BCI illiteracy. However, they also require further improvements in order to obtain more reliable predictions.","Brain-Computer Interfaces (BCI),electroencephalography (EEG),neurophysiological predictor",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"COMPUTER,COMMUNICATION",,https://hal.inria.fr/hal-02971802/document,
80,Complex Motor Imagery-based Brain-Computer Interface System: A Comparison Between Different Classifiers,,,2496-2501,"Lee Seung-Bo,Jung Min-Kyung,Kim Hakseung,Lee Seong-Whan,Kim Dong-Joo","Lee SB,Jung MK,Kim H,Lee SW,Kim DJ",Kim DJ,,Korea University,"Motor imagery (MI) classification is important as the emerging research interest of brain computer interface (BCI) due to its potential about real-world application. Advancing manipulation and control technology of external devices such as robotics, the need of MI for complex and human-like movements is growing. The two most important procedures that influence the performance of MI-BCI are feature extraction and classification. Although there have been recent studies on feature extraction for complex, there is no consensus on the classifier suitable for complex MI. This study aimed to identify the best classifier for complex MI decoding.
Electroencephalography (EEG) recordings measured during complex MI, which are hand grasping, spreading, pronation and supination, were used for binary (grasp vs. twist) and quaternary classification. Time domain parameter, which have shown suitability for complex movement decoding in previous works, was used as the EEG feature. Four types of ten machine learning classifiers, which have been applied to MI-BCI, were compared.
Shrinkage regularized linear discriminant analysis (SRLDA) exhibited the best classification accuracy in both binary (92.8%) and quaternary (55.2%). In the case of training and testing time, a small amount of time for real-time analysis were needed, except random forest and logistic regression.
This study showed that SRLDA is an appropriate classifier for complex MI classification, due to its ability to handle stationary and high dimensionality feature, TDP. The findings suggest that complex MI-BCI could gain more benefit from applying linear and shrinkage regularized model (i.e., SRLDA).",EEG,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,EEG,,,
81,Predicting Water Pipe Failures with a Recurrent Neural Hawkes Process Model,,,2628-2633,"Verheugd Jeroen,da Costa Paulo R. de Oliveira,Afshar Reza Refaei,Zhang Yingqian,Boersma Sjoerd","Verheugd J,da Costa PRD,Afshar RR,Zhang YQ,Boersma S",Verheugd J,,Eindhoven University of Technology,"Water distribution networks have shown an increased rate of failure due to material deterioration. In this paper, we apply a Recurrent Neural Hawkes Process model to learn the failure intensity function of water pipes. The failure intensity function is learned based on two components: the base failure rate that is determined by the unique pipe profile attributes, and the effect of past failures. Compared to the existing solutions, our model is able to predict the time to next failure on an individual water pipe level. The learned failure intensity function is used to identify value points in the deterioration process of water pipes that represent their economical end-of-life. We use data from a Dutch water distribution network that consists of 49,600 km of pipelines to test the performance of the proposed model. We have made this dataset available online.","Predictive maintenance,Water pipe failure,Intensity function,Point Process,Recurrent Neural Networks",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,https://pure.tue.nl/ws/files/162044646/IEEESMC2020_Verheugd.pdf,
82,Classification of Motor Control Difficulty using EMG in Physical Human-Robot Interaction,,,2708-2713,"Manjunatha Hemanth,Jujjavarapu Sri Sadhan,Esfahani Ehsan T.","Manjunatha H,Jujjavarapu SS,Esfahani ET",Esfahani ET,,State University of New York (SUNY) System,"In physical human-robot interaction, a variable admittance/impedance controller is desired to adjust its controller parameters to enhance the collaboration by minimizing the human effort and maximizing the stability. In this paper, we propose a physiological monitoring approach based on electroencephalogram activities to classify the motor control difficulty and use that information for adjusting an admittance controller. We designed a physical human-robot interaction experiment where the human guides the robot's end-effector across four tasks with varying motor control difficulty. Each task is a combination of high/low damping and fine/gross motor control. During the experiments, we measure the muscle activation information in terms of surface electromyogram from eight channels. Two sets of features based on Riemann geometry and time domain (Hudgins' features) are extracted every 500 ms from the EMG data. A support vector machine classifier is trained on these features to estimate whether the existing admittance parameters are comfortable for the user else an increase/decrease of the damping is suggested. Riemann geometry-based features yielded higher accuracy (85.7%) than the Hudgins' features (69.1%) across 21 participants; however, the performance of these classifiers on the new sessions degraded to 63.1% and 54.5% respectively. To address this issue, we implemented a transfer learning approach using Riemannian features that improved the inter-session detection rate to 73.95%.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
83,Under-sampling and Classification of P300 Single-Trials using Self-Organized Maps and Deep Neural Networks for a Speller BCI,,,2972-2978,"Cortez Sergio A.,Flores Christian,Andreu-Perez Javier","Cortez SA,Flores C,Andreu-Perez J",Cortez SA,,Universidad de Ingenieria Tecnologia UTEC,"A Brain-Computer Interface (BCI) allows its user to control machines or other devices by translating its brain activity and using it as commands. This kind of technology has as potential users people with motor disabilities since it would allow them to interact with their environment without using their peripheral nerves, helping them to regain their lost autonomy. One of the most successful BCI applications is the P300-based Speller. Its operation depends entirely on its capacity to identify and discriminate the presence of the P300 potentials from electroencephalographic (EEG) signals. For the system to do this correctly, it is necessary to choose an adequate classifier and train it with a balanced data-set. However, due to the use of an oddball paradigm to elicit the P300 potential, only unbalanced data-sets can be obtained. This paper focuses on the training stage of two classifiers, a deep feedforward network (DFN) and a deep belief network (DBN), to be used in a P300-based BCI. The data-sets obtained from healthy subjects and post-stroke victims were pre-processed and then balanced using a Self-Organizing Maps-based under-sampling approach prior training looking to increase the accuracy of the classifiers. We compared the results with our previous works and observed an increase of 7% in classification accuracy for the most critical subject. The DFN achieved a maximum classification accuracy of 93.29% for a post-stroke subject and 93.60% for a healthy one.","brain-computer interface,neural networks,self-organizing maps,post-stroke,EEG",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"BRAIN-COMPUTER,INTERFACE",,http://repository.essex.ac.uk/28921/1/IEEE_Conference_Template_SMC.pdf,
84,Machine Learning Tools for the Prediction of Fresh Produce Procurement Price,,,3091-3095,"Jafari Fatemeh,Mousavi Jamshid,Ponnambalam Kumaraswamy,Karray Fakhri,Nassar Lobna","Jafari F,Mousavi J,Ponnambalam K,Karray F,Nassar L",Jafari F,,University of Waterloo,"Adequately priced orders and time for fresh produce (FP) are two factors that bring commercial benefits to vendors and minimizes waste. However, many factors, such as income, labor, and other trade issues, affect the price that include uncertainties due to climate change, making decisions on FP procurement prices and quantities extremely challenging. Two artificial intelligence-based forecasting tools, i.e., a single variate and a multivariate model, are trained, tested, and compared in this study to predict future daily offer prices up to 7 days ahead for strawberries using mutual transactions for the distribution centers of Loblaws Companies Limited (LCL) in Canada. Results reveal that the developed multivariate model, utilizing both prices of the LCL dataset and California's strawberries yield dataset as predictors, outperforms the best single variate model.","fresh produce,artificial intelligence,price forecasting",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"TIME-SERIES,MODELS,STATE",,,
85,A Multi-task Framework for Topology-guaranteed Retinal Layer Segmentation in OCT Images,,,3142-3147,"Cao Jun,Liu Xiaoming,Zhang Ying,Wang Man","Cao J,Liu XM,Zhang Y,Wang M",Liu XM,,Wuhan University of Science & Technology,"Optical coherence tomography (OCT) imaging can obtain high-resolution cross-sectional scans of the retina, which can be used in clinical diagnosis. Changes in the thickness of layers indicate the onset of retinal diseases, motivating an accurate measurement of the thickness of retinal layers. Thus, an automatic and robust layer segmentation method is necessary. In this paper, we propose a deep learning-based multi-task framework to obtain the topologically consistent layer segmentation in OCT B-scans. By integrating the distance maps of retinal layer surfaces, the segmentation task is regarded as a multi-task problem of regression and classification. Besides, considering the multi-task learning problem, we propose a task-specific attention module to learn the task-tailored features. Experiment results on a public OCT dataset with multiple sclerosis (MS) demonstrate the effectiveness of the proposed method.","OCT,layer segmentation,topology-guaranteed,distance map,attention",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"AUTOMATIC,SEGMENTATION,MULTIPLE-SCLEROSIS",,,
86,Using deep learning to detect early signs of cognitive disease,,,3168-3173,"Wahltinez O.,Rincon M.,Diaz-Mardomingo M. C.,Garcia-Herranz S.","Wahltinez O,Rincon M,Diaz-Mardomingo MC,Garcia-Herranz S",Wahltinez O,,Universidad Nacional de Educacion a Distancia (UNED),"Handwriting and hand drawings have historically been used as a proxy metric to evaluate psychological and cognitive traits, in addition to fine motor skills. Detecting onset of cognitive diseases early is a very challenging task due to the expertise required to evaluate each individual subject, as well as the time that the process entails. In this work, we evaluated the application of state-of-the-art deep learning and transfer learning models to determine if the author of a copied hand drawing of a template displays signs of cognitive disease. Compared to expert cognitive evaluation, our best performing method yielded a mean accuracy of 67.60% and area under ROC of 0.595 in determining if an undiagnosed subject displays signs of cognitive disease. Our results suggest that state of the art techniques in deep learning have the potential to help alleviate the difficulty of screening for early signs of cognitive disease. Results also suggest that transfer learning did not perform as well as a purpose-built network architecture trained from scratch. Lastly, our results indicate that models which consider all drawings made by a subject outperform models that look at drawing-evaluation pairs independently.","deep learning,transfer learning,cognitive disease,hand drawing",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"ALZHEIMERS-DISEASE,EARLY-DIAGNOSIS,MILD",,,
87,Training and Decision Support for Battlefield Trauma Care,,,3194-3199,"Nemeth Christopher,Amos-Binks Adam,Pinevich Yuliya,Burris Christie,Keeney Natalie,Rule Gregory,Pickering Brian,Laufersweiler Dawn,Heresevich Vitaly","Nemeth C,Amos-Binks A,Pinevich Y,Burris C,Keeney N,Rule G,Pickering B,Laufersweiler D,Heresevich V",Nemeth C,,"Applied Research Associates, Inc.","In Tactical Combat Casualty Care (TCCC), medics perform Role 1 care for battlefield casualties at point of injury by stabilizing them and transporting them to field care facilities such as a Battalion Aid Station (Role 2) or Field Hospital (Role 3) where clinicians provide critical care. Care provider experience and ability vary, and training in the field can help to improve recall and performance of infrequently used critical care skills. This becomes more necessary during Prolonged Field Care (PFC) when evacuation is not immediately available and more complex treatment may be required. Our Trauma Triage Treatment and Training Decision Support (4TDS) project has developed a decision support system (DSS) for Roles 1 and 2. As an application on a Android smart phone and tablet, 4TDS includes training scenarios in skills such as shock identification and management. 4TDS pairs with various vital signs sensors that can stream data for a machine learning algorithm that can detect the probability of shock in a casualty. A ""silent test"" is comparing algorithm performance with actual clinical diagnoses at Mayo Clinic, Rochester, MN. Usability assessment in an austere field setting will enable us to determine medic and clinician acceptance of 4TDS and how well it supports their decision making. Faster, more accurate decisions can improve TCCC patient care under conditions in which delays can increase morbidity and mortality.","human-computer interaction,user interface design,information visualization",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
88,EMG-Based Decoding of Manipulation Motions in Virtual Reality: Towards Immersive Interfaces,,,3296-3303,"Dwivedi Anany,Kwon Yongje,Liarokapis Minas","Dwivedi A,Kwon Y,Liarokapis M",Dwivedi A,,University of Auckland,"To facilitate the development of a new generation of Virtual Reality systems and their introduction in everyday life applications, new intuitive, immersive methods of interfacing have to be developed. Over the years, Electromyography (EMG) based interfaces have been utilized for unobtrusive interaction with computer systems. However, previous EMG studies have not explored the continuous decoding of the effects of human motion (e.g., manipulated object behavior) in simulated and virtual environments. In this work, we present an EMG based learning framework that can allow for an immersive interaction with Virtual Reality environments. To do that, EMG activations from the muscles of the forearm and the hand were acquired during the execution of object manipulation tasks in a virtual world along with the motion of the object. The virtual world was visualized using an HTC Vive VR headset, while the hand motions were tracked with a dataglove equipped with magnetic motion capture sensors. The object motion decoding was formulated as a regression problem using the Random Forests methodology. The study shows that the object motion can be successfully decoded using the EMG activations, despite the lack of haptic feedback.","Electromyography (EMG),Virtual Reality,Muscle Computer Interfaces,Machine Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
89,"3D-Printed, Adjustable Armband for Electromyography-Based Finger Movement Classification With Haptic Feedback",,,3460-3465,"Wang Michelle,Bulger Miasya,Dai Yue,Noel Kira,Axon Christopher,Brandenberger Anna,Fay Stephen,Gao Zenghao,Gilmer Saskia,Hamdan Jad","Wang M,Bulger M,Dai Y,Noel K,Axon C,Brandenberger A,Fay S,Gao ZH,Gilmer S,Hamdan J",Wang M,,McGill University,"Recent work in prosthetic devices suggests that forearm surface electromyography (sEMG) is a promising technology for human-computer interactions. Specifically, a system able to detect individual finger movement can have many clinical and non-clinical applications. Popular consumer-grade sEMG armbands are limited by their fixed electrode arrangement, which can negatively affect the classification of subtle finger gestures. We propose a low-cost, 3D-printed armband with fully adjustable electrode placement for the detection of single-finger tapping motions. We trained machine learning classifiers on features extracted from eight-channel sEMG signals to detect movement from nine fingers. We obtained a classification accuracy of 71.5 +/- 1.1% for a K-Nearest Neighbours (KNN) classifier using features extracted from 500 ms windows of sEMG data. Moreover, a KNN model trained on 200 ms windows from a subset of particularly clean data obtained an accuracy of 93.0 +/- 0.5%. We also introduce a novel haptic feedback mechanism to improve user experience when using the armband, and propose an augmented reality typing interface as a potential application of our armband.","augmented reality,electromyography,haptic interfaces,human computer interaction,machine learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"SURFACE,EMG,FEATURE-EXTRACTION",,,
90,Generative Adversarial Training for Weakly Supervised Nuclei Instance Segmentation,,,3649-3654,"Hu Wei,Sheng Huanhuan,Wu Jing,Li Yining,Liu Tianyi,Wang Yonghao,Wen Yuan","Hu W,Sheng HH,Wu J,Li YN,Liu TY,Wang YH,Wen Y",Hu W,,Wuhan University of Science & Technology,"Nuclei segmentation occupies an important position in medical image analysis, which helps to predict and diagnose diseases. With the further research of deep learning, the task of nuclei segmentation has been automated. However, most existing methods require a great deal of manually marked full masks for training, which is time-consuming and labor-intensive, and can only be done by professional personnel. For the purpose of reducing the cost of labeling, we propose a weakly supervised method using generative adversarial training for segmentation of nucleus. In the case of no boundary, but only the centroid of the nucleus, the proposed method segmented the nucleus region with blurred boundaries. We first use the generative adversarial network(GAN) to generate the likelihood map of the nuclear centroid, then use Guided Backpropagation to visualize the pixels that contributes to the detection of the centroid of each nucleus, and finally obtain the segmentation mask of the nucleus by graphcut. In addition, for the purpose of training the network better, we performed stain normalization on each pathological image. We have verified the proposed method on a multi-organ nuclei dataset. The final experiment results show that our advanced method achieves better segmentation performance than other weakly supervised methods, and can even reach the level of full supervision.","image processing,nuclei segmentation,weak supervision,GAN",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
91,Toward an End-to-End Solution to Identification of Handheld Pharmaceutical Blister Packages,,,3729-3734,"Chung Sheng-Luen,Cho Chang-Lin,Su Shun-Feng","Chung SL,Cho CL,Su SF",Chung SL,,National Taiwan University of Science & Technology,"Verification of dispensed pharmaceutical packages is of paramount importance to prescription dispensing. Due to lack of identification peripherals like bar codes or RFID tags on blister packages, image-based solutions have been utilized. Earlier two-stage solutions require more resources for implementation and training, in addition to more computational time. In contrast, this paper presents an end-to-end trained solution, called Fast Rotated Occluded Rectangular (Fast ROR) pattern recognition architecture, composed of modules of: rotational rectangular detection, affine transformation, and image recognition. In particular, the features used to localize the package and the features used for identification are the same and extracted by a common feature extractor. As a result, the overall architecture is more compact with only one training set needed and more efficient computation time. Comparison experiments have been conducted on the proposed end-to-end FOR and on a representative two-stage HBIN [1] solution: Targeting a pool of 230 types of pharmaceutical packages, 30 paired front and back handheld images for each type were taken and randomly partitioned with 4:1 for training and testing, FOR (vs. HBIN) uses 41.79M (120.32M) network parameters, with a training time of 17 hours (119 hours), and a testing speed of 22.2 fps (10fps). The identification results in terms of F1-score by FOR (vs. HBIN) is 100% (98.67%) in familiar environment, whereas 94.30% (91.27%) when the identification is conducted in new environment.","Deep learning,end-to-end architecture,hand-held object identification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
92,Human-to-Human Knowledge Transfer using Functional Electrical Stimulation,,,3788-3792,"Hernandez-Rios E. Rafael,Penaloza Christian","Hernandez-Rios ER,Penaloza C",Hernandez-Rios ER,,"Mirai Innovat Res Inst, R&D Dept, Osaka, Japan.","The concept of the knowledge transfer from a human expert to another non-expert human through technological interfaces, where a task can be learned by using brain-to-brain or body-to-body connections has great potential for future applications in which traditional verbal or visual communication channels are not available. In this paper, we present a novel approach of human-to-human knowledge transfer using a system based on functional electrical stimulation (FES). Using the proposed approach, hand-arm movements from a human teacher are recognized through an electromyogram signal classification algorithm. Using a master-slave approach, the movement signals are then translated into electrical stimulation signals and transmitted to a human learner using a functional electrical stimulation device. In the experiment conducted, we show how a human expert teaches seven learners a task that consists of associating hand-arm movements with visual stimuli presented to the learners. Furthermore, cognitive engagement was monitored during the learning process using an electroencephalogram (EEG) system. Experimental results show that four out of seven participants were able to learn the task with an accuracy over 80% and their cognitive engagement correlates to their performance.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
93,Balancing Active Inference and Active Learning with Deep Variational Predictive Coding for EEG,,,3839-3844,"Ofner Andre,Stober Sebastian","Ofner A,Stober S",Ofner A,,Otto von Guericke University,"This paper discusses representation learning from electroencephalographic (EEG) signal with deep variational predictive coding networks.We introduce a hierarchical probabilistic network that minimises prediction error at multiple levels of spatio-temporal abstraction. While the lowest layer predicts brain activity directly, higher layers abstract away from the data and predict sequences of the hidden states in lower layers. The network captures both expected and actual uncertainty by relating predicted state posteriors. Each layer minimises (expected) surprise either with or without sampling new evidence from the layer below. This structure motivates both active learning and active inference as means to learn representations. Active learning refers to model parameter exploration which allows to learn regularities, especially when they are stable between trials. Active inference refers to hidden state exploration, a process that enables dynamic inference of the current context using the learned generative model. We train the model on EEG data recorded during free reading and evaluate adaptive EEG prediction in the context of Fixation Related Potentials (FRPs).","Predictive Coding,Deep Learning,Variational Bayes,Active Inference,Active Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
94,Deep-Learning LSTM Mechanism and Wearable Devices based Virtual Fitness-Coach Information System for Barbell Bench Press,,,3880-3885,"Hsiao Chun-Chieh,Yu Po-Chieh,Lee Ren-Guey,Jiang Haiyan","Hsiao CC,Yu PC,Lee RG,Jiang HY",Hsiao CC,,National Taiwan University,"This study aims to design and develop a virtual fitness-coach information system for barbell bench press based on deep-learning Long Short Term Memory (LSTM) mechanism and wearable devices. We utilizes a set of three-axis accelerometers, gyroscopes and Electromyography (EMG) sensing modules to design our proposed wearable devices. Through computer and smartphone, the analysis and real-time assessment of the weight training in barbell free bench press can be performed to avoid injury in weight training and improve the quality of training performance.
In this study, 21 subjects are recruited to use our proposed wearable devices for weight training in barbell free bench press. In the training, the subject's physiological signals and videos are captured, and the subject's signals are extracted according to the 11 most common kinds of errors marked by the fitness instructor, including 7 posture errors and 4 kinds of muscle force errors. After the extracted signal is normalized, the data is fed for the Recurrent Neural Network (RNN) training through the Long Short Term Memory (LSTM) to classify the weight training errors. The experimental results show that the classification threshold used in the classification has the best classification result when set at 0.5, and the overall average accuracy, accuracy, recall rate, F1 Score, FPR and FNR are 91.84%, 89.25%, 88.17%, 88.18%, 6.50% and 11.83%, respectively. We found that in some categories, because the sensors are not powerful enough to capture the characteristics of the errors, the accuracy is low. While the overall accuracy of the other categories is higher than 85%.
In order to accelerate the training speed of LSTM, we also try to use the common factor extraction analysis to reduce the data of accelerometers and gyroscopes from 24 to 18, 12 and 6 dimensions for training. When the total dimension including EMG is 30 dimensions, there is not much difference in the accuracy when the dimension is reduced to 24 or 18. However when it is reduced to 12 dimensions, the evaluation metrics are reduced to below 70%, and the False Negative Rate (FNR) has risen sharply to 30.21%. We therefore choose to reduce the training data from 30 dimensions to 18 dimensions to maintain recognition accuracy and to accelerate LSTM training.
To verify the feasibility of our Virtual Fitness-Coach Information System, we have further recruited 5 subjects for user satisfaction survey of the instant voice feedback and our wearable devices. The users show relatively high satisfiaction about our instant feedback system in the following aspects: helpfulness, clearance, reliability, correctness, and performance. The users also feel relatively comfortable for our wearable devices and suggest further simplification of our wearable devices for ease of wearing.","HEALTH,EXERCISE",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"HEALTH,EXERCISE",,,
95,Feature Fusion of sEMG and Ultrasound Signals in Hand Gesture Recognition,,,3911-3916,"Zeng Jia,Zhou Yu,Yang Yicheng,Wang Jiaole,Liu Honghai","Zeng J,Zhou Y,Yang YC,Wang JL,Liu HH",Liu HH,,Shanghai Jiao Tong University,"Multi-modal sensory fusion is believed to obtain higher accuracy in gesture recognition. Its difficulty lies in mining discriminative features and fusing features from different modalities. Surface electromyography(sEMG) and ultrasound signals are typical signal modalities in gesture recognition. It is expected that the fusion of them can take advantage of the complementarity of electrophysiological information and muscle morphology information. This paper proposed two kinds of feature fusion method. The one is concatenating the manual designed sEMG and ultrasound features, and the other is a convolutional neural network (CNN) based feature exaction and fusion method for sEMG and ultrasound signals. Eight able-bodied subjects were involved to participate in the experiments. In the experiments, four channels of sEMG and A-mode ultrasound signals corresponding to 20 gestures were collected synchronously to evaluate the proposed method. The experimental results demonstrated that the fusion sEMG-ultrasound feature always outperformed the separate sEMG or ultrasound feature regardless of the feature extraction method, and as for fusion sEMG-ultrasound feature, the CNN based method achieve a high accuracy (97.38 +/- 1.49%) in 20 gestures, which surpassed the method of concatenating the manual designed features and applying machine learning algorithm (LDA, KNN, SVM).",PROSTHESES,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,PROSTHESES,,,
96,Towards measuring states of epistemic curiosity through electroencephalographic signals,,,4006-4011,"Appriou Aurelien,Ceha Jessy,Pramij Smeety,Dutartre Dan,Law Edith,Oudeyer Pierre-Yves,Lotte Fabien","Appriou A,Ceha J,Pramij S,Dutartre D,Law E,Oudeyer PY,Lotte F",Appriou A,,Centre National de la Recherche Scientifique (CNRS),"Understanding the neurophysiological mechanisms underlying curiosity and therefore being able to identify the curiosity level of a person, would provide useful information for researchers and designers in numerous fields such as neuroscience, psychology, and computer science. A first step to uncovering the neural correlates of curiosity is to collect neurophysiological signals during states of curiosity, in order to develop signal processing and machine learning (ML) tools to recognize the curious states from the non-curious ones. Thus, we ran an experiment in which we used electroencephalography (EEG) to measure the brain activity of participants as they were induced into states of curiosity, using trivia question and answer chains. We used two ML algorithms, i.e. Filter Bank Common Spatial Pattern (FBCSP) coupled with a Linear Discriminant Algorithm (LDA), as well as a Filter Bank Tangent Space Classifier (FBTSC), to classify the curious EEG signals from the non-curious ones. Global results indicate that both algorithms obtained better performances in the 3-to-5s time windows, suggesting an optimal time window length of 4 seconds (63.09% classification accuracy for the FBTSC, 60.93% classification accuracy for the FBCSP+LDA) to go towards curiosity states estimation based on EEG signals.","curiosity,mental state,learning,ElectroEncephaloGraphy,passive Brain Computer Interfaces",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,https://hal.inria.fr/hal-02971795/document,
97,A comparison of ECG and EEG metrics for in-flight monitoring of helicopter pilot workload,,,4012-4019,"Hajra Sujoy Ghosh,Xi Pengcheng,Law Andrew","Hajra SG,Xi PC,Law A",Hajra SG,,National Research Council Canada,"There is increasing interest in understanding the cognitive and physiological state of operators in safety critical situations (e.g. pilots), specifically as it relates to task difficulty and mental workload. Herein, we evaluate the potential of electrocardiography (ECG) and electroencephalography (EEG) for detecting in-flight changes in helicopter pilot workload. Two National Research Council Canada test pilots performed a series of flight maneuvers in an NRC Bell 205 helicopter which involved a target tracking task with three levels of difficulty. Subjective ratings of pilot workload were collected using the Cooper-Harper handling quality ratings scale and pilot control activity was quantified based on cyclic control movements. ECG derived measures of heart rate and heart rate variability, as well as EEG derived measures of power in three frequency bands (theta 4-8Hz; alpha 8-13Hz; beta 13-22Hz), were computed and compared across task difficulty levels. A set of support vector machine (SVM) regressors were trained and tested to differentiate the three difficulty levels from ECG and EEG features. Differences in subjective ratings and control activity metrics confirmed the task difficulty manipulations (p<0.01). ECG-derived physiological metrics were able to partially resolve differences among the task difficulty levels. Similarly, EEG-derived cognitive measures confirmed the capture of differential neural functioning levels for the task difficulty conditions in the alpha and beta bands (p<0.05), though substantial individual differences were observed between pilots. SVM regressors trained on ECG and EEG features successfully differentiated levels of workload, with the ECG-based regressor (minimum cross-validation MSEECG = 0.17) performing better than the EEG-based regressor (minimum cross-validation MSEEEG = 0.29). This study provides an initial application demonstration of physiological and cognitive metrics and machine learning approaches for detecting differences in task difficulty during helicopter flight. This is the necessary first step for further development of passive brain computer interfaces for real-time in-flight monitoring of helicopter pilot workload.","workload,helicopter pilot,ECG,EEG,machine learning,flight",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"HEART-RATE-VARIABILITY,MENTAL,WORKLOAD,TASK-DIFFICULTY,INDEXES",,,
98,Modeling the Relationship Between Cognitive State and Task Performance in Passive BCIs using Cross-Dataset Learning,,,4020-4025,"McDaniel Jonathan R.,Gordon Stephen M.,Lawhern Vernon J.","McDaniel JR,Gordon SM,Lawhern VJ",McDaniel JR,,"DCS Corp, Alexandria, VA 22310 USA.","New research and development efforts are highlighting the ways in which electroencephalogram-based (EEG) brain-computer interface (BCI) technology can be used to improve the quality of life for healthy individuals. One such application incorporates cognitive state monitoring into passive BCI (pBCI) systems. Among the challenges facing this development, a significant barrier to adoption is the time-intensive calibration typically needed to tune the system to account for variations in neural activity patterns. An open research question is understanding the relationship between underlying user state and user performance in real-world situations and environments. However, user states are often derived and defined as a function of observed user performance for a particular analysis. Understanding the relationship between user state and user performance ideally requires the definition of user state be independent of observed user performance. This work represents our initial steps towards this goal by using cross-dataset learning, where we define user state from a dataset recorded in a highly-controlled experiment, building a subject-independent pBCI model to predict user state using deep learning approaches, and applying this pBCI model to analyze user performance in a new, unobserved dataset. We show that user performance varies smoothly across a continuum of pBCI model outputs. Our results highlight a promising approach for dealing with one of the major hurdles in the development of BCI systems for healthy users.","Brain-Computer Interface,Electroencephalography,Deep Learning,Convolutional Neural Network",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"BRAIN-COMPUTER,INTERFACES,NEURAL-NETWORKS",,,
99,Continuous Driver Steering Intention Prediction Considering Neuromuscular Dynamics and Driving Postures,,,4404-4409,"Xing Yang,Lv Chen,Liu Yahui,Zhao Yifan,Cao Dongpu","Xing Y,Lv C,Liu YH,Zhao YF,Cao DP",Xing Y,,Nanyang Technological University & National Institute of Education (NIE) Singapore,"Predicting driver steering intention enables intelligent vehicles to optimize its assistance and collaborative strategies with the human driver in advance, which contribute to an intelligent mutual-understanding system for driver-vehicle collaboration. In this study, a deep time-series learning-enabled driver steering intention prediction system is developed based on the Electromyography (EMG) signal processing. Specifically, the connection between the upper limb EMG signals from different muscles and the steering torque is established using a deep bi-directional long short-term memory (BiLSTM) recurrent neural network (RNN). The deep time-series model is trained to predict the future steering torque with historical EMG signals, and the prediction horizon is selected as 200 ms in this study. Moreover, three different steering postures with different hand positions on the steering wheel are studied. A joint BiLSTM network with shared temporal pattern extraction layers is developed to investigate the impact of the hand positions on the steering intention prediction. It is found that based on the joint BiLSTM network, the most accurate steering intention can be achieved with both hands on 3-clock positions. The experiments are conducted on a driving simulator environment with 21 participants. The proposed system can be used for precise driver steering intention prediction system towards a better mutual-understanding module on the intelligent and automated driving vehicles.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
100,Multiobjective optimization of deep neural networks with combinations of Lp-norm cost functions for 3D medical image super-resolution,27,3,233-251,"Thurnhofer-Hemsi Karl,Lopez-Rubio Ezequiel,Roe-Vellve Nuria,Molina-Cabello Miguel A.","Thurnhofer-Hemsi K,Lopez-Rubio E,Roe-Vellve N,Molina-Cabello MA",Thurnhofer-Hemsi K,,Universidad de Malaga,,"SUPPORT VECTOR REGRESSION,VARIANCE ANALYSIS,EVOLUTIONARY,SCALARIZATION,INTELLIGENCE,MINIMIZATION,CONVERGENCE,STATISTICS,ALGORITHMS,TUTORIAL",Article; Proceedings Paper,"IOS PRESS, NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS","Computer Science,Engineering",,3.798,"SUPPORT,VECTOR,REGRESSION,VARIANCE,ANALYSIS,EVOLUTIONARY,SCALARIZATION,INTELLIGENCE,MINIMIZATION,CONVERGENCE,STATISTICS,ALGORITHMS,TUTORIAL",INTEGRATED COMPUTER-AIDED ENGINEERING,,
