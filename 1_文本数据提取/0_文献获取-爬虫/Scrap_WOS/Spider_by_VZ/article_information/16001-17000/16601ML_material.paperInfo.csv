,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Using convolutional neural networks to identify patient safety incident reports by type and severity,26,12,1600-1608,"Wang Ying,Coiera Enrico,Magrabi Farah","Wang Y,Coiera E,Magrabi F",Wang Y,10.1093/jamia/ocz146,Macquarie University,"Objective: To evaluate the feasibility of a convolutional neural network (CNN) with word embedding to identify the type and severity of patient safety incident reports.
Materials and Methods: A CNN with word embedding was applied to identify 10 incident types and 4 severity levels. Model training and validation used data sets (n_type = 2860, n_severity = 1160) collected from a state-wide incident reporting system. Generalizability was evaluated using an independent hospital-level reporting system. CNN architectures were examined by varying layer size and hyperparameters. Performance was evaluated by F score, precision, recall, and compared to binary support vector machine (SVM) ensembles on 3 testing data sets (type/severity: n_benchmark = 286/116, n_original = 444/4837, n_independent = 6000/5950).
Results: A CNN with 6 layers was the most effective architecture, outperforming SVMs with better generalizability to identify incidents by type and severity. The CNN achieved high F scores (> 85%) across all test data sets when identifying common incident types including falls, medications, pressure injury, and aggression. When identifying common severity levels (medium/low), CNN outperformed SVMs, improving F scores by 11.9%-45.1% across all 3 test data sets.
Discussion: Automated identification of incident reports using machine learning is challenging because of a lack of large labelled training data sets and the unbalanced distribution of incident classes. The standard classification strategy is to build multiple binary classifiers and pool their predictions. CNNs can extract hierarchical features and assist in addressing class imbalance, which may explain their success in identifying incident report types.
Conclusion: A CNN with word embedding was effective in identifying incidents by type and severity, providing better generalizability than SVMs.","neural networks,word embedding,multiple classification,text classification,clinical incident reports,patient safety",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,,"MEDICAL-RECORDS,CLASSIFICATION,INFORMATION,QUALITY,CNN",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647259,
2,The impact of Co-actors on cognitive load: When the mere presence of others makes learning more difficult,101,,30-41,"Skuballa Irene T.,Xu Kate M.,Jarodzka Halszka","Skuballa IT,Xu KM,Jarodzka H",Skuballa IT,10.1016/j.chb.2019.06.016,"Postbus 2960, NL-6401 DL Heerlen, Netherlands.","A large body of research has established the value of learner characteristics on cognitive load. However, little attention has been paid to the physical environment where learning takes place. The present study takes a step to address this gap by studying the impact of the presence of others during learning on cognitive load. In a between-subject design, participants (N = 115) were randomly arranged in groups of different group sizes to study computer-based multimedia materials (group size range: 1-13, continuous variable). Further, participants' working memory capacity, topic interest, and their prior knowledge were measured to reveal relevant learner characteristics. Dependent variables were learning performance, perceived task difficulty (mental load), and invested mental effort. We tested the predictions from cognitive load theory with alternative path models to identify the best model fit. Our results show that group size predicted learners' perceived task difficulty: the larger the group of co-actors in the learning situation was, the higher the perceived task difficulty. Moreover, higher topic interest led to lower perceived task difficulty, and more mental effort, although that effect became non-significant after multiple testing adjustment. Perceived task difficulty mediated the effect of group size and topic interest on mental effort.","WORKING-MEMORY CAPACITY,SOCIAL FACILITATION,PERFORMANCE,DESIGN,ATTENTION,MODEL,FIT",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Psychology,,8.302,"WORKING-MEMORY,CAPACITY,SOCIAL,FACILITATION,PERFORMANCE,DESIGN,ATTENTION,MODEL,FIT",COMPUTERS IN HUMAN BEHAVIOR,,
3,Image improvement in digital tomosynthesis (DTS) using a deep convolutional neural network,14,,,"Park S.,Kim G.,Cho H.,Kim K.,Lee D.,Kim W.,Lim Y.,Seo C.","Park S,Kim G,Cho H,Kim K,Lee D,Kim W,Lim Y,Seo C",Cho H,10.1088/1748-0221/14/12/C12004,Yonsei University,"Digital tomosynthesis (DTS) is a geometric tomography technique using a limited-angle scan. It has been popularly used in both medical and industrial x-ray imaging applications. DTS provides the tomographic benefits of computed tomography with reduced dose and time. However, conventional DTS reconstruction based on the computationally cheap filtered back-projection (FBP) method typically produces poor image quality due to limited angular samplings. To overcome these difficulties, iterative reconstruction methods are often used in DTS reconstruction as they have the potential to provide multiplanar images of higher quality than conventional FBP-based methods. However, they require enormous computational cost in the iterative process, which remains an obstacle to practical applications. In this study, we propose a method for effectively reducing limitedangle artifacts in conventional FBP reconstruction, using a state-of-the-art deep learning scheme with a convolutional neural network. Our results indicate that the proposed DTS reconstruction method effectively minimized limited-angle artifacts, thus improving image performance in DTS, and that further it provided good image quality in both sagittal and coronal views (as in computed tomography) as well as in axial view.","Computerized Tomography (CT) and Computed Radiography (CR),Medical-image reconstruction methods and algorithms , computer-aided software",Article; Proceedings Paper,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Instruments & Instrumentation,,1.328,"CT,RECONSTRUCTION",JOURNAL OF INSTRUMENTATION,,
4,Automatic Crack Detection and Analysis for Biological Cellular Materials in X-Ray In Situ Tomography Measurements,8,4,559-569,"Wu Ziling,Yang Ting,Deng Zhifei,Huang Baokun,Liu Han,Wang Yu,Chen Yuan,Stoddard Mary Caswell,Li Ling,Zhu Yunhui","Wu ZL,Yang T,Deng ZF,Huang BK,Liu H,Wang Y,Chen Y,Stoddard MC,Li L,Zhu YH",Zhu YH,10.1007/s40192-019-00162-3,Virginia Polytechnic Institute & State University,"We introduce a novel methodology, based on in situ X-ray tomography measurements, to quantify and analyze 3D crack morphologies in biological cellular materials during damage process. Damage characterization in cellular materials is challenging due to the difficulty of identifying and registering cracks from the complicated 3D network structure. In this paper, we develop a pipeline of computer vision algorithms to extract crack patterns from a large volumetric dataset of in situ X-ray tomography measurement obtained during a compression test. Based on a hybrid approach using both model-based feature filtering and data-driven machine learning, the proposed method shows high efficiency and accuracy in identifying the crack pattern from the complex cellular structures and tomography reconstruction artifacts. The identified cracks are registered as 3D tilted planes, where 3D morphology descriptors including crack location, crack opening width, and crack plane orientation are registered to provide quantitative data for future mechanical analysis. This method is applied to two different biological materials with different levels of porosity, i.e., sea urchin (Heterocentrotus mamillatus) spines and emu (Dromaius novaehollandiae) eggshells. The results are verified by experienced human image readers. The methodology presented in this paper can be utilized for crack analysis in many other cellular solids, including both synthetic and natural materials.","Crack detection,Computer vision,X-ray tomography,Machine learning",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Materials Science",,,"SEA-URCHIN,SPINES,LIGHTWEIGHT,CERAMICS,MECHANICAL-BEHAVIOR,MODEL-SYSTEM,CLASSIFICATION,IMAGES",INTEGRATING MATERIALS AND MANUFACTURING INNOVATION,https://link.springer.com/content/pdf/10.1007/s40192-019-00162-3.pdf,
5,A robust voting approach for diabetes prediction using traditional machine learning techniques,1,12,,Mahabub Atik,Mahabub A,Mahabub A,10.1007/s42452-019-1759-7,Khulna University of Engineering & Technology (KUET),"The noteworthy advances in biotechnology and biomedical sciences have prompted a huge creation of information, for example, high throughput genetic information and clinical data, produced from extensive Electronic Health Records. To this end, utilization of machine learning and data mining techniques in biosciences is by and by crucial and fundamental in endeavors to change cleverly all accessible data into profitable knowledge. Diabetes mellitus is characterized as a gathering of metabolic issue applying critical weight on human health around the world. Broad research in all parts of diabetes (determination, pathophysiology, treatment, and so forth.) has prompted the age of tremendous measures of information. The point of the present examination is to direct an orderly audit of the uses of machine-learning, data mining strategies and instruments in the field of diabetes. The main theme of this work is to provide a system which can prognosticate the diabetes in patients with better accuracy. Here, eleven well-known machine-learning algorithms like Naive Bayes, K-NN, SVM, Random Forest, Artificial Neural Network, Logistic Regression, Gradient Boosting, Ada Boosting etc. are used for detection of diabetes at an early stage. The evaluations of all the eleven algorithms are examined on various parameters like accuracy, precision, F-measure and recall. After cross-validation and hyper-tuning, the best three machine-learning algorithms are determined and then used in Ensemble Voting Classifier. The experimental results affirm that the pointed framework can accomplish to outstanding outcome of almost 86% accuracy of the Pima Indians Diabetes Database.","Diabetes prediction,Voting Classifier,Machine-learning,Data mining,PIDD",Article,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Science & Technology - Other Topics,,,CLASSIFICATION,SN APPLIED SCIENCES,https://link.springer.com/content/pdf/10.1007/s42452-019-1759-7.pdf,
6,Slope stability analysis using recent metaheuristic techniques: a comprehensive survey,1,12,,"Mishra Mayank,Gunturi Venkata Ramana,Da Silva Miranda Tiago Filipe","Mishra M,Gunturi VR,Miranda TFD",Mishra M,10.1007/s42452-019-1707-6,Indian Institute of Technology System (IIT System),"In the framework of designing civil engineering structures such as dams and road embankments, slope stability assessment is essential. Many slope stability assessment methods based on swarm intelligence algorithms and artificial intelligence techniques have been developed in the past decade. Therefore, this paper aims to provide an up-to-date overview of slope stability by summarizing the review of applications of several metaheuristics in this field with their advantages and limitations. In this study, we present recent swarm intelligence methods and machine learning techniques used for assessing the stability of slopes and compare them with the antlion optimiser (ALO) technique. The factor of safety related to every slip surface searched was computed using Morgenstern-Price method. The performance of the proposed ALO is evaluated and validated for four slope examples against recent metaheuristics. Finally, the work carried out will help practitioners as they can now have all swarm intelligence approaches combined in one paper and will help in choosing them the right technique based on their application.","Factor of safety,Metaheuristic algorithms,Artificial intelligence,Optimisation techniques,Limit equilibrium method",Review,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Science & Technology - Other Topics,,,"CRITICAL,FAILURE,SURFACE,CRITICAL,SLIP,SURFACE,LION,OPTIMIZATION,ALGORITHM,SIMPLE,GENETIC,ALGORITHM,BEE,COLONY,ALGORITHM,LIMIT,EQUILIBRIUM,RELIABILITY-ANALYSIS,PREDICTION,SEARCH,SAFETY",SN APPLIED SCIENCES,https://link.springer.com/content/pdf/10.1007/s42452-019-1707-6.pdf,
7,Enhancement of a Short-Term Forecasting Method Based on Clustering and kNN: Application to an Industrial Facility Powered by a Cogenerator,12,23,,"Vialetto Giulio,Noro Marco","Vialetto G,Noro M",Vialetto G,10.3390/en12234407,University of Padua,"In recent years, collecting data is becoming easier and cheaper thanks to many improvements in information technology (IT). The connection of sensors to the internet is becoming cheaper and easier (for example, the internet of things, IOT), the cost of data storage and data processing is decreasing, meanwhile artificial intelligence and machine learning methods are under development and/or being introduced to create values using data. In this paper, a clustering approach for the short-term forecasting of energy demand in industrial facilities is presented. A model based on clustering and k-nearest neighbors (kNN) is proposed to analyze and forecast data, and the novelties on model parameters definition to improve its accuracy are presented. The model is then applied to an industrial facility (wood industry) with contemporaneous demand of electricity and heat. An analysis of the parameters and the results of the model is performed, showing a forecast of electricity demand with an error of 3%.","data analytics,big data,forecasting,energy,polygeneration,clustering,kNN,pattern recognition",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"OXIDE,FUEL-CELLS,NEURAL-NETWORK,ENERGY,SYSTEMS,EFFICIENCY,ANALYTICS",ENERGIES,https://res.mdpi.com/d_attachment/energies/energies-12-04407/article_deploy/energies-12-04407.pdf,
8,Predicting quantum advantage by quantum walk with convolutional neural networks,21,12,,"Melnikov Alexey A.,Fedichkin Leonid E.,Alodjants Alexander","Melnikov AA,Fedichkin LE,Alodjants A",Melnikov AA,10.1088/1367-2630/ab5c5e,ITMO University,"Quantum walks are at the heart of modern quantum technologies. They allow to deal with quantum transport phenomena and are an advanced tool for constructing novel quantum algorithms. Quantum walks on graphs are fundamentally different from classical random walks analogs, in particular, they walk faster than classical ones on certain graphs, enabling in these cases quantum algorithmic applications and quantum-enhanced energy transfer. However, little is known about the possible advantages on arbitrary graphs not having explicit symmetries. For these graphs one would need to perform simulations of classical and quantum walk dynamics to check if the speedup occurs, which could take a long computational time. Here we present a new approach for the solution of the quantum speedup problem, which is based on a machine learning algorithm that predicts the quantum advantage by just 'looking' at a graph. The convolutional neural network, which we designed specifically to learn from graphs, observes simulated examples and learns complex features of graphs that lead to a quantum advantage, allowing to identify graphs that exhibit quantum advantage without performing any quantum walk or random walk simulations. The performance of our approach is evaluated for line and random graphs, where classification was always better than random guess even for the most challenging cases. Our findings pave the way to an automated elaboration of novel large-scale quantum circuits utilizing quantum walk based algorithms, and to simulating high-efficiency energy transfer in biophotonics and material science.","quantum walks,machine learning,convolutional neural networks,quantum transport,quantum speedup",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,3.741,"ALGORITHM,SEARCH,TIME",NEW JOURNAL OF PHYSICS,http://arxiv.org/pdf/1901.10632,
9,"Defect detection method using deep convolutional neural network, support vector machine and template matching techniques",24,4,512-519,"Nagata Fusaomi,Tokuno Kenta,Mitarai Kazuki,Otsuka Akimasa,Ikeda Takeshi,Ochi Hiroaki,Watanabe Keigo,Habib Maki K.","Nagata F,Tokuno K,Mitarai K,Otsuka A,Ikeda T,Ochi H,Watanabe K,Habib MK",Nagata F,10.1007/s10015-019-00545-x,"Sanyo Onoda City Univ, Fac Engn, Dept Mech Engn, 1-1-1 Daigaku Dori, Sanyo Onoda 7560884, Japan.","In this paper, a defect detection method using deep convolutional neural network (DCNN), support vector machine (SVM) and template matching techniques is introduced. First, a DCNN for visual inspection is designed and trained using a large number of images to inspect undesirable defects such as crack, burr, protrusion, chipping, spot and fracture phenomena which appear in the manufacturing process of resin molded articles. Then the trained DCNN named sssNet and well-known AlexNet are, respectively, incorporated with two SVMs to classify sample images with high recognition rate into accept as OK category or reject as NG one, in which compressed feature vectors obtained from the DCNNs are used as inputs for the SVMs. The performances of the two types of SVMs with the DCNNs are compared and evaluated through training and classification experiments. Finally, a template matching technique is further proposed to efficiently extract important target areas from original training and test images. This will be able to enhance the reliability and accuracy for defect detection.","Deep convolutional neural network (DCNN),Support vector machine (SVM),Template matching,Defect detection system",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Robotics,,,,ARTIFICIAL LIFE AND ROBOTICS,,
10,Synergistic attention U-Net for sublingual vein segmentation,24,4,550-559,"Yang Tingxiao,Yoshimura Yuichiro,Morita Akira,Namiki Takao,Nakaguchi Toshiya","Yang TX,Yoshimura Y,Morita A,Namiki T,Nakaguchi T",Yang TX,10.1007/s10015-019-00547-9,Chiba University,"The tongue is one of the most sensitive organs of the human body. The changes in the tongue indicate the changes of the human state. One of the features of the tongue, which can be used to inspect the blood circulation of human, is the shape information of the sublingual vein. Therefore, this paper aims to segment the sublingual vein from the RGB images of the tongue. In traditional segmentation network training based on deep learning, the resolution of the input image is generally resized to save training costs. However, the size of the sublingual vein is much smaller than the size of the tongue relative to the entire image. The resized inputs are likely to cause the network to fail to capture target information for the smaller segmentation and produce an ""all black"" output. This study first pointed out that the training of the segmentation of the sublingual vein compared to the tongue segmentation is much more difficult through a small dataset. At the same time, we also compared the effects of different input sizes on small sublingual segmentation. In response to the problems that arise, we propose a synergistic attention network. By dismembering the entire encoder decoder framework and updating the parameters synergistically, the proposed network can not only improve the convergence speed of training process, but also avoid the problem of falling into the optimal local solution and maintains the stability of training without increasing the training cost and additional regional auxiliary labels.","Tongue,Sublingual veins,Segmentation,Synergistic,Attention,Deep learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Robotics,,,,ARTIFICIAL LIFE AND ROBOTICS,,
11,A Resource-Optimized VLSI Implementation of a Patient-Specific Seizure Detection Algorithm on a Custom-Made Wireless Device for Ambulatory Epilepsy Diagnostics,13,6,1175-1185,"Zhan Tianyu,Fatmi Syyeda Zainab,Guraya Sam,Kassiri Hossein","Zhan TY,Fatmi SZ,Guraya S,Kassiri H",Kassiri H,10.1109/TBCAS.2019.2948301,York University - Canada,"A patient-specific epilepsy diagnostic solution in the form of a wireless wearable ambulatory device is presented. First, the design, VLSI implementation, and experimental validation of a resource-optimized machine learning algorithm for epilepsy seizure detection are described. Next, the development of a mini-PCB that integrates a low-power wireless data transceiver and a programmable processor for hosting the seizure detection algorithm is discussed. The algorithm uses only EEG signals from the frontal lobe electrodes while yielding a seizure detection sensitivity and specificity competitive to the standard full EEG systems. The experimental validation of the algorithm VLSI implementation proves the possibility of conducting accurate seizure detection using quickly-mountable dry-electrode headsets without the need for uncomfortable/painful through-hair electrodes or adhesive gels. Details of design and optimization of the algorithm, the VLSI implementation, and the mini-PCB development are presented and resource optimization techniques are discussed. The optimized implementation is uploaded on a low-power Microsemi Igloo FPGA, requires 1237 logic elements, consumes 110 $\mu$W dynamic power, and yields a minimum detection latency of 10.2 $\mu$s. The measurement results from the FPGA implementation on data from 23 patients (198 seizures in total) shows a seizure detection sensitivity and specificity of 92.5 and 80.1, respectively. Comparison to the state of the art is presented from system integration, the VLSI implementation, and the wireless communication perspectives.","Electroencephalography,Electrodes,Wireless communication,Biomedical monitoring,Monitoring,Very large scale integration,Epilepsy,Energy-efficient VLSI implementation,epilepsy,patient specific,point-of-care diagnostics,seizure detection,SVM,machine learning,wearable devices,wireless wearable sensors",Article; Proceedings Paper,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,"STIMULATION,COMPONENTS",IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,,
12,Resource-Aware Distributed Epilepsy Monitoring Using Self-Awareness From Edge to Cloud,13,6,1338-1350,"Forooghifar Farnaz,Aminifar Amir,Atienza David","Forooghifar F,Aminifar A,Atienza D",Forooghifar F,10.1109/TBCAS.2019.2951222,Ecole Polytechnique Federale de Lausanne,"The integration of wearable devices in humans' daily lives has grown significantly in recent years and still continues to affect different aspects of high-quality life. Thus, ensuring the reliability of the decisions becomes essential in biomedical applications, while representing a major challenge considering battery-powered wearable technologies. Transferring the complex and energy-consuming computations to fogs or clouds can significantly reduce the energy consumption of wearable devices and result in a longer lifetime of these systems with a single battery charge. In this work, we aim to distribute the complex and energy-consuming machine-learning computations between the edge, fog, and cloud, based on the notion of self-awareness that takes into account the complexity and reliability of the algorithm. We also model and analyze the trade-offs in terms of energy consumption, latency, and performance of different Internet of Things (IoT) solutions. We consider the epileptic seizure detection problem as our real-world case study to demonstrate the importance of our proposed self-aware methodology.","Cloud computing,Monitoring,Biomedical monitoring,Task analysis,Energy consumption,Batteries,Epilepsy,Cloud,distributed health monitoring,edge,epilepsy,fog,IoT,self-awareness",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,"SUDDEN,UNEXPECTED,DEATH,INTERNET,THINGS,SYSTEMS,ENERGY,IOT,EEG",IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,https://infoscience.epfl.ch/record/271861/files/TBioCAS2019_Forooghifar_Postprint.pdf,
13,ECG Classification Algorithm Based on STDP and R-STDP Neural Networks for Real-Time Monitoring on Ultra Low-Power Personal Wearable Devices,13,6,1483-1493,"Amirshahi Alireza,Hashemi Matin","Amirshahi A,Hashemi M",Hashemi M,10.1109/TBCAS.2019.2948920,Sharif University of Technology,"This paper presents a novel ECG classification algorithm for inclusion as part of real-time cardiac monitoring systems in ultra low-power wearable devices. The proposed solution is based on spiking neural networks which are the third generation of neural networks. In specific, we employ spike-timing dependent plasticity (STDP), and reward-modulated STDP (R-STDP), in which the model weights are trained according to the timings of spike signals, and reward or punishment signals. Experiments show that the proposed solution is suitable for real-time operation, achieves comparable accuracy with respect to previous methods, and more importantly, its energy consumption in real-time classification of ECG signals is significantly smaller. In specific, energy consumption is 1.78$\boldsymbol {\mu }$J per beat, which is 2 to 9 orders of magnitude smaller than previous neural network based ECG classification methods.","Electrocardiography,Neurons,Biological neural networks,Feature extraction,Real-time systems,Energy consumption,Monitoring,Cardiac monitoring,Electrocardiogram (ECG) classification,embedded real-time systems,low power consumption,machine learning,spiking neural network (SNN),wearable devices",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,"FEATURES,SYSTEM",IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,http://arxiv.org/pdf/1905.02954,
14,Cardiovascular Disease Diagnosis: A Machine Learning Interpretation Approach,10,12,258-269,Meshref Hossam,Meshref H,Meshref H,,Taif University,"Research on heart diseases has always been the center of attention of the world health organization. More than 17 9 million people died from it in 2016, which represent 31% of the overall deaths globally. Machine learning techniques have been used extensively in that area to assist physicians to develop a firm opinion about the conditions of their heart disease patients. Some of the existing machine learning models still suffers from limited predication ability, and the chosen analysis approaches are not suitable. As well, it was noticed that the existing approaches pay more attention to building high accuracy models, while overlooking the ability to interpret and understand the recommendations of these models. In this research, different renowned machine learning techniques: Artificial Neural Networks, Support Vector Machines, Naive Bayes, Decision Trees and Random Forests have been investigated to help in building, understanding and interpreting different heart disease diagnosing models. The Artificial Neural Networks model showed the best accuracy of 84.25% compared to the other models. In addition, it was found that despite some designed models have higher accuracies than others, it may be safer to choose a lower accuracy model as a final design of this study. This sacrifice was essential to make sure that a more transparent and trusted model is being used in the heart disease diagnosis process. This transparency validation was conducted using a newly suggested metric: the Feature Ranking Cost index. The use of that index showed promising results by making it clear as which machine learning model has a balance between accuracy and transparency. It is expected that following the detailed analyses and the use of this research findings will be useful to the machine learning community as it could be the basis for post-hoc prediction model interpretation of different clinical data sets.","Heart diseases,machine learning,artificial neural networks,support vector machines,Naive Bayes,decision trees,random forests,model interpretation,feature ranking cost index",Article,"SCIENCE & INFORMATION SAI ORGANIZATION LTD, 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND",Computer Science,,,"DECISION-SUPPORT-SYSTEM,PREDICTION",INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS,,
15,A data ecosystem to support machine learning in materials science,9,4,1125-1133,"Blaiszik Ben,Ward Logan,Schwarting Marcus,Gaff Jonathon,Chard Ryan,Pike Daniel,Chard Kyle,Foster Ian","Blaiszik B,Ward L,Schwarting M,Gaff J,Chard R,Pike D,Chard K,Foster I",Blaiszik B,10.1557/mrc.2019.118,University of Chicago,"Facilitating the application of machine learning (ML) to materials science problems requires enhancing the data ecosystem to enable discovery and collection of data from many sources, automated dissemination of new data across the ecosystem, and the connecting of data with materials-specific ML models. Here, we present two projects, the Materials Data Facility (MDF) and the Data and Learning Hub for Science (DLHub), that address these needs. We use examples to show how MDF and DLHub capabilities can be leveraged to link data with ML models and how users can access those capabilities through web and programmatic interfaces.","BIG DATA,INFRASTRUCTURE,REPOSITORY,PLATFORM",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Materials Science,,2.852,"BIG,DATA,INFRASTRUCTURE,REPOSITORY,PLATFORM",MRS COMMUNICATIONS,http://arxiv.org/pdf/1904.10423,
16,Hematoxylin and Eosin (HE) Stained Liver Portal Area Segmentation Using Multi-Scale Receptive Field Convolutional Neural Network,9,4,623-634,"Xiao Qi-En,Chung Pau-Choo,Tsai Hung-Wen,Cheng Kuo-Sheng,Chow Nan-Haw,Juang Ying-Zong,Tsai Hann-Huei,Wang Cheng-Hsiung,Hsieh Tsan-An","Xiao QE,Chung PC,Tsai HW,Cheng KS,Chow NH,Juang YZ,Tsai HH,Wang CH,Hsieh TA",Wang CH,10.1109/JETCAS.2019.2952063,National Applied Research Laboratories - Taiwan,"Portal area segmentation is an important step in the quantitative histological analysis process for hepatitis grading. However, portal areas often appear of different sizes and appearances due to the variations of surrounding components such as the ductule, bile duct, artery, and portal vein. The slim fibrosis expanding from the portal area further increases challenges of the portal area segmentation. A Multi-scale Receptive Field Convolutional Neural Network (MRF-CNN) for the segmentation of the liver portal areas in hematoxylin and eosin (HE) stained whole slide images (WSIs) is proposed in this paper. The MRF-CNN adopts the atrous spatial pyramid pooling (ASPP) with multiple atrous rates and symmetric encoder-decoder with feature concatenation architecture. The atrous rates in ASPP are devised of receptive fields to extract features of meaningful tissue components in parallel in portal areas. Along with the MRF-CNN, a small object sensitive loss function is also proposed to have the network focus on small portal areas and slim fibrosis. The results show that the proposed model achieves Intersection over Union (IOU) of 0.87 and sensitivity of 0.92. Compared to recent segmentation researches such as Fully Convolutional Network (FCN), U-Net and SegNet, the proposed network achieves an overall the best IOU and sensitivity performance. Experimental results also show that the designed ASPP block benefits in feature extraction, and the ability of identifying small objects in proposed small object sensitive loss has a significant improvement of the segmentation result comparing to the original cross entropy loss.","Convolutional neural networks,Image segmentation,Sensitivity,Accuracy,Liver,Feature extraction,Convolutional neural network,liver portal area,multi-scale receptive field,small object sensitive loss,segmentation",Article; Proceedings Paper,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.138,IMAGES,IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS,,
17,Robust and Lightweight Ensemble Extreme Learning Machine Engine Based on Eigenspace Domain for Compressed Learning,66,12,4699-4712,"Li Huai-Ting,Chou Ching-Yao,Chen Yi-Ta,Wang Sheng-Hui,Wu An-Yeu","Li HT,Chou CY,Chen YT,Wang SH,Wu AY",Wu AY,10.1109/TCSI.2019.2940642,National Taiwan University,"Compressive sensing (CS) is applied to electrocardiography (ECG) telemonitoring system to address the energy constraint of signal acquisition in sensors. In addition, on-sensor-analysis transmitting only abnormal data further reduces the energy consumption. To combine both advantages, ""On-CS-sensor-analysis"" can be achieved by compressed learning (CL), which analyzes signals directly in compressed domain. Extreme learning machine (ELM) provides an effective solution to achieve the goal of low-complexity CL. However, single ELM model has limited accuracy and is sensitive to the quality of data. Furthermore, hardware non-idealities in CS sensors result in learning performance degradation. In this work, we propose the ensemble of sub-eigenspace-ELM (SE-ELM), including two novel approaches: 1) We develop the eigenspace transformation for compressed noisy data, and further utilize a subspace-based dictionary to remove the interferences, and 2) Hardware-friendly design for ensemble of ELM provides high accuracy while maintaining low complexity. The simulation results on ECG-based atrial fibrillation show the SE-ELM can achieve the highest accuracy with 61.9 savings of the required multiplications compared with conventional methods. Finally, we implement this engine in TSMC 90 nm technology. The postlayout results show the proposed CL engine can provide competitive area- and energy-efficiency compared to existing machine learning engines.","Sensors,Engines,Electrocardiography,Feature extraction,Hardware,Energy consumption,Machine learning,Compressed learning,extreme learning machine,machine learning,noise tolerance,very large scale integration (VLSI)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,3.473,"SIGNAL,RECOVERY,PROCESSOR,INVERSE,ENERGY",IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS,,
18,Real-Time Stencil Printing Optimization Using a Hybrid Multi-Layer Online Sequential Extreme Learning and Evolutionary Search Approach,9,12,2490-2498,"Lu Hongya,Wang Haifeng,Yoon Sang Won,Won Daehan","Lu HY,Wang HF,Yoon SW,Won D",Yoon SW,10.1109/TCPMT.2019.2934487,State University of New York (SUNY) System,"This article aims to develop a dynamic optimization model performing real-time control of a stencil printing process (SPP) by maintaining the optimal printer parameter settings. In a surface mount technology (SMT) assembly line, stencil printing is a major process that affects the yield of printed circuit boards (PCBs). During printing, environmental changes may induce the PCB's printing results to deviate from initial optimal outcomes. To consistently improve the system performance, a real-time adaptation of the printer settings is an effective and cost-efficient approach. This research proposes a hybrid online optimization model by using online learning to predict real-time SPP volumes and an evolutionary search (ES) technique to determine the optimal settings. The prediction model investigates the printing volumes' transfer efficiency (TE) in averages and standard deviations (SDs) with relevant features. From the model selection of the online-based learning, the multi-layer online sequential extreme learning machine (MOSELM) shows outstanding prediction performance with R-2 values of 97% for volume averages and 81% for SDs. From the real implicational results, the system achieves a C-pk = 2.8, outperforming other advanced models. The proposed framework exhibits a good balance between accuracy and retraining efficiency, promising effective SMT assembly dynamic control.","Extreme learning machine,online learning,stencil printing process,surface mount technology (SMT)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Materials Science",,1.796,"MACHINE,PASTE",IEEE TRANSACTIONS ON COMPONENTS PACKAGING AND MANUFACTURING TECHNOLOGY,,
19,EEG-Based Multi-Modal Emotion Recognition using Bag of Deep Features: An Optimal Feature Selection Approach,19,23,,"Asghar Muhammad Adeel,Khan Muhammad Jamil,Fawad,Amin Yasar,Rizwan Muhammad,Rahman MuhibUr,Badnava Salman,Mirjavadi Seyed Sajad","Asghar MA,Khan MJ,Fawad,Amin Y,Rizwan M,Rahman M,Badnava S,Mirjavadi SS",Rahman M,10.3390/s19235218,Universite de Montreal,"Much attention has been paid to the recognition of human emotions with the help of electroencephalogram (EEG) signals based on machine learning technology. Recognizing emotions is a challenging task due to the non-linear property of the EEG signal. This paper presents an advanced signal processing method using the deep neural network (DNN) for emotion recognition based on EEG signals. The spectral and temporal components of the raw EEG signal are first retained in the 2D Spectrogram before the extraction of features. The pre-trained AlexNet model is used to extract the raw features from the 2D Spectrogram for each channel. To reduce the feature dimensionality, spatial, and temporal based, bag of deep features (BoDF) model is proposed. A series of vocabularies consisting of 10 cluster centers of each class is calculated using the k-means cluster algorithm. Lastly, the emotion of each subject is represented using the histogram of the vocabulary set collected from the raw-feature of a single channel. Features extracted from the proposed BoDF model have considerably smaller dimensions. The proposed model achieves better classification accuracy compared to the recently reported work when validated on SJTU SEED and DEAP data sets. For optimal classification performance, we use a support vector machine (SVM) and k-nearest neighbor (k-NN) to classify the extracted features for the different emotional states of the two data sets. The BoDF model achieves 93.8% accuracy in the SEED data set and 77.4% accuracy in the DEAP data set, which is more accurate compared to other state-of-the-art methods of human emotion recognition.","emotion recognition,brain computer interface,bag of deep features,continuous wavelet transform",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"CLASSIFICATION,CLASSIFIERS,ENTROPY",SENSORS,https://www.mdpi.com/1424-8220/19/23/5218/pdf,
20,Computer-Aided Diagnosis of Multiple Sclerosis Using a Support Vector Machine and Optical Coherence Tomography Features,19,23,,"Cavaliere Carlo,Vilades Elisa,Alonso-Rodriguez Ma C.,Rodrigo Maria Jesus,Pablo Luis Emilio,Miguel Juan Manuel,Lopez-Guillen Elena,Morla Eva Ma Sanchez,Boquete Luciano,Garcia-Martin Elena","Cavaliere C,Vilades E,Alonso-Rodriguez MC,Rodrigo MJ,Pablo LE,Miguel JM,Lopez-Guillen E,Morla EMS,Boquete L,Garcia-Martin E",Boquete L,10.3390/s19235323,Universidad de Alcala,"The purpose of this paper is to evaluate the feasibility of diagnosing multiple sclerosis (MS) using optical coherence tomography (OCT) data and a support vector machine (SVM) as an automatic classifier. Forty-eight MS patients without symptoms of optic neuritis and forty-eight healthy control subjects were selected. Swept-source optical coherence tomography (SS-OCT) was performed using a DRI (deep-range imaging) Triton OCT device (Topcon Corp., Tokyo, Japan). Mean values (right and left eye) for macular thickness (retinal and choroidal layers) and peripapillary area (retinal nerve fibre layer, retinal, ganglion cell layer-GCL, and choroidal layers) were compared between both groups. Based on the analysis of the area under the receiver operator characteristic curve (AUC), the 3 variables with the greatest discriminant capacity were selected to form the feature vector. A SVM was used as an automatic classifier, obtaining the confusion matrix using leave-one-out cross-validation. Classification performance was assessed with Matthew's correlation coefficient (MCC) and the AUC(CLASSIFIER). The most discriminant variables were found to be the total GCL++ thickness (between inner limiting membrane to inner nuclear layer boundaries), evaluated in the peripapillary area and macular retina thickness in the nasal quadrant of the outer and inner rings. Using the SVM classifier, we obtained the following values: MCC = 0.81, sensitivity = 0.89, specificity = 0.92, accuracy = 0.91, and AUC(CLASSIFIER) = 0.97. Our findings suggest that it is possible to classify control subjects and MS patients without previous optic neuritis by applying machine-learning techniques to study the structural neurodegeneration in the retina.","multiple sclerosis,optical coherence tomography,support vector machine,confusion matrix",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"FOURIER-DOMAIN,OCT,NERVE-FIBER,LAYER,SPECTRAL-DOMAIN,SWEPT-SOURCE,CHOROIDAL,THICKNESS,SEGMENTATION,NEURITIS",SENSORS,https://europepmc.org/articles/pmc6928765?pdf=render,
21,Machine Learning Techniques Applied to Dose Prediction in Computed Tomography Tests,19,23,,"Garcia-Sanchez Antonio-Javier,Garcia Angosto Enrique,Llor Jose Luis,Serna Berna Alfredo,Ramos David","Garcia-Sanchez AJ,Angosto EG,Llor JL,Berna AS,Ramos D",Garcia-Sanchez AJ,10.3390/s19235116,Universidad Politecnica de Cartagena,"Increasingly more patients exposed to radiation from computed axial tomography (CT) will have a greater risk of developing tumors or cancer that are caused by cell mutation in the future. A minor dose level would decrease the number of these possible cases. However, this framework can result in medical specialists (radiologists) not being able to detect anomalies or lesions. This work explores a way of addressing these concerns, achieving the reduction of unnecessary radiation without compromising the diagnosis. We contribute with a novel methodology in the CT area to predict the precise radiation that a patient should be given to accomplish this goal. Specifically, from a real dataset composed of the dose data of over fifty thousand patients that have been classified into standardized protocols (skull, abdomen, thorax, pelvis, etc.), we eliminate atypical information (outliers), to later generate regression curves employing diverse well-known Machine Learning techniques. As a result, we have chosen the best analytical technique per protocol; a selection that was thoroughly carried out according to traditional dosimetry parameters to accurately quantify the dose level that the radiologist should apply in each CT test.","machine learning,dose,computed axial tomography,patients",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"DIAGNOSTIC,REFERENCE,LEVELS,CT,ESTABLISHMENT",SENSORS,https://repositorio.upct.es/bitstream/10317/9309/1/sensors-19-05116-v2.pdf,
22,Flexible Insole Sensors with Stably Connected Electrodes for Gait Phase Detection,19,23,,"Heng Wenzheng,Pang Gaoyang,Xu Feihong,Huang Xiaoyan,Pang Zhibo,Yang Geng","Heng WZ,Pang GY,Xu FH,Huang XY,Pang ZB,Yang G",Yang G,10.3390/s19235197,Zhejiang University,"Gait analysis is an important assessment tool for analyzing vital signals collected from individuals and for providing physical information of the human body, and it is emerging in a diverse range of application scenarios, such as disease diagnosis, fall prevention, rehabilitation, and human-robot interaction. Herein, a kind of surface processed conductive rubber was designed and investigated to develop a pressure-sensitive insole to monitor planar pressure in a real-time manner. Due to a novel surface processing method, the pressure sensor was characterized by stable contact resistance, simple manufacturing, and high mechanical durability. In the experiments, it was demonstrated that the developed pressure sensors were easily assembled with the inkjet-printed electrodes and a flexible substrate as a pressure-sensitive insole while maintaining good sensing performance. Moreover, resistive signals were wirelessly transmitted to computers in real time. By analyzing sampled resistive data combined with the gait information monitored by a visual-based reference system based on machine learning method (k-Nearest Neighbor algorithm), the corresponding relationship between plantar pressure distribution and lower limb joint angles was obtained. Finally, the experimental validation of the ability to accurately divide gait into several phases was conducted, illustrating the potential application of the developed device in healthcare and robotics.","gait phase,insole sensors,surface processing,inkjet printing,visual-based reference,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"ROBOT,SYSTEM",SENSORS,https://europepmc.org/articles/pmc6928953?pdf=render,
23,Super-Resolution for Improving EEG Spatial Resolution using Deep Convolutional Neural Network-Feasibility Study,19,23,,"Kwon Moonyoung,Han Sangjun,Kim Kiwoong,Jun Sung Chan","Kwon M,Han S,Kim K,Jun SC",Jun SC,10.3390/s19235317,Gwangju Institute of Science & Technology (GIST),"Electroencephalography (EEG) has relatively poor spatial resolution and may yield incorrect brain dynamics and distort topography; thus, high-density EEG systems are necessary for better analysis. Conventional methods have been proposed to solve these problems, however, they depend on parameters or brain models that are not simple to address. Therefore, new approaches are necessary to enhance EEG spatial resolution while maintaining its data properties. In this work, we investigated the super-resolution (SR) technique using deep convolutional neural networks (CNN) with simulated EEG data with white Gaussian and real brain noises, and experimental EEG data obtained during an auditory evoked potential task. SR EEG simulated data with white Gaussian noise or brain noise demonstrated a lower mean squared error and higher correlations with sensor information, and detected sources even more clearly than did low resolution (LR) EEG. In addition, experimental SR data also demonstrated far smaller errors for N1 and P2 components, and yielded reasonable localized sources, while LR data did not. We verified our proposed approach's feasibility and efficacy, and conclude that it may be possible to explore various brain dynamics even with a small number of sensors.","convolutional neural networks,electroencephalography,spatial resolution,super-resolution",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"HIGH-DENSITY,EEG,SOURCE,LOCALIZATION,SCALP,POTENTIALS,SURFACE",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6928936,
24,A Gesture Recognition Algorithm for Hand-Assisted Laparoscopic Surgery,19,23,,"Lopez-Casado Carmen,Bauzano Enrique,Rivas-Blanco Irene,Perez-del-Pulgar Carlos J.,Munoz Victor F.","Lopez-Casado C,Bauzano E,Rivas-Blanco I,Perez-del-Pulgar CJ,Munoz VF",Perez-del-Pulgar CJ,10.3390/s19235182,Universidad de Malaga,"Minimally invasive surgery (MIS) techniques are growing in quantity and complexity to cover a wider range of interventions. More specifically, hand-assisted laparoscopic surgery (HALS) involves the use of one surgeon's hand inside the patient whereas the other one manages a single laparoscopic tool. In this scenario, those surgical procedures performed with an additional tool require the aid of an assistant. Furthermore, in the case of a human-robot assistant pairing a fluid communication is mandatory. This human-machine interaction must combine both explicit orders and implicit information from the surgical gestures. In this context, this paper focuses on the development of a hand gesture recognition system for HALS. The recognition is based on a hidden Markov model (HMM) algorithm with an improved automated training step, which can also learn during the online surgical procedure by means of a reinforcement learning process.","surgical robotics,machine learning,gesture recognition",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"DEPTH,DATA,SEGMENTATION,KINECT",SENSORS,https://www.mdpi.com/1424-8220/19/23/5182/pdf,
25,A Novel Framework with High Diagnostic Sensitivity for Lung Cancer Detection by Electronic Nose,19,23,,"Lu Binchun,Fu Lidan,Nie Bo,Peng Zhiyun,Liu Hongying","Lu BC,Fu LD,Nie B,Peng ZY,Liu HY",Liu HY,10.3390/s19235333,Chongqing University,"The electronic nose (e-nose) system is a newly developing detection technology for its advantages of non-invasiveness, simple operation, and low cost. However, lung cancer screening through e-nose requires effective pattern recognition frameworks. Existing frameworks rely heavily on hand-crafted features and have relatively low diagnostic sensitivity. To handle these problems, gated recurrent unit based autoencoder (GRU-AE) is adopted to automatically extract features from temporal and high-dimensional e-nose data. Moreover, we propose a novel margin and sensitivity based ordering ensemble pruning (MSEP) model for effective classification. The proposed heuristic model aims to reduce missed diagnosis rate of lung cancer patients while maintaining a high rate of overall identification. In the experiments, five state-of-the-art classification models and two popular dimensionality reduction methods were involved for comparison to demonstrate the validity of the proposed GRU-AE-MSEP framework, through 214 collected breath samples measured by e-nose. Experimental results indicated that the proposed intelligent framework achieved high sensitivity of 94.22%, accuracy of 93.55%, and specificity of 92.80%, thereby providing a new practical means for wide disease screening by e-nose in medical scenarios.","lung cancer,autoencoder,ensemble pruning,electronic nose,volatile organic compounds",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"EXHALED,BREATH,ENSEMBLE,METHODS,SENSOR,ARRAY,DIVERSITY,MARGIN,DISCRIMINATION,IDENTIFICATION,BIOMARKERS,INSIGHTS",SENSORS,https://europepmc.org/articles/pmc6928832?pdf=render,
26,Non-Destructive Soluble Solids Content Determination for 'Rocha' Pear Based on VIS-SWNIR Spectroscopy under 'Real World' Sorting Facility Conditions,19,23,,"Passos Dario,Rodrigues Daniela,Cavaco Ana Margarida,Antunes Maria Dulce,Guerra Rui","Passos D,Rodrigues D,Cavaco AM,Antunes MD,Guerra R",Passos D; Guerra R,10.3390/s19235165,Universidade do Algarve,"In this paper we report a method to determine the soluble solids content (SSC) of 'Rocha' pear (Pyrus communis L. cv. Rocha) based on their short-wave NIR reflectance spectra (500-1100 nm) measured in conditions similar to those found in packinghouse fruit sorting facilities. We obtained 3300 reflectance spectra from pears acquired from different lots, producers and with diverse storage times and ripening stages. The macroscopic properties of the pears, such as size, temperature and SSC were measured under controlled laboratory conditions. For the spectral analysis, we implemented a computational pipeline that incorporates multiple pre-processing techniques including a feature selection procedure, various multivariate regression models and three different validation strategies. This benchmark allowed us to find the best model/preproccesing procedure for SSC prediction from our data. From the several calibration models tested, we have found that Support Vector Machines provides the best predictions metrics with an RMSEP of around 0.82 degrees Brix and 1.09 degrees Brix for internal and external validation strategies respectively. The latter validation was implemented to assess the prediction accuracy of this calibration method under more 'real world-like' conditions. We also show that incorporating information about the fruit temperature and size to the calibration models improves SSC predictability. Our results indicate that the methodology presented here could be implemented in existing packinghouse facilities for single fruit SSC characterization.","VIS-SWNIR spectroscopy,diffuse reflectance,soluble solids content,machine learning,fruit's internal quality,non-destructive measurements",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"LEAST-SQUARES,VARIABLE,SELECTION,NIR,SPECTROSCOPY,NEURAL-NETWORK,REGRESSION,FIRMNESS,MODELS,TEMPERATURE,VALIDATION,QUALITY",SENSORS,https://europepmc.org/articles/pmc6929082?pdf=render,
27,A Clamping Force Estimation Method Based on a Joint Torque Disturbance Observer Using PSO-BPNN for Cable-Driven Surgical Robot End-Effectors,19,23,,"Wang Zhengyu,Wang Daoming,Chen Bing,Yu Lingtao,Qian Jun,Zi Bin","Wang ZY,Wang DM,Chen B,Yu LT,Qian J,Zi B",Wang DM,10.3390/s19235291,Hefei University of Technology,"The ability to sense external force is an important technique for force feedback, haptics and safe interaction control in minimally-invasive surgical robots (MISRs). Moreover, this ability plays a significant role in the restricting refined surgical operations. The wrist joints of surgical robot end-effectors are usually actuated by several long-distance wire cables. Its two forceps are each actuated by two cables. The scope of force sensing includes multidimensional external force and one-dimensional clamping force. This paper focuses on one-dimensional clamping force sensing method that do not require any internal force sensor integrated in the end-effector's forceps. A new clamping force estimation method is proposed based on a joint torque disturbance observer (JTDO) for a cable-driven surgical robot end-effector. The JTDO essentially considers the variations in cable tension between the actual cable tension and the estimated cable tension using a Particle Swarm Optimization Back Propagation Neural Network (PSO-BPNN) under free motion. Furthermore, a clamping force estimator is proposed based on the forceps' JTDO and their mechanical relations. According to comparative analyses in experimental studies, the detection resolutions of collision force and clamping force were 0.11 N. The experimental results verify the feasibility and effectiveness of the proposed clamping force sensing method.","surgical robot end-effector,clamping force estimation,joint torque disturbance observer,PSO-BPNN,cable tension measurement",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"NEURAL-NETWORK,SENSING,CAPABILITY,DESIGN,PREDICTION,SURGERY,INSTRUMENT,ALGORITHM,SENSOR,MODEL",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6929025,
28,Yoga Posture Recognition and Quantitative Evaluation with Wearable Sensors Based on Two-Stage Classifier and Prior Bayesian Network,19,23,,"Wu Ze,Zhang Jiwen,Chen Ken,Fu Chenglong","Wu Z,Zhang JW,Chen K,Fu CL",Fu CL,10.3390/s19235129,Southern University of Science & Technology,"Currently, with the satisfaction of people's material life, sports, like yoga and tai chi, have become essential activities in people's daily life. For most yoga amateurs, they could only learn yoga by self-study, like mechanically imitating from yoga video. They could not know whether they performed standardly without feedback and guidance. In this paper, we proposed a full-body posture modeling and quantitative evaluation method to recognize and evaluate yoga postures to provide guidance to the learner. Back propagation artificial neural network (BP-ANN) was adopted as the first classifier to divide yoga postures into different categories, and fuzzy C-means (FCM) was utilized as the second classifier to classify the postures in a category. The posture data on each body part was regarded as a multidimensional Gaussian variable to build a Bayesian network. The conditional probability of the Gaussian variable corresponding to each body part relative to the Gaussian variable corresponding to the connected body part was used as criterion to quantitatively evaluate the standard degree of body parts. The angular differences between nonstandard parts and the standard model could be calculated to provide guidance with an easily-accepted language, such as ""lift up your left arm"", ""straighten your right forearm"". To evaluate our method, a wearable device with 11 inertial measurement units (IMUs) fixed onto the body was designed to measure yoga posture data with quaternion format, and the posture database with a total of 211,643 data frames and 1831 posture instances was collected from 11 subjects. Both the posture recognition test and evaluation test were conducted. In the recognition test, 30% data was randomly picked from the database to train BP-ANN and FCM classifiers, and the recognition accuracy of the remaining 70% data was 95.39%, which is highly competitive with previous posture recognition approaches. In the evaluation test, 30% data were picked randomly from subject three, subject four, and subject six, to train the Bayesian network. The probabilities of nonstandard parts were almost all smaller than 0.3, while the probabilities of standard parts were almost all greater than 0.5, and thus the nonstandard parts of body posture could be effectively separated and picked for guidance. We also tested separately the trainers' yoga posture performance in the condition of without and with guidance provided by our proposed method. The results showed that with guidance, the joint angle errors significantly decreased.","yoga posture recognition and evaluation,inertial measurement unit,BP-ANN and FCM,Bayesian network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"GESTURE,RECOGNITION,ARM",SENSORS,https://www.mdpi.com/1424-8220/19/23/5129/pdf,
29,CORONARY HEART DISEASE DETECTION USING NONLINEAR FEATURES AND ONLINE SEQUENTIAL EXTREME LEARNING MACHINE,31,6,,"Saxena Sulekha,Gupta Vijay Kumar,Hrisheekesha P. N.","Saxena S,Gupta VK,Hrisheekesha PN",Saxena S,10.4015/S1016237219500467,"Dr APJ Abdul Kalam Tech Univ, Lucknow 226701, Uttar Pradesh, India.","In this paper, we propose an automated approach that combines the generalized discriminant analysis (GDA) as feature reduction scheme with radial basis function (RBF) kernel and the online sequential extreme learning machine (OSELM) having Sigmoid, Hardlim, RBF and Sine activation function as binary classifier for detection of congestive heart failure (CHF) and coronary artery disease (CAD). For this analysis, 13 nonlinear features as Correlation Dimension (CD), Detrended Fluctuation Analysis (DFA) as DFA-alpha 1 and DFA-alpha 2, Bubble Entropy (BBEn), Sample Entropy (SampEn), Dispersion Entropy (DISEn), Lempel-Ziv Complexity (LZ), Sinai Entropy (SIEn), Improved Multiscale Permutation Entropy (IMPE), Hurst Exponent (HE), Permutation Entropy (PE), Approximate Entropy (ApEn) and Standard Deviation (SD1/SD2) were extracted from Heart Rate Variability (HRV) signals. For validation of proposed method, HRV data were obtained from standard database of normal sinus rhythm (NSR), CHF and CAD subjects. Numerical experiments were done on the combination of database sets such as NSR-CAD, CHF-CAD and NSR-CHF subjects. The simulation results show a clear difference in combination of database sets by using GDA having RBF, Gaussian kernel function and OSELM binary classifier having Sigmoid, RBF and Sine activation function and achieved an accuracy of 98.17% for NSR-CAD, 100% for NSR-CHF and CAD-CHF subjects.","Online sequential extreme learning machine,Generalized discriminant analysis,Lempel-Ziv complexity,Bubble entropy,Dispersion entropy",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Engineering,,,"CLASSIFICATION,ENTROPY,SIGNALS",BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS,,
30,Large scale residential energy efficiency prioritization enabled by machine learning,12,8,2055-2078,"Al Tarhuni Badr,Naji Adel,Brodrick Philip G.,Hallinan Kevin P.,Brecha Robert J.,Yao Zhongmei","Al Tarhuni B,Naji A,Brodrick PG,Hallinan KP,Brecha RJ,Yao ZM",Al Tarhuni B,10.1007/s12053-019-09792-0,University of Dayton,"Cost-effective energy efficiency improvements in residential buildings can realize 30% energy reduction within this energy sector for the USA. Unfortunately, audits on residences to identify potential savings, generally based on detailed energy models, tend to over-estimate anticipated savings. This leads to wariness on the part of potential investors. We address this issue by taking an integrated data- and physics-based approach, using residential building geometrical and energy system characteristics (e.g., envelope, appliances, and HVAC systems), as well as historical energy consumption for each residence and weather data, to predict monthly natural gas energy consumption and savings from the adoption of individual energy saving measures. This approach requires only those geometrical and energy system characteristics associated with the greatest potential for realized savings which are also easy to obtain. We construct a dataset from a collection of houses with a wide range of energy effectiveness, and train a single statistical model that accurately predicts natural gas energy consumption in any of the individual residences. The model is then used to estimate the savings from most impactful energy efficiency investments for individual residences, as well as the collective grouping. The specific case considered here involves hundreds of university-owned student residences in the U.S. Midwest. The resulting machine-learning derived model is used to predict monthly natural gas consumption with a mean squared error of 0.00023 for unitary scaled cross-validation data. We use a nearest neighbor approach to validate savings estimates for virtually improved residences, identifying the surrogate residence most like an improved residence. This validation demonstrates a savings prediction accuracy to within 3.5% for most of the measures considered. The validated models are shown capable of prioritizing investments among the collective of residences considered. Sequential adoption of the most cost-effective energy efficiency measure among a group of residences renders a total energy reduction of 36%. The practical implications of this research are significant. This integrated machine-learning and physics-based approach to estimate savings could be used in any utility district and throughout all of the USA to enable district-wide residential energy reduction based upon sequential adoption of the most cost-effective energy measures.","Machine learning,Data-based energy models,Residential,Energy savings,Prioritized reduction",Review,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Science & Technology - Other Topics,Energy & Fuels,Environmental Sciences & Ecology",,2.447,"NONLINEAR-REGRESSION,CONSUMPTION,PREDICTION,DEMAND",ENERGY EFFICIENCY,,
31,Prediction of Electrical Conductivity of Fiber-Reinforced Cement-Based Composites by Deep Neural Networks,12,23,,"Yuan Dongdong,Jiang Wei,Tong Zheng,Gao Jie,Xiao Jingjing,Ye Wanli","Yuan DD,Jiang W,Tong Z,Gao J,Xiao JJ,Ye WL",Jiang W; Tong Z,10.3390/ma12233868,Chang'an University,"This study presents a deep-learning method for characterizing carbon fiber (CF) distribution and predicting electrical conductivity of CF-reinforced cement-based composites (CFRCs) using scanning electron microscopy (SEM) images. First, SEM images were collected from CFRC specimens with different CF contents. Second, a fully convolutional network (FCN) was utilized to extract carbon fiber components from the SEM images. Then, D-SEM and D-sample were used to evaluate the distribution of CFs. D-SEM and D-sample reflected the real CF distribution in an SEM observation area and a specimen, respectively. Finally, a radial basis neural network was used to predict the electrical conductivity of the CFRC specimens, and its weights (d(i)) were used to evaluate the effects of CF distribution on electrical conductivity. The results showed that the FCN could accurately segment CFs in SEM images with different magnifications. D-sample could accurately reflect the morphological distribution of CFs in CFRC. The electrical conductivity prediction errors were less than 6.58%. In addition, d(i) could quantitatively evaluate the effect of CF distribution on CFRC conductivity.","carbon fiber-reinforced cement-based composite,fiber distribution,electrical conductivity,deep learning,scanning electron microscopy",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"CARBON-FIBERS,DISPERSION,CONCRETE",MATERIALS,https://europepmc.org/articles/pmc6926695?pdf=render,
32,Prediction of Blood Pressure after Induction of Anesthesia Using Deep Learning: A Feasibility Study,9,23,,"Jeong Young-Seob,Kang Ah Reum,Jung Woohyun,Lee So Jeong,Lee Seunghyeon,Lee Misoon,Chung Yang Hoon,Koo Bon Sung,Kim Sang Hyun","Jeong YS,Kang AR,Jung W,Lee SJ,Lee S,Lee M,Chung YH,Koo BS,Kim SH",Kim SH,10.3390/app9235135,Soonchunhyang University,"Anesthesia induction is associated with frequent blood pressure fluctuation such as hypotension and hypertension. If it is possible to precisely predict blood pressure a few minutes ahead, anesthesiologists can proactively give anesthetic management before patients develop hemodynamic problem. The objective of this study is to develop a real-time model for predicting 3 -min-ahead blood pressure from the start of anesthesia induction to surgical incision. We used only vital signs and anesthesia-related data obtained during anesthesia-induction phase and designed a bidirectional recurrent neural network followed by fully connected layers. We conducted experiments on our collected data of 102 patients, and obtained mean absolute errors between 8.2 mmHg and 11.1 mmHg and standard deviation between 8.7 mmHg and 12.7 mmHg. The average elapsed time for prediction of a batch of 100 unseen data was about 26.56 milliseconds. We believe that this study shows feasibility of real-time prediction of future blood pressures, and the performance will be improved by collecting more data and finding better model structures.","blood pressure prediction,deep learning,recurrent neural network,real-time sequence prediction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/9/23/5135/pdf,
33,Redundancy Removed Dual-Tree Discrete Wavelet Transform to Construct Compact Representations for Automated Seizure Detection,9,23,,"Jiang Xinyu,Xu Ke,Zhang Renjie,Ren Haoran,Chen Wei","Jiang XY,Xu K,Zhang RJ,Ren HR,Chen W",Chen W,10.3390/app9235215,Fudan University,"With the development of pervasive sensing and machine learning technologies, automated epileptic seizure detection based on electroencephalogram (EEG) signals has provided tremendous support for the lives of epileptic patients. Discrete wavelet transform (DWT) is an effective method for time-frequency analysis of EEG and has been used for seizure detection in daily healthcare monitoring systems. However, the shift variance, the lack of directionality and the substantial aliasing, limit the effects of DWT in some applications. Dual-tree discrete wavelet transform (DTDWT) can overcome those drawbacks but may increase information redundancy. For classification tasks with small dataset sizes, such redundancy can greatly reduce learning efficiency and model performance. In this work, we proposed a novel redundancy removed DTDWT (RR-DTDWT) framework for automated seizure detection. Energy and modified multi-scale entropy (MMSE) features in a dual tree wavelet domain were extracted to construct a complete picture of mental states. To the best of our knowledge, this is the first study to employ MMSE as an indicator of epileptic seizures. Moreover, a compact EEG representation can be obtained after removing useless information redundancy (redundancy between wavelet trees, adjacent channels and entropy scales) by a general auto-weighted feature selection framework via global redundancy minimization (AGRM). Through validation on Bonn and CHB-MIT databases, the proposed RR-DTDWT method can achieve better performance than previous studies.","EEG monitoring,DWT,DTDWT,automated seizure detection,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"EPILEPTIC,SEIZURE,APPROXIMATE,ENTROPY,CLASSIFICATION,SIGNAL,NETWORKS,FEATURES,SYSTEM",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/9/23/5215/pdf,
34,Predicting Compressive Strength of Cement-Stabilized Rammed Earth Based on SEM Images Using Computer Vision and Deep Learning,9,23,,"Narloch Piotr,Hassanat Ahmad,Tarawneh Ahmad S.,Anysz Hubert,Kotowski Jakub,Almohammadi Khalid","Narloch P,Hassanat A,Tarawneh AS,Anysz H,Kotowski J,Almohammadi K",Narloch P; Anysz H,10.3390/app9235131,Warsaw University of Technology,"Predicting the compressive strength of cement-stabilized rammed earth (CSRE) using current testing machines is time-consuming and costly and may harm the environment due to the samples' waste. This paper presents an automatic method using computer vision and deep learning to solve the problem. For this purpose, a deep convolutional neural network (DCNN) model is proposed, which was evaluated on a new in-house scanning electron microscope (SEM) image database containing 4284 images of materials with different compressive strengths. The experimental results show reasonable prediction results compared to other traditional methods, achieving 84% prediction accuracy and a small (1.5) oot Mean Square Error (RMSE). This indicates that the proposed method (with some enhancements) can be used in practice for predicting the compressive strength of CSRE samples.","deep learning,convolutional neural network,SEM images,rammed earth,cement-stabilized rammed earth,cement stabilization",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"MOISTURE-CONTENT,CLASSIFICATION,RECOGNITION,PARAMETERS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/9/23/5131/pdf,
35,Respiration Monitoring for Premature Neonates in NICU,9,23,,"Sun Yue,Wang Wenjin,Long Xi,Meftah Mohammed,Tan Tao,Shan Caifeng,Aarts Ronald M.,de With Peter H. N.","Sun Y,Wang WJ,Long X,Meftah M,Tan T,Shan CF,Aarts RM,de With PHN",Sun Y,10.3390/app9235246,Eindhoven University of Technology,"In this paper, we investigate an automated pipeline to estimate respiration signals from videos for premature infants in neonatal intensive care units (NICUs). Two flow estimation methods, namely the conventional optical flow- and deep learning-based flow estimation methods, were employed and compared to estimate pixel motion vectors between adjacent video frames. The respiratory signal is further extracted via motion factorization. The proposed methods were evaluated by comparing our automated extracted respiration signals to that extracted from chest impedance on videos of five premature infants. The overall average cross-correlation coefficients are 0.70 for the optical flow-based method and 0.74 for the deep flow-based method. The average root mean-squared errors are 6.10 and 4.55 for the optical flow- and the deep flow-based methods, respectively. The experimental results are promising for further investigation and clinical application of the video-based respiration monitoring method for infants in NICUs.","respiration,respiration rate,video processing,remote sensing,biomedical monitoring",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/9/23/5246/pdf,
36,Using natural language processing to construct a metastatic breast cancer cohort from linked cancer registry and electronic medical records data,2,4,528-537,"Ling Albee Y.,Kurian Allison W.,Caswell-Jin Jennifer L.,Sledge George W. Jr.,Shah Nigam H.,Tamang Suzanne R.","Ling AY,Kurian AW,Caswell-Jin JL,Sledge GW,Shah NH,Tamang SR",Tamang SR,10.1093/jamiaopen/ooz040,Stanford University,"Objectives: Most population-based cancer databases lack information on metastatic recurrence. Electronic medical records (EMR) and cancer registries contain complementary information on cancer diagnosis, treatment and outcome, yet are rarely used synergistically. To construct a cohort of metastatic breast cancer (MBC) patients, we applied natural language processing techniques within a semisupervised machine learning framework to linked EMR-California Cancer Registry (CCR) data.
Materials and Methods: We studied all female patients treated at Stanford Health Care with an incident breast cancer diagnosis from 2000 to 2014. Our database consisted of structured fields and unstructured free-text clinical notes from EMR, linked to CCR, a component of the Surveillance, Epidemiology and End Results Program (SEER). We identified de novo MBC patients from CCR and extracted information on distant recurrences from patient notes in EMR. Furthermore, we trained a regularized logistic regression model for recurrent MBC classification and evaluated its performance on a gold standard set of 146 patients.
Results: There were 11 459 breast cancer patients in total and the median follow-up time was 96.3 months. We identified 1886 MBC patients, 512 (27.1%) of whom were de novo MBC patients and 1374 (72.9%) were recurrent MBC patients. Our final MBC classifier achieved an area under the receiver operating characteristic curve (AUC) of 0.917, with sensitivity 0.861, specificity 0.878, and accuracy 0.870.
Discussion and Conclusion: To enable population-based research on MBC, we developed a framework for retrospective case detection combining EMR and CCR data. Our classifier achieved good AUC, sensitivity, and specificity without expert-labeled examples.","cancer distant recurrence,natural language processing,electronic medical records,SEER",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Health Care Sciences & Services,Medical Informatics",,,,JAMIA OPEN,http://arxiv.org/pdf/1901.05958,
37,Prediction of soil properties with machine learning models based on the spectral response of soil samples in the near infrared range,70,4,298-313,Gruszczynski Stanislaw,Gruszczynski S,Gruszczynski S,10.2478/ssa-2019-0027,AGH University of Science & Technology,"One of the basic methods for soil analysis time and cost reduction is using soil sample spectral response in laboratory conditions. The problem with this method lies in determining the relationship between the shape of the soil spectral response and soil physical or chemical properties. The LUCAS soil database collected by the EU's ESDAC research centre is good material to analyse the relationship between the soil properties and the near infrared (NIR) spectral response. The modelling described in the paper is based on these data. The analysis of the impact of soil properties configuration on absorbance levels in various NIR spectrum ranges was conducted using the stepwise regression models with the properties, properties squared and products of properties being explanatory variables. The analysis of partial correlation of soil properties values with absorbance values and absorbance derivative in the entire spectral range was conducted in order to evaluate the impact of the absorbance transformation (the first derivative of absorbance vector) on the change of significance of relationship with properties values. The Multi Layer Perceptron (MLP) models were used to estimate the absorbance relationship with single soil features. Soil property modelling based on the selection and transformation algorithm of raw values and first and second absorbance derivatives was also conducted along with the suitability evaluation of such models in building digital soil maps. The absorbance is affected by a limited number of tested soil features like pH, texture, content of carbonates, SOC, N, and CEC; P and K contents have, in case of this research, a negligible impact. The NIR methodology can be suitable in conditions of limited soil variation and particularly in development of thematic soil maps.","LUCAS database,near-infrared spectroscopy,soil properties prediction",Article,"POLSKIE TOWARZYSTWO GLEBOZNAWC, POLSKIE TOWARZYSTWO GLEBOZNAWC, WARSAW, 00000, POLAND",Agriculture,,,SPECTROSCOPY,SOIL SCIENCE ANNUAL,https://doi.org/10.2478/ssa-2019-0027,
38,Soft-assembled human-machine perceptual systems,27,6,423-437,Favela Luis H.,Favela LH,Favela LH,10.1177/1059712319847129,State University System of Florida,"Cognitive systems are highly adaptable and flexible, such that action and perception capabilities can be achieved with the body in various ways, and incorporate features of the environment and nonbiological tools. Perceptual learning refers to enduring changes to a system's ability to perceive and respond to environmental stimuli. Here I present an integrative framework for understanding how such capabilities occur in human-machine systems comprising brain-body-tool-environment interactions. Central to this work is the claim that the capacity for high degrees of adaptation, flexibility, and learning are possible because human-machine systems are soft-assembled systems, that is, systems whose material constitution is not rigidly constrained so as to achieve goals via a variety of configurations. I begin by presenting the foundations of the framework on offer: the concepts, methods, and theories of ecological psychology; embodied cognition; dynamical systems theory; and machine intelligence. Next, I apply the framework to the case of visually-guided action. I conclude by explaining how this framework provides the explanatory and investigative tools to understand human-machine perceptual systems as soft-assembled systems that span brains-bodies-tools-environments.","Dynamical systems theory,ecological psychology,embodied cognition,machine intelligence,soft-assembled",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Computer Science,Psychology,Social Sciences - Other Topics",,1.643,"LONG-RANGE,CORRELATIONS,SENSORY-SUBSTITUTION,EMBODIMENT,PERSPECTIVE,HYPOTHESIS,DYNAMICS,ROBOTICS,PEOPLE,MODELS",ADAPTIVE BEHAVIOR,,
39,Using machine learning to characterize heart failure across the scales,18,6,1987-2001,"Peirlinck M.,Costabal F. Sahli,Sack K. L.,Choy J. S.,Kassab G. S.,Guccione J. M.,De Beule M.,Segers P.,Kuhl E.","Peirlinck M,Costabal FS,Sack KL,Choy JS,Kassab GS,Guccione JM,De Beule M,Segers P,Kuhl E",Kuhl E,10.1007/s10237-019-01190-w,Stanford University,"Heart failure is a progressive chronic condition in which the heart undergoes detrimental changes in structure and function across multiple scales in time and space. Multiscale models of cardiac growth can provide a patient-specific window into the progression of heart failure and guide personalized treatment planning. Yet, the predictive potential of cardiac growth models remains poorly understood. Here, we quantify predictive power of a stretch-driven growth model using a chronic porcine heart failure model, subject-specific multiscale simulation, and machine learning techniques. We combine hierarchical modeling, Bayesian inference, and Gaussian process regression to quantify the uncertainty of our experimental measurements during an 8-week long study of volume overload in six pigs. We then propagate the experimental uncertainties from the organ scale through our computational growth model and quantify the agreement between experimentally measured and computationally predicted alterations on the cellular scale. Our study suggests that stretch is the major stimulus for myocyte lengthening and demonstrates that a stretch-driven growth model alone can explain 52.7% of the observed changes in myocyte morphology. We anticipate that our approach will allow us to design, calibrate, and validate a new generation of multiscale cardiac growth models to explore the interplay of various subcellular-, cellular-, and organ-level contributors to heart failure. Using machine learning in heart failure research has the potential to combine information from different sources, subjects, and scales to provide a more holistic picture of the failing heart and point toward new treatment strategies.","Machine learning,Gaussian process regression,Bayesian inference,Uncertainty quantification,Heart failure,Growth and remodeling,Multiscale",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Biophysics,Engineering",,3.257,"CARDIAC,GROWTH,FINITE,GROWTH,DISTRIBUTIONS,ADAPTATION,HYPERTROPHY,MYOCYTES,STRESS",BIOMECHANICS AND MODELING IN MECHANOBIOLOGY,https://biblio.ugent.be/publication/8622189/file/8622323,
40,Semi-Supervised EEG Signals Classification System for Epileptic Seizure Detection,26,12,1922-1926,"Abdelhameed Ahmed M.,Bayoumi Magdy","Abdelhameed AM,Bayoumi M",Abdelhameed AM,10.1109/LSP.2019.2953870,University of Louisiana Lafayette,"In the past few decades, measuring and recording the brain electrical activities using Electroencephalogram (EEG) has become a standout amongst the tools utilized for neurological disorders' diagnosis, especially seizure detection. In this letter, a novel epileptic seizure detection system based on classifying raw EEG signals' recordings, eliminating the overhead of engineered feature extraction, is proposed. The system employs a mixing of unsupervised and supervised deep learning utilizing a one-dimensional convolutional variational autoencoder. To ascertain the robustness of the system against classifying unseen data, the evaluation of the proposed system is done using k-fold cross-validation. The classification results between normal and ictal cases have achieved a 100 accuracy while the classification results between the normal, inter-ictal and ictal cases accomplished a 99 overall accuracy which makes our system one of the most efficient among other state-of-the-art systems.","Classification,cross-validation,deep learning,epileptic seizure detection,feature extraction,variational autoencoder",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,3.586,"NEURAL-NETWORK,PREDICTION",IEEE SIGNAL PROCESSING LETTERS,,
41,,"27,","4,","564-572,",,,,,,"RESUMEN En las ltimas dcadas, la cantidad de accidentes de trnsito debido a la fatiga o somnolencia del conductor ha provocado cuantiosas prdidas humanas y materiales. A su vez, la venta en el parque automotor se ha masificado lo cual indica que posiblemente en los siguientes aos si no se toma las medidas pertinentes para detectar la fatiga existir un incremento en los accidentes automovilsticos. Este trabajo de investigacin propone el desarrollo de un sistema de deteccin de fatiga en los conductores que permita alertar sobre sobre su estado mientras est conduciendo mediante el uso de tcnicas de visin artificial y machine learning. Las tcnicas de estos dos campos de estudio se interceptan para generar modelos supervisados con un alto rendimiento al momento de clasificar el estado de fatiga en los conductores. En este estudio se ha trabajado con un dataset de imgenes frontales enfocndonos en la caracterstica fisiolgica de los ojos obteniendo resultados preliminares prometedores en la deteccin de fatiga en tiempo real."," Fatigue detection; artificial vision; ,machine learning,; HOG descriptor; CEW dataset ", research-article ,,,,,,,,
42,Retinal vessel segmentation using enhanced fuzzy min-max neural network,78,24,35053-35073,"Biyani R. S.,Patre B. M.,Kulkarni U. V.","Biyani RS,Patre BM,Kulkarni UV",Biyani RS,10.1007/s11042-019-08061-7,Shri Guru Gobind Singhji Institute of Engineering & Technology,"Automated segmentation of retinal vessels plays a pivotal role in early diagnosis of ophthalmic disorders. In this paper, a blood vessel segmentation algorithm using an enhanced fuzzy min-max neural network supervised classifier is proposed. The input to the network is an optimal 11-D feature vector which consists of spatial as well as frequency domain features extracted from each pixel of a fundus image. The essence of the method is its hyperbox classifier which performs online learning and gives binary output without any need of post-processing. The method is tested on publicly available databases DRIVE and STARE. The results are compared with the existing methods in the literature. The proposed method exhibits efficient performance and can be implemented in computer aided screening and diagnosis of retinal diseases. The method attains an average accuracy, sensitivity and specificity of 95.73%, 74.75% and 97.81% on DRIVE database and 95.51%, 74.65% and 97.11% on STARE database, respectively.","Diabetic retinopathy,Vessel segmentation,Hyperbox,Fuzzy min-max neural network",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"BLOOD-VESSELS,IMAGES,GABOR",MULTIMEDIA TOOLS AND APPLICATIONS,,
43,GABC based neuro-fuzzy classifier with hybrid features for ECG Beat classification,78,24,35351-35372,"Muthuvel K.,Anto S.,Alexander T. Jerry","Muthuvel K,Anto S,Alexander TJ",Muthuvel K,10.1007/s11042-019-08132-9,"Noorul Islam Univ, Dept Elect & Elect Engn, Kumaracoil, India.","The main objective of the proposed methodology is to classify an ECG signal as normal or abnormal using the optimal neuro-fuzzy classifier. The proposed work consists of two phases namely, feature extraction and neuro-fuzzy classifier based classification. The beat signals are initially taken from the physio-bank ATM. Then, three types of features are extracted from each signal namely, Morphological-based features, Haar wavelet-based features, and Trispectrum based features. After feature extraction, the optimal neuro-fuzzy classifier is classifying the beat signal as normal or abnormal. Here, Artificial Bee Colony (ABC) algorithm is combined with Genetic Algorithm (GA) for training the neuro-fuzzy classifier. For experimental evaluation, the MIT-BIH Arrhythmia Database is utilized and the performances are analyzed in terms of accuracy, sensitivity, and specificity. The experimental results clearly demonstrated that the proposed technique outperformed by having better accuracy of 93% when compared existing technique achieved 84% only.","ECG,Neuro-fuzzy classifier,Artificial bee colony",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,,"HEARTBEAT,CLASSIFICATION,DYNAMIC,FEATURES",MULTIMEDIA TOOLS AND APPLICATIONS,,
44,"Building Footprint Extraction from Multispectral, Spaceborne Earth Observation Datasets Using a Structurally Optimized U-Net Convolutional Neural Network",11,23,,"Pasquali Giorgio,Iannelli Gianni Cristian,Dell'Acqua Fabio","Pasquali G,Iannelli GC,Dell'Acqua F",Dell'Acqua F,10.3390/rs11232803,University of Pavia,"Building footprint detection and outlining from satellite imagery represents a very useful tool in many types of applications, ranging from population mapping to the monitoring of illegal development, from urban expansion monitoring to organizing prompter and more effective rescuer response in the case of catastrophic events. The problem of detecting building footprints in optical, multispectral satellite data is not easy to solve in a general way due to the extreme variability of material, shape, spatial, and spectral patterns that may come with disparate environmental conditions and construction practices rooted in different places across the globe. This difficult problem has been tackled in many different ways since multispectral satellite data at a sufficient spatial resolution started making its appearance on the public scene at the turn of the century. Whereas a typical approach, until recently, hinged on various combinations of spectral-spatial analysis and image processing techniques, in more recent times, the role of machine learning has undergone a progressive expansion. This is also testified by the appearance of online challenges like SpaceNet, which invite scholars to submit their own artificial intelligence (AI)-based, tailored solutions for building footprint detection in satellite data, and automatically compare and rank by accuracy the proposed maps. In this framework, after reviewing the state-of-the-art on this subject, we came to the conclusion that some improvement could be contributed to the so-called U-Net architecture, which has shown to be promising in this respect. In this work, we focused on the architecture of the U-Net to develop a suitable version for this task, capable of competing with the accuracy levels of past SpaceNet competition winners using only one model and one type of data. This achievement could pave the way for achieving better performances than the current state-of-the-art. All these results, indeed, have yet to be augmented through the integration of techniques that in the past have demonstrated a capability of improving the detection accuracy of U-net-based footprint detectors. The most notable cases are represented by an ensemble of different U-Net architectures, the integration of distance transform to improve boundary detection accuracy, and the incorporation of ancillary geospatial data on buildings. Our future work will incorporate those enhancements.","U-Net,building footprint,multispectral satellite imagery,damage assessment,convolutional neural networks,CNNs",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Geology,Remote Sensing,Imaging Science & Photographic Technology",,5.353,"IMAGERY,DAMAGE",REMOTE SENSING,https://www.mdpi.com/2072-4292/11/23/2803/pdf,
45,Capsule network-based classification of rotator cuff pathologies from MRI,80,,,"Sezer Aysun,Sezer Hasan Basri","Sezer A,Sezer HB",Sezer A,10.1016/j.compeleceng.2019.106480,Institut Polytechnique de Paris,"Rotator cuff lesions are very frequent events. The diagnosis of these lesions is challenging and requires experience. The goal of this study is to develop a computer aided diagnosis (CAD) system based on Capsule Network (CapsNet) to classify rotator cuff lesions as normal, degenerated or torn in a new dataset of 1006 shoulder proton density (PD) weighted MRIs. Increasing the number of primary capsules and adding two cascaded convolution layers before capsule layer provided the CapsNet model to extract discriminative features for the better recognition of rotator cuff pathologies. The overall success rate of proposed Capsnet model was 94.75%, compared to custom designed CNN, AlexNet, GoogLenet and the gray level co-occurrence matrix (GLCM) which provided overall success rates of 93.21%, 88.45%, 87.63% and 85.20%, respectively. CapsNet performs better than CNNs on the augmented dataset as well, and robustly handles classification difficulties of rotator cuff pathologies from MRI. (C) 2019 Elsevier Ltd. All rights reserved.","Capsule network,Convolutional neural network,Rotator cuff pathologies,PD weighted MRI,Image classification",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering",,3.297,"TEXTURE,ANALYSIS",COMPUTERS & ELECTRICAL ENGINEERING,https://www.sciencedirect.com/science/article/am/pii/S0045790618331240,
46,An Advanced Analysis System for Identifying Alcoholic Brain State Through EEG Signals,16,6,737-747,"Siuly Siuly,Bajaj Varun,Sengur Abdulkadir,Zhang Yanchun","Siuly S,Bajaj V,Sengur A,Zhang YC",Siuly S,10.1007/s11633-019-1178-7,Victoria University,"This paper addresses an advanced analysis system for the identification of alcoholic brain states from electroencephalogram (EEG) data in an automatic way. This study introduces an optimum allocation based sampling (OAS) scheme to discover the most favourable representative data points from every single time-window of each EEG signal considering the minimal variability of the observations. Combining all representative samples of each time-window in a set, some statistical features are extracted from every set of each class. The Mann-Whitney U test is used to assess whether each of the features is significant between the two classes (e.g., alcoholic and control). In order to evaluate the effectiveness of the OAS-based features, four well-known machine learning methods (decision table, support vector machine (SVM), k-nearest neighbor (k-NN) and logistic regression) are considered for identification of alcoholic brain state. The experimental results on the UCI KDD (i.e., UCI knowledge discovery in databases) database demonstrate that the OAS based decision table algorithm yields the highest accuracy of 99.58% with a low false alarm rate 0.40%, which is an improvement of up to 9.58% over the existing algorithms. A proposed analysis system can be used to detect alcoholism and also to determine the level of alcoholism-related changes in EEG signals.","Electroencephalogram (EEG),alcoholism,optimum allocation technique,feature extraction,decision table",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND","Automation & Control Systems,Computer Science",,,"TRANSFORM-BASED,FEATURES,WAVELET,TRANSFORM,FEATURE-EXTRACTION,DIAGNOSIS,CLASSIFICATION,NEUROTOXICITY,ETHANOL",INTERNATIONAL JOURNAL OF AUTOMATION AND COMPUTING,,
47,An Integrated MCI Detection Framework Based on Spectral-temporal Analysis,16,6,786-799,"Yin Jiao,Cao Jinli,Siuly Siuly,Wang Hua","Yin J,Cao JL,Siuly S,Wang H",Yin J,10.1007/s11633-019-1197-4,La Trobe University,"Aiming to differentiate between mild cognitive impairment (MCI) patients and elderly control subjects, this study proposes an integrated framework based on spectral-temporal analysis for the automatic analysis of resting-state electroencephalogram (EEG) recordings. This framework firstly eliminates noise by employing stationary wavelet transformation (SWT). Then, a set of features is extracted through spectral-temporal analysis. Next, a new wrapper algorithm, named three-dimensional (3-D) evaluation algorithm, is proposed to derive an optimal feature subset. Finally, the support vector machine (SVM) algorithm is adopted to identify MCI patients on the optimal feature subset. Decision tree and K-nearest neighbors (KNN) algorithms are also used to test the effectiveness of the selected feature subset. Twenty-two subjects are involved in experiments, of which eleven persons were in an MCI condition and the rest were elderly control subjects. Extensive experiments show that our method is able to classify MCI patients and elderly control subjects automatically and effectively, with the accuracy of 96.94% achieved by the SVM classifier. Decision tree and KNN algorithms also achieved superior results based on the optimal feature subset extracted by the proposed framework. This study is conducive to timely diagnosis and intervention for MCI patients, and therefore to delaying cognitive decline and dementia onset.","Electroencephalogram (EEG),dementia early detection,mild cognitive impairment (MCI),stationary wavelet transformation (SWT),support vector machine (SVM)",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND","Automation & Control Systems,Computer Science",,,"MILD,COGNITIVE,IMPAIRMENT,ALZHEIMERS-DISEASE,EEG,CLASSIFICATION,DIAGNOSIS,IDENTIFICATION,RECOGNITION,SELECTION",INTERNATIONAL JOURNAL OF AUTOMATION AND COMPUTING,https://vuir.vu.edu.au/41033/6/7.IJAC-2019-04-084%281%29.pdf,
48,Learned and handcrafted features for early-stage laryngeal SCC diagnosis,57,12,2683-2692,"Araujo Tiago,Santos Cristina P.,De Momi Elena,Moccia Sara","Araujo T,Santos CP,De Momi E,Moccia S",Araujo T,10.1007/s11517-019-02051-5,Universidade do Minho,"Squamous cell carcinoma (SCC) is the most common and malignant laryngeal cancer. An early-stage diagnosis is of crucial importance to lower patient mortality and preserve both the laryngeal anatomy and vocal-fold function. However, this may be challenging as the initial larynx modifications, mainly concerning the mucosa vascular tree and the epithelium texture and color, are small and can pass unnoticed to the human eye. The primary goal of this paper was to investigate a learning-based approach to early-stage SCC diagnosis, and compare the use of (i) texture-based global descriptors, such as local binary patterns, and (ii) deep-learning-based descriptors. These features, extracted from endoscopic narrow-band images of the larynx, were classified with support vector machines as to discriminate healthy, precancerous, and early-stage SCC tissues. When tested on a benchmark dataset, a median classification recall of 98% was obtained with the best feature combination, outperforming the state of the art (recall = 95%). Despite further investigation is needed (e.g., testing on a larger dataset), the achieved results support the use of the developed methodology in the actual clinical practice to provide accurate early-stage SCC diagnosis.
Graphical Workflow of the proposed solution. Patches of laryngeal tissue are pre-processed and feature extraction is performed. These features are used in the laryngeal tissue classification.","Convolutional neural networks,Deep learning,Laryngeal cancer,Machine learning,Tissue classification,Textural analysis",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"CLASSIFICATION,CANCER",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,https://www.iris.sssup.it/bitstream/11382/536492/1/MBEC_2019.pdf,
49,Automatic scoring of non-apnoea arousals using hand-crafted features from the polysomnogram,40,12,,"de Chazal Philip,Sadr Nadi","de Chazal P,Sadr N",de Chazal P,10.1088/1361-6579/ab5ed3,University of Sydney,"Objective: We present a system for automated annotation of non-apnoea arousals using twelve signals from the polysomnogram (PSG) including airflow, six signals of electroencephalogram, the electrooculogram, chin electromyogram, oximetry signal, and chest and abdominal respiratory effort signals. Approach: Fifty-nine time- and frequency-domain features were extracted from the twelve signals using 15s epochs. Features from an epoch were combined with features from adjacent epochs and then processed with a bank of feed-forward networks that provided a probability estimate of the occurrence of a non-apnoea arousal event in every epoch. Data from the 2018 PhysioNet/Computing in Cardiology Challenge was used to develop and test the system. Ten-fold cross validation on the 994 PSGs of training data was used to compare the performance of different network configurations. Main results: Our highest performing configuration utilised a bank of 30 feed-forward neural networks. Each network processed +/- 4 epochs of features and each used a single hidden layer of 20 units. The performance of this configuration was evaluated on the independent test set of 989 PSGs and achieved an area under the receiver operator curve of 0.848 and an area under the precision-recall curve of 0.325 for correctly discriminating non-apnoea arousals from non-arousals samples. Significance: The classification performance results of our system demonstrate that automated annotation of non-apnoea arousals can be achieved with a high degree of reliability.","respiratory effort related arousals,non-apnoea arousals,electrocardiogram,oximetry signal,power spectral density,hand-crafted feature,single hidden layer feed-forward neural network",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"OBSTRUCTIVE,SLEEP-APNEA,APPROXIMATE,ENTROPY,EEG,SIGNAL,TOOL",PHYSIOLOGICAL MEASUREMENT,,
50,Deep learning approaches for plethysmography signal quality assessment in the presence of atrial fibrillation,40,12,,"Pereira Tania,Ding Cheng,Gadhoumi Kais,Tran Nate,Colorado Rene A.,Meisel Karl,Hu Xiao","Pereira T,Ding C,Gadhoumi K,Tran N,Colorado RA,Meisel K,Hu X",Pereira T,10.1088/1361-6579/ab5b84,University of California System,"Objective: Photoplethysmography (PPG) monitoring has been implemented in many portable and wearable devices we use daily for health and fitness tracking. Its simplicity and cost-effectiveness has enabled a variety of biomedical applications, such as continuous long-term monitoring of heart arrhythmias, fitness, and sleep tracking, and hydration monitoring. One major issue that can hinder PPG-based applications is movement artifacts, which can lead to false interpretations. In many implementations, noisy PPG signals are discarded. Misinterpreted or discarded PPG signals pose a problem in applications where the goal is to increase the yield of detecting physiological events, such as in the case of paroxysmal atrial fibrillation (AF)-a common episodic heart arrhythmia and a leading risk factor for stroke. In this work, we compared a traditional machine learning and deep learning approaches for PPG quality assessment in the presence of AF, in order to find the most robust method for PPG quality assessment. Approach: The training data set was composed of 78278 30s long PPG recordings from 3764 patients using bedside patient monitors. Two different representations of PPG signals were employed-a time-series based (1D) one and an image-based (2D) one. Trained models were tested on an independent set of 2683 30s PPG signals from 13 stroke patients. Main results: ResNet18 showed a higher performance (0.985 accuracy, 0.979 specificity, and 0.988 sensitivity) than SVM and other deep learning approaches. 2D-based models were generally more accurate than 1D-based models. Significance: 2D representation of PPG signal enhances the accuracy of PPG signal quality assessment.","photoplethysmography,atrial fibrillation,signal quality assessment,deep learning,convolutional neural networks",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"TIME,NETWORKS,STROKE",PHYSIOLOGICAL MEASUREMENT,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7198064,
51,Temperature and Rainfall Are Separate Agents of Selection Shaping Population Differentiation in a Forest Tree,10,12,,"Costa e Silva Joao,Potts Brad,Harrison Peter A.,Bailey Tanya","Silva JCE,Potts B,Harrison PA,Bailey T",Silva JCE,10.3390/f10121145,Universidade de Lisboa,"Research highlights: We present evidence indicating that covariation of functional traits among populations of a forest tree is not due to genetic constraints, but rather selective covariance arising from local adaptation to different facets of the climate, namely rainfall and temperature. Background and Aims: Traits frequently covary among natural populations. Such covariation can be caused by pleiotropy and/or linkage disequilibrium, but also may arise when the traits are genetically independent as a direct consequence of natural selection, drift, mutation and/or gene flow. Of particular interest are cases of selective covariance, where natural selection directly generates among-population covariance in a set of genetically independent traits. We here studied the causes of population-level covariation in two key traits in the Australian tree Eucalyptus pauciflora. Materials and Methods: We studied covariation in seedling lignotuber size and vegetative juvenility using 37 populations sampled from throughout the geographic and ecological ranges of E. pauciflora on the island of Tasmania. We integrated evidence from multiple sources: (i) comparison of patterns of trait covariation within and among populations; (ii) climate-trait modelling using machine-learning algorithms; and (iii) selection analysis linking trait variation to field growth in an arid environment. Results: We showed strong covariation among populations compared with the weak genetic correlation within populations for the focal traits. Population differentiation in these genetically independent traits was correlated with different home-site climate variables (lignotuber size with temperature; vegetative juvenility with rainfall), which spatially covaried. The role of selection in shaping the population differentiation in lignotuber size was supported by its relationship with fitness measured in the field. Conclusions: Our study highlights the multi-trait nature of adaptation likely to occur as tree species respond to spatial and temporal changes in climate.","provenance differentiation,among-population covariance,genetic correlation,adaptation to aridity,lignotuber,leaf ontogeny,Eucalyptus pauciflora",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Forestry,,2.804,"VEGETATIVE,PHASE-CHANGE,EUCALYPTUS-GLOBULUS,NATURAL-SELECTION,GENETIC-CONTROL,CLIMATE-CHANGE,QUANTITATIVE,TRAITS,WATER,AVAILABILITY,EVOLUTIONARY,ADAPTATION,LIGNOTUBER",FORESTS,https://www.mdpi.com/1999-4907/10/12/1145/pdf,
52,Fully Passive Flexible Wireless Neural Recorder for the Acquisition of Neuropotentials from a Rat Model,4,12,3175-3185,"Liu Shiyi,Moncion Carolina,Zhang Jianwei,Balachandar Lakshmini,Kwaku Dzifa,Riera Jorge J.,Volakis John L.,Chae Junseok","Liu SY,Moncion C,Zhang JW,Balachandar L,Kwaku D,Riera JJ,Volakis JL,Chae J",Liu SY,10.1021/acssensors.9b01491,Arizona State University,"Wireless implantable neural interfaces can record high-resolution neuropotentials without constraining patient movement. Existing wireless systems often require intracranial wires to connect implanted electrodes to an external head stage or/and deploy an application-specific integrated circuit (ASIC), which is battery-powered or externally power-transferred, raising safety concerns such as infection, electronics failure, or heat-induced tissue damage. This work presents a biocompatible, flexible, implantable neural recorder capable of wireless acquisition of neuropotentials without wires, batteries, energy harvesting units, or active electronics. The recorder, fabricated on a thin polyimide substrate, features a small footprint of 9 mm x 8 mm x 0.3 mm and is composed of passive electronic components. The absence of active electronics on the device leads to near zero power consumption, inherently avoiding the catastrophic failure of active electronics. We performed both in vitro validation in a tissue-simulating phantom and in vivo validation in an epileptic rat. The fully passive wireless recorder was implanted under rat scalp to measure neuropotentials from its contact electrodes. The implanted wireless recorder demonstrated its capability to capture low voltage neuropotentials, including somatosensory evoked potentials (SSEPs), and interictal epileptiform discharges (IEDs). Wirelessly recorded SSEP and IED signals were directly compared to those from wired electrodes to demonstrate the efficacy of the wireless data. In addition, a convoluted neural network-based machine learning algorithm successfully achieved IED signal recognition accuracy as high as 100 and 91% in wired and wireless IED data, respectively. These results strongly support the fully passive wireless neural recorder's capability to measure neuropotentials as low as tens of microvolts. With further improvement, the recorder system presented in this work may find wide applications in future brain machine interface systems.","neural recorder,implantable,wireless,flexible,fully passive",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics",,8.162,"EXTRAOPERATIVE,ELECTROCORTICOGRAPHY,EEG,SYSTEM,ECOG,COMPLICATIONS,MICROSYSTEM,INTERFACE,IMPLANT,FIELDS",ACS SENSORS,,
53,Steel crack depth estimation based on 2D images using artificial neural networks,58,4,1167-1174,"Mohamed Yasser S.,Shehata Hesham M.,Abdellatif Mohamed,Awad Taher H.","Mohamed YS,Shehata HM,Abdellatif M,Awad TH",Mohamed YS,10.1016/j.aej.2019.10.001,"22 Othman Galal,Elbaraka Tower 1, Cairo, Egypt.","Automatic crack detection is needed to reduce cost and to improve quality of surface inspection that is needed for maintenance of infrastructures. In this research, a novel system was developed to detect steel cracks and to estimate their depth from 2D images. The objective is to develop an affordable and user-friendly inspection system in replacement of expensive 3D measurement devices. A learning strategy was adopted and several learning structures were exploited to decide on the suitable structure. The average intensities of 2D steel crack profiles was fed to neural network together with the maximum depth of steel cracks measured by laser microscope to train a learning structure. Feed forward back propagation Neural Network was found to produce an overall average error of 18.81% in testing which is 10% less than the previous error using another learning strategy (updated 3D Make toolbox) for depth recovery. The system performance is comparable to the state of the art and provides an applicable and affordable inspection device. (C) 2019 The Authors. Published by Elsevier B.V. on behalf of Faculty of Engineering, Alexandria University.","Crack detection,Crack depth estimation,Artificial neural networks,Computer vision,Maintenance and safety",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Engineering,,4.432,ALGORITHM,ALEXANDRIA ENGINEERING JOURNAL,https://doi.org/10.1016/j.aej.2019.10.001,
54,Label Self-Advised Support Vector Machine (LSA-SVM)-Automated Classification of Foot Drop Rehabilitation Case Study,9,4,,"Abboud Sahar Adil,Al-Wais Saba,Abdullah Salma Hameedi,Alnajjar Fady,Al-Jumaily Adel","Abboud SA,Al-Wais S,Abdullah SH,Alnajjar F,Al-Jumaily A",Al-Jumaily A,10.3390/bios9040114,University of Technology Sydney,"Stroke represents a major health problem in our society. One of the effects of stroke is foot drop. Foot drop (FD) is a weakness that occurs in specific muscles in the ankle and foot such as the anterior tibialis, gastrocnemius, plantaris and soleus muscles. Foot flexion and extension are normally generated by lower motor neurons (LMN). The affected muscles impact the ankle and foot in both downward and upward motions. One possible solution for FD is to investigate the movement based on the bio signal (myoelectric signal) of the muscles. Bio signal control systems like electromyography (EMG) are used for rehabilitation devices that include foot drop. One of these systems is function electrical stimulation (FES). This paper proposes new methods and algorithms to develop the performance of myoelectric pattern recognition (M-PR), to improve automated rehabilitation devices, to test these methodologies in offline and real-time experimental datasets. Label classifying is a predictive data mining application with multiple applications in the world, including automatic labeling of resources such as videos, music, images and texts. We combine the label classification method with the self-advised support vector machine (SA-SVM) to create an adapted and altered label classification method, named the label self-advised support vector machine (LSA-SVM). For the experimental data, we collected data from foot drop patients using the sEMG device, in the Metro Rehabilitation Hospital in Sydney, Australia using Ethical Approval (UTS HREC NO. ETH15-0152). The experimental results for the EMG dataset and benchmark datasets exhibit its benefits. Furthermore, the experimental results on UCI datasets indicate that LSA-SVM achieves the best performance when working together with SA-SVM and SVM. This paper describes the state-of-the-art procedures for M-PR and studies all the conceivable structures.","foot drop,Support Vector Machine,electromyography,label classification,rehabilitation devices",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Science & Technology - Other Topics,Instruments & Instrumentation",,5.313,,BIOSENSORS-BASEL,https://www.mdpi.com/2079-6374/9/4/114/pdf,
55,A Machine-Learning-Based Prediction Method for Hypertension Outcomes Based on Medical Data,9,4,,"Chang Wenbing,Liu Yinglai,Xiao Yiyong,Yuan Xinglong,Xu Xingxing,Zhang Siyue,Zhou Shenghan","Chang WB,Liu YL,Xiao YY,Yuan XL,Xu XX,Zhang SY,Zhou SH",Zhou SH,10.3390/diagnostics9040178,Beihang University,"The outcomes of hypertension refer to the death or serious complications (such as myocardial infarction or stroke) that may occur in patients with hypertension. The outcomes of hypertension are very concerning for patients and doctors, and are ideally avoided. However, there is no satisfactory method for predicting the outcomes of hypertension. Therefore, this paper proposes a prediction method for outcomes based on physical examination indicators of hypertension patients. In this work, we divide the patients' outcome prediction into two steps. The first step is to extract the key features from the patients' many physical examination indicators. The second step is to use the key features extracted from the first step to predict the patients' outcomes. To this end, we propose a model combining recursive feature elimination with a cross-validation method and classification algorithm. In the first step, we use the recursive feature elimination algorithm to rank the importance of all features, and then extract the optimal features subset using cross-validation. In the second step, we use four classification algorithms (support vector machine (SVM), C4.5 decision tree, random forest (RF), and extreme gradient boosting (XGBoost)) to accurately predict patient outcomes by using their optimal features subset. The selected model prediction performance evaluation metrics are accuracy, F1 measure, and area under receiver operating characteristic curve. The 10-fold cross-validation shows that C4.5, RF, and XGBoost can achieve very good prediction results with a small number of features, and the classifier after recursive feature elimination with cross-validation feature selection has better prediction performance. Among the four classifiers, XGBoost has the best prediction performance, and its accuracy, F1, and area under receiver operating characteristic curve (AUC) values are 94.36%, 0.875, and 0.927, respectively, using the optimal features subset. This article's prediction of hypertension outcomes contributes to the in-depth study of hypertension complications and has strong practical significance.","hypertension outcomes,feature selection,recursive feature elimination,classification algorithm,XGBoost,prediction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"GENE,SELECTION,RANDOM,FOREST,GLOBAL,BURDEN,SVM-RFE,CLASSIFICATION,COMPLICATIONS,NETWORKS",DIAGNOSTICS,https://europepmc.org/articles/pmc6963807?pdf=render,
56,A Hierarchical Machine Learning Model to Discover Gleason Grade-Specific Biomarkers in Prostate Cancer,9,4,,"Hamzeh Osama,Alkhateeb Abedalrhman,Zheng Julia Zhuoran,Kandalam Srinath,Leung Crystal,Atikukke Govindaraja,Cavallo-Medved Dora,Palanisamy Nallasivam,Rueda Luis","Hamzeh O,Alkhateeb A,Zheng JZ,Kandalam S,Leung C,Atikukke G,Cavallo-Medved D,Palanisamy N,Rueda L",Alkhateeb A; Rueda L,10.3390/diagnostics9040219,University of Windsor,"(1) Background:One of the most common cancers that affect North American men and men worldwide is prostate cancer. The Gleason score is a pathological grading system to examine the potential aggressiveness of the disease in the prostate tissue. Advancements in computing and next-generation sequencing technology now allow us to study the genomic profiles of patients in association with their different Gleason scores more accurately and effectively. (2) Methods: In this study, we used a novel machine learning method to analyse gene expression of prostate tumours with different Gleason scores, and identify potential genetic biomarkers for each Gleason group. We obtained a publicly-available RNA-Seq dataset of a cohort of 104 prostate cancer patients from the National Center for Biotechnology Information's (NCBI) Gene Expression Omnibus (GEO) repository, and categorised patients based on their Gleason scores to create a hierarchy of disease progression. A hierarchical model with standard classifiers in different Gleason groups, also known as nodes, was developed to identify and predict nodes based on their mRNA or gene expression. In each node, patient samples were analysed via class imbalance and hybrid feature selection techniques to build the prediction model. The outcome from analysis of each node was a set of genes that could differentiate each Gleason group from the remaining groups. To validate the proposed method, the set of identified genes were used to classify a second dataset of 499 prostate cancer patients collected from cBioportal. (3) Results: The overall accuracy of applying this novel method to the first dataset was 93.3%; the method was further validated to have 87% accuracy using the second dataset. This method also identified genes that were not previously reported as potential biomarkers for specific Gleason groups. In particular, PIAS3 was identified as a potential biomarker for Gleason score 4 + 3 = 7, and UBE2V2 for Gleason score 6. (4) Insight: Previous reports show that the genes predicted by this newly proposed method strongly correlate with prostate cancer development and progression. Furthermore, pathway analysis shows that both PIAS3 and UBE2V2 share similar protein interaction pathways, the JAK/STAT signaling process.","supervised learning,next generation sequencing,classification,transcriptomics,Gleason score detection,prostate cancer",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"SIGNAL,TRANSDUCER,ACTIVATOR,TRANSCRIPTION-5,EXPRESSION,INHIBITOR,MIGRATION,PROTEINS,CELLS",DIAGNOSTICS,https://www.mdpi.com/2075-4418/9/4/219/pdf,
57,The Performance of Deep Learning Algorithms on Automatic Pulmonary Nodule Detection and Classification Tested on Different Datasets That Are Not Derived from LIDC-IDRI: A Systematic Review,9,4,,"Li Dana,Mikela Vilmun Bolette,Frederik Carlsen Jonathan,Albrecht-Beste Elisabeth,Ammitzbol Lauridsen Carsten,Bachmann Nielsen Michael,Lindskov Hansen Kristoffer","Li D,Vilmun BM,Carlsen JF,Albrecht-Beste E,Lauridsen CA,Nielsen MB,Hansen KL",Li D,10.3390/diagnostics9040207,Rigshospitalet,"The aim of this study was to systematically review the performance of deep learning technology in detecting and classifying pulmonary nodules on computed tomography (CT) scans that were not from the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) database. Furthermore, we explored the difference in performance when the deep learning technology was applied to test datasets different from the training datasets. Only peer-reviewed, original research articles utilizing deep learning technology were included in this study, and only results from testing on datasets other than the LIDC-IDRI were included. We searched a total of six databases: EMBASE, PubMed, Cochrane Library, the Institute of Electrical and Electronics Engineers, Inc. (IEEE), Scopus, and Web of Science. This resulted in 1782 studies after duplicates were removed, and a total of 26 studies were included in this systematic review. Three studies explored the performance of pulmonary nodule detection only, 16 studies explored the performance of pulmonary nodule classification only, and 7 studies had reports of both pulmonary nodule detection and classification. Three different deep learning architectures were mentioned amongst the included studies: convolutional neural network (CNN), massive training artificial neural network (MTANN), and deep stacked denoising autoencoder extreme learning machine (SDAE-ELM). The studies reached a classification accuracy between 68-99.6% and a detection accuracy between 80.6-94%. Performance of deep learning technology in studies using different test and training datasets was comparable to studies using same type of test and training datasets. In conclusion, deep learning was able to achieve high levels of accuracy, sensitivity, and/or specificity in detecting and/or classifying nodules when applied to pulmonary CT scans not from the LIDC-IDRI database.","deep learning,nodule detection,nodule classification,artificial intelligence",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"CONVOLUTIONAL,NEURAL-NETWORK,LUNG-CANCER,DETECTION,CT,IMAGES,DIAGNOSIS,REDUCTION,MTANN",DIAGNOSTICS,https://www.mdpi.com/2075-4418/9/4/207/pdf,
58,Breast Cancer Diagnosis Using an Efficient CAD System Based on Multiple Classifiers,9,4,,"Ragab Dina A.,Sharkas Maha,Attallah Omneya","Ragab DA,Sharkas M,Attallah O",Ragab DA,10.3390/diagnostics9040165,Egyptian Knowledge Bank (EKB),"Breast cancer is one of the major health issues across the world. In this study, a new computer-aided detection (CAD) system is introduced. First, the mammogram images were enhanced to increase the contrast. Second, the pectoral muscle was eliminated and the breast was suppressed from the mammogram. Afterward, some statistical features were extracted. Next, k-nearest neighbor (k-NN) and decision trees classifiers were used to classify the normal and abnormal lesions. Moreover, multiple classifier systems (MCS) was constructed as it usually improves the classification results. The MCS has two structures, cascaded and parallel structures. Finally, two wrapper feature selection (FS) approaches were applied to identify those features, which influence classification accuracy. The two data sets (1) the mammographic image analysis society digital mammogram database (MIAS) and (2) the digital mammography dream challenge were combined together to test the CAD system proposed. The highest accuracy achieved with the proposed CAD system before FS was 99.7% using the Adaboosting of the J48 decision tree classifiers. The highest accuracy after FS was 100%, which was achieved with k-NN classifier. Moreover, the area under the curve (AUC) of the receiver operating characteristic (ROC) curve was equal to 1.0. The results showed that the proposed CAD system was able to accurately classify normal and abnormal lesions in mammogram samples.","the computer-aided detection,the pectoral muscle removal,the statistical features,the decision trees,the k-nearest neighbor,feature selection",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"ADAPTIVE,HISTOGRAM,EQUALIZATION,COMPUTER-AIDED,DETECTION,FEATURE-SELECTION,LUNG,NODULES,CLASSIFICATION,SEGMENTATION,MAMMOGRAMS,REGION",DIAGNOSTICS,https://strathprints.strath.ac.uk/70255/7/Ragab_etal_Diagnostics_2019_Breast_cancer_based_diagnosis_with_an_efficient_CAD_system.pdf,
59,Deep-ACTINet: End-to-End Deep Learning Architecture for Automatic Sleep-Wake Detection Using Wrist Actigraphy,8,12,,"Cho Taeheum,Sunarya Unang,Yeo Minsoo,Hwang Bosun,Koo Yong Seo,Park Cheolsoo","Cho T,Sunarya U,Yeo M,Hwang B,Koo YS,Park C",Park C,10.3390/electronics8121461,Kwangwoon University,"Sleep scoring is the first step for diagnosing sleep disorders. A variety of chronic diseases related to sleep disorders could be identified using sleep-state estimation. This paper presents an end-to-end deep learning architecture using wrist actigraphy, called Deep-ACTINet, for automatic sleep-wake detection using only noise canceled raw activity signals recorded during sleep and without a feature engineering method. As a benchmark test, the proposed Deep-ACTINet is compared with two conventional fixed model based sleep-wake scoring algorithms and four feature engineering based machine learning algorithms. The datasets were recorded from 10 subjects using three-axis accelerometer wristband sensors for eight hours in bed. The sleep recordings were analyzed using Deep-ACTINet and conventional approaches, and the suggested end-to-end deep learning model gained the highest accuracy of 89.65%, recall of 92.99%, and precision of 92.09% on average. These values were approximately 4.74% and 4.05% higher than those for the traditional model based and feature based machine learning algorithms, respectively. In addition, the neuron outputs of Deep-ACTINet contained the most significant information for separating the asleep and awake states, which was demonstrated by their high correlations with conventional significant features. Deep-ACTINet was designed to be a general model and thus has the potential to replace current actigraphy algorithms equipped in wristband wearable devices.","sleep scoring,actigraphy,machine learning,CNN,LSTM,accuracy,recall,precision,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"NEURAL-NETWORK,IDENTIFICATION",ELECTRONICS,https://www.mdpi.com/2079-9292/8/12/1461/pdf,
60,Accelerating Retinal Fundus Image Classification Using Artificial Neural Networks (ANNs) and Reconfigurable Hardware (FPGA),8,12,,"Ghani Arfan,See Chan H.,Sudhakaran Vaisakh,Ahmad Jahanzeb,Abd-Alhameed Raed","Ghani A,See CH,Sudhakaran V,Ahmad J,Abd-Alhameed R",Ghani A,10.3390/electronics8121522,Coventry University,"Diabetic retinopathy (DR) and glaucoma are common eye diseases that affect a blood vessel in the retina and are two of the leading causes of vision loss around the world. Glaucoma is a common eye condition where the optic nerve that connects the eye to the brain becomes damaged, whereas DR is a complication of diabetes caused by high blood sugar levels damaging the back of the eye. In order to produce an accurate and early diagnosis, an extremely high number of retinal images needs to be processed. Given the required computational complexity of image processing algorithms and the need for high-performance architectures, this paper proposes and demonstrates the use of fully parallel field programmable gate arrays (FPGAs) to overcome the burden of real-time computing in conventional software architectures. The experimental results achieved through software implementation were validated on an FPGA device. The results showed a remarkable improvement in terms of computational speed and power consumption. This paper presents various preprocessing methods to analyse fundus images, which can serve as a diagnostic tool for detection of glaucoma and diabetic retinopathy. In the proposed adaptive thresholding-based preprocessing method, features were selected by calculating the area of the segmented optic disk, which was further classified using a feedforward neural network (NN). The analysis was carried out using feature extraction through existing methodologies such as adaptive thresholding, histogram and wavelet transform. Results obtained through these methods were quantified to obtain optimum performance in terms of classification accuracy. The proposed hardware implementation outperforms existing methods and offers a significant improvement in terms of computational speed and power consumption.","neural network,machine learning,glaucoma,diabetic retinopathy,adaptive thresholding,FPGA,IoTs,smart healthcare",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"DIABETIC-RETINOPATHY,AUTOMATED,DETECTION,FEATURE-EXTRACTION,IDENTIFICATION",ELECTRONICS,https://napier-surface.worktribe.com/2383837/1/Accelerating Retinal Fundus Image Classification By Using Artificial Neural Networks (ANNs) And Reconfigurable Hardware (FPGA),
61,Analysis and Classification of Motor Dysfunctions in Arm Swing in Parkinson's Disease,8,12,,"Steinmetzer Tobias,Maasch Michele,Boenninger Ingrid,Travieso Carlos M.","Steinmetzer T,Maasch M,Bonninger I,Travieso CM",Travieso CM,10.3390/electronics8121471,Universidad de Las Palmas de Gran Canaria,"Due to increasing life expectancy, the number of age-related diseases with motor dysfunctions (MD) such as Parkinson's disease (PD) is also increasing. The assessment of MD is visual and therefore subjective. For this reason, many researchers are working on an objective evaluation. Most of the research on gait analysis deals with the analysis of leg movement. The analysis of arm movement is also important for the assessment of gait disorders. This work deals with the analysis of the arm swing by using wearable inertial sensors. A total of 250 records of 39 different subjects were used for this task. Fifteen subjects of this group had motor dysfunctions (MD). The subjects had to perform the standardized Timed Up and Go (TUG) test to ensure that the recordings were comparable. The data were classified by using the wavelet transformation, a convolutional neural network (CNN), and weight voting. During the classification, single signals, as well as signal combinations were observed. We were able to detect MD with an accuracy of 93.4% by using the wavelet transformation and a three-layer CNN architecture.","wavelet transformation,gait analysis,inertial sensors,Parkinson's disease,machine learning,wearable sensors",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,GAIT,ELECTRONICS,https://www.mdpi.com/2079-9292/8/12/1471/pdf,
62,StoolNet for Color Classification of Stool Medical Images,8,12,,"Yang Ziyuan,Leng Lu,Kim Byung-Gyu","Yang ZY,Leng L,Kim BG",Leng L,10.3390/electronics8121464,Nanchang Hangkong University,"The color classification of stool medical images is commonly used to diagnose digestive system diseases, so it is important in clinical examination. In order to reduce laboratorians' heavy burden, advanced digital image processing technologies and deep learning methods are employed for the automatic color classification of stool images in this paper. The region of interest (ROI) is segmented automatically and then classified with a shallow convolutional neural network (CNN) dubbed StoolNet. Thanks to its shallow structure and accurate segmentation, StoolNet can converge quickly. The sufficient experiments confirm the good performance of StoolNet and the impact of the different training sample numbers on StoolNet. The proposed method has several advantages, such as low cost, accurate automatic segmentation, and color classification. Therefore, it can be widely used in artificial intelligence (AI) healthcare.","StoolNet,convolutional neural network,color classification,stool medical image",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,ENHANCEMENT,ELECTRONICS,https://www.mdpi.com/2079-9292/8/12/1464/pdf,
63,Big Data Creates New Opportunities for Materials Research: A Review on Methods and Applications of Machine Learning for Materials Design,5,6,1017-1026,"Zhou Teng,Song Zhen,Sundmacher Kai","Zhou T,Song Z,Sundmacher K",Zhou T,10.1016/j.eng.2019.02.011,Max Planck Society,"Materials development has historically been driven by human needs and desires, and this is likely to continue in the foreseeable future. The global population is expected to reach ten billion by 2050, which will promote increasingly large demands for clean and high-efficiency energy, personalized consumer products, secure food supplies, and professional healthcare. New functional materials that are made and tailored for targeted properties or behaviors will be the key to tackling this challenge. Traditionally, advanced materials are found empirically or through experimental trial-and-error approaches. As big data generated by modern experimental and computational techniques is becoming more readily available, data-driven or machine learning (ML) methods have opened new paradigms for the discovery and rational design of materials. In this review article, we provide a brief introduction on various ML methods and related software or tools. Main ideas and basic procedures for employing ML approaches in materials research are highlighted. We then summarize recent important applications of ML for the large-scale screening and optimal design of polymer and porous materials, catalytic materials, and energetic materials. Finally, concluding remarks and an outlook are provided. (C) 2019 THE AUTHORS. Published by Elsevier LTD on behalf of Chinese Academy of Engineering and Higher Education Press Limited Company.","Big data,Data-driven,Machine learning,Materials screening,Materials design",Review,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Engineering,,8.977,"ARTIFICIAL,NEURAL-NETWORKS,MATERIALS,INFORMATICS,HETEROGENEOUS,CATALYSIS,METHANE,STORAGE,IONIC,LIQUIDS,SOLVENTS,PREDICTION,INDEXES,CLASSIFICATION,DESCRIPTORS",ENGINEERING,https://doi.org/10.1016/j.eng.2019.02.011,
64,Sample Entropy Combined with the K-Means Clustering Algorithm Reveals Six Functional Networks of the Brain,21,12,,"Jia Yanbing,Gu Huaguang","Jia YB,Gu HG",Gu HG,10.3390/e21121156,Tongji University,"Identifying brain regions contained in brain functional networks and functions of brain functional networks is of great significance in understanding the complexity of the human brain. The 160 regions of interest (ROIs) in the human brain determined by the Dosenbach's template have been divided into six functional networks with different functions. In the present paper, the complexity of the human brain is characterized by the sample entropy (SampEn) of dynamic functional connectivity (FC) which is obtained by analyzing the resting-state functional magnetic resonance imaging (fMRI) data acquired from healthy participants. The 160 ROIs are clustered into six clusters by applying the K-means clustering algorithm to the SampEn of dynamic FC as well as the static FC which is also obtained by analyzing the resting-state fMRI data. The six clusters obtained from the SampEn of dynamic FC and the static FC show very high overlap and consistency ratios with the six functional networks. Furthermore, for four of six clusters, the overlap ratios corresponding to the SampEn of dynamic FC are larger than that corresponding to the static FC, and for five of six clusters, the consistency ratios corresponding to the SampEn of dynamic FC are larger than that corresponding to the static FC. The results show that the combination of machine learning methods and the FC obtained using the blood oxygenation level-dependent (BOLD) signals can identify the functional networks of the human brain, and nonlinear dynamic characteristics of the FC are more effective than the static characteristics of the FC in identifying brain functional networks and the complexity of the human brain.","sample entropy,brain functional networks,complexity,dynamic functional connectivity,static functional connectivity,K-means clustering algorithm",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,2.587,"CONNECTIVITY,PARCELLATION,FLUCTUATIONS,DYNAMICS",ENTROPY,https://www.mdpi.com/1099-4300/21/12/1156/pdf,
65,Deep Learning and Artificial Intelligence for the Determination of the Cervical Vertebra Maturation Degree from Lateral Radiography,21,12,,"Makaremi Masrour,Lacaule Camille,Mohammad-Djafari Ali","Makaremi M,Lacaule C,Mohammad-Djafari A",Mohammad-Djafari A,10.3390/e21121222,"ISCT, F-91440 Bures Sur Yvette, France.","Deep Learning (DL) and Artificial Intelligence (AI) tools have shown great success in different areas of medical diagnostics. In this paper, we show another success in orthodontics. In orthodontics, the right treatment timing of many actions and operations is crucial because many environmental and genetic conditions may modify jaw growth. The stage of growth is related to the Cervical Vertebra Maturation (CVM) degree. Thus, determining the CVM to determine the suitable timing of the treatment is important. In orthodontics, lateral X-ray radiography is used to determine it. Many classical methods need knowledge and time to look and identify some features. Nowadays, ML and AI tools are used for many medical and biological diagnostic imaging. This paper reports on the development of a Deep Learning (DL) Convolutional Neural Network (CNN) method to determine (directly from images) the degree of maturation of CVM classified in six degrees. The results show the performances of the proposed method in different contexts with different number of images for training, evaluation and testing and different pre-processing of these images. The proposed model and method are validated by cross validation. The implemented software is almost ready for use by orthodontists.","Deep Learning (DL),Artificial Intelligence (AI),Convolutional Neural Network (CNN),classification,orthodontics,cervical vertebra maturation,machine learning",Article; Proceedings Paper,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,2.587,"SKELETAL,MATURATION,MANDIBULAR,GROWTH,HAND-WRIST,AGE,RELIABILITY,HEIGHT,GREULICH,ENGLISH,CNN",ENTROPY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7514567,
66,Patterns of Heart Rate Dynamics in Healthy Aging Population: Insights from Machine Learning Methods,21,12,,"Makowiec Danuta,Wdowczyk Joanna","Makowiec D,Wdowczyk J",Makowiec D,10.3390/e21121206,University of Gdansk,"Costa et. al (Frontiers in Physiology (2017) 8255) proved that abnormal features of heart rate variability (HRV) can be discerned by the presence of particular patterns in a signal of time intervals between subsequent heart contractions, called RR intervals. In the following, the statistics of these patterns, quantified using entropic tools, are explored in order to uncover the specifics of the dynamics of heart contraction based on RR intervals. The 33 measures of HRV (standard and new ones) were estimated from four hour nocturnal recordings obtained from 181 healthy people of different ages and analyzed with the machine learning methods. The validation of the methods was based on the results obtained from shuffled data. The exploratory factor analysis provided five factors driving the HRV. We hypothesize that these factors could be related to the commonly assumed physiological sources of HRV: (i) activity of the vagal nervous system; (ii) dynamical balance in the autonomic nervous system; (iii) sympathetic activity; (iv) homeostatic stability; and (v) humoral effects. In particular, the indices describing patterns: their total volume, as well as their distribution, showed important aspects of the organization of the ANS control: the presence or absence of a strong correlation between the patterns' indices, which distinguished the original rhythms of people from their shuffled representatives. Supposing that the dynamic organization of RR intervals is age dependent, classification with the support vector machines was performed. The classification results proved to be strongly dependent on the parameters of the methods used, therefore determining that the age group was not obvious.","heart rate variability,entropy,fragmentation,aging in human population,factor analysis,support vector machines classification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,2.587,"RATE-VARIABILITY,RHYTHM,RESPONSIVENESS,ARRHYTHMIAS,COMPLEXITY,STATEMENT,ENTROPY,SYSTEM,SLEEP",ENTROPY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7514550,
67,A Classification-Based Model for Multi-Objective Hyperspectral Sparse Unmixing,57,12,9612-9625,"Xu Xia,Shi Zhenwei,Pan Bin,Li Xuelong","Xu X,Shi ZW,Pan B,Li XL",Shi ZW,10.1109/TGRS.2019.2928021,Beihang University,"Sparse unmixing has become a popular tool for hyperspectral imagery interpretation. It refers to finding the optimal subset of a spectral library to reconstruct the image data and further estimate the proportions of different materials. Recently, multi-objective based sparse unmixing methods have presented promising performance because of their advantages in addressing combinatorial problems. A spectral and multi-objective based sparse unmixing (SMoSU) algorithm was proposed in our previous work, which solves the decision-making problem well. However, it does not show outstanding advantages in strong noise cases. To solve the problem, in this paper, SMoSU is improved based on the estimation of distribution algorithms (EDAs). The machine learning based EDAs have been a reliable approach in solving multi-objective problems. However, most of them are for special problems and relatively weak in theoretical foundations. Thus, it is unreliable to extend it directly to sparse unmixing. Here, we improve EDA on the basis of classification and propose a classification-based model for individual generating under the framework of SMoSU (CM-MoSU). In CM-MoSU, the whole population is divided to be positive and negative. Then, the macroinformation of positive individuals is used to guide the generation of new individuals. Therefore, the optimization task could pay more attention to the feasible space with high quality. Moreover, some theoretical analyses are presented to prove the reliability of CM-MoSU. In experiments, several state-of-the-art sparse unmixing algorithms are compared. Both synthetic and real-world experiments demonstrate the effectiveness of CM-MoSU.","Optimization,Libraries,Hyperspectral imaging,Reliability,Sociology,Statistics,Classification model,hyperspectral images,multi-objective,sparse unmixing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Geochemistry & Geophysics,Engineering,Remote Sensing,Imaging Science & Photographic Technology",,6.086,"ALGORITHM,VARIABILITY,INFORMATION,REGRESSION,NMF",IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,,
68,Machine-Learning-Based Predictive Modeling of Glass Transition Temperatures: A Case of Polyhydroxyalkanoate Homopolymers and Copolymers,59,12,5013-5025,"Pilania Ghanshyam,Iverson Carl N.,Lookman Turab,Marrone Babetta L.","Pilania G,Iverson CN,Lookman T,Marrone BL",Pilania G,10.1021/acs.jcim.9b00807,United States Department of Energy (DOE),"Polyhydroxyalkanoate-based polymers-being ecofriendly, biosynthesizable, and economically viable and possessing a broad range of tunable properties-are currently being actively pursued as promising alternatives for petroleum-based plastics. The vast chemical complexity accessible within this class of polymers gives rise to challenges in the rational discovery of novel polymer chemistries for specific applications. The burgeoning field of polymer informatics addresses this challenge via providing tools and strategies for accelerated property prediction and materials design via surrogate machine-learning models built on reliable past data. In this contribution, we use glass transition temperature T-g as an example target property to demonstrate promise of the data-enabled route to accelerated learning of accurate structure-property mappings in PHA-based polymers. Our analysis uses a data set of experimentally measured T-g values, polymer molecular weights, and a polydispersity index for PHA-based homo- and copolymers that was carefully assembled from the literature. A fingerprinting scheme that captures key properties based on topology, shape, and charge/polarity of specific chemical units or motifs forming the polymer backbone was devised to numerically represent the polymers. A validated statistical learning model is then developed to allow for a mapping of the polymer fingerprints onto the property space in a physically meaningful and reliable manner. Once developed, the model can not only rapidly predict the property of new PHA polymers but also provide uncertainties underlying the predictions. The model is further combined with an evolutionary-algorithm-based search strategy to efficiently identify multicomponent polymer compositions with a prespecified T-g. While the present contribution is focused specifically on T-g, the surrogate model development approach put forward here is general and can, in principle, be extended to a range of other properties.","MICROBIAL SYNTHESIS,PSEUDOMONAS-PUTIDA,BEARING PHENYL,BIOSYNTHESIS,POLYMERS,MONOMER,POLY(3-HYDROXYBUTYRATE-CO-3-HYDROXYVALERATE),POLY(3-HYDROXYBUTYRATE),ALGORITHMS,MECHANICS",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Pharmacology & Pharmacy,Chemistry,Computer Science",,5.39,"MICROBIAL,SYNTHESIS,PSEUDOMONAS-PUTIDA,BEARING,PHENYL,BIOSYNTHESIS,POLYMERS,MONOMER,POLY%283-HYDROXYBUTYRATE-CO-3-HYDROXYVALERATE%29,POLY%283-HYDROXYBUTYRATE%29,ALGORITHMS,MECHANICS",JOURNAL OF CHEMICAL INFORMATION AND MODELING,https://www.osti.gov/biblio/1579702,
69,Inverse artificial neural network modeling for metamaterial unit cell synthesis,18,4,1388-1399,"Nanda Sambhudutta,Sahu Prasanna Kumar,Mishra Rabindra Kishore","Nanda S,Sahu PK,Mishra RK",Nanda S,10.1007/s10825-019-01371-x,National Institute of Technology (NIT System),"Inverse artificial neural network (IANN) modeling is used to synthesize a metamaterial unit cell. The ANN approach is best suited to capture the mapping relation between inputs and outputs given a training dataset. In this work, the IANN method is applied to synthesize a metamaterial unit cell for which the inverse model is ill conditioned. A perfectly trained ANN is capable of generating the input data for a desired set of outputs for a fixed set of synaptic weights. In this work, a prior knowledge based input with difference (PKI-D) method is used to perform the inverse mapping. Although the split-ring resonator (SRR) is widely used to realize metamaterials for different applications, no closed-form formula is available to determine its design parameters. The goal of this work is to determine the dimensions of a SRR for a desired frequency and permeability value. The work is carried out in two phases. In the first phase, the inverse model is developed to estimate a single design parameter, then in the second phase, a multiple-parameter estimation model is developed. The average error for the PKI-D model is found to be 0.059. Backpropagation is used to train (solve) the input vector for unknown parameters.","IANN,Metamaterial,SRR",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Engineering,Physics",,1.73,"OPTIMIZATION,DESIGN",JOURNAL OF COMPUTATIONAL ELECTRONICS,,
70,Extracting Customer Perceptions of Product Sustainability From Online Reviews,141,12,,"El Dehaibi Nasreddine,Goodman Noah D.,MacDonald Erin F.","El Dehaibi N,Goodman ND,MacDonald EF",El Dehaibi N,10.1115/1.4044522,Stanford University,"In order for a sustainable product to be successful in the market, designers must create products that are not only sustainable in reality but are also sustainable as perceived by the customer-and reality versus perception of sustainability can be quite different. This paper details a design method to identify perceptions of sustainable features (PerSFs) by collecting online reviews, manually annotating them using crowdsourced work, and processing the annotated review fragments with a natural language machine learning algorithm. We analyze all three pillars of sustainability-social, environmental, and economic-for positive and negative perceptions of product features of a French press coffee carafe. For social aspects, the results show that positive PerSFs are associated with intangible features, such as giving the product as a gift, while negative PerSFs are associated with tangible features perceived as unsafe, like sharp corners. For environmental aspects, positive PerSFs are associated with reliable materials like metal while negative PerSFs are associated with the use of plastic. For economic aspects, PerSFs mainly serve as a price constraint for designers to satisfy other customer perceptions. We also show that some crucial sustainability concerns related to environmental aspects, like energy and water consumption, did not have a significant impact on customer sentiment, thus demonstrating the anticipated gap in sustainability perceptions and the realities of sustainable design, as noted in previous literature. From these results, online reviews can enable designers to extract PerSFs for further design study and to create products that resonate with customers' sustainable values.","design automation,sustainable design,customer perceptions,online reviews",Article; Proceedings Paper,"ASME, TWO PARK AVE, NEW YORK, NY 10016-5990 USA",Engineering,,3.602,RISK,JOURNAL OF MECHANICAL DESIGN,,
71,Multi-Fidelity Physics-Constrained Neural Network and Its Application in Materials Modeling,141,12,,"Liu Dehao,Wang Yan","Liu DH,Wang Y",Wang Y,10.1115/1.4044400,University System of Georgia,"Training machine learning tools such as neural networks require the availability of sizable data, which can be difficult for engineering and scientific applications where experiments or simulations are expensive. In this work, a novel multi-fidelity physics-constrained neural network is proposed to reduce the required amount of training data, where physical knowledge is applied to constrain neural networks, and multi-fidelity networks are constructed to improve training efficiency. A low-cost low-fidelity physics-constrained neural network is used as the baseline model, whereas a limited amount of data from a high-fidelity physics-constrained neural network is used to train a second neural network to predict the difference between the two models. The proposed framework is demonstrated with two-dimensional heat transfer, phase transition, and dendritic growth problems, which are fundamental in materials modeling. Physics is described by partial differential equations. With the same set of training data, the prediction error of physics-constrained neural network can be one order of magnitude lower than that of the classical artificial neural network without physical constraints. The accuracy of the prediction is comparable to those from direct numerical solutions of equations.","machine learning,multi-fidelity model,physics-constrained neural networks,materials modeling,partial differential equations,computer-aided engineering,simulation-based design",Article,"ASME, TWO PARK AVE, NEW YORK, NY 10016-5990 USA",Engineering,,3.602,"BOUNDARY-VALUE-PROBLEMS,OPTIMIZATION,APPROACH,PRIOR,KNOWLEDGE,FUNCTION,APPROXIMATION,NUMERICAL-SOLUTION,SYSTEMS",JOURNAL OF MECHANICAL DESIGN,,
72,Design for Crashworthiness of Categorical Multimaterial Structures Using Cluster Analysis and Bayesian Optimization,141,12,,"Liu Kai,Wu Tong,Detwiler Duane,Panchal Jitesh H.,Tovar Andres","Liu K,Wu T,Detwiler D,Panchal JH,Tovar A",Liu K,10.1115/1.4044838,Purdue University System,"This work introduces a cluster-based structural optimization (CBSO) method for the design of categorical multimaterial structures subjected to crushing, dynamic loading. The proposed method consists of three steps: conceptual design generation, design clustering, and Bayesian optimization. In the first step, a conceptual design is generated using the hybrid cellular automaton (HCA) algorithm. In the second step, threshold-based cluster analysis yields a lower-dimensional design. Here, a cluster validity index for structural optimization is introduced in order to qualitatively evaluate the clustered design. In the third step, the optimal design is obtained through Bayesian optimization, minimizing a constrained expected improvement function. This function allows to impose soft constraints by properly redefining the expected improvement based on the maximum constraint violation. The Bayesian optimization algorithm implemented in this work has the ability to search over (i) a real design space for sizing optimization, (ii) a categorical design space for material selection, or (iii) a mixed design space for concurrent sizing optimization and material selection. With the proposed method, materials are optimally selected based on multiple attributes and multiple objectives without the need for material ranking. The effectiveness of this approach is demonstrated with the design for crashworthiness of multimaterial plates and thin-walled structures.","structural optimization,finite element-based optimization,Bayesian optimization,metamodel-based design,clustering,multimaterial structures,design optimization,metamodeling,multidisciplinary design and optimization",Article,"ASME, TWO PARK AVE, NEW YORK, NY 10016-5990 USA",Engineering,,3.602,"TOPOLOGY,OPTIMIZATION,SHAPE,OPTIMIZATION",JOURNAL OF MECHANICAL DESIGN,https://scholarworks.iupui.edu/bitstream/1805/23272/1/Liu2019Design.pdf,
73,Evaluation of Tensile Performance of Steel Members by Analysis of Corroded Steel Surface Using Deep Learning,9,12,,"Chun Pang-jo,Yamane Tatsuro,Izumi Shota,Kameda Toshihiro","Chun P,Yamane T,Izumi S,Kameda T",Chun P,10.3390/met9121259,University of Tokyo,"To conduct safety checks of corroded steel structures and formulate appropriate maintenance strategies, the residual strength of steel structural members must be assessed with high accuracy. Finite element method (FEM) analyses that precisely recreate the morphology of corroded surfaces using solid elements are expected to accurately assess the strength; however, the cost of conducting these calculations is extremely high. Therefore, a model that uses mean thickness as the thickness of the shell element is widely used but this method has precision issues, particularly regarding overestimation of risk. Thus, this study proposes a method of structural analysis in which the effective thickness of a shell element is assessed using the convolutional neural network (CNN), a type of deep learning performed on tensile structural members. An FEM model is then built based on the shell element that uses this effective thickness. We cross-validated this method by adding a feature extraction layer that reflects the domain knowledge, together with convolutional and pooling layers that are commonly used for CNN and found that a high level of accuracy could be achieved. Furthermore, regarding corroded steel plates and H-section steel, our method demonstrated results that were extremely close to those of models that used solid elements.","corrosion,residual strength,deep learning,convolutional neural network,CNN,finite element analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Materials Science,Metallurgy & Metallurgical Engineering",,2.487,"RESIDUAL,STRENGTH,CORROSION,PLATES,DEGRADATION",METALS,https://www.mdpi.com/2075-4701/9/12/1259/pdf,
74,Hybrid Machine Learning Optimization Approach to Predict Hot Deformation Behavior of Medium Carbon Steel Material,9,12,,"Murugesan Mohanraj,Sajjad Muhammad,Jung Dong Won","Murugesan M,Sajjad M,Jung DW",Jung DW,10.3390/met9121315,Jeju National University,"The isothermal tensile test of medium carbon steel material was conducted at deformation temperatures varying from 650 to 950 degrees C with an interval of 100 degrees C and strain rates ranging from 0.05 to 1.0 s(-1). In addition, the scanning electron microscopy (SEM) procedures were exploited to study about the surface morphology of medium carbon steel material. Using the experimental data, the artificial neural network (ANN) model with a back-propagation (BP) algorithm was proposed to predict the hot deformation behavior of medium carbon steel material. For model training and testing purpose, the variables such as deformation temperature, strain rate, and strain data were considered as inputs and the flow stress data were used as targets. Before running the neural network, the test data were normalized to effectively run the problem and after solving the problem, the obtained results were again converted in order to achieve the actual data. According to the predicted results, the coefficient of determination (R-2) and the average absolute relative error between the predicted flow stress and the experimental data were determined as 0.999 and 1.335%, respectively. For improving the model predictability, the constrained nonlinear function based optimization procedures was adopted to obtain the best candidate selections of weights and biases. By evaluating each test conditions, it was found that the average absolute relative error based on the optimized ANN-BP model varied from 0.728% to 1.775%. Overall, the trained ANN-BP models proved to be much more efficient and accurate by means of flow stress prediction against the experimental data for all the tested conditions. These optimized results displayed that an ANN-BP model is more accurate for flow stress prediction than that of the conventional flow stress models.","isothermal tensile test,medium carbon steel,surface morphology,neural network,back-propagation,flow stress",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Materials Science,Metallurgy & Metallurgical Engineering",,2.487,"ARTIFICIAL,NEURAL-NETWORK,MODIFIED,JOHNSON-COOK,MODIFIED,ZERILLI-ARMSTRONG,TEMPERATURE,FLOW,BEHAVIOR,ARRHENIUS-TYPE,CONSTITUTIVE,RELATIONSHIP,TITANIUM-ALLOY,STRESS,STRAIN,MODEL",METALS,https://www.mdpi.com/2075-4701/9/12/1315/pdf,
75,Prediction of Central Carbon Segregation in Continuous Casting Billet Using A Regularized Extreme Learning Machine Model,9,12,,"Zou Leilei,Zhang Jiangshan,Liu Qing,Zeng Fanzheng,Chen Jun,Guan Min","Zou LL,Zhang JS,Liu Q,Zeng FZ,Chen J,Guan M",Zhang JS; Liu Q,10.3390/met9121312,University of Science & Technology Beijing,"Central carbon segregation is a typical internal defect of continuous cast steel billets. Real-time and accurate carbon segregation prediction is of great significance for lean control of the production quality in continuous casting processes. In this paper, a data-driven regularized extreme learning machine (R-ELM) model is proposed for the prediction of carbon segregation index (CSI). To improve model performance, outliers in industrial data were eliminated by means of boxplot tool. Besides, Pearson correlation combined with grey relational analysis (GRA) was conducted to avoid multicollinearity and redundancy in input variables. The new model shows potential to evaluate online quality of steel billets. When predictive errors were within +/- 0.03 and +/- 0.025, the prediction accuracy of the R-ELM model was 94% and 89%, respectively, which was higher than that of the multiple linear regression (MLR) model and ELM model. Moreover, the effects of several key continuous casting process parameters on CSI were investigated based on the predictions of the R-ELM model via response surface analysis. The conclusions are consistent with the metallurgical mechanism, and the predictive values of the R-ELM model agree well with experimental values, which further verifies the correctness and generalization ability of the R-ELM model.","continuous casting,central carbon segregation,data preprocessing,prediction model,regularized ELM",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Materials Science,Metallurgy & Metallurgical Engineering",,2.487,"CENTERLINE,SEGREGATION,STEEL,SLABS,MACROSEGREGATION,STRATEGY",METALS,https://www.mdpi.com/2075-4701/9/12/1312/pdf,
76,Retinal blood vessel segmentation from diabetic retinopathy images using tandem PCNN model and deep learning based SVM,199,,,"Jebaseeli T. Jemima,Durai C. Anand Deva,Peter J. Dinesh","Jebaseeli TJ,Durai CAD,Peter JD",Jebaseeli TJ,10.1016/j.ijleo.2019.163328,Karunya Institute of Technology & Sciences,"Diabetic Retinopathy (DR) occurs due to Type-II diabetes. It causes damages to the retinal blood vessels and reason for visual impairment. The predicted center is around the probability of variation in the estimation of retinal veins, and the crisp enrolls vessel development inside the retina. To witness the changes segmentation of retinal blood vessels has to be made. A framework to upgrade the quality of the segmentation results over morbid retinal images is proposed. This framework utilizes Contrast Limited Adaptive Histogram Equalization (CLAHE) for eliminating the background from the source image and enhances the foreground blood vessel pixels, Tandem Pulse Coupled Neural Network (TPCNN) model is endorsed for automatic feature vectors generation, and Deep Learning Based Support Vector Machine (DLBSVM) is proposed for classification and extraction of blood vessels. The DLBSVM parameters are fine-tuned via Firefly algorithm. The STARE, DRIVE, HRF, REVIEW, and DRIONS fundus image datasets are deliberated to assess the recommended techniques. The results render that the proposed technologies improve the segmentation with 80.61% Sensitivity, 99.54% Specificity, and 99.49% Accuracy.","Image segmentation,Blood vessel,Diabetic retinopathy,Neural network,Support vector machine,Fundus image,Feature extraction,Deep learning",Article,"ELSEVIER GMBH, HACKERBRUCKE 6, 80335 MUNICH, GERMANY",Optics,,1.955,ALGORITHM,OPTIK,,
77,A Proof of Concept Study of Using Machine-Learning in Artificial Aortic Valve Design: From Leaflet Design to Stress Analysis.,6,4,,",","Liang Liang,Sun Bill",,10.3390/bioengineering6040104,,,artificial heart valve; deep neural network; finite element analysis; machine learning; transcatheter aortic valve,Journal Article,,,,,,,,
78,Deep Encoder-Decoder Adversarial Reconstruction(DEAR) Network for 3D CT from Few-View Data.,6,4,,",,","Xie Huidong,Shan Hongming,Wang Ge",,10.3390/bioengineering6040111,,"X-ray computed tomography (CT) is widely used in clinical practice. The involved ionizingX-ray radiation, however, could increase cancer risk. Hence, the reduction of the radiation dosehas been an important topic in recent years. Few-view CT image reconstruction is one of the mainways to minimize radiation dose and potentially allow a stationary CT architecture. In this paper,we propose a deep encoder-decoder adversarial reconstruction (DEAR) network for 3D CT imagereconstruction from few-view data. Since the artifacts caused by few-view reconstruction appear in3D instead of 2D geometry, a 3D deep network has a great potential for improving the image qualityin a data driven fashion. More specifically, our proposed DEAR-3D network aims at reconstructing3D volume directly from clinical 3D spiral cone-beam image data. DEAR is validated on a publiclyavailable abdominal CT dataset prepared and authorized by Mayo Clinic. Compared with other2D deep learning methods, the proposed DEAR-3D network can utilize 3D information to producepromising reconstruction results.",deep encoder-decoder adversarial network (DEAR); deep learning; few-view CT; generative adversarial network (GAN); machine learning; sparse-view CT,Journal Article,,,,,,,,
79,A dual-stream deep convolutional network for reducing metal streak artifacts in CT images,64,23,,"Gjesteby Lars,Shan Hongming,Yang Qingsong,Xi Yan,Jin Yannan,Giantsoudi Drosoula,Paganetti Harald,De Man Bruno,Wang Ge","Gjesteby L,Shan HM,Yang QS,Xi Y,Jin YN,Giantsoudi D,Paganetti H,De Man B,Wang G",Wang G,10.1088/1361-6560/ab4e3e,Rensselaer Polytechnic Institute,"Machine learning and deep learning are rapidly finding applications in the medical imaging field. In this paper, we address the long-standing problem of metal artifacts in computed tomography (CT) images by training a dual-stream deep convolutional neural network for streak removal. While many metal artifact reduction methods exist, even state-of-the-art algorithms fall short in some clinical applications. Specifically, proton therapy planning requires high image quality with accurate tumor volumes to ensure treatment success. We explore a dual-stream deep network structure with residual learning to correct metal streak artifacts after a first-pass by a state-of-the-art interpolation-based algorithm, NMAR. We provide the network with a mask of the streaks in order to focus attention on those areas. Our experiments compare a mean squared error loss function with a perceptual loss function to emphasize preservation of image features and texture. Both visual and quantitative metrics are used to assess the resulting image quality for metal implant cases. Success may be due to the duality of information processing, with one network stream performing local structure correction, while the other stream provides an attention mechanism to destreak effectively. This study shows that image-domain deep learning can be highly effective for metal artifact reduction (MAR), and highlights the benefits and drawbacks of different loss functions for solving a major CT reconstruction challenge.","x-ray computed tomography,machine learning,metal artifact reduction,proton therapy,deep learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"LOW-DOSE,CT,COMPUTED-TOMOGRAPHY,REDUCTION,RECONSTRUCTION,PROJECTIONS",PHYSICS IN MEDICINE AND BIOLOGY,,
80,Research on Gesture Recognition of sEMG Based on Deep Neural Network,55,23,113-119,",","Zhang Longjiao,Zeng Xiaoqin",,,Zhang Longjiao,"In order to improve the accuracy of sEMG gesture recognition algorithm and solve the limitation caused by extracting a large number of features artificially, this paper proposes a gesture recognition method based on deep neural network. Firstly, it uses an active segment segmentation method on 8 channel sEMG data which is collected by MYO armband to detect effective actions. Then, it designs a neural network which combines Convolutional Neural Network(CNN) and Long-Short Term Memory network(LSTM). The result shows that the accuracy of gesture recognition reaches 91.6% and the proposed method is proved to be efficient and feasible.",sEMG; gesture recognition; MYO armband; convolution neural network,Article,,,,,,,,
81,Low-Dose CT Restoration Based on CNN in NSST Domain,55,23,209-215,",,","Liu Yi,Gao Jingzhi,Gui Zhiguo",,,Liu Yi,"In order to solve the noise/artifact problem in Low-Dose Computed Tomography(LDCT) images, a Convolution Neural Network(CNN) based on Non-Sample Shearlet Transformation(NSST), NSST-CNN model, is proposed in this paper. During training, NSST decomposition is performed on Normal-Dose Computed Tomography(NDCT) and LDCT images in the data set. The high-frequency sub-images of LDCT are used as the input, and the residual images of the high-frequency sub-images of NDCT and LDCT are used as the label. The mapping relationship between sub-images of LDCT and high-frequency sub-images of the residual images is then learned through CNN training. When testing, the high-frequency sub-images of LDCT are subtracted from the trained noise/artifact and the inverse NSST transform is performed to obtain a high-quality LDCT image. Experimental results show that NSST-CNN achieves a better balance between suppressing artifacts/noise and protecting structural details than KSVD, BM3D, and image space CNN method.",low-dose Computed Tomography(CT); image restoration; non-sample Shearlet transformation; convolutional neural network; residual learning,Article,,,,,,,,
82,Pterygium-Net: a deep learning approach to pterygium detection and localization,78,24,34563-34584,"Zulkifley Mohd Asyraf,Abdani Siti Raihanah,Zulkifley Nuraisyah Hani","Zulkifley MA,Abdani SR,Zulkifley NH",Zulkifley MA,10.1007/s11042-019-08130-x,Universiti Kebangsaan Malaysia,"Automatic pterygium detection is an essential screening tool for health community service groups. It allows non-expert to perform screening process without the needs of big and expensive equipment, especially for the application in rural areas. Thence, patients who have been screened as positive pterygium will be referred to the certified medical personnel for further diagnosis and treatment. Current state-of-the-art algorithms for pterygium detection rely on basic machine learning approach such as artificial neural network and support vector machine, which have not yet achieved high detection sensitivity and specificity as required in standard medical practice. Hence, a deep learning approach based on fully convolutional neural networks is proposed to detect and localize the pterygium infected tissues automatically. The input image requirement for the developed system is low as any commercial mobile phone camera is sufficient. Moreover, the developed algorithm, which we refer as Pterygium-Net works well even if the eye image is captured under low lighting condition with pupil position is not at the center location. Pterygium-Net utilizes three layers of convolutional neural networks (CNN) and three layers of fully connected networks. Two steps are implemented to overcome lacks of training data by generating synthetic images and pre-training the CNN weights and biases in a different public dataset. As for pterygium localization, an additional step of box proposal based on edges information is used to generate possible regions of the pterygium infected tissues. Hanning window is also applied to the generated regions to give more weightage to the center area. Experimental results show that Pterygium-Net produces high average detection sensitivity and specificity of 0.95 and 0.983, respectively. As for pterygium tissues localization, the algorithm achieves 0.811 accuracy with a very low failure rate of 0.053. In the future, deeper networks can be implemented to further improve pterygium localization.","Pterygium detection,Pterygium localization,Machine learning",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,,MULTIMEDIA TOOLS AND APPLICATIONS,,
83,MACHINE-LEARNING ALGORITHM FOR SHIELDED SPECIAL NUCLEAR MATERIALS DETECTION,8,2,145-157,"Masala Eugene,Blomeley Laura","Masala E,Blomeley L",Blomeley L,10.12943/CNR.2018.00004,Atomic Energy of Canada Limited,"A machine-learning algorithm has been implemented by use of a neural network as a preliminary study on the applicability of this method to special nuclear materials detection. The algorithm predicts the presence of the U-238 isotope when learning from a gamma spectrum data measured with a high-purity germanium detector from a sample of depleted uranium. In this work, both a fully connected neural network and a convolutional neural network have been implemented, and the performance of different configurations of the network has been studied. The use of convolutional network showed better performance over the fully connected network, with cost function and success rate values supporting a better prediction while avoiding overfitting. Furthermore, implemented network features such as filtering, max-pooling, dropout regularization, and momentum optimization also showed improved prediction performance.","Neural network,radioisotope identification,shielded source detection",Article,"CANADIAN NUCLEAR LABORATORIES, CHALK RIVER LABORATORIES, CHALK RIVER, ON K0J 1J0, CANADA",Nuclear Science & Technology,,,NEURAL-NETWORKS,CNL NUCLEAR REVIEW,https://doi.org/10.12943/cnr.2018.00004,
84,Statistical-Hypothesis-Aided Tests for Epilepsy Classification,8,4,,"Alqatawneh Alaa,Alhalaseh Rania,Hassanat Ahmad,Abbadi Mohammad","Alqatawneh A,Alhalaseh R,Hassanat A,Abbadi M",Alhalaseh R,10.3390/computers8040084,Mutah University,"In this paper, an efficient, accurate, and nonparametric epilepsy detection and classification approach based on electroencephalogram (EEG) signals is proposed. The proposed approach mainly depends on a feature extraction process that is conducted using a set of statistical tests. Among the many existing tests, those fit with processed data and for the purpose of the proposed approach were used. From each test, various output scalars were extracted and used as features in the proposed detection and classification task. Experiments that were conducted on the basis of a Bonn University dataset showed that the proposed approach had very accurate results (98.4%) in the detection task and outperformed state-of-the-art methods in a similar task on the same dataset. The proposed approach also had accurate results (94.0%) in the classification task, but it did not outperform state-of-the-art methods in a similar task on the same dataset. However, the proposed approach had less time complexity in comparison with those methods that achieved better results.","biomedical signal processing,electromyography,multiple-signal processing,EEG,machine learning,epilepsy",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"FUZZY,INFERENCE,SYSTEM,SEIZURE,DETECTION,EEG,CONNECTIVITY,PREDICTION",COMPUTERS,https://res.mdpi.com/d_attachment/computers/computers-08-00084/article_deploy/computers-08-00084-v2.pdf,
85,Comparative Machine-Learning Approach: A Follow-Up Study on Type 2 Diabetes Predictions by Cross-Validation Methods,7,4,,"Battineni Gopi,Sagaro Getu Gamo,Nalini Chintalapudi,Amenta Francesco,Tayebati Seyed Khosrow","Battineni G,Sagaro GG,Nalini C,Amenta F,Tayebati SK",Battineni G,10.3390/machines7040074,University of Camerino,"(1) Background: Diabetes is a common chronic disease and a leading cause of death. Early diagnosis gives patients with diabetes the opportunity to improve their dietary habits and lifestyle and manage the disease successfully. Several studies have explored the use of machine learning (ML) techniques to predict and diagnose this disease. In this study, we conducted experiments to predict diabetes in Pima Indian females with particular ML classifiers. (2) Method: A Pima Indian diabetes dataset (PIDD) with 768 female patients was considered for this study. Different data mining operations were performed to a conduct comparative analysis of four different ML classifiers: Naive Bayes (NB), J48, Logistic Regression (LR), and Random Forest (RF). These models were analyzed by different cross-validation (K = 5, 10, 15, and 20) values, and the performance measurements of accuracy, precision, F-score, recall, and AUC were calculated for each model. (3) Results: LR was found to have the highest accuracy (0.77) for all 'k' values. When k = 5, the accuracy of J48, NB, and RF was found to be 0.71, 0.76, and 0.75. For k = 10, the accuracy of J48, NB, and RF was found to be 0.73, 0.76, 0.74, while for k = 15, 20, the accuracy of NB was found to be 0.76. The accuracy of J48 and RF was found to be 0.76 when k = 15, and 0.75 when k = 20. Other parameters, such as precision, f-score, recall, and AUC, were also considered in evaluations to rank the algorithms. (4) Conclusion: The present study on PIDD sought to identify an optimized ML model, using with cross-validation methods. The AUC of LR was 0.83, RF 0.82, and NB 0.81). These three were ranked as the best models for predicting whether a patient is diabetic or not.","diabetes,PIDD,accuracy,model validation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Engineering,,2.467,,MACHINES,https://www.mdpi.com/2075-1702/7/4/74/pdf,
86,Computed Tomography-Based Radiomic Features Could Potentially Predict Microsatellite Instability Status in Stage II Colorectal Cancer: A Preliminary Study,26,12,1633-1640,"Fan Shuxuan,Li Xubin,Cui Xiaonan,Zheng Lei,Ren Xiaoyi,Ma Wenjuan,Ye Zhaoxiang","Fan SX,Li XB,Cui XN,Zheng L,Ren XY,Ma WJ,Ye ZX",Ma WJ; Ye ZX,10.1016/j.acra.2019.02.009,Tianjin Medical University,"Rationale and Objectives: To investigate whether quantitative radiomics features extracted from computed tomography (CT) can predict microsatellite instability (MSI) status in an Asian cohort of patients with stage II colorectal cancer (CRC).
Materials and Methods: This retrospective study was approved by our institutional review board, and the informed consent requirement was waived. From March 2016 to March 2018, 119 Chinese patients with pathologically confirmed stage II CRC, available MSI status, and preoperative contrast-enhanced CT images were included in this study. Clinical and pathological information was obtained from the institutional database. The radiomics features were extracted from portal venous-phase CT images of segmented volumes of each entire primary tumor by using Matrix Laboratory (MATLAB), and radiomics signatures were generated using the least absolute shrinkage and selection operator logistic regression model. The minority group was balanced via synthetic minority over-sampling technique method. The association between the clinicopathologic characteristics and MSI status was assessed using Student's t test, Chi-square, or Fisher's exact test. The predictive efficacy of MSI status using radiomics features, clinical factors (including age, gender, CT-reported tumor location, differentiation degree of tumor, smoking history, hypertension history, family history of cancer, diabetes history, level of the Ki-67 expression, and laboratory analysis) and the combined models were evaluated, respectively. Predictive performance was evaluated by the area under receiver operating characteristic curve, accuracy, sensitivity, and specificity.
Results: MSI status was significantly associated with tumor location (p = 0.043); differentiation degree of tumor (p < 0.0001), hypertension history (p = 0.012), and the level of the Ki-67 expression (p = 0.015). Six radiomics features and 11 clinical characteristics were selected for predicting MSI status. The model that used the combination of clinical factors and radiomics features achieved the overall best performance than using either of the two features alone, yielding the area under the curve, sensitivity, and specificity of 0.752, 0.663, 0.841 for the combined model, 0.598, 0.371, 0.825 for clinical factors alone, and 0.688, 0.517, 0.858 for radiomics features alone, respectively.
Conclusion: CT-based radiomic features of stage II CRC are associated with MSI status. Combining analysis of clinical features and CT features could improve predictive efficacy and could potentially select the patients for individualized therapy noninvasively.","Colorectal cancer,Computed tomography,Microsatellite instability,Radiomics,Machine learning,ROC curve",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.751,"COLON-CANCER,MISMATCH,REPAIR,BIOMARKERS",ACADEMIC RADIOLOGY,,
87,Machine Learning for Automatic Paraspinous Muscle Area and Attenuation Measures on Low-Dose Chest CT Scans,26,12,1686-1694,"Barnard Ryan,Tan Josh,Roller Brandon,Chiles Caroline,Weaver Ashley A.,Boutin Robert D.,Kritchevsky Stephen B.,Lenchik Leon","Barnard R,Tan J,Roller B,Chiles C,Weaver AA,Boutin RD,Kritchevsky SB,Lenchik L",Lenchik L,10.1016/j.acra.2019.06.017,Wake Forest University,"Rationale and Objectives: To develop and evaluate an automated machine learning (ML) algorithm for segmenting the paraspinous muscles on chest computed tomography (CT) scans to evaluate for presence of sarcopenia.
Materials and Methods: A convolutional neural network based on the U-Net architecture was trained to perform muscle segmentation on a dataset of 1875 single slice CT images and was tested on 209 CT images of participants in the National Lung Screening Trial. Low-dose, noncontrast CT examinations were obtained at 33 clinical sites, using scanners from four manufacturers. The study participants had a mean age of 71.6 years (range, 70-74 years). Ground truth was obtained by manually segmenting the left paraspinous muscle at the level of the T12 vertebra. Muscle cross-sectional area (CSA) and muscle attenuation (MA) were recorded. Comparison between the ML algorithm and ground truth measures of muscle CSA and MA were obtained using Dice similarity coefficients and Pearson correlations.
Results: Compared to ground truth segmentation, the ML algorithm achieved median (standard deviation) Dice scores of 0.94 (0.04) in the test set. Mean (SD) muscle CSA was 14.3 (3.6) cm(2) for ground truth and 13.7 (3.5) cm(2) for ML segmentation. Mean (SD) MA was 41.6 (7.6) Hounsfield units (HU) for ground truth and 43.5 (7.9) HU for ML segmentation. There was high correlation between ML algorithm and ground truth for muscle CSA (r(2) = 0.86; p < 0.0001) and MA (r(2) = 0.95; p < 0.0001).
Conclusion: The ML algorithm for measurement of paraspinous muscles compared favorably to manual ground truth measurements in the NLST. The algorithm generalized well to a heterogeneous set of low-dose CT images and may be capable of automated quantification of muscle metrics to screen for sarcopenia on routine chest CT examinations.","Muscle,Sarcopenia,Myosteatosis,Chest CT,Machine learning",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.751,"COMPUTED-TOMOGRAPHY,SKELETAL-MUSCLE,OLDER-ADULTS,SARCOPENIA,SEGMENTATION,MORTALITY,IMPACT,COMPLICATIONS,METAANALYSIS,PREDICTOR",ACADEMIC RADIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6878160,
88,Automated Segmentation of Tissues Using CT and MRI: A Systematic Review,26,12,1695-1704,"Lenchik Leon,Heacock Laura,Weaver Ashley A.,Boutin Robert D.,Cook Tessa S.,Itri Jason,Filippi Christopher G.,Gullapalli Rao P.,Lee James,Zagurovskaya Marianna","Lenchik L,Heacock L,Weaver AA,Boutin RD,Cook TS,Itri J,Filippi CG,Gullapalli RP,Lee J,Zagurovskaya M",Lenchik L,10.1016/j.acra.2019.07.006,Wake Forest University,"Rationale and Objectives: The automated segmentation of organs and tissues throughout the body using computed tomography and magnetic resonance imaging has been rapidly increasing. Research into many medical conditions has benefited greatly from these approaches by allowing the development of more rapid and reproducible quantitative imaging markers. These markers have been used to help diagnose disease, determine prognosis, select patients for therapy, and follow responses to therapy. Because some of these tools are now transitioning from research environments to clinical practice, it is important for radiologists to become familiar with various methods used for automated segmentation.
Materials and Methods: The Radiology Research Alliance of the Association of University Radiologists convened an Automated Segmentation Task Force to conduct a systematic review of the peer-reviewed literature on this topic.
Results: The systematic review presented here includes 408 studies and discusses various approaches to automated segmentation using computed tomography and magnetic resonance imaging for neurologic, thoracic, abdominal, musculoskeletal, and breast imaging applications.
Conclusion: These insights should help prepare radiologists to better evaluate automated segmentation tools and apply them not only to research, but eventually to clinical practice.","Segmentation,Machine leaming,Quantitative imaging,CT,MRI",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.751,"OF-THE-ART,MAGNETIC-RESONANCE,COMPUTED-TOMOGRAPHY,SHAPE,MODELS,BREAST,IMAGES,MUSCLE,MACHINE,FAT,LOCALIZATION",ACADEMIC RADIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6878163,
89,Simultaneously Achieving High Activity and Selectivity toward Two-Electron O-2 Electroreduction: The Power of Single-Atom Catalysts,9,12,11042-11054,"Guo Xiangyu,Lin Shiru,Gu Jinxing,Zhang Shengli,Chen Zhongfang,Huang Shiping","Guo XY,Lin SR,Gu JX,Zhang SL,Chen ZF,Huang SP",Huang SP,10.1021/acscatal.9b02778,Beijing University of Chemical Technology,"On-site production of hydrogen peroxide (H2O2) using electrochemical methods could be more efficient than the current industrial process. However, due to the existence of scaling relations for the adsorption of reaction intermediates, there is a long established trade-off between the activity and selectivity of the catalysts, as the enhancement of catalytic activity is typically accompanied by a four-electron O-2 reduction reaction (ORR), leading to the reduced selectivity for the H2O2 production. Herein, by means of density functional theory (DFT) computations, we reported the feasibility of several classes of important and representative experimentally achievable single-atom catalysts (SACs) toward two-electron ORR, paying attention to their stability, selectivity, and activity at the acidic medium. Starting from 210 two-dimensional (2D) SACs, we demonstrated that 31 SACs have the potential to break the metal-based scaling relations and simultaneously achieve high activity and selectivity toward H2O2 production and screened out 7 SACs with higher activity than the PtHg4 in acidic media. Especially, a noble metal-free SAC, namely, a single Zn atom centered phthalocyanine (Zn@Pc-N-4), has a remarkable activity improvement with a small overpotential of 0.15 V. Moreover, using multivariable analysis and machine-learning techniques, we provided a comprehensive understanding of the underlying origin of the selectivity and activity of SACs and unveiled the intrinsic correlations between structure and catalytic performance. This work may pave a way to the design and discovery of more promising materials for H2O2 production.","single-atom catalysts,two-dimensional materials,oxygen reduction reaction,H2O2 production,density functional theory calculations,machine learning",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,13.721,"HYDROGEN-PEROXIDE,SYNTHESIS,OXYGEN,REDUCTION,PALLADIUM,CATALYSTS,ALLOY,CATALYSTS,RATIONAL,DESIGN,H2O2,PD,NITRIDE,EVOLUTION,ELECTROCATALYSIS",ACS CATALYSIS,,
90,Machine Learning for Accelerated Discovery of Solar Photocatalysts,9,12,11774-11787,"Masood Hassan,Toe Cui Ying,Teoh Wey Yang,Sethu Vidhyasaharan,Amal Rose","Masood H,Toe CY,Teoh WY,Sethu V,Amal R",Amal R,10.1021/acscatal.9b02531,University of New South Wales Sydney,"Robust screening of materials on the basis of structure-property-activity relationships to discover active photocatalysts is a highly sought out aspect of photocatalysis research. Recent advancements in machine learning offer considerable opportunities to evolve photocatalysts discovery practices. Machine learning has largely facilitated various areas of science and engineering, including heterogeneous catalysis, but adaptation of it in photocatalysis research is still at an elementary stage. The scarcity of consistent training data is a major bottleneck, and we foresee the integration of photo-catalysis domain knowledge in mainstream machine learning protocols as a viable solution. Here, we present a holistic framework incorporating machine learning and domain knowledge to set directions toward accelerated discovery of solar photocatalysts. This Perspective begins with a discussion on domain knowledge available in photocatalysis which could potentially be leveraged to liaise with machine learning methods. Subsequently, we present prevalent machine learning practices in heterogeneous catalysis tailored to assist discovery of photocatalysts in a purely data-driven fashion. Lastly, we conceptualize various strategies for complementing data-driven machine learning with photocatalysis domain knowledge. The strategies involve the following: (i) integration of theoretical and prior empirical knowledge during the training of machine learning models; (ii) embedding the knowledge in feature space; and (iii) utilizing existing material databases to constrain machine learning predictions. The aforementioned human-in-loop framework (leveraging both human and machine intelligence) could possibly mitigate the lack of interpretability and reliability associated with data-driven machine learning and reinforce complex model architectures irrespective of data scarcity. The concept could also offer substantial benefits to photocatalysis informatics by promoting a paradigm shift away from the Edisonian approach.","photocatalysis,machine learning,domain knowledge,photocatalyst discovery,high-throughput,database",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,13.721,"ARTIFICIAL,NEURAL-NETWORK,ELECTRON-DIFFUSION,LENGTH,HYDROGEN-PRODUCTION,HETEROGENEOUS,PHOTOCATALYSIS,ELECTROCHEMICAL,SYNTHESIS,COMBINATORIAL,DISCOVERY,CHARGE,SEPARATION,REDUCTION,EVOLUTION,CATALYSIS",ACS CATALYSIS,,
91,Femtosecond laser helical drilling of nickel-base single-crystal super-alloy: Effect of machining parameters on geometrical characteristics of micro-holes,14,4,407-420,"Yin C. P.,Wu Z. P.,Dong Y. W.,You Y. C.,Liao T.","Yin CP,Wu ZP,Dong YW,You YC,Liao T",Dong YW,10.14743/apem2019.4.337,Xiamen University,"Laser micro-hole processing has been widely used in industry. Many laser processing parameters can affect the processing results. The relationship between the geometrical shapes of micro-holes and the laser processing parameters has not been determined accurately. In this paper, experiments on the femtosecond laser drilling of the nickel-base single-crystal super-alloy (DD6) materials were conducted to determine the relationship between the parameters, such as the laser single-pulse energy, rotation rate, and downward focus rate, and the geometrical characteristics of the micro-holes, such as the diameter, and roundness. A group of orthogonal experiments were conducted to determine the effects of the comprehensive influencing factors on the geometrical characteristics of the micro-holes. After the experiments were conducted and analysed, the experimental results were modelled by a backpropagation neural network, and the mapping relationship between the laser parameters and the geometrical morphologies of the micro-holes was constructed. The model established by the backpropagation neural network could obtain accurate prediction results, and the predictions of the diameters of the micro-holes were better than those of the roundness. (C) 2019 CPE, University of Maribor. All rights reserved.","Femtosecond laser,Micro-hole machining,Helical drilling,Nickel-base single-crystal super-alloy (DD6),Orthogonal experiment,Artificial neural networks (ANN)",Article,"UNIV MARIBOR, FAC MECHANICAL ENGINEERING, SMETANOVA ULICA 17, MARIBOR, SI-2000, SLOVENIA","Engineering,Materials Science",,2.675,"OPTIMIZATION,ABLATION",ADVANCES IN PRODUCTION ENGINEERING & MANAGEMENT,http://apem-journal.org/Archives/2019/Abstract-APEM14-4_407-420.pdf,
92,Volumetry of Mesiotemporal Structures Reflects Serostatus in Patients with Limbic Encephalitis,40,12,2081-2089,"Ernst L.,David B.,Gaubatz J.,Dominguez-Narciso I.,Luechters G.,Becker A. J.,Weber B.,Hattingen E.,Elger C. E.,Rueber T.","Ernst L,David B,Gaubatz J,Dominguez-Narciso I,Luchters G,Becker AJ,Weber B,Hattingen E,Elger CE,Ruber T",Ruber T,10.3174/ajnr.A6289,University of Bonn,"BACKGROUND AND PURPOSE: Limbic encephalitis is an autoimmune disease. A variety of autoantibodies have been associated with different subtypes of limbic encephalitis, whereas its MR imaging signature is uniformly characterized by mesiotemporal abnormalities across subtypes. Here, we hypothesized that patients with limbic encephalitis would show subtype-specific mesiotemporal structural correlates, which could be classified by supervised machine learning on an individual level. MATERIALS AND METHODS: T1WI MPRAGE scans from 46 patients with antibodies against glutamic acid decarboxylase and 34 patients with antibodies against the voltage-gated potassium channel complex (including 10 patients with leucine-rich glioma-inactivated 1 autoantibodies) and 48 healthy controls were retrospectively ascertained. Parcellation of the amygdala, hippocampus, and hippocampal subfields was performed using FreeSurfer. Volumes were extracted and compared between groups using unpaired, 2-tailed t tests. The volumes of hippocampal subfields were analyzed using a multivariate linear model and a binary decision tree classifier. RESULTS: Temporomesial volume alterations were most pronounced in an early stage and in the affected hemispheric side of patients. Statistical analysis revealed antibody-specific hippocampal fingerprints with a higher volume of CA1 in patients with glutamic acid decarboxylase?associated limbic encephalitis (P?=?.02), compared with controls, whereas CA1 did not differ from that in controls in patients with voltage-gated potassium channel complex autoantibodies. The classifier could successfully distinguish between patients with autoantibodies against leucine-rich glioma-inactivated 1 and glutamic acid decarboxylase with a specificity of 87% and a sensitivity of 80%. CONCLUSIONS: Our results suggest stage-, side- and antibody-specific structural correlates of limbic encephalitis; thus, they create a perspective toward an MR imaging?based diagnosis.","GLUTAMIC-ACID DECARBOXYLASE,TEMPORAL-LOBE EPILEPSY,SELECTIVE VULNERABILITY,AUTOIMMUNE ENCEPHALITIS,HIPPOCAMPAL DAMAGE,LEUCINE-RICH,CA1 NEURONS,ANTIBODIES,SEGMENTATION,MEMORY",Article,"AMER SOC NEURORADIOLOGY, PO BOX 3000, DENVILLE, NJ 07834-9349 USA","Neurosciences & Neurology,Radiology, Nuclear Medicine & Medical Imaging",,,"GLUTAMIC-ACID,DECARBOXYLASE,TEMPORAL-LOBE,EPILEPSY,SELECTIVE,VULNERABILITY,AUTOIMMUNE,ENCEPHALITIS,HIPPOCAMPAL,DAMAGE,LEUCINE-RICH,CA1,NEURONS,ANTIBODIES,SEGMENTATION,MEMORY",AMERICAN JOURNAL OF NEURORADIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6975350,
93,Regression analysis for detecting epileptic seizure with different feature extracting strategies,64,6,619-642,"Hussain Lal,Saeed Sharjil,Idris Adnan,Awan Imtiaz Ahmed,Shah Saeed Arif,Majid Abdul,Ahmed Bilal,Chaudhary Quratul-Ain","Hussain L,Saeed S,Idris A,Awan IA,Shah SA,Majid A,Ahmed B,Chaudhary QA",Hussain L,10.1515/bmt-2018-0012,University of Azad Jammu & Kashmir,"Due to the excitability of neurons in the brain, a neurological disorder is produced known as epilepsy. The brain activity of patients suffering from epilepsy is monitored through electroencephalography (EEG). The multivariate nature of features from time domain, frequency domain, complexity and wavelet entropy based, and the statistical features were extracted from healthy and epileptic subjects using the Bonn University database and seizure and non-seizure intervals using the CHB MIT database. The robust machine learning regression methods based on regression, support vector regression (SVR), regression tree (RT), ensemble regression, Gaussian process regression (GPR) were employed for detecting and predicting epileptic seizures. Performance was measured in terms of root mean square error (RMSE), squared error, mean square error (MSE) and mean absolute error (MAE). Moreover, detailed optimization was performed using a RT to predict the selected features from each feature category. A deeper analysis was conducted on features and tree regression methods where optimal RMSE and MSE results were obtained. The best optimal performance was obtained using the ensemble boosted regression tree (BRT) and exponential GPR with an RMSE of 0.47, an MSE (0.22), an R Square (RS) (0.25) and an MAE (0.30) using the Bonn University database and support vector machine (SVM) fine Gaussian with RMSE (0.63634), RS (0.03), MSE (040493) and MAE (0.31744); squared exponential GPR and rational quadratic GPR with an RMSE of 0.63841, an RS (0.03), an MSE (0.40757) and an MAE (0.3472) was obtained using the CHB MIT database. A further deeper analysis for the prediction of selected features was performed on an RT to compute the optimal feasible point, observed and estimated function values, function evaluation time, objective function evaluation time and overall elapsed time.","classification,decision tree,ensemble classifier,epilepsy,K-nearest neighbors,seizure detection,support vector machine",Review,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY","Engineering,Medical Informatics",,1.404,"HEART-RATE-VARIABILITY,SUPPORT,VECTOR,REGRESSION,DISCRETE,WAVELET,TRANSFORM,TIME-SERIES,ANALYSIS,EEG-SIGNALS,NEURAL-NETWORK,APPROXIMATE,ENTROPY,EYE-OPEN,AUTOMATIC,RECOGNITION,COMPLEXITY,ANALYSIS",BIOMEDICAL ENGINEERING-BIOMEDIZINISCHE TECHNIK,,
94,Diagnostic Clinical Trials in Breast Cancer Brain Metastases: Barriers and Innovations,19,6,383-391,"Fares Jawad,Kanojia Deepak,Rashidi Aida,Ahmed Atique U.,Balyasnikova Irina V,Lesniak Maciej S.","Fares J,Kanojia D,Rashidi A,Ahmed AU,Balyasnikova IV,Lesniak MS",Lesniak MS,10.1016/j.clbc.2019.05.018,Northwestern University,"Optimal treatment of breast cancer brain metastases (BCBM) is often hampered by limitations in diagnostic abilities. Developing innovative tools for BCBM diagnosis is vital for early detection and effective treatment. In this study we explored the advances in trial for the diagnosis of BCBM, with review of the literature. On May 8, 2019, we searched ClinicalTrials.gov for interventional and diagnostic clinical trials involving BCBM, without limiting for date or location. Information on trial characteristics, experimental interventions, results, and publications were collected and analyzed. In addition, a systematic review of the literature was conducted to explore published studies related to BCBM diagnosis. Only 9 diagnostic trials explored BCBM. Of these, 1 trial was withdrawn because of low accrual numbers. Three trials were completed; however, none had published results. Modalities in trial for BCBM diagnosis entailed magnetic resonance imaging (MRI), computed tomography (CT), positron emission tomography (PET), PET-CT, nanobodies, and circulating tumor cells (CTCs), along with a collection of novel tracers and imaging biomarkers. MRI continues to be the diagnostic modality of choice, whereas CT is best suited for acute settings. Advances in PET and PET-CT allow the collection of metabolic and functional information related to BCBM. CTC characterization can help reflect on the molecular foundations of BCBM, whereas cell-free DNA offers new genetic material for further exploration in trials. The integration of machine learning in BCBM diagnosis seems inevitable as we continue to aim for rapid and accurate detection and better patient outcomes.","Artificial intelligence,Circulating tumor cells,Magnetic resonance imaging,Nanobody,Positron emission tomography",Review,"CIG MEDIA GROUP, LP, 3500 MAPLE AVENUE, STE 750, DALLAS, TX 75219-3931 USA",Oncology,,3.356,"CIRCULATING,TUMOR-CELLS,NANOLIPOSOMAL,IRINOTECAN,FREE,DNA,MRI,HYPOXIA,CLINICALTRIALS.GOV,FERUMOXYTOL,NANOBODIES,SURVIVAL,BLOOD",CLINICAL BREAST CANCER,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6888931,
95,Mammography-based radiomic analysis for predicting benign BI-RADS category 4 calcifications,121,,,"Lei Chuqian,Wei Wei,Liu Zhenyu,Xiong Qianqian,Yang Ciqiu,Yang Mei,Zhang Liulu,Zhu Teng,Zhuang Xiaosheng,Liu Chunling","Lei CQ,Wei W,Liu ZY,Xiong QQ,Yang C,Yang M,Zhang LL,Zhu T,Zhuang XS,Liu CL",Wang K,10.1016/j.ejrad.2019.108711,"123 Huifu West Rd, Guangzhou 510080, Guangdong, Peoples R China.","Purpose: We developed and validated a radiomic model based on mammography and assessed its value for predicting the pathological diagnosis of Breast Imaging Reporting and Data System (BI-RADS) category 4 calcifications.
Materials and methods: Patients with a total of 212 eligible calcifications were recruited (159 cases in the primary cohort and 53 cases in the validation cohort). In total, 8286 radiomic features were extracted from the craniocaudal (CC) and mediolateral oblique (MLO) images. Machine learning was used to select features and build a radiomic signature. The clinical risk factors were selected from the independent clinical factors through logistic regression analyses. The radiomic nomogram incorporated the radiomic signature and an independent clinical risk factor. The diagnostic performance of the radiomic model and the radiologists' empirical prediction model was evaluated by the area under the receiver operating characteristic curve (AUC). The differences between the various AUCs were compared with DeLong's test.
Results: Six radiomic features and the menopausal state were included in the radiomic nomogram, which discriminated benign calcifications from malignant calcifications with an AUC of 0.80 in the validation cohort. The difference between the classification results of the radiomic nomogram and that of radiologists was significant (p < 0.05). Particularly for patients with calcifications that are negative on ultrasounds but can be detected by mammography (MG+/US-calcifications), the identification ability of the radiomic nomogram was very strong.
Conclusions: The mammography-based radiomic nomogram is a potential tool to distinguish benign calcifications from malignant calcifications.","Radiomics,Breast,Calcification,Predictive value of test,Unnecessary procedures",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Radiology, Nuclear Medicine & Medical Imaging",,,"BREAST-CANCER,MICROCALCIFICATION,DESCRIPTORS,SCREENING,MAMMOGRAPHY,REGULARIZATION,PATHS,RISK,CHEMORADIOTHERAPY,PERFORMANCE,WOMEN,MODEL",EUROPEAN JOURNAL OF RADIOLOGY,,
96,A Lithology Identification Approach Based on Machine Learning With Evolutionary Parameter Tuning,16,12,1819-1823,"Saporetti Camila Martins,da Fonseca Leonardo Goliatt,Pereira Egberto","Saporetti CM,da Fonseca LG,Pereira E",Saporetti CM,10.1109/LGRS.2019.2911473,"Univ Fed Juiz de Fora, Postgrad Program Computat Modeling, BR-36036900 Juiz De Fora, Brazil.","Identification of underground formation lithology from well-log data is an important task in petroleum exploration and engineering. Due to the cost or imprecision of some methods applied in this activity, there is a need to automate the procedure of reservoir characterization. Machine learning techniques can be efficient alternatives to lithology identification. To acquire proper performance, usually, some parameters of these techniques should be adjusted, and this can become a hard task depending on the complexity of the underlying problem. This letter integrates the gradient boosting (GB) with a differential evolution (DE) for formation lithology identification using data from the Daniudui gas field and the Hangjinqi gas field. This letter's contributions include the use of an evolutionary algorithm to adjust optimally the hyperparameters of the GB, and the results show improvements when compared with those obtained in the literature.","Differential evolution (DE),gradient boosting (GB),lithology",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Geochemistry & Geophysics,Engineering,Remote Sensing,Imaging Science & Photographic Technology",,3.986,REGRESSION,IEEE GEOSCIENCE AND REMOTE SENSING LETTERS,,
97,A Long Short-Term Memory Network for Vessel Reconstruction Based on Laser Doppler Flowmetry via a Steerable Needle,19,23,11367-11376,"Virdyawan Vani,Rodriguez y Baena Ferdinando","Virdyawan V,Baena FRY",Baena FRY,10.1109/JSEN.2019.2934013,Imperial College London,"Hemorrhage is one risk of percutaneous intervention in the brain that can be life-threatening. Steerable needles can avoid blood vessels thanks to their ability to follow curvilinear paths, although knowledge of vessel pose is required. To achieve this, we present the deployment of laser Doppler flowmetry (LDF) sensors as an in-situ vessel detection method for steerable needles. Since the perfusion value from an LDF system does not provide positional information directly, we propose the use of a machine learning technique based on a Long Short-term Memory (LSTM) network to perform vessel reconstruction online. Firstly, the LSTM is used to predict the diameter and position of an approaching vessel based on successive measurements of a single LDF probe. Secondly, a ""no-go"" area is predicted based on the measurement from four LDF probes embedded within a steerable needle, which accounts for the full vessel pose. The network was trained using simulation data and tested on experimental data, with 75% diameter prediction accuracy and 0.27 mm positional Root Mean Square (RMS) Error for the single probe network, and 77% vessel volume overlap for the 4-probe setup.","Laser Doppler flowmetry,vessel reconstruction,percutaneous intervention,steerable needle,machine learning,long short-term memory (LSTM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"BRAIN,PROBE",IEEE SENSORS JOURNAL,https://ieeexplore.ieee.org/ielx7/7361/8901508/08792101.pdf,
98,Reinforcement learning-based design of orienting devices for vibratory bowl feeders,105,9,3631-3642,"Stocker Cosima,Schmid Marc,Reinhart Gunther","Stocker C,Schmid M,Reinhart G",Stocker C,10.1007/s00170-019-03798-9,Technical University of Munich,"The sorting of small parts is one of the common tasks in the field of industrial manufacturing. Vibratory bowl feeders (VBF) are commonly used to accomplish this task. Nowadays, the design process of the VBF is based on a manual and expensive trial-and-error approach, in which different traps are arranged and tuned. This paper outlines a method which modifies this conventional process using Reinforcement Learning to automate the VBF design. To enable this, a software agent is used to model the placement of traps on multiple positions and measure the subsequent configuration efficiency. A physics simulation provides the characteristics of the individual traps. During the training, Q-learning is applied to determine the environmental indicators under which a certain trap should be replaced. A 3D matrix is used to store information in a problem-related representation. Due to the trial-and-error principle of Reinforcement Learning, this training is comparable with the traditional proceedings. In addition, valuable action paths are stored in a memory and the agent frequently is trained on these paths in order to remember good solutions. Additionally, a knowledge base is used to exclude inefficient sets of traps. The rules for the knowledge base are built upon knowledge from the conventional design process. In first test cases, the trained agent is able to assemble traps achieving promising configurations. The results of the agent will be validated in the next step using physics simulation.","Machine learning,Smart assembly,Intelligent support systems,Feeding technology",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND","Automation & Control Systems,Engineering",,,"FEEDING,3D,PARTS,TRAPS",INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY,,
99,A collaborative robot for the factory of the future: BAZAR,105,9,3643-3659,"Cherubini Andrea,Passama Robin,Navarro Benjamin,Sorour Mohamed,Khelloufi Abdellah,Mazhar Osama,Tarbouriech Sonny,Zhu Jihong,Tempier Olivier,Crosnier Andre","Cherubini A,Passama R,Navarro B,Sorour M,Khelloufi A,Mazhar O,Tarbouriech S,Zhu JH,Tempier O,Crosnier A",Cherubini A,10.1007/s00170-019-03806-y,Centre National de la Recherche Scientifique (CNRS),"This paper introduces BAZAR, a collaborative robot that integrates the most advanced sensing and actuating devices in a unique system designed for the Industry 4.0. We present BAZAR's three main features, which are all paramount in the factory of the future. These features are: mobility for navigating in dynamic environments, interaction for operating side-by-side with human workers, and dual-arm manipulation for transporting and assembling bulky objects.","Efficient,Flexible and modular production,Robotics,Smart assembly,Human-robot co-working,Real industrial world case studies,Digital manufacturing and assembly system,Machine learning",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND","Automation & Control Systems,Engineering",,3.32,"MOBILE,ROBOTS,NAVIGATION",INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY,https://hal.archives-ouvertes.fr/hal-02101562/document,
100,"Study of cutting forces using FE, ANOVA, and BPNN in elliptical vibration cutting of titanium alloy Ti-6Al-4V",105,12,5105-5120,"Xie Haibo,Wang Zhanjiang","Xie HB,Wang ZJ",Wang ZJ,10.1007/s00170-019-04537-w,Southwest Jiaotong University,"In this study, the finite element (FE) analysis, analysis of variance (ANOVA), and the back propagation neural network (BPNN) were employed to evaluate and predict the cutting forces of titanium alloy Ti-6Al-4V depending on vibration frequency, tangential amplitude, and thrust amplitude, as well as cutting speed during elliptical vibration cutting (EVC). A series of EVC simulations were conducted based on the verified FE model to evaluate the impacts of different EVC parameters on cutting forces. The results show that the tangential force decreases with increasing vibration frequency, tangential amplitude, and thrust amplitude, but with decreasing cutting speed. The positive and negative thrust forces decrease with increasing frequency and tangential amplitude, but with decreasing thrust amplitude and cutting speed. In addition, ANOVA results clearly indicated that the tangential amplitude is the dominant parameter affecting the cutting forces, and the percent contributions to cutting forces are 69.56%, 66.03%, and 62.83%, respectively. Further, the BPNN models with three different activation functions and different architectures are utilized to predict the cutting forces, and the best performance, in terms of agreement with the target outputs, can be achieved by the network using logarithmic sigmoid activation function and architecture with 15 neurons in one hidden layer. The correlation coefficients for training and testing the selected network are 0.99993 and 0.99916, and the mean square errors are 0.1963 and 2.6070, respectively, and these reveal that BPNN is fairly successful in predicting the cutting forces.","Elliptical vibration cutting,Finite element,Analysis of variance,Back propagation neural network",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND","Automation & Control Systems,Engineering",,3.32,"SURFACE-ROUGHNESS,CHIP,FORMATION,OPTIMIZATION,PARAMETERS,PREDICTION,STEEL,ANN",INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY,,
