,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Multi-objective optimization of high-sulfur natural gas purification plant,16,6,1430-1441,"Shang Jian-Feng,Ji Zhong-Li,Qiu Min,Ma Li-Min","Shang JF,Ji ZL,Qiu M,Ma LM",Ma LM,10.1007/s12182-019-00391-3,China University of Petroleum,"There exists large space to save energy of high-sulfur natural gas purification process. The multi-objective optimization problem has been investigated to effectively reduce the total comprehensive energy consumption and further improve the production rate of purified gas. A steady-state simulation model of high-sulfur natural gas purification process has been set up by using ProMax. Seven key operating parameters of the purification process have been determined based on the analysis of comprehensive energy consumption distribution. To solve the problem that the process model does not converge in some conditions, back-propagation (BP) neural network has been applied to substitute the simulation model to predict the relative parameters in the optimization model. The uniform design method and the table U-21 (10(7)) have been applied to design the experiment points for training and testing BP model. High prediction accuracy can be achieved by using the BP model. Non-dominated sorting genetic algorithm-II has been developed to optimize the two objectives, and 100 Pareto optimal solutions have been obtained. Three optimal points have been selected and evaluated further. The results demonstrate that the total comprehensive energy consumption is reduced by 13.4% and the production rate of purified gas is improved by 0.2% under the optimized operating conditions.","High-sulfur natural gas purification plant,Multi-objective optimization,Process simulation model,Thermodynamic analysis,BP neural network,Genetic algorithm",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Energy & Fuels,Engineering",,3.492,"SWEETENING,PLANT,SENSITIVITY-ANALYSIS,PROCESS,SIMULATION,HYDROGEN-SULFIDE,NEURAL-NETWORK,DESIGN,PERFORMANCE,SCHEME",PETROLEUM SCIENCE,https://link.springer.com/content/pdf/10.1007/s12182-019-00391-3.pdf,
2,,,,,,,,,,,,,,,,,,,,
3,Residual neural network-based fully convolutional network for microstructure segmentation,25,4,282-289,"Jang Junmyoung,Van Donghyun,Jang Hyojin,Baik Dae Hyun,Yoo Sang Duk,Park Jaewoong,Mhin Sungwook,Mazumder Jyoti,Lee Seung Hwan","Jang J,Van D,Jang H,Baik DH,Yoo SD,Park J,Mhin S,Mazumder J,Lee SH",Lee SH,10.1080/13621718.2019.1687635,Korea Aerospace University,"In this study, microstructures of weldment produced using carbon steel A516 grade 60 were analysed via a deep learning approach to measure the fraction of acicular ferrite which considerably influences on mechanical properties of carbon steel. The fully convolutional network was used to conduct the image segmentation. Submerged arc welding was used for welding, and the dataset was constructed using optical microscope. The model was compiled with ResNet, which is the state-of-the-art classifier used as an encoder. The model is trained to distinguish acicular ferrite from microstructures of dataset images and then estimate its accuracy. As a result, the mean intersection over union, which is a metric commonly used to evaluate image segmentation, was shown to be higher than 85%.","Submerged arc welding,carbon steel,acicular ferrite,fraction,segmentation,deep learning,fully convolutional network,ResNet",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Materials Science,Metallurgy & Metallurgical Engineering",,3.704,"ACICULAR,FERRITE,STEEL,MN",SCIENCE AND TECHNOLOGY OF WELDING AND JOINING,,
4,Repeatability of radiomics and machine learning for DWI: Short-term repeatability study of 112 patients with prostate cancer,83,6,2293-2309,"Merisaari Harri,Taimen Pekka,Shiradkar Rakesh,Ettala Otto,Pesola Marko,Saunavaara Jani,Bostrom Peter J.,Madabhushi Anant,Aronen Hannu J.,Jambor Ivan","Merisaari H,Taimen P,Shiradkar R,Ettala O,Pesola M,Saunavaara J,Bostrom PJ,Madabhushi A,Aronen HJ,Jambor I",Merisaari H,10.1002/mrm.28058,University of Turku,"Purpose To evaluate repeatability of prostate DWI-derived radiomics and machine learning methods for prostate cancer (PCa) characterization. Methods A total of 112 patients with diagnosed PCa underwent 2 prostate MRI examinations (Scan1 and Scan2) performed on the same day. DWI was performed using 12 b-values (0-2000 s/mm(2)), post-processed using kurtosis function, and PCa areas were annotated using whole mount prostatectomy sections. A total of 1694 radiomic features including Sobel, Kirch, Gradient, Zernike Moments, Gabor, Haralick, CoLIAGe, Haar wavelet coefficients, 3D analogue to Laws features, 2D contours, and corner detectors were calculated. Radiomics and 4 feature pruning methods (area under the receiver operator characteristic curve, maximum relevance minimum redundancy, Spearman's rho, Wilcoxon rank-sum) were evaluated in terms of Scan1-Scan2 repeatability using intraclass correlation coefficient (ICC)(3,1). Classification performance for clinically significant and insignificant PCa with Gleason grade groups 1 versus >1 was evaluated by area under the receiver operator characteristic curve in unseen random 30% data split. Results The ICC(3,1) values for conventional radiomics and feature pruning methods were in the range of 0.28-0.90. The machine learning classifications varied between Scan1 and Scan2 with % of same class labels between Scan1 and Scan2 in the range of 61-81%. Surface-to-volume ratio and corner detector-based features were among the most represented features with high repeatability, ICC(3,1) >0.75, consistently high ranking using all 4 feature pruning methods, and classification performance with area under the receiver operator characteristic curve >0.70. Conclusion Surface-to-volume ratio and corner detectors for prostate DWI led to good classification of unseen data and performed similarly in Scan1 and Scan2 in contrast to multiple conventional radiomic features.","corner detection,diffusion-weighted imaging,feature extraction,Gleason score,intraclass correlation coefficient,machine learning,prostate cancer,radiomics,repeatability,shape",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,,"B-VALUE,DISTRIBUTION,MATHEMATICAL-MODELS,ARTIFICIAL-INTELLIGENCE,GLEASON,SCORE,DIFFUSION,MRI,VALUES,REPRODUCIBILITY,RELAXATION,PREDICTION",MAGNETIC RESONANCE IN MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7047644,
5,Machine learning-aided analysis for complex local structure of liquid crystal polymers,9,,,"Doi Hideo,Takahashi Kazuaki Z.,Tagashira Kenji,Fukuda Jun-ichi,Aoyagi Takeshi","Doi H,Takahashi KZ,Tagashira K,Fukuda J,Aoyagi T",Takahashi KZ,10.1038/s41598-019-51238-1,National Institute of Advanced Industrial Science & Technology (AIST),"Elucidation of mesoscopic structures of molecular systems is of considerable scientific and technological interest for the development and optimization of advanced materials. Molecular dynamics simulations are a promising means of revealing macroscopic physical properties of materials from a microscopic viewpoint, but analysis of the resulting complex mesoscopic structures from microscopic information is a non-trivial and challenging task. In this study, a Machine Learning-aided Local Structure Analyzer (ML-LSA) is developed to classify the complex local mesoscopic structures of molecules that have not only simple atomistic group units but also rigid anisotropic functional groups such as mesogens. The proposed ML-LSA is applied to classifying the local structures of liquid crystal polymer (LCP) systems, which are of considerable scientific and technological interest because of their potential for sensors and soft actuators. A machine learning (ML) model is constructed from small, and thus computationally less costly, monodomain LCP trajectories. The ML model can distinguish nematic- and smectic-like monodomain structures with high accuracy. The ML-LSA is applied to large, complex quenched LCP structures, and the complex local structures are successfully classified as either nematic- or smectic-like. Furthermore, the results of the ML-LSA suggest the best order parameter for distinguishing the two mesogenic structures. Our ML model enables automatic and systematic analysis of the mesogenic structures without prior knowledge, and thus can overcome the difficulty of manually determining the specific order parameter required for the classification of complex structures.","MOLECULAR-DYNAMICS,SIMULATIONS,PHASE,LIGHT,IDENTIFICATION,NUCLEATION,NETWORKS,MODEL,GELS",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,5.134,"MOLECULAR-DYNAMICS,SIMULATIONS,PHASE,LIGHT,IDENTIFICATION,NUCLEATION,NETWORKS,MODEL,GELS",SCIENTIFIC REPORTS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6841663,
6,"Driverless Government: Speculation, Citizenship and Collective Civic Intelligence",7,3,365-381,Wong Jason Shun,Wong JSS,,10.1080/20507828.2019.1647960,,"This article examines data, algorithms and machine learning as the new materials that make cities smart. Analyzing the threat of relying on digital tools made by corporations to govern and regulate will also provide insight into possible areas in which citizens can insert their own agency. Using a speculative case study, Driverless Government, the project imagines the full potential of using digital tools in a city council meeting by mixing the political, digital and physical to create a hybridized and multimodal proposal. The speculative design provocation challenges the current American bureaucratic system by presenting tools that allow citizens to dispute an optimization-led and corporate agenda by envisioning representation in new forms. Specifically, the project imagines how citizens can create artificial intelligence representatives that advocate for themselves and other agents. By imagining, possibilities and responsibilities for the American citizenry are outlined in order to create cities that are for people.","smart city,civics,big data,industrial Internet of Things,machine learning,artificial intelligence,speculative design,citizen technology",Article,"ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND",Architecture,,,CITY,ARCHITECTURE AND CULTURE,,
7,,,,,,,,,,,,,,,,,,,,
8,,,,,,,,,,,,,,,,,,,,
9,,,,,,,,,,,,,,,,,,,,
10,,,,,,,,,,,,,,,,,,,,
11,Computer-aided diagnosis of retinal diseases using multidomain feature fusion,30,2,367-379,"Keerthiveena B.,Esakkirajan S.,Selvakumar K.,Yogesh T.","Keerthiveena B,Esakkirajan S,Selvakumar K,Yogesh T",Keerthiveena B,10.1002/ima.22379,PSG College Technology,"In this article, an attempt is made to combine both transform and spatial domain features to increase the accuracy, sensitivity, and specificity for the classification of retinal diseases. Papilloedema, macular edema, glaucoma, diabetic retinopathy (DR), and central retinal vein occlusion (CRVO) are the leading cause of blindness in humans. To identify these diseases in a mass screening process, it consumes intense labor and time. In this proposed work, an automated computer aided algorithm is developed to classify the normal from the abnormal (Papilledema, macular edema, glaucoma, DR, and CRVO) images. For any classification task, an increase in data size, number of classes, and dimension of the feature space affect the performance of any classifier. A single classifier is generally unable to handle the wide variability and scalability of the data in any problem. In the proposed algorithm, the feature fusion technique is employed to reduce the input data to the classifier. The features are extracted from wavelet packet transform (WPT) and intensity hue saturation (IHS). A support vector machine (SVM)-based learning algorithm is used to train the classifier using the extracted features. The proposed method yields better results than the existing classifier fusion method with an overall accuracy, sensitivity, specificity, positive prediction value (PPV), negative prediction value (NPV), and area under ROC curve (AUC) of 96.3%, 95.8%, 97.8%, 96.4%,98.1%, and 0.971 respectively.","feature fusion,intensity hue saturation,support vector machine,wavelet packet transform,weighted principal component analysis",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,,"DECISION-SUPPORT-SYSTEM,COLOR,FUNDUS,IMAGES,DIABETIC-RETINOPATHY,STATISTICAL,FEATURES,VESSEL,SEGMENTATION,IDENTIFICATION,TRANSFORM",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
12,An intelligent decision support system for production planning based on machine learning,31,5,1257-1273,"Gonzalez Rodriguez German,Gonzalez-Cava Jose M.,Mendez Perez Juan Albino","Rodriguez GG,Gonzalez-Cava JM,Perez JAM",Rodriguez GG,10.1007/s10845-019-01510-y,Universidad de la Laguna,"This paper presents a new methodology to solve a Closed-Loop Supply Chain (CLSC) management problem through a decision-making system based on fuzzy logic built on machine learning. The system will provide decisions to operate a production plant integrated in a CLSC to meet the production goals with the presence of uncertainties. One of the main contributions of the proposal is the ability to reject the effects that the imbalances in the rest of the chain have on the inventories of raw materials and finished products. For this, an intelligent algorithm will be in charge of the supervision of the plant operation and task-reprogramming to ensure the achievement of the process goals. Fuzzy logic and machine learning techniques are combined to design the tool. The method was tested on an industrial hospital laundry with satisfactory results, thus highlighting the potential of this proposal for its incorporation into the Industry 4.0 framework.","Artificial intelligence,Intelligent manufacturing,Machine learning,Operation management,Decision support system",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,5.829,"GREEN,SUPPLIER,SELECTION,ARTIFICIAL-INTELLIGENCE,FUZZY,CHAIN,TREES,MANAGEMENT,REGRESSION,DESIGN,MODEL",JOURNAL OF INTELLIGENT MANUFACTURING,,
13,Classifying Raman spectra of extracellular vesicles based on convolutional neural networks for prostate cancer detection,51,2,293-300,"Lee Wooje,Lenferink Aufried T. M.,Otto Cees,Offerhaus Herman L.","Lee W,Lenferink ATM,Otto C,Offerhaus HL",Offerhaus HL,10.1002/jrs.5770,University of Twente,"Since early 2000s, machine learning algorithms have been widely used in many research and industrial fields, most prominently in computer vison. Lately, many fields of study have tried to use these automated methods, and there are several reports from the field of spectroscopy. In this study, we demonstrate a classification model based on machine learning to classify Raman spectra. We obtained Raman spectra from extracellular vesicles (EVs) to find tumor derived EVs. The convolutional neural network (CNN) was trained on preprocessed Raman data and raw Raman data. We compare the result from CNN with results from principal component analysis that is widely used among in spectroscopy. The new model classifies EVs with an accuracy of >90%. Moreover, the new model based on CNN is also suitable for classifying the raw Raman data directly without preprocessing with a minimum accuracy of 93%.","Cancer biomarker,convolutional neural network,extracellular vesicles,machine learning,Raman spectroscopy",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Spectroscopy,,2.875,"BREAST-CANCER,SPECTROSCOPY,CLASSIFICATION,TECHNOLOGIES,MACHINE",JOURNAL OF RAMAN SPECTROSCOPY,https://ris.utwente.nl/ws/files/152614683/10.1002_jrs.5770.pdf,
14,Improved Gas Selectivity Based on Carbon Modified SnO2 Nanowires,6,,,"Tonezzer Matteo,Izidoro Sandro C.,Moraes Joao P. A.,Le Thi Thanh Dang","Tonezzer M,Izidoro SC,Moraes JPA,Dang LTT",Tonezzer M,10.3389/fmats.2019.00277,Consiglio Nazionale delle Ricerche (CNR),"The analysis of ambient (home, office, outdoor) atmosphere in order to check the presence of dangerous gases is getting more and more important. Therefore, tiny sensors capable to distinguish the presence of specific pollutants is crucial. Herein, a resistive sensor based on a carbon modified tin oxide nanowires, able to classify different gases and estimate their concentration, is presented. The C-SnO2 nanostructures are grown by chemical vapor deposition and then used as a conductometric sensor under a temperature gradient. The device works at lower temperatures than pure SnO2, with a better response. Five outputs are collected and combined to form multidimensional data that are specific of each gas. Machine learning algorithms are applied to these multidimensional data in order to teach the system how to recognize different gases. The six tested gases (acetone, ammonia, CO, ethanol, hydrogen, and toluene) are perfectly classified by three models, demonstrating the goodness of the raw sensor response. The gas concentration can also be estimated, with an average error of 36% on the low concentration range 1-50 ppm, making the sensor suitable for detecting the exceedance of the danger thresholds.","metal oxide,tin oxide,carbon,gas sensor,selectivity",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Materials Science,,,"ELECTRONIC,NOSE,SENSOR,NANOTUBES,FRAMEWORK,HUMIDITY,MACHINE,ACETONE,SIGNAL,ARRAY",FRONTIERS IN MATERIALS,https://www.frontiersin.org/articles/10.3389/fmats.2019.00277/pdf,
15,"Nanoinformatics, and the big challenges for the science of small things",11,41,19190-19201,"Barnard A. S.,Motevatti B.,Parker A. J.,Fischer J. M.,Feigt C. A.,Opletal G.","Barnard AS,Motevatti B,Parker AJ,Fischer JM,Feigt CA,Opletal G",Barnard AS,10.1039/c9nr05912a,Commonwealth Scientific & Industrial Research Organisation (CSIRO),"The combination of computational chemistry and computational materials science with machine learning and artificial intelligence provides a powerful way of relating structural features of nanomaterials with functional properties. However, combining these fundamentally different scientific approaches is not as straightforward as it seems. Machine learning methods were developed for large data sets with small numbers of consistent features. Typically nanomaterials data sets are small, with high dimensionality and high variance in the feature space, and suffer from numerous destructive biases. None of the established data science or machine learning methods in widespread use today were devised with (nano)materials data sets in mind, but there are ways to overcome these challenges and use them reliably. In this review we will discuss domain-specific constraints on data-driven nanomaterials design, and explore the differences between nanomaterials simulation and nanoinformatics that can be leveraged for greater impact.","ARTIFICIAL NEURAL-NETWORKS,MATERIALS DISCOVERY,ELECTRONIC-PROPERTIES,CRYSTAL-STRUCTURE,MACHINE,CLASSIFICATION,PREDICTION,DESIGN,DESCRIPTORS,MODELS",Review,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,7.632,"ARTIFICIAL,NEURAL-NETWORKS,MATERIALS,DISCOVERY,ELECTRONIC-PROPERTIES,CRYSTAL-STRUCTURE,MACHINE,CLASSIFICATION,PREDICTION,DESIGN,DESCRIPTORS,MODELS",NANOSCALE,,
16,Accelerated Discovery of Two-Dimensional Optoelectronic Octahedral Oxyhalides via High-Throughput Ab Initio Calculations and Machine Learning,10,21,6734-6740,"Ma Xing-Yu,Lewis James P.,Yan Qing-Bo,Su Gang","Ma XY,Lewis JP,Yan CB,Su G",Su G,10.1021/acs.jpclett.9b02420,Chinese Academy of Sciences,"Traditional trial-and-error methods are obstacles for large-scale searching of new optoelectronic materials. Here, we introduce a method combining high-throughput ab initio calculations and machine-learning approaches to predict two-dimensional octahedral oxyhalides with improved optoelectronic properties. We develop an effective machine-learning model based on an expansive data set generated from density functional calculations including the geometric and electronic properties of 300 two-dimensional octahedral oxyhalides. Our model accelerates the screening of potential optoelectronic materials of 5000 two-dimensional octahedral oxyhalides. The distorted stacked octahedral factors proposed in our model play essential roles in the machine-learning prediction. Several potential two-dimensional optoelectronic octahedral oxyhalides with moderate band gaps, high electron mobilities, and ultrahigh absorbance coefficients are successfully hypothesized.","APPROXIMATION,TRANSPORT",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,,"APPROXIMATION,TRANSPORT",JOURNAL OF PHYSICAL CHEMISTRY LETTERS,http://arxiv.org/pdf/1909.10395,
17,Virtual Excited State Reference for the Discovery of Electronic Materials Database: An Open-Access Resource for Ground and Excited State Properties of Organic Molecules,10,21,6835-6841,"Abreha Biruk G.,Agarwal Snigdha,Foster Ian,Blaiszik Ben,Lopez Steven A.","Abreha BG,Agarwal S,Foster I,Blaiszik B,Lopez SA",Lopez SA,10.1021/acs.jpclett.9b02577,Northeastern University,"This letter announces the Virtual Excited State Reference for the Discovery of Electronic Materials Database (VERDE materials DB), the first database to include downloadable excited-state structures (S-0, S-1, T-1) and photophysical properties. VERDE materials DB is searchable, open-access via www.verdedb.org , and focused on light-responsive pi-conjugated organic molecules with applications in green chemistry, organic solar cells, and organic redox flow batteries. It includes results of our active and past virtual screening studies; to date, more than 13 000 density functional theory (DFT) calculations have been performed on 1 500 molecules to obtain frontier molecular orbitals and photophysical properties, including excitation energies, dipole moments, and redox potentials. To improve community access, we have made VERDE materials DB available via an integration with the Materials Data Facility. We are leveraging VERDE materials DB to train machine learning algorithms to identify new materials and structure-property relationships between molecular ground- and excited-states. We present a case-study involving photoaffinity labels, including predictions of new diazirine-based photoaffinity labels anticipated to have high photostabilities.","ORBITAL METHODS,BINDING-SITE,FORCE-FIELD,DESIGN,PHOTOVOLTAICS,FUNCTIONALS",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,7.643,"ORBITAL,METHODS,BINDING-SITE,FORCE-FIELD,DESIGN,PHOTOVOLTAICS,FUNCTIONALS",JOURNAL OF PHYSICAL CHEMISTRY LETTERS,https://www.osti.gov/biblio/1606543,
18,Predicting charge density distribution of materials using a local-environment-based graph convolutional network,100,18,,"Gong Sheng,Xie Tian,Zhu Taishan,Wang Shuo,Fadel Eric R.,Li Yawei,Grossman Jeffrey C.","Gong S,Xie T,Zhu TS,Wang S,Fadel ER,Li YW,Grossman JC",Grossman JC,10.1103/PhysRevB.100.184103,Massachusetts Institute of Technology (MIT),"The electron charge density distribution of materials is one of the key quantities in computational materials science as theoretically it determines the ground state energy and practically it is used in many materials analyses. However, the scaling of density functional theory calculations with number of atoms limits the usage of charge-density-based calculations and analyses. Here we introduce a machine-learning scheme with local-environment-based graphs and graph convolutional neural networks to predict charge density on grid points from the crystal structure. We show the accuracy of this scheme through a comparison of predicted charge densities as well as properties derived from the charge density, and that the scaling is O(N). More importantly, the transferability is shown to be high with respect to different compositions and structures, which results from the explicit encoding of geometry.","REACTIVITY,STATE",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,"MACHINE,LEARNING-MODELS,REACTIVITY,STATE",PHYSICAL REVIEW B,https://dspace.mit.edu/bitstream/1721.1/132177/2/PhysRevB.100.184103.pdf,
19,Development of a quantum chemical descriptor expressing aromatic/quinoidal character for designing narrow-bandgap pi-conjugated polymers,10,41,5584-5593,"Hayashi Yoshihiro,Kawauchi Susumu","Hayashi Y,Kawauchi S",Hayashi Y; Kawauchi S,10.1039/c9py00987f,Tokyo Institute of Technology,"A new quantum chemical descriptor, quinoid stabilization energy (QSE), is established for the computational design of narrow-bandgap polymers. QSE was constructed based on the energy change of homodesmotic reactions of a dimethylated monomer with oligoacetylene. It can be uniquely defined for heterocyclic and polycyclic monomers, unlike the arbitrary conventional descriptors based on bond length alternation. Density functional theory (DFT) calculations revealed a relationship between QSE and the bandgap of polymers. According to the relationships obtained for 268 homopolymers and 179 alternating copolymers selected from many different families, narrow-bandgap polymers can be designed with QSE = 0, which indicates the intermediate state between aromatic and quinoid forms. Copolymers having QSE = 0 can be achieved by combining a quinoidal monomer with an aromatic one. The main advantage of this approach of designing narrow-bandgap polymers is that it requires only information of the monomers and their linking site. Using this approach, we propose a new candidate of narrow-bandgap alternate copolymers constructed by two monomer units that are both usually categorized as acceptors. The proposed copolymer has a calculated bandgap of 0.76 eV, indicating a potentially high air stability. Since QSE as a simple descriptor is highly compatible with machine learning, this approach should accelerate the development of ultra-narrow-bandgap polymers.","FIELD-EFFECT TRANSISTORS,ORGANIC SEMICONDUCTOR,PHENYLENE OLIGOMERS,RATIONAL DESIGN,BUILDING-BLOCK,GAP POLYMERS,PERFORMANCE,DENSITY,NANOPARTICLES,COPOLYMERS",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND",Polymer Science,,5.067,"FIELD-EFFECT,TRANSISTORS,ORGANIC,SEMICONDUCTOR,PHENYLENE,OLIGOMERS,RATIONAL,DESIGN,BUILDING-BLOCK,GAP,POLYMERS,PERFORMANCE,DENSITY,NANOPARTICLES,COPOLYMERS",POLYMER CHEMISTRY,https://pubs.rsc.org/en/content/articlepdf/2019/py/c9py00987f,
20,"The interplay among molecular structures, crystal symmetries and lattice energy landscapes revealed using unsupervised machine learning: a closer look at pyrrole azaphenacenes",21,41,6173-6185,"Yang Jack,Li Nathan,Li Sean","Yang J,Li N,Li S",Yang J,10.1039/c9ce01190k,University of New South Wales Sydney,"The ability to perform large-scale crystal structure predictions (CSPs) has significantly advanced the synthesis of functional molecular solids by design. In our recent work [J. Yang, S. De, J. E. Campbell, S. Li, M. Ceriotti and G. M. Day, Chem. Mater., 2018, 30, 4361], we demonstrated our latest developments in organic CSPs by screening a set of 28 pyrrole azaphenacene isomers which led to one new molecule with higher thermodynamic stability and carrier mobilities in its crystalline form, compared to the one reported experimentally. Hereby, using the lattice energy landscapes of pyrrole azaphenacenes as examples, we applied machine-learning techniques to statistically reveal, in more detail, how molecular symmetry and Z ' values translate to the crystal packing landscapes, which in turn affect the coverage of landscapes through quasi-random crystal structure samplings. A recurring theme in crystal engineering is to identify the probabilities of targeting isostructures to a specific reference crystal upon chemical functionalisations. For this, we propose here a global similarity index in conjunction with an energy-density-isostructurality (EDI) map to analyse the lattice energy landscapes of halogen substituted pyrrole azaphenacenes. A continuous effort in the field is to accelerate CSPs for sampling a much wider chemical space for high-throughput material screenings, and we propose a potential solution to this challenge drawn upon this study. Our work will hopefully stimulate the crystal engineering community in adapting a more statistically-oriented approach in understanding the crystal packing of organic molecules in the age of digitisation.","INTERMOLECULAR FORCE-FIELD,STRUCTURE PREDICTION,CHARGE-TRANSPORT,REPRESENTATION,FRAMEWORK,DESIGN,ATOM",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Crystallography",,3.297,"INTERMOLECULAR,FORCE-FIELD,STRUCTURE,PREDICTION,CHARGE-TRANSPORT,REPRESENTATION,FRAMEWORK,DESIGN,ATOM",CRYSTENGCOMM,,
21,Hybrid fully convolutional networks-based skin lesion segmentation and melanoma detection using deep feature,30,2,348-357,"Jayapriya Kalyanakumar,Jacob Israel Jeena","Jayapriya K,Jacob IJ",Jacob IJ,10.1002/ima.22377,Gandhi Institute of Technology & Management (GITAM),"Fully convolutional networks (FCNs) take the input of arbitrary size and produce correspondingly sized output with efficient inference and learning. The automatic diagnosis of melanoma is very essential for reducing the mortality rate by identifying the disease in earlier stages. A two-stage framework is used for implementing the melanoma detection, segmentation of skin lesion, and identification of melanoma lesions. Two FCNs based on VGG-16 and GoogLeNet are incorporated for improving the segmentation accuracy. A hybrid framework is used for incorporating these two FCNs. The classification is done by extracting the feature from segmented lesion by using deep residual network and a hand-crafted feature. Classification is done by support vector machine. The performance analysis of our framework gives a promising accuracy, that is, 0.8892 for classification in ISBI 2016 dataset and 0.853 for ISIC 2017 dataset.","deep residual network (DRN),hybrid fully convolutional networks,melanoma detection",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,,"BORDER,DETECTION,EPILUMINESCENCE,MICROSCOPY,PATTERN-ANALYSIS,NEURAL-NETWORKS,DERMOSCOPY,DIAGNOSIS,CLASSIFICATION,TOOL",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
22,A machine learning approach based on multifractal features for crack assessment of reinforced concrete shells,35,6,565-578,"Athanasiou Apostolos,Ebrahimkhanlou Arvin,Zaborac Jarrod,Hrynyk Trevor,Salamone Salvatore","Athanasiou A,Ebrahimkhanlou A,Zaborac J,Hrynyk T,Salamone S",Salamone S,10.1111/mice.12509,"10100 Burnet Rd,Bldg 177, Austin, TX 78758 USA.","The geometric properties and spatial characteristics of crack patterns are significant indicators of the extent of damage on reinforced concrete structures. However, manual visual assessment is subjective and depends highly on the inspector's skills. The current study proposes an automated approach for the quantification of digitally documented crack patterns on reinforced concrete shell elements subjected to reversed cyclic shear loading. Multifractal analysis is proposed as a feature extractor for images depicting crack patterns and a set of artificial cracks is analyzed, to quantify how the properties of crack patterns vary as a function of cracking inclination. The results of the parametric study motivated the training of a multiclass classification model, which is used to provide damage level estimates for cracked reinforced concrete members. The training of the classifier is performed using experimental data of reinforced concrete shell elements under well-defined and idealized two-dimensional pure shear stress loading conditions. A dataset with 119 images from crack patterns of reinforced concrete shells is used for training. The multifractal features successfully translate the shape of the crack patterns into meaningful information about the extent of damage; achieving an overall test accuracy of 89.3%.","DAMAGE DETECTION,FRACTAL DIMENSION",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Computer Science,Construction & Building Technology,Engineering,Transportation",,9.756,"DAMAGE,DETECTION,FRACTAL,DIMENSION",COMPUTER-AIDED CIVIL AND INFRASTRUCTURE ENGINEERING,,
23,Automatic classification of lung nodule candidates based on a novel 3D convolution network and knowledge transferred from a 2D network,46,12,5499-5513,"Zuo Wangxia,Zhou Fuqiang,He Yuzhu,Li Xiaosong","Zuo WX,Zhou FQ,He YZ,Li XS",Zhou FQ,10.1002/mp.13867,Beihang University,"ObjectiveIn the automatic lung nodule detection system, the authenticity of a large number of nodule candidates needs to be judged, which is a classification task. However, the variable shapes and sizes of the lung nodules have posed a great challenge to the classification of candidates. To solve this problem, we propose a method for classifying nodule candidates through three-dimensional (3D) convolution neural network (ConvNet) model which is trained by transferring knowledge from a multiresolution two-dimensional (2D) ConvNet model.
MethodsIn this scheme, a novel 3D ConvNet model is preweighted with the weights of the trained 2D ConvNet model, and then the 3D ConvNet model is trained with 3D image volumes. In this way, the knowledge transfer method can make 3D network easier to converge and make full use of the spatial information of nodules with different sizes and shapes to improve the classification accuracy.
ResultsThe experimental results on 551 065 pulmonary nodule candidates in the LUNA16 dataset show that our method gains a competitive average score in the false-positive reduction track in lung nodule detection, with the sensitivities of 0.619 and 0.642 at 0.125 and 0.25 FPs per scan, respectively.
ConclusionsThe proposed method can maintain satisfactory classification accuracy even when the false-positive rate is extremely small in the face of nodules of different sizes and shapes. Moreover, as a transfer learning idea, the method to transfer knowledge from 2D ConvNet to 3D ConvNet is the first attempt to carry out full migration of parameters of various layers including convolution layers, full connection layers, and classifier between different dimensional models, which is more conducive to utilizing the existing 2D ConvNet resources and generalizing transfer learning schemes.","2D network,3D convolutional neural network,automatic classification,knowledge transfer,lung nodule candidates",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"COMPUTER-AIDED,DETECTION,PULMONARY,NODULES,CT,VALIDATION,ALGORITHMS,IMAGES,SYSTEM,CAD",MEDICAL PHYSICS,,
24,Inverse Design of Solid-State Materials via a Continuous Representation,1,5,1370-1384,"Noh Juhwan,Kim Jaehoon,Stein Helge S.,Sanchez-Lengeling Benjamin,Gregoire John M.,Aspuru-Guzik Alan,Jung Yousung","Noh J,Kim J,Stein HS,Sanchez-Lengeling B,Gregoire JM,Aspuru-Guzik A,Jung Y",Jung Y,10.1016/j.matt.2019.08.017,Korea Advanced Institute of Science & Technology (KAIST),"The non-serendipitous discovery of materials with targeted properties is the ultimate goal of materials research, but to date, materials design lacks the incorporation of all available knowledge to plan the synthesis of the next material. This work presents a framework for learning a continuous representation of materials and building a model for new discovery using latent space representation. The ability of autoencoders to generate experimental materials is demonstrated with vanadium oxides via rediscovery of experimentally known structures when the model was trained without them. Approximately 20,000 hypothetical materials are generated, leading to several completely new metastable VxOy materials that may be synthesizable. Comparison with genetic algorithms suggests computational efficiency of generative models that can explore chemical compositional space effectively by learning the distributions of known materials for crystal structure prediction. These results are an important step toward machine-learned inverse design of inorganic functional materials using generative models.","CRYSTAL-STRUCTURE,NEURAL-NETWORKS,SMALL MOLECULES,DATABASE,DISCOVERY,GENERATION,PREDICTION,STABILITY,MODELS",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,15.589,"CRYSTAL-STRUCTURE,NEURAL-NETWORKS,SMALL,MOLECULES,DATABASE,DISCOVERY,GENERATION,PREDICTION,STABILITY,MODELS",MATTER,https://www.cell.com/matter/pdf/S2590-2385(19)30175-4.pdf,
25,Towards a generalised development of synthetic CT images and assessment of their dosimetric accuracy,59,2,180-187,"Handrack Josefine,Bangert Mark,Moehler Christian,Bostel Tilman,Greilich Steffen","Handrack J,Bangert M,Mohler C,Bostel T,Greilich S",Handrack J,10.1080/0284186X.2019.1684558,Helmholtz Association,"Background: The interest in generating ""synthetic computed tomography (CT) images"" from magnetic resonance (MR) images has been increasing over the past years due to advances in MR guidance for radiotherapy. A variety of methods for synthetic CT creation have been developed, from simple bulk density assignment to complex machine learning algorithms. Material and methods: In this study, we present a general method to determine simplistic synthetic CTs and evaluate them according to their dosimetric accuracy. It separates the requirements on the MR image and the associated calculation effort to generate a synthetic CT. To evaluate the significance of the dosimetric accuracy under realistic conditions, clinically common uncertainties including position shifts and Hounsfield lookup table (HLUT) errors were simulated. To illustrate our approach, we first translated CT images from a test set of six pelvic cancer patients to relative electron density (ED) via a clinical HLUT. For each patient, seven simplified ED images (simED) were generated at different levels of complexity, ranging from one to four tissue classes. Then, dose distributions optimised on the reference ED image and the simEDs were compared to each other in terms of gamma pass rates (2 mm/2% criteria) and dose volume metrics. Results: For our test set, best results were obtained for simEDs with four tissue classes representing fat, soft tissue, air, and bone. For this simED, gamma pass rates of 99.95% (range: 99.72-100%) were achieved. The decrease in accuracy from ED simplification was smaller in this case than the influence of the uncertainty scenarios on the reference image, both for gamma pass rates and dose volume metrics. Conclusions: The presented workflow helps to determine the required complexity of synthetic CTs with respect to their dosimetric accuracy. The investigated cases showed potential simplifications, based on which the synthetic CT generation could be faster and more reproducible.","ATTENUATION CORRECTION,ONLY RADIOTHERAPY,DOSE CALCULATION,MRI,GENERATION,WORKFLOW",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Oncology,,,"ATTENUATION,CORRECTION,ONLY,RADIOTHERAPY,DOSE,CALCULATION,MRI,GENERATION,WORKFLOW",ACTA ONCOLOGICA,https://www.tandfonline.com/doi/pdf/10.1080/0284186X.2019.1684558?needAccess=true,
26,A machine-learning approach to predict postprandial hypoglycemia,19,1,,"Seo Wonju,Lee You-Bin,Lee Seunghyun,Jin Sang-Man,Park Sung-Min","Seo W,Lee YB,Lee S,Jin SM,Park SM",Park SM,10.1186/s12911-019-0943-4,Pohang University of Science & Technology (POSTECH),"Background For an effective artificial pancreas (AP) system and an improved therapeutic intervention with continuous glucose monitoring (CGM), predicting the occurrence of hypoglycemia accurately is very important. While there have been many studies reporting successful algorithms for predicting nocturnal hypoglycemia, predicting postprandial hypoglycemia still remains a challenge due to extreme glucose fluctuations that occur around mealtimes. The goal of this study is to evaluate the feasibility of easy-to-use, computationally efficient machine-learning algorithm to predict postprandial hypoglycemia with a unique feature set. Methods We use retrospective CGM datasets of 104 people who had experienced at least one hypoglycemia alert value during a three-day CGM session. The algorithms were developed based on four machine learning models with a unique data-driven feature set: a random forest (RF), a support vector machine using a linear function or a radial basis function, a K-nearest neighbor, and a logistic regression. With 5-fold cross-subject validation, the average performance of each model was calculated to compare and contrast their individual performance. The area under a receiver operating characteristic curve (AUC) and the F1 score were used as the main criterion for evaluating the performance. Results In predicting a hypoglycemia alert value with a 30-min prediction horizon, the RF model showed the best performance with the average AUC of 0.966, the average sensitivity of 89.6%, the average specificity of 91.3%, and the average F1 score of 0.543. In addition, the RF showed the better predictive performance for postprandial hypoglycemic events than other models. Conclusion In conclusion, we showed that machine-learning algorithms have potential in predicting postprandial hypoglycemia, and the RF model could be a better candidate for the further development of postprandial hypoglycemia prediction algorithm to advance the CGM technology and the AP technology further.","Hypoglycemia,Risk prediction,Diabetes",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Medical Informatics,,3.394,"ARTIFICIAL,PANCREAS,GLUCOSE,PREDICTION,GLYCEMIC,CONTROL,TIME,ALGORITHM,SAFETY",BMC MEDICAL INFORMATICS AND DECISION MAKING,https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/s12911-019-0943-4,
27,A data-driven approach to predicting diabetes and cardiovascular disease with machine learning,19,1,,"Dinh An,Miertschin Stacey,Young Amber,Mohanty Somya D.","Dinh A,Miertschin S,Young A,Mohanty SD",Mohanty SD,10.1186/s12911-019-0918-5,University of North Carolina,"Background Diabetes and cardiovascular disease are two of the main causes of death in the United States. Identifying and predicting these diseases in patients is the first step towards stopping their progression. We evaluate the capabilities of machine learning models in detecting at-risk patients using survey data (and laboratory results), and identify key variables within the data contributing to these diseases among the patients. Methods Our research explores data-driven approaches which utilize supervised machine learning models to identify patients with such diseases. Using the National Health and Nutrition Examination Survey (NHANES) dataset, we conduct an exhaustive search of all available feature variables within the data to develop models for cardiovascular, prediabetes, and diabetes detection. Using different time-frames and feature sets for the data (based on laboratory data), multiple machine learning models (logistic regression, support vector machines, random forest, and gradient boosting) were evaluated on their classification performance. The models were then combined to develop a weighted ensemble model, capable of leveraging the performance of the disparate models to improve detection accuracy. Information gain of tree-based models was used to identify the key variables within the patient data that contributed to the detection of at-risk patients in each of the diseases classes by the data-learned models. Results The developed ensemble model for cardiovascular disease (based on 131 variables) achieved an Area Under - Receiver Operating Characteristics (AU-ROC) score of 83.1% using no laboratory results, and 83.9% accuracy with laboratory results. In diabetes classification (based on 123 variables), eXtreme Gradient Boost (XGBoost) model achieved an AU-ROC score of 86.2% (without laboratory data) and 95.7% (with laboratory data). For pre-diabetic patients, the ensemble model had the top AU-ROC score of 73.7% (without laboratory data), and for laboratory based data XGBoost performed the best at 84.4%. Top five predictors in diabetes patients were 1) waist size, 2) age, 3) self-reported weight, 4) leg length, and 5) sodium intake. For cardiovascular diseases the models identified 1) age, 2) systolic blood pressure, 3) self-reported weight, 4) occurrence of chest pain, and 5) diastolic blood pressure as key contributors. Conclusion We conclude machine learned models based on survey questionnaire can provide an automated identification mechanism for patients at risk of diabetes and cardiovascular diseases. We also identify key contributors to the prediction, which can be further explored for their implications on electronic health records.","Machine learning,Health analytics,Ensemble learning,Feature learning",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Medical Informatics,,3.394,"ISCHEMIC-HEART-DISEASE,RISK-FACTOR,REGRESSION,CHOLESTEROL,DIAGNOSIS,GLUCOSE",BMC MEDICAL INFORMATICS AND DECISION MAKING,https://europepmc.org/articles/pmc6836338?pdf=render,
28,Automatic control of cardiac ablation catheter with deep reinforcement learning method,33,11,5415-5423,"You Hyeonseok,Bae EunKyung,Moon Youngjin,Kweon Jihoon,Choi Jaesoon","You H,Bae E,Moon Y,Kweon J,Choi J",Choi J,10.1007/s12206-019-1036-0,University of Ulsan,"To reduce the radiation exposure of personnel during an interventional procedure for arrhythmia, a robot has been developed and implemented herein for use in interventional procedures. Studies on the control of an electrophysiology catheter by robots are being conducted. However, controlling a catheter using a robot has limited precision owing to external forces subjected on the catheter due to blood flow and pulse inside a heart. This study implements a reinforcement learning method for automated control of a catheter by a robot. Using the reinforcement learning method, this study aims to show that such a robot can learn to manipulate a catheter to reach a target in a simulated environment and subsequently control a catheter in an actual environment. Randomization noise is used during the simulation to reduce the differences between the simulation and actual learning environments. Each environment is implemented with different movement values depending on insertion angles and steps of the catheter model. When the results from the simulated learning model are implemented in the actual environment, the success rate of catheter reaching the designated target is 73 %. In addition, the noise-implemented model shows that the success rate can be increased up to 87 %. Through these experiments, the study verifies that a simulated learning model can be implemented in a robot system to control an actual catheter as well as that the success rate of the model can be increased using randomization noise.","Catheter control,Deep learning,Reinforcement learning,Catheter simulation",Article,"KOREAN SOC MECHANICAL ENGINEERS, KSTC NEW BLD. 7TH FLOOR, 635-4 YEOKSAM-DONG KANGNAM-KU, SEOUL 135-703, SOUTH KOREA",Engineering,,,MOTION,JOURNAL OF MECHANICAL SCIENCE AND TECHNOLOGY,,
29,Data driven modeling of magnetism in dilute magnetic semiconductors: correlation between the magnetic features of diluted magnetic semiconductors and electronic properties of the constituent atoms,31,44,,"Khmaissia Fadoua,Frigui Hichem,Andriotis Antonis N.,Menon Madhu","Khmaissia F,Frigui H,Andriotis AN,Menon M",Khmaissia F,10.1088/1361-648X/ab31d6,University of Louisville,"We propose an efficient machine learning based approach in modeling the magnetism of diluted magnetic semiconductors (DMSs) leading to the prediction of new compounds with enhanced magnetic properties.
The approach combines accurate ab initio methods with statistical tools to uncover the correlation between the magnetic features of DMSs and electronic properties of the constituent atoms to determine the underlying factors responsible for the DMS-magnetism. Taking the electronic properties of different DMS systems as descriptors to train different regression models allows us to achieve a speed up of several orders of magnitude in the search for an optimum combination of the host semiconductor and the dopants with enhanced magnetic properties. We demonstrate this by analyzing a large set of descriptors for a wide range of systems and show that only 30% of these features are more likely to contribute to this property.
We also show that training regression models with the reduced set of features to predict the total magnetic moment of new candidate DMSs has reduced the mean square error by about 20% compared to the models trained using the whole set of features. Furthermore, our results indicate that the predictive power of our method can be improved even more by extending our descriptor set.","machine learning,defect-induced magnetism,dilute magnetic semiconductors,feature selection,linear regression",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,2.887,"TEMPERATURE,FERROMAGNETISM,SELECTION,OXIDE,ZNO",JOURNAL OF PHYSICS-CONDENSED MATTER,,
30,,,,,,,,,,,,,,,,,,,,
31,Qualitative classification of waste textiles based on near infrared spectroscopy and the convolutional network,90,9-10,1057-1066,"Liu Zhengdong,Li Wenxia,Wei Zihan","Liu ZD,Li WX,Wei ZH",Li WX,10.1177/0040517519886032,Beijing Institute of Fashion Technology,"The recycling of waste textiles has become a growth point for the sustainable development of the textile and clothing industry. In addition, sorting is a key link in the follow-up recycling process. Since different fabrics are required to be processed by different technologies, manual sorting not only takes time and effort but also cannot achieve accurate and reliable classification. Based on the analysis of near infrared spectroscopy, the theory and methods of deep learning are used for the qualitative classification of waste textiles in order to complete the automatic fabric composition recognition in the sorting process. Firstly, a standard sample set is established by waveform clipping and normalization, and a Textile Recycling Net deep web suitable for near infrared spectroscopy is established. Then, a pixilated layer is used to facilitate the deep learning of features, and the multidimensional features of the spectrum are extracted by using the multi-layer convolutional and pooling layers. Finally, the softmax classifier is adopted to complete the qualitative classification. Experimental results show that the convolutional network classification method using normalized and pixelated near infrared spectroscopy can realize the automatic classification of several common textiles, such as cotton and polyester, and effectively improve the detection level and speed of fabric components.","near infrared spectroscopy,waste textile recycling,convolutional neural network",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Materials Science,,2.057,"QUANTITATIVE-DETERMINATION,NIR,SPECTROPHOTOMETRY,IDENTIFICATION,FIBERS,BLENDS,WOOL",TEXTILE RESEARCH JOURNAL,,
32,A hybrid intelligence technique based on the Taguchi method for multi-objective process parameter optimization of the 3D additive screen printing of athletic shoes,90,9-10,1067-1083,"Wang Yacheng,Liu Yuegang,Sun Yize","Wang YC,Liu YG,Sun YZ",Sun YZ,10.1177/0040517519886073,Donghua University,"This paper presents a hybrid intelligence technique based on the Taguchi method for multi-objective process parameter optimization of 3D additive screen printing of athletic shoes. 3D additive screen printing is mainly used in the high-end athletic shoes and clothes field. It requires overlapping and overprinting dozens of times to make the printed patterns stereoscopic. The process of 3D additive screen printing is complex and variable and the production cycle is long. Because of the variability of the screen printing process and the coupling between process parameters, there is no simple method to guide the trial production of new products and obtain the optimal process parameters of screen printing. Trial-and-error is often used but it expends a lot of manpower, materials, and financial resources. To solve the optimization problem, a Taguchi experiment based on fuzzy comprehensive evaluation with five factors and two responses was first designed. Then, a back-propagation network (BPN), least-squares support-vector machine (LSSVM), and random forest (RF) were trained with experimental data to obtain a forecasting model for the process parameters. On comparison, the RF forecasting model performed best in this case. Then, the multi-objective antlion optimizer (MOALO), which is a new multi-objective optimization algorithm with excellent performance, was improved to the IMOALO, and it was proved that IMOALO has a better performance than MOALO. Combining the RF forecasting model with IMOALO, and carrying out the optimization, the optimal process parameters were obtained. Actual printing production shows that the proposed hybrid intelligence technique improves the production efficiency and first pass yield of printed products.","printing,product design,production,Systems,Product and Systems Engineering",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Materials Science,,2.057,"ANT,LION,OPTIMIZATION,NEURAL-NETWORK,ALGORITHM,PREDICTION,DESIGN,MODEL,PASTE",TEXTILE RESEARCH JOURNAL,,
33,SC3: self-configuring classifier combination for obstructive sleep apnea,32,24,17825-17841,"Mostafa Sheikh Shanawaz,Mendonca Fabio,Julia-Serda Gabriel,Morgado-Dias Fernando,Ravelo-Garcia Antonio G.","Mostafa SS,Mendonca F,Julia-Serda G,Morgado-Dias F,Ravelo-Garcia AG",Mostafa SS,10.1007/s00521-019-04582-2,Universidade de Lisboa,"Obstructive sleep apnea is considered to be one of the most prevalent sleep-related disorders that can affect the general population. However, the gold standard for the diagnosis, polysomnography, is an expensive and complicated process that is commonly unavailable to a large group of the population. Alternatively, automatic approaches have been developed to address this issue. One of the goals of this research is to perform the classification of the apnea events with the lowest possible number of sensors. Therefore, the blood oxygen saturation signal was employed in this work since it is correlated with the occurrence of apnea events and it can be measured from a single noninvasive sensor. The events detection was performed by a combination of classifiers. However, choosing the type of classifier to combine and select the most relevant features for each classifier is considered to be a well-known problem in the field of machine learning. A self-configuring classifier combination technique based on genetic algorithms was developed for multiple classifiers and features selection which was tested along with different databases and input sizes. The best performance for obstructive sleep apnea detection was achieved using maximum voting independent feature selection with 1 min time window having the best sensitivity of 82.48% similar database in the literature. This model was later tested on another database for cross-database accuracy. With an average accuracy of 91.33%, the system proved its capabilities for clinical diagnosis since the model was developed and validated with both subject and database independence.","Combined classifiers,Sleep apnea,Genetic algorithm,Machine learning",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"OXYGEN-SATURATION,FEATURE-SELECTION,OXIMETRY,RISK",NEURAL COMPUTING & APPLICATIONS,,
34,Review: Materials Ecosystem for Additive Manufacturing Powder Bed Fusion Processes,72,1,561-576,"Poorganji Behrang,Ott Eric,Kelkar Rajandra,Wessman Andrew,Jamshidinia Mahdi","Poorganji B,Ott E,Kelkar R,Wessman A,Jamshidinia M",Poorganji B,10.1007/s11837-019-03892-z,"Gen Elect Addit, 9701 Windisch Rd, West Chester, OH 45069 USA.","Additive manufacturing technologies are revolutionizing modern component design across many industries, while leading to an evolution in materials science and engineering. Understanding and controlling the materials ecosystem in additive manufacturing is an essential factor for successful adoption. The relationships among materials chemistry, powder characteristics, processes and final part performance are key and crucial concepts in additive manufacturing technologies. Powder bed fusion (PBF) processes including laser and electron beam melting processes are fundamentally based on controlling the solid-to-liquid and liquid-to-solid phase transformations in each process layer. The powder characteristics, evolution of the microstructure through the additive manufacturing process and subsequent metallurgical post-processing are primarily responsible for material performance. A more comprehensive understanding of aspects such as powder characteristics, liquid- and solid-phase transformations, and the effects of repeated thermal cycling on metallurgical structure development will be required to effectively apply a design-for-additive approach. Numerical modeling and machine learning are among tools that can be used for developing such understanding. This article will provide a review and summary of the materials ecosystem for additive manufacturing powder bed fusion processes.","BULK METALLIC-GLASS,LASER SCAN STRATEGY,HIGH-ENTROPY ALLOYS,MECHANICAL-PROPERTIES,THERMOMECHANICAL MODEL,GRAIN-STRUCTURE,MELT FLOW,MICROSTRUCTURE,SIMULATION,PERSPECTIVES",Review,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA","Materials Science,Metallurgy & Metallurgical Engineering,Mineralogy,Mining & Mineral Processing",,2.989,"BULK,METALLIC-GLASS,LASER,SCAN,STRATEGY,HIGH-ENTROPY,ALLOYS,MECHANICAL-PROPERTIES,THERMOMECHANICAL,MODEL,GRAIN-STRUCTURE,MELT,FLOW,MICROSTRUCTURE,SIMULATION,PERSPECTIVES",JOM,,
35,Radiogenomics of lower-grade gliomas: machine learning-based MRI texture analysis for predicting 1p/19q codeletion status,30,2,877-886,"Kocak Burak,Durmaz Emine Sebnem,Ates Ece,Sel Ipek,Gunes Saime Turgut,Kaya Ozlem Korkmaz,Zeynalova Amalya,Kilickesmez Ozgur","Kocak B,Durmaz ES,Ates E,Sel I,Gunes ST,Kaya OK,Zeynalova A,Kilickesmez O",Kocak B,10.1007/s00330-019-06492-2,Istanbul Training & Research Hospital,"Objective To evaluate the potential value of the machine learning (ML)-based MRI texture analysis for predicting 1p/19q codeletion status of lower-grade gliomas (LGG), using various state-of-the-art ML algorithms. Materials and methods For this retrospective study, 107 patients with LGG were included from a public database. Texture features were extracted from conventional T2-weighted and contrast-enhanced T1-weighted MRI images, using LIFEx software. Training and unseen validation splits were created using stratified 10-fold cross-validation technique along with minority over-sampling. Dimension reduction was done using collinearity analysis and feature selection (ReliefF). Classifications were done using adaptive boosting, k-nearest neighbours, naive Bayes, neural network, random forest, stochastic gradient descent, and support vector machine. Friedman test and pairwise post hoc analyses were used for comparison of classification performances based on the area under the curve (AUC). Results Overall, the predictive performance of the ML algorithms were statistically significantly different, chi 2(6) = 26.7, p < 0.001. There was no statistically significant difference among the performance of the neural network, naive Bayes, support vector machine, random forest, and stochastic gradient descent, adjusted p > 0.05. The mean AUC and accuracy values of these five algorithms ranged from 0.769 to 0.869 and from 80.1 to 84%, respectively. The neural network had the highest mean rank with mean AUC and accuracy values of 0.869 and 83.8%, respectively. Conclusions The ML-based MRI texture analysis might be a promising non-invasive technique for predicting the 1p/19q codeletion status of LGGs. Using this technique along with various ML algorithms, more than four-fifths of the LGGs can be correctly classified.","Artificial intelligence,Machine learning,Radiomics,Glioma,Mutation",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,4.87,"IMAGES,IDH,CLASSIFICATION,INFORMATION,FEATURES,TUMORS",EUROPEAN RADIOLOGY,,
36,Identification of emergent constraints and hidden order in frustrated magnets using tensorial kernel methods of machine learning,100,17,,"Greitemann Jonas,Liu Ke,Jaubert Ludovic D. C.,Yan Han,Shannon Nic,Pollet Lode","Greitemann J,Liu K,Jaubert LDC,Yan H,Shannon N,Pollet L",Liu K,10.1103/PhysRevB.100.174408,University of Munich,"Machine-learning techniques have proved successful in identifying ordered phases of matter. However, it remains an open question how far they can contribute to the understanding of phases without broken symmetry, such as spin liquids. Here we demonstrate how a machine-learning approach can automatically learn the intricate phase diagram of a classical frustrated spin model. The method we employ is a support vector machine equipped with a tensorial kernel and a spectral graph analysis which admits its applicability in an effectively unsupervised context. Thanks to the interpretability of the machine we are able to infer, in closed form, both order parameter tensors of phases with broken symmetry, and the local constraints which signal an emergent gauge structure, and so characterize classical spin liquids. The method is applied to the classical XXZ model on the pyrochlore lattice where it distinguishes, among others, between a hidden biaxial spin-nematic phase and several different classical spin liquids. The results are in full agreement with a previous analysis by Taillefumier et al. [Phys. Rev. X 7, 041057 (2017)], but go further by providing a systematic hierarchy between disordered regimes, and establishing the physical relevance of the susceptibilities associated with the local constraints. Our work paves the way for the search of new orders and spin liquids in generic frustrated magnets.","SPIN ICE,ANTIFERROMAGNETISM,MONOPOLES,ENTROPY,LIQUID",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,"SPIN,ICE,ANTIFERROMAGNETISM,MONOPOLES,ENTROPY,LIQUID",PHYSICAL REVIEW B,https://hal.archives-ouvertes.fr/hal-02265929/document,
37,Evaluation of Texture Analysis for the Differential Diagnosis of Mass-Forming Pancreatitis From Pancreatic Ductal Adenocarcinoma on Contrast-Enhanced CT Images,9,,,"Ren Shuai,Zhang Jingjing,Chen Jingya,Cui Wenjing,Zhao Rui,Qiu Wenli,Duan Shaofeng,Chen Rong,Chen Xiao,Wang Zhongqiu","Ren S,Zhang JJ,Chen JY,Cui WJ,Zhao R,Qiu WL,Duan SF,Chen R,Chen X,Wang ZQ",Wang ZQ,10.3389/fonc.2019.01171,Nanjing University of Chinese Medicine,"Purpose: To investigate the potential of computed tomography (CT) imaging features and texture analysis to differentiate between mass-forming pancreatitis (MFP) and pancreatic ductal adenocarcinoma (PDAC). Materials and Methods: Thirty patients with pathologically proved MFP and 79 patients with PDAC were included in this study. Clinical data and CT imaging features of the two lesions were evaluated. Texture features were extracted from arterial and portal phase CT images using commercially available software (AnalysisKit). Multivariate logistic regression analyses were used to identify relevant CT imaging and texture parameters to discriminate MFP from PDAC. Receiver operating characteristic curves were performed to determine the diagnostic performance of predictions. Results: MFP showed a larger size compared to PDAC (p = 0.009). Cystic degeneration, pancreatic ductal dilatation, vascular invasion, and pancreatic sinistral portal hypertension were more frequent and duct penetrating sign was less frequent in PDAC compared to MFP. Arterial CT attenuation, arterial, and portal enhancement ratios of MFP were higher than PDAC (p < 0.05). In multivariate analysis, arterial CT attenuation and pancreatic duct penetrating sign were independent predictors. Texture features in arterial phase including SurfaceArea, Percentile40, InverseDifferenceMoment_angle90_offset4, LongRunEmphasis_angle45_offset4, and uniformity were independent predictors. Texture features in portal phase including LongRunEmphasis_angle135_offset7, VoxelValueSum, LongRunEmphasis_angle135_offset4, and GLCMEntropy_angle45_offset1 were independent predictors. Areas under the curve of imaging feature-based, texture feature-based in arterial and portal phases, and the combined models were 0.84, 0.96, 0.93, and 0.98, respectively. Conclusions: CT texture analysis demonstrates great potential to differentiate MFP from PDAC.","pancreatic ductal adenocarcinoma,chronic pancreatitis,computed tomography,texture analysis,machine learning",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Oncology,,6.264,"AUTOIMMUNE,PANCREATITIS,CARCINOMA,CANCER,MRI",FRONTIERS IN ONCOLOGY,https://doi.org/10.3389/fonc.2019.01171,
38,High critical transition temperature of lead-based perovskite ferroelectric crystals: A machine learning study,68,21,,"Yang Zi-Xin,Gao Zhang-Ran,Sun Xiao-Fan,Cai Hong-Ling,Zhang Feng-Ming,Wu Xiao-Shan","Yang ZX,Gao ZR,Sun XF,Cai HL,Zhang FM,Wu XS",Wu XS,10.7498/aps.68.20190942,Nanjing University,"Ferroelectrics undergoes a reversible structural phase from the ferroelectric phase to the paraelectric phase when its temperature exceeds the critical temperature namely Curie temperature T-c. As ferro-paraelectric phase transition is always accompanied by heat-flow, dielectric and pyroelectric anomaly, the value of T-c is extremely important for ferroelectrics. In this paper, the Curie temperature of lead-based perovskite ferroelectric solid solution is studied by machine learning methods including kernel ridge regression (KRR), support vector regression (SVR) and extremely randomized trees regression (ETR). We collect the T-c values of 205 different lead-based perovskites from published experimental papers, both simple perovskites with only one type of B site ion and complex perovskites with up to 5 kinds of ions in B position such as PMN-PFN-PZT are gathered. The diversity of our dataset is guaranteed for the good generalization of our model in perovskite solid solution of different complexity. The features are constructed from the physical and chemical properties of the B site elements in corresponding materials. The weighted-average and variance of the elemental properties are calculated and fed to machine learning models. We use the 5 runs of ten fold cross-validation method to evaluate the machine learning models. The hyperparameters are also chosen carefully with the cross-validation to avoid over fitting. The radial basis function kernel is used in both KRR and SVR. The insensitive error in the SVR is set to be 4 which is comparable to the random error in experiment. From our cross-validation, we find that the mean average errors (MAEs) between the predicted and experimental values of the machine learning methods are 14.4 K, 14.7 K, and 16.1 K, respectively. And the root-mean-square errors (RMSEs) are 22.5 K, 23.4 K, 23.8 K, respectively. After the optimization and the evaluation, our three machine learning models are stacked together by averaging the output of each regression model and thus building an ensemble model. The MAE of the ensemble model is 13.9 K. The RMSE of the ensemble model is 21.4 K. The predicted values keep a correlation coefficient of 0.97 with the experimental values. From the variance reduction in ETR, we derive the importance of our features when determining the Curie temperatures. The five most important factors in our ETR model are ""weighted-average thermal conductivity"" , ""weighted-average conductivity"" , ""variance of specific heat capacity"", ""weighted-average element number"", and ""weighted-average relative atomic displacement"". We predict the Curie temperatures higher than those of 200000 types of lead-based perovskites after being trained. Now, we provide two ferroelectric materials that may have high Curie temperatures: 0.02PbMn(1/)(2)Nb(1/2)O(3)-0.98PbTiO(3) (0.02PMN-0.98PT) and 0.02PbGa(1/2)Nb(1/2)-0.02PbMn(1/)(2)Nb(1/2)O(3)-0.96PbTiO(3) (0.02PGN-0.02PMN-0.96PT). The predicted Curie temperatures of them are 481 degrees C and 466 degrees C, respectively.","machine learning,ferroelectric,Curie temperature,perovskite",Article,"CHINESE PHYSICAL SOC, P O BOX 603, BEIJING 100080, PEOPLES R CHINA",Physics,,0.618,"ELECTRICAL-PROPERTIES,DIELECTRIC-PROPERTIES,SINGLE-CRYSTAL,GROWTH,SEARCH,SYSTEM",ACTA PHYSICA SINICA,https://doi.org/10.7498/aps.68.20190942,
39,How to achieve auto-identification in Raman analysis by spectral feature extraction & Adaptive Hypergraph,222,,,"Xie Yi,You Qiaobei,Dai Pingyang,Wang Shuyi,Hong Peiyi,Liu Guokun,Yu Jun,Sun Xilong,Zeng Yongming","Xie Y,You QB,Dai PY,Wang SY,Hong PY,Liu GK,Yu J,Sun XL,Zeng YM",Liu GK,10.1016/j.saa.2019.04.078,Xiamen University,"With the miniaturization of Raman spectrometers, Raman spectroscopy (including Surface-enhanced Raman spectroscopy) has been widely applied to various fields, especially towards rapid detection applications. In order to deal with the accompanied massive databases, large numbers of Raman spectra require to be handled and identified in an effective and automatic manner. This paper proposes an algorithm of material auto-identification, which makes use of machine learning methods to analyze Raman spectra. Firstly, a universal method of spectral feature extraction is designed to automatically process Raman spectra after the background subtraction. Secondly, the extracted feature vectors are used to classify and identify target materials by Adaptive Hypergraph (AH), an efficient classifier in the field of machine learning, in a manner of automation with an accuracy rate of similar to 99%. Compared with Support Vector Machine (SVM) and Random Forest (RF), two typical methods of classification, the AH classifier provides better performance free of tuning any parameter facing different targets. Thirdly, Cubic Spline Interpolation is introduced to enhance the universal of the proposed algorithm between different databases from different Raman spectrometers with variant vendors. The identification accuracy rate is up to 98% using the high frequency sampling spectra as the learning and the low frequency sampling ones as the testing, respectively. (C) 2019 Elsevier B.V. All rights reserved.","Raman spectroscopy,Adaptive Hypergraph,Automation",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Spectroscopy,,3.464,"SPECTROSCOPY,CLASSIFICATION,MACHINE,SERS",SPECTROCHIMICA ACTA PART A-MOLECULAR AND BIOMOLECULAR SPECTROSCOPY,,
40,Can past failures help identify vulnerable bridges to extreme events? A biomimetical machine learning approach,37,2,1099-1131,Naser M. Z.,Naser MZ,Naser MZ,10.1007/s00366-019-00874-2,Clemson University,"With limited resources to properly maintain and upgrade transportation infrastructure, bridges often end up exceeding their expected service lifespan; thus, becoming vulnerable to the adverse effects of aging and extreme loading conditions. In order to better assess the vulnerability of these structures, this study showcases the outcome of an observational analysis that utilizes biomimetical (bio-inspired) machine learning algorithms to predict the vulnerability and expected degree of damage in bridges in the aftermath of an extreme loading event (such as fire, flood, earthquake, etc.). These algorithms comprise deep learning, decision tree, genetic algorithm and genetic programing and were trained and validated using 299 international incidents covering a wide variety of bridge systems/configurations, traffic demands, etc. Based on this analysis, user-friendly assessment tools that can be used to evaluate propensity of a given bridge to undergo high levels of damage and/or collapse are developed. These tools can aid designers and decision-makers in evaluating performance of new or existing bridges against a variety of hazards, as well as in developing relevant design strategies for mitigating disaster-induced failures as to minimize disruptions to supply chain operations and/or evacuations during an emergency.","Bridges,Machine learning,Collapse,Extreme events,Classification",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Computer Science,Engineering",,6.544,"CONSTRUCTION,MATERIALS,MATERIAL,MODELS,FIRE",ENGINEERING WITH COMPUTERS,,
41,Detection and classification of lung nodules in chest X-ray images using deep convolutional neural networks,36,2,370-401,"Mendoza Julio,Pedrini Helio","Mendoza J,Pedrini H",Pedrini H,10.1111/coin.12241,Universidade Estadual de Campinas,"Lung nodule classification is one of the main topics related to computer-aided detection systems. Although convolutional neural networks (CNNs) have been demonstrated to perform well on many tasks, there are few explorations of their use for classifying lung nodules in chest X-ray (CXR) images. In this work, we proposed and analyzed a pipeline for detecting lung nodules in CXR images that includes lung area segmentation, potential nodule localization, and nodule candidate classification. We presented a method for classifying nodule candidates with a CNN trained from the scratch. The effectiveness of our method relies on the selection of data augmentation parameters, the design of a specialized CNN architecture, the use of dropout regularization on the network, inclusive in convolutional layers, and addressing the lack of nodule samples compared to background samples balancing mini-batches on each stochastic gradient descent iteration. All model selection decisions were taken using a CXR subset of the Lung Image Database Consortium and Image Database Resource Initiative dataset separately. Thus, we used all images with nodules in the Japanese Society of Radiological Technology dataset for evaluation. Our experiments showed that CNNs were capable of achieving competitive results when compared to state-of-the-art methods. Our proposal obtained an area under the free-response receiver operating characteristic curve of 7.76 considering 10 false positives per image (FPPI), and sensitivity values of 73.1% and 79.6% with 2 and 5 FPPI, respectively.","chest X-ray images,computer-aided diagnosis,deep convolutional neural networks,lung nodules",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Computer Science,,2.016,"COMPUTER-AIDED,DIAGNOSIS,RADIOGRAPHS,CANCER,SEGMENTATION,SCHEME,FUSION,MODELS,SYSTEM",COMPUTATIONAL INTELLIGENCE,,
42,Incorporating prior shape knowledge via data-driven loss model to improve 3D liver segmentation in deep CNNs,15,2,249-257,"Mohagheghi Saeed,Foruzan Amir Hossein","Mohagheghi S,Foruzan AH",Foruzan AH,10.1007/s11548-019-02085-y,Shahed University,"Purpose Convolutional neural networks (CNNs) have obtained enormous success in liver segmentation. However, there are several challenges, including low-contrast images, and large variations in the shape, and appearance of the liver. Incorporating prior knowledge in deep CNN models improves their performance and generalization. Methods A convolutional denoising auto-encoder is utilized to learn global information about 3D liver shapes in a low-dimensional latent space. Then, the deep data-driven knowledge is used to define a loss function and combine it with the Dice loss in the main segmentation model. The resultant hybrid model would be forced to learn the global shape information as prior knowledge, while it tries to produce accurate results and increase the Dice score. Results The proposed training strategy improved the performance of the 3D U-Net model and reached the Dice score of 97.62% on the Sliver07-I liver dataset, which is competitive to the state-of-the-art automatic segmentation methods. The proposed algorithm enhanced the generalization and robustness of the hybrid model and outperformed the 3D U-Net model in the prediction of unseen images. Conclusions The results indicate that the incorporation of prior shape knowledge enhances liver segmentation tasks in deep CNN models. The proposed method improves the generalization and robustness of the hybrid model due to the abstract features provided by the data-driven loss model.","Deep learning,Convolutional neural network,3D liver segmentation,Prior knowledge",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,,INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
43,Fusion of medical images using deep belief networks,23,2,1439-1453,"Kaur Manjit,Singh Dilbag","Kaur M,Singh D",Singh D,10.1007/s10586-019-02999-x,Manipal University Jaipur,"Image fusion plays a significant role in various computer vision applications. However, designing an efficient image fusion technique is still a challenging task. In this paper, a novel deep belief networks based image fusion framework is proposed to improve the performance of the image fusion process further. We have initially, evaluated the fusion dataset by applying various feature extraction techniques. Thereafter, features selection techniques are applied to select potential features. Finally, the image fusion machine learning model is built by using a deep belief network model. Extensive experiments reveal that the proposed technique outperforms existing image fusion techniques.","Image fusion,Deep belief networks,Medical images,Fuzzy rules",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,1.906,"FEATURES,FUZZY,CLASSIFICATION,TRANSFORM,SYSTEM,MODEL",CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS,,
44,High on/off ratio black phosphorus based memristor with ultra-thin phosphorus oxide layer,115,19,,"Wang Yudan,Wu Facai,Liu Xingqiang,Lin Jun,Chen Jui-Yuan,Wu Wen-Wei,Wei Jingsong,Liu Yuan,Liu Qi,Liao Lei","Wang YD,Wu FC,Liu XQ,Lin J,Chen JY,Wu WW,Wei JS,Liu Y,Liu Q,Liao L",Liu XQ; Liao L,10.1063/1.5115531,Hunan University,"The scaling down of switching media encounters high leakage current in the traditional oxide material based memristors, resulting in high power consumption of chips. Two-dimensional (2D) materials promise an ultimate device scaling down to atomic layer thickness. Herein, black phosphorus (BP) and its self-assembly phosphorous oxide (BP) memristors are constructed, which leverages the high on/off ratio operation of oxides and low leakage current of 2D materials with high performance. The memristors exhibit reproducible and reliable switching characteristics with the on/off ratio >10(7) and data retention >10(4) s. Depending on the high reproducibility, basic ""AND"" and ""OR"" gates have been constructed on flexible substrates. Moreover, on the basis of the symmetry and linearity of conductance in the devices, the neural network simulation for supervised learning presents an online learning accuracy of 91.4%. This work opens an avenue for future flexible electronics.",GRAPHENE,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,3.596,GRAPHENE,APPLIED PHYSICS LETTERS,,
45,A method for the automated classification of benign and malignant masses on digital breast tomosynthesis images using machine learning and radiomic features,13,1,27-36,"Sakai Ayaka,Onishi Yuya,Matsui Misaki,Adachi Hidetoshi,Teramoto Atsushi,Saito Kuniaki,Fujita Hiroshi","Sakai A,Onishi Y,Matsui M,Adachi H,Teramoto A,Saito K,Fujita H",Teramoto A,10.1007/s12194-019-00543-5,Fujita Health University,"In digital mammography, which is used for the early detection of breast tumors, oversight may occur due to overlap between normal tissues and lesions. However, since digital breast tomosynthesis can acquire three-dimensional images, tissue overlapping is reduced, and, therefore, the shape and distribution of the lesions can be easily identified. However, it is often difficult to distinguish between benign and malignant breast lesions on images, and the diagnostic accuracy can be reduced due to complications from radiological interpretations, owing to acquisition of a higher number of images. In this study, we developed an automated classification method for diagnosing breast lesions on digital breast tomosynthesis images using radiomics to comprehensively analyze the radiological images. We extracted an analysis area centered on the lesion and calculated 70 radiomic features, including the shape of the lesion, existence of spicula, and texture information. The accuracy was compared by inputting the obtained radiomic features to four classifiers (support vector machine, random forest, naive Bayes, and multi-layer perceptron), and the final classification result was obtained as an output using a classifier with high accuracy. To confirm the effectiveness of the proposed method, we used 24 cases with confirmed pathological diagnosis on biopsy. We also compared the classification results based on the presence or absence of dimension reduction using least absolute shrinkage and a selection operator (LASSO). As a result, when the support vector machine was used as a classifier, the correct identification rate of the benign tumors was 55% and that of malignant tumors was 84%, with best results. These results indicate that the proposed method may help in more accurately diagnosing cases that are difficult to classify on images.","Breast cancer,Tomosynthesis,Image analysis,Radiomics",Article,"SPRINGER JAPAN KK, SHIROYAMA TRUST TOWER 5F, 4-3-1 TORANOMON, MINATO-KU, TOKYO, 105-6005, JAPAN","Radiology, Nuclear Medicine & Medical Imaging",,,"CANCER,DIAGNOSIS,MAMMOGRAPHY,NODULES,FILTERS",RADIOLOGICAL PHYSICS AND TECHNOLOGY,,
46,Detecting compensatory movements of stroke survivors using pressure distribution data and machine learning algorithms,16,1,,"Cai Siqi,Li Guofeng,Zhang Xiaoya,Huang Shuangyuan,Zheng Haiqing,Ma Ke,Xie Longhan","Cai SQ,Li GF,Zhang XY,Huang SY,Zheng HQ,Ma K,Xie LH",Xie LH,10.1186/s12984-019-0609-6,South China University of Technology,"Background Compensatory movements are commonly employed by stroke survivors during seated reaching and may have negative effects on their long-term recovery. Detecting compensation is useful for coaching the patient to reduce compensatory trunk movements and improving the motor function of the paretic arm. Sensor-based and camera-based systems have been developed to detect compensatory movements, but they still have some limitations, such as causing object obstructions, requiring complex setups and raising privacy concerns. To overcome these drawbacks, this paper proposes a compensatory movement detection system based on pressure distribution data and is unobtrusive, simple and practical. Machine learning algorithms were applied to classify compensatory movements automatically. Therefore, the purpose of this study was to develop and test a pressure distribution-based system for the automatic detection of compensation movements of stroke survivors using machine learning algorithms. Methods Eight stroke survivors performed three types of reaching tasks (back-and-forth, side-to-side, and up-and-down reaching tasks) with both the healthy side and the affected side. The pressure distribution data were recorded, and five features were extracted for classification. The k-nearest neighbor (k-NN) and support vector machine (SVM) algorithms were applied to detect and categorize the compensatory movements. The surface electromyography (sEMG) signals of nine trunk muscles were acquired to provide a detailed description and explanation of compensatory movements. Results Cross-validation yielded high classification accuracies (F1-score>0.95) for both the k-NN and SVM classifiers in detecting compensation movements during all the reaching tasks. In detail, an excellent performance was achieved in discriminating between compensation and noncompensation (NC) movements, with an average F1-score of 0.993. For the multiclass classification of compensatory movement patterns, an average F1-score of 0.981 was achieved in recognizing the NC, trunk lean-forward (TLF), trunk rotation (TR) and shoulder elevation (SE) movements. Conclusions Good classification performance in detecting and categorizing compensatory movements validated the feasibility of the proposed pressure distribution-based system. Reliable classification accuracy achieved by the machine learning algorithms indicated the potential to monitor compensation movements automatically by using the pressure distribution-based system when stroke survivors perform seated reaching tasks.","Stroke,Reaching,Machine learning,Classification,Pressure",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Engineering,Neurosciences & Neurology,Rehabilitation",,5.218,"TRUNK-RESTRAINT,SHOULDER,REHABILITATION,CLASSIFICATION,INDIVIDUALS,RELIABILITY,POSTSTROKE,PATTERNS,RECOVERY,SIGNALS",JOURNAL OF NEUROENGINEERING AND REHABILITATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6829931,
47,Language impairment in adults with end-stage liver disease: application of natural language processing towards patient-generated health records,2,,,"Dickerson Lindsay K.,Rouhizadeh Masoud,Korotkaya Yelena,Bowring Mary Grace,Massie Allan B.,McAdams-Demarco Mara A.,Segev Dorry L.,Cannon Alicia,Guerrerio Anthony L.,Chen Po-Hung","Dickerson LK,Rouhizadeh M,Korotkaya Y,Bowring MG,Massie AB,McAdams-Demarco MA,Segev DL,Cannon A,Guerrerio AL,Chen PH",Mogul DB,10.1038/s41746-019-0179-9,Johns Hopkins University,"End-stage liver disease (ESLD) is associated with cognitive impairment ranging from subtle alterations in attention to overt hepatic encephalopathy that resolves after transplant. Natural language processing (NLP) may provide a useful method to assess cognitive status in this population. We identified 81 liver transplant recipients with ESLD (4/2013-2/2018) who sent at least one patient-to-provider electronic message pre-transplant and post-transplant, and matched them 1:1 to ""healthy"" controls-who had similar disease, but had not been evaluated for liver transplant-by age, gender, race/ethnicity, and liver disease. Messages written by patients pre-transplant and post-transplant and controls was compared across 19 NLP measures using paired Wilcoxon signed-rank tests. While there was no difference overall in word length, patients with Model for End-Stage Liver Disease Score (MELD) >= 30 (n = 31) had decreased word length in pre-transplant messages (3.95 [interquartile range (IQR) 3.79, 4.14]) compared to post-transplant (4.13 [3.96, 4.28], p = 0.01) and controls (4.2 [4.0, 4.4], p = 0.01); there was no difference between post-transplant and controls (p = 0.4). Patients with MELD >= 30 had fewer 6+ letter words in pre-transplant messages (19.5% [16.4, 25.9] compared to post-transplant (23.4% [20.0, 26.7] p= 0.02) and controls (25.0% [19.2, 29.4]; p= 0.01). Overall, patients had increased sentence length pretransplant (12.0 [9.8, 13.7]) compared to post-transplant (11.0 [9.2, 13.3]; p = 0.046); the same was seen for MELD >= 30 (12.3 [9.8, 13.7] pre-transplant vs. 10.8 [9.6, 13.0] post-transplant; p = 0.050). Application of NLP to patient-generated messages identified language differences-longer sentences with shorter words-that resolved after transplant. NLP may provide opportunities to detect cognitive impairment in ESLD.","MINIMAL HEPATIC-ENCEPHALOPATHY,CIRRHOSIS,SPEECH,DEMENTIA,PATTERNS,AMMONIA",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Health Care Sciences & Services,Medical Informatics",,11.665,"MINIMAL,HEPATIC-ENCEPHALOPATHY,CIRRHOSIS,SPEECH,DEMENTIA,PATTERNS,AMMONIA",NPJ DIGITAL MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6828779,
48,Theoretical analysis and mathematical modeling of deformation and stresses of the grooving tool,32,14,10481-10500,"Kurt Abdullah,Bakir Serkan","Kurt A,Bakir S",Kurt A,10.1007/s00521-019-04588-w,Gazi University,"Machining operations involving complex multivariate parameters are defined by many machining parameters. Correct selection of these parameters is crucial for an efficient and economical cutting operation. The grooving operation required in many cases is one of the most problematic methods in all metal cutting operations, especially in terms of chip control. This paper covers theoretical analysis and mathematical modeling of deformation and stresses of the grooving tool. Cutting forces affecting the service life of the grooving tool were measured by various cutting experiments. Deformation and stresses of grooving tool caused by cutting forces were analyzed by finite element method using Ansys software. In modeling with artificial neural networks (ANN), grooving insert width, cutting speed, feed rate, radial force and primary cutting force are inputs in the model and deformation and stresses of the grooving tool are outputs. An algorithm, which is a Matlab script file, was developed to determine the optimal combination of neural network parameters such as the normalization method, number of hidden neurons, transfer function and training algorithm. The best-fitting set determined by the algorithm developed for the model was achieved with the Levenberg-Marquardt backpropagation algorithm, logistic sigmoid transfer function, nine hidden neurons and normalization method with a scaling factor. The MSE, R-2, MAPE values of the ANN model are 2.0327 x 10(-6), 0.999992 and 0.379227, respectively. Performance results have shown that the proposed approach can also be used for ANN modeling of machining parameters in other cutting operations other than grooving.","Machining,Grooving tool,Cutting parameters,Finite element method,Artificial neural networks",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,,,NEURAL COMPUTING & APPLICATIONS,,
49,Machine Learning Models for Analysis of Vital Signs Dynamics: A Case for Sepsis Onset Prediction,2019,,,"Bloch Eli,Rotem Tammy,Cohen Jonathan,Singer Pierre,Aperstein Yehudit","Bloch E,Rotem T,Cohen J,Singer P,Aperstein Y",Aperstein Y,10.1155/2019/5930379,"Afeka Acad Coll Engn, Dept Software Engn, Tel Aviv, Israel.","Objective. Achieving accurate prediction of sepsis detection moment based on bedside monitor data in the intensive care unit (ICU). A good clinical outcome is more probable when onset is suspected and treated on time, thus early insight of sepsis onset may save lives and reduce costs. Methodology. We present a novel approach for feature extraction, which focuses on the hypothesis that unstable patients are more prone to develop sepsis during ICU stay. These features are used in machine learning algorithms to provide a prediction of a patient's likelihood to develop sepsis during ICU stay, hours before it is diagnosed. Results. Five machine learning algorithms were implemented using R software packages. The algorithms were trained and tested with a set of 4 features which represent the variability in vital signs. These algorithms aimed to calculate a patient's probability to become septic within the next 4 hours, based on recordings from the last 8 hours. The best area under the curve (AUC) was achieved with Support Vector Machine (SVM) with radial basis function, which was 88.38%. Conclusions. The high level of predictive accuracy along with the simplicity and availability of input variables present great potential if applied in ICUs. Variability of a patient's vital signs proves to be a good indicator of one's chance to become septic during ICU stay.","HEART-RATE-VARIABILITY,PHYSIOLOGICAL VARIABILITY,APPROXIMATE ENTROPY,ORGAN FAILURE,DEFINITIONS,GUIDELINES,ACCURACY",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Health Care Sciences & Services,,3.188,"HEART-RATE-VARIABILITY,PHYSIOLOGICAL,VARIABILITY,APPROXIMATE,ENTROPY,ORGAN,FAILURE,DEFINITIONS,GUIDELINES,ACCURACY",JOURNAL OF HEALTHCARE ENGINEERING,https://downloads.hindawi.com/journals/jhe/2019/5930379.pdf,
50,Automated Breast Cancer Diagnosis Based on Machine Learning Algorithms,2019,,,"Dhahri Habib,Al Maghayreh Eslam,Mahmood Awais,Elkilani Wail,Nagi Mohammed Faisal","Dhahri H,Al Maghayreh E,Mahmood A,Elkilani W,Nagi MF",Dhahri H,10.1155/2019/4253641,King Saud University,"There have been several empirical studies addressing breast cancer using machine learning and soft computing techniques. Many claim that their algorithms are faster, easier, or more accurate than others are. This study is based on genetic programming and machine learning algorithms that aim to construct a system to accurately differentiate between benign and malignant breast tumors. The aim of this study was to optimize the learning algorithm. In this context, we applied the genetic programming technique to select the best features and perfect parameter values of the machine learning classifiers. The performance of the proposed method was based on sensitivity, specificity, precision, accuracy, and the roc curves. The present study proves that genetic programming can automatically find the best model by combining feature preprocessing methods and classifier algorithms.","FEATURE-SELECTION,REPRESENTATION,CLASSIFICATION,SEGMENTATION,EXTRACTION,FEATURES",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Health Care Sciences & Services,,3.188,"FEATURE-SELECTION,REPRESENTATION,CLASSIFICATION,SEGMENTATION,EXTRACTION,FEATURES",JOURNAL OF HEALTHCARE ENGINEERING,https://downloads.hindawi.com/journals/jhe/2019/4253641.pdf,
51,Lesion classification in mammograms using convolutional neural networks and transfer learning,7,5-6,550-556,"Perre Ana C.,Alexandre Luis A.,Freire Luis C.","Perre AC,Alexandre LA,Freire LC",Perre AC,10.1080/21681163.2018.1498392,Universidade da Beira Interior,"Convolutional neural networks (CNNs) have recently been successfully used in the medical field to detect and classify pathologies in different imaging modalities, including in mammography. One disadvantage of CNNs is the need for large training datasets, which are particularly difficult to obtain in the medical domain. One way to solve this problem is using a transfer learning approach, in which a CNN, previously pre-trained with a large amount of labelled non-medical data, is subsequently fine-tuned using a smaller dataset of medical data. In this paper, we use such a transfer learning approach, which is applied to three different networks that were pre-trained using the Imagenet dataset. We investigate how the performance of these pre-trained CNNs to classify lesions in mammograms is affected by the use, or not, of normalised images during the fine-tuning stage. We also assess the performance of a support vector machine fed with features extracted from the CNN and the combined use of handcrafted features to complement the CNN-extracted features. The obtained results are encouraging.","Mammographic image,convolutional neural network,transfer learning,support vector machine,breast cancer,lesion classification",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,,"COMPUTER-AIDED,DETECTION,BREAST-CANCER,DIAGNOSIS",COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION,https://ubibliorum.ubi.pt/bitstream/10400.6/8144/1/Lesion%20classification%20in%20mammograms%20using%20convolutional%20neural%20networks%20and%20transfer%20learning.pdf,
52,A deep learning approach for diagnosing schizophrenic patients,31,6,803-816,"Srinivasagopalan Srivathsan,Barry Justin,Gurupur Varadraj,Thankachan Sharma","Srinivasagopalan S,Barry J,Gurupur V,Thankachan S",Barry J,10.1080/0952813X.2018.1563636,State University System of Florida,"In this article, the investigators present a new method using a deep learning approach to diagnose schizophrenia. In the experiment presented, the investigators used a secondary dataset provided by The National Institute of Health. The experimentation involves analyzing this dataset for the existence of schizophrenia using traditional machine learning approaches such as logistic regression, support vector machine, and random forest. This is followed by the application of deep learning techniques using three hidden layers in the model. The results obtained indicate that the new deep learning technique formulated by the investigators provide a higher accuracy in diagnosing schizophrenia. These results suggest that deep learning may provide a paradigm shift in diagnosing schizophrenia.","Schizophrenia,fMRI,deep learning,random forest,SVM",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Computer Science,,2.199,,JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE,,
53,Detection of Fusarium Head Blight in Wheat Using a Deep Neural Network and Color Imaging,11,22,,"Qiu Ruicheng,Yang Ce,Moghimi Ali,Zhang Man,Steffenson Brian J.,Hirsch Cory D.","Qiu RC,Yang C,Moghimi A,Zhang M,Steffenson BJ,Hirsch CD",Yang C,10.3390/rs11222658,University of Minnesota System,"Fusarium head blight (FHB) is a devastating disease of wheat worldwide. In addition to reducing the yield of the crop, the causal pathogens also produce mycotoxins that can contaminate the grain. The development of resistant wheat varieties is one of the best ways to reduce the impact of FHB. To develop such varieties, breeders must expose germplasm lines to the pathogen in the field and assess the disease reaction. Phenotyping breeding materials for resistance to FHB is time-consuming, labor-intensive, and expensive when using conventional protocols. To develop a reliable and cost-effective high throughput phenotyping system for assessing FHB in the field, we focused on developing a method for processing color images of wheat spikes to accurately detect diseased areas using deep learning and image processing techniques. Color images of wheat spikes at the milk stage were collected in a shadow condition and processed to construct datasets, which were used to retrain a deep convolutional neural network model using transfer learning. Testing results showed that the model detected spikes very accurately in the images since the coefficient of determination for the number of spikes tallied by manual count and the model was 0.80. The model was assessed, and the mean average precision for the testing dataset was 0.9201. On the basis of the results for spike detection, a new color feature was applied to obtain the gray image of each spike and a modified region-growing algorithm was implemented to segment and detect the diseased areas of each spike. Results showed that the region growing algorithm performed better than the K-means and Otsu's method in segmenting diseased areas. We demonstrated that deep learning techniques enable accurate detection of FHB in wheat based on color image analysis, and the proposed method can effectively detect spikes and diseased areas, which improves the efficiency of the FHB assessment in the field.","fusarium head blight disease,color imaging,deep neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Geology,Remote Sensing,Imaging Science & Photographic Technology",,5.353,"HYPERSPECTRAL,MEASUREMENTS,YELLOW,RUST,RESISTANCE,KERNELS,DISEASES",REMOTE SENSING,https://www.mdpi.com/2072-4292/11/22/2658/pdf,
54,Siamese Reconstruction Network: Accurate Image Reconstruction from Human Brain Activity by Learning to Compare,9,22,,"Jiang Lingyun,Qiao Kai,Wang Linyuan,Zhang Chi,Chen Jian,Zeng Lei,Bu Haibing,Yan Bin","Jiang LY,Qiao K,Wang LY,Zhang C,Chen J,Zeng L,Bu HB,Yan B",Yan B,10.3390/app9224749,"PLA Strateg Support Force Informat Engn Univ, Zhengzhou 450001, Henan, Peoples R China.","Featured Application
This study can be used in brain decoding, to calculate the brain perceived visual information.
Abstract Decoding human brain activities, especially reconstructing human visual stimuli via functional magnetic resonance imaging (fMRI), has gained increasing attention in recent years. However, the high dimensionality and small quantity of fMRI data impose restrictions on satisfactory reconstruction, especially for the reconstruction method with deep learning requiring huge amounts of labelled samples. When compared with the deep learning method, humans can recognize a new image because our human visual system is naturally capable of extracting features from any object and comparing them. Inspired by this visual mechanism, we introduced the mechanism of comparison into deep learning method to realize better visual reconstruction by making full use of each sample and the relationship of the sample pair by learning to compare. In this way, we proposed a Siamese reconstruction network (SRN) method. By using the SRN, we improved upon the satisfying results on two fMRI recording datasets, providing 72.5% accuracy on the digit dataset and 44.6% accuracy on the character dataset. Essentially, this manner can increase the training data about from n samples to 2n sample pairs, which takes full advantage of the limited quantity of training samples. The SRN learns to converge sample pairs of the same class or disperse sample pairs of different class in feature space.","brain decoding,visual reconstruction,functional magnetic resonance imaging,Siamese neural network,deep learning,learning to compare",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,,"FMRI,ACTIVITY,STATES",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/9/22/4749/pdf,
55,Intelligent Glioma Grading Based on Deep Transfer Learning of MRI Radiomic Features,9,22,,"Lo Chung-Ming,Chen Yu-Chih,Weng Rui-Cian,Hsieh Kevin Li-Chun","Lo CM,Chen YC,Weng RC,Hsieh KLC",Hsieh KLC,10.3390/app9224926,Taipei Medical University,"Featured Application Authors are encouraged to provide a concise description of the specific application or a potential application of the work. This section is not mandatory.
Abstract According to a classification of central nervous system tumors by the World Health Organization, diffuse gliomas are classified into grade 2, 3, and 4 gliomas in accordance with their aggressiveness. To quantitatively evaluate a tumor's malignancy from brain magnetic resonance imaging, this study proposed a computer-aided diagnosis (CAD) system based on a deep convolutional neural network (DCNN). Gliomas from a multi-center database (The Cancer Imaging Archive) composed of a total of 30 grade 2, 43 grade 3, and 57 grade 4 gliomas were used for the training and evaluation of the proposed CAD. Using transfer learning to fine-tune AlexNet, a DCNN, its internal layers, and parameters trained from a million images were transferred to learn how to differentiate the acquired gliomas. Data augmentation was also implemented to increase possible spatial and geometric variations for a better training model. The transferred DCNN achieved an accuracy of 97.9% with a standard deviation of +/- 1% and an area under the receiver operation characteristics curve (Az) of 0.9991 +/- 0, which were superior to handcrafted image features, the DCNN without pretrained features, which only achieved a mean accuracy of 61.42% with a standard deviation of +/- 7% and a mean Az of 0.8222 +/- 0.07, and the DCNN without data augmentation, which was the worst with a mean accuracy of 59.85% with a standard deviation +/- 16% and a mean Az of 0.7896 +/- 0.18. The DCNN with pretrained features and data augmentation can accurately and efficiently classify grade 2, 3, and 4 gliomas. The high accuracy is promising in providing diagnostic suggestions to radiologists in the clinic.","glioblastoma,magnetic resonance imaging,deep convolutional neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"HEALTH-ORGANIZATION,CLASSIFICATION,DIAGNOSIS,ASTROCYTOMA,TEXTURE,TUMORS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/9/22/4926/pdf,
56,Automated Identification of Wood Veneer Surface Defects Using Faster Region-Based Convolutional Neural Network with Data Augmentation and Transfer Learning,9,22,,"Urbonas Augustas,Raudonis Vidas,Maskeliunas Rytis,Damasevicius Robertas","Urbonas A,Raudonis V,Maskeliunas R,Damasevicius R",Damasevicius R,10.3390/app9224898,Silesian University of Technology,"In the lumber and wood processing industry, most visual quality inspections are still done by trained human operators. Visual inspection is a tedious and repetitive task that involves a high likelihood of human error. Currently, new automated solutions with high-resolution cameras and visual inspection algorithms are being tested, but they are not always fast and accurate enough for real-time industrial applications. This paper proposes an automatic visual inspection system for the location and classification of defects on the wood surface. We adopted a faster region-based convolutional neural network (faster R-CNN) for the identification of defects on wood veneer surfaces. Faster R-CNN has been successfully used in medical image processing and object tracking before, but it has not yet been applied for wood panel surface quality assurance. To improve the results, we used pre-trained AlexNet, VGG16, BNInception, and ResNet152 neural network models for transfer learning. The results of the experiments using a synthetically augmented dataset are presented. The best average accuracy of 80.6% was obtained using the pretrained ResNet152 neural network model. By combining all the defect classes, a 96.1% accuracy of finding wood panel surface defects was achieved.","defect detection,quality control,wood veneer,data augmentation,transfer learning,faster R-CNN,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"CLASSIFICATION,INSPECTION",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/9/22/4898/pdf,
57,Artificial Neural Network in Fibres Length Prediction for High Precision Control of Cellulose Refining,12,22,,"Almonti Daniele,Baiocco Gabriele,Tagliaferri Vincenzo,Ucciardello Nadia","Almonti D,Baiocco G,Tagliaferri V,Ucciardello N",Ucciardello N,10.3390/ma12223730,University of Rome Tor Vergata,"Paper, a web of interconnected cellulose fibres, is widely used as a base substrate. It has been applied in several applications since it features interesting properties, such as renewability, biodegradability, recyclability, affordability and mechanical flexibility. Furthermore, it offers a broad possibility to modify its surface properties toward specifics additives. The fillers retention and the fibres bonding ability are heavily affected by the cellulose refining process that influences chemical and morphological features of the fibres. Several refining theories were developed in order to determine the best refining conditions. However, it is not trivial to control the cellulose refining as different phenomena occur simultaneously. Therefore, it is intuitively managed by experienced papermakers to improve paper structures and properties. An approach based on the machine learning aimed at estimating the effects of refining on the fibres morphology is proposed in this study. In particular, an artificial neural network (ANN) was implemented and trained with experimental data to predict the fibres length as a function of refining process variables. The prediction of this parameter is crucial to obtain a high-performance process in terms of effectiveness and the optimisation of the final product performance as a function of the process parameter. To achieve these results, data mining of the experimental patterns collected was exploited. It led to the achievement of excellent performance and high accuracy in fibres length prediction.","artificial neural networks,machine learning,cellulose fibres processing,process management,refining optimisation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"PAPER,SURFACES,FORCES,DESIGN,WATER",MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6888444,
58,Effects of Servo Tensile Test Parameters on Mechanical Properties of Medium-Mn Steel,12,22,,"Chi Xuemin,Han Shuo","Chi XM,Han S",Chi XM,10.3390/ma12223793,Dalian University of Technology,"As a new type of third-generation automotive steel with high strength and plasticity, medium-Mn steel (MMnS) has been widely used in automotive industries for its excellent properties. In recent years, servo stamping technology for high-strength metal forming is a hot topic due to its good performance in forming under complex processing conditions, and servo parameters determine the forming quality. In this paper, experiments considering tensile speed and position where speed changes (PSC) were carried out on MMnS to investigate the influences of tensile parameters on mechanical properties including strength and total elongation (TE). The results show that PSC does not significantly impact total elongation. Initial tensile speed (ITS) and final tensile speed (FTS) significantly impact the total elongation. The interaction between all tensile parameters can impact total elongation. Two artificial neural networks, back propagation neural network (BPNN) and radial basis function neural network (RBFNN), were used to establish analytical models. The results of supplemental experiment and residual analysis were conducted to verify the accuracy of the analytical models. The BPNN has a better performance and the analytical model shows that with the increase of PSC, it has a slight impact on the changes of optimal and minimum total elongation, but the combinations of tensile parameters to obtain total elongations higher than 40% change significantly.","total elongation,medium-Mn steel,servo tensile parameters,artificial neural networks",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,,"BLANK-HOLDER,FORCE,HIGH-STRENGTH,TRANSFORMATION,SPRINGBACK,BEHAVIOR,MODEL",MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6888167,
59,Learned Prediction of Compressive Strength of GGBFS Concrete Using Hybrid Artificial Neural Network Models,12,22,,"Han In-Ji,Yuan Tian-Feng,Lee Jin-Young,Yoon Young-Soo,Kim Joong-Hoon","Han IJ,Yuan TF,Lee JY,Yoon YS,Kim JH",Yoon YS; Kim JH,10.3390/ma12223708,Korea University,"A new hybrid intelligent model was developed for estimating the compressive strength (CS) of ground granulated blast furnace slag (GGBFS) concrete, and the synergistic benefits of the hybrid algorithm as compared with a single algorithm were verified. While using the collected 269 data from previous experimental studies, artificial neural network (ANN) models with three different learning algorithms namely back-propagation (BP), particle swarm optimization (PSO), and new hybrid PSO-BP algorithms, were constructed and the performance of the models was evaluated with regard to the prediction accuracy, efficiency, and stability through a threefold procedure. It was found that the PSO-BP neural network model was superior to the simple ANNs that were trained by a single algorithm and it is suitable for predicting the CS of GGBFS concrete.","ground granulated blast furnace slag concrete,artificial neural network,particle swarm optimization,back-propagation,hybrid PSO-BP",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"BLAST-FURNACE,SLAG,SWARM,OPTIMIZATION,ALGORITHM,SILICA,FUME,BRICK,AGGREGATE,EFFICIENCY,RESISTANCE,DESIGN,SYSTEM,STEEL",MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6888290,
60,Prediction of Cyclic Stress-Strain Property of Steels by Crystal Plasticity Simulations and Machine Learning,12,22,,"Miyazawa Yuto,Briffod Fabien,Shiraiwa Takayuki,Enoki Manabu","Miyazawa Y,Briffod F,Shiraiwa T,Enoki M",Shiraiwa T,10.3390/ma12223668,University of Tokyo,"In this study, a method for the prediction of cyclic stress-strain properties of ferrite-pearlite steels was proposed. At first, synthetic microstructures were generated based on an anisotropic tessellation from the results of electron backscatter diffraction (EBSD) analyses. Low-cycle fatigue experiments under strain-controlled conditions were conducted in order to calibrate material property parameters for both an anisotropic crystal plasticity and an isotropic J(2) model. Numerical finite element simulations were conducted using these synthetic microstructures and material properties based on experimental results, and cyclic stress-strain properties were calculated. Then, two-point correlations of synthetic microstructures were calculated to quantify the microstructures. The microstructure-property dataset was obtained by associating a two-point correlation and calculated cyclic stress-strain property. Machine learning, such as a linear regression model and neural network, was conducted using the dataset. Finally, cyclic stress-strain properties were predicted from the result of EBSD analysis using the obtained machine learning model and were compared with the results of the low-cycle fatigue experiments.","steels,fatigue,cyclic stress-strain curve,crystal plasticity,artificial neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"FATIGUE-CRACK,INITIATION,LOCALIZED,DEFORMATION,MICROSTRUCTURE,TEXTURE",MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6888044,
61,Smart connected electronic gastroscope system for gastric cancer screening using multi-column convolutional neural networks,57,21,6795-6806,"Wang Hao,Ding Shuai,Wu Desheng,Zhang Youtao,Yang Shanlin","Wang H,Ding S,Wu DS,Zhang YT,Yang SL",Ding S; Yang SL,10.1080/00207543.2018.1464232,Hefei University of Technology,"Gastroscopy is a widely adopted method for gastric cancer screening and early diagnosis. Clinical studies show that it can effectively prolong patient life and maximise therapeutic effect. However, it is difficult for doctors to identify and detect lesions in real time, which manifests as the major challenge in gastroscopy. In this paper, we propose SCEG, a smart connected electronic gastroscopy system that performs dynamic cancer screening in gastroscopy. By integrating electronic gastroscopy with cloud-based medical image analysis service, we develop an AdaBoost-based multi-column convolutional neural network (MCNN) for enhancing gastric cancer screening. Experimental results show that the proposed MCNN approach significantly outperforms other competing approaches.","artificial intelligence,decision support systems,complex product,endoscopy system,gastric cancer screening,convolutional neural network",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Engineering,Operations Research & Management Science",,6.715,STATISTICS,INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH,,
62,Simulation of bone fractures via geometric techniques: an overview,7,5-6,557-562,"Paulano Felix,Roberto Jimenez-Perez J.,Jimenez Juan J.","Paulano F,Jimenez-Perez JR,Jimenez JJ",Jimenez-Perez JR,10.1080/21681163.2018.1498393,Universidad de Jaen,"The simulation of realistic fracture cases on geometric models representing bone structures is almost an unexplored field of research. These fractured models have several applications in computer-assisted methods that support specialist in fracture reduction interventions. For instance, the generation of specific fracture patterns can provide uncommon cases for training simulators or can be used to improve machine-learning applications. This paper focuses on the issues to be considered in the generation of fractures on geometric models that represent bone structures. The main recent contributions for fracturing geometric models are examined and the challenges in terms of the application of real bone fracture patterns on geometric models are presented. Moreover, different alternatives for the evaluation of the results obtained by the geometric fracture generation algorithms when applied to bone structures are discussed. Finally, the potential applications of the virtual generation of specific bone fractures are described.","Bone fracture generation,geometric approaches",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,,"FINITE-ELEMENT,MODEL,FEMUR,CRACKS",COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION,,
63,A New Approach for Brain Tumor Segmentation and Classification Based on Score Level Fusion Using Transfer Learning,43,11,,"Amin Javeria,Sharif Muhammad,Yasmin Mussarat,Saba Tanzila,Anjum Muhammad Almas,Fernandes Steven Lawrence","Amin J,Sharif M,Yasmin M,Saba T,Anjum MA,Fernandes SL",Amin J,10.1007/s10916-019-1453-8,"Univ Wah, Dept Comp Sci, Wah, Pakistan.","Brain tumor is one of the most death defying diseases nowadays. The tumor contains a cluster of abnormal cells grouped around the inner portion of human brain. It affects the brain by squeezing/ damaging healthy tissues. It also amplifies intra cranial pressure and as a result tumor cells growth increases rapidly which may lead to death. It is, therefore desirable to diagnose/ detect brain tumor at an early stage that may increase the patient survival rate. The major objective of this research work is to present a new technique for the detection of tumor. The proposed architecture accurately segments and classifies the benign and malignant tumor cases. Different spatial domain methods are applied to enhance and accurately segment the input images. Moreover Alex and Google networks are utilized for classification in which two score vectors are obtained after the softmax layer. Further, both score vectors are fused and supplied to multiple classifiers along with softmax layer. Evaluation of proposed model is done on top medical image computing and computer-assisted intervention (MICCAI) challenge datasets i.e., multimodal brain tumor segmentation (BRATS) 2013, 2014, 2015, 2016 and ischemic stroke lesion segmentation (ISLES) 2018 respectively.","Brain tumor detection,Alex network,Google network,Fused score vector,Softmax layer,Segmentation,Classification",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA","Health Care Sciences & Services,Medical Informatics",,3.951,"STROKE,LESION,SEGMENTATION,NETWORKS,MODEL",JOURNAL OF MEDICAL SYSTEMS,,
64,Urine Sediment Recognition Method Based on Multi-View Deep Residual Learning in Microscopic Image,43,11,,"Zhang Xiaohong,Jiang Liqing,Yang Dongxu,Yan Jinyan,Lu Xinhong","Zhang XH,Jiang LQ,Yang DX,Yan JY,Lu XH",Lu XH,10.1007/s10916-019-1457-4,Jining Medical University,"Urine sediment recognition is attracting growing interest in the field of computer vision. A multi-view urine cell recognition method based on multi-view deep residual learning is proposed to solve some existing problems, such as multi-view cell gray change and cell information loss in the natural state. Firstly, the convolutional network is designed to extract the urine sediment features from different perspectives based on the residual network, and the depth-wise separable convolution is introduced to reduce the network parameters. Secondly, Squeeze-and-Excitation block is embedded to learn feature weights, using feature re-calibration to improve network representation, and the robustness of the network is enhanced by adding spatial pyramid pooling. Finally, for further optimizing the recognition results, the Adam with weight decay optimization method is used to accelerate the convergence of the network model. Experiments on self-built urine microscopic image data-set show that our proposed method has state-of-the-art classification accuracy and reduces network computing time.","Urine sediment,Deep residual,Multi-View learning,Squeeze-and-excitation,Convolutional network,Microscopic image",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Health Care Sciences & Services,Medical Informatics",,3.951,,JOURNAL OF MEDICAL SYSTEMS,,
65,A novel chaotic optimal foraging algorithm for unconstrained and constrained problems and its application in white blood cell segmentation,31,11,7633-7664,"Sayed Gehad Ismail,Solyman Mona,Hassanien Aboul Ella","Sayed GI,Solyman M,Hassanien AE",Solyman M,10.1007/s00521-018-3597-8,Egyptian Knowledge Bank (EKB),"Meta-heuristic is defined as an iterative generation process with some random characters, which aims to generate a sufficiently good solution(s) for the global optimization problems. The process of solving a global optimization problem with near-optimal solutions is based on combining in some intelligent way different methodologies for exploiting and exploring the search space and building a structure information through different learning strategies. Optimal foraging algorithm (OFA) is a robust meta-heuristic algorithm inspired by following the animal foraging behavior. Recently, chaos and meta-heuristics have been combined in different algorithms with the aim of overcoming the limitations of meta-heuristics. In this paper, a novel algorithm for combining chaos with OFA is presented. The presented chaotic optimal foraging algorithm (COFA) is introduced with a set of unconstrained and constrained optimization problems using different chaotic maps. The results show that the proposed COFA outperforms the standard OFA for these benchmarks regarding exploitation, exploration, the trajectory of foraging individuals, search history, fitness improvement of the population and convergence rate. The performance of COFA has also compared with other most recent and popular meta-heuristic algorithms proofing its superior. An application of white blood cell segmentation in microscopic images has been chosen, and the proposed chaotic optimal foraging algorithm has been applied to see its ability and accuracy to identify and segment the white blood cell for further diagnosis. According to the statistical analysis of objective values, COFA algorithm is more accurate and robust than original OFA algorithm. COFA proves its ability to converge to the optimal multiple thresholds level-based segmentation more accurate than OFA. The experimental results also show that the proposed COFA proves its high degree of stability compared with original OFA in finding optimal multiple threshold values.","Optimal foraging algorithm,Global optimization,Multi-level thresholding,Kapur's method,Chaos theory",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"PARTICLE,SWARM,OPTIMIZATION,SELECTION",NEURAL COMPUTING & APPLICATIONS,,
66,A proposal for distinguishing between bacterial and viral meningitis using genetic programming and decision trees,23,22,11775-11791,"D'Angelo Gianni,Pilla Raffaele,Tascini Carlo,Rampone Salvatore","D'Angelo G,Pilla R,Tascini C,Rampone S",Rampone S,10.1007/s00500-018-03729-y,University of Sannio,"Meningitis is an inflammation of the protective membranes covering the brain and the spinal cord. Meningitis can have different causes, and discriminating between meningitis etiologies is still considered a hard task, especially when some specific clinical parameters, mostly derived from blood and cerebrospinal fluid analysis, are not completely available. Although less frequent than its viral version, bacterial meningitis can be fatal, especially when diagnosis is delayed. In addition, often unnecessary antibiotic and/or antiviral treatments are used as a solution, which is not cost or health effective. In this work, we address this issue through the use of machine learning-based methodologies. We consider two distinct cases. In one case, we take into account both blood and cerebrospinal parameters; in the other, we rely exclusively on the blood data. As a result, we have rules and formulas applicable in clinical settings. Both results highlight that a combination of the clinical parameters is required to properly distinguish between the two meningitis etiologies. The results on standard and clinical datasets show high performance. The formulas achieve 100% of sensitivity in detecting a bacterial meningitis.","Meningitis,Meningitis etiology,Bacterial meningitis,Viral meningitis,Genetic programming,Symbolic regression,Decision rules,Machine learning,Decision tree,Neural network",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA",Computer Science,,3.518,"POLYMERASE-CHAIN-REACTION,HUMAN-IMMUNODEFICIENCY-VIRUS,NERVOUS-SYSTEM,INFECTION,CEREBROSPINAL-FLUID,UNITED-STATES,DIFFERENTIAL-DIAGNOSIS,NEISSERIA-MENINGITIDIS,HAEMOPHILUS-INFLUENZAE,TUBERCULOUS,MENINGITIS,ASEPTIC-MENINGITIS",SOFT COMPUTING,,
67,A locally weighted machine learning model for generalized prediction of drift capacity in seismic vulnerability assessments,34,11,935-950,"Luo Huan,Paal Stephanie German","Luo H,Paal SG",Paal SG,10.1111/mice.12456,Texas A&M University System,"Drift capacity of reinforced concrete (RC) columns is an important indicator to quantify the seismic vulnerability of RC frame buildings; however, it is challenging to accurately predict this value as the nonlinear behavior can vary greatly by column type. This article proposes a novel, local machine learning (ML) model, called locally weighted least squares support vector machines for regression (LWLS-SVMR), which integrates LS-SVMR and locally weighted training criteria to enhance and generalize the prediction of the drift capacity of RC columns, regardless of the type. A database of 160 circular RC columns covering flexure-, shear-, and flexure-shear-critical specimens was developed to train and test the proposed LWLS-SVMR. The proposed LWLS-SVMR was validated by comparison with popular existing global and local learning approaches as well as a traditional empirical equation, and the results demonstrated that the proposed LWLS-SVMR is superior to all other approaches and thus, is a promising artificial intelligence technique for enhancing the prediction of drift capacity, universally across RC flexure-, shear-, and flexure-shear-critical columns. The LWLS-SVMR exhibits capabilities which may yield it a feasible approach to predict complex, nonlinear behavior in a broad-spectrum manner.","SUPPORT VECTOR REGRESSION,DESIGN,OPTIMIZATION,PERFORMANCE,COLUMNS,SYSTEM",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Computer Science,Construction & Building Technology,Engineering,Transportation",,9.756,"SUPPORT,VECTOR,REGRESSION,DESIGN,OPTIMIZATION,PERFORMANCE,COLUMNS,SYSTEM",COMPUTER-AIDED CIVIL AND INFRASTRUCTURE ENGINEERING,,
68,Deep learning-based autonomous concrete crack evaluation through hybrid image scanning,18,5-6,1722-1737,"Jang Keunyoung,Kim Namgyu,An Yun-Kyu","Jang K,Kim N,An YK",An YK,10.1177/1475921718821719,Sejong University,"This article proposes a deep learning-based autonomous concrete crack detection technique using hybrid images. The hybrid images combining vision and infrared thermography images are able to improve crack detectability while minimizing false alarms. In particular, large-scale concrete-made infrastructures such as bridge and dam can be effectively inspected by spatially scanning the unmanned vehicle-mounted hybrid imaging system including a vision camera, an infrared camera, and a continuous-wave line laser. However, the expert-dependent decision-making for crack identification which has been widely used in industrial fields is often cumbersome, time-consuming, and unreliable. As a target concrete structure gets larger, automated decision-making becomes more desirable from the practical point of view. The proposed technique is able to achieve automated crack identification and visualization by transfer learning of a well-trained deep convolutional neural network, that is, GoogLeNet, while retaining the advantages of the hybrid images. The proposed technique is experimentally validated using a lab-scale concrete specimen with cracks of various sizes. The test results reveal that macro- and microcracks are automatically visualized while minimizing false alarms.","Concrete crack detection,deep convolutional neural network,hybrid image scanning,vision image,infrared thermography,structural health monitoring",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Engineering,Instruments & Instrumentation",,5.861,"LOCK-IN,THERMOGRAPHY,DAMAGE,DETECTION,SURFACE,INSPECTION",STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL,,
69,Videoscope-based inspection of turbofan engine blades using convolutional neural networks and image processing,18,5-6,2020-2039,"Kim Yong-Ho,Lee Jung-Ryul","Kim YH,Lee JR",Lee JR,10.1177/1475921719830328,Korea Advanced Institute of Science & Technology (KAIST),"A typical aircraft engine consists of fans, compressors, turbines, and so on, and each is made of multiple layers of blades. Discovering the site of damages among the large number of blades during aircraft engine maintenance is quite important. However, it is impossible to look directly into the engine unless it is disassembled. For this reason, optical equipment such as a videoscope is used to visually inspect the blades of an engine through inspection holes. The videoscope inspection method has some obvious drawbacks such as the long-time attention on microscopic video feed and high labor intensity. In this research, we developed a damage recognition algorithm using convolutional neural networks and some image-processing techniques related to feature point extraction and matching in order to improve the videoscope inspection method. The image-processing techniques were mainly used for the preprocessing of the videoscope images, from which a suspected damaged region is selected after the preprocessing. The suspected region is finally classified as damaged or normal by the pre-trained convolutional neural networks. We trained the convolutional neural networks 2000 times by using data from 380 images and calculated the classification accuracy using data from 40 images. After repeating the above procedure 50 times with the data randomly divided into training and test groups, an average classification accuracy of 95.2% for each image and a damage detectability of 100% in video were obtained. For verification of the proposed approach, the convolutional neural network part was compared with the traditional neural network, and the preprocessing was compared with the region proposal network of the faster region-based convolutional neural networks. In addition, we developed a platform based on the developed damage recognition algorithm and conducted field tests with a videoscope for a real engine. The damage detection AI platform was successfully applied to the inspection video probed in an in-service engine.","Turbofan engine,blade inspection,convolutional neural networks,image processing,videoscope",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Engineering,Instruments & Instrumentation",,5.861,"DAMAGE,DETECTION",STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL,,
70,Measurement of murine kidney functional biomarkers using DCE-MRI: A multi-slice TRICKS technique and semi-automated image processing algorithm,63,,226-234,"Jiang Kai,Tang Hui,Mishra Prasanna K.,Macura Slobodan I.,Lerman Lilach O.","Jiang K,Tang H,Mishra PK,Macura SI,Lerman LO",Lerman LO,10.1016/j.mri.2019.08.029,Mayo Clinic,"Purpose: To propose a rapid multi-slice T-1 measurement method using time-resolved imaging of contrast kinetics (TRICKS) and a semi-automated image processing algorithm for comprehensive assessment murine kidney function using dynamic contrast-enhanced MRI (DCE-MRI).
Methods: A multi-slice TRICKS sampling scheme was implemented in an established rapid T-1 measurement method. A semi-automated image-processing scheme employing basic image processing techniques and machine learning was developed to facilitate image analysis. Reliability of the multi-slice technique in measuring renal perfusion and glomerular filtration rate (GFR) was tested in normal mice (n = 7 for both techniques) by comparing to the validated single-slice technique. Utility of this method was demonstrated on mice after either sham surgery (n = 7) or induction of unilateral renal artery stenosis (RAS, n = 8). Renal functional parameters were extracted using a validated bi-compartment model.
Results: The TRICKS sampling scheme achieved an acceleration factor of 2.7, allowing imaging of eight axial slices at 1.23 s/scan. With the aid of the semi-automated scheme, image analysis required under 15-min for both kidneys per mouse. The multi-slice technique yielded renal perfusion and GFR values comparable to the single-slice technique. Model-fitted renal parameters successfully differentiated control and stenotic mouse kidneys, including renal perfusion (706.5 +/- 164.0 vs. 375.9 +/- 277.9 mL/100 g/min, P = 0.002), blood flow (1.6 +/- 0.4 vs. 0.7 +/- 0.7 mL/min, P < 0.001), and GFR (142.9 +/- 17.9 vs. 58.0 +/- 42.8 mu L/min, P < 0.001).
Conclusion: The multi-slice TRICKS-based DCE-MRI technique, with a semi-automated image processing scheme, allows rapid and comprehensive measurement of murine kidney function.","Dynamic contrast enhanced MRI,Time-resolved imaging of contrast kinetics,Kidney volume,Renal functional biomarkers,Machine learning",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.608,"CONTRAST-ENHANCED,MRI,GLOMERULAR-FILTRATION-RATE,RENAL,PERFUSION,MAGNETIC-RESONANCE,MOUSE,MYOCARDIUM,CLASSIFICATION,RENOGRAPHY,PERFORMANCE,DISEASE,BREAST",MAGNETIC RESONANCE IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6861697,
71,Optimal pile design of dolphin structure considering axial compressive pressure-bending moment ratio under offshore load conditions,233,4,1141-1153,"Shao Hailong,Lee Jongsoo","Shao H,Lee J",Lee J,10.1177/1475090218813598,Yonsei University,"This study proposes an optimal design of a dolphin structure under offshore load conditions such as berthing, mooring, wind, wave, and current loads. The design objective is to reduce the total weight of the pile structure by determining its diameter, thickness, and arraying direction with constraints of axial compressive pressure-bending moment ratio and total displacement. As design requirements, the stress has to be satisfied under the allowable compressive pressure-bending moment, and the total displacement of the steel piles should be less than 0.1m on the upper deck. The structural analysis data are generated using Box-Behnken design based on the design of experiments. In the meta-model-based approximate optimization process, the pressure-bending moment ratio and total displacement are expressed using a backpropagation neural network, and the structural weight of the pile is approximated via a second-order polynomial-based response surface model. Compared with the initial design, the optimal solution of the total weight of the steel piles reduces by 27.37% under the satisfied constraint conditions. For the post-optimization study, the optimal sensitivity analysis with respect to the seabed level is conducted.","Dolphin structure,steel pile,axial compressive pressure-bending moment ratio,regression method,approximate optimization,seabed sensitivity",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Engineering,,1.7,,PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART M-JOURNAL OF ENGINEERING FOR THE MARITIME ENVIRONMENT,,
72,Deep principal component analysis: An enhanced approach for structural damage identification,18,5-6,1444-1463,"Silva Moises,Santos Adam,Santos Reginaldo,Figueiredo Eloi,Sales Claudomiro,Costa Joao C. W. A.","Silva M,Santos A,Santos R,Figueiredo E,Sales C,Costa JCWA",Silva M,10.1177/1475921718799070,Universidade Federal do Para,"The structural health monitoring relies on the continuous observation of a dynamic system over time to identify its actual condition, detect abnormal behaviors, and predict future states. The regular changes in environmental factors have been reported as one of the main challenges for the application of structural health monitoring systems. These influences in the structural responses are in general nonlinear, affecting the damage-sensitive features in the most varied forms. The usual process to remove these normal changes is referred to as data normalization. In that regard, principal component analysis is probably the most studied algorithm in structural health monitoring, having numerous versions to learn strong nonlinear normal changes. However, in most cases, not all variability is properly accounted for via the existing nonlinear principal component analysis approaches, resulting in poor damage detection and quantification performances. In this article, a new paradigm based on deep principal component analysis, rooted in the deep learning field, is presented to overcome these limitations. This approach extracts the most salient underlying feature distributions by stacking multiple feedforward neural networks trained to learn an identity mapping of the input variables, where the network inputs are reproduced into the outputs. Similar to the traditional nonlinear principal component analysis-based approach, our approach identifies a nonlinear output-only model of an undamaged structure by comprising modal features into an internal bottleneck layer, which implicitly represents the independent environmental factors. The proposed technique is validated through the application on a progressively damaged prestressed concrete bridge and a three-span suspension bridge. The experimental results demonstrate that capturing the most slight nonlinear variations in the data can lead to improved data normalization and, consequently, better damage detection and quantification performances.","Structural health monitoring,deep learning,principal component analysis,data normalization,environmental variability,operational variability",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Engineering,Instruments & Instrumentation",,5.861,"VARYING,ENVIRONMENTAL-CONDITIONS,SWARM,OPTIMIZATION,NEURAL-NETWORKS,EXTRACTION,DIAGNOSIS,FEATURES",STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL,,
73,Automated Medical Diagnosis System Based on Multi-modality Image Fusion and Deep Learning,111,2,1033-1058,Algarni Abeer D.,Algarni AD,Algarni AD,10.1007/s11277-019-06899-6,Princess Nourah bint Abdulrahman University,"Multi-modality medical image fusion aims at integrating information from medical images with different modalities to aid in the diagnosis process. Most research work in this area ends with the fusion stage only. This paper, on the contrary, tries to present a complete diagnosis system based on multi-modality image fusion. This system works on MR and CT images. It begins with the registration step using Scale-Invariant Feature Transform registration algorithm. After that, histogram matching is performed to allow accurate fusion of the medical images. Two methods of the fusion are utilized and compared, wavelet and curvelet fusion. An interpolation stage is included to enhance the resolution of the obtained image after fusion. Finally, a deep learning approach is adopted for classification of images as normal or abnormal. Simulation results reveal good success of the proposed automated diagnosis system based on the fusion and interpolation results.","Image fusion,MR,CT,Registration,Interpolation,Classification,Deep learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Telecommunications,,1.369,INTERPOLATION,WIRELESS PERSONAL COMMUNICATIONS,,
74,Optimal design and robust analysis of a net of active devices for micro-vibration control of an on-orbit large space antenna,164,,241-253,"Angeletti Federica,Gasbarri Paolo,Sabatini Marco","Angeletti F,Gasbarri P,Sabatini M",Gasbarri P,10.1016/j.actaastro.2019.07.028,Sapienza University Rome,"Large deployable antennas are required for the advancement of space communications, Earth observation, radio astronomy and deep space exploration. Most contemporary space antennas have exceeded the size of launching vehicles, leading to the necessity of stowed concepts to overcome the limitation. Many structural models have been investigated by different organizations. Generally, mesh deployable reflectors are currently more mature compared to other foldable solutions. This will be the topic of this paper. Orbital disturbances, perturbations originated by on-board sources and thermal deformations affecting the deployed configuration can deteriorate the accuracy of the communications system. Undesired dynamic behaviour of structural components has to be predicted and counteracted. Therefore, vibration control is a key technology to correct the distortions altering the proper functioning of the system. An intelligent active structure is introduced as a structure configured with distributed actuators and sensors and guided by a controller to modify the dynamic response of the system. In this paper, the supporting structure of a very large mesh reflector is described. A FEM formulation is adopted to assemble the frame and it is validated by comparing it with commercial codes. According to the adopted model, the active elements can be embedded in the middle of the truss elements. Of course, active control of all the devices at the same time requires a control effort which could be not affordable in space applications. However, the effectiveness is not the same for all the actuators. In this study, two cascade optimization procedures are performed to assess the best positioning and velocity feedback gains of the actuators that must be controlled to damp vibrations. In particular, a gradient-based technique is used after both a Genetic Algorithm and a Reinforcement Learning methodology to find the best set of gains for the controller. The objective function is set as a weighted sum of power consumption of the actuators. As a study case, the spacecraft implements a velocity feedback strategy when performing a generic attitude manoeuvre to coordinate the simultaneous action of the devices to ensure the damping performance of the system is enhanced. In addition, the impact of damaged actuators and uncertainties on the mechanical properties of the passive structure has been discussed and analysed.","Vibrations control,Space antennas,Smart materials,Active structures",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Engineering,,2.485,,ACTA ASTRONAUTICA,,
75,A deep learning model to recognize food contaminating beetle species based on elytra fragments,166,,,"Wu Leihong,Liu Zhichao,Bera Tanmay,Ding Hongjian,Langley Darryl A.,Jenkins-Barnes Amy,Furlanello Cesare,Maggio Valerio,Tong Weida,Xu Joshua","Wu LH,Liu ZC,Bera T,Ding HJ,Langley DA,Jenkins-Barnes A,Furlanello C,Maggio V,Tong WD,Xu J",Xu J,10.1016/j.compag.2019.105002,US Food & Drug Administration (FDA),"Insect pests are often associated with food contamination and public health risks. Accurate and timely species-specific identification of pests is a key step to scale impacts, trace back the contamination process and promptly set intervention measures, which usually have serious economic impact. The current procedure involves visual inspection by human analysts of pest fragments recovered from food samples, a time-consuming and error-prone process. Deep Learning models have been widely applied for image recognition, outperforming other machine learning algorithms; however only few studies have applied deep learning for food contamination detection. In this paper, we describe our solution for automatic identification of 15 storage product beetle species frequently detected in food inspection. Our approach is based on a convolutional neural network trained on a dataset of 6900 microscopic images of elytra fragments, obtaining an overall accuracy of 83.8% in cross validation. Notably, the classification performance is obtained without the need of designing and selecting domain specific image features, thus demonstrating the promising prospects of Deep Learning models in detecting food contamination.","Food contamination,Beetle species identification,Deep learning,Convolutional neural networks,Transfer learning",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Agriculture,Computer Science",,5.494,"IDENTIFICATION,FEATURES,INSECTS,HEALTH",COMPUTERS AND ELECTRONICS IN AGRICULTURE,https://doi.org/10.1016/j.compag.2019.105002,
76,Motor imagery EEG recognition with KNN-based smooth auto-encoder,101,,,"Tang Xianlun,Wang Ting,Du Yiming,Dai Yuyan","Tang XL,Wang T,Du YM,Dai YY",Wang T,10.1016/j.artmed.2019.101747,Chongqing University of Posts & Telecommunications,"As new human-computer interaction technology, brain-computer interface has been widely used in various fields of life. The study of EEG signals cannot only improve people's awareness of the brain, but also establish new ways for the brain to communicate with the outside world. This paper takes the motion imaging EEG signal as the research object and proposes an innovative semi-supervised model called KNN-based smooth auto-encoder (k-SAE). K-SAE looks for the nearest neighbor values of the samples to construct a new input and learns the robust features representation by reconstructing this new input instead of the original input, which is different from the traditional automatic encoder (AE), The Gaussian filter is selected as the convolution kernel function in k-SAE to smooth the noise in the feature. Besides, the data information and spatial position of the feature map are recorded by max-pooling and unpooling, that help to prevent loss of important information. The method is applied to two data sets for feature extraction and classification experiments of motor imaging EEG signals. The experimental results show that k-SAE achieves good recognition accuracy and outperforms other state-of-the-art recognition algorithms.","KNN-based smooth auto-encoder,BCI,Motor imagery,Feature extraction,EEG recognition",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Medical Informatics",,5.602,"WAVELET,TRANSFORM,CLASSIFICATION,MACHINE,PATTERN,SYSTEM",ARTIFICIAL INTELLIGENCE IN MEDICINE,,
77,Methods for algorithmic diagnosis of metabolic syndrome,101,,,"Vrbaski Dunja,Vrbaski Milan,Kupusinac Aleksandar,Ivanovic Darko,Stokic Edita,Ivetic Dragan,Doroslovacki Ksenija","Vrbaski D,Vrbaski M,Kupusinac A,Ivanovic D,Stokic E,Ivetic D,Doroslovacki K",Kupusinac A,10.1016/j.artmed.2019.101708,University of Novi Sad,"Metabolic Syndrome (MetS) is associated with the risk of developing chronic disease (atherosclerotic cardiovascular disease, type 2 diabetes, cancers and chronic kidney disease) and has an important role in early prevention. Previous research showed that an artificial neural network (ANN) is a suitable tool for algorithmic MetS diagnostics, that includes solely non-invasive, low-cost and easily-obtainabled (NI&LC&EO) diagnostic methods. This paper considers using four well-known machine learning methods (linear regression, artificial neural network, decision tree and random forest) for MetS predictions and provides their comparison, in order to induce and facilitate development of appropriate medical software by using these methods. Training, validation and testing are conducted on the large dataset that includes 3000 persons. Input vectors are very simple and contain the following parameters: gender, age, body mass index, waist-to-height ratio, systolic and diastolic blood pressures, while the output is MetS diagnosis in true/false form, made in accordance with International Diabetes Federation (IDF). Comparison leads to the conclusion that random forest achieves the highest specificity (SPC = 0.9436), sensitivity (SNS = 0.9154), positive (PPV = 0.9379) and negative (NPV = 0.9150) predictive values. Algorithmic diagnosis of MetS could be beneficial in everyday clinical practice since it can easily identify high risk patients.","Linear regression,Artificial neural network,Decision tree,Random forest,Metabolic syndrome",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Medical Informatics",,,"ARTIFICIAL,NEURAL-NETWORK,ADIPOSE-TISSUE,RISK-FACTORS,INTELLIGENCE,STATE",ARTIFICIAL INTELLIGENCE IN MEDICINE,,
78,Machine learning-based modeling and operation for ALD of SiO2 thin-films using data from a multiscale CFD simulation,151,,131-145,"Ding Yangyao,Zhang Yichi,Ren Yi Ming,Orkoulas Gerassimos,Christofides Panagiotis D.","Ding YY,Zhang YC,Ren YM,Orkoulas G,Christofides PD",Christofides PD,10.1016/j.cherd.2019.09.005,University of California System,"Atomic layer deposition (ALD) is a widely utilized deposition technology in the semiconductor industry due to its superior ability to generate highly conformal films and to deposit materials into high aspect-ratio geometric structures. However, ALD experiments remain expensive and time-consuming, and the existing first-principles based models have not yet been able to provide solutions to key process outputs that are computationally efficient, which is necessary for on-line optimization and real-time control. In this work, a multiscale data-driven model is proposed and developed to capture the macroscopic process domain dynamics with a linear parameter varying model, and to characterize the microscopic domain film growth dynamics with a feed-forward artificial neural network (ANN) model. The multiscale data-driven model predicts the transient deposition rate from the following four key process operating parameters that can be manipulated, measured or estimated by process engineers: precursor feed flow rate, operating pressure, surface heating, and transient film coverage. Our results demonstrate that the multiscale data-driven model can efficiently characterize the transient input-output relationship for the SiO2 thermal ALD process using bis(tertiary-butylamino)silane (BTBAS) as the Si precursor. The multiscale data-driven model successfully reduces the computational time from 0.6 to 1.2 h for each time step, which is required for the first-principles based multiscale computational fluid dynamics (CFD) model, to less than 0.1 s, making its real-time usage feasible. The developed data-driven modeling methodology can be further generalized and used for other thermal ALD or similar deposition systems, which will greatly enhance the feasibility of industrial manufacturing processes. (C) 2019 Institution of Chemical Engineers. Published by Elsevier B.V. All rights reserved.","Atomic layer deposition,Multiscale modeling,Computational fluid dynamics modeling,Kinetic Monte Carlo modeling,ALD operation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Engineering,,3.805,"ATOMIC,LAYER,DEPOSITION,KINETIC,MONTE-CARLO,LATTICE-SIZE,GROWTH,DEPENDENCE,DYNAMICS,SLOPE",CHEMICAL ENGINEERING RESEARCH & DESIGN,https://www.sciencedirect.com/science/article/am/pii/S0263876219304125,
79,Automatic damage type classification and severity quantification using signal based and nonlinear model based damage sensitive features,83,,136-146,"Ghrib Meriem,Rebillat Marc,des Roches Guillaume Vermot,Mechbal Nazih","Ghrib M,Rebillat M,des Roches GV,Mechbal N",Rebillat M,10.1016/j.jprocont.2018.08.002,Arts et Metiers Institute of Technology,"Structural health monitoring (SHM) is an emerging technology designed to automate the inspection process undertaken to assess the health condition of structures. The SHM process is classically decomposed into four sequential steps: damage detection, localization, classification, and quantification. This paper addresses damage type classification and severity quantification issues as classification problems whereby each class corresponds to a given damage type or a certain damage extent. A Support Vector Machine (SVM) is used to perform multi-class classification task. Classically, Signal Based Features (SBF) are used to train SVMs when approaching SHM from a machine learning perspective. In this work, starting from the assumption that damage causes a structure to exhibit nonlinear response, it is investigated whether the use of Nonlinear Model Based Features (NMBF) increases classification performance. NMBF are computed based on parallel Hammerstein models which are identified with an Exponential Sine Sweep (ESS) signal. A study of the sensitivity of classification performance to the noise contained in output signals is also conducted. Dimension reduction of features vector using Principal Component Analysis (PCA) is carried out in order to find out if it allows robustifying the classification/quantification process suggested in this work. Simulated data on a cantilever beam with various damage types and severities as well as experimental data coming from a composite aeronautic plate with various damage severities generated with a unique and original laser process are considered for demonstration. For both application cases, results show that by introducing NMBF, classification performance is improved. Furthermore, PCA allows for high recognition rates while reducing features vector dimension. (C) 2018 Elsevier Ltd. All rights reserved.","Damage type classification,Damage severity quantification,SBF,NMBF,SVM,PCA,Output noise,Cantilever beam,Simulation",Article; Proceedings Paper,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Automation & Control Systems,Engineering",,3.716,"LEAST-SQUARES,TRANSMISSIBILITY,LOCATION",JOURNAL OF PROCESS CONTROL,https://hal.archives-ouvertes.fr/hal-03065251/file/PIMM_JPC_2019_REBILLAT.pdf,
80,Semi-supervised defect classification of steel surface based on multi-training and generative adversarial network,122,,294-302,"He Yu,Song Kechen,Dong Hongwen,Yan Yunhui","He Y,Song KC,Dong HW,Yan YH",Song KC; Yan YH,10.1016/j.optlaseng.2019.06.020,Northeastern University - China,"Defect inspection is very important for guaranteeing the surface quality of industrial steel products, but related methods are based primarily on supervised learning which requires ample labeled samples for training. However, there can be no doubt that inspecting defects on steel surface is always a data-limited task due to difficult sample collection and expensive expert labeling. Unlike the previous works in which only labeled samples are treated using supervised classifiers, we propose a semi-supervised learning (SSL) defect classification approach based on multi-training of two different networks: a categorized generative adversarial network (GAN) and a residual network. This method uses the GAN to generate a large number of unlabeled samples. And then the multitraining algorithm that uses two classifiers based on different learning strategies is proposed to integrate both labeled and unlabeled into SSL process. Finally, through the multiple training process, our SSL method can acquire higher accuracy and better robustness than the supervised one using only limited labeled samples. Experimental results clearly demonstrate that the effectiveness of our proposed method, achieving the classification accuracy of 99.56%.","Defect classification,Steel surface inspection,Semi-supervised learning,Generative adversarial network,Multi-training",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Optics,,4.894,"LOCAL,BINARY,PATTERNS,RECOGNITION",OPTICS AND LASERS IN ENGINEERING,https://www.sciencedirect.com/science/article/am/pii/S0143816619306499,
81,Comparison of machine learning classifiers for differentiation of grade 1 from higher gradings in meningioma: A multicenter radiomics study,63,,244-249,"Hamerla Gordian,Meyer Hans-Jonas,Schob Stefan,Ginat Daniel T.,Altman Ashley,Lim Tchoyoson,Gihr Georg Alexander,Horvath-Rizea Diana,Hoffmann Karl-Titus,Surov Alexey","Hamerla G,Meyer HJ,Schob S,Ginat DT,Altman A,Lim T,Gihr GA,Horvath-Rizea D,Hoffmann KT,Surov A",Hamerla G,10.1016/j.mri.2019.08.011,Leipzig University,"Background and purpose: Advanced imaging analysis for the prediction of tumor biology and modelling of clinically relevant parameters using computed imaging features is part of the emerging field of radiomics research. Here we test the hypothesis that a machine learning approach can distinguish grade 1 from higher gradings in meningioma patients using radiomics features derived from a heterogenous multicenter dataset of multi-paramedic MRI.
Methods: A total of 138 patients from 5 international centers that underwent MRI prior to surgical resection of intracranial meningiomas were included. Segmentation was performed manually on co-registered multi-parametric MR images using apparent diffusion coefficient (ADC) maps, T1-weighted (T1), post-contrast T1-weighted (T1c), subtraction maps (Sub, T1c - T1), T2-weighted fluid-attenuated inversion recovery (FLAIR) and T2-weighted (T2) images. Feature selection was performed and using cross-validation to separate training from testing data, four machine learning classifiers were scored on combinations of MRI modalities: random forest (RF), extreme gradient boosting (XGBoost), support vector machine (SVM) and multilayer perceptron (MLP).
Results: The best AUC of 0.97 (1.0 and 0.97 for sensitivity and specificity) was observed for the combination of ADC, ADC of the peritumoral edema, T1, T1c, Sub and FLAIR-derived features using only 16 of the 10,914 possible features and XGBoost.
Conclusions: Machine learning using radiomics features derived from multi-parametric MRI is capable of high AUC scores with high sensitivity and specificity in classifying meningiomas between low and higher gradings despite heterogeneous protocols across different centers. Feature selection can be performed effectively even when extracting a large amount of data for radiomics fingerprinting.","Random forest,Support vector machine,Multilayer perceptron,XGBoost,Machine learning,Meningioma,Grading,Feature selection",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.608,"APPARENT,DIFFUSION-COEFFICIENT,CENTRAL-NERVOUS-SYSTEM,SURVIVAL,CANCER,IMAGES,TUMORS,BRAIN,KI-67,MRI",MAGNETIC RESONANCE IMAGING,,
82,"Application of a convolutional neural network in permeability prediction: A case study in the Jacksonburg-Stringtown oil field, West Virginia, USA",84,6,B363-B373,"Zhong Zhi,Carr Timothy R.,Wu Xinming,Wang Guochang","Zhong Z,Carr TR,Wu XM,Wang GC",Wu XM,10.1190/GEO2018-0588.1,Chinese Academy of Sciences,"Permeability is a critical parameter for understanding subsurface fluid flow behavior, managing reservoirs, enhancing hydrocarbon recovery, and sequestering carbon dioxide. In general, permeability is measured in the laboratory based on subsurface core samples, calculated from well logs or estimated from well tests. However, laboratory measurements and well tests are expensive, time-consuming, and usually limited to a few core samples or wells in a hydrocarbon field or carbon storage site. Machine-learning techniques are good options for generating a rapid, robust, and cost-effective permeability prediction model because of their strengths to recognize the potential interrelationships between input and output variables. Convolutional neural networks (CNN), as a good pattern recognition algorithm, are widely used in image processing, natural language processing, and speech recognition, but are rarely used with regression problems and even less often in reservoir characterization. We have developed a CNN regression model to estimate the permeability in the Jacksonburg-Stringtown oil field, West Virginia, which is a potential carbon storage site and enhanced oil recovery operations field. We also evaluate the concept of the geologic feature image, which is converted from geophysical well logs. Five variables, including two commonly available conventional well logs (the gamma rays [GRs] and bulk density) and three well-log-derived variables (the slopes of the GR and bulk density curves, and shale content), are used to generate a geologic feature image. The CNN treats the geologic feature image as the input and the permeability as the desired output. In addition, the permeability predicted using traditional backpropagation artificial neural networks, which are optimized by genetic algorithms and particle swarm optimization, is compared with the permeability estimated using our CNN. Our results indicate that the CNN regression model provides more accurate permeability predictions than the traditional neural network.","RESERVOIR CHARACTERIZATION,CARBON SEQUESTRATION,POROSITY,PRESSURE,MODEL,ROCK,CLASSIFICATION,ARCHITECTURE,UNCERTAINTY,TRANSPORT",Article,"SOC EXPLORATION GEOPHYSICISTS, 8801 S YALE ST, TULSA, OK 74137 USA",Geochemistry & Geophysics,,3.281,"RESERVOIR,CHARACTERIZATION,CARBON,SEQUESTRATION,POROSITY,PRESSURE,MODEL,ROCK,CLASSIFICATION,ARCHITECTURE,UNCERTAINTY,TRANSPORT",GEOPHYSICS,,
83,Dynamics reconstruction and classification via Koopman features,33,6,1710-1735,"Zhang Wei,Yu Yao-Chi,Li Jr-Shin","Zhang W,Yu YC,Li JS",Li JS,10.1007/s10618-019-00639-x,Washington University (WUSTL),"Knowledge discovery and information extraction of large and complex datasets has attracted great attention in wide-ranging areas from statistics and biology to medicine. Tools from machine learning, data mining, and neurocomputing have been extensively explored and utilized to accomplish such compelling data analytics tasks. However, for time-series data presenting active dynamic characteristics, many of the state-of-the-art techniques may not perform well in capturing the inherited temporal structures in these data. In this paper, integrating the Koopman operator and linear dynamical systems theory with support vector machines, we develop a novel dynamic data mining framework to construct low-dimensional linear models that approximate the nonlinear flow of high-dimensional time-series data generated by unknown nonlinear dynamical systems. This framework then immediately enables pattern recognition, e.g., classification, of complex time-series data to distinguish their dynamic behaviors by using the trajectories generated by the reduced linear systems. Moreover, we demonstrate the applicability and efficiency of this framework through the problems of time-series classification in bioinformatics and healthcare, including cognitive classification and seizure detection with fMRI and EEG data, respectively. The developed Koopman dynamic learning framework then lays a solid foundation for effective dynamic data mining and promises a mathematically justified method for extracting the dynamics and significant temporal structures of nonlinear dynamical systems.","Koopman operators,Dynamic data mining,Data-driven methods,Dimensionality reduction,Spectral methods,Time-series classification,Healthcare,Bioinformatics",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,4.418,"VOXEL,PATTERN-ANALYSIS,SPECTRAL,PROPERTIES,EPILEPTIC,SEIZURES,FMRI,DATA,SYSTEMS,RECOGNITION,SELECTION,FRAMEWORK,ONSET",DATA MINING AND KNOWLEDGE DISCOVERY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7390473,
84,A deep supervised approach for ischemic lesion segmentation from multimodal MRI using Fully Convolutional Network,84,,,"Karthik R.,Gupta Utkarsh,Jha Ashish,Rajalakshmi R.,Menaka R.","Karthik R,Gupta U,Jha A,Rajalakshmi R,Menaka R",Menaka R,10.1016/j.asoc.2019.105685,VIT Chennai,"The principle restorative step in the treatment of ischemic stroke depends on how fast the lesion is delineated from the Magnetic Resonance Imaging (MRI) images. This will serve as a vital aid to estimate the extent of damage caused to the brain cells. However, manual delineation of the lesion is time-consuming and it is subjected to intra-observer and inter-observer variability. Most of the existing methods for ischemic lesion segmentation rely on extracting handcrafted features followed by application of a machine learning algorithm. Identifying such features demand multidomain expertise in Neuro-radiology as well as Image processing. This can be accomplished by learning the features automatically using Convolutional Neural Network (CNN). To perform segmentation, the spatial arrangement of pixel needs to be preserved in addition to learning local features of an image. Hence, a deep supervised Fully Convolutional Network (FCN) is presented in this work to segment the ischemic lesion. The highlight of this research is the application of Leaky Rectified Linear Unit activation in the last two layers of the network for a precise reconstruction of the ischemic lesion. By doi ng so, the network was able to learn additional features which are not considered in the existing U-Net architecture. Also, an extensive analysis was conducted in this research to select optimal hyperparameters for training the FCN. A mean segmentation accuracy of 0.70 has been achieved from the experiments conducted on ISLES 2015 dataset. Experimental observations show that our proposed FCN method is 10% better than the existing works in terms of Dice Coefficient. (C) 2019 Elsevier B.V. All rights reserved.","Ischemic lesion,FCN,Segmentation,Deep learning,CNN,Brain MRI",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,6.607,"COMPUTER-AIDED,DETECTION,NEURAL-NETWORKS,STROKE,IMAGES,ALGORITHM",APPLIED SOFT COMPUTING,,
85,Automated classification of histopathology images using transfer learning,101,,,Talo Muhammed,Talo M,Talo M,10.1016/j.artmed.2019.101743,Firat University,"Early and accurate diagnosis of diseases can often save lives. Diagnosis of diseases from tissue samples is done manually by pathologists. Diagnostics process is usually time consuming and expensive. Hence, automated analysis of tissue samples from histopathology images has critical importance for early diagnosis and treatment. The computer aided systems can improve the quality of diagnoses and give pathologists a second opinion for critical cases. In this study, a deep learning based transfer learning approach has been proposed to classify histopathology images automatically. Two well-known and current pre-trained convolutional neural network (CNN) models, ResNet-50 and DenseNet-161, have been trained and tested using color and grayscale images. The DenseNet-161 tested on grayscale images and obtained the best classification accuracy of 97.89%. Additionally, ResNet-50 pre-trained model was tested on the color images of the Kimia Path24 dataset and achieved the highest classification accuracy of 98.87%. According to the obtained results, it may be said that the proposed pre-trained models can be used for fast and accurate classification of histopathology images and assist pathologists in their daily clinical tasks.","Medical image classification,Histopathology,Deep learning,Transfer learning,CNN",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Medical Informatics",,5.602,"DEEP,CANCER,DIAGNOSIS",ARTIFICIAL INTELLIGENCE IN MEDICINE,http://arxiv.org/pdf/1903.10035,
86,Detection of dental diseases from radiographic 2d dental image using hybrid graph-cut technique and convolutional neural network,146,,333-342,"Al Kheraif Abdulaziz A.,Wahba Ashraf A.,Fouad H.","Al Kheraif AA,Wahba AA,Fouad H",Wahba AA,10.1016/j.measurement.2019.06.014,Egyptian Knowledge Bank (EKB),"In the present scenario the major oral health issues of man is crucial an area of research. The Data mining techniques, image processing, and Computational intelligence techniques are playing a vital role in biomedical research. Dental image processing helps to improve the early detection and classification of the diagnostic process to make accurate decisions. The radiographic 2d dental image is widely utilized for analytic thinking of several dental disorders. In this paper traces the complete steps such as classification and segmentation as well as pre-processing of dental images has been carried out. In the pre-processing, histogram based on adaptive approach is used to stretch the contrast and equalize the brightness throughout the radiographic X-ray 2d dental Image. This operation is useful to distinguish the foreground teeth and the regions of background bones. Separation of dental 2d images into regions corresponding to the objects is a fundamental step of segmentation. The hybrid graph cut segmentation is used to segment the oral cavity and its tissues. In this research deep learning based convolution neural network (CNN) has been used to process the dental image and shows promising outcomes with 97.07% accuracy. (C) 2019 Elsevier Ltd. All rights reserved.","2d-X-ray image,Dental,Deep learning,CNN,Segmentation,Classification",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Instruments & Instrumentation",,3.778,"TEETH,SEGMENTATION,CLASSIFICATION,PREDICTION,CARIES",MEASUREMENT,,
87,Classification of tree species and stock volume estimation in ground forest images using Deep Learning,166,,,"Liu Jiazheng,Wang Xuefeng,Wang Tian","Liu JZ,Wang XF,Wang T",Wang XF,10.1016/j.compag.2019.105012,Chinese Academy of Forestry,"Tree species classification and estimation of stock volume are two very important tasks in forest management. Currently, Ground Surveys' Development (GSD) is the basic and most common approach employed by foresters. However, GSD is time-consuming and inefficient as it requires great human effort. In this research, digital cameras have been used, to obtain images of the ground forest. The classification and accumulation of tree species is performed, by considering extracted relevant image information. The purpose of this effort is not only to improve research efficiency, but to reduce the consumption of human and material resources as well. This research uses the UNET network which is pre-trained by the VGG16 model. The aim is to semantically segment the image containing the ground forest and the species and then to accurately identify the number of trees contained in the image. The proportion of the number of pixels in the trunk of each segment is estimated by considering the total number of pixels in the image. The nonlinear mixed effect model is used to estimate the growing stock volume. The differences in the growing stock volume caused by different forest types, are resolved by using the growing stock volume estimation equations, related to different tree species. The experimental results show that the tree species' classification accuracy in testing is 96.03% and the average IoU (Intersection over Union) is 86%. The R-2 and RMSE of the growing stock volume prediction model are equal to 80.70% and 30.539 (m(3)/ha) respectively. Therefore, it is concluded that the method proposed in this research can be used as an effective tool for tree species' image segmentation and classification, and that the growing stock volume is predicted accurately by the extracted tree pixel information. The combination of the two approaches provides a new method for forestry ground investigation work.","Ground forest image,Deep Learning,UNET,Tree species classification,Nonlinear mixed effect model,Growing stock volume",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Agriculture,Computer Science",,5.494,"LIDAR,DATA,BIOMASS,GROWTH,STANDS",COMPUTERS AND ELECTRONICS IN AGRICULTURE,,
88,"Comparison of EMD, DWT and WPD for the localization of epileptogenic foci using Random Forest classifier",146,,846-855,"Subasi Abdulhamit,Jukic Samed,Kevric Jasmin","Subasi A,Jukic S,Kevric J",Subasi A,10.1016/j.measurement.2019.07.026,Effat University,"Localization of epileptogenic foci is an essential phase in surgical treatment planning using the earliest time detection of the seizure onset in the recordings of electroencephalogram (EEG). These recordings are defined as the areas of the brain which can be surgically removed to reach control of seizure. The characteristics of the brain area affected by partial epilepsy can be analyzed using focal and non-focal EEG signals. In this work, a method for the classification of focal and non-focal EEG signals is presented to compare different feature extraction methods combined with multi-scale principal component analysis (MSPCA) denoising and Random Forest (RF) as a machine learning technique. After de-noising, different feature extraction methods (EMD, DWT and WPD) are applied. The performance of RF classifier is measured according to accuracy, the area under the Receiver Operating Characteristics (ROC) curve (AUC) and F-measure. EEG based focal region localization with Wavelet Packet Decomposition (WPD) feature extraction and RF classifier reach 99.92% accuracy. Hence, WPD combined with RF machine learning classifier can be used to differentiate the focal and non-focal EEG signals. (C) 2019 Elsevier Ltd. All rights reserved.","Epileptogenic foci,Electroencephalogram (EEG),Discrete Wavelet Transform (DWT),Empirical Mode Decomposition (EMD),Wavelet Packed Decomposition (WPD),Random Forest (RF)",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Instruments & Instrumentation",,3.778,"INTERICTAL,EEG,SIGNALS,SPIKES,EPILEPSY,IDENTIFICATION,DECOMPOSITION,BRAIN,SCALP,MEG",MEASUREMENT,,
89,Automatic detection of pipe-flange reflections in GPR data sections using supervised learning,170,,,"Bordon Pablo,Bonomo Nestor,Martinelli Patricia","Bordon P,Bonomo N,Martinelli P",Bonomo N,10.1016/j.jappgeo.2019.103856,University of Buenos Aires,"Ground Penetrating radar (GPR) is a method widely used to study the near-surface subsoil. Many GPR applications require the acquisition of large volumes of data. In these cases, the processing and analysis of the data involve considerable amounts of time and human effort, and the possibility of errors increases. Considering this, the implementation of dependable methods for the automatic detection of GPR response-patterns of the targeted structures becomes clear, because they can contribute to the efficiency and reliability of the interpretation.
In this work, we present three methods for automatic detection of pipe-flange signals in constant-offset reflection-GPR images. These methods were obtained using well-known supervised machine learning techniques, and data acquired during a previous study of an extensive section of a pipeline. The first two methods are based on support vector machines (SVM), combined with the image descriptors local binary patterns (IBP) and histogram of oriented gradients (HOG), and the third, on artificial neural networks (ANN). The training and validation of these types of algorithms require large numbers of positive and negative samples. From the mentioned study, we had only 16 experimental flange-patterns. Then, in this work, they were taken as references, together with available documentation on the geometry and materials of the pipe and flanges, for building a broad database of synthetic patterns corresponding to different depths of the pipe and characteristics of the environment. These patterns constitute the set of positive samples used for training and validation. They were also used for the final test of the algorithms. The negative samples for the three stages were directly extracted from the profiles.
The results obtained indicate the usefulness of the proposed methodologies to identify the flanges. The best performance corresponded to the ANN, closely followed by SVM combined with HOG, and finally SVM with LBP. In particular, the ANN provided rates of false positive (FP) predictions for the validation and test samples of about 3%, and rates of false negative (FN) predictions of 1.67% for the validation samples and 18.75% for the test samples. Greater FN rates for the test experimental samples, in comparison to those obtained for the validation synthetic samples, were also observed for both SVM algorithms. The detection failures mainly originated in that some complex features of the experimental flange responses could not be appropriately reproduced through the performed numerical simulations, and therefore, some of the patterns were not satisfactorily represented in the sets of positive samples used for training and validation. A first option to improve the results is to obtain a significant number and variety of experimental samples of flange responses and use them to train and validate the algorithms. Other alternatives are to use more sophisticated numerical simulation environments and to find more efficient attributes of the data. (C) 2019 Elsevier B.V. All lights reserved.","GPR,Pipe-flange,Automatic detection,SVM,ANN",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Geology,Mining & Mineral Processing",,2.264,"GROUND-PENETRATING,RADAR,CLASSIFICATION,EXTRACTION,FEATURES,PAVEMENT",JOURNAL OF APPLIED GEOPHYSICS,https://ri.conicet.gov.ar/bitstream/11336/147424/8/CONICET_Digital_Nro.8079771d-b8a2-45bd-ba49-bc1521e5ed96_G.pdf,
90,Improving sensitivity of mercury detection using learning based smartphone colorimetry,298,,,"Sajed S.,Arefi F.,Kolahdouz M.,Sadeghi M. A.","Sajed S,Arefi F,Kolahdouz M,Sadeghi MA",Kolahdouz M,10.1016/j.snb.2019.126942,University of Tehran,"Detection of various contaminations in drinking water such as heavy metal ions and toxic chemicals is costly, time-consuming and requires an accompanying computing device to capture and analyze the data. Hence, there is an extensive need for a rapid, user-friendly, cost-effective, sensitive and ubiquitous detection technique. Smartphones are an effective means to measure, analyze and share the results. In this work, a gadget was designed and printed using a lightweight 3D material, which can be attached to any smartphone and integrated with optical components. A full color TFT LCD display was used as the uniform source of any color of light. Aptamer conjugated gold nanoparticles were employed to determine the concentration of Hg2+ as the basis of a colorimetric sensor. Interaction between the aptamer and the analytes leads to a color change in the solution due to aggregation of gold nanoparticles. For the corresponding color change detection, a novel image processing protocol using RGB value was introduced for each captured image. Multiple linear regression analysis was also exploited to achieve a better sensor response model. Light source enhancement, colorimetry at more points of visible spectrum (470, 540, 640 nm) and a powerful post process technique including machine learning made it possible to obtain an excellent level of sensitivity (1 nM-0.2 ppb).","Gold nanoparticles,Localized surface plasmon resonance,Lab-on-a-phone,colorimetry,RGB value,Multiple linear regression,Mercury concentration",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Chemistry,Electrochemistry,Instruments & Instrumentation",,6.743,"GOLD,NANOPARTICLES,OPTICAL-PROPERTIES,RATIONAL,DESIGN,SENSOR,PROTEIN,IONS,LEAD,SIZE",SENSORS AND ACTUATORS B-CHEMICAL,,
91,Technical Note: PYRO-NN: Python reconstruction operators in neural networks,,,,"Syben Christopher,Michen Markus,Stimpel Bernhard,Seitz Stephan,Ploner Stefan,Maier Andreas K.","Syben C,Michen M,Stimpel B,Seitz S,Ploner S,Maier AK",Syben C,10.1002/mp.13753,University of Erlangen Nuremberg,"Purpose Recently, several attempts were conducted to transfer deep learning to medical image reconstruction. An increasingly number of publications follow the concept of embedding the computed tomography (CT) reconstruction as a known operator into a neural network. However, most of the approaches presented lack an efficient CT reconstruction framework fully integrated into deep learning environments. As a result, many approaches use workarounds for mathematically unambiguously solvable problems. Methods PYRO-NN is a generalized framework to embed known operators into the prevalent deep learning framework Tensorflow. The current status includes state-of-the-art parallel-, fan-, and cone-beam projectors, and back-projectors accelerated with CUDA provided as Tensorflow layers. On top, the framework provides a high-level Python API to conduct FBP and iterative reconstruction experiments with data from real CT systems. Results The framework provides all necessary algorithms and tools to design end-to-end neural network pipelines with integrated CT reconstruction algorithms. The high-level Python API allows a simple use of the layers as known from Tensorflow. All algorithms and tools are referenced to a scientific publication and are compared to existing non-deep learning reconstruction frameworks. To demonstrate the capabilities of the layers, the framework comes with baseline experiments, which are described in the supplementary material. The framework is available as open-source software under the Apache 2.0 licence at . Conclusions PYRO-NN comes with the prevalent deep learning framework Tensorflow and allows to setup end-to-end trainable neural networks in the medical image reconstruction context. We believe that the framework will be a step toward reproducible research and give the medical physics community a toolkit to elevate medical image reconstruction with new deep learning techniques.","inverse problems,known operator learning,machine learning,open source,reconstruction",Article; Early Access,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"IMAGE-RECONSTRUCTION,DEEP,FRAMEWORK,DOMAIN",MEDICAL PHYSICS,https://opus4.kobv.de/opus4-fau/files/15142/MP_MP13753.pdf,
92,Compressed sensing MRI via a multi-scale dilated residual convolution network,63,,93-104,"Dai Yuxiang,Zhuang Peixian","Dai YX,Zhuang PX",Zhuang PX,10.1016/j.mri.2019.07.014,Nanjing University of Information Science & Technology,"Magnetic resonance imaging (MRI) reconstruction is an active inverse problem which can be addressed by conventional compressed sensing (CS) MRI algorithms that exploit the sparse nature of MRI in an iterative optimization-based manner. However, two main drawbacks of iterative optimization-based CSMRI methods are time-consuming and are limited in model capacity. Meanwhile, one main challenge for recent deep learning-based CSMRI is the trade-off between model performance and network size. To address the above issues, we develop a new multi-scale dilated network for MRI reconstruction with high speed and outstanding performance. Comparing to convolutional kernels with same receptive fields, dilated convolutions reduce network parameters with smaller kernels and expand receptive fields of kernels to obtain almost same information. To maintain the abundance of features, we present global and local residual learnings to extract more image edges and details. Then we utilize concatenation layers to fuse multi-scale features and residual learnings for better reconstruction. Compared with several non-deep and deep learning CSMRI algorithms, the proposed method yields better reconstruction accuracy and noticeable visual improvements. In addition, we perform the noisy setting to verify the model stability, and then extend the proposed model on a MRI super-resolution task.","MRI reconstruction,Dilated convolution,Residual learning,Multi-scale",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.608,"IMAGE,RECONSTRUCTION",MAGNETIC RESONANCE IMAGING,http://arxiv.org/pdf/1906.05251,
93,Machine learning aided stochastic structural free vibration analysis for functionally graded bar-type structures,144,,,"Wang Qihan,Wu Di,Tin-Loin Francis,Gao Wei","Wang QH,Wu D,Tin-Loin F,Gao W",Gao W,10.1016/j.tws.2019.106315,University of New South Wales Sydney,"This paper presents a machine learning aided stochastic free vibration analysis for functionally graded (FG) bar-type structures through finite element method (FEM). The considered system uncertainties including the constituent material properties, the dimensions of structural members, and the degree of the gradation of the FGM are incorporated. A novel kernel-based machine learning technique, namely the extended support vector regression (X-SVR), is presented to estimate the governing relationship between the uncertain system parameters and the structural natural frequencies. Subsequently, by applying the Monte-Carlo Simulation (MCS) through the established regression model, various types of statistical characteristics (i.e., mean, standard deviation, probability density function or PDF, and cumulative distribution function or CDF) of structural natural frequencies can be effectively established. Four numerical examples including test functions and practically stimulated engineering structures are thoroughly investigated herein to demonstrate the accuracy, applicability, and computational efficiency of the proposed approach.","Stochastic free vibration analysis,Machine learning,Uncertainty analysis",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Mechanics",,4.629,"NONLINEAR,FREE-VIBRATION,SUPPORT,VECTOR,MACHINE,DYNAMIC-ANALYSIS,FINITE-ELEMENT,FGM,PLATE,SYSTEM,RANDOMNESS,STATIC,ANALYSIS,KERNEL,CLASSIFICATION,RELIABILITY",THIN-WALLED STRUCTURES,,
94,Intelligent skin cancer diagnosis using improved particle swarm optimization and deep learning models,84,,,"Tan Teck Yan,Zhang Li,Lim Chee Peng","Tan TY,Zhang L,Lim CP",Zhang L,10.1016/j.asoc.2019.105725,Northumbria University,"In this research, we propose an intelligent decision support system for skin cancer detection. Since generating an effective lesion representation is a vital step to ensure the success of lesion classification, the discriminative power of different types of features is exploited. Specifically, we combine clinically important asymmetry, border irregularity, colour and dermoscopic structure features with texture features extracted using Grey Level Run Length Matrix, Local Binary Patterns, and Histogram of Oriented Gradients operators for lesion representation. Then, we propose two enhanced Particle Swarm Optimization (PSO) models for feature optimization. The first model employs adaptive acceleration coefficients, multiple remote leaders, in-depth sub-dimension feature search and re-initialization mechanisms to overcome stagnation. The second model uses random acceleration coefficients, instead of adaptive ones, based on non-linear circle, sine and helix functions, respectively, to increase diversification and intensification. Ensemble classifiers are also constructed with each base model trained using each optimized feature subset. A deep convolutional neural network is devised whose hyper-parameters are fine-tuned using the proposed PSO models. Extensive experimental studies using dermoscopic skin lesion data, medical data from the UCI machine learning repository, and ALL-IDB2 image data are conducted to evaluate the model efficiency systematically. The results from empirical evaluations and statistical tests indicate the superiority of the proposed models over other advanced PSO variants and classical search methods pertaining to discriminative feature selection and optimal hyper-parameter identification for deep learning networks in lesion classification as well as other disease diagnosis. (C) 2019 Elsevier B.V. All rights reserved.","Skin cancer detection,Feature selection,Hyper-parameter tuning,Evolutionary algorithm,Deep and ensemble classifier",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,6.607,"FEATURE-SELECTION,IMAGE,SEGMENTATION,ALGORITHM,CLASSIFICATION,SYSTEM",APPLIED SOFT COMPUTING,http://nrl.northumbria.ac.uk/id/eprint/40453/1/Tan%20et%20al%20-%20Intelligent%20Skin%20Cancer%20Diagnosis%20AAM.pdf,
95,Instance-level recognition and quantification for concrete surface bughole based on deep learning,107,,,"Wei Fujia,Yao Gang,Yang Yang,Sun Yujia","Wei FJ,Yao G,Yang Y,Sun YJ",Yao G,10.1016/j.autcon.2019.102920,Chongqing University,"Bughole is one of the primary influences affecting the surface quality of concrete, the traditional measurement methods are carried out by manual inspection, which is considered time consuming and impractical. The previous studies used traditional CNN with bounding boxes to localize the defects, which is unable to locate defect boundaries effectively, and it is difficult to quantify defects. In order to overcome these obstacles, an instance-level recognition and quantification approach based on Mask R-CNN is proposed in this paper. A total of 428 raw images (with a resolution of 3024 x 3024 pixels) are cropped into 256 x 256 pixel images, and 2198 images containing bugholes are selected to create the datasets. Then, the architecture of the Mask R-CNN is modified, trained, validated, and tested using this datasets. Results show 90.0%, 90.8% average precision (AP) for the bounding box and mask, respectively. The accuracy of bounding box and mask are 92.2% and 92.6%, respectively. The quantification performance is evaluated by the measured value of seventy bugholes, results show that more than 68% of bugholes have an area error rate of less than 10%, more than 74% of bugholes have a maximum diameter error rate of less than 10%. The maximum error rate for area and maximum diameter are 22.58% and 17.58%, respectively, and the minimum error rates are 0.23% and 0.16%, respectively.","Bughole recognition,Bughole quantification,Instance segmentation,Deep learning,Concrete surface",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Construction & Building Technology,Engineering",,8.0,"CONVOLUTIONAL,NEURAL-NETWORKS,IMAGE-ANALYSIS,CRACK,DETECTION,MORPHOLOGY,SYSTEM",AUTOMATION IN CONSTRUCTION,,
96,Fully photon modulated heterostructure for neuromorphic computing,65,,,"Li Huilin,Jiang Xiantao,Ye Wenbin,Zhang Han,Zhou Li,Zhang Feng,She Donghong,Zhou Ye,Han Su-Ting","Li HL,Jiang XT,Ye WB,Zhang H,Zhou L,Zhang F,She DH,Zhou Y,Han ST",Han ST,10.1016/j.nanoen.2019.104000,Shenzhen University,"Neuromorphic computing has attracted great attention to mimic the brain functions of perception, learning and memory, which are considered to overcome the von Neumann bottleneck. Here, we developed a novel neuromorphic device based on the ZnO/PbS hybrid heterostructure in order to emulate the bio-synaptic activities in the fully photon modulated mode. Owing to regulation of the conduction state, the excitatory and inhibitory activities have been emulated with the excitation of long-wavelength and short-wavelength photons in the ZnO/PbS neuromorphic device. Excitatory plasticity can be mimicked with the UV light, and IR light induces the inhibitory effect. Furthermore, other synapse functions have also been emulated in these modes, including long-term plasticity, short-term plasticity, paired-pulse facilitation/depression, spike-rate-dependent plasticity, etc. Meanwhile, an artificial neural network has been simulated based on the synaptic plasticity of the excitatory and inhibitory effect in the fully photon modulation, and recognition rates up to 67 +/- 6% can be achieved to distinguish the letter images. Our multifunctional artificial synapse based on the fully photon stimulation can open up a new and efficient way for constructing neuromorphic systems.","Heterostructure,Neuromorphic device,Artificial synapse,Memristor,Photonic synapse",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,17.631,"PHASE-CHANGE,MATERIALS,ARTIFICIAL,SYNAPSES,ZNO,MEMORY",NANO ENERGY,,
97,SANTIS: Sampling- Augmented Neural neTwork with Incoherent Structure for MR image reconstruction,82,5,1890-1904,"Liu Fang,Samsonov Alexey,Chen Lihua,Kijowski Richard,Feng Li","Liu F,Samsonov A,Chen LH,Kijowski R,Feng L",Liu F,10.1002/mrm.27827,University of Wisconsin System,"Purpose: To develop and evaluate a novel deep learning-based reconstruction framework called SANTIS (Sampling-Augmented Neural neTwork with Incoherent Structure) for efficient MR image reconstruction with improved robustness against sampling pattern discrepancy.
Methods: With a combination of data cycle-consistent adversarial network, endto- end convolutional neural network mapping, and data fidelity enforcement for reconstructing undersampled MR data, SANTIS additionally utilizes a samplingaugmented training strategy by extensively varying undersampling patterns during training, so that the network is capable of learning various aliasing structures and thereby removing undersampling artifacts more effectively and robustly. The performance of SANTIS was demonstrated for accelerated knee imaging and liver imaging using a Cartesian trajectory and a golden-angle radial trajectory, respectively. Quantitative metrics were used to assess its performance against different references. The feasibility of SANTIS in reconstructing dynamic contrast-enhanced images was also demonstrated using transfer learning.
Results: Compared to conventional reconstruction that exploits image sparsity, SANTIS achieved consistently improved reconstruction performance (lower errors and greater image sharpness). Compared to standard learning-based methods without sampling augmentation (e. g., training with a fixed undersampling pattern), SANTIS provides comparable reconstruction performance, but significantly improved robustness, against sampling pattern discrepancy. SANTIS also achieved encouraging results for reconstructing liver images acquired at different contrast phases.
Conclusion: By extensively varying undersampling patterns, the sampling-augmented training strategy in SANTIS can remove undersampling artifacts more robustly. The novel concept behind SANTIS can particularly be useful for improving the robustness of deep learning-based image reconstruction against discrepancy between training and inference, an important, but currently less explored, topic.","data augmentation,data cycle-consistent adversarial network,deep learning,image reconstruction,reconstruction robustness,sampling discrepancy",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"DEEP,CLASSIFICATION,COMBINATION",MAGNETIC RESONANCE IN MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6660404,
98,A recurrence network-based convolutional neural network for fatigue driving detection from EEG,29,11,,"Gao Zhong-Ke,Li Yan-Li,Yang Yu-Xuan,Ma Chao","Gao ZK,Li YL,Yang YX,Ma C",Ma C,10.1063/1.5120538,Tianjin University,"Driver fatigue is an important cause of traffic accidents, which has triggered great concern for detecting drivers' fatigue. Numerous methods have been proposed to fulfill this challenging task, including feature methods and machine learning methods. Recently, with the development of deep learning techniques, many studies achieved better results than traditional feature methods, and the combination of traditional methods and deep learning techniques gradually received attention. In this paper, we propose a recurrence network-based convolutional neural network (RN-CNN) method to detect fatigue driving. To be specific, we first conduct a simulated driving experiment to collect electroencephalogram (EEG) signals of subjects under alert state and fatigue state. Then, we construct the multiplex recurrence network (RN) from EEG signals to fuse information from the original time series. Finally, CNN is employed to extract and learn the features of a multiplex RN for realizing a classification task. The results indicate that the proposed RN-CNN method can achieve an average accuracy of 92.95%. To verify the effectiveness of our method, some existing competitive methods are compared with ours. The results show that our method outperforms the existing methods, which demonstrate the effect of the RN-CNN method. Published under license by AIP Publishing.","TIME-SERIES,COMPLEX NETWORKS,BRAIN,VARIABILITY,SLEEPINESS,PERFORMANCE,FREQUENCY,WORKLOAD",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Mathematics,Physics",,3.267,"TIME-SERIES,COMPLEX,NETWORKS,BRAIN,VARIABILITY,SLEEPINESS,PERFORMANCE,FREQUENCY,WORKLOAD",CHAOS,,
99,Capacity assessment and co-optimization of CO2 storage and enhanced oil recovery in residual oil zones,182,,,"Chen Bailian,Pawar Rajesh J.","Chen BL,Pawar RJ",Chen BL,10.1016/j.petrol.2019.106342,United States Department of Energy (DOE),"Residual oil zones (ROZs) are increasingly being commercially exploited using CO2-enhanced oil recovery (CO2EOR) method. In this study, CO2 storage potential, long-term CO2 fate and oil recovery potential in ROZs are characterized based on a reservoir model for Goldsmith-Landreth San Andres Unit in the Permian Basin. The effects of CO2 injection rates, well patterns (five-spot and line-drive), well spacings, injection modes (continuous CO2 injection and water-alternating-gas injection) on the CO2 retention in the reservoir and the oil production are investigated. After the preliminary assessment of CO2 storage and EOR potentials in ROZs, we next develop a novel approach based on a newly developed optimization algorithm-Stochastic Simplex Approximate Gradient (StoSAG) and predictive empirical models constructed using machine learning technique to co-optimize CO2 storage and oil recovery in ROZs. The performance of co-optimization of CO2 storage and oil recovery is compared with the performance of optimization of only CO2 storage.","Residual oil zones,CO2 storage,Enhanced oil recovery,Capacity assessment,Optimization",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Energy & Fuels,Engineering",,,"CARBON,STORAGE,UNCERTAINTY,QUANTIFICATION,EOR,SEQUESTRATION,INJECTION,RESERVOIR,DESIGN,WATER",JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING,https://www.sciencedirect.com/science/article/am/pii/S0920410519307636,
100,Predictive model for water absorption in sublayers using a machine learning method,182,,,"Liu Wei,Liu Wei David,Gu Jianwei,Shen Xinpu","Liu W,Liu WD,Gu JW,Shen XP",Liu WD; Gu JW,10.1016/j.petrol.2019.106367,China University of Petroleum,"The sedimentary rhythm of Chinese oilfields is complicated and the heterogeneity is extremely strong. Allocating water absorption of each sublayer by dividing coefficient or numeric simulation cannot accurately reflect the actual water injection of the reservoir. Calculation based on water absorption profile monitored on site is the most commonly used method in oil field. However, access to these type of data is limited due to its cost and time related to acquisition. In this study, a machine learning approach was adopted to predict water absorption in sublayer based on geologic and production parameters of injectors and producers. On the one hand, it can save test costs. On the other hand, it can continuously predict water absorption of sublayers, and make up for water injection wells with insufficient injection profiles. A handful of training observations are obtained from on-site monitoring. Interwell connectivity is first conducted to identify connected producers for injectors. Introducing interwell connectivity helps to constitute predictor variables and yield significant improvements in feature selection. Connectivities in the well group are represented by similarity between injection sequence and production sequence, which is computed by Dynamic Time Warping. Average importance of predictors are then measured based on Mean Decrease Impurity, Mean Decrease Accuracy, and Ridge regression. Some relative important features are selected to consist the final predictors. The Extreme Gradient Boosting model is developed and then trained for making predictions given any set of observations. The proposed approach is validated by using actual field case from SL oilfield, China. Results show a significant correlation between predictions and actual value from on-site monitoring.","Water absorption,Machine learning,Feature selection,Dynamic time warping (DTW),Extreme gradient boosting (XGBoost)",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Energy & Fuels,Engineering",,4.376,"WELL-RATE,FLUCTUATIONS,FEATURE-SELECTION,INTERWELL,CONNECTIVITY",JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING,,
