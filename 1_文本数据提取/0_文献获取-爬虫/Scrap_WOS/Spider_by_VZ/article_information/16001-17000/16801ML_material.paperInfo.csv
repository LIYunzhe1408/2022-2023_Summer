,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,,,,,,,,,,,,,,,,,,,,
2,Structural damage detection and localization using a hybrid method and artificial intelligence techniques,19,5,1507-1523,"Hoshyar Azadeh Noori,Samali Bijan,Liyanapathirana Ranjith,Houshyar Afsaneh Nouri,Yu Yang","Hoshyar AN,Samali B,Liyanapathirana R,Houshyar AN,Yu Y",Hoshyar AN,10.1177/1475921719887768,Western Sydney University,"In this article, an intelligent scheme for structural damage detection and localization is introduced by implementing a hybrid method using the Hilbert-Huang transform and the wavelet transform. First, the second derivatives of the Discrete Laplacian are computed on Hilbert spectrum parameters at each frequency coordinate, and then, in order to highlight the influence of damage on signals, the data are rescaled and weighted with respect to the variance to adjust the differences in amplitude at different scales. Afterwards, the anti-symmetric extension is applied to deal with the boundary distortion phenomenon. A two-dimensional map is created using the multi two-dimensional discrete wavelet transform. This generates the coefficient matrices of level 2 approximation and horizontal, vertical and diagonal details. Horizontal detail coefficients are used to localize damages due to its sensitiveness to any perturbation. Finally, the validity of the algorithm corresponding to various damage states, the single state damage and multiple state damage, is examined through experimental analysis. The results indicate that the proposed framework can effectively localize cracks on concrete and reinforced concrete beams and can provide reliable crack localization in the presence of noise up to 5% more than the expected noise. In addition, the detection problem is mapped to machine learning tasks (support vector machine, k-nearest neighbours and ensemble methods) to automate the damage detection process. The quality of the models is evaluated and validated using the features extracted from the horizontal detail coefficients. The numerical results show that the ensemble models outperform the other models with respect to accuracy, prediction speed and training time.","Damage detection,localization,hybrid method,artificial intelligence,Hilbert-Huang transform,wavelet transforms,support vector machine,k-nearest neighbours,ensemble methods",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Engineering,Instruments & Instrumentation",,,"HILBERT-HUANG,TRANSFORM,DISCRETE,WAVELET,TRANSFORM,SIGNAL,DECOMPOSITION,CRACK,DETECTION,IDENTIFICATION",STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL,,
3,Multiparametric deep learning tissue signatures for a radiological biomarker of breast cancer: Preliminary results,47,1,75-88,"Parekh Vishwa S.,Macura Katarzyna J.,Harvey Susan C.,Kamel Ihab R.,EI-Khouli Riham,Bluemke David A.,Jacobs Michael A.","Parekh VS,Macura KJ,Harvey SC,Kamel IR,EI-Khouli R,Bluemke DA,Jacobs MA",Jacobs MA,10.1002/mp.13849,Johns Hopkins University,"Purpose Deep learning is emerging in radiology due to the increased computational capabilities available to reading rooms. These computational developments have the ability to mimic the radiologist and may allow for more accurate tissue characterization of normal and pathological lesion tissue to assist radiologists in defining different diseases. We introduce a novel tissue signature model based on tissue characteristics in breast tissue from multiparametric magnetic resonance imaging (mpMRI). The breast tissue signatures are used as inputs in a stacked sparse autoencoder (SSAE) multiparametric deep learning (MPDL) network for segmentation of breast mpMRI. Methods We constructed the MPDL network from SSAE with 5 layers with 10 nodes at each layer. A total cohort of 195 breast cancer subjects were used for training and testing of the MPDL network. The cohort consisted of a training dataset of 145 subjects and an independent validation set of 50 subjects. After segmentation, we used a combined SAE-support vector machine (SAE-SVM) learning method for classification. Dice similarity (DS) metrics were calculated between the segmented MPDL and dynamic contrast enhancement (DCE) MRI-defined lesions. Sensitivity, specificity, and area under the curve (AUC) metrics were used to classify benign from malignant lesions. Results The MPDL segmentation resulted in a high DS of 0.87 +/- 0.05 for malignant lesions and 0.84 +/- 0.07 for benign lesions. The MPDL had excellent sensitivity and specificity of 86% and 86% with positive predictive and negative predictive values of 92% and 73%, respectively, and an AUC of 0.90. Conclusions Using a new tissue signature model as inputs into the MPDL algorithm, we have successfully validated MPDL in a large cohort of subjects and achieved results similar to radiologists.","autoencoders,breast,cancer,CNN,deep learning,diffusion,machine learning,magnetic resonance imaging,multiparametric MRI,tissue biomarkers,tissue signature vector",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"PATHOLOGICAL,COMPLETE,RESPONSE,NEOADJUVANT,CHEMOTHERAPY,NEURAL-NETWORK,MRI,SEGMENTATION,PROSTATE,MODEL",MEDICAL PHYSICS,https://aapm.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mp.13849,
4,Analysis of pressure distribution during movement for the top part of female socks,90,11-12,1301-1310,"Yan Xiang-hui);,Wang Li-jun,Wang Ming-ling);,Shi Jia-ling","Yan XH,Wang LJ,Wang ML,Shi JL",Wang LJ,10.1177/0040517519888826,Zhejiang Sci-Tech University,"Female sports socks were studied to achieve the correlation between the ankle surface curvature and pressure distribution of the top part of socks. The transverse tension performance of the socks' top part was obtained using an Instron universal strength tester, and the leg size was measured with a [TC](2) contactless 3D body scanner. The pressure was monitored by a Pliance-X-32 pressure test system. Gray correlation, variance, and regression analysis were applied to study the correlation between movement velocity, fabric performance, leg circumference, and ankle pressure distribution. The dynamic pressure prediction models of multiple regression and back propagation (BP) neural network on the top part of socks were also established. The results show that the transverse tension performance and sock density have a significant effect on the ankle static pressure. Movement velocity, sock density, and leg circumference are positively correlated with dynamic pressure, while the elastic recovery rate of the fabric is negatively correlated with the pressure. Both of the multiple regression and BP neural network models can predict the dynamic pressure, and the BP neural network model is better than multiple regression at prediction error, which was kept to less than 0.5%. Therefore, the BP neural network model can be effectively used in female ribbed sock top design.","female sports socks,dynamic pressure of socks' top part,movement velocity,leg circumference,multiple regression model,BP neural network model",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Materials Science,,2.057,,TEXTILE RESEARCH JOURNAL,,
5,Multi-pathway multi-echo acquisition and neural contrast translation to generate a variety of quantitative and qualitative image contrasts,83,6,2310-2321,"Cheng Cheng-Chieh,Preiswerk Frank,Madore Bruno","Cheng CC,Preiswerk F,Madore B",Cheng CC,10.1002/mrm.28077,Harvard University,"Purpose Clinical exams typically involve acquiring many different image contrasts to help discriminate healthy from diseased states. Ideally, 3D quantitative maps of all of the main MR parameters would be obtained for improved tissue characterization. Using data from a 7-min whole-brain multi-pathway multi-echo (MPME) scan, we aimed to synthesize several 3D quantitative maps (T-1 and T-2) and qualitative contrasts (MPRAGE, FLAIR, T-1-weighted, T-2-weighted, and proton density [PD]-weighted). The ability of MPME acquisitions to capture large amounts of information in a relatively short amount of time suggests it may help reduce the duration of neuro MR exams. Methods Eight healthy volunteers were imaged at 3.0T using a 3D isotropic (1.2 mm) MPME sequence. Spin-echo, MPRAGE, and FLAIR scans were performed for training and validation. MPME signals were interpreted through neural networks for predictions of different quantitative and qualitative contrasts. Predictions were compared to reference values at voxel and region-of-interest levels. Results Mean absolute errors (MAEs) for T-1 and T-2 maps were 216 ms and 11 ms, respectively. In ROIs containing white matter (WM) and thalamus tissues, the mean T-1/T-2 predicted values were 899/62 ms and 1139/58 ms, consistent with reference values of 850/66 ms and 1126/58 ms, respectively. For qualitative contrasts, signals were normalized to those of WM, and MAEs for MPRAGE, FLAIR, T-1-weighted, T-2-weighted, and PD-weighted contrasts were 0.14, 0.15, 0.13, 0.16, and 0.05, respectively. Conclusions Using an MPME sequence and neural-network contrast translation, whole-brain results were obtained with a variety of quantitative and qualitative contrast in similar to 6.8 min.","contrast translation,machine learning,multi-pathway multi-echo acquisition,quantitative imaging,synthetic imaging",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"STEADY-STATE,DESS,DIFFUSION,MRI,SEQUENCE,FIELD,T-2,OPTIMIZATION,MOTION,BRAIN,PULSE",MAGNETIC RESONANCE IN MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7047605,
6,Atomic Mechanisms for the Si Atom Dynamics in Graphene: Chemical Transformations at the Edge and in the Bulk,29,52,,"Ziatdinov Maxim,Dyck Ondrej,Jesse Stephen,Kalinin Sergei V.","Ziatdinov M,Dyck O,Jesse S,Kalinin SV",Kalinin SV,10.1002/adfm.201904480,United States Department of Energy (DOE),"The dynamic behavior of e-beam irradiated Si atoms in the bulk and at the edges of single-layer graphene is examined using scanning transmission electron microscopy (STEM). A deep learning network is used to convert experimental STEM movies into coordinates of individual Si and carbon atoms. A Gaussian mixture model is further used to establish the elementary atomic configurations of the Si atoms, defining the bonding geometries and chemical species and accounting for the discrete rotational symmetry of the host lattice. The frequencies and Markov transition probabilities between these states are determined. This analysis enables insight into the defect populations and chemical transformation networks from the atomically resolved STEM data. Here, a clear tendency is observed for the formation of a 1D Si crystal along zigzag direction of graphene edges and for the Si impurity coupling to topological defects in bulk graphene.","atom dynamics,electron microscopy,graphene,machine learning",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,18.125,"2-DIMENSIONAL,MATERIALS,ELECTRON-MICROSCOPY,SINGLE,ATOMS,PHASE-CHANGE,BEAM,MICROSTRUCTURE,FABRICATION,KINETICS,MODELS,DAMAGE",ADVANCED FUNCTIONAL MATERIALS,https://www.osti.gov/biblio/1607241,
7,Analyzing gene expression data for pediatric and adult cancer diagnosis using logic learning machine and standard supervised methods,20,,,"Verda Damiano,Parodi Stefano,Ferrari Enrico,Muselli Marco","Verda D,Parodi S,Ferrari E,Muselli M",Muselli M,10.1186/s12859-019-2953-8,"Rulex Inc, Newton, MA 02460 USA.","Background: Logic Learning Machine (LLM) is an innovative method of supervised analysis capable of constructing models based on simple and intelligible rules.
In this investigation the performance of LLM in classifying patients with cancer was evaluated using a set of eight publicly available gene expression databases for cancer diagnosis.
LLM accuracy was assessed by summary ROC curve (sROC) analysis and estimated by the area under an sROC curve (sAUC). Its performance was compared in cross validation with that of standard supervised methods, namely: decision tree, artificial neural network, support vector machine (SVM) and k-nearest neighbor classifier.
Results: LLM showed an excellent accuracy (sAUC = 0.99, 95%CI: 0.98-1.0) and outperformed any other method except SVM.
Conclusions: LLM is a new powerful tool for the analysis of gene expression data for cancer diagnosis. Simple rules generated by LLM could contribute to a better understanding of cancer biology, potentially addressing therapeutic approaches.","Logic learning machine,Neural network,Support vector machine,Decision tree,K-nearest neighbor classifier,Gene expression,Microarrays,Cancer,Diagnosis,Prognosis",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,,AQUAGLYCEROPORINS,BMC BIOINFORMATICS,https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-019-2953-8,
8,Graph Embedding Deep Learning Guides Microbial Biomarkers' Identification,10,,,"Zhu Qiang,Jiang Xingpeng,Zhu Qing,Pan Min,He Tingting","Zhu Q,Jiang XP,Zhu Q,Pan M,He TT",Jiang XP,10.3389/fgene.2019.01182,Central China Normal University,"The microbiome-wide association studies are to figure out the relationship between microorganisms and humans, with the goal of discovering relevant biomarkers to guide disease diagnosis. However, the microbiome data is complex, with high noise and dimensions. Traditional machine learning methods are limited by the models' representation ability and cannot learn complex patterns from the data. Recently, deep learning has been widely applied to fields ranging from text processing to image recognition due to its efficient flexibility and high capacity. But the deep learning models must be trained with enough data in order to achieve good performance, which is impractical in reality. In addition, deep learning is considered as black box and hard to interpret. These factors make deep learning not widely used in microbiome-wide association studies. In this work, we construct a sparse microbial interaction network and embed this graph into deep model to alleviate the risk of overfitting and improve the performance. Further, we explore a Graph Embedding Deep Feedforward Network (GEDFN) to conduct feature selection and guide meaningful microbial markers' identification. Based on the experimental results, we verify the feasibility of combining the microbial graph model with the deep learning model, and demonstrate the feasibility of applying deep learning and feature selection on microbial data. Our main contributions are: firstly, we utilize different methods to construct a variety of microbial interaction networks and combine the network via graph embedding deep learning. Secondly, we introduce a feature selection method based on graph embedding and validate the biological meaning of microbial markers. The code is available at https://github.com/MicroAVA/GEDFN.git.","WIDE ASSOCIATION,METAGENOME",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Genetics & Heredity,,4.888,"WIDE,ASSOCIATION,METAGENOME",FRONTIERS IN GENETICS,https://doi.org/10.3389/fgene.2019.01182,
9,Enhancing materials property prediction by leveraging computational and experimental data using deep transfer learning,10,,,"Jha Dipendra,Choudhary Kamal,Tavazza Francesca,Liao Wei-keng,Choudhary Alok,Campbell Carelyn,Agrawal Ankit","Jha D,Choudhary K,Tavazza F,Liao WK,Choudhary A,Campbell C,Agrawal A",Agrawal A,10.1038/s41467-019-13297-w,Northwestern University,"The current predictive modeling techniques applied to Density Functional Theory (DFT) computations have helped accelerate the process of materials discovery by providing significantly faster methods to scan materials candidates, thereby reducing the search space for future DFT computations and experiments. However, in addition to prediction error against DFT-computed properties, such predictive models also inherit the DFT-computation discrepancies against experimentally measured properties. To address this challenge, we demonstrate that using deep transfer learning, existing large DFT-computational data sets (such as the Open Quantum Materials Database (OQMD)) can be leveraged together with other smaller DFT-computed data sets as well as available experimental observations to build robust prediction models. We build a highly accurate model for predicting formation energy of materials from their compositions; using an experimental data set of 1,963 observations, the proposed approach yields a mean absolute error (MAE) of 0.06 eV/atom, which is significantly better than existing machine learning (ML) prediction modeling based on DFT computations and is comparable to the MAE of DFT-computation itself.","DENSITY-FUNCTIONAL THEORY,MACHINE,DIFFUSION",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,15.805,"DENSITY-FUNCTIONAL,THEORY,MACHINE,DIFFUSION",NATURE COMMUNICATIONS,https://europepmc.org/articles/pmc6874674?pdf=render,
10,,,,,,,,,,,,,,,,,,,,
11,,,,,,,,,,,,,,,,,,,,
12,,,,,,,,,,,,,,,,,,,,
13,Using deep learning techniques in medical imaging: a systematic review of applications on CT and PET,53,6,4093-4160,"Domingues Ines,Pereira Gisele,Martins Pedro,Duarte Hugo,Santos Joao,Abreu Pedro Henriques","Domingues I,Pereira G,Martins P,Duarte H,Santos J,Abreu PH",Abreu PH,10.1007/s10462-019-09788-3,Universidade de Coimbra,"Medical imaging is a rich source of invaluable information necessary for clinical judgements. However, the analysis of those exams is not a trivial assignment. In recent times, the use of deep learning (DL) techniques, supervised or unsupervised, has been empowered and it is one of the current research key areas in medical image analysis. This paper presents a survey of the use of DL architectures in computer-assisted imaging contexts, attending two different image modalities: the actively studied computed tomography and the under-studied positron emission tomography, as well as the combination of both modalities, which has been an important landmark in several decisions related to numerous diseases. In the making of this review, we analysed over 180 relevant studies, published between 2014 and 2019, that are sectioned by the purpose of the research and the imaging modality type. We conclude by addressing research issues and suggesting future directions for further improvement. To our best knowledge, there is no previous work making a review of this issue.","Deep learning,Computed tomography,Positron emission tomography,Medical imaging",Review,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,7.857,"CONVOLUTIONAL,NEURAL-NETWORK,LOW-DOSE,CT,COMPUTER-AIDED,DETECTION,GENERATIVE,ADVERSARIAL,NETWORKS,PULMONARY,NODULE,DETECTION,AUTOMATIC,DETECTION,FEATURE-EXTRACTION,CANCER,DETECTION,LUNG,NODULES,PLANNING,CT",ARTIFICIAL INTELLIGENCE REVIEW,,
14,Decoding Phases of Matter by Machine-Learning Raman Spectroscopy,12,5,,"Cui Anyang,Jiang Kai,Jiang Minhong,Shang Liyan,Zhu Liangqing,Hu Zhigao,Xu Guisheng,Chu Junhao","Cui AY,Jiang K,Jiang MH,Shang LY,Zhu LQ,Hu ZG,Xu GS,Chu JH",Hu ZG,10.1103/PhysRevApplied.12.054049,East China Normal University,"Phase transitions of condensed matter have long been a spotlight issue studied by extensive theoretical and experimental investigations. Machine learning can build an integral model-dominant workflow to statistically analyze the collective dynamics of materials and deduce the structure. We use a supportvector-machine algorithm to propose an effective method to recognize the orthorhombic, tetragonal, and cubic phases as well as to construct the phase diagram in ferroelectric crystals by mining and learning the behavioral vectors of the phonon vibrations in a crystalline lattice from Raman scattering, which is a tool typically used to detect structural properties at the molecular level. This study creates a unifying framework including material synthesis and characterization, feature engineering and principal-component analysis, learner evaluation and optimization, structure prediction, and future development of the model. It paves the way to the application of a generic approach for predicting unexplored structures and materials in the future.","LEAD-FREE,PIEZOELECTRIC PROPERTIES,SINGLE-CRYSTAL,DESIGN,TRANSITIONS,PROPERTY",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,5.111,"LEAD-FREE,PIEZOELECTRIC,PROPERTIES,SINGLE-CRYSTAL,DESIGN,TRANSITIONS,PROPERTY",PHYSICAL REVIEW APPLIED,,
15,CD4+versus CD8+T-lymphocyte identification in an integrated microfluidic chip using light scattering and machine learning,19,22,3888-3898,"Rossi Domenico,Dannhauser David,Telesco Mariarosaria,Netti Paolo A.,Causa Filippo","Rossi D,Dannhauser D,Telesco M,Netti PA,Causa F",Causa F,10.1039/c9lc00695h,University of Naples Federico II,"T lymphocytes are a group of cells representing the main effectors of human adaptive immunity. Characterization of the most representative T-lymphocyte subclasses, CD4+ and CD8+, is challenging, but has a significant impact on clinical decisions. Up to now, T lymphocytes have been identified by quite complex cytometric assays, which are based on antibody labeling. However, a label-free approach based on pure biophysical evaluation at a single-cell level could enable the ability to distinguish between these subclasses. Here, we report a light-scattering approach, supported by accurate data mining, to evaluate cell biophysical properties on an integrated microfluidic chip. In order to perform single-cell optical analysis in viscoelastic fluids, such a chip is composed of mixing, alignment, readout and collection sections. In particular, we measured the cell dimensions, the refractive index of the cell nucleus, the refractive index of the cytosol, and the nucleus-to-cytosol ratio. Combining measurement of biophysical properties and machine learning allows us to both distinguish and count human CD4+ and CD8+ cells with an accuracy of 79%. An enhanced identification accuracy of 88% can be achieved by stimulating the cells with a selective anti-apoptotic protein, which results in increased biophysical differences between CD4+ and CD8+ cells. This approach has been successfully validated by analysis of samples that recapitulate physiological and pathological scenarios (CD4+/CD8+ ratios). The results are encouraging for the possible application of our approach in hematological clinical routines, as well as in diagnosis and follow-up of specific pathologies, such as human immunodeficiency virus (HIV) progression.","FLOW-CYTOMETRY,CELL-POPULATIONS,PASSIVE MIXERS,RATIO,ACTIVATION,ANTIGENS,CD4(+),IL-15",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Biochemistry & Molecular Biology,Chemistry,Science & Technology - Other Topics,Instruments & Instrumentation",,7.379,"FLOW-CYTOMETRY,CELL-POPULATIONS,PASSIVE,MIXERS,RATIO,ACTIVATION,ANTIGENS,CD4%28%2B%29,IL-15",LAB ON A CHIP,,
16,,,,,,,,,,,,,,,,,,,,
17,Unraveling Correlations between Molecular Properties and Device Parameters of Organic Solar Cells Using Machine Learning,10,22,7277-7284,"Sahu Harikrishna,Ma Haibo","Sahu H,Ma HB",Sahu H; Ma HB,10.1021/acs.jpclett.9b02772,Nanjing University,"Understanding the relationships between molecular properties and device parameters is highly desired not only to improve the overall performance of an organic solar cell but also to fulfill the requirements of a device for a particular application such as solar-to-fuel energy conversion (high open-circuit voltage (V-OC)) or solar window applications (high short circuit current (J(SC))). In this work, a series of machine learning models are built for three important device characteristics (V-OC, J(SC), and fill factor) using 13 crucial molecular properties as descriptors, resulting in an impressive predictive performance (r = 0.7). These models may play a vital role in designing promising organic materials for a specific photovoltaic application with high V-OC/J(SC). The importance of descriptors for each device parameter is unraveled, which may assist in tuning them and improve understanding of the energy conversion process.","OPEN-CIRCUIT VOLTAGE,BIMOLECULAR CHARGE RECOMBINATION,FILL FACTOR,DESIGN,FULLERENE,POLYMERS,PERFORMANCE,SEPARATION,ADDITIVES,PREDICT",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,7.643,"OPEN-CIRCUIT,VOLTAGE,BIMOLECULAR,CHARGE,RECOMBINATION,FILL,FACTOR,DESIGN,FULLERENE,POLYMERS,PERFORMANCE,SEPARATION,ADDITIVES,PREDICT",JOURNAL OF PHYSICAL CHEMISTRY LETTERS,,
18,Machine learning and artificial neural network accelerated computational discoveries in materials science,10,3,,"Hong Yang,Hou Bo,Jiang Hengle,Zhang Jingchao","Hong Y,Hou B,Jiang HL,Zhang JC",Zhang JC,10.1002/wcms.1450,University of Nebraska System,"Artificial intelligence (AI) has been referred to as the ""fourth paradigm of science,"" and as part of a coherent toolbox of data-driven approaches, machine learning (ML) dramatically accelerates the computational discoveries. As the machinery for ML algorithms matures, significant advances have been made not only by the mainstream AI researchers, but also those work in computational materials science. The number of ML and artificial neural network (ANN) applications in the computational materials science is growing at an astounding rate. This perspective briefly reviews the state-of-the-art progress in some supervised and unsupervised methods with their respective applications. The characteristics of primary ML and ANN algorithms are first described. Then, the most critical applications of AI in computational materials science such as empirical interatomic potential development, ML-based potential, property predictions, and molecular discoveries using generative adversarial networks (GAN) are comprehensively reviewed. The central ideas underlying these ML applications are discussed, and future directions for integrating ML with computational materials science are given. Finally, a discussion on the applicability and limitations of current ML techniques and the remaining challenges are summarized. This article is categorized under: Computer and Information Science > Chemoinformatics. Structure and Mechanism > Computational Materials Science. Computer and Information Science > Computer Algorithms and Programming. Software > Molecular Modeling.","deep learning,empirical potential development,machine learning,molecular discovery,property prediction",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Chemistry,Mathematical & Computational Biology",,16.743,"MOLECULAR-DYNAMICS,THERMAL-CONDUCTIVITY,GENERALIZATION,PERFORMANCE,INTERATOMIC,POTENTIALS,MECHANICAL-PROPERTIES,GENERAL-PURPOSE,PROTON-TRANSFER,PREDICTION,TRANSPORT,GRAPHENE",WILEY INTERDISCIPLINARY REVIEWS-COMPUTATIONAL MOLECULAR SCIENCE,https://orca.cardiff.ac.uk/129553/1/WIRES-BH.pdf,
19,Machine Learning Approaches for Thermoelectric Materials Research,30,5,,"Wang Tian,Zhang Cheng,Snoussi Hichem,Zhang Gang","Wang T,Zhang C,Snoussi H,Zhang G",Wang T,10.1002/adfm.201906041,Beihang University,"Thermoelectric (TE) materials provide a solid-state solution in waste heat recovery and refrigeration. During the past few decades, considerable effort has been devoted towards improving the performance of TE materials, which requires the optimization of multiple interrelated properties. A fundamental understanding of the interaction processes between the various energy carriers, such as electrons and phonons, is critical for advances in the development of TE materials. However, this understanding remains challenging primarily due to the inaccessibility of time scales using standard atomistic simulations. Machine learning methods, well known for their data-analysis capability, have been successfully applied in research on TE materials in recent years. Here, an overview of the machine learning methods used in thermoelectric studies is provided, with the role that each machine learning method plays being systematically discussed. Furthermore, to date, the scale of thermoelectric-related databases is much smaller than those in other fields, such as e-commerce, image identification, and speech recognition. To overcome this limitation, possible strategies to utilize small databases in promoting materials science are also discussed. Finally, a brief conclusion and outlook are presented.","data analysis,machine learning,thermoelectric materials",Review,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,18.125,"THERMAL-CONDUCTIVITY,DISCOVERY,MODEL",ADVANCED FUNCTIONAL MATERIALS,,
20,Prediction of compressive strength and portland cement composition using cross-validation and feature ranking techniques,225,,292-301,"Vakharia Vinay,Gujar Rajesh","Vakharia V,Gujar R",Vakharia V,10.1016/j.conbuildmat.2019.07.224,Pandit Deendayal Energy University,"Prediction of compressive strength and concrete composition using machine learning models is an essential feature in civil engineering applications. In the present paper, a methodology is proposed for the prediction of compressive strength of concrete and portland cement composition using three experimental data sets. Ten-fold cross-validation procedure is applied to four machine learning models Isotonic regression, Artificial neural network, Support vector machine, and Random forest. Further comparison was made with feature ranking and without feature ranking to reduce the computational time and to achieve better prediction accuracy. The accuracy of machine learning models are analyzed with four parameters, Correlation coefficient. Kendall's tau, Mean absolute error, and Root mean square error. It is observed that better prediction capability is achieved with the ten-fold cross-validation, since it gives a statistically unbiased result. Results obtain reveals a high correlation and less error between the experimental and predicted values for all the three experimental datasets consider. (C) 2019 Elsevier Ltd. All rights reserved.","Concrete,Cement,Feature ranking,Machine learning,Ten-fold cross-validation",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Construction & Building Technology,Engineering,Materials Science",,6.841,"HIGH-PERFORMANCE,CONCRETE,FAULT-DIAGNOSIS,MODEL",CONSTRUCTION AND BUILDING MATERIALS,,
21,"Digestate evaporation treatment in biogas plants: A techno-economic assessment by Monte Carlo, neural networks and decision trees",238,,,"Vondra Marek,Tous Michal,Teng Sin Yong","Vondra M,Tous M,Teng SY",Vondra M,10.1016/j.jclepro.2019.117870,Brno University of Technology,"Biogas production is one of the most promising pathways toward fully utilizing green energy within a circular economy. The anaerobic digestion process is the industry standard technology for biogas production due to its lowered energy consumption and its reliance on microbiology. Even in such an environmental-friendly process, liquid digestate is still produced from the remains of digested bio-feedstock and will require treatment. With unsuitable treatment procedure for liquid digestate, the mass of bio-feedstock can potentially escape the circular supply chain within the economy. This paper recommends the implementation of evaporator systems to provide a sustainable liquid digestate treating mechanism within the economy. Studied evaporator systems are represented by vacuum evaporation in combination with ammonia scrubber, stripping and reverse osmosis. Nevertheless, complex multi-dimensional decisions should be made by stakeholders before implementing such systems. Our work utilizes a novel techno-economics model to study the techno-economics robustness in implementing recent state-of-art vacuum evaporation systems with exploitation of waste heat from combined heat and power (CHP) units in biogas plants (BGP). To take into the account the stochasticity of the real world and robustness of the analysis, we used the Monte-Carlo simulation technique to generate more than 20,000 of different possibilities for the implementation of the evaporation system. Favourable decision pathways are then selected using a novel methodology which utilizes the artificial neural network and a hyper-optimized decision tree classifier. Two pathways that give the highest probability of providing a fast payback period are identified. Descriptive statistics are also used to analyse the distributions of decision parameters that lead to success in implementing the evaporator system. The results highlighted that integration of evaporation system are favourable when transport costs and incentives for CHP units are large and while feed-in tariffs for electricity production and specific investment costs are low. The result of this work is expected to pave the way for BGP stakeholders and decision makers in implementing liquid digestate treating technologies within the currently existing infrastructure. (c) 2019 Elsevier Ltd. All rights reserved.","Anaerobic digestion,Machine learning,Vacuum evaporation,Liquid digestate,Biogas plant,Energy consumption,Nutrient recovery,Circular economy,Ammonium sulphate solution",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Science & Technology - Other Topics,Engineering,Environmental Sciences & Ecology",,9.444,"ANAEROBIC-DIGESTION,ENERGY,PERFORMANCE,LIQUID,DIGESTATE,CO-DIGESTION,LIFE-CYCLE,NUTRIENT,RECOVERY,TECHNOLOGIES,SEPARATION,EFFICIENCY",JOURNAL OF CLEANER PRODUCTION,https://mpra.ub.uni-muenchen.de/95770/1/MPRA_paper_95770.pdf,
22,Improving Automated Pediatric Bone Age Estimation Using Ensembles of Models from the 2017 RSNA Machine Learning Challenge.,1,6,e190053,",,,,","Pan Ian,Thodberg Hans Henrik,Halabi Safwan S,Kalpathy-Cramer Jayashree,Larson David B",,10.1148/ryai.2019190053,,"Purpose: To investigate improvements in performance for automatic bone age estimation that can be gained through model ensembling.Results: The estimated generalization MAD of a single model was 4.55 months. The best-performing ensemble consisted of four models with an MAD of 3.79 months. The mean pairwise correlation of models within this ensemble was 0.47. In comparison, the lowest achievable MAD by combining the highest-ranking models based on individual scores was 3.93 months using eight models with a mean pairwise model correlation of 0.67. 2019 by the Radiological Society of North America, Inc.",,Journal Article,,,,,,,,
23,Unsupervised discovery of solid-state lithium ion conductors,10,,,"Zhang Ying,He Xingfeng,Chen Zhiqian,Bai Qiang,Nolan Adelaide M.,Roberts Charles A.,Banerjee Debasish,Matsunaga Tomoya,Mo Yifei,Ling Chen","Zhang Y,He XF,Chen ZQ,Bai Q,Nolan AM,Roberts CA,Banerjee D,Matsunaga T,Mo YF,Ling C",Ling C,10.1038/s41467-019-13214-1,Toyota Motor Corporation,"Although machine learning has gained great interest in the discovery of functional materials, the advancement of reliable models is impeded by the scarcity of available materials property data. Here we propose and demonstrate a distinctive approach for materials discovery using unsupervised learning, which does not require labeled data and thus alleviates the data scarcity challenge. Using solid-state Li-ion conductors as a model problem, unsupervised materials discovery utilizes a limited quantity of conductivity data to prioritize a candidate list from a wide range of Li-containing materials for further accurate screening. Our unsupervised learning scheme discovers 16 new fast Li-conductors with conductivities of 10(-4)-10(-1) S cm(-1) predicted in ab initio molecular dynamics simulations. These compounds have structures and chemistries distinct to known systems, demonstrating the capability of unsupervised learning for discovering materials over a wide materials space with limited property data.","CONDUCTIVITY,CLASSIFICATION,STABILITY,DESIGN,ORIGIN",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,15.805,"CONDUCTIVITY,CLASSIFICATION,STABILITY,DESIGN,ORIGIN",NATURE COMMUNICATIONS,https://vtechworks.lib.vt.edu/bitstream/10919/96737/1/s41467-019-13214-1.pdf,
24,Data-Driven Safety Envelope of Lithium-Ion Batteries for Electric Vehicles,3,11,2703-2715,"Li Wei,Zhu Juner,Xia Yong,Gorji Maysam B.,Wierzbicki Tomasz","Li W,Zhu JE,Xia Y,Gorji MB,Wierzbicki T",Zhu JE,10.1016/j.joule.2019.07.026,Massachusetts Institute of Technology (MIT),"In the accident scenarios of electric vehicles, the battery pack can be damaged catastrophically, resulting in the electric short circuit, thermal runaway, and possible fire and explosion. Therefore, it is important to investigate the range of conditions under which the safe operation of each individual cell is adequately controlled, known as the ""safety envelope"" The biggest challenge of developing such a safety envelope lies in the acquisition of a large data bank of battery failure tests. In this study, we overcome the challenge by establishing a high-accuracy detailed computational model of lithium-ion pouch cells, in which all the component materials are characterized by well-calibrated constitutive models. A large matrix of extreme mechanical loading conditions is simulated, and a data-driven safety envelope is obtained using the machine learning algorithm. This work is a demonstration of combining numerical data generation with data-driven modeling to predict the safety of energy storage systems.","SHORT-CIRCUIT,MECHANICAL-PROPERTIES,GRANULAR-MATERIALS,THERMAL RUNAWAY,CELLS,CHALLENGES,DESIGN",Article,"CELL PRESS, 50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA","Chemistry,Energy & Fuels,Materials Science",,41.247,"SHORT-CIRCUIT,MECHANICAL-PROPERTIES,GRANULAR-MATERIALS,THERMAL,RUNAWAY,CELLS,CHALLENGES,DESIGN",JOULE,http://www.cell.com/article/S2542435119303708/pdf,
25,Deep spectral learning for label-free optical imaging oximetry with uncertainty quantification,8,,,"Liu Rongrong,Cheng Shiyi,Tian Lei,Yi Ji","Liu RR,Cheng SY,Tian L,Yi J",Yi J,10.1038/s41377-019-0216-0,Boston University,"Measurement of blood oxygen saturation (sO(2)) by optical imaging oximetry provides invaluable insight into local tissue functions and metabolism. Despite different embodiments and modalities, all label-free optical-imaging oximetry techniques utilize the same principle of sO(2)-dependent spectral contrast from haemoglobin. Traditional approaches for quantifying sO(2) often rely on analytical models that are fitted by the spectral measurements. These approaches in practice suffer from uncertainties due to biological variability, tissue geometry, light scattering, systemic spectral bias, and variations in the experimental conditions. Here, we propose a new data-driven approach, termed deep spectral learning (DSL), to achieve oximetry that is highly robust to experimental variations and, more importantly, able to provide uncertainty quantification for each sO(2) prediction. To demonstrate the robustness and generalizability of DSL, we analyse data from two visible light optical coherence tomography (vis-OCT) setups across two separate in vivo experiments on rat retinas. Predictions made by DSL are highly adaptive to experimental variabilities as well as the depth-dependent backscattering spectra. Two neural-network-based models are tested and compared with the traditional least-squares fitting (LSF) method. The DSL-predicted sO(2) shows significantly lower mean-square errors than those of the LSF. For the first time, we have demonstrated en face maps of retinal oximetry along with a pixel-wise confidence assessment. Our DSL overcomes several limitations of traditional approaches and provides a more flexible, robust, and reliable deep learning approach for in vivo non-invasive label-free optical oximetry.","COHERENCE TOMOGRAPHY,RETINAL OXIMETRY,OXYGEN-SATURATION,PATHOLOGY,IMAGES,BLOOD",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Optics,,16.996,"COHERENCE,TOMOGRAPHY,RETINAL,OXIMETRY,OXYGEN-SATURATION,PATHOLOGY,IMAGES,BLOOD",LIGHT-SCIENCE & APPLICATIONS,https://europepmc.org/articles/pmc6864044?pdf=render,
26,Performance comparison of feedforward neural network training algorithms in modelling microwave pyrolysis of oil palm fibre for hydrogen and biochar production,15,1,,"Nasrudin Nor Anisa,Jewaratnam Jegalakshimi,Hossain Arafat,Ganeson Poo Balan","Nasrudin NA,Jewaratnam J,Hossain A,Ganeson PB",Jewaratnam J,10.1002/apj.2388,Universiti Malaya,"Microwave pyrolysis of oil palm fibre (OPF) was conducted to study the effect of microwave power, temperature, and nitrogen (N-2) flow rate on the production of hydrogen and biochar. The effect of microwave power ranging from 400 to 900 W, reaction temperatures ranging from 450 degrees C to 700 degrees C, and N-2 flow rates ranging 200 to 1,200 cm(3) min(-1) were investigated. The microwave power, reaction temperature, and N-2 flow rates are directly proportional to hydrogen and inversely proportional to biochar yield. The characteristics of the biochar were analysed using CHNOS, scanning electron microscopy, and Brunauer-Emmett-Teller results. Central composite design was used to optimize the number of experiment. The optimized experimental datasets were used as inputs for developing a model that can predict the weight of hydrogen and biochar from microwave pyrolysis of OPF. A multilayer feedforward neural network model was developed by comparing the performance of 11 different types of backpropagation training algorithms. The 11 training algorithms belong to six classes, which are (a) additive momentum, (b) self-adaptive learning rate, (c) resilient backpropagation, (d) conjugate gradient, (e) quasi-Newton, and (f) Bayesian regulation (BR). Best performing training algorithm was selected based on the lowest error values computed. The objective of this research is to identify the most suitable training algorithm for this process. Levenberg-Marquardt and BR exhibited very good performance. BR exhibited best performance with lowest error values in predicting weight of hydrogen and biochar. The testing data error values for hydrogen weight is 0.216 root mean square error (RMSE), 0.144 mean absolute error (MAE), and 0.020 mean absolute percentage error (MAPE), and biochar is 0.886 RMSE, 0.489 MAE, and 0.019 MAPE. The optimum number of hidden neuron for this algorithm is 19 with mean square error 0.23. The biochar exhibits porous structure suggesting possible land application.","biochar,clean energy,feedforward neural network,hydrogen,microwave pyrolysis,oil palm fibre",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Engineering,,1.605,"PROCESS,PARAMETERS,BIOMASS,OPF,ENERGY,WASTE",ASIA-PACIFIC JOURNAL OF CHEMICAL ENGINEERING,,
27,Distributed deep learning across multisite datasets for generalized CT hemorrhage segmentation,47,1,89-98,"Remedios Samuel W.,Roy Snehashis,Bermudez Camilo,Patel Mayur B.,Butman John A.,Landman Bennett A.,Pham Dzung L.","Remedios SW,Roy S,Bermudez C,Patel MB,Butman JA,Landman BA,Pham DL",Remedios SW,10.1002/mp.13880,"Henry M. Jackson Foundation for the Advancement of Military Medicine, Inc","Purpose As deep neural networks achieve more success in the wide field of computer vision, greater emphasis is being placed on the generalizations of these models for production deployment. With sufficiently large training datasets, models can typically avoid overfitting their data; however, for medical imaging it is often difficult to obtain enough data from a single site. Sharing data between institutions is also frequently nonviable or prohibited due to security measures and research compliance constraints, enforced to guard protected health information (PHI) and patient anonymity. Methods In this paper, we implement cyclic weight transfer with independent datasets from multiple geographically disparate sites without compromising PHI. We compare results between single-site learning (SSL) and multisite learning (MSL) models on testing data drawn from each of the training sites as well as two other institutions. Results The MSL model attains an average dice similarity coefficient (DSC) of 0.690 on the holdout institution datasets with a volume correlation of 0.914, respectively corresponding to a 7% and 5% statistically significant improvement over the average of both SSL models, which attained an average DSC of 0.646 and average correlation of 0.871. Conclusions We show that a neural network can be efficiently trained on data from two physically remote sites without consolidating patient data to a single location. The resulting network improves model generalization and achieves higher average DSCs on external datasets than neural networks trained on data from a single source.","computed tomography (CT),deep learning,distributed,hemorrhage,image segmentation,lesion,multisite,neural network,traumatic brain injury",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,,"HUMAN,BRAIN,VARIABILITY,DICOM",MEDICAL PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6983946,
28,A fast and scalable method for quality assurance of deformable image registration on lung CT scans using convolutional neural networks,47,1,99-109,"Galib Shaikat M.,Lee Hyoung K.,Guy Christopher L.,Riblett Matthew J.,Hugo Geoffrey D.","Galib SM,Lee HK,Guy CL,Riblett MJ,Hugo GD",Hugo GD,10.1002/mp.13890,Washington University (WUSTL),"Purpose To develop and evaluate a method to automatically identify and quantify deformable image registration (DIR) errors between lung computed tomography (CT) scans for quality assurance (QA) purposes. Methods We propose a deep learning method to flag registration errors. The method involves preparation of a dataset for machine learning model training and testing, design of a three-dimensional (3D) convolutional neural network architecture that classifies registrations into good or poor classes, and evaluation of a metric called registration error index (REI) which provides a quantitative measure of registration error. Results Our study shows that, despite having limited number of training images available (10 CT scan pairs for training and 17 CT scan pairs for testing), the method achieves 0.882 AUC-ROC on the test dataset. Furthermore, the combined standard uncertainty of the estimated REI by our model lies within +/- 0.11 (+/- 11% of true REI value), with a confidence level of approximately 68%. Conclusions We have developed and evaluated our method using original clinical registrations without generating any synthetic/simulated data. Moreover, test data were acquired from a different environment than that of training data, so that the method was validated robustly. The results of this study showed that our algorithm performs reasonably well in challenging scenarios.","deep learning,image registration,neural network,quality assurance",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"TARGET,REGISTRATION,ACCURACY,ERROR,VALIDATION,ALGORITHM",MEDICAL PHYSICS,,
29,Deep learning modeling using normal mammograms for predicting breast cancer risk,47,1,110-118,"Arefan Dooman,Mohamed Aly A.,Berg Wendie A.,Zuley Margarita L.,Sumkin Jules H.,Wu Shandong","Arefan D,Mohamed AA,Berg WA,Zuley ML,Sumkin JH,Wu SD",Wu SD,10.1002/mp.13886,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Purpose To investigate two deep learning-based modeling schemes for predicting short-term risk of developing breast cancer using prior normal screening digital mammograms in a case-control setting. Methods We conducted a retrospective Institutional Review Board-approved study on a case-control cohort of 226 patients (including 113 women diagnosed with breast cancer and 113 controls) who underwent general population breast cancer screening. For each patient, a prior normal (i.e., with negative or benign findings) digital mammogram examination [including mediolateral oblique (MLO) view and craniocaudal (CC) view two images] was collected. Thus, a total of 452 normal images (226 MLO view images and 226 CC view images) of this case-control cohort were analyzed to predict the outcome, i.e., developing breast cancer (cancer cases) or remaining breast cancer-free (controls) within the follow-up period. We implemented an end-to-end deep learning model and a GoogLeNet-LDA model and compared their effects in several experimental settings using two mammographic view images and inputting two different subregions of the images to the models. The proposed models were also compared to logistic regression modeling of mammographic breast density. Area under the receiver operating characteristic curve (AUC) was used as the model performance metric. Results The highest AUC was 0.73 [95% Confidence Interval (CI): 0.68-0.78; GoogLeNet-LDA model on CC view] when using the whole-breast and was 0.72 (95% CI: 0.67-0.76; GoogLeNet-LDA model on MLO + CC view) when using the dense tissue, respectively, as the model input. The GoogleNet-LDA model significantly (all P < 0.05) outperformed the end-to-end GoogLeNet model in all experiments. CC view was consistently more predictive than MLO view in both deep learning models, regardless of the input subregions. Both models exhibited superior performance than the percent breast density (AUC = 0.54; 95% CI: 0.49-0.59). Conclusions The proposed deep learning modeling approach can predict short-term breast cancer risk using normal screening mammogram images. Larger studies are needed to further reveal the promise of deep learning in enhancing imaging-based breast cancer risk assessment.","breast cancer,breast density,deep learning,digital mammography,risk biomarkers",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"DENSITY,ASSESSMENT,CLASSIFICATION,HISTOLOGY,SOFTWARE,IMAGES,CNN",MEDICAL PHYSICS,https://aapm.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mp.13886,
30,Processing Optimization and Property Predictions of Hot-Extruded Bi-Te-Se Thermoelectric Materials via Machine Learning,3,1,,"Wang Zhi-Lei,Adachi Yoshitaka,Chen Zhong-Chun","Wang ZL,Adachi Y,Chen ZC",Chen ZC,10.1002/adts.201900197,Tottori University,"Traditional experiment-based materials research is becoming increasingly insufficient to thoroughly understand materials' characteristics and thus it is becoming difficult to develop novel materials with better performance. Machine learning is applied to hot-extruded CuxBi2Te2.85+ySe0.15 thermoelectric materials, and the relationships between the processing, microstructure, and properties are further investigated via a data-driven approach. A properties-to-microstructure-to-processing inverse analysis is proposed and performed by a genetic algorithm. The analysis results indicate that hot-extruded materials have a potential best figure of merit (ZT) value of 1.15, which is 1.32 times larger than their best experimental value (0.87). To obtain this optimal property, processing variables such as higher extrusion temperature and larger Cu content and microstructure with a larger average grain size and higher density are required. The proposed data-driven approach is expected to provide a new avenue for designing high-performance Bi-Te-Se thermoelectric materials and thus to accelerate discoveries of novel materials.","data-driven materials design,inverse analysis,machine learning,property prediction,thermoelectric materials",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Science & Technology - Other Topics,,4.004,"MICROSTRUCTURE,ALLOYS,PERFORMANCE",ADVANCED THEORY AND SIMULATIONS,,
31,,,,,,,,,,,,,,,,,,,,
32,,,,,,,,,,,,,,,,,,,,
33,,,,,,,,,,,,,,,,,,,,
34,,,,,,,,,,,,,,,,,,,,
35,Exploration research on the fusion of multimodal spectrum technology to improve performance of rapid diagnosis scheme for thyroid dysfunction,13,2,,"Chen Cheng,Du Guoli,Tong Dongni,Lv Guodong,Lv Xiaoyi,Si Rumeng,Tang Jun,Li Hongyi,Ma Hongbing,Mo Jiaqing","Chen C,Du GL,Tong DN,Lv GD,Lv XY,Si RM,Tang J,Li HY,Ma HB,Mo JQ",Lv XY,10.1002/jbio.201900099,Xinjiang University,"The spectral fusion by Raman spectroscopy and Fourier infrared spectroscopy combined with pattern recognition algorithms is utilized to diagnose thyroid dysfunction serum, and finds the spectral segment with the highest sensitivity to further advance diagnosis speed. Compared with the single infrared spectroscopy or Raman spectroscopy, the proposal can improve the detection accuracy, and can obtain more spectral features, indicating greater differences between thyroid dysfunction and normal serum samples. For discriminating different samples, principal component analysis (PCA) was first used for feature extraction to reduce the dimension of high-dimension spectral data and spectral fusion. Then, support vector machine (SVM), back propagation neural network, extreme learning machine and learning vector quantization algorithms were employed to establish the discriminant diagnostic models. The accuracy of spectral fusion of the best analytical model PCA-SVM, single Raman spectral accuracy and single infrared spectral accuracy is 83.48%, 78.26% and 80%, respectively. The accuracy of spectral fusion is higher than the accuracy of single spectrum in five classifiers. And the diagnostic accuracy of spectral fusion in the range of 2000 to 2500cm(-1) is 81.74%, which greatly improves the sample measure speed and data analysis speed than analysis of full spectra. The results from our study demonstrate that the serum spectral fusion technique combined with multivariate statistical methods have great potential for the screening of thyroid dysfunction.","PCA,serum,spectral fusion,SVM,thyroid dysfunction",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Biochemistry & Molecular Biology,Biophysics,Optics",,3.403,RAMAN-SPECTROSCOPY,JOURNAL OF BIOPHOTONICS,,
36,Virtual Materials Intelligence for Design and Discovery of Advanced Electrocatalysts,20,22,2946-2955,"Malek Ali,Eslamibidgoli Mohammad Javad,Mokhtari Mehrdad,Wang Qianpu,Eikerling Michael H.,Malek Kourosh","Malek A,Eslamibidgoli MJ,Mokhtari M,Wang QP,Eikerling MH,Malek K",Malek K,10.1002/cphc.201900570,National Research Council Canada,"Similar to advancements gained from big data in genomics, security, internet of things, and e-commerce, the materials workflow could be made more efficient and prolific through advances in streamlining data sources, autonomous materials synthesis, rapid characterization, big data analytics, and self-learning algorithms. In electrochemical materials science, data sets are large, unstructured/heterogeneous, and difficult to process and analyze from a single data channel or platform. Computer-aided materials design together with advances in data mining, machine learning, and predictive analytics are expected to provide inexpensive and accelerated pathways towards tailor-made functionally optimized energy materials. Fundamental research in the field of electrochemical energy materials focuses primarily on complex interfacial phenomena and kinetic electrocatalytic processes. This perspective article critically assesses AI-driven modeling and computational approaches that are currently applied to those objects. An application-driven materials intelligence platform is introduced, and its functionalities are scrutinized considering the development of electrocatalyst materials for CO2 conversion as a use case.","AI-driven,electrocatalyst,internet of things,machine learning",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Physics",,3.151,"OXYGEN,REDUCTION,CHARGE,ESTIMATION,MATERIALS,SCIENCE,RENEWABLE,ENERGY,STATE,SIMULATION,CHALLENGES,BATTERIES,STORAGE,CO2",CHEMPHYSCHEM,,
37,A Machine Learning Tool for Materials Informatics,3,1,,"Wang Zhi-Lei,Ogawa Toshio,Adachi Yoshitaka","Wang ZL,Ogawa T,Adachi Y",Adachi Y,10.1002/adts.201900177,Nagoya University,"In response to the increasing demand for the highly efficient design of materials, materials informatics has been proposed for using data and computational sciences to extract data features that provide insight into how properties track with microstructure variables. However, the general metrics of microstructural features often ignore the complexities of the microstructure geometry for many properties of interest. An independently developed machine learning tool called shiny materials genome integration system for phase and property analysis (ShinyMIPHA), which is designed with either standalone software or cloud system based on an R programing package of ""Shiny"", is introduced. ShinyMIPHA provides topological microstructure analysis methods based on image processing technology by employing a two-point correlation function, persistent homology, and mean (H)-Gauss (K) curvature approaches, as well as sparse study and regression analysis methods that enable a data-driven properties-to-microstructure-to-processing inverse materials-design approach. The demo version is available at https://adachi- lab.shinyapps.io/demo/.","image analysis,inverse analysis,machine learning,materials informatics,topological microstructures",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Science & Technology - Other Topics,,4.004,"DATA,SCIENCE",ADVANCED THEORY AND SIMULATIONS,,
38,Machine Learning Stability and Bandgaps of Lead-Free Perovskites for Photovoltaics,3,1,,"Stanley Jared C.,Mayr Felix,Gagliardi Alessio","Stanley JC,Mayr F,Gagliardi A",Gagliardi A,10.1002/adts.201900178,Technical University of Munich,"Compositional engineering of perovskites has enabled the precise control of material properties required for their envisioned applications in photovoltaics. However, challenges remain to address efficiency, stability, and toxicity simultaneously. Mixed lead-free and inorganic perovskites have recently demonstrated potential for resolving such issues but their composition space is gigantic, making it difficult to discover promising candidates even using high-throughput methods. A machine learning approach employing a generalized element-agnostic fingerprint is shown to rapidly and accurately predict key properties using a new database of 344 perovskites generated with density functional theory. Bandgap, formation energy, and convex hull distance are predicted using validation subsets to within 146 meV, 15 meV per atom, and 11 meV per atom, respectively. The resulting model is used to predict trends in entirely different chemical spaces, and perform rapid composition and configuration space sampling without the need for expensive ab initio simulations.","density functional theory,feature engineering,lead-free perovskites,machine learning,materials prediction",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Science & Technology - Other Topics,,4.004,"SOLAR-CELLS,COMPOSITIONAL,SPACE,EFFICIENCY,PREDICTIONS,CATIONS,TIN",ADVANCED THEORY AND SIMULATIONS,https://mediatum.ub.tum.de/doc/1554660/document.pdf,
39,Machine Learning Coupled Multi-Scale Modeling for Redox Flow Batteries,3,2,,"Bao Jie,Murugesan Vijayakumar,Kamp Carl Justin,Shao Yuyan,Yan Litao,Wang Wei","Bao J,Murugesan V,Kamp CJ,Shao YY,Yan LT,Wang W",Bao J; Wang W,10.1002/adts.201900167,United States Department of Energy (DOE),"The framework of a multi-scale model that couples a deep neural network, a widely used machine learning approach, with a partial differential equation solver and provides understanding of the relationship between the pore-scale electrode structure reaction and device-scale electrochemical reaction uniformity within a redox flow battery is introduced. A deep neural network is trained and validated using 128 pore-scale simulations that provide a quantitative relationship between battery operating conditions and uniformity of the surface reaction for the pore-scale sample. Using the framework, information about surface reaction uniformity at the pore level to combined uniformity at the device level is upscaled. The information obtained using the framework and deep neural network against the experimental measurements is also validated. Based on the multi-scale model results, a time-varying optimization of electrolyte inlet velocity is established, which leads to a significant reduction in pump power consumption for targeted surface reaction uniformity but little reduction in electric power output for discharging. The multi-scale model coupled with the deep neural network approach establishes the critical link between the micro-structure of a flow-battery component and its performance at the device scale, thereby providing rationale for further operational or material optimization.","flow batteries,machine learning,multi-scale modeling",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Science & Technology - Other Topics,,4.004,"LATTICE,BOLTZMANN-EQUATION,LI-O-2,BATTERIES,PERFORMANCE,ELECTROLYTES,ELECTRODES,DENSITY,DESIGN",ADVANCED THEORY AND SIMULATIONS,https://www.osti.gov/biblio/1603653,
40,Use of artificial intelligence to assess mineral substance criticality in the French market: the example of cobalt,34,1,19-37,"Andriamasinoro Fenintsoa,Danino-Perraud Raphael","Andriamasinoro F,Danino-Perraud R",Andriamasinoro F,10.1007/s13563-019-00206-2,Bureau de Recherches Geologiques et Minieres (BRGM),"The French public and commercial stakeholders need prospective tools to follow how mineral substances criticality change in the French market. After arguing that such tools should necessarily tackle criticality at a complex level, in particular on multiple scales (e.g., France and the EU), we present the first thematic and methodological discussions of our results from the ongoing design of a methodologically based simulation model on two subfields of artificial intelligence: agent-based computational economics (ACE) and machine learning (ML). In applying this to cobalt, our model aims to assess a supply shortage in France for prospective purposes. More precisely, we model a first individual agent (which is already complex by itself) acting at a country level: France. This model is not yet an ACE model per se since only one agent is designed. Nonetheless, we include ACE in the discussions since the work is a premise of such an end. The discussions also include how well the field accepts the methodology. At a thematic level, our preliminary prospective conclusion is a French cobalt supply shortage, should the case arise, would not be due to the variation of price from the UK, the transit leader of cobalt export to France. At a methodological level, we think the idea of methodologically coupling ML and ACE is necessary. ML is well-known in this field, but mainly for the study of mineral prospectivity in mining. Conversely, ACE covers the value chain but is not yet well known in the field and as such is still not trusted.","Cobalt,Machine learning,Agent-based computational economics",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Business & Economics,,,"ELEMENTS,METHODOLOGY,CONSUMPTION,TRACKING,SUPPORT,METALS,COPPER,FLOWS,MODEL,CYCLE",MINERAL ECONOMICS,,
41,Machine learning driven non-invasive approach of water content estimation in living plant leaves using terahertz waves,15,1,,"Zahid Adnan,Abbas Hasan T.,Ren Aifeng,Zoha Ahmed,Heidari Hadi,Shah Syed A.,Imran Muhammad A.,Alomainy Akram,Abbasi Qammer H.","Zahid A,Abbas HT,Ren A,Zoha A,Heidari H,Shah SA,Imran MA,Alomainy A,Abbasi QH",Abbasi QH,10.1186/s13007-019-0522-9,University of Glasgow,"Background: The demand for effective use of water resources has increased because of ongoing global climate transformations in the agriculture science sector. Cost-effective and timely distributions of the appropriate amount of water are vital not only to maintain a healthy status of plants leaves but to drive the productivity of the crops and achieve economic benefits. In this regard, employing a terahertz (THz) technology can be more reliable and progressive technique due to its distinctive features. This paper presents a novel, and non-invasive machine learning (ML) driven approach using terahertz waves with a swissto12 material characterization kit (MCK) in the frequency range of 0.75 to 1.1 THz in real-life digital agriculture interventions, aiming to develop a feasible and viable technique for the precise estimation of water content (WC) in plants leaves for 4 days. For this purpose, using measurements observations data, multi-domain features are extracted from frequency, time, time-frequency domains to incorporate three different machine learning algorithms such as support vector machine (SVM), K-nearest neighbour (KNN) and decision-tree (D-Tree).
Results: The results demonstrated SVM outperformed other classifiers using tenfold and leave-one-observations-out cross-validation for different days classification with an overall accuracy of 98.8%, 97.15%, and 96.82% for Coffee, pea shoot, and baby spinach leaves respectively. In addition, using SFS technique, coffee leaf showed a significant improvement of 15%, 11.9%, 6.5% in computational time for SVM, KNN and D-tree. For pea-shoot, 21.28%, 10.01%, and 8.53% of improvement was noticed in operating time for SVM, KNN and D-Tree classifiers, respectively. Lastly, baby spinach leaf exhibited a further improvement of 21.28% in SVM, 10.01% in KNN, and 8.53% in D-tree in overall operating time for classifiers. These improvements in classifiers produced significant advancements in classification accuracy, indicating a more precise quantification of WC in leaves.
Conclusion: Thus, the proposed method incorporating ML using terahertz waves can be beneficial for precise estimation of WC in leaves and can provide prolific recommendations and insights for growers to take proactive actions in relations to plants health monitoring.","Water content,Plant leaves,Terahertz (THz),Sensing,Agriculture,Classification,Machine learning",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Plant Sciences",,5.312,"CLASSIFICATION,TECHNOLOGY,SELECTION,SECURITY",PLANT METHODS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6859614,
42,Functional form of the superconducting critical temperature from machine learning,100,17,,"Xie S. R.,Stewart G. R.,Hamlin J. J.,Hirschfeld P. J.,Hennig R. G.","Xie SR,Stewart GR,Hamlin JJ,Hirschfeld PJ,Hennig RG",Hennig RG,10.1103/PhysRevB.100.174513,State University System of Florida,"Predicting the critical temperature T-c of new superconductors is a notoriously difficult task, even for electron-phonon paired superconductors, for which the theory is relatively well understood. Early attempts to obtain a simple T-c formula consistent with strong-coupling theory, by McMillan and by Allen and Dynes, led to closed-form approximate relations between T-c and various measures of the phonon spectrum and the electron-phonon interaction appearing in Eliashberg theory. Here we propose that these approaches can be improved with the use of machine-learning algorithms. As an initial test, we train a model for identifying low-dimensional descriptors using the T-c < 10 K dataset by Allen and Dynes, and show that a simple analytical expression thus obtained improves upon the Allen-Dynes fit. Furthermore, the prediction for the recently discovered high-T-c material H3S at high pressure is quite reasonable. Interestingly, T-c's for more recently discovered superconducting systems with a more two-dimensional electron-phonon coupling, which do not follow Allen and Dynes's expression, also do not follow our analytic expression. Thus, this machine-learning approach appears to be a powerful method for highlighting the need for a new descriptor beyond those used by Allen and Dynes to describe their set of isotropic electron-phonon coupled superconductors. We argue that this machine-learning method, and its implied need for a descriptor characterizing Fermi-surface properties, represents a promising approach to superconductor materials discovery which may eventually replace the serendipitous discovery paradigm begun by Kamerlingh Onnes.","ELECTRON-TUNNELING SPECTROSCOPY,TRANSITION-TEMPERATURE,A15,TC,ALPHA-2F(OMEGA),LANTHANUM,HYDRIDE",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,"ELECTRON-TUNNELING,SPECTROSCOPY,TRANSITION-TEMPERATURE,A15,TC,ALPHA-2F%28OMEGA%29,LANTHANUM,HYDRIDE",PHYSICAL REVIEW B,https://www.osti.gov/biblio/1800630,
43,"Fast, accurate, and transferable many-body interatomic potentials by symbolic regression",5,,,"Hernandez Alberto,Balasubramanian Adarsh,Yuan Fenglin,Mason Simon A. M.,Mueller Tim","Hernandez A,Balasubramanian A,Yuan FL,Mason SAM,Mueller T",Mueller T,10.1038/s41524-019-0249-1,Johns Hopkins University,"The length and time scales of atomistic simulations are limited by the computational cost of the methods used to predict material properties. In recent years there has been great progress in the use of machine-learning algorithms to develop fast and accurate interatomic potential models, but it remains a challenge to develop models that generalize well and are fast enough to be used at extreme time and length scales. To address this challenge, we have developed a machine-learning algorithm based on symbolic regression in the form of genetic programming that is capable of discovering accurate, computationally efficient many-body potential models. The key to our approach is to explore a hypothesis space of models based on fundamental physical principles and select models within this hypothesis space based on their accuracy, speed, and simplicity. The focus on simplicity reduces the risk of overfitting the training data and increases the chances of discovering a model that generalizes well. Our algorithm was validated by rediscovering an exact Lennard-Jones potential and a Sutton-Chen embedded-atom method potential from training data generated using these models. By using training data generated from density functional theory calculations, we found potential models for elemental copper that are simple, as fast as embedded-atom models, and capable of accurately predicting properties outside of their training set. Our approach requires relatively small sets of training data, making it possible to generate training data using highly accurate methods at a reasonable computational cost. We present our approach, the forms of the discovered models, and assessments of their transferability, accuracy and speed.","EMBEDDED-ATOM-METHOD,FORCE-FIELD,ENERGY SURFACES,MOLECULAR-DYNAMICS,PARAMETERS,MODEL,SIMULATION,CHEMISTRY",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Chemistry,Materials Science",,13.993,"EMBEDDED-ATOM-METHOD,FORCE-FIELD,ENERGY,SURFACES,MOLECULAR-DYNAMICS,PARAMETERS,MODEL,SIMULATION,CHEMISTRY",NPJ COMPUTATIONAL MATERIALS,http://arxiv.org/pdf/1904.01095,
44,Crowd-sourcing materials-science challenges with the NOMAD 2018 Kaggle competition,5,,,"Sutton Christopher,Ghiringhelli Luca M.,Yamamoto Takenori,Lysogorskiy Yury,Blumenthal Lars,Hammerschmidt Thomas,Golebiowski Jacek R.,Liu Xiangyue,Ziletti Angelo,Scheffler Matthias","Sutton C,Ghiringhelli LM,Yamamoto T,Lysogorskiy Y,Blumenthal L,Hammerschmidt T,Golebiowski JR,Liu XY,Ziletti A,Scheffler M",Sutton C; Ghiringhelli LM,10.1038/s41524-019-0239-3,Max Planck Society,"A public data-analytics competition was organized by the Novel Materials Discovery (NOMAD) Centre of Excellence and hosted by the online platform Kaggle by using a dataset of 3,000 (AlxGayIn1-x-y)(2)O-3 compounds. Its aim was to identify the best machine-learning (ML) model for the prediction of two key physical properties that are relevant for optoelectronic applications: the electronic bandgap energy and the crystalline formation energy. Here, we present a summary of the top-three ranked ML approaches. The first-place solution was based on a crystal-graph representation that is novel for the ML of properties of materials. The second-place model combined many candidate descriptors from a set of compositional, atomic-environment-based, and average structural properties with the light gradient-boosting machine regression model. The third-place model employed the smooth overlap of atomic position representation with a neural network. The Pearson correlation among the prediction errors of nine ML models (obtained by combining the top-three ranked representations with all three employed regression models) was examined by using the Pearson correlation to gain insight into whether the representation or the regression model determines the overall model performance. Ensembling relatively decorrelated models (based on the Pearson correlation) leads to an even higher prediction accuracy.","THIN-FILM TRANSISTORS,ELECTRONIC-STRUCTURE,HIGH-MOBILITY,TRANSPARENT,OXIDE,PREDICTIONS,EXPANSION,CORUNDUM,PHASES",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Chemistry,Materials Science",,13.993,"THIN-FILM,TRANSISTORS,MACHINE,LEARNING-MODELS,ELECTRONIC-STRUCTURE,HIGH-MOBILITY,TRANSPARENT,OXIDE,PREDICTIONS,EXPANSION,CORUNDUM,PHASES",NPJ COMPUTATIONAL MATERIALS,https://pure.mpg.de/pubman/item/item_3027538_5/component/file_3027539/arXiv%3A1812.00085.pdf,
45,Human-machine partnership with artificial intelligence for chest radiograph diagnosis,2,,,"Patel Bhavik N.,Rosenberg Louis,Willcox Gregg,Baltaxe David,Lyons Mimi,Irvin Jeremy,Rajpurkar Pranav,Amrhein Timothy,Gupta Rajan,Halabi Safwan","Patel BN,Rosenberg L,Willcox G,Baltaxe D,Lyons M,Irvin J,Rajpurkar P,Amrhein T,Gupta R,Halabi S",Patel BN,10.1038/s41746-019-0189-7,Stanford University,"Human-in-the-loop (HITL) Al may enable an ideal symbiosis of human experts and Al models, harnessing the advantages of both while at the same time overcoming their respective limitations. The purpose of this study was to investigate a novel collective intelligence technology designed to amplify the diagnostic accuracy of networked human groups by forming real-time systems modeled on biological swarms. Using small groups of radiologists, the swarm-based technology was applied to the diagnosis of pneumonia on chest radiographs and compared against human experts alone, as well as two state-of-the-art deep learning Al models. Our work demonstrates that both the swarm-based technology and deep-learning technology achieved superior diagnostic accuracy than the human experts alone. Our work further demonstrates that when used in combination, the swarm-based technology and deep-learning technology outperformed either method alone. The superior diagnostic accuracy of the combined HITL Al solution compared to radiologists and Al alone has broad implications for the surging clinical Al deployment and implementation strategies in future practice.","DECISION-MAKING,SOCIAL-INFLUENCE,CLASSIFICATION,FUTURE,WISDOM,CANCER,CROWD",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Health Care Sciences & Services,Medical Informatics",,11.665,"DECISION-MAKING,SOCIAL-INFLUENCE,CLASSIFICATION,FUTURE,WISDOM,CANCER,CROWD",NPJ DIGITAL MEDICINE,https://europepmc.org/articles/pmc6861262?pdf=render,
46,Machine learning techniques for estimation of Los Angeles abrasion value of rock aggregates,,,,"Asadi Mojtaba,TaghaviGhalesari Abbasali,Kumar Saurav","Asadi M,TaghaviGhalesari A,Kumar S",TaghaviGhalesari A,10.1080/19648189.2019.1690585,University of Texas System,Rock aggregates are extensively used in the production of materials such as asphalt concrete and Portland cement concrete. Los Angeles Abrasion (LAA) value is one the basic characteristics of crushed aggregates that reflects their resistance against mechanical abrasive factors such as repeated impact loading. There have been several efforts to estimate the LAA value from surrogate physical and/or mechanical properties of the material. Previous works have mainly focussed on a limited number of data samples and thus may not be generalised to make predictions for different lithologies. Another drawback of the current approaches is that they are often in the form of one-to-one correlations between the LAA and a measure of mechanical behaviour such as the uniaxial strength. This paper investigates the capability of Machine Learning (ML) models for prediction of LAA value. Different material properties have been tested as the input parameters to achieve the best prediction results. It was observed that the ML models perform considerably better for predicting LAA compared to the existing correlations reported in the literature.,"Los Angeles abrasion,crushed aggregates,machine learning,data analytics",Article; Early Access,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,2.657,"ARTIFICIAL,NEURAL-NETWORKS,COMPRESSIVE,STRENGTH,FUZZY,INFERENCE,INDEX,TESTS,REGRESSION,PARAMETERS",EUROPEAN JOURNAL OF ENVIRONMENTAL AND CIVIL ENGINEERING,,
47,,,,,,,,,,,,,,,,,,,,
48,,,,,,,,,,,,,,,,,,,,
49,Detecting liver fibrosis using a machine learning-based approach to the quantification of the heart-induced deformation in tagged MR images,33,1,,"Ahmed Yasmine,Hussein Rasha S.,Basha Tamer A.,Khalifa Ayman M.,Ibrahim Ahmed S.,Abdelmoaty Ahmed S.,Abdella Heba M.,Fahmy Ahmed S.","Ahmed Y,Hussein RS,Basha TA,Khalifa AM,Ibrahim AS,Abdelmoaty AS,Abdella HM,Fahmy AS",Basha TA,10.1002/nbm.4215,Egyptian Knowledge Bank (EKB),"Liver disease causes millions of deaths per year worldwide, and approximately half of these cases are due to cirrhosis, which is an advanced stage of liver fibrosis that can be accompanied by liver failure and portal hypertension. Early detection of liver fibrosis helps in improving its treatment and prevents its progression to cirrhosis. In this work, we present a novel noninvasive method to detect liver fibrosis from tagged MRI images using a machine learning-based approach. Specifically, coronal and sagittal tagged MRI imaging are analyzed separately to capture cardiac-induced deformation of the liver. The liver is manually delineated and a novel image feature, namely, the histogram of the peak strain (HPS) value, is computed from the segmented liver region and is used to classify the liver as being either normal or fibrotic. Classification is achieved using a support vector machine algorithm. The in vivo study included 15 healthy volunteers (10 males; age range 30-45 years) and 22 patients (15 males; age range 25-50 years) with liver fibrosis verified and graded by transient elastography, and 10 patients only had a liver biopsy and were diagnosed with a score of F3-F4. The proposed method demonstrates the usefulness and efficiency of extracting the HPS features from the sagittal slices for patients with moderate fibrosis. Cross-validation of the method showed an accuracy of 83.7% (specificity = 86.6%, sensitivity = 81.8%).","diagnosis and grading,liver fibrosis,support vector machine,tagged MRI",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Biophysics,Radiology, Nuclear Medicine & Medical Imaging,Spectroscopy",,3.988,"HEPATITIS-C,TRANSIENT,ELASTOGRAPHY,NONINVASIVE,ASSESSMENT,BIOCHEMICAL,MARKERS,VIRAL-HEPATITIS,SERUM,MARKERS,BIOPSY,DIAGNOSIS,CIRRHOSIS,PREDICT",NMR IN BIOMEDICINE,,
50,Functionally Graded Materials through robotics-inspired path planning,182,,,"Eliseeva O. V.,Kirk T.,Samimi P.,Malak R.,Arroyave R.,Elwany A.,Karaman I.","Eliseeva OV,Kirk T,Samimi P,Malak R,Arroyave R,Elwany A,Karaman I",Karaman I,10.1016/j.matdes.2019.107975,Texas A&M University System,"Functional grading has recently seen renewed interest with the advancement of additive manufacturing. Unfortunately, the integrity of functional gradients in alloys tends to be compromised by the presence of brittle phases. Recently, CALPHAD-based tools have been used to generate isothermal phase diagrams that are in turn utilized to plan gradient paths that avoid these phases. However, existing frameworks rely extensively on the (limited) ability of humans to visualize and navigate high-dimensional spars. To tackle this challenge, a Machine Learning approach was used here to map out undesirable regions as 'obstacles', while a path-planning algorithm, commonly used in robotics community, was utilized to identify a path in a composition space that would avoid the obstacles, while simultaneously minimizing a cost function. This framework was validated by designing and 3-D printing a functional gradient in bulk samples from 316L stainless steel to pure chromium with a multi-material direct laser deposition system. Both the planned gradient and simple linear gradient samples were fabricated and characterized in as-deposited and heat-treated states to determine local compositions, microstructure and phase constituents. The planned gradient resulted in complete elimination of the detrimental sigma phase after heat treatment, demonstrating the success of the methodology. (C) 2019 The Authors. Published by Elsevier Ltd.","Phase diagram,Path planning,Additive manufacturing,Functionally graded alloys,3-D printing",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Materials Science,,7.097,"304L,STAINLESS-STEEL,TITANIUM-VANADIUM,LASER,DEPOSITION,FABRICATION,TI-6AL-4V",MATERIALS & DESIGN,https://doi.org/10.1016/j.matdes.2019.107975,
51,Performance based thermal comfort control (PTCC) using deep reinforcement learning for space cooling,203,,,"Yoon Young Ran,Moon Hyeun Jun","Yoon YR,Moon HJ",Yoon YR,10.1016/j.enbuild.2019.109420,Dankook University,"With the recent increase in energy consumption in buildings, energy-saving strategies in buildings have become a priority in the energy policies of many countries. Therefore, many recent research studies have emphasized the advanced control methods to attain comfortable thermal conditions while minimizing the energy consumption in buildings. A new approach of thermal comfort control for space cooling/heating system is needed to reflect the changing indoor environment information in real time, and to control various factors (e.g., humidity, air velocity, etc.) that affect not only the temperature but also the thermal comfort.
In this study, we propose the Gaussian process regression (GPR) for real-time thermal comfort prediction, a data-driven approach. These data-driven approaches will enable the monitoring of occupants and thermal comfort conditions based on real-time data and situational awareness. Then, based on the thermal comfort performance (PMV) prediction results obtained using the GPR, we investigated control methods involving the integration of systems, i.e., a variable refrigerant flow (VRF) system and a humidifier, instead of using simple set-temperature control for space cooling. For this purpose, deep Q-learning, which is an reinforcement learning method, was employed to derive the VRF and humidification integrated control methods. During zone operation, this algorithm learned an effective control policy based on rewards (thermal comfort and energy consumption) without relying on a thermal dynamics model. Moreover, by comparing the thermal comfort and energy consumption results with those obtained using fixed set-point (rule-based) control and performance-based comfort control for cooling, the efficiency of the proposed performance-based thermal comfort control (PTCC) was evaluated.
As a results, it was found that PTCC yielded the optimal control action value that minimized the energy consumption while satisfying the thermal comfort conditions. In addition, applying the proposed PTCC strategy to cooling control could maintain the required performance level of thermal comfort by reflecting changing environmental conditions in real time, unlike the fixed set-point control. (C) 2019 Elsevier B.V. All rights reserved.","Reinforcement learning,Q-learning,Gaussian process,Thermal comfort,Space cooling,System integrated control,Building energy",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Construction & Building Technology,Energy & Fuels,Engineering",,6.175,"MODEL-PREDICTIVE,CONTROL,HOME,ENERGY,MANAGEMENT,MEAN,VOTE,OPTIMIZATION",ENERGY AND BUILDINGS,,
52,An efficient artificial neural network for damage detection in bridges and beam-like structures by improving training parameters using cuckoo search algorithm,199,,,"Tran-Ngoc H.,Khatir S.,De Roeck G.,Bui-Tien T.,Wahab M. Abdel","Tran-Ngoc H,Khatir S,De Roeck G,Bui-Tien T,Wahab MA",Wahab MA,10.1016/j.engstruct.2019.109637,Ton Duc Thang University,"This paper presents a new approach for damage detection in structures by applying a flexible combination based on an artificial neural network (ANN) and cuckoo search (CS) algorithm. ANN has become one of the most powerful tools employing computational intelligence techniques to tackle complex problems in numerous fields. However, due to the application of backpropagation algorithms based on gradient descent, a major drawback of ANN is the common problem of local minima that acts as a great hindrance to the search for the best solution. To overcome this disadvantage, we propose to combine ANN with evolutionary algorithms based on global search techniques. This paper employs CS to improve ANN training parameters (weight and bias) by minimizing the difference between real and desired outputs and then using these parameters to generate the network. Two numerical models, comprising a steel beam calibrated using experimental measurements and a large-scale truss bridge, are used to assess the robustness of the proposed approach. The results demonstrate that ANN combined with CS (ANN-CS) is accurate and requires a lower computational time than ANN, and evolutionary algorithm (EA) alone in terms of structural damage localization and quantification.","Artificial neural network (ANN),Local minima,Evolutionary algorithm (EA),Cuckoo search (CS),Particle swarm optimization (PSO),Genetic algorithm (GA),Training parameters,Damage detection,Model updating",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,4.795,"GENETIC,ALGORITHM,OPTIMIZATION,IDENTIFICATION,LOCALIZATION,PSO",ENGINEERING STRUCTURES,,
53,Modeling and optimization of African pear seed oil esterification and transesterification using artificial neural network and response surface methodology comparative analysis,140,,,"Ofoefule Akuzuo Uwaoma,Esonye Chizoo,Onukwuli Okechukwu Dominic,Nwaeze Emmanuel,Ume Cyril Sunday","Ofoefule AU,Esonye C,Onukwuli OD,Nwaeze E,Ume CS",Esonye C,10.1016/j.indcrop.2019.111707,"Fed Univ, Dept Chem Petr Engn, Ndufu Alike Ikwo, Abakaliki, Nigeria.","This study aimed at modeling and optimum conditions evaluation of the production of fatty acid methyl esters from high free fatty acid (FFA) and oil content African pear seed. The central composite design of response surface methodology (RSM) was employed for investigating the individual and interactive effect of the process variables (methanol/oil molar ratio, catalyst concentration, temperature and reaction time) on the FFA reduction and African pear seed oil methyl esters (APSOME) yield. A feed-forward neural network model with Levenberg-Marquardt backward propagation training algorithm was also employed to predict the responses. Temperature was found to be the most significant parameter with high F-values of 7.1 and 14.15 and low P-values of 0.0177 and 0.0019 for esterification and transesterification processes respectively. The observed optimum FFA reduction and biodiesel yield were 0.29 wt% and 94.55 wt% respectively, under the optimal conditions of 50 and 63.92 degrees C, 5.0 and 1.88 wt% catalyst concentration, 60 and 58 min reaction time and 13:1 and 6.86:1 methanol to oil molar ratios for esterification and transesterification processes respectively. At these optimal conditions, the validated experimental responses were 0.26 wt% and 95.027 wt% respectively. The performances of both ANN and RSM models showed adequate prediction of the response, with high coefficient of determination (R-2) of 0.899 and 0.909 for esterification and 0.9195 and 0.944 for transesterification processes respectively. The fuel properties of the biodiesel produced at the optimum conditions were found to compare with ASTM D6751 and EN 14214 standard) while the GC-MS characterization showed that the biodiesel has high unsaturation. The overall results confirmed that the biodiesel production using African pear seed oil is viable","African pear,Esterification,Modeling,Optimization,RSM,ANN",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Agriculture,,5.749,"METHYL-ESTER,PRODUCTION,BIODIESEL,PRODUCTION,PRUNUS-AMYGDALUS,DYACRODES,EDULIS,KINETICS",INDUSTRIAL CROPS AND PRODUCTS,,
54,Integration of machine learning approaches for accelerated discovery of transition-metal dichalcogenides as Hg-0 sensing materials,254,,,"Zhao Haitao,Ezeh Collins I,Ren Weijia,Li Wentao,Pang Cheng Heng,Zheng Chenghang,Gao Xiang,Wu Tao","Zhao HT,Ezeh CI,Ren WJ,Li WT,Pang CH,Zheng CH,Gao X,Wu T",Gao X,10.1016/j.apenergy.2019.113651,Zhejiang University,"The detrimental impact of urban airborne Hg-0 from fossil fuel utilization has necessitated the discovery and development of Hg-0 sensing materials for effective Hg-0 detection and mitigation of the pollutant. Earlier studies have hypothetically and experimentally supported 2-dimensional transition-metal dichalcogenides (2D TMDCs), particularly MoS2 to have excellent performance for Hg-0 removal. However, the potential of other TMDCs is yet to be investigated for Hg-0 sensor application. In this study, a total of 28 transition metals within periods 4-6 of the periodic table, excluding the lanthanides series, were examined. To ensure proper data management flow, a high-throughput data mining approach with integrated machine learning and cheminformatics simulation approaches is developed. The systemic approach integrates the Pymatgen, Factsage, Aflow and density functional theory simulation tools for accelerated discovery of suitable TMDCs from raw data via the chemical vapour reaction route. Predicted results showed that TiS2, NiS2, ZrS2, MoS2, PdS2 and WS2 exhibited TMDCs characteristics. Furthermore, first-principles calculation shows Hg-uptake capacity is in the order NiS2 > PdS2 > TiS2 > ZrS2 > WS2 > MoS2, while Hg sensing response is in the order PdS2 > MoS2 > WS2 > ZrS2 > NiS2 > TiS2. Accordingly, PdS2 depicted to be the most suitable TMDCs for airborne Hg-0 sensor application. The proposed systemic approach is an initial platform for materials discovery using integrated machine learning approaches and is well-suited for the screening and the discovery of new materials based on component-oriented structures.","Atmospheric Hg-0 sensor,Data mining,2D TMDCs,Machine learning,DFT",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Energy & Fuels,Engineering",,9.953,"CHEMICAL-VAPOR-DEPOSITION,MOS2,NANOSHEETS,BIG,DATA,PREDICTION,ENERGY,PERFORMANCE,GRAPHENE,CAPTURE,MODELS,WIND",APPLIED ENERGY,,
55,Parent material distribution mapping from tropical soils data via machine learning and portable X-ray fluorescence (pXRF) spectrometry in Brazil,354,,,"Mancini Marcelo,Weindorf David C.,Godinho Silva Sergio Henrique,Chakraborty Somsubhra,dos Santos Teixeira Anita Fernanda,Guimaraes Guilherme Luiz Roberto,Curi Nilton","Mancini M,Weindorf DC,Silva SHG,Chakraborty S,Teixeira AFD,Guilherme LRG,Curi N",Weindorf DC,10.1016/j.geoderma.2019.113885,Texas Tech University System,"Knowledge about parent material (PM) is crucial to understand the properties of overlying soils. Assessing PM of very deep soils, however, is not easy. Previous studies have predicted PM via proximal sensors and machine learning algorithms, but within small areas and with low soil variety. This study evaluates the efficiency of using portable X-ray fluorescence (pXRF) spectrometry together with machine learning algorithms in a large area populated with a wide variety of soil classes and land uses to build accurate PM distribution maps from soil data. Samples from A and B horizons were collected from 117 sites, totaling 234 samples, along with representative PM samples of the predominant PMs in the region. Elemental contents of PM and soil samples were obtained using pXRF. Random Forest (RF), Support Vector Machine (SVM) and Linear Discriminant Analysis (LDA) models built with and without Principal Component Analysis (PCA) were used to predict PMs from A and B horizon samples separately. For validation, PM was identified in 23 different spots and compared with the predicted PM via overall accuracy and Kappa coefficient. Maps built with models excluding PCA had an overall accuracy ranging from 0.87 to 0.96 and kappa coefficient ranging from 0.74 to 0.91. Maps generated with PCA based models reached 100% overall accuracy. Prediction of PM using pXRF with samples from either A or B horizon and machine learning algorithms offers solid results even when applied in large areas with high land use and soil class variability.","Pedology,Machine learning,Digital soil mapping,Prediction models,Tropical soils",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Agriculture,,6.183,"PREDICTION,CLASSIFICATION,LITHOLOGY,REGION,ROCKS",GEODERMA,,
56,Unifying machine learning and quantum chemistry with a deep neural network for molecular wavefunctions,10,,,"Schuett K. T.,Gastegger M.,Tkatchenko A.,Mueller K-R.,Maurer R. J.","Schutt KT,Gastegger M,Tkatchenko A,Muller KR,Maurer RJ",Muller KR,10.1038/s41467-019-12875-2,Technical University of Berlin,"Machine learning advances chemistry and materials science by enabling large-scale exploration of chemical space based on quantum chemical calculations. While these models supply fast and accurate predictions of atomistic chemical properties, they do not explicitly capture the electronic degrees of freedom of a molecule, which limits their applicability for reactive chemistry and chemical analysis. Here we present a deep learning framework for the prediction of the quantum mechanical wavefunction in a local basis of atomic orbitals from which all other ground-state properties can be derived. This approach retains full access to the electronic structure via the wavefunction at force-field-like efficiency and captures quantum mechanics in an analytically differentiable representation. On several examples, we demonstrate that this opens promising avenues to perform inverse design of molecular structures for targeting electronic property optimisation and a clear path towards increased synergy of machine learning and quantum chemistry.",BASIS-SETS,Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,15.805,BASIS-SETS,NATURE COMMUNICATIONS,http://wrap.warwick.ac.uk/128869/7/WRAP-unifying-machine-learning-quantum-chemistry-deep-neural-network-molecular-wavefunctions-Maurer-2019.pdf,
57,Radiomics Analysis for Glioma Malignancy Evaluation Using Diffusion Kurtosis and Tensor Imaging,105,4,784-791,"Takahashi Satoshi,Takahashi Wataru,Tanaka Shota,Haga Akihiro,Nakamoto Takahiro,Suzuki Yuichi,Mukasa Akitake,Takayanagi Shunsaku,Kitagawa Yosuke,Hana Taijun","Takahashi S,Takahashi W,Tanaka S,Haga A,Nakamoto T,Suzuki Y,Mukasa A,Takayanagi S,Kitagawa Y,Hana TJ",Tanaka S,10.1016/j.ijrobp.2019.07.011,University of Tokyo,"Purpose: A noninvasive diagnostic method to predict the degree of malignancy accurately would be of great help in glioma management. This study aimed to create a highly accurate machine learning model to perform glioma grading.
Methods and Materials: Preoperative magnetic resonance imaging acquired for cases of glioma operated on at our institution from October 2014 through January 2018 were obtained retrospectively. Six types of magnetic resonance imaging sequences (T-2-weighted image, diffusion-weighted image, apparent diffusion coefficient [ADC], fractional anisotropy, and mean kurtosis [MK]) were chosen for analysis; 476 features were extracted semiautomatically for each sequence (2856 features in total). Recursive feature elimination was used to select significant features for a machine learning model that distinguishes glioblastoma from lower-grade glioma (grades 2 and 3).
Results: Fifty-five data sets from 54 cases were obtained (14 grade 2 gliomas, 12 grade 3 gliomas, and 29 glioblastomas), of which 44 and 11 data sets were used for machine learning and independent testing, respectively. We detected 504 features with significant differences (false discovery rate <0.05) between glioblastoma and lower-grade glioma. The most accurate machine learning model was created using 6 features extracted from the ADC and MK images. In the logistic regression, the area under the curve was 0.90 +/- 0.05, and the accuracy of the test data set was 0.91 (10 out of 11); using a support vector machine, they were 0.93 +/- 0.03 and 0.91 (10 out of 11), respectively (kernel, radial basis function; c = 1.0).
Conclusions: Our machine learning model accurately predicted glioma tumor grade. The ADC and MK sequences produced particularly useful features. (C) 2019 Elsevier Inc. All rights reserved.","CENTRAL-NERVOUS-SYSTEM,HISTOGRAM ANALYSIS,MR SPECTROSCOPY,GRADE,CLASSIFICATION,FEATURES,TUMORS,IMAGES,BRAIN,MAPS",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,6.884,"CENTRAL-NERVOUS-SYSTEM,HISTOGRAM,ANALYSIS,MR,SPECTROSCOPY,GRADE,CLASSIFICATION,FEATURES,TUMORS,IMAGES,BRAIN,MAPS",INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS,,
58,Machine Learning for Patient-Specific Quality Assurance of VMAT: Prediction and Classification Accuracy,105,4,893-902,"Li Jiaqi,Wang Le,Zhang Xile,Liu Lu,Li Jun,Chan Maria F.,Sui Jing,Yang Ruijie","Li JQ,Wang L,Zhang XL,Liu L,Li J,Chan MF,Sui J,Yang RJ",Yang RJ,10.1016/j.ijrobp.2019.07.049,Peking University,"Purpose: To assess the accuracy of machine learning to predict and classify quality assurance (QA) results for volumetric modulated arc therapy (VMAT) plans.
Methods and Materials: Three hundred three VMAT plans, including 176 gynecologic cancer and 127 head and neck cancer plans, were chosen in this study. Fifty-four complexity metrics were extracted from the QA plans and considered as inputs. Patient-specific QA was performed, and gamma passing rates (GPRs) were used as outputs. One Poisson lasso (PL) regression model was developed, aiming to predict individual GPR, and 1 random forest (RF) classification model was developed to classify QA results as ""pass"" or ""fail."" Both technical validation (TV) and clinical validation (CV) were used to evaluate the model reliability. GPR prediction accuracy of PL and classification performance of PL and RF were evaluated.
Results: In TV, the mean prediction error of PL was 1.81%, 2.39%, and 4.18% at 3%/3 mm, 3%/2 mm, and 2%/2 mm, respectively. No significant differences in prediction errors between TV and CV were observed. In QA results classification, PL had a higher specificity (accurately identifying plans that can pass QA), whereas RF had a higher sensitivity (accurately identifying plans that may fail QA). By using 90% as the action limit at a 3%/2 mm criterion, the specificity of PL and RF was 97.5% and 87.7% in TV and 100% and 71.4% in CV, respectively. The sensitivity of PL and RF was 31.6% and 100% in TV and 33.3% and 100% in CV, respectively. With 100% sensitivity, the QA workload of 81.2% of plans in TV and 62.5% of plans in CV could be reduced by RF.
Conclusions: The PL model could accurately predict GPR for most VMAT plans. The RF model with 100% sensitivity was preferred for QA results classification. Machine learning can be a useful tool to assist VMAT QA and reduce QA workload. (C) 2019 Elsevier Inc. All rights reserved.","PER-BEAM,IMRT,QA,MODULATION,COMPLEXITY,TOOL,VERIFICATION,RAPIDARC,ROUTINE",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,6.884,"PER-BEAM,IMRT,QA,MODULATION,COMPLEXITY,TOOL,VERIFICATION,RAPIDARC,ROUTINE",INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7512077,
59,Strided fully convolutional neural network for boosting the sensitivity of retinal blood vessels segmentation,134,,36-52,"Soomro Toufique Ahmed,Afifi Ahmed J.,Gao Junbin,Hellwich Olaf,Zheng Lihong,Paul Manoranjan","Soomro TA,Afifi AJ,Gao JB,Hellwich O,Zheng LH,Paul M",Soomro TA,10.1016/j.eswa.2019.05.029,Charles Sturt University,"In this paper, a deep convolutional neural network (CNN) is proposed for accurate segmentation of retinal blood vessels. This method plays a significant role in observing many eye diseases. A strided-CNN model is proposed for accurate segmentation of retinal vessels, especially the tiny vessels. The model is a fully convolutional model consisting of an encoder part and a decoder part where the pooling layers are replaced with strided convolutional layers. The strided convolutional layer approach was chosen over the pooling layers approach as the former can be trained. The morphological mappings along with the Principal Component Analysis (PCA)- based pre-processing steps are used to generate contrast images for training dataset. Skip connections are implemented to concatenate features from the encoder part and the decoder part to enhance the vessels segmentation especially the tiny vessels and to make the vessel's edges sharper. We used a class balancing loss function to train and optimize the proposed model to improve vessel image quality. The impact of the proposed segmentation method is evaluated on four databases namely DRIVE, STARE, CHASE-DB1 and HRF. Overall model performance, particularly with respect to tiny vessels, is primarily influenced by sensitivity and accuracy metrics. We demonstrate that our model outperforms other models with a sensitivity of 0.87, 0.808, 0.886 and 0.829 on DRIVE, STARE, CHASE_DBI and HRF respectively, along with respective accuracies of 0.956, 0.954, 0.976 and 0.962. (C) 2019 Elsevier Ltd. All rights reserved.","Retina,Retinal images,Vessels,Strided-CNN,Pool-CNN",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"IMAGE-ANALYSIS,MODEL",EXPERT SYSTEMS WITH APPLICATIONS,,
60,Distinguishing mental attention states of humans via an EEG-based passive BCI using machine learning methods,134,,153-166,"Aci Cigdem Ivan,Kaya Murat,Mishchenko Yuriy","Aci CI,Kaya M,Mishchenko Y",Aci CI,10.1016/j.eswa.2019.05.057,Mersin University,"Recent advances in technology bring about novel operating environments where the role of human participants is reduced to passive observation. While opening new frontiers in productivity and lifestyle, such environments also create hazards related to the inability of human individuals to maintain focus and concentration during passive control tasks. A passive brain-computer interface for monitoring mental attention states of human individuals (focused, unfocused, and drowsy) by using electroencephalographic (EEG) brain activity imaging and machine learning data analysis methods is developed in this work. An EEG data processing pipeline and a machine learning mental state detection algorithm using the Support Vector Machine (SVM) method were designed and compared with k-Nearest Neighbor and Adaptive Neuro-Fuzzy System methods. To collect 25 h of EEG data from 5 participants, a classic EEG headset was modified. We found that the changes in EEG activity in frontal and parietal lobes occurring at 1-5 Hz and 10-15 Hz frequency bands were associated with the changes in individuals' attention state. We demonstrated the ability to use such changes to identify individuals' attention state with 96.70% (best) and 91.72% (avg.) accuracy in experimental settings using a version of continuous performance task with SVM-based mental state detector. The findings help guide the design of future systems for monitoring the state of human individuals by means of EEG brain activity data. (C) 2019 Elsevier Ltd. All rights reserved.","EEG,BCI,Mental state detection,Drowsiness detection,Support vector machine,Passive control task",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"SIGNALS,DROWSINESS,RECOGNITION,SYSTEM",EXPERT SYSTEMS WITH APPLICATIONS,,
61,Development of a hybrid scoring system for EOR screening by combining conventional screening guidelines and random forest algorithm,256,,,"Zhang Na,Wei Mingzhen,Fan Jiayi,Aldhaheri Munqith,Zhang Yandong,Bai Baojun","Zhang N,Wei MZ,Fan JY,Aldhaheri M,Zhang YD,Bai BJ",Wei MZ,10.1016/j.fuel.2019.115915,University of Missouri System,"Selecting a proper EOR method for a prospective reservoir is a key factor for successful application of EOR techniques. Reservoir engineers usually refer to screening guidelines to identify potential EOR processes for a given reservoir. However, these guidelines are characterized by poor discriminating powers. In this study, we develop a hybrid scoring system for EOR processes by combining conventional screening guidelines and the random forest algorithm. M first, the screening guidelines were established by compiling 977 EOR projects from various publications in different languages, including Oil and Gas Journal (OGJ) biannual EOR surveys, SPE publications, DOE reports, Chinese publications, etc. Boxplots were used to detect the special cases for each reservoir/fluid property and to present the graphical screening results. To avoid the experts' bias, the weighting factors for each EOR technique were determined through the application of the random forest algorithm, where the EOR types and the incremental oil recovery were utilized as objective functions. The scoring system was then established by the fuzzification of reservoir/fluid property scores and the computation of composite screening scores. A case study was used to demonstrate that with a simple input of reservoir/fluid information, the novel scoring system could effectively provide recommendations for EOR selection by ranking scores.","ENHANCED-OIL-RECOVERY,WORLDWIDE,CRITERIA",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Energy & Fuels,Engineering",,6.63,"ENHANCED-OIL-RECOVERY,WORLDWIDE,CRITERIA",FUEL,,
62,Predicting Young's modulus of oxide glasses with sparse datasets using machine learning,524,,,"Bishnoi Suresh,Singh Sourabh,Ravinder R.,Bauchy Mathieu,Gosvami Nitya Nand,Kodamana Hariprasad,Krishnan N. M. Anoop","Bishnoi S,Singh S,Ravinder R,Bauchy M,Gosvami NN,Kodamana H,Krishnan NMA",Krishnan NMA,10.1016/j.jnoncrysol.2019.119643,Indian Institute of Technology System (IIT System),"Machine learning (ML) methods are becoming popular tools for predicting and designing novel materials. In particular, neural network (NN) is a promising ML method, which can be used to identify hidden trends in the data. However, these methods rely on a large dataset and often exhibit overfitting when used with a sparse dataset. Further, assessing the uncertainty in predictions for a new dataset or an extrapolation of the present dataset is challenging. Herein, using Gaussian process regression (GPR), we predict Young's modulus for silicate glasses having a sparse dataset. We show that GPR significantly outperforms NN for the sparse dataset while ensuring no overfitting. Further, thanks to the nonparametric nature, GPR provides quantitative bounds for the reliability of predictions while extrapolating. Overall, GPR presents an advanced ML methodology for accelerating the development of novel functional materials such as glasses.","Neural network,Gaussian process regression,Silicate glasses,Young's modulus,Sparse dataset",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.208,"LOGISTIC-REGRESSION,GAUSSIAN-PROCESSES,DESIGN",JOURNAL OF NON-CRYSTALLINE SOLIDS,http://arxiv.org/pdf/1902.09776,
63,,,,,,,,,,,,,,,,,,,,
64,,,,,,,,,,,,,,,,,,,,
65,,,,,,,,,,,,,,,,,,,,
66,,,,,,,,,,,,,,,,,,,,
67,,,,,,,,,,,,,,,,,,,,
68,Machine learning in drying,38,5-6,596-609,"Martynenko Alex,Misra N. N.","Martynenko A,Misra NN",Martynenko A,10.1080/07373937.2019.1690502,Dalhousie University,"Although very important for analysis of drying processes, physics-based models are limited in terms of their prediction ability and in most cases are unsuitable for real-time process control and optimization of industrial drying. In this paper, we provide an overview of the machine learning (ML) techniques and the state-of-the-art ML applications in drying of food and biomaterials. The applications include but not limited to data-driven models, nonlinear control and multi-objective optimization. The advantages of integration of ML with machine vision for real-time observation of product quality and fine-tuning control strategies are briefly discussed. Future research should focus on the integration of ML software tools with sensors to measure process and product variables. In addition, the drying research community should contribute towards building of open-source datasets, which is extremely important to leverage the power of ML algorithms. Integration of sensors, process analysis and software engineering will enable the development of ""intelligent"" drying systems.","Intelligence,data,model,optimization,control,food quality",Article,"TAYLOR & FRANCIS INC, 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA",Engineering,,4.034,"ARTIFICIAL,NEURAL-NETWORKS,MODEL-PREDICTIVE,CONTROL,COMPUTER,VISION,SYSTEM,MULTIOBJECTIVE,OPTIMIZATION,MOISTURE-CONTENT,APPLE,SLICES,SOFT-SENSOR,GRAIN,DRYER,QUALITY,AIR",DRYING TECHNOLOGY,,
69,High-performance dynamic magnetic resonance image reconstruction and synthesis employing deep feature learning convolutional networks,30,2,380-390,"Jeyaraj Pandia Rajan,Nadar Edward Rajan Samuel","Jeyaraj PR,Nadar ERS",Jeyaraj PR,10.1002/ima.22381,Mepco Schlenk Engineering College,"This research paper shows an effective deformable complex 3D image reconstruction and image synthesis technique by consolidating needed high-level features from convolutional Neural Network (CNN) system. By recognize inherent deep feature representations in image patches for morphological changes in medicinal imaging information discovery. Various performance measurements, High Frequency Error Norm (HFEN), Mean Squared Error MSE, peak Signal-to-noise-ratio (PSNR), Structural Similarity Index (SSI), are utilized to inspect different dataset. As presented in the paper outcomes, the proposed method can accomplish predominant performance compared with other cutting-edge techniques with either low or high-level features in terms of the synthesis and reconstruction rate. The proposed deep learning algorithm has a training time of 5 seconds with 0.97 SSI and 0.15 HFEN. In all investigations, the outcome shows that the proposed image synthesis and reconstruction framework reliably exhibited progressively precise outcomes when contrasted with best in class.","dynamic MRI image reconstruction,fine-tuned deep learning,MR image synthesis,visualization",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,NEURAL-NETWORKS,INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
70,Improving multi-label chest X-ray disease diagnosis by exploiting disease and health labels dependencies,79,21-22,14889-14902,"Ge Zongyuan,Mahapatra Dwarikanath,Chang Xiaojun,Chen Zetao,Chi Lianhua,Lu Huimin","Ge ZY,Mahapatra D,Chang XJ,Chen ZT,Chi LH,Lu HM",Ge ZY,10.1007/s11042-019-08260-2,Monash University,"The widely used ChestX-ray14 dataset addresses an important medical image classification problem and has the following caveats: 1) many lung pathologies are visually similar, 2) a variant of multiple diseases including lung cancer, tuberculosis, and pneumonia are present in a single scan at the same time, i.e. multiple labels. Existing literature uses state-of-the-art deep learning models being transfer learned where output neurons of the networks are trained for individual diseases to cater for multiple disease labels in each image. However, most of them don't consider the label relationship explicitly between present and absent classes. In this work we have proposed a pair of novel error functions that can be employed for any deep learning model, Multi-label Softmax Loss (MSML) and Correlation Loss (CorLoss), to specifically address the properties of multiple labels and visually similar data. Moreover, we provide a fine-grained perspective into this problem and use bilinear pooling as an encoding scheme to increase discrimination of the model. The experiments are conducted on the ChestX-ray14 dataset. We first report improvements using our proposed loss with various backbone networks. After that, we extend our experiments to prove the rich disparity being learned by the model with our proposed losses, which can be fused with other models to improve the overall performances.","Chest X-Ray disease recognition,Multi-label learning,Deep convolutional neural network,Model fusion",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,,MULTIMEDIA TOOLS AND APPLICATIONS,,
71,Context-Aware Mixed Reality: A Learning-Based Framework for Semantic-Level Interaction,39,1,484-496,"Chen L.,Tang W.,John N. W.,Wan T. R.,Zhang J. J.","Chen L,Tang W,John NW,Wan TR,Zhang JJ",Chen L,10.1111/cgf.13887,Bournemouth University,"Mixed reality (MR) is a powerful interactive technology for new types of user experience. We present a semantic-based interactive MR framework that is beyond current geometry-based approaches, offering a step change in generating high-level context-aware interactions. Our key insight is that by building semantic understanding in MR, we can develop a system that not only greatly enhances user experience through object-specific behaviours, but also it paves the way for solving complex interaction design challenges. In this paper, our proposed framework generates semantic properties of the real-world environment through a dense scene reconstruction and deep image understanding scheme. We demonstrate our approach by developing a material-aware prototype system for context-aware physical interactions between the real and virtual objects. Quantitative and qualitative evaluation results show that the framework delivers accurate and consistent semantic information in an interactive MR environment, providing effective real-time semantic-level interactions.","interaction techniques,interaction,methods and applications-computer games,methods and applications,augmented reality,virtual environments,center dot Computing methodologies -> Scene understanding,center dot Human-centred computing -> Interaction design",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Computer Science,,2.459,,COMPUTER GRAPHICS FORUM,https://bradscholars.brad.ac.uk/bitstream/10454/17543/10/Wan_et_al-2020-Computer_Graphics_Forum.pdf,
72,Reliable and explainable machine-learning methods for accelerated material discovery,5,,,"Kailkhura Bhavya,Gallagher Brian,Kim Sookyung,Hiszpanski Anna,Han T. Yong-Jin","Kailkhura B,Gallagher B,Kim S,Hiszpanski A,Han TYJ",Kailkhura B,10.1038/s41524-019-0248-2,United States Department of Energy (DOE),"Despite ML's impressive performance in commercial applications, several unique challenges exist when applying ML in materials science applications. In such a context, the contributions of this work are twofold. First, we identify common pitfalls of existing ML techniques when learning from underrepresented/imbalanced material data. Specifically, we show that with imbalanced data, standard methods for assessing quality of ML models break down and lead to misleading conclusions. Furthermore, we find that the model's own confidence score cannot be trusted and model introspection methods (using simpler models) do not help as they result in loss of predictive performance (reliability-explainability trade-off). Second, to overcome these challenges, we propose a general-purpose explainable and reliable machine-learning framework. Specifically, we propose a generic pipeline that employs an ensemble of simpler models to reliably predict material properties. We also propose a transfer learning technique and show that the performance loss due to models' simplicity can be overcome by exploiting correlations among different material properties. A new evaluation metric and a trust score to better quantify the confidence in the predictions are also proposed. To improve the interpretability, we add a rationale generator component to our framework which provides both model-level and decision-level explanations. Finally, we demonstrate the versatility of our technique on two applications: (1) predicting properties of crystalline compounds and (2) identifying potentially stable solar cell materials. We also point to some outstanding issues yet to be resolved for a successful application of ML in material science.","CRYSTAL-STRUCTURE,DESIGN,PREDICTION,VALIDATION,MODELS",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Chemistry,Materials Science",,13.993,"CRYSTAL-STRUCTURE,DESIGN,PREDICTION,VALIDATION,MODELS",NPJ COMPUTATIONAL MATERIALS,http://arxiv.org/pdf/1901.02717,
73,A Bayesian approach to NMR crystal structure determination,21,42,23385-23400,"Engel Edgar A.,Anelli Andrea,Hofstetter Albert,Paruzzo Federico,Emsley Lyndon,Ceriotti Michele","Engel EA,Anelli A,Hofstetter A,Paruzzo F,Emsley L,Ceriotti M",Ceriotti M,10.1039/c9cp04489b,Ecole Polytechnique Federale de Lausanne,"Nuclear Magnetic Resonance (NMR) spectroscopy is particularly well suited to determine the structure of molecules and materials in powdered form. Structure determination usually proceeds by finding the best match between experimentally observed NMR chemical shifts and those of candidate structures. Chemical shifts for the candidate configurations have traditionally been computed by electronic-structure methods, and more recently predicted by machine learning. However, the reliability of the determination depends on the errors in the predicted shifts. Here we propose a Bayesian framework for determining the confidence in the identification of the experimental crystal structure, based on knowledge of the typical errors in the electronic structure methods. We demonstrate the approach on the determination of the structures of six organic molecular crystals. We critically assess the reliability of the structure determinations, facilitated by the introduction of a visualization of the similarity between candidate configurations in terms of their chemical shifts and their structures. We also show that the commonly used values for the errors in calculated C-13 shifts are underestimated, and that more accurate, self-consistently determined uncertainties make it possible to use C-13 shifts to improve the accuracy of structure determinations. Finally, we extend the recently-developed ShiftML model to render it more efficient, accurate, and, most importantly, to evaluate the uncertainties in its predictions. By quantifying the confidence in structure determinations based on ShiftML predictions we further substantiate that it provides a valid replacement for first-principles calculations in NMR crystallography.","SOLID-STATE NMR,X-RAY-DIFFRACTION,STRUCTURE PREDICTION,1ST-PRINCIPLES CALCULATIONS,POWDER CRYSTALLOGRAPHY,SPECTROSCOPY,QUANTUM,PROTON,PARAMETERS,C-13",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Physics",,3.802,"SOLID-STATE,NMR,X-RAY-DIFFRACTION,STRUCTURE,PREDICTION,1ST-PRINCIPLES,CALCULATIONS,POWDER,CRYSTALLOGRAPHY,SPECTROSCOPY,QUANTUM,PROTON,PARAMETERS,C-13",PHYSICAL CHEMISTRY CHEMICAL PHYSICS,http://arxiv.org/pdf/1909.00870,
74,"Comparison and experimental validation of predictive models for soft, fiber-reinforced actuators",40,1,119-135,"Sedal Audrey,Wineman Alan,Gillespie R. Brent,Remy C. David","Sedal A,Wineman A,Gillespie RB,Remy CD",Sedal A,10.1177/0278364919879493,University of Michigan System,"Successful soft robot modeling approaches appearing in the recent literature have been based on a variety of distinct theories, including traditional robotic theory, continuum mechanics, and machine learning. Though specific modeling techniques have been developed for and validated against already realized systems, their strengths and weaknesses have not been explicitly compared against each other. In this article, we show how three distinct model structures, a lumped-parameter model, a continuum mechanical model, and a neural network, compare in capturing the gross trends and specific features of the force generation of soft robotic actuators. In particular, we study models for fiber-reinforced elastomeric enclosures (FREEs), which are a popular choice of soft actuator and that are used in several soft articulated systems, including soft manipulators, exoskeletons, grippers, and locomoting soft robots. We generated benchmark data by testing eight FREE samples that spanned broad design and kinematic spaces and compared the models on their ability to predict the loading-deformation relationships of these samples. This comparison shows the predictive capabilities of each model on individual actuators and each model's generalizability across the design space. While the neural net achieved the highest peak performance, the first principles-based models generalized best across all actuator design parameters tested. The results highlight the essential roles of mathematical structure and experimental parameter determination in building high-performing, generalizable soft actuator models with varying effort invested in system identification.","Soft robotics,robotics,modeling,first principles,neural network,comparison",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",,,6.376,"DESIGN,ARM",INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH,http://arxiv.org/pdf/1902.00054,
75,CT-based radiomics for prediction of histologic subtype and metastatic disease in primary malignant lung neoplasms,15,1,163-172,"Ferreira-Junior Jose Raniery,Koenigkam-Santos Marcel,Magalhaes Tenorio Ariane Priscilla,Faleiros Matheus Calil,Garcia Cipriano Federico Enrique,Fabro Alexandre Todorovic,Nappi Janne,Yoshida Hiroyuki,De Azevedo-Marques Paulo Mazzoncini","Ferreira JR,Koenigkam-Santos M,Tenorio APM,Faleiros MC,Cipriano FEG,Fabro AT,Nappi J,Yoshida H,De Azevedo-Marques PM",Ferreira JR,10.1007/s11548-019-02093-y,Universidade de Sao Paulo,"PurposeAs some of the most important factors for treatment decision of lung cancer (which is the deadliest neoplasm) are staging and histology, this work aimed to associate quantitative contrast-enhanced computed tomography (CT) features from malignant lung tumors with distant and nodal metastases (according to clinical TNM staging) and histopathology (according to biopsy and surgical resection) using radiomics assessment.MethodsA local cohort of 85 patients were retrospectively (2010-2017) analyzed after approval by the institutional research review board. CT images acquired with the same protocol were semiautomatically segmented by a volumetric segmentation method. Tumors were characterized by quantitative CT features of shape, first-order, second-order, and higher-order textures. Statistical and machine learning analyses assessed the features individually and combined with clinical data.ResultsUnivariate and multivariate analyses identified 40, 2003, and 45 quantitative features associated with distant metastasis, nodal metastasis, and histopathology (adenocarcinoma and squamous cell carcinoma), respectively. A machine learning model yielded the highest areas under the receiver operating characteristic curves of 0.92, 0.84, and 0.88 to predict the same previous patterns.ConclusionSeveral radiomic features (including wavelet energies, information measures of correlation and maximum probability from co-occurrence matrix, busyness from neighborhood intensity-difference matrix, directionalities from Tamura's texture, and fractal dimension estimation) significantly associated with distant metastasis, nodal metastasis, and histology were discovered in this work, presenting great potential as imaging biomarkers for pathological diagnosis and target therapy decision.","Radiomics,Lung cancer,Quantitative imaging biomarker,Pattern recognition",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,"MARGIN,SHARPNESS,DISTANT,METASTASIS,PULMONARY,NODULES,EGFR,MUTATIONS,FEATURES,CANCER,IMAGE,SURVIVAL,ADENOCARCINOMA,PROGNOSIS",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
76,EEG signal classification using LSTM and improved neural network algorithms,24,13,9981-10003,"Nagabushanam P.,George S. Thomas,Radha S.","Nagabushanam P,George ST,Radha S",Nagabushanam P,10.1007/s00500-019-04515-0,Karunya Institute of Technology & Sciences,"Neural network (NN) finds role in variety of applications due to combined effect of feature extraction and classification availability in deep learning algorithms. In this paper, we have chosen SVM, logistic regression machine learning algorithms and NN for EEG signal classification. Two-layer LSTM and four-layer improved NN deep learning algorithms are proposed to improve the performance in EEG classification. Novelty lies in one-dimensional gradient descent activation functions with radial basis operations used in the initial layers of improved NN which help in achieving better performance. Statistical features namely mean, standard deviation, kurtosis and skewness are extracted for input EEG collected from Bonn database and then applied for various classification techniques. Accuracy, precision, recall and F1 score are the performance metrics used for analyzing the algorithms. Improved NN and LSTM give better performance compared to all other architectures. The simulations are carried out with variety of activation functions, optimizers and loss models to analyze the performance using Python in keras.","LSTM,Neural network (NN),Improved NN,Logistic regression,EEG,Accuracy",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,3.518,"ALPHA,ARCHITECTURE,TUMORS",SOFT COMPUTING,,
77,A Novel Machine Learning Based in silico Pathogenicity Predictor for Missense Variants in a Hematological Setting,134,,,"Hutter Stephan,Baer Constance,Walter Wencke,Kern Wolfgang,Haferlach Claudia,Haferlach Torsten","Hutter S,Baer C,Walter W,Kern W,Haferlach C,Haferlach T",,10.1182/blood-2019-128488,"
",,,Meeting Abstract,"AMER SOC HEMATOLOGY, 2021 L ST NW, SUITE 900, WASHINGTON, DC 20036 USA",Hematology,,20.107,,BLOOD,https://doi.org/10.1182/blood-2019-128488,
78,,,,,,,,,,,,,,,,,,,,
79,,,,,,,,,,,,,,,,,,,,
80,"Automatic real-time calibration, assessment, and maintenance of generic Raman models for online monitoring of cell culture processes",117,2,406-416,"Tulsyan Aditya,Wang Tony,Schorner Gregg,Khodabandehlou Hamid,Coufal Myra,Undey Cenk","Tulsyan A,Wang T,Schorner G,Khodabandehlou H,Coufal M,Undey C",Tulsyan A,10.1002/bit.27205,Amgen,"Raman spectroscopy is a multipurpose analytical technology that has found great utility in real-time monitoring and control of critical performance parameters of cell culture processes. As a process analytical technology (PAT) tool, the performance of Raman spectroscopy relies on chemometric models that correlate Raman signals to the parameters of interest. The current calibration techniques yield highly specific models that are reliable only on the operating conditions they are calibrated in. Furthermore, once models are calibrated, it is typical for the model performance to degrade over time due to various recipe changes, raw material variability, and process drifts. Maintaining the performance of industrial Raman models is further complicated due to the lack of a systematic approach to assessing the performance of Raman models. In this article, we propose a real-time just-in-time learning (RT-JITL) framework for automatic calibration, assessment, and maintenance of industrial Raman models. Unlike traditional models, RT-JITL calibrates generic models that can be reliably deployed in cell culture experiments involving different modalities, cell lines, media compositions, and operating conditions. RT-JITL is a first fully integrated and fully autonomous platform offering a self-learning approach for calibrating and maintaining industrial Raman models. The efficacy of RT-JITL is demonstrated on experimental studies involving real-time predictions of various cell culture performance parameters, such as metabolite concentrations, viability, and viable cell density. RT-JITL framework introduces a paradigm shift in the way industrial Raman models are calibrated, assessed, and maintained, which to the best of authors' knowledge, have not been done before.","generic models,machine-learning,model assessment,model maintenance,Raman spectroscopy",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Biotechnology & Applied Microbiology,,4.63,"SPECTROSCOPY,GLUCOSE,STATE",BIOTECHNOLOGY AND BIOENGINEERING,,
81,Energy loss prediction in nonoriented materials using machine learning techniques: A novel approach,,,,"Khan Mahmood,Afaq Muhammad,Ul Islam Ihtesham,Iqbal Javed,Shoaib Muhammad","Khan M,Afaq M,Ul Islam I,Iqbal J,Shoaib M",Afaq M,10.1002/ett.3797,"Sarhad Univ Sci & Informat Technol, Dept Comp Sci & Informat Technol, Peshawar 25000, Pakistan.","Traditional extrapolation performed by machine designers for energy loss estimation results in the decrease of the overall efficiency of electrical machines. Therefore, state-of-the-art techniques need to be developed in order to accurately predict the energy loss in electrical machines for their improved performance. To this end, machine learning techniques have been employed to predict accurate energy loss at different frequencies and induction levels under rotational conditions. Such types of flux exist near the teeth of the stator in synchronous machines. In transformers, rotational flux arises at the bends and corners of the stators. It was observed that the random forest machine learning algorithm has the least mean square error and as such is the most suited algorithm, which can be used for the accurate prediction of energy loss in nonoriented materials.",,Article; Early Access,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Telecommunications,,1.791,,TRANSACTIONS ON EMERGING TELECOMMUNICATIONS TECHNOLOGIES,,
82,An Improved Deep Polynomial Network Algorithm for Transcranial Sonography-Based Diagnosis of Parkinson's Disease,12,3,553-562,"Shen Lu,Shi Jun,Dong Yun,Ying Shihui,Peng Yaxin,Chen Lu,Zhang Qi,An Hedi,Zhang Yingchun","Shen L,Shi J,Dong Y,Ying SH,Peng YX,Chen L,Zhang Q,An HD,Zhang YC",Shi J,10.1007/s12559-019-09691-7,Shanghai University,"Transcranial sonography (TCS) is a valid neuroimaging tool for the diagnosis of Parkinson's disease (PD). The TCS-based computer-aided diagnosis (CAD) has attracted increasing attention in recent years, in which feature representation and pattern classification are two critical issues. Deep polynomial network (DPN) is a newly proposed deep learning algorithm that has shown its advantage in learning effective feature representation for samples with a small size. In this work, an improved DPN algorithm with enhanced performance on both feature representation and classification is proposed. First, the empirical kernel mapping (EKM) algorithm is embedded into DPN (EKM-DPN) to improve its feature representation. Second, the network pruning strategy is utilized in the EKM-DPN (named P-EKM-DPN). It not only produces robust feature representation, but also addresses the overfitting issues for the subsequent classifiers to some extent. Lastly, the generalization ability is further enhanced by applying the Dropout approach to P-EKM-DPN (D-P-EKM-DPN). The proposed D-P-EKM-DPN algorithm has been evaluated on a TCS dataset with 153 samples. The experimental results indicate that D-P-EKM-DPN outperforms all the compared algorithms and achieves the best classification accuracy, sensitivity, and specificity of 86.95 +/- 3.15%, 85.77 +/- 7.87%, and 87.16 +/- 6.50%, respectively. The proposed D-P-EKN-DPN algorithm has a great potential in TCS-based CAD for PD due to its excellent performance.","Parkinson's disease,Transcranial sonography,Deep polynomial network,Empirical kernel mapping,Network pruning,Dropout",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Computer Science,Neurosciences & Neurology",,4.917,"NEURAL-NETWORKS,CLASSIFICATION,KERNEL,SELECTION,FEATURES,MACHINE,DROPOUT",COGNITIVE COMPUTATION,,
83,Elucidating the Evolving Atomic Structure in Atomic Layer Deposition Reactions with in Situ XANES and Machine Learning,31,21,8937-8947,"Trejo Orlando,Dadlani Anup L.,De La Paz Francisco,Acharya Shinjita,Kravec Rob,Nordlund Dennis,Sarangi Ritimukta,Prinz Fritz B.,Torgersen Jan,Dasgupta Neil P.","Trejo O,Dadlani AL,De La Paz F,Acharya S,Kravec R,Nordlund D,Sarangi R,Prinz FB,Torgersen J,Dasgupta NP",Dasgupta NP,10.1021/acs.chemmater.9b03025,University of Michigan System,"Precision synthesis of thin films requires an improved mechanistic understanding of the structural evolution of materials at the atomic scale. Atomic layer deposition (ALD) is a critical nanofabrication technique that enables fine-tuning of atomic structure and thickness as a result of its layer-by-layer growth behavior. In this study, in situ X-ray absorption spectra of the S K-edge during ALD growth of ZnS thin films on TiO2 nanoparticles were collected and analyzed. The experimental results show that both sulfide and sulfate species form during the nucleation phase of ZnS on TiO2. As film growth proceeds, the S K-edge of the in situ ZnS film converges to that of a representative ex situ ALD ZnS film. By building representative atomistic models, a high-throughput screening method was developed to determine the most probable atomic configurations as the film structure evolves. The screening method consisted of a supervised machine learning analysis of thousands of simulated X-ray absorption near edge structure (XANES) spectra. Atomic-level insight was gained into changes in the coordination environment of surface species as they transitioned from the nucleation phase toward the crystalline ZnS phase. The experimental and computational strategies presented herein provide an example of how in situ synchrotron-based characterization can be leveraged using robust modeling approaches to elucidate the ordering of atoms during thin-film growth.","RAY-ABSORPTION SPECTROSCOPY,S-K-EDGE,SOLAR-CELLS,VIABILITY,MODULES,H2S",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Materials Science",,10.837,"RAY-ABSORPTION,SPECTROSCOPY,S-K-EDGE,SOLAR-CELLS,VIABILITY,MODULES,H2S",CHEMISTRY OF MATERIALS,https://www.osti.gov/biblio/1598269,
84,A Statistical Learning Framework for Accelerated Bandgap Prediction of Inorganic Compounds,49,1,752-762,"Chaube Suryanaman,Khullar Prerna,Srinivasan Sriram Goverapet,Rai Beena","Chaube S,Khullar P,Srinivasan SG,Rai B",Chaube S,10.1007/s11664-019-07779-2,"TCS Res, Tata Res Dev & Design Ctr, 54-B Hadapsar Ind Estate, Pune 411013, Maharashtra, India.","This study deals with an application of machine learning (ML) techniques for electronic bandgap predictions of a host of entries in the open-source Materials Project (MP) database and inorganic perovskite compounds. Initially, a dataset of 4616 inorganic compounds having available experimental bandgap data was used to generate predictive ML models-support vector machine, k-nearest neighbors, random forest, kernel ridge regression (KRR), and artificial neural networks-requiring only compositional features based on simple elemental attributes. This was followed by identification of the most crucial features for the bandgap and an evaluation of various performance metrics against the dimensionality of the feature space. The trained KRR model having the highest accuracy was then regressed on more than 22,000 entries in the MP database, and the trends are elucidated. Subsequently, out-of-sample validation was performed on a couple of datasets containing several discovered halide perovskites, in conjunction with ab-initio investigations of the undiscovered ones. Finally, the optimal classification and regression models were employed to classify a dataset of 46,970 unknown inorganic halide perovskites into metals and nonmetals followed by bandgap predictions of the nonmetallic entries.","Machine learning,bandgap prediction,inorganic compounds,Materials Project,halide perovskites",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Engineering,Materials Science,Physics",,1.746,"MELTING-POINT,PEROVSKITES,GAP",JOURNAL OF ELECTRONIC MATERIALS,,
85,Phase diagram of uranium from ab initio calculations and machine learning,100,17,,"Kruglov Ivan A.,Yanilkin Alexey,Oganov Artem R.,Korotaev Pavel","Kruglov IA,Yanilkin A,Oganov AR,Korotaev P",Kruglov IA,10.1103/PhysRevB.100.174104,Dukhov Research Institute of Automatics (VNIIA),"Experimental studies of materials at extreme conditions are challenging, and as a consequence, P-T phase diagrams are still unknown for many elements and materials. In this work, we present the P-T phase diagram of uranium calculated up to extreme conditions. First, we searched for possible crystal structures using the evolutionary algorithm USPEX. Their free energies were then calculated using thermodynamic integration (TI) and temperature-dependent effective potential techniques. TI was performed using molecular dynamics, employing a machine learning (ML) force field trained on energies and forces from density-functional calculations at the generalized gradient approximation level. The prediction error of the ML force field for the energy was less than 10 meV/atom. Using thermodynamic perturbation theory (including first and second order corrections), from the free energies of the ML force field, we obtained free energies and phase diagram at the level of quality of the underlying density-functional calculations at pressures up to 800 GPa and temperatures up to 16 000 K.","MOLECULAR-DYNAMICS,FREE-ENERGY,THERMODYNAMIC INTEGRATION,HIGH-PRESSURE,ELASTIC-CONSTANTS,MELTING CURVE,ALPHA,TRANSITION,CRYSTAL,DEFECTS",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,"MOLECULAR-DYNAMICS,FREE-ENERGY,THERMODYNAMIC,INTEGRATION,HIGH-PRESSURE,ELASTIC-CONSTANTS,MELTING,CURVE,ALPHA,TRANSITION,CRYSTAL,DEFECTS",PHYSICAL REVIEW B,,
86,Collective allostatic load measures for teams,20,3,768-781,"Davaslioglu Kemal,Pokorny Bob,Sagduyu Yalin E.,Molintas Henrik,Soltani Sohraab,Grossman Rebecca,Bowers Clint","Davaslioglu K,Pokorny B,Sagduyu YE,Molintas H,Soltani S,Grossman R,Bowers C",Davaslioglu K,10.1177/1475921719884864,Intelligent Automation Inc.,"Teams in action, such as emergency responders and medical personnel, are challenged with environments that are characterized by time pressure, rapidly unfolding events, high information processing demand, and severe consequences of wrong decisions. Such environments in general have adverse effects on team performance. To mitigate this problem and increase the performance and resilience of teams, we developed the Collective Allostatic Load Measures system. Collective Allostatic Load Measures system collects, aggregates, and analyzes multimodal data, and provides recommendation and intervention mechanisms under acute and chronic stressors. The key innovation in Collective Allostatic Load Measures is the integration of multimodal sensing capabilities with accurate algorithms that can process sequential multimodal data from heterogeneous sensors. We built a prototype of Collective Allostatic Load Measures that incorporates the core functionalities that can assess allostatic load at the team level, namely collective allostatic load. Collective Allostatic Load Measures includes a set of commercial off-the-shelf sensors that record an individual's physiological responses, a speech processing module that can extract the communication patterns of a team, a machine-learning based computational analysis module, a mobile phone app, and a web-based dashboard for visualization. Collective Allostatic Load Measures provides near real-time quantitative measurement of collective allostatic load that is leveraged to improve team performance and resilience by recommending interventions.","Allostatic load,collective allostatic load,stress,team performance,performance monitoring,physiological sensors,communication patterns,interventions,recommendations",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Engineering,Instruments & Instrumentation",,5.861,"CONSEQUENCES,CONFLICT,ACCURACY",STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL,https://journals.sagepub.com/doi/pdf/10.1177/1475921719884864,
87,Using machine learning approaches to predict high-cost chronic obstructive pulmonary disease patients in China,26,3,1577-1598,"Luo Li,Li Jialing,Lian Shuhao,Zeng Xiaoxi,Sun Lin,Li Chunyang,Huang Debin,Zhang Wei","Luo L,Li JL,Lian SH,Zeng XX,Sun L,Li CY,Huang DB,Zhang W",Zhang W,10.1177/1460458219881335,Sichuan University,"The accurate identification and prediction of high-cost Chronic obstructive pulmonary disease (COPD) patients is important for addressing the economic burden of COPD. The objectives of this study were to use machine learning approaches to identify and predict potential high-cost patients and explore the key variables of the forecasting model, by comparing differences in the predictive performance of different variable sets. Machine learning approaches were used to estimate the medical costs of COPD patients using the Medical Insurance Data of a large city in western China. The prediction models used were logistic regression, random forest (RF), and extreme gradient boosting (XGBoost). All three models had good predictive performance. The XGBoost model outperformed the others. The areas under the ROC curve for Logistic Regression, RF and XGBoost were 0.787, 0.792 and 0.801. The precision and accuracy metrics indicated that the methods achieved correct and reliable results. The results of this study can be used by healthcare data analysts, policy makers, insurers, and healthcare planners to improve the delivery of health services.","high-cost chronic obstructive pulmonary disease patients,prediction models",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA","Health Care Sciences & Services,Medical Informatics",,3.0,"HEALTH-CARE,EXPENDITURE,MEDICAL-EXPENDITURES,UNITED-STATES,NEURAL-NETWORK,COPD,COMORBIDITY,EXACERBATION,MODELS,ADULTS",HEALTH INFORMATICS JOURNAL,https://journals.sagepub.com/doi/pdf/10.1177/1460458219881335,
88,Automatic detection of small bowel tumors in wireless capsule endoscopy images using ensemble learning,47,1,52-63,"Vieira Pedro M.,Freitas Nuno R.,Valente Joao,Vaz Ismael F.,Rolanda Carla,Lima Carlos S.","Vieira PM,Freitas NR,Valente J,Vaz IF,Rolanda C,Lima CS",Vieira PM,10.1002/mp.13709,Universidade do Minho,"Purpose Wireless Capsule Endoscopy (WCE) is a minimally invasive diagnosis tool for lesion detection in the gastrointestinal tract, reaching places where conventional endoscopy is unable to. However, the significant amount of acquired data leads to difficulties in the diagnosis by the physicians; which can be eased with computer assistance. This paper addresses a method for the automatic detection of tumors in WCE by using a two-step based procedure: region of interest selection and classification. Methods The first step aims to separate abnormal from normal tissue by using automatic segmentation based on a Gaussian Mixture Model (GMM). A modified version of the Anderson method for convergence acceleration of the expectation-maximization (EM) algorithm is proposed. The proposed features for both segmentation and classification are based on the CIELab color space, as a way of bypassing lightness variations, where the L component is discarded. Tissue variability among subjects, light inhomogeneities and even intensity differences among different devices can be overcome by using simultaneously features from both regions. In the second step, an ensemble system with partition of the training data with a new training scheme is proposed. At this stage, the gating network is trained after the experts have been trained decoupling the joint maximization of both modules. The partition module is also used at the test step, leading the incoming data to the most likely expert allowing incremental adaptation by preserving data diversity. Results This algorithm outperforms others based on texture features selected from Wavelets and Curvelets transforms, classified by a regular support vector machine (SVM) in more than 5%. Conclusions This work shows that simpler features can outperform more elaborate ones if appropriately designed. In the current case, luminance was discarded to cope with saturated tissue, facilitating the color perception. Ensemble systems remain an open research field. In the current case, changes in both topology and training strategy have led to significant performance improvements. A system with this level of performance can be used in current clinical practice.","Anderson acceleration algorithm,capsule endoscopy,ensemble learning,support vector machines,fixed-point iteration,ROI selection",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"TOTAL,ENTEROSCOPY,TEXTURE",MEDICAL PHYSICS,https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/mp.13709,
89,Machine Learning-Enabled Competitive Grain Growth Behavior Study in Directed Energy Deposition Fabricated Ti6Al4V,72,1,458-464,"Li Jinghao,Sage Manuel,Guan Xiaoyi,Brochu Mathieu,Zhao Yaoyao Fiona","Li JH,Sage M,Guan XY,Brochu M,Zhao YF",Zhao YF,10.1007/s11837-019-03917-7,McGill University,"Directed energy deposition (DED) of titanium alloys is a rapidly developing technology because of its flexibility in freeform fabrication and remanufacturing. However, the uncertainties of a solidification microstructure during the deposition process are limiting its development. This article presents an artificial neural network (ANN) to investigate the relation between the grain boundary tilt angle and three causative factors, namely the thermal gradient, crystal orientation and Marangoni effect. A series of wire feedstock DED, optical microscope and electron backscatter diffraction experiments was carried out under the Taguchi experimental design to gather the training and testing data for the ANN. Compared with conventional microstructure simulation methods, the strategy and ANN model developed in this work were demonstrated to be a valid way to describe the competitive grain growth behavior in DED fabricated Ti6Al4V. They can be deployed to achieve a quantitative microstructure simulation and extended to other polycrystal material solidification processes.","MECHANICAL-PROPERTIES,CELLULAR-AUTOMATON,MICROSTRUCTURE,CONVECTION,EVOLUTION,TEXTURE",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA","Materials Science,Metallurgy & Metallurgical Engineering,Mineralogy,Mining & Mineral Processing",,2.989,"MECHANICAL-PROPERTIES,CELLULAR-AUTOMATON,MICROSTRUCTURE,CONVECTION,EVOLUTION,TEXTURE",JOM,,
90,Tongue color clustering and visual application based on 2D information,15,2,203-212,"Jiao Wen,Hu Xiao-juan,Tu Li-ping,Zhou Chang-le,Qi Zhen,Luo Zhi-yu,Zeng Ling-zhi,Ma Xu-xiang,Pai Ching-Hsuan,Fu Hong-yuan","Jiao W,Hu XJ,Tu LP,Zhou CL,Qi Z,Luo ZY,Zeng LZ,Ma XX,Pai CH,Fu HY",Xu JT,10.1007/s11548-019-02076-z,Shanghai University of Traditional Chinese Medicine,"Purpose Studies have shown the association between tongue color and diseases. To help clinicians make more objective and accurate decisions quickly, we take unsupervised learning to deal with the basic clustering of tongue color in a 2D way.MethodsA total of 595 typical tongue images were analyzed. The 3D information extracted from the image was transformed into 2D information by principal component analysis (PCA). K-Means was applied for clustering into four diagnostic groups. The results were evaluated by clustering accuracy (CA), Jaccard similarity coefficient (JSC), and adjusted rand index (ARI).ResultsThe new 2D information totally retained 89.63% original information in the L*a*b* color space. And our methods successfully classified tongue images into four clusters and the CA, ARI, and JSC were 89.04%, 0.721, and 0.890, respectively.ConclusionsThe 2D information of tongue color can be used for clustering and to improve the visualization. K-Means combined with PCA could be used for tongue color classification and diagnosis. Methods in the paper might provide reference for the other research based on image diagnosis technology.","Tongue image-based diagnosis,Principal component analysis,K-Means,2D clustering,Visual application",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,RELIABILITY,INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
91,A probabilistic method to estimate gait kinetics in the absence of ground reaction force measurements,96,,,"Tanghe Kevin,Afschrift Maarten,Jonkers Ilse,De Groote Friedl,De Schutter Joris,Aertbelien Erwin","Tanghe K,Afschrift M,Jonkers I,De Groote F,De Schutter J,Aertbelien E",Tanghe K,10.1016/j.jbiomech.2019.109327,KU Leuven,"Human joint torques during gait are usually computed using inverse dynamics. This method requires a skeletal model, kinematics and measured ground reaction forces and moments (GRFM). Measuring GRFM is however only possible in a controlled environment. This paper introduces a probabilistic method based on probabilistic principal component analysis to estimate the joint torques for healthy gait without measured GRFM. A gait dataset of 23 subjects was obtained containing kinematics, measured GRFM and joint torques from inverse dynamics in order to obtain a probabilistic model. This model was then used to estimate the joint torques of other subjects without measured GRFM. Only kinematics, a skeletal model and timing of gait events are needed. Estimation only takes 0.28 ms per time instant. Using cross-validation, the resulting root mean square estimation errors for the lower-limb joint torques are found to be approximately 0.1 Nm/kg, which is 6-18% of the range of the ground truth joint torques. Estimated joint torque and GRFM errors are up to two times smaller than model-based state-of-the-art methods. Model-free artificial neural networks can achieve lower errors than our method, but are less repeatable, do not contain uncertainty information on the estimates and are difficult to use in situations which are not in the learning set. In contrast, our method performs well in a new situation where the walking speed is higher than in the learning dataset. The method can for example be used to estimate the kinetics during overground walking without force plates, during treadmill walking without (separate) force plates and during ambulatory measurements. (C) 2019 Elsevier Ltd. All rights reserved.","Joint torques,Ground reaction forces and moments,Estimation,Inverse Dynamics,Gait",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Biophysics,Engineering",,3.123,"JOINT,KINEMATICS,DECOMPOSITION,PREDICTION,SENSORS,MOTION",JOURNAL OF BIOMECHANICS,,
92,Breast Cancer Detection in the IOT Health Environment Using Modified Recursive Feature Selection,2019,,,"Memon Muhammad Hammad,Li Jian Ping,Ul Haq Amin,Memon Muhammad Hunain,Zhou Wang","Memon MH,Li JP,Ul Haq A,Memon MH,Zhou W",Memon MH; Li JP; Ul Haq A,10.1155/2019/5176705,University of Electronic Science & Technology of China,"The accurate and efficient diagnosis of breast cancer is extremely necessary for recovery and treatment in early stages in IoT healthcare environment. Internet of Things has witnessed the transition in life for the last few years which provides a way to analyze both the real-time data and past data by the emerging role of artificial intelligence and data mining techniques. The current state-of-the-art method does not effectively diagnose the breast cancer in the early stages, and most of the ladies suffered from this dangerous disease. Thus, the early detection of breast cancer significantly poses a great challenge for medical experts and researchers. To solve the problem of early-stage detection of breast cancer, we proposed machine learning-based diagnostic system which effectively classifies the malignant and benign people in the environment of IoT. In the development of our proposed system, a machine learning classifier support vector machine is used to classify the malignant and benign people. To improve the classification performance of the classification system, we used a recursive feature selection algorithm to select more suitable features from the breast cancer dataset. The training/testing splits method is applied for training and testing of the classifier for the best predictive model. Additionally, the classifier performance has been checked on by using performance evaluation metrics such as classification, specificity, sensitivity, Matthews's correlation coefficient, F1-score, and execution time. To test the proposed method, the dataset ""Wisconsin Diagnostic Breast Cancer"" has been used in this research study. The experimental results demonstrate that the recursive feature selection algorithm selects the best subset of features, and the classifier SVM achieved optimal classification performance on this best subset of features. The SVM kernel linear achieved high classification accuracy (99%), specificity (99%), and sensitivity (98%), and the Matthews's correlation coefficient is 99%. From these experimental results, we concluded that the proposed system performance is excellent due to the selection of more appropriate features that are selected by the recursive feature selection algorithm. Furthermore, we suggest this proposed system for effective and efficient early stages diagnosis of breast cancer. Thus, through this system, the recovery and treatment will be more effective for breast cancer. Lastly, the implementation of the proposed system is very reliable in all aspects of IoT healthcare for breast cancer.","SUPPORT VECTOR MACHINE,DIAGNOSIS,HYBRID",Article,"WILEY-HINDAWI, ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND","Computer Science,Engineering,Telecommunications",,1.954,"SUPPORT,VECTOR,MACHINE,DIAGNOSIS,HYBRID",WIRELESS COMMUNICATIONS & MOBILE COMPUTING,https://downloads.hindawi.com/journals/wcmc/2019/5176705.pdf,
93,An investigation into agile learning processes and knowledge sharing practices to prevent identity theft in the online retail organisations,23,9,1857-1884,"Shah Mahmood,Maitlo Abdullah,Jones Paul,Yusuf Yahaya","Shah M,Maitlo A,Jones P,Yusuf Y",Yusuf Y,10.1108/JKM-06-2018-0370,University of Central Lancashire,"Purpose Lack of individual awareness of knowledge sharing practices to prevent identity theft is a significant issue for online retail organisations (OROs). Agile learning processes and sharing of knowledge is essential, but the lack of relevant training inhibits these processes within the online industry. This study aims to identify the inhibiting factors in agile learning and knowledge sharing process with recommendations for best practice for organisations and staff to effectively share knowledge on identity theft prevention. Design/methodology/approach Three qualitative case studies were undertaken in OROs in the UK. Data were collected using semi-structured interviews, internal documents and related external material. The data were analysed using a thematic analysis method. Findings The findings identified that individual staff members within OROs from the information security and fraud prevention departments often share their knowledge as a community. However, there is no formal knowledge sharing process or any related training facilitating this exchange. There is a need for agile learning environment in OROs of the UK. Originality/value The study offers both theoretical and practical contributions to the extant literature of agile learning of knowledge sharing to prevent identity theft in OROs. Existing learning opportunities are not being used to enhance the knowledge of individuals, and OROs need to increase the skills and trust of their staff to share knowledge efficiently. This study identifies the systemic weaknesses inherent in the process of knowledge sharing and existing training provision within OROs. It provides ORO managers with practical guidelines in facilitating trust between individuals and developing appropriate training systems to educate staff on sharing organisational knowledge. This study contributes by extending the knowledge sharing framework proposed by Chong et al. (2011) for enhanced individual knowledge sharing processes to prevent identity theft within OROs. It also identifies OROs' weaknesses in knowledge sharing learning processes for theft prevention and offers prevention guidelines and recommendations for developing effective agile learning environments.","Information security,Knowledge sharing,Case study,Identity theft,Staff awareness,Agile learning",Article,"EMERALD GROUP PUBLISHING LTD, HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND","Information Science & Library Science,Business & Economics",,,"PUBLIC-SECTOR,MEDIATING,ROLE,JOB,ROTATION,MANAGEMENT,IMPACT,INFORMATION,PERFORMANCE,LEADERSHIP,FRAMEWORK,TRUST",JOURNAL OF KNOWLEDGE MANAGEMENT,https://cronfa.swan.ac.uk/Record/cronfa49019/Download/0049019-11032019114354.pdf,
94,A machine learning method correlating pulse pressure wave data with pregnancy,36,1,,"Chen Jianhong,Huang Huang,Hao Wenrui,Xu Jinchao","Chen JH,Huang H,Hao WR,Xu JC",Xu JC,10.1002/cnm.3272,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Pulse feeling , representing the tactile arterial palpation of the heartbeat, has been widely used in traditional Chinese medicine (TCM) to diagnose various diseases. The quantitative relationship between the pulse wave and health conditions however has not been investigated in modern medicine. In this paper, we explored the correlation between pulse pressure wave (PPW), rather than the pulse key features in TCM, and pregnancy by using deep learning technology. This computational approach shows that the accuracy of pregnancy detection by the PPW is 84% with an area under the curve (AUC) of 91%. Our study is a proof of concept of pulse diagnosis and will also motivate further sophisticated investigations on pulse waves.","conventional neural network,deep learning,pregnancy,pulse diagnosis,pulse pressure wave",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Mathematical & Computational Biology,Mathematics",,2.839,"ARTERIAL,STIFFNESS,VELOCITY,DIAGNOSIS,MORTALITY,EVENTS,MARKER",INTERNATIONAL JOURNAL FOR NUMERICAL METHODS IN BIOMEDICAL ENGINEERING,http://arxiv.org/pdf/1910.01726,
95,A method to evaluate the segregation of compacted asphalt pavement by processing the images of paved asphalt mixture,224,,622-629,"Cong Lin,Shi Jiachen,Wang Tongjing,Yang Fan,Zhu Tiantong","Cong L,Shi JC,Wang TJ,Yang F,Zhu TT",Cong L,10.1016/j.conbuildmat.2019.07.041,Tongji University,"Segregation in hot-mix asphalt pavement is a common failure during the construction process. The prevailing segregation detection methods can be used to detect and evaluate segregation only after segregation occurs. This study proposes a real time segregation detection method by using machine learning classifier to categorize the images of the paved mixture (IPM) during construction. The study first manually labeled 224 various levels of hot mix asphalt segregation images. Then, 14 texture features such as contrast, correlation of the IPM were calculated by the gray level co-occurrence matrix (GLCM). Next, the principal component analysis (PCA) was done to reduce the 14 features to 6 main components. Later on, the 6 main components were fed to a Naive Bayesian classifier to categorize the segregation level. Finally, the classification results indicate that the Naive Bayesian classifier has 80% accuracy when compared with the manually labelled results. Results of this study can potentially be adapted for real-time and large-scale hot mix asphalt segregation evaluation. (C) 2019 Elsevier Ltd. All rights reserved.","Asphalt pavement,Segregation,Image processing,Gray level co-occurrence matrix,Principal component analysis,Naive Bayesian classifier",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Construction & Building Technology,Engineering,Materials Science",,6.841,"AGGREGATE,GRADATION,INTELLIGENT,QUALITY",CONSTRUCTION AND BUILDING MATERIALS,,
96,A novel method for tool condition monitoring based on long short-term memory and hidden Markov model hybrid framework in high-speed milling Ti-6Al-4V,105,7-8,3165-3182,"Tao Zhengrui,An Qinglong,Liu Gongyu,Chen Ming","Tao ZR,An QL,Liu GY,Chen M",An QL,10.1007/s00170-019-04464-w,Shanghai Jiao Tong University,"High-speed milling of Ti-6Al-4V produces high temperature in the cutting zone resulting in the rapid notching and severe flank wear, which tend to cause the deterioration of the machined surface and increased manufacturing costs. To track the performance degradation of the cutting tool, more and more studies have been conducted to develop effective tool condition monitoring (TCM) systems, hoping to obtain the tool wear status based on monitoring signals. In recent years, machine learning and deep learning methods have developed rapidly and are becoming increasingly popular, and the related research results inspired this article. In this paper, a novel method based on long short-term memory network and hidden Markov model (LSTM-HMM) is presented to track the flank wear and predict the remaining useful life (RUL). The model is divided into three parts: training phase, diagnostic phase, and prognostic phase. During the training phase, both the observed monitoring signal and extracted features that characterize tool wear status are used as the inputs to the training algorithms to estimate the parameters of the global model and local models. Then proceed to the diagnostic phase, the established global model is utilized to identify the current tool wear stage deciding which model to select from the local model base. Finally, the mean wear amount, the remaining useful life, and the associated confidence interval are calculated in the prognostic phase. The proposed hybrid model and several other published methods are applied to the three datasets acquired from milling experiments. The experimental and analytical results indicate that the integrated framework is applicable to track the tool wear and predict its RUL during the high-speed milling Ti-6Al-4V.","Tool condition monitoring,Long short-term memory network,Hidden Markov model,High-speed milling",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND","Automation & Control Systems,Engineering",,3.32,"CONDITION,CLASSIFICATION,NEURAL-NETWORKS,WEAR,ESTIMATION",INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY,,
97,,,,,,,,,,,,,,,,,,,,
98,,,,,,,,,,,,,,,,,,,,
99,,,,,,,,,,,,,,,,,,,,
