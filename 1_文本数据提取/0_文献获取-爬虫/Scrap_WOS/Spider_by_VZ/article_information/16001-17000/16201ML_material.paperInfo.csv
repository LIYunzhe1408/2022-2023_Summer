,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Applications and Trends of Machine Learning in Genomics and Phenomics for Next-Generation Breeding,9,1,,"Esposito Salvatore,Carputo Domenico,Cardi Teodoro,Tripodi Pasquale","Esposito S,Carputo D,Cardi T,Tripodi P",Tripodi P,10.3390/plants9010034,"CREA Res Ctr Vegetable & Ornamental Crops, I-84098 Pontecagnano Faiano, Italy.","Crops are the major source of food supply and raw materials for the processing industry. A balance between crop production and food consumption is continually threatened by plant diseases and adverse environmental conditions. This leads to serious losses every year and results in food shortages, particularly in developing countries. Presently, cutting-edge technologies for genome sequencing and phenotyping of crops combined with progress in computational sciences are leading a revolution in plant breeding, boosting the identification of the genetic basis of traits at a precision never reached before. In this frame, machine learning (ML) plays a pivotal role in data-mining and analysis, providing relevant information for decision-making towards achieving breeding targets. To this end, we summarize the recent progress in next-generation sequencing and the role of phenotyping technologies in genomics-assisted breeding toward the exploitation of the natural variation and the identification of target genes. We also explore the application of ML in managing big data and predictive models, reporting a case study using microRNAs (miRNAs) to identify genes related to stress conditions.","genotyping by sequencing,genome-wide association studies,QTLs dissection,genomics,nanopore,PacBio,phenomics,machine learning,microRNA",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Plant Sciences,,,"INTER-CROSS,POPULATION,ABIOTIC,STRESS,TRAITS,SELECTION,EXPRESSION,RESISTANCE,TOLERANCE,GENES,GWAS,TOOL",PLANTS-BASEL,https://www.mdpi.com/2223-7747/9/1/34/pdf,
2,ARCHIE: AN AUTOMATED DATA COLLECTION METHOD FOR PHYSICAL PROTOTYPING EFFORTS IN AUTHENTIC DESIGN SITUATIONS,,,,"Nelson Jacob,Berlin Andrew,Menold Jessica","Nelson J,Berlin A,Menold J",Nelson J,,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Effective data collection can be one of the most challenging aspects of engineering design research. Design projects often occur over periods of weeks, months, or years, making continuous data collection a time-intensive task. Further, interrupting the design process to collect data can be intrusive and disrupt the flow of design. ARCHIE is a system designed to take photos of designers' physical prototypes, link them to designer perceptions of the design, and maintain a record of design evolution over time. This device will allow researchers to collect data on physical prototyping efforts in design environments without researcher intervention, reducing the burden of data collection in authentic design settings. The device provides designers with an easier way to document physical prototyping efforts and record the evolution of their design with photos and descriptions and promises to allow for researchers to leverage machine learning to automatically analyze aspects of the prototype such as geometric complexity or material choice by facilitating the creation of databases of design artifacts. This work describes the rationale, method, implementation, and testing of ARCHIE using student design projects.",,Proceedings Paper,"AMER SOC MECHANICAL ENGINEERS, THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA",Engineering,,,,"PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2019, VOL 7",,
3,Convolutional Neural Networks for Heat Flux Model Validation on NSTX-U,48,1,3-13,"Looby Tom,Reinke Matthew,Donovan David,Gray Travis,Messineo Mike,Khodak Andrei","Looby T,Reinke M,Donovan D,Gray T,Messineo M,Khodak A",Looby T,10.1109/TPS.2019.2919288,University of Tennessee System,"To demonstrate the use of embedded thermocouples in new National Spherical Tokamak eXperiment Upgrade (NSTX-U) graphite plasma-facing components (PFCs), a convolutional neural network (CNN) has been trained using the ANSYS simulations to predict the scrape-off layer (SOL) heat flux width, lambda(q), given various machine operational parameters and diagnostic data as inputs. The proof-of-concept CNN was trained on the thermocouple data generated by the approximated NSTX-U heat loads applied to real PFC designs in ANSYS. Once trained, the CNN is capable of high precision reconstruction of parameterized heat flux profiles expected in NSTX-U. In addition, to test the system's ability to cope with noise and systematic error, pseudonoise was injected into the simulated data. CNN can accurately predict the incident heat flux despite this noise and error.","Convolutional,divertor,heat flux,machine learning,National Spherical Tokamak eXperiment Upgrade (NSTX-U),neural network,nuclear fusion",Article; Proceedings Paper,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",,,,,IEEE TRANSACTIONS ON PLASMA SCIENCE,https://www.osti.gov/biblio/1671409,
4,Using Sparse Gaussian Processes for Predicting Robust Inertial Confinement Fusion Implosion Yields,48,1,14-21,"Hatfield Peter,Rose Steven,Scott Robbie,Almosallam Ibrahim,Roberts Stephen,Jarvis Matt","Hatfield P,Rose S,Scott R,Almosallam I,Roberts S,Jarvis M",Hatfield P,10.1109/TPS.2019.2944416,University of Oxford,"Here, we present the application of an advanced sparse Gaussian process-based machine learning algorithm to the challenge of predicting the yields of inertial confinement fusion (ICF) experiments. The algorithm is used to investigate the parameter space of an extremely robust ICF design for the National Ignition Facility, the ""Simplest Design""; deuterium-tritium gas in a plastic ablator with a Gaussian, Planckian drive. In particular, we show that: 1) GPz has the potential to decompose uncertainty on predictions into uncertainty from lack of data and shot-to-shot variation; 2) it permits the incorporation of science-goal-specific cost-sensitive learning (CSL), e.g., focusing on the high-yield parts of parameter space; and 3) it is very fast and effective in high dimensions.","Gaussian processes,inertial confinement",Article; Proceedings Paper,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",,,1.268,SIMULATIONS,IEEE TRANSACTIONS ON PLASMA SCIENCE,http://arxiv.org/pdf/1910.08410,
5,Transfer Learning to Model Inertial Confinement Fusion Experiments,48,1,61-70,"Humbird K. D.,Peterson J. L.,Spears B. K.,McClarren R. G.","Humbird KD,Peterson JL,Spears BK,McClarren RG",Humbird KD,10.1109/TPS.2019.2955098,United States Department of Energy (DOE),"Inertial confinement fusion (ICF) experiments are designed using computer simulations that are approximations of reality and therefore must be calibrated to accurately predict experimental observations. In this article, we propose a novel technique for calibrating from simulations to experiments, or from low fidelity simulations to high fidelity simulations, via ""transfer learning"" (TL). TL is a commonly used technique in the machine learning community, in which models trained on one task are partially retrained to solve a separate, but related task, for which there is a limited quantity of data. We introduce the idea of hierarchical TL, in which neural networks trained on low fidelity models are calibrated to high fidelity models, then to experimental data. This technique essentially bootstraps the calibration process, enabling the creation of models which predict high fidelity simulations or experiments with minimal computational cost. We apply this technique to a database of ICF simulations and experiments carried out at the Omega laser facility. TL with deep neural networks enables the creation of models that are more predictive of Omega experiments than simulations alone. The calibrated models accurately predict future Omega experiments, and are used to search for new, optimal implosion designs.","Inertial confinement,neural networks",Article; Proceedings Paper,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",,,,"BAYESIAN,CALIBRATION,ADIABAT,IGNITION",IEEE TRANSACTIONS ON PLASMA SCIENCE,https://www.osti.gov/biblio/1650463,
6,EXTRACTING CUSTOMER PERCEPTIONS OF PRODUCT SUSTAINABILITY FROM ONLINE REVIEWS,,,,"EI-Dehaibi Nasreddine,MacDonald Erin F.","EI-Dehaibi N,MacDonald EF",EI-Dehaibi N,,Stanford University,"In order for a sustainable product to be successful in the market, designers must create products that are not only sustainable in reality, but are also sustainable as perceived by the customer and reality vs. perception of sustainability can be quite different. This paper details a design method to identify perceived sustainable features (PerSFs) by collecting online reviews, manually annotating them using crowd-sourced work, and processing the annotated review fragments with a Natural Language machine learning algorithm. We analyze all three pillars of sustainability social, environmental, and economic for positive and negative perceptions of product features of a French press coffee carafe. For social aspects, the results show that positive PerSFs are associated with intangible features, such as giving the product as a gift, while negative PerSFs are associated with tangible features perceived as unsafe, like sharp corners. For environmental aspects, positive PerSFs are associated with reliable materials like metal while negative PerSFs are associated with the use of plastic. For economic aspects, PerSFs mainly serve as a price constraint for designers to satisfy, other customer perceptions. We also show that some crucial sustainability concerns related to environmental aspects, like energy and water consumption, did not have a significant impact on customer sentiment, thus demonstrating the anticipated gap in sustainability perceptions and the realities of sustainable design, as noted in previous literature. From these results, online reviews can enable designers to extract PerSFs for further design study and to create products that resonate with customers' sustainable values.",RISK,Proceedings Paper,"AMER SOC MECHANICAL ENGINEERS, THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA",Engineering,,,RISK,"PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2019, VOL 2B",,
7,A REVIEW OF MACHINE LEARNING APPLICATIONS IN ADDITIVE MANUFACTURING,,,,"Razvi Sayyeda Saadia,Feng Shaw,Narayanan Anantha,Lee Yung-Tsun Tina,Witherell Paul","Razvi SS,Feng S,Narayanan A,Lee YTT,Witherell P",Razvi SS,,National Institute of Standards & Technology (NIST) - USA,"Variability in product quality continues to pose a major barrier to the widespread application of additive manufacturing (AM) processes in production environment. Towards addressing this barrier, monitoring AM processes and measuring AM materials and parts has become increasingly commonplace, and increasingly precise, making a new wave of AM-related data available. This newfound data provides a valuable resource for gaining new insight to AM processes and decision making. Machine Learning (ML) provides an avenue to gain this insight by 1) learning fundamental knowledge about AM processes and 2) identifying predictive and actionable recommendations to optimize part quality and process design. This report presents a literature review of ML applications in AM. The review identifies areas in the AM lifecycle, including design, process plan, build, post process, and test and validation, that have been researched using ML. Furthermore, this report discusses the benefits of ML for AM, as well as existing hurdles currently limiting applications.","additive manufacturing,machine learning,deep learning,data analytics,algorithm,survey,review",Proceedings Paper,"AMER SOC MECHANICAL ENGINEERS, THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA","Computer Science,Engineering",,,"POWDER-BED,FUSION,ANOMALY,DETECTION,COMPUTER,VISION,NEURAL-NETWORK,CLASSIFICATION","PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2019, VOL 1",,
8,MULTI-FIDELITY PHYSICS-CONSTRAINED NEURAL NETWORK AND ITS APPLICATION IN MATERIALS MODELING,,,,"Liu Dehao,Wang Yan","Liu DH,Wang Y",Wang Y,,University System of Georgia,"Training machine learning tools such as neural networks requires the availability of sizable data, which can be difficult for engineering and scientific applications where experiments or simulations are expensive. In this work, a novel multi-fidelity physics-constrained neural network is proposed to reduce the required amount of training data, where physical knowledge is applied to constrain neural networks, and multi-fidelity networks are constructed to improve training efficiency. A low-cost lowfidelity physics-constrained neural network is used as the baseline model, whereas a limited amount of data from a highfidelity simulation is used to train a second neural network to predict the difference between the two models. The proposed framework is demonstrated with two-dimensional heat transfer and phase transition problems, which are fundamental in materials modeling. Physics is described by partial differential equations. With the same set oftraining data, the prediction error of physics-constrained neural network can be one order of magnitude lower than that ofa classical artificial neural network without physical constraints. The accuracy of the prediction is comparable to those from direct numerical solutions of equations.","machine learning,multi-fidelity model,physics-constrained neural networks,materials modeling,partial differential equations",Proceedings Paper,"AMER SOC MECHANICAL ENGINEERS, THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA",Engineering,,,"BOUNDARY-VALUE-PROBLEMS,PRIOR,KNOWLEDGE,FUNCTION,APPROXIMATION,OPTIMIZATION,APPROACH,NUMERICAL-SOLUTION,SYSTEMS","PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2019, VOL 2A",,
9,TOPOLOGY DESIGN WITH CONDITIONAL GENERATIVE ADVERSARIAL NETWORKS,,,,"Sharpe Conner,Seepersad Carolyn Conner","Sharpe C,Seepersad CC",Sharpe C,,University of Texas System,"Deep convolutional neural networks have gained significant traction as effective approaches for developing detailed but compact representations of complex structured data. Generative networks in particular have become popular for their ability to mimic data distributions and allow further exploration of them. This attribute can be utilized in engineering design domains, in which the data structures of finite element meshes for analyzing potential designs are well suited to the deep convolutional network approaches that are being developed at a rapid pace in the field of image processing. This paper explores the use of conditional generative adversarial networks (cGANs) as a means of generating a compact latent representation of structures resulting from classical topology optimization techniques. The constraints and contextual factors of a design problem, such as mass fraction, material type, and load location, can then be specified as input conditions to generate potential topologies in a directed fashion. The trained network can be used to aid concept generation, such that engineers can explore a variety of designs relevant to the problem at hand with ease. The latent variables of the generator can also be used as design parameters, and the low dimensionality enables tractable computational design without analytical sensitivities. This paper demonstrates these capabilities and discusses avenues for further developments that would enable the engineering design community to further leverage generative machine learning techniques to their full potential.",,Proceedings Paper,"AMER SOC MECHANICAL ENGINEERS, THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA",Engineering,,,,"PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2019, VOL 2A",,
10,COMPUTATIONAL DESIGN OF A PERSONALIZED ARTIFICIAL SPINAL DISC WITH A DATA-DRIVEN DESIGN VARAIBLE LINKING HEURISTIC,,,,"Yu Zhiyang,Shea Kristina,Stankovic Tino","Yu ZY,Shea K,Stankovic T",Yu ZY,,ETH Zurich,"A personalized, 3D printed, multi-material artificial spinal disc is expected to not only achieve personalized anatomicalfit, but also to restore the natural mechanics of the implanted spinal segment. However, the necessary structure for disc design is not explored and optimizing the design is challenging due to the high -dimensional search space provided by the material distribution precision of multi-material 3D printing as well as necessary nonlinear finite element simulation. Therefore, this study explores the feasibility of two multi-material spinal disc designs and a clustering-based design variable linking method to achieve efficient and effective optimization. The optimization goal is to enable the implant to have natural stiffnesses for five loading cases. The results show that a biomimetic fiber network is necessary for the disc design. Moreover, the optimization performance of the heuristic derived from a clustering-based method is shown to be a good trade-off between the objective function value and the computational time.","Total disc replacement,Personalized medicine,Artificial spinal disc,Computational design,Additive manufacturing,Machine Learning,Optimization",Proceedings Paper,"AMER SOC MECHANICAL ENGINEERS, THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA",Engineering,,,"INTERVERTEBRAL,DISC,MOTION,OPTIMIZATION,SPACE","PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2019, VOL 2A",,
11,Application of deep neural networks to improve diagnostic accuracy of rheumatoid arthritis using diffuse optical tomography,50,1,21-32,"Feng Yangqin,Lighter D.,Zhang Lei,Wang Yan,Dehghani H.","Feng YQ,Lighter D,Zhang L,Wang Y,Dehghani H",Dehghani H,10.1070/QEL17177,University of Birmingham,"A set of deep neural network models for rheumatoid arthritis (RA) classification using a highway network, a convolutional neural network and a residual network is proposed based on the data of diffuse optical tomography (DOT) utilising near-infrared light, which ensures early diagnosis of pathophysiological changes resulting from inflammation. A numerical model of the finger is used to generate images to overcome the inherent problem of insufficient clinical DOT images available. The proposed deep neural network models are applied to automatically classify simulated DOT images of inflamed and non-inflamed joints and transfer learning is also used to improve the performance of the classification. The results demonstrate that all three deep neural network methods improve the diagnostic accuracy as compared to the widely applied support vector machine (SVM), especially for high inter-subject variability databases. In cases of distinct modelled severity of disease, residual network achieved the highest accuracy (> 99%), and both of highway and convolutional neural networks reached 99%, respectively. However, as the severity of the modelled disease is reduced, this accuracy is reduced to 75.2% for residual networks. The results indicate that transfer learning can improve the performance of deep neural network methods on RA classification from DOT data and highlight their potential as a computer aided tool in DOT diagnostic systems.","rheumatoid arthritis diagnosis,diffuse optical tomography,finger joints,deep neural networks,medical image classification",Article,"TURPION LTD, C/O TURPION LTD, IOP PUBLISHING, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6HG, ENGLAND","Engineering,Physics",,0.948,"FOLLOW-UP,RADIOGRAPHY,DISEASE",QUANTUM ELECTRONICS,,
12,A probability and integrated learning based classification algorithm for high-level human emotion recognition problems,150,,,"Jiang Dazhi,Wu Kaichao,Chen Dicheng,Tu Geng,Zhou Teng,Garg Akhil,Gao Liang","Jiang DZ,Wu KC,Chen DC,Tu G,Zhou T,Garg A,Gao L",Gao L,10.1016/j.measurement.2019.107049,Huazhong University of Science & Technology,"In this paper, a probability and integrated learning (PIL) based classification algorithm is proposed for solving high-level human emotion recognition problems. Firstly, by simulating human thinking mode and construction, a novel topology of integrated learning is proposed to obtain the essential material basis for analyzing the complex human emotions. Secondly, classification algorithm based on PIL is presented to adapt the emotion classification fuzziness caused by the emotional uncertainty, which is realized by calculating the confidence interval of the classification probability. This paper also presented three new analyses methods based on classification probability including the emotional sensitivity, emotional decision preference and emotional tube. Our study expects that the proposed method could be used in the affective computing for video, and may play a reference role in artificial emotion established for robot with a natural and humanized way. (C) 2019 Elsevier Ltd. All rights reserved.","Emotion analysis problem,Classification probability,Integrated learning",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Instruments & Instrumentation",,3.778,"OPTIMIZATION,RETRIEVAL,DESIGN,MODEL",MEASUREMENT,,
13,STRUCTURAL HEALTH MONITORING OF COMPOSITE STRUCTURES VIA MACHINE LEARNING OF MECHANOLUMINESCENCE,,,,"Gupta Sujasha,Krishnan Srivatsava,Sundaresan Vishnubaba","Gupta S,Krishnan S,Sundaresan V",Gupta S,,Ohio State University,"The goal of this paper is to develop a machine learning algorithm for structural health monitoring of polymer composites with mechanoluminescent phosphors as distributed sensors. Mechanoluminescence is the phenomenon of light emission from organic/inorganic materials due to mechanical stimuli. Distributed sensors collect a large amount of data and contain structural response information that is difficult to analyze using classical or continuum models. Hence, approaches to analyze this data using machine learning or deep learning is necessary to develop models that describe initiation of damage, propagation and ultimately structural failure.
This paper focuses on developing a machine learning algorithm that predicts the elastic modulus of a structure as a function of input parameters such as stress and measured light output. The training data for the algorithm utilizes experimental results from cyclical loading of elastomeric composite coupons impregnated with ML particles. A multivariate linear regression is performed on the elastic modulus within the training data as a function of stress and ML emission intensity. Error in predicted elastic modulus is minimized using a gradient descent algorithm. The machine learning algorithm outlined in this paper is expected to provide insights into structural response and deterioration of mechanical properties in real-time that cannot be obtained using a finite array of sensors.","Mechanoluminescence,structural health monitoring,machine learning,multivariate regression model",Proceedings Paper,"AMER SOC MECHANICAL ENGINEERS, THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA","Engineering,Materials Science",,,"DAMAGE,DETECTION",,,
14,"PAN precursor fabrication, applications and thermal stabilization process in carbon fiber production: Experimental and mathematical modelling",107,,,"Khayyam Hamid,Jazar Reza N.,Nunna Srinivas,Golkarnarenji Gelayol,Badii Khashayar,Fakhrhoseini Seyed Mousa,Kumar Satish,Naebe Minoo","Khayyam H,Jazar RN,Nunna S,Golkarnarenji G,Badii K,Fakhrhoseini SM,Kumar S,Naebe M",Khayyam H,10.1016/j.pmatsci.2019.100575,Royal Melbourne Institute of Technology (RMIT),"Polyacrylonitrile (PAN) is a versatile man-made polymer and has been used in a large array of products since its first mass production in the mid 40s. Among all applications of PAN the widely used application is in manufacture of precursor fiber for fabrication of carbon fibers. The process of PAN-based carbon fiber production comprises fiber spinning, thermal stabilization and carbonization stages. Carbon fiber properties are significantly dependent on the quality of PAN precursor fiber and in particular the process parameters involved in thermal stabilization. This paper is the first comprehensive review that provides a general understanding of the links between PAN fiber structure, properties, and its stabilization process along with the use of mathematical modelling as a powerful tool in prediction and optimization of the processes involved. Since the promise of the mathematical modelling is to predict the future behaviour of the system and the value of the variables for the unseen or unmeasured domain of variables; and in the era of industry 4.0 rise, this review will be valuable in further understanding of the intricate processes of carbon fiber manufacture and utilising the advanced mathematical modelling using machine learning techniques to predict and optimize a range of critical factors that control the quality of PAN and resultant carbon fibers.","Thermal stabilization process,Mathematical modelling,Carbon fiber,Polyacrylonitrile fiber (PAN),Predictive and Optimization modelling,Artificial intelligence,Machine learning,Industry 4.0",Review,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Materials Science,,39.026,"ELECTROSPUN,POLYACRYLONITRILE,NANOFIBERS,INTERFACIAL,SHEAR-STRENGTH,OXIDATIVE,STABILIZATION,ACRYLIC,FIBERS,METAL-IONS,X-RAY,ISOTACTIC,POLYACRYLONITRILE,QUANTITATIVE-ANALYSIS,RADIAL,HETEROGENEITY,SURFACE,MODIFICATION",PROGRESS IN MATERIALS SCIENCE,,
15,,,,,,,,,,,,,,,,,,,,
16,Point2Volume: A Vision-Based Dietary Assessment Approach Using View Synthesis,16,1,577-586,"Lo Frank P. -W.,Sun Yingnan,Qiu Jianing,Lo Benny P. L.","Lo FPW,Sun YN,Qiu JN,Lo BPL",Lo FPW,10.1109/TII.2019.2942831,Imperial College London,"Dietary assessment is an important tool for nutritional epidemiology studies. To assess the dietary intake, the common approach is to carry out 24-h dietary recall (24HR), a structured interview conducted by experienced dietitians. Due to the unconscious biases in such self-reporting methods, many research works have proposed the use of vision-based approaches to provide accurate and objective assessments. In this article, a novel vision-based method based on real-time three-dimensional (3-D) reconstruction and deep learning view synthesis is proposed to enable accurate portion size estimation of food items consumed. A point completion neural network is developed to complete partial point cloud of food items based on a single depth image or video captured from any convenient viewing position. Once 3-D models of food items are reconstructed, the food volume can be estimated through meshing. Compared to previous methods, our method has addressed several major challenges in vision-based dietary assessment, such as view occlusion and scale ambiguity, and it outperforms previous approaches in accurate portion size estimation.","Three-dimensional displays,Solid modeling,Volume measurement,Deep learning,Cameras,Estimation,Data models,Deep learning,dietary assessment,point cloud completion,three-dimensional (3-D) reconstruction,volume estimation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Computer Science,Engineering",,9.768,,IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS,http://spiral.imperial.ac.uk/bitstream/10044/1/76639/5/08853329.pdf,
17,Node-Centric Graph Learning From Data for Brain State Identification,6,,120-132,"Ghoroghchian Nafiseh,Groppe David M.,Genov Roman,Valiante Taufik A.,Draper Stark C.","Ghoroghchian N,Groppe DM,Genov R,Valiante TA,Draper SC",Ghoroghchian N,10.1109/TSIPN.2020.2964230,University of Toronto,"Data-driven graph learning models a network by determining the strength of connections between its nodes. The data refers to a graph signal which associates a value with each graph node. Existing graph learning methods either use simplified models for the graph signal, or they are prohibitively expensive in terms of computational and memory requirements. This is particularly true when the number of nodes is high or there are temporal changes in the network. In order to consider richer models with a reasonable computational tractability, we introduce a graph learning method based on representation learning on graphs. Representation learning generates an embedding for each graph node, taking the information from neighbouring nodes into account. Our graph learning method further modifies the embeddings to compute the graph similarity matrix. In this work, graph learning is used to examine brain networks for brain state identification. We infer time-varying brain graphs from an extensive dataset of intracranial electroencephalographic (iEEG) signals from ten patients. We then apply the graphs as input to a classifier to distinguish seizure vs. non-seizure brain states. Using the binary classification metric of area under the receiver operating characteristic curve (AUC), this approach yields an average of 9.13 percent improvement when compared to two widely used brain network modeling methods.","Graph learning,similarity matrix,graph signal processing,representation learning,graph neural networks,brain connectivity,seizure detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Telecommunications",,4.152,,IEEE TRANSACTIONS ON SIGNAL AND INFORMATION PROCESSING OVER NETWORKS,http://arxiv.org/pdf/2011.02179,
18,Performance evaluation of gasification system efficiency using artificial neural network,145,,2253-2270,"Ozonoh M.,Oboirien B. O.,Higginson A.,Daramola M. O.","Ozonoh M,Oboirien BO,Higginson A,Daramola MO",Daramola MO,10.1016/j.renene.2019.07.136,University of Witwatersrand,"Gasification is one of the thermo-chemical energy conversion processes with energy self-sufficiency, recoverability and controllable efficiency when compared to combustion and pyrolysis. Gasification process is carried out using different systems (gasifiers), different types of fuels and process conditions, and these factors determine the efficiency of the overall process. The performance of a gasifier is evaluated by some parameters such as Cold Gas Efficiency (CGE), Carbon Conversion Efficiency (CCE), gas yield, gas composition, and lower heating value (LHV) of gas. To understand how efficient a gasifier is, several experiments are needed, but conducting these experiments is time consuming and capital intensive, and the information is vital in energy production plants. Meanwhile, a model that could accurately predict the aforementioned parameters irrespective of the type of gasifier, fuel, and operating conditions is imperative for some time conditions. In this study, Levenberg-Marquardt (LM) back-propagation and Bayesian Regularisation (BR) training algorithms for an Artificial Neural Networks (ANN) were used to study a dataset containing 315 experimental data of biomass, coal, and blends of biomass and coal from various gasifiers and process conditions. Eleven input variables were used in the study, and the result shows that the Mean Square Error (MSE) of the BR algorithm was higher than that of the L-M algorithm. To reduce the MSE, techniques called Input Variables Representation Technique with Visual Inspection method (IVRT-VIM) and Output Variables Representation Technique with Visual Inspection Method (OVRT-VIM) were developed, and their applications produced smaller MSE and an R-2 of between 79 - 98% and 95-96%, respectively. Further, the results of the sensitivity analysis revealed that carbon (% amount) is the most important input parameter affecting the outputs, and with sum of the Squares of the Partial Derivatives (SSD) value of 1.18 for the CGE prediction. (c) 2019 Elsevier Ltd. All rights reserved.","Artificial neural network,Coal and biomass,Energy conversion,Gasification efficiency,Performance evaluation",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Science & Technology - Other Topics,Energy & Fuels",,7.435,"BIOMASS,GASIFICATION,FLUIDIZED-BED,FIXED-BED,ELEMENTAL,COMPOSITION,STEAM,GASIFICATION,HYDROGEN,SYNGAS,MODELS",RENEWABLE ENERGY,,
19,Field applicability of a machine learning-based tensile force estimation for pre-stressed concrete bridges using an embedded elasto-magnetic sensor,19,1,281-292,"Kim Junkyeong,Park Seunghee","Kim J,Park S",Park S,10.1177/1475921719842340,Sungkyunkwan University (SKKU),"It has been proposed that pre-stressed concrete bridges improve load performance by inducing axial pre-stress using pre-stress tendons. However, the tensile force of the pre-stress tendons could not be managed after construction, although it directly supports the load of the structure. Thus, the tensile force of the pre-stress tendon should be checked for structural health monitoring of pre-stressed concrete bridges. In this study, a machine learning-based tensile force estimation method for a pre-stressed concrete girder is proposed using an embedded elasto-magnetic sensor and machine learning method. The feedforward neural network and radial basis function network were applied to estimate the tensile force of the pre-stress tendon using the area ratio of the magnetic hysteresis curve measured by the embedded elasto-magnetic sensor. The feedforward neural network and radial basis function network were trained using 213 datasets obtained in laboratory experiments, and trained feedforward neural network and radial basis function network were applied to a 50-m real-scale pre-stressed concrete girder test for estimating tensile force. Nine embedded elasto-magnetic sensors were installed on the sheath, and the magnetic hysteresis curves of the pre-stress tendons were measured during tensioning. The area ratio was extracted and inputted to the trained feedforward neural network and radial basis function network to estimate the tensile force. The estimated tensile force was compared with the reference tensile force measured by the load cell. According to the result, the estimated tensile force can represent the actual tensile force of the pre-stress tendon without calibrating tensile force estimation algorithms at the site. In addition, it can measure the actual friction loss by estimating the tensile force at the maximum eccentric part. Based on the results, the proposed method might be a solution for the structural health monitoring of pre-stressed concrete bridges with field applicability.","Tensile force estimation,machine learning,embedded elasto-magnetic sensor,feedforward neural network,radial basis function network",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Engineering,Instruments & Instrumentation",,5.861,"IMPEDANCE,STRAND,BEAMS",STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL,,
20,Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data,26,1,227-237,"Krueger Robert,Beyer Johanna,Jang Won-Dong,Kim Nam Wook,Sokolov Artem,Sorger Peter K.,Pfister Hanspeter","Krueger R,Beyer J,Jang WD,Kim NW,Sokolov A,Sorger PK,Pfister H",Krueger R,10.1109/TVCG.2019.2934547,Harvard University,"Facetto is a scalable visual analytics application that is used to discover single-cell phenotypes in high-dimensional multi-channel microscopy images of human tumors and tissues. Such images represent the cutting edge of digital histology and promise to revolutionize how diseases such as cancer are studied, diagnosed, and treated. Highly multiplexed tissue images are complex, comprising 10(9) or more pixels, 60-plus channels, and millions of individual cells. This makes manual analysis challenging and error-prone. Existing automated approaches are also inadequate, in large part, because they are unable to effectively exploit the deep knowledge of human tissue biology available to anatomic pathologists. To overcome these challenges, Facetto enables a semi-automated analysis of cell types and states. It integrates unsupervised and supervised learning into the image and feature exploration process and offers tools for analytical provenance. Experts can cluster the data to discover new types of cancer and immune cells and use clustering results to train a convolutional neural network that classifies new cells accordingly. Likewise, the output of classifiers can be clustered to discover aggregate patterns and phenotype subsets. We also introduce a new hierarchical approach to keep track of analysis steps and data subsets created by users; this assists in the identification of cell types. Users can build phenotype trees and interact with the resulting hierarchical structures of both high-dimensional feature and image spaces. We report on use-cases in which domain scientists explore various large-scale fluorescence imaging datasets. We demonstrate how Facetto assists users in steering the clustering and classification process, inspecting analysis results, and gaining new scientific insights into cancer biology.","Clustering,Classification,Visual Analysis,Multiplex Tissue Imaging,Digital Pathology,Cancer Systems Biology",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA",Computer Science,,,"VISUAL,ANALYSIS,ALGORITHM,FRAMEWORK",IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS,https://doi.org/10.1101/722918,
21,The assessment of small bowel motility with attentive deformable neural network,508,,22-32,"Wu Xing,Zhong Mingyu,Guo Yike,Fujita Hamido","Wu X,Zhong MY,Guo YK,Fujita H",Fujita H,10.1016/j.ins.2019.08.059,Ho Chi Minh City University of Technology (HUTECH),"The small bowel is the longest part of the gastrointestinal tract and quick assessment of its motility using Cine-MRI is conducive to the diagnosis of gastroenteric diseases. Because of the complex shape changes that occur frequently in the small bowel, approaches involving human designed features and simple convolutional neural network (CNN) methods fail to achieve satisfactory performance on massive datasets. To meet the challenge of assessing small bowel motility automatically, we propose the integration of deformable convolutional networks into attentive encoder-decoder. With the help of deformable convolution, a tailored CNN can track small bowel segments in different shapes from each MR image of a Cine-MRI sequence. The proposed attentive encoder-decoder performed significantly better than conventional recurrent neural network (RNN) in the assessment of small bowel motility. Experimental results demonstrate that the proposed method not only automatically assesses small bowel motility correctly, but also outperforms state-of-the-art methods. Furthermore, it provides useful information about the physiology of small bowel motility patterns, which can be used in the diagnosis of gastroenteric diseases. (C) 2019 Elsevier Inc. All rights reserved.","Small bowel motility,Cine-MRI,Recursive neural networks,Attentive encoder-decoder,Deformable convolution",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA",Computer Science,,6.524,MRI,INFORMATION SCIENCES,,
22,Prediction of lower limb joint angles and moments during gait using artificial neural networks,58,1,211-225,"Mundt Marion,Thomsen Wolf,Witter Tom,Koeppe Arnd,David Sina,Bamer Franz,Potthast Wolfgang,Markert Bernd","Mundt M,Thomsen W,Witter T,Koeppe A,David S,Bamer F,Potthast W,Markert B",Mundt M,10.1007/s11517-019-02061-3,RWTH Aachen University,"In recent years, gait analysis outside the laboratory attracts more and more attention in clinical applications as well as in life sciences. Wearable sensors such as inertial sensors show high potential in these applications. Unfortunately, they can only measure kinematic motions patterns indirectly and the outcome is currently jeopardized by measurement discrepancies compared with the gold standard of optical motion tracking. The aim of this study was to overcome the limitation of measurement discrepancies and the missing information on kinetic motion parameters using a machine learning application based on artificial neural networks. For this purpose, inertial sensor data-linear acceleration and angular rate-was simulated from a database of optical motion tracking data and used as input for a feedforward and long short-term memory neural network to predict the joint angles and moments of the lower limbs during gait. Both networks achieved mean correlation coefficients higher than 0.80 in the minor motion planes, and correlation coefficients higher than 0.98 in the sagittal plane. These results encourage further applications of artificial intelligence to support gait analysis.","IMU,Inertial sensors,Machine learning,Data simulation,Data augmentation",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"KINEMATICS,MOTION,ACCURACY,WALKING,REPEATABILITY,CALIBRATION,ALGORITHM,CONTACT,SYSTEM,FORCE",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
23,BrainIAK tutorials: User-friendly learning materials for advanced fMRI analysis,16,1,,"Kumar Manoj,Ellis Cameron T.,Lu Qihong,Zhang Hejia,Capota Mihai,Willke Theodore L.,Ramadge Peter J.,Turk-Browne Nicholas B.,Norman Kenneth A.","Kumar M,Ellis CT,Lu QH,Zhang HJ,Capota MH,Willke TL,Ramadge PJ,Turk-Browne NB,Norman KA",Kumar M,10.1371/journal.pcbi.1007549,Princeton University,"Advanced brain imaging analysis methods, including multivariate pattern analysis (MVPA), functional connectivity, and functional alignment, have become powerful tools in cognitive neuroscience over the past decade. These tools are implemented in custom code and separate packages, often requiring different software and language proficiencies. Although usable by expert researchers, novice users face a steep learning curve. These difficulties stem from the use of new programming languages (e.g., Python), learning how to apply machine-learning methods to high-dimensional fMRI data, and minimal documentation and training materials. Furthermore, most standard fMRI analysis packages (e.g., AFNI, FSL, SPM) focus on preprocessing and univariate analyses, leaving a gap in how to integrate with advanced tools. To address these needs, we developed BrainIAK (brainiak.org), an open-source Python software package that seamlessly integrates several cutting-edge, computationally efficient techniques with other Python packages (e.g., , ) for file handling, visualization, and machine learning. To disseminate these powerful tools, we developed user-friendly tutorials (in Jupyter format; ) for learning BrainIAK and advanced fMRI analysis in Python more generally. These materials cover techniques including: MVPA (pattern classification and representational similarity analysis); parallelized searchlight analysis; background connectivity; full correlation matrix analysis; inter-subject correlation; inter-subject functional connectivity; shared response modeling; event segmentation using hidden Markov models; and real-time fMRI. For long-running jobs or large memory needs we provide detailed guidance on high-performance computing clusters. These notebooks were successfully tested at multiple sites, including as problem sets for courses at Yale and Princeton universities and at various workshops and hackathons. These materials are freely shared, with the hope that they become part of a pool of open-source software and educational materials for large-scale, reproducible fMRI analysis and accelerated discovery.
Author summary The analysis of brain activity, as measured using functional magnetic resonance imaging (fMRI), has led to significant discoveries about how the brain processes information and how this is affected by disease. However, exhaustive multivariate analyses in space and time, run across a large number of subjects, can be complex and computationally intensive, creating a high barrier for entry into this field. Furthermore, the materials available to learn these methods do not encompass all the methods used, work is often published with no publicly available code, and the analyses are often difficult to run on large datasets without cluster computing. We have created interactive software tutorials that make it easy to understand and execute advanced analyses on fMRI data using the BrainIAK package-an open-source package built in Python. We have released these tutorials freely to the public and have significantly reduced computational roadblocks for users by making it possible to run the tutorials with a web browser and internet connection. We hope that this facilitated access and the usability of the underlying code-a compendium for how to program and optimize the latest fMRI analyses-will accelerate training, reproducibility, and discovery in cognitive neuroscience.","REPRESENTATIONS,INFORMATION,CORTEX",Article,"PUBLIC LIBRARY SCIENCE, 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA","Biochemistry & Molecular Biology,Mathematical & Computational Biology",,5.379,"REPRESENTATIONS,INFORMATION,CORTEX",PLOS COMPUTATIONAL BIOLOGY,https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1007549&type=printable,
24,In-depth serum virome analysis in patients with acute liver failure with indeterminate etiology,165,1,127-135,"Ren Yi,Xu Yanjuan,Lee William M.,Di Bisceglie Adrian M.,Fan Xiaofeng","Ren Y,Xu YJ,Lee WM,Di Bisceglie AM,Fan XF",Di Bisceglie AM; Fan XF,10.1007/s00705-019-04466-9,Saint Louis University,"In clinical virome research, whole-genome/transcriptome amplification is required when starting material is limited. An improved method, named ""template-dependent multiple displacement amplification"" (tdMDA), has recently been developed in our lab (Wang et al. in BioTechniques 63:21-25. https://doi.org/10.2144/000114566, 2017). In combination with Illumina sequencing and bioinformatics pipelines, its application in virome sequencing was explored using a serum sample from a patient with chronic hepatitis C virus (HCV) infection. In comparison to an amplification-free procedure, virome sequencing via tdMDA showed a 9.47-fold enrichment for HCV-mapped reads and, accordingly, an increase in HCV genome coverage from 28.5% to 70.1%. Eight serum samples from acute patients liver failure (ALF) with or without known etiology were then used for virome sequencing with an average depth at 94,913x. Both similarity-based (mapping, NCBI BLASTn, BLASTp, and profile hidden Markov model analysis) and similarity-independent methods (machine-learning algorithms) identified viruses from multiple families, including Herpesviridae, Picornaviridae, Myoviridae, and Anelloviridae. However, their commensal nature and cross-detection ruled out an etiological interpretation. Together with a lack of detection of novel viruses in a comprehensive analysis at a resolution of single reads, these data indicate that viral agents might be rare in ALF cases with indeterminate etiology.","DATABASE,DISCOVERY,STRAINS,GENOMES",Article,"SPRINGER WIEN, SACHSENPLATZ 4-6, PO BOX 89, A-1201 WIEN, AUSTRIA",Virology,,2.466,"DATABASE,DISCOVERY,STRAINS,GENOMES",ARCHIVES OF VIROLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6957702,
25,Linking pyrometry to porosity in additively manufactured metals,31,,,"Mitchell John A.,Ivanoff Thomas A.,Dagel Daryl,Madison Jonathan D.,Jared Bradley","Mitchell JA,Ivanoff TA,Dagel D,Madison JD,Jared B",Mitchell JA,10.1016/j.addma.2019.100946,United States Department of Energy (DOE),"Porosity in additively manufactured metals can reduce material strength and is generally undesirable. Although studies have shown relationships between process parameters and porosity, monitoring strategies for defect detection and pore formation are still needed. In this paper, instantaneous anomalous conditions are detected insitu via pyrometry during laser powder bed fusion additive manufacturing and correlated with voids observed using post-build micro-computed tomography. Large two-color pyrometry data sets were used to estimate instantaneous temperatures, melt pool orientations and aspect ratios. Machine learning algorithms were then applied to processed pyrometry data to detect outlier images and conditions. It is shown that melt pool outliers are good predictors of voids observed post-build. With this approach, real time process monitoring can be incorporated into systems to detect defect and void formation. Alternatively, using the methodology presented here, pyrometry data can be post processed for porosity assessment.","Laser powder bed fusion,Insitu monitoring,Pyrometry,Porosity,Data analytics",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science",,,"X-RAY,TOMOGRAPHY,IN-SITU,KEYHOLE,PREDICTION,PRESSURE,FATIGUE,CRACK",ADDITIVE MANUFACTURING,https://www.osti.gov/biblio/1595013,
26,Deep Retinal Image Segmentation With Regularization Under Geometric Priors,29,,2552-2567,"Cherukuri Venkateswararao,Kumar Vijay B. G.,Bala Raja,Monga Vishal","Cherukuri V,Kumar BGV,Bala R,Monga V",Cherukuri V,10.1109/TIP.2019.2946078,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Vessel segmentation of retinal images is a key diagnostic capability in ophthalmology. This problem faces several challenges including low contrast, variable vessel size and thickness, and presence of interfering pathology such as micro-aneurysms and hemorrhages. Early approaches addressing this problem employed hand-crafted filters to capture vessel structures, accompanied by morphological post-processing. More recently, deep learning techniques have been employed with significantly enhanced segmentation accuracy. We propose a novel domain enriched deep network that consists of two components: 1) a representation network that learns geometric features specific to retinal images, and 2) a custom designed computationally efficient residual task network that utilizes the features obtained from the representation layer to perform pixel-level segmentation. The representation and task networks are jointly learned for any given training set. To obtain physically meaningful and practically effective representation filters, we propose two new constraints that are inspired by expected prior structure on these filters: 1) orientation constraint that promotes geometric diversity of curvilinear features, and 2) a data adaptive noise regularizer that penalizes false positives. Multi-scale extensions are developed to enable accurate detection of thin vessels. Experiments performed on three challenging benchmark databases under a variety of training scenarios show that the proposed prior guided deep network outperforms state of the art alternatives as measured by common evaluation metrics, while being more economical in network size and inference time.","Image segmentation,Task analysis,Retinal vessels,Deep learning,Training,Feature extraction,Retinal images,deep learning,priors",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,"BLOOD-VESSEL,SEGMENTATION,FUNDUS,IMAGES,MATCHED-FILTER,MODEL,DELINEATION,EXTRACTION,SELECTION",IEEE TRANSACTIONS ON IMAGE PROCESSING,http://arxiv.org/pdf/1909.09175,
27,High-Order Feature Learning for Multi-Atlas Based Label Fusion: Application to Brain Segmentation With MRI,29,,2702-2713,"Sun Liang,Shao Wei,Wang Mingliang,Zhang Daoqiang,Liu Mingxia","Sun L,Shao W,Wang ML,Zhang DQ,Liu MX",Zhang DQ; Liu MX,10.1109/TIP.2019.2952079,Nanjing University of Aeronautics & Astronautics,"Multi-atlas based segmentation methods have shown their effectiveness in brain regions-of-interesting (ROIs) segmentation, by propagating labels from multiple atlases to a target image based on the similarity between patches in the target image and multiple atlas images. Most of the existing multi-atlas based methods use image intensity features to calculate the similarity between a pair of image patches for label fusion. In particular, using only low-level image intensity features cannot adequately characterize the complex appearance patterns (e.g., the high-order relationship between voxels within a patch) of brain magnetic resonance (MR) images. To address this issue, this paper develops a high-order feature learning framework for multi-atlas based label fusion, where high-order features of image patches are extracted and fused for segmenting ROIs of structural brain MR images. Specifically, an unsupervised feature learning method (i.e., means-covariances restricted Boltzmann machine, mcRBM) is employed to learn high-order features (i.e., mean and covariance features) of patches in brain MR images. Then, a group-fused sparsity dictionary learning method is proposed to jointly calculate the voting weights for label fusion, based on the learned high-order and the original image intensity features. The proposed method is compared with several state-of-the-art label fusion methods on ADNI, NIREP and LONI-LPBA40 datasets. The Dice ratio achieved by our method is 88.30, 88.83, 79.54 and 81.02 on left and right hippocampus on the ADNI, NIREP and LONI-LPBA40 datasets, respectively, while the best Dice ratio yielded by the other methods are 86.51, 87.39, 78.48 and 79.65 on three datasets, respectively.","High-order features,multi-atlas,ROI segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,"IMAGE,REGISTRATION,HIPPOCAMPUS,MODEL,REPRESENTATION,PREDICTION,ALGORITHM,SELECTION,SYSTEM,TRUTH",IEEE TRANSACTIONS ON IMAGE PROCESSING,,
28,Unsupervised Deep Contrast Enhancement With Power Constraint for OLED Displays,29,,2834-2844,"Shin Yong-Goo,Park Seung,Yeo Yoon-Jae,Yoo Min-Jae,Ko Sung-Jea","Shin YG,Park S,Yeo YJ,Yoo MJ,Ko SJ",Ko SJ,10.1109/TIP.2019.2953352,Korea University,"Various power-constrained contrast enhancement (PCCE) techniques have been applied to an organic light emitting diode (OLED) display for reducing the power demands of the display while preserving the image quality. In this paper, we propose a new deep learning-based PCCE scheme that constrains the power consumption of the OLED displays while enhancing the contrast of the displayed image. In the proposed method, the power consumption is constrained by simply reducing the brightness a certain ratio, whereas the perceived visual quality is preserved as much as possible by enhancing the contrast of the image using a convolutional neural network (CNN). Furthermore, our CNN can learn the PCCE technique without a reference image by unsupervised learning. Experimental results show that the proposed method is superior to conventional ones in terms of image quality assessment metrics such as a visual saliency-induced index (VSI) and a measure of enhancement (EME).","Convolutional neural network,deep learning,energy efficiency,image enhancement",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,"IMAGE,QUALITY,ASSESSMENT",IEEE TRANSACTIONS ON IMAGE PROCESSING,http://arxiv.org/pdf/1905.05916,
29,Bi-Directional Dermoscopic Feature Learning and Multi-Scale Consistent Decision Fusion for Skin Lesion Segmentation,29,,3039-3051,"Wang Xiaohong,Jiang Xudong,Ding Henghui,Liu Jun","Wang XH,Jiang XD,Ding HH,Liu J",Jiang XD,10.1109/TIP.2019.2955297,Nanyang Technological University & National Institute of Education (NIE) Singapore,"Accurate segmentation of skin lesion from dermoscopic images is a crucial part of computer-aided diagnosis of melanoma. It is challenging due to the fact that dermoscopic images from different patients have non-negligible lesion variation, which causes difficulties in anatomical structure learning and consistent skin lesion delineation. In this paper, we propose a novel bi-directional dermoscopic feature learning (biDFL) framework to model the complex correlation between skin lesions and their informative context. By controlling feature information passing through two complementary directions, a substantially rich and discriminative feature representation is achieved. Specifically, we place biDFL module on the top of a CNN network to enhance high-level parsing performance. Furthermore, we propose a multi-scale consistent decision fusion (mCDF) that is capable of selectively focusing on the informative decisions generated from multiple classification layers. By analysis of the consistency of the decision at each position, mCDF automatically adjusts the reliability of decisions and thus allows a more insightful skin lesion delineation. The comprehensive experimental results show the effectiveness of the proposed method on skin lesion segmentation, achieving state-of-the-art performance consistently on two publicly available dermoscopic image databases.","Lesions,Skin,Image segmentation,Melanoma,Bidirectional control,Reliability,Feature extraction,Skin lesion segmentation,dermoscopic images,bi-directional dermoscopic feature learning,multi-scale consistent decision fusion",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,"IMAGE,SEGMENTATION,NETWORKS,CLASSIFICATION",IEEE TRANSACTIONS ON IMAGE PROCESSING,http://arxiv.org/pdf/2002.08694,
30,Multistage GAN for Fabric Defect Detection,29,,3388-3400,"Liu Juhua,Wang Chaoyue,Su Hai,Du Bo,Tao Dacheng","Liu JH,Wang CY,Su H,Du B,Tao DC",Du B,10.1109/TIP.2019.2959741,Wuhan University,"Fabric defect detection is an intriguing but challenging topic. Many methods have been proposed for fabric defect detection, but these methods are still suboptimal due to the complex diversity of both fabric textures and defects. In this paper, we propose a generative adversarial network (GAN)-based framework for fabric defect detection. Considering existing challenges in real-world applications, the proposed fabric defect detection system is capable of learning existing fabric defect samples and automatically adapting to different fabric textures during different application periods. Specifically, we customize a deep semantic segmentation network for fabric defect detection that can detect different defect types. Furthermore, we attempted to train a multistage GAN to synthesize reasonable defects in new defect-free samples. First, a texture-conditioned GAN is trained to explore the conditional distribution of defects given different texture backgrounds. Given a novel fabric, we aim to generate reasonable defective patches. Then, a GAN-based fusion network fuses the generated defects to specific locations. Finally, the well-trained multistage GAN continuously updates the existing fabric defect datasets and contributes to the fine-tuning of the semantic segmentation network to better detect defects under different conditions. Comprehensive experiments on various representative fabric samples are conducted to verify the detection performance of our proposed method.","Fabric defect detection,deep learning,semantic segmentation,generative adversarial network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,NETWORKS,IEEE TRANSACTIONS ON IMAGE PROCESSING,,
31,"A Recurrent Neural Network for Particle Tracking in Microscopy Images Using Future Information, Track Hypotheses, and Multiple Detections",29,,3681-3694,"Spilger Roman,Imle Andrea,Lee Ji-Young,Mueller Barbara,Fackler Oliver T.,Bartenschlager Ralf,Rohr Karl","Spilger R,Imle A,Lee JY,Muller B,Fackler OT,Bartenschlager R,Rohr K",Spilger R,10.1109/TIP.2020.2964515,Helmholtz Association,"Automatic tracking of particles in time-lapse fluorescence microscopy images is essential for quantifying the dynamic behavior of subcellular structures and virus structures. We introduce a novel particle tracking approach based on a deep recurrent neural network architecture that exploits past and future information in both forward and backward direction. Assignment probabilities are determined jointly across multiple detections, and the probability of missing detections is computed. In addition, existence probabilities are determined by the network to handle track initiation and termination. For correspondence finding, track hypotheses are propagated to future time points so that information at later time points can be used to resolve ambiguities. A handcrafted similarity measure and handcrafted motion features are not necessary. Manually labeled data is not required for network training. We evaluated the performance of our approach using image data of the Particle Tracking Challenge as well as real fluorescence microscopy image sequences of virus structures. It turned out that the proposed approach outperforms previous methods.","Biomedical imaging,microscopy images,particle tracking,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,"CELL,ENDOCYTOSIS,ALGORITHM,PLATFORM,DENSE",IEEE TRANSACTIONS ON IMAGE PROCESSING,,
32,Analysis and modelling of dissimilar materials welding based on K-nearest neighbour predictor,21,,108-112,"Sathish T.,Rangarajan S.,Muthuram A.,Kumar R. Praveen","Sathish T,Rangarajan S,Muthuram A,Kumar RP",Sathish T,10.1016/j.matpr.2019.05.371,"SMR East Coast Coll Engn & Technol, Thanjavur, Tamil Nadu, India.","In dissimilar materials the welded joints are apply to the Automotive and ship industries. The welded joints quality is better than the essential of suitable weld seam geometry. No previous technique produce the accurate prediction geometry of laser weld seam. The initial data generation Taguchi experiments are conducted on laser welding of two different materials. One is low carbon steel (Q235) and other is stainless steel (SUS301L-HT). The K-Nearest Neighbour predictor is modelled for the laser welding process. This method is providing the following function such as better prediction, accuracy and reduced computation time. (C) 2019 Elsevier Ltd. All rights reserved.","Dissimilar materials welding,Weld seam geometry prediction,K-nearest neighbour,Taguchi experiment,Machine learning",Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,,"NEURAL-NETWORK,PARAMETER,OPTIMIZATION",MATERIALS TODAY-PROCEEDINGS,,
33,Optimal prediction of process parameters by GWO-KNN in stirring-squeeze casting of AA2219 reinforced metal matrix composites,21,,1000-1007,"Adithiyaa T.,Chandramohan D.,Sathish T.","Adithiyaa T,Chandramohan D,Sathish T",Adithiyaa T,10.1016/j.matpr.2019.10.051,St. Peter's Institute of Higher Education & Research,"Rapid globalization and demand for the advanced material, hybrid materials are possessing an up marketed strategy in the field of material research. Due to the demand for lightweight and strong nature of materials, aluminium is considered as largely utilized material for manufacturing components in industrial and other manufacturing sectors. However, aluminium materials are being researched through the decades for improvising the mechanical properties. Therefore, hybrid matrix composites are introduced to improve the mechanical properties by the addition of reinforcements. One of the recent advancements in hybrid metal composites is the introduction of nanoparticles in the composition mixture. In this research work, an aluminium hybrid metal matrix composite is prepared by the nano reinforcement particles. Aluminium is considered to be an efficient element for manufacturing and numerous level of hybridization is carried out in the metal processing. In this current research work, aluminium alloy 2219 is hybridized with nanoparticles of Titanium Carbide, Aluminium Oxide and Silicon Nitride with the proportion of 94% of the primary material with 6% of reinforcement material. The reinforcements are fabricated by the conventional processing of advanced method of casting process namely stirring-squeeze casting process for manufacturing the proposed reinforced material. The advantage of this squeeze casting process, it can limit the defects than conventional casting process. The fabrication process develops eight sets of cylindrical specimens of dimension 50 x 150 mm for testing under varied melt and die temperatures which are maintained at 800 degrees C and 400 degrees C and squeeze pressure of 100 Mpa during each level of fabrication. Mechanical testing is carried out after the fabrication process and tested the properties of prepared specimens under loading conditions. Tensile testing and hardness of the material are tested on universal testing machine and Brinell hardness with intender ball of 5 mm diameter under 250 kg loading condition. The statistical method of analysis is one of the easiest way analysis the error rate of the result obtained in the experimentation through machine learning process. Therefore, this research develops a statistical analysis method for optimizing the process parameters for better improvement in mechanical properties. The K-nearest neighbour (KNN) and grey wolf optimization (GWO) are proposed for optimizing the process parameters of stirring-squeeze casting process. Conclusively, the result concludes with a comparative study of experimental and predicted outcomes. From the result of comparison, the proposed composition of material has highest level of mechanical properties for manufacturing components in a real-time scenario respectively. (C) 2019 Elsevier Ltd. All rights reserved.","Hybrid metal matrix,Aluminium alloy 2219,Titanium carbide,Aluminium oxide,Silicon nitride,Stirring-squeeze casting process,Universal testing machine,Brinell hardness and impact energy,K-nearest neighbour (KNN),Grey wolf optimization (GWO)",Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,,"OPTIMIZATION,DIESEL",MATERIALS TODAY-PROCEEDINGS,,
34,Dielectric or plasmonic Mie object at air-liquid interface: The transferred and the traveling momenta of photon,29,1,,"Mahdy M. R. C.,Rivy Hamim Mahmud,Jony Ziaur Rahman,Alam Nabila Binte,Masud Nabila,Al Quaderi Golam Dastegir,Moosa Ibraheem Muhammad,Rahman Chowdhury Mofizur,Rahman M. Sohel","Mahdy MRC,Rivy HM,Jony ZR,Alam NB,Masud N,Al Quaderi GD,Moosa IM,Rahman CM,Rahman MS",Mahdy MRC,10.1088/1674-1056/ab5efa,North South University (NSU),"Considering the inhomogeneous or heterogeneous background, we have demonstrated that if the background and the half-immersed object are both non-absorbing, the transferred photon momentum to the pulled object can be considered as the one of Minkowski exactly at the interface. In contrast, the presence of loss inside matter, either in the half-immersed object or in the background, causes optical pushing of the object. Our analysis suggests that for half-immersed plasmonic or lossy dielectric, the transferred momentum of photon can mathematically be modeled as the type of Minkowski and also of Abraham. However, according to a final critical analysis, the idea of Abraham momentum transfer has been rejected. Hence, an obvious question arises: whence the Abraham momentum? It is demonstrated that though the transferred momentum to a half-immersed Mie object (lossy or lossless) can better be considered as the Minkowski momentum, Lorentz force analysis suggests that the momentum of a photon traveling through the continuous background, however, can be modeled as the type of Abraham. Finally, as an interesting sidewalk, a machine learning based system has been developed to predict the time-averaged force within a very short time avoiding time-consuming full wave simulation.","Abraham-Minkowski controversy,dielectric interface,machine learning,optical force laws,optical pulling force,optical tractor beams",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,1.262,"RADIATION,PRESSURE,LIGHT,REVERSAL,FORCES,WAVE",CHINESE PHYSICS B,,
35,Automatic Diagnosis of Familial Exudative Vitreoretinopathy Using a Fusion Neural Network for Wide-Angle Retinal Images,8,,162-173,"Ye Yu,Mao Jianbo,Liu Lei,Zhang Shulin,Shen Lijun,Sun Mingzhai","Ye Y,Mao JB,Liu L,Zhang SL,Shen LJ,Sun MZ",Sun MZ,10.1109/ACCESS.2019.2961418,Chinese Academy of Sciences,"Familial exudative vitreoretinopathy (FEVR) is a hereditary disorder that can damage the retina. This retinal damage can lead to vision loss and even blindness in the late stages. Thus, early diagnosis and prevention of the disease's progression are critical. The purpose of this study was to develop an automated diagnosis system for FEVR based on combining deep learning and domain knowledge. A transfer learning scheme was designed to train a deep convolutional neural network (DCNN) to provide segmentation of the retinal vessels. Based on this vessel segmentation and prior clinical knowledge, the vascular characteristics, including the retinal avascular area, vessel angle, fractal dimension, branching and density of blood vessels, were automatically evaluated. Finally, the diagnosis of FEVR was achieved by a feature fusion neural network. Our method was evaluated on 300 images with 168 healthy and 132 FEVR images. By combining deep features and handcrafted features (extracted vascular characteristics), the proposed method achieved an average F1-score of 0.95, with excellent accuracy (94.340025;) and sensitivity (91.430025;); the quadratic weighted $\kappa $ was 0.88 for the diagnosis of FEVR. We demonstrated the effectiveness and robustness of the proposed method using five-fold cross-validation. The proposed automatic diagnosis system can assist doctors for better judgment and make sense of early diagnosis and prevention of the disease's progression.","FEVR,wide-angle retinal images,deep learning,vascular characteristics,fusion",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://doi.org/10.1109/access.2019.2961418,
36,Dual Intercommunication Network: Enabling Interhemispheric Communications in Hemisphere-Inspired ANNs,8,,526-534,Wu Yanze,Wu YZ,Wu YZ,10.1109/ACCESS.2019.2961933,Fudan University,"The human brain has been a main source of inspiration for designing deep learning models. Recently, inspired by the specialized functions of two cerebral hemispheres in processing low and high spatial frequency information, some dual-path neural networks with global and local branches have been proposed to deal with both coarse- and fine-grained visual tasks simultaneously. However, in existing works, the interhemispheric communication mechanism, which is responded by the corpus callosum, the largest white matter structure in the human brain that connecting the left and right cerebral hemispheres, is still not fully explored and exploited. This paper aims to explore how the corpus callosum can inspire us to enable transfer and integration of information between global and local branches in hemisphere-inspired artificial neural networks, such that one branch can leverage the other's learned knowledge and benefit each other. To this end, we propose a gated intercommunication unit to selectively transfer useful knowledge between the two branches via attention mechanisms to alleviate the negative transfer. Experiments on sb-MNIST and two pedestrian attribute datasets show that the proposed method outperforms the compared ones in most cases.","Attribute recognition,computer vision,deep learning,multi-task learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SPATIAL-FREQUENCIES,RECOGNITION,ATTRIBUTE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08941050.pdf,
37,Information Theoretic Feature Transformation Learning for Brain Interfaces,67,1,69-78,"Ozdenizci Ozan,Erdogmus Deniz","Ozdenizci O,Erdogmus D",Ozdenizci O,10.1109/TBME.2019.2908099,Northeastern University,"Objective: A variety of pattern analysis techniques for model training in brain interfaces exploit neural feature dimensionality reduction based on feature ranking and selection heuristics. In the light of broad evidence demonstrating the potential sub-optimality of ranking-based feature selection by any criterion, we propose to extend this focus with an information theoretic learning-driven feature transformation concept. Methods: We present a maximum mutual information linear transformation and a nonlinear transformation framework derived by a general definition of the feature transformation learning problem. Empirical assessments are performed based on electroencephalographic data recorded during a four class motor imagery brain-computer interface (BCI) task. Exploiting the state-of-the-art methods for initial feature vector construction, we compare the proposed approaches with conventional feature selection-based dimensionality reduction techniques, which are widely used in brain interfaces. Furthermore, for the multi-class problem, we present and exploit a hierarchical graphical model-based BCI decoding system. Results: Both binary and multi-class decoding analyses demonstrate significantly better performances with the proposed methods. Conclusion: Information theoretic feature transformations are capable of tackling potential confounders of conventional approaches in various settings. Significance: We argue that this concept provides significant insights to extend the focus on feature selection heuristics to a broader definition of feature transformation learning in brain interfaces.","Feature extraction,Mutual information,Random variables,Brain-computer interfaces,Stochastic processes,Training,Decoding,Feature learning,mutual information,hierarchical decoding,brain-computer interface,electroencephalogram",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"SINGLE-TRIAL,EEG,MUTUAL,INFORMATION,FEATURE-EXTRACTION,FEATURE-SELECTION,COMPUTER,INTERFACES,COMMUNICATION,NETWORKS,PATTERNS",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,http://arxiv.org/pdf/1903.12235,
38,Hearables: Automatic Overnight Sleep Monitoring With Standardized In-Ear EEG Sensor,67,1,203-212,"Nakamura Takashi,Alqurashi Yousef D.,Morrell Mary J.,Mandic Danilo P.","Nakamura T,Alqurashi YD,Morrell MJ,Mandic DP",Nakamura T,10.1109/TBME.2019.2911423,Imperial College London,"Objective: Advances in sensor miniaturization and computational power have served as enabling technologies for monitoring human physiological conditions in real-world scenarios. Sleep disruption may impact neural function, and can be a symptom of both physical and mental disorders. This study proposes wearable in-ear electroencephalography (ear-EEG) for overnight sleep monitoring as a 24/7 continuous and unobtrusive technology for sleep quality assessment in the community. Methods: A total of 22 healthy participants took part in overnight sleep monitoring with simultaneous ear-EEG and conventional full polysomnography recordings. The ear-EEG data were analyzed in the both structural complexity and spectral domains. The extracted features were used for automatic sleep stage prediction through supervized machine learning, whereby the PSG data were manually scored by a sleep clinician. Results: The agreement between automatic sleep stage prediction based on ear-EEG from a single in-ear sensor and the hypnogram based on the full PSG was 74.1% in the accuracy over five sleep stage classification. This is supported by a substantial agreement in the kappa metric (0.61). Conclusion: The in-ear sensor is feasible for monitoring overnight sleep outside the sleep laboratory and also mitigates technical difficulties associated with PSG. It, therefore, represents a 24/7 continuously wearable alternative to conventional cumbersome and expensive sleep monitoring. Significance: The ""standardized"" one-size-fits-all viscoelastic in-ear sensor is a next generation solution to monitor sleep-this technology promises to be a viable method for readily wearable sleep monitoring in the community, a key to affordable healthcare and future eHealth.","Sleep,Monitoring,Biomedical monitoring,Electroencephalography,Ear,Sensors,Standards,Automatic sleep staging,ear-EEG,electroencephalography (EEG),structural complexity analysis,wearable EEG",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"AMERICAN,ACADEMY,ACTIGRAPHY,COMPLEX,CLASSIFICATION,VARIABILITY,VALIDATION,DISORDERS,MEDICINE,ENTROPY,NIGHTS",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,http://spiral.imperial.ac.uk/bitstream/10044/1/70093/6/final_version.pdf,
39,Image Quality Improvement of Hand-Held Ultrasound Devices With a Two-Stage Generative Adversarial Network,67,1,298-311,"Zhou Zixia,Wang Yuanyuan,Guo Yi,Qi Yanxing,Yu Jinhua","Zhou ZX,Wang YY,Guo Y,Qi YX,Yu JH",Wang YY,10.1109/TBME.2019.2912986,Fudan University,"As a widely used imaging modality in the medical field, ultrasound has been applied in community medicine, rural medicine, and even telemedicine in recent years. Therefore, the development of portable ultrasound devices has become a popular research topic. However, the limited size of portable ultrasound devices usually degrades the imaging quality, which reduces the diagnostic reliability. To overcome hardware limitations and improve the image quality of portable ultrasound devices, we propose a novel generative adversarial network (GAN) model to achieve mapping between low-quality ultrasound images and corresponding high-quality images. In contrast to the traditional GAN method, our two-stage GAN that cascades a U-Net network prior to the generator as a front end is built to reconstruct the tissue structure, details, and speckle of the reconstructed image. In the training process, an ultrasound plane-wave imaging (PWI) data-based transfer learning method is introduced to facilitate convergence and to eliminate the influence of deformation caused by respiratory activities during data pair acquisition. A gradual tuning strategy is adopted to obtain better results by the PWI transfer learning process. In addition, a comprehensive loss function is presented to combine texture, structure, and perceptual features. Experiments are conducted using simulated, phantom, and clinical data. Our proposed method is compared to four other algorithms, including traditional gray-level-based methods and learning-based methods. The results confirm that the proposed approach obtains the optimum solution for improving quality and offering useful diagnostic information for portable ultrasound images. This technology is of great significance for providing universal medical care.","Ultrasonic imaging,Image reconstruction,Gallium nitride,Training,Image quality,Speckle,Generative adversarial networks,Portable ultrasound device,generative adversarial networks,image quality improvement,plane-wave imaging,global healthcare",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"MUTUAL,INFORMATION,CARE,ULTRASOUND,REGISTRATION,POINT",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
40,Automatic Sleep Staging Employing Convolutional Neural Networks and Cortical Connectivity Images,31,1,113-123,"Chriskos Panteleimon,Frantzidis Christos A.,Gkivogkli Polyxeni T.,Bamidis Panagiotis D.,Kourtidou-Papadeli Chrysoula","Chriskos P,Frantzidis CA,Gkivogkli PT,Bamidis PD,Kourtidou-Papadeli C",Chriskos P,10.1109/TNNLS.2019.2899781,Aristotle University of Thessaloniki,"Understanding of the neuroscientific sleep mechanisms is associated with mental/cognitive and physical well-being and pathological conditions. A prerequisite for further analysis is the identification of the sleep macroarchitecture through manual sleep staging. Several computer-based approaches have been proposed to extract time and/or frequency-domain features with accuracy ranging from 80% to 95% compared with the golden standard of manual staging. However, their acceptability by the medical community is still suboptimal. Recently, utilizing deep learning methodologies increased the research interest in computer-assisted recognition of sleep stages. Aiming to enhance the arsenal of automatic sleep staging, we propose a novel classification framework based on convolutional neural networks. These receive as input synchronizations features derived from cortical interactions within various electroencephalographic rhythms (delta, theta, alpha, and beta) for specific cortical regions which are critical for the sleep deepening. These functional connectivity metrics are then processed as multidimensional images. We also propose to augment the small portion of sleep onset (N1 stage) through the Synthetic Minority Oversampling Technique in order to deal with the great difference in its duration when compared with the remaining sleep stages. Our results (99.85%) indicate the flexibility of deep learning techniques to learn sleep-related neurophysiological patterns.","Sleep,Feature extraction,Electroencephalography,Biomedical imaging,Convolutional neural networks,Electrooculography,Automatic sleep staging,convolutional neural networks (CNNs),default mode network (DMN),functional connectivity features,minority class oversampling technique",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.746,"DEFAULT,MODE,NETWORK,FUNCTIONAL,CONNECTIVITY,BRAIN,EEG,SYSTEM,DYNAMICS,ENTROPY,SIGNALS,MEG",IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,,
41,Leveraging Coupled Interaction for Multimodal Alzheimer's Disease Diagnosis,31,1,186-200,"Shi Yinghuan,Suk Heung-Il,Gao Yang,Lee Seong-Whan,Shen Dinggang","Shi YH,Suk HI,Gao Y,Lee SW,Shen DG",Gao Y,10.1109/TNNLS.2019.2900077,Nanjing University,"As the population becomes older worldwide, accurate computer-aided diagnosis for Alzheimer's disease (AD) in the early stage has been regarded as a crucial step for neurodegeneration care in recent years. Since it extracts the low-level features from the neuroimaging data, previous methods regarded this computer-aided diagnosis as a classification problem that ignored latent featurewise relation. However, it is known that multiple brain regions in the human brain are anatomically and functionally interlinked according to the current neuroscience perspective. Thus, it is reasonable to assume that the extracted features from different brain regions are related to each other to some extent. Also, the complementary information between different neuroimaging modalities could benefit multimodal fusion. To this end, we consider leveraging the coupled interactions in the feature level and modality level for diagnosis in this paper. First, we propose capturing the feature-level coupled interaction using a coupled feature representation. Then, to model the modality-level coupled interaction, we present two novel methods: 1) the coupled boosting (CB) that models the correlation of pairwise coupled-diversity on both inconsistently and incorrectly classified samples between different modalities and 2) the coupled metric ensemble (CME) that learns an informative feature projection from different modalities by integrating the intrarelation and interrelation of training samples. We systematically evaluated our methods with the AD neuroimaging initiative data set. By comparison with the baseline learning-based methods and the state-of-the-art methods that are specially developed for AD/MCI (mild cognitive impairment) diagnosis, our methods achieved the best performance with accuracy of 95.0% and 80.7% (CB), 94.9% and 79.9% (CME) for AD/NC (normal control), and MCI/NC identification, respectively.","Feature extraction,Magnetic resonance imaging,Neuroimaging,Measurement,Kernel,Training,Brain modeling,Computer-aided AD,MCI diagnosis,coupled boosting (CB),coupled feature (CFR) representation,coupled metric ensemble (CME)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.746,"FEATURE,REPRESENTATION,SPARSE,REPRESENTATION,CLASSIFICATION,SEGMENTATION,MARGIN,PREDICTION,REGRESSION,PROGNOSIS,SELECTION,IMAGES",IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,,
42,DeepOrganNet: On-the-Fly Reconstruction and Visualization of 3D / 4D Lung Models from Single-View Projections by Deep Deformation Network,26,1,960-970,"Wang Yifan,Zhong Zichun,Hua Jing","Wang YF,Zhong ZC,Hua J",Zhong ZC,10.1109/TVCG.2019.2934369,Wayne State University,"This paper introduces a deep neural network based method, i.e., DeepOrganNet, to generate and visualize fully high-fidelity 3D / 4D organ geometric models from single-view medical images with complicated background in real time. Traditional 3D / 4D medical image reconstruction requires near hundreds of projections, which cost insufferable computational time and deliver undesirable high imaging / radiation dose to human subjects. Moreover, it always needs further notorious processes to segment or extract the accurate 3D organ models subsequently. The computational time and imaging dose can be reduced by decreasing the number of projections, but the reconstructed image quality is degraded accordingly. To our knowledge, there is no method directly and explicitly reconstructing multiple 3D organ meshes from a single 2D medical grayscale image on the fly. Given single-view 2D medical images, e.g., 3D / 4D-CT projections or X-ray images, our end-to-end DeepOrganNet framework can efficiently and effectively reconstruct 3D / 4D lung models with a variety of geometric shapes by learning the smooth deformation fields from multiple templates based on a trivariate tensor-product deformation technique, leveraging an informative latent descriptor extracted from input 2D images. The proposed method can guarantee to generate high-quality and high-fidelity manifold meshes for 3D / 4D lung models; while, all current deep learning based approaches on the shape reconstruction from a single image cannot. The major contributions of this work are to accurately reconstruct the 3D organ shapes from 2D single-view projection, significantly improve the procedure time to allow on-the-fly visualization, and dramatically reduce the imaging dose for human subjects. Experimental results are evaluated and compared with the traditional reconstruction method and the state-of-the-art in deep learning, by using extensive 3D and 4D examples, including both synthetic phantom and real patient datasets. The efficiency of the proposed method shows that it only needs several milliseconds to generate organ meshes with 10K vertices, which has great potential to be used in real-time image guided radiation therapy (IGRT).","Deep deformation network,organ meshes,3D,4D shapes,2D projections,single-view",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA",Computer Science,,4.368,"BEAM,COMPUTED-TOMOGRAPHY,IMAGE-RECONSTRUCTION,REGISTRATION,REDUCTION",IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS,http://arxiv.org/pdf/1907.09375,
43,Image Reconstruction: From Sparsity to Data-Adaptive Methods and Machine Learning,108,1,86-109,"Ravishankar Saiprasad,Ye Jong Chul,Fessler Jeffrey A.","Ravishankar S,Ye JC,Fessler JA",Ravishankar S,10.1109/JPROC.2019.2936204,Michigan State University,"The field of medical image reconstruction has seen roughly four types of methods. The first type tended to be analytical methods, such as filtered backprojection (FBP) for X-ray computed tomography (CT) and the inverse Fourier transform for magnetic resonance imaging (MRI), based on simple mathematical models for the imaging systems. These methods are typically fast, but have suboptimal properties such as poor resolution-noise tradeoff for CT. A second type is iterative reconstruction methods based on more complete models for the imaging system physics and, where appropriate, models for the sensor statistics. These iterative methods improved image quality by reducing noise and artifacts. The U.S. Food and Drug Administration (FDA)-approved methods among these have been based on relatively simple regularization models. A third type of methods has been designed to accommodate modified data acquisition methods, such as reduced sampling in MRI and CT to reduce scan time or radiation dose. These methods typically involve mathematical image models involving assumptions such as sparsity or low rank. A fourth type of methods replaces mathematically designed models of signals and systems with data-driven or adaptive models inspired by the field of machine learning. This article focuses on the two most recent trends in medical image reconstruction: methods based on sparsity or low-rank models and data-driven methods based on machine learning techniques.","Image reconstruction,Computed tomography,Mathematical model,Magnetic resonance imaging,Machine learning,X-ray imaging,Data models,Compressed sensing (CS),deep learning,dictionary learning (DL),efficient algorithms,image reconstruction,machine learning,magnetic resonance imaging (MRI),multilayer models,nonconvex optimization,positron emission tomography (PET),single-photon emission computed tomography (SPECT),sparse and low-rank models,structured models,transform learning,X-ray computed tomography (CT)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,13.102,"RANK,HANKEL,MATRIX,LOW-DOSE,CT,GENERATIVE,ADVERSARIAL,NETWORK,DEEP,CONVOLUTIONAL,FRAMELETS,PIECEWISE-CONSTANT,IMAGES,ACCELERATED,DYNAMIC,MRI,NEURAL-NETWORK,K-SPACE,SPARSIFYING,TRANSFORMS,CONVERGENCE,GUARANTEES",PROCEEDINGS OF THE IEEE,http://arxiv.org/pdf/1904.02816,
44,3D Shape-Based Body Composition Inference Model Using a Bayesian Network,24,1,205-213,"Lu Yao,Hahn James K.,Zhang Xiaoke","Lu Y,Hahn JK,Zhang XK",Lu Y,10.1109/JBHI.2019.2903190,George Washington University,"Body composition can be assessed in many different ways. High-end medical equipment, such as Dual-energy X-ray Absorptiometry (DXA), Computed Tomography (CT), and Magnetic Resonance Imaging (MRI) offers high-fidelity pixel/voxel-level assessment, but is prohibitive in cost. In the case of DXA and CT, the approach exposes users to ionizing radiation. Whole-body air displacement plethysmography (BOD POD) can accurately estimate body density, but the assessment is limited to the whole-body fat percentage. Optical three-dimensional (3D) scan and reconstruction techniques, such as using depth cameras, have brought new opportunities for improving body composition assessment by intelligently analyzing body shape features. In this paper, we present a novel supervised inference model to predict pixel-level body composition and percentage of body fat using 3D geometry features and body density. First, we use body density to model a fat distribution base prediction. Then, we use a Bayesian network to infer the probability of the base prediction bias with 3D geometry features. Finally, we correct the bias using non-parametric regression. We use DXA assessment as the ground truth in model training and validation. We compare our method, in terms of pixel-level body composition assessment, with the current state-of-the-art prediction models. Our method outperforms those prediction models by 52.69 on average. We also compare our method, in terms of whole-body fat percentage assessment, with the medical-level equipment-BOD POD. Our method outperforms the BOD POD by 23.28.","Fats,Shape,Three-dimensional displays,Bayes methods,Magnetic resonance imaging,Mathematical model,Solid modeling,Body composition inference,Bayesian network,image data mining,supervised learning,medical imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"CORONARY-HEART-DISEASE,VISCERAL,ADIPOSITY,RISK-FACTORS,FAT,OBESITY,ASSOCIATION,CHILDREN,MASS,MEN",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://europepmc.org/articles/pmc6728241?pdf=render,
45,,,,,,,,,,,,,,,,,,,,
46,A primer on radiomics,60,1,32-41,"Murray Jacob M.,Kaissis Georgios,Braren Rickmer,Kleesiek Jens","Murray JM,Kaissis G,Braren R,Kleesiek J",Kleesiek J,10.1007/s00117-019-00617-w,Helmholtz Association,"Clinical issue The reproducible and exhaustive extraction of information from radiological images is a central task in the practice of radiology. Dynamic developments in the fields of artificial intelligence (AI) and machine learning are introducing new methods for this task. Radiomics is one such method and offers new opportunities and challenges for the future of radiology. Methodological innovations Radiomics describes the quantitative evaluation, interpretation, and clinical assessment of imaging markers in radiological data. Components of a radiomics analysis are data acquisition, data preprocessing, data management, segmentation of regions of interest, computation and selection of imaging markers, as well as the development of a radiomics model used for diagnosis and prognosis. This article explains these components and aims at providing an introduction to the field of radiomics while highlighting existing limitations. Materials and methods This article is based on a selective literature search with the PubMed search engine. Assessment Even though radiomics applications have yet to arrive in routine clinical practice, the quantification of radiological data in terms of radiomics is underway and will increase in the future. This holds the potential for lasting change in the discipline of radiology. Through the successful extraction and interpretation of all the information encoded in radiological images the next step in the direction of a more personalized, future-oriented form of medicine can be taken.","Radiogenomics,Artificial intelligence,Personalized medicine,Machine learning,Artificial neural networks",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Radiology, Nuclear Medicine & Medical Imaging",,0.526,"RADIOGENOMICS,CANCER,IMAGES",RADIOLOGE,,
47,Automated Classification of Apoptosis in Phase Contrast Microscopy Using Capsule Network,39,1,1-10,"Mobiny Aryan,Lu Hengyang,Nguyen Hien V.,Roysam Badrinath,Varadarajan Navin","Mobiny A,Lu HY,Nguyen HV,Roysam B,Varadarajan N",Mobiny A,10.1109/TMI.2019.2918181,University of Houston System,"Automatic and accurate classification of apoptosis, or programmed cell death, will facilitate cell biology research. The state-of-the-art approaches in apoptosis classification use deep convolutional neural networks (CNNs). However, these networks are not efficient in encoding the part-whole relationships, thus requiring a large number of training samples to achieve robust generalization. This paper proposes an efficient variant of capsule networks (CapsNets) as an alternative to CNNs. Extensive experimental results demonstrate that the proposed CapsNets achieve competitive performances in target cell apoptosis classification, while significantly outperforming CNNs when the number of training samples is small. To utilize temporal information within microscopy videos, we propose a recurrent CapsNet constructed by stacking a CapsNet and a bi-directional long short-term recurrent structure. Our experiments show that when considering temporal constraints, the recurrent CapsNet achieves 93.8% accuracy and makes significantly more consistent prediction than NNs.","Routing,Task analysis,Training,Microscopy,Face,Feature extraction,Pediatrics,Apoptosis,capsule network,cell classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CYTOTOXICITY,SCREENING,ASSAY,CELL",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
48,Exploiting Epistemic Uncertainty of Anatomy Segmentation for Anomaly Detection in Retinal OCT,39,1,87-98,"Seebock Philipp,Orlando Jose Ignacio,Schlegl Thomas,Waldstein Sebastian M.,Bogunovic Hrvoje,Klimscha Sophie,Langs Georg,Schmidt-Erfurth Ursula","Seebock P,Orlando JI,Schlegl T,Waldstein SM,Bogunovic H,Klimscha S,Langs G,Schmidt-Erfurth U",Seebock P; Langs G,10.1109/TMI.2019.2919951,Medical University of Vienna,"Diagnosis and treatment guidance are aided by detecting relevant biomarkers in medical images. Although supervised deep learning can perform accurate segmentation of pathological areas, it is limited by requiring a priori definitions of these regions, large-scale annotations, and a representative patient cohort in the training set. In contrast, anomaly detection is not limited to specific definitions of pathologies and allows for training on healthy samples without annotation. Anomalous regions can then serve as candidates for biomarker discovery. Knowledge about normal anatomical structure brings implicit information for detecting anomalies. We propose to take advantage of this property using Bayesian deep learning, based on the assumption that epistemic uncertainties will correlate with anatomical deviations from a normal training set. A Bayesian U-Net is trained on a well-defined healthy environment using weak labels of healthy anatomy produced by existing methods. At test time, we capture epistemic uncertainty estimates of our model using Monte Carlo dropout. A novel post-processing technique is then applied to exploit these estimates and transfer their layered appearance to smooth blob-shaped segmentations of the anomalies. We experimentally validated this approach in retinal optical coherence tomography (OCT) images, using weak labels of retinal layers. Our method achieved a Dice index of 0.789 in an independent anomaly test set of age-related macular degeneration (AMD) cases. The resulting segmentations allowed very high accuracy for separating healthy and diseased cases with late wet AMD, dry geographic atrophy (GA), diabetic macular edema (DME) and retinal vein occlusion (RVO). Finally, we qualitatively observed that our approach can also detect other deviations in normal scans such as cut edge artifacts.","Retina,Uncertainty,Diseases,Anomaly detection,Image segmentation,Biomarkers,Training,Weakly supervised learning,anomaly detection,biomarker discovery,optical coherence tomography,epistemic uncertainty",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,CLASSIFICATION,IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1905.12806,
49,A Partially-Learned Algorithm for Joint Photo-acoustic Reconstruction and Segmentation,39,1,129-139,"Boink Yoeri E.,Manohar Srirang,Brune Christoph","Boink YE,Manohar S,Brune C",Boink YE,10.1109/TMI.2019.2922026,"Univ Twente, Dept Appl Math, NL-7500 Enschede, Netherlands.","In an inhomogeneously illuminated photoacoustic image, important information like vascular geometry is not readily available, when only the initial pressure is reconstructed. To obtain the desired information, algorithms for image segmentation are often applied as a post-processing step. In this article, we propose to jointly acquire the photoacoustic reconstruction and segmentation, by modifying a recently developed partially learned algorithm based on a convolutional neural network. We investigate the stability of the algorithm against changes in initial pressures and photoacoustic system settings. These insights are used to develop an algorithm that is robust to input and system settings. Our approach can easily be applied to other imaging modalities and can be modified to perform other high-level tasks different from segmentation. The method is validated on challenging synthetic and experimental photoacoustic tomography data in limited angle and limited view scenarios. It is computationally less expensive than classical iterative methods and enables higher quality reconstructions and segmentations than the state-of-the-art learned and non-learned methods.","Image reconstruction,Image segmentation,Acoustics,Tomography,Iterative methods,Acoustic measurements,Inverse problems,convolutional neural networks,photoacoustic tomography,segmentation,learned iterative reconstruction",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVEX-OPTIMIZATION,TOMOGRAPHY,NETWORK,IMAGES",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1906.07499,
50,Co-Learning Feature Fusion Maps From PET-CT Images of Lung Cancer,39,1,204-217,"Kumar Ashnil,Fulham Michael,Feng Dagan,Kim Jinman","Kumar A,Fulham M,Feng DG,Kim JM",Kumar A,10.1109/TMI.2019.2923601,University of Sydney,"The analysis of multi-modality positron emission tomography and computed tomography (PET-CT) images for computer-aided diagnosis applications (e.g., detection and segmentation) requires combining the sensitivity of PET to detect abnormal regions with anatomical localization from CT. Current methods for PET-CT image analysis either process the modalities separately or fuse information from each modality based on knowledge about the image analysis task. These methods generally do not consider the spatially varying visual characteristics that encode different information across different modalities, which have different priorities at different locations. For example, a high abnormal PET uptake in the lungs is more meaningful for tumor detection than physiological PET uptake in the heart. Our aim is to improve the fusion of the complementary information in multi-modality PET-CT with a new supervised convolutional neural network (CNN) that learns to fuse complementary information for multi-modality medical image analysis. Our CNN first encodes modality-specific features and then uses them to derive a spatially varying fusion map that quantifies the relative importance of each modality's feature across different spatial locations. These fusion maps are then multiplied with the modality-specific feature maps to obtain a representation of the complementary multi-modality information at different locations, which can then be used for image analysis. We evaluated the ability of our CNN to detect and segment multiple regions (lungs, mediastinum, and tumors) with different fusion requirements using a dataset of PET-CT images of lung cancer. We compared our method to baseline techniques for multi-modality image fusion (fused inputs (FSs), multi-branch (MB) techniques, and multi-channel (MC) techniques) and segmentation. Our findings show that our CNN had a significantly higher foreground detection accuracy (99.29%, p < 0.05) than the fusion baselines (FS: 99.00%, MB: 99.08%, and TC: 98.92%) and a significantly higher Dice score (63.85%) than the recent PET-CT tumor segmentation methods.","Multi-modality imaging,deep learning,fusion learning,PET-CT",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORKS,FDG,PET%2FCT,F-18-FDG,PET%2FCT,CLASSIFICATION,TUMOR,SEGMENTATION,DELINEATION,ENSEMBLE,LYMPHOMA,IMPACT",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1810.02492,
51,Reachability Analysis of Neural Masses and Seizure Control Based on Combination Convolutional Neural Network,30,1,,Ma Zhen,Ma Z,Ma Z,10.1142/S0129065719500230,Binzhou University,"Epileptic seizures arise from synchronous firing of multiple spatially separated neural masses; therefore, many synchrony measures are used for seizure detection and characterization. However, synchrony measures reflect only the overall interaction strength among populations of neurons but cannot reveal the coupling strengths among individual populations, which is more important for seizure control. The concepts of reachability and reachable cluster were proposed to denote the coupling strengths of a set of neural masses. Here, we describe a seizure control method based on coupling strengths using combination convolutional neural network (CCNN) modeling. The neurophysiologically based neural mass model (NMM), which can bridge signal processing and neurophysiology, was used to simulate the proposed controller. Although the adjacency matrix and reachability matrix could not be identified perfectly, the vast majority of adjacency values were identified, reaching 95.64% using the CCNN with an optimal threshold. For cases of discrete and continuous coupling strengths, the proposed controller maintained the average reachable cluster strengths at about 0.1, indicating effective seizure control.","Epilepsy,EEG,neural masses model,combination convolutional neural network",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Computer Science,,5.439,"EEG-BASED,DIAGNOSIS,MATHEMATICAL-MODEL,SYNCHRONIZATION,METHODOLOGY,EPILEPSY,CLASSIFICATION,STIMULATION,TRANSITION,COHERENCE",INTERNATIONAL JOURNAL OF NEURAL SYSTEMS,,
52,Classifiers fusion for improved vessel recognition with application in quantification of generalized arteriolar narrowing,13,1,,"Yin Xiaoxia,Irshad Samra,Zhang Yanchun","Yin XX,Irshad S,Zhang YC",Yin XX,10.1142/S1793545819500214,Guangzhou University,"This paper attempts to estimate diagnostically relevant measure, i.e., Arteriovenous Ratio with an improved retinal vessel classification using feature ranking strategies and multiple classifiers decision-combination scheme. The features exploited for retinal vessel characterization are based on statistical measures of histogram, different filter responses of images and local gradient information. The feature selection process is based on two feature ranking approaches (Pearson Correlation Coefficient technique and Relief-F method) to rank the features followed by use of maximum classification accuracy of three supervised classifiers (k-Nearest Neighbor, Support Vector Machine and Naive Bayes) as a threshold for feature subset selection. Retinal vessels are labeled using the selected feature subset and proposed hybrid classification scheme, i.e., decision fusion of multiple classifiers. The comparative analysis shows an increase in vessel classification accuracy as well as Arteriovenous Ratio calculation performance. The system is tested on three databases, a local dataset of 44 images and two publically available databases, INSPIRE-AVR containing 40 images and VICAVR containing 58 images. The local database also contains images with pathologically diseased structures. The performance of the proposed system is assessed by comparing the experimental results with the gold standard estimations as well as with the results of previous methodologies. Overall, an accuracy of 90.45%, 93.90% and 87.82% is achieved in retinal blood vessel separation with 0.0565, 0.0650 and 0.0849 mean error in Arteriovenous Ratio calculation for Local, INSPIRE-AVR and VICAVR dataset, respectively.","Hypertensive retinopathy,retinal vessel classiffication,optic disk,arteriovenous ratio,region of analysis,support vector machine",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE","Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"ALZHEIMERS-DISEASE,FEATURE,RANKING,RETINAL,ARTERY,VEIN,CLASSIFICATION,ARTERIOVENOUS,RATIO,FUNDUS,PHOTOGRAPHY,FEATURE-SELECTION,SEGMENTATION,HYPERTENSION,COMBINATION",JOURNAL OF INNOVATIVE OPTICAL HEALTH SCIENCES,https://vuir.vu.edu.au/39980/1/s1793545819500214.pdf,
53,MultiResUNet : Rethinking the U-Net architecture for multimodal biomedical image segmentation,121,,74-87,"Ibtehaz Nabil,Rahman M. Sohel","Ibtehaz N,Rahman MS",Rahman MS,10.1016/j.neunet.2019.08.025,Bangladesh University of Engineering & Technology (BUET),"In recent years Deep Learning has brought about a breakthrough in Medical Image Segmentation. In this regard, U-Net has been the most popular architecture in the medical imaging community. Despite outstanding overall performance in segmenting multimodal medical images, through extensive experimentations on some challenging datasets, we demonstrate that the classical U-Net architecture seems to be lacking in certain aspects. Therefore, we propose some modifications to improve upon the already state-of-the-art U-Net model. Following these modifications, we develop a novel architecture, MultiResUNet, as the potential successor to the U-Net architecture. We have tested and compared MultiResUNet with the classical U-Net on a vast repertoire of multimodal medical images. Although only slight improvements in the cases of ideal images are noticed, remarkable gains in performance have been attained for the challenging ones. We have evaluated our model on five different datasets, each with their own unique challenges, and have obtained a relative improvement in performance of 10.15%, 5.07%, 2.63%, 1.41%, and 0.62% respectively. We have also discussed and highlighted some qualitatively superior aspects of MultiResUNet over classical U-Net that are not really reflected in the quantitative measures. (C) 2019 Elsevier Ltd. All rights reserved.","Convolutional neural networks,Medical imaging,Semantic segmentation,U-Net",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,9.171,"VALIDATION,GLAND",NEURAL NETWORKS,http://arxiv.org/pdf/1902.04049,
54,Recognition of words from brain-generated signals of speech-impaired people: Application of autoencoders as a neural Turing machine controller in deep neural networks,121,,186-207,"Boloukian Behzad,Safi-Esfahani Faramarz","Boloukian B,Safi-Esfahani F",Safi-Esfahani F,10.1016/j.neunet.2019.07.012,Islamic Azad University,"There is an essential requirement to support people with speech and communication disabilities. A brain-computer interface using electroencephalography (EEG) is applied to satisfy this requirement. A number of research studies to recognize brain signals using machine learning and deep neural networks (DNNs) have been performed to increase the brain signal detection rate, yet there are several defects and limitations in the techniques. Among them is the use in specific circumstances of machine learning. On the one hand, DNNs extract the features well and automatically. On the other hand, their use results in overfitting and vanishing problems. Consequently, in this research, a deep network is designed on the basis of an autoencoder neural Turing machine (DN-AE-NTM) to resolve the problems by the use of NTM external memory. In addition, the DN-AE-NTM copes with all kinds of signals with high detection rates. The data were collected by P300 EEG devices from several individuals under the same conditions. During the test, each individual was requested to skim images with one to six labels and focus on only one of the images. Not to focus on some images is analogous to producing unimportant information in the individual's brain, which provides unfamiliar signals. Besides the main P300 EEG dataset, EEG recordings of individuals with alcoholism and control individuals and the EEGMMIDB, MNIST, and ORL datasets were implemented and tested. The proposed DN-AE-NTM method classifies data with an average detection rate of 97.5%, 95%, 98%, 99.4%, and 99.1%, respectively, in situations where the signals are noisy so that only 20% of the data are reliable and include useful information. (C) 2019 Elsevier Ltd. All rights reserved.","Speech disabilities,Brain-computer interface,EEG,Brain signals,Neural Turing machine,Deep neural networks",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,,"COMPUTER,INTERFACE,IMAGERY,PCA,EEG,KNN",NEURAL NETWORKS,,
55,iQSPR in XenonPy: A Bayesian Molecular Design Algorithm,39,1-2,,"Wu Stephen,Lambard Guillaume,Liu Chang,Yamada Hironao,Yoshida Ryo","Wu S,Lambard G,Liu C,Yamada H,Yoshida R",Wu S; Yoshida R,10.1002/minf.201900107,Research Organization of Information & Systems (ROIS),"iQSPR is an inverse molecular design algorithm based on Bayesian inference that was developed in our previous study. Here, the algorithm is integrated in Python as a new module called iQSPR-X in the all-in-one materials informatics platform XenonPy. Our new software provides a flexible, easy-to-use, and extensible platform for users to build customized molecular design algorithms using pre-set modules and a pre-trained model library in XenonPy. In this paper, we describe key features of iQSPR-X and provide guidance on its use, illustrated by an application to a polymer design that targets a specific range of bandgap and dielectric constant.","molecular design,machine learning,Bayesian inference,open source,polymer",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Pharmacology & Pharmacy,Computer Science,Mathematical & Computational Biology",,2.723,"CHEMICAL,LANGUAGE,DRUG,DESIGN,GENERATION,SYSTEM",MOLECULAR INFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7050509,
56,Automated vertebrae localization and identification by decision forests and image-based refinement on real-world CT data,125,1,48-56,"Jimenez-Pastor Ana,Alberich-Bayarri Angel,Fos-Guarinos Belen,Garcia-Castro Fabio,Garcia-Juan David,Glocker Ben,Marti-Bonmati Luis","Jimenez-Pastor A,Alberich-Bayarri A,Fos-Guarinos B,Garcia-Castro F,Garcia-Juan D,Glocker B,Marti-Bonmati L",Jimenez-Pastor A,10.1007/s11547-019-01079-9,"QUIBIM SL, Valencia, Spain.","Purpose Development of a fully automatic algorithm for the automatic localization and identification of vertebral bodies in computed tomography (CT). Materials and methods This algorithm was developed using a dataset based on real-world data of 232 thoraco-abdominopelvic CT scans retrospectively collected. In order to achieve an accurate solution, a two-stage automated method was developed: decision forests for a rough prediction of vertebral bodies position, and morphological image processing techniques to refine the previous detection by locating the position of the spinal canal. Results The mean distance error between the predicted vertebrae centroid position and truth was 13.7 mm. The identification rate was 79.6% on the thoracic region and of 74.8% on the lumbar segment. Conclusion The algorithm provides a new method to detect and identify vertebral bodies from arbitrary field-of-view body CT scans.","Artificial intelligence,Decision forest,Spine,Computed tomography",Article,"SPRINGER-VERLAG ITALIA SRL, VIA DECEMBRIO, 28, MILAN, 20137, ITALY","Radiology, Nuclear Medicine & Medical Imaging",,2.624,,RADIOLOGIA MEDICA,,
57,Exergy-based optimisation of a phase change materials integrated hybrid renewable system for active cooling applications using supervised machine learning method,195,,514-526,"Tang Liang,Zhou Yuekuan,Zheng Siqian,Zhang Guoqiang","Tang L,Zhou YK,Zheng SQ,Zhang GQ",Zhou YK,10.1016/j.solener.2019.11.067,Hong Kong Polytechnic University,"The active cooling, latent thermal storage and advanced energy conversions are effective solutions to high-efficiently utilise renewable energy for building applications, whereas the electricity consumption of active facilities for the thermal performance enhancement needs to be considered. In this study, the exergy analysis of a hybrid renewable system, with on-site thermal and electric energy forms, sensible and latent heat storages, was investigated, in terms of technical feasibility of proposed active cooling solutions. The contradiction between the increased electricity consumption of active cooling facilities and the enhancement of renewable generations has been presented, discussed, together with effective solutions, from the perspective of exergy. A machine-learning based optimisation methodology was proposed and used, to address the contradiction and to maximise the overall exergy, with the integration of an advanced optimisation algorithm. The results showed that, in regard to the contradiction, effective solutions include the active water-based cooling and the optimal design of the geometric and operating parameters. Furthermore, with the adoption of optimal parameters through the machine-learning based optimisation, the overall exergy of the hybrid renewable system is 872.06 kWh, which is 2.6% higher than the maximum overall exergy through the Taguchi standard orthogonal array (849.9 kWh). This study demonstrates an effective solution to the contradiction of an active renewable system, together with a machine-learning based optimisation methodology, which can promote the practical feasibility and applicability of active renewable systems in renewable and sustainable buildings.","Exergy analysis,Phase Change Materials (PCMs),Sensible and latent storage,On-site thermal and electric energy,Machine learning,Teaching-learning-based optimisation",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Energy & Fuels,,5.619,"THERMAL-ENERGY,STORAGE,HEATING-SYSTEM,PERFORMANCE,FLOOR,ENHANCEMENT,VENTILATION,BUILDINGS,MASS,PVT",SOLAR ENERGY,,
58,iGLU: An Intelligent Device for Accurate Noninvasive Blood Glucose-Level Monitoring in Smart Healthcare,9,1,35-42,"Jain Prateek,Joshi Amit M.,Mohanty Saraju P.","Jain P,Joshi AM,Mohanty SP",Jain P,10.1109/MCE.2019.2940855,National Institute of Technology (NIT System),"In the case of diabetes, fingertip pricking for blood sample is inconvenient for glucose measurement. Invasive approaches like laboratory tests and one touch glucometers enhance the risk of blood related infections. To mitigate this important issue, this article introduces a novel Internet-of-Medical-Things (IoMT) enabled edge-device for precise, noninvasive blood glucose measurement. The device called ""Intelligent Glucose Meter"" (i.e., iGLU) is based on near-infrared (NIR) spectroscopy and a machine learning model of high accuracy. iGLU has been validated in a hospital and blood glucose values are stored in an IoMT platform for remote monitoring by endocrinologists.","Sugar,Blood,Monitoring,Detectors,Diabetes,Biomedical monitoring",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.329,"MICROSYSTEM,SPECTRA,SYSTEM",IEEE CONSUMER ELECTRONICS MAGAZINE,http://arxiv.org/pdf/1911.04471,
59,Artificial intelligence and machine learning in oncologic imaging,26,1,60-65,"Kleesiek Jens,Murray Jacob M.,Kaissis Georgios,Braren Rickmer","Kleesiek J,Murray JM,Kaissis G,Braren R",Kleesiek J,10.1007/s00761-019-00679-4,Helmholtz Association,"Background. Machine learning (ML) is finding entry into many areas of society, including medicine. This transformation has the potential to drastically change the perception of medicine and medical practice. While these advances currently only influence clinical routine in isolated cases, they also come with risks. These aspects become particularly clear when considering the different stages of oncologic patient care and the involved interdisciplinary and intermodality interactions. In recent publications, computers-in collaboration with humans or alone-have been outperforming humans. This pertains to tumor identification, tumor classification, creation of prognoses, and evaluation of treatments. Additionally, ML algorithms, e.g., artificial neural networks (ANNs), which constitute the drivers behind many of the latest achievements in ML, can deliver this level of performance in a reproducible, fast, and cheap manner.
Objective. This review elucidates the current state of research on ML in oncology by focusing on selected tumor entities, and relates this to the development of research and medicine as a whole.
Materials and methods. This work is based on a selective literature search in the databases PubMed and arXiv.
Conclusion. In the future, AI applications will develop into an integral part of the medical profession and offer advantages for oncologic diagnostics and treatment.","Machine learning,Computer-assisted image processing,Diagnostic imaging,Deep Learning,Neural networks (computer)",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Oncology,,,"CANCER,CLASSIFICATION,PATHOLOGISTS,RADIOMICS",ONKOLOGE,,
60,Graph Convolutional Neural Networks as ,60,1,22-28,"Korolev Vadim,Mitrofanov Artem,Korotcov Alexandru,Tkachenko Valery","Korolev V,Mitrofanov A,Korotcov A,Tkachenko V",Korolev V,10.1021/acs.jcim.9b00587,"Sci Data Software LLC, 14909 Forest Landing Circle, Rockville, MD 20850 USA.","Nowadays the development of new functional materials/chemical compounds using machine learning (ML) techniques is a hot topic and includes several crucial steps, one of which is the choice of chemical structure representation. The classical approach of rigorous feature engineering in ML typically improves the performance of the predictive model, but at the same time, it narrows down the scope of applicability and decreases the physical interpretability of predicted results. In this study, we present graph convolutional neural networks (GCNNs) as an architecture that allows for successfully predicting the properties of compounds from diverse domains of chemical space, using a minimal set of meaningful descriptors. The applicability of GCNN models has been demonstrated by a wide range of chemical domain-specific properties. Their performance is comparable to state-of-the-art techniques; however, this architecture exempts from the need to carry out precise feature engineering.","MECHANICAL-PROPERTIES,ZEOLITES,FRAMEWORK",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Pharmacology & Pharmacy,Chemistry,Computer Science",,5.39,"MACHINE,LEARNING-METHODS,MECHANICAL-PROPERTIES,ZEOLITES,FRAMEWORK",JOURNAL OF CHEMICAL INFORMATION AND MODELING,http://arxiv.org/pdf/1906.06256,
61,A culturally appropriate mobile health application for pregnancy risk communication to latino women,222,1,S575-S576,"Mora Anabel Castillo,Krishnamurti Tamar,Davis Alexander,Simhan Hyagriv","Mora AC,Krishnamurti T,Davis A,Simhan H",,10.1016/j.ajog.2019.11.941,"
",,,Meeting Abstract,"MOSBY-ELSEVIER, 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA",,,8.145,,AMERICAN JOURNAL OF OBSTETRICS AND GYNECOLOGY,http://www.ajog.org/article/S0002937819323117/pdf,
62,CausalBG: Causal Recurrent Neural Network for the Blood Glucose Inference With IoT Platform,7,1,598-610,"He Miao,Gu Weixi,Kong Ying,Zhang Lin,Spanos Costas J.,Mosalam Khalid M.","He M,Gu WX,Kong Y,Zhang L,Spanos CJ,Mosalam KM",Gu WX,10.1109/JIOT.2019.2946693,University of California System,"Predicting blood glucose concentration facilitates timely preventive measures against health risks induced by abnormal glucose events. Advances in IoT devices, such as continuous blood glucose monitors (CGMs) have made it convenient for measurements of blood glucose in real time. However, accurate and personalized blood glucose concentration prediction is still challenging. Previous inference models yield low-inference accuracy due to the ineffective feature extraction and the limited, imbalanced personal training data. The underlying causal correlations among the blood glucose series are scarcely captured by these models. In this article, we propose CausalBG, a causal recurrent neural network (CausalRNN) deployed on an IoT platform with smartphones and CGM for the accurate and efficient individual blood glucose concentration prediction. CausalBG automatically captures the underlying causal relationships embedded in the blood glucose features through CausalRNN, and efficiently shares the limited personal data among users for the sufficient training via the multitask framework. Evaluations and case studies on 112 users demonstrate that CausalBG significantly outperforms the conventional predictive models on the blood glucose dynamics inference.","Sugar,Blood,Physiology,Predictive models,Insulin,Biomedical monitoring,Data models,Data mining,health information management,Internet of Things,Prediction methods,Recurrent neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,10.127,MODEL,IEEE INTERNET OF THINGS JOURNAL,,
63,Studying the Manifold Structure of Alzheimers Disease: A Deep Learning Approach Using Convolutional Autoencoders,24,1,17-26,"Martinez-Murcia Francisco J.,Ortiz Andres,Gorriz Juan-Manuel,Ramirez Javier,Castillo-Barnes Diego","Martinez-Murcia FJ,Ortiz A,Gorriz JM,Ramirez J,Castillo-Barnes D",Martinez-Murcia FJ,10.1109/JBHI.2019.2914970,Universidad de Malaga,"Many classical machine learning techniques have been used to explore Alzheimers disease (AD), evolving from image decomposition techniques such as principal component analysis toward higher complexity, non-linear decomposition algorithms. With the arrival of the deep learning paradigm, it has become possible to extract high-level abstract features directly from MRI images that internally describe the distribution of data in low-dimensional manifolds. In this work, we try a new exploratory data analysis of AD based on deep convolutional autoencoders. We aim at finding links between cognitive symptoms and the underlying neurodegeneration process by fusing the information of neuropsychological test outcomes, diagnoses, and other clinical data with the imaging features extracted solely via a data-driven decomposition of MRI. The distribution of the extracted features in different combinations is then analyzed and visualized using regression and classification analysis, and the influence of each coordinate of the autoencoder manifold over the brain is estimated. The imaging-derived markers could then predict clinical variables with correlations above 0.6 in the case of neuropsychological evaluation variables such as the MMSE or the ADAS11 scores, achieving a classification accuracy over 80 for the diagnosis of AD.","Feature extraction,Magnetic resonance imaging,Manifolds,Alzheimer's disease,Computer architecture,Deep learning,Alzheimer's disease,deep learning,convolutional autoencoder,manifold learning,data fusion",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"MILD,COGNITIVE,IMPAIRMENT,COMPONENT,ANALYSIS,FEATURE-SELECTION,EARLY-DIAGNOSIS,SPECT,IMAGES,MRI,DATA,CLASSIFICATION,SCANS",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://ieeexplore.ieee.org/ielx7/6221020/8949677/08737996.pdf,
64,Evaluating and Enhancing the Generalization Performance of Machine Learning Models for Physical Activity Intensity Prediction From Raw Acceleration Data,24,1,27-38,"Farrahi Vahid,Niemela Maisa,Tjurin Petra,Kangas Maarit,Korpelainen Raija,Jamsa Timo","Farrahi V,Niemela M,Tjurin P,Kangas M,Korpelainen R,Jamsa T",Farrahi V,10.1109/JBHI.2019.2917565,University of Oulu,"Purpose: To evaluate and enhance the generalization performance of machine learning physical activity intensity prediction models developed with raw acceleration data on populations monitored by different activity monitors. Method: Five datasets from four studies, each containing only hip- or wrist-based raw acceleration data (two hip- and three wrist-based) were extracted. The five datasets were then used to develop and validate artificial neural networks (ANN) in three setups to classify activity intensity categories (sedentary behavior, light, and moderate-to-vigorous). To examine generalizability, the ANN models were developed using within dataset (leave-one-subject-out) cross validation, and then cross tested to other datasets with different accelerometers. To enhance the models' generalizability, a combination of four of the five datasets was used for training and the fifth dataset for validation. Finally, all the five datasets were merged to develop a single model that is generalizable across the datasets (50 of the subjects from each dataset for training, the remaining for validation). Results: The datasets showed high performance in within dataset cross validation (accuracy 71.9-95.4, Kappa K 0.63-0.94). The performance of the within dataset validated models decreased when applied to datasets with different accelerometers (41.2-59.9, K 0.21-0.48). The trained models on merged datasets consisting hip and wrist data predicted the left-out dataset with acceptable performance (65.9-83.7, K 0.61-0.79). The model trained with all five datasets performed with acceptable performance across the datasets (80.4-90.7, K 0.68-0.89). Conclusions: Integrating heterogeneous datasets in training sets seems a viable approach for enhancing the generalization performance of the models. Instead, within dataset validation is not sufficient to understand the models' performance on other populations with different accelerometers.","Acceleration,Sociology,Statistics,Predictive models,Data models,Accelerometers,Monitoring,Accelerometers,pattern recognition,artificial neural networks,activity monitor,classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"ENERGY-EXPENDITURE,ACCELEROMETER,OUTPUT,ACTIVITY,RECOGNITION,SEDENTARY,BEHAVIOR,ACTIVITY,MONITORS,HIP,WRIST,VALIDATION,WORN,COMPARABILITY",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://jultika.oulu.fi/files/nbnfi-fe2019091828613.pdf,
65,Deep Residual Inception Encoder-Decoder Network for Medical Imaging Synthesis,24,1,39-49,"Gao Fei,Wu Teresa,Chu Xianghua,Yoon Hyunsoo,Xu Yanzhe,Patel Bhavika","Gao F,Wu T,Chu XH,Yoon H,Xu YZ,Patel B",Chu XH,10.1109/JBHI.2019.2912659,Shenzhen University,"Image synthesis is a novel solution in precision medicine for scenarios where important medical imaging is not otherwise available. The convolutional neural network (CNN) is an ideal model for this task because of its powerful learning capabilities through the large number of layers and trainable parameters. In this research, we propose a new architecture of residual inception encoder-decoder neural network (RIED-Net) to learn the nonlinear mapping between the input images and targeting output images. To evaluate the validity of the proposed approach, it is compared with two models from the literature: synthetic CT deep convolutional neural network (sCT-DCNN) and shallow CNN, using both an institutional mammogram dataset from Mayo Clinic Arizona and a public neuroimaging dataset from the Alzheimers Disease Neuroimaging Initiative. Experimental results show that the proposed RIED-Net outperforms the two models on both datasets significantly in terms of structural similarity index, mean absolute percent error, and peak signal-to-noise ratio.","Image segmentation,Biomedical imaging,Task analysis,Image generation,Magnetic resonance imaging,Tumors,Deep learning,image synthesis,inception,medical imaging and residual net",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"ENHANCED,SPECTRAL,MAMMOGRAPHY,CONVOLUTIONAL,NEURAL-NETWORKS,FIELD,DIGITAL,MAMMOGRAPHY,ALZHEIMERS-DISEASE,BREAST-CANCER,CLASSIFICATION,MODEL,MRI",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
66,Motion Sensor-Based Assessment of Parkinson's Disease Motor Symptoms During Leg Agility Tests: Results From Levodopa Challenge,24,1,111-119,"Aghanavesi Somayeh,Bergquist Filip,Nyholm Dag,Senek Marina,Memedi Mevludin","Aghanavesi S,Bergquist F,Nyholm D,Senek M,Memedi M",Aghanavesi S,10.1109/JBHI.2019.2898332,Dalarna University,"Parkinsons disease (PD) is a degenerative, progressive disorder of the central nervous system that mainly affects motor control. The aim of this study was to develop data-driven methods and test their clinimetric properties to detect and quantify PD motor states using motion sensor data from leg agility tests. Nineteen PD patients were recruited in a levodopa single dose challenge study. PD patients performed leg agility tasks while wearing motion sensors on their lower extremities. Clinical evaluation of video recordings was performed by three movement disorder specialists who used four items from the motor section of the unified PD rating scale (UPDRS), the treatment response scale (TRS) and a dyskinesia score. Using the sensor data, spatiotemporal features were calculated and relevant features were selected by feature selection. Machine learning methods like support vector machines (SVM), decision trees, and linear regression, using ten-fold cross validation were trained to predict motor states of the patients. SVM showed the best convergence validity with correlation coefficients of 0.81 to TRS, 0.83 to UPDRS 31 (body bradykinesia and hypokinesia), 0.78 to SUMUPDRS (the sum of the UPDRS items: 26-leg agility, 27-arising from chair, and 29-gait), and 0.67 to dyskinesia. Additionally, the SVM-based scores had similar test-retest reliability in relation to clinical ratings. The SVM-based scores were less responsive to treatment effects than the clinical scores, particularly with regards to dyskinesia. In conclusion, the results from this study indicate that using motion sensors during leg agility tests may lead to valid and reliable objective measures of PD motor symptoms.","Legged locomotion,Diseases,Foot,Feature extraction,Machine learning,Standards,Acceleration,Leg agility,Parkinson's disease,support vector machine,stepwise regression,predictive models",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"SOCIETY-SPONSORED,REVISION,SCALE,MDS-UPDRS,DYSKINESIA,ASSESSMENT,STEPWISE,REGRESSION,MOVEMENT,QUANTIFICATION,IMPAIRMENT",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://du.diva-portal.org/smash/get/diva2:1290650/FULLTEXT02,
67,Assessment of Motor Impairments in Early Untreated Parkinsons Disease Patients: The Wearable Electronics Impact,24,1,120-130,"Ricci Mariachiara,Di Lazzaro Giulia,Pisani Antonio,Mercuri Nicola B.,Giannini Franco,Saggio Giovanni","Ricci M,Di Lazzaro G,Pisani A,Mercuri NB,Giannini F,Saggio G",Saggio G,10.1109/JBHI.2019.2903627,University of Rome Tor Vergata,"Objective: The complex nature of Parkinsons disease (PD) makes difficult to rate its severity, mainly based on the visual inspection of motor impairments. Wearable sensors have been demonstrated to help overcoming such a difficulty, by providing objective measures of motor abnormalities. However, up to now, those sensors have been used on advanced PD patients with evident motor impairment. As a novelty, here we report the impact of wearable sensors in the evaluation of motor abnormalities in newly diagnosed, untreated, namely de novo, patients. Methods: A network of wearable sensors was used to measure motor capabilities, in 30 de novo PD patients and 30 healthy subjects, while performing five motor tasks. Measurement data were used to determine motor features useful to highlight impairments and were compared with the corresponding clinical scores. Three classifiers were used to differentiate PD from healthy subjects. Results: Motor features gathered from wearable sensors showed a high degree of significance in discriminating the early untreated de novo PD patients from the healthy subjects, with 95 accuracy. The rates of severity obtained from the measured features are partially in agreement with the clinical scores, with some highlighted, though justified, exceptions. Conclusion: Our findings support the feasibility of adopting wearable sensors in the detection of motor anomalies in early, untreated, PD patients. Significance: This work demonstrates that subtle motor impairments, occurring in de novo patients, can be evidenced by means of wearable sensors, providing clinicians with instrumental tools as suitable supports for early diagnosis, and subsequent management.","Task analysis,Wearable sensors,Biomedical measurement,Parkinson's disease,Atmospheric measurements,Particle measurements,IMU,machine learning,motion analysis,parkinson's disease,signal processing,wearable technology",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,,"GAIT,VARIABILITY,DISORDERS,FEATURES,SYSTEM",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
68,Improving Automatic Polyp Detection Using CNN by Exploiting Temporal Dependency in Colonoscopy Video,24,1,180-193,"Qadir Hemin Ali,Balasingham Ilangko,Solhusvik Johannes,Bergsland Jacob,Aabakken Lars,Shin Younghak","Qadir HA,Balasingham I,Solhusvik J,Bergsland J,Aabakken L,Shin Y",Shin Y,10.1109/JBHI.2019.2907434,Norwegian University of Science & Technology (NTNU),"Automatic polyp detection has been shown to be difficult due to various polyp-like structures in the colon and high interclass variations in polyp size, color, shape, and texture. An efficient method should not only have a high correct detection rate (high sensitivity) but also a low false detection rate (high precision and specificity). The state-of-the-art detection methods include convolutional neural networks (CNN). However, CNNs have shown to be vulnerable to small perturbations and noise; they sometimes miss the same polyp appearing in neighboring frames and produce a high number of false positives. We aim to tackle this problem and improve the overall performance of the CNN-based object detectors for polyp detection in colonoscopy videos. Our method consists of two stages: a region of interest (RoI) proposal by CNN-based object detector networks and a false positive (FP) reduction unit. The FP reduction unit exploits the temporal dependencies among image frames in video by integrating the bidirectional temporal information obtained by RoIs in a set of consecutive frames. This information is used to make the final decision. The experimental results show that the bidirectional temporal information has been helpful in estimating polyp positions and accurately predict the FPs. This provides an overall performance improvement in terms of sensitivity, precision, and specificity compared to conventional false positive learning method, and thus achieves the state-of-the-art results on the CVC-ClinicVideoDB video data set.","Detectors,Feature extraction,Sensitivity,Proposals,Colonoscopy,Convolutional neural networks,Cancer,Colonoscopy,polyp detection,computer aided diagnosis,convolutional neural networks,false positive learning,transfer learning,temporal information",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,VALIDATION,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://ntnuopen.ntnu.no/ntnu-xmlui/bitstream/11250/2723541/2/Improving%2bAutomatic%2bPolyp%2bDetection%2bUsing%2bCNN.pdf,
69,Multi-Objective-Based Radiomic Feature Selection for Lesion Malignancy Classification,24,1,194-204,"Zhou Zhiguo,Li Shulong,Qin Genggeng,Folkert Michael,Jiang Steve,Wang Jing","Zhou ZG,Li SL,Qin GG,Folkert M,Jiang S,Wang J",Wang J,10.1109/JBHI.2019.2902298,University of Texas System,"Objective: accurately classifying the malignancy of lesions detected in a screening scan is critical for reducing false positives. Radiomics holds great potential to differentiate malignant from benign tumors by extracting and analyzing a large number of quantitative image features. Since not all radiomic features contribute to an effective classifying model, selecting an optimal feature subset is critical. Methods: this work proposes a new multi-objective based feature selection (MO-FS) algorithm that considers sensitivity and specificity simultaneously as the objective functions during feature selection. For MO-FS, we developed a modified entropy-based termination criterion that stops the algorithm automatically rather than relying on a preset number of generations. We also designed a solution selection methodology for multi-objective learning that uses the evidential reasoning approach (SMOLER) to automatically select the optimal solution from the Pareto-optimal set. Furthermore, we developed an adaptive mutation operation to generate the mutation probability in MO-FS automatically. Results: we evaluated the MO-FS for classifying lung nodule malignancy in low-dose CT and breast lesion malignancy in digital breast tomosynthesis. Conclusion: the experimental results demonstrated that the feature set selected by MO-FS achieved better classification performance than features selected by other commonly used methods. Significance: the proposed method is general and more effective radiomic feature selection strategy.","Feature extraction,Lesions,Entropy,Informatics,Sociology,Statistics,Linear programming,Radiomics,lesion malignancy classification,feature selection,multi-objective evolutionary algorithm,evidential reasoning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"EVIDENTIAL,REASONING,APPROACH,DECISION-ANALYSIS,ALGORITHM,BENIGN,MODEL",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7193672,
70,Hierarchical Rough-to-Fine Model for Infant Age Prediction Based on Cortical Features,24,1,214-225,"Hu Dan,Wu Zhengwang,Lin Weili,Li Gang,Shen Dinggang","Hu D,Wu ZW,Lin WL,Li G,Shen DG",Li G; Shen DG,10.1109/JBHI.2019.2897020,University of North Carolina,"Prediction of the chronological age based on neuroimaging data is important for brain development analysis and brain disease diagnosis. Although many researches have been conducted for age prediction of older children and adults, little work has been dedicated to infants. To this end, this paper focuses on predicting infant age from birth to 2-year old using brain MR images, as well as identifying some related biomarkers. However, brain development during infancy is too rapid and heterogeneous to be accurately modeled by the conventional regression models. To address this issue, a two-stage prediction method is proposed. Specifically, our method first roughly predicts the age range of an infant and then finely predicts the accurate chronological age based on a learned, age-group-specific regression model. Combining this two-stage prediction method with another complementary one-stage prediction method, a hierarchical rough-to-fine (HRtoF) model is built. HRtoF effectively splits the rapid and heterogeneous changes during a long time period into several short time ranges and further mines the discrimination capability of cortical features, thus reaching high accuracy in infant age prediction. Taking 8 types of cortical morphometric features from structural MRI as predictors, the effectiveness of our proposed HRtoF model is validated using an infant dataset including 50 healthy subjects with 251 longitudinal MRI scans from 14 to 797 days. Comparing with five state-of-the-art regression methods, HRtoF model reduces the mean absolute error of the prediction from > 48 days to 32.1 days. The correlation coefficient of the predicted age and the chronological age reaches 0.963. Moreover, based on HRtoF, the relative contributions of the eight types of cortical features for age prediction are also studied.","Predictive models,Brain modeling,Pediatrics,Surface morphology,Feature extraction,Biological system modeling,Cortical features,infant age prediction,longitudinal development,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"HUMAN,CEREBRAL-CORTEX,BRAIN-AGE,SURFACE-AREA,BIRTH,MRI,THICKNESS,CONSTRUCTION,ASYMMETRIES,ATLASES,REGIONS",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://europepmc.org/articles/pmc6675669?pdf=render,
71,Deep Active Shape Model for Robust Object Fitting,29,,2380-2394,"Medley Daniela O.,Santiago Carlos,Nascimento Jacinto C.","Medley DO,Santiago C,Nascimento JC",Medley DO,10.1109/TIP.2019.2948728,Universidade de Coimbra,"Object recognition and localization is still a very challenging problem, despite recent advances in deep learning (DL) approaches, especially for objects with varying shapes and appearances. Statistical models, such as an Active Shape Model (ASM), rely on a parametric model of the object, allowing an easy incorporation of prior knowledge about shape and appearance in a principled way. To take advantage of these benefits, this paper proposes a new ASM framework that addresses two tasks: (i) comparing the performance of several image features used to extract observations from an input image; and (ii) improving the performance of the model fitting by relying on a probabilistic framework that allows the use of multiple observations and is robust to the presence of outliers. The goal in (i) is to maximize the quality of the observations by exploring a wide set of handcrafted features (HOG, SIFT, and texture templates) and more recent DL-based features. Regarding (ii), we use the Generalized Expectation-Maximization algorithm to deal with outliers and to extend the fitting process to multiple observations. The proposed framework is evaluated in the context of facial landmark fitting and the segmentation of the endocardium of the left ventricle in cardiac magnetic resonance volumes. We experimentally observe that the proposed approach is robust not only to outliers, but also to adverse initialization conditions and to large search regions (from where the observations are extracted from the image). Furthermore, the results of the proposed combination of the ASM with DL-based features are competitive with more recent DL approaches (e.g. FCN [1], U-Net [2] and CNN Cascade [3]), showing that it is possible to combine the benefits of statistical models and DL into a new deep ASM probabilistic framework.","Image segmentation,convolutional neural networks,generalized expectation-maximization,HOG,SIFT,active shape model",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,SEGMENTATION,IEEE TRANSACTIONS ON IMAGE PROCESSING,,
72,Machine Learning to Predict the Rapid Growth of Small Abdominal Aortic Aneurysm,44,1,37-42,"Hirata Kenichiro,Nakaura Takeshi,Nakagawa Masataka,Kidoh Masafumi,Oda Seitaro,Utsunomiya Daisuke,Yamashita Yasuyuki","Hirata K,Nakaura T,Nakagawa M,Kidoh M,Oda S,Utsunomiya D,Yamashita Y",Hirata K,10.1097/RCT.0000000000000958,Kumamoto University,"Objective The purpose of this study was to determine whether computed tomography (CT) angiography with machine learning (ML) can be used to predict the rapid growth of abdominal aortic aneurysm (AAA). Materials and Methods This retrospective study was approved by our institutional review board. Fifty consecutive patients (45 men, 5 women, 73.5 years) with small AAA (38.5 +/- 6.2 mm) had undergone CT angiography. To be included, patients required at least 2 CT scans a minimum of 6 months apart. Abdominal aortic aneurysm growth, estimated by change per year, was compared between patients with baseline infrarenal aortic minor axis. For each axial image, major axis of AAA, minor axis of AAA, major axis of lumen without intraluminal thrombi (ILT), minor axis of lumen without ILT, AAA area, lumen area without ILT, ILT area, maximum ILT area, and maximum ILT thickness were measured. We developed a prediction model using an ML method (to predict expansion >4 mm/y) and calculated the area under the receiver operating characteristic curve of this model via 10-fold cross-validation. Results The median aneurysm expansion was 3.0 mm/y. Major axis of AAA and AAA area correlated significantly with future AAA expansion (r = 0.472, 0.416 all P < 0.01). Machine learning and major axis of AAA were a strong predictor of significant AAA expansion (>4 mm/y) (area under the receiver operating characteristic curve were 0.86 and 0.78). Conclusions Machine learning is an effective method for the prediction of expansion risk of AAA. Abdominal aortic aneurysm area and major axis of AAA are the important factors to reflect AAA expansion.","machine learning,infrarenal abdominal aortic aneurysm,expansion predict",Article,"LIPPINCOTT WILLIAMS & WILKINS, TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA","Radiology, Nuclear Medicine & Medical Imaging",,1.592,"FOR-VASCULAR-SURGERY,RUPTURE,THROMBUS,ASSOCIATION,EXPANSION,RATES,METAANALYSIS,GUIDELINES,DIAMETER,MEDICINE",JOURNAL OF COMPUTER ASSISTED TOMOGRAPHY,,
73,Predictive quantitative ultrasound radiomic markers associated with treatment response in head and neck cancer,6,1,,"Tran William T.,Suraweera Harini,Quaioit Karina,Cardenas Daniel,Leong Kai X.,Karam Irene,Poon Ian,Jang Deok,Sannachi Lakshmanan,Gangeh Mehrdad","Tran WT,Suraweera H,Quaioit K,Cardenas D,Leong KX,Karam I,Poon I,Jang D,Sannachi L,Gangeh M",Czarnota GJ,10.2144/fsoa-2019-0048,University of Toronto,"Aim: We aimed to identify quantitative ultrasound (QUS)-radiomic markers to predict radiotherapy response in metastatic lymph nodes of head and neck cancer. Materials & methods: Node-positive head and neck cancer patients underwent pretreatment QUS imaging of their metastatic lymph nodes. Imaging features were extracted using the QUS spectral form, and second-order texture parameters. Machine-learning classifiers were used for predictive modeling, which included a logistic regression, naive Bayes, and k-nearest neighbor classifiers. Results: There was a statistically significant difference in the pretreatment QUS-radiomic parameters between radiological complete responders versus partial responders (p < 0.05). The univariable model that demonstrated the greatest classification accuracy included: spectral intercept (SI)-contrast (area under the curve = 0.741). Multivariable models were also computed and showed that the SI-contrast + SI-homogeneity demonstrated an area under the curve = 0.870. The three-feature model demonstrated that the spectral slope-correlation + SI-contrast + SI-homogeneity-predicted response with accuracy of 87.5%. Conclusion: Multivariable QUS-radiomic features of metastatic lymph nodes can predict treatment response a priori.
Lay abstract: In this study, quantitative ultrasound (QUS) and machine-learning classification was used to predict treatment outcomes in head and neck cancer patients. Metastatic lymph nodes in the neck were scanned using conventional frequency ultrasound (US). Quantitative data were collected from the US-radiofrequency signal a priori. Machine-learning classification models were computed using QUS features; these included the linear fit parameters of the power spectrum, and second-order texture parameters of the QUS parametric images. Treatment outcomes were measured based on radiological response. Patients were classified into binary groups: radiologic complete response (CR) or radiological partial response (PR), which was assessed 3 months following treatment. Initial results demonstrate high accuracy (%Acc = 87.5%) for predicting radiological response. The results of this study suggest that QUS can be used to predict head and neck cancer response to radiotherapy a priori.","chemoradiation,head and neck carcinoma,predictive assay,quantitative ultrasound,radiation therapy,radiomic",Article,"FUTURE SCI LTD, UNITED HOUSE, 2 ALBERT PL, LONDON, N3 1QB, ENGLAND",Research & Experimental Medicine,,,"SQUAMOUS-CELL,CARCINOMA,HUMAN-PAPILLOMAVIRUS,RADIATION-THERAPY,TEXTURAL,FEATURES,MOLECULAR-BIOLOGY,SPECTRUM,ANALYSIS,RADIOTHERAPY,HYPOXIA,CHEMOTHERAPY,OXYGENATION",FUTURE SCIENCE OA,https://www.future-science.com/doi/pdf/10.2144/fsoa-2019-0048,
74,,,,,,,,,,,,,,,,,,,,
75,Cloud-Based Automated Clinical Decision Support System for Detection and Diagnosis of Lung Cancer in Chest CT,8,,,"Masood Anum,Yang Po,Sheng Bin,Li Huating,Li Ping,Qin Jing,Lanfranchi Vitaveska,Kim Jinman,Feng David Dagan","Masood A,Yang P,Sheng B,Li HT,Li P,Qin J,Lanfranchi V,Kim JM,Feng DD",Sheng B,10.1109/JTEHM.2019.2955458,Shanghai Jiao Tong University,"Lung cancer is a major cause for cancer-related deaths. The detection of pulmonary cancer in the early stages can highly increase survival rate. Manual delineation of lung nodules by radiologists is a tedious task. We developed a novel computer-aided decision support system for lung nodule detection based on a 3D Deep Convolutional Neural Network (3DDCNN) for assisting the radiologists. Our decision support system provides a second opinion to the radiologists in lung cancer diagnostic decision making. In order to leverage 3-dimensional information from Computed Tomography (CT) scans, we applied median intensity projection and multi-Region Proposal Network (mRPN) for automatic selection of potential region-of-interests. Our Computer Aided Diagnosis (CAD) system has been trained and validated using LUNA16, ANODE09, and LIDC-IDR datasets; the experiments demonstrate the superior performance of our system, attaining sensitivity, specificity, AUROC, accuracy, of 98.4, 92, 96 and 98.51 with 2.1 FPs per scan. We integrated cloud computing, trained and validated our Cloud-Based 3DDCNN on the datasets provided by Shanghai Sixth People's Hospital, as well as LUNA16, ANODE09, and LIDC-IDR. Our system outperformed the state-of-the-art systems and obtained an impressive 98.7 sensitivity at 1.97 FPs per scan. This shows the potentials of deep learning, in combination with cloud computing, for accurate and efficient lung nodule detection via CT imaging, which could help doctors and radiologists in treating lung cancer patients.","Cancer,Lung,Computed tomography,Training,Solid modeling,Cloud computing,Machine learning,Computer-aided diagnosis,nodule detection,cloud computing,computed tomography,lung cancer",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,,"COMPUTED-TOMOGRAPHY,IMAGES,PULMONARY,NODULE,DETECTION,CLASSIFICATION,ALGORITHMS",IEEE JOURNAL OF TRANSLATIONAL ENGINEERING IN HEALTH AND MEDICINE,https://europepmc.org/articles/pmc6946021?pdf=render,
76,Pixel-Level Cracking Detection on 3D Asphalt Pavement Images Through Deep-Learning- Based CrackNet-V,21,1,273-284,"Fei Yue,Wang Kelvin C. P.,Zhang Allen,Chen Cheng,Li Joshua Q.,Liu Yang,Yang Guangwei,Li Baoxian","Fei Y,Wang KCP,Zhang A,Chen C,Li JQ,Liu Y,Yang GW,Li BX",Zhang A,10.1109/TITS.2019.2891167,Oklahoma State University System,"A few recent developments have demonstrated that deep-learning-based solutions can outperform traditional algorithms for automated pavement crack detection. In this paper, an efficient deep network called CrackNet-V is proposed for automated pixel-level crack detection on 3D asphalt pavement images. Compared with the original CrackNet, CrackNet-V has a deeper architecture but fewer parameters, resulting in improved accuracy and computation efficiency. Inspired by CrackNet, CrackNet-V uses invariant spatial size through all layers such that supervised learning can be conducted at pixel level. Following the VGG network, CrackNet-V uses $3\times 3$ size of filters for the first six convolutional layers and stacks several $3\times 3$ convolutional layers together for deep abstraction, resulting in reduced number of parameters and efficient feature extraction. CrackNet-V has 64113 parameters and consists of ten layers, including one pre-process layer, eight convolutional layers, and one output layer. A new activation function leaky rectified tanh is proposed in this paper for higher accuracy in detecting shallow cracks. The training of CrackNet-V was completed after 3000 iterations, which took only one day on a GeForce GTX 1080Ti device. According to the experimental results on 500 testing images, CrackNet-V achieves a high performance with a Precision of 84.31, Recall of 90.12, and an F-1 score of 87.12. It is shown that CrackNet-V yields better overall performance particularly in detecting fine cracks compared with CrackNet. The efficiency of CrackNet-V further reveals the advantages of deep learning techniques for automated pixel-level pavement crack detection.","CrackNet,CrackNet-V,deep learning,surface cracks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Transportation",,7.253,CLASSIFICATION,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,,
77,"CT Super-Resolution GAN Constrained by the Identical, Residual, and Cycle Learning Ensemble (GAN-CIRCLE)",39,1,188-203,"You Chenyu,Li Guang,Zhang Yi,Zhang Xiaoliu,Shan Hongming,Li Mengzhou,Ju Shenghong,Zhao Zhen,Zhang Zhuiyang,Cong Wenxiang","You CY,Li G,Zhang Y,Zhang XL,Shan HM,Li MZ,Ju SH,Zhao Z,Zhang ZY,Cong WX",Wang G,10.1109/TMI.2019.2922960,Rensselaer Polytechnic Institute,"In this paper, we present a semi-supervised deep learning approach to accurately recover high-resolution (HR) CT images from low-resolution (LR) counterparts. Specifically, with the generative adversarial network (GAN) as the building block, we enforce the cycle-consistency in terms of the Wasserstein distance to establish a nonlinear end-to-end mapping from noisy LR input images to denoised and deblurred HR outputs. We also include the joint constraints in the loss function to facilitate structural preservation. In this process, we incorporate deep convolutional neural network (CNN), residual learning, and network in network techniques for feature extraction and restoration. In contrast to the current trend of increasing network depth and complexity to boost the imaging performance, we apply a parallel ${1}\times {1}$ CNN to compress the output of the hidden layer and optimize the number of layers and the number of filters for each convolutional layer. The quantitative and qualitative evaluative results demonstrate that our proposed model is accurate, efficient and robust for super-resolution (SR) image restoration from noisy LR input images. In particular, we validate our composite SR networks on three large-scale CT datasets, and obtain promising results as compared to the other state-of-the-art methods.","Computed tomography (CT),superresolution,noise reduction,deep learning,adversarial learning,residual learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"LOW-DOSE,CT,TRABECULAR,BONE,MICROARCHITECTURE,IMAGE,QUALITY,ASSESSMENT,ITERATIVE,RECONSTRUCTION,COMPUTED-TOMOGRAPHY,NEURAL-NETWORK,THICKNESS",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1808.04256,
78,Deep Learning in Ultrasound Imaging,108,1,11-29,"van Sloun Ruud J. G.,Cohen Regev,Eldar Yonina C.","van Sloun RJG,Cohen R,Eldar YC",van Sloun RJG,10.1109/JPROC.2019.2932116,Eindhoven University of Technology,"In this article, we consider deep learning strategies in ultrasound systems, from the front end to advanced applications. Our goal is to provide the reader with a broad understanding of the possible impact of deep learning methodologies on many aspects of ultrasound imaging. In particular, we discuss methods that lie at the interface of signal acquisition and machine learning, exploiting both data structure (e.g., sparsity in some domain) and data dimensionality (big data) already at the raw radio-frequency channel stage. As some examples, we outline efficient and effective deep learning solutions for adaptive beamforming and adaptive spectral Doppler through artificial agents, learn compressive encodings for the color Doppler, and provide a framework for structured signal recovery by learning fast approximations of iterative minimization problems, with applications to clutter suppression and super-resolution ultrasound. These emerging technologies may have a considerable impact on ultrasound imaging, showing promise across key components in the receive processing chain.","Imaging,Ultrasonic imaging,Doppler effect,Deep learning,Array signal processing,Image resolution,Clutter,Beamforming,compression,deep learning,deep unfolding,Doppler,image reconstruction,super resolution,ultrasound imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,13.102,"CONTRAST-ENHANCED,ULTRASOUND,CLUTTER,FILTER,DESIGN,FLOW,SUPERRESOLUTION,DOPPLER,SEPARATION,TISSUE",PROCEEDINGS OF THE IEEE,http://arxiv.org/pdf/1907.02994,
79,Machine Learning in PET: From Photon Detection to Quantitative Image Reconstruction,108,1,51-68,"Gong Kuang,Berg Eric,Cherry Simon R.,Qi Jinyi","Gong K,Berg E,Cherry SR,Qi JY",Qi JY,10.1109/JPROC.2019.2936809,University of California System,"Machine learning has found unique applications in nuclear medicine from photon detection to quantitative image reconstruction. Although there have been impressive strides in detector development for time-of-flight positron emission tomography (PET), most detectors still make use of simple signal processing methods to extract the time and position information from the detector signals. Now, with the availability of fast waveform digitizers, machine learning techniques have been applied to estimate the position and arrival time of high-energy photons. In quantitative image reconstruction, machine learning has been used to estimate various corrections factors, including scattered events and attenuation images, as well as to reduce statistical noise in reconstructed images. Here, machine learning either provides a faster alternative to an existing time-consuming computation, such as in the case of scatter estimation, or creates a data-driven approach to map an implicitly defined function, such as in the case of estimating the attenuation map for PET/MR scans. In this article, we will review the above-mentioned applications of machine learning in nuclear medicine.","Photonics,Detectors,Machine learning,Image reconstruction,Attenuation,Positrons,Timing,Attenuation correction,deep learning,denoising,image reconstruction,machine learning,positron emission tomography (PET),scatter correction,timing resolution",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,13.102,"POSITRON-EMISSION-TOMOGRAPHY,ZERO-ECHO-TIME,WHOLE-BODY,PET,ARTIFICIAL,NEURAL-NETWORK,INTER-CRYSTAL,SCATTER,ATTENUATION,CORRECTION,POSITION,ESTIMATION,CT,IMAGES,SCINTILLATOR,MRI",PROCEEDINGS OF THE IEEE,,
80,Model-Based and Data-Driven Strategies in Medical Image Computing,108,1,110-124,"Rueckert Daniel,Schnabel Julia A.","Rueckert D,Schnabel JA",Rueckert D,10.1109/JPROC.2019.2943836,Imperial College London,"Model-based approaches for image reconstruction, analysis, and interpretation have made significant progress over the past decades. Many of these approaches are based on either mathematical, physical, or biological models. A challenge for these approaches is the modeling of the underlying processes (e.g., the physics of image acquisition or the patho-physiology of a disease) with appropriate levels of detail and realism. With the availability of large amounts of imaging data and machine learning (in particular deep learning) techniques, data-driven approaches have become more widespread for use in different tasks in reconstruction, analysis, and interpretation. These approaches learn statistical models directly from labeled or unlabeled image data and have been shown to be very powerful for extracting clinically useful information from medical imaging. While these data-driven approaches often outperform traditional model-based approaches, their clinical deployment often poses challenges in terms of robustness, generalization ability, and interpretability. In this article, we discuss what developments have motivated the shift from model-based approaches toward data-driven strategies and what potential problems are associated with the move toward purely data-driven approaches, in particular deep learning. We also discuss some of the open challenges for data-driven approaches, e.g., generalization to new unseen data (e.g., transfer learning), robustness to adversarial attacks, and interpretability. Finally, we conclude with a discussion on how these approaches may lead to the development of more closely coupled imaging pipelines that are optimized in an end-to-end fashion.","Biomedical imaging,Biological system modeling,Computational modeling,Mathematical model,Data models,Image reconstruction,Artificial neural networks,biomedical imaging,image analysis,image classification,image processing,image reconstruction,image registration,image segmentation,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,,"CONVOLUTIONAL,NEURAL-NETWORKS,TENSOR-BASED,MORPHOMETRY,MR-IMAGES,SEGMENTATION,REGISTRATION,CLASSIFICATION,SHAPE,LOCALIZATION,DEMONS,CNN",PROCEEDINGS OF THE IEEE,https://kclpure.kcl.ac.uk/portal/files/124954246/Model_Based_and_Data_Driven_RUECKERT_Accepted20September2019_ePublished14October2019_GREEN_AAM.pdf,
81,Brain Imaging Genomics: Integrated Analysis and Machine Learning,108,1,125-162,"Shen Li,Thompson Paul M.","Shen L,Thompson PM",Shen L,10.1109/JPROC.2019.2947272,University of Pennsylvania,"Brain imaging genomics is an emerging data science field, where integrated analysis of brain imaging and genomics data, often combined with other biomarker, clinical, and environmental data, is performed to gain new insights into the phenotypic, genetic, and molecular characteristics of the brain as well as their impact on normal and disordered brain function and behavior. It has enormous potential to contribute significantly to biomedical discoveries in brain science. Given the increasingly important role of statistical and machine learning in biomedicine and rapidly growing literature in brain imaging genomics, we provide an up-to-date and comprehensive review of statistical and machine learning methods for brain imaging genomics, as well as a practical discussion on method selection for various biomedical applications.","Genomics,Bioinformatics,Brain,Machine learning,Biomedical imaging,Big data,brain imaging,genomics,machine learning,statistics",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,13.102,"CANONICAL,CORRELATION-ANALYSIS,POLYGENIC,RISK,SCORES,WIDE,ASSOCIATION,ANALYSIS,QUANTITATIVE,TRAIT,LOCI,SET,ENRICHMENT,ANALYSIS,RANK,REGRESSION-MODELS,ALZHEIMERS-DISEASE,GENETIC,INFLUENCES,ANALYSIS,REVEALS,NEUROIMAGING,PHENOTYPES",PROCEEDINGS OF THE IEEE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6941751,
82,Annotated normal CT data of the abdomen for deep learning: Challenges and strategies for implementation,101,1,35-44,"Park S.,Chu L. C.,Fishman E. K.,Yuille A. L.,Vogelstein B.,Kinzler K. W.,Horton K. M.,Hruban R. H.,Zinreich E. S.,Fouladi D. Fadaei","Park S,Chu LC,Fishman EK,Yuille AL,Vogelstein B,Kinzler KW,Horton KM,Hruban RH,Zinreich ES,Fouladi DF",Kawamoto S,10.1016/j.diii.2019.05.008,Johns Hopkins University,"Purpose: The purpose of this study was to report procedures developed to annotate abdominal computed tomography (CT) images from subjects without pancreatic disease that will be used as the input for deep convolutional neural networks (DNN) for development of deep learning algorithms for automatic recognition of a normal pancreas.
Materials and methods: Dual-phase contrast-enhanced volumetric CT acquired from 2005 to 2009 from potential kidney donors were retrospectively assessed. Four trained human annotators manually and sequentially annotated 22 structures in each datasets, then expert radiologists confirmed the annotation. For efficient annotation and data management, a commercial software package that supports three-dimensional segmentation was used.
Results: A total of 1150 dual-phase CT datasets from 575 subjects were annotated. There were 229 men and 346 women (mean age: 45 +/- 12 years; range: 18-79 years). The mean intraobserver intra-subject dual-phase CT volume difference of alt annotated structures was 4.27 mL (7.65%). The deep network prediction for multi-organ segmentation showed high fidelity with 89.4% and 1.29 mm in terms of mean Dice similarity coefficients and mean surface distances, respectively.
Conclusions: A reliable data collection/annotation process for abdominal structures was developed. This process can be used to generate large datasets appropriate for deep learning. (C) 2019 Societe francaise de radiologie. Published by Elsevier Masson SAS. All rights reserved.","d Abdominal computed tomography (CT),Image segmentation,Machine learning,Normal structures,Artificial intelligence (AI)",Article,"ELSEVIER MASSON, CORP OFF, 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE","Radiology, Nuclear Medicine & Medical Imaging",,,"CONVOLUTIONAL,NEURAL-NETWORKS,COMPUTER-AIDED,DETECTION,SEGMENTATION,IMAGES,ALGORITHMS,RADIOLOGY",DIAGNOSTIC AND INTERVENTIONAL IMAGING,https://doi.org/10.1016/j.diii.2019.05.008,
83,A predictive model for the maintenance of industrial machinery in the context of industry 4.0,87,,,"Ruiz-Sarmiento Jose-Raul,Monroy Javier,Moreno Francisco-Angel,Galindo Cipriano,Bonelo Jose-Maria,Gonzalez-Jimenez Javier","Ruiz-Sarmiento JR,Monroy J,Moreno FA,Galindo C,Bonelo JM,Gonzalez-Jimenez J",Ruiz-Sarmiento JR,10.1016/j.engappai.2019.103289,Universidad de Malaga,"The Industry 4.0 paradigm is being increasingly adopted in the production, distribution and commercialization chains worldwide. The integration of the cutting-edge techniques behind it entails a deep and complex revolution - changing from scheduled-based processes to smart, reactive ones - that has to be thoroughly applied at different levels. Aiming to shed some light on the path towards such evolution, this work presents an Industry 4.0 based approach for facing a key aspect within factories: the health assessment of critical assets. This work is framed in the context of the innovative project SiMoDiM, which pursues the design and integration of a predictive maintenance system for the stainless steel industry. As a case of study, it focuses on the machinery involved in the production of high-quality steel sheets, i.e. the Hot Rolling Process, and concretely on predicting the degradation of the drums within the heating coilers of Steckel mills (parts with an expensive replacement that work under severe mechanical and thermal stresses). This paper describes a predictive model based on a Bayesian Filter, a tool from the Machine Learning field, to estimate and predict the gradual degradation of such machinery, permitting the operators to make informed decisions regarding maintenance operations. For achieving that, the proposed model iteratively fuses expert knowledge with real time information coming from the hot rolling processes carried out in the factory. The predictive model has been fitted and evaluated with real data from similar to 118k processes, proving its virtues for promoting the Industry 4.0 era.","Industry 4.0,Predictive maintenance,Machine Learning,Data analysis,Smart manufacturing,Intelligent prognostics tools",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Automation & Control Systems,Computer Science,Engineering",,5.317,"KALMAN,FILTER,PROGNOSTICS,INTERNET,FUTURE",ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE,,
84,Machine Learning in Nanoscience: Big Data at Small Scales,20,1,2-10,"Brown Keith A.,Brittman Sarah,Maccaferri Nicolo,Jariwala Deep,Ceano Umberto","Brown KA,Brittman S,Maccaferri N,Jariwala D,Ceano U",Brown KA,10.1021/acs.nanolett.9b04090,Boston University,"Recent advances in machine learning (ML) offer new tools to extract new insights from large data sets and to acquire small data sets more effectively. Researchers in nanoscience are experimenting with these tools to tackle challenges in many fields. In addition to ML's advancement of nanoscience, nanoscience provides the foundation for neuromorphic computing hardware to expand the implementation of ML algorithms. In this Mini Review, we highlight some recent efforts to connect the ML and nanoscience communities by focusing on three types of interaction: (1) using ML to analyze and extract new insights from large nanoscience data sets, (2) applying ML to accelerate material discovery, including the use of active learning to guide experimental design, and (3) the nanoscience of memristive devices to realize hardware tailored for ML. We conclude with a discussion of challenges and opportunities for future interactions between nanoscience and ML researchers.","Machine learning,data-driven research,active learning,materials discovery,design of experiments",Review,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,12.777,"NEURAL-NETWORKS,CLASSIFICATION,CHALLENGES,GENERATION,BOUNDARIES,NANOSCALE,REDUCTION,DISCOVERY,LATTICE,DESIGN",NANO LETTERS,https://orbilu.uni.lu/bitstream/10993/41197/1/acs.nanolett.9b04090.pdf,
85,Deep Learning Meets Nanophotonics: A Generalized Accurate Predictor for Near Fields and Far Fields of Arbitrary 3D Nanostructures,20,1,329-338,"Wiecha Peter R.,Muskens Otto L.","Wiecha PR,Muskens OL",Wiecha PR; Muskens OL,10.1021/acs.nanolett.9b03971,University of Southampton,"Deep artificial neural networks are powerful tools with many possible applications in nanophotonics. Here, we demonstrate how a deep neural network can be used as a fast, general purpose predictor of the full near-field and far-field response of plasmonic and dielectric nanostructures. A trained neural network is shown to infer the internal fields of arbitrary three-dimensional nanostructures many orders of magnitude faster compared to conventional numerical simulations. Secondary physical quantities are derived from the deep learning predictions and faithfully reproduce a wide variety of physical effects without requiring specific training. We discuss the strengths and limitations of the neural network approach using a number of model studies of single particles and their near-field interactions. Our approach paves the way for fast, yet universal, methods for design and analysis of nanophotonic systems.","Deep learning,nanophotonics,rapid nano-optics simulations,silicon nanostructures,plasmonics",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,12.777,"DIRECTIONAL,SCATTERING,NEURAL-NETWORKS,SILICON,GENERATION",NANO LETTERS,https://eprints.soton.ac.uk/437216/1/WiechaNanoLett2020.pdf,
86,Novel knowledge-based treatment planning model for hypofractionated radiotherapy of prostate cancer patients,69,,36-43,"Chatterjee Avishek,Serban Monica,Faria Sergio,Souhami Luis,Cury Fabio,Seuntjens Jan","Chatterjee A,Serban M,Faria S,Souhami L,Cury F,Seuntjens J",Chatterjee A,10.1016/j.ejmp.2019.11.023,McGill University,"Purpose: To demonstrate the strength of an innovative knowledge-based model-building method for radiotherapy planning using hypofractionated, multi-target prostate patients.
Material and methods: An initial RapidPlan model was trained using 48 patients who received 60 Gy to prostate (PTV60) and 44 Gy to pelvic nodes (PTV44) in 20 fractions. To improve the models goodness-of-fit, an intermediate model was generated using the dose-volume histograms of best-spared organs-at-risk (OARs) of the initial model. Using the intermediate model and manual tweaking, all 48 cases were re-planned. The final model, trained using these re-plans, was validated on 50 additional patients. The validated final model was used to determine any planning advantage of using three arcs instead of two on 16 VMAT cases and tested on 25 additional cases to determine efficacy for single-PTV (PTV60-only) treatment planning.
Results: For model validation, PTV V-95(%) of 99.9% was obtained by both clinical and knowledge-based planning. D i% was lower for model plans: by 1.23 Gy (PTV60, CI = [1.00, 1.45]), and by 2.44 Gy (PTV44, CI = [1.72, 3.16]). OAR sparing was superior for knowledge-based planning: Delta D-mean = 3.70 Gy (bladder, CI = [2.83, 4.57]), and 3.22 Gy (rectum, CI = [2.48, 3.95]); Delta D-2% = 1.17 Gy (bowel bag, CI = [0.64, 1.69]), and 4.78 Gy (femoral heads, CI = [3.90, 5.66]). Using three arcs instead of two, improvements in OAR sparing and PTV coverage were statistically significant, but of magnitudes < 1 Gy. The model failed at reliable DVH predictions for single PTV plans.
Conclusions: Our knowledge-based model delivers efficient, consistent plans with excellent PTV coverage and improved OAR sparing compared to clinical plans.","Knowledge-based,Automatic planning,Machine learning,Prostate radiotherapy",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Radiology, Nuclear Medicine & Medical Imaging",,2.736,"INTENSITY-MODULATED,RADIOTHERAPY,OPTIMIZATION,ENGINE,ARC,THERAPY,AT-RISK,IMRT,VALIDATION,QUALITY,PERFORMANCE,DISEASE,TRIAL",PHYSICA MEDICA-EUROPEAN JOURNAL OF MEDICAL PHYSICS,,
87,,,,,,,,,,,,,,,,,,,,
88,Classification of left and right foot kinaesthetic motor imagery using common spatial pattern,6,1,,"Tariq Madiha,Trivailo Pavel M.,Simic Milan","Tariq M,Trivailo PM,Simic M",Simic M,10.1088/2057-1976/ab54ad,Royal Melbourne Institute of Technology (RMIT),"Background and objectives: Brain-computer interface (BCI) systems typically deploy common spatial pattern (CSP) for feature extraction of mu and beta rhythms based on upper-limbs kinaesthetic motor imageries (KMI). However, it was not used to classify the left versus right foot KMI, due to its location inside the mesial wall of sensorimotor cortex, which makes it difficult to be detected. We report novel classification of mu and beta EEG features, during left and right foot KMI cognitive task, using CSP, and filter bank common spatial pattern (FBCSP) method, to optimize the subject-specific band selection. We initially proposed CSP method, followed by the implementation of FBCSP for optimization of individual spatial patterns, wherein a set of CSP filters was learned, for each of the time/frequency filters in a supervised way. This was followed by the log-variance feature extraction and concatenation of all features (over all chosen spectral-filters). Subsequently, supervised machine learning was implemented, i.e. logistic regression (Logreg) and linear discriminant analysis (LDA), in order to compare the respective foot KMI classification rates. Training and testing data, used in the model, was validated using 10-fold cross validation. Four methodology paradigms are reported, i.e. CSP LDA, CSP Logreg, and FBCSP LDA, FBCSP Logreg. All paradigms resulted in an average classification accuracy rate above the statistical chance level of 60.0% (P<0.01). On average, FBCSP LDA outperformed remaining paradigms with kappa score of 0.41 and classification accuracy of 70.28% 4.23. Similarly, this paradigm enabled discrimination between right and left foot KMI cognitive task at highest accuracy rate i.e. maximum 77.5% with kappa=0.55 and the area under ROC curve as 0.70 (in single-trial analysis). The proposed novel paradigms, using CSP and FBCSP, established a potential to exploit the left versus right foot imagery classification, in synchronous 2-class BCI for controlling robotic foot, or foot neuroprosthesis.","common spatial pattern (CSP),filter bank common spatial pattern (FBCSP),kinaesthetic motor imagery (KMI),brain-computer interface (BCI),EEG",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Radiology, Nuclear Medicine & Medical Imaging",,,"EEG,FILTERS,PERFORMANCE,INTERFACES,AGREEMENT,MOVEMENTS,DESIGN",BIOMEDICAL PHYSICS & ENGINEERING EXPRESS,https://doi.org/10.1088/2057-1976/ab54ad,
89,Prediction of pilling of polyester-cotton blended woven fabric using artificial neural network models,15,,,"Xiao Qi,Wang Rui,Zhang Shujie,Li Danyang,Sun Hongyu,Wang Limin","Xiao Q,Wang R,Zhang SJ,Li DY,Sun HY,Wang LM",Wang R,10.1177/1558925019900152,Tiangong University,"In this article, an intelligent pilling prediction model using back-propagation neural network model and an optimized model with genetic algorithm is introduced. Genetic algorithm is proposed in consideration of the initial weight and threshold of back-propagation artificial neural network, and further improves training speed and the accuracy for prediction pilling of polyester-cotton blended woven fabrics. The results show that the maximum numbers of training steps of the optimized model by genetic algorithm are reduced from 164 steps to 137 steps compared with that of back-propagation model. The training fitness of optimized model by genetic algorithm is improved from 0.914 to 0.945. The simulation fitness is increased from 0.912 to 0.987. And the root mean square error decreased from 1.0431 to 0.6842. The optimized model by genetic algorithm shows a better agreement between the experimental and predicted values.","Genetic algorithm,back propagation,artificial neural network,polyester-cotton blended woven fabric,pilling",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Materials Science,,1.516,"INTERLOCK,KNITTED,FABRICS,OPTIMIZATION,PERFORMANCE,TENDENCY",JOURNAL OF ENGINEERED FIBERS AND FABRICS,https://journals.sagepub.com/doi/pdf/10.1177/1558925019900152,
90,Identification of a Sixteen-gene Prognostic Biomarker for Lung Adenocarcinoma Using a Machine Learning Method,11,5,1288-1298,"Ma Baoshan,Geng Yao,Meng Fanyu,Yan Ge,Song Fengju","Ma BS,Geng Y,Meng FY,Yan G,Song FJ",Ma BS,10.7150/jca.34585,Dalian Maritime University,"Objectives: Lung adenocarcinoma (LUAD) accounts for a majority of cancer-related deaths worldwide annually. The identification of prognostic biomarkers and prediction of prognosis for LUAD patients is necessary.
Materials and Methods: In this study, LUAD RNA-Seq data and clinical data from the Cancer Genome Atlas (TCGA) were divided into TCGA cohort I (n = 338) and II (n = 168). The cohort I was used for model construction, and the cohort II and data from Gene Expression Omnibus (GSE72094 cohort, n = 393; GSE11969 cohort, n = 149) were utilized for validation. First, the survival-related seed genes were selected from the cohort I using the machine learning model (random survival forest, RSF), and then in order to improve prediction accuracy, the forward selection model was utilized to identify the prognosis-related key genes among the seed genes using the clinically-integrated RNA-Seq data. Second, the survival risk score system was constructed by using these key genes in the cohort II, the GSE72094 cohort and the GSE11969 cohort, and the evaluation metrics such as HR, p value and C index were calculated to validate the proposed method. Third, the developed approach was compared with the previous five prediction models. Finally, bioinformatics analyses (pathway, heatmap, protein-gene interaction network) have been applied to the identified seed genes and key genes.
Results and Conclusion: Based on the RSF model and clinically-integrated RNA-Seq data, we identified sixteen key genes that formed the prognostic gene expression signature. These sixteen key genes could achieve a strong power for prognostic prediction of LUAD patients in cohort II (HR = 3.80, p = 1.63e-06, C-index = 0.656), and were further validated in the GSE72094 cohort (HR = 4.12, p = 1.34e-10, C-index = 0.672) and GSE11969 cohort (HR = 3.87, p = 6.81 e-07, C-index = 0.670). The experimental results of three independent validation cohorts showed that compared with the traditional Cox model and the use of standalone RNA-Seq data, the machine-learning-based method effectively improved the prediction accuracy of LUAD prognosis, and the derived model was also superior to the other five existing prediction models. KEGG pathway analysis found eleven of the sixteen genes were associated with Nicotine addiction. Thirteen of the sixteen genes were reported for the first time as the LUAD prognosis-related key genes. In conclusion, we developed a sixteen-gene prognostic marker for LUAD, which may provide a powerful prognostic tool for precision oncology.","Lung adenocarcinoma,Prognosis prediction,RNA-Seq data,Random survival forest,Forward selection model",Article,"IVYSPRING INT PUBL, PO BOX 4546, LAKE HAVEN, NSW 2263, AUSTRALIA",Oncology,,4.277,"EXPRESSION,SIGNATURE,VARIABLE,SELECTION,CANCER,STATISTICS,GENE-EXPRESSION,SURVIVAL,PREDICTION,PARAMETERS,MICRORNA",JOURNAL OF CANCER,https://europepmc.org/articles/pmc6959071?pdf=render,
91,Efficient multi-output scene coordinate prediction for fast and accurate camera relocalization from a single RGB image,190,,,"Nam-Duong Duong,Soladie Catherine,Kacete Amine,Richard Pierre-Yves,Royan Jerome","Duong ND,Soladie C,Kacete A,Richard PY,Royan J",Duong ND,10.1016/j.cviu.2019.102850,"IRT B Com, 1219 Ave Champs Blancs, F-35510 Cesson Sevigne, France.","Camera relocalization refers to the problematic of the camera pose estimation including 3D translation and 3D rotation expressed in the world coordinate system with no temporal constraint. Camera relocalization is necessary in localization systems. However, it is still challenging to have both a real-time and accurate method. In this paper, we introduce our data-oriented hybrid method merging both machine learning and geometric approaches for fast and accurate camera relocalization from a single RGB image. We propose an efficient multi-output deep-forest regression based on a sparse feature detection, that uses a whole learned feature vector at each split function to improve the accuracy of 2D-3D point correspondences. Especially, multiple coordinate regression of our deep-forest allows to deal with ambiguous repetitive structure. The learned feature extraction is able to be pre-trained and reused for different scenes. The use of sparse feature detection reduces processing time and increases accuracy of predictions. Finally, we show favorable results in terms of accuracy and computational time compared to the state-of-the-art methods.","Camera relocalization,Deep forest regression,Scene coordinate prediction,Hybrid method,Split function",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Computer Science,Engineering",,3.532,,COMPUTER VISION AND IMAGE UNDERSTANDING,,
92,On identification of driving-induced stress using electroencephalogram signals: A framework based on wearable safety-critical scheme and machine learning,53,,66-79,"Halim Zahid,Rehan Mahma","Halim Z,Rehan M",Halim Z,10.1016/j.inffus.2019.06.006,"Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Machine Intelligence Res Grp MInG, Topi 23460, Pakistan.","Driving an automobile under high stress level reduces driver's control on vehicle and risk-assessment capabilities, often resulting in road accidents. Driver's anxiety therefore is a key factor to consider in accident prevention and road safety. This emphasizes the modern computing techniques to assist drivers by continuous stress level monitoring. Development of such a system requires designing a framework, which can recognize the drivers' affective state and take preventive measures to account for escalating stress level. This work presents a machine learning-based approach to identify driving-induced stress patterns. For this, electroencephalograph (EEG) signals are utilized as the physiological signals. The ongoing brain activity is logged as EEG signal to determine the link between brain dynamics and emotional states. Three classifiers are utilized in this work, namely: Support Vector Machine (SVM), Neural Network (NN), and Random Forest (RF) to classify EEG patterns on the basis of the subject's self-reported emotional states while driving in various situations. A framework is proposed to recognize emotions based on EEG patterns by systematically identifying emotion-specific features from the raw EEG signal and investigating the classifiers' effectiveness. A comprehensive analysis of various performance measures concludes that among the three classifiers employed in this study, SVM performs better to distinguish between rest and stress state. The evaluation obtained an average classification accuracy of 97.95% +/- 2.65%, precision of 89.23%, sensitivity of 88.83%, and specificity of 94.92%; when tested over 50 automotive drivers.","Information fusion,EEG,Emotion recognition,Driving-induced stress,Stress prediction",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,12.707,"NEGATIVE,EMOTIONS,MENTAL,STRESS,GAMMA-BAND,ANGER,DRIVERS,ASYMMETRY,RESPONSES,SYSTEM,IMPACT,ROAD",INFORMATION FUSION,,
93,Comparison of semi-automatic and deep learning-based automatic methods for liver segmentation in living liver transplant donors,26,1,11-21,"Kavur A. Emre,Gezer Naciye Sinem,Baris Mustafa,Sahin Yusuf,Ozkan Savas,Baydar Bora,Yuksel Ulas,Kilikcier Caglar,Olut Sahin,Akar Gozde Bozdagi","Kavur AE,Gezer NS,Baris M,Sahin Y,Ozkan S,Baydar B,Yuksel U,Kilikcier C,Olut S,Akar GB",Selver MA,10.5152/dir.2019.19025,Dokuz Eylul University,"PURPOSE
We aimed to compare the accuracy and repeatability of emerging machine learning-based (i.e., deep learning) automatic segmentation algorithms with those of well-established interactive semi-automatic methods for determining liver volume in living liver transplant donors at computed tomography (CT) imaging.
METHODS
A total of 12 methods (6 semi-automatic, 6 full-automatic) were evaluated. The semi-automatic segmentation algorithms were based on both traditional iterative models including watershed, fast marching, region growing, active contours arid modern techniques including robust statistics segmenter and super-pixels. These methods entailed some sort of interaction mechanism such as placing initialization seeds on images or determining a parameter range. The automatic methods were based on deep learning and included three framework templates (DeepMedic, NiftyNet and U-Net), the first two of which were applied with default parameter sets and the last two involved adapted novel model designs. For 20 living donors (8 training and 12 test datasets), a group of imaging scientists and radiologists created ground truths by performing manual segmentations on contrast-enhanced CT images. Each segmentation was evaluated using five metrics (i.e., volume overlap and relative volume errors, average/root-mean-square/maximum symmetrical surface distances). The results were mapped to a scoring system and a final grade was calculated by taking their average. Accuracy and repeatability were evaluated using slice-by-slice comparisons and volumetric analysis. Diversity and complementarily were observed through heatmaps. Majority voting (MV) and simultaneous truth and performance level estimation (STAPLE) algorithms were utilized to obtain the fusion of the individual results.
RESULTS
The top four methods were automatic deep learning models, with scores of 79.63, 79.46, 77.15, and 74.50. Intra-user score was determined as 95.14. Overall, automatic deep learning segmentation outperformed interactive techniques on all metrics. The mean volume of liver of ground truth was 1409.93 +/- 271.28 mL, while it was calculated as 1342.21 +/- 231.24 mL using automatic and 1201.26 +/- 258.13 mL using interactive methods, showing higher accuracy and less variation with automatic methods. The qualitative analysis of segmentation results showed significant diversity and complementarity, enabling the idea of using ensembles to obtain superior results. The fusion score of automatic methods reached 83.87 with MV and 86.20 with STAPLE, which my slightly less than fusion of all methods (MV, 86.70) and (STAPLE, 88.74).
CONCLUSION
Use of the new deep learning-based automatic segmentation algorithms substantially increases the accuracy and repeatability for segmentation and volumetric measurements of liver. Fusion of automatic methods based on ensemble approaches exhibits best results with almost no additional time cost due to potential parallel execution of multiple models.","CONVOLUTIONAL NEURAL-NETWORKS,ABDOMINAL ORGANS,VOLUME,MULTILEVEL,ACCURACY,MODEL,MRI,CNN",Article,"AVES, BUYUKDERE CAD 105-9, MECIDIYEKOY, SISLI, ISTANBUL 34394, TURKEY","Radiology, Nuclear Medicine & Medical Imaging",,2.591,"CONVOLUTIONAL,NEURAL-NETWORKS,ABDOMINAL,ORGANS,VOLUME,MULTILEVEL,ACCURACY,MODEL,MRI,CNN",DIAGNOSTIC AND INTERVENTIONAL RADIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7075579,
94,Radiologic-Radiomic Machine Learning Models for Differentiation of Benign and Malignant Solid Rena Masses: Comparison With Expert-Level Radiologists,214,1,W44-W54,"Sun Xue-Ying,Feng Qiu-Xia,Xu Xun,Zhang Jing,Zhu Fei-Peng,Yang Yan-Hao,Zhang Yu-Dong","Sun XY,Feng QX,Xu X,Zhang J,Zhu FP,Yang YH,Zhang YD",Zhang YD,10.2214/AJR.19.21617,Nanjing Medical University,"OBJECTIVE. The objective of our study was to compare the performance of radiologicradiomic machine learning (ML) models and expert-level radiologists for differentiation of benign and malignant solid renal masses using contrast-enhanced CT examinations.
MATERIALS AND METHODS. This retrospective study included a cohort of 254 renal cell carcinomas (RCCs) (190 clear cell RCCs [ccRCCs], 38 chromophobe RCCs [chrRCCs], and 26 papillary RCCs [pRCCs]), 26 fat-poor angioleiomyolipomas, and 10 oncocytomas with preoperative CT examinations. Lesions identified by four expert-level radiologists (> 3000 genitourinary CT and MRI studies) were manually segmented for radiologic-radiomic analysis. Disease-specific support vector machine radiologic-radiomic ML models for classification of renal masses were trained and validated using a 10-fold cross-validation. Performance values for the expert-level radiologists and radiologic-radiomic MI. models were compared using the McNemar test.
RESULTS. The performance values for the four radiologists were as follows: sensitivity of 73.7-96.8% (median, 845%; variance, 122.7%) and specificity of 48.4-71.9% (median, 61.8%; variance, 161.6%) for differentiating ccRa7s from pRCCs and chrRa:s; sensitivity of 73.7-96.8% (median, 84.5%; variance, 122.7%) and specificity of 52.8-88.9% for differentiating ccRCCs from fat-poor angioleiomyolipomas and oncocytomas (median, 80.6%; variance, 269.1%); and sensitivity of 28.1-60.9% (median, 84.5%; variance, 122.7%) and specificity of 75.0-88.9% for differentiating pRCCs and chrRCCs from fat-poor angioleiomyolipomas and oncocytomas (median, 50.0%; variance, 191.1%). After a 10-fold cross-validation, the radiologic-radiomic ML model yielded the following performance values for differentiating ccRa:s from pRa7s and chrRCCs, ccRCCs from fat-poor angioleiomyolipomas and oncocytomas, and pRCCs and chrRCCs from fat-poor angioleiomyolipomas and oncocytomas: a sensitivity of 90.0%, 86.3%, and 73.4% and a specificity of 89.1%, 83.3%, and 91.7%, respectively.
CONCLUSION. Expert-level radiologists had obviously large variances in performance for differentiating benign from malignant solid renal masses. Radiologic-radiomic ML can be a potential way to improve interreader concordance and performance.","expert-level decision performance,fat-poor angioleiomyolipoma,machine learning,oncocytoma,radiomics,renal cell carcinoma",Article,"AMER ROENTGEN RAY SOC, 44211 SLATESTONE CT, LEESBURG, VA USA","Radiology, Nuclear Medicine & Medical Imaging",,4.073,"CELL-CARCINOMA,NEPHROMETRY,SCORE,CLEAR-CELL,EXTERNAL,VALIDATION,CANCER,STATISTICS,TEXTURE,ANALYSIS,CT,ANGIOMYOLIPOMA,NOMOGRAM,SUBTYPES",AMERICAN JOURNAL OF ROENTGENOLOGY,,
95,Automated identification of cephalometric landmarks: Part 2-Might it be better than human?,90,1,69-76,"Hwang Hye-Won,Park Ji-Hoon,Moon Jun-Ho,Yu Youngsung,Kim Hansuk,Her Soo-Bok,Srinivasan Girish,Aljanabi Mohammed Noori A.,Donatelli Richard E.,Lee Shin-Jae","Hwang HW,Park JH,Moon JH,Yu Y,Kim H,Her SB,Srinivasan G,Aljanabi MNA,Donatelli RE,Lee SJ",Lee SJ,10.2319/022019-129.1,Seoul National University (SNU),"Objectives: To compare detection patterns of 80 cephalometric landmarks identified by an automated identification system (AI) based on a recently proposed deep-learning method, the You-Only-Look-Once version 3 (YOLOv3), with those identified by human examiners.
Materials and Methods: The YOLOv3 algorithm was implemented with custom modifications and trained on 1028 cephalograms. A total of 80 landmarks comprising two vertical reference points and 46 hard tissue and 32 soft tissue landmarks were identified. On the 283 test images, the same 80 landmarks were identified by AI and human examiners twice. Statistical analyses were conducted to detect whether any significant differences between AI and human examiners existed. Influence of image factors on those differences was also investigated.
Results: Upon repeated trials, AI always detected identical positions on each landmark, while the human intraexaminer variability of repeated manual detections demonstrated a detection error of 0.97 +/- 1.03 mm. The mean detection error between AI and human was 1.46 +/- 2.97 mm. The mean difference between human examiners was 1.50 +/- 1.48 mm. In general, comparisons in the detection errors between AI and human examiners were less than 0.9 mm, which did not seem to be clinically significant.
Conclusions: AI showed as accurate an identification of cephalometric landmarks as did human examiners. AI might be a viable option for repeatedly identifying multiple cephalometric landmarks.","Automated identification,Cephalometric landmarks,Artificial intelligence,Machine learning,Deep learning",Article,"E H ANGLE EDUCATION RESEARCH FOUNDATION, INC, 1615 BEACON ST, NEWTON N, MA 02468-1507 USA","Dentistry, Oral Surgery & Medicine",,2.599,"SOFT-TISSUE,RESPONSE,ORTHODONTIC,RESEARCH,REPORT,RELIABILITY,VALIDITY",ANGLE ORTHODONTIST,https://meridian.allenpress.com/angle-orthodontist/article-pdf/90/1/69/2391819/i0003-3219-90-1-69.pdf,
96,Machine learning in orthodontics: Introducing a 3D auto-segmentation and auto-landmark finder of CBCT images to assess maxillary constriction in unilateral impacted canine patients,90,1,77-84,"Chen Si,Wang Li,Li Gang,Wu Tai-Hsien,Diachina Shannon,Tejera Beatriz,Kwon Jane Jungeun,Lin Feng-Chang,Lee Yan-Ting,Xu Tianmin","Chen S,Wang L,Li G,Wu TH,Diachina S,Tejera B,Kwon JJ,Lin FC,Lee YT,Xu TM",Ko CC,10.2319/012919-59.1,"Sch Dent, Dept Orthodont, 275 Brauer Hall,CB 7450, Chapel Hill, NC USA.","Objectives: To (1) introduce a novel machine learning method and (2) assess maxillary structure variation in unilateral canine impaction for advancing clinically viable information.
Materials and Methods: A machine learning algorithm utilizing Learning-based multi-source IntegratioN frameworK for Segmentation (LINKS) was used with cone-beam computed tomography (CBCT) images to quantify volumetric skeletal maxilla discrepancies of 30 study group (SG) patients with unilaterally impacted maxillary canines and 30 healthy control group (CG) subjects. Fully automatic segmentation was implemented for maxilla isolation, and maxillary volumetric and linear measurements were performed. Analysis of variance was used for statistical evaluation.
Results: Maxillary structure was successfully auto-segmented, with an average dice ratio of 0.80 for three-dimensional image segmentations and a minimal mean difference of two voxels on the midsagittal plane for digitized landmarks between the manually identified and the machine learning-based (LINKS) methods. No significant difference in bone volume was found between impaction ([2.37 +/- 0.34] x 10(4) mm(3)) and nonimpaction ([2.36 +/- 0.35] x 10(4) mm(3)) sides of SG. The SG maxillae had significantly smaller volumes, widths, heights, and depths (P<.05) than CG.
Conclusions: The data suggest that palatal expansion could be beneficial for those with unilateral canine impaction, as underdevelopment of the maxilla often accompanies that condition in the early teen years. Fast and efficient CBCT image segmentation will allow large clinical data sets to be analyzed effectively.","Machine learning,CBCT,Canine impaction,Orthodontics,Image segmentation",Article,"E H ANGLE EDUCATION RESEARCH FOUNDATION, INC, 1615 BEACON ST, NEWTON N, MA 02468-1507 USA","Dentistry, Oral Surgery & Medicine",,2.599,"MAXILLARY,SEGMENTATION",ANGLE ORTHODONTIST,https://doi.org/10.2319/012919-59.1,
97,Machine learning and glioma imaging biomarkers,75,1,20-32,"Booth T. C.,Williams M.,Luis A.,Cardoso J.,Ashkan K.,Shuaib H.","Booth TC,Williams M,Luis A,Cardoso J,Ashkan K,Shuaib H",Booth TC,10.1016/j.crad.2019.07.001,Guy's & St Thomas' NHS Foundation Trust,"AIM: To review how machine learning (ML) is applied to imaging biomarkers in neurooncology, in particular for diagnosis, prognosis, and treatment response monitoring.
MATERIALS AND METHODS: The PubMed and MEDLINE databases were searched for articles published before September 2018 using relevant search terms. The search strategy focused on articles applying ML to high-grade glioma biomarkers for treatment response monitoring, prognosis, and prediction.
RESULTS: Magnetic resonance imaging (MRI) is typically used throughout the patient pathway because routine structural imaging provides detailed anatomical and pathological information and advanced techniques provide additional physiological detail. Using carefully chosen image features, ML is frequently used to allow accurate classification in a variety of scenarios. Rather than being chosen by human selection, ML also enables image features to be identified by an algorithm. Much research is applied to determining molecular profiles, histological tumour grade, and prognosis using MRI images acquired at the time that patients first present with a brain tumour. Differentiating a treatment response from a post-treatment-related effect using imaging is clinically important and also an area of active study (described here in one of two Special Issue publications dedicated to the application of ML in glioma imaging).
CONCLUSION: Although pioneering, most of the evidence is of a low level, having been obtained retrospectively and in single centres. Studies applying ML to build neuro-oncology monitoring biomarker models have yet to show an overall advantage over those using traditional statistical methods. Development and validation of ML models applied to neurooncology require large, well-annotated datasets, and therefore multidisciplinary and multicentre collaborations are necessary. (C) 2019 The Authors. Published by Elsevier Ltd on behalf of The Royal College of Radiologists.","CONCURRENT RADIATION-THERAPY,TRUE TUMOR PROGRESSION,HIGH-GRADE GLIOMA,BRAIN-TUMORS,RECURRENT GLIOBLASTOMA,MULTIPARAMETRIC MRI,RESPONSE ASSESSMENT,PATIENT SURVIVAL,PSEUDOPROGRESSION,DIFFERENTIATION",Review,"W B SAUNDERS CO LTD, 32 JAMESTOWN RD, LONDON NW1 7BY, ENGLAND","Radiology, Nuclear Medicine & Medical Imaging",,2.597,"CONCURRENT,RADIATION-THERAPY,TRUE,TUMOR,PROGRESSION,HIGH-GRADE,GLIOMA,BRAIN-TUMORS,RECURRENT,GLIOBLASTOMA,MULTIPARAMETRIC,MRI,RESPONSE,ASSESSMENT,PATIENT,SURVIVAL,PSEUDOPROGRESSION,DIFFERENTIATION",CLINICAL RADIOLOGY,https://europepmc.org/articles/pmc6927796?pdf=render,
98,Quality of science and reporting of radiomics in oncologic studies: room for improvement according to radiomics quality score and TRIPOD statement,30,1,523-536,"Park Ji Eun,Kim Donghyun,Kim Ho Sung,Park Seo Young,Kim Jung Youn,Cho Se Jin,Shin Jae Ho,Kim Jeong Hoon","Park JE,Kim D,Kim HS,Park SY,Kim JY,Cho SJ,Shin JH,Kim JH",Kim HS,10.1007/s00330-019-06360-z,University of Ulsan,"Objectives To evaluate radiomics studies according to radiomics quality score (RQS) and Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD) to provide objective measurement of radiomics research. Materials and methods PubMed and Embase were searched for studies published in high clinical imaging journals until December 2018 using the terms ""radiomics"" and ""radiogenomics."" Studies were scored against the items in the RQS and TRIPOD guidelines. Subgroup analyses were performed for journal type (clinical vs. imaging), intended use (diagnostic vs. prognostic), and imaging modality (CT vs. MRI), and articles were compared using Fisher's exact test and Mann-Whitney analysis. Results Seventy-seven articles were included. The mean RQS score was 26.1% of the maximum (9.4 out of 36). The RQS was low in demonstration of clinical utility (19.5%), test-retest analysis (6.5%), prospective study (3.9%), and open science (3.9%). None of the studies conducted a phantom or cost-effectiveness analysis. The adherence rate for TRIPOD was 57.8% (mean) and was particularly low in reporting title (2.6%), stating study objective in abstract and introduction (7.8% and 16.9%), blind assessment of outcome (14.3%), sample size (6.5%), and missing data (11.7%) categories. Studies in clinical journals scored higher and more frequently adopted external validation than imaging journals. Conclusions The overall scientific quality and reporting of radiomics studies is insufficient. Scientific improvements need to be made to feature reproducibility, analysis of clinical utility, and open science categories. Reporting of study objectives, blind assessment, sample size, and missing data is deemed to be necessary.","Neoplasm,Machine learning,Quality improvement,Computed tomography,Magnetic resonance imaging",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,4.87,"LYMPH-NODE,METASTASIS,LOWER-GRADE,GLIOMAS,PREOPERATIVE,PREDICTION,IMAGING,BIOMARKERS,MRI,FEATURES,LUNG,CLASSIFICATION,ACCURACY,SURVIVAL,RADIOGENOMICS",EUROPEAN RADIOLOGY,,
99,Radiomics machine-learning signature for diagnosis of hepatocellular carcinoma in cirrhotic patients with indeterminate liver nodules,30,1,558-570,"Mokrane Fatima-Zohra,Lu Lin,Vavasseur Adrien,Otal Philippe,Peron Jean-Marie,Luk Lyndon,Yang Hao,Ammari Samy,Saenger Yvonne,Rousseau Herve","Mokrane FZ,Lu L,Vavasseur A,Otal P,Peron JM,Luk L,Yang H,Ammari S,Saenger Y,Rousseau H",Mokrane FZ,10.1007/s00330-019-06347-w,CHU de Toulouse,"Purpose To enhance clinician's decision-making by diagnosing hepatocellular carcinoma (HCC) in cirrhotic patients with indeterminate liver nodules using quantitative imaging features extracted from triphasic CT scans. Material and methods We retrospectively analyzed 178 cirrhotic patients from 27 institutions, with biopsy-proven liver nodules classified as indeterminate using the European Association for the Study of the Liver (EASL) guidelines. Patients were randomly assigned to a discovery cohort (142 patients (pts.)) and a validation cohort (36 pts.). Each liver nodule was segmented on each phase of triphasic CT scans, and 13,920 quantitative imaging features (12 sets of 1160 features each reflecting the phenotype at one single phase or its change between two phases) were extracted. Using machine-learning techniques, the signature was trained and calibrated (discovery cohort), and validated (validation cohort) to classify liver nodules as HCC vs. non-HCC. Effects of segmentation and contrast enhancement quality were also evaluated. Results Patients were predominantly male (88%) and CHILD A (65%). Biopsy was positive for HCC in 77% of patients. LI-RADS scores were not different between HCC and non-HCC patients. The signature included a single radiomics feature quantifying changes between arterial and portal venous phases: V-Delta-A(_)DWT1_LL_Variance-2D and reached area under the receiver operating characteristic curve (AUC) of 0.70 (95%CI 0.61-0.80) and 0.66 (95%CI 0.64-0.84) in discovery and validation cohorts, respectively. The signature was influenced neither by segmentation nor by contrast enhancement. Conclusion A signature using a single feature was validated in a multicenter retrospective cohort to diagnose HCC in cirrhotic patients with indeterminate liver nodules. Artificial intelligence could enhance clinicians' decision by identifying a subgroup of patients with high HCC risk.","Cirrhosis,Radiomics,Hepatocellular carcinoma",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA","Radiology, Nuclear Medicine & Medical Imaging",,4.87,"MICROVASCULAR,INVASION,COMPUTED-TOMOGRAPHY,DATA,SYSTEM,20,MM,CT,SMALLER,VALIDATION,ACCURACY,CRITERIA,OUTCOMES",EUROPEAN RADIOLOGY,,
100,Knowledge elicitation based on genetic programming for non destructive testing of critical aerospace systems,102,,633-642,"D'Angelo Gianni,Palmieri Francesco","D'Angelo G,Palmieri F",D'Angelo G,10.1016/j.future.2019.09.007,University of Salerno,"In non-destructive testing of aerospace structures' defects, the tests reliability is a crucial issue for guaranteeing security of both aircrafts and passengers. Most of the widely recognized approaches rely on precision and reliability of testing equipment, but also the methods and techniques used for processing measurement results, in order to detect defects, may heavily influence the overall quality of the testing process. The effectiveness of such methods strongly depends on specific field knowledge that is definitely not easy to be formalized and codified within the results processing practices. Although many studies have been conducted in this direction, such issue is yet an open-problem. This work describes the use of Genetic Programming for the diagnosis and modeling of aerospace structural defects. The resulting approach aims at extracting such knowledge by providing a mathematical model of the considered defects, which can be used for recognizing other similar ones. Eddy-Current Testing has been selected as a case study in order to assess both the performance and functionality of the whole framework, and a publicly available dataset of specific measures for aircraft structures has been considered. The experimental results put into evidence the effectiveness of the proposed approach in building reliable models of the aforementioned defects, so that it can be considered a successful option for building the knowledge needed by tools for controlling the quality of critical aerospace systems. (C) 2019 Elsevier B.V. All rights reserved.","Evolutionary algorithm,Genetic algorithms (GA),Genetic programming (GP),Symbolic regression (SR),Artificial intelligence,Machine learning,Non-destructive testing (NDT),Eddy-current testing (ECT),Composite materials,Carbon-fiber reinforced plastic (CFRP),Carbon-fiber reinforced aluminum (FRA)",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,,"CLASSIFICATION,OPTIMIZATION",FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE,,
