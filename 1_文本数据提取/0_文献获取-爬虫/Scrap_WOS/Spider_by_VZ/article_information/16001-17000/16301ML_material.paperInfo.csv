,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Defect Classification With SVM and Wideband Excitation in Multilayer Aluminum Plates,69,1,241-248,"Pasadas Dario Jeronimo,Ramos Helena Geirinhas,Feng Bo,Baskaran Prashanth,Ribeiro Artur Lopes","Pasadas DJ,Ramos HG,Feng B,Baskaran P,Ribeiro AL",Pasadas DJ,10.1109/TIM.2019.2893009,Instituto de Telecomunicacoes,"This paper presents a nonconventional excitation method with white noise to detect surface and subsurface cracks in aluminum plates, and the performance of the method was compared with the multifrequency excitation method. In a second stage, the best excitation method was combined with the machine learning algorithm support vector machine (SVM) to classify the location and depth of subsurface cracks in multilayer aluminum structures. The experimental measurements were performed on two stacked aluminum plates with their thickness equal to 4 and 3 mm. Several experimental tests were performed for the classification of the subsurface crack location, as well as the depth classification of the cracks. The selected features to train and test the SVM algorithm for classification are reported in this paper. The results obtained from the SVM approach include a classification obtained by training 72 of the experimental measurement data with linear, quadratic, polynomial, and Gaussian radial basis kernels and by testing the remaining 28 of the collecting measurement data.","Support vector machines,Aluminum,Surface cracks,Probes,Testing,Current measurement,Eddy currents,Aluminum,cracks,eddy current,eddy current testing (ECT),multifrequency excitation,noise excitation,support vector machine (SVM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"MULTIFREQUENCY,INSPECTION,INVERSION",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
2,Identifying surface morphological characteristics to differentiate between mixtures of U3O8 synthesized from ammonium diuranate and uranyl peroxide,108,1,29-36,"Heffernan Sean T.,Ly Nhat-Cuong,Mower Brock J.,Vachet Clement,Schwerdt Ian J.,Tasdizen Tolga,McDonald Luther W.","Heffernan ST,Ly NC,Mower BJ,Vachet C,Schwerdt IJ,Tasdizen T,McDonald LW",McDonald LW,10.1515/ract-2019-3140,Utah System of Higher Education,"In the present study, surface morphological differences of mixtures of triuranium octoxide (U3O8), synthesized from uranyl peroxide (UO4) and ammonium diuranate (ADU), were investigated. The purity of each sample was verified using powder X-ray diffractometry (p-XRD), and scanning electron microscopy (SEM) images were collected to identify unique morphological features. The U3O8 from ADU and UO4 was found to be unique. Qualitatively, both particles have similar features being primarily circular in shape. Using the morphological analysis of materials (MAMA) software, particle shape and size were quantified. UO4 was found to produce U3O8 particles three times the area of those produced from ADU. With the starting morphologies quantified, U3O8 samples from ADU and UO4 were physically mixed in known quantities. SEM images were collected of the mixed samples, and the MAMA software was used to quantify particle attributes. As U3O8 particles from ADU were unique from UO4, the composition of the mixtures could be quantified using SEM imaging coupled with particle analysis. This provides a novel means of quantifying processing histories of mixtures of uranium oxides. Machine learning was also used to help further quantify characteristics in the image database through direct classification and particle segmentation using deep learning techniques based on Convolutional Neural Networks (CNN). It demonstrates that these techniques can distinguish the mixtures with high accuracy as well as showing significant differences in morphology between the mixtures. Results from this study demonstrate the power of quantitative morphological analysis for determining the processing history of nuclear materials.","Nuclear forensics,morphology,uranium oxide",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY","Chemistry,Nuclear Science & Technology",,1.265,"URANIUM,POWDERS",RADIOCHIMICA ACTA,,
3,Texture Analysis with 3.0-T MRI for Association of Response to Neoadjuvant Chemotherapy in Breast Cancer,294,1,31-41,"Eun Na Lae,Kang Daesung,Son Eun Ju,Park Jeong Seon,Youk Ji Hyun,Kim Jeong-Ah,Gweon Hye Mi","Eun NL,Kang D,Son EJ,Park JS,Youk JH,Kim JA,Gweon HM",Gweon HM,10.1148/radiol.2019182718,Yonsei University,"Background: Previous studies have suggested that texture analysis is a promising tool in the diagnosis, characterization, and assessment of treatment response in various cancer types. Therefore, application of texture analysis may be helpful for early prediction of pathologic response in breast cancer.
Purpose: To investigate whether texture analysis of features from MRI is associated with pathologic complete response (pCR) to neoadjuvant chemotherapy (NAC) in breast cancer.
Materials and Methods: This retrospective study included 136 women (mean age, 47.9 years; range, 31-70 years) who underwent NAC and subsequent surgery for breast cancer between January 2012 and August 2017. Patients were monitored with 3.0-T MRI before(pretreatment) and after (midtreatment) three or four cycles of NAC. Texture analysis was performed at pre- and midtreatment T2-weighted MRI, contrast material-enhanced T1-weighted MRI, diffusion-weighted MRI, and apparent diffusion coefficient (ADC)mapping by using commercial software. A random forest method was applied to build a predictive model for classifying those with pCR with use of texture parameters. Diagnostic performance for predicting pCR was assessed and compared with that of six other machine learning classifiers (adaptive boosting, decision tree, k-nearest neighbor, linear support vector machine, naive Bayes, and linear discriminant analysis) by using the Wald test and DeLong method.
Results: Forty of the 136 patients (29%) achieved pCR after NAC. In the prediction of pCR, the random forest classifier showed the lowest diagnostic performance with pretreatment ADC (area under the receiver operating characteristic curve [AUC], 0.53;95% confidence interval: 0.44, 0.61) and the highest diagnostic performance with midtreatment contrast-enhanced T1-weightedMRI (AUC, 0.82; 95% confidence interval: 0.74, 0.88) among pre- and midtreatment T2-weighted MRI, contrast-enhanced T1-weightedMRI, diffusion-weighted MRI, and ADC mapping.
Conclusion: Texture parameters using a random forest method of contrast-enhanced T1-weighted MRI at midtreatment of neoadjuvant chemotherapy were valuable and associated with pathologic complete response in breast cancer. (C) RSNA, 2019","PATHOLOGICAL RESPONSE,EARLY PREDICTION,DCE-MRI,TUMOR HETEROGENEITY,FEATURES,PROTOCOLS",Article,"RADIOLOGICAL SOC NORTH AMERICA, 820 JORIE BLVD, OAK BROOK, IL 60523 USA","Radiology, Nuclear Medicine & Medical Imaging",,10.389,"PATHOLOGICAL,RESPONSE,EARLY,PREDICTION,DCE-MRI,TUMOR,HETEROGENEITY,FEATURES,PROTOCOLS",RADIOLOGY,https://pubs.rsna.org/doi/pdf/10.1148/radiol.2019182718,
4,Online breath analysis using metal oxide semiconductor sensors (electronic nose) for diagnosis of lung cancer,14,1,,"Kononov Aleksandr,Korotetsky Boris,Jahatspanian Igor,Gubal Anna,Vasiliev Alexey,Arsenjev Andrey,Nefedov Andrey,Barchuk Anton,Gorbunov Ilya,Kozyrev Kirill","Kononov A,Korotetsky B,Jahatspanian I,Gubal A,Vasiliev A,Arsenjev A,Nefedov A,Barchuk A,Gorbunov I,Kozyrev K",Chuchina V,10.1088/1752-7163/ab433d,Saint Petersburg State University,"The analysis of exhaled breath is drawing a high degree of interest in the diagnostics of various diseases, including lung cancer. Electronic nose (E-nose) technology is one of the perspective approaches in the field due to its relative simplicity and cost efficiency. The use of an E-nose together with pattern recognition algorithms allow 'breath-prints' to be discriminated. The aim of this study was to develop an efficient online E-nose-based lung cancer diagnostic method via exhaled breath analysis with the use of some statistical classification methods. A developed multisensory system consisting of six metal oxide chemoresistance gas sensors was employed in three temperature regimes. This study involved 118 individuals: 65 in the lung cancer group (cytologically verified) and 53 in the healthy control group. The exhaled breath samples of the volunteers were analysed using the developed E-nose system. The dataset obtained, consisting of the sensor responses, was pre-processed and split into training (70%) and test (30%) subsets. The training data was used to fit the classification models; the test data was used for the estimation of prediction possibility. Logistic regression was found to be an adequate data-processing approach. The performance of the developed method was promising for the screening purposes (sensitivity-95.0%, specificity-100.0%, accuracy-97.2%). This shows the applicability of the gas-sensitive sensor array for the exhaled breath diagnostics. Metal oxide sensors are highly sensitive, low-cost and stable, and their poor sensitivity can be enhanced by integrating them with machine learning algorithms, as can be seen in this study. All experiments were carried out with the permission of the N.N. Petrov Research Institute of Oncology ethics committee no. 15/83 dated March 15, 2017.","breath analysis,early diagnostics,lung cancer,electronic nose,metal oxide sensors,volatile organic compounds",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biochemistry & Molecular Biology,Respiratory System",,3.421,"EXHALED,BREATH,BIOMARKERS,CLASSIFICATION,AIR,IMPLEMENTATION,IDENTIFICATION,SENSITIVITY,ORIGIN,ISSUES,ARRAY",JOURNAL OF BREATH RESEARCH,,
5,Estimating Stripping of Asphalt Coating Using k-Means Clustering and Machine Learning-Based Classification,34,1,,"Sahari Moghaddam Ashkan,Rezazadeh Azar Ehsan,Mejias Yolibeth,Bell Heather","Moghaddam AS,Azar ER,Mejias Y,Bell H",Azar ER,10.1061/(ASCE)CP.1943-5487.0000864,Lakehead University,"Stripping is a primary form of moisture-related damage in hot mix asphalt, which mainly results from a loss of bond between the asphalt cement and aggregate. Static immersion and boiling water tests are common methods to estimate stripping of bituminous cover from the aggregate surfaces in loose mixtures, but the accuracy of the assessment depends on the skill and experience of the technician; therefore, alternatives to subjective visual assessments were sought. Image processing methods are known to be reliable means for quality control in different areas and are able to address the inconsistency issues noted with manual assessment. This paper presents an automated image processing system developed to assess the stripping of asphalt coating from aggregate surfaces using the static immersion test. This framework uses a set of preprocessing methods to improve the contrast and lighting condition of the samples. Then it uses k-means algorithm to segment pixels with similar values on the surface of aggregates. Finally, two machine-learning methods were used to classify whether the resulting clusters represent an asphalt coated or uncoated area on the aggregate surfaces in a loose mixture image. This system was evaluated using 159 test samples and demonstrated promising performance, with a mean difference of 4.91% from the technician assessments and standard deviation of 6.50%. (c) 2019 American Society of Civil Engineers.","Asphalt cement,Stripping,Static immersion,Image processing,Machine learning",Article,"ASCE-AMER SOC CIVIL ENGINEERS, 1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA","Computer Science,Engineering",,3.992,"WARM,MIX,ASPHALT,BITUMEN",JOURNAL OF COMPUTING IN CIVIL ENGINEERING,,
6,Blood Gas Predictions for Patients Under Artificial Ventilation Using Fuzzy Logic Models,495,,192-211,"Indera-Putera S. H.,Mahfouf M.,Mills G. H.","Indera-Putera SH,Mahfouf M,Mills GH",Indera-Putera SH,10.1007/978-3-030-11292-9_10,University of Sheffield,"This paper proposes a new modelling framework for accurate predictions of arterial blood gases (ABG) of the previously developed SOPAVent model (Simulation of Patients under Artificial Ventilation). Three ABG parameters which were elicited from the SOPAVent model are the partial arterial pressure of oxygen (PaO2), the partial arterial pressure of carbon-dioxide (PaCO2) and the acid-base (pH). SOPAVent generate predictions of initial ABG and predictions of ABG after ventilator settings were modified. SOPAVent's sub-models, the relative dead space (Kd) and the carbon-dioxide production (VCO2) were designed using interval type-2 fuzzy logic system (IT2FLS). Further explorations of the models were carried out using fuzzy c-means clustering (FCM) and tuning of fuzzy parameters using 'new structure' particle swarm optimization algorithm (nPSO). The new models were integrated into the SOPAVent system for blood gas predictions. SOPAVent was validated using real intensive care unit (ICU) patient data, obtained from the Royal Hallamshire Hospital and Northern General Hospital, Sheffield (UK). The prediction accuracy of SOPAVent was compared with the pre-existing SOPAVent model where the Kd and VCO2 sub-models were developed using machine learning algorithms. Significant improvements in accuracy and correlation were achieved under this frameworks for PaCO2 and pH for both the initial ABG predictions and the post ventilator settings adjustments.","Data clustering,Interval type-2 fuzzy systems,Blood gases,Ventilator management",Proceedings Paper,"SPRINGER-VERLAG SINGAPORE PTE LTD, 152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE","Automation & Control Systems,Computer Science,Engineering,Robotics",,,"INTERVAL,TYPE-2",,,
7,A Machine Learning Approach for Delineating Similar Sound Symptoms of Respiratory Conditions on a Smartphone,495,,664-678,"Uwaoma Chinazunwa,Mansingh Gunjan","Uwaoma C,Mansingh G",Uwaoma C,10.1007/978-3-030-11292-9_33,Claremont Colleges,"Clinical characterization and interpretation of respiratory sound symptoms have remained a challenge due to the similarities in the audio properties that manifest during auscultation in medical diagnosis. The misinterpretation and conflation of these sounds coupled with the comorbidity cases of the associated ailments - particularly, exercised-induced respiratory conditions; result in the under-diagnosis and undertreatment of the conditions. Though several studies have proposed computerized systems for objective classification and evaluation of these sounds, most of the algorithms run on desktop and backend systems. In this study, we leverage the improved computational and storage capabilities of modern smartphones to distinguish the respiratory sound symptoms using machine learning algorithms namely: Random Forest (RF), Support Vector Machine (SVM), and k-Nearest Neighbour (k-NN). The appreciable performance of these classifiers on a mobile phone shows smartphone as an alternate tool for recognition and discrimination of respiratory symptoms in real-time scenarios. Further, the objective clinical data provided by the machine learning process could aid physicians in the screening and treatment of a patient during ambulatory care where specialized medical devices may not be readily available.","Respiratory conditions,Machine learning,Smartphone",Proceedings Paper,"SPRINGER-VERLAG SINGAPORE PTE LTD, 152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE","Automation & Control Systems,Computer Science,Engineering,Robotics",,,,,http://arxiv.org/pdf/2110.07895,
8,A novel region-based multimodal image fusion technique using improved dictionary learning,30,3,558-576,"Meher Bikash,Agrawal Sanjay,Panda Rutuparna,Dora Lingraj,Abraham Ajith","Meher B,Agrawal S,Panda R,Dora L,Abraham A",Panda R,10.1002/ima.22395,Veer Surendra Sai University of Technology,"Recently, the sparse representation (SR) based algorithms have gained much attention from the researchers in the area of image fusion (IF). The building of a compact discriminative dictionary plays a vital role in the sparse-based IF techniques. In this context, an efficient multimodal IF method based on improved dictionary learning is investigated. The key contributions of this paper are: (a) An improved KSVD algorithm is suggested for the dictionary learning process, (b) to reduce the computational time, only the informative patches are selected using energy feature, and (c) a novel region-based fusion scheme is suggested for the first time for the problem on hand. The suggested technique is tested with a number of multimodal images from Harvard Medical School brain database. The results are compared with state-of-the-art multiscale transform-based methods and modified SR-based methods. Unlike earlier methods, our proposed technique generates an adaptive dictionary through selection of informative patches only. This results in a compact dictionary with improved computational efficiency. The experimental results reveal that our approach outperforms other methods. The potential application of the suggested method could be in pathological images for follow-up study and better treatment planning.","dictionary learning,image fusion,region-based fusion,sparse representation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,PERFORMANCE,INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
9,Prediction and optimization of epoxy adhesive strength from a small dataset through active learning,20,1,1010-1021,"Pruksawan Sirawit,Lambard Guillaume,Samitsu Sadaki,Sodeyama Keitaro,Naito Masanobu","Pruksawan S,Lambard G,Samitsu S,Sodeyama K,Naito M",Lambard G; Naito M,10.1080/14686996.2019.1673670,National Institute for Materials Science,"Machine learning is emerging as a powerful tool for the discovery of novel high-performance functional materials. However, experimental datasets in the polymer-science field are typically limited and they are expensive to build. Their size (< 100 samples) limits the development of chemical intuition from experimentalists, as it constrains the use of machine-learning algorithms for extracting relevant information. We tackle this issue to predict and optimize adhesive materials by combining laboratory experimental design, an active learning pipeline and Bayesian optimization. We start from an initial dataset of 32 adhesive samples that were prepared from various molecular-weight bisphenol A-based epoxy resins and polyetheramine curing agents, mixing ratios and curing temperatures, and our data-driven method allows us to propose an optimal preparation of an adhesive material with a very high adhesive joint strength measured at 35.8???1.1?MPa after three active learning cycles (five proposed preparations per cycle). A Gradient boosting machine learning model was used for the successive prediction of the adhesive joint strength in the active learning pipeline, and the model achieved a respectable accuracy with a coefficient of determination, root mean square error and mean absolute error of 0.85, 4.0?MPa and 3.0?MPa, respectively. This study demonstrates the important impact of active learning to accelerate the design and development of tailored highly functional materials from very small datasets.","Materials informatics,active learning,adhesive joint strength,epoxy resin,crosslink network structure",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Materials Science,,6.963,STOICHIOMETRY,SCIENCE AND TECHNOLOGY OF ADVANCED MATERIALS,https://europepmc.org/articles/pmc6818118?pdf=render,
10,Data analytics approach for melt-pool geometries in metal additive manufacturing,20,1,972-978,"Lee Seulbi,Peng Jian,Shin Dongwon,Choi Yoon Suk","Lee S,Peng J,Shin D,Choi YS",Choi YS,10.1080/14686996.2019.1671140,United States Department of Energy (DOE),"Modern data analytics was employed to understand and predict physics-based melt-pool formation by fabricating Ni alloy single tracks using powder bed fusion. An extensive database of melt-pool geometries was created, including processing parameters and material characteristics as input features. Correlation analysis provided insight for relationships between process parameters and melt-pools, and enabled the development of meaningful machine learning models via the use of highly correlated features. We successfully demonstrated that data analytics facilitates understanding of the inherent physics and reliable prediction of melt-pool geometries. This approach can serve as a basis for the melt-pool control and process optimization.","Powder bed fusion (PBF) process,melt-pool,single track,machine learning,correlation analysis",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Materials Science,,6.963,"LASER,DENUDATION,ALGORITHM,FLOW",SCIENCE AND TECHNOLOGY OF ADVANCED MATERIALS,https://europepmc.org/articles/pmc6818108?pdf=render,
11,Unveiling the principle descriptor for predicting the electron inelastic mean free path based on a machine learning framework,20,1,1090-1102,"Liu Xun,Hou Zhufeng,Lu Dabao,Da Bo,Yoshikawa Hideki,Tanuma Shigeo,Sun Yang,Ding Zejun","Liu X,Hou ZF,Lu D,Da B,Yoshikawa H,Tanuma S,Sun Y,Ding ZJ",Ding ZJ,10.1080/14686996.2019.1689785,Chinese Academy of Sciences,"The TPP-2M formula is the most popular empirical formula for the estimation of the electron inelastic mean free paths (IMFPs) in solids from several simple material parameters. The TPP-2M formula, however, poorly describes several materials because it relies heavily on the traditional least-squares analysis. Herein, we propose a new framework based on machine learning to overcome the weakness. This framework allows a selection from an enormous number of combined terms (descriptors) to build a new formula that describes the electron IMFPs. The resulting framework not only provides higher average accuracy and stability but also reveals the physics meanings of several newly found descriptors. Using the identified principle descriptors, a complete physics picture of electron IMFPs is obtained, including both single and collective electron behaviors of inelastic scattering. Our findings suggest that machine learning is robust and efficient to predict the IMFP and has great potential in building a regression framework for data-driven problems. Furthermore, this method could be applicable to find empirical formula for given experimental data using a series of parameters given a priori, holds potential to find a deeper connection between experimental data and a priori parameters.","Surface science,machine learning,inelastic mean free path,the Least Absolute Shrinkage and Selection Operator (LASSO)",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Materials Science,,6.963,"ENERGY-LOSS,SPECTRA,SCATTERING,MODEL,SOLIDS,RANGE",SCIENCE AND TECHNOLOGY OF ADVANCED MATERIALS,https://www.tandfonline.com/doi/pdf/10.1080/14686996.2019.1689785?needAccess=true,
12,Sparse modeling of chemical bonding in binary compounds,20,1,1178-1188,"Kanda Yosuke,Fujii Hitoshi,Oguchi Tamio","Kanda Y,Fujii H,Oguchi T",Oguchi T,10.1080/14686996.2019.1697858,Osaka University,"A sparse model for quantifying energy difference between zinc-blende and rock-salt crystal structures in octet elemental and binary materials is constructed by using the linearly independent descriptor-generation method and exhaustive search, following the previous work by Ghiringhelli et al. [Phys Rev Lett. 2015;114:105503]. The obtained simplest model includes only atomic radius information of constituent atoms and its physical meaning is interpreted in relation to van Arkel-Ketelaar's triangle for classifying chemical bonding in binary compounds.","Sparse modeling,machine learning,chemical bonding,binary compounds",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Materials Science,,6.963,,SCIENCE AND TECHNOLOGY OF ADVANCED MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7006824,
13,A Multichannel 2D Convolutional Neural Network Model for Task-Evoked fMRI Data Classification,2019,,,"Hu Jinlong,Kuang Yuezhen,Liao Bin,Cao Lijie,Dong Shoubin,Li Ping","Hu JL,Kuang YZ,Liao B,Cao LJ,Dong SB,Li P",Hu JL,10.1155/2019/5065214,South China University of Technology,"Deep learning models have been successfully applied to the analysis of various functional MRI data. Convolutional neural networks (CNN), a class of deep neural networks, have been found to excel at extracting local meaningful features based on their shared-weights architecture and space invariance characteristics. In this study, we propose M2D CNN, a novel multichannel 2D CNN model, to classify 3D fMRI data. The model uses sliced 2D fMRI data as input and integrates multichannel information learned from 2D CNN networks. We experimentally compared the proposed M2D CNN against several widely used models including SVM, 1D CNN, 2D CNN, 3D CNN, and 3D separable CNN with respect to their performance in classifying task-based fMRI data. We tested M2D CNN against six models as benchmarks to classify a large number of time-series whole-brain imaging data based on a motor task in the Human Connectome Project (HCP). The results of our experiments demonstrate the following: (i) convolution operations in the CNN models are advantageous for high-dimensional whole-brain imaging data classification, as all CNN models outperform SVM; (ii) 3D CNN models achieve higher accuracy than 2D CNN and 1D CNN model, but 3D CNN models are computationally costly as any extra dimension is added in the input; (iii) the M2D CNN model proposed in this study achieves the highest accuracy and alleviates data overfitting given its smaller number of parameters as compared with 3D CNN.",,Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Mathematical & Computational Biology,Neurosciences & Neurology",,3.278,,COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE,https://doi.org/10.1155/2019/5065214,
14,,,,,,,,,,,,,,,,,,,,
15,Multicenter validation of a machine-learning algorithm for 48-h all-cause mortality prediction,26,3,1912-1925,"Mohamadlou Hamid,Panchavati Saarang,Calvert Jacob,Lynn-Palevsky Anna,Le Sidney,Allen Angier,Pellegrini Emily,Green-Saxena Abigail,Barton Christopher,Fletcher Grant","Mohamadlou H,Panchavati S,Calvert J,Lynn-Palevsky A,Le S,Allen A,Pellegrini E,Green-Saxena A,Barton C,Fletcher G",Calvert J,10.1177/1460458219894494,"Dascena Inc, 414 13th St,Suite 500, Oakland, CA 94612 USA.","In order to evaluate mortality predictions based on boosted trees, this retrospective study uses electronic medical record data from three academic health centers for inpatients 18 years or older with at least one observation of each vital sign. Predictions were made 12, 24, and 48 hours before death. Models fit to training data from each institution were evaluated using hold-out test data from the same institution, and from the other institutions. Gradient-boosted trees (GBT) were compared to regularized logistic regression (LR) predictions, support vector machine (SVM) predictions, quick Sepsis-Related Organ Failure Assessment (qSOFA), and Modified Early Warning Score (MEWS) using area under the receiver operating characteristic curve (AUROC). For training and testing GBT on data from the same institution, the average AUROCs were 0.96, 0.95, and 0.94 across institutional test sets for 12-, 24-, and 48-hour predictions, respectively. When trained and tested on data from different hospitals, GBT AUROCs achieved up to 0.98, 0.96, and 0.96, for 12-, 24-, and 48-hour predictions, respectively. Average AUROC for 48-hour predictions for LR, SVM, MEWS, and qSOFA were 0.85, 0.79, 0.86 and 0.82, respectively. GBT predictions may help identify patients who would benefit from increased clinical care.","electronic health record,machine learning,mortality,prediction",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA","Health Care Sciences & Services,Medical Informatics",,3.0,"EARLY,WARNING,SCORE,CRITICALLY-ILL,PATIENTS,HOSPITAL,MORTALITY,ILLNESS,SEVERITY,RISK,PREDICTION,ICU,ADMISSION,APACHE,SEPSIS,SYSTEM",HEALTH INFORMATICS JOURNAL,https://journals.sagepub.com/doi/pdf/10.1177/1460458219894494,
16,A novel method detecting the key clinic factors of portal vein system thrombosis of splenectomy & cardia devascularization patients for cirrhosis & portal hypertension,20,1,,"Wang Mingzhao,Ding Linglong,Xu Meng,Xie Juanying,Wu Shengli,Xu Shengquan,Yao Yingmin,Liu Qingguang","Wang MZ,Ding LL,Xu M,Xie JY,Wu SL,Xu SQ,Yao YM,Liu QG",Xie JY,10.1186/s12859-019-3233-3,Shaanxi Normal University,"Background: Portal vein system thrombosis (PVST) is potentially fatal for patients if the diagnosis is not timely or the treatment is not proper. There hasn't been any available technique to detect clinic risk factors to predict PVST after splenectomy in cirrhotic patients. The aim of this study is to detect the clinic risk factors of PVST for splenectomy and cardia devascularization patients for liver cirrhosis and portal hypertension, and build an efficient predictive model to PVST via the detected risk factors, by introducing the machine learning method. We collected 92 clinic indexes of splenectomy plus cardia devascularization patients for cirrhosis and portal hypertension, and proposed a novel algorithm named as RFA-PVST (Risk Factor Analysis for PVST) to detect clinic risk indexes of PVST, then built a SVM (support vector machine) predictive model via the detected risk factors. The accuracy, sensitivity, specificity, precision, F-measure, FPR (false positive rate), FNR (false negative rate), FDR (false discovery rate), AUC (area under ROC curve) and MCC (Matthews correlation coefficient) were adopted to value the predictive power of the detected risk factors. The proposed RFA-PVST algorithm was compared to mRMR, SVM-RFE, Relief, S-weight and LLEScore. The statistic test was done to verify the significance of our RFA-PVST.
Results: Anticoagulant therapy and antiplatelet aggregation therapy are the top-2 risk clinic factors to PVST, followed by D-D (D dimer), CHOL (Cholesterol) and Ca (calcium). The SVM (support vector machine) model built on the clinic indexes including anticoagulant therapy, antiplatelet aggregation therapy, RBC (Red blood cell), D-D, CHOL, Ca, TT (thrombin time) and Weight factors has got pretty good predictive capability to PVST. It has got the highest PVST predictive accuracy of 0.89, and the best sensitivity, specificity, precision, F-measure, FNR, FPR, FDR and MCC of 1, 0.75, 0.85, 0.92, 0, 0.25, 0.15 and 0.8 respectively, and the comparable good AUC value of 0.84. The statistic test results demonstrate that there is a strong significant difference between our RFA-PVST and the compared algorithms, including mRMR, SVM-RFE, Relief, S-weight and LLEScore, that is to say, the risk indicators detected by our RFA-PVST are statistically significant.
Conclusions: The proposed novel RFA-PVST algorithm can detect the clinic risk factors of PVST effectively and easily. Its most contribution is that it can display all the clinic factors in a 2-dimensional space with independence and discernibility as y-axis and x-axis, respectively. Those clinic indexes in top-right corner of the 2-dimensional space are detected automatically as risk indicators. The predictive SVM model is powerful with the detected clinic risk factors of PVST. Our study can help medical doctors to make proper treatments or early diagnoses to PVST patients. This study brings the new idea to the study of clinic treatment for other diseases as well.","Liver cirrhosis,Portal vein system thrombosis (PVST),Portal hypertension,Splenectomy,Cardia devascularization,Feature selection,SVM,Discernibility,Independence,Risk degree",Article; Proceedings Paper,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,"RISK-FACTORS,FEATURE-SELECTION,VENOUS,SYSTEM,LAPAROSCOPIC,SPLENECTOMY,SPLENIC,VEIN,ANTICOAGULATION,CLASSIFICATION,DISEASE,EFFICIENT,MODEL",BMC BIOINFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6936084,
17,Breast tumor classification through learning from noisy labeled ultrasound images,47,3,1048-1057,"Cao Zhantao,Yang Guowu,Chen Qin,Chen Xiaolong,Lv Fengmao","Cao ZT,Yang GW,Chen Q,Chen XL,Lv FM",Lv FM,10.1002/mp.13966,Southwestern University of Finance & Economics - China,"Purpose To train deep learning models to differentiate benign and malignant breast tumors in ultrasound images, we need to collect many training samples with clear labels. In general, biopsy results can be used as benign/malignant labels. However, most clinical samples generally do not have biopsy results. Previous works have proposed generating benign/malignant labels according to Breast Imaging, Reporting and Data System (BI-RADS) ratings. However, this approach will cause noisy labels, which means that the benign/malignant labels produced from BI-RADS diagnoses may be inconsistent with the ground truths. Consequently, deep models will overfit the noisy labels and hence obtain poor generalization performance. In this work, we mainly focus on how to reduce the negative effect of noisy labels when they are used to train breast tumor classification models. Methods We propose an effective approach called noise filter network (NF-Net) to address the problem of noisy labels when training breast tumor classification models. Specifically, to prevent deep models from overfitting the noisy labels, we propose incorporating two softmax layers for classification. Additionally, to strengthen the effect of clean labels, we design a teacher-student module for distilling the knowledge of clean labels. Results We conduct extensive comparisons with the existing works on addressing noisy labels. Our method achieves a classification accuracy of 73%, with a precision of 69%, recall of 80%, and F1-score of 0.74. This result is significantly better than those of the existing state-of-the-art works on addressing noisy labels. Conclusions This work provides a means to overcome the label shortage problem in training breast tumor classification models. Specifically, we can generate benign/malignant labels according to the BI-RADS ratings. Although this approach will cause noisy labels, the design of NF-Net can effectively reduce the negative effect of such labels.","breast ultrasound image,deep leaning,weakly supervised learning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"BI-RADS,MAMMOGRAPHY,DIAGNOSIS,NETWORK,RISK",MEDICAL PHYSICS,,
18,Design and Development of Lubricating Material Database and Research on Performance Prediction Method of Machine Learning,9,,,"Jia Dan,Duan Haitao,Zhan Shengpeng,Jin Yongliang,Cheng Bingxue,Li Jian","Jia D,Duan HT,Zhan SP,Jin YL,Cheng BX,Li J",Duan HT; Li J,10.1038/s41598-019-56776-2,"Wuhan Res Inst Mat Protect, State Key Lab Special Surface Protect Mat & Appli, Wuhan, Peoples R China.","Long developing period and cumbersome evaluation for the lubricating materials performance seriously jeopardize the successful development and application of any database system in tribological field. Such major setback can be solved effectively by implementing approaches with high throughput calculation. However, it often involves with vast number of output files, which are computed on the basis of first principle computation, having different data format from that of their experimental counterparts. Commonly, the input, storage and management of first principle calculation files and their individually test counterparts, implementing fast query and display in the database, adding to the use of physical parameters, as predicted with the performance estimated by first principle approach, may solve such setbacks. Investigation is thus performed for establishing database website specifically for lubricating materials, which satisfies both data: (i) as calculated on the basis of first principles and (ii) as obtained by practical experiment. It further explores preliminarily the likely relationship between calculated physical parameters of lubricating oil and its respectively tribological and anti-oxidative performance as predicted by lubricant machine learning model. Success of the method facilitates in instructing the obtainment of optimal design, preparation and application for any new lubricating material so that accomplishment of high performance is possible.",STABILITY,Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,5.134,STABILITY,SCIENTIFIC REPORTS,https://europepmc.org/articles/pmc6937319?pdf=render,
19,DeepFHR: intelligent prediction of fetal Acidemia using fetal heart rate signals based on convolutional neural network,19,1,,"Zhao Zhidong,Deng Yanjun,Zhang Yang,Zhang Yefei,Zhang Xiaohong,Shao Lihuan","Zhao ZD,Deng YJ,Zhang Y,Zhang YF,Zhang XH,Shao LH",Zhao ZD,10.1186/s12911-019-1007-5,Hangzhou Dianzi University,"Background: Fetal heart rate (FHR) monitoring is a screening tool used by obstetricians to evaluate the fetal state. Because of the complexity and non-linearity, a visual interpretation of FHR signals using common guidelines usually results in significant subjective inter-observer and intra-observer variability. Objective: Therefore, computer aided diagnosis (CAD) systems based on advanced artificial intelligence (AI) technology have recently been developed to assist obstetricians in making objective medical decisions.
Methods: In this work, we present an 8-layer deep convolutional neural network (CNN) framework to automatically predict fetal acidemia. After signal preprocessing, the input 2-dimensional (2D) images are obtained using the continuous wavelet transform (CWT), which provides a better way to observe and capture the hidden characteristic information of the FHR signals in both the time and frequency domains. Unlike the conventional machine learning (ML) approaches, this work does not require the execution of complex feature engineering, i.e., feature extraction and selection. In fact, 2D CNN model can self-learn useful features from the input data with the prerequisite of not losing informative features, representing the tremendous advantage of deep learning (DL) over ML.
Results: Based on the test open-access database (CTU-UHB), after comprehensive experimentation, we achieved better classification performance using the optimal CNN configuration compared to other state-of-the-art methods: the averaged ten-fold cross-validation of the accuracy, sensitivity, specificity, quality index defined as the geometric mean of the sensitivity and specificity, and the area under the curve yielded results of 98.34, 98.22, 94.87, 96.53 and 97.82%, respectively
Conclusions: Once the proposed CNN model is successfully trained, the corresponding CAD system can be served as an effective tool to predict fetal asphyxia objectively and accurately.","Fetal acidemia,Computer aided diagnosis system,Continuous wavelet transform,Convolutional neural network,Fetal heart rate",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Medical Informatics,,3.394,"RECORDINGS,AGREEMENT,CLASSIFICATION,FEATURES,MODEL",BMC MEDICAL INFORMATICS AND DECISION MAKING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6937790,
20,Sleep EEG signal analysis based on correlation graph similarity coupled with an ensemble extreme machine learning algorithm,138,,,"Abdulla Shahab,Diykh Mohammed,Laft Raid Luaibi,Saleh Khalid,Deo Ravinesh C.","Abdulla S,Diykh M,Laft RL,Saleh K,Deo RC",Abdulla S,10.1016/j.eswa.2019.07.007,University of Southern Queensland,"Background: Sleep plays an essential role in repairing and healing human mental and physical health. Developing an efficient method for scoring electroencephalogram (EEG) sleep stages is expected to help medical specialists in the early diagnosis of sleep disorders.
Method: In this paper, a novel technique is proposed for classifying sleep stages EEG signals using correlation graphs. First, each 30 s EEG segment is divided into a set of sub-segments. The dimensionality of each sub-segment is reduced by using a statistical model. Second, each EEG segment is transferred into a graph considering each sub-segment as a node in a graph, and a link between each pair of nodes is calculated based on their correlation coefficient. Graph's modularity is used as input features into an ensemble classifier.
Results: Different community detection algorithm based correlation graph are investigated to discern the most effective features to reveal the differences between EEG sleep stages. A combination of various classification techniques: a least square vector machine (LS-SVM), k-means, Naive Bayes, Fuzzy C-means, k-nearest, and logistic regression are tested using multi criteria decision making (MCDM) to design an ensemble classifier. Based on the results of the MCDM, the best four: LS-SVM, Naive Bayes, logistic regression and k-nearest are integrated, to finally utilise as an ensemble classifier to categorise the graph's characteristics. The results obtained from the ensemble classifier are compared with those from the individual classifiers. The performance of the proposed method is compared with state of the art of sleep stages classification. The experimental results showed that the EEG sleep classification based on correlation graphs are able to achieve better recognition results than the existing state of the art techniques. (C) 2019 Elsevier Ltd. All rights reserved.","Community detection,EEG signal,Sleep stages classification,Ensemble model,Correlation coefficient",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"COMPLEX,NETWORKS,APPROACH,STAGE,CLASSIFICATION,K-MEANS,FEATURES,SYSTEM",EXPERT SYSTEMS WITH APPLICATIONS,,
21,Cardiac substructure segmentation with deep learning for improved cardiac sparing,47,2,576-586,"Morris Eric D.,Ghanem Ahmed I.,Dong Ming,Pantelic Milan V.,Walker Eleanor M.,Glide-Hurst Carri K.","Morris ED,Ghanem AI,Dong M,Pantelic MV,Walker EM,Glide-Hurst CK",Glide-Hurst CK,10.1002/mp.13940,"Henry Ford Canc Inst, Dept Radiat Oncol, Detroit, MI 48202 USA.","Purpose Radiation dose to cardiac substructures is related to radiation-induced heart disease. However, substructures are not considered in radiation therapy planning (RTP) due to poor visualization on CT. Therefore, we developed a novel deep learning (DL) pipeline leveraging MRI's soft tissue contrast coupled with CT for state-of-the-art cardiac substructure segmentation requiring a single, non-contrast CT input. Materials/methods Thirty-two left-sided whole-breast cancer patients underwent cardiac T2 MRI and CT-simulation. A rigid cardiac-confined MR/CT registration enabled ground truth delineations of 12 substructures (chambers, great vessels (GVs), coronary arteries (CAs), etc.). Paired MRI/CT data (25 patients) were placed into separate image channels to train a three-dimensional (3D) neural network using the entire 3D image. Deep supervision and a Dice-weighted multi-class loss function were applied. Results were assessed pre/post augmentation and post-processing (3D conditional random field (CRF)). Results for 11 test CTs (seven unique patients) were compared to ground truth and a multi-atlas method (MA) via Dice similarity coefficient (DSC), mean distance to agreement (MDA), and Wilcoxon signed-ranks tests. Three physicians evaluated clinical acceptance via consensus scoring (5-point scale). Results The model stabilized in 19 h (200 epochs, training error <0.001). Augmentation and CRF increased DSC 5.0 +/- 7.9% and 1.2 +/- 2.5%, across substructures, respectively. DL provided accurate segmentations for chambers (DSC = 0.88 +/- 0.03), GVs (DSC = 0.85 +/- 0.03), and pulmonary veins (DSC = 0.77 +/- 0.04). Combined DSC for CAs was 0.50 +/- 0.14. MDA across substructures was <2.0 mm (GV MDA = 1.24 +/- 0.31 mm). No substructures had statistical volume differences (P > 0.05) to ground truth. In four cases, DL yielded left main CA contours, whereas MA segmentation failed, and provided improved consensus scores in 44/60 comparisons to MA. DL provided clinically acceptable segmentations for all graded patients for 3/4 chambers. DL contour generation took 14 s per patient. Conclusions These promising results suggest DL poses major efficiency and accuracy gains for cardiac substructure segmentation offering high potential for rapid implementation into RTP for improved cardiac sparing.","cardiotoxicity,deep learning,magnetic resonance imaging,radiotherapy,segmentation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"WHOLE,HEART,SEGMENTATION,CELL,LUNG-CANCER,CORONARY-ARTERY,RADIATION-THERAPY,RADIOTHERAPY,VALIDATION,TOXICITY,ATLAS,RISK,ASSOCIATION",MEDICAL PHYSICS,https://europepmc.org/articles/pmc7282198?pdf=render,
22,Synthesizing images from multiple kernels using a deep convolutional neural network,47,2,422-430,"Missert Andrew D.,Yu Lifeng,Leng Shuai,Fletcher Joel G.,McCollough Cynthia H.","Missert AD,Yu LF,Leng S,Fletcher JG,McCollough CH",McCollough CH,10.1002/mp.13918,Mayo Clinic,"Purpose Filtering measured projections with a particular convolutional kernel is an essential step in analytic reconstruction of computed tomography (CT) images. A tradeoff between noise and spatial resolution exists for different choices of reconstruction kernel. In a clinical setting, this often requires producing multiple images reconstructed with different kernels for a single CT exam, which increases the burden of computation, networking, archival, and reading. We address this problem by training a deep convolutional neural network (CNN) to synthesize multiple input images into a single output image which exhibits low noise while also preserving features in images reconstructed with the sharpest kernels. Methods A CNN architecture consisting of repeated blocks of residual units containing a total of 20 convolutional layers was used to combine features. The CNN inputs consisted of two images produced with different reconstruction kernels, one smooth and one sharp, which were stacked in the channel dimension. The network was trained using supervised learning with both full-dose and simulated quarter-dose abdominal CT images. After training, the performance was evaluated using a reserved set of full-dose scans that were not used for network optimization. Noise reduction performance was measured by comparing root mean square (RMS) measurements in uniform regions. Spatial resolution was compared using line profiles of anatomic features. Results For the regions tested, the synthetic images feature noise levels slightly below those of the smooth input images, while maintaining the resolution of anatomic details found in the sharp input images. Conclusions A deep CNN can be used combine features from CT images reconstructed with different kernels to produce a single synthesized image series that exhibits both low noise and high spatial resolution. This approach has implications for improving image quality, reducing radiation dose, and simplifying the clinical workflow for CT imaging.","convolutional neural networks,deep learning,image processing,noise reduction",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"LOW-DOSE,CT",MEDICAL PHYSICS,,
23,Cat Swarm Fractional Calculus optimization-based deep learning for artifact removal from EEG signal,32,6,939-958,"Anem Jayalaxmi,Kumar G. Sateesh,Madhu R.","Anem J,Kumar GS,Madhu R",Anem J,10.1080/0952813X.2019.1704438,"Aditya Inst Technol & Management, Tekkali, India.","Electroencephalogram (EEG) signals are commonly used in analysing the brain activity. The EEG signals have small amplitude and hence, they are often affected by the artefacts. For the efficient processing, it is necessary to remove the artefacts from the EEG signals. This paper develops a technique through deep learning scheme for removing the artefacts present in the EEG signal. Initially, the EEG signals are pre-processed and provided to the feature extraction process, where the wavelet features are extracted from the signal by applying the wavelet transform. The extracted features are provided to the proposed classifier, namely deep-ConvLSTM, for removing the artefacts from the EEG signal. Here, the deep learner is trained based on the proposed Cat Swarm Fractional Calculus Optimisation (CSFCO) algorithm, which is the integration of Cat Swarm Optimisation (CSO) and Fractional Calculus (FC). Experimentation of the proposed technique is carried out by introducing artefacts, such as ECG, EMG, EOG and random noise on the EEG signal. Simulation results carried out on the proposed deep-ConvLSTM depict that the proposed framework has better performance than the comparative techniques with the values of 3888.362, 62.356, and 69.939 dB, for the MSE, RMSE, and SNR, respectively.","EEG signal,artefacts,wavelet transform,deep learner,LSTM network",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Computer Science,,2.199,"OCULAR,ARTIFACTS,BAT,ALGORITHM,CLASSIFICATION",JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE,,
24,Convolutional neural network in the detection of lung carcinoma using transfer learning approach,30,2,445-454,"Lakshmi D.,Thanaraj K. Palani,Arunmozhi M.","Lakshmi D,Thanaraj KP,Arunmozhi M",Lakshmi D,10.1002/ima.22394,"St. Joseph's College of Engineering, Chennai","Background Lung carcinoma is the leading cause of 1.76 million deaths worldwide. GLOBOCAN 2018 report says lung cancer occupies the first position in terms of incidence and mortality rate. Reasons include limited access to timely diagnosis and treatment. Objective This research work presents the viability of using convolutional neural network (CNN) for lung carcinoma detection. The proposed network automatically detects the lung carcinomas tissues through transfer learning without the difficulty of specifying features for image classification. Subjects and methods The study involves lung CT images of 12 male and 4 female subjects, aging between 35 and 77 years. These images are obtained in Bitmap image format with a resolution of 512 x 512. Two cases namely healthy and carcinoma are taken for study. Carcinoma cases include poorly differentiated carcinoma, moderately differentiated carcinoma. The training data consists of 800 lung CT slices, validation set consists of 100 CT images, and test data consist of 100 images, respectively. Results Experimental results demonstrate the VGG16 and VGG 19 network implementation with the area under the receiver operating characteristics of 0.930 and 0.90, respectively. VGG19 compete well with a sensitivity and specificity of 80% and 100% compared to VGG16 with 98% and 88%, respectively. Conclusion Hence, the implementation of VGG16 and VGG19 with good accuracy proves that CNN used for lung carcinoma detection leading to timely diagnosis and treatment may decrease the mortality rate.","convolution neural network,transfer learning approach",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,,"NODULE,DETECTION,CLASSIFICATION",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
25,Decoding visual network-related dynamic functional connectivity for eyes-open and eyes-closed using machine learning,30,2,455-463,"Wang Xun-Heng,Jiao Yun,Li Lihua","Wang XH,Jiao Y,Li LH",Wang XH,10.1002/ima.22396,Hangzhou Dianzi University,"Eyes-open (EO) and eyes-closed (EC) are the two experimental conditions during resting state functional magnetic resonance imaging (fMRI) scan sessions. However, the dynamic neural mechanisms of EO/EC based on intrinsic connectivity networks (ICNs) remains largely unexplored. This paper aimed to decode the dynamic internetwork neural mechanisms for EO/EC using data mining and to identify EO/EC resting state fMRI scans based on machine learning. To achieve these goals, the two states were analyzed using the discriminative models, resulting in total accuracy of 85.87%, a sensitivity of 91.3%, and a specificity of 80.43%. In addition, the discriminative features discovered using data mining were related to previous findings. In summary, we applied visual network-related inter-ICN features to decode the neural mechanisms of EO/EC. The reproducible results suggested that visual network-related inter-ICN dynamic features could be beneficial for decoding visual attentions, and had potential as neuroimaging-markers to identify EO/EC resting state fMRI scans.","data mining,dynamic functional connectivity,eyes-open,closed,neural mechanisms",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,"RESTING-STATE,TEMPORAL,PATTERNS,IMPACT",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
26,Electronic Nose and Its Applications: A Survey,17,2,179-209,"Karakaya Diclehan,Ulucan Oguzhan,Turkan Mehmet","Karakaya D,Ulucan O,Turkan M",Turkan M,10.1007/s11633-019-1212-9,Izmir Ekonomi Universitesi,"In the last two decades, improvements in materials, sensors and machine learning technologies have led to a rapid extension of electronic nose (EN) related research topics with diverse applications. The food and beverage industry, agriculture and forestry, medicine and health-care, indoor and outdoor monitoring, military and civilian security systems are the leading fields which take great advantage from the rapidity, stability, portability and compactness of ENs. Although the EN technology provides numerous benefits, further enhancements in both hardware and software components are necessary for utilizing ENs in practice. This paper provides an extensive survey of the EN technology and its wide range of application fields, through a comprehensive analysis of algorithms proposed in the literature, while exploiting related domains with possible future suggestions for this research topic.","Artificial intelligence,machine learning,pattern recognition,electronic nose (EN),sensors technology",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND","Automation & Control Systems,Computer Science",,,"QUARTZ-CRYSTAL-MICROBALANCE,ARTIFICIAL,NEURAL-NETWORKS,PARTIAL,LEAST-SQUARES,GAS,SENSOR,ARRAYS,BIOELECTRONIC,NOSE,MYCOBACTERIUM-TUBERCULOSIS,OLFACTORY,SYSTEM,ROASTING,DEGREE,LEARNING-METHOD,QUALITY-CONTROL",INTERNATIONAL JOURNAL OF AUTOMATION AND COMPUTING,https://link.springer.com/content/pdf/10.1007/s11633-019-1212-9.pdf,
27,Prediction of the Strength of Rubberized Concrete by an Evolved Random Forest Model,2019,,,"Sun Yuantian,Li Guichen,Zhang Junfei,Qian Deyu","Sun YT,Li GC,Zhang JF,Qian DY",Li GC,10.1155/2019/5198583,China University of Mining & Technology,"Rubberized concrete (RC) has attracted more attention these years as it is an economical and environmental-friendly construction material. Normally, the uniaxial compressive strength (UCS) of RC needs to be evaluated before application. In this study, an evolutionary random forest model (BRF) combining random forest (RF) and beetle antennae search (BAS) algorithms was proposed, which can be used for establishing the relationship between UCS of RC and its key variables. A total number of 138 cases were collected from the literature to develop and validate the BRF model. The results showed that the BAS can tune the RF effectively, and therefore, the hyperparameters of RF were obtained. The proposed BRF model can accurately predict the UCS of RC with a high correlation coefficient (0.96). Furthermore, the variable importance was determined, and the results showed that the age of RC is the most significant variable, followed by water-cement ratio, fine rubber aggregate, coarse rubber aggregate, and coarse aggregate. This study provides a new method to access the strength of RC and can efficiently guide the design of RC in practice.","UNCONFINED COMPRESSIVE STRENGTH,MECHANICAL-PROPERTIES,DURABILITY PROPERTIES,NEURAL-NETWORK,MODULUS,MIXTURE",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Construction & Building Technology,Engineering",,1.923,"UNCONFINED,COMPRESSIVE,STRENGTH,MECHANICAL-PROPERTIES,DURABILITY,PROPERTIES,NEURAL-NETWORK,MODULUS,MIXTURE",ADVANCES IN CIVIL ENGINEERING,https://downloads.hindawi.com/journals/ace/2019/5198583.pdf,
28,Predicting structure/property relationships in multi-dimensional nanoparticle data using t-distributed stochastic neighbour embedding and machine learning,11,48,23165-23172,"Barnard A. S.,Opletal G.","Barnard AS,Opletal G",Barnard AS,10.1039/c9nr03940f,Commonwealth Scientific & Industrial Research Organisation (CSIRO),"Combining researchers' domain expertise and advanced dimension reduction methods we demonstrate how visually comparing the distribution of nanoparticles mapped from multiple dimensions to a two dimensional plane can rapidly identify possible single-structure/property relationships and to a lesser extent multi-structure/property relationships. These relationships can be further investigated and confirmed with machine learning, using genetic programming to inform the choice of property-specific models and their hyper-parameters. In the case of our nanodiamond case study, we visually identify and confirm a strong relationship between the size and the probability of observation (stability) and a more complicated (and visually ambiguous) relationship between the ionisation potential and band gaps with a range of different structural, chemical and statistical surface features, making it more difficult to engineer in practice.","NANODIAMONDS,IMPACT",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,,"NANODIAMONDS,IMPACT",NANOSCALE,,
29,A Machine-Learning-Based Approach to Solve Both Contact Location and Force in Soft Material Tactile Sensors,7,4,409-420,"Massari Luca,Schena Emiliano,Massaroni Carlo,Saccomandi Paola,Menciassi Arianna,Sinibaldi Edoardo,Oddo Calogero Maria","Massari L,Schena E,Massaroni C,Saccomandi P,Menciassi A,Sinibaldi E,Oddo CM",Sinibaldi E,10.1089/soro.2018.0172,Istituto Italiano di Tecnologia - IIT,"This study addresses a design and calibration methodology based on numerical finite element method (FEM) modeling for the development of a soft tactile sensor able to simultaneously solve the magnitude and the application location of a normal load exerted onto its surface. The sensor entails the integration of a Bragg grating fiber optic sensor in a Dragon Skin 10 polymer brick (110 mm length, 24 mm width). The soft polymer mediates the transmission of the applied load to the buried fiber Bragg gratings (FBGs), and we also investigated the effect of sensor thickness on receptive field and sensitivity, both with the developed model and experimentally. Force-controlled indentations of the sensor (up to 2.5 N) were carried out through a cylindrical probe applied along the direction of the optical fiber (over an similar to 90 mm span in length). A finite element model of the sensor was built and experimentally validated for 1 and 6 mm thicknesses of the soft polymeric encapsulation material, considering that the latter thickness resulted from numerical simulations as leading to optimal cross talk and sensitivity, given the chosen soft material. The FEM model was also used to train a neural network so as to obtain the inverse sensor function. Using four FBG transducers embedded in the 6-mm-thick soft polymer, the proposed machine learning approach managed to accurately detect both load magnitude (R = 0.97) and location (R = 0.99) over the whole experimental range. The proposed system could be used for developing tactile sensors that can be effectively used for a broad range of applications.","soft tactile sensor,fiber Bragg grating,contact force sensing,contact position localization",Article,"MARY ANN LIEBERT, INC, 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA",Robotics,,9.904,"OF-THE-ART,SENSING,TECHNOLOGIES,HUMAN,HAND,MANIPULATION,ROBOTICS,SYSTEM,UNITS,SKIN",SOFT ROBOTICS,,
30,Representations and descriptors unifying the study of molecular and bulk systems,120,8,,"Rossi Kevin,Cumby James","Rossi K,Cumby J",Cumby J,10.1002/qua.26151,University of Edinburgh,"Establishing a unified framework for describing the structures of molecular and periodic systems is a long-standing challenge in physics, chemistry, and material science. With the rise of machine learning methods in these fields, there is a growing need for such a method. This perspective aims to discuss the development and use of three promising approaches-topological, atom-density, and symmetry-based-for the prediction and rationalization of physical, chemical, and mechanical properties of atomistic systems across different scales and compositions.","atom density,connectivity,data driven,descriptors,machine learning,symmetry distortions",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Chemistry,Mathematics,Physics",,2.688,FRAMEWORK,INTERNATIONAL JOURNAL OF QUANTUM CHEMISTRY,https://www.pure.ed.ac.uk/ws/files/132366186/20200129_Cumby_final_submission.pdf,
31,SpliceFinder: ab initio prediction of splice sites using convolutional neural network,20,1,,"Wang Ruohan,Wang Zishuai,Wang Jianping,Li Shuaicheng","Wang RH,Wang ZS,Wang JP,Li SC",Wang JP; Li SC,10.1186/s12859-019-3306-3,City University of Hong Kong,"Background: Identifying splice sites is a necessary step to analyze the location and structure of genes. Two dinucleotides, GT and AG, are highly frequent on splice sites, and many other patterns are also on splice sites with important biological functions. Meanwhile, the dinucleotides occur frequently at the sequences without splice sites, which makes the prediction prone to generate false positives. Most existing tools select all the sequences with the two dimers and then focus on distinguishing the true splice sites from those pseudo ones. Such an approach will lead to a decrease in false positives; however, it will result in non-canonical splice sites missing.
Result: We have designed SpliceFinder based on convolutional neural network (CNN) to predict splice sites. To achieve the ab initio prediction, we used human genomic data to train our neural network. An iterative approach is adopted to reconstruct the dataset, which tackles the data unbalance problem and forces the model to learn more features of splice sites. The proposed CNN obtains the classification accuracy of 90.25%, which is 10% higher than the existing algorithms. The method outperforms other existing methods in terms of area under receiver operating characteristics (AUC), recall, precision, and F1 score. Furthermore, SpliceFinder can find the exact position of splice sites on long genomic sequences with a sliding window. Compared with other state-of-the-art splice site prediction tools, SpliceFinder generates results in about half lower false positive while keeping recall higher than 0.8. Also, SpliceFinder captures the non-canonical splice sites. In addition, SpliceFinder performs well on the genomic sequences of Drosophila melanogaster, Mus musculus, Rattus, and Danio rerio without retraining.
Conclusion: Based on CNN, we have proposed a new ab initio splice site prediction tool, SpliceFinder, which generates less false positives and can detect non-canonical splice sites. Additionally, SpliceFinder is transferable to other species without retraining. The source code and additional materials are available at https://gitlab.deepomics.org/wangruohan/SpliceFinder.","Canonical and non-canonical splice sites,Splice site prediction,Convolutional neural network",Article; Proceedings Paper,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,"DROSOPHILA-MELANOGASTER,MESSENGER-RNA,ANNOTATION,JUNCTIONS,SEQUENCE,DATABASE,INTRON,GENES",BMC BIOINFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6933889,
32,DMCNN: A Deep Multiscale Convolutional Neural Network Model for Medical Image Segmentation,2019,,,"Teng Lin,Li Hang,Karim Shahid","Teng L,Li H,Karim S",Li H,10.1155/2019/8597606,Shenyang Normal University,"Medical image segmentation is one of the hot issues in the related area of image processing. Precise segmentation for medical images is a vital guarantee for follow-up treatment. At present, however, low gray contrast and blurred tissue boundaries are common in medical images, and the segmentation accuracy of medical images cannot be effectively improved. Especially, deep learning methods need more training samples, which lead to time-consuming process. Therefore, we propose a novelty model for medical image segmentation based on deep multiscale convolutional neural network (CNN) in this article. First, we extract the region of interest from the raw medical images. Then, data augmentation is operated to acquire more training datasets. Our proposed method contains three models: encoder, U-net, and decoder. Encoder is mainly responsible for feature extraction of 2D image slice. The U-net cascades the features of each block of the encoder with those obtained by deconvolution in the decoder under different scales. The decoding is mainly responsible for the upsampling of the feature graph after feature extraction of each group. Simulation results show that the new method can boost the segmentation accuracy. And, it has strong robustness compared with other segmentation methods.","COMPUTATION MODEL,MR",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Health Care Sciences & Services,,3.188,"COMPUTATION,MODEL,MR",JOURNAL OF HEALTHCARE ENGINEERING,https://downloads.hindawi.com/journals/jhe/2019/8597606.pdf,
33,Analyzing brain structural differences associated with categories of blood pressure in adults using empirical kernel mapping-based kernel ELM,18,1,,"Yu Xinying,Peng Bo,Xue Zeyu,Rad Hamidreza Saligheh,Cai Zhenlin,Shi Jun,Zhu Jianbing,Dai Yakang","Yu XY,Peng B,Xue ZY,Rad HS,Cai ZL,Shi J,Zhu JB,Dai YK",Dai YK,10.1186/s12938-019-0740-4,Chinese Academy of Sciences,"Background Hypertension increases the risk of angiocardiopathy and cognitive disorder. Blood pressure has four categories: normal, elevated, hypertension stage 1 and hypertension stage 2. The quantitative analysis of hypertension helps determine disease status, prognosis assessment, guidance and management, but is not well studied in the framework of machine learning. Methods We proposed empirical kernel mapping-based kernel extreme learning machine plus (EKM-KELM+) classifier to discriminate different blood pressure grades in adults from structural brain MR images. ELM+ is the extended version of ELM, which integrates the additional privileged information about training samples in ELM to help train a more effective classifier. In this work, we extracted gray matter volume (GMV), white matter volume, cerebrospinal fluid volume, cortical surface area, cortical thickness from structural brain MR images, and constructed brain network features based on thickness. After feature selection and EKM, the enhanced features are obtained. Then, we select one feature type as the main feature to feed into KELM+, and the rest of the feature types are PI to assist the main feature to train 5 KELM+ classifiers. Finally, the 5 KELM+ classifiers are ensemble to predict classification result in the test stage, while PI is not used during testing. Results We evaluated the performance of the proposed EKM-KELM+ method using four grades of hypertension data (73 samples for each grade). The experimental results show that the GMV performs observably better than any other feature types with a comparatively higher classification accuracy of 77.37% (Grade 1 vs. Grade 2), 93.19% (Grade 1 vs. Grade 3), and 95.15% (Grade 1 vs. Grade 4). The most discriminative brain regions found using our method are olfactory, orbitofrontal cortex (inferior), supplementary motor area, etc. Conclusions Using region of interest features and brain network features, EKM-KELM+ is proposed to study the most discriminative regions that have obvious structural changes in different blood pressure grades. The discriminative features that are selected using our method are consistent with the existing neuroimaging studies. Moreover, our study provides a potential approach to take effective interventions in the early period, when the blood pressure makes minor impacts on the brain structure and function.","Hypertension,Magnetic resonance imaging (MRI),Kernel extreme learning machine plus (KELM plus ),Empirical kernel mapping (EKM),Regions of interest (ROI) features,Brain network features",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Engineering,,,"COGNITIVE,IMPAIRMENT,HYPERTENSION,VOLUMES,FLOW",BIOMEDICAL ENGINEERING ONLINE,https://europepmc.org/articles/pmc6935092?pdf=render,
34,Proposing two new metaheuristic algorithms of ALO-MLP and SHO-MLP in predicting bearing capacity of circular footing located on horizontal multilayer soil,37,2,1537-1547,"Liu Wensheng,Moayedi Hossein,Hoang Nguyen,Lyu Zongjie,Dieu Tien Bui","Liu WS,Moayedi H,Nguyen H,Lyu ZJ,Bui DT",Moayedi H,10.1007/s00366-019-00897-9,Ton Duc Thang University,"In this study, for the issue of shallow circular footing's bearing capacity (also shown as F-ult), we used the merits of artificial neural network (ANN), while optimized it by two metaheuristic algorithms (i.e., ant lion optimization (ALO) and the spotted hyena optimizer (SHO)). Several studies demonstrated that ANNs have significant results in terms of predicting the soil's bearing capacity. Nevertheless, most models of ANN learning consist of different disadvantages. Accordantly, we focused on the application of two hybrid models of ALO-MLP and SHO-MLP for predicting the F(ult)placed in layered soils. Moreover, we performed an Extensive Finite Element (FE) modeling on 16 sets of soil layer (soft soil placed onto stronger soil and vice versa) considering a database that consists of 703 testing and 2810 training datasets for preparing the training and testing datasets. The independent variables in terms of ALO and SHO algorithms have been optimized by taking into account a trial and error process. The input data layers consisted of (i) upper layer foundation/thickness width (h/B) ratio, (ii) bottom and topsoil layer properties (for example, six of the most important properties of soil), (iii) vertical settlement (s), (iv) footing width (B), where the main target was taken F-ult. According to RMSE andR(2), values of (0.996 and 0.034) and (0.994 and 0.044) are obtained for training dataset and values of (0.994 and 0.040) and (0.991 and 0.050) are found for the testing dataset of proposed SHO-MLP and ALO-MLP best-fit prediction network structures, respectively. This proves higher reliability of the proposed hybrid model of SHO-MLP in approximating shallow circular footing bearing capacity.","SHO-MLP,ALO-MLP,ANN,Optimization,Circular footing",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Computer Science,Engineering",,6.544,"MULTIOBJECTIVE,OPTIMIZATION,ALGORITHM,ARTIFICIAL,NEURAL-NETWORKS,MODEL,PILE,FOUNDATIONS,SYSTEM,ROCK,ANN",ENGINEERING WITH COMPUTERS,,
35,Bayesian inference framework for bounded generalized Gaussian-based mixture model and its application to biomedical images classification,30,1,18-30,"Alroobaea Roobaea,Rubaiee Saeed,Bourouis Sami,Bouguila Nizar,Alsufyani Abdulmajeed","Alroobaea R,Rubaiee S,Bourouis S,Bouguila N,Alsufyani A",Bourouis S,10.1002/ima.22391,Taif University,"Biomedical image classification problem has attracted a lot of attention in medical engineering community and medicine applications. Accurate and automatic classification (eg, normal/abnormal or malignant/benign) has a variety of applications such as automatic decision making and is known to be very challenging. In this research, we address this problem by investigating the effectiveness of Bayesian inference methods for statistical bounded mixture models. Indeed, a novel approach termed as Bayesian learning for bounded generalized Gaussian mixture models is developed. The consideration of bounded mixture models is encouraged by their capability to take into account the nature of the data that is compactly supported. Furthermore, the consideration of Bayesian inference is more attractive compared to frequentist reasoning. In this work, we address main issues related to accurate data classification such as the effective estimation of the model's parameters and the selection of the optimal model complexity. Moreover, the problem of over- or under-fitting is treated by taking into account the uncertainty through introducing prior information about the model's parameters. A comparative study between different Gaussian-based models is also performed to evaluate the performance of the proposed framework. Experiments have been conducted on challenging biomedical image datasets that involve retinal images for diabetic retinopathy detection and mammograms for breast cancer detection. Obtained results are encouraging and show the benefits of our Bayesian framework.","Bayesian inference,biomedical imaging,bounded mixture models,generalized Gaussian distribution,image classification,Markov chain Monte Carlo (MCMC)",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,"DIABETIC-RETINOPATHY,AUTOMATIC,DETECTION,RETINAL,IMAGES,BRAIN-TUMOR,SEGMENTATION,MRI,MICROANEURYSMS,CONVERGENCE,SYSTEM",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
36,,,,,,,,,,,,,,,,,,,,
37,A data-driven predictive system using Case-Based Reasoning for the configuration of device-assisted back pain therapy,33,4,617-635,"Recio-Garcia Juan A.,Diaz-Agudo Belen,Kazemi Alireza,Jorro Jose Luis","Recio-Garcia JA,Diaz-Agudo B,Kazemi A,Jorro JL",Diaz-Agudo B,10.1080/0952813X.2019.1704441,Complutense University of Madrid,"Lower back Pain (LBP) is pathological and occurs in about 80% of the population at least once in their life. Physiotherapists personalise manual treatments to heal or relieve pain according to the patient characteristics. The contribution of this methodological paper is the description and evaluation of the configuration software associated to a therapy machine that executes back segment mobilisations. The configuration software uses Case-Based Reasoning (CBR), a successful Machine Learning technique, based on mimicking the human decision making process by reusing previously applied configuration episodes on similar individuals. This paper demonstrates its feasibility and cost-effectiveness for the configuration of treatments as it reuses expert knowledge and maximises effectiveness by taking into account the patient's personal medical record and similar patterns among different patients. Having a baseline of 31% success rate using a standard solution based on interpolation, the CBR engine can achieve, on average, up to 70% success rate when proposing a machine configuration to the physiotherapist. Regarding clinical results, we run a longitudinal observational study that achieves an average improvement of 31.63% using the pain Visual Analogue Scale (VAS), a 7% according to the Oswestry Disability Index (ODI), and 13% in the 36-Item Short Form Health Survey (SF-36).","Case Based Reasoning,Visual Explanations,Personalisation,Device-assisted back pain therapy",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Computer Science,,2.199,"PREVALENCE,MANAGEMENT,EXTENSION,FRAMEWORK",JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE,,
38,Technical Note: A feasibility study on deep learning-based radiotherapy dose calculation,47,2,753-758,"Xing Yixun,Nguyen Dan,Lu Weiguo,Yang Ming,Jiang Steve","Xing YX,Nguyen D,Lu WG,Yang M,Jiang S",Jiang S,10.1002/mp.13953,University of Texas System,"Purpose Various dose calculation algorithms are available for radiation therapy for cancer patients. However, these algorithms are faced with the tradeoff between efficiency and accuracy. The fast algorithms are generally less accurate, while the accurate dose engines are often time consuming. In this work, we try to resolve this dilemma by exploring deep learning (DL) for dose calculation. Methods We developed a new radiotherapy dose calculation engine based on a modified Hierarchically Densely Connected U-net (HD U-net) model and tested its feasibility with prostate intensity-modulated radiation therapy (IMRT) cases. Mapping from an IMRT fluence map domain to a three-dimensional (3D) dose domain requires a deep neural network of complicated architecture and a huge training dataset. To solve this problem, we first project the fluence maps to the dose domain using a broad beam ray-tracing (RT) algorithm, and then we use the HD U-net to map the RT dose distribution into an accurate dose distribution calculated using a collapsed cone convolution/superposition (CS) algorithm. The model is trained on 70 patients with fivefold cross validation, and tested on a separate 8 patients. Results It takes about 1 s to compute a 3D dose distribution for a typical 7-field prostate IMRT plan, which can be further reduced to achieve real-time dose calculation by optimizing the network. The average Gamma passing rate between DL and CS dose distributions for the 8 test patients are 98.5% (+/- 1.6%) at 1 mm/1% and 99.9% (+/- 0.1%) at 2 mm/2%. For comparison of various clinical evaluation criteria (dose-volume points) for IMRT plans between two dose distributions, the average difference for dose criteria is less than 0.25 Gy while for volume criteria is <0.16%, showing that the DL dose distributions are clinically identical to the CS dose distributions. Conclusions We have shown the feasibility of using DL for calculating radiotherapy dose distribution with high accuracy and efficiency.","deep learning,dose calculation,radiotherapy",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"PHOTON,CONVOLUTION",MEDICAL PHYSICS,http://arxiv.org/pdf/1908.03159,
39,Machine learning methods to predict solubilities of rock samples,34,2,,"Hanzelik Pal Peter,Gergely Szilveszter,Gaspar Csaba,Gyory Laszlo","Hanzelik PP,Gergely S,Gaspar C,Gyory L",Hanzelik PP,10.1002/cem.3198,"MOL Grp Plc, MOL E&P Lab, Budapest, Hungary.","Interests in the use of chemometric and data science methods for laboratory techniques have grown rapidly over the last 10 years, for the reason that they are cheaper and faster than traditional analytical methods of material testing. This study uses 888 rock samples collected from the exploration and production (E&P) sector of the oil industry. Based on the Fourier-transform infrared (FT-IR) spectra of these rock samples their solubility predictions have been developed and investigated with nine methods including both linear and non-linear ones. Two of these methods such as Partial Least Squares Regression (PLSR) and Support Vector Regression (SVR) are available in a commercial software package and the other seven methods, Extreme Gradient Boosting (XGBoost), Ridge Regression (RR), k-nearest neighbours (k-NN), Decision Tree (DT), Multilayer Perceptron (MLP), Support Vector Regression (SVR), Artificial Neural Network (ANN) with TensorFlow (TF), were coded by the authors based either on commercial applications or open source libraries. The investigation starts with spectral data pre-processing carried out by standard normal variate (SNV), baseline correction and feature selection methods creating the feature set for all machine learning (ML) applications. The accuracy of predictions has been evaluated with mean squared error as a performance metric for each investigated method. The comparisons of predicted values to real data of test samples have shown that mineral solubility in acids can be well predicted in the range of the uncertainties of real laboratory measurements, therefore it can be used to improve the response time of these investigations and reduce the risk in industrial applications. In those cases, where the unknown samples have got some out of the range features, the limitations in the accuracy of predictions have become clear. We have also identified the limitations in the methodology and planned steps to further improve the prediction capabilities. The identified constraint of samples' multitude further emphasizes the need for database building efforts, so that the real potential in big data and machine learning can be realized.","acid solubility,artificial neural network (ANN) TensorFlow,Extreme Gradient Boosting (XGBoost),mid-infrared spectra,multivariate data analysis (MVDA)",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Automation & Control Systems,Chemistry,Computer Science,Instruments & Instrumentation,Mathematics",,2.513,,JOURNAL OF CHEMOMETRICS,,
40,RNA editing-based classification of diffuse gliomas: predicting isocitrate dehydrogenase mutation and chromosome 1p/19q codeletion,20,1,,"Chen Sean Chun-Chang,Lo Chung-Ming,Wang Shih-Hua,Su Emily Chia-Yu","Chen SCC,Lo CM,Wang SH,Su ECY",Chen SCC,10.1186/s12859-019-3236-0,Taipei Medical University,"Background: Accurate classification of diffuse gliomas, the most common tumors of the central nervous system in adults, is important for appropriate treatment. However, detection of isocitrate dehydrogenase (IDH) mutation and chromosome1p/19q codeletion, biomarkers to classify gliomas, is time- and cost-intensive and diagnostic discordance remains an issue. Adenosine to inosine (A-to-I) RNA editing has emerged as a novel cancer prognostic marker, but its value for glioma classification remains largely unexplored. We aim to (1) unravel the relationship between RNA editing and IDH mutation and 1p/19q codeletion and (2) predict IDH mutation and 1p/19q codeletion status using machine learning algorithms.
Results: By characterizing genome-wide A-to-I RNA editing signatures of 638 gliomas, we found that tumors without IDH mutation exhibited higher total editing level compared with those carrying it (Kolmogorov-Smirnov test, p < 0.0001). When tumor grade was considered, however, only grade IV tumors without IDH mutation exhibited higher total editing level. According to 10-fold cross-validation, support vector machines (SVM) outperformed random forest and AdaBoost (DeLong test, p < 0.05). The area under the receiver operating characteristic curve (AUC) of SVM in predicting IDH mutation and 1p/19q codeletion were 0.989 and 0.990, respectively. After performing feature selection, AUCs of SVM and AdaBoost in predicting IDH mutation were higher than that of random forest (0.985 and 0.983 vs. 0.977; DeLong test, p < 0.05), but AUCs of the three algorithms in predicting 1p/19q codeletion were similar (0.976-0.982). Furthermore, 67% of the six continuously misclassified samples by our 1p/19q codeletion prediction models were misclassifications in the original labelling after inspection of 1p/19q status and/or pathology report, highlighting the accuracy and clinical utility of our models.
Conclusions: The study represents the first genome-wide analysis of glioma editome and identifies RNA editing as a novel prognostic biomarker for glioma. Our prediction models provide standardized, accurate, reproducible and objective classification of gliomas. Our models are not only useful in clinical decision-making, but also able to identify editing events that have the potential to serve as biomarkers and therapeutic targets in glioma management and treatment.","RNA editing,Classification,Gliomas,Machine learning,Prognosis,Isocitrate dehydrogenase",Article; Proceedings Paper,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,"CENTRAL-NERVOUS-SYSTEM,PROGNOSIS,GRADE,SURVIVAL",BMC BIOINFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6929429,
41,Mild cognitive impairment understanding: an empirical study by data-driven approach,20,,,"Liu Liyuan,Yu Bingchen,Han Meng,Yuan Shanshan,Wang Na","Liu LY,Yu BC,Han M,Yuan SS,Wang N",Han M,10.1186/s12859-019-3057-1,University System of Georgia,"Background: Cognitive decline has emerged as a significant threat to both public health and personal welfare, and mild cognitive decline/impairment (MCI) can further develop into Dementia/Alzheimer's disease. While treatment of Dementia/Alzheimer's disease can be expensive and ineffective sometimes, the prevention of MCI by identifying modifiable risk factors is a complementary and effective strategy.
Results: In this study, based on the data collected by Centers for Disease Control and Prevention (CDC) through the nationwide telephone survey, we apply a data-driven approach to re-exam the previously founded risk factors and discover new risk factors. We found that depression, physical health, cigarette usage, education level, and sleep time play an important role in cognitive decline, which is consistent with the previous discovery. Besides that, the first time, we point out that other factors such as arthritis, pulmonary disease, stroke, asthma, marital status also contribute to MCI risk, which is less exploited previously. We also incorporate some machine learning and deep learning algorithms to weigh the importance of various factors contributed to MCI and predicted cognitive declined.
Conclusion: By incorporating the data-driven approach, we can determine that risk factors significantly correlated with diseases. These correlations could also be expanded to another medical diagnosis besides MCI.","Mild cognitive deline impairment (MCI),Data-driven approach,Machine learning",Article; Proceedings Paper,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,ALZHEIMER-DISEASE,BMC BIOINFORMATICS,https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-019-3057-1,
42,Recommender System of Successful Processing Conditions for New Compounds Based on a Parallel Experimental Data Set,31,24,9984-9992,"Hayashi Hiroyuki,Hayashi Katsuyuki,Kouzai Keita,Seko Atsuto,Tanaka Isao","Hayashi H,Hayashi K,Kouzai K,Seko A,Tanaka I",Hayashi H,10.1021/acs.chemmater.9b01799,Kyoto University,"We propose a machine-learning method to recommend successful processing conditions for new compounds on the basis of parallel experiments. Initially, an experimental database was constructed for 67 pseudobinary oxides registered in the Inorganic Crystal Structure Database (ICSD) by parallel experiments using 23 starting materials and 23 cation mixing ratios. Precursor powders were obtained by four synthesis methods (solid-state reaction, polymerized complex, cyclic ether sol-gel, and spray coprecipitation), which were fired at five different temperatures. This resulted in 1648 unique chemical synthesis conditions and database entries. The reactants were characterized sequentially using powder X-ray diffraction equipment with an automatic sample exchanger. The synthesis results were rated as a score, which was placed into a fifth-order tensor with 243 340 elements. The Tucker decomposition method was used to predict yet-to-be-rated scores for unexperimented processing conditions. Good predictive performance of the present model was demonstrated by cross validation. It was further evaluated by examining the presence of highly rated compositions in another database, ICDD-PDF (International Center for Diffraction Data-Powder Diffraction File). Successful processing conditions for unexperimented compositions were found to be well recommended.","COMBINATORIAL,EXTRACTION",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Materials Science",,10.837,"COMBINATORIAL,EXTRACTION",CHEMISTRY OF MATERIALS,,
43,Detection of anaemia from retinal fundus images via deep learning,4,1,18-27,"Mitani Akinori,Huang Abigail,Venugopalan Subhashini,Corrado Greg S.,Peng Lily,Webster Dale R.,Hammel Naama,Liu Yun,Varadarajan Avinash V.","Mitani A,Huang A,Venugopalan S,Corrado GS,Peng L,Webster DR,Hammel N,Liu Y,Varadarajan AV",Mitani A,10.1038/s41551-019-0487-z,Google Incorporated,"Owing to the invasiveness of diagnostic tests for anaemia and the costs associated with screening for it, the condition is often undetected. Here, we show that anaemia can be detected via machine-learning algorithms trained using retinal fundus images, study participant metadata (including race or ethnicity, age, sex and blood pressure) or the combination of both data types (images and study participant metadata). In a validation dataset of 11,388 study participants from the UK Biobank, the fundus-image-only, metadata-only and combined models predicted haemoglobin concentration (in g dl(-1)) with mean absolute error values of 0.73 (95% confidence interval: 0.72-0.74), 0.67 (0.66-0.68) and 0.63 (0.62-0.64), respectively, and with areas under the receiver operating characteristic curve (AUC) values of 0.74 (0.71-0.76), 0.87 (0.85-0.89) and 0.88 (0.86-0.89), respectively. For 539 study participants with self-reported diabetes, the combined model predicted haemoglobin concentration with a mean absolute error of 0.73 (0.68-0.78) and anaemia an AUC of 0.89 (0.85-0.93). Automated anaemia screening on the basis of fundus images could particularly aid patients with diabetes undergoing regular retinal imaging and for whom anaemia can increase morbidity and mortality risks.
Machine-learning algorithms trained with retinal fundus images, with subject metadata or with both data types, predict haemoglobin concentration with mean absolute errors lower than 0.75 g dl(-1) and anaemia with areas under the curve in the range of 0.74-0.89.","DIABETIC-RETINOPATHY,NONINVASIVE HEMOGLOBIN,RISK-FACTORS,PREVALENCE,ACCURACY,TELEMEDICINE,POPULATIONS,VALIDATION,AGREEMENT,CHILDREN",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Engineering,,26.355,"DIABETIC-RETINOPATHY,NONINVASIVE,HEMOGLOBIN,RISK-FACTORS,PREVALENCE,ACCURACY,TELEMEDICINE,POPULATIONS,VALIDATION,AGREEMENT,CHILDREN",NATURE BIOMEDICAL ENGINEERING,http://arxiv.org/pdf/1904.06435,
44,Engaging soft computing in material and modeling uncertainty quantification of dam engineering problems,24,15,11583-11604,"Hariri-Ardebili Mohammad Amin,Salazar Fernando","Hariri-Ardebili MA,Salazar F",Hariri-Ardebili MA,10.1007/s00500-019-04623-x,University of Colorado System,"Due to complex nature of nearly all infrastructures (and more specifically concrete dams), the uncertainty quantification is an inseparable part of risk assessment. Uncertainties might be propagated in different aspects depending on their relative importance such as epistemic and aleatory, or spatial and temporal. The objective of this paper is to focus on the material and modeling uncertainties, and to couple them with soft computing techniques aiming to reduce the computational burden of the conventional Monte Carlo-based finite element simulations. Several scenarios are considered in which the concrete and foundation material properties, the water level, and the dam geometry are assumed as random variables. Five soft computing techniques (i.e., random forest, boosted regression trees, multi-adaptive regression splines, artificial neural networks, and support vector machines) are employed to predict various quantities of interest based on different training sizes. It is argued that the artificial neural network is the most accurate algorithm in majority of cases, with enough accuracy as to be useful in reliability analysis as a complement to numerical models. The results with 200 samples in the training set are enough for reaching useful accuracy in most cases. For the simple prediction tasks, the results were predicted with less than 1% error. It is observed that increasing the number of input parameters increases the prediction error. The partial dependence plots provided most sensitive variables in dam design, which were consistent with the physics of the problem. Finally, several practical recommendations are provided for future applications.","Soft computing,Uncertainty quantification,Dam class,Machine learning,Response prediction,Big data",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,3.518,"CONCRETE,GRAVITY,DAMS,RELIABILITY-ANALYSIS,SEISMIC,CRACKING,REGRESSION,IDENTIFICATION,RISK",SOFT COMPUTING,https://www.scipedia.com/wd/images/d/d6/Draft_Samper_476414756_2102_Hariri-Ardebili-Salazar2019_Article_EngagingSoftComputingInMateria_%281%29.pdf,
45,Clinical evaluation of fully automated thigh muscle and adipose tissue segmentation using a U-Net deep learning architecture in context of osteoarthritic knee pain,33,4,483-493,"Kemnitz Jana,Baumgartner Christian F.,Eckstein Felix,Chaudhari Akshay,Ruhdorfer Anja,Wirth Wolfgang,Eder Sebastian K.,Konukoglu Ender","Kemnitz J,Baumgartner CF,Eckstein F,Chaudhari A,Ruhdorfer A,Wirth W,Eder SK,Konukoglu E",Kemnitz J,10.1007/s10334-019-00816-5,Paracelsus Private Medical University,"Objective Segmentation of thigh muscle and adipose tissue is important for the understanding of musculoskeletal diseases such as osteoarthritis. Therefore, the purpose of this work is (a) to evaluate whether a fully automated approach provides accurate segmentation of muscles and adipose tissue cross-sectional areas (CSA) compared with manual segmentation and (b) to evaluate the validity of this method based on a previous clinical study. Materials and methods The segmentation method is based on U-Net architecture trained on 250 manually segmented thighs from the Osteoarthritis Initiative (OAI). The clinical evaluation is performed on a hold-out test set bilateral thighs of 48 subjects with unilateral knee pain. Results The segmentation time of the method is < 1 s and demonstrated high agreement with the manual method (dice similarity coeffcient: 0.96 +/- 0.01). In the clinical study, the automated method shows that similar to manual segmentation (- 5.7 +/- 7.9%, p < 0.001, effect size: 0.69), painful knees display significantly lower quadriceps CSAs than contralateral painless knees (- 5.6 +/- 7.6%, p < 0.001, effect size: 0.73). Discussion Automated segmentation of thigh muscle and adipose tissues has high agreement with manual segmentations and can replicate the effect size seen in a clinical study on osteoarthritic pain.","Muscle,Magnetic resonance imaging,Deep learning,Convolutional neural networks,Automated segmentation",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,,"CROSS-SECTIONAL,AREA,SEMIAUTOMATED,SEGMENTATION,STRUCTURAL,PROGRESSION,LONGITUDINAL,CHANGE,BETWEEN-KNEE,STRENGTH,QUADRICEPS,VOLUME,VALIDATION,IMAGES",MAGNETIC RESONANCE MATERIALS IN PHYSICS BIOLOGY AND MEDICINE,https://link.springer.com/content/pdf/10.1007/s10334-019-00816-5.pdf,
46,Diagnosis model of pancreatic cancer based on fusion of distribution estimation algorithm and genetic algorithm,32,10,5425-5434,"Wang Xusheng,Li Xiaofeng,Chen Xing,Cao Congjun","Wang XS,Li XF,Chen X,Cao CJ",Li XF,10.1007/s00521-019-04684-x,"Heilongjiang Int Univ, Dept Informat Engn, Harbin 150025, Heilongjiang, Peoples R China.","Since the beginning of the twenty-first century, people's living standards have been continuously improved, followed by changes in diet structure and living habits. These changes have affected the body's endocrine system, causing lesions in the pancreatic tissue. Among these pancreatic tissue diseases, pancreatic cancer is the most harmful to human health because of its inability to find and high mortality within 1 year. At present, in the diagnosis of pancreatic cancer, medical imaging and pathological puncture are the main methods of diagnosis. These methods have a high diagnostic rate for patients with advanced pancreatic cancer, but it is difficult to apply to the diagnosis of early pancreatic cancer. In response to these problems, this paper proposes a pancreatic cancer diagnosis model based on the fusion of distribution estimation algorithm and genetic algorithm. By collecting pathological data of patients with pancreatic cancer from a hospital oncology, pathological data include clinical manifestations of pancreatic cancer patients, serum tumor markers, etc., after data preprocessing, input models, and then use different machine learning classification algorithms to make pancreatic cancer for diagnosis. By evaluating the diagnosis results of each classification algorithm, an optimal classification algorithm is obtained and applied to the diagnosis model of pancreatic cancer. The results show that compared with other classification algorithms, the model using classification algorithm has the highest accuracy, recall rate and harmonic mean, and the diagnostic performance is the best. The results show that the diagnostic model constructed in this paper has a very high application value in the early auxiliary pre-diagnosis of pancreatic cancer.","Distribution estimation algorithm,Genetic algorithm,Pancreatic cancer diagnosis,Model evaluation",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,,NEURAL COMPUTING & APPLICATIONS,,
47,Prediction of Punching Capacity of Slab-Column Connections without Transverse Reinforcement Based on a Backpropagation Neural Network,2019,,,"Bu Jie,Zhang Fanzhen,Zhu Meng,He Zhiyang,Hu Qigao","Bu J,Zhang FZ,Zhu M,He ZY,Hu QG",Zhang FZ,10.1155/2019/7904685,National University of Defense Technology - China,"Punching shear failure of slab-column connections can cause the progressive collapse of a structure. In this study, a punching test database is first established. Then, based on the Levenberg-Marquardt (LM) algorithm and using the nonlinear function of the backpropagation neural network (BPNN), a prediction model of the punching capacity of slab-column connections without transverse reinforcement is established. Finally, the proposed model is compared with the formulas of the Chinese, American, and European standards using several methods. The statistical eigenvalue method shows that the BPNN model has the highest accuracy and the lowest dispersion. The defect point counting method shows that the BPNN model had the fewest total number of defects and was the safest and most economical. The influencing factor analysis suggests that factors in the BPNN model had the most reasonable influence on the punching bearing capacity of slab-column connections. Finally, the model is verified using a case study and the Matlab program. The results show that the average error of the formulas in the Chinese, American, and European standards are 21.08%, 30.21%, and 11.47%, respectively, higher than that of the BPNN model.","SHEAR-STRENGTH,BEAMS,MODEL",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Construction & Building Technology,Engineering",,1.923,"SHEAR-STRENGTH,BEAMS,MODEL",ADVANCES IN CIVIL ENGINEERING,https://doi.org/10.1155/2019/7904685,
48,Trace analysis of uranium ore concentrates using laser ablation inductively coupled plasma mass spectrometry for nuclear forensics,323,2,831-838,"Jovanovic Slobodan V.,Kell Tara,El-Haddad Josette,Cochrane Chris,Drummond Christopher,El-Jaby Ali","Jovanovic SV,Kell T,El-Haddad J,Cochrane C,Drummond C,El-Jaby A",Jovanovic SV,10.1007/s10967-019-06991-y,"Canadian Nucl Safety Commiss, 3484 Limebank Rd, Ottawa, ON K1V 1E1, Canada.","We present a laser ablation inductively coupled plasma mass spectrometry (LA-ICP-MS) method for trace-element analysis of uranium ore concentrates (UOCs). The method was used to characterize a select number of UOC samples representing 20 different producers from 8 distinct geographic locations. These results were then used to assess the origin of the samples using a machine-learning algorithm. The LA-ICP-MS characterization performed equally well as that obtained by the conventional aqueous method, suggesting that this rapid, low waste technique is suitable for National Nuclear Forensic Library applications.","Trace element analysis of uranium ore concentrates,Laser ablation inductively coupled plasma mass spectrometry,Nuclear forensics",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Chemistry,Nuclear Science & Technology",,1.28,"ICP-MS,CALIBRATION,IMPURITIES,MATRIX",JOURNAL OF RADIOANALYTICAL AND NUCLEAR CHEMISTRY,,
49,Hysteresis compensation control of a dielectric elastomer vibration isolator,40,1,497-508,"Meng Lili,Bao Wenjie,Li Fucai,Li Hongguang","Meng LL,Bao WJ,Li FC,Li HG",Li FC,10.1177/1461348419883757,Shanghai Jiao Tong University,"This paper describes the design and fabrication of a dielectric elastomer actuator vibration isolator and accompanying hysteresis compensation controller. The results of experiments to elucidate the hysteresis properties and the quality of the vibration isolation are also presented. The model used to characterize the hysteresis properties of the dielectric elastomer actuator is based on the controlled auto-regressive model and employs the recursive least squares method. A closed-loop proportional-integral-derivative controller was developed to compensate the hysteresis and was tuned via the back propagation neural network algorithm. The results demonstrate that the controller can compensate the hysteresis of the dielectric elastomer actuator, and the dielectric elastomer actuator can be used to isolate incoming vibration from the base. When tested using a narrow band vibration in a 5 Hz band, the isolation of the dielectric elastomer actuator vibration isolator was 45.60% across the frequency band.","Dielectric elastomer,vibration isolator,hysteresis compensation control",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Acoustics,,2.616,"NEURAL-NETWORK,SMART,BEAM,IDENTIFICATION,ACTUATOR,SUPPRESSION,MODEL",JOURNAL OF LOW FREQUENCY NOISE VIBRATION AND ACTIVE CONTROL,https://journals.sagepub.com/doi/pdf/10.1177/1461348419883757,
50,Ultrasonic liver steatosis quantification by a learning-based acoustic model from a novel shear wave sequence,18,1,,"Shi Xiudong,Ye Wen,Liu Fengjun,Zhang Rengyin,Hou Qinguo,Shi Chunzi,Yu Jinhua,Shi Yuxin","Shi XD,Ye W,Liu FJ,Zhang RY,Hou QG,Shi CZ,Yu JH,Shi YX",Shi YX,10.1186/s12938-019-0742-2,Fudan University,"Background An efficient and accurate approach to quantify the steatosis extent of liver is important for clinical practice. For the purpose, we propose a specific designed ultrasound shear wave sequence to estimate ultrasonic and shear wave physical parameters. The utilization of the estimated quantitative parameters is then studied. Results Shear wave attenuation, shear wave absorption, elasticity, dispersion slope and echo attenuation were simultaneously estimated and quantified from the proposed novel shear wave sequence. Then, a regression tree model was utilized to learn the connection between the space represented by all the physical parameters and the liver fat proportion. MR mDIXON quantification was used as the ground truth for liver fat quantification. Our study included a total of 60 patients. Correlation coefficient (CC) with the ground truth were applied to mainly evaluate different methods for which the corresponding values were - 0.25, - 0.26, 0.028, 0.045, 0.46 and 0.83 for shear wave attenuation, shear wave absorption, elasticity, dispersion slope, echo attenuation and the learning-based model, respectively. The original parameters were extremely outperformed by the learning-based model for which the root mean square error for liver steatosis quantification is only 4.5% that is also state-of-the-art for ultrasound application in the related field. Conclusions Although individual ultrasonic and shear wave parameters were not perfectly adequate for liver steatosis quantification, a promising result can be achieved by the proposed learning-based acoustic model based on them.","Liver steatosis quantification,Ultrasonic and shear wave parameter estimation,Learning-based model",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Engineering,,2.905,"LEAST-SQUARES,METHOD,HEPATIC,STEATOSIS,VARIABILITY,ELASTICITY,VISCOSITY,DISEASE,REGION",BIOMEDICAL ENGINEERING ONLINE,https://europepmc.org/articles/pmc6925885?pdf=render,
51,Development and evaluation of inexpensive automated deep learning-based imaging systems for embryology,19,24,4139-4145,"Kanakasabapathy Manoj Kumar,Thirumalaraju Prudhvi,Bormann Charles L.,Kandula Hemanth,Dimitriadis Irene,Souter Irene,Yogesh Vinish,Pavan Sandeep Kota Sai,Yarravarapu Divyank,Gupta Raghav","Kanakasabapathy MK,Thirumalaraju P,Bormann CL,Kandula H,Dimitriadis I,Souter I,Yogesh V,Pavan SKS,Yarravarapu D,Gupta R",Shafiee H,10.1039/c9lc00721k,Harvard University,"Embryo assessment and selection is a critical step in an in vitro fertilization (IVF) procedure. Current embryo assessment approaches such as manual microscopy analysis done by embryologists or semi-automated time-lapse imaging systems are highly subjective, time-consuming, or expensive. Availability of cost-effective and easy-to-use hardware and software for embryo image data acquisition and analysis can significantly empower embryologists towards more efficient clinical decisions both in resource-limited and resource-rich settings. Here, we report the development of two inexpensive (<$100 and <$5) and automated imaging platforms that utilize advances in artificial intelligence (AI) for rapid, reliable, and accurate evaluations of embryo morphological qualities. Using a layered learning approach, we have shown that network models pre-trained with high quality embryo image data can be re-trained using data recorded on such low-cost, portable optical systems for embryo assessment and classification when relatively low-resolution image data are used. Using two test sets of 272 and 319 embryo images recorded on the reported stand-alone and smartphone optical systems, we were able to classify embryos based on their cell morphology with >90% accuracy.","CONVOLUTIONAL NEURAL-NETWORKS,SELECTION,CNN,CLASSIFICATION,FERTILIZATION,INTEROBSERVER",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Biochemistry & Molecular Biology,Chemistry,Science & Technology - Other Topics,Instruments & Instrumentation",,7.379,"CONVOLUTIONAL,NEURAL-NETWORKS,SELECTION,CNN,CLASSIFICATION,FERTILIZATION,INTEROBSERVER",LAB ON A CHIP,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6934406,
52,,,,,,,,,,,,,,,,,,,,
53,,,,,,,,,,,,,,,,,,,,
54,,,,,,,,,,,,,,,,,,,,
55,Inverse analysis and multi-objective optimization of coupling mechanism based laser forming process,45,1,,"Maji Kuntal,Chakraborty Shitanshu S.,Pratihar Dilip K.,Nath Ashish K.","Maji K,Chakraborty SS,Pratihar DK,Nath AK",Maji K,10.1007/s12046-019-1245-3,National Institute of Technology (NIT System),"Laser forming of non-developable surfaces necessitates simultaneous bending and shrinkage of the sheet blank. This can be obtained by coupling mechanism based laser forming. However, soft computing based modeling of this process as well as different laser parameter sets under coupling mechanism giving different optimum combinations of simultaneous bending and shrinkage is rarely reported. In this work, experiments have been carried out following a design of experiments with considered suitable ranges of the input factors, i.e., laser power, travel speed and laser beam diameter activating coupling mechanism. Response surface models for the outputs namely bending and thickening (resulted due to shrinkage) were developed in terms of the considered inputs and parametric effects were analyzed. Finite element modeling was also carried out to analyze the deformation behavior. Multi-objective optimization of laser parameters for different combinations of maximum/minimum of bending and thickening of the sheet material undergoing coupling mechanism has been shown. Forward and inverse models of the process have been built with the help of a backpropagation neural network (BPNN) and genetic algorithm-based neural network (GANN) based on experimental data. Because of the ability of genetic algorithm (GA) to obtain global search, GANN models provide better estimation of the input parameters for inverse modeling or process synthesis compared to that by the BPNN model. Finally, several dome-shaped surfaces were built with constant line energy but different Fourier numbers and hence, different proportions of bending and shrinkage. This was to demonstrate the importance of simultaneous bending and thickening of the sheet (achievable only by coupling mechanism) to generate such non-developable surface with minimal distortion.","Laser forming,coupling mechanism,inverse analysis,multi-objective optimization",Article,"SPRINGER INDIA, 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001, INDIA",Engineering,,1.271,"SHAPED,SURFACE,ANALYTICAL-MODEL,SCAN,STRATEGIES,FINITE-ELEMENT,SHEET,DEFORMATION",SADHANA-ACADEMY PROCEEDINGS IN ENGINEERING SCIENCES,,
56,Imaging Metal Halide Perovskites Material and Properties at the Nanoscale,10,26,,"Howard John M.,Lahoti Richa,Leite Marina S.","Howard JM,Lahoti R,Leite MS",Leite MS,10.1002/aenm.201903161,University System of Maryland,"Metal halide perovskites exhibit optimal properties for optoelectronic devices, ranging from photovoltaics to light-emitting diodes, utilizing simple fabrication routes that produce impressive electrical and optical tunability. As perovskite technologies continue to mature, an understanding of their fundamental properties at length scales relevant to their morphology is critical. In this review, an overview is presented of the key insights into perovskite material properties provided by measurement methods based on the atomic force microscopy (AFM). Specifically, the manner in which AFM-based techniques supply valuable information regarding electrical and chemical heterogeneity, ferroelectricity and ferroelasticity, surface passivation and chemical modification, ionic migration, and material/device stability is discussed. Continued advances in perovskite materials will require multimodal approaches and machine learning, where the output of these scanning probe measurements is combined with high spatial resolution structural and chemical information to provide a complete nanoscale description of materials behavior and device performance.","artificial intelligence,atomic force microscopy,functional imaging,halide perovskites,nanoscale properties",Review,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Energy & Fuels,Materials Science,Physics",,27.97,"PROBE,FORCE,MICROSCOPY,SOLAR-CELLS,HIGH-PERFORMANCE,CHEMICAL-COMPOSITION,GRAIN-BOUNDARIES,PHOTON,ENERGY,ION,MIGRATION,DEGRADATION,EFFICIENCY,PASSIVATION",ADVANCED ENERGY MATERIALS,https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/aenm.201903161,
57,Evaluation and prediction for effect of conductive gussasphalt mixture on corrosion of steel bridge deck,228,,,"Chen Qian,Wang Chaohui,Sun Xiaolong,Cao Yangsen,Guo Tengteng,Chen Jiao","Chen Q,Wang CH,Sun XL,Cao YS,Guo TT,Chen J",Wang CH,10.1016/j.conbuildmat.2019.116837,Chang'an University,"Conductive gussasphalt mixture can melt snow on the bridge deck, but it may corrode steel bridge deck and have an impact on traffic environment and safety when the power is on. To solve this problem, five conductive gussasphalt mixtures were prepared, and the effects of mixture type, working conditions and environmental factors of conductive gussasphalt mixture on corrosion of steel bridge deck was studied systemically. Based on the extreme learning machine optimized by genetic algorithm, the corrosion degree prediction model of steel bridge deck was established. The results indicated that number of times on power, mixture type and temperature had significant effects on the corrosion of steel deck, and their contribution rates were 58.47%, 24.62% and 15.40%, respectively. After optimization by genetic algorithm, the error of extreme learning machine model was 0.40-9.25%. Compared with the traditional extreme learning machine model, they decreased by 5.31-10.63%. (C) 2019 Elsevier Ltd. All rights reserved.","Road engineering,Snow melting,Conductive gussasphalt mixture,Steel deck corrosion,Prediction model,Extreme learning machine",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Construction & Building Technology,Engineering,Materials Science",,6.841,"PERFORMANCE,EVALUATION,ASPHALT,CONCRETE,COEFFICIENT,SURFACE,IMPACT,CYCLE",CONSTRUCTION AND BUILDING MATERIALS,,
58,A comparison of machine learning methods for predicting the compressive strength of field-placed concrete,228,,,"DeRousseau M. A.,Laftchiev E.,Kasprzyk J. R.,Rajagopalan B.,Srubar W. V. III","DeRousseau MA,Laftchiev E,Kasprzyk JR,Rajagopalan B,Srubar WV",Srubar WV,10.1016/j.conbuildmat.2019.08.042,University of Colorado System,"This study evaluates the efficacy of machine learning (ML) methods to predict the compressive strength of field-placed concrete. We employ both field- and laboratory-obtained data to train and test ML models of increasing complexity to determine the best-performing model specific to field-placed concrete. The ability of ML models trained on laboratory data to predict the compressive strength of field-placed concrete is evaluated and compared to those models trained exclusively on field-acquired data. Results substantiate that the random forest ML model trained on field-acquired data exhibits the best performance for predicting the compressive strength of field-placed concrete; the RMSE, MAE, and R-2 values were 730 psi, 530 psi, and 0.51, respectively. We also show that hybridization of field- and laboratory-acquired data for training ML models is a promising method for reducing common over-prediction issues encountered by laboratory-trained models that are used in isolation to predict the compressive strength of field-placed concrete. (C) 2019 Elsevier Ltd. All rights reserved.","Concrete,Compressive strength,Machine learning,Prediction,Statistical modeling",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Construction & Building Technology,Engineering,Materials Science",,6.841,"FLY-ASH,NEURAL-NETWORKS,SILICA,FUME,SLAG,OPTIMIZATION,METAKAOLIN,REGRESSION",CONSTRUCTION AND BUILDING MATERIALS,,
59,Tracing the technological development trajectory in post-lithium-ion battery technologies: A patent-based approach,241,,,"Aaldering Lukas Jan,Song Chie Hoon","Aaldering LJ,Song CH",Song CH,10.1016/j.jclepro.2019.118343,Helmholtz Association,"With the ever-growing energy demands, new battery chemistries beyond lithium ion technology are required to deal with an increased power consumption and promote the vehicle electrification. However, there are still challenges in understanding the cognitive structure of evolving R&D processes. The study of the patent landscape can provide a complementary perspective on the trajectories of technological change and facilitate interdisciplinary discussions that help make future technology planning more rationally. In this study, we investigate the technological development trajectory of post-lithium-ion battery technologies based on the analysis of patent data. A data-driven approach, which comprises of patent co-classification analysis, application of link prediction algorithm and text mining technique, is used to highlight the recent research progress on selected post-lithium-ion battery technologies. These are lithium air, lithium sulfur and sodium-ion batteries. A lithium air battery is composed of a lithium metal anode, a porous carbon cathode with high catalytic activities towards electrochemical oxygen reactions, and either an aqueous or non-aqueous electrolyte. Similarly, a lithium sulfur battery consists of a lithium metal anode, a sulfur composite cathode, and an organic electrolyte. Sodium-ion batteries share the same architecture as the lithium ion-batteries, but are normally based on carbonaceous anode materials, layered transition metal oxides cathode demonstrating a minimal structural change upon intercalation, and aqueous electrolytes. The results indicate that the number of patents related to postlithium-ion battery technologies has noticeably increased since 2008. A few East Asian countries and USA dominate the underlying patent landscape. The co-classification analysis showed that not only the amount of interacting knowledge areas but also the cross-linking with adjacent technological knowledge areas has increased. Moreover, the knowledge areas related to the electric vehicles and polymer applications are predicted to gain more relevance in the future. According to the text mining results, the most common application areas comprise vehicles, devices, energy storage, computers and phones. The main innovations of this study are as follows: First, it identified the current research trends and prospects for the post-lithium-ion battery technologies based on the insights gained from objective data, assisting R&D planners in determining their further directions for research and development. The exploration of the technological development trajectory of post-lithium-ion battery could serve as a reference for relevant researchers to better understand the dynamics and make strategic adjustments, which have profound significance for the progress of clean energy and green chemistry development. Second, it discovered the dynamics of interacting knowledge areas, which indicate an increased tendency of technology convergence.
In case of lithium air and lithium sulfur batteries, notable interactions between knowledge areas pertaining to the core battery components (cell configurations and electrolytes) and application-driven knowledge fields (electric vehicles and phones) were observed. The intensity of these interactions was rather weak in case of sodium-ion battery technology. Accordingly, researchers need to seek for new knowledge outside of their traditional knowledge boundaries to accelerate the commercial breakthrough of post-lithium-ion batteries. In particular, knowledge areas related to electrical vehicles have gained in importance in all of the examined battery technologies, reflecting the drive to produce high-energy battery systems. Third, it predicted the knowledge areas that could gain more relevance in the future research by comparing the predictive power of different machine learning algorithms. This forward-looking approach can add a new empirical perspective to the discussion of sustainable technology development. Fourth, in contrast to common assumption, it showed that SIBs could also power up portable applications like mobile devices or electric vehicles. (C) 2019 Elsevier Ltd. All rights reserved.","Post lithium-ion batteries,Lithium sulfur battery,Lithium air battery,Sodium-ion battery,Patent analysis,Link prediction",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Science & Technology - Other Topics,Engineering,Environmental Sciences & Ecology",,9.444,"ENERGY-STORAGE,TECHNOLOGIES,CO-CLASSIFICATION,ANALYSIS,LIFE-CYCLE,ASSESSMENT,ELECTRIC,VEHICLES,LINK-PREDICTION,CITATION,NETWORK,RECENT,PROGRESS,HYBRID,INNOVATION,IDENTIFICATION",JOURNAL OF CLEANER PRODUCTION,,
60,Microwave tomography with phaseless data on the calcaneus by means of artificial neural networks,58,2,433-442,"Fajardo J. E.,Lotto F. P.,Vericat F.,Carlevaro C. M.,Irastorza R. M.","Fajardo JE,Lotto FP,Vericat F,Carlevaro CM,Irastorza RM",Irastorza RM,10.1007/s11517-019-02090-y,Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET),"The aim of this study is to use a multilayer perceptron (MLP) artificial neural network (ANN) for phaseless imaging the human heel (modeled as a bilayer dielectric media: bone and surrounding tissue) and the calcaneus cross-section size and location using a two-dimensional (2D) microwave tomographic array. Computer simulations were performed over 2D dielectric maps inspired by computed tomography (CT) images of human heels for training and testing the MLP. A morphometric analysis was performed to account for the scatterer shape influence on the results. A robustness analysis was also conducted in order to study the MLP performance in noisy conditions. The standard deviations of the relative percentage errors on estimating the dielectric properties of the calcaneus bone were relatively high. Regarding the calcaneus surrounding tissue, the dielectric parameters estimations are better, with relative percentage error standard deviations up to approximate to 15%. The location and size of the calcaneus are always properly estimated with absolute error standard deviations up to approximate to 3 mm.
Microwave tomography of the calcaneus using phaseless data. Simulations were inspired in Computed Tomography images from real heels (above). Inverse problem was solved using Multilayer Perceptron Artificial Neural Network (below).","Calcaneus,Cancelous bone,Microwave tomography,Dielectric properties,Deep learning,Artificial neural networks",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,,MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,https://ri.conicet.gov.ar/bitstream/11336/121467/2/CONICET_Digital_Nro.6ebe4eac-7f64-417f-a749-2b3ecaae524f_A.pdf,
61,Compounding Meta-Atoms into Metamolecules with Hybrid Artificial Intelligence Techniques,32,6,,"Liu Zhaocheng,Zhu Dayu,Lee Kyu-Tae,Kim Andrew S.,Raju Lakshmi,Cai Wenshan","Liu ZC,Zhu DY,Lee KT,Kim AS,Raju L,Cai WS",Cai WS,10.1002/adma.201904790,University System of Georgia,"Molecules composed of atoms exhibit properties not inherent to their constituent atoms. Similarly, metamolecules consisting of multiple meta-atoms possess emerging features that the meta-atoms themselves do not possess. Metasurfaces composed of metamolecules with spatially variant building blocks, such as gradient metasurfaces, are drawing substantial attention due to their unconventional controllability of the amplitude, phase, and frequency of light. However, the intricate mechanisms and the large degrees of freedom of the multielement systems impede an effective strategy for the design and optimization of metamolecules. Here, a hybrid artificial-intelligence-based framework consolidating compositional pattern-producing networks and cooperative coevolution to resolve the inverse design of metamolecules in metasurfaces is proposed. The framework breaks the design of the metamolecules into separate designs of meta-atoms, and independently solves the smaller design tasks of the meta-atoms through deep learning and evolutionary algorithms. The proposed framework is leveraged to design metallic metamolecules for arbitrary manipulation of the polarization and wavefront of light. Moreover, the efficacy and reliability of the design strategy are confirmed through experimental validations. This framework reveals a promising candidate approach to expedite the design of large-scale metasurfaces in a labor-saving, systematic manner.","deep learning,evolutionary algorithms,nanophotonics,neural networks",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,30.254,"DEEP,NEURAL-NETWORKS,INVERSE,DESIGN,OPTICS",ADVANCED MATERIALS,https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/adma.201904790,
62,Attribute driven inverse materials design using deep learning Bayesian framework,5,,,"Tagade Piyush M.,Adiga Shashishekar P.,Pandian Shanthi,Park Min Sik,Hariharan Krishnan S.,Kolake Subramanya Mayya","Tagade PM,Adiga SP,Pandian S,Park MS,Hariharan KS,Kolake SM",Tagade PM; Adiga SP,10.1038/s41524-019-0263-3,Samsung,"Much of computational materials science has focused on fast and accurate forward predictions of materials properties, for example, given a molecular structure predict its electronic properties. This is achieved with first principles calculations and more recently through machine learning approaches, since the former is computation-intensive and not practical for high-throughput screening. Searching for the right material for any given application, though follows an inverse path-the desired properties are given and the task is to find the right materials. Here we present a deep learning inverse prediction framework, Structure Learning for Attribute-driven Materials Design Using Novel Conditional Sampling (SLAMDUNCS), for efficient and accurate prediction of molecules exhibiting target properties. We apply this framework to the computational design of organic molecules for three applications, organic semiconductors for thin-film transistors, small organic acceptors for solar cells and electrolyte additives with high redox stability. Our method is general enough to be extended to inorganic compounds and represents an important step in deep learning based completely automated materials discovery.","LI-ION BATTERIES,NEURAL-NETWORKS,ORGANIC SEMICONDUCTORS,MARKOV-CHAINS,POTENTIALS,CHALLENGES,ALGORITHM,ENERGIES,LANGUAGE,CELLS",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Chemistry,Materials Science",,13.993,"LI-ION,BATTERIES,NEURAL-NETWORKS,ORGANIC,SEMICONDUCTORS,MARKOV-CHAINS,POTENTIALS,CHALLENGES,ALGORITHM,ENERGIES,LANGUAGE,CELLS",NPJ COMPUTATIONAL MATERIALS,https://www.nature.com/articles/s41524-019-0263-3.pdf,
63,Machine learning guided appraisal and exploration of phase design for high entropy alloys,5,,,"Zhou Ziqing,Zhou Yeju,He Quanfeng,Ding Zhaoyi,Li Fucheng,Yang Yong","Zhou ZQ,Zhou YJ,He QF,Ding ZY,Li FC,Yang Y",Yang Y,10.1038/s41524-019-0265-1,City University of Hong Kong,"High entropy alloys (HEAs) and compositionally complex alloys (CCAs) have recently attracted great research interest because of their remarkable mechanical and physical properties. Although many useful HEAs or CCAs were reported, the rules of phase design, if there are any, which could guide alloy screening are still an open issue. In this work, we made a critical appraisal of the existing design rules commonly used by the academic community with different machine learning (ML) algorithms. Based on the artificial neural network algorithm, we were able to derive and extract a sensitivity matrix from the ML modeling, which enabled the quantitative assessment of how to tune a design parameter for the formation of a certain phase, such as solid solution, intermetallic, or amorphous phase. Furthermore, we explored the use of an extended set of new design parameters, which had not been considered before, for phase design in HEAs or CCAs with the ML modeling. To verify our ML-guided design rule, we performed various experiments and designed a series of alloys out of the Fe-Cr-Ni-Zr-Cu system. The outcomes of our experiments agree reasonably well with our predictions, which suggests that the ML-based techniques could be a useful tool in the future design of HEAs or CCAs.","SOLID-SOLUTION PHASE,SUPERCOOLED LIQUIDS,GLASS,STABILITY,SELECTION,PREDICTION,ELEMENTS",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Chemistry,Materials Science",,13.993,"SOLID-SOLUTION,PHASE,SUPERCOOLED,LIQUIDS,GLASS,STABILITY,SELECTION,PREDICTION,ELEMENTS",NPJ COMPUTATIONAL MATERIALS,https://www.nature.com/articles/s41524-019-0265-1.pdf,
64,Epileptic seizures identification with autoregressive model and firefly optimization based classification,12,3,827-836,"Attia Abdelouahab,Moussaoui Abdelouahab,Chahir Youssef","Attia A,Moussaoui A,Chahir Y",Attia A,10.1007/s12530-019-09319-z,"Mohamed El Bachir El Ibrahimi Univ Bordj Bou Arre, Fac Math & Informat, Comp Sci Dept, Bordj Bou Arreridj 34000, Algeria.","Identifying epilepsy cases and epileptic seizures from electroencephalogram (EEG) signals is a challenging issue, which usually needs high level of skilled neurophysiologists. Numerous works have attempted to develop tools that can provide an assistant to neurophysiologist in analyzing the EEG for epileptic seizures detection. This paper proposes a new automatic framework to identify and classify the epileptic seizure from EEG using a machine learning method. In particular, the feature extraction process of the proposed scheme utilizes autoregressive model (AR) and firefly optimization (FA) to procure an optimal model order (P). Namely, the main aim of FA is to find the best model order (P) with minimum residual variance using Akaike information criterion (AIC) as an objective function of FA algorithm. A support vector machine (SVM) classifier is employed for the classification of the epileptic seizures signals. The presented scheme is also effective for short segment of EEG signals owing to use of AR model in features extraction stage. Experiments with the publicly available Bonn database that is composed of healthy (nonepileptic), interictal and ictal EEG samples show promising results with high accuracy.","Epileptic seizures classification,AR model,Firefly algorithm,SVM,Akaike information criterion",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Computer Science,,1.827,"ARTIFICIAL,NEURAL-NETWORK,EEG,SIGNALS,SUPPORT",EVOLVING SYSTEMS,https://hal-normandie-univ.archives-ouvertes.fr/hal-02456493/document,
65,,,,,,,,,,,,,,,,,,,,
66,,,,,,,,,,,,,,,,,,,,
67,Vibration-based semantic damage segmentation for large-scale structural health monitoring,35,6,579-596,"Sajedi Seyed Omid,Liang Xiao","Sajedi SO,Liang X",Liang X,10.1111/mice.12523,State University of New York (SUNY) System,"Toward reduced recovery time after extreme events, near real-time damage diagnosis of structures is critical to provide reliable information. For this task, a fully convolutional encoder-decoder neural network is developed, which considers the spatial correlation of sensors in the automatic feature extraction process through a grid environment. A cost-sensitive score function is designed to include the consequences of misclassification in the framework while considering the ground motion uncertainty in training. A 10-story-10-bay reinforced concrete (RC) moment frame is modeled to present the design process of the deep learning architecture. The proposed models achieve global testing accuracies of 96.3% to locate damage and 93.2% to classify 16 damage mechanisms. Moreover, to handle class imbalance, three strategies are investigated enabling an increase of 16.2% regarding the mean damage class accuracy. To evaluate the generalization capacities of the framework, the classifiers are tested on 1,080 different RC frames by varying model properties. With less than a 2% reduction in global accuracy, the data-driven model is shown to be reliable for the damage diagnosis of different frames. Given the robustness and capabilities of the grid environment, the proposed framework is applicable to different domains of structural health monitoring research and practice to obtain reliable information.","MODAL PARAMETERS IDENTIFICATION,CUMULATIVE ABSOLUTE VELOCITY,SUPPORT VECTOR MACHINE,REAL-TIME,CONCRETE,MODEL,OPTIMIZATION,METHODOLOGY,DIAGNOSIS,FRAMEWORK",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Computer Science,Construction & Building Technology,Engineering,Transportation",,9.756,"MODAL,PARAMETERS,IDENTIFICATION,CUMULATIVE,ABSOLUTE,VELOCITY,SUPPORT,VECTOR,MACHINE,REAL-TIME,CONCRETE,MODEL,OPTIMIZATION,METHODOLOGY,DIAGNOSIS,FRAMEWORK",COMPUTER-AIDED CIVIL AND INFRASTRUCTURE ENGINEERING,,
68,Submillimeter MR fingerprinting using deep learning-based tissue quantification,84,2,579-591,"Fang Zhenghan,Chen Yong,Hung Sheng-Che,Zhang Xiaoxia,Lin Weili,Shen Dinggang","Fang ZH,Chen Y,Hung SC,Zhang XX,Lin WL,Shen DG",Shen DG,10.1002/mrm.28136,Korea University,"Purpose To develop a rapid 2D MR fingerprinting technique with a submillimeter in-plane resolution using a deep learning-based tissue quantification approach. Methods A rapid and high-resolution MR fingerprinting technique was developed for brain T-1 and T-2 quantification. The 2D acquisition was performed using a FISP-based MR fingerprinting sequence and a spiral trajectory with 0.8-mm in-plane resolution. A deep learning-based method was used to replace the standard template matching method for improved tissue characterization. A novel network architecture (i.e., residual channel attention U-Net) was proposed to improve high-resolution details in the estimated tissue maps. Quantitative brain imaging was performed with 5 adults and 2 pediatric subjects, and the performance of the proposed approach was compared with several existing methods in the literature. Results In vivo measurements with both adult and pediatric subjects show that high-quality T-1 and T-2 mapping with 0.8-mm in-plane resolution can be achieved in 7.5 seconds per slice. The proposed deep learning method outperformed existing algorithms in tissue quantification with improved accuracy. Compared with the standard U-Net, high-resolution details in brain tissues were better preserved by the proposed residual channel attention U-Net. Experiments on pediatric subjects further demonstrated the potential of the proposed technique for fast pediatric neuroimaging. Alongside reduced data acquisition time, a 5-fold acceleration in tissue property mapping was also achieved with the proposed method. Conclusion A rapid and high-resolution MR fingerprinting technique was developed, which enables high-quality T-1 and T-2 quantification with 0.8-mm in-plane resolution in 7.5 seconds per slice.","deep learning,MR fingerprinting,pediatric imaging,quantitative imaging",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"RECONSTRUCTION,BRAIN,T2",MAGNETIC RESONANCE IN MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8210473,
69,A deep learning based automatic surface segmentation algorithm for painting large-size aircraft with 6-DOF robot,40,2,199-210,"Wang Guolei,Hua Xiaotong,Xu Jing,Song Libin,Chen Ken","Wang GL,Hua XT,Xu J,Song LB,Chen K",Hua XT,10.1108/AA-03-2019-0037,Tsinghua University,"Purpose This paper aims to achieve automatically surface segmentation for painting different kinds of aircraft efficiently considering the demands of painting robot. Design/methodology/approach This project creatively proposed one method that accepts point cloud, outputs several blocks, each of which can be handled by ABB IRB 5500 in one station. Parallel PointNet (PPN) is proposed in this paper for better handling six dimensional aircraft data including every point normal. Through semantic segmentation of PPN, each surface has its own identity information indicating which part this surface belongs to. Then clustering considering constraints is applied to complete surface segmentation with identity information. To guarantee segmentation paintable and improve painting efficiency, different dexterous workspaces of IRB 5500 corresponding to different postures have been analyzed carefully. Findings The experiments confirm the effectiveness of the proposed surface segmentation method for painting different types of aircraft by IRB 5500. For semantic segmentation on aircraft data with point normal, PPN has higher precision than PointNet. In addition, the whole algorithm can efficiently segment one complex aircraft into qualified blocks, each of which has its own identity information, can be painted by IRB 5500 in one station and has fewer edges with other blocks. Research limitations/implications - As the provided experiments indicate, the proposed method can segment one aircraft into qualified blocks automatically, which highly improves the efficiency in aircraft painting compared with traditional approaches. Moreover, the proposed method is able to provide identity information of each block, which is necessary for application of different paint parameters and different paint materials. In addition, final segmentation results by the proposed method behaves better than k-means cluster on variance of normal vector distance. Originality/value Inspired by semantic segmentation of 3 D point cloud, some improvements based on PointNet have been proposed for better handling segmentation of 6 D point cloud. By introducing normal vectors, semantic segmentation could be accomplished precisely for close points with opposite normal, such as wing upper and lower surfaces. Combining deep learning skills with traditional methods, the proposed method is proved to behave much better for surface segmentation task in aircraft painting.","Deep learning,Automatic surface segmentation,Robot painting",Article,"EMERALD GROUP PUBLISHING LTD, HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND","Automation & Control Systems,Engineering",,1.667,,ASSEMBLY AUTOMATION,,
70,Analysis of kinking and twinning behavior in extruded Mg-Y-Zn alloys by acoustic emission method with supervised machine learning technique,768,,,"Shiraiwa Takayuki,Tamura Kengo,Enoki Manabu","Shiraiwa T,Tamura K,Enoki M",Shiraiwa T,10.1016/j.msea.2019.138473,University of Tokyo,"The deformation behavior of two extruded Mg-Y-Zn alloys with different volume fractions of long-period stacking ordered (LPSO) phase was analyzed by acoustic emission (AE) method in compression tests. As model materials for AE waveforms corresponding to twinning and kink band formation, pure magnesium and directionally-solidified Mg85Zn6Y9 alloy were also prepared. During compression testing of the model materials, the AE waveforms generated by twinning and kinking were successfully recorded by the combination of AE and high-speed imaging. Using the AE waveforms obtained in model materials, the AE signals in the two extruded Mg-Y-Zn alloys were classified into two classes of twinning and kinking by a supervised machine learning method. The behavior of these two AE classes is consistent with the results of surface observation and previous findings in the literature, and also provided quantitative information on twinning and kinking behavior during compression testing in the extruded Mg-Y-Zn alloys.","Magnesium alloys,Long-period stacking ordered structure (LPSO),Acoustic emission,Kink band,Twinning,Machine learning",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Science & Technology - Other Topics,Materials Science,Metallurgy & Metallurgical Engineering",,5.266,"STACKING-ORDERED,PHASE,TENSION-COMPRESSION,ASYMMETRY,MECHANICAL-PROPERTIES,DEFORMATION-BEHAVIOR,PLASTIC-DEFORMATION,PURE,MAGNESIUM,HIGH-STRENGTH,LPSO,PHASES,AS-CAST,CLASSIFICATION",MATERIALS SCIENCE AND ENGINEERING A-STRUCTURAL MATERIALS PROPERTIES MICROSTRUCTURE AND PROCESSING,,
71,The forward and inversion analysis of high rock-fill dam during construction period using the node-based smoothed point interpolation method,37,5,1531-1555,"Pan Shi Yang,Cheng Jing,Li Tong Chun","Pan SY,Cheng J,Li TC",Li TC,10.1108/EC-05-2019-0192,Hohai University,"Purpose The meshfree node-based smoothed point interpolation method (NS-PIM) is extended to the forward and inversion analysis of a high gravelly soil core rock-fill dam during construction periods. Design/methodology/approach As one member of the meshfree methods, the NS-PIM has the advantages of ""softer"" stiffness and adaptability to large deformations which is quite indispensable for the stability analysis of rock-fill dams. In this work, the present method contains a reconstruction procedure to deal with the existence or nonexistence of the construction layers. After verifying the validity of the NS-PIM method for nonlinear elastic model during construction period, the convergence features of the NS-PIM and FEM methods are further investigated with different mesh schemes. Furthermore, the NS-PIM and FEM methods are applied for the forward analysis of a high gravelly soil core rock-fill dam and the convergence features under complex stress conditions are also studied using the rock-fill dam model. Finally, the NS-PIM method is used to calculate the Duncan-Chang parameters of the deep overburden under the high gravelly soil core rock-fill dam based on the back-propagation neural network method. Findings The results show that: the NS-PIM solution for construction analysis still possesses the property of upper bound solution even under complex stress conditions and can provide comparatively more conservative results for safety evaluation. Furthermore, it can be used to evaluate the accuracy of results and mesh quality together with the FEM solution which has the property of lower bound solution; the inversion analysis in this work provides a set of material parameters for the deep overburden under high rock-fill dam during construction period and the calculated results show good agreement with the measured displacement values and it is feasible to apply the NS-PIM to the forward and inversion analysis of high rock-fill dams on deep overburden during construction periods.
Originality/value First, the analysis from forward to inversion for high rock-fill dams during construction period using the NS-PIM solution is accomplished in this work. A procedure dealing with the existence or nonexistence of the construction layers is also developed for the construction analysis. Second, it is confirmed in this work that the NS-PIM still possesses the property of upper bound solution even under complex stress conditions (the forward analysis of high rock-fill dams during construction period). Thus, more conservative results can be provided for safety evaluation. Furthermore, it can be used to evaluate the accuracy of results and mesh quality together with the FEM solution which has the property of lower bound solution. Third, the calculated material parameters of the deep overburden in this work can be used for further studies of the high rock-fill dam.","Meshfree methods,Deep overburden,Duncan-Chang model,High rock-fill dam,Inversion analysis",Article,"EMERALD GROUP PUBLISHING LTD, HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND","Computer Science,Engineering,Mathematics,Mechanics",,1.442,"HEAT-TRANSFER,BACK-ANALYSIS,PIM,PARAMETERS,ALGORITHM",ENGINEERING COMPUTATIONS,,
72,Machine learning for the detection of early immunological markers as predictors of multi-organ dysfunction,6,1,,"Bravo-Merodio Laura,Acharjee Animesh,Hazeldine Jon,Bentley Conor,Foster Mark,Gkoutos Georgios V.,Lord Janet M.","Bravo-Merodio L,Acharjee A,Hazeldine J,Bentley C,Foster M,Gkoutos GV,Lord JM",Acharjee A; Gkoutos GV,10.1038/s41597-019-0337-6,University of Birmingham,"The immune response to major trauma has been analysed mainly within post-hospital admission settings where the inflammatory response is already underway and the early drivers of clinical outcome cannot be readily determined. Thus, there is a need to better understand the immediate immune response to injury and how this might influence important patient outcomes such as multi-organ dysfunction syndrome (MODS). In this study, we have assessed the immune response to trauma in 61 patients at three different post-injury time points (ultra-early (<=1 h), 4-12 h, 48-72 h) and analysed relationships with the development of MODS. We developed a pipeline using Absolute Shrinkage and Selection Operator and Elastic Net feature selection methods that were able to identify 3 physiological features (decrease in neutrophil CD62L and CD63 expression and monocyte CD63 expression and frequency) as possible biomarkers for MODS development. After univariate and multivariate analysis for each feature alongside a stability analysis, the addition of these 3 markers to standard clinical trauma injury severity scores yields a Generalized Liner Model (GLM) with an average Area Under the Curve value of 0.92 +/- 0.06. This performance provides an 8% improvement over the Probability of Survival (PS14) outcome measure and a 13% improvement over the New Injury Severity Score (NISS) for identifying patients at risk of MODS.","MULTIPLE ORGAN DYSFUNCTION,TRAUMA,SELECTION,MORTALITY,PATTERNS,SEPSIS",Article; Data Paper,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,9.051,"MULTIPLE,ORGAN,DYSFUNCTION,TRAUMA,SELECTION,MORTALITY,PATTERNS,SEPSIS",SCIENTIFIC DATA,https://www.nature.com/articles/s41597-019-0337-6.pdf,
73,EEG-based image classification via a region-level stacked bi-directional deep learning framework,19,,,"Fares Ahmed,Zhong Sheng-hua,Jiang Jianmin","Fares A,Zhong SH,Jiang JM",Jiang JM,10.1186/s12911-019-0967-9,Shenzhen University,"Background: As a physiological signal, EEG data cannot be subjectively changed or hidden. Compared with other physiological signals, EEG signals are directly related to human cortical activities with excellent temporal resolution. After the rapid development of machine learning and artificial intelligence, the analysis and calculation of EEGs has made great progress, leading to a significant boost in performances for content understanding and pattern recognition of brain activities across the areas of both neural science and computer vision. While such an enormous advance has attracted wide range of interests among relevant research communities, EEG-based classification of brain activities evoked by images still demands efforts for further improvement with respect to its accuracy, generalization, and interpretation, yet some characters of human brains have been relatively unexplored.
Methods: We propose a region-level stacked bi-directional deep learning framework for EEG-based image classification. Inspired by the hemispheric lateralization of human brains, we propose to extract additional information at regional level to strengthen and emphasize the differences between two hemispheres. The stacked bi-directional long short-term memories are used to capture the dynamic correlations hidden from both the past and the future to the current state in EEG sequences.
Results: Extensive experiments are carried out and our results demonstrate the effectiveness of our proposed framework. Compared with the existing state-of-the-arts, our framework achieves outstanding performances in EEG-based classification of brain activities evoked by images. In addition, we find that the signals of Gamma band are not only useful for achieving good performances for EEG-based image classification, but also play a significant role in capturing relationships between the neural activations and the specific emotional states.
Conclusions: Our proposed framework provides an improved solution for the problem that, given an image used to stimulate brain activities, we should be able to identify which class the stimuli image comes from by analyzing the EEG signals. The region-level information is extracted to preserve and emphasize the hemispheric lateralization for neural functions or cognitive processes of human brains. Further, stacked bi-directional LSTMs are used to capture the dynamic correlations hidden in EEG data. Extensive experiments on standard EEG-based image classification dataset validate that our framework outperforms the existing state-of-the-arts under various contexts and experimental setups.","EEG,Classification of brain activities,Region-level information,Stacked bi-directional LSTM",Article; Proceedings Paper,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Medical Informatics,,3.394,"CONVOLUTIONAL,NEURAL-NETWORKS,EMOTION,RECOGNITION,LATERALIZATION,MUSIC,SLEEP,LOAD",BMC MEDICAL INFORMATICS AND DECISION MAKING,https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/s12911-019-0967-9,
74,Automated segmentation of cardiomyocyte Z-disks from high-throughput scanning electron microscopy data,19,,,"Khadangi Afshin,Hanssen Eric,Rajagopal Vijay","Khadangi A,Hanssen E,Rajagopal V",Khadangi A,10.1186/s12911-019-0962-1,University of Melbourne,"Background: With the advent of new high-throughput electron microscopy techniques such as serial block-face scanning electron microscopy (SBF-SEM) and focused ion-beam scanning electron microscopy (FIB-SEM) biomedical scientists can study sub-cellular structural mechanisms of heart disease at high resolution and high volume. Among several key components that determine healthy contractile function in cardiomyocytes are Z-disks or Z-lines, which are located at the lateral borders of the sarcomere, the fundamental unit of striated muscle. Z-disks play the important role of anchoring contractile proteins within the cell that make the heartbeat. Changes to their organization can affect the force with which the cardiomyocyte contracts and may also affect signaling pathways that regulate cardiomyocyte health and function. Compared to other components in the cell, such as mitochondria, Z-disks appear as very thin linear structures in microscopy data with limited difference in contrast to the remaining components of the cell.
Methods: In this paper, we propose to generate a 3D model of Z-disks within single adult cardiac cells from an automated segmentation of a large serial-block-face scanning electron microscopy (SBF-SEM) dataset. The proposed fully automated segmentation scheme is comprised of three main modules including ""pre-processing"", ""segmentation"" and ""refinement"". We represent a simple, yet effective model to perform segmentation and refinement steps. Contrast stretching, and Gaussian kernels are used to pre-process the dataset, and well-known ""Sobel operators"" are used in the segmentation module.
Results: We have validated our model by comparing segmentation results with ground-truth annotated Z-disks in terms of pixel-wise accuracy. The results show that our model correctly detects Z-disks with 90.56% accuracy. We also compare and contrast the accuracy of the proposed algorithm in segmenting a FIB-SEM dataset against the accuracy of segmentations from a machine learning program called Ilastik and discuss the advantages and disadvantages that these two approaches have.
Conclusions: Our validation results demonstrate the robustness and reliability of our algorithm and model both in terms of validation metrics and in terms of a comparison with a 3D visualisation of Z-disks obtained using immunofluorescence based confocal imaging.","Cardiac ultrastructure,Image segmentation,Serial-block-face scanning electron microscopy,Focused ion-beam scanning electron microscopy,Computational biology",Article; Proceedings Paper,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Medical Informatics,,3.394,REVEALS,BMC MEDICAL INFORMATICS AND DECISION MAKING,https://europepmc.org/articles/pmc6921388?pdf=render,
75,,,,,,,,,,,,,,,,,,,,
76,,,,,,,,,,,,,,,,,,,,
77,A success history-based adaptive differential evolution optimized support vector regression for estimating plastic viscosity of fresh concrete,37,2,1485-1498,"The-Duong Nguyen,Thu-Hien Tran,Hieu Nguyen,Hoang Nhat-Duc","Nguyen TD,Tran TH,Nguyen H,Hoang ND",Hoang ND,10.1007/s00366-019-00899-7,"Fac Civil Engn, Inst Res & Dev, P809-03 Quang Trung, Da Nang, Vietnam.","Plastic viscosity is an important parameter of fresh concrete mixes. This research investigates a machine learning-based method for constructing a functional mapping between concrete mix properties and the plastic viscosity. The investigated machine learning method relies on the support vector regression (SVR) which is a robust method for nonlinear and multivariate function approximation. Moreover, the history-based adaptive differential evolution with linear population size reduction (L-SHADE) is employed to optimize the SVR model construction phase. Thus, the proposed method, named L-SHADE-SVR, is an integration of machine learning and metaheuristic optimization. To train and verify the L-SHADE-SVR model, a dataset consisting of 142 experimental tests was collected. Experimental results with repetitive phases of model training and testing reveal that the newly constructed model is capable of delivering highly accurate estimation of the plastic viscosity with mean absolute percentage error of 12% and coefficient of determination of 0.82. These outcomes are superior compared to the employed benchmark methods including artificial neural network, multivariate adaptive regression spline, and sequential piecewise multiple linear regression. Therefore, the L-SHADE-SVR model is a promising tool to assist construction engineers in estimating the plastic viscosity of fresh concrete mixes.","Plastic viscosity,Fresh concrete,Support vector regression,L-SHADE,Machine learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Computer Science,Engineering",,6.544,"COMPRESSIVE,STRENGTH,PREDICTION,PULL-OFF,ADHESION,FIREFLY,ALGORITHM,TENSILE-STRENGTH,ELASTIC-MODULUS,AGGREGATE,BEHAVIOR,SYSTEM,MODEL,FLOW",ENGINEERING WITH COMPUTERS,,
78,Fog Computing Employed Computer Aided Cancer Classification System Using Deep Neural Network in Internet of Things Based Healthcare System,44,2,,"Rajan J. Pandia,Rajan S. Edward,Martis Roshan Joy,Panigrahi B. K.","Rajan JP,Rajan SE,Martis RJ,Panigrahi BK",Rajan JP,10.1007/s10916-019-1500-5,Mepco Schlenk Engineering College,"Computer assisted automatic smart pattern analysis of cancer affected pixel structure takes critical role in pre-interventional decision making for oral cancer treatment. Internet of Things (IoT) in healthcare systems is now emerging solution for modern e-healthcare system to provide high quality medical care. In this research work, we proposed a novel method which utilizes a modified vesselness measurement and a Deep Convolutional Neural Network (DCNN) to identify the oral cancer region structure in IoT based smart healthcare system. The robust vesselness filtering scheme handles noise while reserving small structures, while the CNN framework considerably improves classification accuracy by deblurring focused region of interest (ROI) through integrating with multi-dimensional information from feature vector selection step. The marked feature vector points are extracted from each connected component in the region and used as input for training the CNN. During classification, each connected part is individually analysed using the trained DCNN by considering the feature vector values that belong to its region. For a training of 1500 image dataset, an accuracy of 96.8% and sensitivity of 92% is obtained. Hence, the results of this work validate that the proposed algorithm is effective and accurate in terms of classification of oral cancer region in accurate decision making. The developed system can be used in IoT based diagnosis in health care systems, where accuracy and real time diagnosis are essential.","Deep convolutional neural network,Computer vision,Medical image analysis,IoT architecture",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Health Care Sciences & Services,Medical Informatics",,3.951,"IMAGE,CNN",JOURNAL OF MEDICAL SYSTEMS,,
79,Application of automated electron microscopy imaging and machine learning to characterise and quantify nanoparticle dispersion in aqueous media,279,3,177-184,"Ilett M.,Wills J.,Rees P.,Sharma S.,Micklethwaite S.,Brown A.,Brydson R.,Hondow N.","Ilett M,Wills J,Rees P,Sharma S,Micklethwaite S,Brown A,Brydson R,Hondow N",Ilett M,10.1111/jmi.12853,University of Leeds,"For many nanoparticle applications it is important to understand dispersion in liquids. For nanomedicinal and nanotoxicological research this is complicated by the often complex nature of the biological dispersant and ultimately this leads to severe limitations in the analysis of the nanoparticle dispersion by light scattering techniques. Here we present an alternative analysis and associated workflow which utilises electron microscopy. The need to collect large, statistically relevant datasets by imaging vacuum dried, plunge frozen aliquots of suspension was accomplished by developing an automated STEM imaging protocol implemented in an SEM fitted with a transmission detector. Automated analysis of images of agglomerates was achieved by machine learning using two free open-source software tools: CellProfiler and ilastik. The specific results and overall workflow described enable accurate nanoparticle agglomerate analysis of particles suspended in aqueous media containing other potential confounding components such as salts, vitamins and proteins. Lay Description In order to further advance studies in both nanomedicine and nanotoxicology, we need to continue to understand the dispersion of nanoparticles in biological fluids. These biological environments often contain a number of components such as salts, vitamins and proteins which can lead to difficulties when using traditional techniques to monitor dispersion. Here we present an alternative analysis which utilises electron microscopy. In order to use this approach statistically relevant large image datasets were collected from appropriately prepared samples of nanoparticle suspensions by implementing an automated imaging protocol. Automated analysis of these images was achieved through machine learning using two readily accessible freeware; CellProfiler and ilastik. The workflow presented enables accurate nanoparticle dispersion analysis of particles suspended in more complex biological media.","Agglomeration,automated imaging,machine learning,nanoparticles",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Microscopy,,1.855,"IRON-OXIDE,NANOPARTICLES,PROTEIN,CORONA,AGGLOMERATION,SIZE,PARTICLES,STATE",JOURNAL OF MICROSCOPY,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/jmi.12853,
80,Validation of an automated ASPECTS method on non-contrast computed tomography scans of acute ischemic stroke patients,15,5,528-534,"Kuang Hulin,Qiu Wu,Najm Mohamed,Dowlatshahi Dar,Mikulik Robert,Poppe Alex Y.,Puig Josep,Castellanos Mar,Sohn Sung I,Ahn Seong H.","Kuang HL,Qiu W,Najm M,Dowlatshahi D,Mikulik R,Poppe AY,Puig J,Castellanos M,Sohn SI,Ahn SH",Menon BK,10.1177/1747493019895702,"1079 A,29th St NW, Calgary, AB T2N 2T9, Canada.","Background The Alberta Stroke Program Early CT Score (ASPECTS) is a systematic method of assessing the extent of early ischemic change on non-contrast computed tomography in patients with acute ischemic stroke. Our objective was to validate an automated ASPECTS scoring method we recently developed on a large data set. Materials and methods We retrospectively collected 602 acute ischemic stroke patients' non-contrast computed tomography scans. Expert ASPECTS readings on non-contrast computed tomography were compared to automated ASPECTS. Statistical analyses on the total ASPECTS, region level ASPECTS, and dichotomized ASPECTS (<= 4 vs. >4) score were conducted. Results In total, 602 scans were evaluated and 6020 (602 x 10) ASPECTS regions were scored. Median time from stroke onset to computed tomography was 114 min (interquartile range: 73-183 min). Total ASPECTS for the 602 patients generated by the automated method agreed well with expert readings (intraclass correlation coefficient): 0.65 (95% confidence interval (CI): 0.60-0.69). Region level analysis showed that the automated method yielded accuracy of 81.25%, sensitivity of 61.13% (95% CI: 58.4%-63.8%), specificity of 86.56% (95% CI: 85.6%-87.5%), and area under curve of 0.74 (95% CI: 0.73-0.75). For dichotomized ASPECTS (<= 4 vs. >4), the automated method demonstrated sensitivity 97.21% (95% CI: 95.4%-98.4%), specificity 57.81% (95% CI: 44.8%-70.1%), accuracy 93.02%, and area under the curve of 0.78 (95% CI: 0.74-0.81). For each individual region (M1-6, lentiform, insula, and caudate), the automated method demonstrated acceptable performance. Conclusion The automated system we developed approached the stroke expert in performance when scoring ASPECTS on non-contrast computed tomography scans of acute ischemic stroke patients.","Alberta Stroke Program Early CT score,non-contrast computed tomography,ischemic stroke,machine learning,automated ASPECTS scoring",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",,,5.17,"HYPERACUTE,STROKE,CT,ANGIOGRAPHY,SCORE,REPERFUSION,SOFTWARE",INTERNATIONAL JOURNAL OF STROKE,,
81,Rakeness with block sparse Bayesian learning for efficient ZigBee-based EEG telemonitoring,33,3,,"Hanafy Mohamed A.,Ali Hanaa S.,Shaalan A. A.","Hanafy MA,Ali HS,Shaalan AA",Ali HS,10.1002/dac.4219,Egyptian Knowledge Bank (EKB),"Future healthcare systems are shifted toward long-term patient monitoring using embedded ultra-low power devices. In this paper, the strengths of both rakeness-based compressive sensing (CS) and block sparse Bayesian learning (BSBL) are exploited for efficient electroencephalogram (EEG) transmission/reception over wireless body area networks. A binary sensing matrix based on the rakeness concept is used to find the most energetic signal directions. A balance is achieved between collecting energy and enforcing restricted isometry property to capture the underlying signal structure. Correct presentation of the EEG oscillatory activity, EEG wave shape, and main signal characteristics is provided using the discrete cosine transform based BSBL, which models the intra-block correlation. The IEEE 802.15.4 wireless communication technology (ZigBee) is employed, since it targets low data rate communications in an energy efficient manner. To alleviate noise and channel multipath effects, a recursive least square based equalizer is used, with an adaptation algorithm that continually updates the filter weights using successive input samples. For the same compression ratio (CR), results indicate that the proposed system permits a higher reconstruction quality compared with the standard CS algorithm. For higher CRs, lower dimensional projections are allowed, meanwhile guaranteeing a correct reconstruction. Thus, low computational high quality data compression/reconstruction are achieved with minimal energy expenditure at the sensors nodes.","block sparse Bayesian learning (BSBL),EEG telemonitoring,IEEE 802,15,4,rakeness,recursive least square (RLS)",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Telecommunications",,,"SIGNALS,ALGORITHMS",INTERNATIONAL JOURNAL OF COMMUNICATION SYSTEMS,,
82,Reproducible Ultrathin Ferroelectric Domain Switching for High-Performance Neuromorphic Computing,32,7,,"Li Jiankun,Ge Chen,Du Jianyu,Wang Can,Yang Guozhen,Jin Kuijuan","Li JK,Ge C,Du JY,Wang C,Yang GZ,Jin KJ",Ge C; Jin KJ,10.1002/adma.201905764,Chinese Academy of Sciences,"Neuromorphic computing consisting of artificial synapses and neural network algorithms provides a promising approach for overcoming the inherent limitations of current computing architecture. Developments in electronic devices that can accurately mimic the synaptic plasticity of biological synapses, have promoted the research boom of neuromorphic computing. It is reported that robust ferroelectric tunnel junctions can be employed to design high-performance electronic synapses. These devices show an excellent memristor function with many reproducible states (approximate to 200) through gradual ferroelectric domain switching. Both short- and long-term plasticity can be emulated by finely tuning the applied pulse parameters in the electronic synapse. The analog conductance switching exhibits high linearity and symmetry with small switching variations. A simulated artificial neural network with supervised learning built from these synaptic devices exhibited high classification accuracy (96.4%) for the Mixed National Institute of Standards and Technology (MNIST) handwritten recognition data set.","electronic synapses,ferroelectric domain switching,ferroelectric tunnel junctions,neuromorphic computing,ultrathin films",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,30.254,"ELECTRORESISTANCE,DEVICE",ADVANCED MATERIALS,,
83,A Deep Learning Approach for Automated Diagnosis and Multi-Class Classification of Alzheimer's Disease Stages Using Resting-State fMRI and Residual Neural Networks,44,2,,"Ramzan Farheen,Khan Muhammad Usman Ghani,Rehmat Asim,Iqbal Sajid,Saba Tanzila,Rehman Amjad,Mehmood Zahid","Ramzan F,Khan MUG,Rehmat A,Iqbal S,Saba T,Rehman A,Mehmood Z",Iqbal S,10.1007/s10916-019-1475-2,"UET, Dept Comp Sci & Engn, Lahore, Pakistan.","Alzheimer's disease (AD) is an incurable neurodegenerative disorder accounting for 70%-80% dementia cases worldwide. Although, research on AD has increased in recent years, however, the complexity associated with brain structure and functions makes the early diagnosis of this disease a challenging task. Resting-state functional magnetic resonance imaging (rs-fMRI) is a neuroimaging technology that has been widely used to study the pathogenesis of neurodegenerative diseases. In literature, the computer-aided diagnosis of AD is limited to binary classification or diagnosis of AD and MCI stages. However, its applicability to diagnose multiple progressive stages of AD is relatively under-studied. This study explores the effectiveness of rs-fMRI for multi-class classification of AD and its associated stages including CN, SMC, EMCI, MCI, LMCI, and AD. A longitudinal cohort of resting-state fMRI of 138 subjects (25 CN, 25 SMC, 25 EMCI, 25 LMCI, 13 MCI, and 25 AD) from Alzheimer's Disease Neuroimaging Initiative (ADNI) is studied. To provide a better insight into deep learning approaches and their applications to AD classification, we investigate ResNet-18 architecture in detail. We consider the training of the network from scratch by using single-channel input as well as performed transfer learning with and without fine-tuning using an extended network architecture. We experimented with residual neural networks to perform AD classification task and compared it with former research in this domain. The performance of the models is evaluated using precision, recall, f1-measure, AUC and ROC curves. We found that our networks were able to significantly classify the subjects. We achieved improved results with our fine-tuned model for all the AD stages with an accuracy of 100%, 96.85%, 97.38%, 97.43%, 97.40% and 98.01% for CN, SMC, EMCI, LMCI, MCI, and AD respectively. However, in terms of overall performance, we achieved state-of-the-art results with an average accuracy of 97.92% and 97.88% for off-the-shelf and fine-tuned models respectively. The Analysis of results indicate that classification and prediction of neurodegenerative brain disorders such as AD using functional magnetic resonance imaging and advanced deep learning methods is promising for clinical decision making and have the potential to assist in early diagnosis of AD and its associated stages.","Alzheimer's disease,Functional magnetic resonance imaging (fMRI),Diagnosis,Multi-class,Classification,Deep learning,Residual neural networks",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Health Care Sciences & Services,Medical Informatics",,3.951,"FEATURE,REPRESENTATION,MOTION,CORRECTION,HEAD-MOTION,ROBUST,DEMENTIA,OPTIMIZATION,REGISTRATION,ACCURATE,MODEL",JOURNAL OF MEDICAL SYSTEMS,,
84,An Improved Convolutional Neural Network Based Approach for Automated Heartbeat Classification,44,2,,"Wang Haoren,Shi Haotian,Chen Xiaojun,Zhao Liqun,Huang Yixiang,Liu Chengliang","Wang HR,Shi HT,Chen XJ,Zhao LQ,Huang YX,Liu CL",Liu CL,10.1007/s10916-019-1511-2,Shanghai Jiao Tong University,"With age, our blood vessels are prone to aging, which induces cardiovascular disease. As an important basis for diagnosing heart disease and evaluating heart function, the electrocardiogram (ECG) records cardiac physiological electrical activity. Abnormalities in cardiac physiological activity are directly reflected in the ECG. Thus, ECG research is conducive to heart disease diagnosis. Considering the complexity of arrhythmia detection, we present an improved convolutional neural network (CNN) model for accurate classification. Compared with the traditional machine learning methods, CNN requires no additional feature extraction steps due to the automatic feature processing layers. In this paper, an improved CNN is proposed to automatically classify the heartbeat of arrhythmia. Firstly, all the heartbeats are divided from the original signals. After segmentation, the ECG heartbeats can be inputted into the first convolutional layers. In the proposed structure, kernels with different sizes are used in each convolution layer, which takes full advantage of the features in different scales. Then a max-pooling layer followed. The outputs of the last pooling layer are merged and as the input to fully-connected layers. Our experiment is in accordance with the AAMI inter-patient standard, which included normal beats (N), supraventricular ectopic beats (S), ventricular ectopic beats (V), fusion beats (F), and unknown beats (Q). For verification, the MIT arrhythmia database is introduced to confirm the accuracy of the proposed method, then, comparative experiments are conducted. The experiment demonstrates that our proposed method has high performance for arrhythmia detection, the accuracy is 99.06%. When properly trained, the proposed improved CNN model can be employed as a tool to automatically detect different kinds of arrhythmia from ECG.","Electrocardiogram (ECG),Heartbeat classification,Signal processing,Convolutional neural networks,MIT database",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Health Care Sciences & Services,Medical Informatics",,3.951,"ECG,CLASSIFICATION,FEATURES,TRANSFORM,ENTROPY",JOURNAL OF MEDICAL SYSTEMS,,
85,Validation Study of QSAR/DNN Models Using the Competition Datasets,39,1-2,,"Kato Yoshiki,Hamada Shinji,Goto Hitoshi","Kato Y,Hamada S,Goto H",Goto H,10.1002/minf.201900154,Toyohashi University of Technology,"Since the QSAR/DNN model showed predominant predictive performance over other conventional methods in the Kaggle QSAR competition, many artificial neural network (ANN) methods have been applied to drug and material discovery. Appearance of artificial intelligence (AI), which is combined various general purpose ANN platforms with large-scale open access chemical databases, has attracting great interest and expectation in a wide range of molecular sciences. In this study, we investigate various DNN settings in order to reach a high-level of predictive performance comparable to the champion team of the competition, even with a general purpose ANN platform, and introduce the Meister setting for constructing a good QSAR/DNNs model. Here, we have used the most commonly available DNN model and constructed many QSAR/DNN models trained with various DNN settings by using the 15 datasets employed in the competition. As a result, it was confirmed that we can constructed the QSAR/DNN model that shows the same level of R2 performance as the champion team. The difference from the DNN setting recommended by the champion team was to reduce the mini-batch size. We have also explained that the R2 performance of each target depends on the molecular activity type, which is related to the complexity of biological mechanisms and chemical processes observed in molecular activity measurements.","Merck Molecular,Activity Challenge,Chainer Chemistry,Deep Neural Network,Machine Learning",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Pharmacology & Pharmacy,Computer Science,Mathematical & Computational Biology",,2.723,"DERIVATIVES,INHIBITION,DOCKING,ADMET",MOLECULAR INFORMATICS,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/minf.201900154,
86,Predicting Thermal Properties of Crystals Using Machine Learning,3,2,,"Tawfik Sherif Abdulkader,Isayev Olexandr,Spencer Michelle J. S.,Winkler David A.","Tawfik SA,Isayev O,Spencer MJS,Winkler DA",Tawfik SA; Spencer MJS,10.1002/adts.201900208,Royal Melbourne Institute of Technology (RMIT),"Calculating vibrational properties of crystals using quantum mechanical (QM) methods is a challenging problem in computational material science. This problem is solved using complementary machine learning methods that rapidly and reliably recapitulate entropy, specific heat, effective polycrystalline dielectric function, and a non-vibrational property (band gap) for materials calculated by accurate but lengthy QM methods. The materials are described mathematically using property-labeled materials fragment descriptors. The machine learning models predict the QM properties with root mean square errors of 0.31 meV per atom per K for entropy, 0.18 meV per atom per K for specific heat, 4.41 for the trace of the dielectric tensor, and 0.5 eV for band gap. These models are sufficiently accurate to allow rapid screening of large numbers of crystal structures to accelerate material discovery.","crystal properties,density-functional theory,dielectric constant,entropy,machine learning",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Science & Technology - Other Topics,,4.004,,ADVANCED THEORY AND SIMULATIONS,,
87,Computer vision-based damage and stress state estimation for reinforced concrete and steel fiber-reinforced concrete panels,19,6,1645-1665,"Davoudi Rouzbeh,Miller Gregory R.,Calvi Paolo,Kutz J. Nathan","Davoudi R,Miller GR,Calvi P,Kutz JN",Davoudi R,10.1177/1475921719892345,University of Washington,"This article presents a computer vision damage assessment approach that relates surface crack patterns to damage levels and stress state characteristics in conventionally reinforced concrete and steel fiber-reinforced concrete panels. Previous studies have focused on crack patterns for specific structural element types such as beams and columns, but this study considers stress states in a more general framework. In particular, image data from previously published panel test specimens subjected to nominally constant stress have been collected to develop image-based estimation models capable of quantifying damage levels and stress components for full-panel crack patterns, and to investigate subimage sampling strategies to approximate full-panel results using partial-panel images. The objective here is to show that the analog of representative volume elements can be extended to image-based analysis contexts. The image datasets used in this article have been obtained from five different published studies, which provided 189 crack pattern images captured from 33 concrete and steel fiber-reinforced concrete shear panel specimens. Given the limited size of the dataset, a feature-based computer vision approach has been used, with various geometric attributes of surface crack patterns used to train the estimation models. Within the limits of the data available, the preliminary results presented here indicate that quantifiable correlations exist such that stress state and damage level estimation models are valid across a range of loadings (i.e. reverse cyclic and monotonic) and materials (reinforced concrete and steel fiber-reinforced concrete), and that with appropriate sampling techniques, it is possible for subsampled images to yield estimations similar to full-panel results. These localized correlations between crack patterns and stress states potentially could be used in broader contexts for damage assessment of more general reinforced concrete and steel fiber-reinforced concrete members.","Computer vision,machine learning,damage assessment,reinforced concrete,fiber reinforcing,panels",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Engineering,Instruments & Instrumentation",,5.861,"FIELD,MODEL",STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL,,
88,Performance evaluation of classification methods with PCA and PSO for diabetes,9,1,,"Choubey Dilip Kumar,Kumar Prabhat,Tripathi Sudhakar,Kumar Santosh","Choubey DK,Kumar P,Tripathi S,Kumar S",Choubey DK,10.1007/s13721-019-0210-8,Vellore Institute of Technology,"Diabetes has become one of the major health concerns for the modern day population. This can be attributed to a number of factors such as unhealthy lifestyle, meager diet, genetics, obesity, etc. The rapid growth in the number of diabetic patients urges the requirement for a state-of-the-art healthcare against such diseases. Early prediction of such diseases can be very useful for mitigating the risks associated with such diseases. In this context, this research proposes an indigenous efficient diagnostic tool for the detection of diabetes. The proposed methodology comprises two phases: Phase-I deals with collection of Pima Indian Diabetes Dataset from the UCI machine learning repository databases and Localized Diabetes Dataset from Bombay Medical Hall, Upper Bazar Ranchi, Jharkhand, India. In Phase-II, the acquired datasets are processed and analyzed using two different approaches. The first approach entails classification through Logistic Regression, K-Nearest Neighbor, ID3 DT, C4.5 DT, and Naive Bayes. The second approach employs PCA and PSO algorithms for feature reduction prior to the classification of the dataset using the methods used in the first approach. A comparative analysis is performed between the various approaches used in this manuscript. Results obtained clearly depict the efficiency of the proposed approach over the traditional classification approach in terms of less computation time and increased accuracy. The proposed approach has the potential to be applied for effective and early diagnosis of other medical diseases as well.","Pima Indian diabetes dataset,Localized diabetes dataset,PCA,PSO,Feature reduction,Logistic regression,K-nearest neighbor,ID3 DT,C4,5 DT,Naive Bayes,Classification",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Mathematical & Computational Biology,,,"PARTICLE,SWARM,OPTIMIZATION,SUPPORT,VECTOR,MACHINES,K-NEAREST,NEIGHBOR,FEATURE-SELECTION,LOGISTIC-REGRESSION,RULE,EXTRACTION,EXPERT-SYSTEM,DIAGNOSIS,DISEASE,MODEL",NETWORK MODELING AND ANALYSIS IN HEALTH INFORMATICS AND BIOINFORMATICS,,
89,Brain Tumor Detection by Using Stacked Autoencoders in Deep Learning,44,2,,"Amin Javaria,Sharif Muhammad,Gul Nadia,Raza Mudassar,Anjum Muhammad Almas,Nisar Muhammad Wasif,Bukhari Syed Ahmad Chan","Amin J,Sharif M,Gul N,Raza M,Anjum MA,Nisar MW,Bukhari SAC",Sharif M,10.1007/s10916-019-1483-2,COMSATS University Islamabad (CUI),"Brain tumor detection depicts a tough job because of its shape, size and appearance variations. In this manuscript, a deep learning model is deployed to predict input slices as a tumor (unhealthy)/non-tumor (healthy). This manuscript employs a high pass filter image to prominent the inhomogeneities field effect of the MR slices and fused with the input slices. Moreover, the median filter is applied to the fused slices. The resultant slices quality is improved with smoothen and highlighted edges of the input slices. After that, based on these slices' intensity, a 4-connected seed growing algorithm is applied, where optimal threshold clusters the similar pixels from the input slices. The segmented slices are then supplied to the fine-tuned two layers proposed stacked sparse autoencoder (SSAE) model. The hyperparameters of the model are selected after extensive experiments. At the first layer, 200 hidden units and at the second layer 400 hidden units are utilized. The testing is performed on the softmax layer for the prediction of the images having tumors and no tumors. The suggested model is trained and checked on BRATS datasets i.e., 2012(challenge and synthetic), 2013, and 2013 Leaderboard, 2014, and 2015 datasets. The presented model is evaluated with a number of performance metrics which demonstrates the improved performance.","Stacked sparse autoencoder,Glioma,Softmax,Hidden size,Magnetic resonance images",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Health Care Sciences & Services,Medical Informatics",,3.951,"CONVOLUTIONAL,NEURAL-NETWORKS,TISSUE,CHARACTERIZATION,MRI,SEGMENTATION,CLASSIFICATION,IMAGES,MODEL,CRF",JOURNAL OF MEDICAL SYSTEMS,,
90,Deep convolutional neural network based medical image classification for disease diagnosis,6,1,,"Yadav Samir S.,Jadhav Shivajirao M.","Yadav SS,Jadhav SM",Yadav SS,10.1186/s40537-019-0276-2,Dr. Babasaheb Ambedkar Technological University,"Medical image classification plays an essential role in clinical treatment and teaching tasks. However, the traditional method has reached its ceiling on performance. Moreover, by using them, much time and effort need to be spent on extracting and selecting classification features. The deep neural network is an emerging machine learning method that has proven its potential for different classification tasks. Notably, the convolutional neural network dominates with the best results on varying image classification tasks. However, medical image datasets are hard to collect because it needs a lot of professional expertise to label them. Therefore, this paper researches how to apply the convolutional neural network (CNN) based algorithm on a chest X-ray dataset to classify pneumonia. Three techniques are evaluated through experiments. These are linear support vector machine classifier with local rotation and orientation free features, transfer learning on two convolutional neural network models: Visual Geometry Group i.e., VGG16 and InceptionV3, and a capsule network training from scratch. Data augmentation is a data preprocessing method applied to all three methods. The results of the experiments show that data augmentation generally is an effective way for all three algorithms to improve performance. Also, Transfer learning is a more useful classification method on a small dataset compared to a support vector machine with oriented fast and rotated binary (ORB) robust independent elementary features and capsule network. In transfer learning, retraining specific features on a new target dataset is essential to improve performance. And, the second important factor is a proper network complexity that matches the scale of the dataset.","CNN,Transfer learning,Capsule network,ORB,SVM,Image classification",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Computer Science,,,,JOURNAL OF BIG DATA,https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-019-0276-2,
91,Using content-based image retrieval of dermoscopic images for interpretation and education: A pilot study,26,4,503-512,"Sadeghi Mahya,Chilana Parmit,Yap Jordan,Tschandl Philipp,Atkins M. Stella","Sadeghi M,Chilana P,Yap J,Tschandl P,Atkins MS",Atkins MS,10.1111/srt.12822,Simon Fraser University,"Background Dermoscopic content-based image retrieval (CBIR) systems provide a set of visually similar dermoscopic (magnified and illuminated) skin images with a pathology-confirmed diagnosis for a given dermoscopic query image of a skin lesion. Although recent advances in machine learning have spurred novel CBIR algorithms, we have few insights into how end users interact with CBIRs and to what extent CBIRs can be useful for education and image interpretation. Materials and Methods We developed an interactive user interface for a CBIR system with dermoscopic images as a decision support tool and investigated users' interactions and decisions with the system. We performed a pilot experiment with 14 non-medically trained users for a given set of annotated dermoscopic images. Results Our pilot showed that the number of correct classifications and users' confidence levels significantly increased with the CBIR interface compared with a non-CBIR interface, although the timing also increased significantly. The users found the CBIR interface of high educational value, engaging and easy to use. Conclusion Overall, users became more accurate, found the CBIR approach provided a useful decision aid, and had educational value for learning about skin conditions.","classification decision aids,content-based image retrieval,dermoscopy images,diagnosis accuracy,educational,user study",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Dermatology,,2.309,"PIGMENTED,SKIN-LESIONS,DIAGNOSIS,SYSTEM,MELANOMA,TOOL",SKIN RESEARCH AND TECHNOLOGY,,
92,Ros-NET: A deep convolutional neural network for automatic identification of rosacea lesions,26,3,413-421,"Binol Hamidullah,Plotner Alisha,Sopkovich Jennifer,Kaffenberger Benjamin,Niazi Muhammad Khalid Khan,Gurcan Metin N.","Binol H,Plotner A,Sopkovich J,Kaffenberger B,Niazi MKK,Gurcan MN",Binol H,10.1111/srt.12817,Wake Forest University,"Background Rosacea is one of the most common cutaneous disorder characterized primarily by facial flushing, erythema, papules, pustules, telangiectases, and nasal swelling. Diagnosis of rosacea is principally done by a physical examination and a consistent patient history. However, qualitative human assessment is often subjective and suffers from a relatively high intra- and inter-observer variability in evaluating patient outcomes. Materials and Methods To overcome these problems, we propose a quantitative and reproducible computer-aided diagnosis system, Ros-NET, which integrates information from different image scales and resolutions in order to identify rosacea lesions. This involves adaption of Inception-ResNet-v2 and ResNet-101 to extract rosacea features from facial images. Additionally, we propose to refine the detection results by means of facial-landmarks-based zones (ie, anthropometric landmarks) as regions of interest (ROI), which focus on typical areas of rosacea occurrence on a face. Results Using a leave-one-patient-out cross-validation scheme, the weighted average Dice coefficients, in percentages, across all patients (N = 41) with 256 x 256 image patches are 89.8 +/- 2.6% and 87.8 +/- 2.4% with Inception-ResNet-v2 and ResNet-101, respectively. Conclusion The findings from this study support that pre-trained networks trained via transfer learning can be beneficial in identifying rosacea lesions. Our future work will involve expanding the work to a larger database of cases with varying degrees of disease characteristics.","computer-assisted diagnosis,convolutional neural networks,deep learning,rosacea,semantic segmentation,transfer learning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Dermatology,,2.309,"PATHOPHYSIOLOGY,CLASSIFICATION",SKIN RESEARCH AND TECHNOLOGY,,
93,Guiding Mineralization Co-Culture Discovery Using Bayesian Optimization,53,24,14459-14469,"Daly Aisling J.,Stock Michiel,Baetens Jan M.,De Baets Bernard","Daly AJ,Stock M,Baetens JM,De Baets B",Stock M,10.1021/acs.est.9b05942,Ghent University,"Many disciplines rely on testing combinations of compounds, materials, proteins, or bacterial species to drive scientific discovery. It is time-consuming and expensive to determine experimentally, via trial-and-error or random selection approaches, which of the many possible combinations will lead to desirable outcomes. Hence, there is a pressing need for more rational and efficient experimental design approaches to reduce experimental effort. In this work, we demonstrate the potential of machine learning methods for the in silico selection of promising co-culture combinations in the application of bioaugmentation. We use the example of pollutant removal in drinking water treatment plants, which can be achieved using co-cultures of a specialized pollutant degrader with combinations of bacterial isolates. To reduce the experimental effort needed to discover high-performing combinations, we propose a data-driven experimental design. Based on a dataset of mineralization performance for all pairs of 13 bacterial species co-cultured with MSH1, we built a Gaussian process regression model to predict the Gompertz mineralization parameters of the co-cultures of two and three species, based on the single-strain parameters. We subsequently used this model in a Bayesian optimization scheme to suggest potentially high-performing combinations of bacteria. We achieved good performance with this approach, both for predicting mineralization parameters and for selecting effective co-cultures, despite the limited dataset. As a novel application of Bayesian optimization in bioremediation, this experimental design approach has promising applications for highlighting co-culture combinations for in vitro testing in various settings, to lessen the experimental burden and perform more targeted screenings.","2,6-DICHLOROBENZAMIDE BAM,METABOLITE 2,6-DICHLOROBENZAMIDE,HERBICIDE DICHLOBENIL,GROWTH,DEGRADATION,BIOAUGMENTATION,ECOSYSTEMS,TOOL",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Engineering,Environmental Sciences & Ecology",,9.922,"2%2C6-DICHLOROBENZAMIDE,BAM,METABOLITE,2%2C6-DICHLOROBENZAMIDE,HERBICIDE,DICHLOBENIL,GROWTH,DEGRADATION,BIOAUGMENTATION,ECOSYSTEMS,TOOL",ENVIRONMENTAL SCIENCE & TECHNOLOGY,,
94,Rapid diagnosis of infection etiology in febrile pediatric oncology patients using infrared spectroscopy of leukocytes,13,2,,"Agbaria Adam H.,Rosen Guy Beck,Lapidot Itshak,Rich Daniel H.,Mordechai Shaul,Kapelushnik Joseph,Huleihel Mahmoud,Salman Ahmad","Agbaria AH,Rosen GB,Lapidot I,Rich DH,Mordechai S,Kapelushnik J,Huleihel M,Salman A",Salman A,10.1002/jbio.201900215,Ben Gurion University,"Rapid diagnosis of the etiology of infection is highly important for an effective treatment of the infected patients. Bacterial and viral infections are serious diseases that can cause death in many cases. The human immune system deals with many viral and bacterial infections that cause no symptoms and pass quietly without treatment. However, oncology patients undergoing chemotherapy have a very weak immune system caused by leukopenia, and even minor pathogen infection threatens their lives. For this reason, physicians tend to prescribe immediately several types of antibiotics for febrile pediatric oncology patients (FPOPs). Uncontrolled use of antibiotics is one of the major contributors to the development of resistant bacteria. Therefore, for oncology patients, a rapid and objective diagnosis of the etiology of the infection is extremely critical. Current identification methods are time-consuming (>24 h). In this study, the potential of midinfrared spectroscopy in tandem with machine learning algorithms is evaluated for rapid and objective diagnosis of the etiology of infections in FPOPs using simple peripheral blood samples. Our results show that infrared spectroscopy enables the diagnosis of the etiology of infection as bacterial or viral within 70 minutes after the collection of the blood sample with 93% sensitivity and 88% specificity.","FTIR microscopy,infection etiology,leukocytes,machine learning",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Biochemistry & Molecular Biology,Biophysics,Optics",,3.403,"HLA,CLASS-I,CD8,T-CELLS,PNEUMOCOCCAL,CONJUGATE,VACCINE,INFLUENZA-A,VIRUS,COLORECTAL-CANCER,PERIPHERAL-BLOOD,SECONDARY,STRUCTURE,DOWN-REGULATION,LABEL-FREE,EXPRESSION",JOURNAL OF BIOPHOTONICS,,
95,Frustrated magnetism in the J(1)-J(2) honeycomb lattice compounds MgMnO3 and ZnMnO3 synthesized via a metathesis reaction,3,12,,"Haraguchi Yuya,Nawa Kazuhiro,Michioka Chishiro,Ueda Hiroaki,Matsuo Akira,Kindo Koichi,Avdeev Maxim,Sato Taku J.,Yoshimura Kazuyoshi","Haraguchi Y,Nawa K,Michioka C,Ueda H,Matsuo A,Kindo K,Avdeev M,Sato TJ,Yoshimura K",Haraguchi Y,10.1103/PhysRevMaterials.3.124406,Kyoto University,"We investigated the magnetic properties of the ilmenite-type manganates MgMnO3 and ZnMnO3, both of which are composed of a honeycomb lattice of magnetic Mn4+ ions. Both compounds show antiferromagnetic order with weak ferromagnetic moments. In particular, MgMnO3 exhibits a magnetization ""reversal"" behavior which can be described by the N-type ferrimagnetism in the Neel's classification. The relationship between the magnetic properties and the crystal and magnetic structures probed by the neutron diffraction experiments indicates that the two honeycomb lattice magnets have different J(1)-J(2) parameter sets, placing them in the distinct regions in the phase diagram; both nearest neighbor (NN) and next nearest neighbor (NNN) exchange interactions are antiferromagnetic in MgMnO3, while NN and NNN interactions become ferromagnetic and antiferromagnet, respectively, in ZnMnO3.","NEUTRON-DIFFRACTION,CRYSTAL,PHASE",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Materials Science,,4.034,"NEUTRON-DIFFRACTION,CRYSTAL,PHASE",PHYSICAL REVIEW MATERIALS,,
96,Deep-learning-based quality filtering of mechanically exfoliated 2D crystals,5,,,"Saito Yu,Shin Kento,Terayama Kei,Desai Shaan,Onga Masaru,Nakagawa Yuji,Itahashi Yuki M.,Iwasa Yoshihiro,Yamada Makoto,Tsuda Koji","Saito Y,Shin K,Terayama K,Desai S,Onga M,Nakagawa Y,Itahashi YM,Iwasa Y,Yamada M,Tsuda K",Saito Y; Tsuda K,10.1038/s41524-019-0262-4,RIKEN,"Two-dimensional (2D) crystals are attracting growing interest in various research fields such as engineering, physics, chemistry, pharmacy, and biology owing to their low dimensionality and dramatic change of properties compared to the bulk counter parts. Among the various techniques used to manufacture 2D crystals, mechanical exfoliation has been essential to practical applications and fundamental research. However, mechanically exfoliated crystals on substrates contain relatively thick flakes that must be found and removed manually, limiting high-throughput manufacturing of atomic 2D crystals and van der Waals heterostructures. Here, we present a deep-learning-based method to segment and identify the thickness of atomic layer flakes from optical microscopy images. Through carefully designing a neural network based on U-Net, we found that our neural network based on U-net trained only with the data based on realistically small number of images successfully distinguish monolayer and bilayer MoS2 and graphene with a success rate of 70-80%, which is a practical value in the first screening process for choosing monolayer and bilayer flakes of all flakes on substrates without human eye. The remarkable results highlight the possibility that a large fraction of manual laboratory work can be replaced by AI-based systems, boosting productivity.","OPTICAL-IDENTIFICATION,OPTOELECTRONICS,FERROMAGNETISM,ELECTRONICS,PREDICTION,MOS2",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Chemistry,Materials Science",,13.993,"OPTICAL-IDENTIFICATION,OPTOELECTRONICS,FERROMAGNETISM,ELECTRONICS,PREDICTION,MOS2",NPJ COMPUTATIONAL MATERIALS,http://arxiv.org/pdf/1907.03239,
97,Atrial fibrillation classification using deep learning algorithm in Internet of Things-based smart healthcare system,26,3,1827-1840,"Jeyaraj Pandia Rajan,Nadar Edward Rajan Samuel","Jeyaraj PR,Nadar ERS",Jeyaraj PR,10.1177/1460458219891384,Mepco Schlenk Engineering College,"Detecting the electrocardiogram pattern in Internet of Things-based healthcare system and notifying this to the user is a challenging task. Using advance computing methods for classification of electrocardiogram signal is a notable research topic. In this research work, an intelligent electrocardiogram signal classification, employing deep learning algorithm, developed and tested in Internet of Things-based smart healthcare system was proposed. For classification of acquired electrocardiogram signal, a partitioned deep convolutional neural network was proposed. The electrocardiogram feature continuously in the Internet of Things-based monitoring system was learnt. To make use of learned features in the continuous time series data, it forms a higher order space in the server. We have made quantifiable comparative analysis with other classification algorithm with the same time series data collected from different atrial fibrillation samples in the Internet of Things-based e-health system. Our proposed algorithm learned features were tested in atrial fibrillation classified signal with other conventional classifiers with various performance indices. We obtained an accuracy of 96.3 percent with 93.5-percent sensitivity and 97.5-percent precision. From the obtained result, processing with proposed deep convolutional neural network provides reliable timely assist and accurate classification of electrocardiogram signal in Internet of Things-based smart healthcare system.","deep learning algorithm,electrocardiogram signal processing,healthcare system,smart medical informatics",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA","Health Care Sciences & Services,Medical Informatics",,3.0,"CONVOLUTIONAL,NEURAL-NETWORKS,AUTOENCODER",HEALTH INFORMATICS JOURNAL,https://journals.sagepub.com/doi/pdf/10.1177/1460458219891384,
98,ECG-Based Subject Identification Using Statistical Features and Random Forest,2019,,,"Alotaiby Turky N.,Alrshoud Saud Rashid,Alshebeili Saleh A.,Aljafar Latifah M.","Alotaiby TN,Alrshoud SR,Alshebeili SA,Aljafar LM",Alotaiby TN,10.1155/2019/6751932,King Abdulaziz City for Science & Technology,"In this work, a nonfiducial electrocardiogram (ECG) identification algorithm based on statistical features and random forest classifier is presented. Two feature extraction approaches are investigated: direct and band-based approaches. In the former, eleven simple statistical features are directly extracted from a single-lead ECG signal segment. In the latter, the single-lead ECG signal is first decomposed into bands, and the statistical features are extracted from each segment of a given band and concatenated to form the feature vector. Nonoverlapping segments of different lengths (i.e., 1, 3, 5, 7, 10, or 15 sec) are examined. The extracted feature vectors are applied to a random forest classifier, for the purpose of identification. This study considers 290 reference subjects from the ECG database of the Physikalisch-Technische Bundesanstalt (PTB). The proposed identification algorithm achieved an accuracy rate of 99.61% utilizing the single limb lead (I) with the band-based approach. A single chest lead (V1), augmented limb lead (aVF), and Frank's lead (Vx) achieved an accuracy rate of 99.37%, 99.76%, and 99.76%, respectively, using the same approach.","BIOMETRIC-ANALYSIS,RECOGNITION",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Engineering,Instruments & Instrumentation",,2.398,"BIOMETRIC-ANALYSIS,RECOGNITION",JOURNAL OF SENSORS,https://doi.org/10.1155/2019/6751932,
99,Task complexity interacts with state-space uncertainty in the arbitration between model-based and model-free learning,10,,,"Kim Dongjae,Park Geon Yeong,O'Doherty John P.,Lee Sang Wan","Kim D,Park GY,O'Doherty JP,Lee SW",Lee SW,10.1038/s41467-019-13632-1,Korea Advanced Institute of Science & Technology (KAIST),"It has previously been shown that the relative reliability of model-based and model-free reinforcement-learning (RL) systems plays a role in the allocation of behavioral control between them. However, the role of task complexity in the arbitration between these two strategies remains largely unknown. Here, using a combination of novel task design, computational modelling, and model-based fMRI analysis, we examined the role of task complexity alongside state-space uncertainty in the arbitration process. Participants tended to increase model-based RL control in response to increasing task complexity. However, they resorted to model-free RL when both uncertainty and task complexity were high, suggesting that these two variables interact during the arbitration process. Computational fMRI revealed that task complexity interacts with neural representations of the reliability of the two systems in the inferior prefrontal cortex.","PREFRONTAL CORTEX,STRIATUM,INHIBITION,HABITS,CHOICE",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,15.805,"PREFRONTAL,CORTEX,STRIATUM,INHIBITION,HABITS,CHOICE",NATURE COMMUNICATIONS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6915739,
100,Search for high-capacity oxygen storage materials by materials informatics,9,71,41811-41816,"Ohba Nobuko,Yokoya Takuro,Kajita Seiji,Takechi Kensuke","Ohba N,Yokoya T,Kajita S,Takechi K",Ohba N,10.1039/c9ra09886k,Toyota Central R&D Labs Inc,"Oxygen storage materials (OSMs), such as pyrochlore type CeO2-ZrO2 (p-CZ), are used as a catalyst support for three-way catalysts in automotive emission control systems. They have oxygen storage capacity (OSC), which is the ability to release and store oxygen reversibly by the fluctuation of cation oxidation states depending on the reducing or oxidizing atmosphere. In this study, we explore high-capacity OSMs by using materials informatics (MI) combining experiments, first-principles calculations, and machine learning (ML). To generate training data for the ML model, the OSC values of 60 metal oxides were measured from the amount of CO2 produced under alternating flow gas between oxidizing (O-2) and reducing (CO) conditions at 973, 773, and 573 K. Descriptors were computed by atomic properties and first-principles calculations on each oxide. The support vector machine regression model was trained to predict the OSC at each temperature. The features describing OSC were automatically selected using grid search to achieve practical cross validation performance. The features related to the stability of the oxygen atoms in the crystal and the crystal structure itself such as cohesive energy are highly correlated with OSC. The present model predicts the OSC of 1300 existing oxides. Based on its high predictive power for OSC and synthesizability, we focused on Cu3Nb2O8. We synthesized this material and experimentally confirmed that Cu3Nb2O8 showed a higher OSC than conventional OSM p-CZ. This MI scheme can significantly accelerate the development of new OSMs.","CATALYSTS,ENERGY,SUPPORT,DESIGN",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND",Chemistry,,3.39,"CATALYSTS,ENERGY,SUPPORT,DESIGN",RSC ADVANCES,https://pubs.rsc.org/en/content/articlepdf/2019/ra/c9ra09886k,
