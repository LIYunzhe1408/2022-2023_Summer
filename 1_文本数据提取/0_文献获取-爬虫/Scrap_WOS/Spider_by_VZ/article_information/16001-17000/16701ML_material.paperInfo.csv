,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,A brave new world for archaeological survey: Automated machine learning-based potsherd detection using high-resolution drone imagery,112,,,"Orengo H. A.,Garcia-Molsosa A.","Orengo HA,Garcia-Molsosa A",Orengo HA,10.1016/j.jas.2019.105013,Universitat Rovira i Virgili,"Archaeological pedestrian survey is one of the most popular techniques available for primary detection of archaeological sites and description of past landscape use. As such it is an essential tool not just for the understanding of past human distribution, economy, demography and so on but also for cultural heritage management and protection. The most common type of pedestrian surface survey consists of fieldwalking relatively large tracts of land, recording the dispersion of items of material culture, predominantly pottery fragments, by teams of archaeologists and students. This paper presents the first proof of concept for the automated recording of material culture dispersion across large areas using high resolution drone imagery, photogrammetry and a combination of machine learning and geospatial analysis that can be run using the Google Earth Engine geospatial cloud computing platform. The results show the potential of this technique, under appropriate field circumstances, to produce accurate distribution maps of individual potsherds opening a new horizon for the application of archaeological survey. The paper also discusses current limitations and future developments of this method.","Landscape archaeology,Archaeological survey,Drone survey,Photogrammetry,Machine learning,Cloud distributed computing,Automated site detection",Article,"ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD, 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND","Anthropology,Archaeology,Geology",,3.545,"FEATURES,HERITAGE",JOURNAL OF ARCHAEOLOGICAL SCIENCE,https://doi.org/10.1016/j.jas.2019.105013,
2,Comparison between logistic regression and machine learning algorithms on survival prediction of traumatic brain injuries,54,,110-116,"Feng Jin-zhou,Wang Yu,Peng Jin,Sun Ming-wei,Zeng Jun,Jiang Hua","Feng JZ,Wang Y,Peng J,Sun MW,Zeng J,Jiang H",Jiang H,10.1016/j.jcrc.2019.08.010,Sichuan Provincial People's Hospital,"Purpose: To compare twenty-two machine learning (ML) models against logistic regression on survival prediction in severe traumatic brain injury (STBI) patients in a single center study.
Materials and methods: Data was collected from STBI patients admitted to the Sichuan Provincial People's Hospital between December 2009 and November 2011. Twenty-two machine learning (ML) models were tested, and their predictive performance compared with logistic regression (LR) model. Receiver operating characteristics (ROC), area under curve (AUC), accuracy, F-score, precision, recall and Decision Curve Analysis (DCA) were used as performance metrics.
Results: A total of 117 patients were enrolled. AUC of all ML models ranged from 86.3% to 94%. AUC of LR was 83%, and accuracy was 88%. The AUC of Cubic SVM, Quadratic SVM and Linear SVM were higher than that of LR. The precision ratio of LR was 95% and recall ratio was 91%, both were lower than most ML models. The F-Score of LR was 0.93, which was only slightly better than that of Linear Discriminant and Quadratic Discriminant.
Conclusions: The twenty-two ML models selected have capabilities comparable to classical LR model for outcome prediction in STBI patients. Of these, Cubic SVM, Quadratic SVM, Linear SVM performed significantly better than LR. (C) 2019 Elsevier Inc. All rights reserved.","Traumatic brain injury,Machine learning,Logistic regression,Survival prediction,Support vector machine,Critical illness",Article,"W B SAUNDERS CO-ELSEVIER INC, 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA",General & Internal Medicine,,,"OUTCOME,PREDICTION,PERFORMANCE,VALIDATION,MODELS",JOURNAL OF CRITICAL CARE,,
3,Rapid and nondestructive detection of freshness quality of postharvest spinaches based on machine vision and electronic nose,39,6,,"Huang Xingyi,Yu Shanshan,Xu Haixia,Aheto Joshua H.,Bonah Ernest,Ma Mei,Wu Mengzi,Zhang Xiaorui","Huang XY,Yu SS,Xu HX,Aheto JH,Bonah E,Ma M,Wu MZ,Zhang XR",Huang XY,10.1111/jfs.12708,Jiangsu University,"Artificial sensory evaluation and physicochemical analysis tend to be tedious and time consuming. Therefore, this study employs machine vision, electronic nose (E-nose), and multisensory data fusion to rapidly and nondestructively detect spinach freshness during storage. Spinach freshness during refrigeration was classified into four grades by 10 trained panelists. Machine vision and E-nose were then used to obtain the image and odor information of the samples, respectively. K-nearest neighbor (KNN), support vector machine (SVM), and back-propagation artificial neural network (BPNN) were applied to predict spinach freshness. Result from the BPNN model based on machine vision achieved the same result as the KNN model with a classification accuracy of 85.42%. The BPNN model based on E-nose achieved a better result than the SVM model with classification accuracies of 81.25% and 75.00%, respectively. Furthermore, the BPNN model based on multisensory data fusion greatly improved the detection accuracy of spinach freshness with a classification accuracy of 93.75%. Multisensory data fusion approaches based on machine vision and E-nose are capable of intelligently detecting the freshness of postharvest spinach during storage. The main advantage is to allow a rapid and nondestructive detection of spinach freshness without using any chemical pretreatments. Practical Applications Fresh spinach is an important source of minerals, vitamins, carotenes, and other nutrients. Timely and accurately knowing the grade of spinach freshness before decay is of great interest in ensuring edible quality and reducing economic losses. Traditional analytical methods of spinach freshness tend to be tedious and time consuming. Novel analytical techniques such as machine vision and electronic nose (E-nose) showed good feasibility in detecting spinach freshness during refrigerated storage. The detection accuracy could be highly improved based on the multisensory data fusion of machine vision and E-nose. The results of this study confirmed that machine vision and E-nose could constitute a rapid and nondestructive method to detect spinach freshness during storage instead of tedious and time-consuming methods. The method of combining machine vision and E-nose could be applied in the fruit and vegetable industry in the future.","SENSOR ARRAY,LEAVES,INSPECTION,STORAGE,TONGUE,SYSTEM,MEAT,LIFE",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Biotechnology & Applied Microbiology,Food Science & Technology",,1.946,"SENSOR,ARRAY,LEAVES,INSPECTION,STORAGE,TONGUE,SYSTEM,MEAT,LIFE",JOURNAL OF FOOD SAFETY,,
4,Iterative Learning-Based Admittance Control for Autonomous Excavation,96,3-4,493-500,"Fernando Heshan,Marshall Joshua A.,Larsson Johan","Fernando H,Marshall JA,Larsson J",Fernando H,10.1007/s10846-019-00994-3,Queens University - Canada,"This paper presents the development and field validation of an iterative learning-based admittance control algorithm for autonomous excavation in fragmented rock using robotic wheel loaders. An admittance control strategy is augmented with iterative learning, which automatically updates control parameters based on the error between a target bucket fill weight and the measured fill weight at the end of each excavation pass. The algorithm was validated through full-scale autonomous excavation experiments with a 14-tonne capacity load-haul-dump (LHD) machine and two different types of excavation materials: fragmented rock and gravel. In both excavation scenarios, the iterative learning algorithm is able to update the admittance control parameters for a specified target bucket fill weight, eliminating the need to manually re-tune control parameters as material characteristics change. These results have practical significance for increasing the autonomy of robotic wheel loaders used in mining and construction.","Autonomous excavation,Iterative learning,Admittance control,Mining robotics",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Robotics",,2.888,ROBOTS,JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS,https://qspace.library.queensu.ca/bitstream/1974/26315/1/FerMarLar-IRS-2018.pdf,
5,Comparative evaluation of the predictability of neural network methods on the flammability characteristics of extruded polystyrene from microscale combustion calorimetry,138,5,3055-3064,"Mensah Rhoda Afriyie,Jiang Lin,Asante-Okyere Solomon,Xu Qiang,Jin Cong","Mensah RA,Jiang L,Asante-Okyere S,Xu Q,Jin C",Jiang L; Xu Q,10.1007/s10973-019-08335-0,Nanjing University of Science & Technology,"Predictions of both combustible material flammability and heat release parameters have been long goals in fire safety research, for its complex heat, mass transfer and chemical reaction process in gas phase. In this study, neural network method is employed to predict materials flammability considering its wide application in predicting key properties of engineering problems. The use of group method of data handling (GMDH) and feed forward back-propagation (FFBP) neural networks in predicting the heat of combustion and heat release capacity (HRC) from microscale combustion calorimetry has been examined. The study presented models with excellent predictability though GMDH out-performed FFBP. The deviation of the predicted and measured HRC data from this study was compared with the results of other predictive modelling techniques used in flammability studies. The GMDH neural network results presented the least mean deviation of 4.01 signifying accurate predictions. Hence, this study proposed the use of GMDH in predicting flammability characteristics of materials.","Heat of combustion,Heat release capacity,Microscale combustion calorimetry,Group method of data handling,Feed forward back-propagation neural network",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Thermodynamics,Chemistry",,,"STRUCTURE-PROPERTY,RELATIONSHIPS,GENERALIZED,REGRESSION,PREDICTION,PERFORMANCE,POLYMERS,DESIGN,POINT,TOOL",JOURNAL OF THERMAL ANALYSIS AND CALORIMETRY,,
6,Structural and elastic properties of amorphous carbon from simulated quenching at low rates,27,8,,"Jana Richard,Savio Daniele,Deringer Volker L.,Pastewka Lars","Jana R,Savio D,Deringer VL,Pastewka L",Pastewka L,10.1088/1361-651X/ab45da,Helmholtz Association,"We generate representative structural models of amorphous carbon (a-C) from constant-volume quenching from the liquid with subsequent relaxation of internal stresses in molecular dynamics simulations using empirical and machine-learning interatomic potentials. By varying volume and quench rate we generate structures with a range of density and amorphous morphologies. We find that all a-C samples show a universal relationship between hybridization, bulk modulus and density despite having distinctly different cohesive energies. Differences in cohesive energy are traced back to slight changes in the distribution of bondangles that is likely linked to thermal stability of these structures.","amorphous carbon,elastic properties,liquid quench,molecular dynamics simulations",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Materials Science,Physics",,,"DIAMOND-LIKE,CARBON,INTERATOMIC,POTENTIALS,MECHANICAL-PROPERTIES,GROUND-STATE,ULTRA-THIN,FILMS,MODULUS,NANOINDENTATION,CONSTANTS,STRESS",MODELLING AND SIMULATION IN MATERIALS SCIENCE AND ENGINEERING,http://arxiv.org/pdf/1907.05032,
7,Fashion clothes matching scheme based on Siamese Network and AutoEncoder,25,6,593-602,"Gao Guangyu,Liu Liling,Wang Li,Zhang Yihang","Gao GY,Liu LL,Wang L,Zhang YH",Gao GY,10.1007/s00530-019-00617-9,Beijing Institute of Technology,"Owing to the rise of living standard, people attach greater importance to personal appearance, especially clothes matching. With image processing and machine learning technology, we can analyze the pattern of clothes matching for recommendation on clothes images. However, we still face great challenges. To be more specific, there exist excessive complicated factors influencing relation among clothes items, such as color or material, and we also struggle against the problem about how to extract efficient and accurate features. Thus, with the purpose of dealing with such challenges, this paper proposes an efficient clothes matching scheme with Siamese Network and AutoEncoder based on both labeled data from dataset FashionVC and unlabeled data from MicroBlog. More specifically, at first, except for clothes suiting with text from FashionVC, the gallery data also include matching clothes outfits recommended by fashionista in MicroBlog (MbFashion). Meanwhile, a semi-supervised clustering based on assembling was also proposed to generate negative samples to form a comprehensive dataset. Secondly, with consideration of matching patterns from MbFashion, we promoted the Siamese Network properly to more efficiently extract vision features on the constructed training dataset. After that, the traditional features are also extracted, while the Triple AutoEncoder and Bayesian Personalized Ranking are used to map the three kinds of features into the same latent space to learn the compatibility between tops and bottoms. Finally, we conducted a series of experiments and evaluated our results to demonstrate the usefulness and effectiveness of the whole scheme on FashionVC and MbFashion.","Clothes matching,Fashion analysis,Siamese Network,AutoEncoder",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,1.863,,MULTIMEDIA SYSTEMS,,
8,Iterative optimization of photonic crystal nanocavity designs by using deep neural networks,8,12,2243-2256,"Asano Takashi,Noda Susumu","Asano T,Noda S",Asano T,10.1515/nanoph-2019-0308,Kyoto University,"Devices based on two-dimensional photonic-crystal nanocavities, which are defined by their air hole patterns, usually require a high quality (Q) factor to achieve high performance. We demonstrate that hole patterns with very high Q factors can be efficiently found by the iteration procedure consisting of machine learning of the relation between the hole pattern and the corresponding Q factor and new dataset generation based on the regression function obtained by machine learning. First, a dataset comprising randomly generated cavity structures and their first principles Q factors is prepared. Then a deep neural network is trained using the initial dataset to obtain a regression function that approximately predicts the Q factors from the structural parameters. Several candidates for higher Q factors are chosen by searching the parameter space using the regression function. After adding these new structures and their first principles Q factors to the training dataset, the above process is repeated. As an example, a standard silicon-based L3 cavity is optimized by this method. A cavity design with a high Q factor exceeding 11 million is found within 101 iteration steps and a total of 8070 cavity structures. This theoretical Q factor is more than twice the previously reported record values of the cavity designs detected by the evolutionary algorithm and the leaky mode visualization method. It is found that structures with higher Q factors can be detected within less iteration steps by exploring not only the parameter space near the present highest-Q structure but also that distant from the present dataset.","optimization,neural network,photonic crystals,nanocavities,Q factor",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY","Science & Technology - Other Topics,Materials Science,Optics,Physics",,8.902,"INVERSE,DESIGN,MICROCAVITIES,VISUALIZATION,DEFECT",NANOPHOTONICS,http://arxiv.org/pdf/1908.03702,
9,Recent advances in high-throughput superconductivity research,32,12,,"Yuan Jie,Stanev Valentin,Gao Chen,Takeuchi Ichiro,Jin Kui","Yuan J,Stanev V,Gao C,Takeuchi I,Jin K",Yuan J,10.1088/1361-6668/ab51b1,Chinese Academy of Sciences,"Applications are being found for superconducting materials in a rapidly growing number of technological areas, and the search for novel superconductors remains a major scientific task. However, the steady increase in the complexity of candidate materials presents a big challenge to researchers. In particular, conventional experimental methods are not well suited to an efficient search for candidates in a compositional space growing exponentially with the number of elements; neither do they permit a quick extraction of reliable multidimensional phase diagrams delineating the physical parameters that control superconductivity. New research paradigms that can boost the speed and the efficiency of research into superconducting materials are urgently needed. High-throughput methods for the rapid screening and optimization of materials have aided the acceleration of research in bioinformatics and the pharmaceutical industry, yet remain rare in quantum materials research. In this paper we briefly review the history of high-throughput research and then focus on some recent applications of this paradigm in superconductivity research. We consider the role these methods can play in all stages of materials development, including high-throughput computation, synthesis, characterization, and the emerging field of machine learning for materials. The high-throughput paradigm will undoubtedly become an indispensable tool in superconductivity research in the near future.","superconductivity,high-throughput,machine learning,combinatorial film,rapid screening",Review,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,3.16,"MAGNETIC,FORCE,MICROSCOPY,PRESSURE-INDUCED,SUPERCONDUCTIVITY,COMBINATORIAL,MATERIALS,CUPRATE,SUPERCONDUCTORS,INTEGRATED,MATERIALS,ELECTRONIC-STRUCTURE,RAPID,CONSTRUCTION,FUNCTIONAL,OXIDES,PHASE-DIAGRAMS,CHIP,APPROACH",SUPERCONDUCTOR SCIENCE & TECHNOLOGY,http://arxiv.org/pdf/1912.09006,
10,Identifying Factors That Affect Patient Survival After Orthotopic Liver Transplant Using Machine-Learning Techniques,17,6,775-783,"Kazemi Azar,Kazemi Kourosh,Sami Ashkan,Sharifian Roxana","Kazemi A,Kazemi K,Sami A,Sharifian R",Sharifian R,10.6002/ect.2018.0170,"Sch Management & Med Informat Sci, Almas Bldg,Alley 29,Qasrodasht Ave, Shiraz, Iran.","Objectives: Survival after liver transplant depends on pretransplant, peritransplant, and posttransplant factors. Identifying effective factors for patient survival after transplant can help transplant centers make better decisions.
Materials and Methods: Our study included 902 adults who received livers from deceased donors from March 2011 to March 2014 at the Shiraz Organ Transplant Center (Shiraz, Iran). In a 3-step feature selection method, effective features of 6-month survival were extracted by (1) F statistics, Pearson chi-square, and likelihood ratio chi-square and by (2) 5 machine-learning techniques. To evaluate the performance of the machine-learning techniques, Cox regression was applied to the data set. Evaluations were based on the area under the receiver operating characteristic curve and sensitivity of models. (3) We also constructed a model using all factors identified in the previous step.
Results: The model predicted survival based on 26 identified effective factors. In the following order, graft failure, Aspergillus infection, acute renal failure and vascular complications after transplant, as well as graft failure diagnosis interval, previous diabetes mellitus, Model for End-Stage Liver Disease score, donor inotropic support, units of packed cell received, and previous recipient dialysis, were found to be predictive factors in patient survival. The area under the receiver operating characteristic curve and model sensitivity were 0.90 and 0.81, respectively.
Conclusions: Data mining analyses can help identify effective features of patient survival after liver transplant and build models with equal or higher performance than Cox regression. The order of influential factors identified with the machine-learning model was close to clinical experiments.","Cox regression,Data mining,Deceased-donor transplant,Feature selection",Article,"BASKENT UNIV, TASKENT CADDESI NO 77, KAT 4, BAHCELIEVLER, ANKARA, 06490, TURKEY",Transplantation,,0.973,"DIABETES-MELLITUS,MELD,SCORE,HEPATOCELLULAR-CARCINOMA,POSTTRANSPLANT,SURVIVAL,PREDICT,SURVIVAL,GRAFT,FAILURE,PRETRANSPLANT,DONOR,RISK,TRANSFUSION",EXPERIMENTAL AND CLINICAL TRANSPLANTATION,,
11,Breast Tumor Classification Using Fast Convergence Recurrent Wavelet Elman Neural Networks,50,3,2037-2052,"Boldbaatar Enkh-Amgalan,Lin Lo-Yi,Lin Chih-Min","Boldbaatar EA,Lin LY,Lin CM",Lin CM,10.1007/s11063-018-9931-4,Yuan Ze University,"This paper develops an intelligent classification system for breast tumors that uses fine needle aspirate image data. A recurrent wavelet Elman neural network is used to classify the breast tumor as either benign or malignant. The structure of the RWENN uses different wavelet functions for hidden layers so that the generalization and search space are significantly greater than those of a conventional neural network. In this paper, there is also a stable convergence analysis of the RWENN classifier and the optimal learning rates are derived to guarantee the fastest convergence for the classification system. The performance of the developed classifier is compared with the Matlab neural network pattern recognition toolbox and other literature that uses a tenfold cross validation on the Wisconsin breast cancer dataset. The simulation results show that the proposed RWENN classifier has better classification results than other existing methods.","Breast tumor classification,Fine needle aspirate,Recurrent wavelet Elman neural network,Optimal learning rate",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,,"DIAGNOSIS,SYSTEM,RULES",NEURAL PROCESSING LETTERS,,
12,Automated Detection of Vulnerable Plaque for Intravascular Optical Coherence Tomography Images,10,4,590-603,"Liu Ran,Zhang Yanzhen,Zheng Yangting,Liu Yaqiong,Zhao Yang,Yi Lin","Liu R,Zhang YZ,Zheng YT,Liu YQ,Zhao Y,Yi L",Yi L,10.1007/s13239-019-00425-2,Chongqing University,"Purpose-Vulnerable plaque detection is important to acute coronary syndrome (ACS) diagnosis. In recent years, intravascular optical coherence tomography (IVOCT) imaging has been used for vulnerable plaque detection. Current automated detection methods adopt the traditional image classification and object detection algorithms, such as the logistic regression model, SVM, and Haar-Adaboost, to detect vulnerable plaques. The detection quality of these methods is relatively low. The aim of this study is to improve the detection quality of vulnerable plaque.
Methods-We propose an automatic detection system of vulnerable plaque for IVOCT images based on deep convolutional neural network (DCNN). The system is mainly composed of four modules: pre-processing, deep convolutional neural networks (DCNNs), post-processing, and ensemble. The IVOCT images input to DCNNs are firstly pre-processed by using the methods of de-noising and data augmentation. Then multiple DCNNs are used to detect the vulnerable plaques in the IVOCT images; the vulnerable plaque regions and their corresponding labels and scores are output. Next, the output results of each network are processed by the postprocessing module. We propose three algorithms, union of intersecting regions, duplicated region processing, and small gaps removal for post-processing. Finally, the output detection results of multiple networks are combined using a proposed combining method in ensemble module.
Results-Weevaluated the proposed method in a dataset of 300 IVOCT images. Experimental results show that our system can achieve a precision rate of 88.84%, a recall rate of 95.02%, and an overlap rate of 85.09%; the detection quality score is 88.46%.
Conclusions-The proposed algorithms can detect vulnerable plaques with superior performance; our system can be used as an auxiliary diagnostic tool for vulnerable plaque detection in IVOCT images.","Intravascular optical coherence tomography (IVOCT),Acute coronary syndrome (ACS),Vulnerable plaque,Convolutional neural network,Plaque detection",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Cardiovascular System & Cardiology,Engineering",,2.271,ULTRASOUND,CARDIOVASCULAR ENGINEERING AND TECHNOLOGY,,
13,Analysis of brain functional connectivity network in MS patients constructed by modular structure of sparse weights from cognitive task-related fMRI,42,4,921-938,"Ashtiani Seyedeh Naghmeh Miri,Behnam Hamid,Daliri Mohammad Reza,Hossein-Zadeh Gholam-Ali,Mehrpour Masoud","Ashtiani SNM,Behnam H,Daliri MR,Hossein-Zadeh GA,Mehrpour M",Daliri MR,10.1007/s13246-019-00790-1,Iran University Science & Technology,"Cognitive dysfunction in multiple sclerosis (MS) seems to be the result of neural disconnections, leading to a wide range of brain functional network alterations. It is assumed that the analysis of the topological structure of brain connectivity network can be used to assess cognitive impairments in MS disease. We aimed to identify these brain connectivity pattern alterations and detect the significant features for the distinction of MS patients from healthy controls (HC). In this regard, the importance of functional brain networks construction for better exhibition of changes, inducing the improved reflection of functional organization structure should be precisely considered. In this paper, we strove to introduce a framework for modeling the functional connectivity network by considering the two most important intrinsic sparse and modular structures of brain. For the proposed approach, we first derived group-wise sparse representation via learning a common over-complete dictionary matrix from the aggregated cognitive task-based functional magnetic resonance imaging (fMRI) data of all subjects of the two groups to be able to investigate between-group differences. We then applied the modularity concept on achieved sparse coefficients to compute the connectivity strength between the two brain regions. We examined the changes in network topological properties between relapsing-remitting MS (RRMS) and matched HC groups by considering the pairwise connections of regions of the resulted weighted networks and extracting graph-based measures. We found that the informative brain regions were related to their important connectivity weights, which could distinguish MS patients from the healthy controls. The experimental findings also proved the discrimination ability of the modularity measure among all the global features. In addition, we identified such local feature subsets as eigenvector centrality, eccentricity, node strength, and within-module degree, which significantly differed between the two groups. Moreover, these nodal graph measures have been served as the detectors of brain regions, affected by different cognitive deficits. In general, our findings illustrated that integration of sparse representation, modular structure, and pairwise connectivity strength in combination with the graph properties could help us with the early diagnosis of cognitive alterations in the case of MS.","Cognitive dysfunction,Multiple sclerosis (MS) disease,Cognitive task-based fMRI,Sparse representation,Modular structure,Discriminative network properties",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Engineering,,,"RESTING-STATE,FMRI,INDEPENDENT,COMPONENT,ANALYSIS,MULTIPLE-SCLEROSIS,ALZHEIMERS-DISEASE,DEFAULT-MODE,CORTICAL,REORGANIZATION,COMMUNITY,STRUCTURE,SPATIAL,MEMORY,HIPPOCAMPUS,IMPAIRMENT",AUSTRALASIAN PHYSICAL & ENGINEERING SCIENCES IN MEDICINE,,
14,"In obstructive sleep apnea patients, automatic determination of respiratory arrests by photoplethysmography signal and heart rate variability",42,4,959-979,"Bozkurt Mehmet Recep,Ucar Muhammed Kursad,Bozkurt Ferda,Bilgin Cahit","Bozkurt MR,Ucar MK,Bozkurt F,Bilgin C",Ucar MK,10.1007/s13246-019-00796-9,Sakarya University,"Obstructive sleep apnea is a disease that occurs in connection to pauses in respiration during sleep. Detection of the disease is achieved using a polysomnography device, which is the gold standard in diagnosis. Diagnosis is made by the steps of sleep staging and respiration scoring. Respiration scoring is performed with at least four signals. Technical knowledge is required for attaching the electrodes. Additionally, the electrodes are disturbing to an extent that will delay the patient's sleep. It is needed to have systems as alternatives for polysomnography devices that will bring a solution to these issues. This study proposes a new approach for the process of respiration scoring which is one of the diagnostic steps for the disease. A machine-learning-based apnea detection algorithm was developed for the process of respiration scoring. The study used Photoplethysmography (PPG) signal and Heart Rate Variability (HRV) that is derived from this signal. The PPG records obtained from the patient and control groups were cleaned out using a digital filter. Then, the HRV parameter was derived from the PPG signal. Later, 46 features were derived from the PPG signal and 40 features were derived from the HRV. The derived features were classified with reduced machine-learning techniques using the F-score feature-selection algorithm. The evaluation was made in a multifaceted manner. Besides, Principal Component Analysis was performed to reduce system input (features). According to the results, if a real-time embedded system is designed, the system can operate with 16 PPG feature 95%, four PPG feature 93.81% accuracy rate. These success rates are highly sufficient for the system to work. Considering all these values, it is possible to realize a practical respiration scoring system. With this study, it was agreed upon that PPG signal may be used in the diagnosis of this disease by processing it with machine learning and signal processing techniques.","Biomedical signal processing,Respiratory arrests,Photoplethysmography,Obstructive sleep apnea,Automatic respiratory staging,Apnea detection,Heart rate variability,Ensemble classification",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Engineering,,1.467,"ECG,PPG,ALGORITHM,SYSTEM",AUSTRALASIAN PHYSICAL & ENGINEERING SCIENCES IN MEDICINE,,
15,Automatic detection of arrhythmia from imbalanced ECG database using CNN model with SMOTE,42,4,1129-1139,"Pandey Saroj Kumar,Janghel Rekh Ram","Pandey SK,Janghel RR",Pandey SK,10.1007/s13246-019-00815-9,"Natl Inst Informat Technol, Dept Informat Technol, Raipur, Madhya Pradesh, India.","Timely prediction of cardiovascular diseases with the help of a computer-aided diagnosis system minimizes the mortality rate of cardiac disease patients. Cardiac arrhythmia detection is one of the most challenging tasks, because the variations of electrocardiogram(ECG) signal are very small, which cannot be detected by human eyes. In this study, an 11-layer deep convolutional neural network model is proposed for classification of the MIT-BIH arrhythmia database into five classes according to the ANSI-AAMI standards. In this CNN model, we designed a complete end-to-end structure of the classification method and applied without the denoising process of the database. The major advantage of the new methodology proposed is that the number of classifications will reduce and also the need to detect, and segment the QRS complexes, obviated. This MIT-BIH database has been artificially oversampled to handle the minority classes, class imbalance problem using SMOTE technique. This new CNN model was trained on the augmented ECG database and tested on the real dataset. The experimental results portray that the developed CNN model has better performance in terms of precision, recall, F-score, and overall accuracy as compared to the work mentioned in the literatures. These results also indicate that the best performance accuracy of 98.30% is obtained in the 70:30 train-test data set.","Arrhythmia,Convolutional Neural Network,Electrocardiogram,Imbalance,Heartbeat",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Engineering,,1.467,"CONVOLUTIONAL,NEURAL-NETWORK,HEARTBEAT,CLASSIFICATION,DYNAMIC,FEATURES,RECOGNITION,SELECTION",AUSTRALASIAN PHYSICAL & ENGINEERING SCIENCES IN MEDICINE,,
16,Predicting the onset of type 2 diabetes using wide and deep learning with electronic health records,182,,,"Nguyen Binh P.,Pham Hung N.,Tran Hop,Nghiem Nhung,Nguyen Quang H.,Do Trang T. T.,Cao Truong Tran,Simpson Colin R.","Nguyen BP,Pham HN,Tran H,Nghiem N,Nguyen QH,Do TTT,Tran CT,Simpson CR",Nguyen BP,10.1016/j.cmpb.2019.105055,Victoria University Wellington,"Objective: Diabetes is responsible for considerable morbidity, healthcare utilisation and mortality in both developed and developing countries. Currently, methods of treating diabetes are inadequate and costly so prevention becomes an important step in reducing the burden of diabetes and its complications. Electronic health records (EHRs) for each individual or a population have become important tools in understanding developing trends of diseases. Using EHRs to predict the onset of diabetes could improve the quality and efficiency of medical care. In this paper, we apply a wide and deep learning model that combines the strength of a generalised linear model with various features and a deep feed-forward neural network to improve the prediction of the onset of type 2 diabetes mellitus (T2DM).
Materials and methods: The proposed method was implemented by training various models into a logistic loss function using a stochastic gradient descent. We applied this model using public hospital record data provided by the Practice Fusion EHRs for the United States population. The dataset consists of de-identified electronic health records for 9948 patients, of which 1904 have been diagnosed with T2DM. Prediction of diabetes in 2012 was based on data obtained from previous years (2009-2011). The imbalance class of the model was handled by Synthetic Minority Oversampling Technique (SMOTE) for each cross-validation training fold to analyse the performance when synthetic examples for the minority class are created. We used SMOTE of 150 and 30 0 percent, in which 300 percent means that three new synthetic instances are created for each minority class instance. This results in the approximated diabetes:non-diabetes distributions in the training set of 1:2 and 1:1, respectively.
Results: Our final ensemble model not using SMOTE obtained an accuracy of 84.28%, area under the receiver operating characteristic curve (AUC) of 84.13%, sensitivity of 31.17% and specificity of 96.85%. Using SMOTE of 150 and 300 percent did not improve AUC (83.33% and 82.12%, respectively) but increased sensitivity (49.40% and 71.57%, respectively) with a moderate decrease in specificity (90.16% and 76.59%, respectively).
Discussion and conclusions: Our algorithm has further optimised the prediction of diabetes onset using a novel state-of-the-art machine learning algorithm: the wide and deep learning neural network architecture. (C) 2019 Elsevier B.V. All rights reserved.","Electronic health records,Incidence,Onset,Prediction,Type 2 diabetes mellitus,Wide and deep learning",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"POPULATION,MODELS",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
17,Online identification of functional regions in deep brain stimulation based on an unsupervised random forest with feature selection,16,6,,"Cao Lei,Li Jie,Zhou Yuanyuan,Liu Yunhui,Zhao Yiwen,Liu Hao","Cao L,Li J,Zhou YY,Liu YH,Zhao YW,Liu H",Liu H,10.1088/1741-2552/ab2eb4,Chinese Academy of Sciences,"Objective. The identification of functional regions, in particular the subthalamic nucleus, through microelectrode recording (MER) is the key step in deep brain stimulation (DBS). To eliminate variability in a neurosurgeon?s judgment, this study presents an online identification method for identifying functional regions along the electrode trajectory. Approach. Functional regions can be identified through offline clustering and online identification based on the unsupervised random forest (RF) algorithm. We took 106 features from MER and the estimated anatomical distance to target as the dataset to train the RF model. To improve the prediction performance and reduce the computation time, a wrapper feature selection (FS) method was added into the algorithm. The method contains feature ranking based on out-of-bag error or silhouette index and feature subset search based on the roulette selection algorithm. Main results. To evaluate the optimization effect of the FS method on the unsupervised RF algorithm, we compared the results of the algorithm with or without FS on the DBS dataset. In addition, the optimization effect of FS on the computation time is evaluated. The results show that for offline clustering, the accuracy obtained with the selected features is higher than that obtained with all features, and the running time decreased from 259.7?s to 60.8?s in the iteration of the FS. The accuracy in online identification improved from 76.19% to 92.08% through FS. In addition, the functional region online identification time is 41.5?ms, which can meet the requirements of DBS surgery. Significance. In conclusion, using the FS method can improve the accuracy and reduce the computation time of the online identification of functional regions. In addition, the online identification method can provide valuable assistance for both neurosurgeons and stereotactic surgery robots in guiding implantation of the electrode in real time.","deep brain stimulation,microelectrode recording,unsupervised random forest,feature selection,functional region online identification",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"HUMAN,SUBTHALAMIC,NUCLEUS,CLASSIFICATION",JOURNAL OF NEURAL ENGINEERING,,
18,Chronic Obstructive Pulmonary Disease: Thoracic CT Texture Analysis and Machine Learnins to Predict Pulmonary Ventilation,293,3,676-684,"Westcott Andrew,Capaldi Dante P. I.,McCormack David G.,Ward Aaron D.,Fenster Aaron,Parraga Grace","Westcott A,Capaldi DPI,McCormack DG,Ward AD,Fenster A,Parraga G",Parraga G,10.1148/radiol.2019190450,Western University (University of Western Ontario),"Background: Fixed airflow limitation and ventilation heterogeneity are common in chronic obstructive pulmonary disease (COPD). Conventional noncontrast CT provides airway and parenchymal measurements but cannot be used to directly determine lung function.
Purpose: To develop, train, and test a CT texture analysis and machine-learning algorithm to predict lung ventilation heterogeneity in participants with COPD.
Materials and Methods: In this prospective study (ClinicalTrials.gov: NCT02723474; conducted from January 2010 to February 2017), participants were randomized to optimization (n = 1), training (n = 67), and testing (n = 27) data sets. Hyperpolarized (HP) heliumm 3 (He-3) MRI ventilation maps were co-registered with thoracic CT to provide ground truth labels, and 87 quantitative imaging features were extracted and normalized to lung averages to generate 174 features. The volume-of-interest dimension and the training data sampling method were optimized to maximize the area under the receiver operating characteristic curve (AUC). Forward feature selection was performed to reduce the number of features; logistic regression, linear support vector machine, and quadratic support vector machine classifiers were trained through fivefold cross validation. The highest-performing classification model was applied to the test data set. Pearson coefficients were used to determine the relationships between the model, MRI, and pulmonary function measurements.
Results: The quadratic support vector machine performed best in training and was applied to the test data set. Model-predicted ventilation maps had an accuracy of 88% (95% confidence interval [CI]: 88%, 88%) and an AUC of 0.82 (95% CI: 0.82, 0.83) when the HP He-3 MRI ventilation maps were used as the reference standard. Model predicted ventilation defect percentage (VDP) was correlated with VDP at (HPHe)-He-3 MRI (r = 0.90, P < .001). Both model-predicted and HP He-3 MRI VDP were correlated with forced expiratory volume in 1 second (FEV1) (model: r = -0.65, P < .001; MRI: r = -0.70, P < .001), ratio of FEV1 to forced vital capacity (model: r = -0.73, P < .001; MRI: r = -0.75, P < .001), diffusing capacity ( model: r = - 0.69, P < .001; MRI: r = -0.65, P < .001), and quality-of-life score (model: r = 0.59, P = .001; MRI: r = 0.65, P < .001).
Conclusion: Model-predicted ventilation maps generated by using CT textures and machine learning were correlated with MRI ventilation maps (r = 0.90, P < .001). (C) RSNA, 2019","HYPERPOLARIZED HE-3,COMPUTED-TOMOGRAPHY,COPD,EMPHYSEMA,QUANTIFICATION,DEFECTS,MRI,DIAGNOSIS,FEATURES",Article,"RADIOLOGICAL SOC NORTH AMERICA, 820 JORIE BLVD, OAK BROOK, IL 60523 USA","Radiology, Nuclear Medicine & Medical Imaging",,10.389,"HYPERPOLARIZED,HE-3,COMPUTED-TOMOGRAPHY,COPD,EMPHYSEMA,QUANTIFICATION,DEFECTS,MRI,DIAGNOSIS,FEATURES",RADIOLOGY,https://ir.lib.uwo.ca/cgi/viewcontent.cgi?article=1138&context=biophysicspub,
19,Investigation of feed-forward back propagation ANN using voltage signals for the early prediction of the welding defect,1,12,,"Thekkuden Dinu Thomas,Mourad Abdel-Hamid Ismail","Thekkuden DT,Mourad AHI",Mourad AHI,10.1007/s42452-019-1660-4,United Arab Emirates University,"The research paper investigates the prediction capability of the artificial neural network for weld quality assessment from the captured voltage signals in a gas metal arc welding process. The bead-on-plate welds and v-groove welds were made on SA 516 grade 70 material by altering different parameters such as stickout distance, gas flow rate and travel speed. The voltage signals of each weld were captured using a data acquisition system having 8000 Hz data acquisition rate. The descriptive statistics of the voltage data such as mean, standard error, median, mode, standard deviation, sample variance, kurtosis, skewness, minimum and maximum corresponding to bead-on-plate welds and v-groove welds were used for training and testing the neural network respectively. The quality of the weld was assessed by the visual inspection, and from control charts plotted using voltage data. Overall classification accuracy of 94.7% was achieved in the training process. The feed-forward back propagation neural network predicted the quality of test v-groove welds accurately with a 90.9% prediction rate. The results proved that the developed method is promising for the immediate and early prediction of the weld quality.","Weld quality,Artificial neural network,Fast-forward back propagation,Welding voltage",Article,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Science & Technology - Other Topics,,,"STABLE,CRACK-GROWTH,DYNAMIC,RESISTANCE,INSPECTION,SYSTEM,ARC,VOLTAGE,MODE-I,QUALITY,CLASSIFICATION,STEEL,SIGNATURES,GEOMETRY",SN APPLIED SCIENCES,,
20,Machine-learning-based hand motion recognition system by measuring forearm deformation with a distance sensor array,3,4,418-429,"Cho Sung-Gwi,Yoshikawa Masahiro,Ding Ming,Takamatsu Jun,Ogasawara Tsukasa","Cho SG,Yoshikawa M,Ding M,Takamatsu J,Ogasawara T",Cho SG,10.1007/s41315-019-00115-1,Nara Institute of Science & Technology,"Studies on hand motion recognition based on biosignals have become popular as such recognition can be applied to various input interfaces and motion measurements for human-robot/computer interaction. In recent years, many machine-learning-based technologies have been developed to analyze such biosignals more accurately. Among various possible biosignals, we focus on forearm deformation which is an alternative source of information for hand motion recognition. The activities of surface and deep layer muscles, tendons, and bones can be extracted from forearm deformation in a non-invasive manner. In this study, a hand motion recognition system is proposed based on forearm deformation. By using machine-learning-based technology, the proposed method can be applied to various users and various measurement conditions. First, a distance sensor array is developed to measure forearm deformation. Then, we test and verify the suitableness of three types of machine-learning-based classifiers (k-NN, SVM, and DNN) using the measured forearm deformation. In experiments, we verified the accuracy of the proposed system with various users. We also test the system for different elbow postures, and when measuring the data over the clothing.","Forearm deformation,Distance sensor array,Machine learning,Hand,Motion recognition",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA",Robotics,,,"UPPER-LIMB,SEMG",INTERNATIONAL JOURNAL OF INTELLIGENT ROBOTICS AND APPLICATIONS,,
21,Modelling Stand Variables of Beech Coppice Forest Using Spectral Sentinel-2A Data and the Machine Learning Approach,10,2,137-144,"Cabaravdic Azra,Balic Besim","Cabaravdic A,Balic B",Cabaravdic A,10.15177/seefor.19-21,University of Sarajevo,"Background and Purpose: Coppice forests have a particular socio-economic and ecological role in forestry and environmental management. Their production sustainability and spatial stability become imperative for forestry sector as well as for local and global communities. Recently, integrated forest inventory and remotely sensed data analysed with non-parametrical statistical methods have enabled more detailed insight into forest structural characteristics. The aim of this research was to estimate forest attributes of beech coppice forest stands in the Sarajevo Canton through the integration of inventory and Sentinel S2A satellite data using machine learning methods.
Materials and Methods: Basal area, mean stand diameter, growing stock and total volume data were determined from the forest inventory designed for represented stands of coppice forests. Spectral data were collected from bands of Sentinel S2A satellite image, vegetation indices (difference, normalized difference and ratio vegetation index) and biophysical variables (fraction of absorbed photosynthetically active radiation, leaf area index, fraction of vegetation cover, chlorophyll content in the leaf and canopy water content). Machine learning rule-based M5 model tree (M5P) and random forest (RF) methods were used for forest attribute estimation. Predictor subset selection was based on wrapping assuming M5P and RF learning schemes. Models were developed on training data subsets (402 sample plots) and evaluations were performed on validation data subsets (207 sample plots). Performance of the models was evaluated by the percentage of the root mean squared error over the mean value (rRMSE) and the square of the correlation coefficient between the observed and estimated stand variables.
Results and Conclusions: Predictor subset selection resulted in a varied number of predictors for forest attributes and methods with their larger contribution in RI (between 8 and 11). Spectral biophysical variables dominated in subsets. The RI resulted in smaller errors for training sets for all attributes than M5P, while both methods delivered very high errors for validation sets (rRMSE above 50%). The lowest rRMSE of 50% was obtained for stand basal area. The observed variability explained by the M5P and RF models in training subsets was about 30% and 95% respectively, but those values were lower in test subsets (below 12%) but still significant. Differences of the sample and modelled forest attribute means were not significant, while modelled variability for all forest attributes was significantly lower (p<0.01). It seems that additional information is needed to increase prediction accuracy, so stand information (management classes, site class, soil type, canopy closure and others), new sampling strategy and new spectral products could be integrated and examined in further more complex modelling of forest attributes.","Coppice Forest,Inventory Data,Spectral Biophysical Variables,M5 Model Tree,Random Forest Regression",Article,"CROATIAN FOREST RESEARCH INST, CVJETNO NASELJE 41, JASTREBARSKO, 10450, CROATIA",Forestry,,,"VEGETATION,INVENTORY",SEEFOR-SOUTH-EAST EUROPEAN FORESTRY,https://hrcak.srce.hr/file/336652,
22,Prediction of Immunohistochemistry of Suspected Thyroid Nodules by Use of Machine Learning-Based Radiomics,213,6,1348-1357,"Gu Jiabing,Zhu Jian,Qiu Qingtao,Wang Yungang,Bai Tong,Yin Yong","Gu JB,Zhu J,Qiu QT,Wang YG,Bai T,Yin Y",Yin Y,10.2214/AJR.19.21626,Shandong First Medical University & Shandong Academy of Medical Sciences,"OBJECTIVE. The purpose of this study was to develop and validate a radiomics model for evaluating immunohistochemical characteristics in patients with suspected thyroid nodules.
MATERIALS AND METHODS. A total of 103 patients (training cohort-to-validation cohort ratio, approximate to 3:1) with suspected thyroid nodules who had undergone thyroidectomy and immunohistochemical analysis were enrolled. The immunohistochemical markers were cytokeratin 19, galectin 3, thyroperoxidase, and high-molecular-weight cytokeratin. All patients underwent CT before surgery, and a 3D slicer was used to analyze images of the surgical specimen. Test-retest and Spearman correlation coefficient (rho) were used to select reproducible and nonredundant features. The Kruskal-Wallis test (p < 0.05) was used for feature selection, and a feature-based model was built by support vector machine methods. The performance of the radiomic models was assessed with respect to accuracy, sensitivity, specificity, corresponding AUC, and independent validation.
RESULTS. Eighty-six reproducible and nonredundant features selected from the 828 features were used to build the model. The best performance of the cytokeratin 19 model yielded accuracy of 84.4% in the training cohort and 80.0% in the validation cohort. The thyroperoxidase and galectin 3 predictive models yielded accuracies of 81.4% and 82.5% in the training cohort and 84.2% and 85.0% in the validation cohort. The performance of the high-molecularweight cytokeratin predictive model was not good (accuracy, 657%) and could not be validated.
CONCLUSION. A radiomics model with excellent performance was developed for individualized noninvasive prediction of the presence of cytokeratin 19, galectin 3, and thyroperoxidase based on CT images. This model may be used to identify benign and malignant thyroid nodules.","CT,immunohistochemistry,machine learning,radiomics,thyroid nodules",Article,"AMER ROENTGEN RAY SOC, 1891 PRESTON WHITE DR, SUBSCRIPTION FULFILLMENT, RESTON, VA 22091 USA","Radiology, Nuclear Medicine & Medical Imaging",,4.073,"COMPUTED-TOMOGRAPHY,TEXTURE,FEATURES,CANCER,CT,REPRODUCIBILITY,ULTRASOUND,GALECTIN-3,MANAGEMENT,DIAGNOSIS,SURVIVAL",AMERICAN JOURNAL OF ROENTGENOLOGY,,
23,Abdominal artery segmentation method from CT volumes using fully convolutional neural network,14,12,2069-2081,"Oda Masahiro,Roth Holger R.,Kitasaka Takayuki,Misawa Kazunari,Fujiwara Michitaka,Mori Kensaku","Oda M,Roth HR,Kitasaka T,Misawa K,Fujiwara M,Mori K",Oda M,10.1007/s11548-019-02062-5,Nagoya University,"Purpose The purpose of this paper is to present a fully automated abdominal artery segmentation method from a CT volume. Three-dimensional (3D) blood vessel structure information is important for diagnosis and treatment. Information about blood vessels (including arteries) can be used in patient-specific surgical planning and intra-operative navigation. Since blood vessels have large inter-patient variations in branching patterns and positions, a patient-specific blood vessel segmentation method is necessary. Even though deep learning-based segmentation methods provide good segmentation accuracy among large organs, small organs such as blood vessels are not well segmented. We propose a deep learning-based abdominal artery segmentation method from a CT volume. Because the artery is one of small organs that is difficult to segment, we introduced an original training sample generation method and a three-plane segmentation approach to improve segmentation accuracy. Method Our proposed method segments abdominal arteries from an abdominal CT volume with a fully convolutional network (FCN). To segment small arteries, we employ a 2D patch-based segmentation method and an area imbalance reduced training patch generation (AIRTPG) method. AIRTPG adjusts patch number imbalances between patches with artery regions and patches without them. These methods improved the segmentation accuracies of small artery regions. Furthermore, we introduced a three-plane segmentation approach to obtain clear 3D segmentation results from 2D patch-based processes. In the three-plane approach, we performed three segmentation processes using patches generated on axial, coronal, and sagittal planes and combined the results to generate a 3D segmentation result. Results The evaluation results of the proposed method using 20 cases of abdominal CT volumes show that the averaged F-measure, precision, and recall rates were 87.1%, 85.8%, and 88.4%, respectively. This result outperformed our previous automated FCN-based segmentation method. Our method offers competitive performance compared to the previous blood vessel segmentation methods from 3D volumes. Conclusions We developed an abdominal artery segmentation method using FCN. The 2D patch-based and AIRTPG methods effectively segmented the artery regions. In addition, the three-plane approach generated good 3D segmentation results.","Abdominal artery,CT image,Segmentation,Fully convolutional network",Article; Proceedings Paper,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,"VESSELS,IMAGES",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
24,Prediction of optical specifications through ANN model to design a monochromatic optical filter for all three optical windows,198,,,"Swain K. P.,Nayyar Anand,Palai G.","Swain KP,Nayyar A,Palai G",Palai G,10.1016/j.ijleo.2019.163314,Gandhi Institute For Technological Advancement,"Plane wave expansion method is extensively implemented in the literature [1-5] to design monochromatic photonic filters based on silicon grating structure like Silicon (Si) and Silicon Monoxide (SiO) where the thickness of these materials is the significant factor for the selection of the particular admissible wavelength of the optical signal. The thicknesses of these materials are selected by speculation manner while designing which leads to time intense affairs as PWE simulation itself takes time to accomplish. To evade this time-consuming process, a machine learning technique using ANN algorithm is proposed in this work to establish a model for the selection of thickness of Si and SiO to realize the fillers. The ANN model is developed on Google Colab using TensorFlow framework which is provided by Google generously to implement the machine learning algorithm. Here, three ANN models are proposed for the three optical windows (800-900 nm, 1300-1400 nm, 1500-1600 nm) from where the optical specifications (thickness of materials) can be found out for any of the allowable wavelengths of the optical signal within the range for designing the filter. The ANN model is established by collecting the data arbitrarily by PWE simulation method earlier to train the model and finally the model data are validated again by PWE simulation method to check the accuracy of the model.","PWE simulation,Machine learning,ANN model,Google Colab,TensorFlow",Article,"ELSEVIER GMBH, HACKERBRUCKE 6, 80335 MUNICH, GERMANY",Optics,,1.955,"PHOTONIC,STRUCTURE,REALIZATION",OPTIK,,
25,Developing ultrasonic soft sensors to measure rheological properties of non-Newtonian drilling fluids,86,12,744-757,"Jondahl Morten Hansen,Viumdal Hakon","Jondahl MH,Viumdal H",Jondahl MH,10.1515/teme-2019-0039,"Univ South Eastern Norway, Porsgrunn, Norway.","Surveillance of the rheological properties of drilling fluids is crucial when drilling oil wells. The prevailing standard is lab analysis. The need for automated real-time measurements is, however, clear.
Ultrasonic measurements in non-Newtonian fluids have been shown to exhibit a non-linear relationship between the acoustic attenuation and rheological properties of the fluids. In this paper, three different fluid systems are examined. They are diluted to give a total of 33 fluid sets and their ultrasonic and rheological properties are measured. Machine learning models are applied to develop soft sensors that are capable of estimating the rheological properties based on the ultrasonic measurements. This study explores three different machine learning model types and, extensive training and tuning of the models is carried out. The best model types that show good results and the potential to develop a real-time sensor system suitable for use in oil & gas drilling process automation are selected.","Ultrasonic measurement,non-Newtonian fluids,rheology,machine learning,artificialneural network,drilling",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY",Instruments & Instrumentation,,0.416,"VELOCITY,SLURRY,LIQUID",TM-TECHNISCHES MESSEN,,
26,Neural Network Modelling to Characterize Steel Continuous Casting Process Parameters and Prediction of Casting Defects,72,12,3015-3025,"Hore Sheuli,Das Suchandan K.,Humane Manoj M.,Peethala Anil Kumar","Hore S,Das SK,Humane MM,Peethala AK",Hore S,10.1007/s12666-019-01767-0,Council of Scientific & Industrial Research (CSIR) - India,"The current work outlines application of a data-driven multilayer perceptron-based artificial neural network (ANN) model to characterize the influence of melt compositions, tundish temperature, tundish superheat, casting speed and mould oscillation frequency on the important processing parameters such as mould powder consumption rate, oscillation mark depth and metallurgical length during continuous casting process. A two-layer feedforward back-propagation neural network model has been developed for predicting the probability of occurrence of defect in the cast product. The network training architecture has been optimized using a gradient-based algorithm, namely the back-propagation algorithm. The neural network predictions are found to be in good agreement with regard to oscillation mark depth, mould powder consumption rate, metallurgical length and probability of occurrence of defect using data obtained from an operating Indian steel plant (Rashtriya Ispat Nigam Limited, Visakhapatnam). The ANN model prediction has been validated successfully with multiple linear regression analysis carried out on each data set.","Artificial neural network,Continuous casting,Casting defects,Metallurgical length,Mould oscillation parameters,Oscillation mark depth",Article,"SPRINGER INDIA, 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001, INDIA",Metallurgy & Metallurgical Engineering,,1.349,"HEAT-TRANSFER,MECHANISM,CRACKING,TUNDISH,FLOW",TRANSACTIONS OF THE INDIAN INSTITUTE OF METALS,,
27,Toward Interpretable Machine Learning Models for Materials Discovery,1,8,,"Mikulskis Paulius,Alexander Morgan R.,Winkler David Alan","Mikulskis P,Alexander MR,Winkler DA",Winkler DA,10.1002/aisy.201900045,University of Nottingham,"Machine learning (ML) and artificial intelligence (AI) methods for modeling useful materials properties are now important technologies for rational design and optimization of bespoke functional materials. Although these methods make good predictions of the properties of new materials, current modeling methods use efficient but rather arcane (difficult-to-interpret) mathematical features (descriptors) to characterize materials. Data-driven ML models are considerably more useful if more chemically interpretable descriptors are used to train them, as long as these models also accurately recapitulate the properties of materials in training and test sets used to generate and validate the models. Herein, how a particular type of molecular fragment descriptor, the signature descriptor, achieves these joint aims of accuracy and interpretability is described. Seven different types of materials properties are modeled, and the performance of models generated from signature descriptors is compared with those generated by widely used Dragon descriptors. The key descriptors in the model represent functionalities that make chemical sense. Mapping these fragments back on to exemplar materials provides a useful guide to chemists wishing to modify promising lead materials to improve their properties. This is one of the first applications of signature descriptors to the modeling of complex materials properties.","interpretability,machine learning,materials designs,molecular descriptors,structure-property relationships",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Automation & Control Systems,Computer Science,Robotics",,,,ADVANCED INTELLIGENT SYSTEMS,https://nottingham-repository.worktribe.com/2979270/1/Mikulskis_et_al-2019-Advanced_Intelligent_Systems,
28,Tactile Sensors for Advanced Intelligent Systems,1,8,,"Wang Chunfeng,Dong Lin,Peng Dengfeng,Pan Caofeng","Wang CF,Dong L,Peng DF,Pan CF",Peng DF; Pan CF,10.1002/aisy.201900090,Shenzhen University,"With the capability of completing a task or achieving a goal in an uncertain environment while simultaneously having the characteristics of adaptability, self-optimization, self-diagnostics, and self-maintenance, intelligent systems have witnessed extraordinary progress in recent years. These advances involve robotics, artificial intelligence and machine learning, automation, human-machine interfaces, the Internet of Things, control theory and control systems, smart and responsive materials, intelligent sensing systems, and programmed self-assembly. As an active technology conveying mechanical stimuli to a wide range of electrical and optical signals, tactile sensors are essential elements of intelligent systems and have accelerated the emergence of advanced intelligent systems by enabling the accurate recognition and safe interaction of humans and machines, smart sensing of control systems, precise control of robotics, and synergetic work of artificial intelligent systems. Herein, the recent advances of tactile sensors for advanced intelligent systems are reviewed, emphasizing these with the working principles of piezoresistance, resistance, capacitance, piezoelectricity, triboelectricity, and optics. Representative examples of their applications in advanced intelligent systems, such as robotics, human-machine interfaces, and artificial intelligence, are explored. The remaining challenges and perspectives in this emerging field are also discussed.","human-machine interfaces,intelligent systems,robotics,soft electronics,tactile sensors",Review,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Automation & Control Systems,Computer Science,Robotics",,,,ADVANCED INTELLIGENT SYSTEMS,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/aisy.201900090,
29,Deep learning-based brace damage detection for concentrically braced frame structures under seismic loadings,22,16,3473-3486,"Liu Heng,Zhang Yunfeng","Liu H,Zhang YF",Zhang YF,10.1177/1369433219859389,University System of Maryland,"Automated and robust damage detection tool is needed to enhance the resilience of civil infrastructures. In this article, a deep learning-based damage detection procedure using acceleration data is proposed as an automated post-hazard inspection tool for rapid structural condition assessment. The procedure is investigated with a focus on application in concentrically braced frame structure, a commonly used seismic force-resisting structural system with bracing as fuse members. A case study of six-story concentrically braced frame building was selected to numerically validate and demonstrate the proposed method. The deep learning model, a convolutional neural network, was trained and tested using numerically generated dataset from over 2000 sets of nonlinear seismic simulation, and an accuracy of over 90% was observed for bracing buckling damage detection in this case study. The results of the deep learning model were also discussed and extended to define other damage feature indices. This study shows that the proposed procedure is promising for rapid bracing condition inspection in concentrically braced frame structures after earthquakes.","acceleration,damage detection,deep learning,nondestructive evaluation,structural health monitoring",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA","Construction & Building Technology,Engineering",,1.925,PERFORMANCE,ADVANCES IN STRUCTURAL ENGINEERING,,
30,Evaluation of modified adaptive k-means segmentation algorithm,5,4,347-361,"Debelee Taye Girma,Schwenker Friedhelm,Rahimeto Samuel,Yohannes Dereje","Debelee TG,Schwenker F,Rahimeto S,Yohannes D",Debelee TG,10.1007/s41095-019-0151-2,Ulm University,"Segmentation is the act of partitioning an image into different regions by creating boundaries between regions. k-means image segmentation is the simplest prevalent approach. However, the segmentation quality is contingent on the initial parameters (the cluster centers and their number). In this paper, a convolution-based modified adaptive k-means (MAKM) approach is proposed and evaluated using images collected from different sources (MATLAB, Berkeley image database, VOC2012, BGH, MIAS, and MRI). The evaluation shows that the proposed algorithm is superior to k-means++, fuzzy c-means, histogram-based k-means, and subtractive k-means algorithms in terms of image segmentation quality (Q-value), computational cost, and RMSE. The proposed algorithm was also compared to state-of-the-art learning-based methods in terms of IoU and MIoU; it achieved a higher MIoU value.","clustering,modified adaptive k-means (MAKM),segmentation,Q-value",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Computer Science,,,,COMPUTATIONAL VISUAL MEDIA,https://link.springer.com/content/pdf/10.1007/s41095-019-0151-2.pdf,
31,Predicting and explaining inflammation in Crohn's disease patients using predictive analytics methods and electronic medical record data,25,4,1201-1218,"Reddy Bhargava K.,Delen Dursun,Agrawal Rupesh K.","Reddy BK,Delen D,Agrawal RK",Delen D,10.1177/1460458217751015,Oklahoma State University System,"Crohn's disease is among the chronic inflammatory bowel diseases that impact the gastrointestinal tract. Understanding and predicting the severity of inflammation in real-time settings is critical to disease management. Extant literature has primarily focused on studies that are conducted in clinical trial settings to investigate the impact of a drug treatment on the remission status of the disease. This research proposes an analytics methodology where three different types of prediction models are developed to predict and to explain the severity of inflammation in patients diagnosed with Crohn's disease. The results show that machine-learning-based analytic methods such as gradient boosting machines can predict the inflammation severity with a very high accuracy (area under the curve=92.82%), followed by regularized regression and logistic regression. According to the findings, a combination of baseline laboratory parameters, patient demographic characteristics, and disease location are among the strongest predictors of inflammation severity in Crohn's disease patients.","C-reactive protein,Crohn's disease,data mining,electronic medical records,gradient boosting machine,logistic regression,machine learning,predictive analytics,regularized regression",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA","Health Care Sciences & Services,Medical Informatics",,,"C-REACTIVE,PROTEIN,ULCERATIVE-COLITIS,CLINICAL,ACTIVITY,EHR,DATA,RELAPSE,RISK,CLASSIFICATION,INFLIXIMAB,NETWORK,MARKERS",HEALTH INFORMATICS JOURNAL,,
32,An accessible and efficient autism screening method for behavioural data and predictive analyses,25,4,1739-1755,Thabtah Fadi,Thabtah F,Thabtah F,10.1177/1460458218796636,Manukau Institute of Technology,"Autism spectrum disorder is associated with significant healthcare costs, and early diagnosis can substantially reduce these. Unfortunately, waiting times for an autism spectrum disorder diagnosis are lengthy due to the fact that current diagnostic procedures are time-consuming and not cost-effective. Overall, the economic impact of autism and the increase in the number of autism spectrum disorder cases across the world reveal an urgent need for the development of easily implemented and effective screening methods. This article proposes a new mobile application to overcome the problem by offering users and the health community a friendly, time-efficient and accessible mobile-based autism spectrum disorder screening tool called ASDTests. The proposed ASDTests app can be used by health professionals to assist their practice or to inform individuals whether they should pursue formal clinical diagnosis. Unlike existing autism screening apps being tested, the proposed app covers a larger audience since it contains four different tests, one each for toddlers, children, adolescents and adults as well as being available in 11 different languages. More importantly, the proposed app is a vital tool for data collection related to autism spectrum disorder for toddlers, children, adolescent and adults since initially over 1400 instances of cases and controls have been collected. Feature and predictive analyses demonstrate small groups of autistic traits improving the efficiency and accuracy of screening processes. In addition, classifiers derived using machine learning algorithms report promising results with respect to sensitivity, specificity and accuracy rates.","accessibility,autism spectrum disorder screening methods,autism spectrum disorder,behavioural science,classification,machine learning,mobile application",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA","Health Care Sciences & Services,Medical Informatics",,3.0,"SPECTRUM,QUOTIENT,CHECKLIST,DISORDERS,TODDLERS,RESOURCE,AQ",HEALTH INFORMATICS JOURNAL,https://journals.sagepub.com/doi/pdf/10.1177/1460458218796636,
33,Using Surgeon Hand Motions to Predict Surgical Maneuvers,61,8,1326-1339,"Azari David P.,Hu Yu Hen,Miller Brady L.,Le Brian V.,Radwin Robert G.","Azari DP,Hu YH,Miller BL,Le BV,Radwin RG",Radwin RG,10.1177/0018720819838901,University of Wisconsin System,"Objective: This study explores how common machine learning techniques can predict surgical maneuvers from a continuous video record of surgical benchtop simulations.
Background: Automatic computer vision recognition of surgical maneuvers (suturing, tying, and transition) could expedite video review and objective assessment of surgeries.
Method: We recorded hand movements of 37 clinicians performing simple and running subcuticular suturing benchtop simulations, and applied three machine learning techniques (decision trees, random forests, and hidden Markov models) to classify surgical maneuvers every 2 s (60 frames) of video.
Results: Random forest predictions of surgical video correctly classified 74% of all video segments into suturing, tying, and transition states for a randomly selected test set. Hidden Markov model adjustments improved the random forest predictions to 79% for simple interrupted suturing on a subset of randomly selected participants.
Conclusion: Random forest predictions aided by hidden Markov modeling provided the best prediction of surgical maneuvers. Training of models across all users improved prediction accuracy by 10% compared with a random selection of participants.
Application: Marker-less video hand tracking can predict surgical maneuvers from a continuous video record with similar accuracy as robot-assisted surgical platforms, and may enable more efficient video review of surgical procedures for training and coaching.","computer vision,marker-less hand tracking,machine learning,open surgeries,surgical skills",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA","Behavioral Sciences,Engineering,Psychology",,,"MINIMALLY,INVASIVE,SURGERY,OPERATING-ROOM,VIDEO,RECOGNITION,SKILL,SEGMENTATION,KINEMATICS,PATTERNS,TIME",HUMAN FACTORS,,
34,Analysis and classification of malignancy in pancreatic magnetic resonance images using neural network techniques,29,4,399-418,"Balasubramanian Aruna Devi,Murugan Pallikonda Rajasekaran,Thiyagarajan Arun Prasath","Balasubramanian AD,Murugan PR,Thiyagarajan AP",Murugan PR,10.1002/ima.22314,Kalasalingam Academy of Research & Education,"Computer-aided diagnosis (CAD) is a computerized way of detecting tumors in MR images. Magnetic resonance imaging (MRI) has been generally used in the diagnosis and detection of pancreatic tumors. In a medical imaging system, soft tissue contrast and noninvasiveness are clear preferences of MRI. Inaccurate detection of tumor and long time consumption are the disadvantages of MRI. Computerized classifiers can greatly renew the diagnosis activity, in terms of both accuracy and time necessity by normal and abnormal images, automatically. This article presents an intelligent, automatic, accurate, and robust method to classify human pancreas MRI images as normal or abnormal in terms of pancreatic tumor. It represents the response of artificial neural network (ANN) and support vector machine (SVM) techniques for pancreatic tumor classification. For this, we extract features from MR images of pancreas using the GLCM method and select the best features using JAFER algorithm. These features are analyzed by five classification techniques: ANN BP, ANN RBF, SVM Linear, SVM Poly, and SVM RBF. We compare the results with benchmark data set of MR brain images. The analytical outcome presents that the two best features used to classify the MR images using ANN BP technique have 98% classification accuracy.","ANN,GLCM features,image classification,magnetic resonance imaging (MRI),SVM",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,"MR-IMAGES,FEATURES,SEGMENTATION,SELECTION",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
35,Unsupervised learning-based clustering approach for smart identification of pathologies and segmentation of tissues in brain magnetic resonance imaging,29,4,439-456,"Vigneshwaran S.,Govindaraj Vishnuvarthanan,Murugan Pallikonda R.,Zhang Yudong,Arun Prasath Thiyagarajan","Vigneshwaran S,Govindaraj V,Murugan PR,Zhang YD,Arun Prasath T",Vigneshwaran S,10.1002/ima.22321,Kalasalingam Academy of Research & Education,"Human-made/developed algorithms provide automatic identification and segmentation of the tissues, lesions and tumor regions available in brain magnetic resonance scan images, which invocates predicaments such as high computational cost and low accuracy rate. Such hassles are reconciled with the utilization of an unsupervised approach in combination with clustering techniques. Initially, static features are chosen from the input image, which is fed to the self-organizing map (SOM), where the algorithm employs the dimensionality reduction of input images. Consecutively, the reduced SOM prototype of data is clustered by the modified fuzzy K-means (MFKM) algorithm. The MFKM algorithm can be modified in terms of membership variables because it operates with spatial information and converges quickly, and this would be of greater benefit to radiologists as they reduce the wrong predictions and voluminous time that normally occur owing to human involvement. The proposed algorithm provides 98.77% sensitivity and 97.5% specificity, which are better than any other traditional algorithms mentioned in this article.","medical image analysis,modified fuzzy K-means,self-organizing map,tissue segmentation,tumors and lesion identification",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,"MULTIPLE-SCLEROSIS,LESIONS,SELF-ORGANIZING,MAPS,AUTOMATIC,SEGMENTATION,NEURAL-NETWORKS,MR-IMAGES,CT,SCANS,ALGORITHM,REGION,TUMOR,LIVER",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
36,Landmark-based multi-region ensemble convolutional neural networks for bone age assessment,29,4,457-464,"Cao Shaomeng,Chen Zhiye,Li Congsheng,Lv Chuanfeng);,Wu Tongning,Lv Bin","Cao SM,Chen ZY,Li CS,Lv CF,Wu TN,Lv B",Wu TN,10.1002/ima.22323,China Academy of Information & Communication Technology,"Bone age assessment based on hand X-ray imaging is important in pediatry medicine. At present, prediction of bone age is mainly performed by the manual comparison with the existing atlas. To develop an automatic regression framework based on deep learning with high performance and efficiency. A landmark-based multi-region convolutional neural networks for automatic bone age assessment based on left hand X-ray images was proposed. The deep alignment network localized multiple landmarks distributed over the hand, and cropped the local regions to establish the multi-region ensemble convolutional neural networks with different sub-network combinations. The modified loss function and the optimized bone sub-regions were applied to train the networks. The experiments on Digital Hand Atlas Database revealed that the mean absolute error of bone age assessment was 0.52 +/- 0.25 years. It is the first study to predict bone age using deep learning methods throughout the entire process including image preprocessing, landmark localization and bone age predication. The proposed method outperformed most of the existing state-of-the-art deep learning methods and achieved good results compared with the expert's experience. It can improve the efficiency of the medical doctors while minimizing the subjective errors.","bone age assessment,convolutional neural network,deep learning,landmark localization,segmentation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,"AUTOMATED-DETERMINATION,GREULICH,VALIDATION,MODEL",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
37,Pediatric brain extraction from T2-weighted MR images using 3D dual frame U-net and human connectome database,29,4,476-482,"Kim Dongchan,Chae Jong-Hee,Han Yeji","Kim D,Chae JH,Han Y",Han Y,10.1002/ima.22325,Gachon University,"Accurate extraction of brain tissues from magnetic resonance (MR) images is important in neuroradiology. However, brain extraction is more difficult for pediatric brains than for adult brains due to several factors including smaller brain sizes and lower tissue contrasts. In this work, we propose a brain extraction technique that utilizes dual frame (DF) 3D U-net deep learning architecture and the human connectome project (HCP) database for multislice 2D pediatric T2-weighted MR images with diseases. To improve segmentation accuracy in small pediatric brains with detailed boundary regions, DF 3D U-net architecture was used. We pretrained networks with the HCP database to compensate for the limited amount of MR images and manual segmentation masks of pediatric patients. For quantitative analysis, we compared the brain extraction results of brain extraction tool, DF, and conventional 3D U-net using the dice similarity coefficient (DSC), intersection of union (IoU), and boundary F1 (BF) scores; each deep learning architecture was evaluated with and without pretraining using the HCP. This study included 10 patients with diseases and all images were acquired using a PROPELLER MR sequence. Pretraining using the HCP database enhanced segmentation performance of the network, and the skip connections in the DF 3D U-net could enhance the contour similarity of segmentation results. Experimental results showed that the proposed method increased the DSC, IoU, and BF scores by 0.8%, 1.6%, and 1.5%, respectively, compared with those of the conventional 3D U-net without pretraining.","dual frame 3D U-net,HCP database,pediatric brain extraction",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,SEGMENTATION,INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
38,Teeth category classification via seven-layer deep convolutional neural network with max pooling and global average pooling,29,4,577-583,"Li Zhi,Wang Shui-Hua,Fan Rui-Rui,Cao Gang,Zhang Yu-Dong,Guo Ting","Li Z,Wang SH,Fan RR,Cao G,Zhang YD,Guo T",Zhang YD,10.1002/ima.22337,Henan Polytechnic University,"Accurately classify teeth category is important in further dental diagnosis. Analyzing huge dental data, that is, identifying the teeth category, is often a hard task. Current automatic methods are based on computer vision and deep learning approaches. In this study, we aimed to classify the teeth category into four classes: incisor, canine, premolar, and molar. Cone beam computed tomography was used to collect the data. We proposed a seven-layer deep convolutional neural network with global average pooling to identify teeth category. Data augmentation method was used to enlarge the size of training dataset. The results showed the sensitivities of incisor, canine, premolar, and molar teeth are 88%, 86%, 84%, and 90%, respectively. The average sensitivity is 87.0%. We validated max pooling gives better results than average pooling. Our method is better than three state-of-the-art approaches.","cone beam computed tomography,convolutional neural network,data augmentation,deep convolutional neural network,deep learning,global average pooling,max pooling",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,"REPRESENTATION,IMAGES",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
39,Neuro-wavelet based intelligent medical image fusion,29,4,633-644,"Hassan Mehdi,Murtza Iqbal,Zafar Khan Muhammad Aqdus,Tahir Syed Fahad,Fahad Labiba Gillani","Hassan M,Murtza I,Khan MAZ,Tahir SF,Fahad LG",Murtza I,10.1002/ima.22347,Air University Islamabad,"Imaging based sensitive clinical diagnosis is critically depending on image quality. In this article, the problem of enhancing fundus images is addressed by a novel fusion technique. The proposed approach utilizes the representation capability of wavelet transform and the learning ability of artificial neural networks. In this approach, input images are decomposed into wavelet transform followed by appropriate feature extraction for training of neural networks to obtain fused image. To ensure homogeneity, it employs consistency verification for minimizing the fusion artifacts. The visual and quantitative performance of the proposed approach is assessed using a number of experiments performed on the standard datasets of DRIVE and DRION-DB. The experimental results demonstrate that the proposed fusion technique offers high average structural similarity of ""0.99."" The proposed approach outperforms state-of-the-art techniques which validates its effectiveness. The developed approach might be applied by the clinical diagnosis system for fundus related diseases.","artificial neural network,image fusion,image processing,machine learning,wavelet transform",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,,"TRANSFORM,CT,NETWORKS,MRI",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
40,A novel EEG-complexity-based feature and its application on the epileptic seizure detection,10,12,3339-3348,"Zhang Shu-Ling,Zhang Bo,Su Yong-Li,Song Jiang-Ling","Zhang SL,Zhang B,Su YL,Song JL",Zhang B,10.1007/s13042-019-00921-w,Northwest University Xi'an,"The neurophysiology system is a complex network of nerves and cells, which carries messages to and from the brain and spinal cord to various parts of the body. Exploring complexity of the system can be contributed to understand diverse neurophysiological abnormalities, which may further result in different kinds of neurological disorders. In this paper, we present a novel analyzing framework to characterize the complexity of neurophysiological system, under which a specific weighted FPE-complexity-based feature (W-FPE-F) is extracted from EEG and then applied into the automated epileptic seizure detection. Combining with extreme learning machine (ELM) and support vector machine (SVM), performances of the proposed method are finally verified on two open EEG databases. Simulation results show that the proposed method does a good job in detecting the epileptic seizure, particularly, it is able to avoid the undesirable detection performance caused by individual divergence effectively.","Neurophysiology system,Complexity analysis,Feature extraction,Feature weighting,Automated seizure detection,Electroencephalography (EEG)",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Computer Science,,3.558,"EXTREME,LEARNING-MACHINE,ELECTROENCEPHALOGRAM,ENTROPY,RECOGNITION",INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS,,
41,A deep learning framework for automatic diagnosis of unipolar depression,132,,,"Mumtaz Wajid,Qayyum Abdul","Mumtaz W,Qayyum A",Mumtaz W,10.1016/j.ijmedinf.2019.103983,National University of Sciences & Technology - Pakistan,"Background and purpose: In recent years, the development of machine learning (ML) frameworks for automatic diagnosis of unipolar depression has escalated to a next level of deep learning frameworks. However, this idea needs further validation. Therefore, this paper has proposed an electroencephalographic (EEG)-based deep learning framework that automatically discriminated depressed and healthy controls and provided the diagnosis.
Basic procedures: In this paper, two different deep learning architectures were proposed that utilized one dimensional convolutional neural network (1DCNN) and 1DCNN with long short-term memory (LSTM) architecture. The proposed deep learning architectures automatically learn patterns in the EEG data that were useful for classifying the depressed and healthy controls. In addition, the proposed models were validated with resting-state EEG data obtained from 33 depressed patients and 30 healthy controls.
Main findings: As results, significant differences were observed between the two groups. The classification results involving the CNN model were accuracy=98.32%, precision=99.78%, recall=98.34%, and f-score=97.65%. In addition, the study has reported LSTM with 1DCNN classification accuracy=95.97%, precision=99.23%, recall=93.67%, and f-score=95.14%.
Conclusions: Deep learning frameworks could revolutionize the clinical applications for EEG-based diagnosis for depression. Based on the results, it may be concluded that the deep learning framework could be used as an automatic method for diagnosing the depression.","EEG-based deep learning for depression,EEG-based diagnosis of unipolar depression,Convolutional neural network for depression,Long short-term memory classifiers for depression",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Health Care Sciences & Services,Medical Informatics",,4.768,"NONLINEAR,FEATURES,EEG",INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS,,
42,Deep Learning Method for Automated Classification of Anteroposterior and Posteroanterior Chest Radiographs,32,6,925-930,"Kim Tae Kyung,Yi Paul H.,Wei Jinchi,Shin Ji Won,Hager Gregory,Hui Ferdinand K.,Sair Haris I.,Lin Cheng Ting","Kim TK,Yi PH,Wei JC,Shin JW,Hager G,Hui FK,Sair HI,Lin CT",Lin CT,10.1007/s10278-019-00208-0,Johns Hopkins University,"Ensuring correct radiograph view labeling is important for machine learning algorithm development and quality control of studies obtained from multiple facilities. The purpose of this study was to develop and test the performance of a deep convolutional neural network (DCNN) for the automated classification of frontal chest radiographs (CXRs) into anteroposterior (AP) or posteroanterior (PA) views. We obtained 112,120 CXRs from the NIH ChestX-ray14 database, a publicly available CXR database performed in adult (106,179 (95%)) and pediatric (5941 (5%)) patients consisting of 44,810 (40%) AP and 67,310 (60%) PA views. CXRs were used to train, validate, and test the ResNet-18 DCNN for classification of radiographs into anteroposterior and posteroanterior views. A second DCNN was developed in the same manner using only the pediatric CXRs (2885 (49%) AP and 3056 (51%) PA). Receiver operating characteristic (ROC) curves with area under the curve (AUC) and standard diagnostic measures were used to evaluate the DCNN's performance on the test dataset. The DCNNs trained on the entire CXR dataset and pediatric CXR dataset had AUCs of 1.0 and 0.997, respectively, and accuracy of 99.6% and 98%, respectively, for distinguishing between AP and PA CXR. Sensitivity and specificity were 99.6% and 99.5%, respectively, for the DCNN trained on the entire dataset and 98% for both sensitivity and specificity for the DCNN trained on the pediatric dataset. The observed difference in performance between the two algorithms was not statistically significant (p = 0.17). Our DCNNs have high accuracy for classifying AP/PA orientation of frontal CXRs, with only slight reduction in performance when the training dataset was reduced by 95%. Rapid classification of CXRs by the DCNN can facilitate annotation of large image datasets for machine learning and quality assurance purposes.","Deep learning,Deep convoluted neural networks,Artificial intelligence,PACS",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"CONVOLUTIONAL,NEURAL-NETWORKS,ARTIFICIAL-INTELLIGENCE",JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6841900,
43,Classification of Aortic Dissection and Rupture on Post-contrast CT Images Using a Convolutional Neural Network,32,6,939-946,"Harris Robert J.,Kim Shwan,Lohr Jerry,Towey Steve,Velichkovich Zeljko,Kabachenko Tim,Driscoll Ian,Baker Brian","Harris RJ,Kim S,Lohr J,Towey S,Velichkovich Z,Kabachenko T,Driscoll I,Baker B",Harris RJ,10.1007/s10278-019-00281-5,"Virtual Radiol, 11995 Singletree Ln N, Eden Prairie, MN 55344 USA.","Aortic dissections and ruptures are life-threatening injuries that must be immediately treated. Our national radiology practice receives dozens of these cases each month, but no automated process is currently available to check for critical pathologies before the images are opened by a radiologist. In this project, we developed a convolutional neural network model trained on aortic dissection and rupture data to assess the likelihood of these pathologies being present in prospective patients. This aortic injury model was used for study prioritization over the course of 4 weeks and model results were compared with clinicians' reports to determine accuracy metrics. The model obtained a sensitivity and specificity of 87.8% and 96.0% for aortic dissection and 100% and 96.0% for aortic rupture. We observed a median reduction of 395 s in the time between study intake and radiologist review for studies that were prioritized by this model. False-positive and false-negative data were also collected for retraining to provide further improvements in subsequent versions of the model. The methodology described here can be applied to a number of modalities and pathologies moving forward.","Aortic,Dissection,Rupture,Convolutional neural network,Machine learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,,JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6841906,
44,Deep Learning for Detection of Complete Anterior Cruciate Ligament Tear,32,6,980-986,"Chang Peter D.,Wong Tony T.,Rasiej Michael J.","Chang PD,Wong TT,Rasiej MJ",Rasiej MJ,10.1007/s10278-019-00193-4,Columbia University,"Deep learning for MRI detection of sports injuries poses unique challenges. To address these difficulties, this study examines the feasibility and incremental benefit of several customized network architectures in evaluation of complete anterior cruciate ligament (ACL) tears. Two hundred sixty patients, ages 18-40, were identified in a retrospective review of knee MRIs obtained from September 2013 to March 2016. Half of the cases demonstrated a complete ACL tear (624 slices), the other half a normal ACL (3520 slices). Two hundred cases were used for training and validation, and the remaining 60 cases as an independent test set. For each exam with an ACL tear, coronal proton density non-fat suppressed sequence was manually annotated to delineate: (1) a bounding-box around the cruciate ligaments; (2) slices containing the tear. Multiple convolutional neural network (CNN) architectures were implemented including variations in input field-of-view and dimensionality. For single-slice CNN architectures, validation accuracy of a dynamic patch-based sampling algorithm (0.765) outperformed both cropped slice (0.720) and full slice (0.680) strategies. Using the dynamic patch-based sampling algorithm as a baseline, a five-slice CNN input (0.915) outperformed both three-slice (0.865) and single-slice (0.765) inputs. The final highest performing five-slice dynamic patch-based sampling algorithm resulted in independent test set AUC, sensitivity, specificity, PPV, and NPV of 0.971, 0.967, 1.00, 0.938, and 1.00. A customized 3D deep learning architecture based on dynamic patch-based sampling demonstrates high performance in detection of complete ACL tears with over 96% test set accuracy. A cropped field-of-view and 3D inputs are critical for high algorithm performance.","Deep learning,Machine learning,Artificial intelligence,Anterior cruciate ligament,Magnetic resonance imaging",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"RECONSTRUCTION,KNEE",JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6841825,
45,Computer-Aided Diagnosis (CAD) of Pulmonary Nodule of Thoracic CT Image Using Transfer Learning,32,6,995-1007,"Zhang Shikun,Sun Fengrong,Wang Naishun,Zhang Cuicui,Yu Qianlei,Zhang Mingqiang,Babyn Paul,Zhong Hai","Zhang SK,Sun FR,Wang NS,Zhang CC,Yu QL,Zhang MQ,Babyn P,Zhong H",Sun FR,10.1007/s10278-019-00204-4,Shandong University,"Computer-aided diagnosis (CAD) has already been widely used in medical image processing. We recently make another trial to implement convolutional neural network (CNN) on the classification of pulmonary nodules of thoracic CT images. The biggest challenge in medical image classification with the help of CNN is the difficulty of acquiring enough samples, and overfitting is a common problem when there are not enough images for training. Transfer learning has been verified as reasonable in dealing with such problems with an acceptable loss value. We use the classic LeNet-5 model to classify pulmonary nodules of thoracic CT images, including benign and malignant pulmonary nodules, and different malignancies of the malignant nodules. The CT images are obtained from Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) where both pulmonary nodule scanning and nodule annotations are available. These images are labeled and stored in a medical images knowledge base (KB), which is designed and implemented in our previous work. We implement the 10-folder cross validation (CV) to testify the robustness of the classification model we trained. The result demonstrates that the transfer learning of the LeNet-5 is good for classifying pulmonary nodules of thoracic CT images, and the average values of Top-1 accuracy are 97.041% and 96.685% respectively. We believe that our work is beneficial and has potential for practical diagnosis of lung nodules.","Pulmonary nodule,Classification,Thoracic CT,Transfer learning,CNN",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,,JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6841885,
46,Lung Segmentation on HRCT and Volumetric CT for Diffuse Interstitial Lung Disease Using Deep Convolutional Neural Networks,32,6,1019-1026,"Park Beomhee,Park Heejun,Lee Sang Min,Seo Joon Beom,Kim Namkug","Park B,Park H,Lee SM,Seo JB,Kim N",Kim N,10.1007/s10278-019-00254-8,University of Ulsan,"A robust lung segmentation method using a deep convolutional neural network (CNN) was developed and evaluated on high-resolution computed tomography (HRCT) and volumetric CT of various types of diffuse interstitial lung disease (DILD). Chest CT images of 617 patients with various types of DILD, including cryptogenic organizing pneumonia (COP), usual interstitial pneumonia (UIP), and nonspecific interstitial pneumonia (NSIP), were scanned using HRCT (1-2-mm slices, 5-10-mm intervals) and volumetric CT (sub-millimeter thickness without intervals). Each scan was segmented using a conventional image processing method and then manually corrected by an expert thoracic radiologist to create gold standards. The lung regions in the HRCT images were then segmented using a two-dimensional U-Net architecture with the deep CNN, using separate training, validation, and test sets. In addition, 30 independent volumetric CT images of UIP patients were used to further evaluate the model. The segmentation results for both conventional and deep-learning methods were compared quantitatively with the gold standards using four accuracy metrics: the Dice similarity coefficient (DSC), Jaccard similarity coefficient (JSC), mean surface distance (MSD), and Hausdorff surface distance (HSD). The mean and standard deviation values of those metrics for the HRCT images were 98.84 +/- 0.55%, 97.79 +/- 1.07%, 0.27 +/- 0.18 mm, and 25.47 +/- 13.63 mm, respectively. Our deep-learning method showed significantly better segmentation performance (p < 0.001), and its segmentation accuracies for volumetric CT were similar to those for HRCT. We have developed an accurate and robust U-Net-based DILD lung segmentation method that can be used for patients scanned with different clinical protocols, including HRCT and volumetric CT.","Chest CT,Deep learning,Diffuse interstitial lung disease,Lung segmentation,U-net",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,,,JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6841863,
47,High Efficiency Video Coding (HEVC)-Based Surgical Telementoring System Using Shallow Convolutional Neural Network,32,6,1027-1043,"Hassan Ali,Ghafoor Mubeen,Tariq Syed Ali,Zia Tehseen,Ahmad Waqas","Hassan A,Ghafoor M,Tariq SA,Zia T,Ahmad W",Tariq SA,10.1007/s10278-019-00206-2,COMSATS University Islamabad (CUI),"Surgical telementoring systems have gained lots of interest, especially in remote locations. However, bandwidth constraint has been the primary bottleneck for efficient telementoring systems. This study aims to establish an efficient surgical telementoring system, where the qualified surgeon (mentor) provides real-time guidance and technical assistance for surgical procedures to the on-spot physician (surgeon). High Efficiency Video Coding (HEVC/H.265)-based video compression has shown promising results for telementoring applications. However, there is a trade-off between the bandwidth resources required for video transmission and quality of video received by the remote surgeon. In order to efficiently compress and transmit real-time surgical videos, a hybrid lossless-lossy approach is proposed where surgical incision region is coded in high quality whereas the background region is coded in low quality based on distance from the surgical incision region. For surgical incision region extraction, state-of-the-art deep learning (DL) architectures for semantic segmentation can be used. However, the computational complexity of these architectures is high resulting in large training and inference times. For telementoring systems, encoding time is crucial; therefore, very deep architectures are not suitable for surgical incision extraction. In this study, we propose a shallow convolutional neural network (S-CNN)-based segmentation approach that consists of encoder network only for surgical region extraction. The segmentation performance of S-CNN is compared with one of the state-of-the-art image segmentation networks (SegNet), and results demonstrate the effectiveness of the proposed network. The proposed telementoring system is efficient and explicitly considers the physiological nature of the human visual system to encode the video by providing good overall visual impact in the location of surgery. The results of the proposed S-CNN-based segmentation demonstrated a pixel accuracy of 97% and a mean intersection over union accuracy of 79%. Similarly, HEVC experimental results showed that the proposed surgical region-based encoding scheme achieved an average bitrate reduction of 88.8% at high-quality settings in comparison with default full-frame HEVC encoding. The average gain in encoding performance (signal-to-noise) of the proposed algorithm is 11.5 dB in the surgical region. The bitrate saving and visual quality of the proposed optimal bit allocation scheme are compared with the mean shift segmentation-based coding scheme for fair comparison. The results show that the proposed scheme maintains high visual quality in surgical incision region along with achieving good bitrate saving. Based on comparison and results, the proposed encoding algorithm can be considered as an efficient and effective solution for surgical telementoring systems for low-bandwidth networks.","Convolutional neural network (CNN),Deep learning (DL),HEVC,Medical imaging,Segmentation,Telementoring",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,,"WOUND,ASSESSMENT,DEEP,SEGMENTATION,REGION",JOURNAL OF DIGITAL IMAGING,http://miun.diva-portal.org/smash/get/diva2:1335899/FULLTEXT01,
48,Variabilities in Reference Standard by Radiologists and Performance Assessment in Detection of Pulmonary Embolism in CT Pulmonary Angiography,32,6,1089-1096,"Zhou Chuan,Chan Heang-Ping,Chughtai Aamer,Patel Smita,Kuriakose Jean,Hadjiiski Lubomir M.,Wei Jun,Kazerooni Ella A.","Zhou C,Chan HP,Chughtai A,Patel S,Kuriakose J,Hadjiiski LM,Wei J,Kazerooni EA",Zhou C,10.1007/s10278-019-00228-w,University of Michigan System,"Annotating lesion locations by radiologists' manual marking is a key step to provide reference standard for the training and testing of a computer-aided detection system by supervised machine learning. Inter-reader variability is not uncommon in readings even by expert radiologists. This study evaluated the variability of the radiologist-identified pulmonary emboli (PEs) to demonstrate the importance of improving the reliability of the reference standard by a multi-step process for performance evaluation. In an initial reading of 40 CTPA PE cases, two experienced thoracic radiologists independently marked the PE locations. For markings from the two radiologists that did not agree, each radiologist re-read the cases independently to assess the discordant markings. Finally, for markings that still disagreed after the second reading, the two radiologists read together to reach a consensus. The variability of radiologists was evaluated by analyzing the agreement between two radiologists. For the 40 cases, 475 and 514 PEs were identified by radiologists R1 and R2 in the initial independent readings, respectively. For a total of 545 marks by the two radiologists, 81.5% (444/545) of the marks agreed but 101 marks in 36 cases differed. After consensus, 65 (64.4%) and 36 (35.6%) of the 101 marks were determined to be true PEs and false positives (FPs), respectively. Of these, 48 and 17 were false negatives (FNs) and 14 and 22 were FPs by R1 and R2, respectively. Our study demonstrated that there is substantial variability in reference standards provided by radiologists, which impacts the performance assessment of a lesion detection system. Combination of multiple radiologists' readings and consensus is needed to improve the reliability of a reference standard.","Computer-aided detection,Pulmonary embolism,Computed tomographic pulmonary angiography (CTPA),Reader variability,Reference standard",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"COMPUTER-AIDED,DETECTION,VENTILATION-PERFUSION,SCINTIGRAPHY,HELICAL,CT,SPIRAL,CT,INTEROBSERVER,AGREEMENT,DIAGNOSIS,TOMOGRAPHY,SEVERITY",JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6841909,
49,Automated Billing Code Retrieval from MRI Scanner Log Data,32,6,1103-1111,"Denck Jonas,Landschuetz Wilfried,Nairz Knud,Heverhagen Johannes T.,Maier Andreas,Rothgang Eva","Denck J,Landschutz W,Nairz K,Heverhagen JT,Maier A,Rothgang E",Denck J,10.1007/s10278-019-00241-z,"Tech Univ Appl Sci Amberg Weiden, Inst Med Engn, Weiden, Germany.","Although the level of digitalization and automation steadily increases in radiology, billing coding for magnetic resonance imaging (MRI) exams in the radiology department is still based on manual input from the technologist. After the exam completion, the technologist enters the corresponding exam codes that are associated with billing codes in the radiology information system. Moreover, additional billing codes are added or removed, depending on the performed procedure. This workflow is time-consuming and we showed that billing codes reported by the technologists contain errors. The coding workflow can benefit from an automated system, and thus a prediction model for automated assignment of billing codes for MRI exams based on MRI log data is developed in this work. To the best of our knowledge, it is the first attempt to focus on the prediction of billing codes from modality log data. MRI log data provide a variety of information, including the set of executed MR sequences, MR scanner table movements, and given a contrast medium. MR sequence names are standardized using a heuristic approach and incorporated into the features for the prediction. The prediction model is trained on 9754 MRI exams and tested on 1 month of log data (423 MRI exams) from two MRI scanners of the radiology site for the Swiss medical tariffication system Tarmed. The developed model, an ensemble of classifier chains with multilayer perceptron as a base classifier, predicts medical billing codes for MRI exams with a micro-averaged F1-score of 97.8% (recall 98.1%, precision 97.5%). Manual coding reaches a micro-averaged F1-score of 98.1% (recall 97.4%, precision 98.8%). Thus, the performance of automated coding is close to human performance. Integrated into the clinical environment, this work has the potential to free the technologist from a non-value adding an administrative task, therefore enhance the MRI workflow, and prevent coding errors.","Machine learning,Magnetic resonance imaging,Medical coding,Reimbursement,Workflow enhancement",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA","Radiology, Nuclear Medicine & Medical Imaging",,,,JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6841869,
50,Stomach Deformities Recognition Using Rank-Based Deep Features Selection,43,12,,"Khan Muhammad Attique,Sharif Muhammad,Akram Tallha,Yasmin Mussarat,Nayak Ramesh Sunder","Khan MA,Sharif M,Akram T,Yasmin M,Nayak RS",Sharif M,10.1007/s10916-019-1466-3,COMSATS University Islamabad (CUI),"Doctor utilizes various kinds of clinical technologies like MRI, endoscopy, CT scan, etc., to identify patient's deformity during the review time. Among set of clinical technologies, wireless capsule endoscopy (WCE) is an advanced procedures used for digestive track malformation. During this complete process, more than 57,000 frames are captured and doctors need to examine a complete video frame by frame which is a tedious task even for an experienced gastrologist. In this article, a novel computerized automated method is proposed for the classification of abdominal infections of gastrointestinal track from WCE images. Three core steps of the suggested system belong to the category of segmentation, deep features extraction and fusion followed by robust features selection. The ulcer abnormalities from WCE videos are initially extracted through a proposed color features based low level and high-level saliency (CFbLHS) estimation method. Later, DenseNet CNN model is utilized and through transfer learning (TL) features are computed prior to feature optimization using Kapur's entropy. A parallel fusion methodology is opted for the selection of maximum feature value (PMFV). For feature selection, Tsallis entropy is calculated later sorted into descending order. Finally, top 50% high ranked features are selected for classification using multilayered feedforward neural network classifier for recognition. Simulation is performed on collected WCE dataset and achieved maximum accuracy of 99.5% in 21.15 s.","Colorectal cancer,WCE,Saliency estimation,Deep features selection,Features fusion",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Health Care Sciences & Services,Medical Informatics",,3.951,"CAPSULE,ENDOSCOPY,LESION,DETECTION,CLASSIFICATION,SEGMENTATION,STRATEGY,ENTROPY",JOURNAL OF MEDICAL SYSTEMS,,
51,Lung Nodule Detection based on Ensemble of Hand Crafted and Deep Features,43,12,,"Saba Tanzila,Sameh Ahmed,Khan Fatima,Shad Shafqat Ali,Sharif Muhammad","Saba T,Sameh A,Khan F,Shad SA,Sharif M",Saba T,10.1007/s10916-019-1455-6,Prince Sultan University,"Lung cancer is considered as a deadliest disease worldwide due to which 1.76 million deaths occurred in the year 2018. Keeping in view its dreadful effect on humans, cancer detection at a premature stage is a more significant requirement to reduce the probability of mortality rate. This manuscript depicts an approach of finding lung nodule at an initial stage that comprises of three major phases: (1) lung nodule segmentation using Otsu threshold followed by morphological operation; (2) extraction of geometrical, texture and deep learning features for selecting optimal features; (3) The optimal features are fused serially for classification of lung nodule into two categories that is malignant and benign. The lung image database consortium image database resource initiative (LIDC-IDRI) is used for experimentation. The experimental outcomes show better performance of presented approach as compared with the existing methods.","Cells,Texture,Benign,VGG 19,SVM",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Health Care Sciences & Services,Medical Informatics",,3.951,"FALSE-POSITIVE,REDUCTION,COMPUTER-AIDED,DETECTION,PULMONARY,NODULES,CT,IMAGES,AUTOMATIC,DETECTION,CANCER,CLASSIFICATION,SEGMENTATION,TOMOGRAPHY,SCALE",JOURNAL OF MEDICAL SYSTEMS,,
52,Research on prediction model of geotechnical parameters based on BP neural network,31,12,8205-8215,"Cui Kai,Jing Xiang","Cui K,Jing X",Cui K,10.1007/s00521-018-3902-6,Southwest Jiaotong University,"With the vigorous development of the national economy, the pace and scale of urban construction have been unfolded at an unprecedented speed. A large number of construction projects have made the urban engineering geological exploration activities reach a considerable scale in depth and breadth. The survey results of these projects are very valuable information resources, which not only played an important role in urban planning and construction at that time, but also had high reuse value. Based on BP neural network theory, this paper uses engineering geological database as the research and development platform. Based on the theory of BP neural network and the engineering geological database as the research and development platform, this paper establishes the prediction of geotechnical parameters based on the analysis of the characteristics of geotechnical materials and the distribution of geotechnical sediments and geotechnical parameters. Based on the survey data and specific engineering information, the prediction model of the project was established, and the distribution of the stratum and the relevant geotechnical parameters were predicted. Based on the study of geotechnical properties and BP neural network, a new parameter prediction model is established. Taking the engineering geological database as the platform, using the programming language such as MATLAB, the preliminary research and construction of this prediction system were carried out. The results show that the generalization ability of the prediction model meets the requirements.","BP neural network,Geotechnical parameters,Prediction",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,,NEURAL COMPUTING & APPLICATIONS,,
53,Predictive modelling of the higher heating value in biomass torrefaction for the energy treatment process using machine-learning techniques,31,12,8823-8836,"Garcia Nieto P. J.,Garcia-Gonzalo E.,Paredes-Sanchez J. P.,Bernardo Sanchez A.,Menendez Fernandez M.","Nieto PJG,Garcia-Gonzalo E,Paredes-Sanchez JP,Sanchez AB,Fernandez MM",Nieto PJG,10.1007/s00521-018-3870-x,University of Oviedo,"Torrefaction of biomass can be described as a mild form of pyrolysis at temperatures typically ranging between 200 and 300 degrees C in the absence of oxygen. Common biomass reactions during torrefaction include devolatilization, depolymerization, and carbonization of hemicellulose, lignin, and cellulose. Torrefaction of biomass improves properties like moisture content as well as calorific value. The aim of this study was to obtain a predictive model able to perform an early detection of the higher heating value (HHV) in a biomass torrefaction process. This study presents a novel hybrid algorithm, based on support vector machines (SVMs) in combination with the particle swarm optimization (PSO) technique, for predicting the HHV of biomass from operation input parameters determined experimentally during the torrefaction process. Additionally, a multilayer perceptron network (MLP) and random forest (RF) were fitted to the experimental data for comparison purposes. To this end, the most important physical-chemical parameters of this industrial process are monitored and analysed. The results of the present study are two-fold. In the first place, the significance of each physical-chemical variables on the HHV is presented through the model. Secondly, several models for forecasting the calorific value of torrefied biomass are obtained. Indeed, when this hybrid PSO-SVM-based model with cubic kernel function was applied to the experimental dataset and regression with optimal hyperparameters was carried out, a coefficient of determination equal to 0.94 was obtained for the higher heating value estimation of torrefied biomass. Furthermore, the results obtained with the MLP approach and RF-based model are worse than the best obtained with the PSO-SVM-based model. The agreement between experimental data and the model confirmed the good performance of the latter. Finally, we expose the conclusions of this study.","Support vector machines (SVMs),Particle swarm optimization (PSO),Artificial neural networks (ANNs),Higher heating value (HHV) prediction",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"SUPPORT,VECTOR,MACHINE,VOLATILE,SPECIES,RELEASE,LIGNOCELLULOSIC,BIOMASS,CROSS-VALIDATION,WOOD,OPTIMIZATION,PRETREATMENT,FOREST,FUEL,PERFORMANCE",NEURAL COMPUTING & APPLICATIONS,,
54,A novel feature extraction method for machine learning based on surface electromyography from healthy brain,31,12,9013-9022,"Li Gongfa,Li Jiahan,Ju Zhaojie,Sun Ying,Kong Jianyi","Li GF,Li JH,Ju ZJ,Sun Y,Kong JY",Li GF,10.1007/s00521-019-04147-3,Wuhan University of Science & Technology,"Feature extraction is one of most important steps in the control of multifunctional prosthesis based on surface electromyography (sEMG) pattern recognition. In this paper, a new sEMG feature extraction method based on muscle active region is proposed. This paper designs an experiment to classify four hand motions using different features. This experiment is used to prove that new features have better classification performance. The experimental results show that the new feature, active muscle regions (AMR), has better classification performance than other traditional features, mean absolute value (MAV), waveform length (WL), zero crossing (ZC) and slope sign changes (SSC). The average classification errors of AMR, MAV, WL, ZC and SSC are 13%, 19%, 26%, 24% and 22%, respectively. The new EMG features are based on the mapping relationship between hand movements and forearm active muscle regions. This mapping relationship has been confirmed in medicine. We obtain the active muscle regions data from the original EMG signal by the new feature extraction algorithm. The results obtained from this algorithm can well represent hand motions. On the other hand, the new feature vector size is much smaller than other features. The new feature can narrow the computational cost. This proves that the AMR can improve sEMG pattern recognition accuracy rate.","sEMG,New feature,Active muscle regions,Machine learning",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"MYOELECTRIC,CONTROL,CLASSIFICATION,EMG,PROSTHESES,SIGNAL,STRATEGY",NEURAL COMPUTING & APPLICATIONS,,
55,Radiomics for Distinguishing Myocardial Infarction from Myocarditis at Late Gadolinium Enhancement at MRI: Comparison with Subjective Visual Analysis.,1,5,e180026,",,,,,,","Di Noto Tommaso,von Spiczak Jochen,Mannil Manoj,Gantert Elena,Soda Paolo,Manka Robert,Alkadhi Hatem",,10.1148/ryct.2019180026,,"Purpose: To evaluate whether radiomics features of late gadolinium enhancement (LGE) regions at cardiac MRI enable distinction between myocardial infarction (MI) and myocarditis and to compare radiomics with subjective visual analyses by readers with different experience levels.Results: When trained with recursive feature elimination (RFE), a support vector machine achieved the best results (accuracy: 88%) for 2D features, whereas linear discriminant analysis (LDA) showed the highest accuracy (85%) for 3D features (P <.05). When trained with principal component analysis (PCA), LDA attained the highest accuracy with both 2D (86%) and 3D (89%; P =.4) features. Results found for classifiers trained with spline resampling were less accurate than those achieved with one-dimensional (1D) nearest-neighbor interpolation (P <.05), whereas results for classifiers trained with 1D nearest-neighbor interpolation and without resampling were similar (P =.1). As compared with the radiomics approach, subjective visual analysis performance was lower for the less experienced and higher for the experienced reader for both 2D and 3D data. 2019 by the Radiological Society of North America, Inc.",,Journal Article,,,,,,,,
56,A hybrid approach using rough set theory and hypergraph for feature selection on high-dimensional medical datasets,23,23,12655-12672,"Raman M. R. Gauthama,Nivethitha Somu,Kannan Krithivasan,Sriram V. S. Shankar","Raman MRG,Nivethitha S,Kannan K,Sriram VSS",Sriram VSS,10.1007/s00500-019-03818-6,Indian Council of Agricultural Research (ICAR),"'Curse of Dimensionality'-massive generation of high-dimensional medical datasets from various biomedical applications hardens the data analytic process for precise medical diagnosis. The design of an efficient feature selection technique for finding the optimal feature subset can be devised as a prominent solution to the above-said challenge. Further, it also improves the accuracy and minimizes the computational complexity of the learning model. The state-of-the-art feature selection techniques based on heuristic and statistical functions suffer from significant challenges in terms of classification accuracy, time complexity, etc. Hence, this paper presents Rough Set Theory and Hypergraph (RSHGT)-based feature selection technique to identify the optimal feature subset for accurate medical diagnosis. Experimental validations using six medical datasets from the Kent Ridge Biomedical dataset repository prove the efficiency of RSHGT in terms of reduct size, accuracy, precision, recall, and time complexity.","Hypergraph,Rough set theory (RST),Vertex linearity,Minimal transversal,Medical diagnosis",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA",Computer Science,,3.518,"PROBABILISTIC,NEURAL-NETWORK,PARTICLE,SWARM,OPTIMIZATION,GENE,SELECTION,ALGORITHM,CLASSIFICATION",SOFT COMPUTING,,
57,Chemical reaction optimization to disease diagnosis by optimizing hyper-planes classifiers,23,24,13263-13282,"Jalayeri Somayeh,Abdolrazzagh-Nezhad Majid","Jalayeri S,Abdolrazzagh-Nezhad M",Abdolrazzagh-Nezhad M,10.1007/s00500-019-03869-9,"Bozorgmehr Univ Qaenat, Dept Comp Engn, Fac Engn, Qaen, Iran.","Early diagnosis of diseases can save and leads to survival. There are several diagnoses techniques which mostly consist of classification and optimization parts. Although these techniques have their specific advantages, they have their significant disadvantages such as sensitivity to the number of features (symptoms) and need to features selection, challenge to detect non-integrated regions of one class and high complexity of their progresses. In this paper to fill up the disadvantages, a novel classification is proposed to disease diagnosis by different numbers of hyper-planes classifiers (HPC) that divides medical data into adequate regions based on assigning binary codes to each region. The HPC can find useful relationships between the symptoms of the diseases by tagging each region with the suitable class label. To optimize the HPC's coefficients and improve disease diagnosis, chemical reaction optimization (CRO) is adapted based on four reactions on HPC's coefficients, which are coded as molecular structures. Different numbers of HPCs are performed, and their experimental results are compared together. The interesting point of the results is disease diagnosis error 0.000% by five hyper-planes for test data of all investigated medical data set. Also, the best-obtained results of the CRO-HPC are compared with the best outputs of more than 50 methods of disease diagnosis from the previous state-of-the-art literature. This comparison shows that CRO-HPC's diagnosis errors can compete with the majority of the other diagnostic methods.","Hyper-planes classifier,Classification of medical data,Chemical reaction optimization,Disease diagnosis",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,3.518,"SUPPORT,VECTOR,MACHINE,FEATURE-SELECTION,LUNG-CANCER,HYBRID,CLASSIFICATION,SYSTEM,MODEL,PSO",SOFT COMPUTING,,
58,Dependence of UO2 surface morphology on processing history within a single synthetic route,107,12,1121-1131,"Abbott Erik C.,Brenkmann Alexandria,Galbraith Craig,Ong Joshua,Schwerdt Ian J.,Albrecht Brent D.,Tasdizen Tolga,McDonald Luther W.","Abbott EC,Brenkmann A,Galbraith C,Ong J,Schwerdt IJ,Albrecht BD,Tasdizen T,McDonald LW",McDonald LW,10.1515/ract-2018-3065,Utah System of Higher Education,"This study aims to determine forensic signatures for processing history of UO2 based on modifications in intermediate materials within the uranyl peroxide route. Uranyl peroxide was calcined to multiple intermediate U-oxides including Am-UO3, alpha-UO3, and alpha-U3O8 during the production of UO2. The intermediate U-oxides were then reduced to alpha-UO2 via hydrogen reduction under identical conditions. Powder X-ray diffractometry (p-XRD) and X-ray photoelectron spectroscopy (XPS) were used to analyze powders of the intermediate U-oxides and resulting UO2 to evaluate the phase and purity of the freshly synthesized materials. All U-oxides were also analyzed via scanning electron microscopy (SEM) to determine the morphology of the freshly prepared powders. The microscopy images were subsequently analyzed using the Morphological Analysis for Materials (MAMA) version 2.1 software to quantitatively compare differences in the morphology of UO2 from each intermediate U-oxide. In addition, the microscopy images were analyzed using a machine learning model which was trained based on a VGG 16 architecture. Results show no differences in the XRD or XPS spectra of the UO2 produced from each intermediate. However, results from both the segmentation and machine learning proved that the morphology was quantifiably different. In addition, the morphology of UO2 was very similar, if not identical, to the intermediate material from which it was prepared, thus making quantitative morphological analysis a reliable forensic signature of processing history.","Nuclear forensics,morphology,X-ray diffraction,X-ray photoelectron spectroscopy,scanning electron microscopy",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY","Chemistry,Nuclear Science & Technology",,1.265,"AMMONIUM,URANYL,CARBONATE,THERMAL-DECOMPOSITION,URANIUM,TEMPERATURE,PELLETS,U3O8,AUC,CONVERSION,SIGNATURES,REDUCTION",RADIOCHIMICA ACTA,,
59,Extracting comprehensive clinical information for breast cancer using deep learning methods,132,,,"Zhang Xiaohui,Zhang Yaoyun,Zhang Qin,Ren Yuankai,Qiu Tinglin,Ma Jianhui,Sun Qiang","Zhang XH,Zhang YY,Zhang Q,Ren YK,Qiu TL,Ma JH,Sun Q",Sun Q,10.1016/j.ijmedinf.2019.103985,Chinese Academy of Medical Sciences - Peking Union Medical College,"Objective: Breast cancer is the most common malignant tumor among women. The diagnosis and treatment information of breast cancer patients is abundant in multiple types of clinical fields, including clinicopathological data, genotype and phenotype information, treatment information, and prognosis information. However, current studies are mainly focused on extracting information from one specific type of clinical field. This study defines a comprehensive information model to represent the whole-course clinical information of patients. Furthermore, deep learning approaches are used to extract the concepts and their attributes from clinical breast cancer documents by fine-tuning pretrained Bidirectional Encoder Representations from Transformers (BERT) language models.
Materials and methods: The clinical corpus that was used in this study was from one 3A cancer hospital in China, consisting of the encounter notes, operation records, pathology notes, radiology notes, progress notes and discharge summaries of 100 breast cancer patients. Our system consists of two components: a named entity recognition (NER) component and a relation recognition component. For each component, we implemented deep learning-based approaches by fine-tuning BERT, which outperformed other state-of-the-art methods on multiple natural language processing (NLP) tasks. A clinical language model is first pretrained using BERT on a large-scale unlabeled corpus of Chinese clinical text. For NER, the context embeddings that were pretrained using BERT were used as the input features of the Bi-LSTM-CRF (Bidirectional long-short-memory-conditional random fields) model and were fine-tuned using the annotated breast cancer notes. Furthermore, we proposed an approach to fine-tune BERT for relation extraction. It was considered to be a classification problem in which the two entities that were mentioned in the input sentence were replaced with their semantic types.
Results: Our best-performing system achieved F1 scores of 93.53% for the NER and 96.73% for the relation extraction. Additional evaluations showed that the deep learning-based approaches that fine-tuned BERT did outperform the traditional Bi-LSTM-CRF and CRF machine learning algorithms in NER and the attention-Bi-LSTM and SVM (support vector machines) algorithms in relation recognition.
Conclusion: In this study, we developed a deep learning approach that fine-tuned BERT to extract the breast cancer concepts and their attributes. It demonstrated its superior performance compared to traditional machine learning algorithms, thus supporting its uses in broader NER and relation extraction tasks in the medical domain.","Clinical information extraction,Breast cancer,Deep learning,Fine-tuning BERT,Information model",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Health Care Sciences & Services,Medical Informatics",,4.768,"AUTOMATED,EXTRACTION",INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS,,
60,CT Texture Analysis and Machine Learning Improve Post-ablation Prognostication in Patients with Adrenal Metastases: A Proof of Concept,42,12,1771-1776,"Daye Dania,Staziaki Pedro V,Furtado Vanessa Fiorini,Tabari Azadeh,Fintelmann Florian J.,Frenk Nathan Elie,Shyn Paul,Tuncali Kemal,Silverman Stuart,Arellano Ronald","Daye D,Staziaki PV,Furtado VF,Tabari A,Fintelmann FJ,Frenk NE,Shyn P,Tuncali K,Silverman S,Arellano R",Daye D,10.1007/s00270-019-02336-0,Harvard University,"Introduction To assess the performance of pre-ablation computed tomography texture features of adrenal metastases to predict post-treatment local progression and survival in patients who underwent ablation using machine learning as a prediction tool. Materials and Methods This is a pilot retrospective study of patients with adrenal metastases undergoing ablation. Clinical variables were collected. Thirty-two texture features were extracted from manually segmented adrenal tumors. A univariate cox proportional hazard model was used for prediction of local progression and survival. A linear support vector machine (SVM) learning technique was applied to the texture features and clinical variables, with leave-one-out cross-validation. Receiver operating characteristic analysis and the area under the curve (AUC) were used to assess performance between using clinical variables only versus clinical variables and texture features. Results Twenty-one patients (61% male, age 64.1 +/- 10.3 years) were included. Mean time to local progression was 29.8 months. Five texture features exhibited association with progression (p < 0.05). The SVM model based on clinical variables alone resulted in an AUC of 0.52, whereas the SVM model that included texture features resulted in an AUC 0.93 (p = 0.01). Mean overall survival was 35 months. Fourteen texture features were associated with survival in the univariate model (p < 0.05). While the trained SVM model based on clinical variables resulted in an AUC of 0.68, the SVM model that included texture features resulted in an AUC of 0.93 (p = 0.024). Discussion Pre-ablation texture analysis and machine learning improve local tumor progression and survival prediction in patients with adrenal metastases who undergo ablation.","Radiomics,Machine learning,Prognostication,Texture analysis,Ablation,Adrenal metastasis",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA","Cardiovascular System & Cardiology,Radiology, Nuclear Medicine & Medical Imaging",,2.568,"PERCUTANEOUS,MICROWAVE,ABLATION,RADIOFREQUENCY,ABLATION,ARTIFICIAL-INTELLIGENCE,SINGLE-INSTITUTION,GUIDED,ABLATION,CARCINOMA,TUMORS,EXPERIENCE,IMAGES",CARDIOVASCULAR AND INTERVENTIONAL RADIOLOGY,,
61,Machine learning aided stochastic elastoplastic analysis,357,,,"Feng Yuan,Gao Wei,Wu Di,Tin-Loi Francis","Feng Y,Gao W,Wu D,Tin-Loi F",Gao W,10.1016/j.cma.2019.112576,University of New South Wales Sydney,"The stochastic elastoplastic analysis is investigated for structures under plane stress/strain conditions. A novel uncertain nonlinear analysis framework, namely the machine leaning aided stochastic elastoplastic analysis (MLA-SEPA), is presented herein via finite element method (REM). The proposed MLA-SEPA is a favourable alternative to determine structural reliability when full-scale testing is not achievable, thus leading to significant eliminations of manpower and computational efforts spent in practical engineering applications. Within the MLA-SEPA framework, an extended support vector regression (X-SVR) approach is introduced and then incorporated for the subsequent uncertainty quantification. By successfully establishing the governing relationship between the uncertain system parameters and any concerned structural output, a comprehensive probabilistic profile including means, standard deviations, probability density functions (PDFs), and cumulative distribution functions (CDFs) of the structural output can be effectively established through a sampling scheme. Consequently, the nonlinear performance of the structure against both serviceability and strength limit states can be effectively investigated with the consideration of various system uncertainties. Three numerical examples are thoroughly investigated to illustrate the accuracy, applicability and effectiveness of the proposed MLA-SEPA approach. (C) 2019 Elsevier B.V. All rights reserved.","Stochastic finite element method,Extended-support vector regression,Uncertainty analysis",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Engineering,Mathematics,Mechanics",,6.828,"FINITE-ELEMENT-ANALYSIS,SUPPORT,VECTOR,REGRESSION,KARHUNEN-LOEVE,EXPANSION,RESPONSE,ANALYSIS,RELIABILITY-ANALYSIS,ACOUSTIC,SYSTEM,INTERVAL,KERNEL,OPTIMIZATION,SIMULATION",COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING,,
62,Accelerating multiscale finite element simulations of history-dependent materials using a recurrent neural network,357,,,"Ghavamian F.,Simone A.","Ghavamian F,Simone A",Ghavamian F,10.1016/j.cma.2019.112594,Delft University of Technology,"FE2 multiscale simulations of history-dependent materials are accelerated by means of a recurrent neural network (RNN) surrogate for the history-dependent micro level response. We propose a simple strategy to efficiently collect stress-strain data from the micro model, and we modify the RNN model such that it resembles a nonlinear finite element analysis procedure during training We then implement the trained RNN model in the FE2 scheme and employ automatic differentiation to compute the consistent tangent. The exceptional performance of the proposed model is demonstrated through a number of academic examples using strain-softening Perzyna viscoplasticity as the nonlinear material model at the micro level. (C) 2019 Elsevier B.V. All rights reserved.","Machine learning,Recurrent neural network,Deep learning,Multiscale modeling,Viscoplasticity,Strain softening",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Engineering,Mathematics,Mechanics",,6.828,"MODEL,REDUCTION",COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING,https://repository.tudelft.nl/islandora/object/uuid%3A3832b270-d25c-4c06-8a96-000d62298d9d/datastream/OBJ/download,
63,IoT data feature extraction and intrusion detection system for smart cities based on deep migration learning,49,,533-545,"Li Daming,Deng Lianbing,Lee Minchang,Wang Haoxiang","Li DM,Deng LB,Lee MC,Wang HX",Lee MC,10.1016/j.ijinfomgt.2019.04.006,Chosun University,"With the development of information technology and economic growth, the Internet of Things (IoT) industry has also entered the fast lane of development. The IoT industry system has also gradually improved, forming a complete industrial foundation, including chips, electronic components, equipment, software, integrated systems, IoT services, and telecom operators. In the event of selective forwarding attacks, virus damage, malicious virus intrusion, etc., the losses caused by such security problems are more serious than those of traditional networks, which are not only network information materials, but also physical objects. The limitations of sensor node resources in the Internet of Things, the complexity of networking, and the open wireless broadcast communication characteristics make it vulnerable to attacks. Intrusion Detection System (IDS) helps identify anomalies in the network and takes the necessary countermeasures to ensure the safe and reliable operation of IoT applications. This paper proposes an IoT feature extraction and intrusion detection algorithm for intelligent city based on deep migration learning model, which combines deep learning model with intrusion detection technology. According to the existing literature and algorithms, this paper introduces the modeling scheme of migration learning model and data feature extraction. In the experimental part, KDD CUP 99 was selected as the experimental data set, and 10% of the data was used as training data. At the same time, the proposed algorithm is compared with the existing algorithms. The experimental results show that the proposed algorithm has shorter detection time and higher detection efficiency.","Deep learning,Migration learning model,Sensor network,Smart City,Internet of things,Information feature extraction",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Information Science & Library Science,,13.074,INNOVATION,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,,
64,Diagnosis and monitoring of Alzheimer's patients using classical and deep learning techniques,136,,353-364,"Raza M.,Awais M.,Ellahi W.,Aslam N.,Nguyen H. X.,Le-Minh H.","Raza M,Awais M,Ellahi W,Aslam N,Nguyen HX,Le-Minh H",Raza M,10.1016/j.eswa.2019.06.038,Middlesex University,"Machine based analysis and prediction systems are widely used for diagnosis of Alzheimer's Disease (AD). However, lower accuracy of existing techniques and lack of post diagnosis monitoring systems limit the scope of such studies. In this paper, a novel machine learning based diagnosis and monitoring of AD-like diseases is proposed. The AD-like diseases diagnosis process is accomplished by analysing the magnetic resonance imaging (MRI) scans using deep learning and is followed by an activity monitoring framework to monitor the subjects' activities of daily living using body worn inertial sensors. The activity monitoring provides an assistive framework in daily life activities and evaluates vulnerability of the patients based on the activity level. The AD diagnosis results show up to 82% improvement in comparison to well-known existing techniques. Moreover, above 95% accuracy is achieved to classify the activities of daily living which is quite encouraging in terms of monitoring the activity profile of the subject. (C) 2019 Elsevier Ltd. All rights reserved.","Alzheimer Disease (AD),Deep Neural Networks,Activities of Daily Life (ADLs),Support Vector Machine (SVM),Machine learning,Magnetic Resonance Imaging (MRI)",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"INERTIAL,MEASUREMENT,UNITS,PHYSICAL-ACTIVITY,BALANCE,ANALYSIS,DISEASE,EXERCISE,AGE",EXPERT SYSTEMS WITH APPLICATIONS,https://research.edgehill.ac.uk/ws/files/30035222/diagnosis_and_monitoring_of_Alzheimers_patients_R3_v2.1.pdf,
65,Fast optimization of defect compensation and optical proximity correction for extreme ultraviolet lithography mask,452,,169-180,"Zhang Heng);,Li Sikun);,Wang Xiangzhao);,Meng Zejiang);,Cheng Wei","Zhang H,Li SK,Wang XZ,Meng ZJ,Cheng W",Li SK; Wang XZ,10.1016/j.optcom.2019.07.029,Chinese Academy of Sciences,"Mask multilayer defect and optical proximity effect bring harmful impact on the imaging quality of extreme ultraviolet lithography. The undesirable impact could be compensated for by modification of the mask patterns. Based on machine learning and quasi-rigorous electromagnetic method, two fast simulation methods are utilized to accelerate the optimization of the defect compensation patterns. Defect compensation considering simultaneous optical proximity correction is also studied for further improvement of pattern fidelity. Combined with a well-performed evolutionary searching algorithm, the two fast simulation methods are adopted in the defect-compensation optimization for different mask patterns. Mask modification optimization considering both defect compensation and optical proximity correction is also demonstrated by a simulation study. Simulation results demonstrated the acceleration due to the adoption of the two fast simulation methods. Simulation results also validated that both the defect impact and the optical proximity effect can be compensated for under the same mask modification frame. The mask modification strategy combining the two fast simulation methods and the evolutionary algorithm provides a potential and flexible compensation approach for EUVL masks that influenced by multilayer defect and proximity effect.","EUV lithography,Mask diffraction,Defect compensation,Optical proximity correction,Machine learning,Covariance matrix adaption",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Optics,,1.945,,OPTICS COMMUNICATIONS,,
66,Dosimetric study on learning-based cone-beam CT correction in adaptive radiation therapy.,44,4,e71-e79,,,,10.1016/j.meddos.2019.03.001,,"INTRODUCTION: Cone-beam CT (CBCT) image quality is important for its quantitative analysis in adaptive radiation therapy. However, due to severe artifacts, the CBCTs are primarily used for verifying patient setup only so far. We have developed a learning-based image quality improvement method which could provide CBCTs with image quality comparable to planning CTs (pCTs). The accuracy of dose calculations based on these CBCTs is unknown. In this study, we aim to investigate the dosimetric accuracy of our corrected CBCT (CCBCT) in brain stereotactic radiosurgery (SRS) and pelvic radiotherapy.MATERIALS AND METHODS: We retrospectively investigated a total of 32 treatment plans from 22 patients, each of whom with both original treatment pCTs and CBCTs acquired during treatment setup. The CCBCT and original CBCT (OCBCT) were registered to the pCT for generating CCBCT-based and OCBCT-based treatment plans. The original pCT-based plans served as ground truth. Clinically-relevant dose volume histogram (DVH) metrics were extracted from the ground truth, OCBCT-based and CCBCT-based plans for comparison. Gamma analysis was also performed to compare the absorbed dose distributions between the pCT-based and OCBCT/CCBCT-based plans of each patient.RESULTS: CCBCTs demonstrated better image contrast and more accurate HU ranges when compared side-by-side with OCBCTs. For pelvic radiotherapy plans, the mean dose error in DVH metrics for planning target volume (PTV), bladder and rectum was significantly reduced, from 1% to 0.3%, after CBCT correction. The gamma analysis showed the average pass rate increased from 94.5% before correction to 99.0% after correction. For brain SRS treatment plans, both original and corrected CBCT images were accurate enough for dose calculation, though CCBCT featured higher image quality.CONCLUSION: CCBCTs can provide a level of dose accuracy comparable to traditional pCTs for brain and prostate radiotherapy planning and the correction method proposed here can be useful in CBCT-guided adaptive radiotherapy. Copyright © 2019 American Association of Medical Dosimetrists. Published by Elsevier Inc. All rights reserved.",Adaptive radiation therapy; Cone-beam CT,Journal Article,,,,,,,,
67,Subsurface damage detection of a steel bridge using deep learning and uncooled micro-bolometer,226,,376-387,"Ali Rahmat,Cha Young-Jin","Ali R,Cha YJ",Cha YJ,10.1016/j.conbuildmat.2019.07.293,University of Manitoba,"A new deep learning-based method is proposed to detect subsurface damage of steel members in a steel truss bridge using infrared thermography (IRT). To reduce computation costs, the original deep inception neural network (DINN) is modified for transfer learning. The proposed method provides bounding boxes for detecting and localizing subsurface damage such as corrosion and debonding between paint with coating and steel surface. Robustness and accuracy were tested on 200 thermal images (640 x 480 pixels), and 96% accuracy and 97.79% specificity was achieved. The results were validated with ultrasonic pulse velocity (UPV) tests. (C) 2019 Elsevier Ltd. All rights reserved.","Infrared thermography,Damage detection,Deep learning,Subsurface damage,Bridge,Non-destructive evaluation,Steel structure",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Construction & Building Technology,Engineering,Materials Science",,6.841,"INFRARED,THERMOGRAPHY,CRACKS",CONSTRUCTION AND BUILDING MATERIALS,,
68,A generalized method to predict the compressive strength of high-performance concrete by improved random forest algorithm,226,,734-742,"Han Qinghua,Gui Changqing,Xu Jie,Lacidogna Giuseppe","Han QH,Gui CQ,Xu J,Lacidogna G",Xu J,10.1016/j.conbuildmat.2019.07.315,China Earthquake Administration,"The prediction results of high-performance concrete compressive strength (HPCCS) based on machine learning methods are seriously influenced by input variables and model parameters. This study proposes a method with two stages to select proper variables, simplify parameter settings, and predict HPCCS. The appropriate variables are selected in the first stage by measuring their importance based on random forest, and then are optimized to predict HPCCS in the second stage. The results show that the proposed method was effective for input variable optimization, and could return better predictions than that without variable optimization, provided that the parameters are set within a reasonable range. Compared with previous models, the proposed method shows a strong generalization capacity for HPCCS prediction. We find that the prediction performance of the model is better when the input variables are expressed as absolute mass, and the model performers well when the actual compressive strength of HPC is high. (C) 2019 Elsevier Ltd. All rights reserved.","Random forest,High-performance concrete,Compressive strength,Input variable optimization,Parameter determination",Article; Proceedings Paper,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Construction & Building Technology,Engineering,Materials Science",,6.841,"PARTICLE,SWARM,OPTIMIZATION,SUPPORT,VECTOR,REGRESSION,NEURAL-NETWORK,MODEL,CLASSIFICATION,SILICA,FRESH",CONSTRUCTION AND BUILDING MATERIALS,,
69,Instance-based learning of marker proteins of carcinoma cells for cell death/ survival,8,3,313-322,"Jain Shruti,Chauhan D. S.","Jain S,Chauhan DS",Jain S,10.1080/21681163.2019.1692236,Jaypee University of Information Technology,"Data collection, pre-processing, statistical analysis, feature extraction and classification are the main steps of Biomedical Image Processing. This paper presents a proposed model employing all the steps used for biomedical image processing. Different proteins were extracted from the heat map which is due to the combination of three input proteins was pre-processed. Statistical analysis is applied to all the different proteins to yield the marker proteins. ROI was extracted from each marker protein on which second order statistical analysis was applied to evaluate features. In this paper, authors have calculated the mean (observed and predicted), standard deviation, sum of squared error, absolute mean error using different classifiers like k-NN with different distance approaches and SVM using different kernels for selected marker proteins which provide better accuracy and least run-time complexity. Based on the best results, k-NN classifier using Euclidean distance and SVM classifiers using Linear Kernels yields an accuracy of 75.6% and 85.8%, respectively, that result better performance in comparison with other state of the art techniques.","Marker proteins,statistical analysis,second -order statistical features,k-nearest neighbour,support vector machine",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,,RECEPTOR,COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION,,
70,Decision tree algorithm in locally advanced rectal cancer: an example of over-interpretation and misuse of a machine learning approach,146,3,761-765,"De Felice Francesca,Crocetti D.,Parisi M.,Maiuri V.,Moscarelli E.,Caiazzo R.,Bulzonetti N.,Musio D.,Tombolini V.","De Felice F,Crocetti D,Parisi M,Maiuri V,Moscarelli E,Caiazzo R,Bulzonetti N,Musio D,Tombolini V",De Felice F,10.1007/s00432-019-03102-y,Sapienza University Rome,"Purpose To analyse the classification performances of a decision tree method applied to predictor variables in survival outcome in patients with locally advanced rectal cancer (LARC). The aim was to offer a critical analysis to better apply tree-based approach in clinical practice and improve its interpretation. Materials and methods Data concerning patients with histological proven LARC between 2007 and 2014 were reviewed. All patients were treated with trimodality approach with a curative intent. The Kaplan-Meier method was used to estimate overall survival (OS). Decision tree methods were was used to select important variables in outcome prediction. Results A total of 100 patients were included. The 5-year and 7-year OS rates were 76.4% and 71.3%, respectively. Age, co-morbidities, tumor size, clinical tumor classification (cT) and clinical nodes classification (cN) were the important predictor variables to the tree's construction. Overall, 13 distinct groups of patients were defined. Patients aged < 65 years with cT3 disease and elderly patients with a tumor size < 5 cm seemed to have highest rates of survival. But the process over-fitted the data, leading to poor algorithm performance. Conclusion We proposed a decision tree algorithm to identify known and new pre-treatment clinical predictors of survival in LARC. Our analysis confirmed that tree-based machine learning method, especially classification trees, can be easily interpreted even by a non-expert in the field, but controlling cross validation errors is mandatory to capture its statistical power. However, it is necessary to carefully analyze the classification error trend to chose the important predictor variables, especially in little data. Machine learning approach should be considered the new unexplored frontier in LARC. Based on big datasets, decision trees represent an opportunity to improve decision-making process in clinical practice.","Machine learning,Decision tree,Big data,Rectal cancer,Chemoradiotherapy,Surgery,Survival",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Oncology,,,"NEOADJUVANT,CHEMORADIOTHERAPY,PREOPERATIVE,CHEMORADIOTHERAPY,OXALIPLATIN,FLUOROURACIL",JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY,,
71,Data-driven models for temperature distribution effects on natural frequencies and thermal prestress modeling,27,2,,"Jang Jinwoo,Smyth Andrew W.","Jang J,Smyth AW",Smyth AW,10.1002/stc.2489,"Dept Civil Engn & Engn Mech, 610 SW Mudd Bldg, New York, NY 10027 USA.","In vibration-based damage detection, it is fundamentally important to distinguish between changes in the dynamics of a structure and those related to environmental effects. Modal properties of structures are widely used as damage-sensitive features and indicate changes in physical properties due to structural damage or degradation. However, civil structures such as bridges are influenced by various operational and environmental conditions (such as traffic, wind, humidity, and, most importantly, temperature), and these variables also alter the modal properties of structures. Changes in modal properties caused by environmental effects can mask the effect of structural damage, resulting in unreliable structural damage assessments. It is thus fundamentally important to understand the relationship between environmental effects and modal properties. In this paper, a full-scale finite element (FE) model is used in a simulation-based study to investigate the effects of temperature distribution on natural frequencies. Two approaches for modeling the temperature effects on natural frequencies (thermal prestress imposed at an element level and temperature-dependent Young's modulus) are implemented in the FE model, and results are compared. Then, temperature profiles of the model are hypothetically simulated. These simulation results are used to develop a linear model and the three most popular machine learning models to reproduce the effects of temperature distribution on natural frequencies. Finally, a comprehensive comparison is made between the performances of these data-driven models.","machine learning,regression model,system identification,temperature effects on natural frequencies,thermal prestress",Article,"JOHN WILEY & SONS LTD, THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND","Construction & Building Technology,Engineering,Instruments & Instrumentation",,4.76,"VARYING,ENVIRONMENTAL-CONDITIONS,MODAL,PARAMETERS,IDENTIFICATION,VARIABILITY,BRIDGES",STRUCTURAL CONTROL & HEALTH MONITORING,,
72,Estimating damage size and remaining useful life in degraded structures using deep learning-based multi-source data fusion,19,5,1542-1559,"Aria Amin,Lopez Droguett Enrique,Azarm Shapour,Modarres Mohammad","Aria A,Droguett EL,Azarm S,Modarres M",Aria A,10.1177/1475921719890616,University System of Maryland,"In this article, a new deep learning-based approach for online estimation of damage size and remaining useful life of structures is presented. The proposed approach consists of three modules. In the first module, a long short-term memory regression model is used to construct a sensor-based estimation of the damage size where different ranges of temporal correlations are considered for their effects on the accuracy of the damage size estimations. In the second module, a convolutional neural network semantic image segmentation approach is used to construct automated damage size estimations in which a pixel-wise classification is carried out on images of the damaged areas. Using physics-of-failure relations, frequency mismatches associated with sensor- and image-based size estimations are resolved. Finally, in the third module, damage size estimations obtained by the first two modules are fused together for an online remaining useful life estimation of the structure. Performance of the proposed approach is evaluated using sensor and image data obtained from a set of fatigue crack experiments performed on aluminum alloy 7075-T6 specimens. It is shown that using acoustic emission signals obtained from sensors and microscopic images in these experiments, the damage size estimations obtained from the proposed data fusion approach have higher accuracy than the sensor-based and higher frequency than the image-based estimations. Moreover, the accuracy of the data fusion estimations is found to be more than that of image-based estimations for the experiment with the largest sensor dataset. Based on the results obtained, it is concluded that the consideration of longer temporal correlations can lead to improvements in the accuracy of crack size estimations and, thus, a better remaining useful life estimation for structures.","Time-series analysis,image processing,deep learning,data fusion,damage size estimation,remaining useful life",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Engineering,Instruments & Instrumentation",,5.861,"CONVOLUTIONAL,NEURAL-NETWORKS,PROGNOSTICS,IDENTIFICATION,DIAGNOSIS,IMAGE",STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL,,
73,Magnetic resonance imaging of obesity and metabolic disorders: Summary from the 2019 ISMRM Workshop,83,5,1565-1576,"Hu Houchun H.,Branca Rosa Tamara,Hernando Diego,Karampinos Dimitrios C.,Machann Juergen,McKenzie Charles A.,Wu Holden H.,Yokoo Takeshi,Velan S. Sendhil","Hu HH,Branca RT,Hernando D,Karampinos DC,Machann J,McKenzie CA,Wu HH,Yokoo T,Velan SS",Hu HH,10.1002/mrm.28103,Ohio State University,"More than 100 attendees from Australia, Austria, Belgium, Canada, China, Germany, Hong Kong, Indonesia, Japan, Malaysia, the Netherlands, the Philippines, Republic of Korea, Singapore, Sweden, Switzerland, the United Kingdom, and the United States convened in Singapore for the 2019 ISMRM-sponsored workshop on MRI of Obesity and Metabolic Disorders. The scientific program brought together a multidisciplinary group of researchers, trainees, and clinicians and included sessions in diabetes and insulin resistance; an update on recent advances in water-fat MRI acquisition and reconstruction methods; with applications in skeletal muscle, bone marrow, and adipose tissue quantification; a summary of recent findings in brown adipose tissue; new developments in imaging fat in the fetus, placenta, and neonates; the utility of liver elastography in obesity studies; and the emerging role of radiomics in population-based ""big data"" studies. The workshop featured keynote presentations on nutrition, epidemiology, genetics, and exercise physiology. Forty-four proffered scientific abstracts were also presented, covering the topics of brown adipose tissue, quantitative liver analysis from multiparametric data, disease prevalence and population health, technical and methodological developments in data acquisition and reconstruction, newfound applications of machine learning and neural networks, standardization of proton density fat fraction measurements, and X-nuclei applications. The purpose of this article is to summarize the scientific highlights from the workshop and identify future directions of work.","adipose tissue and fat quantification,diabetes and insulin resistance,liver elastography,obesity and metabolic disorders,proton density fat fraction,skeletal muscle,bone marrow",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"BROWN,ADIPOSE-TISSUE,FATTY,LIVER-DISEASE,IN-VIVO,ASSESSMENT,SHIFT-ENCODED,MRI,BODY-MASS,INDEX,MARROW,FAT,INTRAMYOCELLULAR,LIPIDS,MUSCULAR-DYSTROPHY,PROTON,MR,QUANTITATIVE,MRI",MAGNETIC RESONANCE IN MEDICINE,https://push-zb.helmholtz-muenchen.de/deliver.php?id=26312,
74,Prediction of Concrete Compressive Strength and Slump by Machine Learning Methods,2019,,,Cihan M. Timur,Cihan MT,Cihan MT,10.1155/2019/3069046,"Tekirdag Namik Kemal Univ, Corlu Fac Engn, Civil Engn, TR-59860 Tekirdag, Turkey.","Machine learning methods have been successfully applied to many engineering disciplines. Prediction of the concrete compressive strength (f(c)) and slump (S) is important in terms of the desirability of concrete and its sustainability. The goals of this study were (i) to determine the most successful normalization technique for the datasets, (ii) to select the prime regression method to predict the f(c) and S outputs, (iii) to obtain the best subset with the ReliefF feature selection method, and (iv) to compare the regression results for the original and selected subsets. Experimental results demonstrate that the decimal scaling and min-max normalization techniques are the most successful methods for predicting the compressive strength and slump outputs, respectively. According to the evaluation metrics, such as the correlation coefficient, root mean squared error, and mean absolute error, the fuzzy logic method makes better predictions than any other regression method. Moreover, when the input variable was reduced from seven to four by the ReliefF feature selection method, the predicted accuracy was within the acceptable error rate.","LINEAR-REGRESSION,NEURAL-NETWORKS,SILICA FUME,FLY-ASH",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Construction & Building Technology,Engineering",,1.923,"LINEAR-REGRESSION,NEURAL-NETWORKS,SILICA,FUME,FLY-ASH",ADVANCES IN CIVIL ENGINEERING,https://downloads.hindawi.com/journals/ace/2019/3069046.pdf,
75,Machine learning can accurately predict pre-admission baseline hemoglobin and creatinine in intensive care patients,2,,,"Dauvin Antonin,Donado Carolina,Bachtiger Patrik,Huang Ke-Chun,Sauer Christopher Martin,Ramazzotti Daniele,Bonvini Matteo,Celi Leo Anthony,Douglas Molly J.","Dauvin A,Donado C,Bachtiger P,Huang KC,Sauer CM,Ramazzotti D,Bonvini M,Celi LA,Douglas MJ",Celi LA,10.1038/s41746-019-0192-z,Massachusetts Institute of Technology (MIT),"Patients admitted to the intensive care unit frequently have anemia and impaired renal function, but often lack historical blood results to contextualize the acuteness of these findings. Using data available within two hours of ICU admission, we developed machine learning models that accurately (AUC 0.86-0.89) classify an individual patient's baseline hemoglobin and creatinine levels. Compared to assuming the baseline to be the same as the admission lab value, machine learning performed significantly better at classifying acute kidney injury regardless of initial creatinine value, and significantly better at predicting baseline hemoglobin value in patients with admission hemoglobin of <10 g/dl.","HEALTH-CARE,CLASSIFICATION,TRANSFUSION,INFORMATION,MORTALITY,OUTCOMES,DISEASE,BIAS",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Health Care Sciences & Services,Medical Informatics",,11.665,"HEALTH-CARE,CLASSIFICATION,TRANSFUSION,INFORMATION,MORTALITY,OUTCOMES,DISEASE,BIAS",NPJ DIGITAL MEDICINE,https://dspace.mit.edu/bitstream/1721.1/123503/1/s41746-019-0192-z.pdf,
76,Incorporating long-range physics in atomic-scale machine learning,151,20,,"Grisafi Andrea,Ceriotti Michele","Grisafi A,Ceriotti M",Ceriotti M,10.1063/1.5128375,Ecole Polytechnique Federale de Lausanne,"The most successful and popular machine learning models of atomic-scale properties derive their transferability from a locality ansatz. The properties of a large molecule or a bulk material are written as a sum over contributions that depend on the configurations within finite atom-centered environments. The obvious downside of this approach is that it cannot capture nonlocal, nonadditive effects such as those arising due to long-range electrostatics or quantum interference. We propose a solution to this problem by introducing nonlocal representations of the system, which are remapped as feature vectors that are defined locally and are equivariant in O(3). We consider, in particular, one form that has the same asymptotic behavior as the electrostatic potential. We demonstrate that this framework can capture nonlocal, long-range physics by building a model for the electrostatic energy of randomly distributed point-charges, for the unrelaxed binding curves of charged organic molecular dimers, and for the electronic dielectric response of liquid water. By combining a representation of the system that is sensitive to long-range correlations with the transferability of an atom-centered additive model, this method outperforms current state-of-the-art machine-learning schemes and provides a conceptual framework to incorporate nonlocal physics into atomistic machine learning. Published under license by AIP Publishing.","CHEMISTRY,MODEL",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Chemistry,Physics",,,"CHEMISTRY,MODEL",JOURNAL OF CHEMICAL PHYSICS,http://arxiv.org/pdf/1909.04512,
77,Novel perspective of seismic performance-based evaluation and design for resilient and sustainable slope engineering,262,,,"Xiong Min,Huang Yu","Xiong M,Huang Y",Huang Y,10.1016/j.enggeo.2019.105356,Tongji University,"The performance-based seismic assessment and design concept has been applied successfully to superstructures. To promote the development and extension of performance-based design (PBD) with regard to slope engineering, this paper systematically summarizes and reviews the latest developments of PBD regarding the seismic performance evaluation of slopes. Additionally, it attempts to offer a perspective with regard to performance levels, earthquake ground motion, nonlinear dynamic analysis, stochastic reliability, and future research directions, and establish a new generation framework for the performance-based design of slopes. Moreover, this paper proposes the introduction of the most recently developed machine learning algorithm into the seismic performance of slope engineering. This algorithm is the stochastic dynamics assessment method, which is based on the most advanced numerical approach and a new generation of PBD approaches, such as the resilience-based design concept.","Novel perspective,Performance-based,Evaluation,Design,Resilience,Slope",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Geology",,7.138,"GROUND,MOTIONS,NEURAL-NETWORK,SPATIAL,VARIABILITY,EARTH,STRUCTURES,SIMULATION,PREDICTION,DISPLACEMENTS,OPTIMIZATION,EVOLUTION,DYNAMICS",ENGINEERING GEOLOGY,,
78,AOCT-NET: a convolutional network automated classification of multiclass retinal diseases using spectral-domain optical coherence tomography images,58,1,41-53,Alqudah Ali Mohammad,Alqudah AM,Alqudah AM,10.1007/s11517-019-02066-y,Yarmouk University,"Since introducing optical coherence tomography (OCT) technology for 2D eye imaging, it has become one of the most important and widely used imaging modalities for the noninvasive assessment of retinal eye diseases. Age-related macular degeneration (AMD) and diabetic macular edema eye disease are the leading causes of blindness being diagnosed using OCT. Recently, by developing machine learning and deep learning techniques, the classification of eye retina diseases using OCT images has become quite a challenge. In this paper, a novel automated convolutional neural network (CNN) architecture for a multiclass classification system based on spectral-domain optical coherence tomography (SD-OCT) has been proposed. The system used to classify five types of retinal diseases (age-related macular degeneration (AMD), choroidal neovascularization (CNV), diabetic macular edema (DME), and drusen) in addition to normal cases. The proposed CNN architecture with a softmax classifier overall correctly identified 100% of cases with AMD, 98.86% of cases with CNV, 99.17% cases with DME, 98.97% cases with drusen, and 99.15% cases of normal with an overall accuracy of 95.30%. This architecture is a potentially impactful tool for the diagnosis of retinal diseases using SD-OCT images.","Retina,Optical coherence tomography,Spectral domain,Classification,Deep learning",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"DIABETIC,MACULAR,EDEMA,ARTIFICIAL-INTELLIGENCE,DEGENERATION,DIAGNOSIS",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
79,Full color generation with Fano-type resonant HfO2 nanopillars designed by a deep-learning approach,11,44,21266-21274,"Hemmatyar Omid,Abdollahramezani Sajjad,Kiarashinejad Yashar,Zandehshahvar Mohammadreza,Adibi Ali","Hemmatyar O,Abdollahramezani S,Kiarashinejad Y,Zandehshahvar M,Adibi A",Adibi A,10.1039/c9nr07408b,University System of Georgia,"In contrast to lossy plasmonic metasurfaces (MSs), wideband dielectric MSs comprising subwavelength nanostructures supporting Mie resonances are of great interest in the visible wavelength range. Here, for the first time to our knowledge, we experimentally demonstrate a reflective MS consisting of a square-lattice array of hafnia (HfO2) nanopillars to generate a wide color gamut. To design and optimize these MSs, we use a deep-learning algorithm based on a dimensionality reduction technique. Good agreement is observed between simulation and experimental results in yielding vivid and high-quality colors. We envision that these structures not only empower the high-resolution digital displays and sensitive colorimetric biosensors but also can be applied to on-demand applications of beaming in a wide wavelength range down to deep ultraviolet.",DIELECTRIC METASURFACES,Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,7.632,"DIELECTRIC,METASURFACES",NANOSCALE,http://arxiv.org/pdf/1907.01595,
80,Automated optimized parameters for T-distributed stochastic neighbor embedding improve visualization and analysis of large datasets,10,,,"Belkina Anna C.,Ciccolella Christopher O.,Anno Rina,Halpert Richard,Spidlen Josef,Snyder-Cappione Jennifer E.","Belkina AC,Ciccolella CO,Anno R,Halpert R,Spidlen J,Snyder-Cappione JE",Belkina AC,10.1038/s41467-019-13055-y,Boston University,"Accurate and comprehensive extraction of information from high-dimensional single cell datasets necessitates faithful visualizations to assess biological populations. A state-of-the-art algorithm for non-linear dimension reduction, t-SNE, requires multiple heuristics and fails to produce clear representations of datasets when millions of cells are projected. We develop opt-SNE, an automated toolkit for t-SNE parameter selection that utilizes Kullback-Leibler divergence evaluation in real time to tailor the early exaggeration and overall number of gradient descent iterations in a dataset-specific manner. The precise calibration of early exaggeration together with opt-SNE adjustment of gradient descent learning rate dramatically improves computation time and enables high-quality visualization of large cytometry and transcriptomics datasets, overcoming limitations of analysis tools with hard-coded parameters that often produce poorly resolved or misleading maps of fluorescent and mass cytometry data. In summary, opt-SNE enables superior data resolution in t-SNE space and thereby more accurate data interpretation.","MASS CYTOMETRY,FLOW-CYTOMETRY,CELLS,IMMUNE,HETEROGENEITY,FLUORESCENCE,PANEL",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,15.805,"MASS,CYTOMETRY,FLOW-CYTOMETRY,CELLS,IMMUNE,HETEROGENEITY,FLUORESCENCE,PANEL",NATURE COMMUNICATIONS,https://europepmc.org/articles/pmc6882880?pdf=render,
81,An artificial neural network approach for cost estimation of engineering services,,,,"Matel Erik,Vahdatikhaki Faridaddin,Hosseinyalamdary Siavash,Evers Thijs,Voordijk Hans","Matel E,Vahdatikhaki F,Hosseinyalamdary S,Evers T,Voordijk H",Vahdatikhaki F,10.1080/15623599.2019.1692400,University of Twente,"In a globally competitive world, with diminishing profit margins and decreasing market shares, the cost of a project is one of the major criteria in decision making at the early stages of a building design process in the construction industry. To remain competitive in the market, it is crucial for companies to have an accurate estimate of their projects. Nevertheless, given that very little is known about the scope and details of the project, the conventional cost estimation methods tend to be slow and inaccurate. With the rise of computing power, there is now a tendency to use Machine Learning (ML)-based methods, such as Artificial Neural Networks (ANNs), for more accurate cost estimation that can remain reliable in face of insufficient details during the tendering phase. While the use of ANN for cost estimation has been abundantly investigated from the perspective of contractors, there are very limited studies on the development and application of ML-based methods for engineering consultancy firms. Given that the nature of products/services offered by consultancy firms is inherently different from that of contractors (i.e. they are more abstract and less material-based) and also given that the type and level of detail of the available data at the tendering stage is dissimilar, it is important to investigate the applicability of ML-based methods for cost estimation in consultancy firms. To this end, this paper presents an artificial neural network approach for the cost estimation of engineering services. In developing the model, first, the influential factors that affect the costs of engineering services are identified. Thereafter, a model is developed using the data of 132 projects. Subsequently, a heuristic method is developed to systematically improve and fine-tune the performance of the model. Eventually, the findings show that artificial neural networks (ANNs) can obtain a fairly accurate cost estimate, even with small datasets. In fact, the model proposed in this paper performed better than those proposed in other similar works. The model developed in this study showed a 14.5% improvement in the accuracy of the model, considering MAPE.","Machine learning,artificial neural networks,cost estimation,engineering services",Article; Early Access,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Business & Economics,,,PROJECTS,INTERNATIONAL JOURNAL OF CONSTRUCTION MANAGEMENT,https://ris.utwente.nl/ws/files/159577975/An_artificial_neural_network_approach_for_cost_estimation_of_engineering_services.pdf,
82,Progress and Challenges Toward the Rational Design of Oxygen Electrocatalysts Based on a Descriptor Approach,7,1,,"Liu Jieyu,Liu Hui,Chen Haijun,Du Xiwen,Zhang Bin,Hong Zhanglian,Sun Shuhui,Wang Weichao","Liu JY,Liu H,Chen HJ,Du XW,Zhang B,Hong ZL,Sun SH,Wang WC",Wang WC,10.1002/advs.201901614,Nankai University,"Oxygen redox catalysis, including the oxygen reduction reaction (ORR) and oxygen evolution reaction (OER), is crucial in determining the electrochemical performance of energy conversion and storage devices such as fuel cells, metal-air batteries,and electrolyzers. The rational design of electrochemical catalysts replaces the traditional trial-and-error methods and thus promotes the R&D process. Identifying descriptors that link structure and activity as well as selectivity of catalysts is the key for rational design. In the past few decades, two types of descriptors including bulk- and surface-based have been developed to probe the structure-property relationships. Correlating the current descriptors to one another will promote the understanding of the underlying physics and chemistry, triggering further development of more universal descriptors for the future design of electrocatalysts. Herein, the current benchmark activity descriptors for oxygen electrocatalysis as well as their applications are reviewed. Particular attention is paid to circumventing the scaling relationship of oxygen-containing intermediates. For hybrid materials, multiple descriptors will show stronger predictive power by considering more factors such as interface reconstruction, confinement effect, multisite adsorption, etc. Machine learning and high-throughput simulations can thus be crucial in assisting the discovery of new multiple descriptors and reaction mechanisms.","oxygen electrocatalysis descriptors,oxygen redox reactions",Review,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Chemistry,Science & Technology - Other Topics,Materials Science",,17.835,"TRANSITION-METAL,OXIDES,ENERGY,SCALING,RELATIONS,FUNCTIONALIZED,GRAPHITIC,MATERIALS,REDUCTION,REACTION,CATALYTIC-ACTIVITY,ELECTRONIC-STRUCTURE,SURFACE,REACTIVITY,EVOLUTION,REACTION,ADSORPTION,BAND",ADVANCED SCIENCE,https://europepmc.org/articles/pmc6947511?pdf=render,
83,Numerical Inspection of Heterogeneity in Materials using 2D Heat-Conduction and Hybrid GA-tuned Neural-Network,34,2,125-154,"Ghosh Suman,Dubey Ankit Kumar,Das Arup Kumar","Ghosh S,Dubey AK,Das AK",Ghosh S,10.1080/08839514.2019.1691843,National Institute of Technology (NIT System),"Present work investigates the effect on heat conduction due to the intrusion in a homogeneous bulk and proposes models to detect its position from the temperature distribution on the surface. Finite volume-based, automated numerical simulations are performed for obtaining the temperature history along/across the bulk surface having different positions of the intrusion. Two approaches are developed to predict the intrusion-position from temperature data. In approach 1, a multi-layer feed-forward neural network (NN) with back-propagation (BP) algorithm is used, whereas the NN parameters are determined through a thorough sequential parametric study. In approach 2, again a NN with BP algorithm is used, but a global evolutionary optimizer, namely genetic algorithm (GA) is employed to optimize the NN parameters. NN with BP algorithm and GA are indigenously developed using 'C' programming language in 'linux' operating system. NN and GA are indigenously combined in a common monolithic platform using some specially designed system commands so that data transfer take place seamlessly in a fully automated way. The performances of the developed approaches are tested and validated in several ways. After comparison, approach 2 is found to have higher prediction capability.","THERMOGRAPHY,EQUATION,FLOW",Article,"TAYLOR & FRANCIS INC, 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA","Computer Science,Engineering",,,"THERMOGRAPHY,EQUATION,FLOW",APPLIED ARTIFICIAL INTELLIGENCE,,
84,Detection of Extraprostatic Extension of Cancer on Biparametric MRI Combining Texture Analysis and Machine Learning: Preliminary Results,26,10,1338-1344,"Stanzione Arnaldo,Cuocolo Renato,Cocozza Sirio,Romeo Valeria,Persico Francesco,Fusco Ferdinando,Longo Nicola,Brunetti Arturo,Imbriaco Massimo","Stanzione A,Cuocolo R,Cocozza S,Romeo V,Persico F,Fusco F,Longo N,Brunetti A,Imbriaco M",Cuocolo R,10.1016/j.acra.2018.12.025,University of Naples Federico II,"Rationale and Objectives: Extraprostatic extension of disease (EPE) has a major role in risk stratification of prostate cancer patients. Currently, pretreatment local staging is performed with MRI, while the gold standard is represented by histopathological analysis after radical prostatectomy. Texture analysis (TA) is a quantitative postprocessing method for data extraction, while machine leaming (ML) employs artificial intelligence algorithms for data classification. Purpose of this study was to assess whether ML algorithms could predict histopathological EPE using TA features extracted from unenhanced MR images.
Materials and Methods: Index lesions from biparametric MRI examinations of 39 patients with prostate cancer who underwent radical prostatectomy were manually segmented on both T2-weighted images and ADC maps for TA data extraction. Combinations of different feature selection methods and ML classifiers were tested, and their performance was compared to a baseline accuracy reference.
Results: The classifier showing the best performance was the Bayesian Network, using the dataset obtained by the Subset Evaluator feature selection method. It showed a percentage of correctly classified instances of 82%, an area under the curve of 0.88, a weighted true positive rate of 0.82 and a weighted true negative rate of 0.80.
Conclusion: A combined ML and TA approach appears as a feasible tool to predict histopathological EPE on biparametric MR images. (C) 2019 The Association of University Radiologists. Published by Elsevier Inc. All rights reserved.","PROSTATE-CANCER,RADICAL PROSTATECTOMY,MULTIPARAMETRIC MRI,FEATURES,CLASSIFICATION,GUIDELINES,PARAMETERS,DIAGNOSIS,ACCURACY,TUMORS",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.751,"PROSTATE-CANCER,RADICAL,PROSTATECTOMY,MULTIPARAMETRIC,MRI,FEATURES,CLASSIFICATION,GUIDELINES,PARAMETERS,DIAGNOSIS,ACCURACY,TUMORS",ACADEMIC RADIOLOGY,,
85,Detection of interferences in an additive manufacturing process: an experimental study integrating methods of feature selection and machine learning,58,9,2862-2884,"Stanisavljevic Darko,Cemernek David,Gursch Heimo,Urak Guenter,Lechner Gernot","Stanisavljevic D,Cemernek D,Gursch H,Urak G,Lechner G",Stanisavljevic D,10.1080/00207543.2019.1694719,"Virtual Vehicle Res Ctr, Graz, Austria.","Additive manufacturing becomes a more and more important technology for production, mainly driven by the ability to realise extremely complex structures using multiple materials but without assembly or excessive waste. Nevertheless, like any high-precision technology additive manufacturing responds to interferences during the manufacturing process. These interferences - like vibrations - might lead to deviations in product quality, becoming manifest for instance in a reduced lifetime of a product or application issues. This study targets the issue of detecting such interferences during a manufacturing process in an exemplary experimental setup. Collection of data using current sensor technology directly on a 3D-printer enables a quantitative detection of interferences. The evaluation provides insights into the effectiveness of the realised application-oriented setup, the effort required for equipping a manufacturing system with sensors, and the effort for acquisition and processing the data. These insights are of practical utility for organisations dealing with additive manufacturing: the chosen approach for detecting interferences shows promising results, reaching interference detection rates of up to 100% depending on the applied data processing configuration.","additive manufacturing,machine learning,3D-printer,interference detection,data processing system,feature engineering",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Engineering,Operations Research & Management Science",,6.715,"MONITORING-SYSTEM,SENSOR,FUSION,CHALLENGES",INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH,,
86,Brain age prediction using deep learning uncovers associated sequence variants,10,,,"Jonsson B. A.,Bjornsdottir G.,Thorgeirsson T. E.,Ellingsen L. M.,Walters G. Bragi,Gudbjartsson D. F.,Stefansson H.,Stefansson K.,Ulfarsson M. O.","Jonsson BA,Bjornsdottir G,Thorgeirsson TE,Ellingsen LM,Walters GB,Gudbjartsson DF,Stefansson H,Stefansson K,Ulfarsson MO",Stefansson K; Ulfarsson MO,10.1038/s41467-019-13163-9,"Amgen Inc, DeCODE Genet, IS-101 Reykjavik, Iceland.","Machine learning algorithms can be trained to estimate age from brain structural MRI. The difference between an individual's predicted and chronological age, predicted age difference (PAD), is a phenotype of relevance to aging and brain disease. Here, we present a new deep learning approach to predict brain age from a T1-weighted MRI. The method was trained on a dataset of healthy Icelanders and tested on two datasets, IXI and UK Biobank, utilizing transfer learning to improve accuracy on new sites. A genome-wide association study (GWAS) of PAD in the UK Biobank data (discovery set: N = 12378, replication set: N = 4456) yielded two sequence variants, rs1452628-T (beta = -0.08, P = 1.15 x 10(-9)) and rs2435204-G (beta = 0.102, P = 9.73 x 10(-12)). The former is near KCNK2 and correlates with reduced sulcal width, whereas the latter correlates with reduced white matter surface area and tags a well-known inversion at 17q21.31 (H2).","GENOME-WIDE ASSOCIATION,ACCELERATED BRAIN,PARKINSONS-DISEASE,COMMON INVERSION,SELECTION,REGRESSION,THICKNESS,TREK-1,SCHIZOPHRENIA,MORPHOMETRY",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,15.805,"GENOME-WIDE,ASSOCIATION,ACCELERATED,BRAIN,PARKINSONS-DISEASE,COMMON,INVERSION,SELECTION,REGRESSION,THICKNESS,TREK-1,SCHIZOPHRENIA,MORPHOMETRY",NATURE COMMUNICATIONS,https://europepmc.org/articles/pmc6881321?pdf=render,
87,Lie detection using extreme learning machine: A concealed information test based on short-time Fourier transform and binary bat optimization using a novel fitness function,36,2,637-658,"Dodia Shubham,Edla Damodar R.,Bablani Annushree,Cheruku Ramalingaswamy","Dodia S,Edla DR,Bablani A,Cheruku R",Edla DR,10.1111/coin.12256,National Institute of Technology (NIT System),"Lie detection is one of the major challenges that is being faced by the forensic sciences. Identification of lie on the basis of a person's mental behavior is a tedious task. Brain-computer interface is one such medium which provides a solution to this problem by displaying visual stimuli and recording subject's brain responses. A P300 response is elicited whenever a person comes across a familiar stimuli in a series of rare stimuli. This P300 response is used for the lie detection method. In the proposed concealed information test, acquired signals are preprocessed to discard noise. Then, short-time Fourier transform method is applied to extract features from the preprocessed electroencephalogram signals. To avoid the curse of dimensionality and to reduce computational overhead, binary bat algorithm is applied, which helps in choosing optimal subset of features. The obtained set of features is given as an input to the extreme learning machine classifier for training of guilty and innocent samples. The performance of the system is assessed using 10-fold cross-validation. The resultant accuracy obtained from the proposed lie detection system is 88.3%. The system has provided efficient results in contrast with most of the state-of-the-art lie detection methods.","binary bat,brain-computer interface,concealed information test,electroencephalogram,extreme learning machine,short-time Fourier transform",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Computer Science,,2.016,"FEATURE-EXTRACTION,CLASSIFICATION,NETWORKS",COMPUTATIONAL INTELLIGENCE,,
88,"Understanding X-ray Spectroscopy of Carbonaceous Materials by Combining Experiments, Density Functional Theory, and Machine Learning. Part I: Fingerprint Spectra",31,22,9243-9255,"Aarva Anja,Deringer Volker L.,Sainio Sami,Laurila Tomi,Caro Miguel A.","Aarva A,Deringer VL,Sainio S,Laurila T,Caro MA",Aarva A,10.1021/acs.chemmater.9b02049,Aalto University,"Carbonaceous materials, especially tetrahedral amorphous carbon (ta-C), can form complex functionalized surface structures and are thus promising candidates for applications in biomedical devices and electrochemistry. Functional groups at ta-C surfaces have been widely studied by spectroscopic techniques; however, interpretation of the experimental data is extremely difficult, especially in the case of X-ray photoelectron spectroscopy (XPS) and X-ray absorption spectroscopy (XAS). The assignments of experimental XPS and XAS signals are normally based on references obtained from molecular or crystalline samples, which are simplified approximations for the far more complex amorphous structures. Here, we use extensive density functional theory (DFT) simulations to predict XAS and XPS signatures for carbon-based materials in more realistic environments, building on large data sets of structural models generated by a machine-learning (ML) interatomic potential. The results indicate clear signatures: individual fingerprint XAS spectra and distinctive XPS binding energy distributions, both in terms of center and broadness of the signal, for chemically different groups. The results point out what kind of structural information can and cannot be extracted with X-ray spectroscopy. This study will enable a deeper physicochemical understanding of experimental data and ultimately theory-based identification and quantification of functional groups in carbonaceous materials.","C-1S CORE EXCITON,AMORPHOUS-CARBON,TA-C,PHOTOELECTRON-SPECTROSCOPY,ELECTROCHEMICAL DETECTION,ABSORPTION SPECTROSCOPY,ELECTRONIC-STRUCTURE,BINDING-ENERGIES,SURFACES,DIAMOND",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Materials Science",,10.837,"C-1S,CORE,EXCITON,AMORPHOUS-CARBON,TA-C,PHOTOELECTRON-SPECTROSCOPY,ELECTROCHEMICAL,DETECTION,ABSORPTION,SPECTROSCOPY,ELECTRONIC-STRUCTURE,BINDING-ENERGIES,SURFACES,DIAMOND",CHEMISTRY OF MATERIALS,https://pubs.acs.org/doi/pdf/10.1021/acs.chemmater.9b02049,
89,"Understanding X-ray Spectroscopy of Carbonaceous Materials by Combining Experiments, Density Functional Theory, and Machine Learning. Part II: Quantitative Fitting of Spectra",31,22,9256-9267,"Aarva Anja,Deringer Volker L.,Sainio Sami,Laurila Tomi,Caro Miguel A.","Aarva A,Deringer VL,Sainio S,Laurila T,Caro MA",Aarva A,10.1021/acs.chemmater.9b02050,Aalto University,"Carbon-based nanomaterials are a promising platform for diverse technologies, but their rational design requires a more detailed chemical control over their structure and properties than is currently available. A long-standing challenge for the field has been in the interpretation and use of experimental X-ray spectra, especially for the amorphous and disordered forms of carbon. Here, we outline a unified approach to simultaneously and quantitatively analyze experimental X-ray absorption spectroscopy (XAS) and X-ray photoelectron spectroscopy (XPS) spectra of carbonaceous materials. We employ unsupervised machine learning to identify the most representative chemical environments and deconvolute experimental data according to these spectral contributions. To fit experimental spectra we rely on ab initio references and use all the information available: to fit experimental XAS spectra, the whole XAS fingerprint (reference) spectra of certain sites are taken into account, rather than just peak positions, as is currently the standard procedure. We argue that, even for predominantly pure-carbon materials, carbon Kedge and oxygen K-edge spectra should not be interpreted separately, since the presence of even small amounts of functional groups at the surface manifests itself on the X-ray spectroscopic signatures of both elements in an interlinked manner. Finally, we introduce the idea of carrying out simultaneous fits of XAS and XPS spectra, to reduce the number of degrees of freedom and arbitrariness of the fits. This work opens up a new direction, tightly integrating experiment and simulation, for understanding and ultimately controlling the functionalization of carbon nanomaterials at the atomic level.","AMORPHOUS-CARBON,ELECTRONIC-STRUCTURE,BINDING-ENERGIES,GAS-PHASE,SURFACES,OXYGEN,XPS,MOLECULES",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Materials Science",,10.837,"AMORPHOUS-CARBON,ELECTRONIC-STRUCTURE,BINDING-ENERGIES,GAS-PHASE,SURFACES,OXYGEN,XPS,MOLECULES",CHEMISTRY OF MATERIALS,https://pubs.acs.org/doi/pdf/10.1021/acs.chemmater.9b02050,
90,Inverse-QSPR for de novo Design: A Review,39,4,,"Gantzer Philippe,Creton Benoit,Nieto-Draghi Carlos","Gantzer P,Creton B,Nieto-Draghi C",Creton B,10.1002/minf.201900087,IFP Energies Nouvelles,"The use of computer tools to solve chemistry-related problems has given rise to a large and increasing number of publications these last decades. This new field of science is now well recognized and labelled Chemoinformatics. Among all chemoinformatics techniques, the use of statistical based approaches for property predictions has been the subject of numerous research reflecting both new developments and many cases of applications. The so obtained predictive models relating a property to molecular features - descriptors - are gathered under the acronym QSPR, for Quantitative Structure Property Relationships. Apart from the obvious use of such models to predict property values for new compounds, their use to virtually synthesize new molecules - de novo design - is currently a high-interest subject. Inverse-QSPR (i-QSPR) methods have hence been developed to accelerate the discovery of new materials that meet a set of specifications. In the proposed manuscript, we review existing i-QSPR methodologies published in the open literature in a way to highlight developments, applications, improvements and limitations of each.","structure-property relationships,chemoinformatics,inverse QSPR,molecular generation,de novo design",Review,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Pharmacology & Pharmacy,Computer Science,Mathematical & Computational Biology",,2.723,"SIGNATURE,MOLECULAR,DESCRIPTOR,COMBINATORIAL,LIBRARY,DESIGN,ACTIVITY-RELATIONSHIP,MODELS,ARTIFICIAL,NEURAL-NETWORKS,TOPOLOGICAL,INDEXES,CHEMICAL-STRUCTURE,GENETIC,ALGORITHM,INFORMATION-TRANSFER,STRUCTURE,GENERATION,RATIONAL,DESIGN",MOLECULAR INFORMATICS,,
91,Association between periodontal inflammation and hypertension using periodontal inflamed surface area and bleeding on probing,47,2,160-172,"Pietropaoli Davide,Del Pinto Rita,Ferri Claudio,Marzo Giuseppe,Giannoni Mario,Ortu Eleonora,Monaco Annalisa","Pietropaoli D,Del Pinto R,Ferri C,Marzo G,Giannoni M,Ortu E,Monaco A",Pietropaoli D,10.1111/jcpe.13216,University of L'Aquila,"Aim Periodontitis is a relapsing-remitting disease. Compared with bleeding on probing (BoP), expression of disease activity, periodontal inflamed surface area (PISA), incorporates chronic disease parameters. We tested the association of PISA and BoP with blood pressure (BP) in NHANES III. Materials and methods A total of 8,614 subjects (>= 30 years) with complete periodontal and BP examinations were enrolled. PISA was derived from periodontal probing depth and BoP. The association of PISA and BoP with high/uncontrolled BP was examined by multiple-adjusted models. Inflammatory markers were tested as possible mediators. A machine learning (ML) approach was used to define the relative importance of PISA and BoP and estimate the power of BP status prediction. Results Compared to no inflammation, severe PISA and BoP were associated with 43% (p < .001) and 32% (p = .006) higher odds of high/uncontrolled BP (>= 130/80 mmHg), and with higher systolic BP by approximate to 4 (p < .001) and 5 (p < .001) mmHg, respectively. Inflammatory markers appeared to mediate this association with various extents, without threshold effect. BoP predicted high/uncontrolled BP more efficiently than PISA using ML. Conclusion PISA and BoP describe the association of periodontal inflammation and hypertension with subtle differences. The contribution of local inflammation to the global inflammatory burden might explain the observed findings.","hypertension,inflammation,oral health,periodontal diseases,periodontitis",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Dentistry, Oral Surgery & Medicine",,,"BLOOD-PRESSURE,NATIONAL-HEALTH,DISEASE,WEIGHTS,ADULTS",JOURNAL OF CLINICAL PERIODONTOLOGY,,
92,Deep Learning for Deep Chemistry: Optimizing the Prediction of Chemical Patterns,7,,,"Cova Tania F. G. G.,Pais Alberto A. C. C.","Cova TFGG,Pais AACC",Cova TFGG; Pais AACC,10.3389/fchem.2019.00809,Universidade de Coimbra,"Computational Chemistry is currently a synergistic assembly between ab initio calculations, simulation, machine learning (ML) and optimization strategies for describing, solving and predicting chemical data and related phenomena. These include accelerated literature searches, analysis and prediction of physical and quantum chemical properties, transition states, chemical structures, chemical reactions, and also new catalysts and drug candidates. The generalization of scalability to larger chemical problems, rather than specialization, is now the main principle for transforming chemical tasks in multiple fronts, for which systematic and cost-effective solutions have benefited from ML approaches, including those based on deep learning (e.g. quantum chemistry, molecular screening, synthetic route design, catalysis, drug discovery). The latter class of ML algorithms is capable of combining raw input into layers of intermediate features, enabling bench-to-bytes designs with the potential to transform several chemical domains. In this review, the most exciting developments concerning the use of ML in a range of different chemical scenarios are described. A range of different chemical problems and respective rationalization, that have hitherto been inaccessible due to the lack of suitable analysis tools, is thus detailed, evidencing the breadth of potential applications of these emerging multidimensional approaches. Focus is given to the models, algorithms and methods proposed to facilitate research on compound design and synthesis, materials design, prediction of binding, molecular activity, and soft matter behavior. The information produced by pairing Chemistry and ML, through data-driven analyses, neural network predictions and monitoring of chemical systems, allows (i) prompting the ability to understand the complexity of chemical data, (ii) streamlining and designing experiments, (ii) discovering new molecular targets and materials, and also (iv) planning or rethinking forthcoming chemical challenges. In fact, optimization engulfs all these tasks directly.","machine-learning,deep-learning,optimization,models,molecular simulation,chemistry",Review,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Chemistry,,5.385,"NEURAL-NETWORKS,MOLECULAR-DYNAMICS,QUANTUM-MECHANICS,GENERATIVE,MODELS,BIG,DATA,MACHINE,COMPUTER,DESIGN,OPTIMIZATION,DISCOVERY",FRONTIERS IN CHEMISTRY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6988795,
93,Building an Otoscopic screening prototype tool using deep learning,48,1,,"Livingstone Devon,Talai Aron S.,Chau Justin,Forkert Nils D.","Livingstone D,Talai AS,Chau J,Forkert ND",Livingstone D,10.1186/s40463-019-0389-9,University of Calgary,"Background Otologic diseases are often difficult to diagnose accurately for primary care providers. Deep learning methods have been applied with great success in many areas of medicine, often outperforming well trained human observers. The aim of this work was to develop and evaluate an automatic software prototype to identify otologic abnormalities using a deep convolutional neural network. Material and methods A database of 734 unique otoscopic images of various ear pathologies, including 63 cerumen impactions, 120 tympanostomy tubes, and 346 normal tympanic membranes were acquired. 80% of the images were used for the training of a convolutional neural network and the remaining 20% were used for algorithm validation. Image augmentation was employed on the training dataset to increase the number of training images. The general network architecture consisted of three convolutional layers plus batch normalization and dropout layers to avoid over fitting. Results The validation based on 45 datasets not used for model training revealed that the proposed deep convolutional neural network is capable of identifying and differentiating between normal tympanic membranes, tympanostomy tubes, and cerumen impactions with an overall accuracy of 84.4%. Conclusion Our study shows that deep convolutional neural networks hold immense potential as a diagnostic adjunct for otologic disease management.","Neural network,Machine learning,Automated,Otoscopy,Deep learning,Artificial intelligence",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Otorhinolaryngology,,2.927,"OTITIS-MEDIA,DIAGNOSIS,ACCURACY",JOURNAL OF OTOLARYNGOLOGY-HEAD & NECK SURGERY,https://journalotohns.biomedcentral.com/track/pdf/10.1186/s40463-019-0389-9,
94,Cross-Validation of Functional MRI and Paranoid-Depressive Scale: Results From Multivariate Analysis,10,,,"Stoyanov Drozdstoy,Kandilarova Sevdalina,Paunova Rositsa,Garcia Javier Barranco,Latypova Adeliya,Kherif Ferath","Stoyanov D,Kandilarova S,Paunova R,Garcia JB,Latypova A,Kherif F",Stoyanov D,10.3389/fpsyt.2019.00869,Medical University Plovdiv,"Introduction: There exists over the past decades a constant debate driven by controversies in the validity of psychiatric diagnosis. This debate is grounded in queries about both the validity and evidence strength of clinical measures. Materials and Methods: The objective of the study is to construct a bottom-up unsupervised machine learning approach, where the brain signatures identified by three principal components based on activations yielded from the three kinds of diagnostically relevant stimuli are used in order to produce cross-validation markers which may effectively predict the variance on the level of clinical populations and eventually delineate diagnostic and classification groups. The stimuli represent items from a paranoid-depressive self-evaluation scale, administered simultaneously with functional magnetic resonance imaging (fMRI). Results: We have been able to separate the two investigated clinical entities - schizophrenia and recurrent depression by use of multivariate linear model and principal component analysis. Following the individual and group MLM, we identified the three brain patterns that summarized all the individual variabilities of the individual brain patterns. Discussion: This is a confirmation of the possibility to achieve bottom-up classification of mental disorders, by use of the brain signatures relevant to clinical evaluation tests.","validation,psychopathology,machine learning,functional MRI,classification",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Psychiatry,,,"SCHIZOPHRENIA,CLASSIFICATION,METAANALYSIS,DIAGNOSIS,DISORDER,PANSS",FRONTIERS IN PSYCHIATRY,https://europepmc.org/articles/pmc6886009?pdf=render,
95,Application of micro near infrared spectrometer in measuring sugar content of apple,43,6,735-740,",,,","Xu Yonghao,Song Biao,Chen Xiaofan,Huang Meizhen",,,Xu Yonghao,"In order to evaluate the feasibility of miniature near infrared spectroscopy (NIRS) in detecting sugar content of fruits in situ, non-destructive, high-precision and fast detection method of apple sugar content was established by combining particle swarm optimization with back propagation (BP) neural network. The spectral data obtained by NIRscan(micro-NIRS) using single wavelength measurement mode and Hadamard transform measurement mode were studied. A variety of different data preprocessing methods and multiple linear regression, partial least squares, particle swarm optimization (PSO), BP neural network and other algorithms were used to establish the analysis model. The results show that the spectral data obtained by the working mode of Hadamard transform are better. First derivative combined with Savizky-Golay smoothing algorithm is used for data preprocessing. The prediction model of apple sugar content based on PSO and BP neural network has higher prediction accuracy. Predictive correlation coefficient and root mean square error are 0.9911 and 0.1502, respectively. NIRscan (micro-NIRS) is feasible for rapid and high-precision non-destructive testing of apple sugar content in the field.",spectroscopy; apple sugar content; near infrared spectroscopy; digital micro-mirror device; miniature near infrared spectrometer; Hadamard transform; particle swarm optimization; back propagation neural network,Article,,,,,,,,
96,Improved Transductive Support Vector Machine for a Small Labelled Set in Motor Imagery-Based Brain-Computer Interface,2019,,,"Xu Yilu,Hua Jing,Zhang Hua,Hu Ronghua,Huang Xin,Liu Jizhong,Guo Fumin","Xu YL,Hua J,Zhang H,Hu RH,Huang X,Liu JZ,Guo FM",Zhang H; Hu RH,10.1155/2019/2087132,Nanchang University,"Long and tedious calibration time hinders the development of motor imagery- (MI-) based brain-computer interface (BCI). To tackle this problem, we use a limited labelled set and a relatively large unlabelled set from the same subject for training based on the transductive support vector machine (TSVM) framework. We first introduce an improved TSVM (ITSVM) method, in which a comprehensive feature of each sample consists of its common spatial patterns (CSP) feature and its geometric feature. Moreover, we use the concave-convex procedure (CCCP) to solve the optimization problem of TSVM under a new balancing constraint that can address the unknown distribution of the unlabelled set by considering various possible distributions. In addition, we propose an improved self-training TSVM (IST-TSVM) method that can iteratively perform CSP feature extraction and ITSVM classification using an expanded labelled set. Extensive experimental results on dataset IV-a from BCI competition III and dataset II-a from BCI competition IV show that our algorithms outperform the other competing algorithms, where the sizes and distributions of the labelled sets are variable. In particular, IST-TSVM provides average accuracies of 63.25% and 69.43% with the abovementioned two datasets, respectively, where only four positive labelled samples and sixteen negative labelled samples are used. Therefore, our algorithms can provide an alternative way to reduce the calibration time.","SEMI-SUPERVISED CLASSIFICATION,TRAINING ALGORITHM,EEG,SVM",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Mathematical & Computational Biology,Neurosciences & Neurology",,3.278,"SEMI-SUPERVISED,CLASSIFICATION,TRAINING,ALGORITHM,EEG,SVM",COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE,https://downloads.hindawi.com/journals/cin/2019/2087132.pdf,
97,3D-Printing and Machine Learning Control of Soft Ionic Polymer-Metal Composite Actuators,9,,,"Carrico James D.,Hermans Tucker,Kim Kwang J.,Leang Kam K.","Carrico JD,Hermans T,Kim KJ,Leang KK",Leang KK,10.1038/s41598-019-53570-y,Utah System of Higher Education,"This paper presents a new manufacturing and control paradigm for developing soft ionic polymer-metal composite (IPMC) actuators for soft robotics applications. First, an additive manufacturing method that exploits the fused-filament (3D printing) process is described to overcome challenges with existing methods of creating custom-shaped IPMC actuators. By working with ionomeric precursor material, the 3D-printing process enables the creation of 3D monolithic IPMC devices where ultimately integrated sensors and actuators can be achieved. Second, Bayesian optimization is used as a learning-based control approach to help mitigate complex time-varying dynamic effects in 3D-printed actuators. This approach overcomes the challenges with existing methods where complex models or continuous sensor feedback are needed. The manufacturing and control paradigm is applied to create and control the behavior of example actuators, and subsequently the actuator components are combined to create an example modular reconfigurable IPMC soft crawling robot to demonstrate feasibility. Two hypotheses related to the effectiveness of the machine-learning process are tested. Results show enhancement of actuator performance through machine learning, and the proof-of-concepts can be leveraged for continued advancement of more complex IPMC devices. Emerging challenges are also highlighted.","BAYESIAN OPTIMIZATION,INTEGRATED DESIGN,IPMC ACTUATOR,FABRICATION,MICROPUMP,SENSORS,ROBUST,ROBOT,FLOW",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,5.134,"BAYESIAN,OPTIMIZATION,INTEGRATED,DESIGN,IPMC,ACTUATOR,FABRICATION,MICROPUMP,SENSORS,ROBUST,ROBOT,FLOW",SCIENTIFIC REPORTS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6877587,
98,A network-based response feature matrix as a brain injury metric,19,3,927-942,"Wu Shaoju,Zhao Wei,Rowson Bethany,Rowson Steven,Ji Songbai","Wu SJ,Zhao W,Rowson B,Rowson S,Ji SB",Ji SB,10.1007/s10237-019-01261-y,Worcester Polytechnic Institute,"Conventional brain injury metrics are scalars that treat the whole head/brain as a single unit but do not characterize the distribution of brain responses. Here, we establish a network-based ""response feature matrix"" to characterize the magnitude and distribution of impact-induced brain strains. The network nodes and edges encode injury risks to the gray matter regions and their white matter interconnections, respectively. The utility of the metric is illustrated in injury prediction using three independent, real-world datasets: two reconstructed impact datasets from the National Football League (NFL) and Virginia Tech, respectively, and measured concussive and non-injury impacts from Stanford University. Injury predictions with leave-one-out cross-validation are conducted using the two reconstructed datasets separately, and then by combining all datasets into one. Using support vector machine, the network-based injury predictor consistently outperforms four baseline scalar metrics including peak maximum principal strain of the whole brain (MPS), peak linear/rotational acceleration, and peak rotational velocity across all five selected performance measures (e.g., maximized accuracy of 0.887 vs. 0.774 and 0.849 for MPS and rotational acceleration with corresponding positive predictive values of 0.938, 0.772, and 0.800, respectively, using the reconstructed NFL dataset). With sufficient training data, real-world injury prediction is similar to leave-one-out in-sample evaluation, suggesting the potential advantage of the network-based injury metric over conventional scalar metrics. The network-based response feature matrix significantly extends scalar metrics by sampling the brain strains more completely, which may serve as a useful framework potentially allowing for other applications such as characterizing injury patterns or facilitating targeted multi-scale modeling in the future.","Concussion,Brain structural network,Traumatic brain injury,Support vector machine,Worcester head injury model",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Biophysics,Engineering",,3.257,"FINITE-ELEMENT,MODELS,HEAD,KINEMATICS,AXONAL,STRAIN,FOOTBALL,CONCUSSION,PREDICTION,CONSTRUCTION,VALIDATION,IMPACTS,SYSTEM",BIOMECHANICS AND MODELING IN MECHANOBIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7210066,
99,The exploration of feature extraction and machine learning for predicting bone density from simple spine X-ray images in a Korean population,49,4,613-618,"Lee Sangwoo,Choe Eun Kyung,Ka Hae Yeon,Yoon Ji Won,Kim Hua Sun","Lee S,Choe EK,Ka HY,Yoon JW,Kim HS",Choe EK,10.1007/s00256-019-03342-6,Seoul National University (SNU),"Objective Osteoporosis is hard to detect before it manifests symptoms and complications. In this study, we evaluated machine learning models for identifying individuals with abnormal bone mineral density (BMD) through an analysis of spine X-ray features extracted by deep learning to alert high-risk osteoporosis populations. Materials and methods We retrospectively used data obtained from health check-ups including spine X-ray and dual-energy X-ray absorptiometry (DXA). Consecutively, we selected people with normal and abnormal bone mineral density. From the regions of interest of X-ray images, deep convolutional networks were used to generate image features. We designed prediction models for abnormal BMD using the image features trained by machine learning classification algorithms. The performances of each model were evaluated. Results From 334 participants, 170 images of abnormal (T scores < - 1.0 standard deviations (SD)) and 164 of normal BMD (T scores > = - 1.0 SD) were used for analysis. We found that a combination of feature extraction by VGGnet and classification by random forest based on the maximum balanced classification rate (BCR) yielded the best performance in terms of the area under the curve (AUC) (0.74), accuracy (0.71), sensitivity (0.81), specificity (0.60), BCR (0.70), and F1-score (0.73). Conclusion In this study, we explored various machine learning algorithms for the prediction of BMD using simple spine X-ray image features extracted by three deep learning algorithms. We identified the combination for the best performance in predicting high-risk populations with abnormal BMD.","Artificial intelligence,Convolutional neural network,Machine learning,Osteoporosis",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Orthopedics,Radiology, Nuclear Medicine & Medical Imaging",,2.046,"NATIONAL-HEALTH,FRACTURE,RISK,OSTEOPOROSIS,DIAGNOSIS,BURDEN,WOMEN",SKELETAL RADIOLOGY,,
100,Efficient characterization tools for deformation-induced damage at different scales,14,1,95-104,"Kusche Carl F.,Dunlap Anthony,Puetz Felix,Tian Chunhua,Kirchlechner Christoph,Aretz Anke,Schwedt Alexander,Al-Samman Talal,Muenstermann Sebastian,Korte-Kerzel Sandra","Kusche CF,Dunlap A,Putz F,Tian CH,Kirchlechner C,Aretz A,Schwedt A,Al-Samman T,Munstermann S,Korte-Kerzel S",Kusche CF,10.1007/s11740-019-00936-w,RWTH Aachen University,"In modern multiphase materials, damage initiation and growth during plastic deformation is a commonly observed and technologically relevant process. To reliably assess the state of damage in a specimen or, ultimately, a formed product, precise and comparable damage quantification is required. Furthermore, the key to understanding the initiation and evolution of voids in such materials is the characterization of the initiating microstructural mechanisms in a statistically relevant way over a large number of damage sites. In this work, we present the results of large-scale scanning electron microscopy methods for automated damage recognition and analytical characterization, together with a concept for joining the available void size statistics to micromechanical experiments such as micro-cantilever tests. These tests are able to determine a critical crack length for various types of void initiation processes, leading to an improved understanding of the consequences of ductile damage evolution and void growth, and their subsequent interaction leading to material failure. In this way, a framework for quantification and high-resolution characterization of damage mechanisms is constructed, enabling new insights on damage evolution in forming processes.","Damage,Electron microscopy,Machine learning,Characterization,Void recognition",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Engineering,,,"DUAL-PHASE,STEELS,FRACTURE-TOUGHNESS,MECHANICAL-PROPERTIES,MICROSCALE,FRACTURE,NANOINDENTATION,BEHAVIOR,SINGLE,MICROCOMPRESSION,PLASTICITY,INITIATION",PRODUCTION ENGINEERING-RESEARCH AND DEVELOPMENT,,
