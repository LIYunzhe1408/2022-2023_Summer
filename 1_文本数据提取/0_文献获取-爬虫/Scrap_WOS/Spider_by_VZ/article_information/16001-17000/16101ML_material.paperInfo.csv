,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,PhaseNet 2.0: Phase Unwrapping of Noisy Data Based on Deep Learning Approach,29,,4862-4872,"Spoorthi G. E.,Gorthi Rama Krishna Sai Subrahmanyam,Gorthi Subrahmanyam","Spoorthi GE,Gorthi RKSS,Gorthi S",Gorthi RKSS,10.1109/TIP.2020.2977213,Indian Institute of Technology System (IIT System),"Phase unwrapping is an ill-posed classical problem in many practical applications of significance such as 3D profiling through fringe projection, synthetic aperture radar and magnetic resonance imaging. Conventional phase unwrapping techniques estimate the phase either by integrating through the confined path (referred to as path-following methods) or by minimizing the energy function between the wrapped phase and the approximated true phase (referred to as minimum-norm approaches). However, these conventional methods have some critical challenges like error accumulation and high computational time and often fail under low SNR conditions. To address these problems, this paper proposes a novel deep learning framework for unwrapping the phase and is referred to as ""PhaseNet 2.0"". The phase unwrapping problem is formulated as a dense classification problem and a fully convolutional DenseNet based neural network is trained to predict the wrap-count at each pixel from the wrapped phase maps. To train this network, we simulate arbitrary shapes and propose new loss function that integrates the residues by minimizing the difference of gradients and also uses loss to overcome class imbalance problem. The proposed method, unlike our previous approach PhaseNet, does not require post-processing, highly robust to noise, accurately unwraps the phase even at the severe noise level of -5 dB, and can unwrap the phase maps even at relatively high dynamic ranges. Simulation results from the proposed framework are compared with different classes of existing phase unwrapping methods for varying SNR values and discontinuity, and these evaluations demonstrate the advantages of the proposed framework. We also demonstrate the generality of the proposed method on 3D reconstruction of synthetic CAD models that have diverse structures and finer geometric variations. Finally, the proposed method is applied to real-data for 3D profiling of objects using fringe projection technique and digital holographic interferometry. The proposed framework achieves significant improvements over existing methods while being highly efficient with interactive frame-rates on modern GPUs.","Phase unwrapping,semantic segmentation,deep learning,deep convolutional neural network (DCNN),fringe projection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,"FRINGE,PROJECTION,PROFILOMETRY,FOURIER-TRANSFORM,ALGORITHM,NETWORK",IEEE TRANSACTIONS ON IMAGE PROCESSING,,
2,Understanding and Predicting the Memorability of Outdoor Natural Scenes,29,,4927-4941,"Lu Jiaxin,Xu Mai,Yang Ren,Wang Zulin","Lu JX,Xu M,Yang R,Wang ZL",Xu M,10.1109/TIP.2020.2975957,Beihang University,"Memorability measures how easily an image is to be memorized after glancing, which may contribute to designing magazine covers, tourism publicity materials, and so forth. Recent works have shed light on the visual features that make generic images, object images or face photographs memorable. However, these methods are not able to effectively predict the memorability of outdoor natural scene images. To overcome this shortcoming of previous works, in this paper, we provide an attempt to answer: ""what exactly makes outdoor natural scenes memorable"". To this end, we first establish a large-scale outdoor natural scene image memorability (LNSIM) database, containing 2,632 outdoor natural scene images with their ground truth memorability scores and the multi-label scene category annotations. Then, similar to previous works, we mine our database to investigate how low-, middle- and high-level handcrafted features affect the memorability of outdoor natural scenes. In particular, we find that the high-level feature of scene category is rather correlated with outdoor natural scene memorability, and the deep features learnt by deep neural network (DNN) are also effective in predicting the memorability scores. Moreover, combining the deep features with the category feature can further boost the performance of memorability prediction. Therefore, we propose an end-to-end DNN based outdoor natural scene memorability (DeepNSM) predictor, which takes advantage of the learned category-related features. Then, the experimental results validate the effectiveness of our DeepNSM model, exceeding the state-of-the-art methods. Finally, we try to understand the reason of the good performance for our DeepNSM model, and also study the cases that our DeepNSM model succeeds or fails to accurately predict the memorability of outdoor natural scenes.","Databases,Predictive models,Visualization,Analytical models,Face,Feature extraction,Correlation,Memorability,outdoor natural scenes,computer vision",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,IMAGE,IEEE TRANSACTIONS ON IMAGE PROCESSING,http://arxiv.org/pdf/1810.06679,
3,An Artificial Neural Network Approach for Generating High Resolution Designs From Low Resolution Input in Topology Optimization,142,1,,"Napier Nicholas,Sriraman Sai-Aksharah,Tran Huy T.,James Kai A.","Napier N,Sriraman SA,Tran HT,James KA",Napier N,10.1115/1.4044332,University of Illinois System,"We address a central issue that arises within element-based topology optimization. To achieve a sufficiently well-defined material interface, one requires a highly refined finite element mesh; however, this leads to an increased computational cost due to the solution of the finite element analysis problem. By generating an optimal structure on a coarse mesh and using an artificial neural network to map this coarse solution to a refined mesh, we can greatly reduce computational time. This approach resulted in time savings of up to 85% for test cases considered. This significant advantage in computational time also preserves the structural integrity when compared with a fine -mesh optimization with limited error. Along with the savings in computational time, the boundary edges become more refined during the process, allowing for a sharp transition from solid to void. This improved boundary edge can be leveraged to improve the manufacturability of the optimized designs.","design for manufacturing,design visualization,topology optimization,artificial neural networks,machine learning",Article,"ASME, TWO PARK AVE, NEW YORK, NY 10016-5990 USA",Engineering,,,,JOURNAL OF MECHANICAL DESIGN,,
4,DA-Capnet: Dual Attention Deep Learning Based on U-Net for Nailfold Capillary Segmentation,8,,10543-10553,"Hariyani Yuli Sun,Eom Heesang,Park Cheolsoo","Hariyani YS,Eom H,Park C",Park C,10.1109/ACCESS.2020.2965651,Kwangwoon University,"Automatic nailfold capillary segmentation is a challenging task owing to noise and large variabilities in images caused by insufficient focusing and low visibility of the capillaries. This task can be useful to detect and estimate the severity of autoimmune diseases of connective tissues or learning the status of white blood cells based on the cells & x2019; blood flow on the nailfold capillary. Previous studies have addressed this task using manual, semi-automated, and automated segmentation method. However, further improvement is still required. With the recent progress of deep learning on medical imaging, we herein propose dual attention deep learning based on U-Net for nailfold capillary segmentation, named DA-CapNet. Our DA-CapNet improves the U-Net architecture by integrating a dual attention module that can capture a better representation of feature maps from input images. Furthermore, DA-CapNet is compared with three baselines: adaptive Gaussian algorithm, SegNet, the original U-Net. We experimentally demonstrate that our proposed method outperforms these baselines.","Nailfold capillary,segmentation,dual attention,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,DIAGNOSIS,IEEE ACCESS,https://doi.org/10.1109/access.2020.2965651,
5,Transfer Learning-Based DCE-MRI Method for Identifying Differentiation Between Benign and Malignant Breast Tumors,8,,17527-17534,"Zhou Leilei,Zhang Zuoheng,Yin Xindao,Jiang Hong-Bing,Wang Jie,Gui Guan,Chen Yu-Chen,Zheng Jin-Xia","Zhou LL,Zhang ZH,Yin XD,Jiang HB,Wang J,Gui G,Chen YC,Zheng JX",Chen YC,10.1109/ACCESS.2020.2967820,Nanjing Medical University,"In this paper, we propose a transfer learning-based dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) method for classifying fibroadenoma and invasive ductal carcinoma (IDC) in breast tumors. A total of 207 breast tumors from patients were collected and identified by pathologic diagnosis within 15 days after enhanced DCE-MRI examination; 119 patients (average age 50.52 & x00B1;10.33 years) had fibroadenomas, and 88 patients (average age 42.20 & x00B1;10.10 years) had IDCs. Two lesion-level models were built based on the InceptionV3 and VGG19 models, which were pretrained with the ImageNet dataset. The effects of different depths of transfer learning were examined. The network & x2019;s performance was evaluated through five-fold cross validation. In the lesion-level models, the model based on Inception V3 obtained better results (area under the receiver operating characteristic curve (AUC) & x003D; 0.89) when the weights were frozen before layer-276. The other model based on VGG19 obtained better results (AUC & x003D; 0.87) when the weights were frozen before layer-13. Compared with the image-level models, both lesion-level models displayed better discrimination (accuracy increased by 13 & x0025; and 14 & x0025;) based on the VGG19 and Inception V3 models, respectively. Our research confirms that transfer learning can be utilized to classify fibroadenomas and IDCs in DCE-MRI images. Different depths of transfer learning result in different performances, and our proposed lesion-level model notably improves the classification accuracy.","Magnetic resonance imaging,invasive ductal carcinoma,fibroadenoma,transfer learning,lesion classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08966374.pdf,
6,Spatial and Sequential Deep Learning Approach for Predicting Temperature Distribution in a Steel-Making Continuous Casting Process,8,,21953-21965,"Lee Soo Young,Tama Bayu Adhi,Choi Changyun,Hwang Jong-Yeon,Bang Jonggeun,Lee Seungchul","Lee SY,Tama BA,Choi C,Hwang JY,Bang J,Lee S",Lee S,10.1109/ACCESS.2020.2969498,Pohang University of Science & Technology (POSTECH),"Continuous casting is the procedure of the successive casting for solidification of the steel, which contains several cooling processes along the caster to coagulate the molten steel. It is such a rule of thumb that strand surface quality and casting productivity is highly dependent on temperature control. A finite-difference method is one of estimating temperature distribution, yet it hinders the process control efficiently. Song, et al. suggest a multimodal deep learning approach for prediction of the temperature. However, sequential and transient phenomena of solidifying steel are not considered, which makes it difficult to estimate the sequential heat-transfer characteristics in the whole process of the steel concretion. Herein, a deep learning model is proposed to predict the temperature distribution by taking into account both transient and steady-state characteristics. The proposed model addresses both spatial and sequential information by incorporating a convolutional neural network (CNN) and a recurrent neural network (RNN). Our quantitative and qualitative results show considerable predictive performance improvement against baseline models. Furthermore, the proposed model is applicable in a real-world steel-making industry by providing real-time temperature prediction, whilst retaining a lower computational cost.","Continuous casting,recurrent neural networks,convolutional neural networks,deep learning,steel industries,temperature distribution predictions",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"RECURRENT,NEURAL-NETWORK,HEAT-TRANSFER,MODEL,FLOW",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08970351.pdf,
7,Enlarged Training Dataset by Pairwise GANs for Molecular-Based Brain Tumor Classification,8,,22560-22570,"Ge Chenjie,Gu Irene Yu-Hua,Jakola Asgeir Store,Yang Jie","Ge CJ,Gu IYH,Jakola AS,Yang J",Ge CJ,10.1109/ACCESS.2020.2969805,Chalmers University of Technology,"This paper addresses issues of brain tumor subtype classification using Magnetic Resonance Images (MRIs) from different scanner modalities like T1 weighted, T1 weighted with contrast-enhanced, T2 weighted and FLAIR images. Currently most available glioma datasets are relatively moderate in size, and often accompanied with incomplete MRIs in different modalities. To tackle the commonly encountered problems of insufficiently large brain tumor datasets and incomplete modality of image for deep learning, we propose to add augmented brain MR images to enlarge the training dataset by employing a pairwise Generative Adversarial Network (GAN) model. The pairwise GAN is able to generate synthetic MRIs across different modalities. To achieve the patient-level diagnostic result, we propose a post-processing strategy to combine the slice-level glioma subtype classification results by majority voting. A two-stage course-to-fine training strategy is proposed to learn the glioma feature using GAN-augmented MRIs followed by real MRIs. To evaluate the effectiveness of the proposed scheme, experiments have been conducted on a brain tumor dataset for classifying glioma molecular subtypes: isocitrate dehydrogenase 1 (IDH1) mutation and IDH1 wild-type. Our results on the dataset have shown good performance (with test accuracy 88.82%). Comparisons with several state-of-the-art methods are also included.","Molecular-based brain tumor subtype classification,glioma,multi-modal,MRI,data augmentation,generative adversarial networks,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IDH1,MUTATIONS,SURVIVAL,GLIOMAS",IEEE ACCESS,https://research.chalmers.se/publication/516637/file/516637_Fulltext.pdf,
8,Sleep Apnea Severity Estimation From Tracheal Movements Using a Deep Learning Model,8,,22641-22649,"Hafezi Maziar,Montazeri Nasim,Saha Shumit,Zhu Kaiyin,Gavrilovic Bojan,Yadollahi Azadeh,Taati Babak","Hafezi M,Montazeri N,Saha S,Zhu KY,Gavrilovic B,Yadollahi A,Taati B",Yadollahi A; Taati B,10.1109/ACCESS.2020.2969227,University of Toronto,"Objective: Sleep apnea is a chronic respiratory disorder and its standard assessment requires full night in-laboratory polysomnography (PSG). However, PSG is expensive, time-consuming, and inconvenient. Thus, there is a need to monitor sleep apnea with more convenient wearable devices. The objective of this study was to implement deep learning algorithms to monitor sleep apnea severity based on respiratory movements that can be easily recorded over the trachea. Methods: Adult individuals referred to the sleep laboratory at the Toronto Rehabilitation Institute for overnight sleep studies were included (N69). Simultaneously with the PSG, an accelerometer was attached to the participant's suprasternal notch to record tracheal respiratory movements. Twenty-one features were extracted from the tracheal movements and used in a deep learning classifier to detect respiratory events. The apnea hypopnea index (AHI) was estimated as the number of events per hour of sleep. Results: The F1 score of the event-by-event detection algorithm was between 12% and 71% for different groups of sleep apnea severity. There was a strong correlation between the estimated and the PSG-derived AHI r=0.86, p < 0.0001). Using the AHI cut-off of 15, the sensitivity, specificity, and accuracy of diagnosing sleep apnea were 81%, 87%, and 84%, respectively. Conclusion: A combination of advanced machine learning algorithms and respiratory-related movements can accurately estimate sleep apnea severity and detect respiratory events during sleep. Significance: The proposed method can be implemented as a cost-effective and reliable wearable device for monitoring sleep apnea in the home and community.","Accelerometer,apnea hypopnea index,deep learning,physiological features,wearable devices,sleep apnea monitoring",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"AIR-FLOW,CHANNEL,PRACTICE,PARAMETERS,PORTABLE,MONITOR,HOME,DIAGNOSIS,DEVICE,POLYSOMNOGRAPHY,VALIDATION,RISK,BODY",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08968336.pdf,
9,A Light-Weighted CNN Model for Wafer Structural Defect Detection,8,,24006-24018,"Chen Xiaoyan,Chen Jianyong,Han Xiaoguang,Zhao Chundong,Zhang Dongyang,Zhu Kuifeng,Su Yanjie","Chen XY,Chen JY,Han XG,Zhao CD,Zhang DY,Zhu KF,Su YJ",Chen XY,10.1109/ACCESS.2020.2970461,Tianjin University Science & Technology,"Silicon wafer is the raw material of semiconductor chip. It is important and challenging to research a fast and accurate method of identifying and classifying wafer structural defects. To this end, we present a novel detection method in terms of the convolution neural networks (CNN), which achieve more than 99 & x0025; detection accuracy. Due to the wafer images are not available by open datasets, a set of imaging acquisition system is designed to capture wafer images. Digital image preprocessing technology is utilized to split a wafer image into thousands of silicon grain images. The proposed model, called WDD-Net, uses depthwise separable convolutions and global average pooling to reduce parameters and calculations, adopts multiple 1 & x002A;1 standard convolutions to increase the network depth. Specifically, two types of CNN models, VGG-16 and MobileNet-v2, are adopted for comparative analysis. Using the aforementioned three models, the comparative experiments are implemented on data sets that consisting of more than ten thousand grain images. The experimental results show that compared with VGG-16 and MobileNet-v2, the detection speed of the WDD-Net is 105.6FPS, which is 5 times faster. The model size of the WDD-Net is 307KB, which is much smaller than the other two. Furthermore, the WDD-Net directly completes the data collection and defect detection process through the local computing equipment, which is suitable for edge computing.","Image classification,neural networks,semiconductor manufacturing,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NEURAL-NETWORK,PATTERNS,CLASSIFICATION,IDENTIFICATION,ENCODER",IEEE ACCESS,https://doi.org/10.1109/access.2020.2970461,
10,Enhanced Detection of Epileptic Seizure Using EEG Signals in Combination With Machine Learning Classifiers,8,,24046-24055,"Mardini Wail,Yassein Muneer Masadeh Bani,Al-Rawashdeh Rana,Aljawarneh Shadi,Khamayseh Yaser,Meqdadi Omar","Mardini W,Yassein MMB,Al-Rawashdeh R,Aljawarneh S,Khamayseh Y,Meqdadi O",Mardini W,10.1109/ACCESS.2020.2970012,Jordan University of Science & Technology,"Electroencephalogram (EEG) is one of the most powerful tools that offer valuable information related to different abnormalities in the human brain. One of these abnormalities is the epileptic seizure. A framework is proposed for detecting epileptic seizures from EEG signals recorded from normal and epileptic patients. The suggested approach is designed to classify the abnormal signal from the normal one automatically. This work aims to improve the accuracy of epileptic seizure detection and reduce computational costs. To address this, the proposed framework uses the 54-DWT mother wavelets analysis of EEG signals using the Genetic algorithm (GA) in combination with other four machine learning (ML) classifiers: Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Artificial Neural Network (ANN), and Naive Bayes (NB). The performance of 14 different combinations of two-class epilepsy detection is investigated using these four ML classifiers. The experimental results show that the four classifiers produce comparable results for the derived statistical features from the 54-DWT mother wavelets; however, the ANN classifier achieved the best accuracy in most datasets combinations, and it outperformed the other examined classifiers.","Electroencephalogram (EEG),discrete wavelet transform (DWT),epilepsy,artificial neural network,k-nearest neighbor (k-NN),support vector machine (SVM),naive bayes (NB)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FEATURE-EXTRACTION,CLASSIFICATION,IDENTIFICATION,ENTROPY,TRENDS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08972376.pdf,
11,Cluster-Analysis-Based User-Adaptive Fall Detection Using Fusion of Heart Rate Sensor and Accelerometer in a Wearable Device,8,,40389-40401,"Nho Young-Noon,Lim Jong Gwan,Kwon Dong-Soo","Nho YN,Lim JG,Kwon DS",Lim JG,10.1109/ACCESS.2020.2969453,"Mokwon Univ, Dept Intelligent Robot Engn, Daejeon 35349, South Korea.","This paper proposes an automatic fall detector in a wearable device that can reduce risks by detecting falls and promptly alerting caregivers. For this purpose, we propose cluster-analysis-based user-adaptive fall detection using a fusion of heart rate sensor and accelerometer. The objectives of the proposed fall detector are to have high accuracy with a low-complexity model regardless of diverse conditions. To meet the objectives, we propose the best 13-dimensional feature subset by using feature selection. In addition, we verify the performance increment of combining a heart rate sensor with an accelerometer and the effectiveness of the cluster-analysis-based anomaly detection. We also show the effectiveness of the user-adaptive method when using both heart rate and acceleration signals that were hardly covered in other papers. Finally, we prove that the performance of the proposed fall detector achieves is better than that of recent user-adaptive and user-independent approaches. This study is the first attempt to demonstrate the merits of the user-adaptive approach using a combination of heart rate and acceleration signals to detect falls. Moreover, this paper also contributes to fall detection area by providing the data we collected.","Fall detection,anomaly detection,sensor fusion,feature selection,cluster analysis,machine learning,heart rate sensor,accelerometer,Gaussian mixture models,personalization",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SYSTEM,DECELERATION,PREDICTORS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08970371.pdf,
12,Enhanced Skin Condition Prediction Through Machine Learning Using Dynamic Training and Testing Augmentation,8,,40536-40546,"Putra Tryan Aditya,Rufaida Syahidah Izza,Leu Jenq-Shiou","Putra TA,Rufaida SI,Leu JS",Rufaida SI,10.1109/ACCESS.2020.2976045,National Taiwan University of Science & Technology,"In recent years, deep learning has taken the spotlight in automated medical bioimaging. However, the performance of current state-of-the-art score stems primarily from well-tuned parameters and architecture. There is still only limited research focused on dynamic data augmentation, even in the fields of machine learning and computer vision. In this study, we propose a dynamic training and testing augmentation capable of increasing performance significantly. The searching augmentation framework used in this study requires fewer GPU hours than a conventional search algorithm, which needs to train a new model every time augmentation is proposed. Speeding up of the search algorithm is achieved by using Bayesian optimization on a trained model, so we do not have to train a new model every time a new augmentation policy is proposed. The performance of our method is compared with that of a single model and the ensemble model that happens to be the winner of the ISIC 2019 challenge. Furthermore, we use the latest compact yet significantly accurate network architecture EfficientNet as the backbone system. Our method delivers a superior result, and this study also shares the searched augmentation policy utilized, which requires extraordinary resources. Thus, other researchers can use the searched augmentation policies for dermoscopic images to improve performance.","Lesions,Melanoma,Machine learning,Skin,Computer architecture,Machine learning,augmentation,skin cancer,dermoscopic images",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IMAGE,SEGMENTATION,MELANOMA,DERMOSCOPY,DERMATOSCOPY,KERATOSIS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09007729.pdf,
13,Effect of Altered OCT Image Quality on Deep Learning Boundary Segmentation,8,,43537-43553,"Kugelman Jason,Alonso-Caneiro David,Read Scott A.,Vincent Stephen J.,Chen Fred K.,Collins Michael J.","Kugelman J,Alonso-Caneiro D,Read SA,Vincent SJ,Chen FK,Collins MJ",Alonso-Caneiro D,10.1109/ACCESS.2020.2977355,Queensland University of Technology (QUT),"Deep learning methods provide a platform to segment boundaries within the retina and choroid in OCT images of the posterior eye, with the ultimate goal of having a robust model that works well across a wide range of different datasets. However, since most studies of deep learning methods use datasets exhibiting similar image quality for both training and evaluation, the effect of varied image quality on such methods is not normally explored in the context of OCT image segmentation. An understanding of the effects of image quality factors is vital to determine the robustness of the methods and their ability to be applied in clinical practice where images exhibiting a range of different qualities are encountered. This study examined a range of factors that can affect standard OCT image quality and determined how and why the performance of an existing neural network based segmentation method can subsequently degrade as a result. Three image quality factors (noise, contrast reduction, and gamma correction) all had a negative impact upon performance, while more robust performance was maintained in the presence of both JPEG and JPEG2000 image compression. Improving the method & x2019;s robustness to each of these degradations is also demonstrated with marked performance improvements identified by applying a fine-tuning approach to the network. This study improves our understanding of the effect of OCT image degradation on neural network performance, the effect that fine-tuning with poor-image quality data has on the network and highlights the benefit and importance of training resilient models using data augmentation.","Image segmentation,machine learning,optical coherence tomography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"COHERENCE,TOMOGRAPHY,IMAGES,EPITHELIUM,DETACHMENT,SEGMENTATION,RETINAL,LAYER,SEGMENTATION,NERVE-FIBER,LAYER,AUTOMATIC,SEGMENTATION,CHOROIDAL,THICKNESS,SURFACE,SEGMENTATION,NEURAL-NETWORKS,FRAMEWORK,GLAUCOMA",IEEE ACCESS,https://eprints.qut.edu.au/199313/1/57058864.pdf,
14,Deep Learning-Based Methodology for Recognition of Fetal Brain Standard Scan Planes in 2D Ultrasound Images,8,,44443-44451,"Qu Ruowei,Xu Guizhi,Ding Chunxia,Jia Wenyan,Sun Mingui","Qu RW,Xu GZ,Ding CX,Jia WY,Sun MG",Xu GZ,10.1109/ACCESS.2019.2950387,Hebei University of Technology,"Two-dimensional ultrasound scanning (US) has become a highly recommended examination in prenatal diagnosis in many countries. Accurate detection of abnormalities and correct fetal brain standard planes is the most necessary precondition for successful diagnosis and measurement. In the past few years, support vector machine (SVM) and other machine learning methods have been devoted to automatic recognition of 2D ultrasonic images, but the performance of recognition is not satisfactory due to the wide diversity of fetal postures, shortage of data, similarities between standard planes and other reasons. Especially in the recognition of fetal brain images, the features of fetal brain images such as shape, texture, color and others are very similar, which presents great challenges to the recognition work. In this study, we proposed two main methods based on deep convolutional neural networks to automatically recognize six standard planes of fetal brains. One is a deep convolutional neural network (CNN), and the other one is CNN-based domain transfer learning. To examine the performance of these algorithms, we constructed two datasets. Dataset 1 consists of 30,000 2D ultrasound images from 155 subjects between 16 and 34 weeks. Dataset 2, containing 1,200 images, was acquired from a research participant throughout 40 weeks, which is the entire pregnancy. Experimental results show that the proposed solutions achieve promising results and that the frameworks based on deep convolutional neural networks generally outperform the ones using other classical deep learning methods, thus demonstrating the great potential of convolutional neural networks in this area.","Standards,Feature extraction,Ultrasonic imaging,Deep learning,Image recognition,Convolutional neural networks,Medical services,Medical image processing,CNN,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,SEGMENTATION,LOCALIZATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08887441.pdf,
15,Recognizing Hazard Perception in a Visual Blind Area Based on EEG Features,8,,48917-48928,"Guo Zizheng,Pan Yufan,Zhao Guozhen,Zhang Jun,Dong Ni","Guo ZZ,Pan YF,Zhao GZ,Zhang J,Dong N",Guo ZZ,10.1109/ACCESS.2020.2978436,Southwest Jiaotong University,"Many potential hazards are encountered during daily driving in mixed traffic situations, and the anticipatory activity of a driver to a hazard is one of the key factors in many crashes. In a previous study using eye-tracking data, it was reliably recognized whether the eyes of a driver had become fixated or pursued hazard cues. A limitation of using eye-tracking data is that it cannot be identified whether the anticipatory activity of a driver to hazards has been activated. This study aimed to propose a method to recognize whether the psychological anticipation of a driver had been activated by a hazard cue using electroencephalogram (EEG) signals as input. Thirty-six drivers participated in a simulated driving task designed according to a standard psychological anticipatory study paradigm. Power spectral density (PSD) features were extracted from raw EEG data, and feature dimensions were reduced by principal component analysis (PCA). The results showed that when a driver detected a hazard cue, the alpha band immediately decreased, and the beta band increased approximately 300 ms after the cue appeared. Based on performance evaluation of the support vector machine (SVM), k-nearest neighbor (KNN) method, and linear discriminant analysis (LDA), SVM could detect the anticipatory activity of the driver to a potential hazard in a timely manner with an accuracy of 81%. The findings demonstrated that the hazard anticipatory activity of a driver could be recognized with EEG data as input.","Hazards,Electroencephalography,Vehicles,Task analysis,Psychology,Standards,Support vector machines,Hazard perception,EEG,anticipatory activity,SVM",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONTINGENT,NEGATIVE-VARIATION,OSCILLATIONS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09024040.pdf,
16,Accurate Vigilance Detection During Gait by Using Movement Artifact Removal,8,,51179-51188,"Siddiquee Masudur R.,Hasan S. M. Shafiul,Marquez J. Sebastian,Ramon Rodrigo Nicolas,Bai Ou","Siddiquee MR,Hasan SMS,Marquez JS,Ramon RN,Bai O",Siddiquee MR,10.1109/ACCESS.2020.2980546,State University System of Florida,"Human vigilance is a cognitive function that requires sustained attention toward change in the environment. Human vigilance detection is a widely investigated topic which can be accomplished by various approaches. Most studies have focused on stationary vigilance detection due to the high effect of interference such as motion artifacts which are prominent in common movements such as walking. Functional Near-Infrared Spectroscopy is a preferred modality in vigilance detection due to the safe nature, the low cost and ease of implementation. fNIRS is not immune to motion artifact interference, and therefore human vigilance detection performance would be severely degraded when studied during locomotion. Properly treating and removing walking-induced motion artifacts from the contaminated signals is crucial to ensure accurate vigilance detection. This study compared the vigilance level detection during both stationary and walking states and confirmed that the performance of vigilance level detection during walking is significantly deteriorated (with a p & x003C;0.05). Further, this study explored motion artifact removal and applied machine learning methods. Results reveal the vigilance detection during walking has a comparable performance to the stationary state when the motion artifacts are estimated and removed.","Functional near-infrared spectroscopy (fNIRS),gait,inertia measurement unit,machine learning,motion artifacts removal,motion sensors,walking,wireless wearable fNIRS,vigilance during walking",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NEAR-INFRARED,SPECTROSCOPY,FNIRS,ATTENTION,WALKING,CORTEX,INTERFERENCE,FMRI,NIRS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09035429.pdf,
17,Abnormal Infant Movements Classification With Deep Learning on Pose-Based Features,8,,51582-51592,"McCay Kevin D.,Ho Edmond S. L.,Shum Hubert P. H.,Fehringer Gerhard,Marcroft Claire,Embleton Nicholas D.","McCay KD,Ho ESL,Shum HPH,Fehringer G,Marcroft C,Embleton ND",Ho ESL,10.1109/ACCESS.2020.2980269,Northumbria University,"The pursuit of early diagnosis of cerebral palsy has been an active research area with some very promising results using tools such as the General Movements Assessment (GMA). In our previous work, we explored the feasibility of extracting pose-based features from video sequences to automatically classify infant body movement into two categories, normal and abnormal. The classification was based upon the GMA, which was carried out on the video data by an independent expert reviewer. In this paper we extend our previous work by extracting the normalised pose-based feature sets, Histograms of Joint Orientation 2D (HOJO2D) and Histograms of Joint Displacement 2D (HOJD2D), for use in new deep learning architectures. We explore the viability of using these pose-based feature sets for automated classification within a deep learning framework by carrying out extensive experiments on five new deep learning architectures. Experimental results show that the proposed fully connected neural network FCNet performed robustly across different feature sets. Furthermore, the proposed convolutional neural network architectures demonstrated excellent performance in handling features in higher dimensionality. We make the code, extracted features and associated GMA labels publicly available.","Feature extraction,Machine learning,Tools,Two dimensional displays,Pediatrics,Histograms,Medical services,Deep learning,feature extraction,classification,infants,pose-based features",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"GENERAL,MOVEMENTS",IEEE ACCESS,https://doi.org/10.1109/access.2020.2980269,
18,Comparison Study of Radiomics and Deep Learning-Based Methods for Thyroid Nodules Classification Using Ultrasound Images,8,,52010-52017,"Wang Yongfeng,Yue Wenwen,Li Xiaolong,Liu Shuyu,Guo Lehang,Xu Huixiong,Zhang Heye,Yang Guang","Wang YF,Yue WW,Li XL,Liu SY,Guo LH,Xu HX,Zhang HY,Yang G",Guo LH,10.1109/ACCESS.2020.2980290,Tongji University,"Thyroid nodules have a high prevalence and a small percentage is malignant. Many non-invasive methods have been developed with the help of the Internet of Things to improve the detection rate of malignant nodules. These methods can be roughly categorized into two classes: radiomics based and deep learning based approaches. In general, convolutional neural networks based deep learning methods have achieved promising performance in many medical image analysis and classification applications; however, no existing comparison has been done between radiomics based and deep learning based approaches. Therefore, in this paper, we aim to compare the performance of radiomics and deep learning based methods for the classification of thyroid nodules from ultrasound images. On one hand, we developed a radiomics based method, which consists of extracting high throughput 302-dimensional statistical features from pre-processed images. Then dimension reduction was performed using mutual information and linear discriminant analysis respectively to achieve the final classification. On the other hand, a deep learning based method was also developed and tested by pre-training a VGG16 model with fine-tuning. Ultrasound images including 3120 images (1841 benign nodules and 1393 malignant nodules) from 1040 cases were retrospectively collected. The dataset was divided into 80 & x0025; training and 20 & x0025; testing data. The highest accuracies yielded on the testing data for radiomics and deep learning based methods were 66.81 & x0025; and 74.69 & x0025;, respectively. A comparison result demonstrated that the deep learning based method can achieve a better performance than using radiomics.","Machine learning,Feature extraction,Ultrasonic imaging,Cancer,Training,Computational modeling,Biomedical imaging,Ultrasound images,thyroid nodule,thyroid cancer,nodule classification,convolutional neural network,radiomics",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ELASTOGRAPHY,FEATURES,TEXTURE,CANCER,BENIGN",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09034133.pdf,
19,A Machine Learning Approach for Lamb Meat Quality Assessment Using FTIR Spectra,8,,52385-52394,"Alaiz-Rodriguez Rocio,Parnell Andrew C.","Alaiz-Rodriguez R,Parnell AC",Alaiz-Rodriguez R,10.1109/ACCESS.2020.2974623,Universidad de Leon,"The food industry requires automatic methods to establish authenticity of food products. In this work, we address the problem of the certification of suckling lamb meat with respect to the rearing system. We evaluate the performance of neural network classifiers as well as different dimensionality reduction techniques, with the aim of categorizing lamb fat by means of spectroscopy and analyzing the features with more discrimination power. Assessing the stability of feature ranking algorithms also becomes particularly important. We assess six feature selection techniques , Information Gain, Gain Ratio, Relief and two embedded techniques based on the decision rule 1R and SVM (Support Vector Machine). Additionally, we compare them with common approaches in the chemometrics field like the Partial Least Square (PLS) model and Principal Component Analysis (PCA) regression. Experimental results with a fat sample dataset collected from carcasses of suckling lambs show that performing feature selection contributes to classification performance increasing accuracy from 89.70 & x0025; with the full feature set to 91.80 & x0025; and 93.89 & x0025; with the SVM approach and PCA, respectively. Moreover, the neural classifiers yield a significant increase in the accuracy with respect to the PLS model (85.60 & x0025; accuracy). It is noteworthy that unlike PCA or PLS, the feature selection techniques that select relevant wavelengths allow the user to identify the regions in the spectrum with the most discriminant power, which makes the understanding of this process easier for veterinary experts. The robustness of the feature selection methods is assessed via a visual approach.","Feature extraction,Machine learning,Fats,Stability criteria,Principal component analysis,Dairy products,Meat quality assessment,feature selection,machine learning,neural networks,feature selection robustness",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"LEAST-SQUARES,REGRESSION,FEATURE-SELECTION,FOOD,FRAUD,SPECTROSCOPY,ADULTERATION,FAT,NIR,AUTHENTICATION,DISCRIMINATION,VISUALIZATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09000861.pdf,
20,A Novel Approach to Improving Brain Image Classification Using Mutual Information-Accelerated Singular Value Decomposition,8,,52575-52587,"Al-Saffar Zahraa A.,Yildirim Tulay","Al-Saffar ZA,Yildirim T",Al-Saffar ZA,10.1109/ACCESS.2020.2980728,University of Baghdad,"Brain image classification is one of the most useful and widely needed processes in the medical system, and it is a highly challenging field. This paper presents a new method for selecting a significant subset of features as the input to the classifier, called mutual information-accelerated singular value decomposition (MI-ASVD). This novel algorithm is exploited to design an intelligent system for classifying MRI brain images into three classes: healthy, high-grade glioma, and low-grade glioma. The proposed system has six stages: pre-processing, clustering, tumour localization, feature extraction, MI-ASVD and classification. First, the MR images are smoothed by using enhancement techniques such as Gaussian kernel filters. Then, local difference in intensity-means (LDI-Means) clustering is employed to segment and detect suspicious regions. The grey-level run-length matrix (GLRLM), texture, and colour intensity features are used for tumour feature extraction. Later, a special method including a summation of feature selection and dimensionality reduction, MI-ASVD, is applied to select the most useful features for the classification process. Finally, the simplified residual neural network technique is implemented to classify the MR brain images. Using MI-ASVD provided accurate and more efficacious results in classification compared with the original feature space and with two other standard dimensionality reduction methods, principal component analysis (PCA) and singular value decomposition (SVD). It achieved a classification accuracy of 94.91 & x0025;, which is better than the two state-of-the-art techniques as well as methods from similar published studies.","Brain image classification,clustering,image processing,machine learning,mutual information,PCA,residual neural network (RNN),SVD",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"TUMOR,SEGMENTATION,NEURAL-NETWORKS,FEATURES,CRITERIA,TEXTURE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09035475.pdf,
21,An Automated Breast Micro-Calcification Detection and Classification Technique Using Temporal Subtraction of Mammograms,8,,52785-52795,"Loizidou Kosmia,Skouroumouni Galateia,Nikolaou Christos,Pitris Costas","Loizidou K,Skouroumouni G,Nikolaou C,Pitris C",Loizidou K,10.1109/ACCESS.2020.2980616,University of Cyprus,"Radiologists worldwide use mammography as a reliable tool for breast cancer screening. However, mammography assessment is challenging even for well-trained radiologists, leading to a pressing need for Computer Aided Diagnosis (CAD) systems. In this work, a novel technique for the detection and classification of breast Micro-Calcifications (MCs), which are diagnostically significant but difficult to detect findings, is presented. The proposed method is based on the subtraction of temporally sequential mammogram pairs, after pre-processing and image registration, followed by machine-learning. The classification was performed using several features extracted from the subtracted mammograms and selected during training to optimize the accuracy of the results. Six classifiers were tested in a leave-one-patient-out, 4, 5 and 10 fold cross-validation process. This technique was evaluated on a unique dataset, consisting of temporal sequences of mammograms from 80 patients taken between 1 to 6 years apart. The resulting 320 mammograms were reviewed by 2 radiologists who precisely marked each MC location. The accuracy of classifying MCs as benign or suspicious improved from 91.42 & x0025; without temporal subtraction and an Ensemble of Decision Trees (EDT), to 99.55 & x0025; with the use of sequential mammograms and Support Vector Machines (SVMs) with leave-one-patient-out validation. The improvement was statistically significant (p-value & x003C; 0.005). These results verify the accuracy and the effectiveness of the proposed technique should to be further evaluated on a larger dataset.","Breast cancer,computer-aided diagnosis,digital mammography,micro-calcifications,temporal subtraction",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"COMPUTER-AIDED,DETECTION,REGISTRATION,CANCER,BENIGN,DIAGNOSIS,FEATURES",IEEE ACCESS,https://zenodo.org/record/3874375/files/An%20Automated%20Breast%20Micro_calcification%20Detection%20and%20Classification%20Technique%20using%20Temporal%20Subtraction%20of%20Mammograms.pdf,
22,A Novel Interpretable Computer-Aided Diagnosis System of Thyroid Nodules on Ultrasound Based on Clinical Experience,8,,53223-53231,"Zhang Shijie,Du Huarui,Jin Zhuang,Zhu Yaqiong,Zhang Ying,Xie Fang,Zhang Mingbo,Tian Xiaoqi,Zhang Jue,Luo Yukun","Zhang SJ,Du HR,Jin Z,Zhu YQ,Zhang Y,Xie F,Zhang MB,Tian XQ,Zhang J,Luo YK",Zhang J,10.1109/ACCESS.2020.2976495,Peking University,"Computer-aided diagnosis systems (CADs) present valuable second opinions to radiologists in diagnosis. Many studies on thyroid nodules have proposed various CADs to provide a binary result, benignity or malignancy, for doctors, ignoring interpretability of more ultrasonic features that could be more useful. We develop an interpretable CADs (iCADS) that utilizes deep-learning networks & x2019; classification power and interpretability potential of clinical guidelines, like TIRADS, a well-established scale for thyroid nodules. iCADS incorporates a main neural-networks model and six neural-network based interpreters. The outputs of the six interpreters are compared with TIRADS guidelines and the matched result will form a report, more than a benignity or malignancy result, for radiologists. Clinical images of 16,946 thyroid nodules from 5,885 patients were used to train the proposed iCADS. An extra experimental data set containing 501 images were used to test the performance of the model. For better illustrating the assistant ability of iCADS, we also recruited ten junior radiologists to make diagnosis decisions with or without the help of different versions of iCADS. The experiments demonstrated that iCADS can largely improve junior radiologists diagnosis with the help of interpreter strategy. These experiments are also the very first attempt to evaluate the effect of interpretability of deep-learning based CADs in clinical practice. Comparison experiments with other deep-learning based CADs and traditional CADs indicated that the interpreter strategy can easily be combined to other intelligent CADs without the loss of performance. The framework of iCADS can also inspire more research on the development of CADs.","Feature extraction,Ultrasonic imaging,Cancer,Guidelines,Pathology,Lesions,Interpretable computer-aided diagnosis system,deep learning,multi-task learning,thyroid nodules,ultrasound",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IMAGE-ANALYSIS,CANCER,CLASSIFICATION,RISK",IEEE ACCESS,https://doi.org/10.1109/access.2020.2976495,
23,On the classification and quantification of crystal defects after energetic bombardment by machine learned molecular dynamics simulations,22,,,"Dominguez-Gutierrez F. J.,Byggmastar J.,Nordlund K.,Djurabekova F.,von Toussaint U.","Dominguez-Gutierrez FJ,Byggmastar J,Nordlund K,Djurabekova F,von Toussaint U",Dominguez-Gutierrez FJ,10.1016/j.nme.2019.100724,Max Planck Society,"The analysis of the damage on plasma facing materials (PFM), due to their direct interaction with the plasma environment, is needed to build the next generation of nuclear fusion reactors. After systematic analyses of numerous materials over the last decades, tungsten has become the most promising candidate for a nuclear fusion reactor. In this work, we perform molecular dynamics (MD) simulations using a machine learned interatomic potential, based on the Gaussian Approximation Potential framework, to model better neutron bombardment mechanisms in pristine W lattices. The MD potential is trained to reproduce realistic short-range dynamics, the liquid phase, and the material recrystallization, which are important for collision cascades. The formation of point defects is quantified and classified by a descriptor vector (DV) based method, which is independent of the sample temperature and its constituents, requiring only modest computational resources. The locations of vacancies are calculated by the k-d-tree algorithm. The analysis of the damage in the W samples is compared to results obtained by Finnis-Sinclair and Tersoff-Ziegler-Biersack-Littmark potentials, at a sample temperature of 300 K and a primary knock-on atom (PKA) energy range of 0.5-10 keV, where a good agreement with the reported number of Frenkel pair is observed. Our results provide information about the advantages and limits of the machine learned MD simulations with respect to the standard ones. The formation of dumbbell and crowdion defects as a function of PKA energy were identified and distinguished by our DV method.","Tungsten,MD simulations,Descriptor vectors,Machine learning,Gaussian approximation potentials",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Nuclear Science & Technology,,2.384,"TUNGSTEN,VACANCY",NUCLEAR MATERIALS AND ENERGY,http://arxiv.org/pdf/1910.12052,
24,Proposal teaching materials the concepts and principles of machine learning for use in education,,,226-229,"Imai Shinichi,Shiba Yusuke","Imai S,Shiba Y",Imai S,,Tokyo Gakugei University,"In this paper, Technologies such as AI, IoT, and big data are very important contents. However, IoT related content is still in the developing stage and is now evolving at a tremendous speed. It is very important to learn about AI, IoT, big data, etc. Therefore, we propose a teaching tool based on soccer penalty shoots using machine learning. This teaching tool can visually confirm that the goalkeeper robot does not shoot the ball by machine learning.","Machine learning,Education,Teaching materials,Evaluation",Proceedings Paper,"ALIFE ROBOTICS CO, LTD, HIG HANDADAI, OITA, 870-1112, JAPAN","Computer Science,Robotics",,,,PROCEEDINGS OF THE 2020 INTERNATIONAL CONFERENCE ON ARTIFICIAL LIFE AND ROBOTICS (ICAROB2020),,
25,Graph-based semi-supervised one class support vector machine for detecting abnormal lung sounds,364,,,"Lang Rongling,Lu Ruibo,Zhao Chenqian,Qin Honglei,Liu Guodong","Lang RL,Lu RB,Zhao CQ,Qin HL,Liu GD",Qin HL,10.1016/j.amc.2019.06.001,Beihang University,"The detection of abnormal lung sounds collected by electronic stethoscopes plays a fundamental role in pulmonary disease diagnostics for primary care and general patient monitoring in telemedicine. Over the past 40 years, the detection has been performed mainly by supervised learning. This method, however, is time- and cost-consuming, and error-prone because it requires manual labeling large numbers of samples. This work proposes a new method, a graph-based semi-supervised one class support vector machine (OCSVM). It can describe normal lung sounds and detect the abnormal ones only by using a small amount of labeled normal samples and abundant unlabeled samples as training samples, which avoids the shortcomings of the traditional methods. A spectral graph is constructed to indicate the relationship of all the samples, which enriches the information provided by only a small number of labeled normal samples. Then, a graph-based semi-supervised OCSVM model is built and its solution is provided. Employing the information in the spectral graph, the proposed method can enhance the effect of recognition and generalization which are crucial for the effective detection of abnormal lung sounds. Finally, the proposed method is evaluated by experiments with all the samples collected in Shijiazhuang, Hebei province, China. The experimental results show that the method outperforms the original OCSVM when the labeled samples are rare. Meanwhile, the performance of the proposed method becomes better as unlabeled abnormal samples increase. (C) 2019 Published by Elsevier Inc.","Semi-supervised learning,Abnormal lung sound detection,Support vector machine,Spectral graph",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA",Mathematics,,3.469,CLASSIFICATION,APPLIED MATHEMATICS AND COMPUTATION,,
26,Artificial Intelligence Technique for Gene Expression by Tumor RNA-Seq Data: A Novel Optimized Deep Learning Approach,8,,22874-22883,"Khalifa Nour Eldeen M.,Taha Mohamed Hamed N.,Ali Dalia Ezzat,Slowik Adam,Hassanien Abdul Ella","Khalifa NEM,Taha MHN,Ali DE,Slowik A,Hassanien AE",Slowik A,10.1109/ACCESS.2020.2970210,Koszalin University of Technology,"Cancer is one of the most feared and aggressive diseases in the world and is responsible for more than 9 million deaths universally. Staging cancer early increases the chances of recovery. One staging technique is RNA sequence analysis. Recent advances in the efficiency and accuracy of artificial intelligence techniques and optimization algorithms have facilitated the analysis of human genomics. This paper introduces a novel optimized deep learning approach based on binary particle swarm optimization with decision tree (BPSO-DT) and convolutional neural network (CNN) to classify different types of cancer based on tumor RNA sequence (RNA-Seq) gene expression data. The cancer types that will be investigated in this research are kidney renal clear cell carcinoma (KIRC), breast invasive carcinoma (BRCA), lung squamous cell carcinoma (LUSC), lung adenocarcinoma (LUAD) and uterine corpus endometrial carcinoma (UCEC). The proposed approach consists of three phases. The first phase is preprocessing, which at first optimize the high-dimensional RNA-seq to select only optimal features using BPSO-DT and then, converts the optimized RNA-Seq to 2D images. The second phase is augmentation, which increases the original dataset of 2086 samples to be 5 times larger. The selection of the augmentations techniques was based achieving the least impact on manipulating the features of the images. This phase helps to overcome the overfitting problem and trains the model to achieve better accuracy. The third phase is deep CNN architecture. In this phase, an architecture of two main convolutional layers for featured extraction and two fully connected layers is introduced to classify the 5 different types of cancer according to the availability of images on the dataset. The results and the performance metrics such as recall, precision and F1 score show that the proposed approach achieved an overall testing accuracy of 96.9%. The comparative results are introduced, and the proposed method outperforms those in related works in terms of testing accuracy for 5 classes of cancer. Moreover, the proposed approach is less complex and consume less memory.","Cancer,RNA sequence,deep convolutional neural network,gene expression data",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"COMPUTER,VISION,PREDICTION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08974295.pdf,
27,Classification of Cervical Biopsy Images Based on LASSO and EL-SVM,8,,24219-24228,"Huang Pan,Zhang Shuailei,Li Min,Wang Jing,Ma Cailing,Wang Bowei,Lv Xiaoyi","Huang P,Zhang SL,Li M,Wang J,Ma CL,Wang BW,Lv XY",Lv XY,10.1109/ACCESS.2020.2970121,Xinjiang University,"Cervical biopsy (biopsy) is an important part of the diagnosis of cervical cancer. The artificial classification of biopsy images in diagnosis is difficult and depends on the clinical experience of pathologists. However, the classification accuracy of computerized biopsy tissue images with similar lesions is low, and the problem of incomplete experimental objects needs to be addressed. This paper proposes a method of cervical biopsy tissue image classification based on least absolute shrinkage and selection operator (LASSO) and ensemble learning-support vector machine (EL-SVM). Using the LASSO algorithm for feature selection, the average optimization time was reduced by 35.87 seconds while ensuring the accuracy of the classification, and then serial fusion was performed. The EL-SVM classifier was used to identify and classify 468 biopsy tissue images, and the receiver operating characteristic (ROC) curve and error curve were used to evaluate the generalization ability of the classifier. Experiments show that the normal-cervical cancer classification accuracy reached 99.64 & x0025;, the normal-low-grade squamous intraepithelial lesion (LSIL) classification accuracy was 84.25 & x0025;, the normal-high-grade squamous intraepithelial lesion (HSIL) classification accuracy was 87.40 & x0025;, the LSIL-HSIL classification accuracy was 76.34 & x0025;, the LSIL-cervical cancer classification accuracy was 91.88 & x0025;, and the HSIL-cervical cancer classification accuracy was 81.54 & x0025;.","Cervical cancer,cervical biopsy,LASSO,EL-SVM,selective voting",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"RECOGNITION,IDENTIFICATION,TEXTURE,HPV",IEEE ACCESS,https://doi.org/10.1109/access.2020.2970121,
28,Deep Learning-Based HCNN and CRF-RRNN Model for Brain Tumor Segmentation,8,,26665-26675,"Deng Wu,Shi Qinke,Wang Miye,Zheng Bing,Ning Ning","Deng W,Shi QK,Wang MY,Zheng B,Ning N",Ning N,10.1109/ACCESS.2020.2966879,Sichuan University,"This paper proposes a strategy where a structure is developed to recognize and order the tumor type. Over a time of years, numerous specialists have been examined and proposed a technique in this space. A brain tumor segmentation approach is developed based on efficient, deep learning techniques implemented in a unified system to achieve the appearance and spatial accuracy outcomes through Conditional Radom Fields (CRF) and Heterogeneous Convolution Neural Networks (HCNN). In these steps the 2D image patching and picture slices of the deep-learning model is developed. The Proposed method has following steps as follows: 1) train HCNN by image patches; 2) train CRF with CRF-Recurrent Regression based Neural Network (RRNN) by means of image slices with fixed variables of HCNN; 3) fine tune with HCNN and CRF-RRNN image slices. In general, 3 segmentation models have been trained using axial-, coronary-and sagittal image patches and slices, Further assembled into brain tumor segments using a voting fusion technique and it can be examined with Internet of Medical Things (IoMT) Platform. The experimental results proved that our approach has been capable of developing a Flair, T1c and T2 segmenting model and of achieving good performance as with Flair, T1, T1c, and T2 scans.","Brain tumor segmentation,CRF-RRNN,HCNN,IoMT",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORKS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08960329.pdf,
29,Analysis and Identification of Rice Adulteration Using Terahertz Spectroscopy and Pattern Recognition Algorithms,8,,26839-26850,"Li Chao,Li Bin,Ye Dapeng","Li C,Li B,Ye DP",Li B,10.1109/ACCESS.2020.2970868,Beijing Academy of Agriculture & Forestry,"Rice adulteration is a severe problem in agro-products and food regulatory agencies, suppliers, and consumers. In this study, to effectively distinguish whether high-quality rice is mixed with low-quality rice, detection and analysis of adulterated rice in five levels with different mixing proportions was conducted via terahertz spectroscopy and pattern recognition algorithms. Initially, samples were prepared and spectral data were acquired by using the terahertz transmission mode, and a principal component analysis (PCA) algorithm was applied to extract features from original spectrum information and reduce data dimensions. Subsequently, partial least squares-discriminant analysis (PLS-DA), support vector machine (SVM), and a back propagation neural network (BPNN) combined with the absorption spectra after different pretreatments, including standard normal variate (SNV) transformation, baseline correction (BC), and first derivative (1st derivative), were applied to establish the classification models. Results indicate that an SVM model employing the absorption spectra with a 1st derivative pretreatment exhibits the best discrimination ability, with an accuracy up to 97.33% in the prediction set. This result proves that terahertz spectroscopy combined with chemometric methods can be an effective tool to identify rice adulteration levels.","Back propagation neural network,partial least squares-discriminant analysis,rice adulteration,spectral analysis,support vector machines,terahertz spectroscopy",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SAMPLES,SEEDS",IEEE ACCESS,https://doi.org/10.1109/access.2020.2970868,
30,Deep Learning Approach for Apple Edge Detection to Remotely Monitor Apple Growth in Orchards,8,,26911-26925,"Wang Dandan,Li Changying,Song Huaibo,Xiong Hongting,Liu Chang,He Dongjian","Wang DD,Li CY,Song HB,Xiong HT,Liu C,He DJ",He DJ,10.1109/ACCESS.2020.2971524,Northwest A&F University - China,"The automatic intelligent acquisition of apple growth information in the long-term provides a promising benefit for growers to plan the application of nutrients and pesticides during apple maturation. The overall goal of this study was to develop an apple growth monitoring system in an orchard based on a deep learning edge detection network for apple size remote estimation throughout the entire growth period. A remote apple growth monitoring hardware system was built with a spherical video camera and two personal computers to regularly acquire apple images. For software, an edge detection network that fused convolutional features (FCF) was proposed to segment the apple images. To filter out irrelevant apples in the images, points on apples to be monitored were manually selected from the images as seed points, and the region growing method was conducted on the extracted edge maps. Then, the horizontal diameters of the apples were calculated. The experimental results showed that the F1 score of the FCF method was 53.1% on the apple test set, and the average run time was 0.075 s per image, which was better than the other five methods in comparison. The growth of the apples was monitored by our system from the date after apple thinning to apple ripening. The mean average absolute error of the apples' horizontal diameters detected by our system was 0.90 mm, and it decreased by 67.9% when compared with the circle fitting-based method (2.8 mm). These results suggest that our system provides an effective and accurate way to monitor the growth of apples on the trees. The proposed method provides a reference for monitoring the growth of other fruits during the growth period, and it can be used to optimize orchard management.","Apple growth,edge detection,fruit horizontal diameter estimation,remote monitoring,ResNet-50",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FRUIT,DETECTION,LOCALIZATION,RECOGNITION,COLOR,SEGMENTATION,FEATURES,IMAGES,NUMBER",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08981980.pdf,
31,MaligNet: Semisupervised Learning for Bone Lesion Instance Segmentation Using Bone Scintigraphy,8,,27047-27066,"Apiparakoon Terapap,Rakratchatakul Nutthaphol,Chantadisai Maythinee,Vutrapongwatana Usanee,Kingpetch Kanaungnit,Sirisalipoch Sasitorn,Rakvongthai Yothin,Chaiwatanarat Tawatchai,Chuangsuwanich Ekapol","Apiparakoon T,Rakratchatakul N,Chantadisai M,Vutrapongwatana U,Kingpetch K,Sirisalipoch S,Rakvongthai Y,Chaiwatanarat T,Chuangsuwanich E",Chuangsuwanich E,10.1109/ACCESS.2020.2971391,Chulalongkorn University,"One challenge in applying deep learning to medical imaging is the lack of labeled data. Although large amounts of clinical data are available, acquiring labeled image data is difficult, especially for bone scintigraphy (i.e., 2D bone imaging) images. Bone scintigraphy images are generally noisy, and ground-truth or gold standard information from surgical or pathological reports may not be available. We propose a novel neural network model that can segment abnormal hotspots and classify bone cancer metastases in the chest area in a semisupervised manner. Our proposed model, called MaligNet, is an instance segmentation model that incorporates ladder networks to harness both labeled and unlabeled data. Unlike deep learning segmentation models that classify each instance independently, MaligNet utilizes global information via an additional connection from the core network. To evaluate the performance of our model, we created a dataset for bone lesion instance segmentation using labeled and unlabeled example data from 544 and 9,280 patients, respectively. Our proposed model achieved mean precision, mean sensitivity, and mean F1-score of 0.852, 0.856, and 0.848, respectively, and outperformed the baseline mask region-based convolutional neural network (Mask R-CNN) by 3.92%. Further analysis showed that incorporating global information also helps the model classify specific instances that require information from other regions. On the metastasis classification task, our model achieves a sensitivity of 0.657 and a specificity of 0.857, demonstrating its great potential for automated diagnosis using bone scintigraphy in clinical practice.","Bone scintigraphy,semi-supervised learning,lesion instance segmentation,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08979392.pdf,
32,Modality-Specific Deep Learning Model Ensembles Toward Improving TB Detection in Chest Radiographs,8,,27318-27326,"Rajaraman Sivaramakrishnan,Antani Sameer K.","Rajaraman S,Antani SK",Rajaraman S,10.1109/ACCESS.2020.2971257,National Institutes of Health (NIH) - USA,"The proposed study evaluates the efficacy of knowledge transfer gained through an ensemble of modality-specific deep learning models toward improving the state-of-the-art in Tuberculosis (TB) detection. A custom convolutional neural network (CNN) and selected popular pretrained CNNs are trained to learn modality-specific features from large-scale publicly available chest x-ray (CXR) collections including (i) RSNA dataset (normal = 8851, abnormal = 17833), (ii) Pediatric pneumonia dataset (normal = 1583, abnormal = 4273), and (iii) Indiana dataset (normal = 1726, abnormal = 2378). The knowledge acquired through modality-specific learning is transferred and fine-tuned for TB detection on the publicly available Shenzhen CXR collection (normal = 326, abnormal = 336). The predictions of the best performing models are combined using different ensemble methods to demonstrate improved performance over any individual constituent model in classifying TB-infected and normal CXRs. The models are evaluated through cross-validation (n = 5) at the patient-level with an aim to prevent overfitting, improve robustness and generalization. It is observed that a stacked ensemble of the top-3 retrained models demonstrates promising performance (accuracy: 0.941; 95% confidence interval (CI): [0.899, 0.985], area under the curve (AUC): 0.995; 95 CI: [0.945, 1.00]). One-way ANOVA analyses show there are no statistically significant differences in accuracy (P = .791) and AUC (P = .831) among the ensemble methods. Knowledge transferred through modality-specific learning of relevant features helped improve the classification. The ensemble model resulted in reduced prediction variance and sensitivity to training data fluctuations. Results from their combined use are superior to the state-of-the-art.","Classification,confidence interval,convolutional neural network,deep learning,ensemble,knowledge transfer,modality-specific learning,tuberculosis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"TUBERCULOSIS,ANOVA",IEEE ACCESS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7120763,
33,Breast Cancer Image Classification via Multi-Network Features and Dual-Network Orthogonal Low-Rank Learning,8,,27779-27792,"Wang Yongjun,Lei Baiying,Elazab Ahmed,Tan Ee-Leng,Wang Wei,Huang Fanglin,Gong Xuehao,Wang Tianfu","Wang YJ,Lei BY,Elazab A,Tan EL,Wang W,Huang FL,Gong XH,Wang TF",Wang TF,10.1109/ACCESS.2020.2964276,Shenzhen University,"Histopathological image analysis is an important technique for early diagnosis and detection of breast cancer in clinical practice. However, it has limited efficiency and thus the detection of breast cancer is still an open issue in medical image analysis. To improve the early diagnostic accuracy of breast cancer and reduce the workload of doctors, we devise a classification framework based on histology images by combining deep learning with machine learning methodologies in this paper. Specifically, we devise a multi-network feature extraction model by using pre-trained deep convolution neural networks (DCNNs), develop an effective feature dimension reduction method and train an ensemble support vector machine (E-SVM). First, we preprocess the histological images via scale transformation and color enhancement methods. Second, the multi-network features are extracted by using four pre-trained DCNNs (e.g., DenseNet-121, ResNet-50, multi-level InceptionV3, and multi-level VGG-16). Third, a feature selection method via dual-network orthogonal low-rank learning (DOLL) is further developed for performance boosting and overfitting alleviation. Finally, an E-SVM is trained via fused features and voting strategy to perform the classification task, which classifies the images into four classes (i.e., benign, in situ carcinomas, invasive carcinomas, and normal). We evaluate the proposed method on the public ICIAR 2018 Challenge dataset of histology images of breast cancer and achieve a high classification accuracy of 97.70%. Experimental results show that our method can achieve quite promising performance and outperform state-of-the-art methods.","Breast cancer image classification,deep convolutional neural network,multi-network features,low-rank learning,ensemble support vector machine",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DIMENSIONALITY,REDUCTION",IEEE ACCESS,https://doi.org/10.1109/access.2020.2964276,
34,Multi-Set Canonical Correlation Analysis for 3D Abnormal Gait Behaviour Recognition Based on Virtual Sample Generation,8,,32485-32501,"Luo Jian,Tjahjadi Tardi","Luo J,Tjahjadi T",Luo J,10.1109/ACCESS.2020.2973898,Hunan Normal University,"Small sample dataset and two-dimensional (2D) approach are challenges to vision-based abnormal gait behaviour recognition (AGBR). The lack of three-dimensional (3D) structure of the human body causes 2D based methods to be limited in abnormal gait virtual sample generation (VSG). In this paper, 3D AGBR based on VSG and multi-set canonical correlation analysis (3D-AGRBMCCA) is proposed. First, the unstructured point cloud data of gait are obtained by using a structured light sensor. A 3D parametric body model is then deformed to fit the point cloud data, both in shape and posture. The features of point cloud data are then converted to a high-level structured representation of the body. The parametric body model is used for VSG based on the estimated body pose and shape data. Symmetry virtual samples, pose-perturbation virtual samples and various body-shape virtual samples with multi-views are generated to extend the training samples. The spatial-temporal features of the abnormal gait behaviour from different views, body pose and shape parameters are then extracted by convolutional neural network based Long Short-Term Memory model network. These are projected onto a uniform pattern space using deep learning based multi-set canonical correlation analysis. Experiments on four publicly available datasets show the proposed system performs well under various conditions.","Three-dimensional displays,Two dimensional displays,Feature extraction,Correlation,Solid modeling,Data models,Shape,3D body modelling,abnormal gait behaviour recognition,long short-term memory model,multi-set canonical correlation analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SYSTEM,CLASSIFICATION,REPRESENTATION,PARAMETERS,MODEL,2D",IEEE ACCESS,http://wrap.warwick.ac.uk/133999/1/WRAP-multi-set-canonical-correlation-analysis-3D-abnormal-gait-behaviour-recognition-based-virtual-sample-generation-Tjahjadi-2020.pdf,
35,Emotion Recognition From Multi-Channel EEG Signals by Exploiting the Deep Belief-Conditional Random Field Framework,8,,33002-33012,"Chao Hao,Liu Yongli","Chao H,Liu YL",Chao H,10.1109/ACCESS.2020.2974009,Henan Polytechnic University,"Recently, much attention has been attracted to automatic emotion recognition based on multi-channel electroencephalogram (EEG) signals, with the rapid development of machine learning methods. However, traditional methods ignore the correlation information between different channels, and cannot fully capture the long-term dependencies and contextual information of EEG signals. To address the problems, this paper proposes a deep belief-conditional random field (DBN-CRF) framework which integrates the improved deep belief networks with glia chains (DBN-GC) and conditional random field. In the framework, the raw feature vector sequence is firstly extracted from the multi-channel EEG signals by a sliding window. Then, parallel DBN-GC models are utilized to obtain the high-level feature sequence of the multi-channel EEG signals. And the conditional random field (CRF) model generates the predicted emotion label sequence according to the high-level feature sequence. Finally, the decision merge layer based on K-nearest neighbor algorithm is employed to estimate the emotion state. According to our best knowledge, this is the first attempt that applies the conditional random field methodology to deep belief networks for emotion recognition. Experiments are conducted on three publicly available emotional datasets which include AMIGOS, SEED and DEAP. The results demonstrate that the proposed framework can mine inter correlation information of multiple-channel by the glia chains and catch inter channel correlation information and contextual information of EEG signals for emotion recognition. In addition, the classification accuracy of the proposed method is compared with several classical techniques. The results indicate that the proposed method outperforms most of the other deep classifiers. Thus, potential of the proposed framework is demonstrated.","Electroencephalography,Brain modeling,Emotion recognition,Feature extraction,Correlation,Hidden Markov models,Machine learning,Human-computer interaction,emotion recognition,multi-channel EEG signal,DBN-GC,conditional random field",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,FUSION,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08999626.pdf,
36,Ensemble Networks for User Recognition in Various Situations Based on Electrocardiogram,8,,36527-36535,"Kim Min-Gu,Choi Chang,Pan Sung Bum","Kim MG,Choi C,Pan SB",Pan SB,10.1109/ACCESS.2020.2975258,Chosun University,"Research on electrocardiogram (ECG) signals has been actively undertaken to assess their value as a next generation user recognition technology, because they require no stimulation and are robust against forgery and modification. However, even within the same user, the heart rate and waveform of ECG signals will vary depending on physical activity, mental effects, and measurement time. Therefore, when data acquired across changes in the user state is used as registered data, an overfitting problem occurs due to data generalization, which degrades the recognition performance for newly acquired data. Therefore, in this paper, we propose parallel ensemble networks to solve the overfitting problem and prevent the degradation. First, ECG signals acquired in various environments are used as the input data of parallel convolutional neural networks (CNNs). Each CNN is set up with different parameters to detect different features. The ECG signals outputted from each network are classified for each subject, and then fused into one database to be used as registered data for re-training. Instead of fusing all the output signals from each network, only the ECG signals of Top-3 networks showing excellent performance are fused and composed of registered data. The reconstructed registered data are used for user recognition, by re-training with time independent comparison data in the CNN. The experimental results of comparing the proposed parallel ensemble networks with those of previous studies using the self-acquired actual ECG signals show that the proposed method achieves recognition performance higher than the previous studies, with an accuracy rate of 98.5%.","Electrocardiography,Feature extraction,Fingerprint recognition,Machine learning,Face recognition,Heart rate,ECG,biometrics,user recognition,various situations,parallel ensemble networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORK,ECG,CLASSIFICATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09004481.pdf,
37,"Automatic Detection of Diabetic Retinopathy: A Review on Datasets, Methods and Evaluation Metrics",8,,48784-48811,"Mateen Muhammad,Wen Junhao,Hassan Mehdi,Nasrullah Nasrullah,Sun Song,Hayat Shaukat","Mateen M,Wen JH,Hassan M,Nasrullah N,Sun S,Hayat S",Wen JH,10.1109/ACCESS.2020.2980055,Chongqing University,"Diabetic retinopathy (DR) is a fast-spreading disease across the globe, which is caused by diabetes. The DR may lead the diabetic patients to complete vision loss. In this scenario, early identification of DR is more essential to recover the eyesight and provide help for timely treatment. The detection of DR can be manually performed by ophthalmologists and can also be done by an automated system. In the manual system, analysis and explanation of retinal fundus images need ophthalmologists, which is a time-consuming and very expensive task, but in the automated system, artificial intelligence is used to perform an imperative role in the area of ophthalmology and specifically in the early detection of diabetic retinopathy over the traditional detection approaches. Recently, numerous advanced studies related to the identification of DR have been reported. This paper presents a detailed review of the detection of DR with three major aspects; retinal datasets, DR detection methods, and performance evaluation metrics. Furthermore, this study also covers the author's observations and provides future directions in the field of diabetic retinopathy to overcome the research challenges for the research community.","Diabetes,Retina,Retinopathy,Feature extraction,Lesions,Blood vessels,Biomedical imaging,Artificial intelligence,deep learning,diabetic retinopathy,fundus images,machine learning,ophthalmology",Review,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BLOOD-VESSEL,SEGMENTATION,FUNDUS,IMAGES,OPTIC,DISC,HEMORRHAGE,DETECTION,GENERALIZED-METHOD,LESION,DETECTION,NEURAL-NETWORK,CLASSIFICATION,DIAGNOSIS,MICROANEURYSMS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09032162.pdf,
38,A Steel Surface Defect Recognition Algorithm Based on Improved Deep Learning Network Model Using Feature Visualization and Quality Evaluation,8,,49885-49895,"Guan Shengqi,Lei Ming,Lu Hao","Guan SQ,Lei M,Lu H",Guan SQ; Lei M,10.1109/ACCESS.2020.2979755,Xi'an Polytechnic University,"Steel defect detection is used to detect defects on the surface of the steel and to improve the quality of the steel surface. However, traditional image detection algorithms cannot meet the detection requirements because of small defect features and low contrast between background and features about steel surface defect datasets. A novel recognition algorithm for steel surface defects based on improved deep learning network models using feature visualization and quality evaluation is proposed in this paper. Firstly, the VGG19 is used to pre-train the steel surface defect classification task and the corresponding DVGG19 is established to extract the feature images in different layers from defects weight model. Secondly, the SSIM and decision tree are used to evaluate the feature image quality and adjust the parameters and structure of VGG19. On this basis, a new VSD network is obtained and used for the classification of steel surface defects. Comparing with ResNet and VGG19 methods, experiment results show that the proposed method markedly can improve the average accuracy of classification, and the model is able to converge quickly, which can be good for steel surface defect recognition using VSD network model of feature visualization and quality evaluation.","Steel,Feature extraction,Machine learning,Kernel,Convolution,Neural networks,Visualization,Deep learning,DeVGG19 network,feature visualization,steel defect recognition,VSD network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MULTICLASS,CLASSIFICATION,METHOD,SUPPORT,VECTOR,MACHINE,HYPER-SPHERES,INSPECTION,IMAGE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09031427.pdf,
39,MLLBC: A Machine Learning Toolbox for Modeling the Loss Rate of the Lining Bearing Capacity,8,,50256-50267,"Zhang Sen,Wu Wanyin,Yang Zhao,Lin Xu,Ren Zhihua,Yan Zhixin","Zhang S,Wu WY,Yang Z,Lin X,Ren ZH,Yan ZX",Wu WY,10.1109/ACCESS.2020.2979833,"Union Vis Innovat, Shenzhen 518055, Peoples R China.","Testing the health of tunnels, as a branch of highway operation, has an extremely important application in public property and even life safety. Among them, there are many factors that cause the tunnel to deform or collapse. The conventional methods use the finite element method (FEM) which are to simulate the bearing capacity loss rate of the lining by using the mechanical method. However, it takes a long time to calculate the stress-strain-situation of the lining model under each condition. This paper explores the machine learning to calculate the loss rate of the lining bearing capacity under more conditions based on FEM simulation data. Here, we establish a machine learning toolbox for modeling the loss rate of the lining bearing capacity named ""MLLBC"", which contains three main components: 1) data loading; 2) machine learning model deployment; 3) performance evaluation. To ensure the fairness of model evaluation, ten machine learning models use a unified code library. We also conduct experiments on our new dataset which is the loss rate of the lining bearing capacity with different data amounts, as well as experiments on the goodness of model fitting under different ranges of various variables.","Machine learning,Data models,Tools,Load modeling,Analytical models,Finite element analysis,Neural networks,Toolbox,the loss rate of the lining bearing capacity,machine learning,tunnel health",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FAULT-DIAGNOSIS,NEURAL-NETWORKS,TUNNEL",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09032189.pdf,
40,Adaptive Pruning of Transfer Learned Deep Convolutional Neural Network for Classification of Cervical Pap Smear Images,8,,50674-50683,"Wang Pin,Wang Jiaxin,Li Yongming,Li Linyu,Zhang Hehua","Wang P,Wang JX,Li YM,Li LY,Zhang HH",Wang P,10.1109/ACCESS.2020.2979926,Chongqing University,"Automatic classification of cervical Pap smear images plays a key role in computer-aided cervical cancer diagnosis. Conventional classification approaches rely on cell segmentation and feature extraction methods. Due to overlapping cells, dust, impurities and uneven irradiation, the accurate segmentation and feature extraction of Pap smear images are still challenging. To overcome the difficulties of the feature-based approaches, deep learning is becoming more important alternative. Since the number of cervical cytological images is limited, an adaptive pruning deep transfer learning model (PsiNet-TAP) is proposed for Pap smear images classification. We designed a novel network to classify Pap smear images. Due to the limited number of images, we adopted transfer learning to obtain the pre-trained model. Then it was optimized by modifying the convolution layer and pruning some convolution kernels that may interfere with the target classification task. The proposed method PsiNet-TAP was tested on 389 cervical Pap smear images. The method has achieved remarkable performance (accuracy: more than 98%), which demonstrates the strength of the proposed method for providing an efficient tool for cervical cancer classification in clinical settings.","Convolution,Cervical cancer,Kernel,Feature extraction,Solid modeling,Image segmentation,Adaptation models,Adaptive pruning,cervical smear images,convolutional neural networks,transfer learning,uninvolved images",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"STATISTICAL,FEATURES,CELL-NUCLEI,SEGMENTATION,CYTOPLASM",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09031411.pdf,
41,Crack Detection of Concrete Pavement With Cross-Entropy Loss Function and Improved VGG16 Network Model,8,,54564-54573,"Qu Zhong,Mei Jing,Liu Ling,Zhou Dong-Yang","Qu Z,Mei J,Liu L,Zhou DY",Qu Z,10.1109/ACCESS.2020.2981561,Chongqing University of Posts & Telecommunications,"Concrete pavement defects are an important indicator reflecting the safety status of pavement. However, it is difficult to accurately detect the concrete pavement cracks due to the complex concrete pavement environment, such as uneven illumination, deformation and potential shadows, etc. In order to solve these problems, we propose the crack detection algorithm of concrete pavement with convolutional neural network. Firstly, our method is used to classify cracks first and detect the classified crack images, different deep learning models are used in these two parts to achieve different functions. Secondly, in the crack classification section, in view of the low proportion of effective concrete pavement crack images in the mass images collected by crack detection vehicle, the output dimension of FC2 layer of LeNet-5 model is modified before crack detection. It can accurately identify the concrete pavement cracks from several types of disturbance characteristics by training the classification model. Finally, in order to improve the efficiency of crack detection, the algorithm scales the network model horizontally and accesses the convolution layer with the kernel size of. Experiments show that the of our algorithm reaches to 0.896 in CFD dataset. Compared with VGG16, U-Net and Percolation, it is 25.2 & x0025;, 2.8 & x0025;, 39.1 & x0025; improvement of respectively. For Cracktree200 dataset, the is 0.892. Compared with VGG16, U-Net and Percolation, it is 50.3 & x0025;, 16.6 & x0025;, 68.9 & x0025; improvement of respectively. For DeepCrack dataset, the is 0.901. Compared with VGG16, U-Net and Percolation, it is 53 & x0025;, 5.2 & x0025;, 52.2 & x0025; improvement of respectively.","Crack detection,cross-entropy loss function,VGG16 network,crack classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORKS,NONDESTRUCTIVE,EVALUATION,DAMAGE,DETECTION,ALGORITHM,WIDTH,CNN",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09040553.pdf,
42,A Deep Learning Model Based on Concatenation Approach for the Diagnosis of Brain Tumor,8,,55135-55144,"Noreen Neelum,Palaniappan Sellappan,Qayyum Abdul,Ahmad Iftikhar,Imran Muhammad,Shoaib Muhammad","Noreen N,Palaniappan S,Qayyum A,Ahmad I,Imran M,Shoaib M",Noreen N,10.1109/ACCESS.2020.2978629,Monash University,"Brain tumor is a deadly disease and its classification is a challenging task for radiologists because of the heterogeneous nature of the tumor cells. Recently, computer-aided diagnosis-based systems have promised, as an assistive technology, to diagnose the brain tumor, through magnetic resonance imaging (MRI). In recent applications of pre-trained models, normally features are extracted from bottom layers which are different from natural images to medical images. To overcome this problem, this study proposes a method of multi-level features extraction and concatenation for early diagnosis of brain tumor. Two pre-trained deep learning models i.e. Inception-v3 and DensNet201 make this model valid. With the help of these two models, two different scenarios of brain tumor detection and its classification were evaluated. First, the features from different Inception modules were extracted from pre-trained Inception-v3 model and concatenated these features for brain tumor classification. Then, these features were passed to softmax classifier to classify the brain tumor. Second, pre-trained DensNet201 was used to extract features from various DensNet blocks. Then, these features were concatenated and passed to softmax classifier to classify the brain tumor. Both scenarios were evaluated with the help of three-class brain tumor dataset that is available publicly. The proposed method produced 99.34 & x0025;, and 99.51 & x0025; testing accuracies respectively with Inception-v3 and DensNet201 on testing samples and achieved highest performance in the detection of brain tumor. As results indicated, the proposed method based on features concatenation using pre-trained models outperformed as compared to existing state-of-the-art deep learning and machine learning based methods for brain tumor classification.","Tumors,Feature extraction,Machine learning,Brain modeling,Magnetic resonance imaging,Biomedical imaging,Diseases,Deep learning,magnetic resonance imaging,brain tumor classification,pre-trained model,dataset",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09025004.pdf,
43,Extraction of SSVEPs-Based Inherent Fuzzy Entropy Using a Wearable Headband EEG in Migraine Patients,28,1,14-27,"Cao Zehong,Lin Chin-Teng,Lai Kuan-Lin,Ko Li-Wei,King Jung-Tai,Liao Kwong-Kum,Fuh Jong-Ling,Wang Shuu-Jiun","Cao ZH,Lin CT,Lai KL,Ko LW,King JT,Liao KK,Fuh JL,Wang SJ",Lin CT,10.1109/TFUZZ.2019.2905823,University of Technology Sydney,"Inherent fuzzy entropy is an objective measurement of electroencephalography (EEG) complexity reflecting the robustness of brain systems. In this study, we present a novel application of multiscale relative inherent fuzzy entropy using repetitive steady-state visual evoked potentials (SSVEPs) to investigate EEG complexity change between two migraine phases, i.e., interictal (baseline) and preictal (before migraine attacks) phases. We used a wearable headband EEG device with O1, Oz, O2, and Fpz electrodes to collect EEG signals from 80 participants [40 migraine patients and 40 healthy controls (HCs)] under the following two conditions: During resting state and SSVEPs with five 15-Hz photic stimuli. We found a significant enhancement in occipital EEG entropy with increasing stimulus times in both HCs and patients in the interictal phase, but a reverse trend in patients in the preictal phase. In the 1st SSVEP, occipital EEG entropy of the HCs was significantly lower than that of patents in the preictal phase (FDR-adjusted p < 0.05). Regarding the transitional variance of EEG entropy between the 1st and 5th SSVEPs, patients in the preictal phase exhibited significantly lower values than patients in the interictal phase (FDR-adjusted p < 0.05). Furthermore, in the classification model, the AdaBoost ensemble learning showed an accuracy of 81 +/- 6% and area under the curve of 0.87 for classifying interictal and preictal phases. In contrast, there were no differences in EEG entropy among groups or sessions by using other competing entropy models, including approximate entropy, sample entropy, and fuzzy entropy on the same dataset. In conclusion, inherent fuzzy entropy offers novel applications in visual stimulus environments and may have the potential to provide a preictal alert to migraine patients.","Electroencephalography (EEG),inherent fuzzy entropy,migraine,steady-state visual evoked potential (SSVEP)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.444,"CANONICAL,CORRELATION-ANALYSIS,EXCITABILITY,HABITUATION,POTENTIALS,MOBILE",IEEE TRANSACTIONS ON FUZZY SYSTEMS,https://eprints.utas.edu.au/30108/1/131573%20-%20Extraction%20of%20SSVEPs-based%20inherent%20fuzzy%20entropy%20using%20a%20wearable%20headband%20EEG%20in%20migraine%20patients.pdf,
44,Supervised Network-Based Fuzzy Learning of EEG Signals for Alzheimer's Disease Identification,28,1,60-71,"Yu Haitao,Lei Xinyu,Song Zhenxi,Liu Chen,Wang Jiang","Yu HT,Lei XY,Song ZX,Liu C,Wang J",Yu HT,10.1109/TFUZZ.2019.2903753,Tianjin University,"Accurate identification of Alzheimer's disease (AD) with electroencephalograph (EEG) is crucial in the clinical diagnosis of neurological disorders. However, the effectiveness and accuracy of manually labeling EEG signals are barely satisfactory, due to lacking effective biomarkers. In this paper, we propose a novel machine learning method network-based Takagi-Sugeno-Kang (N-TSK) for AD identification which employs the complex network theory and TSK fuzzy system. With the construction of functional network of AD subjects, the topological features of weighted and unweighted networks are extracted. Taken the network parameters as independent inputs, a fuzzy-system-based TSK model is established and further trained to identify AD EEG signals. Experimental results demonstrate the effectiveness of the proposed scheme in AD identification and ability of N-TSK fuzzy classifiers. The highest accuracy can achieve 97.3% for patients with closed eyes and 94.78% with open eyes. In addition, the performance of weighted N-TSK largely exceeds unweighted N-TSK. By further optimizing the network features utilized in the N-TSK fuzzy classifiers, it is found that local efficiency and clustering coefficient are the most effective factors in AD identification. This work provides a potential tool for identifying neurological disorders from the perspective of functional networks with EEG signal, especially contributing to the diagnosis and identification of AD.","Electroencephalography,Electrodes,Brain modeling,Feature extraction,Neurological diseases,Machine learning,Alzheimer's disease (AD),electroencephalograph (EEG),functional network,fuzzy system,supervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.444,"FUNCTIONAL,BRAIN,NETWORKS,GENETIC,NETWORKS,POWER,SPECTRUM,SYNCHRONIZATION,CONNECTIVITY,DIAGNOSIS,INFORMATION,DYNAMICS,BIOLOGY",IEEE TRANSACTIONS ON FUZZY SYSTEMS,,
45,Classification of Motor Imagery Task by Using Novel Ensemble Pruning Approach,28,1,85-91,"Ali Muhammad Ammar,Ucuncu Duygu,Atas Pinar Karadayi,Ozogur-Akyuz Sureyya","Ali MA,Ucuncu D,Atas PK,Ozogur-Akyuz S",Ali MA,10.1109/TFUZZ.2019.2900859,Bahcesehir University,"Brain-computer interface (BCI) assists communication for the disabled and handicapped. It is usually electroencephalogram (EEG) based and uses motor imagery (MI) in its operation. EEG signals are known for being nonstationary and are sensitive to artifacts from various sources such as the physical and mental state of the patient, their mood, their posture, and any external noise or distractions, etc. Processing of this data directly affects the classification accuracy, making it a critical step in any BCI system. Ensemble learning has been used for many kinds of BCI classification applications including MI and P300 event related potential, which has been proven to be robust. The purpose of this paper is to generate an algorithm that uses ensemble pruning method for EEG classification evoked by an MI task. In order to achieve this, we extracted the features of an EEG dataset and trained a range of support vector machines to make a diverse ensemble of classifiers. This ensemble is then pruned by using a novel optimization model by a difference of convex algorithm, which has not been used on EEG data before.","Electroencephalography,Feature extraction,Brain modeling,Discrete wavelet transforms,Task analysis,Optimization,Difference of convex algorithm,ensemble pruning,motor imagery,optimization,support vector machines (SVM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.444,"BRAIN-COMPUTER-INTERFACE,SINGLE-TRIAL,EEG,BCI,SELECTION,SIGNALS,RCMARS,MODEL",IEEE TRANSACTIONS ON FUZZY SYSTEMS,,
46,A Deep Learning Reconstruction Framework for Differential Phase-Contrast Computed Tomography With Incomplete Data,29,1,2190-2202,"Fu Jian,Dong Jianbing,Zhao Feng","Fu J,Dong JB,Zhao F",Fu J,10.1109/TIP.2019.2947790,Beihang University,"Differential phase-contrast computed tomography (DPC-CT) is a powerful analysis tool for soft-tissue and low-atomic-number samples. Limited by the implementation conditions, DPC-CT with incomplete projections happens quite often. Conventional reconstruction algorithms face difficulty when given incomplete data. They usually involve complicated parameter selection operations, which are also sensitive to noise and are time-consuming. In this paper, we report a new deep learning reconstruction framework for incomplete data DPC-CT. It involves the tight coupling of the deep learning neural network and DPC-CT reconstruction algorithm in the domain of DPC projection sinograms. The estimated result is not an artifact caused by the incomplete data, but a complete phase-contrast projection sinogram. After training, this framework is determined and can be used to reconstruct the final DPC-CT images for a given incomplete projection sinogram. Taking the sparse-view, limited-view and missing-view DPC-CT as examples, this framework is validated and demonstrated with synthetic and experimental data sets. Compared with other methods, our framework can achieve the best imaging quality at a faster speed and with fewer parameters. This work supports the application of the state-of-the-art deep learning theory in the field of DPC-CT.","Image reconstruction,Computed tomography,Deep learning,Neural networks,Feature extraction,Absorption,Image reconstruction,tomography,computed tomography (CT),biomedical signal processing,biomedical imaging,reconstruction algorithms",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,11.491,"CONVOLUTIONAL,NEURAL-NETWORK,IMAGE,QUALITY,ASSESSMENT,ITERATIVE,RECONSTRUCTION",IEEE TRANSACTIONS ON IMAGE PROCESSING,http://arxiv.org/pdf/1904.00531,
47,Soft-tissue radiography using multi-scale convolutional neural networks,15,1,,"Ha S.,Youn H.,Kim H. K.","Ha S,Youn H,Kim HK",Kim HK,10.1088/1748-0221/15/01/C01028,Pusan National University,Dual-energy imaging techniques based on the fast kVp switching and the sandwich detector can enhance the conspicuity in digital radiography. Deep learning is an alternative promising approach to obtain dual-energy images without hardware cost and additional patient dose. This paper extends the well-known multi-scale U-net to preserve high-frequency information so as to be applicable to structural filtering of medical images with minimal loss of information. The performance of modified versions of the U-net is presented in comparison with the conventional U-net architecture. Limitation of the modified networks is also discussed.,"Medical-image reconstruction methods and algorithms, computer-aided diagnosis,Image reconstruction in medical imaging,X-ray radiography and digital radiography (DR)",Article; Proceedings Paper,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Instruments & Instrumentation,,1.328,"CHEST,RADIOGRAPHS,NOISE,SUPPRESSION,ALGORITHM,DETECTOR",JOURNAL OF INSTRUMENTATION,,
48,Focus Variation Measurement and Prediction of Surface Texture Parameters Using Machine Learning in Laser Powder Bed Fusion,142,1,,"Ozel Tugrul,Altay Ayca,Kaftanoglu Bilgin,Leach Richard,Senin Nicola,Donmez Alkan","Ozel T,Altay A,Kaftanoglu B,Leach R,Senin N,Donmez A",Ozel T,10.1115/1.4045415,Rutgers State University New Brunswick,"The powder bed fusion-based additive manufacturing process uses a laser to melt and fuse powder metal material together and creates parts with intricate surface topography that are often influenced by laser path, layer-to-layer scanning strategies, and energy density. Surface topography investigations of as-built, nickel alloy (625) surfaces were performed by obtaining areal height maps using focus variation microscopy for samples produced at various energy density settings and two different scan strategies. Surface areal height maps and measured surface texture parameters revealed the highly irregular nature of surface topography created by laser powder bed fusion (LPBF). Effects of process parameters and energy density on the areal surface texture have been identified. Machine learning methods were applied to measured data to establish input and output relationships between process parameters and measured surface texture parameters with predictive capabilities. The advantages of utilizing such predictive models for process planning purposes are highlighted.","additive manufacturing,surface analysis,machine learning,laser powder bed fusion,Metrology,Sensing,monitoring and diagnostics",Article,"ASME, TWO PARK AVE, NEW YORK, NY 10016-5990 USA",Engineering,,3.084,"NICKEL-ALLOY,625,SPATTER,OPTIMIZATION,TOPOGRAPHY,METROLOGY",JOURNAL OF MANUFACTURING SCIENCE AND ENGINEERING-TRANSACTIONS OF THE ASME,,
49,Machine learning for analysis of atomic spectral data,240,,,"Cianciosa M.,Law K. J. H.,Martin E. H.,Green D. L.","Cianciosa M,Law KJH,Martin EH,Green DL",Cianciosa M,10.1016/j.jqsrt.2019.106671,United States Department of Energy (DOE),"Physics based forward models are the basis on which many experimental diagnostics are interpreted. For some diagnostics, models can be computationally expensive which precludes their use in real time analysis. Reduced models have the potential to capture sufficient physics thereby enabling the desired real time analysis. Using statistical inference and machine learning techniques the application of reduced models for inversion of atomic spectral data used to diagnose magnetic fields in a plasma will be examined. Two approaches are considered, (a) a reduction of the forward model where traditional inversion can be performed on the proxy model, and (b) a reduction of the direct inverse where parameters are a function of measured signal. The resulting inversion is sufficiently fast to be utilized in an online context for digital twinning, and ultimately real-time prediction, design, and control of plasma systems, such as tokamaks. These methods will be demonstrated on both simulated and experimentally measured data. (C) 2019 Elsevier Ltd. All rights reserved.","FIELD PITCH-ANGLE,OPTIMIZATION,SPECTROSCOPY,DISCHARGES,LINES",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Optics,Spectroscopy",,2.738,"FIELD,PITCH-ANGLE,OPTIMIZATION,SPECTROSCOPY,DISCHARGES,LINES",JOURNAL OF QUANTITATIVE SPECTROSCOPY & RADIATIVE TRANSFER,https://www.sciencedirect.com/science/article/am/pii/S0022407319302365,
50,Wireless Capsule Endoscopy: A New Tool for Cancer Screening in the Colon With Deep-Learning-Based Polyp Recognition,108,1,178-197,"Jia Xiao,Xing Xiaohan,Yuan Yixuan,Xing Lei,Meng Max Q. -H.","Jia X,Xing XH,Yuan YX,Xing L,Meng MQH",Meng MQH,10.1109/JPROC.2019.2950506,Chinese University of Hong Kong,"Accurate recognition of polyps is crucial for early colorectal cancer diagnosis and treatment. Wireless capsule endoscopy (WCE) is a noninvasive, wireless imaging tool that allows direct visualization of the entire colon without discomfort to patients and has the potential to revolutionize the screening workup for colorectal diseases. However, current manual review is laborious and time consuming, requiring the undivided concentration of the gastroenterologist. Computational methods that can assist automated polyp recognition will enhance the outcome both in terms of diagnostic accuracy and efficiency of WCE. This review introduces the computer-assisted algorithms as applied to colorectal polyp screening, focusing on the successes of deep-learning-based strategies in the WCE sequences. We survey key applications of WCE polyp recognition, covering deep-learning-based image-level classification, lesion region detection, and pixel-accurate segmentation. We conclude by discussing emerging research challenges, possible trends, and future directions.","Cancer screening,deep learning,polyp recognition,wireless capsule endoscopy (WCE)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,13.102,"GENERATIVE,ADVERSARIAL,NETWORKS,NEURAL-NETWORK,CT,IMAGE,CLASSIFICATION,AUTOENCODERS,SEGMENTATION,COLONOSCOPY,VALIDATION,DIAGNOSIS,PATHOLOGY",PROCEEDINGS OF THE IEEE,,
51,Recent Advances of Computational Methods for Identifying Bacteriophage Virion Proteins,27,4,259-264,"Chen Wei,Nie Fulei,Ding Hui","Chen W,Nie FL,Ding H",Chen W,10.2174/0929866526666190410124642,Chengdu University of Traditional Chinese Medicine,"Phage Virion Proteins (PVP) are essential materials of bacteriophage, which participate in a series of biological processes. Accurate identification of phage virion proteins is helpful to understand the mechanism of interaction between the phage and its host bacteria. Since experimental method is labor intensive and time-consuming, in the past few years, many computational approaches have been proposed to identify phage virion proteins. In order to facilitate researchers to select appropriate methods, it is necessary to give a comprehensive review and comparison on existing computational methods on identifying phage virion proteins. In this review, we summarized the existing computational methods for identifying phage virion proteins and also assessed their performances on an independent dataset. Finally, challenges and future perspectives for identifying phage virion proteins were presented. Taken together, we hope that this review could provide clues to researches on the study of phage virion proteins.","Bacteriophage,phage virion protein,host bacteria,feature selection,web-server",Review,"BENTHAM SCIENCE PUBL LTD, EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES",Biochemistry & Molecular Biology,,1.528,"FEATURE-SELECTION,IDENTIFICATION,PREDICTION,SEQUENCES,TOOL",PROTEIN AND PEPTIDE LETTERS,,
52,Fusion of Brain PET and MRI Images Using Tissue-Aware Conditional Generative Adversarial Network With Joint Loss,8,,6368-6378,"Kang Jiayin,Lu Wu,Zhang Wenjuan","Kang JY,Lu W,Zhang WJ",Kang JY,10.1109/ACCESS.2019.2963741,Jiangsu Ocean University,"Positron emission tomography (PET) has rich pseudo color information that reflects the functional characteristics of tissue, but lacks structural information and its spatial resolution is low. Magnetic resonance imaging (MRI) has high spatial resolution as well as strong structural information of soft tissue, but lacks color information that shows the functional characteristics of tissue. For the purpose of integrating the color information of PET with the anatomical structures of MRI to help doctors diagnose diseases better, a method for fusing brain PET and MRI images using tissue-aware conditional generative adversarial network (TA-cGAN) is proposed. Specifically, the process of fusing brain PET and MRI images is treated as an adversarial machine between retaining the color information of PET and preserving the anatomical information of MRI. More specifically, the fusion of PET and MRI images can be regarded as a min-max optimization problem with respect to the generator and the discriminator, where the generator attempts to minimize the objective function via generating a fused image mainly contains the color information of PET, whereas the discriminator tries to maximize the objective function through urging the fused image to include more structural information of MRI. Both the generator and the discriminator in TA-cGAN are conditioned on the tissue label map generated from MRI image, and are trained alternatively with joint loss. Extensive experiments demonstrate that the proposed method enhances the anatomical details of the fused image while effectively preserving the color information from the PET. In addition, compared with other state-of-the-art methods, the proposed method achieves better fusion effects both in subjectively visual perception and in objectively quantitative assessment.","Positron emission tomography,magnetic resonance imaging,image fusion,generative adversarial network,loss function",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MULTI-FOCUS,IMAGE,SHEARLET,TRANSFORM,NEURAL-NETWORK,MODEL,RECONSTRUCTION,IHS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08949485.pdf,
53,ROI-Based Intraoperative MR-CT Registration for Image-Guided Multimode Tumor Ablation Therapy in Hepatic Malignant Tumors,8,,13613-13619,"Xu Panlong,Chen Chao,Wang Xinyi,Li Wentao,Sun Jianqi","Xu PL,Chen C,Wang XY,Li WT,Sun JQ",Sun JQ,10.1109/ACCESS.2020.2966518,Shanghai Jiao Tong University,"Image-guided ablation therapy has been widely used as a minimally invasive treatment for hepatic malignant tumors. Image registration is very useful during such operations, especially for multimode tumor ablation therapy. This research proposes a novel idea for performing MR-CT registration in multimode tumor ablation therapy based on liver segmentation. First, the liver is segmented from the preoperative 3D MR image and the intraoperative 3D CT image using a deep learning method based on a modified UNet & x002B;& x002B; architecture. Then, the preoperative MR image and the intraoperative CT image are coregistered using rigid and nonrigid registration methods with the segmented liver as the region of interest. The segmented binary images, rather than gray-level images, are aligned in the rigid registration step, which proves to be faster and more accurate than the registration method based on gray information. For the nonrigid registration, a multilevel free-form deformation method is applied to correct tiny misalignments. Finally, our method was validated using clinical data from 15 patients. The proposed method achieved an average Dice coefficient and target registration error of 93.36 & x00B1;1.21 & x0025; and 4.42 & x00B1;2.35 mm, respectively, and it can help interventional radiologists adjust the probe position in clinical work.","Deep learning,liver tumor ablation,intraoperative registration,deformable registration",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NONRIGID,REGISTRATION,LIVER",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08959220.pdf,
54,Improving Whole-Heart CT Image Segmentation by Attention Mechanism,8,,14579-14587,"Wang Wei,Ye Chengqin,Zhang Shanzhuo,Xu Yong,Wang Kuanquan","Wang W,Ye CQ,Zhang SZ,Xu Y,Wang KQ",Wang KQ,10.1109/ACCESS.2019.2961410,Harbin Institute of Technology,"Decent whole-heart segmentation from computed tomography (CT) can greatly contribute to the diagnosis and treatment of cardiovascular diseases. However, due to the difficulties such as blurred boundaries between neighbouring tissues and a large number of background voxels in medical images, automated whole-heart segmentation is still a challenging task. In this paper, we proposed three modified attention models, including simple negative example mining (SNEM), attention gate (AG) and U-CliqueNet (UCNet), to lead the deep learning network to focus on more salient information. These three attention modules were further implemented into a deeply-supervised 3D UNET separately and jointly, showing different degrees of improvement on the whole-heart segmentation task. Our experiments advised that SNEM was the most simple and effective attention mechanism for medical image processing among the three and the UCNet could reach the best performance. The combination of the attention mechanisms cannot always synergistically increase the accuracy, but joint models would have a positive influence in most cases. Finally, our network achieved a Dice score of 0.9112, which was a substantially higher performance than most of the state-of-the-art methods.","Medical image processing,CT image segmentation,attention mechanism,attention gate,feedback connection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://doi.org/10.1109/access.2019.2961410,
55,Deformation and Refined Features Based Lesion Detection on Chest X-Ray,8,,14675-14689,"Li Ce,Zhang Dong,Du Shaoyi,Tian Zhiqiang","Li C,Zhang D,Du SY,Tian ZQ",Li C,10.1109/ACCESS.2020.2963926,Lanzhou University of Technology,"Automatic and accurate detection of chest X-ray lesion is a challenging task. In the chest X-ray image, the lesions are shown with blurred boundary contours, different sizes, variable shapes, uneven density, etc. Besides, the deep convolutional neural network (CNN) consists of traditional convolution units, which has the limitations of rectangular sampling. The CNN extracts difficultly the deformation and refined features of chest X-ray lesions. Because of these factors, the accuracy of the lesion detection algorithm is not high. To deal with problems, we propose the deformation and refined features based lesion detection on the chest X-ray algorithm called DRCXNet. Firstly, the deformable convolution with amplitude modulation (AMDCN) is built to extract the deformation features of the lesions on the chest X-ray. Secondly, to obtain the refined feature, the global features and local features are fused, which can enrich the feature space of the lesion. Thirdly, the pooling layer combines with the AMDCN and region proposal network to establish the deformable pooling layer, which enhances the models sensitivity to the lesion location. During the training, the model is optimized by the improved regression loss function with a gradient control factor. On the public datasets RSNA and ChestX-ray8, the proposed method outperforms seven popular detection algorithms. The proposed method is a significant performance in both qualitative and quantitative experiments. Its comprehensive evaluation scores, sensitivity, precision, and the mean dice similarity coefficient are 0.866, 0.914, 0.836 and 0.859 respectively. The proposed algorithm achieves a very satisfactory result.","Chest X-ray,deformable convolution,deformation feature,refined feature,lesion detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,CLASSIFICATION,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08949513.pdf,
56,Speckle Noise Reduction in Ultrasound Images for Improving the Metrological Evaluation of Biomedical Applications: An Overview,8,,15983-15999,"Duarte-Salazar Carlos A.,Eduardo Castro-Ospina Andres,Becerra Miguel A.,Delgado-Trejos Edilson","Duarte-Salazar CA,Castro-Ospina AE,Becerra MA,Delgado-Trejos E",Castro-Ospina AE,10.1109/ACCESS.2020.2967178,"ITM, MIRP Lab Parque I, Medellin 050026, Colombia.","In recent years, many studies have examined filters for eliminating or reducing speckle noise, which is inherent to ultrasound images, in order to improve the metrological evaluation of their biomedical applications. In the case of medical ultrasound images, said noise can produce uncertainty in the diagnosis because details, such as limits and edges, should be preserved. Most algorithms can eliminate speckle noise, but they do not consider the conservation of these details. This paper describes, in detail, 27 techniques that mainly focus on the smoothing or elimination of speckle noise in medical ultrasound images. The aim of this study is to highlight the importance of improving said smoothing and elimination, which are directly related to several processes (such as the detection of regions of interest) described in other articles examined in this study. Furthermore, the description of this collection of techniques facilitates the implementation of evaluations and research with a more specific scope. This study initially covers several classical methods, such as spatial filtering, diffusion filtering, and wavelet filtering. Subsequently, it describes recent techniques in the field of machine learning focused on deep learning, which are not yet well known but greatly relevant, along with some modern and hybrid models in the field of speckle-noise filtering. Finally, five Full-Reference (FR) distortion metrics, common in filter evaluation processes, are detailed along with a compensation methodology between FR and Non-Reference (NR) metrics, which can generate greater certainty in the classification of the filters by considering the information of their behavior in terms of perceptual quality provided by NR metrics.","Diffusion filtering,image pre-processing,metrological evaluation,spatial filtering,speckle noise,ultrasound images,wavelet filtering",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ANISOTROPIC,DIFFUSION,FILTER,EDGE-DETECTION,QUALITY,ASSESSMENT,MEDICAL,ULTRASOUND,MEDIAN,FILTER,ENHANCEMENT,SUPPRESSION,STATISTICS,MODEL,COEFFICIENT",IEEE ACCESS,https://doi.org/10.1109/access.2020.2967178,
57,Multilevel Feature Fusion With 3D Convolutional Neural Network for EEG-Based Workload Estimation,8,,16009-16021,"Kwak Youngchul,Kong Kyeongbo,Song Woo-Jin,Min Byoung-Kyong,Kim Seong-Eun","Kwak Y,Kong K,Song WJ,Min BK,Kim SE",Kim SE,10.1109/ACCESS.2020.2966834,Hanbat National University,"Mental workload is defined as the proportion of the information processing capability used to perform a task. High cognitive load requires additional resources to process information; this demand for additional resources may reduce the processing efficiency and performance. Therefore, the technique of workload estimation can ensure a proper working environment to promote the working efficiency of each person. In this paper, we propose a three-dimensional convolutional neural network (3D CNN) employing a multilevel feature fusion algorithm for mental workload estimation using electroencephalogram (EEG) signals. The 1D EEG signals are converted to 3D EEG images to enable the 3D CNN to learn the spectral and spatial information over the scalp. The multilevel feature fusion framework integrates local and global neuronal activities by workload tasks in the 3D CNN algorithm. Multilevel features are extracted in each layer of the 3D convolution operation and each multilevel feature is multiplied by a weighting factor, which determines the importance of the feature. The weighting factor is adaptively estimated for each EEG image by a backpropagation process. Furthermore, we generate subframes from each EEG image and propose a temporal attention technique based on the long short-term memory model (LSTM) to extract a significant subframe at each multilevel feature that is strongly correlated with task difficulty. To verify the performance of our network, we performed the Sternberg task to measure the mental workload of the participant, which was classified according to its difficulty as low or high workload condition. We showed that the difficulty of the workload was well designed, which was reflected in the behavior of the participant. Our network is trained on this dataset and the accuracy of our network is 90.8 %, which is better than that of conventional algorithms. We also evaluated our method using the public EEG dataset and achieved 93.9 % accuracy.","Convolutional neural network,electroencephalogram (EEG),feature fusion,mental workload,working memory",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MEMORY,LOAD,ALPHA-BAND,COGNITIVE,LOAD,SYNCHRONIZATION,LAPLACIAN,TASKS",IEEE ACCESS,https://doi.org/10.1109/access.2020.2966834,
58,Machine Learning-Based Modeling for the Duration of Load Effect in Wood Structural Members Under Long-Term Sustained Load,8,,17903-17915,"Qi Peng,He Minjuan,Li Mengwei,Zheng Xiuzhi,Li Zheng,Liu Chuang,Zeng Xin,Tao Duo,Qi Xiaoya,Ma Zhong","Qi P,He MJ,Li MW,Zheng XZ,Li Z,Liu C,Zeng X,Tao D,Qi XY,Ma Z",Li Z,10.1109/ACCESS.2020.2966883,Tongji University,"The load resisting capacity of structural members will decrease when they are subjected to long-term sustained load. Such phenomenon is widely known as the duration of load effect, which is mainly caused by the damage accumulation in the material. The deterioration mechanism of the material is a typical stochastic process which is influenced by a large variety of parameters involving complex physical and chemical process. Although classical models have been proposed to evaluate the duration of load effect, it is nearly impossible to quantify the influence of various parameters and to achieve an accurate estimation. To optimize the combination of complexity and goodness-of-fit, a neural network model is proposed in this paper to evaluate the duration of load effect in wood structural members. Taking individual uncertainties into consideration, the proposed model treats the damage in wood as a Markov process and can estimate the residual strength distribution of the investigated wood structural members under long-term sustained load. The coefficient of determination reaches above 95% under sustained loading scenario, and it shows good adaptability across different wood properties. Moreover, the model can be adapted to continuously varied loading scenarios with a 98% coefficient of determination. This research aims to provide a useful and straightforward tool for accurately predicting the duration of load effect in wood structural members, and the proposed algorithm can be easily modified to deal with similar engineering problems for other construction materials.","Timber structures,duration of load,damage accumulation model,machine learning,long-term experiment",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONCRETE,BEHAVIOR",IEEE ACCESS,https://doi.org/10.1109/access.2020.2966883,
59,3D Segmentation of Pulmonary Nodules Based on Multi-View and Semi-Supervised,8,,26457-26467,"Sun Yurou,Tang Jinglei,Lei Weijie,He Dongjian","Sun YR,Tang JL,Lei WJ,He DJ",Tang JL,10.1109/ACCESS.2020.2971542,Northwest A&F University - China,"For large-scale CT images, the automatic segmentation of nodules is the foundation for diagnosis of various pulmonary diseases. Most existing methods have made great progress in pulmonary segmentation. But because of the similar structure between vessels and nodules in 2D, it lacks the ability to extract more discriminative features. The accuracy is still not satisfying. And the task remains challenging due to the lack of voxel labels and training strategies to balance foreground and background. To solve these problems, a 3D segmentation network of pulmonary nodules based on semi-supervised was proposed. Firstly, a framework of multi-view feature extraction was designed to solve the problem of high similarity between nodules and other tissues. It extracted features from three different views to improve precision. And three parallel dilated convolutions were added for multi-scale feature extraction. Hence, the spatial and semantic information of different sizes can be better obtained. Secondly, for the problem of identifying difficult samples, a hybrid loss function with an adjustment factor was proposed. It magnifies the loss of difficult samples, which will attract more attention from the network. And a new regularization term was introduced to avoid overfitting. The entire network was trained with a few labeled CT data set through an improved semi-supervised learning strategy, which was optimized with a new self-paced regularization. Experimental results show that the average sensitivity of the proposed method is 95.81%. It is superior to other methods in terms of precision and Dice index especially when the data set is not satisfied.","Pulmonary nodules segmentation,multi-view,semi-supervised,dilated convolution",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORKS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08981864.pdf,
60,HybridEEGNet: A Convolutional Neural Network for EEG Feature Learning and Depression Discrimination,8,,30332-30342,"Wan Zhijiang,Huang Jiajin,Zhang Hao,Zhou Haiyan,Yang Jie,Zhong Ning","Wan ZJ,Huang JJ,Zhang H,Zhou HY,Yang J,Zhong N",Zhong N,10.1109/ACCESS.2020.2971656,Beijing University of Technology,"Electroencephalogram (EEG) measurement, being an appropriate approach to understanding the underlying mechanisms of the major depressive disorder (MDD), is used to discriminate between depressive and normal control. With the advancement of deep learning methods, many studies have designed deep learning models to improve the classification accuracy of depression discrimination. However, few of them have focused on designing a convolutional filter to learn features according to EEG activity characteristics. In this study, a novel convolutional neural network named HybridEEGNet that is composed of two parallel lines is proposed to learn the synchronous and regional EEG features, and further differentiate normal controls from medicated and unmedicated MDD patients. A ten-fold cross validation method is used to train and test the model. The results show that HybridEEGNet achieves a sensitivity of 68.78%, a specificity of 84.45%, and an accuracy of 79.08% in three-category classification. The result of EEG feature analysis indicates that the differences of spatial distributions and amplitude ranges in the alpha rhythm (especially at approximately 10 Hz) among three categories might be distinctive attributes for depression discrimination.","HybridEEGNet,convolutional neural network,depression discrimination,EEG,feature analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"DISORDER,ELECTROENCEPHALOGRAPHY,NEUROBIOLOGY,BIOMARKERS,DISEASE,POWER",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08981929.pdf,
61,Mechanical Performance and Microstructure Prediction of Hypereutectoid Rail Steels Based on BP Neural Networks,8,,41905-41912,"Deng Yong,Qiao Ling,Zhu Jingchuan,Yang Bin","Deng Y,Qiao L,Zhu JC,Yang B",Yang B,10.1109/ACCESS.2020.2976135,University of Science & Technology Beijing,"Rapid development of railway has heightened the need for the researches on hypereutectoid heavy rail steels. Artificial intelligence method has become an effective tool to realize materials composition design. In this paper, BP neural network models are constructed to determine the relationship among (Cr, P, S, V) alloying elements, mechanical performance and microstructure of hypereutectoid rail steels. Analysis based on this model reveals that Cr is the most prominent element for mechanical properties. The tensile strength, yield strength and hardness can be improved with the increasing content of Cr and V. The addition of P and S seems to decrease the strength and hardness of rail steels. Furthermore, the addition of (Cr, P, S, V) has a slight impact on the content of pearlite dual phases. The increase of (Cr, V) and decrease of (P, S) can contribute to an increase in ferrite content with the associated decrease in cementite. Experimental results agree well with the prediction based on the BP neural network model. This work provides an excellent basis for assessing the mechanical performance and microstructure of hypereutectoid heavy rail steels.","Steel,Training,Biological neural networks,Rails,Biological system modeling,Microstructure,Microstructure,mechanical performance,hypereutectoid rail steels,BP neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BEHAVIOR,PARAMETERS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09007756.pdf,
62,Automatic Markerless Registration and Tracking of the Bone for Computer-Assisted Orthopaedic Surgery,8,,42010-42020,"Liu He,Rodriguez y Baena Ferdinando","Liu H,Baena FRY",Baena FRY,10.1109/ACCESS.2020.2977072,Imperial College London,"To achieve a simple and less invasive registration procedure in computer-assisted orthopaedic surgery, we propose an automatic, markerless registration and tracking method based on depth imaging and deep learning. A depth camera is used to continuously capture RGB and depth images of the exposed bone during surgery, and deep neural networks are trained to first localise the surgical target using the RGB image, then segment the target area of the corresponding depth image, from which the surface geometry of the target bone can be extracted. The extracted surface is then compared to a pre-operative model of the same bone for registration. This process can be performed dynamically during the procedure at a rate of 5-6 Hz, without any need for surgeon intervention or invasive optical markers. Ex vivo registration experiments were performed on a cadaveric knee, and accuracy measurements against an optically tracked ground truth resulted in a mean translational error of 2.74 mm and a mean rotational error of 6.66 degrees. Our results are the first to describe a promising new way to achieve automatic markerless registration and tracking in computer-assisted orthopaedic surgery, demonstrating that truly seamless registration and tracking of the limb is within reach. Our method reduces invasiveness by removing the need for percutaneous markers. The surgeon is also exempted from inserting markers and collecting registration points manually, which contributes to a more efficient surgical workflow and shorter procedure time in the operating room.","Surgery,Bones,Image segmentation,Cameras,Optical imaging,Deep learning,Computer-assisted orthopaedic surgery,deep learning,depth imaging,markerless registration",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,NAVIGATION,IEEE ACCESS,https://doi.org/10.1109/access.2020.2977072,
63,Hyperspectral Band Selection Using Attention-Based Convolutional Neural Networks,8,,42384-42403,"Lorenzo Pablo Ribalta,Tulczyjew Lukasz,Marcinkiewicz Michal,Nalepa Jakub","Lorenzo PR,Tulczyjew L,Marcinkiewicz M,Nalepa J",Nalepa J,10.1109/ACCESS.2020.2977454,Silesian University of Technology,"Hyperspectral imaging has become a mature technology which brings exciting possibilities in various domains, including satellite image analysis. However, the high dimensionality and volume of such imagery is a serious problem which needs to be faced in Earth Observation applications, where efficient acquisition, transfer and storage of hyperspectral images are key factors. To reduce the time (and ultimately cost) of transferring hyperspectral data from a satellite back to Earth, various band selection algorithms have been proposed. They are built upon the observation that for a vast number of applications only a subset of all bands convey the important information about the underlying material, hence we can safely decrease the data dimensionality without deteriorating the performance of hyperspectral classification and segmentation techniques. In this paper, we introduce a novel algorithm for hyperspectral band selection that couples new attention-based convolutional neural networks used to weight the bands according to their importance with an anomaly detection technique which is exploited for selecting the most important bands. The proposed attention-based approach is data-driven, re-uses convolutional activations at different depths of a deep architecture, identifying the most informative regions of the spectrum. Also, it is modular, easy to implement, seamlessly applicable to any convolutional network, and can be trained end-to-end using gradient descent. Our rigorous experiments, performed over benchmark sets and backed up with statistical tests, showed that the deep models equipped with the attention mechanism are competitive with the state-of-the-art band selection techniques and can work orders or magnitude faster, they deliver high-quality classification, and consistently identify significant bands in the training data, permitting the creation of refined and extremely compact sets that retain the most meaningful features. Also, the attention modules do not deteriorate the classification abilities, and slow down neither training nor inference of the deep models.","Feature extraction,Hyperspectral imaging,Training,Convolutional neural networks,Satellites,Anomaly detection,Attention mechanism,band selection,classification,convolutional neural network,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NONLINEAR,DIMENSIONALITY,REDUCTION,FEATURE-EXTRACTION,IMAGERY,CLASSIFICATION,INFORMATION,SEGMENTATION,ALGORITHM,WAVELET",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09019632.pdf,
64,Stenosis Detection From Time-of-Flight Magnetic Resonance Angiography via Deep Learning 3D Squeeze and Excitation Residual Networks,8,,43325-43335,"Chung Hunjin,Kang Koung Mi,Al-Masni Mohammed A.,Sohn Chul-Ho,Nam Yoonho,Ryu Kanghyun,Kim Dong-Hyun","Chung H,Kang KM,Al-Masni MA,Sohn CH,Nam Y,Ryu K,Kim DH",Kim DH,10.1109/ACCESS.2020.2977669,Yonsei University,"Intracranial artery stenosis is an important public health concern internationally, due to it being one of the major causes of ischemic stroke. In this study, we aim to provide a computer-aided diagnosis algorithm capable of automatically distinguishing between Internal Carotid Artery (ICA) stenosis and normal to minimize the labor-intensiveness of stenosis detection. Using Time-of-Flight Magnetic Resonance Angiography (TOF-MRA), a novel deep learning detection model via 3D Squeeze and Excitation Residual Networks (SE-ResNet) is proposed. Pre-processing of TOF-MRA, data augmentation, training of 3D SE-ResNet, and testing using patch-based and patient-based methods with cross-validation is described. The proposed network using a database consisting of 50 normal cases (ICA-N) and 41 stenosis cases (ICA-S) with grade level of above 30% was evaluated. All 41 ICA-S cases were categorized according to the diameter (D_stenosis) of the artery at the site of the most severe stenosis by expert radiologists, whereas percent stenosis was measured by Warfarin-Aspirin Symptomatic Intracranial Disease (WASID) method. The proposed 3D SE-ResNet was further compared with more conventional networks including 3D ResNet and 3D VGG. The results showed the capability to detect stenosis achieving overall Area Under the Curve (AUC) and accuracies of 0.947 and 91.0% for patch-based and 0.884 and 81.0% for patient-based testing, respectively. In addition, the proposed 3D SE-ResNet achieved better performance against conventional 3D ResNet and 3D VGG with improvement rates of 0.053 and 0.095 for patch-based and 0.053 and 0.065 for patient-based testing in terms of AUC, respectively.","Three-dimensional displays,Machine learning,Angiography,Magnetic resonance,Carotid arteries,Training,Stenosis detection,magnetic resonance angiography,internal carotid artery,deep learning,squeeze and excitation,residual networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ARTERY,STENOSIS,PERFORMANCE,RISK,CT",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09020109.pdf,
65,Detection of Ovarian Tumors in Obstetric Ultrasound Imaging Using Logistic Regression Classifier With an Advanced Machine Learning Approach,8,,44999-45008,"Zhang Zheng,Han Yibo","Zhang Z,Han YB",Zhang Z,10.1109/ACCESS.2020.2977962,Nanyang Institute of Technology,"This paper addresses the use in different stages of pregnancy of ultrasound imaging and to examine the tumors diagnosed during lactation or pregnancy. There are recent advancements in the application of obstetric ultrasound and imaging techniques helpful for improving the outcome of the pregnancy using various Learning techniques. This paper addresses the need to implement sustainable ultrasound standards with an acceptably high maternal and perinatal mortality rates to provide better and more affordable, quality Ultrasonic Flaw (UT) equipment which can improve Obstetric health care. The state-of-the-art learning approach for obstetric ultrasound is a category of methods in machine learning that are gaining popularity and attracting interest in various fields, including image processing and computer vision. In this paper advanced Machine learning processes map a raw input image to the desired output image using logistic regression classifier(LRC) and Convolution neural networks (CNNs) are of particular interest among all Machine learning methods. Furthermore, we have utilized the Internet of Medical Things (IoMT) for obstetric tumor image segmentation and identification of tumors for the medical experts. The experimental results show the LRC based on CNN can be utilized to predict the output of the ultrasound of obstetric with increased maternal and perinatal mobility rates.","Ultrasonic imaging,Tumors,Machine learning,Pregnancy,Logistics,Biomedical imaging,Machine learning,convolution neural network,logistic regression model,obstetric ultrasound,IoMT",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09022980.pdf,
66,Channel-Wise Characterization of High Frequency Oscillations for Automated Identification of the Seizure Onset Zone,8,,45531-45543,"Lai Dakun,Zhang Xinyue,Chen Wenjing,Zhang Heng,Kang Tongzhou,Yuan Han,Ding Lei","Lai DK,Zhang XY,Chen WJ,Zhang H,Kang TZ,Yuan H,Ding L",Lai DK,10.1109/ACCESS.2020.2978290,University of Electronic Science & Technology of China,"High frequency oscillations (HFOs) in intracranial electroencephalography (iEEG) recordings are a promising clinical biomarker that can help define the epileptogenic regions in the brain. The aim of this study is to characterize the spatial and temporal distribution of HFOs in channel-wise instead of event-level as usual and to develop an automated the seizure onset zone (SOZ) identification by using a support vector machine (SVM) approach on the channel-wise features in a short-term recording. In this work, five consecutive patients with medically intractable epilepsy were enrolled. For each patient, ten-minute segments were defined from two hours of iEEG recordings during sleep state. A total of 17 channel-wise features including 6 rate-based, 6 duration-based, 3 amplitude-based, and 2 power-based features of HFOs were extracted from each 10-min segment, which including ripples (Rs, 80-250 Hz) and fast ripples (FRs, 250-500Hz) were detected automatically using validated detectors. Each channel-wise feature was ranked by using the Student & x2019;s t-test method and the most distinctive features were selected to explore the characteristics of HFOs in each channel. A supervised-learning based SVM classifier with the selected channel-wise features or their combinations was developed to identify each channel within the independently clinician-defined SOZ or not. Over 3,816 chanel-10-min segments of iEEG recordings, the evaluated accuracy, sensitivity, and specificity of the proposed approach with the optimal combination of top five ranked features for SOZ identification are 86.6 & x0025;, 73.0 & x0025;, and 94.1 & x0025;, respectively, for ten-fold cross-validation, and 86.0 & x0025;, 79.2 & x0025;, and 91.8 & x0025;, respectively, for the leave-1-out cross-validation. Compared with the recently reported SOZ detectors based on event-wise feature of HFOs, the channel-wise features and the combination with machine learning approach demonstrate its feasibility in SOZ identification with a relative higher performance and potentially reduce the time needed currently for long-term recording and manual inspection.","Hafnium oxide,Feature extraction,Electroencephalography,Electrodes,Epilepsy,Machine learning,Epilepsy,high frequency oscillations (HFOs),intracranial electroencephalograms (iEEG),machine learning,seizure onset zone",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"80-500,HZ,EPILEPSY,SPIKES,AREAS,HFOS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09024013.pdf,
67,Quantum GIS Based Descriptive and Predictive Data Analysis for Effective Planning of Waste Management,8,,46193-46205,"Imran,Ahmad Shabir,Kim Do Hyeun","Imran,Ahmad S,Kim DH",Kim DH,10.1109/ACCESS.2020.2979015,Jeju National University,"Waste has a direct impact on human health and the surrounding environment. Apart from the health aspect, many industries' growth is effected by waste material such as the food industry. Waste management authorities are interested in reducing the cost of waste management operations and searching for sustainable waste management solutions. For effective planning of waste management, reliable data analysis is required to produce results that can facilitate the planning process. Data mining and machine learning-based data analysis over the waste data can produce a more detailed, and in-time waste information generation, which can lead to effectively manage the waste amount of specific area. In this paper, a descriptive data analysis approach, along with predictive analysis, is used to produce in-time waste information. The performance of the proposed approach is evaluated using a real waste dataset of Jeju Island, South Korea. Waste bins are virtualized on its actual location on the Jeju map in Quantum Geographic Information Systems(QGIS) software. The performance results of the predictive analysis models are evaluated in terms of Mean Absolute Error(MAE), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error(MAPE). Performance results indicate that predictive analysis models are reliable for the effective planning and optimization of waste management operations.","Waste monitoring,QGIS,descriptive analytics,predictive analytics,waste management,data analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MUNICIPAL,SOLID-WASTE,CHALLENGES",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09026977.pdf,
68,A Stacked Autoencoder Neural Network Algorithm for Breast Cancer Diagnosis With Magnetic Detection Electrical Impedance Tomography,8,,5428-5437,"Chen Ruijuan,Wu Weiwei,Qi Haofeng,Wang Jinhai,Wang Huiquan","Chen RJ,Wu WW,Qi HF,Wang JH,Wang HQ",Wang HQ,10.1109/ACCESS.2019.2961810,Tiangong University,"Magnetic detection electrical impedance tomography (MDEIT) is a novel imaging technique that aims to reconstruct the conductivity distribution with electrical current injection and the external magnetic flux density measurement by magnetic sensors. Aiming at improving the resolution and accuracy of MDEIT and providing an efficient imaging method for breast cancer diagnosis, a new algorithm based on stacked auto-encoder (SAE) neural network is proposed. Both numerical simulation and phantom experiments are done to verify its feasibility. In the numerical simulation, an amount of sample data with different conductivity distribution are calculated. Then a neural network model is established and trained by training these samples. Finally, the conductivity distribution of an imaging target with the anomaly location can be reconstructed by the network model. The reconstruction result of the SAE algorithm is compared with the reconstruction results of the traditional sensitivity matrix (SM) algorithm and the back propagation (BP) neural network algorithm. Under the noise of 30dB, the relative errors of BP algorithm, SM algorithm and SAE algorithm are 137.19%, 24.90% and 15.28% respectively. Result shows by the SAE algorithm, the location of anomalies is reconstructed more accurately, the conductivity value is more closely to the real one and the anti-noise performance is more robust. At last, a breast phantom experiment by self-made platforms is completed to verify the application feasibility of the new algorithm. The relative reconstruction error of conductivity by proposed SAE algorithm can be reduced to 14.56%. The results show that by SAE algorithm, MDEIT can be a promising approach in clinical diagnosis of breast cancer, and it also provide more potential application prospect for the extensive application of MDEIT.","Breast cancer diagnosis,inverse problem,magnetic detection electrical impedance tomography,stacked auto-encoder",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IMAGE-RECONSTRUCTION,FLUX,DENSITY,CLASSIFICATION,REGULARIZATION,SAE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08939559.pdf,
69,Cross-Comparison of EMG-to-Force Methods for Multi-DoF Finger Force Prediction Using One-DoF Training,8,,13958-13968,"Chen Yuyang,Dai Chenyun,Chen Wei","Chen YY,Dai CY,Chen W",Dai CY; Chen W,10.1109/ACCESS.2020.2966007,Fudan University,"Surface electromyography (sEMG) signal is one of the widely applied biological signals in the research field of the force intention prediction. However, due to the severe cross-talk issue of sEMG signals during fine hand contractions, few studies have related sEMG to multiple degree-of-freedom (DoF) force prediction of individual fingers simultanously. Accordingly, this study proposed methods mainly based on neural networks: Convolutional neural Network (CNN) and Recurrent Neural Network (RNN) to achieve better prediction results. Several improvements on traditional methods are also proposed in this article such as: Common Spatial Pattern (CSP), Softmax function and several new channel selection standards to solve the cross-talk issues for the estimation of EMG-force during multiple finger contractions. High-density sEMG signals of forearm extensor muscles were obtained, and experimental data from seven able-bodied subjects were analyzed. Subjects produced 1-DoF and Multi-DoF forces up to 30 & x0025; maximum voluntary contraction (MVC). Then, the root-mean-square values of sEMG were related to joint force. To realize a better practical use, the EMG-to-force models were trained with minimal numbers of trials (using 1-DoF trials only), then assessed on multi-DoF trials. Our results showed that the proposed modifications on traditional method also made an improvement on the prediction results. Our findings suggest that Multi-DoF control for individual fingers with minimal training procedure (using 1-DoF trials only) may be feasible for practical use. Furthermore, methods based on neural networks greatly outperform traditional methods and the combination of CNN and LSTM showed the best performance.","Neural networks,EMG-force prediction,EMG signal processing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONSTANT-POSTURE,SIGNAL,TORQUE,MODELS,BICEPS,ANGLE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08957037.pdf,
70,Brain Deformable Registration Using Global and Local Label-Driven Deep Regression Learning in the First Year of Life,8,,25691-25705,"Hu Shunbo,Zhang Lintao);,Li Guoqiang);,Liu Mingtao);,Fu Deqian);,Zhang Wenyin","Hu SB,Zhang LT,Li GQ,Liu MT,Fu DQ,Zhang WY",Hu SB,10.1109/ACCESS.2019.2957233,Linyi University,"Accurate medical image registration is highly important for the quantitative analysis of infant brain dynamic development in the first year of life. However, the deformable registration of infant brain magnetic resonance (MR) images is highly challenging for the following two reasons: First, there are very large anatomical and appearance variations in these longitudinal images; Second, there is a one-to-many correspondence in appearance between global anatomical tissues and the small local tissues therein. In this paper, we use a CNN (convolution neural network)-based global-and-local-label-driven deformable registration scheme. Two to-be-registered image patches are input into the UNet-style regression network. Then, a dense displacement field (DDF) between them is obtained by optimizing the total loss function between two corresponding label patches. Global and local label patches are used only during training. During inference, two new MR images are divided into many patch pairs and fed into the trained network. By averaging the deformation of the patches at the same location, the final 3D DDF between the two whole images is obtained. The highlight is that the global (white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF)) and local tissues can be registered simultaneously without any prior ground-truth deformation. Especially for the local hippocampal tissues, the Dice ratios are substantially improved after registration via our method. Experimental results are presented on the intrasubject and intersubject registration of infant brain MR images between different time points, and the intersubject registration of brain T1-weighted MR images on the OASIS-1 dataset, according to which the proposed method realizes higher accuracy on both global and local tissues compared with state-of-the-art registration methods.","Strain,Image registration,Three-dimensional displays,Training,Hippocampus,Image segmentation,Task analysis,Infant brain MR images,deformable registration,label-driven learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IMAGE,REGISTRATION,SEGMENTATION,MRI",IEEE ACCESS,https://doi.org/10.1109/access.2019.2957233,
71,PartMitosis: A Partially Supervised Deep Learning Framework for Mitosis Detection in Breast Cancer Histopathology Images,8,,45133-45147,"Sebai Meriem,Wang Tianjiang,Al-Fadhli Saad Ali","Sebai M,Wang TJ,Al-Fadhli SA",Sebai M; Wang TJ,10.1109/ACCESS.2020.2978754,Huazhong University of Science & Technology,"Detection of mitotic tumor cells per tissue area is one of the critical markers of breast cancer prognosis. The aim of this paper is to develop a method for the automatic detection of mitotic figures from breast cancer histological slides using a partially supervised deep learning framework. Unlike the previous literature, which has focused on solving the problem of mitosis detection in the weakly annotated datasets using centroid pixel labels (weak labels) only without taking advantage of the available pixel-level labels (strong labels) of other datasets, in this paper, we design a novel partially supervised framework based on two parallel deep fully convolutional networks. One of them is trained using weak labels and the other is trained using strong labels, together with a weight transfer function. In the detection phase, we fuse the segmentation maps produced by the two networks to obtain the final mitosis detections. Our system exploits the available large sets of mitosis detection samples with mitosis centroid annotation, such as the 2014 ICPR dataset and the AMIDA13 dataset, and only a small set of samples with the annotation of all mitosis pixels, such as the 2012 ICPR dataset, to perform a more accurate mitosis detection on weakly labeled data. This enables us to outperform all previous mitosis detection systems by achieving -scores of 0.575 and 0.698 on the 2014 ICPR dataset and the AMIDA13 dataset respectively.","Semantics,Image segmentation,Feature extraction,Task analysis,Training,Breast cancer,Machine learning,Mitosis detection,partially supervised learning,breast cancer grading,fully convolutional network,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ARROW,DETECTION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09025206.pdf,
72,Automatic Detection of Semantic Classes of Verb-Noun Collocations,24,1,141-150,"Kolesnikova Olga,Gelbukh Alexander,Chanona-Hernandez Liliana","Kolesnikova O,Gelbukh A,Chanona-Hernandez L",Gelbukh A,10.13053/CyS-24-1-3130,Instituto Politecnico Nacional - Mexico,"It does not surprise us that a bank can be a financial institution as well as a piece of land. Quite often one word is used with different meanings. But sometimes the opposite happens: we choose different words to express the same idea. For example, to give a smile means 'to smile', and to lend support means 'to support' (Longman Dictionary of Contemporary English, 1995). These two collocations convey the same idea: to smile is to 'perform', or 'do' a smile, and to support is to 'do' support, so that both verb-noun collocations share the same semantics: to do what is denoted by the noun. Likewise, we find that to acquire popularity and to sink into despair both mean 'to begin to experience the ', and to establish a relation and to find a solution mean 'to create the '. Such semantic patterns or classes are called lexical functions. In this article, we explain the concept of lexical functions, give a summary of state-of-the-art research on automatic detection of lexical functions, and present the framework and results of our experiments on supervised learning of lexical functions fulfilled on the material of Spanish verb-noun collocations.","Verb-noun collocations,lexical functions,semantic classification",Article,"IPN, CENTRO INVESTIGAVION COMPUTACION, AV JUAN DIOS BATIZ, S N ESQ M OTHON MENDIZABAL, UP ADOLFO LOPEZ MATEOS ZACATENCO, MEXICO CITY, 07738, MEXICO",Computer Science,,,,COMPUTACION Y SISTEMAS,,
73,An ELM-Embedded Deep Learning Based Intelligent Recognition System for Computer Numeric Control Machine Tools,8,,24616-24629,"Luo Luqing,Yang Zhi-Xin,Tang Lulu,Zhang Kun","Luo LQ,Yang ZX,Tang LL,Zhang K",Yang ZX,10.1109/ACCESS.2020.2965284,University of Macau,"In modern manufacturing industry featured with automation and flexibility, the intelligent tool management for Computer Numeric Control (CNC) machine plays an essential role in manufacturing automation. The automatic tool recognition in terms of geometric shapes, materials and usage functions could facilitate the seamless integration with downstream process planning and scheduling processes. In this paper, a intelligent tool recognition system is proposed with a novel hybrid framework of multi-channel deep learning network with non-iterative and fast feedforward neural network to meet high efficiency and accuracy requirement in intelligent manufacturing. The combination of the fine-tuning Convolutional Neural Networks (CNNs) with the random parameter assignment mechanism of Extreme Learning Machines (ELMs) reach a balance in accurate feature extraction and fast recognition. In the proposed hybrid framework, features extracted from efficient CNNs are aggregated into robust ELM auto-encoders (ELM-AEs) to generate the compact but rich feature information, which are then feed to the subsequent single layer ELM network for tool recognition. The performance of proposed framework is verified on several standardized 3D shape retrieval and classification dataset, as well as on a self-constructed multi-view 3D data represented tool library database. Numerical experiments reveal a promising application perspective of proposed intelligent recognition system on manufacturing automation.","CNC tool recognition,hybrid deep learning networks,convolutional neural networks,extreme learning machines auto-encode,tool library database",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NEURAL-NETWORKS,EXTREME,CLASSIFICATION,FRAMEWORK",IEEE ACCESS,https://doi.org/10.1109/access.2020.2965284,
74,Computer-Aided Diagnosis of Chronic Kidney Disease in Developing Countries: A Comparative Analysis of Machine Learning Techniques,8,,25407-25419,"Sobrinho Alvaro,Queiroz Andressa C. M. Da S.,Dias Da Silva Leandro,De Barros Costa Evandro,Eliete Pinheiro Maria,Perkusich Angelo","Sobrinho A,Queiroz ACMD,Da Silva LD,Costa ED,Pinheiro ME,Perkusich A",Sobrinho A,10.1109/ACCESS.2020.2971208,"Fed Univ Agreste Pernambuco, Comp Sci, BR-55292270 Garanhuns, Brazil.","The high incidence and prevalence of chronic kidney disease (CKD), often caused by late diagnoses, is a critical public health problem, especially in developing countries such as Brazil. CKD treatment therapies, such as dialysis and kidney transplantation, increase the morbidity and mortality rates, besides the public health costs. This study analyses the usage of machine learning techniques to assist in the early diagnosis of CKD in developing countries. Qualitative and quantitative comparative analyses are, respectively, conducted using a systematic literature review and an experiment with machine learning techniques, with the k-fold cross-validation method based on the Weka (c) software and a CKD dataset. These analyses enable a discussion on the suitability of machine learning techniques for screening for CKD risk, focusing on low-income and hard-to-reach settings of developing countries, due to the specific problems faced by them, e.g., inadequate primary health care. The study results show that the J48 decision tree is a suitable machine learning technique for such screening in developing countries, due to the easy interpretation of its classification results, with 95.00% accuracy, reaching a nearly perfect agreement with an experienced nephrologist's opinion. Conversely, random forest, naive Bayes, support vector machine, multilayer perceptron, and k-nearest neighbor techniques, respectively, yield 93.33%, 88.33%, 76.66%, 75.00%, and 71.67% accuracy, presenting at least moderate agreement with the nephrologist, at the cost of a more difficult interpretation of the classification results.","Reviews,machine learning,medical diagnosis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"PREDICTION,CREATININE,GUIDELINE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08978522.pdf,
75,Sparse Representation-Based Denoising for High-Resolution Brain Activation and Functional Connectivity Modeling: A Task fMRI Study,8,,36728-36740,"Jeong Seongah,Li Xiang,Yang Jiarui,Li Quanzheng,Tarokh Vahid","Jeong S,Li X,Yang JR,Li QZ,Tarokh V",Li QZ,10.1109/ACCESS.2020.2971261,Harvard University,"In the field of neuroimaging and cognitive neuroscience, functional Magnetic Resonance Imaging (fMRI) has been widely used to study the functional localization and connectivity of the brain. However, the inherently low signal-to-noise ratio (SNR) of the fMRI signals greatly limits the accuracy and resolution of current studies. In addressing this fundamental challenge in fMRI analytics, in this work we develop and implement a denoising method for task fMRI (tfMRI) data in order to delineate the high-resolution spatial pattern of the brain activation and functional connectivity via dictionary learning and sparse coding (DLSC). In addition to the traditional unsupervised dictionary learning model which has shown success in image denoising, we further utilize the prior knowledge of task paradigm to learn a dictionary consisting of both data-driven and model-driven terms for a more stable sparse representation of the data. The proposed method is applied to preprocess the motor tfMRI dataset from Human Connectome Project (HCP) for the purpose of brain activation detection and functional connectivity estimation. Comparison between the results from original and denoised fMRI data shows that the disruptive brain activation and functional connectivity patterns can be recovered, and the prominence of such patterns is improved through denoising. The proposed method is then compared with the temporal non-local means (tNLM)-based denoising method and shows consistently superior performance in various experimental settings. The promising results show that the proposed DLSC-based fMRI denoising method can effectively reduce the noise level of the fMRI signals and increase the interpretability of the inferred results, therefore constituting a crucial part of the preprocessing pipeline and provide the foundation for further high-resolution functional analysis.","Task fMRI,fMRI denoising,dictionary learning and sparse coding",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IDENTIFICATION,SIGNALS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08979389.pdf,
76,Learning to Recognize Chest-Xray Images Faster and More Efficiently Based on Multi-Kernel Depthwise Convolution,8,,37265-37274,"Hu Mengjie,Lin Hezheng,Fan Zimeng,Gao Wenjie,Yang Lu,Liu Chun,Song Qing","Hu MJ,Lin HZ,Fan ZM,Gao WJ,Yang L,Liu C,Song Q",Song Q,10.1109/ACCESS.2020.2974242,Beijing University of Posts & Telecommunications,"The development of convolutional neural networks has promoted the progress of computer-aided diagnostic systems. Details in medical image, such as the texture and tissue structure, are crucial features for diagnosis. Therefore, large input images combined with deep convolution neural networks are adopted to boost the performance in recent research of chest X-ray diagnosis. Meanwhile, due to the variable sizes of thoracic diseases, many researchers have worked to introduce additional module to capture multi-scale feature of images in CNN. However, these efforts hardly consider the computational costs of large inputs and introduced additional modules. This paper aims to automatically diagnose diseases on chest X-rays images quickly and effectively. We propose the multi-kernel depthwise convolution(MD-Conv) which contains depthwise convolution kernels with different filter sizes in one depthwise convolution layer. MD-Conv has high calculation efficiency and few parameters. Because its ability to learn multi-scale feature based on the multi-size kernels, it is appropriate for medical images diagnosis tasks in which abnormalities varied in sizes. In addition, larger depthwise convolution kernels are adopted in MD-Conv to obtain a larger receptive field efficiently, which can ensure sufficient receptive field for high resolution inputs. MD-Conv can be easily applied in modern lightweight networks to replace the normal depthwise convolution layer. We conduct experiments on the Chest X-ray 14 Dataset, which is the largest available chest x-ray dataset, and obtain competitive results. We also evaluate the MD-Conv on the new released dataset for pediatric pneumonia diagnosis. We obtain a better performance of 98.3% AUC than original paper (96.8%) for recognize pneumonia versus normal. Meanwhile we compare the FLOPs and Params of different models to show their efficiency for chest X-rays recognition.","Chest x-ray recognition,lightweight networks,multi-kernels depthwise convolution",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://doi.org/10.1109/access.2020.2974242,
77,Non-Local Attention and Densely-Connected Convolutional Neural Networks for Malignancy Suspiciousness Classification of Gastric Ulcer,8,,15812-15822,"Sun Muyi,Liang Kaiyi,Zhang Wenbao,Chang Qing,Zhou Xiaoguang","Sun MY,Liang KY,Zhang WB,Chang Q,Zhou XG",Chang Q,10.1109/ACCESS.2020.2967350,"Shanghai Univ Med & Hlth Sci, Jiading Dist Cent Hosp Affiliated, Dept Radiol, Shanghai Gen Practice Med Educ & Res Ctr, Shanghai 201800, Peoples R China.","Gastric ulcer is one of the most common types of stomach disease. Malignancy suspiciousness classification of gastric ulcer is a crucial indicator for early cancer detection and prognosis. Technically, this problem suffers from the complexity and variability of endoscopic pathological images. For addressing these challenges, we propose a deep learning based classification neural network which combines the densely-connected architecture and non-local attention mechanism. Structurally, we add the attention block into the cascaded dense blocks for catching more contextual information and enhancing the correlation between pixels and regions. Experimentally, we implement sufficient experiments on our own gastroscopic image dataset, which is delicately annotated twice per image by medical specialists. Quantitative comparisons against several prior state-of-the-art methods demonstrate the superiority of our approach. As a result, we achieve an overall diagnostic accuracy of 96.79 %, a recall of 94.92% and an F1-score of 94.70 %, close to the diagnostic level of a gastroenterologist. The area under the receiver operating characteristic (ROC) curves of the deep learning model achieve an average of 0.93.","Gastric ulcer,attention mechanism,malignancy suspiciousness classification,densely-connected neural network,medical image analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SYSTEM,TUMOR",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08962033.pdf,
78,Medical Image Classification Using a Light-Weighted Hybrid Neural Network Based on PCANet and DenseNet,8,,24697-24712,"Huang Zhiwen,Zhu Xingxing,Ding Mingyue,Zhang Xuming","Huang ZW,Zhu XX,Ding MY,Zhang XM",Zhang XM,10.1109/ACCESS.2020.2971225,Huazhong University of Science & Technology,"Medical image classification plays an important role in disease diagnosis since it can provide important reference information for doctors. The supervised convolutional neural networks (CNNs) such as DenseNet provide the versatile and effective method for medical image classification tasks, but they require large amounts of data with labels and involve complex and time-consuming training process. The unsupervised CNNs such as principal component analysis network (PCANet) need no labels for training but cannot provide desirable classification accuracy. To realize the accurate medical image classification in the case of a small training dataset, we have proposed a light-weighted hybrid neural network which consists of a modified PCANet cascaded with a simplified DenseNet. The modified PCANet has two stages, in which the network produces the effective feature maps at each stage by convoluting inputs with various learned kernels. The following simplified DenseNet with a small number of weights will take all feature maps produced by the PCANet as inputs and employ the dense shortcut connections to realize accurate medical image classification. To appreciate the performance of the proposed method, some experiments have been done on mammography and osteosarcoma histology images. Experimental results show that the proposed hybrid neural network is easy to train and it outperforms such popular CNN models as PCANet, ResNet and DenseNet in terms of classification accuracy, sensitivity and specificity.","Medical image classification,hybrid neural network,PCANet,DenseNet",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ORIENTED,GRADIENTS,CANCER,DIAGNOSIS,FEATURES,HISTOGRAMS,TUMOR,SCALE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/08979430.pdf,
79,Color Space Transformation and Multi-Class Weighted Loss for Adhesive White Blood Cell Segmentation,8,,24808-24818,"Li Huiying,Zhao Xiaoqing,Su Anyang,Zhang Haitao,Liu Jingxin,Gu Guiying","Li HY,Zhao XQ,Su AY,Zhang HT,Liu JX,Gu GY",Li HY,10.1109/ACCESS.2020.2970485,Jilin University,"White blood cells (WBCs) are the cells of immune system, protecting against infective diseases and invasion of viruses and bacteria. Their aberrant number, both abnormal increase and decrease, is a sign of an ongoing pathology, a precise evaluation of their number is of the utmost importance as the first step of assessing a potential disease. In blood cell microscopic images, since red blood cells and platelets are similar in color with WBCs, and WBCs are partially adhesive, WBC segmentation for counting is often not resulting in a good performance. Therefore, in this work, a color space transformation is proposed to filter out red blood cells and platelets, which is transforming the blood cell microscopic images of patients with acute lymphoblastic leukemia from RGB color space to HSV to detect and extract WBCs. For precisely segmenting adhesive WBCs in extraction results, we set cell border to the third class, in addition to foreground and background. A weighted cross-entropy loss function based on class weight and distance transformation weight enhanced U-Net to learn cell border features. Our results showed that the method proposed in this paper for WBC segmentation using the data set ALL_IDB1 could achieve an accuracy of 97.92%.","Color space transformation,multi-class segmentation,white blood cell segmentation,weighted loss function",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IMAGES,CLASSIFICATION,ALGORITHM,MODEL",IEEE ACCESS,https://doi.org/10.1109/access.2020.2970485,
80,Review of Crystal Density Prediction Methods for Energetic Materials,28,1,1-12,",,,,","Wang Lili,Xiong Ying,Xie Weiyu,Niu Liangliang,Zhang Chaoyang",,,Wang Lili,"Crystal density is an important parameter for predicting the detonation performance of energetic materials (EMs). Many studies have shown that the theoretical calculation methods are able to figure out accurate densities of CHNO contained EMs. In this work,we overview and categorize some reliable crystal density calculation methods,including isosurface of electron density method,group addition method,molecular surface electrostatic potentials method,crystal packing method and quantitative structure-property relationship method. Among these methods,the effectiveness of molecular volume-based methods depends on its capability to estimate inter-and intramolecular interactions. It is challenging to accurately describe the hydrogen bonding and van der Waals interactions. Due to the huge structure group spaces and highly complex potential energy surface, the crystal packing methods based on empirical forcefields are computationally expensive and lacking accuracy usually. The group addition approach cannot distinguish conformers and polymorphs,and may be unreliable for novel or special energetic materials,which are absent from accurate empirical parameters. The disadvantage of quantitative structure-property relationship method is that it is difficult to give the physical meaning of the equation. The bottleneck of insufficient experimental data and poor model accuracy needs to be solved. Nevertheless,numerous artificial intelligence methods,such as artificial neural networks,genetic algorithm,multiple linear regression,machine learning,have made great achievements in the relationship between properties and structure,facilitating the development of energetic materials based on the materials genome concept and serving as a main tendency in future.",energetic materials; density prediction methods; crystal structure prediction,Review,,,,,,,,
81,Optimizing an ANN model with genetic algorithm (GA) predicting load-settlement behaviours of eco-friendly raft-pile foundation (ERP) system,36,1,421-433,"Liu Longqi,Moayedi Hossein,Rashid Ahmad Safuan A.,Rahman Siti Saimah Abdul,Nguyen Hoang","Liu LQ,Moayedi H,Rashid ASA,Rahman SSA,Nguyen H",Moayedi H,10.1007/s00366-019-00767-4,Ton Duc Thang University,"Eco-friendly raft-pile foundation (ERP) system is one of the most recent developed types of pile foundations that the original materials can be provided from local Bakau. A precise prediction of its behaviour is of interest for many engineers. This paper presents three intelligent systems, namely, adaptive neuro-fuzzy inference system (ANFIS), conventional artificial neural network (ANN), and optimized ANN model with genetic algorithm (GA) for prediction of vertical settlement in ERP system. In this regard, a database compiled from 43 load-settlement results obtained from full-scale maintained load test (PLT). Note that, these floating raft-pile system piles were subjected to vertical axial loading. The ERP system was installed at the marine soft clay soil site at Rantau Panjang Kapar, Selangor, Malaysia. The values of subgrade modulus (K-s), Young's modulus (E-s), soil properties beneath the footing, and applied load were set as model input to predict vertical settlement (s). To evaluate the reliability of the network output, several well-known statistical indexes were used. The results show that the new proposed GA-ANN model could provide a better performance in estimating the maximum settlement of ERP system. In terms of statistical indexes (R-2, and RMSE), the values of (0.998, 0.0259, and 99.99) and (0.997, 0.0324, and 99.998) were obtained for both data sets of training and testing, respectively. Besides, comparing the training and testing data sets, R-2 values of (0.994, 0.9884, 0.995, and 0.9984) and (0.996, 0.985, 0.994, and 0.9973) were found for ANN-LMBP, ANFIS, GA, and GA-ANN models, respectively, which proves the superiority of the proposed GA-ANN model comparing to other methods.","Genetic algorithm,GA-ANN,ANFIS,ANN,ERP system",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Computer Science,Engineering",,6.544,"BEARING,CAPACITY,FREQUENCY,RATIO,FUZZY,MODEL,SOIL,OPTIMIZATION,LIQUEFACTION,PERMEABILITY,PERFORMANCE,STRENGTH,ANFIS",ENGINEERING WITH COMPUTERS,,
82,The Study of Generic Model Set for Reducing Calibration Time in P300-Based Brain-Computer Interface,28,1,3-12,"Jin Jing,Li Shurui,Daly Ian,Miao Yangyang,Liu Chang,Wang Xingyu,Cichocki Andrzej","Jin J,Li SR,Daly I,Miao YY,Liu C,Wang XY,Cichocki A",Jin J,10.1109/TNSRE.2019.2956488,East China University of Science & Technology,"P300-based brain-computer interfaces (BCIs) provide an additional communication channel for individuals with communication disabilities. In general, P300-based BCIs need to be trained, offline, for a considerable period of time, which causes users to become fatigued. This reduces the efficiency and performance of the system. In order to shorten calibration time and improve system performance, we introduce the concept of a generic model set. We used ERP data from 116 participants to train the generic model set. The resulting set consists of ten models, which are trained by weighted linear discriminant analysis (WLDA). Twelve new participants were then invited to test the validity of the generic model set. The results demonstrated that all new participants matched the best generic model. The resulting mean classification accuracy equaled 80% after online training, an accuracy that was broadly equivalent to the typical training model method. Moreover, the calibration time was shortened by 70.7% of the calibration time of the typical model method. In other words, the best matching model method only took 81s to calibrate, while the typical model method took 276s. There were also significant differences in both accuracy and raw bit rate between the best and the worst matching model methods. We conclude that the strategy of combining the generic models with online training is easily accepted and achieves higher levels of user satisfaction (as measured by subjective reports). Thus, we provide a valuable new strategy for improving the performance of P300-based BCI.","P300 speller,brain computer interface,WLDA,generic model set,matching method,online training strategy",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"FEATURE-EXTRACTION,P300,PERFORMANCE,ERP,COMMUNICATION,RECOGNITION",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,http://repository.essex.ac.uk/30517/1/The_Study_of_Generic_Model_Set_for_Reducing_Calibration_Time_in_P300-Based_BrainComputer_Interface.pdf,
83,A Dual-Modal Attention-Enhanced Deep Learning Network for Quantification of Parkinson's Disease Characteristics,28,1,42-51,"Xia Yi,Yao ZhiMing,Ye Qiang,Cheng Nan","Xia Y,Yao ZM,Ye Q,Cheng N",Xia Y,10.1109/TNSRE.2019.2946194,Anhui University,"It is well known that most patients with Parkinson's disease (PD) have different degree of movement disorders, such as shuffling, festination and akinetic episodes, which could degenerate the life quality of PD patients. Therefore, it is very useful to develop a computerized tool to provide an objective evaluation of PD patients' gait. In this study, we implemented a novel gait evaluating approach to provide not only a binary classification of PD gaits and normal walking, but also a quantification of the PD gaits to relate them to the PD severity level. The proposed system is a dual-modal deep-learning-based model, where left and right gait is modeled separately by a convolutional neural network (CNN) followed by an attention-enhanced long short-term memory (LSTM) network. The left and right samples for model training and testing were segmented sequentially from multiple 1D vertical ground reaction force (VGRF) signals according to the detected gait cycle. Experimental results indicate that our model can provide state-of-the-art performance in terms of classification accuracy. It is expected that the proposed model can be a useful gait assistance to provide a quantitative evaluation of PD gaits with high confidence and accuracy if trained suitably.","Parkinson's disease (PD),attention mechanism,classification,long short-term memory (LSTM),vertical ground reaction force (VGRF)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"GAIT,VARIABILITY,COMPONENTS,DISORDERS,ASYMMETRY,DIAGNOSIS,TREMOR,SCALE",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
84,Anomaly Detection of Moderate Traumatic Brain Injury Using Auto-Regularized Multi-Instance One-Class SVM,28,1,83-93,"Rasheed Waqas,Tang Tong Boon","Rasheed W,Tang TB",Tang TB,10.1109/TNSRE.2019.2948798,Universiti Teknologi Petronas,"Detection and quantification of functional deficits due to moderate traumatic brain injury (mTBI) is crucial for clinical decision-making and timely commencement of functional therapy. In this work, we explore magnetoencephalography (MEG) based functional connectivity features i.e. magnitude squared coherence(MSC) and phase lag index (PLI) to quantify synchronized brain activity patterns as a means to detect functional deficits. We propose a multi-instance one-class support vector machine (SVM) model generated from a healthy control population. Any dispersion from the decision boundary of the model would be identified as an anomaly instance of mTBI case (Glasgow Coma Scale, GCS score between 9 and 13). The decision boundary was optimized by considering the closest anomaly (GCS = 13) from the negative class as a support vector. Validated against magnetic resonance imaging (MRI) data, the proposed model at high beta band yielded an accuracy of 94.19% and a sensitivity of 90.00%, when tested with our mTBI dataset. The results support the suggestion of multi-instance one-class SVM for the detection of mTBI.","Neural imaging,medical diagnosis,machine learning,neurorehabilitation,anomaly detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"FUNCTIONAL,CONNECTIVITY,MACHINE,MILD,MAGNETOENCEPHALOGRAPHY,SUPPORT",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
85,A Subject-Transfer Framework Based on Single-Trial EMG Analysis Using Convolutional Neural Networks,28,1,94-103,"Kim Keun-Tae,Guan Cuntai,Lee Seong-Whan","Kim KT,Guan CT,Lee SW",Lee SW,10.1109/TNSRE.2019.2946625,Korea University,"In recent years, electromyography (EMG)-based practical myoelectric interfaces have been developed to improve the quality of daily life for people with physical disabilities. With these interfaces, it is very important to decode a user's movement intention, to properly control the external devices. However, improving the performance of these interfaces is difficult due to the high variations in the EMG signal patterns caused by intra-user variability. Therefore, this paper proposes a novel subject-transfer framework for decoding hand movements, which is robust in terms of intra-user variability. In the proposed framework, supportive convolutional neural network (CNN) classifiers, which are pre-trained using the EMG data of several subjects, are selected and fine-tuned for the target subject via single-trial analysis. Then, the target subject's hand movements are classified by voting the outputs of the supportive CNN classifiers. The feasibility of the proposed framework is validated with NinaPro databases 2 and 3, which comprise 49 hand movements of 40 healthy and 11 amputee subjects, respectively. The experimental results indicate that, when compared to the self-decoding framework, which uses only the target subject's data, the proposed framework can successfully decode hand movements with improved performance in both healthy and amputee subjects. From the experimental results, the proposed subject-transfer framework can be seen to represent a useful tool for EMG-based practical myoelectric interfaces controlling external devices.","Subject-transfer framework,myoelectric interfaces,electromyography,convolutional neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"OF-THE-ART,PATTERN-RECOGNITION,REAL-TIME,MYOELECTRIC,CONTROL,SIGNALS",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
86,Accurate Ambulatory Gait Analysis in Walking and Running Using Machine Learning Models,28,1,191-202,"Zhang Huanghe,Guo Yi,Zanotto Damiano","Zhang HH,Guo Y,Zanotto D",Zanotto D,10.1109/TNSRE.2019.2958679,Stevens Institute of Technology,"Wearable sensors have been proposed as alternatives to traditional laboratory equipment for low-cost and portable real-time gait analysis in unconstrained environments. However, the moderate accuracy of these systems currently limits their widespread use. In this paper, we show that support vector regression (SVR) models can be used to extract accurate estimates of fundamental gait parameters (i.e., stride length, velocity, and foot clearance), from custom-engineered instrumented insoles (SportSole) during walking and running tasks. Additionally, these learning-based models are robust to inter-subject variability, thereby making it unnecessary to collect subject-specific training data. Gait analysis was performed in N=14 healthy subjects during two separate sessions, each including 6-minute bouts of treadmill walking and running at different speeds (i.e., 85% and 115% of each subject's preferred speed). Gait metrics were simultaneously measured with the instrumented insoles and with reference laboratory equipment. SVR models yielded excellent intraclass correlation coefficients (ICC) in all the gait parameters analyzed. Percentage mean absolute errors (MAE%) in stride length, velocity, and foot clearance obtained with SVR models were 1.37%+/- 0.49%, 1.23%+/- 0.27%, and 2.08%+/- 0.72% for walking, 2.59%+/- 0.64%, 2.91%+/- 0.85%, and 5.13%+/- 1.52% for running, respectively. These findings provide evidence that machine learning regression is a promising new approach to improve the accuracy of wearable sensors for gait analysis.","Ambulatory gait analysis,wearable technology,instrumented footwear",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"STRIDE,LENGTH,WEARABLE,SENSOR,SYSTEM,FOOT,VALIDATION,KINEMATICS,PARAMETERS,CLASSIFICATION,RECOGNITION,DISORDERS",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
87,Deep Channel-Correlation Network for Motor Imagery Decoding From the Same Limb,28,1,297-306,"Ma Xuelin,Qiu Shuang,Wei Wei,Wang Shengpei,He Huiguang","Ma XL,Qiu S,Wei W,Wang SP,He HG",He HG,10.1109/TNSRE.2019.2953121,"Chinese Acad Sci CASIA, Inst Automat, Natl Lab Pattern Recognit, Res Ctr Brain Inspired Intelligence, Beijing 100190, Peoples R China.","Motor imagery (MI) is an important brain-computer interface (BCI) paradigm, which can be applied without external stimulus. Imagining different joint movements from the same limb allows intuitive control of the outer devices. However, few researches focused on this field, and the decoding accuracy limited the applications for practical use. In this study, we aim to use deep learning methods to explore the ceiling of the decoding performance of three tasks: the resting state, the MI of right hand and right elbow. To represent the brain functional relationships, the correlation matrix that consists of correlation coefficients between electrodes (channels) was calculated as features. We proposed the Channel-Correlation Network to learn the overall representation among channels for classification. Ensemble learning was applied to integrate the output of multiple Channel-Correlation Networks. Our proposed method achieved the decoding accuracy of up to 87.03% in the 3-class scenario. The results demonstrated the effectiveness of deep learning method for decoding MI of different joints from the same limb and the potential of this fine paradigm to be applied in practice.","Channel-correlation network,electroen-cephalography (EEG),ensemble learning,fine motor imagery,same limb",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"SINGLE-TRIAL,EEG,CONVOLUTIONAL,NEURAL-NETWORKS,FEATURE-EXTRACTION,CLASSIFICATION,DYNAMICS,MACHINE,REAL",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
88,A multi-scale framework with unsupervised joint training of convolutional neural networks for pulmonary deformable image registration,65,1,,"Jiang Zhuoran,Yin Fang-Fang,Ge Yun);,Ren Lei","Jiang ZR,Yin FF,Ge Y,Ren L",Ren L,10.1088/1361-6560/ab5da0,Duke University,"To achieve accurate and fast deformable image registration (DIR) for pulmonary CT, we proposed a Multi-scale DIR framework with unsupervised Joint training of Convolutional Neural Network (MJ-CNN). MJ-CNN contains three models at multi-scale levels for a coarse-to-fine DIR to avoid being trapped in a local minimum. It is trained based on image similarity and deformation vector field (DVF) smoothness, requiring no supervision of ground-truth DVF. The three models are first trained sequentially and separately for their own registration tasks, and then are trained jointly for an end-to-end optimization under the multi-scale framework. In this study, MJ-CNN was trained using public SPARE 4D-CT data. The trained MJ-CNN was then evaluated on public DIR-LAB 4D-CT dataset as well as clinical CT-to-CBCT and CBCT-to-CBCT registration. For 4D-CT inter-phase registration, MJ-CNN achieved comparable accuracy to conventional iteration optimization-based methods, and showed the smallest registration errors compared to recently published deep learning-based DIR methods, demonstrating the efficacy of the proposed multi-scale joint training scheme. Besides, MJ-CNN trained using one dataset (SPARE) could generalize to a different dataset (DIR-LAB) acquired by different scanners and imaging protocols. Furthermore, MJ-CNN trained on 4D-CTs also performed well on CT-to-CBCT and CBCT-to-CBCT registration without any re-training or fine-tuning, demonstrating MJ-CNN's robustness against applications and imaging techniques. MJ-CNN took about 1.4 s for DVF estimation and required no manual-tuning of parameters during the evaluation. MJ-CNN is able to perform accurate DIR for pulmonary CT with nearly real-time speed, making it very applicable for clinical tasks.","deformable image registration,multi-scale framework,joint training,convolutional neural network,unsupervised learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,,PHYSICS IN MEDICINE AND BIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7255696,
89,Statistical evaluation of Q factors of fabricated photonic crystal nanocavities designed by using a deep neural network,13,1,,"Nakada Masahiro,Tanaka Kengo,Asano Takashi,Takahashi Yasushi,Noda Susumu","Nakada M,Tanaka K,Asano T,Takahashi Y,Noda S",Nakada M; Asano T,10.7567/1882-0786/ab5978,Kyoto University,"Photonic crystal (PC) nanocavities with ultra-high quality (Q) factors and small modal volumes enable advanced photon manipulations, such as photon trapping. In order to improve the Q factors of such nanocavities, we have recently proposed a cavity design method based on machine learning. Here, we experimentally compare nanocavities designed by using a deep neural network with those designed by the manual approach that enabled a record value. Thirty air-bridge-type two-dimensional PC nanocavities are fabricated on silicon-on-insulator substrates, and their photon lifetimes are measured. The realized median Q factor increases by about one million by adopting the machine-learning-based design approach. (c) 2019 The Japan Society of Applied Physics","VISUALIZATION,DEVICES,DEFECT",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,2.77,"VISUALIZATION,DEVICES,DEFECT",APPLIED PHYSICS EXPRESS,https://repository.kulib.kyoto-u.ac.jp/dspace/bitstream/2433/245624/1/1882-0786ab5978.pdf,
90,Deep learning based crack damage detection technique for thin plate structures using guided lamb wave signals,29,1,,"Liu Heng,Zhang Yunfeng","Liu H,Zhang YF",Zhang YF,10.1088/1361-665X/ab58d6,University System of Maryland,"In this paper, convolutional neural network (CNN) is employed for crack damage detection in thin aluminum plates. Identifying a successful damage feature is a critical step in computationally efficient damage detection and characterization process; however, such feature identification process is generally time-consuming and often difficult to execute. The CNN model is a deep learning model that can be trained to represent high dimensional data for which traditional mathematical model is ill to describe. This study first formalizes the nondestructive evaluation (NDE) problem of notch-type crack damage detection in thin metal plates into an image classification problem in the machine learning domain, which is then solved with a deep CNN model trained using Lamb wave data converted images. Analytical formulas have been derived for generating Lamb wave signals subsequently used for training and validation test of the proposed crack damage detection technique for thin metal plates. Experimental test data from aluminum plate with simulated notch damage has also been used to independently validate the CNN model. The study results show its potential as a promising NDE tool for crack damage detection in thin plate structures.","nondestructive evaluation,machine learning,damage detection,convolutional neural network,ultrasonic surface wave",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Instruments & Instrumentation,Materials Science",,3.893,"EXCITATION,SENSORS",SMART MATERIALS AND STRUCTURES,,
91,Present Research Situation and Prospect of Multi-Scale Design in Novel Co-Based Superalloys: A Review,56,1,1-20,"Liu Xingjun,Chen Yuechao,Lu Yong,Han Jiajia,Xu Weiwei,Guo Yihui,Yu Jinxin,Wei Zhenbang,Wang Cuiping","Liu XJ,Chen YC,Lu Y,Han JJ,Xu WW,Guo YH,Yu JX,Wei ZB,Wang CP",Liu XJ,10.11900/0412.1961.2019.00159,Harbin Institute of Technology,"In recent years, the development of material genetic methods, together with multi-scale material design theory and calculation methods has provided new ideas for the alloy design of novel Co-based superalloys. Based on the published results of multi-scale design and the research work of our lab- oratory, this paper systematically summarizes the present research status of multi-scale design methods in the field of novel Co-based superalloys. A review of multi-scale calculation methods including first-principle calculation, CALPHAD, phase field simulation, and machine learning is presented in this paper. The development trend of multi-scale design in novel Co-based superalloys is prospected.","superalloy,multi-scale design,computational materials science,materials genome",Review,"SCIENCE PRESS, 16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA",Metallurgy & Metallurgical Engineering,,1.118,"PHASE-FIELD,SIMULATION,AL-W,MECHANICAL-PROPERTIES,DIFFUSION-COEFFICIENTS,ALLOYING,ELEMENTS,ATOMIC,MOBILITIES,COMPREHENSIVE,1ST-PRINCIPLES,THERMODYNAMIC,CALCULATION,IMPURITY,DIFFUSION,ELASTIC,PROPERTIES",ACTA METALLURGICA SINICA,,
92,"Ensemble data mining modeling in corrosion of concrete sewer: A comparative study of network-based (MLPNN & RBFNN) and tree-based (RF, CHAID, & CART) models",43,,,"Zounemat-Kermani Mohammad,Stephan Dietmar,Barjenbruch Matthias,Hinkelmann Reinhard","Zounemat-Kermani M,Stephan D,Barjenbruch M,Hinkelmann R",Zounemat-Kermani M,10.1016/j.aei.2019.101030,Shahid Bahonar University of Kerman (SBUK),"This research aims to evaluate ensemble learning (bagging, boosting, and modified bagging) potential in predicting microbially induced concrete corrosion in sewer systems from the data mining (DM) perspective. Particular focus is laid on ensemble techniques for network-based DM methods, including multi-layer perceptron neural network (MLPNN) and radial basis function neural network (RBFNN) as well as tree-based DM methods, such as chi-square automatic interaction detector (CHAID), classification and regression tree (CART), and random forests (RF). Hence, an interdisciplinary approach is presented by combining findings from material sciences and hydrochemistry as well as data mining analyses to predict concrete corrosion. The effective factors on concrete corrosion such as time, gas temperature, gas-phase H2S concentration, relative humidity, pH, and exposure phase are considered as the models' inputs. All 433 datasets are randomly selected to construct an individual model and twenty component models of boosting, bagging, and modified bagging based on training, validating, and testing for each DM base learners. Considering some model performance indices, (e.g., Root mean square error, RMSE; mean absolute percentage error, MAPE; correlation coefficient, r) the best ensemble predictive models are selected. The results obtained indicate that the prediction ability of the random forests DM model is superior to the other ensemble learners, followed by the ensemble Bag-CHAID method. On average, the ensemble tree-based models acted better than the ensemble network-based models; nevertheless, it was also found that taking the advantages of ensemble learning would enhance the general performance of individual DM models by more than 10%.","Concrete corrosion,Machine learning,Soft computing,Sewer systems,Artificial intelligence",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Computer Science,Engineering",,5.936,"ARTIFICIAL,NEURAL-NETWORKS,CLASSIFICATION,DETERIORATION,PREDICTION,PIPES",ADVANCED ENGINEERING INFORMATICS,,
93,Machine learning derived input-function in a dynamic F-18-FDG PET study of mice,6,1,,"Kuttner Samuel,Wickstrom Kristoffer Knutsen,Kalda Gustav,Dorraji S. Esmaeil,Martin-Armas Montserrat,Oteiza Ana,Jenssen Robert,Fenton Kristin,Sundset Rune,Axelsson Jan","Kuttner S,Wickstrom KK,Kalda G,Dorraji SE,Martin-Armas M,Oteiza A,Jenssen R,Fenton K,Sundset R,Axelsson J",Kuttner S,10.1088/2057-1976/ab6496,UiT The Arctic University of Tromso,"Tracer kinetic modelling, based on dynamic F-18-fluorodeoxyglucose (FDG) positron emission tomography (PET) is used to quantify glucose metabolism in humans and animals. Knowledge of the arterial input-function (AIF) is required for such measurements. Our aim was to explore two non-invasive machine learning-based models, for AIF prediction in a small-animal dynamic FDG PET study. 7 tissue regions were delineated in images from 68 FDG PET/computed tomography mouse scans. Two machine learning-based models were trained for AIF prediction, based on Gaussian processes (GP) and a long short-term memory (LSTM) recurrent neural network, respectively. Because blood data were unavailable, a reference AIF was formed by fitting an established AIF model to vena cava and left ventricle image data. The predicted and reference AIFs were compared by the area under curve (AUC) and root mean square error (RMSE). Net-influx rate constants, K-i, were calculated with a two-tissue compartment model, using both predicted and reference AIFs for three tissue regions in each mouse scan, and compared by means of error, ratio, correlation coefficient, P value and Bland-Altman analysis. The impact of different tissue regions on AIF prediction was evaluated by training a GP and an LSTM model on subsets of tissue regions, and calculating the RMSE between the reference and the predicted AIF curve. Both models generated AIFs with AUCs similar to reference. The LSTM models resulted in lower AIF RMSE, compared to GP. K-i from both models agreed well with reference values, with no significant differences. Myocardium was highlighted as important for AIF prediction, but AIFs with similar RMSE were obtained also without myocardium in the input data. Machine learning can be used for accurate and non-invasive prediction of an image-derived reference AIF in FDG studies of mice. We recommend the LSTM approach, as this model predicts AIFs with lower errors, compared to GP.","PET,input-function,machine learning,compartment modelling",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Radiology, Nuclear Medicine & Medical Imaging",,,"PARTIAL-VOLUME,CORRECTION,BLOOD,QUANTIFICATION,SIMULATION,IMAGES",BIOMEDICAL PHYSICS & ENGINEERING EXPRESS,https://munin.uit.no/bitstream/10037/20448/3/article.pdf,
94,"Combining of Multiple Deep Networks via Ensemble Generalization Loss, Based on MRI Images, for Alzheimer's Disease Classification",27,,206-210,"Choi Jae Young,Lee Bumshik","Choi JY,Lee BH",Lee BH,10.1109/LSP.2020.2964161,Chosun University,"This letter proposes a novel way of using an ensemble of multiple deep convolutional neural networks (DCNNs) for Alzheimer's disease classification, based on magnetic resonance imaging (MRI) images. To create this ensemble of DCNNs, we propose to combine the use of multiple MRI projections (as input) with that of different DCNN architectures to increase the deep ensemble diversity. In particular, to find the optimal fusion weights of the DCNN members, we designed a novel deep ensemble generalization loss, which accounts for interaction and cooperation during the optimal weight search. The optimization framework, equipped with our ensemble generalization loss, was formulated and solved using the sequential quadratic programming. Through this method, we achieved optimal DCNN fusion weights (i.e., a high generalization performance). The experimental results showed that our proposed DCNN ensemble outperforms current deep learning-based methods: it is able to produce state-of-the-art results on the Alzheimer's disease neuroimaging initiative (ADNI) dataset.","Alzheimer's disease classification,ensemble deep learning,generalization loss",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,3.586,,IEEE SIGNAL PROCESSING LETTERS,,
95,Atlas-Based Multiorgan Segmentation for Dynamic Abdominal PET,4,1,50-62,"Ren Silin,Laub Priscille,Lu Yihuan,Naganawa Mika,Carson Richard E.","Ren SL,Laub P,Lu YH,Naganawa M,Carson RE",Ren SL,10.1109/TRPMS.2019.2926889,Yale University,"Region of interest (ROI) delineation is required to extract tissue time-activity curves (TACs) in dynamic PET studies, to analyze functional changes or estimate physiological parameters. In this paper, we present an automatic framework for atlas-based multiorgan segmentation in abdominal dynamic PET images with three different methods (4D-pair, 4D-PCA, and 3-D), incorporating probabilistic atlas information into the segmentation as a spatial prior using maximum a posteriori (MAP) estimation. Due to different tracer kinetics in each organ, PET images from different time periods post injection (p.i.) have great intensity differences. Thus, when dynamic images are available, to use this temporal information, two strategies can be employed. First, tissue activities from two frames with highly different activity distributions were selected, namely, an early 8-10 min p.i. and a late 55-60 min p.i. frame, and modeled as a bivariate Gaussian distribution. Theoretically, this method can be applied if more than one frame of data is available. Second, principal component analysis (PCA) was applied to the full series of dynamic images to extract two images corresponding to the first two components. When dynamic image series are not available, the segmentation framework can be scaled down to 3-D, by building a univariate Gaussian distribution based on one 3-D image. The final segmentation results for all three methods were determined by optimizing the MAP-based energy function with two hyperparameters (lambda(l), eta) by multilabel graph cuts. We performed hyperparameter optimization and evaluated the proposed segmentation methods of 4D-pair and 4D-PCA by leave-one-out cross-validation using 30 sets of 4-D abdominal 18F-FP-(+)-DTBZ PET images. To evaluate segmentation results, the pancreas and spleen TACs were extracted, and the percentage error between the area under curve (AUC) of the TACs extracted by manual and automated segmentations was determined. The 4D-pair method with the hyperparameter combination of (lambda_l = 0.1, eta = 1) yielded the best performance. TAC AUC %error results with PCA-based methods showed slightly higher %error than 4D-pair. The 3-D method showed much larger %error than the other two methods. The 4D-pair results agreed well with the manual segmentation, with mean pancreas and spleen TAC AUC %errors of 0.3 +/- 3.3% and -0.4 +/- 8.1%, respectively. In addition, the distribution volume (V-T) values of pancreas and spleen were determined by kinetic modeling using TACs from either manual or automated segmentations. There were no significant differences between manual- and auto-V-T values (p values of 0.14 and 0.74 for pancreas and spleen, respectively). Thus, the proposed automated segmentation method can provide robust and reliable ROIs of the pancreas and spleen for kinetic modeling.","Image segmentation,machine learning,maximum a posteriori estimation,positron emission tomography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"RESPIRATORY,MOTION,IMAGES,TOMOGRAPHY,CONSTRUCTION,VALIDATION",IEEE TRANSACTIONS ON RADIATION AND PLASMA MEDICAL SCIENCES,,
96,Deep adversarial model for musculoskeletal quality evaluation,57,1,,Li Shenglong,Li SL,Li SL,10.1016/j.ipm.2019.102146,China Medical University,"Radiographic images are commonly used in medical imaging techniques. Interpretation and diagnosis of radiographic images are essential for the treatment of disease. However, it is a time-consuming task for radiologists to interpret a large number of radiological images, so it is significant to develop deep learning techniques to evaluate abnormal parts in radiographic images automatically. With the releasing of the musculoskeletal X-ray image dataset MURA, the evaluation of skeletal muscle abnormal sites in radiographic images has received increasing attention. In this paper, we propose a deep neural network based method for evaluating musculoskeletal quality and finding abnormal sites in radiographic images. We develop a deep dilated convolutional neural network (CNN) for automatic learning of visual features that are highly related to musculoskeletal quality. Based on the quality evaluation results, the model is able to locate abnormal sites. To improve the performance of the method, we introduce an adversarial learning based model to guide its training process iteratively. We test the performance of the proposed method on the standard dataset for musculoskeletal abnormal evaluation. Experimental results are compared with state-of-the-art methods, showing that the proposed method exhibits impressive performance on all of the test classes.","Health evaluation,Deep neural network,Musculoskeletal abnormal,Adversarial learning",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Computer Science,Information Science & Library Science",,5.789,,INFORMATION PROCESSING & MANAGEMENT,,
97,A machine learning approach to the prediction of fretting fatigue life,141,,,"Nowell D.,Nowell P. W.","Nowell D,Nowell PW",Nowell D,10.1016/j.triboint.2019.105913,Imperial College London,"The paper analyses some fretting fatigue results from the literature, reported by Nowell and by Szolwinski and Farris. The principal variables of contact size, peak pressure, remote specimen tension, and tangential force ratio are identified and these are used to construct an Artificial Neural Network (ANN), aimed at predicting total fretting fatigue life. The network is trained and validated using 90% of the data, and its success at predicting the results for the remaining 10% of unseen data is examined. The network is found to be very effective at separating the results into low life and 'run-out' groups. It is less successful at predicting lives for the low life specimens, but this is largely due to the difficulty of incorporating the runout and finite life tests together in the same dataset. The approach is seen to be potentially useful and identifies contact size as a key variable. However, the results highlight the need for significant numbers of experimental results if the method is to be used effectively in future. Nevertheless, the trained network comprises a useful tool for the prediction of future experimental results with this material.","Fretting fatigue,Life prediction,Artificial neural network",Article; Proceedings Paper,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,4.766,STRESS,TRIBOLOGY INTERNATIONAL,http://spiral.imperial.ac.uk/bitstream/10044/1/72809/2/Paper%20271.pdf,
98,A Novel Deep Learning Algorithm for the Automatic Detection of High-Grade Gliomas on T2-Weighted Magnetic Resonance I mages: A Preliminary Machine Learning Study,30,2,199-205,"Atici Mehmet Ali,Sagiroglu Seref,Celtikci Pinar,Ucar Murat,Borcek Alp Ozgun,Emmez Hakan,Celtikci Emrah","Atici MA,Sagiroglu S,Celtikci P,Ucar M,Borcek AO,Emmez H,Celtikci E",Celtikci E,10.5137/1019-5149.JTN.27106-19.2,Gazi University,"AIM: To propose a convolutional neural network (CNN) for the automatic detection of high-grade gliomas (HGGs) on T2-weighted magnetic resonance imaging (MRI) scans.
MATERIAL and METHODS: A total of 3580 images obtained from 179 individuals were used for training and validation. After random rotation and vertical flip, training data was augmented by factor of 10 in each iteration. In order to increase data processing time, every single image converted into a Jpeg image which has a resolution of 320x320. Accuracy, precision and recall rates were calculated after training of the algorithm.
RESULTS: Following training, CNN achieved acceptable performance ratios of 0.854 to 0.944 for accuracy, 0.812 to 0.980 for precision and 0.738 to 0.907 for recall. Also, CNN was able to detect HGG cases even though there is no apparent mass lesion in the given image.
CONCLUSION: Our preliminary findings demonstrate; currently proposed CNN model achieves acceptable performance results for the automatic detection of HGGs on T2-weighted images.","Artificial intelligence,Deep learning,Glioma,Machine learning,Magnetic resonance imaging",Article,"TURKISH NEUROSURGICAL SOC, TASKENT CADDESI 13-4, BAHCELIEVLER, ANKARA 06500, TURKEY","Neurosciences & Neurology,Surgery",,1.107,,TURKISH NEUROSURGERY,http://turkishneurosurgery.org.tr/pdf.php?id=2293,
99,End-to-end trained encoder-decoder convolutional neural network for fetal electrocardiogram signal denoising,41,1,,"Fotiadou Eleni,Konopczynski Tomasz,Hesser Juergen,Vullings Rik","Fotiadou E,Konopczynski T,Hesser J,Vullings R",Fotiadou E,10.1088/1361-6579/ab69b9,Eindhoven University of Technology,"Objective: Non-invasive fetal electrocardiography has the potential to provide vital information for evaluating the health status of the fetus. However, the low signal-to-noise ratio of the fetal electrocardiogram (ECG) impedes the applicability of the method in clinical practice. Quality improvement of the fetal ECG is of great importance for providing accurate information to enable support in medical decision-making. In this paper we propose the use of artificial intelligence for the task of one-channel fetal ECG enhancement as a post-processing step after maternal ECG suppression. Approach: We propose a deep fully convolutional encoder-decoder framework, learning end-to-end mappings from noise-contaminated fetal ECGs to clean ones. Symmetric skip-layer connections are used between corresponding convolutional and transposed convolutional layers to help recover the signal details. Main results: Experiments on synthetic data show an average improvement of 7.5 dB in the signal-to-noise ratio (SNR) for input SNRs in the range of -15 to 15 dB. Application of the method with real signals and subsequent ECG interval analysis demonstrates a root mean square error of 9.9 and 14 ms for the PR and QT intervals, respectively, when compared with simultaneous scalp measurements. The proposed network can achieve substantial noise removal on both synthetic and real data. In cases of highly noise-contaminated signals some morphological features might be unreliably reconstructed. Significance: The presented method has the advantage of preserving individual variations in pulse shape and beat-to-beat intervals. Moreover, no prior knowledge on the power spectra of the noise or the pulse locations is required.","convolutional neural networks,encoder-decoder network,fetal ECG denoising,fetal ECG enhancement,fetal electrocardiography",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"BLIND,SOURCE,EXTRACTION,HEART-RATE,ECG,EXTRACTION,QT,INTERVAL,ALGORITHM,VARIABILITY,CARDIOLOGY",PHYSIOLOGICAL MEASUREMENT,,
100,Forecasting intracranial hypertension using multi-scale waveform metrics,41,1,,"Hueser Matthias,Kuendig Adrian,Karlen Walter,De Luca Valeria,Jaggi Martin","Huser M,Kundig A,Karlen W,De Luca V,Jaggi M",Huser M,10.1088/1361-6579/ab6360,ETH Zurich,"Objective: Acute intracranial hypertension is an important risk factor of secondary brain damage after traumatic brain injury. Hypertensive episodes are often diagnosed reactively, leading to late detection and lost time for intervention planning. A pro-active approach that predicts critical events several hours ahead of time could assist in directing attention to patients at risk. Approach: We developed a prediction framework that forecasts onsets of acute intracranial hypertension in the next 8 h. It jointly uses cerebral auto-regulation indices, spectral energies and morphological pulse metrics to describe the neurological state of the patient. One-minute base windows were compressed by computing signal metrics, and then stored in a multi-scale history, from which physiological features were derived. Main results: Our model predicted events up to 8 h in advance with an alarm recall rate of 90% at a precision of 30% in the MIMIC-III waveform database, improving upon two baselines from the literature. We found that features derived from high-frequency waveforms substantially improved the prediction performance over simple statistical summaries of low-frequency time series, and each of the three feature classes contributed to the performance gain. The inclusion of long-term history up to 8 h was especially important. Significance: Our results highlight the importance of information contained in high-frequency waveforms in the neurological intensive care unit. They could motivate future studies on pre-hypertensive patterns and the design of new alarm algorithms for critical events in the injured brain.","cerebral auto-regulation indices,intracranial hypertension,intracranial pressure,machine learning,ICP pulse morphology",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"TRAUMATIC,BRAIN-INJURY,INTENSIVE-CARE-UNIT,CEREBRAL,PERFUSION-PRESSURE,SECONDARY,INSULTS,SERUM,BIOMARKERS,REACTIVITY,MANAGEMENT,OUTCOMES,PATHOPHYSIOLOGY,AUTOREGULATION",PHYSIOLOGICAL MEASUREMENT,http://arxiv.org/pdf/1902.09499,
