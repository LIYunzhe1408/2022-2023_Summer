,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,A Deep Learning Framework for Vibration-Based Assessment of Delamination in Smart Composite Laminates,20,8,,"Khan Asif,Shin Jae Kyoung,Lim Woo Cheol,Kim Na Yeon,Kim Heung Soo","Khan A,Shin JK,Lim WC,Kim NY,Kim HS",Kim HS,10.3390/s20082335,Dongguk University,"Delamination is one of the detrimental defects in laminated composite materials that often arose due to manufacturing defects or in-service loadings (e.g., low/high velocity impacts). Most of the contemporary research efforts are dedicated to high-frequency guided wave and mode shape-based methods for the assessment (i.e., detection, quantification, localization) of delamination. This paper presents a deep learning framework for structural vibration-based assessment of delamination in smart composite laminates. A number of small-sized (4.5% of total area) inner and edge delaminations are simulated using an electromechanically coupled model of the piezo-bonded laminated composite. Healthy and delaminated structures are stimulated with random loads and the corresponding transient responses are transformed into spectrograms using optimal values of window size, overlapping rate, window type, and fast Fourier transform (FFT) resolution. A convolutional neural network (CNN) is designed to automatically extract discriminative features from the vibration-based spectrograms and use those to distinguish the intact and delaminated cases of the smart composite laminate. The proposed architecture of the convolutional neural network showed a training accuracy of 99.9%, validation accuracy of 97.1%, and test accuracy of 94.5% on an unseen data set. The testing confusion chart of the pre-trained convolutional neural network revealed interesting results regarding the severity and detectability for the in-plane and through the thickness scenarios of delamination.","delamination,smart composite laminates,structural vibration,spectrograms,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"SENSOR-DEBONDING,FAILURE,GUIDED-WAVE,PROPAGATION,SYSTEM-IDENTIFICATION,LAMB,WAVES,DAMAGE,BEAM",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7219247,
2,"Emotion Recognition Using Eye-Tracking: Taxonomy, Review and Current Challenges",20,8,,"Lim Jia Zheng,Mountstephens James,Teo Jason","Lim JZ,Mountstephens J,Teo J",Teo J,10.3390/s20082384,Universiti Malaysia Sabah,"The ability to detect users' emotions for the purpose of emotion engineering is currently one of the main endeavors of machine learning in affective computing. Among the more common approaches to emotion detection are methods that rely on electroencephalography (EEG), facial image processing and speech inflections. Although eye-tracking is fast in becoming one of the most commonly used sensor modalities in affective computing, it is still a relatively new approach for emotion detection, especially when it is used exclusively. In this survey paper, we present a review on emotion recognition using eye-tracking technology, including a brief introductory background on emotion modeling, eye-tracking devices and approaches, emotion stimulation methods, the emotional-relevant features extractable from eye-tracking data, and most importantly, a categorical summary and taxonomy of the current literature which relates to emotion recognition using eye-tracking. This review concludes with a discussion on the current open research problems and prospective future research directions that will be beneficial for expanding the body of knowledge in emotion detection using eye-tracking as the primary sensor modality.","affective computing,emotion recognition,eye-tracking,machine learning,emotion engineering",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"MESIAL,TEMPORAL-LOBE,PROBABILISTIC,FUNCTIONS,FACE,RECOGNITION,PUPIL,SIZE,HEART-RATE,SYSTEM,MODEL,EEG,CLASSIFICATION,MACHINE",SENSORS,https://www.mdpi.com/1424-8220/20/8/2384/pdf,
3,Is War on the Arts War on Human Psychological Systems? A View from Experimental Psychology and Affective Neuroscience,53,2,201-205,Christensen Julia F.,Christensen JF,Christensen JF,10.1162/leon_a_01769,University of London,"Destruction of cultural heritage and artworks e.g. by terrorist groups has significant psychological effects for individuals and communities. This article outlines how the negative psychological effects of iconoclasm and arts destruction may be rooted in the human social brain. The proposed neurocognitive mechanisms include: (1) associative learning mechanisms (memory-reward links), (2) neuroendocrine mechanisms (oxytocin and prolactin reward links) and (3) social touch mechanisms (CT cutaneous mechanoreceptor-reward links). Iconoclasm and arts destruction are a threat to the stability of human psychological systems.","SOCIAL COGNITION,HARRY POTTER,OXYTOCIN,RESPONSES,FICTION,NEUROBIOLOGY,EVOLUTION,FEELINGS,CORTEX,TOUCH",Article,"MIT PRESS, ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA",Art,,,"SOCIAL,COGNITION,HARRY,POTTER,OXYTOCIN,RESPONSES,FICTION,NEUROBIOLOGY,EVOLUTION,FEELINGS,CORTEX,TOUCH",LEONARDO,https://direct.mit.edu/leon/article-pdf/53/2/201/1579215/leon_a_01769.pdf,
4,Multicontext multitask learning networks for mass detection in mammogram,47,4,1566-1578,"Shen Rongbo,Zhou Ke,Yan Kezhou,Tian Kuan,Zhang Jun","Shen RB,Zhou K,Yan KZ,Tian K,Zhang J",Zhou K,10.1002/mp.13945,Huazhong University of Science & Technology,"Purpose: In this paper, for the purpose of accurate and efficient mass detection, we propose a new deep learning framework, including two major stages: Suspicious region localization (SRL) and Multicontext Multitask Learning (MCMTL).
Methods: In the first stage, SRL focuses on finding suspicious regions [regions of interest (ROIs)] and extracting multisize patches of these suspicious regions. A set of bounding boxes with different size is used to extract multisize patches, which aim to capture diverse context information. In the second stage, MCMTL networks integrate features from multisize patches of suspicious regions for classification and segmentation simultaneously, where the purpose of this stage is to keep the true positive suspicious regions and to reduce the false positive suspicious regions.
Results: According to the experimental results on two public datasets (i.e., CBIS-DDSM and INBreast), our method achieves the overall performance of 0.812 TPR@2.53 FPI and 0.919 TPR@0.12 FPI on test sets, respectively.
Conclusions: Our proposed method suggests comparable performance to the state-of-the-art methods. (C) 2019 American Association of Physicists in Medicine","deep learning,mass detection,multi-context learning,multi-task learning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"CLASSIFICATION,ALGORITHM",MEDICAL PHYSICS,,
5,Hierarchical Fully Convolutional Network for Joint Atrophy Localization and Alzheimer's Disease Diagnosis Using Structural MRI,42,4,880-893,"Lian Chunfeng,Liu Mingxia,Zhang Jun,Shen Dinggang","Lian CF,Liu MX,Zhang J,Shen DG",Shen DG,10.1109/TPAMI.2018.2889096,University of North Carolina,"Structural magnetic resonance imaging (sMRI) has been widely used for computer-aided diagnosis of neurodegenerative disorders, e.g., Alzheimer's disease (AD), due to its sensitivity to morphological changes caused by brain atrophy. Recently, a few deep learning methods (e.g., convolutional neural networks, CNNs) have been proposed to learn task-oriented features from sMRI for AD diagnosis, and achieved superior performance than the conventional learning-based methods using hand-crafted features. However, these existing CNN-based methods still require the pre-determination of informative locations in sMRI. That is, the stage of discriminative atrophy localization is isolated to the latter stages of feature extraction and classifier construction. In this paper, we propose a hierarchical fully convolutional network (H-FCN) to automatically identify discriminative local patches and regions in the whole brain sMRI, upon which multi-scale feature representations are then jointly learned and fused to construct hierarchical classification models for AD diagnosis. Our proposed H-FCN method was evaluated on a large cohort of subjects from two independent datasets (i.e., ADNI-1 and ADNI-2), demonstrating good performance on joint discriminative atrophy localization and brain disease diagnosis.","Computer-aided alzheimer's disease diagnosis,fully convolutional networks,discriminative atrophy localization,weakly-supervised learning,structural MRI",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Computer Science,Engineering",,18.46,"VOXEL-BASED,MORPHOMETRY,NEURAL-NETWORK,CLASSIFICATION,IMAGES,SEGMENTATION,AD,PATTERNS,FEATURES,FUSION",IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,https://europepmc.org/articles/pmc6588512?pdf=render,
6,Even faster retinal vessel segmentation via accelerated singular value decomposition,32,7,1893-1902,"Zhang Yan,Lian Jian,Rong Luo,Jia Weikuan,Li Chengjiang,Zheng Yuanjie","Zhang Y,Lian J,Rong L,Jia WK,Li CJ,Zheng YJ",Lian J,10.1007/s00521-019-04505-1,Shandong University of Science & Technology,"Retinal blood vessel segmentation plays a vital role in medical image analysis since the appearance of vessels would contribute in the diagnosis, treatment, and evaluation for various diseases in ophthalmology and other fields, such as cardiology and neurosurgery. Among the state-of-the-art blood vessel segmentation techniques, the Hessian-based multi-scale filter has been widely used and shown its superior performance in the accuracy and visual effect. However, its execution time still remains a challenge due to the employment of eigenvalue decomposition in this approach. Bearing this in mind, we propose an accelerated matrix decomposition mechanism, which could be used to boost not only the original Hessian-based multi-scale approach but also the singular value decomposition-based algorithms. To evaluate the proposed method, we conducted comparison experiments between state-of-the-art techniques and our method. Experimental results show the superior performance of the proposed approach over state of the arts especially in execution time.","Medical image processing,Machine learning,Segmentation",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"OPPORTUNISTIC,SPECTRUM,ACCESS,ATTRIBUTE-BASED,ENCRYPTION,LOCATING,BLOOD-VESSELS,MATHEMATICAL,MORPHOLOGY,PERFORMANCE,ANALYSIS,CROWD,EVACUATION,IMAGES,NETWORK,FEATURES,ALGORITHM",NEURAL COMPUTING & APPLICATIONS,,
7,Auto-MeDiSine: an auto-tunable medical decision support engine using an automated class outlier detection method and AutoMLP,32,7,2621-2633,"Jahangir Maham,Afzal Hammad,Ahmed Mehreen,Khurshid Khawar,Amjad Muhammad Faisal,Nawaz Raheel,Abbas Haider","Jahangir M,Afzal H,Ahmed M,Khurshid K,Amjad MF,Nawaz R,Abbas H",Abbas H,10.1007/s00521-019-04137-5,National University of Sciences & Technology - Pakistan,"With advanced data analysis techniques, efforts for more accurate decision support systems for disease prediction are on the rise. According to the World Health Organization, diabetes-related illnesses and mortalities are on the rise. Hence, early diagnosis is particularly important. In this paper, we present a framework, Auto-MeDiSine, that comprises an automated version of enhanced class outlier detection using a distance-based algorithm (AutoECODB), combined with an ensemble of automatic multilayer perceptron (AutoMLP). AutoECODB is built upon ECODB by automating the tuning of parameters to optimize outlier detection process. AutoECODB cleanses the dataset by removing outliers. Preprocessed dataset is then used to train a prediction model using an ensemble of AutoMLPs. A set of experiments is performed on publicly available Pima Indian Diabetes Dataset as follows: (1) Auto-MeDiSine is compared with other state-of-the-art methods reported in the literature where Auto-MeDiSine realized an accuracy of 88.7%; (2) AutoMLP is compared with other learners including individual (focusing on neural network-based learners) and ensemble learners; and (3) AutoECODB is compared with other preprocessing methods. Furthermore, in order to validate the generality of the framework, Auto-MeDiSine is tested on another publicly available BioStat Diabetes Dataset where it outperforms the existing reported results, reaching an accuracy of 97.1%.","Classification,Disease prediction,Machine learning,Multilayer perceptron,Outlier detection",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"GENERALIZED,DISCRIMINANT-ANALYSIS,NEURAL-NETWORK,DIABETES,DISEASE,DIAGNOSIS,CLASSIFICATION,PREDICTION,REGRESSION",NEURAL COMPUTING & APPLICATIONS,https://e-space.mmu.ac.uk/623523/1/Auto-MeDiSine%20-%20An%20auto-tunable%20medical%20decision%20support%20engine%20using%20an%20automated%20class%20outlier%20detection%20method%20and%20AutoMLP.pdf,
8,Estimating inelastic seismic response of reinforced concrete frame structures using a wavelet support vector machine and an artificial neural network,32,8,2975-2988,"Gharehbaghi Sadjad,Yazdani Hessam,Khatibinia Mohsen","Gharehbaghi S,Yazdani H,Khatibinia M",Gharehbaghi S,10.1007/s00521-019-04075-2,"Behbahan Khatam Alanbia Univ Technol, Dept Civil Engn, Behbahan, Iran.","Modern building codes increasingly enforce evaluating the inelastic response of structures to ensure their safety in major seismic events. Although an inelastic dynamic analysis provides the most realistic and accurate measure for the seismic response, its application for large-scale structures is hampered by the excessive computational burden involved. This is particularly the case for the optimization of inelastic structures subjected to dynamic loads using metaheuristic algorithms where numerous analyses are required before the design converges to the optimum. In this regard, developing predictive models with sufficient accuracy will significantly help to reduce the computational demand, thus making the seismic analysis and optimization of large structures more feasible and common practice. Motivated by this need, this paper reports a study on the capabilities of a wavelet weighted least squares support vector machine (WWLSSVM) and a feedforward, backpropagation artificial neural network (ANN) to accurately predict the inelastic seismic responses of structures. The force- and displacement-based seismic responses of an 18-story reinforced concrete frame subjected to different earthquake ground motion records scaled to the design basis earthquake and maximum considered earthquake levels are used to train the models and examine their accuracies. The first three natural periods of the frame and combinations thereof are considered as the inputs for the model. The results indicate that both models exhibit satisfactory prediction performances, with the ANN model having a slight edge on accuracy in most of the cases studied, especially when a smaller number of samples are used for training. A parametric sensitivity analysis shows that the seismic responses predicted by the ANN model generally exhibit less sensitivity to the inputs than do those predicted by the WWLSSVM model. The results also indicate that force- and displacement-based responses exhibit the highest sensitivity to the first and second natural periods, respectively.","Inelastic seismic response,Reinforced concrete,Wavelet support vector machines,Artificial neural networks",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"OPTIMIZATION,EARTHQUAKE,PREDICTION,FUZZY,DESIGN,SYSTEM",NEURAL COMPUTING & APPLICATIONS,,
9,An image classification framework exploring the capabilities of extreme learning machines and artificial bee colony,32,8,3079-3099,"Reddy Annapareddy V. N.,Krishna Ch Phani,Mallick Pradeep Kumar","Reddy AVN,Krishna CP,Mallick PK",Mallick PK,10.1007/s00521-019-04385-5,Kalinga Institute of Industrial Technology (KIIT),"A hybridized image classification strategy is proposed based on discrete wavelet transform, artificial bee colony (ABC) and extreme learning machine (ELM). The proposed methodology works in three phases: (a) in preprocessing phase, images are decomposed and features are extracted from images using bi-orthogonal wavelet functions; (b) secondly, modified ABC (MABC) optimization algorithm is proposed to determine the optimal parameters such as hidden layer weights and biases to be used by ELM for classification; (c) the ELM in the third phase has been trained and tested with three brain image datasets for different diseases along with normal brain images. The performance recognition of the proposed MABC-ELM in terms of accuracy, rate of per-image classification and speedup has been made with variants of ELM such as ELM, ABC-ELM and MABC-ELM and also with MLPNN, naive Bayesian, linear regression classifiers. Finally, the percentage of accuracy observed by the proposed MABC-ELM, for acute stroke-speech arrest, glioma and multiple sclerosis datasets, is 90%, 90% and 100% with eight hidden nodes in the ELM architecture, and it can be concluded that MABC-ELM gives better generalization performance, more compact network architecture and the hybridization of ELM with modified ABC is worth investigated.","Extreme learning machine,Discrete wavelet transform,Artificial bee colony,MRI image classification",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"NEURAL-NETWORK,FEATURE-EXTRACTION,RECOGNITION,PERFORMANCE,REPRESENTATION,TRANSFORM,ALGORITHM,SCHEME",NEURAL COMPUTING & APPLICATIONS,,
10,DYNAMIC MRI USING DEEP MANIFOLD SELF-LEARNING.,2020,,1052-1055,",,,","Ahmed Abdul Haseeb,Aggarwal Hemant,Nagpal Prashant,Jacob Mathews",,10.1109/isbi45749.2020.9098382,,"We propose a deep self-learning algorithm to learn the manifold structure of free-breathing and ungated cardiac data and to recover the cardiac CINE MRI from highly undersampled measurements. Our method learns the manifold structure in the dynamic data from navigators using autoencoder network. The trained autoencoder is then used as a prior in the image reconstruction framework. We have tested the proposed method on free-breathing and ungated cardiac CINE data, which is acquired using a navigated golden-angle gradient-echo radial sequence. Results show the ability of our method to better capture the manifold structure, thus providing us reduced spatial and temporal blurring as compared to the SToRM reconstruction.",Cardiac MRI; deep learning; denoising auto-enocoder; image reconstruction,Journal Article,,,,,,,,
11,"A single neural network for cone-beam computed tomography-based radiotherapy of head-and-neck, lung and breast cancer",14,,24-31,"Maspero Matteo,Houweling Antonetta C.,Savenije Mark H. F.,van Heijst Tristan C. F.,Verhoeff Joost J. C.,Kotte Alexis N. T. J.,van den Berg Cornelis A. T.","Maspero M,Houweling AC,Savenije MHF,van Heijst TCF,Verhoeff JJC,Kotte ANTJ,van den Berg CAT",Maspero M,10.1016/j.phro.2020.04.002,Utrecht University,"Background and purpose Adaptive radiotherapy based on cone-beam computed tomography (CBCT) requires high CT number accuracy to ensure accurate dose calculations. Recently, deep learning has been proposed for fast CBCT artefact corrections on single anatomical sites. This study investigated the feasibility of applying a single convolutional network to facilitate dose calculation based on CBCT for head-and-neck, lung and breast cancer patients.
Materials and Methods Ninety-nine patients diagnosed with head-and-neck, lung or breast cancer undergoing radiotherapy with CBCT-based position verification were included in this study. The CBCTs were registered to planning CT according to clinical procedures. Three cycle-consistent generative adversarial networks (cycle-GANs) were trained in an unpaired manner on 15 patients per anatomical site generating synthetic-CTs (sCTs). Another network was trained with all the anatomical sites together. Performances of all four networks were compared and evaluated for image similarity against rescan CT (rCT). Clinical plans were recalculated on rCT and sCT and analysed through voxel-based dose differences and gamma-analysis.
Results A sCT was generated in 10 s. Image similarity was comparable between models trained on different anatomical sites and a single model for all sites. Mean dose differences <0.5% were obtained in high-dose regions. Mean gamma (3%, 3 mm) pass-rates were achieved for all sites.
Conclusion Cycle-GAN reduced CBCT artefacts and increased similarity to CT, enabling sCT-based dose calculations. A single network achieved CBCT-based dose calculation generating synthetic CT for head-and-neck, lung, and breast cancer patients with similar performance to a network specifically trained for each anatomical site.","Adaptive radiotherapy,Dose calculation,Image-guided radiotherapy,CBCT,Deep learning,Artificial intelligence,Image-to-image translation,Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,,"DEFORMABLE,REGISTRATION,CBCT,CT,ARTIFACTS,THERAPY",PHYSICS & IMAGING IN RADIATION ONCOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7807541,
12,"Deep learning-based detection, classification, and localization of defects in semiconductor processes",19,2,,"Patel Dhruv V,Bonam Ravi,Oberai Assad A.","Patel DV,Bonam R,Oberai AA",Oberai AA,10.1117/1.JMM.19.2.024801,University of Southern California,"Defects in semiconductor processes can limit yield, increase overall production cost, and also lead to time-dependent critical component failures. Current state-of-the-art optical and electron beam (EB) inspection systems rely on rule-based techniques for defect detection and classification, which are usually rigid in their comparative processes. This rigidity limits overall capability and increases relative engineering time to classify nuisance defects. This is further challenged due to shrinkage of pattern dimensions for advanced nodes. We propose a deep learning-based workflow that circumvents these challenges and enables accurate defect detection, classification, and localization in a unified framework. In particular, we train convolutional neural network-based models using high-resolution EB images of wafers patterned with various types of intentional defects and achieve robust defect detection and classification performance. Furthermore, we generate class activation maps to demonstrate defect localization capability of the model ""without"" explicitly training it with defect location information. To understand the underlying decision-making process of these deep models, we analyze the learned filters in pixel space and Fourier space and interpret the various operations at different layers. We achieve high sensitivity (97%) and specificity (100%) along with rapid and accurate defect localization. We also test performance of the proposed workflow on images from two distinct patterns and find that in order to retain high accuracy a modest level of retraining is necessary. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","lithography,photomask,defects,programmed defects,neural networks,convolutional neural network,generative adversarial network,electron beam images",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Engineering,Science & Technology - Other Topics,Materials Science,Optics",,0.968,,JOURNAL OF MICRO-NANOLITHOGRAPHY MEMS AND MOEMS,,
13,Quantitative Thermal Imaging Biomarkers to Detect Acute Skin Toxicity From Breast Radiation Therapy Using Supervised Machine Learning,106,5,1071-1083,"Saednia Khadijeh,Tabbarah Sami,Lagree Andrew,Wu Tina,Klein Jonathan,Garcia Eduardo,Hall Michael,Chow Edward,Rakovitch Eileen,Childs Charmaine","Saednia K,Tabbarah S,Lagree A,Wu TN,Klein J,Garcia E,Hall M,Chow E,Rakovitch E,Childs C",Tran WT,10.1016/j.ijrobp.2019.12.032,University of Toronto,"Purpose: Radiation-induced dermatitis is a common side effect of breast radiation therapy (RT). Current methods to evaluate breast skin toxicity include clinical examination, visual inspection, and patient-reported symptoms. Physiological changes associated with radiation-induced dermatitis, such as inflammation, may also increase body-surface temperature, which can be detected by thermal imaging. Quantitative thermal imaging markers were identified and used in supervised machine learning to develop a predictive model for radiation dermatitis.
Methods and Materials: Ninety patients treated for adjuvant whole-breast RT (4250 cGy/f(x) = 16) were recruited for the study. Thermal images of the treated breast were taken at 4 intervals: before RT, then weekly at f(x) = 5, f(x) = 10, and f(x) = 15. Parametric thermograms were analyzed and yielded 26 thermal-based features that included surface temperature (degrees C) and texture parameters obtained from (1) gray-level co-occurrence matrix, (2) gray-level run-length matrix, and (3) neighborhood gray-tone difference matrix. Skin toxicity was evaluated at the end of RT using the Common Terminology Criteria for Adverse Events (CTCAE) guidelines (Ver.5). Binary group classes were labeled according to a CTCAE cut-off score of >= 2, and thermal features obtained at f(x) = 5 were used for supervised machine learning to predict skin toxicity. The data set was partitioned for model training, independent testing, and validation. Fifteen patients (similar to 17% of the whole data set) were randomly selected as an unseen test data set, and 75 patients (similar to 83% of the whole data set) were used for training and validation of the model. A random forest classifier with leave-1-patient-out cross-validation was employed for modeling single and hybrid parameters. The model performance was reported using receiver operating characteristic analysis on patients from an independent test set.
Results: Thirty-seven patients presented with adverse skin effects, denoted by a CTCAE score >= 2, and had significantly higher local increases in skin temperature, reaching 36.06 degrees C at f(x) = 10 (P = .029). However, machine-learning models demonstrated early thermal signals associated with skin toxicity after the fifth RT fraction. The cross-validated model showed high prediction accuracy on the independent test data (test accuracy = 0.87) at f(x) = 5 for predicting skin toxicity at the end of RT.
Conclusions: Early thermal markers after 5 fractions of RT are predictive of radiation-induced skin toxicity in breast RT. (C) 2019 Elsevier Inc. All rights reserved.","LASER-DOPPLER FLOWMETRY,TOPICAL AGENTS,CANCER,RADIOTHERAPY,DERMATITIS,THERMOGRAPHY,MICROCIRCULATION,EFFUSIVITY,MANAGEMENT,RADIOMICS",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,6.884,"LASER-DOPPLER,FLOWMETRY,TOPICAL,AGENTS,CANCER,RADIOTHERAPY,DERMATITIS,THERMOGRAPHY,MICROCIRCULATION,EFFUSIVITY,MANAGEMENT,RADIOMICS",INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS,http://shura.shu.ac.uk/25736/9/Tran_QuantitativeThermalImaging%28Supp1%29.pdf,
14,Quantitative spectral quality assessment technique validated using intraoperative in vivo Raman spectroscopy measurements,25,4,,"Dallaire Frederick,Picot Fabien,Tremblay Jean-Philippe,Sheehy Guillaume,Lemoine Emile,Agarwal Rajeev,Kadoury Samuel,Trudel Dominique,Lesage Frederic,Petrecca Kevin","Dallaire F,Picot F,Tremblay JP,Sheehy G,Lemoine E,Agarwal R,Kadoury S,Trudel D,Lesage F,Petrecca K",Leblond F,10.1117/1.JBO.25.4.040501,Universite de Montreal,"Significance: Ensuring spectral quality is prerequisite to Raman spectroscopy applied to surgery. This is because the inclusion of poor-quality spectra in the training phase of Raman-based pathology detection models can compromise prediction robustness and generalizability to new data. Currently, there exists no quantitative spectral quality assessment technique that can be used to either reject low-quality data points in existing Raman datasets based on spectral morphology or, perhaps more importantly, to optimize the in vivo data acquisition process to ensure minimal spectral quality standards are met.
Aim: To develop a quantitative method evaluating Raman signal quality based on the variance associated with stochastic noise in important tissue bands, including C-C stretch, CH2/CH3 deformation, and the amide bands.
Approach: A single-point hand-held Raman spectroscopy probe system was used to acquire 315 spectra from 44 brain cancer patients. All measurements were classified as either high or low quality based on visual assessment (qualitative) and using a quantitative quality factor (QF) metric. Receiver-operator-characteristic (ROC) analyses were performed to evaluate the performance of the quantitative metric to assess spectral quality and improve cancer detection accuracy.
Results: The method can separate high- and low-quality spectra with a sensitivity of 89% and a specificity of 90% which is shown to increase cancer detection sensitivity and specificity by up to 20% and 12%, respectively.
Conclusions: The QF threshold is effective in stratifying spectra in terms of spectral quality and the observed false negatives and false positives can be linked to limitations of qualitative spectral quality assessment. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","Raman spectroscopy,fluorescence,surgery,tissue optics,signal processing,machine learning",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,,JOURNAL OF BIOMEDICAL OPTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7171512,
15,Potential of infrared microscopy to differentiate between dementia with Lewy bodies and Alzheimer's diseases using peripheral blood samples and machine learning algorithms,25,4,,"Salman Ahmad,Lapidot Itshak,Shufan Elad,Agbaria Adam H.,Katz Bat-Sheva Porat,Mordechai Shaul","Salman A,Lapidot I,Shufan E,Agbaria AH,Katz BSP,Mordechai S",Salman A,10.1117/1.JBO.25.4.046501,"Shamoon Coll Engn, Dept Phys, Beer Sheva, Israel.","Significance: Accurate and objective identification of Alzheimer's disease (AD) and dementia with Lewy bodies (DLB) is of major clinical importance due to the current lack of low-cost and noninvasive diagnostic tools to differentiate between the two. Developing an approach for such identification can have a great impact in the field of dementia diseases as it would offer physicians a routine objective test to support their diagnoses. The problem is especially acute because these two dementias have some common symptoms and characteristics, which can lead to misdiagnosis of DLB as AD and vice versa, mainly at their early stages.
Aim: The aim is to evaluate the potential of mid-infrared (IR) spectroscopy in tandem with machine learning algorithms as a sensitive method to detect minor changes in the biochemical structures that accompany the development of AD and DLB based on a simple peripheral blood test, thus improving the diagnostic accuracy of differentiation between DLB and AD.
Approach: IR microspectroscopy was used to examine white blood cells and plasma isolated from 56 individuals: 26 controls, 20 AD patients, and 10 DLB patients. The measured spectra were analyzed via machine learning.
Results: Our encouraging results show that it is possible to differentiate between dementia (AD and DLB) and controls with an similar to 86% success rate and between DLB and AD patients with a success rate of better than 93%.
Conclusions: The success of this method makes it possible to suggest a new, simple, and powerful tool for the mental health professional, with the potential to improve the reliability and objectivity of diagnoses of both AD and DLB. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","infrared spectroscopy,dementia with Lewy bodies,Alzheimer's disease,WBC,plasma,machine learning",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,"APPROPRIATE,USE,CRITERIA,IMAGING,TASK-FORCE,RAMAN-SPECTROSCOPY,NATIONAL,INSTITUTE,FTIR,SPECTROSCOPY,NUCLEAR-MEDICINE,IR,SPECTROSCOPY,AMYLOID,PET,DIAGNOSIS,IDENTIFICATION",JOURNAL OF BIOMEDICAL OPTICS,https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-25/issue-4/046501/Potential-of-infrared-microscopy-to-differentiate-between-dementia-with-Lewy/10.1117/1.JBO.25.4.046501.pdf,
16,Hidden Stratification Causes Clinically Meaningful Failures in Machine Learning for Medical Imaging.,2020,,151-159,",,,","Oakden-Rayner Luke,Dunnmon Jared,Carneiro Gustavo,Re Christopher",,10.1145/3368555.3384468,,,Computing methodologies  Machine learning; convolutional neural networks; hidden stratification; machine learning,Journal Article,,,,,,,,
17,Melanoma and Nevus Skin Lesion Classification Using Handcraft and Deep Learning Feature Fusion via Mutual Information Measures,22,4,,"Almaraz-Damian Jose-Agustin,Ponomaryov Volodymyr,Sadovnychiy Sergiy,Castillejos-Fernandez Heydy","Almaraz-Damian JA,Ponomaryov V,Sadovnychiy S,Castillejos-Fernandez H",Ponomaryov V,10.3390/e22040484,Instituto Politecnico Nacional - Mexico,"In this paper, a new Computer-Aided Detection (CAD) system for the detection and classification of dangerous skin lesions (melanoma type) is presented, through a fusion of handcraft features related to the medical algorithm ABCD rule (Asymmetry Borders-Colors-Dermatoscopic Structures) and deep learning features employing Mutual Information (MI) measurements. The steps of a CAD system can be summarized as preprocessing, feature extraction, feature fusion, and classification. During the preprocessing step, a lesion image is enhanced, filtered, and segmented, with the aim to obtain the Region of Interest (ROI); in the next step, the feature extraction is performed. Handcraft features such as shape, color, and texture are used as the representation of the ABCD rule, and deep learning features are extracted using a Convolutional Neural Network (CNN) architecture, which is pre-trained on Imagenet (an ILSVRC Imagenet task). MI measurement is used as a fusion rule, gathering the most important information from both types of features. Finally, at the Classification step, several methods are employed such as Linear Regression (LR), Support Vector Machines (SVMs), and Relevant Vector Machines (RVMs). The designed framework was tested using the ISIC 2018 public dataset. The proposed framework appears to demonstrate an improved performance in comparison with other state-of-the-art methods in terms of the accuracy, specificity, and sensibility obtained in the training and test stages. Additionally, we propose and justify a novel procedure that should be used in adjusting the evaluation metrics for imbalanced datasets that are common for different kinds of skin lesions.","fusion,handcraft,deep learning,melanoma,convolutional neural networks,transfer learning,computer-aided systems,mutual information,balance,data",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,2.587,"ABCD,RULE,TEXTURAL,FEATURES,DERMATOSCOPY,RECOGNITION,DERMOSCOPY,DIAGNOSIS,CHECKLIST",ENTROPY,https://www.mdpi.com/1099-4300/22/4/484/pdf,
18,Entropy-Based Approach for the Detection of Changes in Arabic Newspapers' Content,22,4,,"Bernikova Olga,Granichin Oleg,Lemberg Dan,Redkin Oleg,Volkovich Zeev","Bernikova O,Granichin O,Lemberg D,Redkin O,Volkovich Z",Volkovich Z,10.3390/e22040441,"ORT Braude Coll Engn, Software Engn Dept, IL-21982 Karmiel, Israel.","A new method for the recognition of meaningful changes in social state based on transformations of the linguistic content in Arabic newspapers is suggested. The detected alterations of the linguistic material in Arabic newspapers play an indicator role. The currently proposed approach acts in an ""online"" fashion and uses pre-trained vector representations of Arabic words. After a pre-processing stage, the words in the issues' texts are substituted by vectors obtained within a word embedding methodology. The approach typifies the consistent linguistic template by the similarity of the embedded vectors. A change in the distributions of the issue-grounded samples indicates a difference in the underlying newspaper template. A two-step procedure implements the concept, where the first step compares the similarity distribution of the current issue versus the union of ones corresponding to several of its predecessors. A repeating under-sampling approach accompanied by a two-sample test stabilizes the sampling and returns a collection of the resultant p-values. In the second stage, the entropy of these sets is sequentially calculated, such that the change points of the time series obtained in this way indicate the changes in the newspaper content. Numerical experiments provided on the following issues of several Arabic newspapers published in the Arab Spring period demonstrate the high reliability of the method.","publishing model modeling,anomaly detection,word embedding",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,2.587,,ENTROPY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7516919,
19,Cell Nuclei Classification in Histopathological Images using Hybrid O-L ConvNet,16,1,,"Tripathi Suvidha,Singh Satish Kumar","Tripathi S,Singh SK",Tripathi S,10.1145/3345318,Indian Institute of Information Technology Allahabad,"Computer-aided histopathological image analysis for cancer detection is a major research challenge in the medical domain. Automatic detection and classification of nuclei for cancer diagnosis impose a lot of challenges in developing state-of-the-art algorithms due to the heterogeneity of cell nuclei and dataset variability. Recently, a multitude of classification algorithms have used complex deep learning models for their dataset. However, most of these methods are rigid, and their architectural arrangement suffers from inflexibility and non-interpretability. In this research article, we have proposed a hybrid and flexible deep learning architecture O(L)ConvNet that integrates the interpretability of traditional object-level features and generalization of deep learning features by using a shallower Convolutional Neural Network (CNN) named as CNN3L. CNN3L reduces the training time by training fewer parameters and hence eliminating space constraints imposed by deeper algorithms. We used F1-score and multiclass Area Under the Curve (AUC) performance parameters to compare the results. To further strengthen the viability of our architectural approach, we tested our proposed methodology with state-of-the-art deep learning architectures AlexNet, VGG16, VGG19, ResNet50, InceptionV3, and DenseNet121 as backbone networks. After a comprehensive analysis of classification results from all four architectures, we observed that our proposed model works well and performs better than contemporary complex algorithms.","Deep learning,hybrid networks,object-level features,transfer learning,histopathological images,cell nuclei classification,class balancing,convolutional neural networks,multi layer perceptron",Article,"ASSOC COMPUTING MACHINERY, 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA",,,2.817,,ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS,,
20,Active Balancing Mechanism for Imbalanced Medical Data in Deep Learning-Based Classification Models,16,1,,"Zhang Hongyi,Zhang Haoke,Pirbhulal Sandeep,Wu Wanqing,De Albuquerque Victor Hugo C.","Zhang HY,Zhang HK,Pirbhulal S,Wu WQ,De Albuquerque VHC",Wu WQ,10.1145/3357253,Sun Yat Sen University,"Imbalanced data always has a serious impact on a predictive model, and most under-sampling techniques consume more time and suffer from loss of samples containing critical information during imbalanced data processing, especially in the biomedical field. To solve these problems, we developed an active balancing mechanism (ABM) based on valuable information contained in the biomedical data. ABM adopts the Gaussian naive Bayes method to estimate the object samples and entropy as a query function to evaluate sample information and only retains valuable samples of the majority class to achieve under-sampling. The Physikalisch Technische Bundesanstalt diagnostic electrocardiogram (ECG) database, including 5,173 normal ECG samples and 26,654 myocardial infarction ECG samples, is applied to verify the validity of ABM. At imbalance rates of 13 and 5, experimental results reveal that ABM takes 7.7 seconds and 13.2 seconds, respectively. Both results are significantly faster than five conventional under-sampling methods. In addition, at the imbalance rate of 13, ABM-based data obtained the highest accuracy of 92.23% and 97.52% using support vector machines and modified convolutional neural networks (MCNNs) with eight layers, respectively. At the imbalance rate of 5, the processed data by ABM also achieved the best accuracy of 92.31% and 98.46% based on support vector machines and MCNNs, respectively. Furthermore, ABM has better performance than two compared methods in F1-measure, G-means, and area under the curve. Consequently, ABM could be a useful and effective approach to deal with imbalanced data in general, particularly biomedical myocardial infarction ECG datasets, and the MCNN can also achieve higher performance compared to the state of the art.","Biomedical,imbalanced data,myocardial infarction,Gaussian naive Bayes,entropy",Article,"ASSOC COMPUTING MACHINERY, 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA",,,2.817,"MYOCARDIAL-INFARCTION,SMOTE",ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS,https://dl.acm.org/doi/pdf/10.1145/3357253,
21,Multi-scale Unrolled Deep Learning Framework for Accelerated Magnetic Resonance Imaging.,2020,,1056-1059,",,,,,,","Nakarmi Ukash,Cheng Joseph Y,Rios Edgar P,Mardani Morteza,Pauly John M,Ying Leslie,Vasanawala Shreyas S",,10.1109/isbi45749.2020.9098684,,"Accelerating data acquisition in magnetic resonance imaging (MRI) has been of perennial interest due to its prohibitively slow data acquisition process. Recent trends in accelerating MRI employ data-centric deep learning frameworks due to its fast inference time and 'one-parameter-fit-all' principle unlike in traditional model-based acceleration techniques. Unrolled deep learning framework that combines the deep priors and model knowledge are robust compared to naive deep learning based framework. In this paper, we propose a novel multi-scale unrolled deep learning framework which learns deep image priors through multi-scale CNN and is combined with unrolled framework to enforce data-consistency and model knowledge. Essentially, this framework combines the best of both learning paradigms:model-based and data-centric learning paradigms. Proposed method is verified using several experiments on numerous data sets.",Magnetic resonance imaging; deep learning; multi-scale CNN; unrolled network,Journal Article,,,,,,,,
22,Development of an artificial intelligence-based assessment model for prediction of embryo viability using static images captured by optical light microscopy during IVF,35,4,770-784,"VerMilyea M.,Hall J. M. M.,Diakiw S. M.,Johnston A.,Nguyen T.,Perugini D.,Miller A.,Picou A.,Murphy A. P.,Perugini M.","VerMilyea M,Hall JMM,Diakiw SM,Johnston A,Nguyen T,Perugini D,Miller A,Picou A,Murphy AP,Perugini M",Perugini M,10.1093/humrep/deaa013,"Presagen Pty Ltd, Life Whisperer Diagnost, Adelaide, SA 5000, Australia.","STUDY QUESTION: Can an artificial intelligence (AI)-based model predict human embryo viability using images captured by optical light microscopy?
SUMMARY ANSWER: We have combined computer vision image processing methods and deep learning techniques to create the non-invasive Life Whisperer AI model for robust prediction of embryo viability, as measured by clinical pregnancy outcome, using single static images of Day 5 blastocysts obtained from standard optical light microscope systems.
WHAT IS KNOWN ALREADY: Embryo selection following IVF is a critical factor in determining the success of ensuing pregnancy. Traditional morphokinetic grading by trained embryologists can be subjective and variable, and other complementary techniques, such as time-lapse imaging, require costly equipment and have not reliably demonstrated predictive ability for the endpoint of clinical pregnancy. AI methods are being investigated as a promising means for improving embryo selection and predicting implantation and pregnancy outcomes.
STUDY DESIGN, SIZE, DURATION: These studies involved analysis of retrospectively collected data including standard optical light microscope images and clinical outcomes of 8886 embryos from 11 different IVF clinics, across three different countries, between 2011 and 2018.
PARTICIPANTS/MATERIALS, SETTING, METHODS: The AI-based model was trained using static two-dimensional optical light microscope images with known clinical pregnancy outcome as measured by fetal heartbeat to provide a confidence score for prediction of pregnancy. Predictive accuracy was determined by evaluating sensitivity, specificity and overall weighted accuracy, and was visualized using histograms of the distributions of predictions. Comparison to embryologists' predictive accuracy was performed using a binary classification approach and a 5-band ranking comparison.
MAIN RESULTS AND THE ROLE OF CHANCE: The Life Whisperer AI model showed a sensitivity of 70.1% for viable embryos while maintaining a specificity of 60.5% for non-viable embryos across three independent blind test sets from different clinics. The weighted overall accuracy in each blind test set was >63%, with a combined accuracy of 64.3% across both viable and non-viable embryos, demonstrating model robustness and generalizability beyond the result expected from chance. Distributions of predictions showed clear separation of correctly and incorrectly classified embryos. Binary comparison of viable/non-viable embryo classification demonstrated an improvement of 24.7% over embryologists' accuracy (P = 0.047, n = 2, Student's t test), and 5-band ranking comparison demonstrated an improvement of 42.0% over embryologists (P = 0.028, n = 2, Student's t test).
LIMITATIONS, REASONS FOR CAUTION: The AI model developed here is limited to analysis of Day 5 embryos; therefore, further evaluation or modification of the model is needed to incorporate information from different time points. The endpoint described is clinical pregnancy as measured by fetal heartbeat, and this does not indicate the probability of live birth. The current investigation was performed with retrospectively collected data, and hence it will be of importance to collect data prospectively to assess real-world use of the AI model.
WIDER IMPLICATIONS OF THE FINDINGS: These studies demonstrated an improved predictive ability for evaluation of embryo viability when compared with embryologists' traditional morphokinetic grading methods. The superior accuracy of the Life Whisperer AI model could lead to improved pregnancy success rates in IVF when used in a clinical setting. It could also potentially assist in standardization of embryo selection methods across multiple clinical environments, while eliminating the need for complex time-lapse imaging equipment. Finally, the cloud-based software application used to apply the Life Whisperer AI model in clinical practice makes it broadly applicable and globally scalable to IVF clinics worldwide.","assisted reproduction,embryo quality,IVF/ICSI outcome,artificial intelligence,machine learning",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Obstetrics & Gynecology,Reproductive Biology",,7.366,TOOL,HUMAN REPRODUCTION,https://europepmc.org/articles/pmc7192535?pdf=render,
23,Topological Data Analysis in Materials Science: The Case of High-Temperature Cuprate Superconductors,30,2,264-276,"Torshin I. Yu,Rudakov K. V","Torshin IY,Rudakov KV",Torshin IY,10.1134/S1054661820020157,"Federal Research Center ""Computer Science & Control"" of RAS","Adequate formalization of problems is the most important task that has to be solved in order to apply the modern methods of so-called ""machine learning"" to real problems. The effective application of the metric, logical, regression, and other algorithms of machine learning becomes possible only when feature generation procedures and classes of objects are adequately defined. In this study, the theory of topological analysis of poorly formalized problems and the theory of analysis of labeled graphs were applied to the problem of predicting numerical characteristics of crystalline materials. The methods developed were tested on the problem of predicting the critical temperature of superconducting transition (T-c) of high-temperature cuprate superconductors (1450 structures). As a result, in a tenfold 6 : 1 cross-validation, the best model with a linear recognition operator yielded quite high average value of the correlation coefficient (r = 0.77) between the predicted and experimentally determined values of T-c.","algebraic approach to pattern recognition,theory of analysis of labeled graphs,data mining,superconductivity,materials science,solid state physics",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Computer Science,,,MODULATION,PATTERN RECOGNITION AND IMAGE ANALYSIS,,
24,Label-free colorectal cancer screening using deep learning and spatial light interference microscopy (SLIM),5,4,,"Zhang Jingfang K.,He Yuchen R.,Sobh Nahil,Popescu Gabriel","Zhang JFK,He YCR,Sobh N,Popescu G",Popescu G,10.1063/5.0004723,University of Illinois System,"Current pathology workflow involves staining of thin tissue slices, which otherwise would be transparent, followed by manual investigation under the microscope by a trained pathologist. While the hematoxylin and eosin (H&E) stain is well-established and a cost-effective method for visualizing histology slides, its color variability across preparations and subjectivity across clinicians remain unaddressed challenges. To mitigate these challenges, recently, we have demonstrated that spatial light interference microscopy (SLIM) can provide a path to intrinsic objective markers that are independent of preparation and human bias. Additionally, the sensitivity of SLIM to collagen fibers yields information relevant to patient outcome, which is not available in H&E. Here, we show that deep learning and SLIM can form a powerful combination for screening applications: training on 1660 SLIM images of colon glands and validating on 144 glands, we obtained an accuracy of 98% (validation dataset) and 99% (test dataset), resulting in benign vs cancer classification accuracy of 97%, defined as area under the receiver operating characteristic curve. We envision that the SLIM whole slide scanner presented here paired with artificial intelligence algorithms may prove valuable as a pre-screening method, economizing the clinician's time and effort.",,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Optics,Physics",,5.27,,APL PHOTONICS,https://aip.scitation.org/doi/pdf/10.1063/5.0004723,
25,CpG-methylation-based risk score predicts progression in colorectal cancer,12,7,605-615,"Deng Yao,Wan Hao,Tian Jianbo,Cheng Xiang,Rao Meilin,Li Jiaoyuan,Zhang Hongli,Zhang Ming,Cai Yimin,Lu Zequn","Deng Y,Wan H,Tian JB,Cheng X,Rao ML,Li JY,Zhang HL,Zhang M,Cai YM,Lu ZQ",Zhong R,10.2217/epi-2019-0300,Huazhong University of Science & Technology,"Aim: To identify patients with colorectal cancer (CRC) who are at a truly higher risk of progression, which is key for individualized approaches to precision therapy. Materials & methods: We developed a predictor associated with progression-free interval (PFI) using The Cancer Genome Atlas CRC methylation data. Results: The risk score was associated with PFI in the whole cohort (p < 0.001). A nomogram consisting of the risk score and other significant clinical features was generated to predict the 3- and 5-year PFI in the whole set (area under the curve: 0.79 and 0.71, respectively). Conclusion: The risk score based on 23 DNA-methylation sites may serve as the basis for improved prediction of progression in patients with CRC in future clinical practice.","biomarkers,colorectal cancer,CpG sites,epigenetics,methylation,prognosis,progression-free interval",Article,"FUTURE MEDICINE LTD, UNITEC HOUSE, 3RD FLOOR, 2 ALBERT PLACE, FINCHLEY CENTRAL, LONDON, N3 1QB, ENGLAND",Genetics & Heredity,,5.53,"TUMOR-SUPPRESSOR,CELL-MIGRATION,BREAST-CANCER,NITRIC-OXIDE,GROWTH,GENES,METASTASIS,SURVIVAL,PROMOTE,PROTEIN",EPIGENOMICS,https://www.futuremedicine.com/doi/pdf/10.2217/epi-2019-0300,
26,Combining automated microfluidic experimentation with machine learning for efficient polymerization design,2,4,200-209,"Rizkin Benjamin A.,Shkolnik Albert S.,Ferraro Neil J.,Hartman Ryan L.","Rizkin BA,Shkolnik AS,Ferraro NJ,Hartman RL",Hartman RL,10.1038/s42256-020-0166-5,New York University,"Understanding polymerization reactions has challenges relating to the complexity of the systems, the hazards associated with the reagents, the environmental footprint of the operations and the highly nonlinear topologies of reaction spaces. In this work, we aim to present a new methodology for studying polymerization reactions using machine-learning-assisted automated microchemical reactors. A custom-designed rapidly prototyped microreactor is used in conjunction with automation and in situ infrared thermography for efficient, high-speed experimentation to map the reaction space of a zirconocene polymerization catalyst and obtain fundamental kinetic parameters. Chemical waste is decreased by two orders of magnitude and catalytic discovery is reduced from weeks to hours. Bayesian regularization backpropagation is used in conjunction with kinetic modelling to understand the reaction space and resultant technoeconomic topology. Here, we show that efficient microfluidic technology can be coupled with machine-learning algorithms to obtain high-fidelity datasets on a complex chemical reaction. Finding the best ratio of ingredients for polymerization reactions can be time consuming and wasteful. An automated microreactor process with integrated machine learning analysis initiates reactions, measures the resulting yield and cleans itself without human intervention. It can test concentrations of reagents systematically to find the combination with the highest production, while producing a low amount of waste.","CATALYZED PROPENE POLYMERIZATION,ZIEGLER-NATTA POLYMERIZATION,OLEFIN-POLYMERIZATION,ZIRCONOCENE CATALYSTS,METALLOCENE CATALYSTS,KINETICS,MECHANISM",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Computer Science,,15.508,"CATALYZED,PROPENE,POLYMERIZATION,ZIEGLER-NATTA,POLYMERIZATION,OLEFIN-POLYMERIZATION,ZIRCONOCENE,CATALYSTS,METALLOCENE,CATALYSTS,KINETICS,MECHANISM",NATURE MACHINE INTELLIGENCE,https://zenodo.org/record/3706898,
27,YOLO-Tomato: A Robust Algorithm for Tomato Detection Based on YOLOv3,20,7,,"Liu Guoxu,Nouaze Joseph Christian,Mbouembe Philippe Lyonel Touko,Kim Jae Ho","Liu GX,Nouaze JC,Mbouembe PLT,Kim JH",Kim JH,10.3390/s20072145,Pusan National University,"Automatic fruit detection is a very important benefit of harvesting robots. However, complicated environment conditions, such as illumination variation, branch, and leaf occlusion as well as tomato overlap, have made fruit detection very challenging. In this study, an improved tomato detection model called YOLO-Tomato is proposed for dealing with these problems, based on YOLOv3. A dense architecture is incorporated into YOLOv3 to facilitate the reuse of features and help to learn a more compact and accurate model. Moreover, the model replaces the traditional rectangular bounding box (R-Bbox) with a circular bounding box (C-Bbox) for tomato localization. The new bounding boxes can then match the tomatoes more precisely, and thus improve the Intersection-over-Union (IoU) calculation for the Non-Maximum Suppression (NMS). They also reduce prediction coordinates. An ablation study demonstrated the efficacy of these modifications. The YOLO-Tomatowas compared to several state-of-the-art detection methods and it had the best detection performance.","tomato detection,harvesting robots,dense architecture,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"IMAGE-ANALYSIS,VISION,FRUIT,LOCALIZATION,MACHINE,APPLES,SCENES",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7180616,
28,Guided patchwork kriging to develop highly transferable thermal conductivity prediction models,3,2,,"Juneja Rinkle,Singh Abhishek K.","Juneja R,Singh AK",Singh AK,10.1088/2515-7639/ab78f2,Indian Institute of Science (IISC) - Bangalore,"The machine learning models developed on a dataset comprising particular class of materials show poor transferability across different classes. The problem can be partially solved by increasing the variability in the dataset at the cost of prediction accuracy. To develop a model on a highly variable database, we propose a localized regression based patchwork kriging approach for capturing most of the complex details in the data. In this approach, the data is partitioned into smaller regions with shared patches of few datapoints across the neighboring boundaries. Local regression functions are developed in each partition with a constrain to give similar performance at the boundary. Out of 17 different properties tried for partitioning the data, the decomposition with respect to target output kappa (l) gave local models with unprecedented accuracies. The partitioning with respect to kappa (l), however, requires its estimate for any unknown compound beforehand. To address this, we developed a global model for the entire database. The global model accurately predicts the order of magnitude of kappa (l) for the compounds in the dataset and hence, directs them towards a particular partition for more accurate prediction. We define this stepwise approach as guided patchwork kriging, which can be applied to develop highly accurate transferable prediction models.","machine learning,thermal conductivity,kriging",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Materials Science,,,"TOTAL-ENERGY,CALCULATIONS,COHP",JOURNAL OF PHYSICS-MATERIALS,https://doi.org/10.1088/2515-7639/ab78f2,
29,Efficient machine-learning based interatomic potentialsfor exploring thermal conductivity in two-dimensional materials,3,2,,"Mortazavi Bohayra,Podryabinkin Evgeny V,Novikov Ivan S.,Roche Stephan,Rabczuk Timon,Zhuang Xiaoying,Shapeev Alexander V","Mortazavi B,Podryabinkin EV,Novikov IS,Roche S,Rabczuk T,Zhuang XY,Shapeev AV",Roche S,10.1088/2515-7639/ab7cbb,Autonomous University of Barcelona,"It is well-known that the calculation of thermal conductivity using classical molecular dynamics (MD) simulations strongly depends on the choice of the appropriate interatomic potentials. As proven for the case of graphene, while most of the available interatomic potentials estimate the structural and elastic constants with high accuracy, when employed to predict the lattice thermal conductivity they however lead to a variation of predictions by one order of magnitude. Here we present our results on using machine-learning interatomic potentials (MLIPs) passively fitted to computationally inexpensive ab-initio molecular dynamics trajectories without any tuning or optimizing of hyperparameters. These first-attempt potentials could reproduce the phononic properties of different two-dimensional (2D) materials obtained using density functional theory (DFT) simulations. To illustrate the efficiency of the trained MLIPs, we consider polyaniline C3N nanosheets. C3N monolayer was selected because the classical MD and different first-principles results contradict each other, resulting in a scientific dilemma. It is shown that the predicted thermal conductivity of 418 +/- 20 W mK(-1) for C3N monolayer by the non-equilibrium MD simulations on the basis of a first-attempt MLIP evidences an improved accuracy when compared with the commonly employed MD models. Moreover, MLIP-based prediction can be considered as a solution to the debated reports in the literature. This study highlights that passively fitted MLIPs can be effectively employed as versatile and efficient tools to obtain accurate estimations of thermal conductivities of complex materials using classical MD simulations. In response to remarkable growth of 2D materials family, the devised modeling methodology could play a fundamental role to predict the thermal conductivity.","machine learning,thermal conductivity,molecular dynamics,density functional theory simulations,Two-dimensional polyaniline C3N monolayer",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Materials Science,,,"TOTAL-ENERGY,CALCULATIONS,POLYANILINE,C3N,GRAPHENE,TRANSPORT,SEMICONDUCTORS,MONOLAYER,1ST-PRINCIPLES",JOURNAL OF PHYSICS-MATERIALS,https://iopscience.iop.org/article/10.1088/2515-7639/ab7cbb/pdf,
30,A Clustering-Based Multi-Layer Distributed Ensemble for Neurological Diagnostics in Cloud Services,8,2,473-483,"Chowdhury Morshed U.,Abawajy Jemal H.,Kelarev Andrei,Jelinek Herbert F.","Chowdhury MU,Abawajy JH,Kelarev A,Jelinek HF",Chowdhury MU,10.1109/TCC.2016.2567389,Deakin University,"This paper investigates the problem of minimizing data transfer between different data centers of the cloud during the neurological diagnostics of cardiac autonomic neuropathy (CAN). This problem has never been considered in the literature before. All classifiers considered for the diagnostics of CAN previously assume complete access to all data, which would lead to enormous burden of data transfer during training if such classifiers were deployed in the cloud. We introduce a new model of clustering-based multi-layer distributed ensembles (CBMLDE). It is designed to eliminate the need to transfer data between different data centers for training of the classifiers. We conducted experiments utilizing a dataset derived from an extensive DiScRi database. Our comprehensive tests have determined the best combinations of options for setting up CBMLDE classifiers. The results demonstrate that CBMLDE classifiers not only completely eliminate the need in patient data transfer, but also have significantly outperformed all base classifiers and simpler counterpart models in all cloud frameworks.","Cardiac autonomic neuropathy,distributed ensembles,classifiers,cloud services",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Computer Science,,6.158,"MANAGEMENT,CLASSIFICATION,VISUALIZATION,MODEL",IEEE TRANSACTIONS ON CLOUD COMPUTING,,
31,MEUS: A Mobile E-Learning Platform for Ultrasound Image Education,13,2,367-373,"Lien Wan-Ching,Lin Phone,Chen Hong-Wun,Chang Herman Chih-Heng,Lee Chia-Peng","Lien WC,Lin P,Chen HW,Chang HCH,Lee CP",Lin P,10.1109/TLT.2020.2977627,National Taiwan University,"Recently, ultrasound has been increasingly used in emergency departments (EDs) due to its promising noninvasive and portable characteristics. Traditional ultrasound training is a complex process that requires knowledge gain, development of psychomotor skills, and visual perception. However, it usually takes a long time for a novice sonographer to finish an ultrasound training program, and the training may target on limited applications. The e-learning, information, and communication technology on digital devices to support learning may overcome the limitations of the traditional ultrasound training. In this article, we design and implement a mobile e-learning platform for ultrasound training, namely MEUS, to address the abovementioned issues. The MEUS provides an interactive learning environment for teachers and learners. Teachers and learners can access MEUS and receive real-time feedback anywhere and anytime through a mobile device or desktop. We implement a multistage learning process. To evaluate the learning performance of using the platform, we add the MEUS platform as a part of the emergency ultrasound training course with the Post Graduate Year (PGY) program in the ED at the National Taiwan University Hospital. Our study shows that the MEUS platform can significantly increase the learning efficacy of the PGY students.","Ultrasonic imaging,Training,Servers,Electronic learning,Mobile handsets,Databases,Emergency medicine (EM),mobile e-learning,ultrasound image",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Computer Science,Education & Educational Research",,4.255,"ULTRASONOGRAPHY,POINT",IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES,,
32,Deep Physiological Affect Network for the Recognition of Human Emotions,11,2,230-243,"Kim Byung Hyung,Jo Sungho","Kim BH,Jo S",Jo S,10.1109/TAFFC.2018.2790939,Korea Advanced Institute of Science & Technology (KAIST),"Here we present a robust physiological model for the recognition of human emotions, called Deep Physiological Affect Network. This model is based on a convolutional long short-term memory (ConvLSTM) network and a new temporal margin-based loss function. Formulating the emotion recognition problem as a spectral-temporal sequence classification problem of bipolar EEG signals underlying brain lateralization and photoplethysmogram signals, the proposed model improves the performance of emotion recognition. Specifically, the new loss function allows the model to be more confident as it observes more of specific feelings while training ConvLSTM models. The function is designed to result in penalties for the violation of such confidence. Our experiments on a public dataset show that our deep physiological learning technology significantly increases the recognition rate of state-of-the-art techniques by 15.96 percent increase in accuracy. An extensive analysis of the relationship between participants' emotion ratings and physiological changes in brain lateralization function during the experiment is also presented.","Emotion recognition,Physiology,Brain modeling,Electroencephalography,Biomedical monitoring,Convolution,Sensors,Emotion recognition,affective computing,physiological signals,EEG,PPG,convolutional,LSTM,emotional lateralization,inter-hemispheric asymmetry,valence,arousal",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Computer Science,,9.047,"EEG,CLASSIFICATION,NEUROSCIENCE,FRAMEWORK,SYSTEMS,MODEL,STATE",IEEE TRANSACTIONS ON AFFECTIVE COMPUTING,,
33,Emotion Recognition Based on High-Resolution EEG Recordings and Reconstructed Brain Sources,11,2,244-257,"Becker Hanna,Fleureau Julien,Guillotel Philippe,Wendling Fabrice,Merlet Isabelle,Albera Laurent","Becker H,Fleureau J,Guillotel P,Wendling F,Merlet I,Albera L",Becker H,10.1109/TAFFC.2017.2768030,Technicolor SA,"Electroencephalography (EEG)-based emotion recognition is currently a hot issue in the affective computing community. Numerous studies have been published on this topic, following generally the same schema: 1) presentation of emotional stimuli to a number of subjects during the recording of their EEG, 2) application of machine learning techniques to classify the subjects' emotions. The proposed approaches vary mainly in the type of features extracted from the EEG and in the employed classifiers, but it is difficult to compare the reported results due to the use of different datasets. In this paper, we present a new database for the analysis of valence (positive or negative emotions), which is made publicly available. The database comprises physiological recordings and 257-channel EEG data, contrary to all previously published datasets, which include at most 62 EEG channels. Furthermore, we reconstruct the brain activity on the cortical surface by applying source localization techniques. We then compare the performances of valence classification that can be achieved with various features extracted from all source regions (source space features) and from all EEG channels (sensor space features), showing that the source reconstruction improves the classification results. Finally, we discuss the influence of several parameters on the classification scores.","Electroencephalography,Feature extraction,Videos,Databases,Emotion recognition,Physiology,Brain modeling,EEG,emotion recognition,source localization,functional connectivity",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Computer Science,,9.047,"FEATURE-EXTRACTION,RESPONSES,DATABASE",IEEE TRANSACTIONS ON AFFECTIVE COMPUTING,,
34,Quantitative Determination of Benzoic Acid in Flour Based on Terahertz Time-Domain Spectroscopy and BPNN Model,57,7,,"Hu Jun,Liu Yande,Sun Xudong,Li Bin,Xu Jia,Ouyang Aiguo","Hu J,Liu YD,Sun XD,Li B,Xu J,Ouyang AG",Liu YD,10.3788/L0P57.073002,East China Jiaotong University,"To establish a quantitative detection model of benzoic acid additive in flour, terahertz time-domain spectra of benzoic acid doped at different percentages (mass fraction) in flour are collected, and the absorption coefficient spectra are obtained through calculation. It is found that the absorption peak amplitude is positively correlated with benzoic acid content. As for the detection method, first, we explore the effects of different spectral pretreatment methods on THz spectroscopy, and then adopt methods like smoothing correction, multiple scatter correction (MSC), baseline correction, and normalization correction to perform the appropriate processing. Subsequent to correction, PLS model is established to select the optimal pretreatment method. Experimental results verify that PLS model established subsequent to normalization is more optimal, with the correlation coefficient of prediction (re) observed to be 0.9790 and root-mean-square error of prediction (RMSEP) observed to be 1. 28%. We establish PLS, least squares support vector machine (LS-SVM), and back propagation neural network (BPNN) regression models for the determination of benzoic acid content in flour. It is proved that the most optimal quantitative determination model of benzoic acid content in flour is BPNN model with correlation coefficient of prediction (re) of 0. 9945 and root-mean-square error of prediction (RMSEP) of 0. 66% subsequent to the normalization of terahertz absorption coefficient. It is concluded that a new solution for the nondestructive detection of benzoic acid additives in flour has been developed, and provide guidance for the detection of other types of additives, all of which are essential for the healthy development of the flour industry.","spectroscopy,food additive,terahertz spectroscopy,BPNN,benzoic acid,flour",Article,"SHANGHAI INST OPTICS & FINE MECHANICS, CHINESE ACAD SCIENCE,  390, QINGHE LU, SHANGHAI, JIADING-QU, PEOPLES R CHINA","Engineering,Optics",,,"FOXTAIL,MILLET,AMINO-ACIDS,HYDROCHLORIDE,SPECTRA",LASER & OPTOELECTRONICS PROGRESS,,
35,Earthquake Hazard Safety Assessment of Existing Buildings Using Optimized Multi-Layer Perceptron Neural Network,13,8,,"Harirchian Ehsan,Lahmer Tom,Rasulzade Shahla","Harirchian E,Lahmer T,Rasulzade S",Harirchian E,10.3390/en13082060,Bauhaus-Universitat Weimar,"The latest earthquakes have proven that several existing buildings, particularly in developing countries, are not secured from damages of earthquake. A variety of statistical and machine-learning approaches have been proposed to identify vulnerable buildings for the prioritization of retrofitting. The present work aims to investigate earthquake susceptibility through the combination of six building performance variables that can be used to obtain an optimal prediction of the damage state of reinforced concrete buildings using artificial neural network (ANN). In this regard, a multi-layer perceptron network is trained and optimized using a database of 484 damaged buildings from the Duzce earthquake in Turkey. The results demonstrate the feasibility and effectiveness of the selected ANN approach to classify concrete structural damage that can be used as a preliminary assessment technique to identify vulnerable buildings in disaster risk-management programs.","earthquake damage,seismic vulnerability,artificial neural network,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"SEISMIC,VULNERABILITY,ASSESSMENT,REINFORCED-CONCRETE,BUILDINGS,VISUAL,SCREENING-PROCEDURE,RISK-ASSESSMENT,PREDICTION,DAMAGE",ENERGIES,https://e-pub.uni-weimar.de/opus4/files/4157/Ehsan_Harichian_Earthquake_energies.pdf,
36,Haptic Material Analysis and Classification Inspired by Human Exploratory Procedures,13,2,404-424,"Strese Matti,Brudermueller Lara,Kirsch Jonas,Steinbach Eckehard","Strese M,Brudermueller L,Kirsch J,Steinbach E",Strese M,10.1109/TOH.2019.2952118,"Tech Univ Munich9184, Chair Media Technol, D-80333 Munich, Germany.","We present a framework for the acquisition and parametrization of object material properties. The introduced acquisition device, denoted as Texplorer2, is able to extract surface material properties while a human operator is performing exploratory procedures. Using the Texplorer2, we scanned 184 material classes which we labeled according to biological, chemical, and geological naming conventions. Based on these real material recordings, we introduce a novel set of mathematical features which align with corresponding material properties defined in perceptual studies from related work and classify the materials using common machine learning techniques. Validation results of the proposed multi-modal features lead to an overall classification accuracy of 90.2% +/- 1.2% and an F-1 score of 0.90 +/- 0.01 using the random forest classifier. For the sake of comparison, a deep neural network is trained and tested on images of the material surfaces; it outperforms (90.7% +/- 1.0%) the hand-crafted feature-based approach yet leads to more critical misclassifications in terms of the proposed taxonomy.","Haptic interfaces,Robot sensing systems,Databases,Taxonomy,Metals,Surface Haptics,content-based features",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA",Computer Science,,3.037,"TACTILE,PERCEPTION,TEXTURAL,FEATURES,REPRESENTATIONS,SURFACES,TOUCH",IEEE TRANSACTIONS ON HAPTICS,,
37,"Gaming Algorithmic Hate-Speech Detection: Stakes, Parties, and Moves",6,2,,"Haapoja Jesse,Laaksonen Salla-Maaria,Lampinen Airi","Haapoja J,Laaksonen SM,Lampinen A",Haapoja J,10.1177/2056305120924778,Aalto University,"A recent strand of research considers how algorithmic systems are gamed in everyday encounters. We add to this literature with a study that uses the game metaphor to examine a project where different organizations came together to create and deploy a machine learning model to detect hate speech from political candidates' social media messages during the Finnish 2017 municipal election. Using interviews and forum discussions as our primary research material, we illustrate how the unfolding game is played out on different levels in a multi-stakeholder situation, what roles different participants have in the game, and how strategies of gaming the model revolve around controlling the information available to it. We discuss strategies that different stakeholders planned or used to resist the model, and show how the game is not only played against the model itself, but also with those who have created it and those who oppose it. Our findings illustrate that while ""gaming the system"" is an important part of gaming with algorithms, these games have other levels where humans play against each other, rather than against technology. We also draw attention to how deploying a hate-speech detection algorithm can be understood as an effort to not only detect but also preempt unwanted behavior.","algorithmic systems,game metaphor,hate-speech,social media,elections",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Communication,,5.073,"TWITTER,GAME,VISIBILITY,MODERATION,FACEBOOK",SOCIAL MEDIA + SOCIETY,https://research.aalto.fi/files/43911078/2056305120924778.pdf,
38,"Application of Artificial Neural Networks to Analyze the Concentration of Ferulic Acid, Deoxynivalenol, and Nivalenol in Winter Wheat Grain",10,4,,"Niedbala Gniewko,Kurasiak-Popowska Danuta,Stuper-Szablewska Kinga,Nawracala Jerzy","Niedbala G,Kurasiak-Popowska D,Stuper-Szablewska K,Nawracala J",Niedbala G,10.3390/agriculture10040127,Poznan University of Life Sciences,"Biotic stress, which includes infection by pathogenic fungi, causes losses of wheat yield in terms of quantity and quality. Ear Fusarium is caused by strains of F. graminearum and F. culmorum, which can produce mycotoxins-deoxynivalenol (DON) and nivalenol (NIV). One of the wheat's defense mechanisms against stressors is the activation of biosynthesis pathways of antioxidant compounds, including ferulic acid. The aim of the study was to conduct pilot studies on the basis of which neural models were created that would examine the impact of the variety and weather conditions on the concentration of ferulic acid, and link its content with the concentration of deoxynivalenol and nivalenol. The plant material was 23 winter wheat genotypes with different Fusarium resistance. The field experiment was conducted in 2011-2013 in Poland in three experimental combinations, namely: with full chemical protection; without chemical protection, but infested with natural disease (control); and in the absence of fungicidal protection, with artificial inoculation by genus Fusarium fungi. As a result of the pilot studies, three neural models-FERUANN analytical models (ferulic acid content), DONANN (deoxynivalenol content) and NIVANN (nivalenol content)-were produced. Each model was based on 14 independent features, 12 of which were in the form of quantitative data, and the other two were presented as qualitative data. The structure of the created models was based on an artificial neural network (ANN) of the multilayer perceptron (MLP) with two hidden layers. The sensitivity analysis of the neural network showed the two most important features determining the concentration of ferulic acid, deoxynivalenol, and nivalenol in winter wheat seeds. These are the experiment variant (VAR) and winter wheat variety (VOW).","winter wheat,grain,artificial neural network,ferulic acid,deoxynivalenol,nivalenol,MLP network,sensitivity analysis,precision agriculture,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Agriculture,,3.044,"FUSARIUM,HEAD,BLIGHT,MULTIPLE,LINEAR-REGRESSION,PHENOLIC-ACIDS,ANTIOXIDANT,CAPACITY,SEED,YIELD,RESISTANCE,AGGRESSIVENESS,MYCOTOXINS,PREDICTION,INFECTION",AGRICULTURE-BASEL,https://www.mdpi.com/2077-0472/10/4/127/pdf,
39,A robust grey wolf-based deep learning for brain tumour detection in MR images,65,2,191-207,"Geetha A.,Gomathi N.","Geetha A,Gomathi N",Geetha A,10.1515/bmt-2018-0244,Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology,"In recent times, the detection of brain tumours has become more common. Generally, a brain tumour is an abnormal mass of tissue where the cells grow uncontrollably and are apparently unregulated by the mechanisms that control cells. A number of techniques have been developed thus far; however, the time needed in a detecting brain tumour is still a challenge in the field of image processing. This article proposes a new accurate detection model. The model includes certain processes such as preprocessing, segmentation, feature extraction and classification. Particularly, two extreme processes such as contrast enhancement and skull stripping are processed under the initial phase. In the segmentation process, we used the fuzzy means clustering (FCM) algorithm. Both the grey co-occurrence matrix (GLCM) as well as the grey-level run-length matrix (GRIM) features were extracted in the feature extraction phase. Moreover, this paper uses a deep belief network (DBN) for classification. The optimized DBN concept is used here, for which grey wolf optimisation (GWO) is used. The proposed model is termed the GW-DBN model. The proposed model compares its performance over other conventional methods in terms of accuracy, specificity, sensitivity, precision, negative predictive value (NPV), the FlScore and Matthews correlation coefficient (MCC), false negative rate (FNR), false positive rate (FPR) and false discovery rate (FDR), and proves the superiority of the proposed work.","brain tumour,fuzzy means clustering segmentation,grey level co-occurrence matrix and grey-level run-length matrix,grey wolf-deep belief network",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY","Engineering,Medical Informatics",,,"SEGMENTATION,CLASSIFICATION,PERFORMANCE",BIOMEDICAL ENGINEERING-BIOMEDIZINISCHE TECHNIK,,
40,Application of Hyperspectral Imaging and Machine Learning Methods to Detect and Quantify Adulterants in Minced Meats,13,4,970-981,"Rady Ahmed,Adedeji Akinbode A.","Rady A,Adedeji AA",Adedeji AA,10.1007/s12161-020-01719-1,University of Kentucky,"The effectiveness of hyperspectral imaging (400-1000 nm) was proved as a nondestructive method to detect, classify, and quantify plant- and animal-based adulterants in minced beef and pork. Machine learning techniques were implemented to build classification and prediction models. Samples were first classified into adulterated (1 class) or pure (5 classes). The type of adulterant (6 classes) was then evaluated. Finally, the level of each adulterant was estimated using partial least squares regression. The optimal classification models based on selected wavelengths of test set yielded classification rates of 75-100% and 100% for pure and adulterated samples, respectively. Whereas, the rates were 83-100% depending on adulterant type. Prediction models for adulterant level yielded correlation coefficient, r, and ratio of performance to prediction, RPD, of 0.69(1.41) for beef adulterated with pork and textured vegetable protein (TVP), and 0.93(2.82) for beef adulterated with TVP. Improvement in results may be achieved with larger sample size.","Minced beef,Adulteration,Hyperspectral imaging,Texturized vegetable protein,Food fraud,Gluten,Pork",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Food Science & Technology,,3.07,"BEEF,SPECTROSCOPY,PREDICTION,ABSORPTION,FRESH,NIR",FOOD ANALYTICAL METHODS,,
41,Quality classification of Jatropha curcas seeds using radiographic images and machine learning,146,,,"de Medeiros Andre Dantas,Pinheiro Daniel Teixeira,Xavier Wanderson Andrade,da Silva Laercio Junio,Fernandes dos Santos Dias Denise Cunha","de Medeiros AD,Pinheiro DT,Xavier WA,da Silva LJ,Dias DCFD",de Medeiros AD,10.1016/j.indcrop.2020.112162,Universidade Federal de Vicosa,"Efficient seed quality assessment methodologies are important for the seed industry. Advanced seed technology research requires the use of high productivity methods that provide detailed information on seed structural integrity and predict its physiological potential quickly and accurately. The aim of this study was to propose a method for predicting germination capacity and discriminate Jatropha curcas L. seeds regarding germination speed and seedling vigor by combining automatic X-ray analysis and machine learning model. The study was performed using automated analysis of radiographic images of seeds, obtaining a series of morphological and tissue integrity descriptors. After the X-ray test, the seeds were submitted to physiological assessments. Based on all individual seed descriptors, quality classes were created and LDA models were applied. Prediction of seed viability, germination speed and seedling vigor resulted in an average of 94.36, 83.72 and 89.72% of correctly classified seeds, respectively. High throughput X-ray image analysis can provide information needed to discriminate individual Jatropha curcas seeds into different classes of quality, i.e., germination capacity, germination speed and seedling vigor. The methodology proposed can be used to discriminate between seed classes quickly and robustly.","High throughput analysis,Tissue density,X-ray imaging,Prediction of seed quality",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Agriculture,,5.749,L.,INDUSTRIAL CROPS AND PRODUCTS,,
42,Binary Whale Optimization Algorithm and Binary Moth Flame Optimization with Clustering Algorithms for Clinical Breast Cancer Diagnoses,37,1,66-96,"Sayed Gehad Ismail,Darwish Ashraf,Hassanien Aboul Ella","Sayed GI,Darwish A,Hassanien AE",Sayed GI,10.1007/s00357-018-9297-3,Egyptian Knowledge Bank (EKB),"Models based on machine learning algorithms have been developed to detect the breast cancer disease early. Feature selection is commonly applied to improve the performance of these models through selecting only relevant features. However, selecting relevant features in unsupervised learning is much difficult. This is due to the absence of class labels that guide the search for relevant information. This kind of the problem has rarely been studied in the literature. This paper presents a hybrid intelligence model that uses the cluster analysis algorithms with bio-inspired algorithms as feature selection for analyzing clinical breast cancer data. A binary version of both moth flame optimization and whale optimization algorithm is proposed. Two evaluation criteria are adopted to evaluate the proposed algorithms: clustering-based measurements and statistics-based measurements. The experimental results positively demonstrate that the capability of the proposed bio-inspired feature selection algorithms to produce both meaningful data partitions and significant feature subsets.","Intelligent systems,Breast cancer,Feature selection,Whale optimization algorithm,Moth flame optimization,WBCD",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Mathematics,Psychology",,,"INITIALIZING,K-MEANS,MEGAPTERA-NOVAEANGLIAE,SEARCH,EXPLORATION%2FEXPLOITATION,BEHAVIOR,HYBRID,MODEL",JOURNAL OF CLASSIFICATION,,
43,Groundwater Potential Mapping Using Remote Sensing and GIS-Based Machine Learning Techniques,12,7,,"Lee Sunmin,Hyun Yunjung,Lee Saro,Lee Moung-Jin","Lee S,Hyun Y,Lee S,Lee MJ",Lee MJ,10.3390/rs12071200,Korea Environment Institute (KEI),"Adequate groundwater development for the rural population is essential because groundwater is an important source of drinking water and agricultural water. In this study, ensemble models of decision tree-based machine learning algorithms were used with geographic information system (GIS) to map and test groundwater yield potential in Yangpyeong-gun, South Korea. Groundwater control factors derived from remote sensing data were used for mapping, including nine topographic factors, two hydrological factors, forest type, soil material, land use, and two geological factors. A total of 53 well locations with both specific capacity (SPC) data and transmissivity (T) data were selected and randomly divided into two classes for model training (70%) and testing (30%). First, the frequency ratio (FR) was calculated for SPC and T, and then the boosted classification tree (BCT) method of the machine learning model was applied. In addition, an ensemble model, FR-BCT, was applied to generate and compare groundwater potential maps. Model performance was evaluated using the receiver operating characteristic (ROC) method. To test the model, the area under the ROC curve was calculated; the curve for the predicted dataset of SPC showed values of 80.48% and 87.75% for the BCT and FR-BCT models, respectively. The accuracy rates from T were 72.27% and 81.49% for the BCT and FR-BCT models, respectively. Both the BCT and FR-BCT models measured the contributions of individual groundwater control factors, which showed that soil was the most influential factor. The machine learning techniques used in this study showed effective modeling of groundwater potential in areas where data are relatively scarce. The results of this study may be used for sustainable development of groundwater resources by identifying areas of high groundwater potential.","groundwater potential,specific capacity,machine learning,boosted tree,ensemble models",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Geology,Remote Sensing,Imaging Science & Photographic Technology",,5.353,"EVIDENTIAL,BELIEF,FUNCTION,ANALYTIC,HIERARCHY,PROCESS,ARTIFICIAL,NEURAL-NETWORK,LOGISTIC-REGRESSION,FREQUENCY,RATIO,MODEL,MANAGEMENT,CLASSIFICATION,PERFORMANCE,ROBUSTNESS",REMOTE SENSING,https://www.mdpi.com/2072-4292/12/7/1200/pdf,
44,"A Hybrid Deep Learning Model to Forecast Particulate Matter Concentration Levels in Seoul, South Korea",11,4,,"Yang Guang,Lee HwaMin,Lee Giyeol","Yang G,Lee H,Lee G",Lee G,10.3390/atmos11040348,Chonnam National University,"Both long- and short-term exposure to high concentrations of airborne particulate matter (PM) severely affect human health. Many countries now regulate PM concentrations. Early-warning systems based on PM concentration levels are urgently required to allow countermeasures to reduce harm and loss. Previous studies sought to establish accurate, efficient predictive models. Many machine-learning methods are used for air pollution forecasting. The long short-term memory and gated recurrent unit methods, typical deep-learning methods, reliably predict PM levels with some limitations. In this paper, the authors proposed novel hybrid models to combine the strength of two types of deep learning methods. Moreover, the authors compare hybrid deep-learning methods (convolutional neural network (CNN)-long short-term memory (LSTM) and CNN-gated recurrent unit (GRU)) with several stand-alone methods (LSTM, GRU) in terms of predicting PM concentrations in 39 stations in Seoul. Hourly air pollution data and meteorological data from January 2015 to December 2018 was used for these training models. The results of the experiment confirmed that the proposed prediction model could predict the PM concentrations for the next 7 days. Hybrid models outperformed single models in five areas selected randomly with the lowest root mean square error (RMSE) and mean absolute error (MAE) values for both PM10 and PM2.5. The error rate for PM10 prediction in Gangnam with RMSE is 1.688, and MAE is 1.161. For hybrid models, the CNN-GRU better-predicted PM10 for all stations selected, while the CNN-LSTM model performed better on predicting PM2.5.","air quality,particulate matter,long short-term memory,gated recurrent unit,hybrid models",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Meteorology & Atmospheric Sciences",,2.848,"ARTIFICIAL,NEURAL-NETWORKS,MULTIPLE-REGRESSION,MODELS,AIR-QUALITY,PM10,PM2.5,PREDICTION,POLLUTION,AREA",ATMOSPHERE,https://www.mdpi.com/2073-4433/11/4/348/pdf,
45,Optimisation of 2D U-Net Model Components for Automatic Prostate Segmentation on MRI,10,7,,"Astono Indriani P.,Welsh James S.,Chalup Stephan,Greer Peter","Astono IP,Welsh JS,Chalup S,Greer P",Astono IP,10.3390/app10072601,University of Newcastle,"In this paper, we develop an optimised state-of-the-art 2D U-Net model by studying the effects of the individual deep learning model components in performing prostate segmentation. We found that for upsampling, the combination of interpolation and convolution is better than the use of transposed convolution. For combining feature maps in each convolution block, it is only beneficial if a skip connection with concatenation is used. With respect to pooling, average pooling is better than strided-convolution, max, RMS or L2 pooling. Introducing a batch normalisation layer before the activation layer gives further performance improvement. The optimisation is based on a private dataset as it has a fixed 2D resolution and voxel size for every image which mitigates the need of a resizing operation in the data preparation process. Non-enhancing data preprocessing was applied and five-fold cross-validation was used to evaluate the fully automatic segmentation approach. We show it outperforms the traditional methods that were previously applied on the private dataset, as well as outperforming other comparable state-of-the-art 2D models on the public dataset PROMISE12.","convolutional neural networks,medical image application,prostate segmentation,magnetic resonance imaging,MRI",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"IMAGES,ATLAS,NETWORKS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/7/2601/pdf,
46,Computer-Aided Diagnosis of Skin Diseases Using Deep Neural Networks,10,7,,"Bajwa Muhammad Naseer,Muta Kaoru,Malik Muhammad Imran,Siddiqui Shoaib Ahmed,Braun Stephan Alexander,Homey Bernhard,Dengel Andreas,Ahmed Sheraz","Bajwa MN,Muta K,Malik MI,Siddiqui SA,Braun SA,Homey B,Dengel A,Ahmed S",Bajwa MN,10.3390/app10072488,University of Kaiserslautern,"Propensity of skin diseases to manifest in a variety of forms, lack and maldistribution of qualified dermatologists, and exigency of timely and accurate diagnosis call for automated Computer-Aided Diagnosis (CAD). This study aims at extending previous works on CAD for dermatology by exploring the potential of Deep Learning to classify hundreds of skin diseases, improving classification performance, and utilizing disease taxonomy. We trained state-of-the-art Deep Neural Networks on two of the largest publicly available skin image datasets, namely DermNet and ISIC Archive, and also leveraged disease taxonomy, where available, to improve classification performance of these models. On DermNet we establish new state-of-the-art with 80% accuracy and 98% Area Under the Curve (AUC) for classification of 23 diseases. We also set precedence for classifying all 622 unique sub-classes in this dataset and achieved 67% accuracy and 98% AUC. On ISIC Archive we classified all 7 diseases with 93% average accuracy and 99% AUC. This study shows that Deep Learning has great potential to classify a vast array of skin diseases with near-human accuracy and far better reproducibility. It can have a promising role in practical real-time skin disease diagnosis by assisting physicians in large-scale screening using clinical or dermoscopic images.","artificial intelligence in dermatology,automated skin disease diagnosis,computer-aided diagnosis,medical image analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"MELANOMA,DIAGNOSIS,IDENTIFICATION,DERMOSCOPY",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/7/2488/pdf,
47,Region-Based CNN Method with Deformable Modules for Visually Classifying Concrete Cracks,10,7,,"Deng Lu,Chu Hong-Hu,Shi Peng,Wang Wei,Kong Xuan","Deng L,Chu HH,Shi P,Wang W,Kong X",Wang W,10.3390/app10072528,Hunan University,"Cracks are often the most intuitive indicators for assessing the condition of in-service structures. Intelligent detection methods based on regular convolutional neural networks (CNNs) have been widely applied to the field of crack detection in recently years; however, these methods exhibit unsatisfying performance on the detection of out-of-plane cracks. To overcome this drawback, a new type of region-based CNN (R-CNN) crack detector with deformable modules is proposed in the present study. The core idea of the method is to replace the traditional regular convolution and pooling operation with a deformable convolution operation and a deformable pooling operation. The idea is implemented on three different regular detectors, namely the Faster R-CNN, region-based fully convolutional networks (R-FCN), and feature pyramid network (FPN)-based Faster R-CNN. To examine the advantages of the proposed method, the results obtained from the proposed detector and corresponding regular detectors are compared. The results show that the addition of deformable modules improves the mean average precisions (mAPs) achieved by the Faster R-CNN, R-FCN, and FPN-based Faster R-CNN for crack detection. More importantly, adding deformable modules enables these detectors to detect the out-of-plane cracks that are difficult for regular detectors to detect.","structural health monitoring (SHM),deep learning,convolutional neural network,deformable convolution,concrete cracks,out-of-plane crack",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"CLASSIFICATION,IDENTIFICATION,MODE",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/7/2528/pdf,
48,Health State Classification of a Spherical Tank Using a Hybrid Bag of Features and K-Nearest Neighbor,10,7,,"Hasan Md Junayed,Kim Jaeyoung,Kim Cheol Hong,Kim Jong-Myon","Hasan MJ,Kim J,Kim CH,Kim JM",Kim JM,10.3390/app10072525,University of Ulsan,"Feature analysis puts a great impact in determining the various health conditions of mechanical vessels. To achieve balance between traditional feature extraction and the automated feature selection process, a hybrid bag of features (HBoF) is designed for multiclass health state classification of spherical tanks in this paper. The proposed HBoF is composed of (a) the acoustic emission (AE) features and (b) the time and frequency based statistical features. A wrapper-based feature chooser algorithm, Boruta, is utilized to extract the most intrinsic feature set from HBoF. The selective feature matrix is passed to the multi-class k-nearest neighbor (k-NN) algorithm to differentiate among normal condition (NC) and two faulty conditions (FC1 and FC2). Experimental results demonstrate that the proposed methodology generates an average 99.7% accuracy for all working conditions. Moreover, it outperforms the existing state-of-art works by achieving at least 19.4%.","spherical tank,AE features,boruta,fault diagnosis,multiclass classification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"FEATURE-SELECTION,BEARING",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/7/2525/pdf,
49,Visual and Quantitative Evaluation of Amyloid Brain PET Image Synthesis with Generative Adversarial Network,10,7,,"Kang Hyeon,Park Jang-Sik,Cho Kook,Kang Do-Young","Kang H,Park JS,Cho K,Kang DY",Kang DY,10.3390/app10072628,Dong A University,"Conventional data augmentation (DA) techniques, which have been used to improve the performance of predictive models with a lack of balanced training data sets, entail an effort to define the proper repeating operation (e.g., rotation and mirroring) according to the target class distribution. Although DA using generative adversarial network (GAN) has the potential to overcome the disadvantages of conventional DA, there are not enough cases where this technique has been applied to medical images, and in particular, not enough cases where quantitative evaluation was used to determine whether the generated images had enough realism and diversity to be used for DA. In this study, we synthesized 18F-Florbetaben (FBB) images using CGAN. The generated images were evaluated using various measures, and we presented the state of the images and the similarity value of quantitative measurement that can be expected to successfully augment data from generated images for DA. The method includes (1) conditional WGAN-GP to learn the axial image distribution extracted from pre-processed 3D FBB images, (2) pre-trained DenseNet121 and model-agnostic metrics for visual and quantitative measurements of generated image distribution, and (3) a machine learning model for observing improvement in generalization performance by generated dataset. The Visual Turing test showed similarity in the descriptions of typical patterns of amyloid deposition for each of the generated images. However, differences in similarity and classification performance per axial level were observed, which did not agree with the visual evaluation. Experimental results demonstrated that quantitative measurements were able to detect the similarity between two distributions and observe mode collapse better than the Visual Turing test and t-SNE.","Alzheimer's disease,deep learning,data augmentation,generative adversarial network,positron emission tomography",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"CONVOLUTIONAL,NEURAL-NETWORKS,DEEP,CLASSIFICATION,VALIDATION,PROSPECTS,CT",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/7/2628/pdf,
50,Automatic Cephalometric Landmark Detection on X-ray Images Using a Deep-Learning Method,10,7,,"Song Yu,Qiao Xu,Iwamoto Yutaro,Chen Yen-wei","Song Y,Qiao X,Iwamoto Y,Chen YW",Chen YW,10.3390/app10072547,Ritsumeikan University,"Accurate automatic quantitative cephalometry are essential for orthodontics. However, manual labeling of cephalometric landmarks is tedious and subjective, which also must be performed by professional doctors. In recent years, deep learning has gained attention for its success in computer vision field. It has achieved large progress in resolving problems like image classification or image segmentation. In this paper, we propose a two-step method which can automatically detect cephalometric landmarks on skeletal X-ray images. First, we roughly extract a region of interest (ROI) patch for each landmark by registering the testing image to training images, which have annotated landmarks. Then, we utilize pre-trained networks with a backbone of ResNet50, which is a state-of-the-art convolutional neural network, to detect each landmark in each ROI patch. The network directly outputs the coordinates of the landmarks. We evaluate our method on two datasets: ISBI 2015 Grand Challenge in Dental X-ray Image Analysis and our own dataset provided by Shandong University. The experiments demonstrate that the proposed method can achieve satisfying results on both SDR (Successful Detection Rate) and SCR (Successful Classification Rate). However, the computational time issue remains to be improved in the future.","cephalometric landmark,X-ray,deep learning,ResNet,registration",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/7/2547/pdf,
51,Estimating the Unit Weight of Local Organic Soils from Laboratory Tests Using Artificial Neural Networks,10,7,,"Straz Grzegorz,Borowiec Artur","Straz G,Borowiec A",Straz G,10.3390/app10072261,Rzeszow University of Technology,"The estimation of the unit weight of soil is carried out using laboratory methods; however, it requires high-quality research material in the form of samples with undisturbed structures, the acquisition of which, especially in the case of organic soils, is extremely difficult, time-consuming and expensive. This paper presents a proposal to use artificial neural networks to estimate the unit weight of local organic soils as leading parameters in the process of checking the load capacity of subsoil, under a direct foundation in drained conditions, in accordance with current standards guidelines. The initial recognition of the subsoil, and the locating of organic soils at the Theological and Pastoral Institute in Rzeszow, was carried out using a mechanical cone penetration test (CPTM), using various interpretation criteria, and then, material for laboratory tests was obtained. The analysis of the usefulness of the artificial intelligence method, in this case, was based on data from laboratory tests. Standard multi-layer backpropagation networks were used to predict the soil unit weight based on two leading variables: the organic content LOIT and the natural water content w. The applied neural model provided reliable prediction results, comparable to the standard regression methods.","artificial neural networks,organic soils,soil unit weight,organic content,cone penetration test",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"COMPUTATIONAL,INTELLIGENCE,TOOLS,PREDICTION",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/7/2261/pdf,
52,A Study of the Use of Gyroscope Measurements in Wearable Fall Detection Systems,12,4,,"Casilari Eduardo,Alvarez-Marco Moises,Garcia-Lagos Francisco","Casilari E,Alvarez-Marco M,Garcia-Lagos F",Casilari E,10.3390/sym12040649,Universidad de Malaga,"Due to the serious impact of falls on the quality of life of the elderly and on the economical sustainability of health systems, the study of new monitoring systems capable of automatically alerting about falls has gained much research interest during the last decade. In the field of Human Activity Recognition, Fall Detection Systems (FDSs) can be contemplated as pattern recognition architectures able to discriminate falls from ordinary Activities of Daily Living (ADLs). In this regard, the combined application of cellular communications and wearable devices that integrate inertial sensors offers a cost-efficient solution to track the user mobility almost ubiquitously. Inertial Measurement Units (IMUs) typically utilized for these architectures, embed an accelerometer and a gyroscope. This paper investigates if the use of the angular velocity (captured by the gyroscope) as an input feature of the movement classifier introduces any benefit with respect to the most common case in which the classification decision is uniquely based on the accelerometry signals. For this purpose, the work assesses the performance of a deep learning architecture (a convolutional neural network) which is optimized to differentiate falls from ADLs as a function of the raw data measured by the two inertial sensors (gyroscope and accelerometer). The system is evaluated against on a well-known public dataset with a high number of mobility traces (falls and ADL) measured from the movements of a wide group of experimental users.","fall detection system,inertial sensors,wearable,accelerometer,gyroscope,convolutional neural networks",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"PRE-IMPACT,DETECTION,ACTIVITY,RECOGNITION,OLDER-PEOPLE,SENSOR,ALGORITHM,DEVICE,CLASSIFICATION,IDENTIFICATION,PREVENTION",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/4/649/pdf,
53,Within the Lack of Chest COVID-19 X-ray Dataset: A Novel Detection Model Based on GAN and Deep Transfer Learning,12,4,,"Loey Mohamed,Smarandache Florentin,Khalifa Nour Eldeen M.","Loey M,Smarandache F,Khalifa NEM",Loey M,10.3390/sym12040651,Egyptian Knowledge Bank (EKB),"The coronavirus (COVID-19) pandemic is putting healthcare systems across the world under unprecedented and increasing pressure according to the World Health Organization (WHO). With the advances in computer algorithms and especially Artificial Intelligence, the detection of this type of virus in the early stages will help in fast recovery and help in releasing the pressure off healthcare systems. In this paper, a GAN with deep transfer learning for coronavirus detection in chest X-ray images is presented. The lack of datasets for COVID-19 especially in chest X-rays images is the main motivation of this scientific study. The main idea is to collect all the possible images for COVID-19 that exists until the writing of this research and use the GAN network to generate more images to help in the detection of this virus from the available X-rays images with the highest accuracy possible. The dataset used in this research was collected from different sources and it is available for researchers to download and use it. The number of images in the collected dataset is 307 images for four different types of classes. The classes are the COVID-19, normal, pneumonia bacterial, and pneumonia virus. Three deep transfer models are selected in this research for investigation. The models are the Alexnet, Googlenet, and Restnet18. Those models are selected for investigation through this research as it contains a small number of layers on their architectures, this will result in reducing the complexity, the consumed memory and the execution time for the proposed model. Three case scenarios are tested through the paper, the first scenario includes four classes from the dataset, while the second scenario includes 3 classes and the third scenario includes two classes. All the scenarios include the COVID-19 class as it is the main target of this research to be detected. In the first scenario, the Googlenet is selected to be the main deep transfer model as it achieves 80.6% in testing accuracy. In the second scenario, the Alexnet is selected to be the main deep transfer model as it achieves 85.2% in testing accuracy, while in the third scenario which includes two classes (COVID-19, and normal), Googlenet is selected to be the main deep transfer model as it achieves 100% in testing accuracy and 99.9% in the validation accuracy. All the performance measurement strengthens the obtained results through the research.","2019 novel coronavirus,deep transfer learning,machine learning,COVID-19,SARS-CoV-2,convolutional neural network,GAN",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"RECOGNITION,CORONAVIRUS,NETWORKS",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/4/651/pdf,
54,The use of missing values in proteomic data-independent acquisition mass spectrometry to enable disease activity discrimination,36,7,2217-2223,"McGurk Kathryn A.,Dagliati Arianna,Chiasserini Davide,Lee Dave,Plant Darren,Baricevic-Jones Ivona,Kelsall Janet,Eineman Rachael,Reed Rachel,Geary Bethany","McGurk KA,Dagliati A,Chiasserini D,Lee D,Plant D,Baricevic-Jones I,Kelsall J,Eineman R,Reed R,Geary B",McGurk KA,10.1093/bioinformatics/btz898,University of Manchester,"Motivation: Data-independent acquisition mass spectrometry allows for comprehensive peptide detection and relative quantification than standard data-dependent approaches. While less prone to missing values, these still exist. Current approaches for handling the so-called missingness have challenges. We hypothesized that non-random missingness is a useful biological measure and demonstrate the importance of analysing missingness for proteomic discovery within a longitudinal study of disease activity.
Results: The magnitude of missingness did not correlate with mean peptide concentration. The magnitude of missingness for each protein strongly correlated between collection time points (baseline, 3months, 6months; R=0.95-0.97, confidence interval = 0.94-0.97) indicating little time-dependent effect. This allowed for the identification of proteins with outlier levels of missingness that differentiate between the patient groups characterized by different patterns of disease activity. The association of these proteins with disease activity was confirmed by machine learning techniques. Our novel approach complements analyses on complete observations and other missing value strategies in biomarker prediction of disease activity.",IMPUTATION,Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Computer Science,Mathematical & Computational Biology,Mathematics",,8.47,IMPUTATION,BIOINFORMATICS,https://academic.oup.com/bioinformatics/article-pdf/36/7/2217/33027393/btz898.pdf,
55,ImPLoc: a multi-instance deep learning model for the prediction of protein subcellular localization based on immunohistochemistry images,36,7,2244-2250,"Long Wei,Yang Yang,Shen Hong-Bin","Long W,Yang Y,Shen HB",Yang Y,10.1093/bioinformatics/btz909,Shanghai Jiao Tong University,"Motivation: The tissue atlas of the human protein atlas (HPA) houses immunohistochemistry (IHC) images visualizing the protein distribution from the tissue level down to the cell level, which provide an important resource to study human spatial proteome. Especially, the protein subcellular localization patterns revealed by these images are helpful for understanding protein functions, and the differential localization analysis across normal and cancer tissues lead to new cancer biomarkers. However, computational tools for processing images in this database are highly underdeveloped. The recognition of the localization patterns suffers from the variation in image quality and the difficulty in detecting microscopic targets.
Results: We propose a deep multi-instance multi-label model, ImPLoc, to predict the subcellular locations from IHC images. In this model, we employ a deep convolutional neural network-based feature extractor to represent image features, and design a multi-head self-attention encoder to aggregate multiple feature vectors for subsequent prediction. We construct a benchmark dataset of 1186 proteins including 7855 images from HPA and 6 subcellular locations. The experimental results show that ImPLoc achieves significant enhancement on the prediction accuracy compared with the current computational methods. We further apply ImPLoc to a test set of 889 proteins with images from both normal and cancer tissues, and obtain 8 differentially localized proteins with a significance level of 0.05.","AUTOMATED-ANALYSIS,GENE ONTOLOGY,CANCER",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Computer Science,Mathematical & Computational Biology,Mathematics",,8.47,"AUTOMATED-ANALYSIS,GENE,ONTOLOGY,CANCER",BIOINFORMATICS,,
56,SpaCell: integrating tissue morphology and spatial gene expression to predict disease cells,36,7,2293-2294,"Tan Xiao,Su Andrew,Minh Tran,Quan Nguyen","Tan X,Su A,Tran M,Nguyen Q",Nguyen Q,10.1093/bioinformatics/btz914,University of Queensland,"Motivation: Spatial transcriptomics (ST) technology is increasingly being applied because it enables the measurement of spatial gene expression in an intact tissue along with imaging morphology of the same tissue. However, current analysis methods for ST data do not use image pixel information, thus missing the quantitative links between gene expression and tissue morphology.
Results: We developed a user-friendly deep learning software, SpaCell, to integrate millions of pixel intensity values with thousands of gene expression measurements from spatially barcoded spots in a tissue. We show the integration approach outperforms the use of gene-count data alone or imaging data alone to build deep learning models to identify cell types or predict labels of tissue images with high resolution and accuracy.",,Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Computer Science,Mathematical & Computational Biology,Mathematics",,8.47,,BIOINFORMATICS,https://doi.org/10.1101/837211,
57,Single-channel oximetry monitor versus in-lab polysomnography oximetry analysis: does it make a difference?,41,4,,"Behar Joachim A.,Palmius Niclas,Zacharie Sroussi,Chocron Armand,Penzel Thomas,Bittencourt Lia,Tufik Sergio","Behar JA,Palmius N,Zacharie S,Chocron A,Penzel T,Bittencourt L,Tufik S",Behar JA,10.1088/1361-6579/ab8856,Technion Israel Institute of Technology,"Objective: Portable oximetry has been shown to be a promising candidate for large-scale obstructive sleep apnea screening. In polysomnography (PSG), the gold standard OSA diagnosis test, the oxygen desaturation index (ODI) is usually computed from desaturation events occurring during sleep periods only, i.e. overnight desaturations occurring during or overlapping with a wake state are excluded. However, for unattended home oximetry, all desaturations are taken into account since no reference electroencephalogram is available for sleep staging. We aim to evaluate the hypothesis that the predictive power of oximetry for OSA screening is not impaired when reference sleep stages are not available. Approach: We used a PSG clinical database of 887 individuals from a representative Sao Paulo (Brazil) population sample. Using features derived from the oxygen saturation time series and demographic information, OxyDOSA, a published machine learning model, was trained to distinguish between non-OSA and OSA individuals using the ODI computed while including versus excluding overnight desaturations overlapping with a wake period, thus mimicking portable and PSG oximetry analyses, respectively. Main results: When excluding wake desaturations, the OxyDOSA model had an AUROC = 94.9 +/- 1.6, Se = 85.9 +/- 2.8, Sp = 90.1 +/- 2.6 and F-1 = 86.4 +/- 2.7. When considering wake desaturations, the OxyDOSA model had an AUROC = 94.4 +/- 1.6, Se = 88.0 +/- 2.0, Sp = 87.7 +/- 2.9 and F-1 = 86.2 +/- 2.4. Non-inferiority was demonstrated (p = 0.049) at a tolerance level of 3%. In addition, analysis of the desaturations excluded by PSG oximetry analysis suggests that up to 21% of the total number of desaturations might actually be related to apneas or hypopneas. Significance: This analysis of a large representative population sample provided strong evidence that the predictive power of oximetry for OSA screening using the OxyDOSA model is not impaired when reference sleep stages are not available. This finding motivates the usage of portable oximetry for OSA screening.","obstructive sleep apnea screening,oxygen saturation,machine learning,mobile health",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"OBSTRUCTIVE,SLEEP-APNEA",PHYSIOLOGICAL MEASUREMENT,,
58,Estimation and Correlation Analysis of Lower Limb Joint Angles Based on Surface Electromyography,9,4,,"Wang Junhong,Wang Lipeng,Xi Xugang,Miran Seyed M.,Xue Anke","Wang JH,Wang LP,Xi XG,Miran SM,Xue AK",Wang JH; Xi XG,10.3390/electronics9040556,Hangzhou Dianzi University,"Many people lose their motor function because of spinal cord injury or stroke. This work studies the patient's continuous movement intention of joint angles based on surface electromyography (sEMG), which will be used for rehabilitation. In this study, we introduced a new sEMG feature extraction method based on wavelet packet decomposition, built a prediction model based on the extreme learning machine (ELM) and analyzed the correlation between sEMG signals and joint angles based on the detrended cross-correlation analysis. Twelve individuals participated in rehabilitation tasks, to test the performance of the proposed method. Five channels of sEMG signals were recorded, and denoised by the empirical mode decomposition. The prediction accuracy of the wavelet packet feature-based ELM prediction model was found to be 96.23% +/- 2.36%. The experimental results clearly indicate that the wavelet packet feature and ELM is a better combination to build a prediction model.","rehabilitation robots,estimation of continuous joint motion,sEMG signals,wavelet packet decomposition,correlation analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"EXTREME,LEARNING-MACHINE,NEURAL-NETWORK,NUMBER",ELECTRONICS,https://www.mdpi.com/2079-9292/9/4/556/pdf,
59,Assessing Earthquake-Induced Urban Rubble by Means of Multiplatform Remotely Sensed Data,9,4,,"Pollino Maurizio,Cappucci Sergio,Giordano Ludovica,Iantosca Domenico,De Cecco Luigi,Bersan Danilo,Rosato Vittorio,Borfecchia Flavio","Pollino M,Cappucci S,Giordano L,Iantosca D,De Cecco L,Bersan D,Rosato V,Borfecchia F",Pollino M,10.3390/ijgi9040262,Italian National Agency New Technical Energy & Sustainable Economics Development,"Earthquake-induced rubble in urbanized areas must be mapped and characterized. Location, volume, weight and constituents are key information in order to support emergency activities and optimize rubble management. A procedure to work out the geometric characteristics of the rubble heaps has already been reported in a previous work, whereas here an original methodology for retrieving the rubble's constituents by means of active and passive remote sensing techniques, based on airborne (LiDAR and RGB aero-photogrammetric) and satellite (WorldView-3) Very High Resolution (VHR) sensors, is presented. Due to the high spectral heterogeneity of seismic rubble, Spectral Mixture Analysis, through the Sequential Maximum Angle Convex Cone algorithm, was adopted to derive the linear mixed model distribution of remotely sensed spectral responses of pure materials (endmembers). These endmembers were then mapped on the hyperspectral signatures of various materials acquired on site, testing different machine learning classifiers in order to assess their relative abundances. The best results were provided by the C-Support Vector Machine, which allowed us to work out the characterization of the main rubble constituents with an accuracy up to 88.8% for less mixed pixels and the Random Forest, which was the only one able to detect the likely presence of asbestos.","seismic post-emergency,disaster management,environmental analysis LiDAR,remote sensing,WorldView-3,COPERNICUS,multispectral,hyperspectral,urban rubble,spectral mixture analysis,machine learning,asbestos",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Physical Geography,Remote Sensing",,2.971,"SPECTRAL,MIXTURE,ANALYSIS,IMAGERY,EXTRACTION",ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION,https://www.mdpi.com/2220-9964/9/4/262/pdf,
60,Testing Novel Portland Cement Formulations with Carbon Nanotubes and Intrinsic Properties Revelation: Nanoindentation Analysis with Machine Learning on Microstructure Identification,10,4,,"Konstantopoulos Georgios,Koumoulos Elias P.,Charitidis Costas A.","Konstantopoulos G,Koumoulos EP,Charitidis CA",Koumoulos EP,10.3390/nano10040645,National Technical University of Athens,"Nanoindentation was utilized as a non-destructive technique to identify Portland Cement hydration phases. Artificial Intelligence (AI) and semi-supervised Machine Learning (ML) were used for knowledge gain on the effect of carbon nanotubes to nanomechanics in novel cement formulations. Data labelling is performed with unsupervised ML with k-means clustering. Supervised ML classification is used in order to predict the hydration products composition and 97.6% accuracy was achieved. Analysis included multiple nanoindentation raw data variables, and required less time to execute than conventional single component probability density analysis (PDA). Also, PDA was less informative than ML regarding information exchange and re-usability of input in design predictions. In principle, ML is the appropriate science for predictive modeling, such as cement phase identification and facilitates the acquisition of precise results. This study introduces unbiased structure-property relations with ML to monitor cement durability based on cement phases nanomechanics compared to PDA, which offers a solution based on local optima of a multidimensional space solution. Evaluation of nanomaterials inclusion in composite reinforcement using semi-supervised ML was proved feasible. This methodology is expected to contribute to design informatics due to the high prediction metrics, which holds promise for the transfer learning potential of these models for studying other novel cement formulations.","artificial Intelligence,machine learning,carbon nanotubes,cement microstructure,materials characterisation,nanoanalysis,nanomechanics",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,5.346,"C-S-H,MECHANICAL-PROPERTIES,ELASTIC-MODULUS,PASTES,CONCRETE,HOMOGENIZATION,CHALLENGES,SIGNATURE,PHASES,GEL",NANOMATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7221838,
61,"Transcriptomics in Toxicogenomics, Part III: Data Modelling for Risk Assessment",10,4,,"Serra Angela,Fratello Michele,Cattelani Luca,Liampa Irene,Melagraki Georgia,Kohonen Pekka,Nymark Penny,Federico Antonio,Kinaret Pia Anneli Sofia,Jagiello Karolina","Serra A,Fratello M,Cattelani L,Liampa I,Melagraki G,Kohonen P,Nymark P,Federico A,Kinaret PAS,Jagiello K",Greco D,10.3390/nano10040708,Tampere University,"Transcriptomics data are relevant to address a number of challenges in Toxicogenomics (TGx). After careful planning of exposure conditions and data preprocessing, the TGx data can be used in predictive toxicology, where more advanced modelling techniques are applied. The large volume of molecular profiles produced by omics-based technologies allows the development and application of artificial intelligence (AI) methods in TGx. Indeed, the publicly available omics datasets are constantly increasing together with a plethora of different methods that are made available to facilitate their analysis, interpretation and the generation of accurate and stable predictive models. In this review, we present the state-of-the-art of data modelling applied to transcriptomics data in TGx. We show how the benchmark dose (BMD) analysis can be applied to TGx data. We review read across and adverse outcome pathways (AOP) modelling methodologies. We discuss how network-based approaches can be successfully employed to clarify the mechanism of action (MOA) or specific biomarkers of exposure. We also describe the main AI methodologies applied to TGx data to create predictive classification and regression models and we address current challenges. Finally, we present a short description of deep learning (DL) and data integration methodologies applied in these contexts. Modelling of TGx data represents a valuable tool for more accurate chemical safety assessment. This review is the third part of a three-article series on Transcriptomics in Toxicogenomics.","toxicogenomics,transcriptomics,data modelling,benchmark dose analysis,network analysis,read-across,QSAR,machine learning,deep learning,data integration",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,5.346,"NONNEGATIVE,MATRIX,FACTORIZATION,GENE-COEXPRESSION,NETWORK,FEATURE-SELECTION,EXPRESSION,DATA,DRUG,DISCOVERY,DOSE-RESPONSE,TOXICITY,PREDICTION,VARIABLE,SELECTION,CONNECTIVITY,MAP,MICROARRAY,DATA",NANOMATERIALS,https://trepo.tuni.fi/bitstream/10024/122722/2/transcriptomics_in_toxicogenomics_part_III_2020.pdf,
62,Spectral Adversarial Feature Learning for Anomaly Detection in Hyperspectral Imagery,58,4,2352-2365,"Xie Weiying,Liu Baozhu,Li Yunsong,Lei Jie,Chang Chein- I,He Gang","Xie WY,Liu BZ,Li YS,Lei J,Chang CI,He G",Li YS; He G,10.1109/TGRS.2019.2948177,Xidian University,"Theoretically, hyperspectral images (HSIs) are capable of providing subtle spectral differences between different materials, but in fact, it is difficult to distinguish between background and anomalies because the samples of anomalous pixels in HSIs are limited and susceptible to background and noise. To explore the discriminant features, a spectral adversarial feature learning (SAFL) architecture is specially designed for hyperspectral anomaly detection in this article. In addition to reconstruction loss, SAFL also introduces spectral constraint loss and adversarial loss in the network with batch normalization to extract the intrinsic spectral features in deep latent space. To further reduce the false alarm rate, we present an iterative optimization approach by a weighted suppression function that depends on the contribution rate of each feature to the detection. In particular, the structure tensor matrix is adopted to adaptively calculate the contribution rate of each feature. Benefiting from these improvements, the proposed method is superior to the typical and state-of-the-art methods either in detection probability or false alarm rate.","Feature extraction,Anomaly detection,Hyperspectral imaging,Decoding,Image reconstruction,Training,Adversarial learning,anomaly detection,feature extraction,hyperspectral image (HSI),iterative optimization",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Geochemistry & Geophysics,Engineering,Remote Sensing,Imaging Science & Photographic Technology",,6.086,"STRUCTURE,TENSOR,RX-ALGORITHM,CLASSIFICATION",IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,,
63,Change Detection in Multisource VHR Images via Deep Siamese Convolutional Multiple-Layers Recurrent Neural Network,58,4,2848-2864,"Chen Hongruixuan,Wu Chen,Du Bo,Zhang Liangpei,Wang Le","Chen HRX,Wu C,Du B,Zhang LP,Wang L",Wu C,10.1109/TGRS.2019.2956756,Wuhan University,"With the rapid development of Earth observation technology, very-high-resolution (VHR) images from various satellite sensors are more available, which greatly enrich the data source of change detection (CD). Multisource multitemporal images can provide abundant information on observed landscapes with various physical and material views, and it is exigent to develop efficient techniques to utilize these multisource data for CD. In this article, we propose a novel and general deep siamese convolutional multiple-layers recurrent neural network (RNN) (SiamCRNN) for CD in multitemporal VHR images. Superior to most VHR image CD methods, SiamCRNN can be used for both homogeneous and heterogeneous images. Integrating the merits of both convolutional neural network (CNN) and RNN, SiamCRNN consists of three subnetworks: deep siamese convolutional neural network (DSCNN), multiple-layers RNN (MRNN), and fully connected (FC) layers. The DSCNN has a flexible structure for multisource image and is able to extract spatial-spectral features from homogeneous or heterogeneous VHR image patches. The MRNN stacked by long-short term memory (LSTM) units is responsible for mapping the spatial-spectral features extracted by DSCNN into a new latent feature space and mining the change information between them. In addition, FC, the last part of SiamCRNN, is adopted to predict change probability. The experimental results in two homogeneous data sets and one challenging heterogeneous VHR images data set demonstrate that the promising performances of the proposed network outperform several state-of-the-art approaches.","Change detection (CD),deep siamese convolutional multiple-layers recurrent neural network,deep siamese convolutional neural network (DSCNN),heterogeneous images,long-short term memory (LSTM),multiple-layers recurrent neural network (MRNN),very-high-resolution (VHR) images",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Geochemistry & Geophysics,Engineering,Remote Sensing,Imaging Science & Photographic Technology",,6.086,"CHANGE,VECTOR,ANALYSIS,SLOW,FEATURE,ANALYSIS,MAD",IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,,
64,A Generic Quality Control Framework for Fetal Ultrasound Cardiac Four-Chamber Planes,24,4,931-942,"Dong Jinbao,Liu Shengfeng,Liao Yimei,Wen Huaxuan,Lei Baiying,Li Shengli,Wang Tianfu","Dong JB,Liu SF,Liao YM,Wen HX,Lei BY,Li SL,Wang TF",Wang TF,10.1109/JBHI.2019.2948316,Shenzhen University,"Quality control/assessment of ultrasound (US) images is an essential step in clinical diagnosis. This process is usually done manually, suffering from some drawbacks, such as dependence on operator's experience and extensive labors, as well as high inter- and intra-observer variation. Automatic quality assessment of US images is therefore highly desirable. Fetal US cardiac four-chamber plane (CFP) is one of the most commonly used cardiac views, which was used in the diagnosis of heart anomalies in the early 1980s. In this paper, we propose a generic deep learning framework for automatic quality control of fetal US CFPs. The proposed framework consists of three networks: (1) a basic CNN (B-CNN), roughly classifying four-chamber views from the raw data; (2) a deeper CNN (D-CNN), determining the gain and zoom of the target images in a multi-task learning manner; and (3) the aggregated residual visual block net (ARVBNet), detecting the key anatomical structures on a plane. Based on the output of the three networks, overall quantitative score of each CFP is obtained, so as to achieve fully automatic quality control. Experiments on a fetal US dataset demonstrated our proposed method achieved a highest mean average precision (mAP) of 93.52% at a fast speed of 101 frames per second (FPS). In order to demonstrate the adaptability and generalization capacity, the proposed detection network (i.e., ARVBNet) has also been validated on the PASCAL VOC dataset, obtaining a highest mAP of 81.2% when input size is approximately 300 x 300.","Quality control,Anatomical structure,Quality assessment,Ultrasonic imaging,Real-time systems,Quality control,cardiac four-chamber planes (CFPs),convolutional neural network (CNN),real-time object detection,aggregated residual visual block (ARVB)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,HEART,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
65,"Localizing B-Lines in Lung Ultrasonography by Weakly Supervised Deep Learning, In-Vivo Results",24,4,957-964,"van Sloun Ruud J. G.,Demi Libertario","van Sloun RJG,Demi L",Demi L,10.1109/JBHI.2019.2936151,University of Trento,"Lung ultrasound (LUS) is nowadays gaining growing attention from both the clinical and technical world. Of particular interest are several imaging-artifacts, e.g., A- and B- line artifacts. While A-lines are a visual pattern which essentially represent a healthy lung surface, B-line artifacts correlate with a wide range of pathological conditions affecting the lung parenchyma. In fact, the appearance of B-lines correlates to an increase in extravascular lung water, interstitial lung diseases, cardiogenic and non-cardiogenic lung edema, interstitial pneumonia and lung contusion. Detection and localization of B-lines in a LUS video are therefore tasks of great clinical interest, with accurate, objective and timely evaluation being critical. This is particularly true in environments such as the emergency units, where timely decision may be crucial. In this work, we present and describe a method aimed at supporting clinicians by automatically detecting and localizing B-lines in an ultrasound scan. To this end, we employ modern deep learning strategies and train a fully convolutional neural network to perform this task on B-mode images of dedicated ultrasound phantoms in-vitro, and on patients in-vivo. An accuracy, sensitivity, specificity, negative and positive predictive value equal to 0.917, 0.915, 0.918, 0.950 and 0.864 were achieved in-vitro, respectively. Using a clinical system in-vivo, these statistics were 0.892, 0.871, 0.930, 0.798 and 0.958, respectively. We moreover calculate neural attention maps that visualize which components in the image triggered the network, thereby offering simultaneous weakly-supervised localization. These promising results confirm the capability of the proposed method to identify and localize the presence of B-lines in clinical lung ultrasonography.","Lung,Ultrasonic imaging,Training,Phantoms,Diseases,Imaging phantoms,Feature extraction,Lung Ultrasound Imaging,B-lines,Deep Learning,Class Activation Mapping",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,ULTRASOUND,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://iris.unitn.it/retrieve/handle/11572/241097/276334/Deep_learning_for_the_detection_and_localization_of_B_lines_in_lung_ultrasound.pdf,
66,CR-Unet: A Composite Network for Ovary and Follicle Segmentation in Ultrasound Images,24,4,974-983,"Li Haoming,Fang Jinghui,Liu Shengfeng,Liang Xiaowen,Yang Xin,Mai Zixin,Manh The Van,Wang Tianfu,Chen Zhiyi,Ni Dong","Li HM,Fang JH,Liu SF,Liang XW,Yang X,Mai ZX,Van MT,Wang TF,Chen ZY,Ni D",Ni D,10.1109/JBHI.2019.2946092,Shenzhen University,"Transvaginal ultrasound (TVUS) is widely used in infertility treatment. The size and shape of the ovary and follicles must be measured manually for assessing their physiological status by sonographers. However, this process is extremely time-consuming and operator-dependent. In this study, we propose a novel composite network, namely CR-Unet, to simultaneously segment the ovary and follicles in TVUS. The CR-Unet incorporates the spatial recurrent neural network (RNN) into a plain U-Net. It can effectively learn multi-scale and long-range spatial contexts to combat the challenges of this task, such as the poor image quality, low contrast, boundary ambiguity, and complex anatomy shapes. We further adopt deep supervision strategy to make model training more effective and efficient. In addition, self-supervision is employed to iteratively refine the segmentation results. Experiments on 3204 TVUS images from 219 patients demonstrate the proposed method achieved the best segmentation performance compared to other state-of-the-art methods for both the ovary and follicles, with a Dice Similarity Coefficient (DSC) of 0.912 and 0.858, respectively.","Two dimensional displays,Image segmentation,Ultrasonic imaging,Shape,Task analysis,Biomedical imaging,Support vector machines,Ovarian follicle,segmentation,transvaginal ultrasound,U-Net,recurrent neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"AUTOMATED-ANALYSIS,SEQUENCE",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
67,Automatic Identification of Breast Ultrasound Image Based on Supervised Block-Based Region Segmentation Algorithm and Features Combination Migration Deep Learning Model,24,4,984-993,"Liao Wen-Xuan,He Ping,Hao Jin,Wang Xuan-Yu,Yang Ruo-Lin,An Dong,Cui Li-Gang","Liao WX,He P,Hao J,Wang XY,Yang RL,An D,Cui LG",An D,10.1109/JBHI.2019.2960821,China Agricultural University,"Breast cancer is a high-incidence type of cancer for women. Early diagnosis plays a crucial role in the successful treatment of the disease and the effective reduction of deaths. In this paper, deep learning technology combined with ultrasound imaging diagnosis was used to identify and determine whether the tumors were benign or malignant. First, the tumor regions were segmented from the breast ultrasound (BUS) images using the supervised block-based region segmentation algorithm. Then, a VGG-19 network pretrained on the ImageNet dataset was applied to the segmented BUS images to predict whether the breast tumor was benign or malignant. The benchmark data for bio-validation were obtained from 141 patients with 199 breast tumors, including 69 cases of malignancy and 130 cases of benign tumors. The experiment showed that the accuracy of the supervised block-based region segmentation algorithm was almost the same as that of manual segmentation; therefore, it can replace manual work. The diagnostic effect of the combination feature model established based on the depth feature of the B-mode ultrasonic imaging and strain elastography was better than that of the model established based on these two images alone. The correct recognition rate was 92.95%, and the AUC was 0.98 for the combination feature model.","Breast tumor,Elastography,Ultrasound images,Convolutional neural network,identification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"COMPUTER-AIDED,DIAGNOSIS,TUMORS,CLASSIFICATION,INFORMATION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
68,Mitral Annulus Segmentation Using Deep Learning in 3-D Transesophageal Echocardiography,24,4,994-1003,"Andreassen Borge Solli,Veronesi Federico,Gerard Olivier,Solberg Anne H. Schistad,Samset Eigil","Andreassen BS,Veronesi F,Gerard O,Solberg AHS,Samset E",Andreassen BS,10.1109/JBHI.2019.2959430,University of Oslo,"3D Transesophageal Echocardiography is an excellent tool for evaluating the mitral valve and is also well suited for guiding cardiac interventions. We introduce a fully automatic method for mitral annulus segmentation in 3D Transesophageal Echocardiography, which requires no manual input. One hundred eleven multi-frame 3D transesophageal echocardiography recordings were split into training, validation, and test sets. Each 3D recording was decomposed into a set of 2D planes, exploiting the symmetry around the centerline of the left ventricle. A deep 2D convolutional neural network was trained to predict the mitral annulus coordinates, and the predictions from neighboring planes were regularized by enforcing continuity around the annulus. Applying the final model and post-processing to the test set data gave a mean error of 2.0 mm - with a standard deviation of 1.9 mm. Fully automatic segmentation of the mitral annulus can alleviate the need for manual interaction in the quantification of an array of mitral annular parameters and has the potential to eliminate inter-observer variability.","Deep learning,echocardiography,machine learning,mitral annulus segmentation,soft-argmax",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"HEART-DISEASE,ARTIFICIAL-INTELLIGENCE,VALVE,QUANTIFICATION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://www.duo.uio.no/bitstream/10852/80775/1/Author_accepted_manuscript_JBHI2959430.pdf,
69,Objective Analysis of Neck Muscle Boundaries for Cervical Dystonia Using Ultrasound Imaging and Deep Learning,24,4,1016-1027,"Loram Ian,Siddique Abdul,Sanchez Maria B.,Harding Pete,Silverdale Monty,Kobylecki Christopher,Cunningham Ryan","Loram I,Siddique A,Sanchez MB,Harding P,Silverdale M,Kobylecki C,Cunningham R",Loram I,10.1109/JBHI.2020.2964098,Manchester Metropolitan University,"Objective: To provide objective visualization and pattern analysis of neck muscle boundaries to inform and monitor treatment of cervical dystonia. Methods: We recorded transverse cervical ultrasound (US) images and whole-body motion analysis of sixty-one standing participants (35 cervical dystonia, 26 age matched controls). We manually annotated 3,272 US images sampling posture and the functional range of pitch, yaw, and roll head movements. Using previously validated methods, we used 60-fold cross validation to train, validate and test a deep neural network (U-net) to classify pixels to 13 categories (five paired neck muscles, skin, ligamentum nuchae, vertebra). For all participants for their normal standing posture, we segmented US images and classified condition (Dystonia/Control), sex and age (higher/lower) from segment boundaries. We performed an explanatory, visualization analysis of dystonia muscle-boundaries. Results: For all segments, agreement with manual labels was Dice Coefficient (64 +/- 21%) and Hausdorff Distance (5.7 +/- 4 mm). For deep muscle layers, boundaries predicted central injection sites with average precision 94 +/- 3%. Using leave-one-out cross-validation, a support-vector-machine classified condition, sex, and age from predicted muscle boundaries at accuracy 70.5%, 67.2%, 52.4% respectively, exceeding classification by manual labels. From muscle boundaries, Dystonia clustered optimally into three sub-groups. These sub-groups are visualized and explained by three eigen-patterns which correlate significantly with truncal and head posture. Conclusion: Using US, neck muscle shape alone discriminates dystonia from healthy controls. Significance: Using deep learning, US imaging allows online, automated visualization, and diagnostic analysis of cervical dystonia and segmentation of individual muscles for targeted injection.","Deep learning,ultrasound imaging,cervical dystonia,segmentation,muscle boundaries,diagnosis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"MANAGEMENT,LONG",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://e-space.mmu.ac.uk/624842/1/08954690.pdf,
70,Diagnosis of Benign and Malignant Thyroid Nodules Using Combined Conventional Ultrasound and Ultrasound Elasticity Imaging,24,4,1028-1036,"Qin Pinle,Wu Kuan,Hu Yishan,Zeng Jianchao,Chai Xiangfei","Qin PL,Wu K,Hu YS,Zeng JC,Chai XF",Zeng JC,10.1109/JBHI.2019.2950994,North University of China,"Ultrasonography is one of the main imaging methods for diagnosing thyroid nodules. Automatic differentiation between benign and malignant nodules in ultrasound images can greatly assist inexperienced clinicians in their diagnosis. The key of problem is the effective utilization of the features of ultrasound images. In this study, we propose a method that is based on the combination of conventional ultrasound and ultrasound elasticity images based on a convolutional neural network and introduces richer feature information for the classification of benign and malignant thyroid nodules. First, the conventional network model performs pretraining on ImageNet and transfers the feature parameters to the ultrasound image domain by transfer learning so that depth features may be extracted and small samples may be processed. Then, we combine the depth features of conventional ultrasound and ultrasound elasticity images to form a hybrid feature space. Finally, the classification is completed on the hybrid feature space, and an end-to-end CNN model is implemented. The experimental results demonstrate that the accuracy of the proposed method is 0.9470, which is better than that of other single data-source methods under the same conditions.","Ultrasonic imaging,Feature extraction,Elasticity,Biomedical imaging,Cancer,Training,Image classification,transfer learning,deep learning,ultrasound image,elastic ultrasound",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"SHEAR-WAVE,ELASTOGRAPHY,DIFFERENTIAL-DIAGNOSIS,NETWORKS",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
71,Using Deep Learning in Ultrasound Imaging of Bicipital Peritendinous Effusion to Grade Inflammation Severity,24,4,1037-1045,"Lin Bor-Shing,Chen Jean-Lon,Tu Yi-Hsuan,Shih Ya-Xing,Lin Yu-Ching,Chi Wen-Ling,Wu Yi-Cheng","Lin BS,Chen JL,Tu YH,Shih YX,Lin YC,Chi WL,Wu YC",Chen JL,10.1109/JBHI.2020.2968815,Chang Gung Memorial Hospital,"Inflammation of the long head of the biceps tendon is a common cause of shoulder pain. Bicipital peritendinous effusion (BPE) is the most common biceps tendon abnormality and is related to various shoulder injuries. Physicians usually use ultrasound imaging to grade the inflammation severity of the long head of the biceps tendon. However, obtaining a clear and accurate ultrasound image is difficult for inexperienced attending physicians. To reduce physicians' workload and avoid errors, an automated BPE recognition system was developed in this article for classifying inflammation into the following categories-normal and mild, moderate, and severe. An ultrasound image serves as the input in the proposed system; the system determines whether the ultrasound image contains biceps. If the image depicts biceps, then the system predicts BPE severity. In this study, two crucial methods were used for solving problems associated with computer-aided detection. First, the faster regions with convolutional neural network (faster R-CNN) used to extract the region of interest (ROI) area identification to evaluate the influence of dataset scale and spatial image context on performance. Second, various CNN architectures were evaluated and explored. Model performance was analyzed by using various network configurations, parameters, and training sample sizes. The proposed system was used for three-class BPE classification and achieved 75% accuracy. The results obtained for the proposed system were determined to be comparable to those of other related state-of-the-art methods.","Biceps,convolutional neural network (CNN),deep learning,faster regions with convolutional neural network (faster R-CNN),ultrasound imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"CONVOLUTIONAL,NEURAL-NETWORKS,DIAGNOSTIC-ACCURACY,SHOULDER,TENDON,IMPINGEMENT",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
72,Hierarchical Class Incremental Learning of Anatomical Structures in Fetal Echocardiography Videos,24,4,1046-1058,"Patra Arijit,Noble Julia Alison","Patra A,Noble JA",Patra A,10.1109/JBHI.2020.2973372,University of Oxford,"This paper proposes an ultrasound video interpretation algorithm that enables novel classes or instances to be added over time, without significantly compromising prediction abilities on prior representations. The motivating application is diagnostic fetal echocardiography analysis. Currently in clinical practice, recording full diagnostic fetal echocardiography is not common. Diagnostic videos are typically available in varying length and summarize a number of diagnostic sub-tasks of varying difficulty. Although large clinical datasets may be available at onset to build ultrasound image-based models for automatic image analysis, data may also become available over extended time to assist in algorithm refinement. To address this scenario, we propose to use an incremental learning approach to build a hierarchical network model that allows for a parallel inclusion of previously unseen anatomical classes without requiring prior data distributions. Super classes are obtained by coarse classification followed by fine classification to allow the model to self-organize anatomical structures in a sequence of categories through a modular architecture. We show that this approach can be adapted with new variable data distributions without significantly affecting previously learned representations. Two extreme situations of new data addition are considered; (1) when new class data is available over time with volume and distribution similar to prior available classes, and (2) when imbalanced datasets arrive over future time to be learned in a few-shot setting. In either case, availability of data from prior classes is not assumed. Evolution of the learning process is validated using incremental accuracies of fine classification over novel classes and compared to results from an end-to-end transfer learning-derived model fine-tuned on a clinical dataset annotated by experienced sonographers. The modularization of subsequent learning reduces the depreciation in future accuracies over old tasks from 6.75% to 1.10% using balanced increments. The depreciation is reduced from 6.95% to 1.89% with imbalanced data distributions in future increments, while retaining competitive classification accuracies in new additions of fine classes with parameter operations in the same order of magnitude in all stages in both cases.","Task analysis,Videos,Anatomical structure,Echocardiography,Ultrasonic imaging,Training,Fetal ultrasound,hierarchical models,incremental learning,similarity learning,ultrasound analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,,,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
73,A Feasible Feature Extraction Method for Atrial Fibrillation Detection From BCG,24,4,1093-1103,"Wen Xin,Huang Yanqi,Wu Xiaomei,Zhang Biyong","Wen X,Huang YQ,Wu XM,Zhang BY",Wu XM,10.1109/JBHI.2019.2927165,Fudan University,"Atrial fibrillation (AF) is the most frequently occurring form of arrhythmia, which induces multiple fatal diseases and impairs the quality of life in patients; thus, the study of the diagnostic methods for detecting AF is clinically important. Here, we present a feature extraction method for the detection of AF using a ballistocardiogram (BCG), which is based on a physiological signal database collected by a non-contact sensor. The BCG signals, including both with AF and sinus rhythm (SR), were collected from 37 subjects during overnight sleep (approximately 8 h). The signals were split into 2915 1-min segments (AF: 1494, SR: 1421) without overlap and labeled as AF and SR. BCG signals were transformed into BCG energy signals in order to highlight the features of AF and SR BCG signals; and four new data sequences representing different characteristics of the BCG energy signals were generated. The mean value, variance, skewness, and kurtosis of the four data sequences were calculated and 16 features were extracted for each segment. Five machine learning algorithms were used for classification. The results of this study show that the support vector machine performed the best among the five tested classifiers and achieved sensitivity, precision, and accuracy of 0.968, 0.928, and 0.945, respectively. These results indicate that the proposed feature extraction method can be well applied to AF and SR classification and may lay foundations for the development of systems for long-term home cardiac monitoring and AF screening.","Feature extraction,Hypertension,Monitoring,Rhythm,Support vector machines,Heart rate variability,Ballistocardiogram,atrial fibrillation,feature extraction,classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"SEISMOCARDIOGRAPHY,CLASSIFICATION,UPDATE",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
74,Direct Cup-to-Disc Ratio Estimation for Glaucoma Screening via Semi-Supervised Learning,24,4,1104-1113,"Zhao Rongchang,Chen Xuanlin,Liu Xiyao,Chen Zailiang,Guo Fan,Li Shuo","Zhao RC,Chen XL,Liu XY,Chen ZL,Guo F,Li S",Li S,10.1109/JBHI.2019.2934477,Western University (University of Western Ontario),"Glaucoma is a chronic eye disease that leads to irreversible vision loss. The Cup-to-Disc Ratio (CDR) serves as the most important indicator for glaucoma screening and plays a significant role in clinical screening and early diagnosis of glaucoma. In general, obtaining CDR is subjected to measuring on manually or automatically segmented optic disc and cup. Despite great efforts have been devoted, obtaining CDR values automatically with high accuracy and robustness is still a great challenge due to the heavy overlap between optic cup and neuroretinal rim regions. In this paper, a direct CDR estimation method is proposed based on the well-designed semi-supervised learning scheme, in which CDR estimation is formulated as a general regression problem while optic disc/cup segmentation is cancelled. The method directly regresses CDR value based on the feature representation of optic nerve head via deep learning technique while bypassing intermediate segmentation. The scheme is a two-stage cascaded approach comprised of two phases: unsupervised feature representation of fundus image with a convolutional neural networks (MFPPNet) and CDR value regression by random forest regressor. The proposed scheme is validated on the challenging glaucoma dataset Direct-CSU and public ORIGA, and the experimental results demonstrate that our method can achieve a lower average CDR error of 0.0563 and a higher correlation of around 0.726 with measurement before manual segmentation of optic disc/cup by human experts. Our estimated CDR values are also tested for glaucoma screening, which achieves the areas under curve of 0.905 on dataset of 421 fundus images. The experiments show that the proposed method is capable of state-of-the-art CDR estimation and satisfactory glaucoma screening with calculated CDR value.","Cup-to-disc ratio (CDR),representation learning,direct estimation,glaucoma screening,semi-supervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"OPTIC,DISC,FUNDUS,IMAGES,SEGMENTATION,DIAGNOSIS",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
75,Learning to Quantify Emphysema Extent: What Labels Do We Need?,24,4,1149-1159,"Orting Silas Nyboe,Petersen Jens,Thomsen Laura H.,Wille Mathilde M. W.,de Bruijne Marleen","Orting SN,Petersen J,Thomsen LH,Wille MMW,de Bruijne M",Orting SN,10.1109/JBHI.2019.2932145,University of Copenhagen,"Accurate assessment of pulmonary emphysema is crucial to assess disease severity and subtype, to monitor disease progression, and to predict lung cancer risk. However, visual assessment is time-consuming and subject to substantial inter-rater variability while standard densitometry approaches to quantify emphysema remain inferior to visual scoring. We explore if machine learning methods that learn from a large dataset of visually assessed CT scans can provide accurate estimates of emphysema extent and if methods that learn from emphysema extent scoring can outperform algorithms that learn only from emphysema presence scoring. Four Multiple Instance Learning classifiers, trained on emphysema presence labels, and five Learning with Label Proportions classifiers, trained on emphysema extent labels, are compared. Performance is evaluated on 600 low-dose CT scans from the Danish Lung Cancer Screening Trial and we find that learning from emphysema presence labels, which are much easier to obtain, gives equally good performance to learning from emphysema extent labels. The best performing Multiple Instance Learning and Learning with Label Proportions classifiers, achieve intra-class correlation coefficients around 0.90 and average overall agreement with raters of 78% and 79% compared to an inter-rater agreement of 83%.","Lung,Visualization,Support vector machines,Logistics,Cancer,Standards,Computed tomography,Emphysema,multiple instance learning,learning with label proportions,chest CT",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"CT,CANCER,COPD,PROGRESSION,DESIGN",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://arxiv.org/pdf/1810.07433,
76,Toward a Better Estimation of Functional Brain Network for Mild Cognitive Impairment Identification: A Transfer Learning View,24,4,1160-1168,"Li Weikai,Zhang Limei,Qiao Lishan,Shen Dinggang","Li WK,Zhang LM,Qiao LS,Shen DG",Qiao LS,10.1109/JBHI.2019.2934230,Liaocheng University,"Mild cognitive impairment (MCI) is an intermediate stage of brain cognitive decline, associated with increasing risk of developing Alzheimer's disease (AD). It is believed that early treatment of MCI could slow down the progression of AD, and functional brain network (FBN) could provide potential imaging biomarkers for MCI diagnosis and response to treatment. However, there are still some challenges to estimate a ""good"" FBN, particularly due to the poor quality and limited quantity of functional magnetic resonance imaging (fMRI) data from the target domain (i.e., MCI study). Inspired by the idea of transfer learning, we attempt to transfer information in high-quality data from source domain (e.g., human connectome project in this paper) into the target domain towards a better FBN estimation, and propose a novel method, namely NERTL (Network Estimation via Regularized Transfer Learning). Specifically, we first construct a high-quality network ""template"" based on the source data, and then use the template to guide or constrain the target of FBN estimation by a weighted l(1)-norm regularizer. Finally, we conduct experiments to identify subjects with MCI from normal controls (NCs) based on the estimated FBNs. Despite its simplicity, our proposed method is more effective than the baseline methods in modeling discriminative FBNs, as demonstrated by the superior MCI classification accuracy of 82.4% and the area under curve (AUC) of 0.910.","Estimation,Functional magnetic resonance imaging,Correlation,Informatics,Data models,Brain modeling,Reliability,Mild cognitive impairment (MCI),functional brain network (FBN),functional magnetic resonance imaging (fMRI),sparse representation,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"ALZHEIMERS-DISEASE,HUMAN,CONNECTOME,CONNECTIVITY,FMRI,CLASSIFICATION,DIAGNOSIS,MODEL",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://www.biorxiv.org/content/biorxiv/early/2019/06/27/684779.full.pdf,
77,Densely Connected Neural Network With Unbalanced Discriminant and Category Sensitive Constraints for Polyp Recognition,17,2,574-583,"Yuan Yixuan,Qin Wenjian,Ibragimov Bulat,Zhang Guanglei,Han Bin,Meng Max Q-H,Xing Lei","Yuan YX,Qin WJ,Ibragimov B,Zhang GL,Han B,Meng MQH,Xing L",Yuan YX,10.1109/TASE.2019.2936645,City University of Hong Kong,"Automatic polyp recognition in endoscopic images is challenging because of the low contrast between polyps and the surrounding area, the fuzzy and irregular polyp borders, and varying imaging light conditions. In this article, we propose a novel densely connected convolutional network with ""unbalanced discriminant (UD)"" loss and ""category sensitive (CS)"" loss (DenseNet-UDCS) for the task. We first utilize densely connected convolutional network (DenseNet) as the basic framework to conduct end-to-end polyp recognition task. Then, the proposed dual constraints, UD loss and CS loss, are simultaneously incorporated into the DenseNet model to calculate discriminative and suitable image features. The UD loss in our network effectively captures classification errors from both majority and minority categories to deal with the strong data imbalance of polyp images and normal ones. The CS loss imposes the ratio of intraclass and interclass variations in the deep feature learning process to enable features with large interclass variation and small intraclass compactness. With the joint supervision of UD loss and CS loss, a robust DenseNet-UDCS model is trained to recognize polyps from endoscopic images. The experimental results achieved polyp recognition accuracy of 93.19%, showing that the proposed DenseNet-UDCS can accurately characterize the endoscopic images and recognize polyps from the images. In addition, our DenseNet-UDCS model is superior in detection accuracy in comparison with state-of-the-art polyp recognition methods. Note to Practitioners-Wireless capsule endoscopy (WCE) is a crucial diagnostic tool for polyp detection and therapeutic monitoring, thanks to its noninvasive, user-friendly, and nonpainful properties. A challenge in harnessing the enormous potential of the WCE to benefit the gastrointestinal (GI) patients is that it requires clinicians to analyze a huge number of images (about 50 000 images for each patient). We propose a novel automatic polyp recognition scheme, namely, DenseNet-UDCS model, by addressing practical image unbalanced problem and small interclass variances and large intraclass differences in the data set. The comprehensive experimental results demonstrate superior reliability and robustness of the proposed model compared to the other polyp recognition approaches. Our DenseNet-UDCS model can be further applied in the clinical practice to provide valuable diagnosis information for GI disease recognition and precision medicine.","Deep learning,Image recognition,Task analysis,Data models,Biomedical imaging,Shape,Feature extraction,Category sensitive (CS) loss,densely connected convolutional network (DenseNet),polyp image classification,unbalanced discriminant (UD) loss",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Automation & Control Systems,,5.516,"WIRELESS,CAPSULE,ENDOSCOPY,CLASSIFICATION,IMAGES",IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING,,
78,A Fast and Low-Cost Repetitive Movement Pattern Indicator for Massive Dementia Screening,17,2,771-783,"Li Ting-Ying,Chien Yi-Wei,Chou Chi-Chun,Liao Chun-Feng,Cheah Wen-Ting,Fu Li-Chen,Cheng Cheryl Chia-Hui,Chou Chun-Chen,Chen I-An","Li TY,Chien YW,Chou CC,Liao CF,Cheah WT,Fu LC,Cheng CCH,Chou CC,Chen IA",Fu LC,10.1109/TASE.2019.2942386,National Taiwan University,"Because of the worldwide aging population, more and more elders suffer from dementia problem. Nowadays, it is an inconvenient and time-consuming process for medical doctors to diagnose elders who live independently with possible dementia because the process imposes a large quantity of diagnostic questions from a checklist that needs to be answered by elders themselves or their caregivers either directly or after a long-term observation. In order to help doctors to make this diagnostic process easier, this article proposes a supporting system that can quickly estimate the likelihood for an elder of having dementia based on 2 to 4 hours monitoring of a behavioral test done by the elder. During the test, the elder only needs to perform certain activities selected from the so-called instrumental activities of daily living (IADL) in a smart home environment, and their movement trajectories will be extracted from motion sensors deployed in the smart home environment and be analyzed to find a potential correlation with the indoor wandering patterns. A machine learning algorithm is selected to carry out the classification task, namely, into dementia and nondementia groups, based on our proposed features of the aforementioned wandering patterns. Two data sets are employed for performance evaluation, where the first one is 232 elders including seven dementia, whereas the second one is collected by ourselves from a senior center, which is 30 elders including nine dementia. It turns out that the average precision and recall for the first data set are both up to 98.3% with area under the ROC curve (AUC-ROC) being 0.846, and those for the second data set are 89.9% and 90.0% with AUC-ROC being 0.921. Note to Practitioners-We proposed a supporting system which can classify the elders as either dementia or nondementia with high accuracy. The trajectories of the elders will be extracted from motion sensors that deployed in the smart home environment. The indoor wandering patterns according to repetitive movements are analyzed and classified using the machine learning technique. The proposed system used ambient sensors instead of wearable sensors or cameras to let the elders feel more comfortable when they are being monitored. In addition, the proposed system only required a short period of time to screen the elders and easier for medical doctors to diagnose the elders without wasting time for asking the large quantity of diagnostic questions from a checklist that needs to be answered by the elders themselves or their caregivers.","Dementia,Smart homes,Sensors,Monitoring,Feature extraction,Trajectory,Dementia,indoor wandering pattern,machine learning,motion sensors,quickly monitor,smart home",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Automation & Control Systems,,,"MILD,COGNITIVE,IMPAIRMENT,ALZHEIMERS-DISEASE,NAIVE,BAYES,SYMPTOMS,BEHAVIOR,NETWORK,ELDERS",IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING,,
79,Automated Classification for Visual-Only Postmortem Inspection of Porcine Pathology,17,2,1005-1016,"McKenna Stephen,Amaral Telmo,Kyriazakis Ilias","McKenna S,Amaral T,Kyriazakis I",McKenna S,10.1109/TASE.2019.2960106,University of Dundee,"Several advantages would arise from the automated detection of pathologies of pig carcasses, including avoidance of the inherent risks of subjectivity and variability between human observers. Here, we develop a novel automated classification of two porcine offal pathologies at abattoir: a focal, localized pathology of the liver and a diffuse pathology of the heart, as cases in point. We develop a pattern recognition system based on machine learning to identify those organs that exhibit signs of the pathology of interest. Specifically, deep neural networks are trained to produce probability heat maps, highlighting regions on the surface of an organ potentially affected by a given condition. A final classification stage then decides whether a given organ is affected by the condition in question based on statistics computed from the heat map. We compare outcomes of automated classification with classification by expert pathologists. Results show the classification of liver and heart pathologies in agreement with an expert at levels comparable to, or exceeding, interexpert agreement. A system using methods such as those presented here has potential to overcome the limitations of human-based abattoir inspection, especially if this is based on visual-only inspection, and ultimately to provide a new gold standard for pathology. Note to Practitioners-The motivation for this article reflects the current requirement for visual-only inspection of livestock carcasses at slaughter houses and the need to provide a gold standard for recognition of carcass pathologies. Visual-only inspection is motivated by the need to reduce cross contamination between carcasses by manual palpation, but this leads to substantial variability in detection accuracy both within and between inspectors. This has significant public health implications. Here we present a system that comprises hardware to capture images of pig offal and software to analyze those images and identify cases of liver milk spots and hearts affected by pericarditis. It can classify high proportions of offal with accuracy comparable to that of veterinarians with extensive experience in pig pathology, thus demonstrating the potential to overcome the limitations of human-based abattoir inspection (especially if it is visual-only) and ultimately to provide a new gold standard. Our work is the first to address the automation of pig offal inspection, thus shedding light on the challenges associated with both appropriate image capture and successful image analysis, such as the need to cope with wide variations in the appearance of both normal and diseased organs, as well as different types of lesions and their impact on how much effort is required from experts in order to produce data needed to train the system. Future directions of work should include extending the system to identify more pathologies and implementing a real-time system to cope with production line speed.","Agriculture,food industry,machine vision,neural network applications",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Automation & Control Systems,,5.516,"SEGMENTATION,QUALITY",IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING,https://discovery.dundee.ac.uk/ws/files/40303397/AmaralKyriazakisMcKenna_IEEETASE.pdf,
80,Online Model-Free n-Step HDP With Stability Analysis,31,4,1255-1269,"Al Dabooni Seaar,Wunsch Donald C. II","Al Dabooni S,Wunsch DC",Al Dabooni S,10.1109/TNNLS.2019.2919614,University of Missouri System,"Because of a powerful temporal-difference (TD) with lambda [TD( lambda )] learning method, this paper presents a novel n-step adaptive dynamic programming (ADP) architecture that combines TD( lambda ) with regular TD learning for solving optimal control problems with reduced iterations. In contrast with a backward view learning of TD( lambda ) that is required an extra parameter named eligibility traces to update at the end of each episode (offline training), the new design in this paper has forward view learning, which is updated at each time step (online training) without needing the eligibility trace parameter in various applications without mathematical models. Therefore, the new design is called the online model-free n-step action-dependent (AD) heuristic dynamic programming [NSHDP( lambda )]. NSHDP( lambda ) has three neural networks: the critic network (CN) with regular one-step TD [TD(0)], the CN with n-step TD learning [or TD( lambda )], and the actor network (AN). Because the forward view learning does not require any extra eligibility traces associated with each state, the NSHDP( lambda ) architecture has low computational costs and is memory efficient. Furthermore, the stability is proven for NSHDP( lambda ) under certain conditions by using Lyapunov analysis to obtain the uniformly ultimately bounded (UUB) property. We compare the results with the performance of HDP and traditional action-dependent HDP( lambda ) [ADHDP( lambda )] with different lambda values. Moreover, a complex nonlinear system and 2-D maze problem are two simulation benchmarks in this paper, and the third one is an inverted pendulum simulation benchmark, which is presented in the supplemental material part of this paper. NSHDP( lambda ) performance is examined and compared with other ADP methods.","Mathematical model,Stability analysis,Dynamic programming,Programming,Training,Computer architecture,Learning systems,Adaptive dynamic programming (ADP),action-dependent (AD) heuristic dynamic programming (ADHDP),lambda-return,Lyapunov stability,uniformly ultimately bounded (UUB)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.746,"BACKPROPAGATION,REPRESENTATION",IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,,
81,Artificial intelligence in glioma imaging: challenges and advances,17,2,,"Jin Weina,Fatehi Mostafa,Abhishek Kumar,Mallya Mayur,Toyota Brian,Hamarneh Ghassan","Jin WN,Fatehi M,Abhishek K,Mallya M,Toyota B,Hamarneh G",Jin WN,10.1088/1741-2552/ab8131,Simon Fraser University,"Primary brain tumors including gliomas continue to pose significant management challenges to clinicians. While the presentation, the pathology, and the clinical course of these lesions are variable, the initial investigations are usually similar. Patients who are suspected to have a brain tumor will be assessed with computed tomography (CT) and magnetic resonance imaging (MRI). The imaging findings are used by neurosurgeons to determine the feasibility of surgical resection and plan such an undertaking. Imaging studies are also an indispensable tool in tracking tumor progression or its response to treatment. As these imaging studies are non-invasive, relatively cheap and accessible to patients, there have been many efforts over the past two decades to increase the amount of clinically-relevant information that can be extracted from brain imaging. Most recently, artificial intelligence (AI) techniques have been employed to segment and characterize brain tumors, as well as to detect progression or treatment-response. However, the clinical utility of such endeavours remains limited due to challenges in data collection and annotation, model training, and the reliability of AI-generated information.
We provide a review of recent advances in addressing the above challenges. First, to overcome the challenge of data paucity, different image imputation and synthesis techniques along with annotation collection efforts are summarized. Next, various training strategies are presented to meet multiple desiderata, such as model performance, generalization ability, data privacy protection, and learning with sparse annotations. Finally, standardized performance evaluation and model interpretability methods have been reviewed. We believe that these technical approaches will facilitate the development of a fully-functional AI tool in the clinical care of patients with gliomas.","glioma imaging,brain radiomics,machine learning,deep learning",Review,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"NEURAL-NETWORKS,DEEP,CLASSIFICATION,SEGMENTATION,TEMOZOLOMIDE,NEUROSCIENCE,MUTATIONS,SYSTEM,CANCER,1P%2F19Q",JOURNAL OF NEURAL ENGINEERING,http://arxiv.org/pdf/1911.12886,
82,Composition design of 7XXX aluminum alloys optimizing stress corrosion cracking resistance using machine learning,7,4,,"Cao Xinyu,Zhang Yingbo,Li Jiaheng,Hui Chen","Cao XY,Zhang YB,Li JH,Hui C",Zhang YB,10.1088/2053-1591/ab8492,Southwest Jiaotong University,"In this paper, three different strategies based on machine learning methods were applied to Al-Zn-Mg-Cu series alloy composition design with the targeted property of stress corrosion cracking (SCC) resistance. By comparing the results of the strategies, it was discovered that the performance of the efficient global optimization (EGO) method was better than that of response surface optimization method, and much better than that of Random method, among which the Al-6.05Zn-1.46Mg-1.32Cu-0.13Zr-0.02Ti-0.50Y-0.23Ce (named EGO alloy) alloy had the best stress corrosion cracking resistance. The slow strain rate test (SSRT) technique was carried out to compare the EGO alloy with the traditional 7N01 alloy. It indicated that the I-SCC of the new EGO alloy was lower than that of traditional 7N01 alloy for both single and double aging treatment. With the XRD, SEM and EDS analysis, it was found the rare earth elements formed Al8Cu4(Y, Ce) and quadrilateral phase Al20Ti2(Y, Ce) in the EGO alloy.","Al-Zn-Mg-Cu alloy,composition design,efficient global optimization,stress corrosion cracking",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Materials Science,,1.618,"MECHANICAL-PROPERTIES,HEAT-TREATMENT,MICROSTRUCTURE,STRENGTH,BEHAVIOR,EVOLUTION,RRA,SCC,ZR",MATERIALS RESEARCH EXPRESS,https://doi.org/10.1088/2053-1591/ab8492,
83,View-collaborative fuzzy soft subspace clustering for automatic medical image segmentation,79,13-14,9523-9542,"Zhao Kaifa,Jiang Yizhang,Xia Kaijian,Zhou Leyuan,Chen Yangyang,Xu Ke,Qian Pengjiang","Zhao KF,Jiang YZ,Xia KJ,Zhou LY,Chen YY,Xu K,Qian PJ",Qian PJ,10.1007/s11042-019-07974-7,Jiangnan University,"With the rapid development of medical imaging methodologies, such as magnetic resonance (MR) and positron emission tomography (PET)/MR, various types of MR images, which are acquired using inconsistent MR pulse sequences on the same patient, have been applied in medical-image-based diagnoses. A feature map extracted from an MR image describes the patient's condition from one perspective. By effectively using all feature maps from various MR images, it is possible to completely describe the intrinsic characteristics of the patient's condition to facilitate a diagnosis. Facing such a scenario, classic machine learning algorithms typically stack these feature maps for unified processing and do not explore the importance of each feature within a single feature map or the relationships among feature maps. To address these challenges, both multiview and subspace learning scenarios are considered in this study, and the multiview collaboration-based fuzzy soft subspace clustering (MVC-FSSC) algorithm is proposed. The MVC-FSSC algorithm not only strives to exploit the agreement of decisions across all views via collaborative learning but also strives to utilize the soft subspace-based weighting mechanism to automatically evaluate the contribution of each dimensional feature to each estimated cluster within a single view. Our experimental results indicate that the proposed MVC-FSSC algorithm can effectively explore the collaborative relations among all views and the importance of features in their respective views. Additionally, our MVC-FSSC method has substantial advantages over traditional clustering algorithms in MR image segmentation. Applying the MVC-FSSC algorithm to five patients' MR images, the average mean absolute prediction deviation (MAPD) is 98.62 +/- 8.34, which is significantly better than the score of 131.90 +/- 16.03 that was obtained using the collaborative fuzzy k-means (CO-FKM) algorithm and the score of 128.87 +/- 11.32 that was obtained using the quadratic weights and Gini-Simpson diversity-based fuzzy clustering (QWGSD-FC) algorithm.","Multiview clustering,Soft subspace clustering,Medical image segmentation,Collaborative learning",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"ALGORITHM,FUSION",MULTIMEDIA TOOLS AND APPLICATIONS,,
84,Automatic epilepsy detection using hybrid decomposition with multi class support vector method,79,15-16,9871-9890,Sujatha Krishnamoorthy,Sujatha K,Sujatha K,10.1007/s11042-019-08359-6,Wenzhou-Kean University,"The epilepsy has been detected from the electroencephalogram (EEG) by utilizing the complex wavelet transform with support vector machine. These methods successfully examine each and every frequency in the EEG signal for detecting the epilepsy with effective manner because epilepsy is one of the most important brain abnormalities which affect the entire brain function. The epilepsy is occurring due to the brain stroke, lack of blood flow, brain fever and so on, these lead to create the number of human deaths. So, the brain epilepsy needs to be analyzed and it has to be detected for improving the epilepsy recognition rate. But the major problem with the epilepsy recognition is the accuracy and efficiency of the classifier because of the traditional approximation entropy only extracts the minimum number of features which is difficult to detect the epilepsy with effective manner. These problems increase the false classification rate while analyzing the brain features. So, brain abnormalities has been automatically recognized by using the various machine learning steps like preprocessing, signal decomposition, feature extraction, feature selection and classification. In this research, the brain Epilepsy is recognized by applying the Hybrid Multi Class Support Vector Machine (HMCSVM). Then the performance of the system is analyzed using the experimental results and discussions.","Electroencephalogram,Epilepsy,Multi class support vector method,Signal decomposition",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,,MULTIMEDIA TOOLS AND APPLICATIONS,,
85,Deep learning convolutional neural network (CNN) With Gaussian mixture model for predicting pancreatic cancer,79,15-16,10233-10247,"Sekaran Kaushik,Chandana P.,Krishna N. Murali,Kadry Seifedine","Sekaran K,Chandana P,Krishna NM,Kadry S",Kadry S,10.1007/s11042-019-7419-5,Beirut Arab University,"The tremendous research towards medical health systems are giving ample scope for the computing systems to emerge with the latest innovations. These innovations are leading to the efficient implementations of the medical systems which involve in automatic diagnosis of the health related problems. The most important health research is going on towards cancer prediction, which has different forms and can be affected on different portions of the body parts. One of the most affected cancer that predicted to be incurable are Pancreatic Cancer, which cannot be treated efficiently once identified, in most of the cases it found to be unpredictable as it lies in the abdomen region below the stomach. Therefore the advancements in the medical research is trending towards the implementations of an automated systems which identifies the stages of cancer if affected and provide the better diagnosis and treatment if identified. Deep learning is one such area which extended its research towards medical imaging, which automates the process of diagnosing the problems of the patients when appended with the set of machines like CT/PET Scan systems. In this paper, the deep learning strategy named Convolutional Neural network (CNN) model is used to predict the cancer images of the pancreas, which is embedded with the model of Gaussian Mixture model with EM algorithm to predict the essential features from the CT Scan and predicts the percentage of cancer spread in the pancreas with the threshold parameters taken as a markers. The experimentation is carried out on the CT Scan images dataset of pancreas collected from the Cancer Imaging Archive (TCIA) consists of approximately 19,000 images supported by the National Institutes of Health Clinical Center to analyze the performance of the model.","Convolutional neural network (CNN),Gaussian mixture model (GMM),Expectation-Maximization algorithm (EM),TCIA",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,,MULTIMEDIA TOOLS AND APPLICATIONS,,
86,Predictive analytics & modeling for modern health care system for cerebral palsy patients,79,15-16,10285-10307,"Singh D. Narendhar,Hashmi Mohammad Farukh,Sharma Sudhir Kr.","Singh DN,Hashmi MF,Sharma SK",Hashmi MF,10.1007/s11042-019-07834-4,National Institute of Technology (NIT System),"The time-shifting elements and high between individual changeability make early forecast of a seizure express a difficult errand. Numerous examinations have demonstrated that EEG signals do have profitable data that if effectively broke down, could help in the expectation of seizures in epileptic patients before their event. A few numerical changes have been broke down for its connection with seizure beginning forecast and a progression of analyses were done to ensure their qualities. New calculations are exhibited to help elucidate, screen, and cross-approve the order of EEG signs to foresee the ictal (for example seizure) states, explicitly the preictal, interictal, and postictal states in the mind. These new strategies show promising outcomes in distinguishing the nearness of a preictal stage before the ictal state. Artificial Intelligence and Machine Learning are playing major role in Diagnosis and Predicting the diseases, EEG signal were recorded with 16 channel system from brain scalp and stored in system. From recorded database seizure levels were analyzed from each channel by articrafting with ICA and PCA algorithms and processed through Band pass filter to identify the Delta, Theta, Alpha and Beta levels. After collecting the brain signals from each channel they were bided with FFT to get the data in time domain series. A machine learning model is developed using python programming by sampling on obtained EEG data, sampled data is trained on to the system. Machine Learning algorithms were applied to the data to accuracy and predict the accuracy on developed model neural network is applied to identify the True-False values. The analyzed data is integrated with IOT framework to Diagnosis the Cerebral Palsy patient remotely. Remote monitoring system for the persons with Intellectual disabilities and update the health status to care takers time to time while they are at work. It's also reduces the patient work load by checking his details staying at home rather going to a hospital. If system identifies any changes in patient heart rate, brain signals, body temperature, the system alerts the doctor and respective relatives about patient's status over IOT and also stores the patient details in the cloud.","Electroencephalogram (EEG),Independent component analysis (ICA),Principal component analysis (PCA),Support vector machine (SVM),Internet of things,Fast Fourier transform (FFT)",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,EPILEPSY,MULTIMEDIA TOOLS AND APPLICATIONS,,
87,Integrating compositional pattern-producing networks and optimized convolution neural networks using deep learning techniques for detecting brain abnormalities,79,15-16,10489-10503,Velammal B. L.,Velammal BL,Velammal BL,10.1007/s11042-019-7174-7,Anna University,"In brain abnormality approach, accurate and reliable diagnosis is a critical component, because it provides potential abnormality in tissues as well as functional structures significantly to demarcate surgical plan. In the recent past, various diagnosing procedures have been carried out such as Double Density Discrete Wavelet Transform (DDDWT), Support Vector Machine (SVM) classifier, Convolutional Neural Networks etc., whereas treatment outcome and planning are the critical components. Build upon the successful deep learning approach, a novel brain abnormality diagnostic method has been developed by integrating Compositional Pattern Producing (CPP) and Optimized Convolutional Neural Networks (OCNN) in an unified framework. This hybrid approach includes Independent Component Analysis (ICA) with parallel factor and region of interest (ROI) for preprocessing, training CPP using image patches and fine tuning CPP-OCNN using image slices for segmentation as well as for extraction. This model could segment the images by slices than patches which are more accurate and less complex in segmentation with optimized kernel SVM classifier for abnormality detection. The system is evaluated based on MRI imaging datasets provided by CHB-MIT scalp EEG of micro bleeds dataset and efficiently validated with the help of the experimental results by minimizing the Root mean square and by improving the accuracy, smoothness, correlation, sensitivity and specificity using state of the art techniques.","Neural Networks,Independent component analysis,Electroencephalography (EEG),Discrete wavelet transform,Image slicing",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"TUMOR,SEGMENTATION",MULTIMEDIA TOOLS AND APPLICATIONS,,
88,An adaptive anchored neighborhood regression method for medical image enhancement,79,15-16,10533-10550,"Jiang Lihua,Ye Shuang,Yang Xiaomin,Ma Xiao,Lu Lu,Ahmad Awias,Jeon Gwanggil","Jiang LH,Ye S,Yang XM,Ma X,Lu L,Ahmad A,Jeon G",Yang XM; Lu L,10.1007/s11042-019-08353-y,Sichuan University,"Chinese Government has launched ambitious healthcare reform aiming to provide better healthcare services for both urban and rural residents via remote diagnosis. Recently, the requirement of high-resolution (HR) images becomes more urgent in the medical field, especially for remote diagnosis. Remote diagnosis is an important means of the Internet of Medical Things (IoMT), which senses patients' health status according to the medical images and transfers clinical data. Owing to the superiority of reconstruction speed and quality, adjusted anchored neighborhood regression has attracted much attention. However, the hypercells formed by neighborhoods may not center on atoms, and hence it is not accurate to group the neighborhood centered on atoms. In this paper, we propose an adaptive medical image enhancement method. Specifically, we cluster training samples into neighborhoods centered on patches. The LR space is re-divided by replacing dictionary atoms with cluster patch centers as the center of hypercells. By this means, the neighborhood anchored in the patch is defined by computing its K nearest patches, and then applied to pre-compute the projection to map low-resolution patch onto the HR domain. Average quantitative results show that our method is superior to the compared methods in two common medical datasets by 1.19% and 2.32%, respectively, while maintaining the similar running time.","Medical image,Enhancement,Adaptive anchored neighborhood,Hypercells",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"SUPERRESOLUTION,INTERPOLATION",MULTIMEDIA TOOLS AND APPLICATIONS,,
89,Detecting heart failure using wearables: a pilot study,41,4,,"Shah Amit J.,Isakadze Nino,Levantsevych Oleksiy,Vest Adriana,Clifford Gari,Nemati Shamim","Shah AJ,Isakadze N,Levantsevych O,Vest A,Clifford G,Nemati S",Shah AJ,10.1088/1361-6579/ab7f93,Emory University,"Objective: Heart failure (HF) can be difficult to diagnose by physical examination alone. We examined whether wristband technologies may facilitate more accurate bedside testing. Approach: We studied on a cohort of 97 monitored in-patients and performed a cross-sectional analysis to predict HF with data from the wearable and other clinically available data. We recorded photoplethysmography (PPG) and accelerometry data using the wearable at 128 samples per second for 5 min. HF diagnosis was ascertained via chart review. We extracted four features of beat-to-beat variability and signal quality, and used them as inputs to a machine learning classification algorithm. Main results: The median [interquartile] age was 60 [51 68] years, 65% were men, and 54% had heart failure; in addition, 30% had acutely decompensated HF. The best 10-fold cross-validated testing performance for the diagnosis of HF was achieved using a support vector machine. The waveform-based features alone achieved a pooled test area under the curve (AUC) of 0.80; when a high-sensitivity cut-point (90%) was chosen, the specificity was 50%. When adding demographics, medical history, and vital signs, the AUC improved to 0.87, and specificity improved to 72% (90% sensitivity). Significance: In a cohort of monitored in-patients, we were able to build an HF classifier from data gathered on a wristband wearable. To our knowledge, this is the first study to demonstrate an algorithm using wristband technology to classify HF patients. This supports the use of such a device as an adjunct tool in bedside diagnostic evaluation and risk stratification.","heart failure,mobile health technology,biomedical informatics",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,,,PHYSIOLOGICAL MEASUREMENT,,
90,Chemical sensor systems based on 2D and thin film materials,7,2,,"Mackin Charles,Fasoli Andrea,Xue Mantian,Lin Yuxuan,Adebiyi Aminat,Bozano Luisa,Palacios Tomas","Mackin C,Fasoli A,Xue MT,Lin YX,Adebiyi A,Bozano L,Palacios T",Mackin C,10.1088/2053-1583/ab6e88,International Business Machines (IBM),"This review examines the advantages of two-dimensional (2D) and thin film materials in the development of chemical sensor systems. More specifically, this paper focuses on the use of graphene, transition metal dichalcogenides (TMDs), and thin film metal-oxide semiconductors (MOX) in gasand liquid-phase chemical sensing applications. Key features in terms of material properties, device characteristics, as well as scalability for system development are examined. Key challenges associated with various sensing approaches (e.g. optical, electrochemical, FET/chemiresistive) are presented along with recent advances. Lastly, common methods for preprocessing and pattern recognition are summarized while highlighting the development of olfaction-inspired sensor systems to motivate the use of machine learning for data analysis.","graphene,artificial neural networks,metal oxide semiconductors,systems,chemical sensors,biosensors",Review,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Materials Science,,8.161,"ION-SELECTIVE,ELECTRODES,HIGH-PERFORMANCE,WSE2,GAS,SENSORS,LARGE-AREA,VAPOR-DEPOSITION,NEURAL-NETWORKS,MONOLAYER,MOS2,2-DIMENSIONAL,SEMICONDUCTORS,TEMPERATURE,MODULATION,DRIFT,COUNTERACTION",2D MATERIALS,,
91,A novel structure-property relationship model based on machine learning,28,3,,"Zhang Huiran,Guo Zhiting,Hu Hongqing,Zhou Gaofeng,Liu Qing,Xu Yan,Qian Quan,Dai Dongbo","Zhang H,Guo Z,Hu HQ,Zhou GF,Liu Q,Xu Y,Qian Q,Dai DB",Dai DB,10.1088/1361-651X/ab6bb7,Shanghai University,"In materials science, the relationship between the material internal structure and its associated macroscale properties can be used to guide the design of materials. In this study, we constructed an interpretative machine learning (ML) model to capture the structure-property relationship and predict the solid solubility in binary alloy systems. To do this, we used a dataset containing about 1843 binary alloys and corresponding experiment values of solid solubility. We designed a common function to represent the relationship between individual descriptor and solid solubility, and a deep neural network to integrate the multiple functions. The resulting model can correctly predict the solid solubility value than other ML models. What is more, based on this model, it is feasible to analyze the effect of structures on target property.","binary alloys,structure-property relationship,solid solution,machine learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Materials Science,Physics",,2.439,"SOLID,SOLUBILITY,MECHANICAL-PROPERTIES,PREDICTION,SUPPORT,SELECTION,TERNARY,DESIGN,BINARY,ALLOYS,SCALE",MODELLING AND SIMULATION IN MATERIALS SCIENCE AND ENGINEERING,,
92,Mesoporous Mn-Doped Fe Nanoparticle-Modified Reduced Graphene Oxide for Ethyl Violet Elimination: Modeling and Optimization Using Artificial Intelligence,8,4,,"Hou Yu,Qi Jimei,Hu Jiwei,Xiang Yiqiu,Xin Ling,Wei Xionghui","Hou Y,Qi JM,Hu JW,Xiang YQ,Xin L,Wei XH",Hu JW,10.3390/pr8040488,Guizhou Normal University,"Mesoporous Mn-doped Fe nanoparticle-modified reduced graphene oxide (Mn-doped Fe/rGO) was prepared through a one-step co-precipitation method, which was then used to eliminate ethyl violet (EV) in wastewater. The prepared Mn-doped Fe/rGO was characterized by X-ray diffraction, X-ray photoelectron spectroscopy, Raman spectroscopy, high-resolution transmission electron microscopy, scanning electron microscopy, energy dispersive spectroscopy, N-2-sorption, small angle X-ray diffraction and superconducting quantum interference device. The Brunauer-Emmett-Teller specific surface area of Mn-doped Fe/rGO composites was 104.088 m(2)/g. The EV elimination by Mn-doped Fe/rGO was modeled and optimized by artificial intelligence (AI) models (i.e., radial basis function network, random forest, artificial neural network genetic algorithm (ANN-GA) and particle swarm optimization). Among these AI models, ANN-GA is considered as the best model for predicting the removal efficiency of EV by Mn-doped Fe/rGO. The evaluation of variables shows that dosage gives the maximum importance to Mn-doped Fe/rGO removal of EV. The experimental data were fitted to kinetics and adsorption isotherm models. The results indicated that the process of EV removal by Mn-doped Fe/rGO obeyed the pseudo-second-order kinetics model and Langmuir isotherm, and the maximum adsorption capacity was 1000.00 mg/g. This study provides a possibility for synthesis of Mn-doped Fe/rGO by co-precipitation as an excellent material for EV removal from the aqueous phase.","ethyl violet,Mn-doped Fe,rGO nanocomposites,mesoporous materials,artificial intelligence,gradient boosted regression trees",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Engineering,,2.824,"RBF,NEURAL-NETWORK,AQUEOUS-SOLUTION,EXPERIMENTAL-DESIGN,CHEMICAL-REDUCTION,ADSORPTION,DYE,REMOVAL,WATER,SORPTION,CARBON",PROCESSES,https://www.mdpi.com/2227-9717/8/4/488/pdf,
93,Can Machine Learning Predict Stress Reduction Based on Wearable Sensors' Data Following Relaxation at Workplace? A Pilot Study,8,4,,"Tonacci Alessandro,Dellabate Alessandro,Dieni Andrea,Bachi Lorenzo,Sansone Francesco,Conte Raffaele,Billeci Lucia","Tonacci A,Dellabate A,Dieni A,Bachi L,Sansone F,Conte R,Billeci L",Tonacci A,10.3390/pr8040448,"Natl Res Council Italy IFC NR, Inst Clin Physiol, Via Moruzzi 1, I-56124 Pisa, Italy.","Nowadays, psychological stress represents a burdensome condition affecting an increasing number of subjects, in turn putting into practice several strategies to cope with this issue, including the administration of relaxation protocols, often performed in non-structured environments, like workplaces, and constrained within short times. Here, we performed a quick relaxation protocol based on a short audio and video, and analyzed physiological signals related to the autonomic nervous system (ANS) activity, including electrocardiogram (ECG) and galvanic skin response (GSR). Based on the features extracted, machine learning was applied to discriminate between subjects benefitting from the protocol and those with negative or no effects. Twenty-four healthy volunteers were enrolled for the protocol, equally and randomly divided into Group A, performing an audio-video + video-only relaxation, and Group B, performing an audio-video + audio-only protocol. From the ANS point of view, Group A subjects displayed a significant difference in the heart rate variability-related parameter SDNN across the test phases, whereas both groups displayed a different GSR response, albeit at different levels, with Group A displaying greater differences across phases with respect to Group B. Overall, the majority of the volunteers enrolled self-reported an improvement of their well-being status, according to structured questionnaires. The use of neural networks helped in discriminating those with a positive effect of the relaxation protocol from those with a negative/neutral impact based on basal autonomic features with a 79.2% accuracy. The results obtained demonstrated a significant heterogeneity in autonomic effects of the relaxation, highlighting the importance of maintaining a structured, well-defined protocol to produce significant benefits at the ANS level. Machine learning approaches can be useful to predict the outcome of such protocols, therefore providing subjects less prone to positive responses with personalized advice that could improve the effect of such protocols on self-relaxation perception.","autonomic nervous system,ECG,galvanic skin response,heart rate,heart rate variability,machine learning,mindfulness,neural networks,relaxation,signal processing,skin conductance,wearable sensors,yoga",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Engineering,,,"AUTONOMIC,NERVOUS-SYSTEM,YOGA,MEDITATION",PROCESSES,https://www.mdpi.com/2227-9717/8/4/448/pdf,
94,Monitoring Mixing Processes Using Ultrasonic Sensors and Machine Learning,20,7,,"Bowler Alexander L.,Bakalis Serafim,Watson Nicholas J.","Bowler AL,Bakalis S,Watson NJ",Watson NJ,10.3390/s20071813,University of Nottingham,"Mixing is one of the most common processes across food, chemical, and pharmaceutical manufacturing. Real-time, in-line sensors are required for monitoring, and subsequently optimising, essential processes such as mixing. Ultrasonic sensors are low-cost, real-time, in-line, and applicable to characterise opaque systems. In this study, a non-invasive, reflection-mode ultrasonic measurement technique was used to monitor two model mixing systems. The two systems studied were honey-water blending and flour-water batter mixing. Classification machine learning models were developed to predict if materials were mixed or not mixed. Regression machine learning models were developed to predict the time remaining until mixing completion. Artificial neural networks, support vector machines, long short-term memory neural networks, and convolutional neural networks were tested, along with different methods for engineering features from ultrasonic waveforms in both the time and frequency domain. Comparisons between using a single sensor and performing multisensor data fusion between two sensors were made. Classification accuracies of up to 96.3% for honey-water blending and 92.5% for flour-water batter mixing were achieved, along with R-2 values for the regression models of up to 0.977 for honey-water blending and 0.968 for flour-water batter mixing. Each prediction task produced optimal performance with different algorithms and feature engineering methods, vindicating the extensive comparison between different machine learning approaches.","food and drink manufacturing,industry 4.0,digital manufacturing,mixing,ultrasonic sensors,machine learning,convolutional neural networks,long short-term memory neural networks,wavelet transform",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"ARTIFICIAL,NEURAL-NETWORKS,RHEOLOGICAL,PROPERTIES,MECHANICAL-PROPERTIES,FLAW,CLASSIFICATION,SYSTEM,DOUGH,IDENTIFICATION,SPECTROSCOPY,DISPERSION,PREDICTION",SENSORS,https://www.mdpi.com/1424-8220/20/7/1813/pdf,
95,A Smartphone Lightweight Method for Human Activity Recognition Based on Information Theory,20,7,,"Braganca Hendrio,Colonna Juan G.,Lima Wesllen Sousa,Souto Eduardo","Braganca H,Colonna JG,Lima WS,Souto E",Braganca H,10.3390/s20071856,Universidade Federal de Amazonas,"Smartphones have emerged as a revolutionary technology for monitoring everyday life, and they have played an important role in Human Activity Recognition (HAR) due to its ubiquity. The sensors embedded in these devices allows recognizing human behaviors using machine learning techniques. However, not all solutions are feasible for implementation in smartphones, mainly because of its high computational cost. In this context, the proposed method, called HAR-SR, introduces information theory quantifiers as new features extracted from sensors data to create simple activity classification models, increasing in this way the efficiency in terms of computational cost. Three public databases (SHOAIB, UCI, WISDM) are used in the evaluation process. The results have shown that HAR-SR can classify activities with 93% accuracy when using a leave-one-subject-out cross-validation procedure (LOSO).","human activity recognition,symbolic representation,discrete domain,time series classification,information theory,inertial sensors",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"MOBILE,SIMILARITY",SENSORS,https://www.mdpi.com/1424-8220/20/7/1856/pdf,
96,Investigating the Use of Pretrained Convolutional Neural Network on Cross-Subject and Cross-Dataset EEG Emotion Recognition,20,7,,"Cimtay Yucel,Ekmekcioglu Erhan","Cimtay Y,Ekmekcioglu E",Cimtay Y,10.3390/s20072034,Loughborough University,"The electroencephalogram (EEG) has great attraction in emotion recognition studies due to its resistance to deceptive actions of humans. This is one of the most significant advantages of brain signals in comparison to visual or speech signals in the emotion recognition context. A major challenge in EEG-based emotion recognition is that EEG recordings exhibit varying distributions for different people as well as for the same person at different time instances. This nonstationary nature of EEG limits the accuracy of it when subject independency is the priority. The aim of this study is to increase the subject-independent recognition accuracy by exploiting pretrained state-of-the-art Convolutional Neural Network (CNN) architectures. Unlike similar studies that extract spectral band power features from the EEG readings, raw EEG data is used in our study after applying windowing, pre-adjustments and normalization. Removing manual feature extraction from the training system overcomes the risk of eliminating hidden features in the raw data and helps leverage the deep neural network's power in uncovering unknown features. To improve the classification accuracy further, a median filter is used to eliminate the false detections along a prediction interval of emotions. This method yields a mean cross-subject accuracy of 86.56% and 78.34% on the Shanghai Jiao Tong University Emotion EEG Dataset (SEED) for two and three emotion classes, respectively. It also yields a mean cross-subject accuracy of 72.81% on the Database for Emotion Analysis using Physiological Signals (DEAP) and 81.8% on the Loughborough University Multimodal Emotion Dataset (LUMED) for two emotion classes. Furthermore, the recognition model that has been trained using the SEED dataset was tested with the DEAP dataset, which yields a mean prediction accuracy of 58.1% across all subjects and emotion classes. Results show that in terms of classification accuracy, the proposed approach is superior to, or on par with, the reference subject-independent EEG emotion recognition studies identified in literature and has limited complexity due to the elimination of the need for feature extraction.","EEG,emotion recognition,pretrained models,convolutional neural network,dense layer,subject independency,dataset independency,raw data,filtering on output",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"FEATURES,KERNEL",SENSORS,https://res.mdpi.com/d_attachment/sensors/sensors-20-02034/article_deploy/sensors-20-02034.pdf,
97,Ultrasound Image-Based Diagnosis of Malignant Thyroid Nodule Using Artificial Intelligence,20,7,,"Dat Tien Nguyen,Kang Jin Kyu,Tuyen Danh Pham,Batchuluun Ganbayar,Park Kang Ryoung","Nguyen DT,Kang JK,Pham TD,Batchuluun G,Park KR",Pham TD,10.3390/s20071822,Dongguk University,"Computer-aided diagnosis systems have been developed to assist doctors in diagnosing thyroid nodules to reduce errors made by traditional diagnosis methods, which are mainly based on the experiences of doctors. Therefore, the performance of such systems plays an important role in enhancing the quality of a diagnosing task. Although there have been the state-of-the art studies regarding this problem, which are based on handcrafted features, deep features, or the combination of the two, their performances are still limited. To overcome these problems, we propose an ultrasound image-based diagnosis of the malignant thyroid nodule method using artificial intelligence based on the analysis in both spatial and frequency domains. Additionally, we propose the use of weighted binary cross-entropy loss function for the training of deep convolutional neural networks to reduce the effects of unbalanced training samples of the target classes in the training data. Through our experiments with a popular open dataset, namely the thyroid digital image database (TDID), we confirm the superiority of our method compared to the state-of-the-art methods.","ultrasound image,malignant thyroid nodule,artificial intelligence,deep learning,weighted binary cross-entropy loss",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"NETWORK-BASED,METHOD,LESION,CLASSIFICATION,NEURAL-NETWORKS,FEATURES,SEGMENTATION,SELECTION",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7180806,
98,Detection of Atrial Fibrillation Using 1D Convolutional Neural Network,20,7,,"Hsieh Chaur-Heh,Li Yan-Shuo,Hwang Bor-Jiunn,Hsiao Ching-Hua","Hsieh CH,Li YS,Hwang BJ,Hsiao CH",Hwang BJ,10.3390/s20072136,Ming Chuan University,"The automatic detection of atrial fibrillation (AF) is crucial for its association with the risk of embolic stroke. Most of the existing AF detection methods usually convert 1D time-series electrocardiogram (ECG) signal into 2D spectrogram to train a complex AF detection system, which results in heavy training computation and high implementation cost. This paper proposes an AF detection method based on an end-to-end 1D convolutional neural network (CNN) architecture to raise the detection accuracy and reduce network complexity. By investigating the impact of major components of a convolutional block on detection accuracy and using grid search to obtain optimal hyperparameters of the CNN, we develop a simple, yet effective 1D CNN. Since the dataset provided by PhysioNet Challenge 2017 contains ECG recordings with different lengths, we also propose a length normalization algorithm to generate equal-length records to meet the requirement of CNN. Experimental results and analysis indicate that our method of 1D CNN achieves an average F-1 score of 78.2%, which has better detection accuracy with lower network complexity, as compared with the existing deep learning-based methods.","electrocardiogram (ECG),atrial fibrillation (AF),convolutional neural network (CNN),deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"FEATURE-SELECTION,ECG,CLASSIFICATION,RECOGNITION",SENSORS,https://europepmc.org/articles/pmc7180882?pdf=render,
99,End-to-End Deep Learning Fusion of Fingerprint and Electrocardiogram Signals for Presentation Attack Detection,20,7,,"Jomaa Rami M.,Mathkour Hassan,Bazi Yakoub,Islam Md Saiful","Jomaa RM,Mathkour H,Bazi Y,Islam MS",Jomaa RM,10.3390/s20072085,King Saud University,"Although fingerprint-based systems are the commonly used biometric systems, they suffer from a critical vulnerability to a presentation attack (PA). Therefore, several approaches based on a fingerprint biometrics have been developed to increase the robustness against a PA. We propose an alternative approach based on the combination of fingerprint and electrocardiogram (ECG) signals. An ECG signal has advantageous characteristics that prevent the replication. Combining a fingerprint with an ECG signal is a potentially interesting solution to reduce the impact of PAs in biometric systems. We also propose a novel end-to-end deep learning-based fusion neural architecture between a fingerprint and an ECG signal to improve PAdetection in fingerprint biometrics. Our model uses state-of-the-art EfficientNets for generating a fingerprint feature representation. For the ECG, we investigate three different architectures based on fully-connected layers (FC), a 1D-convolutional neural network (1D-CNN), and a 2D-convolutional neural network (2D-CNN). The 2D-CNN converts the ECG signals into an image and uses inverted Mobilenet-v2 layers for feature generation. We evaluated the method on a multimodal dataset, that is, a customized fusion of the LivDet 2015 fingerprint dataset and ECG data from real subjects. Experimental results reveal that this architecture yields a better average classification accuracy compared to a single fingerprint modality.","fingerprint,ECG,presentation attack detection,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"CONVOLUTIONAL,NEURAL-NETWORKS,ECG,SYSTEM,BIOMETRICS",SENSORS,https://europepmc.org/articles/pmc7181006?pdf=render,
100,Uncertainty in Blood PressureMeasurement Estimated Using Ensemble-Based Recursive Methodology,20,7,,"Lee Soojeong,Dajani Hilmi R.,Rajan Sreeraman,Lee Gangseong,Groza Voicu Z.","Lee S,Dajani HR,Rajan S,Lee G,Groza VZ",Lee S,10.3390/s20072108,Sejong University,"Automated oscillometric blood pressure monitors are commonly used to measure blood pressure for many patients at home, office, and medical centers, and they have been actively studied recently. These devices usually provide a single blood pressure point and they are not able to indicate the uncertainty of the measured quantity. We propose a new technique using an ensemble-based recursive methodology to measure uncertainty for oscillometric blood pressure measurements. There are three stages we consider: the first stage is pre-learning to initialize good parameters using the bagging technique. In the second stage, we fine-tune the parameters using the ensemble-based recursive methodology that is used to accurately estimate blood pressure and then measure the uncertainty for the systolic blood pressure and diastolic blood pressure in the third stage.","uncertainty,confidence interval,oscillometry blood pressure measurement,deep neural,network,ensemble method",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,"PRESSURE-MEASUREMENT,CONFIDENCE-INTERVAL,ALGORITHM",SENSORS,https://europepmc.org/articles/pmc7180780?pdf=render,
