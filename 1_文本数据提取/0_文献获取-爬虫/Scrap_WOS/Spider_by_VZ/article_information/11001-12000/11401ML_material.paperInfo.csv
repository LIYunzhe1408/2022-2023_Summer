,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Hyperspectral Imaging for the Detection of Glioblastoma Tumor Cells in H&E Slides Using Convolutional Neural Networks,20,7,,"Ortega Samuel,Halicek Martin,Fabelo Himar,Camacho Rafael,de la Luz Plaza Maria,Godtliebsen Fred,Callico Gustavo M.,Fei Baowei","Ortega S,Halicek M,Fabelo H,Camacho R,Plaza MDL,Godtliebsen F,Callico GM,Fei BW",Ortega S; Fei BW,10.3390/s20071911,University of Texas System,"Hyperspectral imaging (HSI) technology has demonstrated potential to provide useful information about the chemical composition of tissue and its morphological features in a single image modality. Deep learning (DL) techniques have demonstrated the ability of automatic feature extraction from data for a successful classification. In this study, we exploit HSI and DL for the automatic differentiation of glioblastoma (GB) and non-tumor tissue on hematoxylin and eosin (H&E) stained histological slides of human brain tissue. GB detection is a challenging application, showing high heterogeneity in the cellular morphology across different patients. We employed an HSI microscope, with a spectral range from 400 to 1000 nm, to collect 517 HS cubes from 13 GB patients using 20x magnification. Using a convolutional neural network (CNN), we were able to automatically detect GB within the pathological slides, achieving average sensitivity and specificity values of 88% and 77%, respectively, representing an improvement of 7% and 8% respectively, as compared to the results obtained using RGB (red, green, and blue) images. This study demonstrates that the combination of hyperspectral microscopic imaging and deep learning is a promising tool for future computational pathologies.","hyperspectral imaging,medical optics and biotechnology,optical pathology,convolutional neural networks,tissue diagnostics,tissue characterization,glioblastoma",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,NUCLEI,SENSORS,https://accedacris.ulpgc.es/jspui/bitstream/10553/73844/2/hyperspectral_imaging_detection.pdf,
2,EEG Based Classification of Long-Term Stress Using Psychological Labeling,20,7,,"Saeed Sanay Muhammad Umar,Anwar Syed Muhammad,Khalid Humaira,Majid Muhammad,Bagci Ulas","Saeed SMU,Anwar SM,Khalid H,Majid M,Bagci U",Anwar SM,10.3390/s20071886,University of Engineering & Technology Taxila,"Stress research is a rapidly emerging area in the field of electroencephalography (EEG) signal processing. The use of EEG as an objective measure for cost effective and personalized stress management becomes important in situations like the nonavailability of mental health facilities. In this study, long-term stress was classified with machine learning algorithms using resting state EEG signal recordings. The labeling for the stress and control groups was performed using two currently accepted clinical practices: (i) the perceived stress scale score and (ii) expert evaluation. The frequency domain features were extracted from five-channel EEG recordings in addition to the frontal and temporal alpha and beta asymmetries. The alpha asymmetry was computed from four channels and used as a feature. Feature selection was also performed to identify statistically significant features for both stress and control groups (via t-test). We found that support vector machine was best suited to classify long-term human stress when used with alpha asymmetry as a feature. It was observed that the expert evaluation-based labeling method had improved the classification accuracy by up to 85.20%. Based on these results, it is concluded that alpha asymmetry may be used as a potential bio-marker for stress classification, when labels are assigned using expert evaluation.","long-term stress,electroencephalography,machine learning,perceived stress scale,expert evaluation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"MENTAL,STRESS,ASYMMETRY",SENSORS,https://www.mdpi.com/1424-8220/20/7/1886/pdf,
3,Deep Learning Approaches for Detecting Freezing of Gait in Parkinson's Disease Patients through On-Body Acceleration Sensors,20,7,,"Sigcha Luis,Costa Nelson,Pavon Ignacio,Costa Susana,Arezes Pedro,Manuel Lopez Juan,De Arcas Guillermo","Sigcha L,Costa N,Pavon I,Costa S,Arezes P,Lopez JM,De Arcas G",Pavon I,10.3390/s20071895,Universidad Politecnica de Madrid,"Freezing of gait (FOG) is one of the most incapacitating motor symptoms in Parkinson's disease (PD). The occurrence of FOG reduces the patients' quality of live and leads to falls. FOG assessment has usually been made through questionnaires, however, this method can be subjective and could not provide an accurate representation of the severity of this symptom. The use of sensor-based systems can provide accurate and objective information to track the symptoms' evolution to optimize PD management and treatments. Several authors have proposed specific methods based on wearables and the analysis of inertial signals to detect FOG in laboratory conditions, however, its performance is usually lower when being used at patients' homes. This study presents a new approach based on a recurrent neural network (RNN) and a single waist-worn triaxial accelerometer to enhance the FOG detection performance to be used in real home-environments. Also, several machine and deep learning approaches for FOG detection are evaluated using a leave-one-subject-out (LOSO) cross-validation. Results show that modeling spectral information of adjacent windows through an RNN can bring a significant improvement in the performance of FOG detection without increasing the length of the analysis window (required to using it as a cue-system).","IMU,accelerometer,convolutional neural networks,LSTM,consecutive windows,denoising autoencoder,time distributed,spectral representation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"FEATURE-EXTRACTION,FALLS,ACCELEROMETER,QUESTIONNAIRE,NETWORKS,RISK",SENSORS,https://www.mdpi.com/1424-8220/20/7/1895/pdf,
4,Investigation of Machine Learning Approaches for Traumatic Brain Injury Classification via EEG Assessment in Mice,20,7,,"Vishwanath Manoj,Jafarlou Salar,Shin Ikhwan,Lim Miranda M.,Dutt Nikil,Rahmani Amir M.,Cao Hung","Vishwanath M,Jafarlou S,Shin I,Lim MM,Dutt N,Rahmani AM,Cao H",Cao H,10.3390/s20072027,University of California System,"Due to the difficulties and complications in the quantitative assessment of traumatic brain injury (TBI) and its increasing relevance in today's world, robust detection of TBI has become more significant than ever. In this work, we investigate several machine learning approaches to assess their performance in classifying electroencephalogram (EEG) data of TBI in a mouse model. Algorithms such as decision trees (DT), random forest (RF), neural network (NN), support vector machine (SVM), K-nearest neighbors (KNN) and convolutional neural network (CNN) were analyzed based on their performance to classify mild TBI (mTBI) data from those of the control group in wake stages for different epoch lengths. Average power in different frequency sub-bands and alpha:theta power ratio in EEG were used as input features for machine learning approaches. Results in this mouse model were promising, suggesting similar approaches may be applicable to detect TBI in humans in practical scenarios.","electroencephalogram (EEG),traumatic brain Injury (TBI)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,MODEL,SENSORS,https://res.mdpi.com/d_attachment/sensors/sensors-20-02027/article_deploy/sensors-20-02027.pdf,
5,Automated Transverse Crack Mapping System with Optical Sensors and Big Data Analytics,20,7,,"Won Kwanghee,Sim Chungwook","Won K,Sim C",Sim C,10.3390/s20071838,University of Nebraska System,"Transverse cracks on bridge decks provide the path for chloride penetration and are the major reason for deck deterioration. For such reasons, collecting information related to the crack widths and spacing of transverse cracks are important. In this study, we focused on developing a data pipeline for automated crack detection using non-contact optical sensors. We developed a data acquisition system that is able to acquire data in a fast and simple way without obstructing traffic. Understanding that GPS is not always available and odometer sensor data can only provide relative positions along the direction of traffic, we focused on providing an alternative localization strategy only using optical sensors. In addition, to improve existing crack detection methods which mostly rely on the low-intensity and localized line-segment characteristics of cracks, we considered the direction and shape of the cracks to make our machine learning approach smarter. The proposed system may serve as a useful inspection tool for big data analytics because the system is easy to deploy and provides multiple properties of cracks. Progression of crack deterioration, if any, both in spatial and temporal scale, can be checked and compared if the system is deployed multiple times.","optical sensor,computer vision,big data pipeline,automated transverse crack mapping,bridge deck",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://www.mdpi.com/1424-8220/20/7/1838/pdf,
6,Estimating Exerted Hand Force via Force Myography to Interact with a Biaxial Stage in Real-Time by Learning Human Intentions: A Preliminary Investigation,20,7,,"Zakia Umme,Menon Carlo","Zakia U,Menon C",Menon C,10.3390/s20072104,Simon Fraser University,"Force myography (FMG) signals can read volumetric changes of muscle movements, while a human participant interacts with the environment. For collaborative activities, FMG signals could potentially provide a viable solution to controlling manipulators. In this paper, a novel method to interact with a two-degree-of-freedom (DoF) system consisting of two perpendicular linear stages using FMG is investigated. The method consists in estimating exerted hand forces in dynamic arm motions of a participant using FMG signals to provide velocity commands to the biaxial stage during interactions. Five different arm motion patterns with increasing complexities, i.e., ""x-direction"", ""y-direction"", ""diagonal"", ""square"", and ""diamond"", were considered as human intentions to manipulate the stage within its planar workspace. FMG-based force estimation was implemented and evaluated with a support vector regressor (SVR) and a kernel ridge regressor (KRR). Real-time assessments, where 10 healthy participants were asked to interact with the biaxial stage by exerted hand forces in the five intended arm motions mentioned above, were conducted. Both the SVR and the KRR obtained higher estimation accuracies of 90-94% during interactions with simple arm motions (x-direction and y-direction), while for complex arm motions (diagonal, square, and diamond) the notable accuracies of 82-89% supported the viability of the FMG-based interactive control.","force myography signal,exerted hand force,intended arm motion,biaxial stage,planar workspace,collaborative interactions,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,"EMG,PREDICTION,WRIST,MODEL",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7180929,
7,Virtual Museums as Learning Agents,12,7,,Daniela Linda,Daniela L,Daniela L,10.3390/su12072698,University of Latvia,"Virtual solutions for exhibiting museum collections are no longer a novelty, as such experiences already exist in the world, but the remote use of museum collections for learning purposes has so far not been widely used in the educational environment. This article analyzes virtual museum applications by evaluating them from a learning perspective, including 25 criteria in the evaluation rubric divided into three groups: (i) Technical performance; (ii) information architecture; and (iii) educational value. This will enable educators to select the most appropriate material for their specific learning purpose and to plan the most appropriate learning strategies by organizing training sessions to acquire knowledge that can be enhanced by museum information and teaching students digital skills in evaluating information available in the digital environment, analyzing its pros and cons to teach them how to develop new innovative solutions. The research is carried out from a phenomenological perspective; to be more precise, virtual museums are analyzed using the principles of transcendental design and a hermeneutic design is used to interpret the resulting data. A total of 36 applications of virtual museums were analyzed, whereupon the results were compiled using static data analysis software, while 13 applications were used for the hermeneutic data analysis. The results suggest that the strength of virtual museums is in information architecture, but less attention is paid to the educational value of the material, which points to the need to change the principles of virtual museum design and emphasizes the role of teachers in using virtual museums as learning agents.","virtual museums,technical performance,information architecture,educational value,learning agent,learning perspective,evaluation rubric",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Science & Technology - Other Topics,Environmental Sciences & Ecology",,3.473,"AUGMENTED,REALITY,EDUCATION,FRAMEWORK",SUSTAINABILITY,https://www.mdpi.com/2071-1050/12/7/2698/pdf,
8,Computational Hybrid Machine Learning Based Prediction of Shear Capacity for Steel Fiber Reinforced Concrete Beams,12,7,,"Hai-Bang Ly,Tien-Thinh Le,Huong-Lan Thi Vu,Van Quan Tran,Lu Minh Le,Binh Thai Pham","Ly HB,Le TT,Vu HLT,Tran VQ,Le LM,Pham BT",Ly HB; Pham BT,10.3390/su12072709,"Univ Transport Technol, Hanoi 100000, Vietnam.","Understanding shear behavior is crucial for the design of reinforced concrete beams and sustainability in construction and civil engineering. Although numerous studies have been proposed, predicting such behavior still needs further improvement. This study proposes a soft-computing tool to predict the ultimate shear capacities (USCs) of concrete beams reinforced with steel fiber, one of the most important factors in structural design. Two hybrid machine learning (ML) algorithms were created that combine neural networks (NNs) with two distinct optimization techniques (i.e., the Real-Coded Genetic Algorithm (RCGA) and the Firefly Algorithm (FFA)): the NN-RCGA and the NN-FFA. A database of 463 experimental data was gathered from reliable literature for the development of the models. After the construction, validation, and selection of the best model based on common statistical criteria, a comparison with the empirical equations available in the literature was carried out. Further, a sensitivity analysis was conducted to evaluate the importance of 16 inputs and reveal the dependency of structural parameters on the USC. The results showed that the NN-RCGA (R = 0.9771) was better than the NN-FFA and other analytical models (R = 0.5274-0.9075). The sensitivity analysis results showed that web width, effective depth, and a clear depth ratio were the most important parameters in modeling the shear capacity of steel fiber-reinforced concrete beams.","civil engineering,structural engineering,shear capacity,fiber reinforced concrete beams,machine learning,optimization techniques",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Science & Technology - Other Topics,Environmental Sciences & Ecology",,3.473,"ARTIFICIAL,NEURAL-NETWORK,CODED,GENETIC,ALGORITHM,MECHANICAL-PROPERTIES,FIBROUS,CONCRETE,STRENGTH,BEHAVIOR,OPTIMIZATION,PERFORMANCE,SURFACE,MODEL",SUSTAINABILITY,https://www.mdpi.com/2071-1050/12/7/2709/pdf,
9,"Accessibility to Food Retailers: The Case of Belo Horizonte, Brazil",12,7,,"Magalhaes de Oliveira Renata Lucia,Henrique Fontanele Garcia Camila Soares,Goes Pinto Paulo Henrique","de Oliveira RLM,Garcia CSHF,Pinto PHG",de Oliveira RLM,10.3390/su12072654,"Fed Ctr Technol Educ Minas Gerais CEFET MG, Dept Appl Social Sci, BR-30510000 Belo Horizonte, MG, Brazil.","Access to food products is essential to sustain life. In this paper, we discuss the differences concerning accessibility levels to food retailers among potential consumers in Belo Horizonte, Brazil. The goal was to characterize spatial mismatches regarding opportunities to access food and identify suitable areas for sustainable last food mile solutions, such as non-motorized home delivery and purchase trips. For this, we have spatially related: (i) the population concentration; (ii) the income of households and (iii) accessibility measures considering both the spatial structure of food retailers and the distance between households and stores, considering the food last mile. We have then used spatial statistics (Global Moran's I index, average nearest neighborhood analysis) and spatial analyses (overlay and processing) to determine the spatial pattern and the relation of the variables population, income, and accessibility to food retailers. We have considered the cumulative-opportunity measure, which is an indicator of the number of opportunities that can be reached within a time threshold. There is great spatial differentiation regarding the accessibility levels of food retailers and the results can be considered to support the development of policy and land use regulation that can stimulate non-motorized and collaborative delivery as an effective last-mile solution.","accessibility,food service facilities,grocery retailers,city logistics,last mile delivery",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Science & Technology - Other Topics,Environmental Sciences & Ecology",,3.473,"LOCAL,MORANS,I,E-GROCERY,DELIVERY,SERVICES,URBAN,LOGISTICS,E-COMMERCE,IMPACTS,FREIGHT,REGRESSION,SOILS,CITY",SUSTAINABILITY,https://www.mdpi.com/2071-1050/12/7/2654/pdf,
10,A Comparative Analysis of Deep Learning and Machine Learning on Detecting Movement Directions Using PIR Sensors,7,4,2855-2868,"Yun Jaeseok,Woo Jiyoung","Yun J,Woo J",Woo J,10.1109/JIOT.2019.2963326,Soonchunhyang University,"Machine learning has played a significant role in building intelligent systems in the history of data science. In the recent paradigm where objects in the world will be connected with each other, commonly referred to as the Internet of Things (IoT), people begin to consider the challenges and opportunities to utilize the huge data sets generated, also referred to as Big data. One of the active research topics in dealing with the IoT's big data is the practical feasibility of algorithms used in classical machine learning but also in a newly emerging branch, called deep learning. In this article, we demonstrate a quantitative analysis comparing performance between classical machine learning and deep learning algorithms with a human movement direction detecting application based on analog pyroelectric infrared (PIR) sensor signals. The sensing data acquisition and retrieval system is implemented with the open-source IoT software platforms based on the oneM2M standard. With the analog PIR data sets collected from 30 subjects, we perform experimental studies comparing classical machine learning and deep learning algorithms in terms of economic feasibility, scalability, generality, and real-time detection performance. The results show that classical machine learning shows better performance in real-time detection (i.e., with the sensing values within the first 0.5 s). In contrast, our simple deep learning model achieves about 90% accuracy for detecting moving directions even with the data sets from only three subjects and a single PIR sensor. Moreover, it could be applied to a larger number of subjects without updates.","Deep learning,Intelligent sensors,Sensor systems,Internet of Things,Deep learning,Internet of Things (IoT) platform,machine learning,oneM2M standards,pyroelectric infrared (PIR) sensor",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,10.127,"INFRARED-SENSOR,IDENTIFICATION,OCCUPANCY,FUSION,SPACE",IEEE INTERNET OF THINGS JOURNAL,,
11,Machine learning surrogates for molecular dynamics simulations of soft materials,42,,,"Kadupitiya J. C. S.,Sun Fanbo,Fox Geoffrey,Jadhao Vikram","Kadupitiya JCS,Sun FB,Fox G,Jadhao V",Jadhao V,10.1016/j.jocs.2020.101107,Indiana University System,"Molecular dynamics (MD) simulations accelerated by high-performance computing (HPC) methods are powerful tools to investigate and extract the microscopic mechanisms characterizing the properties of soft materials such as self-assembled nanoparticles, virus capsids, confined electrolytes, and polymeric fluids. In this paper, we extend the idea developed in our earlier work of integrating machine learning (ML) methods with HPC-accelerated MD simulations of soft materials in order to enhance their predictive power and advance their applications for research and educational activities. Parallelized MD simulations of self-assembling ions in nanoconfinement are employed to demonstrate our approach. We find that an artificial neural network-based regression model successfully learns nearly all the interesting features associated with the output ionic density profiles over a broad range of ionic system parameters. The ML model generates predictions that are in excellent agreement with the results from MD simulations. The inference time associated with the ML model is over a factor of 10,000 smaller than the corresponding parallel MD simulation time. Through this demonstration, we introduce a ""machine learning surrogate"" for MD simulations of soft-matter systems. We develop and deploy a web application on nanoHUB to realize the advantages associated with the ML surrogate. The results demonstrate that the performance of MD simulations can be further enhanced by using ML, enabling rapid and accurate simulation-driven exploration of the soft material design space. (C) 2020 Elsevier B.V. All rights reserved.","Machine learning,Molecular dynamics simulations,Parallel computing,Scientific computing,Soft materials",Article; Proceedings Paper,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,3.483,,JOURNAL OF COMPUTATIONAL SCIENCE,https://www.sciencedirect.com/science/article/am/pii/S1877750319310609,
12,Machine learning approaches for ELNES/XANES,69,2,92-109,"Mizoguchi Teruyasu,Kiyohara Shin","Mizoguchi T,Kiyohara S",Mizoguchi T,10.1093/jmicro/dfz109,University of Tokyo,"Materials characterization is indispensable for materials development. In particular, spectroscopy provides atomic configuration, chemical bonding and vibrational information, which are crucial for understanding the mechanism underlying the functions of a material. Despite its importance, the interpretation of spectra using human-driven methods, such as manual comparison of experimental spectra with reference/simulated spectra, is becoming difficult owing to the rapid increase in experimental spectral data. To overcome the limitations of such methods, we develop new data-driven approaches based on machine learning. Specifically, we use hierarchical clustering, a decision tree and a feedforward neural network to investigate the electron energy loss near edge structures (ELNES) spectrum, which is identical to the X-ray absorption near edge structure (XANES) spectrum. Hierarchical clustering and the decision tree are used to interpret and predict ELNES/XANES, while the feedforward neural network is used to obtain hidden information about the material structure and properties from the spectra. Further, we construct a prediction model that is robust against noise by data augmentation. Finally, we apply our method to noisy spectra and predict six properties accurately. In summary, the proposed approaches can pave the way for fast and accurate spectrum interpretation/prediction as well as local measurement of material functions.","machine learning,ELNES,XANES,first principles simulation",Review,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND",Microscopy,,1.618,"NEAR-EDGE,STRUCTURES,ABSORPTION,FINE-STRUCTURE,VIBRATIONAL,SPECTROSCOPY,IONIC,LIQUID,ELECTRON,ELNES,1ST-PRINCIPLES,PREDICTION,IDENTIFICATION,DOPANTS",MICROSCOPY,,
13,Application of machine learning techniques to electron microscopic/spectroscopic image data analysis,69,2,110-122,"Muto Shunsuke,Shiga Motoki","Muto S,Shiga M",Muto S,10.1093/jmicro/dfz036,Nagoya University,"The combination of scanning transmission electron microscopy (STEM) with analytical instruments has become one of the most indispensable analytical tools in materials science. A set of microscopic image/spectral intensities collected from many sampling points in a region of interest, in which multiple physical/chemical components may be spatially and spectrally entangled, could be expected to be a rich source of information about a material. To unfold such an entangled image comprising information and spectral features into its individual pure components would necessitate the use of statistical treatment based on informatics and statistics. These computer-aided schemes or techniques are referred to as multivariate curve resolution, blind source separation or hyperspectral image analysis, depending on their application fields, and are classified as a subset of machine learning. In this review, we introduce non-negative matrix factorization, one of these unfolding techniques, to solve a wide variety of problems associated with the analysis of materials, particularly those related to STEM, electron energy-loss spectroscopy and energy-dispersive X-ray spectroscopy. This review, which commences with the description of the basic concept, the advantages and drawbacks of the technique, presents several additional strategies to overcome existing problems and their extensions to more general tensor decomposition schemes for further flexible applications are described.","tensor decomposition,non-negative matrix factorization,scanning transmission electron microscopy,electron energy-loss spectroscopy,hyperspectral image analysis",Review,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND",Microscopy,,1.618,"VERTEX,COMPONENT,ANALYSIS,TENSOR,DECOMPOSITIONS,NONNEGATIVE,MATRIX,ACTIVE,MATERIAL,EELS,DEGRADATION,INFORMATION,EXTRACTION,REGRESSION,LITHIUM",MICROSCOPY,https://doi.org/10.1093/jmicro/dfz036,
14,Breast cancer diagnosis using a multi-verse optimizer-based gradient boosting decision tree,2,4,,"Tabrizchi Hamed,Tabrizchi Mohammad,Tabrizchi Hamid","Tabrizchi H,Tabrizchi M,Tabrizchi H",Tabrizchi H,10.1007/s42452-020-2575-9,Shahid Bahonar University of Kerman (SBUK),"Breast cancer is among the most common cancers women got, which can be effectively cured providing that it is diagnosed at the early stages. In the current study, we attempted to classify breast cancer into two groups of malignant and benign by proposing a new ensemble learning method using Multi-Verse Optimizer (MVO) and Gradient Boosting Decision Tree (GBDT). Moreover, the prediction rate of GBDT has been shown to be desirable, its efficiency and classification accuracy are significantly dependent on feature selection and parameter setting. Based on the MVO, we attempted to propose an efficient approach to optimize feature selection and GBDT's parameters at the same time. In other words, the MVO algorithm is able to play the role of a tuner to set the GBDT's main parameters and optimize feature selection results. To implement and test the proposed approach, standard criteria (i.e. accuracy, sensitivity, specificity, etc.) was used for performance evaluation. Also, the datasets of Wisconsin Diagnostic Breast Cancer and Wisconsin Breast Cancer were considered for this purpose. Comparing the results of GBDT-MVO model with other proposed models demonstrated that this model is more precise and has considerably lower variance in the case of a breast cancer diagnosis.","Cancer diagnoses,Classification,Gradient boosting decision tree,Multiverse optimizer",Article,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Science & Technology - Other Topics,,,"SUPPORT,VECTOR,MACHINE,PARTICLE,SWARM,OPTIMIZATION,FEATURE-SELECTION,BANKRUPTCY,PREDICTION,CLASSIFICATION,ALGORITHMS",SN APPLIED SCIENCES,,
15,Serial sectioning in the SEM for three dimensional materials science,24,2,,"Echlin McLean P.,Burnett Timothy L.,Polonsky Andrew T.,Pollock Tresa M.,Withers Philip J.","Echlin MP,Burnett TL,Polonsky AT,Pollock TM,Withers PJ",Withers PJ,10.1016/j.cossms.2020.100817,University of Manchester,"Here we explore the range of serial sectioning techniques that have evolved over the past decade, providing a comprehensive toolkit for capturing rich 3D microstructures, chemistries and crystallographic information, with sub-micron resolution at volumes that extend out to mm(3) or even cm(3). In each case we consider the challenges associated with their application, the volumes they can analyze, the damage to the surface they impart, and their suitability for different materials. In certain cases these warrant hybrid methods, motivating workflows that leverage multiple sectioning modes within the same instrument. Finally, we provide a perspective on their future development, including advances in data collection, segmentation, registration, data fusion, and correlative microscopy. Furthermore, the exploitation of 3D techniques for a better understanding of existing materials, and the design of new ones, is discussed through their use in multiscale modelling, digital twinning, material informatics and machine learning frameworks.","Serial sectioning,Materials science,Life sciences,Biology,Scanning electron microscopy",Review,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Materials Science,Physics",,10.362,"SCANNING-ELECTRON-MICROSCOPY,HEAT-AFFECTED,ZONE,FEMTOSECOND,LASER,ORIENTATION,FATIGUE,DAMAGE,BISQUE,RECONSTRUCTION,TOMOGRAPHY,ABLATION",CURRENT OPINION IN SOLID STATE & MATERIALS SCIENCE,https://doi.org/10.1016/j.cossms.2020.100817,
16,Modeling the Maximum Magnetic Entropy Change of Doped Manganite Using a Grid Search-Based Extreme Learning Machine and Hybrid Gravitational Search-Based Support Vector Regression,10,4,,"Ibn Shamsah Sami M.,Owolabi Taoreed O.","Ibn Shamsah SM,Owolabi TO",Owolabi TO,10.3390/cryst10040310,"Adekunle Ajasin Univ, Phys & Elect Dept, Akungba Akoko 342111, Ondo State, Nigeria.","The thermal response of a magnetic solid to an applied magnetic field constitutes magnetocaloric effect. The maximum magnetic entropy change (MMEC) is one of the quantitative parameters characterizing this effect, while the magnetic solids exhibiting magnetocaloric effect have great potential in magnetic refrigeration technology as they offer a green solution to the known pollutant-based refrigerants. In order to determine the MMEC of doped manganite and the influence of dopants on the magnetocaloric effect of doped manganite compounds, this work developed a grid search (GS)-based extreme learning machine (ELM) and hybrid gravitational search algorithm (GSA)-based support vector regression (SVR) for estimating the MMEC of doped manganite compounds using ionic radii and crystal lattice parameters as descriptors. Based on the root-mean-square error (RMSE), the developed GSA-SVR-radii model performs better than the existing genetic algorithm (GA)-SVR-ionic model in the literature by 27.09%, while the developed GSA-SVR-crystal model performs better than the existing GA-SVR-lattice model in the literature by 38.34%. Similarly, the developed ELM-GS-crystal model performs better than the existing GA-SVR-ionic model with a performance enhancement of 14.39% and 20.65% using the mean absolute error (MAE) and RMSE, respectively, as performance measuring parameters. The developed models also perform better than the existing models using correlation coefficient as the performance measuring parameter when validated with experimentally measured MMEC. The superior performance of the present models coupled with easy accessibility of the descriptors definitely will facilitate the synthesis of doped manganite compounds with a high magnetocaloric effect without experimental stress.","magnetocaloric effect,support vector regression,extreme learning machine,maximum magnetic entropy change,gravitational search algorithm",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Crystallography,Materials Science",,2.615,"MAGNETOCALORIC,PROPERTIES,THERMOELECTRIC,PROPERTIES,SURFACE,ENERGIES,ROOM-TEMPERATURE,COOLING,POWER,MN-SITE,SUBSTITUTION,SR,FE,NI",CRYSTALS,https://www.mdpi.com/2073-4352/10/4/310/pdf,
17,Artificial Intelligence Algorithm Enabled Industrial-Scale Graphene Characterization,10,4,,"Leong Wei Sun,Arrabito Giuseppe,Prestopino Giuseppe","Leong WS,Arrabito G,Prestopino G",Leong WS,10.3390/cryst10040308,National University of Singapore,"No characterization method is available to quickly perform quality inspection of 2D materials produced on an industrial scale. This hinders the adoption of 2D materials for product manufacturing in many industries. Here, we report an artificial-intelligence-assisted Raman analysis to quickly probe the quality of centimeter-large graphene samples in a non-destructive manner. Chemical vapor deposition of graphene is devised in this work such that two types of samples were obtained: layer-plus-islands and layer-by-layer graphene films, at centimeter scales. Using these samples, we implemented and integrated an unsupervised learning algorithm with an automated Raman spectroscopy to precisely cluster 20,250 and 18,000 Raman spectra collected from layer-plus-islands and layer-by-layer graphene films, respectively, into five and two clusters. Each cluster represents graphene patches with different layer numbers and stacking orders. For instance, the two clusters detected in layer-by-layer graphene films represent monolayer and bilayer graphene based on their Raman fingerprints. Our intelligent Raman analysis is fully automated, with no human operation involved, is highly reliable (99.95% accuracy), and can be generalized to other 2D materials, paving the way towards industrialization of 2D materials for various applications in the future.","two-dimensional materials,graphene,Raman spectroscopy,unsupervised learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Crystallography,Materials Science",,2.615,"2-DIMENSIONAL,MATERIALS,RAMAN-SPECTROSCOPY,CONTACT-RESISTANCE,CHALLENGES,GRAPHITE,DEVICES,GROWTH,OXYGEN",CRYSTALS,https://www.mdpi.com/2073-4352/10/4/308/pdf,
18,Pyrolysis of Low Density Polyethylene: Kinetic Study Using TGA Data and ANN Prediction,12,4,,"Dubdub Ibrahim,Al-Yaari Mohammed","Dubdub I,Al-Yaari M",Al-Yaari M,10.3390/polym12040891,King Faisal University,"Pyrolysis of waste low-density polyethylene (LDPE) is considered to be a highly efficient, promising treatment method. This work aims to investigate the kinetics of LDPE pyrolysis using three model-free methods (Friedman, Flynn-Wall-Qzawa (FWO), and Kissinger-Akahira-Sunose (KAS)), two model-fitting methods (Arrhenius and Coats-Redfern), as well as to develop, for the first time, a highly efficient artificial neural network (ANN) model to predict the kinetic parameters of LDPE pyrolysis. Thermogravimetric (TG) and derivative thermogravimetric (DTG) thermograms at 5, 10, 20 and 40 K min(-1) showed only a single pyrolysis zone, implying a single reaction. The values of the kinetic parameters (E and A) of LDPE pyrolysis have been calculated at different conversions by three model-free methods and the average values of the obtained activation energies are in good agreement and ranging between 193 and 195 kJ mol(-1). In addition, these kinetic parameters at different heating rates have been calculated using Arrhenius and Coats-Redfern methods. Moreover, a feed-forward ANN with backpropagation model, with 10 neurons in two hidden layers and logsig-logsig transfer functions, has been employed to predict the thermogravimetric analysis (TGA) kinetic data. Results showed good agreement between the ANN-predicted and experimental data (R > 0.9999). Then, the selected network topology was tested for extra new input data with a highly efficient performance.","pyrolysis,low density polyethylene (LDPE),kinetics,activation energy,thermogravimetric analysis (TGA),artificial neural networks (ANN)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Polymer Science,,4.493,"ARTIFICIAL,NEURAL-NETWORK,THERMAL-DEGRADATION,KINETICS,SEWAGE-SLUDGE,BEHAVIORS,WASTE,POLYPROPYLENE,POLYSTYRENE,COMBUSTION,PARAMETERS,CRACKING",POLYMERS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7240361,
19,Use of Data Mining Techniques for the Prediction of Surface Roughness of Printed Parts in Polylactic Acid (PLA) by Fused Deposition Modeling (FDM): A Practical Application in Frame Glasses Manufacturing,12,4,,"Molero Esther,Jesus Fernandez Juan,Rodriguez-Alabanda Oscar,Guerrero-Vaca Guillermo,Romero Pablo E.","Molero E,Fernandez JJ,Rodriguez-Alabanda O,Guerrero-Vaca G,Romero PE",Guerrero-Vaca G,10.3390/polym12040840,Universidad de Cordoba,"In the present work, ten data mining algorithms have been used to generate models capable of predicting the surface roughness of parts printed on polylactic acid (PLA) by using fused deposition modeling (FDM). The models have been trained using experimental data measured on 27 horizontal (XY) and 27 vertical (XZ) specimens, printed using different values for the parameters studied (layer height, extrusion temperature, print speed, print acceleration and flow). The models generated by multilayer perceptron (MLP) and logistic model trees (LMT) have obtained the best results in a cross-validation. Although it does not obtain such optimal results, the J48 algorithm (C4.5) allows the generation of models in the form of a decision tree. These trees permit to determine which print parameters have an influence on the surface roughness. For XY specimens, the surface roughness measured in the direction parallel to the extrusion path (R-a,R-0,R-XY ) depends on the flow, the print temperature and the layer height; in the direction perpendicular to the extrusion path, the surface roughness (R-a,R-90,R-XY) depends only on the flow. For XZ specimens, the surface roughness measured in the direction parallel to the extrusion path (R-a,R-0,R-XZ) depends only on the print speed; in the direction perpendicular to the extrusion path (R-a,R-90,R-XZ), it depends on the layer height and the extrusion temperature. According to the study carried out, the most suitable set up provides values of R-a,R-0,R-XY, R-a,R-90,R-XY, R-a,R-0,R-XZ and R-a,R-90,R-XZ equal to 0.46, 1.18, 0.45 and 11.54, respectively. A practical application of this work is the manufacture of PLA frame glasses using FDM.","fused deposition modeling,FDM,FFF,data mining,machine learning,PLA,surface roughness,WEKA,decision trees,C4.5,neural networks,ANN,frame glasses",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Polymer Science,,4.493,"MECHANICAL-PROPERTIES,PROCESS,PARAMETERS,QUALITY",POLYMERS,http://helvia.uco.es/xmlui/bitstream/10396/19897/1/polymers-12-00840.pdf,
20,A handle on the scandal: Data driven approaches to structure prediction,8,4,,Narasimhan Shobhana,Narasimhan S,Narasimhan S,10.1063/5.0003256,Department of Science & Technology (India),"Structure-property relationships play a central role in condensed matter physics, chemistry, and materials science. However, the problem of predicting the structure of a material, given its chemical composition, remains immensely challenging. Here, we review some of the progress that has been made in this area for both crystalline materials and atomic clusters. Early work consisted of heuristic rules-of-thumb or structure maps using descriptors that were obtained largely by inspection. Increasingly, these approaches are being expanded to use descriptors that have been obtained by applying machine learning techniques to big data containing information from the experiment and/or first principles calculations. Improved techniques for global optimization in the multi-dimensional coordinate space have also led to major advances in the field.","CRYSTAL-STRUCTURE PREDICTION,GLOBAL OPTIMIZATION,CLUSTERS,CHEMISTRY,SEMICONDUCTOR,PHOSPHORENE,MAGNETISM",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Science & Technology - Other Topics,Materials Science,Physics",,4.841,"CRYSTAL-STRUCTURE,PREDICTION,GLOBAL,OPTIMIZATION,CLUSTERS,CHEMISTRY,SEMICONDUCTOR,PHOSPHORENE,MAGNETISM",APL MATERIALS,https://aip.scitation.org/doi/pdf/10.1063/5.0003256,
21,Recent advances in high speed diffuse optical imaging in biomedicine,5,4,,"Applegate M. B.,Istfan R. E.,Spink S.,Tank A.,Roblyer D.","Applegate MB,Istfan RE,Spink S,Tank A,Roblyer D",Roblyer D,10.1063/1.5139647,Boston University,"Diffuse optical imaging (DOI) is a label-free, safe, inexpensive, and quantitative imaging modality that provides metabolic and molecular contrast in tissue using visible or near-infrared light. DOI modalities can image up to several centimeters deep in tissue, providing access to a wide range of human tissues and organ sites. DOI technologies have benefitted from several decades of academic research, which has provided a variety of platforms that prioritize imaging depth, resolution, field-of-view, spectral content, and other application-specific criteria. Until recently, however, acquisition and processing speeds have represented a stubborn barrier to further clinical exploration and implementation. Over the last several years, advances in high-speed data acquisition enabled by high-speed digital electronics, newly available sources and detectors, and innovative new scanning methods have led to major improvements in DOI rates. These advances are now being coupled with new data processing algorithms that utilize deep learning and other computationally efficient methods to provide rapid or real-time feedback in the clinic. Together, these improvements have the potential to help advance DOI technologies to the point where major impacts can be made in clinical care. Here, we review recent advances in acquisition and processing speed for several important DOI modalities.","NEAR-INFRARED SPECTROSCOPY,FREQUENCY-DOMAIN,REAL-TIME,BREAST-CANCER,NEOADJUVANT CHEMOTHERAPY,TOMOGRAPHY SYSTEM,CYCLING HYPOXIA,PULSE OXIMETRY,HUMAN BRAIN,BLOOD-FLOW",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Optics,Physics",,5.27,"NEAR-INFRARED,SPECTROSCOPY,FREQUENCY-DOMAIN,REAL-TIME,BREAST-CANCER,NEOADJUVANT,CHEMOTHERAPY,TOMOGRAPHY,SYSTEM,CYCLING,HYPOXIA,PULSE,OXIMETRY,HUMAN,BRAIN,BLOOD-FLOW",APL PHOTONICS,https://aip.scitation.org/doi/pdf/10.1063/1.5139647,
22,MULTIPLE CLASSIFICATION TECHNIQUES TOWARD A ROBUST AND RELIABLE P300 BCI SYSTEM,32,2,,"Labib Fatma El-Zahraa M.,Fouad Islam A.,Mabrouk Mai S.,Sharawy Amr A.","Labib FEZM,Fouad IA,Mabrouk MS,Sharawy AA",Fouad IA,10.4015/S1016237220500106,Egyptian Knowledge Bank (EKB),"A brain-computer interface (BCI) can be used for people with severe physical disabilities such as ALS or amyotrophic lateral sclerosis. BCI can allow these individuals to communicate again by creating a new communication channel directly from the brain to an output device. BCI technology can allow paralyzed people to share their intent with others, and thereby demonstrate that direct communication from the brain to the external world is possible and that it might serve useful functions. BCI systems include machine learning algorithms (MLAs). Their performance depends on the feature extraction and classification techniques employed. In this paper, we propose a system to exploit the P300 signal in the brain, a positive detection in event-related potentials. The P300 signal can be incorporated into a spelling device. There are two benefits behind this kind of research. First of all, this work presents the research status and the advantages of communication via a BCI system, especially the P300 BCI system for disordered people, and the related literature review is presented. Secondly, the paper discusses the performance of different machine learning algorithms. Two-different datasets are presented: the first dataset 2004 and the second dataset 2019. A preprocessing step is introduced to the subjects in both datasets first to extract the important features before applying the proposed machine learning methods: linear discriminant analysis (LDA I and LDA II), support vector machine (SVM I, SVM II, SVM III, and SVM IV), linear regression (LREG), Bayesian linear discriminant analysis (BLDA), and twin support vector machine (TSVM). By comparing the performance of the different machine learning systems, in the first dataset it is found that BLDA and SVMIV classifiers yield the highest performance for both subjects ""A"" and ""B"". BLDA yields 98% and 66% for 15th and 5th sequences, respectively, whereas SVMIV yields 98% and 54.4% for 15th and 5th sequences, respectively. While in the second dataset, it is obvious that BLDA classifier yields the highest performance for both subjects ""1"" and ""2"", it achieves 90.115%. The paper summarizes the P300 BCI system for the two introduced datasets. It discusses the proposed system, compares the classification methods performances, and considers some aspects for the future work to be handled. The results show high accuracy and less computational time which makes the system more applicable for online applications.","Brain-Computer Interface (BCI),P300 Signal,Linear Discriminant Analysis (LDA),Support Vector Machine (SVM),Linear Regression (LREG),Bayesian Linear Discriminant Analysis (BLDA),Twin Support Vector Machine (TSVM)",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Engineering,,,"BRAIN-COMPUTER-INTERFACE,SINGLE,TRIAL,EEG,MENTAL,PROSTHESIS,WHEELCHAIR,ENSEMBLE,SVMS",BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS,,
23,AN EMPIRICAL STUDY OF CANCER CLASSIFICATION TECHNIQUES BASED ON THE NEURAL NETWORKS,32,2,,"Menaga D.,Revathi S.","Menaga D,Revathi S",Menaga D,10.4015/S1016237220500131,B. S. Abdur Rahman Crescent Institute of Science & Technology,"Cancer is one of the most common dreadful diseases prevailing worldwide, and patients with cancer are rescued only when the cancer is detected at a very early stage. Early detection of cancer is appropriate as in the fourth stage, but the chance of survival is limited. The symptoms of cancers are rigorous, and therefore, all the symptoms should be studied properly before the diagnosis. Thus, an automatic prediction system is necessary for classifying the tumor, i.e. malignant or benign tumor. Over the past few years, cancer classification is increased rapidly, but there is no general technique to find novel cancer classes (class discovery) or to assign tumors to known classes. Accordingly, this survey analyzes distinct cancer classification techniques. Thus, this review article provides a detailed review of 50 research papers presenting the suggested cancer classification techniques, like Deep learning-based techniques, Neural network-based techniques, and Hybrid techniques. Moreover, an elaborative analysis and discussion are made based on the year of publication, utilized datasets, accuracy range, evaluation metrics, implementation tool, and adopted classification methods. Eventually, the research gaps and issues of various cancer classification schemes are presented for extending the researchers towards a better future scope.","Cancer classification,Deep learning-based techniques,Gene expression data,NN-based techniques,Classification accuracy",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Engineering,,,"GENE-EXPRESSION,DATA,SELECTION,ENSEMBLE",BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS,,
24,"Distributed Proprioception of 3D Configuration in Soft, Sensorized Robots via Deep Learning",5,2,3299-3306,"Truby Ryan L.,Della Santina Cosimo,Rus Daniela","Truby RL,Della Santina C,Rus D",Truby RL,10.1109/LRA.2020.2976320,Massachusetts Institute of Technology (MIT),"Creating soft robots with sophisticated, autonomous capabilities requires these systems to possess reliable, on-line proprioception of 3D configuration through integrated soft sensors. We present a framework for predicting a soft robot's 3D configuration via deep learning using feedback from a soft, proprioceptive sensor skin. Our framework introduces a kirigami-enabled strategy for rapidly sensorizing soft robots using off-the-shelf materials, a general kinematic description for soft robot geometry, and an investigation of neural network designs for predicting soft robot configuration. Even with hysteretic, non-monotonic feedback from the piezoresistive sensors, recurrent neural networks show potential for predicting our new kinematic parameters and, thus, the robot's configuration. One trained neural network closely predicts steady-state configuration during operation, though complete dynamic behavior is not fully captured. We validate our methods on a trunk-like arm with 12 discrete actuators and 12 proprioceptive sensors. As an essential advance in soft robotic perception, we anticipate our framework will open new avenues towards closed loop control in soft robotics.","Modeling,control,and learning for soft robots,soft sensors and actuators,deep learning in robotics and automation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,"CONSTANT,CURVATURE,DESIGN",IEEE ROBOTICS AND AUTOMATION LETTERS,https://dspace.mit.edu/bitstream/1721.1/135195/2/09013033.pdf,
25,mDixon-Based Synthetic CT Generation for PET Attenuation Correction on Abdomen and Pelvis Jointly Using Transfer Fuzzy Clustering and Active Learning-Based Classification,39,4,819-832,"Qian Pengjiang,Chen Yangyang,Kuo Jung-Wen,Zhang Yu-Dong,Jiang Yizhang,Zhao Kaifa,Al Helo Rose,Friel Harry,Baydoun Atallah,Zhou Feifei","Qian PJ,Chen YY,Kuo JW,Zhang YD,Jiang YZ,Zhao KF,Al Helo R,Friel H,Baydoun A,Zhou FF",Muzic RF,10.1109/TMI.2019.2935916,Case Western Reserve University,"We propose a new method for generating synthetic CT images from modified Dixon (mDixon) MR data. The synthetic CT is used for attenuation correction (AC) when reconstructing PET data on abdomen and pelvis. While MR does not intrinsically contain any information about photon attenuation, AC is needed in PET/MR systems in order to be quantitatively accurate and to meet qualification standards required for use in many multi-center trials. Existing MR-based synthetic CT generation methods either use advanced MR sequences that have long acquisition time and limited clinical availability or use matching of the MR images from a newly scanned subject to images in a library of MR-CT pairs which has difficulty in accounting for the diversity of human anatomy especially in patients that have pathologies. To address these deficiencies, we present a five-phase interlinked method that uses mDixon MR acquisition and advanced machine learning methods for synthetic CT generation. Both transfer fuzzy clustering and active learning-based classification (TFC-ALC) are used. The significance of our efforts is fourfold: 1) TFC-ALC is capable of better synthetic CT generation than methods currently in use on the challenging abdomen using only common Dixon-based scanning. 2) TFC partitions MR voxels initially into the four groups regarding fat, bone, air, and soft tissue via transfer learning; ALC can learn insightful classifiers, using as few but informative labeled examples as possible to precisely distinguish bone, air, and soft tissue. Combining them, the TFC-ALC method successfully overcomes the inherent imperfection and potential uncertainty regarding the co-registration between CT and MR images. 3) Compared with existing methods, TFC-ALC features not only preferable synthetic CT generation but also improved parameter robustness, which facilitates its clinical practicability. Applying the proposed approach on mDixon-MR data from ten subjects, the average score of the mean absolute prediction deviation (MAPD) was 89.78 +/- 8.76 which is significantly better than the 133.17 +/- 9.67 obtained using the all-water (AW) method (p=4.11E-9) and the 104.97 +/- 10.03 obtained using the four-cluster-partitioning (FCP, i.e., external-air, internal-air, fat, and soft tissue) method (p=0.002). 4) Experiments in the PET SUV errors of these approaches show that TFC-ALC achieves the highest SUV accuracy and can generally reduce the SUV errors to 5% or less. These experimental results distinctively demonstrate the effectiveness of our proposed TFCALC method for the synthetic CT generation on abdomen and pelvis using only the commonly-available Dixon pulse sequence.","Synthetic CT generation,Dixon-based MR,abdomen,attenuation correction (AC),transfer fuzzy clustering (TFC),active learning-based classification (ALC)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"ZERO-ECHO-TIME,INTEGRATED,WHOLE-BODY,MRI-ONLY,RADIOTHERAPY,PSEUDO-CT,CLINICAL-EVALUATION,IMAGE,SEGMENTATION,PET%2FMRI,PERFORMANCE,SCANNER,SEQUENCES",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7284852,
26,Deeply-Supervised Networks With Threshold Loss for Cancer Detection in Automated Breast Ultrasound,39,4,866-876,"Wang Yi,Wang Na,Xu Min,Yu Junxiong,Qin Chenchen,Luo Xiao,Yang Xin,Wang Tianfu,Li Anhua,Ni Dong","Wang Y,Wang N,Xu M,Yu JX,Qin CC,Luo X,Yang X,Wang TF,Li AH,Ni D",Ni D,10.1109/TMI.2019.2936500,Shenzhen University,"ABUS, or Automated breast ultrasound, is an innovative and promising method of screening for breast examination. Comparing to common B-mode 2D ultrasound, ABUS attains operator-independent image acquisition and also provides 3D views of the whole breast. Nonetheless, reviewing ABUS images is particularly time-intensive and errors by oversight might occur. For this study, we offer an innovative 3D convolutional network, which is used for ABUS for automated cancer detection, in order to accelerate reviewing and meanwhile to obtain high detection sensitivity with low false positives (FPs). Specifically, we offer a densely deep supervision method in order to augment the detection sensitivity greatly by effectively using multi-layer features. Furthermore, we suggest a threshold loss in order to present voxel-level adaptive threshold for discerning cancer vs. non-cancer, which can attain high sensitivity with low false positives. The efficacy of our network is verified from a collected dataset of 219 patients with 614 ABUS volumes, including 745 cancer regions, and 144 healthy women with a total of 900 volumes, without abnormal findings. Extensive experiments demonstrate our method attains a sensitivity of 95% with 0.84 FP per volume. The proposed network provides an effective cancer detection scheme for breast examination using ABUS by sustaining high sensitivity with low false positives. The code is publicly available at https://github.com/nawang0226/abus_code.","Automated breast ultrasound (ABUS),cancer detection,deep supervision,convolutional neural networks,threshold loss",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"COMPUTER-AIDED,DETECTION,NEURAL-NETWORKS,TUMOR-DETECTION,MAMMOGRAPHY,WOMEN,RISK,US",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
27,Deep Learning Diffuse Optical Tomography,39,4,877-887,"Yoo Jaejun,Sabir Sohail,Heo Duchang,Kim Kee Hyun,Wahab Abdul,Choi Yoonseok,Lee Seul- I,Chae Eun Young,Kim Hak Hee,Bae Young Min","Yoo J,Sabir S,Heo D,Kim KH,Wahab A,Choi Y,Lee SI,Chae EY,Kim HH,Bae YM",Ye JC,10.1109/TMI.2019.2936522,Korea Advanced Institute of Science & Technology (KAIST),"Diffuse optical tomography (DOT) has been investigated as an alternative imaging modality for breast cancer detection thanks to its excellent contrast to hemoglobin oxidization level. However, due to the complicated non-linear photon scattering physics and ill-posedness, the conventional reconstruction algorithms are sensitive to imaging parameters such as boundary conditions. To address this, here we propose a novel deep learning approach that learns non-linear photon scattering physics and obtains an accurate three dimensional (3D) distribution of optical anomalies. In contrast to the traditional black-box deep learning approaches, our deep network is designed to invert the Lippman-Schwinger integral equation using the recent mathematical theory of deep convolutional framelets. As an example of clinical relevance, we applied the method to our prototype DOT system. We show that our deep neural network, trained with only simulation data, can accurately recover the location of anomalies within biomimetic phantoms and live animals without the use of an exogenous contrast agent.","Deep learning,diffuse optical tomography,framelet denoising,convolutional neural network (CNN),convolution framelets",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORK,RECONSTRUCTION,SCATTERING,INVERSION,BREAST",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1712.00912,
28,Stacked Bidirectional Convolutional LSTMs for Deriving 3D Non-Contrast CT From Spatiotemporal 4D CT,39,4,985-996,"van de Leemput Sil C.,Prokop Mathias,van Ginneken Bram,Manniesing Rashindra","van de Leemput SC,Prokop M,van Ginneken B,Manniesing R",van de Leemput SC,10.1109/TMI.2019.2939044,Radboud University Nijmegen,"The imaging workup in acute stroke can be simplified by deriving non-contrast CT (NCCT) from CT perfusion (CTP) images. This results in reduced workup time and radiation dose. To achieve this, we present a stacked bidirectional convolutional LSTM (C-LSTM) network to predict 3D volumes from 4D spatiotemporal data. Several parameterizations of the C-LSTM network were trained on a set of 17 CTP-NCCT pairs to learn to derive a NCCT from CTP and were subsequently quantitatively evaluated on a separate cohort of 16 cases. The results show that the C-LSTM network clearly outperforms the baseline and competitive convolutional neural network methods. We show good scalability and performance of the method by continued training and testing on an independent dataset which includes pathology of 80 and 83 CTP-NCCT pairs, respectively. C-LSTM is, therefore, a promising general deep learning approach to learn from high-dimensional spatiotemporal medical images.","Deep learning,neural networks,long short-term memory,LSTM,convolutional neural network,CNN,convolutional LSTM,C-LSTM",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"HEALTH-CARE,PROFESSIONALS,ACUTE,ISCHEMIC-STROKE,NEURAL-NETWORK,ENDOVASCULAR,TREATMENT,EARLY,MANAGEMENT,IMAGE,THROMBECTOMY,RECONSTRUCTION,GUIDELINES,UPDATE",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
29,Automated Muscle Segmentation from Clinical CT Using Bayesian U-Net for Personalized Musculoskeletal Modeling,39,4,1030-1040,"Hiasa Yuta,Otake Yoshito,Takao Masaki,Ogawa Takeshi,Sugano Nobuhiko,Sato Yoshinobu","Hiasa Y,Otake Y,Takao M,Ogawa T,Sugano N,Sato Y",Hiasa Y,10.1109/TMI.2019.2940555,Nara Institute of Science & Technology,"We propose a method for automatic segmentation of individual muscles from a clinical CT. The method uses Bayesian convolutional neural networks with the U-Net architecture, using Monte Carlo dropout that infers an uncertainty metric in addition to the segmentation label. We evaluated the performance of the proposed method using two data sets: 20 fully annotated CTs of the hip and thigh regions and 18 partially annotated CTs that are publicly available from The Cancer Imaging Archive (TCIA) database. The experiments showed a Dice coefficient (DC) of 0.891 +/- 0.016 (mean +/- std) and an average symmetric surface distance (ASD) of 0.994 +/- 0.230 mm over 19 muscles in the set of 20 CTs. These results were statistically significant improvements compared to the state-of-the-art hierarchical multi-atlas method which resulted in 0.845 +/- 0.031 DC and 1.556 +/- 0.444 mm ASD. We evaluated validity of the uncertainty metric in the multi-class organ segmentation problem and demonstrated a correlation between the pixels with high uncertainty and the segmentation failure. One application of the uncertainty metric in active-learning is demonstrated, and the proposed query pixel selection method considerably reduced the manual annotation cost for expanding the training data set. The proposed method allows an accurate patient-specific analysis of individual muscle shapes in a clinical routine. This would open up various applications including personalization of biomechanical simulation and quantitative evaluation of muscle atrophy.","Bayesian deep learning,convolutional neural networks,active learning,image segmentation,musculoskeletal model",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"MULTI-ATLAS,SEGMENTATION,BODY,TISSUE,GAIT",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1907.08915,
30,Deep Unfolded Robust PCA With Application to Clutter Suppression in Ultrasound,39,4,1051-1063,"Solomon Oren,Cohen Regev,Zhang Yi,Yang Yi,He Qiong,Luo Jianwen,van Sloun Ruud J. G.,Eldar Yonina C.","Solomon O,Cohen R,Zhang Y,Yang Y,He Q,Luo JW,van Sloun RJG,Eldar YC",Cohen R,10.1109/TMI.2019.2941271,Technion Israel Institute of Technology,"Contrast enhanced ultrasound is a radiation-free imaging modality which uses encapsulated gas microbubbles for improved visualization of the vascular bed deep within the tissue. It has recently been used to enable imaging with unprecedented subwavelength spatial resolution by relying on super-resolution techniques. A typical preprocessing step in super-resolution ultrasound is to separate the microbubble signal from the cluttering tissue signal. This step has a crucial impact on the final image quality. Here, we propose a new approach to clutter removal based on robust principle component analysis (PCA) and deep learning. We begin by modeling the acquired contrast enhanced ultrasound signal as a combination of low rank and sparse components. This model is used in robust PCA and was previously suggested in the context of ultrasound Doppler processing and dynamic magnetic resonance imaging. We then illustrate that an iterative algorithm based on this model exhibits improved separation of microbubble signal from the tissue signal over commonly practiced methods. Next, we apply the concept of deep unfolding to suggest a deep network architecture tailored to our clutter filtering problem which exhibits improved convergence speed and accuracy with respect to its iterative counterpart. We compare the performance of the suggested deep network on both simulations and in-vivo rat brain scans, with a commonly practiced deep-network architecture and with the fast iterative shrinkage algorithm. We show that our architecture exhibits better image quality and contrast.","Deep unfolding,inverse problems,machine learning,neural network,robust PCA,ultrasound imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"FILTER,DESIGN,THRESHOLDING,ALGORITHM,DOPPLER,DECOMPOSITION,SPARSE,SEPARATION",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.biorxiv.org/content/biorxiv/early/2018/11/21/469437.full.pdf,
31,Spatio-Temporal Convolutional LSTMs for Tumor Growth Prediction by Learning 4D Longitudinal Patient Data,39,4,1114-1126,"Zhang Ling,Lu Le,Wang Xiaosong,Zhu Robert M.,Bagheri Mohammadhadi,Summers Ronald M.,Yao Jianhua","Zhang L,Lu L,Wang XS,Zhu RM,Bagheri M,Summers RM,Yao JH",Zhang L; Yao JH,10.1109/TMI.2019.2943841,National Institutes of Health (NIH) - USA,"Prognostic tumor growth modeling via volumetric medical imaging observations can potentially lead to better outcomes of tumor treatment management and surgical planning. Recent advances of convolutional networks (ConvNets) have demonstrated higher accuracy than traditional mathematical models can be achieved in predicting future tumor volumes. This indicates that deep learning based data-driven techniques may have great potentials on addressing such problem. However, current 2D image patch based modeling approaches can not make full use of the spatio-temporal imaging context of the tumor's longitudinal 4D (3D + time) patient data. Moreover, they are incapable to predict clinically-relevant tumor properties, other than the tumor volumes. In this paper, we exploit to formulate the tumor growth process through convolutional Long Short-Term Memory (ConvLSTM) that extract tumor's static imaging appearances and simultaneously capture its temporal dynamic changes within a single network. We extend ConvLSTM into the spatio-temporal domain (ST-ConvLSTM) by jointly learning the inter-slice 3D contexts and the longitudinal or temporal dynamics from multiple patient studies. Our approach can incorporate other non-imaging patient information in an end-to-end trainable manner. Experiments are conducted on the largest 4D longitudinal tumor dataset of 33 patients to date. Results validate that the proposed ST-ConvLSTM model produces a Dice score of 83.2%+/- 5.1% and a RVD of 11.2%+/- 10.8%, both statistically significantly outperforming (p < 0.05) other compared methods of traditional linear model, ConvLSTM, and generative adversarial network (GAN) under the metric of predicting future tumor volumes. Additionally, our new method enables the prediction of both cell density and CT intensity numbers. Last, we demonstrate the generalizability of ST-ConvLSTM by employing it in 4D medical image segmentation task, which achieves an averaged Dice score of 86.3%+/- 1.2% for left-ventricle segmentation in 4D ultrasound with 3 seconds per patient case.","Tumor growth prediction,deep learning,convolutional LSTM,spatio-temporal longitudinal study,4D medical imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"MODEL,DIFFUSION,SEGMENTATION",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1902.08716,
32,Noise Adaptation Generative Adversarial Network for Medical Image Analysis,39,4,1149-1159,"Zhang Tianyang,Cheng Jun,Fu Huazhu,Gu Zaiwang,Xiao Yuting,Zhou Kang,Gao Shenghua,Zheng Rui,Liu Jiang","Zhang TY,Cheng J,Fu HZ,Gu ZW,Xiao YT,Zhou K,Gao SH,Zheng R,Liu J",Cheng J,10.1109/TMI.2019.2944488,Chinese Academy of Sciences,"Machine learning has been widely used in medical image analysis under an assumption that the training and test data are under the same feature distributions. However, medical images from difference devices or the same device with different parameter settings are often contaminated with different amount and types of noises, which violate the above assumption. Therefore, the models trained using data from one device or setting often fail to work for that from another. Moreover, it is very expensive and tedious to label data and re-train models for all different devices or settings. To overcome this noise adaptation issue, it is necessary to leverage on the models trained with data from one device or setting for new data. In this paper, we reformulate this noise adaptation task as an image-to-image translation task such that the noise patterns from the test data are modified to be similar to those from the training data while the contents of the data are unchanged. In this paper, we propose a novel Noise Adaptation Generative Adversarial Network (NAGAN), which contains a generator and two discriminators. The generator aims to map the data from source domain to target domain. Among the two discriminators, one discriminator enforces the generated images to have the same noise patterns as those from the target domain, and the second discriminator enforces the content to be preserved in the generated images. We apply the proposed NAGAN on both optical coherence tomography (OCT) images and ultrasound images. Results show that the method is able to translate the noise style. In addition, we also evaluate our proposed method with segmentation task in OCT and classification task in ultrasound. The experimental results show that the proposed NAGAN improves the analysis outcome.","Generative adversarial network,style transfer,noise adaptation,medical image analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,,
33,Deep Neural Networks Improve Radiologists Performance in Breast Cancer Screening,39,4,1184-1194,"Wu Nan,Phang Jason,Park Jungkyu,Shen Yiqiu,Huang Zhe,Zorin Masha,Jastrzebski Stanislaw,Fevry Thibault,Katsnelson Joe,Kim Eric","Wu N,Phang J,Park J,Shen YQ,Huang Z,Zorin M,Jastrzebski S,Fevry T,Katsnelson J,Kim E",Geras KJ,10.1109/TMI.2019.2945514,New York University,"We present a deep convolutional neural network for breast cancer screening exam classification, trained, and evaluated on over 200000 exams (over 1000000 images). Our network achieves an AUC of 0.895 in predicting the presence of cancer in the breast, when tested on the screening population. We attribute the high accuracy to a few technical advances. 1) Our network 2019;s novel two-stage architecture and training procedure, which allows us to use a high-capacity patch-level network to learn from pixel-level labels alongside a network learning from macroscopic breast-level labels. 2) A custom ResNet-based network used as a building block of our model, whose balance of depth and width is optimized for high-resolution medical images. 3) Pretraining the network on screening BI-RADS classification, a related task with more noisy labels. 4) Combining multiple input views in an optimal way among a number of possible choices. To validate our model, we conducted a reader study with 14 readers, each reading 720 screening mammogram exams, and show that our model is as accurate as experienced radiologists when presented with the same data. We also show that a hybrid model, averaging the probability of malignancy predicted by a radiologist with a prediction of our neural network, is more accurate than either of the two separately. To further understand our results, we conduct a thorough analysis of our network 2019;s performance on different subpopulations of the screening population, the model 2019;s design, training procedure, errors, and properties of its internal representations. Our best models are publicly available at https://github.com/nyukat/breast_cancer_classifier.","Deep learning,deep convolutional neural networks,breast cancer screening,mammography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"DIAGNOSTIC-ACCURACY,MAMMOGRAPHY",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7427471,
34,Fetal Congenital Heart Disease Echocardiogram Screening Based on DGACNN: Adversarial One-Class Classification Combined with Video Transfer Learning,39,4,1206-1222,"Gong Yuxin,Zhang Yingying,Zhu Haogang,Lv Jing,Cheng Qian,Zhang Hongjia,He Yihua,Wang Shuliang","Gong YX,Zhang YY,Zhu HG,Lv J,Cheng Q,Zhang HJ,He YH,Wang SL",Zhu HG,10.1109/TMI.2019.2946059,Beihang University,"Fetal congenital heart disease (FHD) is a common and serious congenital malformation in children. In Asia, FHD birth defect rates have reached as high as 9.3 0025. For the early detection of birth defects and mortality, echocardiography remains the most effective method for screening fetal heart malformations. However, standard echocardiograms of the fetal heart, especially four-chamber view images, are difficult to obtain. In addition, the pathophysiological changes in fetal hearts during different pregnancy periods lead to ever-changing two-dimensional fetal heart structures and hemodynamics, and it requires extensive professional knowledge to recognize and judge disease development. Thus, research on the automatic screening for FHD is necessary. In this paper, we proposed a new model named DGACNN that shows the best performance in recognizing FHD, achieving a rate of 85. The motivation for this network is to deal with the problem that there are insufficient training datasets to train a robust model. There are many unlabeled video slices, but they are tough and time-consuming to annotate. Thus, how to use these un-annotated video slices to improve the DGACNN capability for recognizing FHD, in terms of both recognition accuracy and robustness, is very meaningful for FHD screening. The architecture of DGACNN comprises two parts, that is, DANomaly and GACNN (Wgan-GP and CNN). DANomaly, similar to the ALOCC network, but incorporates cycle adversarial learning to train an end-to-end one-class classification (OCC) network that is more robust and has a higher accuracy than ALOCC in screening video slices. For the GACNN architecture, we use FCH (four chamber heart) video slices at around the end-systole, as screened by DANomaly, to train a WGAN-GP for the purpose of obtaining ideal low-level features that can robustly improve the FHD recognition accuracy. A few annotated video slices, as screened by DANomaly, can also be used for data augmentation so as to improve the FHD recognition further. The experiments show that the DGACNN outperforms other state-of-the-art networks by 10025; in recognizing FHD. A comparison experiment shows that the proposed network already outperforms the performance of expert cardiologists in recognizing FHD, reaching 84 025; in a test. Thus, the proposed architecture has high potential for helping cardiologists complete early FHD screenings.","Fetal congenital heart disease,one-class classification,generative adversarial network,transfer learning,echocardiography,four-chamber heart",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORKS,UNITED-STATES",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
35,DECT-MULTRA: Dual-Energy CT Image Decomposition With Learned Mixed Material Models and Efficient Clustering,39,4,1223-1234,"Li Zhipeng,Ravishankar Saiprasad,Long Yong,Fessler Jeffrey A.","Li ZP,Ravishankar S,Long Y,Fessler JA",Long Y,10.1109/TMI.2019.2946177,Shanghai Jiao Tong University,"Dual-energy computed tomography (DECT) imaging plays an important role in advanced imaging applications due to its material decomposition capability. Image-domain decomposition operates directly on CT images using linear matrix inversion, but the decomposed material images can be severely degraded by noise and artifacts. This paper proposes a new method dubbed DECT-MULTRA for image-domain DECT material decomposition that combines conventional penalized weighted-least squares (PWLS) estimation with regularization based on a mixed union of learned transforms (MULTRA) model. Our proposed approach pre-learns a union of common-material sparsifying transforms from patches extracted from all the basis materials, and a union of cross-material sparsifying transforms from multi-material patches. The common-material transforms capture the common properties among different material images, while the cross-material transforms capture the cross-dependencies. The proposed PWLS formulation is optimized efficiently by alternating between an image update step and a sparse coding and clustering step, with both of these steps having closed-form solutions. The effectiveness of our method is validated with both XCAT phantom and clinical head data. The results demonstrate that our proposed method provides superior material image quality and decomposition accuracy compared to other competing methods.","Image-domain decomposition,sparsifying transform learning,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"MULTIMATERIAL,DECOMPOSITION,OVERCOMPLETE,DICTIONARIES,MULTIENERGY,CT,RECONSTRUCTION",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.osti.gov/biblio/1768537,
36,Epileptic Seizure Detection in EEG Signals Using a Unified Temporal-Spectral Squeeze-and-Excitation Network,28,4,782-794,"Li Yang,Liu Yu,Cui Wei-Gang,Guo Yu-Zhu,Huang Hui,Hu Zhong-Yi","Li Y,Liu Y,Cui WG,Guo YZ,Huang H,Hu ZY",Liu Y,10.1109/TNSRE.2020.2973434,Beihang University,"The intelligent recognition of epileptic electro-encephalogram (EEG) signals is a valuable tool for the epileptic seizure detection. Recent deep learning models fail to fully consider both spectral and temporal domain representations simultaneously, which may lead to omitting the nonstationary or nonlinear property in epileptic EEGs and further produce a suboptimal recognition performance consequently. In this paper, an end-to-end EEG seizure detection framework is proposed by using a novel channel-embedding spectral-temporal squeeze-and-excitation network (CE-stSENet) with a maximum mean discrepancy-based information maximizing loss. Specifically, the CE-stSENet firstly integrates both multi-level spectral and multi-scale temporal analysis simultaneously. Hierarchical multi-domain representations are then captured in a unified manner with a variant of squeeze-and-excitation block. The classification net is finally implemented for epileptic EEG recognition based on features extracted in previous subnetworks. Particularly, to address the fact that the scarcity of seizure events results in finite data distribution and the severe overfitting problem in seizure detection, the CE-stSENet is coordinated with a maximum mean discrepancy-based information maximizing loss for mitigating the overfitting problem. Competitive experimental results on three EEG datasets against the state-of-the-art methods demonstrate the effectiveness of the proposed framework in recognizing epileptic EEGs, indicating its powerful capability in the automatic seizure detection.","EEG,deep learning,multi-domain feature extraction,squeeze & excitation,maximum mean discrepancy,seizure detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"CLASSIFICATION,SELECTION,FEATURES",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
37,Transparent Electrophysiological Muscle Classification From EMG Signals Using Fuzzy-Based Multiple Instance Learning,28,4,842-849,"Kamali Tahereh,Stashuk Daniel W.","Kamali T,Stashuk DW",Kamali T,10.1109/TNSRE.2020.2979412,University of Waterloo,"Although a well-established body of literature has examined electrophysiological muscle classification methods and systems, ways to enhance their transparency is still an important challenge and requires further study. In this work, a transparent semi-supervised electrophysiological muscle classification system which uses needle-detected EMG signals to classify muscles as normal, myopathic, or neurogenic is proposed. The electrophysiological muscle classification (EMC) problem is naturally formulated using multiple instance learning (MIL) and needs an adaptation of standard supervised classifiers for the purpose of training and evaluating bags of instances. Here, a novel MIL-based EMC system in which the muscle classifier uses predictions based on motor unit potentials (MUPs) to infer muscle labels is described. This system uses morphological, stability, near fiber and spectral MUP features. Quantitative results obtained from applying the proposed transparent system to four electrophysiologically different groups of muscles, composed of proximal and distal hand and leg muscles, resulted in an average classification accuracy of 95.85%. The findings show the superior and stable performance of the proposed EMC system compared to previous works using other supervised, semi-supervised and unsupervised methods.","Muscles,Electromagnetic compatibility,Neurons,Electromyography,Diseases,Shape,Electric potential,Electrophysiological muscle classification,multiple instance learning,needle electrodiagnostic examination,TSK fuzzy system",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"MUAP,CLASSIFICATION,DIAGNOSIS",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
38,Emotion-Inducing Imagery Versus Motor Imagery for a Brain-Computer Interface,28,4,850-859,"Bigirimana A. D.,Siddique N.,Coyle D.","Bigirimana AD,Siddique N,Coyle D",Bigirimana AD,10.1109/TNSRE.2020.2978951,Ulster University,"Neural correlates of intentionally induced human emotions may offer alternative imagery strategies to control brain-computer interface (BCI) applications. In this paper, a novel BCI control strategy i.e., imagining fictional or recalling mnemonic sad and happy events, emotion-inducing imagery (EII), is compared to motor imagery (MI) in a study involving multiple sessions using a two-class electroencephalogram (EEG)-based BCI paradigm with 12 participants. The BCI setup enabled online continuous visual feedback presentation in a game involving one-dimensional control of a game character. MI and EII are compared across different signal-processing frameworks which are based on neural-time-series-prediction-preprocessing (NTSPP), filter bank common spatial patterns (FBCSP) and hemispheric asymmetry (ASYM). Online single-trial classification accuracies (CA) results indicate that MI performance across all participants is 77.54% compared to EII performance of 68.78% ( ${p} < 0.05$ ). The results show that an ensemble of the NTSPP, FBCSP and ASYM frameworks maximizes performance for EII with average CA of 71.64% across all participants. Furthermore, the participants' subjective responses indicate that they preferred MI over emotion-inducing imagery (EII) in controlling the game character, and MI was perceived to offer most control over the game character. The results suggest that EII is not a viable alternative to MI for the majority of participants in this study but may be an alternative imagery for a subset of BCI users based on acceptable EII performance (CA >70%) observed for some participants.","BCI,EEG,emotion-inducing imagery,motor imagery,games,neurogaming,assistive technology,machine learning,AI",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"REAL-TIME,CLASSIFICATION,SERIES,PREDICTION,ASYMMETRY,SIGNALS,COMMON",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,https://pure.ulster.ac.uk/ws/files/78466873/FINAL_VERSION.pdf,
39,Quantitative Assessment of Upper-Limb Motor Function for Post-Stroke Rehabilitation Based on Motor Synergy Analysis and Multi-Modality Fusion,28,4,943-952,"Wang Chen,Peng Liang,Hou Zeng-Guang,Li Jingyue,Zhang Tong,Zhao Jun","Wang C,Peng L,Hou ZG,Li JY,Zhang T,Zhao J",Hou ZG,10.1109/TNSRE.2020.2978273,Chinese Academy of Sciences,"Functional assessment is an essential part of rehabilitation protocols after stroke. Conventionally, the assessment process relies heavily on clinical experience and lacks quantitative analysis. In order to objectively quantify the upper-limb motor impairments in patients with post-stroke hemiparesis, this study proposes a novel assessment approach based on motor synergy quantification and multi-modality fusion. Fifteen post-stroke hemiparetic patients and fifteen age-matched healthy persons participated in this study. During different goal-directed tasks, kinematic data and surface electromyography(sEMG) signals were synchronously collected from these participants, and then motor features extracted from each modal data could be fed into the respective local classifiers. In addition, kinematic synergies and muscle synergies were quantified by principal component analysis (PCA) and ${k}$ weighted angular similarity ( ${k}$ WAS) algorithm to provide in-depth analysis of the coactivated features responsible for observable movement impairments. By integrating the outputs of local classifiers and the quantification results of motor synergies, ensemble classifiers can be created to generate quantitative assessment for different modalities separately. In order to further exploit the complementarity between the evaluation results at kinematic and muscular levels, a multi-modal fusion scheme was developed to comprehensively analyze the upper-limb motor function and generate a probability-based function score. Under the proposed assessment framework, three types of machine learning methods were employed to search the optimal performance of each classifier. Experimental results demonstrated that the classification accuracy was respectively improved by 4.86% and 2.78% when the analysis of kinematic and muscle synergies was embedded in the assessment system, and could be further enhanced to 96.06% by fusing the characteristics derived from different modalities. Furthermore, the assessment result of multi-modality fusion framework exhibited a significant correlation with the score of standard clinical tests ( ${R = - {0.87},\;{P} = {1.98}{e} - {5}}$ ). These promising results show the feasibility of applying the proposed method to clinical assessments for post-stroke hemiparetic patients.","Post-stroke hemiparesis,upper limb functional assessment,motor synergies,multi-modality fusion,motion capture technology,electromyography (EMG)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"STROKE,COORDINATION,PRINCIPLES,PATTERNS,DISEASE,TIME",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
40,Automatic Seizure Detection using Fully Convolutional Nested LSTM,30,4,,"Li Yang,Yu Zuyi,Chen Yang,Yang Chunfeng,Li Yue,Li X. Allen,Li Baosheng","Li Y,Yu ZY,Chen Y,Yang CF,Li Y,Li XA,Li BS",Li BS,10.1142/S0129065720500197,Southeast University - China,"The automatic seizure detection system can effectively help doctors to monitor and diagnose epilepsy thus reducing their workload. Many outstanding studies have given good results in the two-class seizure detection problems, but most of them are based on hand-wrought feature extraction. This study proposes an end-to-end automatic seizure detection system based on deep learning, which does not require heavy preprocessing on the EEG data or feature engineering. The fully convolutional network with three convolution blocks is first used to learn the expressive seizure characteristics from EEG data. Then these robust EEG features pertinent to seizures are presented as an input to the Nested Long Short-Term Memory (NLSTM) model to explore the inherent temporal dependencies in EEG signals. Lastly, the high-level features obtained from the NLSTM model are fed into the softmax layer to output predicted labels. The proposed method yields an accuracy range of 98.44-100% in 10 different experiments based on the Bonn University database. A larger EEG database is then used to evaluate the performance of the proposed method in real-life situations. The average sensitivity of 97.47%, specificity of 96.17%, and false detection rate of 0.487 per hour are yielded. For CHB-MIT Scalp EEG database, the proposed model also achieves a segment-level sensitivity of 94.07% with a false detection rate of 0.66 per hour. The excellent results obtained on three different EEG databases demonstrate that the proposed method has good robustness and generalization power under ideal and real-life conditions.","Seizure detection,EEG,deep learning,fully convolutional network,NLSTM",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Computer Science,,5.439,"EPILEPTIC,SEIZURES,NEURAL-NETWORK,CLASSIFICATION,METHODOLOGY,PREDICTION,TRANSFORM,ENTROPY,EEGS",INTERNATIONAL JOURNAL OF NEURAL SYSTEMS,,
41,Design and Analysis for Fall Detection System Simplification,,158,,"Martinez-Villasenor Lourdes,Ponce Hiram","Martinez-Villasenor L,Ponce H",Martinez-Villasenor L,10.3791/60361,Universidad Panamericana - Ciudad de Mexico,"This paper presents a methodology based on multimodal sensors to configure a simple, comfortable and fast fall detection and human activity recognition system that can be easily implemented and adopted. The methodology is based on the configuration of specific types of sensors, machine-learning methods and procedures. The protocol is divided into four phases: (1) database creation (2) data analysis (3) system simplification and (4) evaluation. Using this methodology, we created a multimodal database for fall detection and human activity recognition, namely UP-Fall Detection. It comprises data samples from 17 subjects that perform 5 types of falls and 6 different simple activities, during 3 trials. All information was gathered using 5 wearable sensors (tri-axis accelerometer, gyroscope and light intensity), 1 electroencephalograph helmet, 6 infrared sensors as ambient sensors, and 2 cameras in lateral and front viewpoints. The proposed novel methodology adds some important stages to perform a deep analysis of the following design issues in order to simplify a fall detection system: a) select which sensors or combination of sensors are to be used in a simple fall detection system, b) determine the best placement of the sources of information, and c) select the most suitable machine learning classification method for fall and human activity detection and recognition. Even though some multimodal approaches reported in literature only focus on one or two of the above-mentioned issues, our methodology allows simultaneously solving these three design problems related to a human fall and activity detection and recognition system.","Bioengineering,Issue 158,fall detection,human activity recognition,machine learning,healthcare,ambient assisted living,sensors,multimodal approaches,classification",Article,"JOURNAL OF VISUALIZED EXPERIMENTS, 1 ALEWIFE CENTER, STE 200, CAMBRIDGE, MA 02140 USA",Science & Technology - Other Topics,,1.696,,JOVE-JOURNAL OF VISUALIZED EXPERIMENTS,https://www.jove.com/pdf/60361/design-and-analysis-for-fall-detection-system-simplification,
42,Performance Improvements during Mineral Processing Using Material Fingerprints Derived from Machine Learning-A Conceptual Framework,10,4,,"van Duijvenbode Jeroen R.,Buxton Mike W. N.,Shishvan Masoud Soleymani","van Duijvenbode JR,Buxton MWN,Shishvan MS",van Duijvenbode JR,10.3390/min10040366,Delft University of Technology,"Material attributes (e.g., chemical composition, mineralogy, texture) are identified as the causative source of variations in the behaviour of mineral processing. That makes them suitable to act as key characteristics to characterise and classify material. Therefore, vast quantities of collected data describing material attributes could help to forecast the behaviour of mineral processing. This paper proposes a conceptual framework that creates a data-driven link between ore and the processing behaviour through the creation of material ""fingerprints"". A fingerprint is a machine learning-based classification of measured material attributes compared to the range of attributes found within the mine's mineral reserves. The outcome of the classification acts as a label for a machine learning model and contains relevant information, which may identify the root cause of measured differences in processing behaviour. Therefore, this class label can forecast the associated behaviour of mineral processing. Furthermore, insight is given into the confidence of available data originating from different analytical techniques. Taken together, this enhances the understanding of how differences in geology impact metallurgical plant performance. Targeted measurements at low-confidence unit processes and for specific attributes would upgrade the confidence in fingerprints and capabilities to predict plant performance.","data confidence,machine learning,mineral processing,behavioural prediction,mining",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Geochemistry & Geophysics,Mineralogy,Mining & Mineral Processing",,,ORE,MINERALS,https://repository.tudelft.nl/islandora/object/uuid%3A948ba82d-7cb7-4b6d-96ad-733298b0917a/datastream/OBJ/download,
43,Development and validation of a CT-based radiomic nomogram for preoperative prediction of early recurrence in advanced gastric cancer,145,,13-20,"Zhang Wenjuan,Fang Mengjie,Dong Di,Wang Xiaoxiao,Ke Xiaoai,Zhang Liwen,Hu Chaoen,Guo Lingyun,Guan Xiaoying,Zhou Junlin","Zhang WJ,Fang MJ,Dong D,Wang XX,Ke XA,Zhang LW,Hu CE,Guo LY,Guan XY,Zhou JL",Zhou JL,10.1016/j.radonc.2019.11.023,Lanzhou University,"Background: In the clinical management of advanced gastric cancer (AGC), preoperative identification of early recurrence after curative resection is essential. Thus, we aimed to create a CT-based radiomic model to predict early recurrence in AGC patients preoperatively.
Materials and methods: We enrolled 669 consecutive patients (302 in the training set, 219 in the internal test set and 148 in the external test set) with clinicopathologically confirmed AGC from two centers. Radiomic features were extracted from preoperative diagnostic CT images. Machine learning methods were applied to shrink feature size and build a predictive radiomic signature. We incorporated the radiomic signature and clinical risk factors into a nomogram using multivariable logistic regression analysis. The area under the curve (AUC) of operating characteristics (ROC), accuracy, and calibration curves were assessed to evaluate the nomogram's performance in discriminating early recurrence.
Results: A radiomic signature, including three hand crafted features and six deep learning features, was significantly associated with early recurrence (p-value <0.0001 for all sets). In addition, clinical N stage, carbohydrate antigen 199 levels, carcinoembryonic antigen levels, and Borrmann type were considered useful predictors for early recurrence. The nomogram, combining all these predictors, showed powerful prognostic ability in the training set and two test sets with AUCs of 0.831 (95% CI, 0.786-0.876), 0.826 (0.772-0.880) and 0.806 (0.732-0.881), respectively. The predicted risk yielded good agreement with the observed recurrence probability.
Conclusions: By incorporating a radiomic signature and clinical risk factors, we created a radiomic nomogram to predict early recurrence in patients with AGC, preoperatively, which may serve as a potential tool to guide personalized treatment. (C) 2019 Elsevier B.V. All rights reserved.","Gastric cancer,Computed tomography,Radiomics,Deep learning,Prognosis",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,5.881,"PHASE-III,TRIAL,SERUM,TUMOR-MARKERS,NODE-METASTASIS,PLUS,CISPLATIN,GASTRECTOMY,CAPECITABINE,CHEMOTHERAPY,INTERGROUP,CARCINOMA,PATTERNS",RADIOTHERAPY AND ONCOLOGY,,
44,An effective image retrieval system using machine learning and fuzzy c- means clustering approach,79,15-16,10123-10140,"Nair Lakshmi R.,Subramaniam Kamalraj,Venkatesan G. K. D. Prasanna","Nair LR,Subramaniam K,Venkatesan GKDP",Nair LR,10.1007/s11042-019-08090-2,Karpagam Academy of Higher Education (KAHE),"Recently, Content-based medical image retrieval (CBMIR) systems enable fast diagnosis via the assessment of the visual information in medical application. Most of the state-of-the-art CBMIR systems facing few issues: computationally expensive due to the usage of high dimensional feature vectors and complex classifier/clustering approaches. The reasons behind this are, inability to properly handle the ""semantic gap"" and the high intra-class versus inter-class variability problem of the medical image database (like radiographic image database). This yields a crucial demand for developing computationally efficient and highly effective retrieval system. For this purpose, the present study proposed an efficient retrieval system which has a four-fold: First, pre-processing and Feature extraction of input image using canonical correlation analysis (CCA). By this approach extracted the feature in both pixel and feature domains and examined more rigorously. Second, applied Fuzzy C means clustering of pixel intensity values as features based on the singular value decomposition. Through this can grouping, the image based on the pixel intensity value. Third, deep convolutional neural network with SVM classifier which makes implementable and requires only a compact feature vector representation of the stored database image with their class levels during retrieval. Finally evaluated the performance based on the measure of Mean Average Precision, Correct rate (CR), Error rate (ER), Accuracy. The classification results and learned features are used for the purpose of retrieving the medical images in a database. The proposed retrieval system performs better than the traditional approach in terms of measuring average value of precision, recall, f-measure and accuracy 95.9%, 94.96%, 95.37% and 95.798% respectively. The suggested approach is best suited towards retrieving the medical images for various part of the body.","Medical image retrieval,feature extraction,deep learning,correlation analysis,support vector machine",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,CLASSIFICATION,MULTIMEDIA TOOLS AND APPLICATIONS,,
45,A hybrid BCI system based on motor imagery and transient visual evoked potential,79,15-16,10327-10340,"Feng Zhengquan,He Qinghua,Zhang Jingna,Wang Li,Zhu Xinjian,Qiu Mingguo","Feng ZQ,He QH,Zhang JN,Wang L,Zhu XJ,Qiu MG",Qiu MG,10.1007/s11042-019-7607-3,Army Medical University,"Motion imaging (MI) refers to the psychological realization of motions without movement or muscle activity; the basis of neural rehabilitation as a brain-computer interface (BCI) technique has been extensively studied. The combination of motor imaging and brain-computer interface technology can take advantage of patients' willingness to take the initiative to assist them in rehabilitation. Studies have shown that MI combined with BCI rehabilitation training is better than traditional rehabilitation training. Transient visual evoked potentials and motor imaging constructed a hybrid BCI system. Three healthy subjects were tested. EEG signals were superimposed preprocessing according to visual stimulus superimposed frequency and motor guidance frequency respectively. Transient visual evoked EEG segmentation is used as a control signal of choice, the use of wavelet decomposition helps to extract features, and then use BP neural network recognition for classification and identification. Visual guidance, motion-oriented event-related synchronization, or desynchronization feature signals as rehabilitation exercise control signals, are using time-domain sliding energy analysis to extract features, and then using BP neural network recognition for classification and identification. EEG signals collected in the experiment were superimposed signals of transient visual evoked and motorized EEG. There were 300 transient electroencephalogram (EEG) and 100 segments Imagine EEG segmentation. According to the results of the test, the average recognition rate of visual evoked EEG reached 95.42%; the average recognition rate of motor imaginary EEG was 73.08%, but there was a large individual difference in motor imaging EEG signals except 1 Name of the test rate of 85%, the remaining two subjects were less than 70% recognition rate. There is a large individual difference between motion imaging and signal feature recognition, and it takes a long time to train. Therefore, it is necessary to study further the selection of control signals for rehabilitation training. As the threshold feedback signal, controlling the amplitude feedback of rehabilitation training can promote the motivation of participants' motivation to stimulate and enhance the rehabilitation treatment effect.","Transient visual evoked,Brain-computer interface,EEG,Motor imagination",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"MENTAL,PRACTICE,STROKE,RECOVERY,P300",MULTIMEDIA TOOLS AND APPLICATIONS,,
46,Use of machine intelligence to conduct analysis of human brain data for detection of abnormalities in its cognitive functions,79,15-16,10955-10973,"Amin Javeria,Sharif Muhammad,Yasmin Mussarat,Saba Tanzila,Raza Mudassar","Amin J,Sharif M,Yasmin M,Saba T,Raza M",Yasmin M,10.1007/s11042-019-7324-y,"Univ Wah, Dept Comp Sci, Wah Cantonment, Pakistan.","The physical appearance of a brain tumor in human beings may be an indication of problems in psychological (cognitive) functions. Such functions include learning, understanding, problem solving, decision making, and planning. Early brain tumor detection can be done by using the proper procedure of screening. MRI is used for the detection of disease staging and follow-up without ionization radiation. In this manuscript, an automated system is proposed for the analysis of brain data and detection of cognitive functions abnormalities. The region of interest (ROI) is enhanced using a proposed partial differential diffusion filter (PDDF) which is a modified form of anisotropic diffusion filter. Otsu algorithm is used for better segmentation. Moreover, a new method is also proposed for feature extraction which is a concatenation of local binary pattern (LBP) and Gray level co-occurrence matrix (C2LBPGLCM). The proposed method accurately distinguishes between healthy and unhealthy images with high specificity, sensitivity, and area under the curve.","Magnetic resonance imaging (MRI),Gray level co-occurrence matrix (GLCM),Potential differential diffusion filter (PDDF),Local binary pattern (LBP),LBP based GLCM (C2LBPGLCM)",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"TUMOR,SEGMENTATION,CLASSIFICATION,FEATURES,RECOGNITION,DIAGNOSIS,SELECTION,IMAGES,TISSUE",MULTIMEDIA TOOLS AND APPLICATIONS,,
47,Artificial Intelligence in Radiology-Ethical Considerations,10,4,,"Brady Adrian P.,Neri Emanuele","Brady AP,Neri E",Brady AP,10.3390/diagnostics10040231,"Mercy Univ Hosp, Dept Radiol, Cork T12 WE28, Ireland.","Artificial intelligence (AI) is poised to change much about the way we practice radiology in the near future. The power of AI tools has the potential to offer substantial benefit to patients. Conversely, there are dangers inherent in the deployment of AI in radiology, if this is done without regard to possible ethical risks. Some ethical issues are obvious; others are less easily discerned, and less easily avoided. This paper explains some of the ethical difficulties of which we are presently aware, and some of the measures we may take to protect against misuse of AI.","artificial intelligence,radiology ethics,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,CONFLICT-OF-INTEREST,DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7235856,
48,Automatic Annotation of Narrative Radiology Reports,10,4,,"Krsnik Ivan,Glavas Goran,Krsnik Marina,Miletic Damir,Stajduhar Ivan","Krsnik I,Glavas G,Krsnik M,Miletic D,Stajduhar I",Stajduhar I,10.3390/diagnostics10040196,University of Rijeka,"Narrative texts in electronic health records can be efficiently utilized for building decision support systems in the clinic, only if they are correctly interpreted automatically in accordance with a specified standard. This paper tackles the problem of developing an automated method of labeling free-form radiology reports, as a precursor for building query-capable report databases in hospitals. The analyzed dataset consists of 1295 radiology reports concerning the condition of a knee, retrospectively gathered at the Clinical Hospital Centre Rijeka, Croatia. Reports were manually labeled with one or more labels from a set of 10 most commonly occurring clinical conditions. After primary preprocessing of the texts, two sets of text classification methods were compared: (1) traditional classification models-Naive Bayes (NB), Logistic Regression (LR), Support Vector Machine (SVM), and Random Forests (RF)-coupled with Bag-of-Words (BoW) features (i.e., symbolic text representation) and (2) Convolutional Neural Network (CNN) coupled with dense word vectors (i.e., word embeddings as a semantic text representation) as input features. We resorted to nested 10-fold cross-validation to evaluate the performance of competing methods using accuracy, precision, recall, and F1 score. The CNN with semantic word representations as input yielded the overall best performance, having a micro-averaged F1 score of 86.7%. The CNN classifier yielded particularly encouraging results for the most represented conditions: degenerative disease (95.9%), arthrosis (93.3%), and injury (89.2%). As a data-hungry deep learning model, the CNN, however, performed notably worse than the competing models on underrepresented classes with fewer training instances such as multicausal disease or metabolic disease. LR, RF, and SVM performed comparably well, with the obtained micro-averaged F1 scores of 84.6%, 82.2%, and 82.1%, respectively.","free-form radiology report,automatic labeling,decision support system,natural language processing,machine learning,word embedding,knee",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"TEXT,ANALYSIS,CLASSIFICATION",DIAGNOSTICS,https://europepmc.org/articles/pmc7235892?pdf=render,
49,AK-DL: A Shallow Neural Network Model for Diagnosing Actinic Keratosis with Better Performance than Deep Neural Networks,10,4,,"Wang Liyang,Chen Angxuan,Zhang Yan,Wang Xiaoya,Zhang Yu,Shen Qun,Xue Yong","Wang LY,Chen AX,Zhang Y,Wang XY,Zhang Y,Shen Q,Xue Y",Xue Y,10.3390/diagnostics10040217,China Agricultural University,"Actinic keratosis (AK) is one of the most common precancerous skin lesions, which is easily confused with benign keratosis (BK). At present, the diagnosis of AK mainly depends on histopathological examination, and ignorance can easily occur in the early stage, thus missing the opportunity for treatment. In this study, we designed a shallow convolutional neural network (CNN) named actinic keratosis deep learning (AK-DL) and further developed an intelligent diagnostic system for AK based on the iOS platform. After data preprocessing, the AK-DL model was trained and tested with AK and BK images from dataset HAM10000. We further compared it with mainstream deep CNN models, such as AlexNet, GoogLeNet, and ResNet, as well as traditional medical image processing algorithms. Our results showed that the performance of AK-DL was better than the mainstream deep CNN models and traditional medical image processing algorithms based on the AK dataset. The recognition accuracy of AK-DL was 0.925, the area under the receiver operating characteristic curve (AUC) was 0.887, and the training time was only 123.0 s. An iOS app of intelligent diagnostic system was developed based on the AK-DL model for accurate and automatic diagnosis of AK. Our results indicate that it is better to employ a shallow CNN in the recognition of AK.","actinic keratosis,AK-DL,intelligent diagnostic app,mainstream deep model",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,CLASSIFICATION,DIAGNOSTICS,https://www.mdpi.com/2075-4418/10/4/217/pdf,
50,Ensemble Deep Learning Models for Heart Disease Classification: A Case Study from Mexico,11,4,,"Baccouche Asma,Garcia-Zapirain Begonya,Olea Cristian Castillo,Elmaghraby Adel","Baccouche A,Garcia-Zapirain B,Olea CC,Elmaghraby A",Baccouche A,10.3390/info11040207,University of Louisville,"Heart diseases are highly ranked among the leading causes of mortality in the world. They have various types including vascular, ischemic, and hypertensive heart disease. A large number of medical features are reported for patients in the Electronic Health Records (EHR) that allow physicians to diagnose and monitor heart disease. We collected a dataset from Medica Norte Hospital in Mexico that includes 800 records and 141 indicators such as age, weight, glucose, blood pressure rate, and clinical symptoms. Distribution of the collected records is very unbalanced on the different types of heart disease, where 17% of records have hypertensive heart disease, 16% of records have ischemic heart disease, 7% of records have mixed heart disease, and 8% of records have valvular heart disease. Herein, we propose an ensemble-learning framework of different neural network models, and a method of aggregating random under-sampling. To improve the performance of the classification algorithms, we implement a data preprocessing step with features selection. Experiments were conducted with unidirectional and bidirectional neural network models and results showed that an ensemble classifier with a BiLSTM or BiGRU model with a CNN model had the best classification performance with accuracy and F1-score between 91% and 96% for the different types of heart disease. These results are competitive and promising for heart disease dataset. We showed that ensemble-learning framework based on deep models could overcome the problem of classifying an unbalanced heart disease dataset. Our proposed framework can lead to highly accurate models that are adapted for clinical real data and diagnosis use.","heart disease classification,neural network,ensemble-learning model,under-sampling,features selection,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"ELECTRONIC,HEALTH,RECORDS,NEURAL-NETWORKS,MACHINE,PREDICTION,DIAGNOSIS,CHALLENGES,FEATURES",INFORMATION,https://doi.org/10.3390/info11040207,
51,SOPHIA: An Event-Based IoT and Machine Learning Architecture for Predictive Maintenance in Industry 4.0,11,4,,"Calabrese Matteo,Cimmino Martin,Fiume Francesca,Manfrin Martina,Romeo Luca,Ceccacci Silvia,Paolanti Marina,Toscano Giuseppe,Ciandrini Giovanni,Carrotta Alberto","Calabrese M,Cimmino M,Fiume F,Manfrin M,Romeo L,Ceccacci S,Paolanti M,Toscano G,Ciandrini G,Carrotta A",Romeo L,10.3390/info11040202,Marche Polytechnic University,"Predictive Maintenance (PdM) is a prominent strategy comprising all the operational techniques and actions required to ensure machine availability and to prevent a machine-down failure. One of the main challenges of PdM is to design and develop an embedded smart system to monitor and predict the health status of the machine. In this work, we use a data-driven approach based on machine learning applied to woodworking industrial machines for a major woodworking Italian corporation. Predicted failures probabilities are calculated through tree-based classification models (Gradient Boosting, Random Forest and Extreme Gradient Boosting) and calculated as the temporal evolution of event data. This is achieved by applying temporal feature engineering techniques and training an ensemble of classification algorithms to predict Remaining Useful Lifetime (RUL) of woodworking machines. The effectiveness of the proposed method is showed by testing an independent sample of additional woodworking machines without presenting machine down. The Gradient Boosting model achieved accuracy, recall, and precision of 98.9%, 99.6%, and 99.1%. Our predictive maintenance approach deployed on a Big Data framework allows screening simultaneously multiple connected machines by learning from terabytes of log data. The target prediction provides salient information which can be adopted within the maintenance management practice.","predictive maintenance,machine learning,Remaining Useful Lifetime,feature engineering,Big Data platform",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"HIDDEN,MARKOV,MODEL,PROGNOSTICS,SYSTEM",INFORMATION,https://www.mdpi.com/2078-2489/11/4/202/pdf,
52,Anti-Shake HDR Imaging Using RAW Image Data,11,4,,"Liu Yan,Lv Bingxue,Huang Wei,Jin Baohua,Li Canlin","Liu Y,Lv BX,Huang W,Jin BH,Li CL",Liu Y,10.3390/info11040213,Zhengzhou University of Light Industry,"Camera shaking and object movement can cause the output images to suffer from blurring, noise, and other artifacts, leading to poor image quality and low dynamic range. Raw images contain minimally processed data from the image sensor compared with JPEG images. In this paper, an anti-shake high-dynamic-range imaging method is presented. This method is more robust to camera motion than previous techniques. An algorithm based on information entropy is employed to choose a reference image from the raw image sequence. To further improve the robustness of the proposed method, the Oriented FAST and Rotated BRIEF (ORB) algorithm is adopted to register the inputs, and a simple Laplacian pyramid fusion method is implanted to generate the high-dynamic-range image. Additionally, a large dataset with 435 various exposure image sequences is collected, which includes the corresponding JPEG image sequences to test the effectiveness of the proposed method. The experimental results illustrate that the proposed method achieves better performance in terms of anti-shake ability and preserves more details for real scene images than traditional algorithms. Furthermore, the proposed method is suitable for extreme-exposure image pairs, which can be applied to binocular vision systems to acquire high-quality real scene images, and has a lower algorithm complexity than deep learning-based fusion methods.","raw data,high dynamic range,camera shake,image fusion",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"FUSION,SENSORS,MODEL",INFORMATION,https://www.mdpi.com/2078-2489/11/4/213/pdf,
53,Design of Negative Curvature Hollow Core Fiber Based on Reinforcement Learning,38,7,1959-1965,"Hu Xiaowen,Schuelzgene Axel","Hu XW,Schulzgene A",Hu XW,10.1109/JLT.2020.2971943,State University System of Florida,"In negative curvature hollow core fibers (NCHCFs), light guidance is based on the capillary structure in the cladding. To achieve desirable fiber propagation properties, various designs of the capillary structure have been proposed in literature. However, the design process so far depends more or less on experience. In this article, we propose a reinforcement learning (RL) based method of systematically optimizing the capillary structure to achieve low average confinement loss (CL) for a given operating wavelength range and core radius. We use a recurrent neural network (RNN) to interactively study the properties of different capillary structures. The wavelength averaged CLs of the resulting designs are more than one order of magnitude lower than the lowest average CL of prior designs in literature. The same approach can be applied to search for optimum capillary structures in terms of other fiber propagation properties such as bending loss (BL), higher order modes extinction ratio (HOMER), overlap of the optical mode with the capillary structure, or a trade-off among these properties.","Negative curvature hollow core fiber,optical fiber design,reinforcement learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Optics,Telecommunications",,3.764,"SINGLE-MODE,BOUNDARY,CURVATURE,CONFINEMENT,LOSS,SILICA,HOLLOW,WAVE-GUIDES,TRANSMISSION,SCATTERING",JOURNAL OF LIGHTWAVE TECHNOLOGY,,
54,Investigating Feature Selection and Random Forests for Inter-Patient Heartbeat Classification,13,4,,"Saenz-Cogollo Jose Francisco,Agelli Maurizio","Saenz-Cogollo JF,Agelli M",Saenz-Cogollo JF,10.3390/a13040075,"Ctr Adv Studies Res & Dev Sardinia CRS4, Edificio 1, I-09010 Pula, CA, Italy.","Finding an optimal combination of features and classifier is still an open problem in the development of automatic heartbeat classification systems, especially when applications that involve resource-constrained devices are considered. In this paper, a novel study of the selection of informative features and the use of a random forest classifier while following the recommendations of the Association for the Advancement of Medical Instrumentation (AAMI) and an inter-patient division of datasets is presented. Features were selected using a filter method based on the mutual information ranking criterion on the training set. Results showed that normalized beat-to-beat (R-R) intervals and features relative to the width of the ventricular depolarization waves (QRS complex) are the most discriminative among those considered. The best results achieved on the MIT-BIH Arrhythmia Database were an overall accuracy of 96.14% and F1-scores of 97.97%, 73.06%, and 90.85% in the classification of normal beats, supraventricular ectopic beats, and ventricular ectopic beats, respectively. In comparison with other state-of-the-art approaches tested under similar constraints, this work represents one of the highest performances reported to date while relying on a very small feature vector.","ECG feature selection,heartbeat classification,arrhythmia detection,random forest classifier",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"WAVELET,TRANSFORMATION,COMPLEXES,ENSEMBLE,SYSTEM",ALGORITHMS,https://www.preprints.org/manuscript/202003.0036/v1/download,
55,Performance Comparison of Parametric and Non-Parametric Regression Models for Uncertainty Analysis of Sheet Metal Forming Processes,10,4,,"Marques Armando E.,Prates Pedro A.,Pereira Andre F. G.,Oliveira Marta C.,Fernandes Jose V,Ribeiro Bernardete M.","Marques AE,Prates PA,Pereira AFG,Oliveira MC,Fernandes JV,Ribeiro BM",Marques AE,10.3390/met10040457,Universidade de Coimbra,"This work aims to compare the performance of various parametric and non-parametric metamodeling techniques when applied to sheet metal forming processes. For this, the U-Channel and the Square Cup forming processes were studied. In both cases, three steel grades were considered, and numerical simulations were performed, in order to establish a database for each combination of forming process and material. Each database was used to train and test the various metamodels, and their predictive performances were evaluated. The best performing metamodeling techniques were Gaussian processes, multi-layer perceptron, support vector machines, kernel ridge regression and polynomial chaos expansion.","sheet metal forming,uncertainty analysis,metamodeling,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Materials Science,Metallurgy & Metallurgical Engineering",,,DESIGN,METALS,https://www.mdpi.com/2075-4701/10/4/457/pdf,
56,Automatic segmentation of mitochondria and endolysosomes in volumetric electron microscopy data,119,,,"Mekuc Manca Zerovnik,Bohak Ciril,Hudoklin Samo,Kim Byeong Hak,Romih Rok,Kim Min Young,Marolt Matija","Mekuc MZ,Bohak C,Hudoklin S,Kim BH,Romih R,Kim MY,Marolt M",Mekuc MZ,10.1016/j.compbiomed.2020.103693,University of Ljubljana,"Automatic segmentation of intracellular compartments is a powerful technique, which provides quantitative data about presence, spatial distribution, structure and consequently the function of cells. With the recent development of high throughput volumetric data acquisition techniques in electron microscopy (EM), manual segmentation is becoming a major bottleneck of the process. To aid the cell research, we propose a technique for automatic segmentation of mitochondria and endolysosomes obtained from urinary bladder urothelial cells by the dual beam EM technique. We present a novel publicly available volumetric EM dataset - the first of urothelial cells, evaluate several state-of-the-art segmentation methods on the new dataset and present a novel segmentation pipeline, which is based on supervised deep learning and includes mechanisms that reduce the impact of dependencies in the input data, artefacts and annotation errors. We show that our approach outperforms the compared methods on the proposed dataset.","Intracellular compartments,Segmentation,Volumetric electron microscopy data,Mitochondria,Endosomes,Lysosomes,Endolysosomes,Urothelium,Deep learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"3D,UROTHELIUM",COMPUTERS IN BIOLOGY AND MEDICINE,,
57,Improving breast mass classification by shared data with domain transformation using a generative adversarial network,119,,,"Muramatsu Chisako,Nishio Mizuho,Goto Takuma,Oiwa Mikinao,Morita Takako,Yakami Masahiro,Kubo Takeshi,Togashi Kaori,Fujita Hiroshi","Muramatsu C,Nishio M,Goto T,Oiwa M,Morita T,Yakami M,Kubo T,Togashi K,Fujita H",Muramatsu C,10.1016/j.compbiomed.2020.103698,Shiga University,"Training of a convolutional neural network (CNN) generally requires a large dataset. However, it is not easy to collect a large medical image dataset. The purpose of this study is to investigate the utility of synthetic images in training CNNs and to demonstrate the applicability of unrelated images by domain transformation. Mammograms showing 202 benign and 212 malignant masses were used for evaluation. To create synthetic data, a cycle generative adversarial network was trained with 599 lung nodules in computed tomography (CT) and 1430 breast masses on digitized mammograms (DDSM). A CNN was trained for classification between benign and malignant masses. The classification performance was compared between the networks trained with the original data, augmented data, synthetic data, DDSM images, and natural images (ImageNet dataset). The results were evaluated in terms of the classification accuracy and the area under the receiver operating characteristic curves (AUC). The classification accuracy improved from 65.7% to 67.1% with data augmentation. The use of an ImageNet pretrained model was useful (79.2%). Performance was slightly improved when synthetic images or the DDSM images only were used for pretraining (67.6 and 72.5%, respectively). When the ImageNet pretrained model was trained with the synthetic images, the classification performance slightly improved (81.4%), although the difference in AUCs was not statistically significant. The use of the synthetic images had an effect similar to the DDSM images. The results of the proposed study indicated that the synthetic data generated from unrelated lesions by domain transformation could be used to increase the training samples.","Mammography,Classification,Deep learning,Generative adversarial network,ROC curve",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,AUGMENTATION,COMPUTERS IN BIOLOGY AND MEDICINE,,
58,Deep evolutionary analysis reveals the design principles of fold A glycosyltransferases,9,,,"Taujale Rahil,Venkat Aarya,Huang Liang-Chin,Zhou Zhongliang,Yeung Wayland,Rasheed Khaled M.,Li Sheng,Edison Arthur S.,Moremen Kelley W.,Kannan Natarajan","Taujale R,Venkat A,Huang LC,Zhou ZL,Yeung W,Rasheed KM,Li S,Edison AS,Moremen KW,Kannan N",Kannan N,10.7554/eLife.54532,University System of Georgia,"Glycosyltransferases (GTs) are prevalent across the tree of life and regulate nearly all aspects of cellular functions. The evolutionary basis for their complex and diverse modes of catalytic functions remain enigmatic. Here, based on deep mining of over half million GT-A fold sequences, we define a minimal core component shared among functionally diverse enzymes. We find that variations in the common core and emergence of hypervariable loops extending from the core contributed to GT-A diversity. We provide a phylogenetic framework relating diverse GT-A fold families for the first time and show that inverting and retaining mechanisms emerged multiple times independently during evolution. Using evolutionary information encoded in primary sequences, we trained a machine learning classifier to predict donor specificity with nearly 90% accuracy and deployed it for the annotation of understudied GTs. Our studies provide an evolutionary framework for investigating complex relationships connecting GT-A fold sequence, structure, function and regulation.","N-ACETYLGLUCOSAMINYLTRANSFERASE,NEISSERIA-MENINGITIDIS,CONFORMATIONAL-CHANGES,CRYSTAL-STRUCTURES,UDP-GALNAC,DONOR,ALIGNMENT,MUTATION,COMPLEX,GLYCOSYLATION",Article,"ELIFE SCIENCES PUBLICATIONS LTD, SHERATON HOUSE, CASTLE PARK, CAMBRIDGE, CB3 0AX, ENGLAND",Life Sciences & Biomedicine - Other Topics,,9.059,"N-ACETYLGLUCOSAMINYLTRANSFERASE,NEISSERIA-MENINGITIDIS,CONFORMATIONAL-CHANGES,CRYSTAL-STRUCTURES,UDP-GALNAC,DONOR,ALIGNMENT,MUTATION,COMPLEX,GLYCOSYLATION",ELIFE,https://www.biorxiv.org/content/biorxiv/early/2020/01/01/2019.12.31.891697.full.pdf,
59,HJB-Equation-Based Optimal Learning Scheme for Neural Networks With Applications in Brain-Computer Interface,4,2,159-170,"Reddy Tharun Kumar,Arora Vipul,Behera Laxmidhar","Reddy TK,Arora V,Behera L",Behera L,10.1109/TETCI.2018.2858761,Indian Institute of Technology System (IIT System),"This paper proposes a novel method for training neural networks (NNs). It uses an approach from optimal control theory, namely, Hamilton-Jacobi-Bellman equation, which optimizes system performance along the trajectory. This formulation leads to a closed-form solution for an optimal weight update rule, which has been combined with per-parameter adaptive scheme AdaGrad to further enhance its performance. To evaluate the proposedmethod, the NNs are trained and tested on two problems related to EEG classification, namely, mental imagery classification (multiclass) and eye state recognition (binary class). In addition, a novel dataset with the name EEG eye state, for benchmarking learningmethods, is presented. The convergence proof for the proposed approach is also included, and performance is validated on many small to large scale, synthetic datasets (UCI, LIBSVM datasets). The performance of NNs trained with the proposed scheme is compared with other state-of-the-art approaches. Evaluation results substantiate the improvements brought about by the proposed scheme regarding faster convergence and better accuracy.","Neural network training,optimal control,HJB equation,brain-computer interface,eye state recognition",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Computer Science,,,"TIME-SERIES,PREDICTION,ALGORITHM,NEED",IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE,,
60,On Combining Biclustering Mining and AdaBoost for Breast Tumor Classification,32,4,728-738,"Huang Qinghua,Chen Yongdong,Liu Longzhong,Tao Dacheng,Li Xuelong","Huang QH,Chen YD,Liu LZ,Tao DH,Li XL",Huang QH,10.1109/TKDE.2019.2891622,Northwestern Polytechnical University,"Breast cancer is now considered as one of the leading causes of deaths among women all over the world. Aiming to assist clinicians in improving the accuracy of diagnostic decisions, computer-aided diagnosis (CAD) system is of increasing interest in breast cancer detection and analysis nowadays. In this paper, a novel computer-aided diagnosis scheme with human-in-the-loop is proposed to help clinicians identify the benign and malignant breast tumors in ultrasound. In this framework, feature acquisition is performed by a user-participated feature scoring scheme that is based on Breast Imaging Reporting and Data System (BI-RADS) lexicon and experience of doctors. Biclustering mining is then used as a useful tool to discover the column consistency patterns on the training data. The patterns frequently appearing in the tumors with the same label can be regarded as a potential diagnostic rule. Subsequently, the diagnostic rules are utilized to construct component classifiers of the Adaboost algorithm via a novel rules combination strategy which resolves the problem of classification in different feature spaces (PC-DFS). Finally, the AdaBoost learning is performed to discover effective combinations and integrate them into a strong classifier. The proposed approach has been validated using a large ultrasounic dataset of 1,062 breast tumor instances (including 418 benign cases and 644 malignant cases) and its performance was compared with several conventional approaches. The experimental results show that the proposed method yielded the best prediction performance, indicating a good potential in clinical applications.","Breast tumors,Feature extraction,Breast cancer,Ultrasonic imaging,Biclustering,ensemble learning of diagnostic rules,feature space dependent normalized distance,PC-DFS,computer-aided diagnosis",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Computer Science,Engineering",,6.085,"COMPUTER-AIDED,DIAGNOSIS,DECISION,TREE,ULTRASOUND,SYSTEM,MASSES,FEATURES,NODULES,US",IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,,
61,Deep Learning Approach for Generating MRA Images From 3D Quantitative Synthetic MRI Without Additional Scans,55,4,249-256,"Fujita Shohei,Hagiwara Akifumi,Otsuka Yujiro,Hori Masaaki,Takei Naoyuki,Hwang Ken-Pin,Irie Ryusuke,Andica Christina,Kamagata Koji,Akashi Toshiaki","Fujita S,Hagiwara A,Otsuka Y,Hori M,Takei N,Hwang KP,Irie R,Andica C,Kamagata K,Akashi T",Hagiwara A,10.1097/RLI.0000000000000628,Juntendo University,"Objectives
Quantitative synthetic magnetic resonance imaging (MRI) enables synthesis of various contrast-weighted images as well as simultaneous quantification of T1 and T2 relaxation times and proton density. However, to date, it has been challenging to generate magnetic resonance angiography (MRA) images with synthetic MRI. The purpose of this study was to develop a deep learning algorithm to generate MRA images based on 3D synthetic MRI raw data.
Materials and Methods
Eleven healthy volunteers and 4 patients with intracranial aneurysms were included in this study. All participants underwent a time-of-flight (TOF) MRA sequence and a 3D-QALAS synthetic MRI sequence. The 3D-QALAS sequence acquires 5 raw images, which were used as the input for a deep learning network. The input was converted to its corresponding MRA images by a combination of a single-convolution and a U-net model with a 5-fold cross-validation, which were then compared with a simple linear combination model. Image quality was evaluated by calculating the peak signal-to-noise ratio (PSNR), structural similarity index measurements (SSIMs), and high frequency error norm (HFEN). These calculations were performed for deep learning MRA (DL-MRA) and linear combination MRA (linear-MR), relative to TOF-MRA, and compared with each other using a nonparametric Wilcoxon signed-rank test. Overall image quality and branch visualization, each scored on a 5-point Likert scale, were blindly and independently rated by 2 board-certified radiologists.
Results
Deep learning MRA was successfully obtained in all subjects. The mean PSNR, SSIM, and HFEN of the DL-MRA were significantly higher, higher, and lower, respectively, than those of the linear-MRA (PSNR, 35.3 +/- 0.5 vs 34.0 +/- 0.5, P < 0.001; SSIM, 0.93 +/- 0.02 vs 0.82 +/- 0.02, P < 0.001; HFEN, 0.61 +/- 0.08 vs 0.86 +/- 0.05, P < 0.001). The overall image quality of the DL-MRA was comparable to that of TOF-MRA (4.2 +/- 0.7 vs 4.4 +/- 0.7, P = 0.99), and both types of images were superior to that of linear-MRA (1.5 +/- 0.6, for both P < 0.001). No significant differences were identified between DL-MRA and TOF-MRA in the branch visibility of intracranial arteries, except for ophthalmic artery (1.2 +/- 0.5 vs 2.3 +/- 1.2, P < 0.001).
Conclusions
Magnetic resonance angiography generated by deep learning from 3D synthetic MRI data visualized major intracranial arteries as effectively as TOF-MRA, with inherently aligned quantitative maps and multiple contrast-weighted images. Our proposed algorithm may be useful as a screening tool for intracranial aneurysms without requiring additional scanning time.","convolutional neural network,deep learning,image synthesis,machine learning,magnetic resonance angiography,magnetic resonance imaging,QALAS,quantitative synthetic MRI,time-of-flight",Article,"LIPPINCOTT WILLIAMS & WILKINS, TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA","Radiology, Nuclear Medicine & Medical Imaging",,5.958,"UNRUPTURED,INTRACRANIAL,ANEURYSMS,MAGNETIC-RESONANCE,ANGIOGRAPHY,SEGMENTATION,BRAIN,QUANTIFICATION,OPTIMIZATION",INVESTIGATIVE RADIOLOGY,https://journals.lww.com/investigativeradiology/Fulltext/2020/04000/Deep_Learning_Approach_for_Generating_MRA_Images.8.aspx,
62,Classifying and analyzing small-angle scattering data using weighted k nearest neighbors machine learning techniques,53,,326-334,"Archibald Richard K.,Doucet Mathieu,Johnston Travis,Young Steven R.,Yang Erika,Heller William T.","Archibald RK,Doucet M,Johnston T,Young SR,Yang E,Heller WT",Archibald RK,10.1107/S1600576720000552,United States Department of Energy (DOE),"A consistent challenge for both new and expert practitioners of small-angle scattering (SAS) lies in determining how to analyze the data, given the limited information content of said data and the large number of models that can be employed. Machine learning (ML) methods are powerful tools for classifying data that have found diverse applications in many fields of science. Here, ML methods are applied to the problem of classifying SAS data for the most appropriate model to use for data analysis. The approach employed is built around the method of weighted k nearest neighbors (wKNN), and utilizes a subset of the models implemented in the SasView package (https://www. sasview.org/) for generating a well defined set of training and testing data. The prediction rate of the wKNN method implemented here using a subset of SasView models is reasonably good for many of the models, but has difficulty with others, notably those based on spherical structures. A novel expansion of the wKNN method was also developed, which uses Gaussian processes to produce local surrogate models for the classification, and this significantly improves the classification accuracy. Further, by integrating a stochastic gradient descent method during post-processing, it is possible to leverage the local surrogate model both to classify the SAS data with high accuracy and to predict the structural parameters that best describe the data. The linking of data classification and model fitting has the potential to facilitate the translation of measured data into results for both novice and expert practitioners of SAS.","small-angle scattering data,machine learning,modeling,SasView",Article,"INT UNION CRYSTALLOGRAPHY, 2 ABBEY SQ, CHESTER, CH1 2HU, ENGLAND","Chemistry,Crystallography",,4.18,"COMPUTER,CALIBRATION",JOURNAL OF APPLIED CRYSTALLOGRAPHY,,
63,SGM: a novel time-frequency algorithm based on unsupervised learning improves high-frequency oscillation detection in epilepsy,17,2,,"Migliorelli Carolina,Bachiller Alejandro,Alonso Joan F.,Romero Sergio,Aparicio Javier,Jacobs-Le Van Julia,Mananas Miguel A.,San Antonio-Arce Victoria","Migliorelli C,Bachiller A,Alonso JF,Romero S,Aparicio J,Jacobs-Le Van J,Mananas MA,San Antonio-Arce V",Bachiller A,10.1088/1741-2552/ab8345,CIBER - Centro de Investigacion Biomedica en Red,"Objective. We propose a novel automated method called the S-Transform Gaussian Mixture detection algorithm (SGM) to detect high-frequency oscillations (HFO) combining the strengths of different families of previously published detectors. Approach. This algorithm does not depend on parameter tuning on a subject (or database) basis, uses time-frequency characteristics, and relies on non-supervised classification to determine if the events standing out from the baseline activity are HFO or not. SGM consists of three steps: the first stage computes the signal baseline using the entropy of the autocorrelation; the second uses the S-Transform to obtain several time-frequency features (area, entropy, and time and frequency widths); and in the third stage Gaussian mixture models cluster time-frequency features to decide if events correspond to HFO-like activity. To validate the SGM algorithm we tested its performance in simulated and real environments. Main results. We assessed the algorithm on a publicly available simulated stereoelectroencephalographic (SEEG) database with varying signal-to-noise ratios (SNR), obtaining very good results for medium and high SNR signals. We further tested the SGM algorithm on real signals from patients with focal epilepsy, in which HFO detection was performed visually by experts, yielding a high agreement between experts and SGM. Significance. The SGM algorithm displayed proper performance in simulated and real environments and therefore can be used for non-supervised detection of HFO. This non-supervised algorithm does not require previous labelling by experts or parameter adjustment depending on the subject or database considered. SGM is not a computationally intensive algorithm, making it suitable to detect and characterize HFO in long-term SEEG recordings.","epilepsy,high-frequency oscillations (HFO),electroencephalography (EEG),signal classification,epilepsy",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"BIOMARKER,HFOS",JOURNAL OF NEURAL ENGINEERING,https://doi.org/10.1088/1741-2552/ab8345,
64,Machine learning recommends affordable new Ti alloy with bone-like modulus,34,,41-50,"Wu Chun-Te,Chang Hsiao-Tzu,Wu Chien-Yu,Chen Shi-Wei,Huang Sih-Ying,Huang Mingxin,Pan Yeong-Tsuen,Bradbury Peta,Chou Joshua,Yen Hung-Wei","Wu CT,Chang HT,Wu CY,Chen SW,Huang SY,Huang MX,Pan YT,Bradbury P,Chou J,Yen HW",Chou J; Yen HW,10.1016/j.mattod.2019.08.008,National Taiwan University,"A neural-network machine called ""beta Low"" enables a high-throughput recommendation for new 13 titanium alloys with Young's moduli lower than 50 GPa. The machine was trained by using a very general approach with small data from experiments. Its efficiency and accuracy break the barrier for alloy discovery. beta Low's best recommendation, Ti-12Nb-12Zr-12Sn (in wt.%) alloy, was unexpected in previous methods. This new alloy meets the requirements for bio-compatibility, low modulus, and low cost, and holds promise for orthopedic and prosthetic implants. Moreover, beta Low's prediction guides us to realize that the unexplored space of the chemical compositions of low-modulus biomedical titanium alloys is still large. Machine-learning-aided materials design accelerates the progress of materials development and reduces research costs in this work.","TITANIUM-ALLOYS,MECHANICAL-PROPERTIES,YOUNGS MODULUS,DEFORMATION-BEHAVIOR,TENSILE PROPERTIES,NEURAL-NETWORKS,PHASE,TEMPERATURE,DESIGN,ZR",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Materials Science,,36.768,"TITANIUM-ALLOYS,MECHANICAL-PROPERTIES,YOUNGS,MODULUS,DEFORMATION-BEHAVIOR,TENSILE,PROPERTIES,NEURAL-NETWORKS,PHASE,TEMPERATURE,DESIGN,ZR",MATERIALS TODAY,,
65,Deep neural network based framework for complex correlations in engineering metrics,44,,,"Asghari Vahid,Leung Yat Fai,Hsu Shu-Chien","Asghari V,Leung YF,Hsu SC",Hsu SC,10.1016/j.aei.2020.101058,Hong Kong Polytechnic University,"Linear or polynomial regression and artificial neural networks are often adopted to obtain correlation models between various attributes in engineering fields. Although these are straightforward, they may not perform well for datasets that involve complex correlations among multiple attributes, and overfitting can occur when highorder polynomials are used to match the data from one scenario but fail to produce accurate predictions elsewhere. This paper presents a Deep Neural Networks (DNN) based framework for obtaining complex correlations in engineering metrics and provides guidelines to assess data adequacy, remove outliers and to identify and resolve overfitting problems. Moreover, a clear and concise set of procedures for tuning hyperparameters of DNN is discussed. As an illustration, a DNN model was trained to predict the undrained shear strength of clays based on liquid limit, plastic limit, water content, vertical effective stress, and preconsolidation stress. This analysis is conducted with 1101 samples gathered from different sites all over the world. Prediction of soil strengths often involved significant uncertainties due to the natural variations in earth materials and site conditions, contributing to complex relationships among various material properties. Our results show that the proposed framework performs better than conventional correlation models established from previous studies. The developed framework and accompanying Python script can be readily applied to the prediction of clay properties at other sites, and also to other types of engineering metrics.","Deep neural networks,Machine learning,Regression modelling,Soil shear strength,Index properties of soil",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Computer Science,Engineering",,5.936,"CLAY,PARAMETERS,SHEAR-STRENGTH,PREDICTION,ARCHITECTURES,FOUNDATIONS",ADVANCED ENGINEERING INFORMATICS,,
66,SAFE: An EEG dataset for stable affective feature selection,44,,,"Lan Zirui,Liu Yisi,Sourina Olga,Wang Lipo,Scherer Reinhold,Muller-Putz Gernot","Lan ZR,Liu YS,Sourina O,Wang LP,Scherer R,Muller-Putz G",Liu YS,10.1016/j.aei.2020.101047,"Fraunhofer Singapore, Singapore, Singapore.","An affective brain-computer interface (aBCI) is a direct communication pathway between human brain and computer, via which the computer tries to recognize the affective states of its user and respond accordingly. As aBCI introduces personal affective factors into human-computer interaction, it could potentially enrich the user's experience during the interaction. Successful emotion recognition plays a key role in such a system. The state-of-the-art aBCIs leverage machine learning techniques which consist in acquiring affective electroencephalogram (EEG) signals from the user and calibrating the classifier to the affective patterns of the user. Many studies have reported satisfactory recognition accuracy using this paradigm. However, affective neural patterns are volatile over time even for the same subject. The recognition accuracy cannot be maintained if the usage of aBCI prolongs without recalibration. Existing studies have overlooked the performance evaluation of aBCI during long-term use. In this paper, we propose SAFE-an EEG dataset for stable affective feature selection. The dataset includes multiple recording sessions spanning across several days for each subject. Multiple sessions across different days were recorded so that the long-term recognition performance of aBCI can be evaluated. Based on this dataset, we demonstrate that the recognition accuracy of aBCIs deteriorates when re-calibration is ruled out during long-term usage. Then, we propose a stable feature selection method to choose the most stable affective features, for mitigating the accuracy deterioration to a lesser extent and maximizing the aBCI performance in the long run. We invite other researchers to test the performance of their aBCI algorithms on this dataset, and especially to evaluate the long-term performance of their methods.","EEG dataset,Emotion recognition,Affective features,Stable feature selection,Long-term aBCI performance",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Computer Science,Engineering",,,"EMOTION,RECOGNITION,TIME-SERIES",ADVANCED ENGINEERING INFORMATICS,http://repository.essex.ac.uk/27302/1/ADVEI_2019_75_R2.pdf,
67,Machine learning methods for optimal compatibility of materials in ecodesign,68,2,199-206,"Rojek I,Dostatni E.","Rojek I,Dostatni E",Rojek I,10.24425/bpasts.2020.131848,Kazimierz Wielki University,"Machine learning (ML) methods facilitate automated data mining. The authors compare the effectiveness of selected ML methods (RBF networks, Kohonen networks, and random forest) as modelling tools supporting the selection of materials in ecodesign. Applied in the design process, ML methods help benefit from the knowledge, experience and creativity of designers stored in historical data in databases. Implemented into a decision support system, the knowledge can be utilized - in the case under analysis - in the process of design of environmentally friendly products. The study was initiated with an analysis of input data for the selection of materials. The input data, specified in cooperation with designers, include both technological and environmental parameters which guarantee the desired compatibility of materials. Next, models were developed using selected ML methods. The models were assessed and implemented into an expert system. The authors show which models best fit their purpose and why. Models supporting the selection of materials, connections and disassembly methods help boost the recycling properties of designed products.","classification models,ecodesign,selection of materials,compatibility",Article,"POLSKA AKAD NAUK, POLISH ACAD SCI, DIV IV TECHNICAL SCIENCES PAS, PL DEFILAD 1, WARSZAWA, 00-901, POLAND",Engineering,,1.699,"DESIGN,IMPLEMENTATION,RECOGNITION,STRATEGIES,PREDICTION,PRODUCTS",BULLETIN OF THE POLISH ACADEMY OF SCIENCES-TECHNICAL SCIENCES,,
68,Data-Oriented Constitutive Modeling of Plasticity in Metals,13,7,,Hartmaier Alexander,Hartmaier A,Hartmaier A,10.3390/ma13071600,Ruhr University Bochum,"Constitutive models for plastic deformation of metals are typically based on flow rules determining the transition from elastic to plastic response of a material as function of the applied mechanical load. These flow rules are commonly formulated as a yield function, based on the equivalent stress and the yield strength of the material, and its derivatives. In this work, a novel mathematical formulation is developed that allows the efficient use of machine learning algorithms describing the elastic-plastic deformation of a solid under arbitrary mechanical loads and that can replace the standard yield functions with more flexible algorithms. By exploiting basic physical principles of elastic-plastic deformation, the dimensionality of the problem is reduced without loss of generality. The data-oriented approach inherently offers a great flexibility to handle different kinds of material anisotropy without the need for explicitly calculating a large number of model parameters. The applicability of this formulation in finite element analysis is demonstrated, and the results are compared to formulations based on Hill-like anisotropic plasticity as reference model. In future applications, the machine learning algorithm can be trained by hybrid experimental and numerical data, as for example obtained from fundamental micromechanical simulations based on crystal plasticity models. In this way, data-oriented constitutive modeling will also provide a new way to homogenize numerical results in a scale-bridging approach.","plasticity,machine learning,constitutive modeling",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"YIELD,SURFACE",MATERIALS,https://europepmc.org/articles/pmc7178379?pdf=render,
69,High-performance synaptic transistors for neuromorphic computing,29,4,,"Zhong Hai,Sun Qin-Chao,Li Guo,Du Jian-Yu,Huang He-Yi,Guo Er-Jia,He Meng,Wang Can,Yang Guo-Zhen,Ge Chen","Zhong H,Sun QC,Li G,Du JY,Huang HY,Guo EJ,He M,Wang C,Yang GZ,Ge C",Ge C; Jin KJ,10.1088/1674-1056/ab7806,Chinese Academy of Sciences,"The further development of traditional von Neumann-architecture computers is limited by the breaking of Moore's law and the von Neumann bottleneck, which make them unsuitable for future high-performance artificial intelligence (AI) systems. Therefore, new computing paradigms are desperately needed. Inspired by the human brain, neuromorphic computing is proposed to realize AI while reducing power consumption. As one of the basic hardware units for neuromorphic computing, artificial synapses have recently aroused worldwide research interests. Among various electronic devices that mimic biological synapses, synaptic transistors show promising properties, such as the ability to perform signal transmission and learning simultaneously, allowing dynamic spatiotemporal information processing applications. In this article, we provide a review of recent advances in electrolyte- and ferroelectric-gated synaptic transistors. Their structures, materials, working mechanisms, advantages, and disadvantages will be presented. In addition, the challenges of developing advanced synaptic transistors are discussed.","synaptic transistor,artificial synapse,synaptic plasticity,electrolyte gating,ferroelectric gating",Review,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,1.262,"LONG-TERM,POTENTIATION,THIN-FILM,TRANSISTORS,PLASTICITY,MEMORY,DEPRESSION,DEVICES,SYNAPSES,MODEL,SPIN",CHINESE PHYSICS B,,
70,Transfer Learning of Potential Energy Surfaces for Efficient Atomistic Modeling of Doping and Alloy,41,4,633-636,"Mo Pinghui,Shi Mengchao,Yao Wenze,Liu Jie","Mo PH,Shi MC,Yao WZ,Liu J",Liu J,10.1109/LED.2020.2972066,Hunan University,"This letter proposes a transfer learning (TL) method to generate neural network (NN) database to model doping and alloy. By leveraging the valuable potential energy surface (PES) information already available in source system and similarities between source and target systems, the proposed TL successfully reduces computational cost by several orders of magnitude, while keeping ab-initio level high accuracy. We show that it is generally applicable to model p-type, n-type, and alloy atomic substitutions.","Transfer learning,supervised learning,ab-initio TCAD,neural network,dopant,alloy,density functional theory",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,3.967,"PERFORMANCE,PHOSPHORENE,DYNAMICS,MOS2",IEEE ELECTRON DEVICE LETTERS,,
71,Sequential Cluster Estimation: A Generalized Model for Finding Large Numbers of Clusters in Data,6,2,6-9,Runkler Thomas A.,Runkler TA,Runkler TA,10.1109/MSMC.2020.2965319,Technical University of Munich,"Clustering is an unsupervised learning method that partitions a set of objects into groups (clusters) of similar objects, where similarity is often computed from numerical object feature vectors (also called data points). An early (and still very popular) clustering algorithm, called k-means, finds clusters by minimizing the sum of the squared distances between data points and associated cluster centers. The k-means algorithm (like many other so-called hard clustering algorithms) assigns each object to one and only one of the considered clusters. In practice, however, cluster assignments may often be ambiguous. Objects may partially belong to several clusters or fit to none of these clusters. Such kinds of ambiguity can be mathematically handled by what is termed fuzzy set theory. A fuzzy variant of k-means called fuzzy c-means (FCM) has emerged to become one of the most popular fuzzy clustering methods, with hundreds of thousands of scientific publications. For a survey. Fuzzy clustering is often used to generate membership functions for fuzzy rule-based systems. Alternating cluster estimation (ACE)is an extension of FCM for arbitrary membership function shapes. This article introduces sequential cluster estimation (SCE), a variant of ACE that finds clusters sequentially and outperforms nonsequential clustering for data with many clusters.","Solid modeling,Phase change materials,Estimation,Clustering algorithms,Data models,Fuzzy systems,Production",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Computer Science,,,,IEEE SYSTEMS MAN AND CYBERNETICS MAGAZINE,https://ieeexplore.ieee.org/ielx7/6745853/9072208/09072211.pdf,
72,A Review of Algorithm & Hardware Design for AI-Based Biomedical Applications,14,2,145-163,"Wei Ying,Zhou Jun,Wang Yin,Liu Yinggang,Liu Qingsong,Luo Jiansheng,Wang Chao,Ren Fengbo,Huang Li","Wei Y,Zhou J,Wang Y,Liu YG,Liu QS,Luo JS,Wang C,Ren FB,Huang L",Zhou J,10.1109/TBCAS.2020.2974154,University of Electronic Science & Technology of China,"This paper reviews the state of the arts and trends of the AI-Based biomedical processing algorithms and hardware. The algorithms and hardware for different biomedical applications such as ECG, EEG and hearing aid have been reviewed and discussed. For algorithm design, various widely used biomedical signal classification algorithms have been discussed including support vector machine (SVM), back propagation neural network (BPNN), convolutional neural networks (CNN), probabilistic neural networks (PNN), recurrent neural networks (RNN), Short-term Memory Network (LSTM), fuzzy neural network and etc. The pros and cons of the classification algorithms have been analyzed and compared in the context of application scenarios. The research trends of AI-Based biomedical processing algorithms and applications are also discussed. For hardware design, various AI-Based biomedical processors have been reviewed and discussed, including ECG classification processor, EEG classification processor, EMG classification processor and hearing aid processor. Various techniques on architecture and circuit level have been analyzed and compared. The research trends of the AI-Based biomedical processor have also been discussed.","AI,algorithm,biomedical application,proce-ssor",Review,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,"CONVOLUTIONAL,NEURAL-NETWORK,EPILEPTIC,SEIZURE,DETECTION,SUPPORT,VECTOR,MACHINES,AUTOMATED,DETECTION,EMG,SIGNALS,CLASSIFICATION,FPGA,IDENTIFICATION,OPTIMIZATION,RECOGNITION",IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,,
73,Deep Learning Approach for Epileptic Focus Localization,14,2,209-220,"Daoud Hisham,Bayoumi Magdy","Daoud H,Bayoumi M",Daoud H,10.1109/TBCAS.2019.2957087,University of Louisiana Lafayette,"The task of epileptic focus localization receives great attention due to its role in an effective epileptic surgery. The clinicians highly depend on the intracranial EEG data to make a surgical decision related to epileptic subjects suffering from uncontrollable seizures. This surgery usually aims to remove the epileptogenic region which requires precise characterization of that area using the EEG recordings. In this paper, we propose two methods based on deep learning targeting accurate automatic epileptic focus localization using the non-stationary EEG recordings. Our first proposed method is based on semi-supervised learning, in which a deep convolutional autoencoder is trained and then the pre-trained encoder is used with multi-layer perceptron as a classifier. The goal is to determine the location of the EEG signal that is responsible for the epileptic activity. In the second proposed method, unsupervised learning scheme is implemented by merging deep convolutional variational autoencoder and K-means algorithm for clustering the iEEG signals into two distinct clusters based on the seizure source. The proposed methods automate and integrate the features extraction and classification processes instead of manually extracting the features as done in the previous studies. Dimensionality reduction is achieved using the autoencoder, while the important spatio-temporal features are extracted from the EEG recordings using the convolutional layers. Moreover, we implemented the inference network of the semi-supervised model on FPGA. The results of our experiments demonstrate high classification accuracy and clustering performance in localizing the epileptic focus compared with the state of the art.","Electroencephalography,Feature extraction,Training,Surgery,Machine learning,Convolution,Brain modeling,Classification,clustering,convolutional autoen-coder,EEG,epileptic focus localization,variational autoencoder",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,"DISCRETE,WAVELET,TRANSFORM,IDENTIFICATION,CLASSIFICATION",IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,,
74,A Fully Embedded Adaptive Real-Time Hand Gesture Classifier Leveraging HD-sEMG and Deep Learning,14,2,232-243,"Tam Simon,Boukadoum Mounir,Campeau-Lecours Alexandre,Gosselin Benoit","Tam S,Boukadoum M,Campeau-Lecours A,Gosselin B",Tam S,10.1109/TBCAS.2019.2955641,University of Quebec,"This paper presents a real-time fine gesture recognition system for multi-articulating hand prosthesis control, using an embedded convolutional neural network (CNN) to classify hand-muscle contractions sensed at the forearm. The sensor consists in a custom non-intrusive, compact, and easy-to-install 32-channel high-density surface electromyography (HDsEMG) electrode array, built on a flexible printed circuit board (PCB) to allow wrapping around the forearm. The sensor provides a low-noise digitization interface with wireless data transmission through an industrial, scientific and medical (ISM) radio link. An original frequency-time-space cross-domain preprocessing method is proposed to enhance gesture-specific data homogeneity and generate reliable muscle activation maps, leading to 98.15% accuracy when using a majority vote over 5 subsequent inferences by the proposed CNN. The obtained real-time gesture recognition, within 100 to 200 ms, and CNN properties show reliable and promising results to improve on the state-of-the-art of commercial hand prostheses. Moreover, edge computing using a specialized embedded artificial intelligence (AI) platform ensures reliable, secure and low latency real-time operation as well as quick and easy access to training, fine-tuning and calibration of the neural network. Co-design of the signal processing, AI algorithms and sensing hardware ensures a reliable and power-efficient embedded gesture recognition system.","Electrodes,Real-time systems,Prosthetics,Muscles,Electromyography,Gesture recognition,Deep learning,Armband,Control,Convolution,Deep Learning,Edge Computing,Electromyography,Gesture,HD-EMG,Machine Learning,Motion,Myoelectric,Neural Network,Prosthetic Hand,Real-Time,Recognition",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,OF-THE-ART,IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,,
75,Kalman-Based Real-Time Functional Decomposition for the Spectral Calibration in Swept Source Optical Coherence Tomography,14,2,257-273,"Zavareh Amir Tofighi,Hoyos Sebastian","Zavareh AT,Hoyos S",Zavareh AT,10.1109/TBCAS.2019.2953212,Texas A&M University System,"This paper presents a real-time functional decomposition adaptive algorithm for the optimal sampling of the interferometric signal in Swept-Source Optical Coherence Tomography imaging systems, which completely eliminates the input signal dependent nonlinearities that are problematic in current state-of-the-art OCT realizations that use interpolation and resampling. The proposed adaptive calibration algorithm uses the Kalman approach to estimate the wavenumber index parameter k from the Mach-Zender Interferometer signal which is then applied to an adaptive level crossing sampler to generate a sampling clock that k-linearizes the data on real-time during the sampling process. Such a system implements an artifact-free realization of the technology removing the need for classical interpolation and resampling. The new real-time linearization scheme has the additional capability of increasing the imaging acquisition speed by 10X while providing robustness to noise, properties that are demonstrated through mathematical analysis and simulation results throughout the paper.","Kalman Filtering,Machine Learning,Mach-Zehnder Interferometer,Michelson Interferometer,Optical Coherence Tomography,Spectral Calibration,Swept Source Optical Coherence Tomography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,"DOMAIN,OCT,QUALITY,FILTER",IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,,
76,A Real-Time Arrhythmia Heartbeats Classification Algorithm Using Parallel Delta Modulations and Rotated Linear-Kernel Support Vector Machines,67,4,978-986,"Tang Xiaochen,Ma Ziwei,Hu Qisong,Tang Wei","Tang XC,Ma ZW,Hu QS,Tang W",Tang W,10.1109/TBME.2019.2926104,New Mexico State University,"Real-time wearable electrocardiogram monitoring sensor is one of the best candidates in assisting cardiovascular disease diagnosis. In this paper, we present a novel real-time machine learning system for Arrhythmia classification. The system is based on the parallel Delta modulation and QRS/PT wave detection algorithms. We propose a patient dependent rotated linear-kernel support vector machine classifier that combines the global and local classifiers, with three types of feature vectors extracted directly from the Delta modulated bit-streams. The performance of the proposed system is evaluated using the MIT-BIH Arrhythmia database. According to the AAMI standard, two binary classifications are performed and evaluated, which are supraventricular ectopic beat (SVEB) versus the rest four classes, and ventricular ectopic beat (VEB) versus the rest. For SVEB classification, the preferred SkP-32 method's F1 score, sensitivity, specificity, and positive predictivity value are 0.83, 79.3%, 99.6%, and 88.2%, respectively, and for VEB classification, the numbers are 0.92%, 92.8%, 99.4%, and 91.6%, respectively. The results show that the performance of our proposed approach is comparable to that of published research. The proposed low-complexity algorithm has the potential to be implemented as an on-sensor machine learning solution.","Electrocardiography,Feature extraction,Databases,Heart beat,Monitoring,Delta modulation,Real-time systems,ECG,parallel delta modulator,SVM",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"FEATURE-SELECTION,ECG,MORPHOLOGY,FEATURES,DISEASE,DRIVEN,RADIO,ADC",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
77,Facilitating Calibration in High-Speed BCI Spellers via Leveraging Cross-Device Shared Latent Responses,67,4,1105-1113,"Nakanishi Masaki,Wang Yu-Te,Wei Chun-Shu,Chiang Kuan-Jung,Jung Tzyy-Ping","Nakanishi M,Wang YT,Wei CS,Chiang KJ,Jung TP",Nakanishi M,10.1109/TBME.2019.2929745,University of California System,"Objective: This paper proposes a novel device-to-device transfer-learning algorithm for reducing the calibration cost in a steady-state visual evoked potential (SSVEP)-based brain-computer interface (BCI) speller by leveraging electroencephalographic (EEG) data previously acquired by different EEG systems. Methods: The transferring is done by projecting the scalp-channel EEG signals onto a shared latent domain across devices. Three spatial filtering techniques, including channel averaging, canonical correlation analysis (CCA), and task-related component analysis (TRCA), were employed to extract the shared responses from different devices. The transferred data were integrated into a template-matching-based algorithm to detect SSVEPs. To evaluate its transferability, this paper conducted two sessions of simulated online BCI experiments with ten subjects using 40 visual stimuli modulated by joint frequency-phase coding method. In each session, two different EEG devices were used: first, the Quick-30 system (Cognionics, Inc.) with dry electrodes, and second, the ActiveTwo system (BioSemi, Inc.) with wet electrodes. Results: The proposed method with CCA- and TRCA-based spatial filters achieved significantly higher classification accuracy compared with the calibration-free standard CCA-based method. Conclusion: This paper validated the feasibility and effectiveness of the proposed method in implementing calibration-free SSVEP-based BCIs. Significance: The proposed method has great potentials to enhance practicability and usability of real-world SSVEP-based BCI applications by leveraging user-specific data recorded in previous sessions even with different EEG systems and montages.","Electroencephalography,Visualization,Calibration,Electrodes,Training,Correlation,Task analysis,Brain-computer interfaces,canonical correlation analysis,electroencephalography,steady-state visual evoked potentials,task-related component analysis,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"CANONICAL,CORRELATION-ANALYSIS,VISUAL-EVOKED,POTENTIALS,BRAIN-COMPUTER,INTERFACE,FREQUENCY,RECOGNITION,ENHANCING,DETECTION,COMMUNICATION",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
78,A Deep Learning Framework for Single-Sided Sound Speed Inversion in Medical Ultrasound,67,4,1142-1151,"Feigin Micha,Freedman Daniel,Anthony Brian W.","Feigin M,Freedman D,Anthony BW",Feigin M,10.1109/TBME.2019.2931195,Massachusetts Institute of Technology (MIT),"Objective: Ultrasound elastography is gaining traction as an accessible and useful diagnostic tool for things such as, cancer detection and differentiation and thyroid disease diagnostics. Unfortunately, state-of-the-art shear wave imaging techniques, essential to promote this goal, are limited to high-end ultrasound hardware due to high-power requirements, and are extremely sensitive to patient and sonographer motion, and generally suffer from low frame rates. Motivated by research and theory showing that longitudinal wave sound speed carries similar diagnostic abilities to shear wave imaging, we present an alternative approach using single-sided pressure-wave sound speed measurements from channel data. Methods: In this paper, we present a single-sided sound speed inversion solution using a fully convolutional deep neural network. We use simulations for training, allowing the generation of limitless ground truth data. Results: We show that it is possible to invert for longitudinal sound speed in soft tissue at high frame rates. We validate the method on simulated data. We present highly encouraging results on limited real data. Conclusion: Sound speed inversion on channel data has made significant potential possible in real time with deep learning technologies. Significance: Specialized shear wave ultrasound systems remain inaccessible in many locations. Longitudinal sound speed and deep learning technologies enable an alternative approach to diagnosis based on tissue elasticity. High frame rates are also possible.","Ultrasonic imaging,Deep learning,Diseases,Elastography,Young's modulus,Deep learning,inverse problems,ultrasound,sound speed inversion",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"LOW-DOSE,CT,GENERATIVE,ADVERSARIAL,NETWORK,ELASTOGRAPHY,ELASTICITY,TISSUES",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,http://arxiv.org/pdf/1810.00322,
79,A Generic Approach to Lung Field Segmentation From Chest Radiographs Using Deep Space and Shape Learning,67,4,1206-1220,"Mansoor Awais,Cerrolaza Juan J.,Perez Geovanny,Biggs Elijah,Okada Kazunori,Nino Gustavo,Linguraru Marius George","Mansoor A,Cerrolaza JJ,Perez G,Biggs E,Okada K,Nino G,Linguraru MG",Mansoor A,10.1109/TBME.2019.2933508,Children's National Health System,"Computer-aided diagnosis (CAD) techniques for lung field segmentation from chest radiographs (CXR) have been proposed for adult cohorts, but rarely for pediatric subjects. Statistical shape models (SSMs), the workhorse of most state-of-the-art CXR-based lung field segmentation methods, do not efficiently accommodate shape variation of the lung field during the pediatric developmental stages. The main contributions of our work are: 1) a generic lung field segmentation framework from CXR accommodating large shape variation for adult and pediatric cohorts; 2) a deep representation learning detection mechanism, ensemble space learning, for robust object localization; and 3) marginal shape deep learning for the shape deformation parameter estimation. Unlike the iterative approach of conventional SSMs, the proposed shape learning mechanism transforms the parameter space into marginal subspaces that are solvable efficiently using the recursive representation learning mechanism. Furthermore, our method is the first to include the challenging retro-cardiac region in the CXR-based lung segmentation for accurate lung capacity estimation. The framework is evaluated on 668 CXRs of patients between 3 month to 89 year of age. We obtain a mean Dice similarity coefficient of $0.96 \pm 0.03$ (including the retro-cardiac region). For a given accuracy, the proposed approach is also found to be faster than conventional SSM-based iterative segmentation methods. The computational simplicity of the proposed generic framework could be similarly applied to the fast segmentation of other deformable objects.","Lung field,chest radiograph,deep learning,space learning,shape learning,statistical shape models",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"AUTOMATIC,SEGMENTATION,PATTERN-CLASSIFICATION,ROBUST",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,https://europepmc.org/articles/pmc7293875?pdf=render,
80,A deep convolutional neural network architecture for interstitial lung disease pattern classification,58,4,725-737,"Huang Sheng,Lee Feifei,Miao Ran,Si Qin,Lu Chaowen,Chen Qiu","Huang S,Lee FF,Miao R,Si Q,Lu CW,Chen Q",Lee FF,10.1007/s11517-019-02111-w,University of Shanghai for Science & Technology,"Interstitial lung disease (ILD) refers to a group of various abnormal inflammations of lung tissues and early diagnosis of these disease patterns is crucial for the treatment. Yet it is difficult to make an accurate diagnosis due to the similarity among the clinical manifestations of these diseases. In order to assist the radiologists, computer-aided diagnosis systems have been developed. Besides, the potential of deep convolutional neural networks (CNNs) is also expected to exert on the medical image analysis in recent years. In this paper, we design a new deep convolutional neural network (CNN) architecture to achieve the classification task of ILD patterns. Furthermore, we also propose a novel two-stage transfer learning (TSTL) method to deal with the problem of the lack of training data, which leverages the knowledge learned from sufficient textural source data and auxiliary unlabeled lung CT data to the target domain. We adopt the unsupervised manner to learn the unlabeled data, by which the objective function composed of the prediction confidence and mutual information are optimized. The experimental results show that our proposed CNN architecture achieves desirable performance and outperforms most of the state-of-the-art ones. The comparative analysis demonstrates the promising feasibility and advantages of the proposed two-stage transfer learning strategy as well as the potential of the knowledge learning from lung CT data.
The framework of the proposed two-stage transfer learning method.","Interstitial lung diseases (ILDs),Convolutional neural networks (CNNs),Deep convolutional autoencoder,Transfer learning",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"COMPUTED-TOMOGRAPHY,SCANS,AIDED,DETECTION,DIAGNOSIS",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
81,Deep learning-based noise reduction algorithm using patch group technique in cadmium zinc telluride fusion imaging system: A Monte Carlo simulation study,207,,,"Park Minji,Lee Seohyeon,Choi Serin,Lee Soeun,Han Seonyeong,Lee Hyejin,Kang Seong-Hyeon,Lee Youngjin","Park M,Lee S,Choi S,Lee S,Han S,Lee H,Kang SH,Lee Y",Lee Y,10.1016/j.ijleo.2020.164472,Gachon University,"Anatomical and functional fusion imaging systems using cadmium zinc telluride (CZT) are widely used in the field of medical imaging and nuclear-medicine. However, noise is inevitable in the CZT images, and reducing noise is thus crucial for accurate diagnosis of diseases. Among various available techniques for noise reduction in images, deep learning-based noise reduction algorithm using patch group is considered the most efficient method. Therefore, this study is focused on designing deep learning-based noise reduction algorithm using patch group and evaluating it using simulated CZT fusion images with X-ray and gamma ray. We used the Geant4 Application for Tomographic Emission (version 6), which is a Monte Carlo simulation tool, and the normalized noise power spectrum, coefficient of variation (COV), and contrast to noise ratio (CNR) were evaluated. Furthermore, the proposed deep learning-based noise reduction algorithm exhibited better values compared with the conventional noise reduction algorithms. In particular, the COV and CNR values of our algorithm were approximately 8.46 and 1.85 times better than that of the original CZT image. Thus, we successfully demonstrated the feasibility of the proposed deep learning-based noise reduction algorithm using the patch group technique in a CZT fusion imaging system.","X-ray and gamma ray fusion image,CZT detector,Patch group-based noise reduction algorithm,Deep learning,GATE simulation",Article,"ELSEVIER GMBH, HACKERBRUCKE 6, 80335 MUNICH, GERMANY",Optics,,1.955,"METAL-ARTIFACT-REDUCTION,CT,DETECTOR,HARDWARE",OPTIK,,
82,Predicting the band gap of ZnO quantum dots via supervised machine learning models,207,,,"Regonia Paul Rossener,Pelicano Christian Mark,Tani Ryosuke,Ishizumi Atsushi,Yanagi Hisao,Ikeda Kazushi","Regonia PR,Pelicano CM,Tani R,Ishizumi A,Yanagi H,Ikeda K",Regonia PR; Pelicano CM,10.1016/j.ijleo.2020.164469,Nara Institute of Science & Technology,"Developing mathematical models for zinc oxide (ZnO) nanostructures can significantly accelerate the production of ZnO-based devices and applications. Herein, the implementation of supervised machine learning to predict the optical band gap energy of ZnO is presented. Different models such as Kernel Ridge Regression (KRR) and Artificial Neural Network (ANN) were trained with empirical features, including experimental time and temperature conditions during ZnO fabrication. Test results revealed high accuracy of the models (KRR with quadratic features), with root mean squared error = 0.0849 eV, and mean absolute error percentage = 1.7328 %. These results show the capabilities of machine learning models for automated prediction of semiconductor properties, which can be used to accelerate materials design and applications.","ZnO quantum dots,Band gap,Machine learning",Article,"ELSEVIER GMBH, HACKERBRUCKE 6, 80335 MUNICH, GERMANY",Optics,,,"DOPED,ZINC-OXIDE,PHOTOCATALYTIC,PROPERTIES,PHOTOLUMINESCENCE,LAYER",OPTIK,,
83,A semi-automated method for integrating textural and material data into as-built BIM using TIS,5,2,127-146,"Zabin Asem,Khalil Baha,Ali Tang,Abdalla Jamal A.,Elaksher Ahmed","Zabin A,Khalil B,Ali T,Abdalla JA,Elaksher A",Abdalla JA,10.12989/acd.2020.5.2.127,American University of Sharjah,"Building Information Modeling (BIM) is increasingly used throughout the facility's life cycle for various applications, such as design, construction, facility management, and maintenance. For existing buildings, the geometry of as-built BIM is often constructed using dense, three dimensional (3D) point clouds data obtained with laser scanners. Traditionally, as-built BIM systems do not contain the material and textural information of the buildings' elements. This paper presents a semi-automatic method for generation of material and texture rich as-built BIM. The method captures and integrates material and textural information of building elements into as-built BIM using thermal infrared sensing (TIS). The proposed method uses TIS to capture thermal images of the interior walls of an existing building. These images are then processed to extract the interior walls using a segmentation algorithm. The digital numbers in the resulted images are then transformed into radiance values that represent the emitted thermal infrared radiation. Machine learning techniques are then applied to build a correlation between the radiance values and the material type in each image. The radiance values were used to extract textural information from the images. The extracted textural and material information are then robustly integrated into the as-built BIM providing the data needed for the assessment of building conditions in general including energy efficiency, among others.","As-Built BIM,building materials,thermal infrared imaging,thermography,texture extraction,feature technology,information visualization,machine learning",Article,"TECHNO-PRESS, PO BOX 33, YUSEONG, DAEJEON 305-600, SOUTH KOREA",Computer Science,,,"INFORMATION,DESIGN,RECOGNITION,SIMULATION",ADVANCES IN COMPUTATIONAL DESIGN,,
84,Data-driven machine-learning-based seismic failure mode identification of reinforced concrete shear walls,208,,,"Mangalathu Sujith,Jang Hansol,Hwang Seong-Hoon,Jeon Jong-Su","Mangalathu S,Jang H,Hwang SH,Jeon JS",Jeon JS,10.1016/j.engstruct.2020.110331,Hanyang University,"A reinforced concrete shear wall is one of the most critical structural members in buildings, in terms of carrying lateral loads. Despite its importance, post-earthquake reconnaissance and recent experimental studies have highlighted the insufficient safety margins of shear walls. The lack of empirical and mechanics-based models prevents rapid failure mode identification of existing shear walls. This study builds on recent advances in the area of machine learning to determine the failure mode of shear walls as a function of geometric configurations, material properties, and reinforcement details. This study assembles a comprehensive database consisting of 393 experimental results for shear walls with various geometric configurations. Eight machine learning models, including Naive Bayes, K-Nearest Neighbors, Decision Tree, Random Forest, AdaBoost, XGBoost, LightGBM, and CatBoost were evaluated in this study, in order to establish the best prediction model. As a result of detailed evaluation, a machine learning model based on the Random Forest method is proposed in this paper. The proposed method has 86% accuracy in identifying the failure mode of shear walls. This study also demonstrates that aspect ratio, boundary element reinforcement indices, and wall length-to-wall thickness ratio are the critical parameters influencing the failure mode of shear walls. Finally, an open-source data-driven classification model that can be used in design offices across the world is provided in this paper. The proposed model has the flexibility to account for additional experimental results yielding new insights.","Failure mode classification,Machine learning,Reinforced concrete shear wall,Critical input parameters",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,4.795,STRENGTH,ENGINEERING STRUCTURES,,
85,Mechanical MNIST: A benchmark dataset for mechanical metamodels,36,,,Lejeune Emma,Lejeune E,Lejeune E,10.1016/j.eml.2020.100659,Boston University,"Metamodels, or models of models, map defined model inputs to defined model outputs. Typically, metamodels are constructed by generating a dataset through sampling a direct model and training a machine learning algorithm to predict a limited number of model outputs from varying model inputs. When metamodels are constructed to be computationally cheap, they are an invaluable tool for applications ranging from topology optimization, to uncertainty quantification, to multi-scale simulation. By nature, a given metamodel will be tailored to a specific dataset. However, the most pragmatic metamodel type and structure will often be general to larger classes of problems. At present, the most pragmatic metamodel selection for dealing with mechanical data has not been thoroughly explored. Drawing inspiration from the benchmark datasets available to the computer vision research community, we introduce a benchmark data set (Mechanical MNIST) for constructing metamodels of heterogeneous material undergoing large deformation. We then show examples of how our benchmark dataset can be used, and establish baseline metamodel performance. Because our dataset is readily available, it will enable the direct quantitative comparison between different metamodeling approaches in a pragmatic manner. We anticipate that it will enable the broader community of researchers to develop improved metamodeling techniques for mechanical data that will surpass the baseline performance that we show here. (c) 2020 Elsevier Ltd. All rights reserved.","Finite element analysis,Machine learning,Metamodel,Dataset",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science,Mechanics",,5.532,"UNCERTAINTY,QUANTIFICATION,OPTIMIZATION,MODEL",EXTREME MECHANICS LETTERS,,
86,Artificial intelligence method to design and fold alpha -helical structural proteins from the primary amino acid sequence,36,,,"Qin Zhao,Wu Lingfei,Sun Hui,Huo Siyu,Ma Tengfei,Lim Eugene,Chen Pin-Yu,Marelli Benedetto,Buehler Markus J.","Qin Z,Wu LF,Sun H,Huo SY,Ma TF,Lim E,Chen PY,Marelli B,Buehler MJ",Buehler MJ,10.1016/j.eml.2020.100652,Massachusetts Institute of Technology (MIT),"The development of rational techniques to discover new mechanically relevant proteins for use in variety of applications ranging from mechanics, agriculture to biotechnology remains an outstanding nanomechanical design problem. The key barrier is to design a sequence to fold into a predictable structure to achieve a certain material function. Focused on alpha-helical proteins (as found in skin, hair, and many other mechanically relevant protein materials), we report a Multi-scale Neighborhood-based Neural Network (MNNN) model to learn how a specific amino acid sequence folds into a protein structure. The algorithm predicts the protein structure without using a template or co-evolutional information at a maximum error of 2.1 A. We find that the prediction accuracy is higher than other models and the prediction consumes less than six orders of magnitude time than ab initio folding methods. We demonstrate that MNNN can predict the structure of an unknown protein that agrees with experiments, and our model hence shows a great advantage in the rational design of de novo proteins. (c) 2020 Elsevier Ltd. All rights reserved.","Protein,Nanomechanics,Artificial intelligence,Machine learning,Deep neural networks,Folding,Structure prediction,Computation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science,Mechanics",,5.532,"CIRCULAR-DICHROISM,SPECTRA,INTERMEDIATE-FILAMENTS,SECONDARY,STRUCTURE,DYNAMICS,PREDICTION,SIMULATION,NETWORKS",EXTREME MECHANICS LETTERS,https://doi.org/10.1101/660639,
87,Cross-Modal Material Perception for Novel Objects: A Deep Adversarial Learning Method,17,2,697-707,"Zheng Wendong,Liu Huaping,Wang Bowen,Sun Fuchun","Zheng WD,Liu HP,Wang BW,Sun FC",Liu HP,10.1109/TASE.2019.2941230,Tsinghua University,"To more actively perform fine manipulation tasks in the real world, intelligent robots should be able to understand and communicate the physical attributes of the material during interaction with an object. Tactile and vision are two important sensing modalities in robotic perception system. In this article, we propose a cross-modal material perception framework for recognizing novel objects. Concretely, it first adopts an object-agnostic method to associate information from tactile and visual modalities. It then recognizes a novel object by using its tactile signal to retrieve perceptually similar surface material images through the learned cross-modal correlation. This problem exhibits a challenge because data from visual and tactile modalities are highly heterogeneous and weakly paired. Moreover, the framework should not only consider cross-modal pairwise relevance but also be discriminative and generalized for unseen objects. To this end, we propose a weakly paired cross-modal adversarial learning (WCMAL) model for the visual-tactile cross-modal retrieval, which combines the advantages of deep learning and adversarial learning. In particular, the model fully considers the weak pairing problem between the two modalities. Finally, we conduct verification experiments on a publicly available data set. The results demonstrate the effectiveness of the proposed method. Note to Practitioners-Since cross-modal perception can improve the active operation of automation systems, it is invaluable for industrial intelligence, particularly when only one sensing modality cannot be used or suitable in some applications. In this article, we provide a framework of cross-modal material perception for object recognition using the idea of the cross-modal retrieval. Concretely, we use relevant tactile data of an unknown object to retrieve perceptually similar surface images, which are used to evaluate its material properties. Different from that previous works using tactile information as a complement or alternative to visual information to recognize specific objects, our proposed framework is able to estimate and infer material properties of both seen and unseen objects, which can enhance manipulation systems intelligence and improve the quality of the interaction. In our future works, more modality information will be incorporated to further enhance the cross-modal material perception.","Robot sensing systems,Visualization,Object recognition,Measurement,Cross-modal perception,deep adversarial learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Automation & Control Systems,,5.516,"TACTILE,PERCEPTION,RETRIEVAL,IDENTIFICATION,RECOGNITION",IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING,,
88,Learning the representation of raw acoustic emission signals by direct generative modelling and its use in chronology-based clusters identification,90,,,"Ramasso Emmanuel,Butaud Pauline,Jeannin Thomas,Sarasini Fabrizio,Placet Vincent,Godin Nathalie,Tirillo Jacopo,Gabrion Xavier","Ramasso E,Butaud P,Jeannin T,Sarasini F,Placet V,Godin N,Tirillo J,Gabrion X",Ramasso E,10.1016/j.engappai.2020.103478,"Univ Bourgogne Franche Comte, Dept Appl Mech, CNRS UFC ENSMM UTBM, FEMTO ST, F-25000 Besancon, France.","Acoustic emission (AE) is a passive monitoring technique used for learning about the behaviour of an engineered system. The streaming obtained by continuously recording AE transient signals is treated by a four steps procedure: 1) The detection of salient AE signals by distinguishing noise against non-noise signals using wavelet denoising, 2) the statistical representation of randomly selected AE signals using Autoregressive Weakly Hidden Markov Models, 3) an inference phase by applying those models to unknown AE signals and generating a set of novelty scores reflecting differences between signals, 4) the clustering of novelty scores using constraint-based consensus clustering. Compared to the standard way relying on the transformation of all AE signals by manual feature engineering (MFE) before clustering, the main breaktrough proposed in this paper holds in the use of the raw AE signals, with different lengths and various scales, to build high level information and organise the low level streaming data. Validated first on simulated data, we show the potential of this methodology for interpreting acoustic emission streaming originating from composite materials.","Acoustic emission,Raw waveform,Model-based clustering,Representation learning,Novelty detection",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Automation & Control Systems,Computer Science,Engineering",,5.317,"TIME-SERIES,DATA,HIDDEN,MARKOV,BEHAVIOR,TENSILE,TESTS,ONSET",ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE,https://www.sciencedirect.com/science/article/am/pii/S0952197620300038,
89,Characterizing Alzheimer's Disease With Image and Genetic Biomarkers Using Supervised Topic Models,24,4,1180-1187,"Yang Jie,Feng Xinyang,Laine Andrew F.,Angelini Elsa D.","Yang J,Feng XY,Laine AF,Angelini ED",Laine AF,10.1109/JBHI.2019.2928831,Columbia University,"Neuroimaging and genetic biomarkers have been widely studied from discriminative perspectives towards Alzheimer's disease (AD) classification, since neuroanatomical patterns and genetic variants are jointly critical indicators for AD diagnosis. Generative methods, designed to model common occurring patterns, could potentially advance the understanding of this disease, but have not been fully explored for AD characterization. Moreover, the introduction of a supervised component into the generative process can constrain the model for more discriminative characterization. In this study, we propose an original method based on supervised topic modeling to characterize AD from a generative perspective, yet maintaining discriminative power at differentiating disease populations. Our topic modeling jointly exploits discretized image features and categorical genetic features. Diagnostic information - cognitively normal (CN), mild cognitive impairment (MCI) and AD - is introduced as a supervision variable. Experimental results on the ADNI cohort demonstrate that our model, while achieving competitive discriminative performance, can discover topics revealing both well-known and novel neuroanatomical patterns including temporal, parietal and frontal regions; as well as associations between genetic factors and neuroanatomical patterns.","Genetics,Diseases,Biological system modeling,Biomarkers,Sociology,Statistics,Brain modeling,Alzheimer's disease,MRI,genetics,topic modeling,mixed membership model,generative method",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,ATROPHY,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
90,Underwater laser micro-milling of fine-grained aluminium and the process modelling by machine learning,30,4,,"Feng Wenhe,Guo Jiang,Yan Wenjin,Wu Hu,Wan Yin Chi,Wang Xincai","Feng WH,Guo J,Yan WJ,Wu H,Wan YC,Wang XC",Guo J,10.1088/1361-6439/ab7322,Dalian University of Technology,"Nanosecond-pulsed laser ablation is often accompanied by adverse thermal effects, such as oxidation, debris recast and burr formation. To reduce these effects, in this paper, the authors present the underwater laser milling process using RSA-905 fine-grained aluminium as the target material for the first time. The results show that channels up to 200 mu m in width, 700 mu m depth and bottom roughness around 1 mu m R-a could be fabricated with reduced thermal effects. By conducting multi- and single-factor experiments, empirical models relating the laser processing parameters to the key dimensions of channels were derived using an artificial neural network algorithm and polynomial regression, and the models' accuracies were evaluated. Based on the models, the cross-section profile of a channel subject to a given set of processing parameters can be predicted. The process can serve as a pre-treatment technique in mechanical milling such that the tool life will be extended and the profile of a desired feature can be precisely defined.","underwater laser machining,channel fabrication,burr-free,regression analysis,machine learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Science & Technology - Other Topics,Instruments & Instrumentation,Physics",,1.952,"TITANIUM-ALLOY,ABLATION,FEATURES,WATER,NANOSECOND,SUBSTRATE,SILICON,AIR",JOURNAL OF MICROMECHANICS AND MICROENGINEERING,,
91,Plagiarism detection in students' programming assignments based on semantics: multimedia e-learning based smart assessment methodology,79,13-14,8581-8598,"Ullah Farhan,Wang Junfeng,Farhan Muhammad,Jabbar Sohail,Wu Zhiming,Khalid Shehzad","Ullah F,Wang JF,Farhan M,Jabbar S,Wu ZM,Khalid S",Wang JF,10.1007/s11042-018-5827-6,Sichuan University,"The multimedia-based e-Learning methodology provides virtual classrooms to students. The teacher uploads learning materials, programming assignments and quizzes on university' Learning Management System (LMS). The students learn lessons from uploaded videos and then solve the given programming tasks and quizzes. The source code plagiarism is a serious threat to academia. However, identifying similar source code fragments between different programming languages is a challenging task. To solve the problem, this paper proposed a new plagiarism detection technique between C++ and Java source codes based on semantics in multimedia-based e-Learning and smart assessment methodology. First, it transforms source codes into tokens to calculate semantic similarity in token by token comparison. After that, it finds semantic similarity in scalar value for the complete source codes written in C++ and Java. To analyse the experiment, we have taken the dataset consists of four (4) case studies of Factorial, Bubble Sort, Binary Search and Stack data structure in both C++ and Java. The entire experiment is done in R Studio with R version 3.4.2. The experimental results show better semantic similarity results for plagiarism detection based on comparison.","Latent Semantic Analysis,Semantic Similarity,Machine Learning,Multimedia,e-Learning,Smart Assessment",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,,MULTIMEDIA TOOLS AND APPLICATIONS,,
92,An ensemble shape gradient features descriptor based nodule detection paradigm: a novel model to augment complex diagnostic decisions assistance,79,13-14,8649-8675,"Jaffar M. Arfan,Zia M. Sultan,Hussain Majid,Siddiqui Abdul Basit,Akram Sheeraz,Jamil Uzma","Jaffar MA,Zia MS,Hussain M,Siddiqui AB,Akram S,Jamil U",Jaffar MA,10.1007/s11042-018-6092-4,Al-Imam Muhammad Ibn Saud Islamic University,"Primarily, there are three basic operational constituents of Nodule Detection Systems namely nodule candidate detection, classification of nodule and extraction of features. Thresholding is one of the most important factor for nodule detection. To segment the lungs and nodules, Gaussian approximation based Particle Swarm Optimization (PSO) is used to determine the optimal threshold value. After extracting lungs part, 2D and 3D region of interests (ROI's) are used to detect nodules with area and volume information of nodules and then distinguish between wall and vessels by using fuzzy C-mean. There are three key objects namely wall, nodule and vessel in the lugs volume with specific shape. Shape-based features with Histogram of Oriented Surface Normal Vectors (HOSNV) are used as a feature descriptor. A scaled and rotation invariant multi-coordinate histogram of thegradient is used to identify nodules with different sizes and directionless shapes. So, a Novel Ensemble Shape Gradient Features (NESGF) descriptor for pulmonary nodule classification is proposed using the Histogram of Oriented Surface Normal Vectors and Multi-Coordinate Histogram of Gradient descriptor. The random forest has been used to classify the nodules through intelligent usage of the ensemble concepts to learn weak classifiers. A standard benchmark database Lung Image Consortium Database (LICD) is used for testing and validation purposes. In order to show the performance of segmentation quality, the proposed model is compared through three quantitative measures inclusive of Variation of Information (VoI), Probabilistic Rand Index (PRI) and Jaccard Measure. The methods Area Under Curve, Sensitivity, Specificity and Sensitivity have are used for classification. For classification, accuracy, sensitivity, specificity and Area under curve (AUC) has been used.","Shape-based features,CT-scan imaging,Segmentation,Nodules detection,Particle swarm optimization,Random forest",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"LUNG,NODULES,AUTOMATIC,DETECTION,PULMONARY,NODULES,CANCER,STATISTICS,DETECTION,SYSTEM,CLASSIFICATION,SEGMENTATION,IMAGES",MULTIMEDIA TOOLS AND APPLICATIONS,,
93,Image registration optimization mechanism based on reinforcement learning and real time denoising,79,13-14,9489-9508,"Ke Jiangyan,Zhang Zhijie,Ye Yingze","Ke JY,Zhang ZJ,Ye YZ",Ke JY,10.1007/s11042-019-07914-5,Jimei University,"Image noise has a serious impact on image transmission, image data collection and image processing. Image noise is mainly denoised by additive noise and multiplicative noise. Firstly, based on the analysis that random noise has a direct impact on image recognition accuracy and registration performance, aiming at capturing and controlling the interaction between reinforcement learning agents and noise environment, an image recognition model based on noise stimulation is proposed, which will help capture and analyze random noise. Then, in order to construct a complete image data set and its linear combination of transfer process, a denoising algorithm based on reinforcement learning is proposed, which uses the sparse vector based on noise obtained by reinforcement learning to represent a given noise signal. Finally, based on image denoising based on reinforcement learning, an image registration optimization mechanism is proposed by maximizing the similarity measure between two images or minimizing the distance measure to find the coordinate correspondence between images. The simulation results show that the proposed algorithm is credible, effective and efficient in terms of consistency of noise analysis, accuracy of correspondence between feature points, registration error and computational utility of the algorithm.","Image characteristics,Image noise,Reinforcement learning,Denoise,Real time control",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,,MULTIMEDIA TOOLS AND APPLICATIONS,,
94,A machine-learning approach for classifying defects on tree trunks using terrestrial LiDAR,171,,,"Van-Tho Nguyen,Constant Thiery,Kerautret Bertrand,Debled-Rennesson Isabelle,Colin Francis","Nguyen VT,Constant T,Kerautret B,Debled-Rennesson I,Colin F",Nguyen VT,10.1016/j.compag.2020.105332,AgroParisTech,"Three-dimensional data are increasingly prevalent in forestry thanks to terrestrial LiDAR. This work assesses the feasibility for an automated recognition of the type of local defects present on the bark surface. These singularities are frequently external markers of inner defects affecting wood quality, and their type, size, and frequency are major components of grading rules. The proposed approach assigns previously detected abnormalities in the bark roughness to one of the defect types: branches, branch scars, epicormic shoots, burls, and smaller defects. Our machine learning approach is based on random forests using potential defects shape descriptors, including Hu invariant moments, dimensions, and species. The results of our experiments involving different French commercial species, oak, beech, fir, and pine showed that most defects were well classified with an average F-1 score of 0.86.","Roundwood quality,Random forests,Standing tree grading",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Agriculture,Computer Science",,5.494,"SCOTS,PINE,STANDING,TREES,CT,IMAGES,WOOD,CLASSIFICATION,ATTRIBUTES,QUALITY,BIOMASS,METRICS,SYSTEM",COMPUTERS AND ELECTRONICS IN AGRICULTURE,https://hal.archives-ouvertes.fr/hal-02931277/document,
95,Use of Stratified Cascade Learning to predict hospitalization risk with only socioeconomic factors,104,,,"Filikov Anton,Pethe Sayali,Kelley Robert,Fischer Anne,Ozminkowski Ron","Filikov A,Pethe S,Kelley R,Fischer A,Ozminkowski R",Filikov A,10.1016/j.jbi.2020.103393,"IBM Watson Hlth, 75 Binney St, Cambridge, MA 02142 USA.","Background and objective: Published models predicting health related outcomes rely on clinical, claims and social determinants of health (SDH) data. Addressing the challenge of predicting with only SDH we developed a novel framework termed Stratified Cascade Learning (SCL) and used it for predicting the risk of hospitalization (ROH).
Materials and methods: The variable set includes 27 SDH and ""age"" and ""sex"" for a cohort of diabetic patients. The SCL model uses three sub-models: SM1 (whole training set) stratifies training set into ""predictable"" and ""unpredictable"" subsets, SM2 (built on whole training set) classifies test set patients into ""predictable"" and ""unpredictable"", and SM3 (built on only the ""predictable"" subset) predicts the ROH for the patients classified as ""predictable"" by SM2.
Results: The SCL model does not improve either the AUC or the NPV of the basic classifier, but materially improves accuracy and specificity measures at the expense of lowering sensitivity for the ""predictable"" subset. Optimization of the risk thresholds of the sub-models does not noticeably change the AUC and NPV but further improves the accuracy and specificity at the expense of further lowering sensitivity.
Conclusion: Since the SLC model yields low sensitivity it fails to predict high risk patients. But it yields high specificity that can be useful when the objective is to eliminate low-risk patients as candidates for further testing or treatment. The use of the SCL is not limited to healthcare, it can be applied to any predictive modeling problem when reliable predictions can only be made for a fraction of incoming data.","Machine learning,Stratified cascade learning,Health care,Hospitalization risk,Social determinants of health",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Computer Science,Medical Informatics",,5.221,"READMISSION,MODELS",JOURNAL OF BIOMEDICAL INFORMATICS,https://doi.org/10.1016/j.jbi.2020.103393,
96,Optimal feedback control of batch self-assembly processes using dynamic programming,88,,32-42,"Grover Martha A.,Griffin Daniel J.,Tang Xun,Kim Youngjo,Rousseau Ronald W.","Grover MA,Griffin DJ,Tang X,Kim Y,Rousseau RW",Grover MA,10.1016/j.jprocont.2020.01.013,University System of Georgia,"This paper reviews a previously-reported methodology for establishing feedback control of self-assembly. The methodology combines dimension reduction, supervised learning, and dynamic programming to obtain an optimal feedback control policy for reaching a desired assembled state. Sampled data are used in calculating the optimal feedback policy; this data can be generated using a predictive model (i.e. ""simulated data"") or using experimental data. The control strategy is demonstrated, with both simulation and experimental results, for two applications: control of colloidal assembly (to produce perfect colloidal crystals) and control of crystallization from solution (to produce crystals of desired average size). (C) 2020 Elsevier Ltd. All rights reserved.","Dynamic programming,Markov decision processes,Closed-loop control,Reduced-order models,Learning",Article; Proceedings Paper,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Automation & Control Systems,Engineering",,,"PARTICLE-SIZE,DISTRIBUTION,MODEL-PREDICTIVE,CONTROL,CHORD,LENGTH,MEASUREMENTS,MARKOV,STATE,MODELS,SHAPE,EVOLUTION,DISTRIBUTIONS,NUCLEATION,STRATEGIES",JOURNAL OF PROCESS CONTROL,,
97,Prognosis Analysis of Heart Failure Based on Recurrent Attention Model,41,2,71-79,"Gong J.);,Bai X.);,Li D-a);,Zhao J.);,Li X.","Gong J,Bai X,Li DA,Zhao J,Li X",,10.1016/j.irbm.2019.08.002,,"Objectives: Heart failure is a group of complex clinical syndromes that lead to ventricular filling or impaired ejection ability due to abnormal heart structure or function. Difficult treatment, poor prognosis and high mortality are the main characteristics of heart failure. According to admission data and past medical use, the 30-day mortality rate of patients with heart failure was obtained and the main characteristics affecting the 30-day mortality of patients with heart failure were determined.
Material and methods: Based on the data of April 2016 to July 2018 of Shanxi Acadeny of Medical Sciences, and we chose 4,682 information on heart failure patients, of which 539 died in the hospital by screening. We built a 30-day mortality prediction model for patients with heart failure. The model can fuse clinical data and text data through multiple kernel learning, and input the fused data into the recurrent attention model. It can not only predict the 30-day mortality of patients with heart failure, but also the influencing factors of prognosis of patients with heart failure were also obtained.
Results: The prediction accuracy of the recurrent attention network is obviously higher than that of other machine learning models, and the accuracy rate reaches 93.4%. The AUC value of the area under the ROC curve of the model reaches 87%, which is obviously higher than that of the traditional machine learning models such as decision tree, naive Bayesian and support vector machine. In addition, the model can also reach a conclusion that New York heart function classification, age, NT-ProBNP, LVEF, beta-blockers, ventricular arrhythmia, high blood pressure, coronary heart disease (CHD) and bronchitis were independent risk factors for death. And patients with revascularization, ACEI/ARB drugs, beta-blockers, spironolactone have a better prognosis than non-users. This provides an important reference for doctors to better treat and manage patients with heart failure.
Conclusion: Experiments show that the prognostic effect of the recurrent attention model is significantly higher than that of other traditional machine learning models. Because the model increases the attention mechanism, the important features affecting the prognostic results are obtained, which enables doctors to prescribe drugs according to the symptoms, take timely precautions and help patients to treat in time. (C) 2019 Published by Elsevier Masson SAS on behalf of AGBM.","Heart failure,Recurrent attention model,Prognosis",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA",Engineering,,1.483,"READMISSION,DIAGNOSIS",IRBM,,
98,Decoding rejuvenating effects of mechanical loading on skeletal aging using in vivo mu CT imaging and deep learning,106,,193-207,"Asgharzadeh Pouyan,Roehrle Oliver,Willie Bettina M.,Birkhold Annette I","Asgharzadeh P,Rohrle O,Willie BM,Birkhold AI",Asgharzadeh P,10.1016/j.actbio.2020.02.007,University of Stuttgart,"Throughout the process of aging, dynamic changes of bone material, micro- and macro-architecture result in a loss of strength and therefore in an increased likelihood of fragility fractures. To date, precise contributions of age-related changes in bone (re)modeling and (de)mineralization dynamics to this fragility increase are not completely understood. Here, we present an image-based deep learning approach to quantitatively describe the effects of short-term aging and adaptive response to cyclic loading applied to proximal mouse tibiae and fibulae. Our approach allowed us to perform an end-to-end age prediction based on mu CT imaging to determine the dynamic biological process of aging during a two week period, therefore permitting short-term bone aging analysis with 95% accuracy in predicting time points. In a second application, our deep learning analysis reveals that two weeks of in vivo mechanical loading are associated with an underlying rejuvenating effect of 5 days. Additionally, by quantitatively analyzing the learning process, we could, for the first time, identify the localization of the age-relevant encoded information and demonstrate 89% load-induced similarity of these locations in the loaded tibia with younger control bones. These data therefore suggest that our method enables identifying a general prognostic phenotype of a certain skeletal age as well as a temporal and localized loading-treatment effect on this apparent skeletal age for the studied mouse tibia and fibula. Future translational applications of this method may provide an improved decision-support method for osteoporosis treatment at relatively low cost.
Statement of Significance
Bone is a highly complex and dynamic structure that undergoes changes during the course of aging as well as in response to external stimuli, such as loading. Automatic assessment of ""age"" and ""state"" of the bone may lead to early prognosis of deceases such as osteoporosis and enables evaluating the effects of certain treatments. Here, we present an artificial intelligence-based method capable of automatically predicting the skeletal age from mu CT images with 95% accuracy. Additionally, we utilize it to demonstrate the rejuvenation effects of in-vivo loading treatment on bones. We further, for the first time, break down aging-related local changes in bone by quantitatively analyzing ""what the age assessment model has learned"" and use this information to investigate the structural details of rejuvenation process. (C) 2020 Acta Materialia Inc. Published by Elsevier Ltd. All rights reserved.","Bone,Aging,Rejuvenation effect,Machine learning,Deep neural network",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Materials Science",,,"BONE-MINERAL,DENSITY,AGE-RELATED-CHANGES,CORTICAL,BONE,TRABECULAR,ARCHITECTURE,FUNCTIONAL,ADAPTATION,MICROARCHITECTURE,FRACTURE,STRENGTH,C57BL%2F6,SURFACE",ACTA BIOMATERIALIA,http://arxiv.org/pdf/1905.08099,
99,Physical exertion modeling for construction tasks using combined cardiorespiratory and thermoregulatory measures,112,,,"Umer Waleed,Heng Li,Yu Yantao,Antwi-Afari Maxwell Fordjour,Anwer Shahnawaz,Luo Xiaochun","Umer W,Heng L,Yu YT,Antwi-Afari MF,Anwer S,Luo XC",Umer W,10.1016/j.autcon.2020.103079,King Fahd University of Petroleum & Minerals,"Physical exertion led fatigue is a serious threat to occupational health and safety of construction workers worldwide. Its acute effects include a decrease in cognitive abilities, productivity and heightened risk of accidents whereas prolonged physical exertion led fatigue could lead to psychological issues and development of musculoskeletal disorders. To monitor physical exertion, traditionally questionnaires have been used while recent advances have focused on onsite and on-body sensors to automate the process. Considering the limitation of the recent approaches, this study explored the use of combined cardiorespiratory and thermoregulatory measures to model physical exertion using machine learning algorithms. Controlled manual material handling experiments were conducted during a preliminary study to induce exertion at a steady rate involving ten participants. The results revealed that the proposed methodology could predict exertion levels with a high accuracy of 95.3% for combined data modeling of all participants. However, for some predictions, the error between predicted and actual exertion was up to five levels on the Borg-20 scale. To mitigate this issue, individualized machine learning models were used that effectively reduced the maximum error to one level with an average accuracy of 96.7% while using only one-tenth of the total data set. Overall, this study highlights the advantage of using multiple physiological measures for enhancing physical exertion modeling. Notably, the study underpins the use of individualized models for exertion monitoring and management to prevent physical fatigue development and its ill effects.","Construction labor,Physical demands,Health and safety,Machine learning,Physiological monitoring",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Construction & Building Technology,Engineering",,8.0,"PSYCHOLOGICAL,STRESS,BODY-TEMPERATURE,RESPIRATORY,FREQUENCY,AUTOMATED,DETECTION,EXERCISE,INTENSITY,WEARABLE,SENSORS,FATIGUE,WORKERS,CLASSIFICATION,TIME",AUTOMATION IN CONSTRUCTION,,
100,Classification of Volumetric Images Using Multi-Instance Learning and Extreme Value Theorem,39,4,854-865,"Tennakoon Ruwan,Bortsova Gerda,Orting Silas,Gostar Amirali K.,Wille Mathilde M. W.,Saghir Zaigham,Hoseinnezhad Reza,de Bruijne Marleen,Bab-Hadiashar Alireza","Tennakoon R,Bortsova G,Orting S,Gostar AK,Wille MMW,Saghir Z,Hoseinnezhad R,de Bruijne M,Bab-Hadiashar A",Tennakoon R,10.1109/TMI.2019.2936244,Royal Melbourne Institute of Technology (RMIT),"Volumetric imaging is an essential diagnostic tool for medical practitioners. The use of popular techniques such as convolutional neural networks (CNN) for analysis of volumetric images is constrained by the availability of detailed (with local annotations) training data and GPU memory. In this paper, the volumetric image classification problem is posed as a multi-instance classification problem and a novel method is proposed to adaptively select positive instances from positive bags during the training phase. This method uses the extreme value theory to model the feature distribution of the images without a pathology and use it to identify positive instances of an imaged pathology. The experimental results, on three separate image classification tasks (i.e. classify retinal OCT images according to the presence or absence of fluid build-ups, emphysema detection in pulmonary 3D-CT images and detection of cancerous regions in 2D histopathology images) show that the proposed method produces classifiers that have similar performance to fully supervised methods and achieves the state of the art performance in all examined test cases.","Multiple instance learning,weakly supervised learning,CNN,OCT,CT,Macular Edema,emphysema,COPD",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,CT,IEEE TRANSACTIONS ON MEDICAL IMAGING,https://rmit-researchmanagement.esploro.exlibrisgroup.com/view/delivery/61RMIT_INST/12254548340001341/13256830080001341,
