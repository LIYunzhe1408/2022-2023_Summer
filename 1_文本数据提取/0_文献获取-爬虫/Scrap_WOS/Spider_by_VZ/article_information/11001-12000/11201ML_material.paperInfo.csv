,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,A data-driven surrogate to image-based flow simulations in porous media,201,,,"Takbiri-Borujeni Ali,Kazemi Hadi,Nasrabadi Nasser","Takbiri-Borujeni A,Kazemi H,Nasrabadi N",Takbiri-Borujeni A,10.1016/j.compfluid.2020.104475,West Virginia University,"The objective for this work is to develop a data-driven surrogate to high-fidelity numerical flow simulations using digital images of porous media. The proposed model can capture the pixel-scale velocity vectors in a large verity of digital porous media created by random two-dimensional (2D) circle packs. To develop the model, images of the 2D media (binary images of solid grains and void spaces) along with their corresponding velocity vectors at the pixel level computed using lattice Boltzmann simulation runs are used to train and to predict the solutions with a high accuracy in much less computational time. The velocity vector predictions made by the surrogate models are used to compute the permeability tensor for samples that have not been used in the training. The results show high accuracy in the prediction of both velocity vectors and permeability tensors. The proposed methodology harness the enormous amount of generated data from high-fidelity flow simulations to decode the often under-utilized patterns in simulations and to accurately predict solutions to new cases. The developed model can truly capture the physics of the problem and enhance the prediction capabilities of the simulations at a much lower cost. These predictive models, in essence, do not spatially reduce the order of the problem. They, however, possess the same numerical resolutions as their Lattice Boltzmann simulations equivalents do with the great advantage that their solutions can be achieved by a significant reduction in computational costs (speed and memory). (C) 2020 Elsevier Ltd. All rights reserved.","Lattice Boltzmann simulations,Porous media,Machine learning,Data-driven models,Deep learning,Convolutional neural networks",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Mechanics",,3.144,"LATTICE-BOLTZMANN,PACKS,GEOMETRIES,NETWORKS,MODELS",COMPUTERS & FLUIDS,,
2,Bayesian-based probabilistic fatigue crack growth evaluation combined with machine-learning-assisted GPR,229,,,"Hu Dianyin,Su Xiao,Liu Xi,Mao Jianxing,Shan Xiaoming,Wang Rongqiao","Hu DY,Su X,Liu X,Mao JX,Shan XM,Wang RQ",Mao JX,10.1016/j.engfracmech.2020.106933,Beihang University,"This paper presents a Bayesian-based calibration method that simultaneously improves the model accuracy and the computational efficiency for fatigue crack growth (FCG) life prediction on turbine discs. Uncertainties derived from geometry, material and models are elaborately quantified based on the data from measurements and experiments. A Bayesian approach is used for uncertainty quantification, where Markov Chain Monte Carlo algorithm is employed to estimate posterior distributions. Gaussian process regression (GPR) is introduced to describe the propagation of uncertainties and improve the efficiency in high-dimensional analysis. With the integrated methodology, uncertainties are embodied in life prediction results of a whole turbine disc. A full-scale spin test is carried out under low cycle fatigue loading, where three effective crack samples are generated and monitored. Compared with the experimental results, the mean values of the predictions are bounded within a factor of +/- 2.0, validating the potential usage of the proposed method in the probabilistic FCG life assessment.","Bayesian method,Uncertainty quantification,Fatigue crack growth,Full-scale experiment,Gaussian process regression",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Mechanics,,4.243,"INITIAL,FLAW,SIZE,LIFE,PREDICTION,UNCERTAINTY,FRACTURE,SUPERALLOY,INFERENCE,GH4169",ENGINEERING FRACTURE MECHANICS,,
3,Classification of solid fuels with machine learning,266,,,"Elmaz Furkan,Buyukcakir Barkin,Yucel Ozgun,Mutlu Ali Yener","Elmaz F,Buyukcakir B,Yucel O,Mutlu AY",Yucel O,10.1016/j.fuel.2020.117066,Gebze Technical University,"In energy applications, fuels are processed in various ways according to their types. Experiments conducted with non-optimal processing procedures cause waste of the materials and may lead to inaccurate conclusions. Moreover, classifying the fuel material becomes harder when the material is already processed or collected from an environment that makes it difficult to discern. Thus, with the constantly developing and diversifying energy applications, the need for a framework that can classify solid fuels is increased. In this study, we used machine learning based approach to classify fuels with the use of proximate analysis results, i.e., fixed carbon, volatile matter and ash contents. We collected a data set from the literature and group them into four classes, i.e., coals, woods, agricultural residue and manufactured biomass. Then, K-nearest neighbor, support vector machine and random forest machine learning classifiers are employed to develop prediction models. Furthermore, hierarchical classification approach is taken to combine each classifier's advantages with integration of expert opinion to create a complete and highly accurate classifier framework which can classify an unknown fuel into one of the four categories. K-fold cross validation is used to evaluate classifiers' performances in unbiased manner. With hierarchical classifier, % 96 and %92 classification accuracy is achieved for training and testing phases, respectively. Source code of the proposed hierarchical classifier framework is also provided.","Solid fuel classification,Proximate analysis,Hierarchical classification,Support vector machines,K-nearest neighbors,Random forests",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Energy & Fuels,Engineering",,6.63,"HIGHER,HEATING,VALUE,SUPPORT,VECTOR,MACHINE,PROXIMATE,ANALYSIS,K-FOLD,GAS-CHROMATOGRAPHY,CALORIFIC,VALUE,BIOMASS,WASTES,COALS,HHV",FUEL,,
4,Predicting the effect of bed materials in bubbling fluidized bed gasification using artificial neural networks (ANNs) modeling approach,266,,,"Serrano Daniel,Golpour Iman,Sanchez-Delgado Sergio","Serrano D,Golpour I,Sanchez-Delgado S",Serrano D,10.1016/j.fuel.2020.117021,"Carlos III Univ Madrid, Thermal & Fluid Engn Dept, Energy Syst Engn Res Grp, Madrid, Spain.","The effect of different bed materials was included a as new input into an artificial neural network model to predict the gas composition (CO2, CO, CH(4 )and H-2) and gas yield of a biomass gasification process in a bubbling fluidized bed. Feed and cascade forward back propagation networks with one and two hidden layers and with Levenberg-Marquardt and Bayesian Regulation learning algorithms were employed for the training of the networks. A high number of network topologies were simulated to determine the best configuration. It was observed that the developed models are able to predict the CO2, CO, CH4, H-2 and gas yield with good accuracy (R-2 > 0.94 and MSE < 1.7 x 10(-3)). The results obtained indicate that this approach is a powerful tool to help in the efficient design, operation and control of bubbling fluidized bed gasifiers working with different operating conditions, including the effect of the bed material.","Gasification,Bubbling fluidized bed,Artificial neural network",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Energy & Fuels,Engineering",,,"AIR-STEAM,GASIFICATION,HYDROGEN-RICH,GAS,BIOMASS,GASIFICATION,TAR,PERFORMANCE,DOLOMITE,OLIVINE,OPTIMIZATION,SIMULATION,PYROLYSIS",FUEL,,
5,Crack characterization in ferromagnetic steels by pulsed eddy current technique based on GA-BP neural network model,500,,,"Wang Zhenwei,Fei Yuan,Ye Pengxin,Qiu Fasheng,Tian Guiyun,Woo Wai Lok","Wang ZW,Fei Y,Ye PX,Qiu FS,Tian GY,Woo WL",Wang ZW,10.1016/j.jmmm.2020.166412,University of Electronic Science & Technology of China,"Ferromagnetic steels are widely used in engineering structures such as rail track, oil/gas pipeline and steel hanging bridge. Cracks resulted from manufacturing processes or previous loading will seriously undermine the safety of the engineering structures and even lead to catastrophic industrial accidents. Accurate and quantitative characterization the cracks in ferromagnetic steels are therefore of vital importance. In this paper, the cracks in ferromagnetic steels are detected by the pulsed eddy current (PEC) technique. Firstly, the physical mechanism of the relative magnetic permeability of the ferromagnetic steel on the detection signal of PEC is interpreted from a microscopic level of magnetic domain wall movement. The relationship of the crack width/depth and the detection signal of PEC is then investigated and verified by numerical simulations and experimental study. Finally, the cracks are inversely characterized by using Genetic Algorithm (GA) based Back-Propagation (BP) neural network (NN) considering the nonlinearity of the crack geometric parameters with the detection signal of PEC. The prediction results indicated that the proposed algorithm can characterize the crack depth and width within the relative error of 10%. The proposed approach combining PEC and GA based BPNN has been verified to quantitatively detect cracks in ferromagnetic steel.","Ferromagnetic steels,Pulsed eddy current (PEC) technique,Crack,GA based BP neural network,Magnetic domain wall",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Materials Science,Physics",,2.836,"SENSOR,SIGNAL",JOURNAL OF MAGNETISM AND MAGNETIC MATERIALS,,
6,The Materials Simulation Toolkit for Machine learning (MAST-ML): An automated open source toolkit to accelerate data-driven materials research,176,,,"Jacobs Ryan,Mayeshiba Tam,Afflerbach Ben,Miles Luke,Williams Max,Turner Matthew,Finkel Raphael,Morgan Dane","Jacobs R,Mayeshiba T,Afflerbach B,Miles L,Williams M,Turner M,Finkel R,Morgan D",Jacobs R,10.1016/j.commatsci.2020.109544,University of Wisconsin System,"As data science and machine learning methods are taking on an increasingly important role in the materials research community, there is a need for the development of machine learning software tools that are easy to use (even for nonexperts with no programming ability), provide flexible access to the most important algorithms, and codify best practices of machine learning model development and evaluation. Here, we introduce the Materials Simulation Toolkit for Machine Learning (MAST-ML), an open source Python-based software package designed to broaden and accelerate the use of machine learning in materials science research. MAST-ML provides predefined routines for many input setup, model fitting, and post-analysis tasks, as well as a simple structure for executing a multi-step machine learning model workflow. In this paper, we describe how MAST-ML is used to streamline and accelerate the execution of machine learning problems. We walk through how to acquire and run MAST-ML, demonstrate how to execute different components of a supervised machine learning workflow via a customized input file, and showcase a number of features and analyses conducted automatically during a MAST-ML run. Further, we demonstrate the utility of MAST-ML by showcasing examples of recent materials informatics studies which used MAST-ML to formulate and evaluate various machine learning models for an array of materials applications. Finally, we lay out a vision of how MAST-ML, together with complementary software packages and emerging cyberinfrastructure, can advance the rapidly growing field of materials informatics, with a focus on producing machine learning models easily, reproducibly, and in a manner that facilitates model evolution and improvement in the future.","Machine learning,Materials informatics,Data science,Open source software",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"PREDICTIONS,ROBUST",COMPUTATIONAL MATERIALS SCIENCE,http://arxiv.org/pdf/1910.06291,
7,Accelerating the development of multi-component Cu-Al-based shape memory alloys with high elastocaloric property by machine learning,176,,,"Zhao Xin-Peng,Huang Hai-You,Wen Cheng,Su Yan-Jing,Qian Ping","Zhao XP,Huang HY,Wen C,Su YJ,Qian P",Huang HY,10.1016/j.commatsci.2020.109521,University of Science & Technology Beijing,"Exploring elastocaloric materials with high transformation entropy change (Delta S) is a key mission for the development of elastocaloric refrigeration technology. Here, we show an adaptive design strategy, tightly coupled a machine learning (ML) with theoretical calculations to accelerate the discovery process of multi-component CuAl-based shape memory alloys (SMAs) with high Delta S. Based on a linear regression model, Al, Co, Fe, Ni are the elements that are beneficial to the significant promotion of Delta S in the Cu-Al-based alloys. In our results, Cu72.2Al20.2Ni6.2Co0.7B0.7 is discovered with the highest Delta S of 1.88 J/mol K from a potential space of similar to 500,000 compositions, which is higher than the highest ones found in ternary Cu-Al-Mn and reported experimental value by 9.9% and 17.5%.","Shape memory alloy,Machine learning,Elastocaloric effect,Entropy",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"TRANSFORMATION,TEMPERATURES,LATTICE-VIBRATIONS,SITE,PREFERENCE,DAMPING,PROPERTIES,TI,SIMULATION,SEARCH,SYSTEM,CR",COMPUTATIONAL MATERIALS SCIENCE,,
8,Intelligent traffic control for autonomous vehicle systems based on machine learning,144,,,"Lee Sangmin,Kim Younghoon,Kahng Hyungu,Lee Soon-Kyo,Chung Seokhyun,Cheong Taesu,Shin Keeyong,Park Jeehyuk,Kim Seoung Bum","Lee S,Kim Y,Kahng H,Lee SK,Chung S,Cheong T,Shin K,Park J,Kim SB",Kim SB,10.1016/j.eswa.2019.113074,Korea University,"This study aimed to resolve a real-world traffic problem in a large-scale plant. Autonomous vehicle systems (AVSs), which are designed to use multiple vehicles to transfer materials, are widely used to transfer wafers in semiconductor manufacturing. Traffic control is a significant challenge with AVSs because all vehicles must be monitored and controlled in real time, to cope with uncertainties such as congestion. However, existing traffic control systems, which are primarily designed and controlled by human experts, are insufficient to prevent heavy congestion that impedes production. In this study, we developed a traffic control system based on machine learning predictions, and a routing method that dynamically determines AVS routes with reduced congestion rates. We predicted congestion for critical bottleneck areas, and utilized the predictions for adaptive routing control of all vehicles to avoid congestion. We conducted an experimental evaluation to compare the predictive performance of four popular algorithms. We performed a simulation study based on data from semiconductor fabrication to demonstrate the utility and superiority of the proposed method. The experimental results showed that AVSs with the proposed approach outperformed the existing approach in terms of delivery time, transfer time, and queuing time. We found that adopting machine learning-based traffic control can enhance the performance of existing AVSs and reduce the burden on the human experts who monitor and control AVSs. (C) 2019 Elsevier Ltd. All rights reserved.","Intelligent traffic control,Machine learning,Autonomous vehicle systems,Vehicle routing",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"MATERIAL,HANDLING-SYSTEM,SEQUENTIAL,DETECTION,OPTIMIZATION,METHOD,ROUTING,PROBLEM,CONGESTION,DESIGN,HEURISTICS,SIMULATION,MANAGEMENT,ALGORITHM",EXPERT SYSTEMS WITH APPLICATIONS,,
9,,,,,,,,,,,,,,,,,,,,
10,Machine Learning-Driven Insights into Defects of Zirconium Metal- Organic Frameworks for Enhanced Ethane-Ethylene Separation,32,7,2986-2997,"Wu Ying,Duan Haipeng,Xi Hongxia","Wu Y,Duan HP,Xi HX",Wu Y; Xi HX,10.1021/acs.chemmater.9b05322,South China University of Technology,"Structural defects in metal-organic frameworks (MOFs) have the potential to yield desirable properties that could not be achieved by ""defect-free"" crystals, but previous works in this area have focused on limited versions of defects due to the difficulty of detecting defects in MOFs. In this work, a modeling library containing 425 defective UiO-66 (UiO-66-Ds) with a comprehensive population (in terms of concentration and distribution) of missing-linker defects was created. Taking ethane-ethylene separation as a case study, we demonstrated that machine learning could provide data-driven insight into how the defects control the performance of UiO-66-Ds in adsorption, separation, and mechanical stability. We found that the missing-linker ratio in real materials could be predicted from the gravimetric surface area and pore volume, making it a useful complement for the challenges of directly measuring the defect concentration. We further identified the ""privileged"" UiO-66-Ds that were optimal in overall properties and provided decision trees as guidance to access and design these top performers. This work offers a general strategy for fully exploring the defects in MOFs, providing long-term opportunities for the development of defect engineering in the adsorption community.","MECHANICAL STABILITY,MOLECULAR SIMULATION,LINKER DEFECTS,FORCE-FIELD,UIO-66,ADSORPTION,ACID,CO2,PREDICTION,PRESSURE",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Materials Science",,10.837,"MECHANICAL,STABILITY,MOLECULAR,SIMULATION,LINKER,DEFECTS,FORCE-FIELD,UIO-66,ADSORPTION,ACID,CO2,PREDICTION,PRESSURE",CHEMISTRY OF MATERIALS,,
11,Machine Learning Accelerated Recovery of the Cubic Structure in Mixed-Cation Perovskite Thin Films,32,7,2998-3006,"Ali Adnan,Park Heesoo,Mall Raghvendra,Aissa Brahim,Sanvito Stefano,Bensmail Halima,Belaidi Abdelhak,El-Mellouhi Fedwa","Ali A,Park H,Mall R,Aissa B,Sanvito S,Bensmail H,Belaidi A,El-Mellouhi F",El-Mellouhi F,10.1021/acs.chemmater.9b05342,Hamad Bin Khalifa University-Qatar,"Data-driven approaches for materials design and selection have accelerated materials discovery along with the upsurge of machine learning applications. We report here a prediction-to-lab-scale synthesis of cubic phase triple-cation lead halide perovskites guided by a machine learning perovskite stability predictor. The starting double-cation perovskite resulting from the incorporation of 15% dimethylammonium (DMA) in methyl-ammonium lead triiodide suffers from significant deviation from the perovskite structure. By analyzing the X-ray diffraction and scanning electron microscopy, we confirmed that it is possible to recover the perovskite structure with the cubic phase at room temperature (RT) while minimizing the iterations of trial-and-error by adding <10 mol % of cesium cation additives, as guided by the machine learning predictor. Our conclusions highly support the cubic-phase stabilization at RT by controlling the stoichiometric ratio of various sized cations. This prediction-to-lab-scale synthesis approach also enables us to identify room for improvements of the current machine learning predictor to take into consideration the cubic phase stability as well as phase segregation.","SOLAR-CELLS,STABILITY,ENHANCEMENT,INCREASE,CRYSTAL",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Materials Science",,10.837,"SOLAR-CELLS,STABILITY,ENHANCEMENT,INCREASE,CRYSTAL",CHEMISTRY OF MATERIALS,,
12,Multimodal recognition of pain intensity and pain modality with machine learning,34,5,400-409,"Walter S.,Al-Hamadi A.,Gruss S.,Frisch S.,Traue H. C.,Werner P.","Walter S,Al-Hamadi A,Gruss S,Frisch S,Traue HC,Werner P",Walter S,10.1007/s00482-020-00468-8,Ulm University,"Background The objective recording of subjectively experienced pain is a problem that has not been sufficiently solved to date. In recent years, data sets have been created to train artificial intelligence algorithms to recognize patterns of pain intensity. The multimodal recognition of pain with machine learning could provide a way to reduce an over- or undersupply of analgesics, explicitly in patients with limited communication skills. Objectives This study investigated the methodology of automated multimodal recognition of pain intensity and modality using machine-learning techniques of artificial intelligence. Multimodal recognition rates of experimentally induced phasic electrical and heat pain stimuli were compared with uni- and bimodal recognition rates. Material and methods On the basis of the X-ITE Pain Database, healthy subjects were stimulated with phasic electro-induced pain and heat pain, and their corresponding pain responses were recorded with multimodal sensors (acoustic, video-based, physiological). After complex signal processing, machine-learning methods were used to calculate recognition rates with respect to pain intensity (baseline vs. pain threshold, pain tolerance, mean value of pain threshold and tolerance) and pain modality (electrical vs. heat). Finally, a statistical comparison of uni- vs. multimodal and bi- vs. multimodal detection rates was performed. Results With few exceptions, multimodal recognition of pain intensity rates was statistically superior to unimodal recognition rates, regardless of the pain modality. Multimodal pain recognition distinguished significantly better between heat and electro-induced pain. Further, multimodal recognition rates were predominantly superior to bimodal recognition rates. Conclusion Priority should be given to the multimodal approach to the recognition of pain intensity and modality compared with unimodality. Further clinical studies should clarify whether multimodal automated recognition of pain intensity and modality is in fact superior to bimodal recognition.","Automated pain recognition,Machine learning,Artificial intelligence,Multimodality,Fusion algorithms",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Anesthesiology,Neurosciences & Neurology",,1.382,,SCHMERZ,,
13,Inverse methods for design of soft materials,152,14,,"Sherman Zachary M.,Howard Michael P.,Lindquist Beth A.,Jadrich Ryan B.,Truskett Thomas M.","Sherman ZM,Howard MP,Lindquist BA,Jadrich RB,Truskett TM",Truskett TM,10.1063/1.5145177,University of Texas System,"Functional soft materials, comprising colloidal and molecular building blocks that self-organize into complex structures as a result of their tunable interactions, enable a wide array of technological applications. Inverse methods provide a systematic means for navigating their inherently high-dimensional design spaces to create materials with targeted properties. While multiple physically motivated inverse strategies have been successfully implemented in silico, their translation to guiding experimental materials discovery has thus far been limited to a handful of proof-of-concept studies. In this perspective, we discuss recent advances in inverse methods for design of soft materials that address two challenges: (1) methodological limitations that prevent such approaches from satisfying design constraints and (2) computational challenges that limit the size and complexity of systems that can be addressed. Strategies that leverage machine learning have proven particularly effective, including methods to discover order parameters that characterize complex structural motifs and schemes to efficiently compute macroscopic properties from the underlying structure. We also highlight promising opportunities to improve the experimental realizability of materials designed computationally, including discovery of materials with functionality at multiple thermodynamic states, design of externally directed assembly protocols that are simple to implement in experiments, and strategies to improve the accuracy and computational efficiency of experimentally relevant models.","STRUCTURE-PROPERTY LINKAGES,SELF-ASSEMBLY PATHWAYS,TOPOGRAPHICAL TEMPLATES,CAPILLARY MIGRATION,BLOCK-COPOLYMERS,LOCAL-STRUCTURE,ORDER,OPTIMIZATION,IDENTIFICATION,FABRICATION",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Chemistry,Physics",,3.166,"STRUCTURE-PROPERTY,LINKAGES,SELF-ASSEMBLY,PATHWAYS,TOPOGRAPHICAL,TEMPLATES,CAPILLARY,MIGRATION,BLOCK-COPOLYMERS,LOCAL-STRUCTURE,ORDER,OPTIMIZATION,IDENTIFICATION,FABRICATION",JOURNAL OF CHEMICAL PHYSICS,https://aip.scitation.org/doi/pdf/10.1063/1.5145177,
14,Severity detection tool for patients with infectious disease,7,2,45-50,"Tadesse Girmaw Abebe,Zhu Tingting,Nhan Le Nguyen Thanh,Nguyen Thanh Hung,Ha Thi Hai Duong,Truong Huu Khanh,Pham Van Quang,Duc Duong Tran,Lam Minh Yen,Van Doorn Rogier","Tadesse GA,Zhu TT,Thanh NLN,Hung NT,Duong HTH,Khanh TH,Quang PV,Tran DD,Yen LM,Van Doorn R",Tadesse GA,10.1049/htl.2019.0030,University of Oxford,"Hand foot and mouth disease (HFMD) and tetanus are serious infectious diseases in low- and middle-income countries. Tetanus, in particular, has a high mortality rate and its treatment is resource-demanding. Furthermore, HFMD often affects a large number of infants and young children. As a result, its treatment consumes enormous healthcare resources, especially when outbreaks occur. Autonomic nervous system dysfunction (ANSD) is the main cause of death for both HFMD and tetanus patients. However, early detection of ANSD is a difficult and challenging problem. The authors aim to provide a proof-of-principle to detect the ANSD level automatically by applying machine learning techniques to physiological patient data, such as electrocardiogram waveforms, which can be collected using low-cost wearable sensors. Efficient features are extracted that encode variations in the waveforms in the time and frequency domains. The proposed approach is validated on multiple datasets of HFMD and tetanus patients in Vietnam. Results show that encouraging performance is achieved. Moreover, the proposed features are simple, more generalisable and outperformed the standard heart rate variability analysis. The proposed approach would facilitate both the diagnosis and treatment of infectious diseases in low- and middle-income countries, and thereby improve patient care.","support vector machines,cardiology,electrocardiography,patient care,neurophysiology,patient diagnosis,diseases,learning (artificial intelligence),patient treatment,medical signal processing,medical computing,health care,feature extraction,severity detection tool,infectious disease,HFMD,serious infectious diseases,middle-income countries,high mortality rate,resource-demanding,young children,enormous healthcare resources,autonomic nervous system dysfunction,tetanus patients,difficult problem,proof-of-principle,ANSD level,physiological patient data,electrocardiogram,photoplethysmogram waveforms,low-cost wearable sensors,frequency domains,support vector machine,classifying ANSD levels,standard heart rate variability analysis,patient care",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Engineering,,,"HEART-RATE-VARIABILITY,NEONATAL,TETANUS,FEATURES",HEALTHCARE TECHNOLOGY LETTERS,https://ora.ox.ac.uk/objects/uuid:c8db26b6-e5c0-4676-bf9c-cd8b07b94711/download_file?safe_filename=TadesseetalVoR2020.pdf&type_of_work=Journal+article,
15,Learning to Use the Force: Fitting Repulsive Potentials in Density-Functional Tight-Binding with Gaussian Process Regression,16,4,2181-2191,"Panosetti Chiara,Engelmann Artur,Nemec Lydia,Reuter Karsten,Margraf Johannes T.","Panosetti C,Engelmann A,Nemec L,Reuter K,Margraf JT",Margraf JT,10.1021/acs.jctc.9b00975,Technical University of Munich,"The Density-Functional Tight Binding (DFTB) method is a popular semiempirical approximation to Density Functional Theory (DFT). In many cases, DFTB can provide comparable accuracy to DFT at a fraction of the cost, enabling simulations on length and time scales that are unfeasible with first-principles DFT. At the same time (and in contrast to empirical interatomic potentials and force fields), DFTB still offers direct access to electronic properties such as the band structure. These advantages come at the cost of introducing empirical parameters to the method, leading to a reduced transferability compared to true first-principle approaches. Consequently, it would be very useful if the parameter sets could be routinely adjusted for a given project. While fairly robust and transferable parametrization workflows exist for the electronic structure part of DFTB, the so-called repulsive potential V(rep )poses a major challenge. In this paper, we propose a machine-learning (ML) approach to fitting V-rep, using Gaussian Process Regression (GPR) to reconstruct V-rep with DFT- DFTB force residues as training data. The use of GPR circumvents the need for nonlinear or global parameter optimization, while at the same time offering arbitrary flexibility in terms of the functional form. We also show that the proposed method can be applied to multiple elements at once, by fitting repulsive potentials for organic molecules containing carbon, hydrogen, and oxygen. Overall, the new approach removes focus from the choice of functional form and parametrization procedure, in favor of a data-driven philosophy.","ENERGY SURFACES,COMPLEX MATERIALS,DFTB PARAMETERS,PERIODIC-TABLE,MOLECULES,HYDROGEN,APPROXIMATIONS,OPTIMIZATION,SIMULATIONS,CHEMISTRY",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Physics",,6.652,"ENERGY,SURFACES,COMPLEX,MATERIALS,DFTB,PARAMETERS,PERIODIC-TABLE,MOLECULES,HYDROGEN,APPROXIMATIONS,OPTIMIZATION,SIMULATIONS,CHEMISTRY",JOURNAL OF CHEMICAL THEORY AND COMPUTATION,,
16,Linking the evolution of catalytic properties and structural changes in copper-zinc nanocatalysts using operando EXAFS and neural-networks,11,14,3727-3736,"Timoshenko Janis,Jeon Hyo Sang,Sinev Ilya,Haase Felix T.,Herzog Antonia,Roldan Cuenya Beatriz","Timoshenko J,Jeon HS,Sinev I,Haase FT,Herzog A,Roldan Cuenya B",Roldan Cuenya B,10.1039/d0sc00382d,Max Planck Society,"Understanding the evolution of unique structural motifs in bimetallic catalysts under reaction conditions, and linking them to the observed catalytic properties is necessary for the rational design of the next generation of catalytic materials. Extended X-ray absorption fine structure (EXAFS) spectroscopy is a premier experimental method to address this issue, providing the possibility to track the changes in the structure of working catalysts. Unfortunately, the intrinsic heterogeneity and enhanced disorder characteristic of catalytic materials experiencing structural transformations under reaction conditions, as well as the low signal-to-noise ratio that is common for in situ EXAFS spectra hinder the application of conventional data analysis approaches. Here we address this problem by employing machine learning methods (artificial neural networks) to establish the relationship between EXAFS features and structural motifs in metals as well as oxide materials. We apply this approach to time-dependent EXAFS spectra acquired from copper-zinc nanoparticles during the electrochemical reduction of CO2 to reveal the details of the composition-dependent structural evolution and brass alloy formation, and their correlation with the catalytic selectivity of these materials.","X-RAY-ABSORPTION,ELECTROCHEMICAL REDUCTION,BIMETALLIC NANOPARTICLES,CO2 ELECTROREDUCTION,LOCAL-STRUCTURE,CARBON-DIOXIDE,ZN,DYNAMICS,SIZE,SPECTROSCOPY",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND",Chemistry,,9.658,"X-RAY-ABSORPTION,ELECTROCHEMICAL,REDUCTION,BIMETALLIC,NANOPARTICLES,CO2,ELECTROREDUCTION,LOCAL-STRUCTURE,CARBON-DIOXIDE,ZN,DYNAMICS,SIZE,SPECTROSCOPY",CHEMICAL SCIENCE,https://pure.mpg.de/pubman/item/item_3222206_2/component/file_3222656/d0sc00382d.pdf,
17,Machine-learning structural and electronic properties of metal halide perovskites using a hierarchical convolutional neural network,6,1,,"Saidi Wissam A.,Shadid Waseem,Castelli Ivano E.","Saidi WA,Shadid W,Castelli IE",Saidi WA,10.1038/s41524-020-0307-8,Pennsylvania Commonwealth System of Higher Education (PCSHE),"The development of statistical tools based on machine learning (ML) and deep networks is actively sought for materials design problems. While structure-property relationships can be accurately determined using quantum mechanical methods, these first-principles calculations are computationally demanding, limiting their use in screening a large set of candidate structures. Herein, we use convolutional neural networks to develop a predictive model for the electronic properties of metal halide perovskites (MHPs) that have a billions-range materials design space. We show that a well-designed hierarchical ML approach has a higher fidelity in predicting properties of the MHPs compared to straight-forward methods. In this architecture, each neural network element has a designated role in the estimation process from predicting complex features of the perovskites such as lattice constant and octahedral till angle to narrowing down possible ranges for the values of interest. Using the hierarchical ML scheme, the obtained root-mean-square errors for the lattice constants, octahedral angle and bandgap for the MHPs are 0.01 angstrom, 5 degrees, and 0.02 eV, respectively. Our study underscores the importance of a careful network design and a hierarchical approach to alleviate issues associated with imbalanced dataset distributions, which is invariably common in materials datasets.","EFFECTIVE MASSES,LEAD,SEMICONDUCTORS,TRANSPORT,DEFECTS,LENGTHS,ENERGY",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Chemistry,Materials Science",,13.993,"EFFECTIVE,MASSES,LEAD,SEMICONDUCTORS,TRANSPORT,DEFECTS,LENGTHS,ENERGY",NPJ COMPUTATIONAL MATERIALS,https://backend.orbit.dtu.dk/ws/files/210861022/s41524_020_0307_8.pdf,
18,,,,,,,,,,,,,,,,,,,,
19,Study on metal mine detection from underwater sonar images using data mining and machine learning techniques,12,5,5083-5092,"Padmaja Venkataraman,Rajendran V.,Vijayalakshmi P.","Padmaja V,Rajendran V,Vijayalakshmi P",Padmaja V,10.1007/s12652-020-01958-4,Sathyabama Institute of Science & Technology,"Ocean mines are the major threat to the safety of great vessels and other living beings in the marine life. It is a self-contained explosive device placed in water to destroy ships or submarines. Due to various factors like variations in operating and target shapes, environmental conditions, presence of spatially varying clutter, compositions and orientation, detection and classification of sonar imagery with respect to underwater objects is a complicated problem. It is well known that many post processing techniques in image processing have done to receive high resolution images to distinguish the objects. However the mentioned technique needs a special method to detect the metal from the usual sub bottom materials mainly rocks. Hence the data collection made in simulated environment locating metals in rock bed and collected with the sonar and the distinguished features of metals from rock have been identified with the totally different approach called intruder detection technique using data mining/machine learning. This paper proposes a novel approach for discriminating and detection of objects in underwater environment with accuracy of 90% (full feature set) and 86% (selected feature set). Hence, it is quite revealing that the new technique is better in classification of mine like objects in underwater, justified with samples of sonar data sets.","Uwcns,UWSNs,Mine detection,Machine learning,Data mining,KNN classifier,Gradient booster,Decision tree,SVM",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Telecommunications",,6.163,,JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING,,
20,A combined approach of atom probe tomography and unsupervised machine learning to understand phase transformation in (AlxGa1-x)(2)O-3,116,15,,"Sarker Jith,Broderick Scott,Bhuiyan A. F. M. Anhar Uddin,Feng Zixuan,Zhao Hongping,Mazumder Baishakhi","Sarker J,Broderick S,Bhuiyan AFMAU,Feng ZX,Zhao HP,Mazumder B",Mazumder B,10.1063/5.0002049,State University of New York (SUNY) System,"In this paper, we investigated the evolution of microstructural chemistry of metal organic chemical vapor deposition grown (010) (AlxGa1-x)(2)O-3 films with varying Al contents, x=0.10-1.0, using atom probe tomography (APT). At a low Al content (x <= 0.25), the films are homogeneous, where layer inhomogeneity appears at a high Al content (x>0.25). Further increasing the Al content up to x
>= 0.60 results in a homogeneous (AlxGa1-x)(2)O-3 layer. This change in microstructural features was linked to the phase transformation of (AlxGa1-x)(2)O-3 using a manifold learning approach to capture the governing features hidden in the data dimensionality. Combining APT to unsupervised machine learning enables APT to be an independent material characterization tool to investigate the microstructure, chemical composition, and phase related information.","BANDGAP,PHOTODETECTORS",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,3.596,"BANDGAP,PHOTODETECTORS",APPLIED PHYSICS LETTERS,,
21,Automatic detection algorithm for establishing standard to identify ,58,6,1393-1404,"Kokubo Ayako,Kuwabara Mitsuo,Nakajima Hiroshi,Tomitani Naoko,Yamashita Shingo,Shiga Toshikazu,Kario Kazuomi","Kokubo A,Kuwabara M,Nakajima H,Tomitani N,Yamashita S,Shiga T,Kario K",Kario K,10.1007/s11517-020-02162-4,Jichi Medical University,"Blood pressure (BP) variability is one of the important risk factors of cardiovascular disease (CVD). ""Surge BP,"" which represents short-term BP variability, is defined as pathological exaggerated BP increase capable of triggering cardiovascular events. Surge BP is effectively evaluated by our new BP monitoring device. To the best of our knowledge, we are the first to develop an algorithm for the automatic detection of surge BP from continuous ""beat-by-beat"" (BbB) BP measurements. It enables clinicians to save significant time identifying surge BP in big data from their patients' continuous BbB BP measurements. A total of 94 subjects (74 males and 20 females) participated in our study to develop the surge BP detection algorithm, resulting in a total of 3272 surges collected from the study subjects. The surge BP detection algorithm is a simple classification model based on supervised learning which formulates shape of surge BP as detection rules. Surge BP identified with our algorithm was evaluated against surge BP manually labeled by experts with 5-fold cross validation. The recall and precision of the algorithm were 0.90 and 0.64, respectively. Processing time on each subject was 11.0 +/- 4.7 s. Our algorithm is adequate for use in clinical practice and will be helpful in efforts to better understand this unique aspect of the onset of CVD.","Clinical informatics,Medical informatics applications,Expert systems,Learning from labeled data,Blood pressure monitors",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,,"OBSTRUCTIVE,SLEEP-APNEA,MORTALITY,RISK",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7211788,
22,A deep learning approach to the inversion of borehole resistivity measurements,24,3,971-994,"Shahriari M.,Pardo D.,Picon A.,Galdran A.,Del Ser J.,Torres-Verdin C.","Shahriari M,Pardo D,Picon A,Galdran A,Del Ser J,Torres-Verdin C",Shahriari M,10.1007/s10596-019-09859-y,"SCCH, Softwarepk 21, A-4232 Hagenberg Im Muhlkreis, Austria.","Borehole resistivity measurements are routinely employed to measure the electrical properties of rocks penetrated by a well and to quantify the hydrocarbon pore volume of a reservoir. Depending on the degree of geometrical complexity, inversion techniques are often used to estimate layer-by-layer electrical properties from measurements. When used for well geosteering purposes, it becomes essential to invert the measurements into layer-by-layer values of electrical resistivity in real time. We explore the possibility of using deep neural networks (DNNs) to perform rapid inversion of borehole resistivity measurements. Accordingly, we construct a DNN that approximates the following inverse problem: given a set of borehole resistivity measurements, the DNN is designed to deliver a physically reliable and data-consistent piecewise one-dimensional layered model of the surrounding subsurface. Once the DNN is constructed, we can invert borehole measurements in real time. We illustrate the performance of the DNN for inverting logging-while-drilling (LWD) measurements acquired in high-angle wells via synthetic examples. Numerical results are promising, although further work is needed to achieve the accuracy and reliability required by petrophysicists and drillers.","Logging-while-drilling (LWD),Resistivity measurements,Real-time inversion,Deep learning,Well geosteering,Deep neural networks",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Geology",,2.925,,COMPUTATIONAL GEOSCIENCES,http://arxiv.org/pdf/1810.04522,
23,Machine learning the magnetocaloric effect in manganites from lattice parameters,126,5,,"Zhang Yun,Xu Xiaojie","Zhang Y,Xu XJ",Zhang Y,10.1007/s00339-020-03503-8,University of North Carolina,"Efficient solid-state refrigeration techniques have drawn increasing attention due to their potential for improving energy efficiency of refrigeration temperature control systems without using harmful gas as in conventional gas compression techniques. Research on magnetocaloric lanthanum manganites with a large maximum magnetic entropy change near room temperature shows promising results for further developments of magnetic refrigeration devices. By incorporating chemical substitutions, oxygen content modifications, and various synthesis methods, these manganites experience lattice distortions from perovskite cubic structures to pseudocubic, orthorhombic, and rhombohedral structures. Further changes in lattice parameters can also be achieved by the introduction of strain due to lattice mismatches. Empirical results and previous models through thermodynamics and first principles show that changes in lattice parameters correlate with those in MMCE, but correlations are merely general tendencies and obviously not universal. In this work, the Gaussian process regression model is developed as a machine learning tool to find statistical correlations between the MMCE and lattice parameters among lanthanum manganites. More than 100 lattices, cubic, pseudocubic, orthorhombic, and rhombohedral, with the MMCE ranging from 0.65 to 8.00Jkg(-1)K(-1) under a field change of 5 T are explored for this purpose. The modeling approach demonstrates a high degree of accuracy and stability, contributing to efficient and low-cost estimations of the magnetocaloric effect. Furthermore, the machine learning algorithm predicts close MMCE results on epitaxial films with strained lattices against experimental results, which can provide guidance on thin film structure design and help understandings of magnetic phase transformations and magnetocaloric effects.","Magnetic entropy,Gaussian process regression,Lattice parameters,Magnetocalorics,Manganite",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Materials Science,Physics",,2.111,"MAGNETIC,ENTROPY,CHANGE,CRITICAL-BEHAVIOR,ROOM-TEMPERATURE,FE,NI,SUBSTITUTION,CR,CO",APPLIED PHYSICS A-MATERIALS SCIENCE & PROCESSING,,
24,Automatic detection and classification of EEG artifacts using fuzzy kernel SVM and wavelet ICA (WICA),24,21,16011-16019,"Yasoda K.,Ponmagal R. S.,Bhuvaneshwari K. S.,Venkatachalam K.","Yasoda K,Ponmagal RS,Bhuvaneshwari KS,Venkatachalam K",Venkatachalam K,10.1007/s00500-020-04920-w,Barkatullah University,"Electroencephalography (EEG) is almost contaminated with many artifacts while recording the brain signal activity. Clinical diagnostic and brain computer interface applications frequently require the automated removal of artifacts. In digital signal processing and visual assessment, EEG artifact removal is considered to be the key analysis technique. Nowadays, a standard method of dimensionality reduction technique like independent component analysis (ICA) and wavelet transform combination can be explored for removing the EEG signal artifacts. Manual artifact removal is time-consuming; in order to avoid this, a novel method of wavelet ICA (WICA) using fuzzy kernel support vector machine (FKSVM) is proposed for removing and classifying the EEG artifacts automatically. Proposed method presents an efficient and robust system to adopt the robotic classification and artifact computation from EEG signal without explicitly providing the cutoff value. Furthermore, the target artifacts are removed successfully in combination with WICA and FKSVM. Additionally, proposes the various descriptive statistical features such as mean, standard deviation, variance, kurtosis and range provides the model creation technique in which the training and testing the data of FKSVM is used to classify the EEG signal artifacts. The future work to implement various machine learning algorithm to improve performance of the system.","Wavelet ICA (WICA),Fuzzy kernel support vector machine (FKSVM),Aircraft,ECG signal",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,3.518,"REMOVAL,ELECTROENCEPHALOGRAMS,POTENTIALS,EXTRACTION",SOFT COMPUTING,,
25,Myelin water fraction estimation using small-tip fast recovery MRI,84,4,1977-1990,"Whitaker Steven T.,Nataraj Gopal,Nielsen Jon-Fredrik,Fessler Jeffrey A.","Whitaker ST,Nataraj G,Nielsen JF,Fessler JA",Whitaker ST,10.1002/mrm.28259,University of Michigan System,"Purpose To demonstrate the feasibility of an optimized set of small-tip fast recovery (STFR) MRI scans for rapidly estimating myelin water fraction (MWF) in the brain.
Methods We optimized a set of STFR scans to minimize the Cramer-Rao Lower Bound of MWF estimates. We evaluated the RMSE of MWF estimates from the optimized scans in simulation. We compared STFR-based MWF estimates (both modeling exchange and not modeling exchange) to multi-echo spin echo (MESE)-based estimates. We used the optimized scans to acquire in vivo data from which a MWF map was estimated. We computed the STFR-based MWF estimates using PERK, a recently developed kernel regression technique, and the MESE-based MWF estimates using both regularized non-negative least squares (NNLS) and PERK.
Results In simulation, the optimized STFR scans led to estimates of MWF with low RMSE across a range of tissue parameters and across white matter and gray matter. The STFR-based MWF estimates that modeled exchange compared well to MESE-based MWF estimates in simulation. When the optimized scans were tested in vivo, the MWF map that was estimated using a 3-compartment model with exchange was closer to the MESE-based MWF map.
Conclusions The optimized STFR scans appear to be well suited for estimating MWF in simulation and in vivo when we model exchange in training. In this case, the STFR-based MWF estimates are close to the MESE-based estimates.","kernel ridge regression,machine learning,myelin water fraction (MWF),scan optimization,small-tip fast recovery (STFR)",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"BRAIN,T-1",MAGNETIC RESONANCE IN MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7478173,
26,Neonatal sleep stage identification using long short-term memory learning system,58,6,1383-1391,"Fraiwan Luay,Alkhodari Mohanad","Fraiwan L,Alkhodari M",Fraiwan L,10.1007/s11517-020-02169-x,Abu Dhabi University,"Neonatal sleep analysis at the neonatal intensive care units (NICU) is critical for the diagnosis of any brain growth risks during the early stages of life. In this paper, an investigation is carried out on the use of a long short-term memory (LSTM) learning system in automatic sleep stage scoring in neonates. The developed algorithm automatically classifies sleep stages based on inputs from a single channel EEG recording. Up to this date, only a single study have developed an approach for automatic sleep stage scoring in neonatal sleep signals using deep neural network (DNN). A total of 5095 sleep stages signals acquired from EEG recordings of the University of Pittsburgh are used in this study. The sleep stages are annotated by a medical doctor from the Pediatric Neurology Department of Case Western Reserve University for three neonatal sleep stages including the awake (W), active sleep (AS), and quiet sleep (QS) stages on every 60-s epoch. The signals are pre-processed through normalization and filtering. The resulted signals are divided following 4-, 6-, and 10-fold cross-validation schemes. The training and classification process is done using a bi-directional LSTM network classifier built with pre-defined training parameters. At the end, the developed algorithm is evaluated along with a complete summary table that reports the results of this study and other state-of-the-art studies. The current study achieved high levels of Cohen's kappa (kappa), accuracy, and F1 score with 91.37%, 96.81%, and 94.43%, respectively. Based on the confusion matrix, the overall true positives percentage reached 95.21%. The developed algorithm gave promising results in automatic sleep stage scoring in neonatal sleep signals. Future work include LSTM architecture and training parameters improvements to enhance the overall accuracy of the classifier.","Neonatal,Sleep stage scoring,Deep learning,Recurrent neural network,Long short-term memory classifier,Training,Classification",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"AUTOMATED,DETECTION,NEURAL-NETWORK,INFANT,SLEEP,CLASSIFICATION,EEG,DIFFERENTIATION,PRETERM",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
27,Supervised deep semantics-preserving hashing for real-time pulmonary nodule image retrieval,17,6,1857-1868,"Qi Yongjun,Gu Junhua,Zhang Yajuan,Wu Gengshen,Wang Feng","Qi YJ,Gu JH,Zhang YJ,Wu GS,Wang F",Gu JH,10.1007/s11554-020-00963-2,Hebei University of Technology,"Hashing-based medical image retrieval has drawn extensive attention recently, which aims at providing effective aided diagnosis for medical personnel. In the paper, a novel deep hashing framework is proposed in the medical image retrieval, where the processes of deep feature extraction, binary code learning, and deep hash function learning are jointly carried out in supervised fashion. Particularly, the discrete constrained objective function in the hash code learning is optimized iteratively, where the binary code can be directly solved with no need for relaxation. In the meantime, the semantic similarity is maintained by fully exploring supervision information during the discrete optimization, where the neighborhood structure of training data is preserved by applying a graph regularization term. Additionally, to gain the fine-grained ranking of the returned medical images sharing the same Hamming distance, a novel image re-ranking scheme is proposed to refine the similarity measurement by jointly considering Euclidean distance between the real-valued feature descriptors and their category information between those images. Extensive experiments on the pulmonary nodule image dataset demonstrate that the proposed method can achieve better retrieval performance over the state of the arts.","Deep learning,Semantics-preserving hashing,Pulmonary nodule,Real-time image retrieval",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.137,"LUNG,NODULES",JOURNAL OF REAL-TIME IMAGE PROCESSING,https://eprints.lancs.ac.uk/id/eprint/143968/1/accepted_manuscript.pdf,
28,Review: Relations Between Metastable Austenite and Fatigue Behavior of Steels,56,4,459-475,"Xu Wei,Huang Minghao,Wang Jinliang,Shen Chunguang,Zhang Tianyu,Wang Chenchong","Xu W,Huang MH,Wang JL,Shen CG,Zhang TY,Wang CC",Xu W,10.11900/0412.1961.2019.00399,Northeastern University - China,"With the deepening and improvement of the research on the conventional mechanical properties of metallic materials, the long-term service properties, such as fatigue and creep, showed more and more critical influence on the development of metallic materials. As one of the most important engineering structural materials, in order to clarify the fatigue failure mechanism, the research of steels on the relationship between microstructure and fatigue properties has been a hot and difficult problem for a long time. With the rapid development of smelting technology for steels, the research on the influencing factors of fatigue gradually changes from inclusions to microstructures as metastable austenite, precipitates, etc. Therefore, in order to further analyze the feasible direction of the research on the influence of microstructure on fatigue, this paper summarizes the influence and mechanism of metastable austenite on the fatigue property of advanced steel materials. The influence mechanism of metastable austenite on fatigue property by relevant scholars under different service conditions such as low cycle fatigue and high cycle fatigue was reviewed. Based on the experimental results, the relationship between metastable austenite and fatigue properties was quantitatively evaluated by machine learning. The quantitative relationship between the content/stability of metastable austenite and fatigue life was established, which could provide the basis direction for the further study of the mechanism of fatigue for steels.","advanced steel,metastable austenite,fatigue property,failure mechanism,machine learning",Review,"SCIENCE PRESS, 16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA",Metallurgy & Metallurgical Engineering,,1.118,"HIGH-CYCLE,FATIGUE,INDUCED,MARTENSITIC-TRANSFORMATION,HIGH-STRENGTH,STEEL,TRIP-AIDED,STEELS,DUAL-PHASE,STEELS,RETAINED,AUSTENITE,STAINLESS-STEEL,MECHANICAL-PROPERTIES,INDUCED,PLASTICITY,CRACK,GROWTH",ACTA METALLURGICA SINICA,,
29,Machine learning distinguishes neurosurgical skill levels in a virtual reality tumor resection task,58,6,1357-1367,"Siyar Samaneh,Azarnoush Hamed,Rashidi Saeid,Winkler-Schwartz Alexander,Bissonnette Vincent,Ponnudurai Nirros,Del Maestro Rolando F.","Siyar S,Azarnoush H,Rashidi S,Winkler-Schwartz A,Bissonnette V,Ponnudurai N,Del Maestro RF",Azarnoush H,10.1007/s11517-020-02155-3,Amirkabir University of Technology,"This study outlines the first investigation of application of machine learning to distinguish ""skilled"" and ""novice"" psychomotor performance during a virtual reality (VR) brain tumor resection task. Tumor resection task participants included 23 neurosurgeons and senior neurosurgery residents as the ""skilled"" group and 92 junior neurosurgery residents and medical students as the ""novice"" group. The task involved removing a series of virtual brain tumors without causing injury to surrounding tissue. Originally, 150 features were extracted followed by statistical and forward feature selection. The selected features were provided to 4 classifiers, namely, K-Nearest Neighbors, Parzen Window, Support Vector Machine, and Fuzzy K-Nearest Neighbors. Sets of 5 to 30 selected features were provided to the classifiers. A working point of 15 premium features resulted in accuracy values as high as 90% using the Supprt Vector Machine. The obtained results highlight the potentials of machine learning, applied to VR simulation data, to help realign the traditional apprenticeship educational paradigm to a more objective model, based on proven performance standards.
Graphical abstract Using several scenarios of virtual reality neurosurgical tumor resection together with machine learning classifiers to distinguish skill level","Virtual reality simulation,Machine learning,Classifiers,Neurosurgery skill education and assessment,Tumor resection",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"FORCE,APPLICATION,PERFORMANCE,SIMULATOR,NEUROTOUCH,EXPERTISE,REMOVAL,METRICS",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,http://arxiv.org/pdf/1811.08159,
30,A cloud-based platform for the non-invasive management of coronary artery disease,14,8,1102-1123,"Sakellarios Antonis,Correia Joao,Kyriakidis Savvas,Georga Elena,Tachos Nikolaos,Siogkas Panagiotis,Sans Francisco,Stofella Paolo,Massimiliano Valiani,Clemente Alberto","Sakellarios A,Correia J,Kyriakidis S,Georga E,Tachos N,Siogkas P,Sans F,Stofella P,Massimiliano V,Clemente A",Fotiadis DI,10.1080/17517575.2020.1746975,University of Ioannina,"We present the architecture and the usability testing of a novel cloud-based platform, which integrates cyber-physical systems and interoperability standards enabling a clinical decision support system for risk stratification, diagnosis, prognosis and treatment of CAD. In this work multi-disciplinary human data were used for the development of machine learning and computational biomechanics based predictive models. Two Lab-on-Chip devices have been integrated into the cloud platform. A targeted RNA-panel provides the mRNA gene expression values for the stratification algorithm. The results of the usability testing demonstrate that the platform is efficient, accurate and performs all developed tasks quickly.","Cardiovascular disease,cloud-platform,CDSS,cyber-physical systems,interoperability",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Computer Science,,3.316,"ATHEROSCLEROTIC,PLAQUE,DEVELOPMENT,PREDICTION",ENTERPRISE INFORMATION SYSTEMS,,
31,,,,,,,,,,,,,,,,,,,,
32,Bone mineral density value evaluation based on photoacoustic spectral analysis combined with deep learning method,18,4,,"Zhou Xue,Jin Zhibin,Feng Ting,Cheng Qian,Wang Xueding,Ding Yao,Zhan Hongchen,Yuan Jie","Zhou X,Jin ZB,Feng T,Cheng Q,Wang XD,Ding Y,Zhan HC,Yuan J",Zhan HC; Yuan J,10.3788/COL202018.041701,Nanjing University,"The diagnosis of osteoporosis is eventually converted to the measurement of bone mineral density (BMD) in clinical trials. Since our previous work had proved the ability of using photoacoustic spectral analysis (PASA) to efficiently detect osteoporosis, in this contribution, we proposed a fully connected multi-layer deep neural network combined with PASA to semi-quantify BMD values corresponding to varying degrees of bone loss and to further evaluate the degree of osteoporosis. Experiments were carried out on swine femur heads, and the performance of our proposed method is satisfying for future clinical screening.","photoacoustics,osteoporosis,neural network",Article,"OSA-OPTICAL SOC, 2010 MASSACHUSETTS AVE, NW, WASHINGTON, DC 20036-1012 USA",Optics,,1.474,"CLINICAL-USE,OSTEOPOROSIS,MANAGEMENT,FRACTURE,IMPACT",CHINESE OPTICS LETTERS,,
33,Rubber fatigue life prediction using a random forest method and nonlinear cumulative fatigue damage model,137,14,,"Liu Qiaobin,Shi Wenku,Chen Zhiyong","Liu QB,Shi WK,Chen ZY",Chen ZY,10.1002/app.48519,Jilin University,"In this study, a random forest machine-learning method is introduced on the basis of the analysis of measured constant amplitude stress fatigue data. This method aims to predict rubber fatigue life under constant amplitude stress. Strain mean value, strain amplitude, and strain ratio are used as independent variables, and the prediction model of rubber fatigue life under constant amplitude stress is established. A nonlinear cumulative fatigue damage model is proposed to calculate rubber fatigue life under the variable amplitude stress. Results show that the random forest method has high precision and generalization capability for rubber fatigue life prediction under constant amplitude stress and the nonlinear cumulative fatigue damage model could be employed to calculate the fatigue life of rubber under variable amplitude stress with enough accuracy according to the constant amplitude stress fatigue life data. This research can provide a reference for rubber fatigue life prediction. (c) 2019 Wiley Periodicals, Inc. J. Appl. Polym. Sci. 2019, 136, 48519.","life prediction,nonlinear cumulative fatigue damage model,random forest,rubber fatigue,variable amplitude stress",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Polymer Science,,2.754,"NATURAL-RUBBER,BEHAVIOR",JOURNAL OF APPLIED POLYMER SCIENCE,,
34,Exudate Detection for Diabetic Retinopathy Using Pretrained Convolutional Neural Networks,2020,,,"Mateen Muhammad,Wen Junhao,Nasrullah Nasrullah,Sun Song,Hayat Shaukat","Mateen M,Wen JH,Nasrullah N,Sun S,Hayat S",Wen JH,10.1155/2020/5801870,Chongqing University,"In the field of ophthalmology, diabetic retinopathy (DR) is a major cause of blindness. DR is based on retinal lesions including exudate. Exudates have been found to be one of the signs and serious DR anomalies, so the proper detection of these lesions and the treatment should be done immediately to prevent loss of vision. In this paper, pretrained convolutional neural network- (CNN-) based framework has been proposed for the detection of exudate. Recently, deep CNNs were individually applied to solve the specific problems. But, pretrained CNN models with transfer learning can utilize the previous knowledge to solve the other related problems. In the proposed approach, initially data preprocessing is performed for standardization of exudate patches. Furthermore, region of interest (ROI) localization is used to localize the features of exudates, and then transfer learning is performed for feature extraction using pretrained CNN models (Inception-v3, Residual Network-50, and Visual Geometry Group Network-19). Moreover, the fused features from fully connected (FC) layers are fed into the softmax classifier for exudate classification. The performance of proposed framework has been analyzed using two well-known publicly available databases such as e-Ophtha and DIARETDB1. The experimental results demonstrate that the proposed pretrained CNN-based framework outperforms the existing techniques for the detection of exudates.","IMAGES,SEGMENTATION",Article,"WILEY-HINDAWI, ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND","Mathematics,Science & Technology - Other Topics",,2.8,"IMAGES,SEGMENTATION",COMPLEXITY,https://downloads.hindawi.com/journals/complexity/2020/5801870.pdf,
35,Ensemble based technique for the assessment of fetal health using cardiotocograph - a case study with standard feature reduction techniques,79,47-48,35147-35168,"Das Sahana,Mukherjee Himadri,Obaidullah Sk. Md.,Roy Kaushik,Saha Chanchal Kumar","Das S,Mukherjee H,Obaidullah SM,Roy K,Saha CK",Roy K,10.1007/s11042-020-08853-2,West Bengal State University,"Intrauterine fetal hypoxia is one of the leading cause of perinatal mortality and morbidity. This can eventually lead to severe neurological damage like cerebral palsy and in extreme cases to fetal demise. It is thus necessary to monitor the fetus during intrapartum and antepartum period. Cardiotocograph (CTG) as a method of assessing the status of the fetus had been in use for last six decades. Nowadays it is the most widely used non-invasive technique for the continuous monitoring of the fetal heart rate (FHR) and the uterine contraction pressure (UCP). Though its introduction limited the birth related problems, the accuracy of interpretation was hindered by quite a few factors. Different guidelines that are provided for the interpretation are based on crisp logic which fails to capture the inherent uncertainty present in the medical diagnosis. Misinterpretations had led to inaccurate diagnosis which resulted in many medico-legal litigations. The vagueness present in the physician's evaluation is best modeled using soft-computing based techniques. In this paper authors used the CTG dataset from UCI Irvine Machine Learning Data Repository which contains 2126 data and each data-point is represented by 37 features. Dimensionality of the feature set was reduced using different automated methods as well as manually by the physicians. The resulting data sets were classified using various machine learning algorithms. Aim of this study is to establish which set of features is best suited to give good insight into the status of the fetus and also determine the most effective machine learning technique for this purpose. The accuracy of the outcomes were measured using statistical methods such as sensitivity, specificity, precision, F-Measure, confusion matrix and kappa value. We obtained an accuracy of 99.91% and kappa measure of 0.997 when the feature set was reduced using MRMR.","Cardiotocograph,FHR,UCP,Confusion matrix,MRMR,Kappa",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,HEART-RATE,MULTIMEDIA TOOLS AND APPLICATIONS,,
36,MRI reconstruction using deep Bayesian estimation,84,4,2246-2261,"Luo Guanxiong,Zhao Na,Jiang Wenhao,Hui Edward S.,Cao Peng","Luo GX,Zhao N,Jiang WH,Hui ES,Cao P",Cao P,10.1002/mrm.28274,University of Hong Kong,"Purpose To develop a deep learning-based Bayesian estimation for MRI reconstruction. Methods We modeled the MRI reconstruction problem with Bayes's theorem, following the recently proposed PixelCNN++ method. The image reconstruction from incomplete k-space measurement was obtained by maximizing the posterior possibility. A generative network was utilized as the image prior, which was computationally tractable, and the k-space data fidelity was enforced by using an equality constraint. The stochastic backpropagation was utilized to calculate the descent gradient in the process of maximum a posterior, and a projected subgradient method was used to impose the equality constraint. In contrast to the other deep learning reconstruction methods, the proposed one used the likelihood of prior as the training loss and the objective function in reconstruction to improve the image quality. Results The proposed method showed an improved performance in preserving image details and reducing aliasing artifacts, compared with GRAPPA,l1-ESPRiT, model-based deep learning architecture for inverse problems (MODL), and variational network (VN), last two were state-of-the-art deep learning reconstruction methods. The proposed method generally achieved more than 3 dB peak signal-to-noise ratio improvement for compressed sensing and parallel imaging reconstructions compared with the other methods. Conclusions The Bayesian estimation significantly improved the reconstruction performance, compared with the conventionall1-sparsity prior in compressed sensing reconstruction tasks. More importantly, the proposed reconstruction framework can be generalized for most MRI reconstruction scenarios.","Bayesian estimation,compressed sensing,deep learning reconstruction,generative network,parallel imaging",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,,MAGNETIC RESONANCE IN MEDICINE,http://arxiv.org/pdf/1909.01127,
37,Regional-content-aware nuclear norm for low-does CT image denosing,40,4,1177-1183,",,,,","Song Yun,Zhang Yuanke,Lu Hongbing,Xing Yuxiang,Ma Jianhua",,,Song Yun,"The low-rank constraint model based on traditional Nuclear Norm Minimization(NNM)tends to cause local texture detail loss in the denoising of Low-Dose CT(LDCT)image. To tackle this issue,a regional-content-aware weighted NNM algorithm was proposed for LDCT image denoising. Firstly,a Singular Value Decomposition(SVD)based method was proposed to estimate the local noise intensity in LDCT image. Then,the target image block matching was performed based on the local statistical characteristics. Finally,the weights of the nuclear norms were adaptively set based on both the local noise intensity of the image and the different singular value levels,and the weighted NNM based LDCT image denoising was realized. The simulation results illustrated that the proposed algorithm decreased the Root Mean Square Error(RMSE)index by 30.11%,14.38% and 8.75% respectively compared with the traditional NNM,total variation minimization and transform learning algorithms,and improved the Structural SIMilarity(SSIM)index by 34.24%,23.06% and 11.52% respectively compared with the above three algorithms. The experimental results on real clinical data illustrated that the mean value of the radiologists'scores of the results obtained by the proposed algorithm was 8.94,which is only 0.21 lower than that of the corresponding full dose CT images,and was significantly higher than those of the traditional NNM,total variation minimization and transform learning algorithms. The simulation and clinical experimental results indicate that the proposed algorithm can effectively reduce the artifact noise while preserving the texture detail information in LDCT images.",Low-Does Computed Tomography (LDCT); noise reduction; Nuclear Norm Minimization (NNM); low rank; regional content awareness,Article,,,,,,,,
38,Transfer of motor skill between virtual reality viewed using a head-mounted display and conventional screen environments,17,1,,"Juliano Julia M.,Liew Sook-Lei","Juliano JM,Liew SL",Liew SL,10.1186/s12984-020-00678-2,University of Southern California,"Background Virtual reality viewed using a head-mounted display (HMD-VR) has the potential to be a useful tool for motor learning and rehabilitation. However, when developing tools for these purposes, it is important to design applications that will effectively transfer to the real world. Therefore, it is essential to understand whether motor skills transfer between HMD-VR and conventional screen-based environments and what factors predict transfer. Methods We randomized 70 healthy participants into two groups. Both groups trained on a well-established measure of motor skill acquisition, the Sequential Visual Isometric Pinch Task (SVIPT), either in HMD-VR or in a conventional environment (i.e., computer screen). We then tested whether the motor skills transferred from HMD-VR to the computer screen, and vice versa. After the completion of the experiment, participants responded to questions relating to their presence in their respective training environment, age, gender, video game use, and previous HMD-VR experience. Using multivariate and univariate linear regression, we then examined whether any personal factors from the questionnaires predicted individual differences in motor skill transfer between environments. Results Our results suggest that motor skill acquisition of this task occurs at the same rate in both HMD-VR and conventional screen environments. However, the motor skills acquired in HMD-VR did not transfer to the screen environment. While this decrease in motor skill performance when moving to the screen environment was not significantly predicted by self-reported factors, there were trends for correlations with presence and previous HMD-VR experience. Conversely, motor skills acquired in a conventional screen environment not only transferred but improved in HMD-VR, and this increase in motor skill performance could be predicted by self-reported factors of presence, gender, age and video game use. Conclusions These findings suggest that personal factors may predict who is likely to have better transfer of motor skill to and from HMD-VR. Future work should examine whether these and other predictors (i.e., additional personal factors such as immersive tendencies and task-specific factors such as fidelity or feedback) also apply to motor skill transfer from HMD-VR to more dynamic physical environments.","Virtual reality,Head-mounted display,Motor skill acquisition,Transfer,Presence",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Engineering,Neurosciences & Neurology,Rehabilitation",,5.218,"ACQUISITION,SELECTION,CONTEXT,STROKE,2D",JOURNAL OF NEUROENGINEERING AND REHABILITATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7149857,
39,Predicting HSE band gaps from PBE charge densities via neural network functionals,32,15,,"Lentz Levi C.,Kolpak Alexie M.","Lentz LC,Kolpak AM",Lentz LC,10.1088/1361-648X/ab5f3a,Massachusetts Institute of Technology (MIT),"Density functional theory (DFT) has become a standard method for ab initio calculations of material properties. However, it has a number of shortcomings, particularly in predicting key properties, such as band gap and optical spectra, which are dependent on excited states. To treat such properties, more accurate approaches such as GW or DFT with hybrid functionals (including HSE, PBE0, and B3LYP, to name a few) can be employed; however, these approaches are unfeasible for many large and/or complex systems due to their high computational cost and large memory requirements. In this work, we investigate the ability to train neural networks of the traditional DFT charge density computed with a standard PBE functional to accurately predict HSE band gaps. We show that a single network PBE charge density functional can predict the HSE band gap of seven different materials-silicon, gallium arsenide, molybdenum disulfide, germanium, tin phosphate, titanium phosphate, and zirconium phosphate-under a wide variety of conditions with an RSME of 172.6 meV, which is 34% better accuracy than standard regression between the PBE and HSE band gaps. This approach, which, in principle, can be used to map PBE charge densities to band gaps or other properties computed with any higher accuracy method, has the potential to decrease computational costs, increase prediction accuracy, and enable accurate high-throughput screening for a wide variety of complex materials systems.","density functional theory,band gap,machine learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,2.887,"POWDER,DIFFRACTION,PHOSPHATES,MACHINE",JOURNAL OF PHYSICS-CONDENSED MATTER,,
40,Deep Reinforcement Learning for Data Association in Cell Tracking,8,,,"Wang Junjie,Su Xiaohong,Zhao Lingling,Zhang Jun","Wang JJ,Su XH,Zhao LL,Zhang J",Zhao LL,10.3389/fbioe.2020.00298,Harbin Institute of Technology,"Accurate target detection and association are vital for the development of reliable target tracking, especially for cell tracking based on microscopy images due to the similarity of cells. We propose a deep reinforcement learning method to associate the detected targets between frames. According to the dynamic model of each target, the cost matrix is produced by conjointly considering various features of targets and then used as the input of a neural network. The proposed neural network is trained using reinforcement learning to predict a distribution over the association solution. Furthermore, we design a residual convolutional neural network that results in more efficient learning. We validate our method on two applications: the multiple target tracking simulation and the ISBI cell tracking. The results demonstrate that our approach based on reinforcement learning techniques could effectively track targets following different motion patterns and show competitive results.","cell tracking,linear assignment problem,deep learning,deep reinforcement learning,data association,residual CNN",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND","Biotechnology & Applied Microbiology,Science & Technology - Other Topics",,5.973,,FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY,https://europepmc.org/articles/pmc7161216?pdf=render,
41,Optical spectroscopy-based imaging techniques for the diagnosis of breast cancer: A novel approach,55,8,778-804,"Pal Uttam M.,Saxena Mansi,Vishnu G. K. Anil,Parsana Darshan,Sarvani B. S. R.,Varma Manoj,Jayachandra Mahesh,Kurpad Vishnu,Baruah Deb,Gogoi Gayatri","Pal UM,Saxena M,Vishnu GKA,Parsana D,Sarvani BSR,Varma M,Jayachandra M,Kurpad V,Baruah D,Gogoi G",Pandya HJ,10.1080/05704928.2020.1749651,Indian Institute of Science (IISC) - Bangalore,"There have been substantial advancements in optical spectroscopy-based imaging techniques in recent years. These developments can potentially herald a transformational change in the diagnostic pathway for diseases such as cancer. In this paper, we review the clinical and engineering aspects of novel optical spectroscopy-based imaging tools. We provide a comprehensive analysis of optical and non-optical spectroscopy-based breast cancer diagnosis techniques vis-a-vis the current standard techniques such as X-Ray mammography, ultrasonography, and tissue biopsy. The recent advancements in optical spectroscopy-based imaging systems such as Transillumination Imaging (TI) and the various types of Diffuse Optical Imaging (DOI) systems (parallel-plate, bed-based, and handheld) are examined. The engineering aspects, including mechanical, electronics, optics, automatic interpretation using artificial intelligence (AI), and ergonomics are discussed. The abilities of these technologies for measuring several cancer biomarkers such as hemoglobin, water, lipid, collagen, oxygen saturation (SO2), and tissue oxygenation index (TOI) are investigated. This article critically assesses the diagnostic ability and practical deployment of these new technologies to differentiate between the normal and cancerous tissue.","Transillumination imaging,diffuse optical imaging,near-infrared spectroscopy,breast cancer,rapid diagnosis,machine learning",Review,"TAYLOR & FRANCIS INC, 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA","Instruments & Instrumentation,Spectroscopy",,5.771,"IN-VIVO,DIGITAL,MAMMOGRAPHY,SCREENING-PROGRAM,MENSTRUAL-CYCLE,FOLLOW-UP,TOMOGRAPHY,BENIGN,TISSUE,WOMEN,ULTRASOUND",APPLIED SPECTROSCOPY REVIEWS,https://discovery.ucl.ac.uk/id/eprint/10094186/3/Vaidya_Optical%20spectroscopy-based%20imaging%20techniques%20for%20the%20diagnosis%20of%20breast%20cancer.%20A%20novel%20approach_AAM.pdf,
42,Physical insights into stress-strain process of polymers under tensile deformation via machine learning,18,2-3,323-334,"Shi Rui,Li Shu-Jia,Yu Linxiuzi,Qian Hu-Jun,Lu Zhong-Yuan","Shi R,Li SJ,Yu LXZ,Qian HJ,Lu ZY",Shi R,10.1080/1539445X.2020.1741387,Jilin University,"Strain localization is a ubiquitous phenomenon of soft matters subjected to strain. Polymeric materials are a very important class of soft materials and widely used nowadays. Polymers have unique strain localization behavior such as crazing during tensile deformation. How to understand the mechanism at the molecular level of strain localization in polymeric materials has become an important topic in material science. In this work, tensile deformation process of polymers both under a melt state and a glassy state are investigated in MD simulations using a generic coarse-grained model. We use a machine learning technique, i.e., support vector machine (SVM) algorithm, to understand the local molecular structure and the dynamical properties during tensile deformation. By defining ""softness"" from the SVM model, we investigate the stress-strain behavior of both ductile polymer above glass transition temperature and brittle polymer glass during tensile deformation. We demonstrated that the softness can be used to predict physical properties efficiently; the softness provides deep physical insights into the non-equilibrium stress-strain process. We also find that the Hookean behavior of polymer glasses is mostly contributed by the hard regions of the system, and the elastic limit is quantitatively discussed as well.","Computer simulations,mechanical properties,polymers,machine learning,softness",Article,"TAYLOR & FRANCIS INC, 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA",Materials Science,,1.731,"MOLECULAR-DYNAMICS,SIMULATION,CAVITATION,RELAXATION,INITIATION",SOFT MATERIALS,,
43,Spatiotemporal refinement of signal flow through association cortex during learning,11,1,,"Gilad Ariel,Helmchen Fritjof","Gilad A,Helmchen F",Helmchen F,10.1038/s41467-020-15534-z,University of Zurich,"Association areas in neocortex encode novel stimulus-outcome relationships, but the principles of their engagement during task learning remain elusive. Using chronic wide-field calcium imaging, we reveal two phases of spatiotemporal refinement of layer 2/3 cortical activity in mice learning whisker-based texture discrimination in the dark. Even before mice reach learning threshold, association cortex-including rostro-lateral (RL), posteromedial (PM), and retrosplenial dorsal (RD) areas-is generally suppressed early during trials (between auditory start cue and whisker-texture touch). As learning proceeds, a spatiotemporal activation sequence builds up, spreading from auditory areas to RL immediately before texture touch (whereas PM and RD remain suppressed) and continuing into barrel cortex, which eventually efficiently discriminates between textures. Additional correlation analysis substantiates this diverging learning-related refinement within association cortex. Our results indicate that a pre-learning phase of general suppression in association cortex precedes a learning-related phase of task-specific signal flow enhancement. Learning is a dynamic process involving many cortical areas. Here, using cortex-wide imaging, the authors show that in mice learning to discriminate between two textures a distinct task related signal flow is enhanced involving a specific association area whereas other association areas are suppressed.","LONG-RANGE,PARIETAL CORTEX,PROJECTION NEURONS,GABAERGIC NEURONS,PREFRONTAL CORTEX,TRANSGENIC MICE,VISUAL-CORTEX,DECISION,MEMORY,CIRCUIT",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,15.805,"LONG-RANGE,PARIETAL,CORTEX,PROJECTION,NEURONS,GABAERGIC,NEURONS,PREFRONTAL,CORTEX,TRANSGENIC,MICE,VISUAL-CORTEX,DECISION,MEMORY,CIRCUIT",NATURE COMMUNICATIONS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7142160,
44,Prediction of geometry deviations in additive manufactured parts: comparison of linear regression with machine learning algorithms,32,1,179-200,"Baturynska Ivanna,Martinsen Kristian","Baturynska I,Martinsen K",Baturynska I,10.1007/s10845-020-01567-0,Norwegian University of Science & Technology (NTNU),"Dimensional accuracy in additive manufacturing (AM) is still an issue compared with the tolerances for injection molding. In order to make AM suitable for the medical, aerospace, and automotive industries, geometry variations should be controlled and managed with a tight tolerance range. In the previously published article, the authors used statistical analysis to develop linear models for the prediction of dimensional features of laser-sintered specimens. Two identical builds with the same material, process, and build parameters were produced, resulting in 434 samples for mechanical testing (ISO 527-2 1BA). The developed linear models had low accuracy, and therefore needed an application of more advanced data analysis techniques. In this work, machine learning techniques are applied for the same data, and results are compared with the previously reported linear models. The linear regression model is the best for width. Multilayer perceptron and gradient boost regressor models have outperformed other for thickness and length. The recommendations on how the developed models can be used in the future are proposed.","Additive manufacturing,PA12,Polyamide,Machine learning,Dimensional accuracy,Support vector regression,Decision tree regressor,Multilayer perceptron,Gradient boosting regressor",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,5.829,"SHRINKAGE,COMPENSATION,PROCESS,PARAMETERS,OPTIMIZATION,ORIENTATION,MODEL",JOURNAL OF INTELLIGENT MANUFACTURING,https://ntnuopen.ntnu.no/ntnu-xmlui/bitstream/11250/2651873/1/Baturynska-Martinsen2020_Article_PredictionOfGeometryDeviations.pdf,
45,Automatic prostate segmentation using deep learning on clinically diverse 3D transrectal ultrasound images,47,6,2413-2426,"Orlando Nathan,Gillies Derek J.,Gyacskov Igor,Romagnoli Cesare,D'Souza David,Fenster Aaron","Orlando N,Gillies DJ,Gyacskov I,Romagnoli C,D'Souza D,Fenster A",Orlando N; Gillies DJ,10.1002/mp.14134,Western University (University of Western Ontario),"Purpose Needle-based procedures for diagnosing and treating prostate cancer, such as biopsy and brachytherapy, have incorporated three-dimensional (3D) transrectal ultrasound (TRUS) imaging to improve needle guidance. Using these images effectively typically requires the physician to manually segment the prostate to define the margins used for accurate registration, targeting, and other guidance techniques. However, manual prostate segmentation is a time-consuming and difficult intraoperative process, often occurring while the patient is under sedation (biopsy) or anesthetic (brachytherapy). Minimizing procedure time with a 3D TRUS prostate segmentation method could provide physicians with a quick and accurate prostate segmentation, and allow for an efficient workflow with improved patient throughput to enable faster patient access to care. The purpose of this study was to develop a supervised deep learning-based method to segment the prostate in 3D TRUS images from different facilities, generated using multiple acquisition methods and commercial ultrasound machine models to create a generalizable algorithm for needle-based prostate cancer procedures. Methods Our proposed method for 3D segmentation involved prediction on two-dimensional (2D) slices sampled radially around the approximate central axis of the prostate, followed by reconstruction into a 3D surface. A 2D U-Net was modified, trained, and validated using images from 84 end-fire and 122 side-fire 3D TRUS images acquired during clinical biopsies and brachytherapy procedures. Modifications to the expansion section of the standard U-Net included the addition of 50% dropouts and the use of transpose convolutions instead of standard upsampling followed by convolution to reduce overfitting and improve performance, respectively. Manual contours provided the annotations needed for the training, validation, and testing datasets, with the testing dataset consisting of 20 end-fire and 20 side-fire unseen 3D TRUS images. Since predicting with 2D images has the potential to lose spatial and structural information, comparisons to 3D reconstruction and optimized 3D networks including 3D V-Net, Dense V-Net, and High-resolution 3D-Net were performed following an investigation into different loss functions. An extended selection of absolute and signed error metrics were computed, including pixel map comparisons [dice similarity coefficient (DSC), recall, and precision], volume percent differences (VPD), mean surface distance (MSD), and Hausdorff distance (HD), to assess 3D segmentation accuracy. Results Overall, our proposed reconstructed modified U-Net performed with a median [first quartile, third quartile] absolute DSC, recall, precision, VPD, MSD, and HD of 94.1 [92.6, 94.9]%, 96.0 [93.1, 98.5]%, 93.2 [88.8, 95.4]%, 5.78 [2.49, 11.50]%, 0.89 [0.73, 1.09] mm, and 2.89 [2.37, 4.35] mm, respectively. When compared to the best-performing optimized 3D network (i.e., 3D V-Net with a Dice plus cross-entropy loss function), our proposed method performed with a significant improvement across nearly all metrics. A computation time <0.7 s per prostate was observed, which is a sufficiently short segmentation time for intraoperative implementation. Conclusions Our proposed algorithm was able to provide a fast and accurate 3D segmentation across variable 3D TRUS prostate images, enabling a generalizable intraoperative solution for needle-based prostate cancer procedures.
This method has the potential to decrease procedure times, supporting the increasing interest in needle-based 3D TRUS approaches.","3D ultrasound prostate segmentation,biopsy,brachytherapy,deep learning,prostate cancer",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"INTEROBSERVER,VARIABILITY,CONVEX-OPTIMIZATION,VOLUME,MEASUREMENT,TRUS",MEDICAL PHYSICS,https://aapm.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mp.14134,
46,Brain Tumor Segmentation Using an Ensemble of 3D U-Nets and Overall Survival Prediction Using Radiomic Features,14,,,"Feng Xue,Tustison Nicholas J.,Patel Sohil H.,Meyer Craig H.","Feng X,Tustison NJ,Patel SH,Meyer CH",Feng X,10.3389/fncom.2020.00025,University of Virginia,"Accurate segmentation of different sub-regions of gliomas such as peritumoral edema, necrotic core, enhancing, and non-enhancing tumor core from multimodal MRI scans has important clinical relevance in diagnosis, prognosis and treatment of brain tumors. However, due to the highly heterogeneous appearance and shape of these tumors, segmentation of the sub-regions is challenging. Recent developments using deep learning models has proved its effectiveness in various semantic and medical image segmentation tasks, many of which are based on the U-Net network structure with symmetric encoding and decoding paths for end-to-end segmentation due to its high efficiency and good performance. In brain tumor segmentation, the 3D nature of multimodal MRI poses challenges such as memory and computation limitations and class imbalance when directly adopting the U-Net structure. In this study we aim to develop a deep learning model using a 3D U-Net with adaptations in the training and testing strategies, network structures, and model parameters for brain tumor segmentation. Furthermore, instead of picking one best model, an ensemble of multiple models trained with different hyper-parameters are used to reduce random errors from each model and yield improved performance. Preliminary results demonstrate the effectiveness of this method and achieved the 9th place in the very competitive 2018 Multimodal Brain Tumor Segmentation (BraTS) challenge. In addition, to emphasize the clinical value of the developed segmentation method, a linear model based on the radiomics features extracted from segmentation and other clinical features are developed to predict patient overall survival. Evaluation of these innovations shows high prediction accuracy in both low-grade glioma and glioblastoma patients, which achieved the 1st place in the 2018 BraTS challenge.","brain tumor segmentation,ensemble,3D U-net,deep learning,survival prediction,linear regression",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND","Mathematical & Computational Biology,Neurosciences & Neurology",,2.909,IMAGES,FRONTIERS IN COMPUTATIONAL NEUROSCIENCE,http://arxiv.org/pdf/1812.01049,
47,Prediction of Nanoscale Friction for Two-Dimensional Materials Using a Machine Learning Approach,68,2,,"Baboukani Behnoosh Sattari,Ye Zhijiang,Reyes Kristofer G.,Nalam Prathima C.","Baboukani BS,Ye ZJ,Reyes KG,Nalam PC",Reyes KG; Nalam PC,10.1007/s11249-020-01294-w,State University of New York (SUNY) System,"Several two-dimensional (2D) materials such as graphene, molybdenum disulfide, or boron nitride are emerging as alternatives for lubrication additives to control friction and wear at the interface. On the other hand, the initiative to accelerate materials discovery through data-driven computational methods has identified numerous novel topologies and families of 2D materials that can potentially be designed as low-friction additives. Hence, generating a structure-property (friction) correlations for 2D material-based additives that present a large variation in atomic composition is the next big challenge. Herein, we present a machine learning (ML) method using the Bayesian modeling and transfer learning approach to predict the maximum energy barrier (MEB) of the potential surface energy (correlated to intrinsic friction) of ten different 2D materials that were previously unexplored for their tribological properties. The descriptors (or properties) required to train the ML model with high accuracy are identified by taking into account the established physical models for dissipation in 2D materials. As a result, a difference of less than 8% in MEB values as predicted via the ML model presented here and the PES profiles generated using molecular dynamics simulations, for a select few 2D materials, was obtained. The model also enabled the identification of material properties that present the highest sensitivity to the corrugated potential, hence enabling the development of design routes for the synthesis of 2D materials with optimal tribological properties.","Van der waals,Potential energy surface,Friction,2D materials,Transfer learning,Bayesian model,Maximum energy barrier",Article,"SPRINGER/PLENUM PUBLISHERS, 233 SPRING ST, NEW YORK, NY 10013 USA",Engineering,,,"EXCITON,BINDING-ENERGY,ELECTRONIC-PROPERTIES,THERMAL-CONDUCTIVITY,AB-INITIO,DIELECTRIC-PROPERTIES,ELASTIC,PROPERTIES,LATTICE-DYNAMICS,MONOLAYER,MOS2,GRAPHENE,SINGLE",TRIBOLOGY LETTERS,,
48,High-throughput discovery of high Curie point two-dimensional ferromagnetic materials,6,1,,"Kabiraj Arnab,Kumar Mayank,Mahapatra Santanu","Kabiraj A,Kumar M,Mahapatra S",Kabiraj A,10.1038/s41524-020-0300-2,Indian Institute of Science (IISC) - Bangalore,"Databases for two-dimensional materials host numerous ferromagnetic materials without the vital information of Curie temperature since its calculation involves a manually intensive complex process. In this work, we develop a fully automated, hardware-accelerated, dynamic-translation based computer code, which performs first principles-based computations followed by Heisenberg model-based Monte Carlo simulations to estimate the Curie temperature from the crystal structure. We employ this code to conduct a high-throughput scan of 786 materials from a database to discover 26 materials with a Curie point beyond 400 K. For rapid data mining, we further use these results to develop an end-to-end machine learning model with generalized chemical features through an exhaustive search of the model space as well as the hyperparameters. We discover a few more high Curie point materials from different sources using this data-driven model. Such material informatics, which agrees well with recent experiments, is expected to foster practical applications of two-dimensional magnetism.","PYTHON LIBRARY,DYNAMICS,CRYSTAL,METALS",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Chemistry,Materials Science",,13.993,"PYTHON,LIBRARY,DYNAMICS,CRYSTAL,METALS",NPJ COMPUTATIONAL MATERIALS,http://eprints.iisc.ac.in/65210/3/41524_2020_300_MOESM3_ESM.xls,
49,,,,,,,,,,,,,,,,,,,,
50,"Tolerance factor, phase stability and order-disorder of the pyrochlore structure",7,7,1583-1590,"Song Zhen,Liu Quanlin","Song Z,Liu QL",Liu QL,10.1039/d0qi00016g,University of Science & Technology Beijing,"The tolerance factor is a structural indicator that connects the crystal structure and chemical composition. In this work, we establish the tolerance factor for pyrochlore A(2)B(2)O(7)-type compounds, using ionic radii of the compositional species. It is derived following similar procedures to those of perovskite and garnet structures. More than 180 A(2)B(2)O(7) type compounds are examined to test its validity in predicting the pyrochlore phase stability. It can also be used to understand the reverse and order-disorder cationic occupations. This structural descriptor could be used together with machine learning or high-throughput screening methods for new material design and discovery.","EFFECTIVE IONIC-RADII,OXIDES,EVOLUTION,SN",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND",Chemistry,,6.175,"EFFECTIVE,IONIC-RADII,OXIDES,EVOLUTION,SN",INORGANIC CHEMISTRY FRONTIERS,,
51,Spin dynamics of a magnetic Weyl semimetal Sr1-xMn1-ySb2,101,13,,"Cai Zhengwei,Bao Song,Wang Wei,Ma Zhen,Dong Zhao-Yang,Shangguan Yanyan,Wang Jinghui,Ran Kejing,Li Shichao,Kamazawa Kazuya","Cai ZW,Bao S,Wang W,Ma Z,Dong ZY,Shangguan YY,Wang JH,Ran KJ,Li SC,Kamazawa K",Yu SL,10.1103/PhysRevB.101.134408,Nanjing University,"Dirac matters provide a platform for exploring the interplay of their carriers with other quantum phenomena. Sr1-xMn1-ySb2 has been proposed to be a magnetic Weyl semimetal and provides an excellent platform to study the coupling between Weyl fermions and magnons. Here, we report comprehensive inelastic neutron scattering (INS) measurements on single crystals of Sr1-xMn1-ySb2, which have been well characterized by magnetization and magnetotransport measurements, both of which demonstrate that the material is a topologically nontrivial semimetal. The INS spectra clearly show a spin gap of similar to 6 meV. The dispersion in the magnetic Mn layer extends up to about 76 meV, while that between the layers has a narrow band width of 6 meV. We find that the linear spin-wave theory using a Heisenberg spin Hamiltonian can reproduce the experimental spectra with the following parameters: a nearest-neighbor (SJ(1) similar to 28.0 meV) and next-nearest-neighbor in-plane exchange interaction (SJ(2) similar to 9.3 meV), interlayer exchange coupling (SJ(c) similar to -0.1 meV), and spin anisotropy constant (SD similar to -0.07 meV). Despite the coexistence of Weyl fermions and magnons, we find no clear evidence that the magnetic dynamics are influenced by the Weyl fermions in Sr1-xMn1-ySb2, possibly because that the Weyl fermions and magnons reside in the Sb and Mn layers separately, and the interlayer coupling is weak due to the quasi-two-dimensional nature of the material, as also evident from the small SJ(c) of -0.1 meV.","BERRYS PHASE,ELECTRONIC-PROPERTIES,ULTRAHIGH MOBILITY,MAGNETORESISTANCE,DISCOVERY,NODES",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,"BERRYS,PHASE,ELECTRONIC-PROPERTIES,ULTRAHIGH,MOBILITY,MAGNETORESISTANCE,DISCOVERY,NODES",PHYSICAL REVIEW B,http://arxiv.org/pdf/2004.03893,
52,"Prediction of MOF Performance in Vacuum Swing Adsorption Systems for Postcombustion CO2 Capture Based on Integrated Molecular Simulations, Process Optimizations, and Machine Learning Models",54,7,4536-4544,"Burns Thomas D.,Pai Kasturi Nagesh,Subraveti Sai Gokul,Collins Sean P.,Krykunov Mykhaylo,Rajendran Arvind,Woo Tom K.","Burns TD,Pai KN,Subraveti SG,Collins SP,Krykunov M,Rajendran A,Woo TK",Rajendran A,10.1021/acs.est.9b07407,University of Alberta,"Postcombustion CO2 capture and storage (CCS) is a key technological approach to reducing greenhouse gas emission while we transition to carbon-free energy production. However, current solvent-based CO2 capture processes are considered too energetically expensive for widespread deployment. Vacuum swing adsorption (VSA) is a low-energy CCS that has the potential for industrial implementation if the right sorbents can be found. Metal-organic framework (MOF) materials are often promoted as sorbents for low-energy CCS by highlighting select adsorption properties without a clear understanding of how they perform in real-world VSA processes. In this work, atomistic simulations have been fully integrated with a detailed VSA simulator, validated at the pilot scale, to screen 1632 experimentally characterized MOFs. A total of 482 materials were found to meet the 95% CO2 purity and 90% CO2 recovery targets (95/90-PRTs)-365 of which have parasitic energies below that of solvent-based capture (similar to 290 kWh(e)/MT CO2) with a low value of 217 kWh(e)/MT CO2. Machine learning models were developed using common adsorption metrics to predict a material's ability to meet the 95/90-PRT with an overall prediction accuracy of 91%. It was found that accurate parasitic energy and productivity estimates of a VSA process require full process simulations.","METAL-ORGANIC FRAMEWORKS,CARBON-DIOXIDE CAPTURE,FLUE-GAS,ADSORBENT,EQUILIBRIUM,SEPARATIONS,NITROGEN,ENERGY",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Engineering,Environmental Sciences & Ecology",,9.922,"METAL-ORGANIC,FRAMEWORKS,CARBON-DIOXIDE,CAPTURE,FLUE-GAS,ADSORBENT,EQUILIBRIUM,SEPARATIONS,NITROGEN,ENERGY",ENVIRONMENTAL SCIENCE & TECHNOLOGY,,
53,Deep learning-based radiomic features for improving neoadjuvant chemoradiation response prediction in locally advanced rectal cancer,65,7,,"Fu Jie,Zhong Xinran,Li Ning,Van Dams Ritchell,Lewis John,Sung Kyunghyun,Raldow Ann C.,Jin Jing,Qi X. Sharon","Fu J,Zhong XR,Li N,Van Dams R,Lewis J,Sung K,Raldow AC,Jin J,Qi XS",Fu J,10.1088/1361-6560/ab7970,University of California System,"Radiomic features achieve promising results in cancer diagnosis, treatment response prediction, and survival prediction. Our goal is to compare the handcrafted (explicitly designed) and deep learning (DL)-based radiomic features extracted from pre-treatment diffusion-weighted magnetic resonance images (DWIs) for predicting neoadjuvant chemoradiation treatment (nCRT) response in patients with locally advanced rectal cancer (LARC). 43 Patients receiving nCRT were included. All patients underwent DWIs before nCRT and total mesorectal excision surgery 6-12 weeks after completion of nCRT. Gross tumor volume (GTV) contours were drawn by an experienced radiation oncologist on DWIs. The patient-cohort was split into the responder group (n = 22) and the non-responder group (n = 21) based on the post-nCRT response assessed by postoperative pathology, MRI or colonoscopy. Handcrafted and DL-based features were extracted from the apparent diffusion coefficient (ADC) map of the DWI using conventional computer-aided diagnosis methods and a pre-trained convolution neural network, respectively. Least absolute shrinkage and selection operator (LASSO)-logistic regression models were constructed using extracted features for predicting treatment response. The model performance was evaluated with repeated 20 times stratified 4-fold cross-validation using receiver operating characteristic (ROC) curves and compared using the corrected paired t-test. The model built with handcrafted features achieved the mean area under the ROC curve (AUC) of 0.64, while the one built with DL-based features yielded the mean AUC of 0.73. The corrected paired t-test on AUC showed P-value < 0.05. DL-based features extracted from pre-treatment DWIs achieved significantly better classification performance compared with handcrafted features for predicting nCRT response in patients with LARC.","deep learning,radiomics,diffusion-weighted MR imaging,locally advanced rectal cancer,treatment response prediction",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,,PHYSICS IN MEDICINE AND BIOLOGY,http://arxiv.org/pdf/1909.04012,
54,DeepDose: Towards a fast dose calculation engine for radiation therapy using deep learning,65,7,,"Kontaxis C.,Bol G. H.,Lagendijk J. J. W.,Raaymakers B. W.","Kontaxis C,Bol GH,Lagendijk JJW,Raaymakers BW",Kontaxis C,10.1088/1361-6560/ab7630,Utrecht University,"We present DeepDose, a deep learning framework for fast dose calculations in radiation therapy. Given a patient anatomy and linear-accelerator IMRT multi-leaf-collimator shape or segment, a novel set of physics-based inputs is calculated that encode the linac machine parameters into the underlying anatomy. These inputs are then used to train a deep convolutional network to derive the dose distribution of individual MLC shapes on a given patient anatomy.
In this work we demonstrate the proof-of-concept application of DeepDose on 101 prostate patients treated in our clinic with fixed-beam IMRT. The ground-truth data used for training, validation and testing of the prediction were calculated with a state-of-the-art Monte Carlo dose engine at 1% statistical uncertainty per segment. A deep convolution network was trained using the data of 80 patients at the clinically used 3 mm(3) grid spacing while 10 patients were used for validation.
For another 11 independent test patients, the network was able to accurately estimate the segment doses from the clinical plans of each patient passing the clinical QA when compared with the Monte Carlo calculations, yielding on average 99.9%+/- 0.3% for the forward calculated patient plans at 3%/3 mm gamma tests. Dose prediction using the trained network was very fast at approximately 0.9 seconds for the input generation and 0.6 seconds for single GPU inference per segment and 1 minute per patient in total.
The overall performance of this dose calculation framework in terms of both accuracy and inference speed, makes it compelling for online adaptive workflows where fast segment dose calculations are needed.","dose engine,IMRT,deep learning,AI,treatment planning,plan adaptation,MR-linac",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"PLATFORM,IMPACT",PHYSICS IN MEDICINE AND BIOLOGY,https://doi.org/10.1088/1361-6560/ab7630,
55,Improving accuracy and robustness of deep convolutional neural network based thoracic OAR segmentation,65,7,,"Feng Xue,Bernard Mark E.,Hunter Thomas,Chen Quan","Feng X,Bernard ME,Hunter T,Chen Q",Chen Q,10.1088/1361-6560/ab7877,University of Kentucky,"Deep convolutional neural network (DCNN) has shown great success in various medical image segmentation tasks, including organ-at-risk (OAR) segmentation from computed tomography (CT) images. However, most studies use the dataset from the same source(s) for training and testing so that the ability of a trained DCNN to generalize to a different dataset is not well studied, as well as the strategy to address the issue of performance drop on a different dataset. In this study we investigated the performance of a well-trained DCNN model from a public dataset for thoracic OAR segmentation on a local dataset and explored the systematic differences between the datasets. We observed that a subtle shift of organs inside patient body due to the abdominal compression technique during image acquisition caused significantly worse performance on the local dataset. Furthermore, we developed an optimal strategy via incorporating different numbers of new cases from the local institution and using transfer learning to improve the accuracy and robustness of the trained DCNN model. We found that by adding as few as 10 cases from the local institution, the performance can reach the same level as in the original dataset. With transfer learning, the training time can be significantly shortened with slightly worse performance for heart segmentation.","deep learning,segmentation,generalization error,robustness",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"ORGANS,CT",PHYSICS IN MEDICINE AND BIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8035811,
56,Effective and efficient multitask learning for brain tumor segmentation,17,6,1951-1960,"Cheng Guohua,Cheng Jingliang,Luo Mengyan,He Linyang,Tian Yan,Wang Ruili","Cheng GH,Cheng JL,Luo MY,He LY,Tian Y,Wang RL",Cheng GH,10.1007/s11554-020-00961-4,Fudan University,"Recently, brain tumor segmentation has achieved great success, partially because of deep learning-based relation exploration and multiscale analysis. However, the computational complexity hinders the real-time application. In this paper, we propose a revised multitask learning approach in which a lightweight network with only two scales is adopted to segment different kinds of tumor regions. Moreover, we design a hybrid hard sampling method that considers both sample sparsity and effectiveness. Extensive experiments on the BraTS19 segmentation challenge dataset have shown that our proposed method improves the Dice coefficient by a margin of 0.4-1.0 for different kinds of brain tumor regions and obtains results that are competitive with state-of-the-art brain tumor segmentation approaches.","Brain tumor segmentation,Image segmentation,Deep learning,Multitask learning",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.137,"NEURAL-NETWORKS,STABILITY",JOURNAL OF REAL-TIME IMAGE PROCESSING,,
57,Online variational learning of finite invertedBeta-Liouvillemixture model for biomedical analysis,30,3,794-814,"Kalra Meeta,Bouguila Nizar,Fan Wentao","Kalra M,Bouguila N,Fan WT",Kalra M,10.1002/ima.22421,Concordia University - Canada,"Image segmentation is widely applied for biomedical image analysis. However, segmentation of medical images is challenging due to many image modalities, such as, CT, X-ray, MRI, microscopy among others. An additional challenge to this is the high variability, inconsistent regions with missing edges, absence of texture contrast, and high noise in the background of biomedical images. Thus, many segmentation approaches have been investigated to address these issues and to transform medical images into meaningful information. During the past decade, finite mixture models have been revealed to be one of the most flexible and popular approaches in data clustering. In this article, we propose a statistical framework for online variational learning of finite inverted Beta-Liouville mixture model for clustering medical images. The online variational learning framework is used to estimate the parameters and the number of mixture components simultaneously, thus decreasing the computational complexity of the model. To this end, we evaluated our proposed algorithm on five different biomedical image data sets including optic disc detection and localization in diabetic retinopathy, digital imaging in melanoma lesion detection and segmentation, brain tumor detection, colon cancer detection and computer aid detection (CAD) of Malaria. Furthermore, we compared the proposed algorithm with three other popular algorithms. In our results, we analyze that the proposed online variational learning of finite IBL mixture model algorithm performs accurately on multiple modalities of medical images. It detects the disease patterns with high confidence. Computational and statistical approaches like the one presented in this article hold a significant impact on medical image analysis and interpretation in both clinical applications and scientific research. We believe that the proposed algorithm has the capacity to address multi modal biomedical image data sets and can be further applied by researchers to analyze correct disease patterns.","biomedical images,brain tumor detection,CAD of malaria,colon cancer,diabetic retinopathy,feature extraction,finite inverted Beta-Liouville,image segmentation,mixture model,optic disc localization and detection,skin melanoma",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,"BRAIN-TUMOR,MIXTURE,DIAGNOSIS,SELECTION",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
58,,,3,12-16,,,,10.26897/2687-1149-2020-3-12-16,,"        ,          ,        .     .             14%,        (95%)    (5%),             1,7 .         1,74  0,1 /(-),       5,7  0,2%.             ,         74,9%,   4,4% ,      .         ,       ,  83,0%,       67.                0,064 */. ,                 3,7%       .",;  ; ;  ;  ;   ,Article,,,,,,,,
59,Detecting dental problem related brain disease using intelligent bacterial optimized associative deep neural network,23,3,1647-1657,"Mahmoud Nourelhoda M.,Fouad H.,Alsadon Omar,Soliman Ahmed M.","Mahmoud NM,Fouad H,Alsadon O,Soliman AM",Fouad H,10.1007/s10586-020-03104-3,King Saud University,"Nowadays, a lot of people have the oral health problems due to continuous changes in the lifestyle such as the person's speech which can be affected by the malocclusion in teeth and the crooked teeth. The dental problems can cause cavity and bacterial infection. The dental and speech problems mostly can be related to the Alzheimer disease, and cognitive changes. Therefore, the dental information is collected from patients and analyzed by applying intelligent machine learning techniques. The gathered dental information is normalized by standardized min max approach. Further, different statistical parameters are derived which are huge in dimension. The optimal features are selected using grey wolf optimized approach. The method effectively selects the optimum dental features and the selected features are processed using bacterial optimized associative deep neural network. The network collects the Alzheimer disease features and compare them with the collected dental features to establish the brain related issues with dental features. The efficiency of the system is evaluated using experimental results and discussion. Thus, the introduced intelligent bacterial optimized associative deep neural network recognizes the relationship up to 98.98% of accuracy which is the maximum accuracy compared to other methods. Further, IBADNN-based Alzheimer detection system approach attains maximum predicting and selecting disease features (precision 98.65% and recall 99.03%) whereas other approaches such as OLVQ (precision 95.03% and recall 96.23%), HACANN (precision 96.36% and recall 96.91%) and GCNN (precision 97.47% and recall 97.512%) and attains low predicting and selecting accuracy.","Oral health,Dental problems,Alzheimer disease,Cognitive changes,Standardized min max approach,Grey wolf optimized approach,Bacterial optimized associative deep neural network",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,1.906,"COGNITIVE,IMPAIRMENT,ORAL,HYGIENE,DEMENTIA,SELECTION,HEALTH,MODEL",CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS,,
60,"Ontology-Based Radiology Teaching File Summarization, Coverage, and Integration",33,3,797-813,"Deshpande Priya,Rasin Alexander,Son Jun,Kim Sungmin,Brown Eli,Furst Jacob,Raicu Daniela S.,Montner Steven M.,Armato Samuel G. III","Deshpande P,Rasin A,Son J,Kim S,Brown E,Furst J,Raicu DS,Montner SM,Armato SG",Deshpande P,10.1007/s10278-020-00331-3,DePaul University,"Radiology teaching file repositories contain a large amount of information about patient health and radiologist interpretation of medical findings. Although valuable for radiology education, the use of teaching file repositories has been hindered by the ability to perform advanced searches on these repositories given the unstructured format of the data and the sparseness of the different repositories. Our term coverage analysis of two major medical ontologies, Radiology Lexicon (RadLex) and Unified Medical Language System (UMLS) Systematized Nomenclature of Medicine Clinical Terms (SNOMED CT), and two teaching file repositories, Medical Imaging Resource Community (MIRC) and MyPacs, showed that both ontologies combined cover 56.3% of terms in the MIRC and only 17.9% of terms in MyPacs. Furthermore, the overlap between the two ontologies (i.e., terms included by both the RadLex and UMLS SNOMED CT) was a mere 5.6% for the MIRC and 2% for the RadLex. Clustering the content of the teaching file repositories showed that they focus on different diagnostic areas within radiology. The MIRC teaching file covers mostly pediatric cases; a few cases are female patients with heart-, chest-, and bone-related diseases. The MyPacs contains a range of different diseases with no focus on a particular disease category, gender, or age group. MyPacs also provides a wide variety of cases related to the neck, face, heart, chest, and breast. These findings provide valuable insights on what new cases should be added or how existent cases may be integrated to provide more comprehensive data repositories. Similarly, the low-term coverage by the ontologies shows the need to expand ontologies with new terminology such as new terms learned from these teaching file repositories and validated by experts. While our methodology to organize and index data using clustering approaches and medical ontologies is applied to teaching file repositories, it can be applied to any other medical clinical data.","Cluster analysis,Radiology teaching files,Medical ontologies,Coverage analysis,Data integration",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,RADLEX,JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7256159,
61,Scanner invariant representations for diffusion MRI harmonization,84,4,2174-2189,"Moyer Daniel,Steeg Greg Ver,Tax Chantal M. W.,Thompson Paul M.","Moyer D,Steeg GV,Tax CMW,Thompson PM",Moyer D,10.1002/mrm.28243,University of Southern California,"Purpose In the present work, we describe the correction of diffusion-weighted MRI for site and scanner biases using a novel method based on invariant representation. Theory and Methods Pooled imaging data from multiple sources are subject to variation between the sources. Correcting for these biases has become very important as imaging studies increase in size and multi-site cases become more common. We propose learning an intermediate representation invariant to site/protocol variables, a technique adapted from information theory-based algorithmic fairness; by leveraging the data processing inequality, such a representation can then be used to create an image reconstruction that is uninformative of its original source, yet still faithful to underlying structures. To implement this, we use a deep learning method based on variational auto-encoders (VAE) to construct scanner invariant encodings of the imaging data. Results To evaluate our method, we use training data from the 2018 MICCAI Computational Diffusion MRI (CDMRI) Challenge Harmonization dataset. Our proposed method shows improvements on independent test data relative to a recently published baseline method on each subtask, mapping data from three different scanning contexts to and from one separate target scanning context. Conclusions As imaging studies continue to grow, the use of pooled multi-site imaging will similarly increase. Invariant representation presents a strong candidate for the harmonization of these data.","diffusion MRI,harmonization,invariant representation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"BRAIN,ACQUISITION,RELIABILITY",MAGNETIC RESONANCE IN MEDICINE,http://arxiv.org/pdf/1904.05375,
62,Multi-domain modeling of atrial fibrillation detection with twin attentional convolutional long short-term memory neural networks,193,,,"Jin Yanrui,Qin Chengjin,Huang Yixiang,Zhao Wenyi,Liu Chengliang","Jin YR,Qin CJ,Huang YX,Zhao WY,Liu CL",Liu CL,10.1016/j.knosys.2019.105460,Shanghai Jiao Tong University,"Atrial fibrillation (AF) is a common arrhythmia, and its incidence increases with age. Many methods have been developed to identify AF, including both the hand-picked features by experts and the recent emerging artificial intelligent (AI) methods. As the traditional hand-picked features have almost reached the boundary of their capability, the AI methods have shown their great potentials to achieve high accuracy for the AF identification. However, some common AI methods, especially deep learning methods, do not provide good properties of interpretability, making it difficult to explore the internal relationship between input and prediction results. In addition, most of the reported methods are only for the intra-patient test of AF and Non-AF. In this study, we try to develop an AF detector based on a twin-attentional convolutional long short-term memory neural network (TAC-LSTM), which can not only generate results with high accuracy but also enable a human-friendly function to provide the possible explanations of the automated extracted features by AI. TAC-LSTM was applied to extract multi-domain features of ECG signals for AF detection and to mine the influence of different input segments on the final prediction results. Finally, the proposed method is validated on the MIT-BIH Atrial Fibrillation Database (AFDB) with intra-patient test and inter-patient test and the results also have shown that multi-domain features extracted by TAC-LSTM can provide more useful information. Collectively, TAC-LSTM can be used for clinicians as an auxiliary diagnostic tool. (c) 2020 Elsevier B.V. All rights reserved.","Atrial fibrillation detection,Convolutional long short-term memory neural networks,ECG,Interpretable attention mechanism,Wavelet transform",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,7.842,"COMPUTER-AIDED,DIAGNOSIS,AUTOMATED,DETECTION,ARRHYTHMIAS,CLASSIFICATION,TRANSFORM,INTERVALS,FEATURES",KNOWLEDGE-BASED SYSTEMS,,
63,A mountable toilet system for personalized health monitoring via the analysis of excreta,4,6,624-635,"Park Seung-min,Won Daeyoun D.,Lee Brian J.,Escobedo Diego,Estevas Andre,Aalipour Amin,Ge T. Jessie,Ha Kim Jung,Suh Susie,Choi Elliot H.","Park SM,Won DD,Lee BJ,Escobedo D,Estevas A,Aalipour A,Ge TJ,Ha Kim J,Suh S,Choi EH",Gambhir SS,10.1038/s41551-020-0534-9,Stanford University,"Technologies for the longitudinal monitoring of a person's health are poorly integrated with clinical workflows, and have rarely produced actionable biometric data for healthcare providers. Here, we describe easily deployable hardware and software for the long-term analysis of a user's excreta through data collection and models of human health. The 'smart' toilet, which is self-contained and operates autonomously by leveraging pressure and motion sensors, analyses the user's urine using a standard-of-care colorimetric assay that traces red-green-blue values from images of urinalysis strips, calculates the flow rate and volume of urine using computer vision as a uroflowmeter, and classifies stool according to the Bristol stool form scale using deep learning, with performance that is comparable to the performance of trained medical personnel. Each user of the toilet is identified through their fingerprint and the distinctive features of their anoderm, and the data are securely stored and analysed in an encrypted cloud server. The toilet may find uses in the screening, diagnosis and longitudinal monitoring of specific patient populations.
A 'smart' toilet that uses pressure and motion sensors, biometric identification, urinalysis strips, a computer-vision uroflowmeter and machine learning longitudinally tracks biomarkers of health and disease in the user's urine and stool.","STOOL FORM SCALE,SYNTHETIC URINARY BIOMARKERS,OCCULT BLOOD-TEST,COLORECTAL-CANCER,FECAL CALPROTECTIN,TRACT SYMPTOMS,UROFLOWMETRY,MICROBIOME,RELIABILITY,VALIDITY",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Engineering,,26.355,"STOOL,FORM,SCALE,SYNTHETIC,URINARY,BIOMARKERS,OCCULT,BLOOD-TEST,COLORECTAL-CANCER,FECAL,CALPROTECTIN,TRACT,SYMPTOMS,UROFLOWMETRY,MICROBIOME,RELIABILITY,VALIDITY",NATURE BIOMEDICAL ENGINEERING,https://europepmc.org/articles/pmc7377213?pdf=render,
64,Unsupervised learning in a BCI chess application using label proportions and expectation-maximization,7,1-2,22-35,"Huebner David,Schall Albrecht,Tangermann Michael","Hubner D,Schall A,Tangermann M",Tangermann M,10.1080/2326263X.2020.1741072,University of Freiburg,"The online usage of brain-computer interfaces (BCI) generates unlabeled data. This data in combination with the rich structure contained in BCI applications based on event-related potentials allow to design novel unsupervised classification approaches like learning from label proportions (LLP) or its combination with expectation-maximization (EM) into a mixed model. In this work, we explore the feasibility of unsupervised classification in a BCI chess application. We propose an LLP extension based on weighted least squares regression. It requires randomization of timing parameters but overcomes the dependency on additional symbols. Simulations on electroencephalogram data obtained from six subjects playing BCI-controlled chess show that a combination of unsupervised LLP with EM (despite not using any labels) by constant adaptation quickly reaches and on the long run outperforms the average performance level of non-adaptive supervised classifiers. With our contribution, we increase the scope for which unsupervised learning methods can successfully be applied in BCI.","Unsupervised learning,learning from label proportions,event-related potentials,random SOA,expectation-maximization",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Engineering,Neurosciences & Neurology",,,"BRAIN-COMPUTER,INTERFACES,CLASSIFICATION",BRAIN-COMPUTER INTERFACES,,
65,"Rational Design of Mixed Solvent Systems for Acid-Catalyzed Biomass Conversion Processes Using a Combined Experimental, Molecular Dynamics and Machine Learning Approach",63,7-8,649-663,"Walker Theodore W.,Chew Alex K.,Van Lehn Reid C.,Dumesic James A.,Huber George W.","Walker TW,Chew AK,Van Lehn RC,Dumesic JA,Huber GW",Huber GW,10.1007/s11244-020-01260-9,University of Wisconsin System,"Mixtures of water and organic cosolvents (mixed solvent systems) play an important role in mediating acid-catalyzed biomass conversion reactions. A minimum amount of water is typically required to dissolve biomass-derived materials, while adding an organic cosolvent can enhance the rates and selectivities of the desirable, catalytic reaction steps. Understanding the molecular-level bases underlying these solvent effects would provide a powerful measure of control over the reaction environment for biomass conversion processes, whereby the rates of desired reaction steps could be preferentially enhanced over the undesirable ones by modulating the composition of the solvent system. However, a quantitative basis to anticipate these solvent effects is currently lacking, and optimizing the composition of the liquid phase for new biomass conversion reactions typically requires laborious screening of the continuous space of possible mixed solvent systems. Herein, we summarize our efforts to estimate solvent effects on the rates and selectivities of liquid-phase, acid-catalyzed biomass conversions reactions using experiments, classical molecular dynamics simulations, and machine learning tools. We then synthesize these insights into a workflow that allows for the rational design of mixed solvent systems for acid-catalyzed biomass conversion processes using computationally efficient methods and minimal experiments. We demonstrate this design framework by analyzing two case studies: the acid-catalyzed dehydration of cyclohexanol to cyclohexene, and the partial dehydration of fructose to 5-hydroxymethylfurfural.","Solvent effects,Machine learning,Molecular dynamics,Reaction kinetics,Biomass conversion,Acid catalysts",Article,"SPRINGER/PLENUM PUBLISHERS, 233 SPRING ST, NEW YORK, NY 10013 USA",Chemistry,,2.832,"GENERAL,FORCE-FIELD,TETRAHYDROFURAN-WATER,SELECTIVE,CONVERSION,FRUCTOSE,GLUCOSE,PRETREATMENT,REACTIVITY,SOLVATION,KINETICS,EXCHANGE",TOPICS IN CATALYSIS,,
66,Learning osteoarthritis imaging biomarkers from bone surface spherical encoding,84,4,2190-2203,"Martinez Alejandro Morales,Caliva Francesco,Flament Io,Liu Felix,Lee Jinhee,Cao Peng,Shah Rutwik,Majumdar Sharmila,Pedoia Valentina","Martinez AM,Caliva F,Flament I,Liu F,Lee J,Cao P,Shah R,Majumdar S,Pedoia V",Pedoia V,10.1002/mrm.28251,University of California System,"Purpose To learn bone shape features from spherical bone map of knee MRI images using established convolutional neural networks (CNN) and use these features to diagnose and predict osteoarthritis (OA).
Methods A bone segmentation model was trained on 25 manually annotated 3D MRI volumes to segment the femur, tibia, and patella from 47 078 3D MRI volumes. Each bone segmentation was converted to a 3D point cloud and transformed into spherical coordinates. Different fusion strategies were performed to merge spherical maps obtained by each bone. A total of 41 822 merged spherical maps with corresponding Kellgren-Lawrence grades for radiographic OA were used to train a CNN classifier model to diagnose OA using bone shape learned features. Several OA Diagnosis models were tested and the weights for each trained model were transferred to the OA Incidence models. The OA incidence task consisted of predicting OA from a healthy scan within a range of eight time points, from 1 y to 8 y. The validation performance was compared and the test set performance was reported.
Results The OA Diagnosis model had an area-under-the-curve (AUC) of 0.905 on the test set with a sensitivity and specificity of 0.815 and 0.839. The OA Incidence models had an AUC ranging from 0.841 to 0.646 on the test set for the range from 1 y to 8 y.
Conclusion Bone shape was successfully used as a predictive imaging biomarker for OA. This approach is novel in the field of deep learning applications for musculoskeletal imaging and can be expanded to other OA biomarkers.","bone shape,deep learning,musculoskeletal MRI,osteoarthritis",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"KNEE,OSTEOARTHRITIS,SHAPE,PREVALENCE,DISEASE",MAGNETIC RESONANCE IN MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7329596,
67,Robust Biomarker Screening Using Spares Learning Approach for Liver Cancer Prognosis,8,,,"Kaushik Aman Chandra,Mehmood Aamir,Wei Dong-Qing,Dai Xiaofeng","Kaushik AC,Mehmood A,Wei DQ,Dai XF",Dai XF,10.3389/fbioe.2020.00241,Jiangnan University,"LncRNAs, miRNAs, mRNAs, methylation, and proteins exert profound biological functions and are widely applied as prognostic features in liver cancer. This study aims to identify prognostic biomarkers' signature for liver cancer. Samples with inadequate tumor purity were filtered out and the expression data from different resources were retrieved. The Spares learning approach was applied to select lncRNAs, miRNAs, mRNAs, methylation, and proteins' features based on their differentially expressed groups. The LASSO boosting technique was employed for the predictive model construction. A total of 200 lncRNAs, 200 miRNAs, 371 mRNAs, 371 methylations, and 184 proteins were observed to be differentially expressed. Five lncRNAs, 11 miRNAs, 30 mRNAs, 4 methylations, and 3 proteins were selected for further evaluation using the feature elimination technique. The highest accuracy of 89.32% is achieved as a result of training and learning by Spares learning methodology. Final outcomes revealed that 5 lncRNA, 11 miRNA, 30 mRNA, 4 methylation, and 3 protein signatures could be potential biomarkers for the prognosis of liver cancer patients.","biomarkers,spares learning,liver cancer,prognosis,ncRNA",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND","Biotechnology & Applied Microbiology,Science & Technology - Other Topics",,5.973,BREAST-CANCER,FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY,https://www.frontiersin.org/articles/10.3389/fbioe.2020.00241/pdf,
68,Exploring the configuration spaces of surface materials using time-dependent diffraction patterns and unsupervised learning,10,1,,Packwood Daniel M.,Packwood DM,Packwood DM,10.1038/s41598-020-62782-6,Kyoto University,"Computational methods for exploring the atomic configuration spaces of surface materials will lead to breakthroughs in nanotechnology and beyond. In order to develop such methods, especially ones utilizing machine learning approaches, descriptors which encode the structural features of the candidate configurations are required. In this paper, we propose the use of time-dependent electron diffraction simulations to create descriptors for the configurations of surface materials. Our proposal utilizes the fact that the sub-femtosecond time-dependence of electron diffraction patterns are highly sensitive to the arrangement of atoms in the surface region of the material, allowing one to distinguish configurations which possess identical symmetry but differ in the locations of the atoms in the unit cell. We demonstrate the effectiveness of this approach by considering the simple cases of copper(111) and an organic self-assembled monolayer system, and use it to search for metastable configurations of these materials.",CRYSTAL-STRUCTURE PREDICTION,Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,5.134,"CRYSTAL-STRUCTURE,PREDICTION",SCIENTIFIC REPORTS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7125295,
69,A multimodal computer-aided diagnostic system for precise identification of renal allograft rejection: Preliminary results,47,6,2427-2440,"Shehata Mohamed,Shalaby Ahmed,Switala Andrew E.,El-Baz Maryam,Ghazal Mohammed,Fraiwan Luay,Khalil Ashraf,Abou El-Ghar Mohamed,Badawy Mohamed,Bakr Ashraf M.","Shehata M,Shalaby A,Switala AE,El-Baz M,Ghazal M,Fraiwan L,Khalil A,Abou El-Ghar M,Badawy M,Bakr AM",Shehata M,10.1002/mp.14109,University of Louisville,"Purpose Early assessment of renal allograft function post-transplantation is crucial to minimize and control allograft rejection. Biopsy - the gold standard - is used only as a last resort due to its invasiveness, high cost, adverse events (e.g., bleeding, infection, etc.), and the time for reporting. To overcome these limitations, a renal computer-assisted diagnostic (Renal-CAD) system was developed to assess kidney transplant function.
Methods The developed Renal-CAD system integrates data collected from two image-based sources and two clinical-based sources to assess renal transplant function. The imaging sources were the apparent diffusion coefficients (ADCs) extracted from 47 diffusion-weighted magnetic resonance imaging (DW-MRI) scans at 11 different b-values (b0, b50, b100, ..., b1000 s/mm2), and the transverse relaxation rate (R2*) extracted from 30 blood oxygen level-dependent MRI (BOLD-MRI) scans at 5 different echo times (TEs = 2, 7, 12, 17, and 22 ms). Serum creatinine (SCr) and creatinine clearance (CrCl) were the clinical sources for kidney function evaluation. The Renal-CAD system initially performed kidney segmentation using the level-set method, followed by estimation of the ADCs from DW-MRIs and the R2* from BOLD-MRIs. ADCs and R2* estimates from 30 subjects that have both types of scans were integrated with their associated SCr and CrCl. The integrated biomarkers were then used as our discriminatory features to train and test a deep learning-based classifier, namely stacked autoencoders (SAEs) to differentiate non-rejection (NR) from acute rejection (AR) renal transplants.
Results Using a leave-one-subject-out cross-validation approach along with SAEs, the Renal-CAD system demonstrated 93.3% accuracy, 90.0% sensitivity, and 95.0% specificity in differentiating AR from NR. Robustness of the Renal-CAD system was also confirmed by the area under the curve value of 0.92. Using a stratified tenfold cross-validation approach, the Renal-CAD system demonstrated its reproducibility and robustness by a diagnostic accuracy of 86.7%, sensitivity of 80.0%, specificity of 90.0%, and AUC of 0.88.
Conclusion The obtained results demonstrate the feasibility and efficacy of accurate, noninvasive identification of AR at an early stage using the Renal-CAD system.","ADC,CrCl,Multimodal imaging,R2*,Renal-CAD,SAEs,SCr",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"DIFFUSION-WEIGHTED,MRI,TRANSPLANTED,KIDNEYS,FOLLOW-UP,OXYGENATION,DYSFUNCTION,REPRESENTATION",MEDICAL PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8524762,
70,A method of rapid quantification of patient-specific organ doses for CT using deep-learning-based multi-organ segmentation and GPU-accelerated Monte Carlo dose computing,47,6,2526-2536,"Peng Zhao,Fang Xi,Yan Pingkun,Shan Hongming,Liu Tianyu,Pei Xi,Wang Ge,Liu Bob,Kalra Mannudeep K.,Xu X. George","Peng Z,Fang X,Yan PK,Shan HM,Liu TY,Pei X,Wang G,Liu B,Kalra MK,Xu XG",Xu XG,10.1002/mp.14131,Rensselaer Polytechnic Institute,"Purpose One technical barrier to patient-specific computed tomography (CT) dosimetry has been the lack of computational tools for the automatic patient-specific multi-organ segmentation of CT images and rapid organ dose quantification. When previous CT images are available for the same body region of the patient, the ability to obtain patient-specific organ doses for CT - in a similar manner as radiation therapy treatment planning - will open the door to personalized and prospective CT scan protocols. This study aims to demonstrate the feasibility of combining deep-learning algorithms for automatic segmentation of multiple radiosensitive organs from CT images with the GPU-based Monte Carlo rapid organ dose calculation.
Methods A deep convolutional neural network (CNN) based on the U-Net for organ segmentation is developed and trained to automatically delineate multiple radiosensitive organs from CT images. Two databases are used: The lung CT segmentation challenge 2017 (LCTSC) dataset that contains 60 thoracic CT scan patients, each consisting of five segmented organs, and the Pancreas-CT (PCT) dataset, which contains 43 abdominal CT scan patients each consisting of eight segmented organs. A fivefold cross-validation method is performed on both sets of data. Dice similarity coefficients (DSCs) are used to evaluate the segmentation performance against the ground truth. A GPU-based Monte Carlo dose code, ARCHER, is used to calculate patient-specific CT organ doses. The proposed method is evaluated in terms of relative dose errors (RDEs). To demonstrate the potential improvement of the new method, organ dose results are compared against those obtained for population-average patient phantoms used in an off-line dose reporting software, VirtualDose, at Massachusetts General Hospital.
Results The median DSCs are found to be 0.97 (right lung), 0.96 (left lung), 0.92 (heart), 0.86 (spinal cord), 0.76 (esophagus) for the LCTSC dataset, along with 0.96 (spleen), 0.96 (liver), 0.95 (left kidney), 0.90 (stomach), 0.87 (gall bladder), 0.80 (pancreas), 0.75 (esophagus), and 0.61 (duodenum) for the PCT dataset. Comparing with organ dose results from population-averaged phantoms, the new patient-specific method achieved smaller absolute RDEs (mean +/- standard deviation) for all organs: 1.8% +/- 1.4% (vs 16.0% +/- 11.8%) for the lung, 0.8% +/- 0.7% (vs 34.0% +/- 31.1%) for the heart, 1.6% +/- 1.7% (vs 45.7% +/- 29.3%) for the esophagus, 0.6% +/- 1.2% (vs 15.8% +/- 12.7%) for the spleen, 1.2% +/- 1.0% (vs 18.1% +/- 15.7%) for the pancreas, 0.9% +/- 0.6% (vs 20.0% +/- 15.2%) for the left kidney, 1.7% +/- 3.1% (vs 19.1% +/- 9.8%) for the gallbladder, 0.3% +/- 0.3% (vs 24.2% +/- 18.7%) for the liver, and 1.6% +/- 1.7% (vs 19.3% +/- 13.6%) for the stomach. The trained automatic segmentation tool takes This work shows the feasibility to perform combined automatic patient-specific multi-organ segmentation of CT images and rapid GPU-based Monte Carlo dose quantification with clinically acceptable accuracy and efficiency.","convolutional neural network,CT organ dose,Monte Carlo,multi-organ segmentation,patient-specific",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"NORMAL,TISSUE,TUBE,CURRENT,VALIDATION,SIMULATIONS,TOMOGRAPHY,MODEL",MEDICAL PHYSICS,http://arxiv.org/pdf/1908.00360,
71,Multi-needle Localization with Attention U-Net in US-guided HDR Prostate Brachytherapy,47,7,2735-2745,"Zhang Yupei,Lei Yang,Qiu Richard L. J.,Wang Tonghe,Wang Hesheng,Jani Ashesh B.,Curran Walter J.,Patel Pretesh,Liu Tian,Yang Xiaofeng","Zhang YP,Lei Y,Qiu RLJ,Wang TH,Wang HS,Jani AB,Curran WJ,Patel P,Liu T,Yang XF",Zhang YP,10.1002/mp.14128,Emory University,"Purpose Ultrasound (US)-guided high dose rate (HDR) prostate brachytherapy requests the clinicians to place HDR needles (catheters) into the prostate gland under transrectal US (TRUS) guidance in the operating room. The quality of the subsequent radiation treatment plan is largely dictated by the needle placements, which varies upon the experience level of the clinicians and the procedure protocols. Real-time plan dose distribution, if available, could be a vital tool to provide more subjective assessment of the needle placements, hence potentially improving the radiation plan quality and the treatment outcome. However, due to low signal-to-noise ratio (SNR) in US imaging, real-time multi-needle segmentation in 3D TRUS, which is the major obstacle for real-time dose mapping, has not been realized to date. In this study, we propose a deep learning-based method that enables accurate and real-time digitization of the multiple needles in the 3D TRUS images of HDR prostate brachytherapy.
Methods A deep learning model based on the U-Net architecture was developed to segment multiple needles in the 3D TRUS images. Attention gates were considered in our model to improve the prediction on the small needle points. Furthermore, the spatial continuity of needles was encoded into our model with total variation (TV) regularization. The combined network was trained on 3D TRUS patches with the deep supervision strategy, where the binary needle annotation images were provided as ground truth. The trained network was then used to localize and segment the HDR needles for a new patient's TRUS images. We evaluated our proposed method based on the needle shaft and tip errors against manually defined ground truth and compared our method with other state-of-art methods (U-Net and deeply supervised attention U-Net).
Results Our method detected 96% needles of 339 needles from 23 HDR prostate brachytherapy patients with 0.290 +/- 0.236 mm at shaft error and 0.442 +/- 0.831 mm at tip error. For shaft localization, our method resulted in 96% localizations with less than 0.8 mm error (needle diameter is 1.67 mm), while for tip localization, our method resulted in 75% needles with 0 mm error and 21% needles with 2 mm error (TRUS image slice thickness is 2 mm). No significant difference is observed (P = 0.83) on tip localization between our results with the ground truth. Compared with U-Net and deeply supervised attention U-Net, the proposed method delivers a significant improvement on both shaft error and tip error (P < 0.05).
Conclusions We proposed a new segmentation method to precisely localize the tips and shafts of multiple needles in 3D TRUS images of HDR prostate brachytherapy. The 3D rendering of the needles could help clinicians to evaluate the needle placements. It paves the way for the development of real-time plan dose assessment tools that can further elevate the quality and outcome of HDR prostate brachytherapy.","deep learning,multi-needle localization,prostate brachytherapy,total variation regularization,ultrasound images",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"ULTRASOUND,RATIONALE,TRACKING,RANSAC",MEDICAL PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7759387,
72,OffsampleAI: artificial intelligence approach to recognize off-sample mass spectrometry images,21,1,,"Ovchinnikova Katja,Kovalev Vitaly,Stuart Lachlan,Alexandrov Theodore","Ovchinnikova K,Kovalev V,Stuart L,Alexandrov T",Alexandrov T,10.1186/s12859-020-3425-x,European Molecular Biology Laboratory (EMBL),"Background Imaging mass spectrometry (imaging MS) is an enabling technology for spatial metabolomics of tissue sections with rapidly growing areas of applications in biology and medicine. However, imaging MS data is polluted with off-sample ions caused by sample preparation, particularly by the MALDI (matrix-assisted laser desorption/ionization) matrix application. Off-sample ion images confound and hinder statistical analysis, metabolite identification and downstream analysis with no automated solutions available. Results We developed an artificial intelligence approach to recognize off-sample ion images. First, we created a high-quality gold standard of 23,238 expert-tagged ion images from 87 public datasets from the METASPACE knowledge base. Next, we developed several machine and deep learning methods for recognizing off-sample ion images. The following methods were able to reproduce expert judgements with a high agreement: residual deep learning (F1-score 0.97), semi-automated spatio-molecular biclustering (F1-score 0.96), and molecular co-localization (F1-score 0.90). In a test-case study, we investigated off-sample images corresponding to the most common MALDI matrix (2,5-dihydroxybenzoic acid, DHB) and characterized properties of matrix clusters. Conclusions Overall, our work illustrates how artificial intelligence approaches enabled by open-access data, web technologies, and machine and deep learning open novel avenues to address long-standing challenges in imaging MS.","Imaging mass spectrometry,Off-sample images,Pattern recognition,Machine learning,Deep learning,Artificial intelligence,METASPACE",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,"MATRIX,MALDI",BMC BIOINFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7119286,
73,Quantifying accuracy of stochastic methods of reconstructing complex materials by deep learning,101,4,,"Kamrava Serveh,Sahimi Muhammad,Tahmasebi Pejman","Kamrava S,Sahimi M,Tahmasebi P",Sahimi M,10.1103/PhysRevE.101.043301,University of Southern California,"Time and cost are two main hurdles to acquiring a large number of digital image I of the microstructure of materials. Thus, use of stochastic methods for producing plausible realizations of materials' morphology based on one or very few images has become an increasingly common practice in their modeling. The accuracy of the realizations is often evaluated using two-point microstructural descriptors or physics-based modeling of certain phenomena in the materials, such as transport processes or fluid flow. In many cases, however, two-point correlation functions do not provide accurate evaluation of the realizations, as they are usually unable to distinguish between high- and low-quality reconstructed models. Calculating flow and transport properties of the realization is an accurate way of checking the quality of the realizations, but it is computationally expensive. In this paper a method based on machine learning is proposed for evaluating stochastic approaches for reconstruction of materials, which is applicable to any of such methods. The method reduces the dimensionality of the realizations using an unsupervised deep-learning algorithm by compressing images and realizations of materials. Two criteria for evaluating the accuracy of a reconstruction algorithm are then introduced. One, referred to as the internal uncertainty space, is based on the recognition that for a reconstruction method to be effective, the differences between the realizations that it produces must be reasonably wide, so that they faithfully represent all the possible spatial variations in the materials' microstructure. The second criterion recognizes that the realizations must be close to the original I and, thus, it quantifies the similarity based on an external uncertainty space. Finally, the ratio of two uncertainty indices associated with the two criteria is considered as the final score of the accuracy of a stochastic algorithm, which provides a quantitative basis for comparing various realizations and the approaches that produce them. The proposed method is tested with images of three types of heterogeneous materials in order to evaluate four stochastic reconstruction algorithms.","CONDITIONAL SIMULATION,POROUS-MEDIA,MICROSTRUCTURE,COALESCENCE,TOMOGRAPHY,EVOLUTION,TRANSPORT,POROSITY,GROWTH",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,2.414,"CONDITIONAL,SIMULATION,POROUS-MEDIA,MICROSTRUCTURE,COALESCENCE,TOMOGRAPHY,EVOLUTION,TRANSPORT,POROSITY,GROWTH",PHYSICAL REVIEW E,,
74,Neural network agent playing spin Hamiltonian games on a quantum computer,53,13,,"Sotnikov Oleg M.,Mazurenko Vladimir V.","Sotnikov OM,Mazurenko VV",Sotnikov OM,10.1088/1751-8121/ab73ad,Ural Federal University,"Quantum computing is expected to provide new promising approaches for solving the most challenging problems in material science, communication, search, machine learning and other domains. However, due to the decoherence and gate imperfection errors modern quantum computer systems are characterized by a very complex, dynamical, uncertain and fluctuating computational environment. We develop an autonomous agent effectively interacting with such an environment to solve magnetism problems. By using reinforcement learning the agent is trained to find the best-possible approximation of a spin Hamiltonian ground state from self-play on quantum devices. We show that the agent can learn the entanglement to imitate the ground state of the quantum spin dimer. The experiments were conducted on quantum computers provided by IBM. To compensate the decoherence we use a local spin correction procedure derived from a general sum rule for spin-spin correlation functions of a quantum system with an even number of antiferromagnetically-coupled spins in the ground state. Our study paves a way to create a new family of neural network eigensolvers for quantum computers.","quantum computing,machine learning,spin models,reinforcement learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,1.998,GO,JOURNAL OF PHYSICS A-MATHEMATICAL AND THEORETICAL,http://arxiv.org/pdf/1904.02467,
75,,,,,,,,,,,,,,,,,,,,
76,,,,,,,,,,,,,,,,,,,,
77,A model for predicting the risk of musculoskeletal disorders among computer professionals,26,2,384-396,"Sasikumar Vishnu,Binoosh Second Champakkadayil Abdul Basheer","Sasikumar V,Binoosh SCAB",Sasikumar V,10.1080/10803548.2018.1480583,"College of Engineering, Trivandrum","Objective. This study aimed to develop a model for predicting the risk of musculoskeletal disorders among computer professionals. Materials and methods. A preliminary study with a modified Nordic musculoskeletal questionnaire was conducted to identify the risk in different body parts of the professionals during their work. A discrete postural evaluation of the dynamic postures involved in the work was assessed using rapid upper limb assessment. Postural, physiological and work-related factors were considered as attributes of the model. The model was developed using various machine learning algorithms, and was then tested and validated. Results. The postural factor of the computer professionals was found to be significantly (p < 0.01) correlated with the musculoskeletal disorders. Results of the logistic regression analysis showed that physiological and work-related factors were also significantly (p < 0.05) associated with musculoskeletal disorders. The Random Forest algorithm and Naive Bayes Classifier predicted the risk of musculoskeletal disorders with the highest accuracy (81.25%). Conclusion. Postural, physiological and work-related factors contribute to the development of musculoskeletal disorders. The Random Forest algorithm or Naive Bayes Classifier model developed based on these factors could be used to accurately predict the risk of musculoskeletal disorders among computer professionals at any instance of time, during their work.","musculoskeletal disorders,rapid upper limb assessment,predictive modelling,machine learning",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Engineering,Public, Environmental & Occupational Health",,2.011,"WORK,USERS,PREVALENCE,SYMPTOMS,SYSTEM,STRAIN,LOADS,RULA,OCRA,JOB",INTERNATIONAL JOURNAL OF OCCUPATIONAL SAFETY AND ERGONOMICS,,
78,Adaptive self-learning mechanisms for updating short-term production decisions in an industrial mining complex,31,7,1795-1811,"Kumar Ashish,Dimitrakopoulos Roussos,Maulen Marco","Kumar A,Dimitrakopoulos R,Maulen M",Kumar A,10.1007/s10845-020-01562-5,McGill University,"A mining complex is an integrated value chain where the materials extracted from a group of mineral deposits are sent to different processing streams to produce sellable products. A major short-term decision in a mining complex is to determine the flow of materials that first includes deciding which handling facilities to send the extracted materials and then determining how to utilize the processing facilities. The flow of materials through the mining complex is significantly dependent on the performance of and interaction between its different components. New digital technologies, including the development of advanced sensors and monitoring devices, have enabled a mining complex to acquire new information about the performance of its different components. This paper proposes a new continuous updating framework that combines policy gradient reinforcement learning and an extended ensemble Kalman filter to adapt the short-term flow of materials in a mining complex with incoming information. The framework first uses a new extended ensemble Kalman filter to update the uncertainty models of the different components of a mining complex with new incoming information. Then, the updated uncertainty models are fed to a neural network trained using a policy gradient reinforcement learning algorithm to adapt the short-term flow of materials in a mining complex. The proposed framework is applied to a copper mining complex and shows its ability to efficiently adapt the short-term flow of materials in an operational mining environment with new incoming information. The framework better meets the different production targets while improving the cumulative cash flow compared to industry standard approaches.","Mining complex,Production planning,Artificial intelligence,Reinforcement learning,Sensor information,Ensemble Kalman filter,Real-time,Destination policies,Deep learning",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,5.829,"DATA,ASSIMILATION,OPTIMIZATION,MODEL,SIMULATION,RECONCILIATION,CLASSIFICATION,UNCERTAINTY,INFORMATION,ORE",JOURNAL OF INTELLIGENT MANUFACTURING,https://link.springer.com/content/pdf/10.1007/s10845-020-01562-5.pdf,
79,A Generic Machine Learning Algorithm for the Prediction of Gas Adsorption in Nanoporous Materials,124,13,7117-7126,"Fanourgakis George S.,Gkagkas Konstantinos,Tylianakis Emmanuel,Froudakis George","Fanourgakis GS,Gkagkas K,Tylianakis E,Froudakis G",Fanourgakis GS; Froudakis G,10.1021/acs.jpcc.9b10766,University of Crete,"In the present study, we propose a new set of descriptors, appropriate for machine learning (ML) methods, aiming to predict accurately the gas adsorption capacities of nanoporous materials. The present work focuses on systems with nonnegligible electrostatic interactions between the materials' framework and the guest gas. For that, the CO2, H-2, and H2S gases are examined. The present approach is a generalization of our recent development for guest gases with no electrostatic interactions, such as CH4. For both types of systems, as ML descriptors we consider the adsorption probabilities by the materials' framework of a small number of probe atoms with different van der Waals diameters. After examination and evaluation of various numerical schemes, probe atoms that carry in their centers an electric dipole are found to be the most appropriate for systems with electrostatic interactions. The accuracy of the present approach is assessed by comparing the ML predictions with a data set of reference results obtained after performing grand canonical Monte Carlo (GCMC) simulations. More specifically, the CO2, H-2, and H2S adsorption capacities of the computation-ready, experimental (CoRE) MOFs at several different thermodynamic conditions are considered. The low computational cost for the calculation of the proposed set of ML descriptors allows the screening of very large databases.","METAL-ORGANIC FRAMEWORKS,CHARGES,TOOLS",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,4.467,"METAL-ORGANIC,FRAMEWORKS,CHARGES,TOOLS",JOURNAL OF PHYSICAL CHEMISTRY C,,
80,Understanding and Predicting the Cause of Defects in Graphene Oxide Nanostructures Using Machine Learning,124,13,7404-7413,"Motevalli Benyamin,Sun Baichuan,Barnard Amanda S.","Motevalli B,Sun BC,Barnard AS",Barnard AS,10.1021/acs.jpcc.9b10615,Australian National University,"Machine learning is a powerful way of uncovering hidden structure/property relationships in nanoscale materials, and it is tempting to assign structural causes to properties based on feature rankings reported by interpretable models. In this study of defective graphene oxide nanoflakes, we use classification, regression, and causal inference to show that not all important structural features directly influence the concentration of broken bonds, as a representative property. We find that while the presence of oxygen is important for actual bond breakage the presence and distribution of hydrogen determines how often bond breakage occurs.","ELECTRONIC-PROPERTIES,STRUCTURE/PROPERTY RELATIONSHIPS,INFERENCE,FUNCTIONALIZATION,STATISTICS,REDUCTION,MEMBRANES,NETWORKS",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,4.467,"ELECTRONIC-PROPERTIES,STRUCTURE%2FPROPERTY,RELATIONSHIPS,INFERENCE,FUNCTIONALIZATION,STATISTICS,REDUCTION,MEMBRANES,NETWORKS",JOURNAL OF PHYSICAL CHEMISTRY C,,
81,,,,,,,,,,,,,,,,,,,,
82,Depression screening using mobile phone usage metadata: a machine learning approach,27,4,522-530,"Razavi Rouzbeh,Gharipour Amin,Gharipour Mojgan","Razavi R,Gharipour A,Gharipour M",Razavi R,10.1093/jamia/ocz221,Kent State University,"Objective: Depression is currently the second most significant contributor to non-fatal disease burdens globally. While it is treatable, depression remains undiagnosed in many cases. As mobile phones have now become an integral part of daily life, this study examines the possibility of screening for depressive symptoms continuously based on patients' mobile usage patterns.
Materials and Methods: 412 research participants reported a range of their mobile usage statistics. Beck Depression Inventory-2nd ed (BDI-II) was used to measure the severity of depression among participants. A wide array of machine learning classification algorithms was trained to detect participants with depression symptoms (ie, BDI-II score >= 14). The relative importance of individual variables was additionally quantified.
Results: Participants with depression were found to have fewer saved contacts on their devices, spend more time on their mobile devices to make and receive fewer and shorter calls, and send more text messages than participants without depression. The best model was a random forest classifier, which had an out-of-sample balanced accuracy of 0.768. The balanced accuracy increased to 0.811 when participants' age and gender were included.
Discussions/Conclusion: The significant predictive power of mobile usage attributes implies that, by collecting mobile usage statistics, mental health mobile applications can continuously screen for depressive symptoms for initial diagnosis or for monitoring the progress of ongoing treatments. Moreover, the input variables used in this study were aggregated mobile usage metadata attributes, which has low privacy sensitivity making it more likely for patients to grant required application permissions.","depression,mobile usage,mobile health,machine learning",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"PSYCHOMETRIC,PROPERTIES,INVENTORY-II,BDI-II,VALIDITY,DEVICES,ADULTS",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647279,
83,Does BERT need domain adaptation for clinical negation detection?,27,4,584-591,"Lin Chen,Bethard Steven,Dligach Dmitriy,Sadeque Farig,Savova Guergana,Miller Timothy A.","Lin C,Bethard S,Dligach D,Sadeque F,Savova G,Miller TA",Miller TA,10.1093/jamia/ocaa001,Harvard University,"Introduction: Classifying whether concepts in an unstructured clinical text are negated is an important unsolved task. New domain adaptation and transfer learning methods can potentially address this issue.
Objective: We examine neural unsupervised domain adaptation methods, introducing a novel combination of domain adaptation with transformer-based transfer learning methods to improve negation detection. We also want to better understand the interaction between the widely used bidirectional encoder representations from transformers (BERT) system and domain adaptation methods.
Materials and Methods: We use 4 clinical text datasets that are annotated with negation status. We evaluate a neural unsupervised domain adaptation algorithm and BERT, a transformer-based model that is pretrained on massive general text datasets. We develop an extension to BERT that uses domain adversarial training, a neural domain adaptation method that adds an objective to the negation task, that the classifier should not be able to distinguish between instances from 2 different domains.
Results: The domain adaptation methods we describe show positive results, but, on average, the best performance is obtained by plain BERT (without the extension). We provide evidence that the gains from BERT are likely not additive with the gains from domain adaptation.
Discussion: Our results suggest that, at least for the task of clinical negation detection, BERT subsumes domain adaptation, implying that BERT is already learning very general representations of negation phenomena such that fine-tuning even on a specific corpus does not lead to much overfitting.
Conclusion: Despite being trained on nonclinical text, the large training sets of models like BERT lead to large gains in performance for the clinical negation detection task.","natural language processing,machine learning,domain adaptation,deep learning,negation",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7075528,
84,"Physician understanding, explainability, and trust in a hypothetical machine learning risk calculator",27,4,592-600,"Diprose William K.,Buist Nicholas,Hua Ning,Thurier Quentin,Shand George,Robinson Reece","Diprose WK,Buist N,Hua N,Thurier Q,Shand G,Robinson R",Diprose WK,10.1093/jamia/ocz229,University of Auckland,"Objective: Implementation of machine learning (ML) may be limited by patients' right to ""meaningful information about the logic involved"" when ML influences healthcare decisions. Given the complexity of healthcare decisions, it is likely that ML outputs will need to be understood and trusted by physicians, and then explained to patients. We therefore investigated the association between physician understanding of ML outputs, their ability to explain these to patients, and their willingness to trust the ML outputs, using various ML explainability methods.
Materials and Methods: We designed a survey for physicians with a diagnostic dilemma that could be resolved by an ML risk calculator. Physicians were asked to rate their understanding, explainability, and trust in response to 3 different ML outputs. One ML output had no explanation of its logic (the control) and 2 ML outputs used different model-agnostic explainability methods. The relationships among understanding, explainability, and trust were assessed using Cochran-Mantel-Haenszel tests of association.
Results: The survey was sent to 1315 physicians, and 170 (13%) provided completed surveys. There were significant associations between physician understanding and explainability (P<.001), between physician understanding and trust (P<.001), and between explainability and trust (P<.001). ML outputs that used modelagnostic explainability methods were preferred by 88% of physicians when compared with the control condition; however, no particular ML explainability method had a greater influence on intended physician behavior.
Conclusions: Physician understanding, explainability, and trust in ML risk calculators are related. Physicians preferred ML outputs accompanied by model-agnostic explanations but the explainability method did not alter intended physician behavior.","artificial intelligence,explainability,interpretability,decision support,medicine",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"ARTIFICIAL-INTELLIGENCE,PULMONARY-EMBOLISM,MODEL,CLASSIFICATION,ACCEPTANCE,PREDICTION,EMERGENCY",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647292,
85,Brine-Oil Interfacial Tension Modeling: Assessment of Machine Learning Techniques Combined with Molecular Dynamics,12,13,15837-15843,"Kirch Alexsandro,Celaschi Yuri M.,de Almeida James M.,Miranda Caetano R.","Kirch A,Celaschi YM,de Almeida JM,Miranda CR",Miranda CR,10.1021/acsami.9b22189,Universidade de Sao Paulo,"The physical chemistry mechanisms behind the oil-brine interface phenomena are not yet fully clarified. The knowledge of the relation between brine composition and concentration for a given oil may lead to the ionic tuning of the injected solution on geochemical and enhanced oil recovery processes. Thus, it is worth examining the parameters influencing the interfacial properties. In this context, we have combined machine learning (ML) techniques with classical molecular dynamics simulations (MD) to predict oil/brine interfacial tensions (IFT) effectively and compared this process to a linear regression (LR) method. To diversify our data set, we have introduced a new atomistic crude oil model (medium) with 36 different types of hydrocarbon molecules. The MD simulations were performed for mono- and multicomponent (toluene, heptane, Heptol, light, and medium) oil systems interfaced with sulfate and chloride brines with varying cations (Na2+, K+, Ca2+, and Mg2+) and salinity concentration. Thus, a consistent IFT data set was built for the ML training and LR fitting at room temperature and pressure conditions, over the feature space considering oil density, oil composition, salinity, and ionic concentrations. On the basis of gradient boosted (GB) algorithms, we have observed that the dominant quantities affecting the IFT are related to the oil attributes and the salinity concentration, and no specific ion dominates the IFT changes. When the obtained LR model was validated against MD and experimental data from the literature, the error varied up to 2% and 9%, respectively, showing a robust and consistent transferability. The combination of MD simulations and ML techniques may provide a fast and cost-effective IFT determination over multiple and complex fluid-fluid and fluid-solid interfaces.","machine learning,molecular dynamics simulations,oil/brine interface,medium oil model,linear regression model,feature importance analysis",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science",,9.57,"FORCE-FIELD,SIMULATIONS,SALINITY,RECOVERY,TEMPERATURE,SYSTEMS,NACL",ACS APPLIED MATERIALS & INTERFACES,,
86,Experimental Study Comparing the Effectiveness of Physical Isolation and ANN Digital Compensation Methodologies at Eliminating the Stress Wave Effect Error on Piezoelectric Pressure Sensor,20,8,,"Feng Lei,Ma Tiehua","Feng L,Ma TH",Feng L,10.3390/s20082397,North University of China,"Stress wave, accompanied by explosion shock wave overpressure measurement and dynamic pressure calibration on shock tube, could cause error signals in the piezoelectric pressure sensor (PPS) used for measuring and calibrating. We may call this error the stress wave effect (SWE). In this paper, the SWE and its isolation from PPS were studied by using a split Hopkinson pressure bar (SHPB). In the experimental study of SWE, when increasing the input stress, the corresponding output signal of the PPS was analyzed, and the existence of SWE was verified using the result of the spectrum analysis of the output signal. The stress wave isolation pedestal used in the stress wave isolation experiment was made of nylon and plexiglass polymer materials. The effects of the isolation pedestal's materials and length on the stress wave isolation were analyzed using the study results. Finally, an artificial neural network (ANN) was trained with the data of the SWE study and was further applied to compensate the SWE error of the PPS output signal. The compensating results were compared with the isolating results, and the advantages and disadvantages of the digital compensation and physical isolation methods were analyzed.","piezoelectric pressure sensor (PPS),stress wave effect (SWE),split Hopkinson pressure bar (SHPB),physical isolation,digital compensation,artificial neural network (ANN)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"CALIBRATION,BEHAVIOR",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7219595,
87,Stack ensembled model to measure size and mass of almond kernels,43,4,,"Vidyarthi Sriram K.,Tiwari Rakhee,Singh Samrendra K.","Vidyarthi SK,Tiwari R,Singh SK",Vidyarthi SK,10.1111/jfpe.13374,"Morning Star Co, Woodland, CA 95695 USA.","After harvesting almond crop, accurate measurement of almond kernel sizes is a significant specification to plan, develop and enhance almond processing operations. The size and mass of the individual almond kernels are vital parameters usually associated with almond quality and yield. In this study, we propose a novel methodology that combines image processing and machine-learning ensemble that accurately measures the size and mass of whole raw almond kernels (classification-Nonpareil) simultaneously. We have developed an image-processing algorithm using recursive method to identify the individual almond kernels from an image and estimate the size of the kernels based on the occupied pixels by a kernel. The number of pixels representing an almond kernel was used as its digital fingerprint to predict its size and mass. Various popular machine learning (ML) models were implemented to build a stacked ensemble model (SEM), predicting the mass of the individual almond kernels based on the features derived from the pixels of the individual kernels in the image. The prediction accuracy and robustness of image processing and SEM were analyzed using uncertainty quantification. The mean error in estimating the average length of 1,000 almond kernel was 3.12%. Similarly, mean errors associated with predicting the 1,000 kernel mass were 0.63%. The developed algorithm in almond imaging in this study can be used to facilitate a rapid almond yield and quality appraisals.","CLASSIFICATION,SEGMENTATION,SHAPE,TREE",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Food Science & Technology",,2.417,"CLASSIFICATION,SEGMENTATION,SHAPE,TREE",JOURNAL OF FOOD PROCESS ENGINEERING,,
88,Multispectral imaging for predicting the water status in mushroom during hot-air dehydration,85,4,903-909,"Younas Shoaib,Liu Changhong,Qu Hao,Mao Yu,Liu Wei,Wei Liyang,Yan Ling,Zheng Lei","Younas S,Liu CH,Qu H,Mao Y,Liu W,Wei LY,Yan L,Zheng L",Mao Y; Zheng L,10.1111/1750-3841.15081,Hefei University of Technology,"In-depth understanding of the shifting of water status during dehydration is crucial for obtaining better quality of dried food. In this work, we report a nondestructive method to measure the water status in hot-air dried mushroom via multispectral imaging (MSI) technology combined with chemometric methods. The low-field nuclear magnetic resonance (LF-NMR) measurements were performed as reference. During drying process, the moisture content changed dramatically with notable migration and conversion of different water phases. Partial least squares (PLS), back propagation neural network (BPNN), and least squares-support vector machine (LS-SVM) models were applied to develop quantitative models. Among all, BPNN model showed considerably better performance of prediction with coefficient of determination R(2)c = 0.9829, R(2)p = 0.9639. The results demonstrated that MSI technology combined with chemometric methods is an impressive approach for determination of the water status in hot-air dried mushrooms, which would facilitate infield of food processing by providing applicable and appropriate platform.
Practical Application Experimental investigation of different water status during food processing. Assessment of the potential of multispectral imaging to predict water status. Usage of novel measurement method for food processors.","hot-air drying,multispectral imaging,mushroom,nondestructive technique,water status",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Food Science & Technology,,3.377,"NONDESTRUCTIVE,DETERMINATION,DRYING,METHODS,QUALITY,PORK,BEEF,NMR,FEASIBILITY,STORAGE,POWDER,COLOR",JOURNAL OF FOOD SCIENCE,,
89,Wearable Sensor-Based Gait Analysis for Age and Gender Estimation,20,8,,"Ahad Md Atiqur Rahman,Thanh Trung Ngo,Antar Anindya Das,Ahmed Masud,Hossain Tahera,Muramatsu Daigo,Makihara Yasushi,Inoue Sozo,Yagi Yasushi","Ahad MAR,Ngo TT,Antar AD,Ahmed M,Hossain T,Muramatsu D,Makihara Y,Inoue S,Yagi Y",Ahad MAR,10.3390/s20082424,Osaka University,"Wearable sensor-based systems and devices have been expanded in different application domains, especially in the healthcare arena. Automatic age and gender estimation has several important applications. Gait has been demonstrated as a profound motion cue for various applications. A gait-based age and gender estimation challenge was launched in the 12th IAPR International Conference on Biometrics (ICB), 2019. In this competition, 18 teams initially registered from 14 countries. The goal of this challenge was to find some smart approaches to deal with age and gender estimation from sensor-based gait data. For this purpose, we employed a large wearable sensor-based gait dataset, which has 745 subjects (357 females and 388 males), from 2 to 78 years old in the training dataset; and 58 subjects (19 females and 39 males) in the test dataset. It has several walking patterns. The gait data sequences were collected from three IMUZ sensors, which were placed on waist-belt or at the top of a backpack. There were 67 solutions from ten teams-for age and gender estimation. This paper extensively analyzes the methods and achieved-results from various approaches. Based on analysis, we found that deep learning-based solutions lead the competitions compared with conventional handcrafted methods. We found that the best result achieved 24.23% prediction error for gender estimation, and 5.39 mean absolute error for age estimation by employing angle embedded gait dynamic image and temporal convolution network.","gait,recognition,wearable sensor,age estimation,gender,smartphone",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"ELDERLY-PEOPLE,WALKING,SPEED,PERFORMANCE,RECOGNITION,ADULTS",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7219505,
90,"Predictive Maintenance for Pump Systems and Thermal Power Plants: State-of-the-Art Review, Trends and Challenges",20,8,,"Olesen Jonas Fausing,Shaker Hamid Reza","Olesen JF,Shaker HR",Shaker HR,10.3390/s20082425,University of Southern Denmark,"Thermal power plants are an important asset in the current energy infrastructure, delivering ancillary services, power, and heat to their respective consumers. Faults on critical components, such as large pumping systems, can lead to material damage and opportunity losses. Pumps plays an essential role in various industries and as such clever maintenance can ensure cost reductions and high availability. Prognostics and Health Management, PHM, is the study utilizing data to estimate the current and future conditions of a system. Within the field of PHM, Predictive Maintenance, PdM, has been gaining increased attention. Data-driven models can be built to estimate the remaining-useful-lifetime of complex systems that would be difficult to identify by man. With the increased attention that the Predictive Maintenance field is receiving, review papers become increasingly important to understand what research has been conducted and what challenges need to be addressed. This paper does so by initially conceptualising the PdM field. A structured overview of literature in regard to application within PdM is presented, before delving into the domain of thermal power plants and pump systems. Finally, related challenges and trends will be outlined. This paper finds that a large number of experimental data-driven models have been successfully deployed, but the PdM field would benefit from more industrial case studies. Furthermore, investigations into the scale-ability of models would benefit industries that are looking into large-scale implementations. Here, examining a method for automatic maintenance of the developed model will be of interest. This paper can be used to understand the PdM field as a broad concept but does also provide a niche understanding of the domain in focus.","machine learning,predictive maintenance,remaining useful lifetime,state of the art review",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"REMAINING,USEFUL,LIFE,PERFORMANCE,DEGRADATION,ASSESSMENT,COMBINED,HEAT,MACHINE,PROGNOSTICS,FRAMEWORK,CLASSIFICATION,ALGORITHMS,REGRESSION,SIGNALS",SENSORS,https://www.mdpi.com/1424-8220/20/8/2425/pdf,
91,Development and Evaluation of a New Spectral Disease Index to Detect Wheat Fusarium Head Blight Using Hyperspectral Imaging,20,8,,"Zhang Dongyan,Wang Qian,Lin Fenfang,Yin Xun,Gu Chunyan,Qiao Hongbo","Zhang DY,Wang Q,Lin FF,Yin X,Gu CY,Qiao HB",Qiao HB,10.3390/s20082260,Anhui University,"Fusarium head blight (FHB) is a major disease threatening worldwide wheat production. FHB is a short cycle disease and is highly destructive under conducive environments. To provide technical support for the rapid detection of the FHB disease, we proposed to develop a new Fusarium disease index (FDI) based on the spectral data of 374-1050 nm. This study was conducted through the analysis of reflectance spectral data of healthy and diseased wheat ears at the flowering and filling stages by hyperspectral imaging technology and the random forest method. The characteristic wavelengths selected were 570 nm and 678 nm for the late flowering stage, 565 nm and 661 nm for the early filling stage, 560 nm and 663 nm for the combined stage (combining both flowering and filling stages) by random forest. FDI at each stage was derived from the wavebands of each corresponding stage. Compared with other 16 existing spectral indices, FDI demonstrated a stronger ability to determine the severity of the FHB disease. Its determination coefficients (R-2) values exceeded 0.90 and the RMSEs were less than 0.08 in the models for each stage. Furthermore, the model for the combined stage performed better when used at single growth stage, but its effect was weaker than that of the models for the two individual growth stages. Therefore, using FDI can provide a new tool to detect the FHB disease at different growth stages in wheat.","hyperspectral imaging,spectral indices,random forest,growth stage,Fusarium head blight",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"REFLECTANCE,INDEXES,CHLOROPHYLL,CONTENT,VEGETATION,INDEXES,CANOPY,LEAF,GREEN,PREDICTION,LEAVES",SENSORS,https://europepmc.org/articles/pmc7219049?pdf=render,
92,Anti-tumour immune response in GL261 glioblastoma generated by Temozolomide Immune-Enhancing Metronomic Schedule monitored with MRSI-based nosological images,33,4,,"Wu Shuang,Calero-Perez Pilar,Villamanan Lucia,Arias-Ramos Nuria,Pumarola Marti,Ortega-Martorell Sandra,Julia-Sape Margarida,Arus Carles,Candiota Ana Paula","Wu S,Calero-Perez P,Villamanan L,Arias-Ramos N,Pumarola M,Ortega-Martorell S,Julia-Sape M,Arus C,Candiota AP",Candiota AP,10.1002/nbm.4229,CIBER - Centro de Investigacion Biomedica en Red,"Glioblastomas (GB) are brain tumours with poor prognosis even after aggressive therapy. Improvements in both therapeutic and follow-up strategies are urgently needed. In previous work we described an oscillatory pattern of response to Temozolomide (TMZ) using a standard administration protocol, detected through MRSI-based machine learning approaches. In the present work, we have introduced the Immune-Enhancing Metronomic Schedule (IMS) with an every 6-d TMZ administration at 60 mg/kg and investigated the consistence of such oscillatory behaviour. A total of n = 17 GL261 GB tumour-bearing C57BL/6j mice were studied with MRI/MRSI every 2 d, and the oscillatory behaviour (6.2 +/- 1.5 d period from the TMZ administration day) was confirmed during response. Furthermore, IMS-TMZ produced significant improvement in mice survival (22.5 +/- 3.0 d for controls vs 135.8 +/- 78.2 for TMZ-treated), outperforming standard TMZ treatment. Histopathological correlation was investigated in selected tumour samples (n = 6) analyzing control and responding fields. Significant differences were found for CD3+ cells (lymphocytes, 3.3 +/- 2.5 vs 4.8 +/- 2.9, respectively) and Iba-1 immunostained area (microglia/macrophages, 16.8% +/- 9.7% and 21.9% +/- 11.4%, respectively). Unexpectedly, during IMS-TMZ treatment, tumours from some mice (n = 6) fully regressed and remained undetectable without further treatment for 1 mo. These animals were considered ""cured"" and a GL261 re-challenge experiment performed, with no tumour reappearance in five out of six cases. Heterogeneous therapy response outcomes were detected in tumour-bearing mice, and a selected group was investigated (n = 3 non-responders, n = 6 relapsing tumours, n = 3 controls). PD-L1 content was found ca. 3-fold increased in the relapsing group when comparing with control and non-responding groups, suggesting that increased lymphocyte inhibition could be associated to IMS-TMZ failure. Overall, data suggest that host immune response has a relevant role in therapy response/escape in GL261 tumours under IMS-TMZ therapy. This is associated to changes in the metabolomics pattern, oscillating every 6 d, in agreement with immune cycle length, which is being sampled by MRSI-derived nosological images.","glioma,immune memory,TMZ,immune response,metronomic therapy,orthotopic tumours,PD-L1",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Biophysics,Radiology, Nuclear Medicine & Medical Imaging,Spectroscopy",,3.988,"RANDOMIZED,PHASE-III,MOUSE,GLIOMA,BRAIN-TUMORS,CANCER,PERTURBATION,PATTERN,PD-L1,EXPRESSION,SURVIVAL,MODEL",NMR IN BIOMEDICINE,https://researchonline.ljmu.ac.uk/id/eprint/11715/7/Anti-tumour%20immune%20response%20in%20GL261%20glioblastoma%20generated%20by%20Temozolomide%20Immune-Enhancing%20Metronomic%20Schedule%20monitored%20with%20MRSI-based%20nosological%20images.pdf,
93,Arrhythmia Diagnosis by Using Level-Crossing ECG Sampling and Sub-Bands Features Extraction for Mobile Healthcare,20,8,,"Qaisar Saeed Mian,Hussain Syed Fawad","Qaisar SM,Hussain SF",Qaisar SM,10.3390/s20082252,Effat University,"Mobile healthcare is an emerging technique for clinical applications. It is usually based on cloud-connected biomedical implants. In this context, a novel solution is presented for the detection of arrhythmia by using electrocardiogram (ECG) signals. The aim is to achieve an effective solution by using real-time compression, efficient signal processing, and data transmission. The system utilizes level-crossing-based ECG signal sampling, adaptive-rate denoising, and wavelet-based sub-band decomposition. Statistical features are extracted from the sub-bands and used for automated arrhythmia classification. The performance of the system was studied by using five classes of arrhythmia, obtained from the MIT-BIH dataset. Experimental results showed a three-fold decrease in the number of collected samples compared to conventional counterparts. This resulted in a significant reduction of the computational cost of the post denoising, features extraction, and classification. Moreover, a seven-fold reduction was achieved in the amount of data that needed to be transmitted to the cloud. This resulted in a notable reduction in the transmitter power consumption, bandwidth usage, and cloud application processing load. Finally, the performance of the system was also assessed in terms of the arrhythmia classification, achieving an accuracy of 97%.","electrocardiogram (ECG),compression,arrhythmia classification,level-crossing sampling,adaptive-rate processing,hysteresis,machine learning,mobile healthcare,wavelet decomposition,sub-bands features extraction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"WAVELET,TRANSFORM,CLASSIFICATION,ADC,COMPRESSION,FREQUENCY",SENSORS,https://www.mdpi.com/1424-8220/20/8/2252/pdf,
94,Automatic detection of simulated motion blur in mammograms,47,4,1786-1795,"Kamona Nada,Loew Murray","Kamona N,Loew M",Kamona N,10.1002/mp.14069,George Washington University,"Purpose: To use machine-learning algorithms and blur measure (BM) operators to automatically detect motion blur in mammograms. Motion blur has been reported to reduce lesion detection performance and mask small abnormalities, resulting in failure to detect them until they reach more advanced stages. Automatic detection of blur could support the clinical decision-making process during the mammography exam by allowing for an immediate retake, thereby preventing unnecessary expense, time, and patient anxiety.
Methods: Blur was simulated mathematically to mimic the real blur seen in clinical practice. The blur point-spread-function (PSF) mask is generated by distributing pixel intensity of an image pixel moving under random motion within the range of blur effect (the maximum amount of tissue motion allowed). The random motion trajectory vector is generated on a super-sampled image frame to accommodate smaller substeps; the vector was then sampled on a regular pixel grid using subpixel linear interpolation to generate the blur PSF mask. This randomly generated motion trajectory is constrained by several factors: the effects of variations in tissue elasticity, imaging exposure time, and size of blur effect (motion boundary in millimeters) were examined. The blur mask is convolved with a mammogram to create blur. Five motion blur magnitudes (0.1, 0.25, 0.5, 1.0, and 1.5 mm) were simulated on 244 and 434 mammograms from the INbreast and DDSM databases, respectively. Blur was quantified using nine BM operators for each mammogram and at each blur level. The mammograms were assigned to training (70%) and testing (30%) datasets to train three machine-learning classifiers: Ensemble Bagged Trees, fine Gaussian SVM, and weighted KNN, to distinguish five levels of blurred from unblurred mammograms, using six-way classification.
Results: For the INbreast mammograms, the average classification accuracies were 87.7%, 85.7%, and 85.7% for Ensemble Bagged Trees, fine Gaussian SVM, and weighted KNN, respectively, and the average classification accuracies for DDSM were 93.5%, 93.6%, and 92.7% for Ensemble Bagged Trees, fine Gaussian SVM, and weighted KNN, respectively.
Conclusions: Preliminary results show the potential to detect simulated blur automatically using those methods. Although limited work has been done to quantify the effects of motion blur on radiologists' performance, there is evidence that motion blur might not be detected visually by a human observer and could negatively affect radiologists' lesion detection performance. As of this date, no other study has investigated the ability of machine-learning classifiers and BM operators to detect motion blur in mammograms. (C) 2020 American Association of Physicists in Medicine.","automatic detection,blur measure operators,machine-learning,mammograms,motion-blur",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,BREAST,MEDICAL PHYSICS,,
95,Structure-related electrochemical performance of organosulfur compounds for lithium-sulfur batteries,13,4,1076-1095,"Zhang Xiaoyin,Chen Ke,Sun Zhenhua,Hu Guangjian,Xiao Ru,Cheng Hui-Ming,Li Feng","Zhang XY,Chen K,Sun ZH,Hu GJ,Xiao R,Cheng HM,Li F",Sun ZH; Li F,10.1039/c9ee03848e,Chinese Academy of Sciences,"Lithium-sulfur batteries (Li-S batteries) are promising next-generation energy storage devices due to their high theoretical energy density, low cost, and environmental compatibility. When trying to convert experiment into practice, one finds that sulfur cathodes, especially a cyclic octasulfur cathode, and lithium metal anodes present several problems, including sulfur shuttling, the fact that S is an insulator, complex 16-electron reactions, and the formation of lithium dendrites. In recent years, organosulfur compounds have been extensively investigated for Li-S batteries in order to solve these problems and understand the electrochemical process during their redox reactions. This review aims to summarize the different functions of organosulfur compounds, and figure out a guideline for understanding and using them in Li-S batteries. The organosulfur compounds currently used as active materials are classified into three types based on their electrochemical behavior, and design principles of the molecular and polymer structures of organosulfur compounds are concluded. Based on these design principles, we summarize how to control their electrochemical performance, and suggest possible electrochemical mechanisms and other characteristics. Finally, we propose guidelines for the development of promising organosulfur compounds using emerging technologies, including advanced characterization techniques, innovative methods of synthesis of such compounds, and machine-learning techniques.","CATHODE MATERIALS,HIGH-CAPACITY,ELEMENTAL SULFUR,INVERSE VULCANIZATION,COMPOSITE CATHODE,ENERGY,COPOLYMERIZATION,POLYSULFIDES,CONFINEMENT,POLYMERS",Review,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Energy & Fuels,Engineering,Environmental Sciences & Ecology",,36.942,"CATHODE,MATERIALS,HIGH-CAPACITY,ELEMENTAL,SULFUR,INVERSE,VULCANIZATION,COMPOSITE,CATHODE,ENERGY,COPOLYMERIZATION,POLYSULFIDES,CONFINEMENT,POLYMERS",ENERGY & ENVIRONMENTAL SCIENCE,,
96,Visualizing morphological principles for efficient photocurrent generation in organic non-fullerene acceptor blends,13,4,1259-1268,"Koentges Wolfgang,Perkhun Pavlo,Kammerer Jochen,Alkarsifi Riva,Wuerfel Uli,Margeat Olivier,Videlot-Ackermann Christine,Simon Jean-Jacques,Schroeder Rasmus R.,Ackermann Jorg","Kontges W,Perkhun P,Kammerer J,Alkarsifi R,Wurfel U,Margeat O,Videlot-Ackermann C,Simon JJ,Schroder RR,Ackermann J",Pfannmoller M,10.1039/c9ee03535d,Ruprecht Karls University Heidelberg,"The efficiency of organic solar cells with donor polymers and non-fullerene acceptors depends on a complex morphology. Similar chemical and electronic structures impede generating in-depth insights in morphological details. We visualise molecular arrangements and the nanomorphology in PBDB-T:ITIC blends by correlating transmission electron micrographs and material distribution maps. Material phases are identified by machine learning on hyperspectral data from electron spectroscopic imaging. We observe a specific polymorph of ITIC after thermal annealing. During annealing, enhanced by the presence of additives, PBDB-T acts as nucleation site for ITIC due to strong pi-pi-interactions of the electron withdrawing groups of both molecules. This leads to efficient charge transport paths in ITIC phases with direct pi-pi-contact to PBDB-T at the interface. We conclude that pi-pi-stacking between donor and acceptor molecules facilitates charge carrier generation within mixed interface regions.","POLYMER SOLAR-CELLS,CHARGE SEPARATION,ELECTRON-ACCEPTOR,SOLVENT,ENERGY,PHOTOVOLTAICS,STATES,FILMS",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Energy & Fuels,Engineering,Environmental Sciences & Ecology",,36.942,"POLYMER,SOLAR-CELLS,CHARGE,SEPARATION,ELECTRON-ACCEPTOR,SOLVENT,ENERGY,PHOTOVOLTAICS,STATES,FILMS",ENERGY & ENVIRONMENTAL SCIENCE,https://hal.archives-ouvertes.fr/hal-02495484/document,
97,Deep learning-based MR-to-CT synthesis: The influence of varying gradient echo-based MR images as input channels,83,4,1429-1441,"Florkow Mateusz C.,Zijlstra Frank,Willemsen Koen,Maspero Matteo,van den Berg Cornelis A. T.,Kerkmeijer Linda G. W.,Castelein Rene M.,Weinans Harrie,Viergever Max A.,van Stralen Marijn","Florkow MC,Zijlstra F,Willemsen K,Maspero M,van den Berg CAT,Kerkmeijer LGW,Castelein RM,Weinans H,Viergever MA,van Stralen M",Florkow MC,10.1002/mrm.28008,Utrecht University,"Purpose: To study the influence of gradient echo-based contrasts as input channels to a 3D patch-based neural network trained for synthetic CT (sCT) generation in canine and human populations.
Methods: Magnetic resonance images and CT scans of human and canine pelvic regions were acquired and paired using nonrigid registration. Magnitude MR images and Dixon reconstructed water, fat, in-phase and opposed-phase images were obtained from a single T1-weighted multi-echo gradient-echo acquisition. From this set, 6 input configurations were defined, each containing 1 to 4 MR images regarded as input channels. For each configuration, a UNet-derived deep learning model was trained for synthetic CT generation. Reconstructed Hounsfield unit maps were evaluated with peak SNR, mean absolute error, and mean error. Dice similarity coefficient and surface distance maps assessed the geometric fidelity of bones. Repeatability was estimated by replicating the training up to 10 times.
Results: Seventeen canines and 23 human subjects were included in the study. Performance and repeatability of single-channel models were dependent on the TE-related water-fat interference with variations of up to 17% in mean absolute error, and variations of up to 28% specifically in bones. Repeatability, Dice similarity coefficient, and mean absolute error were statistically significantly better in multichannel models with mean absolute error ranging from 33 to 40 Hounsfield units in humans and from 35 to 47 Hounsfield units in canines.
Conclusion: Significant differences in performance and robustness of deep learning models for synthetic CT generation were observed depending on the input. In-phase images outperformed opposed-phase images, and Dixon reconstructed multichannel inputs outperformed single-channel inputs.","deep learning,gradient echo,MR contrasts,synthetic CT",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"ATTENUATION,CORRECTION,ONLY,RADIOTHERAPY,GENERATION,PET%2FMRI,TIME",MAGNETIC RESONANCE IN MEDICINE,https://europepmc.org/articles/pmc6972695?pdf=render,
98,Analyzing the Effectiveness of the Brain-Computer Interface for Task Discerning Based on Machine Learning,20,8,,"Browarczyk Jakub,Kurowski Adam,Kostek Bozena","Browarczyk J,Kurowski A,Kostek B",Kostek B,10.3390/s20082403,Gdansk University of Technology,"The aim of the study is to compare electroencephalographic (EEG) signal feature extraction methods in the context of the effectiveness of the classification of brain activities. For classification, electroencephalographic signals were obtained using an EEG device from 17 subjects in three mental states (relaxation, excitation, and solving logical task). Blind source separation employing independent component analysis (ICA) was performed on obtained signals. Welch's method, autoregressive modeling, and discrete wavelet transform were used for feature extraction. Principal component analysis (PCA) was performed in order to reduce the dimensionality of feature vectors. k-Nearest Neighbors (kNN), Support Vector Machines (SVM), and Neural Networks (NN) were employed for classification. Precision, recall, F1 score, as well as a discussion based on statistical analysis, were shown. The paper also contains code utilized in preprocessing and the main part of experiments.","electroencephalography (EEG),brain-computer interface (BCI),feature extraction,automatic classification,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"INDEPENDENT,COMPONENT,ANALYSIS,EEG,SIGNAL,CLASSIFICATION,FEATURE-EXTRACTION,STATISTICAL,COMPARISONS,NEURAL-NETWORKS,CLASSIFIERS,DYNAMICS,MODEL",SENSORS,https://www.mdpi.com/1424-8220/20/8/2403/pdf,
99,NeuroVAD: Real-Time Voice Activity Detection from Non-Invasive Neuromagnetic Signals,20,8,,"Dash Debadatta,Ferrari Paul,Dutta Satwik,Wang Jun","Dash D,Ferrari P,Dutta S,Wang J",Wang J,10.3390/s20082248,University of Texas System,"Neural speech decoding-driven brain-computer interface (BCI) or speech-BCI is a novel paradigm for exploring communication restoration for locked-in (fully paralyzed but aware) patients. Speech-BCIs aim to map a direct transformation from neural signals to text or speech, which has the potential for a higher communication rate than the current BCIs. Although recent progress has demonstrated the potential of speech-BCIs from either invasive or non-invasive neural signals, the majority of the systems developed so far still assume knowing the onset and offset of the speech utterances within the continuous neural recordings. This lack of real-time voice/speech activity detection (VAD) is a current obstacle for future applications of neural speech decoding wherein BCI users can have a continuous conversation with other speakers. To address this issue, in this study, we attempted to automatically detect the voice/speech activity directly from the neural signals recorded using magnetoencephalography (MEG). First, we classified the whole segments of pre-speech, speech, and post-speech in the neural signals using a support vector machine (SVM). Second, for continuous prediction, we used a long short-term memory-recurrent neural network (LSTM-RNN) to efficiently decode the voice activity at each time point via its sequential pattern-learning mechanism. Experimental results demonstrated the possibility of real-time VAD directly from the non-invasive neural signals with about 88% accuracy.","brain-computer interface,MEG,wavelet,LSTM-RNN,SVM,VAD,speech-BCI",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"SPEECH,BRAIN,MAGNETOENCEPHALOGRAPHY,TASKS",SENSORS,https://europepmc.org/articles/pmc7218843?pdf=render,
100,Semantic Segmentation of Natural Materials on a Point Cloud Using Spatial and Multispectral Features,20,8,,"Jurado J. M.,Cardenas J. L.,Ogayar C. J.,Ortega L.,Feito F. R.","Jurado JM,Cardenas JL,Ogayar CJ,Ortega L,Feito FR",Jurado JM,10.3390/s20082244,Universidad de Jaen,"The characterization of natural spaces by the precise observation of their material properties is highly demanded in remote sensing and computer vision. The production of novel sensors enables the collection of heterogeneous data to get a comprehensive knowledge of the living and non-living entities in the ecosystem. The high resolution of consumer-grade RGB cameras is frequently used for the geometric reconstruction of many types of environments. Nevertheless, the understanding of natural spaces is still challenging. The automatic segmentation of homogeneous materials in nature is a complex task because there are many overlapping structures and an indirect illumination, so the object recognition is difficult. In this paper, we propose a method based on fusing spatial and multispectral characteristics for the unsupervised classification of natural materials in a point cloud. A high-resolution camera and a multispectral sensor are mounted on a custom camera rig in order to simultaneously capture RGB and multispectral images. Our method is tested in a controlled scenario, where different natural objects coexist. Initially, the input RGB images are processed to generate a point cloud by applying the structure-from-motion (SfM) algorithm. Then, the multispectral images are mapped on the three-dimensional model to characterize the geometry with the reflectance captured from four narrow bands (green, red, red-edge and near-infrared). The reflectance, the visible colour and the spatial component are combined to extract key differences among all existing materials. For this purpose, a hierarchical cluster analysis is applied to pool the point cloud and identify the feature pattern for every material. As a result, the tree trunk, the leaves, different species of low plants, the ground and rocks can be clearly recognized in the scene. These results demonstrate the feasibility to perform a semantic segmentation by considering multispectral and spatial features with an unknown number of clusters to be detected on the point cloud. Moreover, our solution is compared to other method based on supervised learning in order to test the improvement of the proposed approach.","multispectral imaging,heterogeneous data fusion,point cloud segmentation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"EXTRACTION,IMAGERY",SENSORS,https://www.mdpi.com/1424-8220/20/8/2244/pdf,
