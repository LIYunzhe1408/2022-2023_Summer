,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Partial Policy-Based Reinforcement Learning for Anatomical Landmark Localization in 3D Medical Images,39,4,1245-1255,"Al Walid Abdullah,Yun Il Dong","Al WA,Yun ID",Yun ID,10.1109/TMI.2019.2946345,Hankuk University Foreign Studies,"Utilizing the idea of long-term cumulative return, reinforcement learning (RL) has shown remarkable performance in various fields. We follow the formulation of landmark localization in 3D medical images as an RL problem. Whereas value-based methods have been widely used to solve RL-based localization problems, we adopt an actor-critic based direct policy search method framed in a temporal difference learning approach. In RL problems with large state and/or action spaces, learning the optimal behavior is challenging and requires many trials. To improve the learning, we introduce a partial policy-based reinforcement learning to enable solving the large problem of localization by learning the optimal policy on smaller partial domains. Independent actors efficiently learn the corresponding partial policies, each utilizing their own independent critic. The proposed policy reconstruction from the partial policies ensures a robust and efficient localization, where the sub-agents uniformly contribute to the state-transitions based on their simple partial policies mapping to binary actions. Experiments with three different localization problems in 3D CT and MR images showed that the proposed reinforcement learning requires a significantly smaller number of trials to learn the optimal behavior compared to the original behavior learning scheme in RL. It also ensures a satisfactory performance when trained on fewer images.","Actor-critic,landmark localization,medical image,partial policy,reinforcement learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"RECOGNITION,CT",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1807.02908,
2,MoDL-MUSSELS: Model-Based Deep Learning for Multishot Sensitivity-Encoded Diffusion MRI,39,4,1268-1277,"Aggarwal Hemant K.,Mani Merry P.,Jacob Mathews","Aggarwal HK,Mani MP,Jacob M",Aggarwal HK,10.1109/TMI.2019.2946501,University of Iowa,"We introduce a model-based deep learning architecture termed MoDL-MUSSELS for the correction of phase errors in multishot diffusion-weighted echo-planar MR images. The proposed algorithm is a generalization of the existing MUSSELS algorithm with similar performance but significantly reduced computational complexity. In this work, we show that an iterative re-weighted least-squares implementation of MUSSELS alternates between a multichannel filter bank and the enforcement of data consistency. The multichannel filter bank projects the data to the signal subspace, thus exploiting the annihilation relations between shots. Due to the high computational complexity of the self-learned filter bank, we propose replacing it with a convolutional neural network (CNN) whose parameters are learned from exemplary data. The proposed CNN is a hybrid model involving a multichannel CNN in the k-space and another CNN in the image space. The k-space CNN exploits the annihilation relations between the shot images, while the image domain network is used to project the data to an image manifold. The experiments show that the proposed scheme can yield reconstructions that are comparable to state-of-the-art methods while offering several orders of magnitude reduction in run-time.","Diffusion MRI,Echo Planar Imaging,Deep Learning,convolutional neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"REWEIGHTED,ALGORITHMS,RECONSTRUCTION,RECOVERY,SENSE",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7894613,
3,A predictive failure framework for brittle porous materials via machine learning and geometric matching methods,55,11,4734-4747,"Karakoc Alp,Keles Ozgur","Karakoc A,Keles O",Keles O,10.1007/s10853-019-04339-1,California State University System,"Brittle porous materials are used in many applications, such as molten metal filter, battery, fuel cell, catalyst, membrane, and insulator. The porous structure of these materials causes variations in their fracture strength that is known as the mechanical reliability problem. Despite the importance of brittle porous materials, the origin of the strength variations is still unclear. The current study presents a machine learning approach to characterize the stochastic fracture of porous ceramics and glasses. A combined finite element modeling and fracture mechanics approach was used to generate a unique empirical data set consisting of normalized stress intensity factors (nSIFs, KI/r? = Y ffiffiffiffiffi pap) that define fracture strength of brittle systems under uniaxial tensile loading and biaxial tensile loading. These empirical data sets were used to generate prediction functions and validate their accuracy. Monte Carlo simulations with two machine learning algorithms, random forests (RF) and artificial neural networks (ANN), were used to simultaneously determine the optimum percentages for the training and test data set split and the prediction function validation. The constraint was taken to be the mean absolute percentage error (MAPE) during the process. In the implementation step, new porous media with uniformly distributed pores were created and the prediction functions were used to obtain nSIFs and characterize the media. As a novelty of this approach, which ensures the predictive characterization of the generated media, a geometric matching method by means of the Euclidean bipartite matching between the empirical and the generated media was presented and the nSIFs were compared by means of MAPE. As a result of the study, MAPE ranges are 3.4-17.93% (uniaxial load) and 2.83-19.42% (biaxial load) for RF, 3.79- 17.43% and 3.39-21.43 for ANN at the validation step; 3.54-18.20% (uniaxial load) and 3.06-21.60% (biaxial load) for RF, 3.57-18.26% and 3.43-21.76% for ANN at the implementation step. The proposed approach can be thus used as a predictive characterization tool,","FRACTURE STATISTICS,CRACK ORIENTATION,CERAMICS,SIZE,CAVITIES",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Materials Science,,3.69,"FRACTURE,STATISTICS,CRACK,ORIENTATION,CERAMICS,SIZE,CAVITIES",JOURNAL OF MATERIALS SCIENCE,https://research.aalto.fi/files/40615894/CHEM_Karakoc_Keles_2020_predictive_failure_CompThe.pdf,
4,Photonic architecture for reinforcement learning,22,4,,"Flamini Fulvio,Hamann Arne,Jerbi Sofiene,Trenkwalder Lea M.,Nautrup Hendrik Poulsen,Briegel Hans J.","Flamini F,Hamann A,Jerbi S,Trenkwalder LM,Nautrup HP,Briegel HJ",Flamini F,10.1088/1367-2630/ab783c,University of Innsbruck,"The last decade has seen an unprecedented growth in artificial intelligence and photonic technologies, both of which drive the limits of modern-day computing devices. In line with these recent developments, this work brings together the state of the art of both fields within the framework of reinforcement learning. We present the blueprint for a photonic implementation of an active learning machine incorporating contemporary algorithms such as SARSA, Q-learning, and projective simulation. We numerically investigate its performance within typical reinforcement learning environments, showing that realistic levels of experimental noise can be tolerated or even be beneficial for the learning process. Remarkably, the architecture itself enables mechanisms of abstraction and generalization, two features which are often considered key ingredients for artificial intelligence. The proposed architecture, based on single-photon evolution on a mesh of tunable beamsplitters, is simple, scalable, and a first integration in quantum optical experiments appears to be within the reach of near-term technology.","machine learning,reinforcement learning,quantum photonics,integrated photonic circuits",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,3.741,"PHASE-CHANGE,MATERIALS,NEURAL-NETWORKS,GO",NEW JOURNAL OF PHYSICS,http://arxiv.org/pdf/1907.07503,
5,PoreFlow-Net: A 3D convolutional neural network to predict fluid flow through porous media,138,,,"Santos Javier E.,Xu Duo,Jo Honggeun,Landry Christopher J.,Prodanovic Masa,Pyrcz Michael J.","Santos JE,Xu D,Jo H,Landry CJ,Prodanovic M,Pyrcz MJ",Santos JE,10.1016/j.advwatres.2020.103539,University of Texas System,"We present the PoreFlow-Net, a 3D convolutional neural network architecture that provides fast and accurate fluid flow predictions for 3D digital rock images. We trained our network to extract spatial relationships between the porous medium morphology and the fluid velocity field. Our workflow computes simple geometrical information from 3D binary images to train a deep neural network (the PoreFlow-Net) optimized to generalize the problem of flow through porous materials. Our results show that the extracted information is sufficient to obtain accurate flow field predictions in less than a second, without performing expensive numerical simulations providing a speed-up of several orders of magnitude. We also demonstrate that our model, trained with simple synthetic geometries, is able to provide accurate results in real samples spanning granular rocks, carbonates, and slightly consolidated media from a variety of subsurface formations, which highlights the ability of the model to generalize the porous media flow problem. The workflow presented here shows the successful application of a disruptive technology (physics-based training of machine learning models) to the digital rock physics community.","Fluid flow,Porous media,Surrogate models,Permeability,Deep learning,Convolutional neural networks",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Water Resources,,4.929,"PERMEABILITY,IMAGES,SEGMENTATION,EQUATION",ADVANCES IN WATER RESOURCES,,
6,A Deep Learning Approach to Grasping the Invisible,5,2,2232-2239,"Yang Yang,Liang Hengyue,Choi Changhyun","Yang Y,Liang HY,Choi C",Yang Y,10.1109/LRA.2020.2970622,University of Minnesota System,"We study an emerging problem named ""grasping the invisible"" in robotic manipulation, in which a robot is tasked to grasp an initially invisible target object via a sequence of pushing and grasping actions. In this problem, pushes are needed to search for the target and rearrange cluttered objects around it to enable effective grasps. We propose to solve the problem by formulating a deep learning approach in a critic-policy format. The target-oriented motion critic, which maps both visual observations and target information to the expected future rewards of pushing and grasping motion primitives, is learned via deep Q-learning. We divide the problem into two subtasks, and two policies are proposed to tackle each of them, by combining the critic predictions and relevant domain knowledge. A Bayesian-based policy accounting for past action experience performs pushing to search for the target; once the target is found, a classifier-based policy coordinates target-oriented pushing and grasping to grasp the target in clutter. The motion critic and the classifier are trained in a self-supervised manner through robot-environment interactions. Our system achieves a 93% and 87% task success rate on each of the two subtasks in simulation and an 85% task success rate in real robot experiments on the whole problem, which outperforms several baselines by large margins. Supplementary material is available at https://sites.google.com/umn.edu/grasping-invisible.","Dexterous manipulation,deep learning in robotics and automation,computer vision for automation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,,IEEE ROBOTICS AND AUTOMATION LETTERS,http://arxiv.org/pdf/1909.04840,
7,Learning to Walk a Tripod Mobile Robot Using Nonlinear Soft Vibration Actuators With Entropy Adaptive Reinforcement Learning,5,2,2317-2324,"Kim Jae In,Hong Mineui,Lee Kyungjae,Kim DongWook,Park Yong-Lae,Oh Songhwai","Kim JI,Hong M,Lee K,Kim D,Park YL,Oh S",Park YL,10.1109/LRA.2020.2970945,Seoul National University (SNU),"Soft mobile robots have shown great potential in unstructured and confined environments by taking advantage of their excellent adaptability and high dexterity. However, there are several issues to be addressed, such as actuating speeds and controllability, in soft robots. In this letter, a new vibration actuator is proposed using the nonlinear stiffness characteristic of a hyperelastic material, which creates continuous vibration of the actuator. By integrating three proposed actuators, we also present an advanced soft mobile robot with high degrees of freedom of movement. However, since the dynamic model of the soft mobile robot is generally hard to obtain(intractable), it is difficult to design a controller for the robot. In this regard, we present a method to train a controller, using a novel reinforcement learning (RL) algorithm called adaptive soft actor-critic (ASAC). ASAC gradually reduces a parameter called an entropy temperature, which regulates the entropy of the control policy. In this way, the proposed method can narrow down the search space during training, and reduce the duration of demanding data collection processes in real-world experiments. For the verification of the robustness and the controllability of our robot and the RL algorithm, experiments for zig-zagging path tracking and obstacle avoidance were conducted, and the robot successfully finished the missions with only an hour of training time.","Modeling,control,and learning for soft robots,hydraulic,pneumatic actuators,motion and path planning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,,IEEE ROBOTICS AND AUTOMATION LETTERS,,
8,Realtime Simulation of Thin-Shell Deformable Materials Using CNN-Based Mesh Embedding,5,2,2325-2332,"Tan Qingyang,Pan Zherong,Gao Lin,Manocha Dinesh","Tan QY,Pan ZR,Gao L,Manocha D",Pan ZR,10.1109/LRA.2020.2970624,University of North Carolina,"We address the problem of accelerating thin-shell deformable object simulations by dimension reduction. We present a new algorithm to embed a high-dimensional configuration space of deformable objects in a low-dimensional feature space, where the configurations of objects and feature points have approximate one-to-one mapping. Our key technique is a graph-based convolutional neural network (CNN) defined on meshes with arbitrary topologies and a new mesh embedding approach based on physics-inspired loss term. We have applied our approach to accelerate high-resolution thin shell simulations corresponding to cloth-like materials, where the configuration space has tens of thousands of degrees of freedom. We show that our physics-inspired embedding approach leads to higher accuracy compared with prior mesh embedding methods. Finally, we show that the temporal evolution of the mesh in the feature space can also be learned using a recurrent neural network (RNN) leading to fully learnable physics simulators. After training our learned simulator runs 500-10000x faster and the accuracy is high enough for robot manipulation tasks.","Simulation and animation,dexterous manipulation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,MANIPULATION,IEEE ROBOTICS AND AUTOMATION LETTERS,http://arxiv.org/pdf/1909.12354,
9,Permanent Magnet-Based Localization for Growing Robots in Medical Applications,5,2,2666-2673,"Watson Connor,Morimoto Tania K.","Watson C,Morimoto TK",Watson C,10.1109/LRA.2020.2972890,University of California System,"Growing robots that achieve locomotion by extending from their tip, are inherently compliant and can safely navigate through constrained environments that prove challenging for traditional robots. However, the same compliance and tip-extension mechanism that enables this ability, also leads directly to challenges in their shape estimation and control. In this letter, we present a low-cost, wireless, permanent magnet-based method for localizing the tip of these robots. A permanent magnet is placed at the robot tip, and an array of magneto-inductive sensors is used to measure the change in magnetic field as the robot moves through its workspace. We develop an approach to localization that combines analytical and machine learning techniques and show that it outperforms existing methods. We also measure the position error over a 500 mm x 500 mm workspace with different magnet sizes to show that this approach can accommodate growing robots of different scales. Lastly, we show that our localization method is suitable for tracking the tip of a growing robot by deploying a 12 mm robot through different, constrained environments. Our method achieves position and orientation errors of 3.0 +/- 1.1mmand 6.5 +/- 5.4. in the planar case and 4.3 +/- 2.3 mm, 3.9 +/- 3.0., and 3.8 +/- 3.5. in the 5-DOF setting.","Medical robotics and systems,surgical robotics,steerable catheters,needles,modeling,control,learning for soft robots",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,TRACKING,IEEE ROBOTICS AND AUTOMATION LETTERS,,
10,Generate Structured Radiology Report from CT Images Using Image Annotation Techniques: Preliminary Results with Liver CT,33,2,375-390,"Loveymi Samira,Dezfoulian Mir Hossein,Mansoorizadeh Muharram","Loveymi S,Dezfoulian MH,Mansoorizadeh M",Mansoorizadeh M,10.1007/s10278-019-00298-w,Bu Ali Sina University,"A medical annotation system for radiology images extracts clinically useful information from the images, allowing the machines to infer useful abstract semantics and become capable of automatic reasoning and making diagnostic decision. It also supplies human-interpretable explanation for the images. We have implemented a computerized framework that, given a liver CT image, predicts radiological annotations with high accuracy, in order to generate a structured report, which includes predicting very specific high-level semantic content. Each report of a liver CT image is related to different inhomogeneous parts like the liver, lesion, and vessel. We put forward a claim that gathering all kinds of features is not suitable for filling all parts of the report. As a matter of fact, for each group of annotations, one should find and extract the best feature that results in the best answers for that specific annotation. To this end, the main challenge is discovering the relationships between these specific semantic concepts and their association with the low-level image features. Our framework was implemented by combining a set of the state-of-the-art low-level imaging features. In addition, we propose a novel feature (DLBP (deep local binary pattern)) based on LBP that incorporates multi-slice analysis in CT images and further improves the performance. In order to model our annotation system, two methods were used, namely multi-class support vector machine (SVM) and random subspace (RS) which is an ensemble learning method. Applying this representation leads to a high prediction accuracy of 93.1% despite its relatively low dimension in comparison with the existing works.","Deep local binary pattern,Medical image annotation,Computed tomography,Liver CT images",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,,"RETRIEVAL,CLASSIFICATION,LESIONS",JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7165219,
11,Deep Learning for Low-Dose CT Denoising Using Perceptual Loss and Edge Detection Layer,33,2,504-515,"Gholizadeh-Ansari Maryam,Alirezaie Javad,Babyn Paul","Gholizadeh-Ansari M,Alirezaie J,Babyn P",Alirezaie J,10.1007/s10278-019-00274-4,Ryerson University,"Low-dose CT denoising is a challenging task that has been studied by many researchers. Some studies have used deep neural networks to improve the quality of low-dose CT images and achieved fruitful results. In this paper, we propose a deep neural network that uses dilated convolutions with different dilation rates instead of standard convolution helping to capture more contextual information in fewer layers. Also, we have employed residual learning by creating shortcut connections to transmit image information from the early layers to later ones. To further improve the performance of the network, we have introduced a non-trainable edge detection layer that extracts edges in horizontal, vertical, and diagonal directions. Finally, we demonstrate that optimizing the network by a combination of mean-square error loss and perceptual loss preserves many structural details in the CT image. This objective function does not suffer from over smoothing and blurring effects causing by per-pixel loss and grid-like artifacts resulting from perceptual loss. The experiments show that each modification to the network improves the outcome while changing the complexity of the network, minimally.","Low-dose CT image,Dilated convolution,Deep neural network,Noise removal,Perceptual loss,Edge detection",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"NOISE-REDUCTION,RECONSTRUCTION,ALGORITHM,IMAGES",JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7165209,
12,Artificial Neural Network Approach Modeling for Sorption of Cobalt from Aqueous Solution Using Modified Maghemite Nanoparticles,146,4,,"Hassan Mohamed R.,Fikry Refaat M.,Yakout Sobhy M.","Hassan MR,Fikry RM,Yakout SM",Hassan MR,10.1061/(ASCE)EE.1943-7870.0001565,Egyptian Knowledge Bank (EKB),"This research defines the utilization of the artificial neural network (ANN) for demonstrating the sorption percentage of cobalt from an aqueous solution using modified maghemite nanoparticles. The effect of operating conditions such as temperature (degrees C), initial cobalt concentration, initial pH, contact time (min), and sorbent mass (g) are focused on the best conditions for maximum cobalt ions removal. Prepared nanoparticles were described using X-ray diffraction (XRD), scanning electron microscopy (SEM), X-ray fluorescence (XRF), and Fourier transform infrared spectroscopy (FTIR) measurements. The Langmuir model had been adequately matched with the experimental equilibrium data. Kinetic data demonstrate that the pseudo-second-order and intraparticle diffusion models regulate the kinetic processes of sorption. An ANN model was developed using 25 data sets for training, five data sets for validation, and 10 data sets for testing by a single-layer feedforward back-propagation network with 20 neurons to get a minimum mean square error (MSE). A tanh-sigmoid was used as the activation function for input and purelin for output layers. The high correlation coefficient (R2)=1 for trained data; R2=0.998 for tested data; MSE=3.78x10-28 of the trained data; and MSE=6.0513x10-9 for tested data between the model, and the experimental data revealed that the model could forecast the release of cobalt from an aqueous solution using modified maghemite nanoparticles efficiently. (c) 2020 American Society of Civil Engineers.","Artificial neural network,Sorption,Cobalt,Maghemite nanoparticles",Article,"ASCE-AMER SOC CIVIL ENGINEERS, 1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA","Engineering,Environmental Sciences & Ecology",,1.87,"COAL,FLY-ASH,METHYLENE-BLUE,GENETIC,ALGORITHM,GRAPHENE,OXIDE,METAL-IONS,REMOVAL,ADSORPTION,OPTIMIZATION,EQUILIBRIUM,KINETICS",JOURNAL OF ENVIRONMENTAL ENGINEERING,,
13,Automated Video Face Labelling for Films and TV Material,42,4,780-792,"Parkhi Omkar M.,Rahtu Esa,Cao Qiong,Zisserman Andrew","Parkhi OM,Rahtu E,Cao Q,Zisserman A",Parkhi OM,10.1109/TPAMI.2018.2889831,University of Oxford,"The objective of this work is automatic labelling of characters in TV video and movies, given weak supervisory information provided by an aligned transcript. We make five contributions: (i) a new strategy for obtaining stronger supervisory information from aligned transcripts; (ii) an explicit model for classifying background characters, based on their face-tracks; (iii) employing new ConvNet based face features, and (iv) a novel approach for labelling all face tracks jointly using linear programming. Each of these contributions delivers a boost in performance, and we demonstrate this on standard benchmarks using tracks provided by authors of prior work. As a fifth contribution, we also investigate the generalisation and strength of the features and classifiers by applying them ""in the raw"" on new video material where no supervisory information is used. In particular, to provide high quality tracks on those material, we propose efficient track classifiers to remove false positive tracks by the face tracker. Overall we achieve a dramatic improvement over the state of the art on both TV series and film datasets, and almost saturate performance on some benchmarks.","Face,Target tracking,Labeling,TV,Visualization,Pattern analysis,Automatic face labelling,face tracking,deep learning",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Computer Science,Engineering",,18.46,,IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,https://ora.ox.ac.uk/objects/uuid:184c3c35-0983-4dc1-b3b7-5200a12debce/download_file?safe_filename=ParkhietalAAM2018.pdf&type_of_work=Journal+article,
14,Weighted Manifold Alignment using Wave Kernel Signatures for Aligning Medical Image Datasets,42,4,988-997,"Clough James R.,Balfour Daniel R.,Cruz Gastao,Marsden Paul K.,Prieto Claudia,Reader Andrew J.,King Andrew P.","Clough JR,Balfour DR,Cruz G,Marsden PK,Prieto C,Reader AJ,King AP",Clough JR,10.1109/TPAMI.2019.2891600,University of London,"Manifold alignment (MA) is a technique to map many high-dimensional datasets to one shared low-dimensional space. Here we develop a pipeline for using MA to reconstruct high-resolution medical images. We present two key contributions. First, we develop a novel MA scheme in which each high-dimensional dataset can be differently weighted preventing noisier or less informative data from corrupting the aligned embedding. We find that this generalisation improves performance in our experiments in both supervised and unsupervised MA problems. Second, we use the wave kernel signature as a graph descriptor for the unsupervised MA case finding that it significantly outperforms the current state-of-the-art methods and provides higher quality reconstructed magnetic resonance volumes than existing methods.","Manifolds,Kernel,Biomedical imaging,Pipelines,Laplace equations,Two dimensional displays,Manifold alignment,graph descriptor,wave kernel signature,magnetic resonance imaging,slice stacking",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Computer Science,Engineering",,18.46,"DIMENSIONALITY,REDUCTION",IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,https://kclpure.kcl.ac.uk/ws/files/104796751/wma_final_no_journal_typesetting.pdf,
15,"Multi-objective optimization of injection-molded plastic parts using entropy weight, random forest, and genetic algorithm methods",40,4,360-371,"Cao Yanli,Fan Xiying,Guo Yonghuan,Li Sai,Huang Haiyue","Cao YL,Fan XY,Guo YH,Li S,Huang HY",Fan XY,10.1515/polyeng-2019-0326,Jiangsu Normal University,"The qualities of injection-molded parts are affected by process parameters. Warpage and volume shrinkage are two typical defects. Moreover, insufficient or excessively large clamping force also affects the quality of parts and the cost of the process. An experiment based on the orthogonal design was conducted to minimize the above defects. Moldflow software was used to simulate the injection process of each experiment. The entropy weight was used to determine the weight of each index, the comprehensive evaluation value was calculated, and multi-objective optimization was transformed into single-objective optimization. A regression model was established by the random forest (RF) algorithm. To further illustrate the reliability and accuracy of the model, back-propagation neural network and kriging models were taken as comparative algorithms. The results showed that the error of RF was the smallest and its performance was the best. Finally, genetic algorithm was used to search for the minimum of the regression model established by RF. The optimal parameters were found to improve the quality of plastic parts and reduce the energy consumption. The plastic parts manufactured by the optimal process parameters showed good quality and met the requirements of production.","entropy weight,genetic algorithm,injection molding,multi-objective optimization,random forest",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY",Polymer Science,,1.433,"ARTIFICIAL,NEURAL-NETWORK,WARPAGE,OPTIMIZATION,TAGUCHI,DESIGN,PARAMETERS,SHRINKAGE,ANOVA",JOURNAL OF POLYMER ENGINEERING,,
16,An EEG-Based Attentiveness Recognition System Using Hilbert-Huang Transform and Support Vector Machine,40,2,230-238,"Peng Chia-Ju,Chen Yi-Chun,Chen Chun-Chuan,Chen Shih-Jui,Cagneau Barthelemy,Chassagne Luc","Peng CJ,Chen YC,Chen CC,Chen SJ,Cagneau B,Chassagne L",Chen SJ,10.1007/s40846-019-00500-y,National Central University,"Purpose Attentiveness recognition benefits the detection of the mental state and concentration when humans perform specific tasks. Hilbert-Huang transform (HHT) is useful for the analysis of nonlinear or nonstationary bio-signals including brainwaves. In this work, a method is proposed for the characterization of attentiveness levels by using electroencephalogram (EEG) signals and HHT analysis. Methods Single-channel EEG signals from the frontal area were acquired from participants at different levels of attentiveness and were decomposed into a set of intrinsic mode functions (IMF) by empirical mode decomposition (EMD). Hilbert transform analysis was applied to each IMF to obtain the marginal frequency spectrum. Then the band powers and spectral entropies (SEs) were selected as the attributes of a support vector machine (SVM) for a two-class classification task. Results Compared with the predictive models of approximate entropy (ApEn) and fast Fourier transform (FFT), the results show that the band powers extracted from IMF2 to IMF5 of alpha\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\alpha$$\end{document} and beta\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\beta$$\end{document} waves and their SE can best discriminate between attentive and relaxed states with the average classification accuracy of 84.80%. Conclusion In conclusion, this integrated signal processing method is capable of attentiveness recognition that can offer efficient differentiation and may be used in a clinical setting for the detection of attention deficit.","Attentiveness,Electroencephalogram,Hilbert-Huang transform,Machine learning",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Engineering,,1.733,"EMPIRICAL,MODE,DECOMPOSITION,FEATURE-EXTRACTION,SPECTRAL,ENTROPY,SIGNAL,FREQUENCY,ATTENTION,POWER,ADHD",JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING,https://hal.archives-ouvertes.fr/hal-02399380/document,
17,Deep learning to detect Alzheimer's disease from neuroimaging: A systematic literature review,187,,,"Ebrahimighahnavieh Mr Amir,Luo Suhuai,Chiong Raymond","Ebrahimighahnavieh MA,Luo SH,Chiong R",Chiong R,10.1016/j.cmpb.2019.105242,University of Newcastle,"Alzheimer's Disease (AD) is one of the leading causes of death in developed countries. From a research point of view, impressive results have been reported using computer-aided algorithms, but clinically no practical diagnostic method is available. In recent years, deep models have become popular, especially in dealing with images. Since 2013, deep learning has begun to gain considerable attention in AD detection research, with the number of published papers in this area increasing drastically since 2017. Deep models have been reported to be more accurate for AD detection compared to general machine learning techniques. Nevertheless, AD detection is still challenging, and for classification, it requires a highly discriminative feature representation to separate similar brain patterns. This paper reviews the current state of AD detection using deep learning. Through a systematic literature review of over 100 articles, we set out the most recent findings and trends. Specifically, we review useful biomarkers and features (personal information, genetic data, and brain scans), the necessary pre-processing steps, and different ways of dealing with neuroimaging data originating from single-modality and multi-modality studies. Deep models and their performance are described in detail. Although deep learning has achieved notable performance in detecting AD, there are several limitations, especially regarding the availability of datasets and training procedures. (C) 2019 Elsevier B.V. All rights reserved.","Deep learning,Alzheimer's disease,Convolutional neural networks,Recurrent neural networks,Auto-encoders,Transfer learning",Review,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"MILD,COGNITIVE,IMPAIRMENT,CONVOLUTIONAL,NEURAL-NETWORK,NATIONAL,INSTITUTE,ASSOCIATION,WORKGROUPS,FEATURE,REPRESENTATION,DIAGNOSTIC,GUIDELINES,IMPROVED,CLASSIFICATION,IMAGING,DATA,MRI,DEMENTIA",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
18,An efficient architecture for medical high-resolution images transmission in mobile telemedicine systems,187,,,"Liu Lijun,Wang Lizhen,Huang Qingsong,Zhou Lihua,Fu Xiaodong,Liu Li","Liu LJ,Wang LZ,Huang QS,Zhou LH,Fu XD,Liu L",Wang LZ,10.1016/j.cmpb.2019.105088,Yunnan University,"Background and Objective: The medical high-resolution image is very important in image processing and computer vision applications, which plays a critical role in image-guided diagnosis, clinical trials, consultation, and case discussion. How to efficiently access medical high-resolution images in mobile telemedicine systems is becoming a big challenge. Therefore, this work proposes an efficient pyramid architecture for optimizing medical high-resolution images transmission and rendering.
Methods: The proposed architecture consists of three core schemes: (1) unbalance pyramid scheme based on geometric relationship, (2) indexing scheme based on hash table and lattice partitioning and (3) query scheme based on similar matching. Then, we design the responsive service components: generating service, indexing service, and query service. Finally, these services are combined into a prototype system that enables efficient transmission and rendering of medical high-resolution images.
Results: The result shows that the unbalance pyramid scheme can quickly generate the pyramid structure and the corresponding image files. The indexing scheme can create the index structure and the index file in real-time. The query scheme can not only match the best layer to which the image block belongs in real-time, but also can accurately capture the query image block.
Conclusions: The prototype system based on proposed architecture is fully compliant with the DICOM standard, which can be seamlessly integrated with other existing medical systems or mobile applications, and used in various scenarios such as diagnosis, research, and education. (C) 2020 Elsevier B.V. All rights reserved.","Medical high-resolution image,Unbalance image pyramid,Image transmission,Mobile telemedicine,DICOM and DICOM web service",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"WEB-BASED,SYSTEM,ELECTRONIC,WHITEBOARD,FRAMEWORK,ARGUMENTATION,COMPRESSION,RETRIEVAL,DIAGNOSIS,GRAPHS",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
19,Celiac disease diagnosis from videocapsule endoscopy images with residual learning and deep feature extraction,187,,,"Wang Xinle,Qian Haiyang,Ciaccio Edward J.,Lewis Suzanne K.,Bhagat Govind,Green Peter H.,Xu Shenghao,Huang Liang,Gao Rongke,Liu Yu","Wang XL,Qian HY,Ciaccio EJ,Lewis SK,Bhagat G,Green PH,Xu SH,Huang L,Gao RK,Liu Y",Gao RK; Liu Y,10.1016/j.cmpb.2019.105236,Hefei University of Technology,"Background and Objective: Videocapsule endoscopy (VCE) is a relatively new technique for evaluating the presence of villous atrophy in celiac disease patients. The diagnostic analysis of video frames is currently time-consuming and tedious. Recently, computer-aided diagnosis (CAD) systems have become an attractive research area for diagnosing celiac disease. However, the images captured from VCE are susceptible to alterations in light illumination, rotation direction, and intestinal secretions. Moreover, textural features of the mucosal villi obtained by VCE are difficult to characterize and extract. This work aims to find a novel deep learning feature learning module to assist in the diagnosis of celiac disease.
Methods: In this manuscript, we propose a novel deep learning recalibration module which shows significant gain in diagnosing celiac disease. In this recalibration module, the block-wise recalibration component is newly employed to capture the most salient feature in the local channel feature map. This learning module was embedded into ResNet50, Inception-v3 to diagnose celiac disease using a 10-time 10-fold cross-validation based upon analysis of VCE images. In addition, we employed model weights to extract feature points from training and test samples before the last fully connected layer, and then input to a support vector machine (SVM), k-nearest neighbor (KNN), and linear discriminant analysis (LDA) for differentiating celiac disease images from heathy controls.
Results: Overall, the accuracy, sensitivity and specificity of the 10-time 10-fold cross-validation were 95.94%, 97.20% and 95.63%, respectively.
Conclusions: A novel deep learning recalibration module, with global response and local salient factors is proposed, and it has a high potential for utilizing deep learning networks to diagnose celiac disease using VCE images. (C) 2019 Elsevier B.V. All rights reserved.","Block-wise channel squeeze and excitation component,Residual network,Videocapsule endoscopy,Machine learning,Celiac disease",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"VIDEO,CAPSULE,ENDOSCOPY,CLASSIFICATION",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
20,Analysis-Synthesis Learning With Shared Features: Algorithms for Histology Image Classification,67,4,1061-1073,"Li Xuelu,Monga Vishal,Rao U. K. Arvind","Li XL,Monga V,Rao UKA",Li XL,10.1109/TBME.2019.2928997,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Objective: The diversity of tissue structure in histopathological images makes feature extraction for classification a challenging task. Dictionary learning within a sparse representation-based classification (SRC) framework has been shown to be successful for feature discovery. However, there exist stiff practical challenges: 1) computational complexity of SRC can be onerous in the decision stage since it involves solving a sparsity constrained optimization problem and often over a large number of image patches; and 2) images from distinct classes continue to share several geometric features. We propose a novel analysis-synthesis model learning with shared features algorithm (ALSF) for classifying such images more effectively. Methods: In the ALSF, a joint analysis and synthesis learning model is introduced to learn the classifier and the feature extractor at the same time. Unlike SRC, no explicit optimization is needed in the inference phase leading to much reduced computation. Crucially, we introduce the learning of a low-rank shared dictionary and a shared analysis operator, which more accurately represents both similarities and differences in histopathological images from distinct classes. We also develop an extension of ALSF with a sparsity constraint, whose presence or absence facilitates a cost-performance tradeoff. Results: The ALSF is evaluated on three challenging and well-known datasets: 1) spleen tissue images; 2) brain tumor images; and 3) breast cancer tissue dataset, provided by different organizations. Conclusion: Experimental results demonstrate both complexity and performance benefits of the ALSF over state-of-the-art alternatives. Significance: Modeling shared features with appropriate quantitative constraints lead to significantly improved classification in histopathology.","Feature extraction,Analytical models,Dictionaries,Optimization,Cancer,Deep learning,Histopathological image classification,analysis and synthesis learning model,shared features learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"THRESHOLDING,ALGORITHM,HISTOPATHOLOGY,DICTIONARY",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
21,Machine learning applied to multi-sensor information to reduce false alarm rate in the ICU,34,2,339-352,"Hever Gal,Cohen Liel,O'Connor Michael F.,Matot Idit,Lerner Boaz,Bitan Yuval","Hever G,Cohen L,O'Connor MF,Matot I,Lerner B,Bitan Y",Bitan Y,10.1007/s10877-019-00307-x,Ben Gurion University,"Studies reveal that the false alarm rate (FAR) demonstrated by intensive care unit (ICU) vital signs monitors ranges from 0.72 to 0.99. We applied machine learning (ML) to ICU multi-sensor information to imitate a medical specialist in diagnosing patient condition. We hypothesized that applying this data-driven approach to medical monitors will help reduce the FAR even when data from sensors are missing. An expert-based rules algorithm identified and tagged in our dataset seven clinical alarm scenarios. We compared a random forest (RF) ML model trained using the tagged data, where parameters (e.g., heart rate or blood pressure) were (deliberately) removed, in detecting ICU signals with the full expert-based rules (FER), our ground truth, and partial expert-based rules (PER), missing these parameters. When all alarm scenarios were examined, RF and FER were almost identical. However, in the absence of one to three parameters, RF maintained its values of the Youden index (0.94-0.97) and positive predictive value (PPV) (0.98-0.99), whereas PER lost its value (0.54-0.8 and 0.76-0.88, respectively). While the FAR for PER with missing parameters was 0.17-0.39, it was only 0.01-0.02 for RF. When scenarios were examined separately, RF showed clear superiority in almost all combinations of scenarios and numbers of missing parameters. When sensor data are missing, specialist performance worsens with the number of missing parameters, whereas the RF model attains high accuracy and low FAR due to its ability to fuse information from available sensors, compensating for missing parameters.","False alarms,Intensive care unit,Machine learning,Missing data,Random forest",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Anesthesiology,,2.155,,JOURNAL OF CLINICAL MONITORING AND COMPUTING,,
22,"Automated Classification of Manufacturing Process Capability Utilizing Part Shape, Material, and Quality Attributes",20,2,,"Zhao Changxuan,Dinar Mahmoud,Melkote Shreyes N.","Zhao CX,Dinar M,Melkote SN",Melkote SN,10.1115/1.4045410,University System of Georgia,"The ability to classify the capabilities of different manufacturing processes based on computer-aided design (CAD) models of parts is a key missing link in cybermanufacturing. In this paper, we present a one-step approach for automatically classifying the capabilities of three discrete manufacturing processes-milling, turning, and casting-based on part shape, quality, and material property attributes. Specifically, our approach utilizes machine learning to classify manufacturing process capabilities of these processes in terms of part shape attributes such as curvature, rotational symmetry, and pairwise surface point distance (D2) histogram computed from CAD models, as well as part quality (surface finish and size tolerance) and material property attributes of parts. In this manner, historical data can be utilized to classify the capabilities of manufacturing processes. We show that it is possible to achieve high classification accuracies-88% and 83% for the training and test data sets, respectively-using this approach. In addition, a key insight gained from this work is that part shape attributes alone are inadequate for discriminating between the capabilities of the manufacturing processes considered. Specifically, the inclusion of material property and part quality attributes enables the classifier to predict viable manufacturing processes that would otherwise be ignored using shape attributes alone. Future extensions of this work will include enriching the classification process with additional attributes such as production cost, as well as alternative classification methods.","cybermanufacturing,data-driven engineering,manufacturing planning",Article,"ASME, TWO PARK AVE, NEW YORK, NY 10016-5990 USA","Computer Science,Engineering",,,"FEATURE,RECOGNITION,DESIGN,FUTURE,MODEL",JOURNAL OF COMPUTING AND INFORMATION SCIENCE IN ENGINEERING,,
23,A novel hybrid algorithm for aiding prediction of prognosis in patients with hepatitis,32,8,3839-3852,"Parisi Luca,RaviChandran Narrendar,Manaog Marianne Lyne","Parisi L,RaviChandran N,Manaog ML",Parisi L,10.1007/s00521-019-04050-x,University of Auckland,"This study investigated the application of a novel hybrid artificial intelligence (AI)-based classifier for aiding prediction of the prognosis in patients with chronic hepatitis. Nineteen biomarkers on 155 patients with hepatitis from the University California Irvine Machine Learning repository were used as input data. Weights derived by applying the geometric margin maximisation criterion of a Lagrangian support vector machine (LSVM) were used for selecting the features associated with the highest relative importance towards the required classification, i.e. to predict whether a patient with hepatitis would have survived or died. Thus, the 19 initial features were reduced to the 16 most important prognostic factors and were fed into various AI-based classifiers. Results indicated an overall classification accuracy and area under the receiver operating characteristic curve of 100% for the proposed hybrid algorithm, the LSVM multilayer perceptron (MLP), thus demonstrating its potential for aiding prediction of prognosis in patients with hepatitis in a clinical setting.","Multilayer perceptron,Decision support,Prognosis,Hepatitis",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"DIAGNOSIS,SYSTEM,LIVER,FIBROSIS,DISEASE,CLASSIFICATION,RISK",NEURAL COMPUTING & APPLICATIONS,,
24,Convolutional neural network as a novel classification approach for laser-induced breakdown spectroscopy applications in lithological recognition,166,,,"Chen Junxi,Pisonero Jorge,Chen Sha,Wang Xu,Fan Qingwen,Duan Yixiang","Chen JX,Pisonero J,Chen S,Wang X,Fan QW,Duan YX",Fan QW; Duan YX,10.1016/j.sab.2020.105801,Sichuan University,"Rapid and accurate identification of multiple types of rocks using spectroscopic techniques has a wide market application prospect and is always challenging due to similar chemical composition and complex matrix effects. In recent years, laser induced breakdown spectroscopy (LIBS) coupled with supervised machine learning and chemometrics methods (e.g. k-nearest neighbor (kNN), support vector machine (SVM), partial least squares (PLS), artificial neural network (ANN)) and combined with feature engineering techniques (e.g. principal component analysis (PCA)), has demonstrated great capabilities for efficient identification of materials with similar chemical composition. To further increase the classification accuracy, LIBS coupled with a convolutional neural network with two-dimensional input (2D CNN) is here investigated for the identification of rock samples, including dolomites, granites, limestones, mudstones and shales. A regularized network structure was first designed, according to the performance of validation dataset, to enable the most reliable discrimination of the rock specimens. The accuracy of test dataset was then evaluated by the determined model. Results indicated that validation and test set of the 2D CNN was able to reach an accuracy of 0.9877 and 1, respectively. Finally, the performance was compared with other identification methods, including: one-dimensional convolutional neural network (1D CNN), kNN, PCA-kNN, SVM, PCA-SVM, PLS-DA, and Human-Assisted ANN (HA-ANN). The proposed approach has demonstrated that CNN has a great potential for the lithological identification and could be a feasible and useful tool for LIBS spectral data processing.","Laser induced breakdown spectroscopy,Convolutional neural network,Lithological recognition",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Spectroscopy,,3.375,"IDENTIFICATION,ELEMENTS,LIBS",SPECTROCHIMICA ACTA PART B-ATOMIC SPECTROSCOPY,,
25,A survey of feature extraction and fusion of deep learning for detection of abnormalities in video endoscopy of gastrointestinal-tract,53,4,2635-2707,"Ali Hussam,Sharif Muhammad,Yasmin Mussarat,Rehmani Mubashir Husain,Riaz Farhan","Ali H,Sharif M,Yasmin M,Rehmani MH,Riaz F",Ali H,10.1007/s10462-019-09743-2,COMSATS University Islamabad (CUI),"A standard screening procedure involves video endoscopy of the Gastrointestinal tract. It is a less invasive method which is practiced for early diagnosis of gastric diseases. Manual inspection of a large number of gastric frames is an exhaustive, time-consuming task, and requires expertise. Conversely, several computer-aided diagnosis systems have been proposed by researchers to cope with the dilemma of manual inspection of the massive volume of frames. This article gives an overview of different available alternatives for automated inspection, detection, and classification of various GI abnormalities. Also, this work elaborates techniques associated with content-based image retrieval and automated systems for summarizing endoscopic procedures. In this survey, we perform a comprehensive review of feature extraction techniques and deep learning methods which were specifically developed for automatic analysis of endoscopic videos. In addition, we categorize features extraction techniques according to image processing domains and further we classify them based on their visual descriptions. We also review hybrid feature extraction techniques which are developed by the fusion of different kind of basic descriptors. Moreover, this survey covers various endoscopy data-sets available for the bench-marking of vision based algorithms. On the basis of literature, we explain emerging trends in computerized analysis of endoscopy. We also survey important issues, challenges, and future research directions to the development of computer-assisted systems for detection of maladies and interactive surgery in the GI tract.","Convolutional neural network (CNN),Deep learning,Feature extraction,Gastrointestinal tract,Gastric cancer,Video endoscopy,Classification",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,7.857,"WIRELESS,CAPSULE,ENDOSCOPY,CONVOLUTIONAL,NEURAL-NETWORKS,COMPUTER-AIDED,CLASSIFICATION,CONFOCAL,LASER,ENDOMICROSCOPY,SMALL-BOWEL,TUMORS,GASTRIC-CANCER,AUTOMATIC,DETECTION,TEXTURE,DESCRIPTORS,IMAGE,SEGMENTATION,BLEEDING,DETECTION",ARTIFICIAL INTELLIGENCE REVIEW,,
26,"Identification of epileptic seizures in EEG signals using time-scale decomposition (ITD), discrete wavelet transform (DWT), phase space reconstruction (PSR) and neural networks",53,4,3059-3088,"Zeng Wei,Li Mengqing,Yuan Chengzhi,Wang Qinghui,Liu Fenglin,Wang Ying","Zeng W,Li MQ,Yuan CZ,Wang QH,Liu FL,Wang Y",Zeng W,10.1007/s10462-019-09755-y,Longyan University,"Traditionally, detection of epileptic seizures based on the visual inspection of neurologists is tedious, laborious and subjective. To overcome such disadvantages, numerous seizure detection techniques involving signal processing and machine learning tools have been developed. However, there still remain the problems of automatic detection with high efficiency and accuracy in distinguishing normal, interictal and ictal electroencephalogram (EEG) signals. In this study we propose a novel method for automatic identification of epileptic seizures in singe-channel EEG signals based upon time-scale decomposition (ITD), discrete wavelet transform (DWT), phase space reconstruction (PSR) and neural networks. First, EEG signals are decomposed into a series of proper rotation components (PRCs) and a baseline signal by using the ITD method. The first two PRCs of the EEG signals are extracted, which contain most of the EEG signals' energy and are considered to be the predominant PRCs. Second, four levels DWT is employed to decompose the predominant PRCs into different frequency bands, in which third-order Daubechies (db3) wavelet function is selected for analysis. Third, phase space of the PRCs is reconstructed based on db3, in which the properties associated with the nonlinear EEG system dynamics are preserved. Three-dimensional (3D) PSR together with Euclidean distance (ED) has been utilized to derive features, which demonstrate significant difference in EEG system dynamics between normal, interictal and ictal EEG signals. Fourth, neural networks are then used to model, identify and classify EEG system dynamics between normal (healthy), interictal and ictal EEG signals. Finally, experiments are carried out on the University of Bonn's widely used and publicly available epilepsy dataset to assess the effectiveness of the proposed method. By using the 10-fold cross-validation style, the achieved average classification accuracy for eleven cases is reported to be 98.15%. Compared with many state-of-the-art methods, the results demonstrate superior performance and the proposed method can serve as a potential candidate for the automatic detection of seizure EEG signals in the clinical application.","Electroencephalogram (EEG),Epileptic seizure detection,Time-scale decomposition (ITD),Phase space reconstruction (PSR),Discrete wavelet transform (DWT),System dynamics,Neural networks",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,7.857,"EMPIRICAL,MODE,DECOMPOSITION,FEATURE-EXTRACTION,FAULT-DIAGNOSIS,BINARY,PATTERN,CLASSIFICATION,REPRESENTATION,PREDICTION,DIMENSION,ENTROPY,FOREST",ARTIFICIAL INTELLIGENCE REVIEW,,
27,Recursive multiresolution convolutional neural networks for 3D aortic valve annulus planimetry,15,4,577-588,"Theriault-Lauzier Pascal,Alsosaimi Hind,Mousavi Negareh,Buithieu Jean,Spaziano Marco,Martucci Giuseppe,Brophy James,Piazza Nicolo","Theriault-Lauzier P,Alsosaimi H,Mousavi N,Buithieu J,Spaziano M,Martucci G,Brophy J,Piazza N",Theriault-Lauzier P,10.1007/s11548-020-02131-0,University of Ottawa,"Purpose Transcatheter aortic valve replacement (TAVR) is the standard of care in a large population of patients with severe symptomatic aortic valve stenosis. The sizing of TAVR devices is done from ECG-gated CT angiographic image volumes. The most crucial step of the analysis is the determination of the aortic valve annular plane. In this paper, we present a fully tridimensional recursive multiresolution convolutional neural network (CNN) to infer the location and orientation of the aortic valve annular plane. Methods We manually labeled 1007 ECG-gated CT volumes from 94 patients with severe degenerative aortic valve stenosis. The algorithm was implemented and trained using the TensorFlow framework (Google LLC, USA). We performed K-fold cross-validation with K = 9 groups such that CT volumes from a given patient are assigned to only one group. Results We achieved an average out-of-plane localization error of (0.7 +/- 0.6) mm for the training dataset and of (0.9 +/- 0.8) mm for the evaluation dataset, which is on par with other published methods and clinically insignificant. The angular orientation error was (3.9 +/- 2.3)degrees for the training dataset and (6.4 +/- 4.0)degrees for the evaluation dataset. For the evaluation dataset, 84.6% of evaluation image volumes had a better than 10 degrees angular error, which is similar to expert-level accuracy. When measured in the inferred annular plane, the relative measurement error was (4.73 +/- 5.32)% for the annular area and (2.46 +/- 2.94)% for the annular perimeter. Conclusions The proposed algorithm is the first application of CNN to aortic valve planimetry and achieves an accuracy on par with proposed automated methods for localization and approaches an expert-level accuracy for orientation. The method relies on no heuristic specific to the aortic valve and may be generalizable to other anatomical features.","Heart,Neural network,Machine learning,Segmentation,X-ray imaging and computed tomography",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,"LANDMARK,DETECTION,CT,SEGMENTATION,HEART,ROOT",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
28,Intrapapillary capillary loop classification in magnification endoscopy: open dataset and baseline methodology,15,4,651-659,"Garcia-Peraza-Herrera Luis C.,Everson Martin,Lovat Laurence,Wang Hsiu-Po,Wang Wen Lun,Haidry Rehan,Stoyanov Danail,Ourselin Sebastien,Vercauteren Tom","Garc?a-Peraza-Herrera LC,Everson M,Lovat L,Wang HP,Wang WL,Haidry R,Stoyanov D,Ourselin S,Vercauteren T",Garc?a-Peraza-Herrera LC,10.1007/s11548-020-02127-w,University of London,Purpose Early squamous cell neoplasia (ESCN) in the oesophagus is a highly treatable condition. Lesions confined to the mucosal layer can be curatively treated endoscopically. We build a computer-assisted detection system that can classify still images or video frames as normal or abnormal with high diagnostic accuracy. Methods We present a new benchmark dataset containing 68K binary labelled frames extracted from 114 patient videos whose imaged areas have been resected and correlated to histopathology. Our novel convolutional network architecture solves the binary classification task and explains what features of the input domain drive the decision-making process of the network. Results The proposed method achieved an average accuracy of 91.7% compared to the 94.7% achieved by a group of 12 senior clinicians. Our novel network architecture produces deeply supervised activation heatmaps that suggest the network is looking at intrapapillary capillary loop patterns when predicting abnormality. Conclusion We believe that this dataset and baseline method may serve as a reference for future benchmarks on both video frame classification and explainability in the context of ESCN detection. A future work path of high clinical relevance is the extension of the classification to ESCN types.,"Early squamous cell neoplasia (ESCN),Intrapapillary capillary loop (IPCL),Class activation map (CAM)",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,"SQUAMOUS-CELL,CARCINOMA,ESOPHAGEAL,DEPTH",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,https://link.springer.com/content/pdf/10.1007/s11548-020-02127-w.pdf,
29,Deep learning for automated cerebral aneurysm detection on computed tomography images,15,4,715-723,"Dai Xilei,Huang Lixiang,Qian Yi,Xia Shuang,Chong Winston,Liu Junjie,Di Ieva Antonio,Hou Xiaoxi,Ou Chubin","Dai XL,Huang LX,Qian Y,Xia S,Chong WT,Liu JJ,Di Ieva A,Hou XX,Ou CB",Qian Y,10.1007/s11548-020-02121-2,Macquarie University,"Purpose Cerebrovascular aneurysms are being observed with rapidly increasing incidence. Therefore, tools are needed for accurate and efficient detection of aneurysms. We used deep learning techniques with CT angiography acquired from multiple medical centers and different machines to develop and evaluate an automatic detection model. Methods In this study, we have introduced a deep learning model, the faster RCNN model, in order to develop a tool for automatic detection of aneurysms from medical images. The inputs of the model were 2D nearby projection (NP) images from 3D CTA, which were made by the NP method proposed in this study. This method made aneurysms clearly visible on images and improved the model's performance. The study included 311 patients with 352 aneurysms, selected from three hospitals, and 208 and 103 of these patients, respectively, were randomly selected to train and test the models. Results The sensitivity of the trained model was 91.8%. For aneurysm sizes larger than 3 mm, the sensitivity of successful aneurysm detection was 96.7%. We achieved state-of-the-art sensitivity for > 3 mm aneurysms. The sensitivities also indicated that there was no significant difference among aneurysms at different locations in the body. Computing time for the detection process was less than 25 s per case. Conclusions We successfully developed a deep learning model that can automatically detect aneurysms. The model performed well for aneurysms of different sizes or in different locations. This finding indicates that the deep learning model has the potential to vastly improve clinician performance by providing automated aneurysm detection.","Deep learning,Aneurysm detection,CTA,CNN",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,"UNRUPTURED,INTRACRANIAL,ANEURYSMS,DIABETIC-RETINOPATHY,ASSISTED,DETECTION,CT,ANGIOGRAPHY,DIAGNOSIS",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
30,A hybrid feature extraction and machine learning approaches for epileptic seizure detection,31,2,503-525,"Atal Dinesh Kumar,Singh Mukhtiar","Atal DK,Singh M",Singh M,10.1007/s11045-019-00673-4,Delhi Technological University,"Epileptic seizure detection from the brain EEG signals is an essential step for speeding up the diagnosis that assists researchers and medical professionals. For this, various classification signal processing techniques have been developed in the traditional works. Still, they limit with the problems of increased complexity, reduced performance and insufficient classification rate. This motivates to design an automatic system for classifying the normal and abnormal EEG signals. Thus, an efficient machine learning approaches are implemented in this work, to overcome the existing techniques limitations. Here, an enhanced curvelet transform technique is established in order to overcome the disadvantage of Gabor and Wavelet transformations data loss and indiscriminate orientations. This method has the capacity to furnish the all the signals data required with no information loss of shearlet transformation and hence implemented to preprocess the given EEG signal, which smoothen the signal by eliminating the noise. Then, a modified graph theory, fractal dimension and novel pattern transformation techniques are employed to extract the features and patterns. The extraction of features is crucial for classification and compression of huge volume of EEG signal that possess low information. This theory improves the precision and speed of the computational technique. Most of the current research, Graph theory is reflected in the area of quantitative description of the time series data. It is predominantly employed for the reduction of noise and not affected during choosing the factors. From the patterns, the statistical features are extracted by using a standard gray level co-occurrence matrix technique that comprises entropy, homogeneity, energy, correlation and maximum probability. This method calculates the linear dependency of the adjacent samples thereby effective measurement of information loss in the transmitted signal is accomplished. Then, these extracted features are fed to the classifier named as novel random forest classification for detecting and classifying the signal as healthy, ictal and interictal. During simulation, various performance measures have been used for evaluating the results of existing and proposed classification techniques and results validate the efficacy of proposed technique.","Electroencepharogram (EEG) signal,Epileptic seizure detection,Enhanced curvelet transformation (ECT),Modified graph theory (MRT),Novel pattern transformation (NPT),Novel random forest classification (NRFC)",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,1.92,"WAVELET,TRANSFORM,TIME-FREQUENCY,CLASSIFICATION",MULTIDIMENSIONAL SYSTEMS AND SIGNAL PROCESSING,,
31,Restoration of Out-of-Focus Fluorescence Microscopy Images Using Learning-Based Depth-Variant Deconvolution,12,2,,"He Da,Cai De,Zhou Jiasheng,Luo Jiajia,Chen Sung-Liang","He D,Cai D,Zhou JS,Luo JJ,Chen SL",Chen SL,10.1109/JPHOT.2020.2974766,Shanghai Jiao Tong University,"Image quality is degraded in the out-of-focus region because of the depth-variant (DV) point spread function (DV-PSF) of a fluorescence microscope. Either non-blind or blind deconvolution for restoration results in limited improvement. In this work, we propose a two-step learning-based DV deconvolution (LB-DVD) to restore the out-of-focus image. In the first step, DV-PSF is predicted by a defocus level prediction convolutional neural network (DelpNet). In the second step, the extracted DV-PSF is used for DV deconvolution. To our knowledge, LB-DVD is proposed and demonstrated for the first time. DelpNet achieves an accuracy of 98.2% for predicting defocus levels of image patches (84 x 84 pixels). The subsequent DV deconvolution gives rise to good performance in peak signal-to-noise ratios and structural similarity index, which are improved by up to 6.6 dB and 11%, respectively, before and after the deconvolution. As for a wide-field image, there exist different DV-PSFs within the two-dimensional fluorescence image due to the surface undulation. An overlapping weighting patch-wise LB-DVD is used in image montage to eliminate patch boundary artifacts. As a result, our LB-DVD shows the feasibility and promise to be applied to typical fluorescence microscopy in practical applications.","Fluorescence microscopy,convolutional neural network,deconvolution",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Optics,Physics",,2.602,"OPTICAL,COHERENCE,TOMOGRAPHY,QUALITY",IEEE PHOTONICS JOURNAL,https://doi.org/10.1109/jphot.2020.2974766,
32,Sim-To-Real Transfer Learning Approach for Tracking Multi-DOF Ankle Motions Using Soft Strain Sensors,5,2,3525-3532,"Park Hyunkyu,Cho Junhwi,Park Junghoon,Na Youngjin,Kim Jung","Park H,Cho J,Park J,Na Y,Kim J",Kim J,10.1109/LRA.2020.2979631,Korea Advanced Institute of Science & Technology (KAIST),"A data-driven approach has recently been investigated for identifying human joint angles by means of soft strain sensors because of the corresponding modeling difficulty. However, this approach commonly incurs a high computational burden due to the voluminous amount of data required and the time-series-oriented network architecture. Moreover, the nature of soft sensors makes the problem worse due to the inherent nonlinearity and hysteresis of the material. In this study, we developed a novel wearable sensing brace design for measuring multiple degrees of freedom (DOF) ankle motions to minimize hysteresis and to improve the measurement repeatability and developed a computationally efficient calibration method based on sim-to-real transfer learning. By attaching the soft sensors to shin links rather than directly to the ankle joint, the effects of external disturbances during joint motions were minimized. To calibrate the sensors to body motions, transfer learning was used based on the results from musculoskeletal simulation(OpenSim) and sensor data. The average tracking error for ankle motions using the proposed method was found to be 12.0 degrees for five healthy subjects, while the direct deep neural network approach showed an error of 17.9 degrees. The proposed method could be used to calibrate the soft sensors with 1000 times faster training speed while maintaining comparable tracking accuracy with a smaller amount of data.","Capacitive sensors,Calibration,Hysteresis,Robot sensing systems,Tracking,Strain measurement,Modeling,control,learning for soft robots,soft sensors and actuators,soft robot applications",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,"RECOGNITION,MODEL,SKIN",IEEE ROBOTICS AND AUTOMATION LETTERS,,
33,Safety Augmented Value Estimation From Demonstrations (SAVED): Safe Deep Model-Based RL for Sparse Cost Robotic Tasks,5,2,3612-3619,"Thananjeyan Brijen,Balakrishna Ashwin,Rosolia Ugo,Li Felix,McAllister Rowan,Gonzalez Joseph E.,Levine Sergey,Borrelli Francesco,Goldberg Ken","Thananjeyan B,Balakrishna A,Rosolia U,Li F,McAllister R,Gonzalez JE,Levine S,Borrelli F,Goldberg K",Thananjeyan B,10.1109/LRA.2020.2976272,University of California System,"Reinforcement learning (RL) for robotics is challenging due to the difficulty in hand-engineering a dense cost function, which can lead to unintended behavior, and dynamical uncertainty, which makes exploration and constraint satisfaction challenging. We address these issues with a new model-based reinforcement learning algorithm, Safety Augmented Value Estimation from Demonstrations (SAVED), which uses supervision that only identifies task completion and a modest set of suboptimal demonstrations to constrain exploration and learn efficiently while handling complex constraints. We then compare SAVED with 3 state-of-the-art model-based and model-free RL algorithms on 6 standard simulation benchmarks involving navigation and manipulation and a physical knot-tying task on the daVinci surgical robot. Results suggest that SAVEDoutperforms priormethods in terms of success rate, constraint satisfaction, and sample efficiency, making it feasible to safely learn a control policy directly on a real robot in less than an hour. For tasks on the robot, baselines succeed less than 5% of the time while SAVED has a success rate of over 75% in the first 50 training iterations. Code and supplementary material is available at https://tinyurl.com/ saved-rl.","Task analysis,Heuristic algorithms,Cost function,Planning,Uncertainty,Robots,Trajectory,Reinforcement learning,imitation learning,optimal control",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,,IEEE ROBOTICS AND AUTOMATION LETTERS,http://arxiv.org/pdf/1905.13402,
34,Novel Wearable Monitoring System of Forward Head Posture Assisted by Magnet-Magnetometer Pair and Machine Learning,20,7,3838-3848,"Han Hobeom,Jang Hyeongkyu,Yoon Sang Won","Han H,Jang H,Yoon SW",Yoon SW,10.1109/JSEN.2019.2959817,Hanyang University,"Forward head posture (FHP) increasingly threatens human health through numerous disorders. Wearable sensing methods facilitate promising solutions to portably quantify FHP symptoms. Flex and acceleration sensors are two major wearable sensors; however, several technical challenges still remain. This work proposes a novel wearable FHP sensing solution relying on a three-axis magnetometer paired with a miniature permanent magnet. The magnetometer precisely calibrates head postures by tracking directional changes of the magnetic field from the magnet and by sensor-fusing with an accelerometer. Sensor-fused data are processed by machine learning algorithms, either to provide neck-angle values representing craniovertebral angle with reduced noise (regression algorithms) or to determine risk levels of FHP (classification algorithms). Performances of four regression and four classification algorithms are compared for two experimental scenarios (named calibration-mode and usage-mode scenarios). In both scenarios, our sensor-fusion with the magnet-magnetometer pair exhibited outstanding performances compared to a conventional accelerometer approach. The performances differed by machine learning algorithms and scenarios, but reliably demonstrated extremely high correlation coefficients (R =0.9945) and classification accuracy (similar to 95.6%) in the calibration-mode scenario. When participants watched videos using their own smartphones (usage mode), a high correlation coefficient (R =similar to 0.9365) and classification accuracy (similar to>90.4%) were achieved.","Forward head posture,magnetometer,machine learning,wearable monitoring",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"MUSCULOSKELETAL,DYSFUNCTION,CRANIOVERTEBRAL,ANGLE,INSTRUMENT,MODES",IEEE SENSORS JOURNAL,,
35,LSTM-Based Auto-Encoder Model for ECG Arrhythmias Classification,69,4,1232-1240,"Hou Borui,Yang Jianyong,Wang Pu,Yan Ruqiang","Hou BR,Yang JY,Wang P,Yan RQ",Yan RQ,10.1109/TIM.2019.2910342,Xi'an Jiaotong University,"This paper introduces a novel deep learning-based algorithm that integrates a long short-term memory (LSTM)-based auto-encoder (AE) network with support vector machine (SVM) for electrocardiogram (ECG) arrhythmias classification. The LSTM-based AE network (LSTM-AE) is used to learn the features from ECG arrhythmias signals, and the SVM is used to classify those signals from the learned features. The LSTM-AE consists of an encoder model, which extracts high-level feature information from ECG arrhythmias signals through LSTM network, and a decoder model which outputs reconstruct ECG arrhythmias signals from high-level features through LSTM network. Experiments show that the proposed method can learn better features than the traditional method without any prior knowledge, presenting a good potential for the ECG arrhythmias classification. In the classification of five heartbeats types, including normal, left bundle branch block (LBBB), right bundle branch block (RBBB), atrial premature complexes (APC), premature ventricular contractions (PVC), the proposed method achieved average accuracy, sensitivity, and specificity of 99.74%;, 99.35%;, and 99.84%;, respectively, in the beat-based cross-validation approach, and 85.20%;, 62.99%;, and 90.75%;, respectively, in the record-based cross-validation approach, in public MIT-BIH Arrhythmia Database. While based on the Advancement of Medical Instrumentation (AAMI) standards, the proposed method achieved average accuracy, sensitivity, and specificity of 99.45%;, 98.63%;, and 99.66%;, respectively, in the beat-based cross-validation approach.","Auto-encoder (AE),cardiovascular diseases (CVDs),electrocardiogram (ECG),heartbeat arrhythmia,recurrent neural networks (RNNs),support vector machine (SVM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"MULTIRESOLUTION,WAVELET,TRANSFORM,AUTOMATIC,CLASSIFICATION,NETWORK,MODEL,SIGNALS,IDENTIFICATION,RECOGNITION,COMPRESSION,FEATURES",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
36,An End-to-End Steel Surface Defect Detection Approach via Fusing Multiple Hierarchical Features,69,4,1493-1504,"He Yu,Song Kechen,Meng Qinggang,Yan Yunhui","He Y,Song KC,Meng QG,Yan YH",Song KC; Yan YH,10.1109/TIM.2019.2915404,Northeastern University - China,"A complete defect detection task aims to achieve the specific class and precise location of each defect in an image, which makes it still challenging for applying this task in practice. The defect detection is a composite task of classification and location, leading to related methods is often hard to take into account the accuracy of both. The implementation of defect detection depends on a special detection data set that contains expensive manual annotations. In this paper, we proposed a novel defect detection system based on deep learning and focused on a practical industrial application: steel plate defect inspection. In order to achieve strong classification ability, this system employs a baseline convolution neural network (CNN) to generate feature maps at each stage, and then the proposed multilevel feature fusion network (MFN) combines multiple hierarchical features into one feature, which can include more location details of defects. Based on these multilevel features, a region proposal network (RPN) is adopted to generate regions of interest (ROIs). For each ROI, a detector, consisting of a classifier and a bounding box regressor, produces the final detection results. Finally, we set up a defect detection data set NEU-DET for training and evaluating our method. On the NEU-DET, our method achieves 74.8/82.3 mAP with baseline networks ResNet34/50 by using 300 proposals. In addition, by using only 50 proposals, our method can detect at 20 ft/s on a single GPU and reach 92% of the above performance, hence the potential for real-time detection.","Automated defect inspection (ADI),defect detection dataset (NEU-DET),defect detection network (DDN),multilevel-feature fusion network (MFN)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,CLASSIFICATION,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,https://figshare.com/articles/journal_contribution/An_end-to-end_steel_surface_defect_detection_approach_via_fusing_multiple_hierarchical_features/12249215/files/22534055.pdf,
37,Next-generation heartbeat classification with a column-store DBMS and UDFs,54,2,363-390,"Castro-Lopez Oscar,Lopez-Barron Daniel E.,Vega-Lopez Ines F.","Castro-Lopez O,Lopez-Barron DE,Vega-Lopez IF",Vega-Lopez IF,10.1007/s10844-019-00557-w,Universidad Autonoma de Sinaloa,"We live in a digital world where data is being generated at an always increasing rate. This creates the need to develop new technology not only for storing these vast amounts of data, but also for manipulating and analyzing it. It is through this data analysis that we can make decisions and generate knowledge. The medical field is no exception and healthcare and biomedical data must be stored and analyzed to gain insights that help in disease prevention and diagnostics. An example of this kind of data are electrocardiograms (ECG), whose careful analysis has proven to be of significant help to diagnose cardiovascular abnormalities. ECG recording devices can produce a very large amount of data in a short period of time. Usually abstracted as unstructured data, ECG digital signals have traditionally been stored and analyzed using file-based solutions for storage, and ad-hoc programs for data processing. We favor the idea that ECG signals can be abstracted as sets of tuples and stored in database relations. In this paper we present a proposal to store, manage, and analyze ECG data in a column-store database management system (DBMS). We provide extensive empirical evidence showing that incorporating complex analytical tasks such as ECG transformation and classification into a DBMS is not only feasible but also efficient and scalable. For this, we rely on the Structured Query Language provided by relational DBMSs, and the implementation of user defined functions.","User defined functions,Data management,Signal database",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,1.939,"ECG,BEAT,CLASSIFICATION,ELECTROCARDIOGRAPHY",JOURNAL OF INTELLIGENT INFORMATION SYSTEMS,,
38,Spatial resolution of local field potential signals in macaque V4,17,2,,"Foroushani Armin Najarpour,Neupane Sujaya,Pastor Pablo De Heredia,Pack Christopher C.,Sawan Mohamad","Foroushani AN,Neupane S,Pastor PD,Pack CC,Sawan M",Foroushani AN,10.1088/1741-2552/ab7321,Universite de Montreal,"Objective. An important challenge for the development of cortical visual prostheses is to generate spatially localized percepts of light, using artificial stimulation. Such percepts are called phosphenes, and the goal of prosthetic applications is to generate a pattern of phosphenes that matches the structure of the retinal image. A preliminary step in this process is to understand how the spatial positions of phosphene-like visual stimuli are encoded in the distributed activity of cortical neurons. The spatial resolution with which the distributed responses discriminate positions puts a limit on the capability of visual prosthesis devices to induce phosphenes at multiple positions. While most previous prosthetic devices have targeted the primary visual cortex, the extrastriate cortex has the advantage of covering a large part of the visual field with a smaller amount of cortical tissue, providing the possibility of a more compact implant. Here, we studied how well ensembles of Local Field Potentials (LFPs) and Multiunit activity (MUA) responses from extrastriate cortical visual area V4 of a behaving macaque monkey can discriminate between two-dimensional spatial positions. Approach. We used support vector machines (SVM) to determine the capabilities of LFPs and MUA to discriminate responses to phosphene-like stimuli (probes) at different spatial separations. We proposed a selection strategy based on the combined responses of multiple electrodes and used the linear learning weights to find the minimum number of electrodes for fine and coarse discriminations. We also measured the contribution of correlated trial-to-trial variability in the responses to the discrimination performance for MUA and LFP. Main results. We found that despite the large receptive field sizes in V4, the combined responses from multiple sites, whether MUA or LFP, are capable of fine and coarse discrimination of positions. Our electrode selection procedure significantly increased discrimination performance while reducing the required number of electrodes. Analysis of noise correlations in MUA and LFP responses showed that noise correlations in LFPs carry more information about spatial positions. Significance. This study determined the coding strategy for fine discrimination, suggesting that spatial positions could be well localized with patterned stimulation in extrastriate area V4. It also provides a novel approach to build a compact prosthesis with relatively few electrodes, which has the potential advantage of reducing tissue damage in real applications.","spatial discrimination,local field potential,V4,neural coding,support vector machines,correlation,cortical visual prosthesis",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"PRIMARY,VISUAL-CORTEX,ELECTRICAL-STIMULATION,NEURONAL,CORRELATION,INTRACORTICAL,MICROSTIMULATION,ARTIFICIAL,VISION,CORTICAL-NEURONS,TARGET,SELECTION,TEMPORAL,SCALES,CEREBRAL-CORTEX,BLIND",JOURNAL OF NEURAL ENGINEERING,http://arxiv.org/pdf/1911.07388,
39,Using machine learning to reveal the population vector from EEG signals,17,2,,"Kobler Reinmar J.,Almeida Ines,Sburlea Andreea I,Mueller-Putz Gernot R.","Kobler RJ,Almeida I,Sburlea AI,Muller-Putz GR",Muller-Putz GR,10.1088/1741-2552/ab7490,Graz University of Technology,"Objective. Since the discovery of the population vector that directly relates neural spiking activity with arm movement direction, it has become feasible to control robotic arms and neuroprostheses using invasively recorded brain signals. For non-invasive approaches, a direct relation between human brain signals and arm movement direction is yet to be established. Approach. Here, we investigated electroencephalographic (EEG) signals in temporal and spectral domains in a continuous, circular arm movement task. Using machine learning methods that respect the linear mixture of brain activity within EEG signals, we show that directional information is represented in the temporal domain in amplitude modulations of the same frequency as the arm movement, and in the spectral domain in power modulations of the 20-24 Hz frequency band. Main results. In the temporal domain, the directional information was mainly expressed in primary sensorimotor cortex (SM1) and posterior parietal cortex (PPC) contralateral to the moving arm, while in the spectral domain SM1 and PPC of both hemispheres predicted arm movement direction. The different cortical representations suggest distinct neural representations in both domains. Significance. This direct relation between neural activity and arm movement direction in both domains demonstrates the potential of machine learning to reveal neuroscientific insights about the dynamics of human arm movements.","electroencephalography,arm movement,machine learning,population vector,movement direction,continuous movement,source imaging",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"BRAIN-COMPUTER,INTERFACES,ARM,MOVEMENTS,HAND,MOVEMENTS,MOTOR,DIRECTION,ELECTROENCEPHALOGRAM,OSCILLATIONS,CORTEX,TRAJECTORIES,RESTORATION",JOURNAL OF NEURAL ENGINEERING,https://doi.org/10.1088/1741-2552/ab7490,
40,EEG-based personal identification method using unsupervised feature extraction and its robustness against intra-subject variability,17,2,,"Nishimoto Takashi,Higashi Hiroshi,Morioka Hiroshi,Ishii Shin","Nishimoto T,Higashi H,Morioka H,Ishii S",Ishii S,10.1088/1741-2552/ab6d89,"36-1 Yoshida Honmachi,Sakyo Ku, Kyoto 6068501, Japan.","Objective. Brain activity signals are possible biomarkers for personal authentication. However, they are inherently variable due to measurement-environment factors and subject-dependent factors; electroencephalography (EEG) signals could be different in days even for the same task, subject, and experimental settings. This variability could cause loss of consistency of the signals across multiple measurements of a single subject, and hence decrease the performance of EEG-based personal identification. In this study, we evaluated the influence of the variability on personal EEG features by using our original EEG dataset. Approach. We collected EEG signals in twenty subjects across four rounds (morning and afternoon daily for two days). At each round, we reinstalled an EEG cap on the subjects' scalps. To extract personal EEG features that were invariant across the sessions, we proposed unsupervised learning methods; common dictionary learning and t-distributed stochastic neighbor embedding. To assess the performance of personal identification, we compared two different experimental settings; test data recorded in the same round as the training data (Setting SR) and test data recorded in different rounds (Setting DR). Main results. The performance in SR was better than that in DR, suggesting that features dependent on the rounds were dominant. However, the 40% accuracy rate in DR, which is significantly higher than the chance level, suggests that our proposed method robustly extracted the personal features against the variability, in most cases. Furthermore, we also evaluated the performance of a problem, which involved detecting individuals who were not registered in the authentication system. In this problem, we obtained a similar result that the variability for the rounds influenced the performance. However, we obtained a good performance in the detection of some unknown subjects even in DR. Significance. We found the variability in EEG data actually affected the personal features that were used for personal identification. Even considering the variability in EEG data, however, we found our proposed method is applicable in personal authentication scenarios, i.e. personal identification and unknown detection.","personal identification,biometric authentication,electroencephalography,dictionary learning,sparse coding,resting-state brain activity,spatial attention",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"RECOGNITION,PATTERNS,SPARSE",JOURNAL OF NEURAL ENGINEERING,https://iopscience.iop.org/article/10.1088/1741-2552/ab6d89/pdf,
41,Ensemble classifier based on optimized extreme learning machine for motor imagery classification,17,2,,"Zhang Li,Wen Dezhong,Li Changsheng,Zhu Rui","Zhang L,Wen DZ,Li CS,Zhu R",Zhang L; Wen DZ,10.1088/1741-2552/ab7264,Chongqing University,"Objective. Designing an effective classifier with high classification accuracy and strong generalization capability is essential for brain-computer interface (BCI) research. In this study, an extreme learning machine (ELM) based method is proposed to improve the classification accuracy of motor imagery electroencephalogram (EEG). Approach. The proposed method constructs an ensemble classifier based on optimized ELMs. Particle swarm optimization is used to simultaneously optimize the input weights and hidden biases of ELM to avoid the randomness and instability of classification result when ELM uses randomly generated parameters, and majority voting strategy is used to fuse the classification results of multiple base classifiers to avoid the negative impact of ELM with local optimal parameters on classification result. The proposed method was compared with four competing methods in experiments based on two public EEG datasets and some existing methods reported in the literature using the same datasets as well. Main results. The results indicate that the proposed method achieved significant higher classification accuracies than those of the competing methods on both two-class and four-class motor imagery data. Moreover, compared to the existing methods, it still obtained superior average accuracies of two-class classification and performed better for the subjects with relatively poor accuracies on both two-class and four-class classifications. Significance. The significant accuracy improvement demonstrates the superiority of the proposed method. It can be a promising candidate for accurate classification of motor imagery EEG in BCI systems.","brain-computer interface (BCI),motor imagery (MI),particle swarm optimization (PSO),extreme learning machine (ELM),majority voting strategy",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"EEG,FEATURES,BCI",JOURNAL OF NEURAL ENGINEERING,,
42,F2S3: Robustified determination of 3D displacement vector fields using deep learning,14,2,177-189,"Gojcic Zan,Zhou Caifa,Wieser Andreas","Gojcic Z,Zhou CF,Wieser A",Gojcic Z,10.1515/jag-2019-0044,ETH Zurich,"Areal deformation monitoring based on point clouds can be a very valuable alternative to the established point-based monitoring techniques, especially for deformation monitoring of natural scenes. However, established deformation analysis approaches for point clouds do not necessarily expose the true 3D changes, because the correspondence between points is typically established naively. Recently, approaches to establish the correspondences in the feature space by using local feature descriptors that analyze the geometric peculiarities in the neighborhood of the interest points were proposed. However, the resulting correspondences are noisy and contain a large number of outliers. This impairs the direct applicability of these approaches for deformation monitoring. In this work, we propose Feature to Feature Supervoxel-based Spatial Smoothing (F2S3), a new deformation analysis method for point cloud data. In F2S3 we extend the recently proposed feature-based algorithms with a neural network based outlier detection, capable of classifying the putative pointwise correspondences into inliers and outliers based on the local context extracted from the supervoxels. We demonstrate the proposed method on two data sets, including a real case data set of a landslide located in the Swiss Alps. We show that while the traditional approaches, in this case, greatly underestimate the magnitude of the displacements, our method can correctly estimate the true 3D displacement vectors.","Deformation monitoring,point clouds,neural networks,local feature descriptors,outlier detection,displacement vectors,RANSAC",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY",Remote Sensing,,,,JOURNAL OF APPLIED GEODESY,https://www.degruyter.com/downloadpdf/journals/jag/14/2/article-p177.pdf,
43,Sequential decision-making in mining and processing based on geometallurgical inputs,149,,,"Koch Pierre-Henri,Rosenkranz Jan","Koch PH,Rosenkranz J",Koch PH,10.1016/j.mineng.2020.106262,Lulea University of Technology,"Geometallurgy as a multi-disciplinary field has been applied at various levels in different operations. By linking the ore performance in mineral beneficiation processes to the ore block model, it supports estimating the value of a block before it is mined. Efforts in the classification of the ore into geometallurgical classes have led to a better understanding of the entire value chain. While classification provides a convenient tool for forecasting and visualization purposes, it simplifies the actual complexity of an ore body. In mining and process planning, sequential decisions are made to maximize an objective function or equivalently minimize a regret function. Using available information from geology or metallurgical test work, an optimal strategy can be found using tools from the machine learning community.
In this study, a framework based on machine learning to maximize the use of such classifications for sequential decision-making is proposed. The concepts of reinforcement learning and bandit algorithms, offer powerful tools to explore and exploit different optimization strategies. In certain cases, theoretical guarantees about the performance of given methods can be obtained by regret bounds.
Based on existing models of a porphyry copper deposit and an iron ore deposit, this study presents a methodology and different available algorithms to maximize an objective function that depends on a high number of variables and in the presence of noise or uncertainty in the models. Different numerical experiments provide a basis for discussion and comparison to human decisions. The hypotheses relative to each algorithm are discussed in relation to the mineral processing models.","Geometallurgy,Optimization,Decision-making,Data integration,Process simulation,Digitalization",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Engineering,Mineralogy,Mining & Mineral Processing",,4.884,"POLICIES,REGRET",MINERALS ENGINEERING,,
44,A neural network approach for spatial variation assessment - A nepheline syenite case study,149,,,"Silva Camilo A. Mena,Ellefmo Steinar L.,Sandoy Roar,Sorensen Bjorn E.,Aasly Kurt","Silva CAM,Ellefmo SL,Sandoy R,Sorensen BE,Aasly K",Silva CAM,10.1016/j.mineng.2019.106178,Norwegian University of Science & Technology (NTNU),"The present geometallurgical study shows the application of a machine-learning methodology to the prediction of material properties from the Nabbaren nepheline syenite deposit in Norway. The approach used in this study created and tested a shallow neural network along with cluster analysis for the prediction of laboratory concentrate yield and modal mineralogy. The input is bulk chemistry data from the mining company open pit database. The methodology proposed unveils general trends in the deposit to a suitable operational scale for the open pit mine. The accuracy of the prediction models is good, with one of the prediction models achieving a strong correlation coefficient of 0.9. The application of a neural network approach showed a successful attempt in the prediction of concentrate yield and modal mineralogy in the Nabbaren nepheline syenite deposit. However, further investigations in terms of deposit internal variation and mineralogical studies are needed for utilising these prediction models, to further improve the modal mineralogy prediction model by better domaining and for a more representative distribution of samples for modal mineralogy analyses.","Geometallurgy,Neural network,Concentrate yield,Mineralogy,Modelling,Spatial modelling,Industrial minerals,Nepheline syenite",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Engineering,Mineralogy,Mining & Mineral Processing",,4.884,"ORE-DEPOSIT,PROCESS,MINERALOGY,SEILAND,PROVINCE,STJERNOY,EVOLUTION,TEXTURE,CLASSIFICATION,MODEL,TOOL",MINERALS ENGINEERING,,
45,Classification of Alzheimer's disease based on brain MRI and machine learning,32,7,1927-1936,"Fan Zhao,Xu Fanyu,Qi Xuedan,Li Cai,Yao Lili","Fan Z,Xu FY,Qi XD,Li C,Yao LL",Fan Z,10.1007/s00521-019-04495-0,Shanxi Medical University,"Alzheimer's disease (AD) is one of the most common diseases in the world. It is a neurodegenerative disease that can cause cognitive impairment and memory deterioration. In recent years, the number of the elderly population is increasing, and the incidence of elderly diseases has increased significantly. The most representative of these diseases is Alzheimer's disease. According to some data, the average survival time of Alzheimer's disease patients is only 5.5 years, which is the ""fourth killer"" that endangers the health of the elderly after cardiovascular diseases, cerebrovascular diseases and cancer. According to conservative estimates of the International Federation of Alzheimer's Diseases, the number of Alzheimer's disease patients worldwide will increase to 75.62 million by 2030; by 2050, the number of patients will reach 135.46 million. Therefore, it is urgent to classify the course of Alzheimer's disease. In this paper, support vector machine (SVM) model method is used to classify and predict different disease processes of Alzheimer's disease based on structural brain magnetic resonance imaging (MRI) imaging data, so as to help the auxiliary diagnosis of the disease. In this paper, the extracted MRI data and the SVM model are combined to obtain more accurate classification prediction results. The accuracy of classification and prediction is the best. According to the predicted results, the data characteristics related to diseases can be determined, which can provide a basis for clinical and basic research, etiology and pathological changes.","Machine learning,Support vector machine,Brain MRI,Alzheimer's disease",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"DIAGNOSTIC-CRITERIA,RISK,DEMENTIA,MEMORY,AD",NEURAL COMPUTING & APPLICATIONS,,
46,Forward and reverse modelling of flow forming of solution annealed H30 aluminium tubes,32,7,2081-2093,"Podder Bikramjit,Banerjee Prabas,Kumar K. Ramesh,Hui Nirmal Baran","Podder B,Banerjee P,Kumar KR,Hui NB",Hui NB,10.1007/s00521-018-3749-x,"NIT, Durgapur, India.","Modelling of flow forming of tube-shaped solution annealed H30 Aluminium alloy is considered in the present study. Initially, a total of 136 experiments have been conducted to realize the process and subsequently influences of three inputs (feed-speed ratio, roller infeed and axial stagger) on the three outputs, viz. internal diameter, springback and ovality have been studied. Three neural network-based approaches (back-propagation neural network, limited-memory BFGS network and genetic neural system) have been developed for forward as well as reverse modelling of the process. During forward modelling, the performances of the three neural network-based approaches have been compared with the regression model. It is seen that GANN has performed much better compared to the other methods. Percentage accuracy in predicting ovality using regression analysis is the worst, and it necessitates consideration of more input process parameters for better prediction accuracy. However, NN-based approaches adapted such cases well. Comparison of all the three NN-based approaches among themselves has been made during reverse modelling. During this process, prediction accuracy, using LBFGSNN, is found to be better than the other two methods. Thus, it is perceived that NN-based models might suit better for prediction of shape accuracy of flow-formed shell.","Flow-forming,H30 aluminium alloy,Springback,Ovality,Neural network,Genetic algorithm,L-BFGS-B algorithm",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,,"OPTIMIZATION,PARAMETERS,ROUGHNESS,ALGORITHM",NEURAL COMPUTING & APPLICATIONS,,
47,An entropy-based classification of breast cancerous genes using microarray data,32,7,2397-2404,"Mondal Mausami,Semwal Rahul,Raj Utkarsh,Aier Imlimaong,Varadwaj Pritish Kumar","Mondal M,Semwal R,Raj U,Aier I,Varadwaj PK",Varadwaj PK,10.1007/s00521-018-3864-8,Indian Institute of Information Technology Allahabad,"Gene expression levels obtained from microarray data provide a promising technique for doing classification on cancerous data. Due to the high dimensionality of the microarray datasets, the redundant genes need to be removed and only significant genes are required for building the classifier. In this work, an entropy-based method was used based on supervised learning to differentiate between normal tissue and breast tumor based on their gene expression profiles. This work employs four widely used machine learning techniques for breast cancer prediction, namely support vector machine (SVM), random forest, k-nearest neighbor (KNN) and naive Bayes. The performance of these techniques was evaluated on four different classification performance measurements which result in getting more accuracy in case of SVM as compared to other machine learning algorithms. Classification accuracy of 91.5% was achieved by support vector machine with 0.833 F1 measures. Furthermore, these techniques were evaluated on the basis of performance by ROC curve and calibration graph.","Support vector machine,k-Nearest neighbor,Random forest,Naive Bayes,Classification",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"SUPPORT,VECTOR,MACHINE,EXPRESSION,PREDICTION,REGRESSION",NEURAL COMPUTING & APPLICATIONS,,
48,Quantitative comparison of the predictions of fracture toughness temperature dependence using ASTM E1921 master curve and stress distribution T-scaling methods,111,,,"Meshii Toshiyuki,Yakushi Goh,Takagishi Yoichi,Fujimoto Yohei,Ishihara Kenichi","Meshii T,Yakushi G,Takagishi Y,Fujimoto Y,Ishihara K",Meshii T,10.1016/j.engfailanal.2020.104458,University of Fukui,"The fracture toughness temperature dependence of ferritic steels in the ductile-to-brittle transition temperature region, predicted using the ASTM E1921 master curve (MC) and stress distribution T-scaling (CDS) methods, is presented in this paper. A total of 34 cases (i.e., combination of material heats and specimen types) including 661 fracture toughness test data were considered. First, the direct correlation between fracture toughness and yield stress-as suggested by the CDS method-was validated using machine learning techniques. Subsequently, the accuracy of the predictions obtained by each method was quantitatively evaluated using a coefficient of determination. In 25 out of the 34 cases, the CDS method showed better prediction ability than the MC method. In the other 9 cases, the difference between the two methods was small, if considered from an engineering perspective.","Fracture toughness,Ductile-to-brittle transition temperature region,Temperature dependence,T-scaling,Machine learning",Article; Proceedings Paper,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Engineering,Materials Science",,3.233,"TRANSITION,FAILURE,STEEL",ENGINEERING FAILURE ANALYSIS,https://doi.org/10.1016/j.engfailanal.2020.104458,
49,Machine-Learning-Accelerated Perovskite Crystallization,2,4,938-947,"Kirman Jeffrey,Johnston Andrew,Kuntz Douglas A.,Askerka Mikhail,Gao Yuan,Todorovic Petar,Ma Dongxin,Prive Gilbert G.,Sargent Edward H.","Kirman J,Johnston A,Kuntz DA,Askerka M,Gao Y,Todorovic P,Ma DX,Prive GG,Sargent EH",Sargent EH,10.1016/j.matt.2020.02.012,University of Toronto,"Perovskites have seen significant research interest in the last decade. As ternary and quaternary compounds, their chemical space is exceptionally large, yet perovskite development has been limited to a restricted set of chemical constituents often discovered through trial and error. Here, we report a highthroughput experimental framework for the discovery of new perovskite single crystals. We use machine learning (ML) to guide the sequence of ever-improved robotic synthetic trials. We perform high-throughput syntheses of perovskite single crystals with a protein crystallization robot and characterize the outcomes with the aid of convolutional neural network-based image recognition. We then use an ML model to predict the optimal conditions for the synthesis of a new perovskite single crystal, enabling us to report the first synthesis of (3-PLA)(2)PbCl4.This material exhibits strong blue emission, illustrating the applicability of the method in identifying new optoelectronic materials.",SOLAR-CELLS,Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,15.589,SOLAR-CELLS,MATTER,http://www.cell.com/article/S2590238520300746/pdf,
50,Deep 1D-Convnet for accurate Parkinson disease detection and severity prediction from gait,143,,,"El Maachi Imanne,Bilodeau Guillaume-Alexandre,Bouachir Wassim","El Maachi I,Bilodeau GA,Bouachir W",Bouachir W,10.1016/j.eswa.2019.113075,University of Quebec,"Diagnosing Parkinson's disease is a complex task that requires the evaluation of several motor and non motor symptoms. During diagnosis, gait abnormalities are among the important symptoms that physicians should consider. However, gait evaluation is challenging and relies on the expertise and subjectivity of clinicians. In this context, the use of an intelligent gait analysis algorithm may assist physicians in order to facilitate the diagnosis process. This paper proposes a novel intelligent Parkinson detection system based on deep learning techniques to analyze gait information. We used 1D convolutional neural network (1D-Convnet) to build a Deep Neural Network (DNN) classifier. The proposed model processes 18 1D-signals coming from foot sensors measuring the vertical ground reaction force (VGRF). The first part of the network consists of 18 parallel 1D-Convnet corresponding to system inputs. The second part is a fully connected network that connects the concatenated outputs of the 1D-Convnets to obtain a final classification. We tested our algorithm in Parkinson's detection and in the prediction of the severity of the disease with the Unified Parkinson's Disease Rating Scale (UPDRS). Our experiments demonstrate the high efficiency of the proposed method in the detection of Parkinson disease based on gait data. The proposed algorithm achieved an accuracy of 98.7%. To our knowledge, this is the state-of-the-start performance in Parkinson's gait recognition. Furthermore, we achieved an accuracy of 85.3% in Parkinson's severity prediction. To the best of our knowledge, this is the first algorithm to perform a severity prediction based on the UPDRS.
These results show that the model is able to learn intrinsic characteristics from gait data and to generalize to unseen subjects, which could be helpful in a clinical diagnosis. (C) 2019 Elsevier Ltd. All rights reserved.","1D-Convnet,Parkinson,Gait,Classification,Deep learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"FEATURES,RHYTHM",EXPERT SYSTEMS WITH APPLICATIONS,https://r-libre.teluq.ca/1791/1/ESWA%20paper.pdf,
51,A feature transfer enabled multi-task deep learning model on medical imaging,143,,,"Gao Fei,Yoon Hyunsoo,Wu Teresa,Chu Xianghua","Gao F,Yoon H,Wu T,Chu XH",Yoon H,10.1016/j.eswa.2019.112957,Arizona State University,"Object detection, segmentation, and classification are three common tasks in medical image analysis. Multi-task deep learning (MTL) tackles these three tasks jointly, which provides two advantages-saving computational cost and improving robustness against overfitting. Existing multi-task deep models start with learning each task as an individual objective in parallel and then integrate the tasks at the end of the architecture with one cost function. Such architecture fails to take advantage of the combined power of the features from each individual task at an early stage of the training. In this research, we propose a new architecture, FT-MTL-Net, an MTL model enabled by feature transfer. Traditional transfer learning deals with the same or similar task (e.g., classification) from different data sources (a.k.a. domain). The underlying assumption is that the knowledge gained from various source domains may help the learning task on the target domain. Our proposed FT-MTL-Net utilizes the different tasks from the same domain. Considering that features from the tasks are different views of the domain, the combined feature maps can be well exploited using knowledge from multiple views to enhance the generalizability. To evaluate the validity of the proposed approach, FT-MTL-Net is compared with models from literature including eight classification models, four detection models, and three segmentation models using a publicly available Full Filed Digital Mammogram dataset for breast cancer diagnosis. Experimental results show that the proposed FT-MTL-Net outperforms the competing models in classification and detection and has comparable results in segmentation. (C) 2019 Elsevier Ltd. All rights reserved.","Multi-task deep learning,Object detection,Segmentation,Classification,Medical imaging analysis",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"CONVOLUTIONAL,NEURAL-NETWORK,CLASSIFICATION,MAMMOGRAMS,SEGMENTATION,MASS,CNN",EXPERT SYSTEMS WITH APPLICATIONS,http://arxiv.org/pdf/1906.01828,
52,Real-time biomechanical modeling of the liver using Machine Learning models trained on Finite Element Method simulations,143,,,"Pellicer-Valero Oscar J.,Jose Ruperez Maria,Martinez-Sanchis Sandra,Martin-Guerrero Jose D.","Pellicer-Valero OJ,Ruperez MJ,Martinez-Sanchis S,Martin-Guerrero JD",Pellicer-Valero OJ,10.1016/j.eswa.2019.113083,University of Valencia,"The development of accurate real-time models of the biomechanical behavior of different organs and tissues still poses a challenge in the field of biomechanical engineering. In the case of the liver, specifically, such a model would constitute a great leap forward in the implementation of complex applications such as surgical simulators, computed-assisted surgery or guided tumor irradiation.
In this work, a relatively novel approach for developing such a model is presented. It consists in the use of a machine learning algorithm, which provides real-time inference, trained on tens of thousands of simulations of the biomechanical behavior of the liver carried out by the finite element method on more than 100 different liver geometries.
Considering a target accuracy threshold of 3 mm for the Euclidean Error, four different scenarios were modeled and assessed: a single liver with an arbitrary force applied (99.96% of samples within the accepted error range), a single liver with two simultaneous forces applied (99.84% samples in range), a single liver with different material properties and an arbitrary force applied (98.46% samples in range), and a much more general model capable of modeling the behavior of any liver with an arbitrary force applied (99.01% samples in range for the median liver).
The results show that the Machine Learning models perform extremely well on all the scenarios, managing to keep the Mean Euclidean Error under 1 mm in all cases. Furthermore, the proposed model achieves working frequencies above 100Hz on modest hardware (with frequencies above 1000Hz being easily achievable on more powerful GPUs) thus fulfilling the real-time requirements. These results constitute a remarkable improvement in this field and may involve a prompt implementation in clinical practice. (C) 2019 Elsevier Ltd. All rights reserved.","Machine learning,Finite element method,Real time,Liver,Coherent point drift,Biomechanical modeling",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"DEFORMATIONS,FRAMEWORK",EXPERT SYSTEMS WITH APPLICATIONS,https://riunet.upv.es/bitstream/10251/167836/7/Pellcer-Valero%3bRup%c3%a9rez%3bMartnez-Sanchs%20-%20Real-tme%20bomechancal%20modelng%20of%20the%20lver%20usng%20Machne%20Lear....pdf,
53,Comparison of supervised machine learning classification techniques in prediction of locoregional recurrences in early oral tongue cancer,136,,,"Alabi Rasheed Omobolaji,Elmusrati Mohammed,Sawazaki-Calone Iris,Kowalski Luiz Paulo,Haglund Caj,Coletta Ricardo D.,Makitie Antti A.,Salo Tuula,Almangush Alhadi,Leivo Ilmo","Alabi RO,Elmusrati M,Sawazaki-Calone I,Kowalski LP,Haglund C,Coletta RD,Makitie AA,Salo T,Almangush A,Leivo I",Alabi RO,10.1016/j.ijmedinf.2019.104068,University of Vaasa,"Background: The proper estimate of the risk of recurrences in early-stage oral tongue squamous cell carcinoma (OTSCC) is mandatory for individual treatment-decision making. However, this remains a challenge even for experienced multidisciplinary centers.
Objectives: We compared the performance of four machine learning (ML) algorithms for predicting the risk of locoregional recurrences in patients with OTSCC. These algorithms were Support Vector Machine (SVM), Naive Bayes (NB), Boosted Decision Tree (BDT), and Decision Forest (DF).
Materials and methods: The study cohort comprised 311 cases from the five University Hospitals in Finland and A.C. Camargo Cancer Center, Sao Paulo, Brazil. For comparison of the algorithms, we used the harmonic mean of precision and recall called F1 score, specificity, and accuracy values. These algorithms and their corresponding permutation feature importance (PFI) with the input parameters were externally tested on 59 new cases. Furthermore, we compared the performance of the algorithm that showed the highest prediction accuracy with the prognostic significance of depth of invasion (DOI).
Results: The results showed that the average specificity of all the algorithms was 71% The SVM showed an accuracy of 68% and F1 score of 0.63, NB an accuracy of 70% and F1 score of 0.64, BDT an accuracy of 81% and F1 score of 0.78, and DF an accuracy of 78% and F1 score of 0.70. Additionally, these algorithms outperformed the DOI-based approach, which gave an accuracy of 63%. With PFI-analysis, there was no significant difference in the overall accuracies of three of the algorithms; PFI-BDT accuracy increased to 83.1%, PFI-DF increased to 80%, PFI-SVM decreased to 64.4%, while PFI-NB accuracy increased significantly to 81.4%.
Conclusions: Our findings show that the best classification accuracy was achieved with the boosted decision tree algorithm. Additionally, these algorithms outperformed the DOI-based approach. Furthermore, with few parameters identified in the PFI analysis, ML technique still showed the ability to predict locoregional recurrence. The application of boosted decision tree machine learning algorithm can stratify OTSCC patients and thus aid in their individual treatment planning.","Artificial intelligence,Oral tongue cancer,Machine learning,Prediction",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Health Care Sciences & Services,Medical Informatics",,4.768,"SQUAMOUS-CELL,CARCINOMA,SURVIVAL,METASTASIS,MODEL,INVASION",INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS,http://jultika.oulu.fi/files/nbnfi-fe2020051230662.pdf,
54,Status of research and development of learning-based approaches in nuclear science and engineering: A review,359,,,"Gomez-Fernandez Mario,Higley Kathryn,Tokuhiro Akira,Welter Kent,Wong Weng-Keen,Yang Haori","Gomez-Fernandez M,Higley K,Tokuhiro A,Welter K,Wong WK,Yang HR",Gomez-Fernandez M,10.1016/j.nucengdes.2019.110479,Oregon State University,"Nuclear technology industries have increased their interest in using data-driven methods to improve safety, reliability, and availability of assets. To do so, it is important to understand the fundamentals between the disciplines to effectively develop and deploy such systems. This survey presents an overview of the fundamentals of artificial intelligence and the state of development of learning-based methods in nuclear science and engineering to identify the risks and opportunities of applying such methods to nuclear applications. This paper focuses on applications related to three key subareas related to safety and decision-making. These are reactor health and monitoring, radiation detection, and optimization. The principles of learning-based methods in these applications are explained and recent studies are explored. Furthermore, as these methods have become more practical during the past decade, it is foreseen that the popularity of learning-based methods in nuclear science and technology will increase; consequently, understanding the benefits and barriers of implementing such methodologies can help create better research plans, and identify project risks and opportunities.","Nuclear science,Machine learning,Robust artificial intelligence,Artificial monitoring and controls,Decision-making,Human-machine symbiosis,Advanced technologies,Innovation",Review,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND",Nuclear Science & Technology,,1.837,"ARTIFICIAL,NEURAL-NETWORKS,GAMMA-RAY,SPECTRA,MULTILAYER,FEEDFORWARD,NETWORKS,OCCURRING,RADIOACTIVE,MATERIALS,LOADING,PATTERN,OPTIMIZATION,2-PHASE,FLOW,REGIMES,HUMAN,HEALTH-RISK,POWER-PLANTS,DIAGNOSTIC,SYSTEM,DECISION-MAKING",NUCLEAR ENGINEERING AND DESIGN,https://doi.org/10.1016/j.nucengdes.2019.110479,
55,Reconstruction method with the learned regularizer for imaging problems in electrical capacitance tomography,89,,,"Lei J.,Liu Q. B.","Lei J,Liu QB",Lei J,10.1016/j.asoc.2020.106126,North China Electric Power University,"The electrical capacitance tomography (ECT) is an attractive tomography method for process monitoring applications across different tasks and domains, but low quality images deteriorate its reliability and applicability. In order to change this situation, a potent method is developed to reduce reconstruction artifacts in this study. The learned regularization (LR) from a new ensemble learning method that integrates the advantageous properties of the least square support vector machine (LSSVM) method, the random projection (RP) method and the sparse matrix regression (SMR) solved by the differential evolution (DE) algorithm is proposed to increase the elasticity in mining and utilizing the prior knowledge. A potent model for imaging is devised by simultaneously taking advantage of the domain knowledge of the reconstruction targets (RTs) and the LR. The iterative split Bregman (ISB) is extended into a simple but powerful solver for the devised model by leveraging the forward backward splitting (FBS) algorithm and the soft thresholding (ST) algorithm to solve sub-problems efficiently. The imaging method proposed in the study is validated to successfully work on a series of testing tasks with the significant improvement of the reconstruction quality (RQ) over the popular imaging methods. (C) 2020 Elsevier B.V. All rights reserved.","Image reconstruction,Least square support vector machine,Random projection,Ensemble learning,Learned regularization,Regularized imaging method,Differential evolution algorithm,Inverse problem,Electrical capacitance tomography",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,6.607,"ALTERNATING,DIRECTION,METHOD,DIFFERENTIAL,EVOLUTION,INVERSION,ALGORITHM,SIGNAL,RECOVERY,OPTIMIZATION,MULTIPLIERS,ITERATION,SELECTION,ONLINE",APPLIED SOFT COMPUTING,,
56,Using machine learning and feature engineering to characterize limited material datasets of high-entropy alloys,175,,,"Dai Dongbo,Xu Tao,Wei Xiao,Ding Guangtai,Xu Yan,Zhang Jincang,Zhang Huiran","Dai DB,Xu T,Wei X,Ding GT,Xu Y,Zhang JC,Zhang HR",Zhang HR,10.1016/j.commatsci.2020.109618,Shanghai University,"The prediction of the phase formation of high entropy alloys (HEAs) has attracted great research interest recent years due to their superior structure and mechanical properties of single phase. However, the identification of these single phase solid solution alloys is still a challenge. Previous studies mainly focus on trial-and-error experiments or thermodynamic criteria, the previous is time consuming while the latter depends on the descriptors quality, both provide unreliable prediction. In this study, we attempted to predict the phase formation based on feature engineering and machine learning (ML) with a small dataset. The descriptor dimensionality is augmented from original small dimension to high dimension by non-linear combinations to characterize HEAs. The results showed that this method could achieve higher accuracy in predicting the phase formation of HEAs than traditional methods. Except the prediction of HEAs, this method also can be applied to other materials with limited dataset.","High-entropy alloy,Phase transformations,Machine learning,Feature engineering",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"SOLID-SOLUTION,PHASE,PREDICTION,SELECTION,DESIGN,CLASSIFICATION,STABILITY",COMPUTATIONAL MATERIALS SCIENCE,,
57,Predicting microstructure-dependent mechanical properties in additively manufactured metals with machine- and deep-learning methods,175,,,"Herriott Carl,Spear Ashley D.","Herriott C,Spear AD",Spear AD,10.1016/j.commatsci.2020.109599,Utah System of Higher Education,"In this work, we investigate the performance of data-driven modeling for mechanical property prediction of a simulated microstructural dataset. The dataset comprises realistic microstructural subvolumes of metal additive-manufactured stainless steel 316L and corresponding effective mechanical properties that were generated with a physics-driven modeling framework. The data-driven models leveraged for this work include Ridge regression, XGBoost, and a custom 3D convolutional neural network (CNN) based on VGGNet. Morphological and crystallographic features describing each microstructure serve as the inputs for the Ridge regression and XGBoost models. The CNN is trained with a 3D image of the microstructure represented by progressively informative input data (ranging from grain ID to crystal orientation, and supplemented with auxiliary features describing the mechanical loading) to determine the relative improvement among different feature types. Comparisons are drawn between the predictive performance of each data-driven model in terms of different scoring metrics and spatial-property maps. The computational efficiency of each data-driven model and the physics-driven modeling framework is also reported. Among all of the data-driven models tested, the CNN models that use crystal orientation as input (with or without auxiliary input features) provide the best predictions, require little preprocessing, and predict spatial-property maps in a matter of seconds.","Convolutional neural network,Machine learning,Metal additive manufacturing,Spatial-property prediction",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"SOLIDIFICATION,DEFORMATION,ALLOYS",COMPUTATIONAL MATERIALS SCIENCE,,
58,Artificial Intelligence to Power the Future of Materials Science and Engineering,2,4,,"Sha Wuxin,Guo Yaqing,Yuan Qing,Tang Shun,Zhang Xinfang,Lu Songfeng,Guo Xin,Cao Yuan-Cheng,Cheng Shijie","Sha WX,Guo YQ,Yuan Q,Tang S,Zhang XF,Lu SF,Guo X,Cao YC,Cheng SJ",Cao YC,10.1002/aisy.201900143,Huazhong University of Science & Technology,"Artificial intelligence (AI) has received widespread attention over the last few decades due to its potential to increase automation and accelerate productivity. In recent years, a large number of training data, improved computing power, and advanced deep learning algorithms are conducive to the wide application of AI, including material research. The traditional trial-and-error method is inefficient and time-consuming to study materials. Therefore, AI, especially machine learning, can accelerate the process by learning rules from datasets and building models to predict. This is completely different from computational chemistry where a computer is only a calculator, using hard-coded formulas provided by human experts. Herein, the application of AI in material innovation is reviewed, including material design, performance prediction, and synthesis. The realization details of AI techniques and advantages over conventional methods are emphasized in these applications. Finally, the future development direction of AI is expounded from both algorithm and infrastructure aspects.","artificial intelligence,chemical syntheses,machine learning,materials science,properties predictions",Review,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Automation & Control Systems,Computer Science,Robotics",,,"DEEP,NEURAL-NETWORKS,MATERIALS,DISCOVERY,MACHINE,OPTIMIZATION,DESIGN,GO,POTENTIALS,PREDICTION,CATALYST,GAME",ADVANCED INTELLIGENT SYSTEMS,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/aisy.201900143,
59,Textile-Based Inductive Soft Strain Sensors for Fast Frequency Movement and Their Application in Wearable Devices Measuring Multiaxial Hip Joint Angles during Running,2,4,,"Tavassolian Mohammad,Cuthbert Tyler J.,Napier Christopher,Peng JingYang,Menon Carlo","Tavassolian M,Cuthbert TJ,Napier C,Peng JY,Menon C",Menon C,10.1002/aisy.201900165,Simon Fraser University,"Wearable multiaxes motion tracking with inductive sensors and machine learning is presented. The production, characterization, and use of a modular and size-adjustable inductive sensor for kinematic motion tracking are introduced. The sensor is highly stable and able to track high-frequency (>15Hz) and high strain rates (>450%s(-1)). Four sensors are used to fabricate a pair of motion capture shorts. A random forest machine learning algorithm is used to predict the sagittal, transverse, and frontal hip joint angle, using the raw signals from sport shorts during running with a cohort of 12 participants against a gold standard optical motion capture system to an accuracy as high as R-2=0.98 and root mean squared error of 2 degrees in all three planes. Herein, an alternative strain sensor is provided to those typically used (piezoresistive/capacitive) for soft wearable motion capture devices with distinct advantages that can find applications in smart wearable devices, robotics, or direct integration into textiles.","inductive sensors,kinematic tracking,smart sensors,soft sensors,wearable devices",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Automation & Control Systems,Computer Science,Robotics",,,"LUMBAR,SPINE,KINEMATICS,STEREOPHOTOGRAMMETRY,ELECTRONICS,VALIDATION,SYSTEMS,DESIGN,FORCES",ADVANCED INTELLIGENT SYSTEMS,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/aisy.201900165,
60,A Tutorial on Bayesian Inference to Identify Material Parameters in Solid Mechanics,27,2,361-385,"Rappel H.,Beex L. A. A.,Hale J. S.,Noels L.,Bordas S. P. A.","Rappel H,Beex LAA,Hale JS,Noels L,Bordas SPA",Bordas SPA,10.1007/s11831-018-09311-x,University of Luxembourg,"The aim of this contribution is to explain in a straightforward manner how Bayesian inference can be used to identify material parameters of material models for solids. Bayesian approaches have already been used for this purpose, but most of the literature is not necessarily easy to understand for those new to the field. The reason for this is that most literature focuses either on complex statistical and machine learning concepts and/or on relatively complex mechanical models. In order to introduce the approach as gently as possible, we only focus on stress-strain measurements coming from uniaxial tensile tests and we only treat elastic and elastoplastic material models. Furthermore, the stress-strain measurements are created artificially in order to allow a one-to-one comparison between the true parameter values and the identified parameter distributions.","ELASTIC-CONSTANTS,STRUCTURAL MODELS,IDENTIFICATION,SELECTION,UNCERTAINTY,CALIBRATION,PLATES",Review,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering,Mathematics",,8.169,"ELASTIC-CONSTANTS,STRUCTURAL,MODELS,IDENTIFICATION,SELECTION,UNCERTAINTY,CALIBRATION,PLATES",ARCHIVES OF COMPUTATIONAL METHODS IN ENGINEERING,https://orbi.uliege.be/bitstream/2268/230043/1/2019_ACME_BayesianTut.pdf,
61,Machine learning based stochastic dynamic analysis of functionally graded shells,237,,,"Vaishali,Mukhopadhyay T.,Karsh P. K.,Basu B.,Dey S.","Vaishali,Mukhopadhyay T,Karsh PK,Basu B,Dey S",Mukhopadhyay T,10.1016/j.compstruct.2020.111870,Indian Institute of Technology System (IIT System),"This paper presents stochastic dynamic characterization of functionally graded shells based on an efficient Support Vector Machine assisted finite element (FE) approach. Different shell geometries such as cylindrical, spherical, elliptical paraboloid and hyperbolic paraboloid are investigated for the stochastic dynamic analysis. Monte Carlo Simulation is carried out in conjunction with the machine learning based FE computational framework for obtaining the complete probabilistic description of the natural frequencies. Here the coupled machine learning based FE model is found to reduce the computational time and cost significantly without compromising the accuracy of results. In the stochastic approach, both individual and compound effect of depth-wise source-uncertainty in material properties of FGM shells are considered taking into account the influences of different critical parameters such as the power-law exponent, temperature, thickness and variation of shell geometries. A moment-independent sensitivity analysis is carried out to enumerate the relative significance of different random input parameters considering depth-wise variation and collectively. The presented numerical results clearly indicate that it is imperative to take into account the relative stochastic deviations (including their probabilistic characterization) of the global dynamic characteristics for different shell geometries to ensure adequate safety and serviceability of the system while having an economical structural design.","FGM shells,Free vibration,Support vector machine,Monte Carlo simulation,Depth-wise sensitivity analysis",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Mechanics,Materials Science",,5.536,"FREE-VIBRATION,ANALYSIS,SHEAR,DEFORMATION-THEORY,NATURAL,FREQUENCY,FINITE-ELEMENT,SYSTEM,RANDOMNESS,BUCKLING,ANALYSIS,SANDWICH,PLATES,UNCERTAINTY,STATISTICS,SIMULATION",COMPOSITE STRUCTURES,,
62,Statistical modeling and knowle dge-based segmentation of cerebral artery based on TOF-MRA and MR-T1,186,,,"Li Na,Zhou Shoujun,Wu Zonghan,Zhang Baochang,Zhao Gang","Li N,Zhou SJ,Wu ZH,Zhang BC,Zhao G",Zhou SJ,10.1016/j.cmpb.2019.105110,Chinese Academy of Sciences,"Background and objective: For cerebrovascular segmentation from time-of-flight (TOF) magnetic resonance angiography (MRA), the focused issues are segmentation accuracy, vascular network coverage ratio, and cerebral artery and vein (CA/CV) separation. Therefore, cerebral artery segmentation is a challenging work, while a complete solution is lacking so far.
Methods: The preprocessing of skull-stripping and Hessian-based feature extraction is first implemented to acquire an indirect prior knowledge of vascular distribution and shape. Then, a novel intensity- and shape-based Markov statistical modeling is proposed for complete cerebrovascular segmentation, where our low-level process employs a Gaussian mixture model to fit the intensity histogram of the skull-stripped TOF-MRA data, while our high-level process employs the vascular shape prior to construct the energy function. To regularize the individual data processes, Markov regularization parameter is automatically estimated by using a machine-learning algorithm. Further, cerebral artery and vein (CA/CV) separation is explored with a series of morphological logic operations, which are based on a direct priori knowledge on the relationship of arteriovenous topology and brain tissues in between TOF-MRA and MR-T1.
Results: We employed 109 sets of public datasets from MIDAS for qualitative and quantitative assessment. The Dice similarity coefficient, false negative rate (FNR), and false positive rate (FPR) of 0.933, 0.158, and 0.091% on average, as well as CA/CV separation results with the agreement, FNR, and FPR of 0.976, 0.041, and 0.022 on average. For clinical visual assessment, our methods can segment various sizes of the vessel in different contrast region, especially performs better on vessels of small size in low contrast region.
Conclusion: Our methods obtained satisfying results in visual and quantitative evaluation. The proposed method is capable of accurate cerebrovascular segmentation and efficient CA/CV separation. Further, it can stimulate valuable clinical applications on the computer-assisted cerebrovascular intervention according to the neurosurgeon's recommendation. (C) 2019 The Authors. Published by Elsevier B.V.","Cerebral artery-vein separation,Markov label field,Hessian-based characteristics,Morphology and logic operation",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"VESSEL,SEGMENTATION,LEVEL,SET,SEPARATION,VEINS,ANGIOGRAPHY,3D",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,https://doi.org/10.1016/j.cmpb.2019.105110,
63,Performance Analysis of Machine Learning Algorithms for Cervical Cancer Detection,15,2,1-21,"Singh Sanjay Kumar,Goyal Anjali","Singh SK,Goyal A",Singh SK,10.4018/IJHISI.2020040101,I. K. Gujral Punjab Technical University,"Cervical cancer is second most prevailing cancer in women all over the world and the Pap smear is one of the most popular techniques used to diagnosis cervical cancer at an early stage. Developing countries like India has to face the challenges in order to handle more cases day by day. In this article, various online and offline machine learning algorithms has been applied on benchmarked data sets to detect cervical cancer. This article also addresses the problem of segmentation with hybrid techniques and optimizes the number of features using extra tree classifiers. Accuracy, precision score, recall score, and Fl score are increasing in the proportion of data for training and attained up to 100% by some algorithms. Algorithm like logistic regression with Ll regularization has an accuracy of 100%, but it is too much costly in terms of CPU time in comparison to some of the algorithms which obtain 99% accuracy with less CPU time. The key finding in this article is the selection of the best machine learning algorithm with the highest accuracy. Cost effectiveness in terms of CPU time is also analysed.","Cervical Cancer Detection,Decision Tree,Gaussian Naive Bayes,Gradient Boosting,K-Nearest Neighbour,Logistic Regression,Machine Learning,Pap-Smear Classification,Perceptron,Random Forest",Article,"IGI GLOBAL, 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA",Medical Informatics,,,"CLASSIFICATION,SEGMENTATION,NETWORKS",INTERNATIONAL JOURNAL OF HEALTHCARE INFORMATION SYSTEMS AND INFORMATICS,https://www.igi-global.com/ViewTitle.aspx?TitleId=246044&isxn=9781522597964,
64,Retinal Vessel Segmentation Using an Entropy-Based Optimization Algorithm,15,2,61-79,"Kaur Sukhpreet,Mann Kulwinder Singh","Kaur S,Mann KS",Kaur S,10.4018/IJHISI.2020040105,I. K. Gujral Punjab Technical University,"This article presents an algorithm for the segmentation of retinal blood vessels for the detection of diabetic retinopathy eye diseases. This disease occurs in patients with untreated diabetes for a long time. Since this disease is related to the retina, it can eventually lead to vision impairment. The proposed algorithm is a supervised learning method of blood vessels segmentation in which the classification system is trained with the features that are extracted from the images. The proposed system is implemented on the images of DRIVE, STARE and CHASE_DB1 databases. The segmentation is done by forming clusters with the features of patterns. The features were extracted using independent component analysis and the classification is performed by support vector machines (SVM). The results of the parameters are grouped by accuracy, sensitivity, specificity, positive predictive value, false positive rate and are compared with particle swarm optimization (PSO), the firefly optimization algorithm (FA) and the lion optimization algorithm (LOA).","Diabetic Retinopathy,Feature Extraction,Optimization,Retinal Vessels",Article,"IGI GLOBAL, 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA",Medical Informatics,,,"COLOR,IMAGES,GRAY-LEVEL,GABOR,WAVELET",INTERNATIONAL JOURNAL OF HEALTHCARE INFORMATION SYSTEMS AND INFORMATICS,https://www.igi-global.com/ViewTitle.aspx?TitleId=246048&isxn=9781522597964,
65,Efficient goal attainment and engagement in a care manager system using unstructured notes,3,1,62-69,"Rosenthal Sara,Das Subhro,Hsueh Pei-Yun Sabrina,Barker Ken,Chen Ching-Hua","Rosenthal S,Das S,Hsueh PYS,Barker K,Chen CH",Rosenthal S,10.1093/jamiaopen/ooaa001,International Business Machines (IBM),"Objective: To improve efficient goal attainment of patients by analyzing the unstructured text in care manager (CM) notes (CMNs). Our task is to determine whether the goal assigned by the CM can be achieved in a timely manner.
Materials and Methods: Our data consists of CM structured and unstructured records from a private firm in Orlando, FL. The CM data is based on phone interactions between the CM and the patient. A portion of the data has been manually annotated to indicate engagement. We present 2 machine learning classifiers: an engagement model and a goal attainment model.
Results: We can successfully distinguish automatically between engagement and lack of engagement. Subsequently, incorporating engagement and features from textual information from the unstructured notes significantly improves goal attainment classification.
Discussion: Two key challenges in this task were the time-consuming annotation effort for engagement classification and the limited amount of data for the more difficult goal attainment class (specifically, for people who take a long time to achieve their goals). We successfully explore domain adaptation and transfer learning techniques to improve performance on the under-represented classes. We also explore the value of using features from unstructured notes to improve the model and interpretability.
Conclusions: Unstructured CMNs can be used to improve accuracy of our classification models for predicting patient self-management goal attainment. This work can be used to help identify patients who may require special attention from CMs to improve engagement in self-management.","evidence-based healthcare management,patient engagement,natural language processing",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Health Care Sciences & Services,Medical Informatics",,,"INTEGRATED,CARE,SELF-REGULATION,HEALTH",JAMIA OPEN,https://europepmc.org/articles/pmc7309242?pdf=render,
66,Sustainability assessment and modeling based on supervised machine learning techniques: The case for food consumption,251,,,"Abdella Galal M.,Kucukvar Murat,Onat Nuri Cihat,Al-Yafay Hussein M.,Bulak Muhammet Enis","Abdella GM,Kucukvar M,Onat NC,Al-Yafay HM,Bulak ME",Kucukvar M,10.1016/j.jclepro.2019.119661,Qatar University,"Sustainability of food consumption requires the understanding of multi-dimensional environmental, economic and social impacts using a holistic and integrated sustainability assessment and modeling framework. This article presents a novel method on the assessment and modeling of sustainability impacts of food consumption. First, sustainability impacts of food consumption categories are quantified using high sector resolution input-output tables of U.S. economy. Later, an integrated sustainability modeling framework based on two supervised machine-learning techniques such as k-means clustering and logistics regression is presented. The proposed framework involves five steps: (1) economic input-output life cycle sustainability assessment, (2) non-dimensional normalization, (3) sustainability performance evaluation, (4) centroid-based clustering analysis, and (5) sustainability impact modeling. The findings show that the supply chains of food production sectors are accounted for major environmental impacts with higher than 80% of portions for total carbon footprints. Animal slaughtering, rendering, and processing is found as the most dominant sector in most of the environmental impact categories. The logistic model results revealed an overall model accuracy equal to 91.67%. Furthermore, among all the environmental sustainability indicators, it has found that CO and SO2 are the most significant contributors. The results also show that 13.7% of the food and beverage sectors are clustered as high, in which the bread and bakery product manufacturing is the central sector. The large value of the variance (5.24) is attributed to the large total weighted impact value of the animal (except poultry) slaughtering, rendering, and processing cluster. (C) 2019 Elsevier Ltd. All rights reserved.","Input-output analysis,Sustainability indicators,Sustainability assessment and modeling,Food consumption",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Science & Technology - Other Topics,Engineering,Environmental Sciences & Ecology",,9.444,"MULTICRITERIA,DECISION-MAKING,LIFE-CYCLE,ASSESSMENT,PRINCIPAL,COMPONENT,ANALYSIS,DATA,ENVELOPMENT,ANALYSIS,CARBON,FOOTPRINT,ENVIRONMENTAL,SUSTAINABILITY,UNITED-STATES,ELECTRIC,VEHICLES,ECO-EFFICIENCY,SUPPLY,CHAINS",JOURNAL OF CLEANER PRODUCTION,,
67,Driving determinants and prospective prediction simulations on carbon emissions peak for China's heavy chemical industry,251,,,"Lu Can,Li Wei,Gao Shubin","Lu C,Li W,Gao SB",Li W,10.1016/j.jclepro.2019.119642,North China Electric Power University,"Unprecedented huge mitigation task should be associated with profound efforts in facilitating emission reduction process over the globe. As the largest CO2 emitting country, China has been strenuously promoting the mitigation resilient development pathways in conjunction with the 2030 carbon emission peak commitment from Nationally Determined Contribution document which submitted under the Paris Agreement. Based on the peaking objective, carbon emission in heavy chemical industry should be received most attentions in terms of its large proportion with respect to the emission sources from other sectors. Particle swarm optimization (PSO) algorithm optimized back propagation neural network (BP) model is employed to predict future carbon emission for heavy chemical industry with the timeframe of 2017-2035 on the basis of the previous data. The significant magnitude of each carbon emission driving force is acquired in terms of the absolute influence coefficient method. The results indicated that, carbon emission in heavy chemical industry and its corresponding sub-sectors could be achieved peak under the implementation of the predetermined mitigation scenarios. The proportion of carbon emission in energy processing industry, steel industry, and building material industry is accounted for a larger fraction over the cumulative carbon emission in heavy chemical industry during the simulation period upon 2035. (C) 2019 Elsevier Ltd. All rights reserved.","Heavy chemical industry,Carbon emission peak,Driving force,Particle swarm optimization,China",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Science & Technology - Other Topics,Engineering,Environmental Sciences & Ecology",,9.444,"BP,NEURAL-NETWORK,CO2,EMISSIONS,SCENARIO,ANALYSIS,DIOXIDE,EMISSION,TRADING,MARKET,STIRPAT,MODEL,ENERGY,POLICY,DECOMPOSITION,INTENSITY",JOURNAL OF CLEANER PRODUCTION,,
68,Power consumption estimation for mask image projection stereolithography additive manufacturing using machine learning based approach,251,,,"Yang Yiran,He Miao,Li Lin","Yang YR,He M,Li L",Li L,10.1016/j.jclepro.2019.119710,University of Illinois System,"Additive manufacturing (AM) or 3D printing has been implemented in a wide range of areas, owing to its superior capabilities of fabricating complex geometries with high design freedom compared to traditional manufacturing. In recent years, the potential environmental impacts that can be caused by AM processes and materials have attracted increasing attentions. Research efforts have been conducted to study and attempt to enhance the environmental performance of AM. In current literature on AM energy consumption, most studies focus on the production stage and investigate the relation between energy consumption and process parameters (i.e., layer thickness). In this work, multiple geometry characteristics (e.g., surface areas and shapes) at each printing layer are studied and linked with the power consumption of mask image projection stereolithography using machine learning based approach. The established models will be able to provide AM designers with a useful tool for estimating power consumption based on layer-wise geometry information in the design stage and promote the awareness of cleaner production in AM. In this work, effective features are selected and/or extracted from layer-wise geometry characteristics and used to train and test machine learning models. According to our results, the shallow neural network has the lowest averaged root-mean-square error (RMSE) of 0.75% considering both training and testing, and the stacked autoencoders (SAE) structure has the best testing performance with RMSE of 0.85%. (C) 2019 Elsevier Ltd. All rights reserved.","Additive manufacturing,Mask image projection stereolithography,Power consumption,Geometry characteristics,Machine learning",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Science & Technology - Other Topics,Engineering,Environmental Sciences & Ecology",,9.444,"ENERGY-CONSUMPTION,EFFICIENCY",JOURNAL OF CLEANER PRODUCTION,https://www.sciencedirect.com/science/article/am/pii/S0959652619345809,
69,Evolving Neural Conditional Random Fields for drilling report classification,187,,,"Ribeiro Luiz C. F.,Afonso Luis C. S.,Colombo Danilo,Guilherme Ivan R.,Papa Joao P.","Ribeiro LCF,Afonso LCS,Colombo D,Guilherme IR,Papa JP",Ribeiro LCF,10.1016/j.petrol.2019.106846,Universidade Estadual Paulista,"Oil and gas prospecting is an important economic activity, besides being expensive and quite complex, thus requiring close monitoring to avoid work accidents and mainly environmental damages. An essential source of information concerns the daily drilling reports that contain operations technical interpretations and additional information from rig sensors. However, only a few works have focused on mining textual information from such reports for providing intelligent-based decision-making mechanisms to aid safety and efficiency concerns in drilling operations. This work proposes a contextual-driven approach based on Recurrent Neural Networks to recognize events in drilling reports that can outperform other related techniques. We also introduce a novel approach based on evolutionary computing to combine partially trained models using cyclical learning rates. Experiments conducted on two unbalanced datasets provided by Petrobras (Petroleo Brasileiro S.A.) show that our model improved Macro-F1 scores over the baseline by more than 47%. Besides, the proposed ensembling technique further enhanced these values by another 3% in the best scenario. Such promising results can shed light over new research directions in the field.(1)","Drilling reports classification,Natural Language Processing,Conditional Random Fields",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Energy & Fuels,Engineering",,4.376,,JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING,,
70,Accelerated dynamic contrast enhanced MRI based on region of interest compressed sensing,67,,18-23,"Konar Amaresha Shridhar,Vajuvalli Nithin N.,Rao Rashmi,Jain Divya,Babu D. R. Ramesh,Geethanath Sairam","Konar AS,Vajuvalli NN,Rao R,Jain D,Babu DRR,Geethanath S",Geethanath S,10.1016/j.mri.2019.11.014,Columbia University,"Magnetic Resonance Imaging (MRI) provides excellent soft tissue contrast with one significant limitation of slow data acquisition. Dynamic Contrast Enhanced MRI (DCE-MRI) is one of the widely employed techniques to estimate tumor tissue physiological parameters using contrast agents. DCE-MRI data acquisition and reconstruction requires high spatiotemporal resolution, especially during the post-contrast phase. The region of Interest Compressed Sensing (ROICS) is based on Compressed Sensing (CS) framework and works on the hypothesis that limiting CS to an ROI can achieve superior CS performance. In this work, ROICS has been demonstrated on breast DCE-MRI data at chosen acceleration factors and the results are compared with conventional CS implementation. Normalized Root Mean Square Error (NRMSE) was calculated to compare ROICS with CS quantitatively. CS and ROICS reconstructed images were used to compare K-trans and v(e) values derived using standard Tofts Model (TM). This also validated the superior performance of ROICS over conventional CS. ROICS generated Concentration Time Curves (CTC's) at chosen acceleration factors follow similar trend as the ground truth data as compared to CS. Both qualitative and quantitative analyses show that ROICS outperforms CS particularly at acceleration factors of 5 x and above.","Compressed sensing,Accelerated MRI,Spatio-temporal resolution,Pharmacokinetic modeling,Breast cancer imaging",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"FIELD-OF-VIEW,TEMPORAL,RESOLUTION,TIME",MAGNETIC RESONANCE IMAGING,,
71,EEG-based biometric identification with convolutional neural network,79,15-16,10655-10675,"Chen J. X.,Mao Z. J.,Yao W. X.,Huang Y. F.","Chen JX,Mao ZJ,Yao WX,Huang YF",Chen JX,10.1007/s11042-019-7258-4,Shaanxi University of Science & Technology,"Although more interest arising in biometric identification with electroencephalogram (EEG) signals, there is still a lack of simple and robust models that can be applied in real applications. This work proposes a new convolutional neural network with global spatial and local temporal filter called (GSLT-CNN), which works directly with raw EEG data, not requiring the need for engineering features. We investigate the performance of the GSLT-CNN model on datasets of 157 subjects collected from 4 different experiments that measure endogenous brain states (driving fatigue and emotion) as well as time-locked artificially induced brain responses such as rapid serial visual response (RSVP). We evaluate the GSLT-CNN model against the comparable SVM, Bagging Tree and LDA models with effective feature selection method. The results show the GSLT-CNN model is highly efficient and robust in training more than 279 K epochs within less than 0.5 h and achieves 96% accuracy in identifying 157 subjects, which is 3% better than the best accuracy of SVM on selected PSD feature, 10% better than that of SVM on selected AR feature and 23% better than that of normal CV-CNN model on raw EEG feature. It demonstrates the potential of deep learning solutions for real-life EEG-based biometric identification. We also show that the cross-session identification accuracy from time-locked RSVP data (99%) is slightly higher than that from single-session non-time-locked driving fatigue data (97%) and much higher than that from epochs measuring random brain states (90%), which implies RSVP could be a more beneficial design to achieve high identification accuracy with EEG and our GSLT-CNN model is robust for cross-session identification in RSVP experiment.","Biometric identification,Electroencephalogram (EEG),Convolutional neural networks,Deconvolutional networks,Brain-computer interface",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"BRAIN,POTENTIALS,DYNAMICS",MULTIMEDIA TOOLS AND APPLICATIONS,,
72,Development of a low-cost e-nose to assess aroma profiles: An artificial intelligence application to assess beer quality,308,,,"Viejo Claudia Gonzalez,Fuentes Sigfredo,Godbole Amruta,Widdicombe Bryce,Unnithan Ranjith R.","Viejo CG,Fuentes S,Godbole A,Widdicombe B,Unnithan RR",Fuentes S,10.1016/j.snb.2020.127688,University of Melbourne,"The assessment of aromas in beer is critical to assess its quality since it could be used as an indicator of contamination or faults, which will directly influence consumers' acceptability. Traditional techniques to evaluate aromas are time-consuming, require special training, costly equipment, and trained personnel. Therefore, this study aimed to develop a portable, low-cost electronic nose (e-nose) coupled with machine learning modeling to predict aromas in beer. Nine different gas sensors were used i) ethanol, ii) methane, iii) carbon monoxide, iv) hydrogen, v) ammonia/alcohol/benzene, vi) hydrogen sulfide, vii) ammonia, viii) benzene/alcohol/ammonia and ix) carbon dioxide. Output data were assessed for significant differences using ANOVA and least significant differences as post hoc test (alpha = 0.05). Two artificial neural network (ANN) models were also developed to predict i) the peak area of 17 different volatile aromatic compounds (Model 1) obtained from gas chromatography-mass spectroscopy (GC-MS) and ii) the intensity of ten sensory descriptors acquired from a sensory session with 12 trained panelists. Results from the ANOVA showed that there were significant differences between the samples used, which showed that the e-nose was able to discriminate samples. The resulting ANN models were highly accurate with correlation coefficients of R = 0.97 (Model 1) and R = 0.93 (Model 2). The combined method using the developed e-nose and the ANN models could be used by the industry as a low-cost, rapid, reliable and effective technique for beer quality assessment within the production line. This may also be calibrated for its use in other foods and beverages.","Electronic nose,Beer quality,Machine learning,Aromatic compounds",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Chemistry,Electrochemistry,Instruments & Instrumentation",,6.743,"ELECTRONIC,NOSE,CLASSIFICATION,EXTRACTION,SENSORS",SENSORS AND ACTUATORS B-CHEMICAL,,
73,A Deep Learning framework for simulation and defect prediction applied in microelectronics,100,,,"Dimitriou Nikolaos,Leontaris Lampros,Vafeiadis Thanasis,Ioannidis Dimosthenis,Wotherspoon Tracy,Tinker Gregory,Tzovaras Dimitrios","Dimitriou N,Leontaris L,Vafeiadis T,Ioannidis D,Wotherspoon T,Tinker G,Tzovaras D",Dimitriou N,10.1016/j.simpat.2019.102063,Centre for Research & Technology Hellas,"The prediction of upcoming events in industrial processes has been a long-standing research goal since it enables optimization of manufacturing parameters, planning of equipment maintenance and more importantly prediction and eventually prevention of defects. While existing approaches have accomplished substantial progress, they are mostly limited to processing of one dimensional signals or require parameter tuning to model environmental parameters. In this paper, we propose an alternative approach based on deep neural networks that simulates changes in the 3D structure of a monitored object in a batch based on previous 3D measurements. In particular, we propose an architecture based on 3D Convolutional Neural Networks (3DCNN) in order to model the geometric variations in manufacturing parameters and predict upcoming events related to sub-optimal performance. We validate our framework on a microelectronics use-case using the recently published ""PCB scans"" dataset where we simulate changes on the shape and volume of glue deposited on an Liquid Crystal Polymer (LCP) substrate before the attachment of integrated circuits (IC). Experimental evaluation examines the impact of different choices in the cost function during training and shows that the proposed method can be efficiently used for defect prediction.","Deep learning,Defect prediction,Industrial simulation,Integrated circuit",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,3.162,"STATE,DIAGNOSIS,PATTERNS,MODEL",SIMULATION MODELLING PRACTICE AND THEORY,http://arxiv.org/pdf/2002.10986,
74,Si microring resonator crossbar arrays for deep learning accelerator,59,,,"Ohno Shuhei,Toprasertpong Kasidit,Takagi Shinichi,Takenaka Mitsuru","Ohno S,Toprasertpong K,Takagi S,Takenaka M",Ohno S,10.35848/1347-4065/ab6d82,University of Tokyo,"We propose Si microring resonator (MRR) crossbar arrays as a programmable nanophotonoic processor (PNP) for a deep learning accelerator. The proposed MRR crossbar array can perform multiply-accumulate (MAC) operation in an optical domain. We numerically reveal that an optical neural network (ONN) based on the proposed MRR crossbar arrays can be used for the pattern recognition task with a similar performance to that of an ONN based on cascaded Mach-Zehnder interferometers. We predict that the power consumption can be reduced by approximately tenfold. The small area of the MRR also contributes to the reduction in its chip size by a factor of 36. The fabricated test devices consisting of Si MRRs with phase shifters exhibited no significant crosstalk between neighboring MRRs and showed the feasibility of MAC operation, Photonic integrated circuit using the proposed MRR crossbar arrays is promising for large-scale and low-power PNP for deep learning. (C) 2020 The Japan Society of Applied Physics","NEURAL-NETWORKS,SILICON,COUPLERS,DESIGN",Article; Proceedings Paper,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,1.362,"NEURAL-NETWORKS,SILICON,COUPLERS,DESIGN",JAPANESE JOURNAL OF APPLIED PHYSICS,,
75,Prediction of composite microstructure stress-strain curves using convolutional neural networks,189,,,"Yang Charles,Kim Youngsoo,Ryu Seunghwa,Gu Grace X.","Yang C,Kim Y,Ryu S,Gu GX",Gu GX,10.1016/j.matdes.2020.108509,University of California System,"Stress-strain curves are an important representation of a material's mechanical properties, from which important properties such as elastic modulus, strength, and toughness, are defined. However, generating stress-strain curves from numerical methods such as finite element method (FEM) is computationally intensive, especially when considering the entire failure path for a material. As a result, it is difficult to perform high throughput computational design of materials with large design spaces, especially when considering mechanical responses beyond the elastic limit. In this work, a combination of principal component analysis (PCA) and convolutional neural networks (CNN) are used to predict the entire stress-strain behavior of binary composites evaluated over the entire failure path, motivated by the significantly faster inference speed of empirical models. We show that PCA transforms the stress-strain curves into an effective latent space by visualizing the eigenbasis of PCA. Despite having a dataset of only 10(-27) % of possible microstructure configurations, the mean absolute error of the prediction is <10% of the range of values in the dataset, when measuring model performance based on derived material descriptors, such as modulus, strength, and toughness. Our study demonstrates the potential to use machine learning to accelerate material design, characterization, and optimization. (C) 2020 The Authors. Published by Elsevier Ltd.","Machine learning,Convolutional neural networks,Mechanical properties,Microstructure,Computational mechanics",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Materials Science,,7.097,"PHASE-FIELD,MODELS,ABAQUS,IMPLEMENTATION,STAGGERED,COMPOSITES,FRACTURE,PROPAGATION,NACRE",MATERIALS & DESIGN,https://doi.org/10.1016/j.matdes.2020.108509,
76,A Deep Transfer Learning Solution for Food Material Recognition Using Electronic Scales,16,4,2290-2300,"Xiao Guangyi,Wu Qi,Chen Hao,Cao Da,Guo Jingzhi,Gong Zhiguo","Xiao GY,Wu Q,Chen H,Cao D,Guo JZ,Gong ZG",Cao D,10.1109/TII.2019.2931148,Hunan University,"In this article, we present a novel solution to automating the procurement of food materials by using electronic scales, which can automatically identify the food materials along weighing them. Although the CNN model is regarded as one of the most effective solutions to image recognition, the traditional techniques cannot handle the mismatch problem between the lab training data and the real world data. To solve the problem, we propose to embed a partial-and-imbalanced domain adaptation technique (tree adaptation network) in the deep learning model, which can borrow knowledge from sibling classes, to overcome the imbalance problem, and transfer knowledge from the source domain to the target domain, to fight the mismatch problem between the lab training data and the real world data. Experiments show that the proposed approach outperforms state-of-the-art algorithms. Furthermore, the proposed techniques have already been used in practice.","Training data,Adaptation models,Informatics,Procurement,Consumer electronics,Task analysis,Fasteners,CNN network,imbalance,lab-to-reality transition,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Computer Science,Engineering",,9.768,,IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS,,
77,Machine Learning Based Predictive Model for AFP-Based Unidirectional Composite Laminates,16,4,2315-2324,"Wanigasekara Chathura,Oromiehie Ebrahim,Swain Akshya,Prusty B. Gangadhara,Nguang Sing Kiong","Wanigasekara C,Oromiehie E,Swain A,Prusty BG,Nguang SK",Wanigasekara C,10.1109/TII.2019.2932398,University of Auckland,"Manufacturing of composites using automated fiber placement (AFP) is a complex process that involves large number of processing conditions and variables. Improper selection of these parameters adversely affects the quality and integrity of the manufactured laminates. Thus, it is important to develop a predictive model that can assess how changes in critical process conditions alter the outputs of the manufacturing process. The goal of this investigation is to learn the complex behavior of composites by developing an intelligent model, which can subsequently be used for the prediction of various characteristics of the composites. However, manufacturing of AFP composites is both expensive and time-consuming and therefore the available data samples are less, from the prospective of machine learning, which leads to the small data learning problem. This article first solves this problem through virtual sample generation, and then a neural network based predictive model is developed to accurately learn the complex relationships between various processing parameters in AFP.","Predictive models,Informatics,Heating systems,Tools,Machine learning,Laminates,Automated fiber placement (AFP),virtual sample generation (VSG)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Computer Science,Engineering",,9.768,"VIRTUAL,SAMPLES,NEURAL-NETWORKS,INFORMATION,CLASSIFICATION,OPTIMIZATION",IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS,,
78,Industrial IoT for Intelligent Steelmaking With Converter Mouth Flame Spectrum Information Processed by Deep Learning,16,4,2640-2650,"Han Yang,Zhang Cai-Jun,Wang Lu,Zhang Yan-Chao","Han Y,Zhang CJ,Wang L,Zhang YC",Zhang CJ,10.1109/TII.2019.2948100,North China University of Science & Technology,"In this article, based on the fact that the converter mouth flame is the comprehensive external appearance of the physical and chemical reactions in the converter during the steelmaking process, the continuous spectrum information of the converter mouth flame was obtained by USB4000 spectrometer. In the framework of the Internet of Things, a bidirectional recursive multiscale convolution depth neural network algorithm can take into account the characteristics of frequency domain structure and time domain dynamic sequence. It is applied to the deep-learning of the converter mouth flame spectrum information. The dynamic prediction model of carbon content and temperature value in molten steel at the later stage of steelmaking is constructed. The static control system and dynamic prediction model of automatic steelmaking are intelligently fused to realize one-key steelmaking control. The results show that the average hit rate of carbon content, temperature, and carbon temperature at the end of steelmaking is 94.78 & x0025;, 98.41 & x0025;, and 93.43 & x0025;, which makes the end-point control of steelmaking more stable and the blowing rate less than 1 & x0025;.","Fires,Steel,Mouth,Carbon,Process control,Smelting,Neural networks,Bidirectional recursive,deep-learning,Internet of Things (IoT),multiscale convolution,steelmaking end-point",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Computer Science,Engineering",,9.768,"HEALTH-CARE,SYSTEM,INTERNET,THINGS,POWER",IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS,,
79,Teaching citizen scientists to categorize glitches using machine learning guided training,105,,,"Jackson Corey,Osterlund Carsten,Crowston Kevin,Harandi Mahboobeh,Allen Sarah,Bahaadini Sara,Coughlin Scotty,Kalogera Vicky,Katsaggelos Aggelos,Larson Shane","Jackson C,Osterlund C,Crowston K,Harandi M,Allen S,Bahaadini S,Coughlin S,Kalogera V,Katsaggelos A,Larson S",Jackson C,10.1016/j.chb.2019.106198,Syracuse University,"Existing literature points to scaffolded training as an effective yet resource-intensive approach to help newcomers learn and stay motivated. Experts need to select relevant learning materials and continuously assess learners' progress. Peer production communities such as Wikipedia and Open Source Software Development projects face the additional problem of turning volunteers into productive participants as soon as possible. To address these challenges, we designed and tested a training regime combining scaffolded instruction and machine learning to select learning materials and gradually introduces new materials to individuals as their competences improve. We evaluated the training regime on 386 participants that contribute to Gravity Spy, an online citizen science project where people are asked to categorize glitches to assist scientists in the search for gravitational waves. Volunteers were assigned to one of two conditions; (1) a machine learning guided training (MLGT) system that continuously assesses volunteers skill level and adjusts the learning materials or (2) an unscaffolded training program where all learning materials were administered at once. Our analysis revealed that volunteers in the MLGT condition were more accurate on the categorization task (an average accuracy of 90% vs. 54%), executed more tasks (an average of 228 vs. 121 tasks), and were retained for a longer period (an average of 2.5 vs. 2 sessions) than volunteers in the unscaffolded training. The results suggest that MLGT is an effective pedagogical approach for training volunteers in categorization tasks and increases volunteers' motivation.","Citizen science,Experiment,Training,Online communities,Zooniverse,User studies,Scaffolding,Learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Psychology,,8.302,"TASK,SELECTION,SCIENCE,COMMUNITIES,MOTIVATION,KNOWLEDGE,SIMILARITY,FRAMEWORK",COMPUTERS IN HUMAN BEHAVIOR,https://doi.org/10.1016/j.chb.2019.106198,
80,,,,,,,,,,,,,,,,,,,,
81,A multilevel features selection framework for skin lesion classification,10,1,,"Akram Tallha,Lodhi Hafiz M. Junaid,Naqvi Syed Rameez,Naeem Sidra,Alhaisoni Majed,Ali Muhammad,Haider Sajjad Ali,Qadri Nadia N.","Akram T,Lodhi HMJ,Naqvi SR,Naeem S,Alhaisoni M,Ali M,Haider SA,Qadri NN",Naqvi SR,10.1186/s13673-020-00216-y,COMSATS University Islamabad (CUI),"Melanoma is considered to be one of the deadliest skin cancer types, whose occurring frequency elevated in the last few years; its earlier diagnosis, however, significantly increases the chances of patients' survival. In the quest for the same, a few computer based methods, capable of diagnosing the skin lesion at initial stages, have been recently proposed. Despite some success, however, margin exists, due to which the machine learning community still considers this an outstanding research challenge. In this work, we come up with a novel framework for skin lesion classification, which integrates deep features information to generate most discriminant feature vector, with an advantage of preserving the original feature space. We utilize recent deep models for feature extraction, and by taking advantage of transfer learning. Initially, the dermoscopic images are segmented, and the lesion region is extracted, which is later subjected to retrain the selected deep models to generate fused feature vectors. In the second phase, a framework for most discriminant feature selection and dimensionality reduction is proposed, entropy-controlled neighborhood component analysis (ECNCA). This hierarchical framework optimizes fused features by selecting the principle components and extricating the redundant and irrelevant data. The effectiveness of our design is validated on four benchmark dermoscopic datasets; PH2, ISIC MSK, ISIC UDA, and ISBI-2017. To authenticate the proposed method, a fair comparison with the existing techniques is also provided. The simulation results clearly show that the proposed design is accurate enough to categorize the skin lesion with 98.8%, 99.2% and 97.1% and 95.9% accuracy with the selected classifiers on all four datasets, and by utilizing less than 3% features.","Skin lesion,Convolutional neural network,Dermoscopy,Deep learning,Feature selection,Transfer learning",Article,"KOREA INFORMATION PROCESSING SOC, 1002HO YONGSUNGBIZTEL 314-1 2GA HANKANGRO YONGSAN-GU, SEOUL, 140-750, SOUTH KOREA",Computer Science,,4.082,"IMAGE,SEGMENTATION,NEURAL-NETWORK,DERMOSCOPY,MELANOMAS,STEP",HUMAN-CENTRIC COMPUTING AND INFORMATION SCIENCES,https://hcis-journal.springeropen.com/track/pdf/10.1186/s13673-020-00216-y,
82,Backpropagation neural networks modelling of photocatalytic degradation of organic pollutants using TiO2-based photocatalysts,95,10,2739-2749,"Ayodele Bamidele Victor,Alsaffar May Ali,Mustapa Siti Indati,Vo Dai-Viet N.","Ayodele BV,Alsaffar MA,Mustapa SI,Vo DVN",Ayodele BV,10.1002/jctb.6407,Universiti Tenaga Nasional,"BACKGROUND The advanced oxidation process using photocatalysts has been proven to be an efficient technique used for the degradation of organic pollutants in wastewater. However, there exists a nonlinear relationship between the process parameters of the photodegradation reaction, which needs to be well understood for the design of an efficient photoreactor. This study employed a backpropagation artificial neural network (BPANN) for the modelling of photocatalytic degradation of indole, anthraquinone dye and methyl blue using undoped and Ag+-doped TiO2 catalysts.
RESULTS A Levenberg-Marquardt algorithm was employed to train the BPANN by varying the hidden neurons to obtained an optimized architecture. Optimized architectures with 3-14-1, 4-12-1 and 3-16-1 consist of the input layers, hidden layer and the output layer, were obtained using the datasets from photodegradation of indole, anthraquinone dye and methyl blue, respectively. The optimized BPANN accurately predicts the indole, anthraquinone dye and methyl blue degradation as a function of colour removal from the wastewater. High coefficients of determination (R-2) of 0.999, 0.961 and 0.993 were obtained for the prediction of the photodegradation of indole, anthraquinone dye and methyl blue, respectively, with over 95% confidence level. The study revealed that dye concentration, catalyst dosage and reaction time have the highest level of importance for the photodegradation of indole, anthraquinone dye and methyl blue, respectively.
CONCLUSION This study has demonstrated the robustness of BPANN for predictive modelling of photodegradation of organic pollutants such as indole, anthraquinone dye and methyl blue. (c) 2020 Society of Chemical Industry","backpropagation,artificial neural network,titanium oxide,photocatalysts,degradation,organic pollutants",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Biotechnology & Applied Microbiology,Chemistry,Engineering",,3.137,"RESPONSE-SURFACE,METHODOLOGY,ADVANCED,OXIDATION,PROCESSES,EXPERIMENTAL-DESIGN,OPTIMIZATION,WATER,REMOVAL,INDOLE,SYNGAS,TIO2,RSM",JOURNAL OF CHEMICAL TECHNOLOGY AND BIOTECHNOLOGY,,
83,Few-shot learning with deformable convolution for multiscale lesion detection in mammography,47,7,2970-2985,"Li Ce,Zhang Dong,Tian Zhiqiang,Du Shaoyi,Qu Yanyun","Li C,Zhang D,Tian ZQ,Du SY,Qu YY",Li C,10.1002/mp.14129,Lanzhou University of Technology,"Purpose Image-based breast lesion detection is a powerful clinical diagnosis technology. In recent years, deep learning architectures have achieved considerable success in medical image analysis however, they always require large-scale samples. In mammography images, breast lesions are inconspicuous, multiscale, and have blurred edges. Moreover, few well-labeled images exist. Because of these factors, the detection accuracy of conventional deep learning methods is low. Therefore, we attempted to improve the accuracy of mammary lesion detection by introducing transfer learning (TL) into a deep learning framework for the few-shot learning task and thus provide a method that will further assist physicians in detecting breast lesions.
Methods In this paper, we propose a method called ""few-shot learning with deformable convolution for multiscale lesion detection in mammography,"" named FDMNet. Deformable convolution is introduced for enhancing the network's ability to detect lesions, and the sensitivity of the multiscale feature space is reinforced by using a feature pyramid method. Furthermore, by introducing location information in the predictor, the sensitivity of the model to lesion location is also enhanced. The proposed method, through the TL technique that is applied mines the potentially common knowledge of features in the source domain and transfers it into the target domain to improve the accuracy of breast lesion detection in the few-shot learning task.
Results On the publicly available datasets for screening mammography CBIS-DDSM and Mini-MIAS, the proposed method performs better than five widely used detection methods. On the CBIS-DDSM dataset, its comprehensive scores, sensitivity, precision, and the mean dice similarity coefficient are 0.911, 0.949, 0.873, and 0.913, respectively, and on the Mini-MIAS dataset, these values are 0.931, 0.966, 0.882, and 0.941, respectively.
Conclusions To achieve the few-shot learning required for medical image analysis, the proposed method uses TL to execute feature knowledge transformation and includes deformable convolution to build a feature pyramid structure, which enhances the learning performance of the network for lesions. The results of comparative numerical experiments show that the proposed method outperforms some state-of-the-art methods.","attention factor,deformable convolution,few-shot learning,lesion detection,multiscale feature",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,NEURAL-NETWORKS,MEDICAL PHYSICS,,
84,Convolutional Neural Network for Seizure Detection of Nocturnal Frontal Lobe Epilepsy,2020,,,"Pisano Fabio,Sias Giuliana,Fanni Alessandra,Cannas Barbara,Dourado Antonio,Pisano Barbara,Teixeira Cesar A.","Pisano F,Sias G,Fanni A,Cannas B,Dourado A,Pisano B,Teixeira CA",Pisano F,10.1155/2020/4825767,University of Cagliari,"The Nocturnal Frontal Lobe Epilepsy (NFLE) is a form of epilepsy in which seizures occur predominantly during sleep. In other forms of epilepsy, the commonly used clinical approach mainly involves manual inspection of encephalography (EEG) signals, a laborious and time-consuming process which often requires the contribution of more than one experienced neurologist. In the last decades, numerous approaches to automate this detection have been proposed and, more recently, machine learning has shown very promising performance. In this paper, an original Convolutional Neural Network (CNN) architecture is proposed to develop patient-specific seizure detection models for three patients affected by NFLE. The performances, in terms of accuracy, sensitivity, and specificity, exceed by several percentage points those in the most recent literature. The capability of the patient-specific models has been also tested to compare the obtained seizure onset times with those provided by the neurologists, with encouraging results. Moreover, the same CNN architecture has been used to develop a cross-patient seizure detection system, resorting to the transfer-learning paradigm. Starting from a patient-specific model, few data from a new patient are enough to customize his model. This contribution aims to alleviate the task of neurologists, who may have a robust indication to corroborate their clinical conclusions.","EEG,ACCELEROMETRY,MODEL",Article,"WILEY-HINDAWI, ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND","Mathematics,Science & Technology - Other Topics",,2.8,"EEG,ACCELEROMETRY,MODEL",COMPLEXITY,https://www.openaccessrepository.it/record/27995/files/fulltext.pdf,
85,A frequency-domain machine learning method for dual-calibrated fMRI mapping of oxygen extraction fraction (OEF) and cerebral metabolic rate of oxygen consumption (CMRO2).,3,,,",,,,,,","Germuska Michael,Chandler Hannah,Okell Thomas,Fasano Fabrizio,Tomassini Valentina,Murphy Kevin,Wise Richard",,10.3389/frai.2020.00012,,,BOLD; CMRO2; OEF; artificial neural networks; calibrated-fMRI; machine learning; magnetic resonance imaging; metabolism; oxygen extraction fraction,Journal Article,,,,,,,,
86,Trends in 3D Printing Processes for Biomedical Field: Opportunities and Challenges,28,5,1345-1367,"Ghilan Alina,Chiriac Aurica P.,Nita Loredana E.,Rusu Alina G.,Neamtu Iordana,Chiriac Vlad Mihai","Ghilan A,Chiriac AP,Nita LE,Rusu AG,Neamtu I,Chiriac VM",Chiriac AP,10.1007/s10924-020-01722-x,Romanian Academy of Sciences,"Additive manufacturing (AM) is considered the latest technology that creates breakthrough innovations and addresses complex medical problems. This is clearly demonstrated by the promising results obtained in regenerative medicine, diagnosis, implants, artificial tissues and organs. This paper provides a basic understanding of the fundamentals of 3D/4D printing along with bioprinting processes. We are briefly discussing about the main printing systems including stereolithography, inkjet 3D printing, extrusion, laser-assisted printing, selective laser melting and Poly-Jet printing. The basic requirements for the selection of successful inks based on polymers, polymer blends, and composites are described. Furthermore, the on-going transition from 3D to 4D printing is highlighted with emphasis on the newest applications in the medical area. Also, a glimpse into the future possibilities and benefits provided by machine learning in the additive manufacturing field is emphasized. Machine learning can improve printing efficiency by using generative design and testing in the pre-fabrication stage. Finally, important limitations and prospects are identified. Within the next few years, AM is set to become an important component in patient-specific medical technologies.","Additive manufacturing,Medicine,Machine learning,Biomaterials,Bioprinting,Polymer,Bioinks",Review,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Engineering,Polymer Science",,3.536,"POLY%28LACTIC,ACID%29,SCAFFOLDS,DIRECT-WRITE,FABRICATION,HYALURONIC-ACID,REGENERATIVE,MEDICINE,MECHANICAL-PROPERTIES,COMPOSITE,SCAFFOLDS,MATERIALS,DISCOVERY,BONE,REGENERATION,CELL,RESPONSES,TISSUE",JOURNAL OF POLYMERS AND THE ENVIRONMENT,https://link.springer.com/content/pdf/10.1007/s10924-020-01722-x.pdf,
87,Inverting shock-wave temperatures via artificial neural networks,127,12,,"He Zhiyu,Guo Erfu,Huang Xiuguang,Mo Chongjie,Kang Wei,Zhang Fan,Wang Chen,Zhang Hao,Chu Xinkun,Jia Guo","He ZY,Guo EF,Huang XG,Mo CJ,Kang W,Zhang F,Wang C,Zhang H,Chu XK,Jia G",Guo EF,10.1063/1.5139992,Chinese Academy of Engineering Physics,"Temperature is one of the most important parameters for characterizing the thermodynamic state of matter in extreme conditions. However, there is as of yet no universal and accurate way to measure the temperature associated with a shock wave propagating in an opaque material, let alone an inversion method for determining how this temperature evolves. Based on the current strong generalization and learning abilities of artificial neural networks, this paper proposes using an artificial neural network to determine (i) how the shock-wave temperature in a material evolves and (ii) the surface temperature of the interface between the material and vacuum when a shock wave propagates through the material. Data generated using a one-dimensional numerical hydrodynamic simulation are used to train the artificial neural network by applying backpropagation and optimization to many datasets. Once the artificial neural network is trained sufficiently, it becomes an excellent approximator that can estimate the shock-wave temperature from a given streaked-optical-pyrometer image and other known information from the experiment. The paper ends with various possible extensions to the present research. Published under license by AIP Publishing.",DRIVEN,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,DRIVEN,JOURNAL OF APPLIED PHYSICS,,
88,Extraction of mechanical properties of materials through deep learning from instrumented indentation,117,13,7052-7062,"Lu Lu,Dao Ming,Kumar Punit,Ramamurty Upadrasta,Karniadakis George Em,Suresh Subra","Lu L,Dao M,Kumar P,Ramamurty U,Karniadakis GE,Suresh S",Karniadakis GE,10.1073/pnas.1922210117,Brown University,"Instrumented indentation has been developed and widely utilized as one of the most versatile and practical means of extracting mechanical properties of materials. This method is particularly desirable for those applications where it is difficult to experimentally determine the mechanical properties using stress-strain data obtained from coupon specimens. Such applications include material processing and manufacturing of small and large engineering components and structures involving the following: three-dimensional (3D) printing, thin-film and multilayered structures, and integrated manufacturing of materials for coupled mechanical and functional properties. Here, we utilize the latest developments in neural networks, including a multifidelity approach whereby deep-learning algorithms are trained to extract elasto-plastic properties of metals and alloys from instrumented indentation results using multiple datasets for desired levels of improved accuracy. We have established algorithms for solving inverse problems by recourse to single, dual, and multiple indentation and demonstrate that these algorithms significantly outperform traditional brute force computations and function-fitting methods. Moreover, we present several multifidelity approaches specifically for solving the inverse indentation problem which 1) significantly reduce the number of high-fidelity datasets required to achieve a given level of accuracy, 2) utilize known physical and scaling laws to improve training efficiency and accuracy, and 3) integrate simulation and experimental data for training disparate datasets to learn and minimize systematic errors. The predictive capabilities and advantages of these multifidelity methods have been assessed by direct comparisons with experimental results for indentation for different commercial alloys, including two wrought aluminum alloys and several 3D printed titanium alloys.","3D printed materials,stress-strain behavior,multifidelity modeling,transfer learning,machine learning",Article,"NATL ACAD SCIENCES, 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA",Science & Technology - Other Topics,,12.291,"SPHERICAL,INDENTATION,PLASTIC,PROPERTIES,ELASTIC-MODULUS,NEURAL-NETWORKS,ELECTRICAL,RESPONSE,GRADED,MATERIALS,SHARP,INDENTERS,POISSONS,RATIO,PART,I,NANOINDENTATION",PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA,https://www.pnas.org/content/pnas/117/13/7052.full.pdf,
89,Classification of Lung Nodules Based on Deep Residual Networks and Migration Learning,2020,,,"Wu Panpan,Sun Xuanchao,Zhao Ziping,Wang Haishuai,Pan Shirui,Schuller Bjoern","Wu PP,Sun XC,Zhao ZP,Wang HS,Pan SR,Schuller B",Zhao ZP; Wang HS,10.1155/2020/8975078,Tianjin Normal University,"The classification process of lung nodule detection in a traditional computer-aided detection (CAD) system is complex, and the classification result is heavily dependent on the performance of each step in lung nodule detection, causing low classification accuracy and high false positive rate. In order to alleviate these issues, a lung nodule classification method based on a deep residual network is proposed. Abandoning traditional image processing methods and taking the 50-layer ResNet network structure as the initial model, the deep residual network is constructed by combining residual learning and migration learning. The proposed approach is verified by conducting experiments on the lung computed tomography (CT) images from the publicly available LIDC-IDRI database. An average accuracy of 98.23% and a false positive rate of 1.65% are obtained based on the ten-fold cross-validation method. Compared with the conventional support vector machine (SVM)-based CAD system, the accuracy of our method improved by 9.96% and the false positive rate decreased by 6.95%, while the accuracy improved by 1.75% and 2.42%, respectively, and the false positive rate decreased by 2.07% and 2.22%, respectively, in contrast to the VGG19 model and InceptionV3 convolutional neural networks. The experimental results demonstrate the effectiveness of our proposed method in lung nodule classification for CT images.",IMAGES,Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Mathematical & Computational Biology,Neurosciences & Neurology",,3.278,IMAGES,COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE,https://opus.bibliothek.uni-augsburg.de/opus4/files/76348/8975078.pdf,
90,Modelling effects of S3D visual discomfort in human emotional state using data mining techniques,79,27-28,19803-19829,"Cegar Dragana Dordevic,Barreda-Angeles Miguel,Kukolj Dragan,Le Callet Patrick","Cegar DD,Barreda-Angeles M,Kukolj D,Le Callet P",Cegar DD,10.1007/s11042-020-08844-3,"RT RK Inst Comp Based Syst, Novi Sad, Serbia.","In recent years, the rapid development of diverse media has been evident in disparate fields such as consumer electronics, automotive infotainment and healthcare software. There is a need for innovative methods to assess user perceived Quality of Experience (QoE), as a proxy for consumer satisfaction with such systems and services. Users emotional state plays a key role in QoE; thus, it is necessary to consider it in user experience evaluation and the design process of stereoscopic 3D video content. In the present article we introduce the use of a specially designed model based on a feedforward Multilayer Perception Artificial Neural Network as an appropriate Machine Learning technique for the estimation of human emotional state while viewing various categories of stereoscopic 3D video content. The goal is to design an emotional state estimator based on direct psychophysiological measurements. The considered psychophysiological signals include heart rate (HR) calculated from an echocardiogram (ECG), electro-dermal activity (EDA), and brain activity (BA) in EEG signals. Participants watched a series of 3D video contents varying in terms of visual quality, while the mentioned psychophysiological signals were recorded, and self-reported subjectively experienced emotions using a Self-Assessment Manikin (SAM) questionnaire. The obtained results show that it is possible to construct such a highly precise estimator of emotional states.","Quality of experience,Artificial neural network,Multilayer perception,Machine learning,Data mining,Heart rate,Electro-dermal activity,Electro-encephalogram,Self-assessment manikin,Emotional state,S3D video,Content recommendation,Visual discomfort",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,STRESS,MULTIMEDIA TOOLS AND APPLICATIONS,,
91,Accelerated topology optimization by means of deep learning,62,3,1185-1212,"Kallioras Nikos Ath,Kazakis Georgios,Lagaros Nikos D.","Kallioras NA,Kazakis G,Lagaros ND",Lagaros ND,10.1007/s00158-020-02545-z,National Technical University of Athens,"This study is focused on enhancing the computational efficiency of the solid isotropic material with penalization (SIMP) approach implemented for solving topology optimization problems. Solving such problems might become extremely time-consuming; in this direction, machine learning (ML) and specifically deep neural computing are integrated in order to accelerate the optimization procedure. The capability of ML-based computational models to extract multiple levels of representation of non-linear input data has been implemented successfully in various problems ranging from time series prediction to pattern recognition. The later one triggered the development of the methodology proposed in the current study that is based on deep belief networks (DBNs). More specifically, a DBN is calibrated on transforming the input data to a new higher-level representation. Input data contains the density fluctuation pattern of the finite element discretization provided by the initial steps of SIMP approach, and output data corresponds to the resulted density values distribution over the domain as obtained by SIMP. The representation capabilities and the computational advantages offered by the proposed DBN-based methodology coupled with the SIMP approach are investigated in several benchmark topology optimization test examples where it is observed more than one order of magnitude reduction on the iterations that were originally required by SIMP, while the advantages become more pronounced in case of large-scale problems.","Topology optimization,Deep learning,Deep belief networks,Restricted Boltzmann machines,Pattern recognition,SIMP",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Computer Science,Engineering,Mechanics",,4.715,"STRUCTURAL,OPTIMIZATION,FILTERS,DESIGN,CONTINUATION,ALGORITHM,POLYTOP,WRITTEN",STRUCTURAL AND MULTIDISCIPLINARY OPTIMIZATION,,
92,Memory devices and applications for in-memory computing,15,7,529-544,"Sebastian Abu,Le Gallo Manuel,Khaddam-Aljameh Riduan,Eleftheriou Evangelos","Sebastian A,Le Gallo M,Khaddam-Aljameh R,Eleftheriou E",Sebastian A,10.1038/s41565-020-0655-z,International Business Machines (IBM),"Traditional von Neumann computing systems involve separate processing and memory units. However, data movement is costly in terms of time and energy and this problem is aggravated by the recent explosive growth in highly data-centric applications related to artificial intelligence. This calls for a radical departure from the traditional systems and one such non-von Neumann computational approach is in-memory computing. Hereby certain computational tasks are performed in place in the memory itself by exploiting the physical attributes of the memory devices. Both charge-based and resistance-based memory devices are being explored for in-memory computing. In this Review, we provide a broad overview of the key computational primitives enabled by these memory devices as well as their applications spanning scientific computing, signal processing, optimization, machine learning, deep learning and stochastic computing.
This Review provides an overview of memory devices and the key computational primitives for in-memory computing, and examines the possibilities of applying this computing approach to a wide range of applications.","PHASE-CHANGE MATERIALS,DEEP NEURAL-NETWORKS,LOGIC,DESIGN,SPIN,ACCELERATOR,GENERATION,SWITCHES,SYNAPSE,SIGNAL",Review,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Science & Technology - Other Topics,Materials Science",,42.237,"PHASE-CHANGE,MATERIALS,DEEP,NEURAL-NETWORKS,LOGIC,DESIGN,SPIN,ACCELERATOR,GENERATION,SWITCHES,SYNAPSE,SIGNAL",NATURE NANOTECHNOLOGY,,
93,Ability of near-infrared spectroscopy and chemometrics to predict the age of mosquitoes reared under different conditions,13,1,,"Ong Oselyne T. C.,Kho Elise A.,Esperanca Pedro M.,Freebairn Chris);,Dowell Floyd E.,Devine Gregor J.,Churcher Thomas S.","Ong OTC,Kho EA,Esperanca PM,Freebairn C,Dowell FE,Devine GJ,Churcher TS",Ong OTC,10.1186/s13071-020-04031-3,QIMR Berghofer Medical Research Institute,"Background Practical, field-ready age-grading tools for mosquito vectors of disease are urgently needed because of the impact that daily survival has on vectorial capacity. Previous studies have shown that near-infrared spectroscopy (NIRS), in combination with chemometrics and predictive modeling, can forecast the age of laboratory-reared mosquitoes with moderate to high accuracy. It remains unclear whether the technique has utility for identifying shifts in the age structure of wild-caught mosquitoes. Here we investigate whether models derived from the laboratory strain of mosquitoes can be used to predict the age of mosquitoes grown from pupae collected in the field. Methods NIRS data from adult female Aedes albopictus mosquitoes reared in the laboratory (2, 5, 8, 12 and 15 days-old) were analysed against spectra from mosquitoes emerging from wild-caught pupae (1, 7 and 14 days-old). Different partial least squares (PLS) regression methods trained on spectra from laboratory mosquitoes were evaluated on their ability to predict the age of mosquitoes from more natural environments. Results Models trained on spectra from laboratory-reared material were able to predict the age of other laboratory-reared mosquitoes with moderate accuracy and successfully differentiated all day 2 and 15 mosquitoes. Models derived with laboratory mosquitoes could not differentiate between field-derived age groups, with age predictions relatively indistinguishable for day 1-14. Pre-processing of spectral data and improving the PLS regression framework to avoid overfitting can increase accuracy, but predictions of mosquitoes reared in different environments remained poor. Principal components analysis confirms substantial spectral variations between laboratory and field-derived mosquitoes despite both originating from the same island population. Conclusions Models trained on laboratory mosquitoes were able to predict ages of laboratory mosquitoes with good sensitivity and specificity though they were unable to predict age of field-derived mosquitoes. This study suggests that laboratory-reared mosquitoes do not capture enough environmental variation to accurately predict the age of the same species reared under different conditions. Further research is needed to explore alternative pre-processing methods and machine learning techniques, and to understand factors that affect absorbance in mosquitoes before field application using NIRS.","Asian tiger mosquito,Age,Spectroscopy,Chemometrics,Near-infrared",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Parasitology,Tropical Medicine",,,"ANOPHELES-GAMBIAE,AEDES-ALBOPICTUS,CULICIDAE,DIPTERA,SPECTRA,AEGYPTI",PARASITES & VECTORS,https://www.researchsquare.com/article/rs-8610/v4.pdf?c=1585627228000,
94,Immunohistochemical index prediction of breast tumor based on multi-dimension features in contrast-enhanced ultrasound,58,6,1285-1295,"Chen Fang,Liu Jia,Wan Peng,Liao Hongen,Kong Wentao","Chen F,Liu J,Wan P,Liao HG,Kong WT",Chen F,10.1007/s11517-020-02164-2,Nanjing University of Aeronautics & Astronautics,"Breast cancer is the leading killer of Chinese women. Immunohistochemistry index has great significance in the treatment strategy selection and prognosis analysis for breast cancer patients. Currently, histopathological examination of the tumor tissue through surgical biopsy is the gold standard to determine immunohistochemistry index. However, this examination is invasive and commonly causes discomfort in patients. There has been a lack of noninvasive method capable of predicting immunohistochemistry index for breast cancer patients. This paper proposes a machine learning method to predict the immunohistochemical index of breast cancer patients by using noninvasive contrast-enhanced ultrasound. A total of 119 breast cancer patients were included in this retrospective study. Each patient implemented the pathological examination of immunohistochemical expression and underwent contrast-enhanced ultrasound imaging of breast tumor. The multi-dimension features including 266 three-dimension features and 837 two-dimension dynamic features were extracted from the contrast-enhanced ultrasound sequences. Using the machine learning prediction method, 21 selected multi-dimension features were integrated to generate a model for predicting the immunohistochemistry index noninvasively. The immunohistochemical index of human epidermal growth factor receptor-2 (HER2) was predicted based on multi-dimension features in contrast-enhanced ultrasound sequence with the sensitivity of 71%, and the specificity of 79% in the testing cohort. Therefore, the noninvasive contrast-enhanced ultrasound can be used to predict the immunohistochemical index. To our best knowledge, no studies have been reported about predicting immunohistochemical index by using contrast-enhanced ultrasound sequences for breast cancer patients. Our proposed method is noninvasive and can predict immunohistochemical index by using contrast-enhanced ultrasound in several minutes, instead of relying totally on the invasive and biopsy-based histopathological examination.","Breast cancer,Immunohistochemical index,Multi-dimension features,Machine learning,Contrast-enhanced ultrasound",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"BI-RADS,DIFFERENTIAL-DIAGNOSIS,ESTROGEN-RECEPTOR,CANCER,THERAPY,LESIONS,BENIGN,HER-2,KI-67,GENE",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
95,A novel muscle-computer interface for hand gesture recognition using depth vision,11,11,5569-5580,"Zhou Xuanyi,Qi Wen,Ovur Salih Ertug,Zhang Longbin,Hu Yingbai,Su Hang,Ferrigno Giancarlo,De Momi Elena","Zhou XY,Qi W,Ovur SE,Zhang LB,Hu YB,Su H,Ferrigno G,De Momi E",Su H,10.1007/s12652-020-01913-3,Polytechnic University of Milan,"Muscle computer Interface (muCI), one of the widespread human-computer interfaces, has been widely adopted for the identification of hand gestures by using the electrical activity of muscles. Although multi-modal theory and machine learning algorithms have made enormous progress in muCI over the last decades, the processing of the collecting and labeling large data sets creates a high workload and leads to time-consuming implementations. In this paper, a novel muCI was developed to integrate the advantages of EMG signals and depth vision, which could be used to automatically label the cluster of EMG data collected using depth vision. A three layers hierarchical k-medoids approach was designed to extract and label the clustering feature of ten hand gestures. A multi-class linear discriminant analysis algorithm was applied to build the hand gesture classifier. The results showed that the proposed algorithm had high accuracy and the muCI performed well, which could automatically label the hand gesture in all experiments. The proposed muCI can be utilized for hand gesture recognition without labeling the data in advance and has the potential for robot manipulation and virtual reality applications.","Depth vision,Hand gesture recognition,Muscle computer interface,Clustering,Classification",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Telecommunications",,6.163,"CLASSIFICATION,PROTOTYPE",JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING,,
96,Molecular generation targeting desired electronic properties via deep generative models,12,12,6744-6758,"Yuan Qi,Santana-Bonilla Alejandro,Zwijnenburg Martijn A.,Jelfs Kim E.","Yuan Q,Santana-Bonilla A,Zwijnenburg MA,Jelfs KE",Jelfs KE,10.1039/c9nr10687a,Imperial College London,"As we seek to discover new functional materials, we need ways to explore the vast chemical space of precursor building blocks, not only generating large numbers of possible building blocks to investigate, but trying to find non-obvious options, that we might not suggest by chemical experience alone. Artificial intelligence techniques provide a possible avenue to generate large numbers of organic building blocks for functional materials, and can even do so from very small initial libraries of known building blocks. Specifically, we demonstrate the application of deep recurrent neural networks for the exploration of the chemical space of building blocks for a test case of donor-acceptor oligomers with specific electronic properties. The recurrent neural network learned how to produce novel donor-acceptor oligomers by trading off between selected atomic substitutions, such as halogenation or methylation, and molecular features such as the oligomer's size. The electronic and structural properties of the generated oligomers can be tuned by sampling from different subsets of the training database, which enabled us to enrich the library of donor-acceptors towards desired properties. We generated approximately 1700 new donor-acceptor oligomers with a recurrent neural network tuned to target oligomers with a HOMO-LUMO gap <2 eV and a dipole moment <2 Debye, which could have potential application in organic photovoltaics.","DENSITY-FUNCTIONAL THERMOCHEMISTRY,CIRCULAR-DICHROISM SPECTRA,SOLAR-CELLS,BASIS-SETS,DESIGN,DISCOVERY,STATES,SPACE,FIELD",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,7.632,"DENSITY-FUNCTIONAL,THERMOCHEMISTRY,CIRCULAR-DICHROISM,SPECTRA,SOLAR-CELLS,BASIS-SETS,DESIGN,DISCOVERY,STATES,SPACE,FIELD",NANOSCALE,http://spiral.imperial.ac.uk/bitstream/10044/1/78237/2/RNN_paper_accepted.pdf,
97,Drug design by machine-trained elastic networks: predicting Ser/Thr-protein kinase inhibitors' activities,25,2,899-909,"Toussi Cyrus Ahmadi,Haddadnia Javad,Matta Cherif F.","Toussi CA,Haddadnia J,Matta CF",Matta CF,10.1007/s11030-020-10074-6,Dalhousie University,"An elastic network model (ENM) represents a molecule as a matrix of pairwise atomic interactions. Rich in coded information, ENMs are hereby proposed as a novel tool for the prediction of the activity of series of molecules, with widely different chemical structures, but a common biological activity. The new approach is developed and tested using a set of 183 inhibitors of serine/threonine-protein kinase enzyme (Plk3) which is an enzyme implicated in the regulation of cell cycle and tumorigenesis. The elastic network (EN) predictive model is found to exhibit high accuracy and speed compared to descriptor-based machine-trained modeling. EN modeling appears to be a highly promising new tool for the high demands of industrial applications such as drug and material design. Graphic abstract","Elastic network models,Quantitative structure-activity relationships (QSAR),Machine learning,Artificial intelligence,Normal modes,Serine,threonine-protein kinase inhibitors",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Biochemistry & Molecular Biology,Chemistry,Pharmacology & Pharmacy",,2.539,"LOCALIZATION-DELOCALIZATION,MATRICES,SUPPORT,VECTOR,MACHINES,NORMAL-MODES,ELECTRON,LOCALIZATION,BIOLOGICAL-ACTIVITIES,NEURAL-NETWORK,QSAR,CLASSIFICATION,SELECTION,DATABASE",MOLECULAR DIVERSITY,,
98,Operating a treatment planning system using a deep-reinforcement learning-based virtual treatment planner for prostate cancer intensity-modulated radiation therapy treatment planning,47,6,2329-2336,"Shen Chenyang,Nguyen Dan,Chen Liyuan,Gonzalez Yesenia,McBeth Rafe,Qin Nan,Jiang Steve B.,Jia Xun","Shen CY,Nguyen D,Chen LY,Gonzalez Y,McBeth R,Qin N,Jiang SVB,Jia X",Shen CY; Jia X,10.1002/mp.14114,University of Texas System,"Purpose In the treatment planning process of intensity-modulated radiation therapy (IMRT), a human planner operates the treatment planning system (TPS) to adjust treatment planning parameters, for example, dose volume histogram (DVH) constraints' locations and weights, to achieve a satisfactory plan for each patient. This process is usually time-consuming, and the plan quality depends on planer's experience and available planning time. In this study, we proposed to model the behaviors of human planners in treatment planning by a deep reinforcement learning (DRL)-based virtual treatment planner network (VTPN), such that it can operate the TPS in a human-like manner for treatment planning.
Methods and Materials Using prostate cancer IMRT as an example, we established the VTPN using a deep neural network developed. We considered an in-house optimization engine with a weighted quadratic objective function. Virtual treatment planner network was designed to observe an intermediate plan DVHs and decide the action to improve the plan by changing weights and threshold dose in the objective function. We trained the VTPN in an end-to-end DRL process in 10 patient cases. A plan score was used to measure plan quality. We demonstrated the feasibility and effectiveness of the trained VTPN in another 64 patient cases.
Results Virtual treatment planner network was trained to spontaneously learn how to adjust treatment planning parameters to generate high-quality treatment plans. In the 64 testing cases, with initialized parameters, quality score was 4.97 (+/- 2.02), with 9.0 being the highest possible score. Using VTPN to perform treatment planning improved quality score to 8.44 (+/- 0.48).
Conclusions To our knowledge, this was the first time that intelligent treatment planning behaviors of human planner in external beam IMRT are autonomously encoded in an artificial intelligence system. The trained VTPN is capable of behaving in a human-like way to produce high-quality plans.","auto-planning,deep reinforcement learning,intelligent virtual treatment planner,treatment planning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"PARAMETER,OPTIMIZATION,NEURAL-NETWORKS,IMRT,RADIOTHERAPY,WEIGHTS,GAME,GO",MEDICAL PHYSICS,https://aapm.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mp.14114,
99,Classification of pulmonary lesion based on multiparametric MRI: utility of radiomics and comparison of machine learning methods,30,8,4595-4605,"Wang Xinhui,Wan Qi,Chen Houjin,Li Yanfeng,Li Xinchun","Wang XH,Wan Q,Chen HJ,Li YF,Li XC",Chen HJ,10.1007/s00330-020-06768-y,Beijing Jiaotong University,"Objectives We develop and validate a radiomics model based on multiparametric magnetic resonance imaging (MRI) in the classification of the pulmonary lesion and identify optimal machine learning methods. Materials and methods This retrospective analysis included 201 patients (143 malignancies, 58 benign lesions). Radiomics features were extracted from multiparametric MRI, including T2-weighted imaging (T2WI), T1-weighted imaging (TIWI), and apparent diffusion coefficient (ADC) map. Three feature selection methods, including recursive feature elimination (RFE), t test, and least absolute shrinkage and selection operator (LASSO), and three classification methods, including linear discriminate analysis (LDA), support vector machine (SVM), and random forest (RF) were used to distinguish benign and malignant pulmonary lesions. Performance was compared by AUC, sensitivity, accuracy, precision, and specificity. Analysis of performance differences in three randomly drawn cross-validation sets verified the stability of the results. Results For most single MR sequences or combinations of multiple MR sequences, RFE feature selection method with SVM classifier had the best performance, followed by RFE with RF. The radiomics model based on multiple sequences showed a higher diagnostic accuracy than single sequence for every machine learning method. Using RFE with SVM, the joint model of T1WI, T2WI, and ADC showed the highest performance with AUC = 0.88 +/- 0.02 (sensitivity 83%; accuracy 82%; precision 91%; specificity 79%) in test set. Conclusion Quantitative radiomics features based on multiparametric MRI have good performance in differentiating lung malignancies and benign lesions. The machine learning method of RFE with SVM is superior to the combination of other feature selection and classifier methods.","Magnetic resonance imaging,Lung cancer,Radiomics,Machine learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,4.87,"LUNG-CANCER,QUANTITATIVE-ANALYSIS,PROSTATE-CANCER,FEATURES,IMAGES,DWI",EUROPEAN RADIOLOGY,,
100,Convolutional neural networks for pavement roughness assessment using calibration-free vehicle dynamics,35,11,1209-1229,"Jeong Jong-Hyun,Jo Hongki,Ditzler Gregory","Jeong JH,Jo H,Ditzler G",Jo H,10.1111/mice.12546,University of Arizona,"Road roughness is a measure of how uncomfortable a ride is, and provides an important indicator for the needs of roadway maintenance or repavement, which is closely tied to the state and federal budget prioritization. As such, accurate and timely monitoring of deteriorating road conditions and following maintenance are essential to improve the overall ride quality on the road. Various technologies, including vehicle-mounted laser profiling systems, have been developed and adopted for road roughness (e.g., IRI-International Roughness Index) measurement; however, their high cost limits their use. While recent advances in smartphone technologies allow us to use their embedded accelerometers for road roughness monitoring, the complicated process of necessary vehicle calibration hinders the widespread use of the technology in the actual practices. In this work, a deep learning IRI estimation method is proposed with the goal of using anonymous (i.e., calibration-free) vehicles and their responses measured by smartphones as road roughness sensors. A state-of-the-art deep learning algorithm (i.e., CNN-convolutional neural network) and multimetric vehicle dynamics data (i.e., accelerometer, gyroscope), possibly measured by drivers' smartphones, are employed for the purpose. Optimized CNN architecture and data configuration have been investigated to achieve the best performance. The efficacy of the proposed method has been numerically validated using real road IRI information (i.e., Speedway, Tucson, AZ), real driving speed profiles, and four different types of vehicle data with associated uncertainties.","DAMAGE DETECTION,CRACK DETECTION,CLASSIFICATION,IDENTIFICATION,RECOGNITION,RESPONSES,MACHINE,CNN",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Computer Science,Construction & Building Technology,Engineering,Transportation",,9.756,"DAMAGE,DETECTION,CRACK,DETECTION,CLASSIFICATION,IDENTIFICATION,RECOGNITION,RESPONSES,MACHINE,CNN",COMPUTER-AIDED CIVIL AND INFRASTRUCTURE ENGINEERING,,
