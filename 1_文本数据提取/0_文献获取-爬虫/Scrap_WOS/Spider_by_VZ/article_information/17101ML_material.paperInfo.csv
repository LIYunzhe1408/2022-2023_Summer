,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,A Multi-Scale Directional Line Detector for Retinal Vessel Segmentation,19,22,,"Khawaja Ahsan,Khan Tariq M.,Khan Mohammad A. U.,Nawaz Syed Junaid","Khawaja A,Khan TM,Khan MAU,Nawaz SJ",Khawaja A,10.3390/s19224949,COMSATS University Islamabad (CUI),"The assessment of transformations in the retinal vascular structure has a strong potential in indicating a wide range of underlying ocular pathologies. Correctly identifying the retinal vessel map is a crucial step in disease identification, severity progression assessment, and appropriate treatment. Marking the vessels manually by a human expert is a tedious and time-consuming task, thereby reinforcing the need for automated algorithms capable of quick segmentation of retinal features and any possible anomalies. Techniques based on unsupervised learning methods utilize vessel morphology to classify vessel pixels. This study proposes a directional multi-scale line detector technique for the segmentation of retinal vessels with the prime focus on the tiny vessels that are most difficult to segment out. Constructing a directional line-detector, and using it on images having only the features oriented along the detector's direction, significantly improves the detection accuracy of the algorithm. The finishing step involves a binarization operation, which is again directional in nature, helps in achieving further performance improvements in terms of key performance indicators. The proposed method is observed to obtain a sensitivity of 0.8043, 0.8011, and 0.7974 for the Digital Retinal Images for Vessel Extraction (DRIVE), STructured Analysis of the Retina (STARE), and Child Heart And health Study in England (CHASE_DB1) datasets, respectively. These results, along with other performance enhancements demonstrated by the conducted experimental evaluation, establish the validity and applicability of directional multi-scale line detectors as a competitive framework for retinal image segmentation.","directional filter bank,image segmentation,multi-scale line detector,vessel segmentation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"BLOOD-VESSELS,GRAY-LEVEL,IMAGES,EXTRACTION",SENSORS,https://www.mdpi.com/1424-8220/19/22/4949/pdf,
2,Optimised dispensing of predatory mites by multirotor UAVs in wind: A distribution pattern modelling approach for precision pest management,187,,226-238,"Teske April L.,Chen Gang,Nansen Christian,Kong Zhaodan","Teske AL,Chen G,Nansen C,Kong ZD",Kong ZD,10.1016/j.biosystemseng.2019.09.009,University of California System,"Multirotor unmanned aerial vehicles (UAVs), or drones, are increasingly being used to spray liquid pesticides to control emerging pest infestations in field crops. In recent years, UAVs have been used to release predatory mites and other natural enemies to optimise and promote sustainable pest management practices by relying less on conventional insecticides. Drone dispensed samples of predatory mites are typically mixed with a granular material, vermiculite, which serves as a filler. The low density of the vermiculite and weather conditions (mainly wind), influences the distribution pattern of predatory mites when delivered by a UAV-based system. The purpose of this paper is to present a data driven methodology to develop a mathematical model that can be used to optimise UAV-based autonomous dispensing of predatory mites. The model characterises the distribution of vermiculite as a function of wind speed and direction, and the UAVs altitude and forward speed. The model is constructed by first conducting outdoor experiments and then using machine-learning techniques on the collected data. The constructed model produced an average generalisation error of 12.8%, RMSE. Due to its parametric and predictive nature, the model is amenable for the future design of UAV flight controllers that can compensate for the targeting error caused by wind. The proposed modelling methodology could be useful not only for the dispensing of predatory mites, but also for other UAV dispensing applications, such as liquid or granular pesticide deliveries. (C) 2019 IAgrE. Published by Elsevier Ltd. All rights reserved.","Unmanned aerial vehicle,Precision pest management,Machine learning,Natural enemies,Precision agriculture,Predatory mites",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA",Agriculture,,4.508,"UNMANNED,AERIAL,VEHICLE",BIOSYSTEMS ENGINEERING,,
3,Patch-Based Adaptive Background Subtraction for Vascular Enhancement in X-Ray Cineangiograms,23,6,2563-2575,"Song Shuang,Yang Jian,Ai Danni,Du Chenbing,Huang Yong,Song Hong,Zhang Luosha,Han Yechen,Wang Yongtian,Frangi Alejandro F.","Song S,Yang J,Ai DN,Du CB,Huang Y,Song H,Zhang LS,Han YC,Wang YT,Frangi AF",Yang J; Ai DN; Wang YT,10.1109/JBHI.2019.2892072,Beijing Institute of Technology,"Objective: Automatic vascular enhancement in X-ray cineangiography is of crucial interest, for instance, for better visualizing and quantifying coronary arteries in diagnostic and interventional procedures. Methods: A novel patch-based adaptive background subtraction method (PABSM) is proposed automatically enhancing vessels in coronary X-ray cineangiography. First, pixels in the cineangiogram are described by the vesselness and Gabor features. Second, a classifier is utilized to separate the cineangiogram into the rough vascular and non-vascular region. Dilation is applied to the classified binary image to include more vascular region. Third, a patch-based background synthesis is utilized to fill the removed vascular region. Results: A database containing 320 cineangiograms of 175 patients was collected, and then an interventional cardiologist annotated all vascular structures. The performance of PABSM is compared with six state-of-the-art vascular enhancement methods regarding the precisionrecall curve and C-value. The area under the precisionrecall curve is $0.7133$ , and the C-value is $0.9659$ . Conclusion: PABSM can automatically enhance the coronary artery in the cineangiograms. It preserves the integrity of vascular topological structures, particularly in complex vascular regions, and removes noise caused by the non-uniform gray-level distribution in the cineangiogram. Significance: PABSM can avoid the motion artifacts and it eases the subsequent vascular segmentation, which is crucial for the diagnosis and interventional procedures of coronary artery diseases.","Arteries,Feature extraction,Training,Standards,Image edge detection,Eigenvalues and eigenfunctions,Gabor filters,Learning,adaptive background,enhancement,coronary cineangiography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"VESSEL,ENHANCEMENT,ROTATIONAL,ANGIOGRAPHY,LAYER,SEPARATION,SEGMENTATION,TREE,3D,RECONSTRUCTION,EXTRACTION,FILTERS",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://eprints.whiterose.ac.uk/141139/7/Patch-based_Adaptive_Background_Subtraction_for_Vascular_Enhancement_in_.._%20%28002%29.pdf,
4,Bayesian inference of metabolic kinetics from genome-scale multiomics data,15,11,,"St John Peter C.,Strutz Jonathan,Broadbelt Linda J.,Tyo Keith E. J.,Bomble Yannick J.","St John PC,Strutz J,Broadbelt LJ,Tyo KEJ,Bomble YJ",Bomble YJ,10.1371/journal.pcbi.1007424,United States Department of Energy (DOE),"Modern biological tools generate a wealth of data on metabolite and protein concentrations that can be used to help inform new strain designs. However, learning from these data to predict how a cell will respond to genetic changes, a key need for engineering, remains challenging. A promising technique for leveraging omics measurements in metabolic modeling involves the construction of kinetic descriptions of the enzymatic reactions that occur within a cell. Parameterizing these models from biological data can be computationally difficult, since methods must also quantify the uncertainty in model parameters resulting from the observed data. While the field of Bayesian inference offers a wide range of methods for efficiently estimating distributions in parameter uncertainty, such techniques are poorly suited to traditional kinetic models due to their complex rate laws and resulting nonlinear dynamics. In this paper, we employ linear-logarithmic kinetics to simplify the calculation of steady-state flux distributions and enable efficient sampling and inference methods. We demonstrate that detailed information on the posterior distribution of parameters can be obtained efficiently at a variety of problem scales, including nearly genome-scale kinetic models trained on multiomics datasets. These results allow modern Bayesian machine learning tools to be leveraged in understanding biological data and in developing new, efficient strain designs.
Author Summary Genetic engineering of microbes is a promising strategy to enable more efficient and environmentally friendly production routes for chemicals and materials traditionally produced from petroleum. While the tools to both edit microbial genomes and measure the resulting changes to cellular physiology are growing increasingly efficient, our ability to predict which genetic interventions will have the greatest likelihood of achieving the desired phenotype is still lacking. In particular, computational methods are needed that are able to efficiently ingest the increasing amount of data generated from large biological datasets to guide subsequent rounds of experiments. This study presents an efficient algorithm coupled to modern computational tools that permits a closer integration of modeling in the design, build, test, and learn cycle of genetic engineering.","FLUX CONTROL COEFFICIENTS,ESCHERICHIA-COLI,LINEAR RELATION,UNCERTAINTY,FRAMEWORK,MODELS,ELASTICITIES,PARAMETERS,REDESIGN",Article,"PUBLIC LIBRARY SCIENCE, 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA","Biochemistry & Molecular Biology,Mathematical & Computational Biology",,5.379,"FLUX,CONTROL,COEFFICIENTS,ESCHERICHIA-COLI,LINEAR,RELATION,UNCERTAINTY,FRAMEWORK,MODELS,ELASTICITIES,PARAMETERS,REDESIGN",PLOS COMPUTATIONAL BIOLOGY,https://europepmc.org/articles/pmc6855570?pdf=render,
5,Burned area detection and mapping using Sentinel-1 backscatter coefficient and thermal anomalies,233,,,"Belenguer-Plomer Miguel A.,Tanase Mihai A.,Fernandez-Carrillo Angel,Chuvieco Emilio","Belenguer-Plomer MA,Tanase MA,Fernandez-Carrillo A,Chuvieco E",Belenguer-Plomer MA,10.1016/j.rse.2019.111345,Universidad de Alcala,"This paper presents a burned area mapping algorithm based on change detection of Sentinel-1 backscatter data guided by thermal anomalies. The algorithm self-adapts to the local scattering conditions and it is robust to variations of input data availability. The algorithm applies the Reed-Xiaoli detector (RXD) to distinguish anomalous changes of the backscatter coefficient. Such changes are linked to fire events, which are derived from thermal anomalies (hotspots) acquired during the detection period by the Moderate Resolution Imaging Spectroradiometer (MODIS) and the Visible Infrared Imaging Radiometer Suite (VIIRS) sensors. Land cover maps were used to account for changing backscatter behaviour as the RXD is class dependent. A machine learning classifier (random forests) was used to detect burned areas where hotspots were not available. Burned area perimeters derived from optical images (Landsat-8 and Sentinel-2) were used to validate the algorithm results. The validation dataset covers 21 million hectares in 18 locations that represent the main biomes affected by fires, from boreal forests to tropical and sub-tropical forests and savannas. A mean Dice coefficient (DC) over all studied locations of 0.59 +/- 0.06 (+/- confidence interval, 95%) was obtained. Mean omission (OE) and commission errors (CE) were 0.43 +/- 0.08 and 0.37 +/- 0.06, respectively. Comparing results with the MODIS based MCD64A1 Version 6, our detections are quite promising, improving on average DC by 0.13 and reducing OE and CE by 0.12 and 0.06, respectively.","Burned area detection,Sentinel-1,Backscatter coefficient,SAR,Random forests,Reed-Xiaoli detector,Fire",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Environmental Sciences & Ecology,Remote Sensing,Imaging Science & Photographic Technology",,11.057,"RANDOM,FOREST,CLASSIFIER,GLOBAL,FIRE,EMISSIONS,BAND,SAR,BACKSCATTER,C-BAND,RADIOFREQUENCY,INTERFERENCE,SCATTERING,MODEL,BOREAL,FORESTS,CLIMATE,SEVERITY,ALGORITHM",REMOTE SENSING OF ENVIRONMENT,https://doi.org/10.1016/j.rse.2019.111345,
6,Computer-aided diagnosis for the identification of breast cancer using thermogram images: A comprehensive review,102,,,"Raghavendra U.,Gudigar Anjan,Rao Tejaswi N.,Ciaccio Edward J.,Ng E. Y. K.,Acharya U. Rajendra","Raghavendra U,Gudigar A,Rao TN,Ciaccio EJ,Ng EYK,Acharya UR",Gudigar A,10.1016/j.infrared.2019.103041,Manipal Academy of Higher Education (MAHE),"Breast cancer is a cancer that can form in the cells of breasts. It is much more common in females than in males. The typical periods of cancer development are during puberty, pregnancy, and breastfeeding. Thermography can be utilized for breast analysis, and provides useful data on the location of hyperthermia and the vascular state of the tissue. Computer-aided diagnosis is an algorithmic approach which can be assistive during routine screening, so that human error in breast analysis for cancer detection is reduced. In early-stage cancer, the accuracy of the assessment then increases, enabling clinicians to make an improved diagnosis of benign versus malignant classification. Herein, we have reviewed thermogram-based computer-aided diagnostic systems developed during the last two decades for breast cancer screening and analysis. We explore the quantitative and qualitative performances of machine learning based approaches, which include segmentation based and feature extraction based methods, dimensionality reduction, and various classification schemes, as proposed in the literature. We also describe the limitations, as well as future requirements to improve current techniques, which can help researchers and clinicians to be apprised of quantitative developments and to plan for the future.","Breast cancer,Computer-aided diagnosis tools,Thermograms",Review,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Optics,Physics",,2.581,"TEXTURE,FEATURES,NEURAL-NETWORK,FEATURE-EXTRACTION,CLASSIFICATION,SEGMENTATION,DATABASE,SYSTEM,BENIGN,TUMOR",INFRARED PHYSICS & TECHNOLOGY,,
7,A Stochastic Model for Virtual Data Generation of Crack Patterns in the Ceramics Manufacturing Process,56,6,596-600,"Park Youngho,Hyun Sangil,Hong Youn-Woo","Park Y,Hyun S,Hong YW",Hyun S,10.4191/kcers.2019.56.6.12,Korea Institute of Ceramic Engineering & Technology,"Artificial intelligence with a sufficient amount of realistic big data in certain applications has been demonstrated to play an important role in designing new materials or in manufacturing high-quality products. To reduce cracks in ceramic products using machine learning, it is desirable to utilize big data in recently developed data-driven optimization schemes. However, there is insufficient big data for ceramic processes. Therefore, we developed a numerical algorithm to make ""virtual"" manufacturing data sets using indirect methods such as computer simulations and image processing. In this study, a numerical algorithm based on the random walk was demonstrated to generate images of cracks by adjusting the conditions of the random walk process such as the number of steps, changes in direction, and the number of cracks.","Cracks,Random walk,Virtual big data,AI",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Materials Science,,1.304,"MATERIALS,SCIENCE",JOURNAL OF THE KOREAN CERAMIC SOCIETY,https://www.jkcs.or.kr/upload/pdf/kcers-2019-56-6-12.pdf,
8,Efficient Detection of Ventricular Late Potentials on ECG Signals Based on Wavelet Denoising and SVM Classification,10,11,,"Giorgio Agostino,Rizzi Maria,Guaragnella Cataldo","Giorgio A,Rizzi M,Guaragnella C",Guaragnella C,10.3390/info10110328,Politecnico di Bari,"The analysis of cardiac signals is still regarded as attractive by both the academic community and industry because it helps physicians in detecting abnormalities and improving the diagnosis and therapy of diseases. Electrocardiographic signal processing for detecting irregularities related to the occurrence of low-amplitude waveforms inside the cardiac signal has a considerable workload as cardiac signals are heavily contaminated by noise and other artifacts. This paper presents an effective approach for the detection of ventricular late potential occurrences which are considered as markers of sudden cardiac death risk. Three stages characterize the implemented method which performs a beat-to-beat processing of high-resolution electrocardiograms (HR-ECG). Fifteen lead HR-ECG signals are filtered and denoised for the improvement of signal-to-noise ratio. Five features were then extracted and used as inputs of a classifier based on a machine learning approach. For the performance evaluation of the proposed method, a HR-ECG database consisting of real ventricular late potential (VLP)-negative and semi-simulated VLP-positive patterns was used. Experimental results show that the implemented system reaches satisfactory performance in terms of sensitivity, specificity accuracy, and positive predictivity; in fact, the respective values equal to 98.33%, 98.36%, 98.35%, and 98.52% were achieved.","ventricular late potential (VLP),HR-ECG,computer-aided detection (CAD),wavelet transform,support vector machine (SVM),machine learning,accuracy",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"TO-BEAT,DETECTION,AVERAGED,ELECTROCARDIOGRAM,FREQUENCY-DOMAIN,ARRHYTHMIC,EVENTS,HIGH-RESOLUTION,IDENTIFICATION,RISK,QRS,TACHYCARDIA,INFARCTION",INFORMATION,https://www.mdpi.com/2078-2489/10/11/328/pdf,
9,Survey on Social Relationship Recognition Based on Images,55,21,36-45,",","Gao Jianjun,Qing Linbo",,,Gao Jianjun,"Social relationship is the general term for the relationship between people in the process of common material and spiritual activities. So far, all the researches have been done before are all related to the fields like social science, face recognition, impression recognition, motion recognition, scene recognition, object detection. As for this paper, start with a definition of different categories of relationships, it is divided into 4 parts from simple relation to difficult one by summarizing the researches relating to the topic. It introduces the method to extract the features and classification based on both traditional machine learning and deep learning. Meanwhile, the paper concludes the datasets and mechanism for different categories and compares the results, advantages and disadvantages of every work. This paper discusses the utilization of relationship recognition in real world and the possible direction that can be studied in the future.","social relationship; relationship recognition; computer vision; ,machine learning,; image classification",Review,,,,,,,,
10,Management Information System for Predicting Quantity Martials,8,4,1143-1149,"Shannaq Boumedyen,Al Shamsi Ibrahim,Majeed Saif Nabhan Abdul","Shannaq B,Al Shamsi I,Majeed SNA",Shannaq B,10.18421/TEM84-06,"Univ Burimi, Fac Coll Business MIS, Alburimi, Oman.","The purpose of this research work is to present in a systematic way the use of the integration method comprising the information system and prediction model towards optimizing the accuracy of Quantity Survey (QS) calculation. The main attention is paid to applied value of the considered methodology, to profitable interpretation and clarification of the results obtained. In order to achieve the goals, information system with the prediction model has been developed and integrated, which predicts the volume of concrete and steel materials using comprehensive experiments over a set of prediction shared algorithms. A new approach to prediction is proposed, based on the use of results of an automatic Information system capable to generate featured to improve the accuracy in the prediction problem. It was experimentally shown that in some cases this approach can be quite effective to significantly improve the quality of prediction and classification.","Prediction,Information system,QS,Neural networks,Machine learning",Article,"ASSOC INFORMATION COMMUNICATION TECHNOLOGY EDUCATION & SCIENCE, HILMA ROZAJCA 15, NOVI PAZAR, 36300, SERBIA",Computer Science,,,,TEM JOURNAL-TECHNOLOGY EDUCATION MANAGEMENT INFORMATICS,,
11,Exploring an Ensemble of Methods that Combines Fuzzy Cognitive Maps and Neural Networks in Solving the Time Series Prediction Problem of Gas Consumption in Greece,12,11,,"Papageorgiou Konstantinos I,Poczeta Katarzyna,Papageorgiou Elpiniki,Gerogiannis Vassilis C.,Stamoulis George","Papageorgiou KI,Poczeta K,Papageorgiou E,Gerogiannis VC,Stamoulis G",Papageorgiou KI,10.3390/a12110235,"Univ Thessaly, Dept Comp Sci & Telecommun, Lamia 35100, Greece.","This paper introduced a new ensemble learning approach, based on evolutionary fuzzy cognitive maps (FCMs), artificial neural networks (ANNs), and their hybrid structure (FCM-ANN), for time series prediction. The main aim of time series forecasting is to obtain reasonably accurate forecasts of future data from analyzing records of data. In the paper, we proposed an ensemble-based forecast combination methodology as an alternative approach to forecasting methods for time series prediction. The ensemble learning technique combines various learning algorithms, including SOGA (structure optimization genetic algorithm)-based FCMs, RCGA (real coded genetic algorithm)-based FCMs, efficient and adaptive ANNs architectures, and a hybrid structure of FCM-ANN, recently proposed for time series forecasting. All ensemble algorithms execute according to the one-step prediction regime. The particular forecast combination approach was specifically selected due to the advanced features of each ensemble component, where the findings of this work evinced the effectiveness of this approach, in terms of prediction accuracy, when compared against other well-known, independent forecasting approaches, such as ANNs or FCMs, and the long short-term memory (LSTM) algorithm as well. The suggested ensemble learning approach was applied to three distribution points that compose the natural gas grid of a Greek region. For the evaluation of the proposed approach, a real-time series dataset for natural gas prediction was used. We also provided a detailed discussion on the performance of the individual predictors, the ensemble predictors, and their combination through two well-known ensemble methods (the average and the error-based) that are characterized in the literature as particularly accurate and effective. The prediction results showed the efficacy of the proposed ensemble learning approach, and the comparative analysis demonstrated enough evidence that the approach could be used effectively to conduct forecasting based on multivariate time series.","fuzzy cognitive maps,neural networks,time series forecasting,ensemble learning,prediction,machine learning,natural gas",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"LOAD,FORECASTING-MODEL,NATURAL-GAS,GENETIC,ALGORITHM,DEMAND,COMBINATION,ARIMA,OPTIMIZATION,SOFTWARE,AVERAGES",ALGORITHMS,https://www.mdpi.com/1999-4893/12/11/235/pdf,
12,A Review on Personalized Pediatric Dosimetry Applications Using Advanced Computational Tools,3,6,607-620,"Papadimitroulas Panagiotis,Kostou Theodora,Chatzipapas Konstantinos,Visvikis Dimitris,Mountris Konstantinos A.,Jaouen Vincent,Katsanos Konstantinos,Diamantopoulos Athanasios,Apostolopoulos Dimitris,Balomenos Athanasios","Papadimitroulas P,Kostou T,Chatzipapas K,Visvikis D,Mountris KA,Jaouen V,Katsanos K,Diamantopoulos A,Apostolopoulos D,Balomenos A",Kagadis GC,10.1109/TRPMS.2018.2876562,University of Patras,"Pediatric patient-specific dosimetry of ionizing radiation is of great scientific and social interest. Children provide a higher relative cancer-risk from exposure to ionizing radiation compared to adults. The proposed study reviews the recent techniques applied in pediatric imaging and therapy applications for dosimetry purposes. Modern medicine makes use of advance computational tools for the personalization of internal and external dosimetry, especially in the sensitive group of children. Several groups of pediatric computational models have been developed which are combined with Monte Carlo (MC) simulations, machine learning (ML) techniques, and image processing algorithms for accurate dosimetry assessment. More specifically, this paper reviews the dosimetry applications in pediatric diagnostic procedures, including computed tomography and nuclear medicine applications. Right afterward, the most recent applications in therapeutic brachytherapy protocols are presented, which is a rather sensitive procedure in pediatrics. Finally, modern tools for dosimetry optimization are discussed, reviewing the most indicative applications with: 1) MC simulations for pediatric dosimetry assessment; 2) pediatric computational models, widely used in medical applications; and 3) ML techniques that provide an alternative method for estimating individualized absorbed doses.","Monte Carlo (MC) simulations,pediatric computational models,personalized dosimetry",Review,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"DOSE-RATE,BRACHYTHERAPY,MONTE-CARLO,SIMULATIONS,AMERICAN,CONSENSUS,GUIDELINES,IMAGE,GENTLY,CAMPAIGN,LOW-GRADE,GLIOMAS,NUCLEAR-MEDICINE,DOSAGE,CARD,ADMINISTERED,ACTIVITIES,TARGETED,RADIONUCLIDE,S-VALUES",IEEE TRANSACTIONS ON RADIATION AND PLASMA MEDICAL SCIENCES,https://ieeexplore.ieee.org/ielx7/7433213/8876808/08494773.pdf,
13,Endmember Learning with K-Means through SCD Model in Hyperspectral Scene Reconstructions,5,11,,"Chatterjee Ayan,Yuen Peter W. T.","Chatterjee A,Yuen PWT",Chatterjee A; Yuen PWT,10.3390/jimaging5110085,Cranfield University,"This paper proposes a simple yet effective method for improving the efficiency of sparse coding dictionary learning (DL) with an implication of enhancing the ultimate usefulness of compressive sensing (CS) technology for practical applications, such as in hyperspectral imaging (HSI) scene reconstruction. CS is the technique which allows sparse signals to be decomposed into a sparse representation ""a"" of a dictionary Du. The goodness of the learnt dictionary has direct impacts on the quality of the end results, e.g., in the HSI scene reconstructions. This paper proposes the construction of a concise and comprehensive dictionary by using the cluster centres of the input dataset, and then a greedy approach is adopted to learn all elements within this dictionary. The proposed method consists of an unsupervised clustering algorithm (K-Means), and it is then coupled with an advanced sparse coding dictionary (SCD) method such as the basis pursuit algorithm (orthogonal matching pursuit, OMP) for the dictionary learning. The effectiveness of the proposed K-Means Sparse Coding Dictionary (KMSCD) is illustrated through the reconstructions of several publicly available HSI scenes. The results have shown that the proposed KMSCD achieves similar to 40% greater accuracy, 5 times faster convergence and is twice as robust as that of the classic Spare Coding Dictionary (C-SCD) method that adopts random sampling of data for the dictionary learning. Over the five data sets that have been employed in this study, it is seen that the proposed KMSCD is capable of reconstructing these scenes with mean accuracies of approximately 20-500% better than all competing algorithms adopted in this work. Furthermore, the reconstruction efficiency of trace materials in the scene has been assessed: it is shown that the KMSCD is capable of recovering similar to 12% better than that of the C-SCD. These results suggest that the proposed DL using a simple clustering method for the construction of the dictionary has been shown to enhance the scene reconstruction substantially. When the proposed KMSCD is incorporated with the Fast non-negative orthogonal matching pursuit (FNNOMP) to constrain the maximum number of materials to coexist in a pixel to four, experiments have shown that it achieves approximately ten times better than that constrained by using the widely employed TMM algorithm. This may suggest that the proposed DL method using KMSCD and together with the FNNOMP will be more suitable to be the material allocation module of HSI scene simulators like the CameoSim package.","sparse coding,dictionary learning,unmixing,hyperspectral scene reconstruction,hyperspectral,multispectral,k-means",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Imaging Science & Photographic Technology,,,"SPARSE,REGRESSION,FAST,ALGORITHM,PURSUIT",JOURNAL OF IMAGING,https://www.mdpi.com/2313-433X/5/11/85/pdf,
14,Machine Learning Classification of Cervical Tissue Liquid Based Cytology Smear Images by Optomagnetic Imaging Spectroscopy,26,6,1694-1699,"Hut Igor,Jeftic Branislava,Matija Lidija,Cojbasic Zarko,Koruga Djuro","Hut I,Jeftic B,Matija L,Cojbasic Z,Koruga D",Hut I,10.17559/TV-20190528192618,University of Belgrade,"Semi-automated system for classification of cervical smear images based on Optomagnetic Imaging Spectroscopy (OMIS) and machine learning is proposed. Optomagnetic Imaging Spectroscopy has been applied to screen 700 cervical samples prepared according to Liquid Based Cytology (LBC) principles and to record spectra of the samples. Peak intensities and peak shift frequencies from the spectra have been used as features in classification models. Several machine learning algorithms have been tested and results of classification have been compared. Results suggest that the presented approach can be used to improve standard LBC screening tests for cervical cancer detection. Developed system enables detection of pre-cancerous and cancerous states with sensitivity of 79% and specificity of 83% along with AUC (ROC) of 88% and could be used as an improved alternative procedure for cervical cancer screening. Moreover, this can be achieved via portable apparatus and with immediately available results.","cervical cancer,classification,LBC,machine learning,OMIS,screening",Article,"UNIV OSIJEK, TECH FAC, TRG IVANE BRLIC-MAZURANIC 2, SLAVONSKI BROD, HR-35000, CROATIA",Engineering,,0.786,"GUIDELINES,TREES",TEHNICKI VJESNIK-TECHNICAL GAZETTE,https://hrcak.srce.hr/file/332437,
15,Platelet-rich clots as identified by Martius Scarlet Blue staining are isodense on NCCT,11,11,1145-1149,"Fitzgerald Sean T.,Wang Shunli,Dai Daying,Douglas Andrew,Kadirvel Ramanathan,Gounis Matthew J.,Chueh Juyu,Puri Ajit S.,Layton Kennith F.,Thacker Ike C.","Fitzgerald ST,Wang SL,Dai DY,Douglas A,Kadirvel R,Gounis MJ,Chueh J,Puri AS,Layton KF,Thacker IC",Fitzgerald ST,10.1136/neurintsurg-2018-014637,Mayo Clinic,"Background Current studies on clot characterization in acute ischemic stroke focus on fibrin and red blood cell composition. Few studies have examined platelet composition in acute ischemic stroke clots. We characterize clot composition using the Martius Scarlet Blue stain and assess associations between platelet density and CT density.
Materials and method Histopathological analysis of the clots collected as part of the multi-institutional STRIP registry was performed using Martius Scarlet Blue stain and the composition of the clots was quantified using Orbit Image Analysis (www.orbit.bio) machine learning software. Prior to endovascular treatment, each patient underwent non-contrast CT (NCCT) and the CT density of each clot was measured. Correlations between clot components and clinical information were assessed using the chi (2) test.
Results Eighty-five patients were included in the study. The mean platelet density of the clots was 15.7% (2.5-72.5%). There was a significant correlation between platelet-rich clots and the absence of hyperdensity on NCCT, (rho =0.321, p=0.003*, n=85). Similarly, there was a significant inverse correlation between the percentage of platelets and the mean Hounsfield Units on NCCT (rho=-0.243, p=0.025*, n=85).
Conclusion Martius Scarlet Blue stain can identify patients who have platelet-rich clots. Platelet-rich clots are isodense on NCCT.","platelets,stroke,CT,thrombectomy",Article,"BMJ PUBLISHING GROUP, BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND","Neurosciences & Neurology,Surgery",,4.815,"ACUTE,ISCHEMIC-STROKE,PLASMINOGEN-ACTIVATOR,THROMBI,THROMBECTOMY",JOURNAL OF NEUROINTERVENTIONAL SURGERY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7754082,
16,Adaptive Network Based Fuzzy Inference System with Meta-Heuristic Optimizations for International Roughness Index Prediction,9,21,,"Hoang-Long Nguyen,Binh Thai Pham,Le Hoang Son,Nguyen Trung Thang,Hai-Bang Ly,Tien-Thinh Le,Ho Lanh Si,Thanh-Hai Le,Dieu Tien Bui","Nguyen HL,Pham BT,Son L,Thang NT,Ly HB,Le TT,Ho LS,Le TH,Bui DT",Bui DT,10.3390/app9214715,Ton Duc Thang University,"The International Roughness Index (IRI) is the one of the most important roughness indexes to quantify road surface roughness. In this paper, we propose a new hybrid approach between adaptive network based fuzzy inference system (ANFIS) and various meta-heuristic optimizations such as the genetic algorithm (GA), particle swarm optimization (PSO), and the firefly algorithm (FA) to develop several hybrid models namely GA based ANGIS (GANFIS), PSO based ANFIS (PSOANFIS), FA based ANFIS (FAANFIS), respectively, for the prediction of the IRI. A benchmark model named artificial neural networks (ANN) was also used to compare with those hybrid models. To do this, a total of 2811 samples in the case study of the north of Vietnam (Northwest region, Northeast region, and the Red River Delta Area) within the scope of management of the DRM-I Department were used to validate the models in terms of various criteria like coefficient of determination (R) and the root mean square error (RMSE). Experimental results affirmed the potentiality and effectiveness of the proposed prediction models whereas the PSOANFIS (RMSE = 0.145 and R = 0.888) is better than the other models named GANFIS (RMSE = 0.155 and R = 0.872), FAANFIS (RMSE = 0.170 and R = 0.849), and ANN (RMSE = 0.186 and R = 0.804). The results of this study are helpful for accurate prediction of the IRI for evaluation of quality of road surface roughness.","International Roughness Index,ANFIS,machine learning,ANN,particle swarm optimization",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"NEURAL-NETWORK,LANDSLIDE,SUSCEPTIBILITY,PAVEMENT,ROUGHNESS,COEFFICIENT,ENSEMBLE",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/9/21/4715/pdf,
17,Development of a Comprehensive Model for the Coulombic Efficiency and Capacity Fade of LiFePO4 Batteries under Different Aging Conditions,9,21,,Kuo Ting-Jung,Kuo TJ,Kuo TJ,10.3390/app9214572,National Taiwan University,"In this paper, a comprehensive model for LiFePO4 batteries is proposed to ensure high efficiency and safe operation. The proposed model has a direct correlation between its parameters and the electrochemical principles to estimate the state of charge (SoC) and the remaining capacity of the LiFePO4 battery. This model was based on a modified Thevenin circuit, Butler-Volmer kinetics, the Arrhenius equation, Peukert's law, and a back propagation neural network (BPNN), which can be divided into two parts. The first part can be represented by the dual exponential terms, responsive to the Coulomb efficiency; the second part can be described by the BPNN, estimating the remaining capacity. The model successfully estimates the SoC of the batteries that were tested with an error of 1.55%. The results suggest that the model is able to accurately estimate the SoC and the remaining capacity in various environments (discharging C rates and temperatures).","LiFePO4 batteries,state of charge (SoC),Butler-Volmer equation,Arrhenius,Peukert,coulomb efficiency,back propagation neural network (BPNN)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"LITHIUM-ION,BATTERIES,LOW-TEMPERATURE,PERFORMANCE,ARTIFICIAL,NEURAL-NETWORK,ELECTRODE,MATERIALS,CHARGE,STATE,DEGRADATION,MECHANISMS,PREDICTION,PRECISION",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/9/21/4572/pdf,
18,Computational Analysis of Deep Visual Data for Quantifying Facial Expression Production,9,21,,"Leo Marco,Carcagni Pierluigi,Distante Cosimo,Mazzeo Pier Luigi,Spagnolo Paolo,Levante Annalisa,Petrocchi Serena,Lecciso Flavia","Leo M,Carcagni P,Distante C,Mazzeo PL,Spagnolo P,Levante A,Petrocchi S,Lecciso F",Leo M,10.3390/app9214542,Consiglio Nazionale delle Ricerche (CNR),"The computational analysis of facial expressions is an emerging research topic that could overcome the limitations of human perception and get quick and objective outcomes in the assessment of neurodevelopmental disorders (e.g., Autism Spectrum Disorders, ASD). Unfortunately, there have been only a few attempts to quantify facial expression production and most of the scientific literature aims at the easier task of recognizing if either a facial expression is present or not. Some attempts to face this challenging task exist but they do not provide a comprehensive study based on the comparison between human and automatic outcomes in quantifying children's ability to produce basic emotions. Furthermore, these works do not exploit the latest solutions in computer vision and machine learning. Finally, they generally focus only on a homogeneous (in terms of cognitive capabilities) group of individuals. To fill this gap, in this paper some advanced computer vision and machine learning strategies are integrated into a framework aimed to computationally analyze how both ASD and typically developing children produce facial expressions. The framework locates and tracks a number of landmarks (virtual electromyography sensors) with the aim of monitoring facial muscle movements involved in facial expression production. The output of these virtual sensors is then fused to model the individual ability to produce facial expressions. Gathered computational outcomes have been correlated with the evaluation provided by psychologists and evidence has been given that shows how the proposed framework could be effectively exploited to deeply analyze the emotional competence of ASD children to produce facial expressions.","assistive technology,autism,facial expressions,computer vision",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"AUTISM,EMOTION,MODEL,FEATURES,CHILDREN,NETWORK,MIND",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/9/21/4542/pdf,
19,AR Graphic Representation of Musical Notes for Self-Learning on Guitar,9,21,,"Sylvia Del Rio-Guerra Marta,Martin-Gutierrez Jorge,Lopez-Chao Vicente A.,Flores Parra Rodolfo,Ramirez Sosa Mario A.","Del Rio-Guerra MS,Martin-Gutierrez J,Lopez-Chao VA,Parra RF,Sosa MAR",Martin-Gutierrez J,10.3390/app9214527,Universidad de la Laguna,"Despite being one of the most commonly self-taught instruments, and despite the ready availability of significant amounts of didactic material, the guitar is a challenging instrument to learn. This paper proposes an application based on augmented reality (AR) that is designed to teach beginner students basic musical chords on the guitar, and provides details of the experimental study performed to determine whether the AR methodology produced faster results than traditional one-on-one training with a music teacher. Participants were divided into two groups of the same size. Group 1 consisted of 32 participants who used the AR app to teach themselves guitar, while Group 2, with a further 32 participants, received formal instruction from a music teacher. Results found no differences in learning times between the two groups based on the variables of method and gender. However, participant feedback suggested that there are advantages to the self-taught approach using AR that are worth considering. A system usability scale (SUS) questionnaire was used to measure the usability of the application, obtaining a score of 82.5, which was higher than the average of 68 that indicates an application to be good from a user experience point of view, and satisfied the purpose for which the application was created.","learning interfaces,augmented reality,guitar,accurate registration,learning music,education",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"GENDER-DIFFERENCES,EDUCATION,ROCKSMITH,TRACKING,TUITION,NUMBER,PLAY",APPLIED SCIENCES-BASEL,https://doi.org/10.3390/app9214527,
20,Experiment and Modeling on Macro Fiber Composite Stress-Induced Actuation Function Degradation,9,21,,"Wang Wei,Zhang Zikuo,Yang Zhichun","Wang W,Zhang ZK,Yang ZC",Wang W,10.3390/app9214714,Northwestern Polytechnical University,"The effect of stress depolarization will cause actuation function degradation of a piezoelectric actuator, which can eventually trigger function failure of the piezoelectric smart structure system. In the present study, we experimentally demonstrate the degradation process of the actuation function of the Macro Fiber Composite (MFC) piezoelectric actuator. Actuation function degradation data of MFC actuators undergoing cyclic loads with four different stress amplitudes have been measured. Based upon the experimental results, the radial basis function (RBF) neural network learning algorithm was adopted to establish a neural network model, in order to predict the actuation function degenerative degree of the MFC actuator, undergoing arbitrary cyclic load within the concerned stress amplitude range. The maximum relative error between the predicted result and our experimental result is 4%.","stress induced,MFC actuator,actuation function degradation,experimental observation,predictive modeling",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"PIEZOELECTRIC,PROPERTIES,PZT,PIEZOCERAMICS,PERFORMANCE",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/9/21/4714/pdf,
21,Deep learning based retinal OCT segmentation,114,,,"Pekala M.,Joshi N.,Liu T. Y. Alvin,Bressler N. M.,DeBuc D. Cabrera,Burlina P.","Pekala M,Joshi N,Liu TYA,Bressler NM,DeBuc DC,Burlina P",Burlina P,10.1016/j.compbiomed.2019.103445,Johns Hopkins University,"We look at the recent application of deep learning (DL) methods in automated fine-grained segmentation of spectral domain optical coherence tomography (OCT) images of the retina. We describe a new method combining fully convolutional networks (FCN) with Gaussian Processes for post processing. We report performance comparisons between the proposed approach, human clinicians, and other machine learning (ML) such as graph based approaches. The approach is demonstrated on an OCT dataset consisting of mild non-proliferative diabetic retinopathy from the University of Miami. The method is shown to have performance on par with humans, also compares favorably with the other ML methods, and appears to have as small or smaller mean unsigned error (equal to 1.06), versus errors ranging from 1.17 to 1.81 for other methods, and compared with human error of 1.10.","Fully convolutional networks,Gaussian process regression,OCT segmentation,Neurodegenerative,Retinal and vascular diseases",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"OPTICAL,COHERENCE,TOMOGRAPHY,GEOGRAPHIC,ATROPHY,DIABETIC-PATIENTS,IMAGES,LAYER,NEURODEGENERATION,FEATURES,FLUID,AMD",COMPUTERS IN BIOLOGY AND MEDICINE,http://arxiv.org/pdf/1801.09749,
22,Bilateral photoplethysmography for peripheral arterial disease screening in haemodialysis patients using astable multivibrator and machine learning classifier,13,9,1277-1286,"Wu Jian-Xing,Lin Chia-Hung,Kan Chung-Dann,Chen Wei-Ling","Wu JX,Lin CH,Kan CD,Chen WL",Lin CH,10.1049/iet-smt.2018.5330,National Chin-Yi University of Technology,"Peripheral arterial disease (PAD) is highly prevalent in haemodialysis (HD) patients with type 2 diabetes. Atherosclerosis may occur in both lower and upper peripheral arteries, causing progressive dialysis access stenosis in HD patients. To assess the risk of PAD, non-invasive bilateral photoplethysmography (PPG) can be used to obtain continuous variations in blood flow volume in in vivo examinations. The authors propose an astable multivibrator to model the peripheral circulation system and to produce PPG oscillation with time constants, duty ratio (rising time), and amplitude ratio of systolic and diastolic pressures. Then, the bilateral differences in the time constant and duty ratio are used to separate the normal condition from PAD. The machine learning decision-making process utilises a screening method to automatically detect subjects with and without the risk of PAD. The radial-based function is employed to parameterise the similarity and dissimilarity levels using probability values. Colour relation analysis incorporates the probability values into the perceptual colour relationships for PAD screening. The experimental results indicate that in comparison with bilateral timing parameters, degree of stenosis, and resistive index, the proposed screening method is efficient in preventing complications of PAD and is easily implemented in an embedded system.","learning (artificial intelligence),diseases,medical signal processing,photoplethysmography,haemodynamics,blood vessels,probability,peripheral arterial disease screening,haemodialysis patients,astable multivibrator,type 2 diabetes,upper peripheral arteries,progressive dialysis access stenosis,HD patients,noninvasive bilateral photoplethysmography,continuous variations,blood flow volume,peripheral circulation system,PPG oscillation,time constants,duty ratio,rising time,amplitude ratio,systolic pressures,diastolic pressures,bilateral differences,screening method,probability values,PAD screening,bilateral timing parameters,in vivo examinations,atherosclerosis,lower peripheral arteries,radial-based function,colour relation analysis,perceptual colour relationships,resistive index,embedded system",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND",Engineering,,1.965,,IET SCIENCE MEASUREMENT & TECHNOLOGY,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-smt.2018.5330,
23,Deep transfer learning methods for colon cancer classification in confocal laser microscopy images,14,11,1837-1845,"Gessert Nils,Bengs Marcel,Wittig Lukas,Droemann Daniel,Keck Tobias,Schlaefer Alexander,Ellebrecht David B.","Gessert N,Bengs M,Wittig L,Droemann D,Keck T,Schlaefer A,Ellebrecht DB",Gessert N,10.1007/s11548-019-02004-1,Hamburg University of Technology,"Purpose The gold standard for colorectal cancer metastases detection in the peritoneum is histological evaluation of a removed tissue sample. For feedback during interventions, real-time in vivo imaging with confocal laser microscopy has been proposed for differentiation of benign and malignant tissue by manual expert evaluation. Automatic image classification could improve the surgical workflow further by providing immediate feedback. Methods We analyze the feasibility of classifying tissue from confocal laser microscopy in the colon and peritoneum. For this purpose, we adopt both classical and state-of-the-art convolutional neural networks to directly learn from the images. As the available dataset is small, we investigate several transfer learning strategies including partial freezing variants and full fine-tuning. We address the distinction of different tissue types, as well as benign and malignant tissue. Results We present a thorough analysis of transfer learning strategies for colorectal cancer with confocal laser microscopy. In the peritoneum, metastases are classified with an AUC of 97.1, and in the colon the primarius is classified with an AUC of 73.1. In general, transfer learning substantially improves performance over training from scratch. We find that the optimal transfer learning strategy differs for models and classification tasks. Conclusions We demonstrate that convolutional neural networks and transfer learning can be used to identify cancer tissue with confocal laser microscopy. We show that there is no generally optimal transfer learning strategy and model as well as task-specific engineering is required. Given the high performance for the peritoneum, even with a small dataset, application for intraoperative decision support could be feasible.","Colon cancer,Confocal laser microscopy,Transfer learning,Convolution neural network",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,,"CONVOLUTIONAL,NEURAL-NETWORKS,PERITONEAL,CARCINOMATOSIS,SKIN,CT",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,http://arxiv.org/pdf/1905.07991,
24,Memory-efficient 2.5D convolutional transformer networks for multi-modal deformable registration with weak label supervision applied to whole-heart CT and MRI scans,14,11,1901-1912,"Hering Alessa,Kuckertz Sven,Heldmann Stefan,Heinrich Mattias P.","Hering A,Kuckertz S,Heldmann S,Heinrich MP",Hering A,10.1007/s11548-019-02068-z,"Fraunhofer Inst Digital Med MEVIS, Maria Goeppert Str 3, D-23562 Lubeck, Germany.","Purpose Despite its potential for improvements through supervision, deep learning-based registration approaches are difficult to train for large deformations in 3D scans due to excessive memory requirements. Methods We propose a new 2.5D convolutional transformer architecture that enables us to learn a memory-efficient weakly supervised deep learning model for multi-modal image registration. Furthermore, we firstly integrate a volume change control term into the loss function of a deep learning-based registration method to penalize occurring foldings inside the deformation field. Results Our approach succeeds at learning large deformations across multi-modal images. We evaluate our approach on 100 pair-wise registrations of CT and MRI whole-heart scans and demonstrate considerably higher Dice Scores (of 0.74) compared to a state-of-the-art unsupervised discrete registration framework (deeds with Dice of 0.71). Conclusion Our proposed memory-efficient registration method performs better than state-of-the-art conventional registration methods. By using a volume change control term in the loss function, the number of occurring foldings can be considerably reduced on new registration cases.","Multi-modal registration,Convolutional neural networks,Weakly supervised learning,CT,MRI,2,5D",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,,,INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
25,Fully automated intracranial ventricle segmentation on CT with 2D regional convolutional neural network to estimate ventricular volume,14,11,1923-1932,"Huff Trevor J.,Ludwig Parker E.,Salazar David,Cramer Justin A.","Huff TJ,Ludwig PE,Salazar D,Cramer JA",Huff TJ,10.1007/s11548-019-02038-5,Creighton University,"Purpose Hydrocephalus is a clinically significant condition which can have devastating consequences if left untreated. Currently available methods for quantifying this condition using CT imaging are unreliable and prone to error. The purpose of this study is to investigate the clinical utility of using convolutional neural networks to calculate ventricular volume and explore limitations. Methods A two-dimensional convolutional neural network was designed to perform fully automated ventricular segmentation on CT images. A total of 300 head CTs were collected and used in this exploration. Two hundred were used to train the network, 50 were used for validation, and 50 were used for testing. Results Dice scores for the left lateral, right lateral, and third ventricle segmentations were 0.92, 0.92, and 0.79, respectively; the coefficients of determination were r(2) = 0.991, r(2) = 0.994, and r(2) = 0.976; the average volume differences between manual and automated segmentation were 0.821 ml, 0.587 ml, and 0.099 ml. Conclusion Two-dimensional convolutional neural network architectures can be used to accurately segment and quantify intracranial ventricle volume. While further refinements are necessary, it is likely these networks could be used as a clinical tool to quantify hydrocephalus accurately and efficiently.","U-Net,Convolutional neural network (CNN),Machine learning,Intracranial ventricle volume,Automated segmentation",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,"IMAGES,MRI",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
26,Deep learning for World Health Organization grades of pancreatic neuroendocrine tumors on contrast-enhanced magnetic resonance images: a preliminary study,14,11,1981-1991,"Gao Xuan,Wang Xiaolin","Gao X,Wang XL",Wang XL,10.1007/s11548-019-02070-5,"Shanghai Inst Med Imaging, 180 Fenglin Rd, Shanghai 200032, Peoples R China.","Purpose The World Health Organization (WHO) grading system of pancreatic neuroendocrine tumor (PNET) plays an important role in the clinical decision. The rarity of PNET often negatively affects the radiological application of deep learning algorithms due to the low availability of radiological images. We tried to investigate the feasibility of predicting WHO grades of PNET on contrast-enhanced magnetic resonance (MR) images by deep learning algorithms. Materials and methods Ninety-six patients with PNET underwent preoperative contrast-enhanced MR imaging. Fivefold cross-validation was used in which five iterations of training and validation were performed. Within every iteration, on the training set augmented by synthetic images generated from generative adversarial network (GAN), a convolutional neural network (CNN) was trained and its performance was evaluated on the paired internal validation set. Finally, the trained CNNs from cross-validation and their averaged counterpart were separately assessed on another ten patients from a different external validation set. Results Averaging the results across the five iterations in the cross-validation, for the CNN model, the average accuracy was 85.13% +/- 0.44% and micro-average AUC was 0.9117 +/- 0.0053. Evaluated on the external validation set, the average accuracy of the five trained CNNs ranges between 79.08 and 82.35%, and the range of micro-average AUC was between 0.8825 and 0.8932. The average accuracy and micro-average AUC of the averaged CNN were 81.05% and 0.8847, respectively. Conclusion Synthetic images generated from GAN could be used to alleviate the difficulty of radiological image collection for uncommon disease like PNET. With the help of GAN, the CNN showed the potential to predict the WHO grades of PNET on contrast-enhanced MR images.","Pancreatic neuroendocrine tumor,Convolutional neural network,Generative adversarial network,Magnetic resonance imaging",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,"CONVOLUTIONAL,NEURAL-NETWORK,DIFFUSION-COEFFICIENT,IMAGING,FEATURES,CLASSIFICATION,PREDICTION,MALIGNANCY,CT",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
27,Machine learning methods for automated technical skills assessment with instructional feedback in ultrasound-guided interventions,14,11,1993-2003,"Holden Matthew S.,Xia Sean,Lia Hillary,Keri Zsuzsanna,Bell Colin,Patterson Lindsey,Ungi Tamas,Fichtinger Gabor","Holden MS,Xia S,Lia H,Keri Z,Bell C,Patterson L,Ungi T,Fichtinger G",Holden MS,10.1007/s11548-019-01977-3,Queens University - Canada,"Objective Currently, there is a worldwide shift toward competency-based medical education. This necessitates the use of automated skills assessment methods during self-guided interventions training. Making assessment methods that are transparent and configurable will allow assessment to be interpreted into instructional feedback. The purpose of this work is to develop and validate skills assessment methods in ultrasound-guided interventions that are transparent and configurable. Methods We implemented a method based upon decision trees and a method based upon fuzzy inference systems for technical skills assessment. Subsequently, we validated these methods for their ability to predict scores of operators on a 25-point global rating scale in ultrasound-guided needle insertions and their ability to provide useful feedback for training. Results Decision tree and fuzzy rule-based assessment performed comparably to state-of-the-art assessment methods. They produced median errors (on a 25-point scale) of 1.7 and 1.8 for in-plane insertions and 1.5 and 3.0 for out-of-plane insertions, respectively. In addition, these methods provided feedback that was useful for trainee learning. Decision tree assessment produced feedback with median usefulness 7 out of 7; fuzzy rule-based assessment produced feedback with median usefulness 6 out of 7. Conclusion Transparent and configurable assessment methods are comparable to the state of the art and, in addition, can provide useful feedback. This demonstrates their value in self-guided interventions training curricula.","Ultrasound-guided needle insertion,Simulation-based training,Medical education,Objective skill assessment",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,"SURGICAL,SKILL,OPERATING-ROOM,CLASSIFICATION,MOTION,COMPETENCE,PERFORMANCE,SCORE,TOOL",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
28,Cohort selection for clinical trials: n2c2 2018 shared task track 1,26,11,1163-1171,"Stubbs Amber,Filannino Michele,Soysal Ergin,Henry Samuel,Uzuner Ozlem","Stubbs A,Filannino M,Soysal E,Henry S,Uzuner O",Stubbs A,10.1093/jamia/ocz163,Simmons University,"Objective: Track 1 of the 2018 National NLP Clinical Challenges shared tasks focused on identifying which patients in a corpus of longitudinal medical records meet and do not meet identified selection criteria.
Materials and Methods: To address this challenge, we annotated American English clinical narratives for 288 patients according to whether they met these criteria. We chose criteria from existing clinical trials that represented a variety of natural language processing tasks, including concept extraction, temporal reasoning, and inference.
Results: A total of 47 teams participated in this shared task, with 224 participants in total. The participants represented 18 countries, and the teams submitted 109 total system outputs. The best-performing system achieved a micro F1 score of 0.91 using a rule-based approach. The top 10 teams used rule-based and hybrid systems to approach the problems.
Discussion: Clinical narratives are open to interpretation, particularly in cases where the selection criterion may be underspecified. This leaves room for annotators to use domain knowledge and intuition in selecting patients, which may lead to error in system outputs. However, teams who consulted medical professionals while building their systems were more likely to have high recall for patients, which is preferable for patient selection systems.
Conclusions: There is not yet a 1-size-fits-all solution for natural language processing systems approaching this task. Future research in this area can look to examining criteria requiring even more complex inferences, temporal reasoning, and domain knowledge.","natural language processing,clinical narratives,machine learning,cohort selection,information extraction",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,EFFICIENCY,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6798568,
29,Hybrid bag of approaches to characterize selection criteria for cohort identification,26,11,1172-1180,"Vydiswaran V. G. Vinod,Strayhorn Asher,Zhao Xinyan,Robinson Phil,Agarwal Mahesh,Bagazinski Erin,Essiet Madia,Iott Bradley E.,Joo Hyeon,Ko PingJui","Vydiswaran VGV,Strayhorn A,Zhao XY,Robinson P,Agarwal M,Bagazinski E,Essiet M,Iott BE,Joo H,Ko PJ",Vydiswaran VGV,10.1093/jamia/ocz079,University of Michigan System,"Objective: The 2018 National NLP Clinical Challenge (2018 n2c2) focused on the task of cohort selection for clinical trials, where participating systems were tasked with analyzing longitudinal patient records to determine if the patients met or did not meet any of the 13 selection criteria. This article describes our participation in this shared task.
Materials and Methods: We followed a hybrid approach combining pattern-based, knowledge-intensive, and feature weighting techniques. After preprocessing the notes using publicly available natural language processing tools, we developed individual criterion-specific components that relied on collecting knowledge resources relevant for these criteria and pattern-based and weighting approaches to identify ""met"" and ""not met"" cases.
Results: As part of the 2018 n2c2 challenge, 3 runs were submitted. The overall micro-averaged F1 on the training set was 0.9444. On the test set, the micro-averaged F1 for the 3 submitted runs were 0.9075, 0.9065, and 0.9056. The best run was placed second in the overall challenge and all 3 runs were statistically similar to the top-ranked system. A reimplemented system achieved the best overall F1 of 0.9111 on the test set.
Discussion: We highlight the need for a focused resource-intensive effort to address the class imbalance in the cohort selection identification task.
Conclusion: Our hybrid approach was able to identify all selection criteria with high F1 performance on both training and test sets. Based on our participation in the 2018 n2c2 task, we conclude that there is merit in continuing a focused criterion-specific analysis and developing appropriate knowledge resources to build a quality cohort selection system.","natural language processing (L01, 224, 065, 580),information storage and retrieval [L01, 313, 500, 750, 280],information systems [L01, 313, 500, 750, 300],cohort identification,clinical trial selection criteria",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"AUTOMATIC,IDENTIFICATION,KNOWLEDGE,EXTRACTION,RECORDS",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647216,
30,Cohort selection for clinical trials using deep learning models,26,11,1181-1188,"Segura-Bedmar Isabel,Raez Pablo","Segura-Bedmar I,Raez P",Segura-Bedmar I,10.1093/jamia/ocz139,Universidad Carlos III de Madrid,"Objective: The goal of the 2018 n2c2 shared task on cohort selection for clinical trials (track 1) is to identify which patients meet the selection criteria for clinical trials. Cohort selection is a particularly demanding task to which natural language processing and deep learning can make a valuable contribution. Our goal is to evaluate several deep learning architectures to deal with this task.
Materials and Methods: Cohort selection can be formulated as a multilabeling problem whose goal is to determine which criteria are met for each patient record. We explore several deep learning architectures such as a simple convolutional neural network (CNN), a deep CNN, a recurrent neural network (RNN), and CNN-RNN hybrid architecture. Although our architectures are similar to those proposed in existing deep learning systems for text classification, our research also studies the impact of using a fully connected feedforward layer on the performance of these architectures.
Results: The RNN and hybrid models provide the best results, though without statistical significance. The use of the fully connected feedforward layer improves the results for all the architectures, except for the hybrid architecture.
Conclusions: Despite the limited size of the dataset, deep learning methods show promising results in learning useful features for the task of cohort selection. Therefore, they can be used as a previous filter for cohort selection for any clinical trial with a minimum of human intervention, thus reducing the cost and time of clinical trials significantly.","cohort selection,deep learning,multilabel text classification,convolutional neural network,recurrent neural network",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://e-archivo.uc3m.es/bitstream/10016/31254/2/cohort_segura_JAMIA_2019.pdf,
31,Optimizing clinical trials recruitment via deep learning,26,11,1195-1202,"Gligorijevic Jelena,Gligorijevic Djordje,Pavlovski Martin,Milkovits Elizabeth,Glass Lucas,Grier Kevin,Vankireddy Praveen,Obradovic Zoran","Gligorijevic J,Gligorijevic D,Pavlovski M,Milkovits E,Glass L,Grier K,Vankireddy P,Obradovic Z",Obradovic Z,10.1093/jamia/ocz064,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Objective: Clinical trials, prospective research studies on human participants carried out by a distributed team of clinical investigators, play a crucial role in the development of new treatments in health care. This is a complex and expensive process where investigators aim to enroll volunteers with predetermined characteristics, administer treatment(s), and collect safety and efficacy data. Therefore, choosing top-enrolling investigators is essential for efficient clinical trial execution and is 1 of the primary drivers of drug development cost.
Materials and Methods: To facilitate clinical trials optimization, we propose DeepMatch (DM), a novel approach that builds on top of advances in deep learning. DM is designed to learn from both investigator and trial-related heterogeneous data sources and rank investigators based on their expected enrollment performance on new clinical trials.
Results: Large-scale evaluation conducted on 2618 studies provides evidence that the proposed ranking-based framework improves the current state-of-the-art by up to 19% on ranking investigators and up to 10% on detecting top/bottom performers when recruiting investigators for new clinical trials.
Discussion: The extensive experimental section suggests that DM can provide substantial improvement over current industry standards in several regards: (1) the enrollment potential of the investigator list, (2) the time it takes to generate the list, and (3) data-informed decisions about new investigators.
Conclusion: Due to the great significance of the problem at hand, related research efforts are set to shift the paradigm of how investigators are chosen for clinical trials, thereby optimizing and automating them and reducing the cost of new therapies.","clinical trials,electronic health records,deep learning,deep matching,pointwise ranking",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,TEXT,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647233,
32,Cohort selection for clinical trials using hierarchical neural network,26,11,1203-1208,"Xiong Ying,Shi Xue,Chen Shuai,Jiang Dehuan,Tang Buzhou,Wang Xiaolong,Chen Qingcai,Yan Jun","Xiong Y,Shi X,Chen S,Jiang DH,Tang BZ,Wang XL,Chen QC,Yan J",Tang BZ,10.1093/jamia/ocz099,Harbin Institute of Technology,"Objective: Cohort selection for clinical trials is a key step for clinical research. We proposed a hierarchical neural network to determine whether a patient satisfied selection criteria or not.
Materials and Methods: We designed a hierarchical neural network (denoted as CNN-Highway-LSTM or LSTM-Highway-LSTM) for the track 1 of the national natural language processing (NLP) clinical challenge (n2c2) on cohort selection for clinical trials in 2018. The neural network is composed of 5 components: (1) sentence representation using convolutional neural network (CNN) or long short-term memory (LSTM) network; (2) a highway network to adjust information flow; (3) a self-attention neural network to reweight sentences; (4) document representation using LSTM, which takes sentence representations in chronological order as input; (5) a fully connected neural network to determine whether each criterion is met or not. We compared the proposed method with its variants, including the methods only using the first component to represent documents directly and the fully connected neural network for classification (denoted as CNN-only or LSTM-only) and the methods without using the highway network (denoted as CNN-LSTM or LSTM-LSTM). The performance of all methods was measured by micro-averaged precision, recall, and F1 score.
Results: The micro-averaged F1 scores of CNN-only, LSTM-only, CNN-LSTM, LSTM-LSTM, CNN-Highway-LSTM, and LSTM-Highway-LSTM were 85.24%, 84.25%, 87.27%, 88.68%, 88.48%, and 90.21%, respectively. The highest micro-averaged F1 score is higher than our submitted 1 of 88.55%, which is 1 of the top-ranked results in the challenge. The results indicate that the proposed method is effective for cohort selection for clinical trials.
Discussion: Although the proposed method achieved promising results, some mistakes were caused by word ambiguity, negation, number analysis and incomplete dictionary. Moreover, imbalanced data was another challenge that needs to be tackled in the future.
Conclusion: In this article, we proposed a hierarchical neural network for cohort selection. Experimental results show that this method is good at selecting cohort.","cohort selection,clinical trials,hierarchical neural network,classification,mental health records",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"EXTRACTION,TEXT,ARCHITECTURE,SYSTEM",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647215,
33,Medical knowledge infused convolutional neural networks for cohort selection in clinical trials,26,11,1227-1236,"Chen Chi-Jen,Warikoo Neha,Chang Yung-Chun,Chen Jin-Hua,Hsu Wen-Lian","Chen CJ,Warikoo N,Chang YC,Chen JH,Hsu WL",Chang YC,10.1093/jamia/ocz128,Taipei Medical University,"Objective: In this era of digitized health records, there has been a marked interest in using de-identified patient records for conducting various health related surveys. To assist in this research effort, we developed a novel clinical data representation model entitled medical knowledge-infused convolutional neural network (MKCNN), which is used for learning the clinical trial criteria eligibility status of patients to participate in cohort studies.
Materials and Methods: In this study, we propose a clinical text representation infused with medical knowledge (MK). First, we isolate the noise from the relevant data using a medically relevant description extractor; then we utilize log-likelihood ratio based weights from selected sentences to highlight ""met"" and ""not-met"" knowledge-infused representations in bichannel setting for each instance. The combined medical knowledge-infused representation (MK) from these modules helps identify significant clinical criteria semantics, which in turn renders effective learning when used with a convolutional neural network architecture.
Results: MKCNN outperforms other Medical Knowledge (MK) relevant learning architectures by approximately 3%; notably SVM and XGBoost implementations developed in this study. MKCNN scored 86.1% on F1metric, a gain of 6% above the average performance assessed from the submissions for n2c2 task. Although pattern/rule-based methods show a higher average performance for the n2c2 clinical data set, MKCNN significantly improves performance of machine learning implementations for clinical datasets.
Conclusion: MKCNN scored 86.1% on the F1 score metric. In contrast to many of the rule-based systems introduced during the n2c2 challenge workshop, our system presents a model that heavily draws on machine-based learning. In addition, the MK representations add more value to clinical comprehension and interpretation of natural texts.","natural language processing,cohort selection,clinical trials,convolutional neural network,medical records",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,CLASSIFICATION,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647228,
34,Evaluating shallow and deep learning strategies for the 2018 n2c2 shared task on clinical text classification,26,11,1247-1254,"Oleynik Michel,Kugic Amila,Kasac Zdenko,Kreuzthaler Markus","Oleynik M,Kugic A,Kasac Z,Kreuzthaler M",Oleynik M,10.1093/jamia/ocz149,Medical University of Graz,"Objective: Automated clinical phenotyping is challenging because word-based features quickly turn it into a high-dimensional problem, in which the small, privacy-restricted, training datasets might lead to overfitting. Pretrained embeddings might solve this issue by reusing input representation schemes trained on a larger dataset. We sought to evaluate shallow and deep learning text classifiers and the impact of pretrained embeddings in a small clinical dataset.
Materials and Methods: We participated in the 2018 National NLP Clinical Challenges (n2c2) Shared Task on cohort selection and received an annotated dataset with medical narratives of 202 patients for multilabel binary text classification. We set our baseline to a majority classifier, to which we compared a rule-based classifier and orthogonal machine learning strategies: support vector machines, logistic regression, and long short-term memory neural networks. We evaluated logistic regression and long short-term memory using both self-trained and pretrained BioWordVec word embeddings as input representation schemes.
Results: Rule-based classifier showed the highest overall micro F-1 score (0.9100), with which we finished first in the challenge. Shallow machine learning strategies showed lower overall micro F-1 scores, but still higher than deep learning strategies and the baseline. We could not show a difference in classification efficiency between self-trained and pretrained embeddings.
Discussion: Clinical context, negation, and value-based criteria hindered shallow machine learning approaches, while deep learning strategies could not capture the term diversity due to the small training dataset.
Conclusion: Shallow methods for clinical phenotyping can still outperform deep learning methods in small imbalanced data, even when supported by pretrained embeddings.","natural language processing,data mining,machine learning,deep learning",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,,"HEALTH,COHORT",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://europepmc.org/articles/pmc6798565?pdf=render,
35,Network context matters: graph convolutional network model over social networks improves the detection of unknown HIV infections among young men who have sex with men,26,11,1263-1271,"Xiang Yang,Fujimoto Kayo,Schneider John,Jia Yuxi,Zhi Degui,Tao Cui","Xiang Y,Fujimoto K,Schneider J,Jia YX,Zhi DG,Tao C",Tao C,10.1093/jamia/ocz070,University of Texas System,"Objective: HIV infection risk can be estimated based on not only individual features but also social network information. However, there have been insufficient studies using n machine learning methods that can maximize the utility of such information. Leveraging a state-of-the-art network topology modeling method, graph convolutional networks (GCN), our main objective was to include network information for the task of detecting previously unknown HIV infections.
Materials and Methods: We used multiple social network data (peer referral, social, sex partners, and affiliation with social and health venues) that include 378 young men who had sex with men in Houston, TX, collected between 2014 and 2016. Due to the limited sample size, an ensemble approach was engaged by integrating GCN for modeling information flow and statistical machine learning methods, including random forest and logistic regression, to efficiently model sparse features in individual nodes.
Results: Modeling network information using GCN effectively increased the prediction of HIV status in the social network. The ensemble approach achieved 96.6% on accuracy and 94.6% on F1 measure, which outperformed the baseline methods (GCN, logistic regression, and random forest: 79.0%, 90.5%, 94.4% on accuracy, respectively; and 57.7%, 80.2%, 90.4% on F1). In the networks with missing HIV status, the ensemble also produced promising results.
Conclusion: Network context is a necessary component in modeling infectious disease transmissions such as HIV. GCN, when combined with traditional machine learning approaches, achieved promising performance in detecting previously unknown HIV infections, which may provide a useful tool for combatting the HIV epidemic.","HIV,epidemiology,machine learning,graph convolutional networks,social networks",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"RISK,NETWORKS,HEALTH",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6798573,
36,Toward a clinical text encoder: pretraining for clinical natural language processing with applications to substance misuse,26,11,1272-1278,"Dligach Dmitriy,Afshar Majid,Miller Timothy","Dligach D,Afshar M,Miller T",Dligach D,10.1093/jamia/ocz072,Loyola University Chicago,"Objective: Our objective is to develop algorithms for encoding clinical text into representations that can be used for a variety of phenotyping tasks.
Materials and Methods: Obtaining large datasets to take advantage of highly expressive deep learning methods is difficult in clinical natural language processing (NLP). We address this difficulty by pretraining a clinical text encoder on billing code data, which is typically available in abundance. We explore several neural encoder architectures and deploy the text representations obtained from these encoders in the context of clinical text classification tasks. While our ultimate goal is learning a universal clinical text encoder, we also experiment with training a phenotype-specific encoder. A universal encoder would be more practical, but a phenotype-specific encoder could perform better for a specific task.
Results: We successfully train several clinical text encoders, establish a new state-of-the-art on comorbidity data, and observe good performance gains on substance misuse data.
Discussion: We find that pretraining using billing codes is a promising research direction. The representations generated by this type of pretraining have universal properties, as they are highly beneficial for many phenotyping tasks. Phenotype-specific pretraining is a viable route for trading the generality of the pretrained encoder for better performance on a specific phenotyping task.
Conclusions: We successfully applied our approach to many phenotyping tasks. We conclude by discussing potential limitations of our approach.","natural language processing,biomedical informatics,phenotyping",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://europepmc.org/articles/pmc6798566?pdf=render,
37,ML-Net: multi-label classification of biomedical texts with deep neural networks,26,11,1279-1285,"Du Jingcheng,Chen Qingyu,Peng Yifan,Xiang Yang,Tao Cui,Lu Zhiyong","Du JC,Chen QY,Peng YF,Xiang Y,Tao C,Lu ZY",Lu ZY,10.1093/jamia/ocz085,National Institutes of Health (NIH) - USA,"Objective: In multi-label text classification, each textual document is assigned 1 or more labels. As an important task that has broad applications in biomedicine, a number of different computational methods have been proposed. Many of these methods, however, have only modest accuracy or efficiency and limited success in practical use. We propose ML-Net, a novel end-to-end deep learning framework, for multi-label classification of biomedical texts.
Materials and Methods: ML-Net combines a label prediction network with an automated label count prediction mechanism to provide an optimal set of labels. This is accomplished by leveraging both the predicted confidence score of each label and the deep contextual information (modeled by ELMo) in the target document. We evaluate ML-Net on 3 independent corpora in 2 text genres: biomedical literature and clinical notes. For evaluation, we use example-based measures, such as precision, recall, and the F measure. We also compare ML-Net with several competitive machine learning and deep learning baseline models.
Results: Our benchmarking results show that ML-Net compares favorably to state-of-the-art methods in multi-label classification of biomedical text. ML-Net is also shown to be robust when evaluated on different text genres in biomedicine.
Conclusion: ML-Net is able to accuractely represent biomedical document context and dynamically estimate the label count in a more systematic and accurate manner. Unlike traditional machine learning methods, ML-Net does not require human effort for feature engineering and is a highly efficient and scalable approach to tasks with a large set of labels, so there is no need to build individual classifiers for each separate label.","multi-label text classification,biomedical text,deep neural network,biomedical literacutre,clinical notes",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,HALLMARKS,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,http://arxiv.org/pdf/1811.05475,
38,CAESNet: Convolutional AutoEncoder based Semi-supervised Network for improving multiclass classification of endomicroscopic images,26,11,1286-1296,"Tong Li,Wu Hang,Wang May D.","Tong L,Wu H,Wang MD",Wang MD,10.1093/jamia/ocz089,University System of Georgia,"Objective: This article presents a novel method of semisupervised learning using convolutional autoencoders for optical endomicroscopic images. Optical endomicroscopy (OE) is a newly emerged biomedical imaging modality that can support real-time clinical decisions for the grade of dysplasia. To enable real-time decision making, computer-aided diagnosis (CAD) is essential for its high speed and objectivity. However, traditional supervised CAD requires a large amount of training data. Compared with the limited number of labeled images, we can collect a larger number of unlabeled images. To utilize these unlabeled images, we have developed a Convolutional AutoEncoder based Semi-supervised Network (CAESNet) for improving the classification performance.
Materials and Methods: We applied our method to an OE dataset collected from patients undergoing endoscope-based confocal laser endomicroscopy procedures for Barrett's esophagus at Emory Hospital, which consists of 429 labeled images and 2826 unlabeled images. Our CAESNet consists of an encoder with 5 convolutional layers, a decoder with 5 transposed convolutional layers, and a classification network with 2 fully connected layers and a softmax layer. In the unsupervised stage, we first update the encoder and decoder with both labeled and unlabeled images to learn an efficient feature representation. In the supervised stage, we further update the encoder and the classification network with only labeled images for multiclass classification of the OE images.
Results: Our proposed semisupervised method CAESNet achieves the best average performance for multiclass classification of OE images, which surpasses the performance of supervised methods including standard convolutional networks and convolutional autoencoder network.
Conclusions: Our semisupervised CAESNet can efficiently utilize the unlabeled OE images, which improves the diagnosis and decision making for patients with Barrett's esophagus.","endomicroscopy,Barrett's esophagus,semisupervised learning,convolutional autoencoders",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"CONFOCAL,LASER,ENDOMICROSCOPY,COMPUTER-AIDED,DIAGNOSIS,BARRETTS-ESOPHAGUS,SURVEILLANCE,MULTICENTER,DISEASE",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://europepmc.org/articles/pmc6798571?pdf=render,
39,Enhancing clinical concept extraction with contextual embeddings,26,11,1297-1304,"Si Yuqi,Wang Jingqi,Xu Hua,Roberts Kirk","Si YQ,Wang JQ,Xu H,Roberts K",Roberts K,10.1093/jamia/ocz096,University of Texas System,"Objective: Neural network-based representations (""embeddings"") have dramatically advanced natural language processing (NLP) tasks, including clinical NLP tasks such as concept extraction. Recently, however, more advanced embedding methods and representations (eg, ELMo, BERT) have further pushed the state of the art in NLP, yet there are no common best practices for how to integrate these representations into clinical tasks. The purpose of this study, then, is to explore the space of possible options in utilizing these new models for clinical concept extraction, including comparing these to traditional word embedding methods (word2vec, GloVe, fastText).
Materials and Methods: Both off-the-shelf, open-domain embeddings and pretrained clinical embeddings from MIMIC-III (Medical Information Mart for Intensive Care III) are evaluated. We explore a battery of embedding methods consisting of traditional word embeddings and contextual embeddings and compare these on 4 concept extraction corpora: i2b2 2010, i2b2 2012, SemEval 2014, and SemEval 2015. We also analyze the impact of the pretraining time of a large language model like ELMo or BERT on the extraction performance. Last, we present an intuitive way to understand the semantic information encoded by contextual embeddings.
Results: Contextual embeddings pretrained on a large clinical corpus achieves new state-of-the-art performances across all concept extraction tasks. The best-performing model outperforms all state-of-the-art methods with respective F1-measures of 90.25, 93.18 (partial), 80.74, and 81.65.
Conclusions: We demonstrate the potential of contextual embeddings through the state-of-the-art performance these methods achieve on clinical concept extraction. Additionally, we demonstrate that contextual embeddings encode valuable semantic information not accounted for in traditional word representations.","clinical concept extraction,contextual embeddings,language model",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"INFORMATION,EXTRACTION,WORD,EMBEDDINGS",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6798561,
40,Cost-aware active learning for named entity recognition in clinical text,26,11,1314-1322,"Wei Qiang,Chen Yukun,Salimi Mandana,Denny Joshua C.,Mei Qiaozhu,Lasko Thomas A.,Chen Qingxia,Wu Stephen,Franklin Amy,Cohen Trevor","Wei Q,Chen YK,Salimi M,Denny JC,Mei QZ,Lasko TA,Chen QX,Wu S,Franklin A,Cohen T",Xu H,10.1093/jamia/ocz102,University of Texas System,"Objective: Active Learning (AL) attempts to reduce annotation cost (ie, time) by selecting the most informative examples for annotation. Most approaches tacitly (and unrealistically) assume that the cost for annotating each sample is identical. This study introduces a cost-aware AL method, which simultaneously models both the annotation cost and the informativeness of the samples and evaluates both via simulation and user studies.
Materials and Methods: We designed a novel, cost-aware AL algorithm (Cost-CAUSE) for annotating clinical named entities; we first utilized lexical and syntactic features to estimate annotation cost, then we incorporated this cost measure into an existing AL algorithm. Using the 2010 i2b2/VA data set, we then conducted a simulation study comparing Cost-CAUSE with noncost-aware AL methods, and a user study comparing Cost-CAUSE with passive learning.
Results: Our cost model fit empirical annotation data well, and Cost-CAUSE increased the simulation area under the learning curve (ALC) scores by up to 5.6% and 4.9%, compared with random sampling and alternate AL methods. Moreover, in a user annotation task, Cost-CAUSE outperformed passive learning on the ALC score and reduced annotation time by 20.5%-30.2%.
Discussion: Although AL has proven effective in simulations, our user study shows that a real-world environment is far more complex. Other factors have a noticeable effect on the AL method, such as the annotation accuracy of users, the tiredness of users, and even the physical and mental condition of users.
Conclusion: Cost-CAUSE saves significant annotation cost compared to random sampling.","natural language processing,active learning,electronic health records,named entity recognition,user study",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://europepmc.org/articles/pmc6798575?pdf=render,
41,"Development of a global infectious disease activity database using natural language processing, machine learning, and human expertise",26,11,1355-1359,"Feldman Joshua,Thomas-Bachli Andrea,Forsyth Jack,Patel Zaki Hasnain,Khan Kamran","Feldman J,Thomas-Bachli A,Forsyth J,Patel ZH,Khan K",Thomas-Bachli A,10.1093/jamia/ocz112,"209 Victoria St, Toronto, ON M5B 1T8, Canada.","Objective: We assessed whether machine learning can be utilized to allow efficient extraction of infectious disease activity information from online media reports.
Materials and Methods: We curated a data set of labeled media reports (n=8322) indicating which articles contain updates about disease activity. We trained a classifier on this data set. To validate our system, we used a held out test set and compared our articles to the World Health Organization Disease Outbreak News reports.
Results: Our classifier achieved a recall and precision of 88.8% and 86.1%, respectively. The overall surveillance system detected 94% of the outbreaks identified by the WHO covered by online media (89%) and did so 43.4 (IQR: 9.5-61) days earlier on average.
Discussion: We constructed a global real-time disease activity database surveilling 114 illnesses and syndromes. We must further assess our system for bias, representativeness, granularity, and accuracy.
Conclusion: Machine learning, natural language processing, and human expertise can be used to efficiently identify disease activity from digital media reports.","machine learning,public health surveillance,communicable diseases,internet,health information systems",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"SURVEILLANCE,INTELLIGENCE",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647217,
42,Development and application of a high throughput natural language processing architecture to convert all clinical documents in a clinical data warehouse into standardized medical vocabularies,26,11,1364-1369,"Afshar Majid,Dligach Dmitriy,Sharma Brihat,Cai Xiaoyuan,Boyda Jason,Birch Steven,Valdez Daniel,Zelisko Suzan,Joyce Cara,Modave Francois","Afshar M,Dligach D,Sharma B,Cai XY,Boyda J,Birch S,Valdez D,Zelisko S,Joyce C,Modave F",Afshar M,10.1093/jamia/ocz068,Loyola University Chicago,"Objective: Natural language processing (NLP) engines such as the clinical Text Analysis and Knowledge Extraction System are a solution for processing notes for research, but optimizing their performance for a clinical data warehouse remains a challenge. We aim to develop a high throughput NLP architecture using the clinical Text Analysis and Knowledge Extraction System and present a predictive model use case.
Materials and Methods: The CDW was comprised of 1 103 038 patients across 10 years. The architecture was constructed using the Hadoop data repository for source data and 3 large-scale symmetric processing servers for NLP. Each named entity mention in a clinical document was mapped to the Unified Medical Language System concept unique identifier (CUI).
Results: The NLP architecture processed 83 867 802 clinical documents in 13.33 days and produced 37 721 886 606 CUIs across 8 standardized medical vocabularies. Performance of the architecture exceeded 500 000 documents per hour across 30 parallel instances of the clinical Text Analysis and Knowledge Extraction System including 10 instances dedicated to documents greater than 20 000 bytes. In a use-case example for predicting 30-day hospital readmission, a CUI-based model had similar discrimination to n-grams with an area under the curve receiver operating characteristic of 0.75 (95% CI, 0.74-0.76).
Discussion and Conclusion: Our health system's high throughput NLP architecture may serve as a benchmark for large-scale clinical research using a CUI-based approach.","natural language processing,unstructured data,clinical text and knowledge extraction system,data architecture,unified medical language system",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"BIG,DATA,SYSTEM,EXTRACTION,TEXT,NLP",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647210,
43,Identification of Bicycling Periods Using the MicroPEM Personal Exposure Monitor,19,21,,"Chew Robert,Thornburg Jonathan,Jack Darby,Smith Cara,Yang Qiang,Chillrud Steven","Chew R,Thornburg J,Jack D,Smith C,Yang Q,Chillrud S",Chew R,10.3390/s19214613,Research Triangle Institute,"Exposure assessment studies are the primary means for understanding links between exposure to chemical and physical agents and adverse health effects. Recently, researchers have proposed using wearable monitors during exposure assessment studies to obtain higher fidelity readings of exposures actually experienced by subjects. However, limited research has been conducted to link a wearer's actions to periods of exposure, a necessary step for estimating inhaled dosage. To aid researchers in these settings, we developed a machine learning model for identifying periods of bicycling activity using passively collected data from the RTI MicroPEM wearable exposure monitor, a lightweight device capable of continuously sampling both air pollution levels and accelerometry parameters. Our best performing model identifies biking activity with a mean leave-one-session-out (LOSO) cross-validation F1 score of 0.832 (unweighted) and 0.979 (weighted). Accelerometer derived features contributed greatly to the model performance, as well as temporal smoothing of the predicted activities. Additionally, we found competitive activity recognition can occur with even relatively low sampling rates, suggesting suitability for exposure assessment studies where continuous data collection for long periods (without recharge) are needed to capture realistic daily routines and exposures.","human activity recognition,machine learning,wearable sensors,exposure assessment,air pollution",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"ACTIVITY,RECOGNITION,AIR-POLLUTION,TRENDS,URBAN",SENSORS,https://www.mdpi.com/1424-8220/19/21/4613/pdf,
44,Learning to Detect Cracks on Damaged Concrete Surfaces Using Two-Branched Convolutional Neural Network,19,21,,"Lee Jieun,Kim Hee-Sun,Kim Nayoung,Ryu Eun-Mi,Kang Je-Won","Lee J,Kim HS,Kim N,Ryu EM,Kang JW",Kang JW,10.3390/s19214796,Ewha Womans University,"Image sensors are widely used for detecting cracks on concrete surfaces to help proactive and timely management of concrete structures. However, it is a challenging task to reliably detect cracks on damaged surfaces in the real world due to noise and undesired artifacts. In this paper, we propose an autonomous crack detection algorithm based on convolutional neural network (CNN) to solve the problem. To this aim, the proposed algorithm uses a two-branched CNN architecture, consisting of sub-networks named a crack-component-aware (CCA) network and a crack-region-aware (CRA) network. The CCA network is to learn gradient component regarding cracks, and the CRA network is to learn a region-of-interest by distinguishing critical cracks and noise such as scratches. Specifically, the two sub-networks are built on convolution-deconvolution CNN architectures, but also they are comprised of different functional components to achieve their own goals efficiently. The two sub-networks are trained in an end-to-end to jointly optimize parameters and produce the final output of localizing important cracks. Various crack image samples and learning methods are used for efficiently training the proposed network. In the experimental results, the proposed algorithm provides better performance in the crack detection than the conventional algorithms.","deep learning,crack detection,convolutional neural network,edge detection,fire-damaged concrete,image processing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"IMAGES,SYSTEM",SENSORS,https://europepmc.org/articles/pmc6864448?pdf=render,
45,Positive and Negative Evidence Accumulation Clustering for Sensor Fusion: An Application to Heartbeat Clustering,19,21,,"Marquez David G.,Felix Paulo,Garcia Constantino A.,Tejedor Javier,Fred Ana L. N.,Otero Abraham","Marquez DG,Felix P,Garcia CA,Tejedor J,Fred ALN,Otero A",Marquez DG,10.3390/s19214635,San Pablo CEU University,"In this work, a new clustering algorithm especially geared towards merging data arising from multiple sensors is presented. The algorithm, called PN-EAC, is based on the ensemble clustering paradigm and it introduces the novel concept of negative evidence. PN-EAC combines both positive evidence, to gather information about the elements that should be grouped together in the final partition, and negative evidence, which has information about the elements that should not be grouped together. The algorithm has been validated in the electrocardiographic domain for heartbeat clustering, extracting positive evidence from the heartbeat morphology and negative evidence from the distances between heartbeats. The best result obtained on the MIT-BIH Arrhythmia database yielded an error of 1.44%. In the St. Petersburg Institute of Cardiological Technics 12-Lead Arrhythmia Database database (INCARTDB), an error of 0.601% was obtained when using two electrocardiogram (ECG) leads. When increasing the number of leads to 4, 6, 8, 10 and 12, the algorithm obtains better results (statistically significant) than with the previous number of leads, reaching an error of 0.338%. To the best of our knowledge, this is the first clustering algorithm that is able to process simultaneously any number of ECG leads. Our results support the use of PN-EAC to combine different sources of information and the value of the negative evidence.","sensor fusion,clustering,evidence accumulation,fusion techniques,machine learning,ECG,multilead clustering,heartbeat clustering,multimodal clustering",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,"BEAT,CLASSIFICATION,HERMITE,FUNCTIONS,ECG,MORPHOLOGY,ENSEMBLES,ALGORITHMS,RECOGNITION,COMPLEXES,IMPROVE",SENSORS,https://europepmc.org/articles/pmc6864688?pdf=render,
46,Heartbeat Sound Signal Classification Using Deep Learning,19,21,,"Raza Ali,Mehmood Arif,Ullah Saleem,Ahmad Maqsood,Choi Gyu Sang,On Byung-Won","Raza A,Mehmood A,Ullah S,Ahmad M,Choi GS,On BW",Ullah S,10.3390/s19214819,"Khwaja Fareed Univ Engn & Informat Technol, Dept Comp Sci, Rahim Yar Khan 64200, Punjab, Pakistan.","Presently, most deaths are caused by heart disease. To overcome this situation, heartbeat sound analysis is a convenient way to diagnose heart disease. Heartbeat sound classification is still a challenging problem in heart sound segmentation and feature extraction. Dataset-B applied in this study that contains three categories Normal, Murmur and Extra-systole heartbeat sound. In the purposed framework, we remove the noise from the heartbeat sound signal by applying the band filter, After that we fixed the size of the sampling rate of each sound signal. Then we applied down-sampling techniques to get more discriminant features and reduce the dimension of the frame rate. However, it does not affect the results and also decreases the computational power and time. Then we applied a purposed model Recurrent Neural Network (RNN) that is based on Long Short-Term Memory (LSTM), Dropout, Dense and Softmax layer. As a result, the purposed method is more competitive compared to other methods.","heart sound,classification,deep learning,RNN",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"NEURAL-NETWORKS,SEGMENTATION",SENSORS,https://europepmc.org/articles/pmc6864449?pdf=render,
47,Optimization of an artificial neural network to estimate laser ablation efficiency,29,11,,Yildiz Fikret,Yildiz F,Yildiz F,10.1088/1555-6611/ab43d9,Hakkari University,"The use of fiber laser in surgery has many advantages due to its small size, efficiency, operation in continuous and pulse mode and easy coupling to fiber optics for various applications. Laser surgery requires very precise control on laser parameters, and imprecision can cause unacceptable damages during operation, particularly in neurosurgical applications. There have been many experimental studies looking to optimize laser parameters to control laser thermal therapy. In this study, we propose an artificial neural network method (ANN) to predict laser ablation damage as a function of laser parameters and temperature. The purpose of this study was to investigate the performance of artificial neural networks to predict the ablation efficiency of a 1940 nm thulium fiber laser on ovine brain tissue. Twelve experimental data were used to train an ANN model. Tissue type (cortical/subcortical), laser mode, laser power, laser energy, time, temperature and temperature change were used as inputs for the ANN and the ablation efficiency (ablated area/total thermally altered area) was the output of the model. Four untrained data were used to validate the ANN prediction ability after finding correlation between the ANN inputs and output. Experimental and predicted data were compared to find the accuracy of the model. Moreover, optimum laser mode (continuous/pulse) selection was also studied. Five different machine learning methods were used for laser mode selection, and the results were compared. Our results showed that prediction for the ablation efficiency of an ANN is lower than 15% and 87.5% classification accuracy was obtained for optimum laser mode selection.","laser ablation,thulium fiber laser,artificial neural network (ANN),machine learning,neurosurgery",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Optics,Physics",,1.157,"EX-VIVO,HEPATOCELLULAR-CARCINOMA,MORPHOLOGICAL,FEATURES,INDUCED,THERMOTHERAPY,RADIOFREQUENCY,ACHIEVEMENT,THERAPY,TUMORS",LASER PHYSICS,,
48,Data interpretation framework integrating machine learning and pattern recognition for self-powered data-driven damage identification with harvested energy variations,86,,136-153,"Salehi Hadi,Biswas Subir,Burgueno Rigoberto","Salehi H,Biswas S,Burgueno R",Burgueno R,10.1016/j.engappai.2019.08.004,"428 S Shaw Lane,Room 3574,Engn Bldg, E Lansing, MI 48824 USA.","Data mining methods have been widely used for structural health monitoring (SHM) and damage identification for analysis of continuous signals. Nonetheless, the applicability and effectiveness of these techniques cannot be guaranteed when dealing with discrete binary and incomplete/missing signals (i.e., not continuous in time). In this paper a novel data interpretation framework for SHM with noisy and incomplete signals, using a through-substrate self-powered sensing technology, is presented within the context of artificial intelligence (AI). AI methods, namely, machine learning and pattern recognition, were integrated within the data interpretation framework developed for use in a practical engineering problem: data-driven SHM of plate-like structures. Finite element simulations on an aircraft stabilizer wing and experimental vibration tests on a dynamically loaded plate were conducted to validate the proposed framework. Machine learning algorithms, including support vector machine, k-nearest neighbor, and artificial neural networks, were integrated within the developed learning framework for performance assessment of the monitored structures. Different levels of harvested energy were considered to evaluate the robustness of the SHM system with respect to such variations. Results demonstrate that the SHM methodology employing the proposed machine learning-based data interpretation framework is efficient and robust for damage detection with incomplete and sparse/missing binary signals, overcoming the notable issue of energy availability for smart damage identification platforms being used in structural/infrastructure and aerospace health monitoring. The present study aims to advance data mining and interpretation techniques in the SHM domain, promoting the practical application of machine learning and pattern recognition with incomplete and missing/sparse signals in smart cities and smart infrastructure monitoring.","Structural health monitoring,Machine learning,Low-rank matrix completion,Pattern recognition,Self-powered sensors,Plate-like structures,Incomplete signals,Energy harvesting",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Automation & Control Systems,Computer Science,Engineering",,5.317,"SUPPORT,VECTOR,MACHINE,GENETIC,ALGORITHM,NEURAL-NETWORKS,IMPACT,DAMAGE,CFRP,PLATES,LOCALIZATION,PARADIGM,SHAPES,SYSTEM",ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE,https://www.sciencedirect.com/science/article/am/pii/S0952197619301897,
49,Prediction of the color change of heat-treated wood during artificial weathering by artificial neural network,77,6,1107-1116,"Tat Thang Nguyen,Thi Hai Van Nguyen,Ji Xiaodi,Yuan Bingnan,Hien Mai Trinh,Khoa Thi Lanh Do,Guo Minghui","Nguyen TT,Nguyen THV,Ji XD,Yuan BN,Trinh HM,Do KTL,Guo MH",Guo MH,10.1007/s00107-019-01449-0,Northeast Forestry University - China,"The purpose of this study was to predict the color change of heat-treated wood during artificial weathering by an artificial neural network (ANN) model. Chemical component analysis was used to analyze the origin of color change of the heat-treated wood. The network included an input layer consisting of three input nodes, namely, the weathering exposure time, heat treatment temperature, and heat-treated wood species, a hidden layer using six neurons and an output layer consisting of one output node, namely heat-treated wood color. A hyperbolic tangent sigmoid transfer function was used in the hidden layer, and the training algorithm was the Levenberg-Marquardt backpropagation. According to the results, the mean absolute percentage errors (MAPE) were 8.17, 9.70, and 9.85% for the prediction of color change (Delta E) for training, validation and testing data sets, respectively. Determination coefficients (R-2) above 0.92 were obtained with the proposed ANN model for all data sets. These results showed that the ANN model can be successfully used for predicting the color change of heat-treated wood during artificial weathering. FTIR results showed that the color change of heat-treated wood during artificial weathering is due to the change in the chemical composition, especially the photodegradation of lignin and wood extractives.","DIMENSIONAL STABILITY,MECHANICAL-PROPERTIES,SURFACE-CHEMISTRY,HIGH-TEMPERATURE,TROPICAL WOODS,PART 1,SOFTWOOD,EXTRACTIVES,BEHAVIOR,SPRUCE",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA","Forestry,Materials Science",,2.164,"DIMENSIONAL,STABILITY,MECHANICAL-PROPERTIES,SURFACE-CHEMISTRY,HIGH-TEMPERATURE,TROPICAL,WOODS,PART,1,SOFTWOOD,EXTRACTIVES,BEHAVIOR,SPRUCE",EUROPEAN JOURNAL OF WOOD AND WOOD PRODUCTS,,
50,Patient-specific reconstruction of volumetric computed tomography images from a single projection view via deep learning,3,11,880-888,"Shen Liyue,Zhao Wei,Xing Lei","Shen LY,Zhao W,Xing L",Xing L,10.1038/s41551-019-0466-4,Stanford University,"Tomographic imaging using penetrating waves generates cross-sectional views of the internal anatomy of a living subject. For artefact-free volumetric imaging, projection views from a large number of angular positions are required. Here we show that a deep-learning model trained to map projection radiographs of a patient to the corresponding 3D anatomy can subsequently generate volumetric tomographic X-ray images of the patient from a single projection view. We demonstrate the feasibility of the approach with upper-abdomen, lung, and head-and-neck computed tomography scans from three patients. Volumetric reconstruction via deep learning could be useful in image-guided interventional procedures such as radiation therapy and needle biopsy, and might help simplify the hardware of tomographic imaging systems.","SPATIAL-RESOLUTION PROPERTIES,3D TUMOR-LOCALIZATION,DIABETIC-RETINOPATHY,NEURAL-NETWORKS,CANCER,VALIDATION,MRI",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Engineering,,26.355,"SPATIAL-RESOLUTION,PROPERTIES,3D,TUMOR-LOCALIZATION,DIABETIC-RETINOPATHY,NEURAL-NETWORKS,CANCER,VALIDATION,MRI",NATURE BIOMEDICAL ENGINEERING,https://europepmc.org/articles/pmc6858583?pdf=render,
51,Rapid Discovery of Ferroelectric Photovoltaic Perovskites and Material Descriptors via Machine Learning,3,11,,"Lu Shuaihua,Zhou Qionghua,Ma Liang,Guo Yilv,Wang Jinlan","Lu SH,Zhou QH,Ma L,Guo Y,Wang JL",Wang JL,10.1002/smtd.201900360,Southeast University - China,"Rapid discovery of novel functional materials is urgent but a tremendous challenge using trial-and-error methods in vast chemical space. Here, a multistep screening scheme is developed by combining high-throughput calculations and machine learning (ML) techniques. Successfully, 151 promising stable ferroelectric photovoltaic (FPV) perovskites with proper bandgap are screened out from 19 841 candidate compositions. Two new descriptors are proposed to describe mixed inorganic perovskites' formability through ML feature engineering. Additionally, phase-transition energy difference is used as a criterion for directly judging whether the compound can expose spontaneous polarization. The ML prediction accuracy of both energy difference and bandgap regressions is over 90% and ML produces comparable results to density functional theory calculations. Moreover, bandgaps of eight selected FPV perovskites are all close to the optimal value of single-junction solar cells. This scheme not only realizes the ML acceleration for targeted multiproperty materials' design and expansion of materials database, but also opens a way for descriptor development.","ferroelectric photovoltaic perovskites,first-principles methods,high-throughput calculations,machine learning",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science",,14.367,"TIN,POLARIZATION,PREDICTION,EFFICIENCY,STABILITY,SEARCH,LIMIT",SMALL METHODS,,
52,Development of a Machine Learning Based Fast Running Model to Determine Rapidly the Process Conditions in Drawing Process,20,1,9-17,"Cho Donghyuk,Lee Youngseog","Cho D,Lee Y",Lee Y,10.1007/s12239-019-0123-7,Chung Ang University,"This study proposes a fast running model that interconnects input and output data for a single-pass cold bar drawing process through the use of Artificial Neural Network (ANN) and automatically generated a large volume of elastic-plastic finite element (FE) analysis results. The prediction accuracy of the FE analysis was verified by comparing the FE analysis with measurements from a drawing experiment. A Python-based script that automatically controls ABAQUS was coded to sequentially produce output data that varies according to the input data, which is a combination of 18 grades of steel and 1,000 process conditions. The ANN was trained using input and output data, and then a nine-dimensional fast running model was developed. The fast running model predicted the values of output variables (drawing force, strain at the center, strain on the surface, accumulated damage at the center, contact pressure, and the fracture (or non-fracture) of the material) in 0.1 second no matter how the mechanical properties of the steels and process conditions change. With this fast running model, engineers in the drawing industry can easily determine or modify the process conditions to improve productivity and product quality even when a grade of steel that has never been employed before is drawn.","Machine learning,ANN,Fast running model,Elastic-plastic FE simulation,Laboratory bar drawing test",Article; Proceedings Paper,"KOREAN SOC AUTOMOTIVE ENGINEERS-KSAE, #1301, PARADISE VENTURE TOWER, 52-GIL 21, TEHERAN-RO, GANGNAM-GU, SEOUL 135-919, SOUTH KOREA","Engineering,Transportation",,1.495,"PREDICTION,FRACTURE",INTERNATIONAL JOURNAL OF AUTOMOTIVE TECHNOLOGY,,
53,Identification and analysis of photometric points on 2D facial images: a machine learning approach in orthodontics,9,5,715-724,"Rao Gururajaprasad Kaggal Lakshmana,Srinivasa Arvind Channarayapatna,Iskandar Yulita Hanum P.,Mokhtar Norehan","Rao GKL,Srinivasa AC,Iskandar YHP,Mokhtar N",Rao GKL,10.1007/s12553-019-00313-8,Universiti Sains Malaysia,"The lack of an effective and automated facial landmark identification tool has prompted us to design and develop a smart machine learning approach. The study aims to address two objectives. The primary objective is to assess the effectiveness and accuracy of algorithmic methodology in identifying and analysing facial landmarks on two dimensional (2D) facial images and the secondary objective is to understand the clinical application of automation in facial landmark identification. The study has utilised 418 facial landmark points and 220 landmark measures from 22 2D facial images of volunteers. The study has used a deep learning algorithm 'You Only Look Once (YOLO)' to determine the accuracy of the developed system and its clinical applications. The system identified 418 landmarks in total with facial recognition being 100%. Of the total 220 landmark measures, the system provided 48 (21.81%) measures in the error range of 0 to 1 mm, 75 (34.09%) measures in the error range of 2 to 3 mm, 92 (41.81%) measures in the error range of 4 to 5 mm followed by 5 (2.2%) measures in the range of 6 mm. The smart and innovative approach provides valuable training and a helpful tool for the students performing the clinical facial analysis. The automated system with its effective and efficient algorithm delivers fast and reliable landmark identification and analysis.","Orthodontic photometric points,Orthodontic facial measures,Frontal facial photography,YOLO,Deep learning,Orthodontics,Smart learning",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Medical Informatics,,,,HEALTH AND TECHNOLOGY,,
54,Application of machine learning techniques to analyze anastomosis integrity after Total gastrectomy for prediction of clinical leakage,9,5,757-763,"Celik Sebahattin,Sohail Ayesha,Ashraf Shaina,Arshad Arooba","Celik S,Sohail A,Ashraf S,Arshad A",Sohail A,10.1007/s12553-019-00334-3,COMSATS University Islamabad (CUI),"Intraoperative testing (IT) is used to confirm the integrity of gastrointestinal anastomosis. Clinical trials are available in the literature to support the fact that methylene blue can identify the leaks, and can thus help in minimizing the postoperative ratio of clinical leaks after total gastrectomy. In the recent literature, machine learning tools have been used very successfully to investigate the hypothesis of such complex clinical trials, where incomplete data is available. In this article, data obtained from a clinical study, is analyzed using machine learning, to verify whether or not the methylene blue test can accurately identify the leaks and to predict future outcomes. Furthermore, a comparative study based on most robust machine learning solvers is presented in this article to identify the most appropriate machine learning technique(s) for future applications. We have considered the data (over a period starting from Jan 2007 till Dec 2014) based on the total gastrostomies (TG), where methylene blue test was applied. Data was obtained from 198 patients having gastric cancer. Out of 198, 108 cases went through methylene blue test done by a nasojejunal tube while no test was carried out for rest of 90 cases. Intraoperative leakage rate, mortality rate, length of hospitalization and postoperative clinical leakage rate were the measured outcomes. To analyze the data and to predict whether there will be a leak or not, machine learning techniques were applied and the accuracy was compared. The main objective of this research is to predict the clinical leakage after applying methylene blue test on gastric cancer patients. This objective is successfully achieved by implementing six machine learning approaches. Case specific machine learning approaches are discussed to evaluate post clinical leakage rate and radio leakage rate. From our analysis, we have concluded that the prediction of intraoperative leak, post clinical leak and radio leak is possible with the aid of different machine learning techniques. An important conclusion drawn from this study is that a single machine learning technique can not accurately predict different stages of leak, since the accuracy of the technique depends on the specification of clinical data that varies from stage to stage.","Machine learning,Anastomosis,Predicting clinical leak,Intraoperative leakage rate,Forecasting",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Medical Informatics,,,"GASTRIC-CANCER,OUTCOMES",HEALTH AND TECHNOLOGY,,
55,Cervical cancer prognosis using genetic algorithm and adaptive boosting approach,9,5,877-886,Sharma Manoj,Sharma M,Sharma M,10.1007/s12553-019-00375-8,"MRSPTU, Giani Zail Singh Campus Coll Engn & Technol, Dept Elect & Commun Engn, Bathinda 151001, India.","Cervical cancer is fourth main causes of death in women. Cervix is the main origin of cervical cancer. The idea of this research is to explore and propose an efficient and improved prediction method of cervical cancer. Earlier detection and prediction methods/test were very complex, tedious and requires medical and pathological expertise. In this paper, Machine learning approach is used for prediction and detection of cervical cancer. Integrated approach of Genetic Algorithm and Adaptive Boosting is used for performance evaluation for prediction of disease. Genetic algorithm is used as attribute selector to decrease the number of attributes. This not only declines the computational cost but also reduces the number of parameters for diagnosis. Adaptive Boosting is used to improve the performance of classifiers. C 4.5 Decision Tree and Support Vector Machine (SVM) are proposed for prediction of disease. Initially 32 attributes are used for prediction of cervical cancer. The numbers of attributes are reduced with genetic algorithm and further performance enhancement is proposed with adaptive boosting technique. With proposed integrated approach of genetic algorithm and adaptive boosting the improved accuracy lies between 94.17%-94.69%, sensitivity 97.36%-98.90%, specificity 93.37%-94.72% and precision 93%-95.17% for Support Vector Machine Radial Bias Function (SVM RBF), SVM Linear and Decision Tree.","Cervical cancer,Genetic algorithm,SVM RBF,SVM linear,Decision tree",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Medical Informatics,,,"DIFFUSION-WEIGHTED,MRI,DIAGNOSIS",HEALTH AND TECHNOLOGY,,
56,Detection of Hemodynamically Significant Coronary Stenosis: CT Myocardial Perfusion versus Machine Learning CT Fractional Flow Reserve,293,2,305-314,"Li Yuehua,Yu Mengmeng,Dai Xu,Lu Zhigang,Shen Chengxing,Wang Yining,Lu Bin,Zhang Jiayin","Li YH,Yu MM,Dai X,Lu ZG,Shen CX,Wang YN,Lu B,Zhang JY",Zhang JY,10.1148/radiol.2019190098,Shanghai Jiao Tong University,"Background: Direct intraindividual comparison of dynamic CT myocardial perfusion imaging (MPI) and machine learning (ML)-based CT fractional flow reserve (FFR) has not been explored for diagnosing hemodynamically significant coronary artery disease.
Purpose: To investigate the diagnostic performance of dynamic CT MPI and ML-based CT FFR for functional assessment of coronary stenosis.
Materials and Methods: Between January 2, 2017, and October 17, 2018, consecutive participants with stable angina were prospectively enrolled. All participants underwent dynamic CT MPI coronary CT angiography and invasive conventional coronary angiography (CCA) FFR within 2 weeks. Receiver operating characteristic (ROC) curve analysis was used to assess diagnostic performance.
Results: Eighty-six participants (mean age, 67 years +/- 12 [standard deviation]; 67 men) with 157 target vessels were included for final analysis. The mean radiation doses for dynamic CT MPI and coronary CT angiography were 3.6 mSv +/- 1.1 and 2.7 mSv +/- 0.8, respectively. Myocardial blood flow (MBF) was lower in ischemic segments compared with nonischemic segments and reference segments (defined as the territory of vessels without stenosis) (75 mL/100 mL/min +/- 20 vs 148 mL/100 mL/min +/- 22 and 169 mL/100 mL/min +/- 34, respectively, both P < .001). Similarly, CT FFR was also lower for hemodynamically significant lesions than for hemodynamically nonsignificant lesions (0.68 +/- 0.1 vs 0.83 +/- 0.1, respectively, P < .001). MBF had the largest area under the ROC curve (AUC) (using 99 mL/100 mL/min as a cutoff) among all parameters, outperforming ML-based CT FFR (AUC = 0.97 vs 0.85, P < .001). The vessel-based specificity and diagnostic accuracy of MBF were higher than those of ML-based CT FFR (93% vs 68%, P < .001 and 94% vs 78%, respectively, P = .04) whereas the sensitivity of both methods was similar (96% vs 88%, respectively, P = .11).
Conclusion: Dynamic CT myocardial perfusion imaging was able to help accurately evaluate the hemodynamic significance of coronary stenosis using a reduced amount of radiation. In addition, the myocardial blood flow derived from dynamic CT myocardial perfusion imaging outperformed machine learning-based CT fractional flow reserve for identifying lesions causing ischemia. (C) RSNA, 2019","DIAGNOSTIC PERFORMANCE,COMPUTED-TOMOGRAPHY,FUNCTIONAL SEVERITY,BLOOD-FLOW,ANGIOGRAPHY,ACCURACY",Article,"RADIOLOGICAL SOC NORTH AMERICA, 820 JORIE BLVD, OAK BROOK, IL 60523 USA","Radiology, Nuclear Medicine & Medical Imaging",,10.389,"DIAGNOSTIC,PERFORMANCE,COMPUTED-TOMOGRAPHY,FUNCTIONAL,SEVERITY,BLOOD-FLOW,ANGIOGRAPHY,ACCURACY",RADIOLOGY,https://pubs.rsna.org/doi/pdf/10.1148/radiol.2019190098,
57,Data augmentation in dermatology image recognition using machine learning,25,6,815-820,Aggarwal Pushkar,Aggarwal P,Aggarwal P,10.1111/srt.12726,University of Cincinnati,"Background Each year in the United States, over 80 million people are affected by acne, atopic dermatitis, rosacea, psoriasis, and impetigo. Artificial intelligence and machine learning could prove to be a good tool for assisting in the diagnosis of dermatological conditions. The objective of this study was to evaluate the use of data augmentation in machine learning image recognition of five dermatological disease manifestations-acne, atopic dermatitis, impetigo, psoriasis, and rosacea. Materials and Methods Open-source dermatological images were gathered and used to retrain TensorFlow Inception version-3. Retraining was done twice-once with and once without data augmentation. Both models were tested with the same images, and R software was used to perform statistical analysis. Results The average of each of the statistical measures (sensitivity, specificity, PPV, NPN, MCC, and F1 Score) increased when data augmentation was added to the model. In particular, the average Matthews correlation coefficient increased by 7.7%. Each of the five dermatological manifestations had an increase in area under the curve (AUC) after data augmentation with the average increase in AUC of 0.132 and a standard deviation of 0.033. Atopic dermatitis had the highest increase in AUC of 0.18. With data augmentation, the lowest AUC was 0.87 for psoriasis and the highest was 0.97 for acne, indicating that the model performs well. Conclusion With a deep learning-based approach, it is possible to differentiate dermatological images with appreciable MCC, F1 score, and AUC. Further, data augmentation can be used to increase the model's accuracy by a significant amount.","acne,artificial intelligence,atopic dermatitis,image recognition,impetigo,psoriasis,rosacea",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Dermatology,,2.309,,SKIN RESEARCH AND TECHNOLOGY,,
58,Machine Learning-based Analysis of Rectal Cancer MRI Radiomics for Prediction of Metachronous Liver Metastasis,26,11,1495-1504,"Liang Meng,Cai Zhengting,Zhang Hongmei,Huang Chencui,Meng Yankai,Zhao Li,Li Dengfeng,Ma Xiaohong,Zhao Xinming","Liang M,Cai ZT,Zhang HM,Huang CC,Meng YK,Zhao L,Li DF,Ma XH,Zhao XM",Ma XH; Zhao XM,10.1016/j.acra.2018.12.019,Chinese Academy of Medical Sciences - Peking Union Medical College,"Rationale and Objectives: To use machine learning-based magnetic resonance imaging radiomics to predict metachronous liver metastases (MLM) in patients with rectal cancer.
Materials and Methods: This study retrospectively analyzed 108 patients with rectal cancer (54 in MLM group and 54 in nonmetastases group). Feature selection were performed in the radiomic feature sets extracted from images of T2-weighted image (T2WI) and venous phase (VP) sequence respectively, and the combining feature set with 2058 radiomic features incorporating two sequences with the least absolute shrinkage and selection operator method. Five-fold cross-validation and two machine learning algorithms (support vector machine [SVM]; logistic regression [LR]) were utilized for predictive model constructing. The diagnostic performance of the models was evaluated by receiver operating characteristic curves with indicators of accuracy, sensitivity, specificity and area under the curve, and compared by DeLong test.
Results: Five, 8, and 22 optimal features were selected from 1029 T2WI, 1029 VP, and 2058 combining features, respectively. Four-group models were constructed using the five T2WI features (Model(T2)), the 8 VP features (Model(VP)), the combined 13 optimal features (Model(com-bined)), and the 22 optimal features selected from 2058 features (Model(optimal)). In Model(VP), the LR was superior to the SVM algorithm (P = 0.0303). The Model(optimal) using LR algorithm showed the best prediction performance (P = 0.0019-0.0081) with accuracy, sensitivity, specificity, and area under the curve of 0.80, 0.83, 0.76, and 0.87, respectively.
Conclusion: Radiomics models based on baseline rectal magnetic resonance imaging has high potential for MLM prediction, especially the Model(optimal) using LR algorithm. Moreover, except for Model(VP), the LR was not superior to the SVM algorithm for model construction.","Machine learning,Radiomics,Magnetic resonance imaging,Rectal cancer,Liver metastasis",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.751,"CT,TEXTURE,ANALYSIS,LYMPH-NODE,METASTASIS,COLORECTAL-CANCER,PREOPERATIVE,PREDICTION,TUMOR,PROGRESSION,CHEMORADIOTHERAPY,CHEMORADIATION,SIGNATURE,CARCINOMA,RADIATION",ACADEMIC RADIOLOGY,,
59,,9,11,10192-10211,"Timoshenko Janis,Frenkel Anatoly I.","Timoshenko J,Frenkel AI",Timoshenko J,10.1021/acscatal.9b03599,Max Planck Society,"The rapid growth of methods emerging in the past decade for synthesis of ""designer"" catalysts-ranging from the size and shape-selected nanoparticles to mass-selected clusters, to precisely engineered bimetallic surfaces, to single site and pair site catalysts-has opened opportunities for tailoring the catalyst structure for the desired activity and selectivity. It has also sharpened the need for developing approaches to the operando characterization, ones that identify the catalytic active sites and follow their evolutions in reaction conditions. Commonly used methods for determination of the activity descriptors in the nanocatalysts, based on the correlation between the changes in catalyst performance and evolution of its structural and electronic properties, are hampered by the paucity of experimental techniques that can detect such properties with high accuracy and in reaction conditions. Out of many such techniques, X-ray absorption spectroscopy (XAS) stands out as an element-specific method that is very sensitive to the local geometric and electronic properties of the metal atoms and their surroundings and, therefore, is able to track catalyst structure modifications in operando conditions. Despite the vast amount of structure-specific information (such as, e.g., the charge states and radial distribution function of neighbors of selected atomic species) stored in the XAS data of catalysts, extracting it from the spectra is challenging, especially in the conditions of low metal weight loading, nanoscale dimensions, heterogeneous size and composition distributions, and harsh reaction environment. In this Perspective, we discuss the recent developments in XAS data analysis achieved by employing supervised and unsupervised machine learning (ML) methods for structural characterization of catalysts. By benefiting from the sensitivity of ML methods to subtle variations in experimental data, a previously ""hidden"" relationship between the X-ray absorption spectrum and descriptors of material's structure and/or composition can be found, as illustrated on representative examples of mono-, hetero-, and nonmetallic catalysts. In the case of supervised ML, the experimental spectra can be rapidly ""inverted"", and the structure of the catalyst can be tracked in real time and in reaction conditions. Emerging opportunities for catalysis research that the ML methods enable, such as high-throughput data analysis, and their applications to other experimental probes of catalyst structure are discussed.","X-ray absorption spectroscopy,heterogeneous catalysis,machine learning,neural networks,principal component analysis,clustering,multivariate curve resolution",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,13.721,"MULTIVARIATE,CURVE,RESOLUTION,IN-SITU,XAS,NEGATIVE,THERMAL-EXPANSION,NEAR-EDGE,STRUCTURE,LOCAL-STRUCTURE,HETEROGENEOUS,CATALYSIS,OPERANDO,SPECTROSCOPY,METAL,NANOPARTICLES,COMPONENT,ANALYSIS,METHANOL,SYNTHESIS",ACS CATALYSIS,https://www.osti.gov/biblio/1595081,
60,Using convolutional neural networks for character verification on integrated circuit components of printed circuit boards,49,11,4022-4032,"Lin Chun-Hui,Wang Shyh-Hau,Lin Cheng-Jian","Lin CH,Wang SH,Lin CJ",Lin CJ,10.1007/s10489-019-01486-5,National Chin-Yi University of Technology,"Manufacturers of printed circuit boards (PCBs) typically use automated optical inspection (AOI) machines to test their PCBs. However, AOI machines employ conventional image-processing methods. If the integrated circuit (IC) components are not identical to the golden samples, then the AOI machine registers those IC components as flaws. Conventional image-processing methods cause misjudgments and increase the cost of manual reviews. Character-verification and image-classification systems are proposed in this paper for detecting misplaced, missing, and reversed-polarity parts. The regions of IC components can be identified on PCBs by using the contour border-detection method. Through the proposed convolutional neural network (CNN) structure and refinement mechanism, the characters can be successfully recognized. The image-classification system was applied only to images with blurry characters. Different CNN learning structures were used in both systems, and the refinement mechanism was used in both systems to improve the results. The proposed character-verification and image-classification methods achieved 98.84% and 99.48% passing rates, and the amount of required training time was less than that of other methods, demonstrating the proposed methods' greater effectiveness.","Printed circuit board,Convolutional neural networks,Component testing,Contour detection,Deep learning",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,4.602,"RECOGNITION,IMAGES",APPLIED INTELLIGENCE,,
61,Differentiation of renal angiomyolipoma without visible fat from renal cell carcinoma by machine learning based on whole-tumor computed tomography texture features,60,11,1543-1552,"Cui En-Ming,Lin Fan,Li Qing,Li Rong-Gang,Chen Xiang-Meng,Liu Zhuang-Sheng,Long Wan-Sheng","Cui EM,Lin F,Li Q,Li RG,Chen XM,Liu ZS,Long WS",Long WS,10.1177/0284185119830282,Sun Yat Sen University,"Background Morphological findings showed poor accuracy in differentiating angiomyolipoma without visible fat (AMLwvf) from renal cell carcinoma (RCC). Purpose To determine the performance of a machine learning classifier in differentiating AMLwvf from different subtypes of RCC based on whole-tumor slices of CT images. Material and Methods In this retrospective study, 171 pathologically proven renal masses were collected from a single institution. Texture features were extracted from whole-tumor images in three phases including the pre-contrast (PCP), corticomedullary (CMP), and nephrographic (NP) phases. A support vector machine with the recursive feature elimination method based on fivefold cross-validation (SVM-RFECV) with the synthetic minority oversampling technique (SMOTE) was utilized to establish classifiers for differentiating AMLwvf from all subtypes of RCC (all-RCC), clear cell RCC (ccRCC), and non-ccRCC. The performances of the classifiers based on three-phase and single-phase images were compared with each other and morphological interpretations. Results A machine learning classifier achieved the best performance in differentiating AMLwvf from all-RCC, ccRCC, and non-ccRCC. The performance of the best machine learning classifier for differentiating AMLwvf from all-RCC (area under the curve [AUC] = 0.96) and ccRCC (AUC = 0.97) was higher than that for differentiating AMLwvf from non-ccRCC (AUC = 0.89); morphological interpretations achieved lower performance for differentiating AMLwvf from all-RCC (AUC = 0.67), ccRCC (AUC = 0.68), and non-ccRCC (AUC = 0.64). Conclusion Machine learning can be a useful non-invasive technique for differentiating AMLwvf from all-RCC, ccRCC, and non-ccRCC, and it can be more accurate than morphological interpretation by radiologists.","Renal cell carcinoma,angiomyolipoma,computed tomography (CT),machine learning",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Radiology, Nuclear Medicine & Medical Imaging",,1.92,"MINIMAL,FAT,MASSES,DIFFERENTIATION,POOR,ANGIOMYOLIPOMA,PARTIAL,NEPHRECTOMY,IMAGING,FEATURES,UNENHANCED,CT,CLASSIFICATION,DIAGNOSIS,IMAGES,HETEROGENEITY",ACTA RADIOLOGICA,,
62,A semi-automatic metadata extraction model and method for video-based e-learning contents,24,6,3243-3268,"Pal Saurabh,Pramanik Pijush Kanti Dutta,Majumdar Tripti,Choudhury Prasenjit","Pal S,Pramanik PKD,Majumdar T,Choudhury P",Pramanik PKD,10.1007/s10639-019-09926-y,National Institute of Technology (NIT System),"Video-based learning offers a learner a self-paced, lucid, memorizable, and a flexible way of learning. The availability of abundant educational video materials on the web has certainly abetted an individual's learning means. But the lack of necessary information about the videos makes it difficult for the learner to search and select the exact video as per his/her requirement and suitability in terms of the learner's learning capability and the material's relevancy, difficulty level, etc. Educational video recommendation systems also suffer from a similar problem. Extracting the required metadata, by different means, from the learning videos is a plausible solution. Despite the credible research efforts on video metadata extraction, the problem of educational video metadata extraction has been overlooked. This paper proposes a comprehensive approach to extract educational metadata from a learning video. A semiautomatic mechanism that includes manual and computational approaches is introduced for metadata extraction and to evaluate the values of these metadata. Along with identifying a set of specific metadata attributes from IEEE LOM, few additional attributes are suggested which are imperative to assess the suitability of a video-based learning object in terms of the personalized preference and suitability of a learner. The test results are validated by comparing with the manually extracted metadata by experts, on the same videos. The outcome establishes the promising effectiveness of the approach.","Video metadata extraction,Video-based learning,Metadata,IEEE LOM,Speech-to-text conversion,Educational recommendation system",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Education & Educational Research,,,,EDUCATION AND INFORMATION TECHNOLOGIES,,
63,ADDITIVE MANUFACTURED TOOLSET PARTS,55,6,14-35,"Abdi Frank,Tam Clement,Anderson Stephen,Moazami Nirna,Nikbin Kamran,Godines Cody,Tandon Gyaneswar,Harik Vasyl,Miraj Rashid","Abdi F,Tam C,Anderson S,Moazami N,Nikbin K,Godines C,Tandon G,Harik V,Miraj R",Abdi F,,"AlphaSTAR Corp, Long Beach, CA 90804 USA.","Additive Manufacturing (AM) achieves significant fabrication cost savings and, enables complex 4 eometries that are otherwise impossible to fabricate using conventional manufacturing processes. 3D-printed parts produced by Laser Power Bed Fusion (LPBF) may suffer from: (i) defects (invisible and visible), (ii) net-shape warpage, (iii) high residual stress, (iv) surface roughness and voids, (v) inconsistent density as a function of localized defects, (vi) anisotropic microstructure due to variable cooling rates and (vii) low through-the-thickness interlaminar strength. AM defects (e.g. unfused powder, balling, humping, and keyholing) are affected by variations in power and speed that result in pores, thermal cracks, surface finish and warping. Som closelye of these defects are related to the thermal behavior during printing, in which materials go through multiple stages of heating, melting, and cooling. The objective is to minimize the trial and ' error AM build and replace costly, time consuming X-rays and CT scans by performing real-time quantitative Non-destructive Evaluation (NDE) using integrated sensors, advanced Integrated Computational and Material Engineering (ICME) tools, and machine learning algorithms. This will improve quality, reduce cost and allow quicker qualification of AM parts.",,Article,"SAMPE PUBLISHERS, 1161 PARKVIEW DRIVE, COVINA, CA 91722 USA","Engineering,Materials Science",,0.363,,SAMPE JOURNAL,,
64,Combination of hyperspectral sensing images and chemometrics for measuring tensile strength indices of organic plastic sheeting in the field,,,,"Zou Zhiyong,Wu Xiangwei,Bie Yunbo,Wang Qi,Wang Li,Zou Bing","Zou ZY,Wu XW,Bie YB,Wang Q,Wang L,Zou B",Zou ZY,10.1080/15567036.2019.1683651,Sichuan Agricultural University,"In this paper, hyperspectral sensing image and chemometrics were combined to measure the tensile strength of the organic plastic sheeting of ethylene-vinyl acetate copolymer (EVAC). Three different brands of EVAC sheeting materials were used in the investigation. Spectral data of 978-1676 nm agricultural greenhouse EVAC sheeting were collected by near infrared hyperspectral imager in closed black box. The tensile strength analysis device is used to evaluate the tensile strength indices. The appropriate chemometrics is adopted to build the associated model between the feature spectral data, which expresses the cross-linking attributes of the inner organic molecules, and the tensile strength indices. The cross-validation methods are performed to measure the accuracy and robustness of the training model. The established associated model is then able to evaluate the tensile strength indices of the unknown EVAC sheeting instances. With the leading machine learning algorithm, the corresponding support vector machine regression shows the best detection results, with the percentage of square correlation coefficient () to be 86.63% and the lower root mean square error () to be 1.049. It seems that the strategy, which integrates the hyperspectral sensing technology and chemometrics, can be implemented in real-time measuring of the tensile strength indices of EVAC organic plastic sheeting according to the experimental results.","Infrared,chemometrics,sheeting,tensile strength,cross-linking",Article; Early Access,"TAYLOR & FRANCIS INC, 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA","Energy & Fuels,Engineering,Environmental Sciences & Ecology",,2.406,"ETHYLENE-VINYL,ACETATE,COMBUSTION,MODELS,FILM",ENERGY SOURCES PART A-RECOVERY UTILIZATION AND ENVIRONMENTAL EFFECTS,,
65,Methods of artificial intelligence in vascular medicine Status quo and prospects exemplified by AAAs,24,7,539-547,"Bruder L.,Reutersberg B.,Bassilious M.,Schuettler W.,Eckstein H-H,Gee M. W.","Bruder L,Reutersberg B,Bassilious M,Schuettler W,Eckstein HH,Gee MW",Gee MW,10.1007/s00772-019-00574-7,Technical University of Munich,"Background Artificial intelligence (AI) methods enjoy widespread use in an ever-increasing number of areas. In particular, the use of AI in medicine has seen incremental growth in recent years. Objective To what extent are AI methods being used in vascular medicine at present? What are potential clinical applications? What are the challenges? Material and methods Current applications of AI methods in medicine are presented on the basis of a literature search, existing AI approaches and possibilities for the application in the field of vascular surgery are discussed. By means of a current research topic, namely estimation of the risk of rupture in abdominal aortic aneurysms (AAA), the use and interplay of different AI methods are presented. Results In the field of vascular surgery AI methods are still underrepresented. As evidenced by the example of AAA there is a high potential for application in vascular medicine. Conclusion While promising, the AI methods and models suffer from a lack of interpretability, i.e. they are limited in their ability to provide insights as to the causal mechanisms dictating an observed phenomenon. Moreover, the development of accurate and diagnostically conclusive AI models necessitates large medical datasets. Due to data privacy concerns, the sharing of medical data poses a complex legal problem, particularly in Germany, and represents another barrier for expanding the use of AI methods.","Machine learning,Precision medicine,Digital medicine,Abdominal aortic aneurysm,Rupture risk",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Cardiovascular System & Cardiology,,0.199,"ABDOMINAL,AORTIC-ANEURYSM,WALL,STRESS,SHAPE,PREDICTION,THICKNESS,DIAMETER,RISK",GEFASSCHIRURGIE,,
66,"Improving survival prediction of high-grade glioma via machine learning techniques based on MRI radiomic, genetic and clinical risk factors",120,,,"Tan Yan,Mu Wei,Wang Xiao-chun,Yang Guo-qiang,Gillies Robert James,Zhang Hui","Tan Y,Mu W,Wang XC,Yang GQ,Gillies RJ,Zhang H",Zhang H,10.1016/j.ejrad.2019.07.010,Shanxi Medical University,"Objectives: To develop a radiomic signature to predict overall survival (OS) for high-grade glioma (HGG), and construct a nomogram by combining selected radiomic, genetic and clinical risk factors to further improve the performance of the risk model.
Materials and Methods: 147 cases of HGG with MRI images, genetic data, clinical data were studied, wherein 112 patients were used as training cohort, and 35 patients were as independent test cohort. Radiomics features were extracted from tumor area and peritumoral edema area on CE-T1WI and T2FLAIR images. Association between radiomics signature, genetic, clinical risk factors and OS was explored by Kaplan-Meier survival analysis and log rank test. The multivariate Cox regression analysis was trained with radiomic features along with selected genetic and clinical risk factors, which was presented as a nomogram.
Results: The radiomic signature constructed by 11 radiomics features stratified patients into low- and high-risk groups, and the C-Index for OS prediction was 0.707 and 0.711 in training and test cohorts, respectively. The multivariable Cox regression analysis identified radiomics signature (hazard ratio (HR): 2.18, P = 0.005), IDH (HR: 0.490, P = 0.007) and age (HR: 1.039, P = 0.005) as independent risk factors. A nomogram combining these independent risk factors further improved the performance for OS estimation (C-index = 0.764 and 0.758 in training and test cohorts, respectively).
Conclusion: The radiomics signature is a new prognostic biomarker for HGG. A nomogram incorporating radiomics signature, IDH and age improved the performance of OS estimation, which might be a new complement to the treatment guidelines of glioma.","High grade glioma,Radiomics,Genetic risk factor,Clinical risk factor,Overall survival",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Radiology, Nuclear Medicine & Medical Imaging",,3.539,"CENTRAL-NERVOUS-SYSTEM,GLIOBLASTOMA,ONCOLOGY,NOMOGRAM,OUTCOMES,CANCER",EUROPEAN JOURNAL OF RADIOLOGY,,
67,Consumer Grade Brain Sensing for Emotion Recognition,19,21,9896-9907,"Lakhan Payongkit,Banluesombatkul Nannapas,Changniam Vongsagon,Dhithijaiyratn Ratwade,Leelaarporn Pitshaporn,Boonchieng Ekkarat,Hompoonsup Supanida,Wilaiprasitporn Theerawit","Lakhan P,Banluesombatkul N,Changniam V,Dhithijaiyratn R,Leelaarporn P,Boonchieng E,Hompoonsup S,Wilaiprasitporn T",Wilaiprasitporn T,10.1109/JSEN.2019.2928781,Vidyasirimedhi Institute of Science & Technology,"For several decades, electroencephalography (EEG) has featured as one of the most commonly used tools in emotional state recognition via monitoring of distinctive brain activities. An array of datasets has been generated with the use of diverse emotion-eliciting stimuli and the resulting brainwave responses conventionally captured with high-end EEG devices. However, the applicability of these devices is to some extent limited by practical constraints and may prove difficult to be deployed in highly mobile context omnipresent in everyday happenings. In this study, we evaluate the potential of OpenBCI to bridge this gap by first comparing its performance to research grade EEG system, employing the same algorithms that were applied on benchmark datasets. Moreover, for the purpose of emotion classification, we propose a novel method to facilitate the selection of audio-visual stimuli of high/low valence and arousal. Our setup entailed recruiting 200 healthy volunteers of varying years of age to identify the top 60 affective video clips from a total of 120 candidates through standardized self assessment, genre tags, and unsupervised machine learning. In addition, 43 participants were enrolled to watch the pre-selected clips during which emotional EEG brainwaves and peripheral physiological signals were collected. These recordings were analyzed and extracted features fed into a classification model to predict whether the elicited signals were associated with a high or low level of valence and arousal. As it turned out, our prediction accuracies were decidedly comparable to those of previous studies that utilized more costly EEG amplifiers for data acquisition.","Electroencephalography,Emotion recognition,Biomedical monitoring,Feature extraction,Sensors,Brain,Prediction algorithms,Consumer grade EEG,low-cost EEG,OpenBCI,emotion recognition,affective computing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"LOW-COST,EEG,DATABASE,SIGNALS,MUSIC",IEEE SENSORS JOURNAL,http://arxiv.org/pdf/1810.04582,
68,Robot-Assisted Autism Spectrum Disorder Diagnostic Based on Artificial Reasoning,96,2,267-281,"Ramirez-Duque Andres A.,Frizera-Neto Anselmo,Bastos Teodiano Freire","Ramirez-Duque AA,Frizera-Neto A,Bastos TF",Ramirez-Duque AA,10.1007/s10846-018-00975-y,Universidade Federal do Espirito Santo,"Autism spectrum disorder (ASD) is a neurodevelopmental disorder that affects people from birth, whose symptoms are found in the early developmental period. The ASD diagnosis is usually performed through several sessions of behavioral observation, exhaustive screening, and manual coding behavior. The early detection of ASD signs in naturalistic behavioral observation may be improved through Child-Robot Interaction (CRI) and technological-based tools for automated behavior assessment. Robot-assisted tools using CRI theories have been of interest in intervention for children with Autism Spectrum Disorder (CwASD), elucidating faster and more significant gains from the diagnosis and therapeutic intervention when compared to classical methods. Additionally, using computer vision to analyze child's behaviors and automated video coding to summarize the responses would help clinicians to reduce the delay of ASD diagnosis. In this article, a CRI to enhance the traditional tools for ASD diagnosis is proposed. The system relies on computer vision and an unstructured and scalable network of RGBD sensors built upon Robot Operating System (ROS) and machine learning algorithms for automated face analysis. Also, a proof of concept is presented, with participation of three typically developing (TD) children and three children in risk of suffering from ASD.","Child-Robot interaction,Autism spectrum disorder,Convolutional neural network,Robot reasoning model,Statistical shape modeling",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Robotics",,2.888,"JOINT,ATTENTION,SOCIAL,ROBOT,CHILDREN,TECHNOLOGIES,CONSENSUS,INFANTS,AGENT,PROBO",JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS,,
69,Prediction of the vertical force during FSW of AZ31 magnesium alloy sheets using an artificial neural network-based model,31,11,7211-7226,"D'Orazio Alessio,Forcellese Archimede,Simoncini Michela","D'Orazio A,Forcellese A,Simoncini M",Simoncini M,10.1007/s00521-018-3562-6,Universita Ecampus,"A multivariable empirical model based on an artificial neural network (ANN) was developed in order to predict the vertical force occurring during friction stir welding (FSW) of sheets in AZ31 magnesium alloy. To this purpose, FSW experiments were performed at different values of rotational and welding speeds, and the vertical force versus time curve was recorded during the different stages of the process by means of a dedicated sandwich dynamometer. Such results were used in the training stage of the artificial neural network-based model developed to predict vertical force versus time curves. A multi-layer feed forward ANN, using the back-propagation algorithm, consisting of the input layer with four input parameters (rotational speed, welding speed, rotational speed to welding speed ratio and processing time), two hidden layers with four neurons each, and the output layer with the vertical force as output, was built and trained. The generalization capability of the ANN was tested using a two-step procedure: in the former, the leave-one-out cross-validation method was used whilst, in the latter, curves not included in the training dataset were taken into account. The low values of the relative error and average absolute relative error, and the high correlation coefficients between predicted and experimental results have proven the excellent capability of the artificial neural network in modeling complex shape of the curve and in capturing the effect of the process parameters on the vertical force without a priori knowledge of the complex microstructural and mechanical mechanisms taking place during friction stir welding. Finally, the relationship between vertical force and processing time, at different welding and rotational speeds, was also predicted using the support vector machine algorithm and the results were compared with those given by the ANN-based model.","Magnesium alloy,Friction stir welding,Vertical force,Artificial neural network,Support vector machine",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"MECHANICAL-PROPERTIES,WELDING,PROCESSES,BACK-PROPAGATION,BEAD,GEOMETRY,PARAMETERS,OPTIMIZATION,TOOL,DEFORMATION,JOINTS,BEHAVIOR",NEURAL COMPUTING & APPLICATIONS,,
70,An integrated Taguchi loss function-fuzzy cognitive map-MCGP with utility function approach for supplier selection problem,31,11,7595-7614,"Alizadeh Arash,Yousefi Samuel","Alizadeh A,Yousefi S",Yousefi S,10.1007/s00521-018-3591-1,Urmia University of Technology,"Due to the effects of supplier evaluation and selection problem on the quality of products and companies' business activities, supplier selection is considered as a strategic issue in organizations' development plans. The purpose of this study is to provide an integrated framework for supplier selection problem regarding to the loss of criteria deviation from specification limits, causal relationships between criteria and the preferences of decision makers (DMs) in the supplier selection problem. Thus, in the first step, the loss of each criterion is calculated using Taguchi loss function (TLF), then fuzzy cognitive map (FCM) and hybrid learning algorithm are applied to determine criteria weights. Finally, considering outputs of TLF and FCM methods, multi-choice goal programming with utility function (MCGP-U) is used to select an optimal supplier and to increase the DMs' expected utility values, simultaneously. The results of implementation of proposed framework based on the extended MCGP-U model on an active company in paint and coating industry show that delivery time criterion has the most effect and priority on suppliers' evaluations. Also among six qualified suppliers, a supplier with the least total loss value and the most utility values is selected as the optimal supplier for the under consideration company.","Supplier selection,Taguchi loss function,Fuzzy cognitive map,Multi-choice goal programming with utility function",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"DECISION-SUPPORT,SYSTEM,MODEL",NEURAL COMPUTING & APPLICATIONS,,
71,Prediction of bond performance of tension lap splices using artificial neural networks,198,,,"Hwang Hyeon-Jong,Baek Jang-Woon,Kim Jae-Yo,Kim Chang-Soo","Hwang HJ,Baek JW,Kim JY,Kim CS",Kim CS,10.1016/j.engstruct.2019.109535,Seoul National University of Science & Technology,"Recently, machine learning has been widely used in civil engineering, because better design can be achieved using the advanced computer intelligence and test results. In the present study, to improve design reliability and to extend design application range for the development and lap splice lengths, an artificial neural network model (ANN) was presented using 1008 existing experimental studies for splice tests. Although some of the test parameters are out of the limitations of design codes, all test results were used for the ANN to extend design application range considering present-day construction materials and practices. From a parametric study with the ANN, the effect of design variables was investigated, and predictions by the ANN were compared with existing design equations. Finally, based on the parametric study result, modifications were proposed for existing design equations to consider the effect of non-uniform bond stress distribution and the effect of cover concrete and transverse bars, as well as to extend design application range. Comparisons showed that the modifications improved the accuracy of the design methods. The high accuracy to the large number of existing test results confirms that the modifications based on the ANN can improve design reliability and also can extend design application range for the development and lap splice lengths.","Artificial neural networks,Bond strength,Development length,Lap splice length,Splice test,Non-uniform bond stress distribution",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,4.795,"EPOXY-COATED,REINFORCEMENT,BAR,DEVELOPMENT,LENGTH,STRENGTH,CONCRETE",ENGINEERING STRUCTURES,,
72,A clinical risk matrix for obstructive sleep apnea using Bayesian network approaches,8,4,339-349,"Ferreira-Santos Daniela,Rodrigues Pedro Pereira","Ferreira-Santos D,Rodrigues PP",Ferreira-Santos D,10.1007/s41060-018-0118-x,Universidade do Porto,"In obstructive sleep apnea, respiratory effort is maintained but ventilation decreases/disappears due to upper-airway partial/total occlusion. This condition affects about 4% of men and 2% of women worldwide. This study aimed to define an auxiliary diagnostic method that can support the decision to perform polysomnography, based on risk and diagnostic factors. Our sample performed polysomnography between January and May 2015. Two Bayesian classifiers were used to build the models: Naive Bayes and Tree Augmented Naive Bayes, using 38 variables identified by literature review or just a selection of 6. Area under the ROC curve, sensitivity, specificity and predictive values were evaluated using leave-one-out and cross-validation techniques. From a total of 241 patients, only 194 fulfilled the inclusion criteria, 123 (63%) were male, with a mean age of 58 years, 66 (34%) patients had a normal result and 128 (66%) a diagnosis of obstructive sleep apnea. The cross-validated AUCs for each model were: NB38: 69.2%; TAN38: 69.0%; NB6: 74.6% and TAN6: 63.6%. Regarding risk matrix, female gender presented a starting rate of 8%, comparing to 20% in male gender, almost 3 times higher. The high (34%) proportion of normal results confirms the need for a pre-evaluation prior to polysomnography, making the search for a validated model to screen patients with suspicion of obstructive sleep apnea essential, especially at primary care level.","Obstructive sleep apnea,Risk factors,Diagnosis,Bayesian network,Clinical model,Sensitivity,Specificity",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Computer Science,,,"DIAGNOSIS,EPIDEMIOLOGY,CARE,MANAGEMENT,FEATURES",INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS,https://link.springer.com/content/pdf/10.1007%2Fs41060-018-0118-x.pdf,
73,Identification of suspicious invasive placentation based on clinical MRI data using textural features and automated machine learning,29,11,6152-6162,"Sun Huaiqiang,Qu Haibo,Chen Lu,Wang Wei,Liao Yi,Zou Ling,Zhou Ziyi,Wang Xiaodong,Zhou Shu","Sun HQ,Qu HB,Chen L,Wang W,Liao Y,Zou L,Zhou ZY,Wang XD,Zhou S",Zhou S,10.1007/s00330-019-06372-9,Sichuan University,"Objective The aim of this study was to investigate whether intraplacental texture features from routine placental MRI can objectively and accurately predict invasive placentation. Material and methods This retrospective study includes 99 pregnant women with pathologically confirmed placental invasion and 56 pregnant women with simple placenta previa. All participants underwent magnetic resonance imaging after 24 gestational weeks. The placenta was segmented in sagittal images from both turbo spin echo (TSE) and balanced turbo field echo (bTFE) sequences. Textural features were extracted from the both original and Laplacian of Gaussian (LoG)-filtered MRI images. An automated machine learning algorithm was applied to the extracted feature sets to obtain the optimal preprocessing steps, classification algorithm, and corresponding hyper-parameters. Results A gradient boosting classifier using all textual features from original and LoG-filtered TSE images and bTFE images identified by the automated machine learning algorithm achieved the optimal performance with sensitivity, specificity, accuracy, and area under ROC curve (AUC) of 100%, 88.5%, 95.2%, and 0.98 in the prediction of placental invasion. In addition, textural features that contributed to the prediction of placental invasion differ from the features significantly affected by normal placenta maturation. Conclusions Quantifying intraplacental heterogeneity using LoG filtration and texture analysis highlights the different heterogeneous appearance caused by abnormal placentation relative to normal maturation. The predictive model derived from automated machine learning yielded good performance, indicating the proposed radiomic analysis pipeline can accurately predict placental invasion and facilitate clinical decision-making for pregnant women with suspicious placental invasion.","Magnetic resonance imaging,Placenta accreta,Radiomics,Computer-assisted image analysis,Machine learning",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA","Radiology, Nuclear Medicine & Medical Imaging",,4.87,"SEGMENTATION,INFORMATION,ACCRETA,IMAGES,PREVIA",EUROPEAN RADIOLOGY,,
74,Head and neck squamous cell carcinoma: prediction of cervical lymph node metastasis by dual-energy CT texture analysis with machine learning,29,11,6172-6181,"Forghani Reza,Chatterjee Avishek,Reinhold Caroline,Perez-Lara Almudena,Romero-Sanchez Griselda,Ueno Yoshiko,Bayat Maryam,Alexander James W. M.,Kadi Lynda,Chankowsky Jeffrey","Forghani R,Chatterjee A,Reinhold C,Perez-Lara A,Romero-Sanchez G,Ueno Y,Bayat M,Alexander JWM,Kadi L,Chankowsky J",Forghani R,10.1007/s00330-019-06159-y,McGill University,"Objectives This study was conducted in order to evaluate a novel risk stratification model using dual-energy CT (DECT) texture analysis of head and neck squamous cell carcinoma (HNSCC) with machine learning to (1) predict associated cervical lymphadenopathy and (2) compare the accuracy of spectral versus single-energy (65 keV) texture evaluation for endpoint prediction. Methods Eighty-seven patients with HNSCC were evaluated. Texture feature extraction was performed on virtual monochromatic images (VMIs) at 65 keV alone or different sets of multi-energy VMIs ranging from 40 to 140 keV, in addition to iodine material decomposition maps and other clinical information. Random forests (RF) models were constructed for outcome prediction with internal cross-validation in addition to the use of separate randomly selected training (70%) and testing (30%) sets. Accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) were determined for predicting positive versus negative nodal status in the neck. Results Depending on the model used and subset of patients evaluated, an accuracy, sensitivity, specificity, PPV, and NPV of up to 88, 100, 67, 83, and 100%, respectively, could be achieved using multi-energy texture analysis. Texture evaluation of VMIs at 65 keV alone or in combination with only iodine maps had a much lower accuracy. Conclusions Multi-energy DECT texture analysis of HNSCC is superior to texture analysis of 65 keV VMIs and iodine maps alone and can be used to predict cervical nodal metastases with relatively high accuracy, providing information not currently available by expert evaluation of the primary tumor alone.","Multidetector computed tomography,Machine learning,Artificial intelligence,Head and neck neoplasms,Computer-assisted diagnosis",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,4.87,"COMPUTED-TOMOGRAPHY,IODINE,OVERLAY,BENIGN,DIFFERENTIATION,IMAGES,MRI,CHEMORADIOTHERAPY,DISSECTION,MODEL",EUROPEAN RADIOLOGY,,
75,Automated identification of cephalometric landmarks: Part 1-Comparisons between the latest deep-learning methods YOLOV3 and SSD,89,6,903-909,"Park Ji-Hoon,Hwang Hye-Won,Moon Jun-Ho,Yu Youngsung,Kim Hansuk,Her Soo-Bok,Srinivasan Girish,Aljanabi Mohammed Noori A.,Donatelli Richard E.,Lee Shin-Jae","Park JH,Hwang HW,Moon JH,Yu Y,Kim H,Her SB,Srinivasan G,Aljanabi MNA,Donatelli RE,Lee SJ",Lee SJ,10.2319/022019-127.1,Seoul National University (SNU),"Objective: To compare the accuracy and computational efficiency of two of the latest deep-learning algorithms for automatic identification of cephalometric landmarks.
Materials and Methods: A total of 1028 cephalometric radiographic images were selected as learning data that trained You-Only-Look-Once version 3 (YOLOv3) and Single Shot Multibox Detector (SSD) methods. The number of target labeling was 80 landmarks. After the deep-learning process, the algorithms were tested using a new test data set composed of 283 images. Accuracy was determined by measuring the point-to-point error and success detection rate and was visualized by drawing scattergrams. The computational time of both algorithms was also recorded.
Results: The YOLOv3 algorithm outperformed SSD in accuracy for 38 of 80 landmarks. The other 42 of 80 landmarks did not show a statistically significant difference between YOLOv3 and SSD. Error plots of YOLOv3 showed not only a smaller error range but also a more isotropic tendency. The mean computational time spent per image was 0.05 seconds and 2.89 seconds for YOLOv3 and SSD, respectively. YOLOv3 showed approximately 5% higher accuracy compared with the top benchmarks in the literature.
Conclusions: Between the two latest deep-learning methods applied, YOLOv3 seemed to be more promising as a fully automated cephalometric landmark identification system for use in clinical practice.","Automated identification,Cephalometric landmarks,Artificial intelligence,Machine learning,Deep learning",Article,"E H ANGLE EDUCATION RESEARCH FOUNDATION, INC, 1615 BEACON ST, NEWTON N, MA 02468-1507 USA","Dentistry, Oral Surgery & Medicine",,2.599,"ACTIVE,SHAPE,MODELS,ORTHODONTIC,RESEARCH,REPORT,RELIABILITY,VALIDITY",ANGLE ORTHODONTIST,https://meridian.allenpress.com/angle-orthodontist/article-pdf/89/6/903/2367159/022019-127_1.pdf,
76,Sensor-based machine learning for workflow detection and as key to detect expert level in laparoscopic suturing and knot-tying,33,11,3732-3740,"Kowalewski Karl-Friedrich,Garrow Carly R.,Schmidt Mona W.,Benner Laura,Mueller-Stich Beat P.,Nickel Felix","Kowalewski KF,Garrow CR,Schmidt MW,Benner L,Muller-Stich BP,Nickel F",Nickel F,10.1007/s00464-019-06667-4,Ruprecht Karls University Heidelberg,"Introduction The most common way of assessing surgical performance is by expert raters to view a surgical task and rate a trainee's performance. However, there is huge potential for automated skill assessment and workflow analysis using modern technology. The aim of the present study was to evaluate machine learning (ML) algorithms using the data of a Myo armband as a sensor device for skills level assessment and phase detection in laparoscopic training. Materials and methods Participants of three experience levels in laparoscopy performed a suturing and knot tying task on silicon models. Experts rated performance using Objective Structured Assessment of Surgical Skills (OSATS). Participants wore Myo armbands (Thalmic Labs (TM), Ontario, Canada) to record acceleration, angular velocity, orientation, and Euler orientation. ML algorithms (decision forest, neural networks, boosted decision tree) were compared for skill level assessment and phase detection. Results 28 participants (8 beginner, 10 intermediate, 10 expert) were included, and 99 knots were available for analysis. A neural network regression model had the lowest mean absolute error in predicting OSATS score (3.7 +/- 0.6 points, r(2) = 0.03 +/- 0.81; OSATS min.-max.: 4-37 points). An ensemble of binary-class neural networks yielded the highest accuracy in predicting skill level (beginners: 82.2% correctly identified, intermediate: 3.0%, experts: 79.5%) whereas standard statistical analysis failed to discriminate between skill levels. Phase detection on raw data showed the best results with a multi-class decision jungle (average 16% correctly identified), but improved to 43% average accuracy with two-class boosted decision trees after Dynamic time warping (DTW) application. Conclusion Modern machine learning algorithms aid in interpreting complex surgical motion data, even when standard analysis fails. Dynamic time warping offers the potential to process and compare surgical motion data in order to allow automated surgical workflow detection. However, further research is needed to interpret and standardize available data and improve sensor accuracy.","Myo armband,Machine learning,Neural networks,Laparoscopy,Surgical education,Electromyography,Skill assessment,Workflow analysis,Artificial intelligence,Laparoscopic training",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA",Surgery,,4.595,"OBJECTIVE,STRUCTURED,ASSESSMENT,OPEN,SURGERY,BIG,DATA,SKILL,TOOL",SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES,,
77,Prediction of prostate cancer aggressiveness with a combination of radiomics and machine learning-based analysis of dynamic contrast-enhanced MRI,74,11,,"Liu B.,Cheng J.,Guo D. J.,He X. J.,Luo Y. D.,Zeng Y.,Li C. M.","Liu B,Cheng J,Guo DJ,He XJ,Luo YD,Zeng Y,Li CM",Li CM,10.1016/j.crad.2019.07.011,Chongqing Medical University,"AIM: To investigate whether the combination of radiomics and automatic machine learning-based classification of original images from multiphase dynamic contrast-enhanced (DCE)-magnetic resonance imaging (MRI) can predict prostate cancer (PCa) aggressiveness before biopsy.
MATERIALS AND METHODS: Forty consecutive biopsy-confirmed PCa patients were included. Biopsy was performed within 4 weeks after the DCE-MRI examinations. According to the time-signal-intensity curve, lesion segmentation was performed on the first and on the strongest phase of the enhancement on the original DCE-MRI images, and 1,029 quantitative radiomics features were calculated automatically from each lesion, wherein there were three datasets available (Dataset-F, Dataset-S and Dataset-FS). The variance threshold method, select k-best method and least absolute shrinkage and selection operator (LASSO) algorithm were used to reduce the feature dimensions. Five machine learning approaches leveraging cross-validation were employed, and the clinical value of each model was evaluated by area under the receiver operating characteristic curve (AUC). Correlation analysis was performed between the features of the machine learning model that achieved the best classification performance and the Gleason score (GS) of the PCa lesion.
RESULTS: Eight, four, and 16 features were selected as optimal subsets in Dataset-F, -S and -FS, respectively. Among all three datasets, logistic regression (LR)-based analysis with Dataset-FS had the highest predication efficacy (AUC=0.93). Ten features in Dataset-FS showed significantly positively correlation with GS. The model performance of Dataset-F was generally better than that in Dataset-S.
CONCLUSIONS: A combination of radiomics and machine learning-analysis based analysis of the union of the first and strongest phases of original DCE-MRI images can predict PCa aggressiveness non-invasively, accurately, and automatically. (C) 2019 Published by Elsevier Ltd on behalf of The Royal College of Radiologists.","NEOADJUVANT CHEMOTHERAPY,TEXTURE ANALYSIS,DIAGNOSIS,PERFORMANCE,METASTASIS,UPDATE,IMAGES,HEAD,PET",Article,"W B SAUNDERS CO LTD, 32 JAMESTOWN RD, LONDON NW1 7BY, ENGLAND","Radiology, Nuclear Medicine & Medical Imaging",,2.597,"NEOADJUVANT,CHEMOTHERAPY,TEXTURE,ANALYSIS,DIAGNOSIS,PERFORMANCE,METASTASIS,UPDATE,IMAGES,HEAD,PET",CLINICAL RADIOLOGY,,
78,The role of machine learning in scientific workflows,33,6,1128-1139,"Deelman Ewa,Mandal Anirban,Jiang Ming,Sakellariou Rizos","Deelman E,Mandal A,Jiang M,Sakellariou R",Deelman E,10.1177/1094342019852127,University of Southern California,"Machine learning (ML) is being applied in a number of everyday contexts from image recognition, to natural language processing, to autonomous vehicles, to product recommendation. In the science realm, ML is being used for medical diagnosis, new materials development, smart agriculture, DNA classification, and many others. In this article, we describe the opportunities of using ML in the area of scientific workflow management. Scientific workflows are key to today's computational science, enabling the definition and execution of complex applications in heterogeneous and often distributed environments. We describe the challenges of composing and executing scientific workflows and identify opportunities for applying ML techniques to meet these challenges by enhancing the current workflow management system capabilities. We foresee that as the ML field progresses, the automation provided by workflow management systems will greatly increase and result in significant improvements in scientific productivity.","Scientific workflows,machine learning,workflow systems,anomaly detection,workflow composition",Article; Proceedings Paper,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Computer Science,,2.138,"PERFORMANCE,DESIGN,SYSTEM,WEB",INTERNATIONAL JOURNAL OF HIGH PERFORMANCE COMPUTING APPLICATIONS,https://www.research.manchester.ac.uk/portal/files/159328628/aaa.pdf,
79,Using a Natural Language Processing and Machine Learning Algorithm Program to Analyze Inter-Radiologist Report Style Variation and Compare Variation Between Radiologists When Using Highly Structured Versus More Free Text Reporting,48,6,524-530,"Donnelly Lane F.,Grzeszczuk Robert,Guimaraes Carolina V.,Zhang Wei,Bisset George S. III","Donnelly LF,Grzeszczuk R,Guimaraes CV,Zhang W,Bisset GS",Donnelly LF,10.1067/j.cpradiol.2018.09.005,Stanford University,"Purpose: To use a natural language processing and machine learning algorithm to evaluate inter-radiologist report variation and compare variation between radiologists using highly structured versus more free text reporting.
Materials and Methods: 28,615 radiology reports were analyzed for 4 metrics: verbosity, observational terms only, unwarranted negative findings, and repeated language in different sections. Radiology reports for two imaging examinations were analyzed and compared - one which was more templated (ultrasound - appendicitis) and one which relied on more free text (chest radiograph - single view). For each metric, the mean and standard deviation for defined outlier results for all dictations (individual and group mean) was calculated. The mean number of outlier metrics per reader per study was calculated and compared between radiologists and between the two report types. Wilcoxon rank test and paired Wilcoxon signed rank test were applied. The radiologists were also ranked based on the number of outlier metrics identified per study.
Results: There was great variability in radiologist dictation styles - outlier metrics per report varied greatly between radiologists with the maximum 10 times higher than the minimum score. Metric values were greater (P < 0.0001) on the standardized reports using free text than the more structured reports.
Conclusions: The algorithm successfully evaluated metrics showing variability in reporting profiles particularly when there is free text. This variability can be an obstacle to providing effective communication and reliability of care. (C) 2018 Elsevier Inc. All rights reserved.","SYSTEM,IMPROVEMENT,SKILLS",Article,"MOSBY-ELSEVIER, 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"SYSTEM,IMPROVEMENT,SKILLS",CURRENT PROBLEMS IN DIAGNOSTIC RADIOLOGY,,
80,Prediction of Compressive Strength of Concrete: Critical Comparison of Performance of a Hybrid Machine Learning Model with Standalone Models,31,11,,"Cook Rachel,Lapeyre Jonathan,Ma Hongyan,Kumar Aditya","Cook R,Lapeyre J,Ma HY,Kumar A",Kumar A,10.1061/(ASCE)MT.1943-5533.0002902,University of Missouri System,"The use of machine learning (ML) techniques to model quantitative composition-property relationships in concrete has received substantial attention in the past few years. This paper presents a novel hybrid ML model (RF-FFA) for prediction of compressive strength of concrete by combining the random forests (RF) model with the firefly algorithm (FFA). The firefly algorithm is utilized to determine optimum values of two hyper-parameters (i.e., number of trees and number of leaves per tree in the forest) of the RF model in relation to the nature and volume of the dataset. The RF-FFA model was trained to develop correlations between input variables and output of two different categories of datasets; such correlations were subsequently leveraged by the model to make predictions in previously untrained data domains. The first category included two separate datasets featuring highly nonlinear and periodic relationship between input variables and output, as given by trigonometric functions. The second category included two real-world datasets, composed of mixture design variables of concretes as inputs and their age-dependent compressive strengths as outputs. The prediction performance of the hybrid RF-FFA model was benchmarked against commonly used standalone ML models-support vector machine (SVM), multilayer perceptron artificial neural network (MLP-ANN), M5Prime model tree algorithm (M5P), and RF. The metrics used for evaluation of prediction accuracy included five different statistical parameters as well as a composite performance index (CPI). Results show that the hybrid RF-FFA model consistently outperforms the standalone ML models in terms of prediction accuracy-regardless of the nature and volume of datasets.","Machine learning,Concrete,Compressive strength,Random forests,Firefly algorithm",Article,"ASCE-AMER SOC CIVIL ENGINEERS, 1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA","Construction & Building Technology,Engineering,Materials Science",,3.501,"ARTIFICIAL,NEURAL-NETWORKS,SUPPORT,VECTOR,REGRESSION,RANDOM,FORESTS,GENETIC,ALGORITHMS,CLASSIFICATION,APPROXIMATION,DISCOVERY,KNOWLEDGE,INSIGHTS,TOOL",JOURNAL OF MATERIALS IN CIVIL ENGINEERING,,
81,Estimating Asphalt Concrete Modulus of Existing Flexible Pavements for Mechanistic-Empirical Rehabilitation Analyses,31,11,,"Gong Hongren,Sun Yiren,Huang Baoshan","Gong HR,Sun YR,Huang BS",Huang BS,10.1061/(ASCE)MT.1943-5533.0002892,University of Tennessee System,"The modulus of the existing asphalt concrete (AC) layer, back-calculated from nondestructive pavement tests, is a crucial input for an accurate overlay design in the pavement mechanistic-empirical (ME) design system. However, nondestructive testing (NDT) data for this purpose are not always available for network-level rehabilitation analyses. To address this issue, this paper proposes a regularized regression method to accurately estimate the moduli with data readily available from pavement management systems, including distress, structural information, and climatic conditions. The data from the Long-Term Pavement Performance (LTPP) database were used for model training. Prediction performance comparisons among three regularization regression methods (ridge, elastic net, and lasso) and the ordinary least-squares regression were conducted. The results showed that the elastic net regression outperformed the other three methods in terms of predictability and interpretability. The mean squared errors of the regularization regression methods were found to be considerably lower than that of the ordinary least-squares regression. The moduli estimated by the regularization methods were very close to the back-calculated ones from the LTPP database, which demonstrated the feasibility of estimating the moduli of existing pavement when in paucity of NDT data. After applying the estimated moduli in the pavement ME design system, the predicted alligator cracking was closer to the measured data than those without these data.","Mechanistic-Empirical Pavement Design Guide (MEPDG),Asphalt concrete,Modulus,Falling weight deflectometer (FWD),Machine learning,Regularized regression,Long-Term Pavement Performance (LTPP)",Article,"ASCE-AMER SOC CIVIL ENGINEERS, 1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA","Construction & Building Technology,Engineering,Materials Science",,3.501,"DESIGN-GUIDE,FATIGUE,CRACKING,LAYER,CONDITION,REGRESSION,PREDICTION,SELECTION,REGULARIZATION,PERFORMANCE,MODEL,RAP",JOURNAL OF MATERIALS IN CIVIL ENGINEERING,,
82,High cycle fatigue life prediction of laser additive manufactured stainless steel: A machine learning approach,128,,,"Zhang Meng,Sun Chen-Nan,Zhang Xiang,Goh Phoi Chin,Wei Jun,Hardacre David,Li Hua","Zhang M,Sun CN,Zhang X,Goh PC,Wei J,Hardacre D,Li H",Li H,10.1016/j.ijfatigue.2019.105194,Nanyang Technological University & National Institute of Education (NIE) Singapore,"Variations in the high cycle fatigue response of laser powder bed fusion materials can be caused by the choice of processing and post-processing strategies. The numerous influencing factors arising from the process demand an effective and unified approach to fatigue property assessment. This work examines the use of a neuro-fuzzybased machine learning method for predicting the high cycle fatigue life of laser powder bed fusion stainless steel 316L. A dataset, consisting of fatigue life data for samples subjected to varying processing conditions (laser power, scan speed and layer thickness), post-processing treatments (annealing and hot isostatic pressing) and cyclic stresses, was constructed for simulating a complex nonlinear input-output environment. The associated fracture mechanisms, including the modes of crack initiation and deformation, were characterised. Two models, by employing the processing/post-processing parameters and the static tensile properties respectively as the inputs, were developed from the training data. Despite the diverse fatigue and fracture properties, the models demonstrated good prediction accuracy when checked against the test data, and the computationally-derived fuzzy rules agree well with understanding of the fracture mechanisms. Direct application of the model to literature results, however, yielded a range of prediction accuracies because of the variability in the reported data. Retraining the model by incorporating the literature results into the dataset led to improved modelling performance.","Fatigue,Fracture,Neuro-fuzzy modelling,Stainless steel 316L,Additive manufacturing",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Materials Science",,4.946,"POWDER,BED,FUSION,FUZZY,INFERENCE,SYSTEM,PROCESS,PARAMETERS,FRACTURE-BEHAVIOR,PROPERTY,PERFORMANCE,MICROSTRUCTURE,TI-6AL-4V,STRENGTH",INTERNATIONAL JOURNAL OF FATIGUE,,
83,Error assessment and optimal cross-validation approaches in machine learning applied to impurity diffusion,169,,,"Lu Hai-Jin,Zou Nan,Jacobs Ryan,Afflerbach Ben,Lu Xiao-Gang,Morgans Dane","Lu HJ,Zou N,Jacobs R,Afflerbach B,Lu XG,Morgans D",Lu XG,10.1016/j.commatsci.2019.06.010,Shanghai University,"Machine learning models have been widely utilized in materials science to discover trends in existing data and then make predictions to generate large databases, providing powerful tools for accelerating materials discovery and design. However, there is a significant need to refine approaches both for developing the best models and assessing the uncertainty in their predictions. In this work, we evaluate the performance of Gaussian kernel ridge regression (GKRR) and Gaussian process regression (GPR) for modeling ab-initio predicted impurity diffusion activation energies, using a database with 15 pure metal hosts and 408 host-impurity pairs. We demonstrate the advantages of basing the feature selection on minimizing the Leave-Group-Out (LOG) cross-validation (CV) root mean squared error (RMSE) instead of the more commonly used random K-fold CV RMSE. For the best descriptor and hyperparameter sets, the LOG RMSE from the GKRR (GPR) model is only 0.148 eV (0.155 eV) and the corresponding 5-fold RMSE is 0.116 eV (0.129 eV), demonstrating the model can effectively predict diffusion activation energies. We also show that the ab-initio impurity migration barrier can be employed as a feature to increase the accuracy of the model significantly while still yielding a significant speedup in the ability to predict the activation energy of new systems. Finally, we define r as the magnitude of the ratio of the actual error (residual) in a left-out data point during CV to the predicted standard deviation for that same data point in the GPR model, and compare the distribution of r to a normal distribution. Deviations of r from a normal distribution can be used to quantify the accuracy of the machine learning error estimates, and our results generally show that the approach yields accurate, normally-distributed error estimates for this diffusion data set.","Machine learning,Diffusion,Gaussian process,Error assessment",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"ALLOYING,ELEMENTS,COEFFICIENTS",COMPUTATIONAL MATERIALS SCIENCE,,
84,A novel deep learning based method for the computational material design of flexoelectric nanostructures with topology optimization,165,,21-30,"Hamdia Khader M.,Ghasemi Hamid,Bazi Yakoub,AlHichri Haikel,Alajlan Naif,Rabczuk Timon","Hamdia KM,Ghasemi H,Bazi Y,AlHichri H,Alajlan N,Rabczuk T",Rabczuk T,10.1016/j.finel.2019.07.001,King Saud University,"We present a deep learning method to investigate the effect of flexoelectricity in nanostructures. For this purpose, deep neural network (DNN) algorithm is employed to map the relation between the inputs and the material response of interest. The DNN model is trained and tested making use of database that has been established by solving the governing equations of flexoelectricity using a NURBS-based IGA formulation at design points in the full probability space of the input parameters. Firstly, pure flexoelectric cantilever nanobeam is investigated under mechanical and electrical loading conditions. Then, structures of composite system constituted by two non-piezoelectric material phases are addressed in order to find the optimized topology with respect to the energy conversion factor. The results show promising capabilities of the proposed method, in terms of accuracy and computational efficiency. The deep learning method we used have produced superior optimal designs compared to the numerical methods. The findings of this study will be of profound interest to researcher involved further in the optimization and design of flexoelectric structures.","Flexoelectricity,Piezoelectricity,Isogeometric analysis (IGA),Machine learning,Deep neural network,Topology optimization",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Mathematics,Mechanics",,3.17,FRAMEWORK,FINITE ELEMENTS IN ANALYSIS AND DESIGN,,
85,Effect of layer-wise fine-tuning in magnification-dependent classification of breast cancer histopathological image,36,9,1755-1769,"Sharma Shallu,Mehra Rajesh","Sharma S,Mehra R",Sharma S,10.1007/s00371-019-01768-6,"National Institute of Technical Teachers Training & Research, Chandigarh","A large and balanced training data are the foremost requirement in proper convergence of a deep convolutional neural network (CNN). Medical data always suffer from the problem of unbalancing and inadequacy that makes it difficult to train CNN from scratch. It is known that the transfer learning approach provides great potential to deal with inadequate dataset besides the benefit of faster training. The efficient transfer of knowledge from natural images to histopathological images has yet to be achieved. In view of the foregoing, an attempt has been made toward the classification of BreakHis dataset using pre-trained 'AlexNet' model with a suitable fine-tuning approach. The effective depth of fine-tuning is also determined at different levels of magnification (40x, 100x, 200x and 400x). The experimental trials conform that the moderate level of fine-tuning is an optimum choice for the classification of magnification-dependent histology images in contrast to the shallow and deep tuning of the pre-trained network which in turn depends on the size and relative distribution of a dataset. Additionally, the layer-wise fine-tuning approach provides a neck-to-neck performance with the latest state-of-the-art developments.","Transfer learning,Layer-wise fine-tuning,Convolutional neural network,Magnification factor,Histopathological images,Breast cancer",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,2.081,FEATURES,VISUAL COMPUTER,,
86,A nature-inspired biomarker for mental concentration using a single-channel EEG,32,12,7941-7956,"Basterrech Sebastian,Kromer Pavel","Basterrech S,Kromer P",Basterrech S,10.1007/s00521-019-04574-2,Technical University of Ostrava,"We developed a system for measuring the attentional process during the performance of specific activities. The proposed biomarker device is able to estimate the mental concentration using a single-channel EEG. The system captures the EEG signal and several brain waves located in the left orbitofrontal brain region. Furthermore, we extended the input features of the system applying spectrum analysis. We applied two well-known evolutionary algorithms for selecting the best combination of input features: simulated annealing and geometric particle swarm optimization. Besides, we solved the binary classification problem (concentration vs. relaxation) using support vector machines and neural networks. Support vector machines are among the most common instruments for solving binary classification problems. On the other hand, we selected to study a family of neural networks named echo state networks, because the model is ideal for embedded systems and has shown good accuracy in real-world applications. The training and execution are fast, robust, and reliable. The developed system is autonomous, portable, reliable, non-invasive and has a low economic cost. Besides, it can be easily adjusted for each person and for each problem.","Brain-computer interface,Biomarkers,Echo state network,Simulated annealing,Swarm intelligence",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"PARTICLE,SWARM,RESERVOIR,OPTIMIZATION,NETWORKS",NEURAL COMPUTING & APPLICATIONS,,
87,Diagnostic Value of Machine Learning-Based Quantitative Texture Analysis in Differentiating Benign and Malignant Thyroid Nodules,2019,,,"Colakoglu Bulent,Alis Deniz,Yergin Mert","Colakoglu B,Alis D,Yergin M",Alis D,10.1155/2019/6328329,Mehmet Akif Ersoy Thoracic Cardiovascular Surgery Education Research Hospital,"Aim. The aim of this study is to evaluate the diagnostic value of machine learning- (ML-) based quantitative texture analysis in the differentiation of benign and malignant thyroid nodules. Materials and methods. A sum of 306 quantitative textural features of 235 thyroid nodules (102 malignant, 43.4%; 133 benign, 56.4%) of a total of 198 patients were investigated using the random forest ML classifier. Feature selection and dimension reduction were conducted using reproducibility testing and a wrapper method. The diagnostic accuracy, sensitivity, specificity, and area under curve (AUC) of the proposed method were compared with the histopathological or cytopathological findings as reference methods. Results. Of the 306 initial texture features, 284 (92.2%) showed good reproducibility (intraclass correlation >= 0.80). The random forest classifier accurately identified 87 out of 102 malignant thyroid nodules and 117 out of 133 benign thyroid nodules, which is a diagnostic sensitivity of 85.2%, specificity of 87.9%, and accuracy of 86.8%. The AUC of the model was 0.92. Conclusions. Quantitative textural analysis of thyroid nodules using ML classification can accurately discriminate benign and malignant thyroid nodules. Our findings should be validated by multicenter prospective studies using completely independent external data.","COMPUTER-AIDED DIAGNOSIS,LESION CLASSIFICATION,OBSERVER VARIABILITY,ULTRASOUND,RADIOMICS,FEATURES,SYSTEM,CANCER,COMBINATION,PREVALENCE",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Oncology,,,"COMPUTER-AIDED,DIAGNOSIS,LESION,CLASSIFICATION,OBSERVER,VARIABILITY,ULTRASOUND,RADIOMICS,FEATURES,SYSTEM,CANCER,COMBINATION,PREVALENCE",JOURNAL OF ONCOLOGY,https://downloads.hindawi.com/journals/jo/2019/6328329.pdf,
88,,,,,,,,,,,,,,,,,,,,
89,,,,,,,,,,,,,,,,,,,,
90,Cross-Validation With Confidence,115,532,1978-1997,Lei Jing,Lei J,Lei J,10.1080/01621459.2019.1672556,Carnegie Mellon University,"Cross-validation is one of the most popular model and tuning parameter selection methods in statistics and machine learning. Despite its wide applicability, traditional cross-validation methods tend to overfit, due to the ignorance of the uncertainty in the testing sample. We develop a novel statistically principled inference tool based on cross-validation that takes into account the uncertainty in the testing sample. This method outputs a set of highly competitive candidate models containing the optimal one with guaranteed probability. As a consequence, our method can achieve consistent variable selection in a classical linear regression setting, for which existing cross-validation methods require unconventional split ratios. When used for tuning parameter selection, the method can provide an alternative trade-off between prediction accuracy and model interpretability than existing variants of cross-validation. We demonstrate the performance of the proposed method in several simulated and real data examples. Supplemental materials for this article can be found online.","Cross-validation,Hypothesis testing,Model selection,Overfitting,Tuning parameter selection",Article,"AMER STATISTICAL ASSOC, 732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA",Mathematics,,6.086,"TUNING,PARAMETER,SELECTION,MODEL,SELECTION,LASSO",JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION,http://arxiv.org/pdf/1703.07904,
91,Robust retinal blood vessel segmentation using convolutional neural network and support vector machine,12,3,3559-3569,"Balasubramanian Kishore,Ananthamoorthy N. P.","Balasubramanian K,Ananthamoorthy NP",Balasubramanian K,10.1007/s12652-019-01559-w,"Dr Mahalingam Coll Engn & Technol, Pollachi 642002, India.","In recent decades, automatic retinal blood vessel segmentation and classification (RBVSC) helps to determine many diseases such as glaucoma, hypertension, macular-degeneration, diabetes-mellitus, etc. The early recognition of these disorders is essential for preventing patients from blindness. In this work, a new supervised system was developed to enhance the performance of RBVSC. At first, the input retinal images were collected from two datasets such as: Digital Retinal Image for Vessel Extraction (DRIVE) and STARE (STructured Analysis of the Retina). Then, the retinal vessels were segmented utilizing mean orientation based super-pixel segmentation. Besides, Convolutional Neural Network (CNN) was applied to extract the feature vectors from segmented regions. Finally, a binary classifier [Support Vector Machine (SVM)] performs classification on the extracted features for classifying the ""vessel"" and ""non-vessel"" regions. The combination of CNN and SVM automatically learns the feature values from raw images and classifies the patterns easily. From the experimental study, the proposed system improved RBVSC up to 2-4% compared to other existing systems and classification methodologies: Deep Neural Network (DNN), Random Forest (RF) and Naive Bayes (NB) by means of specificity, accuracy, sensitivity and kappa index.","Convolutional neural network,Feature learning,Median filter,Retinal blood vessel segmentation and classification,Support vector machine",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Telecommunications",,6.163,IMAGES,JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING,,
92,Automated label-free detection of injured neuron with deep learning by two-photon microscopy,13,1,,"Wang Shu,Lin Bingbing,Lin Guimin,Lin Ruolan,Huang Feng,Liu Weilin,Wang Xingfu,Liu Xueyong,Zhang Yu,Wang Feng","Wang S,Lin BB,Lin GM,Lin RL,Huang F,Liu WL,Wang XF,Liu XY,Zhang Y,Wang F",Chen LD,10.1002/jbio.201960062,Fujian University of Traditional Chinese Medicine,"Stroke is a significant cause of morbidity and long-term disability globally. Detection of injured neuron is a prerequisite for defining the degree of focal ischemic brain injury, which can be used to guide further therapy. Here, we demonstrate the capability of two-photon microscopy (TPM) to label-freely identify injured neurons on unstained thin section and fresh tissue of rat cerebral ischemia-reperfusion model, revealing definite diagnostic features compared with conventional staining images. Moreover, a deep learning model based on convolutional neural network is developed to automatically detect the location of injured neurons on TPM images. We then apply deep learning-assisted TPM to evaluate the ischemic regions based on tissue edema, two-photon excited fluorescence signal intensity, as well as neuronal injury, presenting a novel manner for identifying the infarct core, peri-infarct area, and remote area. These results propose an automated and label-free method that could provide supplementary information to augment the diagnostic accuracy, as well as hold the potential to be used as an intravital diagnostic tool for evaluating the effectiveness of drug interventions and predicting potential therapeutics.","deep learning,focal cerebral ischemia-reperfusion,injured neuron,two-photon excited fluorescence,two-photon microscopy",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Biochemistry & Molecular Biology,Biophysics,Optics",,3.403,"CEREBRAL-ARTERY,OCCLUSION,FLUORESCENCE,BRAIN,ISCHEMIA,TRANSPLANTATION,IDENTIFICATION,CELL",JOURNAL OF BIOPHOTONICS,,
93,"High-performance fiber reinforced concrete as a repairing material to normal concrete structures: Experiments, numerical simulations and a machine learning-based prediction model",223,,1167-1181,"Jiao Pengcheng,Roy Manish,Barri Kaveh,Zhu Ronghua,Ray Indrajit,Alavi Amir H.","Jiao PC,Roy M,Barri K,Zhu RH,Ray I,Alavi AH",Jiao PC,10.1016/j.conbuildmat.2019.07.312,Zhejiang University,"High-performance fiber reinforced concrete (HPFRC) has been reported as a repairing material to normal concrete (NC) structures due to its predominant mechanical performance. Here, we investigate the debonding behavior between HPFRC and NC subjected to direct shear loading. HPFRC specimens are fabricated and experimentally calibrated to determine the compressive and bending (i.e., flexural) strengths. HPFRC-NC samples are fabricated using two bonding strategies, i.e., mechanical surface treatments with and without chemical agent. Direct shear loading is applied to test the HPFRC-NC debonding behavior. A finite element (FE) model is developed to predict the direct shear debonding response. The FE model is validated by the experimental observations and then used to characterize the debonding behavior with various geometric and material parameters, as well as bonding interface treatments. Subsequently, a robust machine learning model is developed to formulate the shear debonding strength of HPFRC-NC with those influencing parameters. Design examples are presented to illustrate the efficiency of the proposed machine learning model in describing the debonding response of HPFRC-NC. A sensitivity analysis is further conducted to investigate the contribution of the chosen predictors to the debonding behavior of HPFRC-NC. The reported HPFRC and machine learning-based prediction model provide powerful tools to address repairing issues in various existing normal concrete structures. (C) 2019 Elsevier Ltd. All rights reserved.","High-performance fiber reinforced concrete (HPFRC),Normal concrete (NC),Debonding behavior,Machine learning,Prediction model,Direct shear test",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Construction & Building Technology,Engineering,Materials Science",,6.841,"COMPRESSIVE,STRENGTH,NEURAL-NETWORK,BOND,STRENGTH,FLEXURAL,BEHAVIOR,CYCLIC,BEHAVIOR,BEAMS,DESIGN,SUBSTRATE,COLUMNS,FUZZY",CONSTRUCTION AND BUILDING MATERIALS,,
94,Rapid identification of pathogenic bacteria using Raman spectroscopy and deep learning,10,,,"Ho Chi-Sing,Jean Neal,Hogan Catherine A.,Blackmon Lena,Jeffrey Stefanie S.,Holodniy Mark,Banaei Niaz,Saleh Amr A. E.,Ermon Stefano,Dionne Jennifer","Ho CS,Jean N,Hogan CA,Blackmon L,Jeffrey SS,Holodniy M,Banaei N,Saleh AAE,Ermon S,Dionne J",Saleh AAE; Dionne J,10.1038/s41467-019-12898-9,Stanford University,"Raman optical spectroscopy promises label-free bacterial detection, identification, and antibiotic susceptibility testing in a single step. However, achieving clinically relevant speeds and accuracies remains challenging due to weak Raman signal from bacterial cells and numerous bacterial species and phenotypes. Here we generate an extensive dataset of bacterial Raman spectra and apply deep learning approaches to accurately identify 30 common bacterial pathogens. Even on low signal-to-noise spectra, we achieve average isolate-level accuracies exceeding 82% and antibiotic treatment identification accuracies of 97.0 +/- 0.3%. We also show that this approach distinguishes between methicillin-resistant and -susceptible isolates of Staphylococcus aureus (MRSA and MSSA) with 89 +/- 0.1% accuracy. We validate our results on clinical isolates from 50 patients. Using just 10 bacterial spectra from each patient isolate, we achieve treatment identification accuracies of 99.7%. Our approach has potential for culture-free pathogen identification and antibiotic susceptibility testing, and could be readily extended for diagnostics on blood, urine, and sputum.","RESISTANCE,INFECTION,CHILDREN",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,15.805,"RESISTANCE,INFECTION,CHILDREN",NATURE COMMUNICATIONS,http://arxiv.org/pdf/1901.07666,
95,Identification of advanced spin-driven thermoelectric materials via interpretable machine learning,5,,,"Iwasaki Yuma,Sawada Ryohto,Stanev Valentin,Ishida Masahiko,Kirihara Akihiro,Omori Yasutomo,Someya Hiroko,Takeuchi Ichiro,Saitoh Eiji,Yorozu Shinichi","Iwasaki Y,Sawada R,Stanev V,Ishida M,Kirihara A,Omori Y,Someya H,Takeuchi I,Saitoh E,Yorozu S",Iwasaki Y,10.1038/s41524-019-0241-9,NEC Corporation,"Machine learning is becoming a valuable tool for scientific discovery. Particularly attractive is the application of machine learning methods to the field of materials development, which enables innovations by discovering new and better functional materials. To apply machine learning to actual materials development, close collaboration between scientists and machine learning tools is necessary. However, such collaboration has been so far impeded by the black box nature of many machine learning algorithms. It is often difficult for scientists to interpret the data-driven models from the viewpoint of material science and physics. Here, we demonstrate the development of spin-driven thermoelectric materials with anomalous Nernst effect by using an interpretable machine learning method called factorized asymptotic Bayesian inference hierarchical mixture of experts (FAB/HMEs). Based on prior knowledge of material science and physics, we were able to extract from the interpretable machine learning some surprising correlations and new knowledge about spin-driven thermoelectric materials. Guided by this, we carried out an actual material synthesis that led to the identification of a novel spin-driven thermoelectric material. This material shows the largest thermopower to date.",POWER,Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND","Chemistry,Materials Science",,13.993,POWER,NPJ COMPUTATIONAL MATERIALS,https://www.nature.com/articles/s41524-019-0241-9.pdf,
96,Regional and gender differences in population-based oral health insurance data,24,7,2331-2339,"Stamm Tanja,Ritschl Valentin,Platzer Alexander,Omara Maisa,Mosor Erika,Reichardt Berthold,Schmitl Lina,Behanova Martina,Bekes Katrin","Stamm T,Ritschl V,Platzer A,Omara M,Mosor E,Reichardt B,Schmitl L,Behanova M,Bekes K",Stamm T,10.1007/s00784-019-03090-w,Medical University of Vienna,"Objective Early dental monitoring contributes substantially to good oral health in children. However, little is known on whether children from different geographical regions and gender are equally reached with current preventive and curative oral health strategies. The aim of our study therefore was to explore regional and gender differences in a population-based oral health dataset of Austrian children up to the age of 14. Materials and methods We extracted the first electronically available health insurance data of children aged up to 14 years on dental services within a 4-year observation period in Austria and performed a separate analysis in up to 6-year-old children. In addition, we used a smaller randomly selected sample dataset of 3000 children as the large numbers would result in significant, but very small effects. Results In a total of 130,895 children, of whom 77,173 children (59%) were up to the age of six, we detected an east-west gradient: The eastern regions of Austria showed an older age at first contact and a higher number of dental services. A child aged up to 6 years who needed more than four dental services had a likelihood of 40% to be from Vienna, Austria's capital city located in the east. The smaller random sample did not show significant gender differences. Conclusions Even in regions with a high density of dentists, such as Vienna, we obviously did not reach young children in the same extent as in other regions.","Pediatric dentistry,Oral health-related quality of life,Population-based data,Health services research,Machine learning",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Dentistry, Oral Surgery & Medicine",,,"DENTAL,VISITS,CHILDREN,CARIES",CLINICAL ORAL INVESTIGATIONS,https://link.springer.com/content/pdf/10.1007/s00784-019-03090-w.pdf,
97,Isolating the Factors That Govern Fracture Development in Rocks Throughout Dynamic In Situ X-Ray Tomography Experiments,46,20,11127-11135,"McBeck Jessica,Kandula Neelima,Aiken John M.,Cordonnier Benoit,Renard Francois","McBeck J,Kandula N,Aiken JM,Cordonnier B,Renard F",McBeck J,10.1029/2019GL084613,University of Oslo,"Centuries of work have highlighted the importance of several characteristics on fracture propagation. However, the relative importance of each characteristic on the likelihood of propagation remains elusive. We rank this importance by performing dynamic X-ray microtomography experiments that provide unique access to characteristics of evolving fracture networks as rocks are triaxially compressed toward failure. We employed a machine learning technique based on logistic regression analysis to predict whether or not a fracture grows from 14 fracture geometry and network characteristics identified throughout four experiments on crystalline rocks in which thousands of fractures propagated. The characteristics that best predict fracture growth are the length, thickness, volume, and orientation of fractures with respect to the external stress field and the distance to the closest neighboring fracture. Growing fractures tend to be more clustered, shorter, thinner, volumetrically smaller, and dipping closer to 30-60 degrees from the maximum compression direction than closing fractures.","fracture growth,machine learning,X-ray tomography,logistic regression,triaxial compression,rock",Article,"AMER GEOPHYSICAL UNION, 2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA",Geology,,,"STRESS-INTENSITY,FACTORS,DEFORMATION,EVOLUTION,PREDICTS",GEOPHYSICAL RESEARCH LETTERS,https://www.duo.uio.no/bitstream/10852/75998/2/McBeck_et_al-2019-Geophysical_Research_Letters.pdf,
98,High Entropy Alloys Mined From Binary Phase Diagrams,9,,,"Qi Jie,Cheung Andrew M.,Poon S. Joseph","Qi J,Cheung AM,Poon SJ",Qi J,10.1038/s41598-019-50015-4,University of Virginia,"High entropy alloys (HEA) are a new type of high-performance structural material. Their vast degrees of compositional freedom provide for extensive opportunities to design alloys with tailored properties. However, compositional complexities present challenges for alloy design. Current approaches have shown limited reliability in accounting for the compositional regions of single solid solution and composite phases. For the first time, a phenomenological method analysing binary phase diagrams to predict HEA phases is presented. The hypothesis is that the H EA structural stability is encoded within the phase diagrams. Accordingly, we introduce several phase-diagram inspired parameters and employ machine learning (ML) to classify 600+ reported HEAs based on these parameters. Compared to other large database statistical prediction models, this model gives more detailed and accurate phase predictions. Both the overall HEA prediction and specifically single-phase HEA prediction rate are above 80%. To validate our method, we demonstrated its capability in predicting HEA solid solution phases with or without intermetallics in 42 randomly selected complex compositions, with a success rate of 81%. The presented search approach with high predictive capability can be exploited to interact with and complement other computation-intense methods such as CALPHAD in providing an accelerated and precise HEA design.","THERMODYNAMICS,MULTICOMPONENT,SELECTION,BCC",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,5.134,"THERMODYNAMICS,MULTICOMPONENT,SELECTION,BCC",SCIENTIFIC REPORTS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6820750,
99,Review-Data-Driven Discovery of Novel Phosphors,9,1,,"Li Shuxing,Xie Rong-Jun","Li SX,Xie RJ",Xie RJ,10.1149/2.0192001JSS,Xiamen University,"Innovative phosphor materials are continuously pursued with advances in solid-state lighting and display technologies. Traditional methods of searching for newphosphors are usually based on a time-consuming and laborious trail-and-error process. Newly emerging approaches, such as high-throughput calculations and machine learning, provide great potentials to significantly accelerate the design and discovery of new materials. Here, we overview the recent development on searching for phosphor materials assisted by datadriven computations, aiming to (i) clarify the composition-structure-property relationships; (ii) construct materials descriptors by computation methods; and (iii) design novel phosphors by combining computation with experiments. Finally, future prospects for data-driven discovery of novel phosphors are highlighted. (C) The Author(s) 2019. Published by ECS.","LIGHT-EMITTING-DIODES,LUMINESCENCE PROPERTIES,RED PHOSPHOR,EU2+,BAND,CE3+,TRANSITION,STABILITY,ENERGIES,CA",Review,"ELECTROCHEMICAL SOC INC, 65 SOUTH MAIN STREET, PENNINGTON, NJ 08534 USA","Materials Science,Physics",,2.016,"LIGHT-EMITTING-DIODES,LUMINESCENCE,PROPERTIES,RED,PHOSPHOR,EU2%2B,BAND,CE3%2B,TRANSITION,STABILITY,ENERGIES,CA",ECS JOURNAL OF SOLID STATE SCIENCE AND TECHNOLOGY,,
100,Controlling Supramolecular Chirality in Peptide-pi-Peptide Networks by Variation of the Alkyl Spacer Length,35,43,14060-14073,"Panda Sayak Subhra,Shmilovich Kirill,Ferguson Andrew L.,Tovar John D.","Panda SS,Shmilovich K,Ferguson AL,Tovar JD",Tovar JD,10.1021/acs.langmuir.9b02683,Johns Hopkins University,"Self-assembled supramolecular organic materials with pi-functionalities are of great interest because of their applications as biocompatible nanoelectronics. A detailed understanding of molecular parameters to modulate the formation of hierarchical structures can inform design principles for materials with engineered optical and electronic properties. In this work, we combine molecular-level characterization techniques with all-atom molecular simulations to investigate the subtle relationship between the chemical structure of peptide-pi-peptide molecules and the emergent supramolecular chirality of their spontaneously self-assembled nanoaggregates. We demonstrate through circular dichroism measurements that we can modulate the chirality by incorporating alkyl spacers of various lengths in between the peptides and thienylene-phenylene pi-system chromophores: even numbers of alkyl carbons in the spacer units (0, 2) induce M-type helical character whereas odd numbers (1, 3) induce P-type. Corroborating molecular dynamics simulations and explicating machine learning analysis techniques identify hydrogen bonding and hydrophobic packing to be the principal discriminants of the observed chirality switches. Our results present a molecular-level design rule to engineer chirality into optically and electronically active nanoaggregates of these peptidic building blocks by exploiting systematic variations in the alkyl spacer length.","SIDE-CHAIN LENGTH,ODD-EVEN,INTERCHAIN INTERACTIONS,PERYLENE BISIMIDES,NANOSTRUCTURES,OLIGOTHIOPHENE,ASSEMBLIES,POLYMERS,NANOWIRES,STEREOMUTATION",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Materials Science",,,"SIDE-CHAIN,LENGTH,ODD-EVEN,INTERCHAIN,INTERACTIONS,PERYLENE,BISIMIDES,NANOSTRUCTURES,OLIGOTHIOPHENE,ASSEMBLIES,POLYMERS,NANOWIRES,STEREOMUTATION",LANGMUIR,,
