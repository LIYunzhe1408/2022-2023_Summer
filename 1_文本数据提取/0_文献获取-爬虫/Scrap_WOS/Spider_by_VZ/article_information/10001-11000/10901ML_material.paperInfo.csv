,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,K-Net: Integrate Left Ventricle Segmentation and Direct Quantification of Paired Echo Sequence,39,5,1690-1702,"Ge Rongjun,Yang Guanyu,Chen Yang,Luo Limin,Feng Cheng,Ma Hong,Ren Junyi,Li Shuo","Ge RJ,Yang GY,Chen Y,Luo LM,Feng C,Ma H,Ren JY,Li S",Chen Y,10.1109/TMI.2019.2955436,Southeast University - China,"The integration of segmentation and direct quantification on the left ventricle (LV) from the paired apical views(i.e., apical 4-chamber and 2-chamber together) echo sequence clinically achieves the comprehensive cardiac assessment: multiview segmentation for anatomical morphology, and multidimensional quantification for contractile function. Direct quantification of LV, i.e., to automatically quantify multiple LV indices directly from the image via task-aware feature representation and regression, avoids accumulative error from the inter-step target. This integration sequentially makes a stereoscopical reflection of cardiac activity jointly from the paired orthogonal cross views sequences, overcoming limited observation with a single plane. We propose a K-shaped Unified Network (K-Net), the first end-to-end framework to simultaneously segment LV from apical 4-chamber and 2-chamber views, and directly quantify LV from major- and minor-axis dimensions (1D), area (2D), and volume (3D), in sequence. It works via four components: 1) the K-Net architecture with the Attention Junction enables heterogeneous tasks learning of segmentation task of pixel-wise classification, and direct quantification task of image-wise regression, by interactively introducing the information from segmentation to jointly promote spatial attention map to guide quantification focusing on LV-related region, and transferring quantification feedback to make global constraint on segmentation; 2) the Bi-ResLSTMs distributed in K-Net layer-by-layer hierarchically extract spatial-temporal information in echo sequence, with bidirectional recurrent and short-cut connection to model spatial-temporal information among all frames; 3) the Information Valve tailing the Bi-ResLSTMs selectively exchanges information among multiple views, by stimulating complementary information and suppressing redundant information to make the efficient cross-flow for each view; 4) the Evolution Loss comprehensively guides sequential data learning, with static constraint for frame values, and dynamic constraint for inter-frame value changes. The experiments show that our K-Net gains high performance with a Dice coefficient up to 91.44% and a mean absolute error of the major-axis dimension down to 2.74mm, which reveal its clinical potential.","Image segmentation,Task analysis,Two dimensional displays,Valves,Biomedical imaging,Three-dimensional displays,Germanium,Left ventricle,echocardiography sequence,paired apical views,segmentation,direct quantification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CARDIAC,BIVENTRICULAR,VOLUMES,IMAGE,SEGMENTATION,BOUNDARY,DETECTION,WHOLE,MYOCARDIUM,2D-ECHOCARDIOGRAPHY,ECHOCARDIOGRAPHY,RECOMMENDATIONS,TRACKING,MODELS",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
2,Multi-Modal Deep Guided Filtering for Comprehensible Medical Image Processing,39,5,1703-1711,"Stimpel Bernhard,Syben Christopher,Schirrmacher Franziska,Hoelter Philipp,Doerfler Arnd,Maier Andreas","Stimpel B,Syben C,Schirrmacher F,Hoelter P,Dorfler A,Maier A",Stimpel B,10.1109/TMI.2019.2955184,University of Erlangen Nuremberg,"Deep learning-based image processing is capable of creating highly appealing results. However, it is still widely considered as a ""blackbox"" transformation. In medical imaging, this lack of comprehensibility of the results is a sensitive issue. The integration of known operators into the deep learning environment has proven to be advantageous for the comprehensibility and reliability of the computations. Consequently, we propose the use of the locally linear guided filter in combination with a learned guidance map for general purpose medical image processing. The output images are only processed by the guided filter while the guidance map can be trained to be task-optimal in an end-to-end fashion. We investigate the performance based on two popular tasks: image super resolution and denoising. The evaluation is conducted based on pairs of multi-modal magnetic resonance imaging and cross-modal computed tomography and magnetic resonance imaging datasets. For both tasks, the proposed approach is on par with state-of-the-art approaches. Additionally, we can show that the input image's content is almost unchanged after the processing which is not the case for conventional deep learning approaches. On top, the proposed pipeline offers increased robustness against degraded input as well as adversarial attacks.","Training,Spatial resolution,Image coding,Conferences,Convolution,Comprehensible image processing,deep learning,guided filtering,multi-modal imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,MRI,IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1911.07731,
3,Multi-Hypergraph Learning-Based Brain Functional Connectivity Analysis in fMRI Data,39,5,1746-1758,"Xiao Li,Wang Junqi,Kassani Peyman H.,Zhang Yipu,Bai Yuntong,Stephen Julia M.,Wilson Tony W.,Calhoun Vince D.,Wang Yu-Ping","Xiao L,Wang JQ,Kassani PH,Zhang YP,Bai YT,Stephen JM,Wilson TW,Calhoun VD,Wang YP",Wang YP,10.1109/TMI.2019.2957097,Tulane University,"Recently, a hypergraph constructed from functional magnetic resonance imaging (fMRI) was utilized to explore brain functional connectivity networks (FCNs) for the classification of neurodegenerative diseases. Each edge of a hypergraph (called hyperedge) can connect any number of brain regions-of-interest (ROIs) instead of only two ROIs, and thus characterizes high-order relations among multiple ROIs that cannot be uncovered by a simple graph in the traditional graph based FCN construction methods. Unlike the existing hypergraph based methods where all hyperedges are assumed to have equal weights and only certain topological features are extracted from the hypergraphs, we propose a hypergraph learning based method for FCN construction in this paper. Specifically, we first generate hyperedges from fMRI time series based on sparse representation, then employ hypergraph learning to adaptively learn hyperedge weights, and finally define a hypergraph similarity matrix to represent the FCN. In our proposed method, weighting hyperedges results in better discriminative FCNs across subjects, and the defined hypergraph similarity matrix can better reveal the overall structure of brain network than using those hypergraph topological features. Moreover, we propose a multi-hypergraph learning based method by integrating multi-paradigm fMRI data, where the hyperedge weights associated with each fMRI paradigm are jointly learned and then a unified hypergraph similarity matrix is computed to represent the FCN. We validate the effectiveness of the proposed method on the Philadelphia Neurodevelopmental Cohort dataset for the classification of individuals' learning ability from three paradigms of fMRI data. Experimental results demonstrate that our proposed approach outperforms the traditional graph based methods (i.e., Pearson's correlation and partial correlation with the graphical Lasso) and the existing unweighted hypergraph based methods, which sheds light on how to optimize estimation of FCNs for cognitive and behavioral study.","Functional magnetic resonance imaging,Correlation,Learning systems,Sparse matrices,Feature extraction,Time series analysis,Neuroimaging,Data fusion,functional connectivity,functional MRI,hypergraph,learning ability,similarity matrix",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"ORDER,INTERACTIONS,NETWORKS,REPRESENTATION,INTELLIGENCE,ORGANIZATION,PATTERNS,FUSION",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7376954,
4,Layout Pattern Synthesis for Lithography Optimizations,33,2,283-290,"Kareem Pervaiz,Kwon Yonghwi,Shin Youngsoo","Kareem P,Kwon Y,Shin Y",Kareem P,10.1109/TSM.2020.2982989,Korea Advanced Institute of Science & Technology (KAIST),"A set of comprehensive test patterns is important for a number of lithography applications. Pattern diversity is, however, hard to achieve either from parametric patterns or from actual patterns even though they are carefully extracted and classified. Automatic layout pattern synthesis is proposed in this paper. A generative adversarial network (GAN) is employed to generate a new set of discrete cosine transform (DCT) signals. It is converted to an image format through inverse DCT (IDCT). The image is blurred since output DCT signals from GAN correspond to lower frequency region. Another GAN, this time a conditional GAN (cGAN), is introduced to get sharpened layout pattern. A key in this process is to train the two GANs in such a way that generated patterns are different from existing actual patterns while they are still valid layouts. Experiments indicate that synthetic patterns are less redundant and cover 76% more space in image parameter set space than actual patterns. We choose a machine-learning guided OPC as an example application: when synthetic patterns are included to train OPC model, edge proximity error decreases by 21%. Resist model calibration is chosen as a second example: when synthetic patterns are combined with parametric- and real-patterns, CD RMSE decreases by 10.3%.","Automatic layout synthesis,layout pattern coverage,resist modeling,OPC,ML-OPC",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Physics",,2.479,MODELS,IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING,,
5,Microsite Influence on Woody Plant Regeneration in aPinus palustrisWoodland Following Catastrophic Disturbance,11,5,,"Logan Alexandra T.,Goode Jonathan D.,Keellings David J.,Hart Justin L.","Logan AT,Goode JD,Keellings DJ,Hart JL",Logan AT,10.3390/f11050588,University of Alabama System,"Information and material biological legacies that persist after catastrophic forest disturbance collectively constitute the ecological memory of the system and may strongly influence future stand development. Catastrophic disturbances often result in an influx of coarse woody debris (CWD), and this material legacy may provide beneficial microsites that affect successional and structural developmental pathways. We examined how microenvironmental characteristics influence the regeneration of woody plants in a subtropical woodland that experienced a large influx of CWD from a catastrophic wind disturbance. Specifically, we asked (1) what microenvironmental factors best explain woody plant density, richness, and height in the regeneration layer and (2) does woody plant density, richness, and height benefit from the large influx of CWD to a degree that competition dynamics and succession may be modified? Data were collected in aPinus palustriswoodland that had experienced an EF3 tornado and was subjected to a four-year prescribed fire rotation. We documented live woody plants <5 cm diameter at breast height, soil, and site characteristics and tested for differences in seedling and sapling density, species richness, and height in relation to CWD proximity. We used a random forest machine learning algorithm to examine the influence of microenvironmental conditions on the characteristics of woody plants in the regeneration layer. Woody plant density and species richness were not significantly different by proximity to CWD, but plants near CWD were slightly taller than plants away from CWD. The best predictors of woody plant density, richness, and height were abiotic site characteristics including slope gradient and azimuth, organic matter depth and weight, and soil water content. Results indicated that the regeneration of woody plants in thisP. palustriswoodland was not strongly influenced by the influx of CWD, but by other biological legacies such as existing root networks and soil characteristics. Our study highlights the need to consider ecological memory in forest management decision-making after catastrophic disturbance. Information and material legacies shape recovery patterns, but, depending on the system, some legacies will be more influential on successional and developmental pathways than others.","coarse woody debris,ecological memory,resilience,succession,tornado",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Forestry,,2.804,"SEASON,PRESCRIBED,FIRE,ALPINE,SPRUCE,FORESTS,FALL-LINE,NUTRIENT,DYNAMICS,OLD-GROWTH,UNDERSTORY,VEGETATION,WIND,DISTURBANCE,VASCULAR,PLANTS,BOREAL,FOREST,GROUND-LAYER",FORESTS,https://www.mdpi.com/1999-4907/11/5/588/pdf,
6,A High Performance System for the Diagnosis of Headache via Hybrid Machine Learning Model,11,5,655-663,"Qawasmeh Ahmad,Alhusan Noor,Hanandeh Feras,Al-Atiyat Maram","Qawasmeh A,Alhusan N,Hanandeh F,Al-Atiyat M",Qawasmeh A,,Hashemite University,"Headache has been a major concern for patients, medical doctors, clinics and hospitals over the years due to several factors. Headache is categorized into two major types: (1) Primary Headache, which can be tension, cluster or migraine, and (2) Secondary Headache where further medical evaluation must be considered. This work presents a high performance Headache Prediction Support System (HPSS). HPSS provides preliminary guidance for patients, medical students and even clinicians for initial headache diagnosis. The mechanism of HPSS is based on a hybrid machine learning model. First, 19 selected attributes (questions) were chosen carefully by medical specialists according to the most recent International Classification of Headache Disorders (ICHD-3) criteria. Then, a questionnaire was prepared to confidentially collect data from real patients under the supervision of specialized clinicians at different hospitals in Jordan. Later, a hybrid solution consisting of clustering and classification was employed to emphasize the diagnosis results obtained by clinicians and to predict headache type for new patients respectively. Twenty-six (26) different classification algorithms were applied on 614 patients' records. The highest accuracy was obtained by integrating K-Means and Random Forest with a migraine accuracy of 99.1% and an overall accuracy of 93%. Our web-based interface was developed over the hybrid model to enable patients and clinicians to use our system in the most convenient way. This work provides a comparative study of different headache diagnosis systems via 9 different performance metrics. Our hybrid model shows a great potential for highly accurate headache prediction. HPSS was used by different patients, medical students, and clinicians with a very positive feedback. This work evaluates and ranks the impact of headache symptoms on headache diagnosis from a machine learning perspective. This can help medical experts for further headache criteria improvements.","High performance computing,Clinical Decision Support System (CDSS),machine learning,primary and secondary headache,performance analysis and improvement,headache diagnosis,open medical application",Article,"SCIENCE & INFORMATION SAI ORGANIZATION LTD, 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND",Computer Science,,,"CLASSIFICATION,DISORDERS,ALGORITHM,MIGRAINE",INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS,,
7,A Neural Networks Approach to Detecting Lost Heritage in Historical Video,9,5,,"Condorelli Francesca,Rinaudo Fulvio,Salvadore Francesco,Tagliaventi Stefano","Condorelli F,Rinaudo F,Salvadore F,Tagliaventi S",Condorelli F,10.3390/ijgi9050297,Polytechnic University of Turin,"Documenting Cultural Heritage through the extraction of 3D measures with photogrammetry is fundamental for the conservation of the memory of the past. However, when the heritage has been lost the only way to recover this information is the use of historical images from archives. The aim of this study is to experiment with new ways to search for architectural heritage in video material and to save the effort of the operator in the archive in terms of efficiency and time. A workflow is proposed to automatically detect lost heritage in film footage using Deep Learning to find suitable images to process with photogrammetry for its 3D virtual reconstruction. The performance of the network was tested on two case studies considering different architectural scenarios, the Tour Saint Jacques which still exists for the tuning of the networks, and Les Halles to test the algorithms on a real case of an architecture which has been destroyed. Despite the poor quantity and low quality of the historical images available for the training of the network, it has been demonstrated that, with few frames, it was possible to reach the same results in terms of performance of a network trained on a large dataset. Moreover, with the introduction of new metrics based on time intervals the measure of the real time saving in terms of human effort was achieved. These findings represent an important innovation in the documentation of destroyed monuments and open new ways to recover information about the past.","machine learning,deep learning,neural networks,object detection,video processing and classification,photogrammetry,lost cultural heritage,3D reconstruction,open source algorithms,metric quality assessment",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Physical Geography,Remote Sensing",,2.971,,ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION,https://www.mdpi.com/2220-9964/9/5/297/pdf,
8,Estimation of protein from the images of health drink powders,57,5,1887-1895,"Shermila P. Josephin,Milton A.","Shermila PJ,Milton A",Shermila PJ,10.1007/s13197-019-04224-4,"Arunachala Coll Engn Women, Dept Elect & Commun Engn, Nagercoil 629203, Tamil Nadu, India.","Using new technologies to know the nutrition contents of food is the new emerging area of research. Predicting protein content from the image of food is one such area that will be most useful to the human beings because monitoring the nutrition intake has many health benefits. Patients with rare diseases like maple syrup urine disease need to be in good diet practices in order to survive. Protein intake has to be monitored for those individuals. In this paper, protein measurement of health drink powder is performed using image processing techniques. In this work food images are captured and a new database with 990 images of 9 health drink powders is created. Protein content is predicted using deep learning convolutional neural network and also using image features with linear regression. Image features like first order statistics, histogram-oriented gradient, gray level co-occurrence matrix, local binary pattern and gradient magnitude and gradient direction features obtained by applying Prewitt, Sobel and Kirsch are used to estimate the protein content. Training and testing are done using linear regression model which uses support vector machine to obtain the optimal hyper plane. A tenfold cross validation is used to improve the statistical significance of the results. Experimental results show that the protein contents are predicted with an average error of +/- 2.71. Deep learning improves the prediction with an average error of +/- 1.96.","Protein prediction,Image database of health drink powders,Deep learning,Linear regression",Article,"SPRINGER INDIA, 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001, INDIA",Food Science & Technology,,3.574,DIETARY-INTAKE,JOURNAL OF FOOD SCIENCE AND TECHNOLOGY-MYSORE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7171020,
9,Feature Importance of Stabilised Rammed Earth Components Affecting the Compressive Strength Calculated with Explainable Artificial Intelligence Tools,13,10,,"Anysz Hubert,Brzozowski Lukasz,Kretowicz Wojciech,Narloch Piotr","Anysz H,Brzozowski L,Kretowicz W,Narloch P",Anysz H,10.3390/ma13102317,Warsaw University of Technology,"Cement-stabilized rammed earth (CSRE) is a sustainable construction material. The use of it allows for economizing on the cost of a structure. These two properties of CSRE are based on the fact that the soil used for the rammed mixture is usually dug close to the construction site, so it has random characteristics. That is the reason for the lack of widely accepted prescriptions for CSRE mixture, which could ascertain high enough compressive strength. Therefore, assessing which components of CSRE have the highest impact on its compressive strength becomes an important issue. There are three machine learning regression tools, i.e., artificial neural networks, decision tree, and random forest, used for predicting the compressive strength based on the relative content of CSRE composites (clay, silt, sand, gravel, cement, and water content). The database consisted of 434 samples of CSRE, which were prepared and crushed for testing purposes. Relatively low prediction errors of aforementioned models allowed for the use of explainable artificial intelligence tools (drop-out loss, mean squared error reduction, accumulated local effect) to rank the influence of the ingredients on the dependent variable-the compressive strength. Consistent results from all above-mentioned methods are discussed and compared to some statistical analysis of selected features. This innovative approach, helpful in designing the construction material is a solid base for reliable conclusions.","rammed earth,cement stabilized rammed earth,multivariate regression,random forest,artificial inteligence,features importance ranking",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"DATA-STANDARDIZATION,CROSS-VALIDATION,W%2FC,RATIO,CONCRETE,CONSTRUCTION,DURABILITY,PREDICTION,PARAMETERS,PORTLAND,TESTS",MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7288123,
10,Automatic heart sound classification from segmented/unsegmented phonocardiogram signals using time and frequency features,41,5,,"Khan Faiq Ahmad,Abid Anam,Khan Muhammad Salman","Khan FA,Abid A,Khan MS",Khan MS,10.1088/1361-6579/ab8770,University of Engineering & Technology Peshawar,"Objective: Heart abnormality detection using heart sound signals (phonocardiogram (PCG)) has been an active research area for the last few decades. In this paper, automatic heart sound classification using segmented and unsegmented PCG signals is presented. Approach: In this paper: (i) we perform an in-depth analysis of various time and frequency domain features, followed by experimental determination of effective feature subsets for improved classification performance; (ii) both segmented and unsegmented PCG signals are studied and important results concerning the respective feature subsets and their classification performances are reported; and (iii) different classification algorithms, including the support vector machine, kth nearest neighbor, decision tree, ensemble classifier, artificial neural network and long short-term memory network (LSTMs), are employed to evaluate the performance of the proposed feature subsets and their comparison with other established features and methods is presented. Main results: It is observed that LSTM performs better on mel-frequency cepstral coefficient (MFCC) features extracted from unsegmented PCG data, with an area under curve (AUC) score of 91.39%, however, the MFCC features do not show a consistent performance with other classifiers (the second highest AUC score is 62.08% with the decision tree classifier). In contrast, in the case of time-frequency features from segmented data, the performance of all the classifiers is appreciable with AUC scores over 70%. In particular, the conventional machine learning techniques shows consistency in achieving over 80% in AUC scores. Significance: The results of this study highlight the importance of time and frequency domain features. Thus it is necessary to employ both the time and frequency features of segmented PCG signals to achieve improved classification.","decision support system,computer-aided diagnostics,heart sounds analysis,feature extraction,supervised classification,area under curve",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"NOISE-REDUCTION,SEGMENTATION",PHYSIOLOGICAL MEASUREMENT,,
11,Spectral harmonization and red edge prediction of Landsat-8 to Sentinel-2 using land cover optimized multivariate regressors,241,,,"Scheffler Daniel,Frantz David,Segl Karl","Scheffler D,Frantz D,Segl K",Scheffler D,10.1016/j.rse.2020.111723,Helmholtz Association,"Multi-sensor remote sensing applications consistently gain importance, boosted by a growing number of freely available earth observation data, increasing computing capacity, and increasingly complex algorithms that need as temporally dense data as possible. Using data provided by different sensors can greatly improve the temporal resolution of time series, fill data gaps and thus improve the quality of land cover monitoring applications. However, multi-sensor approaches are often adversely affected by different spectral characteristics of the sensing instruments, leading to inconsistencies in downstream products. Spectral harmonization, i.e., the transformation of one sensor into the spectral domain of another sensor, may reduce these inconsistencies. It simplifies workflows, increases the reliability of subsequently derived multi-sensor products and may also enable the generation of new products that are not possible with the initial spectral definition. In this paper, we compare the effect of multivariate spectral harmonization techniques on the inter-sensor reflectance consistency and derived products such as spectral indices or land cover classifications. We simulated surface reflectance data of Landsat-8 and Sentinel-2A from airborne hyperspectral data to eliminate any sources of error originating from unequal acquisition geometries, illumination or atmospheric state. We evaluate different methods based on linear, quadratic and random forest regression as well as linear interpolation, and predict not only matching but also unilaterally missing bands (red edge). We additionally consider material-dependent spectral characteristics in the harmonization process by using separate transformation functions for spectral clusters of the input dataset. Our results suggest that spectral harmonization is useful to improve multi-sensor consistency of remote sensing data and subsequently derived products, especially if multiple transformation functions are incorporated. There is a strong dependency between harmonization performance and the similarity of source and target sensor's spectral characteristics. For spectrally transforming Landsat-8 to Sentinel-2A, we achieved the lowest radiometric inter-sensor deviations with 50 spectral clusters and linear regression. Based on simulated data, deviations are below 1.7% reflectance within the red edge spectral region and below 0.3% reflectance for the remaining bands (RMSE). Regarding spectral indices, our results show a reduction of inter-sensor deviation (vegetation pixels only) to 38% of the initial error for NDVI (Normalized Difference Vegetation Index) and to 43% for EVI (Enhanced Vegetation Index). Furthermore, we computed the REIP (Red Edge Inflection Point) with an accuracy of 3.1 nm from Sentinel-2 adapted Landsat-8 data. An exemplary multispectral classification use case revealed an increasing inter-sensor consistency of classification results from 92.3% to 97.3% mean error. Applied to time series of real Landsat-8 and Sentinel-2 data, we observed similar trends, albeit intermingled with non-sensor-induced inconsistencies.","Spectral harmonization,Satellite image harmonization,Machine learning,Time series analysis,Analysis ready data",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Environmental Sciences & Ecology,Remote Sensing,Imaging Science & Photographic Technology",,11.057,"SURFACE,REFLECTANCE,VEGETATION,INDEXES,GENERAL-METHOD,CLOUD,SHADOW,MODIS,NDVI,PERFORMANCE,IMPROVEMENT,QUANTITIES,CONTINUITY",REMOTE SENSING OF ENVIRONMENT,https://gfzpublic.gfz-potsdam.de/pubman/item/item_5001143_5/component/file_5001191/5001143.pdf,
12,Design of a Multi-Robot System for Wind Turbine Maintenance,13,10,,"Franko Josef,Du Shengzhi,Kallweit Stephan,Duelberg Enno,Engemann Heiko","Franko J,Du SZ,Kallweit S,Duelberg E,Engemann H",Franko J,10.3390/en13102552,"Univ Appl Sci Aachen, MASKOR Inst, Fac Mech Engn & Mech, D-52074 Aachen, Germany.","The maintenance of wind turbines is of growing importance considering the transition to renewable energy. This paper presents a multi-robot-approach for automated wind turbine maintenance including a novel climbing robot. Currently, wind turbine maintenance remains a manual task, which is monotonous, dangerous, and also physically demanding due to the large scale of wind turbines. Technical climbers are required to work at significant heights, even in bad weather conditions. Furthermore, a skilled labor force with sufficient knowledge in repairing fiber composite material is rare. Autonomous mobile systems enable the digitization of the maintenance process. They can be designed for weather-independent operations. This work contributes to the development and experimental validation of a maintenance system consisting of multiple robotic platforms for a variety of tasks, such as wind turbine tower and rotor blade service. In this work, multicopters with vision and LiDAR sensors for global inspection are used to guide slower climbing robots. Light-weight magnetic climbers with surface contact were used to analyze structure parts with non-destructive inspection methods and to locally repair smaller defects. Localization was enabled by adapting odometry for conical-shaped surfaces considering additional navigation sensors. Magnets were suitable for steel towers to clamp onto the surface. A friction-based climbing ring robot (SMART- Scanning, Monitoring, Analyzing, Repair and Transportation) completed the set-up for higher payload. The maintenance period could be extended by using weather-proofed maintenance robots. The multi-robot-system was running the Robot Operating System (ROS). Additionally, first steps towards machine learning would enable maintenance staff to use pattern classification for fault diagnosis in order to operate safely from the ground in the future.","wind turbine maintenance,climbing robot,low cost,weather independent operations,condition monitoring,odometry on wind turbines",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,ROBOT,ENERGIES,https://www.mdpi.com/1996-1073/13/10/2552/pdf,
13,Machine Learning Prediction of Surface Segregation Energies on Low Index Bimetallic Surfaces,13,9,,"Ologunagba Damilola,Kattel Shyam","Ologunagba D,Kattel S",Kattel S,10.3390/en13092182,State University System of Florida,"Surface chemical composition of bimetallic catalysts can differ from the bulk composition because of the segregation of the alloy components. Thus, it is very useful to know how the different components are arranged on the surface of catalysts to gain a fundamental understanding of the catalysis occurring on bimetallic surfaces. First-principles density functional theory (DFT) calculations can provide deeper insight into the surface segregation behavior and help understand the surface composition on bimetallic surfaces. However, the DFT calculations are computationally demanding and require large computing platforms. In this regard, statistical/machine learning methods provide a quick and alternative approach to study materials properties. Here, we trained previously reported surface segregation energies on low index surfaces of bimetallic catalysts using various linear and non-linear statistical methods to find a correlation between surface segregation energies and elemental properties. The results revealed that the surface segregation energies on low index bimetallic surfaces can be predicted using fundamental elemental properties.","catalysts,surface segregation energy,density functional theory,machine learning,bimetallic alloys",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"CO2,REDUCTION,CATALYSTS,NI,HYDROGENATION,NANOPARTICLES,PLATINUM,ELECTROCATALYSTS,SUPPORT,ALLOYS,MODEL",ENERGIES,https://www.mdpi.com/1996-1073/13/9/2182/pdf,
14,Power Prediction of Airborne Wind Energy Systems Using Multivariate Machine Learning,13,9,,"Rushdi Mostafa A.,Rushdi Ahmad A.,Dief Tarek N.,Halawa Amr M.,Yoshida Shigeo,Schmehl Roland","Rushdi MA,Rushdi AA,Dief TN,Halawa AM,Yoshida S,Schmehl R",Schmehl R,10.3390/en13092367,Delft University of Technology,"Kites can be used to harvest wind energy at higher altitudes while using only a fraction of the material required for conventional wind turbines. In this work, we present the kite system of Kyushu University and demonstrate how experimental data can be used to train machine learning regression models. The system is designed for 7 kW traction power and comprises an inflatable wing with suspended kite control unit that is either tethered to a fixed ground anchor or to a towing vehicle to produce a controlled relative flow environment. A measurement unit was attached to the kite for data acquisition. To predict the generated tether force, we collected input-output samples from a set of well-designed experimental runs to act as our labeled training data in a supervised machine learning setting. We then identified a set of key input parameters which were found to be consistent with our sensitivity analysis using Pearson input-output correlation metrics. Finally, we designed and tested the accuracy of a neural network, among other multivariate regression models. The quality metrics of our models show great promise in accurately predicting the tether force for new input/feature combinations and potentially guide new designs for optimal power generation.","airborne wind energy,kite system,kite power,tether force,machine learning,neural network,power prediction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"KITE,MODEL,GENERATION,DESIGN",ENERGIES,https://www.mdpi.com/1996-1073/13/9/2367/pdf,
15,Do Machine Learning Techniques and Dynamic Methods Help Forecast US Natural Gas Crises?,13,9,,"Zhang Wenting,Hamori Shigeyuki","Zhang WT,Hamori S",Hamori S,10.3390/en13092371,Kobe University,"Our study combines machine learning techniques and dynamic moving window and expanding window methods to predict crises in the US natural gas market. Specifically, as machine learning models, we employ extreme gradient boosting (XGboost), support vector machines (SVMs), a logistic regression (LogR), random forests (RFs), and neural networks (NNs). The data set used to develop the model covers the period 1994 to 2019 and contains 121 explanatory variables, including those related to crude oil, stock markets, US bond and gold futures, the CBOE Volatility Index (VIX) index, and agriculture futures. To the best of our knowledge, this study is the first to combine machine learning techniques with dynamic approaches to predict US natural gas crises. To improve the model's prediction accuracy, we applied a suite of parameter-tuning methods (e.g., grid-search) to select the best-performing hyperparameters for each model. Our empirical results demonstrated very good prediction accuracy for US natural gas crises when combining the XGboost model with the dynamic moving window method. We believe our findings will be useful to investors wanting to diversify their portfolios, as well as to policymakers wanting to take preemptive action to reduce losses.","dynamic approaches,forecasting,logistic regression,random forests,support vector machines,US natural gas crises,XGboost,neural networks",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"EARLY,WARNING,SYSTEM,FINANCIAL,CRISES,EMERGING,MARKETS,INDICATORS,PREDICT",ENERGIES,http://www.lib.kobe-u.ac.jp/repository/90007130.pdf,
16,Deep learning enabled inverse design in nanophotonics,9,5,1041-1057,"So Sunae,Badloe Trevon,Noh Jaebum,Rho Junsuk,Bravo-Abad Jorge","So S,Badloe T,Noh J,Rho J,Bravo-Abad J",Rho J,10.1515/nanoph-2019-0474,Pohang University of Science & Technology (POSTECH),"Deep learning has become the dominant approach in artificial intelligence to solve complex data-driven problems. Originally applied almost exclusively in computer-science areas such as image analysis and nature language processing, deep learning has rapidly entered a wide variety of scientific fields including physics, chemistry and material science. Very recently, deep neural networks have been introduced in the field of nano-photonics as a powerful way of obtaining the nonlinear mapping between the topology and composition of arbitrary nanophotonic structures and their associated functional properties. In this paper, we have discussed the recent progress in the application of deep learning to the inverse design of nanophotonic devices, mainly focusing on the three existing learning paradigms of supervised-, unsupervised-, and reinforcement learning. Deep learning forward modelling i.e. how artificial intelligence learns how to solve Maxwell's equations, is also discussed, along with an outlook of this rapidly evolving research area.","artificial intelligence,nanophotonics,machine learning,inverse design,forward modelling,metamaterials",Review,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY","Science & Technology - Other Topics,Materials Science,Optics,Physics",,8.902,"COUPLED-WAVE,ANALYSIS,ARTIFICIAL-INTELLIGENCE,MULTILAYER,SYSTEMS,NEURAL-NETWORK,OPTIMIZATION,METASURFACE,NANOSTRUCTURES,METAMATERIALS,RECOGNITION,FABRICATION",NANOPHOTONICS,https://doi.org/10.1515/nanoph-2019-0474,
17,MobileNetV2 Ensemble for Cervical Precancerous Lesions Classification,8,5,,"Buiu Catalin,Danaila Vlad-Rares,Raduta Cristina Nicoleta","Buiu C,Danaila VR,Raduta CN",Buiu C,10.3390/pr8050595,Polytechnic University of Bucharest,"Women's cancers remain a major challenge for many health systems. Between 1991 and 2017, the death rate for all major cancers fell continuously in the United States, excluding uterine cervix and uterine corpus cancers. Together with HPV (Human Papillomavirus) testing and cytology, colposcopy has played a central role in cervical cancer screening. This medical procedure allows physicians to view the cervix at a magnification of up to 10%. This paper presents an automated colposcopy image analysis framework for the classification of precancerous and cancerous lesions of the uterine cervix. This framework is based on an ensemble of MobileNetV2 networks. Our experimental results show that this method achieves accuracies of 83.33% and 91.66% on the four-class and binary classification tasks, respectively. These results are promising for the future use of automatic classification methods based on deep learning as tools to support medical doctors.","biomedical image processing,computer-aided diagnosis,cervical cancer,deep learning,transfer learning,MobileNetV2,ensemble",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Engineering,,2.824,"CONVOLUTIONAL,NEURAL-NETWORKS,CANCER,DIAGNOSIS,PREVENTION,CYTOLOGY,IMAGES",PROCESSES,https://www.mdpi.com/2227-9717/8/5/595/pdf,
18,A Simple and Sustainable Prediction Method of Liquefaction-Induced Settlement at Pohang Using an Artificial Neural Network,12,10,,"Park Sung-Sik,Ogunjinmi Peter D.,Woo Seung-Wook,Lee Dong-Eun","Park SS,Ogunjinmi PD,Woo SW,Lee DE",Lee DE,10.3390/su12104001,Kyungpook National University,"Conventionally, liquefaction-induced settlements have been predicted through numerical or analytical methods. In this study, a machine learning approach for predicting the liquefaction-induced settlement at Pohang was investigated. In particular, we examined the potential of an artificial neural network (ANN) algorithm to predict the earthquake-induced settlement at Pohang on the basis of standard penetration test (SPT) data. The performance of two ANN models for settlement prediction was studied and compared in terms of the R-2 correlation. Model 1 (input parameters: unit weight, corrected SPT blow count, and cyclic stress ratio (CSR)) showed higher prediction accuracy than model 2 (input parameters: depth of the soil layer, corrected SPT blow count, and the CSR), and the difference in the R2 correlation between the models was about 0.12. Subsequently, an optimal ANN model was used to develop a simple predictive model equation, which was implemented using a matrix formulation. Finally, the liquefaction-induced settlement chart based on the predictive model equation was proposed, and the applicability of the chart was verified by comparing it with the interferometric synthetic aperture radar (InSAR) image.","settlement,artificial neural network,liquefaction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Science & Technology - Other Topics,Environmental Sciences & Ecology",,3.473,"DEFORMATIONS,KOREA",SUSTAINABILITY,https://www.mdpi.com/2071-1050/12/10/4001/pdf,
19,"Recent Developments Regarding Painting Robots for Research in Automatic Painting, Artificial Creativity, and Machine Learning",10,10,,"Guelzow Joerg Marvin,Paetzold Patrick,Deussen Oliver","Gulzow JM,Paetzold P,Deussen O",Gulzow JM,10.3390/app10103396,University of Konstanz,"E-David (Electronic Drawing Apparatus for Vivid Image Display) is a system for controlling a variety of painting machines in order to create robotic paintings. This article summarizes the hardware set-up used for painting, along with recent developments, lessons learned from past painting machines, as well as plans for new approaches. We want to apply e-David as a platform for research towards improving automatic painting and to explore machine creativity. We present different painting machines, from small low-cost plotters to large industrial robots, and discuss the benefits and limitations of each type of platform and present their applicability to different tasks within the domain of robotic painting and artificial creativity research. A unified control interface with a scripting language allows users a simplified usage of different e-David-like machines. Furthermore, we present our system for automated stroke experimentation and recording, which is an advance towards allowing the machine to autonomously learn about brush dynamics. Finally, we also show how e-David can be used by artists ""in the field"" for different exhibitions.","robotics,painting,art,generative method,brush,brushstroke,data collection",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,GENERATION,APPLIED SCIENCES-BASEL,https://kops.uni-konstanz.de/bitstream/123456789/50170/1/Guelzow_2-kgk7jktayv9o5.pdf,
20,How Deeply to Fine-Tune a Convolutional Neural Network: A Case Study Using a Histopathology Dataset,10,10,,"Kandel Ibrahem,Castelli Mauro","Kandel I,Castelli M",Kandel I,10.3390/app10103359,Universidade Nova de Lisboa,"Accurate classification of medical images is of great importance for correct disease diagnosis. The automation of medical image classification is of great necessity because it can provide a second opinion or even a better classification in case of a shortage of experienced medical staff. Convolutional neural networks (CNN) were introduced to improve the image classification domain by eliminating the need to manually select which features to use to classify images. Training CNN from scratch requires very large annotated datasets that are scarce in the medical field. Transfer learning of CNN weights from another large non-medical dataset can help overcome the problem of medical image scarcity. Transfer learning consists of fine-tuning CNN layers to suit the new dataset. The main questions when using transfer learning are how deeply to fine-tune the network and what difference in generalization that will make. In this paper, all of the experiments were done on two histopathology datasets using three state-of-the-art architectures to systematically study the effect of block-wise fine-tuning of CNN. Results show that fine-tuning the entire network is not always the best option; especially for shallow networks, alternatively fine-tuning the top blocks can save both time and computational power and produce more robust classifiers.","convolutional neural network,image classification,transfer learning,medical images,deep learning,fine-tuning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://repozitorij.uni-lj.si/Dokument.php?lang=slv&id=139644&dn=,
21,Automatic Pancreas Segmentation Using Coarse-Scaled 2D Model of Deep Learning: Usefulness of Data Augmentation and Deep U-Net,10,10,,"Nishio Mizuho,Noguchi Shunjiro,Fujimoto Koji","Nishio M,Noguchi S,Fujimoto K",Nishio M,10.3390/app10103360,Kyoto University,"Combinations of data augmentation methods and deep learning architectures for automatic pancreas segmentation on CT images are proposed and evaluated. Images from a public CT dataset of pancreas segmentation were used to evaluate the models. Baseline U-net and deep U-net were chosen for the deep learning models of pancreas segmentation. Methods of data augmentation included conventional methods, mixup, and random image cropping and patching (RICAP). Ten combinations of the deep learning models and the data augmentation methods were evaluated. Four-fold cross validation was performed to train and evaluate these models with data augmentation methods. The dice similarity coefficient (DSC) was calculated between automatic segmentation results and manually annotated labels and these were visually assessed by two radiologists. The performance of the deep U-net was better than that of the baseline U-net with mean DSC of 0.703-0.789 and 0.686-0.748, respectively. In both baseline U-net and deep U-net, the methods with data augmentation performed better than methods with no data augmentation, and mixup and RICAP were more useful than the conventional method. The best mean DSC was obtained using a combination of deep U-net, mixup, and RICAP, and the two radiologists scored the results from this model as good or perfect in 76 and 74 of the 82 cases.","pancreas,segmentation,computed tomography,deep learning,data augmentation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,CT,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/10/3360/pdf,
22,Endoscopy-Driven Pretraining for Classification of Dysplasia in Barrett's Esophagus with Endoscopic Narrow-Band Imaging Zoom Videos,10,10,,"van der Putten Joost,Struyvenberg Maarten,de Groof Jeroen,Curvers Wouter,Schoon Erik,Baldaque-Silva Francisco,Bergman Jacques,van der Sommen Fons,de With Peter H. N.","van der Putten J,Struyvenberg M,de Groof J,Curvers W,Schoon E,Baldaque-Silva F,Bergman J,van der Sommen F,de With PHN",van der Putten J,10.3390/app10103407,Eindhoven University of Technology,"Featured Application This work focuses on the use of deep learning and convolutional neural networks to classify dysplasia in patients with Barrett's Esophagus. For this, we use the Narrow Band Imaging modality, which exploits different wavelengths to capture the tissue at different levels of penetration depth, leading to high-contrast imaging of mucosal and vascular patterns. Such patterns reveal information on histology, but they are hard to interpret for physicians. Our approach will aid the endoscopist in the interpretation of NBI imagery, leading to a higher false positive detections and a more robust diagnosis. In addition, this work also shows the potential benefits of using endoscopy-driven pretraining, instead of the more commonly used natural-image pretraining based on e.g., ImageNet.
Abstract Endoscopic diagnosis of early neoplasia in Barrett's Esophagus is generally a two-step process of primary detection in overview, followed by detailed inspection of any visible abnormalities using Narrow Band Imaging (NBI). However, endoscopists struggle with evaluating NBI-zoom imagery of subtle abnormalities. In this work, we propose the first results of a deep learning system for the characterization of NBI-zoom imagery of Barrett's Esophagus with an accuracy, sensitivity, and specificity of 83.6%, 83.1%, and 84.0%, respectively. We also show that endoscopy-driven pretraining outperforms two models, one without pretraining as well as a model with ImageNet initialization. The final model outperforms absence of pretraining by approximately 10% and the performance is 2% higher in terms of accuracy compared to ImageNet pretraining. Furthermore, the practical deployment of our model is not hampered by ImageNet licensing, thereby paving the way for clinical application.","endoscopic zoom imagery,Barrett's esophagus,deep learning,classification,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"ADENOCARCINOMA,VALIDATION,PATTERNS,MUCOSAL,SYSTEM",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/10/3407/pdf,
23,Improving Innovation from Science Using Kernel Tree Methods as a Precursor to Designed Experimentation,10,10,,"Young Timothy M.,Breyer Robert A.,Liles Terry,Petutschnigg Alexander","Young TM,Breyer RA,Liles T,Petutschnigg A",Young TM,10.3390/app10103387,University of Tennessee System,"A key challenge in applied science when planning a designed experiment is to determine the aliasing structure of the interaction effects and selecting the appropriate levels for the factors. In this study, kernel tree methods are used as precursors to identify significant interactions and levels of the factors useful for developing a designed experiment. This approach is aligned with integrating data science with the applied sciences to reduce the time from innovation in research and development to the advancement of new products, a very important consideration in today's world of rapid advancements in industries such as pharmaceutical, medicine, aerospace, etc. Significant interaction effects for six common independent variables using boosted trees and random forests of k = 1000 and k = 10,000 bootstraps were identified from industrial databases. The four common variables were related to speed, pressing time, pressing temperature, and fiber refining. These common variables maximized tensile strength of medium density fiberboard (MDF) and the ultimate static load of oriented strand board (OSB), both widely-used industrial products. Given the results of the kernel tree methods, four possible designs with interaction effects were developed: full factorial, fractional factorial Resolution IV, Box-Behnken, and Central Composite Designs (CCD).","kernel tree methods,interaction effects,aliasing structure,design experimentation,response surface methods",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"REGRESSION,TREES,CLASSIFICATION,TREES,VARIABLE,SELECTION",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/10/3387/pdf,
24,Durability Assessment of PVA Fiber-Reinforced Cementitious Composite Containing Nano-SiO2 Using Adaptive Neuro-Fuzzy Inference System,10,5,,"Liu Ting-Yu,Zhang Peng,Li Qing-Fu,Hu Shao-Wei,Ling Yi-Feng","Liu TY,Zhang P,Li QF,Hu SW,Ling YF",Zhang P,10.3390/cryst10050347,Zhengzhou University,"In this study, the durability of polyvinyl alcohol fiber-reinforced cementitious composite containing nano-SiO2 was evaluated using the adaptive neuro-fuzzy inference system (ANFIS). According to the structural characteristics of the cementitious composite material and some related standards, the classification criteria for the evaluation indices of cementitious composite materials were clarified, and a corresponding structural framework of durability assessment was constructed. Based on the hypothesis testing principle, the required test data capacity was determined under a certain degree of accuracy, and durability experimental data and expert evaluation results were simulated according to statistical principles to ensure that there were sufficient datasets for ANFIS training. Using an environmental factor submodule as an example, 14 sets of actual test data were used to verify that the ANFIS can quickly and effectively mimic the expert evaluation reasoning process to evaluate the durability of cementitious composites. Compared with other studies related to the durability of cementitious composites, a systematic evaluation system for the durability of concrete was established. We used a polyvinyl alcohol fiber-reinforced cementitious composite containing nano-SiO2 to conduct a comprehensive evaluation of cementitious composites. Compared with the traditional expert evaluation method, the durability evaluation system based on the ANFIS learned expert experience, stored the expert experience in fuzzy rules, and eliminated the subjectivity of expert evaluation, thereby making the evaluation more objective and scientific.","cementitious composite,nano-SiO2,PVA fiber,durability evaluation,adaptive neuro-fuzzy inference system",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Crystallography,Materials Science",,2.615,"CONCRETE,STRUCTURES,CHLORIDE,PENETRATION,RELIABILITY,TENSILE",CRYSTALS,https://www.mdpi.com/2073-4352/10/5/347/pdf,
25,Simulation methods for stochastic storage problems: a statistical learning perspective,11,2,377-415,"Ludkovski Michael,Maheshwari Aditya","Ludkovski M,Maheshwari A",Maheshwari A,10.1007/s12667-018-0318-4,University of California System,"We consider solution of stochastic storage problems through regression Monte Carlo methods. Taking a statistical learning perspective, we develop the dynamic emulation algorithm (DEA) that unifies the different existing approaches in a single modular template. We then investigate the two central aspects of regression architecture and experimental design that constitute DEA. For the regression piece, we discuss various non-parametric approaches, in particular introducing the use of Gaussian process regression in the context of stochastic storage. For simulation design, we compare the performance of traditional design (grid discretization), against space-filling, and several adaptive alternatives. The overall DEA template is illustrated with multiple examples drawing from natural gas storage valuation and optimal control of back-up generator in a microgrid.","Regression Monte Carlo,Simulation design,Gaussian process regression,Natural gas storage,Microgrid control",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Energy & Fuels,,,"SQUARES,MONTE-CARLO,VALUATION,OPTIMIZATION,OPTIONS,ALGORITHM,DESIGN",ENERGY SYSTEMS-OPTIMIZATION MODELING SIMULATION AND ECONOMIC ASPECTS,http://arxiv.org/pdf/1803.11309,
26,The Industry Internet of Things (IIoT) as a Methodology for Autonomous Diagnostics in Aerospace Structural Health Monitoring,7,5,,"Malik Sarah,Rouf Rakeen,Mazur Krzysztof,Kontsos Antonios","Malik S,Rouf R,Mazur K,Kontsos A",Kontsos A,10.3390/aerospace7050064,Drexel University,"Structural Health Monitoring (SHM), defined as the process that involves sensing, computing, and decision making to assess the integrity of infrastructure, has been plagued by data management challenges. The Industrial Internet of Things (IIoT), a subset of Internet of Things (IoT), provides a way to decisively address SHM's big data problem and provide a framework for autonomous processing. The key focus of IIoT is operational efficiency and cost optimization. The purpose, therefore, of the IIoT approach in this investigation is to develop a framework that connects nondestructive evaluation sensor data with real-time processing algorithms on an IoT hardware/software system to provide diagnostic capabilities for efficient data processing related to SHM. Specifically, the proposed IIoT approach is comprised of three components: the Cloud, the Fog, and the Edge. The Cloud is used to store historical data as well as to perform demanding computations such as off-line machine learning. The Fog is the hardware that performs real-time diagnostics using information received both from sensing and the Cloud. The Edge is the bottom level hardware that records data at the sensor level. In this investigation, an application of this approach to evaluate the state of health of an aerospace grade composite material at laboratory conditions is presented. The key link that limits human intervention in data processing is the implemented database management approach which is the particular focus of this manuscript. Specifically, a NoSQL database is implemented to provide live data transfer from the Edge to both the Fog and Cloud. Through this database, the algorithms used are capable to execute filtering by classification at the Fog level, as live data is recorded. The processed data is automatically sent to the Cloud for further operations such as visualization. The system integration with three layers provides an opportunity to create a paradigm for intelligent real-time data quality management.","Industrial Internet of Things (IIoT),big data,edge,fog,cloud,NoSQL,diagnostics",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Engineering,,1.688,,AEROSPACE,https://www.mdpi.com/2226-4310/7/5/64/pdf,
27,Adaptive Boosting Based Personalized Glucose Monitoring System (PGMS) for Non-Invasive Blood Glucose Prediction with Improved Accuracy,10,5,,"Anand Pradeep Kumar,Shin Dong Ryeol,Memon Mudasar Latif","Anand PK,Shin DR,Memon ML",Shin DR,10.3390/diagnostics10050285,Sungkyunkwan University (SKKU),"In this paper, we present an architecture of a personalized glucose monitoring system (PGMS). PGMS consists of both invasive and non-invasive sensors on a single device. Initially, blood glucose is measured invasively and non-invasively, to train the machine learning models. Then, paired data and corresponding errors are divided scientifically into six different clusters based on blood glucose ranges as per the patient's diabetic conditions. Each cluster is trained to build the unique error prediction model using an adaptive boosting (AdaBoost) algorithm. Later, these error prediction models undergo personalized calibration based on the patient's characteristics. Once, the errors in predicted non-invasive values are within the acceptable error range, the device gets personalized for a patient to measure the blood glucose non-invasively. We verify PGMS on two different datasets. Performance analysis shows that the mean absolute relative difference (MARD) is reduced exceptionally to 7.3% and 7.1% for predicted values as compared to 25.4% and 18.4% for measured non-invasive glucose values. The Clarke error grid analysis (CEGA) plot for non-invasive predicted values shows 97% data in Zone A and 3% data in Zone B for dataset 1. Moreover, for dataset 2 results echoed with 98% and 2% in Zones A and B, respectively.","diabetic care,non-invasive blood glucose monitoring,personalized calibration,machine learning,adaptive boosting,clustering,error prediction model",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,,DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7278000,
28,An Effective Mental Stress State Detection and Evaluation System Using Minimum Number of Frontal Brain Electrodes,10,5,,Attallah Omneya,Attallah O,Attallah O,10.3390/diagnostics10050292,Egyptian Knowledge Bank (EKB),"Currently, mental stress is a common social problem affecting people. Stress reduces human functionality during routine work and may lead to severe health defects. Detecting stress is important in education and industry to determine the efficiency of teaching, to improve education, and to reduce risks from human errors that might occur due to workers' stressful situations. Therefore, the early detection of mental stress using machine learning (ML) techniques is essential to prevent illness and health problems, improve quality of education, and improve industrial safety. The human brain is the main target of mental stress. For this reason, an ML system is proposed which investigates electroencephalogram (EEG) signal for thirty-six participants. Extracting useful features is essential for an efficient mental stress detection (MSD) system. Thus, this framework introduces a hybrid feature-set that feeds five ML classifiers to detect stress and non-stress states, and classify stress levels. To produce a reliable, practical, and efficient MSD system with a reduced number of electrodes, the proposed MSD scheme investigates the electrodes placements on different sites on the scalp and selects that site which has the higher impact on the accuracy of the system. Principal Component analysis is employed also, to reduce the features extracted from such electrodes to lower model complexity, where the optimal number of principal components is examined using sequential forward procedure. Furthermore, it examines the minimum number of electrodes placed on the site which has greater impact on stress detection and evaluation. To test the effectiveness of the proposed system, the results are compared with other feature extraction methods shown in literature. They are also compared with state-of-the-art techniques recorded for stress detection. The highest accuracies achieved in this study are 99.9%(sd = 0.015) and 99.26% (sd = 0.08) for identifying stress and non-stress states, and distinguishing between stress levels, respectively, using only two frontal brain electrodes for detecting stress and non-stress, and three frontal electrodes for evaluating stress levels respectively. The results show that the proposed system is reliable as the sensitivity is 99.9(0.064), 98.35(0.27), specificity is 99.94(0.02), 99.6(0.05), precision is 99.94(0.06), 98.9(0.23), and the diagnostics odd ratio (DOR) is >= 100 for detecting stress and non-stress, and evaluating stress levels respectively. This shows that the proposed framework has compelling performance and can be employed for stress detection and evaluation in medical, educational and industrial fields. Finally, the results verified the efficiency and reliability of the proposed system in predicting stress and non-stress on new patients, as the accuracy achieved 98.48% (sd = 1.12), sensitivity = 97.78% (sd = 1.84), specificity = 97.75% (sd = 2.05), precision = 99.26% (sd = 0.67), and DOR >= 100 using only two frontal electrodes.","electroencephalogram (EEG),mental stress detection (MSD),machine learning,mental arithmetic",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,,"FEATURE-EXTRACTION,FEATURE-SELECTION,EEG,CLASSIFICATION,RECOGNITION,INTERFACE,FRAMEWORK",DIAGNOSTICS,https://www.mdpi.com/2075-4418/10/5/292/pdf,
29,Deep Learning Based Automatic Malaria Parasite Detection from Blood Smear and Its Smartphone Based Application,10,5,,"Fuhad K. M. Faizullah,Tuba Jannat Ferdousey,Sarker Md Rabiul Ali,Momen Sifat,Mohammed Nabeel,Rahman Tanzilur","Fuhad KMF,Tuba JF,Sarker MRA,Momen S,Mohammed N,Rahman T",Rahman T,10.3390/diagnostics10050329,North South University (NSU),"Malaria is a life-threatening disease that is spread by the Plasmodium parasites. It is detected by trained microscopists who analyze microscopic blood smear images. Modern deep learning techniques may be used to do this analysis automatically. The need for the trained personnel can be greatly reduced with the development of an automatic accurate and efficient model. In this article, we propose an entirely automated Convolutional Neural Network (CNN) based model for the diagnosis of malaria from the microscopic blood smear images. A variety of techniques including knowledge distillation, data augmentation, Autoencoder, feature extraction by a CNN model and classified by Support Vector Machine (SVM) or K-Nearest Neighbors (KNN) are performed under three training procedures named general training, distillation training and autoencoder training to optimize and improve the model accuracy and inference performance. Our deep learning-based model can detect malarial parasites from microscopic images with an accuracy of 99.23% while requiring just over 4600 floating point operations. For practical validation of model efficiency, we have deployed the miniaturized model in different mobile phones and a server-backed web application. Data gathered from these environments show that the model can be used to perform inference under 1 s per sample in both offline (mobile only) and online (web application) mode, thus engendering confidence that such models may be deployed for efficient practical inferential systems.","Plasmodium parasites,microscopic,blood smear,data augmentation,CNN,knowledge distillation,Autoencoder,inference performance,floating point operations,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"POLYMERASE-CHAIN-REACTION,IMAGE-ANALYSIS,CLASSIFICATION,MICROSCOPY,DIAGNOSIS,SUPPORT",DIAGNOSTICS,https://europepmc.org/articles/pmc7277980?pdf=render,
30,Development of a Deep-Learning-Based Artificial Intelligence Tool for Differential Diagnosis between Dry and Neovascular Age-Related Macular Degeneration,10,5,,"Heo Tae-Young,Kim Kyoung Min,Min Hyun Kyu,Gu Sun Mi,Kim Jae Hyun,Yun Jaesuk,Min Jung Kee","Heo TY,Kim KM,Min HK,Gu SM,Kim JH,Yun J,Min JK",Yun J; Min JK,10.3390/diagnostics10050261,Chungbuk National University,"The use of deep-learning-based artificial intelligence (AI) is emerging in ophthalmology, with AI-mediated differential diagnosis of neovascular age-related macular degeneration (AMD) and dry AMD a promising methodology for precise treatment strategies and prognosis. Here, we developed deep learning algorithms and predicted diseases using 399 images of fundus. Based on feature extraction and classification with fully connected layers, we applied the Visual Geometry Group with 16 layers (VGG16) model of convolutional neural networks to classify new images. Image-data augmentation in our model was performed using Keras ImageDataGenerator, and the leave-one-out procedure was used for model cross-validation. The prediction and validation results obtained using the AI AMD diagnosis model showed relevant performance and suitability as well as better diagnostic accuracy than manual review by first-year residents. These results suggest the efficacy of this tool for early differential diagnosis of AMD in situations involving shortages of ophthalmology specialists and other medical devices.","age-related macular degeneration,class activation map,convolutional neural network,cross-validation,retina",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,,DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7277105,
31,Deep Learning-Based Morphological Classification of Human Sperm Heads,10,5,,"Iqbal Imran,Mustafa Ghulam,Ma Jinwen","Iqbal I,Mustafa G,Ma JW",Ma JW,10.3390/diagnostics10050325,Peking University,"Human infertility is considered as a serious disease of the reproductive system that affects more than 10% of couples across the globe and over 30% of the reported cases are related to men. The crucial step in the assessment of male infertility and subfertility is semen analysis that strongly depends on the sperm head morphology, i.e., the shape and size of the head of a spermatozoon. However, in medical diagnosis, the morphology of the sperm head is determined manually, and heavily depends on the expertise of the clinician. Moreover, this assessment as well as the morphological classification of human sperm heads are laborious and non-repeatable, and there is also a high degree of inter and intra-laboratory variability in the results. In order to overcome these problems, we propose a specialized convolutional neural network (CNN) architecture to accurately classify human sperm heads based on sperm images. It is carefully designed with several layers, and multiple filter sizes, but fewer filters and parameters to improve efficiency and effectiveness. It is demonstrated that our proposed architecture outperforms state-of-the-art methods, exhibiting 88% recall on the SCIAN dataset in the total agreement setting and 95% recall on the HuSHeM dataset for the classification of human sperm heads. Our proposed method shows the potential of deep learning to surpass embryologists in terms of reliability, throughput, and accuracy.","classification,convolutional neural network (CNN),deep learning,infertility,sperm head morphology",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,,DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7277990,
32,The Influence of Methylating Mutations on Acute Myeloid Leukemia: Preliminary Analysis on 56 Patients,10,5,,"Pasca Sergiu,Turcas Cristina,Jurj Ancuta,Teodorescu Patric,Iluta Sabina,Hotea Ionut,Bojan Anca,Selicean Cristina,Fetica Bogdan,Petrushev Bobe","Pasca S,Turcas C,Jurj A,Teodorescu P,Iluta S,Hotea I,Bojan A,Selicean C,Fetica B,Petrushev B",Tomuleasa C,10.3390/diagnostics10050263,Iuliu Hatieganu University of Medicine & Pharmacy,"Acute myeloid leukemia (AML) is a hematologic malignancy characterized by abnormal proliferation and a lack of differentiation of myeloid blasts. Considering the dismal prognosis this disease presents, several efforts have been made to better classify it and offer a tailored treatment to each subtype. This has been formally done by the World Health Organization (WHO) with the AML classification schemes from 2008 and 2016. Nonetheless, there are still mutations that are not currently included in the WHO AML classification, as in the case of some mutations that influence methylation. In this regard, the present study aimed to determine if some of the mutations that influence DNA methylation can be clustered together regarding methylation, expression, and clinical profile. Data from the TCGA LAML cohort were downloaded via cBioPortal. The analysis was performed using R 3.5.2, and the necessary packages for classical statistics, dimensionality reduction, and machine learning. We included only patients that presented mutations in DNMT3A, TET2, IDH1/2, ASXL1, WT1, and KMT2A. Afterwards, mutations that were present in too few patients were removed from the analysis, thus including a total of 57 AML patients. We observed that regarding expression, methylation, and clinical profile, patients with mutated TET2, IDH1/2, and WT1 presented a high degree of similarity, indicating the equivalence that these mutations present between themselves. Nonetheless, we did not observe this similarity between DNMT3A- and KMT2A-mutated AML. Moreover, when comparing the hypermethylating group with the hypomethylating one, we also observed important differences regarding expression, methylation, and clinical profile. In the current manuscript we offer additional arguments for the similarity of the studied hypermethylating mutations and suggest that those should be clustered together in further classifications. The hypermethylating and hypomethylating groups formed above were shown to be different from each other considering overall survival, methylation profile, expression profile, and clinical characteristics. In this manuscript, we present additional arguments for the similarity of the effect generated by TET2, IDH1/2, and WT1 mutations in AML patients. Thus, we hypothesize that hypermethylating mutations skew the AML cells to a similar phenotype with a possible sensitivity to hypermethylating agents.","acute myeloid leukemia,methylation,classification,TCGA,mutations",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"WORLD-HEALTH-ORGANIZATION,DNA,METHYLTRANSFERASE,IDH2,MUTATIONS,TET2,FUNCTION,AML,GENE,AZACITIDINE,DNMT3A,WT1,RNA",DIAGNOSTICS,https://europepmc.org/articles/pmc7277399?pdf=render,
33,Using Machine Learning to Predict Bacteremia in Febrile Children Presented to the Emergency Department,10,5,,"Tsai Chih-Min,Lin Chun-Hung Richard,Zhang Huan,Chiu I-Min,Cheng Chi-Yung,Yu Hong-Ren,Huang Ying-Hsien","Tsai CM,Lin CHR,Zhang H,Chiu IM,Cheng CY,Yu HR,Huang YH",Huang YH,10.3390/diagnostics10050307,Chang Gung Memorial Hospital,"Blood culture is frequently used to detect bacteremia in febrile children. However, a high rate of negative or false-positive blood culture results is common at the pediatric emergency department (PED). The aim of this study was to use machine learning to build a model that could predict bacteremia in febrile children. We conducted a retrospective case-control study of febrile children who presented to the PED from 2008 to 2015. We adopted machine learning methods and cost-sensitive learning to establish a predictive model of bacteremia. We enrolled 16,967 febrile children with blood culture tests during the eight-year study period. Only 146 febrile children had true bacteremia, and more than 99% of febrile children had a contaminant or negative blood culture result. The maximum area under the curve of logistic regression and support vector machines to predict bacteremia were 0.768 and 0.832, respectively. Using the predictive model, we can categorize febrile children by risk value into five classes. Class 5 had the highest probability of having bacteremia, while class 1 had no risk. Obtaining blood cultures in febrile children at the PED rarely identifies a causative pathogen. Prediction models can help physicians determine whether patients have bacteremia and may reduce unnecessary expenses.","machine learning,predict,bacteremia,children,emergency department",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"BLOOD,CULTURE,CONTAMINATION,C-REACTIVE-PROTEIN,OCCULT,BACTEREMIA,BACTERIAL-INFECTIONS,PRACTICE,GUIDELINE,YOUNG-CHILDREN,VACCINE,ERA,INFANTS,FEVER,PROCALCITONIN",DIAGNOSTICS,https://www.mdpi.com/2075-4418/10/5/307/pdf,
34,Investigation of Melt Pool Geometry Control in Additive Manufacturing Using Hybrid Modeling,10,5,,"Mondal Sudeepta,Gwynn Daniel,Ray Asok,Basak Amrita","Mondal S,Gwynn D,Ray A,Basak A",Basak A,10.3390/met10050683,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Metal additive manufacturing (AM) works on the principle of consolidating feedstock material in layers towards the fabrication of complex objects through localized melting and resolidification using high-power energy sources. Powder bed fusion and directed energy deposition are two widespread metal AM processes that are currently in use. During layer-by-layer fabrication, as the components continue to gain thermal energy, the melt pool geometry undergoes substantial changes if the process parameters are not appropriately adjusted on-the-fly. Although control of melt pool geometry via feedback or feedforward methods is a possibility, the time needed for changes in process parameters to translate into adjustments in melt pool geometry is of critical concern. A second option is to implement multi-physics simulation models that can provide estimates of temporal process parameter evolution. However, such models are computationally near intractable when they are coupled with an optimization framework for finding process parameters that can retain the desired melt pool geometry as a function of time. To address these challenges, a hybrid framework involving machine learning-assisted process modeling and optimization for controlling the melt pool geometry during the build process is developed and validated using experimental observations. A widely used 3D analytical model capable of predicting the thermal distribution in a moving melt pool is implemented and, thereafter, a nonparametric Bayesian, namely, Gaussian Process (GP), model is used for the prediction of time-dependent melt pool geometry (e.g., dimensions) at different values of the process parameters with excellent accuracy along with uncertainty quantification at the prediction points. Finally, a surrogate-assisted statistical learning and optimization architecture involving GP-based modeling and Bayesian Optimization (BO) is employed for predicting the optimal set of process parameters as the scan progresses to keep the melt pool dimensions at desired values. The results demonstrate that a model-based optimization can be significantly accelerated using tools of machine learning in a data-driven setting and reliable a priori estimates of process parameter evolution can be generated to obtain desired melt pool dimensions for the entire build process.","additive manufacturing,melt pool dimension control,machine learning,Gaussian process modeling,Bayesian Optimization,surrogate-assisted modeling",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Materials Science,Metallurgy & Metallurgical Engineering",,2.487,"SCANNING,LASER,EPITAXY,GLOBAL,OPTIMIZATION,MICROSTRUCTURE,PREDICTION,ALGORITHMS,SIMULATION,DEPOSITION,CHALLENGES,EVOLUTION,CMSX-4",METALS,https://www.mdpi.com/2075-4701/10/5/683/pdf,
35,Classification of Bainitic Structures Using Textural Parameters and Machine Learning Techniques,10,5,,"Mueller Martin,Britz Dominik,Ulrich Laura,Staudt Thorsten,Muecklich Frank","Muller M,Britz D,Ulrich L,Staudt T,Mucklich F",Muller M,10.3390/met10050630,Universitatsklinikum des Saarlandes,"Bainite is an essential constituent of modern high strength steels. In addition to the still great challenge of characterization, the classification of bainite poses difficulties. Challenges when dealing with bainite are the variety and amount of involved phases, the fineness and complexity of the structures and that there is often no consensus among human experts in labeling and classifying those. Therefore, an objective and reproducible characterization and classification is crucial. To achieve this, it is necessary to analyze the substructure of bainite using scanning electron microscope (SEM). This work will present how textural parameters (Haralick features and local binary pattern) calculated from SEM images, taken from specifically produced benchmark samples with defined structures, can be used to distinguish different bainitic microstructures by using machine learning techniques (support vector machine). For the classification task of distinguishing pearlite, granular, degenerate upper, upper and lower bainite as well as martensite a classification accuracy of 91.80% was achieved, by combining Haralick features and local binary pattern.","bainite,microstructure classification,textural parameters,Haralick parameters,local binary pattern,machine learning,support vector machine",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Materials Science,Metallurgy & Metallurgical Engineering",,2.487,"MICROSTRUCTURE,CLASSIFICATION,LOW-CARBON,STEEL,FEATURES",METALS,https://publikationen.sulb.uni-saarland.de/bitstream/20.500.11880/29460/1/metals-10-00630-v2.pdf,
36,Applying 3D U-Net Architecture to the Task of Multi-Organ Segmentation in Computed Tomography,25,1,43-50,Radiuk Pavlo,Radiuk P,Radiuk P,10.2478/acss-2020-0005,Ministry of Education & Science of Ukraine,"The achievement of high-precision segmentation in medical image analysis has been an active direction of research over the past decade. Significant success in medical imaging tasks has been feasible due to the employment of deep learning methods, including convolutional neural networks (CNNs). Convolutional architectures have been mostly applied to homogeneous medical datasets with separate organs. Nevertheless, the segmentation of volumetric medical images of several organs remains an open question. In this paper, we investigate fully convolutional neural networks (FCNs) and propose a modified 3D U-Net architecture devoted to the processing of computed tomography (CT) volumetric images in the automatic semantic segmentation tasks. To benchmark the architecture, we utilised the differentiable Sorensen-Dice similarity coefficient (SDSC) as a validation metric and optimised it on the training data by minimising the loss function. Our hand-crafted architecture was trained and tested on the manually compiled dataset of CT scans. The improved 3D U-Net architecture achieved the average SDSC score of 84.8 % on testing subset among multiple abdominal organs. We also compared our architecture with recognised state-of-the-art results and demonstrated that 3D U-Net based architectures could achieve competitive performance and efficiency in the multi-organ segmentation task.","Computed tomography volumetric images,fully convolutional neural networks,medical image analysis,multi-organ segmentation,Sorensen-Dice similarity coefficient",Article,"SCIENDO, BOGUMILA ZUGA 32A, WARSAW, MAZOVIA, POLAND",Computer Science,,,"CONVOLUTIONAL,NEURAL-NETWORKS,IMAGE,SEGMENTATION,DEEP,CANCER",APPLIED COMPUTER SYSTEMS,https://doi.org/10.2478/acss-2020-0005,
37,Secure multiparty computation for privacy-preserving drug discovery,36,9,2872-2880,"Ma Rong,Li Yi,Li Chenxing,Wan Fangping,Hu Hailin,Xu Wei,Zeng Jianyang","Ma R,Li Y,Li CX,Wan FP,Hu HL,Xu W,Zeng JY",Xu W; Zeng JY,10.1093/bioinformatics/btaa038,Tsinghua University,"Motivation: Quantitative structure-activity relationship (QSAR) and drug-target interaction (DTI) prediction are both commonly used in drug discovery. Collaboration among pharmaceutical institutions can lead to better performance in both QSAR and DTI prediction. However, the drug-related data privacy and intellectual property issues have become a noticeable hindrance for inter-institutional collaboration in drug discovery.
Results: We have developed two novel algorithms under secure multiparty computation (MPC), including QSARMPC and DTIMPC, which enable pharmaceutical institutions to achieve high-quality collaboration to advance drug discovery without divulging private drug-related information. QSARMPC, a neural network model under MPC, displays good scalability and performance and is feasible for privacy-preserving collaboration on large-scale QSAR prediction. DTIMPC integrates drug-related heterogeneous network data and accurately predicts novel DTIs, while keeping the drug information confidential. Under several experimental settings that reflect the situations in real drug discovery scenarios, we have demonstrated that DTIMPC possesses significant performance improvement over the baseline methods, generates novel DTI predictions with supporting evidence from the literature and shows the feasible scalability to handle growing DTI data. All these results indicate that QSARMPC and DTIMPC can provide practically useful tools for advancing privacy-preserving drug discovery.","INTERACTION PREDICTION,NEURAL NETS,DESIGN,INFORMATION,NETWORKS,BINDING,PROFILE",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Computer Science,Mathematical & Computational Biology,Mathematics",,8.47,"MACHINE,LEARNING,TECHNIQUES,INTERACTION,PREDICTION,NEURAL,NETS,DESIGN,INFORMATION,NETWORKS,BINDING,PROFILE",BIOINFORMATICS,,
38,3D-Cell-Annotator: an open-source active surface tool for single-cell segmentation in 3D microscopy images,36,9,2948-2949,"Tasnadi Ervin A.,Toth Timea,Kovacs Maria,Diosdi Akos,Pampaloni Francesco,Molnar Jozsef,Piccinini Filippo,Horvath Peter","Tasnadi EA,Toth T,Kovacs M,Diosdi A,Pampaloni F,Molnar J,Piccinini F,Horvath P",Horvath P,10.1093/bioinformatics/btaa029,Hungarian Academy of Sciences,"aSummary: Segmentation of single cells in microscopy images is one of the major challenges in computational biology. It is the first step of most bioimage analysis tasks, and essential to create training sets for more advanced deep learning approaches. Here, we propose 3D-Cell-Annotator to solve this task using 3D active surfaces together with shape descriptors as prior information in a semi-automated fashion. The software uses the convenient 3D interface of the widely used Medical Imaging Interaction Toolkit (MITK). Results on 3D biological structures (e.g. spheroids, organoids and embryos) show that the precision of the segmentation reaches the level of a human expert.",,Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Computer Science,Mathematical & Computational Biology,Mathematics",,8.47,,BIOINFORMATICS,http://real.mtak.hu/120216/1/btaa029.pdf,
39,Exploration of Chinese Sign Language Recognition Using Wearable Sensors Based on Deep Belief Net,24,5,1310-1320,"Yu Yi,Xiang Chen,Cao Shuai,Zhang Xu,Chen Xun","Yu Y,Xiang C,Cao S,Zhang X,Chen X",Xiang C,10.1109/JBHI.2019.2941535,"Univ Sci & Technol USTC, Dept Elect Sci & Tech Nol, Hefei 230026, Peoples R China.","In this paper, deep belief net (DBN) was applied into the field of wearable-sensor based Chinese sign language (CSL) recognition. Eight subjects were involved in the study, and all of the subjects finished a five-day experiment performing CSL on a target word set consisting of 150 CSL subwords. During the experiment, surface electromyography (sEMG), accelerometer (ACC), and gyroscope (GYRO) signals were collected from the participants. In order to obtain the optimal structure of the network, three different sensor fusion strategies, including data-level fusion, feature-level fusion, and decision-level fusion, were explored. In addition, for the feature-level fusion strategy, two different feature sources, which are hand-crafted features and network generated features, and two different network structures, which are fully-connected net and DBN, were also compared. The result showed that feature level fusion could achieve the best recognition accuracy among the three fusion strategies, and feature-level fusion with network generated features and DBN could achieve the best recognition accuracy. The best recognition accuracy realized in this study was 95.1% for the user-dependent test and 88.2% for the user-independent test. The significance of the study is that it applied the deep learning method into the field of wearable sensors-based CSL recognition, and according to our knowledge it's the first study comparing human engineered features with the network generated features in the correspondent field. The results from the study shed lights on the method of using network-generated features during sensor fusion and CSL recognition.","Feature extraction,Deep learning,Assistive technology,Gesture recognition,Training,Muscles,Electromyography,Chinese sign language,wearable sensors,electromyography,gyroscope,accelerometer,sensor fusion,deep learning,deep belief net",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"ACCELEROMETER,ENTROPY",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
40,A Hierarchical Neural Network for Sleep Stage Classification Based on Comprehensive Feature Learning and Multi-Flow Sequence Learning,24,5,1351-1366,"Sun Chenglu,Chen Chen,Li Wei,Fan Jiahao,Chen Wei","Sun CL,Chen C,Li W,Fan JH,Chen W",Chen C; Chen W,10.1109/JBHI.2019.2937558,Fudan University,"Automatic sleep staging methods usually extract hand-crafted features or network trained features from signals recorded by polysomnography (PSG), and then estimate the stages by various classifiers. In this study, we propose a classification approach based on a hierarchical neural network to process multi-channel PSG signals for improving the performance of automatic five-class sleep staging. The proposed hierarchical network contains two stages: comprehensive feature learning stage and sequence learning stage. The first stage is used to obtain the feature matrix by fusing the hand-crafted features and network trained features. A multi-flow recurrent neural network (RNN) as the second stage is utilized to fully learn temporal information between sleep epochs and fine-tune the parameters in the first stage. The proposed model was evaluated by 147 full night recordings in a public sleep database, the Montreal Archive of Sleep Studies (MASS). The proposed approach can achieve the overall accuracy of 0.878, and the F1-score is 0.818. The results show that the approach can achieve better performance compared to the state-of-the-art methods. Ablation experiment and model analysis proved the effectiveness of different components of the proposed model. The proposed approach allows automatic sleep stage classification by multi-channel PSG signals with different criteria standards, signal characteristics, and epoch divisions, and it has the potential to exploit sleep information comprehensively.","Sleep Stage Classification,Convolutional Neural Network,Recurrent Neural Network,EEG Signal",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"DECISION-SUPPORT-SYSTEM,RESOURCE",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
41,Progressive Transfer Learning and Adversarial Domain Adaptation for Cross-Domain Skin Disease Classification,24,5,1379-1393,"Gu Yanyang,Ge Zongyuan,Bonnington C. Paul,Zhou Jun","Gu YY,Ge ZY,Bonnington CP,Zhou J",Zhou J,10.1109/JBHI.2019.2942429,Griffith University,"Deep learning has been used to analyze and diagnose various skin diseases through medical imaging. However, recent researches show that a well-trained deep learning model may not generalize well to data from different cohorts due to domain shift. Simple data fusion techniques such as combining disease samples from different data sources are not effective to solve this problem. In this paper, we present two methods for a novel task of cross-domain skin disease recognition. Starting from a fully supervised deep convolutional neural network classifier pre-trained on ImageNet, we explore a two-step progressive transfer learning technique by fine-tuning the network on two skin disease datasets. We then propose to adopt adversarial learning as a domain adaptation technique to perform invariant attribute translation from source to target domain in order to improve the recognition performance. In order to evaluate these two methods, we analyze generalization capability of the trained model on melanoma detection, cancer detection, and cross-modality learning tasks on two skin image datasets collected from different clinical settings and cohorts with different disease distributions. The experiments prove the effectiveness of our method in solving the domain shift problem.","Skin,Adaptation models,Melanoma,Deep learning,Data models,Automatic melanoma detection,dermoscopy image,cycle-GAN,deep learning,transfer learning,domain adaptation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"DEEP,SEGMENTATION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
42,Unsupervised 3D End-to-End Medical Image Registration With Volume Tweening Network,24,5,1394-1404,"Zhao Shengyu,Lau Tingfung,Luo Ji,Chang Eric I-Chao,Xu Yan","Zhao SY,Lau TF,Luo J,Chang ERC,Xu Y",Xu Y,10.1109/JBHI.2019.2951024,Beihang University,"3D medical image registration is of great clinical importance. However, supervised learning methods require a large amount of accurately annotated corresponding control points (or morphing), which are very difficult to obtain. Unsupervised learning methods ease the burden of manual annotation by exploiting unlabeled data without supervision. In this article, we propose a new unsupervised learning method using convolutional neural networks under an end-to-end framework, Volume Tweening Network (VTN), for 3D medical image registration. We propose three innovative technical components: (1) An end-to-end cascading scheme that resolves large displacement; (2) An efficient integration of affine registration network; and (3) An additional invertibility loss that encourages backward consistency. Experiments demonstrate that our algorithm is 880x faster (or 3.3x faster without GPU acceleration) than traditional optimization-based methods and achieves state-of-the-art performance in medical image registration.","Biomedical imaging,Image registration,Transforms,Three-dimensional displays,Strain,Registers,Measurement,Registration,unsupervised,convolutional neural networks,end-to-end,medical image",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"LEARNING,FRAMEWORK",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://arxiv.org/pdf/1902.05020,
43,Deep Learning-Based Gleason Grading of Prostate Cancer From Histopathology Images-Role of Multiscale Decision Aggregation and Data Augmentation,24,5,1413-1426,"Karimi Davood,Nir Guy,Fazli Ladan,Black Peter C.,Goldenberg Larry,Salcudean Septimiu E.","Karimi D,Nir G,Fazli L,Black PC,Goldenberg L,Salcudean SE",Karimi D,10.1109/JBHI.2019.2944643,University of British Columbia,"Visual inspection of histopathology images of stained biopsy tissue by expert pathologists is the standard method for grading of prostate cancer (PCa). However, this process is time-consuming and subject to high inter-observer variability. Machine learning-based methods have the potential to improve efficient throughput of large volumes of slides while decreasing variability, but they are not easy to develop because they require substantial amounts of labeled training data. In this paper, we propose a deep learning-based classification technique and data augmentation methods for accurate grading of PCa in histopathology images in the presence of limited data. Our method combines the predictions of three separate convolutional neural networks (CNNs) that work with different patch sizes. This enables our method to take advantage of the greater amount of contextual information in larger patches as well as greater quantity of smaller patches in the labeled training data. The predictions produced by the three CNNs are combined using a logistic regression model, which is trained separately after the CNN training. To effectively train our models, we propose new data augmentation methods and empirically study their effects on the classification accuracy. The proposed method achieves an accuracy of $\text{92}\%$ in classifying cancerous patches versus benign patches and an accuracy of $\text{86}\%$ in classifying low-grade (i.e., Gleason grade 3) from high-grade (i.e., Gleason grades 4 and 5) patches. The agreement level of our automatic grading method with expert pathologists is within the range of agreement between pathologists. Our experiments indicate that data augmentation is necessary for achieving expert-level performance with deep learning-based methods. A combination of image-space augmentation and feature-space augmentation leads to the best results. Our study shows that well-designed and properly trained deep learning models can achieve PCa Gleason grading accuracy that is comparable to an expert pathologist.","Prostate cancer,Gleason grading,histopathology,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"ISUP,CONSENSUS,CONFERENCE,INTEROBSERVER,REPRODUCIBILITY,INTERNATIONAL-SOCIETY,MITOSIS,DETECTION,CARCINOMA,SMOTE,CLASSIFICATION,SEGMENTATION,VALIDATION,NUCLEI",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
44,Deep Learning for Smartphone-Based Malaria Parasite Detection in Thick Blood Smears,24,5,1427-1438,"Yang Feng,Poostchi Mandieh,Yu Hang,Zhou Zhou,Silamut Kamolrat,Yu Jian,Maude Richard J.,Jaeger Stefan,Antani Sameer","Yang F,Poostchi M,Yu H,Zhou Z,Silamut K,Yu J,Maude RJ,Jaeger S,Antani S",Yang F,10.1109/JBHI.2019.2939121,Beijing Jiaotong University,"Objective: This work investigates the possibility of automated malaria parasite detection in thick blood smears with smartphones. Methods: We have developed the first deep learning method that can detect malaria parasites in thick blood smear images and can run on smartphones. Our method consists of two processing steps. First, we apply an intensity-based Iterative Global Minimum Screening (IGMS), which performs a fast screening of a thick smear image to find parasite candidates. Then, a customized Convolutional Neural Network (CNN) classifies each candidate as either parasite or background. Together with this paper, we make a dataset of 1819 thick smear images from 150 patients publicly available to the research community. We used this dataset to train and test our deep learning method, as described in this paper. Results: A patient-level five-fold cross-evaluation demonstrates the effectiveness of the customized CNN model in discriminating between positive (parasitic) and negative image patches in terms of the following performance indicators: accuracy (93.46% +/- 0.32%), AUC (98.39% +/- 0.18%), sensitivity (92.59% +/- 1.27%), specificity (94.33% +/- 1.25%), precision (94.25% +/- 1.13%), and negative predictive value (92.74% +/- 1.09%). High correlation coefficients (>0.98) between automatically detected parasites and ground truth, on both image level and patient level, demonstrate the practicality of our method. Conclusion: Promising results are obtained for parasite detection in thick blood smears for a smartphone application using deep learning methods. Significance: Automated parasite detection running on smartphones is a promising alternative to manual parasite counting for malaria diagnosis, especially in areas lacking experienced parasitologists.","Feature extraction,Blood,Diseases,Support vector machines,Deep learning,Sensitivity,Image segmentation,Deep learning,convolutional neural networks,computer-aided diagnosis,malaria",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://ieeexplore.ieee.org/ielx7/6221020/9086632/08846750.pdf,
45,A Proteomics-Based Analysis Reveals Predictive Biological Patterns in Fabry Disease,9,5,,"Tebani Abdellah,Mauhin Wladimir,Abily-Donval Lenaig,Lesueur Celine,Berger Marc G.,Nadjar Yann,Berger Juliette,Benveniste Oliver,Lamari Foudil,Laforet Pascal","Tebani A,Mauhin W,Abily-Donval L,Lesueur C,Berger MG,Nadjar Y,Berger J,Benveniste O,Lamari F,Laforet P",Bekri S,10.3390/jcm9051325,CHU de Rouen,"Background: Fabry disease (FD) is an X-linked progressive lysosomal disease (LD) due to glycosphingolipid metabolism impairment. Currently, plasmatic globotriaosylsphingosine (LysoGb3) is used for disease diagnosis and monitoring. However, this biomarker is inconstantly increased in mild forms and in some female patients. Materials and Methods: We applied a targeted proteomic approach to explore disease-related biological patterns that might explain the disease pathophysiology. Forty proteins, involved mainly in inflammatory and angiogenesis processes, were assessed in 69 plasma samples retrieved from the French Fabry cohort (FFABRY) and from 83 healthy subjects. For predictive performance assessment, we also included other LD samples (Gaucher, Pompe and Niemann Pick C). Results: The study yielded four discriminant proteins that include three angiogenesis proteins (fibroblast growth factor 2 (FGF2), vascular endothelial growth factor A (VEGFA), vascular endothelial growth factor C (VEGFC)) and one cytokine interleukin 7 (IL-7). A clear elevation of FGF2 and IL-7 concentrations was observed in FD compared to other LD samples. No correlation was observed between these proteins and globotriaosylsphingosine (LysoGb3). A significant correlation exists between IL-7 and residual enzyme activity in a non-classical phenotype. This highlights the orthogonal biological information yielded by these proteins that might help in stratifying Fabry patients. Conclusion: This work highlights the potential of using proteomics approaches in exploring FD and enhancing FD diagnosis and therapeutic monitoring performances.","inborn errors of metabolism,Fabry disease,lysosomal storage diseases,proteomics,systems biology,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,,"ENZYME,REPLACEMENT,THERAPY,CARDIAC,VARIANT,GROWTH-FACTOR,PLASMA,GLOBOTRIAOSYLSPHINGOSINE,MASS,GLOBOTRIAOSYLCERAMIDE,PREVALENCE,DIAGNOSIS,URINE",JOURNAL OF CLINICAL MEDICINE,https://europepmc.org/articles/pmc7290805?pdf=render,
46,Optimal Operation Control of PV-Biomass Gasifier-Diesel-Hybrid Systems Using Reinforcement Learning Techniques,13,10,,"Kozlov Alexander N.,Tomin Nikita V.,Sidorov Denis N.,Lora Electo E. S.,Kurbatsky Victor G.","Kozlov AN,Tomin NV,Sidorov DN,Lora EES,Kurbatsky VG",Kozlov AN; Sidorov DN,10.3390/en13102632,Russian Academy of Sciences,"The importance of efficient utilization of biomass as renewable energy in terms of global warming and resource shortages are well known and documented. Biomass gasification is a promising power technology especially for decentralized energy systems. Decisive progress has been made in the gasification technologies development during the last decade. This paper deals with the control and optimization problems for an isolated microgrid combining the renewable energy sources (solar energy and biomass gasification) with a diesel power plant. The control problem of an isolated microgrid is formulated as a Markov decision process and we studied how reinforcement learning can be employed to address this problem to minimize the total system cost. The most economic microgrid configuration was found, and it uses biomass gasification units with an internal combustion engine operating both in single-fuel mode (producer gas) and in dual-fuel mode (diesel fuel and producer gas).","biomass,operations research,machine learning,microgrids,optimization,CO2 reduction,mixed integer linear programming,reinforcement learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"RENEWABLE,ENERGY,SYSTEM,WASTE-TO-ENERGY,POWER-GENERATION,CO-GASIFICATION,DOWNDRAFT,GASIFIERS,FUEL-CELL,COMBUSTION,OPTIMIZATION,DESIGN,WOOD",ENERGIES,https://www.mdpi.com/1996-1073/13/10/2632/pdf,
47,StressFoot: Uncovering the Potential of the Foot for Acute Stress Sensing in Sitting Posture,20,10,,"Elvitigala Don Samitha,Matthies Denys J. C.,Nanayakkara Suranga","Elvitigala DS,Matthies DJC,Nanayakkara S",Elvitigala DS,10.3390/s20102882,University of Auckland,"Stress is a naturally occurring psychological response and identifiable by several body signs. We propose a novel way to discriminate acute stress and relaxation, using movement and posture characteristics of the foot. Based on data collected from 23 participants performing tasks that induced stress and relaxation, we developed several machine learning models to construct the validity of our method. We tested our models in another study with 11 additional participants. The results demonstrated replicability with an overall accuracy of 87%. To also demonstrate external validity, we conducted a field study with 10 participants, performing their usual everyday office tasks over a working day. The results showed substantial robustness. We describe ten significant features in detail to enable an easy replication of our models.","stress sensing,smart insoles,smart shoes,unobtrusive sensing,stress,center of pressure",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"HEART-RATE-VARIABILITY,MUSCLE-ACTIVITY,EXPRESSION,NONCONTACT,PRESSURE,BODY",SENSORS,https://europepmc.org/articles/pmc7285061?pdf=render,
48,A Novel LSTM for Multivariate Time Series with Massive Missingness,20,10,,"Fouladgar Nazanin,Fraemling Kary","Fouladgar N,Framling K",Fouladgar N,10.3390/s20102832,Umea University,"Multivariate time series with missing data is ubiquitous when the streaming data is collected by sensors or any other recording instruments. For instance, the outdoor sensors gathering different meteorological variables may encounter low material sensitivity to specific situations, leading to incomplete information gathering. This is problematic in time series prediction with massive missingness and different missing rate of variables. Contribution addressing this problem on the regression task of meteorological datasets by employing Long Short-Term Memory (LSTM), capable of controlling the information flow with its memory unit, is still missing. In this paper, we propose a novel model called forward and backward variable-sensitive LSTM (FBVS-LSTM) consisting of two decay mechanisms and some informative data. The model inputs are mainly the missing indicator, time intervals of missingness in both forward and backward direction and missing rate of each variable. We employ this information to address the so-called missing not at random (MNAR) mechanism. Separately learning the features of each parameter, the model becomes adapted to deal with massive missingness. We conduct our experiment on three real-world datasets for the air pollution forecasting. The results demonstrate that our model performed well along with other LSTM-derivation models in terms of prediction accuracy.","multivariate time series,regression,massive missingness,LSTM",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"PREDICTION,IMPUTATION,MODEL,VALUES",SENSORS,http://umu.diva-portal.org/smash/get/diva2:1430880/FULLTEXT01,
49,Measurement System for Unsupervised Standardized Assessment of Timed ,20,10,,"Fudickar Sebastian,Hellmers Sandra,Lau Sandra,Diekmann Rebecca,Bauer Juergen M.,Hein Andreas","Fudickar S,Hellmers S,Lau S,Diekmann R,Bauer JM,Hein A",Fudickar S,10.3390/s20102824,Carl von Ossietzky Universitat Oldenburg,"Comprehensive and repetitive assessments are needed to detect physical changes in an older population to prevent functional decline at the earliest possible stage and to initiate preventive interventions. Established instruments like the Timed ""Up & Go"" (TUG) Test and the Sit-to-Stand Test (SST) require a trained person (e.g., physiotherapist) to assess physical performance. More often, these tests are only applied to a selected group of persons already functionally impaired and not to those who are at potential risk of functional decline. The article introduces the Unsupervised Screening System (USS) for unsupervised self-assessments by older adults and evaluates its validity for the TUG and SST. The USS included ambient and wearable movement sensors to measure the user's test performance. Sensor datasets of the USS's light barriers and Inertial Measurement Units (IMU) were analyzed for 91 users aged 73 to 89 years compared to conventional stopwatch measurement. A significant correlation coefficient of 0.89 for the TUG test and of 0.73 for the SST were confirmed among USS's light barriers. Correspondingly, for the inertial data-based measures, a high and significant correlation of 0.78 for the TUG test and of 0.87 for SST were also found. The USS was a validated and reliable tool to assess TUG and SST.","Timed ""Up & Go"" Test,TUG,Five Times Sit-to-Stand Test,5xSST,machine learning,assessment,unsupervised,functional,system usability,validity analysis,evaluation,inertial measurement units,technology",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"LOWER-EXTREMITY,FUNCTION,QUALITY-OF-LIFE,DETECTABLE,CHANGE,PHYSICAL-ACTIVITY,MUSCLE,STRENGTH,ELDERLY-PEOPLE,OLDER-PEOPLE,RELIABILITY,MOBILITY,DISABILITY",SENSORS,https://www.mdpi.com/1424-8220/20/10/2824/pdf,
50,IoT-Blockchain Enabled Optimized Provenance System for Food Industry 4.0 Using Advanced Deep Learning,20,10,,"Khan Prince Waqas,Byun Yung-Cheol,Park Namje","Khan PW,Byun YC,Park N",Byun YC,10.3390/s20102990,Jeju National University,"Agriculture and livestock play a vital role in social and economic stability. Food safety and transparency in the food supply chain are a significant concern for many people. Internet of Things (IoT) and blockchain are gaining attention due to their success in versatile applications. They generate a large amount of data that can be optimized and used efficiently by advanced deep learning (ADL) techniques. The importance of such innovations from the viewpoint of supply chain management is significant in different processes such as for broadened visibility, provenance, digitalization, disintermediation, and smart contracts. This article takes the secure IoT-blockchain data of Industry 4.0 in the food sector as a research object. Using ADL techniques, we propose a hybrid model based on recurrent neural networks (RNN). Therefore, we used long short-term memory (LSTM) and gated recurrent units (GRU) as a prediction model and genetic algorithm (GA) optimization jointly to optimize the parameters of the hybrid model. We select the optimal training parameters by GA and finally cascade LSTM with GRU. We evaluated the performance of the proposed system for a different number of users. This paper aims to help supply chain practitioners to take advantage of the state-of-the-art technologies; it will also help the industry to make policies according to the predictions of ADL.","livestock,internet of things,blockchain,advanced deep learning,industry 4,0,provenance",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"TRACEABILITY,SYSTEM,OIL",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7287702,
51,Fully Convolutional Deep Neural Networks with Optimized Hyperparameters for Detection of Shockable and Non-Shockable Rhythms,20,10,,"Krasteva Vessela,Menetre Sarah,Didon Jean-Philippe,Jekova Irena","Krasteva V,Menetre S,Didon JP,Jekova I",Jekova I,10.3390/s20102875,Bulgarian Academy of Sciences,"Deep neural networks (DNN) are state-of-the-art machine learning algorithms that can be learned to self-extract significant features of the electrocardiogram (ECG) and can generally provide high-output diagnostic accuracy if subjected to robust training and optimization on large datasets at high computational cost. So far, limited research and optimization of DNNs in shock advisory systems is found on large ECG arrhythmia databases from out-of-hospital cardiac arrests (OHCA). The objective of this study is to optimize the hyperparameters (HPs) of deep convolutional neural networks (CNN) for detection of shockable (Sh) and nonshockable (NSh) rhythms, and to validate the best HP settings for short and long analysis durations (2-10 s). Large numbers of (Sh + NSh) ECG samples were used for training (720 + 3170) and validation (739 + 5921) from Holters and defibrillators in OHCA. An end-to-end deep CNN architecture was implemented with one-lead raw ECG input layer (5 s, 125 Hz, 2.5 uV/LSB), configurable number of 5 to 23 hidden layers and output layer with diagnostic probability p is an element of [0: Sh,1: NSh]. The hidden layers contain N convolutional blocks x 3 layers (Conv1D (filters = Fi, kernel size = Ki), max-pooling (pool size = 2), dropout (rate = 0.3)), one global max-pooling and one dense layer. Random search optimization of HPs = {N, Fi, Ki}, i = 1, ... N in a large grid of N = [1, 2, ... 7], Fi = [5;50], Ki = [5;100] was performed. During training, the model with maximal balanced accuracy BAC = (Sensitivity + Specificity)/2 over 400 epochs was stored. The optimization principle is based on finding the common HPs space of a few top-ranked models and prediction of a robust HP setting by their median value. The optimal models for 1-7 CNN layers were trained with different learning rates LR = [10(-5); 10(-2)] and the best model was finally validated on 2-10 s analysis durations. A number of 4216 random search models were trained. The optimal models with more than three convolutional layers did not exhibit substantial differences in performance BAC = (99.31-99.5%). Among them, the best model was found with {N = 5, Fi = {20, 15, 15, 10, 5}, Ki = {10, 10, 10, 10, 10}, 7521 trainable parameters} with maximal validation performance for 5-s analysis (BAC = 99.5%, Se = 99.6%, Sp = 99.4%) and tolerable drop in performance (<2% points) for very short 2-s analysis (BAC = 98.2%, Se = 97.6%, Sp = 98.7%). DNN application in future-generation shock advisory systems can improve the detection performance of Sh and NSh rhythms and can considerably shorten the analysis duration complying with resuscitation guidelines for minimal hands-off pauses.","ECG,deep learning,convolutional neural networks,shock advisory system,life-threatening arrhythmias,ventricular fibrillation,out-of-hospital cardiac arrest",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"THREATENING,VENTRICULAR-ARRHYTHMIAS,FIBRILLATION,DETECTION,ANALYSIS,ALGORITHM,CLASSIFICATION,TACHYCARDIA,FREQUENCY,DEFIBRILLATION,DOMAIN,ADULTS",SENSORS,https://europepmc.org/articles/pmc7285174?pdf=render,
52,Industry 4.0 Lean Shopfloor Management Characterization Using EEG Sensors and Deep Learning,20,10,,"Schmidt Daniel,Villalba Diez Javier,Ordieres-Mere Joaquin,Gevers Roman,Schwiep Joerg,Molina Martin","Schmidt D,Diez JV,Ordieres-Mere J,Gevers R,Schwiep J,Molina M",Schmidt D; Diez JV,10.3390/s20102860,Universidad Politecnica de Madrid,"Achieving the shift towards Industry 4.0 is only feasible through the active integration of the shopfloor into the transformation process. Several shopfloor management (SM) systems can aid this conversion. They form two major factions. The first includes methodologies such as Balanced Scorecard (BSC). A defining feature is rigid structures to fixate on pre-defined goals. Other SM strategies instead concentrate on continuous improvement by giving directions. An example of this group is the ""HOSHIN KANRI TREE"" (HKT). One way of analyzing the dissimilarities, the advantages and disadvantages of these groups, is to examine the neurological patterns of workers as they are applying these. This paper aims to achieve this evaluation through non-invasive electroencephalography (EEG) sensors, which capture the electrical activity of the brain. A deep learning (DL) soft sensor is used to classify the recorded data with an accuracy of 96.5%. Through this result and an analysis using the correlations of the EEG signals, it has been possible to detect relevant characteristics and differences in the brain's activity. In conclusion, these findings are expected to help assess SM systems and give guidance to Industry 4.0 leaders.","EEG sensors,manufacturing systems,shopfloor management,machine learning,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"CROSS-CORRELATION,FREQUENCY-ANALYSIS,TEMPOROPARIETAL,JUNCTION,BALANCED,SCORECARD,NEURAL-NETWORKS,HOSHIN,KANRI,PERFORMANCE,CLASSIFICATION,COMPLEXITY,GRADIENT",SENSORS,https://www.mdpi.com/1424-8220/20/10/2860/pdf,
53,Drought Stress Detection Using Low-Cost Computer Vision Systems and Machine Learning Techniques,22,3,27-29,"Ramos-Giraldo Paula,Reberg-Horton Chris,Locke Anna M.,Mirsky Steven,Lobaton Edgar","Ramos-Giraldo P,Reberg-Horton C,Locke AM,Mirsky S,Lobaton E",Ramos-Giraldo P,10.1109/MITP.2020.2986103,University of North Carolina,"The real-time detection of drought stress has major implications for preventing cash crop yield loss due to variable weather conditions and ongoing climate change. The most widely used indicator of drought sensitivity/tolerance in corn and soybean is the presence or absence of leaf wilting during periods of water stress. We develop a low-cost automated drought detection system using computer vision coupled with machine learning (ML) algorithms that document the drought response in corn and soybeans field crops. Using ML, we predict the drought status of crop plants with more than 80% accuracy relative to expert-derived visual drought ratings.","Agriculture,Stress,Machine learning,Computer vision,Loss measurement,Stress measurement,Cameras",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Computer Science,Telecommunications",,3.126,,IT PROFESSIONAL,,
54,Machine Learning in the Assessment of Meat Quality,22,3,39-41,"Penning Bryan W.,Snelling Warren M.,Woodward-Greene M. Jennifer","Penning BW,Snelling WM,Woodward-Greene MJ",Penning BW,10.1109/MITP.2020.2986123,United States Department of Agriculture (USDA),"We compare two approaches to automate carcass quality grading using different artificial intelligence methods. The first is based on image analysis, and the second uses state-of-the-art Rapid Evaporative Ionization Mass Spectrometry. Both employ machine learning (ML) to increase the speed and accuracy of carcass quality evaluation. The image analysis method increased speed and accuracy for all quality measures except marbling when compared to human meat inspectors. The mass spectrometry method tested eight ML algorithms, and achieved an impressive 81.5% to 99% accuracy in predicting carcass quality traits. However, this accuracy was dependent on the trait examined, so ML algorithms were not the answer for all traits.","Prediction algorithms,Mass spectroscopy,Image analysis,Muscles,Cameras,Production,Artificial intelligence",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Computer Science,Telecommunications",,3.126,,IT PROFESSIONAL,,
55,Constructing realistic effective spin Hamiltonians with machine learning approaches,22,5,,"Li Xue-Yang,Lou Feng,Gong Xin-Gao,Xiang Hongjun","Li XY,Lou F,Gong XG,Xiang HJ",Xiang HJ,10.1088/1367-2630/ab85df,Fudan University,"The effective Hamiltonian method has recently received considerable attention due to its power to deal with finite-temperature problems and large-scale systems. In this work, we put forward a machine learning (ML) approach to generate realistic effective Hamiltonians. In order to find out the important interactions among many possible terms, we propose some new techniques. In particular, we suggest a new criterion to select models with less parameters using a penalty factor instead of the commonly-adopted additional penalty term, and we improve the efficiency of variable selection algorithms by estimating the importance of each possible parameter by its relative uncertainty and the error induced in the parameter reduction. We also employ a testing set and optionally a validation set to help prevent over-fitting problems. To verify the reliability and usefulness of our approach, we take two-dimensional MnO and three-dimensional TbMnO3 as examples. In the case of TbMnO3, our approach not only reproduces the known results that the Heisenberg, biquadratic, and ring exchange interactions are the major spin interactions, but also finds out that the next most important spin interactions are three-body fourth-order interactions. In both cases, we obtain effective spin Hamiltonians with high fitting accuracy. These tests suggest that our ML approach is powerful for identifying the effective spin Hamiltonians. Our ML approach is general so that it can be adopted to construct other effective Hamiltonians.","effective Hamiltonian,interaction terms,magnetic systems,machine learning,variable selection",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,3.741,"SIMULATIONS,EXCHANGE",NEW JOURNAL OF PHYSICS,https://doi.org/10.1088/1367-2630/ab85df,
56,"Analysis of Active Neutron Measurements From the Mars Science Laboratory Dynamic Albedo of Neutrons Instrument: Intrinsic Variability, Outliers, and Implications for Future Investigations",125,5,,"Kerner H. R.,Hardgrove C. J.,Czarnecki S.,Gabriel T. S. J.,Mitrofanov I. G.,Litvak M. L.,Sanin A. B.,Lisov D. I.","Kerner HR,Hardgrove CJ,Czarnecki S,Gabriel TSJ,Mitrofanov IG,Litvak ML,Sanin AB,Lisov DI",Kerner HR,10.1029/2019JE006264,University System of Maryland,"The Dynamic Albedo of Neutrons (DAN) instrument onboard Mars Science Laboratory uses neutron die-away, an active nuclear spectroscopy technique, to measure the abundance and depth distribution of hydrogen and neutron-absorbing elements (e.g., Fe and Cl) in the top similar to 0.5 m of the Mars subsurface. We examined the intrinsic variability in neutron die-away data using simulated DAN measurements with a range of compositions relevant to equatorial and high-latitude environments on Mars. Our analysis shows that the total neutron counts and timing of neutron arrival explain most variability in thermal neutron die-away curves for a DAN-like instrument configuration over homogeneous subsurfaces. We analyzed the variability in thermal neutron die-away across a variety of elemental compositions that might be observed by DAN or future instruments. We found that when H concentration is low (e.g., in equatorial regions including Gale crater), neutron die-away is most sensitive to variations in H. Conversely, when H concentration is high (e.g., in poleward regions of Mars or icy bodies), neutron die-away is most sensitive to variations in neutron absorbers. We estimated that the H and neutron absorber concentrations in DAN measurements acquired Sols 1-2080 in Gale crater and found that most measurements had low H and moderate absorber content. We presented an outlier analysis of these measurements to identify targets with high potential scientific impact and found that most outliers along the traverse corresponded with abnormally low or high neutron absorber content measurements, some of which may be associated with high-silica fracture-associated halos and felsic igneous material.","nuclear spectroscopy,Mars Science Laboratory,Mars,machine learning,outlier detection,statistical analysis",Article,"AMER GEOPHYSICAL UNION, 2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA",Geochemistry & Geophysics,,4.28,"DAN,EXPERIMENT,ONBOARD,GALE,CRATER,YELLOWKNIFE,BAY,ROCKS,CRUST,SPECTROMETER,CONSTRAINTS,HYDROGEN,CHEMCAM",JOURNAL OF GEOPHYSICAL RESEARCH-PLANETS,,
57,Machine learning-assisted cross-domain prediction of ionic conductivity in sodium and lithium-based superionic conductors using facile descriptors,4,5,,"Xu Yijie,Zong Yun,Hippalgaonkar Kedar","Xu YJ,Zong Y,Hippalgaonkar K",Zong Y; Hippalgaonkar K,10.1088/2399-6528/ab92d8,Agency for Science Technology & Research (ASTAR),"Solid state lithium- and sodium-ion batteries utilize solid ionically conducting compounds as electrolytes. However, the ionic conductivity of such materials tends to be lower than their liquid counterparts, necessitating research efforts into finding suitable alternatives. The process of electrolyte screening is often based on a mixture of domain expertise and trial-and-error, both of which are time and resource-intensive. In this work, we present a novel machine-learning based approach to predict the ionic conductivity of sodium and lithium-based SICON compounds. Using primarily theoretical elemental feature descriptors derivable from tabulated information on the unit cell and the atomic properties of the components of a target compound on a limited dataset of 70 NASICON-examples, we have designed a logistic regression-based model capable of distinguishing between poor and good superionic conductors with a validation accuracy of over 84%. Moreover, we demonstrate how such a system is capable of cross-domain classification on lithium-based examples with the same accuracy, despite being introduced to zero lithium-based compounds during training. Through a systematic permutation-based evaluation process, we reduced the number of considered features from 47 to 7, reduction of over 83%, while simultaneously improving model performance. The contributions of different electronic and structural features to overall ionic conductivity is also discussed, and contrasted with accepted theories in literature. Our results demonstrate the utility of such a facile tool in providing opportunities for initial screening of potential candidates as solid-state electrolytes through the use of existing data examples and simple tabulated or calculated features, reducing the time-to-market of such materials by helping to focus efforts on promising candidates. Given enough data utilizing suitable descriptors, high accurate cross-domain classifiers could be created for experimentalists, improving laboratory and computational efficiency.","machine learning,batteries,NASICON,classification,descriptors,ionic conductivity",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,,"CRYSTAL-CHEMISTRY,ELECTRICAL-CONDUCTIVITY,ELECTRODE,MATERIALS,SOLID,ELECTROLYTES,PHASE-TRANSITIONS,NASICON,MATERIALS,NA,STABILITY,TRANSPORT,IMPEDANCE",JOURNAL OF PHYSICS COMMUNICATIONS,https://iopscience.iop.org/article/10.1088/2399-6528/ab92d8/pdf,
58,EXpectation Propagation LOgistic REgRession on permissioned blockCHAIN (ExplorerChain): decentralized online healthcare/genomics predictive model learning,27,5,747-756,"Kuo Tsung-Ting,Gabriel Rodney A.,Cidambi Krishna R.,Ohno-Machado Lucila","Kuo TT,Gabriel RA,Cidambi KR,Ohno-Machado L",Ohno-Machado L,10.1093/jamia/ocaa023,University of California System,"Objective: Predicting patient outcomes using healthcare/genomics data is an increasingly popular/important area. However, some diseases are rare and require data from multiple institutions to construct generalizable models. To address institutional data protection policies, many distributed methods keep the data locally but rely on a central server for coordination, which introduces risks such as a single point of failure. We focus on providing an alternative based on a decentralized approach. We introduce the idea using blockchain technology for this purpose, with a brief description of its own potential advantages/disadvantages.
Materials and Methods: We explain how our proposed EXpectation Propagation LOgistic REgRession on Permissioned blockCHAIN (ExplorerChain) can achieve the same results when compared to a distributed model that uses a central server on 3 healthcare/genomic datasets, and what trade-offs need to be considered when using centralized/decentralized methods. We explain how the use of blockchain technology can help decrease some of the problems encountered in decentralized methods.
Results: We showed that the discrimination power of ExplorerChain can be statistically similar to its counterpart central server-based algorithm. While ExplorerChain inherited some benefits of blockchain, it had a small increased running time.
Discussion: ExplorerChain has the same prerequisites as a distributed model with a centralized server for coordination. In a manner similar to secure multi-party computation strategies, it assumes that participating institutions are honest, but ""curious.""
Conclusion: When evaluated on relatively small datasets, results suggest that ExplorerChain, which combines artificial intelligence and blockchain technologies, performs as well as a central server-based method, and may avoid some risks at the cost of efficiency.","blockchain distributed ledger technology,privacy-preserving predictive modeling,clinical information systems,decision support systems",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,,"PRIVACY,REPLACEMENT,DIAGNOSIS",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://europepmc.org/articles/pmc7309256?pdf=render,
59,Classifying non-small cell lung cancer types and transcriptomic subtypes using convolutional neural networks,27,5,757-769,"Yu Kun-Hsing,Wang Feiran,Berry Gerald J.,Re Christopher,Altman Russ B.,Snyder Michael,Kohane Isaac S.","Yu KH,Wang FR,Berry GJ,Re C,Altman RB,Snyder M,Kohane IS",Yu KH,10.1093/jamia/ocz230,Harvard University,"Objective: Non-small cell lung cancer is a leading cause of cancer death worldwide, and histopathological evaluation plays the primary role in its diagnosis. However, the morphological patterns associated with the molecular subtypes have not been systematically studied. To bridge this gap, we developed a quantitative histopathology analytic framework to identify the types and gene expression subtypes of non-small cell lung cancer objectively.
Materials and Methods: We processed whole-slide histopathology images of lung adenocarcinoma (n=427) and lung squamous cell carcinoma patients (n=457) in the Cancer Genome Atlas. We built convolutional neural networks to classify histopathology images, evaluated their performance by the areas under the receiver-operating characteristic curves (AUCs), and validated the results in an independent cohort (n=125).
Results: To establish neural networks for quantitative image analyses, we first built convolutional neural network models to identify tumor regions from adjacent dense benign tissues (AUCs > 0.935) and recapitulated expert pathologists' diagnosis (AUCs > 0.877), with the results validated in an independent cohort (AUCs=0.726-0.864). We further demonstrated that quantitative histopathology morphology features identified the major transcriptomic subtypes of both adenocarcinoma and squamous cell carcinoma (P<.01).
Discussion: Our study is the first to classify the transcriptomic subtypes of non-small cell lung cancer using fully automated machine learning methods. Our approach does not rely on prior pathology knowledge and can discover novel clinically relevant histopathology patterns objectively. The developed procedure is generalizable to other tumor types or diseases.","non-small cell lung cancer,transcriptomic subtypes,convolutional neural networks,machine learning,quantitative pathology",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"ARTIFICIAL-INTELLIGENCE,PLUS,CARBOPLATIN,CLASSIFICATION,ADENOCARCINOMA,STATISTICS,VALIDATION,PACLITAXEL,AGREEMENT,MODEL",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.biorxiv.org/content/biorxiv/early/2019/01/25/530360.full.pdf,
60,Validating the robustness of an internet of things based atrial fibrillation detection system,133,,55-61,"Faust Oliver,Kareem Murtadha,Shenfield Alex,Ali Ali,Acharya U. Rajendra","Faust O,Kareem M,Shenfield A,Ali A,Acharya UR",Faust O,10.1016/j.patrec.2020.02.005,Sheffield Hallam University,"This paper describes the validation of a deep learning model for Internet of Things (IoT) based health care applications. As such, the deep learning model was created to detect episodes of Atrial Fibrillation (AF) using Heart Rate (HR) signals. The initial Long Short-Term Memory (LSTM) model was developed using 20 data sets, from distinct subjects, obtained from the AFDB database on PhysioNet. This model achieved an AF detection accuracy of 98.51% with ten fold cross validation. In this study, we validated the initial results by testing the developed deep learning model with unknown data. To be specific, we fed the data from 82 subjects to the deep learning system and compared the classification results with the diagnosis results indicated by human practitioners. The validation results show 94% accuracy with an area under the Receiver Operating Characteristic (ROC) curve of 96.58. These results indicate that the LSTM model is able to extract the feature maps from the unknown data and hence detect the AF periods accurately. With this blindfold validation testing we violated a well known design rule for learning systems which states that more data should be used for training than for testing. By doing so, we have established that our deep learning system is fit for practical deployment, because in a practical situation the diagnosis support system must apply the knowledge, extracted from a limited training data set, to a HR trace from a patient. (C) 2020 Elsevier B.V. All rights reserved.","Intelligent internet of things,Deep learning,Atrial fibrillation,Heart rate,Blindfold validation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,,SIGNALS,PATTERN RECOGNITION LETTERS,,
61,"Diagnosis of carpal tunnel syndrome: A comparative study of shear wave elastography, morphometry and artificial intelligence techniques",133,,77-85,"Ardakani Ali Abbasian,Afshar Ahmadreza,Bhatt Shweta,Bureau Nathalie J.,Tahmasebi Aylin,Acharya U. Rajendra,Mohammadi Afshin","Ardakani AA,Afshar A,Bhatt S,Bureau NJ,Tahmasebi A,Acharya UR,Mohammadi A",Mohammadi A,10.1016/j.patrec.2020.02.020,Urmia University of Medical Sciences,"Ultrasonography is an acceptable modality to evaluate median nerve (MN) in patients with carpal tunnel syndrome (CTS). Additional investigations are needed to evaluate sonographic parameters and compare their performances with artificial intelligence (AI) methods. The aim of this study is to compare the performance of shear wave elastography, morphometry, and AI techniques to predict MN entrapment accurately. 200 wrists including 100 CTS and 100 control wrists were included. Twelve morphological and five elasticity parameters were measured from each MN. Two AI techniques namely, support vector machine (SVM), and convolutional neural network (CNN) were used to diagnose CTS. MN area with area under receiver-operating characteristic curve (AUC) of 0.949 and mean elasticity with AUC of 0.942 showed the highest performance to differentiate CTS from control wrists among morphological and elasticity parameters, respectively. The CNN achieved the best performance with AUC of 0.980, while SVM obtained AUC of 0.943 in testing dataset to diagnose CTC. MN is larger, stiffer, more irregular and extended in CTS patients. Deep learning technique yielded the highest performance in diagnosing CTS automatically. AI methods have vast potential to be implemented in clinical practice as an auxiliary tool for the assessment of CTS with high accuracy. (C) 2020 Elsevier B.V. All rights reserved.","Carpal tunnel syndrome,Ultrasonography,Elasticity imaging techniques,Deep learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,3.615,"MEDIAN,NERVE,ULTRASOUND,ELASTOGRAPHY,PRACTICE,PARAMETER,GRAY-SCALE,DOPPLER,ULTRASONOGRAPHY,SONOGRAPHY,SEVERITY,ACCURACY,RATIO",PATTERN RECOGNITION LETTERS,,
62,Smartwatch-Derived Data and Machine Learning Algorithms Estimate Classes of Ratings of Perceived Exertion in Runners: A Pilot Study,20,9,,"Davidson Padraig,Duking Peter,Zinner Christoph,Sperlich Billy,Hotho Andreas","Davidson P,Duking P,Zinner C,Sperlich B,Hotho A",Davidson P,10.3390/s20092637,University of Wurzburg,"The rating of perceived exertion (RPE) is a subjective load marker and may assist in individualizing training prescription, particularly by adjusting running intensity. Unfortunately, RPE has shortcomings (e.g., underreporting) and cannot be monitored continuously and automatically throughout a training sessions. In this pilot study, we aimed to predict two classes of RPE (<= 15 ""Somewhat hard to hard"" on Borg's 6-20 scale vs. RPE <mml:semantics>>15</mml:semantics> in runners by analyzing data recorded by a commercially-available smartwatch with machine learning algorithms. Twelve trained and untrained runners performed long-continuous runs at a constant self-selected pace to volitional exhaustion. Untrained runners reported their RPE each kilometer, whereas trained runners reported every five kilometers. The kinetics of heart rate, step cadence, and running velocity were recorded continuously ( 1<mml:semantics>Hz</mml:semantics>) with a commercially-available smartwatch (Polar V800). We trained different machine learning algorithms to estimate the two classes of RPE based on the time series sensor data derived from the smartwatch. Predictions were analyzed in different settings: accuracy overall and per runner type; i.e., accuracy for trained and untrained runners independently. We achieved top accuracies of <mml:semantics>84.8</mml:semantics>% for the whole dataset, <mml:semantics>81.8</mml:semantics>% for the trained runners, and <mml:semantics>86.1</mml:semantics>% for the untrained runners. We predict two classes of RPE with high accuracy using machine learning and smartwatch data. This approach might aid in individualizing training prescriptions.","artificial intelligence,endurance,exercise intensity,precision training,prediction,wearable",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7248997,
63,Real-Time Hand Gesture Recognition Using Surface Electromyography and Machine Learning: A Systematic Literature Review,20,9,,"Jaramillo-Yanez Andres,Benalcazar Marco E.,Mena-Maldonado Elisa","Jaramillo-Yanez A,Benalcazar ME,Mena-Maldonado E",Jaramillo-Yanez A,10.3390/s20092467,Escuela Politecnica Nacional Ecuador,"Today, daily life is composed of many computing systems, therefore interacting with them in a natural way makes the communication process more comfortable. Human-Computer Interaction (HCI) has been developed to overcome the communication barriers between humans and computers. One form of HCI is Hand Gesture Recognition (HGR), which predicts the class and the instant of execution of a given movement of the hand. One possible input for these models is surface electromyography (EMG), which records the electrical activity of skeletal muscles. EMG signals contain information about the intention of movement generated by the human brain. This systematic literature review analyses the state-of-the-art of real-time hand gesture recognition models using EMG data and machine learning. We selected and assessed 65 primary studies following the Kitchenham methodology. Based on a common structure of machine learning-based systems, we analyzed the structure of the proposed models and standardized concepts in regard to the types of models, data acquisition, segmentation, preprocessing, feature extraction, classification, postprocessing, real-time processing, types of gestures, and evaluation metrics. Finally, we also identified trends and gaps that could open new directions of work for future research in the area of gesture recognition using EMG.","human-computer interaction,hand gesture recognition,systematic literature review,machine learning,electromyography,real-time systems",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"PATTERN-RECOGNITION,MYOELECTRIC,CONTROL,CLASSIFICATION,SCHEME,MOTION,RECOGNITION,EMG,SIGNALS,EXTRACTION,WAVELET,ROBUST,IDENTIFICATION,INFORMATION",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7250028,
64,Recognition of Patient Groups with Sleep Related Disorders Using Bio-signal Processing and Deep Learning,20,9,,"Jarchi Delaram,Andreu-Perez Javier,Kiani Mehrin,Vysata Oldrich,Kuchynka Jiri,Prochazka Ales,Sanei Saeid","Jarchi D,Andreu-Perez J,Kiani M,Vysata O,Kuchynka J,Prochazka A,Sanei S",Jarchi D,10.3390/s20092594,University of Essex,"Accurately diagnosing sleep disorders is essential for clinical assessments and treatments. Polysomnography (PSG) has long been used for detection of various sleep disorders. In this research, electrocardiography (ECG) and electromayography (EMG) have been used for recognition of breathing and movement-related sleep disorders. Bio-signal processing has been performed by extracting EMG features exploiting entropy and statistical moments, in addition to developing an iterative pulse peak detection algorithm using synchrosqueezed wavelet transform (SSWT) for reliable extraction of heart rate and breathing-related features from ECG. A deep learning framework has been designed to incorporate EMG and ECG features. The framework has been used to classify four groups: healthy subjects, patients with obstructive sleep apnea (OSA), patients with restless leg syndrome (RLS) and patients with both OSA and RLS. The proposed deep learning framework produced a mean accuracy of 72% and weighted F1 score of 0.57 across subjects for our formulated four-class problem.","electrocardiography,electromyography,polysomnography,respiratory modulation,synchrosqueezed wavelet transform",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"RESTLESS,LEGS,SYNDROME,MOVEMENT,ENTROPY",SENSORS,http://irep.ntu.ac.uk/id/eprint/39782/1/1318853_Sanei.pdf,
65,Five Typical Stenches Detection Using an Electronic Nose,20,9,,"Jiang Wei,Gao Daqi","Jiang W,Gao DQ",Gao DQ,10.3390/s20092514,East China University of Science & Technology,"This paper deals with the classification of stenches, which can stimulate olfactory organs to discomfort people and pollute the environment. In China, the triangle odor bag method, which only depends on the state of the panelist, is widely used in determining odor concentration. In this paper, we propose a stenches detection system composed of an electronic nose and machine learning algorithms to discriminate five typical stenches. These five chemicals producing stenches are 2-phenylethyl alcohol, isovaleric acid, methylcyclopentanone, gamma -undecalactone, and 2-methylindole. We will use random forest, support vector machines, backpropagation neural network, principal components analysis (PCA), and linear discriminant analysis (LDA) in this paper. The result shows that LDA (support vector machine (SVM)) has better performance in detecting the stenches considered in this paper.","stenches detection,odor concentration,electronic nose",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,QUALITY,SENSORS,https://www.mdpi.com/1424-8220/20/9/2514/pdf,
66,Prediction of Visual Memorability with EEG Signals: A Comparative Study,20,9,,"Jo Sang-Yeong,Jeong Jin-Woo","Jo SY,Jeong JW",Jeong JW,10.3390/s20092694,Kumoh National University Technology,"Visual memorability is a method to measure how easily media contents can be memorized. Predicting the visual memorability of media contents has recently become more important because it can affect the design principles of multimedia visualization, advertisement, etc. Previous studies on the prediction of the visual memorability of images generally exploited visual features (e.g., color intensity and contrast) or semantic information (e.g., class labels) that can be extracted from images. Some other works tried to exploit electroencephalography (EEG) signals of human subjects to predict the memorability of text (e.g., word pairs). Compared to previous works, we focus on predicting the visual memorability of images based on human biological feedback (i.e., EEG signals). For this, we design a visual memory task where each subject is asked to answer whether they correctly remember a particular image 30 min after glancing at a set of images sampled from the LaMemdataset. During the visual memory task, EEG signals are recorded from subjects as human biological feedback. The collected EEG signals are then used to train various classification models for prediction of image memorability. Finally, we evaluate and compare the performance of classification models, including deep convolutional neural networks and classical methods, such as support vector machines, decision trees, and k-nearest neighbors. The experimental results validate that the EEG-based prediction of memorability is still challenging, but a promising approach with various opportunities and potentials.","visual memorability,electroencephalography,deep learning,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,,SENSORS,https://europepmc.org/articles/pmc7248904?pdf=render,
67,Investigating an Integrated Sensor Fusion System for Mental Fatigue Assessment for Demanding Maritime Operations,20,9,,"Monteiro Thiago Gabriel,Li Guoyuan,Skourup Charlotte,Zhang Houxiang","Monteiro TG,Li GY,Skourup C,Zhang HX",Zhang HX,10.3390/s20092588,Norwegian University of Science & Technology (NTNU),"Human-related issues are currently the most significant factor in maritime causalities, especially in demanding operations that require coordination between two or more vessels and/or other maritime structures. Some of these human-related issues include incorrect, incomplete, or nonexistent following of procedures; lack of situational awareness; and physical or mental fatigue. Among these, mental fatigue is especially dangerous, due to its capacity to reduce reaction time, interfere in the decision-making process, and affect situational awareness. Mental fatigue is also especially hard to identify and quantify. Self-assessment of mental fatigue may not be reliable and few studies have assessed mental fatigue in maritime operations, especially in real time. In this work we propose an integrated sensor fusion system for mental fatigue assessment using physiological sensors and convolutional neural networks. We show, by using a simulated navigation experiment, how data from different sensors can be fused into a robust mental fatigue assessment tool, capable of achieving up to <mml:semantics>100%</mml:semantics> detection accuracy for single-subject classification. Additionally, the use of different sensors seems to favor the representation of the transition between mental fatigue states.","physiological sensors,mental fatigue,maritime operations,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,SLEEPINESS,SENSORS,https://ntnuopen.ntnu.no/ntnu-xmlui/bitstream/11250/2658943/1/sensors-20-02588-v2%2b%25281%2529.pdf,
68,A Wearable System to Objectify Assessment of Motor Tasks for Supporting Parkinson's Disease Diagnosis,20,9,,"Rovini Erika,Maremmani Carlo,Cavallo Filippo","Rovini E,Maremmani C,Cavallo F",Rovini E,10.3390/s20092630,Scuola Superiore Sant'Anna,"Objective assessment of the motor evaluation test for Parkinson's disease (PD) diagnosis is an open issue both for clinical and technical experts since it could improve current clinical practice with benefits both for patients and healthcare systems. In this work, a wearable system composed of four inertial devices (two SensHand and two SensFoot), and related processing algorithms for extracting parameters from limbs motion was tested on 40 healthy subjects and 40 PD patients. Seventy-eight and 96 kinematic parameters were measured from lower and upper limbs, respectively. Statistical and correlation analysis allowed to define four datasets that were used to train and test five supervised learning classifiers. Excellent discrimination between the two groups was obtained with all the classifiers (average accuracy ranging from 0.936 to 0.960) and all the datasets (average accuracy ranging from 0.953 to 0.966), over three conditions that included parameters derived from lower, upper or all limbs. The best performances (accuracy = 1.00) were obtained when classifying all the limbs with linear support vector machine (SVM) or gaussian SVM. Even if further studies should be done, the current results are strongly promising to improve this system as a support tool for clinicians in objectifying PD diagnosis and monitoring.","decision support system,motion analysis,motor assessment,Parkinson's disease diagnosis,signal processing,supervised learning,wearable inertial devices",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,GESTURE,SENSORS,https://www.mdpi.com/1424-8220/20/9/2630/pdf,
69,An Intelligent Non-Invasive Real-Time Human Activity Recognition System for Next-Generation Healthcare,20,9,,"Taylor William,Shah Syed Aziz,Dashtipour Kia,Zahid Adnan,Abbasi Qammer H.,Imran Muhammad Ali","Taylor W,Shah SA,Dashtipour K,Zahid A,Abbasi QH,Imran MA",Taylor W,10.3390/s20092653,University of Glasgow,"Human motion detection is getting considerable attention in the field of Artificial Intelligence (AI) driven healthcare systems. Human motion can be used to provide remote healthcare solutions for vulnerable people by identifying particular movements such as falls, gait and breathing disorders. This can allow people to live more independent lifestyles and still have the safety of being monitored if more direct care is needed. At present wearable devices can provide real-time monitoring by deploying equipment on a person's body. However, putting devices on a person's body all the time makes it uncomfortable and the elderly tend to forget to wear them, in addition to the insecurity of being tracked all the time. This paper demonstrates how human motions can be detected in a quasi-real-time scenario using a non-invasive method. Patterns in the wireless signals present particular human body motions as each movement induces a unique change in the wireless medium. These changes can be used to identify particular body motions. This work produces a dataset that contains patterns of radio wave signals obtained using software-defined radios (SDRs) to establish if a subject is standing up or sitting down as a test case. The dataset was used to create a machine learning model, which was used in a developed application to provide a quasi-real-time classification of standing or sitting state. The machine-learning model was able to achieve 96.70% accuracy using the Random Forest algorithm using 10 fold cross-validation. A benchmark dataset of wearable devices was compared to the proposed dataset and results showed the proposed dataset to have similar accuracy of nearly 90%. The machine-learning models developed in this paper are tested for two activities but the developed system is designed and applicable for detecting and differentiating x number of activities.","human motion detection,machine learning,random forest,KNN,SVM,neural networks,USRP,channel state information,real-time classification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"INTERNET,RADAR",SENSORS,http://eprints.gla.ac.uk/215018/1/215018.pdf,
70,Intelligent Machine Learning Approach for Effective Recognition of Diabetes in E-Healthcare Using Clinical Data,20,9,,"Ul Haq Amin,Li Jian Ping,Khan Jalaluddin,Memon Muhammad Hammad,Nazir Shah,Ahmad Sultan,Khan Ghufran Ahmad,Ali Amjad","Ul Haq A,Li JP,Khan J,Memon MH,Nazir S,Ahmad S,Khan GA,Ali A",Ul Haq A,10.3390/s20092649,University of Electronic Science & Technology of China,"Significant attention has been paid to the accurate detection of diabetes. It is a big challenge for the research community to develop a diagnosis system to detect diabetes in a successful way in the e-healthcare environment. Machine learning techniques have an emerging role in healthcare services by delivering a system to analyze the medical data for diagnosis of diseases. The existing diagnosis systems have some drawbacks, such as high computation time, and low prediction accuracy. To handle these issues, we have proposed a diagnosis system using machine learning methods for the detection of diabetes. The proposed method has been tested on the diabetes data set which is a clinical dataset designed from patient's clinical history. Further, model validation methods, such as hold out, K-fold, leave one subject out and performance evaluation metrics, includes accuracy, specificity, sensitivity, F1-score, receiver operating characteristic curve, and execution time have been used to check the validity of the proposed system. We have proposed a filter method based on the Decision Tree (Iterative Dichotomiser 3) algorithm for highly important feature selection. Two ensemble learning algorithms, Ada Boost and Random Forest, are also used for feature selection and we also compared the classifier performance with wrapper based feature selection algorithms. Classifier Decision Tree has been used for the classification of healthy and diabetic subjects. The experimental results show that the proposed feature selection algorithm selected features improve the classification performance of the predictive model and achieved optimal accuracy. Additionally, the proposed system performance is high compared to the previous state-of-the-art methods. High performance of the proposed method is due to the different combinations of selected features set and Plasma glucose concentrations, Diabetes pedigree function, and Blood mass index are more significantly important features in the dataset for prediction of diabetes. Furthermore, the experimental results statistical analysis demonstrated that the proposed method would effectively detect diabetes and can be deployed in an e-healthcare environment.","diabetes disease,feature selection,e-healthcare,decision tree,performance,machine learning,medical data",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"DISEASE,DIAGNOSIS,CLASSIFICATION,SYSTEM,ALGORITHMS,PREDICTION,SELECTION,DESIGN,MODEL",SENSORS,https://europepmc.org/articles/pmc7249007?pdf=render,
71,A Strictly Unsupervised Deep Learning Method for HEp-2 Cell Image Classification,20,9,,"Vununu Caleb,Lee Suk-Hwan,Kwon Ki-Ryong","Vununu C,Lee SH,Kwon KR",Kwon KR,10.3390/s20092717,Pukyong National University,"Classifying the images that portray the Human Epithelial cells of type 2 (HEp-2) represents one of the most important steps in the diagnosis procedure of autoimmune diseases. Performing this classification manually represents an extremely complicated task due to the heterogeneity of these cellular images. Hence, an automated classification scheme appears to be necessary. However, the majority of the available methods prefer to utilize the supervised learning approach for this problem. The need for thousands of images labelled manually can represent a difficulty with this approach. The first contribution of this work is to demonstrate that classifying HEp-2 cell images can also be done using the unsupervised learning paradigm. Unlike the majority of the existing methods, we propose here a deep learning scheme that performs both the feature extraction and the cells' discrimination through an end-to-end unsupervised paradigm. We propose the use of a deep convolutional autoencoder (DCAE) that performs feature extraction via an encoding-decoding scheme. At the same time, we embed in the network a clustering layer whose purpose is to automatically discriminate, during the feature learning process, the latent representations produced by the DCAE. Furthermore, we investigate how the quality of the network's reconstruction can affect the quality of the produced representations. We have investigated the effectiveness of our method on some benchmark datasets and we demonstrate here that the unsupervised learning, when done properly, performs at the same level as the actual supervised learning-based state-of-the-art methods in terms of accuracy.","HEp-2 cell images classification,computer-aided diagnosis,pattern recognition,deep learning,convolutional autoencoders,cell images clustering",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"TEXTURAL,FEATURES",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7249201,
72,"IGRNet: A Deep Learning Model for Non-Invasive, Real-Time Diagnosis of Prediabetes through Electrocardiograms",20,9,,"Wang Liyang,Mu Yao,Zhao Jing,Wang Xiaoya,Che Huilian","Wang LY,Mu Y,Zhao J,Wang XY,Che HL",Che HL,10.3390/s20092556,China Agricultural University,"The clinical symptoms of prediabetes are mild and easy to overlook, but prediabetes may develop into diabetes if early intervention is not performed. In this study, a deep learning model-referred to as IGRNet-is developed to effectively detect and diagnose prediabetes in a non-invasive, real-time manner using a 12-lead electrocardiogram (ECG) lasting 5 s. After searching for an appropriate activation function, we compared two mainstream deep neural networks (AlexNet and GoogLeNet) and three traditional machine learning algorithms to verify the superiority of our method. The diagnostic accuracy of IGRNet is 0.781, and the area under the receiver operating characteristic curve (AUC) is 0.777 after testing on the independent test set including mixed group. Furthermore, the accuracy and AUC are 0.856 and 0.825, respectively, in the normal-weight-range test set. The experimental results indicate that IGRNet diagnoses prediabetes with high accuracy using ECGs, outperforming existing other machine learning methods; this suggests its potential for application in clinical practice as a non-invasive, prediabetes diagnosis technology.","prediabetes,12-lead ECG,deep learning,high-accuracy diagnosis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"HEART-RATE-VARIABILITY,ECG,CLASSIFICATION,ASSOCIATION,GLUCOSE,RISK",SENSORS,https://www.mdpi.com/1424-8220/20/9/2556/pdf,
73,Stress Evaluation in Simulated Autonomous and Manual Driving through the Analysis of Skin Potential Response and Electrocardiogram Signals,20,9,,"Zontone Pamela,Affanni Antonio,Bernardini Riccardo,Del Linz Leonida,Piras Alessandro,Rinaldo Roberto","Zontone P,Affanni A,Bernardini R,Del Linz L,Piras A,Rinaldo R",Rinaldo R,10.3390/s20092494,University of Udine,"The evaluation of car drivers' stress condition is gaining interest as research on Autonomous Driving Systems (ADS) progresses. The analysis of the stress response can be used to assess the acceptability of ADS and to compare the driving styles of different autonomous drive algorithms. In this contribution, we present a system based on the analysis of the Electrodermal Activity Skin Potential Response (SPR) signal, aimed to reveal the driver's stress induced by different driving situations. We reduce motion artifacts by processing two SPR signals, recorded from the hands of the subjects, and outputting a single clean SPR signal. Statistical features of signal blocks are sent to a Supervised Learning Algorithm, which classifies between stress and normal driving (non-stress) conditions. We present the results obtained from an experiment using a professional driving simulator, where a group of people is asked to undergo manual and autonomous driving on a highway, facing some unexpected events meant to generate stress. The results of our experiment show that the subjects generally appear more stressed during manual driving, indicating that the autonomous drive can possibly be well received by the public. During autonomous driving, however, significant peaks of the SPR signal are evident during unexpected events. By examining the electrocardiogram signal, the average heart rate is generally higher in the manual case compared to the autonomous case. This further supports our previous findings, even if it may be due, in part, to the physical activity involved in manual driving.","autonomous driving,stress recognition,skin potential response,electrocardiogram,supervised learning algorithm",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"DRIVERS,STRESS,VEHICLES,SYSTEM",SENSORS,https://europepmc.org/articles/pmc7249664?pdf=render,
74,A Bioinspired Wireless Epidermal Photoreceptor for Artificial Skin Vision,30,22,,"Zhang Yujia,Tao Tiger H.","Zhang YJ,Tao TH",Tao TH,10.1002/adfm.202000381,Chinese Academy of Sciences,"Skin vision can be found in many invertebrates, such as earthworms, jellyfish, and octopuses using light-sensitive rod cells in the skin. It enables optical perception and colorimetric responses, providing intriguing capabilities that human skin does not have. A bioinspired wireless, battery-free, artificial skin vision (ASV) device consisting of flexible optical and optoelectronic components which essentially mimic the hierarchical structures and biological functions of rod cells in a skin-like configuration for light sensing and signal processing is developed. The ASV device can collect sweat with integrated microfluidic channels and allow real-time measurement of on-skin fluids by monitoring the intrinsic optical properties via a customizable microprism light filter. The device also shows sensitive colorimetric responses to input stimulus at chosen detection wavelengths and demonstrates a capacity for in situ quantitative analysis of biomarkers in sweat through alternative colorimetric light filters. Multiple ASVs together create a body area network with a collection of wireless sensors that can work in parallel to acquire multidimensional human physiological signals and predict fitness variations using a specified deep learning neural network. The system has potential applications in biomimetic engineering, physiological monitoring, and intelligent personalized diagnostics.","bioinspired devices,deep learning,epidermal electronics,physiological monitoring,wearable photoreceptors",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,18.125,"LIGHT,EARTHWORM,STARFISH,HISTORY",ADVANCED FUNCTIONAL MATERIALS,,
75,Toward Edge-Based Deep Learning in Industrial Internet of Things,7,5,4329-4341,"Liang Fan,Yu Wei,Liu Xing,Griffith David,Golmie Nada","Liang F,Yu W,Liu X,Griffith D,Golmie N",Yu W,10.1109/JIOT.2019.2963635,University System of Maryland,"As a typical application of the Internet of Things (IoT), the Industrial IoT (IIoT) connects all the related IoT sensing and actuating devices ubiquitously so that the monitoring and control of numerous industrial systems can be realized. Deep learning, as one viable way to carry out big-data-driven modeling and analysis, could be integrated in IIoT systems to aid the automation and intelligence of IIoT systems. As deep learning requires large computation power, it is commonly deployed in cloud servers. Thus, the data collected by IoT devices must be transmitted to the cloud for training process, contributing to network congestion and affecting the IoT network performance as well as the supported applications. To address this issue, in this article, we leverage the fog/edge computing paradigm and propose an edge computing-based deep learning model, which utilizes edge computing to migrate the deep learning process from cloud servers to edge nodes, reducing data transmission demands in the IIoT network and mitigating network congestion. Since edge nodes have limited computation ability compared to servers, we design a mechanism to optimize the deep learning model so that its requirements for computational power can be reduced. To evaluate our proposed solution, we design a testbed implemented in the Google cloud and deploy the proposed convolutional neural network (CNN) model, utilizing a real-world IIoT data set to evaluate our approach. (1) Our experimental results confirm the effectiveness of our approach, which cannot only reduce the network traffic overhead for IIoT but also maintain the classification accuracy in comparison with several baseline schemes. (1) Certain commercial equipment, instruments, or materials are identified in this article in order to specify the experimental procedure adequately. Such identification is not intended to imply recommendation or endorsement by the National Institute of Standards and Technology, nor is it intended to imply that the materials or equipment identified are necessarily the best available for the purpose.","Distributed deep learning,edge computing,fog computing,Industrial Internet of Things (IIoT)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,10.127,"BIG,DATA,NETWORKS,SECURITY",IEEE INTERNET OF THINGS JOURNAL,,
76,Classification of Decompensated Heart Failure From Clinical and Home Ballistocardiography,67,5,1303-1313,"Aydemir Varol Burak,Nagesh Supriya,Shandhi Md. Mobashir Hasan,Fan Joanna,Klein Liviu,Etemadi Mozziyar,Heller James Alex,Inan Omer T.,Rehg James M.","Aydemir VB,Nagesh S,Shandhi MMH,Fan JN,Klein L,Etemadi M,Heller JA,Inan OT,Rehg JM",Aydemir VB,10.1109/TBME.2019.2935619,University System of Georgia,"Objective: To improve home monitoring of heart failure patients so as to reduce emergency room visits and hospital readmissions. We aim to do this by analyzing the ballistocardiogram (BCG) to evaluate the clinical state of the patient. Methods: 1) High quality BCG signals were collected at home from HF patients after discharge. 2) The BCG recordings were preprocessed to exclude outliers and artifacts. 3) Parameters of the BCG that contain information about the cardiovascular system were extracted. These features were used for the task of classification of the BCG recording based on the status of HF. Results: The best AUC score for the task of classification obtained was 0.78 using slight variant of the leave one subject out validation method. Conclusion: This work demonstrates that high quality BCG signals can be collected in a home environment and used to detect the clinical state of HF patients. Significance: In future work, a clinician/caregiver can be introduced into the system so that appropriate interventions can be performed based on the clinical state monitored at home.","Monitoring,Heart,Hafnium,Biomedical monitoring,Sensors,Indexes,Ballistocardiography,machine learning,heart failure",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,,"CARDIAC,CONTRACTILITY,EJECTION,FRACTION,BLOOD-PRESSURE,MANAGEMENT,SYSTEM,HOSPITALIZATION,PERFORMANCE,TECHNOLOGY,TRANSITION,EXERCISE",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7271768,
77,An Efficient IoT-Based Platform for Remote Real-Time Cardiac Activity Monitoring,66,2,106-114,Raj Sandeep,Raj S,Raj S,10.1109/TCE.2020.2981511,"Indian Inst Informat Technol Bhagalpur, Dept Elect & Commun Engn, Bhagalpur 813210, India.","In this article, a novel and an efficient methodology is presented for real-time monitoring of ECG signals. The method involves fast Fourier transform (FFT) based discrete wavelet transform (DWT) for extracting the features from the heartbeats which involves less computational complexity in terms of additions and multiplications operations for higher order filter lengths. These features extracted are recognized using particle swarm optimization (PSO) tuned twin support vector machines (TSVM) classifier. The TSVM classifier is four times faster than the standard SVM while the PSO technique is employed to gradually tune the classifier parameters to achieve more accuracy. The proposed methodology is implemented on IoT based microcontroller platform and validated on the benchmark Physionet data to classify 16 categories of ECG signals. Once an abnormality is detected, the platform generates a pop-up message as a warning and sends the information to a remote platform allowing hospitals to take preventive measures. The platform reported a higher overall accuracy of 95.68% than the existing studies. Further, such implementation can be utilized as a warning system in both homecare as well as tele-monitoring applications to continuously monitor the cardiac condition of a subject anywhere to the state-of-art heart disease diagnosis.","Electrocardiogram (ECG),feature extraction,machine learning,microcontroller platform,wifi-module",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Telecommunications",,2.658,"SYSTEM,CLASSIFICATION,DESIGN,IMPLEMENTATION",IEEE TRANSACTIONS ON CONSUMER ELECTRONICS,,
78,Kernel Granger Causality Based on Back Propagation Neural Network Fuzzy Inference System on fMRI Data,28,5,1049-1058,"Guo Huiming,Zeng Weiming,Shi Yuhu,Deng Jin,Zhao Le","Guo HM,Zeng WM,Shi YH,Deng J,Zhao L",Zeng WM,10.1109/TNSRE.2020.2984519,Shanghai Maritime University,"Granger causality (GC) is one of the most popular measures to investigate causality influence among brain regions and has been achieved significant results for exploring brain networks based on functional magnetic resonance imaging (fMRI). However, the predictors and order selection of conventional GC are based on linear models which result in such restrictions as poorly detection of nonlinearity and so on, in the application. This paper proposes a novel GC model called back propagation (BP) based kernel function Granger causality (BP_KFGC), in which symplectic geometry is used for embedding dimension and fuzzy inference system for predicting time series. The proposed method doesn't depend on the prediction of the vector auto-regression model, so that time series don't need to be wide-sense stationary as linear GC and kernel GC. In addition, it is a multivariate approach which is applicable to both linear and nonlinear systems and eliminates the effects of latent variables. The performance of the new method is evaluated and compared with linear GC, partial GC, neural network GC and kernel GC by simulated data with multiple adjustments to the nonlinearity. The results show that BP_KFGC outperforms the other four methods in detecting both linear and nonlinear causalities. Furthermore, we applied BP_KFGC to construct directed weight network (DWN) of Alzheimer's disease (AD) patients and health controls (HCs), and then nine graph-based features of DWN were used for classification by the classifier of support vector machine with radial basis kernel function. The accuracy of 95.89%, sensitivity of 93.31%, and specificity of 94.97% were achieved which may provide an auxiliary mean for the clinical diagnosis of AD.","fMRI,Granger causality measurement,back propagation neural network,fuzzy inference system,kernel function,support vector machine",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"MILD,COGNITIVE,IMPAIRMENT,EFFECTIVE,CONNECTIVITY,SIGNALS",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
79,High-Frame-Rate Color Doppler Echocardiography: A Quantitative Comparison of Different Approaches,67,5,923-933,"Ramalli Alessandro,Rodriguez-Molares Alfonso,Avdal Jorgen,D'hooge Jan,Lovstakken Lasse","Ramalli A,Rodriguez-Molares A,Avdal J,D'hooge J,Lovstakken L",Ramalli A,10.1109/TUFFC.2019.2958031,KU Leuven,"Ultrasound color Doppler imaging (CDI) provides a map of the axial blood flow velocities in a 2-D/3-D region of interest. While CDI is clinically effective for a qualitative analysis of abnormal blood flows, e.g., for valvular disease in cardiology, it is in limited use for quantitative measures, mainly hampered by low frame rate and measurement bias. These limitations can be reduced by different approaches toward high-frame-rate (HFR) imaging at the expense of reduced image quality and penetration depth. The aim of this study was to compare the impact of different HFR sequences on CDI quantitatively. Different cardiac scan sequences, including diverging waves and multiline transmission, were designed, implemented on a research system, and compared in terms of patient safety parameters, image quality, and penetration depth. Furthermore, in vivo images were acquired and compared for healthy volunteers. Results showed that the HFR techniques spread artifacts on larger areas than the standard single-line scans (> +50%). In addition, due to patient safety limitations, they reduce the penetration depth up to -5 cm. On the other hand, the HFR techniques provide comparable velocity estimates (relative difference <6%) and enhance the time resolution of the color Doppler images, achieving frame rates up to 625 Hz in continuous acquisition.","Feature extraction,Classification algorithms,Protocols,Telecommunication traffic,Machine learning,Training,Data models,Cardiac imaging,clinical,color Doppler,color flow,diverging waves,echocardiography,high frame rate (HFR),multiline transmission (MLT)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,,"FLOW,DOPPLER,GUIDELINES,DIAGNOSIS,SOCIETY,UPDATE",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,https://flore.unifi.it/bitstream/2158/1181601/1/TUFFC2958031_authorSubmitted.pdf,
80,AI-optimized detector design for the future Electron-Ion Collider: the dual-radiator RICH case,15,5,,"Cisbani E.,Del Dotto A.,Fanelli C.,Williams M.,Alfred M.,Barbosa F.,Barion L.,Berdnikov V,Brooks W.,Cao T.","Cisbani E,Del Dotto A,Fanelli C,Williams M,Alfred M,Barbosa F,Barion L,Berdnikov V,Brooks W,Cao T",Fanelli C,10.1088/1748-0221/15/05/P05009,United States Department of Energy (DOE),"Advanced detector R&D requires performing computationally intensive and detailed simulations as part of the detector-design optimization process. We propose a general approach to this process based on Bayesian optimization and machine learning that encodes detector requirements. As a case study, we focus on the design of the dual-radiator Ring Imaging Cherenkov (dRICH) detector under development as a potential component of the particle-identification system at the future Electron-Ion Collider (EIC). The EIC is a US-led frontier accelerator project for nuclear physics, which has been proposed to further explore the structure and interactions of nuclear matter at the scale of sea quarks and gluons. We show that the detector design obtained with our automated and highly parallelized framework outperforms the baseline dRICH design within the assumptions of the current model. Our approach can be applied to any detector R&D, provided that realistic simulations are available.","Detector design and construction technologies and materials,Cherenkov detectors",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Instruments & Instrumentation,,,,JOURNAL OF INSTRUMENTATION,https://dspace.mit.edu/bitstream/1721.1/134167/2/1911.05797.pdf,
81,Modeling EDFA Gain Ripple and Filter Penalties With Machine Learning for Accurate QoT Estimation,38,9,2616-2629,"Mahajan Ankush,Christodoulopoulos Konstantinos,Martinez Ricardo,Spadaro Salvatore,Munoz Raul","Mahajan A,Christodoulopoulos K,Martinez R,Spadaro S,Munoz R",Mahajan A,10.1109/JLT.2020.2975081,Centre Tecnologic Telecomunicacions Catalunya (CTTC),"For reliable and efficient network planning and operation, accurate estimation of Quality of Transmission (QoT) before establishing or reconfiguring the connection is necessary. In optical networks, a design margin is generally included in a QoT estimation tool (Qtool) to account for modeling and parameter inaccuracies, ensuring the acceptable performance. In this article, we use monitoring information from an operating network combined with supervised machine learning (ML) techniques to understand the network conditions. In particular, we model the penalties generated due to i) Erbium Doped Fiber Amplifier (EDFA) gain ripple effect, and ii) filter spectral shape uncertainties at Reconfigurable Optical Add and Drop Multiplexer (ROADM) nodes. Enhancing the Qtool with the proposed ML regression models yields estimates for new or reconfigured connections that account for these two effects, resulting in more accurate QoT estimation and a reduced design margin. We initially propose two supervised ML regression models, implemented with Support Vector Machine Regression (SVMR), to estimate the individual penalties of the two effects and then a combined model. On Deutsche Telekom (DT) network topology with 12 nodes and 40 bidirectional links, we achieve a design margin reduction of similar to 1 dB for new connection requests.","Estimation,Erbium-doped fiber amplifiers,Optical fiber networks,Signal to noise ratio,Uncertainty,Optical fiber filters,Erbium doped fiber amplifier (EDFA),filter cascading,machine learning,network margins,parameter uncertainties,quality of transmission (QoT)",Article; Proceedings Paper,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Optics,Telecommunications",,3.764,"MITIGATION,DESIGN",JOURNAL OF LIGHTWAVE TECHNOLOGY,https://zenodo.org/record/3979381/files/Modeling%20EDFA%20Gain%20Ripple%20and%20Filter.pdf,
82,Mu-net: Multi-scale U-net for two-photon microscopy image denoising and restoration,125,,92-103,"Lee Sehyung,Negishi Makiko,Urakubo Hidetoshi,Kasai Haruo,Ishii Shin","Lee S,Negishi M,Urakubo H,Kasai H,Ishii S",Lee S,10.1016/j.neunet.2020.01.026,Kyoto University,"Advances in two two-photon microscopy (2PM) have made three-dimensional (3D) neural imaging of deep cortical regions possible. However, 2PM often suffers from poor image quality because of various noise factors, including blur, white noise, and photo bleaching. In addition, the effectiveness of the existing image processing methods is limited because of the special features of 2PM images such as deeper tissue penetration but higher image noises owing to rapid laser scanning. To address the denoising problems in 2PM 3D images, we present a new algorithm based on deep convolutional neural networks (CNNs). The proposed model consists of multiple U-nets in which an individual U-net removes noises at different scales and then yields a performance improvement based on a coarse-to-fine strategy. Moreover, the constituent CNNs employ fully 3D convolution operations. Such an architecture enables the proposed model to facilitate end-to-end learning without any pre/post processing. Based on the experiments on 2PM image denoising, we observed that our new algorithm demonstrates substantial performance improvements over other baseline methods. (c) 2020 Elsevier Ltd. All rights reserved.","Image denoising,Two-photon microscopy image,Deep learning,U-net,GAN",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,9.171,,NEURAL NETWORKS,,
83,Learning pairing symmetries in disordered superconductors using spin-polarized local density of states,22,5,,"Chen Liang,Wang Chen-Xi,Han Rong-Sheng,Zhang Ye-Qi","Chen L,Wang CX,Han RS,Zhang YQ",Chen L,10.1088/1367-2630/ab8261,North China Electric Power University,"We construct an artificial neural network to study the pairing symmetries in disordered superconductors. For Hamiltonians on square lattice with s-wave, d-wave, and nematic pairing potentials, we use the spin-polarized local density of states near a magnetic impurity in the clean system to train the neural network. We find that, when the depth of the artificial neural network is sufficient large, it will have the power to predict the pairing symmetries in disordered superconductors. In a large parameter regime of the potential disorder, the artificial neural network predicts the correct pairing symmetries with relatively high confidences.","pairing symmetry,spin-polarized spectroscopy,machine learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,3.741,"QUASI-PARTICLE,INTERFERENCE,D-WAVE,SUPERCONDUCTOR,IMPURITY,ATOMS,BOUND-STATES",NEW JOURNAL OF PHYSICS,https://iopscience.iop.org/article/10.1088/1367-2630/ab8261/pdf,
84,Data integration for accelerated materials design via preference learning,22,5,,"Sun Xiaolin,Hou Zhufeng,Sumita Masato,Ishihara Shinsuke,Tamura Ryo,Tsuda Koji","Sun XL,Hou ZF,Sumita M,Ishihara S,Tamura R,Tsuda K",Tsuda K,10.1088/1367-2630/ab82b9,University of Tokyo,"Machine learning applications in materials science are often hampered by shortage of experimental data. Integration with external datasets from past experiments is a viable way to solve the problem. But complex calibration is often necessary to use the data obtained under different conditions. In this paper, we present a novel calibration-free strategy to enhance the performance of Bayesian optimization with preference learning. The entire learning process is solely based on pairwise comparison of quantities (i.e., higher or lower) in the same dataset, and experimental design can be done without comparing quantities in different datasets. We demonstrate that Bayesian optimization is significantly enhanced via data integration for organic molecules and inorganic solid-state materials. Our method increases the chance that public datasets are reused and may encourage data sharing in various fields of physics.","preference learning,Gaussian process,data integration,surrogate model",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,3.741,,NEW JOURNAL OF PHYSICS,http://arxiv.org/pdf/1910.11516,
85,The classification of gliomas based on a Pyramid dilated convolution resnet model,133,,173-179,"Lu Zhenyu,Bai Yanzhong,Chen Yi,Su Chunqiu,Lu Shanshan,Zhan Tianming,Hong Xunning,Wang Shuihua","Lu ZY,Bai YZ,Chen Y,Su CQ,Lu SS,Zhan TM,Hong XN,Wang SH",Zhan TM,10.1016/j.patrec.2020.03.007,Nanjing Audit University,"Gliomas are characterized by high morbidity and high mortality in primary tumors. The identification of glioma type is helpful for radiologists to facilitate correct medical judgments and better prognosis for patients. In order to avoid harm to patients caused by a biopsy, radiologists attempt to classify Magnetic Resonance Images(MRI) using deep learning methods. In the present paper, we propose a deep learning convolutional neural network ResNet based on the pyramid dilated convolution for Gliomas classification. The pyramid dilated convolution is integrated into the bottom of Resnet to increase the receptive field of the original network and improve the classification accuracy. After adding the pyramid dilated convolution model, the receptive field of the original network underlying convolution was improved. A clinical dataset is used to test the pyramid dilated convolution ResNet neural network model proposed in this paper. The experimental results demonstrate that the proposed method can effectively improve glioma classification performance. (C) 2020 Elsevier B.V. All rights reserved.","Gliomas,Classification,Deep learning,ResNet,Dilated convolution",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,3.615,"RECOGNITION,ALGORITHM,TUMORS",PATTERN RECOGNITION LETTERS,,
86,Automated detection and classification of fundus diabetic retinopathy images using synergic deep learning model,133,,210-216,"Shankar K.,Sait Abdul Rahaman Wahab,Gupta Deepak,Lakshmanaprabu S. K.,Khanna Ashish,Pandey Hari Mohan","Shankar K,Sait ARW,Gupta D,Lakshmanaprabu SK,Khanna A,Pandey HM",Shankar K,10.1016/j.patrec.2020.02.026,Alagappa University,"In recent days, the incidence of Diabetic Retinopathy (DR)has become high, affecting the eyes because of drastic increase in the glucose level in blood. Globally, almost half of the people under the age of 70 gets severely affected by diabetes. In the absence of earlier recognition and proper medication, the DR patients tend to lose their vision. When the warning signs are tracked down, the severity level of the disease has to be validated so to take decisions regarding appropriate treatment further. The current research paper focuses on the concept of classification of DR fundus images on the basis of severity level using a deep learning model. This paper proposes a deep learning-based automated detection and classification model for fundus DR images. The proposed method involves various processes namely preprocessing, segmentation and classification. The methods begins with preprocessing stage in which unnecessary noise that exists in the edges is removed. Next, histogram-based segmentation takes place to extract the useful regions from the image. Then, Synergic Deep Learning (SDL) model was applied to classify the DR fundus images to various severity levels. The justification for the presented SDL model was carried out on Messidor DR dataset. The experimentation results indicated that the presented SDL model offers better classification over the existing models. (C) 2020 Elsevier B.V. All rights reserved.","Deep learning,Classification,Diabetic retinopathy,Messidor dataset,Synergic deep learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,3.615,,PATTERN RECOGNITION LETTERS,https://research.edgehill.ac.uk/ws/files/29195215/Manuscript1.pdf,
87,Visual question answering with attention transfer and a cross-modal gating mechanism,133,,334-340,"Li Wei,Sun Jianhui,Liu Ge,Zhao Linglan,Fang Xiangzhong","Li W,Sun JH,Liu G,Zhao LL,Fang XZ",Li W,10.1016/j.patrec.2020.02.031,Shanghai Jiao Tong University,"Visual question answering (VQA) is challenging since it requires to understand both language information and corresponding visual contents. A lot of efforts have been made to capture single-step language and visual interactions. However, answering complex questions requires multiple steps of reasoning which gradually adjusts the region of interest to the most relevant part of the given image, which has not been well investigated. To integrate question related object relations into attention mechanism, we propose a multi-step attention architecture to facilitate the modeling of multi-modal correlations. Firstly, an attention transfer mechanism is integrated to gradually adjust the region of interest considering reasoning representation of questions. Secondly, we propose a cross-modal gating strategy to filter out irrelevant information based on multi-modal correlations. Finally, we achieve the state-of-the-art performance on the VQA 1.0 dataset and favorable results on the VQA 2.0 dataset, which verifies the effectiveness of our proposed method. (C) 2020 Elsevier B.V. All rights reserved.","Attention,Visual question answering,Gating",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,3.615,,PATTERN RECOGNITION LETTERS,,
88,Purifying real images with an attention-guided style transfer network for gaze estimation,91,,,"Fu Xianping,Yan Yuxiao,Yan Yang,Peng Jinjia,Wang Huibing","Fu XP,Yan YX,Yan Y,Peng JJ,Wang HB",Fu XP; Yan YX; Wang HB,10.1016/j.engappai.2020.103609,Dalian Maritime University,"Recently, the progress of learning-by-synthesis has proposed a training model for synthetic images, which can effectively reduce the cost of human and material resources. Image synthesis has been widely accepted as a cost effective way to learn models because it provides training sets that are large, diverse and accurately labeled. However, the realism of the synthetic image is not enough, this affects generalization on naturalistic test image. In an attempt to address this issue, previous methods learn a model to improve the realism of synthetic image. Different from previous methods, we take the first step towards purifying the real image to weaken the influence of light and convert the distribution of an outdoor naturalistic image through a real-time style transfer task to that of indoor synthetic image. In this paper, we first introduce the segmentation masks to construct Red, Green, and Blue-mask (RGB-mask) pairs as inputs, then we design an attention-guided style transfer network to learn style features separately from the attention and background regions, learn content features from full and attention regions. Moreover, we propose a novel region-level task-guided loss to restrain the features learnt from style and content. Experiments were performed using a mixed research (qualitative and quantitative) method to demonstrate the possibility of purifying real images in complex directions. We evaluate the proposed method on three public datasets, including Labeled pupils in the wild (LPW), Common Objects in COntext (COCO) and MPIIGaze. Extensive experimental results show that the proposed method is effective and achieves the state-of-the-art results.","Gaze estimation,Style transfer,Attention-guided style transfer network,Learning-by-synthesis",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Automation & Control Systems,Computer Science,Engineering",,5.317,"REGRESSION,APPEARANCE",ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE,http://arxiv.org/pdf/2002.06145,
89,Joint DBN and Fuzzy C-Means unsupervised deep clustering for lung cancer patient stratification,91,,,"Zhao Zijuan,Zhao Juanjuan,Song Kai,Hussain Akbar,Du Qianqian,Dong Yunyun,Liu Jihua,Yang Xiaotang","Zhao ZJ,Zhao JJ,Song K,Hussain A,Du QQ,Dong YY,Liu JH,Yang XT",Zhao JJ,10.1016/j.engappai.2020.103571,Taiyuan University of Technology,"Patient stratification has made a great contribution to efficient and personalized medicine. An important task in patient stratification is to discover quite distinct disease subtypes for effective treatment. In this paper, we propose a new deep learning and clustering model which combines Deep Belief Network (DBN) and Fuzzy C-Means(FCM), called Unsupervised Deep Fuzzy C-Means clustering Network(UDFCMN), to cluster lung cancer patients from lung CT images. In our deep clustering network, images after preprocessing are first encoded into multiple layers of hidden variables to extract hierarchical features and feature distribution and form the high-level representations. Here, to solve the problem of feature homogenization in DBN, we introduce the Winner-Take-All (WTA) idea to meliorate the traditional DBN structure, called WTADBN. Then FCM is used to produce the initial cluster labels with the new representations learnt by stacked WTARBM. Therefore, the FCM-generated cluster labels are used for the fine-tuning of the DBN as ground-truth labels. And an unsupervised image clustering and patient stratification process is completed by cross iteration. We tested our deep FCM clustering algorithm to do experiment on both public dataset from the internet and private dataset from cooperate hospital. For the latter one, the clinical and biological verification was also performed. Experimental results reveal outperformance of UDFCMN as compared to the state-of-the-art unsupervised classification methods. These results also indicate that our approach may have practical applications in lung cancer pathogenesis studies and provide useful guidelines for personalized cancer therapy.","Deep clustering,Deep belief network,Fuzzy C-Means,Patient stratification",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Automation & Control Systems,Computer Science,Engineering",,5.317,"MOLECULAR,SUBTYPE",ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE,,
90,A Classification Method of Oracle Materials Based on Local Convolutional Neural Network Framework,40,3,32-44,"Chen Shanxiong,Han Xu,Gao Weizhe,Liu Xuxin,Mo Bofeng","Chen SX,Han X,Gao WZ,Liu XX,Mo BF",Chen SX,10.1109/MCG.2020.2973109,Southwest University - China,"The classification of materials of oracle bone is one of the most basic aspects for oracle bone morphology. However, the classification method depending on experts' experience requires long-term learning and accumulation for professional knowledge. This article presents a multiregional convolutional neural network to classify the rubbings of oracle bones. First, we detected the ""shield grain"" and ""tooth grain"" on the oracle bone rubbings, then complete the division of multiple areas on an image of oracle bone. Second, the convolutional neural network is used to extract the features of each region and we complete the fusion of multiple local features. Finally, the classification of tortoise shell and animal bone was realized. Utilizing the image of oracle bone provided by experts, we conducted an experiment; the result show our method has better classification accuracy. It has made contributions to the progress of the study of oracle bone morphology.","Bones,Feature extraction,Image edge detection,Image segmentation,Image classification,Convolutional neural networks,oracle bone classification,convolutional neural network,edge detection,image segmentation",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA",Computer Science,,2.481,,IEEE COMPUTER GRAPHICS AND APPLICATIONS,,
91,A Brain-Computer Interface Framework Based on Compressive Sensing and Deep Learning,9,3,90-95,"Shrivastwa Ritu Ranjan,Pudi Vikramkumar,Duo Chen,So Rosa,Chattopadhyay Anupam,Guan Cuntai","Shrivastwa RR,Pudi V,Duo C,So R,Chattopadhyay A,Guan CT",Shrivastwa RR,10.1109/MCE.2019.2959059,"Secure IC SAS, Cesson Sevigne, France.","Compression of brain-computer interface (BCI) signals is significant to reduce transmission bandwidth to cloud/remote servers and to minimize storage cost. Precise reconstruction of the compressed signal is also crucial as these data are further used for spike detection and/or classification. The conventional compressive sensing (CS) techniques to reconstruct the compressed BCI signals are computationally expensive. There are several existing techniques for CS reconstruction, including block-sparse Bayesian learning and block-based CS, which also work to replace a reconstruction methodology of CS in medical imaging with deep learning (DL) techniques. DL can be helpful in reconstructing compressed BCI signals, including Electroencephalography (EEG) and Electrocorticography (ECoG). Pertinent to that, in this work, a convolutional neural network (CNN) based reconstruction framework has been proposed to reconstruct spike signals that has been highly compressed using the CS technique. An accuracy of 91.62% has been achieved over signals compressed at 90% compression rate, when compared with original signals using a cross-correlation technique.","Image reconstruction,Electroencephalography,Sensors,Image coding,Compressed sensing,Biomedical imaging,Bandwidth",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.329,SIGNALS,IEEE CONSUMER ELECTRONICS MAGAZINE,,
92,Temporally Nonstationary Component Analysis; Application to Noninvasive Fetal Electrocardiogram Extraction,67,5,1377-1386,"Jamshidian-Tehrani Fahimeh,Sameni Reza,Jutten Christian","Jamshidian-Tehrani F,Sameni R,Jutten C",Sameni R,10.1109/TBME.2019.2936943,Shiraz University,"Objective: Mixtures of temporally nonstationary signals are very common in biomedical applications. The nonstationarity of the source signals can be used as a discriminative property for signal separation. Herein, a semi-blind source separation algorithm is proposed for the extraction of temporally nonstationary components from linear multichannel mixtures of signals and noises. Methods: A hypothesis test is proposed for the detection and fusion of temporally nonstationary events, by using ad hoc indexes for monitoring the first and second order statistics of the innovation process. As proof of concept, the general framework is customized and tested over noninvasive fetal cardiac recordings acquired from the maternal abdomen, over publicly available datasets, using two types of nonstationarity detectors: 1) a local power variations detector, and 2) a model-deviations detector using the innovation process properties of an extended Kalman filter. Results: The performance of the proposed method is assessed in presence of white and colored noise, in different signal-to-noise ratios. Conclusion and Significance: The proposed scheme is general and it can be used for the extraction of nonstationary events and sample deviations from a presumed model in multivariate data, which is a recurrent problem in many machine learning applications.","Nonstationary component analysis,semi-blind source separation,nonstationarity detection,generalized eigenvalue decomposition,approximate joint diagonalization,fetal electrocardiogram extraction",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"BLIND,SEPARATION,DIAGONALIZATION,ALGORITHM,MODEL",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,http://arxiv.org/pdf/2108.09353,
93,Sequential Factorized Autoencoder for Localizing the Origin of Ventricular Activation From 12-Lead Electrocardiograms,67,5,1505-1516,"Gyawali Prashnna Kumar,Horacek B. Milan,Sapp John L.,Wang Linwei","Gyawali PK,Horacek BM,Sapp JL,Wang LW",Gyawali PK,10.1109/TBME.2019.2939138,Rochester Institute of Technology,"Objective: This work presents a novel approach to handle the inter-subject variations existing in the population analysis of ECG, applied for localizing the origin of ventricular tachycardia (VT) from 12-lead electrocardiograms (ECGs). Methods: The presented method involves a factor disentangling sequential autoencoder (f-SAE) - realized in both long short-term memory (LSTM) and gated recurrent unit (GRU) networks - to learn to disentangle the inter-subject variations from the factor relating to the location of origin of VT. To perform such disentanglement, a pair-wise contrastive loss is introduced. Results: The presented methods are evaluated on ECG dataset with 1012 distinct pacing sites collected from scar-related VT patients during routine pace-mapping procedures. Experiments demonstrate that, for classifying the origin of VT into the predefined segments, the presented f-SAE improves the classification accuracy by 8.94% from using prescribed QRS features, by 1.5% from the supervised deep CNN network, and 5.15% from the standard SAE without factor disentanglement. Similarly, when predicting the coordinates of the VT origin, the presented f-SAE improves the performance by 2.25 mm from using prescribed QRS features, by 1.18 mm from the supervised deep CNN network and 1.6 mm from the standard SAE. Conclusion: These results demonstrate the importance as well as the feasibility of the presented f-SAE approach for separating inter-subject variations when using 12-lead ECG to localize the origin of VT. Significance: This work suggests the important research direction to deal with the well-known challenge posed by inter-subject variations during population analysis from ECG signals.","Electrocardiography,Logic gates,Data models,Adaptation models,Heart,Standards,Recurrent neural networks,Ventricular Tachycardia,Electrophysiology,Disentangled Representations,Sequential Autoencoder",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,SITE,IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7051887,
94,Induced-Current Learning Method for Nonlinear Reconstructions in Electrical Impedance Tomography,39,5,1326-1334,"Wei Zhun,Chen Xudong","Wei Z,Chen XD",Chen XD,10.1109/TMI.2019.2948909,National University of Singapore,"Electrical impedance tomography (EIT) is an attractive technique that aims to reconstruct the unknown electrical property in a domain from the surface electrical measurements. In this work, the induced-current learning method (ICLM) is proposed to solve nonlinear electrical impedance tomography (EIT) problems. Specifically, the cascaded end-to-end convolutional neural network (CEE-CNN) architecture is designed to implement the ICLM. The CEE-CNN greatly decreases the nonlinearities in EIT problems by designing a combined objective function and introducing multiple labels. A noticeable characteristic of the proposed CNN scheme is that the input parameters are chosen as both induced contrast current (ICC) and the updated electrical field from a spectral analysis and the output is chosen as ICC, which is fundamentally different from prevailing CNN schemes. Further, several skip connections are introduced to focus on learning only the unknown part of ICC. ICLM is verified with both numerical and experimental tests on typical EIT problems, and it is found that ICLM is able to solve typical EIT problems in less than 1 second with high image qualities. More importantly, it is also highly robust to measurement noises and modeling errors, such as inaccurate boundary data.","Tomography,Conductivity,Mathematical model,Image reconstruction,Inverse problems,Pollution measurement,Electrodes,Electrical impedance tomography,deep learning,convolutional neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORK,INVERSE,PROBLEMS,ALGORITHMS,BOUNDARY",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
95,A Multi-Organ Nucleus Segmentation Challenge,39,5,1380-1391,"Kumar Neeraj,Verma Ruchika,Anand Deepak,Zhou Yanning,Onder Omer Fahri,Tsougenis Efstratios,Chen Hao,Heng Pheng-Ann,Li Jiahui,Hu Zhiqiang","Kumar N,Verma R,Anand D,Zhou YN,Onder OF,Tsougenis E,Chen H,Heng PA,Li JH,Hu ZQ",Kumar N,10.1109/TMI.2019.2947628,University of Illinois System,"Generalized nucleus segmentation techniques can contribute greatly to reducing the time to develop and validate visual biomarkers for new digital pathology datasets. We summarize the results of MoNuSeg 2018 Challenge whose objective was to develop generalizable nuclei segmentation techniques in digital pathology. The challenge was an official satellite event of the MICCAI 2018 conference in which 32 teams with more than 80 participants from geographically diverse institutes participated. Contestants were given a training set with 30 images from seven organs with annotations of 21,623 individual nuclei. A test dataset with 14 images taken from seven organs, including two organs that did not appear in the training set was released without annotations. Entries were evaluated based on average aggregated Jaccard index (AJI) on the test set to prioritize accurate instance segmentation as opposed to mere semantic segmentation. More than half the teams that completed the challenge outperformed a previous baseline. Among the trends observed that contributed to increased accuracy were the use of color normalization as well as heavy data augmentation. Additionally, fully convolutional networks inspired by variants of U-Net, FCN, and Mask-RCNN were popularly used, typically based on ResNet or VGG base architectures. Watershed segmentation on predicted semantic segmentation maps was a popular post-processing strategy. Several of the top techniques compared favorably to an individual human annotator and can be used with confidence for nuclear morphometrics.","Image segmentation,Pathology,Image color analysis,Semantics,Task analysis,Deep learning,Multi-organ,nucleus segmentation,digital pathology,instance segmentation,aggregated Jaccard index",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,https://figshare.com/articles/journal_contribution/A_multi-organ_nucleus_segmentation_challenge/14236643/files/26876531.pdf,
96,De-smokeGCN: Generative Cooperative Networks for Joint Surgical Smoke Detection and Removal,39,5,1615-1625,"Chen Long,Tang Wen,John Nigel W.,Wan Tao Ruan,Zhang Jian Jun","Chen L,Tang W,John NW,Wan TR,Zhang JJ",Tang W,10.1109/TMI.2019.2953717,Bournemouth University,"Surgical smoke removal algorithms can improve the quality of intra-operative imaging and reduce hazards in image-guided surgery, a highly desirable post-process for many clinical applications. These algorithms also enable effective computer vision tasks for future robotic surgery. In this article, we present a new unsupervised learning framework for high-quality pixel-wise smoke detection and removal. One of the well recognized grand challenges in using convolutional neural networks (CNNs) for medical image processing is to obtain intra-operative medical imaging datasets for network training and validation, but availability and quality of these datasets are scarce. Our novel training framework does not require ground-truth image pairs. Instead, it learns purely from computer-generated simulation images. This approach opens up new avenues and bridges a substantial gap between conventional non-learning based methods and which requiring prior knowledge gained from extensive training datasets. Inspired by the Generative Adversarial Network (GAN), we have developed a novel generative-collaborative learning scheme that decomposes the de-smoke process into two separate tasks: smoke detection and smoke removal. The detection network is used as prior knowledge, and also as a loss function to maximize its support for training of the smoke removal network. Quantitative and qualitative studies show that the proposed training framework outperforms the state-of-the-art de-smoking approaches including the latest GAN framework (such as PIX2PIX). Although trained on synthetic images, experimental results on clinical images have proved the effectiveness of the proposed network for detecting and removing surgical smoke on both simulated and real-world laparoscopic images.","Endoscopy,image enhancement,machine learning,de-smoking",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"MINIMALLY,INVASIVE,SURGERY,IMAGE,WEATHER",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://bradscholars.brad.ac.uk/bitstream/10454/17544/5/Wan_IEEE_Transactions_on_Medical_Imaging_Final.pdf,
97,Hyperspectral Pansharpening With Deep Priors,31,5,1529-1543,"Xie Weiying,Lei Jie,Cui Yuhang,Li Yunsong,Du Qian","Xie WY,Lei J,Cui YH,Li YS,Du Q",Cui YH,10.1109/TNNLS.2019.2920857,Xidian University,"Hyperspectral (HS) image can describe subtle differences in the spectral signatures of materials, but it has low spatial resolution limited by the existing technical and budget constraints. In this paper, we propose a promising HS pansharpening method with deep priors (HPDP) to fuse a low-resolution (LR) HS image with a high-resolution (HR) panchromatic (PAN) image. Different from the existing methods, we redefine the spectral response function (SRF) based on the larger eigenvalue of structure tensor (ST) matrix for the first time that is more in line with the characteristics of HS imaging. Then, we introduce HFNet to capture deep residual mapping of high frequency across the upsampled HS image and the PAN image in a band-by-band manner. Specifically, the learned residual mapping of high frequency is injected into the structural transformed HS images, which are the extracted deep priors served as additional constraint in a Sylvester equation to estimate the final HR HS image. Comparative analyses validate that the proposed HPDP method presents the superior pansharpening performance by ensuring higher quality both in spatial and spectral domains for all types of data sets. In addition, the HFNet is trained in the high-frequency domain based on multispectral (MS) images, which overcomes the sensitivity of deep neural network (DNN) to data sets acquired by different sensors and the difficulty of insufficient training samples for HS pansharpening.","Bayes methods,Hyperspectral sensors,High frequency,Spatial resolution,Fuses,Imaging,Deep priors,high frequency,hyperspectral (HS) pansharpening,structure tensor (ST),sylvester equation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.746,"IMAGE,SUPERRESOLUTION,FUSION,RESOLUTION,MS",IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,,
98,Cascade Superpixel Regularized Gabor Feature Fusion for Hyperspectral Image Classification,31,5,1638-1652,"Jia Sen,Lin Zhijie,Deng Bin,Zhu Jiasong,Li Qingquan","Jia S,Lin ZJ,Deng B,Zhu JS,Li QQ",Zhu JS,10.1109/TNNLS.2019.2921564,Shenzhen University,"A 3-D Gabor wavelet provides an effective way to obtain the spectral-spatial-fused features for hyperspectral image, which has shown advantageous performance for material classification and recognition. In this paper, instead of separately employing the Gabor magnitude and phase features, which, respectively, reflect the intensity and variation of surface materials in local area, a cascade superpixel regularized Gabor feature fusion (CSRGFF) approach has been proposed. First, the Gabor filters with particular orientation are utilized to obtain Gabor features (including magnitude and phase) from the original hyperspectral image. Second, a support vector machine (SVM)-based probability representation strategy is developed to fully exploit the decision information in SVM output, and the achieved confidence score can make the following fusion with Gabor phase more effective. Meanwhile, the quadrant bit coding and Hamming distance metric are applied to encode the Gabor phase features and measure sample similarity in sequence. Third, the carefully defined characteristics of two kinds of features are directly combined together without any weighting operation to describe the weight of samples belonging to each class. Finally, a series of superpixel graphs extracted from the raw hyperspectral image with different numbers of superpixels are employed to successively regularize the weighting cube from over-segmentation to under-segmentation, and the classification performance gradually improves with the decrease in the number of superpixels in the regularization procedure. Four widely used real hyperspectral images have been conducted, and the experimental results constantly demonstrate the superiority of our CSRGFF approach over several state-of-the-art methods.","Hyperspectral imaging,Feature extraction,Transforms,Image analysis,Machine learning,Learning systems,Cascade superpixel regularization (SR),feature fusion,hyperspectral image classification,image segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.746,"SPATIAL,CLASSIFICATION,REPRESENTATION,INFORMATION,FRAMEWORK,PROFILES",IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,,
99,Development of hybrid artificial intelligence based automatic sleep/awake detection,14,3,353-366,"Bozkurt Mehmet Recep,Ucar Muhammed Kursad,Bozkurt Ferda,Bilgin Cahit","Bozkurt MR,Ucar MK,Bozkurt F,Bilgin C",Ucar MK,10.1049/iet-smt.2019.0034,Sakarya University,"Background and Objective: Obstructive Sleep Apnea is a disease that causes respiratory arrest in sleep and reduces sleep quality. The diagnosis of the disease is made by the physician in two stages by examining the patient records taken with the polysomnography device. Because of the negative aspects of this process, new diagnostic processes and devices are needed. In this article, a new approach to sleep staging, which is one of the diagnostic steps of the disease, was proposed. An artificial intelligence-based sleep/awake system detection was developed for sleep staging processing. Photoplethysmography (PPG) signal and heart rate variable (HRV) were used in the study. PPG records taken from patient and control groups were cleaned by the digital filter. The HRV parameter was then derived from the PPG signal. Then, 40 features from HRV signal and 46 features from PPG signal were extracted. The extracted features were classified by reduced machine learning techniques with F-score feature selection method. In order to evaluate the performances of the classifiers, the sensitivity and specificity values, the accuracy rates for each class were computed in the test set and receiver operating characteristic curve prepared. In addition, area under the curve (AUC), Kappa coefficient and F-score were calculated. According to the results obtained, the system can be realised with 91.09% accuracy rate using 11 PPG and HRV and with 90.01% accuracy rate using 14 HRV features. These success rates are quite enough for the system to work. When all these values are taken into consideration, it is possible to realise a practical sleep/awake detection system. This article suggests that the PPG signal can be used to diagnose obstructive sleep apnea by processing with artificial intelligence and signal processing techniques.","electrocardiography,signal classification,learning (artificial intelligence),medical signal processing,feature extraction,medical disorders,neurophysiology,diseases,patient monitoring,photoplethysmography,sleep,hybrid artificial intelligence,obstructive sleep apnea,respiratory arrest,sleep quality,patient records,polysomnography device,diagnostic processes,sleep staging processing,heart rate,PPG records,HRV parameter,PPG signal,HRV signal,reduced machine,F-score feature selection method,receiver operating characteristic curve,HRV features,signal processing techniques",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND",Engineering,,1.965,"EMPIRICAL,MODE,DECOMPOSITION,HEART-RATE-VARIABILITY,EEG,SIGNALS,SLEEP-APNEA,WAVELET,TRANSFORM,NEURAL-NETWORK,ECG,SYSTEM,CLASSIFICATION,IDENTIFICATION",IET SCIENCE MEASUREMENT & TECHNOLOGY,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-smt.2019.0034,
100,Thoughts concerning the application of thermogram images for automated diagnosis of dry eye - A review,106,,,"Vicnesh Jahmunah,Oh Shu Lih,Wei Joel Koh En,Ciaccio Edward J.,Chua Kuang Chua,Tong Louis,Acharya U. Rajendra","Vicnesh J,Oh SL,Wei JKE,Ciaccio EJ,Chua KC,Tong L,Acharya UR",Acharya UR,10.1016/j.infrared.2020.103271,"Ngee Ann Polytech, Dept Elect & Comp Engn, Singapore 599489, Singapore.","Dry eye disease (DED) is a multifactorial condition of the tear and ocular surface that is characterized by loss of homeostasis and symptoms of tear instability. Some symptoms of DED include blurring of vision, crusting of eyelids, and irritation to the eyes. An array of clinical methods, such as Schirmer's test, is used to classify DED. Yet, these approaches are often invasive, need to be performed manually by clinicians, and/or they do not have reproducible results. They are also prone to interobserver variation among clinicians. Thus, computer-aided detection (CAD) systems are preferred for DED diagnosis. This paper reviews the existing CAD techniques used to automatically diagnose DED, and focuses on the benefits of thermographic CAD systems. CAD systems for DED using thermography are found to be highly sensitive, specific, accurate, minimally invasive, convenient, and satisfactory. Also, deep learning techniques are discussed to precede conventional machine learning techniques in the development of a CAD system. It is concluded that the use of thermographic CAD systems coupled with a deep learning technique is likely to be useful for DED assessment in future work.","Computer-aided detection system,Dry eye disease,Infrared thermography,Machine learning,Deep learning",Review,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Optics,Physics",,2.581,"RATE-VARIABILITY,SIGNALS,OCULAR,SURFACE,TEAR,FILM,INFRARED,THERMOGRAPHY,LIPID,LAYER,SYSTEM,DISEASE,IDENTIFICATION,CLASSIFICATION,FEATURES",INFRARED PHYSICS & TECHNOLOGY,,
