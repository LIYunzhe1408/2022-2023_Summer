,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Machine learning for radiation outcome modeling and prediction,47,5,E178-E184,"Luo Yi,Chen Shifeng,Valdes Gilmer","Luo Y,Chen SF,Valdes G",Luo Y,10.1002/mp.13570,University of Michigan System,"Aims This review paper intends to summarize the application of machine learning to radiotherapy outcome modeling based on structured and un-structured radiation oncology datasets.
Materials and methods The most appropriate machine learning approaches for structured datasets in terms of accuracy and interpretability are identified. For un-structured datasets, deep learning algorithms are explored and a critical view of the use of these approaches in radiation oncology is also provided.
Conclusions We discuss the challenges in radiotherapy outcome prediction, and suggest to improve radiation outcome modeling by developing appropriate machine learning approaches where both accuracy and interpretability are taken into account.","accuracy,interpretability,machine learning,radiation outcome modeling,structured and unstructured datasets",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"TISSUE,COMPLICATION,PROBABILITY,CELL,LUNG-CANCER,NEURAL-NETWORK,DOSE-VOLUME,THERAPY,PNEUMONITIS,DIAGNOSIS,SUPPORT,HEAD,LIFE",MEDICAL PHYSICS,http://deepblue.lib.umich.edu/bitstream/2027.42/155503/2/mp13570.pdf,
2,CT-based True- and False-Lumen Segmentation in Type B Aortic Dissection Using Machine Learning.,2,3,e190179,",,,,,,,","Hahn Lewis D,Mistelbauer Gabriel,Higashigaito Kai,Koci Martin,Willemink Martin J,Sailer Anna M,Fischbein Michael,Fleischmann Dominik",,10.1148/ryct.2020190179,,"Purpose: To develop a segmentation pipeline for segmentation of aortic dissection CT angiograms into true and false lumina on multiplanar reformations (MPRs) perpendicular to the aortic centerline and derive quantitative morphologic features, specifically aortic diameter and true- or false-lumen cross-sectional area.Materials and Methods: An automated segmentation pipeline including two convolutional neural network (CNN) segmentation algorithms was developed. The algorithm derives the aortic centerline, generates MPRs orthogonal to the centerline, and segments the true and false lumina. A total of 153 CT angiograms obtained from 45 retrospectively identified patients (mean age, 50 years; range, 22-79 years) were used to train (n = 103), validate (n = 22), and test (n = 28) the CNN pipeline. Accuracy was evaluated by using the Dice similarity coefficient (DSC). Segmentations were then used to derive the maximal diameter of test-set patients and cross-sectional area profiles of the true and false lumina.Results: The segmentation pipeline yielded a mean DSC of 0.873 ± 0.056 for the true lumina and 0.894 ± 0.040 for the false lumina of test-set cases. Automated maximal diameter measurements correlated well with manual measurements (R 2 = 0.95). Profiles of cross-sectional diameter, true-lumen area, and false-lumen area over several follow-up examinations were derived. 2020 by the Radiological Society of North America, Inc.",,Journal Article,,,,,,,,
3,Value of Machine Learning-based Coronary CT Fractional Flow Reserve Applied to Triple-Rule-Out CT Angiography in Acute Chest Pain.,2,3,e190137,,,,10.1148/ryct.2020190137,,"Purpose: To evaluate the additional value of noninvasive artificial intelligence (AI)-based CT-derived fractional flow reserve (CT FFR), derived from triple-rule-out coronary CT angiography for acute chest pain (ACP) in the emergency department (ED) setting.Materials and Methods: AI-based CT FFR from triple-rule-out CT angiography data sets was retrospectively obtained in 159 of 271 eligible patients (102 men; mean age, 57.0 years ± 9.7 [standard deviation]) presenting to the ED with ACP. The agreement between CT FFR (≤ 0.80) and stenosis at triple-rule-out CT angiography (≥ 50%), as well as downstream cardiac diagnostic testing, was investigated. Furthermore, the predictive value of CT FFR for coronary revascularization and major adverse cardiac events (MACE) was assessed over a 1-year follow-up period.Results: CT FFR and triple-rule-out CT angiography demonstrated agreement in severity of coronary artery disease (CAD) in 52% (82 of 159) of all cases. CT FFR of 0.80 and less served as a better predictor for coronary revascularization and MACE than stenosis of 50% and greater at triple-rule-out CT angiography (odds ratio, 3.4; 95% confidence interval: 1.4, 8.2 vs odds ratio, 2.2; 95% confidence interval: 0.9, 5.3) (P < .01). In the subgroup of patients with additional noninvasive cardiac testing (94 of 159), there was higher agreement as to the presence or absence of significant disease with CT FFR (55%) than with coronary triple-rule-out CT angiography (47%) (P = .23).Conclusion: CT FFR derived from triple-rule-out CT angiography was a better predictor for coronary revascularization and MACE and showed better agreement with additional diagnostic testing than triple-rule-out CT angiography. Therefore, CT FFR may improve the specificity in identifying patients with ACP with significant CAD in the ED setting and reduce unnecessary downstream testing.© RSNA, 2020See also the commentary by Ihdayhid and Ben Zekry in this issue. 2020 by the Radiological Society of North America, Inc.",,Journal Article,,,,,,,,
4,Brain structural disorders detection and classification approaches: a review,53,5,3349-3401,"Bhatele Kirti Raj,Bhadauria Santa Singh","Bhatele KR,Bhadauria S",Bhatele KR,10.1007/s10462-019-09766-9,Rajiv Gandhi Technological University,"This paper is an effort to encapsulate the various developments in the domain of different unsupervised, supervised and half supervised brain anomaly detection approaches or techniques proposed by the researchers working in the domain of the Medical image segmentation and classification. As researchers are constantly working hard in the domain of image segregation, interpretation and computer vision in order to automate the task of tumour segmentation, anomaly detection, classification and other structural disorder prediction at an early stage with the aid of computer. The different medical imaging modalities are used by the doctors in order to diagnose the brain tumour and other structural brain disorders which are an integral part of diagnosis and prognosis process. When these different medical image modalities are used along with various image segmentation methods and machine learning approaches tends to perform brain structural disorder detection and classification in a semi-automated or fully automated manner with high accuracy. This paper presents all such approaches using various medical image modalities for the accurate detection and classification of brain tumour and other brain structural disorders. In this paper, all the major phases of any brain tumour or brain structural disorder detection and classification approach is covered begin with the comparison of various medical image pre-processing techniques then major segmentation approaches followed by the approaches based on machine learning. This paper also presents an evaluation and comparison among the various popular texture and shape based feature extraction methods used in combination with different machine learning classifiers on the BRATS 2013 dataset. The fusion of MRI modalities used along with the hybrid features extraction methods and ensemble model delivers the best result in terms of accuracy.","Medical imaging modalities,Magnetic resonance imaging (MRI),Computed tomography (CT) scans,Image segmentation,Machine learning,Ensemble learning,Deep learning,Brain tumour,Alzheimer disease (AD),Schizophrenia disease (SCH),Bipolar disorder (BP),Parkinson's disease (PD) etc",Review,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,7.857,"CONVOLUTIONAL,NEURAL-NETWORKS,MAGNETIC-RESONANCE,IMAGES,TUMOR,SEGMENTATION,PARKINSONS-DISEASE,NOISE-REDUCTION,MR-IMAGES,FEATURES,DIAGNOSIS,SCHIZOPHRENIA,SELECTION",ARTIFICIAL INTELLIGENCE REVIEW,,
5,Generation of Head Movements of a Robot Using Multimodal Features of Peer Participants in Group Discussion Conversation,4,2,,"Huang Hung-Hsuan,Kimura Seiya,Kuwabara Kazuhiro,Nishida Toyoaki","Huang HH,Kimura S,Kuwabara K,Nishida T",Huang HH,10.3390/mti4020015,"Univ Fukuchiyama, Fac Informat, Fukushima Ku, Kyoto 6200886, Japan.","In recent years, companies have been seeking communication skills from their employees. Increasingly more companies have adopted group discussions during their recruitment process to evaluate the applicants' communication skills. However, the opportunity to improve communication skills in group discussions is limited because of the lack of partners. To solve this issue as a long-term goal, the aim of this study is to build an autonomous robot that can participate in group discussions, so that its users can repeatedly practice with it. This robot, therefore, has to perform humanlike behaviors with which the users can interact. In this study, the focus was on the generation of two of these behaviors regarding the head of the robot. One is directing its attention to either of the following targets: the other participants or the materials placed on the table. The second is to determine the timings of the robot's nods. These generation models are considered in three situations: when the robot is speaking, when the robot is listening, and when no participant including the robot is speaking. The research question is: whether these behaviors can be generated end-to-end from and only from the features of peer participants. This work is based on a data corpus containing 2.5 h of the discussion sessions of 10 four-person groups. Multimodal features, including the attention of other participants, voice prosody, head movements, and speech turns extracted from the corpus, were used to train support vector machine models for the generation of the two behaviors. The performances of the generation models of attentional focus were in an F-measure range between 0.4 and 0.6. The nodding model had an accuracy of approximately 0.65. Both experiments were conducted in the setting of leave-one-subject-out cross validation. To measure the perceived naturalness of the generated behaviors, a subject experiment was conducted. In the experiment, the proposed models were compared. They were based on a data-driven method with two baselines: (1) a simple statistical model based on behavior frequency and (2) raw experimental data. The evaluation was based on the observation of video clips, in which one of the subjects was replaced by a robot performing head movements in the above-mentioned three conditions. The experimental results showed that there was no significant difference from original human behaviors in the data corpus and proved the effectiveness of the proposed models.","robot,gaze,visual focus of attention,nod,multiparty interaction,machine learning,support vector machine",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,GAZE,MULTIMODAL TECHNOLOGIES AND INTERACTION,https://www.mdpi.com/2414-4088/4/2/15/pdf,
6,Predicting ultimate bond strength of corroded reinforcement and surrounding concrete using a metaheuristic optimized least squares support vector regression model,32,11,7289-7309,"Nhat-Duc Hoang,Xuan-Linh Tran,Hieu Nguyen","Hoang ND,Tran XL,Nguyen H",Tran XL,10.1007/s00521-019-04258-x,Duy Tan University,"The ultimate bond strength of corroded steel reinforcement and surrounding concrete critically affects the load carrying capacity and eventually serviceability of the reinforced concrete structures. This study constructs and verifies a data-driven method for estimating ultimate bond strength. The proposed method is a hybridization of least squares support vector regression (LSSVR) and differential flower pollination (DFP) computational intelligence approaches. Since the problem of ultimate bond strength prediction involves nonlinear and multivariate data modeling, the LSSVR is employed to infer the mapping function between ultimate bond strength and its influencing factors of concrete compressive strength, concrete cover, steel type, diameter of steel bar, bond length, and corrosion level. Moreover, in order to overcome the very challenging task of fine-tuning the LSSVR model training, the DFP algorithm, as a population-based metaheuristic, is utilized to optimize the performance of the LSSVR prediction model. A dataset including 218 experimental tests has been collected from the literature to construct and verify the proposed hybrid method. Experimental results supported by the Wilcoxon signed-rank test point out that the hybridization of LSSVR and DFP can deliver predictive results (root-mean-square error=2.39, mean absolute percentage error=33.82%, and coefficient of determination=0.84) superior to those of benchmark models including the artificial neural network, the multivariate adaptive regression splines, and the regression tree. Additionally, a software program based on the LSSVR model and the DFP optimization result has also been developed and compiled in Visual C#.Net to ease the model implementation. Hence, the hybrid model of DFP and LSSVR can be a promising alternative to assist engineers in the task of evaluating the health of reinforced concrete structures.","Ultimate bond strength,Steel reinforcement,Least squares support vector regression,Differential flower pollination,Machine learning",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"ARTIFICIAL,NEURAL-NETWORK,PARTICLE,SWARM,OPTIMIZATION,SHEAR-STRENGTH,FIREFLY,ALGORITHM,STEEL,BARS,MACHINE,CORROSION,BEHAVIOR,CRACKING,TREE",NEURAL COMPUTING & APPLICATIONS,,
7,Local bit-plane decoded convolutional neural network features for biomedical image retrieval,32,11,7539-7551,"Dubey Shiv Ram,Roy Swalpa Kumar,Chakraborty Soumendu,Mukherjee Snehasis,Chaudhuri Bidyut Baran","Dubey SR,Roy SK,Chakraborty S,Mukherjee S,Chaudhuri BB",Dubey SR,10.1007/s00521-019-04279-6,"Indian Inst Informat Technol, Comp Vis Grp, Chittoor 517646, Andhra Pradesh, India.","Biomedical image retrieval is a challenging problem due to the varying contrast and size of structures in the images. The approaches for biomedical image retrieval generally rely on the feature descriptors to characterize the images. The feature descriptor of query image is compared with the descriptors of images from the database, to find the best matches. Several hand-crafted feature descriptors have been proposed so far for biomedical image retrieval by exploiting the local relationship of neighboring image pixels. It is observed in the literature that the local bit-plane decoded features are well suited for this retrieval task. Moreover, in recent past, it is also observed that the convolutional neural network-based features such as AlexNet, Vgg16, GoogleNet and ResNet perform well in many computer vision-related tasks. Motivated by the success of the deep learning-based approaches, this paper proposes a local bit-plane decoding-based AlexNet descriptor (LBpDAD) for biomedical image retrieval. The proposed LBpDAD is computed by max-fusing the ReLU operated feature maps of pre-trained AlexNet at a particular layer, obtained from the original and local bit-plane decoded images. The proposed approach is also compared with Vgg16, GoogleNet and ResNet models. The experiments on the proposed method over three benchmark biomedical databases of different modalities such as MRI, CT and microscopic show the efficacy of the proposed descriptor.","Biomedical images,Convolutional neural networks,AlexNet,Image retrieval,Local bit-plane decoding",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"FEATURE,DESCRIPTOR,PATTERNS,CLASSIFICATION,ROTATION,MRI",NEURAL COMPUTING & APPLICATIONS,,
8,A holistic deep learning approach for identification and classification of sub-solid lung nodules in computed tomographic scans,84,,,"Savitha G.,Jidesh P.","Savitha G,Jidesh P",Jidesh P,10.1016/j.compeleceng.2020.106626,National Institute of Technology (NIT System),"Prompt detection of malignant lung nodules significantly improves the chance of survivability of the affected patients. The lung nodules in their early stages appear as subsolid or part-solid nodules whose identification remains a challenging task. Many of the present lung nodule detection systems fail to identify the nodules in their early stages. Limitations in the feature extraction process lead to significant false-positive rates, which eventually diminish the accuracy aspects of the system. In this study, a sophisticated deep learning approach is employed for feature extraction which improves the nodule localization or identification stage of the system. Further, the false positives sneaking out of the system are drastically reduced by adopting a Conditional Random Framework in the model. The quantitative demonstrations prove the efficiency of the model to detect sub-solid nodules in CT images. Thus the employability of the model for early detection of the nodules is tested and verified. (c) 2020 Elsevier Ltd. All rights reserved.","Part-solid nodule,Conditional random field,Deep convolution neural network,Computed tomography images",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering",,3.297,,COMPUTERS & ELECTRICAL ENGINEERING,,
9,A MACHINE LEARNING APPROACH BASED ON SVM FOR CLASSIFICATION OF LIVER DISEASES,32,3,,"Fathi Mohammad,Nemati Mohammadreza,Mohammadi Seyed Mohsen,Abbasi-Kesbi Reza","Fathi M,Nemati M,Mohammadi SM,Abbasi-Kesbi R",Abbasi-Kesbi R,10.4015/S1016237220500180,University of Tehran,"The liver is an organ in the body that plays an important role in the production and secretion of the bile. Recently, the number of liver patients are increasing because of the inhalation of harmful gases, the consumption of contaminated foods, herbs, and narcotics. Today, classification algorithms are widely used in diverse medical applications. In this paper, the classification of the liver, and non-liver patients is performed based on a support vector machine (SVM) on two datasets. To this end, the dataset is normalized and then sorted based on a proposed algorithm. After that, the feature selection is performed in order to remove the outliers and missing data. Then, 10-fold cross-validation is used for the data partition. In the end, the classification models of Linear, Quadratic and Gaussian SVM are defined and performance evaluation of the proposed method is investigated by calculation of F1-score, accuracy, and sensitivity. The results show that ILPD data have maximum accuracy, sensitivity, and F1-score of 90.9%, 89.2%, and 94%, respectively, so that a minimum improvement of 17.9% is obtained in accuracy than previous works. Additionally, the highest accuracy, sensitivity, and F1-score of BUPA data is 92.2%, 89%, and 94.3%, separately.","ILPD,BUPA,Liver patients,Classification,SVM",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Engineering,,,"MINIATURE,SENSOR,SYSTEM",BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS,,
10,DIAGNOSIS OF LUNG NODULES FROM 2D COMPUTER TOMOGRAPHY SCANS,32,3,,"Karrar Ayat,Mabrouk Mai S.,AbdEl Wahed Manal","Karrar A,Mabrouk MS,AbdEl Wahed M",Karrar A,10.4015/S1016237220500179,Egyptian Knowledge Bank (EKB),"Cancers typically are both highly dangerous and common. Among these, lung cancer has one of the lowest survival rates compared to other cancers. CT scans can reveal dense masses of different shapes and sizes; in the lungs, these are called lung nodules. This study applied a computer-aided diagnosis (CAD) system to detect candidate nodules - and diagnose it either solitary or juxtapleural - with equivalent diameters, ranging from 7.78 mm to 22.48 mm in a 2D CT slice. Pre-processing and segmentation is a very important step to segment and enhance the CT image. A segmentation and enhancement algorithm is achieved using bilateral filtering, Thresholding the gray-level transformation function, Bounding box and maximum intensity projection. Border artifacts are removed by clearing the lung border, erosion, dilation and superimposing. Feature extraction is done by extracting 20 gray-level co-occurrence matrix features from four directions: 0 degrees, 45 degrees, 90 degrees and 135 degrees and one distance of separation (d = 1 pixel). In the classification step, two classifiers are proposed to classify two types of nodules based on their locations: as juxtapleural or solitary nodules. The two classifiers are a deep learning convolutional neural network (CNN) and the K-nearest neighbor (KNN) algorithm. Random oversampling and 10-fold cross-validation are used to improve the results. In our CAD system, the highest accuracy and sensitivity rates achieved by the CNN were 96% and 95%, respectively, for solitary nodule detection. The highest accuracy and sensitivity rates achieved by the KNN model were 93.8% and 96.7%, respectively, and K was set to 1 to detect juxtapleural nodules.","CT scans,Maximum intensity projection,Convolutional neural network,Deep learning,K-nearest neighbor",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Engineering,,,SYSTEM,BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS,,
11,FFBPNN-BASED HIGH DROWSINESS CLASSIFICATION USING EMG AND WPT,32,3,,Wali Mousa Kadhim,Wali MK,Wali MK,10.4015/S1016237220500234,Middle Technical University,"The detection of drowsiness level is important because it is the main reason for fatal road accidents. Electromyography of the upper arm and shoulder is an important physiological signal affected by drivers' drowsiness, in which its amplitude level and frequency band of the sleep-deprived case are different than those of the alert state. Therefore depending on electromyography (EMG), its drowsiness frequency (80-100 Hz) was detected in order to determine high drowsiness state based on wavelet packet transform (WPT) which decomposes the EMG signal into its approximation and detail coefficients up to level 4 using db2, db7, sym5 and coif5 wavelets. In this research after extraction, the two higher order statistical features, kurtosis and skewness, are computed from 3 s window of the three EMG channels, and analysis of variance test is used to check whether their mean values are different for the different classes as both p-values are less than 0.005 under db2 wavelet. Therefore, they were supplied to feed forward back propagation neural network (FFBPNN) as this type of neural network is used for distinguishing and classification purposes for different objects. They obtained an accuracy of 75% for detecting high levels among other levels of normal and low drowsiness with an average sensitivity of 78.63% and specificity of 75.97% because the spectrum of the EMG alert (non-drowsiness) signal of 80-100 Hz is different from that of drowsy 80-90 Hz and high drowsy 78-95 Hz signals.","Electromyography,Drowsiness frequency,Wavelet packet transform,Feed forward back propagation Neural network",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Engineering,,,"DRIVER,FATIGUE,ELECTROMYOGRAM",BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS,,
12,Epithelial-to-mesenchymal transition is a prognostic marker for patient outcome in advanced stage HNSCC patients treated with chemoradiotherapy,147,,186-194,"van der Heijden Martijn,Essers Paul B. M.,Verhagen Caroline V. M.,Willems Stefan M.,Sanders Joyce,de Roest Reinout H.,Vossen David M.,Leemans C. Rene,Verheij Marcel,Brakenhoff Ruud H.","van der Heijden M,Essers PBM,Verhagen CVM,Willems SM,Sanders J,de Roest RH,Vossen DM,Leemans CR,Verheij M,Brakenhoff RH",Vens C,10.1016/j.radonc.2020.05.013,Netherlands Cancer Institute,"Background: The prognosis of patients with HPV-negative advanced stage head and neck squamous cell carcinoma (HNSCC) remains poor. No prognostic markers other than TNM staging are routinely used in clinic. Epithelial-to-mesenchymal transition (EMT) has been shown to be a strong prognostic factor in other cancer types. The purpose of this study was to determine the role of EMT in HPV-negative HNSCC outcomes.
Methods: Pretreatment tumor material from patients of two cohorts, totalling 174 cisplatin-based chemoradiotherapy treated HPV-negative HNSCC patients, was RNA-sequenced. Seven different EMT gene expression signatures were used for EMT status classification and generation of HNSCC-specific EMT models using Random Forest machine learning.
Results: Mesenchymal classification by all EMT signatures consistently enriched for poor prognosis patients in both cohorts of 98 and 76 patients. Uniand multivariate analyses show important HR of 1.6-5.8, thereby revealing EMT's role in HNSCC outcome. Discordant classification by these signatures prompted the generation of an HNSCC-specific EMT profile based on the concordantly classified samples in the first cohort (cross-validation AUC 0.98). The independent validation cohort confirmed the association of mesenchymal classification by the HNSCC-EMT model with poor overall survival (HR = 3.39, p < 0.005) and progression free survival (HR = 3.01, p < 0.005) in multivariate analysis with TNM. Analysis of an additional HNSCC cohort from PET-positive patients with metastatic disease prior to treatment further supports this relationship and reveals a strong link of EMT to the propensity to metastasize.
Conclusions: EMT in HPV-negative HNSCC co-defines patient outcome after chemoradiotherapy. The generated HNSCC-EMT prediction models can function as strong prognostic biomarkers. (c) 2020 The Authors. Published by Elsevier B.V. Radiotherapy and Oncology 147 (2020) 186-194 This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-ncnd/4.0/).","Epithelial to mesenchymal transition,Head and neck cancer,Prognostic biomarkers,Chemoradiotherapy,HNSCC,RNA-Seq",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,5.881,"GENE-EXPRESSION,CANCER,CELL,HEAD,CARCINOMAS,RESPONSES,SURVIVAL,EGFR",RADIOTHERAPY AND ONCOLOGY,http://www.thegreenjournal.com/article/S0167814020302668/pdf,
13,"Point-of-care, multispectral, smartphone-based dermascopes for dermal lesion screening and erythema monitoring",25,6,,"Uthoff Ross D.,Song Bofan,Maarouf Melody,Shi Vivian,Liang Rongguang","Uthoff RD,Song BF,Maarouf M,Shi V,Liang RG",Uthoff RD; Liang RG,10.1117/1.JBO.25.6.066004,University of Arizona,"Significance: The rates of melanoma and nonmelanoma skin cancer are rising across the globe. Due to a shortage of board-certified dermatologists, the burden of dermal lesion screening and erythema monitoring has fallen to primary care physicians (PCPs). An adjunctive device for lesion screening and erythema monitoring would be beneficial because PCPs are not typically extensively trained in dermatological care.
Aim: We aim to examine the feasibility of using a smartphone-camera-based dermascope and a USB-camera-based dermascope utilizing polarized white-light imaging (PWLI) and polarized multispectral imaging (PMSI) to map dermal chromophores and erythema.
Approach: Two dermascopes integrating LED-based PWLI and PMSI with both a smartphonebased camera and a USB-connected camera were developed to capture images of dermal lesions and erythema. Image processing algorithms were implemented to provide chromophore concentrations and redness measures.
Results: PWLI images were successfully converted to an alternate colorspace for erythema measures, and the spectral bandwidth of the PMSI LED illumination was sufficient for mapping of deoxyhemoglobin, oxyhemoglobin, and melanin chromophores. Both types of dermascopes were able to achieve similar relative concentration results.
Conclusion: Chromophore mapping and erythema monitoring are feasible with PWLI and PMSI using LED illumination and smartphone-based cameras. These systems can provide a simpler, more portable geometry and reduce device costs compared with interference-filterbased or spectrometer-based clinical-grade systems. Future research should include a rigorous clinical trial to collect longitudinal data and a large enough dataset to train and implement a machine learning-based image classifier. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","dermatoscopy,dermoscopy,smartphone imaging,multispectral imaging,mHealth",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,"SKIN,SELF-EXAMINATION,DIGITAL,DERMOSCOPY,CUTANEOUS,MELANOMA,DIFFERENTIATION,DIAGNOSIS,DENSITY,TRENDS,NEVI",JOURNAL OF BIOMEDICAL OPTICS,https://europepmc.org/articles/pmc7309634?pdf=render,
14,Fast intelligent cell phenotyping for high-throughput optofluidic time-stretch microscopy based on the XGBoost algorithm,25,6,,"Zhao Wanyue,Guo Yingxue,Yang Sigang,Chen Minghua,Chen Hongwei","Zhao WY,Guo YX,Yang SG,Chen MH,Chen HW",Chen HW,10.1117/1.JBO.25.6.066001,Tsinghua University,"Significance: The use of optofluidic time-stretch flow cytometry enables extreme-throughput cell imaging but suffers from the difficulties of capturing and processing a large amount of data. As significant amounts of continuous image data are generated, the images require identification with high speed.
Aim: We present an intelligent cell phenotyping framework for high-throughput optofluidic time-stretch microscopy based on the XGBoost algorithm, which is able to classify obtained cell images rapidly and accurately. The applied image recognition consists of density-based spatial clustering of applications with noise outlier detection, histograms of oriented gradients combining gray histogram fused feature, and XGBoost classification.
Approach: We tested the ability of this framework against other previously proposed or commonly used algorithms to phenotype two groups of cell images. We quantified their performances with measures of classification ability and computational complexity based on AUC and test runtime. The tested cell image datasets were acquired from high-throughput imaging of over 20,000 drug-treated and untreated cells with an optofluidic time-stretch microscope.
Results: The framework we built beats other methods with an accuracy of over 97% and a classification frequency of 3000 cells/s. In addition, we determined the optimal structure of training sets according to model performances under different training set components.
Conclusions: The proposed XGBoost-based framework acts as a promising solution to processing large flow image data. This work provides a foundation for future cell sorting and clinical practice of high-throughput imaging cytometers. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","time-stretch microscopy,imaging cytometry,automatic cell detection,machine learning",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,CLASSIFICATION,JOURNAL OF BIOMEDICAL OPTICS,https://europepmc.org/articles/pmc7267411?pdf=render,
15,Recent Advances on the Design Automation for Performance-Optimized Fiber Reinforced Polymer Composite Components,4,2,,"Boon Yi Di,Joshi Sunil Chandrakant,Bhudolia Somen Kumar,Gohel Goram","Boon YD,Joshi SC,Bhudolia SK,Gohel G",Boon YD; Bhudolia SK,10.3390/jcs4020061,Nanyang Technological University & National Institute of Education (NIE) Singapore,"Advanced manufacturing techniques, such as automated fiber placement and additive manufacturing enables the fabrication of fiber-reinforced polymer composite components with customized material and structural configurations. In order to take advantage of this customizability, the design process for fiber-reinforced polymer composite components needs to be improved. Machine learning methods have been identified as potential techniques capable of handling the complexity of the design problem. In this review, the applications of machine learning methods in various aspects of structural component design are discussed. They include studies on microstructure-based material design, applications of machine learning models in stress analysis, and topology optimization of fiber-reinforced polymer composites. A design automation framework for performance-optimized fiber-reinforced polymer composite components is also proposed. The proposed framework aims to provide a comprehensive and efficient approach for the design and optimization of fiber-reinforced polymer composite components. The challenges in building the models required for the proposed framework are also discussed briefly.","fiber-reinforced polymer,deep learning,composite microstructure,stress analysis,topology optimization",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Materials Science,,,"CONTINUUM,DAMAGE,MODEL,TOPOLOGY,OPTIMIZATION,TAPE-PLACEMENT,CARBON,NETWORK,GLASS",JOURNAL OF COMPOSITES SCIENCE,https://www.mdpi.com/2504-477X/4/2/61/pdf,
16,A Machine Learning Model to Detect Flow Disturbances during Manufacturing of Composites by Liquid Moulding,4,2,,"Gonzalez Carlos,Fernandez-Leon Joaquin","Gonzalez C,Fernandez-Leon J",Gonzalez C,10.3390/jcs4020071,IMDEA Materials Institute,"In this work, a supervised machine learning (ML) model was developed to detect flow disturbances caused by the presence of a dissimilar material region in liquid moulding manufacturing of composites. The machine learning model was designed to predict the position, size and relative permeability of an embedded rectangular dissimilar material region through use of only the signals corresponding to an array of pressure sensors evenly distributed on the mould surface. The burden of experimental tests required to train in an efficient manner such predictive models is so high that favours its substitution with synthetically-generated simulation datasets. A regression model based on the use of convolutional neural networks (CNN) was developed and trained with data generated from mould-filling simulations carried out through use of OpenFoam as numerical solver. The evolution of the pressure sensors through the filling time was stored and used as grey-level images containing information regarding the pressure, the sensor location within the mould and filling time. The trained CNN model was able to recognise the presence of a dissimilar material region from the data used as inputs, meeting accuracy expectation in terms of detection. The purpose of this work was to establish a general framework for fully-synthetic-trained machine learning models to address the occurrence of manufacturing disturbances without placing emphasis on its performance, robustness and optimization. Accuracy and model robustness were also addressed in the paper. The effect of noise signals, pressure sensor network size, presence of different shape dissimilar regions, among others, were analysed in detail. The ability of ML models to examine and overcome complex physical and engineering problems such as defects produced during manufacturing of materials and parts is particularly innovative and highly aligned with Industry 4.0 concepts.","machine learning,mould filling simulations,composite materials,liquid moulding",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Materials Science,,,NETWORKS,JOURNAL OF COMPOSITES SCIENCE,https://www.mdpi.com/2504-477X/4/2/71/pdf,
17,Response SurfaceMethodology and Artificial Neural Network-Based Models for Predicting Performance of Wire Electrical Discharge Machining of Inconel 718 Alloy,4,2,,"Lalwani Vishal,Sharma Priyaranjan,Pruncu Catalin Iulian,Unune Deepak Rajendra","Lalwani V,Sharma P,Pruncu CI,Unune DR",Pruncu CI,10.3390/jmmp4020044,Imperial College London,"This paper deals with the development and comparison of prediction models established using response surface methodology (RSM) and artificial neural network (ANN) for a wire electrical discharge machining (WEDM) process. The WEDM experiments were designed using central composite design (CCD) for machining of Inconel 718 superalloy. During experimentation, the pulse-on-time (T-ON), pulse-off-time (T-OFF), servo-voltage (SV), peak current (I-P), and wire tension (WT) were chosen as control factors, whereas, the kerf width (Kf), surface roughness (R-a), and materials removal rate (MRR) were selected as performance attributes. The analysis of variance tests was performed to identify the control factors that significantly affect the performance attributes. The double hidden layer ANN model was developed using a back-propagation ANN algorithm, trained by the experimental results. The prediction accuracy of the established ANN model was found to be superior to the RSM model. Finally, the Non-Dominated Sorting Genetic Algorithm-II (NSGA-II) was implemented to determine the optimum WEDM conditions from multiple objectives.","response surface method (RSM),artificial neural network (ANN),wire electrical discharge machining (WEDM),kerf width (Kf),surface roughness (R-a),NSGA-II",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Engineering,Materials Science",,,"MATERIAL,REMOVAL,RATE,SURFACE-ROUGHNESS,PARAMETRIC,OPTIMIZATION,WEDM,PROCESS,CUT,EDM,TAGUCHI,STEEL,ANN,METHODOLOGY,INTEGRITY",JOURNAL OF MANUFACTURING AND MATERIALS PROCESSING,https://www.mdpi.com/2504-4494/4/2/44/pdf,
18,First Steps through Intelligent Grinding Using Machine Learning via Integrated Acoustic Emission Sensors,4,2,,"Mirifar Siamak,Kadivar Mohammadali,Azarhoushang Bahman","Mirifar S,Kadivar M,Azarhoushang B",Kadivar M,10.3390/jmmp4020035,"Furtwangen Univ Appl Sci, Inst Precis Machining KSF, D-78056 Villingen Schwenningen, Germany.","The surface roughness of the ground parts is an essential factor in the assessment of the grinding process, and a crucial criterion in choosing the dressing and grinding tools and parameters. Additionally, the surface roughness directly influences the functionality of the workpiece. The application of artificial intelligence in the prediction of complex results of machining processes, such as surface roughness and cutting forces has increasingly become popular. This paper deals with the design of the appropriate artificial neural network for the prediction of the ground surface roughness and grinding forces, through an individual integrated acoustic emission (AE) sensor in the machine tool. Two models were trained and tested. Once using only the grinding parameters, and another with both acoustic emission signals and grinding parameters as input data. The recorded AE-signal was pre-processed, amplified and denoised. The feedforward neural network was chosen for the modeling with Bayesian backpropagation, and the model was tested by various experiments with different grinding and neural network parameters. It was found that the predictions presented by the achieved network parameters model agreed well with the experimental results with a superb accuracy of 99 percent. The results also showed that the AE signals act as an additional input parameter in addition to the grinding parameters, and could significantly increase the efficiency of the neural network in predicting the grinding forces and the surface roughness.","grinding,artificial neural networks,acoustic emission,online monitoring,process prediction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Engineering,Materials Science",,,"SURFACE-ROUGHNESS,NEURAL-NETWORK,PREDICTION,REGRESSION,SIMULATION,FORCES",JOURNAL OF MANUFACTURING AND MATERIALS PROCESSING,https://www.mdpi.com/2504-4494/4/2/35/pdf,
19,A Deep Learning Approach for Segmentation of Red Blood Cell Images and Malaria Detection,22,6,,"Delgado-Ortet Maria,Molina Angel,Alferez Santiago,Rodellar Jose,Merino Anna","Delgado-Ortet M,Molina A,Alferez S,Rodellar J,Merino A",Delgado-Ortet M; Merino A,10.3390/e22060657,University of Barcelona,"Malaria is an endemic life-threating disease caused by the unicellular protozoan parasites of the genusPlasmodium. Confirming the presence of parasites early in all malaria cases ensures species-specific antimalarial treatment, reducing the mortality rate, and points to other illnesses in negative cases. However, the gold standard remains the light microscopy of May-Grunwald-Giemsa (MGG)-stained thin and thick peripheral blood (PB) films. This is a time-consuming procedure, dependent on a pathologist's skills, meaning that healthcare providers may encounter difficulty in diagnosing malaria in places where it is not endemic. This work presents a novel three-stage pipeline to (1) segment erythrocytes, (2) crop and mask them, and (3) classify them into malaria infected or not. The first and third steps involved the design, training, validation and testing of a Segmentation Neural Network and a Convolutional Neural Network from scratch using a Graphic Processing Unit. Segmentation achieved a global accuracy of 93.72% over the test set and the specificity for malaria detection in red blood cells (RBCs) was 87.04%. This work shows the potential that deep learning has in the digital pathology field and opens the way for future improvements, as well as for broadening the use of the created networks.","deep learning,malaria detection,red blood cell (RBC) segmentation,blood cell classification,convolutional neural networks",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,2.587,DIAGNOSIS,ENTROPY,https://upcommons.upc.edu/bitstream/2117/343339/1/entropy-22-00657-v3.pdf,
20,Rhythm Analysis during Cardiopulmonary Resuscitation Using Convolutional Neural Networks,22,6,,"Isasi Iraia,Irusta Unai,Aramendi Elisabete,Eftestol Trygve,Kramer-Johansen Jo,Wik Lars","Isasi I,Irusta U,Aramendi E,Eftestol T,Kramer-Johansen J,Wik L",Isasi I,10.3390/e22060595,University of Basque Country,"Chest compressions during cardiopulmonary resuscitation (CPR) induce artifacts in the ECG that may provoque inaccurate rhythm classification by the algorithm of the defibrillator. The objective of this study was to design an algorithm to produce reliable shock/no-shock decisions during CPR using convolutional neural networks (CNN). A total of 3319 ECG segments of 9sextracted during chest compressions were used, whereof 586 were shockable and 2733 nonshockable. Chest compression artifacts were removed using a Recursive Least Squares (RLS) filter, and the filtered ECG was fed to a CNN classifier with three convolutional blocks and two fully connected layers for the shock/no-shock classification. A 5-fold cross validation architecture was adopted to train/test the algorithm, and the proccess was repeated 100 times to statistically characterize the performance. The proposed architecture was compared to the most accurate algorithms that include handcrafted ECG features and a random forest classifier (baseline model). The median (90% confidence interval) sensitivity, specificity, accuracy and balanced accuracy of the method were 95.8% (94.6-96.8), 96.1% (95.8-96.5), 96.1% (95.7-96.4) and 96.0% (95.5-96.5), respectively. The proposed algorithm outperformed the baseline model by 0.6-points in accuracy. This new approach shows the potential of deep learning methods to provide reliable diagnosis of the cardiac rhythm without interrupting chest compression therapy.","out-of-hospital cardiac arrest (OHCA),cardiopulmonary resuscitation (CPR),electrocardiogram (ECG),adaptive filter,deep learning,machine learning,convolutional neural network (CNN),random forest (RF) classifier",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,2.587,"AUTOMATED,EXTERNAL,DEFIBRILLATOR,HOSPITAL,CARDIAC-ARREST,CHEST,COMPRESSIONS,CPR,ARTIFACTS,CLASSIFICATION,ELECTROCARDIOGRAM,FIBRILLATION,FREQUENCY,REMOVAL,QUALITY",ENTROPY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7845778,
21,Assessment of Airflow and Oximetry Signals to Detect Pediatric Sleep Apnea-Hypopnea Syndrome Using AdaBoost,22,6,,"Jimenez-Garcia Jorge,Gutierrez-Tobal Gonzalo C.,Garcia Maria,Kheirandish-Gozal Leila,Martin-Montero Adrian,Alvarez Daniel,del Campo Felix,Gozal David,Hornero Roberto","Jimenez-Garcia J,Gutierrez-Tobal GC,Garcia M,Kheirandish-Gozal L,Martin-Montero A,Alvarez D,del Campo F,Gozal D,Hornero R",Jimenez-Garcia J,10.3390/e22060670,Universidad de Valladolid,"The reference standard to diagnose pediatric Obstructive Sleep Apnea (OSA) syndrome is an overnight polysomnographic evaluation. When polysomnography is either unavailable or has limited availability, OSA screening may comprise the automatic analysis of a minimum number of signals. The primary objective of this study was to evaluate the complementarity of airflow (AF) and oximetry (SpO(2)) signals to automatically detect pediatric OSA. Additionally, a secondary goal was to assess the utility of a multiclass AdaBoost classifier to predict OSA severity in children. We extracted the same features from AF and SpO(2)signals from 974 pediatric subjects. We also obtained the 3% Oxygen Desaturation Index (ODI) as a common clinically used variable. Then, feature selection was conducted using the Fast Correlation-Based Filter method and AdaBoost classifiers were evaluated. Models combining ODI 3% and AF features outperformed the diagnostic performance of each signal alone, reaching 0.39 Cohens's kappa in the four-class classification task. OSA vs. No OSA accuracies reached 81.28%, 82.05% and 90.26% in the apnea-hypopnea index cutoffs 1, 5 and 10 events/h, respectively. The most relevant information from SpO(2)was redundant with ODI 3%, and AF was complementary to them. Thus, the joint analysis of AF and SpO(2)enhanced the diagnostic performance of each signal alone using AdaBoost, thereby enabling a potential screening alternative for OSA in children.","sleep apnea-hypopnea syndrome,airflow,oximetry,AdaBoost,spectral analysis,nonlinear analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,,"RESPIRATORY,POLYGRAPHY,NOCTURNAL,OXIMETRY,DIAGNOSIS,CHILDREN,POLYSOMNOGRAPHY,RECORDINGS,ENTROPY,UTILITY",ENTROPY,https://www.mdpi.com/1099-4300/22/6/670/pdf,
22,Groupwise Non-Rigid Registration with Deep Learning: An Affordable Solution Applied to 2D Cardiac Cine MRI Reconstruction,22,6,,"Martin-Gonzalez Elena,Sevilla Teresa,Revilla-Orodea Ana,Casaseca-de-la-Higuera Pablo,Alberola-Lopez Carlos","Martin-Gonzalez E,Sevilla T,Revilla-Orodea A,Casaseca-de-la-Higuera P,Alberola-Lopez C",Martin-Gonzalez E,10.3390/e22060687,Universidad de Valladolid,"Groupwise image (GW) registration is customarily used for subsequent processing in medical imaging. However, it is computationally expensive due to repeated calculation of transformations and gradients. In this paper, we propose a deep learning (DL) architecture that achieves GW elastic registration of a 2D dynamic sequence on an affordable average GPU. Our solution, referred to as dGW, is a simplified version of the well-known U-net. In our GW solution, the image that the other images are registered to, referred to in the paper astemplate image, is iteratively obtained together with the registered images. Design and evaluation have been carried out using 2D cine cardiac MR slices from 2 databases respectively consisting of 89 and 41 subjects. The first database was used for training and validation with 66.6-33.3% split. The second one was used for validation (50%) and testing (50%). Additional network hyperparameters, which are-in essence-those that control the transformation smoothness degree, are obtained by means of a forward selection procedure. Our results show a 9-fold runtime reduction with respect to an optimization-based implementation; in addition, making use of the well-known structural similarity (SSIM) index we have obtained significative differences with dGW with respect to an alternative DL solution based on Voxelmorph.","non-rigid registration,elastic motion,CNN,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,2.587,"COMPRESSED,SENSING,RECONSTRUCTION,MOTION,QUALITY",ENTROPY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7517224,
23,Numerical modeling of SiC by low-pressure chemical vapor deposition from methyltrichlorosilane,28,6,1733-1743,"Guan Kang,Gao Yong,Zeng Qingfeng,Luan Xingang,Zhang Yi,Cheng Laifei,Wu Jianqing,Lu Zhenya","Guan K,Gao Y,Zeng QF,Luan XG,Zhang Y,Cheng LF,Wu JQ,Lu ZY",Wu JQ; Lu ZY,10.1016/j.cjche.2020.03.035,South China University of Technology,"The development of functional relationships between the observed deposition rate and the experimental conditions is an important step toward understanding and optimizing low-pressure chemical vapor deposition (LPCVD) or low-pressure chemical vapor infiltration (LPCVI). In the field of ceramic matrix composites (CMCs), methyltrichlorosilane (CH3SiCl3, MTS) is the most widely used source gas system for SiC, because stoichiometric SiC deposit can be facilitated at 900 degrees C-1300 degrees C. However, the reliability and accuracy of existing numerical models for these processing conditions are rarely reported. In this study, a comprehensive transport model was coupled with gas-phase and surface kinetics. The resulting gas-phase kinetics was confirmed via the measured concentration of gaseous species. The relationship between deposition rate and 24 gaseous species has been effectively evaluated by combining the special superiority of the novel extreme machine learning method and the conventional sticking coefficient method. Surface kinetics were then proposed and shown to reproduce the experimental results. The proposed simulation strategy can be used for different material systems. (C) 2020 The Chemical Industry and Engineering Society of China, and Chemical Industry Press Co., Ltd. All rights reserved.","Chemical vapor deposition,MTS/H-2,Gas-phase and surface kinetics,Extreme learning machine method,Numerical model",Article,"CHEMICAL INDUSTRY PRESS CO LTD, NO 13, QINGNIANHU SOUTH ST, DONGCHENG DIST, BEIJING 100011, PEOPLES R CHINA",Engineering,,2.853,"SILICON-CARBIDE,DEPOSITION,EXTREME,LEARNING-MACHINE,GAS-PHASE,MULTISCALE,ANALYSIS,HYDROGEN-CHLORIDE,CVD,SIMULATION,KINETICS,GROWTH,CERAMICS",CHINESE JOURNAL OF CHEMICAL ENGINEERING,,
24,Conventional Machine Learning and Deep Learning Approach for Multi-Classification of Breast Cancer Histopathology Images-a Comparative Insight,33,3,632-654,"Sharma Shallu,Mehra Rajesh","Sharma S,Mehra R",Sharma S,10.1007/s10278-019-00307-y,"National Institute of Technical Teachers Training & Research, Chandigarh","Automatic multi-classification of breast cancer histopathological images has remained one of the top-priority research areas in the field of biomedical informatics, due to the great clinical significance of multi-classification in providing diagnosis and prognosis of breast cancer. In this work, two machine learning approaches are thoroughly explored and compared for the task of automatic magnification-dependent multi-classification on a balanced BreakHis dataset for the detection of breast cancer. The first approach is based on handcrafted features which are extracted using Hu moment, color histogram, and Haralick textures. The extracted features are then utilized to train the conventional classifiers, while the second approach is based on transfer learning where the pre-existing networks (VGG16, VGG19, and ResNet50) are utilized as feature extractor and as a baseline model. The results reveal that the use of pre-trained networks as feature extractor exhibited superior performance in contrast to baseline approach and handcrafted approach for all the magnifications. Moreover, it has been observed that the augmentation plays a pivotal role in further enhancing the classification accuracy. In this context, the VGG16 network with linear SVM provides the highest accuracy that is computed in two forms, (a) patch-based accuracies (93.97% for 40x, 92.92% for 100x, 91.23% for 200x, and 91.79% for 400x); (b) patient-based accuracies (93.25% for 40x, 91.87% for 100x, 91.5% for 200x, and 92.31% for 400x) for the classification of magnification-dependent histopathological images. Additionally, ""Fibro-adenoma"" (benign) and ""Mucous Carcinoma"" (malignant) classes have been found to be the most complex classes for the entire magnification factors.","Breast cancer,Histopathological images,Multi-classification,Handcrafted features,Transfer learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,,JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7256154,
25,"Predicting Unnecessary Nodule Biopsies from a Small, Unbalanced, and Pathologically Proven Dataset by Transfer Learning",33,3,685-696,"Han Fangfang,Yan Linkai,Chen Junxin,Teng Yueyang,Chen Shuo,Qi Shouliang,Qian Wei,Yang Jie,Moore William,Zhang Shu","Han FF,Yan LK,Chen JX,Teng YY,Chen S,Qi SL,Qian W,Yang J,Moore W,Zhang S",Qian W,10.1007/s10278-019-00306-z,University of Texas System,"This study explores an automatic diagnosis method to predict unnecessary nodule biopsy from a small, unbalanced, and pathologically proven database. The automatic diagnosis method is based on a convolutional neural network (CNN) model. Because of the small and unbalanced samples, the presented method aims to improve the transfer learning capability via the VGG16 architecture and optimize the related transfer learning parameters. For comparison purpose, a traditional machine learning method is implemented, which extracts the texture features and classifies the features by support vector machine (SVM). The database includes 68 biopsied nodules, 16 are pathologically proven benign and the remaining 52 are malignant. To consider the volumetric data by the CNN model, each image slice from each nodule volume is selected randomly until all image slices of each nodule are utilized. The leave-one-out and 10-folder cross validations are applied to train and test the randomly selected 68 image slices (one image slice from one nodule) in each experiment, respectively. The averages over all the experimental outcomes are the final results. The experiments revealed that the features from both the medical and the natural images share the similarity of focusing on simpler and less-abstract objects, leading to the conclusion that not the more the transfer convolutional layers, the better the classification results. Transfer learning from other larger datasets can supply additional information to small and unbalanced datasets to improve the classification performance. The presented method has shown the potential to adapt CNN architecture to improve the prediction of unnecessary nodule biopsy from small, unbalanced, and pathologically proven volumetric dataset.","Lung cancer screening,Small and unbalanced dataset,Decrease unnecessary biopsy,Transfer learning,Convolutional neural networks",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"SOLITARY,PULMONARY,NODULES,CANCER,CLASSIFICATION,SEGMENTATION,MALIGNANCY,SURVIVAL",JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7256141,
26,Real-time Malaria Parasite Screening in Thick Blood Smears for Low-Resource Setting,33,3,763-775,"Chibuta Samson,Acar Aybar C.","Chibuta S,Acar AC",Chibuta S,10.1007/s10278-019-00284-2,Middle East Technical University,"Malaria is a serious public health problem in many parts of the world. Early diagnosis and prompt effective treatment are required to avoid anemia, organ failure, and malaria-associated deaths. Microscopic analysis of blood samples is the preferred method for diagnosis. However, manual microscopic examination is very laborious and requires skilled health personnel of which there is a critical shortage in the developing world such as in sub-Saharan Africa. Critical shortages of trained health personnel and the inability to cope with the workload to examine malaria slides are among the main limitations of malaria microscopy especially in low-resource and high disease burden areas. We present a low-cost alternative and complementary solution for rapid malaria screening for low resource settings to potentially reduce the dependence on manual microscopic examination. We develop an image processing pipeline using a modified YOLOv3 detection algorithm to run in real time on low-cost devices. We test the performance of our solution on two datasets. In the dataset collected using a microscope camera, our model achieved 99.07% accuracy and 97.46% accuracy on the dataset collected using a mobile phone camera. While the mean average precision of our model is on par with human experts at an object level, we are several orders of magnitude faster than human experts as we can detect parasites in images as well as videos in real time.","Malaria parasites,Microscopy,Object detection,Deep learning,Low-cost",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,,JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7256156,
27,Development of use-specific high-performance cyber-nanomaterial optical detectors by effective choice of machine learning algorithms,1,2,,"Hejazi Davoud,Liu Shuangjun,Farnoosh Amirreza,Ostadabbas Sarah,Kar Swastik","Hejazi D,Liu SJ,Farnoosh A,Ostadabbas S,Kar S",Ostadabbas S,10.1088/2632-2153/ab8967,Northeastern University,"Due to their inherent variabilities, nanomaterials-based sensors are challenging to translate into real-world applications, where reliability and reproducibility are key. Machine learning can be a powerful approach for obtaining reliable inferences from data generated by such sensors. Here, we show that the best choice of ML algorithm in a cyber-nanomaterial detector is largely determined by the specific use-considerations, including accuracy, computational cost, speed, and resilience against drifts and long-term ageing effects. When sufficient data and computing resources are provided, the highest sensing accuracy can be achieved by the k-nearest neighbors (kNNs) and Bayesian inference algorithms, however, these algorithms can be computationally expensive for real-time applications. In contrast, artificial neural networks (ANNs) are computationally expensive to train (off-line), but they provide the fastest result under testing conditions (on-line) while remaining reasonably accurate. When access to data is limited, support vector machines (SVMs) can perform well even with small training sample sizes, while other algorithms show considerable reduction in accuracy if data is scarce, hence, setting a lower limit on the size of required training data. We also show by tracking and modeling the long-term drifts of the detector performance over a one year time-frame, it is possible to dramatically improve the predictive accuracy without any re-calibration. Our research shows for the first time that if the ML algorithm is chosen specific to the use-case, low-cost solution-processed cyber-nanomaterial detectors can be practically implemented under diverse operational requirements, despite their inherent variabilities.","2D materials,artificial neural networks (ANN),Bayesian inference,k-nearest neighbor (kNN),optical wavelength estimation,support vector machine (SVM),transition metal dichalcogenides (TMDs)",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Computer Science,Science & Technology - Other Topics",,,"PREDICTION,INTERNET",MACHINE LEARNING-SCIENCE AND TECHNOLOGY,http://arxiv.org/pdf/1912.11751,
28,A charge density prediction model for hydrocarbons using deep neural networks,1,2,,"Kamal Deepak,Chandrasekaran Anand,Batra Rohit,Ramprasad Rampi","Kamal D,Chandrasekaran A,Batra R,Ramprasad R",Ramprasad R,10.1088/2632-2153/ab5929,University System of Georgia,"The electronic charge density distribution rho(r) of a given material is among the most fundamental quantities in quantum simulations from which many large scale properties and observables can be calculated. Conventionally, rho(r) is obtained using Kohn-Sham density functional theory (KS-DFT) based methods. But, the high computational cost of KS-DFT renders it intractable for systems involving thousands/millions of atoms. Thus, recently there has been efforts to bypass expensive KS equations, and directly predict rho(r) using machine learning (ML) based methods. Here, we build upon one such scheme to create a robust and reliable rho(r) prediction model for a diverse set of hydrocarbons, involving huge chemical and morphological complexity /(saturated, unsaturated molecules, cyclo-groups and amorphous and semi-crystalline polymers). We utilize a grid-based fingerprint to capture the atomic neighborhood around an arbitrary point in space, and map it to the reference rho(r) obtained from standard DFT calculations at that point. Owing to the grid-based learning, dataset sizes exceed billions of points, which is trained using deep neural networks in conjunction with a incremental learning based approach. The accuracy and transferability of the ML approach is demonstrated on not only a diverse test set, but also on a completely unseen system of polystyrene under different strains. Finally, we note that the general approach adopted here could be easily extended to other material systems, and can be used for quick and accurate determination of rho(r) for DFT charge density initialization, computing dipole or quadrupole, and other observables for which reliable density functional are known.","electron density,machine learning,hydrocarbons,density functional theory,neural networks",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Computer Science,Science & Technology - Other Topics",,,"DER-WAALS,MOLECULES,ELECTRONIC-STRUCTURE,MACHINE,FRAMEWORK,DESIGN",MACHINE LEARNING-SCIENCE AND TECHNOLOGY,https://doi.org/10.1088/2632-2153/ab5929,
29,SMILES-X: autonomous molecular compounds characterization for small datasets without descriptors,1,2,,"Lambard Guillaume,Gracheva Ekaterina","Lambard G,Gracheva E",Lambard G,10.1088/2632-2153/ab57f3,National Institute for Materials Science,"There is more and more evidence that machine learning can be successfully applied in materials science and related fields. However, datasets in these fields are often quite small (from tens to several thousands of samples). This means the most advanced machine learning techniques remain neglected, as they are considered to be applicable to big data only. Moreover, materials informatics methods often rely on human-engineered descriptors, that should be carefully chosen, or even created, to fit the physicochemical property that one intends to predict. In this article, we propose a new method that tackles both the issue of small datasets and the difficulty of developing task-specific descriptors. The SMILES-X is an autonomous pipeline for molecular compounds characterisation based on a {Embed-Encode-Attend-Predict} neural architecture with a data-specific Bayesian hyper-parameters optimisation. The only input to the architecture-the SMILES strings-are de-canonicalised in order to efficiently augment the data. One of the key features of the architecture is the attention mechanism, which enables the interpretation of output predictions without extra computational cost. The SMILES-X achieves state-of-the-art results in the inference of aqueous solubility ((RMSE) over bar (test)similar or equal to 0.57 +/- 0.07 mols/L), hydration free energy ((RMSE) over bar (test)similar or equal to 0.81 +/- 0.22 kcal/mol, which is similar to 24.5% better than molecular dynamics simulations), and octanol/water distribution coefficient ((RMSE) over bar (test)similar or equal to 0.59 +/- 0.02 for LogD at pH 7.4) of molecular compounds. The SMILES-X is intended to become an important asset in the toolkit of materials scientists and chemists. The source code for the SMILES-X is available at .","cheminformatics,small molecules,SMILES,natural language processing,machine learning,attention mechanism,small datasets",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Computer Science,Science & Technology - Other Topics",,,"ORGANIC-CHEMISTRY,DRUG,DISCOVERY,PREDICTION,LANGUAGE,COMPLEX",MACHINE LEARNING-SCIENCE AND TECHNOLOGY,http://arxiv.org/pdf/1906.09938,
30,Deep learning-guided surface characterization for autonomous hydrogen lithography,1,2,,"Rashidi Mohammad,Croshaw Jeremiah,Mastel Kieran,Tamura Marcus,Hosseinzadeh Hedieh,Wolkow Robert A.","Rashidi M,Croshaw J,Mastel K,Tamura M,Hosseinzadeh H,Wolkow RA",Croshaw J; Wolkow RA,10.1088/2632-2153/ab6d5e,University of Alberta,"As the development of atom scale devices transitions from novel, proof-of-concept demonstrations to state-of-the-art commercial applications, automated assembly of such devices must be implemented. Here we present an automation method for the identification of defects prior to atomic fabrication via hydrogen lithography using deep learning. We trained a convolutional neural network to locate and differentiate between surface features of the technologically relevant hydrogen-terminated silicon surface imaged using a scanning tunneling microscope. Once the positions and types of surface features are determined, the predefined atomic structures are patterned in a defect-free area. By training the network to differentiate between common defects we are able to avoid charged defects as well as edges of the patterning terraces. Augmentation with previously developed autonomous tip shaping and patterning modules allows for atomic scale lithography with minimal user intervention.","convolutional neural network,hydrogen terminated silicon,scanning probe microscopy,surface dangling bonds,automated fabrication,hydrogen lithography",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Computer Science,Science & Technology - Other Topics",,,"SELF-DIRECTED,GROWTH,ATOM,IMAGES,STEP",MACHINE LEARNING-SCIENCE AND TECHNOLOGY,http://arxiv.org/pdf/1902.08818,
31,Synergizing medical imaging and radiotherapy with deep learning,1,2,,"Shan Hongming,Jia Xun,Yan Pingkun,Li Yunyao,Paganetti Harald,Wang Ge","Shan HM,Jia X,Yan PK,Li YY,Paganetti H,Wang G",Wang G,10.1088/2632-2153/ab869f,Rensselaer Polytechnic Institute,"This article reviews deep learning methods for medical imaging (focusing on image reconstruction, segmentation, registration, and radiomics) and radiotherapy (ranging from planning and verification to prediction) as well as the connections between them. Then, future topics are discussed involving semantic analysis through natural language processing and graph neural networks. It is believed that deep learning in particular, and artificial intelligence and machine learning in general, will have a revolutionary potential to advance and synergize medical imaging and radiotherapy for unprecedented smart precision healthcare.","LOW-DOSE CT,GENERATIVE ADVERSARIAL NETWORK,CONVOLUTIONAL NEURAL-NETWORK,KNOWLEDGE-BASED PREDICTION,BRAIN-TUMOR SEGMENTATION,LUNG-CANCER,AT-RISK,RECONSTRUCTION,RADIOMICS,IMAGES",Review,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Computer Science,Science & Technology - Other Topics",,,"LOW-DOSE,CT,GENERATIVE,ADVERSARIAL,NETWORK,CONVOLUTIONAL,NEURAL-NETWORK,KNOWLEDGE-BASED,PREDICTION,BRAIN-TUMOR,SEGMENTATION,LUNG-CANCER,AT-RISK,RECONSTRUCTION,RADIOMICS,IMAGES",MACHINE LEARNING-SCIENCE AND TECHNOLOGY,https://iopscience.iop.org/article/10.1088/2632-2153/ab869f/pdf,
32,A machine learning workflow for molecular analysis: application to melting points,1,2,,"Sivaraman Ganesh,Jackson Nicholas E.,Sanchez-Lengeling Benjamin,Vazquez-Mayagoitia Alvaro,Aspuru-Guzik Alan,Vishwanath Venkatram,de Pablo Juan J.","Sivaraman G,Jackson NE,Sanchez-Lengeling B,Vazquez-Mayagoitia A,Aspuru-Guzik A,Vishwanath V,de Pablo JJ",Jackson NE,10.1088/2632-2153/ab8aa3,United States Department of Energy (DOE),"Computational tools encompassing integrated molecular prediction, analysis, and generation are key for molecular design in a variety of critical applications. In this work, we develop a workflow for molecular analysis (MOLAN) that integrates an ensemble of supervised and unsupervised machine learning techniques to analyze molecular data sets. The MOLAN workflow combines molecular featurization, clustering algorithms, uncertainty analysis, low-bias dataset construction, high-performance regression models, graph-based molecular embeddings and attribution, and a semi-supervised variational autoencoder based on the novel SELFIES representation to enable molecular design. We demonstrate the utility of the MOLAN workflow in the context of a challenging multi-molecule property prediction problem: the determination of melting points solely from single molecule structure. This application serves as a case study for how to employ the MOLAN workflow in the context of molecular property prediction.","materials,melting point,machine learning,workflow",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Computer Science,Science & Technology - Other Topics",,,"PREDICTION,CLASSIFICATION,DESIGN,MODELS,REPRESENTATION,QSPR,SET",MACHINE LEARNING-SCIENCE AND TECHNOLOGY,https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/60c744c3702a9b73a718a8d7/original/a-diversified-machine-learning-strategy-for-predicting-and-understanding-molecular-melting-points.pdf,
33,Methods for comparing uncertainty quantifications for material property predictions,1,2,,"Tran Kevin,Neiswanger Willie,Yoon Junwoong,Zhang Qingyang,Xing Eric,Ulissi Zachary W.","Tran K,Neiswanger W,Yoon J,Zhang QY,Xing E,Ulissi ZW",Ulissi ZW,10.1088/2632-2153/ab7e1a,Carnegie Mellon University,"Data science and informatics tools have been proliferating recently within the computational materials science and catalysis fields. This proliferation has spurned the creation of various frameworks for automated materials screening, discovery, and design. Underpinning these frameworks are surrogate models with uncertainty estimates on their predictions. These uncertainty estimates are instrumental for determining which materials to screen next, but the computational catalysis field does not yet have a standard procedure for judging the quality of such uncertainty estimates. Here we present a suite of figures and performance metrics derived from the machine learning community that can be used to judge the quality of such uncertainty estimates. This suite probes the accuracy, calibration, and sharpness of a model quantitatively. We then show a case study where we judge various methods for predicting density-functional-theory-calculated adsorption energies. Of the methods studied here, we find that the best performer is a model where a convolutional neural network is used to supply features to a Gaussian process regressor, which then makes predictions of adsorption energies along with corresponding uncertainty estimates.","uncertainty,density functional theory,neural networks",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Computer Science,Science & Technology - Other Topics",,,"INITIO,MOLECULAR-DYNAMICS,TOTAL-ENERGY,CALCULATIONS",MACHINE LEARNING-SCIENCE AND TECHNOLOGY,https://doi.org/10.1088/2632-2153/ab7e1a,
34,Neural networks and kernel ridge regression for excited states dynamics of CH2NH2+ : From single-state to multi-state representations and multi-property machine learning models,1,2,,"Westermayr Julia,Faber Felix A.,Christensen Anders S.,von Lilienfeld O. Anatole,Marquetand Philipp","Westermayr J,Faber FA,Christensen AS,von Lilienfeld OA,Marquetand P",Marquetand P,10.1088/2632-2153/ab88d0,University of Vienna,"Excited-state dynamics simulations are a powerful tool to investigate photo-induced reactions of molecules and materials and provide complementary information to experiments. Since the applicability of these simulation techniques is limited by the costs of the underlying electronic structure calculations, we develop and assess different machine learning models for this task. The machine learning models are trained on ab initio calculations for excited electronic states, using the methylenimmonium cation (CH2NH2+) as a model system. Two distinct strategies for modeling excited state properties are tested in this work. The first strategy is to treat each state separately in a kernel ridge regression model and all states together in a multiclass neural network. The second strategy is to instead encode the state as input into the model, which is tested with both models. Numerical evidence suggests that using the state as input yields the best performance. An important goal for excited-state machine learning models is their use in dynamics simulations, which needs not only state-specific information but also couplings, i.e. properties involving pairs of states. Accordingly, we investigate how well machine learning models can predict the couplings. Furthermore, we explore how combining all properties in a single neural network affects the accuracy. Finally, machine learning predicted energies, forces, and couplings are used to carry out excited-state dynamics simulations. Results demonstrate the scopes and possibilities of machine learning to model excited-state properties.","machine learning,photodynamics,excited states,quantum chemistry,neural networks,kernel ridge regression",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Computer Science,Science & Technology - Other Topics",,,"INITIO,MOLECULAR-DYNAMICS,SPECTROSCOPY,RELAXATION,POTENTIALS,SURFACE",MACHINE LEARNING-SCIENCE AND TECHNOLOGY,http://arxiv.org/pdf/1912.08484,
35,Survey of terahertz photonics and biophotonics,59,6,,"Ahi Kiarash,Jessurun Nathan,Hosseini Mohammad-Parsa,Asadizanjani Navid","Ahi K,Jessurun N,Hosseini MP,Asadizanjani N",Ahi K,10.1117/1.OE.59.6.061629,University of Connecticut,"We review the advances of terahertz (THz) science and technology in biophotonics, including related challenges and solutions. The main impediment to THz spectroscopy and imaging in this field is the high absorption of the THz beam in water. Hence, transmission imaging and spectroscopy of thick wet tissue using THz radiation has generally been quite difficult. However, the absorption of THz waves by water molecules is so strong that increasing the power of the THz source can lead to structural and functional changes in tissues, so solutions must go beyond a larger power output. In terms of resolution, THz imaging is superior to ultrasound but inferior to visible light microscopy. Owing to its unique material analysis capabilities, promising diagnosis applications have been demonstrated through THz imaging and spectroscopy. Unfortunately, many applications are limited by beam penetration depth and resolution. Hence, researchers from a wide variety of scientific and technical fields have been actively improving these features through the development of electronic devices and materials. In addition, ground-breaking optical architecture and materials to reduce beam absorption in the optics of a system and generate focused beams with smaller diameters have been proposed. On the software side, image processing techniques to computationally enhance the resolution and quality of THz imaging have been proposed. Data science and machine learning to automate the diagnosis of defects and diseases through processing THz images and spectroscopy data have been proposed. We have reviewed the applications of THz radiation in biophotonics and research achievements toward advancing these applications. A conclusion with a roadmap toward increasing the footprint of the THz technology in biophotonics is also proposed. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","terahertz,imaging,spectroscopy,characterization,plasmonic antenna,biophotonics",Article; Proceedings Paper,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA",Optics,,1.098,"REFRACTIVE-INDEX,IMAGING-SYSTEMS,AMINO-ACIDS,PROTEIN-DETECTION,MILLIMETER-WAVE,QUALITY-CONTROL,THZ,TOMOGRAPHY,HUMAN,SKIN,REAL-TIME,EX-VIVO",OPTICAL ENGINEERING,https://www.spiedigitallibrary.org/journals/optical-engineering/volume-59/issue-6/061629/Survey-of-terahertz-photonics-and-biophotonics/10.1117/1.OE.59.6.061629.pdf,
36,Using hidden semi-Markov model with hierarchical Dirichlet process to infer pilots fatigue states,37,6,1196-1206,",,,,","Luo Yingxue,Jia Bo,Qiu Xuyi,Deng Pingyu,Wu Qi",,,Luo Yingxue,"In the civil aviation and military aviation field,the long flight and harsh conditions will make pilots feel fatigued.The pilots fatigue will seriously affect their judgment,so the inference of fatigue state is important to ensure flight safety.Brain fatigue cognition faces two main problems:one is how to extract feature of fatigue cognition,and the other is how to identify the latent state of brain cognition with duration.For the first problem,a method based on smooth pseudo-affine Wigner-Ville distribution(SPAWVD)with kaiser window function was proposed to calculate the instantaneous spectral features of Electroencephalogram(EEG)rhythms.Features extracted by this method had better local significance.For the second problem,a residual life hidden semi-Markov model(HSMM)was established to learn the dynamic mechanism of the brain.It modeled the duration of brain fatigue cognitive states and avoids fast switching between states caused by hidden semi-Markov model(HMM).Then a multi-layer learning network based on hierarchical Dirichlet process(HDP)was built to provide subtasks that share the subject of fatigue awareness.The result of the experiment was satisfactory and proved that the model had a high ability to identify pilots latent brain cognitive state.",electroencephalogram signals; pilots fatigue; hidden semi-Markov model; smooth pseudo-affine Wigner- Ville distribution,Article,,,,,,,,
37,Difficulty-Aware Meta-Learning for Rare Disease Diagnosis,47,6,E603-E603,"Li X.,Lyu L.,Xing L.","Li X,Lyu L,Xing L",,,"
",,,Meeting Abstract,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,,MEDICAL PHYSICS,http://arxiv.org/pdf/1907.00354,
38,High-throughput screening of polymeric membranes for liquid mixture separation,28,,83-89,Hedden Ronald C.,Hedden RC,Hedden RC,10.1016/j.coche.2020.02.008,Rensselaer Polytechnic Institute,"Advances in high-throughput screening (HTS) metrologies could accelerate discovery of superior polymeric membranes for separation of liquid mixtures. However, HTS remains underexploited in membrane materials research. This review examines relevant advances in membrane materials and HTS techniques made since 2000, including both predictive and direct screening approaches that are applicable to membranes for liquid mixture separation. Advances in dense polymeric and mixed-matrix materials for hydrophilic and organophilic membranes are discussed. Recent studies demonstrating predictive and direct HTS approaches on membranes for separation of liquid mixtures are summarized. The synergistic combination of HTS with molecular simulations and machine learning is suggested as a potentially powerful approach to accelerating discovery of polymeric and mixed-matrix membranes that exhibit exceptional performance.","MIXED-MATRIX MEMBRANES,MULTIWALLED CARBON NANOTUBES,AQUEOUS-SOLUTIONS,SODIUM ALGINATE,PERVAPORATION DEHYDRATION,COMPOSITE MEMBRANE,ETHANOL RECOVERY,WATER,BUTANOL,COMBINATORIAL",Review,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Biotechnology & Applied Microbiology,Engineering",,5.451,"MIXED-MATRIX,MEMBRANES,MULTIWALLED,CARBON,NANOTUBES,AQUEOUS-SOLUTIONS,SODIUM,ALGINATE,PERVAPORATION,DEHYDRATION,COMPOSITE,MEMBRANE,ETHANOL,RECOVERY,WATER,BUTANOL,COMBINATORIAL",CURRENT OPINION IN CHEMICAL ENGINEERING,,
39,Machine-learning-assisted metasurface design for high-efficiency thermal emitter optimization,7,2,,"Kudyshev Zhaxylyk A.,Kildishev Alexander V.,Shalaev Vladimir M.,Boltasseva Alexandra","Kudyshev ZA,Kildishev AV,Shalaev VM,Boltasseva A",Kudyshev ZA; Boltasseva A,10.1063/1.5134792,Purdue University System,"Nanophotonic devices can provide solutions to challenges in energy conversion, information technologies, chemical or biological sensing, quantum computing, and secure communications. The realization of practical optical structures and devices is a complex problem due to the multitude of constraints on their optical performance, materials, scalability, and experimental tolerances, all of which are requirements implying large optimization spaces. However, despite the complexity of the process, to date, almost all nanophotonic structures are designed either intuitively or based on a priori selected topologies, and by adjusting a limited number of parameters. These intuition-based models are limited to ad hoc needs and have narrow applicability and predictive power, with the exhaustive parameter searches often performed manually. Since the comprehensive search in hyper-dimensional design space is highly resource-heavy, multi-objective optimization has so far been almost impossible. Humans' restrained capacity to think hyper-dimensionally also limits the perception of multivariate optimization models, and, therefore, advanced machinery is needed to manage the multi-domain, hyper-dimensional design parameter space. In this work, we merge the topology optimization method with deep learning algorithms, such as adversarial autoencoders, and show substantial improvement of the optimization process in terms of computational time (4900 times faster) and final devices efficiencies (similar to 98%) by providing unparalleled control of the compact design space representations. By enabling efficient, global optimization searches within complex landscapes, the proposed compact hyperparametric representations could become crucial for multi-constrained problems. The proposed approach could enable a much broader scope of the optimal designs and data-driven materials synthesis that goes beyond photonic and optoelectronic applications.","ROBUST TOPOLOGY OPTIMIZATION,NANOPHOTONICS,ABSORBERS,NETWORKS",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,19.201,"ROBUST,TOPOLOGY,OPTIMIZATION,MATERIAL,INTERPOLATION,NANOPHOTONICS,ABSORBERS,NETWORKS",APPLIED PHYSICS REVIEWS,http://arxiv.org/pdf/1910.12741,
40,Automated Cardiovascular Pathology Assessment Using Semantic Segmentation and Ensemble Learning,33,3,607-612,"Lindsey Tony,Lee Jin-Ju","Lindsey T,Lee JJ",Lindsey T,10.1007/s10278-019-00197-0,National Aeronautics & Space Administration (NASA),"Cardiac magnetic resonance imaging provides high spatial resolution, enabling improved extraction of important functional and morphological features for cardiovascular disease staging. Segmentation of ventricular cavities and myocardium in cardiac cine sequencing provides a basis to quantify cardiac measures such as ejection fraction. A method is presented that curtails the expense and observer bias of manual cardiac evaluation by combining semantic segmentation and disease classification into a fully automatic processing pipeline. The initial processing element consists of a robust dilated convolutional neural network architecture for voxel-wise segmentation of the myocardium and ventricular cavities. The resulting comprehensive volumetric feature matrix captures diagnostic clinical procedure data and is utilized by the final processing element to model a cardiac pathology classifier. Our approach evaluated anonymized cardiac images from a training data set of 100 patients (4 pathology groups, 1 healthy group, 20 patients per group) examined at the University Hospital of Dijon. The top average Dice index scores achieved were 0.940, 0.886, and 0.849 for structure segmentation of the left ventricle (LV), myocardium, and right ventricle (RV), respectively. A 5-ary pathology classification accuracy of 90% was recorded on an independent test set using the trained model. Performance results demonstrate the potential for advanced machine learning methods to deliver accurate, efficient, and reproducible cardiac pathological assessment.","2D U-Net,Cardiac cine-MRI,Semantic segmentation,Feature selection,Classification",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,,JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7256130,
41,Hybrid Transfer Learning for Classification of Uterine Cervix Images for Cervical Cancer Screening,33,3,619-631,"Kudva Vidya,Prasad Keerthana,Guruvare Shyamala","Kudva V,Prasad K,Guruvare S",Prasad K,10.1007/s10278-019-00269-1,Manipal Academy of Higher Education (MAHE),"Transfer learning using deep pre-trained convolutional neural networks is increasingly used to solve a large number of problems in the medical field. In spite of being trained using images with entirely different domain, these networks are flexible to adapt to solve a problem in a different domain too. Transfer learning involves fine-tuning a pre-trained network with optimal values of hyperparameters such as learning rate, batch size, and number of training epochs. The process of training the network identifies the relevant features for solving a specific problem. Adapting the pre-trained network to solve a different problem requires fine-tuning until relevant features are obtained. This is facilitated through the use of large number of filters present in the convolutional layers of pre-trained network. A very few features out of these features are useful for solving the problem in a different domain, while others are irrelevant, use of which may only reduce the efficacy of the network. However, by minimizing the number of filters required to solve the problem, the efficiency of the training the network can be improved. In this study, we consider identification of relevant filters using the pre-trained networks namely AlexNet and VGG-16 net to detect cervical cancer from cervix images. This paper presents a novel hybrid transfer learning technique, in which a CNN is built and trained from scratch, with initial weights of only those filters which were identified as relevant using AlexNet and VGG-16 net. This study used 2198 cervix images with 1090 belonging to negative class and 1108 to positive class. Our experiment using hybrid transfer learning achieved an accuracy of 91.46%.","Cervical cancer screening,Deep learning,Transfer learning,Hybrid transfer learning,Machine learning,Medical image classification,Artificial intelligence",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"CONVOLUTIONAL,NEURAL-NETWORKS,VISUAL,INSPECTION,ACETIC-ACID,ULTRASOUND,FEATURES",JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7256135,
42,Material informatics for layered high-T-C superconductors,8,6,,"Liu Zhong-Li,Kang Peng,Zhu Yu,Liu Lei,Guo Hong","Liu ZL,Kang P,Zhu Y,Liu L,Guo H",Liu ZL,10.1063/5.0004641,Luoyang Normal University,"Superconductors were typically discovered by trial-and-error aided by the knowledge and intuition of individual researchers. In this work, using materials informatics aided by machine learning (ML), we build an ML model of superconductors, which is based on several material descriptors with apparent physical meanings to efficiently predict critical superconducting temperature T-C. The descriptors include the average atomic mass of a compound, the average number of electrons in an unfilled shell, the average ground state atomic magnetic moments, the maximum difference of electronegativity, etc. To fully optimize the ML model, we develop a multi-step learning and multi-algorithm cross-verification approach. For known high T-C superconductors, our ML model predicts excellent T-C values with over 92% confidence. When the ML model is applied to about 2500 layered materials in the inorganic crystal structure database, 25 of them are predicted to be superconductors not known before, including 12 cuprates, 7 iron-based crystals, and 6 others, with T-C ranging from similar to 32 K to similar to 138 K. The findings shed considerable light on the mapping between the material descriptors and T-C for layered superconductors. The ML calculates that in our descriptors, the maximum difference of electronegativity is the most important one.","TRANSITION,HYDRIDE",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Science & Technology - Other Topics,Materials Science,Physics",,4.841,"TRANSITION,HYDRIDE",APL MATERIALS,https://aip.scitation.org/doi/pdf/10.1063/5.0004641,
43,Deep learning for mass detection in Full Field Digital Mammograms,121,,,"Agarwal Richa,Diaz Oliver,Yap Moi Hoon,Llado Xavier,Marti Robert","Agarwal R,Diaz O,Yap MH,Llado X,Marti R",Marti R,10.1016/j.compbiomed.2020.103774,Universitat de Girona,"In recent years, the use of Convolutional Neural Networks (CNNs) in medical imaging has shown improved performance in terms of mass detection and classification compared to current state-of-the-art methods. This paper proposes a fully automated framework to detect masses in Full-Field Digital Mammograms (FFDM). This is based on the Faster Region-based Convolutional Neural Network (Faster-RCNN) model and is applied for detecting masses in the large-scale OPTIMAM Mammography Image Database (OMI-DB), which consists of similar to 80,000 FFDMs mainly from Hologic and General Electric (GE) scanners. This research is the first to benchmark the performance of deep learning on OMI-DB. The proposed framework obtained a True Positive Rate (TPR) of 0.93 at 0.78 False Positive per Image (FPI) on FFDMs from the Hologic scanner. Transfer learning is then used in the Faster R-CNN model trained on Hologic images to detect masses in smaller databases containing FFDMs from the GE scanner and another public dataset INbreast (Siemens scanner). The detection framework obtained a TPR of 0.91 +/- 0.06 at 1.69 FPI for images from the GE scanner and also showed higher performance compared to state-of-the-art methods on the INbreast dataset, obtaining a TPR of 0.99 +/- 0.03 at 1.17 FPI for malignant and 0.85 +/- 0.08 at 1.0 FPI for benign masses, showing the potential to be used as part of an advanced CAD system for breast cancer screening.","Deep learning,CNN,Mammogram,FFDM,Mass detection",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"CLASSIFICATION,SEGMENTATION,DIAGNOSIS",COMPUTERS IN BIOLOGY AND MEDICINE,https://dugi-doc.udg.edu/bitstream/10256/18496/1/DeepLearningMass-ByNcNd.pdf,
44,Application of deep learning technique to manage COVID-19 in routine clinical practice using CT images: Results of 10 convolutional neural networks,121,,,"Ardakani Ali Abbasian,Kanafi Alireza Rajabzadeh,Acharya U. Rajendra,Khadem Nazanin,Mohammadi Afshin","Ardakani AA,Kanafi AR,Acharya UR,Khadem N,Mohammadi A",Mohammadi A,10.1016/j.compbiomed.2020.103795,Urmia University of Medical Sciences,"Fast diagnostic methods can control and prevent the spread of pandemic diseases like coronavirus disease 2019 (COVID-19) and assist physicians to better manage patients in high workload conditions. Although a laboratory test is the current routine diagnostic tool, it is time-consuming, imposing a high cost and requiring a well-equipped laboratory for analysis. Computed tomography (CT) has thus far become a fast method to diagnose patients with COVID-19. However, the performance of radiologists in diagnosis of COVID-19 was moderate. Accordingly, additional investigations are needed to improve the performance in diagnosing COVID-19. In this study is suggested a rapid and valid method for COVID-19 diagnosis using an artificial intelligence technique based. 1020 CT slices from 108 patients with laboratory proven COVID-19 (the COVID-19 group) and 86 patients with other atypical and viral pneumonia diseases (the non-COVID-19 group) were included. Ten well-known convolutional neural networks were used to distinguish infection of COVID-19 from non-COVID-19 groups: AlexNet, VGG-16, VGG-19, SqueezeNet, GoogleNet, MobileNet-V2, ResNet-18, ResNet-50, ResNet-101, and Xception. Among all networks, the best performance was achieved by ResNet-101 and Xception. ResNet-101 could distinguish COVID-19 from non-COVID-19 cases with an AUC of 0.994 (sensitivity, 100%; specificity, 99.02%; accuracy, 99.51%). Xception achieved an AUC of 0.994 (sensitivity, 98.04%; specificity, 100%; accuracy, 99.02%). However, the performance of the radiologist was moderate with an AUC of 0.873 (sensitivity, 89.21%; specificity, 83.33%; accuracy, 86.27%). ResNet-101 can be considered as a high sensitivity model to characterize and diagnose COVID-19 infections, and can be used as an adjuvant tool in radiology departments.","Computed tomography,Coronavirus infections,COVID-19,Deep learning,Lung diseases,Pneumonia,Machine learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"NODULE,DETECTION,LUNG-CANCER,DIAGNOSIS,RADIOLOGISTS",COMPUTERS IN BIOLOGY AND MEDICINE,https://doi.org/10.1016/j.compbiomed.2020.103795,
45,Assessment and prediction of spine surgery invasiveness with machine learning techniques,121,,,"Campagner Andrea,Berjano Pedro,Lamartina Claudio,Langella Francesco,Lombardi Giovanni,Cabitza Federico","Campagner A,Berjano P,Lamartina C,Langella F,Lombardi G,Cabitza F",Campagner A,10.1016/j.compbiomed.2020.103796,IRCCS Istituto Ortopedico Galeazzi,"Background: The interest in Minimally Invasive Surgery (MIS) techniques has greatly increased in the recent years due to their significant advantages, both in terms of outcome improvement and cost reduction. Also in spine surgery, MIS is now applicable to several conditions and, above all, in low back pain (LBP) treatment. However, reliable and objective measures of invasiveness, necessary to compare different procedures, are still lacking.
Methods: In this article we study the application of Machine Learning (ML) techniques to define an invasiveness score for LBP procedures based on biological markers and inflammatory profiles. In so doing, we can assess the invasiveness of surgical procedures. We also propose a predictive model for treatment planning based on the evaluation of invasiveness of surgical alternatives for specific patients, using their pre-surgery biomarkers. The data used in study was characterized by low sample size and high-dimensionality, thus we adopted a combination of feature selection, careful selection of ML models and conservative model selection choices in order to address these concerns. We also performed an external validation based on a statistically significantly different datasets in order to confirm the relevance of the findings.
Results: We report the results of an experimental study on real-world data, for which we obtained promising results for both considered applications: we report an AUC of 0.87 for the task of invasiveness score definition, and an AUC of 0.76 for the invasiveness prediction task. The results obtained on the external validation were in agreement with the obtained results. Further, in both cases the performances were considered as excellent by the involved clinicians and the selected predictive features were biologically relevant and associated with invasiveness and biological impact in the relevant literature.
Conclusion: Our results show that ML techniques could be effectively employed not only for diagnosis or prognosis, but also for treatment planning, a task of fundamental importance toward personalized and value-based healthcare. These results also show that ML approaches could be effectively used even in scenarios (e.g. pilot studies) where only small samples are available.","Machine learning,Invasiveness,Spine surgery,Medicine,Data analysis",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"LOW-BACK-PAIN,CLASSIFICATION,VALIDATION,MARKERS,MODEL",COMPUTERS IN BIOLOGY AND MEDICINE,,
46,Proposing a convolutional neural network for stress assessment by means of derived heart rate from functional near infrared spectroscopy,121,,,"Hakimi Naser,Jodeiri Ata,Mirbagheri Mahya,Setarehdan S. Kamaledin","Hakimi N,Jodeiri A,Mirbagheri M,Setarehdan SK",Hakimi N,10.1016/j.compbiomed.2020.103810,Utrecht University,"Background: Stress is known as one of the major factors threatening human health. A large number of studies have been performed in order to either assess or relieve stress by analyzing the brain and heart-related signals.
Method: In this study, a method based on the Convolutional Neural Network (CNN) approach is proposed to assess stress induced by the Montreal Imaging Stress Task. The proposed model is trained on the heart rate signal derived from functional Near-Infrared Spectroscopy (fNIRS), which is referred to as HRF. In this regard, fNIRS signals of 20 healthy volunteers were recorded using a configuration of 23 channels located on the prefrontal cortex. The proposed deep learning system consists of two main parts where in the first part, the one-dimensional convolutional neural network is employed to build informative activation maps, and then in the second part, a stack of deep fully connected layers is used to predict the stress existence probability. Thereafter, the employed CNN method is compared with the Dense Neural Network, Support Vector Machine, and Random Forest regarding various classification metrics.
Results: Results clearly showed the superiority of CNN over all other methods. Additionally, the trained HRF model significantly outperforms the model trained on the filtered fNIRS signals, where the HRF model could achieve 98.69 +/- 0.45% accuracy, which is 10.09% greater than the accuracy obtained by the NIBS model.
Conclusions: Employment of the proposed deep learning system trained on the HRF measurements leads to higher stress classification accuracy than the accuracy reported in the existing studies where the same experimental procedure has been done. Besides, the proposed method suggests better stability with lower variation in prediction. Furthermore, its low computational cost opens up the possibility to be applied in real-time monitoring of stress assessment.","Functional near infrared spectroscopy,Heart rate,Stress assessment,Deep learning,Convolutional neural network,Independent component analysis",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"PSYCHOSOCIAL,STRESS,FNIRS,BRAIN,EEG,ACTIVATION,SPEECH,SYSTEM,CLASSIFICATION,PREDICTION,ALGORITHM",COMPUTERS IN BIOLOGY AND MEDICINE,,
47,A computer-aided diagnosis system for brain magnetic resonance imaging images using a novel differential feature neural network,121,,,"Huang Zheng,Xu Han,Su Shun,Wang Tianyu,Luo Yang,Zhao Xingang,Liu Yunhui,Song Guoli,Zhao Yiwen","Huang Z,Xu H,Su S,Wang TY,Luo Y,Zhao XG,Liu YH,Song GL,Zhao YW",Song GL,10.1016/j.compbiomed.2020.103818,Chinese Academy of Sciences,"To improve the performance of brain tumor diagnosis, numerous automatic brain tumor diagnosis systems that use machine learning technologies have been proposed. However, most current systems ignore the structural symmetry of brain magnetic resonance imaging (MRI) images and regard brain tumor diagnosis as a simple pattern recognition task. As a result, the performance of the current systems is not ideal. To improve the performance of the brain tumor screening process, an innovative differential feature map (DFM) block is proposed to magnify tumor regions, and DFM blocks are further combined with squeeze-and-excitation (SE) blocks to form a differential feature neural network (DFNN). First, an automatic image rectification method is applied so that the symmetry axes of brain MRI images are approximately parallel to the perpendicular axis. Moreover, a DFNN is constructed to classify the brain MRI images into two categories: ""abnormal"" and ""normal"". The experimental results show that the average accuracy of the proposed system on two databases can reach 99.2% and 98%, and the introduction of the proposed DFM block can improve the average accuracy on these two databases by 1.8% and 1.3%, respectively, which indicates that the proposed DFM block can improve the performance of the brain tumor screening process.","Brain tumor diagnosis,Differential feature neural network,Magnetic resonance imaging",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,,COMPUTERS IN BIOLOGY AND MEDICINE,,
48,Diagnostic classification of cancers using extreme gradient boosting algorithm and multi-omics data,121,,,"Ma Baoshan,Meng Fanyu,Yan Ge,Yan Haowen,Chai Bingjie,Song Fengju","Ma BS,Meng FY,Yan G,Yan HW,Chai BJ,Song FJ",Ma BS,10.1016/j.compbiomed.2020.103761,Dalian Maritime University,"Accurate diagnostic classification of cancers can greatly help physicians to choose surveillance and treatment strategies for patients. Following the explosive growth of huge amounts of biological data, the shift from traditional biostatistical methods to computer-aided means has made machine-learning methods as an integral part of today's cancer prognosis prediction. In this work, we proposed a classification model by leveraging the power of extreme gradient boosting (XGBoost) and using increasingly complex multi-omits data with the aim to separate early stage and late stage cancers. We applied XGBoost model to four kinds of cancer data downloaded from TCGA and compared its performance with other popular machine-learning methods. The experimental results showed that our method obtained statistically significantly better or comparable predictive performance. The results of this study also revealed that DNA methylation outperforms other molecular data (mRNA expression and miRNA expression) in terms of accuracy and stability for discriminating between early stage and late stage groups. Furthermore, integration of multi-omits data by autoencoder can enhance the classification accuracy of cancer stage. Finally, we conducted bioinformatics analyses to assess the medical utility of the significant genes ranked by their importance using XGBoost algorithm. Extensively comparative experiments demonstrated that the XGBoost method has a remarkable performance in predicting the stage of cancer patients with multi-omits data. Moreover, identification of novel candidate genes associated with cancer stages would contribute to further elucidate disease pathogenesis and develop novel therapeutics.","Diagnostic classification,Machine learning,Extreme gradient boosting,Multi-omics data,Cancer",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"SQUAMOUS-CELL,CARCINOMA,EXPRESSION,GENE,HEAD,PREDICTION",COMPUTERS IN BIOLOGY AND MEDICINE,,
49,Brain tumor segmentation and grading of lower-grade glioma using deep learning in MRI images,121,,,"Naser Mohamed A.,Deen M. Jamal","Naser MA,Deen MJ",Naser MA,10.1016/j.compbiomed.2020.103758,University of Texas System,"Gliomas are the most common malignant brain tumors with different grades that highly determine the rate of survival in patients. Tumor segmentation and grading using magnetic resonance imaging (MRI) are common and essential for diagnosis and treatment planning. To achieve this clinical need, a deep learning approach that combines convolutional neural networks (CNN) based on the U-net for tumor segmentation and transfer learning based on a pre-trained convolution-base of Vgg16 and a fully connected classifier for tumor grading was developed. The segmentation and grading models use the same pipeline of T1-precontrast, fluid attenuated inversion recovery (FLAIR), and T1-postcontrast MRI images of 110 patients of lower-grade glioma (LGG) for training and evaluations. The mean dice similarity coefficient (DSC) and tumor detection accuracy achieved by the segmentation model are 0.84 and 0.92, respectively. The grading model classifies LGG into grade II and grade III with accuracy, sensitivity, and specificity of 0.89, 0.87, and 0.92, respectively at the MRI images' level and 0.95, 0.97, and 0.98 at the patients' level. This work demonstrates the potential of using deep learning in MRI images to provide a non-invasive tool for simultaneous and automated tumor segmentation, detection, and grading of LGG for clinical applications.","Brain tumor,Segmentation,Classification,Grading,Glioma,Deep learning,Magnetic resonance imaging",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,CLASSIFICATION,COMPUTERS IN BIOLOGY AND MEDICINE,,
50,Bone segmentation on whole-body CT using convolutional neural network with novel data augmentation techniques,121,,,"Noguchi Shunjiro,Nishio Mizuho,Yakami Masahiro,Nakagomi Keita,Togashi Kaori","Noguchi S,Nishio M,Yakami M,Nakagomi K,Togashi K",Noguchi S,10.1016/j.compbiomed.2020.103767,Kyoto University,"Background: The purpose of this study was to develop and evaluate an algorithm for bone segmentation on whole-body CT using a convolutional neural network (CNN).
Methods: Bone segmentation was performed using a network based on U-Net architecture. To evaluate its performance and robustness, we prepared three different datasets: (1) an in-house dataset comprising 16,218 slices of CT images from 32 scans in 16 patients; (2) a secondary dataset comprising 12,529 slices of CT images from 20 scans in 20 patients, which were collected from The Cancer Imaging Archive; and (3) a publicly available labelled dataset comprising 270 slices of CT images from 27 scans in 20 patients. To improve the network's performance and robustness, we evaluated the efficacy of three types of data augmentation technique: conventional method, mixup, and random image cropping and patching (RICAP).
Results: The network trained on the in-house dataset achieved a mean Dice coefficient of 0.983 +/- 0.005 on cross validation with the in-house dataset, and 0.943 +/- 0.007 with the secondary dataset. The network trained on the public dataset achieved a mean Dice coefficient of 0.947 +/- 0.013 on 10 randomly generated 15-3-9 splits of the public dataset. These results outperform those reported previously. Regarding augmentation technique, the conventional method, RICAP, and a combination of these were effective.
Conclusions: The CNN-based model achieved accurate bone segmentation on whole-body CT, with generalizability to various scan conditions. Data augmentation techniques enabled construction of an accurate and robust model even with a small dataset.","Bone,Segmentation,CT,CNN,U-net,Data augmentation,Mixup,RICAP",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"PROBABILISTIC,ATLAS,IMAGE,SEGMENTATION,INTENSITY",COMPUTERS IN BIOLOGY AND MEDICINE,,
51,Automated detection of COVID-19 cases using deep neural networks with X-ray images,121,,,"Ozturk Tulin,Talo Muhammed,Yildirim Eylul Azra,Baloglu Ulas Baran,Yildirim Ozal,Acharya U. Rajendra","Ozturk T,Talo M,Yildirim EA,Baloglu UB,Yildirim O,Acharya UR",Yildirim O,10.1016/j.compbiomed.2020.103792,Munzur University,"The novel coronavirus 2019 (COVID-2019), which first appeared in Wuhan city of China in December 2019, spread rapidly around the world and became a pandemic. It has caused a devastating effect on both daily lives, public health, and the global economy. It is critical to detect the positive cases as early as possible so as to prevent the further spread of this epidemic and to quickly treat affected patients. The need for auxiliary diagnostic tools has increased as there are no accurate automated toolkits available. Recent findings obtained using radiology imaging techniques suggest that such images contain salient information about the COVID-19 virus. Application of advanced artificial intelligence (AI) techniques coupled with radiological imaging can be helpful for the accurate detection of this disease, and can also be assistive to overcome the problem of a lack of specialized physicians in remote villages. In this study, a new model for automatic COVID-19 detection using raw chest X-ray images is presented. The proposed model is developed to provide accurate diagnostics for binary classification (COVID vs. No-Findings) and multi-class classification (COVID vs. No-Findings vs. Pneumonia). Our model produced a classification accuracy of 98.08% for binary classes and 87.02% for multi-class cases. The DarkNet model was used in our study as a classifier for the you only look once (YOLO) real time object detection system. We implemented 17 convolutional layers and introduced different filtering on each layer. Our model (available at (http://github.com/muhammedtalo/COVID-19)) can be employed to assist radiologists in validating their initial screening, and can also be employed via cloud to immediately screen patients.","Coronavirus (COVID-19),Deep learning,Chest X-ray images,Radiology images",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"CLASSIFICATION,PNEUMONIA",COMPUTERS IN BIOLOGY AND MEDICINE,https://research-information.bris.ac.uk/ws/files/235042282/Automated_Detection_of_COVID_19_Cases_Using_Deep_Neural_Networks_with_X_Ray_Images_.pdf,
52,COVID-19 detection using deep learning models to exploit Social Mimic Optimization and structured chest X-ray images using fuzzy color and stacking approaches,121,,,"Togacar Mesut,Ergen Burhan,Comert Zafer","Togacar M,Ergen B,Comert Z",Togacar M,10.1016/j.compbiomed.2020.103805,Firat University,"Coronavirus causes a wide variety of respiratory infections and it is an RNA-type virus that can infect both humans and animal species. It often causes pneumonia in humans. Artificial intelligence models have been helpful for successful analyses in the biomedical field. In this study, Coronavirus was detected using a deep learning model, which is a sub-branch of artificial intelligence. Our dataset consists of three classes namely: coronavirus, pneumonia, and normal X-ray imagery. In this study, the data classes were restructured using the Fuzzy Color technique as a preprocessing step and the images that were structured with the original images were stacked. In the next step, the stacked dataset was trained with deep learning models (MobileNetV2, SqueezeNet) and the feature sets obtained by the models were processed using the Social Mimic optimization method. Thereafter, efficient features were combined and classified using Support Vector Machines (SVM). The overall classification rate obtained with the proposed approach was 99.27%. With the proposed approach in this study, it is evident that the model can efficiently contribute to the detection of COVID-19 disease.","COVID-19,2019-nCoV,Fuzzy color technique,Stacking technique,Social mimic,Deep learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,CLASSIFICATION,COMPUTERS IN BIOLOGY AND MEDICINE,https://doi.org/10.1016/j.compbiomed.2020.103805,
53,Early Diagnosis of Skin Melanoma Using Several Imaging Systems,128,6,824-834,"Kudrin K. G.,Rimskaya E. N.,Apollonova I. A.,Nikolaev A. P.,Chernomyrdin N. V,Svyatoslavov D. S.,Davydov D. V,Reshetov I. V","Kudrin KG,Rimskaya EN,Apollonova IA,Nikolaev AP,Chernomyrdin NV,Svyatoslavov DS,Davydov DV,Reshetov IV",Kudrin KG,10.1134/S0030400X20060132,"Fed Med Biol Agcy Russia, Fed Res & Clin Ctr, Acad Postgrad Educ, Moscow 125371, Russia.","A complex approach was proposed for early diagnosis of skin melanoma. The approach includes sequential examinations of skin lesions using several imaging systems. A focus is placed on the specifics of morphometry using clinical images of skin neoplasms, features of imaging systems, and main steps of automated image processing and image recognition to diagnose melanoma. Metrological features were described for the approach; errors of measuring the clinical parameters of skin neoplasms did not exceed the allowable error level. The approach was tested, and the sensitivity and specificity of the methods employed was found to be higher than 90%.","imaging systems,pigmented skin neoplasms,early diagnosis of melanoma,digital image processing,machine learning",Article,"PLEIADES PUBLISHING INC, PLEIADES HOUSE, 7 W 54 ST, NEW YORK,  NY, UNITED STATES","Optics,Spectroscopy",,0.671,"OPTICAL,COHERENCE,TOMOGRAPHY,IN-VIVO,NONINVASIVE,DIAGNOSIS,CANCER,STATISTICS,MICROSCOPY,DERMOSCOPY,LESIONS,DIFFERENTIATION,EPIDEMIOLOGY,DERMATOSCOPY",OPTICS AND SPECTROSCOPY,,
54,Myocardial infarction evaluation from stopping time decision toward interoperable algorithmic states in reinforcement learning,20,1,,"Park Jong-Rul,Chung Sung Phil,Hwang Sung Yeon,Shin Tae Gun,Park Jong Eun","Park JR,Chung SP,Hwang SY,Shin TG,Park JE",Park JE,10.1186/s12911-020-01133-x,Sungkyunkwan University (SKKU),"Background The Elliot wave principle commonly characterizes the impulsive and corrective wave trends for both financial market trends and electrocardiograms. The impulsive wave trends of electrocardiograms can annotate several wave components of heart-beats including pathological heartbeat waveforms. The stopping time inquires which ordinal element satisfies the assumed mathematical condition within a numerical set. The proposed work constitutes several algorithmic states in reinforcement learning from the stopping time decision, which determines the impulsive wave trends. Each proposed algorithmic state is applicable to any relevant algorithmic state in reinforcement learning with fully numerical explanations. Because commercial electrocardiographs still misinterpret myocardial infarctions from extraordinary electrocardiograms, a novel algorithm needs to be developed to evaluate myocardial infarctions. Moreover, differential diagnosis for right ventricle infarction is required to contraindicate a medication such as nitroglycerin. Methods The proposed work implements the stopping time theory to impulsive wave trend distribution. The searching process of the stopping time theory is equivalent to the actions toward algorithmic states in reinforcement learning. The state value from each algorithmic state represents the numerically deterministic annotated results from the impulsive wave trend distribution. The shape of the impulsive waveform is evaluated from the interoperable algorithmic states via least-first-power approximation and approximate entropy. The annotated electrocardiograms from the impulsive wave trend distribution utilize a structure of neural networks to approximate the isoelectric baseline amplitude value of the electrocardiograms, and detect the conditions of myocardial infarction. The annotated results from the impulsive wave trend distribution consist of another reinforcement learning environment for the evaluation of impulsive waveform direction. Results The accuracy to discern myocardial infarction was found to be 99.2754% for the data from the comma-separated value format files, and 99.3579% for those containing representative beats. The clinical dataset included 276 electrocardiograms from the comma-separated value files and 623 representative beats. Conclusions Our study aims to support clinical interpretation on 12-channel electrocardiograms. The proposed work is suitable for a differential diagnosis under infarction in the right ventricle to avoid contraindicated medication during emergency. An impulsive waveform that is affected by myocardial infarction or the electrical direction of electrocardiography is represented as an inverse waveform.","Electrocardiogram,Myocardial infarction,Least-first-power approximation,Approximate entropy,Stopping time,Reinforcement learning",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Medical Informatics,,3.394,"SAMPLE,ENTROPY,PREVALENCE",BMC MEDICAL INFORMATICS AND DECISION MAKING,https://ir.ymlib.yonsei.ac.kr/bitstream/22282913/184949/1/T999202207.pdf,
55,Implementation of Real-Time Body Motion Classification Using ZigBee Based Wearable BAN System,E103B,6,662-668,"Mitta Masahiro,Kim Minseok,Ichikawa Yuki","Mitta M,Kim M,Ichikawa Y",Kim M,10.1587/transcom.2019HMP0005,Niigata University,"This paper presents a real-time body motion classification system using the radio channel characteristics of a wearable body area network (BAN). We developed a custom wearable BAN radio channel measurement system by modifying an off-the-shelf ZigBee-based sensor network system, where the link quality indicator (LQI) values of the wireless links between the coordinator and four sensor nodes can be measured. After interpolating and standardizing the raw data samples in a pre-processing stage, the time-domain features are calculated, and the body motion is classified by a decision-tree based random forest machine learning algorithm which is most suitable for real-time processing. The features were carefully chosen to exclude those that exhibit the same tendency based on the mean and variance of the features to avoid overfitting. The measurements demonstrated successful real-time body motion classification and revealed the potential for practical use in various daily-life applications.","motion classification,machine learning,BAN,radio channel,real-time,LQI",Article,"IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG, KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011, JAPAN","Engineering,Telecommunications",,,"CHANNEL,MODEL",IEICE TRANSACTIONS ON COMMUNICATIONS,,
56,Learning based Coding for Medical Image Compression,11,6,111-117,Saudagar Abdul Khader Jilani,Saudagar AKJ,Saudagar AKJ,,Al-Imam Muhammad Ibn Saud Islamic University,"The area of Image processing has emerged with different coding approaches, and applications which are ranging from fundamental image compression model to high quality applications. The advancement of image processing, has given the advantage of automation in various image coding applications, among which medical image processing is one of the prime area. Medical diagnosis has always remained a time taking and sensitive approach for accurate medical treatment. Towards improving these issues, automation systems have been developed. In the process of automation, the images are processed and passed to a remote processing unit for processing and decision making. It is observed that, images are coded for compression to minimize the processing and computational overhead. However, the issue of compressing data over accuracy always remains a challenge. Thus, for an optimization in image compression, there is a need for compression through the reduction of non-relevant coefficients in medical images. The proposed image compression model helped in developing a coding technique to attain accurate compression by retaining image precision with lower computational overhead in clinical image coding. Towards making the image compression more efficient, this research work introduces an approach of image compression based on learning coding. This research achieves superior results in terms of Compression rate, Encoding time, Decoding time, Total processing time and Peak signal-to-noise ratio (PSNR).","Image compression,medical image processing,neural network,learning based coding,peak signal-to-noise ratio",Article,"SCIENCE & INFORMATION SAI ORGANIZATION LTD, 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND",Computer Science,,,,INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS,,
57,Translation of an esophagus histopathological FT-IR imaging model to a fast quantum cascade laser modality,13,8,,"Liberda Danuta,Hermes Michael,Koziol Paulina,Stone Nick,Wrobel Tomasz P.","Liberda D,Hermes M,Koziol P,Stone N,Wrobel TP",Wrobel TP,10.1002/jbio.202000122,Jagiellonian University,"The technical progress in fast quantum cascade laser (QCL) microscopy offers a platform where chemical imaging becomes feasible for clinical diagnostics. QCL systems allow the integration of previously developed FT-IR-based pathology recognition models in a faster workflow. The translation of such models requires a systematic approach, focusing only on the spectral frequencies that carry crucial information for discrimination of pathologic features. In this study, we optimize an FT-IR-based histopathological method for esophageal cancer detection to work with a QCL system. We explore whether the classifier's performance is affected by paraffin presence from tissue blocks compared to removing it chemically. Working with paraffin-embedded samples reduces preprocessing time in the lab and allows samples to be archived after analysis. Moreover, we test, whether the creation of a QCL model requires a preestablished FTIR model or can be optimized using solely QCL measurements.","esophageal cancer,histopathology,infrared imaging,machine learning,quantum cascade laser",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Biochemistry & Molecular Biology,Biophysics,Optics",,3.403,"SPECTROSCOPY,CLASSIFICATION",JOURNAL OF BIOPHOTONICS,,
58,Efficient Position Decoding Methods Based on Fluorescence Calcium Imaging in the Mouse Hippocampus,32,6,1144-1167,"Tu Mengyu,Zhao Ruohe,Adler Avital,Gan Wen-Biao,Chen Zhe S.","Tu MY,Zhao RH,Adler A,Gan WB,Chen ZS",Tu MY,10.1162/neco_a_01281,New York University,"Large-scale fluorescence calcium imaging methods have become widely adopted for studies of long-term hippocampal and cortical neuronal dynamics. Pyramidal neurons of the rodent hippocampus show spatial tuning in freely foraging or head-fixed navigation tasks. Development of efficient neural decoding methods for reconstructing the animal's position in real or virtual environments can provide a fast readout of spatial representations in closed-loop neuroscience experiments. Here, we develop an efficient strategy to extract features from fluorescence calcium imaging traces and further decode the animal's position. We validate our spike inference-free decoding methods in multiple in vivo calcium imaging recordings of the mouse hippocampus based on both supervised and unsupervised decoding analyses. We systematically investigate the decoding performance of our proposed methods with respect to the number of neurons, imaging frame rate, and signal-to-noise ratio. Our proposed supervised decoding analysis is ultrafast and robust, and thereby appealing for real-time position decoding applications based on calcium imaging.","SPIKE TRAIN INFERENCE,SPATIAL TOPOLOGY,PLACE CELLS,CODES,DECONVOLUTION,MEMORY,REPLAY",Article,"MIT PRESS, ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA","Computer Science,Neurosciences & Neurology",,2.618,"SPIKE,TRAIN,INFERENCE,SPATIAL,TOPOLOGY,PLACE,CELLS,CODES,DECONVOLUTION,MEMORY,REPLAY",NEURAL COMPUTATION,https://direct.mit.edu/neco/article-pdf/32/6/1144/1864850/neco_a_01281.pdf,
59,Noninvasive KRAS mutation estimation in colorectal cancer using a deep learning method based on CT imaging,20,1,,"He Kan,Liu Xiaoming,Li Mingyang,Li Xueyan,Yang Hualin,Zhang Huimao","He K,Liu XM,Li MY,Li XY,Yang HL,Zhang HM",Zhang HM,10.1186/s12880-020-00457-4,Jilin University,"Background The detection of Kirsten rat sarcoma viral oncogene homolog (KRAS) gene mutations in colorectal cancer (CRC) is key to the optimal design of individualized therapeutic strategies. The noninvasive prediction of the KRAS status in CRC is challenging. Deep learning (DL) in medical imaging has shown its high performance in diagnosis, classification, and prediction in recent years. In this paper, we investigated predictive performance by using a DL method with a residual neural network (ResNet) to estimate the KRAS mutation status in CRC patients based on pre-treatment contrast-enhanced CT imaging. Methods We have collected a dataset consisting of 157 patients with pathology-confirmed CRC who were divided into a training cohort (n = 117) and a testing cohort (n = 40). We developed an ResNet model that used portal venous phase CT images to estimate KRAS mutations in the axial, coronal, and sagittal directions of the training cohort and evaluated the model in the testing cohort. Several groups of expended region of interest (ROI) patches were generated for the ResNet model, to explore whether tissues around the tumor can contribute to cancer assessment. We also explored a radiomics model with the random forest classifier (RFC) to predict KRAS mutations and compared it with the DL model. Results The ResNet model in the axial direction achieved the higher area under the curve (AUC) value (0.90) in the testing cohort and peaked at 0.93 with an input of 'ROI and 20-pixel' surrounding area. AUC of radiomics model in testing cohorts were 0.818. In comparison, the ResNet model showed better predictive ability. Conclusions Our experiments reveal that the computerized assessment of the pre-treatment CT images of CRC patients using a DL model has the potential to precisely predict KRAS mutations. This new model has the potential to assist in noninvasive KRAS mutation estimation.","Colorectal Neoplasm,Mutation,Deep learning",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Radiology, Nuclear Medicine & Medical Imaging",,2.683,"CONVOLUTIONAL,NEURAL-NETWORK,GRADE,GLIOMAS,CLASSIFICATION",BMC MEDICAL IMAGING,https://europepmc.org/articles/pmc7268438?pdf=render,
60,DIGITAL ANALYSIS OF GEO-REFERENCED CONCRETE SCANNING ELECTRON MICROSCOPE (SEM) IMAGES,30,2,65-79,"Ahamad Mohd Sanusi S.,Maizul Elly Nur Myaisara","Ahamad MSS,Maizul ENM",Ahamad MSS,10.2478/ceer-2020-0020,Universiti Sains Malaysia,"The microstructural evaluation of complex cementitious materials has been made possible by the microscopic imaging tools such as Scanning Electron Microscope (SEM) and X-Ray Microanalysis. Particularly, the application of concrete SEM imaging and digital image analysis have become common in the analysis and mapping of concrete technology. In this study, six samples of two-dimensional (2D) SEM images were spatially resampled to produce Geo-referenced SEM sample images. Subsequently, they were analyzed and the intensity histogram plot was produced to facilitate visual interpretation. The consecutive digital image analysis performed was the enhancement and noise removal process using two filtering methods i.e. median and adaptive box filter. The filtered resampled images, then undergone the unsupervised K-Means classification process to collectively separate each individual pixel corresponds to the spectral data. By spatial segmentation of K-Means algorithms, the cluster groups generated were carefully reviewed before proceeding to the final analysis. From the resulting data, the mapping of the spatial distribution of k-cluster and the quantification of micro-cracks (voids) were performed. The results of the SEM images (1st - 4th sample) showed a higher percentage of k-cluster data indicating a good correlation with the major elemental composition of EDX analysis, namely Oxide (O), Silicon (Si) and Carbon (C). Meanwhile, the subjective visual assessment of the image (5th and 6th sample) has confirmed the micro-crack developments on the concrete SEM images upon which the crack density was 3.02 % and 1.30 %, respectively.","scanning electron microscope,geo-referenced image,digital image analysis,image mapping",Article,"SCIENDO, BOGUMILA ZUGA 32A, WARSAW, MAZOVIA, POLAND",Engineering,,,"INTERFACIAL,TRANSITION,ZONE,MICROSTRUCTURAL,ANALYSIS,QUANTITATIVE-ANALYSIS,STRENGTH,NOISE,QUANTIFICATION,IDENTIFICATION",CIVIL AND ENVIRONMENTAL ENGINEERING REPORTS,https://www.sciendo.com/pdf/10.2478/ceer-2020-0020,
61,Estimation of spatiotemporal response of rooted soil using a machine learning approach,21,6,462-477,"Cheng Zhi-liang,Zhou Wan-huan,Ding Zhi,Guo Yong-xing","Cheng ZL,Zhou WH,Ding Z,Guo YX",Zhou WH,10.1631/jzus.A1900555,University of Macau,"In this study, a machine learning method, i.e. genetic programming (GP), is employed to obtain a simplified statistical model to describe the variation of soil suction in drying cycles using five selected influential parameters. The data used for model development was recorded by an in-situ experiment. The image processing technology is used to quantify several tree canopy parameters. Based on four accuracy metrics, i.e. root mean square error (RMSE), mean absolute percentage error (MAPE), coefficient of determination (R-2), and relative error, the performance of the proposed GP model was evaluated. The results indicate that the model can give a reasonable estimation for the spatiotemporal variations of soil suction around a tree with acceptable errors. Global sensitivity analysis for the statistical model obtained using limited data of a specific region demonstrates the drying time as the most influential variable and the initial soil suction as the second most influential variable for the soil suction variations. A case study was conducted using a set of assumed input variable values and validated that the simplified GP model can be used to estimate and predict the spatiotemporal variations of soil suction in rooted soil at a certain range.","Genetic programming (GP),Simplified statistical model,Spatiotemporal variations,Soil suction,TU413,7",Article,"ZHEJIANG UNIV, EDITORIAL BOARD, 20 YUGU RD, HANGZHOU, 310027, PEOPLES R CHINA","Engineering,Physics",,1.912,"VOLUMETRIC,WATER-CONTENT,SENSITIVITY-ANALYSIS,INDUCED,SUCTION,MODEL,TEMPERATURE,RETENTION,UNCERTAINTY,EMBANKMENT,PARAMETERS,PREDICTION",JOURNAL OF ZHEJIANG UNIVERSITY-SCIENCE A,,
62,Lifshitz transition in triangular lattice Kondo-Heisenberg model*,29,7,,"Zhang Lan,Zhong Yin,Luo Hong-Gang","Zhang L,Zhong Y,Luo HG",Zhong Y,10.1088/1674-1056/ab8da4,Lanzhou University,"Motivated by recent experimental progress on triangular lattice heavy-fermion compounds, we investigate possible Lifshitz transitions and the scanning tunnel microscope (STM) spectra of the Kondo-Heisenberg model on the triangular lattice. In the heavy Fermi liquid state, the introduced Heisenberg antiferromagnetic interaction (J(H)) results in the twice Lifshitz transition at the case of the nearest-neighbour electron hopping but with next-nearest-neighbour hole hopping and the case of the nearest-neighbour hole hopping but with next-nearest-neighbour electron hopping, respectively. Driven byJ(H), the Lifshitz transitions on triangular lattice are all continuous in contrast to the case on square lattice. Furthermore, the STM spectra shows rich line-shape which is influenced by the Kondo couplingJ(K), the Heisenberg antiferromagnetic interactionJ(H), and the ratio of the tunneling amplitude of f-electront(f)versus conduction electront(c). Our work provides a possible scenario to understand the Fermi surface topology and the quantum critical point in heavy-fermion compounds.","Kondo-Heisenberg model,Lifshitz transition,heavy-fermion systems",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,1.262,"HEAVY,FERMIONS,POINT",CHINESE PHYSICS B,http://arxiv.org/pdf/2003.02403,
63,Non-Standardized Patch-Based ECG Lead Together With Deep Learning Based Algorithm for Automatic Screening of Atrial Fibrillation,24,6,1569-1578,"Lai Dakun,Bu Yuxiang,Su Ye,Zhang Xinshu,Ma Chang-Sheng","Lai DK,Bu YX,Su Y,Zhang XS,Ma CS",Lai DK,10.1109/JBHI.2020.2980454,University of Electronic Science & Technology of China,"This study was to assess the feasibility of using non-standardized single-lead electrocardiogram (ECG) monitoring to automatically detect atrial fibrillation (AF) with special emphasis on the combination of deep learning based algorithm and modified patch-based ECG lead. Fifty-five consecutive patients were monitored for AF in around 24 hours by patch-based ECG devices along with a standard 12-lead Holter. Catering to potential positional variability of patch lead, four typical positions on the upper-left chest were proposed. For each patch lead, the performance of automated algorithms with four different convolutional neural networks (CNN) was evaluated for AF detection against blinded annotations of two clinicians. A total of 349,388 10-second segments of AF and 161,084 segments of sinus rhythm were detected successfully. Good agreement between patch-based single-lead and standard 12-lead recordings was obtained at the position MP1 that corresponds to modified lead II, and a promising performance of the automated algorithm with an R-R intervals based CNN model was achieved on this lead in terms of accuracy (93.1%), sensitivity (93.1%), and specificity (93.4%). The present results suggest that the optimized patch-based ECG lead along by deep learning based algorithms may offer the possibility of providing an accurate, easy, and inexpensive clinical tool for mass screening of AF.","Electrocardiography,Lead,Standards,Rhythm,Monitoring,Detection algorithms,Digital audio players,Atrial fibrillation,convolutional neural network,electrocardiogram monitoring,patch recorder,single-lead",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"PREVALENCE,VALIDATION,RISK",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
64,Detecting Atrial Fibrillation and Atrial Flutter in Daily Life Using Photoplethysmography Data,24,6,1610-1618,"Eerikainen Linda M.,Bonomi Alberto G.,Schipper Fons,Dekker Lukas R. C.,de Morree Helma M.,Vullings Rik,Aarts Ronald M.","Eerikainen LM,Bonomi AG,Schipper F,Dekker LRC,de Morree HM,Vullings R,Aarts RM",Eerikainen LM,10.1109/JBHI.2019.2950574,Eindhoven University of Technology,"Objective: Photoplethysmography (PPG) enables unobtrusive heart rate monitoring, which can be used in wrist-worn applications. Its potential for detecting atrial fibrillation (AF) has been recently presented. Besides AF, another cardiac arrhythmia increasing stroke risk and requiring treatment is atrial flutter (AFL). Currently, the knowledge about AFL detection with PPG is limited. The objective of our study was to develop a model that classifies AF, AFL, and sinus rhythm with or without premature beats from PPG and acceleration data measured at the wrist in daily life. Methods: A dataset of 40 patients was collected by measuring PPG and accelerometer data, as well as electrocardiogram as a reference, during 24-hour monitoring. The dataset was split into 75%-25% for training and testing a Random Forest (RF) model, which combines features from PPG, inter-pulse intervals (IPI), and accelerometer data, to classify AF, AFL, and other rhythms. The performance was compared to an AF detection algorithm combining traditional IPI features for determining the robustness of the accuracy in presence of AFL. Results: The RF model classified AF/AFL/other with sensitivity and specificity of 97.6/84.5/98.1% and 98.2/99.7/92.8%, respectively. The results with the IPI-based AF classifier showed that the majority of false detections were caused by AFL. Conclusion: The PPG signal contains information to classify AFL in the presence of AF, sinus rhythm, or sinus rhythm with premature contractions. Significance: PPG could indicate presence of AFL, not only AF.","Rhythm,Heart rate,Electrocardiography,Monitoring,Training,Accelerometers,Computational modeling,Photoplethysmography,Accelerometer,Atrial Fibrillation (AF),Atrial Flutter,Random Forest",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"REDUCTION,SELECTION,RISK",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://ieeexplore.ieee.org/ielx7/6221020/9108313/08890854.pdf,
65,Joint Prediction of Breast Cancer Histological Grade and Ki-67 Expression Level Based on DCE-MRI and DWI Radiomics,24,6,1632-1642,"Fan Ming,Yuan Wei,Zhao Wenrui,Xu Maosheng,Wang Shiwei,Gao Xin,Li Lihua","Fan M,Yuan W,Zhao WR,Xu MS,Wang SW,Gao X,Li LH",Li LH,10.1109/JBHI.2019.2956351,Hangzhou Dianzi University,"Objective: Histologic grade and Ki-67 proliferation status are important clinical indictors for breast cancer prognosis and treatment. The purpose of this study is to improve prediction accuracy of these clinical indicators based on tumor radiomic analysis. Methods: We jointly predicted Ki-67 and tumor grade with a multitask learning framework by separately utilizing radiomics from tumor MRI series. Additionally, we showed how multitask learning models (MTLs) could be extended to combined radiomics from the MRI series for a better prediction based on the assumption that features from different sources of images share common patterns while providing complementary information. Tumor radiomic analysis was performed with morphological, statistical and textural features extracted on the DWI and dynamic contrast-enhanced MRI (DCE-MRI) series of the precontrast and subtraction images, respectively. Results: Joint prediction of Ki-67 status and tumor grade on MR images using the MTL achieved performance improvements over that of single-task-based predictive models. Similarly, for the prediction tasks of Ki-67 and tumor grade, the MTL for combined precontrast and apparent diffusion coefficient (ADC) images achieved AUCs of 0.811 and 0.816, which were significantly better than that of the single-task- based model with p values of 0.005 and 0.017, respectively. Conclusion: Mapping MRI radiomics to two related clinical indicators improves prediction performance for both Ki-67 expression level and tumor grade. Significance: Joint prediction of indicators by multitask learning that combines correlations of MRI radiomics is important for optimal tumor therapy and treatment because clinical decisions are made by integrating multiple clinical indicators.","Tumors,Feature extraction,Breast cancer,Magnetic resonance imaging,Pathology,Informatics,Breast cancer,Ki-67,histologic grade,radiomics,multitask learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"INTERNATIONAL,EXPERT,CONSENSUS,DIFFUSION-WEIGHTED,MRI,NEOADJUVANT,CHEMOTHERAPY,PROGNOSTIC-FACTORS,PRIMARY,THERAPY,FEATURES,HETEROGENEITY,MANAGEMENT,IMAGES,TUMORS",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://repository.kaust.edu.sa/bitstream/10754/660471/1/IEEEJBHIrevise_-_Highlight2.pdf,
66,MR-Forest: A Deep Decision Framework for False Positive Reduction in Pulmonary Nodule Detection,24,6,1652-1663,"Zhu Hongbo,Zhao Hai,Song Chunhe,Bian Zijian,Bi Yuanguo,Liu Tong,He Xuan,Yang Dongxiang,Cai Wei","Zhu HB,Zhao H,Song CH,Bian ZJ,Bi YG,Liu T,He X,Yang DX,Cai W",Bi YG,10.1109/JBHI.2019.2947506,"Minist Educ, Engn Res Ctr Secur Technol Complex Network Syst, Shenyang 110169, Peoples R China.","With the development of deep learning methods such as convolutional neural network (CNN), the accuracy of automated pulmonary nodule detection has been greatly improved. However, the high computational and storage costs of the large-scale network have been a potential concern for the future widespread clinical application. In this paper, an alternative Multi-ringed (MR)-Forest framework, against the resource-consuming neural networks (NN)-based architectures, has been proposed for false positive reduction in pulmonary nodule detection, which consists of three steps. First, a novel multi-ringed scanning method is used to extract the order ring facets (ORFs) from the surface voxels of the volumetric nodule models; Second, Mesh-LBP and mapping deformation are employed to estimate the texture and shape features. By sliding and resampling the multi-ringed ORFs, feature volumes with different lengths are generated. Finally, the outputs of multi-level are cascaded to predict the candidate class. On 1034 scans merging the dataset from the Affiliated Hospital of Liaoning University of Traditional Chinese Medicine (AH-LUTCM) and the LUNA16 Challenge dataset, our framework performs enough competitiveness than state-of-the-art in false positive reduction task (CPM score of 0.865). Experimental results demonstrate that MR-Forest is a successful solution to satisfy both resource-consuming and effectiveness for automated pulmonary nodule detection. The proposed MR-forest is a general architecture for 3D target detection, it can be easily extended in many other medical imaging analysis tasks, where the growth trend of the targeting object is approximated as a spheroidal expansion.","Feature extraction,Forestry,Three-dimensional displays,Harmonic analysis,Artificial neural networks,Task analysis,Computed tomography,False positive reduction,spherical surface feature,deep decision,ORFs,computer tomography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"AUTOMATIC,DETECTION,CLASSIFICATION,IMAGES",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
67,Computer-Aided Diagnosis in Histopathological Images of the Endometrium Using a Convolutional Neural Network and Attention Mechanisms,24,6,1664-1676,"Sun Hao,Zeng Xianxu,Xu Tao,Peng Gang,Ma Yutao","Sun H,Zeng XX,Xu T,Peng G,Ma YT",Ma YT,10.1109/JBHI.2019.2944977,Wuhan University,"Uterine cancer (also known as endometrial cancer) can seriously affect the female reproductive system, and histopathological image analysis is the gold standard for diagnosing endometrial cancer. Due to the limited ability to model the complicated relationships between histopathological images and their interpretations, existing computer-aided diagnosis (CAD) approaches using traditional machine learning algorithms often failed to achieve satisfying results. In this study, we develop a CAD approach based on a convolutional neural network (CNN) and attention mechanisms, called HIENet. In the ten-fold cross-validation on similar to 3,300 hematoxylin and eosin (H&E) image patches from similar to 500 endometrial specimens, HIENet achieved a 76.91 +/- 1.17% (mean +/- s. d.) accuracy for four classes of endometrial tissue, i.e., normal endometrium, endometrial polyp, endometrial hyperplasia, and endometrial adenocarcinoma. Also, HIENet obtained an area-under-the-curve (AUC) of 0.9579 +/- 0.0103 with an 81.04 +/- 3.87% sensitivity and 94.78 +/- 0.87% specificity in a binary classification task that detected endometrioid adenocarcinoma. Besides, in the external validation on 200 H&E image patches from 50 randomly-selected female patients, HIENet achieved an 84.50% accuracy in the four-class classification task, as well as an AUC of 0.9829 with a 77.97% (95% confidence interval, CI, 65.27%similar to 87.71%) sensitivity and 100% (95% CI, 97.42%similar to 100.00%) specificity. The proposed CAD method outperformed three human experts and five CNN-based classifiers regarding overall classification performance. It was also able to provide pathologists better interpretability of diagnoses by highlighting the histopathological correlations of local pixel-level image features to morphological characteristics of endometrial tissue.","Cancer,Pathology,Deep learning,Lung,Support vector machines,Medical diagnostic imaging,Endometrial cancer,Hematoxylin and eosin (H&E) image,Deep learning,Class activation map (CAM),Human-machine collaboration",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"LIQUID-BASED,CYTOLOGY,LEVEL,CLASSIFICATION,NUCLEAR,MORPHOMETRY,CANCER,STATISTICS,TEXTURE,DISCRIMINATION,HYPERPLASIA,CARCINOMA,FEATURES",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://arxiv.org/pdf/1904.10626,
68,Decoding Brain States From fMRI Signals by Using Unsupervised Domain Adaptation,24,6,1677-1685,"Gao Yufei,Zhang Yameng,Cao Zhiyuan,Guo Xiaojuan,Zhang Jiacai","Gao YF,Zhang YM,Cao ZY,Guo XJ,Zhang JC",Zhang JC,10.1109/JBHI.2019.2940695,Beijing Normal University,"With the development of deep learning in medical image analysis, decoding brain states from functional magnetic resonance imaging (fMRI) signals has made significant progress. Previous studies often utilized deep neural networks to automatically classify brain activity patterns related to diverse cognitive states. However, due to the individual differences between subjects and the variation in acquisition parameters across devices, the inconsistency in data distributions degrades the performance of cross-subject decoding. Besides, most current networks were trained in a supervised way, which is not suitable for the actual scenarios in which massive amounts of data are unlabeled. To address these problems, we proposed the deep cross-subject adaptation decoding (DCAD) framework to decipher the brain states. The proposed volume-based 3D feature extraction architecture can automatically learn the common spatiotemporal features of labeled source data to generate a distinct descriptor. Then, the distance between the source and target distributions is minimized via an unsupervised domain adaptation (UDA) method, which can help to accurately decode the cognitive states across subjects. The performance of the DCAD was evaluated on task-fMRI (tfMRI) dataset from the Human Connectome Project (HCP). Experimental results showed that the proposed method achieved the state-of-the-art decoding performance with mean 81.9% and 84.9% accuracies under two conditions (4 brain states and 9 brain states respectively) of working memory task. Our findings also demonstrated that UDA can mitigate the impact of the data distribution shift, thereby providing a superior choice for increasing the performance of cross-subject decoding without depending on annotations.","Decoding,Three-dimensional displays,Task analysis,Functional magnetic resonance imaging,Feature extraction,Kernel,Deep learning,Neural decoding,cross-subject,unsupervised domain adaptation,tfMRI",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"ACTIVITY,PATTERNS,REPRESENTATIONS,CONNECTIVITY",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
69,GoogLeNet-Based Ensemble FCNet Classifier for Focal Liver Lesion Diagnosis,24,6,1686-1694,"Balagourouchetty Lakshmipriya,Pragatheeswaran Jayanthi K.,Pottakkat Biju,Ramkumar G.","Balagourouchetty L,Pragatheeswaran JK,Pottakkat B,Ramkumar G",Balagourouchetty L,10.1109/JBHI.2019.2942774,"Manakula Vinayagar Inst Technol, Dept Elect & Commun Engn, Pondicherry 605107, India.","Transfer learning techniques are recently preferred for the computer aided diagnosis (CAD) of variety of diseases, as it makes the classification feasible from limited training dataset. In this work, an ensemble FCNet classifier is proposed to classify hepatic lesions from the deep features extracted using GoogleNet-LReLU transfer learning approachs. In the existing GoogLeNet architecture three modifications are done: ReLU activation functions in the inception modules are replaced by leaky ReLU activation function; a stack of three fully connected layers are included before the classification layer; and deep features of different level of abstraction extracted from the output of every inception layer given as classifier input in order to significantly enhance the classifier performance. The performance of the proposed classifier by the virtue of the above mentioned modifications is tested on six classes of liver CT images namely normal, hepatocellular carcinoma, hemangioma, cyst, abscess and liver metastasis. The results presented in this work demonstrate the efficacy of the proposed classifier design in achieving better classification accuracy.","Liver,Lesions,Feature extraction,Computed tomography,Image segmentation,Biomedical imaging,Image color analysis,Contrast Enhanced Computed Tomography,GoogLeNet,liver pathologies,multi-temporal fusion,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"CONVOLUTIONAL,NEURAL-NETWORKS,DEEP,SYSTEM,FEATURES,BREAST,TUMORS",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
70,Deep Learning Classification of Neuro-Emotional Phase Domain Complexity Levels Induced by Affective Video Film Clips,24,6,1695-1702,Aydin Serap,Aydin S,Aydin S,10.1109/JBHI.2019.2959843,Hacettepe University,"In the present article, a novel emotional complexity marker is proposed for classification of discrete emotions induced by affective video film clips. Principal Component Analysis (PCA) is applied to full-band specific phase space trajectory matrix (PSTM) extracted from short emotional EEG segment of 6 s, then the first principal component is used to measure the level of local neuronal complexity. As well, Phase Locking Value (PLV) between right and left hemispheres is estimated for in order to observe the superiority of local neuronal complexity estimation to regional neuro-cortical connectivity measurements in clustering nine discrete emotions (fear, anger, happiness, sadness, amusement, surprise, excitement, calmness, disgust) by using Long-Short-Term-Memory Networks as deep learning applications. In tests, two groups (healthy females and males aged between 22 and 33 years old) are classified with the accuracy levels of 68.52% and 79.36% through the proposed emotional complexity markers and and connectivity levels in terms of PLV in amusement. The groups are found to be statistically different (p << 0.5) in amusement with respect to both metrics, even if gender difference does not lead to different neuro-cortical functions in any of the other discrete emotional states. The high deep learning classification accuracy of 98.00% is commonly obtained for discrimination of positive emotions from negative emotions through the proposed new complexity markers. Besides, considerable useful classification performance is obtained in discriminating mixed emotions from each other through full-band connectivity features. The results reveal that emotion formation is mostly influenced by individual experiences rather than gender. In detail, local neuronal complexity is mostly sensitive to the affective valance rating, while regional neuro-cortical connectivity levels are mostly sensitive to the affective arousal ratings.","Electroencephalography,Complexity theory,Principal component analysis,Emotion recognition,Informatics,Trajectory,Brain biophysics,emotion recognition,affective neuroscience,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"PARKINSONS-DISEASE,FEATURE-EXTRACTION,OCULAR,ARTIFACTS,EEG,SIGNALS,FEATURES,RECOGNITION,PERFORMANCE,POTENTIALS,RECURRENT,REDUCTION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
71,Non-Invasive Estimation of Hemoglobin Using a Multi-Model Stacking Regressor,24,6,1717-1726,"Acharya Soumyadipta,Swaminathan Dhivya,Das Sreetama,Kansara Krity,Chakraborty Sushovan,Kumar Dinesh R.,Francis Tony,Aatre Kiran R.","Acharya S,Swaminathan D,Das S,Kansara K,Chakraborty S,Kumar RD,Francis T,Aatre KR",Acharya S,10.1109/JBHI.2019.2954553,Johns Hopkins University,"Objective: We describe a novel machine-learning based method to estimate total Hemoglobin (Hb) using photoplethysmograms (PPGs) acquired non-invasively. Methods: In a study conducted in Karnataka, India, 1583 women (pregnant and non-pregnant) of childbearing age, with Hb values ranging between 1.6 to 14.8 g/dL, had their Hb values estimated using intravenous blood samples and concurrently by a finger sensor custom designed and prototyped for this study. The finger sensor collected PPG signals at four wavelengths: 590 nm, 660 nm, 810 nm, and 940 nm. A novel feature vector was derived from these PPGs. A machine learning model comprising of a two-layer stack of regressors including Least Absolute Shrinkage and Selection Operator (LASSO), Ridge, Elastic Net, Adaptive (Ada) Boost and Support Vector Regressors (SVR) was designed and tested. Results: We report a statistically significant Pearson's correlation coefficient (PCC) of 0.81 (p < 0.01) between the Hb value estimated by the proposed methodology and gold standard values of Hb, with a Root Mean Square Error (RMSE) of 1.353 +/- 0.042 g/dL. The performance of the stacked regressor model was significantly better than the performance of individual regressors (low RMSE, and better CC; p < 0.05). Post-hoc analysis showed that including pregnant women in the training data set significantly improved the performance of the algorithm. Conclusion: This article demonstrates the feasibility of a machine learning based non-invasive hemoglobin measurement system, especially for maternal anemia detection. Significance: By developing and demonstrating a machine learning approach on a large data set, we have demonstrated that such an approach could become the basis for a public health screening tool to detect and treat maternal anemia and could supplement global health intervention strategies.","Blood,Fingers,Attenuation,Estimation,Machine learning,Pregnancy,Anemia,Beer-Lambert's law,machine learning,non-invasive hemoglobin,plethysmography,stacked regressor",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"PREDICTION,SELECTION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
72,Machine Learning Algorithm for Gait Analysis and Classification on Early Detection of Parkinson,4,6,,"Alkhatib Rami,Diab Mohamad O.,Corbier Christophe,El Badaoui Mohamed","Alkhatib R,Diab MO,Corbier C,El Badaoui M",Alkhatib R,10.1109/LSENS.2020.2994938,"Rafik Hariri Univ, Mech & Mechatron Engn Dept, Coll Engn, Damour, Lebanon.","Gait analysis using kinetic data such as pressure distribution underneath the foot has been a topic of interest for assessing falls in elderly and certain pathology such as Parkinson's disease. The disease which affects the central nervous system cannot be ultimately diagnosed by a test. In this letter, we describe a detection algorithm able to classify subjects into Parkinson or normal subjects based on load distribution during gait. This will allow those with the disease to benefit from early detection and thus early treatment. We perform spatial and time signal analyses over vertical ground reaction forces to categorize gaits as balanced or unbalanced, where unbalanced gaits correspond to subjects with Parkinson's disease and balanced gaits could be relevant to both normal and diseased subjects. Then simple features like correlation are used to further differentiate between balanced-normal subjects and balanced-diseased subjects. A 95% overall classification accuracy has been achieved using a linear decision boundary. This letter can be employed to form the basis of designing a portable device for early Parkinson's disease detection on a real-time basis. Moreover, it can be used for evaluation purposes of a rehabilitation program.","Sensor applications,balanced gait,center of pressure (COP),linear and quadratic discriminant analysis,load distribution,unbalanced gait,vertical ground reaction forces (VGRFs)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,,"GROUND,REACTION,FORCE,WALKING,SPEED,VARIABILITY",IEEE SENSORS LETTERS,,
73,A Functional-Near-Infrared-Spectroscopy-Based Evaluation of Cognitive Lagging From Prefrontal Hemodynamics,4,6,,"De Amiyangshu,Biswas Souvik,Konar Amit,Ghosh Lidia","De A,Biswas S,Konar A,Ghosh L",Konar A,10.1109/LSENS.2020.2997641,Jadavpur University,"Functional near infrared spectroscopy (fNIRS) devices capture the variability in oxygenated and deoxygenated blood flow in the cortical layers of the brain during execution of cognitive tasks. The present letter employs fNIRS device to study the cognitive lagging in working memory (WM) performance based on visuo-spatial forward span number search. The unsupervised learning-based clustering yields three distinct clusters of hemodynamic loads during the task performance. From these three clusters, we estimate cognitive lagging by computing the performance score per unit time and assigned three cognitive load classes: low, moderate, and high. Moving toward the classification approach of these three cognitive load classes, ensemble learning classifier produces higher classification accuracy, which reaches a maximum of 91.66%. The trend of shifting cognitive load from low toward high with performance score is observed from estimated Pearson's cross-correlation using the medoid points of cognitive load clusters and associated performance scores. The visualization of dynamic changes in cognitive load (low, moderate, and high) in temporal span of WM performance is obtained from the voxel plot approach, which advocates that regional deactivation of orbitofrontal cortex and augmented hemodynamic load in the dorsolateral prefrontal cortex has a possible relation with this cognitive lagging. In the view of experimental outcomes, the fNIRS-sensor-based measuring of cognitive load could be a future assessment tool for cognitive failure in higher task demand.","Sensor applications,cognitive lagging,cognitive load,ensemble learning classification,functional near infrared spectroscopy (fNIRS),partition around medoid (PAM) clustering,sensor application,working memory (WM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,,WORKING-MEMORY,IEEE SENSORS LETTERS,,
74,Cross Spectrum Aided Deep Feature Extraction Based Neuromuscular Disease Detection Framework,4,6,,"Roy Sayanjit Singha,Samanta Kaniska,Modak Sudip,Chatterjee Soumya,Bose Rohit","Roy SS,Samanta K,Modak S,Chatterjee S,Bose R",Roy SS,10.1109/LSENS.2020.2992452,"Techno India Univ, Elect Engn Dept, Kolkata 700091, India.","In this letter, a novel neuromuscular disease detection framework employing cross-wavelet spectrum (XWS) based deep feature extraction is proposed. In joint time-frequency analysis, cross-wavelet transform (XWT) is an important tool which provides the degree of correlation between two time series in both time scale and time-frequency plane. In this present contribution, XWT of healthy, myopathy, and amyotrophic lateral sclerosis electromyography signals was initially done with a reference healthy signal to obtain their respective XWS. The obtained cross-spectrum images of different electromyography signals were fed to a pretrained deep residual network for the purpose of feature extraction. Then, we selected the most discriminative feature set using one way analysis of variance test and false discovery rate correction. Finally, using the selected deep features, classification of Electromyography (EMG) signals was done using different benchmark machine learning classifiers. Four (three binary and one multiclass) classification tasks were performed and we observed that the proposed method delivered very high classification accuracy for all cases, which can be implemented for real time neuromuscular disease detection.","Sensor applications,cross-wavelet transform (XWT),classification,residual network,deep learning and electromyography signals",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,,,IEEE SENSORS LETTERS,,
75,Comparison of Different Machine Learning Approaches to Predict Small for Gestational Age Infants,6,2,334-346,"Li JianQiang,Liu Lu,Sun Jingchao,Mo Haowen,Yang Ji-Jiang,Chen Shi,Liu Huiting,Wang Qing,Pan Hui","Li JQ,Liu L,Sun JC,Mo HW,Yang JJ,Chen S,Liu HT,Wang Q,Pan H",Li JQ,10.1109/TBDATA.2016.2620981,Beijing University of Technology,"Diagnosing infants who are small for gestational age (SGA) at early stages could help physicians to introduce interventions for SGA infants earlier. Machine learning (ML) is envisioned as a tool to identify SGA infants. However, ML has not been widely studied in this field. To develop effective SGA prediction models, we conducted four groups of experiments that considered basic ML methods, imbalanced data, feature selection and the time characteristics of variables, respectively. Infants with SGA data collected from 2010 to 2013 with gestational weeks between 24 and 42 were detected. Support vector machine (SVM), random forest (RF), logistic regression (LR) and Sparse LR models were trained on 10-fold cross validation. Precision and the area under the curve (AUC) of the receiver operator characteristic curve were evaluated. For each group, the performance of SVM and Sparse LR was similarly well. LR without any sparsity penalties performed worst, possibly caused by the overfitting problem. With the combination of handling imbalanced data and feature selection, the RF ensemble classifier performed best, which even obtained the highest AUC value (0.8547) with the help of expert knowledge. In other cases, RF performed worse than Sparse LR and SVM, possibly because of fully grown trees.","Support vector machines,Pediatrics,Predictive models,Training,Radio frequency,Vegetation,Big data,Feature selection,machine learning,prediction model,small for gestational age",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Computer Science,,,DOPPLER,IEEE TRANSACTIONS ON BIG DATA,,
76,Novel Nonlinear Approach for Real-Time Fatigue EEG Data: An Infinitely Warped Model of Weighted Permutation Entropy,21,6,2437-2448,"Wu Edmond Q.,Zhu Li-Min,Zhang Wen-Ming,Deng Ping-Yu,Jia Bo,Chen Sheng-Di,Ren He,Zhou Gui-Rong","Wu EDQ,Zhu LM,Zhang WM,Deng PY,Jia B,Chen SD,Ren H,Zhou GR",Wu EDQ,10.1109/TITS.2019.2918438,Shanghai Jiao Tong University,"Workload assessment faces two major issues. That is, how to learn effective fatigue characteristics and how to find the potential state of the workload. This paper proposes a solution to assess the brain fatigue workload of pilots through an instantaneous spectral entropy feature and an infinitely warped model. The instantaneous characteristics of electroencephalography (EEG) signals are extracted by Hilbert transform, and Euclidean norm weighted permutation entropy is proposed. The infinitely warped model is a new automatic learning model for detecting arbitrary shapes of EEG data. In addition, we propose a rapid learning framework to learn mental fatigue by integrating Treelet transform and infinitely warped models. Compared to other state-of-the-art methods, our approach is better able to handle complex data in complex shapes. The experimental results show that this method can more effectively assess the brain fatigue of pilots.","Fatigue,Electroencephalography,Entropy,Brain modeling,Sleep,Feature extraction,Shape,Pilots' fatigue,electroencephalogram signals,permutation entropy,Gaussian mixture model",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Transportation",,7.253,"DRIVER,FATIGUE,CLASSIFICATION,SLEEPINESS,RECOGNITION,FEATURES,NETWORK,BRAIN",IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,,
77,Detecting High-Functioning Autism in Adults Using Eye Tracking and Machine Learning,28,6,1254-1261,"Yaneva Victoria,Le An Ha,Eraslan Sukru,Yesilada Yeliz,Mitkov Ruslan","Yaneva V,Ha LA,Eraslan S,Yesilada Y,Mitkov R",Yaneva V,10.1109/TNSRE.2020.2991675,University of Wolverhampton,"The purpose of this study is to test whether visual processing differences between adults with and without high-functioning autism captured through eye tracking can be used to detect autism. We record the eye movements of adult participants with and without autism while they look for information within web pages. We then use the recorded eye-tracking data to train machine learning classifiers to detect the condition. The data was collected as part of two separate studies involving a total of 71 unique participants (31 with autism and 40 control), which enabled the evaluation of the approach on two separate groups of participants, using different stimuli and tasks. We explore the effects of a number of gaze-based and other variables, showing that autism can be detected automatically with around 74% accuracy. These results confirm that eye-tracking data can be used for the automatic detection of high-functioning autism in adults and that visual processing differences between the two groups exist when processing web pages.","Autism,Task analysis,Visualization,Gaze tracking,Web pages,Data collection,Reliability,Autism,eye tracking,web,screening,diagnostic classification,detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"SPECTRUM,DISORDER,CLASSIFICATION,DIAGNOSIS,FEATURES,CHILDREN",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,https://open.metu.edu.tr/bitstream/handle/11511/68158/index.pdf,
78,A Heterogeneous Sensing Suite for Multisymptom Quantification of Parkinson's Disease,28,6,1397-1406,"Huo Weiguang,Angeles Paolo,Tai Yen F.,Pavese Nicola,Wilson Samuel,Hu Michele T.,Vaidyanathan Ravi","Huo WG,Angeles P,Tai YF,Pavese N,Wilson S,Hu MT,Vaidyanathan R",Huo WG,10.1109/TNSRE.2020.2978197,Imperial College London,"Parkinson's disease (PD) is the second most common neurodegenerative disease affecting millions worldwide. Bespoke subject-specific treatment (medication or deep brain stimulation (DBS)) is critical for management, yet depends on precise assessment cardinal PD symptoms - bradykinesia, rigidity and tremor. Clinician diagnosis is the basis of treatment, yet it allows only a cross-sectional assessment of symptoms which can vary on an hourly basis and is liable to inter- and intra-rater subjectivity across human examiners. Automated symptomatic assessment has attracted significant interest to optimise treatment regimens between clinician visits, however, no wearable has the capacity to simultaneously assess all three cardinal symptoms. Challenges in the measurement of rigidity, mapping muscle activity out-of-clinic and sensor fusion have inhibited translation. In this study, we address all through a novel wearable sensor system and machine learning algorithms. The sensor system is composed of a force-sensor, three inertial measurement units (IMUs) and four custom mechanomyography (MMG) sensors. The system was tested in its capacity to predict Unified Parkinson's Disease Rating Scale (UPDRS) scores based on quantitative assessment of bradykinesia, rigidity and tremor in PD patients. 23 PD patients were tested with the sensor system in parallel with exams conducted by treating clinicians and 10 healthy subjects were recruited as a comparison control group. Results prove the system accurately predicts UPDRS scores for all symptoms (85.4% match on average with physician assessment) and discriminates between healthy subjects and PD patients (96.6% on average). MMG features can also be used for remote monitoring of severity and fluctuations in PD symptoms out-of-clinic. This closed-loop feedback system enables individually tailored and regularly updated treatment, facilitating better outcomes for a very large patient population.","Parkinson's disease symptoms,wearable sensor system,machine learning,MMG,telemedicine,muscle stiffness",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"DEEP-BRAIN-STIMULATION,OBJECTIVE,ASSESSMENT,MOTOR,SYMPTOMS,TREMOR,RIGIDITY,SYSTEM,CLASSIFICATION,BRADYKINESIA",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
79,Classification of Electromyographic Hand Gesture Signals Using Modified Fuzzy C-Means Clustering and Two-Step Machine Learning Approach,28,6,1428-1435,"Jia Guangyu,Lam Hak-Keung,Ma Shichao,Yang Zhaohui,Xu Yujia,Xiao Bo","Jia GY,Lam HK,Ma SC,Yang ZH,Xu YJ,Xiao B",Lam HK,10.1109/TNSRE.2020.2986884,University of London,"Understanding and classifying electromyogram (EMG) signals is of significance for dexterous prosthetic hand control, sign languages, grasp recognition, human-machine interaction, etc.. The existing research of EMG-based hand gesture classification faces the challenges of unsatisfied classification accuracy, insufficient generalization ability, lack of training data and weak robustness. To address these problems, this paper combines unsupervised and supervised learning methods to classify an EMG dataset consisting of 10 classes of hand gestures. To lessen the difficulty of classification, clustering methods including subtractive clustering and fuzzy c-means (FCM) clustering algorithms are employed first to obtain the initial partition of the inputs. In particular, modified FCM algorithm is proposed to accustom the conventional FCM to the multi-class classification problem. Based on the grouping information obtained from clustering, a type of two-step supervised learning approach is proposed. Specifically, a top-classifier and three sub-classifiers integrated with windowing method and majority voting are employed to accomplish the two-step classification. The results demonstrate that the proposed method achieves 100% test accuracy and the strongest robustness compared to the conventional machine learning approaches, which shows the potential for industrial and healthcare applications, such as movement intention detection, grasp recognition and dexterous prostheses control.","Electromyography,Machine learning,Robustness,Training,Supervised learning,Clustering algorithms,Electrodes,EMG signals,clustering,hand gesture classification,machine learning,deep learning,fuzzy c-means (FCM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"EMG,FINGERS",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,https://kclpure.kcl.ac.uk/portal/files/133816911/FINAL_VERSION.pdf,
80,Obstructive sleep apnea detection using ecg-sensor with convolutional neural networks,79,23-24,15813-15827,"Wang Xiaowei,Cheng Maowei,Wang Yefu,Liu Shaohui,Tian Zhihong,Jiang Feng,Zhang Hongjun","Wang XW,Cheng MW,Wang YF,Liu SH,Tian ZH,Jiang F,Zhang HJ",Liu SH,10.1007/s11042-018-6161-8,Harbin Institute of Technology,"In recent years, AI(Artificial Intelligence) has achieved great development in modern society. More and more modern technologies are applied in surveillance and monitoring. Healthcare monitoring is growing ubiquitous in modern wearable devices, such as a smart watch, electrocardiogram (ECG) necklace, smart band. Many sensors are attached to these smart devices to record and monitor physiological signals caused by activities, and then propagated those recorded electrical data to be further processed to give health diagnosis, disease prevention or making a distress call automatically. Obstructive sleep apnea (OSA) is a sleep disorder with a high occurrence in adult people and observed as an autonomous risk factor for circulatory problems such as ischemic heart attacks and stroke. Numerous traditional neural network based methods have been developed to detect OSA, where these methods however could not provide the intended result because they rely on shallow network. In this paper, we propose an effective OSA detection based on Convolutional neural network. Our method first extracts features from Apnea-Electrocardiogram (ECG) recordings using RR-intervals (time interval from one R-wave to the next R-wave in an ECG signal) and then CNN model having three convolution layers and three fully connected layers is trained with extracted features and applied for OSA detection. The first two convolution layers are followed by batch normalization and pooling layer, and softmax is connected to the last fully connected layer to give final decision. Experimental results on extracted feature of Apnea-ECG signal reveal that our model have better results in terms of performance measure sensitivity, specificity and accuracy. It is expected that the related technology can be applied into smart sensors, especially wearable devices.","Intelligent surveillance,Sleep apnea,Feature extraction,ECG,Apnea detection,CNN",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"HEART-RATE,AUTOMATED,DETECTION,KERNELS",MULTIMEDIA TOOLS AND APPLICATIONS,,
81,Computer-aided detection and diagnosis of microcalcification clusters on full field digital mammograms based on deep learning method using neutrosophic boosting,79,23-24,17147-17167,"Cai Guanxiong,Guo Yanhui,Chen Weiguo,Zeng Hui,Zhou Yuanpin,Lu Yao","Cai GX,Guo YH,Chen WG,Zeng H,Zhou YP,Lu Y",Lu Y,10.1007/s11042-019-7726-x,Sun Yat Sen University,"Computer-aided detection (CADe) and diagnosis (CADx) system of mammographic microcalcification clusters (MCCs) is built for helping human observers to find suspicious areas of MCC and providing risk predictions of malignancy as a reference, since it is challenging and time consuming for radiologists to manually identify some subtle microcalcifications (MCs) and perform precise interpretation in mammograms. However, the performance of traditional CADe and CADx systems is not good enough, thus it is difficult to combine them into a whole system that integrates detection and diagnosis together. The purpose of this study is to develop a fully automatic computer-aided MCC detection and diagnosis system based on deep learning method. In order to detect subtle MCs accurately, a MC candidate detection system is used to obtain a great number of potential MC candidates, then a deep convolution neural network (DCNN) is trained specially to discriminate true MCs from detected MC candidates. Different from previous literatures committing to finding and selecting effective features, the proposed method replaces manual feature extraction step by using DCNN. To accelerate the training procedure of the DCNN, a neutrosophic boosting (NB) strategy is applied in the training stage. Then a density-based regional clustering method is imposed on those true MCs to form MCCs. Finally, another DCNN is employed to differentiate benign from malignant MCC lesions. For cluster-based MCC detection evaluation, a sensitivity of 90% is achieved at 0.14 false positives (FPs) per image. For case-based MCC classification evaluation, the area under the receiver operating characteristic curves (AUCs) on validation and testing sets are 0.945, 0.933 for proposed system, respectively. Our obtained results demonstrated the effectiveness of the proposed method for automated detection and classification of MCCs.","Full-field digital mammogram (FFDM),Microcalcification (MC),Deep convolution neural network (DCNN)",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"SEGMENTATION,SELECTION",MULTIMEDIA TOOLS AND APPLICATIONS,,
82,Using deep learning to predict beam-tunable Pareto optimal dose distribution for intensity-modulated radiation therapy,47,9,3898-3912,"Bohara Gyanendra,Sadeghnejad Barkousaraie Azar,Jiang Steve,Nguyen Dan","Bohara G,Barkousaraie AS,Jiang S,Nguyen D",Nguyen D,10.1002/mp.14374,University of Texas System,"Purpose Many researchers have developed deep learning models for predicting clinical dose distributions and Pareto optimal dose distributions. Models for predicting Pareto optimal dose distributions have generated optimal plans in real time using anatomical structures and static beam orientations. However, Pareto optimal dose prediction for intensity-modulated radiation therapy (IMRT) prostate planning with variable beam numbers and orientations has not yet been investigated. We propose to develop a deep learning model that can predict Pareto optimal dose distributions by using any given set of beam angles, along with patient anatomy, as input to train the deep neural networks. We implement and compare two deep learning networks that predict with two different beam configuration modalities. Methods We generated Pareto optimal plans for 70 patients with prostate cancer. We used fluence map optimization to generate 500 IMRT plans that sampled the Pareto surface for each patient, for a total of 35 000 plans. We studied and compared two different models, Models I and II. Although they both used the same anatomical structures - including the planning target volume (PTV), organs at risk (OARs), and body - these models were designed with two different methods for representing beam angles. Model I directly uses beam angles as a second input to the network as a binary vector. Model II converts the beam angles into beam doses that are conformal to the PTV. We divided the 70 patients into 54 training, 6 validation, and 10 testing patients, thus yielding 27 000 training, 3000 validation, and 5000 testing plans. Mean square loss (MSE) was taken as the loss function. We used the Adam optimizer with a default learning rate of 0.01 to optimize the network's performance. We evaluated the models' performance by comparing their predicted dose distributions with the ground truth (Pareto optimal) dose distribution, in terms of dose volume histogram (DVH) plots and evaluation metrics such as PTV D-98, D-95, D-50, D-2, D-max, D-mean, Paddick Conformation Number, R50, and Homogeneity index. Results Our deep learning models predicted voxel-level dose distributions that precisely matched the ground truth dose distributions. The DVHs generated also precisely matched the ground truth. Evaluation metrics such as PTV statistics, dose conformity, dose spillage (R50), and homogeneity index also confirmed the accuracy of PTV curves on the DVH. Quantitatively, Model I's prediction error of 0.043 (confirmation), 0.043 (homogeneity), 0.327 (R50), 2.80% (D95), 3.90% (D98), 0.6% (D50), and 1.10% (D2) was lower than that of Model II, which obtained 0.076 (confirmation), 0.058 (homogeneity), 0.626 (R50), 7.10% (D95), 6.50% (D98), 8.40% (D50), and 6.30% (D2). Model I also outperformed Model II in terms of the mean dose error and the max dose error on the PTV, bladder, rectum, left femoral head, and right femoral head. Conclusions Treatment planners who use our models will be able to use deep learning to control the trade-offs between the PTV and OAR weights, as well as the beam number and configurations in real time. Our dose prediction methods provide a stepping stone to building automatic IMRT treatment planning.","beam tunable,deep learning,intensity-modulated radiation therapy,neural networks,pareto optimality,prostate cancer",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"DIRECT-APERTURE,OPTIMIZATION,3D,CONFORMAL,RADIOTHERAPY,PLAN,QUALITY,IMRT,CANCER,BREAST,GENERATION,CARCINOMA",MEDICAL PHYSICS,http://arxiv.org/pdf/2006.11236,
83,A Fast and Accurate SSVEP Brain Machine Interface Using Dry Electrodes and High Frequency Stimuli by Employing Ensemble Learning,18,6,1000-1007,"Silva A.,Cruz G.,Pinheiro C.","Silva A,Cruz G,Pinheiro C",Silva A,10.1109/TLA.2020.9099676,Universidade Federal de Goias,"This paper presents an original approach to the processing and classification of visual evoked potentials signals (SSVEP). It introduces an ensemble learning model that combines canonical correlation analysis with methods based on power spectral density. The stimuli used was built using LEDs and ranged from 7.04 Hz up to 38.46 Hz. The data was collect using ADS1299 and three dry electrodes. The tests were performed for different light intensities and different distances between the LEDs. In total, 22 participants were recruited and the mean accuracy was 99.1 +/- 2.27 % with a decision time of 1 second. To the best of our knowledge, these results surpass what was previously published in others works that used high frequency stimuli in SSVEP-BCI, i.e., a mean accuracy of approximately 90%, with decision time of 5 seconds.","Light emitting diodes,Electroencephalography,Visualization,Bagging,IEEE transactions,Electrodes,canonical correlation analysis,cca,brain-computer,eeg,visual evoked potentials,ssvep",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,0.675,,IEEE LATIN AMERICA TRANSACTIONS,,
84,Automated Die Inking,20,2,295-307,"Xanthopoulos Constantinos,Neckermann Arnold,List Paulus,Tschernay Klaus-Peter,Sarson Peter,Makris Yiorgos","Xanthopoulos C,Neckermann A,List P,Tschernay KP,Sarson P,Makris Y",Xanthopoulos C,10.1109/TDMR.2020.2994291,University of Texas System,"Ensuring high reliability in modern integrated circuits (ICs) requires the employment of several die screening methodologies. One such technique, commonly referred to as die inking, aims to discard devices that are likely to fail, based on their proximity to known failed devices on the wafer. Die inking is traditionally performed manually by visually inspecting each manufactured wafer and thus it is very time-consuming. Towards reducing this cost, we introduce a novel machine learning-based methodology to learn and automatically generate the inking pat-terns from the failure maps, thus eliminating the need for human intervention. Effectiveness is demonstrated on an industrial set of manually inked wafers.","Testing,Manuals,Manufacturing,Materials reliability,Integrated circuits,Performance evaluation,Inking,die screening,automation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Physics",,1.777,"ADAPTIVE,TEST,BURN-IN,SEARCH",IEEE TRANSACTIONS ON DEVICE AND MATERIALS RELIABILITY,,
85,Optimized Combination of Multiple Graphs With Application to the Integration of Brain Imaging and (epi)Genomics Data,39,6,1801-1811,"Bai Yuntong,Pascal Zille,Calhoun Vince,Wang Yu-Ping","Bai YT,Pascal Z,Calhoun V,Wang YP",Bai YT,10.1109/TMI.2019.2958256,Tulane University,"With the rapid development of high-throughput technologies, a growing amount of multi-omics data are collected, giving rise to a great demand for combining such data for biomedical discovery. Due to the cost and time to label the data manually, the number of labelled samples is limited. This motivated the need for semi-supervised learning algorithms. In this work, we applied a graph-based semi-supervised learning (GSSL) to classify a severe chronic mental disorder, schizophrenia (SZ). An advantage of GSSL is that it can simultaneously analyse more than two types of data, while many existing models focus on pairwise data analysis. In particular, we applied GSSL to the analysis of single nucleotide polymorphism (SNP), functional magnetic resonance imaging (fMRI) and DNA methylation data, which accounts for genetics, brain imaging (endophenotypes), and environmental factors (epigenomics) respectively. While parameter selection has been an open challenge for most models, another key contribution of this work is that we explored the parameter space to interpret their meaning and established practical guidelines. Based on the practical significance of each hyper-parameter, a relatively small range of candidate values can be determined in a data-driven way to both optimize and speed up the parameter tuning process. We validated the model through both synthetic data and a real SZ dataset of 184 subjects from the Mental Illness and Neuroscience Discovery (MIND) Clinical Imaging Consortium. In comparison to several existing approaches, our algorithm achieved better performance in terms of classification accuracy. We also confirmed the significance of several brain regions associated with SZ.","Optimization,Mathematical model,Symmetric matrices,Functional magnetic resonance imaging,Diseases,Semisupervised learning,Task analysis,Multi-view learning,graph-based analysis,parameter selection,schizophrenia",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"SUPERIOR,TEMPORAL,GYRUS,SCHIZOPHRENIA,OMICS,ABNORMALITIES,CLASSIFICATION,CEREBELLUM,ACTIVATION,COGNITION,THALAMUS,DEFICITS",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7394342,
86,UNet plus plus : Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation,39,6,1856-1867,"Zhou Zongwei,Siddiquee Md Mahfuzur Rahman,Tajbakhsh Nima,Liang Jianming","Zhou ZW,Siddiquee MMR,Tajbakhsh N,Liang JM",Liang JM,10.1109/TMI.2019.2959609,Arizona State University,"The state-of-the-art models for medical image segmentation are variants of U-Net and fully convolutional networks (FCN). Despite their success, these models have two limitations: (1) their optimal depth is apriori unknown, requiring extensive architecture search or inefficient ensemble of models of varying depths; and (2) their skip connections impose an unnecessarily restrictive fusion scheme, forcing aggregation only at the same-scale feature maps of the encoder and decoder sub-networks. To overcome these two limitations, we propose UNet++, a new neural architecture for semantic and instance segmentation, by (1) alleviating the unknown network depth with an efficient ensemble of U-Nets of varying depths, which partially share an encoder and co-learn simultaneously using deep supervision; (2) redesigning skip connections to aggregate features of varying semantic scales at the decoder sub-networks, leading to a highly flexible feature fusion scheme; and (3) devising a pruning scheme to accelerate the inference speed of UNet++. We have evaluated UNet++ using six different medical image segmentation datasets, covering multiple imaging modalities such as computed tomography (CT), magnetic resonance imaging (MRI), and electron microscopy (EM), and demonstrating that (1) UNet++ consistently outperforms the baseline models for the task of semantic segmentation across different datasets and backbone architectures; (2) UNet++ enhances segmentation quality of varying-size objects-an improvement over the fixed-depth U-Net; (3) Mask RCNN++ (Mask R-CNN with UNet++ design) outperforms the original Mask R-CNN for the task of instance segmentation; and (4) pruned UNet++ models achieve significant speedup while showing only modest performance degradation. Our implementation and pre-trained models are available at https://github.com/MrGiovanni/UNetPlusPlus.","Neuronal structure segmentation,liver segmentation,cell segmentation,nuclei segmentation,brain tumor segmentation,lung nodule segmentation,medical image segmentation,semantic segmentation,instance segmentation,deep supervision,model pruning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"ARCHITECTURES,ENSEMBLE,NODULES,NETWORK",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7357299,
87,ERGO: Efficient Recurrent Graph Optimized Emitter Density Estimation in Single Molecule Localization Microscopy,39,6,1942-1956,"Cardoen Ben,Ben Yedder Hanene,Sharma Anmol,Chou Keng C.,Nabi Ivan R.,Hamarneh Ghassan","Cardoen B,Ben Yedder H,Sharma A,Chou KC,Nabi IR,Hamarneh G",Cardoen B,10.1109/TMI.2019.2962361,Simon Fraser University,"Single molecule localization microscopy (SMLM) allows unprecedented insight into the three-dimensional organization of proteins at the nanometer scale. The combination of minimal invasive cell imaging with high resolution positions SMLM at the forefront of scientific discovery in cancer, infectious, and degenerative diseases. By stochastic temporal and spatial separation of light emissions from fluorescent labelled proteins, SMLM is capable of nanometer scale reconstruction of cellular structures. Precise localization of proteins in 3D astigmatic SMLM is dependent on parameter sensitive preprocessing steps to select regions of interest. With SMLM acquisition highly variable over time, it is non-trivial to find an optimal static parameter configuration. The high emitter density required for reconstruction of complex protein structures can compromise accuracy and introduce artifacts. To address these problems, we introduce two modular auto-tuning pre-processing methods: adaptive signal detection and learned recurrent signal density estimation that can leverage the information stored in the sequence of frames that compose the SMLM acquisition process. We show empirically that our contributions improve accuracy, precision and recall with respect to the state of the art. Both modules auto-tune their hyper-parameters to reduce the parameter space for practitioners, improve robustness and reproducibility, and are validated on a reference in silico dataset. Adaptive signal detection and density prediction can offer a practitioner, in addition to informed localization, a tool to tune acquisition parameters ensuring improved reconstruction of the underlying protein complex. We illustrate the challenges faced by practitioners in applying SMLM algorithms on real world data markedly different from the data used in development and show how ERGO can be run on new datasets without retraining while motivating the need for robust transfer learning in SMLM.","Image reconstruction,Microscopy,Proteins,Estimation,Three-dimensional displays,Labeling,Two dimensional displays,Single molecule localization microscopy,density estimation,signal detection,deep learning,recurrent network,dSTORM,astigmatism",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"SUPERRESOLUTION,BOOTSTRAP,CANCER,ALLOWS,DEEP",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
88,GANPOP: Generative Adversarial Network Prediction of Optical Properties From Single Snapshot Wide-Field Images,39,6,1988-1999,"Chen Mason T.,Mahmood Faisal,Sweer Jordan A.,Durr Nicholas J.","Chen MT,Mahmood F,Sweer JA,Durr NJ",Durr NJ,10.1109/TMI.2019.2962786,Johns Hopkins University,"We present a deep learning framework for wide-field, content-aware estimation of absorption and scattering coefficients of tissues, called Generative Adversarial Network Prediction of Optical Properties (GANPOP). Spatial frequency domain imaging is used to obtain ground-truth optical properties at 660 nm from in vivo human hands and feet, freshly resected human esophagectomy samples, and homogeneous tissue phantoms. Images of objects with either flat-field or structured illumination are paired with registered optical property maps and are used to train conditional generative adversarial networks that estimate optical properties from a single input image. We benchmark this approach by comparing GANPOP to a single-snapshot optical property (SSOP) technique, using a normalized mean absolute error (NMAE) metric. In human gastrointestinal specimens, GANPOP with a single structured-light input image estimates the reduced scattering and absorption coefficients with 60% higher accuracy than SSOP while GANPOP with a single flat-field illumination image achieves similar accuracy to SSOP. When applied to both in vivo and ex vivo swine tissues, a GANPOP model trained solely on structured-illumination images of human specimens and phantoms estimates optical properties with approximately 46% improvement over SSOP, indicating adaptability to new, unseen tissue types. Given a training set that appropriately spans the target domain, GANPOP has the potential to enable rapid and accurate wide-field measurements of optical properties.","Optical imaging,tissue optical properties,neural networks,machine learning,spatial frequency domain imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORKS,LIGHT-SCATTERING,REAL-TIME,SPECTROSCOPY,REFLECTANCE,CELLS,MODEL",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8314791,
89,Anatomical Attention Guided Deep Networks for ROI Segmentation of Brain MR Images,39,6,2000-2012,"Sun Liang,Shao Wei,Zhang Daoqiang,Liu Mingxia","Sun L,Shao W,Zhang DQ,Liu MX",Zhang DQ,10.1109/TMI.2019.2962792,Nanjing University of Aeronautics & Astronautics,"Brain region-of-interest (ROI) segmentation based on structural magnetic resonance imaging (MRI) scans is an essential step for many computer-aid medical image analysis applications. Due to low intensity contrast around ROI boundary and large inter-subject variance, it has been remaining a challenging task to effectively segment brain ROIs from structural MR images. Even though several deep learning methods for brain MR image segmentation have been developed, most of them do not incorporate shape priors to take advantage of the regularity of brain structures, thus leading to sub-optimal performance. To address this issue, we propose an anatomical attention guided deep learning framework for brain ROI segmentation of structural MR images, containing two subnetworks. The first one is a segmentation subnetwork, used to simultaneously extract discriminative image representation and segment ROIs for each input MR image. The second one is an anatomical attention subnetwork, designed to capture the anatomical structure information of the brain from a set of labeled atlases. To utilize the anatomical attention knowledge learned from atlases, we develop an anatomical gate architecture to fuse feature maps derived from a set of atlas label maps and those from the to-be-segmented image for brain ROI segmentation. In this way, the anatomical prior learned from atlases can be explicitly employed to guide the segmentation process for performance improvement. Within this framework, we develop two anatomical attention guided segmentation models, denoted as anatomical gated fully convolutional network (AG-FCN) and anatomical gated U-Net (AG-UNet), respectively. Experimental results on both ADNI and LONI-LPBA40 datasets suggest that the proposed AG-FCN and AG-UNet methods achieve superior performance in ROI segmentation of brain MR images, compared with several state-of-the-art methods.","Anatomical attention,deep learning,ROI segmentation,brain MR image",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"ATLAS,LABEL,FUSION,REGISTRATION,HIPPOCAMPAL,SIMILARITY,MODEL",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
90,3D-GLCM CNN: A 3-Dimensional Gray-Level Co-Occurrence Matrix-Based CNN Model for Polyp Classification via CT Colonography,39,6,2013-2024,"Tan Jiaxing,Gao Yongfeng,Liang Zhengrong,Cao Weiguo,Pomeroy Marc J.,Huo Yumei,Li Lihong,Barish Matthew A.,Abbasi Almas F.,Pickhardt Perry J.","Tan JX,Gao YF,Liang ZR,Cao WG,Pomeroy MJ,Huo YM,Li LH,Barish MA,Abbasi AF,Pickhardt PJ",Liang ZR,10.1109/TMI.2019.2963177,State University of New York (SUNY) System,"Accurately classifying colorectal polyps, or differentiating malignant from benign ones, has a significant clinical impact on early detection and identifying optimal treatment of colorectal cancer. Convolution neural network (CNN) has shown great potential in recognizing different objects (e.g. human faces) from multiple slice (or color) images, a task similar to the polyp differentiation, given a large learning database. This study explores the potential of CNN learning from multiple slice (or feature) images to differentiate malignant from benign polyps from a relatively small database with pathological ground truth, including 32 malignant and 31 benign polyps represented by volumetric computed tomographic (CT) images. The feature image in this investigation is the gray-level co-occurrence matrix (GLCM). For each volumetric polyp, there are 13 GLCMs, computed from each of the 13 directions through the polyp volume. For comparison purpose, the CNN learning is also applied to the multi-slice CT images of the volumetric polyps. The comparison study is further extended to include Random Forest (RF) classification of the Haralick texture features (derived from the GLCMs). From the relatively small database, this study achieved scores of 0.91/0.93 (two-fold/leave-one-out evaluations) AUC (area under curve of the receiver operating characteristics) by using the CNN on the GLCMs, while the RF reached 0.84/0.86 AUC on the Haralick features and the CNN rendered 0.79/0.80 AUC on the multiple-slice CT images. The presented CNN learning from the GLCMs can relieve the challenge associated with relatively small database, improve the classification performance over the CNN on the raw CT images and the RF on the Haralick features, and have the potential to perform the clinical task of differentiating malignant from benign polyps with pathological ground truth.","Polyp differentiation,image features,deep learning,GLCM,CT colonoscopy",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORKS,COMPUTER-AIDED,DIAGNOSIS,AMERICAN-CANCER-SOCIETY,NODULE,DETECTION,FEATURES,SURVEILLANCE,COLONOSCOPY,REDUCTION,LESIONS,SYSTEM",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://europepmc.org/articles/pmc7269812?pdf=render,
91,Robust Self-Supervised Learning of Deterministic Errors in Single-Plane (Monoplanar) and Dual-Plane (Biplanar) X-Ray Fluoroscopy,39,6,2051-2060,"Chow Jacky C. K.,Boyd Steven K.,Lichti Derek D.,Ronsky Janet L.","Chow JCK,Boyd SK,Lichti DD,Ronsky JL",Chow JCK,10.1109/TMI.2019.2963446,University of Calgary,"Fluoroscopic imaging that captures X-ray images at video framerates is advantageous for guiding catheter insertions by vascular surgeons and interventional radiologists. Visualizing the dynamical movements non-invasively allows complex surgical procedures to be performed with less trauma to the patient. To improve surgical precision, endovascular procedures can benefit from more accurate fluoroscopy data via calibration. This paper presents a robust self-calibration algorithm suitable for single-plane and dual-plane fluoroscopy. A three-dimensional (3D) target field was imaged by the fluoroscope in a strong geometric network configuration. The unknown 3D positions of targets and the fluoroscope pose were estimated simultaneously by maximizing the likelihood of the Student-t probability distribution function. A smoothed k-nearest-neighbour (kNN) regression is then used to model the deterministic component of the image reprojection error of the robust bundle adjustment. The Maximum Likelihood Estimation step and the kNN regression step are then repeated iteratively until convergence. Four different error modeling schemes were compared while varying the quantity of training images. It was found that using a smoothed kNN regression can automatically model the systematic errors in fluoroscopy with similar accuracy as a human expert using a small training dataset. When all training images were used, the 3D mapping error was reduced from 0.61-0.83 mm to 0.04 mm post-calibration (94.2-95.7% improvement), and the 2D reprojection error was reduced from 1.17-1.31 to 0.20-0.21 pixels (83.2-83.8% improvement). When using biplanar fluoroscopy, the 3D measurement accuracy of the system improved from 0.60 mm to 0.32 mm (47.2% improvement).","Calibration,photogrammetry,X-ray,fluoroscopy",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,"GEOMETRIC,IMAGE,DISTORTION,RADIATION-EXPOSURE,GLOBAL,METHOD,ACCURACY,RECONSTRUCTION,INTENSIFIERS,CALIBRATION,REPAIR",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2001.00686,
92,Explainable Anatomical Shape Analysis Through Deep Hierarchical Generative Models,39,6,2088-2099,"Biffi Carlo,Cerrolaza Juan J.,Tarroni Giacomo,Bai Wenjia,de Marvao Antonio,Oktay Ozan,Ledig Christian,Le Folgoc Loic,Kamnitsas Konstantinos,Doumou Georgia","Biffi C,Cerrolaza JJ,Tarroni G,Bai WJ,de Marvao A,Oktay O,Ledig C,Le Folgoc L,Kamnitsas K,Doumou G",Biffi C,10.1109/TMI.2020.2964499,Imperial College London,"Quantification of anatomical shape changes currently relies on scalar global indexes which are largely insensitive to regional or asymmetric modifications. Accurate assessment of pathology-driven anatomical remodeling is a crucial step for the diagnosis and treatment of many conditions. Deep learning approaches have recently achieved wide success in the analysis of medical images, but they lack interpretability in the feature extraction and decision processes. In this work, we propose a new interpretable deep learning model for shape analysis. In particular, we exploit deep generative networks to model a population of anatomical segmentations through a hierarchy of conditional latent variables. At the highest level of this hierarchy, a two-dimensional latent space is simultaneously optimised to discriminate distinct clinical conditions, enabling the direct visualisation of the classification space. Moreover, the anatomical variability encoded by this discriminative latent space can be visualised in the segmentation space thanks to the generative properties of the model, making the classification task transparent. This approach yielded high accuracy in the categorisation of healthy and remodelled left ventricles when tested on unseen segmentations from our own multi-centre dataset as well as in an external validation set, and on hippocampi from healthy controls and patients with Alzheimer's disease when tested on ADNI data. More importantly, it enabled the visualisation in three-dimensions of both global and regional anatomical features which better discriminate between the conditions under exam. The proposed approach scales effectively to large populations, facilitating high-throughput analysis of normal anatomy and pathology in large-scale studies of volumetric imaging.","Shape analysis,explainable deep learning,generative modeling,MRI",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"ALZHEIMERS-DISEASE,HEALTHY",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1907.00058,
93,Deep Learning of Imaging Phenotype and Genotype for Predicting Overall Survival Time of Glioblastoma Patients,39,6,2100-2109,"Tang Zhenyu,Xu Yuyun,Jin Lei,Aibaidula Abudumijiti,Lu Junfeng,Jiao Zhicheng,Wu Jinsong,Zhang Han,Shen Dinggang","Tang ZY,Xu YY,Jin L,Aibaidula A,Lu JF,Jiao ZC,Wu JS,Zhang H,Shen DG",Wu JS,10.1109/TMI.2020.2964310,Fudan University,"Glioblastoma (GBM) is the most common and deadly malignant brain tumor. For personalized treatment, an accurate pre-operative prognosis for GBM patients is highly desired. Recently, many machine learning-based methods have been adopted to predict overall survival (OS) time based on the pre-operative mono- or multi-modal imaging phenotype. The genotypic information of GBM has been proven to be strongly indicative of the prognosis; however, this has not been considered in the existing imaging-based OS prediction methods. The main reason is that the tumor genotype is unavailable pre-operatively unless deriving from craniotomy. In this paper, we propose a new deep learning-based OS prediction method for GBM patients, which can derive tumor genotype-related features from pre-operative multimodal magnetic resonance imaging (MRI) brain data and feed them to OS prediction. Specifically, we propose a multi-task convolutional neural network (CNN) to accomplish both tumor genotype and OS prediction tasks jointly. As the network can benefit from learning tumor genotype-related features for genotype prediction, the accuracy of predicting OS time can be prominently improved. In the experiments, multimodal MRI brain dataset of 120 GBM patients, with as many as four different genotypic/molecular biomarkers, are used to evaluate our method. Our method achieves the highest OS prediction accuracy compared to other state-of-the-art methods.","Glioblastoma,overall survival,prognosis,genotype,molecular,multi-task,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"MGMT,METHYLATION,RADIOMICS,BRAIN,HETEROGENEITY,DIFFUSION,MUTATION,GLIOMAS,TUMORS,MRI,COMBINATION",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7289674,
94,Biomarker Localization From Deep Learning Regression Networks,39,6,2121-2132,"Cano-Espinosa Carlos,Gonzalez German,Washko George R.,Cazorla Miguel,San Jose Estepar Raul","Cano-Espinosa C,Gonzalez G,Washko GR,Cazorla M,Estepar RS",Cano-Espinosa C,10.1109/TMI.2020.2965486,Universitat d'Alacant,"Biomarker estimation methods from medical images have traditionally followed a segment-and-measure strategy. Deep-learning regression networks have changed such a paradigm, enabling the direct estimation of biomarkers in databases where segmentation masks are not present. While such methods achieve high performance, they operate as a black-box. In this work, we present a novel deep learning network structure that, when trained with only the value of the biomarker, can perform biomarker regression and the generation of an accurate localization mask simultaneously, thus enabling a qualitative assessment of the image locus that relates to the quantitative result. We showcase the proposed method with three different network structures and compare their performance against direct regression networks in four different problems: pectoralis muscle area (PMA), subcutaneous fat area (SFA), liver mass area in single slice computed tomography (CT), and Agatston score estimated from non-contrast thoracic CT images (CAC). Our results show that the proposed method improves the performance with respect to direct biomarker regression methods (correlation coefficient of 0.978, 0.998, and 0.950 for the proposed method in comparison to 0.971, 0.982, and 0.936 for the reference regression methods on PMA, SFA and CAC respectively) while achieving good localization (DICE coefficients of 0.875, 0.914 for PMA and SFA respectively, p < 0.05 for all pairs). We observe the same improvement in regression results comparing the proposed method with those obtained by quantify the outputs using an U-Net segmentation network (0.989 and 0.951 respectively). We, therefore, conclude that it is possible to obtain simultaneously good biomarker regression and localization when training biomarker regression networks using only the biomarker value.","Biomarker direct regression,biomarker localization,coronary artery calcification,convolutional neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"PECTORALIS-MUSCLE,AREA,CARDIAC,CT,CORONARY",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7307703,
95,Deep Neural Networks With Region-Based Pooling Structures for Mammographic Image Classification,39,6,2246-2255,"Shu Xin,Zhang Lei,Wang Zizhou,Lv Qing,Yi Zhang","Shu X,Zhang L,Wang ZZ,Lv Q,Yi Z",Zhang L,10.1109/TMI.2020.2968397,Sichuan University,"Breast cancer is one of the most frequently diagnosed solid cancers. Mammography is the most commonly used screening technology for detecting breast cancer. Traditional machine learning methods of mammographic image classification or segmentation using manual features require a great quantity of manual segmentation annotation data to train the model and test the results. But manual labeling is expensive, time-consuming, and laborious, and greatly increases the cost of system construction. To reduce this cost and the workload of radiologists, an end-to-end full-image mammogram classification method based on deep neural networks was proposed for classifier building, which can be constructed without bounding boxes or mask ground truth label of training data. The only label required in this method is the classification of mammographic images, which can be relatively easy to collect from diagnostic reports. Because breast lesions usually take up a fraction of the total area visualized in the mammographic image, we propose different pooling structures for convolutional neural networks(CNNs) instead of the common pooling methods, which divide the image into regions and select the few with high probability of malignancy as the representation of the whole mammographic image. The proposed pooling structures can be applied on most CNN-based models, which may greatly improve the models' performance on mammographic image data with the same input. Experimental results on the publicly available INbreast dataset and CBIS dataset indicate that the proposed pooling structures perform satisfactorily on mammographic image data compared with previous state-of-the-art mammographic image classifiers and detection algorithm using segmentation annotations.","Mammographic image,breast cancer,deep neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,BREAST-CANCER,IEEE TRANSACTIONS ON MEDICAL IMAGING,,
96,"MimickNet, Mimicking Clinical Image Post- Processing Under Black-Box Constraints",39,6,2277-2286,"Huang Ouwen,Long Will,Bottenus Nick,Lerendegui Marcelo,Trahey Gregg E.,Farsiu Sina,Palmeri Mark L.","Huang OW,Long W,Bottenus N,Lerendegui M,Trahey GE,Farsiu S,Palmeri ML",Huang OW,10.1109/TMI.2020.2970867,Duke University,"Image post-processing is used in clinical-grade ultrasound scanners to improve image quality (e.g., reduce speckle noise and enhance contrast). These post-processing techniques vary across manufacturers and are generally kept proprietary, which presents a challenge for researchers looking to match current clinical-grade workflows. We introduce a deep learning framework, MimickNet, that transforms conventional delay-and-summed (DAS) beams into the approximate Dynamic Tissue Contrast Enhanced (DTCE (TM)) post-processed images found on Siemens clinical-grade scanners. Training MimickNet only requires post-processed image samples from a scanner of interest without the need for explicit pairing to DAS data. This flexibility allows MimickNet to hypothetically approximate any manufacturer's post-processing without access to the pre-processed data. MimickNet post-processing achieves a 0.940 +/- 0.018 structural similarity index measurement (SSIM) compared to clinical-grade post-processing on a 400 cine-loop test set, 0.937 +/- 0.025 SSIM on a prospectively acquired dataset, and 0.928 +/- 0.003 SSIM on an out-of-distribution cardiac cine-loop after gain adjustment. To our knowledge, this is the first work to establish deep learning models that closely approximate ultrasound post-processing found in current medical practice. MimickNet serves as a clinical post-processing baseline for future works in ultrasound image formation to compare against. Additionally, it can be used as a pretrained model for fine-tuning towards different post-processing techniques. To this end, we have made the MimickNet software, phantom data, and permitted in vivo data open-source at https://github.com/ouwen/MimickNet.","Clinical ultrasound,CycleGAN,image enhancement,MimickNet,ultrasound post-processing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"LAG,SPATIAL,COHERENCE,NETWORK",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://europepmc.org/articles/pmc7286793?pdf=render,
97,Automated MRI-Based Deep Learning Model for Detection of Alzheimer's Disease Process,30,6,,"Feng Wei,Van Halm-Lutterodt Nicholas,Tang Hao,Mecum Andrew,Mesregah Mohamed Kamal,Ma Yuan,Li Haibin,Zhang Feng,Wu Zhiyuan,Yao Erlin","Feng W,Van Halm-Lutterodt N,Tang H,Mecum A,Mesregah MK,Ma Y,Li HB,Zhang F,Wu ZY,Yao EL",Guo XH,10.1142/S012906572050032X,Capital Medical University,"In the context of neuro-pathological disorders, neuroimaging has been widely accepted as a clinical tool for diagnosing patients with Alzheimer's disease (AD) and mild cognitive impairment (MCI). The advanced deep learning method, a novel brain imaging technique, was applied in this study to evaluate its contribution to improving the diagnostic accuracy of AD. Three-dimensional convolutional neural networks (3D-CNNs) were applied with magnetic resonance imaging (MRI) to execute binary and ternary disease classification models. The dataset from the Alzheimer's disease neuroimaging initiative (ADNI) was used to compare the deep learning performances across 3D-CNN, 3D-CNN-support vector machine (SVM) and two-dimensional (2D)-CNN models. The outcomes of accuracy with ternary classification for 2D-CNN, 3D-CNN and 3D-CNN-SVM were 82.57 +/- 7.35%, 89.76 +/- 8.67% and 95.74 +/- 2.31% respectively. The 3D-CNN-SVM yielded a ternary classification accuracy of 93.71%, 96.82% and 96.73% for NC, MCI and AD diagnoses, respectively. Furthermore, 3D-CNN-SVM showed the best performance for binary classification. Our study indicated that 'NC versus MCI' showed accuracy, sensitivity and specificity of 98.90%, 98.90% and 98.80%; 'NC versus AD' showed accuracy, sensitivity and specificity of 99.10%, 99.80% and 98.40%; and 'MCI versus AD' showed accuracy, sensitivity and specificity of 89.40%, 86.70% and 84.00%, respectively. This study clearly demonstrates that 3D-CNN-SVM yields better performance with MRI compared to currently utilized deep learning methods. In addition, 3D-CNN-SVM proved to be efficient without having to manually perform any prior feature extraction and is totally independent of the variability of imaging protocols and scanners. This suggests that it can potentially be exploited by untrained operators and extended to virtual patient imaging data. Furthermore, owing to the safety, noninvasiveness and nonirradiative properties of the MRI modality, 3D-CNN-SMV may serve as an effective screening option for AD in the general population. This study holds value in distinguishing AD and MCI subjects from normal controls and to improve value-based care of patients in clinical practice.","Deep learning,convolution neural networks,three-dimensional magnetic resonance imaging,support vector machine,Alzheimer's disease,mild cognitive impairment",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Computer Science,,5.439,"MILD,COGNITIVE,IMPAIRMENT,EEG-BASED,DIAGNOSIS,CLASSIFICATION,NETWORK,CONNECTIVITY,REPRESENTATION,METHODOLOGY,PREDICTION,CONVERSION,COHERENCE",INTERNATIONAL JOURNAL OF NEURAL SYSTEMS,,
98,Perturbation-evoked potentials can be classified from single-trial EEG,17,3,,"Ditz Jonas C.,Schwarz Andreas,Mueller-Putz Gernot R.","Ditz JC,Schwarz A,Muller-Putz GR",Muller-Putz GR,10.1088/1741-2552/ab89fb,Graz University of Technology,"Objective.Loss of balance control can have serious consequences on interaction between humans and machines as well as the general well-being of humans. Perceived balance perturbations are always accompanied by a specific cortical activation, the so-called perturbation-evoked potential (PEP). In this study, we investigate the possibility to classify PEPs from ongoing EEG.Approach.Fifteen healthy subjects were exposed to seated whole-body perturbations. Each participant performed 120 trials; they were rapidly tilted to the right and left, 60 times respectively.Main results.We achieved classification accuracies of more than 85% between PEPs and rest EEG using a window-based classification approach. Different window lengths and electrode layouts were compared. We were able to achieve excellent classification performance (87.6 +/- 8.0% accuracy) by using a short window length of 200 ms and a minimal electrode layout consisting of only the Cz electrode. The peak classification accuracy coincides in time with the strongest component of PEPs, called N1.Significance.We showed that PEPs can be discriminated against ongoing EEG with high accuracy. These findings can contribute to the development of a system that can detect balance perturbations online.","passive brain-computer interface,perturbation-evoked potential,human-machine interaction,EEG,machine learning,rehabilitation,assistive device",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"BRAIN-COMPUTER,INTERFACES,CEREBRAL,POTENTIALS,RESPONSES,STANCE,GAIT,MOVEMENT,AFFERENT",JOURNAL OF NEURAL ENGINEERING,https://doi.org/10.1088/1741-2552/ab89fb,
99,Neonatal EEG sleep stage classification based on deep learning and HMM,17,3,,"Ghimatgar Hojat,Kazemi Kamran,Helfroush Mohammad Sadegh,Pillay Kirubin,Dereymaker Anneleen,Jansen Katrien,De Vos Maarten,Aarabi Ardalan","Ghimatgar H,Kazemi K,Helfroush MS,Pillay K,Dereymaker A,Jansen K,De Vos M,Aarabi A",Aarabi A,10.1088/1741-2552/ab965a,CHU Amiens,"Objective. Automatic sleep stage scoring is of great importance for investigating sleep architecture during infancy. In this work, we introduce a novel multichannel approach based on deep learning networks and hidden Markov models (HMM) to improve the accuracy of sleep stage classification in term neonates.Approach. The classification performance was evaluated on quiet sleep (QS) and active sleep (AS) stages, each with two sub-states, using multichannel EEG data recorded from sixteen neonates with postmenstrual age of 38-40 weeks. A comprehensive set of linear and nonlinear features were extracted from thirty-second EEG segments. The feature space dimensionality was then reduced by using an evolutionary feature selection method called MGCACO (Modified Graph Clustering Ant Colony Optimization) based on the relevance and redundancy analysis. A bi-directional long-short time memory (BiLSTM) network was trained for sleep stage classification. The number of channels was optimized using the sequential forward selection method to reduce the spatial space. Finally, an HMM-based postprocessing stage was used to reduce false positives by incorporating the knowledge of transition probabilities between stages into the classification process. The method performance was evaluated using the K-fold (KFCV) and leave-one-out cross-validation (LOOCV) strategies.Main results. Using six-bipolar channels, our method achieved a mean kappa and an overall accuracy of 0.71-0.76 and 78.9%-82.4% using the KFCV and LOOCV strategies, respectively.Significance. The presented automatic sleep stage scoring method can be used to study the neurodevelopmental process and to diagnose brain abnormalities in term neonates.","EEG,sleep stage classification,feature selection,channel selection,deep learning,HMM,neonates",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"CHANNEL,SELECTION,SEIZURE,DETECTION,LINE,LENGTH,SIGNALS,SYSTEM,DECOMPOSITION,INFANTS,STATES,MODEL",JOURNAL OF NEURAL ENGINEERING,,
100,Eyeblink recognition improves fatigue prediction from single-channel forehead EEG in a realistic sustained attention task,17,3,,"Ko Li-Wei,Komarov Oleksii,Lai Wei-Kai,Liang Wei-Gang,Jung Tzyy-Ping","Ko LW,Komarov O,Lai WK,Liang WG,Jung TP",Ko LW,10.1088/1741-2552/ab909f,National Yang Ming Chiao Tung University,"Objective. A passive brain-computer interface recognizes its operator's cognitive state without an explicitly performed control task. This technique is commonly used in conjunction with consumer-grade EEG devices for detecting the conditions of fatigue, attention, emotional arousal, or motion sickness. While it is easy to mount the sensors in the forehead area, which is not covered with hair, the recorded signals become greatly contaminated with eyeblink and movement artifacts, which makes it a challenge to acquire the data of suitable for analysis quality, particularly in few channel systems where a lack of spatial information limits the applicability of sophisticated signal cleaning algorithms. In this article, we demonstrate that by combining the features associated with electrocortical activities and eyeblink recognition analysis, it becomes feasible to design an accurate system for the inattention state prediction using just a single EEG sensor. Approach. Fifteen healthy 22-28 years old participants took part in the experiment that implemented a realistic sustained attention task of nighttime highway driving in a virtual environment. The EEG data were collected using a portable wireless Mindo-4 device, which constitutes an adjustable elastic strip with foam-based sensors, a data-acquisition module, an amplification and digitizing unit, and a Bluetooth (R) module. Main results. The spectral analysis of the EEG samples that immediately preceded the lane departure events revealed alterations in the tonic power spectral density, which accompanied elongations in the drivers' reaction times. The RMSE of the predicted reaction times, which are based on a combination of the brain-related and eyeblink features, is 0.034 +/- 0.019 s, and the r(2) is 0.885 +/- 0.057 according to a within-session leave-one-trial-out cross-validation. Significance. The drowsiness prediction from a frontal single-channel setup can achieve a comparable performance with using an array of occipital EEG sensors. As a direct result of utilizing a dry sensor placed in the non-covered with hair head area, the proposed approach in this study is low-cost and user-friendly.","brain computer interface,single-channel EEG,dry electrodes,machine learning,fatigue,attention,driving",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"DRIVER,SLEEPINESS,DROWSINESS,DYNAMICS,SIGNALS,SYSTEM",JOURNAL OF NEURAL ENGINEERING,,
