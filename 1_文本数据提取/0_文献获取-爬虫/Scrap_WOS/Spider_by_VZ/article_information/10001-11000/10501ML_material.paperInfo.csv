,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Radon Inversion via Deep Learning,39,6,2076-2087,"He Ji,Wang Yongbo,Ma Jianhua","He J,Wang YB,Ma JH",Ma JH,10.1109/TMI.2020.2964266,Southern Medical University - China,"The Radon transform is widely used in physical and life sciences, and one of its major applications is in medical X-ray computed tomography (CT), which is significantly important in disease screening and diagnosis. In this paper, we propose a novel reconstruction framework for Radon inversion with deep learning (DL) techniques. For simplicity, the proposed framework is denoted as iRadonMAP, i.e., inverse Radon transform approximation. Specifically, we construct an interpretable neural network that contains three dedicated components. The first component is a fully connected filtering (FCF) layer along the rotation angle direction in the sinogram domain, and the second one is a sinusoidal back-projection (SBP) layer, which back-projects the filtered sinogram data into the spatial domain. Next, a common network structure is added to further improve the overall performance. iRadonMAP is first pretrained on a large number of generic images from the ImageNet database and then fine-tuned with clinical patient data. The experimental results demonstrate the feasibility of the proposed iRadonMAP framework for Radon inversion.","Radon transform,Radon inversion,computed tomography,image reconstruction,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"RAY,CT,RECONSTRUCTION,COMPUTED-TOMOGRAPHY,IMAGE-RECONSTRUCTION,DOMAIN,REDUCTION,ALGORITHM,CNN",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1808.03015,
2,CT Male Pelvic Organ Segmentation via Hybrid Loss Network With Incomplete Annotation,39,6,2151-2162,"Wang Shuai,Nie Dong,Qu Liangqiong,Shao Yeqin,Lian Jun,Wang Qian,Shen Dinggang","Wang S,Nie D,Qu LQ,Shao YQ,Lian J,Wang Q,Shen DG",Shen DG,10.1109/TMI.2020.2966389,University of North Carolina,"Sufficient data with complete annotation is essential for training deep models to perform automatic and accurate segmentation of CT male pelvic organs, especially when such data is with great challenges such as low contrast and large shape variation. However, manual annotation is expensive in terms of both finance and human effort, which usually results in insufficient completely annotated data in real applications. To this end, we propose a novel deep framework to segment male pelvic organs in CT images with incomplete annotation delineated in a very user-friendly manner. Specifically, we design a hybrid loss network derived from both voxel classification and boundary regression, to jointly improve the organ segmentation performance in an iterative way. Moreover, we introduce a label completion strategy to complete the labels of the rich unannotated voxels and then embed them into the training data to enhance the model capability. To reduce the computation complexity and improve segmentation performance, we locate the pelvic region based on salient bone structures to focus on the candidate segmentation organs. Experimental results on a large planning CT pelvic organ dataset show that our proposed method with incomplete annotation achieves comparable segmentation performance to the state-of-the-art methods with complete annotation. Moreover, our proposed method requires much less effort of manual contouring from medical professionals such that an institutional specific model can be more easily established.","Image segmentation,male pelvic organ,deep learning,incomplete annotation,CT",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"AUTOMATIC,SEGMENTATION,PROSTATE,SEGMENTATION,PLANNING,CT,IMAGES,BLADDER,RECTUM",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8195629,
3,Enabling a Single Deep Learning Model for Accurate Gland Instance Segmentation: A Shape-Aware Adversarial Learning Framework,39,6,2176-2189,"Yan Zengqiang,Yang Xin,Cheng Kwang-Ting","Yan ZQ,Yang X,Cheng KT",Yang X,10.1109/TMI.2020.2966594,Huazhong University of Science & Technology,"Segmenting gland instances in histology images is highly challenging as it requires not only detecting glands from a complex background but also separating each individual gland instance with accurate boundary detection. However, due to the boundary uncertainty problem in manual annotations, pixel-to-pixel matching based loss functions are too restrictive for simultaneous gland detection and boundary detection. State-of-the-art approaches adopted multi-model schemes, resulting in unnecessarily high model complexity and difficulties in the training process. In this paper, we propose to use one single deep learning model for accurate gland instance segmentation. To address the boundary uncertainty problem, instead of pixel-to-pixel matching, we propose a segment-level shape similarity measure to calculate the curve similarity between each annotated boundary segment and the corresponding detected boundary segment within a fixed searching range. As the segment-level measure allows location variations within a fixed range for shape similarity calculation, it has better tolerance to boundary uncertainty and is more effective for boundary detection. Furthermore, by adjusting the radius of the searching range, the segment-level shape similarity measure is able to deal with different levels of boundary uncertainty. Therefore, in our framework, images of different scales are down-sampled and integrated to provide both global and local contextual information for training, which is helpful in segmenting gland instances of different sizes. To reduce the variations of multi-scale training images, by referring to adversarial domain adaptation, we propose a pseudo domain adaptation framework for feature alignment. By constructing loss functions based on the segment-level shape similarity measure, combining with the adversarial loss function, the proposed shape-aware adversarial learning framework enables one single deep learning model for gland instance segmentation. Experimental results on the 2015 MICCAI Gland Challenge dataset demonstrate that the proposed framework achieves state-of-the-art performance with one single deep learning model. As the boundary uncertainty problem widely exists in medical image segmentation, it is broadly applicable to other applications.","Gland instance segmentation,segment-level shape similarity measure,adversarial learning,feature alignment",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,,
4,Combinatorial Synthesis and High-Throughput Characterization of Microstructure and Phase Transformation in Ni-Ti-Cu-V Quaternary Thin-Film Library,6,6,637-643,"Al Hasan Naila M.,Hou Huilong,Sarkar Suchismita,Thienhaus Sigurd,Mehta Apurva,Ludwig Alfred,Takeuchi Ichiro","Al Hasan NM,Hou HL,Sarkar S,Thienhaus S,Mehta A,Ludwig A,Takeuchi I",Takeuchi I,10.1016/j.eng.2020.05.003,University System of Maryland,"Ni-Ti-based shape memory alloys (SMAs) have found widespread use in the last 70 years, but improving their functional stability remains a key quest for more robust and advanced applications. Named for their ability to retain their processed shape as a result of a reversible martensitic transformation, SMAs are highly sensitive to compositional variations. Alloying with ternary and quaternary elements to fine-tune the lattice parameters and the thermal hysteresis of an SMA, therefore, becomes a challenge in materials exploration. Combinatorial materials science allows streamlining of the synthesis process and data management from multiple characterization techniques. In this study, a composition spread of Ni-Ti-Cu-V thin-film library was synthesized by magnetron co-sputtering on a thermally oxidized Si wafer. Composition-dependent phase transformation temperature and microstructure were investigated and determined using high-throughput wavelength dispersive spectroscopy, synchrotron X-ray diffraction, and temperature-dependent resistance measurements. Of the 177 compositions in the materials library, 32 were observed to have shape memory effect, of which five had zero or near-zero thermal hysteresis. These compositions provide flexibility in the operating temperature regimes that they can be used in. A phase map for the quaternary system and correlations of functional properties are discussed with respect to the local microstructure and composition of the thin-film library. (C) 2020 THE AUTHORS. Published by Elsevier LTD on behalf of Chinese Academy of Engineering and Higher Education Press Limited Company.","Ni-Ti-Cu-V alloys,Combinatorial materials science,Quaternary alloys,Shape memory alloys,Thin-film library,Elastocaloric cooling,Thermoelastic cooling,Phase transformation,High-throughput characterization,Property mapping,Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Engineering,,8.977,"SHAPE-MEMORY,ALLOYS,TEMPERATURES,HYSTERESIS,SCIENCE",ENGINEERING,https://www.osti.gov/biblio/1647628,
5,On the complexities of sediment load modeling using integrative machine learning: Application of the great river of Loiza in Puerto Rico,585,,,"Zounemat-Kermani Mohammad,Mahdavi-Meymand Amin,Alizamir Meysam,Adarsh S.,Yaseen Zaher Mundher","Zounemat-Kermani M,Mahdavi-Meymand A,Alizamir M,Adarsh S,Yaseen ZM",Zounemat-Kermani M,10.1016/j.jhydrol.2020.124759,Shahid Bahonar University of Kerman (SBUK),"Sediment transportation in water bodies may cause many problems for the water resources projects and damage the environment. Hence, modeling sediment load components, including suspended sediment load (SSL) and bedload (BL) in rivers is of prime importance. Effective modeling of SSL and BL remains a challenging task due to their complex hydrological process. On this account, this study aims to appraise the potential of conventional machine learning (ML) models including adaptive neuro-fuzzy inference system (ANFIS), support vector regression (SVR), and their integrative version with nature optimization algorithm called genetic algorithm (GAANFIS and GA-SVR) for SSL and BL prediction. Two traditional models are developed for modeling verification including the sediment rating curve (SRC) and multiple linear regression (MLR). The modeling results are assessed using four statistical measures (e.g., root mean square error (RMSE), mean absolute error (MAE), Nash-Sutcliffe Efficiency (NSE), and coefficient of determination (R-2)), diagnostic analysis (scatter plots and Taylor diagram), and evaluation of the dependence of the state of the river flow-sediment system (hysteresis analysis). Based on the attained predictability performance, the integrative ML models reveal a superior prediction capacity in comparison with the standalone ANFIS, SVR, and the traditional models. In quantitative evaluation, the proposed integrative ML models indicate a remarkable prediction enhancement approximately 44% mean magnitude based on the MAE metric against the SRC traditional model for both the SSL and BL predicted values. Overall, the current investigation evidences the potential of the nature-inspired algorithm as a hyper-parameter optimizer for ML models that produce a reliable and robust predictive model for sediment concentration quantification.","Heuristic algorithms,Soft computing,Hydrology,Bed load,River engineering",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Geology,Water Resources",,6.033,"BED,MATERIAL,LOAD,SUSPENDED,SEDIMENT,PREDICTION,TRANSPORT,SIMULATION,TRANSFORM,IDENTIFICATION,DISCHARGE,SYSTEM,RUNOFF",JOURNAL OF HYDROLOGY,,
6,An artificial immune system-based algorithm for abnormal pattern in medical domain,76,6,4272-4286,"Sharmila L.,Sakthi U.","Sharmila L,Sakthi U",Sharmila L,10.1007/s11227-018-2340-7,Sathyabama Institute of Science & Technology,"In general, medical pattern is a collection of characters formed using the characters such as 'a', 'c', 'g' and 't'. The length of the pattern varies from one disease to another disease, and the pattern also seems to be different for different patients. Identifying an unusual pattern from the information design is troublesome a decade ago. In this paper, with a specific end goal to enhance the precision of the anomalous distinguishing pattern, an Artificial Immune System (AIS) is framed. In the present study, AIS is used to obtain the abnormal pattern by learning the characteristics of the entire data set. Due to the powerful and adaptive nature of AIS, detecting and identifying abnormal pattern is more accurate. This proposed idea is implemented in MATLAB software and experimented on DNA/RNA dataset and the performance is verified.","Pattern matching,Pattern recognition,Artificial immune system,Abnormal pattern detection,Learning data",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.344,"GENE-EXPRESSION,MOLECULAR,CLASSIFICATION,MICROARRAY,DATA,IDENTIFICATION,DISCOVERY,PROFILES,CANCER",JOURNAL OF SUPERCOMPUTING,,
7,Broad Learning System for Nonparametric Modeling of Clay Parameters,6,2,,"Kuok Sin-Chi,Yuen Ka-Veng","Kuok SC,Yuen KV",Yuen KV,10.1061/AJRUA6.0001066,University of Macau,"Due to the complex and uncertain nature of geomaterial properties, establishing representative parametric models between clay parameters is a challenging task. Nonparametric machine learning offers an accessible approach to develop empirical transformation models of clay parameters based on the available measurement. In this study, nonparametric modeling of clay parameter relationships via broad learning system (BLS) is introduced. Broad learning architecture provides an effective tool for nonparametric modeling based on noise-corrupted data. The architecture of deep learning is configured with stacks of hierarchical layers, which consume expensive computational cost for network training. In contrast, the network of BLS is established in a flat architecture and it can be modified incrementally. As a result, the broad learning flat network can be reconfigured efficiently to accommodate additional training data. To demonstrate the performance of the learning algorithm for clay parameters, the comprehensive global database CLAY/10/7490 with 7,490 data points from over 250 studies worldwide is utilized and analyzed. (C) 2020 American Society of Civil Engineers.","UNIAXIAL COMPRESSIVE STRENGTH,BAYESIAN-APPROACH,NEURAL-NETWORKS,SELECTION,STRESS",Article,"ASCE-AMER SOC CIVIL ENGINEERS, 1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA",Engineering,,2.266,"UNIAXIAL,COMPRESSIVE,STRENGTH,BAYESIAN-APPROACH,NEURAL-NETWORKS,SELECTION,STRESS",ASCE-ASME JOURNAL OF RISK AND UNCERTAINTY IN ENGINEERING SYSTEMS PART A-CIVIL ENGINEERING,,
8,Polarimetric Identification of 3D-Printed Nano Particle Encoded Optical Codes,12,3,,"Ahmadi Kavan,Latorre-Carmona Pedro,Javidi Bahram,Carnicer Artur","Ahmadi K,Latorre-Carmona P,Javidi B,Carnicer A",Carnicer A,10.1109/JPHOT.2020.2987484,University of Barcelona,"Document signature is a powerful technique used to determine whether a message is tampered or valid. Recently, this concept was extended to optical codes: we demonstrated that the combined use of optical techniques and machine learning algorithms might be able to distinguish among different classes of samples. In the present work, we produce nano particle encoded optical codes with predetermined designs synthesized with a 3D printer. We used conventional polylactic acid filament filled with metallic powder to include the effect of nano-encoding for unique polarimetric signatures. We investigated an interesting real-world scenario, that is, we demonstrate how a single class of codes is distinguished among a group of samples to be rejected. This is a difficult unbalanced problem since the number of polarimetric signatures that characterize the true class is small compared to the complete dataset. Each sample is characterized by analyzing the polarization state of the emerging light. Using the one class-support vector machine algorithm we found high accuracy figures in the recognition of the true class codes. To the best of our knowledge, this is the first report on implementing optical codes with nano particle encoded materials using 3D printing technology.","Optical polarization,Programmable logic arrays,Adaptive optics,Optical sensors,Three-dimensional displays,Optical imaging,Aluminum,Optical authentication and security,optical polarization,speckle noise",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Optics,Physics",,2.602,"AUTHENTICATION,SECURITY,SUPPORT",IEEE PHOTONICS JOURNAL,http://diposit.ub.edu/dspace/bitstream/2445/166231/1/701821.pdf,
9,A Robust Reference Optical Spectrum Based in-Band OSNR Monitoring Method Suitable for Flexible Optical Networks,12,3,,"Zhong Yibo,Cui Sheng,Lu Hongwei,Ke Changjian,Wang Haoyu,Jiang Peishan,Liu Deming","Zhong YB,Cui S,Lu HW,Ke CJ,Wang HY,Jiang PS,Liu DM",Cui S,10.1109/JPHOT.2020.2983058,Huazhong University of Science & Technology,"The in-band OSNR monitoring methods based on the noise-free reference optical spectrum (ROS) have attracted much attention in the field of optical performance monitoring because they are cost-effective and insensitive to chromatic dispersion and polarization mode dispersion. In this paper, we propose a new ROS based in-band OSNR monitoring method that is robust to the distortions due to non-ideal modulation, the variations of the in-line EDFA gain and the number of filtering elements traversed by the signal. Moreover, this method supports using the standard ROS retrieved by the existing machine-learning technique based optical spectrum identification technique, and thus can remove the need to measure the ROS near the transmitter, which is hard to perform, especially in flexible optical networks. These merits make the method more robust and convenient to use in practice. Extensive numerical simulations are presented to demonstrate the merits of the proposed method with respect to the existing ROS based methods.","Optical signal to noise ratio (OSNR),optical performance monitoring (OPM),optical spectrum (OS),cascaded filtering effect (CFE)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Optics,Physics",,,,IEEE PHOTONICS JOURNAL,https://ieeexplore.ieee.org/ielx7/4563994/9080409/09050528.pdf,
10,Automatic detection of tympanic membrane and middle ear infection from oto-endoscopic images via convolutional neural networks,126,,384-394,"Khan Mohammad Azam,Kwon Soonwook,Choo Jaegul,Hong Seok Min,Kang Sung Hun,Park Il-Ho,Kim Sung Kyun,Hong Seok Jin","Khan MA,Kwon S,Choo J,Hong SM,Kang SH,Park IH,Kim SK,Hong SJ",Kim SK; Hong SJ,10.1016/j.neunet.2020.03.023,Hallym University,"Convolutional neural networks (CNNs), a popular type of deep neural network, have been actively applied to image recognition, object detection, object localization, semantic segmentation, and object instance segmentation. Accordingly, the applicability of deep learning to the analysis of medical images has increased. This paper presents a novel application of state-of-the-art CNN models, such as DenseNet, to the automatic detection of the tympanic membrane (TM) and middle ear (ME) infection. We collected 2,484 oto-endoscopic images (OEIs) and classified them into one of three categories: normal, chronic otitis media (COM) with TM perforation, and otitis media with effusion (OME). Our results indicate that CNN models have significant potential for the automatic recognition of TM and ME infections, demonstrating a competitive accuracy of 95% in classifying TM and middle ear effusion (MEE) from OEIs. In addition to accuracy measurement, our approach achieves nearly perfect measures of 0.99 in terms of the average area under the receiver operating characteristics curve (AUROC). All these results indicate robust performance when recognizing TM and ME effusions in OEIs. Visualization through a class activation mapping (CAM) heatmap demonstrates that our proposed model performs prediction based on the correct region of OEIs. All these outcomes ensure the reliability of our method; hence, the study can aid otolaryngologists and primary care physicians in real-world scenarios. (c) 2020 Elsevier Ltd. All rights reserved.","Otoscope,Tympanic membrane,Otitis media,Convolutional neural networks",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,9.171,"DIABETIC-RETINOPATHY,OTOSCOPY,VALIDATION,SYSTEM,SKILLS",NEURAL NETWORKS,,
11,"The Lancaster Sensorimotor Norms: multidimensional measures of perceptual and action strength for 40,000 English words",52,3,1271-1291,"Lynott Dermot,Connell Louise,Brysbaert Marc,Brand James,Carney James","Lynott D,Connell L,Brysbaert M,Brand J,Carney J",Lynott D; Connell L,10.3758/s13428-019-01316-z,Lancaster University,"Sensorimotor information plays a fundamental role in cognition. However, the existing materials that measure the sensorimotor basis of word meanings and concepts have been restricted in terms of their sample size and breadth of sensorimotor experience. Here we present norms of sensorimotor strength for 39,707 concepts across six perceptual modalities (touch, hearing, smell, taste, vision, and interoception) and five action effectors (mouth/throat, hand/arm, foot/leg, head excluding mouth/throat, and torso), gathered from a total of 3,500 individual participants using Amazon's Mechanical Turk platform. The Lancaster Sensorimotor Norms are unique and innovative in a number of respects: They represent the largest-ever set of semantic norms for English, at 40,000 words x 11 dimensions (plus several informative cross-dimensional variables), they extend perceptual strength norming to the new modality of interoception, and they include the first norming of action strength across separate bodily effectors. In the first study, we describe the data collection procedures, provide summary descriptives of the dataset, and interpret the relations observed between sensorimotor dimensions. We then report two further studies, in which we (1) extracted an optimal single-variable composite of the 11-dimension sensorimotor profile (Minkowski 3 strength) and (2) demonstrated the utility of both perceptual and action strength in facilitating lexical decision times and accuracy in two separate datasets. These norms provide a valuable resource to researchers in diverse areas, including psycholinguistics, grounded cognition, cognitive semantics, knowledge representation, machine learning, and big-data approaches to the analysis of language and conceptual representations. The data are accessible via the Open Science Framework () and an interactive web application ().","MODALITY EXCLUSIVITY NORMS,MOTOR CORTEX,LARGE SET,LANGUAGE,RATINGS,EXPERIENCE,CONCRETENESS,SIMULATION,REPRESENTATION,IMAGEABILITY",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Psychology,,7.023,"MODALITY,EXCLUSIVITY,NORMS,MOTOR,CORTEX,LARGE,SET,LANGUAGE,RATINGS,EXPERIENCE,CONCRETENESS,SIMULATION,REPRESENTATION,IMAGEABILITY",BEHAVIOR RESEARCH METHODS,https://biblio.ugent.be/publication/8676494/file/8676671.pdf,
12,Benchmark AFLOW Data Sets for Machine Learning,9,2,153-156,"Clement Conrad L.,Kauwe Steven K.,Sparks Taylor D.","Clement CL,Kauwe SK,Sparks TD",Sparks TD,10.1007/s40192-020-00174-4,Utah System of Higher Education,"Materials informatics is increasingly finding ways to exploit machine learning algorithms. Techniques such as decision trees, ensemble methods, support vector machines, and a variety of neural network architectures are used to predict likely material characteristics and property values. Supplemented with laboratory synthesis, applications of machine learning to compound discovery and characterization represent one of the most promising research directions in materials informatics. A shortcoming of this trend, in its current form, is a lack of standardized materials data sets on which to train, validate, and test model effectiveness. Applied machine learning research depends on benchmark data to make sense of its results. Fixed, predetermined data sets allow for rigorous model assessment and comparison. Machine learning publications that do not refer to benchmarks are often hard to contextualize and reproduce. In this data descriptor article, we present a collection of data sets of different material properties taken from the AFLOW database. We describe them, the procedures that generated them, and their use as potential benchmarks. We provide a compressed ZIP file containing the data sets and a GitHub repository of associated Python code. Finally, we discuss opportunities for future work incorporating the data sets and creating similar benchmark collections.","AFLOW,Benchmark data sets,Machine learning,Materials informatics",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Materials Science",,,,INTEGRATING MATERIALS AND MANUFACTURING INNOVATION,,
13,Mapping marine litter with Unmanned Aerial Systems: A showcase comparison among manual image screening and machine learning techniques,155,,,"Goncalves Gil,Andriolo Umberto,Pinto Luis,Duarte Diogo","Goncalves G,Andriolo U,Pinto L,Duarte D",Andriolo U,10.1016/j.marpolbul.2020.111158,INESC,"Recent works have shown the feasibility of Unmanned Aerial Systems (UAS) for monitoring marine pollution.
We provide a comparison among techniques to detect and map marine litter objects on an UAS-derived orthophoto of a sandy beach-dune system. Manual image screening technique allowed a detailed description of marine litter categories. Random forest classifier returned the best-automated detection rate (F-score 70%), while convolutional neural network performed slightly worse (F-score 60%) due to a higher number of false positive detections.
We show that automatic methods allow faster and more frequent surveys, while still providing a reliable density map of the marine litter load. Image manual screening should be preferred when the characterization of marine litter type and material is required.
Our analysis suggests that the use of UAS-derived orthophoto is appropriate to obtain a detailed geolocation of marine litter items, requires much less human effort and allows a wider area coverage.","Coastal pollution,Plastic,Random forest,Convolutional neural network,Beach,Dune",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Environmental Sciences & Ecology,Marine & Freshwater Biology",,5.907,"BEACH,LITTER,RANDOM,FOREST,LIDAR,DATA,DEBRIS,SEA,CLASSIFICATION,ABUNDANCE,ISLAND",MARINE POLLUTION BULLETIN,,
14,"Deep Learning-Based Localization and Perception Systems: Approaches for Autonomous Cargo Transportation Vehicles in Large-Scale, Semiclosed Environments",27,2,139-150,"Liu Zhe,Suo Chuanzhe,Liu Yingtian,Shen Yueling,Qiao Zhijian,Wei Huanshu,Zhou Shunbo,Li Haoang,Liang Xinwu,Wang Hesheng","Liu Z,Suo CZ,Liu YT,Shen YL,Qiao ZJ,Wei HS,Zhou SB,Li HA,Liang XW,Wang HS",Liu Z,10.1109/MRA.2020.2977290,Chinese University of Hong Kong,"Vehicles capable of delivering heavy cargoes are a major means for the promotion of social productivity and are widely applied in industry. Even though self-driving technologies have been studied for a few decades and several successful applications have been demonstrated, autonomous industry vehicles are currently applied only in some specific scenarios with very low speed and fixed routes and are typically implemented in the indoor closed area of small-scale warehouses. In this article, we introduce the main perception and localization approaches of autonomous cargo transportation vehicles for industrial applications. We also demonstrate how these technologies can enable autonomous cargo transportation in the Hong Kong International Airport.","Three-dimensional displays,Transportation,Task analysis,Lasers,Feature extraction,Industries,Vehicle dynamics",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Robotics",,5.39,,IEEE ROBOTICS & AUTOMATION MAGAZINE,,
15,Multitasking Genetic Algorithm (MTGA) for Fuzzy System Optimization,28,6,1050-1061,"Wu Dongrui,Tan Xianfeng","Wu DR,Tan XF",Wu DR,10.1109/TFUZZ.2020.2968863,Huazhong University of Science & Technology,"Multitask learning uses auxiliary data or knowledge from relevant tasks to facilitate the learning in a new task. Multitask optimization applies multitask learning an optimization to study how effectively and efficiently tackle the multiple optimization problems, simultaneously. Evolutionary multitasking, or multifactorial optimization, is an emerging subfield of multitask optimization, which integrates evolutionary computation and multitask learning. This article proposes a novel and easy-to-implement multitasking genetic algorithm (MTGA), which copes well with significantly different optimization tasks by estimating and using the bias among them. Comparative studies with eight state-of-the-art single-task and multitask approaches in the literature on nine benchmarks demonstrated that, on average, the MTGA outperformed all of them and had lower computational cost than six of them. Based on the MTGA, a simultaneous optimization strategy for fuzzy system design is also proposed. Experiments on simultaneous optimization of type-1 and interval type-2 fuzzy logic controllers for couple-tank water level control demonstrated that the MTGA can find better fuzzy logic controllers than other approaches.","Task analysis,Biological cells,Optimization,Sociology,Statistics,Evolutionary computation,Genetic algorithms,Evolutionary multitasking,fuzzy logic controller (FLC),genetic algorithm,multifactorial optimization (MFO),multitask learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.444,"EVOLUTIONARY,MULTITASKING",IEEE TRANSACTIONS ON FUZZY SYSTEMS,http://arxiv.org/pdf/1812.06303,
16,Small Lung Nodules Detection Based on Fuzzy-Logic and Probabilistic Neural Network With Bioinspired Reinforcement Learning,28,6,1178-1189,"Capizzi Giacomo,Lo Sciuto Grazia,Napoli Christian,Polap Dawid,Wozniak Marcin","Capizzi G,Lo Sciuto G,Napoli C,Polap D,Wozniak M",Capizzi G,10.1109/TFUZZ.2019.2952831,University of Catania,"Internal organs, like lungs, are very often examined by the use of screening methods. For this purpose, we present an evaluation model based on a composition of fuzzy system combined with a neural network. The input image is evaluated by means of custom rules, which use type-1 fuzzy membership functions. The results are forwarded to a neural network for final evaluation. Our model was validated by using X-ray images with lung nodules. The results show the high performances of our approach with sensitivity and specificity reaching almost 95% and 90%, respectively, with an accuracy of 92.56%. The new methodology lowers the computational demands considerably and increases detection performances.","Lung,X-ray imaging,Neural networks,Fuzzy sets,Cancer,Probabilistic logic,Fuzzy systems,Automatic pathology recognition,biomedical image processing,chest X-ray screening fuzzy-logic,probabilistic neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.444,"COMPUTER-AIDED,DETECTION,PULMONARY,NODULES,CT,IMAGES,CLASSIFICATION,FEATURES,TEXTURE,SHAPE,COMBINATION,MACHINE",IEEE TRANSACTIONS ON FUZZY SYSTEMS,https://iris.uniroma1.it/retrieve/handle/11573/1328646/1285759/Capizzi_postprint_Small-Lung-Nodules_2019.pdf,
17,Covid-19: automatic detection from X-ray images utilizing transfer learning with convolutional neural networks,43,2,635-640,"Apostolopoulos Ioannis D.,Mpesiana Tzani A.","Apostolopoulos ID,Mpesiana TA",Apostolopoulos ID,10.1007/s13246-020-00865-4,University of Patras,"In this study, a dataset of X-ray images from patients with common bacterial pneumonia, confirmed Covid-19 disease, and normal incidents, was utilized for the automatic detection of the Coronavirus disease. The aim of the study is to evaluate the performance of state-of-the-art convolutional neural network architectures proposed over the recent years for medical image classification. Specifically, the procedure called Transfer Learning was adopted. With transfer learning, the detection of various abnormalities in small medical image datasets is an achievable target, often yielding remarkable results. The datasets utilized in this experiment are two. Firstly, a collection of 1427 X-ray images including 224 images with confirmed Covid-19 disease, 700 images with confirmed common bacterial pneumonia, and 504 images of normal conditions. Secondly, a dataset including 224 images with confirmed Covid-19 disease, 714 images with confirmed bacterial and viral pneumonia, and 504 images of normal conditions. The data was collected from the available X-ray images on public medical repositories. The results suggest that Deep Learning with X-ray imaging may extract significant biomarkers related to the Covid-19 disease, while the best accuracy, sensitivity, and specificity obtained is 96.78%, 98.66%, and 96.46% respectively. Since by now, all diagnostic tests show failure rates such as to raise concerns, the probability of incorporating X-rays into the diagnosis of the disease could be assessed by the medical community, based on the findings, while more research to evaluate the X-ray approach from different aspects may be conducted.","Covid-19,Automatic detections,X-ray,Transfer learning,Deep learning",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,,,PHYSICAL AND ENGINEERING SCIENCES IN MEDICINE,https://link.springer.com/content/pdf/10.1007/s13246-020-00865-4.pdf,
18,Artificial intelligence and machine learning for targeted energy storage solutions,21,,160-166,"Barrett Dean H.,Haruna Aderemi","Barrett DH,Haruna A",Barrett DH,10.1016/j.coelec.2020.02.002,University of Witwatersrand,"With the application of machine learning to large-material data sets, models are being developed that allow us to better predict novel materials with designed properties. Advances in artificial intelligence and its subclasses, as well as compute infrastructure, are making it possible to rapidly compute material properties, to access time/length scales and chemical spaces beyond the current capabilities of density functional theory and to outperform humans in interpretation and characterization of the data. This review highlights the latest developments in the field with special interest to energy storage materials.","Artificial Intelligence,Machine Learning,Battery-Energy Storage,Deep Learning,Database,Materials Computation,Algorithm",Review,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Chemistry,Electrochemistry,Materials Science",,7.045,"ELECTRODE,MATERIALS,LITHIUM,DESIGN,INTERFACE,DISCOVERY,CATHODE,PROJECT,ANODE",CURRENT OPINION IN ELECTROCHEMISTRY,,
19,Development and validation of phenotype classifiers across multiple sites in the observational health data sciences and informatics network,27,6,877-883,"Kashyap Mehr,Seneviratne Martin,Banda Juan M.,Falconer Thomas,Ryu Borim,Yoo Sooyoung,Hripcsak George,Shah Nigam H.","Kashyap M,Seneviratne M,Banda JM,Falconer T,Ryu B,Yoo S,Hripcsak G,Shah NH",Kashyap M,10.1093/jamia/ocaa032,"Stanford Univ Lyman Grad Residences, 121 Campus Dr,Apt 3312A,1265 Welch Rd, Stanford, CA 94305 USA.","Objective: Accurate electronic phenotyping is essential to support collaborative observational research. Supervised machine learning methods can be used to train phenotype classifiers in a high-throughput manner using imperfectly labeled data. We developed 10 phenotype classifiers using this approach and evaluated performance across multiple sites within the Observational Health Data Sciences and Informatics (OHDSI) network.
Materials and Methods: We constructed classifiers using the Automated PHenotype Routine for Observational Definition, Identification, Training and Evaluation (APHRODITE) R-package, an open-source framework for learning phenotype classifiers using datasets in the Observational Medical Outcomes Partnership Common Data Model. We labeled training data based on the presence of multiple mentions of disease-specific codes. Performance was evaluated on cohorts derived using rule-based definitions and real-world disease prevalence. Classifiers were developed and evaluated across 3 medical centers, including 1 international site.
Results: Compared to the multiple mentions labeling heuristic, classifiers showed a mean recall boost of 0.43 with a mean precision loss of 0.17. Performance decreased slightly when classifiers were shared across medical centers, with mean recall and precision decreasing by 0.08 and 0.01, respectively, at a site within the USA, and by 0.18 and 0.10, respectively, at an international site.
Discussion and Conclusion: We demonstrate a high-throughput pipeline for constructing and sharing phenotype classifiers across sites within the OHDSI network using APHRODITE. Classifiers exhibit good portability between sites within the USA, however limited portability internationally, indicating that classifier generalizability may have geographic limitations, and, consequently, sharing the classifier-building recipe, rather than the pretrained classifiers, may be more useful for facilitating collaborative observational research.","electronic phenotyping,electronic health records,cohort identification,phenotype,machine learning",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,,"ALGORITHMS,RECORD",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.biorxiv.org/content/biorxiv/early/2019/06/24/673418.full.pdf,
20,Where is my infusion pump? Harnessing network dynamics for improved hospital equipment fleet management,27,6,884-892,"Martinez Diego A.,Cai Jiarui,Oke Jimi B.,Jarrell Andrew S.,Feijoo Felipe,Appelbaum Jeffrey,Klein Eili,Barnes Sean,Levin Scott R.","Martinez DA,Cai JR,Oke JB,Jarrell AS,Feijoo F,Appelbaum J,Klein E,Barnes S,Levin SR",Martinez DA,10.1093/jamia/ocaa033,Johns Hopkins University,"Objective: Timely availability of intravenous infusion pumps is critical for high-quality care delivery. Pumps are shared among hospital units, often without central management of their distribution. This study seeks to characterize unit-to-unit pump sharing and its impact on shortages, and to evaluate a system-control tool that balances inventory across all care areas, enabling increased availability of pumps.
Materials and Methods: A retrospective study of 3832 pumps moving in a network of 5292 radiofrequency and infrared sensors from January to November 2017 at The Johns Hopkins Hospital in Baltimore, Maryland. We used network analysis to determine whether pump inventory in one unit was associated with inventory fluctuations in others. We used a quasi-experimental design and segmented regressions to evaluate the effect of the system-control tool on enabling safe inventory levels in all care areas.
Results: We found 93 care areas connected through 67,111 pump transactions and 4 discernible clusters of pump sharing. Up to 17% (95% confidence interval, 7%-27%) of a unit's pump inventory was explained by the inventory of other units within its cluster. The network analysis supported design and deployment of a hospital-wide inventory balancing system, which resulted in a 44% (95% confidence interval, 36%-53%) increase in the number of care areas above safe inventory levels.
Conclusions: Network phenomena are essential inputs to hospital equipment fleet management. Consequently, benefits of improved inventory management in strategic unit(s) are capable of spreading safer inventory levels throughout the hospital.","efficiency,organizational,systems analysis,machine learning,radio frequency identification device,electronic health records",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,,"OPERATIONAL,FAILURES,CARE",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647311,
21,Using word embeddings to improve the privacy of clinical notes,27,6,901-907,"Abdalla Mohamed,Abdalla Moustafa,Rudzicz Frank,Hirst Graeme","Abdalla M,Abdalla M,Rudzicz F,Hirst G",Abdalla M,10.1093/jamia/ocaa038,University of Toronto,"Objective: In this work, we introduce a privacy technique for anonymizing clinical notes that guarantees all private health information is secured (including sensitive data, such as family history, that are not adequately covered by current techniques).
Materials and Methods: We employ a new ""random replacement"" paradigm (replacing each token in clinical notes with neighboring word vectors from the embedding space) to achieve 100% recall on the removal of sensitive information, unachievable with current ""search-and-secure"" paradigms. We demonstrate the utility of this paradigm on multiple corpora in a diverse set of classification tasks.
Results: We empirically evaluate the effect of our anonymization technique both on upstream and downstream natural language processing tasks to show that our perturbations, while increasing security (ie, achieving 100% recall on any dataset), do not greatly impact the results of end-to-end machine learning approaches.
Discussion: As long as current approaches utilize precision and recall to evaluate deidentification algorithms, there will remain a risk of overlooking sensitive information. Inspired by differential privacy, we sought to make it statistically infeasible to recreate the original data, although at the cost of readability. We hope that the work will serve as a catalyst to further research into alternative deidentification methods that can address current weaknesses.
Conclusion: Our proposed technique can secure clinical texts at a low cost and extremely high recall with a readability trade-off while remaining useful for natural language processing classification tasks. We hope that our work can be used by risk-averse data holders to release clinical texts to researchers.","privacy,data anonymization,natural language processing,personal health records",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"DE-IDENTIFICATION,RELATEDNESS,INFORMATION",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://europepmc.org/articles/pmc7309261?pdf=render,
22,Spoken words as biomarkers: using machine learning to gain insight into communication as a predictor of anxiety,27,6,929-933,"Demiris George,Magan Kristin L. Corey,Oliver Debra Parker,Washington Karla T.,Chadwick Chad,Voigt Jeffrey D.,Brotherton Sam,Naylor Mary D.","Demiris G,Magan KLC,Oliver DP,Washington KT,Chadwick C,Voigt JD,Brotherton S,Naylor MD",Demiris G,10.1093/jamia/ocaa049,University of Pennsylvania,"Objective: The goal of this study was to explore whether features of recorded and transcribed audio communication data extracted by machine learning algorithms can be used to train a classifier for anxiety.
Materials and Methods: We used a secondary data set generated by a clinical trial examining problem-solving therapy for hospice caregivers consisting of 140 transcripts of multiple, sequential conversations between an interviewer and a family caregiver along with standardized assessments of anxiety prior to each session; 98 of these transcripts (70%) served as the training set, holding the remaining 30% of the data for evaluation.
Results: A classifier for anxiety was developed relying on language-based features. An 86% precision, 78% recall, 81% accuracy, and 84% specificity were achieved with the use of the trained classifiers. High anxiety inflections were found among recently bereaved caregivers and were usually connected to issues related to transitioning out of the caregiving role. This analysis highlighted the impact of lowering anxiety by increasing reciprocity between interviewers and caregivers.
Conclusion: Verbal communication can provide a platform for machine learning tools to highlight and predict behavioral health indicators and trends.","caregivers,anxiety,machine learning,communication,behavioral research",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,HEALTH,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7309232,
23,"Design, fabrication, modeling and control of a fabric-based spherical robotic arm",68,,,"Hofer Matthias,D'Andrea Raffaello","Hofer M,D'Andrea R",Hofer M,10.1016/j.mechatronics.2020.102369,"Inst Dynam Syst & Control, Sonneggstr 3, CH-8092 Zurich, Switzerland.","In this paper we present a spherical soft robotic arm made from fabric. The inflatable arm has a small mass and is pneumatically actuated. A configuration is employed with only three actuators controlling the two rotational degrees of freedom of a spherical joint. This differs from the commonly employed antagonistic pairs, including four actuators for two degrees of freedom. The fabrication procedure of the lightweight and compliant system is discussed in detail and uses commonly available materials and tools. The capability of the robotic arm to adjust the joint stiffness as a function of the actuator pressures is investigated and characterized for different deflection directions. The static mapping from the actuator pressures to the orientation of the robotic arm is identified from data and the inverse mapping is employed in a position controller. The modeling and controller derivation are performed for three different stiffness levels demonstrating the ability of the spherical robotic arm to change the joint stiffness independently of controlling the position. The position tracking performance is experimentally evaluated by tracking a square trajectory. A comparison of the tracking performance for the different stiffness levels shows that accurate tracking is more challenging for the smallest joint stiffness. A gray-box model capturing the interactions of the two degrees of freedom is used in a learning scheme that is applied for the smallest stiffness level. The learning approach reduces interactions between the two degrees of freedom and demonstrates the control performance achievable with the system developed.","Soft robotics,Pneumatic bellow actuator,Fabrication,Data-Driven modeling,Learning control",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Automation & Control Systems,Engineering,Robotics",,3.526,"SOFT,STIFFNESS",MECHATRONICS,https://doi.org/10.1016/j.mechatronics.2020.102369,
24,Fast screening for children's developmental language disorders via comprehensive speech ability evaluation-using a novel deep learning framework,8,11,,"Zhang Xing,Qin Feng,Chen Zelin,Gao Leyan,Qiu Guoxin,Lu Shuo","Zhang X,Qin F,Chen ZL,Gao LY,Qiu GX,Lu S",Lu S,10.21037/atm-19-3097,Sun Yat Sen University,"Background: Developmental language disorders (DLDs) are the most common developmental disorders in children. For screening DLDs, speech ability (SA) is one of the most important indicators.
Methods: In this paper, we propose a solution for the fast screening of children's DLDs based on a comprehensive SA evaluation and a deep framework of machine learning. Fast screening is crucial for promoting the prevalence and practicality of DLD screening which in turn is important for the treatment of DLDs and related social and behavioral abnormalities (e.g., dyslexia and autism). Our solution is focused on addressing the drawbacks existing in the previous DLD screening methods which include test failure due to text-based inducing material design and illiteracy of most young children, incomplete language evaluation indicators, and professional-reliant evaluation procedures. First, to avoid test failure, a novel comprehensive inducing procedure (CIP) with non-text (i.e., audio-visual) stimulus materials was designed that could cover a large range of modalities to adequately explore the comprehensive SA of the subjects. Second, to address incomplete language evaluation, a set of comprehensive evaluation indicators with full consideration of the characteristics of the children's language acquisition is proposed; furthermore, to break the professional-reliant limitation, we specifically designed a deep framework for fast and accurate screening.
Results: Experimental results showed that the proposed deep framework is effective and professional with a 92.6% accuracy on DLD screening. Additionally, to provide a benchmark for the novel problem, we provide a CIP dataset with about 2,200 responses from over 200 children, which may also be useful for further DLD studies and insightful for the fast screening design of other behavioral abnormalities.
Conclusions: Fast screening of children's DLDs can be achieved at accuracy up to 92.6% by our proposed deep learning framework. For successful fast screening, an elaborated CIP with corresponding comprehensive evaluating indicators is necessary to be designed for children suspected to have DLDs.","Developmental language disorders (DLDs),developmental language disorder indicators (DLD indicators),fast screening",Article,"AME PUBL CO, FLAT-RM C 16F, KINGS WING PLAZA 1, NO 3 KWAN ST, SHATIN, HONG KONG 00000, PEOPLES R CHINA","Oncology,Research & Experimental Medicine",,4.629,"NEURAL-NETWORKS,FLUENCY",ANNALS OF TRANSLATIONAL MEDICINE,https://atm.amegroups.com/article/viewFile/44371/pdf,
25,Microstructure design using machine learning generated low dimensional and continuous design space,11,,,"Jung Jaimyun,Yoon Jae Ik,Park Hyung Keun,Jo Hyeontae,Kim Hyoung Seop","Jung J,Yoon JI,Park HK,Jo H,Kim HS",Kim HS,10.1016/j.mtla.2020.100690,Pohang University of Science & Technology (POSTECH),"The cornerstone of materials design is the design space used in solving materials related optimization problems. Materials design strategies often involve evaluating properties of materials with selected design variables. Because a microstructure comprises a high dimensional data, dimensionality reduction using principal component analysis or multi-dimensional scaling has become a common practice in generating low dimensional design variables. Unfortunately, generation of microstructures is not guaranteed using design variables formulated using popular dimensionality reduction techniques. These design variables are limited to the initial dataset used for dimensionality reduction, resulting in a discontinuous design space. This shortcoming severely constrains design flexibility and can hamper the performance of design strategies. To address this limitation, we propose the use of the latent space of a convolutional autoencoder trained with synthetic dual phase (DP) microstructures as low dimensional and continuous design space. Once the design space is established, Bayesian optimization is adopted to search for optimal microstructures that exhibit maximal tensile strength. The strength of each microstructure is approximated using microstructure based finite element method. To take full advantage of the continuous design space, a second Bayesian optimization with a refined search space is adopted. The second Bayesian optimization resulted in higher maximum strength value and fewer number of data necessary to find the optimal microstructure compared to Bayesian optimization without search space refinement. Furthermore, multiple microstructures exhibiting strengths comparable to that of the optimal microstructure can be identified within the refined search space, providing significant flexibility in microstructure design.","Microstructure-based modelling,Machine learning,Bayesian optimization,Convolutional autoencoder",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Materials Science,,,"STRUCTURE-PROPERTY,LINKAGES,YIELD,STRENGTH,DP,STEELS,OPTIMIZATION,STRAIN,DEFORMATION,BEHAVIOR,MODEL",MATERIALIA,,
26,In-memory hyperdimensional computing,3,6,327-+,"Karunaratne Geethan,Le Gallo Manuel,Cherubini Giovanni,Benini Luca,Rahimi Abbas,Sebastian Abu","Karunaratne G,Le Gallo M,Cherubini G,Benini L,Rahimi A,Sebastian A",Sebastian A,10.1038/s41928-020-0410-3,International Business Machines (IBM),"A complete in-memory hyperdimensional computing system, which uses 760,000 phase-change memory devices, can efficiently perform machine learning related tasks including language classification, news classification and hand gesture recognition from electromyography signals.
Hyperdimensional computing is an emerging computational framework that takes inspiration from attributes of neuronal circuits including hyperdimensionality, fully distributed holographic representation and (pseudo)randomness. When employed for machine learning tasks, such as learning and classification, the framework involves manipulation and comparison of large patterns within memory. A key attribute of hyperdimensional computing is its robustness to the imperfections associated with the computational substrates on which it is implemented. It is therefore particularly amenable to emerging non-von Neumann approaches such as in-memory computing, where the physical attributes of nanoscale memristive devices are exploited to perform computation. Here, we report a complete in-memory hyperdimensional computing system in which all operations are implemented on two memristive crossbar engines together with peripheral digital complementary metal-oxide-semiconductor (CMOS) circuits. Our approach can achieve a near-optimum trade-off between design complexity and classification accuracy based on three prototypical hyperdimensional computing-related learning tasks: language classification, news classification and hand gesture recognition from electromyography signals. Experiments using 760,000 phase-change memory devices performing analog in-memory computing achieve comparable accuracies to software implementations.",STATEFUL LOGIC OPERATIONS,Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Engineering,,33.695,"STATEFUL,LOGIC,OPERATIONS",NATURE ELECTRONICS,http://arxiv.org/pdf/1906.01548,
27,Single-Trial EEG Responses Classified Using Latency Features,30,6,,"Hardiansyah Irzam,Pergher Valentina,Van Hulle Marc M.","Hardiansyah I,Pergher V,Van Hulle MM",Van Hulle MM,10.1142/S0129065720500331,KU Leuven,"Covert attention has been repeatedly shown to impact on EEG responses after single and repeated practice sessions. Machine learning techniques are increasingly adopted to classify single-trial EEG responses thereby primarily relying on amplitude-based features instead of latency-based features. In this study, we investigated changes in EEG response signatures of nine healthy older subjects when performing 10 sessions of covert attention training. We show that, when we trained classifiers to distinguish recorded EEC patterns between the two experimental conditions (a target stimulus is ""present"" or ""not present""), latency-based classifiers outperform the amplitude-based ones and that classification accuracy improved along with behavioral accuracy, providing supportive evidence of brain plasticity.","Longitudinal covert attention training,EEG,latency features",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Computer Science,,5.439,"EVENT-RELATED,POTENTIALS,WORKING-MEMORY,COGNITIVE,PLASTICITY,SELECTIVE,ATTENTION,BRAIN,POTENTIALS,ERP,YOUNG,OLD,COMPONENT,GAINS",INTERNATIONAL JOURNAL OF NEURAL SYSTEMS,,
28,Effects of process parameters on cutting temperature in dry machining of ball screw,101,,493-502,"Liu Chao,He Yan,Wang Yulin,Li Yufeng,Wang Shilong,Wang Lexiang,Wang Yan","Liu C,He Y,Wang YL,Li YF,Wang SL,Wang LX,Wang Y",He Y,10.1016/j.isatra.2020.01.031,Chongqing University,"Temperature in the cutting zone during dry machining has a significant effect on the tool life and surface integrity of the workpiece. This paper describes a comprehensive research on the cutting temperature in dry machining of ball screw under whirling milling by using infrared imaging. The effects of tool parameter and geometric parameter of workpiece together with the cutting parameters on the maximum and average temperatures in the cutting zone were analyzed in full detail. The influencing degree of these parameters on the maximum and average temperatures was affected by the value ranges of the parameters. In addition, the regression model and back propagation (BP) neural network model were proposed for predicting the maximum and average temperatures in the cutting zone. The verification of the predictive models showed that compared to the regression model, BP neural network model could predict the cutting temperature with high precision. The R-2 of BP neural network model for predicting the maximum and average cutting temperatures in the cutting zone was higher than 99.8%, and the mean relative error and root mean square error were less than 4% and 19%, respectively. (c) 2020 ISA. Published by Elsevier Ltd. All rights reserved.","Cutting temperature,Predictive models,Dry machining,Process parameters",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Automation & Control Systems,Engineering,Instruments & Instrumentation",,5.317,"SURFACE-TEMPERATURE,EDGE,PREPARATION,ANALYTICAL-MODEL,TOOL,PREDICTION,SPEED,CHIP,PERFORMANCE,GEOMETRY,STEEL",ISA TRANSACTIONS,,
29,Multi-task deep learning for fine-grained classification and grading in breast cancer histopathological images,79,21-22,14509-14528,"Li Lingqiao,Pan Xipeng,Yang Huihua,Liu Zhenbing,He Yubei,Li Zhongming,Fan Yongxian,Cao Zhiwei,Zhang Longhao","Li LQ,Pan XP,Yang HH,Liu ZB,He YB,Li ZM,Fan YX,Cao ZW,Zhang LH",Yang HH,10.1007/s11042-018-6970-9,Beijing University of Posts & Telecommunications,"Fine-grained classification and grading of breast cancer (BC) histopathological images are of great value in clinical application. However, automatic classification and grading of BC histopathological images are complicated by (1) small inter-class variance and large intra-class variance exist in BC histopathological images, and (2) features extracted from similar histopathological images with different magnification are quite different. To address these issues, an improved deep convolution neural network model is proposed and the procedure can be divided into three main stages. Firstly, in the representation learning process, multi-class recognition task and verification task of image pair are combined. Secondly, in the feature extraction process, a prior knowledge is built, which is ""the variances in feature outputs between different subclasses is relatively large while the variance between the same subclass is small."" Additionally, the prior information that histopathological images with different magnification belong to the same subclass are embedded in the feature extraction process, which contributes to less sensitive with image magnification. The experimental results based on three different histopathological image datasets show that the performance of the proposed method is better than state of the art, with better robustness and generalization ability.","Multi-task deep learning,Histopathological image classification,Fine-grained,Convolutional neural network,Breast cancer",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,,MULTIMEDIA TOOLS AND APPLICATIONS,,
30,Discriminative locally linear mapping for medical diagnosis,79,21-22,14573-14591,"He Ping,Chang Xincheng,Xu Xiaohua,Zhang Zhijun,Jing Tianyu,Lou Yuan","He P,Chang XC,Xu XH,Zhang ZJ,Jing TY,Lou Y",Xu XH,10.1007/s11042-018-7064-4,Yangzhou University,"Medical diagnosis based on machine learning has received growing interest in recent years. However, traditional classification algorithms often fail to appropriately deal with medical datasets because of their high dimensionality. Manifold learning is a branch of nonlinear dimension reduction algorithms that can map the high dimensional data into a low-dimensional space. In this paper, we propose a novel manifold-based medical diagnosis algorithm named Discriminative Locally Linear Mapping (DL2M). DL2M is built on the basis of the well-known manifold leaning algorithm LLE (Locally Linear Embedding). It incorporates the discriminative information of training data into the manifold transformation of LLE, and then propagates the discriminative mapping into out-of-sample extension. DL2M is not only advantageous in preserving the local structure of original manifold, but also maps the different classes of data as far as possible in the low-dimensional feature space. The time complexity of DL2M algorithm is also discussed. Sufficient experimental results demonstrate that our method exhibits promising classification performance on the real-world medical datasets.","Medical diagnosis,Manifold learning,Classification,Locally linear embedding,Out-of-sample extension",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"GEODESIC,PROPAGATION",MULTIMEDIA TOOLS AND APPLICATIONS,,
31,Diabetic retinopathy detection through artificial intelligent techniques: a review and open issues,79,21-22,15209-15252,"Ishtiaq Uzair,Kareem Sameem Abdul,Abdullah Erma Rahayu Mohd Faizal,Mujtaba Ghulam,Jahangir Rashid,Ghafoor Hafiz Yasir","Ishtiaq U,Kareem SA,Abdullah ERMF,Mujtaba G,Jahangir R,Ghafoor HY",Kareem SA,10.1007/s11042-018-7044-8,Universiti Malaya,"Diabetic Retinopathy (DR) is the disease caused by uncontrolled diabetes that may lead to blindness among the patients. Due to the advancements in artificial intelligence, early detection of DR through an automated system is more beneficial over the manual detection. At present, there are several published studies on automated DR detection systems through machine learning or deep learning approaches. This study presents a review on DR detection techniques from five different aspects namely, datasets, image preprocessing techniques, machine learning-based approaches, deep learning-based approaches, and performance measures. Moreover, it also presents the authors' observation and significance of the review findings. Furthermore, we also discuss nine new research challenges in DR detection. After a rigorous selection process, 74 primary publications were selected from eight academic databases for this review. From the selected studies, it was observed that many public datasets are available in the field of DR detection. In image preprocessing techniques, contrast enhancement combined with green channel extraction contributed the most in classification accuracy. In features, shape-based, texture-based and statistical features were reported as the most discriminative in DR detection. The Artificial Neural Network was proven eminent classifier compared to other machine learning classifiers. In deep learning, Convolutional Neural Network outperformed compared to other deep learning networks. Finally, to measure the classification performance, accuracy, sensitivity, and specificity metrics were mostly employed. This review presents a comprehensive summary of DR detection techniques and will be proven useful for the community of scientists working in the field of automated DR detection techniques.","Diabetic retinopathy,Convolutional neural network,DIARETDB1,Image preprocessing,Artificial neural network,Transfer learning",Review,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"BLOOD-VESSEL,SEGMENTATION,FUNDUS,IMAGES,NEURAL-NETWORKS,RETINAL,IMAGES,AUTOMATED,DETECTION,EXUDATES,DETECTION,BRIGHT,LESIONS,SEVERITY,LEVEL,CLASSIFIER,SYSTEM",MULTIMEDIA TOOLS AND APPLICATIONS,,
32,RetoNet: a deep learning architecture for automated retinal ailment detection,79,21-22,15319-15328,Nair Lekha R.,Nair LR,Nair LR,10.1007/s11042-018-7114-y,"Coll Engn, Kallooppara, India.","Researchers are trying to tap the immense potential of big data to revolutionize all aspects of societal activity and to assist in having well informed decisions. Healthcare being one such field where proper analytics of available big medical data can lead to early detection and treatment of many ailments. Machine learning played a significant role in the design of automated diagnostic systems and today we have deep learning models in this arena which are outperforming human expertise in terms of predictive accuracy. This paper proposes RetoNet, a convolutional neural network architecture, which is trained and optimized to detect retinal ailment from fundus images with pronounced accuracy and its performance is also proven to be superior to a transfer learning based model developed for the same. Deep learning based e-diagnostic system can be an accurate, cost effective and convenient solution for the shortage of expertise on demand in the healthcare field.","Deep learning,ANN,Convolutional neural network,E-health,Retinal disease detection",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"NEURAL-NETWORKS,RETINOPATHY,SEGMENTATION,DRUSEN",MULTIMEDIA TOOLS AND APPLICATIONS,,
33,Recurrent generative adversarial network for learning imbalanced medical image semantic segmentation,79,21-22,15329-15348,"Rezaei Mina,Yang Haojin,Meinel Christoph","Rezaei M,Yang HJ,Meinel C",Rezaei M,10.1007/s11042-019-7305-1,University of Potsdam,"We propose a new recurrent generative adversarial architecture named RNN-GAN to mitigate imbalance data problem in medical image semantic segmentation where the number of pixels belongs to the desired object are significantly lower than those belonging to the background. A model trained with imbalanced data tends to bias towards healthy data which is not desired in clinical applications and predicted outputs by these networks have high precision and low recall. To mitigate imbalanced training data impact, we train RNN-GAN with proposed complementary segmentation mask, in addition, ordinary segmentation masks. The RNN-GAN consists of two components: a generator and a discriminator. The generator is trained on the sequence of medical images to learn corresponding segmentation label map plus proposed complementary label both at a pixel level, while the discriminator is trained to distinguish a segmentation image coming from the ground truth or from the generator network. Both generator and discriminator substituted with bidirectional LSTM units to enhance temporal consistency and get inter and intra-slice representation of the features. We show evidence that the proposed framework is applicable to different types of medical images of varied sizes. In our experiments on ACDC-2017, HVSMR-2016, and LiTS-2017 benchmarks we find consistently improved results, demonstrating the efficacy of our approach.","Imbalanced medical image semantic segmentation,Recurrent generative adversarial network",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,,MULTIMEDIA TOOLS AND APPLICATIONS,,
34,Detection and classification of pulmonary nodules using deep learning and swarm intelligence,79,21-22,15437-15465,"de Pinho Pinheiro Cesar Affonso,Nedjah Nadia,Mourelle Luiza de Macedo","Pinheiro CAD,Nedjah N,Mourelle LD",Nedjah N,10.1007/s11042-019-7473-z,Universidade do Estado do Rio de Janeiro,"Cancer diagnosis is usually an arduous task in medicine, especially when it comes to pulmonary cancer, which is one of the most deadly and hard to treat types of that disease. Early detecting pulmonary cancerous nodules drastically increases surviving chances but also makes it an even harder problem to solve, as it mostly depends on a visual inspection of tomography scans. In order to help improving cancer detection and surviving rates, engineers and scientists have been developing computer-aided diagnosis systems, similar to the one presented in this paper. These systems are used as second opinions, to help health professionals during the diagnosis of numerous diseases. This work uses computational intelligence techniques to propose a new approach towards solving the problem of detecting pulmonary carcinogenic nodules in computed tomography scans. The applied technology consists of using Deep Learning and Swarm Intelligence to develop different nodule detection and classification models. We exploit seven different swarm intelligence algorithms and convolutional neural networks, prepared for biomedical image segmentation, to find and classify cancerous pulmonary nodules in the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) databases. The aim of this work is to use swarm intelligence to train convolutional neural networks and verify whether this approach brings more efficiency than the classic training algorithms, such as back-propagation and gradient descent methods. As main contribution, this work confirms the superiority of swarm-trained models over the back-propagation-based model for this application, as three out of the seven algorithms are proved to be superior regarding all four performance metrics, which are accuracy, precision, sensitivity, and specificity, as well as training time, where the best swarm-trained model operates 25% faster than the back-propagation model. The performed experiments show that the developed models can achieve up to 93.71% accuracy, 93.53% precision, 92.96% sensitivity, and 98.52% specificity.","Deep learning,Swarm intelligence,Nodule detection,Convolutional neural networks",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"ALGORITHM,OPTIMIZATION,ABC",MULTIMEDIA TOOLS AND APPLICATIONS,,
35,Breast Cancer Multi-classification through Deep Neural Network and Hierarchical Classification Approach,79,21-22,15481-15511,"Murtaza Ghulam,Shuib Liyana,Mujtaba Ghulam,Raza Ghulam","Murtaza G,Shuib L,Mujtaba G,Raza G",Murtaza G; Shuib L,10.1007/s11042-019-7525-4,Universiti Malaya,"Breast cancer (BC) is the third leading cause of deaths in women globally. In general, histopathology images are recommended for early diagnosis and detailed analysis for BC. Thus, state-of-the-art classification models are required for the early prediction of BC using histopathology images. This study aims to develop an accurate and computationally feasible classification model named Biopsy Microscopic Image Cancer Network (BMIC_Net) to classify BC into eight distinct subtypes through deep learning (DL) and hierarchical classification approach. For experiments, the publicly available dataset BreakHis is used and splitted into training and testing set. Furthermore, data augmentation was performed on training set only and 4096 result-oriented features were extracted through DL. In order to improve the classification performance, feature reduction schemes were experimented to elicit the most discriminative feature subset. Finally, six machine-learning algorithms were analyzed to acquire the best results. The experimental results revealed that BMIC_Net outperformed existing baseline models by obtaining the highest accuracy of 95.48% for first-level classifier and 94.62% and 92.45% for second-level classifiers. Thus, this model can be deployed on a normal desktop machine in any healthcare center of less privileged areas in under-developing countries to serve as second opinion for breast cancer classification.","Breast Cancer,Deep Learning and Transfer Learning,Hierarchical Classification,Histopathology Images,Image Classification,Convolutional Neural Network",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"MAMMOGRAMS,DIAGNOSIS,MASSES",MULTIMEDIA TOOLS AND APPLICATIONS,,
36,Transfer learning with pre-trained deep convolutional neural networks for serous cell classification,79,21-22,15593-15611,"Baykal Elif,Dogan Hulya,Ercin Mustafa Emre,Ersoz Safak,Ekinci Murat","Baykal E,Dogan H,Ercin ME,Ersoz S,Ekinci M",Baykal E,10.1007/s11042-019-07821-9,Karadeniz Technical University,"Serous effusion is a condition of excess accumulation of fluids in serous cavities due to different underlying pathological conditions. The basis of cytopathological assessment of serous effusions is the identification of cells in the fluid based on their morphology and texture. This assessment is a physically and mentally laborious task, and it can also lead to variability among pathologists. In literature, only a small number of feature-based methods are conducted for automated serous cell classification. In this study, a transfer learning with pre-trained deep convolutional neural networks (ConvNets) is proposed to automatically identify 11 different categories of serous cells in effusion cytology. Unlike the methods which rely on the extraction of cellular features such as morphology and texture, this method is an appearance-based machine learning approach. We fine-tuned four pre-trained ConvNet architectures that are AlexNet, GoogleNet, ResNet and DenseNet on the serous cell dataset. To reduce the overfitting effect, we augmented the data by image rotation, translation, and mirroring. The proposed method was evaluated on both original and augmented sets of serous cells derived from a publicly available dataset. Among the four ConvNet models, ResNet and DenseNet obtained the highest accuracies of 93.44% and 92.90%. However, when two models were compared in terms of accuracy and model complexity, ResNet-TL was selected as the best network model. When compared to the results without data augmentation, data augmentation increased the accuracy rate approximately 10%. Results show that higher classification results were achieved than other traditional methods without requiring precise segmentation.","Serous effusion,Cytopathological assessment,Cell classification,Convolutional neural networks,Transfer learning",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,GRAPH,MULTIMEDIA TOOLS AND APPLICATIONS,,
37,Improving detection of Melanoma and Naevus with deep neural networks,79,21-22,15635-15654,"Maiti Ananjan,Chatterjee Biswajoy","Maiti A,Chatterjee B",Maiti A,10.1007/s11042-019-07814-8,"Techno India Coll Technol, Dept Informat Technol, Kolkata, India.","Machines can acknowledge the images of skin lesion as well as the disease compared to an experienced dermatologist. These might be executed by giving a proper label for the provided images of skin lesion. Within the proposed study researchers have examined various frameworks for detection of skin cancer as well as classification of melanoma. The current research includes a unique image pre-processing technique and modification of the image followed by image segmentation. The 23 texture and ten shape features of the dataset are further refined with feature engineering techniques. The improved dataset has been processed inside a Deep Neural Network models by binary cross-entropy. The dataset passes through several mixes of multiple activation layers with varying features and optimization techniques. As an outcome of the study, researchers have selected a useful, timesaving model to find an image as melanoma or even naevus. The model was evaluated with 170 images of MED NODE and 2000 images of ISIC dataset. This improved framework achieves a favorable accuracy of 96.8% with few noticeable epochs which concern other 12 machine learning models and five deep learning models. In the future, certainly there can be an investigation with several classes of skin cancer with an improved dataset.","Melanoma classification,Image preprocessing,Feature engineering,Segmentation,Artificial intelligence,Deep neural network",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"PARALLEL,FRAMEWORK,IMAGES",MULTIMEDIA TOOLS AND APPLICATIONS,,
38,DFU_QUTNet: diabetic foot ulcer classification using novel deep convolutional neural network,79,21-22,15655-15677,"Alzubaidi Laith,Fadhel Mohammed A.,Oleiwi Sameer R.,Al-Shamma Omran,Zhang Jinglan","Alzubaidi L,Fadhel MA,Oleiwi SR,Al-Shamma O,Zhang JL",Alzubaidi L,10.1007/s11042-019-07820-w,Queensland University of Technology (QUT),"Diabetic Foot Ulcer (DFU) is the main complication of Diabetes, which, if not properly treated, may lead to amputation. One of the approaches of DFU treatment depends on the attentiveness of clinicians and patients. This treatment approach has drawbacks such as the high cost of the diagnosis as well as the length of treatment. Although this approach gives powerful results, the need for a remote, cost-effective, and convenient DFU diagnosis approach is urgent. In this paper, we introduce a new dataset of 754-ft images which contain healthy skin and skin with a diabetic ulcer from different patients. A novel Deep Convolutional Neural Network, DFU_QUTNet, is also proposed for the automatic classification of normal skin (healthy skin) class versus abnormal skin (DFU) class. Stacking more layers to a traditional Convolutional Neural Network to make it very deep does not lead to better performance, instead leading to worse performance due to the gradient. Therefore, our proposed DFU_QUTNet network is designed based on the idea of increasing the width of the network while keeping the depth compared to the state-of-the-art networks. Our network has been proven to be very beneficial for gradient propagation, as the error can be back-propagated through multiple paths. It also helps to combine different levels of features at each step of the network. Features extracted by DFU_QUTNet network are used to train Support Vector Machine (SVM) and K-Nearest Neighbors (KNN) classifiers. For the sake of comparison, we have fine-tuned then re-trained and tested three pre-trained deep learning networks (GoogleNet, VGG16, and AlexNet) for the same task. The proposed DFU_QUTNet network outperformed the state-of-the-art CNN networks by achieving the F1-score of 94.5%.","Diabetic foot ulcers,Convolutional neural networks,Deep learning,Classification,Transfer learning",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"IMAGES,INFECTION,RISK",MULTIMEDIA TOOLS AND APPLICATIONS,,
39,Hearing loss detection by discrete wavelet transform and multi-layer perceptron trained by nature-inspired algorithms,79,21-22,15717-15745,"Yang Jingyuan,Govindaraj Vishnu Varthanan,Yang Ming,Wang Shui-Hua","Yang JY,Govindaraj VV,Yang M,Wang SH",Govindaraj VV,10.1007/s11042-019-08344-z,Kalasalingam Academy of Research & Education,"(Aim) For detecting the hearing loss (HL) more accurately and efficiently, the new computer-aid diagnosis (CAD) based on a nature-inspired algorithm (NIAs) is proposed in this study. (Method) First, the discrete wavelet transform (DWT) is used for extracting texture features from the brain images, and then the principle component analysis (PCA) is employed to decrease the dimension of features. Second, the Multi-Layer Perceptron (MLP) is used as a classifier. Traditional gradient-based descent algorithms are vulnerable to get struck at local minima; thus, the NIAs are introduced. The differential evolution algorithm (DE), particle swarm optimization (PSO), artificial bee colony algorithm (ABC), and improved ABC (IABC) are employed to train MLP. Because the ordinary ABC is good at exploration but gives a poor performance at exploitation, therefore a new model of ABC, called IABC is proposed. The K-fold validation method is utilized to measure the performance of the CAD. (Result) To verify the performance of our method, The CAD based on IABC is compared with state-of-the-art-approaches. (Conclusion) The experiment results show that the overall accuracy of our method has the highest overall accuracy among five approaches. Therefore, the proposed CAD is effective method for detecting hearing loss.","Hearing loss,Computer-aid diagnosis,Discrete wavelet transform,Multi-layer perceptron,Nature-inspired algorithms,Improved artificial bee Colony algorithm,K-fold cross validation",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"NEURAL-NETWORK,CLASSIFICATION,OPTIMIZATION,MACHINE,IMAGE",MULTIMEDIA TOOLS AND APPLICATIONS,,
40,Prediction of fresh and hardened properties of self-compacting concrete using support vector regression approach,32,12,7995-8010,"Saha Prasenjit,Debnath Prasenjit,Thomas Paul","Saha P,Debnath P,Thomas P",Saha P,10.1007/s00521-019-04267-w,National Institute of Technology (NIT System),"This article presents the feasibility of using support vector regression (SVR) technique to determine the fresh and hardened properties of self-compacting concrete. Two different kernel functions, namely exponential radial basis function (ERBF) and radial basis function (RBF), were used to develop the SVR model. An experimental database of 115 data samples was collected from different literatures to develop the SVR model. The data used in SVR model have been organized in the form of six input parameters that covers dosage of binder content, fly ash, water-powder ratio, fine aggregate, coarse aggregate and superplasticiser. The above-mentioned ingredients have been taken as input variables, whereas slump flow value, L-box ratio, V-funnel time and compressive strength have been considered as output variables. The obtained results indicate that the SVR-ERBF model outperforms SVR-RBF model for learning and predicting the experimental data with the highest value of the coefficient of correlation (R) equal to 0.965, 0.954, 0.979 and 0.9773 for slump flow, L-box ratio, V-funnel and compressive strength, respectively, with small values of statistical errors. Also, the efficiency of SVR model is compared to artificial neural network (ANN) and multivariable regression analysis (MVR). In addition, a sensitivity analysis was also carried out to determine the effects of various input parameters on output. This study indicates that SVR-ERBF model can be used as an alternative approach in predicting the properties of self-compacting concrete.","Support vector regression,Kernel functions,Self-compacting concrete,Compressive strength",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"ARTIFICIAL,NEURAL-NETWORK,HIGH-STRENGTH,CONCRETE,COMPRESSIVE,STRENGTH,SILICA,FUME,FLY-ASH,MECHANICAL-PROPERTIES,ELASTIC-MODULUS,MACHINE,MODELS,GEOPOLYMERS",NEURAL COMPUTING & APPLICATIONS,,
41,Combining functional near-infrared spectroscopy and EEG measurements for the diagnosis of attention-deficit hyperactivity disorder,32,12,8367-8380,"Guven Aysegul,Altinkaynak Miray,Dolu Nazan,Izzetoglu Meltem,Pektas Ferhat,Ozmen Sevgi,Demirci Esra,Batbat Turgay","Guven A,Altinkaynak M,Dolu N,Izzetoglu M,Pektas F,Ozmen S,Demirci E,Batbat T",Guven A,10.1007/s00521-019-04294-7,Erciyes University,"Recently multimodal neuroimaging which combines signals from different brain modalities has started to be considered as a potential to improve the accuracy of diagnosis. The current study aimed to explore a new method for discriminating attention-deficit hyperactivity disorder (ADHD) patients and control group by means of simultaneous measurement of electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS). Twenty-three pre-medicated combined type ADHD children and 21 healthy children were included in the study. Nonlinear brain dynamics of subjects were obtained from EEG signal using Higuchi fractal dimensions and Lempel-Ziv complexity, latency and amplitude values of P3 wave obtained from auditory evoked potentials and frontal cortex hemodynamic responses calculated from fNIRS. Lower complexity values, prolonged P3 latency and reduced P3 amplitude values were found in ADHD children. fNIRS indicated that the control subjects exhibited higher right prefrontal activation than ADHD children. Features are analyzed, looking for the best classification accuracy and finally machine learning techniques, namely Support Vector Machines, Naive Bayes and Multilayer Perception Neural Network, are introduced for EEG signals alone and for combination of fNIRS and EEG signals. Naive Bayes provided the best classification with an accuracy rate of 79.54% and 93.18%, using EEG and EEG-fNIRS systems, respectively. Our findings demonstrate that utilization of information by combining features obtained from fNIRS and EEG improves the classification accuracy. As a conclusion, our method has indicated that EEG-fNIRS multimodal neuroimaging is a promising method for ADHD objective diagnosis.","Attention-deficit hyperactivity disorder,Electroencephalography,Functional near-infrared spectroscopy,Multimodal neuroimaging",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"MEDICATION-NAIVE,ADOLESCENTS,VISUAL,SELECTIVE,ATTENTION,LATERAL,PREFRONTAL,CORTEX,DEFICIT%2FHYPERACTIVITY,DISORDER,ADHD,CHILDREN,HEMODYNAMIC-RESPONSE,STROOP,INTERFERENCE,COMPLEXITY,ANALYSIS,INTEGRATIVE,THEORY,FRACTAL,DIMENSION",NEURAL COMPUTING & APPLICATIONS,,
42,Modeling the activity coefficient at infinite dilution of water in ionic liquids using artificial neural networks and support vector machines,32,12,8635-8653,"Benimam Hania,Si-Moussa Cherif,Laidi Maamar,Hanini Salah","Benimam H,Si-Moussa C,Laidi M,Hanini S",Laidi M,10.1007/s00521-019-04356-w,Universite Yahia Fares Medea,"The activity coefficient at infinite dilution of water in ionic liquids is a thermodynamic property of a paramount importance in separation processes. However, accurate modeling of this parameter remains a challenging task due to the highly nonlinear behavior of the water/ionic liquid systems. Also, available models consider a large number of inputs that are usually difficult to access and require complicated use techniques. Therefore, the main objective of this paper is to use artificial intelligence techniques to propose models (based on a reduced number of inputs that are easily accessible, and to improve the accuracy of the correlative performance for activity coefficient at infinite dilution of water in ILs). The present work features the application of artificial neural networks, support vector machine and least square support vector machine, among data-driven methods, for modeling the activity coefficient at infinite dilution of water in 53 ionic liquids. Overall, the models proposed are able to accurately correlate 318 experimental data points gathered from the literature. According to the results, the ANN is more powerful and effective computational learning machine than the two remaining ones. The correlation coefficientsR(2)and deviations expressed as an average absolute relative deviation for the neural network model are estimated to be 0.99997 and 0.56%, respectively. Furthermore, the neural network model's interpolation and extrapolation capabilities are demonstrated, and its accuracy is compared to other proposed models in the literature based on multi-linear regression, least squares support vector machine and another feedforward neural network. This work also includes a graphical user interface for the proposed model, as well as an inputs' sensitivity analysis.","Activity coefficient,Ionic liquids,Artificial neural networks,Support vector machine,Least square support vector machine,Infinite dilution",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"SUPERCRITICAL,CARBON-DIOXIDE,ORGANIC,SOLUTES,COSMO-RS,PHYSICOCHEMICAL,PROPERTIES,SOLVENT,MIXTURES,BINARY-SYSTEMS,PREDICTION,SOLUBILITY,TOXICITY,QSAR",NEURAL COMPUTING & APPLICATIONS,,
43,Machine Learning Classification of Articular Cartilage Integrity Using Near Infrared Spectroscopy,13,3,219-228,"Afara Isaac O.,Sarin Jaakko K.,Ojanen Simo,Finnila Mikko A. J.,Herzog Walter,Saarakkala Simo,Korhonen Rami K.,Toyras Juha","Afara IO,Sarin JK,Ojanen S,Finnila MAJ,Herzog W,Saarakkala S,Korhonen RK,Toyras J",Afara IO,10.1007/s12195-020-00612-5,University of Eastern Finland,"Introduction Assessment of cartilage integrity during arthroscopy is limited by the subjective visual nature of the technique. To address this shortcoming in diagnostic evaluation of articular cartilage, near infrared spectroscopy (NIRS) has been proposed. In this study, we evaluated the capacity of NIRS, combined with machine learning techniques, to classify cartilage integrity. Methods Rabbit (n = 14) knee joints with artificial injury, induced via unilateral anterior cruciate ligament transection (ACLT), and the corresponding contra-lateral (CL) joints, including joints from separate non-operated control (CNTRL) animals (n = 8), were used. After sacrifice, NIR spectra (1000-2500 nm) were acquired from different anatomical locations of the joints (n(TOTAL) = 313: n(CNTRL) = 111, n(CL) = 97, n(ACLT) = 105). Machine and deep learning methods (support vector machines-SVM, logistic regression-LR, and deep neural networks-DNN) were then used to develop models for classifying the samples based solely on their NIR spectra. Results The results show that the model based on SVM is optimal of distinguishing between ACLT and CNTRL samples (ROC_AUC = 0.93, kappa = 0.86), LR is capable of distinguishing between CL and CNTRL samples (ROC_AUC = 0.91, kappa = 0.81), while DNN is optimal for discriminating between the different classes (multi-class classification, kappa = 0.48). Conclusion We show that NIR spectroscopy, when combined with machine learning techniques, is capable of holistic assessment of cartilage integrity, with potential for accurately distinguishing between healthy and diseased cartilage.","Osteoarthritis,Cartilage,Near infrared spectroscopy,Machine learning,Deep learning,Classification",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Cell Biology,Biophysics,Engineering",,2.935,"NIR,SPECTROSCOPY,DEFECTS,SCORE",CELLULAR AND MOLECULAR BIOENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7225230,
44,Semi-supervised segmentation of lesion from breast ultrasound images with attentional generative adversarial network,189,,,"Han Luyi,Huang Yunzhi,Dou Haoran,Wang Shuai,Ahamad Sahar,Luo Honghao,Liu Qi,Fan Jingfan,Zhang Jiang","Han LY,Huang YZ,Dou HR,Wang S,Ahamad S,Luo HH,Liu Q,Fan JF,Zhang J",Huang YZ,10.1016/j.cmpb.2019.105275,Sichuan University,"Background and objective: Automatic segmentation of breast lesion from ultrasound images is a crucial module for the computer aided diagnostic systems in clinical practice. Large-scale breast ultrasound (BUS) images remain unannotated and need to be effectively explored to improve the segmentation quality. To address this, a semi-supervised segmentation network is proposed based on generative adversarial networks (GAN).
Methods: In this paper, a semi-supervised learning model, denoted as BUS-GAN, consisting of a segmentation base network-BUS-S and an evaluation base network-BUS-E, is proposed. The BUS-S network can densely extract multi-scale features in order to accommodate the individual variance of breast lesion, thereby enhancing the robustness of segmentation. Besides, the BUS-E network adopts a dual-attentive-fusion block having two independent spatial attention paths on the predicted segmentation map and leverages the corresponding original image to distill geometrical-level and intensity-level information, respectively, so that to enlarge the difference between lesion region and background, thus improving the discriminative ability of the BUS-E network. Then, through adversarial training, the BUS-GAN model can achieve higher segmentation quality because the BUS-E network guides the BUS-S network to generate more accurate segmentation maps with more similar distribution as ground truth.
Results: The counterpart semi-supervised segmentation methods and the proposed BUS-GAN model were trained with 2000 in-house images, including 100 annotated images and 1900 unannotated images, and tested on two different sites, including 800 in-house images and 163 public images. The results validate that the proposed BUS-GAN model can achieve higher segmentation accuracy on both the in-house testing dataset and the public dataset than state-of-the-art semi-supervised segmentation methods.
Conclusions: The developed BUS-GAN model can effectively utilize the unannotated breast ultrasound images to improve the segmentation quality. In the future, the proposed segmentation method can be a potential module for the automatic breast ultrasound diagnose system, thus relieving the burden of a tedious image annotation process and alleviating the subjective influence of physicians' experiences in clinical practice. Our code will be made available on https://github.com/fiy2W/BUS-GAN. (C) 2019 Elsevier B.V. All rights reserved.","Ultrasound image,Breast lesion,Image segmentation,Semi-supervised learning,Generative adversarial networks,Attention mechanism",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,DIAGNOSIS,COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
45,A survey on machine and statistical learning for longitudinal analysis of neuroimaging data in Alzheimer's disease,189,,,"Marti-Juan Gerard,Sanroma-Guell Gerard,Piella Gemma","Marti-Juan G,Sanroma-Guell G,Piella G",Marti-Juan G,10.1016/j.cmpb.2020.105348,Pompeu Fabra University,"Background and Objectives: Recently, longitudinal studies of Alzheimer's disease have gathered a substantial amount of neuroimaging data. New methods are needed to successfully leverage and distill meaningful information on the progression of the disease from the deluge of available data. Machine learning has been used successfully for many different tasks, including neuroimaging related problems. In this paper, we review recent statistical and machine learning applications in Alzheimer's disease using longitudinal neuroimaging. Methods: We search for papers using longitudinal imaging data, focused on Alzheimer's Disease and published between 2007 and 2019 on four different search engines. Results: After the search, we obtain 104 relevant papers. We analyze their approach to typical challenges in longitudinal data analysis, such as missing data and variability in the number and extent of acquisitions. Conclusions: Reviewed works show that machine learning methods using longitudinal data have potential for disease progression modelling and computer-aided diagnosis. We compare results and models, and propose future research directions in the field. (C) 2020 Elsevier B.V. All rights reserved.","Longitudinal,Disease progression,Alzheimer's disease,Machine learning",Review,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"MILD,COGNITIVE,IMPAIRMENT,AMYLOID-BETA,BASE-LINE,FDG-PET,CONVERSION,PREDICTION,CEREBROSPINAL-FLUID,HYPOTHETICAL,MODEL,GLOBAL,PREVALENCE,BIOMARKER,CHANGES,BRAIN,ATROPHY",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,http://repositori.upf.edu/bitstream/10230/45480/1/marti_cmpb_survey.pdf,
46,Enhanced visuomotor learning and generalization in expert surgeons,71,,,"Hewitson Christopher L.,Crossley Matthew J.,Kaplan David M.","Hewitson CL,Crossley MJ,Kaplan DM",Kaplan DM,10.1016/j.humov.2020.102621,Macquarie University,"Although human motor learning has been intensively studied for many decades, it remains unknown whether group differences are present in expert cohorts that must routinely cope with and learn new visuomotor mappings such as expert minimally invasive surgeons. We found that expert surgeons compensate for a visuomotor perturbation more rapidly than naive controls. Modelling indicates that these differences in expert behavioural performance reflects greater trial-to-trial retention, as opposed to greater trial-to-trial learning rate. We also found that surgeons generalize to novel reach directions more broadly than controls, a result which was subsequently confirmed by our modelling. In general, our findings show that minimally invasive surgeons exhibit enhanced visuomotor learning and spatial generalization.","Visuomotor adaptation,Sensorimotor learning,Generalization,Experts,Surgery,Minimally invasive surgery",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Neurosciences & Neurology,Psychology,Sport Sciences",,2.644,"SPATIAL,WORKING-MEMORY,MOTOR,VARIABILITY,INTERNAL-MODELS,VIDEO,GAMES,ADAPTATION,IMPLICIT,EXPLICIT,AGE,COMBINATION,CURVE",HUMAN MOVEMENT SCIENCE,https://doi.org/10.1101/611012,
47,Comparative analysis among feature selection of sEMG signal for hand gesture classification by armband,18,6,1135-1143,"Mendes J.,Freitas M.,Siqueira H.,Lazzaretti A.,Stevan S.,Pichorim S.","Mendes J,Freitas M,Siqueira H,Lazzaretti A,Stevan S,Pichorim S",Mendes J,10.1109/TLA.2020.9099752,Pontificia Universidade Catolica do Parana,"This work presents a comparative study between dimensionality reduction and feature selection to classification problem for six hand gestures by sEMG signal. The classified signals are wrist flexion, wrist extension, wrist flexion for the left, wrist extension to the right, forearm supination, and forearm pronation. An armband with eight channels was used to acquire the signals from 13 subjects (8 male and 5 female). Then, 29 features from time and frequency domain were extracted. Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), and Support Vector Machine (SVM) were used as classifiers. Regarding the dimensionality reduction, Principal Component Analysis and LDA were applied in the signal; for feature selection, the feature combination for wrapper method step wise forward was used. The best scenario with dimensionality reduction was obtained with QDA classifier and 80 attributes from PCA, reaching accuracies of 84%. In the second scenario, with 112 attributes (8 features), a non-linear SVM (with Gaussian kernel) reached accuracies of 91%. Both methods presented similar performances among the accuracies for each class; however, dimensionality reduction approach presented less computational cost whilst has a lower accuracy compared with feature selection approach.","Feature extraction,Support vector machines,Principal component analysis,Dimensionality reduction,Wrist,Irrigation,IEEE transactions,sEMG,classification,dimensionality reduction,feature selection,armband",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,,"SURFACE,ELECTROMYOGRAPHY,DIMENSIONALITY,REDUCTION,DISCRIMINANT-ANALYSIS",IEEE LATIN AMERICA TRANSACTIONS,,
48,Deep Neural Network for Respiratory Sound Classification in Wearable Devices Enabled by Patient Specific Model Tuning,14,3,535-544,"Acharya Jyotibdha,Basu Arindam","Acharya J,Basu A",Acharya J,10.1109/TBCAS.2020.2981172,Nanyang Technological University & National Institute of Education (NIE) Singapore,"The primary objective of this paper is to build classification models and strategies to identify breathing sound anomalies (wheeze, crackle) for automated diagnosis of respiratory and pulmonary diseases. In this work we propose a deep CNN-RNN model that classifies respiratory sounds based on Mel-spectrograms. We also implement a patient specific model tuning strategy that first screens respiratory patients and then builds patient specific classification models using limited patient data for reliable anomaly detection. Moreover, we devise a local log quantization strategy for model weights to reduce the memory footprint for deployment in memory constrained systems such as wearable devices. The proposed hybrid CNN-RNN model achieves a score of 66.31% on four-class classification of breathing cycles for ICBHI'17 scientific challenge respiratory sound database. When the model is re-trained with patient specific data, it produces a score of 71.81% for leave-one-out validation. The proposed weight quantization technique achieves approximate to 4x reduction in total memory cost without loss of performance. The main contribution of the paper is as follows: Firstly, the proposed model is able to achieve state of the art score on the ICBHI'17 dataset. Secondly, deep learning models are shown to successfully learn domain specific knowledge when pre-trained with breathing data and produce significantly superior performance compared to generalized models. Finally, local log quantization of trained weights is shown to be able to reduce the memory requirement significantly. This type of patient-specific re-training strategy can be very useful in developing reliable long-term automated patient monitoring systems particularly in wearable healthcare solutions.","Data models,Biological system modeling,Deep learning,Quantization (signal),Feature extraction,Training,Diseases,CNN,LSTM,patient specific model,respiratory audio analysis,weight quantization",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,RECOGNITION,IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,http://arxiv.org/pdf/2004.08287,
49,Deep Neural Oracles for Short-Window Optimized Compressed Sensing of Biosignals,14,3,545-557,"Mangia Mauro,Prono Luciano,Marchioni Alex,Pareschi Fabio,Rovatti Riccardo,Setti Gianluca","Mangia M,Prono L,Marchioni A,Pareschi F,Rovatti R,Setti G",Mangia M,10.1109/TBCAS.2020.2982824,University of Bologna,"The recovery of sparse signals given their linear mapping on lower-dimensional spaces can be partitioned into a support estimation phase and a coefficient estimation phase. We propose to estimate the support with an oracle based on a deep neural network trained jointly with the linear mapping at the encoder. The divination of the oracle is then used to estimate the coefficients by pseudo-inversion. This architecture allows the definition of an encoding-decoding scheme with state-of-the-art recovery capabilities when applied to biological signals such as ECG and EEG, thus allowing extremely low-complex encoders. As an additional feature, oracle-based recovery is able to self-assess, by indicating with remarkable accuracy chunks of signals that may have been reconstructed with a non-satisfactory quality. This self-assessment capability is unique in the CS literature and paves the way for further improvements depending on the requirements of the specific application. As an example, our scheme is able to satisfyingly compress by a factor of 2.67 an ECG or EEG signal with a complexity equivalent to only 24 signed sums per processed sample.","Image reconstruction,Decoding,Estimation,Electrocardiography,Electroencephalography,Complexity theory,Neural networks,Biosignal compression,compressed sensing,deep neural networks,low-complexity compression",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,"SIGNAL,RECOVERY,ECG,EFFICIENT,PROJECTIONS",IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,,
50,eBreCaP: extreme learning-based model for breast cancer survival prediction,14,3,160-169,"Dhillon Arwinder,Singh Ashima","Dhillon A,Singh A",Dhillon A,10.1049/iet-syb.2019.0087,Thapar Institute of Engineering & Technology,"Breast cancer is the second leading cause of death in the world. Breast cancer research is focused towards its early prediction, diagnosis, and prognosis. Breast cancer can be predicted on omics profiles, clinical tests, and pathological images. The omics profiles comprise of genomic, proteomic, and transcriptomic profiles that are available as high-dimensional datasets. Survival prediction is carried out on omics data to predict early the onset of disease, relapse, reoccurrence of diseases, and biomarker identification. The early prediction of breast cancer is desired for the effective treatment of patients as delay can aggravate the staging of cancer. In this study, extreme learning machine (ELM) based model for breast cancer survival prediction named eBreCaP is proposed. It integrates the genomic (gene expression, copy number alteration, DNA methylation, protein expression) and pathological image datasets; and trains them using an ensemble of ELM with the six best-chosen models suitable to be applied on integrated data. eBreCaP has been evaluated on nine performance parameters, namely sensitivity, specificity, precision, accuracy, Matthews correlation coefficient, area under curve, area under precision-recall, hazard ratio, and concordance Index. eBreCaP has achieved an accuracy of 85% for early breast cancer survival prediction using the ensemble of ELM with gradient boosting.","proteins,learning (artificial intelligence),patient treatment,proteomics,DNA,genetics,medical image processing,genomics,cancer,biochemistry,extreme learning-based model,breast cancer research,omics profiles,genomic profiles,transcriptomic profiles,extreme learning machine based model,early breast cancer survival prediction,proteomic profiles,clinical tests,high-dimensional datasets,diseases,gene expression,copy number alteration,DNA methylation,protein expression,pathological image datasets,Matthews correlation coefficient,area under curve,concordance Index,gradient boosting",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND","Cell Biology,Mathematical & Computational Biology",,1.491,"GENE-EXPRESSION,FEATURE-SELECTION,NETWORKS",IET SYSTEMS BIOLOGY,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-syb.2019.0087,
51,Evaluation framework for automatic privacy auditing tools for hospital data breach detections: A case study,138,,,"Yesmin Tahera,Carter Michael W.","Yesmin T,Carter MW",Carter MW,10.1016/j.ijmedinf.2020.104123,University of Toronto,"Objective: We aim to 1) design an evaluation framework to examine the accuracy of automatic privacy auditing tools, 2) apply the evaluation method at a hospital to validate the performance of an auditing tool that uses a machine learning algorithm to automate user access auditing, and 3) recommend further improvements in auditing for the hospital.
Materials and methods: Using the black box method of user acceptance testing, we have designed an evaluation framework consisting of appropriate and inappropriate behaviour scenarios to examine the privacy auditing tools. The scenarios were designed from clinical and non-clinical hospital staff perspective, taking expert opinions from the privacy officers and considering examples from the Information and Privacy Commission (IPC) and were tested using Mackenzie Richmond Hill Hospital's data.
Results: The case study using this evaluation framework found that on average 98.09 % of total accesses of the hospital were identified as appropriate and the tool was unable to explain the remaining 1.91 % of accesses. In addition, a statistically significant (P < 0.05) increasing trend on categorizing appropriate accesses by the tool have been observed. Furthermore, an analysis of unexplained accesses revealed the contributing factors and found issues related to hospital workflows and data quality (information was missing about staff roles and departments).
Conclusion: Given that adoption of these machine learning tools is increasing in hospitals, this research provides an evaluation framework and an empirical evidence on the effectiveness of automated privacy auditing and detecting anomalies for dynamic hospital workflows.","Privacy auditing,Hospital data breach,Inappropriate accesses,Machine learning,Evaluation framework",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Health Care Sciences & Services,Medical Informatics",,4.768,"ELECTRONIC,HEALTH,RECORDS,CARE,SECURITY,ACCESS",INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS,,
52,Developing an improved crystal graph convolutional neural network framework for accelerated materials discovery,4,6,,"Park Cheol Woo,Wolverton Chris","Park CW,Wolverton C",Wolverton C,10.1103/PhysRevMaterials.4.063801,Northwestern University,"The recently proposed crystal graph convolutional neural network (CGCNN) offers a highly versatile and accurate machine learning (ML) framework by learning material properties directly from graphlike representations of crystal structures (""crystal graphs""). Here, we develop an improved variant of the CGCNN model (iCGCNN) that outperforms the original by incorporating information of the Voronoi tessellated crystal structure, explicit three-body correlations of neighboring constituent atoms, and an optimized chemical representation of interatomic bonds in the crystal graphs. We demonstrate the accuracy of the improved framework in two distinct illustrations: First, when trained/validated on 180 000/20 000 density functional theory (DFT) calculated thermodynamic stability entries taken from the Open Quantum Materials Database (OQMD) and evaluated on a separate test set of 230 000 entries, iCGCNN achieves a predictive accuracy that is significantly improved, i.e., 20% higher than that of the original CGCNN. Second, when used to assist a high-throughput search for materials in the ThCr2Si2 structure-type, iCGCNN exhibited a success rate of 31% which is 155 times higher than an undirected high-throughput search and 2.4 times higher than that of the original CGCNN. Using both CGCNN and iCGCNN, we screened 132 600 compounds with elemental decorations of the ThCr2Si2 prototype crystal structure and identified a total of 97 unique stable compounds by performing 757 DFT calculations, accelerating the computational time of the high-throughput search by a factor of 65. Our results suggest that the iCGCNN can be used to accelerate high-throughput discoveries of new materials by quickly and accurately identifying crystalline compounds with properties of interest.","MACHINE,ROBUST",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Materials Science,,4.034,"MACHINE,ROBUST",PHYSICAL REVIEW MATERIALS,http://arxiv.org/pdf/1906.05267,
53,The Use of Random Forests to Identify Brain Regions on Amyloid and FDG PET Associated With MoCA Score,45,6,427-433,"Zukotynski Katherine,Gaudet Vincent,Kuo Phillip H.,Adamo Sabrina,Goubran Maged,Scott Christopher J. M.,Bocti Christian,Borrie Michael,Chertkow Howard,Frayne Richard","Zukotynski K,Gaudet V,Kuo PH,Adamo S,Goubran M,Scott CJM,Bocti C,Borrie M,Chertkow H,Frayne R",Zukotynski K,10.1097/RLU.0000000000003043,McMaster University,"Purpose The aim of this study was to evaluate random forests (RFs) to identify ROIs on F-18-florbetapir and F-18-FDG PET associated with Montreal Cognitive Assessment (MoCA) score.
Materials and Methods Fifty-seven subjects with significant white matter disease presenting with either transient ischemic attack/lacunar stroke or mild cognitive impairment from early Alzheimer disease, enrolled in a multicenter prospective observational trial, had MoCA and F-18-florbetapir PET; 55 had F-18-FDG PET. Scans were processed using the MINC toolkit to generate SUV ratios, normalized to cerebellar gray matter (F-18-florbetapir PET), or pons (F-18-FDG PET). SUV ratio data and MoCA score were used for supervised training of RFs programmed in MATLAB.
Results F-18-Florbetapir PETs were randomly divided into 40 training and 17 testing scans; 100 RFs of 1000 trees, constructed from a random subset of 16 training scans and 20 ROIs, identified ROIs associated with MoCA score: right posterior cingulate gyrus, right anterior cingulate gyrus, left precuneus, left posterior cingulate gyrus, and right precuneus. Amyloid increased with decreasing MoCA score. F-18-FDG PETs were randomly divided into 40 training and 15 testing scans; 100 RFs of 1000 trees, each tree constructed from a random subset of 16 training scans and 20 ROIs, identified ROIs associated with MoCA score: left fusiform gyrus, left precuneus, left posterior cingulate gyrus, right precuneus, and left middle orbitofrontal gyrus. F-18-FDG decreased with decreasing MoCA score.
Conclusions Random forests help pinpoint clinically relevant ROIs associated with MoCA score; amyloid increased and F-18-FDG decreased with decreasing MoCA score, most significantly in the posterior cingulate gyrus.","amyloid,F-18-FDG,PET,random forest,Montreal Cognitive Assessment score",Article,"LIPPINCOTT WILLIAMS & WILKINS, TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"MONTREAL,COGNITIVE,ASSESSMENT,ALZHEIMERS-DISEASE,DIAGNOSTIC,GUIDELINES,NATIONAL,INSTITUTE,MRI,MEASURES,IMPAIRMENT,RECOMMENDATIONS,WORKGROUPS,DEMENTIA,VOLUME",CLINICAL NUCLEAR MEDICINE,,
54,Experimental Establishment of Phase Diagrams Guided by Uncertainty Sampling: An Application to the Deposition of Zn-Sn-P Films by Molecular Beam Epitaxy,2,6,571-575,"Katsube Ryoji,Terayama Kei,Tamura Ryo,Nose Yoshitaro","Katsube R,Terayama K,Tamura R,Nose Y",Katsube R; Nose Y,10.1021/acsmaterialslett.0c00104,Kyoto University,"The construction of phase diagrams is an essential step in the development of materials and devices, but this process requires considerable time and the efforts of well-established researchers. Recently, a machine learning method based on uncertainty sampling, phase diagram construction (PDC), was developed in order to minimize the number of required experiments. In the present study, we, for the first time, demonstrate PDC-assisted experimental determination of an uninvestigated phase diagram for the deposition of Zn-Sn-P films by molecular beam epitaxy (MBE). Interestingly, without any background knowledge of materials science, an undetected phase in the initial dataset was detected after only 4 cycles of PDC-assisted experiments, and the phase diagram was sufficiently refined after only 11 cycles. Based on the results and thermodynamic discussions, we confirm the effectiveness of PDC on the construction of phase diagrams for MBE process. The demonstration in this study shows the machine-learning method, PDC, will accelerate discovery and development of materials; furthermore, we discuss how to use PDC more effectively, considering the objectives involved in the construction of phase diagrams.","GROWTH,PHOSPHIDATION,INP",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Materials Science,,8.323,"GROWTH,PHOSPHIDATION,INP",ACS MATERIALS LETTERS,https://pubs.acs.org/doi/pdf/10.1021/acsmaterialslett.0c00104,
55,Prediction of interface and vacancy segregation energies at silver interfaces without determining interface structures,13,6,,"Otani Ryuken,Kiyohara Shin,Shibata Kiyou,Mizoguchi Teruyasu","Otani R,Kiyohara S,Shibata K,Mizoguchi T",Mizoguchi T,10.35848/1882-0786/ab8b6c,University of Tokyo,"Interfaces play a crucial role in determining the functional and mechanical properties of materials. However, predicting interface properties is not straightforward because the atomic arrangements at the interface are different from those in the bulk. Hence, in this study, we discovered a descriptor from the bulk that helps predict the interface properties without the need to determine the interface structure. The descriptors related to the angle of elevation effectively described the structure units on both the bulk surface and optimized interface. Our model successfully predicted the interface and vacancy segregation energies at silver interfaces without using the interface structure.","machine learning,interface,structure property relationship",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,2.77,"THERMOELECTRIC,SEEBECK,COEFFICIENT",APPLIED PHYSICS EXPRESS,https://doi.org/10.35848/1882-0786/ab8b6c,
56,Classification of Aortic Stenosis Using Time-Frequency Features From Chest Cardio-Mechanical Signals,67,6,1672-1683,"Yang Chenxi,Aranoff Nicole D.,Green Philip,Tavassolian Negar","Yang CX,Aranoff ND,Green P,Tavassolian N",Tavassolian N,10.1109/TBME.2019.2942741,Stevens Institute of Technology,"Objectives: This paper introduces a novel method for the detection and classification of aortic stenosis (AS) using the time-frequency features of chest cardio-mechanical signals collected from wearable sensors, namely seismo-cardiogram (SCG) and gyro-cardiogram (GCG) signals. Such a method could potentially monitor high-risk patients out of the clinic. Methods: Experimental measurements were collected from twenty patients with AS and twenty healthy subjects. Firstly, a digital signal processing framework is proposed to extract time-frequency features. The features are then selected via the analysis of variance test. Different combinations of features are evaluated using the decision tree, random forest, and artificial neural network methods. Two classification tasks are conducted. The first task is a binary classification between normal subjects and AS patients. The second task is a multi-class classification of AS patients with co-existing valvular heart diseases. Results: In the binary classification task, the average accuracies achieved are 96.25% from decision tree, 97.43% from random forest, and 95.56% from neural network. The best performance is from combined SCG and GCG features with random forest classifier. In the multi-class classification, the best performance is 92.99% using the random forest classifier and SCG features. Conclusion: The results suggest that the solution could be a feasible method for classifying aortic stenosis, both in the binary and multi-class tasks. It also indicates that most of the important time-frequency features are below 11 Hz.Significance: The proposed method shows great potential to provide continuous monitoring of valvular heart diseases to prevent patients from sudden critical cardiac situations.","Feature extraction,Heart,Diseases,Valves,Time-frequency analysis,Task analysis,Protocols,Aortic stenosis,gyro-cardiography (GCG),machine-learning,MEMS accelerometer,MEMS gyroscope,seismo-cardiography (SCG),signal processing,time-frequency analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"EMPIRICAL,MODE,DECOMPOSITION,CARDIOVASCULAR-DISEASE,HEART-DISEASE,SEISMOCARDIOGRAM",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
57,Training-Free Bayesian Self-Adaptive Classification for sEMG Pattern Recognition Including Motion Transition,67,6,1775-1786,"Park Seongsik,Chung Wan Kyun,Kim Keehoon","Park S,Chung WK,Kim K",Kim K,10.1109/TBME.2019.2947089,Pohang University of Science & Technology (POSTECH),"A direct, ready-to-use surface electromyogram (sEMG) pattern classification algorithm that does not require prerequisite training, regardless of the user, is proposed herein. In addition to data collection, conventional supervised learning approaches for sEMG require labeling and segmenting the data and additional time for the learning algorithm. Consequently, these approaches cannot cope well with sEMG patterns during motion transitions of various movement speeds. The proposed unsupervised and self-adaptive method employs an iterative self-adaptive procedure realized by the probabilistic methods of diffusion, updating, and registration to cluster the activation patterns simultaneously in real time, and classify the current sEMG as new clustered patterns. Experiments demonstrated that even for the same motion, the proposed method could autonomously detect changes in muscular activation patterns varying with the speed of motion. Furthermore, some patterns of both steady- and transient-state motions could be distinguished. In addition, it was verified that the classified sEMG pattern could be correlated consistently with the actual motion, thereby realizing a high level of motion classification.","Supervised learning,Biomedical measurement,Muscles,Transient analysis,Maximum likelihood estimation,Bayes methods,Training,Adaptive learning,Bayesian method,pattern classification,surface electromyogram (sEMG),unsupervised probabilistic method",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"FRAMEWORK,SIGNALS",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
58,Collaborative framework for automatic classification of respiratory sounds,14,4,223-228,Ntalampiras Stavros,Ntalampiras S,Ntalampiras S,10.1049/iet-spr.2019.0487,University of Milan,"There are several diseases (e.g. asthma, pneumonia etc.) affecting the human respiratory apparatus altering its airway path substantially, thus characterising its acoustic properties. This work unfolds an automatic audio signal processing framework achieving classification between normal and abnormal respiratory sounds. Thanks to a recent challenge, a real-world dataset specifically designed to address the needs of the specific problem is available to the scientific community. Unlike previous works in the literature, the authors take advantage of information provided by several stethoscopes simultaneously, i.e. elaborating at the acoustic sensor network level. To this end, they employ two features sets extracted from different domains, i.e. spectral and wavelet. These are modelled by convolutional neural networks, hidden Markov models and Gaussian mixture models. Subsequently, a synergistic scheme is designed operating at the decision level of the best-performing classifier with respect to each stethoscope. Interestingly, such a scheme was able to boost the classification accuracy surpassing the current state of the art as it is able to identify respiratory sound patterns with a 66.7% accuracy.","Gaussian processes,signal classification,hidden Markov models,pattern classification,diseases,feature extraction,audio signal processing,learning (artificial intelligence),pneumodynamics,medical signal processing,convolutional neural nets,acoustic sensor network level,spectral domains,wavelet domains,convolutional neural networks,hidden Markov models,Gaussian mixture models,decision level,stethoscope,classification accuracy,respiratory sound patterns,collaborative framework,automatic classification,diseases,human respiratory apparatus,airway path,acoustic properties,automatic audio signal,normal respiratory sounds,abnormal respiratory sounds,real-world dataset,scientific community",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Engineering,,1.569,"IDENTIFICATION,RECOGNITION",IET SIGNAL PROCESSING,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-spr.2019.0487,
59,Comparison of machine learning methods for the construction of a standalone gait diagnosis device,14,4,243-250,"Han Yi Chiew,Wong Kiing Ing,Murray Iain","Han YC,Wong KI,Murray I",Han YC,10.1049/iet-spr.2019.0228,Curtin University Sarawak,"In this research, the authors investigate the feasibility of selecting three-dimensional thigh and shank angles as the features of machine learning methods. Four common machine learning techniques, i.e. random forest, k-nearest neighbour, support vector machine and perceptron, were compared in terms of accuracy and memory usage so that a real-time standalone gait diagnosis device can be constructed using low-end inertial measurement units (IMUs). With proper re-sampling and normalisation, they discovered that the support vector machine and perceptron resulted in the top two highest accuracies (96-99%) among the four machine learning methods. The memory requirement of the perceptron is the lowest among the machine learning methods. Therefore, perceptron was selected as the classification algorithm for the standalone gait diagnosis device. The trained perceptron was transferred to the thigh and shank's IMUs to process the data locally in real-time. The constructed standalone gait diagnosis device lit up green or red light emitting diodes when normal or abnormal gaits were detected, respectively. This standalone device was further tested in real-life and achieved a mean classification accuracy of 96.50%.","pattern classification,perceptrons,learning (artificial intelligence),support vector machines,patient diagnosis,gait analysis,medical diagnostic computing,biomedical equipment,standalone device,machine learning,support vector machine,perceptron,real-time standalone gait diagnosis device,low-end inertial measurement units,classification algorithm,three-dimensional thigh angles,three-dimensional shank angles",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND",Engineering,,,"CLASSIFICATION,RECOGNITION,FEATURES,DISEASE",IET SIGNAL PROCESSING,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-spr.2019.0228,
60,Platelet-rich emboli are associated with von Willebrand factor levels and have poorer revascularization outcomes,12,6,557-562,"Douglas Andrew,Fitzgerald Sean,Mereuta Oana Madalina,Rossi Rosanna,O'Leary Sean,Pandit Abhay,McCarthy Ray,Gilvarry Michael,Holmegaard Lukas,Abrahamsson Margareta","Douglas A,Fitzgerald S,Mereuta OM,Rossi R,O'Leary S,Pandit A,McCarthy R,Gilvarry M,Holmegaard L,Abrahamsson M",Doyle K,10.1136/neurintsurg-2019-015410,"Natl Univ Ireland Galway, CURAM, Physiol, Galway H91 TK33, Ireland.","Background and aims
Platelets and von Willebrand factor (vWF) are key factors in thrombosis and thus are likely key components of acute ischemic stroke (AIS) emboli. We aimed to characterize platelet and vWF levels in AIS emboli and to assess associations between their expression levels and clinical and procedural information.
Materials and method
Histopathological and immunohistochemical analysis of emboli collected as part of the multi-institutional RESTORE registry was performed. The composition of the emboli was quantified using Orbit Image Analysis machine learning software. Correlations between clot components and clinical and procedural information were assessed using the chi(2) test.
Results
Ninety-one emboli samples retrieved from 63 patients were analyzed in the study. The mean platelet (CD42b) content of the clots was 33.9% and the mean vWF content of the clots was 29.8%. There was a positive correlation between platelet and vWF levels (rho=0.564, p<0.001*, n=91). There was an inverse correlation between both platelets and vWF levels and percentage of red blood cells (RBCs) in the emboli (CD42b vs RBC: rho=-0.535, p<0.001*, n=91; vWF vs RBC: rho=-0.366, p<0.001*, n=91). Eighty-one percent of patients in the low platelet group had a good revascularization outcome (Thrombolysis in Cerebral Infarction 2c/3) compared with 58% in the high platelet group (chi(2)=5.856, p=0.016).
Conclusion
Platelet and vWF levels in AIS emboli correlate with each other and both have an inverse relationship with RBC composition. Patients with platelet-rich clots have poorer revascularization outcomes.","stroke,platelets,thrombectomy",Article,"BMJ PUBLISHING GROUP, BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND","Neurosciences & Neurology,Surgery",,4.815,"NEUTROPHIL,EXTRACELLULAR,TRAPS,RED-BLOOD-CELLS,ISCHEMIC-STROKE,T-PA,THROMBOLYSIS,THROMBECTOMY,ACTIVATION,RETENTION",JOURNAL OF NEUROINTERVENTIONAL SURGERY,,
61,Using machine learning in an open optical line system controller,12,6,C1-C11,"D'Amico Andrea,Straullu Stefano,Nespola Antonino,Khan Ihtesham,London Elliot,Virgillito Emanuele,Piciaccia Stefano,Tanzi Alberto,Galimberti Gabriele,Curri Vittorio","D'Amico A,Straullu S,Nespola A,Khan I,London E,Virgillito E,Piciaccia S,Tanzi A,Galimberti G,Curri V",D'Amico A,10.1364/JOCN.382557,Polytechnic University of Turin,"The reduction of system margin in open optical line systems (OLSs) requires the capability to predict the quality of transmission (QoT) within them. This quantity is given by the generalized signal-to-noise ratio (GSNR), including both the effects of amplified spontaneous emission (ASE) noise and nonlinear interference accumulation. Among these, estimating the ASE noise is the most challenging task due to the spectrally resolved working point of the erbium-doped fiber amplifiers (EDFAs), which depend on the spectral load, given the overall gain profile. An accurate GSNR estimation enables control of the power optimization and the possibility to automatically deploy lightpaths with a minimum margin in a reliable manner. We suppose an agnostic operation of the OLS, meaning that the EDFAs are operated as black boxes and rely only on telemetry data from the optical channel monitor at the end of the OLS. We acquire an experimental data set from an OLS made of 11 EDFAs and show that, without any knowledge of the system characteristics, an average extra margin of 2.28 dB is necessary to maintain a conservative threshold of QoT. Following this, we applied deep neural network machine-learning techniques, demonstrating a reduction in the needed margin average down to 0.15 dB. (C) 2020 Optical Society of America Provided under the terms of the OSA Open Access Publishing Agreement","DESIGN,VALIDATION,MODULATION,NETWORKS,QUALITY,NOISE",Article,"OPTICAL SOC AMER, 2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA","Computer Science,Optics,Telecommunications",,3.18,"DESIGN,VALIDATION,MODULATION,NETWORKS,QUALITY,NOISE",JOURNAL OF OPTICAL COMMUNICATIONS AND NETWORKING,https://zenodo.org/record/4522075/files/jocn-12-6-C1.pdf,
62,Convolutional Neural Network Detection of Axillary Lymph Node Metastasis Using Standard Clinical Breast MRI,20,3,E301-E308,"Ren Thomas,Cattell Renee,Duanmu Hongyi,Huang Pauline,Li Haifang,Vanguri Rami,Liu Michael Z.,Jambawalikar Sachin,Ha Richard,Wang Fusheng","Ren T,Cattell R,Duanmu H,Huang P,Li HF,Vanguri R,Liu MZ,Jambawalikar S,Ha R,Wang FS",Duong TQ,10.1016/j.clbc.2019.11.009,"Stony Brook Sch Med, Dept Radiol, 101 Nicolls Rd, Stony Brook, NY 11794 USA.","This study used an supervised deep learning algorithm, the convolutional neural network, to detect axillary lymph node metastasis on standard clinical breast magnetic resonance imaging scans. Data consisted of 66 abnormal nodes and 193 normal nodes from Stony Brook Hospital patients. The model yielded an accuracy of 84.8% +/- 2.4% and a receiver operating characteristic area under the curve of 0.91 +/- 0.02.
Background: Axillary lymph node status is important for breast cancer staging and treatment planning as the majority of breast cancer metastasis spreads through the axillary lymph nodes. There is currently no reliable noninvasive imaging method to detect nodal metastasis associated with breast cancer. Materials and Methods: Magnetic resonance imaging (MRI) data were those from the peak contrast dynamic image from 1.5 Tesla MRI scanners at the pre-neoadjuvant chemotherapy stage. Data consisted of 66 abnormal nodes from 38 patients and 193 normal nodes from 61 patients. Abnormal nodes were those determined by expert radiologist based on (18)Fluorodeoxyglucose positron emission tomography images. Normal nodes were those with negative diagnosis of breast cancer. The convolutional neural network consisted of 5 convolutional layers with filters from 16 to 128. Receiver operating characteristic analysis was performed to evaluate prediction performance. For comparison, an expert radiologist also scored the same nodes as normal or abnormal. Results: The convolutional neural network model yielded a specificity of 79.3% +/- 5.1%, sensitivity of 92.1% +/- 2.9%, positive predictive value of 76.9% +/- 4.0%, negative predictive value of 93.3% +/- 1.9%, accuracy of 84.8% +/- 2.4%, and receiver operating characteristic area under the curve of 0.91 +/- 0.02 for the validation data set. These results compared favorably with scoring by radiologists (accuracy of 78%). Conclusion: The results are encouraging and suggest that this approach may prove useful for classifying lymph node status on MRI in clinical settings in patients with breast cancer, although additional studies are needed before routine clinical use can be realized. This approach has the potential to ultimately be a noninvasive alternative to lymph node biopsy. (C) 2019 Elsevier Inc. All rights reserved.","Breast cancer,Machine learning,Magnetic resonance imaging,Pathological complete response,Sentinel lymph node biopsy",Article,"CIG MEDIA GROUP, LP, 3500 MAPLE AVENUE, STE 750, DALLAS, TX 75219-3931 USA",Oncology,,3.356,"F-18-FDG,PET%2FCT,FDG-PET,CANCER,BIOPSY,ACCURACY",CLINICAL BREAST CANCER,,
63,COVID-19 Detection in Chest X-ray Images using a Deep Learning Approach,6,2,11-14,"Saiz Fatima A.,Barandiaran Inigo","Saiz FA,Barandiaran I",Saiz FA,10.9781/ijimai.2020.04.003,"Basque Res & Technol Alliance BRTA, Vicomtech Fdn, Donostia San Sebastian, Spain.","The Corona Virus Disease (COVID-19) is an infectious disease caused by a new virus that has not been detected in humans before. The virus causes a respiratory illness like the flu with various symptoms such as cough or fever that, in severe cases, may cause pneumonia. The COVID-19 spreads so quickly between people, affecting to 1,200,000 people worldwide at the time of writing this paper (April 2020). Due to the number of contagious and deaths are continually growing day by day, the aim of this study is to develop a quick method to detect COVID-19 in chest X-ray images using deep learning techniques. For this purpose, an object detection architecture is proposed, trained and tested with a public available dataset composed with 1500 images of non-infected patients and infected with COVID-19 and pneumonia. The main goal of our method is to classify the patient status either negative or positive COVID-19 case. In our experiments using SDD300 model we achieve a 94.92% of sensibility and 92.00% of specificity in COVID-19 detection, demonstrating the usefulness application of deep learning models to classify COVID-19 in X-ray images.","COVID-19,Deep Learning,Object Detection,X-ray",Article,"UNIV INT RIOJA-UNIR, RECTORADO, AVENIDA DE LA PAZ, 137, LOGRONO, 26006, SPAIN",Computer Science,,2.467,,INTERNATIONAL JOURNAL OF INTERACTIVE MULTIMEDIA AND ARTIFICIAL INTELLIGENCE,https://doi.org/10.9781/ijimai.2020.04.003,
64,Climate adaptive optimal design of an aerogel glazing system with the integration of a heuristic teaching-learning-based algorithm in machine learning-based optimization,153,,375-391,"Zhou Yuekuan,Zheng Siqian","Zhou YK,Zheng SQ",Zheng SQ,10.1016/j.renene.2020.01.133,Hunan University,"Integrating advanced materials in building glazing systems is critical for promoting net-zero energy buildings. In this research, both experimental and numerical studies were conducted on an aerogel glazing system. In order to provide climate adaptive designs on the aerogel glazing system with optimal geometric and operating parameters, a generic optimization methodology was developed by flexibly integrating supervised machine learning and advanced teaching-learning-based optimization algorithm. The proposed optimization methodology was thereafter used for optimal system designs in different climate regions. Results indicate that the proposed surrogate model can intelligently and accurately learn and update the optimization function with straightforward mathematical associations between multi-variables and objectives. In addition, within optimal cases, total heat gain and heat flux are dominated by the extinction coefficient in southern cities, whereas the total heat gain is dominated by the thermal conductivity in the northern city, LanZhou. By adopting the proposed technique in this study, compared to optimal results following the Taguchi standard orthogonal array, the total heat gain can be reduced by 62.5% to 36.27 kWh/m(2) in LanZhou, and by 5.9% to 267.18 kWh/m(2) in GuangZhou, respectively. This study formulates a general methodology for climate adaptive optimal designs on aerogel glazing systems in different climatic regions. (C) 2020 Elsevier Ltd. All rights reserved.","Aerogel glazing system,Climatic regions,Machine learning,Optimization function,Teaching-learning-based optimization",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Science & Technology - Other Topics,Energy & Fuels",,7.435,"SILICA,AEROGEL,BUILDING,ENVELOPE,HEAT-TRANSFER,ENERGY,PERFORMANCE,INSULATION,COMPOSITE,WINDOW,THICKNESS,IMPACT",RENEWABLE ENERGY,,
65,Active Disturbance Rejection Decoupling Control for Three-Degree-of- Freedom Six-Pole Active Magnetic Bearing Based on BP Neural Network,30,4,,"Wang Shaoshuai,Zhu Huangqiu,Wu Mengyao,Zhang Weiyu","Wang SS,Zhu HQ,Wu MY,Zhang WY",Zhu HQ,10.1109/TASC.2020.2990794,Jiangsu University,"In order to decouple the three-degree-of-freedom six-pole active magnetic bearing (3-DOF 6-pole AMB) with strong couplings, nonlinear and unstable disturbance, an active disturbance rejection control strategy based on BP neural network (ADRC-BP) is put forward. Firstly, the configuration, magnetic circuit, working principle and mathematical model of 3-DOF 6-pole AMB are introduced and established. Then, taking the 3-DOF 6-pole AMB as the controlled object, an ADRC-BP system is designed and a method of parameter tuning is proposed. Finally, the effectiveness of the control strategy is verified by simulation and experiments. The results show that the ADRC-BP has strong robustness and adaptability to the uncertainty of magnetic bearing model and the variation of external disturbance. The decoupling control effect of ADRC-BP is better than that of conventional ADRC.","Active magnetic bearing,mathematical model,six-pole,active disturbance rejection control,BP neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Physics",,1.566,,IEEE TRANSACTIONS ON APPLIED SUPERCONDUCTIVITY,,
66,Physical reservoir computing-an introductory perspective,59,6,,Nakajima Kohei,Nakajima K,Nakajima K,10.35848/1347-4065/ab8d4f,University of Tokyo,"Understanding the fundamental relationships between physics and its information-processing capability has been an active research topic for many years. Physical reservoir computing is a recently introduced framework that allows one to exploit the complex dynamics of physical systems as information-processing devices. This framework is particularly suited for edge computing devices, in which information processing is incorporated at the edge (e.g. into sensors) in a decentralized manner to reduce the adaptation delay caused by data transmission overhead. This paper aims to illustrate the potentials of the framework using examples from soft robotics and to provide a concise overview focusing on the basic motivations for introducing it, which stem from a number of fields, including machine learning, nonlinear dynamical systems, biological science, materials science, and physics.","reservoir computing,physical system,nonlinear dynamics,machine learning,material",Review,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,1.362,"ECHO,STATE,PROPERTY,MORPHOLOGICAL,COMPUTATION,SELF-ORGANIZATION,CHAOS,NETWORKS,MEMORY,RECOGNITION,EDGE,EMBODIMENT,PREDICTION",JAPANESE JOURNAL OF APPLIED PHYSICS,https://iopscience.iop.org/article/10.35848/1347-4065/ab8d4f/pdf,
67,The precision of case difficulty and referral decisions: an innovative automated approach,24,6,1909-1915,"Mallishery Shivani,Chhatpar Pavan,Banga K. S.,Shah Trusha,Gupta Pankaj","Mallishery S,Chhatpar P,Banga KS,Shah T,Gupta P",Mallishery S,10.1007/s00784-019-03050-4,"Nair Hosp, Dent Coll, Mumbai 400008, Maharashtra, India.","Objectives Endodontic treatment works as a successful treatment modality in several cases. However, it may fail due to some reasons unforeseeable by the dentist. Many failures can be prevented by carefully assessing the difficulty level of the case before initiating treatment or by referral to a specialist. This study presents an approach using machine learning to generate an algorithm which can help predict the difficulty level of the case and decide about a referral, with the help of the standard American Association of Endodontists (AAE) Endodontic Case Difficulty Assessment Form. Materials and methods Using the AAE Endodontic Case Difficulty Form after obtaining the patients' consent, 500 potential root canal patients were diagnosed. The filled forms were assessed by two pre-calibrated endodontists, and, in cases of conflicting opinion, a third endodontist's opinion was taken. Artificial neural network was used for generating the algorithm. Results Using 500 filled AAE forms, a sensitivity of 94.96% was achieved by the machine learning algorithm. Conclusion This study provides an option for automation to the conventional method of predicting the difficulty level of a case, thus increasing the speed of decision-making and referrals if necessary.","Artificial intelligence,Case difficulty,Machine learning,Referral,Treatment planning",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Dentistry, Oral Surgery & Medicine",,3.623,,CLINICAL ORAL INVESTIGATIONS,,
68,Fabrication of a portable device for stress monitoring using wearable sensors and soft computing algorithms,32,11,7515-7537,"Golgouneh Alireza,Tarvirdizadeh Bahram","Golgouneh A,Tarvirdizadeh B",Tarvirdizadeh B,10.1007/s00521-019-04278-7,University of Tehran,"Stress is an issue that everyone experiences in today's modern life. Prolonged exposure to stress can cause many mental and physical diseases. Accordingly, the stress management issue has become popular, and the need for personal healthcare devices has increased in recent years. Therefore, the aim of this research is to design and manufacture a portable stress monitoring system, based on photoplethysmography (PPG) and galvanic skin response (GSR) physiological signals, acquired by wearable sensors. To do so, we proposed a novel algorithm for continuous measurement of the stress index (SI) as well as the classification of stress levels. In order to estimate an accurate value for SI, various soft computing algorithms such as support vector regression, artificial neural networks (ANN), and adaptive neuro-fuzzy inference system (ANFIS) were adopted for modeling the stress based on the features extracted from normalized and non-normalized types of PPG and GSR signals and their combinations. Furthermore, K-nearest neighbor (KNN), ANNs, Naive Bayes, and support vector machine (SVM) were utilized to discriminate different levels of stress in subjects. The obtained results indicate that the ANFIS algorithm can estimate the SI training output with the correlation coefficient (CC) of 0.9281 and the average relative error of 0.23 on a subset of the combined features of PPG and GSR signals. Also, the best classification performance was for KNN (K=3) algorithm, with 85.3% accuracy. To evaluate the developed system, data of 16 subjects, out of the training dataset, participated in the experiment in the presence of the experts and psychologists, were used. The average CC of 0.81 and classification accuracy of 75% were obtained, using the implemented ANFIS model and KNN classifier.","Machine learning,Stress,Photoplethysmography,Galvanic skin response,Portable device,Emotion recognition,Physiological signals,Arousal detection",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"HEART-RATE-VARIABILITY,MENTAL,STRESS,TIME,ANALYZE,SYSTEM",NEURAL COMPUTING & APPLICATIONS,,
69,Thermodynamic re-assessment of pure chromium using modified segmented regression model,69,,,"Obaied A.,Bocklund B.,Zomorodpoosh S.,Zhang L.,Otis R.,Liu Zi-Kui,Roslyakova I","Obaied A,Bocklund B,Zomorodpoosh S,Zhang L,Otis R,Liu ZK,Roslyakova I",Obaied A,10.1016/j.calphad.2020.101762,Ruhr University Bochum,"Chromium is considered an essential addition element in multiple industrial applications. Therefore, obtaining an accurate and robust description of its properties is important. Recently, several attempts were made to improve the thermodynamic description of pure elements and binary systems in the frame of the third generation CALPHAD databases. Moreover, it became increasingly important to develop mathematical tools that can allow researchers more access to each phase of the material over the entire temperature range. Thus, the recently proposed segmented regression model was modified using the so-called sigmoid function for the case of pure Cr. A comprehensive analysis of phase equilibria and thermodynamic properties of pure Cr was used to develop an updated unary description from 0 K to 6000 K using the proposed modified segmented regression (MSR) model. In addition, two newly developed machine learning tools were utilized to analyze the datasets used in this assessment to determine any possible outliers.","Chromium,Thermodynamic properties,Third generation,CALPHAD databases, sigmoid function,Segmented regression",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Thermodynamics,Chemistry,Materials Science,Metallurgy & Metallurgical Engineering",,2.734,"HEAT-CAPACITY,HIGH-TEMPERATURES,SGTE,DATA,0,K,ELEMENTS,METALS,PHASES,ANTIFERROMAGNETISM,SOFTWARE,VANADIUM",CALPHAD-COMPUTER COUPLING OF PHASE DIAGRAMS AND THERMOCHEMISTRY,https://www.sciencedirect.com/science/article/am/pii/S0364591620300274,
70,"Should We Ignore, Follow, or Biopsy? Impact of Artificial Intelligence Decision Support on Breast Ultrasound Lesion Assessment",214,6,1445-1452,"Mango Victoria L.,Sun Mary,Wynn Ralph T.,Ha Richard","Mango VL,Sun M,Wynn RT,Ha R",Mango VL,10.2214/AJR.19.21872,Memorial Sloan Kettering Cancer Center,"OBJECTIVE. The objective of this study was to assess the impact of artificial intelligence (AI)-based decision support (DS) on breast ultrasound (US) lesion assessment.
MATERIALS AND METHODS. A multicenter retrospective review of 900 breast lesions (470/900[52.2%] benign; 430/900 [47.8%] malignant) on US by 15 physicians (11 radiologists, two surgeons, two obstetrician/gynecologists). An AI system (Koios DS for Breast, Koios Medical) evaluated images and assigned them to one of four categories: benign, probably benign, suspicious, and probably malignant. Each reader reviewed cases twice: 750 cases with US only or with US plus DS; 4 weeks later, cases were reviewed in the opposite format. One hundred fifty additional cases were presented identically in each session. DS and reader sensitivity, specificity, and positive likelihood ratios (PLRs) were calculated as well as reader AUCs with and without DS. The Kendall tau-b correlation coefficient was used to assess intra and interreader variability.
RESULTS. Mean reader AUC for cases reviewed with US only was 0.83 (95% CI, 0.78-0.89); for cases reviewed with US plus DS, mean AUC was 0.87 (95% CI, 0.84-0.90). PLR for the DS system was 1.98 (95% CI, 1.78-2.18) and was higher than the PLR for all readers but one. Fourteen readers had better AUC with US plus DS than with US only. Mean Kendall tau-b for US-only interreader variability was 0.54 (95% CI, 0.53-0.55); for US plus DS, it was 0.68 (95% CI, 0.67-0.69). Intrareader variability improved with DS; class switching (defined as crossing from BI-RADS category 3 to BI-RADS category 4A or above) occurred in 13.6% of cases with US only versus 10.8% of cases with US plus DS (p = 0.04).
CONCLUSION. AI-based DS improves accuracy of sonographic breast lesion assessment while reducing inter- and intraobserver variability.","artificial intelligence,breast cancer,breast ultrasound,computer-aided diagnosis,machine learning",Article,"AMER ROENTGEN RAY SOC, 44211 SLATESTONE CT, LEESBURG, VA USA","Radiology, Nuclear Medicine & Medical Imaging",,4.073,"COMPUTER-AIDED,DETECTION,CANCER,US,MAMMOGRAPHY,AGREEMENT,LEXICON,SYSTEM",AMERICAN JOURNAL OF ROENTGENOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8162774,
71,Learning the retinal anatomy from scarce annotated data using self-supervised multimodal reconstruction,91,,,"Hervella Alvaro S.,Rouco Jose,Novo Jorge,Ortega Marcos","Hervella AS,Rouco J,Novo J,Ortega M",Hervella AS,10.1016/j.asoc.2020.106210,Universidade da Coruna,"Deep learning is becoming the reference paradigm for approaching many computer vision problems. Nevertheless, the training of deep neural networks typically requires a significantly large amount of annotated data, which is not always available. A proven approach to alleviate the scarcity of annotated data is transfer learning. However, in practice, the use of this technique typically relies on the availability of additional annotations, either from the same or natural domain. We propose a novel alternative that allows to apply transfer learning from unlabelled data of the same domain, which consists in the use of a multimodal reconstruction task. A neural network trained to generate one image modality from another must learn relevant patterns from the images to successfully solve the task. These learned patterns can then be used to solve additional tasks in the same domain, reducing the necessity of a large amount of annotated data.
In this work, we apply the described idea to the localization and segmentation of the most important anatomical structures of the eye fundus in retinography. The objective is to reduce the amount of annotated data that is required to solve the different tasks using deep neural networks. For that purpose, a neural network is pre-trained using the self-supervised multimodal reconstruction of fluorescein angiography from retinography. Then, the network is fine-tuned on the different target tasks performed on the retinography. The obtained results demonstrate that the proposed self-supervised transfer learning strategy leads to state-of-the-art performance in all the studied tasks with a significant reduction of the required annotations. (C) 2020 The Authors. Published by Elsevier B.V.","Deep learning,Eye fundus,Self-supervised learning,Optic disc,Blood vessels,Fovea,Medical imaging,Transfer learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,6.607,"CONVOLUTIONAL,NEURAL-NETWORKS,OPTIC,DISC,VESSEL,SEGMENTATION,BLOOD-VESSELS,IMAGE,FOVEA",APPLIED SOFT COMPUTING,https://doi.org/10.1016/j.asoc.2020.106210,
72,A survey on methods and challenges in EEG based authentication,93,,,"Bidgoly Amir Jalaly,Bidgoly Hamed Jalaly,Arezoumand Zeynab","Bidgoly AJ,Bidgoly HJ,Arezoumand Z",Bidgoly AJ,10.1016/j.cose.2020.101788,"Univ Qom, Dept Informat Technol & Comp Engn, Qom, Iran.","EEG is the recording of electrical activities of the brain, usually along the scalp surface, which are the results of synaptic activations of the brain's neurons. In recent years, it has been shown that EEG is an appropriate signal for the biometric authentication and has important features such as resistance to spoofing attacks and impossibility to use under pressure and coercion states. In this paper, the state-of-the-art methods in EEG based authentication are reviewed. This review includes a number of aspects such as the various tasks that the user required to perform during the authentication, devices and available datasets, the preprocessing procedures and the classification methods used in the EEG biometric authentication. Both shallow and deep classification methods are reviewed in this paper. The study shows that the deep learning approaches which are used in the past few years, although still require further research, have shown great results. Moreover, the paper summarizes the works to address the open challenges of this area. The EEG authentication challenges have been discussed from a variety of points of view, including privacy, user-friendliness, attacks, and authentication requirements such as universality, permanency, uniqueness, and collectability. This paper can be used as a preliminary plan and a roadmap for researchers interested in EEG biometric. (C) 2020 Elsevier Ltd. All rights reserved.","EEG,Biometric factor,Authentication,User identification,Pattern recognition,Survey",Review,"ELSEVIER ADVANCED TECHNOLOGY, OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Computer Science,,4.573,"BIOMETRIC,CRYPTOSYSTEM,USER,IDENTIFICATION,SIGNALS,SYSTEM,RECOGNITION,PERMANENCE,NETWORKS,FRAMEWORK,CEREBRE,LEVEL",COMPUTERS & SECURITY,,
73,Noncontact detection of concrete flaws by neural network classification of laser doppler vibrometer signals,2,2,,"Muramatsu Masayasu,Uchida Shigeaki,Takahashi Yasuo","Muramatsu M,Uchida S,Takahashi Y",Muramatsu M,10.1088/2631-8695/ab8ba4,Osaka University,"This study aimed to develop a non-contact and high-speed damage detection technology for use on concrete structures. A laser Doppler vibrometer was used to obtain the vibrations of a concrete structure at a high signal-to-noise ratio. The observed vibration data were transformed into frequency spectra by Fourier transform. Using the simulation by the finite element method, it was predicted that the characteristic spectrum appeared in the low frequency region for the cracked part. However, the experimental results did not show such a difference clearly. In contrast, in the high-frequency region of the experimental data, a spectrum peculiar to the cracked part tended to appear. Nonetheless, the difference was so small that it was often buried by variations in hammering strength. Therefore, it was difficult to manually determine the signal of the cracked part. Machine learning using a convolutional neural network was carried out in order to judge the location and dimensions of a cracked part with high accuracy. As a result, cracks in the concrete were detected with a high accuracy of more than 90%.","concrete,laser doppler vibrometer,convolutional neural network,non-destructive inspection",Article,"IOP Publishing Ltd, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Engineering,,,"DAMAGE,DETECTION,PIEZOELECTRIC,TRANSDUCERS,IMPACT-ECHO,SYSTEM",ENGINEERING RESEARCH EXPRESS,,
74,Machine Learning Offers Exciting Potential for Predicting Postprocedural Outcomes: A Framework for Developing Random Forest Models in IR,31,6,1018-+,"Sinha Ishan,Aluthge Dilum P.,Chen Elizabeth S.,Sarkar Indra Neil,Ahn Sun Ho","Sinha I,Aluthge DP,Chen ES,Sarkar IN,Ahn SH",Sinha I,10.1016/j.jvir.2019.11.030,Brown University,"Purpose: To demonstrate that random forest models trained on a large national sample can accurately predict relevant outcomes and may ultimately contribute to future clinical decision support tools in IR.
Materials and Methods: Patient data from years 2012-2014 of the National Inpatient Sample were used to develop random forest machine learning models to predict iatrogenic pneumothorax after computed tomography-guided transthoracic biopsy (TTB), in-hospital mortality after transiugular intrahepatic portosystemic shunt (TIPS), and length of stay > 3 days after uterine artery embolization (UAE). Model performance was evaluated with area under the receiver operating characteristic curve (AUROC) and maximum F1 score. The threshold for AUROC significance was set at 0.75.
Results: AUROC was 0.913 for the TTB model, 0.788 for the TIPS model, and 0.879 for the UAE model. Maximum F1 score was 0.532 for the TTB model, 0.357 for the TIPS model, and 0.700 for the UAE model. The TTB model had the highest AUROC, while the UAE model had the highest F1 score. All models met the criteria for AUROC significance.
Conclusions: This study demonstrates that machine learning models may suitably predict a variety of different clinically relevant outcomes, including procedure-specific complications, mortality, and length of stay. Performance of these models will improve as more high-quality IR data become available.","PNEUMOTHORAX,RISK,MORTALITY,BIOPSY",Article; Proceedings Paper,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging,Cardiovascular System & Cardiology",,3.702,"PNEUMOTHORAX,RISK,MORTALITY,BIOPSY",JOURNAL OF VASCULAR AND INTERVENTIONAL RADIOLOGY,,
75,Quantitative enhancement thresholds and machine learning algorithms for the evaluation of renal lesions using single-phase split-filter dual-energy CT,45,6,1922-1928,"Obmann Markus M.,Cosentino Aurelio,Cyriac Joshy,Hofmann Verena,Stieltjes Bram,Boll Daniel T.,Yeh Benjamin M.,Benz Matthias R.","Obmann MM,Cosentino A,Cyriac J,Hofmann V,Stieltjes B,Boll DT,Yeh BM,Benz MR",Obmann MM; Benz MR,10.1007/s00261-019-02195-w,University of Basel,"Purpose To establish thresholds for contrast enhancement-based attenuation (CM) and iodine concentration (IOD) for the quantitative evaluation of enhancement in renal lesions on single-phase split-filter dual-energy CT (tbDECT) and combine measurements in a machine learning algorithm to potentially improve performance. Material 126 patients with incidental renal cysts (both hypo- and hyperdense cysts) or high suspicion for renal cell carcinoma (312 total lesions) undergoing abdominal, portal venous phase tbDECT were initially included in this retrospective study. Gold standard was pathological confirmation or follow-up imaging (MRI or multiphasic CT). CM, IOD, and ROI size were recorded. Thresholds for CM and IOD were identified using Youden-Index of the empirical ROC curves. Decision tree (DTC) and random forest classifier (RFC) were trained. Sensitivities, specificities, and AUCs were compared using McNemar and DeLong test. Results The final study cohort comprised 40 enhancing and 113 non-enhancing renal lesions. Optimal thresholds for quantitative iodine measurements and contrast enhancement-based attenuation were 1.0 +/- 0.0 mg/ml and 23.6 +/- 0.3 HU, respectively. Single DECT parameters (IOD, CM) showed similar overall performance with an AUC of 0.894 and 0.858 (p = 0.541) (sensitivity 90 and 80%, specificity 88 and 92%, respectively). While overall performance for the DTC (AUC 0.944) was higher than RFC (AUC 0.886), this difference (p = 0.409) and comparison to CM (p = 0.243) and IOD (p = 0.353) was not statistically significant. Conclusions Enhancement in incidental renal lesions on single-phase tbDECT can be classified with up to 87.5% sensitivity and 94.6% specificity. Algorithms combining DECT parameters did not increase overall performance.","Dual-energy X-ray computed tomography,Computer-assisted radiographic image interpretation,Artificial intelligence,Kidney diseases",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,2.965,"MASSES,ACCURACY,CYSTS,MDCT",ABDOMINAL RADIOLOGY,,
76,A novel machine learning based computational framework for homogenization of heterogeneous soft materials: application to liver tissue,19,3,1131-1142,"Hashemi Mohammad Saber,Baniassadi Majid,Baghani Mostafa,George Daniel,Remond Yves,Sheidaei Azadeh","Hashemi MS,Baniassadi M,Baghani M,George D,Remond Y,Sheidaei A",Sheidaei A,10.1007/s10237-019-01274-7,Iowa State University,"Real-time simulation of organs increases comfort and safety for patients during the surgery. Proper generalized decomposition (PGD) is an efficient numerical method with coordinate errors below 1 mm and response time below 0.1 s that can be used for simulated surgery. For input of this approach, nonlinear mechanical properties of each segment of the liver need to be calculated based on the geometries of the patient's liver extracted using medical imaging techniques. In this research work, a map of the mechanical properties of the liver tissue has been estimated with a novel combined method of the finite element (FE) optimization. Due to the existence of major-size vessels in the liver that makes the surrounding tissue anisotropic, the simulation of hyperelastic material with two different sections is computationally expensive. Thus, a homogenized, anisotropic, and hyperelastic model with the nearest response to the real heterogeneous model was developed and presented. Because of various possibilities of the vessel orientation, position, and size, homogenization has been carried out for adequate samples of heterogeneous models to train artificial neural networks (ANNs) as machine learning tools. Then, an unknown sample of heterogeneous material was categorized and mapped to its homogenized material parameters with the trained networks for the fast and low-cost generalization of our combined FE optimization method. The results showed the efficiency of the proposed novel machine learning based technique for the prediction of effective material properties of unknown heterogeneous tissues.","Mechanical homogenization,Finite element analysis (FEA),Optimization,Artificial neural network (ANN)",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Biophysics,Engineering",,3.257,"SIMULATION,MODEL",BIOMECHANICS AND MODELING IN MECHANOBIOLOGY,,
77,Dentronics: Towards robotics and artificial intelligence in dentistry,36,6,765-778,"Grischke Jasmin,Johannsmeier Lars,Eich Lukas,Griga Leif,Haddadin Sami","Grischke J,Johannsmeier L,Eich L,Griga L,Haddadin S",Grischke J,10.1016/j.dental.2020.03.021,"Robokind Robot Mankind Fdn, Appelstr 30, D-30167 Hannover, Germany.","Objectives. This paper provides an overview of existing applications and concepts of robotic systems and artificial intelligence in dentistry. This review aims to provide the community with novel inputs and argues for an increased utilization of these recent technological developments, referred to as Dentronics, in order to advance dentistry.
Methods. First, background on developments in robotics, artificial intelligence (AI) and machine learning (ML) are reviewed that may enable novel assistive applications in dentistry (Sec A). Second, a systematic technology review that evaluates existing state-of-the-art applications in AI, ML and robotics in the context of dentistry is presented (Sec B).
Results. A systematic literature research in pubmed yielded in a total of 558 results. 41 studies related to ML, 53 studies related to AI and 49 original research papers on robotics application in dentistry were included. ML and AI have been applied in dental research to analyze large amounts of data to eventually support dental decision making, diagnosis, prognosis and treatment planning with the help of data-driven analysis algorithms based on machine learning. So far, only few robotic applications have made it to reality, mostly restricted to pilot use cases.
Significance. The authors believe that dentistry can greatly benefit from the current rise of digital human-centered automation and be transformed towards a new robotic, ML and AI-enabled era. In the future, Dentronics will enhance reliability, reproducibility, accuracy and efficiency in dentistry through the democratized use of modern dental technologies, such as medical robot systems and specialized artificial intelligence. Dentronics will increase our understanding of disease pathogenesis, improve risk-assessment-strategies, diagnosis, disease prediction and finally lead to better treatment outcomes. (C) 2020 The Academy of Dental Materials. Published by Elsevier Inc. All rights reserved.","Machine learning,Artificial intelligence,Robot,Robotics,Dentistry,Dental robots,Dentronics",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Dentistry, Oral Surgery & Medicine,Materials Science",,6.256,"DENTAL,ARCH,GENERATOR,LIGHTWEIGHT,ROBOT,IMPEDANCE,CONTROL,SYSTEM,SIMULATOR,MACHINE,MOTION,MANIPULATION,KNOWLEDGE,ACCURACY",DENTAL MATERIALS,,
78,Detecting explosives by PGNAA using KNN Regressors and decision tree classifier: A proof of concept,124,,,"Hossny K.,Magdi S.,Soliman Abdelfattah Y.,Hossny Ahmad Hany","Hossny K,Magdi S,Soliman AY,Hossny AH",Hossny K,10.1016/j.pnucene.2020.103332,Egyptian Knowledge Bank (EKB),"Radiation based techniques such as PGNAA provided a good alternative to conventional explosives detection methods due to the simplicity and efficiency of the quantitative isotopic technique. This paper introduces a framework that identifies explosive materials using H, C, and O isotopic prints. The first step is to regress the weight fractions of H, C and O isotopes in the sample separately using the gamma peaks as input. The regressed percentages will be used as input to the classifier to identify if this sample is explosive or not. The data used for training the model are generated using MCNP5 and validated on the 2017 ROMASHA experimental setup in Frank Laboratory in JINR, Russia. Our data set consisted of 316 gamma peak observations, which are split into 85% for training and 15% for testing. Experiments showed that KNN-regressor achieved best results to predict the H, C and O weight fractions with average MSE of 0.005 and R-2 of 0.95. Also, the decision-tree-classifier achieved best results to identify whether the sample is explosive or not with the accuracy of 0.98. And, the assembled pipeline achieved total accuracy of 0.92 after error propagation through the two models. The proposed framework emphasized that machine learning and PGNAA are capable of learning and identifying explosives with the accuracy of 92%.","Explosives detection,Prompt Gamma Neutron Activation Analysis (PGNAA),MCNP,ROMAHSA experimental setup,KNN Regressor,Decision tree classifier,Aviation security",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Nuclear Science & Technology,,1.926,,PROGRESS IN NUCLEAR ENERGY,,
79,"A Simple, Inexpensive, Wearable Glove with Hybrid Resistive-Pressure Sensors for Computational Sensing, Proprioception, and Task Identification",2,6,,"Hughes Josie,Spielberg Andrew,Chounlakone Mark,Chang Gloria,Matusik Wojciech,Rus Daniela","Hughes J,Spielberg A,Chounlakone M,Chang G,Matusik W,Rus D",Spielberg A,10.1002/aisy.202000002,Massachusetts Institute of Technology (MIT),"Wearable devices have many applications ranging from health analytics to virtual and mixed reality interaction, to industrial training. For wearable devices to be practical, they must be responsive, deformable to fit the wearer, and robust to the user's range of motion. Signals produced by the wearable must also be informative enough to infer the precise physical state or activity of the user. Herein, a fully soft, wearable glove is developed, which is capable of real-time hand pose reconstruction, environment sensing, and task classification. The design is easy to fabricate using low cost, commercial off-the-shelf items in a manner that is amenable to automated manufacturing. To realize such capabilities, resisitive and fluidic sensing technologies with machine learning neural architectures are merged. The glove is formed from a conductive knit which is strain sensitive, providing information through a network of resistance measurements. Fluidic sensing captured via pressure changes in fibrous sewn-in flexible tubes, measuring interactions with the environment. The system can reconstruct user hand pose and identify sensory inputs such as holding force, object temperature, conductability, material stiffness, and user heart rate, all with high accuracy. The ability to identify complex environmentally dependent tasks, including held object identification and handwriting recognition is demonstrated.","machine learning,multimodal sensing,soft sensing,task recognition,wearable computing,wearable gloves",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Automation & Control Systems,Computer Science,Robotics",,,"STRAIN,SENSORS,STRETCHABLE,ELECTRONICS,SOFT,ACQUISITION,FABRICATION,PARAMETERS,DESIGN,GRASP",ADVANCED INTELLIGENT SYSTEMS,https://dspace.mit.edu/bitstream/1721.1/135364/2/aisy.202000002.pdf,
80,A Cotton Module Feeder Plastic Contamination Inspection System,2,2,280-293,"Pelletier Mathew G.,Holt Greg A.,Wanjura John D.","Pelletier MG,Holt GA,Wanjura JD",Pelletier MG,10.3390/agriengineering2020018,United States Department of Agriculture (USDA),"The removal of plastic contamination in cotton lint is an issue of top priority to the U.S. cotton industry. One of the main sources of plastic contamination showing up in marketable cotton bales, at the U.S. Department of Agriculture's classing office, is plastic from the module wrap used to wrap cotton modules produced by the new John Deere round module harvesters. Despite diligent efforts by cotton ginning personnel to remove all plastic encountered during unwrapping of the seed cotton modules, plastic still finds a way into the cotton gin's processing system. To help mitigate plastic contamination at the gin; an inspection system was developed that utilized low-cost color cameras to see plastic on the module feeder's dispersing cylinders, that are normally hidden from view by the incoming feed of cotton modules. This technical note presents the design of an automated intelligent machine-vision guided cotton module-feeder inspection system. The system includes a machine-learning program that automatically detects plastic contamination in order to alert the cotton gin personnel as to the presence of plastic contamination on the module feeder's dispersing cylinders. The system was tested throughout the entire 2019 cotton ginning season at two commercial cotton gins and at one gin in the 2018 ginning season. This note describes the over-all system and mechanical design and provides an over-view and coverage of key relevant issues. Included as an attachment to this technical note are all the mechanical engineering design files as well as the bill-of-materials part source list. A discussion of the observational impact the system had on reduction of plastic contamination is also addressed.","machine vision,plastic contamination,cotton,automated inspection",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Agriculture,,,,AGRIENGINEERING,https://www.mdpi.com/2624-7402/2/2/18/pdf,
81,Big Data and Its Applications in Smart Real Estate and the Disaster Management Life Cycle: A Systematic Analysis,4,2,,"Munawar Hafiz Suliman,Qayyum Siddra,Ullah Fahim,Sepasgozar Samad","Munawar HS,Qayyum S,Ullah F,Sepasgozar S",Munawar HS,10.3390/bdcc4020004,University of New South Wales Sydney,"Big data is the concept of enormous amounts of data being generated daily in different fields due to the increased use of technology and internet sources. Despite the various advancements and the hopes of better understanding, big data management and analysis remain a challenge, calling for more rigorous and detailed research, as well as the identifications of methods and ways in which big data could be tackled and put to good use. The existing research lacks in discussing and evaluating the pertinent tools and technologies to analyze big data in an efficient manner which calls for a comprehensive and holistic analysis of the published articles to summarize the concept of big data and see field-specific applications. To address this gap and keep a recent focus, research articles published in last decade, belonging to top-tier and high-impact journals, were retrieved using the search engines of Google Scholar, Scopus, and Web of Science that were narrowed down to a set of 139 relevant research articles. Different analyses were conducted on the retrieved papers including bibliometric analysis, keywords analysis, big data search trends, and authors' names, countries, and affiliated institutes contributing the most to the field of big data. The comparative analyses show that, conceptually, big data lies at the intersection of the storage, statistics, technology, and research fields and emerged as an amalgam of these four fields with interlinked aspects such as data hosting and computing, data management, data refining, data patterns, and machine learning. The results further show that major characteristics of big data can be summarized using the seven Vs, which include variety, volume, variability, value, visualization, veracity, and velocity. Furthermore, the existing methods for big data analysis, their shortcomings, and the possible directions were also explored that could be taken for harnessing technology to ensure data analysis tools could be upgraded to be fast and efficient. The major challenges in handling big data include efficient storage, retrieval, analysis, and visualization of the large heterogeneous data, which can be tackled through authentication such as Kerberos and encrypted files, logging of attacks, secure communication through Secure Sockets Layer (SSL) and Transport Layer Security (TLS), data imputation, building learning models, dividing computations into sub-tasks, checkpoint applications for recursive tasks, and using Solid State Drives (SDD) and Phase Change Material (PCM) for storage. In terms of frameworks for big data management, two frameworks exist including Hadoop and Apache Spark, which must be used simultaneously to capture the holistic essence of the data and make the analyses meaningful, swift, and speedy. Further field-specific applications of big data in two promising and integrated fields, i.e., smart real estate and disaster management, were investigated, and a framework for field-specific applications, as well as a merger of the two areas through big data, was highlighted. The proposed frameworks show that big data can tackle the ever-present issues of customer regrets related to poor quality of information or lack of information in smart real estate to increase the customer satisfaction using an intermediate organization that can process and keep a check on the data being provided to the customers by the sellers and real estate managers.
Similarly, for disaster and its risk management, data from social media, drones, multimedia, and search engines can be used to tackle natural disasters such as floods, bushfires, and earthquakes, as well as plan emergency responses. In addition, a merger framework for smart real estate and disaster risk management show that big data generated from the smart real estate in the form of occupant data, facilities management, and building integration and maintenance can be shared with the disaster risk management and emergency response teams to help prevent, prepare, respond to, or recover from the disasters.","big data,data analytics,machine learning,big data management,big data frameworks,big data storage,smart real estate management,property management,disaster management,disaster risk management",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"DATA,ANALYTICS,TEXT,ANALYTICS,CHALLENGES,CONSTRUCTION,MODEL,TIME,RESILIENCE,RECOVERY,OPPORTUNITIES,INTELLIGENCE",BIG DATA AND COGNITIVE COMPUTING,http://eprints.usq.edu.au/42596/1/BDCC-04-00004-v2.pdf,
82,Low-Power Embedded System for Gait Classification Using Neural Networks,10,2,,"Luna-Perejon Francisco,Dominguez-Morales Manuel,Gutierrez-Galan Daniel,Civit-Balcells Anton","Luna-Perejon F,Dominguez-Morales M,Gutierrez-Galan D,Civit-Balcells A",Luna-Perejon F,10.3390/jlpea10020014,University of Sevilla,"Abnormal foot postures can be measured during the march by plantar pressures in both dynamic and static conditions. These detections may prevent possible injuries to the lower limbs like fractures, ankle sprain or plantar fasciitis. This information can be obtained by an embedded instrumented insole with pressure sensors and a low-power microcontroller. However, these sensors are placed in sparse locations inside the insole, so it is not easy to correlate manually its values with the gait type; that is why a machine learning system is needed. In this work, we analyse the feasibility of integrating a machine learning classifier inside a low-power embedded system in order to obtain information from the user's gait in real-time and prevent future injuries. Moreover, we analyse the execution times, the power consumption and the model effectiveness. The machine learning classifier is trained using an acquired dataset of 3000+ steps from 6 different users. Results prove that this system provides an accuracy over 99% and the power consumption tests obtains a battery autonomy over 25 days.","machine learning,neural networks,gait analysis,embedded system",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Engineering,,,"FOOT,POSTURE,PLANTAR,PRESSURE,PAIN,WALKING,PLANUS",JOURNAL OF LOW POWER ELECTRONICS AND APPLICATIONS,https://idus.us.es/bitstream/11441/97767/1/jlpea-10-00014.pdf,
83,Burst Pressure Prediction of Cylindrical Vessels Using Artificial Neural Network,142,3,,"Zolfaghari Abolfazl,Izadi Moein","Zolfaghari A,Izadi M",Zolfaghari A,10.1115/1.4045729,Ohio State University,"Pressure vessel plays an important role in wide range of applications to store gas or liquid substances. In order to design a pressure vessel safely, one of the main factors which has to be considered is selection of proper burst pressure perdition criterion. Due to large range of available materials in manufacturing of the vessels under different working conditions, several criteria to forecast burst pressure of the vessels have been developed and used by designers. Choosing the most proper criterion based on working condition and the material is a vital task to meet design requirements because inappropriate criterion may lead to unsafe vessel or over design. This issue makes not only pressure vessel design more complex but also maintenance planning, especially for designers who do not have enough experience, is a challenging task. Therefore, lack of a burst pressure predictor model, which is able to determine the pressure more accurately for wide range of materials and applications, has been remained unsolved. To evaluate machine learning techniques in prediction of burst pressure of pressure vessels, in this paper, a new model based on artificial neural network (ANN) has been proposed and developed. Input parameters of the model include internal and outer diameter, thickness, ultimate and yield strength; output is burst pressure. The obtained results showed that the constructed model has a good potential to be used as more applicable model compared to current models in design of pressure vessels.","pressure vessel,burst pressure,machine learning,artificial neural network,safe design,data mining,statistical learning",Article,"ASME, TWO PARK AVE, NEW YORK, NY 10016-5990 USA",Engineering,,1.004,"FAILURE,PRESSURE,BEHAVIOR,FLOW",JOURNAL OF PRESSURE VESSEL TECHNOLOGY-TRANSACTIONS OF THE ASME,,
84,A knowledge-driven feature learning and integration method for breast cancer diagnosis on multi-sequence MRI,69,,40-48,"Feng Hongwei,Cao Jiaqi,Wang Hongyu,Xie Yilin,Yang Di,Feng Jun,Chen Baoying","Feng HW,Cao JQ,Wang HY,Xie YL,Yang D,Feng J,Chen BY",Wang HY,10.1016/j.mri.2020.03.001,Xi'an University of Posts & Telecommunications,"Background: The classification of benign versus malignant breast lesions on multi-sequence Magnetic Resonance Imaging (MRI) is a challenging task since breast lesions are heterogeneous and complex. Recently, deep learning methods have been used for breast lesion diagnosis with raw image input. However, without the guidance of domain knowledge, these data-driven methods cannot ensure that the features extracted from images are comprehensive for breast cancer diagnosis. Specifically, these features are difficult to relate to clinically relevant phenomena.
Purpose: Inspired by the cognition process of radiologists, we propose a Knowledge-driven Feature Learning and Integration (KFLI) framework, to discriminate between benign and malignant breast lesions using Multi-sequences MRI.
Methods: Starting from sequence division based on characteristics, we use domain knowledge to guide the feature learning process so that the feature vectors of sub-sequence are constrained to lie in characteristic-related semantic space. Then, different deep networks are designed to extract various sub-sequence features. Furthermore, a weighting module is employed for the integration of the features extracted from different subsequence images adaptively.
Results: The KFLI is a domain knowledge and deep network ensemble, which can extract sufficient and effective features from each sub-sequence for a comprehensive diagnosis of breast cancer. Experiments on 100 MRI studies have demonstrated that the KFLI achieves sensitivity, specificity, and accuracy of 84.6%, 85.7% and 85.0%, respectively, which outperforms other state-of-the-art algorithms.","Multi-sequence MRI,Breast cancer diagnosis,Deep learning,Feature learning,Knowledge-driven",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.608,"DCE-MRI,CLASSIFICATION,SEGMENTATION,LESION",MAGNETIC RESONANCE IMAGING,,
85,Identification and classification of materials using machine vision and machine learning in the context of industry 4.0,31,5,1229-1241,"Penumuru Durga Prasad,Muthuswamy Sreekumar,Karumbu Premkumar","Penumuru DP,Muthuswamy S,Karumbu P",Muthuswamy S,10.1007/s10845-019-01508-6,"Indian Institute of Information Technology, Design & Manufacturing, Kancheepuram","Manufacturing has experienced tremendous changes from industry 1.0 to industry 4.0 with the advancement of technology in fast-developing areas such as computing, image processing, automation, machine vision, machine learning along with big data and Internet of things. Machine tools in industry 4.0 shall have the ability to identify materials which they handle so that they can make and implement certain decisions on their own as needed. This paper aims to present a generalized methodology for automated material identification using machine vision and machine learning technologies to contribute to the cognitive abilities of machine tools as wells as material handling devices such as robots deployed in industry 4.0. A dataset of the surfaces of four materials (Aluminium, Copper, Medium density fibre board, and Mild steel) that need to be identified and classified is prepared and processed to extract red, green and blue color components of RGB color model. These color components are used as features while training the machine learning algorithm. Support vector machine is used as a classifier and other classification algorithms such as Decision trees, Random forests, Logistic regression, and k-Nearest Neighbor are also applied to the prepared data set. The capability of the proposed methodology to identify the different group of materials is verified with the images available in an open source database. The methodology presented has been validated by conducting four experiments for checking the classification accuracies of the classifier. Its robustness has also been checked for various camera orientations, illumination levels, and focal length of the lens. The results presented show that the proposed scheme can be implemented in an existing manufacturing setup without major modifications.","Industry 4,0,Image processing,Machine vision,Machine learning,Support vector machine",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,5.829,"NEURAL-NETWORK,SYSTEM",JOURNAL OF INTELLIGENT MANUFACTURING,,
86,Role of Data Analytics in Infrastructure Asset Management: Overcoming Data Size and Quality Problems,146,2,,"Piryonesi S. Madeh,El-Diraby Tamer E.","Piryonesi SM,El-Diraby TE",Piryonesi SM,10.1061/JPEODX.0000175,University of Toronto,"This study explores the performance regime of different classification algorithms as they are applied to the analysis of asphalt pavement deterioration data. The aim is to examine how different algorithms deal with the typically limited and low-quality data sets in the infrastructure asset management domain, and whether better configurations of relevant algorithms help overcome these limitations. Furthermore, the emphasis on choosing the most affordable attributes (e.g., temperature and precipitation levels) makes the results reproducible to smaller municipalities. This analysis used the data of more than 3,000 examples of road sections, which were retrieved from the Long-Term Pavement Performance (LTPP) database. The algorithms examined in this study include two types of decision trees, naive Bayes classifier, naive Bayes coupled with kernels, logistic regression, k-nearest neighbors (k-NN), random forest, and gradient boosted trees. The performance of these algorithms is compared, and their weaknesses and strengths are discussed. They were all applied to predict the deterioration of pavement condition index (PCI). Of specific importance is the positive role of ensemble learning. It is shown how using higher efficiencies by using ensemble learning can compensate for data shortcomings. The accuracy of some of the models in predicting the PCI after 3 years exceeded 90%. Suggestions are made to improve the performance of some algorithms. For instance, the naive Bayes classifier was coupled with kernel estimates to achieve a better accuracy. It is demonstrated that using kernel estimates can increase the accuracy of the naive Bayes classifier dramatically. Further, the study examines the impact of data segmentation. Data were divided into four different climatic regions. The accuracy of prediction was sufficiently high after segmentation, with the highest accuracy in the dry and nonfreeze zone and the lowest performance in the region with a wet and freezing climate.","Machine learning,Ensemble learning,Transportation asset management,Pavement condition index,Highway maintenance,Data preparation",Article,"ASCE-AMER SOC CIVIL ENGINEERS, 1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA","Engineering,Transportation",,1.8,"PAVEMENT,PERFORMANCE,CRACK,INITIATION,ROUGHNESS,MODEL,PREDICTION,REGRESSION,IRI,ANN",JOURNAL OF TRANSPORTATION ENGINEERING PART B-PAVEMENTS,,
87,Machine learning-optimized Tamm emitter for high-performance thermophotovoltaic system with detailed balance analysis,72,,,"Hu Run,Song Jinlin,Liu Yida,Xi Wang,Zhao Yiting,Yu Xingjian,Cheng Qiang,Tao Guangming,Luo Xiaobing","Hu R,Song JL,Liu YD,Xi W,Zhao YT,Yu XJ,Cheng Q,Tao GM,Luo XB",Hu R; Luo XB,10.1016/j.nanoen.2020.104687,Huazhong University of Science & Technology,"Light-matter interaction upon nanophotonic structures in the infrared wavelength has drew increasing attentions due to the extensive potential applications. Among them, thermophotovoltaic (TPV) systems can exhibit higher efficiency over the Shockley-Queisser limit due to the nanophotonic structure-enabled tunable narrowband thermal emission rather than the broadband incident spectrum. However, two long-standing issues remain formidable as bottlenecks for achieving better performances of TPV system. One is the competing role of the power density and the system efficiency of TPV system, and the other is the magnanimity possibilities of structures, configurations, dimensions, and materials of thermal emitters that disables the manual optimization of TPV system. Here, we attempt to achieve high-performance TPV system by employing the machine learning algorithm under the framework of material informatics. The power density and system efficiency are well modelled through the detailed balance analysis with full considering the photocurrent generation in the PV cells. Through optimization, the non-trial aperiodic Tamm emitters are obtained and the metal-side one is preferable in terms of the TPV performance. The present work is demonstrated to be feasible and efficient in optimizing the TPV performance, and opens a new door for the optimization problems in other fields.","Thermophotovoltaics,Tamm emitter,Machine learning,Optimization",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,17.631,"THERMAL,EMISSION,POLARITONS,DESIGN,CAVITY",NANO ENERGY,,
88,Metaheuristic-based inverse design of materials - A survey,6,2,414-430,"Liao T. Warren,Li Guoqiang","Liao TW,Li GQ",Liao TW,10.1016/j.jmat.2020.02.011,Louisiana State University System,"There is a growing interest in the inverse approach to material deign, in which the desired target properties are used as input to identify the atomic identity, composition and structure (ACS) that exhibit such properties. As an overview, this paper surveys and summarizes previous works in metaheuristic-based inverse design of various materials. The basics of metaheuristic-based inverse design of materials are presented, including feature identification (fingerprinting), machine learning of ACS -> property models (forward design), metaheuristic algorithms for property -> ACS predictions (inverse design), and experimental validations, with focus on inverse design. The past studies are organized into a two-level hierarchy with how properties are predicted at the higher level, either by first principles, simulation, or machine learning model, and the number of target properties considered at the lower level, either one or more than one. The uniqueness and limitation of previous research are discussed and several possible topics for future research are identified. This review intends to serve as the steppingstone/springboard for those interested in advancing this area of research. (C) 2020 The Chinese Ceramic Society. Production and hosting by Elsevier B.V.","Inverse design,Materials,Metaheuristics,Machine learning,Fingerprinting",Review,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Chemistry,Materials Science,Physics",,8.409,"ARTIFICIAL,BEE,COLONY,MULTIOBJECTIVE,GENETIC,ALGORITHM,SYMBIOTIC,ORGANISMS,SEARCH,HIGH-ENTROPY,ALLOYS,STRUCTURAL,OPTIMIZATION,PARTICLE,SWARM,TRIMETALLIC,NANOPARTICLES,EVOLUTIONARY,ALGORITHMS,DIFFERENTIAL,EVOLUTION,MATERIALS,DISCOVERY",JOURNAL OF MATERIOMICS,https://doi.org/10.1016/j.jmat.2020.02.011,
89,"Modeling mesoscale energy localization in shocked HMX, Part II: training machine-learned surrogate models for void shape and void-void interaction effects",30,4,349-371,"Roy S.,Rai N. K.,Sen O.,Hardin D. B.,Diggs A. S.,Udaykumar H. S.","Roy S,Rai NK,Sen O,Hardin DB,Diggs AS,Udaykumar HS",Udaykumar HS,10.1007/s00193-019-00931-1,University of Iowa,"Surrogate models for hotspot ignition and growth rates were presented in Part I (Nassar et al., Shock Waves 29(4):537-558, 2018), where the hotspots were formed by the collapse of single cylindrical voids. Such isolated cylindrical voids are idealizations of the void morphology in real meso-structures. This paper therefore investigates the effect of non-cylindrical void shapes and void-void interactions on hotspot ignition and growth. Surrogate models capturing these effects are constructed using a Bayesian Kriging approach. The training data for machine learning the surrogates are derived from reactive void collapse simulations spanning the parameter space of void aspect ratio, void orientation (theta)and void fraction (phi) The resulting surrogate models portray strong dependence of the ignition and growth rates on void aspect ratio and orientation, particularly when they are oriented at acute angles with respect to the imposed shock. The surrogate models for void interaction effects show significant changes in hotspot ignition and growth rates as the void fraction increases. The paper elucidates the physics of hotspot evolution in void fields due to the creation and interaction of multiple hotspots. The results from this work will be useful not only for constructing meso-informed macroscale models of HMX, but also for understanding the physics of void-void interactions and sensitivity due to void shape and orientation.","Energetic materials,Multiscale modeling,Mesoscale,Void-void interactions,Surrogate modeling,Machine learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Mechanics,,1.806,"DETONATION,INITIATION,HOT-SPOTS,COLLAPSE,SIMULATION,IMPACT,SPEED,PENETRATION,ALGORITHMS",SHOCK WAVES,http://arxiv.org/pdf/1903.09137,
90,Auto-encoder-based generative models for data augmentation on regression problems,24,11,7999-8009,Ohno Hiroshi,Ohno H,Ohno H,10.1007/s00500-019-04094-0,Toyota Central R&D Labs Inc,"Recently, auto-encoder-based generative models have been widely used successfully for image processing. However, there are few studies on the realization of continuous input-output mappings for regression problems. Lack of a sufficient amount of training data plagues regression problems, which is also a notable problem in machine learning, which affects its application in the field of materials science. Using variational auto-encoders (VAEs) as generative models for data augmentation, we address the issue of small data size for regression problems. VAEs are popular and powerful auto-encoder-based generative models. Generative auto-encoder models such as VAEs use multilayer neural networks to generate sample data. In this study, we demonstrate the effectiveness of multi-task learning (auto-encoding and regression tasks) relating to regression problems. We conducted experiments on seven benchmark datasets and on one ionic conductivity dataset as an application in materials science. The experimental results show that the multi-task learning for VAEs improved the generalization performance of multivariable linear regression model trained with augmented data.","Generative models,Multi-task learning,Variational auto-encoders,Multivariable linear regression,Materials informatics",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,3.518,NOISE,SOFT COMPUTING,,
91,Non-invasive tumor decoding and phenotyping of cerebral gliomas utilizing multiparametric F-18-FET PET-MRI and MR Fingerprinting,47,6,1435-1445,"Haubold Johannes,Demircioglu Aydin,Gratz Marcel,Glas Martin,Wrede Karsten,Sure Ulrich,Antoch Gerald,Keyvani Kathy,Nittka Mathias,Kannengiesser Stephan","Haubold J,Demircioglu A,Gratz M,Glas M,Wrede K,Sure U,Antoch G,Keyvani K,Nittka M,Kannengiesser S",Haubold J,10.1007/s00259-019-04602-2,University of Duisburg Essen,"Objectives The introduction of the 2016 WHO classification of CNS tumors has made the combined molecular and histopathological characterization of tumors a pivotal part of glioma patient management. Recent publications on radiogenomics-based prediction of the mutational status have demonstrated the predictive potential of imaging-based, non-invasive tissue characterization algorithms. Hence, the aim of this study was to assess the potential of multiparametric F-18-FET PET-MRI including MR fingerprinting accelerated with machine learning and radiomic algorithms to predict tumor grading and mutational status of patients with cerebral gliomas. Materials and methods 42 patients with suspected primary brain tumor without prior surgical or systemic treatment or biopsy underwent an F-18-FET PET-MRI examination. To differentiate the mutational status and the WHO grade of the cerebral tumors, support vector machine and random forest were trained with the radiomics signature of the multiparametric PET-MRI data including MR fingerprinting. Surgical sampling served as a gold standard for histopathological reference and assessment of mutational status. Results The 5-fold cross-validated area under the curve in predicting the ATRX mutation was 85.1%, MGMT mutation was 75.7%, IDH1 was 88.7%, and 1p19q was 97.8%. The area under the curve of differentiating low-grade glioma vs. high-grade glioma was 85.2%. Conclusion F-18-FET PET-MRI and MR fingerprinting enable high-quality imaging-based tumor decoding and phenotyping for differentiation of low-grade vs. high-grade gliomas and for prediction of the mutational status of ATRX, IDH1, and 1p19q. These initial results underline the potential of F-18-FET PET-MRI to serve as an alternative to invasive tissue characterization.","Glioma,IDH1,ATRX,1p19q,PET-MRI,Radiomics,FET PET,MR fingerprinting",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,8.391,"C-11-METHIONINE,PET,PROGNOSTIC,VALUE,HIGH-GRADE,PERFUSION,GENOTYPE",EUROPEAN JOURNAL OF NUCLEAR MEDICINE AND MOLECULAR IMAGING,,
92,Critical Temperature Prediction for a Superconductor: A Variational Bayesian Neural Network Approach,30,4,,"Thanh Dung Le,Noumeir Rita,Huu Luong Quach,Kim Ji Hyung,Kim Jung Ho,Kim Ho Min","Le TD,Noumeir R,Quach HL,Kim JH,Kim JH,Kim HM",Le TD,10.1109/TASC.2020.2971456,University of Quebec,"Much research in recent years has focused on using empirical machine learning approaches to extract useful insights on the structure-property relationships of superconductor material. Notably, these approaches are bringing extreme benefits when superconductivity data often come from costly and arduously experimental work. However, this assessment cannot be based solely on an open black-box machine learning, which is not fully interpretable, because it can be counter-intuitive to understand why the model may give an appropriate response to a set of input data for superconductivity characteristic analyses, e.g., critical temperature. The purpose of this study is to describe and examine an alternative approach for predicting the superconducting transition temperature T-c from SuperCon database obtained by Japan's National Institute for Materials Science. We address a generative machine-learning framework called Variational Bayesian Neural Network using superconductors chemical elements and formula to predict Tc. In such a context, the importance of the paper in focus is twofold. First, to improve the interpretability, we adopt a variational inference to approximate the distribution in latent parameter space for the generative model. It statistically captures the mutual correlation of superconductor compounds and; then, gives the estimation for the Tc. Second, a stochastic optimization algorithm, which embraces a statistical inference named Monte Carlo sampler, is utilized to optimally approximate the proposed inference model, ultimately determine and evaluate the predictive performance. As a result, in comparison with the standard evaluation metrics, the results are promising and also agree with the existing models prevalent in the field. The R-2 value obtained is very close to the best model (0.94), whereas a considerable improvement is seen in the RMSE value (3.83 K). Notably, the proposed model is known as the first of its kind for predicting a superconductor's Tc.","Critical transition temperature,machine learning,bayesian neural network,variational inference,stochastic optimization algorithm,high temperature superconducting (HTS)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Physics",,1.566,,IEEE TRANSACTIONS ON APPLIED SUPERCONDUCTIVITY,http://arxiv.org/pdf/2002.04977,
93,Fatigue life prediction of metallic materials considering mean stress effects by means of an artificial neural network,135,,,"Barbosa Joelton Fonseca,Correia Jose A. F. O.,Freire Junior R. C. S.,De Jesus Abilio M. P.","Barbosa JF,Correia JAFO,Freire  RCS,De Jesus AMP",Barbosa JF; Freire  RCS,10.1016/j.ijfatigue.2020.105527,Universidade Federal do Rio Grande do Norte,"The mean stress effect plays an important role in the fatigue life predictions, its influence significantly changes high-cycle fatigue behaviour, directly decreasing the fatigue limit with the increase of the mean stress. Fatigue design of structural details and mechanical components must account for mean stress effects in order to guarantee the performance and safety criteria during their foreseen operational life. The purpose of this research work is to develop a new methodology to generate a constant life diagram (CLD) for metallic materials, based on assumptions of Haigh diagram and artificial neural networks, using the probabilistic Stussi fatigue S-N fields. This proposed methodology can estimate the safety region for high-cycle fatigue regimes as a function of the mean stress and stress amplitude in regions where tensile loading is predominance, using fatigue S-N curves only for two stress R-ratios. In this approach, the experimental fatigue data of the P355NL1 pressure vessel steel available for three stress R-ratios ( - 1, - 0.5, 0), are used. A multilayer perceptron network has been trained with the back-propagation algorithm; its architecture consists of two input neurons (sigma(m), N) and one output neuron (sigma(a)). The suggested CLD based on trained artificial neural network algorithm and probabilistic Stussi fatigue fields applied to dog-bone shaped specimens made of P355NL1 steel showed a good agreement with the high-cycle fatigue experimental data, only using the stress R-ratios equal to 0 and -0.5. Furthermore, a procedure for estimating the fatigue resistance reduction factor, K-f, for the fatigue life prediction of structural details (stress R-ratios equal to 0, 0.15 and 0.3) in extrapolation regions is suggested and used to generate the K-f results for stress R-ratios from -1 to 0.3, based on machine learning artificial neural network algorithm.","Fatigue,Artificial neural network,Back-propagation algorithm,Stussi model,Constant life diagram",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Materials Science",,4.946,"HIGH-CYCLE,FATIGUE,TENSILE,LIMIT,MODEL",INTERNATIONAL JOURNAL OF FATIGUE,,
94,NOx removal efficiency of urban photocatalytic pavements at pilot scale,719,,,"Cordero J. M.,Hingorani R.,Jimenez-Relinque E.,Grande M.,Borge R.,Narros A.,Castellote M.","Cordero JM,Hingorani R,Jimenez-Relinque E,Grande M,Borge R,Narros A,Castellote M",Cordero JM,10.1016/j.scitotenv.2020.137459,Universidad Politecnica de Madrid,"Photocatalytic technology implemented in construction materials is a promising solution to contribute to alleviate air quality issues found in big cities. Photocatalysis has been proved able to mineralise most harmful contaminants. However, important problems associated with monitoring the efficiency of these solutions under real conditions still remain, including the lack of affordable analytical tools to measure NOx concentrations with enough accuracy. In this work, two pilot scale demonstration platforms were built at two different locations to assess the photocatalytic NOx removal efficiency of ten selected materials exposed outdoors for AQmesh low-cost sensor PODs were used to measure ground-level to measure NO and NO2 concentrations during nearly one year. The pollutant removal efficiency of the materials was then calculated based on a comparison with simultaneously concentration measurements carried-out on reference, non-active materials. It was found that the NO2 removal efficiency presented large variations across the seasons, with maxima during the warmer months, while NO efficiencies were comparatively steadier. Statistical analysis delivered evidence that the efficiencies significantly depend on different meteorological variables (irradiance and relative humidity) besides NO, NO2 ambient concentrations. Lower efficiencies were observed for higher concentration levels and vice versa. The influence of water vapour could be related to two different effects: a short-term contribution by the instantaneous air humidity and a long-term component associated with the hygroscopic state of the material. The contribution of wind to the pollutant removal efficiencies was principally related to the humidity of air masses moving above the location and to the advection of pollutants from specific emission sources. (C) 2020 Elsevier B.V. All rights reserved.","Air quality,Heterogeneous photocatalysis,Construction materials,NOx removal efficiency,Machine teaming,Environmental variables",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Environmental Sciences & Ecology,,7.842,"AIR-POLLUTION,CEMENTITIOUS,MATERIALS,GAS,SENSORS,DEGRADATION,OXIDATION,OXIDE,CALIBRATION,KINETICS,BEHAVIOR,CLUSTER",SCIENCE OF THE TOTAL ENVIRONMENT,,
95,Modeling stress-strain curves with neural networks: a scalable alternative to the return mapping algorithm,178,,,"du Bos Maxime Lavech,Balabdaoui Fadoua,Heidenreich Julian N.","du Bos ML,Balabdaoui F,Heidenreich JN",Balabdaoui F,10.1016/j.commatsci.2020.109629,ETH Zurich,"Modeling stress-strain curves in mechanics of material needs deriving suitable constitutive equations and solving those equations using some Euler-like scheme in th more general setting of a return mapping algorithm. However, such an approach which is based on establishing a framework that is thermodynamically consistent and physically motivated may require a substantial theoretical and experimental work. In order to bypass this traditional scheme, we consider an alternative data-driven approach motivated by tools developed in the larger scope of machine learning. In particular, we show how feedforward neural networks have the ability to accurately model stress-strain relationships for an isotropic and rate independent elastoplastic solid. Taking into account the experimental cost of producing many measurements and the computational cost associated with the training of neural networks, we elaborate a full end-to-end methodology to model stress-strain curves with neural networks in a low-data regime.","Neural Networks,Return Mapping Algorithm,Constitutive Equations",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,,BEHAVIOR,COMPUTATIONAL MATERIALS SCIENCE,,
96,"Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI",58,,82-115,"Barredo Arrieta Alejandro,Diaz-Rodriguez Natalia,Del Ser Javier,Bennetot Adrien,Tabik Siham,Barbado Alberto,Garcia Salvador,Gil-Lopez Sergio,Molina Daniel,Benjamins Richard","Arrieta AB,Diaz-Rodriguez N,Del Ser J,Bennetot A,Tabik S,Barbado A,Garcia S,Gil-Lopez S,Molina D,Benjamins R",Del Ser J,10.1016/j.inffus.2019.12.012,"TECNALIA, P Tecnol,Ed 700, Derio 48160, Bizkaia, Spain.","In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.","Explainable Artificial Intelligence,Machine Learning,Deep Learning,Data Fusion,Interpretability,Comprehensibility,Transparency,Privacy,Fairness,Accountability,Responsible Artificial Intelligence",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,12.707,"GENERALIZED,ADDITIVE-MODELS,TRAINED,NEURAL-NETWORKS,SUPPORT,VECTOR,MACHINES,RULE,EXTRACTION,LOGISTIC-REGRESSION,DATA,FUSION,BLACK-BOX,DECISION,TREES,BIG,DATA,FEATURE-SELECTION",INFORMATION FUSION,http://arxiv.org/pdf/1910.10045,
97,Predicting autism spectrum disorder from associative genetic markers of phenotypic groups using machine learning,12,3,3257-3270,"Sekaran Karthik,Sudha M.","Sekaran K,Sudha M",Sudha M,10.1007/s12652-020-02155-z,Vellore Institute of Technology,"Machine learning is a discipline of artificial intelligence, geared towards the development of various critical applications. Due to its high precision, it is widely adopted in the process of extracting useful hidden patterns and valuable insights from complex data structures. Data extracted from the real-time environment might contain some irrelevant information. The presence of noise in the data degrades the model performance. Gene expression is an important source, carries the genetic information of species. Gene expression pattern reveals the significant relationship between genes associated with several diseases. But due to irregular molecular interactions and reactions occurs during the transcription process, the gene expressions are minimally affected. It causes a detrimental effect on the identification of biological markers of the diseases. To address this problem, a novel gene selection strategy is proposed to identify the candidate gene biomarkers from the genomic data. Signal to Noise ratio with logistic sigmoid function, Hilbert-Schmidt Independence Criterion Lasso, and regularized genetic algorithm amalgamation finds the optimal features. The proposed system is tested with the microarray gene expression dataset of autism spectrum disorder (ASD), accessed from gene expression omnibus repository. FAM104B, CCNDBP1, H1F0, ZER1 are identified as the candidate biomarkers of ASD. The methodical performance evaluation of the proposed model is examined with widely used machine learning algorithms. The proposed methodology enhanced the prediction rate of ASD and attained an accuracy of 97.62%, outperformed existing methods. Also, this system could act as a significant tool to assist the medical practitioners for accurate ASD diagnosis.","Autism spectrum disorder,Biomarkers,Dimensionality reduction,Hilbert-schmidt independence criterion lasso,Machine learning,Regularized genetic algorithm",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Telecommunications",,,"FEATURE-SELECTION,CLASSIFICATION,EXPRESSION,CHILDREN,MODEL",JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING,,
98,Intelligent methods for root cause analysis behind the center line deviation of the steel strip,10,1,386-393,"Tiensuu Henna,Tamminen Satu,Haapala Olli,Roning Juha","Tiensuu H,Tamminen S,Haapala O,Roning J",Tiensuu H,10.1515/eng-2020-0041,University of Oulu,"This article presents a statistical prediction model-based intelligent decision support tool for center line deviation monitoring. Data mining methods enable the data driven manufacturing. They also help to understand the manufacturing process and to test different hypotheses. In this study, the original assumption was that the shape of the strip during the hot rolling has a strong effect on the behaviour of the steel strip in Rolling, Annealing and Pickling line (RAP). Our goal is to provide information that enables to react well in advance to strips with challenging shape. In this article, we show that the most critical shape errors arising in hot rolling process will be transferred to critical errors in RAP-line process as well. In addition, our results reveal that the most critical feature characterizes the deviation better than the currently used criterion for rework. The developed model enables the user to understand better the quality of the products, how the process works, and how the quality model predicts and performs.","smart decision support,data driven manufacturing,machine learning,steel strip rolling,GBM",Article,"DE GRUYTER POLAND SP Z O O, BOGUMILA ZUGA 32A STR, 01-811 WARSAW, MAZOVIA, POLAND",Engineering,,,,OPEN ENGINEERING,https://www.degruyter.com/document/doi/10.1515/eng-2020-0041/pdf,
99,Parallel deep convolutional neural network for content based medical image retrieval,12,1,781-795,"Haripriya P.,Porkodi R.","Haripriya P,Porkodi R",Haripriya P,10.1007/s12652-020-02077-w,Bharathiar University,"DICOM images which helps in diagnosis and prognosis would be critical component in health care systems. Speedy recovery of past historic DICOM images based on the given query image is becoming a critical requirement for the Laboratories and Doctors for quick inference and accurate analogy of the patient conditions. In existing, It is also identified that there is a presence of imbalanced data set which degrade the retrieval accuracy of the model which may reduce by using extract the different kinds of features. The DCNN classifiers are trained by datasets whose data distributions of individual classes are not even or similar, they have always suffered from imbalanced classification performance against classes. Through DCNN can be used to minimize the gaps in terms of accuracy and retrieval but still efficiency parallelization would be essential for faster training and retrieval time. Time complexity is always been a major issue in DCNN, to overcome the above complexity the parallelization of model or data dimension need to be adapted. In this paper, parallel deep convolutional neural network (PDCNN) model is proposed by hyper parameter optimimzation for CBMIR system. The proposed model incorporating the low level content features, high level semantic features and compact features along with DCNN features to tackle the imbalanced dataset problem and reducing the DCNN training time for DICOM images. The high-level and compact features are extracted to resolve the imbalanced dataset problem by using the following algorithms: (a) local binary pattern (LBP), (b) histogram of oriented gradients (HOG) and (c) radon. The data parallelism was adopted in the proposed DCNN model to reduce the network training time by execution of DCNN layers across multiple CPU cores on a single PC. The implementation results for the proposed model in terms of Precision, Recall and F measure values are 87%, 87% and 92% respectively.","Deep convolutional neural network,Deep learning,Parallelization,Overlapping",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Telecommunications",,,GRAY-SCALE,JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING,,
100,Artificial intelligence neural network based on intelligent diagnosis,12,1,923-931,Li Xiren,Li XR,Li XR,10.1007/s12652-020-02108-6,Shanghai University,"The medical model that uses artificial intelligence technology to assist diagnosis and treatment is called smart medicine. It can learn the medical knowledge of experts, and can simulate the thinking and reasoning of doctors to give patients a reliable diagnosis and treatment plan. The purpose of this article is to help young doctors with uneven distribution of medical resources and insufficient experience by exploring the application of artificial intelligence neural networks in the intelligent diagnosis of diabetes. This paper proposes to use BP neural network and probabilistic neural network to model diabetes diagnosis. First, the number of hidden layer units of BP network is selected according to the input feature vector. The training effect is best when the number of hidden layer units is 12, and the diagnostic accuracy rate is 91.7% through experiments. Then built a PNN network model, using 75% of the data for training, 25% of the data for testing, and testing the effectiveness of the network model. The diagnostic accuracy was 97.9%. Finally, the accuracy of the 20 neural network models was tested 20 times. After a comparative analysis, it is concluded that the PNN network model is better than the BP neural network model in terms of performance and accuracy. Compared with the traditional diagnosis process, the neural network-based diagnosis model can effectively save doctors time and improve diagnosis efficiency.","Artificial intelligence,Diagnosis of diabetes,BP neural network,Probabilistic neural network,Intelligent diagnosis",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Telecommunications",,6.163,,JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING,,
