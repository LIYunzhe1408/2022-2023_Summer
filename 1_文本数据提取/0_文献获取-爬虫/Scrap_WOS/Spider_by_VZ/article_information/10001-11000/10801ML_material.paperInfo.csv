,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Prediction model construction of mouse stem cell pluripotency using CpG and non-CpG DNA methylation markers,21,1,,"Joe Soobok,Nam Hojung","Joe S,Nam H",Nam H,10.1186/s12859-020-3448-3,Gwangju Institute of Science & Technology (GIST),"Background Genome-wide studies of DNA methylation across the epigenetic landscape provide insights into the heterogeneity of pluripotent embryonic stem cells (ESCs). Differentiating into embryonic somatic and germ cells, ESCs exhibit varying degrees of pluripotency, and epigenetic changes occurring in this process have emerged as important factors explaining stem cell pluripotency. Results Here, using paired scBS-seq and scRNA-seq data of mice, we constructed a machine learning model that predicts degrees of pluripotency for mouse ESCs. Since the biological activities of non-CpG markers have yet to be clarified, we tested the predictive power of CpG and non-CpG markers, as well as a combination thereof, in the model. Through rigorous performance evaluation with both internal and external validation, we discovered that a model using both CpG and non-CpG markers predicted the pluripotency of ESCs with the highest prediction performance (0.956 AUC, external test). The prediction model consisted of 16 CpG and 33 non-CpG markers. The CpG and most of the non-CpG markers targeted depletions of methylation and were indicative of cell pluripotency, whereas only a few non-CpG markers reflected accumulations of methylation. Additionally, we confirmed that there exists the differing pluripotency between individual developmental stages, such as E3.5 and E6.5, as well as between induced mouse pluripotent stem cell (iPSC) and somatic cell. Conclusions In this study, we investigated CpG and non-CpG methylation in relation to mouse stem cell pluripotency and developed a model thereon that successfully predicts the pluripotency of mouse ESCs.","DNA-methylation,Stem cell pluripotency,Non-CpG methylation",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,"EPIGENETIC,REGULATION,DIFFERENTIATION,REGRESSION,SELECTION",BMC BIOINFORMATICS,https://europepmc.org/articles/pmc7199378?pdf=render,
2,Investigation of mechanical factor of soil reinforced with four types of fibers: An integrated experimental and extreme learning machine approach,17,5,650-664,"Garg Ankit,Bordoloi Sanandam,Mondal Somnath,Ni Jun-Jun,Sreedeep S.","Garg A,Bordoloi S,Mondal S,Ni JJ,Sreedeep S",Ni JJ,10.1080/15440478.2018.1521763,Hong Kong University of Science & Technology,"This study investigates and compares mechanical factor (a dimensionless parameter and defined as the ratio of the compressive strength of fiber reinforced soil to that of unreinforced soil) for soils reinforced with four different fibers (three natural fibers and one synthetic fiber). An integrated methodology was utilized, including 351 laboratory experiments for obtaining data and Extreme Learning Machine (ELM) technique for developing functional relationships between mechanical factor and soil and fiber parameters. Soils reinforced with synthetic fiber (Polypropylene) and with natural fibers exhibited different characteristics when subjected to the same variation in soil parameters. This phenomenon can be attributed to the differences in surface morphology and water absorption capability of Polypropylene comparative to other natural fibers. Polypropylene-soil composite shows the maximum sensitivity to the soil moisture. It also shows the least sensitivity toward soil density and fiber content among all tested fiber-soil composites.","Extreme learning machine,reinforced soil,mechanical factor,natural fibers,synthetic fibers",Article,"TAYLOR & FRANCIS INC, 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA",Materials Science,,4.183,"COIR,FIBER,BEHAVIOR,STRENGTH,DESIGN,MODEL,WEED",JOURNAL OF NATURAL FIBERS,,
3,Multi-view deep learning for rigid gas permeable lens base curve fitting based on Pentacam images,58,7,1467-1482,"Hashemi Sara,Veisi Hadi,Jafarzadehpur Ebrahim,Rahmani Rouhollah,Heshmati Zainabolhoda","Hashemi S,Veisi H,Jafarzadehpur E,Rahmani R,Heshmati Z",Veisi H,10.1007/s11517-020-02154-4,University of Tehran,"Many studies in the rigid gas permeable (RGP) lens fitting field have focused on providing the best fit for patients with irregular astigmatism, a challenging issue. Despite the ease and accuracy of fitting in the current fitting methods, no studies have provided a high-pace solution with the final best fit to assist experts. This work presents a deep learning solution for identifying features in Pentacam four refractive maps and RGP base curve identification. An authentic dataset of 247 samples of Pentacam four refractive maps was gathered, providing a multi-view image of the corneal structure. Scratch-based convolutional neural network (CNN) architectures and well-known CNN architectures such as AlexNet, GoogLeNet, and ResNet have been used to extract features and transfer learning. Features are aggregated through a fusion technique. Based on a comparison of means square error (MSE) of normalized labels, the multi-view scratch-based CNN provided R-squared of 0.849, 0.846, 0.835, and 0.834 followed by GoogLeNet, comparable with current methods. Transfer learning outperforms various scratch-based CNN models, through which proper specifications some scratch-based models were able to increase coefficient of determinations. CNNs on multi-view Pentacam images have enabled fast detection of the RGP lens base curve, higher patient satisfaction, and reduced chair time.","Transfer learning,Multi-view convolutional neural network,Image analysis,RGP lens base curve fitting",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"CONVOLUTIONAL,NEURAL-NETWORKS,CLASSIFICATION,TOPOGRAPHER,SOFTWARE",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
4,Recognition of positive and negative valence states in children with autism spectrum disorder (ASD) using discrete wavelet transform (DWT) analysis of electrocardiogram signals (ECG),12,1,405-416,"Bagirathan Anandhi,Selvaraj Jerritta,Gurusamy Anusuya,Das Himangshu","Bagirathan A,Selvaraj J,Gurusamy A,Das H",Selvaraj J,10.1007/s12652-020-01985-1,"Vels Institute of Science, Technology & Advanced Studies","Children with autism spectrum disorder (ASD) are deficit in communication, social skills, empathy, emotional responsiveness and have significant behavioral pattern. They have difficulty in understanding other feelings and their own emotions. This leads to the sudden emotional outburst and aggressive behavior in these children. Parents, caretakers and doctors find it very difficult to prevent such extreme behaviors. Learning the positive and negative valence leads in determining the early indications before the onset of emotional outbursts in children with ASD. The present study measures the psycho physiological electrocardiogram (ECG) signal from the typically developed (TD) children and children with ASD in the age group of 5-11 years. Personalized protocol was developed for every child with ASD to induce positive and negative valence and ECG data was collected using wearable Shimmer ECG device. The heart rate variability (HRV) and the QRS amplitude were derived from ECG signal using Pan-Tompkins algorithm and eleven features were extracted using DWT (db2, db4 and db8) mother wavelet. The significant features of ECG, HRV and QRS amplitude were classified using the K nearest neighbor (KNN), support vector machine (SVM) and ensemble classifier. Ensemble and KNN classifier achieved maximum accuracy of 81% and 76.2% for children with ASD and Ensemble and SVM classifiers obtained maximum accuracy of 87.4% and 83.8% for TD children using HRV data.","Autism spectrum disorder (ASD),Heart rate variability (HRV),Pan-Tompkins algorithm,K nearest neighbor (KNN)",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Telecommunications",,6.163,"EMOTION,RECOGNITION,PARKINSONS-DISEASE,FACIAL,EXPRESSION,YOUNG-CHILDREN,RESPONSES,AROUSAL,EEG,FEATURES,SYSTEM",JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING,,
5,ML Lifecycle Canvas: Designing Machine Learning-Empowered UX with Material Lifecycle Thinking,35,5-6,362-386,"Zhou Zhibin,Sun Lingyun,Zhang Yuyang,Liu Xuanhui,Gong Qing","Zhou ZB,Sun LY,Zhang YY,Liu XH,Gong Q",Sun LY,10.1080/07370024.2020.1736075,"Key Lab Design Intelligence & Digital Creat Zheji, Hangzhou, Peoples R China.","As a particular type of artificial intelligence technology, machine learning (ML) is widely used to empower user experience (UX). However, designers, especially the novice designers, struggle to integrate ML into familiar design activities because of its ever-changing and growable nature. This paper proposes a design method called Material Lifecycle Thinking (MLT) that considers ML as a design material with its own lifecycle. MLT encourages designers to regard ML, users, and scenarios as three co-creators who cooperate in creating ML-empowered UX. We have developed ML Lifecycle Canvas (Canvas), a conceptual design tool that incorporates visual representations of the co-creators and ML lifecycle. Canvas guides designers to organize essential information for the application of MLT. By involving design students in the ""research through design"" process, the development of Canvas was iterated through its application to design projects. MLT and Canvas have been evaluated in design workshops, with completed proposals and evaluation results demonstrating that our work is a solid step forward in bridging the gap between UX and ML.","Design method,machine learning,user experience,design tool",Article,"TAYLOR & FRANCIS INC, 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA",Computer Science,,5.362,"INTELLIGENCE,AUTOMATION,COMPLEX,TRUST",HUMAN-COMPUTER INTERACTION,,
6,A novel super-resolution CT image reconstruction via semi-supervised generative adversarial network,32,18,14563-14578,"Jiang Xin,Liu Mingzhe,Zhao Feixiang,Liu Xianghe,Zhou Helen","Jiang X,Liu MZ,Zhao FX,Liu XH,Zhou HL",Jiang X,10.1007/s00521-020-04905-8,Chengdu University of Technology,"Reconstruction of super-resolution CT images using deep learning requires a large number of high-resolution images. However, high-resolution images are often limited to access due to CT performance and operation factors. In this paper, a new semi-supervised generative adversarial network is presented to accurately recover high-resolution CT images from low-resolution counterparts. We use a deep unsupervised network of 16 residual blocks to design the generator and build a discriminator based on a supervised network. We also apply a parallel 1 x 1 convolution operation to reduce the dimensionality of each hidden layer's output. Four types of loss functions are presented to build a new one for enforcing the mappings between the generator and discriminator. The bulk specification layer in the commonly used residual network is removed to construct a new type of residual network. In terms of experiments, we conduct an objective and subjective comprehensive evaluation with several state-of-the-art methods. The comparison results show that our proposed network has better advantages in super-resolution image reconstruction.","Super-resolution,Computed tomography images,Residual blocks,Generative adversarial network",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"HASHING-BASED,APPROACH,SERVICE,RECOMMENDATION,RESOLUTION",NEURAL COMPUTING & APPLICATIONS,,
7,Hybrid descriptor for placental maturity grading,79,29-30,21223-21239,"Lei Baiying,Jiang Feng,Zhou Feng,Ni Dong,Yao Yuan,Chen Siping,Wang Tianfu","Lei BY,Jiang F,Zhou F,Ni D,Yao Y,Chen SP,Wang TF",Wang TF,10.1007/s11042-019-08489-x,Shenzhen University,"Placental maturity grading (PMG) is quite essential to assess fetal growth and maternal health. To this date, PMG has mostly relied on the subjective judgment of the clinician, which is time-consuming and may cause wrong estimation due to redundancy and repeatability of the process. To tackle it, we propose an automatic method to stage placental maturity via deep hybrid descriptors based on B-mode ultrasound (BUS) and color Doppler energy (CDE) images. Specifically, convolutional descriptors extracted from multiple deep convolutional neural networks (DCNNs) and hand-crafted features are integrated to get the hybrid descriptors for grading performance boosting. First, different models with various feature layers are combined to obtain hybrid descriptors from images. Second, the transfer learning strategy is also utilized to enhance the grading performance via the deeply represented features. Third, extracted descriptors are encoded by Fisher vector (FV). Finally, we use support vector machine (SVM) as the classifier to grade placental maturity. The experimental results demonstrate that our proposed method could achieve good performance in PMG.","Placental maturity grading,Convolutional neural networks,Hybrid descriptors,Fisher vector,Color Doppler energy imaging",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"ULTRASOUND,GROWTH,CLASSIFICATION",MULTIMEDIA TOOLS AND APPLICATIONS,,
8,Photoacoustic optical semiconductor characterization based on machine learning and reverse-back procedure,52,5,,"Djordjevic K. Lj,Galovic S. P.,Jordovic-Pavlovic M. I,Nesic M. V,Popovic M. N.,Cojbasic Z. M.,Markushev D. D.","Djordjevic KL,Galovic SP,Jordovic-Pavlovic MI,Nesic MV,Popovic MN,Cojbasic ZM,Markushev DD",Djordjevic KL,10.1007/s11082-020-02373-x,University of Belgrade,"This paper introduces the possibility of the determination of optical absorption and reflexivity coefficient of silicon samples using neural networks and reverse-back procedure based on the photoacoustics response in the frequency domain. Differences between neural network predictions and parameters obtained with standard photoacoustic signal correction procedures are used to adjust our experimental set-up due to the instability of the optical excitation source and the state (contamination) of the illuminated surface. It has been shown that the changes of the optical absorption values correspond to the light source wavelength fluctuations, while changes in the reflexivity coefficient, obtained in this way, correspond to the small effect of the ultrathin layer formation of SiO2 due to the natural process of surface oxidation.","Photoacoustic,Semiconductors,Artificial neural networks,Thermal diffusion,Thermal expansion,Photothermal,Inverse problem,n-type silicon,Reverse-back procedure",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Engineering,Physics,Optics",,,,OPTICAL AND QUANTUM ELECTRONICS,,
9,Transfer Learning with Deep Convolutional Neural Network (CNN) for Pneumonia Detection Using Chest X-ray,10,9,,"Rahman Tawsifur,Chowdhury Muhammad E. H.,Khandakar Amith,Islam Khandaker R.,Islam Khandaker F.,Mahbub Zaid B.,Kadir Muhammad A.,Kashem Saad","Rahman T,Chowdhury MEH,Khandakar A,Islam KR,Islam KF,Mahbub ZB,Kadir MA,Kashem S",Chowdhury MEH,10.3390/app10093233,Qatar University,"Pneumonia is a life-threatening disease, which occurs in the lungs caused by either bacterial or viral infection. It can be life-endangering if not acted upon at the right time and thus the early diagnosis of pneumonia is vital. The paper aims to automatically detect bacterial and viral pneumonia using digital x-ray images. It provides a detailed report on advances in accurate detection of pneumonia and then presents the methodology adopted by the authors. Four different pre-trained deep Convolutional Neural Network (CNN): AlexNet, ResNet18, DenseNet201, and SqueezeNet were used for transfer learning. A total of 5247 chest X-ray images consisting of bacterial, viral, and normal chest x-rays images were preprocessed and trained for the transfer learning-based classification task. In this study, the authors have reported three schemes of classifications: normal vs. pneumonia, bacterial vs. viral pneumonia, and normal, bacterial, and viral pneumonia. The classification accuracy of normal and pneumonia images, bacterial and viral pneumonia images, and normal, bacterial, and viral pneumonia were 98%, 95%, and 93.3%, respectively. This is the highest accuracy, in any scheme, of the accuracies reported in the literature. Therefore, the proposed study can be useful in more quickly diagnosing pneumonia by the radiologist and can help in the fast airport screening of pneumonia patients.","pneumonia,bacterial and viral pneumonia,chest X-ray,deep learning,transfer learning,image processing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"VIRAL,PNEUMONIA,DIFFERENTIATION,RADIOGRAPHS,PREDICTION,DIAGNOSIS",APPLIED SCIENCES-BASEL,http://arxiv.org/pdf/2004.06578,
10,Segmentation of Intracranial Hemorrhage Using Semi-Supervised Multi-Task Attention-Based U-Net,10,9,,"Wang Justin L.,Farooq Hassan,Zhuang Hanqi,Ibrahim Ali K.","Wang JL,Farooq H,Zhuang HQ,Ibrahim AK",Ibrahim AK,10.3390/app10093297,State University System of Florida,"Intracranial Hemorrhage (ICH) has high rates of mortality, and risk factors associated with it are sometimes nearly impossible to avoid. Previous techniques to detect ICH using machine learning have shown some promise. However, due to a limited number of labeled medical images available, which often causes poor model accuracy in terms of the Dice coefficient, there is much to be improved. In this paper, we propose a modified u-net and curriculum learning strategy using a multi-task semi-supervised attention-based model, initially introduced by Chen et al., to segment ICH sub-groups from CT images. Using a modified inverse-sigmoid-based curriculum learning training strategy, we were able to stabilize Chen's algorithm experimentally. This semi-supervised model produced higher Dice coefficient values in comparison to a supervised counterpart, regardless of the amount of labeled data used to train the model. Specifically, when training with 80% of the ground truth data, our semi-supervised model produced a Dice coefficient of 0.67, which was higher than 0.61, obtained by a comparable supervised model. This result also surpassed by a greater margin the one obtained by using the out-of-the-box u-net by Hssayeni et al.","segmentation,semi-supervised,ICH,hemorrhage,u-net,attention,curriculum",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,,CT,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/9/3297/pdf,
11,Application of Improved LightGBM Model in Blood Glucose Prediction,10,9,,"Wang Yan,Wang Tao","Wang Y,Wang T",Wang T,10.3390/app10093227,Lanzhou University of Technology,"In recent years, with increasing social pressure and irregular schedules, many people have developed unhealthy eating habits, which has resulted in an increasing number of patients with diabetes, a disease that cannot be cured under the current medical conditions, and can only be mitigated by early detection and prevention. A lot of human and material resources are required for the detection of the blood glucose of a large number of people in medical examination, while the integrated learning model based on machine learning can quickly predict the blood glucose level and assist doctors in treatment. Therefore, an improved LightGBM model based on the Bayesian hyper-parameter optimization algorithm is proposed for the prediction of blood glucose, namely HY_LightGBM, which optimizes parameters using a Bayesian hyper-parameter optimization algorithm based on LightGBM. The Bayesian hyper-parameter optimization algorithm is a model-based method for finding the minimum value of the function so as to obtain the optimal parameters of the LightGBM model. Experiments have demonstrated that the parameters obtained by the Bayesian hyper-parameter optimization algorithm are superior to those obtained by a genetic algorithm and random search. The improved LightGBM model based on the Bayesian hyper-parameter optimization algorithm achieves a mean square error of 0.5961 in blood glucose prediction, with a higher accuracy than the XGBoost model and CatBoost model.","blood glucose prediction,integrated learning,LightGBM,Bayesian super parameter optimization",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"GENETIC,ALGORITHM,CLASSIFICATION,OPTIMIZATION,PLASMA",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/9/3227/pdf,
12,Machine-Learning Based Hybrid-Feature Analysis for Liver Cancer Classification Using Fused (MR and CT) Images,10,9,,"Naeem Samreen,Ali Aqib,Qadri Salman,Mashwani Wali Khan,Tairan Nasser,Shah Habib,Fayaz Muhammad,Jamal Farrukh,Chesneau Christophe,Anam Sania","Naeem S,Ali A,Qadri S,Mashwani WK,Tairan N,Shah H,Fayaz M,Jamal F,Chesneau C,Anam S",Mashwani WK,10.3390/app10093134,Kohat University of Science & Technology,"The purpose of this research is to demonstrate the ability of machine-learning (ML) methods for liver cancer classification using a fused dataset of two-dimensional (2D) computed tomography (CT) scans and magnetic resonance imaging (MRI). Datasets of benign (hepatocellular adenoma, hemangioma, cyst) and malignant (hepatocellular carcinoma, hepatoblastoma, metastasis) liver cancer were acquired at Bahawal Victoria Hospital (BVH), Bahawalpur, Pakistan. The final dataset was generated by fusion of 1200 (100 x 6 x 2) MR and CT-scan images, 200 (100 MRI and 100 CT-scan) images size 512 x 512 for each class of cancer. The acquired dataset was preprocessed by employing the Gabor filters to reduce the noise and taking an automated region of interest (ROIs) using an Otsu thresholding-based segmentation approach. The preprocessed dataset was used to acquire 254 hybrid-feature data for each ROI, which is the combination of the histogram, wavelet, co-occurrence, and run-length features, while 10 optimized hybrid features were selected by employing (probability of error plus average correlation) feature selection technique. For classification, we deployed this optimized hybrid-feature dataset to four ML classifiers: multilayer perceptron (MLP), support vector machine (SVM), random forest (RF), and J48, using a ten fold cross-validation method. MLP showed an overall accuracy of (95.78% on MRI and 97.44% on CT). Unfortunately, the obtained results were not promising, and there were some limitations due to the different modalities of the dataset. Thereafter, a fusion of MRI and CT-scan datasets generated the fused optimized hybrid-feature dataset. The MLP has shown a promising accuracy of 99% among all the deployed classifiers.","liver cancer,Otsu thresholding-based segmentation,fused optimized hybrid features,multilayer perceptron",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"UPDATE,FUSION",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/9/3134/pdf,
13,Mineral Raman Spectral Recognition Based on Siamese Network,57,9,,"Wu Chengwei,Shi Rujin,Zeng Wandan","Wu CW,Shi RJ,Zeng WD",Zeng WD,10.3788/LOP57.093301,Shanghai Institute of Technology,"Mineral identification is a critical task in geological surveys and in many engineering applications. Compared to the physical methods and chemical methods, Raman spectroscopy provides a faster qualitative and quantitative analysis, and most importantly, its damage to the original mineral is negligible in mineral analysis. But the data analysis based on Raman spectroscopy, results of traditional machine learning methods do not work well, especially in the case of minerals with a large categories. This paper proposes a similarity learning method based on Siamese network. After optimizing the negative samples by Hungarian algorithm, and compared with traditional models, we achieve the best robust results. What Siamese network computes is the similarity between minerals, in addition to the identification of minerals, it can also provide a reference for the alternative materials of the mineral to some extent.","vision,Raman spectroscopy,machine learning,Siamese network,similarity learning,mineral analysis",Article,"SHANGHAI INST OPTICS & FINE MECHANICS, CHINESE ACAD SCIENCE,  390, QINGHE LU, SHANGHAI, JIADING-QU, PEOPLES R CHINA","Engineering,Optics",,,,LASER & OPTOELECTRONICS PROGRESS,,
14,Automated classification of indoor environmental quality control using stacked ensembles based on electroencephalograms,35,5,448-464,"Kim Jimin,Kim Hakpyeong,Hong Taehoon","Kim J,Kim H,Hong T",Hong T,10.1111/mice.12515,Yonsei University,"This study aims to develop an automated classification of indoor air quality control using the machine learning based on an electroencephalogram (EEG) signal. Two experiments were conducted: The first aimed to select an EEG channel based on the brain wave indices when the indoor environmental quality (IEQ) changes. We then extract the brain wave indices' feature when the subjects conduct adaptive behaviors and predict the IEQ condition control using machine learning including the stacked ensembles. The extracted features were classified using base estimators such as distributed random forest, gradient boosting machine (GBM), generalized linear models (GLMs), deep neural network, and new predicted data were retrained and predicted by metalearner (i.e., GLM). In Dimension 1, the air conditioning system and the air ventilation system, and the area under curve (AUC) of the proposed stacked ensembles trained by base estimators was the highest, 0.9038. In Dimension 2, turning on and turning off, the AUC of the GBM is the highest, 0.8384. Based on these results, the EEG signal can be used to suggest an automatic IEQ control model that can then reduce the drowsiness, and increase attention.","BRAIN-COMPUTER INTERFACE,THERMAL COMFORT,EEG,REMOVAL,SYSTEM,SIGNAL,MOTOR,TECHNOLOGIES,STIMULATION,ARTIFACT",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Computer Science,Construction & Building Technology,Engineering,Transportation",,9.756,"BRAIN-COMPUTER,INTERFACE,THERMAL,COMFORT,EEG,REMOVAL,SYSTEM,SIGNAL,MOTOR,TECHNOLOGIES,STIMULATION,ARTIFACT",COMPUTER-AIDED CIVIL AND INFRASTRUCTURE ENGINEERING,,
15,Cloud-aided online EEG classification system for brain healthcare: A case study of depression evaluation with a lightweight CNN,50,5,596-610,"Ke Hengjin,Chen Dan,Shah Tejal,Liu Xianzeng,Zhang Xinhua,Zhang Lei,Li Xiaoli","Ke HJ,Chen D,Shah T,Liu XZ,Zhang XH,Zhang L,Li XL",Chen D,10.1002/spe.2668,Wuhan University,"Brain healthcare, when supported by Internet of Things, can perform online and accurate analysis of brain big data for the classification of multivariate Electroencephalogram (EEG), which is a prerequisite for the recent boom in neurofeedback applications and clinical practices. However, it remains a grand research challenge due to (1) the embedded intensive noises and the intrinsic nonstationarity determined by the evolution of brain states; and (2) the lack of a user-friendly computing platform to sustain the complicated analytics. This study presents the design of an online EEG classification system aided by Cloud centering on a lightweight Convolutional Neural Network (CNN). The system incrementally trains the CNN on Cloud and enables hot deployment of the trained classifier without the need to restart the gateway to adapt to the users' needs. The classifier maintains a High Convolutional Layer to gain the ability of processing high-dimensional EEG segments. The number of hidden layers is minimized to ensure the efficiency of training. The lightweight CNN adopts an ""hourglass"" block of fully connected layers to reduce the number of neurons quickly toward the output end. A case study of depression evaluation has been performed against raw EEG datasets to distinguish between (1) Healthy and Major Depression Disorder with an accuracy, sensitivity, and specificity of [98.59% +/- 0.28%], [97.77% +/- 0.63%], and [99.51% +/- 0.19%], respectively; and (2) Effective and Noneffective treatment outcome with an accuracy, sensitivity, and specificity of [99.53% +/- 0.002%], [99.50% +/- 0.01%], and [99.58% +/- 0.02%], respectively. The results show that the classification can be completed several magnitudes faster when EEG is collected on the gateway (several milliseconds vs. 4 seconds).","brain healthcare,Cloud computing,CNN,depression,EEG classification",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Computer Science,,2.046,"BIG,DATA,CHALLENGES",SOFTWARE-PRACTICE & EXPERIENCE,,
16,Classification of Carbon Fiber Reinforced Polymer Defects Based on One-Dimensional CNN,57,10,,"Zhan Xianglin,Zhao Wanting","Zhan XL,Zhao WT",Zhan XL; Zhao WT,10.3788/LOP57.101013,Civil Aviation University of China,"Aiming at classification of carbon fiber reinforced polymer (CFRP) defect types, an ultrasonic one-dimensional convolutional neural network (U-1DCNN) is proposed and the Bayesian optimization algorithm is used to optimize hyperparameters. By automatically extracting the features of ultrasonic Lambda-Scan signals, three defect types, i. e., delamination, gas cavity, and non-defect, arc automatically distinguished. First, a dataset is constructed by collecting ultrasonic Lambda-Scan signals. Then, multi-convolutional blocks arc used to simultaneously extract as well as enhance the diversity of extracted features. Subsequently, one-dimensional residual units arc stacked and connected, simplifying the training of the network while further extracting the features. The learning rate and momentum parameter of stochastic gradient descent of the network arc optimized by Bayesian optimization algorithm. Finally, nonlinear mapping of the Lambda-Scan signals and defects is realized. Experiment results show that U-1DCNN can recognize CFRP defects by automatically extracting features, with the accuracy reaching 99. 50 %. The recognition speed of U-1DCNN is faster than the two-dimensional CNN method, which is advantageous for defect detection.","image processing,identification of defect types,convolutional neural network,ultrasonic signals,carbon fiber reinforced polymer (CFRP)",Article,"SHANGHAI INST OPTICS & FINE MECHANICS, CHINESE ACAD SCIENCE,  390, QINGHE LU, SHANGHAI, JIADING-QU, PEOPLES R CHINA","Engineering,Optics",,,,LASER & OPTOELECTRONICS PROGRESS,,
17,Intact Detection of Highly Occluded Immature Tomatoes on Plants Using Deep Learning Techniques,20,10,,"Mu Yue,Chen Tai-Shen,Ninomiya Seishi,Guo Wei","Mu Y,Chen TS,Ninomiya S,Guo W",Mu Y,10.3390/s20102984,Nanjing Agricultural University,"Automatic detection of intact tomatoes on plants is highly expected for low-cost and optimal management in tomato farming. Mature tomato detection has been wildly studied, while immature tomato detection, especially when occluded with leaves, is difficult to perform using traditional image analysis, which is more important for long-term yield prediction. Therefore, tomato detection that can generalize well in real tomato cultivation scenes and is robust to issues such as fruit occlusion and variable lighting conditions is highly desired. In this study, we build a tomato detection model to automatically detect intact green tomatoes regardless of occlusions or fruit growth stage using deep learning approaches. The tomato detection model used faster region-based convolutional neural network (R-CNN) with Resnet-101 and transfer learned from the Common Objects in Context (COCO) dataset. The detection on test dataset achieved high average precision of 87.83% (intersection over union >= 0.5) and showed a high accuracy of tomato counting (R-2 = 0.87). In addition, all the detected boxes were merged into one image to compile the tomato location map and estimate their size along one row in the greenhouse. By tomato detection, counting, location and size estimation, this method shows great potential for ripeness and yield prediction.","precision horticulture,deep learning,image analysis,robotic harvesting",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"FRUIT,DETECTION,GROWTH,GREENHOUSE,COLOR",SENSORS,https://europepmc.org/articles/pmc7288109?pdf=render,
18,Catalyst Acquisition by Data Science (CADS): a web-based catalyst informatics platform for discovering catalysts,5,5,903-911,"Fujima Jun,Tanaka Yuzuru,Miyazato Itsuki,Takahashi Lauren,Takahashi Keisuke","Fujima J,Tanaka Y,Miyazato I,Takahashi L,Takahashi K",Fujima J; Takahashi K,10.1039/d0re00098a,National Institute for Materials Science,"An innovative web-based integrated catalyst informatics platform, Catalyst Acquisition by Data Science (CADS), is developed for use towards the discovery and design of catalysts. The platform provides three main functionalities: a repository for data sharing and publishing, an analytic workspace for exploratory visual analysis, and catalyst property prediction tools with pretrained machine learning models. Access to such a platform helps decrease barriers to entry faced by researchers in catalytic chemistry when attempting to apply catalyst informatics towards data by providing analytical and visualization tools that can be simultaneously applied and easily accessed within a central space, thereby helping the advancement of catalyst informatics. The developed platform allows researchers to upload and collect data onto the platform and conduct data analysis using a system of linked workspaces consisting of interactive visualization tools and machine learning tools that simultaneously update according to the researchers' actions in real time. The platform also provides a space for collaboration where researchers can choose to publish their uploaded data and resulting analyses to the platform for collaborations with other users and groups. As an example, CADS is applied towards oxidative coupling of methane (OCM) data where use of the platform tools reveals underlying patterns and trends that are otherwise hidden within the original data. Thus, the proposed platform contributes towards the advancement of catalyst informatics for both specialists and non-specialists.",,Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Engineering",,4.502,,REACTION CHEMISTRY & ENGINEERING,,
19,"Prediction of Diabetic Nephropathy from the Relationship between Fatigue, Sleep and Quality of Life",10,9,,"Lien Angela Shin-Yu,Jiang Yi-Der,Tsai Jia-Ling,Hwang Jawl-Shan,Lin Wei-Chao","Lien ASY,Jiang YD,Tsai JL,Hwang JS,Lin WC",Lin WC,10.3390/app10093282,Chang Gung University,"Fatigue and poor sleep quality are the most common clinical complaints of people with diabetes mellitus (DM). These complaints are early signs of DM and are closely related to diabetic control and the presence of complications, which lead to a decline in the quality of life. Therefore, an accurate measurement of the relationship between fatigue, sleep status, and the complication of DM nephropathy could lead to a specific definition of fatigue and an appropriate medical treatment. This study recruited 307 people with Type 2 diabetes from two medical centers in Northern Taiwan through a questionnaire survey and a retrospective investigation of medical records. In an attempt to identify the related factors and accurately predict diabetic nephropathy, we applied hybrid research methods, integrated biostatistics, and feature selection methods in data mining and machine learning to compare and verify the results. Consequently, the results demonstrated that patients with diabetic nephropathy have a higher fatigue level and Charlson comorbidity index (CCI) score than without neuropathy, the presence of neuropathy leads to poor sleep quality, lower quality of life, and poor metabolism. Furthermore, by considering feature selection in selecting representative features or variables, we achieved consistence results with a support vector machine (SVM) classifier and merely ten representative factors and a prediction accuracy as high as 74% in predicting the presence of diabetic nephropathy.","fatigue,sleep quality,quality of life,diabetic nephropathy,feature selection,data mining",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"FEATURE-SELECTION,GLYCEMIC,CONTROL,OLDER-ADULTS,CLASSIFICATION,ASSOCIATIONS,DEPRESSION,SYMPTOMS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/9/3282/pdf,
20,Machine-learning-assisted high-throughput computational screening of high performance metal-organic frameworks,5,4,725-742,"Shi Zenan,Yang Wenyuan,Deng Xiaomei,Cai Chengzhi,Yan Yaling,Liang Hong,Liu Zili,Qiao Zhiwei","Shi ZA,Yang WY,Deng XM,Cai CZ,Yan YL,Liang H,Liu ZL,Qiao ZW",Qiao ZW,10.1039/d0me00005a,Guangzhou University,"Over the past two decades, the number of works on metal-organic frameworks (MOFs) in the fields of gas adsorption and separation has experienced explosive growth due to their high void fraction and ultra-high specific surface area. With the rapid increase of MOF databases, high-throughput computational screening (HTCS) has become the main method for selecting high-performance target materials from the large quantity of MOFs. Traditional HTCS methods, e.g. grand canonical Monte Carlo (GCMC) and density functional theory (DFT), could accelerate the discovery of materials; however, there are some shortcomings in these methods such as high computational cost and slow speed, considering the vast and almost infinite MOF database as well as different separation systems and diverse operating conditions. Machine learning (ML) is a potential screening method with the ability to accurately predict the high-performance materials through the training of data, which were obtained by HTCS, and the ML model that fits accurately the complex system can improve the screening speed by 2-3 orders of magnitude. In this work, in view of ML-assisted HTCS of MOFs in recent years, the relevant research progress including CH4 storage, H-2 storage, CO2 separation, etc. is summarized, aiming to clarify the potential problems and challenges about ML-assisted HTCS by categorizing the application and development of ML in this field. Then, a series of ML algorithms were designed and developed to adapt to different MOF systems, and to search key descriptors based on ML to reverse design new MOFs with excellent performance. Therefore, the ML-assisted HTCS method could accelerate the development of MOFs and promote their applications in various fields.","METHANE STORAGE,MOLECULAR SIMULATION,MATERIALS DISCOVERY,GENETIC ALGORITHM,HYDROGEN STORAGE,CARBON-DIOXIDE,CO2,ADSORPTION,SEPARATION,CHEMISTRY",Review,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Engineering,Science & Technology - Other Topics,Materials Science",,4.667,"METHANE,STORAGE,MOLECULAR,SIMULATION,MATERIALS,DISCOVERY,GENETIC,ALGORITHM,HYDROGEN,STORAGE,CARBON-DIOXIDE,CO2,ADSORPTION,SEPARATION,CHEMISTRY",MOLECULAR SYSTEMS DESIGN & ENGINEERING,,
21,To switch or not to switch - a machine learning approach for ferroelectricity,2,5,2063-2072,"Neumayer Sabine M.,Jesse Stephen,Velarde Gabriel,Kholkin Andrei L.,Kravchenko Ivan,Martin Lane W.,Balke Nina,Maksymovych Peter","Neumayer SM,Jesse S,Velarde G,Kholkin AL,Kravchenko I,Martin LW,Balke N,Maksymovych P",Maksymovych P,10.1039/c9na00731h,United States Department of Energy (DOE),"With the advent of increasingly elaborate experimental techniques in physics, chemistry and materials sciences, measured data are becoming bigger and more complex. The observables are typically a function of several stimuli resulting in multidimensional data sets spanning a range of experimental parameters. As an example, a common approach to study ferroelectric switching is to observe effects of applied electric field, but switching can also be enacted by pressure and is influenced by strain fields, material composition, temperature, time, etc. Moreover, the parameters are usually interdependent, so that their decoupling toward univariate measurements or analysis may not be straightforward. On the other hand, both explicit and hidden parameters provide an opportunity to gain deeper insight into the measured properties, provided there exists a well-defined path to capture and analyze such data. Here, we introduce a new, two-dimensional approach to represent hysteretic response of a material system to applied electric field. Utilizing ferroelectric polarization as a model hysteretic property, we demonstrate how explicit consideration of electromechanical response to two rather than one control voltages enables significantly more transparent and robust interpretation of observed hysteresis, such as differentiating between charge trapping and ferroelectricity. Furthermore, we demonstrate how the new data representation readily fits into a variety of machine-learning methodologies, from unsupervised classification of the origins of hysteretic response via linear clustering algorithms to neural-network-based inference of the sample temperature based on the specific morphology of hysteresis.","SCANNING PROBE MICROSCOPY,PIEZORESPONSE FORCE MICROSCOPY,DOMAIN-WALLS,POLARIZATION,NANOGENERATOR,NANOSCALE,STATES,FILMS",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Science & Technology - Other Topics,Materials Science",,4.553,"SCANNING,PROBE,MICROSCOPY,PIEZORESPONSE,FORCE,MICROSCOPY,DOMAIN-WALLS,POLARIZATION,NANOGENERATOR,NANOSCALE,STATES,FILMS",NANOSCALE ADVANCES,https://elar.urfu.ru/bitstream/10995/90587/1/10.1039-c9na00731h.pdf,
22,The Use of Neural Networks in Combination with Evolutionary Algorithms to Optimise the Copper Flotation Enrichment Process,10,9,,"Jamroz Dariusz,Niedoba Tomasz,Pieta Paulina,Surowiak Agnieszka","Jamroz D,Niedoba T,Pieta P,Surowiak A",Niedoba T,10.3390/app10093119,AGH University of Science & Technology,"The paper presents a way of combining neural networks with evolutionary algorithms in order to find optimal parameters of the copper flotation enrichment process. The neural network was used in order to build a model describing the flotation process. The network learning was carried out with the use of samples from previous empirical measurements of the actual process. The model created in this way made it possible to find optimal parameters not only from among the measurement spaces, but also those that go beyond the measurements. Then, evolutionary algorithms were used in order to find optimal flotation parameters. The learned neural network previously described was used to calculate the criterion in the evolutionary algorithm.","genetic algorithms,neural network,optimisation,evolutionary algorithms,flotation,copper ore",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"MULTIPARAMETER,DATA,VISUALIZATION,OBSERVATIONAL,TUNNELS,METHOD,JUMPING,GENE,ADAPTATIONS,CLASSIFICATION,PERFORMANCE,CIRCUITS,DESIGN,PCA",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/9/3119/pdf,
23,Deep-Learning-Based Active Hyperspectral Imaging Classification Method Illuminated by the Supercontinuum Laser,10,9,,"Liu Yu,Tao Zilong,Zhang Jun,Hao Hao,Peng Yuanxi,Hou Jing,Jiang Tian","Liu Y,Tao ZL,Zhang J,Hao H,Peng YX,Hou J,Jiang T",Hou J; Jiang T,10.3390/app10093088,National University of Defense Technology - China,"Hyperspectral imaging (HSI) technology is able to provide fine spectral and spatial information of objects. It has the ability to discriminate materials and thereby has been used in a wide range of areas. However, traditional HSI strongly depends on the sunlight and hence is restricted to daytime. In this paper, a visible/near-infrared active HSI classification method illuminated by a visible/near-infrared supercontinuum laser is developed for spectra detection and objects imaging in the dark. Besides, a deep-learning-based classifier, hybrid DenseNet, is created to learn the feature representations of spectral and spatial information parallelly from active HSI data and is used for the active HSI classification. By applying the method to a selection of objects in the dark successfully, we demonstrate that with the active HSI classification method, it is possible to detect objects of interest in practical applications. Correct active HSI classification of different objects further supports the viability of the method for camouflage detection, biomedical alteration detection, cave painting mapping and so on.","active hyperspectral imaging,supercontinuum laser,classification,deep-learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,NETWORK,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/9/3088/pdf,
24,Augmented patient-specific functional medical imaging by implicit manifold learning,36,5,,"Rapadamnaba Robert,Nicoud Franck,Mohammadi Bijan","Rapadamnaba R,Nicoud F,Mohammadi B",Rapadamnaba R,10.1002/cnm.3325,Centre National de la Recherche Scientifique (CNRS),"This paper uses machine learning to enrich magnetic resonance angiography and magnetic resonance imaging acquisitions. A convolutional neural network is built and trained over a synthetic database linking geometrical parameters and mechanical characteristics of the arteries to blood flow rates and pressures in an arterial network. Once properly trained, the resulting neural network can be used in order to predict blood pressure in cerebral arteries noninvasively in nearly real-time. One challenge here is that not all input variables present in the synthetic database are known from patient-specific medical data. To overcome this challenge, a learning technique, which we refer to as implicit manifold learning, is employed: in this view, the input and output data of the neural network are selected based on their availability from medical measurements rather than being defined from the mechanical description of the arterial system. The results show the potential of the method and that machine learning is an alternative to costly ensemble based inversion involving sophisticated fluid structure models.","convolutional neural network,hemodynamic problems,machine learning,noninvasive pressure estimation,transfer learning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Mathematical & Computational Biology,Mathematics",,2.839,"BLOOD-FLOW,TEXT,CATEGORIZATION,MACHINE,PREDICTION,ALGORITHMS,REGRESSION",INTERNATIONAL JOURNAL FOR NUMERICAL METHODS IN BIOMEDICAL ENGINEERING,https://hal.archives-ouvertes.fr/hal-02500022/document,
25,AlpsNMR: an R package for signal processing of fully untargeted NMR-based metabolomics,36,9,2943-2945,"Madrid-Gambin Francisco,Oller-Moreno Sergio,Fernandez Luis,Bartova Simona,Giner Maria Pilar,Joyce Christopher,Ferraro Francesco,Montoliu Ivan,Moco Sofia,Marco Santiago","Madrid-Gambin F,Oller-Moreno S,Fernandez L,Bartova S,Giner MP,Joyce C,Ferraro F,Montoliu I,Moco S,Marco S",Fernandez L,10.1093/bioinformatics/btaa022,Barcelona Institute of Science & Technology,"aSummary: Nuclear magnetic resonance (NMR)-based metabolomics is widely used to obtain metabolic fingerprints of biological systems. While targeted workflows require previous knowledge of metabolites, prior to statistical analysis, untargeted approaches remain a challenge. Computational tools dealing with fully untargeted NMR-based metabolomics are still scarce or not user-friendly. Therefore, we developed AlpsNMR (Automated spectraL Processing System for NMR), an R package that provides automated and efficient signal processing for untargeted NMR metabolomics. AlpsNMR includes spectra loading, metadata handling, automated outlier detection, spectra alignment and peak-picking, integration and normalization. The resulting output can be used for further statistical analysis. AlpsNMR proved effective in detecting metabolite changes in a test case. The tool allows less experienced users to easily implement this workflow from spectra to a ready-to-use dataset in their routines.",AUTOMATED QUANTIFICATION,Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Computer Science,Mathematical & Computational Biology,Mathematics",,8.47,"AUTOMATED,QUANTIFICATION",BIOINFORMATICS,http://diposit.ub.edu/dspace/bitstream/2445/180153/1/699828.pdf,
26,"Plant Phenomics: Fundamental Bases, Software and Hardware Platforms, and Machine Learning",67,3,397-412,"Demidchik V. V.,Shashko A. Y.,Bandarenka U. Y.,Smolikova G. N.,Przhevalskaya D. A.,Charnysh M. A.,Pozhvanov G. A.,Barkosvkyi A. V.,Smolich I. I.,Sokolik A. I.","Demidchik VV,Shashko AY,Bandarenka UY,Smolikova GN,Przhevalskaya DA,Charnysh MA,Pozhvanov GA,Barkosvkyi AV,Smolich II,Sokolik AI",Demidchik VV,10.1134/S1021443720030061,Belarusian State University,"In recent years, a new branch of plant physiology, plant phenomics, which focuses on identifying patterns of organization and changes in plant Phenomes, i.e., physical and biochemical characteristics, considered as a set of phenotypes of a plant organism, has emerged. Phenomics is a postgenomic discipline that actively uses the achievements of the genomic era and bioinformatics. It supplements them with standardized and statistically significant factual material on phenotypes with a high degree of detail. The technique of obtaining and analyzing information about phenotypes in phenomics is called phenotyping. High-performance phenotyping, providing digital automated analysis of large data samples, has become widespread. Recent progress in high-performance phenotyping has been associated with the development of image registration systems in various spectral regions, approaches to cultivating plant objects under standardized conditions, sensory technologies, robotics, and methods for data processing and analysis, such as computer vision and machine learning (artificial neural network). Phenomics technologies have a high information content analysis, surpassing human capabilities, performing measurements in the hyperspectral range using X-ray tomography and ultra-precise ""thermal"" images, and have a number of other low-invasive and precision approaches. Arrays of data obtained using phenomics technologies are recorded and processed automatically and are free from the problems of subjective assessment and inadequate statistical processing. It is assumed that phenotyping will allow for the creation of digital models of the vital activity processes and the ""formation"" of plant productivity at the organism level in connection with the dynamics of transcriptomes, proteomes, and metabolomes. Phenomics helps researchers transform a large amount of information received from modern sensors into new knowledge using computer data processing and modeling, reducing the distance from basic science to the practical application of results in crop production and breeding. Phenotyping is actively developing both in laboratory and in greenhouse conditions as well as on open agricultural sites, forests, and in real natural phytocenoses. The review analyzes the current state of plant phenomics with a focus on technical aspects, in particular, the design of hardware-software phenotyping complexes, i.e., phenomics platforms, as well as the use of neural networks in phenotyping of plant organisms.","plants,plant phenomics,high-performance phenotyping,phenomics platform,computer vision,machine learning,convolutional neural networks",Review,"PLEIADES PUBLISHING INC, PLEIADES HOUSE, 7 W 54 ST, NEW YORK,  NY, UNITED STATES",Plant Sciences,,1.608,"CHLOROPHYLL,FLUORESCENCE,LIGHT,ACCLIMATION,DROUGHT,STRESS,WATER-STRESS,GROWTH,RESPONSES,SHAPE,QUANTIFICATION,CLASSIFICATION,ARCHITECTURE",RUSSIAN JOURNAL OF PLANT PHYSIOLOGY,,
27,Lung nodule detection and classification based on geometric fit in parametric form and deep learning,32,9,4629-4647,"Naqi Syed Muhammad,Sharif Muhammad,Jaffar Arfan","Naqi SM,Sharif M,Jaffar A",Naqi SM,10.1007/s00521-018-3773-x,COMSATS University Islamabad (CUI),"This study presents an automated detection and classification method to facilitate the radiologists in the diagnosis process. The major problem in these systems is the inclusion of false positives in the results, which may lead to inaccurate diagnosis. A nodule detection and classification method is proposed that consists of four major phases. First, the lung region extraction is performed based on optimal gray level threshold that is computed by fractional-order Darwinian particle swarm optimization. Then, a novel nodule candidate detection method, based on geometric fit in parametric form incorporating the geometric properties of the nodules, is proposed. In the next phase, a hybrid geometric texture feature descriptor is created for better representation of the candidate nodules, which is a combination of 2D as well as 3D information about nodule candidates. Finally, a deep learning approach based on stacked autoencoder and softmax for feature reduction and classification is applied to reduce false positives. Performance analysis on the largest publically available dataset, Lung Image Database Consortium and Image Database Resource Initiative, depicts that the proposed method has significantly reduced the number of false positives to 2.8 per scan with a promising sensitivity of 95.6%. The results demonstrate the significance of the methodology in automatic lung nodule detection and classification. Furthermore, it will facilitate and provide assistance to radiologists in precise nodule detection.","Autoencoder,Deep learning,False positives,Lung nodule,Hybrid features,Segmentation",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"COMPUTER-AIDED,DETECTION,IMAGE,DATABASE,CONSORTIUM,FALSE-POSITIVE,REDUCTION,PULMONARY,NODULES,AUTOMATIC,DETECTION,NEURAL-NETWORKS,SEGMENTATION,CANCER,SHAPE,ENSEMBLE",NEURAL COMPUTING & APPLICATIONS,,
28,"Machine learning-based motor assessment of Parkinson's disease using postural sway, gait and lifestyle features on crowdsourced smartphone data",6,3,,"Abujrida Hamza,Agu Emmanuel,Pahlavan Kaveh","Abujrida H,Agu E,Pahlavan K",Abujrida H,10.1088/2057-1976/ab39a8,Worcester Polytechnic Institute,"Objectives: Remote assessment of gait in patients' homes has become a valuable tool for monitoring the progression of Parkinson's disease (PD). However, these measurements are often not as accurate or reliable as clinical evaluations because it is challenging to objectively distinguish the unique gait characteristics of PD. We explore the inference of patients' stage of PD from their gait using machine learning analyses of data gathered from their smartphone sensors. Specifically, we investigate supervised machine learning (ML) models to classify the severity of the motor part of the UPDRS (MDS-UPDRS 2.10-2.13). Our goals are to facilitate remote monitoring of PD patients and to answer the following questions: (1) What is the patient PD stage based on their gait? (2) Which features are best for understanding and classifying PD gait severities? (3) Which ML classifier types best discriminate PD patients from healthy controls (HC)? and (4) Which ML classifier types can discriminate the severity of PD gait anomalies? Methodology: Our work uses smartphone sensor data gathered from 9520 patients in the mPower study, of whom 3101 participants uploaded gait recordings and 344 subjects and 471 controls uploaded at least 3 walking activities. We selected 152 PD patients who performed at least 3 recordings before and 3 recordings after taking medications and 304 HC who performed at least 3 walking recordings. From the accelerometer and gyroscope sensor data, we extracted statistical, time, wavelet and frequency domain features, and other lifestyle features were derived directly from participants' survey data. We conducted supervised classification experiments using 10-fold cross-validation and measured the model precision, accuracy, and area under the curve (AUC). Results: The best classification model, best feature, highest classification accuracy, and AUC were (1) random forest and entropy rate, 93% and 0.97, respectively, for walking balance (MDS-UPDRS-2.12); (2) bagged trees and MinMaxDiff, 95% and 0.92, respectively, for shaking/tremor (MDS-UPDRS-2.10); (3) bagged trees and entropy rate, 98% and 0.98, respectively, for freeze of gait; and (4) random forest and MinMaxDiff, 95% and 0.99, respectively, for distinguishing PD patients from HC. Conclusion: Machine learning classification was challenging due to the use of data that were subjectively labeled based on patients' answers to the MDS-UPDRS survey questions. However, with use of a significantly larger number of subjects than in prior work and clinically validated gait features, we were able to demonstrate that automatic patient classification based on smartphone sensor data can be used to objectively infer the severity of PD and the extent of specific gait anomalies.","Parkinson's disease,gait analysis,smartphone sensing,machine learning,remote monitoring",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Radiology, Nuclear Medicine & Medical Imaging",,,AGE,BIOMEDICAL PHYSICS & ENGINEERING EXPRESS,,
29,Human respiration monitoring using infrared thermography and artificial intelligence,6,3,,"Jagadev Preeti,Giri Lalat Indu","Jagadev P,Giri LI",Jagadev P,10.1088/2057-1976/ab7a54,National Institute of Technology (NIT System),"The respiration rate (RR) is the most vital parameter used for the determination of human health. The most widely adopted techniques, used to monitor the RR are contact in nature and face many drawbacks. This paper reports the use of Infrared Thermography, in reliably monitoring the RR in a contact-less and non-invasive way. A thermal camera is used to monitor the variation in nasal temperature during respiration continuously. Further, the nostrils (region of interest) are tracked during head motion and object occlusion, by implementing a computer vision algorithm that makes use of 'Histogram of oriented gradients' and 'Support vector machine' (SVM). The signal to noise ratio (SNR) of the acquired breathing signals is very low; hence they are subjected to appropriate filtering methods. The filters are compared depending on the performance metrics such as SNR and Mean square error. The breaths per minute are obtained without any manual intervention by implementing the 'Breath detection algorithm' (BDA). This algorithm is implemented on 150 breathing signals and its performance is determined by computing the parameters such as Precision, Sensitivity, Spurious cycle rate, and Missed cycle rate values, obtained as 98.6%, 97.2%, 1.4%, and 2.8% respectively. The parameters obtained from the BDA are fed to the k-Nearest Neighbour (k-NN) and SVM classifiers, that determine whether the human volunteers have abnormal or normal respiration, or have Bradypnea (slow breathing), or Tachypnea (fast breathing). The Validation accuracies obtained are 96.25% and 99.5% with Training accuracies 97.75% and 99.4% for SVM and k-NN classifiers respectively. The Testing accuracies of the completely built SVM and k-NN classifiers are 96% and 99%, respectively. The various performance metrics like Sensitivity, Specificity, Precision, G-mean and F-measure are calculated as well, for every class, for both the classifiers. Finally, the Standard deviation values of the SVM and k-NN classifiers are computed and are obtained as 0.022 and 0.007, respectively. It is observed that the k-NN classifier shows a better performance compared to the SVM classifier. The pattern between the data points fed to the classifiers is viewed by making use of the t-Stochastic Neighbor Embedding algorithm. It is noticed from these plots that the separation between the data points belonging to different classes, improves and shows minimal overlap by increasing the perplexity value and number of iterations.","Respiration rate,Infrared Thermography,Breath detection algorithm,t-Stochastic Neighbour Embedding algorithm,Machine learning,Cubic Polynomial filter,Butterworth filter",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Radiology, Nuclear Medicine & Medical Imaging",,,,BIOMEDICAL PHYSICS & ENGINEERING EXPRESS,,
30,Machine Learning Based Automated Segmentation and Hybrid Feature Analysis for Diabetic Retinopathy Classification Using Fundus Image,22,5,,"Ali Aqib,Qadri Salman,Mashwani Wali Khan,Kumam Wiyada,Kumam Poom,Naeem Samreen,Goktas Atila,Jamal Farrukh,Chesneau Christophe,Anam Sania","Ali A,Qadri S,Mashwani WK,Kumam W,Kumam P,Naeem S,Goktas A,Jamal F,Chesneau C,Anam S",Kumam W,10.3390/e22050567,Rajamangala University of Technology Thanyaburi,"The object of this study was to demonstrate the ability of machine learning (ML) methods for the segmentation and classification of diabetic retinopathy (DR). Two-dimensional (2D) retinal fundus (RF) images were used. The datasets of DR-that is, the mild, moderate, non-proliferative, proliferative, and normal human eye ones-were acquired from 500 patients at Bahawal Victoria Hospital (BVH), Bahawalpur, Pakistan. Five hundred RF datasets (sized 256 x 256) for each DR stage and a total of 2500 (500 x 5) datasets of the five DR stages were acquired. This research introduces the novel clustering-based automated region growing framework. For texture analysis, four types of features-histogram (H), wavelet (W), co-occurrence matrix (COM) and run-length matrix (RLM)-were extracted, and various ML classifiers were employed, achieving 77.67%, 80%, 89.87%, and 96.33% classification accuracies, respectively. To improve classification accuracy, a fused hybrid-feature dataset was generated by applying the data fusion approach. From each image, 245 pieces of hybrid feature data (H, W, COM, and RLM) were observed, while 13 optimized features were selected after applying four different feature selection techniques, namely Fisher, correlation-based feature selection, mutual information, and probability of error plus average correlation. Five ML classifiers named sequential minimal optimization (SMO), logistic (Lg), multi-layer perceptron (MLP), logistic model tree (LMT), and simple logistic (SLg) were deployed on selected optimized features (using 10-fold cross-validation), and they showed considerably high classification accuracies of 98.53%, 99%, 99.66%, 99.73%, and 99.73%, respectively.","diabetic retinopathy,clustering,segmentation,hybrid features,classification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,2.587,IDENTIFICATION,ENTROPY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7517087,
31,"Classification of Covid-19 Coronavirus, Pneumonia and Healthy Lungs in CT Scans Using Q-Deformed Entropy and Deep Learning Features",22,5,,"Hasan Ali M.,AL-Jawad Mohammed M.,Jalab Hamid A.,Shaiba Hadil,Ibrahim Rabha W.,AL-Shamasneh Ala'a R.","Hasan AM,AL-Jawad MM,Jalab HA,Shaiba H,Ibrahim RW,AL-Shamasneh AR",Jalab HA,10.3390/e22050517,Universiti Malaya,"Many health systems over the world have collapsed due to limited capacity and a dramatic increase of suspected COVID-19 cases. What has emerged is the need for finding an efficient, quick and accurate method to mitigate the overloading of radiologists' efforts to diagnose the suspected cases. This study presents the combination of deep learning of extracted features with the Q-deformed entropy handcrafted features for discriminating between COVID-19 coronavirus, pneumonia and healthy computed tomography (CT) lung scans. In this study, pre-processing is used to reduce the effect of intensity variations between CT slices. Then histogram thresholding is used to isolate the background of the CT lung scan. Each CT lung scan undergoes a feature extraction which involves deep learning and a Q-deformed entropy algorithm. The obtained features are classified using a long short-term memory (LSTM) neural network classifier. Subsequently, combining all extracted features significantly improves the performance of the LSTM network to precisely discriminate between COVID-19, pneumonia and healthy cases. The maximum achieved accuracy for classifying the collected dataset comprising 321 patients is 99.68%.","deep learning,CT scans of lungs,fractional calculus,Q-deformed entropy,features extraction,LSTM network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,2.587,SEGMENTATION,ENTROPY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7517011,
32,Automatic segmentation of brain tumor resections in intraoperative ultrasound images using U-Net,7,3,,"Carton Francois-Xavier,Chabanas Matthieu,Le Lann Florian,Noble Jack H.","Carton FX,Chabanas M,Le Lann F,Noble JH",Carton FX,10.1117/1.JMI.7.3.031503,Communaute Universite Grenoble Alpes,"To compensate for the intraoperative brain tissue deformation, computer-assisted intervention methods have been used to register preoperative magnetic resonance images with intraoperative images. In order to model the deformation due to tissue resection, the resection cavity needs to be segmented in intraoperative images. We present an automatic method to segment the resection cavity in intraoperative ultrasound (iUS) images. We trained and evaluated two-dimensional (2-D) and three-dimensional (3-D) U-Net networks on two datasets of 37 and 13 cases that contain images acquired from different ultrasound systems. The best overall performing method was the 3-D network, which resulted in a 0.72 mean and 0.88 median Dice score over the whole dataset. The 2-D network also had good results with less computation time, with a median Dice score over 0.8. We also evaluated the sensitivity of network performance to training and testing with images from different ultrasound systems and image field of view. In this application, we found specialized networks to be more accurate for processing similar images than a general network trained with all the data. Overall, promising results were obtained for both datasets using specialized networks. This motivates further studies with additional clinical data, to enable training and validation of a clinically viable deep-learning model for automated delineation of the tumor resection cavity in iUS images. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","brain-shift,resection,intraoperative ultrasound,segmentation,deep learning",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"SHIFT,COMPENSATION,DATABASE,MRI",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7026519,
33,SpineCloud: image analytics for predictive modeling of spine surgery outcomes,7,3,,"De Silva Tharindu,Vedula S. Swaroop,Perdomo-Pantoja Alexander,Vijayan Rohan,Doerr Sophia A.,Uneri Ali,Han Runze,Ketcha Michael D.,Skolasky Richard L.,Witham Timothy","De Silva T,Vedula SS,Perdomo-Pantoja A,Vijayan R,Doerr SA,Uneri A,Han RZ,Ketcha MD,Skolasky RL,Witham T",Siewerdsen JH,10.1117/1.JMI.7.3.031502,Johns Hopkins University,"Purpose: Data-intensive modeling could provide insight on the broad variability in outcomes in spine surgery. Previous studies were limited to analysis of demographic and clinical characteristics. We report an analytic framework called ""SpineCloud"" that incorporates quantitative features extracted from perioperative images to predict spine surgery outcome.
Approach: A retrospective study was conducted in which patient demographics, imaging, and outcome data were collected. Image features were automatically computed from perioperative CT. Postoperative 3- and 12-month functional and pain outcomes were analyzed in terms of improvement relative to the preoperative state. A boosted decision tree classifier was trained to predict outcome using demographic and image features as predictor variables. Predictions were computed based on SpineCloud and conventional demographic models, and features associated with poor outcome were identified from weighting terms evident in the boosted tree.
Results: Neither approach was predictive of 3- or 12-month outcomes based on preoperative data alone in the current, preliminary study. However, SpineCloud predictions incorporating image features obtained during and immediately following surgery (i.e., intraoperative and immediate postoperative images) exhibited significant improvement in area under the receiver operating characteristic (AUC): AUC = 0.72 (CI95 = 0.59 to 0.83) at 3 months and AUC = 0.69 (CI95 = 0.55 to 0.82) at 12 months.
Conclusions: Predictive modeling of lumbar spine surgery outcomes was improved by incorporation of image-based features compared to analysis based on conventional demographic data. The SpineCloud framework could improve understanding of factors underlying outcome variability and warrants further investigation and validation in a larger patient cohort. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","lumbar spine surgery,prediction models,machine learning,image analytics,out-come modeling,data analytics",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"TARGET,LOCALIZATION,3D-2D,REGISTRATION,PATIENT,OUTCOMES,CONTROLLED-TRIAL,LUMBAR,FUSION,STENOSIS,IMPACT,PAIN",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7026518,
34,Constructing a tissue-specific texture prior by machine learning from previous full-dose scan for Bayesian reconstruction of current ultralow-dose CT images,7,3,,"Gao Yongfeng,Tan Jiaxing,Shi Yongyi,Lu Siming,Gupta Amit,Li Haifang,Liang Zhengrong","Gao YF,Tan JX,Shi YY,Lu SM,Gupta A,Li HF,Liang ZR",Liang ZR,10.1117/1.JMI.7.3.032502,State University of New York (SUNY) System,"Purpose: Bayesian theory provides a sound framework for ultralow-dose computed tomography (ULdCT) image reconstruction with two terms for modeling the data statistical property and incorporating a priori knowledge for the image that is to be reconstructed. We investigate the feasibility of using a machine learning (ML) strategy, particularly the convolutional neural network (CNN), to construct a tissue-specific texture prior from previous full-dose computed tomography.
Approach: Our study constructs four tissue-specific texture priors, corresponding with lung, bone, fat, and muscle, and integrates the prior with the prelog shift Poisson (SP) data property for Bayesian reconstruction of ULdCT images. The Bayesian reconstruction was implemented by an algorithm called SP-CNN-T and compared with our previous Markov random field (MRF)-based tissue-specific texture prior algorithm called SP-MRF-T.
Results: In addition to conventional quantitative measures, mean squared error and peak signal-to-noise ratio, structure similarity index, feature similarity, and texture Haralick features were used to measure the performance difference between SP-CNN-T and SP-MRF-T algorithms in terms of the structure and tissue texture preservation, demonstrating the feasibility and the potential of the investigated ML approach.
Conclusions: Both training performance and image reconstruction results showed the feasibility of constructing CNN texture prior model and the potential of improving the structure preservation of the nodule comparing to our previous regional tissue-specific MRF texture prior model. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","prelog shift Poisson model,convolutional neural network tissue-specific texture prior,machine learning",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"CONVOLUTIONAL,NEURAL-NETWORK,LEAST-SQUARES,NOISE-REDUCTION,LIKELIHOOD,REGULARIZATION,ALGORITHMS",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7040436,
35,Hybrid machine learning architecture for automated detection and grading of retinal images for diabetic retinopathy,7,3,,"Narayanan Barath Narayanan,Hardie Russell C.,De Silva Manawaduge Supun,Kueterman Nathaniel K.","Narayanan BN,Hardie RC,De Silva MS,Kueterman NK",Narayanan BN,10.1117/1.JMI.7.3.034501,University of Dayton,"Purpose: Diabetic retinopathy is the leading cause of blindness, affecting over 93 million people. An automated clinical retinal screening process would be highly beneficial and provide a valuable second opinion for doctors worldwide. A computer-aided system to detect and grade the retinal images would enhance the workflow of endocrinologists.
Approach: For this research, we make use of a publicly available dataset comprised of 3662 images. We present a hybrid machine learning architecture to detect and grade the level of diabetic retinopathy (DR) severity. We also present and compare simple transfer learning-based approaches using established networks such as AlexNet, VGG16, ResNet, Inception-v3, NASNet, DenseNet, and GoogLeNet for DR detection. For the grading stage (mild, moderate, proliferative, or severe), we present an approach of combining various convolutional neural networks with principal component analysis for dimensionality reduction and a support vector machine classifier. We study the performance of these networks under different preprocessing conditions.
Results: We compare these results with various existing state-of-the-art approaches, which include single-stage architectures. We demonstrate that this architecture is more robust to limited training data and class imbalance. We achieve an accuracy of 98.4% for DR detection and an accuracy of 96.3% for distinguishing severity of DR, thereby setting a benchmark for future research efforts using a limited set of training images.
Conclusions: Results obtained using the proposed approach serve as a benchmark for future research efforts. We demonstrate as a proof-of-concept that an automated detection and grading system could be developed with a limited set of images and labels. This type of independent architecture for detection and grading could be used in areas with a scarcity of trained clinicians based on the necessity. (C) 2020 Society of Photo Optical Instrumentation Engineers (SPIE)","diabetic retinopathy,computer-aided detection,endocrinology,convolutional neural networks,support vector machine,principal component analysis",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,IDENTIFICATION,JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7309178,
36,"Optimization design of lightweight structure inspired by glass sponges (Porifera, Hexacinellida) and its mechanical properties",15,3,,"Li Longhai,Guo Ce,Chen Yiting,Chen Yinhe","Li LH,Guo C,Chen YT,Chen YH",Guo C,10.1088/1748-3190/ab6ca9,Nanjing University of Aeronautics & Astronautics,"The glass sponge is a porous lightweight structure in the deep sea. It has high toughness, high strength, and high stability. In this work, a super-depth-of-field microscope was employed to observe the microstructure of the glass sponge. Based on its morphological characteristics, two novel bio-inspired lightweight structures were proposed, and the finite-element analyses (FEA) of the structures were carried out under compression, torsion, and bending loads, respectively. The structure samples were fabricated using stereolithography 3D-printing technology, and the dimension sizes of the samples were equal to those of the corresponding FEA models. Mechanical tests were performed on an electronic universal testing machine, and the results were used to demonstrate the reliability of the FEA. Additionally, lightweight numbers (LWN) were proposed to evaluate the lightweight efficiency, and a honeycomb structure was selected as the reference structure. The results indicate that the lightweight numbers of the novel bio-inspired structures are higher than those of the honeycomb structure, respectively. Finally, the proposed structures were optimized by the response surface, BP (Back Propagation) and GA-BP (Genetic Algorithm optimized Back Propagation) method. The results show that the GA-BP model after training has a high accuracy. These results can provide significant guidance for the design of tube-shaped, thin-walled structures in the engineering.","glass sponges,microstructure,mechanical properties,lightweight numbers,optimization,bio-inspired",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Materials Science,Robotics",,3.52,"MULTIOBJECTIVE,OPTIMIZATION,COMPRESSION,COMPOSITE",BIOINSPIRATION & BIOMIMETICS,,
37,Real-time prediction of quality characteristics in laser beam welding using optical coherence tomography and machine learning,32,2,,"Stadter Christian,Schmoeller Maximilian,von Rhein Lara,Zaeh Michael F.","Stadter C,Schmoeller M,von Rhein L,Zaeh MF",Stadter C,10.2351/7.0000077,Technical University of Munich,"Laser beam welding significantly outperforms conventional joining techniques in terms of flexibility and productivity. The process benefits, in particular, from the highly focused energy and thus from a well-defined heat input. The high intensities of brilliant laser radiation, however, induce very dynamic effects and complex processes within the interaction zone. The high process dynamics require a consistent and reliable quality assurance to ensure the required weld quality. A novel sensor concept for laser material processing based on optical coherence tomography (OCT) was used to measure the capillary depth of the keyhole during deep penetration welding. The OCT measurements were compared with analyses of the surface quality of the weld seams. A machine learning approach could be utilized to reveal correlations between the weld depth signal and the weld seam surface quality, underlining the high level of information contained in the OCT signal about characteristic process phenomena that affect the weld seam quality. Fundamental investigations on aluminum, copper, and galvanized steel were carried out to analyze the structure of the data recorded by the OCT sensor. Based on that, evaluation strategies focusing on quality characteristics were developed and validated to enable a valid interpretation of the OCT signal. The topography of the weld seams was used to classify the surface quality and correlated with the weld depth signal of the OCT system. For this purpose, a preprocessing of the OCT data and a detailed analysis of the topographic information were developed. The processed data were correlated using artificial neural networks. It was shown that by using adequate network structures and training methods, the inline process data of the capillary depth can be used to predict the surface quality with decent prediction accuracy.","predictive quality,machine learning,artificial neural networks,process data,data interpretation",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Materials Science,Optics,Physics",,2.103,,JOURNAL OF LASER APPLICATIONS,,
38,Toward robust multitype and orientation detection of vessels in maritime surveillance,29,3,,"Ghahremani Amir,Bondarev Egor,de With Peter H. N.","Ghahremani A,Bondarev E,de With PHN",Ghahremani A,10.1117/1.JEI.29.3.033015,Eindhoven University of Technology,"Reliable multitype and orientation vessel detection is of vital importance for maritime surveillance. We develop three separate convolutional neural network (CNN) models for high-performance single-class vessel detection and then multiclass vessel-type/orientation detection. We also propose a modular combined network, which enhances the multiclass operation. The initial three models provide reliable F-1 scores of 85%, 82%, and 76%, respectively. In addition, the modular combined approach improves the F-1 scores for the multitype and orientation vessel detection by 2% and 3%, respectively. The training and testing were done on a dataset, including the multitype/orientation annotations, covering 31,078 vessel labels (10 vessel types and 5 orientations), which is offered to public access. (C) 2020 SPIE and IS&T","convolutional neural networks,multiclass detection,vessel detection,maritime surveillance",Article,"IS&T & SPIE, 1000 20TH ST, BELLINGHAM, WA 98225 USA","Engineering,Optics,Imaging Science & Photographic Technology",,1.006,"QUALITY,ASSESSMENT,IMAGE,ALGORITHM",JOURNAL OF ELECTRONIC IMAGING,,
39,High-resolution sub-sampling incoherent x-ray imaging with a single-pixel detector,5,5,,"He Yu-Hang,Zhang Ai-Xin,Li Ming-Fei,Huang Yi-Yi,Quan Bao-Gang,Li Da-Zhang,Wu Ling-An,Chen Li-Ming","He YH,Zhang AX,Li MF,Huang YY,Quan BG,Li DZ,Wu LA,Chen LM",Wu LA,10.1063/1.5140322,Chinese Academy of Sciences,"X-ray ""ghost"" imaging has drawn great attention for its potential to obtain images with a high resolution and lower radiation dose in medical diagnosis, even with only a single-pixel detector. However, it is hard to realize with a portable x-ray source due to its low flux. Here, we demonstrate a computational x-ray ghost imaging scheme where a real bucket detector and specially designed high-efficiency modulation masks are used, together with a robust deep learning algorithm in which a compressed set of Hadamard matrices is incorporated into a multi-level wavelet convolutional neural network. With a portable incoherent x-ray source of similar to 37 mu m diameter, we have obtained an image of a real object from only 18.75% of the Nyquist sampling rate. A high imaging resolution of similar to 10 mu m has been achieved, which is required for cancer detection and so represents a concrete step toward the realization of a practical low cost x-ray ghost imaging camera for applications in biomedicine, archeology, material science, and so forth.",,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Optics,Physics",,5.27,,APL PHOTONICS,https://aip.scitation.org/doi/pdf/10.1063/1.5140322,
40,Deep learning for NLTE spectral opacities,27,5,,"Kluth G.,Humbird K. D.,Spears B. K.,Peterson J. L.,Scott H. A.,Patel M. V.,Koning J.,Marinak M.,Divol L.,Young C. V.","Kluth G,Humbird KD,Spears BK,Peterson JL,Scott HA,Patel MV,Koning J,Marinak M,Divol L,Young CV",Kluth G,10.1063/5.0006784,CEA,"Computer simulations of high energy density science experiments are computationally challenging, consisting of multiple physics calculations including radiation transport, hydrodynamics, atomic physics, nuclear reactions, laser-plasma interactions, and more. To simulate inertial confinement fusion (ICF) experiments at high fidelity, each of these physics calculations should be as detailed as possible. However, this quickly becomes too computationally expensive even for modern supercomputers, and thus many simplifying assumptions are made to reduce the required computational time. Much of the research has focused on acceleration techniques for the various packages in multiphysics codes. In this work, we explore a novel method for accelerating physics packages via machine learning. The non-local thermodynamic equilibrium (NLTE) package is one of the most expensive calculations in the simulations of indirect drive inertial confinement fusion, taking several tens of percent of the total wall clock time. We explore the use of machine learning to accelerate this package, by essentially replacing the physics calculation with a deep neural network that has been trained to emulate the physics code. We demonstrate the feasibility of this approach on a simple problem and perform a side-by-side comparison of the physics calculation and the neural network inline in an ICF Hohlraum simulation. We show that the neural network achieves a 10x speed up in NLTE computational time while achieving good agreement with the physics code for several quantities of interest. Published under license by AIP Publishing.",NEURAL-NETWORKS,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,1.839,NEURAL-NETWORKS,PHYSICS OF PLASMAS,https://www.osti.gov/biblio/1810674,
41,Non-Invasive Hydration Level Estimation in Human Body Using Galvanic Skin Response,20,9,4891-4900,"Rizwan Ali,Abu Ali Najah,Zoha Ahmed,Ozturk Metin,Alomainy Akram,Imran Muhammad Ali,Abbasi Qammer H.","Rizwan A,Abu Ali N,Zoha A,Ozturk M,Alomainy A,Imran MA,Abbasi QH",Abu Ali N,10.1109/JSEN.2020.2965892,United Arab Emirates University,"Dehydration and overhydration, both have mild to severe medical implications on human health. Tracking Hydration Level (HL) is, therefore, very important particularly in patients, kids, elderly, and athletes. The limited solutions available for the estimation of HL are commonly inefficient, invasive, or require clinical trials. Need for a non-invasive auto-detection solution is imminent to track HL on a regular basis. To the best of authors' knowledge, it is for the first time a Machine Learning (ML) based auto-estimation solution is proposed that uses Galvanic Skin Response (GSR) as a proxy of HL in the human body. Various body postures, such as sitting and standing, and distinct hydration states, hydrated vs dehydrated, are considered during the data collection and analysis phases. Six different ML algorithms are trained using real GSR data, and their efficacy is compared for different parameters (i.e., window size, feature combinations etc). It is reported that a simple algorithm like K-NN outperforms other algorithms with accuracy upto 87.78% for the correct estimation of the HL.","Skin conductance level (SCL),GSR,electrodermal activity (EDA),hydration level,bio-sensors data",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,,IEEE SENSORS JOURNAL,http://eprints.gla.ac.uk/207708/1/207708.pdf,
42,Automated Alcoholism Detection Using Fourier-Bessel Series Expansion Based Empirical Wavelet Transform,20,9,4914-4924,"Anuragi Arti,Sisodia Dilip Singh,Pachori Ram Bilas","Anuragi A,Sisodia DS,Pachori RB",Sisodia DS,10.1109/JSEN.2020.2966766,National Institute of Technology (NIT System),"In this paper, the Fourier-Bessel series expansion based empirical wavelet transform (FBSE-EWT) is proposed for automated alcoholism detection using electroencephalogram (EEG) signals. The FBSE-EWT is applied to decompose EEG signals into narrow sub-band signals using a boundary detection approach. The accumulated line length, log energy entropy, and norm entropy features are extracted from different frequency scales of narrow sub-band signals. A total of twenty features are extracted from each attribute and out of which ten features are from low to high frequency sub-band signals and other ten features are from high to low frequency sub-band signals. In order to reduce the classification model complexity, the most significant features are selected using feature selection techniques. Six feature ranking methods such as Relief-F, t-test, Chi-test, relief attribute evaluation, correlation attribute evaluation, and gain ratio are used to select the most common features based on the majority voting technique. Experiments are performed by considering top ranked 5, 10, 15, and 20 features and classification methods such as least square support vector machine (LS-SVM), support vector machine (SVM), and k nearest neighbor (k-NN) classifiers. The training and testing is done using leave-one out cross-validation (LOOCV) in order to avoid over-fitting. The performances of classifiers are evaluated using accuracy, sensitivity, and specificity measures. The results suggest that LS-SVM with radial basis function (RBF) kernel achieves a highest average accuracy of 98.8%, sensitivity of 98.3%, and specificity of 99.1% with top 20 significant features.","Alcoholism detection,EEG signal,FBSE-EWT,accumulated entropy features,classifiers",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"EPILEPTIC,SEIZURE,DETECTION,EEG,SIGNALS,MYOCARDIAL-INFARCTION,ECG,SIGNALS,LINE,LENGTH,FEATURES,CLASSIFICATION,DECOMPOSITION,TUMORS",IEEE SENSORS JOURNAL,,
43,Rapid Antibiotic Susceptibility Testing Based on Bacterial Motion Patterns With Long Short-Term Memory Neural Networks,20,9,4940-4950,"Iriya Rafael,Jing Wenwen,Syal Karan,Mo Manni,Chen Chao,Yu Hui,Hayde Shelley E.,Wang Shaopeng,Tao Nongjian","Iriya R,Jing WW,Syal K,Mo MN,Chen C,Yu H,Hayde SE,Wang SP,Tao NJ",Tao NJ,10.1109/JSEN.2020.2967058,Arizona State University,"Antibiotic resistance is an increasing public health threat. To combat it, a fast method to determine the antibiotic susceptibility of infecting pathogens is required. Herewe present an optical imaging-basedmethod to track the motion of single bacterial cells and generate a model to classify active and inactive cells based on the motion patterns of the individual cells. The model includes an image-processing algorithm to segment individual bacterial cells and track the motion of the cells over time, and a deep learning algorithm (Long Short-Term Memory network) to learn and determine if a bacterial cell is active or inactive. By applying the model to human urine specimens spiked with an Escherichia coli lab strain, we show that the method can accurately perform antibiotic susceptibility testing as fast as 30 minutes for five commonly used antibiotics.","Antibiotic resistance,antibiotic susceptibility testing,AST,E. coli,single cell tracking,deep learning,neural networks,long short-term memory,LSTM",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"CLINICAL-PRACTICE,GUIDELINES,SINGLE-CELL,GROWTH,ANTIMICROBIAL,SUSCEPTIBILITY,SEGMENTATION,RESISTANCE,MOTILITY,CAPTURE,PROTEIN,SHIFT",IEEE SENSORS JOURNAL,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7241544,
44,PUB-SalNet: A Pre-Trained Unsupervised Self-Aware Backpropagation Network for Biomedical Salient Segmentation,13,5,,"Chen Feiyang,Jiang Ying,Zeng Xiangrui,Zhang Jing,Gao Xin,Xu Min","Chen FY,Jiang Y,Zeng XR,Zhang J,Gao X,Xu M",Xu M,10.3390/a13050126,Carnegie Mellon University,"Salient segmentation is a critical step in biomedical image analysis, aiming to cut out regions that are most interesting to humans. Recently, supervised methods have achieved promising results in biomedical areas, but they depend on annotated training data sets, which requires labor and proficiency in related background knowledge. In contrast, unsupervised learning makes data-driven decisions by obtaining insights directly from the data themselves. In this paper, we propose a completely unsupervised self-aware network based on pre-training and attentional backpropagation for biomedical salient segmentation, named as PUB-SalNet. Firstly, we aggregate a new biomedical data set from several simulated Cellular Electron Cryo-Tomography (CECT) data sets featuring rich salient objects, different SNR settings, and various resolutions, which is called SalSeg-CECT. Based on the SalSeg-CECT data set, we then pre-train a model specially designed for biomedical tasks as a backbone module to initialize network parameters. Next, we present a U-SalNet network to learn to selectively attend to salient objects. It includes two types of attention modules to facilitate learning saliency through global contrast and local similarity. Lastly, we jointly refine the salient regions together with feature representations from U-SalNet, with the parameters updated by self-aware attentional backpropagation. We apply PUB-SalNet for analysis of 2D simulated and real images and achieve state-of-the-art performance on simulated biomedical data sets. Furthermore, our proposed PUB-SalNet can be easily extended to 3D images. The experimental results on the 2d and 3d data sets also demonstrate the generalization ability and robustness of our method.","unsupervised learning,saliency segmentation,biomedical image processing,pre-trained methods",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,ATTENTION,ALGORITHMS,https://escholarship.org/content/qt8qq67880/qt8qq67880.pdf?t=qfz9ie,
45,Accuracy of an Artificial Intelligence Deep Learning Algorithm Implementing a Recurrent Neural Network With Long Short-term Memory for the Automated Detection of Calcified Plaques From Coronary Computed Tomography Angiography,35,,S49-S57,"Fischer Andreas M.,Eid Marwen,De Cecco Carlo N.,Gulsun Mehmet A.,van Assen Marly,Nance John W.,Sahbaee Pooyan,De Santis Domenico,Bauer Maximilian J.,Jacobs Brian E.","Fischer AM,Eid M,De Cecco CN,Gulsun MA,van Assen M,Nance JW,Sahbaee P,De Santis D,Bauer MJ,Jacobs BE",Schoepf UJ,10.1097/RTI.0000000000000491,Medical University of South Carolina,"Purpose: The purpose of this study was to evaluate the accuracy of a novel fully automated deep learning (DL) algorithm implementing a recurrent neural network (RNN) with long short-term memory (LSTM) for the detection of coronary artery calcium (CAC) from coronary computed tomography angiography (CCTA) data. Materials and Methods: Under an IRB waiver and in HIPAA compliance, a total of 194 patients who had undergone CCTA were retrospectively included. Two observers independently evaluated the image quality and recorded the presence of CAC in the right (RCA), the combination of left main and left anterior descending (LM-LAD), and left circumflex (LCx) coronary arteries. Noncontrast CACS scans were allowed to be used in cases of uncertainty. Heart and coronary artery centerline detection and labeling were automatically performed. Presence of CAC was assessed by a RNN-LSTM. The algorithm's overall and per-vessel sensitivity, specificity, and diagnostic accuracy were calculated. Results: CAC was absent in 84 and present in 110 patients. As regards CCTA, the median subjective image quality, signal-to-noise ratio, and contrast-to-noise ratio were 3.0, 13.0, and 11.4. A total of 565 vessels were evaluated. On a per-vessel basis, the algorithm achieved a sensitivity, specificity, and diagnostic accuracy of 93.1% (confidence interval [CI], 84.3%-96.7%), 82.76% (CI, 74.6%-89.4%), and 86.7% (CI, 76.8%-87.9%), respectively, for the RCA, 93.1% (CI, 86.4%-97.7%), 95.5% (CI, 88.77%-98.75%), and 94.2% (CI. 90.2%-94.6%), respectively, for the LM-LAD, and 89.9% (CI, 80.2%-95.8%), 90.0% (CI, 83.2%-94.7%), and 89.9% (CI, 85.0%-94.1%), respectively, for the LCx. The overall sensitivity, specificity, and diagnostic accuracy were 92.1% (CI, 92.1%-95.2%), 88.9% (CI. 84.9%-92.1%), and 90.3% (CI, 88.0%-90.0%), respectively. When accounting for image quality, the algorithm achieved a sensitivity, specificity, and diagnostic accuracy of 76.2%, 87.5%, and 82.2%, respectively, for poor-quality data sets and 93.3%, 89.2% and 90.9%, respectively, when data sets rated adequate or higher were combined. Conclusion: The proposed RNN-LSTM demonstrated high diagnostic accuracy for the detection of CAC from CCTA.","machine learning,coronary artery calcium score,coronary computed tomography angiography,recurrent neural network,convolutional neural network,long short-term memory",Article,"LIPPINCOTT WILLIAMS & WILKINS, TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"CARDIOVASCULAR,RISK-ASSESSMENT,ARTERY,CALCIUM,CARDIAC,CT,CHEST-PAIN,QUANTIFICATION,NONCONTRAST,ATHEROSCLEROSIS,AMERICAN,SOCIETY,DISEASE",JOURNAL OF THORACIC IMAGING,https://pure.rug.nl/ws/files/148025649/Accuracy_of_an_Artificial_Intelligence_Deep.9.pdf,
46,Classification of Body Constitution Based on TCM Philosophy and Deep Learning,12,5,,"Li Yung-Hui,Aslam Muhammad Saqlain,Yang Kai-Lin,Kao Chung-An,Teng Shin-You","Li YH,Aslam MS,Yang KL,Kao CA,Teng SY",Aslam MS,10.3390/sym12050803,National Central University,"There is a growing demand for alternative or complementary medicine in health care disciplines that uses a non-invasive instrument to evaluate the health status of various organs inside the human body. In this regard, we proposed a real-time, non-invasive, and painless technique to assess an individual's health condition. Our approach is based on the combination of iridology and the philosophy of traditional Chinese medicine (TCM). The iridology chart presents perfect symmetry between the left and right eyes, and such a unique representation reveals the body constitution based on TCM philosophy, which classifies the aforementioned body constitution into a combination of nine categories to describe the varieties of genomic traits. In addition, we applied a deep-learning method along with the combination of iridology and TCM to predict the possible physiological or psychological strength or weakness of the subjects and give advice to them about how to take care of their health according to the body constitution assessment. We used several pre-trained convolutional neural networks (CNNs, or ConvNet), such as a residual neural network (ResNet50), InceptionV3, and dense convolutional network (DenseNet201), to classify the body constitution using iris images. In the experiments, the CASIA-Iris-Thousand database was used to perform this task. The experimental results showed that the proposed iris-based health assessment method achieved an 82.9% accuracy.","iridology,health care,deep learning,complementary medicine,TCM,five elements",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"IRIDOLOGY,MEDICINE",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/5/803/pdf,
47,Automatic Reclaimed Wafer Classification Using Deep Learning Neural Networks,12,5,,"Shih Po-Chou,Hsu Chun-Chin,Tien Fang-Chih","Shih PC,Hsu CC,Tien FC",Tien FC,10.3390/sym12050705,National Taipei University of Technology,"Silicon wafer is the most crucial material in the semiconductor manufacturing industry. Owing to limited resources, the reclamation of monitor and dummy wafers for reuse can dramatically lower the cost, and become a competitive edge in this industry. However, defects such as void, scratches, particles, and contamination are found on the surfaces of the reclaimed wafers. Most of the reclaimed wafers with the asymmetric distribution of the defects, known as the ""good (G)"" reclaimed wafers, can be re-polished if their defects are not irreversible and if their thicknesses are sufficient for re-polishing. Currently, the ""no good (NG)"" reclaimed wafers must be first screened by experienced human inspectors to determine their re-usability through defect mapping. This screening task is tedious, time-consuming, and unreliable. This study presents a deep-learning-based reclaimed wafers defect classification approach. Three neural networks, multilayer perceptron (MLP), convolutional neural network (CNN) and Residual Network (ResNet), are adopted and compared for classification. These networks analyze the pattern of defect mapping and determine not only the reclaimed wafers are suitable for re-polishing but also where the defect categories belong. The open source TensorFlow library was used to train the MLP, CNN, and ResNet networks using collected wafer images as input data. Based on the experimental results, we found that the system applying CNN networks with a proper design of kernels and structures gave fast and superior performance in identifying defective wafers owing to its deep learning capability, and the ResNet averagely exhibited excellent accuracy, while the large-scale MLP networks also acquired good results with proper network structures.","reclaimed wafer,multilayer perceptron,convolutional neural network,ResNet,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"BIN,MAP,RECOGNITION,INSPECTION,SYSTEM",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/5/705/pdf,
48,Multistage Image Compressive Sensing Neural Network Based on Residual Learning,48,5,82-91,",","Yang Chunling,Pei Hanqi",,,Yang Chunling,"There are two main problems in traditional Image Compressive Sensing (ICS) : in sampling aspect, traditional linear sampling methods have some limitations; in reconstruction aspect,optimization-based reconstruction methods are highly time-consuming. Newly proposed ICS Neural Network can successfully deal with the speed problem in reconstruction,but lacks the accuracy of traditional algorithms. To solve this problem,a novel multistage ICS network based on residual learning (MSResICS) was proposed. It consists of three sub-networks, namely,sampling sub-network, initial reconstruction sub-network, and image enhancement sub-network. In sampling stage,with the help of residual learning,a nonlinear sampling sub-network was designed,which breaks the limitation of conventional sampling method and retains richer image information in samples. In reconstruction stage,the initial reconstruction sub-network extracts features from samples and obtain an initial reconstructed image of high quality by introducing interpolation convolution. With residual learning and interpolation convolution,a multistage image enhancing sub-network was proposed to further refine the reconstruction image and improve the quality of final result. Extensive simulations show that MSResICS has a better reconstruction accuracy than the existing optimal ICS reconstruction methods.",image compressive sensing; residual learning; deep network; sampling mechanism,Article,,,,,,,,
49,State-of-the-art analysis of geochemical data for mineral exploration,20,2,217-232,"Grunsky E. C.,de Caritat P.","Grunsky EC,de Caritat P",Grunsky EC,10.1144/geochem2019-031,University of Waterloo,"Multi-element geochemical surveys of rocks, soils, stream/lake/floodplain sediments and regolith are typically carried out at continental, regional and local scales. The chemistry of these materials is defined by their primary mineral assemblages and their subsequent modification by comminution and weathering. Modern geochemical datasets represent a multi-dimensional geochemical space that can be studied using multivariate statistical methods from which patterns reflecting geochemical/geological processes are described (process discovery). These patterns form the basis from which probabilistic predictive maps are created (process validation). Processing geochemical survey data requires a systematic approach to effectively interpret the multi-dimensional data in a meaningful way. Problems that are typically associated with geochemical data include closure, missing values, censoring, merging, levelling different datasets and adequate spatial sample design. Recent developments in advanced multivariate analytics, geospatial analysis and mapping provide an effective framework to analyse and interpret geochemical datasets. Geochemical and geological processes can often be recognized through the use of data discovery procedures such as the application of principal component analysis. Classification and predictive procedures can be used to confirm lithological variability, alteration and mineralization. Geochemical survey data of lake/till sediments from Canada and of floodplain sediments from Australia show that predictive maps of bedrock and regolith processes can be generated. Upscaling a multivariate statistics-based prospectivity analysis for arc-related Cu-Au mineralization from a regional survey in the southern Thomson Orogen in Australia to the continental scale, reveals a number of regions with a similar (or stronger) multivariate response and hence potentially similar (or higher) mineral potential throughout Australia.","geochemistry,analytical methods,compositional data,multivariate analytics,process discovery,process validation,predictive mapping,machine learning,geospatial coherence,Melville Peninsula,Nunavut,Thomson Region,New South Wales",Article; Proceedings Paper,"GEOLOGICAL SOC PUBL HOUSE, UNIT 7, BRASSMILL ENTERPRISE CENTRE, BRASSMILL LANE, BATH BA1 3JN, AVON, ENGLAND",Geochemistry & Geophysics,,,"COMPOSITIONAL,DATA,MELVILLE,PENINSULA,SPATIAL-ANALYSIS,MISSING,VALUES,REGOLITH,ZEROS",GEOCHEMISTRY-EXPLORATION ENVIRONMENT ANALYSIS,https://doi.org/10.1144/geochem2019-031,
50,A Deep Learning Model for Automatic Plastic Mapping Using Unmanned Aerial Vehicle (UAV) Data,12,9,,"Jakovljevic Gordana,Govedarica Miro,Alvarez-Taboada Flor","Jakovljevic G,Govedarica M,Alvarez-Taboada F",Alvarez-Taboada F,10.3390/rs12091515,Universidad de Leon,"Although plastic pollution is one of the most noteworthy environmental issues nowadays, there is still a knowledge gap in terms of monitoring the spatial distribution of plastics, which is needed to prevent its negative effects and to plan mitigation actions. Unmanned Aerial Vehicles (UAVs) can provide suitable data for mapping floating plastic, but most of the methods require visual interpretation and manual labeling. The main goals of this paper are to determine the suitability of deep learning algorithms for automatic floating plastic extraction from UAV orthophotos, testing the possibility of differentiating plastic types, and exploring the relationship between spatial resolution and detectable plastic size, in order to define a methodology for UAV surveys to map floating plastic. Two study areas and three datasets were used to train and validate the models. An end-to-end semantic segmentation algorithm based on U-Net architecture using the ResUNet50 provided the highest accuracy to map different plastic materials (F1-score: Oriented Polystyrene (OPS): 0.86; Nylon: 0.88; Polyethylene terephthalate (PET): 0.92; plastic (in general): 0.78), showing its ability to identify plastic types. The classification accuracy decreased with the decrease in spatial resolution, performing best on 4 mm resolution images for all kinds of plastic. The model provided reliable estimates of the area and volume of the plastics, which is crucial information for a cleaning campaign.","deep learning,mapping plastic,automatic detection,AI,remote sensing,UAV,segmentation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Geology,Remote Sensing,Imaging Science & Photographic Technology",,5.353,DEBRIS,REMOTE SENSING,https://www.mdpi.com/2072-4292/12/9/1515/pdf,
51,Olive Oils Classification via Laser-Induced Breakdown Spectroscopy,10,10,,"Gyftokostas Nikolaos,Stefas Dimitrios,Couris Stelios","Gyftokostas N,Stefas D,Couris S",Couris S,10.3390/app10103462,University of Patras,"The classification of olive oils and the authentication of their geographic origin are important issues for public health and for the olive oil market and related industry. The development of fast, easy to use, suitable for on-line, in-situ and remote operation techniques for olive oils classification is of high interest. In the present work, 36 olive oils from different places in Crete, Greece, are studied using a laser-based technique, Laser-Induced Breakdown Spectroscopy (LIBS), assisted by machine learning algorithms, aiming to classify them in terms of their geographical origin. The excellent classification results obtained demonstrate the great potential of LIBS, which is further extended by the use of machine learning.","LIBS,machine learning,supervised and unsupervised algorithms,classification,authentication of olive oils,chemometrics",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"GEOGRAPHIC,ORIGIN,FTIR,SPECTROSCOPY,FOOD",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/10/3462/pdf,
52,Empirical Modeling of Liquefied Nitrogen Cooling Impact during Machining Inconel 718,10,10,,"Hribersek Matija,Berus Lucijano,Pusavec Franci,Klancnik Simon","Hribersek M,Berus L,Pusavec F,Klancnik S",Klancnik S,10.3390/app10103603,University of Maribor,"This paper explains liquefied nitrogen's cooling ability on a nickel super alloy called Inconel 718. A set of experiments was performed where the Inconel 718 plate was cooled by a moving liquefied nitrogen nozzle with changing the input parameters. Based on the experimental data, the empirical model was designed by an adaptive neuro-fuzzy inference system (ANFIS) and optimized with the particle swarm optimization algorithm (PSO), with the aim to predict the cooling rate (temperature) of the used media. The research has shown that the velocity of the nozzle has a significant impact on its cooling ability, among other factors such as depth and distance. Conducted experimental results were used as a learning set for the ANFIS model's construction and validated via k-fold cross-validation. Optimization of the ANFIS's external input parameters was also performed with the particle swarm optimization algorithm. The best results achieved by the optimized ANFIS structure had test root mean squared error (test RMSE) = 0.2620, and test R-2 = 0.8585, proving the high modeling ability of the proposed method. The completed research contributes to knowledge of the field of defining liquefied nitrogen's cooling ability, which has an impact on the surface characteristics of the machined parts.","cryogenic machining,cooling impact,Inconel 718,machine learning,adaptive neuro-fuzzy inference system,particle swarm optimization",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"PARTICLE,SWARM,PERFORMANCE,PARAMETERS,ALLOY,OPTIMIZATION,TEMPERATURE,PREDICTION,SURFACE,ANFIS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/10/3603/pdf,
53,Machine Learning Methods for Improved Understanding of a Pumping Test in Heterogeneous Aquifers,12,5,,"Fan Yong,Hu Litang,Wang Hongliang,Liu Xin","Fan Y,Hu LT,Wang HL,Liu X",Fan Y,10.3390/w12051342,"China ENFI Engn Corp, Beijing 100038, Peoples R China.","Pumping tests are very important means for investigating aquifer properties; however, interpreting the data using common analytical solutions become invalid in complex aquifer systems. The paper aims to explore the potential of machine learning methods in retrieving the pumping tests information in a field site in the Democratic Republic of Congo. A newly planned mining site with a pumping test of three pumping wells and 28 observation wells over one month was chosen to analyze the significance of machine learning methods in the pumping test analysis. Widely used machine learning methods, including correlation, cluster, time-series analysis, artificial neural network (ANN), support vector machine (SVR), random forest (RF) method, and linear regression, are all used in this study. Correlation and cluster analyses among wells provide visual pictures of possible hydraulic connections. The pathway with the best permeability ranges from the depth of 250 m to 350 m. Time-series analysis perfectly captured changes of drawdowns within the three pumping wells. The RF method is found to have the higher accuracy and the lower sensitivity to model parameters than ANN and SVR methods. The coupling of the linear regressive model and analytical solutions is applied to estimate hydraulic conductivities. The results found that ML methods can significantly and effectively improve our understanding of pumping tests by revealing inherent information hidden in those tests.","pumping tests,machine learning,time-series analysis,cluster analysis,random forest method",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Water Resources",,,"ARTIFICIAL,NEURAL-NETWORKS,SUPPORT,VECTOR,MACHINES,GROUNDWATER,LEVEL,RANDOM,FORESTS,MODELS,PREDICTION,REGRESSION,WATER",WATER,https://www.mdpi.com/2073-4441/12/5/1342/pdf,
54,Machine learning: Accelerating materials development for energy storage and conversion,2,3,553-576,"Chen An,Zhang Xu,Zhou Zhen","Chen A,Zhang X,Zhou Z",Zhang X; Zhou Z,10.1002/inf2.12094,Nankai University,"With the development of modern society, the requirement for energy has become increasingly important on a global scale. Therefore, the exploration of novel materials for renewable energy technologies is urgently needed. Traditional methods are difficult to meet the requirements for materials science due to long experimental period and high cost. Nowadays, machine learning (ML) is rising as a new research paradigm to revolutionize materials discovery. In this review, we briefly introduce the basic procedure of ML and common algorithms in materials science, and particularly focus on latest progress in applying ML to property prediction and materials development for energy-related fields, including catalysis, batteries, solar cells, and gas capture. Moreover, contributions of ML to experiments are involved as well. We highly expect that this review could lead the way forward in the future development of ML in materials science.","big data,energy storage and conversion,machine learning,property prediction",Review,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Materials Science,,25.405,"DENSITY-FUNCTIONAL,THEORY,ARTIFICIAL,NEURAL-NETWORKS,MOLECULAR-DYNAMICS,SIMULATIONS,METAL-ORGANIC,FRAMEWORKS,THERMODYNAMIC,STABILITY,CO2,ELECTROREDUCTION,ELECTRONIC-STRUCTURE,MATERIALS,DISCOVERY,DESIGN,PRINCIPLES,CATHODE,MATERIALS",INFOMAT,https://doi.org/10.1002/inf2.12094,
55,Artificial intelligence-based classification of schizophrenia: A high density electroencephalographic and support vector machine study,62,3,273-+,"Tikka Sai Krishna,Singh Bikesh Kumar,Nizamie S. Haque,Garg Shobit,Mandal Sunandan,Thakur Kavita,Singh Lokesh Kumar","Tikka SK,Singh BK,Nizamie SH,Garg S,Mandal S,Thakur K,Singh LK",Tikka SK,10.4103/psychiatry.IndianJPsychiatry_91_20,All India Institute of Medical Sciences (AIIMS) Raipur,"Background: Interview-based schizophrenia (SCZ) diagnostic methods are not completely valid. Moreover, SCZ-the disease entity is very heterogeneous. Supervised-Machine-Learning (sML) application of Artificial-Intelligence holds a tremendous promise in solving these issues. Aims: To sML-based discriminating validity of resting-state electroencephalographic (EEG) quantitative features in classifying SCZ from healthy and, positive (PS) and negative symptom (NS) subgroups, using a high-density recording. Settings and Design: Data collected at a tertiary care mental-health institute using a cross-sectional study design and analyzed at a premier Engineering Institute. Materials and Methods: Data of 38-SCZ patients and 20-healthy controls were retrieved. The positive-negative subgroup classification was done using Positive and Negative Syndrome Scale operational-criteria. EEG was recorded using 256-channel high-density equipment. Eight priori regions-of-interest were selected. Six-level wavelet decomposition and Kernel-Support Vector Machine (SVM) method were used for feature extraction and data classification. Statistical Analysis: Mann-Whitney test was used for comparison of machine learning-features. Accuracy, sensitivity, specificity, and area under receiver operating characteristics-curve were measured as discriminatory indices of classifications. Results: Accuracy of classifying SCZ from healthy and PS from NS SCZ, were 78.95% and 89.29%, respectively. While beta and gamma frequency related features most accurately classified SCZ from healthy controls, delta and theta frequency related features most accurately classified positive from negative SCZ. Inferior frontal gyrus features most accurately contributed to both the classificatory instances. Conclusions: SVM-based classification and sub-classification of SCZ using EEG data is optimal and might help in improving the ""validity"" and reducing the ""heterogeneity"" in the diagnosis of SCZ. These results might only be generalized to acute and moderately ill male SCZ patients.","Feature-extraction,machine-learning,negative symptoms,positive symptoms,validity",Article,"WOLTERS KLUWER MEDKNOW PUBLICATIONS, WOLTERS KLUWER INDIA PVT LTD , A-202, 2ND FLR, QUBE, C T S  NO 1498A-2 VILLAGE MAROL, ANDHERI EAST, MUMBAI, 400059, INDIA",Psychiatry,,2.132,"DIAGNOSIS,SYMPTOMS",INDIAN JOURNAL OF PSYCHIATRY,https://doi.org/10.4103/psychiatry.indianjpsychiatry_91_20,
56,Prediction of Explosive Spalling of Heated Steel Fiber Reinforced Concrete using Artificial Neural Networks,18,5,227-240,"Liu Jin-Cheng,Zhang Zhigang","Liu JC,Zhang ZG",Zhang ZG,10.3151/jact.18.227,Chongqing University,"Explosive spalling is a severe threat to concrete at high temperature. The addition of steel fibers is believed to be useful to mitigate explosive spalling of concrete. But predicting explosive spalling of steel fiber reinforced concrete remains to be a challenging topic. This paper adopted a popular machine learning approach, i.e., artificial neural network (ANN), to predict explosive spalling of steel fiber reinforced concrete and furthermore study the effect of steel fibers on explosive spalling resistance of concrete. Two ANN models were developed, with ANN1 concrete mix-based and ANN2 concrete strength-based. Twenty groups of heating tests were conducted to validate the proposed ANN models. Both ANN models showed the prediction accuracy of 100%, which demonstrates that ANN is a powerful tool for assessing explosive spalling risk of steel fiber reinforced concrete. A parametric study was also conducted to investigate the effect of steel fibers on explosive spalling resistance of concrete using the well-validated ANN1.","HIGH-PERFORMANCE CONCRETE,HIGH-STRENGTH CONCRETE,MECHANICAL-PROPERTIES,ELEVATED-TEMPERATURE,POLYPROPYLENE FIBERS,COMPRESSIVE STRENGTH,SILICA FUME,FIRE RESISTANCE,AGGREGATE SIZE,FLY-ASH",Article,"JAPAN CONCRETE INST, SOGO HANZOMON BLDG 12F, NO 7, KOJIMACHI 1-CHOME, CHIYODA-KU, TOKYO 102-0083, JAPAN","Construction & Building Technology,Engineering,Materials Science",,2.05,"HIGH-PERFORMANCE,CONCRETE,HIGH-STRENGTH,CONCRETE,MECHANICAL-PROPERTIES,ELEVATED-TEMPERATURE,POLYPROPYLENE,FIBERS,COMPRESSIVE,STRENGTH,SILICA,FUME,FIRE,RESISTANCE,AGGREGATE,SIZE,FLY-ASH",JOURNAL OF ADVANCED CONCRETE TECHNOLOGY,https://www.jstage.jst.go.jp/article/jact/18/5/18_227/_pdf,
57,Development of hemorrhage identification model using non-invasive vital signs,41,5,,"Chen Yang,Yoon Joo Heung,Pinsky Michael R.,Ma Ting,Clermont Gilles","Chen Y,Yoon JH,Pinsky MR,Ma T,Clermont G",Ma T,10.1088/1361-6579/ab8cb2,Harbin Institute of Technology,"Objective: Early detection and timely management of bleeding is critical as failure to recognize physiologically significant bleeding is associated with significant morbidity and mortality. Many such instances are detected late, even in highly monitored environments, contributing to delay in recognition and intervention. We propose a non-invasive early identification model to detect bleeding events using continuously collected photoplethysmography (PPG) and electrocardiography (ECG) waveforms.Approach: Fifty-nine York pigs undergoing fixed-rate, controlled hemorrhage were involved in this study and a least absolute shrinkage and selection operator regression-based early detection model was developed and tested using PPG and ECG derived features. The output of the early detection model was a risk trajectory indicating the future probability of bleeding.Main results: Our proposed models were generally accurate in predicting bleeding with an area under the curve of 0.89 (95% CI 0.87-0.92) and achieved an average time of 16.1 mins to detect 16.8% blood loss when a false alert rate of 1% was tolerated. Models developed on non-invasive data performed with similar discrimination and lead time to hemorrhage compared to models using invasive arterial blood pressure as monitoring data.Significance: A bleed detection model using only non-invasive monitoring performs as well as those using invasive arterial pressure monitoring.","hemorrhage detection,animal model,photoplethysmography,machine learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"COMPENSATORY,RESERVE,WAVE-FORM,INDEX,PREDICTION,SHOCK,CARE",PHYSIOLOGICAL MEASUREMENT,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7894612,
58,SmartProbe: a bioimpedance sensing system for head and neck cancer tissue detection,41,5,,"Cheng Zhuoqi,Carobbio Andrea Luigi Camillo,Soggiu Lara,Migliorini Marco,Guastini Luca,Mora Francesco,Fragale Marco,Ascoli Alessandro,Africano Stefano,Caldwell Darwin G.","Cheng ZQ,Carobbio ALC,Soggiu L,Migliorini M,Guastini L,Mora F,Fragale M,Ascoli A,Africano S,Caldwell DG",Cheng ZQ,10.1088/1361-6579/ab8cb4,Istituto Italiano di Tecnologia - IIT,"Objectives: This study presents SmartProbe, an electrical bioimpedance (EBI) sensing system based on a concentric needle electrode (CNE). The system allows the use of commercial CNEs for accurate EBI measurement, and was specially developed for in-vivo real-time cancer detection. Approach: Considering the uncertainties in EBI measurements due to the CNE manufacturing tolerances, we propose a calibration method based on statistical learning. This is done by extracting the correlation between the measured impedance value |Z|, and the material conductivity sigma, for a group of reference materials. By utilizing this correlation, the relationship of sigma and |Z| can be described as a function and reconstructed using a single measurement on a reference material of known conductivity. Main results: This method simplifies the calibration process, and is verified experimentally. Its effectiveness is demonstrate by results that show less than 6% relative error. An additional experiment is conducted for evaluating the system's capability to detect cancerous tissue. Four types of ex-vivo human tissue from the head and neck region, including mucosa, muscle, cartilage and salivary gland, are characterized using SmartProbe. The measurements include both cancer and surrounding healthy tissue excised from 10 different patients operated on for head and neck cancer. The measured data is then processed using dimension reduction and analyzed for tissue classification. The final results show significant differences between pathologic and healthy tissues in muscle, mucosa and cartilage specimens. Significance: These results are highly promising and indicate a great potential for SmartProbe to be used in various cancer detection tasks.","electrical bioimpedance,cancer detection,electrode calibration,machine learning,principal component analysis",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"DIELECTRIC-PROPERTIES,ELECTRICAL-CONDUCTIVITY,ELECTRODE,POLARIZATION,MAGNETIC-RESONANCE,DUAL-ENERGY,IMPEDANCE,FREQUENCY",PHYSIOLOGICAL MEASUREMENT,,
59,Localization of origins of premature ventricular contraction in the whole ventricle based on machine learning and automatic beat recognition from 12-lead ECG,41,5,,"He Kaiyue,Nie Zhenning,Zhong Gaoyan,Yang Cuiwei,Sun Jian","He KY,Nie ZN,Zhong GY,Yang CW,Sun J",Yang CW,10.1088/1361-6579/ab86d7,Fudan University,"Objective: The localization of origins of premature ventricular contraction (PVC) is the key factor for the success of ablation of ventricular arrhythmias. Existing methods rely heavily on manual extraction of PVC beats, which limits their application to the automatic PVC recognition from long-term data recorded by ECG monitors before and during operation. In addition, research identifying PVC sources in the whole ventricle have not been reported. The purpose of this study was to validate the feasibility of localization of origins of PVC in the whole ventricle and to explore an automatic algorithm for recognition of PVC beats based on long-term 12-lead ECG.Approach: This study included 249 patients with spontaneous PVCs or pacing-induced PVCs. A novel algorithm was used to automatically extract PVC beats from a massive amount of original ECG data, which was collected by different acquisition devices. After clustering and labelling, 374 sample groups, each containing dozens to hundreds of PVC beats, formed the entire dataset of 11 categories corresponding to 11 regions of PVC origins in the whole ventricle. To choose the best classification model for the current task, four machine learning methods, support vector machine (SVM), random forest (RF), gradient-boosting decision tree (GBDT) and Gaussian naive Bayes (GNB), were compared by randomly selecting 70% of the entire dataset (sample groups = 257) for training and the remaining 30% (sample groups = 117) for testing. The average performance of each model was estimated by the bootstrap method using 1000 resampling trials.Main results: For PVC beat recognition, the achieved testing accuracy, sensitivity and specificity is 97.6%, 98.3% and 96.7%, respectively. For localization purpose, the achieved testing accuracy varies slightly from 70.7% to 74.1% among four classifiers, and when neighboring regions were combined, the testing rank accuracy is improved to a range of 91.5% to 93.2%.Significance: The proposed algorithm can automatically recognize PVC beats and map them to one of the 11 regions in the whole ventricle. Owing to the high accuracy of PVC beat recognition and the capability to target the potential PVC origins in multi regions, it is expected to be a predominant technique being used in clinical settings to automatically analyze huge ECG data before and during operation so as to replace the tedious manual identification.","premature ventricular contraction beat,noninvasive localization,12-lead ECG,machine learning,automatic recognition",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"EXIT,SITE,TACHYCARDIA,ACTIVATION,ABLATION,ELECTROCARDIOGRAM,PREVALENCE,ALGORITHM",PHYSIOLOGICAL MEASUREMENT,,
60,Coronavirus Disease (COVID-19): A Machine Learning Bibliometric Analysis,34,,1613-1617,"De Felice Francesca,Polimeni Antonella","De Felice F,Polimeni A",De Felice F,10.21873/invivo.11951,Sapienza University Rome,"Background/Aim: To evaluate the research trends in coronavirus disease (COVID-19). Materials and Methods: A bibliometric analysis was performed using a machine learning bibliometric methodology. Information regarding publication outputs, countries, institutions, journals, keywords, funding and citation counts was retrieved from Scopus database. Results: A total of 1883 eligible papers were returned. An exponential increase in the COVID-19 publications occurred in the last months. As expected, China produced the majority of articles, followed by the United States of America, the United Kingdom and Italy. There is greater collaboration between highly contributing authors and institutions. The ""BMJ"" published the highest number of papers (n=129) and ""The Lancet"" had the most citations (n=1439). The most ubiquitous topic was COVID-19 clinical features. Conclusion: This bibliometric analysis presents the most influential references related to COVID-19 during this time and could be useful to improve understanding and management of COVID-19.","COVID-19,coronavirus,bibliometric analysis,machine learning,management",Review,"INT INST ANTICANCER RESEARCH, EDITORIAL OFFICE 1ST KM KAPANDRITIOU-KALAMOU RD KAPANDRITI, PO BOX 22, ATHENS 19014, GREECE",Research & Experimental Medicine,,2.106,,IN VIVO,https://iris.uniroma1.it/bitstream/11573/1411138/1/De-Felice_Coronavirus_2020.pdf,
61,A Machine-Learning-Based Approach to Predict the Health Impacts of Commuting in Large Cities: Case Study of London,12,5,,"Tamang Madhav Raj Theeng,Sharif Mhd Saeed,Al-Bayatti Ali H.,Alfakeeh Ahmed S.,Alsayed Alhuseen Omar","Tamang MRT,Sharif MS,Al-Bayatti AH,Alfakeeh AS,Alsayed AO",Sharif MS,10.3390/sym12050866,"UEL, Sch Architecture Comp & Engn, ACE, Univ Way, London E16 2RD, England.","The daily commute represents a source of chronic stress that is positively correlated with physiological consequences, including increased blood pressure, heart rate, fatigue, and other negative mental and physical health effects. The purpose of this research is to investigate and predict the physiological effects of commuting in Greater London on the human body based on machine-learning approaches. For each participant, the data were collected for five consecutive working days, before and after the commute, using non-invasive wearable biosensor technology. Multimodal behaviour, analysis and synthesis are the subjects of major efforts in computing field to realise the successful human-human and human-agent interactions, especially for developing future intuitive technologies. Current analysis approaches still focus on individuals, while we are considering methodologies addressing groups as a whole. This research paper employs a pool of machine-learning approaches to predict and analyse the effect of commuting objectively. Comprehensive experimentation has been carried out to choose the best algorithmic structure that suit the problem in question. The results from this study suggest that whether the commuting period was short or long, all objective bio-signals (heat rate and blood pressure) were higher post-commute than pre-commute. In addition, the results match both the subjective evaluation obtained from the Positive and Negative Affect Schedule and the proposed objective evaluation of this study in relation to the correlation between the effect of commuting on bio-signals. Our findings provide further support for shorter commutes and using the healthier or active modes of transportation.","machine learning,stress,urban environments,commuting,stress recognition,heart rate,blood pressure",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,,"NEGATIVE,AFFECT,STRESS",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/5/866/pdf,
62,CryptoDL: Predicting Dyslexia Biomarkers from Encrypted Neuroimaging Dataset Using Energy-Efficient Residue Number System and Deep Convolutional Neural Network,12,5,,"Usman Opeyemi Lateef,Muniyandi Ravie Chandren","Usman OL,Muniyandi RC",Usman OL,10.3390/sym12050836,Universiti Kebangsaan Malaysia,"The increasing availability of medical images generated via different imaging techniques necessitates the need for their remote analysis and diagnosis, especially when such datasets involve brain morphological biomarkers, an important biological symmetry concept. This development has made the privacy and confidentiality of patients' medical records extremely important. In this study, an approach for a secure dyslexia biomarkers classification is proposed using a deep learning model and the concept of residue number system (RNS). A special moduli set of RNS was used to develop a pixel-bitstream encoder that encrypts the 7-bit binary value of each pixel present in the training and testing brain magnetic resonance imaging (MRI) dataset (neuroimaging dataset) prior to classification using cascaded deep convolutional neural network (CNN). Theoretical analysis of our encoder design shows that the proposed pixel-bitstream encoder is a combinational circuit that requires fewer fast adders, with area complexity of 4n A(FA) and time delay of (3n + 3) D-FA for n >= 3. FPGA implementation of the proposed encoder shows 23.5% critical path delay improvement and saves up to 42.4% power. Our proposed cascaded deep CNN also shows promising classification outcomes, with the highest performance accuracy of 73.2% on the encrypted data. Specifically, this study has attempted to explore the potencies of CNN to discriminate cases of dyslexia from control subjects using encrypted dyslexia biomarkers neuroimaging dataset. This kind of research becomes expedient owing to the educational and medical importance of dyslexia.","dyslexia biomarker,residue number system,encryption,deep learning,neuroimaging dataset",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"IMAGING,FINDINGS,SEGMENTATION,CNN",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/5/836/pdf,
63,Driving Drowsiness Detection with EEG Using a Modified Hierarchical Extreme Learning Machine Algorithm with Particle Swarm Optimization: A Pilot Study,9,5,,"Ma Yuliang,Zhang Songjie,Qi Donglian,Luo Zhizeng,Li Rihui,Potter Thomas,Zhang Yingchun","Ma YL,Zhang SJ,Qi DL,Luo ZZ,Li RH,Potter T,Zhang YC",Zhang YC,10.3390/electronics9050775,University of Houston System,"Driving fatigue accounts for a large number of traffic accidents in modern life nowadays. It is therefore of great importance to reduce this risky factor by detecting the driver's drowsiness condition. This study aimed to detect drivers' drowsiness using an advanced electroencephalography (EEG)-based classification technique. We first collected EEG data from six healthy adults under two different awareness conditions (wakefulness and drowsiness) in a virtual driving experiment. Five different machine learning techniques, including the K-nearest neighbor (KNN), support vector machine (SVM), extreme learning machine (ELM), hierarchical extreme learning machine (H-ELM), and the proposed modified hierarchical extreme learning machine algorithm with particle swarm optimization (PSO-H-ELM), were applied to classify the subject's drowsiness based on the power spectral density (PSD) feature extracted from the EEG data. The mean accuracies of the five classifiers were 79.31%, 79.31%, 74.08%, 81.67%, and 83.12%, respectively, demonstrating the superior performance of our new PSO-H-ELM algorithm in detecting drivers' drowsiness, compared to the other techniques.","drivers' drowsiness,electroencephalography,extreme learning machines,particle swarm optimization",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,FATIGUE,ELECTRONICS,https://www.mdpi.com/2079-9292/9/5/775/pdf,
64,Identification of Diseases Based on the Use of Inertial Sensors: A Systematic Review,9,5,,"Ponciano Vasco,Pires Ivan Miguel,Ribeiro Fernando Reinaldo,Marques Goncalo,Villasana Maria Vanessa,Garcia Nuno M.,Zdravevski Eftim,Spinsante Susanna","Ponciano V,Pires IM,Ribeiro FR,Marques G,Villasana MV,Garcia NM,Zdravevski E,Spinsante S",Pires IM,10.3390/electronics9050778,Universidade da Beira Interior,"Inertial sensors are commonly embedded in several devices, including smartphones, and other specific devices. This type of sensors may be used for different purposes, including the recognition of different diseases. Several studies are focused on the use of accelerometer signals for the automatic recognition of different diseases, and it may empower the different treatments with the use of less invasive and painful techniques for patients. This paper aims to provide a systematic review of the studies available in the literature for the automatic recognition of different diseases by exploiting accelerometer sensors. The most reliably detectable disease using accelerometer sensors, available in 54% of the analyzed studies, is the Parkinson's disease. The machine learning methods implemented for the automatic recognition of Parkinson's disease reported an accuracy of 94%. The recognition of other diseases is investigated in a few other papers, and it appears to be the target of further analysis in the future.","accelerometer,wearable electronic devices,diseases,monitoring,ambulatory,automatic identification,parkinson's disease",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"GAIT,ANALYSIS,OLDER-ADULTS,DEVICE",ELECTRONICS,https://repositorio.ipcb.pt/bitstream/10400.11/7082/1/Identification%20of%20Diseases%20Based%20on%20the%20Use%20of%20Inertial%20Sensors.%20A%20Systematic%20Review.pdf,
65,DeepBRDF: A Deep Representation for Manipulating Measured BRDF,39,2,157-166,"Hu Bingyang,Guo Jie,Chen Yanjun,Li Mengtian,Guo Yanwen","Hu BY,Guo J,Chen YJ,Li MT,Guo YW",Guo J,10.1111/cgf.13920,Nanjing University,"Effective compression of densely sampled BRDF measurements is critical for many graphical or vision applications. In this paper, we present DeepBRDF, a deep-learning-based representation that can significantly reduce the dimensionality of measured BRDFs while enjoying high quality of recovery. We consider each measured BRDF as a sequence of image slices and design a deep autoencoder with a masked L-2 loss to discover a nonlinear low-dimensional latent space of the high-dimensional input data. Thorough experiments verify that the proposed method clearly outperforms PCA-based strategies in BRDF data compression and is more robust. We demonstrate the effectiveness of DeepBRDF with two applications. For BRDF editing, we can easily create a new BRDF by navigating on the low-dimensional manifold of DeepBRDF, guaranteeing smooth transitions and high physical plausibility. For BRDF recovery, we design another deep neural network to automatically generate the full BRDF data from a single input image. Aided by our DeepBRDF learned from real-world materials, a wide range of reflectance behaviors can be recovered with high accuracy.","CCS Concepts,. Computing methodologies -> Reflectance modeling,Neural networks",Article; Proceedings Paper,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Computer Science,,2.459,APPEARANCE,COMPUTER GRAPHICS FORUM,,
66,Unified Neural Encoding of BTFs,39,2,167-178,"Rainer Gilles,Ghosh Abhijeet,Jakob Wenzel,Weyrich Tim","Rainer G,Ghosh A,Jakob W,Weyrich T",Rainer G,10.1111/cgf.13921,University of London,"Realistic rendering using discrete reflectance measurements is challenging, because arbitrary directions on the light and view hemispheres are queried at render time, incurring large memory requirements and the need for interpolation. This explains the desire for compact and continuously parametrized models akin to analytic BRDFs; however, fitting BRDF parameters to complex data such as BTF texels can prove challenging, as models tend to describe restricted function spaces that cannot encompass real-world behavior. Recent advances in this area have increasingly relied on neural representations that are trained to reproduce acquired reflectance data. The associated training process is extremely costly and must typically be repeated for each material. Inspired by autoencoders, we propose a unified network architecture that is trained on a variety of materials, and which projects reflectance measurements to a shared latent parameter space. Similarly to SVBRDF fitting, real-world materials are represented by parameter maps, and the decoder network is analog to the analytic BRDF expression (also parametrized on light and view directions for practical rendering application). With this approach, encoding and decoding materials becomes a simple matter of evaluating the network. We train and validate on BTF datasets of the University of Bonn, but there are no prerequisites on either the number of angular reflectance samples, or the sample positions. Additionally, we show that the latent space is well-behaved and can be sampled from, for applications such as mipmapping and texture synthesis.","CCS Concepts,. Computer Graphics -> Rendering",Article; Proceedings Paper,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Computer Science,,2.459,"TEXTURE,REPRESENTATION,COMPRESSION",COMPUTER GRAPHICS FORUM,https://discovery.ucl.ac.uk/10094250/7/Weyrich_rainer2020unified.pdf,
67,State of the Art on Neural Rendering,39,2,701-727,"Tewari A.,Fried O.,Thies J.,Sitzmann V.,Lombardi S.,Sunkavalli K.,Martin-Brualla R.,Simon T.,Saragih J.,Niessner M.","Tewari A,Fried O,Thies J,Sitzmann V,Lombardi S,Sunkavalli K,Martin-Brualla R,Simon T,Saragih J,Niessner M",Tewari A,10.1111/cgf.14022,Max Planck Society,"Efficient rendering of photo-realistic virtual worlds is a long standing effort of computer graphics. Modern graphics techniques have succeeded in synthesizing photo-realistic images from hand-crafted scene representations. However, the automatic generation of shape, materials, lighting, and other aspects of scenes remains a challenging problem that, if solved, would make photo-realistic computer graphics more widely accessible. Concurrently, progress in computer vision and machine learning have given rise to a new approach to image synthesis and editing, namely deep generative models. Neural rendering is a new and rapidly emerging field that combines generative machine learning techniques with physical knowledge from computer graphics, e.g., by the integration of differentiable rendering into network training. With a plethora of applications in computer graphics and vision, neural rendering is poised to become a new area in the graphics community, yet no survey of this emerging field exists. This state-of-the-art report summarizes the recent trends and applications of neural rendering. We focus on approaches that combine classic computer graphics techniques with deep generative models to obtain controllable and photorealistic outputs. Starting with an overview of the underlying computer graphics and machine learning concepts, we discuss critical aspects of neural rendering approaches. Specifically, our emphasis is on the type of control, i.e., how the control is provided, which parts of the pipeline are learned, explicit vs. implicit control, generalization, and stochastic vs. deterministic synthesis. The second half of this state-of-the-art report is focused on the many important use cases for the described algorithms such as novel view synthesis, semantic photo manipulation, facial and body reenactment, relighting, free-viewpoint video, and the creation of photo-realistic avatars for virtual and augmented reality telepresence. Finally, we conclude with a discussion of the social implications of such technology and investigate open research problems.","GENERATIVE ADVERSARIAL NETWORKS,IMAGE,REPRESENTATION,ILLUMINATION,MODEL",Article; Proceedings Paper,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Computer Science,,2.459,"GENERATIVE,ADVERSARIAL,NETWORKS,IMAGE,REPRESENTATION,ILLUMINATION,MODEL",COMPUTER GRAPHICS FORUM,http://arxiv.org/pdf/2004.03805,
68,Comparison of the Performance of Partial Least Squares and Support Vector Regressions for Predicting Fatty Acids and Fatty Acid Classes in Marine Oil Dietary Supplements by Using Vibrational Spectroscopic Data,83,5,881-889,"Karunathilaka Sanjeewa R.,Yakes Betsy Jean,Choi Sung Hwan,Bruckner Lea,Mossoba Magdi M.","Karunathilaka SR,Yakes BJ,Choi SH,Bruckner L,Mossoba MM",Karunathilaka SR,10.4315/JFP-19-563,University System of Maryland,"Simple, fast, and accurate analytical techniques for verifying the accuracy of label declarations for marine oil dietary supplements containing eicosapentaenoic acid (EPA) and docosahexaenoic acid (DHA) are required because of the increased consumption of these products. We recently developed broad-based partial least squares regression (PLS-R) models to quantify six fatty acids (FAs) and FA classes by using the spectroscopic data from a portable Fourier transform infrared (FTIR) device and a benchtop Fourier transform near infrared (FT-NIR) spectrometer. We developed an improved quantification method for these FAs and FA classes by incorporating a nonlinear calibration approach based on the machine learning technique support vector machines. For the two spectroscopic methods, high accuracy in prediction was indicated by low root mean square error of prediction and by correlation coefficients (R-2) close to 1, indicating excellent model performance. The percent accuracy of the support vector regression (SV-R) model predicted values for EPA and DHA in the reference material was 90 to 110%. In comparison to PLS-R, SV-R accuracy for prediction of FA and FA class concentrations was up to 2.4 times higher for both ATR-FTIR and FT-NIR spectroscopic data. The SV-R models also provided closer agreement with the certified and reference values for the prediction of EPA and DHA in the reference standard. Based on our findings, the SV-R methods had superior accuracy and predictive quality for predicting the FA concentrations in marine oil dietary supplements. The combination of SV-R with ATR-FTIR and/or FT-NIR spectroscopic data can potentially be applied for the rapid screening of marine oil products to verify the accuracy of label declarations.","Attenuated total reflection Fourier transform infrared spectroscopy,Fourier transform near infrared spectroscopy,Marine oil dietary supplements,Partial least squares regression,Support vector regression",Article,"INT ASSOC FOOD PROTECTION, 6200 AURORA AVE SUITE 200W, DES MOINES, IA 50322-2863 USA","Biotechnology & Applied Microbiology,Food Science & Technology",,2.224,"INFRARED-SPECTROSCOPY,RAMAN-SPECTROSCOPY,FTIR,SPECTROSCOPY,ATR-FTIR,CLASSIFICATION,MACHINES,MILK",JOURNAL OF FOOD PROTECTION,,
69,Automated delineation of the clinical target volume using anatomically constrained 3D expansion of the gross tumor volume,146,,37-43,"Shusharina Nadya,Soderberg Jonas,Edmunds David,Lofman Fredrik,Shih Helen,Bortfeld Thomas","Shusharina N,Soderberg J,Edmunds D,Lofman F,Shih H,Bortfeld T",Bortfeld T,10.1016/j.radonc.2020.01.028,Harvard University,,"RADIATION ONCOLOGY,SEGMENTATION,ORGANS,RISK,HEAD,CT",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,5.881,"RADIATION,ONCOLOGY,SEGMENTATION,ORGANS,RISK,HEAD,CT",RADIOTHERAPY AND ONCOLOGY,,
70,Constructing a Personalized Cross-Day EEG-Based Emotion-Classification Model Using Transfer Learning,24,5,1255-1264,Lin Yuan-Pin,Lin YP,Lin YP,10.1109/JBHI.2019.2934172,National Sun Yat Sen University,"State-of-the-art electroencephalogram (EEG)-based emotion-classification works indicate that a personalized model may not be well exploited until sufficient labeled data are available, given a substantial EEG non-stationarity over days. However, it is impractical to impose a labor-intensive, time-consuming multiple-day data collection. This study proposes a robust principal component analysis (RPCA)-embedded transfer learning (TL) to generate a personalized cross-day model with less labeled data, while obviating intra- and inter-individual differences. Upon the add-session-in validation on two datasets MDME (five-day data of 12 subjects) and SDMN (single-day data of 26 subjects), the experimental results showed that TL enabled the classifier of an MDME individual (using his/her 1st-day session only) to improve progressively in valence and arousal classification by adding similar source sessions (SSs) via the within-dataset TL (wdTL) and cross-dataset TL (cdTL) manners. When recruiting three SSs to test on the 5th-day session, the wdTL improvement (valence: 11.19%, arousal: 5.82%) marginally outperformed the subject-dependent (SD) counterpart (valence: 9.75%, arousal: 3.77%) that was obtained using their own 2nd-4th-day sessions only. The cdTL returned a similar trend in valence (8.35%), yet it was less effective in arousal (0.81%). Most importantly, such cross-day enhancements did not occur in either SD or TL scenarios until RPCA processing. This work sheds light on how to construct a personalized model by leveraging ever-growing EEG repositories.","Electroencephalography,Brain modeling,Data models,Oscillators,Principal component analysis,Emotional responses,Sparse matrices,Affective computing,EEG-based emotion classification,EEG non-stationarity,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,RECOGNITION,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
71,Synthesis of Electrocardiogram V-Lead Signals From Limb-Lead Measurement Using R-Peak Aligned Generative Adversarial Network,24,5,1265-1275,"Lee JeeEun,Oh KyeongTaek,Kim Byeongnam,Yoo Sun K.","Lee J,Oh K,Kim B,Yoo SK",Yoo SK,10.1109/JBHI.2019.2936583,Yonsei University,"Recently, portable electrocardiogram (ECG) hardware devices have been developed using limb-lead measurements. However, portable ECGs provide insufficient ECG information because of limitations in the number of leads and measurement positions. Therefore, in this study, V-lead ECG signals were synthesized from limb leads using an R-peak aligned generative adversarial network (GAN). The data used the Physikalisch-Technische Bundesanstalt (PTB) dataset provided by PhysioNet. First, R-peak alignment was performed to maintain the physiological information of the ECG. Second, time domain ECG was converted to bi-dimensional space by ordered time-sequence embedding. Finally, the GAN was learned through the pairs between the modified limb II (MLII) lead and each chest (V) lead. The result showed that the mean structural similarity index (SSIM) was 0.92, and the mean error rate of the percent mean square difference (PRD) of the chest leads was 7.21%.","Electrocardiography,Gallium nitride,Biomedical measurement,Generative adversarial networks,Mathematical model,Time-domain analysis,Informatics,Electrocardiogram,generative adversarial network,synthesis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"12-LEAD,ELECTROCARDIOGRAM,3-LEAD,DERIVATION,SYSTEM,ECG",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
72,Estimation of Vertical Ground Reaction Force Using Low-Cost Insole With Force Plate-Free Learning From Single Leg Stance and Walking,24,5,1276-1283,"Eguchi Ryo,Yorozu Ayanori,Fukumoto Takahiko,Takahashi Masaki","Eguchi R,Yorozu A,Fukumoto T,Takahashi M",Eguchi R,10.1109/JBHI.2019.2937279,Keio University,"For the evaluation of pathological gait, a machine learning-based estimation of the vertical ground reaction force (vGRF) using a low-cost insole is proposed as an alternative to costly force plates. However, learning a model for estimation still relies on the use of force plates, which is not accessible in small clinics and individuals. Therefore, this paper presents a force plate-free learning from a single leg stance (SLS) and natural walking measured only by the insoles. This method used a linear least squares regression that fits insole measurements during SLS to body weight in order to learn a model to estimate vGRF during walking. Constraints were added to the regression so that vGRF estimates during walking were of proper magnitude, and the constraint bounds were newly defined as a linear function of stance duration. Moreover, a lower bound for the estimated vGRF in mid-stance was added to the constraints to enhance estimation accuracy. The vGRF estimated by the proposed method was compared with force platforms for 4 healthy young adults and 13 elderly adults including patients with mild osteoarthritis, knee pain, and valgus hallux. Through the experiments, the proposed learning method had a normalized root mean squared error under 10% for healthy young and elderly adults with stance durations within a certain range (600-800 ms). From these results, the validity of the proposed learning method was verified for various users requiring assessment in the field of medicine and healthcare.","Gait analysis,estimation,ground reaction force,instrumented insole,machine learning,linear least squares regression,linear constraint,single leg stance,walking,force plate",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"AMBULATORY,ASSESSMENT,PRESSURE,INSOLES,GAIT,SPEED,SYSTEM,VALIDITY,FEEDBACK",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
73,Inter-Patient ECG Classification With Symbolic Representations and Multi-Perspective Convolutional Neural Networks,24,5,1321-1332,"Niu Jinghao,Tang Yongqiang,Sun Zhengya,Zhang Wensheng","Niu JH,Tang YQ,Sun ZY,Zhang WS",Zhang WS,10.1109/JBHI.2019.2942938,Chinese Academy of Sciences,"This paper presents a novel deep learning framework for the inter-patient electrocardiogram (ECG) heartbeat classification. A symbolization approach especially designed for ECG is introduced, which can jointly represent the morphology and rhythm of the heartbeat and alleviate the influence of inter-patient variation through baseline correction. The symbolic representation of the heartbeat is used by a multi-perspective convolutional neural network (MPCNN) to learn features automatically and classify the heartbeat. We evaluate our method for the detection of the supraventricular ectopic beat (SVEB) and ventricular ectopic beat (VEB) on MIT-BIH arrhythmia dataset. Compared with the state-of-the-art methods based on manual features or deep learning models, our method shows superior performance: the overall accuracy of 96.4%, F1 scores for SVEB and VEB of 76.6% and 89.7%, respectively. The ablation study on our method validates the effectiveness of the proposed symbolization approach and joint representation architecture, which can help the deep learning model to learn more general features and improve the ability of generalization for unseen patients. Because our method achieves a competitive inter-patient heartbeat classification performance without complex handcrafted features or the intervention of the human expert, it can also be adjusted to handle various other tasks relative to ECG classification.","Heart beat,Electrocardiography,Heart rate variability,Deep learning,Feature extraction,Task analysis,Informatics,ECG classification,biomedical monitoring,convolutional neural network,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"HEARTBEAT,CLASSIFICATION,ARRHYTHMIA,DETECTION,FEATURES",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
74,A Multi-Domain Connectome Convolutional Neural Network for Identifying Schizophrenia From EEG Connectivity Patterns,24,5,1333-1343,"Phang Chun-Ren,Noman Fuad,Hussain Hadri,Ting Chee-Ming,Ombao Hernando","Phang CR,Noman F,Hussain H,Ting CM,Ombao H",Ting CM,10.1109/JBHI.2019.2941222,Universiti Teknologi Malaysia,"Objective: We exploit altered patterns in brain functional connectivity as features for automatic discriminative analysis of neuropsychiatric patients. Deep learning methods have been introduced to functional network classification only very recently for fMRI, and the proposed architectures essentially focused on a single type of connectivity measure. Methods: We propose a deep convolutional neural network (CNN) framework for classification of electroencephalogram (EEG)-derived brain connectome in schizophrenia (SZ). To capture complementary aspects of disrupted connectivity in SZ, we explore combination of various connectivity features consisting of time and frequency-domain metrics of effective connectivity based on vector autoregressive model and partial directed coherence, and complex network measures of network topology. We design a novel multi-domain connectome CNN (MDC-CNN) based on a parallel ensemble of 1D and 2D CNNs to integrate the features from various domains and dimensions using different fusion strategies. We also consider an extension to dynamic brain connectivity using the recurrent neural networks. Results: Hierarchical latent representations learned by the multiple convolutional layers from EEG connectivity reveals apparent group differences between SZ and healthy controls (HC). Results on a large resting-state EEG dataset show that the proposed CNNs significantly outperform traditional support vector machine classifier. The MDC-CNN with combined connectivity features further improves performance over single-domain CNNs using individual features, achieving remarkable accuracy of 91.69% with a decision-level fusion. Conclusion: The proposed MDC-CNN by integrating information from diverse brain connectivity descriptors is able to accurately discriminate SZ from HC. Significance: The new framework is potentially useful for developing diagnostic tools for SZ and other disorders.","Electroencephalography,Reactive power,Time measurement,Frequency-domain analysis,Brain modeling,EEG,brain connectivity networks,deep learning,convolution neural networks,ensemble classifiers",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"AUTISM,SPECTRUM,DISORDER,BIPOLAR,DISORDER,BRAIN,NETWORKS,CLASSIFICATION,COHERENCE",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://repository.kaust.edu.sa/bitstream/10754/656770/1/08836535.pdf,
75,Deep Learning on Computerized Analysis of Chronic Obstructive Pulmonary Disease,24,5,1344-1350,"Altan Gokhan,Kutlu Yakup,Allahverdi Novruz","Altan G,Kutlu Y,Allahverdi N",Altan G,10.1109/JBHI.2019.2931395,Iskenderun Technical University,"Goal: Chronic obstructive pulmonary disease (COPD) is one of the deadliest diseases in the world. Because COPD is an incurable disease and requires considerable time to be diagnosed even by an experienced specialist, it becomes important to provide analysis abnormalities in simple ways. The aim of the study is to compare multiple machine-learning algorithms for the early diagnosis of COPD using multichannel lung sounds. Methods: Deep learning (DL) is an efficient machine-learning algorithm, which comprises unsupervised training to reduce optimization and supervised training by a feature-based distribution of classification parameters. This study focuses on analyzing multichannel lung sounds using statistical features of frequency modulations that are extracted using the Hilbert-Huang transform. Results: Deep-learning algorithm was used in the classification stage of the proposed model to separate the patients with COPD and healthy subjects. The proposed DL model with the Hilbert-Huang transform based statistical features was successful in achieving high classification performance rates of 93.67%, 91%, and 96.33% for accuracy, sensitivity, and specificity, respectively. Conclusion: The proposed computerized analysis of the multichannel lung sounds using DL algorithms provides a standardized assessment with high classification performance. Significance: Our study is a pioneer study that directly focuses on the lung sounds to separate COPD and non-COPD patients. Analyzing 12-channel lung sounds gives the advantages of assessing the entire lung obstructions.","Lung,Diseases,Classification algorithms,Transforms,Training,Feature extraction,Frequency modulation,Deep Learning,Deep Belief Networks,RespiratoryDatabase@TR,Chronic Obstructive Pulmonary Disease",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"EMPIRICAL,MODE,DECOMPOSITION,CLASSIFICATION,DIAGNOSIS",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
76,Sequential Saliency Guided Deep Neural Network for Joint Mitosis Identification and Localization in Time-Lapse Phase Contrast Microscopy Images,24,5,1367-1378,"Lu Yao,Liu An-An,Chen Mei,Nie Wei-Zhi,Su Yu-Ting","Lu Y,Liu AA,Chen M,Nie WZ,Su YT",Liu AA; Su YT,10.1109/JBHI.2019.2943228,Tianjin University,"The analysis of cell mitotic behavior plays important role in many biomedical research and medical diagnostic applications. To improve the accuracy of mitosis detection in automated analysis systems, this paper proposes the sequential saliency guided deep neural network (SSG-DNN) to jointly identify and localize mitotic events in time-lapse phase contrast microscopy images. It consists of three key modules. First, the module of visual context learning extracts static visual feature and dynamic visual transition within individual volumetric cell regions. Secondly, with these information, the module of sequential saliency modeling aims to discover the saliency distribution over all successive frames in each volumetric region. Finally, the module of sequence structure modeling can leverage both visual context and saliency distribution for mitosis identification and localization. SSG-DNN can jointly realize visual feature learning and sequential structure modeling in the end-to-end framework. Moreover, the proposed method is independent of complicated preconditioning methods for mitotic candidate extraction and can be applied for mitosis detection in one-shot manner. To our knowledge, it is the first weakly supervised work to realize joint mitosis identification and localization only with sequence-wise labels. In our experiments, we evaluate its performances of both tasks on the popular C3H10 dataset and a novel and large-scale dataset, C2C12-16, which contains much more mitotic events and is more challenging owing to diverse cell culture conditions. Experimental results can demonstrate the superiority of the proposed method.","Visualization,Feature extraction,Microscopy,Task analysis,Computer architecture,Image sequences,Informatics,Microscopy Image,Mitosis Detection,Computer Vision,Deep Learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"STEM-CELL,POPULATIONS,TRACKING,RECOGNITION,SEQUENCES",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
77,Clinical Interpretable Deep Learning Model for Glaucoma Diagnosis,24,5,1405-1412,"Liao WangMin,Zou BeiJi,Zhao RongChang,Chen YuanQiong,He ZhiYou,Zhou MengJie","Liao WM,Zou BJ,Zhao RC,Chen YQ,He ZY,Zhou MJ",Zhao RC,10.1109/JBHI.2019.2949075,Central South University,"Despite the potential to revolutionise disease diagnosis by performing data-driven classification, clinical interpretability of ConvNet remains challenging. In this paper, a novel clinical interpretable ConvNet architecture is proposed not only for accurate glaucoma diagnosis but also for the more transparent interpretation by highlighting the distinct regions recognised by the network. To the best of our knowledge, this is the first work of providing the interpretable diagnosis of glaucoma with the popular deep learning model. We propose a novel scheme for aggregating features from different scales to promote the performance of glaucoma diagnosis, which we refer to as M-LAP. Moreover, by modelling the correspondence from binary diagnosis information to the spatial pixels, the proposed scheme generates glaucoma activations, which bridge the gap between global semantical diagnosis and precise location. In contrast to previous works, it can discover the distinguish local regions in fundus images as evidence for clinical interpretable glaucoma diagnosis. Experimental results, performed on the challenging ORIGA datasets, show that our method on glaucoma diagnosis outperforms state-of-the-art methods with the highest AUC (0.88). Remarkably, the extensive results, optic disc segmentation (dice of 0.9) and local disease focus localization based on the evidence map, demonstrate the effectiveness of our methods on clinical interpretability.","Feature extraction,Semantics,Biomedical optical imaging,Optical imaging,Lesions,Convolution,Computer architecture,Glaucoma diagnosis,clinical interpreta-tion,medical image processing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"CAROTID-ARTERY,WALL,OPTIC,DISC",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
78,Predicting Quality of Overnight Glycaemic Control in Type 1 Diabetes Using Binary Classifiers,24,5,1439-1446,"Guemes Amparo,Cappon Giacomo,Hernandez Bernard,Reddy Monika,Oliver Nick,Georgiou Pantelis,Herrero Pau","Guemes A,Cappon G,Hernandez B,Reddy M,Oliver N,Georgiou P,Herrero P",Herrero P,10.1109/JBHI.2019.2938305,Imperial College London,"In type 1 diabetes management, maintaining nocturnal blood glucose within target range can be challenging. Although semi-automatic systems to modulate insulin pump delivery, such as low-glucose insulin suspension and the artificial pancreas, are starting to become a reality, their elevated cost and performance below user expectations is hindering their adoption. Hence, a decision support system that helps people with type 1 diabetes, on multiple daily injections or insulin pump therapy, to avoid undesirable overnight blood glucose fluctuations (hyper- or hypoglycaemic) is an attractive alternative. In this paper, we introduce a novel data-driven approach to predict the quality of overnight glycaemic control in people with type 1 diabetes by analyzing commonly gathered data during the day-time period (continuous glucose monitoring data, meal intake and insulin boluses). The proposed approach is able to predict whether overnight blood glucose concentrations are going to remain within or outside the target range, and therefore allows the user to take the appropriate preventive action (snack or change in basal insulin). For this purpose, a number of popular established machine learning algorithms for binary classification were evaluated and compared on a publicly available clinical dataset (i.e., OhioT1DM). Although there is no clearly superior classification algorithm, this study indicates that, by using commonly gathered data in type 1 diabetes management, it is possible to predict the quality of overnight glycaemic control with reasonable accuracy (AUC-ROC = 0.7).","Feature extraction,Insulin,Sugar,Diabetes,Blood,Decision support systems,Insulin pumps,Decision support systems,machine learning,glycaemic control,night quality,type 1 diabetes",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,,CHILDREN,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
79,Technical Validation of an Automated Mobile Gait Analysis System for Hereditary Spastic Paraplegia Patients,24,5,1490-1499,"Martindale Christine F.,Roth Nils,Gassner Heiko,List Julia,Regensburger Martin,Eskofier Bjoern M.,Kohl Zacharias","Martindale CF,Roth N,Gassner H,List J,Regensburger M,Eskofier BM,Kohl Z",Martindale CF,10.1109/JBHI.2019.2937574,University of Erlangen Nuremberg,"Hereditary spastic paraplegias (HSP) represents a group of orphan neurodegenerative diseases with gait disturbance as the predominant clinical feature. Due to its rarity, research within this field is still limited. Aside from clinical analysis using established scales, gait analysis has been employed to enhance the understanding of the mechanisms behind the disease. However, state of the art gait analysis systems are often large, immobile and expensive. To overcome these limitations, this paper presents the first clinically relevant mobile gait analysis system for HSP patients. We propose an unsupervised model based on local cyclicity estimation and hierarchical hidden Markov models (LCE-hHMM). The system provides stride time, swing time, stance time, swing duration and cadence. These parameters are validated against a GAITRite system and manual sensor data labelling using a total of 24 patients within 2 separate studies. The proposed system achieves a stride time error of -0.00 $\pm$ 0.09 s (correlation coefficient, r = 1.00) and a swing duration error of -0.67 $\pm$ 3.27 % (correlation coefficient, r = 0.93) with respect to the GAITRite system. We show that these parameters are also correlated to the clinical spastic paraplegia rating scale (SPRS) in a similar manner to other state of the art gait analysis systems, as well as to supervised and general versions of the proposed model. Finally, we show a proof of concept for this system to be used to analyse alterations in the gait of individual patients. Thus, with further clinical studies, due to its automated approach and mobility, this system could be used to determine treatment effects in future clinical trials.","Mobile gait analysis,hereditary spastic paraplegia,hidden Markov model,semi-supervised learning,cyclicity",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,,"STRIDE,LENGTH,FEATURES,DIPLEGIA,WALKING,FOOT",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
80,Multi-Objective Optimization for Personalized Prediction of Venous Thromboembolism in Ovarian Cancer Patients,24,5,1500-1508,"Fresard Maria Emilia,Erices Rafaela,Bravo Maria Loreto,Cuello Mauricio,Owen Gareth I,Ibanez Carolina,Rodriguez-Fernandez Maria","Fresard ME,Erices R,Bravo ML,Cuello M,Owen GI,Ibanez C,Rodriguez-Fernandez M",Rodriguez-Fernandez M,10.1109/JBHI.2019.2943499,Pontificia Universidad Catolica de Chile,"Thrombotic events are one of the leading causes of mortality and morbidity related to cancer, with ovarian cancer having one of the highest incidence rates. The need to prevent these events through the prescription of adequate schemes of antithrombotic prophylaxis has motivated the development of models that aid the identification of patients at higher risk of thrombotic events with lethal consequences. However, antithrombotic prophylaxis increases the risk of bleeding and this risk depends on the class and intensity of the chosen antithrombotic prophylactic scheme, the clinical and personal condition of the patient and the disease characteristics. Moreover, the datasets used to obtain current models are imbalanced, i.e., they incorporate more patients who did not suffer thrombotic events than patients who experienced them what can lead to wrong predictions, especially for the clinically relevant patient group at high risk of thrombosis. Herein, predictive models based on machine learning were developed utilizing 121 high-grade serous ovarian carcinoma patients, considering the clinical variables of the patients and those typical of the disease. To properly manage the data imbalance, cost-sensitive classification together with multi-objective optimization was performed considering different combinations of metrics. In this way, five Pareto fronts and a series of optimal models with different false positive and false negative rates were obtained. With this novel approach to the development of clinical predictive models, personalized models can be developed, helping the clinician to achieve a better balance between the risk of bleeding and the risk of thrombosis.","Predictive models,Measurement,Cancer,Thrombosis,Hemorrhaging,Biological system modeling,Optimization,Clinical biomarkers,prediction models,ovarian cancer,venous thromboembolism,multi-objective optimization",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"RISK-FACTORS,METABOLIC,SYNDROME,CHEMOTHERAPY,VALIDATION,THROMBOSIS,EVENTS,STRATIFICATION,CLASSIFICATION,MODEL",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
81,Early Prediction of Dropout and Final Exam Performance in an Online Statistics Course,15,2,86-94,"Figueroa-Canas Josep,Sancho-Vinuesa Teresa","Figueroa-Canas J,Sancho-Vinuesa T",Figueroa-Canas J,10.1109/RITA.2020.2987727,UOC Universitat Oberta de Catalunya,"Higher education students who either do not complete the courses they have enrolled on or interrupt their studies indefinitely remain a major concern for practitioners and researchers. Within each course, early prediction of student dropout helps teachers to intervene in time to reduce dropout rates. Early prediction of course achievement helps teachers suggest new learning materials aimed at preventing at-risk students from failing or not completing the course. Several machine learning techniques have been used to classify or predict at-risk students, including tree-based methods, which, though not the best performers, are easy to interpret. This study presents two procedures for identifying at-risk students (dropout-prone and non-achievers) early on in an online university statistics course. These enable us to understand how classifiers work. We found that student dropout and course performance prediction was only determined by their performance in the first half of the formative quizzes. Nevertheless, other elements of participation on the virtual campus were initially considered. The classifiers will serve as a reference for intervention, despite their moderate performance metrics.","Dropout prediction,performance prediction,decision trees,quiz completion,online university education",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Computer Science,,,"HIGHER-EDUCATION,STUDENT-DROPOUT,SUCCESS,MODELS",IEEE REVISTA IBEROAMERICANA DE TECNOLOGIAS DEL APRENDIZAJE-IEEE RITA,,
82,Manifold Embedded Knowledge Transfer for Brain-Computer Interfaces,28,5,1117-1127,"Zhang Wen,Wu Dongrui","Zhang W,Wu DR",Wu DR,10.1109/TNSRE.2020.2985996,Huazhong University of Science & Technology,"Transfer learning makes use of data or knowledge in one problem to help solve a different, yet related, problem. It is particularly useful in brain-computer interfaces (BCIs), for coping with variations among different subjects and/or tasks. This paper considers offline unsupervised cross-subject electroencephalogram (EEG) classification, i.e., we have labeled EEG trials from one or more source subjects, but only unlabeled EEG trials from the target subject. We propose a novel manifold embedded knowledge transfer (MEKT) approach, which first aligns the covariance matrices of the EEG trials in the Riemannian manifold, extracts features in the tangent space, and then performs domain adaptation by minimizing the joint probability distribution shift between the source and the target domains, while preserving their geometric structures. MEKT can cope with one or multiple source domains, and can be computed efficiently. We also propose a domain transferability estimation (DTE) approach to identify the most beneficial source domains, in case there are a large number of source domains. Experiments on four EEG datasets from two different BCI paradigms demonstrated that MEKT outperformed several state-of-the-art transfer learning approaches, and DTE can reduce more than half of the computational cost when the number of source subjects is large, with little sacrifice of classification accuracy.","Covariance matrices,Electroencephalography,Manifolds,Feature extraction,Task analysis,Geometry,Symmetric matrices,Brain-computer interfaces,electroencephalogram,Riemannian manifold,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"SINGLE-TRIAL,EEG,KERNEL,REGULARIZATION",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,http://arxiv.org/pdf/1910.05878,
83,Brain-Controlled Robotic Arm System Based on Multi-Directional CNN-BiLSTM Network Using EEG Signals,28,5,1226-1238,"Jeong Ji-Hoon,Shim Kyung-Hwan,Kim Dong-Joo,Lee Seong-Whan","Jeong JH,Shim KH,Kim DJ,Lee SW",Lee SW,10.1109/TNSRE.2020.2981659,Korea University,"Brain-machine interfaces (BMIs) can be used to decode brain activity into commands to control external devices. This paper presents the decoding of intuitive upper extremity imagery for multi-directional arm reaching tasks in three-dimensional (3D) environments. We designed and implemented an experimental environment in which electroencephalogram (EEG) signals can be acquired for movement execution and imagery. Fifteen subjects participated in our experiments. We proposed a multi-directional convolution neural network-bidirectional long short-term memory network (MDCBN)-based deep learning framework. The decoding performances for six directions in 3D space were measured by the correlation coefficient (CC) and the normalized root mean square error (NRMSE) between predicted and baseline velocity profiles. The grand-averaged CCs of multi-direction were 0.47 and 0.45 for the execution and imagery sessions, respectively, across all subjects. The NRMSE values were below 0.2 for both sessions. Furthermore, in this study, the proposed MDCBN was evaluated by two online experiments for real-time robotic arm control, and the grand-averaged success rates were approximately 0.60 (+/- 0.14) and 0.43 (+/- 0.09), respectively. Hence, we demonstrate the feasibility of intuitive robotic arm control based on EEG signals for real-world environments.","Brain-machine interface (BMI),electroencephalogram (EEG),motor imagery,intuitive robotic arm control,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"CONVOLUTIONAL,NEURAL-NETWORKS,MOTOR,IMAGERY,COMPUTER,INTERFACE,CLASSIFICATION,SUBJECT,SENSORIMOTOR,RECOGNITION,CORTEX",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
84,Emotion Recognition Using Convolutional Neural Network with Selected Statistical Photoplethysmogram Features,10,10,,"Lee MinSeop,Lee Yun Kyu,Lim Myo-Taeg,Kang Tae-Koo","Lee M,Lee YK,Lim MT,Kang TK",Lim MT,10.3390/app10103501,Korea University,"Emotion recognition research has been conducted using various physiological signals. In this paper, we propose an efficient photoplethysmogram-based method that fuses the deep features extracted by two deep convolutional neural networks and the statistical features selected by Pearson's correlation technique. A photoplethysmogram (PPG) signal can be easily obtained through many devices, and the procedure for recording this signal is simpler than that for other physiological signals. The normal-to-normal (NN) interval values of heart rate variability (HRV) were utilized to extract the time domain features, and the normalized PPG signal was used to acquire the frequency domain features. Then, we selected features that correlated highly with an emotion through Pearson's correlation. These statistical features were fused with deep-learning features extracted from a convolutional neural network (CNN). The PPG signal and the NN interval were used as the inputs of the CNN to extract the features, and the total concatenated features were utilized to classify the valence and the arousal, which are the basic parameters of emotion. The Database for Emotion Analysis using Physiological signals (DEAP) was chosen for the experiment, and the results demonstrated that the proposed method achieved a noticeable performance with a short recognition interval.","PPG,emotion recognition,statistical feature,feature fusion,convolutional neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/10/3501/pdf,
85,A Customized VGG19 Network with Concatenation of Deep and Handcrafted Features for Brain Tumor Detection,10,10,,"Rajinikanth Venkatesan,Raj Alex Noel Joseph,Thanaraj Krishnan Palani,Naik Ganesh R.","Rajinikanth V,Raj ANJ,Thanaraj KP,Naik GR",Naik GR,10.3390/app10103429,Western Sydney University,"Brain tumor (BT) is one of the brain abnormalities which arises due to various reasons. The unrecognized and untreated BT will increase the morbidity and mortality rates. The clinical level assessment of BT is normally performed using the bio-imaging technique, and MRI-assisted brain screening is one of the universal techniques. The proposed work aims to develop a deep learning architecture (DLA) to support the automated detection of BT using two-dimensional MRI slices. This work proposes the following DLAs to detect the BT: (i) implementing the pre-trained DLAs, such as AlexNet, VGG16, VGG19, ResNet50 and ResNet101 with the deep-features-based SoftMax classifier; (ii) pre-trained DLAs with deep-features-based classification using decision tree (DT), k nearest neighbor (KNN), SVM-linear and SVM-RBF; and (iii) a customized VGG19 network with serially-fused deep-features and handcrafted-features to improve the BT detection accuracy. The experimental investigation was separately executed using Flair, T2 and T1C modality MRI slices, and a ten-fold cross validation was implemented to substantiate the performance of proposed DLA. The results of this work confirm that the VGG19 with SVM-RBF helped to attain better classification accuracy with Flair (>99%), T2 (>98%), T1C (>97%) and clinical images (>98%).","brain tumor,brain MRI slices,VGG19,deep features,handcrafted-features,features concatenation,SVM-RBF",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"MR-IMAGES,SEGMENTATION,CLASSIFICATION,DIAGNOSIS,SYSTEM",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/10/3429/pdf,
86,Surrogate Neural Network Model for Prediction of Load-Bearing Capacity of CFSS Members Considering Loading Eccentricity,10,10,,Tien-Thinh Le,Le TT,Le TT,10.3390/app10103452,Duy Tan University,"In this study, a surrogate Machine Learning (ML)-based model was developed, to predict the load-bearing capacity (LBC) of concrete-filled steel square hollow section (CFSS) members, considering loading eccentricity. The proposed Artificial Neural Network (ANN) model was trained and validated against experimental data using the following error measurement criteria: coefficient of determination (R-2), slope of regression, root mean square error (RMSE) and mean absolute error (MAE). A parametric study was conducted to calibrate the parameters of the ANN model, including the number of neurons, activation function, cost function and training algorithm, respectively. The results showed that the ANN model can provide reliable and effective prediction of LBC (R-2 = 0.975, Slope = 0.975, RMSE = 294.424 kN and MAE = 191.878 kN). Sensitivity analysis showed that the geometric parameters of the steel tube (width and thickness) and the compressive strength of concrete were the most important variables. Finally, the effect of eccentric loading on the LBC of CFSS members is presented and discussed, showing that the ANN model can assist in the creation of continuous LBC maps, within the ranges of input variables adopted in this study.","concrete-filled steel square hollow section columns,compressive behavior,Machine Learning,loading eccentricity,surrogate model,load-bearing capacity",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"STEEL,TUBULAR,COLUMNS,STRENGTH,BEHAVIOR,PERFORMANCE,DESIGN,UNCERTAINTIES,ALGORITHM,SECTION,BOX",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/10/3452/pdf,
87,Neural Network Reflectance Prediction Model for Both Open Ocean and Coastal Waters,12,9,,"Mukherjee Lipi,Zhai Peng-Wang,Gao Meng,Hu Yongxiang,Franz Bryan A.,Werdell P. Jeremy","Mukherjee L,Zhai PW,Gao M,Hu YX,Franz BA,Werdell PJ",Zhai PW,10.3390/rs12091421,University System of Maryland,"Remote sensing of global ocean color is a valuable tool for understanding the ecology and biogeochemistry of the worlds oceans, and provides critical input to our knowledge of the global carbon cycle and the impacts of climate change. Ocean polarized reflectance contains information about the constituents of the upper ocean euphotic zone, such as colored dissolved organic matter (CDOM), sediments, phytoplankton, and pollutants. In order to retrieve the information on these constituents, remote sensing algorithms typically rely on radiative transfer models to interpret water color or remote-sensing reflectance; however, this can be resource-prohibitive for operational use due to the extensive CPU time involved in radiative transfer solutions. In this work, we report a fast model based on machine learning techniques, called Neural Network Reflectance Prediction Model (NNRPM), which can be used to predict ocean bidirectional polarized reflectance given inherent optical properties of ocean waters. This supervised model is trained using a large volume of data derived from radiative transfer simulations for coupled atmosphere and ocean systems using the successive order of scattering technique (SOS-CAOS). The performance of the model is validated against another large independent test dataset generated from SOS-CAOS. The model is able to predict both polarized and unpolarized reflectances with an absolute error (AE) less than 0.004 for 99% of test cases. We have also shown that the degree of linear polarization (DoLP) for unpolarized incident light can be predicted with an AE less than 0.002 for 99% of test cases. In general, the simulation time of SOS-CAOS depends on optical depth, and required accuracy. When comparing the average speeds of the NNRPM against the SOS-CAOS model for the same parameters, we see that the NNRPM is able to predict the Ocean BRDF 6000 times faster than SOS-CAOS. Both ultraviolet and visible wavelengths are included in the model to help differentiate between dissolved organic material and chlorophyll in the study of the open ocean and the coastal zone. The incorporation of this model into the retrieval algorithm will make the retrieval process more efficient, and thus applicable for operational use with global satellite observations.","radiative transfer,retrieval,reflectance model,polarization,ocean optics,neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Geology,Remote Sensing,Imaging Science & Photographic Technology",,,"INHERENT,OPTICAL-PROPERTIES,POLARIMETRIC,MEASUREMENTS,MULTIPLE-SCATTERING,LEAVING,RADIANCE,JOINT,RETRIEVAL,MUELLER,MATRIX,PHASE,FUNCTION,COLOR,AEROSOL,INVERSION",REMOTE SENSING,https://www.mdpi.com/2072-4292/12/9/1421/pdf,
88,Predicting the suitability of lateritic soil type for low cost sustainable housing with image recognition and machine learning techniques,29,,,"Olukan Tuza A.,Chiou Yu-Cheng,Chiu Cheng Hsiang,Lai Chia-Yun,Santos Sergio,Chiesa Matteo","Olukan TA,Chiou YC,Chiu CH,Lai CY,Santos S,Chiesa M",Chiesa M,10.1016/j.jobe.2020.101175,UiT The Arctic University of Tromso,"From a sustainability point of view, laterites-compressed earth bricks (LCEB) are a promising substitute for building structures in place of the conventional concrete masonry units. On the other hand, techniques for identifying and classifying laterites soil for compressed earth bricks (CEB) production are still relying on direct human expertise or `experts'. Human experts exploit direct visual inspection and other basic senses such as smelling, touching or nibbling to generate a form of binomial classification, i.e. suitable or unsuitable. The source of predictive power is otherwise supposed to be found in color, scent, texture or combinations of these. Lack of clarity regarding the actual method and the possible explanatory mechanisms lead to 1) difficulties to train other people into the skills and 2) might also add to apathy to using CEB masonry units for housing. Here we systematize the selection method of experts. We chose imaging analysis techniques based on 1) easiness in image acquisition (Digital Camera) and 2) availability of machine learning and statistical techniques. We find that most of the predictive power of the 'expert' can be packed into visual inspection by demonstrating that with image analysis alone we get a 98% match. This makes it practically unnecessary the study of any other 'expert' skills and provides a method to alleviate the housing problems dealing with material construction in the developing world.","Increase,Sustainability,Building materials,Housing,Shortage",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Construction & Building Technology,Engineering",,,"ARTIFICIAL,NEURAL-NETWORK,ENGINEERING,CLASSIFICATION,DIGITAL,CAMERA,COLOR",JOURNAL OF BUILDING ENGINEERING,https://munin.uit.no/bitstream/10037/20249/3/article.pdf,
89,Modified U-Net (mU-Net) With Incorporation of Object-Dependent High Level Features for Improved Liver and Liver-Tumor Segmentation in CT Images,39,5,1316-1325,"Seo Hyunseok,Huang Charles,Bassenne Maxime,Xiao Ruoxiu,Xing Lei","Seo H,Huang C,Bassenne M,Xiao RX,Xing L",Xing L,10.1109/TMI.2019.2948320,Stanford University,"Segmentation of livers and liver tumors is one of the most important steps in radiation therapy of hepatocellular carcinoma. The segmentation task is often done manually, making it tedious, labor intensive, and subject to intra-/inter- operator variations. While various algorithms for delineating organ-at-risks (OARs) and tumor targets have been proposed, automatic segmentation of livers and liver tumors remains intractable due to their low tissue contrast with respect to the surrounding organs and their deformable shape in CT images. The U-Net has gained increasing popularity recently for image analysis tasks and has shown promising results. Conventional U-Net architectures, however, suffer from three major drawbacks. First, skip connections allow for the duplicated transfer of low resolution information in feature maps to improve efficiency in learning, but this often leads to blurring of extracted image features. Secondly, high level features extracted by the network often do not contain enough high resolution edge information of the input, leading to greater uncertainty where high resolution edge dominantly affects the network's decisions such as liver and liver-tumor segmentation. Thirdly, it is generally difficult to optimize the number of pooling operations in order to extract high level global features, since the number of pooling operations used depends on the object size. To cope with these problems, we added a residual path with deconvolution and activation operations to the skip connection of the U-Net to avoid duplication of low resolution information of features. In the case of small object inputs, features in the skip connection are not incorporated with features in the residual path. Furthermore, the proposed architecture has additional convolution layers in the skip connection in order to extract high level global features of small object inputs as well as high level features of high resolution edge information of large object inputs. Efficacy of the modified U-Net (mU-Net) was demonstrated using the public dataset of Liver tumor segmentation (LiTS) challenge 2017. For liver-tumor segmentation, Dice similarity coefficient (DSC) of 89.72 %, volume of error (VOE) of 21.93 %, and relative volume difference (RVD) of - 0.49 % were obtained. For liver segmentation, DSC of 98.51 %, VOE of 3.07 %, and RVD of 0.26 % were calculated. For the public 3D Image Reconstruction for Comparison of Algorithm Database (3Dircadb), DSCs were 96.01 % for the liver and 68.14 % for liver-tumor segmentations, respectively. The proposed mU-Net outperformed existing state-of-art networks.","Feature extraction,Liver,Convolution,Image segmentation,Tumors,Data mining,Biomedical imaging,Frequency analysis,deep learning,liver segmentation,mU-Net,U-Net",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORKS",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1911.00140,
90,A Spatio-Temporal Model of Seizure Propagation in Focal Epilepsy,39,5,1404-1418,"Craley Jeff,Johnson Emily,Venkataraman Archana","Craley J,Johnson E,Venkataraman A",Craley J,10.1109/TMI.2019.2950252,Johns Hopkins University,"We propose a novel Coupled Hidden Markov Model (CHMM) to detect and localize epileptic seizures in clinical multichannel scalp electroencephalography (EEG) recordings. Our model captures the spatio-temporal spread of a seizure by assigning a sequence of latent states (i.e. baseline or seizure) to each EEG channel. The state evolution is coupled between neighboring and contralateral channels to mimic clinically observed spreading patterns. Since the latent state space is exponential, a structured variational algorithm is developed for approximate inference. The model is evaluated on simulated and clinical EEG from two different hospitals. One dataset contains seizure recordings of adult focal epilepsy patients at the Johns Hopkins Hospital; the other contains publicly available non-specified seizure recordings from pediatric patients at Boston Children's Hospital. Our CHMM model outperforms standard machine learning techniques in the focal dataset and achieves comparable performance to the best baseline method in the pediatric dataset. We also demonstrate the ability to track seizures, which is valuable information to localize focal onset zones.","Electroencephalography,Hidden Markov models,Brain modeling,Feature extraction,Epilepsy,Time-domain analysis,Support vector machines,Seizure detection,focal epilepsy,coupled hidden Markov models,variational inference,electroencephalography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"DISCRETE,WAVELET,TRANSFORM,EEG,PERFORMANCE,METHODOLOGY,DETECT",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
91,A 3D Probabilistic Deep Learning System for Detection and Diagnosis of Lung Cancer Using Low-Dose CT Scans,39,5,1419-1429,"Ozdemir Onur,Russell Rebecca L.,Berlin Andrew A.","Ozdemir O,Russell RL,Berlin AA",Berlin AA,10.1109/TMI.2019.2947595,"Draper, Cambridge, MA 02139 USA.","We introduce a new computer aided detection and diagnosis system for lung cancer screening with low-dose CT scans that produces meaningful probability assessments. Our system is based entirely on 3D convolutional neural networks and achieves state-of-the-art performance for both lung nodule detection and malignancy classification tasks on the publicly available LUNA16 and Kaggle Data Science Bowl challenges. While nodule detection systems are typically designed and optimized on their own, we find that it is important to consider the coupling between detection and diagnosis components. Exploiting this coupling allows us to develop an end-to-end system that has higher and more robust performance and eliminates the need for a nodule detection false positive reduction stage. Furthermore, we characterize model uncertainty in our deep learning systems, a first for lung CT analysis, and show that we can use this to provide well-calibrated classification probabilities for both nodule detection and patient malignancy diagnosis. These calibrated probabilities informed by model uncertainty can be used for subsequent risk-based decision making towards diagnostic interventions or disease treatments, as we demonstrate using a probability-based patient referral strategy to further improve our results.","Solid modeling,Lung,Three-dimensional displays,Cancer,Computed tomography,Deep learning,Uncertainty,Machine learning,artificial neural networks,medical diagnostic imaging,image segmentation,image classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"NODULES,IMAGES",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1902.03233,
92,Identifying Morphological Indicators of Aging With Neural Networks on Large-Scale Whole-Body MRI,39,5,1430-1437,"Langner Taro,Wikstrom Johan,Bjerner Tomas,Ahlstrom Hakan,Kullberg Joel","Langner T,Wikstrom J,Bjerner T,Ahlstrom H,Kullberg J",Langner T,10.1109/TMI.2019.2950092,Uppsala University,"A wealth of information is contained in images obtained by whole-body magnetic resonance imaging (MRI). Studying the link between the imaged anatomy and properties known from outside sources has the potential to give new insights into the underlying factors that manifest themselves in individual human morphology. In this work we investigate the expression of age-related changes in the whole-body image. A large dataset of about 32,000 subjects scanned from neck to knee and aged 44-82 years from the UK Biobank study was used for a machine-based analysis. We trained a convolutional neural network based on the VGG16 architecture to predict the age of a given subject based on image data from these scans. In 10-fold cross-validation on 23,000 of these images the network reached a mean absolute error (MAE) of 2.49 years (R-2 = 0.83) and showed consistent performance on a separate test set of another 8,000 images. On a second test set of 100 images the network outperformed the averaged estimates given by three experienced radiologists, which reached an MAE of 5.58 years (R-2 = 0.08), by more than three years on average. In an attempt to explain these findings, we employ saliency analysis that opens up the image-based criteria used by the automated method to human interpretation. We aggregate the saliency into a single anatomical visualization which clearly highlights structures in the aortic arch and knee as primary indicators of age.","Magnetic resonance imaging,Biomedical imaging,Aging,Training,Radiology,Surgery,Magnetic resonance imaging (MRI),whole-body,machine learning,neural network,age",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,AGE,IEEE TRANSACTIONS ON MEDICAL IMAGING,https://ieeexplore.ieee.org/ielx7/42/9084068/08887538.pdf,
93,Dense Depth Estimation in Monocular Endoscopy With Self-Supervised Learning Methods,39,5,1438-1447,"Liu Xingtong,Sinha Ayushi,Ishii Masaru,Hager Gregory D.,Reiter Austin,Taylor Russell H.,Unberath Mathias","Liu XT,Sinha A,Ishii M,Hager GD,Reiter A,Taylor RH,Unberath M",Liu XT,10.1109/TMI.2019.2950936,Johns Hopkins University,"We present a self-supervised approach to training convolutional neural networks for dense depth estimation from monocular endoscopy data without a priori modeling of anatomy or shading. Our method only requires monocular endoscopic videos and a multi-view stereo method, e.g., structure from motion, to supervise learning in a sparse manner. Consequently, our method requires neither manual labeling nor patient computed tomography (CT) scan in the training and application phases. In a cross-patient experiment using CT scans as groundtruth, the proposed method achieved submillimeter mean residual error. In a comparison study to recent self-supervised depth estimation methods designed for natural video on in vivo sinus endoscopy data, we demonstrate that the proposed approach outperforms the previous methods by a large margin. The source code for this work is publicly available online at https://github.com/lppllppl920/EndoscopyDepthEstimation-Pytorch.","Estimation,Endoscopes,Cameras,Videos,Training,Image reconstruction,Three-dimensional displays,Endoscopy,unsupervised learning,self-supervised learning,depth estimation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"NAVIGATION,SYSTEM,VISION",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7289272,
94,Automatic Diagnosis Based on Spatial Information Fusion Feature for Intracranial Aneurysm,39,5,1448-1458,"Zeng Yuwen,Liu Xinke,Xiao Nan,Li Youxiang,Jiang Yuhua,Feng Junqiang,Guo Shuxiang","Zeng YW,Liu XK,Xiao N,Li YX,Jiang YH,Feng JQ,Guo SX",Xiao N,10.1109/TMI.2019.2951439,Beijing Institute of Technology,"Timely and accurate auxiliary diagnosis of intracranial aneurysm can help radiologist make treatment plans quickly, saving lives and cutting costs at the same time. At present, Digital Subtraction Angiography (DSA) is the gold standard for the diagnosis of intracranial aneurysm, but as radiologists interpret those imaging sequences frame by frame, misdiagnosis might occur. The utilization of computer-aided diagnosis (CAD) can ease the burdens of radiologists and improve the detection accuracy of aneurysms. In this article, a deep learning method is applied to detect the intracranial aneurysm in 3D Rotational Angiography (3D-RA) based on a spatial information fusion (SIF) method, and instead of a 3D vascular model, 2D image sequences are used. Given the intracranial aneurysm and vascular overlap having similar feature in the most time, rather than focusing on distinguishing them in one frame, the morphological differences between frames are considered as major feature. In the training data, consecutive frames of every imaging time series are extracted and concatenated in a specific way, so that the spatial contextual information could be embedded into a single two-dimensional image. This method enables the time series with obvious correlation between frames be directly trained on 2D convolutional neural network (CNN), instead of 3D-CNN with huge computational cost. Finally, we got an accuracy of 98.89%, with sensitivity and specificity of 99.38% and 98.19%, respectively, which proves the feasibility and availability of the SIF feature.","Aneurysm,Three-dimensional displays,Angiography,Sensitivity,Two dimensional displays,Intracranial aneurysm,computer-aided diagnosis,spatial information fusion,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"ANGIOGRAPHY,DSA",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
95,CANet: Cross-Disease Attention Network for Joint Diabetic Retinopathy and Diabetic Macular Edema Grading,39,5,1483-1493,"Li Xiaomeng,Hu Xiaowei,Yu Lequan,Zhu Lei,Fu Chi-Wing,Heng Pheng-Ann","Li XM,Hu XW,Yu LQ,Zhu L,Fu CW,Heng PA",Li XM; Hu XW,10.1109/TMI.2019.2951844,Chinese University of Hong Kong,"Diabetic retinopathy (DR) and diabetic macular edema (DME) are the leading causes of permanent blindness in the working-age population. Automatic grading of DR and DME helps ophthalmologists design tailored treatments to patients, thus is of vital importance in the clinical practice. However, prior works either grade DR or DME, and ignore the correlation between DR and its complication, i.e., DME. Moreover, the location information, e.g., macula and soft hard exhaust annotations, are widely used as a prior for grading. Such annotations are costly to obtain, hence it is desirable to develop automatic grading methods with only image-level supervision. In this article, we present a novel cross-disease attention network (CANet) to jointly grade DR and DME by exploring the internal relationship between the diseases with only image-level supervision. Our key contributions include the disease-specific attention module to selectively learn useful features for individual diseases, and the disease-dependent attention module to further capture the internal relationship between the two diseases. We integrate these two attention modules in a deep network to produce disease-specific and disease-dependent features, and to maximize the overall performance jointly for grading DR and DME. We evaluate our network on two public benchmark datasets, i.e., ISBI 2018 IDRiD challenge dataset and Messidor dataset. Our method achieves the best result on the ISBI 2018 IDRiD challenge dataset and outperforms other methods on the Messidor dataset. Our code is publicly available at https://github.com/xmengli999/CANet.","Diabetes,Task analysis,Feature extraction,Retinopathy,Hemorrhaging,Biomedical imaging,Diabetic retinopathy,diabetic macular edema,joint grading,attention mechanism",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"RETINAL,IMAGES,SYSTEM",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1911.01376,
96,Privileged Modality Distillation for Vessel Border Detection in Intracoronary Imaging,39,5,1524-1534,"Gao Zhifan,Chung Jonathan,Abdelrazek Mohamed,Leung Stephanie,Hau William Kongto,Xian Zhanchao,Zhang Heye,Li Shuo","Gao ZF,Chung J,Abdelrazek M,Leung S,Hau WK,Xian ZC,Zhang HY,Li S",Li S,10.1109/TMI.2019.2952939,Western University (University of Western Ontario),"Intracoronary imaging is a crucial imaging technology in coronary disease diagnosis as it visualizes the internal tissue morphologies of coronary arteries. Vessel border detection in intracoronary images (VBDI) is desired because it can help the succeeding procedures of computer-aided disease diagnosis. However, existing VDBI methods suffer from the challenge of vessel-environment variability (i.e. high intra- and inter-subject diversity of vessels and their surrounding tissues appeared in images). This challenge leads to the ineffectiveness in the vessel region representation for hand-crafted features, in the receptive field extraction for deeply-represented features, as well as performance suppression derived from clinical data limitation. To solve this challenge, we propose a novel privileged modality distillation (PMD) framework for VBDI. PMD transforms the single-input-single-task (SIST) learning problem in the single-mode VBDI to a multiple-input-multiple-task (MIMT) problem by using the privileged image modality to help the learning model in the target modality. This learns the enriched high-level knowledge with similar semantics and generalizes PMD on diversity-increased low-level image features for improving the model adaptation to diverse vessel environments. Moreover, PMD refines MIMT to SIST by distilling the learned knowledge from multiple to one modality. This eliminates the reliance on privileged modality in the test phase, and thus enables the applicability to each of different intracoronary modalities. A structure-deformable neural network is proposed as an elaborately-designed implementation of PMD. It expands a conventional SIST network structure to the MIMT structure, and then recovers it to the final SIST structure. The PMD is validated on intravascular ultrasound imaging and optical coherence tomography imaging. One modality is the target, and the other one can be considered as the privileged modality owing to their semantic relatedness. The experiments show that our PMD is effective in VBDI (e.g. the Dice index is larger than 0.95), as well as superior to six state-of-the-art VBDI methods.","Vessel border detection,privileged information,knowledge distillation,intravascular ultrasound,optical coherence tomography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"OPTICAL,COHERENCE,TOMOGRAPHY,MEDIA-ADVENTITIA,BORDERS,CAROTID-ARTERY,WALL,INTRAVASCULAR,ULTRASOUND,SEGMENTATION,LUMEN,ANGIOGRAPHY,IVUS,ACQUISITION,STANDARDS",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
97,Deep Learning Analysis of Coronary Arteries in Cardiac CT Angiography for Detection of Patients Requiring Invasive Coronary Angiography,39,5,1545-1557,"Zreik Majd,van Hamersvelt Robbert W.,Khalili Nadieh,Wolterink Jelmer M.,Voskuil Michiel,Viergever Max A.,Leiner Tim,Isgum Ivana","Zreik M,van Hamersvelt RW,Khalili N,Wolterink JM,Voskuil M,Viergever MA,Leiner T,Isgum I",Zreik M,10.1109/TMI.2019.2953054,Utrecht University,"In patients with obstructive coronary artery disease, the functional significance of a coronary artery stenosis needs to be determined to guide treatment. This is typically established through fractional flow reserve (FFR) measurement, performed during invasive coronary angiography (ICA). We present a method for automatic and non-invasive detection of patients requiring ICA, employing deep unsupervised analysis of complete coronary arteries in cardiac CT angiography (CCTA) images. We retrospectively collected CCTA scans of 187 patients, 137 of them underwent invasive FFR measurement in 192 different coronary arteries. These FFR measurements served as a reference standard for the functional significance of the coronary stenosis. The centerlines of the coronary arteries were extracted and used to reconstruct straightened multi-planar reformatted (MPR) volumes. To automatically identify arteries with functionally significant stenosis that require ICA, each MPR volume was encoded into a fixed number of encodings using two disjoint 3D and 1D convolutional autoencoders performing spatial and sequential encodings, respectively. Thereafter, these encodings were employed to classify arteries using a support vector machine classifier. The detection of coronary arteries requiring invasive evaluation, evaluated using repeated cross-validation experiments, resulted in an area under the receiver operating characteristic curve of 0.81 +/- 0.02 on the artery-level, and 0.87 +/- 0.02 on the patient-level. The results demonstrate the feasibility of automatic non-invasive detection of patients that require ICA and possibly subsequent coronary artery intervention. This could potentially reduce the number of patients that unnecessarily undergo ICA.","Functionally significant coronary artery stenosis,convolutional autoencoder,convolutional neural network,fractional flow reserve,coronary CT angiography,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,"FRACTIONAL,FLOW,RESERVE,COMPUTED-TOMOGRAPHY,DIAGNOSTIC,PERFORMANCE,GRAY,ZONE,FOLLOW-UP,DISEASE,STENOSES,QUANTIFICATION,SEGMENTATION,SEVERITY",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1906.04419,
98,Imaging of Nonlinear and Dynamic Functional Brain Connectivity Based on EEG Recordings With the Application on the Diagnosis of Alzheimer's Disease,39,5,1571-1581,"Zhao Yifan,Zhao Yitian,Durongbhan Pholpat,Chen Liangyu,Liu Jiang,Billings S. A.,Zis Panagiotis,Unwin Zoe C.,De Marco Matteo,Venneri Annalena","Zhao YF,Zhao YT,Durongbhan P,Chen LY,Liu J,Billings SA,Zis P,Unwin ZC,De Marco M,Venneri A",Chen LY,10.1109/TMI.2019.2953584,China Medical University,"Since age is the most significant risk factor for the development of Alzheimer's disease (AD), it is important to understand the effect of normal ageing on brain network characteristics before we can accurately diagnose the condition based on information derived from resting state electroencephalogram (EEG) recordings, aiming to detect brain network disruption. This article proposes a novel brain functional connectivity imaging method, particularly targeting the contribution of nonlinear dynamics of functional connectivity, on distinguishing participants with AD from healthy controls (HC). We describe a parametric method established upon a Nonlinear Finite Impulse Response model, and a revised orthogonal least squares algorithm used to estimate the linear, nonlinear and combined connectivity between any two EEG channels without fitting a full model. This approach, where linear and non-linear interactions and their spatial distribution and dynamics can be estimated independently, offered us the means to dissect the dynamic brain network disruption in AD from a new perspective and to gain some insight into the dynamic behaviour of brain networks in two age groups (above and below 70) with normal cognitive function. Although linear and stationary connectivity dominates the classification contributions, quantitative results have demonstrated that nonlinear and dynamic connectivity can significantly improve the classification accuracy, barring the group of participants below the age of 70, for resting state EEG recorded during eyes open. The developed approach is generic and can be used as a powerful tool to examine brain network characteristics and disruption in a user friendly and systematic way.","Alzheimer's disease,dementia,visualisation,system identification,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"SCALP,EEG,EPILEPSY",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://dspace.lib.cranfield.ac.uk/bitstream/1826/14771/1/functional_brain_connectivity_based_on_EEG_recordings-2019.pdf,
99,Dilated Residual Learning With Skip Connections for Real-Time Denoising of Laser Speckle Imaging of Blood Flow in a Log-Transformed Domain,39,5,1582-1593,"Chen Weimin,Lu Jinling,Zhu Xuan,Hong Jiachi,Liu Xiaohu,Li Miaowen,Li Pengcheng","Chen WM,Lu JL,Zhu X,Hong JC,Liu XH,Li MW,Li PC",Li PC,10.1109/TMI.2019.2953626,Huazhong University of Science & Technology,"Laser speckle contrast imaging (LSCI) is a wide-field and noncontact imaging technology for mapping blood flow. Although the denoising method based on block-matching and three-dimensional transform-domain collaborative filtering (BM3D) was proposed to improve its signal-to-noise ratio (SNR) significantly, the processing time makes it difficult to realize real-time denoising. Furthermore, it is still difficult to obtain an acceptable level of SNR with a few raw speckle images given the presence of significant noise and artifacts. A feed-forward denoising convolutional neural network (DnCNN) achieves state-of-the-art performance in denoising nature images and is efficiently accelerated by GPU. However, it performs poorly in learning with original speckle contrast images of LSCI owing to the inhomogeneous noise distribution. Therefore, we propose training DnCNN for LSCI in a log-transformed domain to improve training accuracy and it achieves an improvement of 5.13 dB in the peak signal-to-noise ratio (PSNR). To decrease the inference time and improve denoising performance, we further propose a dilated deep residual learning network with skip connections (DRSNet). The image-quality evaluations of DRSNet with five raw speckle images outperform that of spatially average denoising with 20 raw speckle images. DRSNet takes 35 ms (i.e., 28 frames per second) for denoising a blood flow image with $486\times648$ pixels on an NVIDIA 1070 GPU, which is approximately 2.5 times faster than DnCNN. In the test sets, DRSNet also improves 0.15 dB in the PSNR than that of DnCNN. The proposed network shows good potential in real-time monitoring of blood flow for biomedical applications.","Blood flow,convolutional neural network (CNN),dilated convolution,laser speckle contrast imaging (LSCI),skip connection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONTRAST,EXPOSURE,SPECTROSCOPY,VISIBILITY,ALGORITHM",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
100,Progressively Trained Convolutional Neural Networks for Deformable Image Registration,39,5,1594-1604,"Eppenhof Koen A. J.,Lafarge Maxime W.,Veta Mitko,Pluim Josien P. W.","Eppenhof KAJ,Lafarge MW,Veta M,Pluim JPW",Eppenhof KAJ,10.1109/TMI.2019.2953788,Eindhoven University of Technology,"Deep learning-based methods for deformable image registration are attractive alternatives to conventional registration methods because of their short registration times. However, these methods often fail to estimate larger displacements in complex deformation fields, for which a multi-resolution strategy is required. In this article, we propose to train neural networks progressively to address this problem. Instead of training a large convolutional neural network on the registration task all at once, we initially train smaller versions of the network on lower resolution versions of the images and deformation fields. During training, we progressively expand the network with additional layers that are trained on higher resolution data. We show that this way of training allows a network to learn larger displacements without sacrificing registration accuracy and that the resulting network is less sensitive to large misregistrations compared to training the full network all at once. We generate a large number of ground truth example data by applying random synthetic transformations to a training set of images, and test the network on the problem of intrapatient lung CT registration. We analyze the learned representations in the progressively growing network to assess how the progressive learning strategy influences training. Finally, we show that a progressive training procedure leads to improved registration accuracy when learning large and complex deformations.","Deformable image registration,progressive training,convolutional neural networks,machine learning,lung registration",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"INFORMATION,FRAMEWORK",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
