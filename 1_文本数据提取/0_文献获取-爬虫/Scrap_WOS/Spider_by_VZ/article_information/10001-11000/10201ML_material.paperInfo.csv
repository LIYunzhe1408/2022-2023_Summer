,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Deep-Learning-Enabled Fast Optical Identification and Characterization of 2D Materials,32,29,,"Han Bingnan,Lin Yuxuan,Yang Yafang,Mao Nannan,Li Wenyue,Wang Haozhe,Yasuda Kenji,Wang Xirui,Fatemi Valla,Zhou Lin","Han B,Lin YX,Yang YF,Mao NN,Li WY,Wang HZ,Yasuda KJ,Wang XR,Fatemi V,Zhou L",Yin J,10.1002/adma.202000953,Beihang University,"Advanced microscopy and/or spectroscopy tools play indispensable roles in nanoscience and nanotechnology research, as they provide rich information about material processes and properties. However, the interpretation of imaging data heavily relies on the ""intuition"" of experienced researchers. As a result, many of the deep graphical features obtained through these tools are often unused because of difficulties in processing the data and finding the correlations. Such challenges can be well addressed by deep learning. In this work, the optical characterization of 2D materials is used as a case study, and a neural-network-based algorithm is demonstrated for the material and thickness identification of 2D materials with high prediction accuracy and real-time processing capability. Further analysis shows that the trained network can extract deep graphical features such as contrast, color, edges, shapes, flake sizes, and their distributions, based on which an ensemble approach is developed to predict the most relevant physical properties of 2D materials. Finally, a transfer learning technique is applied to adapt the pretrained network to other optical identification applications. This artificial-intelligence-based material characterization approach is a powerful tool that would speed up the preparation, initial characterization of 2D materials and other nanomaterials, and potentially accelerate new material discoveries.","2D materials,deep learning,machine learning,optical microscopy",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,30.254,GRAPHENE,ADVANCED MATERIALS,https://dspace.mit.edu/bitstream/1721.1/133692/2/1906.11220.pdf,
2,CapsNet-SSP: multilane capsule network for predicting human saliva-secretory proteins,21,1,,"Du Wei,Sun Yu,Li Gaoyang,Cao Huansheng,Pang Ran,Li Ying","Du W,Sun Y,Li GY,Cao HS,Pang R,Li Y",Li Y,10.1186/s12859-020-03579-2,Jilin University,"Background Compared with disease biomarkers in blood and urine, biomarkers in saliva have distinct advantages in clinical tests, as they can be conveniently examined through noninvasive sample collection. Therefore, identifying human saliva-secretory proteins and further detecting protein biomarkers in saliva have significant value in clinical medicine. There are only a few methods for predicting saliva-secretory proteins based on conventional machine learning algorithms, and all are highly dependent on annotated protein features. Unlike conventional machine learning algorithms, deep learning algorithms can automatically learn feature representations from input data and thus hold promise for predicting saliva-secretory proteins. Results We present a novel end-to-end deep learning model based on multilane capsule network (CapsNet) with differently sized convolution kernels to identify saliva-secretory proteins only from sequence information. The proposed model CapsNet-SSP outperforms existing methods based on conventional machine learning algorithms. Furthermore, the model performs better than other state-of-the-art deep learning architectures mostly used to analyze biological sequences. In addition, we further validate the effectiveness of CapsNet-SSP by comparison with human saliva-secretory proteins from existing studies and known salivary protein biomarkers of cancer. Conclusions The main contributions of this study are as follows: (1) an end-to-end model based on CapsNet is proposed to identify saliva-secretory proteins from the sequence information; (2) the proposed model achieves better performance and outperforms existing models; and (3) the saliva-secretory proteins predicted by our model are statistically significant compared with existing cancer biomarkers in saliva. In addition, a web server of CapsNet-SSP is developed for saliva-secretory protein identification, and it can be accessed at the following URL:. We believe that our model and web server will be useful for biomedical researchers who are interested in finding salivary protein biomarkers, especially when they have identified candidate proteins for analyzing diseased tissues near or distal to salivary glands using transcriptome or proteomics.","Saliva-secretory protein,Deep learning,Capsule network,Convolutional neural network",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,"SECONDARY,STRUCTURE,BREAST-CANCER,BLOOD,MARKERS,BIOMARKERS,DIAGNOSIS,PROTEOME,IDENTIFICATION,HEAD",BMC BIOINFORMATICS,https://europepmc.org/articles/pmc7285745?pdf=render,
3,Energy storage emerging: A perspective from the Joint Center for Energy Storage Research,117,23,12550-12557,"Trahey Lynn,Brushett Fikile R.,Balsara Nitash P.,Ceder Gerbrand,Cheng Lei,Chiang Yet-Ming,Hahn Nathan T.,Ingram Brian J.,Minteer Shelley D.,Moore Jeffrey S.","Trahey L,Brushett FR,Balsara NP,Ceder G,Cheng L,Chiang YM,Hahn NT,Ingram BJ,Minteer SD,Moore JS",Brushett FR,10.1073/pnas.1821672117,United States Department of Energy (DOE),"Energy storage is an integral part of modern society. A contemporary example is the lithium (Li)-ion battery, which enabled the launch of the personal electronics revolution in 1991 and the first commercial electric vehicles in 2010. Most recently, Li-ion batteries have expanded into the electricity grid to firm variable renewable generation, increasing the efficiency and effectiveness of transmission and distribution. Important applications continue to emerge including decarbonization of heavy-duty vehicles, rail, maritime shipping, and aviation and the growth of renewable electricity and storage on the grid. This perspective compares energy storage needs and priorities in 2010 with those now and those emerging over the next few decades. The diversity of demands for energy storage requires a diversity of purpose-built batteries designed to meet disparate applications. Advances in the frontier of battery research to achieve transformative performance spanning energy and power density, capacity, charge/discharge times, cost, lifetime, and safety are highlighted, along with strategic research refinements made by the Joint Center for Energy Storage Research (JCESR) and the broader community to accommodate the changing storage needs and priorities. Innovative experimental tools with higher spatial and temporal resolution, in situ and operando characterization, first-principles simulation, high throughput computation, machine learning, and artificial intelligence work collectively to reveal the origins of the electrochemical phenomena that enable new means of energy storage. This knowledge allows a constructionist approach to materials, chemistries, and architectures, where each atom or molecule plays a prescribed role in realizing batteries with unique performance profiles suitable for emergent demands.","energy storage,Joint Center for Energy Storage Research,batteries,transportation,grid",Article,"NATL ACAD SCIENCES, 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA",Science & Technology - Other Topics,,12.291,"SPARINGLY,SOLVATING,ELECTROLYTES,FLOW,BATTERY,LITHIUM,DESIGN,INTERCALATION,TRANSPORT,MAGNESIUM,POLYMERS,CATHODE,DENSITY",PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA,https://escholarship.org/content/qt92z0n633/qt92z0n633.pdf?t=qo7ums,
4,Application of Whole-Genome Sequences and Machine Learning in Source Attribution of Salmonella Typhimurium,40,9,1693-1705,"Munck N.,Njage Patrick Murigu Kamau,Leekitcharoenphon Pimlapas,Litrup Eva,Hald Tine","Munck N,Njage PMK,Leekitcharoenphon P,Litrup E,Hald T",Munck N,10.1111/risa.13510,Technical University of Denmark,"Prevention of the emergence and spread of foodborne diseases is an important prerequisite for the improvement of public health. Source attribution models link sporadic human cases of a specific illness to food sources and animal reservoirs. With the next generation sequencing technology, it is possible to develop novel source attribution models. We investigated the potential of machine learning to predict the animal reservoir from which a bacterial strain isolated from a human salmonellosis case originated based on whole-genome sequencing. Machine learning methods recognize patterns in large and complex data sets and use this knowledge to build models. The model learns patterns associated with genetic variations in bacteria isolated from the different animal reservoirs. We selected different machine learning algorithms to predict sources of human salmonellosis cases and trained the model with Danish Salmonella Typhimurium isolates sampled from broilers (n = 34), cattle (n = 2), ducks (n = 11), layers (n = 4), and pigs (n = 159). Using cgMLST as input features, the model yielded an average accuracy of 0.783 (95% CI: 0.77-0.80) in the source prediction for the random forest and 0.933 (95% CI: 0.92-0.94) for the logit boost algorithm. Logit boost algorithm was most accurate (valid accuracy: 92%, CI: 0.8706-0.9579) and predicted the origin of 81% of the domestic sporadic human salmonellosis cases. The most important source was Danish produced pigs (53%) followed by imported pigs (16%), imported broilers (6%), imported ducks (2%), Danish produced layers (2%), Danish produced cattle and imported cattle (<1%) while 18% was not predicted. Machine learning has potential for improving source attribution modeling based on sequence data. Results of such models can inform risk managers to identify and prioritize food safety interventions.","Machine learning,source attribution,whole genome sequencing",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Public, Environmental & Occupational Health,Mathematics,Mathematical Methods In Social Sciences",,4.155,"SURVEILLANCE,MODELS",RISK ANALYSIS,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/risa.13510,
5,A vision-based active learning convolutional neural network model for concrete surface crack detection,23,13,2952-2964,"Wang Zhen,Xu Guoshan,Ding Yong,Wu Bin,Lu Guoyu","Wang Z,Xu GS,Ding Y,Wu B,Lu GY",Ding Y,10.1177/1369433220924792,Harbin Institute of Technology,"Concrete surface crack detection based on computer vision, specifically via a convolutional neural network, has drawn increasing attention for replacing manual visual inspection of bridges and buildings. This article proposes a new framework for this task and a sampling and training method based on active learning to treat class imbalances. In particular, the new framework includes a clear definition of two categories of samples, a relevant sliding window technique, data augmentation and annotation methods. The advantages of this framework are that data integrity can be ensured and a very large amount of annotation work can be saved. Training datasets generated with the proposed sampling and training method not only are representative of the original dataset but also highlight samples that are highly complex, yet informative. Based on the proposed framework and sampling and training strategy, AlexNet is re-tuned, validated, tested and compared with an existing network. The investigation revealed outstanding performances of the proposed framework in terms of the detection accuracy, precision and F1 measure due to its nonlinear learning ability, training dataset integrity and active learning strategy.","active learning,automatic inspection,class imbalance,convolutional neural network,crack detection,deep learning",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA","Construction & Building Technology,Engineering",,1.925,"DEEP,RECOGNITION",ADVANCES IN STRUCTURAL ENGINEERING,,
6,"Sensor Type, Axis, and Position-Based Fusion and Feature Selection for Multimodal Human Daily Activity Recognition in Wearable Body Sensor Networks",2020,,,"Badawi Abeer A.,Al-Kabbany Ahmad,Shaban Heba A.","Badawi AA,Al-Kabbany A,Shaban HA",Al-Kabbany A,10.1155/2020/7914649,Egyptian Knowledge Bank (EKB),"This research addresses the challenge of recognizing human daily activities using surface electromyography (sEMG) and wearable inertial sensors. Effective and efficient recognition in this context has emerged as a cornerstone in robust remote health monitoring systems, among other applications. We propose a novel pipeline that can attain state-of-the-art recognition accuracies on a recent-and-standard dataset-the Human Gait Database (HuGaDB). Using wearable gyroscopes, accelerometers, and electromyography sensors placed on the thigh, shin, and foot, we developed an approach that jointly performs sensor fusion and feature selection. Being done jointly, the proposed pipeline empowers the learned model to benefit from the interaction of features that might have been dropped otherwise. Using statistical and time-based features from heterogeneous signals of the aforementioned sensor types, our approach attains a mean accuracy of 99.8%, which is the highest accuracy on HuGaDB in the literature. This research underlines the potential of incorporating EMG signals especially when fusion and selection are done simultaneously. Meanwhile, it is valid even with simple off-the-shelf feature selection methods such the Sequential Feature Selection family of algorithms. Moreover, through extensive simulations, we show that the left thigh is a key placement for attaining high accuracies. With one inertial sensor on that single placement alone, we were able to achieve a mean accuracy of 98.4%. The presented in-depth comparative analysis shows the influence that every sensor type, position, and placement can have on the attained recognition accuracies-a tool that can facilitate the development of robust systems, customized to specific scenarios and real-life applications.",,Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Health Care Sciences & Services,,3.188,,JOURNAL OF HEALTHCARE ENGINEERING,https://europepmc.org/articles/pmc7298253?pdf=render,
7,Autonomous Discovery in the Chemical Sciences Part I: Progress,59,51,22858-22893,"Coley Connor W.,Eyke Natalie S.,Jensen Klavs F.","Coley CW,Eyke NS,Jensen KF",Coley CW; Jensen KF,10.1002/anie.201909987,Massachusetts Institute of Technology (MIT),"This two-part Review examines how automation has contributed to different aspects of discovery in the chemical sciences. In this first part, we describe a classification for discoveries of physical matter (molecules, materials, devices), processes, and models and how they are unified as search problems. We then introduce a set of questions and considerations relevant to assessing the extent of autonomy. Finally, we describe many case studies of discoveries accelerated by or resulting from computer assistance and automation from the domains of synthetic chemistry, drug discovery, inorganic chemistry, and materials science. These illustrate how rapid advancements in hardware automation and machine learning continue to transform the nature of experimentation and modeling. Part two reflects on these case studies and identifies a set of open challenges for the field.","automation,chemoinformatics,drug discovery,machine learning,materials science",Review,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Chemistry,,14.205,"HIGH-THROUGHPUT,DISCOVERY,INTERFERENCE,COMPOUNDS,PAINS,MACHINE,LEARNING,APPROACH,SUPPORT,VECTOR,MACHINES,AIDED,SYNTHESIS,DESIGN,CLEAN,ENERGY,PROJECT,NEURAL-NETWORK,MODEL,DE-NOVO,DESIGN,CONTINUOUS-FLOW,GENETIC,ALGORITHM",ANGEWANDTE CHEMIE-INTERNATIONAL EDITION,http://arxiv.org/pdf/2003.13754,
8,Optimizing deep learning model selection for angular feature extraction in satellite imagery,14,3,,"Immel Poppy G.,Desai Meera A.,Moody Daniela I","Immel PG,Desai MA,Moody DI",Immel PG,10.1117/1.JRS.14.032612,"Ursa Space Syst Inc, Ithaca, NY 14850 USA.","Deep learning techniques have been leveraged in numerous applications and across different data modalities over the past few decades, more recently in the domain of remotely sensed imagery. Given the complexity and depth of convolutional neural network (CNN) architectures, it is difficult to fully evaluate performance, optimize the hyperparameters, and provide robust solutions to a specific machine learning problem that can be applied to nontraditional real-world feature extraction and automation tasks. Ursa Space Systems Inc. develops machine learning approaches to build custom solutions and extract answers from synthetic aperture radar satellite data fused with other remote sensing data sets. One application is identifying the orientation of nontexture linear features in imagery, such as an inlet pipe on top of a cylindrical oil storage tank. We propose a two-phase approach for determining this orientation: first an optimized CNN is used in a nontraditional way to probabilistically determine a coarse location and orientation of the inlet pipe, followed by a maximum likelihood voting scheme to automatically extract the orientation of the angular feature within 7.5 deg. We use a known hyperparameter optimization technique to determine the best deep learning CNN architecture for our specific problem and under user-defined optimization and accuracy constraints, by optimizing model hyperparameters (number of layers, size of the input image, and data set preprocessing) using a manual and grid search approach. The use of this systematic approach for hyperparameter optimization yields increased accuracy for our angular feature extraction and orientation finding algorithm from 86% to 94%. Additionally, this proposed algorithm shows how machine learning can be used to improve real-world remote sensing workflows. (C) 2020 Society of Photo Optical Instrumentation Engineers (SPIE)","angular feature extraction,nontexture feature orientation,object orientation,multi-spectral imagery convolutional neural network(CNN) applications,CNN model optimization",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Environmental Sciences & Ecology,Remote Sensing,Imaging Science & Photographic Technology",,1.565,SEARCH,JOURNAL OF APPLIED REMOTE SENSING,,
9,Online fat detection and evaluation in modelling digital physiological fish,51,8,3175-3190,"Nian Rui,Gao Mingshan,Kong Shuang,Yu Junjie,Wang Ruirui,Li Xueshan,Zhang Shichang,Hao Baochen,Xu Xiao,Che Renzheng","Nian R,Gao MS,Kong S,Yu JJ,Wang RR,Li XS,Zhang SC,Hao BC,Xu X,Che RZ",Nian R,10.1111/are.14653,Ocean University of China,"The accumulation of excess fat in fish might impair the health of fish in aquaculture. This paper introduces an online sequential extreme learning machine (OS-ELM) into region-of-interest (ROI) detection of adipose tissues in fish digitalized by means of magnetic resonance imaging (MRI). Three typical economic fish species, turbot (Scophthalmus maximus L.), large yellow croaker (Pseudosciaena crocea R.) and Japanese seabass (Lateolabrax japonicus), were selected to compose into digital physiological atlas. We manually labelled with ITK-SNAP discriminating adipose tissue regions as standard references. Then, single-hidden-layer feedforward neural networks (SLFNs) were established to deduce the potential mathematical criterion for fat detection via OS-ELM for each fish species. We further carried out classical adaptive segmentation to extract details in fat location and distribution of adipose tissues. The quantitative correspondence regarding adipose tissues regions, between 3D voxel representation in MRI and chemical measurement in real fish, have been statistically investigated across each species. The experimental results showed that our online fat detection automatically through MRI is consistent with the standard references, and the recognition rate for three fish species could be up to 89.13% +/- 5.32%, 91.43% +/- 6.68% and 93.08% +/- 6.57% on average, with FAR rate 5.35%, 4.05%, 3.39% and FRRs of 5.52%, 4.52% and 3.53% respectively. Those 3D volumes involved in fat region counting keep pace with the real weights of adipose tissues across species, which implies we might utilize 3D voxel counting to quantify fat accumulation in adipose tissues in a species-dependent manner. The proposed mechanism brings comparative performances for fat detection and evaluation at a much faster speed, which could help high-throughput insights into fat metabolism process in fish.","adipose tissue,chemical analysis,lipid content,magnetic resonance imaging,online sequential extreme learning machine,single-hidden-layer feedforward networks",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Fisheries,,2.415,"EXTREME,LEARNING-MACHINE,LIPID,DISTRIBUTION,ADIPOSE-TISSUE,QUANTIFICATION,ALGORITHM,TROUT,CARP",AQUACULTURE RESEARCH,,
10,An improved MobileNet-SSD algorithm for automatic defect detection on vehicle body paint,79,31-32,23367-23385,"Zhang Jindong,Xu Jiabin,Zhu Linyao,Zhang Kunpeng,Liu Tong,Wang Donghui,Wang Xue","Zhang JD,Xu JB,Zhu LY,Zhang KP,Liu T,Wang DH,Wang X",Zhang JD,10.1007/s11042-020-09152-6,Jilin University,"In order to improve the efficiency and accuracy of manual vehicle paint defect detection, the computer vision technology and deep learning methods is used to achieve automatic detection of vehicle paint defects based on small samples in this study. The vehicle body paint defect image was collected in real time, and a new data enhancement algorithm was proposed to enhance the database for the over-fitting phenomenon caused by small sample data. Aiming at the defect characteristics inherent in vehicle paints, an improved MobileNet-SSD algorithm for automatic detection of paint defects is proposed by improving the feature layer of MobileNet-SSD network and optimizing the matching strategy of bounding box. The experimental results show that the improved MobileNet-SSD algorithm can detect the defects of six traditional body paint films with an accuracy rate of over 95%, which is 10% faster than the traditional SSD algorithm, and can realize real-time and accurate detection of body paint defects.","Data enhancement,Defect detection,Deep learning,Machine vision",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,,MULTIMEDIA TOOLS AND APPLICATIONS,,
11,A pilot study using a machine-learning approach of morphological and hemodynamic parameters for predicting aneurysms enhancement,15,8,1313-1321,"Lv Nan,Karmonik Christof,Shi Zhaoyue,Chen Shiyue,Wang Xinrui,Liu Jianmin,Huang Qinghai","Lv N,Karmonik C,Shi ZY,Chen SY,Wang XR,Liu JM,Huang QH",Karmonik C,10.1007/s11548-020-02199-8,The Methodist Hospital System,"Purpose The development of straightforward classification methods is needed to identify unstable aneurysms and rupture risk for clinical use. In this study, we aim to investigate the relative importance of geometrical, hemodynamic and clinical risk factors represented by the PHASES score for predicting aneurysm wall enhancement using several machine-learning (ML) models. Methods Nine different ML models were applied to 65 aneurysm cases with 24 predictor variables. ML models were optimized with the training set using tenfold cross-validation with five repeats with the area under the curve (AUC) as cost parameter. Models were validated using the test set. Accuracy being significantly higher (p < 0.05) than the non-information rate (NIR) was used as measure of performance. The relative importance of the predictor variables was determined from a subset of five ML models in which this information was available. Results Best-performing ML model was based on gradient boosting (AUC = 0.98). Second best-performing model was based on generalized linear modeling (AUC = 0.80). The size ratio was determined as the dominant predictor for wall enhancement followed by the PHASES score and mean wall shear stress value at the aneurysm wall. Four ML models exhibited a statistically significant higher accuracy (0.79) than the NIR (0.58): random forests, generalized linear modeling, gradient boosting and linear discriminant analysis. Conclusions ML models are capable of predicting the relative importance of geometrical, hemodynamic and clinical parameters for aneurysm wall enhancement. Size ratio, PHASES score and mean wall shear stress value at the aneurysm wall are of highest importance when predicting wall enhancement in cerebral aneurysms.","Aneurysm wall enhancement,Machine learning,Predictive modeling",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,"UNRUPTURED,INTRACRANIAL,ANEURYSMS,WALL,ENHANCEMENT,RISK-FACTORS,RUPTURE,RISK,NATURAL-HISTORY,ARTERIAL-WALL,PATIENT,PROBABILITY",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,,
12,"The articles.ELM resource: simplifying access to protein linear motif literature by annotation, text-mining and classification",,,,"Palopoli N.,Iserte J. A.,Chemes L. B.,Marino-Buslje C.,Parisi G.,Gibson T. J.,Davey N. E.","Palopoli N,Iserte JA,Chemes LB,Marino-Buslje C,Parisi G,Gibson TJ,Davey NE",Davey NE,10.1093/database/baaa040,Royal Marsden NHS Foundation Trust,"Modern biology produces data at a staggering rate. Yet, much of these biological data is still isolated in the text, figures, tables and supplementary materials of articles. As a result, biological information created at great expense is significantly underutilised. The protein motif biology field does not have sufficient resources to curate the corpus of motif-related literature and, to date, only a fraction of the available articles have been curated. In this study, we develop a set of tools and a web resource, 'articles.ELM', to rapidly identify the motif literature articles pertinent to a researcher's interest. At the core of the resource is a manually curated set of about 8000 motif-related articles. These articles are automatically annotated with a range of relevant biological data allowing in-depth search functionality. Machine-learning article classification is used to group articles based on their similarity to manually curated motif classes in the Eukaryotic Linear Motif resource. Articles can also be manually classified within the resource. The 'articles.ELM' resource permits the rapid and accurate discovery of relevant motif articles thereby improving the visibility of motif literature and simplifying the recovery of valuable biological insights sequestered within scientific articles. Consequently, this web resource removes a critical bottleneck in scientific productivity for the motif biology field.",,Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND",Mathematical & Computational Biology,,4.159,,DATABASE-THE JOURNAL OF BIOLOGICAL DATABASES AND CURATION,https://europepmc.org/articles/pmc7276420?pdf=render,
13,Fully Automated Identification of Two-Dimensional Material Samples,13,6,,"Greplova Eliska,Gold Carolin,Kratochwil Benedikt,Davatz Tim,Pisoni Riccardo,Kurzmann Annika,Rickhaus Peter,Fischer Mark H.,Ihn Thomas,Huber Sebastian D.","Greplova E,Gold C,Kratochwil B,Davatz T,Pisoni R,Kurzmann A,Rickhaus P,Fischer MH,Ihn T,Huber SD",Greplova E,10.1103/PhysRevApplied.13.064017,ETH Zurich,"Thin nanomaterials are key constituents of modern quantum technologies and materials research. The identification of specimens of these materials with the properties required for the development of state-of-the-art quantum devices is usually a complex and tedious human task. In this work, we provide a neural-network-driven solution that allows for accurate and efficient scanning, data processing, and sample identification of experimentally relevant two-dimensional materials. We show how to approach the classification of imperfect and imbalanced data sets using an iterative application of multiple noisy neural networks. We embed the trained classifier into a comprehensive solution for end-to-end automatized data processing and sample identification.","NEURAL-NETWORK,GRAPHENE,ELECTRONICS",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,5.111,"NEURAL-NETWORK,GRAPHENE,ELECTRONICS",PHYSICAL REVIEW APPLIED,http://arxiv.org/pdf/1911.00066,
14,Refractive index prediction models for polymers using machine learning,127,21,,"Lightstone Jordan P.,Chen Lihua,Kim Chiho,Batra Rohit,Ramprasad Rampi","Lightstone JP,Chen LH,Kim C,Batra R,Ramprasad R",Ramprasad R,10.1063/5.0008026,University System of Georgia,"The refractive index (RI) is an important material property and is necessary for making informed materials selection decisions when optical properties are important. Acquiring accurate empirical measurements of RI is time consuming, and while semi-empirical and computational determination of RI is generally faster than empirical determination, predictions are less accurate. In this work, we utilized experimentally measured RI data of polymers to build a machine learning model capable of making accurate near-instantaneous predictions of RI. The Gaussian process regression model is trained using data of 527 unique polymers. Feature engineering techniques were also used to optimize model performance. This new model is one of the most chemically diverse and accurate RI prediction models to date and improves upon our previous work. We also concluded that the model is capable of providing insights about structure-property relationships important for estimating the RI when designing new polymer backbones.",LIGHT,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,LIGHT,JOURNAL OF APPLIED PHYSICS,,
15,Estimating the thermal insulating performance of multi-component refractory ceramic systems based on a machine learning surrogate model framework,127,21,,"Santos D. P.,Pelissari P. I. B. G. B.,de Mello R. F.,Pandolfelli V. C.","Santos DP,Pelissari PIBGB,de Mello RF,Pandolfelli VC",Santos DP,10.1063/5.0004395,Universidade Federal de Sao Carlos,"Predicting the insulating thermal behavior of a multi-component refractory ceramic system could be a difficult task, which can be tackled using the finite element (FE) method to solve the partial differential equations of the heat transfer problem, thus calculating the temperature profiles throughout the system in any given period. Nevertheless, using FE can still be very time-consuming when analyzing the thermal performance of insulating systems in some scenarios. This paper proposes a framework based on a machine learning surrogate model to significantly reduce the required computation time for estimating the thermal performance of several multi-component insulating systems. Based on an electric resistance furnace case study, the framework estimated the feasibility and the final temperature of nearly
1.9 x
10 5 insulating candidates' arrangements with reasonable accuracy by simulating only an initial sample of
2.8 % of them via FE. The framework accuracy was evaluated by varying the initial sample size from
approximate to 0.9 % to
8 % of total combinations, indicating that
3 %-
5 % is the optimal range in the case study. Finally, the proposed framework was compared to the evolutionary screening procedure, a previously proposed method for selecting insulating materials for furnace linings, from which it was concluded that the machine learning framework provides better control over the number of required FE simulations, provides faster optimization of its hyperparameters, and enables the designers to estimate the thermal performance of the entire search space with small errors on temperature prediction.",,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,,JOURNAL OF APPLIED PHYSICS,,
16,The structural information filtered features (SIFF) potential: Maximizing information stored in machine-learning descriptors for materials prediction,127,21,,"Zeledon Jorge Arturo Hernandez,Romero Aldo H.,Ren Pengju,Wen Xiaodong,Li Yongwang,Lewis James P.","Zeledon JAH,Romero AH,Ren PJ,Wen XD,Li YW,Lewis JP",Lewis JP,10.1063/5.0002252,Chinese Academy of Sciences,"Machine learning inspired potentials continue to improve the ability for predicting structures of materials. However, many challenges still exist, particularly when calculating structures of disordered systems. These challenges are primarily due to the rapidly increasing dimensionality of the feature-vector space which in most machine-learning algorithms is dependent on the size of the structure. In this article, we present a feature-engineered approach that establishes a set of principles for representing potentials of physical structures (crystals, molecules, and clusters) in a feature space rather than a physically motivated space. Our goal in this work is to define guiding principles that optimize information storage of the physical parameters within the feature representations. In this manner, we focus on keeping the dimensionality of the feature space independent of the number of atoms in the structure. Our Structural Information Filtered Features (SIFF) potential represents structures by utilizing a feature vector of low-correlated descriptors, which correspondingly maximizes information within the descriptor. We present results of our SIFF potential on datasets composed of disordered (carbon and carbon-oxygen) clusters, molecules with C7O2H2 stoichiometry in the GDB9-14B dataset, and crystal structures of the form (AlxGayInz)(2)O-3 as proposed in the NOMAD Kaggle competition. Our potential's performance is at least comparable, sometimes significantly more accurate, and often more efficient than other well-known machine-learning potentials for structure prediction. However, primarily, we offer a different perspective on how researchers should consider opportunities in maximizing information storage for features.",,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,,JOURNAL OF APPLIED PHYSICS,,
17,Mining of effective local order parameters for classifying crystal structures: A machine learning study,152,21,,"Doi Hideo,Takahashi Kazuaki Z.,Aoyagi Takeshi","Doi H,Takahashi KZ,Aoyagi T",Takahashi KZ,10.1063/5.0005228,National Institute of Advanced Industrial Science & Technology (AIST),"Determining local structures of molecular systems helps the scientific and technological understanding of the function of materials. Molecular simulations provide microscopic information on molecular systems, but analyzing the resulting local structures is a non-trivial task. Many kinds of order parameters have been developed for detecting such local structures. Bond-orientational order parameters are promising for classifying local structures and have been used to analyze systems with such structures as body-centered cubic, face-centered cubic, hexagonal close-packed, and liquid. A specific set of order parameters derived from Lechner's definitional equation are widely used to classify complex local structures. However, there has been no thorough investigation of the classification capability of other Lechner parameters, despite their potential to precisely distinguish local structures. In this work, we evaluate the classification capability of 112 species of bond-orientational order parameters including Lechner's definitions. A total of 234 248 combinations of these parameters are also evaluated. The evaluation is systematically and automatically performed using machine learning techniques. To distinguish the four types of local structures, we determine the better set of two order parameters by comparing with a conventional set. A set of three order parameters is also suggested for better accuracy. Therefore, the machine learning scheme in the present study enables the systematic, accurate, and automatic mining of effective order parameters for classifying crystal structures.","SIMULATION,IDENTIFICATION,NUCLEATION,PHASE",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Chemistry,Physics",,,"SIMULATION,IDENTIFICATION,NUCLEATION,PHASE",JOURNAL OF CHEMICAL PHYSICS,,
18,QSAR without borders,49,11,3525-3564,"Muratov Eugene N.,Bajorath Jurgen,Sheridan Robert P.,Tetko Igor V,Filimonov Dmitry,Poroikov Vladimir,Oprea Tudor I,Baskin Igor I.,Varnek Alexandre,Roitberg Adrian","Muratov EN,Bajorath J,Sheridan RP,Tetko IV,Filimonov D,Poroikov V,Oprea TI,Baskin II,Varnek A,Roitberg A",Tropsha A,10.1039/d0cs00098a,University of North Carolina,"Prediction of chemical bioactivity and physical properties has been one of the most important applications of statistical and more recently, machine learning and artificial intelligence methods in chemical sciences. This field of research, broadly known as quantitative structure-activity relationships (QSAR) modeling, has developed many important algorithms and has found a broad range of applications in physical organic and medicinal chemistry in the past 55+ years. This Perspective summarizes recent technological advances in QSAR modeling but it also highlights the applicability of algorithms, modeling methods, and validation practices developed in QSAR to a wide range of research areas outside of traditional QSAR boundaries including synthesis planning, nanotechnology, materials science, biomaterials, and clinical informatics. As modern research methods generate rapidly increasing amounts of data, the knowledge of robust data-driven modelling methods professed within the QSAR field can become essential for scientists working both within and outside of chemical research. We hope that this contribution highlighting the generalizable components of QSAR modeling will serve to address this challenge.","QUANTITATIVE STRUCTURE-ACTIVITY,ADVERSE OUTCOME PATHWAYS,ACTIVITY-RELATIONSHIP MODELS,MATCHED MOLECULAR PAIRS,DATA MINING TECHNIQUES,DEEP NEURAL-NETWORKS,BIOLOGICAL-ACTIVITY,INDUSTRIAL-CHEMICALS,ACTIVITY PREDICTION,ORGANIC-REACTIONS",Review,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND",Chemistry,,53.712,"QUANTITATIVE,STRUCTURE-ACTIVITY,ADVERSE,OUTCOME,PATHWAYS,ACTIVITY-RELATIONSHIP,MODELS,MATCHED,MOLECULAR,PAIRS,DATA,MINING,TECHNIQUES,DEEP,NEURAL-NETWORKS,BIOLOGICAL-ACTIVITY,INDUSTRIAL-CHEMICALS,ACTIVITY,PREDICTION,ORGANIC-REACTIONS",CHEMICAL SOCIETY REVIEWS,https://pubs.rsc.org/en/content/articlepdf/2020/cs/d0cs00098a,
19,Geometric landscapes for material discovery within energy-structure-function maps,11,21,5423-5433,"Moosavi Seyed Mohamad,Xu Henglu,Chen Linjiang,Cooper Andrew I,Smit Berend","Moosavi SM,Xu HL,Chen LJ,Cooper AI,Smit B",Smit B,10.1039/d0sc00049c,Ecole Polytechnique Federale de Lausanne,"Porous molecular crystals are an emerging class of porous materials formed by crystallisation of molecules with weak intermolecular interactions, which distinguishes them from extended nanoporous materials like metal-organic frameworks (MOFs). To aid discovery of porous molecular crystals for desired applications, energy-structure-function (ESF) maps were developed that combine a priori prediction of both the crystal structure and its functional properties. However, it is a challenge to represent the high-dimensional structural and functional landscapes of an ESF map and to identify energetically favourable and functionally interesting polymorphs among the 1000s to 10 000s of structures typically on a single ESF map. Here, we introduce geometric landscapes, a representation for ESF maps based on geometric similarity, quantified by persistent homology. We show that this representation allows the exploration of complex ESF maps, automatically pinpointing interesting crystalline phases available to the molecule. Furthermore, we show that geometric landscapes can serve as an accountable descriptor for porous materials to predict their performance for gas adsorption applications. A machine learning model trained using this geometric similarity could reach a remarkable accuracy in predicting the materials' performance for methane storage applications.","CRYSTAL-STRUCTURE PREDICTION,METAL-ORGANIC FRAMEWORKS,METHANE STORAGE,GAS,PERSISTENCE,MOLECULES,SOLIDS,CAGE,ALGORITHMS,ADSORPTION",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND",Chemistry,,9.658,"CRYSTAL-STRUCTURE,PREDICTION,METAL-ORGANIC,FRAMEWORKS,METHANE,STORAGE,GAS,PERSISTENCE,MOLECULES,SOLIDS,CAGE,ALGORITHMS,ADSORPTION",CHEMICAL SCIENCE,https://escholarship.org/content/qt3207161x/qt3207161x.pdf?t=quohio,
20,Machine Learning for Brain Images Classification of Two Language Speakers,2020,,,Barranco-Gutierrez Alejandro-Israel,Barranco-Gutierrez AI,Barranco-Gutierrez AI,10.1155/2020/9045456,"Catedras CONACyT TecNM Celaya, Celaya 38010, Mexico.","The image analysis of the brain with machine learning continues to be a relevant work for the detection of different characteristics of this complex organ. Recent research has observed that there are differences in the structure of the brain, specifically in white matter, when learning and using a second language. This work focuses on knowing the brain from the classification of Magnetic Resonance Images (MRIs) of bilingual and monolingual people who have English as their common language. Different artificial neural networks of a hidden layer were tested until reaching two neurons in that layer. The number of entries used was nine hundred and the classifier registered a high percentage of effectiveness. The training was supervised which could be improved in a future investigation. This task is usually carried out by an expert human with Tract-Based Spatial Statistics analysis and fractional anisotropy expressed in different colors on a screen. So, this proposal presents another option to quantitatively analyse this type of phenomena which allows to contribute to neuroscience by automatically detecting bilingual people of monolinguals by using machine learning from MRIs. This reinforces what is reported in manual detections and the way that a machine can do it.","WHITE-MATTER INTEGRITY,BILINGUALISM",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Mathematical & Computational Biology,Neurosciences & Neurology",,3.278,"WHITE-MATTER,INTEGRITY,BILINGUALISM",COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE,https://europepmc.org/articles/pmc7294350?pdf=render,
21,,,,,,,,,,,,,,,,,,,,
22,,,,,,,,,,,,,,,,,,,,
23,,,,,,,,,,,,,,,,,,,,
24,Classification of breast masses on ultrasound shear wave elastography using convolutional neural networks,42,4-5,213-220,"Fujioka Tomoyuki,Katsuta Leona,Kubota Kazunori,Mori Mio,Kikuchi Yuka,Kato Arisa,Oda Goshi,Nakagawa Tsuyoshi,Kitazume Yoshio,Tateishi Ukihide","Fujioka T,Katsuta L,Kubota K,Mori M,Kikuchi Y,Kato A,Oda G,Nakagawa T,Kitazume Y,Tateishi U",Kubota K,10.1177/0161734620932609,Dokkyo Medical University,"We aimed to use deep learning with convolutional neural networks (CNNs) to discriminate images of benign and malignant breast masses on ultrasound shear wave elastography (SWE). We retrospectively gathered 158 images of benign masses and 146 images of malignant masses as training data for SWE. A deep learning model was constructed using several CNN architectures (Xception, InceptionV3, InceptionResNetV2, DenseNet121, DenseNet169, and NASNetMobile) with 50, 100, and 200 epochs. We analyzed SWE images of 38 benign masses and 35 malignant masses as test data. Two radiologists interpreted these test data through a consensus reading using a 5-point visual color assessment (SWEc) and the mean elasticity value (in kPa) (SWEe). Sensitivity, specificity, and area under the receiver operating characteristic curve (AUC) were calculated. The best CNN model (which was DenseNet169 with 100 epochs), SWEc, and SWEe had a sensitivity of 0.857, 0.829, and 0.914 and a specificity of 0.789, 0.737, and 0.763 respectively. The CNNs exhibited a mean AUC of 0.870 (range, 0.844-0.898), and SWEc and SWEe had an AUC of 0.821 and 0.855. The CNNs had an equal or better diagnostic performance compared with radiologist readings. DenseNet169 with 100 epochs, Xception with 50 epochs, and Xception with 100 epochs had a better diagnostic performance compared with SWEc (P = 0.018-0.037). Deep learning with CNNs exhibited equal or higher AUC compared with radiologists when discriminating benign from malignant breast masses on ultrasound SWE.","breast imaging,ultrasound,elastography,shear wave elastography,deep learning,convolutional neural network",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA","Acoustics,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,1.608,"DIFFERENTIATION,BENIGN,LESIONS,STRAIN,US",ULTRASONIC IMAGING,,
25,Machine-Learning Clustering Technique Applied to Powder X-Ray Diffraction Patterns to Distinguish Compositions of ThMn12-Type Alloys,3,7,,"Utimula Keishu,Hunkao Rutchapon,Yano Masao,Kimoto Hiroyuki,Hongo Kenta,Kawaguchi Shogo,Suwanna Sujin,Maezono Ryo","Utimula K,Hunkao R,Yano M,Kimoto H,Hongo K,Kawaguchi S,Suwanna S,Maezono R",Utimula K,10.1002/adts.202000039,Japan Advanced Institute of Science & Technology (JAIST),"A clustering technique is applied using dynamic-time-wrapping (DTW) analysis to X-ray diffraction (XRD) spectrum patterns in order to identify the microscopic structures of substituents introduced into the main phase of magnetic alloys. The clustering technique is found to perform well, identifying the concentrations of the substituents with success rates of approximate to 90%. This level of performance is attributed to the capability of DTW processing to filter out irrelevant information such as the peak intensities (due to the uncontrollability of diffraction conditions in polycrystalline samples) and the uniform shift of peak positions (due to the thermal expansion of lattices). The established framework is not limited to the system treated in this work, but is widely applicable to systems the properties of which are to be tuned by atomic substitutions within a phase. The framework has a broader potential to predict properties such as magnetic moments, optical spectra etc.) from observed XRD patterns, by predicting such properties evaluated from predicted microscopic local structure.","dynamic time wrapping,machine learning,magnetic alloys",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Science & Technology - Other Topics,,4.004,"TOTAL-ENERGY,CALCULATIONS,CRYSTAL",ADVANCED THEORY AND SIMULATIONS,http://arxiv.org/pdf/1810.03972,
26,Persistent-Homology-Based Microstructural Optimization of Materials Using t-Distributed Stochastic Neighbor Embedding,3,7,,"Wang Zhi-Lei,Ogawa Toshio,Adachi Yoshitaka","Wang ZL,Ogawa T,Adachi Y",Adachi Y,10.1002/adts.202000040,Nagoya University,"Microstructure optimization is a core issue to maximize the performance of materials. Due to the increasing demand for highly efficient materials, traditional trial-and-error-based experimental methods have become insufficient for designing novel materials with useful properties. Based on the fact that materials with similar microstructural features exhibit similar properties, this work proposes a persistent-homology-based microstructure optimization approach performed with a machine learning algorithm of t-distributed stochastic neighbor embedding to find optimal microstructures for specific properties. The method is applied to dual-phase steels, where a microstructure with high-fraction martensite is identified for achieving a maximum stress. The method proposed here is expected to provide new basis to understand the materials paradigm and thus accelerate the materials discovery process.","machine learning,microstructure optimization,persistent homology,similarity analysis,t-SNE",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Science & Technology - Other Topics,,4.004,"PROPERTY,STEELS",ADVANCED THEORY AND SIMULATIONS,,
27,A Framework for Optimal Safety Li-ion Batteries Design using Physics-Based Models and Machine Learning Approaches,167,10,,"Yamanaka Takumi,Takagishi Yoichi,Yamaue Tatsuya","Yamanaka T,Takagishi Y,Yamaue T",Yamanaka T,10.1149/1945-7111/ab975c,"Kobelco Res Inst Inc, Nishi Ku, Kobe, Hyogo 6512271, Japan.","Numerical physics-based models for Li-ion batteries under abuse conditions are useful in understanding failure mechanisms and deciding safety designs. Since battery design is generally required to decrease the failure risks while increasing the performance, multi-objective optimization methods are useful. Nevertheless, these usually require huge computational costs because these models targeting abuse battery conditions generally have many input physical parameters and computational costs for calculating one result are high. Therefore, we develop a framework for performing multi-objective optimization at a reasonable computational cost using machine learning methods. With this framework, an inverse analysis of optimal Li-ion battery design conditions, including safety conditions, is performed. Nail penetration simulations on different input conditions are performed so as to build a database for battery design conditions/test conditions (descriptors) and safety/performance (predictors). As a result of analyzing the relationship between descriptors and predictors, a high correlation between fire spread and negative electrode active material diameter is confirmed. Furthermore, a regression model to predict the database is created with a Gaussian process model. Using the model and a genetic algorithm, optimal design conditions are searched, and the design conditions that offer higher safety and better performance are identified under the assumed conditions. (C) 2020 The Electrochemical Society (""ECS""). Published on behalf of ECS by IOP Publishing Limited.","INTERNAL SHORT,THERMAL-MODEL,OPTIMIZATION,REGRESSION,CIRCUIT",Article,"ELECTROCHEMICAL SOC INC, 65 SOUTH MAIN STREET, PENNINGTON, NJ 08534 USA","Electrochemistry,Materials Science",,4.364,"INTERNAL,SHORT,THERMAL-MODEL,OPTIMIZATION,REGRESSION,CIRCUIT",JOURNAL OF THE ELECTROCHEMICAL SOCIETY,,
28,,,,,,,,,,,,,,,,,,,,
29,Inverse-designed spinodoid metamaterials,6,1,,"Kumar Siddhant,Tan Stephanie,Zheng Li,Kochmann Dennis M.","Kumar S,Tan SH,Zheng L,Kochmann DM",Kochmann DM,10.1038/s41524-020-0341-6,ETH Zurich,"After a decade of periodic truss-, plate-, and shell-based architectures having dominated the design of metamaterials, we introduce the non-periodic class of spinodoid topologies. Inspired by natural self-assembly processes, spinodoid metamaterials are a close approximation of microstructures observed during spinodal phase separation. Their theoretical parametrization is so intriguingly simple that one can bypass costly phase-field simulations and obtain a rich and seamlessly tunable property space. Counter-intuitively, breaking with the periodicity of classical metamaterials is the enabling factor to the large property space and the ability to introduce seamless functional grading. We introduce an efficient and robust machine learning technique for the inverse design of (meta-)materials which, when applied to spinodoid topologies, enables us to generate uniform and functionally graded cellular mechanical metamaterials with tailored direction-dependent (anisotropic) stiffness and density. We specifically present biomimetic artificial bone architectures that not only reproduce the properties of trabecular bone accurately but also even geometrically resemble natural bone.","PHASE-FIELD MODEL,TOPOLOGY OPTIMIZATION,ELASTIC PROPERTIES,POROUS SCAFFOLDS,YIELD STRENGTH,ENERGY,BONE,HOMOGENIZATION,DIFFUSION",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Chemistry,Materials Science",,13.993,"LOW-DENSITY,MATERIAL,PHASE-FIELD,MODEL,TOPOLOGY,OPTIMIZATION,ELASTIC,PROPERTIES,POROUS,SCAFFOLDS,YIELD,STRENGTH,ENERGY,BONE,HOMOGENIZATION,DIFFUSION",NPJ COMPUTATIONAL MATERIALS,https://repository.tudelft.nl/islandora/object/uuid%3Ad78e6f8a-50ec-4f45-89bd-a32a60145801/datastream/OBJ/download,
30,A prognostic nomogram integrating novel biomarkers identified by machine learning for cervical squamous cell carcinoma,18,1,,"Li Yimin,Lu Shun,Lan Mei,Peng Xinhao,Zhang Zijian,Lang Jinyi","Li YM,Lu S,Lan M,Peng XH,Zhang ZJ,Lang JY",Lang JY,10.1186/s12967-020-02387-9,University of Electronic Science & Technology of China,"Background Cervical cancer (CC) represents the fourth most frequently diagnosed malignancy affecting women all over the world. However, effective prognostic biomarkers are still limited for accurately identifying high-risk patients. Here, we provided a combination machine learning algorithm-based signature to predict the prognosis of cervical squamous cell carcinoma (CSCC). Methods and materials After utilizing RNA sequencing (RNA-seq) data from 36 formalin-fixed and paraffin-embedded (FFPE) samples, the most significant modules were highlighted by the weighted gene co-expression network analysis (WGCNA). A candidate genes-based prognostic classifier was constructed by the least absolute shrinkage and selection operator (LASSO) and then validated in an independent validation set. Finally, based on the multivariate analysis, a nomogram including the FIGO stage, therapy outcome, and risk score level was built to predict progression-free survival (PFS) probability. Results A mRNA-based signature was developed to classify patients into high- and low-risk groups with significantly different PFS and overall survival (OS) rate (training set: p < 0.001 for PFS, p = 0.016 for OS; validation set: p = 0.002 for PFS, p = 0.028 for OS). The prognostic classifier was an independent and powerful prognostic biomarker for PFS in both cohorts (training set: hazard ratio [HR] = 0.13, 95% CI 0.05-0.33, p < 0.001; validation set: HR = 0.02, 95% CI 0.01-0.04, p < 0.001). A nomogram that integrated the independent prognostic factors was constructed for clinical application. The calibration curve showed that the nomogram was able to predict 1-, 3-, and 5-year PFS accurately, and it performed well in the external validation cohorts (concordance index: 0.828 and 0.864, respectively). Conclusion The mRNA-based biomarker is a powerful and independent prognostic factor. Furthermore, the nomogram comprising our prognostic classifier is a promising predictor in identifying the progression risk of CSCC patients.","Cervical squamous cell cancer,Weighted gene co-expression network analysis,Least absolute shrinkage and selection operator,Prognostic biomarkers,Nomogram",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Research & Experimental Medicine,,5.76,"INTRACAVITARY,BRACHYTHERAPY,UTERINE,CERVIX,ADENOCARCINOMA,EXPRESSION,RECURRENCE,RESISTANCE,SIGNATURE,PROTEINS,INVASION,SIGNALS",JOURNAL OF TRANSLATIONAL MEDICINE,https://translational-medicine.biomedcentral.com/track/pdf/10.1186/s12967-020-02387-9.pdf,
31,,,,,,,,,,,,,,,,,,,,
32,,,,,,,,,,,,,,,,,,,,
33,,,,,,,,,,,,,,,,,,,,
34,,,,,,,,,,,,,,,,,,,,
35,"An Efficient Combination among sMRI, CSF, Cognitive Score, andAPOE epsilon 4 Biomarkers for Classification of AD and MCI Using Extreme Learning Machine",2020,,,"Khatri Uttam,Kwon Goo-Rak","Khatri U,Kwon GR",Kwon GR,10.1155/2020/8015156,Chosun University,"Alzheimer's disease (AD) is the most common cause of dementia and a progressive neurodegenerative condition, characterized by a decline in cognitive function. Symptoms usually appear gradually and worsen over time, becoming severe enough to interfere with individual daily tasks. Thus, the accurate diagnosis of both AD and the prodromal stage (i.e., mild cognitive impairment (MCI)) is crucial for timely treatment. As AD is inherently dynamic, the relationship between AD indicators is unclear and varies over time. To address this issue, we first aimed at investigating differences in atrophic patterns between individuals with AD and MCI and healthy controls (HCs). Then we utilized multiple biomarkers, along with filter- and wrapper-based feature selection and an extreme learning machine- (ELM-) based approach, with 10-fold cross-validation for classification. Increasing efforts are focusing on the use of multiple biomarkers, which can be useful for the diagnosis of AD and MCI. However, optimum combinations have yet to be identified and most multimodal analyses use only volumetric measures obtained from magnetic resonance imaging (MRI). Anatomical structural MRI (sMRI) measures have also so far mostly been used separately. The full possibilities of using anatomical MRI for AD detection have thus yet to be explored. In this study, three measures (cortical thickness, surface area, and gray matter volume), obtained from sMRI through preprocessing for brain atrophy measurements; cerebrospinal fluid (CSF), for quantification of specific proteins; cognitive score, as a measure of cognitive performance; andAPOE epsilon 4 allele status were utilized. Our results show that a combination of specific biomarkers performs well, with accuracies of 97.31% for classifying AD vs. HC, 91.72% for MCI vs. HC, 87.91% for MCI vs. AD, and 83.38% for MCIs vs. MCIc, respectively, when evaluated using the proposed algorithm. Meanwhile, the areas under the curve (AUC) from the receiver operating characteristic (ROC) curves combining multiple biomarkers provided better classification performance. The proposed features combination and selection algorithm effectively classified AD and MCI, and MCIs vs. MCIc, the most challenging classification task, and therefore could increase the accuracy of AD classification in clinical practice. Furthermore, we compared the performance of the proposed method with SVM classifiers, using a cross-validation method with Alzheimer's Disease Neuroimaging Initiative (ADNI) datasets.","ALZHEIMERS ASSOCIATION WORKGROUPS,DIAGNOSTIC GUIDELINES,NATIONAL INSTITUTE,DISEASE,IMPAIRMENT,PREDICTION,CONVERSION,PATTERNS,MRI,RECOMMENDATIONS",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Mathematical & Computational Biology,Neurosciences & Neurology",,,"ALZHEIMERS,ASSOCIATION,WORKGROUPS,DIAGNOSTIC,GUIDELINES,NATIONAL,INSTITUTE,DISEASE,IMPAIRMENT,PREDICTION,CONVERSION,PATTERNS,MRI,RECOMMENDATIONS",COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE,http://downloads.hindawi.com/journals/cin/2020/8015156.pdf,
36,Impact of commercial processing on volatile compounds and sensory profiles of flat peach juices by PLSR and BP network,44,8,,"Wang Peng,Tian Honglei,Tan Fengling,Liu Yufei,Yu Bin,Zhan Ping","Wang P,Tian HL,Tan FL,Liu YF,Yu B,Zhan P",Zhan P,10.1111/jfpp.14575,Shaanxi Normal University,"Fresh peach juice and commercial juices were assessed by a trained sensory panel. Differences in the volatiles between fresh and commercial juices were distinguished by partial least squares regression (PLSR) combined with backpropagation artificial neural network. Totally, 10 compounds of three samples were identical: five esters, four alcohols, and one aldehyde. In addition, principal component analysis and hierarchical clustering analysis combined with PLSR revealed that esters were the characteristic volatiles accounting for the differences between fresh and commercial juices. By taking esters as input, the established BP network could correctly distinguish flat peach and commercial juices. Moreover, 10 esters were selected as the key volatiles with the BP network. However, commercial treatment caused a significant reduction in the content of the key esters between fresh flat peaches and commercial juices. Therefore, the changes in esters caused the significant differences in flavor quality between fresh juice and flat peach juices products.
Practical applications The decrease in esters is the main factor that caused the difference in flavor quality between the commercial juices and fresh flat peach juice. Therefore, it is necessary to optimize processing parameters to reduce the loss of esters, which further improves the flavor quality of commercial flat peach juice. These results provide a theoretical reference for the design of a modern high-quality peach juice processing technology.","NEURAL-NETWORK,ORANGE JUICE,GC-MS,GAS-CHROMATOGRAPHY,FLAVOR COMPONENTS,QUALITY,STORAGE,CULTIVARS,FRUIT,L.",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Food Science & Technology,,2.271,"NEURAL-NETWORK,ORANGE,JUICE,GC-MS,GAS-CHROMATOGRAPHY,FLAVOR,COMPONENTS,QUALITY,STORAGE,CULTIVARS,FRUIT,L.",JOURNAL OF FOOD PROCESSING AND PRESERVATION,,
37,Classification of Infected Necrotizing Pancreatitis for Surgery Within or Beyond 4 Weeks Using Machine Learning,8,,,"Lan Lan,Guo Qiang,Zhang Zhigang,Zhao Weiling,Yang Xiaoyan,Lu Huimin,Zhou Zongguang,Zhou Xiaobo","Lan L,Guo Q,Zhang ZG,Zhao WL,Yang XY,Lu HM,Zhou ZG,Zhou XB",Lan L,10.3389/fbioe.2020.00541,Sichuan University,"Background:The timing of surgery for necrotizing pancreatitis remains a matter of controversial debate, which has not been resolved by randomized controlled trial (RCT). This study aims to classify surgical timing within or beyond 4 weeks for patients with infected necrotizing pancreatitis by using machine learning methods. Methods:This study analyzed 223 patients who underwent surgery for infected pancreatic necrosis at West China Hospital of Sichuan University. We used logistic regression, support vector machine, and random forest with/without the simulation of generative adversarial networks to classify the surgical intervention within or beyond 4 weeks in the patients with infected necrotizing pancreatitis. Results:Our analyses showed that interleukin 6, infected necrosis, the onset of fever and C-reactive protein were important factors in determining the timing of surgical intervention (< 4 or >= 4 weeks) for the patients with infected necrotizing pancreatitis. The main factors associated with postoperative mortality in patients who underwent early surgery (< 4 weeks) included modified Marshall score on admission and preoperational modified Marshall score. Preoperational modified Marshall score, time of surgery, duration of organ failure and onset of renal failure were important predictive factors for the postoperative mortality of patients who underwent delayed surgery (>= 4 weeks). Conclusions:Machine learning models can be used to predict timing of surgical intervention effectively and key factors associated with surgical timing and postoperative survival are identified for infected necrotizing pancreatitis.","classification,surgery,timing,machine learning,necrotizing pancreatitis",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND","Biotechnology & Applied Microbiology,Science & Technology - Other Topics",,5.973,"SURGICAL,INTERVENTION,GUIDELINES,MANAGEMENT,NETWORKS",FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY,https://europepmc.org/articles/pmc7287166?pdf=render,
38,Artificial Chemist: An Autonomous Quantum Dot Synthesis Bot,32,30,,"Epps Robert W.,Bowen Michael S.,Volk Amanda A.,Abdel-Latif Kameel,Han Suyong,Reyes Kristofer G.,Amassian Aram,Abolhasani Milad","Epps RW,Bowen MS,Volk AA,Abdel-Latif K,Han SY,Reyes KG,Amassian A,Abolhasani M",Abolhasani M,10.1002/adma.202001626,University of North Carolina,"The optimal synthesis of advanced nanomaterials with numerous reaction parameters, stages, and routes, poses one of the most complex challenges of modern colloidal science, and current strategies often fail to meet the demands of these combinatorially large systems. In response, an Artificial Chemist is presented: the integration of machine-learning-based experiment selection and high-efficiency autonomous flow chemistry. With the self-driving Artificial Chemist, made-to-measure inorganic perovskite quantum dots (QDs) in flow are autonomously synthesized, and their quantum yield and composition polydispersity at target bandgaps, spanning 1.9 to 2.9 eV, are simultaneously tuned. Utilizing the Artificial Chemist, eleven precision-tailored QD synthesis compositions are obtained without any prior knowledge, within 30 h, using less than 210 mL of total starting QD solutions, and without user selection of experiments. Using the knowledge generated from these studies, the Artificial Chemist is pre-trained to use a new batch of precursors and further accelerate the synthetic path discovery of QD compositions, by at least twofold. The knowledge-transfer strategy further enhances the optoelectronic properties of the in-flow synthesized QDs (within the same resources as the no-prior-knowledge experiments) and mitigates the issues of batch-to-batch precursor variability, resulting in QDs averaging within 1 meV from their target peak emission energy.","autonomous synthesis,machine learning,microfluidics,perovskites,quantum dots",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,30.254,"HALIDE,PEROVSKITES,CSPBX3,ANION-EXCHANGE,NANOCRYSTALS,REACTOR,BR,CL,OPTIMIZATION,TEMPERATURE,PLATFORM",ADVANCED MATERIALS,https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/adma.202001626,
39,Prediction of Adhesion Strength Using Extreme Learning Machine and Support Vector Regression Optimized with Genetic Algorithm,45,8,6985-7004,"Hazir Ender,Ozcan Tuncay,Koc Kocuk Huseyin","Hazir E,Ozcan T,Koc KH",Hazir E,10.1007/s13369-020-04625-0,Istanbul University - Cerrahpasa,"Adhesion strength is one of the most significant quality characteristics for coating performance. Heat treatment and sanding process parameters affect the adhesion strength. The aim of this study was to predict the adhesion strength using machine learning and optimization algorithms. Process factors were selected such as temperature, time, cutting speed, feed rate and grit size while coating performance index was selected as adhesion strength. Adhesion strength values of the specimens were determined by employing pull-off adhesion-type equipment. Firstly, central composite design with analysis of variance was used to create the experimental design and to determine the effective factors. Moreover, the main effect plot was used to determine the values of effective factors. Then, support vector machine (SVR) and extreme learning machine (ELM) were used to predict the adhesion strength. Finally, genetic algorithm was applied to optimize the parameters of SVM and ELM in order to improve the prediction accuracy. The proposed hybrid SVR-GA and ELM-GA approaches were compared with linear regression (LR), SVR and ELM. Experimental results showed that the proposed SVR-GA and ELM-GA approaches outperformed the LR, SVR and ELM in terms of prediction accuracy.","Support vector machine,Extreme learning machine,Genetic algorithm,Surface coating,Adhesion strength",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Science & Technology - Other Topics,,2.205,"HEAT-TREATMENT,SURFACE-ROUGHNESS,WOOD,PERFORMANCE,MODEL",ARABIAN JOURNAL FOR SCIENCE AND ENGINEERING,,
40,Dynamic imaging of lithium in solid-state batteries by operando electron energy-loss spectroscopy with sparse coding,11,1,,"Nomura Yuki,Yamamoto Kazuo,Fujii Mikiya,Hirayama Tsukasa,Igaki Emiko,Saitoh Koh","Nomura Y,Yamamoto K,Fujii M,Hirayama T,Igaki E,Saitoh K",Nomura Y,10.1038/s41467-020-16622-w,Panasonic,"Lithium-ion transport in cathodes, anodes, solid electrolytes, and through their interfaces plays a crucial role in the electrochemical performance of solid-state lithium-ion batteries. Direct visualization of the lithium-ion dynamics at the nanoscale provides valuable insight for understanding the fundamental ion behaviour in batteries. Here, we report the dynamic changes of lithium-ion movement in a solid-state battery under charge and discharge reactions by time-resolved operando electron energy-loss spectroscopy with scanning transmission electron microscopy. Applying image denoising and super-resolution via sparse coding drastically improves the temporal and spatial resolution of lithium imaging. Dynamic observation reveals that the lithium ions in the lithium cobaltite cathode are complicatedly extracted with diffusion through the lithium cobaltite domain boundaries during charging. Even in the open-circuit state, they move inside the cathode. Operando electron energy-loss spectroscopy with sparse coding is a promising combination to visualize the ion dynamics and clarify the fundamentals of solid-state electrochemistry. Understanding lithium ion dynamics holds the key to unlocking better battery materials and devices. Here, by combining electron energy-loss spectroscopy and machine learning, the authors reveal how lithium is extracted from LiCoO2 cathode used in a solid-state battery.",ION BATTERY,Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,15.805,"ION,BATTERY,CATHODE,MATERIAL",NATURE COMMUNICATIONS,https://www.nature.com/articles/s41467-020-16622-w.pdf,
41,A bidirectional reflectance distribution function model of space targets in visible spectrum based on GA-BP network,126,6,,"Liu Yuying,Dai Jingjing,Zhao Sisi,Zhang Jinghao,Li Tong,Shang Weidong,Zheng Yongchao,Wang Zhiyong","Liu YY,Dai JJ,Zhao SS,Zhang JH,Li T,Shang WD,Zheng YC,Wang ZY",Wang ZY,10.1007/s00340-020-07455-y,"Beijing Univ Technol, Inst Laser Engn, Beijing 100020, Peoples R China.","An optimized Back-Propagation network (BP network) based on Genetic Algorithm (GA) was introduced to construct bidirectional reflectance distribution function (BRDF) model. To verify the performance of GA-BP network, two different kinds of space target materials were used for experiment. Based on the experimental data, we used GA to simulate the undetermined parameters of a five-parameter BRDF model, and used GA-BP network and BP network to construct a new BRDF model respectively. The fitting results manifest that the GA-BP network is suitable for construct a new BRDF model and outperforms the five-parameter BRDF model in speed and accuracy under the same condition.","NEURAL-NETWORK,ALGORITHM,BRDF,OPTIMIZATION,PREDICTION",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Optics,Physics",,1.825,"NEURAL-NETWORK,ALGORITHM,BRDF,OPTIMIZATION,PREDICTION",APPLIED PHYSICS B-LASERS AND OPTICS,,
42,Machine-Learning-Optimized Aperiodic Superlattice Minimizes Coherent Phonon Heat Conduction,10,2,,"Hu Run,Iwamoto Sotaro,Feng Lei,Ju Shenghong,Hu Shiqian,Ohnishi Masato,Nagai Naomi,Hirakawa Kazuhiko,Shiomi Junichiro","Hu R,Iwamoto S,Feng L,Ju SH,Hu SQ,Ohnishi M,Nagai N,Hirakawa K,Shiomi J",Shiomi J,10.1103/PhysRevX.10.021050,University of Tokyo,"Lattice heat conduction can be modulated via nanostructure interfaces. Although advances have been made by viewing phonons as particles, the controllability should be enhanced by fully utilizing their wave nature. By considering phonons as coherent waves, herein we design an optimized aperiodic superlattice that minimizes the coherent phonon heat conduction by alternatingly coupling coherent phonon transport calculations and machine learning. The thermal conductivity of the fabricated aperiodic superlattice agrees well with the calculations over a temperature range of 77-300 K, indicating that complex aperiodic wave interference of coherent phonons can be controlled. The thermal conductivity of the aperiodic superlattice is significantly smaller than the conventional periodic superlattice due to enhanced phonon localization. The optimized aperiodic structure is formed by connecting weakly correlated local structures that introduce interference over broad phonon frequencies. Controlling coherent phonons by aperiodic interferences opens a new route for phonon engineering.",THERMAL-CONDUCTIVITY,Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,15.641,THERMAL-CONDUCTIVITY,PHYSICAL REVIEW X,http://link.aps.org/pdf/10.1103/PhysRevX.10.021050,
43,Topology-Based Machine Learning Strategy for Cluster Structure Prediction,11,11,4392-4401,"Chen Xin,Chen Dong,Weng Mouyi,Jiang Yi,Wei Guo-Wei,Pan Feng","Chen X,Chen D,Weng MY,Jiang Y,Wei GW,Pan F",Wei GW,10.1021/acs.jpclett.0c00974,Michigan State University,"In cluster physics, the determination of the ground-state structure of medium-sized and large-sized clusters is a challenge due to the number of local minimal values on the potential energy surface growing exponentially with cluster size. Although machine learning approaches have had much success in materials sciences, their applications in clusters are often hindered by the geometric complexity clusters. Persistent homology provides a new topological strategy to simplify geometric complexity while retaining important chemical and physical information without having to ""downgrade"" the original data. We further propose persistent pairwise independence (PPI) to enhance the predictive power of persistent homology. We construct topology-based machine learning models to reveal hidden structure-energy relationships in lithium (Li) clusters. We integrate the topology-based machine learning models, a particle swarm optimization algorithm, and density functional theory calculations to accelerate the search of the globally stable structure of clusters.","POTENTIAL-ENERGY SURFACES,GEOMETRY OPTIMIZATION,PERSISTENT HOMOLOGY,GLOBAL MINIMUM,CHEMISTRY,CARBON",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,7.643,"POTENTIAL-ENERGY,SURFACES,GEOMETRY,OPTIMIZATION,PERSISTENT,HOMOLOGY,GLOBAL,MINIMUM,CHEMISTRY,CARBON",JOURNAL OF PHYSICAL CHEMISTRY LETTERS,https://europepmc.org/articles/pmc7351018?pdf=render,
44,,,,,,,,,,,,,,,,,,,,
45,Exploration of Machine Learning to Predict Hot Ductility of Cast Steel from Chemical Composition and Thermal Conditions,27,2,298-305,"Hong Daegeun,Kwon Sanghum,Yim Changhee","Hong D,Kwon S,Yim C",Yim C,10.1007/s12540-020-00713-w,Pohang University of Science & Technology (POSTECH),"This study explores the use of machine learning (ML) as a data-driven approach to estimate hot ductility of cast steel from literature data. Four ML algorithms were used to predict hot ductility by considering elemental composition and thermal conditions. Experimentally-measured reduction of area (RA) values were converted to a low-temperature limit, center-temperature, and high-temperature limit, which were represented as Gaussian curves. The prediction accuracy of the four ML models was evaluated using RMSE for these three output variables. In a case study of three steels that had different contents of alloying elements, only the Neural-net model predicted the RA trough more accurately in all cases. These results demonstrate the utility of ML models to predict hot ductility of cast steels.","Prediction model,Data-driven inverse model,Random forest,Gaussian process,Support vector machine,Neural network,Gaussian fitting",Article,"KOREAN INST METALS MATERIALS, KIM BLDG 6TH FLOOR, SEOCHO-DAERO 56 GIL 38, SEOCHO-GU, SEOUL 137-881, SOUTH KOREA","Materials Science,Metallurgy & Metallurgical Engineering",,,"MECHANICAL-PROPERTIES,BEHAVIOR,SUPPORT,CYCLE",METALS AND MATERIALS INTERNATIONAL,,
46,Pre-operative Microvascular Invasion Prediction Using Multi-parametric Liver MRI Radiomics,33,6,1376-1386,"Nebbia Giacomo,Zhang Qian,Arefan Dooman,Zhao Xinxiang,Wu Shandong","Nebbia G,Zhang Q,Arefan D,Zhao XX,Wu SD",Wu SD,10.1007/s10278-020-00353-x,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Microvascular invasion (mVI) is the most significant independent predictor of recurrence for hepatocellular carcinoma (HCC), but its pre-operative assessment is challenging. In this study, we investigate the use of multi-parametric MRI radiomics to predict mVI status before surgery. We retrospectively collected pre-operative multi-parametric liver MRI scans for 99 patients who were diagnosed with HCC. These patients received surgery and pathology-confirmed diagnosis of mVI. We extracted radiomics features from manually segmented HCC regions and built machine learning classifiers to predict mVI status. We compared the performance of such classifiers when built on five MRI sequences used both individually and combined. We investigated the effects of using features extracted from the tumor region only, the peritumoral marginal region only, and the combination of the two. We used the area under the receiver operating characteristic curve (AUC) and accuracy as performance metrics. By combining features extracted from multiple MRI sequences, AUCs are 86.69%, 84.62%, and 84.19% when features are extracted from the tumor only, the peritumoral region only, and the combination of the two, respectively. For tumor-extracted features, the T2 sequence (AUC = 80.84%) and portal venous sequence (AUC = 79.22%) outperform other MRI sequences in single-sequence-based models and their combination yields the highest AUC of 86.69% for mVI status prediction. Our results show promise in predicting mVI from pre-operative liver MRI scans and indicate that information from multi-parametric MRI sequences is complementary in identifying mVI.","Hepatocellular carcinoma,Microvascular invasion,Radiomics,Machine learning,MRI",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"HEPATOCELLULAR-CARCINOMA,TRANSPLANTATION,RECURRENCE,SELECTION,RESECTION,SYSTEM,TRENDS,CANCER,GRADE",JOURNAL OF DIGITAL IMAGING,,
47,A Scalable Natural Language Processing for Inferring BT-RADS Categorization from Unstructured Brain Magnetic Resonance Reports,33,6,1393-1400,"Lee Scott J.,Weinberg Brent D.,Gore Ashwani,Banerjee Imon","Lee SJ,Weinberg BD,Gore A,Banerjee I",Banerjee I,10.1007/s10278-020-00350-0,Emory University,"The aim of this study is to develop an automated classification method for Brain Tumor Reporting and Data System (BT-RADS) categories from unstructured and structured brain magnetic resonance imaging (MR) reports. This retrospective study included 1410 BT-RADS structured reports dated from January 2014 to December 2017 and a test set of 109 unstructured brain MR reports dated from January 2010 to December 2014. Text vector representations and semantic word embeddings were generated from individual report sections (i.e., ""History,"" ""Findings,"" etc.) using Tf-idf statistics and a fine-tuned word2vec model, respectively. Section-wise ensemble models were trained using gradient boosting (XGBoost), elastic net regularization, and random forests, and classification accuracy was evaluated on an independent test set of unstructured brain MR reports and a validation set of BT-RADS structured reports. Section-wise ensemble models using XGBoost and word2vec semantic word embeddings were more accurate than those using Tf-idf statistics when classifying unstructured reports, with an f1 score of 0.72. In contrast, models using traditional Tf-idf statistics outperformed the word2vec semantic approach for categorization from structured reports, with an f1 score of 0.98. Proposed natural language processing pipeline is capable of inferring BT-RADS report scores from unstructured reports after training on structured report data. Our study provides a detailed experimentation process and may provide guidance for the development of RADS-focused information extraction (IE) applications from structured and unstructured radiology reports.","BT-RADS,Deep learning,NLP,Distributional semantics,Text mining",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"INFORMATION,RADIOLOGY",JOURNAL OF DIGITAL IMAGING,,
48,Learning the Clustering of Longitudinal Shape Data Sets into a Mixture of Independent or Branching Trajectories,128,12,2794-2809,"Debavelaere Vianney,Durrleman Stanley,Allassonniere Stephanie","Debavelaere V,Durrleman S,Allassonniere S",Debavelaere V,10.1007/s11263-020-01337-8,Institut Polytechnique de Paris,"Given repeated observations of several subjects over time, i.e. a longitudinal data set, this paper introduces a new model to learn a classification of the shapes progression in an unsupervised setting: we automatically cluster a longitudinal data set in different classes without labels. Our method learns for each cluster an average shape trajectory (or representative curve) and its variance in space and time. Representative trajectories are built as the combination of pieces of curves. This mixture model is flexible enough to handle independent trajectories for each cluster as well as fork and merge scenarios. The estimation of such non linear mixture models in high dimension is known to be difficult because of the trapping states effect that hampers the optimisation of cluster assignments during training. We address this issue by using a tempered version of the stochastic EM algorithm. Finally, we apply our algorithm on different data sets. First, synthetic data are used to show that a tempered scheme achieves better convergence. We then apply our method to different real data sets: 1D RECIST score used to monitor tumors growth, 3D facial expressions and meshes of the hippocampus. In particular, we show how the method can be used to test different scenarios of hippocampus atrophy in ageing by using an heteregenous population of normal ageing individuals and mild cognitive impaired subjects.","Longitudinal data analysis,Mixture model,Branching population,Stochastic optimization,Statistical model,Riemannian manifold",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,13.284,"PROGRESSION,MANIFOLDS,MODELS",INTERNATIONAL JOURNAL OF COMPUTER VISION,https://hal.archives-ouvertes.fr/hal-02283747/document,
49,Estimation of pharmacokinetic parameters from DCE-MRI by extracting long and short time-dependent features using an LSTM network,47,8,3447-3457,"Zou Jiaren,Balter James M.,Cao Yue","Zou JR,Balter JM,Cao Y",Zou JR,10.1002/mp.14222,University of Michigan System,"Purpose T-1-weighted dynamic contrast-enhanced Magnetic Resonance Imaging (DCE-MRI) is typically quantified by least squares (LS) fitting to a pharmacokinetic (PK) model to yield parameters of microvasculature and perfusion in normal and disease tissues. Such fitting is both time-consuming as well as subject to inaccuracy and instability in parameter estimates. Here, we propose a novel neural network approach to estimate the PK parameters by extracting long and short time-dependent features in DCE-MRI.
Methods A Long Short-Term Memory (LSTM) network, widely used for processing sequence data, was employed to map DCE-MRI time-series accompanied with an arterial input function to parameters of the extended Tofts model. Head and neck DCE-MRI from 103 patients were used for training and testing the LSTM model. Arterial input functions (AIFs) from 78 patients were used to generate synthetic DCE-MRI time-series for training, during which data augmentation was used to overcome the limited size of in vivo data. The model was tested on independent synthesized DCE data using AIFs from 25 patients. The LSTM performance was optimized for the numbers of layers and hidden state features. The performance of the LSTM was tested for different temporal resolution, total acquisition time, and contrast-to-noise ratio (CNR), and compared to the conventional LS fitting and a CNN-based method.
Results Compared to LS fitting, the LSTM model had comparable accuracy in PK parameter estimations from fully temporal-sampled DCE-MRI data (similar to 3 s per frame), but much better accuracy for the data with temporally subsampling (4s or greater per frame), total acquisition time truncation by 48%-16%, or low CNR (5 and 10). The LSTM reduced normalized root mean squared error by 40.4%, 46.9%, and 53.0% for sampling intervals of 4s, 5s, and 6s, respectively, compared to LS fitting. Compared to the CNN model, the LSTM model reduced the error in the parameter estimates up to 55.2%. Also, the LSTM improved the inference time by similar to 14 times on CPU compared to LS fitting.
Conclusion Our study suggests that the LSTM model could achieve improved robustness and computation speed for PK parameter estimation compared to LS fitting and the CNN based network, particularly for suboptimal data.","contrast agent,DCE-MRI,long-short-term memory,machine learning,pharmacokinetic model,temporal correlation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"THERAPY,SENSITIVITY,SENSE,HEAD",MEDICAL PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7429301,
50,Detailed identification of epidermal growth factor receptor mutations in lung adenocarcinoma: Combining radiomics with machine learning,47,8,3458-3466,"Li Shu,Luo Ting,Ding Changwei,Huang Qinlai,Guan Zhihao,Zhang Hao","Li S,Luo T,Ding CW,Huang QL,Guan ZH,Zhang H",Li S,10.1002/mp.14238,China Medical University,"Purpose To investigate the use of radiomics in the in-depth identification of epidermal growth factor receptor (EGFR) mutation status in patients with lung adenocarcinoma.
Methods Computed tomography images of 438 patients with lung adenocarcinoma were collected in two different institutions, and 496 radiomic features were extracted. In the training set, lasso logistic regression was used to establish radiomic signatures. Combining radiomic index and clinical features, five machine learning methods, and a tenfold cross-validation strategy were used to establish combined models for EGFR(+) vs EGFR(-), and 19Del vs L858R, groups. The predictive power of the models was then evaluated using an independent external validation cohort.
Results In the EGFR(+) vs EGFR(-) and 19Del vs L858R groups, radiomic signatures consisting of 12 and 7 radiomic features were established, respectively; the area under the curves (AUCs) of the lasso logistic regression model on the validation set was 0.76 and 0.71, respectively. After inclusion of the clinical features, the maximum AUC of combined models on the validation set was 0.79 and 0.74, respectively. Logistic regression analysis showed good performance in the two groups, with AUCs of 0.79 and 0.71 on the validation set. Additionally, the AUC of combined models in the EGFR(+) vs EGFR(-) group was higher than that of the 19Del vs L858R group.
Conclusions Our study shows the potential of radiomics to predict EGFR mutation status. There are imaging phenotypic differences between EGFR(+) and EGFR(-), and between 19Del and L858R; these can be used to allow patients with lung adenocarcinoma to choose more appropriate and personalized treatment options.","computed tomography,EGFR mutation,lasso logistic regression,lung adenocarcinoma,machine learning,radiomics",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"EGFR,MUTATIONS,CANCER,FEATURES,IMAGES,GEFITINIB",MEDICAL PHYSICS,,
51,Deep learning for identification of critical regions associated with toxicities after liver stereotactic body radiation therapy,47,8,3721-3731,"Ibragimov Bulat,Toesca Diego A. S.,Chang Daniel T.,Yuan Yixuan,Koong Albert C.,Xing Lei,Vogelius Ivan R.","Ibragimov B,Toesca DAS,Chang DT,Yuan YX,Koong AC,Xing L,Vogelius IR",Ibragimov B,10.1002/mp.14235,University of Copenhagen,"Purpose Radiation therapy (RT) is prescribed for curative and palliative treatment for around 50% of patients with solid tumors. Radiation-induced toxicities of healthy organs accompany many RTs and represent one of the main limiting factors during dose delivery. The existing RT planning solutions generally discard spatial dose distribution information and lose the ability to recognize radiosensitive regions of healthy organs potentially linked to toxicity manifestation. This study proposes a universal deep learning-based algorithm for recognitions of consistent dose patterns and generation of toxicity risk maps for the abdominal area.
Methods We investigated whether convolutional neural networks (CNNs) can automatically associate abdominal computed tomography (CT) images and RT dose plans with post-RT toxicities without being provided segmentation of abdominal organs. The CNNs were also applied to study RT plans, where doses at specific anatomical regions were reduced/increased, with the aim to pinpoint critical regions sparing of which significantly reduces toxicity risks. The obtained risk maps were computed for individual anatomical regions inside the liver and statistically compared to the existing clinical studies.
Results A database of 122 liver stereotactic body RT (SBRT) executed at Stanford Hospital from July 2004 and November 2015 was assembled. All patients treated for primary liver cancer, mainly hepatocellular carcinoma and cholangiocarcinoma, with complete follow-ups were extracted from the database. The SBRT treatment doses ranged from 26 to 50 Gy delivered in 1-5 fractions for primary liver cancer. The patients were followed up for 1-68 months depending on the survival time. The CNNs were trained to recognize acute and late grade 3+ biliary stricture/obstruction, hepatic failure or decompensation, hepatobiliary infection, liver function test (LFT) elevation or/and portal vein thrombosis, named for convenience hepatobiliary (HB) toxicities. The toxicity prediction accuracy was of 0.73 measured in terms of the area under the receiving operator characteristic curve. Significantly higher risk scores (P < 0.05) of HB toxicity manifestation were associated with irradiation for the hepatobiliary tract in comparison to the risk scores for liver segments I-VIII and portal vein. This observation is in strong agreement with anatomical and clinical expectations.
Conclusion In this work, we proposed and validated a universal deep learning-based solution for the identification of radiosensitive anatomical regions. Without any prior anatomical knowledge, CNNs automatically recognized the importance of hepatobiliary tract sparing during liver SBRT. (c) 2020 American Association of Physicists in Medicine","atlas,convolutional neural networks,deep learning,liver radiotherapy,toxicity,treatment outcome prediction",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"DOSE-SURFACE,MAPS,NEURAL-NETWORK,CANCER,RADIOTHERAPY,RECTAL,TOXICITY,PREDICTION,CLASSIFICATION,CORRELATE,MODEL,SBRT",MEDICAL PHYSICS,,
52,High-Throughput Analysis of Materials for Chemical Looping Processes,10,27,,"Singstock Nicholas R.,Bartel Christopher J.,Holder Aaron M.,Musgrave Charles B.","Singstock NR,Bartel CJ,Holder AM,Musgrave CB",Holder AM; Musgrave CB,10.1002/aenm.202000685,University of Colorado System,"Chemical looping is a promising approach for improving the energy efficiency of many industrial chemical processes. However, a major limitation of modern chemical looping technologies is the lack of suitable active materials to mediate the involved subreactions. Identification of suitable materials has been historically limited by the scarcity of high-temperature (>600 degrees C) thermochemical data to evaluate candidate materials. An accuratethermodynamic approach is demonstrated here to rapidly identify active materials which is applicable to a wide variety of chemical looping chemistries. Application of this analysis to chemical looping combustion correctly classifies 17/17 experimentally studied redox materials by their viability and identifies over 1300 promising yet previously unstudied active materials. This approach is further demonstrated by analyzing redox pairs for mediating a novel chemical looping process for producing pure SO2 from raw sulfur and air which could provide a more efficient and lower emission route to sulfuric acid. 12 promising redox materials for this process are identified, two of which are supported by previous experimental studies of their individual oxidation and reduction reactions. This approach provides the necessary foundation for connecting process design with high-throughput material discovery to accelerate the innovation and development of a wide range of chemical looping technologies.","chemical looping,high-throughput screening,machine learning,redox catalysis",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Energy & Fuels,Materials Science,Physics",,27.97,"POWER-GENERATION,SYSTEM,OXYGEN,CARRIERS,AIR,SEPARATION,EFFICIENT,GENERATION,HYDROGEN-PRODUCTION,REDOX,CATALYSTS,SULFUR-DIOXIDE,CO2,CAPTURE,COMBUSTION,METHANE",ADVANCED ENERGY MATERIALS,https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/aenm.202000685,
53,High-resolution resonance spin-flip Raman spectroscopy of pairs of manganese ions in a CdTe quantum well,101,24,,"Cherbunin R. V,Litviak V. M.,Ryzhov I. I.,Koudinov A. V,Elsaesser S.,Knapp A.,Kiessling T.,Geurts J.,Chusnutdinow S.,Wojtowicz T.","Cherbunin RV,Litviak VM,Ryzhov II,Koudinov AV,Elsasser S,Knapp A,Kiessling T,Geurts J,Chusnutdinow S,Wojtowicz T",Koudinov AV,10.1103/PhysRevB.101.241301,Saint Petersburg State University,"We report the observation of tens of minor lines of the combinational spin-flip Raman scattering in a CdTe:Mn quantum well by means of the high-resolution optical spectroscopy. Classification of this manifold leads to four characteristic values of energy, that correspond to four different types of pair clusters of Mn ions: the nearest, second, third, etc., neighbors. All the four energies show up in a single experiment with a very high precision, providing experimental grounds for a deeper understanding of the d-d exchange interactions in a diluted magnetic semiconductor and demonstrating the capacity of the employed method. The major (nearestneighbor) exchange constant J(1) = 6.15 +/- 0.05 K was found to consent with its previously reported value. Other detected characteristic energies are as follows (+/- 0.05 K): J((2)) = 1.80 K, J((3)) = 1.39 K, J((4)) = 0.81 K.","HIGH-FIELD MAGNETIZATION,SEMIMAGNETIC SEMICONDUCTORS,EXCHANGE INTERACTIONS,SCATTERING,STEPS,CLUSTERS,SUSCEPTIBILITY,CD1-XMNXTE,SATURATION,EXCITONS",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,"HIGH-FIELD,MAGNETIZATION,SEMIMAGNETIC,SEMICONDUCTORS,EXCHANGE,INTERACTIONS,SCATTERING,STEPS,CLUSTERS,SUSCEPTIBILITY,CD1-XMNXTE,SATURATION,EXCITONS",PHYSICAL REVIEW B,http://arxiv.org/pdf/1903.01276,
54,Detection of topological materials with machine learning,101,24,,"Claussen Nikolas,Bernevig B. Andrei,Regnault Nicolas","Claussen N,Bernevig BA,Regnault N",Claussen N,10.1103/PhysRevB.101.245117,Centre National de la Recherche Scientifique (CNRS),"Databases compiled using ab initio and symmetry-based calculations now contain tens of thousands of topological insulators and topological semimetals. This makes the application of modern machine learning methods to topological materials possible. Using gradient boosted trees, we show how to construct a machine learning model which can predict the topology of a given existent material with an accuracy of 90%. Such predictions are orders of magnitude faster than actual ab initio calculations. We use machine learning models to probe how different material properties affect topological features. Notably, we observe that topology is mostly determined by the ""coarse-grained"" chemical composition and crystal symmetry and depends little on the particular positions of atoms in the crystal lattice. We identify the sources of our model's errors and we discuss approaches to overcome them.",CATALOG,Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,CATALOG,PHYSICAL REVIEW B,http://arxiv.org/pdf/1910.10161,
55,Efficient Closed-loop Maximization of Carbon Nanotube Growth Rate using Bayesian Optimization,10,1,,"Chang Jorge,Nikolaev Pavel,Carpena-Nunez Jennifer,Rao Rahul,Decker Kevin,Islam Ahmad E.,Kim Jiseob,Pitt Mark A.,Myung Jay I.,Maruyama Benji","Chang J,Nikolaev P,Carpena-Nunez J,Rao R,Decker K,Islam AE,Kim J,Pitt MA,Myung JI,Maruyama B",Myung JI,10.1038/s41598-020-64397-3,Ohio State University,"A major technological challenge in materials research is the large and complex parameter space, which hinders experimental throughput and ultimately slows down development and implementation. In single-walled carbon nanotube (CNT) synthesis, for instance, the poor yield obtained from conventional catalysts is a result of limited understanding of input-to-output correlations. Autonomous closedloop experimentation combined with advances in machine learning (ML) is uniquely suited for high-throughput research. Among the ML algorithms available, Bayesian optimization (BO) is especially apt for exploration and optimization within such high-dimensional and complex parameter space. BO is an adaptive sequential design algorithm for finding the global optimum of a black-box objective function with the fewest possible measurements. Here, we demonstrate a promising application of BO in CNT synthesis as an efficient and robust algorithm which can (1) improve the growth rate of CNT in the BO-planner experiments over the seed experiments up to a factor 8; (2) rapidly improve its predictive power (or learning); (3) Consistently achieve good performance regardless of the number or origin of seed experiments; (4) exploit a high-dimensional, complex parameter space, and (5) achieve the former 4 tasks in just over 100 hundred experiments (similar to 8 experimental hours) - a factor of 5x faster than our previously reported results.",WATER,Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,5.134,WATER,SCIENTIFIC REPORTS,https://www.nature.com/articles/s41598-020-64397-3.pdf,
56,"Current Status, Challenges, and Possible Solutions of EEG-Based Brain-Computer Interface: A Comprehensive Review",14,,,"Rashid Mamunur,Sulaiman Norizam,Majeed Anwar P. P. Abdul,Musa Rabiu Muazu,Ab Nasir Ahmad Fakhri,Bari Bifta Sama,Khatun Sabira","Rashid M,Sulaiman N,Majeed APPA,Musa RM,Ab Nasir AF,Bari BS,Khatun S",Rashid M,10.3389/fnbot.2020.00025,Universiti Malaysia Pahang,"Brain-Computer Interface (BCI), in essence, aims at controlling different assistive devices through the utilization of brain waves. It is worth noting that the application of BCI is not limited to medical applications, and hence, the research in this field has gained due attention. Moreover, the significant number of related publications over the past two decades further indicates the consistent improvements and breakthroughs that have been made in this particular field. Nonetheless, it is also worth mentioning that with these improvements, new challenges are constantly discovered. This article provides a comprehensive review of the state-of-the-art of a complete BCI system. First, a brief overview of electroencephalogram (EEG)-based BCI systems is given. Secondly, a considerable number of popular BCI applications are reviewed in terms of electrophysiological control signals, feature extraction, classification algorithms, and performance evaluation metrics. Finally, the challenges to the recent BCI systems are discussed, and possible solutions to mitigate the issues are recommended.","brain-computer interface (BCI),electroencephalogram (EEG),machine learning,classification,feature extraction",Review,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND","Computer Science,Robotics,Neurosciences & Neurology",,3.272,"SSVEP-BASED,BCI,MOTOR,IMAGERY,CLASSIFICATION,CONVOLUTIONAL,NEURAL-NETWORK,REMOVE,MUSCLE,ARTIFACTS,SUPPORT,VECTOR,MACHINES,HIDDEN,MARKOV-MODELS,LOG,ENERGY,ENTROPY,FEATURE-EXTRACTION,REAL-TIME,NEUROPHYSIOLOGICAL,PROTOCOL",FRONTIERS IN NEUROROBOTICS,https://europepmc.org/articles/pmc7283463?pdf=render,
57,Anion order in oxysulfide perovskites: origins and implications,6,1,,"Pilania Ghanshyam,Ghosh Ayana,Hartman Steven T.,Mishra Rohan,Stanek Christopher R.,Uberuaga Blas P.","Pilania G,Ghosh A,Hartman ST,Mishra R,Stanek CR,Uberuaga BP",Pilania G,10.1038/s41524-020-0338-1,United States Department of Energy (DOE),"Heteroanionic oxysulfide perovskite compounds represent an emerging class of new materials allowing for a wide range of tunability in the electronic structure that could lead to a diverse spectrum of novel and improved functionalities. Unlike cation ordered double perovskites-where the origins and design rules of various experimentally observed cation orderings are well known and understood-anion ordering in heteroanionic perovskites remains a largely uncharted territory. In this contribution, we present and discuss insights that have emerged from our first-principles-based electronic structure analysis of a prototypical anion-ordered SrHf(O0.5S0.5)(3) oxysulfide chemistry, studied in all possible anion configurations allowed within a finite size supercell. We demonstrate that the preferred anion ordering is always an all-cis arrangement of anions around an HfO3S3 octahedron. As a general finding beyond the specific chemistry, the origins of this ordering tendency are traced back to a combined stabilization effect stemming from electronic, elastic, and electrostatic contributions. These qualitative notions are also quantified using state-of-the-art machine learning models. We further study the relative stability of the identified ordering as a function of A (Ca, Sr, Ba) and B (Ti, Zr, Hf) site chemistries and probe chemistry-dependent trends in the electronic structure and functionality of the material. Most remarkably, we find that the identified ground-state anion ordering breaks the inversion symmetry to create a family of oxysulfide ferroelectrics with a macroscopic polarization >30 mu C/cm(2), exhibiting a significant promise for electronic materials applications.","CRYSTAL-STRUCTURE,CHALCOGENIDE PEROVSKITES,SEMICONDUCTOR,POLARIZATION,BAZRS3",Article,"NATURE PORTFOLIO, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Chemistry,Materials Science",,13.993,"CRYSTAL-STRUCTURE,CHALCOGENIDE,PEROVSKITES,SEMICONDUCTOR,POLARIZATION,BAZRS3",NPJ COMPUTATIONAL MATERIALS,https://www.nature.com/articles/s41524-020-0338-1.pdf,
58,A reactive scheduling method for disturbances in aircraft moving assembly line,59,15,4756-4772,"Zhu Hongwei,Lu Zhiqiang,Lu Chenyao,Ren Yifei","Zhu HW,Lu ZQ,Lu CY,Ren YF",Lu ZQ,10.1080/00207543.2020.1771456,Tongji University,"Aircraft assembly requires a large number of materials from hundreds of suppliers, and the uncertainty in material delivery has a negative impact on the assembly schedule. Existing researches stop short of introducing how to reschedule assembly activities in this context, so this paper addresses a reactive scheduling problem of aircraft moving assembly line with uncertain material delivery, and a bi-objective model is established. To absorb the advantage of machine learning-based method, we present a SVDD-based reactive scheduling method (SVDD-RS). Firstly, the models under different settings of disturbances in material delivery are solved, and the obtained policies are used to train the SVDD classification model in the offline training phase. In the online reactive scheduling phase, the trained SVDD classification model is used to make a preliminary decision for unstarted activities, and exact start-times are further determined by the local forward-looking algorithm. Computational experiments are carried out over practical cases generated from an aircraft assembly line to evaluate the performance of SVDD-RS. The results show that the SVDD classification model can quickly select policies with reasonable accuracy, and SVDD-RS can guarantee a quick response to the disturbance and produce a high-quality solution, compared to other existing reactive scheduling methods.","Uncertainty,materials handling,dynamic scheduling,assembly lines",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Engineering,Operations Research & Management Science",,6.715,"RESOURCE,ALGORITHM,JOBS",INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH,,
59,,,,,,,,,,,,,,,,,,,,
60,,,,,,,,,,,,,,,,,,,,
61,Automatic Segmentation of Meniscus in Multispectral MRI Using Regions with Convolutional Neural Network (R-CNN),33,4,916-929,"Olmez Emre,Akdogan Volkan,Korkmaz Murat,Er Orhan","Olmez E,Akdogan V,Korkmaz M,Er O",Olmez E,10.1007/s10278-020-00329-x,Bozok University,"The meniscus has a significant function in human anatomy, and Magnetic Resonance Imaging (MRI) has an essential role in meniscus examination. Due to a variety of MRI data, it is excessively difficult to segment the meniscus with image processing methods. An MRI data sequence contains multiple images, and the region features we are looking for may vary from each image in the sequence. Therefore, feature extraction becomes more difficult, and hence, explicitly programming for segmentation becomes more difficult. Convolutional Neural Network (CNN) extracts features directly from images and thus eliminates the need for manual feature extraction. Regions with Convolutional Neural Network (R-CNN) allow us to use CNN features in object detection problems by combining CNN features with Region Proposals. In this study, we designed and trained an R-CNN for detecting meniscus region in MRI data sequence. We used transfer learning for training R-CNN with a small amount of meniscus data. After detection of the meniscus region by R-CNN, we segmented meniscus by morphological image analysis using two different MRI sequences. Automatic detection of the meniscus region with R-CNN made the meniscus segmentation process easier, and the use of different contrast features of two different image sequences allowed us to differentiate the meniscus from its surroundings.","Automatic segmentation of meniscus,Regions with convolutional neural network,Region proposals,Transfer learning,Deep learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"KNEE,MENISCUS",JOURNAL OF DIGITAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7522137,
62,A novel method to process surface electromyography signal for pedestrian lower limb motion pattern recognition,42,13,2492-2498,"Gu Chenyang,Ren Chunhua,Zhou Meilin","Gu CY,Ren CH,Zhou ML",Ren CH,10.1177/0142331220918357,Chongqing University,"Surface electromyography (sEMG) signals mainly contain power line interference (PLI), white Gaussian noise (WGN), and baseline wandering (BW) noise. These noises lead to the problems of poor feature extraction performance and low recognition rate. In this paper, we propose a novel sEMG signal processing method named filtering and self-enhancement algorithm with classical wavelet (FSECW) algorithm, which denoises interference noises of raw signals and improve the pedestrian motion pattern recognition rate. The proposed FSECW algorithm contains two core parts: in the first part, the original signal is reconstructed after four-layer wavelet decomposition. This part decreases the BW noise and enhances the active segment; in the other part, band-pass filtering and lifting wavelet transformation are used to reduce noises inside and outside the sEMG signal band. Then two signals from the above parts are multiplied. Thus, the enhanced filtered signal of the active segment is obtained. After feature extraction, the algorithm uses classical machine learning algorithm for motion pattern recognition. Experimental results show that the proposed FSECW algorithm does not need to set different thresholds for different data sets with the same motion pattern. Moreover, it has better adaptability to conversions of different motion patterns.","sEMG,motion pattern recognition,signal processing method",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Automation & Control Systems,Instruments & Instrumentation",,1.816,"SEMG,SYSTEM",TRANSACTIONS OF THE INSTITUTE OF MEASUREMENT AND CONTROL,,
63,Hippocampus segmentation on noncontrast CT using deep learning,47,7,2950-2961,"Porter Evan,Fuentes Patricia,Siddiqui Zaid,Thompson Andrew,Levitin Ronald,Solis David,Myziuk Nick,Guerrero Thomas","Porter E,Fuentes P,Siddiqui Z,Thompson A,Levitin R,Solis D,Myziuk N,Guerrero T",Guerrero T,10.1002/mp.14098,Beaumont Health,"Purpose Accurate segmentation of the hippocampus for hippocampal avoidance whole-brain radiotherapy currently requires high-resolution magnetic resonance imaging (MRI) in addition to neuroanatomic expertise for manual segmentation. Removing the need for MR images to identify the hippocampus would reduce planning complexity, the need for a treatment planning MR imaging session, potential uncertainties associated with MRI-computed tomography (CT) image registration, and cost. Three-dimensional (3D) deep convolutional network models have the potential to automate hippocampal segmentation. In this study, we investigate the accuracy and reliability of hippocampal segmentation by automated deep learning models from CT alone and compare the accuracy to experts using MRI fusion.
Methods Retrospectively, 390 Gamma Knife patients with high-resolution CT and MR images were collected. Following the RTOG 0933 guidelines, images were rigidly fused, and a neuroanatomic expert contoured the hippocampus on the MR, then transferred the contours to CT. Using a calculated cranial centroid, the image volumes were cropped to 200 x 200 x 35 voxels, which were used to train four models, including our proposed Attention-Gated 3D ResNet (AG-3D ResNet). These models were then compared with results from a nested tenfold validation. From the predicted test set volumes, we calculated the 100% Hausdorff distance (HD). Acceptability was assessed using the RTOG 0933 protocol criteria, and contours were considered passing with HD <= 7 mm.
Results The bilateral hippocampus passing rate across all 90 models trained in the nested cross-fold validation was 80.2% for AG-3D ResNet, which performs with a comparable pass rate (P = 0.3345) to physicians during centralized review for the RTOG 0933 Phase II clinical trial.
Conclusions Our proposed AG-3D ResNet's segmentation of the hippocampus from noncontrast CT images alone are comparable to those obtained by participating physicians from the RTOG 0933 Phase II clinical trial.","attention gating,CT,deep learning,hippocampus,ResNet,segmentation,U-Net,whole-brain radiotherapy",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"WHOLE-BRAIN,RADIOTHERAPY,CONVOLUTIONAL,NEURAL-NETWORK,STEM-CELL,COMPARTMENT,QUALITY-OF-LIFE,PHASE-III,TRIAL,NEUROCOGNITIVE,FUNCTION,CONFORMAL,AVOIDANCE,RADIATION-THERAPY,METASTASES,PRESERVATION",MEDICAL PHYSICS,,
64,Machine learning's limitations in avoiding automation of bias,36,1,197-203,"Varona Daniel,Lizama-Mue Yadira,Suarez Juan Luis","Varona D,Lizama-Mue Y,Suarez JL",Varona D,10.1007/s00146-020-00996-y,Western University (University of Western Ontario),"The use of predictive systems has become wider with the development of related computational methods, and the evolution of the sciences in which these methods are applied Solon and Selbst (Calif L REV 104: 671-732, 2016) and Pedreschi et al. (2007). The referred methods include machine learning techniques, face and/or voice recognition, temperature mapping, and other, within the artificial intelligence domain. These techniques are being applied to solve problems in socially and politically sensitive areas such as crime prevention and justice management, crowd management, and emotion analysis, just to mention a few. However, dissimilar predictions can be found nowadays as the result of the application of these methods resulting in misclassification, for example for the case of conviction risk assessment Office of Probation and Pretrial Services (2011) or decision-making process when designing public policies Lange (2015). The goal of this paper is to identify current gaps on fairness achievement within the context of predictive systems in artificial intelligence by analyzing available academic and scientific literature up to 2020. To achieve this goal, we have gathered available materials at the Web of Science and Scopus from last 5 years and analyzed the different proposed methods and their results in relation to the bias as an emergent issue in the Artificial Intelligence field of study. Our tentative conclusions indicate that machine learning has some intrinsic limitations which are leading to automate the bias when designing predictive algorithms. Consequently, other methods should be explored; or we should redefine the way current machine learning approaches are being used when building decision making/decision support systems for crucial institutions of our political systems such as the judicial system, just to mention one.","Machine learning,Bias,Bias automation,Artificial intelligence",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,,PREDICTION,AI & SOCIETY,,
65,Multi-view metric learning with Fisher discriminant analysis and its applications for breast image retrieval,35,6,619-630,"Zhou Guo-hua,Jiang Hui,Gu Xiao-qing,Yin Xin-chun","Zhou GH,Jiang H,Gu XQ,Yin XC",Zhou GH,10.3788/YJYXS20203506.0619,"Changzhou Inst Ind Technol, Dept Informat Engn, Changzhou 213164, Peoples R China.","The traditional medical image retrieval uses a single image, but the image information in a single image is limited, and the medical images taken from different angles can not be effectively utilized. To solve this problem, a medical image retrieval method based on multi-view metric learning with Fisher discriminant analysis (MVML-FDA) is proposed. The MVML-FDA learns robust metric space from multiple views based on Fisher discriminant model. A robust metric space allows the medical images of the same class to be closely mapped in the metric space, and different classes of medical images are separated from each other as much as possible. At the same time, the view weighting factor is set to make full use of the different representation information of each view feature. According to the distance metric learning, the MVML-FDA is applied to the diagnosis of breast diseases. The experimental results on the Breast Cancer Digital Repository dataset show that the proposed method has better performance, and improves retrieval accuracy by 7% compared with four multi-view methods.","medical image retrieval,breast image,multi-view,distance metric learning",Article,"SCIENCE PRESS, 16 DONGHUANGCHENGGEN NORTH ST, BEIJING, 100717, PEOPLES R CHINA",Crystallography,,,"CANCER,VECTOR",CHINESE JOURNAL OF LIQUID CRYSTALS AND DISPLAYS,,
66,Chronic Obstructive Pulmonary Disease Quantification Using CT Texture Analysis and Densitometry: Results From the Danish Lung Cancer Screening Trial,214,6,1269-1279,"Sorensen Lauge,Nielsen Mads,Petersen Jens,Pedersen Jesper H.,Dirksen Asger,de Bruijne Marleen","Sorensen L,Nielsen M,Petersen J,Pedersen JH,Dirksen A,de Bruijne M",Sorensen L,10.2214/AJR.19.22300,University of Copenhagen,"OBJECTIVE. The purpose of this study is to establish whether texture analysis and densitometry are complementary quantitative measures of chronic obstructive pulmonary disease (COPD) in a lung cancer screening setting.
MATERIALS AND METHODS. This was a retrospective study of data collected prospectively (in 2004-2010) in the Danish Lung Cancer Screening Trial. The texture score, relative area of emphysema, and percentile density were computed for 1915 baseline low-dose lung CT scans and were evaluated, both individually and in combination, for associations with lung function (i.e., forced expiratory volume in 1 second as a percentage of predicted normal [FEV1% predicted]), diagnosis of mild to severe COPD, and prediction of a rapid decline in lung function. Multivariate linear regression models with lung function as the outcome were compared using the likelihood ratio test or the Vuong test, and AUC values for diagnostic and prognostic capabilities were compared using the DeLong test.
RESULTS. Texture showed a significantly stronger association with lung function (p < 0.001 vs densitometric measures), a significantly higher diagnostic AUC value (for COPD, 0.696; for Global Initiative for Chronic Obstructive Lung Disease (GOLD) grade 1,0.648; for GOLD grade 2, 0.768; and for GOLD grade 3, 0.944; p < 0.001 vs densitometric measures), and a higher but not significantly different association with lung function decline. In addition, only texture could predict a rapid decline in lung function (AUC value, 0.538;p < 0.05 vs random guessing). The combination of texture and both densitometric measures strengthened the association with lung function and decline in lung function (p < 0.001 and p < 0.05, respectively, vs texture) but did not improve diagnostic or prognostic performance.
CONCLUSION. The present study highlights texture as a promising quantitative CT measure of COPD to use alongside, or even instead of, densitometric measures. Moreover, texture may allow early detection of COPD in subjects who undergo lung cancer screening.","chronic obstructive pulmonary disease,densitometry,machine learning,quantitative CT,texture analysis",Article,"AMER ROENTGEN RAY SOC, 44211 SLATESTONE CT, LEESBURG, VA USA","Radiology, Nuclear Medicine & Medical Imaging",,,"QUANTITATIVE,COMPUTED-TOMOGRAPHY,EMPHYSEMA,COPD,CLASSIFICATION,PATTERNS,PROGRESS,DENSITY,DECLINE,FOCUS,RISK",AMERICAN JOURNAL OF ROENTGENOLOGY,,
67,A Machine Vision-Based Method for Monitoring Broiler Chicken Floor Distribution,20,11,,"Guo Yangyang,Chai Lilong,Aggrey Samuel E.,Oladeinde Adelumola,Johnson Jasmine,Zock Gregory","Guo YY,Chai LL,Aggrey SE,Oladeinde A,Johnson J,Zock G",Chai LL,10.3390/s20113179,University System of Georgia,"The proper spatial distribution of chickens is an indication of a healthy flock. Routine inspections of broiler chicken floor distribution are done manually in commercial grow-out houses every day, which is labor intensive and time consuming. This task requires an efficient and automatic system that can monitor the chicken's floor distributions. In the current study, a machine vision-based method was developed and tested in an experimental broiler house. For the new method to recognize bird distribution in the images, the pen floor was virtually defined/divided into drinking, feeding, and rest/exercise zones. As broiler chickens grew, the images collected each day were analyzed separately to avoid biases caused by changes of body weight/size over time. About 7000 chicken areas/profiles were extracted from images collected from 18 to 35 days of age to build a BP neural network model for floor distribution analysis, and another 200 images were used to validate the model. The results showed that the identification accuracies of bird distribution in the drinking and feeding zones were 0.9419 and 0.9544, respectively. The correlation coefficient (R), mean square error (MSE), and mean absolute error (MAE) of the BP model were 0.996, 0.038, and 0.178, respectively, in our analysis of broiler distribution. Missed detections were mainly caused by interference with the equipment (e.g., the feeder hanging chain and water line); studies are ongoing to address these issues. This study provides the basis for devising a real-time evaluation tool to detect broiler chicken floor distribution and behavior in commercial facilities.","broiler chicken,health and welfare,animal behaviors,precision farming",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"COMPUTER,VISION,OPTICAL-FLOW,BEHAVIOR,SYSTEM,QUANTIFICATION,GENERATION,PATTERNS",SENSORS,https://europepmc.org/articles/pmc7309057?pdf=render,
68,Sensor Failure Tolerable Machine Learning-Based Food Quality Prediction Model,20,11,,"Kaya Aydin,Keceli Ali Seydi,Catal Cagatay,Tekinerdogan Bedir","Kaya A,Keceli AS,Catal C,Tekinerdogan B",Kaya A,10.3390/s20113173,Cankaya University,"For the agricultural food production sector, the control and assessment of food quality is an essential issue, which has a direct impact on both human health and the economic value of the product. One of the fundamental properties from which the quality of the food can be derived is the smell of the product. A significant trend in this context is machine olfaction or the automated simulation of the sense of smell using a so-called electronic nose or e-nose. Hereby, many sensors are used to detect compounds, which define the odors and herewith the quality of the product. The proper assessment of the food quality is based on the correct functioning of the adopted sensors. Unfortunately, sensors may fail to provide the correct measures due to, for example, physical aging or environmental factors. To tolerate this problem, various approaches have been applied, often focusing on correcting the input data from the failed sensor. In this study, we adopt an alternative approach and propose machine learning-based failure tolerance that ignores failed sensors. To tolerate for the failed sensor and to keep the overall prediction accuracy acceptable, a Single Plurality Voting System (SPVS) classification approach is used. Hereby, single classifiers are trained by each feature and based on the outcome of these classifiers, and a composed classifier is built. To build our SPVS-based technique, K-Nearest Neighbor (kNN), Decision Tree, and Linear Discriminant Analysis (LDA) classifiers are applied as the base classifiers. Our proposed approach has a clear advantage over traditional machine learning models since it can tolerate the sensor failure or other types of failures by ignoring and thus enhance the assessment of food quality. To illustrate our approach, we use the case study of beef cut quality assessment. The experiments showed promising results for beef cut quality prediction in particular, and food quality assessment in general.","classifier,single plurality voting system,ensemble classifier,machine learning,beef cut quality prediction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"ELECTRONIC-NOSE,DRIFT,COMPENSATION,FRAMEWORK",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7309019,
69,Can Multiple Uses of Biomass Limit the Feedstock Availability for Future Biogas Production? An Overview of Biogas Feedstocks and Their Alternative Uses,13,11,,"Dieu Linh Hoang,Davis Chris,Moll Henri C.,Nonhebel Sanderine","Hoang DL,Davis C,Moll HC,Nonhebel S",Hoang DL,10.3390/en13112747,"Integrated Res Energy Environm & Soc IREES, Nijenborgh 6, NL-9747 AG Groningen, Netherlands.","Biogas is expected to contribute 10% of the total renewable energy use in Europe in 2030. This expectation largely depends on the use of several biomass byproducts and wastes as feedstocks. However, the current development of a biobased economy requires biomass sources for multiple purposes. If alternative applications also use biogas feedstocks, it becomes doubtful whether they will be available for biogas production. To explore this issue, this paper aims to provide an overview of potential alternative uses of different biogas feedstocks being researched in literature. We conducted a literature review using the machine learning technique ""co-occurrence analysis of terms"". This technique reads thousands of abstracts from literature and records when pairs of biogas feedstock-application are co-mentioned. These pairs are assumed to represent the use of a feedstock for an application. We reviewed 109 biogas feedstocks and 217 biomass applications, revealing 1053 connections between them in nearly 55,000 scientific articles. Our results provide two insights. First, a large share of the biomass streams presently considered in the biogas estimates have many alternative uses, which likely limit their contribution to future biogas production. Second, there are streams not being considered in present estimates for biogas production although they have the proper characteristics.","biogas,biomass waste,competing uses,biomass applications,bio-based economy,biomass value pyramid,co-occurrence analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"MUNICIPAL,SOLID-WASTE,HYDROTHERMAL,LIQUEFACTION,MANURE,ENERGY,FOOD,FERMENTATION,PATHWAYS,STRAW,STATE,FIELD",ENERGIES,https://www.mdpi.com/1996-1073/13/11/2747/pdf,
70,Maximizing human effort for analyzing scientific images: A case study using digitized herbarium sheets,8,6,,"Brenskelle Laura,Guralnick Rob P.,Denslow Michael,Stucky Brian J.","Brenskelle L,Guralnick RP,Denslow M,Stucky BJ",Brenskelle L; Stucky BJ,10.1002/aps3.11370,State University System of Florida,"Premise Digitization and imaging of herbarium specimens provides essential historical phenotypic and phenological information about plants. However, the full use of these resources requires high-quality human annotations for downstream use. Here we provide guidance on the design and implementation of image annotation projects for botanical research. Methods and Results We used a novel gold-standard data set to test the accuracy of human phenological annotations of herbarium specimen images in two settings: structured, in-person sessions and an online, community-science platform. We examined how different factors influenced annotation accuracy and found that botanical expertise, academic career level, and time spent on annotations had little effect on accuracy. Rather, key factors included traits and taxa being scored, the annotation setting, and the individual scorer. In-person annotations were significantly more accurate than online annotations, but both generated relatively high-quality outputs. Gathering multiple, independent annotations for each image improved overall accuracy. Conclusions Our results provide a best-practices basis for using human effort to annotate images of plants. We show that scalable community science mechanisms can produce high-quality data, but care must be taken to choose tractable taxa and phenophases and to provide informative training material.","citizen science,herbarium specimens,image annotation,machine learning,phenology,specimen images",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Plant Sciences,,1.929,,APPLICATIONS IN PLANT SCIENCES,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7328657,
71,Analyzing MRI scans to detect glioblastoma tumor using hybrid deep belief networks,7,1,,"Reddy Annapareddy V. N.,Krishna Ch. Phani,Mallick Pradeep Kumar,Satapathy Sandeep Kumar,Tiwari Prayag,Zymbler Mikhail,Kumar Sachin","Reddy AVN,Krishna CP,Mallick PK,Satapathy SK,Tiwari P,Zymbler M,Kumar S",Kumar S,10.1186/s40537-020-00311-y,South Ural State University,"Glioblastoma (GBM) is a stage 4 malignant tumor in which a large portion of tumor cells are reproducing and dividing at any moment. These tumors are life threatening and may result in partial or complete mental and physical disability. In this study, we have proposed a classification model using hybrid deep belief networks (DBN) to classify magnetic resonance imaging (MRI) for GBM tumor. DBN is composed of stacked restricted Boltzmann machines (RBM). DBN often requires a large number of hidden layers that consists of large number of neurons to learn the best features from the raw image data. Hence, computational and space complexity is high and requires a lot of training time. The proposed approach combines DTW with DBN to improve the efficiency of existing DBN model. The results are validated using several statistical parameters. Statistical validation verifies that the combination of DTW and DBN outperformed the other classifiers in terms of training time, space complexity and classification accuracy.","Discrete wavelet transform,Deep belief network,Glioblastoma tumor,Magnetic resonance imaging",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Computer Science,,,"CLASSIFICATION,IMAGES",JOURNAL OF BIG DATA,https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-020-00311-y,
72,An assessment of machine learning models for slump flow and examining redundant features,25,6,565-574,Unlu Ramazan,Unlu R,Unlu R,10.12989/cac.2020.25.6.565,Gumushane University,"Over the years, several machine learning approaches have been proposed and utilized to create a prediction model for the high-performance concrete (HPC) slump flow. Despite HPC is a highly complex material, predicting its pattern is a rather ambitious process. Hence, choosing and applying the correct method remain a crucial task. Like some other problems, prediction of HPC slump flow suffers from abnormal attributes which might both have an influence on prediction accuracy and increases variance. In recent years, different studies are proposed to optimize the prediction accuracy for HPC slump flow. However, more state-of-the-art regression algorithms can be implemented to create a better model. This study focuses on several methods with different mathematical backgrounds to get the best possible results. Four well-known algorithms Support Vector Regression, M5P Trees, Random Forest, and MLPReg are implemented with optimum parameters as base learners. Also, redundant features are examined to better understand both how ingredients influence on prediction models and whether possible to achieve acceptable results with a few components. Based on the findings, the MLPReg algorithm with optimum parameters gives better results than others in terms of commonly used statistical error evaluation metrics. Besides, chosen algorithms can give rather accurate results using just a few attributes of a slump flow dataset.","multilayer perceptron regression,regression trees,support vector regression,redundant features,M5P trees",Article,"TECHNO-PRESS, PO BOX 33, YUSEONG, DAEJEON 305-600, SOUTH KOREA","Computer Science,Construction & Building Technology,Engineering,Materials Science",,,"SELF-COMPACTING,CONCRETE,MIX,DESIGN,METHOD,COMPRESSIVE,STRENGTH,MINERAL,ADDITIVES,NEURAL-NETWORKS,PERFORMANCE,PREDICTION,ADMIXTURES",COMPUTERS AND CONCRETE,,
73,PSI-rooted subgraph: A novel feature for IoT botnet detection using classifier algorithms,6,2,128-138,"Huy-Trung Nguyen,Quoc-Dung Ngo,Doan-Hieu Nguyen,Van-Hoang Le","Nguyen HT,Ngo QD,Nguyen DH,Le VH",Nguyen HT,10.1016/j.icte.2019.12.001,Vietnam Academy of Science & Technology (VAST),"It is obvious that IoT devices are widely used more and more in many areas. However, due to limited resources (e.g., memory, CPU), the security mechanisms on many IoT devices such as IP-Camera, router are low. Therefore, botnets are an emerging threat to compromise IoT devices recently. To tackle this, a novel method for IoT botnets detection plays a crucial role. In this paper, we have some contributions for IoT botnet detection: first, we present a novel high-level PSI-rooted subgraph-based feature for the detection of IoT botnets; second, we generate a limited number of features that have precise behavioral descriptions, which require smaller space and reduce processing time; third, The evaluation results show the effectiveness and robustness of PSI-rooted subgraph-based features, as with five machine classifiers consisting of Random Forest, Decision Tree, Bagging, k-Nearest Neighbor, and Support Vector Machine, each classifier achieves more than 97% detection rate and low time-consuming. Moreover, compared to other work, our proposed method obtains better performance. Finally, we publicize all our materials on Github, which will benefit future research (e.g., IoT botnet detection approach). (C) 2020 The Korean Institute of Communications and Information Sciences (KICS). Publishing services by Elsevier B.V.","IoT botnet,IoT security,Static malware detection,PSI-rooted subgraph,Machine learning,Deep learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Telecommunications",,3.481,,ICT EXPRESS,https://doi.org/10.1016/j.icte.2019.12.001,
74,Local Dynamics of Excitations in Glassy Liquids,76,12,1076-1082,"Lee Hyun Taek,Landy Jonathan,Kim Jaeup U.,Jho YongSeok","Lee HT,Landy J,Kim JU,Jho Y",Jho Y,10.3938/jkps.76.1076,Gyeongsang National University,"In this study, we propose new elementary processes of the excitation dynamics in glassy liquids, which trigger the structural rearrangement in a local and isolated region known as the cooperative rearrangement region. We identify the existence of primary particles which facilitate local dynamics by using a machine learning technique and a time series analysis. The local soft domains are established by a few soft particles that hop between local energy basins. While particles in contact with these primary soft particles respond non-linearly, other particles not in direct contact with them respond linearly as elastic materials.","Glassy liquids,Excitation,Soft domains,Machine learning",Article,"KOREAN PHYSICAL SOC, 635-4, YUKSAM-DONG, KANGNAM-KU, SEOUL 135-703, SOUTH KOREA",Physics,,0.533,"RELAXATION,MOTION",JOURNAL OF THE KOREAN PHYSICAL SOCIETY,,
75,Prediction of Electropulse-Induced Nonlinear Temperature Variation of Mg Alloy Based on Machine Learning,58,6,413-422,"Yu Jinyeong,Lee Myoungjae,Moon Young Hoon,Noh Yoojeong,Lee Taekyung","Yu J,Lee M,Moon YH,Noh Y,Lee T",Lee T,10.3365/KJMM.2020.58.6.413,Pusan National University,"Electropulse-induced heating has attracted attention due to its high energy efficiency. However, the process gives rise to a nonlinear temperature variation, which is difficult to predict using a traditional physics model. As an alternative, this study employed machine-learning technology to predict such temperature variation for the first time. Mg alloy was exposed to a single electropulse with a variety of pulse magnitudes and durations for this purpose. Nine machine-learning models were established from algorithms from artificial neural network (ANN), deep neural network (DNN), and extreme gradient boosting (XGBoost). The ANN models showed an insufficient predicting capability with respect to the region of peak temperature, where temperature varied most significantly. The DNN models were built by increasing model complexity, enhancing architectures, and tuning hyperparameters. They exhibited a remarkable improvement in predicting capability at the heating-cooling boundary as well as overall estimation. As a result, the DNN-2 model in this group showed the best prediction of nonlinear temperature variation among the machine-learning models built in this study. The XGBoost model exhibited poor predicting performance when default hyperparameters were applied. However, hyperparameter tuning of learning rates and maximum depths resulted in a decent predicting capability with this algorithm. Furthermore, XGBoost models exhibited an extreme reduction in learning time compared with the ANN and DNN models. This advantage is expected to be useful for predicting more complicated cases including various materials, multi-step electropulses, and electrically-assisted forming.","machine learning,magnesium,electropulse,electrically-assisted forming",Article,"KOREAN INST METALS MATERIALS, KIM BLDG 6TH FLOOR, SEOCHO-DAERO 56 GIL 38, SEOCHO-GU, SEOUL 137-881, SOUTH KOREA","Materials Science,Metallurgy & Metallurgical Engineering",,0.592,"PULSED,ELECTRIC-CURRENT,NEURAL-NETWORK,APPROACH,DEFORMATION",KOREAN JOURNAL OF METALS AND MATERIALS,http://kjmm.org/upload/pdf/kjmm-2020-58-6-413.pdf,
76,Automated Segmentation of Left Ventricular Myocardium on Cardiac Computed Tomography Using Deep Learning,21,6,660-669,"Koo Hyun Jung,Lee June-Goo,Ko Ji Yeon,Lee Gaeun,Kang Joon-Won,Kim Young-Hak,Yang Dong Hyun","Koo HJ,Lee JG,Ko JY,Lee G,Kang JW,Kim YH,Yang DH",Yang DH,10.3348/kjr.2019.0378,University of Ulsan,"Objective: To evaluate the accuracy of a deep learning-based automated segmentation of the left ventricle (LV) myocardium using cardiac CT.
Materials and Methods: To develop a fully automated algorithm, 100 subjects with coronary artery disease were randomly selected as a development set (50 training / 20 validation / 30 internal test). An experienced cardiac radiologist generated the manual segmentation of the development set. The trained model was evaluated using 1000 validation set generated by an experienced technician. Visual assessment was performed to compare the manual and automatic segmentations. In a quantitative analysis, sensitivity and specificity were calculated according to the number of pixels where two three-dimensional masks of the manual and deep learning segmentations overlapped. Similarity indices, such as the Dice similarity coefficient (DSC), were used to evaluate the margin of each segmented masks.
Results: The sensitivity and specificity of automated segmentation for each segment (1-16 segments) were high (85.5-100.0%). The DSC was 88.3 +/- 6.2%. Among randomly selected 100 cases, all manual segmentation and deep learning masks for visual analysis were classified as very accurate to mostly accurate and there were no inaccurate cases (manual vs. deep learning: very accurate, 31 vs. 53; accurate, 64 vs. 39; mostly accurate, 15 vs. 8). The number of very accurate cases for deep learning masks was greater than that for manually segmented masks.
Conclusion: We present deep learning-based automatic segmentation of the LV myocardium and the results are comparable to manual segmentation data with high sensitivity, specificity, and high similarity scores.","Segmentation,Left ventricle,Deep learning,Machine learning,Computed tomography",Article,"KOREAN RADIOLOGICAL SOC, 121-8 YANGJAE-DONG, SEOCHO-GU, SEOUL 137-130, SOUTH KOREA","Radiology, Nuclear Medicine & Medical Imaging",,3.947,"END-SYSTOLIC,VOLUME,CT,ECHOCARDIOGRAPHY,ANGIOGRAPHY,HEART,SOFTWARE,SURVIVAL,MODEL",KOREAN JOURNAL OF RADIOLOGY,https://europepmc.org/articles/pmc7231613?pdf=render,
77,Machine learning the computational cost of quantum chemistry,1,2,,"Heinen Stefan);,Schwilk Max);,von Rudorff Guido Falk);,von Lilienfeld O. Anatole","Heinen S,Schwilk M,von Rudorff GF,von Lilienfeld OA",von Lilienfeld OA,10.1088/2632-2153/ab6ac4,University of Basel,"Computational quantum mechanics based molecular and materials design campaigns consume increasingly more high-performance computer resources, making improved job scheduling efficiency desirable in order to reduce carbon footprint or wasteful spending. We introduce quantum machine learning (QML) models of the computational cost of common quantum chemistry tasks. For 2D nonlinear toy systems, single point, geometry optimization, and transition state calculations the out of sample prediction error of QML models of wall times decays systematically with training set size. We present numerical evidence for a toy system containing two functions and three commonly used optimizer and for thousands of organic molecular systems including closed and open shell equilibrium structures, as well as transition states. Levels of electronic structure theory considered include B3LYP/def2-TZVP, MP2/6-311G(d), local CCSD(T)/VTZ-F12, CASSCF/VDZ-F12, and MRCISD+Q-F12/VDZ-F12. In comparison to conventional indiscriminate job treatment, QML based wall time predictions significantly improve job scheduling efficiency for all tasks after training on just thousands of molecules. Resulting reductions in CPU time overhead range from 10% to 90%.","high throughput computing (HTC),quantum chemistry",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Computer Science,Science & Technology - Other Topics",,,"LOCAL,COUPLED-CLUSTER,SET,MODEL,CHEMISTRY,MOLECULAR-PROPERTIES,TOTAL,ENERGIES,SPLIT-VALENCE,PERFORMANCE,EFFICIENT,ALGORITHM,SMILES",MACHINE LEARNING-SCIENCE AND TECHNOLOGY,https://doi.org/10.1088/2632-2153/ab6ac4,
78,Double-Shot Transfer Learning for Breast Cancer Classification from X-Ray Images,10,11,,"Alkhaleefah Mohammad,Ma Shang-Chih,Chang Yang-Lang,Huang Bormin,Chittem Praveen Kumar,Achhannagari Vishnu Priya","Alkhaleefah M,Ma SC,Chang YL,Huang B,Chittem PK,Achhannagari VP",Chang YL,10.3390/app10113999,National Taipei University of Technology,"Differentiation between benign and malignant breast cancer cases in X-ray images can be difficult due to their similar features. In recent studies, the transfer learning technique has been used to classify benign and malignant breast cancer by fine-tuning various pre-trained networks such as AlexNet, visual geometry group (VGG), GoogLeNet, and residual network (ResNet) on breast cancer datasets. However, these pre-trained networks have been trained on large benchmark datasets such as ImageNet, which do not contain labeled images related to breast cancers which lead to poor performance. In this research, we introduce a novel technique based on the concept of transfer learning, called double-shot transfer learning (DSTL). DSTL is used to improve the overall accuracy and performance of the pre-trained networks for breast cancer classification. DSTL updates the learnable parameters (weights and biases) of any pre-trained network by fine-tuning them on a large dataset that is similar to the target dataset. Then, the updated networks are fine-tuned with the target dataset. Moreover, the number of X-ray images is enlarged by a combination of augmentation methods including different variations of rotation, brightness, flipping, and contrast to reduce overfitting and produce robust results. The proposed approach has demonstrated a significant improvement in classification accuracy and performance of the pre-trained networks, making them more suitable for medical imaging.","breast cancer,classification,image augmentation,medical images,transfer learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/11/3999/pdf,
79,The Elephant in the Machine: Proposing a New Metric of Data Reliability and its Application to a Medical Case to Assess Classification Reliability,10,11,,"Cabitza Federico,Campagner Andrea,Albano Domenico,Aliprandi Alberto,Bruno Alberto,Chianca Vito,Corazza Angelo,Di Pietto Francesco,Gambino Angelo,Gitto Salvatore","Cabitza F,Campagner A,Albano D,Aliprandi A,Bruno A,Chianca V,Corazza A,Di Pietto F,Gambino A,Gitto S",Cabitza F,10.3390/app10114014,University of Milano-Bicocca,"In this paper, we present and discuss a novel reliability metric to quantify the extent a ground truth, generated in multi-rater settings, as a reliable basis for the training and validation of machine learning predictive models. To define this metric, three dimensions are taken into account: agreement (that is, how much a group of raters mutually agree on a single case); confidence (that is, how much a rater is certain of each rating expressed); and competence (that is, how accurate a rater is). Therefore, this metric produces a reliability score weighted for the raters' confidence and competence, but it only requires the former information to be actually collected, as the latter can be obtained by the ratings themselves, if no further information is available. We found that our proposal was both more conservative and robust to known paradoxes than other existing agreement measures, by virtue of a more articulated notion of the agreement due to chance, which was based on an empirical estimation of the reliability of the single raters involved. We discuss the above metric within a realistic annotation task that involved 13 expert radiologists in labeling the MRNet dataset. We also provide a nomogram by which to assess the actual accuracy of a classification model, given the reliability of its ground truth. In this respect, we also make the point that theoretical estimates of model performance are consistently overestimated if ground truth reliability is not properly taken into account.","inter-rater agreement,reliability,ground truth,machine learning,MRNet,knee,magnetic resonance imaging",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"INTERRATER,RELIABILITY,HIGH,AGREEMENT,LOW,KAPPA,PERFORMANCE,ERROR",APPLIED SCIENCES-BASEL,https://boa.unimib.it/bitstream/10281/292803/1/applsci-10-04014.pdf,
80,Classification of Heart Sounds Using Convolutional Neural Network,10,11,,"Li Fan,Tang Hong,Shang Shang,Mathiak Klaus,Cong Fengyu","Li F,Tang H,Shang S,Mathiak K,Cong FY",Cong FY,10.3390/app10113956,Dalian University of Technology,"Featured Application
Combining of multi-features extracted manually and convolutional neural network classifier for automatic heart sounds classification.
Abstract Heart sounds play an important role in the diagnosis of cardiac conditions. Due to the low signal-to-noise ratio (SNR), it is problematic and time-consuming for experts to discriminate different kinds of heart sounds. Thus, objective classification of heart sounds is essential. In this study, we combined a conventional feature engineering method with deep learning algorithms to automatically classify normal and abnormal heart sounds. First, 497 features were extracted from eight domains. Then, we fed these features into the designed convolutional neural network (CNN), in which the fully connected layers that are usually used before the classification layer were replaced with a global average pooling layer to obtain global information about the feature maps and avoid overfitting. Considering the class imbalance, the class weights were set in the loss function during the training process to improve the classification algorithm's performance. Stratified five-fold cross-validation was used to evaluate the performance of the proposed method. The mean accuracy, sensitivity, specificity and Matthews correlation coefficient observed on the PhysioNet/CinC Challenge 2016 dataset were 86.8%, 87%, 86.6% and 72.1% respectively. The proposed algorithm's performance achieves an appropriate trade-off between sensitivity and specificity.","automatic heart sound classification,feature engineering,convolutional neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"RECOGNITION,AMPLITUDE,ECG",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/11/3956/pdf,
81,A Machine Learning Approach to Predict an Early Biochemical Recurrence after a Radical Prostatectomy,10,11,,"Park Seongkeun,Byun Jieun,Woo Ji Young","Park S,Byun J,Woo JY",Byun J,10.3390/app10113854,Hallym University,"Background: Approximately 20-50% of prostate cancer patients experience biochemical recurrence (BCR) after radical prostatectomy (RP). Among them, cancer recurrence occurs in about 20-30%. Thus, we aim to reveal the utility of machine learning algorithms for the prediction of early BCR after RP. Methods: A total of 104 prostate cancer patients who underwent magnetic resonance imaging and RP were evaluated. Four well-known machine learning algorithms (i.e., k-nearest neighbors (KNN), multilayer perceptron (MLP), decision tree (DT), and auto-encoder) were applied to build a prediction model for early BCR using preoperative clinical and imaging and postoperative pathologic data. The sensitivity, specificity, and accuracy for detection of early BCR of each algorithm were evaluated. Area under the receiver operating characteristics (AUROC) analyses were conducted. Results: A prediction model using an auto-encoder showed the highest prediction ability of early BCR after RP using all data as input (AUC = 0.638) and only preoperative clinical and imaging data (AUC = 0.656), followed by MLP (AUC = 0.607 and 0.598), KNN (AUC = 0.596 and 0.571), and DT (AUC = 0.534 and 0.495). Conclusion: The auto-encoder-based prediction system has the potential for accurate detection of early BCR and could be useful for long-term follow-up planning in prostate cancer patients after RP.","machine learning,prostate cancer,biochemical recurrence",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"CANCER-SPECIFIC,MORTALITY,DISEASE,RECURRENCE,NOMOGRAM,BIOPSIES,SCORE,RISK,PROBABILITY,GUIDELINES,ANTIGEN,MEN",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/11/3854/pdf,
82,A Fast Self-Learning Subspace Reconstruction Method for Non-Uniformly Sampled Nuclear Magnetic Resonance Spectroscopy,10,11,,"Tu Zhangren,Liu Huiting,Zhan Jiaying,Guo Di","Tu ZR,Liu HT,Zhan JY,Guo D",Guo D,10.3390/app10113939,Xiamen University of Technology,"Multidimensional nuclear magnetic resonance (NMR) spectroscopy is one of the most crucial detection tools for molecular structure analysis and has been widely used in biomedicine and chemistry. However, the development of NMR spectroscopy is hampered by long data collection time. Non-uniform sampling empowers rapid signal acquisition by collecting a small subset of data. Since the sampling rate is lower than that of the Nyquist sampling ratio, undersampling artifacts arise in reconstructed spectra. To obtain a high-quality spectrum, it is necessary to apply reasonable prior constraints in spectrum reconstruction models. The self-learning subspace method has been shown to possess superior advantages than that of the state-of-the-art low-rank Hankel matrix method when adopting high acceleration in data sampling. However, the self-learning subspace method is time-consuming due to the singular value decomposition in iterations. In this paper, we propose a fast self-learning subspace method to enable fast and high-quality reconstructions. Aided by parallel computing, the experiment results show that the proposed method can reconstruct high-fidelity spectra but spend less than 10% of the time required by the non-parallel self-learning subspace method.","nuclear magnetic resonance spectroscopy,non-uniform sampling,self-learning subspace,matrix factorization,acceleration",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"ACCELERATED,NMR-SPECTROSCOPY,RESOLUTION",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/11/3939/pdf,
83,Blended Multi-Modal Deep ConvNet Features for Diabetic Retinopathy Severity Prediction,9,6,,"Bodapati Jyostna Devi,Naralasetti Veeranjaneyulu,Shareef Shaik Nagur,Hakak Saqib,Bilal Muhammad,Maddikunta Praveen Kumar Reddy,Jo Ohyun","Bodapati JD,Naralasetti V,Shareef SN,Hakak S,Bilal M,Maddikunta PKR,Jo O",Jo O,10.3390/electronics9060914,Chungbuk National University,"Diabetic Retinopathy (DR) is one of the major causes of visual impairment and blindness across the world. It is usually found in patients who suffer from diabetes for a long period. The major focus of this work is to derive optimal representation of retinal images that further helps to improve the performance of DR recognition models. To extract optimal representation, features extracted from multiple pre-trained ConvNet models are blended using proposed multi-modal fusion module. These final representations are used to train a Deep Neural Network (DNN) used for DR identification and severity level prediction. As each ConvNet extracts different features, fusing them using 1D pooling and cross pooling leads to better representation than using features extracted from a single ConvNet. Experimental studies on benchmark Kaggle APTOS 2019 contest dataset reveals that the model trained on proposed blended feature representations is superior to the existing methods. In addition, we notice that cross average pooling based fusion of features from Xception and VGG16 is the most appropriate for DR recognition. With the proposed model, we achieve an accuracy of 97.41%, and a kappa statistic of 94.82 for DR identification and an accuracy of 81.7% and a kappa statistic of 71.1% for severity level prediction. Another interesting observation is that DNN with dropout at input layer converges more quickly when trained using blended features, compared to the same model trained using uni-modal deep features.","diabetic retinopathy (DR),pre-trained deep ConvNet,uni-modal deep features,multi-modal deep features,transfer learning,1D pooling,cross pooling",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"AUTOMATED,DETECTION,CLASSIFICATION,ALGORITHM,MICROANEURYSMS,IDENTIFICATION",ELECTRONICS,http://arxiv.org/pdf/2006.00197,
84,Learning to See in Extremely Low-Light Environments with Small Data,9,6,,"Xu Yifeng,Wang Huigang,Cooper Garth Douglas,Rong Shaowei,Sun Weitao","Xu YF,Wang HG,Cooper GD,Rong SW,Sun WT",Wang HG,10.3390/electronics9061011,Northwestern Polytechnical University,"Recent advances in deep learning have shown exciting promise in various artificial intelligence vision tasks, such as image classification, image noise reduction, object detection, semantic segmentation, and more. The restoration of the image captured in an extremely dark environment is one of the subtasks in computer vision. Some of the latest progress in this field depends on sophisticated algorithms and massive image pairs taken in low-light and normal-light conditions. However, it is difficult to capture pictures of the same size and the same location under two different light level environments. We propose a method named NL2LL to collect the underexposure images and the corresponding normal exposure images by adjusting camera settings in the ""normal"" level of light during the daytime. The normal light of the daytime provides better conditions for taking high-quality image pairs quickly and accurately. Additionally, we describe the regularized denoising autoencoder is effective for restoring a low-light image. Due to high-quality training data, the proposed restoration algorithm achieves superior results for images taken in an extremely low-light environment (about 100 x underexposure). Our algorithm surpasses most contrasted methods solely relying on a small amount of training data, 20 image pairs. The experiment also shows the model adapts to different brightness environments.","low light,image restoration,denoise,noise reduction,deep leaning,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"IMAGE,QUALITY,ASSESSMENT",ELECTRONICS,https://www.mdpi.com/2079-9292/9/6/1011/pdf,
85,Temporal and Spatial Detection of the Onset of Local Necking and Assessment of its Growth Behavior,13,11,,"Jaremenko Christian,Affronti Emanuela,Merklein Marion,Maier Andreas","Jaremenko C,Affronti E,Merklein M,Maier A",Jaremenko C,10.3390/ma13112427,University of Erlangen Nuremberg,"This study proposes a method for the temporal and spatial determination of the onset of local necking determined by means of a Nakajima test set-up for a DC04 deep drawing and a DP800 dual-phase steel, as well as an AA6014 aluminum alloy. Furthermore, the focus lies on the observation of the progress of the necking area and its transformation throughout the remainder of the forming process. The strain behavior is learned by a machine learning approach on the basis of the images when the process is close to material failure. These learned failure characteristics are transferred to new forming sequences, so that critical areas indicating material failure can be identified at an early stage, and consequently enable the determination of the beginning of necking and the analysis of the necking area. This improves understanding of the necking behavior and facilitates the determination of the evaluation area for strain paths. The growth behavior and traceability of the necking area is objectified by the proposed weakly supervised machine learning approach, thereby rendering a heuristic-based determination unnecessary. Furthermore, a simultaneous evaluation on image and pixel scale is provided that enables a distinct selection of the failure quantile of the probabilistic forming limit curve.","pattern recognition,machine learning,deep learning,classification,segmentation,artificial intelligence,forming limit curve,sheet metal forming",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"FORMING,LIMIT,STRAINS",MATERIALS,https://europepmc.org/articles/pmc7321208?pdf=render,
86,Genomics models in radiotherapy: From mechanistic to machine learning,47,5,E203-E217,"Kang John,Coates James T.,Strawderman Robert L.,Rosenstein Barry S.,Kerns Sarah L.","Kang J,Coates JT,Strawderman RL,Rosenstein BS,Kerns SL",Kang J,10.1002/mp.13751,University of Rochester,"Machine learning (ML) provides a broad framework for addressing high-dimensional prediction problems in classification and regression. While ML is often applied for imaging problems in medical physics, there are many efforts to apply these principles to biological data toward questions of radiation biology. Here, we provide a review of radiogenomics modeling frameworks and efforts toward genomically guided radiotherapy. We first discuss medical oncology efforts to develop precision biomarkers. We next discuss similar efforts to create clinical assays for normal tissue or tumor radiosensitivity. We then discuss modeling frameworks for radiosensitivity and the evolution of ML to create predictive models for radiogenomics.","black box model,modeling,radiogenomics,radiosensitivity",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"SINGLE-NUCLEOTIDE,POLYMORPHISMS,RADIATION,PNEUMONITIS,RISK,DATA,METAANALYSIS,SHOWS,CELL,LUNG-CANCER,NORMAL-TISSUE,WIDE,ASSOCIATION,PROSTATE-CANCER,MOLECULAR,SIGNATURE,FEATURE-SELECTION,LATE,TOXICITY",MEDICAL PHYSICS,http://arxiv.org/pdf/1904.09662,
87,Machine learning techniques for biomedical image segmentation: An overview of technical aspects and introduction to state-of-art applications,47,5,E148-E167,"Seo Hyunseok,Khuzani Masoud Badiei,Vasudevan Varun,Huang Charles,Ren Hongyi,Xiao Ruoxiu,Jia Xiao,Xing Lei","Seo H,Khuzani MB,Vasudevan V,Huang C,Ren HY,Xiao RX,Jia X,Xing L",Xing L,10.1002/mp.13649,Stanford University,"In recent years, significant progress has been made in developing more accurate and efficient machine learning algorithms for segmentation of medical and natural images. In this review article, we highlight the imperative role of machine learning algorithms in enabling efficient and accurate segmentation in the field of medical imaging. We specifically focus on several key studies pertaining to the application of machine learning methods to biomedical image segmentation. We review classical machine learning algorithms such as Markov random fields, k-means clustering, random forest, etc. Although such classical learning models are often less accurate compared to the deep-learning techniques, they are often more sample efficient and have a less complex structure. We also review different deep-learning architectures, such as the artificial neural networks (ANNs), the convolutional neural networks (CNNs), and the recurrent neural networks (RNNs), and present the segmentation results attained by those learning models that were published in the past 3 yr. We highlight the successes and limitations of each machine learning paradigm. In addition, we discuss several challenges related to the training of different machine learning models, and we present some heuristics to address those challenges.","deep learning,machine learning,medical Image,overview,segmentation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"CONVOLUTIONAL,NEURAL-NETWORKS,BRAIN-TUMOR,SEGMENTATION,THE-ART,DEEP,INFORMATION,MODEL,HEAD",MEDICAL PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7338207,
88,Mining structure-property relationships in polymer nanocomposites using data driven finite element analysis and multi-task convolutional neural networks,5,5,962-975,"Wang Yixing,Zhang Min,Lin Anqi,Iyer Akshay,Prasad Aditya Shanker,Li Xiaolin,Zhang Yichi,Schadler Linda S.,Chen Wei,Brinson L. Catherine","Wang YX,Zhang M,Lin AQ,Iyer A,Prasad AS,Li XL,Zhang YC,Schadler LS,Chen W,Brinson LC",Brinson LC,10.1039/d0me00020e,Duke University,"Data-driven methods have attracted increasingly more attention in materials research since the advent of the material genome initiative. The combination of materials science with computer science, statistics, and data-driven methods aims to expediate materials research and applications and can utilize both new and archived research data. In this paper, we present a data driven and deep learning approach that builds a portion of the structure-property relationship for polymer nanocomposites. Analysis of archived experimental data motivates development of a computational model which allows demonstration of the approach and gives flexibility to sufficiently explore a wide range of structures. Taking advantage of microstructure reconstruction methods and finite element simulations, we first explore qualitative relationships between microstructure descriptors and mechanical properties, resulting in new findings regarding the interplay of interphase, volume fraction and dispersion. Then we present a novel deep learning approach that combines convolutional neural networks with multi-task learning for building quantitative correlations between microstructures and property values. The performance of the model is compared with other state-of-the-art strategies including two-point statistics and structure descriptor-based approaches. Lastly, the interpretation of the deep learning model is investigated to show that the model is able to capture physical understandings while learning.","MOLECULAR-DYNAMICS SIMULATION,HIGH-CONTRAST COMPOSITES,LINKAGES,INTERPHASE,NANOPARTICLES,MECHANISMS,MATRIX,MODEL",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Engineering,Science & Technology - Other Topics,Materials Science",,4.667,"MOLECULAR-DYNAMICS,SIMULATION,HIGH-CONTRAST,COMPOSITES,LINKAGES,INTERPHASE,NANOPARTICLES,MECHANISMS,MATRIX,MODEL",MOLECULAR SYSTEMS DESIGN & ENGINEERING,,
89,Permeable Breakwaters Performance Modeling: A Comparative Study of Machine Learning Techniques,12,11,,"Gandomi Mostafa,Pirooz Moharram Dolatshahi,Varjavand Iman,Nikoo Mohammad Reza","Gandomi M,Pirooz MD,Varjavand I,Nikoo MR",Pirooz MD,10.3390/rs12111856,University of Tehran,"The advantage of permeable breakwaters over more traditional types has attracted great interest in the behavior of these structures in the field of engineering. The main objective of this study is to apply 19 well-known machine learning regressors to derive the best model of innovative breakwater hydrodynamic behavior with reflection and transmission coefficients as the target parameters. A database of 360 laboratory tests on the low-scale breakwater is used to establish the model. The proposed models link the reflection and transmission coefficients to seven dimensionless parameters, including relative chamber width, relative rockfill height, relative chamber width in terms of wavelength, wave steepness, wave number multiplied by water depth, and relative wave height in terms of rockfill height. For the validation of the models, the cross-validation method was used for all models except the multilayer perceptron neural network (MLP) and genetic programming (GP) models. To validate the MLP and GP, the database is divided into three categories: training, validation, and testing. Furthermore, two explicit functional relationships are developed by utilizing the GP for each target. The exponential Gaussian process regression (GPR) model in predicting the reflection coefficient (R-2 = 0.95, OBJ function = 0.0273), and similarly, the exponential GPR model in predicting the transmission coefficient (R-2 = 0.98, OBJ function = 0.0267) showed the best performance and the highest correlation with the actual records and can further be used as a reference for engineers in practical work. Also, the sensitivity analysis of the proposed models determined that the relative height parameter of the rockfill material has the greatest contribution to the introduced breakwater behavior.","permeable breakwater,reflection,transmission,sensitivity analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Geology,Remote Sensing,Imaging Science & Photographic Technology",,5.353,"SCOUR,DEPTH,HYDRODYNAMIC,PERFORMANCE,WAVE,REFLECTION,NEURAL-NETWORKS,PREDICTION,CLASSIFICATION,TREE,ROWS",REMOTE SENSING,https://www.mdpi.com/2072-4292/12/11/1856/pdf,
90,A Metaheuristic Optimization Approach for Parameter Estimation in Arrhythmia Classification from Unbalanced Data,20,11,,"Carlos Carrillo-Alarcon Juan,Alberto Morales-Rosales Luis,Rodriguez-Rangel Hector,Lobato-Baez Mariana,Munoz Antonio,Algredo-Badillo Ignacio","Carrillo-Alarcon JC,Morales-Rosales LA,Rodriguez-Rangel H,Lobato-Baez M,Munoz A,Algredo-Badillo I",Algredo-Badillo I,10.3390/s20113139,"Instituto Nacional de Astrofisica, Optica y Electronica","The electrocardiogram records the heart's electrical activity and generates a significant amount of data. The analysis of these data helps us to detect diseases and disorders via heart bio-signal abnormality classification. In unbalanced-data contexts, where the classes are not equally represented, the optimization and configuration of the classification models are highly complex, reflecting on the use of computational resources. Moreover, the performance of electrocardiogram classification depends on the approach and parameter estimation to generate the model with high accuracy, sensitivity, and precision. Previous works have proposed hybrid approaches and only a few implemented parameter optimization. Instead, they generally applied an empirical tuning of parameters at a data level or an algorithm level. Hence, a scheme, including metrics of sensitivity in a higher precision and accuracy scale, deserves special attention. In this article, a metaheuristic optimization approach for parameter estimations in arrhythmia classification from unbalanced data is presented. We selected an unbalanced subset of those databases to classify eight types of arrhythmia. It is important to highlight that we combined undersampling based on the clustering method (data level) and feature selection method (algorithmic level) to tackle the unbalanced class problem. To explore parameter estimation and improve the classification for our model, we compared two metaheuristic approaches based on differential evolution and particle swarm optimization. The final results showed an accuracy of 99.95%, a F1 score of 99.88%, a sensitivity of 99.87%, a precision of 99.89%, and a specificity of 99.99%, which are high, even in the presence of unbalanced data.","electrocardiogram (ECG),signal processing,machine learning,arrhythmia,unbalanced",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"HEARTBEAT,CLASSIFICATION,ECG,RECOGNITION,SELECTION,ENSEMBLE,FEATURES",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7308921,
91,A Very High-Speed Validation Scheme Based on Template Matching for Segmented Character Expiration Codes on Beverage Cans,20,11,,"Rodriguez-Rodriguez Jose C.,de Blasio Gabriele S.,Garcia Carmelo R.,Quesada-Arencibia Alexis","Rodriguez-Rodriguez JC,de Blasio GS,Garcia CR,Quesada-Arencibia A",Quesada-Arencibia A,10.3390/s20113157,Universidad de Las Palmas de Gran Canaria,"This paper expands upon a previous publication and is the natural continuation of an earlier study which presented an industrial validator of expiration codes printed on aluminium or tin cans, called MONICOD. MONICOD is distinguished by its high operating speed, running at 200 frames per second and validating up to 35 cans per second. This paper adds further detail to this description by describing the final stage of the MONICOD industrial validator: the process of effectively validating the characters. In this process we compare the acquired shapes, segmented during the prior stages, with expected character shapes. To do this, we use a template matching scheme (here called ""morphologies"") based on bitwise operations. Two learning algorithms for building the valid morphology databases are also presented. The results of the study presented here show that in the acquisition of 9885 frames containing 465 cans to be validated, there was only one false positive (0.21% of the total). Another notable feature is that it is at least 20% faster in validation time with error rates similar to those of classifiers such as support vector machines (SVM), radial base functions (RBF), multi-layer perceptron with backpropagation (MLP) and k-nearest neighbours (KNN).","image processing,optical character recognition,OCR,pattern recognition,industrial inspection,very high-speed computing,character segmentation,tracking,template matching,supervised learning,unsupervised learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"MOMENT,GENERATING,ALGORITHM,COMPUTATION,TIME,RECOGNITION,EFFICIENT,IMAGES",SENSORS,https://accedacris.ulpgc.es/jspui/bitstream/10553/73272/1/a_very_high_speed_validation_scheme_based.pdf,
92,Automated Detection of Presymptomatic Conditions in Spinocerebellar Ataxia Type 2 Using Monte Carlo Dropout and Deep Neural Network Techniques with Electrooculogram Signals,20,11,,"Stoean Catalin,Stoean Ruxandra,Atencia Miguel,Abdar Moloud,Velazquez-Perez Luis,Khosravi Abbas,Nahavandi Saeid,Acharya U. Rajendra,Joya Gonzalo","Stoean C,Stoean R,Atencia M,Abdar M,Velazquez-Perez L,Khosravi A,Nahavandi S,Acharya UR,Joya G",Stoean R,10.3390/s20113032,"Romanian Inst Sci & Technol, Cluj Napoca 400022, Romania.","Application of deep learning (DL) to the field of healthcare is aiding clinicians to make an accurate diagnosis. DL provides reliable results for image processing and sensor interpretation problems most of the time. However, model uncertainty should also be thoroughly quantified. This paper therefore addresses the employment of Monte Carlo dropout within the DL structure to automatically discriminate presymptomatic signs of spinocerebellar ataxia type 2 in saccadic samples obtained from electrooculograms. The current work goes beyond the common incorporation of this special type of dropout into deep neural networks and uses the uncertainty derived from the validation samples to construct a decision tree at the register level of the patients. The decision tree built from the uncertainty estimates obtained a classification accuracy of 81.18% in automatically discriminating control, presymptomatic and sick classes. This paper proposes a novel method to address both uncertainty quantification and explainability to develop reliable healthcare support systems.","deep learning,medicine,sensor data,electrooculogram,uncertainty quantification,Monte Carlo dropout,decision trees",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"IDENTIFICATION,DIAGNOSIS",SENSORS,https://www.mdpi.com/1424-8220/20/11/3032/pdf,
93,MRI Segmentation and Classification of Human Brain Using Deep Learning for Diagnosis of Alzheimer's Disease: A Survey,20,11,,"Yamanakkanavar Nagaraj,Choi Jae Young,Lee Bumshik","Yamanakkanavar N,Choi JY,Lee B",Lee B,10.3390/s20113243,Chosun University,"Many neurological diseases and delineating pathological regions have been analyzed, and the anatomical structure of the brain researched with the aid of magnetic resonance imaging (MRI). It is important to identify patients with Alzheimer's disease (AD) early so that preventative measures can be taken. A detailed analysis of the tissue structures from segmented MRI leads to a more accurate classification of specific brain disorders. Several segmentation methods to diagnose AD have been proposed with varying complexity. Segmentation of the brain structure and classification of AD using deep learning approaches has gained attention as it can provide effective results over a large set of data. Hence, deep learning methods are now preferred over state-of-the-art machine learning methods. We aim to provide an outline of current deep learning-based segmentation approaches for the quantitative analysis of brain MRI for the diagnosis of AD. Here, we report how convolutional neural network architectures are used to analyze the anatomical brain structure and diagnose AD, discuss how brain MRI segmentation improves AD classification, describe the state-of-the-art approaches, and summarize their results using publicly available datasets. Finally, we provide insight into current issues and discuss possible future research directions in building a computer-aided diagnostic system for AD.","magnetic resonance imaging,Alzheimer's disease,deep learning",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"MILD,COGNITIVE,IMPAIRMENT,CONVOLUTIONAL,NEURAL-NETWORKS,VOXEL-BASED,MORPHOMETRY,HIPPOCAMPAL,ATROPHY,TUMOR,SEGMENTATION,DIFFUSION,TENSOR,TISSUE,SEGMENTATION,DEMENTIA,IMAGES,CNN",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7313699,
94,Micromagnetic materials characterization using machine learning,87,6,428-437,"Szielasko Klaus,Wolter Bernd,Tschuncky Ralf,Youssef Sargon","Szielasko K,Wolter B,Tschuncky R,Youssef S",Szielasko K,10.1515/teme-2019-0099,Fraunhofer Gesellschaft,"Micromagnetic materials characterization is a nondestructive means of predicting mechanical properties and stress of steel and iron products. The method is based on the circumstance that both mechanical and magnetic behaviour relate to microstructure over similar interaction mechanisms, which leads to characteristic correlations between mechanical and magnetic properties of ferromagnetic materials. The prediction of mechanical properties or stress from micromagnetic parameters represents an inverse problem commonly addressed by regression and classification approaches. Challenges for the industrial application of micromagnetic methods lie in the development of robust sensors, definition of significant features, and implementation of powerful machine learning algorithms for a reliable quantitative target value prediction by processing of the micromagnetic features. This contribution briefly explains the background of micromagnetics, describes the typical challenges experienced in practice and provides insight into latest progress in the application of machine learning to micromagnetic data.","Micromagnetic,materials characterization,mechanical properties,3MA,machine learning",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY",Instruments & Instrumentation,,0.416,,TM-TECHNISCHES MESSEN,,
95,The Clinical and Chest CT Features Associated With Severe and Critical COVID-19 Pneumonia,55,6,327-331,"Li Kunhua,Wu Jiong,Wu Faqi,Guo Dajing,Chen Linli,Fang Zheng,Li Chuanming","Li KH,Wu J,Wu FQ,Guo DJ,Chen LL,Fang Z,Li CM",Li CM,10.1097/RLI.0000000000000672,Chongqing Medical University,"Objective The aim of this study was to investigate the clinical and computed tomography (CT) features associated with severe and critical coronavirus disease 2019 (COVID-19) pneumonia. Materials and Methods Eighty-three patients with COVID-19 pneumonia including 25 severe/critical cases and 58 ordinary cases were enrolled. The chest CT images and clinical data of them were reviewed and compared. The risk factors associated with disease severity were analyzed. Results Compared with the ordinary patients, the severe/critical patients had older ages, higher incidence of comorbidities, cough, expectoration, chest pain, and dyspnea. The incidences of consolidation, linear opacities, crazy-paving pattern, and bronchial wall thickening in severe/critical patients were significantly higher than those of the ordinary patients. Besides, severe/critical patients showed higher incidences of lymph node enlargement, pericardial effusion, and pleural effusion than the ordinary patients. The CT scores of severe/critical patients were significantly higher than those of the ordinary patients (P< 0.001). Receiver operating characteristic curve showed that the sensitivity and specificity of CT score were 80.0% and 82.8%, respectively, for the discrimination of the 2 types. The clinical factors of age older than 50 years, comorbidities, dyspnea, chest pain, cough, expectoration, decreased lymphocytes, and increased inflammation indicators were risk factors for severe/critical COVID-19 pneumonia. Computed tomography findings of consolidation, linear opacities, crazy-paving pattern, bronchial wall thickening, high CT scores, and extrapulmonary lesions were features of severe/critical COVID-19 pneumonia. Conclusions There are significant differences in clinical symptoms, laboratory examinations, and CT manifestations between the ordinary patients and the severe/critical patients. Many factors are related to the severity of the disease, which can help clinicians to judge the severity of the patient and evaluate the prognosis.","COVID-19,SARS-CoV-2,acute respiratory disease,pneumonia,severity,risk factor",Article,"LIPPINCOTT WILLIAMS & WILKINS, TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA","Radiology, Nuclear Medicine & Medical Imaging",,5.958,,INVESTIGATIVE RADIOLOGY,https://europepmc.org/articles/pmc7147273?pdf=render,
96,A framework for the optimal integration of solar assisted district heating in different urban sized communities: A robust machine learning approach incorporating global sensitivity analysis,267,,,"Abokersh Mohamed Hany,Valles Manel,Cabeza Luisa F.,Boer Dieter","Abokersh MH,Valles M,Cabeza LF,Boer D",Boer D,10.1016/j.apenergy.2020.114903,Universitat Rovira i Virgili,"A promising pathway towards sustainable transaction to clean energy production lies in the adoption of solar assisted district heating systems (SDHS). However, SDHS technical barriers during their design and operation phases, combined with their economic limitation, promote a high variation in quantifying SDHS benefits over their lifetime. This study proposes a complete multi-objective optimization framework using a robust machine learning approach to inherent sustainability principles in the design of SDHS. Moreover, the framework investigates the uncertainty in the context of SDHS design, in which the Global Sensitivity Analysis (GSA) is combined with the heuristics optimization approach. The framework application is illustrated through a case study for the optimal integration of SHDS at different urban community sizes (10, 25, 50, and 100 buildings) located in Madrid. The results reveal a substantial improvement in economic and environmental benefits for deploying SDHS, especially with including the seasonal storage tank (SST) construction properties in the optimization problem, and it can achieve a payback period up to 13.7 years. In addition, the solar fraction of the optimized SDHS never falls below 82.1% for the investigated community sizes with an efficiency above 69.5% for the SST. Finally, the GSA indicates the SST investment cost and its relevant construction materials, are primarily responsible for the variability in the optimal system feasibility. The proposed framework can provide a good starting point to solve the enormous computational expenses drawbacks associated with the heuristics optimization approach. Furthermore, it can function as a decision support tool to fulfill the European Union energy targets regarding clean energy production.","Solar assist district heating system,Artificial Neural Network,Bayesian optimization approach,Life cycle assessment,Multi-objective optimization,Global sensitivity analysis",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Energy & Fuels,Engineering",,9.953,"THERMAL-ENERGY,STORAGE,SEASONAL,STORAGE,OPTIMAL-DESIGN,METAMODELING,TECHNIQUES,BUILDING,PERFORMANCE,OPTIMIZATION,SYSTEM,UNCERTAINTY,PLANTS,SUPPORT",APPLIED ENERGY,https://repositori.udl.cat/bitstream/10459.1/68436/1/029917.pdf,
97,Genetic programming-assisted multi-scale optimization for multi-objective dynamic performance of laminated composites: the advantage of more elementary-level analyses,32,12,7969-7993,"Kalita Kanak,Mukhopadhyay Tanmoy,Dey Partha,Haldar Salil","Kalita K,Mukhopadhyay T,Dey P,Haldar S",Mukhopadhyay T,10.1007/s00521-019-04280-z,Indian Institute of Technology System (IIT System),"High-fidelity multi-scale design optimization of many real-life applications in structural engineering still remains largely intractable due to the computationally intensive nature of numerical solvers like finite element method. Thus, in this paper, an alternate route of metamodel-based design optimization methodology is proposed in multi-scale framework based on a symbolic regression implemented using genetic programming (GP) coupled withd-optimal design. This approach drastically cuts the computational costs by replacing the finite element module with appropriately constructed robust and efficient metamodels. Resulting models are compact, have good interpretability and assume a free-form expression capable of capturing the non-linearly, complexity and vastness of the design space. Two robust nature-inspired optimization algorithms, viz. multi-objective genetic algorithm and multi-objective particle swarm optimization, are used to generate Pareto optimal solutions for several test problems with varying complexity. TOPSIS, a multi-criteria decision-making approach, is then applied to choose the best alternative among the Pareto optimal sets. Finally, the applicability of GP in efficiently tackling multi-scale optimization problems of composites is investigated, where a real-life scenario is explored by varying fractions of pertinent engineering materials to bring about property changes in the final composite structure across two different scales. The study reveals that a microscale optimization leads to better optimized solutions, demonstrating the advantage of carrying out a multi-scale optimization without any additional computational burden.","Multi-scale optimization,Genetic programming,Symbolic regression,d-Optimal design,Robust composite structures",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,,"FREE-VIBRATION,ANALYSIS,STACKING-SEQUENCE,OPTIMIZATIONS,STOCHASTIC,NATURAL,FREQUENCY,SHEAR,DEFORMATION-THEORY,RESPONSE-SURFACE,SANDWICH,PLATES,NEURAL-NETWORKS,BUCKLING,ANALYSIS,DESIGN,UNCERTAINTY",NEURAL COMPUTING & APPLICATIONS,,
98,A deep-learning-based approach for adenoid hypertrophy diagnosis,47,5,2171-2181,"Shen Yi,Li Xiaohu,Liang Xiao,Xu Hai,Li Chuanfu,Yu Yongqiang,Qiu Bensheng","Shen Y,Li XH,Liang X,Xu H,Li CF,Yu YQ,Qiu BS",Qiu BS,10.1002/mp.14063,Chinese Academy of Sciences,"Purpose Adenoid hypertrophy is a pathological hyperplasia of adenoids and may cause snoring, apnea, and impede breathing during sleep. In clinical practice, radiologists diagnose the severity of adenoid hypertrophy by measuring the ratio of adenoid width (A) to nasopharyngeal width (N) according to the lateral cephalogram, which indicates the locations of four keypoints. The entire diagnostic process is tedious and time-consuming due to the acquisition of A and N. Thus, there is an urgent need to develop computer-aided diagnostic tools for adenoid hypertrophy.
Methods In this paper, we first propose the use of deep learning to solve the problem of adenoid hypertrophy classification. Deep learning driven by big data has developed greatly in the image processing field. However, obtaining a large amount of training data is hard, making the application of deep learning to medical images more difficult. This paper proposes a keypoint localization method to incorporate more prior information to improve the performance of the model under limited data. Furthermore, we design a novel regularized term called VerticalLoss to capture the vertical relationship between keypoints to provide prior information to strengthen the network performance.
Results To evaluate the performance of our proposed method, we conducted experiments with a clinical dataset from the First Affiliated Hospital of Anhui Medical University consisting of a total of 688 patients. As our results show, we obtained a classification accuracy of 95.6%, a macro F1-score of 0.957, and an average AN ratio error of 0.026. Furthermore, we obtained a macro F1-score of 0.89, a classification accuracy of 94%, and an average AN ratio error of 0.027 while using only half of the data for training.
Conclusions The study shows that our proposed method can achieve satisfactory results in the task of adenoid hypertrophy classification. Our approach incorporates more prior information, which is especially important in the field of medical imaging, where it is difficult to obtain large amounts of training data.","adenoid hypertrophy,convolutional neural networks,keypoint localization",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,CHILDREN,MEDICAL PHYSICS,,
99,Homology-based radiomic features for prediction of the prognosis of lung cancer based on CT-based radiomics,47,5,2197-2205,"Kadoya Noriyuki,Tanaka Shohei,Kajikawa Tomohiro,Tanabe Shunpei,Abe Kota,Nakajima Yujiro,Yamamoto Takaya,Takahashi Noriyoshi,Takeda Kazuya,Dobashi Suguru","Kadoya N,Tanaka S,Kajikawa T,Tanabe S,Abe K,Nakajima Y,Yamamoto T,Takahashi N,Takeda K,Dobashi S",Kadoya N,10.1002/mp.14104,Tohoku University,"Purpose Radiomics is a new technique that enables noninvasive prognostic prediction by extracting features from medical images. Homology is a concept used in many branches of algebra and topology that can quantify the contact degree. In the present study, we developed homology-based radiomic features to predict the prognosis of non-small-cell lung cancer (NSCLC) patients and then evaluated the accuracy of this prediction method.
Methods Four datasets were used: two to provide training and test data and two for the selection of robust radiomic features. All the datasets were downloaded from The Cancer Imaging Archive (TCIA). In two-dimensional cases, the Betti numbers consist of two values: b(0) (zero-dimensional Betti number), which is the number of isolated components, and b(1) (one-dimensional Betti number), which is the number of one-dimensional or ""circular"" holes. For homology-based evaluation, computed tomography (CT) images must be converted to binarized images in which each pixel has two possible values: 0 or 1. All CT slices of the gross tumor volume were used for calculating the homology histogram. First, by changing the threshold of the CT value (range: -150 to 300 HU) for all its slices, we developed homology-based histograms for b(0), b(1), and b(1)/b(0) using binarized images. All histograms were then summed, and the summed histogram was normalized by the number of slices. 144 homology-based radiomic features were defined from the histogram. To compare the standard radiomic features, 107 radiomic features were calculated using the standard radiomics technique.
To clarify the prognostic power, the relationship between the values of the homology-based radiomic features and overall survival was evaluated using LASSO Cox regression model and the Kaplan-Meier method. The retained features with nonzero coefficients calculated by the LASSO Cox regression model were used for fitting the regression model. Moreover, these features were then integrated into a radiomics signature. An individualized rad score was calculated from a linear combination of the selected features, which were weighted by their respective coefficients.
Results When the patients in the training and test datasets were stratified into high-risk and low-risk groups according to the rad scores, the overall survival of the groups was significantly different. The C-index values for the homology-based features (rad score), standard features (rad score), and tumor size were 0.625, 0.603, and 0.607, respectively, for the training datasets and 0.689, 0.668, and 0.667 for the test datasets. This result showed that homology-based radiomic features had slightly higher prediction power than the standard radiomic features.
Conclusions Prediction performance using homology-based radiomic features had a comparable or slightly higher prediction power than standard radiomic features. These findings suggest that homology-based radiomic features may have great potential for improving the prognostic prediction accuracy of CT-based radiomics. In this result, it is noteworthy that there are some limitations.","CT image,lung cancer,machine learning,radiomics,survival",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,,"INFORMATION,SURVIVAL",MEDICAL PHYSICS,,
100,Machine and deep learning methods for radiomics,47,5,E185-E202,"Avanzo Michele,Wei Lise,Stancanello Joseph,Vallieres Martin,Rao Arvind,Morin Olivier,Mattonen Sarah A.,El Naqa Issam","Avanzo M,Wei LS,Stancanello J,Vallieres M,Rao A,Morin O,Mattonen SA,El Naqa I",Avanzo M,10.1002/mp.13678,"IRCCS, Dept Med Phys, Ctr Rifrrimento Oncol Aviano CRO, I-33081 Aviano, PN, Italy.","Radiomics is an emerging area in quantitative image analysis that aims to relate large-scale extracted imaging information to clinical and biological endpoints. The development of quantitative imaging methods along with machine learning has enabled the opportunity to move data science research towards translation for more personalized cancer treatments. Accumulating evidence has indeed demonstrated that noninvasive advanced imaging analytics, that is, radiomics, can reveal key components of tumor phenotype for multiple three-dimensional lesions at multiple time points over and beyond the course of treatment. These developments in the use of CT, PET, US, and MR imaging could augment patient stratification and prognostication buttressing emerging targeted therapeutic approaches. In recent years, deep learning architectures have demonstrated their tremendous potential for image segmentation, reconstruction, recognition, and classification. Many powerful open-source and commercial platforms are currently available to embark in new research areas of radiomics. Quantitative imaging research, however, is complex and key statistical principles should be followed to realize its full potential. The field of radiomics, in particular, requires a renewed focus on optimal study design/reporting practices and standardization of image acquisition, feature calculation, and rigorous statistical analysis for the field to move forward. In this article, the role of machine and deep learning as a major computational vehicle for advanced model building of radiomics-based signatures or classifiers, and diverse clinical applications, working principles, research opportunities, and available computational platforms for radiomics will be reviewed with examples drawn primarily from oncology. We also address issues related to common applications in medical physics, such as standardization, feature extraction, model building, and validation.","deep learning,machine learning,quantitative image analysis,radiomics",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"CELL,LUNG-CANCER,FDG-PET,RADIOMICS,TEXTURAL,FEATURES,RADIATION-THERAPY,BREAST-CANCER,SURVIVAL,ANALYSIS,NEURAL-NETWORKS,CT,IMAGES,PREDICTION",MEDICAL PHYSICS,http://deepblue.lib.umich.edu/bitstream/2027.42/155519/2/mp13678.pdf,
