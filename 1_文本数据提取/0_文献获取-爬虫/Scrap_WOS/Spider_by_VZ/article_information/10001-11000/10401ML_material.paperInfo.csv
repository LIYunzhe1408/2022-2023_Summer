,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Learning graph in graph convolutional neural networks for robust seizure prediction,17,3,,"Lian Qi,Qi Yu,Pan Gang,Wang Yueming","Lian Q,Qi Y,Pan G,Wang YM",Wang YM,10.1088/1741-2552/ab909d,Zhejiang University,"Objective. Brain-computer interface (BCI) has demonstrated its effectiveness in epilepsy treatment and control. In a BCI-aided epilepsy treatment system, therapic electrical stimulus is delivered in response to the prediction of upcoming seizure onsets, therefore timely and accurate seizure prediction algorithm plays an important role. However, unlike typical signatures such as slow or sharp waves in ictal periods, the signal patterns in preictal periods are usually subtle, and highly individual-dependent. How to extract effective and robust preictal features is still a challenging problem.Approach. Most recently, graph convolutional neural network (GCNN) has demonstrated the strength in the electroencephalogram (EEG) and intracranial electroencephalogram (iEEG) signal modeling, due to its advantages in describing complex relationships among different EEG/iEEG regions. However, current GCNN models are not suitable for seizure prediction. The effectiveness of GCNNs highly relies on prior graphs that describe the underlying relationships in EEG regions. However, due to the complex mechanism of seizure evolution, the underlying relationship in the preictal period can be diverse in different patients, making it almost impossible to build a proper prior graph in general. To deal with this problem, we propose a novel approach to automatically learn a patient-specific graph in a data-driven way, which is called the joint graph structure and representation learning network (JGRN). JGRN constructs a global-local graph convolutional neural network which jointly learns the graph structures and connection weights in a task-related learning process in iEEG signals, thus the learned graph and feature representations can be optimized toward the objective of seizure prediction.Main results. Experimental results show that our JGRN outperforms CNN and GCNN models remarkably, and the improvement is more obvious when preictal features are subtle.Significance. The proposed approach promises to achieve robust seizure prediction performance and to have the potential to be extended to general problems in brain-computer interfaces.","brain computer interface,seizure prediction,graph neural network,deep learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"PHASE,SYNCHRONIZATION,CORTICAL,STIMULATION,EPILEPTIC,SEIZURES,EEG,SIGNALS,SYSTEM",JOURNAL OF NEURAL ENGINEERING,,
2,Estimation of phase in EEG rhythms for real-time applications,17,3,,"McIntosh J. R.,Sajda P.","McIntosh JR,Sajda P",McIntosh JR,10.1088/1741-2552/ab8683,Columbia University,"Objective.Estimating the ongoing phase of oscillations in electroencephalography (EEG) recordings is an important aspect of understanding brain function, as well as for the development of phase-dependent closed-loop real-time systems that deliver stimuli. Such stimuli may take the form of direct brain stimulation (for example transcranial magnetic stimulation), or sensory stimuli (for example presentation of an auditory stimulus). We identify two linked problems related to estimating the phase of EEG rhythms with a specific focus on the alpha-band: 1) when the signal after a specific stimulus is unknown (real-time case), or 2) when it is corrupted by the presence of the stimulus itself (offline analysis). We propose methods to estimate the phase at the presentation time of these stimuli.Approach.Machine learning methods are used to learn the causal mapping from an unprocessed EEG recording to a phase estimate generated with a non-causal signal processing chain. This mapping is then used to predict the phase causally where non-causal methods are inappropriate.Main results.We demonstrate the ability of these machine learning methods to estimate instantaneous phase from an EEG signal subjected to very minor pre-processing with higher accuracy than commonly used signal-processing methods.Significance.Neural oscillations have been implicated in a wide variety of sensory, cognitive and motor functions. The instantaneous phase of these rhythms may reflect specific processes of computation which can be acted upon if they can be estimated with sufficient accuracy. Such brain-state dependent paradigms are of increasing medical and scientific interest.","electroencephalography (EEG),real-time,closed-loop,phase estimation,alpha-rhythm,causal filtering",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"TRANSCRANIAL,BRAIN-STIMULATION,OSCILLATIONS,EXCITABILITY,STATES,ERP",JOURNAL OF NEURAL ENGINEERING,http://arxiv.org/pdf/1910.08784,
3,Auditory attention tracking states in a cocktail party environment can be decoded by deep convolutional neural networks,17,3,,"Tian Yin,Ma Liang","Tian Y,Ma L",Tian Y,10.1088/1741-2552/ab92b2,Chongqing University of Posts & Telecommunications,"Objective.A deep convolutional neural network (CNN) is a method for deep learning (DL). It has a powerful ability to automatically extract features and is widely used in classification tasks with scalp electroencephalogram (EEG) signals. However, the small number of samples and low signal-to-noise ratio involved in scalp EEG with low spatial resolution constitute a limitation that might restrict potential brain-computer interface (BCI) applications that are based on the CNN model. In the present study, a novel CNN model with source-spatial feature images (SSFIs) as the input is proposed to decode auditory attention tracking states in a cocktail party environment.Approach.We first extract SSFIs using rhythm entropy and weighted minimum norm estimation. Next, we develop a CNN model with three convolutional layers. Furthermore, we estimate the performance of the proposed model via generalized performance, alternative models that deleted or replaced a model's component, and loss curves. Finally, we use a deep transfer model with fine-tuning for a low (poor) behavioral performance group (L-group).Main results.Based on cortical activity reconstructions from the scalp EEGs, the classification accuracy (CA) of the proposed model is 80.4% (chance level: 52.5%), which is superior to that achieved by scalp EEG. Additionally, the performance of the proposed model is more stable when compared to alternative models that delete or replace specific model components. The proposed model identifies the difference between two auditory attention tracking states (successful versus unsuccessful) at an early stage with a short time window (250 ms after target offset). Furthermore, we propose a deep transfer learning model to improve the classification for the L-group. With this model, the CA of the L-group significantly increase by 5.3%.Significance.Our proposed model improves the performance of a decoder for auditory attention tracking, which could be suitable for relieving the difficulty with the attentional modulation of individual's neural responses. It provides a novel communication channel with auditory cognitive BCI for patients with attention and hearing impairment.","auditory attention tracking,electroencephalogram (EEG),convolutional neural network (CNN),brain-computer interface (BCI),deep learning (DL)",Article,"IOP Publishing Ltd, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"ALPHA,OSCILLATIONS,BAND,OSCILLATIONS,EEG,SPEECH,BETA,FEEDFORWARD,FEEDBACK,CORTEX,TIME",JOURNAL OF NEURAL ENGINEERING,,
4,Machine learning-based identification of radiofrequency electromagnetic radiation (RF-EMR) effect on brain morphology: a preliminary study,58,8,1751-1765,"Maurya Ritesh,Singh Neha,Jindal Tanu,Pathak Vinay Kumar,Dutta Malay Kishore","Maurya R,Singh N,Jindal T,Pathak VK,Dutta MK",Dutta MK,10.1007/s11517-020-02198-6,"Dr APJ Abdul Kalam Tech Univ, Ctr Adv Studies, New Campus, Lucknow 226031, Uttar Pradesh, India.","The brain of a human and other organisms is affected by the electromagnetic field (EMF) radiations, emanating from the cell phones and mobile towers. Prolonged exposure to EMF radiations may cause neurological changes in the brain, which in turn may bring chemical as well as morphological changes in the brain. Conventionally, the identification of EMF radiation effect on the brain is performed using cellular-level analysis. In the present work, an automatic image processing-based approach is used where geometric features extracted from the segmented brain region has been analyzed for identifying the effect of EMF radiation on the morphology of a brain, using drosophila as a specimen. Genetic algorithm-based evolutionary feature selection algorithm has been used to select an optimal set of geometrical features, which, when fed to the machine learning classifiers, result in their optimal performance. The best classification accuracy has been obtained with the neural network with an optimally selected subset of geometrical features. A statistical test has also been performed to prove that the increase in the performance of classifier post-feature selection is statistically significant. This machine learning-based study indicates that there exists discrimination between the microscopic brain images of the EMF-exposed drosophila and non-exposed drosophila.","Drosophila melanogaster,Brain morphology,Radiofrequency electromagnetic radiation (RF-EMR),Center-initialized K-means algorithm,Geometrical features,Genetic algorithm,Classifier",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"PRENATAL,EXPOSURE,SPATIAL,MEMORY,DENTATE,GYRUS,MICROWAVE,CELLS,FIELD,ALGORITHM,BEHAVIOR,SYSTEM,TUMORS",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
5,Classification of cerebral microbleeds based on fully-optimized convolutional neural network,79,21-22,15151-15169,"Hong Jin,Wang Shui-Hua,Cheng Hong,Liu Jie","Hong J,Wang SH,Cheng H,Liu J",Liu J,10.1007/s11042-018-6862-z,Sun Yat Sen University,"Cerebral microbleeds are important biomarkers of many cerebrovascular diseases and cognitive dysfunctions. Their distribution patterns can indicate some underlying aetiologies. Hitherto, few researches tried to detect cerebral microbleeds accurately and automatically. Some improvements have been achieved via traditional machine learning methods. In this paper, we proposed a method based on convolutional neural network (CNN) for further improving the performance. Firstly, sliding neighborhood processing method was applied to generate the input and target datasets based on 10 3D brain images of cerebral autosomal-dominant arteriopathy with subcortical infarcts and Leukoencephalopathy scanned by susceptibility-weighted imaging (SWI). Then, CNN was used to classify the cerebral microbleeds. To exert the full-power of convolutional neural network, almost all hyperparameters of CNN structure that could affect the performance were tested, such as the number of layers, type of activation function, pooling method, and filter size. A fully-optimized convolutional neural network structure for cerebral microbleeds classification was obtained. It performed better than four existed state-of-the-art approaches with a sensitivity of 99.74%, a specificity of 96.89% and an accuracy of 98.32%.","Cerebral microbleeds,Sliding neighborhood processing,Convolutional neural network,Fully-optimized structure",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"COMPUTER-AIDED,DETECTION,IMAGE",MULTIMEDIA TOOLS AND APPLICATIONS,,
6,Automated approaches for ROIs extraction in medical thermography: a review and future directions,79,21-22,15273-15296,"Singh Jaspreet,Arora Ajat Shatru","Singh J,Arora AS",Singh J,10.1007/s11042-018-7113-z,Sant Longowal Institute of Engineering & Technology (SLIET),"Historically, the skin temperature has been used as a functional indicator of the processes undergoing inside the body, where the anomalous change in temperature gives indication of illness. Infrared thermography (IRT) is a non-invasive approach which radiometrically measures the temperature distribution on the object's surface based on emanating IR radiation. In medical field, IRT has been used to diagnose the various problems associated with superficial body parts since 1960s. The clinical abnormalities can be diagnosed by visual and subjective analysis of the thermograms, but human based diagnoses are likely to be influenced by narcissus effect, negligence, visual exhaustion and mental workload. Apart, the deep and objective diagnostic information, like severity and type of a disease can only be obtained by statistically analyse the region of interest (ROI). So, the segmentation of ROI has often been an initial step in medical diagnosis, where the automated approaches lead to fast and highly reproducible analysis. Recent advancement in deep learning opens a new way for effective computer-aided medical diagnosis, several studies have proposed deep learning based automatic segmentation and data classification. This review focuses on the wide range of image processing techniques adopted for automatic segmentation of various clinically significant ROIs, like breast, face, foot, hand etc. In addition, the present efforts are targeted on the selection of characteristic points for an effective automatic segmentation and identification of new areas to carry out the further research. Besides, the basics of medical IRT, need of automatic segmentation and factors which hinder the automatic segmentation in IRT are also discussed.","Infrared thermography,Computer-aided medical diagnosis,Deep learning,Automatic segmentation,Performance validation",Review,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"BREAST-CANCER,DETECTION,THERMAL,IMAGE-ANALYSIS,INFRARED,THERMOGRAPHY,CHARACTERISTIC,AREAS,ASYMMETRY,ANALYSIS,SEGMENTATION,TEMPERATURE,REGIONS,KNEE,CRYOTHERAPY",MULTIMEDIA TOOLS AND APPLICATIONS,,
7,Deep extreme learning machine with leaky rectified linear unit for multiclass classification of pathological brain images,79,21-22,15381-15396,"Nayak Deepak Ranjan,Das Dibyasundar,Dash Ratnakar,Majhi Snehashis,Majhi Banshidhar","Nayak DR,Das D,Dash R,Majhi S,Majhi B",Nayak DR,10.1007/s11042-019-7233-0,National Institute of Technology (NIT System),"Automatic binary classification of brain magnetic resonance (MR) images has made remarkable progress in the past decade. In comparison, a few pieces of work has been reported on multiclass classification of brain MR images. However, there exist enough scopes for improved automation and accuracy. Most of the existing schemes follow the multi-stage pipeline structure of conventional machine learning framework, where the features are designed manually or hand-crafted. In recent years, deep learning models have attracted great interest from researchers for analyzing medical images that eliminate the traditional steps of machine learning. In this paper, we present an automated method based on deep extreme learning machine (ELM) also termed as multilayer ELM (ML-ELM) for multiclass classification of the pathological brain. ML-ELM is a multilayer architecture stacked with ELM based autoencoders. The effectiveness of leaky rectified linear unit (LReLU) activation function is investigated with ML-ELM. Extensive simulations on a multiclass brain MR image dataset indicate that the ML-ELM with LReLU activation (ML-ELM+LReLU) achieves higher performance with faster training speed compared to its counterparts as well as state-of-the-art schemes. The basic purpose of employing ML-ELM+LReLU algorithm is to eliminate the need for hand-crafted feature extraction and to develop a more stable and generalized system for multiclass brain MR image classification.","Deep learning,Pathological brain,Magnetic resonance imaging,Leaky rectified linear unit,Extreme learning machine",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"SUPPORT,VECTOR,MACHINE,DIABETIC-RETINOPATHY,WAVELET,TRANSFORM,DIAGNOSIS,ADABOOST,ENTROPY,NETWORK",MULTIMEDIA TOOLS AND APPLICATIONS,,
8,Deep learning based diagnosis of Parkinson's disease using convolutional neural network,79,21-22,15467-15479,"Sivaranjini S.,Sujatha C. M.","Sivaranjini S,Sujatha CM",Sivaranjini S,10.1007/s11042-019-7469-8,Anna University,"Parkinson's disease is the second most common degenerative disease caused by loss of dopamine producing neurons. The substantia nigra region is deprived of its neuronal functions causing striatal dopamine deficiency which remains as hallmark in Parkinson's disease. Clinical diagnosis reveals a range of motor to non motor symptoms in these patients. Magnetic Resonance (MR) Imaging is able to capture the structural changes in the brain due to dopamine deficiency in Parkinson's disease subjects. In this work, an attempt has been made to classify the MR images of healthy control and Parkinson's disease subjects using deep learning neural network. The Convolutional Neural Network architecture AlexNet is used to refine the diagnosis of Parkinson's disease. The MR images are trained by the transfer learned network and tested to give the accuracy measures. An accuracy of 88.9% is achieved with the proposed system. Deep learning models are able to help the clinicians in the diagnosis of Parkinson's disease and yield an objective and better patient group classification in the near future.","Parkinson's disease,MRI,Deep learning,Convolutional neural networks,AlexNet",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"MRI,SEGMENTATION,PROGRESSION,ATROPHY",MULTIMEDIA TOOLS AND APPLICATIONS,,
9,Automated detection of Glaucoma using deep learning convolution network (G-net),79,21-22,15531-15553,"Juneja Mamta,Singh Shaswat,Agarwal Naman,Bali Shivank,Gupta Shubham,Thakur Niharika,Jindal Prashant","Juneja M,Singh S,Agarwal N,Bali S,Gupta S,Thakur N,Jindal P",Jindal P,10.1007/s11042-019-7460-4,Panjab University,"Glaucoma is an ocular disease that is the leading cause of irreversible blindness due to an increased Intraocular pressure resulting in damage to the optic nerve of eye. A common method for diagnosing glaucoma progression is through examination of dilated pupil in the eye by expert ophthalmologist. But this approach is laborious and consumes a large amount of time, thus the issue can be resolved using automation by using the concept of machine learning. Convolution neural networks (CNN's) are well suited to resolve this class of problems as they can infer hierarchical information from the image which helps them to distinguish between glaucomic and non-glaucomic image patterns for diagnostic decisions. This paper presents an Artificially Intelligent glaucoma expert system based on segmentation of optic disc and optic cup. A Deep Learning architecture is developed with CNN working at its core for automating the detection of glaucoma. The proposed system uses two neural networks working in conjunction to segment optic cup and disc. The model was tested on 50 fundus images and achieved an accuracy of 95.8% for disc and 93% for cup segmentation.","Glaucoma detection,Optic disc,Optic cup,Retinal fundus image,Neural network,Image segmentation",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"OPTIC,CUP,SEGMENTATION,FUNDUS,IMAGES,DISC,DIAGNOSIS",MULTIMEDIA TOOLS AND APPLICATIONS,,
10,Detection of breast cancer via deep convolution neural networks using MRI images,79,21-22,15555-15573,"Yurttakal Ahmet Hasim,Erbay Hasan,Ikizceli Turkan,Karacavus Seyhan","Yurttakal AH,Erbay H,Ikizceli T,Karacavus S",Erbay H,10.1007/s11042-019-7479-6,Kirikkale University,"Breast cancer is the type of cancer that develops from cells in the breast tissue. It is the leading cancer in women. Early detection of the breast cancer tumor is crucial in the treatment process. Mammography is a valuable tool for identifying breast cancer in the early phase before physical symptoms develop. To reduce false-negative diagnosis in mammography, a biopsy is recommended for lesions with greater than a 2% chance of having suspected malignant tumors and, among them, less than 30 percent are found to have malignancy. To decrease unnecessary biopsies, recently, Magnetic Resonance Imaging (MRI) has also been used to diagnose breast cancer. MRI is the highly recommended test for detecting and monitoring breast cancer tumors and interpreting lesioned regions since it has an excellent capability for soft tissue imaging. However, it requires an experienced radiologist and time-consuming process. On the other hand, convolutional neural networks (CNNs) have demonstrated better performance in image classification compared to feature-based methods and show promising performance in medical imaging. Herein, CNN was employed to characterize lesions as malignant or benign tumors using MRI images. Using only pixel information, a multi-layer CNN architecture with online data augmentation was designed. Later, the CNN architecture was trained and tested. The accuracy of the network is 98.33% and the error rate 0.0167. The sensitivity of the network is 1.0 whereas specificity is 0.9688. The precision is 0.9655.","Breast cancer,Convolutional neural network,Classification",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"COMPUTER-AIDED,DIAGNOSIS,MAGNETIC-RESONANCE,CLASSIFICATION,SEGMENTATION,GUIDELINES,ACCURACY,LESIONS,BENIGN,CNN",MULTIMEDIA TOOLS AND APPLICATIONS,,
11,An improved computer based diagnosis system for early detection of abnormal lesions in the brain tissues with using magnetic resonance and computerized tomography images,79,21-22,15613-15634,"Ural Berkan,Ozisik Pinar,Hardalac Firat","Ural B,Ozisik P,Hardalac F",Ural B,10.1007/s11042-019-07823-7,Gazi University,"Detection of masses can be a challenging task for radiologists and physicians. Manual tumor diagnosis in the brain is sometimes a time consuming process and can be insufficient for fast and accurate detection and interpretation. This study introduces an improved interface-supported early diagnosis system to increase the speed and accuracy for supporting the traditional methods. The first stage in the system involves collecting information from the brain tissue, and assessing whether it is normal or abnormal through the processing of Magnetic Resonance Imaging (MRI) and Computerized Tomography (CT) images. The next stage involves gathering results from the image(s) after the single/multiple and volumetric and multiscale image analysis. The other stage involves Feature Extraction for some cases and making an interpretation about the abnormal Region of Interest (ROI) area via Deep Learning and conventional Artificial Intelligence methods is the last stage. The output of the system is mainly the name of the mass type which was introduced to the network. The results were obtained for totally 300 images for High-Grade Glioma (HGG), Low-Grade Glioma (LGG), Glioblastoma (GBM), Meningioma as well as Ischemic and Hemorrhagic stroke. For the cases, the DICE score was obtained as 0.927 and the normal/abnormal differentiation of the brain tissues was also achieved successfully. Finally, this system can give a chance to the doctors for supporting the results, speeding up the diagnosis process and also decreasing the rate of possible misdiagnosis.","Computer-aided medical diagnosis systems,Abnormality detection and localization,Classification of brain masses,Deep learning,Artificial intelligence",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"INTRACEREBRAL,HEMORRHAGE,SEGMENTATION,CHEMOTHERAPY,VALIDITY,CRITERIA,MRI",MULTIMEDIA TOOLS AND APPLICATIONS,,
12,Deep Learning and Adaptive Graph-Based Growing Contours for Agricultural Field Extraction,12,12,,"Wagner Matthias P.,Oppelt Natascha","Wagner MP,Oppelt N",Wagner MP,10.3390/rs12121990,University of Kiel,"Field mapping and information on agricultural landscapes is of increasing importance for many applications. Monitoring schemes and national cadasters provide a rich source of information but their maintenance and regular updating is costly and labor-intensive. Automatized mapping of fields based on remote sensing imagery may aid in this task and allow for a faster and more regular observation. Although remote sensing has seen extensive use in agricultural research topics, such as plant health monitoring, crop type classification, yield prediction, and irrigation, field delineation and extraction has seen comparatively little research interest. In this study, we present a field boundary detection technique based on deep learning and a variety of image features, and combine it with the graph-based growing contours (GGC) method to extract agricultural fields in a study area in northern Germany. The boundary detection step only requires red, green, and blue (RGB) data and is therefore largely independent of the sensor used. We compare different image features based on color and luminosity information and evaluate their usefulness for the task of field boundary detection. A model based on texture metrics, gradient information, Hessian matrix eigenvalues, and local statistics showed good results with accuracies up to 88.2%, an area under the ROC curve (AUC) of up to 0.94, and F(1)score of up to 0.88. The exclusive use of these universal image features may also facilitate transferability to other regions. We further present modifications to the GGC method intended to aid in upscaling of the method through process acceleration with a minimal effect on results. We combined the boundary detection results with the GGC method for field polygon extraction. Results were promising, with the new GGC version performing similarly or better than the original version while experiencing an acceleration of 1.3x to 2.3x on different subsets and input complexities. Further research may explore other applications of the GGC method outside agricultural remote sensing and field extraction.","field extraction,field boundary detection,deep learning,multilayer perceptron,active contours,growing snakes,graph-based growing contours",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Geology,Remote Sensing,Imaging Science & Photographic Technology",,5.353,"CLASSIFICATION,DELINEATION,IMAGERY,SEGMENTATION,BIOMASS,SNAKES,YIELD",REMOTE SENSING,https://macau.uni-kiel.de/servlets/MCRFileNodeServlet/macau_derivate_00001695/remotesensing-12-01990.pdf,
13,Vibrational Spectroscopy of Peritoneal Dialysis Effluent for Rapid Assessment of Patient Characteristics,10,6,,"Grunert Tom,Herzog Rebecca,Wiesenhofer Florian M.,Vychytil Andreas,Ehling-Schulz Monika,Kratochwill Klaus","Grunert T,Herzog R,Wiesenhofer FM,Vychytil A,Ehling-Schulz M,Kratochwill K",Grunert T,10.3390/biom10060965,University of Veterinary Medicine Vienna,"Peritoneal dialysis (PD) offers specific advantages over hemodialysis, enabling increased autonomy of patients with end-stage renal disease, but PD-related complications need to be detected in a timely manner. Fourier transform infrared (FTIR) spectroscopy could provide rapid and essential insights into the patients' risk profiles via molecular fingerprinting of PD effluent, an abundant waste material that is rich in biological information. In this study, we measured FTIR spectroscopic profiles in PD effluent from patients taking part in a randomized controlled trial of alanyl-glutamine addition to the PD-fluid. Principal component analysis of FTIR spectra enabled us to differentiate between effluent samples from patients immediately after completion of instillation of the PD-fluid into the patients' cavity and 4 h later as well as between patients receiving PD-fluid supplemented with 8 mM alanyl-glutamine compared with control. Moreover, feasibility of FTIR spectroscopy coupled to supervised classification algorithms to predict patient-, PD-, as well as immune-associated parameters were investigated. PD modality (manual continuous ambulatory PD (CAPD) vs. cycler-assisted automated PD (APD)), residual urine output, ultrafiltration, transport parameters, and cytokine concentrations showed high predictive potential. This study provides proof-of-principle that molecular signatures determined by FTIR spectroscopy of PD effluent, combined with machine learning, are suitable for cost-effective, high-throughput diagnostic purposes in PD.","peritoneal dialysis,peritoneum,vibrational spectroscopy,FTIR,molecular signatures,peritonitis,metabolites,machine learning,photonic-based diagnostics",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Biochemistry & Molecular Biology,,5.362,"INFRARED-SPECTROSCOPY,CLASSIFICATION,MACHINE,GLUCOSE,PLASMA,UREA",BIOMOLECULES,https://europepmc.org/articles/pmc7357123?pdf=render,
14,Comparative Analysis of Rhino-Cytological Specimens with Image Analysis and Deep Learning Techniques,9,6,,"Dimauro Giovanni,Bevilacqua Vitoantonio,Fina Pio Raffaele,Buongiorno Domenico,Brunetti Antonio,Latrofa Sergio,Cassano Michele,Gelardi Matteo","Dimauro G,Bevilacqua V,Fina PR,Buongiorno D,Brunetti A,Latrofa S,Cassano M,Gelardi M",Dimauro G,10.3390/electronics9060952,Universita degli Studi di Bari Aldo Moro,"Cytological study of the nasal mucosa (also known as rhino-cytology) represents an important diagnostic aid that allows highlighting of the presence of some types of rhinitis through the analysis of cellular features visible under a microscope. Nowadays, the automated detection and classification of cells benefit from the capacity of deep learning techniques in processing digital images of the cytological preparation. Even though the results of such automatic systems need to be validated by a specialized rhino-cytologist, this technology represents a valid support that aims at increasing the accuracy of the analysis while reducing the required time and effort. The quality of the rhino-cytological preparation, which is clearly important for the microscope observation phase, is also fundamental for the automatic classification process. In fact, the slide-preparing technique turns out to be a crucial factor among the multiple ones that may modify the morphological and chromatic characteristics of the cells. This paper aims to investigate the possible differences between direct smear (SM) and cytological centrifugation (CYT) slide-preparation techniques, in order to preserve image quality during the observation and cell classification phases in rhino-cytology. Firstly, a comparative study based on image analysis techniques has been put forward. The extraction of densitometric and morphometric features has made it possible to quantify and describe the spatial distribution of the cells in the field images observed under the microscope. Statistical analysis of the distribution of these features has been used to evaluate the degree of similarity between images acquired from SM and CYT slides. The results prove an important difference in the observation process of the cells prepared with the above-mentioned techniques, with reference to cell density and spatial distribution: the analysis of CYT slides has been more difficult than of the SM ones due to the spatial distribution of the cells, which results in a lower cell density than the SM slides. As a marginal part of this study, a performance assessment of the computer-aided diagnosis (CAD) system called Rhino-cyt has also been carried out on both groups of image slide types.","nasal cytology,automatic cell recognition,rhinology,image analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"COMPUTER-AIDED,DIAGNOSIS",ELECTRONICS,https://doi.org/10.3390/electronics9060952,
15,Identification of Epileptic EEG Signals Using Convolutional Neural Networks,10,12,,"Abiyev Rahib,Arslan Murat,Idoko John Bush,Sekeroglu Boran,Ilhan Ahmet","Abiyev R,Arslan M,Idoko JB,Sekeroglu B,Ilhan A",Abiyev R,10.3390/app10124089,Near East University,"Epilepsy is one of the chronic neurological disorders that is characterized by a sudden burst of excess electricity in the brain. This abnormality appears as a seizure, the detection of which is an important research topic. An important tool used to study brain activity features, neurological disorders and particularly epileptic seizures, is known as electroencephalography (EEG). The visual inspection of epileptic abnormalities in EEG signals by neurologists is time-consuming. Different scientific approaches have been used to accurately detect epileptic seizures from EEG signals, and most of those approaches have obtained good performance. In this study, deep learning based on convolutional neural networks (CNN) was considered to increase the performance of the identification system of epileptic seizures. We applied a cross-validation technique in the design phase of the system. For efficiency, comparative results between other machine-learning approaches and deep CNNs have been obtained. The experiments were performed using standard datasets. The results obtained indicate the efficiency of using CNN in the detection of epilepsy.","epilepsy,deep learning,convolutional neural networks,electroencephalography",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"SEIZURE,PREDICTION,COMPONENT,ANALYSIS,CLASSIFICATION,MACHINE,METHODOLOGY,SYSTEM,LONG",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/12/4089/pdf,
16,Hybrid Scheme for Automated Classification of Pulmonary Nodules Using PET/CT Images and Patient Information,10,12,,"Yamada Ayumi,Teramoto Atsushi,Hoshi Masato,Toyama Hiroshi,Imaizumi Kazuyoshi,Saito Kuniaki,Fujita Hiroshi","Yamada A,Teramoto A,Hoshi M,Toyama H,Imaizumi K,Saito K,Fujita H",Teramoto A,10.3390/app10124225,Fujita Health University,"The classification of pulmonary nodules using computed tomography (CT) and positron emission tomography (PET)/CT is often a hard task for physicians. To this end, in our previous study, we developed an automated classification method using PET/CT images. In actual clinical practice, in addition to images, patient information (e.g., laboratory test results) is available and may be useful for automated classification. Here, we developed a hybrid scheme for automated classification of pulmonary nodules using these images and patient information. We collected 36 conventional CT images and PET/CT images of patients who underwent lung biopsy following bronchoscopy. Patient information was also collected. For classification, 25 shape and functional features were first extracted from the images. Benign and malignant nodules were identified using machine learning algorithms along with the images' features and 17 patient-information-related features. In the leave-one-out cross-validation of our hybrid scheme, 94.4% of malignant nodules were identified correctly, and 77.7% of benign nodules were diagnosed correctly. The hybrid scheme performed better than that of our previous method that used only image features. These results indicate that the proposed hybrid scheme may improve the accuracy of malignancy analysis.","lung cancer,pulmonary nodule,PET,CT,patient information,classification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"CT,TOMOGRAPHY,DIAGNOSIS,ACCURACY",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/12/4225/pdf,
17,Automatic ECG Diagnosis Using Convolutional Neural Network,9,6,,"Avanzato Roberta,Beritelli Francesco","Avanzato R,Beritelli F",Beritelli F,10.3390/electronics9060951,University of Catania,"Cardiovascular disease (CVD) is the most common class of chronic and life-threatening diseases and, therefore, considered to be one of the main causes of mortality. The proposed new neural architecture based on the recent popularity of convolutional neural networks (CNN) was a solution for the development of automatic heart disease diagnosis systems using electrocardiogram (ECG) signals. More specifically, ECG signals were passed directly to a properly trained CNN network. The database consisted of more than 4000 ECG signal instances extracted from outpatient ECG examinations obtained from 47 subjects: 25 males and 22 females. The confusion matrix derived from the testing dataset indicated 99% accuracy for the ""normal"" class. For the ""atrial premature beat"" class, ECG segments were correctly classified 100% of the time. Finally, for the ""premature ventricular contraction"" class, ECG segments were correctly classified 96% of the time. In total, there was an average classification accuracy of 98.33%. The sensitivity (SNS) and the specificity (SPC) were, respectively, 98.33% and 98.35%. The new approach based on deep learning and, in particular, on a CNN network guaranteed excellent performance in automatic recognition and, therefore, prevention of cardiovascular diseases.","ECG signal detection,cardiovascular diseases,convolutional neural network (CNN),myocardial infarction (MI)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"MYOCARDIAL-INFARCTION,CLASSIFICATION,PHYSIONET,RESOURCE,SIGNALS,MODELS",ELECTRONICS,https://www.mdpi.com/2079-9292/9/6/951/pdf,
18,Channel and Spatial Attention Regression Network for Cup-to-Disc Ratio Estimation,9,6,,"Li Shuo,Ge Chiru,Sui Xiaodan,Zheng Yuanjie,Jia Weikuan","Li S,Ge CR,Sui XD,Zheng YJ,Jia WK",Zheng YJ; Jia WK,10.3390/electronics9060909,Shandong Normal University,"Cup-to-disc ratio (CDR) is of great importance during assessing structural changes at the optic nerve head (ONH) and diagnosis of glaucoma. While most efforts have been put on acquiring the CDR number through CNN-based segmentation algorithms followed by the calculation of CDR, these methods usually only focus on the features in the convolution kernel, which is, after all, the operation of the local region, ignoring the contribution of rich global features (such as distant pixels) to the current features. In this paper, a new end-to-end channel and spatial attention regression deep learning network is proposed to deduces CDR number from the regression perspective and combine the self-attention mechanism with the regression network. Our network consists of four modules: the feature extraction module to extract deep features expressing the complicated pattern of optic disc (OD) and optic cup (OC), the attention module including the channel attention block (CAB) and the spatial attention block (SAB) to improve feature representation by aggregating long-range contextual information, the regression module to deduce CDR number directly, and the segmentation-auxiliary module to focus the model's attention on the relevant features instead of the background region. Especially, the CAB selects relatively important feature maps in channel dimension, shifting the emphasis on the OD and OC region; meanwhile, the SAB learns the discriminative ability of feature representation at pixel level by capturing the relationship of intra-feature map. The experimental results of ORIGA dataset show that our method obtains absolute CDR error of 0.067 and the Pearson's correlation coefficient of 0.694 in estimating CDR and our method has a great potential in predicting the CDR number.","joint OD and OC segmentation,cup-to-disc ratio estimation,self-attention mechanism,glaucoma screening",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"OPTICAL,COHERENCE,TOMOGRAPHY,AUTOMATED,SEGMENTATION,GRAPH,CUT,IMAGES,QUANTIFICATION",ELECTRONICS,https://www.mdpi.com/2079-9292/9/6/909/pdf,
19,Deep Learning-Based Detection of Pigment Signs for Analysis and Diagnosis of Retinitis Pigmentosa,20,12,,"Arsalan Muhammad,Baek Na Rae,Owais Muhammad,Mahmood Tahir,Park Kang Ryoung","Arsalan M,Baek NR,Owais M,Mahmood T,Park KR",Park KR,10.3390/s20123454,Dongguk University,"Ophthalmological analysis plays a vital role in the diagnosis of various eye diseases, such as glaucoma, retinitis pigmentosa (RP), and diabetic and hypertensive retinopathy. RP is a genetic retinal disorder that leads to progressive vision degeneration and initially causes night blindness. Currently, the most commonly applied method for diagnosing retinal diseases is optical coherence tomography (OCT)-based disease analysis. In contrast, fundus imaging-based disease diagnosis is considered a low-cost diagnostic solution for retinal diseases. This study focuses on the detection of RP from the fundus image, which is a crucial task because of the low quality of fundus images and non-cooperative image acquisition conditions. Automatic detection of pigment signs in fundus images can help ophthalmologists and medical practitioners in diagnosing and analyzing RP disorders. To accurately segment pigment signs for diagnostic purposes, we present an automatic RP segmentation network (RPS-Net), which is a specifically designed deep learning-based semantic segmentation network to accurately detect and segment the pigment signs with fewer trainable parameters. Compared with the conventional deep learning methods, the proposed method applies a feature enhancement policy through multiple dense connections between the convolutional layers, which enables the network to discriminate between normal and diseased eyes, and accurately segment the diseased area from the background. Because pigment spots can be very small and consist of very few pixels, the RPS-Net provides fine segmentation, even in the case of degraded images, by importing high-frequency information from the preceding layers through concatenation inside and outside the encoder-decoder. To evaluate the proposed RPS-Net, experiments were performed based on 4-fold cross-validation using the publicly available Retinal Images for Pigment Signs (RIPS) dataset for detection and segmentation of retinal pigments. Experimental results show that RPS-Net achieved superior segmentation performance for RP diagnosis, compared with the state-of-the-art methods.","deep learning,retinal disease,retinitis pigmentosa,semantic segmentation,RPS-Net",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"OPTIC,DISC,SEGMENTATION,FUNDUS,IMAGES,RETINAL,IMAGES,CLASSIFICATION,NETWORK",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7349531,
20,Comparison of Deep-Learning and Conventional Machine-Learning Methods for the Automatic Recognition of the Hepatocellular Carcinoma Areas from Ultrasound Images,20,11,,"Brehar Raluca,Mitrea Delia-Alexandrina,Vancea Flaviu,Marita Tiberiu,Nedevschi Sergiu,Lupsor-Platon Monica,Rotaru Magda,Badea Radu Ioan","Brehar R,Mitrea DA,Vancea F,Marita T,Nedevschi S,Lupsor-Platon M,Rotaru M,Badea RI",Brehar R,10.3390/s20113085,Technical University of Cluj Napoca,"The emergence of deep-learning methods in different computer vision tasks has proved to offer increased detection, recognition or segmentation accuracy when large annotated image datasets are available. In the case of medical image processing and computer-aided diagnosis within ultrasound images, where the amount of available annotated data is smaller, a natural question arises: are deep-learning methods better than conventional machine-learning methods? How do the conventional machine-learning methods behave in comparison with deep-learning methods on the same dataset? Based on the study of various deep-learning architectures, a lightweight multi-resolution Convolutional Neural Network (CNN) architecture is proposed. It is suitable for differentiating, within ultrasound images, between the Hepatocellular Carcinoma (HCC), respectively the cirrhotic parenchyma (PAR) on which HCC had evolved. The proposed deep-learning model is compared with other CNN architectures that have been adapted by transfer learning for the ultrasound binary classification task, but also with conventional machine-learning (ML) solutions trained on textural features. The achieved results show that the deep-learning approach overcomes classical machine-learning solutions, by providing a higher classification performance.","image processing,Convolutional Neural Networks (CNN),pattern recognition,ultrasound images,Hepatocellular Carcinoma (HCC),automatic diagnosis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,CLASSIFICATION,SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7309124,
21,Estimating Blood Pressure from the Photoplethysmogram Signal and Demographic Features Using Machine Learning Techniques,20,11,,"Chowdhury Moajjem Hossain,Shuzan Md Nazmul Islam,Chowdhury Muhammad E. H.,Mahbub Zaid B.,Uddin M. Monir,Khandakar Amith,Reaz Mamun Bin Ibne","Chowdhury MH,Shuzan MNI,Chowdhury MEH,Mahbub ZB,Uddin MM,Khandakar A,Reaz MB",Chowdhury MEH,10.3390/s20113127,Qatar University,"Hypertension is a potentially unsafe health ailment, which can be indicated directly from the blood pressure (BP). Hypertension always leads to other health complications. Continuous monitoring of BP is very important; however, cuff-based BP measurements are discrete and uncomfortable to the user. To address this need, a cuff-less, continuous, and noninvasive BP measurement system is proposed using the photoplethysmograph (PPG) signal and demographic features using machine learning (ML) algorithms. PPG signals were acquired from 219 subjects, which undergo preprocessing and feature extraction steps. Time, frequency, and time-frequency domain features were extracted from the PPG and their derivative signals. Feature selection techniques were used to reduce the computational complexity and to decrease the chance of over-fitting the ML algorithms. The features were then used to train and evaluate ML algorithms. The best regression models were selected for systolic BP (SBP) and diastolic BP (DBP) estimation individually. Gaussian process regression (GPR) along with the ReliefF feature selection algorithm outperforms other algorithms in estimating SBP and DBP with a root mean square error (RMSE) of 6.74 and 3.59, respectively. This ML model can be implemented in hardware systems to continuously monitor BP and avoid any critical health conditions due to sudden changes.","blood pressure,photoplethysmograph,feature selection algorithm,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"MEASURING,DEVICES,SOCIETY",SENSORS,http://arxiv.org/pdf/2005.03357,
22,Gait Analysis in Parkinson's Disease: An Overview of the Most Accurate Markers for Diagnosis and Symptoms Monitoring,20,12,,"di Biase Lazzaro,Di Santo Alessandro,Caminiti Maria Letizia,De Liso Alfredo,Shah Syed Ahmar,Ricci Lorenzo,Di Lazzaro Vincenzo","di Biase L,Di Santo A,Caminiti ML,De Liso A,Shah SA,Ricci L,Di Lazzaro V",di Biase L,10.3390/s20123529,University Campus Bio-Medico - Rome Italy,"The aim of this review is to summarize that most relevant technologies used to evaluate gait features and the associated algorithms that have shown promise to aid diagnosis and symptom monitoring in Parkinson's disease (PD) patients. We searched PubMed for studies published between 1 January 2005, and 30 August 2019 on gait analysis in PD. We selected studies that have either used technologies to distinguish PD patients from healthy subjects or stratified PD patients according to motor status or disease stages. Only those studies that reported at least 80% sensitivity and specificity were included. Gait analysis algorithms used for diagnosis showed a balanced accuracy range of 83.5-100%, sensitivity of 83.3-100% and specificity of 82-100%. For motor status discrimination the gait analysis algorithms showed a balanced accuracy range of 90.8-100%, sensitivity of 92.5-100% and specificity of 88-100%. Despite a large number of studies on the topic of objective gait analysis in PD, only a limited number of studies reported algorithms that were accurate enough deemed to be useful for diagnosis and symptoms monitoring. In addition, none of the reported algorithms and technologies has been validated in large scale, independent studies.","Parkinson's disease,gait analysis,diagnosis,symptoms monitoring,wearable,home-monitoring,machine learning",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"CARBIDOPA,INTESTINAL,GEL,DEEP,BRAIN-STIMULATION,LCIG,INFUSION,QUANTIFICATION,CLASSIFICATION,BRADYKINESIA,MEDICATION,KINEMATICS,SEVERITY,RIGIDITY",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7349580,
23,A Multi-Objective Approach for Optimal Energy Management in Smart Home Using the Reinforcement Learning,20,12,,"Diyan Muhammad,Silva Bhagya Nathali,Han Kijun","Diyan M,Silva BN,Han K",Han K,10.3390/s20123450,Kyungpook National University,"Maintaining a fair use of energy consumption in smart homes with many household appliances requires sophisticated algorithms working together in real time. Similarly, choosing a proper schedule for appliances operation can be used to reduce inappropriate energy consumption. However, scheduling appliances always depend on the behavior of a smart home user. Thus, modeling human interaction with appliances is needed to design an efficient scheduling algorithm with real-time support. In this regard, we propose a scheduling algorithm based on human appliances interaction in smart homes using reinforcement learning (RL). The proposed scheduling algorithm divides the entire day into various states. In each state, the agents attached to household appliances perform various actions to obtain the highest reward. To adjust the discomfort which arises due to performing inappropriate action, the household appliances are categorized into three groups i.e., (1) adoptable, (2) un-adoptable, (3) manageable. Finally, the proposed system is tested for the energy consumption and discomfort level of the home user against our previous scheduling algorithm based on least slack time phenomenon. The proposed scheme outperforms the Least Slack Time (LST) based scheduling in context of energy consumption and discomfort level of the home user.","reinforcement learning,home energy management,appliance scheduling,human-appliance interaction,user comfort",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"DEMAND-RESPONSE,COMMERCIAL,BUILDINGS,CONSUMPTION,ALGORITHM,SYSTEM",SENSORS,https://europepmc.org/articles/pmc7349083?pdf=render,
24,Real-Time Prediction of Rate of Penetration in S-Shape Well Profile Using Artificial Intelligence Models,20,12,,Elkatatny Salaheldin,Elkatatny S,Elkatatny S,10.3390/s20123506,King Fahd University of Petroleum & Minerals,"Rate of penetration (ROP) is defined as the amount of removed rock per unit area per unit time. It is affected by several factors which are inseparable. Current established models for determining the ROP include the basic mathematical and physics equations, as well as the use of empirical correlations. Given the complexity of the drilling process, the use of artificial intelligence (AI) has been a game changer because most of the unknown parameters can now be accounted for entirely at the modeling process. The objective of this paper is to evaluate the ability of the optimized adaptive neuro-fuzzy inference system (ANFIS), functional neural networks (FN), random forests (RF), and support vector machine (SVM) models to predict the ROP in real time from the drilling parameters in the S-shape well profile, for the first time, based on the drilling parameters of weight on bit (WOB), drillstring rotation (DSR), torque (T), pumping rate (GPM), and standpipe pressure (SPP). Data from two wells were used for training and testing (Well A and Well B with 4012 and 1717 data points, respectively), and one well for validation (Well C) with 2500 data points. Well A and Well B data were combined in the training-testing phase and were randomly divided into a 70:30 ratio for training/testing. The results showed that the ANFIS, FN, and RF models could effectively predict the ROP from the drilling parameters in the S-shape well profile, while the accuracy of the SVM model was very low. The ANFIS, FN, and RF models predicted the ROP for the training data with average absolute percentage errors (AAPEs) of 9.50%, 13.44%, and 3.25%, respectively. For the testing data, the ANFIS, FN, and RF models predicted the ROP with AAPEs of 9.57%, 11.20%, and 8.37%, respectively. The ANFIS, FN, and RF models overperformed the available empirical correlations for ROP prediction. The ANFIS model estimated the ROP for the validation data with an AAPE of 9.06%, whereas the FN model predicted the ROP with an AAPE of 10.48%, and the RF model predicted the ROP with an AAPE of 10.43%. The SVM model predicted the ROP for the validation data with a very high AAPE of 30.05% and all empirical correlations predicted the ROP with AAPEs greater than 25%.","ROP prediction,artificial intelligence,drilling parameter,S-shape",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://www.mdpi.com/1424-8220/20/12/3506/pdf,
25,A Microservices e-Health System for Ecological Frailty Assessment Using Wearables,20,12,,"Garcia-Moreno Francisco M.,Bermudez-Edo Maria,Luis Garrido Jose,Rodriguez-Garcia Estefania,Manuel Perez-Marmol Jose,Jose Rodriguez-Fortiz Maria","Garcia-Moreno FM,Bermudez-Edo M,Garrido JL,Rodriguez-Garcia E,Perez-Marmol JM,Rodriguez-Fortiz MJ",Garcia-Moreno FM,10.3390/s20123427,University of Granada,"The population in developed countries is aging and this fact results in high elderly health costs, as well as a decrease in the number of active working members to support these costs. This could lead to a collapse of the current systems. One of the first insights of the decline in elderly people is frailty, which could be decelerated if it is detected at an early stage. Nowadays, health professionals measure frailty manually through questionnaires and tests of strength or gait focused on the physical dimension. Sensors are increasingly used to measure and monitor different e-health indicators while the user is performing Basic Activities of Daily Life (BADL). In this paper, we present a system based on microservices architecture, which collects sensory data while the older adults perform Instrumental ADLs (IADLs) in combination with BADLs. IADLs involve physical dimension, but also cognitive and social dimensions. With the sensory data we built a machine learning model to assess frailty status which outperforms the previous works that only used BADLs. Our model is accurate, ecological, non-intrusive, flexible and can help health professionals to automatically detect frailty.","wearable devices,sensors,mobile health systems,microservices architecture,IoT,machine learning,elderly frailty assessment,e-health",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,"ACTIVITY,RECOGNITION,PHYSICAL-ACTIVITY,OLDER-ADULTS,HEART-RATE,GAIT,ARCHITECTURE,DEFINITION,DISCOVERY,DECLINE,DEVICES",SENSORS,https://www.mdpi.com/1424-8220/20/12/3427/pdf,
26,Prediction of Body Weight of a Person Lying on a Smart Mat in Nonrestraint and Unconsciousness Conditions,20,12,,"Kim Tae-Hwan,Hong Youn-Sik","Kim TH,Hong YS",Hong YS,10.3390/s20123485,Incheon National University,"We want to predict body weight while lying in bed for an elderly patient who is unable to move by himself/herself. To this end, we have implemented a prototype system that estimates the body weight of a person lying on a smart mat in nonrestraint and unconsciousness conditions. A total of 128 FSR (force sensing resistor) sensors were placed in a 16 x 8-grid structure on the smart mat. We formulated three methods based on the features to be applied: segmentation, average cumulative sum of pressure, and serialization. All the proposed methods were implemented with four different machine-learning models: regression, deep neural network (DNN), convolutional neural network (CNN), and random forest. We compared their performance using MAE and RMSE as evaluation criteria. From the experimental results, we chose the serialization method with the DNN model as the best model. Despite the limitations of the presence of dead space due to the wide spacing between the sensors and the small dataset, the MAE and the RMSE of the body weight prediction of the proposed method was 4.608 and 5.796, respectively. That is, it showed an average error of +/- 4.6 kg for the average weight of 72.9 kg.","body weight,FSR sensors,smart mat,nonrestraint,unconsciousness",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7349795,
27,A Novel Method to Identify Pneumonia through Analyzing Chest Radiographs Employing a Multichannel Convolutional Neural Network,20,12,,"Nahid Abdullah-Al,Sikder Niloy,Bairagi Anupam Kumar,Razzaque Md Abdur,Masud Mehedi,Kouzani Abbas Z.,Mahmud M. A. Parvez","Nahid AA,Sikder N,Bairagi AK,Razzaque MA,Masud M,Kouzani AZ,Mahmud MAP",Nahid AA,10.3390/s20123482,Khulna University,"Pneumonia is a virulent disease that causes the death of millions of people around the world. Every year it kills more children than malaria, AIDS, and measles combined and it accounts for approximately one in five child-deaths worldwide. The invention of antibiotics and vaccines in the past century has notably increased the survival rate of Pneumonia patients. Currently, the primary challenge is to detect the disease at an early stage and determine its type to initiate the appropriate treatment. Usually, a trained physician or a radiologist undertakes the task of diagnosing Pneumonia by examining the patient's chest X-ray. However, the number of such trained individuals is nominal when compared to the 450 million people who get affected by Pneumonia every year. Fortunately, this challenge can be met by introducing modern computers and improved Machine Learning techniques in Pneumonia diagnosis. Researchers have been trying to develop a method to automatically detect Pneumonia using machines by analyzing and the symptoms of the disease and chest radiographic images of the patients for the past two decades. However, with the development of cogent Deep Learning algorithms, the formation of such an automatic system is very much within the realms of possibility. In this paper, a novel diagnostic method has been proposed while using Image Processing and Deep Learning techniques that are based on chest X-ray images to detect Pneumonia. The method has been tested on a widely used chest radiography dataset, and the obtained results indicate that the model is very much potent to be employed in an automatic Pneumonia diagnosis scheme.","pneumonia,chest radiograph,medical image processing,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"COMPUTER-AIDED,DIAGNOSIS,CLASSIFICATION,IMAGES",SENSORS,https://europepmc.org/articles/pmc7348917?pdf=render,
28,A Deep Reinforcement Learning-Based MPPT Control for PV Systems under Partial Shading Condition,20,11,,"Phan Bao Chau,Lai Ying-Chih,Lin Chin E.","Phan BC,Lai YC,Lin CE",Lai YC,10.3390/s20113039,National Cheng Kung University,"On the issues of global environment protection, the renewable energy systems have been widely considered. The photovoltaic (PV) system converts solar power into electricity and significantly reduces the consumption of fossil fuels from environment pollution. Besides introducing new materials for the solar cells to improve the energy conversion efficiency, the maximum power point tracking (MPPT) algorithms have been developed to ensure the efficient operation of PV systems at the maximum power point (MPP) under various weather conditions. The integration of reinforcement learning and deep learning, named deep reinforcement learning (DRL), is proposed in this paper as a future tool to deal with the optimization control problems. Following the success of deep reinforcement learning (DRL) in several fields, the deep Q network (DQN) and deep deterministic policy gradient (DDPG) are proposed to harvest the MPP in PV systems, especially under a partial shading condition (PSC). Different from the reinforcement learning (RL)-based method, which is only operated with discrete state and action spaces, the methods adopted in this paper are used to deal with continuous state spaces. In this study, DQN solves the problem with discrete action spaces, while DDPG handles the continuous action spaces. The proposed methods are simulated in MATLAB/Simulink for feasibility analysis. Further tests under various input conditions with comparisons to the classical Perturb and observe (P&O) MPPT method are carried out for validation. Based on the simulation results in this study, the performance of the proposed methods is outstanding and efficient, showing its potential for further applications.","solar PV,maximum power point tracking (MPPT),partial shading condition (PSC),deep Q network (DQN),deep deterministic policy gradient (DDPG)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"POWER,POINT,TRACKING,PHOTOVOLTAIC,SYSTEMS,ENERGY,MANAGEMENT,ALGORITHM,DESIGN",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7308943,
29,Machine-Learning-Based Muscle Control of a 3D-Printed Bionic Arm,20,11,,"Said Sherif,Boulkaibet Ilyes,Sheikh Murtaza,Karar Abdullah S.,Alkork Samer,Nait-ali Amine","Said S,Boulkaibet I,Sheikh M,Karar AS,Alkork S,Nait-ali A",Said S,10.3390/s20113144,American University of Middle East,"In this paper, a customizable wearable 3D-printed bionic arm is designed, fabricated, and optimized for a right arm amputee. An experimental test has been conducted for the user, where control of the artificial bionic hand is accomplished successfully using surface electromyography (sEMG) signals acquired by a multi-channel wearable armband. The 3D-printed bionic arm was designed for the low cost of 295 USD, and was lightweight at 428 g. To facilitate a generic control of the bionic arm, sEMG data were collected for a set of gestures (fist, spread fingers, wave-in, wave-out) from a wide range of participants. The collected data were processed and features related to the gestures were extracted for the purpose of training a classifier. In this study, several classifiers based on neural networks, support vector machine, and decision trees were constructed, trained, and statistically compared. The support vector machine classifier was found to exhibit an 89.93% success rate. Real-time testing of the bionic arm with the optimum classifier is demonstrated.","Myo armband,bionic arm,prosthetic,gesture,recognition,robotics,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"RECOGNITION,SYSTEM",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7313684,
30,Motion Sensors-Based Machine Learning Approach for the Identification of Anterior Cruciate Ligament Gait Patterns in On-the-Field Activities in Rugby Players,20,11,,"Tedesco Salvatore,Crowe Colum,Ryan Andrew,Sica Marco,Scheurer Sebastian,Clifford Amanda M.,Brown Kenneth N.,O'Flynn Brendan","Tedesco S,Crowe C,Ryan A,Sica M,Scheurer S,Clifford AM,Brown KN,O'Flynn B",Tedesco S,10.3390/s20113029,University College Cork,"Anterior cruciate ligament (ACL) injuries are common among athletes. Despite a successful return to sport (RTS) for most of the injured athletes, a significant proportion do not return to competitive levels, and thus RTS post ACL reconstruction still represents a challenge for clinicians. Wearable sensors, owing to their small size and low cost, can represent an opportunity for the management of athletes on-the-field after RTS by providing guidance to associated clinicians. In particular, this study aims to investigate the ability of a set of inertial sensors worn on the lower-limbs by rugby players involved in a change-of-direction (COD) activity to differentiate between healthy and post-ACL groups via the use of machine learning. Twelve male participants (six healthy and six post-ACL athletes who were deemed to have successfully returned to competitive rugby and tested in the 5-10 year period following the injury) were recruited for the study. Time- and frequency-domain features were extracted from the raw inertial data collected. Several machine learning models were tested, such as k-nearest neighbors, naive Bayes, support vector machine, gradient boosting tree, multi-layer perceptron, and stacking. Feature selection was implemented in the learning model, and leave-one-subject-out cross-validation (LOSO-CV) was adopted to estimate training and test errors. Results obtained show that it is possible to correctly discriminate between healthy and post-ACL injury subjects with an accuracy of 73.07% (multi-layer perceptron) and sensitivity of 81.8% (gradient boosting). The results of this study demonstrate the feasibility of using body-worn motion sensors and machine learning approaches for the identification of post-ACL gait patterns in athletes performing sport tasks on-the-field even a number of years after the injury occurred.","machine learning,ACL,biomechanics,IMUs,inertial sensors,gait analysis,running,on-the-field,rugby",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"MOVEMENT,PATTERNS,DEFICIENT,KNEE,RECONSTRUCTION,INDIVIDUALS,PERFORMANCE,DEVIATIONS,ASYMMETRY,INJURY,STATE",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7309071,
31,Towards Fingerprint Spoofing Detection in the Terahertz Range,20,12,,"Palka Norbert,Kowalski Marcin","Palka N,Kowalski M",Palka N,10.3390/s20123379,Military University of Technology in Warsaw,"Spoofing attacks using imitations of fingerprints of legal users constitute a serious threat. In this study, a terahertz time domain spectroscopy (TDS) setup in a reflection configuration was used for the non-intrusive detection of fingerprint spoofing. Herein, the skin structure of the finger pad is described with a focus on the outermost stratum corneum. We identified and characterized five representative spoofing materials and prepared thin and thick finger imitations. The complex refractive index of the materials was determined in TDS in the transmission configuration. For dataset collection, we selected a group of 16 adults of various ages and genders. The reflection results were analyzed both in the time (reflected signal) and frequency (reflectivity) domains. The measured signals were positively verified with the theoretical calculations. The signals corresponding to samples differ from the finger-related signals, which facilitates spoofing detection. Thanks to deconvolution, we provide a basic explanation of the observed phenomena. We propose two spoofing detection methods, predefined time-frequency features and deep learning based. The methods achieved high true detection rates of 87.9% and 98.8%. Our results show that the terahertz technology can be successfully applied for spoofing detection with high detection probability.","fingerprint spoof detection,terahertz radiation,time domain spectroscopy,neural networks",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,"SKIN,SPECTROSCOPY,RECOGNITION",SENSORS,https://europepmc.org/articles/pmc7349377?pdf=render,
32,Efficient Pneumonia Detection in Chest Xray Images Using Deep Transfer Learning,10,6,,"Hashmi Mohammad Farukh,Katiyar Satyarth,Keskar Avinash G.,Bokde Neeraj Dhanraj,Geem Zong Woo","Hashmi MF,Katiyar S,Keskar AG,Bokde ND,Geem ZW",Geem ZW,10.3390/diagnostics10060417,Gachon University,"Pneumonia causes the death of around 700,000 children every year and affects 7% of the global population. Chest X-rays are primarily used for the diagnosis of this disease. However, even for a trained radiologist, it is a challenging task to examine chest X-rays. There is a need to improve the diagnosis accuracy. In this work, an efficient model for the detection of pneumonia trained on digital chest X-ray images is proposed, which could aid the radiologists in their decision making process. A novel approach based on a weighted classifier is introduced, which combines the weighted predictions from the state-of-the-art deep learning models such as ResNet18, Xception, InceptionV3, DenseNet121, and MobileNetV3 in an optimal way. This approach is a supervised learning approach in which the network predicts the result based on the quality of the dataset used. Transfer learning is used to fine-tune the deep learning models to obtain higher training and validation accuracy. Partial data augmentation techniques are employed to increase the training dataset in a balanced way. The proposed weighted classifier is able to outperform all the individual models. Finally, the model is evaluated, not only in terms of test accuracy, but also in the AUC score. The final proposed weighted classifier model is able to achieve a test accuracy of 98.43% and an AUC score of 99.76 on the unseen data from the Guangzhou Women and Children's Medical Center pneumonia dataset. Hence, the proposed model can be used for a quick diagnosis of pneumonia and can aid the radiologists in the diagnosis process.","pneumonia,chest X-ray images,convolution neural network (CNN),deep learning,transfer learning,computer-aided diagnostics",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"TUBERCULOSIS,CLASSIFICATION",DIAGNOSTICS,https://www.mdpi.com/2075-4418/10/6/417/pdf,
33,A New Type of Fuzzy-Rule-Based System With Chaotic Swarm Intelligence for Multiclassification of Pain Perception From fMRI,28,6,1096-1109,"Anter Ahmed M.,Huang Gan,Li Linling,Zhang Li,Liang Zhen,Zhang Zhiguo","Anter AM,Huang G,Li LL,Zhang L,Liang Z,Zhang ZG",Zhang ZG,10.1109/TFUZZ.2020.2979150,Shenzhen University,"Machine learning has been increasingly used in decoding brain states from functional magnetic resonance imaging (fMRI). One important application is to classify the levels of pain perception from patients' fMRI for clinical pain assessment. However, the huge number of fMRI features and the complex relationships between fMRI and pain levels affect the performance of pain classification models heavily. In this article, we introduce a new fuzzy-rule-based hybrid optimization approach for dimension reduction and multiclassification problems using chaotic map, crow search optimization (CSO), and self-organizing fuzzy logic prototype (SOFLP). The approach is named as CCSO-SOFLP. In the proposed approach, chaotic map-based CSO is employed to find the optimal features from ultra-high-dimensional fMRI, and the fuzzy-rule-based SOFLP is employed for multiclassification of pain levels. In this sense, CSO is provided to avoid being stuck in local minima and to increase the computational performance. On the other hand, multilayer SOFLP classifier can continuously learn from new data and identify prototypes from the observed data and use them to build fuzzy rules, to define a suitable local area for each prototype, and to avoid overlapping. The proposed approach is applied on a pain-evoked fMRI data set to classify the levels of pain. Results indicate that the proposed approach can decode levels of pain and identify predictive fMRI patterns with higher accuracy and convergence speed and shorter execution time. Therefore, the new type of fuzzy-rule-based system with chaotic swarm intelligence holds great potential to predict pain perception in clinical uses.","Pain,Functional magnetic resonance imaging,Optimization,Decoding,Convergence,Feature extraction,Fuzzy logic,Crow search optimization (CSO),functional magnetic resonance imaging (fMRI) decoding,fuzzy rules,pain prediction,self-organizing fuzzy logic prototype (SOFLP)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.444,"OPTIMIZATION,ALGORITHM,C-MEANS,IDENTIFICATION,INFERENCE,MODEL",IEEE TRANSACTIONS ON FUZZY SYSTEMS,,
34,Using a Motion Sensor to Categorize Nonspecific Low Back Pain Patients: A Machine Learning Approach,20,12,,"Abdollahi Masoud,Ashouri Sajad,Abedi Mohsen,Azadeh-Fard Nasibeh,Parnianpour Mohamad,Khalaf Kinda,Rashedi Ehsan","Abdollahi M,Ashouri S,Abedi M,Azadeh-Fard N,Parnianpour M,Khalaf K,Rashedi E",Rashedi E,10.3390/s20123600,Rochester Institute of Technology,"Nonspecific low back pain (NSLBP) constitutes a critical health challenge that impacts millions of people worldwide with devastating health and socioeconomic consequences. In today's clinical settings, practitioners continue to follow conventional guidelines to categorize NSLBP patients based on subjective approaches, such as the STarT Back Screening Tool (SBST). This study aimed to develop a sensor-based machine learning model to classify NSLBP patients into different subgroups according to quantitative kinematic data, i.e., trunk motion and balance-related measures, in conjunction with STarT output. Specifically, inertial measurement units (IMU) were attached to the trunks of ninety-four patients while they performed repetitive trunk flexion/extension movements on a balance board at self-selected pace. Machine learning algorithms (support vector machine (SVM) and multi-layer perceptron (MLP)) were implemented for model development, and SBST results were used as ground truth. The results demonstrated that kinematic data could successfully be used to categorize patients into two main groups: high vs. low-medium risk. Accuracy levels of similar to 75% and 60% were achieved for SVM and MLP, respectively. Additionally, among a range of variables detailed herein, time-scaled IMU signals yielded the highest accuracy levels (i.e., similar to 75%). Our findings support the improvement and use of wearable systems in developing diagnostic and prognostic tools for various healthcare applications. This can facilitate development of an improved, cost-effective quantitative NSLBP assessment tool in clinical and home settings towards effective personalized rehabilitation.","objective clinical decision-making,wearable systems,trunk kinematics,pattern recognition,classification,STarT back screening tool",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,"FALL-RISK-ASSESSMENT,PRIMARY-CARE,START,BACK,SCREENING,TOOL,CLASSIFICATION,GAIT,RELIABILITY,KINEMATICS,PARAMETERS,MANAGEMENT",SENSORS,https://www.biorxiv.org/content/biorxiv/early/2019/10/13/803155.full.pdf,
35,Wearable Monitoring and Interpretable Machine Learning Can Objectively Track Progression in Patients during Cardiac Rehabilitation,20,12,,"De Canniere Helene,Corradi Federico,Smeets Christophe J. P.,Schoutteten Melanie,Varon Carolina,Van Hoof Chris,Van Huffel Sabine,Groenendaal Willemijn,Vandervoort Pieter","De Canniere H,Corradi F,Smeets CJP,Schoutteten M,Varon C,Van Hoof C,Van Huffel S,Groenendaal W,Vandervoort P",De Canniere H,10.3390/s20123601,Hasselt University,"Cardiovascular diseases (CVD) are often characterized by their multifactorial complexity. This makes remote monitoring and ambulatory cardiac rehabilitation (CR) therapy challenging. Current wearable multimodal devices enable remote monitoring. Machine learning (ML) and artificial intelligence (AI) can help in tackling multifaceted datasets. However, for clinical acceptance, easy interpretability of the AI models is crucial. The goal of the present study was to investigate whether a multi-parameter sensor could be used during a standardized activity test to interpret functional capacity in the longitudinal follow-up of CR patients. A total of 129 patients were followed for 3 months during CR using 6-min walking tests (6MWT) equipped with a wearable ECG and accelerometer device. Functional capacity was assessed based on 6MWT distance (6MWD). Linear and nonlinear interpretable models were explored to predict 6MWD. The t-distributed stochastic neighboring embedding (t-SNE) technique was exploited to embed and visualize high dimensional data. The performance of support vector machine (SVM) models, combining different features and using different kernel types, to predict functional capacity was evaluated. The SVM model, using chronotropic response and effort as input features, showed a mean absolute error of 42.8 m (+/- 36.8 m). The 3D-maps derived using the t-SNE technique visualized the relationship between sensor-derived biomarkers and functional capacity, which enables tracking of the evolution of patients throughout the CR program. The current study showed that wearable monitoring combined with interpretable ML can objectively track clinical progression in a CR population. These results pave the road towards ambulatory CR.","wearable sensor,machine learning,physical fitness assessment,cardiac rehabilitation,patient progression monitoring",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"HEART-FAILURE,PATIENTS,6-MINUTE,WALK,TEST,PHYSICAL-ACTIVITY,PERFORMANCE,MANAGEMENT",SENSORS,https://www.mdpi.com/1424-8220/20/12/3601/pdf,
36,Artificial Neural Network for Atrial Fibrillation Identification in Portable Devices,20,12,,"Marinucci Daniele,Sbrollini Agnese,Marcantoni Ilaria,Morettini Micaela,Swenne Cees A.,Burattini Laura","Marinucci D,Sbrollini A,Marcantoni I,Morettini M,Swenne CA,Burattini L",Burattini L,10.3390/s20123570,Marche Polytechnic University,"Atrial fibrillation (AF) is a common cardiac disorder that can cause severe complications. AF diagnosis is typically based on the electrocardiogram (ECG) evaluation in hospitals or in clinical facilities. The aim of the present work is to propose a new artificial neural network for reliable AF identification in ECGs acquired through portable devices. A supervised fully connected artificial neural network (RSL_ANN), receiving 19 ECG features (11 morphological, 4 on F waves and 4 on heart-rate variability (HRV)) in input and discriminating between AF and non-AF classes in output, was created using the repeated structuring and learning (RSL) procedure. RSL_ANN was created and tested on 8028 (training: 4493; validation: 1125; testing: 2410) annotated ECGs belonging to the ""AF Classification from a Short Single Lead ECG Recording"" database and acquired with the portable KARDIA device by AliveCor. RSL_ANN performance was evaluated in terms of area under the curve (AUC) and confidence intervals (CIs) of the received operating characteristic. RSL_ANN performance was very good and very similar in training, validation and testing datasets. AUC was 91.1% (CI: 89.1-93.0%), 90.2% (CI: 86.2-94.3%) and 90.8% (CI: 88.1-93.5%) for the training, validation and testing datasets, respectively. Thus, RSL_ANN is a promising tool for reliable identification of AF in ECGs acquired by portable devices.","atrial fibrillation,artificial neural networks,portable devices",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7348709,
37,Recognition of EEG Signal Motor Imagery Intention Based on Deep Multi-View Feature Learning,20,12,,"Xu Jiacan,Zheng Hao,Wang Jianhui,Li Donglin,Fang Xiaoke","Xu JC,Zheng H,Wang JH,Li DL,Fang XK",Xu JC,10.3390/s20123496,Northeastern University - China,"Recognition of motor imagery intention is one of the hot current research focuses of brain-computer interface (BCI) studies. It can help patients with physical dyskinesia to convey their movement intentions. In recent years, breakthroughs have been made in the research on recognition of motor imagery task using deep learning, but if the important features related to motor imagery are ignored, it may lead to a decline in the recognition performance of the algorithm. This paper proposes a new deep multi-view feature learning method for the classification task of motor imagery electroencephalogram (EEG) signals. In order to obtain more representative motor imagery features in EEG signals, we introduced a multi-view feature representation based on the characteristics of EEG signals and the differences between different features. Different feature extraction methods were used to respectively extract the time domain, frequency domain, time-frequency domain and spatial features of EEG signals, so as to made them cooperate and complement. Then, the deep restricted Boltzmann machine (RBM) network improved by t-distributed stochastic neighbor embedding(t-SNE) was adopted to learn the multi-view features of EEG signals, so that the algorithm removed the feature redundancy while took into account the global characteristics in the multi-view feature sequence, reduced the dimension of the multi-visual features and enhanced the recognizability of the features. Finally, support vector machine (SVM) was chosen to classify deep multi-view features. Applying our proposed method to the BCI competition IV 2a dataset we obtained excellent classification results. The results show that the deep multi-view feature learning method further improved the classification accuracy of motor imagery tasks.","brain-computer interface (BCI),electroencephalography (EEG),multi-view learning,deep neural network,parametric t-distributed stochastic neighbor embedding (p,t-SNE)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"FEATURE-EXTRACTION,CLASSIFICATION,FILTERS,OPTIMIZATION,ALGORITHM",SENSORS,https://europepmc.org/articles/pmc7349253?pdf=render,
38,Resting-State Brain Activity for Early Prediction Outcome in Postanoxic Patients in a Coma with Indeterminate Clinical Prognosis,41,6,1022-1030,"Pugin D.,Hofmeister J.,Gasche Y.,Vulliemoz S.,Lovblad K. -O.,Van De Ville D.,Haller S.","Pugin D,Hofmeister J,Gasche Y,Vulliemoz S,Lovblad KO,Van De Ville D,Haller S",Pugin D,10.3174/ajnr.A6572,University of Geneva,"The authors used resting-state fMRI in a prospective study to compare whole-brain functional connectivity between patients with good and poor outcomes, implementing support vector machine learning. They automatically predicted coma outcome using resting-state fMRI and also compared the prediction based on resting-state fMRI with the outcome prediction based on DWI. Of 17 eligible patients who completed the study procedure (among 351 patients screened), 9 regained consciousness and 8 remained comatose. They found higher functional connectivity in patients recovering consciousness, with greater changes occurring within and between the occipitoparietal and temporofrontal regions. Coma outcome prognostication based on resting-state fMRI machine learning was very accurate, notably for identifying patients with good outcome. They conclude that resting-state fMRI might bridge the gap left in early prognostication of postanoxic patients in a coma by identifying those with both good and poor outcomes.
BACKGROUND AND PURPOSE: Early outcome prediction of postanoxic patients in a coma after cardiac arrest proves challenging. Current prognostication relies on multimodal testing, using clinical examination, electrophysiologic testing, biomarkers, and structural MR imaging. While this multimodal prognostication is accurate for predicting poor outcome (ie, death), it is not sensitive enough to identify good outcome (ie, consciousness recovery), thus leaving many patients with indeterminate prognosis. We specifically assessed whether resting-state fMRI provides prognostic information, notably in postanoxic patients in a coma with indeterminate prognosis early after cardiac arrest, specifically for good outcome.
MATERIALS AND METHODS: We used resting-state fMRI in a prospective study to compare whole-brain functional connectivity between patients with good and poor outcomes, implementing support vector machine learning. Then, we automatically predicted coma outcome using resting-state fMRI and also compared the prediction based on resting-state fMRI with the outcome prediction based on DWI.
RESULTS: Of 17 eligible patients who completed the study procedure (among 351 patients screened), 9 regained consciousness and 8 remained comatose. We found higher functional connectivity in patients recovering consciousness, with greater changes occurring within and between the occipitoparietal and temporofrontal regions. Coma outcome prognostication based on resting-state fMRI machine learning was very accurate, notably for identifying patients with good outcome (accuracy, 94.4%; area under the receiver operating curve, 0.94). Outcome predictors using resting-state fMRI performed significantly better (P < .05) than DWI (accuracy, 60.0%; area under the receiver operating curve, 0.63).
CONCLUSIONS: Indeterminate prognosis might lead to major clinical uncertainty and significant variations in life-sustaining treatments. Resting-state fMRI might bridge the gap left in early prognostication of postanoxic patients in a coma by identifying those with both good and poor outcomes.","HOSPITAL CARDIAC-ARREST,FUNCTIONAL CONNECTIVITY,CARDIOPULMONARY-RESUSCITATION,NETWORK CONNECTIVITY,DEFAULT NETWORK,SURVIVORS,CONSCIOUSNESS,MRI,HYPOTHERMIA,GUIDELINES",Article,"AMER SOC NEURORADIOLOGY, PO BOX 3000, DENVILLE, NJ 07834-9349 USA","Neurosciences & Neurology,Radiology, Nuclear Medicine & Medical Imaging",,4.457,"HOSPITAL,CARDIAC-ARREST,FUNCTIONAL,CONNECTIVITY,CARDIOPULMONARY-RESUSCITATION,NETWORK,CONNECTIVITY,DEFAULT,NETWORK,SURVIVORS,CONSCIOUSNESS,MRI,HYPOTHERMIA,GUIDELINES",AMERICAN JOURNAL OF NEURORADIOLOGY,https://archive-ouverte.unige.ch/unige:136391/ATTACHMENT01,
39,A Novel Approach for Biofilm Detection Based on a Convolutional Neural Network,9,6,,"Dimauro Giovanni,Deperte Francesca,Maglietta Rosalia,Bove Mario,La Gioia Fabio,Reno Vito,Simone Lorenzo,Gelardi Matteo","Dimauro G,Deperte F,Maglietta R,Bove M,La Gioia F,Reno V,Simone L,Gelardi M",Dimauro G,10.3390/electronics9060881,Universita degli Studi di Bari Aldo Moro,"Rhinology studies anatomy, physiology and diseases affecting the nasal region: one of the most modern techniques to diagnose these diseases is nasal cytology or rhinocytology, which involves analyzing the cells contained in the nasal mucosa under a microscope and researching of other elements such as bacteria, to suspect a pathology. During the microscopic observation, bacteria can be detected in the form of biofilm, that is, a bacterial colony surrounded by an organic extracellular matrix, with a protective function, made of polysaccharides. In the field of nasal cytology, the presence of biofilm in microscopic samples denotes the presence of an infection. In this paper, we describe the design and testing of interesting diagnostic support, for the automatic detection of biofilm, based on a convolutional neural network (CNN). To demonstrate the reliability of the system, alternative solutions based on isolation forest and deep random forest techniques were also tested. Texture analysis is used, with Haralick feature extraction and dominant color. The CNN-based biofilm detection system shows an accuracy of about 98%, an average accuracy of about 100% on the test set and about 99% on the validation set. The CNN-based system designed in this study is confirmed as the most reliable among the best automatic image recognition technologies, in the specific context of this study. The developed system allows the specialist to obtain a rapid and accurate identification of the biofilm in the slide images.","convolutional neural network,biofilm detection,deep learning,rhinocitology",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"COMPUTER-AIDED,DIAGNOSIS,NASAL,CYTOLOGY,DEEP,SEGMENTATION,IMAGES",ELECTRONICS,https://www.mdpi.com/2079-9292/9/6/881/pdf,
40,Development of a Wearable Electrical Impedance Tomographic Sensor for Gesture Recognition With Machine Learning,24,6,1550-1556,"Yao Jiafeng,Chen Huaijin,Xu Zifei,Huang Jingshi,Li Jianping,Jia Jiabin,Wu Hongtao","Yao JF,Chen HJ,Xu ZF,Huang JS,Li JP,Jia JB,Wu HT",Yao JF,10.1109/JBHI.2019.2945593,Nanjing University of Aeronautics & Astronautics,"A wearable electrical impedance tomographic (wEIT) sensor with 8 electrodes is developed to realize gesture recognition with machine learning algorithms. To optimize the wEIT sensor, gesture recognition rates are compared by using a series of electrodes with different materials and shapes. To improve the gesture recognition rates, several Machine Learning algorithms are used to recognize three different gestures with the obtained voltage data. To clarify the gesture recognition mechanism, an electrical model of the electrode-skin contact impedance is established. Experimental results show that: rectangular copper electrodes realize the highest recognition rate; the existence of the electrode-skin contact impedance could improve the gesture recognition rate; Medium Gaussian SVM (Support Vector Machine) algorithm is the optimal algorithm with an average recognition rate of 95%.","Electrodes,Gesture recognition,Impedance,Tomography,Contacts,Skin,Copper,Contact impedance,electrical impedance tomography,gesture recognition,machine learning,wearable sensor",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,SYSTEM,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://www.pure.ed.ac.uk/ws/files/206792740/206258327AFPRM.pdf,
41,Heart Sound Segmentation Using Bidirectional LSTMs With Attention,24,6,1601-1609,"Fernando Tharindu,Ghaemmaghami Houman,Denman Simon,Sridharan Sridha,Hussain Nayyar,Fookes Clinton","Fernando T,Ghaemmaghami H,Denman S,Sridharan S,Hussain N,Fookes C",Fernando T,10.1109/JBHI.2019.2949516,Queensland University of Technology (QUT),"Objective: This paper proposes a novel framework for the segmentation of phonocardiogram (PCG) signals into heart states, exploiting the temporal evolution of the PCG as well as considering the salient information that it provides for the detection of the heart state. Methods: We propose the use of recurrent neural networks and exploit recent advancements in attention based learning to segment the PCG signal. This allows the network to identify the most salient aspects of the signal and disregard uninformative information. Results: The proposed method attains state-of-the-art performance on multiple benchmarks including both human and animal heart recordings. Furthermore, we empirically analyse different feature combinations including envelop features, wavelet and Mel Frequency Cepstral Coefficients (MFCC), and provide quantitative measurements that explore the importance of different features in the proposed approach. Conclusion: We demonstrate that a recurrent neural network coupled with attention mechanisms can effectively learn from irregular and noisy PCG recordings. Our analysis of different feature combinations shows that MFCC features and their derivatives offer the best performance compared to classical wavelet and envelop features. Significance: Heart sound segmentation is a crucial pre-processing step for many diagnostic applications. The proposed method provides a cost effective alternative to labour extensive manual segmentation, and provides a more accurate segmentation than existing methods. As such, it can improve the performance of further analysis including the detection of murmurs and ejection clicks. The proposed method is also applicable for detection and segmentation of other one dimensional biomedical signals.","Heart,Phonocardiography,Animals,Feature extraction,Noise measurement,Task analysis,Recurrent neural networks,Heart sound segmentation,deep recurrent neural networks,attention models,long short term memory networks,biomedical signal processing,phonocardiogram",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,ALGORITHM,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://arxiv.org/pdf/2004.03712,
42,Deep Learning-Based Classification of Liver Cancer Histopathology Images Using Only Global Labels,24,6,1643-1651,"Sun Chunli,Xu Ao,Liu Dong,Xiong Zhiwei,Zhao Feng,Ding Weiping","Sun CL,Xu A,Liu D,Xiong ZW,Zhao F,Ding WP",Ding WP,10.1109/JBHI.2019.2949837,Chinese Academy of Sciences,"Liver cancer is a leading cause of cancer deaths worldwide due to its high morbidity and mortality. Histopathological image analysis (HIA) is a crucial step in the early diagnosis of liver cancer and is routinely performed manually. However, this process is time-consuming, error-prone, and easily affected by the expertise of pathologists. Recently, computer-aided methods have been widely applied to medical image analysis; however, the current medical image analysis studies have not yet focused on the histopathological morphology of liver cancer due to its complex features and the insufficiency of training images with detailed annotations. This paper proposes a deep learning method for liver cancer histopathological image classification using only global labels. To compensate for the lack of detailed cancer region annotations in those images, patch features are extracted and fully utilized. Transfer learning is used to obtain the patch-level features and then combined with multiple-instance learning to acquire the image-level features for classification. The method proposed here solves the processing of large-scale images and training sample insufficiency in liver cancer histopathological images for image classification. The proposed method can distinguish and classify liver histopathological images as abnormal or normal with high accuracy, thus providing support for the early diagnosis of liver cancer.","Liver,Cancer,Feature extraction,Image analysis,Image color analysis,Training,Biomedical imaging,Global labels,histopathological image analysis,liver cancer,multiple instance learning,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"CONVOLUTIONAL,NEURAL-NETWORKS,SEGMENTATION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
43,MediMLP: Using Grad-CAM to Extract Crucial Variables for Lung Cancer Postoperative Complication Prediction,24,6,1762-1771,"He Tao,Guo Jixiang,Chen Nan,Xu Xiuyuan,Wang Zihuai,Fu Kaiyu,Liu Lunxu,Yi Zhang","He T,Guo JX,Chen N,Xu XY,Wang ZH,Fu KY,Liu LX,Yi Z",Yi Z,10.1109/JBHI.2019.2949601,Sichuan University,"Lung cancer postoperative complication prediction (PCP) is significant for decreasing the perioperative mortality rate after lung cancer surgery. In this paper we concentrate on two PCP tasks: (1) the binary classification for predicting whether a patient will have postoperative complications; and (2) the three-class multi-label classification for predicting which postoperative complication a patient will experience. Furthermore, an important clinical requirement of PCP is the extraction of crucial variables from electronic medical records. We propose a novel multi-layer perceptron (MLP) model called medical MLP (MediMLP) together with the gradient-weighted class activation mapping (Grad-CAM) algorithm for lung cancer PCP. The proposed MediMLP, which involves one locally connected layer and fully connected layers with a shortcut connection, simultaneously extracts crucial variables and performs PCP tasks. The experimental results indicated that MediMLP outperformed normal MLP on two PCP tasks and had comparable performance with existing feature selection methods. Using MediMLP and further experimental analysis, we found that the variable of ""time of indwelling drainage tube"" was very relevant to lung cancer postoperative complications.","Task analysis,Lung,Surgery,Biomedical imaging,Visualization,Feature selection,Lung cancer,MLP,Neural networks,Postoperative complication",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
44,Personalized automatic sleep staging with single-night data: a pilot study with Kullback-Leibler divergence regularization,41,6,,"Huy Phan,Mikkelsen Kaare,Chen Oliver Y.,Koch Philipp,Mertins Alfred,Kidmose Preben,De Vos Maarten","Phan H,Mikkelsen K,Chen OY,Koch P,Mertins A,Kidmose P,De Vos M",Phan H,10.1088/1361-6579/ab921e,University of London,"Objective: Brain waves vary between people. This work aims to improve automatic sleep staging for longitudinal sleep monitoring via personalization of algorithms based on individual characteristics extracted from sleep data recorded during the first night.Approach: As data from a single night are very small, thereby making model training difficult, we propose a Kullback-Leibler (KL) divergence regularized transfer learning approach to address this problem. We employ the pretrained SeqSleepNet (i.e. the subject independent model) as a starting point and finetune it with the single-night personalization data to derive the personalized model. This is done by adding the KL divergence between the output of the subject independent model and it of the personalized model to the loss function during finetuning. In effect, KL-divergence regularization prevents the personalized model from overfitting to the single-night data and straying too far away from the subject independent model.Main results: Experimental results on the Sleep-EDF Expanded database consisting of 75 subjects show that sleep staging personalization with single-night data is possible with help of the proposed KL-divergence regularization. On average, we achieve a personalized sleep staging accuracy of 79.6%, a Cohen's kappa of 0.706, a macro F1-score of 73.0%, a sensitivity of 71.8%, and a specificity of 94.2%.Significance: We find both that the approach is robust against overfitting and that it improves the accuracy by 4.5 percentage points compared to the baseline method without personalization and 2.2 percentage points compared to it with personalization but without regularization.","automatic sleep staging,personalization,transfer learning,single-night data,KL-divergence regularization",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,RESOURCE,PHYSIOLOGICAL MEASUREMENT,https://doi.org/10.1088/1361-6579/ab921e,
45,Development of a Deep Learning Algorithm for Periapical Disease Detection in Dental Radiographs,10,6,,"Endres Michael G.,Hillen Florian,Salloumis Marios,Sedaghat Ahmad R.,Niehues Stefan M.,Quatela Olivia,Hanken Henning,Smeets Ralf,Beck-Broichsitter Benedicta,Rendenbach Carsten","Endres MG,Hillen F,Salloumis M,Sedaghat AR,Niehues SM,Quatela O,Hanken H,Smeets R,Beck-Broichsitter B,Rendenbach C",Gaudin RA,10.3390/diagnostics10060430,Harvard University,"Periapical radiolucencies, which can be detected on panoramic radiographs, are one of the most common radiographic findings in dentistry and have a differential diagnosis including infections, granuloma, cysts and tumors. In this study, we seek to investigate the ability with which 24 oral and maxillofacial (OMF) surgeons assess the presence of periapical lucencies on panoramic radiographs, and we compare these findings to the performance of a predictive deep learning algorithm that we have developed using a curated data set of 2902 de-identified panoramic radiographs. The mean diagnostic positive predictive value (PPV) of OMF surgeons based on their assessment of panoramic radiographic images was 0.69 (+/- 0.13), indicating that dentists on average falsely diagnose 31% of cases as radiolucencies. However, the mean diagnostic true positive rate (TPR) was 0.51 (+/- 0.14), indicating that on average 49% of all radiolucencies were missed. We demonstrate that the deep learning algorithm achieves a better performance than 14 of 24 OMF surgeons within the cohort, exhibiting an average precision of 0.60 (+/- 0.04), and an F(1)score of 0.58 (+/- 0.04) corresponding to a PPV of 0.67 (+/- 0.05) and TPR of 0.51 (+/- 0.05). The algorithm, trained on limited data and evaluated on clinically validated ground truth, has potential to assist OMF surgeons in detecting periapical lucencies on panoramic radiographs.","artificial intelligence,diagnosis,computer-assisted,image interpretation,computer-assisted,machine learning,radiography,panoramic radiograph",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"AUTOMATED,CARIES,DETECTION,APICAL,PERIODONTITIS,COMPUTED-TOMOGRAPHY,ACCURACY,QUALITY,FILM",DIAGNOSTICS,https://europepmc.org/articles/pmc7344682?pdf=render,
46,On the Data-Driven Modeling of Reactive Extrusion,5,2,,"Ibanez Ruben,Casteran Fanny,Argerich Clara,Ghnatios Chady,Hascoet Nicolas,Ammar Amine,Cassagnau Philippe,Chinesta Francisco","Ibanez R,Casteran F,Argerich C,Ghnatios C,Hascoet N,Ammar A,Cassagnau P,Chinesta F",Chinesta F,10.3390/fluids5020094,heSam Universite,"This paper analyzes the ability of different machine learning techniques, able to operate in the low-data limit, for constructing the model linking material and process parameters with the properties and performances of parts obtained by reactive polymer extrusion. The use of data-driven approaches is justified by the absence of reliable modeling and simulation approaches able to predict induced properties in those complex processes. The experimental part of this work is based on the in situ synthesis of a thermoset (TS) phase during the mixing step with a thermoplastic polypropylene (PP) phase in a twin-screw extruder. Three reactive epoxy/amine systems have been considered and anhydride maleic grafted polypropylene (PP-g-MA) has been used as compatibilizer. The final objective is to define the appropriate processing conditions in terms of improving the mechanical properties of these new PP materials by reactive extrusion.","reactive extrusion,data-driven,machine learning,artificial engineering,polymer processing,digital twin",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,,,FLUIDS,https://www.mdpi.com/2311-5521/5/2/94/pdf,
47,Artificial Neural Networks in Classification of Steel Grades Based on Non-Destructive Tests,13,11,,"Beskopylny Alexey,Lyapin Alexandr,Anysz Hubert,Meskhi Besarion,Veremeenko Andrey,Mozgovoy Andrey","Beskopylny A,Lyapin A,Anysz H,Meskhi B,Veremeenko A,Mozgovoy A",Beskopylny A,10.3390/ma13112445,Don State Technical University,"Assessment of the mechanical properties of structural steels characterizing their strength and deformation parameters is an essential problem in the monitoring of structures that have been in operation for quite a long time. The properties of steel can change under the influence of loads, deformations, or temperatures. There is a problem of express determination of the steel grade used in structures-often met in the practice of civil engineering or machinery manufacturing. The article proposes the use of artificial neural networks for the classification and clustering of steel according to strength characteristics. The experimental studies of the mechanical characteristics of various steel grades were carried out, and a special device was developed for conducting tests by shock indentation of a conical indenter. A technique based on a neural network was built. The developed algorithm allows with average accuracy-over 95%-to attribute the results to the corresponding steel grade.","non-destructive test,machine learning,clustering,steel,cone indentation,impact,artificial neural networks",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"INDENTATION,PREDICTION,HARDNESS",MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7321333,
48,Dynamic Ferromagnetic Hysteresis Modelling Using a Preisach-Recurrent Neural Network Model,13,11,,"Grech Christian,Buzio Marco,Pentella Mariano,Sammut Nicholas","Grech C,Buzio M,Pentella M,Sammut N",Grech C,10.3390/ma13112561,University of Malta,"In this work, a Preisach-recurrent neural network model is proposed to predict the dynamic hysteresis in ARMCO pure iron, an important soft magnetic material in particle accelerator magnets. A recurrent neural network coupled with Preisach play operators is proposed, along with a novel validation method for the identification of the model's parameters. The proposed model is found to predict the magnetic flux density of ARMCO pure iron with a Normalised Root Mean Square Error (NRMSE) better than 0.7%, when trained with just six different hysteresis loops. The model is evaluated using ramp-rates not used in the training procedure, which shows the ability of the model to predict data which has not been measured. The results demonstrate that the Preisach model based on a recurrent neural network can accurately describe ferromagnetic dynamic hysteresis when trained with a limited amount of data, showing the model's potential in the field of materials science.","ARMCO pure iron,dynamic hysteresis loop,machine learning,magnetic properties,particle accelerators,Preisach,recurrent neural networks",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"MAGNETIC,HYSTERESIS,IDENTIFICATION,COMPENSATION",MATERIALS,https://www.um.edu.mt/library/oar/bitstream/123456789/58860/3/materials-13-02561.pdf,
49,Intelligent Identification of MoS(2)Nanostructures with Hyperspectral Imaging by 3D-CNN,10,6,,"Li Kai-Chun,Lu Ming-Yen,Hong Thai Nguyen,Feng Shih-Wei,Artemkina Sofya B.,Fedorov Vladimir E.,Wang Hsiang-Chen","Li KC,Lu MY,Nguyen HT,Feng SW,Artemkina SB,Fedorov VE,Wang HC",Wang HC,10.3390/nano10061161,National Chung Cheng University,"Increasing attention has been paid to two-dimensional (2D) materials because of their superior performance and wafer-level synthesis methods. However, the large-area characterization, precision, intelligent automation, and high-efficiency detection of nanostructures for 2D materials have not yet reached an industrial level. Therefore, we use big data analysis and deep learning methods to develop a set of visible-light hyperspectral imaging technologies successfully for the automatic identification of few-layers MoS2. For the classification algorithm, we propose deep neural network, one-dimensional (1D) convolutional neural network, and three-dimensional (3D) convolutional neural network (3D-CNN) models to explore the correlation between the accuracy of model recognition and the optical characteristics of few-layers MoS2. The experimental results show that the 3D-CNN has better generalization capability than other classification models, and this model is applicable to the feature input of the spatial and spectral domains. Such a difference consists in previous versions of the present study without specific substrate, and images of different dynamic ranges on a section of the sample may be administered via the automatic shutter aperture. Therefore, adjusting the imaging quality under the same color contrast conditions is unnecessary, and the process of the conventional image is not used to achieve the maximum field of view recognition range of similar to 1.92 mm(2). The image resolution can reach similar to 100 nm and the detection time is 3 min per one image.","hyperspectral imagery,deep learning,3D-CNN,MoS2,automated optical inspection",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,5.346,"MONOLAYER,MOS2,LAYER,MOS2,SINGLE-LAYER,MIXED,PIXEL,EVOLUTION,GROWTH",NANOMATERIALS,https://europepmc.org/articles/pmc7353172?pdf=render,
50,The Neural Network Revamping the Process's Reliability in Deep Lean via Internet of Things,8,6,,"Abed Ahmed M.,Elattar Samia,Gaafar Tamer S.,Alrowais Fadwa Moh","Abed AM,Elattar S,Gaafar TS,Alrowais FM",Elattar S,10.3390/pr8060729,Princess Nourah bint Abdulrahman University,"Deep lean is a novel approach that is concerned with the profound analysis for waste's behavior at hidden layers in manufacturing processes to enhance processes' reliability level at the upstream. Ideal Standard Co. for bathtubs suffered from defects and cost losses in the spraying section, due to differences in the painting cover thickness due to bubbles, caused by eddies, which move toward the bathtubs through hoses. These bubbles and their movement are considered as a form of lean's waste. The spraying liquid inside the tanks and hoses must move with uniform velocity, viscosity, pressure, feed rate and suitable Reynolds circulation values to eliminate the eddy causes. These factors are tackled through the adoption Internet of Things (IoT) technologies that are aided by neural networks (NN) when an abnormal flow rate is detected using sensor data in real-time that can reduce the defects. The NN aimed at forecasting eddies' movement lines that carry bubbles and works on being blasted before entering the hoses through using Design of Experiment (DOE). This paper illustrates a deep lean perspective as driven by the define, measure, analysis, improvement and control (DMAIC) methodology to improve reliability. The eddy moves downstream slowly with an anti-clockwise flow for some of the optimal values for the influencing factors, whereas the circulation of Omega increases, whether for vertical or horizontal travel.","deep learning,DMAIC,eddy waste control,circulation number,Reynolds number",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Engineering,,2.824,"VORTEX,BREAKDOWN,NUMERICAL-SIMULATION,AGRICULTURE",PROCESSES,https://www.mdpi.com/2227-9717/8/6/729/pdf,
51,User Affect Elicitation with a Socially Emotional Robot,9,2,,"Shao Mingyang,Snyder Matt,Nejat Goldie,Benhabib Beno","Shao MY,Snyder M,Nejat G,Benhabib B",Shao MY,10.3390/robotics9020044,University of Toronto,"To effectively communicate with people, social robots must be capable of detecting, interpreting, and responding to human affect during human-robot interactions (HRIs). In order to accurately detect user affect during HRIs, affect elicitation techniques need to be developed to create and train appropriate affect detection models. In this paper, we present such a novel affect elicitation and detection method for social robots in HRIs. Non-verbal emotional behaviors of the social robot were designed to elicit user affect, which was directly measured through electroencephalography (EEG) signals. HRI experiments with both younger and older adults were conducted to evaluate our affect elicitation technique and compare the two types of affect detection models we developed and trained utilizing multilayer perceptron neural networks (NNs) and support vector machines (SVMs). The results showed that; on average, the self-reported valence and arousal were consistent with the intended elicited affect. Furthermore, it was also noted that the EEG data obtained could be used to train affect detection models with the NN models achieving higher classification rates","human-robot interaction,affective computing,assistive and social robotics",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Robotics,,,"OLDER-ADULTS,EEG,DATABASE,HUMANS,RECOGNITION,EXPRESSION,MUSIC,BODY,TIME",ROBOTICS,https://www.mdpi.com/2218-6581/9/2/44/pdf,
52,Spatio-Temporal Representation of an Electoencephalogram for Emotion Recognition Using a Three-Dimensional Convolutional Neural Network,20,12,,"Cho Jungchan,Hwang Hyoseok","Cho J,Hwang H",Hwang H,10.3390/s20123491,Gachon University,"Emotion recognition plays an important role in the field of human-computer interaction (HCI). An electroencephalogram (EEG) is widely used to estimate human emotion owing to its convenience and mobility. Deep neural network (DNN) approaches using an EEG for emotion recognition have recently shown remarkable improvement in terms of their recognition accuracy. However, most studies in this field still require a separate process for extracting handcrafted features despite the ability of a DNN to extract meaningful features by itself. In this paper, we propose a novel method for recognizing an emotion based on the use of three-dimensional convolutional neural networks (3D CNNs), with an efficient representation of the spatio-temporal representations of EEG signals. First, we spatially reconstruct raw EEG signals represented as stacks of one-dimensional (1D) time series data to two-dimensional (2D) EEG frames according to the original electrode position. We then represent a 3D EEG stream by concatenating the 2D EEG frames to the time axis. These 3D reconstructions of the raw EEG signals can be efficiently combined with 3D CNNs, which have shown a remarkable feature representation from spatio-temporal data. Herein, we demonstrate the accuracy of the emotional classification of the proposed method through extensive experiments on the DEAP (a Dataset for Emotion Analysis using EEG, Physiological, and video signals) dataset. Experimental results show that the proposed method achieves a classification accuracy of 99.11%, 99.74%, and 99.73% in the binary classification of valence and arousal, and, in four-class classification, respectively. We investigate the spatio-temporal effectiveness of the proposed method by comparing it to several types of input methods with 2D/3D CNN. We then verify the best performing shape of both the kernel and input data experimentally. We verify that an efficient representation of an EEG and a network that fully takes advantage of the data characteristics can outperform methods that apply handcrafted features.","EEG,emotion recognition,convolutional neural network,three-dimensional CNN,DEAP",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"FEATURES,CLASSIFICATION,MACHINE,ENTROPY,VECTOR",SENSORS,https://www.mdpi.com/1424-8220/20/12/3491/pdf,
53,Deep Transfer Learning in Diagnosing Leukemia in Blood Cells,9,2,,"Loey Mohamed,Naman Mukdad,Zayed Hala","Loey M,Naman M,Zayed H",Naman M,10.3390/computers9020029,Egyptian Knowledge Bank (EKB),"Leukemia is a fatal disease that threatens the lives of many patients. Early detection can effectively improve its rate of remission. This paper proposes two automated classification models based on blood microscopic images to detect leukemia by employing transfer learning, rather than traditional approaches that have several disadvantages. In the first model, blood microscopic images are pre-processed; then, features are extracted by a pre-trained deep convolutional neural network named AlexNet, which makes classifications according to numerous well-known classifiers. In the second model, after pre-processing the images, AlexNet is fine-tuned for both feature extraction and classification. Experiments were conducted on a dataset consisting of 2820 images confirming that the second model performs better than the first because of 100% classification accuracy.","deep learning,leukemia detection,transfer learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"CLASSIFICATION,MODEL,SYSTEM",COMPUTERS,https://www.mdpi.com/2073-431X/9/2/29/pdf,
54,Classification of Vowels from Imagined Speech with Convolutional Neural Networks,9,2,,"Tamm Markus-Oliver,Muhammad Yar,Muhammad Naveed","Tamm MO,Muhammad Y,Muhammad N",Muhammad Y,10.3390/computers9020046,University of Tartu,"Imagined speech is a relatively new electroencephalography (EEG) neuro-paradigm, which has seen little use in Brain-Computer Interface (BCI) applications. Imagined speech can be used to allow physically impaired patients to communicate and to use smart devices by imagining desired commands and then detecting and executing those commands in a smart device. The goal of this research is to verify previous classification attempts made and then design a new, more efficient neural network that is noticeably less complex (fewer number of layers) that still achieves a comparable classification accuracy. The classifiers are designed to distinguish between EEG signal patterns corresponding to imagined speech of different vowels and words. This research uses a dataset that consists of 15 subjects imagining saying the five main vowels (a, e, i, o, u) and six different words. Two previous studies on imagined speech classifications are verified as those studies used the same dataset used here. The replicated results are compared. The main goal of this study is to take the proposed convolutional neural network (CNN) model from one of the replicated studies and make it much more simpler and less complex, while attempting to retain a similar accuracy. The pre-processing of data is described and a new CNN classifier with three different transfer learning methods is described and used to classify EEG signals. Classification accuracy is used as the performance metric. The new proposed CNN, which uses half as many layers and less complex pre-processing methods, achieved a considerably lower accuracy, but still managed to outperform the initial model proposed by the authors of the dataset by a considerable margin. It is recommended that further studies investigating classifying imagined speech should use more data and more powerful machine learning techniques. Transfer learning proved beneficial and should be used to improve the effectiveness of neural networks.","EEG,imagined speech,machine learning,convolutional neural networks,transfer learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,,COMPUTERS,https://www.mdpi.com/2073-431X/9/2/46/pdf,
55,In Situ Monitoring Systems of The SLM Process: On the Need to Develop Machine Learning Models for Data Processing,10,6,,"Yadav Pinku,Rigo Olivier,Arvieu Corinne,Le Guen Emilie,Lacoste Eric","Yadav P,Rigo O,Arvieu C,Le Guen E,Lacoste E",Lacoste E,10.3390/cryst10060524,Centre National de la Recherche Scientifique (CNRS),"In recent years, technological advancements have led to the industrialization of the laser powder bed fusion process. Despite all of the advancements, quality assurance, reliability, and lack of repeatability of the laser powder bed fusion process still hinder risk-averse industries from adopting it wholeheartedly. The process-induced defects or drifts can have a detrimental effect on the quality of the final part, which could lead to catastrophic failure of the finished part. It led to the development of in situ monitoring systems to effectively monitor the process signatures during printing. Nevertheless, post-processing of the in situ data and defect detection in an automated fashion are major challenges. Nowadays, many studies have been focused on incorporating machine learning approaches to solve this problem and develop a feedback control loop system to monitor the process in real-time. In our study, we review the types of process defects that can be monitored via process signatures captured by in situ sensing devices and recent advancements in the field of data analytics for easy and automated defect detection. We also discuss the working principles of the most common in situ sensing sensors to have a better understanding of the process. Commercially available in situ monitoring devices on laser powder bed fusion systems are also reviewed. This review is inspired by the work of Grasso and Colosimo, which presented an overall review of powder bed fusion technology.","L-PBF,in situ sensing,quality assurance,machine learning",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Crystallography,Materials Science",,2.615,"MELT,POOL,RESIDUAL-STRESS,MECHANICAL-PROPERTIES,PROCESS,PARAMETERS,SURFACE-ROUGHNESS,DEFECT,DETECTION,STAINLESS-STEEL,LASER,POWDER,PARTS",CRYSTALS,https://zenodo.org/record/3903446/files/crystals-10-00524.pdf,
56,"COVID-19 Diagnostics, Tools, and Prevention",10,6,,"Allam Mayar,Cai Shuangyi,Ganesh Shambavi,Venkatesan Mythreye,Doodhwala Saurabh,Song Zexing,Hu Thomas,Kumar Aditi,Heit Jeremy,Coskun Ahmet F.","Allam M,Cai SY,Ganesh S,Venkatesan M,Doodhwala S,Song ZX,Hu T,Kumar A,Heit J,Coskun AF",Coskun AF,10.3390/diagnostics10060409,University System of Georgia,"The Coronavirus Disease 2019 (COVID-19), caused by the severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2), outbreak from Wuhan City, Hubei province, China in 2019 has become an ongoing global health emergency. The emerging virus, SARS-CoV-2, causes coughing, fever, muscle ache, and shortness of breath or dyspnea in symptomatic patients. The pathogenic particles that are generated by coughing and sneezing remain suspended in the air or attach to a surface to facilitate transmission in an aerosol form. This review focuses on the recent trends in pandemic biology, diagnostics methods, prevention tools, and policies for COVID-19 management. To meet the growing demand for medical supplies during the COVID-19 era, a variety of personal protective equipment (PPE) and ventilators have been developed using do-it-yourself (DIY) manufacturing. COVID-19 diagnosis and the prediction of virus transmission are analyzed by machine learning algorithms, simulations, and digital monitoring. Until the discovery of a clinically approved vaccine for COVID-19, pandemics remain a public concern. Therefore, technological developments, biomedical research, and policy development are needed to decipher the coronavirus mechanism and epidemiological characteristics, prevent transmission, and develop therapeutic drugs.","COVID-19,SARS-CoV-2,rapid testing,immunity,vaccines,3D printing,do-it-yourself,digital tracking,machine learning,pandemic policy",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"RESPIRATORY,SYNDROME,CORONAVIRUS,DISCOVERY,INHIBITOR,HEPATITIS,IMMUNITY",DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7344926,
57,Detection of Parkinson's Disease from 3T T1 Weighted MRI Scans Using 3D Convolutional Neural Network,10,6,,"Chakraborty Sabyasachi,Aich Satyabrata,Kim Hee-Cheol","Chakraborty S,Aich S,Kim HC",Aich S; Kim HC,10.3390/diagnostics10060402,Inje University,"Parkinson's Disease is a neurodegenerative disease that affects the aging population and is caused by a progressive loss of dopaminergic neurons in the substantia nigra pars compacta (SNc). With the onset of the disease, the patients suffer from mobility disorders such as tremors, bradykinesia, impairment of posture and balance, etc., and it progressively worsens in the due course of time. Additionally, as there is an exponential growth of the aging population in the world the number of people suffering from Parkinson's Disease is increasing and it levies a huge economic burden on governments. However, until now no therapeutic method has been discovered for completely eradicating the disease from a person's body after it's onset. Therefore, the early detection of Parkinson's Disease is of paramount importance to tackle the progressive loss of dopaminergic neurons in patients to serve them with a better life. In this study, 3T T1-weighted MRI scans were acquired from the Parkinson's Progression Markers Initiative (PPMI) database of 406 subjects from baseline visit, where 203 were healthy and 203 were suffering from Parkinson's Disease. Following data pre-processing, a 3D convolutional neural network (CNN) architecture was developed for learning the intricate patterns in the Magnetic Resonance Imaging (MRI) scans for the detection of Parkinson's Disease. In the end, it was observed that the developed 3D CNN model performed superiorly by completely aligning with the hypothesis of the study and plotted an overall accuracy of 95.29%, average recall of 0.943, average precision of 0.927, average specificity of 0.9430, f1-score of 0.936, and Receiver Operating Characteristic-Area Under Curve (ROC-AUC) score of 0.98 for both the classes respectively.","Parkinson's Disease,neurodegeneration,magnetic resonance imaging (MRI),convolutional neural network (CNN),deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,,"SUBSTANTIA-NIGRA,TEXTURE,ATLASES",DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7345307,
58,Weakly Labeled Data Augmentation for Deep Learning: A Study on COVID-19 Detection in Chest X-Rays,10,6,,"Rajaraman Sivaramakrishnan,Antani Sameer","Rajaraman S,Antani S",Rajaraman S,10.3390/diagnostics10060358,National Institutes of Health (NIH) - USA,"The novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused a pandemic resulting in over 2.7 million infected individuals and over 190,000 deaths and growing. Assertions in the literature suggest that respiratory disorders due to COVID-19 commonly present with pneumonia-like symptoms which are radiologically confirmed as opacities. Radiology serves as an adjunct to the reverse transcription-polymerase chain reaction test for confirmation and evaluating disease progression. While computed tomography (CT) imaging is more specific than chest X-rays (CXR), its use is limited due to cross-contamination concerns. CXR imaging is commonly used in high-demand situations, placing a significant burden on radiology services. The use of artificial intelligence (AI) has been suggested to alleviate this burden. However, there is a dearth of sufficient training data for developing image-based AI tools. We propose increasing training data for recognizing COVID-19 pneumonia opacities using weakly labeled data augmentation. This follows from a hypothesis that the COVID-19 manifestation would be similar to that caused by other viral pathogens affecting the lungs. We expand the training data distribution for supervised learning through the use of weakly labeled CXR images, automatically pooled from publicly available pneumonia datasets, to classify them into those with bacterial or viral pneumonia opacities. Next, we use these selected images in a stage-wise, strategic approach to train convolutional neural network-based algorithms and compare against those trained with non-augmented data. Weakly labeled data augmentation expands the learned feature space in an attempt to encompass variability in unseen test distributions, enhance inter-class discrimination, and reduce the generalization error. Empirical evaluations demonstrate that simple weakly labeled data augmentation (Acc: 0.5555 and Acc: 0.6536) is better than baseline non-augmented training (Acc: 0.2885 and Acc: 0.5028) in identifying COVID-19 manifestations as viral pneumonia. Interestingly, adding COVID-19 CXRs to simple weakly labeled augmented training data significantly improves the performance (Acc: 0.7095 and Acc: 0.8889), suggesting that COVID-19, though viral in origin, creates a uniquely different presentation in CXRs compared with other viral pneumonia manifestations.","augmentation,chest X-rays,convolutional neural network,COVID-19,deep learning,pneumonia,localization",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,,DIAGNOSTICS,https://www.mdpi.com/2075-4418/10/6/358/pdf,
59,Classification Models for Skin Tumor Detection Using Texture Analysis in Medical Images,6,6,,"Almeida Marcos A. M.,Santos Iury A. X.","Almeida MAM,Santos IAX",Almeida MAM,10.3390/jimaging6060051,Universidade Federal de Pernambuco,"Medical images have made a great contribution to early diagnosis. In this study, a new strategy is presented for analyzing medical images of skin with melanoma and nevus to model, classify and identify lesions on the skin. Machine learning applied to the data generated by first and second order statistics features, Gray Level Co-occurrence Matrix (GLCM), keypoints and color channel information-Red, Green, Blue and grayscale images of the skin were used to characterize decisive information for the classification of the images. This work proposes a strategy for the analysis of skin images, aiming to choose the best mathematical classifier model, for the identification of melanoma, with the objective of assisting the dermatologist in the identification of melanomas, especially towards an early diagnosis.","texture analysis,melanoma,glcm matrix,machine learning,classifiers",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Imaging Science & Photographic Technology,,,ALGORITHMS,JOURNAL OF IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321076,
60,Breast Tumor Classification Using an Ensemble Machine Learning Method,6,6,,"Assiri Adel S.,Nazir Saima,Velastin Sergio A.","Assiri AS,Nazir S,Velastin SA",Velastin SA,10.3390/jimaging6060039,Universidad Carlos III de Madrid,"Breast cancer is the most common cause of death for women worldwide. Thus, the ability of artificial intelligence systems to detect possible breast cancer is very important. In this paper, an ensemble classification mechanism is proposed based on a majority voting mechanism. First, the performance of different state-of-the-art machine learning classification algorithms were evaluated for the Wisconsin Breast Cancer Dataset (WBCD). The three best classifiers were then selected based on their F3 score. F3 score is used to emphasize the importance of false negatives (recall) in breast cancer classification. Then, these three classifiers, simple logistic regression learning, support vector machine learning with stochastic gradient descent optimization and multilayer perceptron network, are used for ensemble classification using a voting mechanism. We also evaluated the performance of hard and soft voting mechanism. For hard voting, majority-based voting mechanism was used and for soft voting we used average of probabilities, product of probabilities, maximum of probabilities and minimum of probabilities-based voting methods. The hard voting (majority-based voting) mechanism shows better performance with 99.42%, as compared to the state-of-the-art algorithm for WBCD.","breast cancer tumor,classification,majority-based voting mechanism,multilayer perceptron learning network,simple logistic regression,stochastic gradient descent learning,wisconsin breast cancer dataset",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Imaging Science & Photographic Technology,,,"CANCER,PREDICTION",JOURNAL OF IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321060,
61,Explainable Machine Learning Framework for Image Classification Problems: Case Study on Glioma Cancer Prediction,6,6,,"Pintelas Emmanuel,Liaskos Meletis,Livieris Ioannis E.,Kotsiantis Sotiris,Pintelas Panagiotis","Pintelas E,Liaskos M,Livieris IE,Kotsiantis S,Pintelas P",Pintelas E,10.3390/jimaging6060037,University of Patras,"Image classification is a very popular machine learning domain in which deep convolutional neural networks have mainly emerged on such applications. These networks manage to achieve remarkable performance in terms of prediction accuracy but they are considered as black box models since they lack the ability to interpret their inner working mechanism and explain the main reasoning of their predictions. There is a variety of real world tasks, such as medical applications, in which interpretability and explainability play a significant role. Making decisions on critical issues such as cancer prediction utilizing black box models in order to achieve high prediction accuracy but without provision for any sort of explanation for its prediction, accuracy cannot be considered as sufficient and ethnically acceptable. Reasoning and explanation is essential in order to trust these models and support such critical predictions. Nevertheless, the definition and the validation of the quality of a prediction model's explanation can be considered in general extremely subjective and unclear. In this work, an accurate and interpretable machine learning framework is proposed, for image classification problems able to make high quality explanations. For this task, it is developed a feature extraction and explanation extraction framework, proposing also three basic general conditions which validate the quality of any model's prediction explanation for any application domain. The feature extraction framework will extract and create transparent and meaningful high level features for images, while the explanation extraction framework will be responsible for creating good explanations relying on these extracted features and the prediction model's inner function with respect to the proposed conditions. As a case study application, brain tumor magnetic resonance images were utilized for predicting glioma cancer. Our results demonstrate the efficiency of the proposed model since it managed to achieve sufficient prediction accuracy being also interpretable and explainable in simple human terms.","image classification,image processing,white box,black box,cancer prediction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Imaging Science & Photographic Technology,,,,JOURNAL OF IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321040,
62,Explainable Deep Learning Models in Medical Image Analysis,6,6,,"Singh Amitojdeep,Sengupta Sourya,Lakshminarayanan Vasudevan","Singh A,Sengupta S,Lakshminarayanan V",Singh A,10.3390/jimaging6060052,University of Waterloo,"Deep learning methods have been very effective for a variety of medical diagnostic tasks and have even outperformed human experts on some of those. However, the black-box nature of the algorithms has restricted their clinical use. Recent explainability studies aim to show the features that influence the decision of a model the most. The majority of literature reviews of this area have focused on taxonomy, ethics, and the need for explanations. A review of the current applications of explainable deep learning for different medical imaging tasks is presented here. The various approaches, challenges for clinical deployment, and the areas requiring further research are discussed here from a practical standpoint of a deep learning researcher designing a system for the clinical end-users.","explainability,explainable AI,XAI,deep learning,medical imaging,diagnosis",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Imaging Science & Photographic Technology,,,CLASSIFICATION,JOURNAL OF IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321083,
63,Deep Multimodal Learning for the Diagnosis of Autism Spectrum Disorder,6,6,,"Tang Michelle,Kumar Pulkit,Chen Hao,Shrivastava Abhinav","Tang M,Kumar P,Chen H,Shrivastava A",Shrivastava A,10.3390/jimaging6060047,University System of Maryland,"Recent medical imaging technologies, specifically functional magnetic resonance imaging (fMRI), have advanced the diagnosis of neurological and neurodevelopmental disorders by allowing scientists and physicians to observe the activity within and between different regions of the brain. Deep learning methods have frequently been implemented to analyze images produced by such technologies and perform disease classification tasks; however, current state-of-the-art approaches do not take advantage of all the information offered by fMRI scans. In this paper, we propose a deep multimodal model that learns a joint representation from two types of connectomic data offered by fMRI scans. Incorporating two functional imaging modalities in an automated end-to-end autism diagnosis system will offer a more comprehensive picture of the neural activity, and thus allow for more accurate diagnoses. Our multimodal training strategy achieves a classification accuracy of 74% and a recall of 95%, as well as an F1 score of 0.805, and its overall performance is superior to using only one type of functional data.","deep learning,multimodal learning,convolutional neural networks,autism,fMRI",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Imaging Science & Photographic Technology,,,,JOURNAL OF IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321065,
64,Disturbance Simulation in the Packaging Process of Confectionary Using Virtual Commissioning,8,2,,"Wolf Johanna,Carsch Sebastian,Troll Clemens,Majschak Jens-Peter","Wolf J,Carsch S,Troll C,Majschak JP",Wolf J,10.3390/machines8020019,Fraunhofer Gesellschaft,"Operator assistance systems can help to reduce disturbance-related machine downtime in food production and packaging processes, especially when combined with machine learning algorithms. These assistance systems analyze the available sensor signals of the process control over time to help operators identify the causes of disturbances. Training such systems requires sufficient test data, which often are hardly available. Thus, this paper presents a study to investigate how test data for teaching machine learning algorithms can be generated by numerical simulation. The potential of using virtual commissioning (VC) software for simulating disturbances of discrete processes is examined, considering the example of a friction and collision-afflicted sub-process from an intermitting wrapping machine for confectionary. In this study the software industrialPhysics (iP) is analyzed regarding accuracy of static and dynamic friction and restitution. The values are verified by setting up virtual substitute tests and comparing the results with analytically determined values. Subsequently, prerecorded disturbances are classified, and seven selected elements are simulated in VC software, recording visual effects and switching the characteristics of sensors. The verification shows that VC software is generally adequate for the assigned task. Restrictions occur regarding the computing power required of the built-in physics engine and the resulting reduction of the machine to be simulated.","virtual commissioning,disturbance simulation,packaging machines",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Engineering,,2.467,DECISION-SUPPORT-SYSTEM,MACHINES,https://www.mdpi.com/2075-1702/8/2/19/pdf,
65,Discrimination of Object Curvature Based on a Sparse Tactile Sensor Array,11,6,,"Liu Weiting,Zhan Binpeng,Gu Chunxin,Yu Ping,Zhang Guoshi,Fu Xin,Cipriani Christian,Hu Liang","Liu WT,Zhan BP,Gu CX,Yu P,Zhang GS,Fu X,Cipriani C,Hu L",Hu L,10.3390/mi11060583,Zhejiang University,"Object curvature plays an important role in grasping and manipulation. To be more exact, local curvature is a more useful information for grasping practically. Vision and touch are the two main methods to extract surface curvature of an object, but vision is often limited since the complete contact area is invisible during manipulation. In this paper, the authors propose an object curvature estimation method based on an artificial neural network algorithm through a lab-developed sparse tactile sensor array. The compliant layer covering on the sensor is indispensable for fitting the curved surface. Three types (plane, convex sphere, and convex cylinder) of sample and each type of sample including 30 different radiuses (1 mm to 30 mm) were used in the experiment. The overall classification accuracy was 93.1%. The average curvature radius estimating error based on an artificial neural network (ANN) algorithm was 1.87 mm. When the radius of curvature was bigger than 5 mm, the average relative error was smaller than 20%. As a comparison, the sensor array density we used in this paper was less than 9/cm(2), which was smaller than the density of human SAII receptors, but the discrimination result was close to the SAII receptors. Comparison with the curvature discrimination ability of the human body showed that this method has a promising application prospect.","sparse tactile sensor array,machine learning,neural network,discrimination of curvature,compliant contact",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Science & Technology - Other Topics,Instruments & Instrumentation,Physics",,2.943,"INFORMATION,FINGERTIPS,AFFERENTS",MICROMACHINES,https://europepmc.org/articles/pmc7344426?pdf=render,
66,An Interpretable Extreme Gradient Boosting Model to Predict Ash Fusion Temperatures,10,6,,"Rzychon Maciej,Zogala Alina,Rog Leokadia","Rzychon M,Zogala A,Rog L",Rzychon M,10.3390/min10060487,Central Mining Institute (GIG),"The hemispherical temperature (HT) is the most important indicator representing ash fusion temperatures (AFTs) in the Polish industry to assess the suitability of coal for combustion as well as gasification purposes. It is important, for safe operation and energy saving, to know or to be able to predict value of this parameter. In this study a non-linear model predicting the HT value, based on ash oxides content for 360 coal samples from the Upper Silesian Coal Basin, was developed. The proposed model was established using the machine learning method-extreme gradient boosting (XGBoost) regressor. An important feature of models based on the XGBoost algorithm is the ability to determine the impact of individual input parameters on the predicted value using the feature importance (FI) technique. This method allowed the determination of ash oxides having the greatest impact on the projected HT. Then, the partial dependence plots (PDP) technique was used to visualize the effect of individual oxides on the predicted value. The results indicate that proposed model could estimate value of HT with high accuracy. The coefficient of determination (R-2) of the prediction has reached satisfactory value of 0.88.","ash fusion temperature,XGBoost,feature importance,partial dependence plots,chemical ash composition",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Geochemistry & Geophysics,Mineralogy,Mining & Mineral Processing",,2.737,"COAL,ASH,CHEMICAL-COMPOSITION,COMBUSTION,BEHAVIOR",MINERALS,https://www.mdpi.com/2075-163X/10/6/487/pdf,
67,A Feed-Forward Back Propagation Neural Network Approach to Predict the Life Condition of Crude Oil Pipeline,8,6,,"Shaik Nagoor Basha,Pedapati Srinivasa Rao,Taqvi Syed Ali Ammar,Othman A. R.,Abd Dzubir Faizul Azly","Shaik NB,Pedapati SR,Taqvi SAA,Othman AR,Abd Dzubir FA",Pedapati SR,10.3390/pr8060661,Universiti Teknologi Petronas,"Pipelines are like a lifeline that is vital to a nation's economic sustainability; as such, pipelines need to be monitored to optimize their performance as well as reduce the product losses incurred in the transportation of petroleum chemicals. A significant number of pipes would be underground; it is of immediate concern to identify and analyse the level of corrosion and assess the quality of a pipe. Therefore, this study intends to present the development of an intelligent model that predicts the condition of crude oil pipeline cantered on specific factors such as metal loss anomalies (over length, width and depth), wall thickness, weld anomalies and pressure flow. The model is developed using Feed-Forward Back Propagation Network (FFBPN) based on historical inspection data from oil and gas fields. The model was trained using the Levenberg-Marquardt algorithm by changing the number of hidden neurons to achieve promising results in terms of maximum Coefficient of determination (R-2) value and minimum Mean Squared Error (MSE). It was identified that a strong R-2 value depends on the number of hidden neurons. The model developed with 16 hidden neurons accurately predicted the Estimated Repair Factor (ERF) value with an R-2 value of 0.9998. The remaining useful life (RUL) of a pipeline is estimated based on the metal loss growth rate calculations. The deterioration profiles of considered factors are generated to identify the individual impact on pipeline condition. The proposed FFBPN was validated with other published models for its robustness and it was found that FFBPN performed better than the previous approaches. The deterioration curves were generated and it was found that pressure has major negative affect on pipeline condition and weld girth has a minor negative affect on pipeline condition. This study can help petroleum and natural gas industrial operators assess the life condition of existing pipelines and thus enhances their inspection and rehabilitation forecasting.","pipeline,artificial neural networks,life prediction,deterioration,estimated repair factor",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Engineering,,2.824,"FAILURE,MODEL",PROCESSES,https://www.mdpi.com/2227-9717/8/6/661/pdf,
68,Retinal Blood Vessel Segmentation Using Hybrid Features and Multi-Layer Perceptron Neural Networks,12,6,,"Tamim Nasser,Elshrkawey M.,Azim Gamil Abdel,Nassar Hamed","Tamim N,Elshrkawey M,Azim GA,Nassar H",Tamim N; Nassar H,10.3390/sym12060894,Egyptian Knowledge Bank (EKB),"Segmentation of retinal blood vessels is the first step for several computer aided-diagnosis systems (CAD), not only for ocular disease diagnosis such as diabetic retinopathy (DR) but also of non-ocular disease, such as hypertension, stroke and cardiovascular diseases. In this paper, a supervised learning-based method, using a multi-layer perceptron neural network and carefully selected vector of features, is proposed. In particular, for each pixel of a retinal fundus image, we construct a 24-D feature vector, encoding information on the local intensity, morphology transformation, principal moments of phase congruency, Hessian, and difference of Gaussian values. A post-processing technique depending on mathematical morphological operators is used to optimise the segmentation. Moreover, the selected feature vector succeeded in outfitting the symmetric features that provided the final blood vessel probability as a binary map image. The proposed method is tested on three known datasets: Digital Retinal Image for Extraction (DRIVE), Structure Analysis of the Retina (STARE), and CHASED_DB1 datasets. The experimental results, both visual and quantitative, testify to the robustness of the proposed method. This proposed method achieved 0.9607, 0.7542, and 0.9843 in DRIVE, 0.9632, 0.7806, and 0.9825 on STARE, 0.9577, 0.7585 and 0.9846 in CHASE_DB1, with respectable accuracy, sensitivity, and specificity performance metrics. Furthermore, they testify that the method is superior to seven similar state-of-the-art methods.","retinal image analysis,edge detection,feature extraction,blood vessel segmentation,medical imaging,pattern recognition",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"IMAGES,ENHANCEMENT,DELINEATION,LEVEL,SET",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/6/894/pdf,
69,Gaussians on Riemannian Manifolds: Applications for Robot Learning and Adaptive Control,27,2,33-45,Calinon Sylvain,Calinon S,Calinon S,10.1109/MRA.2020.2980548,"Idiap Res Inst, Martigny, Switzerland.","This article presents an overview of robot learning and adaptive control applications that can benefit from a joint use of Riemannian geometry and probabilistic representations. The roles of Riemannian manifolds, geodesics, and parallel transport in robotics are discussed, and several forms of manifolds already employed in robotics are explained. A varied range of techniques employing Gaussian distributions on Riemannian manifolds is then introduced, and two example applications are presented, involving the control of a prosthetic hand from surface electromyography (sEMG) data and the teleoperation of a bimanual underwater robot.","Manifolds,Geometry,Robot sensing systems,Robot learning,Adaptive control,Covariance matrices",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Robotics",,5.39,OPTIMIZATION,IEEE ROBOTICS & AUTOMATION MAGAZINE,http://arxiv.org/pdf/1909.05946,
70,A Multistage Deep Residual Network for Biomedical Cyber-Physical Systems,14,2,1953-1962,"Pandey Ankur,Sequeria Ryan,Kumar Preetam,Kumar Sudhir","Pandey A,Sequeria R,Kumar P,Kumar S",Pandey A,10.1109/JSYST.2019.2923670,Indian Institute of Technology (IIT) - Patna,"In this paper, we propose a novel biomedical cyber-physical system for automated and efficient arrhythmia and seizure detection in the time-series biomedical signals such as electrocardiogram (ECG) and electroencephalography (EEG). We use a novel multilayer, automated, and multistage deep residual network for the anomaly detection in the biomedical signals. Generally, the biomedical datasets have class imbalance problem; hence, we leverage the concepts of undersampling techniques to address this issue. The proposed algorithm is validated on the publicly available benchmark MIT-BIH Arrhythmia and CHB-MIT Scalp databases. The results show a significant improvement in terms of the sensitivity of 90% and 97.1% for supraventricular and ventricular beats for best fold, respectively. The accuracy obtained is at par with most of the state-of-the-art methods, and in particular, for the supraventricular beats, the proposed method outperforms all but one state-of-the-art method. The advantage of the proposed method is that it gives reliable results with EEG samples of small duration and, as opposed to other state-of-the-artmethods, it does not involve any preprocessing, hence computationally efficient. Additionally, the proposed algorithm provides 81% sensitivity for seizure detection in EEG signals, which is comparable to existing deep learning methods.","Anomaly detection,biomedical monitoring,cyber-physical systems (CPS),electrocardiogram (ECG),electroencephalography (EEG),residual learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Operations Research & Management Science,Telecommunications",,4.193,"PREDICTING,EPILEPTIC,SEIZURES,CLASSIFICATION",IEEE SYSTEMS JOURNAL,,
71,Patient-derived model systems and the development of next-generation anticancer therapeutics,56,,72-78,"Krall Nikolaus,Superti-Furga Giulio,Vladimer Gregory I","Krall N,Superti-Furga G,Vladimer GI",Vladimer GI,10.1016/j.cbpa.2020.01.002,"Allcyte GmbH, A-1030 Vienna, Austria.","Anticancer drug discovery and development using conventional cell line and animal models has traditionally had a low overall success rate. Despite yielding game-changing new therapeutics, 10-20 new molecules have to be brought to the clinic to obtain one new approval, making this approach costly and inefficient. The use of in vitro experimental models based on primary human tumour tissues has the potential to provide a representation of human cancer biology that is closer to an actual patient and to 'bridge the translational gap' between preclinical and clinical research. Here, we review recent advances in the use of human tumour samples for preclinical research through organoid development or as primary patient materials. While challenges still remain regarding analysis, validation and scalability, evidence is mounting for the applicability of both models as preclinical research tools.","Primary cancer models,Screening,Drug discovery,Translational medicine,High-content screening,Machine learning,Organoids,Primary patient samples,Single-cell imaging,Single-cell analysis",Review,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Biochemistry & Molecular Biology,Biophysics",,8.721,"ORGANOID,MODELS,CANCER,STRATEGY",CURRENT OPINION IN CHEMICAL BIOLOGY,,
72,Combination possibility and deep learning model as clinical decision-aided approach for prostate cancer,26,2,945-962,"Eminaga Okyaz,Al-Hamad Omran,Boegemann Martin,Breil Bernhard,Semjonow Axel","Eminaga O,Al-Hamad O,Boegemann M,Breil B,Semjonow A",Eminaga O,10.1177/1460458219855884,Stanford University,This study aims to introduce as proof of concept a combination model for classification of prostate cancer using deep learning approaches. We utilized patients with prostate cancer who underwent surgical treatment representing the various conditions of disease progression. All possible combinations of significant variables from logistic regression and correlation analyses were determined from study data sets. The combination possibility and deep learning model was developed to predict these combinations that represented clinically meaningful patient's subgroups. The observed relative frequencies of different tumor stages and Gleason score Gls changes from biopsy to prostatectomy were available for each group. Deep learning models and seven machine learning approaches were compared for the classification performance of Gleason score changes and pT2 stage. Deep models achieved the highest F1 scores by pT2 tumors (0.849) and Gls change (0.574). Combination possibility and deep learning model is a useful decision-aided tool for prostate cancer and to group patients with prostate cancer into clinically meaningful groups.,"classification model,combination and learn model,deep learning,pathology,prediction model,prostate cancer,risk classification,SEER,wide learning",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA","Health Care Sciences & Services,Medical Informatics",,3.0,"BIOPSY,GLEASON,SCORE,PREDICTION,MODEL,RADICAL,PROSTATECTOMY,ACTIVE,SURVEILLANCE,PATHOLOGICAL,STAGE,PARTIN,TABLES,VALIDATION,RISK,SURVIVAL,MEN",HEALTH INFORMATICS JOURNAL,https://journals.sagepub.com/doi/pdf/10.1177/1460458219855884,
73,Detecting nematic order in STM/STS data with artificial intelligence,8,6,,"Goetz Jeremy B.,Zhang Yi,Lawler Michael J.","Goetz JB,Zhang Y,Lawler MJ",Lawler MJ,10.21468/SciPostPhys.8.6.087,State University of New York (SUNY) System,"Detecting the subtle yet phase defining features in Scanning Tunneling Microscopy and Spectroscopy data remains an important challenge in quantum materials. We meet the challenge of detecting nematic order from the local density of states data with supervised machine learning and artificial neural networks for the difficult scenario without sharp features such as visible lattice Bragg peaks or Friedel oscillation signatures in the Fourier transform spectrum. We train the artificial neural networks to classify simulated data of symmetric and nematic two-dimensional metals in the presence of disorder. The supervised machine learning succeeds only with at least one hidden layer in the ANN architecture, demonstrating it is a higher level of complexity than a nematic order detected from Bragg peaks, which requires just two neurons. We apply the finalized ANN to experimental STM data on CaFe2As2, and it predicts nematic symmetry breaking with dominating confidence, in agreement with previous analysis. Our results suggest ANNs could be a useful tool for the detection of nematic order in STM data and a variety of other forms of symmetry breaking.",STATES,Article,"SCIPOST FOUNDATION, C/O J S CAUX, INST PHYSICS, UNIV AMSTERDAM, AMSTERDAM, 1098 XH, NETHERLANDS",Physics,,5.889,STATES,SCIPOST PHYSICS,http://arxiv.org/pdf/1901.11042,
74,Computer-Aided Bacillus Detection in Whole-Slide Pathological Images Using a Deep Convolutional Neural Network,10,12,,"Lo Chung-Ming,Wu Yu-Hung,Li Yu-Chuan (Jack),Lee Chieh-Chi","Lo CM,Wu YH,Li YC,Lee CC",Lo CM,10.3390/app10124059,Taipei Medical University,"Mycobacterial infections continue to greatly affect global health and result in challenging histopathological examinations using digital whole-slide images (WSIs), histopathological methods could be made more convenient. However, screening for stained bacilli is a highly laborious task for pathologists due to the microscopic and inconsistent appearance of bacilli. This study proposed a computer-aided detection (CAD) system based on deep learning to automatically detect acid-fast stained mycobacteria. A total of 613 bacillus-positive image blocks and 1202 negative image blocks were cropped from WSIs (at approximately 20 x 20 pixels) and divided into training and testing samples of bacillus images. After randomly selecting 80% of the samples as the training set and the remaining 20% of samples as the testing set, a transfer learning mechanism based on a deep convolutional neural network (DCNN) was applied with a pretrained AlexNet to the target bacillus image blocks. The transferred DCNN model generated the probability that each image block contained a bacillus. A probability higher than 0.5 was regarded as positive for a bacillus. Consequently, the DCNN model achieved an accuracy of 95.3%, a sensitivity of 93.5%, and a specificity of 96.3%. For samples without color information, the performances were an accuracy of 73.8%, a sensitivity of 70.7%, and a specificity of 75.4%. The proposed DCNN model successfully distinguished bacilli from other tissues with promising accuracy. Meanwhile, the contribution of color information was revealed. This information will be helpful for pathologists to establish a more efficient diagnostic procedure.","digital pathology,whole-slide images,mycobacterial infection,convolutional neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"MYCOBACTERIUM-TUBERCULOSIS,DIGITAL,PATHOLOGY,LEVEL,CLASSIFICATION,IDENTIFICATION,DIAGNOSIS,CHALLENGES,PREVENTION,MICROSCOPY,TISSUE,SPUTUM",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/12/4059/pdf,
75,Hyperspectral Imaging for Skin Feature Detection: Advances in Markerless Tracking for Spine Surgery,10,12,,"Manni Francesca,van der Sommen Fons,Zinger Svitlana,Shan Caifeng,Holthuizen Ronald,Lai Marco,Bustrom Gustav,Hoveling Richelle J. M.,Edstrom Erik,Elmi-Terander Adrian","Manni F,van der Sommen F,Zinger S,Shan CF,Holthuizen R,Lai M,Bustrom G,Hoveling RJM,Edstrom E,Elmi-Terander A",Manni F,10.3390/app10124078,Eindhoven University of Technology,"Featured Application Current spinal navigation systems rely on optical reference markers to detect the patient's position. To bypass the use of current reference marker solutions, our work aims at a reliable and simple skin feature detection technology for improving clinical workflow during spine surgery. Unfortunately, reference markers or reference frames can be displaced or obscured during the surgical procedures. We present a solution by applying hyperspectral imaging (HSI) to directly detect skin features for navigation. The initial results demonstrate that HSI has the potential to replace marker-based solutions and can serve as a platform for the further development of markerless tracking. In spinal surgery, surgical navigation is an essential tool for safe intervention, including the placement of pedicle screws without injury to nerves and blood vessels. Commercially available systems typically rely on the tracking of a dynamic reference frame attached to the spine of the patient. However, the reference frame can be dislodged or obscured during the surgical procedure, resulting in loss of navigation. Hyperspectral imaging (HSI) captures a large number of spectral information bands across the electromagnetic spectrum, providing image information unseen by the human eye. We aim to exploit HSI to detect skin features in a novel methodology to track patient position in navigated spinal surgery. In our approach, we adopt two local feature detection methods, namely a conventional handcrafted local feature and a deep learning-based feature detection method, which are compared to estimate the feature displacement between different frames due to motion. To demonstrate the ability of the system in tracking skin features, we acquire hyperspectral images of the skin of 17 healthy volunteers. Deep-learned skin features are detected and localized with an average error of only 0.25 mm, outperforming the handcrafted local features with respect to the ground truth based on the use of optical markers.","hyperspectral imaging,feature detection,spine surgery,markerless tracking,deep local features",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"PEDICLE,SCREW,PLACEMENT,AUGMENTED,REALITY,BAND,SELECTION,ACCURACY,LUMBAR,INSTRUMENTATION,FEASIBILITY,TECHNOLOGY,3D",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/12/4078/pdf,
76,Development of a Deep Learning-Based Algorithm to Detect the Distal End of a Surgical Instrument,10,12,,"Sugimori Hiroyuki,Sugiyama Taku,Nakayama Naoki,Yamashita Akemi,Ogasawara Katsuhiko","Sugimori H,Sugiyama T,Nakayama N,Yamashita A,Ogasawara K",Sugiyama T,10.3390/app10124245,Hokkaido University,"This work aims to develop an algorithm to detect the distal end of a surgical instrument using object detection with deep learning. We employed nine video recordings of carotid endarterectomies for training and testing. We obtained regions of interest (ROI; 32 x 32 pixels), at the end of the surgical instrument on the video images, as supervised data. We applied data augmentation to these ROIs. We employed a You Only Look Once Version 2 (YOLOv2) -based convolutional neural network as the network model for training. The detectors were validated to evaluate average detection precision. The proposed algorithm used the central coordinates of the bounding boxes predicted by YOLOv2. Using the test data, we calculated the detection rate. The average precision (AP) for the ROIs, without data augmentation, was 0.4272 +/- 0.108. The AP with data augmentation, of 0.7718 +/- 0.0824, was significantly higher than that without data augmentation. The detection rates, including the calculated coordinates of the center points in the centers of 8 x 8 pixels and 16 x 16 pixels, were 0.6100 +/- 0.1014 and 0.9653 +/- 0.0177, respectively. We expect that the proposed algorithm will be efficient for the analysis of surgical records.","object detection,deep learning,surgical video analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"SKILL,SEGMENTATION,TRACKING,TISSUE",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/12/4245/pdf,
77,High-Throughput MicroRNA Profiling of Vitreoretinal Lymphoma: Vitreous and Serum MicroRNA Profiles Distinct from Uveitis,9,6,,"Minezaki Teruumi,Usui Yoshihiko,Asakage Masaki,Takanashi Masakatsu,Shimizu Hiroyuki,Nezu Naoya,Narimatsu Akitomo,Tsubota Kinya,Umazume Kazuhiko,Yamakawa Naoyuki","Minezaki T,Usui Y,Asakage M,Takanashi M,Shimizu H,Nezu N,Narimatsu A,Tsubota K,Umazume K,Yamakawa N",Usui Y,10.3390/jcm9061844,Tokyo Medical University,"Purpose: Vitreoretinal lymphoma (VRL) is a non-Hodgkin lymphoma of the diffuse large B cell type (DLBCL), which is an aggressive cancer causing central nervous system related mortality. The pathogenesis of VRL is largely unknown. The role of microRNAs (miRNAs) has recently acquired remarkable importance in the pathogenesis of many diseases including cancers. Furthermore, miRNAs have shown promise as diagnostic and prognostic markers of cancers. In this study, we aimed to identify differentially expressed miRNAs and pathways in the vitreous and serum of patients with VRL and to investigate the pathogenesis of the disease. Materials and Methods: Vitreous and serum samples were obtained from 14 patients with VRL and from controls comprising 40 patients with uveitis, 12 with macular hole, 14 with epiretinal membrane, 12 healthy individuals. The expression levels of 2565 miRNAs in serum and vitreous samples were analyzed. Results: Expression of the miRNAs correlated significantly with the extracellular matrix (ECM) -receptor interaction pathway in VRL. Analyses showed that miR-326 was a key driver of B-cell proliferation, and miR-6513-3p could discriminate VRL from uveitis. MiR-1236-3p correlated with vitreous interleukin (IL)-10 concentrations. Machine learning analysis identified miR-361-3p expression as a discriminator between VRL and uveitis. Conclusions: Our findings demonstrate that aberrant microRNA expression in VRL may affect the expression of genes in a variety of cancer-related pathways. The altered serum miRNAs may discriminate VRL from uveitis, and serum miR-6513-3p has the potential to serve as an auxiliary tool for the diagnosis of VRL.","vitreoretinal lymphoma,microRNA,uveitis,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,,"B-CELL,LYMPHOMA,CD44,EXPRESSION,PROGNOSTIC-SIGNIFICANCE,EPIDEMIOLOGIC,SURVEY,CLINICAL-FEATURES,HIPPO,PATHWAY,VALUABLE,TOOL,PROLIFERATION,PATHOGENESIS,CANCER",JOURNAL OF CLINICAL MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7356511,
78,Diagnosis of Diabetes Based on Analysis of Exhaled Air by Terahertz Spectroscopy and Machine Learning,128,6,809-814,"Kistenev Yu V,Teteneva A. V,Sorokina T. V,Knyazkova A. I,Zakharova O. A.,Cuisset A.,Vaks V. L.,Domracheva E. G.,Chernyaeva M. B.,Anfertev V. A.","Kistenev YV,Teteneva AV,Sorokina TV,Knyazkova AI,Zakharova OA,Cuisset A,Vaks VL,Domracheva EG,Chernyaeva MB,Anfertev VA",Kistenev YV,10.1134/S0030400X20060090,Tomsk State University,"Results of studying the exhaled air of patients with diabetes mellitus in comparison with healthy volunteers with the use of broadband terahertz time-domain spectroscopy are presented. Typical spectral subranges in which absorption spectrum profiles of breath tests of the target and control group differ most significantly are revealed: 0.560, 0.738, 0.970, 1.070, 1.140, 1.180, and 1.400 THz. Using the principal component analysis, it is shown that the set of absorption coefficients in these regions allows one to reliably separate the target and control groups. The obtained results are compared with measurements of acetone vapors in the exhaled air of patients with diabetes mellitus and healthy volunteers.","diabetes,expired air,terahertz spectroscopy,machine learning",Article,"PLEIADES PUBLISHING INC, PLEIADES PUBLISHING INC, MOSCOW, 00000, RUSSIA","Optics,Spectroscopy",,0.671,"OXIDATIVE,STRESS,TYPE-2,MELLITUS,BIOMARKERS,MARKERS",OPTICS AND SPECTROSCOPY,,
79,Autonomous Fire Resistance Evaluation,146,6,,Naser M. Z.,Naser MZ,Naser MZ,10.1061/(ASCE)ST.1943-541X.0002641,Clemson University,"The structural fire engineering community has been slowly evolving over the past few decades. While we continue to favor a classical stand toward evaluating fire resistance of structures through fire experimentations, a movement toward developing numerical assessment tools is on the rise. A close examination of notable works shows that the majority of these tools continue to have limited scalability, lack standardization, and thorough validation. Perhaps two of the main challenges of adopting such tools can be summed by their need for collecting true representation of response parameters (e.g., temperature-dependent material properties, etc.), and necessity to carry out resource-intensive two-stage thermo-structural analysis. In order to overcome such challenges, and in pursuit of modernizing fire resistance evaluation, this paper introduces a new generation of fire-based evaluation tools that capitalize on perception rather than imitation. More specifically, this paper explores how automation and cognition (A&C), realized through machine learning (ML), can be applied to comprehend structural behavior under fire conditions. To achieve this goal, genetic programing (GP) and computer vision (CV) are used to assess fire response of structural members. The outcome of this study demonstrates that A&C can accurately evaluate fire resistance and identify damage/spalling magnitude in reinforced concrete (RC) structures; thus, paving the way to realize autonomous fire-based evaluation and inspection. (C) 2020 American Society of Civil Engineers.","Fire resistance,Automation,Cognition,Machine learning",Article,"ASCE-AMER SOC CIVIL ENGINEERS, 1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA","Construction & Building Technology,Engineering",,3.82,"REINFORCED-CONCRETE,COLUMNS,RC,BEAMS,MECHANICAL-PROPERTIES,STRENGTH,PERFORMANCE,BEHAVIOR,PREDICTION,MODEL",JOURNAL OF STRUCTURAL ENGINEERING,,
80,Molecular and DNA Artificial Neural Networks via Fractional Coding,14,3,490-503,"Liu Xingyi,Parhi Keshab K.","Liu XY,Parhi KK",Parhi KK,10.1109/TBCAS.2020.2979485,University of Minnesota System,"This article considers implementation of artificial neural networks (ANNs) using molecular computing and DNA based on fractional coding. Prior work had addressed molecular two-layer ANNs with binary inputs and arbitrary weights. In prior work using fractional coding, a simple molecular perceptron that computes sigmoid of scaled weighted sum of the inputs was presented where the inputs and the weights lie between [-1,1]. Even for computing the perceptron, the prior approach suffers from two major limitations. First, it cannot compute the sigmoid of the weighted sum, but only the sigmoid of the scaled weighted sum. Second, many machine learning applications require the coefficients to be arbitrarily positive and negative numbers that are not bounded between [-1,1]; such numbers cannot be handled by the prior perceptron using fractional coding. This paper makes four contributions. First molecular perceptrons that can handle arbitrary weights and can compute sigmoid of the weighted sums are presented. Thus, these molecular perceptrons are ideal for regression applications and multi-layer ANNs. A new molecular divider is introduced and is used to compute sigmoid(ax) where a > 1. Second, based on fractional coding, a molecular artificial neural network (ANN) with one hidden layer is presented. Third, a trained ANN classifier with one hidden layer from seizure prediction application from electroencephalogram is mapped to molecular reactions and DNA and their performances are presented. Fourth, molecular activation functions for rectified linear unit (ReLU) and softmax are also presented.","DNA,Encoding,Proteins,Protein engineering,Neural networks,Medical treatment,Molecular computing,Artificial neural network (ANN),DNA,fractional coding,molcular ReLU,molecular divider,molecular neural networks,molecular sigmoid,molecular softmax,stochastic logic",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,"SYNTHETIC,BIOLOGY,COMPUTATION,ANALOG,ARCHITECTURES,CONSTRUCTION,LOGIC",IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,http://arxiv.org/pdf/1910.05643,
81,A Noninvasive Glucose Monitoring SoC Based on Single Wavelength Photoplethysmography,14,3,504-515,"Hina Aminah,Saadeh Wala","Hina A,Saadeh W",Saadeh W,10.1109/TBCAS.2020.2979514,Lahore University of Management Sciences,"Conventional glucose monitoring methods for the growing numbers of diabetic patients around the world are invasive, painful, costly and, time-consuming. Complications aroused due to the abnormal blood sugar levels in diabetic patients have created the necessity for continuous noninvasive glucose monitoring. This article presents a wearable system for glucose monitoring based on a single wavelength near-infrared (NIR) Photoplethysmography (PPG) combined with machine-learning regression (MLR). The PPG readout circuit consists of a switched capacitor Transimpedance amplifier with 1 M omega gain and a 10-Hz switched capacitor LPF. It allows a DC bias current rejection up to 20 mu A with an input-referred current noise of 7.3 pA/root Hz. The proposed digital processor eliminates motion artifacts, and baseline drifts from PPG signal, extracts six distinct features and finally predicts the blood glucose level using Support Vector Regression with Fine Gaussian kernel (FGSVR) MLR. A novel piece-wise linear (PWL) approach for the exponential function is proposed to realize the FGSVR on-chip. The overall system is implemented using a 180 nm CMOS process with a chip area of 4.0 mm(2) while consuming 1.62 mW. The glucose measurements are performed for 200 subjects with R-2 of 0.937. The proposed system accurately predicts the sugar level with a mean absolute relative difference (mARD) of 7.62%.","Sugar,Light emitting diodes,Monitoring,Diabetes,Feature extraction,Clocks,Biomedical monitoring,Glucose Monitoring,near-infrared (NIR),Photoplethysmography (PPG),wearable devices",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,SYSTEM,IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,,
82,Adaptive Sedation Monitoring From EEG in ICU Patients With Online Learning,67,6,1696-1706,"Zheng Wei-Long,Sun Haoqi,Akeju Oluwaseun,Westover M. Brandon","Zheng WL,Sun HQ,Akeju O,Westover MB",Westover MB,10.1109/TBME.2019.2943062,Harvard University,"Sedative medications are routinely administered to provide comfort and facilitate clinical care in critically ill ICU patients. Prior work shows that brain monitoring using electroencephalography (EEG) to track sedation levels may help medical personnel to optimize drug dosing and avoid the adverse effects of oversedation and undersedation. However, the performance of sedation monitoring methods proposed to date deal poorly with individual variability across patients, leading to inconsistent performance. To address this challenge we develop an online learning approach based on Adaptive Regularization of Weight Vectors (AROW). Our approach adaptively updates a sedation level prediction algorithm under a continuously evolving data distribution. The prediction model is gradually calibrated for individual patients in response to EEG observations and routine clinical assessments over time. The evaluations are performed on a population of 172 sedated ICU patients whose sedation levels were assessed using the Richmond Agitation-Sedation Scale (scores between -5 = comatose and 0 = awake). The proposed adaptive model achieves better performance than the same model without adaptation (average accuracies with tolerance of one level difference: 68.76% vs. 61.10%). Moreover, our approach is shown to be robust to sudden changes caused by label noise. Medication administrations have different effects on model performance. We find that the model performs best in patients receiving only propofol, compared to patients receiving no sedation or multiple simultaneous sedative medications.","Electroencephalography,Brain modeling,Monitoring,Adaptation models,Training,Predictive models,Data models,Sedation monitoring,electroencephalography (EEG),online learning,Richmond Agitation-Sedation Scale,intensive care unit,level of consciousness",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,,"BISPECTRAL,INDEX,DEPTH,ANESTHESIA,DELIRIUM,LEVEL",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7085963,
83,Stable Responsive EMG Sequence Prediction and Adaptive Reinforcement With Temporal Convolutional Networks,67,6,1707-1717,"Betthauser Joseph L.,Krall John T.,Bannowsky Shain G.,Levay Gyorgy,Kaliki Rahul R.,Fifer Matthew S.,Thakor Nitish V","Betthauser JL,Krall JT,Bannowsky SG,Levay G,Kaliki RR,Fifer MS,Thakor NV",Betthauser JL,10.1109/TBME.2019.2943309,Johns Hopkins University,"Prediction of movement intentions from electromyographic (EMG) signals is typically performed with a pattern recognition approach, wherein a short dataframe of raw EMG is compressed into an instantaneous feature-encoding that is meaningful for classification. However, EMG signals are time-varying, implying that a frame-wise approach may not sufficiently incorporate temporal context into predictions, leading to erratic and unstable prediction behavior. Objective: We demonstrate that sequential prediction models and, specifically, temporal convolutional networks are able to leverage useful temporal information from EMG to achieve superior predictive performance. Methods: We compare this approach to other sequential and frame-wise models predicting 3 simultaneous hand and wrist degrees-of-freedom from 2 amputee and 13 non-amputee human subjects in a minimally constrained experiment. We also compare these models on the publicly available Ninapro and CapgMyo amputee and non-amputee datasets. Results: Temporal convolutional networks yield predictions that are more accurate and stable (p < 0.001) than frame-wise models, especially during inter-class transitions, with an average response delay of 4.6 ms (p < 0.001) and simpler feature-encoding. Their performance can be further improved with adaptive reinforcement training. Significance: Sequential models that incorporate temporal information from EMG achieve superior movement prediction performance and these models allow for novel types of interactive training. Conclusions: Addressing EMG decoding as a sequential modeling problem will lead to enhancements in the reliability, responsiveness, and movement complexity available from prosthesis control systems.","Electromyography,Predictive models,Stability analysis,Convolution,Decoding,Computational modeling,Prosthetics,Biomedical monitoring,Reinforcement learning,Neural networks,Recurrent neural networks,Electromyographic (EMG),stability,latency,sequence,amputee,reinforcement,temporal convolutional network (TCN),ED-TCN",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"PATTERN-RECOGNITION,CLASSIFICATION,SIGNALS",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
84,Modeling Hierarchical Brain Networks via Volumetric Sparse Deep Belief Network,67,6,1739-1748,"Dong Qinglin,Ge Fangfei,Ning Qiang,Zhao Yu,Lv Jinglei,Huang Heng,Yuan Jing,Jian Xi,Shen Dinggang,Liu Tianming","Dong QL,Ge FF,Ning Q,Zhao Y,Lv JL,Huang H,Yuan J,Jian X,Shen D,Liu TM",Liu TM,10.1109/TBME.2019.2945231,University System of Georgia,"It has been recently shown that deep learning models such as convolutional neural networks (CNN), deep belief networks (DBN) and recurrent neural networks (RNN), exhibited remarkable ability in modeling and representing fMRI data for the understanding of functional activities and networks because of their superior data representation capability and wide availability of effective deep learning tools. For example, spatial and/or temporal patterns of functional brain activities embedded in fMRI data can be effectively characterized and modeled by a variety of CNN/DBN/RNN deep learning models as shown in recent studies. However, it has been rarely investigated whether it is possible to directly infer hierarchical brain networks from volumetric fMRI data using deep learning models such as DBN. The perceived difficulties of such studies include very large number of input variables, very large number of training parameters, the lack of effective software tools, the challenge of results interpretation, and etc. To bridge these technical gaps, we designed a novel volumetric sparse deep belief network (VS-DBN) model and implemented it through the popular TensorFlow open source platform to reconstruct hierarchical brain networks from volumetric fMRI data based on the Human Connectome Project (HCP) 900 subjects release. Our experimental results showed that a large number of interpretable and meaningful brain networks can be robustly reconstructed from HCP 900 subjects in a hierarchical fashion, and importantly, these brain networks exhibit reasonably good consistency and correspondence across multiple HCP task-based fMRI datasets. Our work contributed a new general deep learning framework for inferring multiscale volumetric brain networks and offered novel insights into the hierarchical organization of functional brain architecture.","Functional magnetic resonance imaging,Data models,Brain modeling,Task analysis,Deep learning,Image reconstruction,Training,Deep belief network (DBN),task fMRI,hierarchical brain network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"NEURAL-NETWORKS,FMRI,SIGNALS,TASK-FMRI,REPRESENTATION,CONNECTIVITY,ARCHITECTURE,RECOGNITION,INFERENCES,ATLASES",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
85,Unobtrusive Screening of Central Sleep Apnea From Pressure Sensors Measurements: A Patient-Specific Longitudinal Study,69,6,3282-3296,"Azimi Hilda,Bouchard Martin,Goubran Rafik,Knoefel Frank","Azimi H,Bouchard M,Goubran R,Knoefel F",Azimi H,10.1109/TIM.2020.2981111,University of Ottawa,"Historically, the lack of patients' sleep histories has caused low identification of sleep apnea (SA) and referral rates. Moreover, the costly and time-consuming nature of polysomnography (PSG) as a standard clinical test for detecting SA and the lack of sleep clinics has created a demand for suitable home-based monitoring devices. Pressure measurement using a pressure sensitive mat (PSM) can address the challenges found in current sleep-monitoring solutions. The noncontact PSM has a potential to replace obtrusive breathing sensors in the sleep lab and to be used as a prescreening tool for patients suspected of having SA. Applying classical support vector machine (SVM), this article presents a personalized system based on the measurements of each patient to detect central SA (CSA) events and monitor sleep characteristics longitudinally. For this purpose, sensor set-ups were installed in nine seniors' homes to collect unsupervised pressure data in approximately one year ranging from 8 to 12 months. Cost-based and resampling-based approaches were examined to combat imbalanced data. The results showed that the cost-based method outperformed other methods. Next, the patient-specific system was used to determine the total number of CSA events, as well as their starting time and duration in each day. The SA severity was measured by the central apnea index (CAI). In addition, other sleep characteristics such as bed occupancy (BO), day clock, and night clock were extracted from the PSM measurements. The impact of longitudinal sleep monitoring could be in tracking SA treatment progression, and possibly providing information on the interaction between SA and other disease progressions.","Biomedical measurement,data analysis,machine learning,patient monitoring,pressure measurement,sleep apnea (SA)",Article; Proceedings Paper,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",,,,"SUPPORT,VECTOR,MACHINES,PATTERN-RECOGNITION,RESPIRATORY,EVENTS,BODY,MOVEMENTS,DIAGNOSIS,NIGHT,CLASSIFICATION,VALIDATION,VIDEO",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
86,Laser Cladding Quality Monitoring Using Coaxial Image Based on Machine Learning,69,6,2868-2880,"Kao I-Hsi,Hsu Ya-Wen,Lai Yi Horng,Perng Jau-Woei","Kao IH,Hsu YW,Lai YH,Perng JW",Perng JW,10.1109/TIM.2019.2926878,National Sun Yat Sen University,"The processing quality of laser cladding is a topic of interest to laser machine manufacturers. The management of various experimental data and process quality of the laser machine can effectively guide the customer to better adjust the processing parameters. This study finds that the processing quality of laser cladding is related to the signal of the coaxial image. Therefore, this study uses a machine learning method to establish a model of coaxial image and laser processing quality. The study does not merely implement a single machine learning method but also compares various machine learning algorithms. Convolutional neural networks and autoencoders are implemented as algorithms for the feature extraction phase. Linear regression, random forest, support vector machine, and SoftMax neural networks are implemented as algorithms for classification. The receiver operating characteristic curve and the accuracy rate are the result indicators of this paper. The experimental results show that there is indeed a correlation between the laser processing quality and the coaxial image, and the algorithm in this study can effectively supervise the processing quality of laser cladding.","Coaxial image,failure detection,laser cladding,machine learning,monitoring",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"FAULT-DETECTION,CLASSIFICATION,REGRESSION,ENERGY,FUSION,MODEL",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
87,Application of Unconventional Seismic Attributes and Unsupervised Machine Learning for the Identification of Fault and Fracture Network,10,11,,"Ashraf Umar,Zhang Hucai,Anees Aqsa,Mangi Hassan Nasir,Ali Muhammad,Ullah Zaheen,Zhang Xiaonan","Ashraf U,Zhang HC,Anees A,Mangi HN,Ali M,Ullah Z,Zhang XN",Ashraf U; Anees A,10.3390/app10113864,Yunnan University,"The identification of small scale faults (SSFs) and fractures provides an improved understanding of geologic structural features and can be exploited for future drilling prospects. Conventional SSF and fracture characterization are challenging and time-consuming. Thus, the current study was conducted with the following aims: (a) to provide an effective way of utilizing the seismic data in the absence of image logs and cores for characterizing SSFs and fractures; (b) to present an unconventional way of data conditioning using geostatistical and structural filtering; (c) to provide an advanced workflow through multi-attributes, neural networks, and ant-colony optimization (ACO) for the recognition of fracture networks; and (d) to identify the fault and fracture orientation parameters within the study area. Initially, a steering cube was generated, and a dip-steered median filter (DSMF), a dip-steered diffusion filter (DSDF), and a fault enhancement filter (FEF) were applied to sharpen the discontinuities. Multiple structural attributes were applied and shortlisted, including dip and curvature attributes, filtered and unfiltered similarity attributes, thinned fault likelihood (TFL), fracture density, and fracture proximity. These shortlisted attributes were computed through unsupervised vector quantization (UVQ) neural networks. The results of the UVQ revealed the orientations, locations, and extensions of fractures in the study area. The ACO proved helpful in identifying the fracture parameters such as fracture length, dip angle, azimuth, and surface area. The adopted workflow also revealed a small scale fault which had an NNW-SSE orientation with minor heave and throw. The implemented workflow of structural interpretation is helpful for the field development of the study area and can be applied worldwide in carbonate, sand, coal, and shale gas fields.","fracture network,thinned fault likelihood,fracture density,fracture proximity,ant-colony optimization,unsupervised neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"SAWAN,GAS-FIELD,NEURAL-NETWORK,DENSITY-ESTIMATION,OIL-FIELD,RESERVOIR,BASIN,SANDSTONES,EXTRACTION,PREDICTION,SURFACES",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/11/3864/pdf,
88,Classification-Based Regression Models for Prediction of the Mechanical Properties of Roller-Compacted Concrete Pavement,10,11,,"Ashrafian Ali,Amiri Mohammad Javad Taheri,Masoumi Parisa,Asadi-shiadeh Mahsa,Yaghoubi-chenari Mojtaba,Mosavi Amir,Nabipour Narjes","Ashrafian A,Amiri MJT,Masoumi P,Asadi-shiadeh M,Yaghoubi-chenari M,Mosavi A,Nabipour N",Mosavi A,10.3390/app10113707,Technische Universitat Dresden,"In the field of pavement engineering, the determination of the mechanical characteristics is one of the essential processes for reliable material design and highway sustainability. Early determination of the mechanical characteristics of pavement is essential for road and highway construction and maintenance. Tensile strength (TS), compressive strength (CS), and flexural strength (FS) of roller-compacted concrete pavement (RCCP) are crucial characteristics. In this research, the classification-based regression models random forest (RF), M5rule model tree (M5rule), M5prime model tree (M5p), and chi-square automatic interaction detection (CHAID) are used for simulation of the mechanical characteristics of RCCP. A comprehensive and reliable dataset comprising 621, 326, and 290 data records for CS, TS, and FS experimental cases was extracted from several open sources in the literature. The mechanical properties are determined based on influential input combinations that are processed using principle component analysis (PCA). The PCA method specifies that volumetric/weighted content forms of experimental variables (e.g., coarse aggregate, fine aggregate, supplementary cementitious materials, water, and binder) and specimens' age are the most effective inputs to generate better performance. Several statistical metrics were used to evaluate the proposed classification-based regression models. The RF model revealed an optimistic classification capacity of the CS, TS, and FS prediction of the RCCP in comparison with the CHAID, M5rule, and M5p models. Monte-Carlo simulation was used to verify the results in terms of the uncertainty and sensitivity of variables. Overall, the proposed methodology formed a reliable soft computing model that can be implemented for material engineering, construction, and design.","roller-compacted concrete pavement,classification-regression models,feature selection,mechanical properties,machine learning,Monte-Carlo uncertainty,data science,civil engineering,transportation,mobility,prediction model,random forest (RF),structural health monitoring,pavement management",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"COMPRESSIVE,STRENGTH,ABRASION,RESISTANCE,CRUMB,RUBBER,COAL,WASTE,FLY-ASH,AGGREGATE,PERFORMANCE,FORMULATIONS,DURABILITY,MODULUS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/11/3707/pdf,
89,Development of Advanced Computer Aid Model for Shear Strength of Concrete Slender Beam Prediction,10,11,,"Sharafati Ahmad,Haghbin Masoud,Aldlemy Mohammed Suleman,Mussa Mohamed H.,Al Zand Ahmed W.,Ali Mumtaz,Bhagat Suraj Kumar,Al-Ansari Nadhir,Yaseen Zaher Mundher","Sharafati A,Haghbin M,Aldlemy MS,Mussa MH,Al Zand AW,Ali M,Bhagat SK,Al-Ansari N,Yaseen ZM",Yaseen ZM,10.3390/app10113811,Ton Duc Thang University,"High-strength concrete (HSC) is highly applicable to the construction of heavy structures. However, shear strength (Ss) determination of HSC is a crucial concern for structure designers and decision makers. The current research proposes the novel models based on the combination of adaptive neuro-fuzzy inference system (ANFIS) with several meta-heuristic optimization algorithms, including ant colony optimizer (ACO), differential evolution (DE), genetic algorithm (GA), and particle swarm optimization (PSO), to predict the Ss of HSC slender beam. The proposed models were constructed using several input combinations incorporating several related dimensional parameters such as effective depth of beam (d), shear span (a), maximum size of aggregate (a(g)), compressive strength of concrete (f(c)), and percentage of tension reinforcement (rho). To assess the impact of the non-homogeneity of the dataset on the prediction result accuracy, two possible modeling scenarios, (i) non-processed (initial) dataset (NP) and (ii) pre-processed dataset (PP), are inspected by several performance indices. The modeling results demonstrated that ANFIS-PSO hybrid model attained the best prediction accuracy over the other models and for the pre-processed input parameters. Several uncertainty analyses were examined (i.e., model, variables, and data), and results indicated predicting the HSC shear strength was more sensitive to the model structure uncertainty than the input parameters.","structure monitoring,shear strength prediction,machine learning,hybrid ANFIS model,high-strength concrete",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"ARTIFICIAL,NEURAL-NETWORKS,ANT,COLONY,OPTIMIZATION,FUZZY,INFERENCE,SYSTEM,RC,BEAMS,DESIGN,PROCEDURE,PART,I,FRP,STIRRUPS,CAPACITY,SLABS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/11/3811/pdf,
90,Prediction of Soluble Solids Content in Green Plum by Using a Sparse Autoencoder,10,11,,"Shen Luxiang,Wang Honghong,Liu Ying,Liu Yang,Zhang Xiao,Fei Yeqi","Shen LX,Wang HH,Liu Y,Liu Y,Zhang X,Fei YQ",Liu Y,10.3390/app10113769,Nanjing Forestry University,"The soluble solids content (SSC) affects the flavor of green plums and is an important parameter during processing. In recent years, the hyperspectral technology has been widely used in the nondestructive testing of fruit ingredients. However, the prediction accuracy of most models can hardly be improved further. The rapid development of deep learning technology has established the foundation for the improvement of building models. A new hyperspectral imaging system aimed at measuring the green plum SSC is developed, and a sparse autoencoder (SAE)-partial least squares regression (PLSR) model is combined to further improve the accuracy of component prediction. The results of the experiment show that the SAE-PLSR model, which has a correlation coefficient of 0.938 and root mean square error of 0.654 for the prediction set, can achieve better performance for the SSC prediction of green plums than the three traditional methods. In this paper, integration approaches have combined three different pretreatment methods with PLSR to predict the SSC in green plums. The SAE-PLSR model has shown good prediction performance, indicating that the proposed SAE-PLSR model can effectively detect the SSC in green plums.","green plum,SSC,hyperspectral,prediction,deep learning,SAE",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,NEURAL-NETWORK,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/11/3769/pdf,
91,Simulation-Trained Sparse Coding for High-Precision Phase Imaging in Low-Dose Electron Holography,26,3,429-438,"Anada Satoshi,Nomura Yuki,Hirayama Tsukasa,Yamamoto Kazuo","Anada S,Nomura Y,Hirayama T,Yamamoto K",Anada S,10.1017/S1431927620001452,Japan Fine Ceramics Center,"We broaden the applicability of sparse coding, a machine learning method, to low-dose electron holography by using simulated holograms for learning and validation processes. The holograms, with shot noise, are prepared to generate a model, or a dictionary, that includes basic features representing interference fringes. The dictionary is applied to sparse representations of other simulated holograms with various signal-to-noise ratios (SNRs). Results demonstrate that this approach successfully removes noise for holograms with an extremely small SNR of 0.10, and that the denoised holograms provide the accurate phase distribution. Furthermore, this study demonstrates that the dictionary learned from the simulated holograms can be applied to denoising of experimental holograms of a p-n junction specimen recorded with different exposure times. The results indicate that the simulation-trained sparse coding is suitable for use over a wide range of imaging conditions, in particular for observing electron beam-sensitive materials.","electron holography,hologram simulation,image denoising,low-dose imaging,machine learning,sparse coding",Article,"CAMBRIDGE UNIV PRESS, 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA","Materials Science,Microscopy",,3.162,"DETECTION,LIMITS,RECONSTRUCTION,RESOLUTION",MICROSCOPY AND MICROANALYSIS,,
92,Deep Neural Network Enabled Space Group Identification in EBSD,26,3,447-457,"Kaufmann Kevin,Zhu Chaoyi,Rosengarten Alexander S.,Vecchio Kenneth S.","Kaufmann K,Zhu CY,Rosengarten AS,Vecchio KS",Vecchio KS,10.1017/S1431927620001506,University of California System,"Electron backscatter diffraction (EBSD) is one of the primary tools in materials development and analysis. The technique can perform simultaneous analyses at multiple length scales, providing local sub-micron information mapped globally to centimeter scale. Recently, a series of technological revolutions simultaneously increased diffraction pattern quality and collection rate. After collection, current EBSD pattern indexing techniques (whether Hough-based or dictionary pattern matching based) are capable of reliably differentiating between a ""user selected"" set of phases, if those phases contain sufficiently different crystal structures. EBSD is currently less well suited for the problem of phase identification where the phases in the sample are unknown. A pattern analysis technique capable of phase identification, utilizing the information-rich diffraction patterns potentially coupled with other data, such as EDS-derived chemistry, would enable EBSD to become a high-throughput technique replacing many slower (X-ray diffraction) or more expensive (neutron diffraction) methods. We utilize a machine learning technique to develop a general methodology for the space group classification of diffraction patterns; this is demonstrated within the (4/m, (3) over bar, 2/m) point group. We evaluate the machine learning algorithm's performance in real-world situations using materials outside the training set, simultaneously elucidating the role of atomic scattering factors, orientation, and pattern quality on classification accuracy.","convolutional neural network,crystal structure,EBSD,machine learning,space groups",Article,"CAMBRIDGE UNIV PRESS, 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA","Materials Science,Microscopy",,3.162,"ELECTRON,BACKSCATTER,DIFFRACTION,IMAGE,REGISTRATION,PHASE,SCATTERING,DESIGN",MICROSCOPY AND MICROANALYSIS,https://www.cambridge.org/core/services/aop-cambridge-core/content/view/6513AF66C29C63F8ACFC26D223F479A5/S1431927620001506a.pdf/div-class-title-deep-neural-network-enabled-space-group-identification-in-ebsd-div.pdf,
93,Phase Mapping in EBSD Using Convolutional Neural Networks,26,3,458-468,"Kaufmann Kevin,Zhu Chaoyi,Rosengarten Alexander S.,Maryanovsky Daniel,Wang Haoren,Vecchio Kenneth S.","Kaufmann K,Zhu CY,Rosengarten AS,Maryanovsky D,Wang HR,Vecchio KS",Vecchio KS,10.1017/S1431927620001488,University of California System,"The emergence of commercial electron backscatter diffraction (EBSD) equipment ushered in an era of information rich maps produced by determining the orientation of user-selected crystal structures. Since then, a technological revolution has occurred in the quality, rate detection, and analysis of these diffractions patterns. The next revolution in EBSD is the ability to directly utilize the information rich diffraction patterns in a high-throughput manner. Aided by machine learning techniques, this new methodology is, as demonstrated herein, capable of accurately separating phases in a material by crystal symmetry, chemistry, and even lattice parameters with fewer human decisions. This work is the first demonstration of such capabilities and addresses many of the major challenges faced in modern EBSD. Diffraction patterns are collected from a variety of samples, and a convolutional neural network, a type of machine learning algorithm, is trained to autonomously recognize the subtle differences in the diffraction patterns and output phase maps of the material. This study offers a path to machine learning coupled phase mapping as databases of EBSD patterns encompass an increasing number of the possible space groups, chemistry changes, and lattice parameter variations.","convolutional neural network,crystal structure,EBSD,electron diffraction,machine learning",Article,"CAMBRIDGE UNIV PRESS, 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA","Materials Science,Microscopy",,3.162,"ELECTRON,BACKSCATTER,DIFFRACTION,IMAGE,REGISTRATION,PATTERNS,DIFFERENTIATION,IDENTIFICATION,DESIGN",MICROSCOPY AND MICROANALYSIS,https://www.cambridge.org/core/services/aop-cambridge-core/content/view/623282EB1DF6DB0559CEC8C74D30A74F/S1431927620001488a.pdf/div-class-title-phase-mapping-in-ebsd-using-convolutional-neural-networks-div.pdf,
94,AdaEn-Net: An ensemble of adaptive 2D-3D Fully Convolutional Networks for medical image segmentation,126,,76-94,"Calisto Maria Baldeon,Lai-Yuen Susana K.","Calisto MB,Lai-Yuen SK",Lai-Yuen SK,10.1016/j.neunet.2020.03.007,State University System of Florida,"Fully Convolutional Networks (FCNs) have emerged as powerful segmentation models but are usually designed manually, which requires extensive time and can result in large and complex architectures. There is a growing interest to automatically design efficient architectures that can accurately segment 3D medical images. However, most approaches either do not fully exploit volumetric information or do not optimize the model's size. To address these problems, we propose a self-adaptive 2D-3D ensemble of FCNs called AdaEn-Net for 3D medical image segmentation that incorporates volumetric data and adapts to a particular dataset by optimizing both the model's performance and size. The AdaEn-Net consists of a 2D FCN that extracts intra-slice information and a 3D FCN that exploits inter-slice information. The architecture and hyperparameters of the 2D and 3D architectures are found through a multiobjective evolutionary based algorithm that maximizes the expected segmentation accuracy and minimizes the number of parameters in the network. The main contribution of this work is a model that fully exploits volumetric information and automatically searches for a high-performing and efficient architecture. The AdaEn-Net was evaluated for prostate segmentation on the PROMISE12 Grand Challenge and for cardiac segmentation on the MICCAI ACDC challenge. In the first challenge, the AdaEn-Net ranks 9 out of 297 submissions and surpasses the performance of an automatically-generated segmentation network while producing an architecture with 13x fewer parameters. In the second challenge, the proposed model is ranked within the top 8 submissions and outperforms an architecture designed with reinforcement learning while having 1.25x fewer parameters. (c) 2020 Elsevier Ltd. All rights reserved.","Medical image segmentation,Deep learning,Neural architecture search,Hyperparameter optimization,Multiobjective optimization",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,9.171,"SEARCH,ALGORITHM",NEURAL NETWORKS,,
95,NFN plus : A novel network followed network for retinal vessel segmentation,126,,153-162,"Wu Yicheng,Xia Yong,Song Yang,Zhang Yanning,Cai Weidong","Wu YC,Xia Y,Song Y,Zhang YN,Cai WD",Xia Y,10.1016/j.neunet.2020.02.018,Northwestern Polytechnical University,"In the early diagnosis of diabetic retinopathy, the morphological attributes of blood vessels play an essential role to construct a retinal computer-aided diagnosis system. However, due to the challenges including limited densely annotated data, inter-vessel differences and structured prediction problem, it remains challenging to segment accurately the retinal vessels, particularly the capillaries on color fundus images. To address these issues, in this paper, we propose a novel deep learning-based model called NFN+ to effectively extract multi-scale information and make full use of deep feature maps. In NFN+, the front network converts an image patch into a probabilistic retinal vessel map, and the followed network further refines the map to achieve a better post-processing module, which helps represent the vessel structures implicitly. We employ the inter-network skip connections to unite two identical multi-scale backbones, which enables the useful multi-scale features to be directly transferred from shallow layers to deeper layers. The refined probabilistic retinal vessel maps produced from the augmented images are then averaged to construct the segmentation results. We evaluated this model on the digital retinal images for vessel extraction (DRIVE), structured analysis of the retina (STARE), and the child heart and health study (CHASE) databases. Our results indicate that the elaborated cascaded designs can produce performance gain and the proposed NFN+ model, to our best knowledge, achieved the state-of-the-art retinal vessel segmentation accuracy on color fundus images (AUC: 98.30%, 98.75% and 98.94%, respectively). (c) 2020 Elsevier Ltd. All rights reserved.","Retinal vessel segmentation,Deep learning,Cascaded networks,Skip connections",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,9.171,"BLOOD-VESSELS,IMAGES,CLASSIFICATION,VALIDATION,ALGORITHM,LEVEL",NEURAL NETWORKS,,
96,Brain MRI analysis using a deep learning based evolutionary approach,126,,218-234,"Shahamat Hossein,Abadeh Mohammad Saniee","Shahamat H,Abadeh MS",Abadeh MS,10.1016/j.neunet.2020.03.017,Tarbiat Modares University,"Convolutional neural network (CNN) models have recently demonstrated impressive performance in medical image analysis. However, there is no clear understanding of why they perform so well, or what they have learned. In this paper, a three-dimensional convolutional neural network (3D-CNN) is employed to classify brain MRI scans into two predefined groups. In addition, a genetic algorithm based brain masking (GABM) method is proposed as a visualization technique that provides new insights into the function of the 3D-CNN. The proposed GABM method consists of two main steps. In the first step, a set of brain MRI scans is used to train the 3D-CNN. In the second step, a genetic algorithm (GA) is applied to discover knowledgeable brain regions in the MRI scans. The knowledgeable regions are those areas of the brain which the 3D-CNN has mostly used to extract important and discriminative features from them. For applying GA on the brain MRI scans, a new chromosome encoding approach is proposed. The proposed framework has been evaluated using ADNI (including 140 subjects for Alzheimer's disease classification) and ABIDE (including 1000 subjects for Autism classification) brain MRI datasets. Experimental results show a 5-fold classification accuracy of 0.85 for the ADNI dataset and 0.70 for the ABIDE dataset. The proposed GABM method has extracted 6 to 65 knowledgeable brain regions in ADNI dataset (and 15 to 75 knowledgeable brain regions in ABIDE dataset). These regions are interpreted as the segments of the brain which are mostly used by the 3D-CNN to extract features for brain disease classification. Experimental results show that besides the model interpretability, the proposed GABM method has increased final performance of the classification model in some cases with respect to model parameters. (c) 2020 Elsevier Ltd. All rights reserved.","3D-CNN,Genetic algorithm,Deep learning,Interpretable classifier,Brain MRI classification",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,9.171,"AUTISM,SPECTRUM,DISORDER,MULTI-ATLAS,SEGMENTATION,FUNCTIONAL,CONNECTIVITY,CLASSIFICATION,DEPRESSION,DIAGNOSIS,SYMPTOMS,CHILDREN,VOLUME,MODEL",NEURAL NETWORKS,,
97,On Modelling Label Uncertainty in Deep Neural Networks: Automatic Estimation of Intra- Observer Variability in 2D Echocardiography Quality Assessment,39,6,1868-1883,"Liao Zhibin,Girgis Hany,Abdi Amir,Vaseli Hooman,Hetherington Jorden,Rohling Robert,Gin Ken,Tsang Teresa,Abolmaesumi Purang","Liao ZB,Girgis H,Abdi A,Vaseli H,Hetherington J,Rohling R,Gin K,Tsang T,Abolmaesumi P",Abolmaesumi P,10.1109/TMI.2019.2959209,University of British Columbia,"Uncertainty of labels in clinical data resulting from intra-observer variability can have direct impact on the reliability of assessments made by deep neural networks. In this paper, we propose a method for modelling such uncertainty in the context of 2D echocardiography (echo), which is a routine procedure for detecting cardiovascular disease at point-of-care. Echo imaging quality and acquisition time is highly dependent on the operator's experience level. Recent developments have shown the possibility of automating echo image quality quantification by mapping an expert's assessment of quality to the echo image via deep learning techniques. Nevertheless, the observer variability in the expert's assessment can impact the quality quantification accuracy. Here, we aim to model the intra-observer variability in echo quality assessment as an aleatoric uncertainty modelling regression problem with the introduction of a novel method that handles the regression problem with categorical labels. A key feature of our design is that only a single forward pass is sufficient to estimate the level of uncertainty for the network output. Compared to the 0.11 +/- 0.09 absolute error (in a scale from 0 to 1) archived by the conventional regression method, the proposed method brings the error down to 0.09 +/- 0.08, where the improvement is statistically significant and equivalents to 5.7% test accuracy improvement. The simplicity of the proposed approach means that it could be generalized to other applications of deep learning in medical imaging, where there is often uncertainty in clinical labels.","Label uncertainty,modelling,2D echocardiography,quality assessment,cross-entropy,loss regularization,deep learning,DenseNet,LSTM,deep neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CLASSIFICATION,NOISE",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1911.00674,
98,Attention by Selection: A Deep Selective Attention Approach to Breast Cancer Classification,39,6,1930-1941,"Xu Bolei,Liu Jingxin,Hou Xianxu,Liu Bozhi,Garibaldi Jon,Ellis Ian O.,Green Andy,Shen Linlin,Qiu Guoping","Xu BL,Liu JX,Hou XX,Liu BZ,Garibaldi J,Ellis IO,Green A,Shen LL,Qiu GP",Qiu GP,10.1109/TMI.2019.2962013,Shenzhen University,"Deep learning approaches are widely applied to histopathological image analysis due to the impressive levels of performance achieved. However, when dealing with high-resolution histopathological images, utilizing the original image as input to the deep learning model is computationally expensive, while resizing the original image to achieve low resolution incurs information loss. Some hard-attention based approaches have emerged to select possible lesion regions from images to avoid processing the original image. However, these hard-attention based approaches usually take a long time to converge with weak guidance, and valueless patches may be trained by the classifier. To overcome this problem, we propose a deep selective attention approach that aims to select valuable regions in the original images for classification. In our approach, a decision network is developed to decide where to crop and whether the cropped patch is necessary for classification. These selected patches are then trained by the classification network, which then provides feedback to the decision network to update its selection policy. With such a co-evolution training strategy, we show that our approach can achieve a fast convergence rate and high classification accuracy. Our approach is evaluated on a public breast cancer histopathological image database, where it demonstrates superior performance compared to state-of-the-art deep learning approaches, achieving approximately 98% classification accuracy while only taking 50% of the training time of the previous hard-attention approach.","Histopathological image,reinforcement learning,breast cancer classification,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,,
99,Quadratic Autoencoder (Q-AE) for Low-Dose CT Denoising,39,6,2035-2050,"Fan Fenglei,Shan Hongming,Kalra Mannudeep K.,Singh Ramandeep,Qian Guhan,Getzin Matthew,Teng Yueyang,Hahn Juergen,Wang Ge","Fan FL,Shan HM,Kalra MK,Singh R,Qian GH,Getzin M,Teng YY,Hahn J,Wang G",Wang G,10.1109/TMI.2019.2963248,Rensselaer Polytechnic Institute,"Inspired by complexity and diversity of biological neurons, our group proposed quadratic neurons by replacing the inner product in current artificial neurons with a quadratic operation on input data, thereby enhancing the capability of an individual neuron. Along this direction, we are motivated to evaluate the power of quadratic neurons in popular network architectures, simulating human-like learning in the form of ""quadratic-neuron-based deep learning"". Our prior theoretical studies have shown important merits of quadratic neurons and networks in representation, efficiency, and interpretability. In this paper, we use quadratic neurons to construct an encoder-decoder structure, referred as the quadratic autoencoder, and apply it to low-dose CT denoising. The experimental results on the Mayo low-dose CT dataset demonstrate the utility and robustness of quadratic autoencoder in terms of image denoising and model efficiency. To our best knowledge, this is the first time that the deep learning approach is implemented with a new type of neurons and demonstrates a significant potential in the medical imaging field.","Deep learning,quadratic neurons,autoencoder,low-dose CT",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"DEEP,NEURAL-NETWORK,IMAGE-RECONSTRUCTION,COMPUTED-TOMOGRAPHY,NOISE-REDUCTION,ALGORITHM",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1901.05593,
100,Instance-Level Microtubule Tracking,39,6,2061-2075,"Masoudi Samira,Razi Afsaneh,Wright Cameron H. G.,Gatlin Jesse C.,Bagci Ulas","Masoudi S,Razi A,Wright CHG,Gatlin JC,Bagci U",Bagci U,10.1109/TMI.2019.2963865,State University System of Florida,"We propose a new method of instance-level microtubule (MT) tracking in time-lapse image series using recurrent attention. Our novel deep learning algorithm segments individual MTs at each frame. Segmentation results from successive frames are used to assign correspondences among MTs. This ultimately generates a distinct path trajectory for each MT through the frames. Based on these trajectories, we estimate MT velocities. To validate our proposed technique, we conduct experiments using real and simulated data. We use statistics derived from real time-lapse series of MT gliding assays to simulate realistic MT time-lapse image series in our simulated data. This data set is employed as pre-training and hyperparameter optimization for our network before training on the real data. Our experimental results show that the proposed supervised learning algorithm improves the precision for MT instance velocity estimation drastically to 71.3% from the baseline result (29.3%). We also demonstrate how the inclusion of temporal information into our deep network can reduce the false negative rates from 67.8% (baseline) down to 28.7% (proposed). Our findings in this work are expected to help biologists characterize the spatial arrangement of MTs, specifically the effects of MT-MT interactions.","Microtubules,TIRF microscopy,instance-level segmentation,instance-level sub-cellular tracking,microtubule-microtubule interaction",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"FLUORESCENCE,MICROSCOPY,IMAGES,DYNAMIC,INSTABILITY,PARTICLE,TRACKING,OPTICAL-FLOW,SEGMENTATION",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1901.06006,
