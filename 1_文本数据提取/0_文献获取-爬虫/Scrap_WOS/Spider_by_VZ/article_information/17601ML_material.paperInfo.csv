,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,K-Means clustering and neural network for object detecting and identifying abnormality of brain tumor,23,19,9083-9096,"Arunkumar N.,Mohammed Mazin Abed,Abd Ghani Mohd Khanapi,Ibrahim Dheyaa Ahmed,Abdulhay Enas,Ramirez-Gonzalez Gustavo,de Albuquerque Victor Hugo C.","Arunkumar N,Mohammed MA,Abd Ghani MK,Ibrahim DA,Abdulhay E,Ramirez-Gonzalez G,de Albuquerque VHC",Mohammed MA,10.1007/s00500-018-3618-7,Universiti Teknologi Malaysia,"Brain tumor diagnosis is a challenging and difficult process in view of the assortment of conceivable shapes, regions, and image intensities. The pathological detection and identification of brain tumor and comparison among normal and abnormal tissues need grouped scientific techniques for features extraction, displaying, and measurement of the disease images. Our study shows an improved automated brain tumor segmentation and identification approach using ANN from MR images without human mediation by applying the best attributes toward preparatory brain tumor case revelation. To obtain the exact district region of brain tumor from MR images, we propose a brain tumor segmentation technique that has three noteworthy improvement focuses. To begin with, K-means clustering will be utilized as a part of the principal organization in the process of improving the MR image to be marked in the districts regions in light of their gray scale. Second, ANN is utilized to choose the correct object in view of training phase. Third, texture feature of brain tumor area will be extracted to the division stage. With respect to the brain tumor identification, the grayscale features are utilized to analyze and diagnose the brain tumor to differentiate the benign and malignant cases. According to the study results demonstrated that: (1) enhancement adaptive strategy was utilized as post-processing in brain tumor identification; (2) identify and build an assessment foundation of automated segmentation and identification for brain tumor cases; (3) highlight the methods based on region growing method and K-means clustering technique to select the best region; and (4) evaluate the proficiency of the foreseen outcomes by comparing ANN and SVM segmentation outcomes, and brain tumor cases classification. The ANN approach classifier recorded accuracy of 94.07% with line assumption (brain tumor cases classification) and sensitivity of 90.09% and specificity of 96.78%.","Brain tumor,Image segmentation,Automatic segmentation,Brain identification,Artificial neural networks,K-Means clustering,Magnetic resonance images",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,3.518,"SEGMENTATION,CLASSIFICATION,SYSTEM,IMAGES",SOFT COMPUTING,,
2,Strength prediction of similar materials to ionic rare earth ores based on orthogonal test and back propagation neural network,23,19,9429-9437,"Zhong Wen,Deng Yunchuan,Tenreiro Machado J. A.,Zhang Chao,Zhao Kui,Wang Xiaojun","Zhong W,Deng YC,Machado JAT,Zhang C,Zhao K,Wang XJ",Zhong W,10.1007/s00500-019-03833-7,Jiangxi University of Science & Technology,"This paper aims to predict the strength of materials similar to the ionic rare earth (IRE) ores [hereinafter referred as similar materials (SM)]. A 4 x Y x 2 back propagation neural network (BPNN) prediction model, based on 18 groups of samples of the SM with different mix proportions, was used to describe their strength. The BPNN modelling scheme includes four input layer neurons, representing the amounts of kaolinite, potassium feldspar, anorthose and mica, and two output layer neurons corresponding to the strength indices c and phi of the samples after 6 h leaching. Comparing the training and prediction errors, it is verified that the error in predicted strength is minimized when the number of hidden layer neurons Y equals 9. The correlation coefficient R of the prediction model is as high as 0.998, and the maximum relative errors of the strength indices (c and phi) are 4.11% and 4.26%, respectively. Orthogonal tests show that the BPNN is a reliable and accurate method to predict the strength of SM. Featuring uniform dispersion, comparability and nonlinear optimization, the proposed method sheds further light on the strength prediction of IRE ores.","Back propagation neural network (BPNN),Orthogonal test,Ionic rare earth (IRE),Similar materials (SM),Strength prediction",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA",Computer Science,,3.518,"UNCONFINED,COMPRESSIVE,STRENGTH,CONCRETE,OPTIMIZATION,MODELS",SOFT COMPUTING,,
3,Fingerprint liveness detection using local quality features,35,10,1393-1410,"Sharma Ram Prakash,Dey Somnath","Sharma RP,Dey S",Sharma RP,10.1007/s00371-018-01618-x,Indian Institute of Technology System (IIT System),"Fingerprint-based recognition is widely deployed in different domains. However, current recognition systems are vulnerable to presentation attack. Presentation attack utilizes an artificial replica of a fingerprint to deceive the sensors. In such scenarios, fingerprint liveness detection is required to ensure the actual presence of a live fingerprint. In this paper, we propose a static software-based approach using quality features to detect the liveness in a fingerprint image. The proposed method extracts eight sensor-independent quality features from the detailed ridge-valley structure of a fingerprint at the local level to form a 13-dimensional feature vector. Sequential Forward Floating Selection and Random Forest Feature Selection are used to select the optimal feature set from the created feature vector. To classify fake and live fingerprints, we have used support vector machine, random forest, and gradient boosted tree classifiers. The proposed method is tested on a publically available database of LivDet 2009 competition. The experimental results demonstrate that the least average classification error of 5.3% is achieved on LivDet 2009 database, exhibiting supremacy of the proposed method over current state-of-the-art approaches. Additionally, we have analyzed the importance of individual features on LivDet 2009 database, and effectiveness of the best-performing features is evaluated on LivDet 2011, 2013, and 2015 databases. The obtained results depict that the proposed approach is able to perform well irrespective of the different sensors and materials used in these databases. Further, the proposed method utilizes a single fingerprint image. This characteristic makes our method more user-friendly, faster, and less intrusive.","Biometrics,Presentation attack detection,Fingerprint liveness,Quality features",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Computer Science,,2.081,"CLASSIFICATION,PERSPIRATION,RECOGNITION,IRIS",VISUAL COMPUTER,http://arxiv.org/pdf/1806.02974,
4,Machine learning-based texture analysis for differentiation of large adrenal cortical tumours on CT,74,10,,"Elmohr M. M.,Fuentes D.,Habra M. A.,Bhosale P. R.,Qayyum A. A.,Gates E.,Morshid A. I,Hazle J. D.,Elsayes K. M.","Elmohr MM,Fuentes D,Habra MA,Bhosale PR,Qayyum AA,Gates E,Morshid AI,Hazle JD,Elsayes KM",Elsayes KM,10.1016/j.crad.2019.06.021,University of Texas System,"AIM: To compare the efficacy of computed tomography (CT) texture analysis and conventional evaluation by radiologists for differentiation between large adrenal adenomas and carcinomas.
MATERIALS AND METHODS: Quantitative CT texture analysis was used to evaluate 54 histopathologically proven adrenal masses (mean size=5.9 cm; range=4.1-10 cm) from 54 patients referred to Anderson Cancer Center from January 2002 through April 2014. The patient group included 32 women (mean age at mass evaluation=59 years) and 22 men (mean age at mass evaluation=61 years). Adrenal lesions seen on precontrast and venous-phase CT images were labelled by three different readers, and the labels were used to generate intensity- and geometry-based textural features. The textural features and the attenuation values were considered as input values for a random forest-based classifier. Similarly, the adrenal lesions were classified by two different radiologists based on morphological criteria. Prediction accuracy and interobserver agreement were compared.
RESULTS: The textural predictive model achieved a mean accuracy of 82%, whereas the mean accuracy for the radiologists was 68.5% (p<0.0001). The interobserver agreements between the predictive model and radiologists 1 and 2 were 0.44 (p<0.0005; 95% confidence interval [CI]: 0.25-0.62) and 0.47 (p<0.0005; 95% CI: 0.28-0.66), respectively. The Dice similarity coefficient between the readers' image labels was 0.875 +/- 0.04.
CONCLUSION: CT texture analysis of large adrenal adenomas and carcinomas is likely to improve CT evaluation of adrenal cortical tumours. (C) 2019 Published by Elsevier Ltd on behalf of The Royal College of Radiologists.","ADRENOCORTICAL CARCINOMA,UNENHANCED CT,MASSES,INCIDENTALOMAS,CANCER,SEGMENTATION,PREVALENCE,MANAGEMENT,SELECTION",Article,"W B SAUNDERS CO LTD, 32 JAMESTOWN RD, LONDON NW1 7BY, ENGLAND","Radiology, Nuclear Medicine & Medical Imaging",,2.597,"ADRENOCORTICAL,CARCINOMA,UNENHANCED,CT,MASSES,INCIDENTALOMAS,CANCER,SEGMENTATION,PREVALENCE,MANAGEMENT,SELECTION",CLINICAL RADIOLOGY,,
5,Automatic classification of ultrasound breast lesions using a deep convolutional neural network mimicking human decision-making,29,10,5458-5468,"Ciritsis Alexander,Rossi Cristina,Eberhard Matthias,Marcon Magda,Becker Anton S.,Boss Andreas","Ciritsis A,Rossi C,Eberhard M,Marcon M,Becker AS,Boss A",Ciritsis A,10.1007/s00330-019-06118-7,"Univ Hosp Zurich, Inst Diagnost & Intervent Radiol, Ramistr 100, CH-8091 Zurich, Switzerland.","Objectives To evaluate a deep convolutional neural network (dCNN) for detection, highlighting, and classification of ultrasound (US) breast lesions mimicking human decision-making according to the Breast Imaging Reporting and Data System (BI-RADS). Methods and materials One thousand nineteen breast ultrasound images from 582 patients (age 56.3 +/- 11.5 years) were linked to the corresponding radiological report. Lesions were categorized into the following classes: no tissue, normal breast tissue, BI-RADS 2 (cysts, lymph nodes), BI-RADS 3 (non-cystic mass), and BI-RADS 4-5 (suspicious). To test the accuracy of the dCNN, one internal dataset (101 images) and one external test dataset (43 images) were evaluated by the dCNN and two independent readers. Radiological reports, histopathological results, and follow-up examinations served as reference. The performances of the dCNN and the humans were quantified in terms of classification accuracies and receiver operating characteristic (ROC) curves. Results In the internal test dataset, the classification accuracy of the dCNN differentiating BI-RADS 2 from BI-RADS 3-5 lesions was 87.1% (external 93.0%) compared with that of human readers with 79.2 +/- 1.9% (external 95.3 +/- 2.3%). For the classification of BI-RADS 2-3 versus BI-RADS 4-5, the dCNN reached a classification accuracy of 93.1% (external 95.3%), whereas the classification accuracy of humans yielded 91.6 +/- 5.4% (external 94.1 +/- 1.2%). The AUC on the internal dataset was 83.8 (external 96.7) for the dCNN and 84.6 +/- 2.3 (external 90.9 +/- 2.9) for the humans. Conclusion dCNNs may be used to mimic human decision-making in the evaluation of single US images of breast lesion according to the BI-RADS catalog. The technique reaches high accuracies and may serve for standardization of highly observer-dependent US assessment.","Ultrasound,Breast,Artificial intelligence,Machine learning",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA","Radiology, Nuclear Medicine & Medical Imaging",,4.87,"BI-RADS,CANCER,MAMMOGRAPHY,FEATURES,NODULES,BENIGN,BIOPSY,IMAGES,WOMEN",EUROPEAN RADIOLOGY,,
6,A radiomics nomogram based on multiparametric MRI might stratify glioblastoma patients according to survival,29,10,5528-5538,"Zhang Xi,Lu Hongbing,Tian Qiang,Feng Na,Yin Lulu,Xu Xiaopan,Du Peng,Liu Yang","Zhang X,Lu HB,Tian Q,Feng N,Yin LL,Xu XP,Du P,Liu Y",Liu Y,10.1007/s00330-019-06069-z,Air Force Military Medical University,"Objectives To construct a radiomics nomogram for the individualized estimation of the survival stratification in glioblastoma (GBM) patients using the multiregional information extracted from multiparametric MRI, which could facilitate the clinical decision-making for GBM patients. Materials and methods A total of 105 eligible GBM patients (57 in the long-term and 48 in the short-term survival groups, separated by an overall survival of 12 months) were selected from the Cancer Genome Atlas. These patients were divided into a training set (n = 70) and a validation set (n = 35). Radiomics features (n = 4000) were extracted from multiple regions of the GBM using multiparametric MRI. Then, a radiomics signature was constructed using least absolute shrinkage and selection operator regression for each patient in the training set. Combined with clinical risk factors, a radiomics nomogram was constructed based on a multivariate logistic regression model. The performance of this radiomics nomogram was assessed by calibration, discrimination, and clinical usefulness. Results The radiomics signature consisted of 25 selected features and performed better than clinical risk factors (i.e., age, Karnofsky performance status, and treatment strategy) in survival stratification. When the radiomics signature and clinical risk factors were combined, the radiomics nomogram exhibited promising discrimination in the training (C-index, 0.971) and validation (C-index, 0.974) sets. The favorable calibration and decision curve analysis indicated the clinical usefulness of the radiomics nomogram. Conclusions The presented radiomics nomogram, as a non-invasive prediction tool, could exhibit a favorable predictive accuracy and provide individualized probabilities of survival stratification for GBM patients.","Multiparametric MRI,Glioblastoma,Machine learning,Nomogram",Article,"SPRINGER, 233 SPRING ST, NEW YORK, NY 10013 USA","Radiology, Nuclear Medicine & Medical Imaging",,4.87,"NEWLY-DIAGNOSED,GLIOBLASTOMA,PROGNOSTIC-FACTORS,PREDICTION,FEATURES,HETEROGENEITY,ONCOLOGY,GLIOMA",EUROPEAN RADIOLOGY,,
7,Machine Learning-Based Failure Mode Recognition of Circular Reinforced Concrete Bridge Columns: Comparative Study,145,10,,"Mangalathu Sujith,Jeon Jong-Su","Mangalathu S,Jeon JS",Jeon JS,10.1061/(ASCE)ST.1943-541X.0002402,Hanyang University,"The prediction of failure mode of columns is critical in deciding the operational and recovery strategies of a bridge after a seismic event. This paper contributes to the critical need of failure mode prediction for circular reinforced concrete bridge columns by exploring the capabilities of machine learning methods. Three types of failure mode such as flexure, flexure-shear, and shear are considered in this study, and 311 specimens are compiled from experimental studies on the circular columns. The efficiency of various machine learning models such as quadratic discriminant analysis, K-nearest neighbors, decision trees, random forests, naive Bayes, and artificial neural network is evaluated using a randomly assigned test set from the collected data. It is noted that artificial neural network has superior performance amongst all the machine-learning methods, and the comparison of this classification with the existing methods underscores the advantage of the artificial neural network in failure mode recognition. Classification based on artificial neural network is 91% accurate in identifying the failure mode of the collected experimental data.","Failure mode classification,Machine learning,Artificial neural network,Experimental data,Circular reinforced concrete bridge columns",Article,"ASCE-AMER SOC CIVIL ENGINEERS, 1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA","Construction & Building Technology,Engineering",,3.82,"ARTIFICIAL,NEURAL-NETWORKS,SEISMIC,SHEAR-STRENGTH,CLASSIFICATION,PERFORMANCE",JOURNAL OF STRUCTURAL ENGINEERING,,
8,Biometric identification of listener identity from frequency following responses to speech,16,5,,"Llanos Fernando,Xie Zilong,Chandrasekaran Bharath","Llanos F,Xie ZL,Chandrasekaran B",Llanos F,10.1088/1741-2552/ab1e01,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Objective. We investigate the biometric specificity of the frequency following response (FFR), an EEG marker of early auditory processing that reflects phase-locked activity from neural ensembles in the auditory cortex and subcortex (Chandrasekaran and Kraus 2010, Bidelman, 2015a, 2018, Coffey et al 2017b). Our objective is two-fold: demonstrate that the FFR contains information beyond stimulus properties and broad group-level markers, and to assess the practical viability of the FFR as a biometric across different sounds, auditory experiences, and recording days. Approach. We trained the hidden Markov model (HMM) to decode listener identity from FFR spectro-temporal patterns across multiple frequency bands. Our dataset included FFRs from twenty native speakers of English or Mandarin Chinese (10 per group) listening to Mandarin Chinese tones across three EEG sessions separated by days. We decoded subject identity within the same auditory context (same tone and session) and across different stimuli and recording sessions. Main results. The HMM decoded listeners for averaging sizes as small as one single FFR. However, model performance improved for larger averaging sizes (e.g. 25 FFRs), similarity in auditory context (same tone and day), and lack of familiarity with the sounds (i.e. native English relative to native Chinese listeners). Our results also revealed important biometric contributions from frequency bands in the cortical and subcortical EEG. Significance. Our study provides the first deep and systematic biometric characterization of the FFR and provides the basis for biometric identification systems incorporating this neural signal.","biometric identification system,frequency following response,electroencephalogram,neural plasticity,machine learning,hidden Markov model",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"HUMAN,BRAIN-STEM,HIDDEN,MARKOV-MODELS,HUMAN,ELECTROENCEPHALOGRAM,PERSON,AUTHENTICATION,NEURAL,REPRESENTATION,GENETIC,INFLUENCES,PITCH,CONTOURS,EEG,SCALP,ROC",JOURNAL OF NEURAL ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7244000,
9,SpikeDeeptector: a deep-learning based method for detection of neural spiking activity,16,5,,"Saif-ur-Rehman Muhammad,Lienkaemper Robin,Parpaley Yaroslav,Wellmer Joerg,Liu Charles,Lee Brian,Kellis Spencer,Andersen Richard,Iossifidis Ioannis,Glasmachers Tobias","Saif-ur-Rehman M,Lienkamper R,Parpaley Y,Wellmer J,Liu C,Lee B,Kellis S,Andersen R,Iossifidis I,Glasmachers T",Klaes C,10.1088/1741-2552/ab1e63,Ruhr University Bochum,"Objective. In electrophysiology, microelectrodes are the primary source for recording neural data (single unit activity). These microelectrodes can be implanted individually or in the form of arrays containing dozens to hundreds of channels. Recordings of some channels contain neural activity, which are often contaminated with noise. Another fraction of channels does not record any neural data, but only noise. By noise, we mean physiological activities unrelated to spiking, including technical artifacts and neural activities of neurons that are too far away from the electrode to be usefully processed. For further analysis, an automatic identification and continuous tracking of channels containing neural data is of great significance for many applications, e.g. automated selection of neural channels during online and offline spike sorting. Automated spike detection and sorting is also critical for online decoding in brain-computer interface (BCI) applications, in which only simple threshold crossing events are often considered for feature extraction. To our knowledge, there is no method that can universally and automatically identify channels containing neural data. In this study, we aim to identify and track channels containing neural data from implanted electrodes, automatically and more importantly universally. By universally, we mean across different recording technologies, different subjects and different brain areas. Approach. We propose a novel algorithm based on a new way of feature vector extraction and a deep learning method, which we call SpikeDeeptector. SpikeDeeptector considers a batch of waveforms to construct a single feature vector and enables contextual learning. The feature vectors are then fed to a deep learning method, which learns contextualized, temporal and spatial patterns, and classifies them as channels containing neural spike data or only noise. Main results. We trained the model of SpikeDeeptector on data recorded from a single tetraplegic patient with two Utah arrays implanted in different areas of the brain. The trained model was then evaluated on data collected from six epileptic patients implanted with depth electrodes, unseen data from the tetraplegic patient and data from another tetraplegic patient implanted with two Utah arrays. The cumulative evaluation accuracy was 97.20% on 1.56 million hand labeled test inputs. Significance. The results demonstrate that SpikeDeeptector generalizes not only to the new data, but also to different brain areas, subjects, and electrode types not used for training.","deep learning,convolutional neural networks,contextual learning,brain-computer interface,spike sorting",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"REPRESENTATIONS,CLASSIFICATION,ALGORITHMS,NEURONS",JOURNAL OF NEURAL ENGINEERING,https://doi.org/10.1088/1741-2552/ab1e63,
10,Multi-objective optimization of interatomic potentials with application to MgO,27,7,,"Ragasa E. J.,O'Brien C. J.,Hennig R. G.,Foiles S. M.,Phillipot S. R.","Ragasa EJ,O'Brien CJ,Hennig RG,Foiles SM,Phillipot SR",Phillipot SR,10.1088/1361-651X/ab28d9,State University System of Florida,"The parameterization of a functional form for an interatomic potential is treated as a problem in multi-objective optimization. An autonomous, machine-learning approach based on the identification of the Pareto hyper-surface of errors in predicted properties allows the development of an ensemble of parameterizations with high materials fidelity and robustness. The efficacy of this approach is illustrated for the simple example of a Buckingham potential for MgO. This approach also provides a strong foundation for uncertainty quantification of potential parameterizations.","interatomic potential,atomic-level simulation,Pareto optimization,rational design",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Materials Science,Physics",,2.439,"EMBEDDED-ATOM,METHOD,INITIO,MOLECULAR-DYNAMICS,SIMULATION,ENERGY,TRANSITION,GENERATION,DERIVATION,ORDER",MODELLING AND SIMULATION IN MATERIALS SCIENCE AND ENGINEERING,https://www.osti.gov/biblio/1544803,
11,2D MoS2 nanopores: ionic current blockade height for clustering DNA events,6,4,,"Carral Angel Diaz,Sarap Chandra Shekar,Liu Ke,Radenovic Aleksandra,Fyta Maria","Carral AD,Sarap CS,Liu K,Radenovic A,Fyta M",Fyta M,10.1088/2053-1583/ab2c38,University of Stuttgart,"2D nanopores can be used to electrophoretically drive DNA molecules, which can in turn be identified through measurable electronic current blockades. In this work, we use experimental data from molybdenum disulfide nanopores threading DNA nucleotides and propose a methodological approach to interpret DNA events. Specifically, the experimental ionic traces are used to train an unsupervised machine learning model for identifying distinct molecular events through the 2D nanopore. For the first time, we propose a clustering of experimental 2D nanopore data based on the ionic current blockade height and unrelated to the traditional dwell time for each DNA event. Within this approach, the blockade level information is implicitly included in the feature space analysis and does not need to be treated explicitly. We could show the higher efficiency of the blockade height over the traditional dwell time also in coping with sparse nanopore data sets. Our approach allows for a deep insight into characteristic molecular features in 2D nanopores and provides a feedback mechanism to tune these materials and interpret the measured signals. It has, thus, a high impact on the efficiency of 2D nanopore-based DNA sequencers.","2D nanopores,molybdenum-disulfide,DNA,clustering,machine learning,DNA translocation",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Materials Science,,8.161,"TRANSLOCATION,GRAPHENE,DISCRIMINATION,NOISE",2D MATERIALS,https://doi.org/10.1088/2053-1583/ab2c38,
12,High accuracy beam splitting using spatial light modulator combined with machine learning algorithms,121,,227-235,"Mikhaylova Dmitriy,Zhou Baifan,Kiedrowski Thomas,Mikut Ralf,Lasagni Andres-Fabian","Mikhaylova D,Zhou BF,Kiedrowski T,Mikut R,Lasagni AF",Mikhaylova D,10.1016/j.optlaseng.2019.04.010,"Robert Bosch Mfg Solut GmbH, Wernerstr 51,ATMO 1DE SGP22, D-70469 Stuttgart, Germany.","Phase-only spatial light modulators are ideal for the generation of beam splitter profiles to parallelize a variety of laser processes. A novel approach for the calculation of phase holograms is proposed to achieve a highly accurate power distribution over all spots. The Iterative Fourier Transform Algorithm (IFTA) is extended by the use of different machine learning methods, which are trained in an open camera-feedback loop. After the training phase, improvement of the beam splitting accuracy is then validated experimentally. The advantage of the presented approach is shown by comparing it to the standard IFTA algorithm. Finally, use of the approach is demonstrated through metal marking with an ultrashort pulse laser.","Spatial light modulator,Beam splitting,Machine learning,Convolutional neural networks",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Optics,,4.894,"2-PHOTON,POLYMERIZATION,PHASE,GRATINGS,HOLOGRAMS,GENERATION,DEVICES,IMAGE",OPTICS AND LASERS IN ENGINEERING,,
13,Predicting short- and long-term glycated haemoglobin response after insulin initiation in patients with type 2 diabetes mellitus using machine-learning algorithms,21,12,2704-2711,"Nagaraj Sunil B.,Sidorenkov Grigory,van Boven Job F. M.,Denig Petra","Nagaraj SB,Sidorenkov G,van Boven JFM,Denig P",Nagaraj SB,10.1111/dom.13860,University of Groningen,"Aim To assess the potential of supervised machine-learning techniques to identify clinical variables for predicting short-term and long-term glycated haemoglobin (HbA1c) response after insulin treatment initiation in patients with type 2 diabetes mellitus (T2DM). Materials and methods We included patients with T2DM from the Groningen Initiative to Analyse Type 2 diabetes Treatment (GIANTT) database who started insulin treatment between 2007 and 2013 and had a minimum follow-up of 2 years. Short- and long-term responses at 6 (+/- 2) and 24 (+/- 2) months after insulin initiation, respectively, were assessed. Patients were defined as good responders if they had a decrease in HbA1c >= 5 mmol/mol or reached the recommended level of HbA1c <= 53 mmol/mol. Twenty-four baseline clinical variables were used for the analysis and an elastic net regularization technique was used for variable selection. The performance of three traditional machine-learning algorithms was compared for the prediction of short- and long-term responses and the area under the receiver-operating characteristic curve (AUC) was used to assess the performance of the prediction models. Results The elastic net regularization-based generalized linear model, which included baseline HbA1c and estimated glomerular filtration rate, correctly classified short- and long-term HbA1c response after treatment initiation, with AUCs of 0.80 (95% CI 0.78-0.83) and 0.81 (95% CI 0.79-0.84), respectively, and outperformed the other machine-learning algorithms. Using baseline HbA1c alone, an AUC = 0.71 (95% CI 0.65-0.73) and 0.72 (95% CI 0.66-0.75) was obtained for predicting short-term and long-term response, respectively. Conclusions Machine-learning algorithm performed well in the prediction of an individual's short-term and long-term HbA1c response using baseline clinical variables.","cohort study,database research,insulin therapy,observational study,primary care,type 2 diabetes",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Endocrinology & Metabolism,,6.587,"PEOPLE,METFORMIN,VARIANTS,SMOKING,HBA1C,CARE",DIABETES OBESITY & METABOLISM,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6899933,
14,Prediction of concrete coefficient of thermal expansion and other properties using machine learning,220,,587-595,"Nilsen Vanessa,Pham Le T.,Hibbard Michael,Klager Adam,Cramer Steven M.,Morgan Dane","Nilsen V,Pham LT,Hibbard M,Klager A,Cramer SM,Morgan D",Morgan D,10.1016/j.conbuildmat.2019.05.006,University of Wisconsin System,"The coefficient of thermal expansion (CTE) significantly influences the performance of concrete. However, CTE measurements are both time consuming and expensive: therefore, CTE is often predicted from empirical equations based on historical data and concrete composition. In this work we demonstrate the application of linear regression and random forest machine learning methods to predict CTE and other properties from a database of Wisconsin concrete mixes. The random forest model accuracy, as assessed by cross-validation, is found to be significantly better than the American Association of State Highway and Transportation Officials (AASHTO) recommended prediction methods for CTE, denoted as level-2 and level-3. (C) 2019 Elsevier Ltd. All rights reserved.","Concrete,Coefficient of thermal expansion,Machine learning,Random forest,Compressive strength",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Construction & Building Technology,Engineering,Materials Science",,6.841,"SELF-COMPACTING,CONCRETE,COMPRESSIVE,STRENGTH,DESIGN,FIBER",CONSTRUCTION AND BUILDING MATERIALS,,
15,Wave-Function Engineering for Spectrally Uncorrelated Biphotons in the Telecommunication Band Based on a Machine-Learning Framework,12,3,,"Cui Chaohan,Arian Reeshad,Guha Saikat,Peyghambarian N.,Zhuang Quntao,Zhang Zheshen","Cui CH,Arian R,Guha S,Peyghambarian N,Zhuang QT,Zhang ZS",Cui CH,10.1103/PhysRevApplied.12.034059,University of Arizona,"Indistinguishable single photons are key ingredients for a plethora of quantum-information-processing applications, ranging from quantum communications to photonic quantum computing. A mainstream platform to produce indistinguishable single photons over a wide spectral range is based on biphoton generation through spontaneous parametric down-conversion in nonlinear crystals. The purity of the biphotons produced is, however, limited by their spectral correlations. Here we present a design recipe, based on a machine-learning framework, for the engineering of biphoton joint spectral amplitudes over a wide spectral range. By customizing the poling profile of the KTiOPO4 crystal, we show, numerically, that spectral purities of 99.22%, 99.99%, and 99.82%, respectively, can be achieved in the 1310-, 1550-, and 1600-nm bands after applying a moderate 8-nm filter. The machine-learning framework thus enables the generation of near-indistinguishable single photons over the entire telecommunication band without resorting to the KTiOPO4 crystal's group-velocity-matching wavelength window near 1582 nm.","ATOMIC ENSEMBLES,HIGH-PURITY,QUANTUM,PHOTONS,GENERATION",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,,"ATOMIC,ENSEMBLES,HIGH-PURITY,QUANTUM,PHOTONS,GENERATION",PHYSICAL REVIEW APPLIED,https://repository.arizona.edu/bitstream/10150/634863/1/PhysRevApplied.12.034059.pdf,
16,Real-Time Road Crack Mapping Using an Optimized Convolutional Neural Network,2019,,,"Naddaf-Sh M-Mahdi,Hosseini SeyedSaeid,Zhang Jing,Brake Nicholas A.,Zargarzadeh Hassan","Naddaf-Sh MM,Hosseini S,Zhang J,Brake NA,Zargarzadeh H",Zargarzadeh H,10.1155/2019/2470735,Texas State University System,"Pavement surveying and distress mapping is completed by roadway authorities to quantify the topical and structural damage levels for strategic preventative or rehabilitative action. The failure to time the preventative or rehabilitative action and control distress propagation can lead to severe structural and financial loss of the asset requiring complete reconstruction. Continuous and computer-aided surveying measures not only can eliminate human error when analyzing, identifying, defining, and mapping pavement surface distresses, but also can provide a database of road damage patterns and their locations. The database can be used for timely road repairs to gain the maximum durability of the asphalt and the minimum cost of maintenance. This paper introduces an autonomous surveying scheme to collect, analyze, and map the image-based distress data in real time. A descriptive approach is considered for identifying cracks from collected images using a convolutional neural network (CNN) that classifies several types of cracks. Typically, CNN-based schemes require a relatively large processing power to detect desired objects in images in real time. However, the portability objective of this work requires to utilize low-weight processing units. To that end, the CNN training was optimized by the Bayesian optimization algorithm (BOA) to achieve the maximum accuracy and minimum processing time with minimum neural network layers. First, a database consisting of a diverse population of crack distress types such as longitudinal, transverse, and alligator cracks, photographed at multiple angles, was prepared. Then, the database was used to train a CNN whose hyperparameters were optimized using BOA. Finally, a heuristic algorithm is introduced to process the CNN's output and produce the crack map. The performance of the classifier and mapping algorithm is examined against still images and videos captured by a drone from cracked pavement. In both instances, the proposed CNN was able to classify the cracks with 97% accuracy. The mapping algorithm is able to map a diverse population of surface cracks patterns in real time at the speed of 11.1 km per hour.",DAMAGE DETECTION,Article,"WILEY-HINDAWI, ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND","Mathematics,Science & Technology - Other Topics",,2.8,"DAMAGE,DETECTION",COMPLEXITY,https://downloads.hindawi.com/journals/complexity/2019/2470735.pdf,
17,A deep neural network model for packing density predictions and its application in the study of 1.5 million organic molecules,10,36,8374-8383,"Afzal Mohammad Atif Faiz,Sonpal Aditya,Haghighatlari Mojtaba,Schultz Andrew J.,Hachmann Johannes","Afzal MAF,Sonpal A,Haghighatlari M,Schultz AJ,Hachmann J",Afzal MAF; Hachmann J,10.1039/c9sc02677k,State University of New York (SUNY) System,"The process of developing new compounds and materials is increasingly driven by computational modeling and simulation, which allow us to characterize candidates before pursuing them in the laboratory. One of the non-trivial properties of interest for organic materials is their packing in the bulk, which is highly dependent on their molecular structure. By controlling the latter, we can realize materials with a desired density (as well as other target properties). Molecular dynamics simulations are a popular and reasonably accurate way to compute the bulk density of molecules, however, since these calculations are computationally intensive, they are not a practically viable option for high-throughput screening studies that assess material candidates on a massive scale. In this work, we employ machine learning to develop a data-derived prediction model that is an alternative to physics-based simulations, and we utilize it for the hyperscreening of 1.5 million small organic molecules as well as to gain insights into the relationship between structural makeup and packing density. We also use this study to analyze the learning curve of the employed neural network approach and gain empirical data on the dependence of model performance and training data size, which will inform future investigations.","REFRACTIVE-INDEX,PHOTOVOLTAICS,PERFORMANCE,POLYIMIDES,DISCOVERY,LIQUIDS,SYSTEMS,DESIGN",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND",Chemistry,,9.658,"REFRACTIVE-INDEX,PHOTOVOLTAICS,PERFORMANCE,POLYIMIDES,DISCOVERY,LIQUIDS,SYSTEMS,DESIGN",CHEMICAL SCIENCE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6855195,
18,,,,,,,,,,,,,,,,,,,,
19,Predictions of the mechanical properties of unidirectional fibre composites by supervised machine learning,9,,,"Pathan M. V,Ponnusami S. A.,Pathan J.,Pitisongsawat R.,Erice B.,Petrinic N.,Tagarielli V. L.","Pathan MV,Ponnusami SA,Pathan J,Pitisongsawat R,Erice B,Petrinic N,Tagarielli VL",Tagarielli VL,10.1038/s41598-019-50144-w,University of Oxford,"We present an application of data analytics and supervised machine learning to allow accurate predictions of the macroscopic stiffness and yield strength of a unidirectional composite loaded in the transverse plane. Predictions are obtained from the analysis of an image of the material microstructure, as well as knowledge of the constitutive models for fibres and matrix, without performing physically-based calculations. The computational framework is based on evaluating the 2-point correlation function of the images of 1800 microstructures, followed by dimensionality reduction via principal component analysis. Finite element (FE) simulations are performed on 1800 corresponding statistical volume elements (SVEs) representing cylindrical fibres in a continuous matrix, loaded in the transverse plane. A supervised machine learning (ML) exercise is performed, employing a gradient-boosted tree regression model with 10-fold cross-validation strategy. The model obtained is able to accurately predict the homogenized properties of arbitrary microstructures.","LINKAGES,CONDUCTIVITY",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,5.134,"LINKAGES,CONDUCTIVITY",SCIENTIFIC REPORTS,http://spiral.imperial.ac.uk/bitstream/10044/1/73189/11/PredictionsOfTheMechanicalPropertiesOfUnidirectional.pdf,
20,,,,,,,,,,,,,,,,,,,,
21,Materials property prediction using symmetry-labeled graphs as atomic position independent descriptors,100,10,,"Jorgensen Peter Bjorn,del Rio Estefania Garijo,Schmidt Mikkel N.,Jacobsen Karsten Wedel","Jorgensen PB,del Rio EG,Schmidt MN,Jacobsen KW",Jorgensen PB,10.1103/PhysRevB.100.104114,Technical University of Denmark,"Computational materials screening studies require fast calculation of the properties of thousands of materials. The calculations are often performed with density functional theory (DFT), but the necessary computer time sets limitations for the investigated material space. Therefore, the development of machine-learning models for prediction of DFT-calculated properties is currently of interest. A particular challenge for new materials is that the atomic positions are generally not known. We present a machine-learning model for the prediction of DFT-calculated formation energies based on Voronoi quotient graphs and local symmetry classification without the need for detailed information about atomic positions. The model is implemented as a message passing neural network and tested on the Open Quantum Materials Database (OQMD) and the Materials Project Database. The test mean absolute error is 22 meV on the OQMD and 43 meV on Materials Project Database. The possibilities for prediction in a realistic computational screening setting are investigated on a data set of 5976 ABSe(3) selenides with very limited overlap with the OQMD training set. Pretraining on OQMD and subsequent training on 100 selenides result in a mean absolute error below 0.1 eV for the formation energy of the selenides.",NETS,Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,"MACHINE,LEARNING-MODELS,NETS",PHYSICAL REVIEW B,http://arxiv.org/pdf/1905.06048,
22,A comparison of machine learning algorithms for the surveillance of autism spectrum disorder,14,9,,"Lee Scott H.,Maenner Matthew J.,Heilig Charles M.","Lee SH,Maenner MJ,Heilig CM",Lee SH,10.1371/journal.pone.0222907,Centers for Disease Control & Prevention - USA,"Objective
The Centers for Disease Control and Prevention (CDC) coordinates a labor-intensive process to measure the prevalence of autism spectrum disorder (ASD) among children in the United States. Random forests methods have shown promise in speeding up this process, but they lag behind human classification accuracy by about 5%. We explore whether more recently available document classification algorithms can close this gap.
Materials and methods
Using data gathered from a single surveillance site, we applied 8 supervised learning algorithms to predict whether children meet the case definition for ASD based solely on the words in their evaluations. We compared the algorithms' performance across 10 random train-test splits of the data, using classification accuracy, F1 score, and number of positive calls to evaluate their potential use for surveillance.
Results
Across the 10 train-test cycles, the random forest and support vector machine with Naive Bayes features (NB-SVM) each achieved slightly more than 87% mean accuracy. The NB-SVM produced significantly more false negatives than false positives (P = 0.027), but the random forest did not, making its prevalence estimates very close to the true prevalence in the data. The best-performing neural network performed similarly to the random forest on both measures. Discussion The random forest performed as well as more recently available models like the NB-SVM and the neural network, and it also produced good prevalence estimates. NB-SVM may not be a good candidate for use in a fully-automated surveillance workflow due to increased false negatives. More sophisticated algorithms, like hierarchical convolutional neural networks, may not be feasible to train due to characteristics of the data. Current algorithms might perform better if the data are abstracted and processed differently and if they take into account information about the children in addition to their evaluations.
Conclusion
Deep learning models performed similarly to traditional machine learning methods at predicting the clinician-assigned case status for CDC's autism surveillance system. While deep learning methods had limited benefit in this task, they may have applications in other surveillance systems.","DISABILITIES MONITORING NETWORK,UNITED-STATES,PREVALENCE,CHILDREN,SITES",Article,"PUBLIC LIBRARY SCIENCE, 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA",Science & Technology - Other Topics,,,"DISABILITIES,MONITORING,NETWORK,UNITED-STATES,PREVALENCE,CHILDREN,SITES",PLOS ONE,https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0222907&type=printable,
23,Automated grading of non-small cell lung cancer by fuzzy rough nearest neighbour method,8,1,,"Moitra Dipanjan,Mandal Rakesh Kr","Moitra D,Mandal RK",Moitra D,10.1007/s13721-019-0204-6,University of North Bengal,"Lung cancer is one of the most lethal diseases across the world. Most lung cancers belong to the category of non-small cell lung cancer (NSCLC). Many studies have so far been carried out to avoid the hazards and bias of manual classification of NSCLC tumors. A few of such studies were intended towards automated nodal staging using the standard machine learning algorithms. Many others tried to classify tumors as either benign or malignant. None of these studies considered the pathological grading of NSCLC. Automated grading may perfectly depict the dissimilarity between normal tissue and cancer affected tissue. Such automation may save patients from undergoing a painful biopsy and may also help radiologists or oncologists in grading the tumor or lesion correctly. The present study aims at the automated grading of NSCLC tumors using the fuzzy rough nearest neighbour (FRNN) method. The dataset was extracted from The Cancer Imaging Archive and it comprised PET/CT images of NSCLC tumors of 211 patients. Accelerated segment test (FAST) and histogram oriented gradients methods were used to detect and extract features from the segmented images. Gray level co-occurrence matrix (GLCM) features were also considered in the study. The features along with the clinical grading information were fed into four machine learning algorithms: FRNN, logistic regression, multi-layer perceptron, and support vector machine. The results were thoroughly compared in the light of various evaluation-metrics. The confusion matrix was found balanced, and the outcome was found more cost-effective for FRNN. Results were also compared with various other leading studies done earlier in this field. The proposed FRNN model performed satisfactorily during the experiment. Further exploration of FRNN may be very helpful for radiologists and oncologists in planning the treatment for NSCLC. More varieties of cancers may be considered while conducting similar studies.","Lung cancer,PET/CT,Fuzzy,Rough Set,Nearest Neighbour",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Mathematical & Computational Biology,,,"PULMONARY,NODULES,CLASSIFICATION,PROGNOSIS,DIAGNOSIS",NETWORK MODELING AND ANALYSIS IN HEALTH INFORMATICS AND BIOINFORMATICS,,
24,Data-Driven Discovery of Photoactive Quaternary Oxides Using First-Principles Machine Learning,31,18,7221-7230,"Davies Daniel W.,Butler Keith T.,Walsh Aron","Davies DW,Butler KT,Walsh A",Walsh A,10.1021/acs.chemmater.9b01519,Imperial College London,"We present a low-cost, virtual high-throughput materials design workflow and use it to identify earth-abundant materials for solar energy applications from the quaternary oxide chemical space. A statistical model that predicts bandgap from chemical composition is built using supervised machine learning. The trained model forms the first in a hierarchy of screening steps. An ionic substitution algorithm is used to assign crystal structures, and an oxidation state probability model is used to discard unlikely chemistries. We demonstrate the utility of this process for screening over 1 million oxide compositions. We find that, despite the difficulties inherent to identifying stable multicomponent inorganic materials, several compounds produced by our workflow are calculated to be thermodynamically stable or metastable and have desirable optoelectronic properties according to first-principles calculations. The predicted oxides are Li2MnSiO5, MnAg(SeO3)(2), and two polymorphs of MnCdGe2O6, all four of which are found to have direct electronic bandgaps in the visible range of the solar spectrum.","TOTAL-ENERGY CALCULATIONS,CHEMICAL-COMPOSITION,SEMICONDUCTORS,GENERATION,PREDICTION,DESIGN",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Materials Science",,10.837,"TOTAL-ENERGY,CALCULATIONS,CHEMICAL-COMPOSITION,SEMICONDUCTORS,GENERATION,PREDICTION,DESIGN",CHEMISTRY OF MATERIALS,,
25,Machine Learning Optimization of p-Type Transparent Conducting Films,31,18,7340-7350,"Wei Lingfei,Xu Xiaojie,Gurudayal,Bullock James,Ager Joel W.","Wei LF,Xu XJ,Gurudayal,Bullock J,Ager JW",Ager JW,10.1021/acs.chemmater.9b01953,United States Department of Energy (DOE),"p-Type transparent conducting materials (p-TCMs) are important components of optoelectronic devices including solar cells, photodetectors, displays, and flexible sensors. Cu-Zn-S thin films prepared by chemical bath deposition (CBD) can have both high transparency in the visible range (>80%) as well as excellent hole conductivity (>1000 S cm(-1)). However, the interplay between the deposition parameters in the CBD process (metal and sulfur precursor concentrations, temperature, pH, complexing agents, etc.) creates a multidimensional parameter space such that optimization for a specific application is challenging and time-consuming. Here we show that strategic design of experiment combined with machine learning (ML) allows for the efficient optimization of p-TCM performance. The approach is guided by a figure of merit (FOM) calculated from the film conductivity and optical transmission in the desired spectral range. A specific example is shown using two steps of optimization using a selected subset of four experimental CBD factors. The ML model is based on support vector regression employing a radial basis function as the kernel function. 10-fold cross-validation was performed to mitigate overfitting. After the first round of optimization, predicted areas in the parameter space with maximal FOMs were selected for a second round of optimization. Films with optimal FOMs were incorporated into heterojunction solar cells and transparent photodiodes. The optimization approach shown here will be generally applicable to any materials synthesis process with multiple parameters.","CHEMICAL BATH DEPOSITION,ZNS THIN-FILMS,SOLAR-ENERGY MATERIALS,BAND-GAP,FEATURE-SELECTION,DESIGN,FIGURE,MERIT,PARAMETERS,PREDICTION",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Materials Science",,10.837,"CHEMICAL,BATH,DEPOSITION,ZNS,THIN-FILMS,SOLAR-ENERGY,MATERIALS,BAND-GAP,FEATURE-SELECTION,DESIGN,FIGURE,MERIT,PARAMETERS,PREDICTION",CHEMISTRY OF MATERIALS,https://www.osti.gov/biblio/1569175,
26,Prediction of complication related death after radical cystectomy for bladder cancer with machine learning methodology,,,,"Klen Riku,Salminen Antti P.,Mahmoudian Mehrad,Syvanen Kari T.,Elo Laura L.,Bostrom Peter J.","Klen R,Salminen AP,Mahmoudian M,Syvanen KT,Elo LL,Bostrom PJ",Salminen AP,10.1080/21681805.2019.1665579,University of Turku,"Purpose: To create a pre-operatively usable tool to identify patients at high risk of early death (within 90 days post-operatively) after radical cystectomy and to assess potential risk factors for post-operative and surgery related mortality. Materials and methods: Material consists of 1099 consecutive radical cystectomy (RC) patients operated at 16 different hospitals in Finland 2005-2014. Machine learning methodology was utilized. For model building and testing, the data was randomly divided into training data (n = 733, 66.7%) and independent testing data (n = 366, 33.3%). To predict the risk of early death after RC from baseline variables, a binary classifier was constructed using logistic regression with lasso regularization. Finally, a user-friendly risk table was constructed for practical use. Results: The model resulted in an area under the receiver operating characteristic curve (AUROC) of 0.73 (95% CI = 0.59-0.87). The strongest risk factors were: American Society of Anesthesiologists physical status classification (ASA), congestive heart failure (CHF), age adjusted Charlson comorbidity index (ACCI) and chronic pulmonary disease. Conclusion: This study with a novel methodological approach adds CHF and chronic pulmonary disease to previously known independent prognostic risk factors for early death after RC. Importantly, the risk prediction tool uses purely pre-operative data and can be used before surgery.","Radical cystectomy,complication,mortality,risk factor",Article; Early Access,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Urology & Nephrology,,1.856,"MORTALITY,MORBIDITY,SELECTION",SCANDINAVIAN JOURNAL OF UROLOGY,,
27,Novel functional brain network methods based on CNN with an application in proficiency evaluation,359,,153-162,"Hua Chengcheng,Wang Hong,Chen Jichi,Zhang Tao,Wang Qiaoxiu,Chang Wenwen","Hua CC,Wang H,Chen JC,Zhang T,Wang QX,Chang WW",Wang H,10.1016/j.neucom.2019.05.088,Northeastern University - China,"With the advancements in the research about the EEG signal processing, there are a large number of different analytical methods include the functional brain network (FBN) methods, most of them are unsupervised and need multi handcrafted steps until classification. It is expected to propose a general-purpose method based on deep learning methods to improve the situation. Therefore, in this paper, we proposed two methods based on the convolutional neural network (CNN). One was analyzing adjacent matrixes computed by the phase locking value (PLV) to generate features based on CNN, which was equivalent to the graph-theoretic (GT) indexes functionally. The other method was a novel end-to-end method, brain connection based on CNN (BCCNN), which used a factorized 1-D CNN to filter the temporal part of the raw EEG, computed the correlation coefficients among the electrodes to build a new kind of FBNs and then extracted features from the FBNs like the last method. Then we performed a working memory (WM) experiment to verify the validity of the two methods. Those methods were used to detect the proficiency of the subjects in a WM task. In the results, the accuracy of the first method was 99.33%, which was as good as that of the GT indexes (99.35%). The accuracy of the second methods was 96.53%, which was lower than the performance of the PLV but higher than that of two conventional CNNs (94.37%, 90.83%). (C) 2019 Elsevier B.V. All rights reserved.","Electroencephalograph (EEG),Functional brain network (FBN),Convolutional neural network (CNN),End-to-end,General-purpose",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"CONVOLUTIONAL,NEURAL-NETWORKS,SLEEP,STAGE,CLASSIFICATION,PHASE-SYNCHRONIZATION,CHANNEL,EEG,MULTIVARIATE,PERFORMANCE,INDEX",NEUROCOMPUTING,,
28,Stacked sparse autoencoder and case-based postprocessing method for nucleus detection,359,,494-508,"Li Siqi,Jiang Huiyan,Bai Jie,Liu Ye,Yao Yu-dong","Li SQ,Jiang HY,Bai J,Liu Y,Yao YD",Jiang HY,10.1016/j.neucom.2019.06.005,Northeastern University - China,"Accurate nucleus detection is of great importance in pathological image analyses and diagnoses, which is a critical prerequisite for tasks such as automated grading hepatocellular carcinoma (HCC) nuclei. This paper proposes an automated nucleus detection framework based on a stacked sparse autoencoder (SSAE) and a case-based postprocessing method (CPM) in a coarse-to-fine manner. SSAE, an unsupervised learning model, is first trained using image patches of breast cancer. Then, the transfer learning and sliding window techniques are applied to other cancers' pathological images (HCC and colon cancer) to extract the high-level features of image patches via the trained SSAE. Subsequently, these high-level features are fed to a logistic regression classifier (LRC) to classify whether each image patch contains a complete nucleus in a coarse detection process. Finally, CPM is developed for refining the coarse detection results which removes false positive nuclei and locates adhesive or overlapped nuclei effectively. SSAE-CPM achieves an average nucleus detection accuracy of 0.8748 on HCC pathological images, which can accurately locate almost all nuclei on the pathological images with serious differentiation. In addition, our proposed detection framework is also evaluated on a public dataset of colon cancer, with a mean F-1 score of 0.8355. Experimental results demonstrate the performance advantages of our proposed SSAE-CPM detection framework as compared with related work. While our detection framework is trained on the pathological images of breast cancer, it can be easily and effectively applied to nucleus detection tasks on other cancers without re-training. (C) 2019 Elsevier B.V. All rights reserved.","Automated nucleus detection,Stacked sparse autoencoder,Case-based postprocessing method,Transfer learning,Coarse-to-fine manner",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,,"SEGMENTATION,ALGORITHM,IMAGES,REPRESENTATION",NEUROCOMPUTING,,
29,Live-load strain evaluation of the prestressed concrete box-girder bridge using deep learning and clustering,19,4,1051-1063,"Zhao Hanwei,Ding Youliang,Li Aiqun,Ren Zhaozhao,Yang Kang","Zhao HW,Ding YL,Li AQ,Ren ZZ,Yang K",Ding YL,10.1177/1475921719875630,Southeast University - China,"The monitoring data makes it feasible to quickly evaluate the cracking of the prestressed concrete box-girder bridge. The live-load strain can accurately quantify the load effect and cracking of bridges due to its explicit datum point of signal. Based on the live-load strain data from bridge monitoring system, this study develops a comprehensive data-driven method of state evaluation and cracking early warning for the prestressed concrete box-girder bridge. The feature of vehicle-induced strain is extracted using the deep learning and classification of long short-term memory network. The vehicle-induced strain features are clustered via Gaussian mixture model, and the cracking early warning of the bridge is conducted according to the reliability of heavy vehicle clustering data. This method can be used as an indicator for the bridge inspection, truck-weight-limit and reinforcement work. The results demonstrate that (1) using the long short-term memory network, a deep learning model can be trained to intelligently classify the non-stationary and stationary sections of vehicle-induced strains, of which the test accuracy of classification surpasses 99%, and (2) according to the Gaussian mixture model probability distribution of data, the vehicle-induced strain features can be clustered by the corresponding Gaussian mixture model crest, which is the premise for reflecting relational mapping between vehicle loading and strain response.","Structural health monitoring,deep learning,data clustering,live-load strain evaluation,early warning of cracking",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Engineering,Instruments & Instrumentation",,5.861,"IDENTIFICATION,DAMAGE",STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL,,
30,Using Machine Learning and Natural Language Processing to Review and Classify the Medical Literature on Cancer Susceptibility Genes,3,,,"Bao Yujia,Deng Zhengyi,Wang Yan,Kim Heeyoon,Armengol Victor Diego,Acevedo Francisco,Ouardaoui Nofal,Wang Cathy,Parmigiani Giovanni,Barzilay Regina","Bao YJ,Deng ZY,Wang Y,Kim H,Armengol VD,Acevedo F,Ouardaoui N,Wang C,Parmigiani G,Barzilay R",Braun D,10.1200/CCI.19.00042,Harvard University,"PURPOSE The medical literature relevant to germline genetics is growing exponentially. Clinicians need tools that help to monitor and prioritize the literature to understand the clinical implications of pathogenic genetic variants. We developed and evaluated two machine learning models to classify abstracts as relevant to the penetrance-risk of cancer for germline mutation carriers-or prevalence of germline genetic mutations.
MATERIALS AND METHODS We conducted literature searches in PubMed and retrieved paper titles and abstracts to create an annotated data set for training and evaluating the two machine learning classification models. Our first model is a support vector machine (SVM) which learns a linear decision rule on the basis of the bag-ofngrams representation of each title and abstract. Our second model is a convolutional neural network (CNN) which learns a complex nonlinear decision rule on the basis of the raw title and abstract. We evaluated the performance of the two models on the classification of papers as relevant to penetrance or prevalence.
RESULTS For penetrance classification, we annotated 3,740 paper titles and abstracts and evaluated the two models using 10-fold cross-validation. The SVM model achieved 88.93% accuracy-percentage of papers that were correctly classified-whereas the CNN model achieved 88.53% accuracy. For prevalence classification, we annotated 3,753 paper titles and abstracts. The SVM model achieved 88.92% accuracy and the CNN model achieved 88.52% accuracy.
CONCLUSION Our models achieve high accuracy in classifying abstracts as relevant to penetrance or prevalence. By facilitating literature review, this tool could help clinicians and researchers keep abreast of the burgeoning knowledge of gene-cancer associations and keep the knowledge bases for clinical decision support tools up to date. (C) 2019 by American Society of Clinical Oncology","WORKLOAD,QUALITY",Review,"AMER SOC CLINICAL ONCOLOGY, 2318 MILL ROAD, STE 800, ALEXANDRIA, VA 22314 USA",Oncology,,,"WORKLOAD,QUALITY",JCO CLINICAL CANCER INFORMATICS,https://dspace.mit.edu/bitstream/1721.1/136447/2/1904.12617.pdf,
31,Structured report data can be used to develop deep learning algorithms: a proof of concept in ankle radiographs,10,1,,"dos Santos Daniel Pinto,Brodehl Sebastian,Baessler Bettina,Arnhold Gordon,Dratsch Thomas,Chon Seung-Hun,Mildenberger Peter,Jungmann Florian","dos Santos DP,Brodehl S,Baessler B,Arnhold G,Dratsch T,Chon SH,Mildenberger P,Jungmann F",dos Santos DP,10.1186/s13244-019-0777-8,University of Cologne,"Background Data used for training of deep learning networks usually needs large amounts of accurate labels. These labels are usually extracted from reports using natural language processing or by time-consuming manual review. The aim of this study was therefore to develop and evaluate a workflow for using data from structured reports as labels to be used in a deep learning application. Materials and methods We included all plain anteriorposterior radiographs of the ankle for which structured reports were available. A workflow was designed and implemented where a script was used to automatically retrieve, convert, and anonymize the respective radiographs of cases where fractures were either present or absent from the institution's picture archiving and communication system (PACS). These images were then used to retrain a pretrained deep convolutional neural network. Finally, performance was evaluated on a set of previously unseen radiographs. Results Once implemented and configured, completion of the whole workflow took under 1 h. A total of 157 structured reports were retrieved from the reporting platform. For all structured reports, corresponding radiographs were successfully retrieved from the PACS and fed into the training process. On an unseen validation subset, the model showed a satisfactory performance with an area under the curve of 0.850 (95% CI 0.634-1.000) for detection of fractures. Conclusion We demonstrate that data obtained from structured reports written in clinical routine can be used to successfully train deep learning algorithms. This highlights the potential role of structured reporting for the future of radiology, especially in the context of deep learning.","Structured reporting,Workflow,Machine learning,Radiography,Ankle fractures",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,4.879,RADIOLOGY,INSIGHTS INTO IMAGING,https://europepmc.org/articles/pmc6777645?pdf=render,
32,Evaluating the performance of a predictive modeling approach to identifying members at high-risk of hospitalization,23,3,228-234,"Holloway Jack,Neely Chris,Yuan Xiaojing,Zhang Yuan,Ouyang Jason,Cantrell Dawn,Chaisson Janet,Bergeron Tasha,Washington Vindell,Nigam Somesh","Holloway J,Neely C,Yuan XJ,Zhang Y,Ouyang J,Cantrell D,Chaisson J,Bergeron T,Washington V,Nigam S",Holloway J,10.1080/13696998.2019.1666854,"Blue Cross Blue Shield Louisiana, Healthcare Informat, 5525 Reitz Ave, Baton Rouge, LA 70809 USA.","Aims: To evaluate the risk-of-hospitalization (ROH) models developed at Blue Cross Blue Shield of Louisiana (BCBSLA) and compare this approach to the DxCG risk-score algorithms utilized by many health plans. Materials and Methods: Time zero for this study was December 31, 2016. BCBSLA members were eligible for study inclusion if they were fully insured; aged 80 years or younger; and had continuous enrollment starting on or before June 1, 2016, through time zero. Up to 2 years of historical claims data from time zero per patient was included for model development. Members were excluded if they had cancer, renal failure, or were admitted for hospice. The Blue Cross ROH models were developed using (1) regularized logistic regression and (2) random decision forests (a tree ensemble learning classification method). All models were generated using Scikit-learn: Machine Learning in Python. Prognostic capabilities of DxCG risk-score algorithms were compared to those of the Blue Cross models. Results: When stratifying by the top 0.1% of members with the highest ROH, the Blue Cross logistic regression model had the highest area under the receiving operator characteristics curve (0.862) based on the result of 10-fold cross-validation. The Blue Cross random decision forests model had the highest positive predictive value (49.0%) and positive likelihood ratio (61.4), but sensitivity, specificity, negative predictive values, and negative likelihood ratios were similar across all four models. Limitations: The Blue Cross ROH models were developed and evaluated using BCBSLA data, and predictive power may fluctuate if applied to other databases. Conclusions: The predictability of the Blue Cross models show how member-specific, regional data can be used to accurately identify patients with a high ROH, which may allow healthcare workers to intervene earlier and subsequently reduce the healthcare burden for patients and providers.","Admissions,hospitalizations,predictive modeling,machine learning,high risk,risk score",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Health Care Sciences & Services,General & Internal Medicine",,2.406,,JOURNAL OF MEDICAL ECONOMICS,https://www.tandfonline.com/doi/pdf/10.1080/13696998.2019.1666854?needAccess=true,
33,Dependence of a cooling rate on structural and vibrational properties of amorphous silicon: A neural network potential-based molecular dynamics study,151,11,,"Li Wenwen,Ando Yasunobu","Li WW,Ando Y",Ando Y,10.1063/1.5114652,National Institute of Advanced Industrial Science & Technology (AIST),"Amorphous materials have variable structural order, which has a significant influence on their electronic, transport, and thermal properties. However, this difference in structure has rarely been investigated by atomistic modeling. In this study, a high-quality machine-learning-based interatomic potential was used to generate a series of atomic structures of amorphous silicon with different degrees of disorder by simulated cooling from the melt with different cooling rates (10(11)-10(15) K/s). We found that the short- and intermediate-range orders are enhanced with decreasing cooling rate, and the influence of the structural order change is in excellent agreement with the experimental annealing process in terms of the structural, energetic, and vibrational properties. In addition, by comparing the excess energies, structure factors, radial distribution functions, phonon densities of states, and Raman spectra, it is possible to determine the corresponding theoretical model for experimental samples prepared with a certain method and thermal history.","PURE,SI,CRYSTALLINE,ORDER,PSEUDOPOTENTIALS,SPECTRA,LITHIUM",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Chemistry,Physics",,3.166,"PURE,SI,CRYSTALLINE,ORDER,PSEUDOPOTENTIALS,SPECTRA,LITHIUM",JOURNAL OF CHEMICAL PHYSICS,https://aip.scitation.org/doi/pdf/10.1063/1.5114652,
34,Non-negative Matrix Factorization and Its Extensions for Spectral Image Data Analysis,17,,148-154,"Shiga Motoki,Muto Shunsuke","Shiga M,Muto S",Shiga M,10.1380/ejssnt.2019.148,Gifu University,"Scanning transmission electron microscopy combined with electron energy-loss spectroscopy and energy-dispcrsivc X-ray spectroscopy is useful for analyzing chemical stales and elemental components in a new material. Using these instruments, the spectra over the spatial grid points in a region of interest can be observed. This measurement technique is called spectral imaging (SI). Because of the large size of SI data, the analysis cost is a bottleneck in the evaluation process of the material. To reduce the analysis cost, machine learning techniques can be applied. which can automatically extract essential information from the data. This paper reviews our developed machine learning method, which is based on non-negative matrix factorization and its extensions. A spatial orthogonality constraint and a generalized noise model, which includes Gaussian and Poisson noise models, arc introduced. Numerical experiments demonstrate the effectiveness and characteristics of our developed methods.","Scanning transmission electron microscopy,Electron energy-loss spectroscopy,Spectral image analysis,Non-negative matrix factorization,Machine learning",Review,"SURFACE SCI SOC JAPAN, HONGO CORP 402, 2-40-13 HONGO, BUNKYO-KU, TOKYO, 113-0033, JAPAN",Science & Technology - Other Topics,,,"ALGORITHMS,DIVERGENCE,EELS",E-JOURNAL OF SURFACE SCIENCE AND NANOTECHNOLOGY,https://www.jstage.jst.go.jp/article/ejssnt/17/0/17_148/_pdf,
35,Bulk and surface DFT investigations of inorganic halide perovskites screened using machine learning and materials property databases,21,35,19423-19436,"Jain Deepak,Chaube Suryanaman,Khullar Prerna,Srinivasan Sriram Goverapet,Rai Beena","Jain D,Chaube S,Khullar P,Srinivasan SG,Rai B",Srinivasan SG,10.1039/c9cp03240a,"TCS Res, Tata Res Dev & Design Ctr, 54-B Hadapsar Ind Estate, Pune 411013, Maharashtra, India.","In the recent past, there has been proliferation in high-throughput density functional theory and data-driven explorations of materials motivated by a need to reduce physical testing and costly computations for materials discovery. This has, in conjunction with the development of open-access materials property databases, encouraged accelerated and more streamlined discovery and screening of technologically relevant materials. In this work, we report our results on the screening and DFT studies of one such class of materials, i.e. ABX(3) inorganic halide perovskites (A, B and X representing the monovalent, divalent and halide ions respectively) using a coupled machine-learning (ML) and density functional theory (DFT) approach. Utilizing the support vector machine algorithm, we predict the formability of 454 inorganic halide compounds in the perovskite phase. Compounds with a formation probability P >= 0.8 are further checked for thermodynamic stability in at least one of these three open materials databases - Materials Project (MP), Automatic FLOW for Materials Discovery (AFLOW) and Open Quantum Materials Database (OQMD). The shortlisted candidate perovskites are then considered for DFT computations. Taking input geometries from MP's structure predictor, the optimized lattice parameters and computed band gaps (BG) for all screened compounds are compared with predictions across all databases. Subsequently, detailed studies on low index surfaces are presented for two halide perovksites - RbSnCl3 and RbSnBr3 - having band-gaps in the favourable range for photovoltaics (PV). Different possible (100), (110) and (111) surface terminations are investigated for each of these compositions and the atomic relaxations, surface energies and electronic band structures are reported for each termination. To the best of our knowledge, no surface studies have been reported in the literature for any of the halide perovskites present in our database. These studies, therefore, are an important step towards gaining a fundamental understanding of the interfacial properties of perovskites, which can help facilitate further breakthroughs in the PV technology.","DENSITY-FUNCTIONAL THEORY,AB-INITIO CALCULATIONS,PHASE-TRANSITIONS,PLUS U,STABILITY,CH3NH3PBI3,BATIO3,WATER,LEAD,1ST-PRINCIPLES",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Physics",,3.802,"DENSITY-FUNCTIONAL,THEORY,AB-INITIO,CALCULATIONS,PHASE-TRANSITIONS,PLUS,U,STABILITY,CH3NH3PBI3,BATIO3,WATER,LEAD,1ST-PRINCIPLES",PHYSICAL CHEMISTRY CHEMICAL PHYSICS,,
36,Deep learning algorithm predicts diabetic retinopathy progression in individual patients,2,,,"Arcadu Filippo,Benmansour Fethallah,Maunz Andreas,Willis Jeff,Haskova Zdenka,Prunotto Marco","Arcadu F,Benmansour F,Maunz A,Willis J,Haskova Z,Prunotto M",Prunotto M,10.1038/s41746-019-0172-3,Roche Holding,"The global burden of diabetic retinopathy (DR) continues to worsen and DR remains a leading cause of vision loss worldwide. Here, we describe an algorithm to predict DR progression by means of deep learning (DL), using as input color fundus photographs (CFPs) acquired at a single visit from a patient with DR. The proposed DL models were designed to predict future DR progression, defined as 2-step worsening on the Early Treatment Diabetic Retinopathy Diabetic Retinopathy Severity Scale, and were trained against DR severity scores assessed after 6, 12, and 24 months from the baseline visit by masked, well-trained, human reading center graders. The performance of one of these models (prediction at month 12) resulted in an area under the curve equal to 0.79. Interestingly, our results highlight the importance of the predictive signal located in the peripheral retinal fields, not routinely collected for DR assessments, and the importance of microvascular abnormalities. Our findings show the feasibility of predicting future DR progression by leveraging CFPs of a patient acquired at a single visit. Upon further development on larger and more diverse datasets, such an algorithm could enable early diagnosis and referral to a retina specialist for more frequent monitoring and even consideration of early intervention. Moreover, it could also improve patient recruitment for clinical trials targeting DR.","NEURAL-NETWORK,SEVERITY,CLASSIFICATION,VALIDATION,IMAGES,SYSTEM",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Health Care Sciences & Services,Medical Informatics",,11.665,"NEURAL-NETWORK,SEVERITY,CLASSIFICATION,VALIDATION,IMAGES,SYSTEM",NPJ DIGITAL MEDICINE,https://www.nature.com/articles/s41746-019-0172-3.pdf,
37,Heart sound classification using machine learning and phonocardiogram,33,26,,"Arora Vinay,Leekha Rohan,Singh Raman,Chana Inderveer","Arora V,Leekha R,Singh R,Chana I",Arora V,10.1142/S0217984919503214,Thapar Institute of Engineering & Technology,"This research pertains to classification of the heart sound using digital Phonocardiogram (PCG) signals targeted to screen for heart ailments. In this study, an existing variant of the decision tree, i.e. XgBoost has been used with unsegmented heart sound signal. The dataset provided by PhysioNet Computing in Cardiology (CinC) Challenge 2016 has been used to validate the technique proposed in this research work. The said dataset comprises six databases (A-F) having 3240 heart sound recordings in all with the duration lasting from 5-120 s. The approach proposed in this paper has been compared with 18 existing methodologies. The proposed method is accurate with the mean score of 92.9, while sensitivity and specificity scores are 94.5 and 91.3, respectively. The timely prediction of heart health will support specialists to attain useful risk stratification of patients and also assist clinicians in effective decision-making. These predictive facts may serve as a guide to provide improved quality of care to the patients by way of effective treatment planning and monitoring.","Heart sound,decision tree,XgBoost,PCG signal",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Physics,,1.138,"NEURAL-NETWORKS,ALGORITHMS,FREQUENCY,FEATURES",MODERN PHYSICS LETTERS B,,
38,Classification of diffusion modes in single-particle tracking data: Feature-based versus deep-learning approach,100,3,,"Kowalek Patrycja,Loch-Olszewska Hanna,Szwabinski Janusz","Kowalek P,Loch-Olszewska H,Szwabinski J",Kowalek P,10.1103/PhysRevE.100.032410,Wroclaw University of Science & Technology,"Single-particle trajectories measured in microscopy experiments contain important information about dynamic processes occurring in a range of materials including living cells and tissues. However, extracting that information is not a trivial task due to the stochastic nature of the particles' movement and the sampling noise. In this paper, we adopt a deep-learning method known as a convolutional neural network (CNN) to classify modes of diffusion from given trajectories. We compare this fully automated approach working with raw data to classical machine learning techniques that require data preprocessing and extraction of human-engineered features from the trajectories to feed classifiers like random forest or gradient boosting. All methods are tested using simulated trajectories for which the underlying physical model is known. From the results it follows that CNN is usually slightly better than the feature-based methods, but at the cost of much longer processing times. Moreover, there are still some borderline cases in which the classical methods perform better than CNN.","INTRACELLULAR-TRANSPORT,MOLECULE MICROSCOPY,MOTION,CELLS",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,2.414,"INTRACELLULAR-TRANSPORT,MOLECULE,MICROSCOPY,MOTION,CELLS",PHYSICAL REVIEW E,http://arxiv.org/pdf/1902.07942,
39,Machine-learning model for predicting phase formations of high-entropy alloys,3,9,,"Li Yao);,Guo Wanlin","Li Y,Guo WL",Guo WL,10.1103/PhysRevMaterials.3.095005,Nanjing University of Aeronautics & Astronautics,"The phase formations of high-entropy alloys (HEAs) are essential to their properties, but efficient prediction of them remains a challenge. In this work, we propose a support vector machine model that is capable of distinguishing stable body-centered cubic (BCC), face-centered cubic (FCC) HEA phases, and the remaining phases out of the 322 as-cast samples with a cross validation accuracy over 90% after training and test. With the model, we predicted 369 FCC and 267 BCC equiatomic HEAs from the composition space of 16 metallic elements, one order larger than the number of available experimental data. Furthermore, dozens of refractory HEAs with high ratios of melting temperature to density have been screened out. Eleven of them agree with recent experiments and the 20 quinary ones with highest melting temperatures are validated through first-principles calculations. The proposed model is complementary to the calculation of phase diagrams and ab initio methods and could serve as an effective guide for designing new HEAs.","SOLID-SOLUTION PHASE,MECHANICAL-PROPERTIES,MICROSTRUCTURE,THERMODYNAMICS,EXPLORATION,BEHAVIOR,DESIGN",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Materials Science,,4.034,"SOLID-SOLUTION,PHASE,MECHANICAL-PROPERTIES,MICROSTRUCTURE,THERMODYNAMICS,EXPLORATION,BEHAVIOR,DESIGN",PHYSICAL REVIEW MATERIALS,,
40,,,,,,,,,,,,,,,,,,,,
41,,,,,,,,,,,,,,,,,,,,
42,,,,,,,,,,,,,,,,,,,,
43,Optimisation of hybrid tandem metal active gas welding using Gaussian process regression,25,3,208-217,"Lee Dae Young,Leifsson Leifur,Kim Jin-Young,Lee Seung Hwan","Lee DY,Leifsson L,Kim JY,Lee SH",Lee SH,10.1080/13621718.2019.1666222,Korea Aerospace University,"In this paper, an additional filler wire with opposite polarity was inserted in tandem flux cored arc welding process to increase the welding speed and deposition rate. In this hybrid welding, the optimisation of welding parameters is required to improve the bead geometry which directly indicates the welding quality. However, the correlation between the parameters and the bead geometry is hard to identify, so the process parameters are usually selected intuitively by the experienced engineers. Therefore, welding process modelling is constructed with the Gaussian process regression model, and parameter optimisation is performed with sequential quadratic programming optimisation algorithm. The proposed modelling optimisation process is verified by performing the welding experiment using the parameters that are optimised by the proposed process.","Tandem flux cored arc welding,hot-wire,hybrid tandem metal active gas welding,Gaussian process regression,parameter optimisation,fillet welding,machine learning",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Materials Science,Metallurgy & Metallurgical Engineering",,3.704,"PARAMETER,OPTIMIZATION,PREDICTION",SCIENCE AND TECHNOLOGY OF WELDING AND JOINING,,
44,Knee menisci segmentation and relaxometry of 3D ultrashort echo time cones MR imaging using attention U-Net with transfer learning,83,3,1109-1122,"Byra Michal,Wu Mei,Zhang Xiaodong,Jang Hyungseok,Ma Ya-Jun,Chang Eric Y.,Shah Sameer,Du Jiang","Byra M,Wu M,Zhang XD,Jang H,Ma YJ,Chang EY,Shah S,Du J",Du J,10.1002/mrm.27969,University of California System,"Purpose To develop a deep learning-based method for knee menisci segmentation in 3D ultrashort echo time (UTE) cones MR imaging, and to automatically determine MR relaxation times, namely the T1, T1(rho), and T2* parameters, which can be used to assess knee osteoarthritis (OA). Methods Whole knee joint imaging was performed using 3D UTE cones sequences to collect data from 61 human subjects. Regions of interest (ROIs) were outlined by 2 experienced radiologists based on subtracted T1(rho)-weighted MR images. Transfer learning was applied to develop 2D attention U-Net convolutional neural networks for the menisci segmentation based on each radiologist's ROIs separately. Dice scores were calculated to assess segmentation performance. Next, the T1, T1(rho), T2* relaxations, and ROI areas were determined for the manual and automatic segmentations, then compared. Results The models developed using ROIs provided by 2 radiologists achieved high Dice scores of 0.860 and 0.833, while the radiologists' manual segmentations achieved a Dice score of 0.820. Linear correlation coefficients for the T1, T1(rho), and T2* relaxations calculated using the automatic and manual segmentations ranged between 0.90 and 0.97, and there were no associated differences between the estimated average meniscal relaxation parameters. The deep learning models achieved segmentation performance equivalent to the inter-observer variability of 2 radiologists. Conclusion The proposed deep learning-based approach can be used to efficiently generate automatic segmentations and determine meniscal relaxations times. The method has the potential to help radiologists with the assessment of meniscal diseases, such as OA.","deep learning,menisci,osteoarthritis,quantitative MR,segmentation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"RELAXATION-TIME,OSTEOARTHRITIS,CARTILAGE,T2",MAGNETIC RESONANCE IN MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6879791,
45,Phillips-Inspired Machine Learning for Band Gap and Exciton Binding Energy Prediction,10,18,5640-+,"Liang Jiechun,Zhu Xi","Liang JC,Zhu X",Zhu X,10.1021/acs.jpclett.9b02232,Chinese University of Hong Kong,"In this work, inspired by Phillips's ionicity theory in solid-state physics, we directly sort out the critical factors of the band gap's feature correlations in the machine learning architected with the Lasso algorithm. Even based on a small 2D materials data set, we can fundamentally approach an accurate and rational model about the band gap and exciton binding energy with robust transferability to other databases. Our machine learning outputs can reveal the exact physics pictures behind the predicted quantity as well as the ""secondary understanding"" of the correlation between the approximated physics models in exciton. This work stresses the significant value of physics endorsement on the machine learning (ML) algorithm and provides a symbolic regression solution for the ""few-shot"" training scheme for ML technology in materials science. Moreover, physics-inspired secondary understanding could be an essential supplement for ML in scientific research fields.","DENSITY-FUNCTIONAL THEORY,BINARY COMPOUNDS,SEMICONDUCTORS,RESOLUTION,SELECTION",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,7.643,"DENSITY-FUNCTIONAL,THEORY,BINARY,COMPOUNDS,SEMICONDUCTORS,RESOLUTION,SELECTION",JOURNAL OF PHYSICAL CHEMISTRY LETTERS,,
46,The racializing forces of/in AI educational technologies*,45,3,236-250,"Dixon-Roman Ezekiel,Nichols T. Philip,Nyame-Mensah Ama","Dixon-Roman E,Nichols TP,Nyame-Mensah A",Dixon-Roman E,10.1080/17439884.2020.1667825,University of Pennsylvania,"In this article, we examine the sociopolitical implications of AI technologies as they are integrated into writing instruction and assessment. Drawing from new materialist and Black feminist thought, we consider how learning analytics platforms for writing are animated by and through entanglements of algorithmic reasoning, state standards and assessments, embodied literacy practices, and sociopolitical relations. We do a close reading of research and development documents associated with Essay Helper, a machine learning platform that provides formative feedback on student writing based on standards-aligned rubrics and training data. In particular, we consider the performative acts of the algorithm in the Essay Helper platform - both in the ways that reconstitutes material-discursive relations of difference, and its implications for transactions of teaching and learning. We argue that, through these processes, the algorithms function as racializing assemblages, and conclude by suggesting pathways toward alternative futures that reconfigure the sociopolitical relations the platform inherits.","AI,machine learning,learning analytics,new materialisms,black study",Article,"ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND",Education & Educational Research,,4.621,"LEARNING,ANALYTICS,POPULATION",LEARNING MEDIA AND TECHNOLOGY,,
47,"Materials Databases: The Need for Open, Interoperable Databases with Standardized Data and Rich Metadata",2,11,,Coudert Francois-Xavier,Coudert FX,Coudert FX,10.1002/adts.201900131,Centre National de la Recherche Scientifique (CNRS),"Driven by the recent rapid increase in the number of materials databases published (open and commercial), some perspectives on the growing need for standardized, interoperable, open databases are discussed here. The field of computational materials discovery is quickly expanding, and recent advances in data mining, high-throughput screening, and machine learning highlight the potential of open databases.","databases,metadata,open science",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Science & Technology - Other Topics,,,"METAL-ORGANIC,FRAMEWORKS",ADVANCED THEORY AND SIMULATIONS,https://hal.archives-ouvertes.fr/hal-02492782/file/1907.02791.pdf,
48,"Artificial intelligence techniques for the vibration, noise, and emission characteristics of a hydrogen-enriched diesel engine",41,18,2194-2206,"Yildirim Sefa,Tosun Erdi,Calik Ahmet,Uluocak Ihsan,Avsar Ercan","Yildirim S,Tosun E,Calik A,Uluocak I,Avsar E",Calik A,10.1080/15567036.2018.1550540,Mersin University,"The present paper investigates the prediction of vibration, noise level, and emission characteristics of a four-stroke, four-cylinder diesel engine fueled with sunflower, canola, and corn biodiesel blends while H-2 injected through inlet manifold using two different artificial intelligence methods: artificial neural network(ANN) and support vector machines(SVM). The aim of using these methods is to predict vibration, noise, carbon monoxide (CO), CO2, and NOx based on the initial experimental study by varying engine speed, blends of biodiesel, and H-2 energy substitution ratio. Experimental data weregathered from the literature. For theANN method, LevenbergMarquardt backpropagation training algorithm with logarithmic sigmoid and linear transfer function for hidden and output layers, respectively, gives the best results for prediction of vibration, noise, and emission characteristics. For SVM, a regression model is implemented with Gaussian kernel function. Results show that the ANN performs better than SVM, and the bestmean average percent error and R-2 for the models developed are 2.03 and 0.988 for vibration acceleration, 0.39 and 0.9615 for noise, 7.27 and 0.8549 for CO, 5.09 and 0.9398 for NOx, and2.21 and 0.993 for CO2 values, respectively. Eventually, it is found that the ANN method is a good choice for simulation and prediction of dual fueled hydrogen sunflower, canola, and corn biodiesel blends.","Vibration,noise,hydrogen fuel,artificial neural network,support vector machines,biodiesel",Article,"TAYLOR & FRANCIS INC, 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA","Energy & Fuels,Engineering,Environmental Sciences & Ecology",,2.406,"EXHAUST,EMISSIONS,BIODIESEL,BLENDS,GASOLINE-ENGINE,OIL,BIODIESEL,FUEL,BLENDS,PERFORMANCE,PREDICTION,COMBUSTION,BUTANOL,CASTOR",ENERGY SOURCES PART A-RECOVERY UTILIZATION AND ENVIRONMENTAL EFFECTS,,
49,Application of Deep Learning in Food: A Review,18,6,1793-1811,"Zhou Lei,Zhang Chu,Liu Fei,Qiu Zhengjun,He Yong","Zhou L,Zhang C,Liu F,Qiu ZJ,He Y",Zhang C,10.1111/1541-4337.12492,Zhejiang University,"Deep learning has been proved to be an advanced technology for big data analysis with a large number of successful cases in image processing, speech recognition, object detection, and so on. Recently, it has also been introduced in food science and engineering. To our knowledge, this review is the first in the food domain. In this paper, we provided a brief introduction of deep learning and detailedly described the structure of some popular architectures of deep neural networks and the approaches for training a model. We surveyed dozens of articles that used deep learning as the data analysis tool to solve the problems and challenges in food domain, including food recognition, calories estimation, quality detection of fruits, vegetables, meat and aquatic products, food supply chain, and food contamination. The specific problems, the datasets, the preprocessing methods, the networks and frameworks used, the performance achieved, and the comparison with other popular solutions of each research were investigated. We also analyzed the potential of deep learning to be used as an advanced data mining tool in food sensory and consume researches. The result of our survey indicates that deep learning outperforms other methods such as manual feature extractors, conventional machine learning algorithms, and deep learning as a promising tool in food quality and safety inspection. The encouraging results in classification and regression problems achieved by deep learning will attract more research efforts to apply deep learning into the field of food in the future.","computer vision,deep learning,food quality,food recognition,spectroscopy",Review,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Food Science & Technology,,15.365,"CONVOLUTIONAL,NEURAL-NETWORK,COMPUTER,VISION,QUALITY,RECOGNITION,EXTRACTION,SYSTEM,IMAGES,LOINS",COMPREHENSIVE REVIEWS IN FOOD SCIENCE AND FOOD SAFETY,,
50,A practical computerized decision support system for predicting the severity of Alzheimer's disease of an individual,130,,157-171,"Bucholc Magda,Ding Xuemei,Wang Haiying,Glass David H.,Wang Hui,Prasad Girijesh,Maguire Liam P.,Bjourson Anthony J.,McClean Paula L.,Todd Stephen","Bucholc M,Ding XM,Wang HY,Glass DH,Wang H,Prasad G,Maguire LP,Bjourson AJ,McClean PL,Todd S",Bucholc M; Wong-Lin K,10.1016/j.eswa.2019.04.022,Ulster University,"Computerized clinical decision support systems can help to provide objective, standardized, and timely dementia diagnosis. However, current computerized systems are mainly based on group analysis, discrete classification of disease stages, or expensive and not readily accessible biomarkers, while current clinical practice relies relatively heavily on cognitive and functional assessments (CFA). In this study, we developed a computational framework using a suite of machine learning tools for identifying key markers in predicting the severity of Alzheimer's disease (AD) from a large set of biological and clinical measures. Six machine learning approaches, namely Kernel Ridge Regression (KRR), Support Vector Regression, and k-Nearest Neighbor for regression and Support Vector Machine (SVM), Random Forest, and k-Nearest Neighbor for classification, were used for the development of predictive models. We demonstrated high predictive power of CFA. Predictive performance of models incorporating CFA was shown to consistently have higher accuracy than those based solely on biomarker modalities. We found that KRR and SVM were the best performing regression and classification methods respectively. The optimal SVM performance was observed for a set of four CFA test scores (FAQ ADAS13, MoCA, MMSE) with multi-class classification accuracy of 83.0%, 95%CI = (72.1%, 93.8%) while the best performance of the KRR model was reported with combined CFA and MRI neuroimaging data, i.e., R-2=0.874, 95%CI = (0.827, 0.922). Given the high predictive power of CFA and their widespread use in clinical practice, we designed a data-driven and self-adaptive computerized clinical decision support system (CDSS) prototype for evaluating the severity of AD of an individual on a continuous spectrum. The system implemented an automated computational approach for data pre-processing, modelling, and validation and used exclusively the scores of selected cognitive measures as data entries. Taken together, we have developed an objective and practical CDSS to aid AD diagnosis. (C) 2019 Elsevier Ltd. All rights reserved.","Dementia,Alzheimer's disease,Decision support system,Machine learning,Diagnosis support,Cognitive impairment",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"MILD,COGNITIVE,IMPAIRMENT,MENTAL-STATE-EXAMINATION,FEATURE-SELECTION,ASSESSMENT,SCALE,FUNCTIONAL-ACTIVITIES,RANDOM,FOREST,ADAS-COG,FDG-PET,DEMENTIA,CLASSIFICATION",EXPERT SYSTEMS WITH APPLICATIONS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6688646,
51,A liver fibrosis staging method using cross-contrast network,130,,124-131,"Huang Yudan,Chen Ying,Zhu Haochuan,Li Weifeng,Ge Yun,Huang Xiaolin,He Jian","Huang YD,Chen Y,Zhu HC,Li WF,Ge Y,Huang XL,He J",Chen Y,10.1016/j.eswa.2019.03.049,Nanjing University,"In this paper we proposes a cross-contrast neural network (CCNN) for liver fibrosis classification. This method consists of two main parts. The first part extracts feature and gets the cross probability maps for utilizing the implicit contrast information among the inputs. The second part measures the similarity between two maps using the modified information based similarity (IBS) theory. IBS theory is a statistical method quantifies similarity between symbols and have been proved valid in many areas (Yang, Hseu, Yien, Goldberger, & Peng, 2003), but it has not been combined with neural network so far. CCNN combines the advantages of statistical analysis and convolutional neural networks, fitting the problem that the number of medical images is relatively small for traditional deep neural network to train. We apply CCNN on a 34-person dataset (23/11 for train/test) and the experimental results (shown in Table 3) clearly demonstrate the efficiency of the method. The highest accuracy is achieved on binary classification of F3 vs. F4, F0 vs.F3 and F1 vs. F3, which are 98.33%. The accuracy of no-to-moderate fibrosis (F0-2) vs. advanced fibrosis (F3-4) and 5 categories is 93.33% and 71.11% relatively. We find that most classification error occurs with F2. After removing F2, the classification accuracy of 4 categories rises to 84.44%. (C) 2019 Published by Elsevier Ltd.","Convolutional neural network,IBS theory,Liver fibrosis,Cross-contrast",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"HEPATIC-FIBROSIS,TEXTURE,ANALYSIS,CLASSIFICATION,DIAGNOSIS,MRI",EXPERT SYSTEMS WITH APPLICATIONS,,
52,A rule extraction approach from support vector machines for diagnosing hypertension among diabetics,130,,188-205,"Singh Namrata,Singh Pradeep,Bhagat Deepika","Singh N,Singh P,Bhagat D",Singh N,10.1016/j.eswa.2019.04.029,National Institute of Technology (NIT System),"Diabetes mellitus is a major non-communicable disease ever rising as an epidemic and a public health crisis worldwide. One of the several life-threatening complications of diabetes is hypertension or high blood pressure which mostly remains undiagnosed and untreated until symptoms become severe. Diabetic complications can be greatly reduced or prevented by early detection of individuals at risk. In recent past, several machine learning classification algorithms have been widely applied for diagnosing diabetes but very few studies have been conducted for detecting hypertension among diabetic subjects. Specifically, existing rule-based models fail to produce comprehensible rule sets. To resolve this limitation, this paper endeavours to develop a hybrid approach for extracting rules from support vector machines. A feature selection mechanism is introduced for selecting significantly associated features from the dataset. XGBoost has been utilized to convert SVM black box model into an apprehensible decision-making tool. A new dataset has been obtained from Pt. JNM, Medical College, Raipur, India comprising of 300 diabetic subjects with 108 hypertensives and 192 normotensives. In addition, five public diabetes-related datasets have been taken for generalization of the results. Experiments reveal that the proposed model outperforms ten other benchmark classifiers. Friedman rank and post hoc Bonferroni-Dunn tests demonstrate the significance of the proposed method over others. (C) 2019 Elsevier Ltd. All rights reserved.","Diabetes,Extreme gradient boosting,Hypertension,Medical diagnosis,Rule extraction,Support vector machine",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"HYBRID,INTELLIGENT,SYSTEM,CARDIOVASCULAR-DISEASE,BLOOD-PRESSURE,DATA,CLASSIFICATION,RISK-FACTORS,MODEL,EXPRESSION,ALGORITHM,SELECTION,MELLITUS",EXPERT SYSTEMS WITH APPLICATIONS,,
53,Characterization of CO2 storage and enhanced oil recovery in residual oil zones,183,,291-304,"Chen Bailian,Pawar Rajesh J.","Chen B,Pawar RJ",Chen B; Pawar RJ,10.1016/j.energy.2019.06.142,United States Department of Energy (DOE),"Residual oil zones (ROZs) are reservoirs in which oil is swept over geologic time period and exists at residual saturation. The oil in such reservoirs cannot be commercially exploited using conventional oil recovery methods as the oil exists at residual oil saturation. Instead, enhanced oil recovery methods such as CO2 injection are required. Recently, ROZs have been increasingly studied as potential CO2 storage targets. In spite of increased interest in ROZs, there are significant gaps in the knowledge of parameters and processes that impact CO2 storage and oil recovery. In this work, we identify key geologic and operational characteristics that affect CO2 storage capacity and oil recovery potential by performing Monte Carlo simulations and sensitivity analysis. In addition to CO2 storage capacity, we also characterize the long-term CO2 fate in ROZs. The distinction of CO2 storage in ROZs from conventional oil reservoirs and saline aquifers are also characterized. Furthermore, predictive models based on machine learning techniques are developed to estimate CO2 storage and oil production potentials for ROZs. The applicability of the predictive models is demonstrated for five ROZs in the Permian Basin. Published by Elsevier Ltd.","Residual oil zones,CO2 storage,Enhanced oil recovery,Predictive empirical models,Machine learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Thermodynamics,Energy & Fuels",,6.845,"UNCERTAINTY,QUANTIFICATION,SEQUESTRATION,OPTIMIZATION,RESERVOIR,DESIGN,MODELS",ENERGY,https://www.osti.gov/biblio/1530797,
54,Intelligent decisions to stop or mitigate lost circulation based on machine learning,183,,1104-1113,"Abbas Ahmed K.,Bashikh Ali A.,Abbas Hayder,Mohammed Haider Q.","Abbas AK,Bashikh AA,Abbas H,Mohammed HQ",Abbas AK,10.1016/j.energy.2019.07.020,"Iraqi Drilling Co, Basra, Iraq.","Lost circulation is one of the frequent challenges encountered during the drilling of oil and gas wells. It is detrimental because it can not only increase non-productive time and operational cost but also lead to other safety hazards such as wellbore instability, pipe sticking, and blow out. However, selecting the most effective treatment may still be regarded as an ill-structured issue since it does not have a unique solution. Therefore, the objective of this study is to develop an expert system that can screen drilling operation parameters and drilling fluid characteristics required to diagnose the lost circulation problem correctly and suggest the most appropriate solution for the issue at hand.
In the first step, field datasets were collected from 385 wells drilled in Southern Iraq from different fields. Then, fscaret package in R environment was applied to detect the importance and ranking of the input parameters that affect the lost circulation solution. The new models were developed to predict the lost circulation solution for vertical and deviated wells using artificial neural networks (ANNs) and support vector machine (SVM). The using of the machine learning methods could assist the drilling engineer to make an intelligent decision with proper corrective lost circulation treatment. (C) 2019 Elsevier Ltd. All rights reserved.","Lost circulation,Intelligent decision,Artificial neural networks,Support vector machine",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Thermodynamics,Energy & Fuels",,6.845,"ARTIFICIAL,NEURAL-NETWORK,FEATURE-SELECTION,EMISSION,CHARACTERISTICS,VECTOR,REGRESSION,SIZE,DISTRIBUTION,DIESEL-ENGINE,PREDICTION,PERFORMANCE,ALGORITHM,WELLBORE",ENERGY,,
55,Real-time monitoring of the moisture content of filter cakes in vacuum filters by a novel soft sensor,223,,282-291,"Huttunen Manu,Nygren Lauri,Kinnarinen Teemu,Ekberg Bjarne,Lindh Tuomo,Karvonen Vesa,Ahola Jero,Hakkinen Antti","Huttunen M,Nygren L,Kinnarinen T,Ekberg B,Lindh T,Karvonen V,Ahola J,Hakkinen A",Huttunen M,10.1016/j.seppur.2019.03.091,"LUT Univ, LUT Sch Energy Syst, POB 20, FI-53851 Lappeenranta, Finland.","The moisture content of filter cakes is probably the most important characteristic that should be kept at a desired level in industrial cake filtration applications to maintain consistent product quality and minimize energy consumption. Most of the currently applied methods for contactless real-time monitoring of the moisture content are based for example on x-ray or microwave techniques, and therefore, the equipment for the purpose is highly specialized. This paper introduces a novel soft sensor for filter cake moisture estimation that uses machine learning algorithms and data collected with basic process instrumentation. The method is primarily based on the cooling effect observed in the cake and air, caused by evaporation of liquid from the cake during the dewatering period, and it can be supported by other process data. The specific energy consumption of vacuum filtration and the subsequent thermal drying to zero moisture is also analyzed. The results of pilot-scale experiments with calcite slurry and a horizontal belt vacuum filter show that in order to minimize the specific energy consumption of vacuum filtration, it is crucial to find the right combination of slurry concentration, vacuum level, and mass of filter cake per unit area. The proposed method for estimating the filter cake moisture content is especially suitable for real-time monitoring and control, enabling also considerable reduction in the energy consumption of the overall process. When applying the proposed soft sensor method in a pilot-scale process, the mean absolute error of the estimated moisture content of the filter cake is similar to 0.4 percentage points when the temperature of air at the vacuum pump inlet and the vacuum pump air flow rate are included in the input variables.","Thermodynamics,Vacuum filtration,Dewatering,Moisture content prediction,Soft sensor",Article,"ELSEVIER SCIENCE BV, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS",Engineering,,6.656,MODEL,SEPARATION AND PURIFICATION TECHNOLOGY,https://lutpub.lut.fi/bitstream/10024/160202/1/huttunen_et_al_real-time_monitoring_accepted_version.pdf,
56,EEG-Based Emotion Recognition Using Deep Convolutional Neural Network,55,18,103-110,",,,","Chen Jingxia,Wang Liyan,Jia Xiaoyun,Zhang Pengwei",,,Chen Jingxia,"In order to improve the accuracy of emotional recognition by end-to-end automatic learning of emotional features in spatial and temporal dimensions of electroencephalogram(EEG), an EEG emotional feature learning and classification method using deep Convolution Neural Network(CNN) models is proposed based on temporal features, frequential features and their combination features of EEG signals in DEAP dataset. The shallow machine learning models including Bagging Tree(BT), Support Vector Machine(SVM), Linear Discriminant Analysis(LDA) and Bayesian Linear Discriminant Analysis(BLDA) models and deep CNN models are used to make emotional binary classification experiments on DEAP datasets in valence and arousal dimensions. The experimental results show that the deep CNN models achieve the best recognition performance on temporal and frequency combined features in both valence and arousal dimensions, which is 3.58% higher than the performance of the best traditional BT classifier in valence dimension and 3.29% higher than that of BT classifier in arousal dimension.",electroencephalogram(EEG); Convolution Neural Network(CNN); deep learning; emotion recognition; combined features,Article,,,,,,,,
57,SUBSTRA: Supervised Bayesian Patient Stratification,35,18,3263-3272,"Khakabimamaghani Sahand,Kelkar Yogeshwar D.,Grande Bruno M.,Morin Ryan D.,Ester Martin,Ziemek Daniel","Khakabimamaghani S,Kelkar YD,Grande BM,Morin RD,Ester M,Ziemek D",Ester M,10.1093/bioinformatics/btz112,Simon Fraser University,"Motivation: Patient stratification methods are key to the vision of precision medicine. Here, we consider transcriptional data to segment the patient population into subsets relevant to a given phenotype. Whereas most existing patient stratification methods focus either on predictive performance or interpretable features, we developed a method striking a balance between these two important goals.
Results: We introduce a Bayesian method called SUBSTRA that uses regularized biclustering to identify patient subtypes and interpretable subtype-specific transcript clusters. The method iteratively re-weights feature importance to optimize phenotype prediction performance by producing more phenotype-relevant patient subtypes. We investigate the performance of SUBSTRA in finding relevant features using simulated data and successfully benchmark it against state-of-the-art unsupervised stratification methods and supervised alternatives. Moreover, SUBSTRA achieves predictive performance competitive with the supervised benchmark methods and provides interpretable transcriptional features in diverse biological settings, such as drug response prediction, cancer diagnosis, or kidney transplant rejection.",CANCER,Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Computer Science,Mathematical & Computational Biology,Mathematics",,8.47,CANCER,BIOINFORMATICS,https://www.biorxiv.org/content/biorxiv/early/2019/02/03/538512.full.pdf,
58,Structured crowdsourcing enables convolutional segmentation of histology images,35,18,3461-3467,"Amgad Mohamed,Elfandy Habiba,Hussein Hagar,Atteya Lamees A.,Elsebaie Mai A. T.,Elnasr Lamia S. Abo,Sakr Rokia A.,Salem Hazem S. E.,Ismail Ahmed F.,Saad Anas M.","Amgad M,Elfandy H,Hussein H,Atteya LA,Elsebaie MAT,Elnasr LSA,Sakr RA,Salem HSE,Ismail AF,Saad AM",Cooper LAD,10.1093/bioinformatics/btz083,Emory University,"Motivation: While deep-learning algorithms have demonstrated outstanding performance in semantic image segmentation tasks, large annotation datasets are needed to create accurate models. Annotation of histology images is challenging due to the effort and experience required to carefully delineate tissue structures, and difficulties related to sharing and markup of whole-slide images.
Results: We recruited 25 participants, ranging in experience from senior pathologists to medical students, to delineate tissue regions in 151 breast cancer slides using the Digital Slide Archive. Interparticipant discordance was systematically evaluated, revealing low discordance for tumor and stroma, and higher discordance for more subjectively defined or rare tissue classes. Feedback provided by senior participants enabled the generation and curation of 20 000+ annotated tissue regions. Fully convolutional networks trained using these annotations were highly accurate (mean AUC=0.945), and the scale of annotation data provided notable improvements in image classification accuracy.",DIGITAL SLIDE ARCHIVE,Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Computer Science,Mathematical & Computational Biology,Mathematics",,8.47,"DIGITAL,SLIDE,ARCHIVE",BIOINFORMATICS,http://pdfs.semanticscholar.org/e836/097124961253cd69f794fd80b22c9799a2f0.pdf,
59,Identification of caveolin-1 domain signatures via machine learning and graphlet analysis of single-molecule super-resolution data,35,18,3468-3475,"Khater Ismail M.,Meng Fanrui,Nabi Ivan Robert,Hamarneh Ghassan","Khater IM,Meng FR,Nabi IR,Hamarneh G",Hamarneh G,10.1093/bioinformatics/btz113,Simon Fraser University,"Motivation: Network analysis and unsupervised machine learning processing of single-molecule localization microscopy of caveolin-1 (Cav1) antibody labeling of prostate cancer cells identified biosignatures and structures for caveolae and three distinct non-caveolar scaffolds (S1A, S1B and S2). To obtain further insight into low-level molecular interactions within these different structural domains, we now introduce graphlet decomposition over a range of proximity thresholds and show that frequency of different subgraph (k = 4 nodes) patterns for machine learning approaches (classification, identification, automatic labeling, etc.) effectively distinguishes caveolae and scaffold blobs.
Results: Caveolae formation requires both Cav1 and the adaptor protein CAVIN1 (also called PTRF). As a supervised learning approach, we applied a wide-field CAVIN1/PTRF mask to CAVIN1/PTRF-transfected PC3 prostate cancer cells and used the random forest classifier to classify blobs based on graphlet frequency distribution (GFD). GFD of CAVIN1/PTRF-positive (PTRF+) and -negative Cav1 clusters showed poor classification accuracy that was significantly improved by stratifying the PTRF+ clusters by either number of localizations or volume. Low classification accuracy (<50%) of large PTRF+ clusters and caveolae blobs identified by unsupervised learning suggests that their GFD is specific to caveolae. High classification accuracy for small PTRF+ clusters and caveolae blobs argues that CAVIN1/PTRF associates not only with caveolae but also non-caveolar scaffolds. At low proximity thresholds (50-100 nm), the caveolae groups showed reduced frequency of highly connected graphlets and increased frequency of completely disconnected graphlets. GFD analysis of single-molecule localization microscopy Cav1 clusters defines changes in structural organization in caveolae and scaffolds independent of association with CAVIN1/PTRF.","NETWORK,ARCHITECTURE,CAVIN,COAT",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Computer Science,Mathematical & Computational Biology,Mathematics",,8.47,"NETWORK,ARCHITECTURE,CAVIN,COAT",BIOINFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6748737,
60,Stochastic characterization of textile reinforcements in composites based on X-ray microtomographic scans,224,,,"Madra Anna,Causse Philippe,Trochu Francois,Adrie Jerome,Maire Eric,Breitkopf Piotr","Madra A,Causse P,Trochu F,Adrie J,Maire E,Breitkopf P",Madra A,10.1016/j.compstruct.2019.111031,Pennsylvania Commonwealth System of Higher Education (PCSHE),"A stochastic method is introduced to characterize the dual-scale geometry of textile reinforcements in composites. The fiber tows are identified automatically from X-ray microtomographic scans with a machine learning algorithm, quantifying the error of the procedure. The tow geometry is then used to construct a stochastic model as a Gaussian Random Process which permits quantification of the uncertainty in the measurements of micro-scale fiber volume fraction. The hyperparameters of the model are calibrated with a custom-built multi-objective evolutionary algorithm. The approach is illustrated by the analysis of a vinyl-ester composite reinforced with a glass fiber non-crimp fabric.","Textile composites,X-ray microtomography,Multi-scale modeling,Uncertainty quantification",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Mechanics,Materials Science",,5.536,"FE,ANALYSES,SEGMENTATION,DEFORMATION,SIMULATION,INTERFACES,BEHAVIOR",COMPOSITE STRUCTURES,,
61,"Automated fibre placement based composite structures: Review on the defects, impacts and inspections techniques",224,,,"Oromiehie Ebrahim,Prusty B. Gangadhara,Compston Paul,Rajan Ginu","Oromiehie E,Prusty BG,Compston P,Rajan G",Oromiehie E,10.1016/j.compstruct.2019.110987,University of New South Wales Sydney,"Automated fibre placement (AFP) offers high throughput, efficient and accurate manufacturing methods for making multi-stiffened laminated composites. However, processing conditions, machine tolerances and steering of tape can induce small random defects within the laminate, which may compromise the structural integrity. Thus, this paper presents a comprehensive review on the processing/steering-induced defects in AFP and their influence on the quality of the final product. Three key processing parameters in AFP, specifically consolidation force, lay-up speed and curing/melting temperature are attempted elaborately. Additionally, the paper attempted to present the discussions on in-situ process monitoring as well as the Machine Learning (ML) based predictive models for AFP based composites.","Automated fibre placement,Processing defects",Review,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Mechanics,Materials Science",,5.536,"SANDWICH,COMPOSITES,RESIDUAL-STRESSES,BRAGG-GRATINGS,STRAIN,TEMPERATURE,STRENGTH,FBG,COMPRESSION,WAVINESS,SENSORS",COMPOSITE STRUCTURES,,
62,Gaussian approximation potential for studying the thermal conductivity of silicene,126,10,,"Zhang Cunzhi,Sun Qiang","Zhang CZ,Sun Q",Sun Q,10.1063/1.5119281,Peking University,"Due to the compatibility with the well-developed Si-based semiconductor technology, the properties of silicene and silicene-based materials have attracted tremendous attention. Among them, the thermal conductivity (TC) is of special importance for electronic devices. However, unlike graphene, the poor quality of empirical potentials hinders the reliable evaluation of TC for silicene using molecular dynamics (MD). Here, we present a Gaussian approximation potential (GAP) for silicene based on ab initio derived training data. The potential can precisely describe the geometries, mechanical properties, as well as phonon dispersion of free-standing sheet, outperforming any other empirical ones. Using sinusoidal approach-to-equilibrium MD simulations based on the GAP potential, the TC of silicene is found to be 32.4 +/- 2.9W/mK at room temperature. Importantly, our result achieves a good agreement with Boltzmann transport equation (BTE) based first-principles predictions (similar to 30W/mK), such that the TC value of silicene is confirmed via both MD and BTE; thus, we prove that the accuracy of machine learning potentials, like GAP, can enable a faithful prediction of TC at a density functional theory (DFT) level.",,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,,JOURNAL OF APPLIED PHYSICS,,
63,A quantitative uncertainty metric controls error in neural network-driven chemical discovery,10,34,7913-7922,"Janet Jon Paul,Duan Chenru,Yang Tzuhsiung,Nandy Aditya,Kulik Heather J.","Janet JP,Duan CR,Yang TH,Nandy A,Kulik HJ",Kulik HJ,10.1039/c9sc02298h,Massachusetts Institute of Technology (MIT),"Machine learning (ML) models, such as artificial neural networks, have emerged as a complement to high-throughput screening, enabling characterization of new compounds in seconds instead of hours. The promise of ML models to enable large-scale chemical space exploration can only be realized if it is straightforward to identify when molecules and materials are outside the model's domain of applicability. Established uncertainty metrics for neural network models are either costly to obtain (e.g., ensemble models) or rely on feature engineering (e.g., feature space distances), and each has limitations in estimating prediction errors for chemical space exploration. We introduce the distance to available data in the latent space of a neural network ML model as a low-cost, quantitative uncertainty metric that works for both inorganic and organic chemistry. The calibrated performance of this approach exceeds widely used uncertainty metrics and is readily applied to models of increasing complexity at no additional cost. Tightening latent distance cutoffs systematically drives down predicted model errors below training errors, thus enabling predictive error control in chemical discovery or identification of useful data points for active learning.","CATALYST DESIGN,MACHINE,MOLECULES,LIBRARY,SYSTEM,MODEL",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND",Chemistry,,9.658,"CATALYST,DESIGN,MACHINE,MOLECULES,LIBRARY,SYSTEM,MODEL",CHEMICAL SCIENCE,https://dspace.mit.edu/bitstream/1721.1/134631/2/c9sc02298h.pdf,
64,Rationalizing the interphase stability of Li|doped-Li(7)La(3)Zr(2)O(12)via automated reaction screening and machine learning,7,34,19961-19969,"Liu Bo,Yang Jiong,Yang Hongliang,Ye Caichao,Mao Yuanqing,Wang Jiping,Shi Siqi,Yang Jihui,Zhang Wenqing","Liu B,Yang J,Yang HL,Ye CC,Mao YQ,Wang JP,Shi SQ,Yang JH,Zhang WQ",Yang J,10.1039/c9ta06748e,Shanghai University,"Lithium metal batteries are a promising candidate for future high-energy-density energy storage. However, dendrite growth and the high reactivity of the Li metal anode result in low cycling efficiency and severe safety concerns. Here, we present a strategy to stabilize the lithium metal anode through cation doping in Li7La3Zr2O12 (LLZOM, M = dopant). High-throughput automated reaction screening together with a machine learning approach are developed to evaluate possible reactions and the thermodynamic stability of the Li|LLZOM interfaces under various chemical conditions. It is discovered that some dopants, such as M = Sc3+ (doping on Zr site), Ce3+ (La or Zr), Ac3+ (La), Y3+ (La or Zr), Tm3+ (La or Zr), Er3+ (La or Zr), Ho3+ (La or Zr), Dy3+ (La or Zr), Nd3+ (La or Zr), Tb3+ (La or Zr), Pr3+ (La), Pm3+ (La or Zr), Sm3+ (La or Zr), Gd3+ (La or Zr), Lu3+ (La), Ce4+ (Zr), Th4+ (Zr), and Pa5+ (Zr), exhibit thermodynamic stability against Li; while others, M = Ca2+ (La or Zr), Yb3+ (La), Br3+ (Li), Te4+ (Zr), Se4+ (Zr), S4+ (Zr), Hf4+ (Zr), Cl5+ (Zr), and I5+ (Zr), may lead to the spontaneous formation of a stable, passivating solid electrolyte interphase (SEI) layer on the Li metal, and alleviate dendritic lithium growth. From the machine learning approach, the formation energy of oxides MxOy emerges as the most crucial feature dominating the route of interface reactions, implying that the M-O bond strength governs the interface stability of the cation-doped LLZOM. The machine learning model then predicts 18 unexplored LLZOM systems, which are all validated in subsequent calculations. Our work offers practical insights for experimentalists into the selection of appropriate dopants in LLZO to stabilize Li metal anodes in solid-state batteries.","LITHIUM METAL ANODE,SOLID-ELECTROLYTE,ION CONDUCTORS,THERMODYNAMIC STABILITY,LI7LA3ZR2O12,CONDUCTIVITY,1ST-PRINCIPLES,INSTABILITY,INTERFACE,KINETICS",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Energy & Fuels,Materials Science",,11.995,"LITHIUM,METAL,ANODE,SOLID-ELECTROLYTE,ION,CONDUCTORS,THERMODYNAMIC,STABILITY,LI7LA3ZR2O12,CONDUCTIVITY,1ST-PRINCIPLES,INSTABILITY,INTERFACE,KINETICS",JOURNAL OF MATERIALS CHEMISTRY A,,
65,,,,,,,,,,,,,,,,,,,,
66,Varicose ulcer(C6) wound image tissue classification using multidimensional convolutional neural networks,67,7,374-384,"Rajathi V,Bhavani R. R.,Jiji G. Wiselin","Rajathi V,Bhavani RR,Jiji GW",Rajathi V,10.1080/13682199.2019.1663083,"Dr Sivanthi Aditanar Coll Engn, Dept Comp Sci & Engn, Tiruchendur 628215, Tamil Nadu, India.","Varicose ulcers occur due to improper functioning of venous valves in legs. These ulcers are the severe external signs of vein-related problems, such as chronic pain, leg swelling and leg heaviness. The aim of the proposed methodology is to increase better diagnosis and treatment results by computer-assisted tissue classification (granulation, slough, necrotic and epithelial) of varicose ulcer using the Multidimensional Convolutional Neural Network as a deep learning architecture. This work consists of (i) preprocessing to remove the flash light reflection from the RGB wound images, (ii) active contour segmentation to segment the wounded areas from the skin and (iii) Multidimensional convolutional neural network for which the segmented images and their corresponding ground truth images are given as input. After CNN training, the fully connected layer gives the output as segmented images which include different types of tissues which are to be predicted. The Multidimensional Convolutional Neural Network structure of the layer can be modified by defining the layer structure using Matlab functions to get more accurate results for tissue classification. The proposed approach is evaluated using metrics with efficient performance rates of average accuracy (99.55%), specificity (98.06%) and sensitivity (95.66%). Experiments conducted on varicose ulcer wound image aim to improve healing status and skin health conditions based on the texture of the tissue.","Active venous ulcer,flash light removal,active contour segmentation,Multidimensional Convolutional Neural network",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Imaging Science & Photographic Technology,,0.987,DIAGNOSIS,IMAGING SCIENCE JOURNAL,,
67,,,,,,,,,,,,,,,,,,,,
68,,,,,,,,,,,,,,,,,,,,
69,Teaching an Old Dog New Tricks: Machine Learning an Improved TIP3P Potential Model for Liquid-Vapor Phase Phenomena,123,36,22643-22655,"Loeffler Troy D.,Chan Henry,Sasikumar Kiran,Narayanan Badri,Cherukara Mathew J.,Gray Stephen,Sankaranarayanan Subramanian K. R. S.","Loeffler TD,Chan H,Sasikumar K,Narayanan B,Cherukara MJ,Gray S,Sankaranarayanan SKRS",Loeffler TD; Chan H; Sankaranarayanan SKRS,10.1021/acs.jpcc.9b06348,United States Department of Energy (DOE),"Water is ubiquitous yet displays a rich variety of thermodynamic properties and anomalies. An understanding of liquid-vapor phenomena in water is of broad importance to everyday processes such as evaporation, condensation, and cavitation, as well as energy technologies such as steam turbines. An accurate description of the vapor-liquid phenomena is quite challenging owing to the significant differences between how water behaves in small, sparsely distributed clusters and how it behaves in a dense bulk liquid. It is not surprising that there exist a myriad of different water models, which have attempted to describe water behavior with varying degrees of success. In general, water models have evolved from simple three-point transferable interatomic potentials (TIP3P) to more complex four-point and five-point TIP models to more recent polarizable models. The natural evolution from TIP3P to TIP4P families of models was, in part, due to the belief that we have perhaps reached the limit of what the simple three-point models are capable of achieving. The advent of big data analytics and ever-increasing supercomputing resources has brought to the forefront powerful machine learning techniques for materials design. Here, we take advantage of machine learning techniques such as hierarchical objective genetic algorithms to demonstrate that simple computationally efficient models developed decades ago can be retrained to perform significantly better than their original counterparts. In a departure from typical practice, we train our model against an elaborate temperature-dependent data obtained from molecular dynamics trajectories to cluster properties using extensive configurational sampling and on-the-fly Monte Carlo simulations. To demonstrate the power of our machine learning approach, we choose the popular TIP3P model that, however, is widely acknowledged to perform poorly in describing vapor-liquid properties. We retrain this TIP3P model to dramatically improve its performance over the original model. Our new ML-TIP3P performs on par or, in some respects, better than even the current best performing nonpolarizable model (TIP4P/2005) for vapor-liquid properties. To exemplify the suitability of our approach, we apply our newly developed model to study a highly nonequilibrium vapor-liquid phenomenon, laser-induced heterogeneous cavitation in a gold-water system. Overall, our study highlights a general strategy for atomistic model development that can be potentially used to retrain existing potential models and help them attain their best possible performance.","TRIPLE POINT,WATER,EQUILIBRIA,CAVITATION,SIMULATION,TIP4P/2005,GENERATION,NUCLEATION,ENSEMBLE,DYNAMICS",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,4.467,"TRIPLE,POINT,WATER,EQUILIBRIA,CAVITATION,SIMULATION,TIP4P%2F2005,GENERATION,NUCLEATION,ENSEMBLE,DYNAMICS",JOURNAL OF PHYSICAL CHEMISTRY C,,
70,,,,,,,,,,,,,,,,,,,,
71,Emerging role of machine learning in light-matter interaction,8,,,"Zhou Jiajia,Huang Bolong,Yan Zheng,Bunzli Jean-Claude G.","Zhou JJ,Huang BL,Yan Z,Bunzli JCG",Zhou JJ,10.1038/s41377-019-0192-4,University of Technology Sydney,"Machine learning has provided a huge wave of innovation in multiple fields, including computer vision, medical diagnosis, life sciences, molecular design, and instrumental development. This perspective focuses on the implementation of machine learning in dealing with light-matter interaction, which governs those fields involving materials discovery, optical characterizations, and photonics technologies. We highlight the role of machine learning in accelerating technology development and boosting scientific innovation in the aforementioned aspects. We provide future directions for advanced computing techniques via multidisciplinary efforts that can help to transform optical materials into imaging probes, information carriers and photonics devices.","DISCOVERY,DESIGN",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Optics,,16.996,"DISCOVERY,DESIGN",LIGHT-SCIENCE & APPLICATIONS,https://europepmc.org/articles/pmc6804848?pdf=render,
72,110th Anniversary: Ensemble-Based Machine Learning for Industrial Fermenter Classification and Foaming Control,58,36,16719-16729,"Agarwal Aman,Liu Y. A.","Agarwal A,Liu YA",Liu YA,10.1021/acs.iecr.9b02424,Virginia Polytechnic Institute & State University,"In the industrial sector, foaming remains an inevitable side effect of mixing, shearing, powder incorporation, and the metabolic activities of microorganisms in a bioprocess. Excessive foaming can interfere with the mixing of reactants and lead to problems such as decreased effective reactor volume, microbial contamination, product loss, and increased reaction time. Physical modeling of foaming is an arduous process as it requires estimation of foam height, which is dynamic in nature and varies for different processes. This work demonstrates a novel application of ensemble-based machine learning methods for prediction of different fermenter types in a fermentation process (to allow for successful data integration) and of the onset of foaming. Ensemble-based methods are robust nonlinear modeling techniques that aggregate a set of learners to obtain better predictive performance than a single learner. We apply two ensemble frameworks, extreme gradient boosting (XGBoost) and random forest (RF), to build classification and regression models. We use real plant data for 64 batches from four fermenters with different material, geometry, and equipment specifications. Our first task is to develop an ensemble-based fermenter classification model that uses well-known fermentation independent variables for each batch alone, without having to incorporate explicitly the design specifications. The resulting fermenter classification model is able to differentiate or classify the fermenter type with an accuracy of 99.49% for our integrated data sets of over 183 000 instances. This enables us to integrate multiple plant data sets from different fermenter specifications and develop a generalized foaming prediction model. Next, we build classification and regression models for foaming prediction. The resulting models are able to predict the foaming indicator (the exhaust differential pressure) to achieve an accuracy of 82.39% and an RMSE value of +/- 12 mbarg, which is well within the tolerance for foaming prediction in industrial practice. These results demonstrate the effectiveness of ensemble-based machine learning models for fermenter classification, data integration, and foaming prediction involving multiple fermenter design specifications. Using these tools, we can orchestrate the addition of chemical antifoam agents (AFA) or defoamers in an ad hoc manner to mitigate the adverse effects of excessive AFA addition. Our work differentiates itself from previous work in this area through the following contributions: (1) accurate ensemble-based classification modeling to differentiate fermenter types on the basis of known independent variables alone, without prior knowledge of fermenter design specifications, thus allowing for data integration of multiple plant data sets to build better prediction models; (2) accurate prediction of foaming based on exhaust differential pressure using both classification and regression models; and (3) usage of a large, industrial, multivariate fermenter data set.",PREDICTION,Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Engineering,,4.013,PREDICTION,INDUSTRIAL & ENGINEERING CHEMISTRY RESEARCH,,
73,,,,,,,,,,,,,,,,,,,,
74,,,,,,,,,,,,,,,,,,,,
75,,,,,,,,,,,,,,,,,,,,
76,Microfluidics for Biomedical Analysis,4,4,,"Yang Yong,Chen Yong,Tang Hao,Zong Nan,Jiang Xingyu","Yang Y,Chen Y,Tang H,Zong N,Jiang XY",Jiang XY,10.1002/smtd.201900451,Southern University of Science & Technology,"Many new techniques and materials have been applied to microfluidic systems in the past decade, and integrated microfluidic chips have become powerful platforms for realizing highly sensitive, high throughput, and low-cost analysis. This article reviews the latest advancements of microfluidic platforms for biological and biomedical analysis in the fields of fundamental biology research, clinical application, food safety, and environmental monitoring, with a focus on nucleic acid-based molecular diagnosis and protein-based immunodiagnosis. The combination of microfluidics with advanced techniques (e.g., nanotechnology, 3D printing, deep learning) would offer innovative new tools for bioanalyses. The current challenges and the future developments of microfluidic technologies for clinical applications are also discussed. It is anticipated that this review will be beneficial to promoting microfluidics toward a broad range of applications in the future.","biomarkers,lab-on-a-chip,microfluidics,molecular diagnostics,point-of-care testing",Review,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science",,14.367,"CIRCULATING,TUMOR-CELLS,POLYMERASE-CHAIN-REACTION,ON-A-CHIP,PATTERNING,MULTIPLE,TYPES,CONTINUOUS-FLOW,PCR,PAPER-BASED,DEVICE,LOW-COST,ISOTHERMAL,AMPLIFICATION,ULTRASENSITIVE,DETECTION,ENZYMATIC,AMPLIFICATION",SMALL METHODS,,
77,Cluster analysis of time evolution (CAT) for quantitative susceptibility mapping (QSM) and quantitative blood oxygen level-dependent magnitude (qBOLD)-based oxygen extraction fraction (OEF) and cerebral metabolic rate of oxygen (CMRO2) mapping,83,3,844-857,"Cho Junghun,Zhang Shun,Kee Youngwook,Spincemaille Pascal,Nguyen Thanh D.,Hubertus Simon,Gupta Ajay,Wang Yi","Cho J,Zhang S,Kee Y,Spincemaille P,Nguyen TD,Hubertus S,Gupta A,Wang Y",Wang Y,10.1002/mrm.27967,Cornell University,"Purpose To improve the accuracy of QSM plus quantitative blood oxygen level-dependent magnitude (QSM + qBOLD or QQ)-based mapping of the oxygen extraction fraction (OEF) and cerebral metabolic rate of oxygen (CMRO2) using cluster analysis of time evolution (CAT). Methods 3D multi-echo gradient echo and arterial spin labeling images were acquired in 11 healthy subjects and 5 ischemic stroke patients. DWI was also carried out on patients. CAT was developed for analyzing signal evolution over TE. QQ-based OEF and CMRO2 were reconstructed with and without CAT, and results were compared using region of interest analysis and a paired t-test. Results Simulations demonstrated that CAT substantially reduced noise error in QQ-based OEF. In healthy subjects, QQ-based OEF appeared less noisy and more uniform with CAT than without CAT; average OEF with and without CAT in cortical gray matter was 32.7 +/- 4.0% and 37.9 +/- 4.5%, with corresponding CMRO2 of 148.4 +/- 23.8 and 171.4 +/- 22.4 mu mol/100 g/min, respectively. In patients, regions of low OEF were confined within the ischemic lesions defined on DWI when using CAT, which was not observed without CAT. Conclusion The cluster analysis of time evolution (CAT) significantly improves the robustness of QQ-based OEF against noise.","cerebral metabolic rate of oxygen,cluster analysis of time evolution,K-means,machine learning,oxygen extraction fraction,quantitative blood oxygenation level-dependent imaging,quantitative susceptibility mapping",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"MULTIPLE-SCLEROSIS,LESIONS,ENABLED,DIPOLE,INVERSION,MRI-BASED,METHODS,MAGNETIC-SUSCEPTIBILITY,BRAIN,OXYGENATION,ARTERIAL,FRACTION,CAROTID,STENOSIS,FAT,NAVIGATOR,STROKE,RISK,VOLUME",MAGNETIC RESONANCE IN MEDICINE,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mrm.27967,
78,HYDRA: Hybrid deep magnetic resonance fingerprinting,46,11,4951-4969,"Song Pingfan,Eldar Yonina C.,Mazor Gal,Rodrigues Miguel R. D.","Song PF,Eldar YC,Mazor G,Rodrigues MRD",Song PF,10.1002/mp.13727],Imperial College London,"Purpose Magnetic resonance fingerprinting (MRF) methods typically rely on dictionary matching to map the temporal MRF signals to quantitative tissue parameters. Such approaches suffer from inherent discretization errors, as well as high computational complexity as the dictionary size grows. To alleviate these issues, we propose a HYbrid Deep magnetic ResonAnce fingerprinting (HYDRA) approach, referred to as HYDRA. Methods HYDRA involves two stages: a model-based signature restoration phase and a learning-based parameter restoration phase. Signal restoration is implemented using low-rank based de-aliasing techniques while parameter restoration is performed using a deep nonlocal residual convolutional neural network. The designed network is trained on synthesized MRF data simulated with the Bloch equations and fast imaging with steady-state precession (FISP) sequences. In test mode, it takes a temporal MRF signal as input and produces the corresponding tissue parameters. Results We validated our approach on both synthetic data and anatomical data generated from a healthy subject. The results demonstrate that, in contrast to conventional dictionary matching-based MRF techniques, our approach significantly improves inference speed by eliminating the time-consuming dictionary matching operation, and alleviates discretization errors by outputting continuous-valued parameters. We further avoid the need to store a large dictionary, thus reducing memory requirements. Conclusions Our approach demonstrates advantages in terms of inference speed, accuracy, and storage requirements over competing MRF methods.","deep learning,magnetic resonance fingerprinting,nonlocal residual convolutional neural network,quantitative magnetic resonance imaging,self-attention",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,,"NEURAL-NETWORKS,SLIDING-WINDOW,BRAIN,TIME,T1,HEALTHY,T-1",MEDICAL PHYSICS,,
79,Breast cancer diagnosis through active learning in content-based image retrieval,357,,1-10,"Bressan Rafael S.,Bugatti Pedro H.,Saito Priscila T. M.","Bressan RS,Bugatti PH,Saito PTM",Saito PTM,10.1016/j.neucom.2019.05.041,Pontificia Universidade Catolica do Parana,"One of the cornerstones of content-based image retrieval (CBIR) for medical image diagnosis is to select the images that present higher similarity with a given query image. Different from previous literature efforts, the present work aims to seamlessly fuse a powerful machine learning strategy based on the active learning paradigm, in order to obtain greater efficacy regarding similarity queries in medical CBIR systems. To do so, we propose a new approach, named as Medical Active leaRning and Retrieval (MAR-Row) to aid the breast cancer diagnosis. It enables to deal with more feasible strategies, specifically for the medical context and its inherent constraints. We also proposed an active learning strategy to select a small set of more informative images, considering selection criteria based on not only similarity, but also on certain degrees of diversity and uncertainty. To validate our proposed approach, we performed experiments using public medical image datasets, different descriptors for each one and compared our approach against four widely applied and well-known literature approaches, such as: Traditional CBIR without relevance feedback strategies, Query Point Movement Strategy (QPM), Query Expansion (QEX) and SVM Active Learning (SVM-AL). From the experiments, we can observe that our approach presents a strong performance over state-of-the-art ones reaching a precision gain of up to 87.3%. MARRow also presented a well-suited and consistent increasing rate along the learning iterations. Moreover, our approach can significantly minimize the expert's involvement in the analysis and annotation process (reducing up to 88%). The results testify that MARRow improves the precision of the similarity queries. It is capable to explore at the maximum the experts' intentions, which are captured during the relevance feedback process, incrementally improving the learning model. Therefore, our approach can be suitable and applied in challenging processes, such as real and medical contexts, enhancing medical decision support systems (e.g. breast cancer diagnosis). (C) 2019 Elsevier B.V. All rights reserved.","Machine learning,Computer vision,Image analysis,Active learning,Image retrieval,Breast cancer diagnosis",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,,SYSTEM,NEUROCOMPUTING,,
80,Standardization of life-cycle performance evaluation and application to suspension bridge with multiple pylons,16,4,567-582,"Chen Airong,Wang Dalei,Ma Rujin,Pan Zichao","Chen AR,Wang DL,Ma RJ,Pan ZC",Wang DL,10.1080/15732479.2019.1662065,Tongji University,"Owing to environmental and loading effects, complex processes of deterioration in structural performance will be encountered in the maintenance and management of long-span bridges during their service life. Therefore, the method of evaluation for acquiring the current status and trend in the deterioration of bridge performance is important. To improve the efficiency and objectivity of performance evaluations, the concept of standardization can be introduced to specify each step of the evaluation procedure. This paper presents a preliminary research framework for the standardization of performance evaluations for the Taizhou multi-pylon suspension bridge, which has special structural characteristics. This study is a part of a three-stage project on data standardization, evaluation, and retention. First, a framework with six core modules (action, structure, response, performance, indicator, and target) is established. Second, the relationship between these core modules and the performance evaluation procedure is discussed. Third, the content (e.g., definition and hierarchy) of each core module is described in detail. Finally, three examples (saddle sliding on top of middle steel pylon, concrete carbonation, and performance of middle pylon under extreme actions) are provided to demonstrate how the framework can be applied in performance evaluations of long-span bridges.","Long-span bridge,performance evaluation,standardization,numerical analysis,structural response,computer vision,machine learning",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,3.533,"CONCRETE,CARBONATION,SPATIAL,VARIABILITY,ACCURACY,CHLORIDE,MODEL",STRUCTURE AND INFRASTRUCTURE ENGINEERING,,
81,A LightGBM-Based EEG Analysis Method for Driver Mental States Classification,2019,,,"Zeng Hong,Yang Chen,Zhang Hua,Wu Zhenhua,Zhang Jiaming,Dai Guojun,Babiloni Fabio,Kong Wanzeng","Zeng H,Yang C,Zhang H,Wu ZH,Zhang JM,Dai GJ,Babiloni F,Kong WZ",Kong WZ,10.1155/2019/3761203,Hangzhou Dianzi University,"Fatigue driving can easily lead to road traffic accidents and bring great harm to individuals and families. Recently, electroencephalography- (EEG-) based physiological and brain activities for fatigue detection have been increasingly investigated. However, how to find an effective method or model to timely and efficiently detect the mental states of drivers still remains a challenge. In this paper, we combine common spatial pattern (CSP) and propose a light-weighted classifier, LightFD, which is based on gradient boosting framework for EEG mental states identification. The comparable results with traditional classifiers, such as support vector machine (SVM), convolutional neural network (CNN), gated recurrent unit (GRU), and large margin nearest neighbor (LMNN), show that the proposed model could achieve better classification performance, as well as the decision efficiency. Furthermore, we also test and validate that LightFD has better transfer learning performance in EEG classification of driver mental states. In summary, our proposed LightFD classifier has better performance in real-time EEG mental state prediction, and it is expected to have broad application prospects in practical brain-computer interaction (BCI).","CONVOLUTIONAL NEURAL-NETWORKS,HEART-RATE-VARIABILITY,PASSIVE BCI,FATIGUE",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Mathematical & Computational Biology,Neurosciences & Neurology",,3.278,"CONVOLUTIONAL,NEURAL-NETWORKS,HEART-RATE-VARIABILITY,PASSIVE,BCI,FATIGUE",COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE,https://doi.org/10.1155/2019/3761203,
82,Automated tracking of level of consciousness and delirium in critical illness using deep learning,2,,,"Sun Haoqi,Kimchi Eyal,Akeju Oluwaseun,Nagaraj Sunil B.,McClain Lauren M.,Zhou David W.,Boyle Emily,Zheng Wei-Long,Ge Wendong,Westover M. Brandon","Sun HQ,Kimchi E,Akeju O,Nagaraj SB,McClain LM,Zhou DW,Boyle E,Zheng WL,Ge WD,Westover MB",Westover MB,10.1038/s41746-019-0167-0,Harvard University,"Over- and under-sedation are common in the ICU, and contribute to poor ICU outcomes including delirium. Behavioral assessments, such as Richmond Agitation-Sedation Scale (RASS) for monitoring levels of sedation and Confusion Assessment Method for the ICU (CAM-ICU) for detecting signs of delirium, are often used. As an alternative, brain monitoring with electroencephalography (EEG) has been proposed in the operating room, but is challenging to implement in ICU due to the differences between critical illness and elective surgery, as well as the duration of sedation. Here we present a deep learning model based on a combination of convolutional and recurrent neural networks that automatically tracks both the level of consciousness and delirium using frontal EEG signals in the ICU. For level of consciousness, the system achieves a median accuracy of 70% when allowing prediction to be within one RASS level difference across all patients, which is comparable or higher than the median technician-nurse agreement at 59%. For delirium, the system achieves an AUC of 0.80 with 69% sensitivity and 83% specificity at the optimal operating point. The results show it is feasible to continuously track level of consciousness and delirium in the ICU.","AGITATION-SEDATION SCALE,ICU PATIENTS,EEG,ELECTROENCEPHALOGRAPHY,CLASSIFICATION,RELIABILITY,VALIDATION,VALIDITY,TIME",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Health Care Sciences & Services,Medical Informatics",,11.665,"AGITATION-SEDATION,SCALE,ICU,PATIENTS,EEG,ELECTROENCEPHALOGRAPHY,CLASSIFICATION,RELIABILITY,VALIDATION,VALIDITY,TIME",NPJ DIGITAL MEDICINE,https://europepmc.org/articles/pmc6733797?pdf=render,
83,Shear Resistance Prediction of Post-fire Reinforced Concrete Beams Using Artificial Neural Network,13,1,,"Cai Bin,Xu Long-Fei,Fu Feng","Cai B,Xu LF,Fu F",Fu F,10.1186/s40069-019-0358-8,City University London,"In this paper, a prediction method based on artificial neural network was developed to rapidly determine the residual shear resistance of reinforced concrete (RC) beams after fire. Firstly, the temperature distribution along the beam section was determined through finite element analysis using software ABAQUS. A residual shear strength calculation model was developed and validated using the test data. Using this model, 384 data entries were derived for training and testing. The input layer of neural network involved parameters of beam height, beam width, fire exposure time, cross-sectional area of stirrup, stirrup spacing, concrete strength, and concrete cover thickness. The output was the shear resistance of RC beams. It was found that use of BP neural network could precisely predict the post-fire shear resistance of RC beams. The predicted data were highly consistent with the target data. Thus, this is a novel method for computing post-fire shear resistance of RC beams. Using this new method, further investigation was also made on the effects of different parameters on the shear resistance of the beams.","reinforced concrete,fire,shear resistance,sectional analysis,BP neural networks",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Construction & Building Technology,Engineering,Materials Science",,3.157,"FIRE,PERFORMANCE,CAPACITY,ANN",INTERNATIONAL JOURNAL OF CONCRETE STRUCTURES AND MATERIALS,https://openaccess.city.ac.uk/id/eprint/22661/8/Cai2019_Article_ShearResistancePredictionOfPos.pdf,
84,Tool wear prediction in hard turning of EN8 steel using cutting force and surface roughness with artificial neural network,234,1,329-342,"Thangarasu S. K.,Shankar S.,Mohanraj T.,Devendran K.","Thangarasu SK,Shankar S,Mohanraj T,Devendran K",Thangarasu SK,10.1177/0954406219873932,Kongu Engineering College,"In this work, the flank wear of the cutting tool is predicted using artificial neural network based on the responses of cutting force and surface roughness. EN8 steel is chosen as a work piece material and turning test is conducted with various levels of speed, feed and depth of cut. Cutting force and surface roughness are measured for both the fresh and dull tool under dry cutting conditions. The tool insert used is CNMG 120408 grade, TiN coated cemented carbide tool. The experiments are conducted based on the response surface methodology face central composite design of experiments. The feed rate (14.52%), depth of cut (27.72%) and the interaction of feed rate and depth of cut (50.39%) influence the cutting force. The feed rate (21.33%) and the interaction of cutting speed and depth of cut (26.67%) influence the flank wear. The feed rate (61.63%) has the significant influence on surface roughness. The feed forward back propagation neural network of 5-n-1 architecture is trained using the algorithms like Levenberg Marquardt, BFGS quasi-Newton, and Gradient Descent with Momentum and Gradient descent with adaptive learning rate. The network performance has been assessed based on their mean square error and computation time. From this analysis, the BFGS quasi-Newton back propagation algorithm produced the least mean squared error value with minimum computation time.","Flank wear,hard turning,neural network,response surface methodology",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Engineering,,1.606,"RESPONSE-SURFACE,CONNECTIONIST,METHODS,STATISTICAL-ANALYSIS,NANOFLUID,FLOWS,NSGA-II,ANN,OPTIMIZATION,VIBRATION,RSM,APPLICABILITY",PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART C-JOURNAL OF MECHANICAL ENGINEERING SCIENCE,,
85,Water cut/salt content forecasting in oil wells using a novel data-driven approach,74,,,"Ahmadi Rouhollah,Shahrabi Jamal,Aminshahidy Babak","Ahmadi R,Shahrabi J,Aminshahidy B",Shahrabi J,10.2516/ogst/2019040,Amirkabir University of Technology,"Water cut is an important parameter in reservoir management and surveillance. Unlike traditional approaches, including numerical simulation and analytical techniques, which were developed for predicting water production in oil wells based on some assumptions and limitations, a new data-driven approach is proposed for forecasting water cut in two different types of oil wells in this article. First, a classification approach is presented for water cut prediction in sweet oil wells with discontinuous salt production patterns. Different classification algorithms including Support Vector Machine (SVM), Classification Tree (CT), Random Forest (RF), Multi-Layer Perceptron (MLP), Linear Discriminant Analysis (LDA) and Naive Bayes (NB) are investigated in this regard. According to the results of a case study on a real Iranian sweet oil well, RF, CT, MLP and SVM can provide the best performance measures, respectively. Next, a Vector Autoregressive (VAR) model is proposed for forecasting water cut in salty oil wells with continuous water production during the life of the well. The proposed VAR model is verified using data of two real salty oil wells. The results confirm that the well-tuned proposed VAR model could provide reliable and acceptable results with very good accuracy in forecasting water production for the near future days.","MODEL,IDENTIFICATION,AGREEMENT,ORDER,CUT",Article,"EDP SCIENCES S A, 17, AVE DU HOGGAR, PA COURTABOEUF, BP 112, F-91944 LES ULIS CEDEX A, FRANCE","Energy & Fuels,Engineering",,1.722,"MODEL,IDENTIFICATION,AGREEMENT,ORDER,CUT",OIL & GAS SCIENCE AND TECHNOLOGY-REVUE D IFP ENERGIES NOUVELLES,https://ogst.ifpenergiesnouvelles.fr/10.2516/ogst/2019040/pdf,
86,Robotic assisted design workflows: a study of key human factors influencing team fluency in human-robot collaborative design processes,62,5,409-423,"Vazquez Alicia Nahmad,Jabi Wassim","Vazquez AN,Jabi W",Vazquez AN,10.1080/00038628.2019.1660611,Cardiff University,"This paper presents the initial results and analysis of key human elements towards the development of human-robot collaboration (HRC) in architectural design workflows. Key team fluency elements such as trust, reliance and robustness for successful human-robot teams are identified to analyse the development of team fluency in the context of non-expert-designers interacting with robots. A design process is then described based on feedback, and phase-changing materials that encourages HRC during the genesis of the design. Two stages of development are presented. In stage one, an exploratory study was conducted to collect designers' opinions quantitatively and qualitatively. The results were analysed leading to the identification of primary parameters that affect HRC in design processes. In the second stage, machine learning is used to enhance the collaborative characteristics of the robotic partner. The results reveal insights to human perceptions of robotic collaboration, and explore neural-network-based feedback to enable expanded HRC and communication.","Machine learning,digital design,human-robot interaction,human-robot team,fluency",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Architecture,,,"TRUST,ANIMACY",ARCHITECTURAL SCIENCE REVIEW,https://orca.cardiff.ac.uk/125319/1/RAD_final.pdf,
87,A modality conversion approach to MV-DRs and KV-DRRs registration using information bottlenecked conditional generative adversarial network,46,10,4575-4587,"Liu Cong,Lu Zheming,Ma Longhua,Wang Lang,Jin Xiance,Si Wen","Liu C,Lu ZM,Ma LH,Wang L,Jin XC,Si W",Si W,10.1002/mp.13770,Shanghai Business School,"Purpose As affordable equipment, electronic portal imaging devices (EPIDs) are wildly used in radiation therapy departments to verify patients' positions for accurate radiotherapy. However, these devices tend to produce visually ambiguous and low-contrast planar digital radiographs under megavoltage x ray (MV-DRs), which poses a tremendous challenge for clinicians to perform multimodal registration between the MV-DRs and the kilovoltage digital reconstructed radiographs (KV-DRRs) developed from the planning computed tomography. Furthermore, the existent of strong appearance variations also makes accurate registration beyond the reach of current automatic algorithms. Methods We propose a novel modality conversion approach to this task that first synthesizes KV images from MV-DRs, and then registers the synthesized and real KV-DRRs. We focus on the synthesis technique and develop a conditional generative adversarial network with information bottleneck extension (IB-cGAN) that takes MV-DRs and nonaligned KV-DRRs as inputs and outputs synthesized KV images. IB-cGAN is designed to address two main challenges in deep-learning-based synthesis: (a) training with a roughly aligned dataset suffering from noisy correspondences; (b) making synthesized images have real clinical meanings that faithfully reflects MV-DRs rather than nonaligned KV-DRRs. Accordingly, IB-cGAN employs (a) an adversarial loss to provide training supervision at semantic level rather than the imprecise pixel level; (b) an IB to constrain the information from the nonaligned KV-DRRs. Results We collected 2698 patient scans to train the model and 208 scans to test its performance. The qualitative results demonstrate realistic KV images can be synthesized allowing clinicians to perform the visual registration. The quantitative results show it significantly outperforms current nonmodality conversion methods by 22.37% (P = 0.0401) in terms of registration accuracy. Conclusions The modality conversion approach facilitates the downstream MV-KV registration for both clinicians and off-the-shelf registration algorithms. With this approach, it is possible to benefit the developing countries where inexpensive EPIDs are widely used for the image-guided radiation therapy.","generative adversarial networks,image-guided radiation therapy,image synthesis,information bottleneck,multimodal image registration",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,,MEDICAL PHYSICS,,
88,Prediction of Left Ventricular Mechanics Using Machine Learning,7,,,"Dabiri Yaghoub,Van der Velden Alex,Sack Kevin L.,Choy Jenny S.,Kassab Ghassan S.,Guccione Julius M.","Dabiri Y,Van der Velden A,Sack KL,Choy JS,Kassab GS,Guccione JM",Guccione JM,10.3389/fphy.2019.00117,University of California System,"The goal of this paper was to provide a real-time left ventricular (LV) mechanics simulator using machine learning (ML). Finite element (FE) simulations were conducted for the LV with different material properties to obtain a training set. A hyperelastic fiber-reinforced material model was used to describe the passive behavior of the myocardium during diastole. The active behavior of the heart resulting from myofiber contractions was added to the passive tissue during systole. The active and passive properties govern the LV constitutive equation. These mechanical properties were altered using optimal Latin hypercube design of experiments to obtain training FE models with varied active properties (volume and pressure predictions) and varied passive properties (stress predictions). For prediction of LV pressures, we used eXtreme Gradient Boosting (XGboost) and Cubist, and XGBoost was used for predictions of LV pressures, volumes as well as LV stresses. The LV pressure and volume results obtained from ML were similar to FE computations. The ML results could capture the shape of LV pressure as well as LV pressure-volume loops. The results predicted by Cubist were smoother than those from XGBoost. The mean absolute errors were as follows: XGBoost volume: 1.734 +/- 0.584 ml, XGBoost pressure: 1.544 +/- 0.298 mmHg, Cubist volume: 1.495 +/- 0.260 ml, Cubist pressure: 1.623 +/- 0.191 mmHg, myofiber stress: 0.334 +/- 0.228 kPa, cross myofiber stress: 0.075 +/- 0.024 kPa, and shear stress: 0.050 +/- 0.032 kPa. The simulation results show ML can predict LV mechanics much faster than the FE method. The ML model can be used as a tool to predict LV behavior. Training of our ML model based on a large group of subjects can improve its predictability for real world applications.","left ventricle,machine learning,finite element method,XGBoost,Cubist",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Physics,,3.33,"HEART-FAILURE,REGRESSION,INJECTION,ELEMENT,IMPACT,WALL",FRONTIERS IN PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6941671,
89,Physics-driven learning of x-ray skin dose distribution in interventional procedures,46,10,4654-4665,"Roser Philipp,Zhong Xia,Birkhold Annette,Strobel Norbert,Kowarschik Markus,Fahrig Rebecca,Maier Andreas","Roser P,Zhong X,Birkhold A,Strobel N,Kowarschik M,Fahrig R,Maier A",Roser P,10.1002/mp.13758,University of Erlangen Nuremberg,"Purpose Radiation doses accumulated during very complicated image-guided x-ray procedures have the potential to cause stochastic, but also deterministic effects, such as skin rashes or even hair loss. To monitor and reduce radiation-related risks to patients' skin, x-ray imaging devices are equipped with online air kerma monitoring components. Traditionally, such measurements have been used to estimate skin entrance dose by (a) estimating air kerma at the interventional reference point (IRP), (b) forward projecting the dose distribution, and (c) considering a backscatter factor among other correction factors. Unfortunately, the complicated interaction between incident x-ray photons, secondary electrons, and skin tissue cannot be properly accounted for by assuming a linear relationship between forward projected air kerma and a backscatter factor. Gold standard skin dose models are therefore determined using Monte Carlo (MC) techniques. However, MC simulations are computationally complex in general and possible acceleration mainly depends on the employed hardware and variance reduction techniques. To obtain reliable and fast dose estimates, we propose to combine MC-based simulations with learning-based methods. Methods The basic idea of our method is to approximate the radiation physics to calculate a first-order exposure estimate quickly. This initial estimate is then refined using prior knowledge derived from MC simulations. To this end, the primary photon propagation inside a voxelized patient model is estimated using a less accurate but fast photon ray casting (RC) simulation based on the Beer-Lambert law. The results of the RC simulation are then fed into a convolutional neural network (CNN), which maps the propagation of primary photons to the dose deposition inside the patient model. Additionally, the patient model itself including anatomy and material properties, such as mass density and mass energy-absorption coefficients, are fed into the CNN as well. The CNN is trained using smoothed results of MC simulations as output and RC simulations of identical imaging settings and patient models as input. Results In total, 163 MC and associated RC simulations are carried out for the head, thorax, abdomen, and pelvis in three different voxel phantoms. We used 108 or 109 primarily emitted photons sampled from a 125 kV peak voltage spectrum, respectively. Edge-preserving smoothing (EPS) is applied to reduce (a) general stochastic uncertainties and (b) stochastic uncertainty concerning MC simulations of less primary photons. The CNN is trained using seven imaging settings of the abdomen in a single phantom. Testing its performance on the remaining datasets, the CNN is capable of estimating skin dose with an error of below 10% for the majority of test cases. Conclusion The combination of deep neural networks and MC simulation of particle physics has the potential to decrease the computational complexity of accurate skin dose estimation. The proposed approach can provide dose distributions in under one second when running on high-end hardware. On lower cost hardware, it took up to 2 min to arrive at the same result. This makes our approach applicable in high-end environments as well as in budget solutions. Furthermore, the number of primary photons only affects the training time, while the execution time is independent of the number of primary photons.","convolutional neural network,dose estimation,interventional X-ray imaging,Monte Carlo simulation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"MONTE-CARLO,SIMULATIONS,BACKSCATTER,FACTORS,REAL-TIME,RADIATION",MEDICAL PHYSICS,,
90,Toward predicting the evolution of lung tumors during radiotherapy observed on a longitudinal MR imaging study via a deep learning algorithm,46,10,4699-4707,"Wang Chuang,Rimner Andreas,Hu Yu-Chi,Tyagi Neelam,Jiang Jue,Yorke Ellen,Riyahi Sadegh,Mageras Gig,Deasy Joseph O.,Zhang Pengpeng","Wang C,Rimner A,Hu YC,Tyagi N,Jiang J,Yorke E,Riyahi S,Mageras G,Deasy JO,Zhang PP",Zhang PP,10.1002/mp.13765,Memorial Sloan Kettering Cancer Center,"Purpose To predict the spatial and temporal trajectories of lung tumor during radiotherapy monitored under a longitudinal magnetic resonance imaging (MRI) study via a deep learning algorithm for facilitating adaptive radiotherapy (ART). Methods We monitored 10 lung cancer patients by acquiring weekly MRI-T2w scans over a course of radiotherapy. Under an ART workflow, we developed a predictive neural network (P-net) to predict the spatial distributions of tumors in the coming weeks utilizing images acquired earlier in the course. The three-step P-net consisted of a convolutional neural network to extract relevant features of the tumor and its environment, followed by a recurrence neural network constructed with gated recurrent units to analyze trajectories of tumor evolution in response to radiotherapy, and finally an attention model to weight the importance of weekly observations and produce the predictions. The performance of P-net was measured with Dice and root mean square surface distance (RMSSD) between the algorithm-predicted and experts-contoured tumors under a leave-one-out scheme. Results Tumor shrinkage was 60% +/- 27% (mean +/- standard deviation) by the end of radiotherapy across nine patients. Using images from the first three weeks, P-net predicted tumors on future weeks (4, 5, 6) with a Dice and RMSSD of (0.78 +/- 0.22, 0.69 +/- 0.24, 0.69 +/- 0.26), and (2.1 +/- 1.1 mm, 2.3 +/- 0.8 mm, 2.6 +/- 1.4 mm), respectively. Conclusion The proposed deep learning algorithm can capture and predict spatial and temporal patterns of tumor regression in a longitudinal imaging study. It closely follows the clinical workflow, and could facilitate the decision-making of ART. A prospective study including more patients is warranted.","deep learning,longitudinal,lung,MRI,radiotherapy,treatment response",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,NETWORKS,MEDICAL PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7391789,
91,,,,,,,,,,,,,,,,,,,,
92,Reduction of false alarms in the intensive care unit using an optimized machine learning based approach,2,,,"Au-Yeung Wan-Tai M.,Sahani Ashish K.,Isselbacher Eric M.,Armoundas Antonis A.","Au-Yeung WTM,Sahani AK,Isselbacher EM,Armoundas AA",Armoundas AA,10.1038/s41746-019-0160-7,Harvard University,"This work attempts to reduce the number of false alarms generated by bedside monitors in the intensive care unit (ICU), as a majority of current alarms are false. In this study, we applied methods that can be categorized into three stages: signal processing, feature extraction, and optimized machine learning. At the stage of signal processing, we ensured that the heartbeats were properly annotated. During feature extraction, besides extracting features that are relevant to the arrhythmic alarms, we also extracted a set of signal quality indices (SQIs), which we used to distinguish noise/artifact from normal physiological signals. When applying a machine learning algorithm (Random Forest), we performed feature selection in order to reduce the complexity of the models and improve the efficiency of the algorithm. The dataset used is from Reducing False Arrhythmia Alarms in the ICU: the PhysioNet/Computing in Cardiology Challenge 2015. Using the performance metric ""score"" from the Challenge, we achieved a score of 83.08 in the real-time category on the hidden test set, which is the highest in all published work.","SIGNAL QUALITY,CLASSIFICATION,FUSION,HEALTH",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Health Care Sciences & Services,Medical Informatics",,11.665,"SIGNAL,QUALITY,CLASSIFICATION,FUSION,HEALTH",NPJ DIGITAL MEDICINE,https://europepmc.org/articles/pmc6728371?pdf=render,
93,Human hand kinematic data during feeding and cooking tasks,6,,,"Roda-Sales Alba,Vergara Margarita,Sancho-Bru Joaquin L.,Gracia-Ibanez Veronica,Jarque-Bou Nestor J.","Roda-Sales A,Vergara M,Sancho-Bru JL,Gracia-Ibanez V,Jarque-Bou NJ",Roda-Sales A,10.1038/s41597-019-0175-6,Universitat Jaume I,"This work presents a database of human hand kinematics containing data collected during the performance of a wide variety of activities of daily living involving feeding and cooking. The data were recorded using CyberGlove instrumented gloves on both hands measuring 18 degrees of freedom on each. A total of 20 subjects participated in each part of the experiment, and the objects and their arrangement were the same across subjects, although they performed the tasks in a natural non-directed way. This dataset contains a total of 1160 continuous calibrated recordings taken at 100 Hz during the performance of the tasks, with filtered signal. Statistical descriptive analyses from these data are presented. This database can be useful for machine learning purposes and prostheses control, as well as for the characterization of healthy human hand kinematics.","MOVEMENT,OBJECT,MOTION,JOINTS",Article; Data Paper,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,9.051,"MOVEMENT,OBJECT,MOTION,JOINTS",SCIENTIFIC DATA,https://europepmc.org/articles/pmc6754415?pdf=render,
94,Machine Learning Interatomic Potentials as Emerging Tools for Materials Science,31,46,,"Deringer Volker L.,Caro Miguel A.,Csanyi Gabor","Deringer VL,Caro MA,Csanyi G",Deringer VL,10.1002/adma.201902765,University of Cambridge,"Atomic-scale modeling and understanding of materials have made remarkable progress, but they are still fundamentally limited by the large computational cost of explicit electronic-structure methods such as density-functional theory. This Progress Report shows how machine learning (ML) is currently enabling a new degree of realism in materials modeling: by ""learning"" electronic-structure data, ML-based interatomic potentials give access to atomistic simulations that reach similar accuracy levels but are orders of magnitude faster. A brief introduction to the new tools is given, and then, applications to some select problems in materials science are highlighted: phase-change materials for memory devices; nanoparticle catalysts; and carbon-based electrodes for chemical sensing, supercapacitors, and batteries. It is hoped that the present work will inspire the development and wider use of ML-based interatomic potentials in diverse areas of materials research.","amorphous solids,atomistic modeling,big data,force fields,molecular dynamics",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,30.254,"PHASE-CHANGE,MATERIALS,NEURAL-NETWORK,POTENTIALS,COMPUTER-SIMULATION,ENERGY,SURFACES,CARBON,CRYSTAL,CRYSTALLIZATION,CHEMISTRY,DESIGN,MEMORY",ADVANCED MATERIALS,https://www.repository.cam.ac.uk/bitstream/1810/296958/1/Accepted_Manuscript.pdf,
95,Development of a new parameter optimization scheme for a reactive force field based on a machine learning approach,40,23,2000-2012,"Nakata Hiroya,Bai Shandan","Nakata H,Bai SD",Nakata H,10.1002/jcc.25841,Kyocera,"Reactive molecular dynamics (MD) simulation is performed using a reactive force field (ReaxFF). To this end, we developed a new method to optimize the ReaxFF parameters based on a machine learning approach. This approach combines the k-nearest neighbor and random forest regressor algorithm to efficiently locate several possible ReaxFF parameter sets. As a pilot test of the developed approach, the optimized ReaxFF parameter set was applied to perform chemical vapor deposition (CVD) of an alpha-Al2O3 crystal. The crystal structure of alpha-Al2O3 was reasonably reproduced even at a relatively high temperature (2000 K). The reactive MD simulation suggests that the (112 over bar 0) surface grows faster than the (0001) surface, indicating that the developed parameter optimization technique could be used for understanding the chemical reaction in the CVD process. (c) 2019 Wiley Periodicals, Inc.","machine learning,reactive molecular dynamics,chemical vapor deposition",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Chemistry,,3.568,"MOLECULAR-DYNAMICS,SIMULATIONS,DIVIDE-AND-CONQUER,TOTAL-ENERGY,REAXFF,DENSITY,FRAGMENTATION,FORMULATION,MODEL,FRAMEWORK,MECHANISM",JOURNAL OF COMPUTATIONAL CHEMISTRY,,
96,A Unified Approach to Sparse Tweedie Modeling of Multisource Insurance Claim Data,62,3,339-356,"Fontaine Simon,Yang Yi,Qian Wei,Gu Yuwen,Fan Bo","Fontaine S,Yang Y,Qian W,Gu YW,Fan B",Yang Y,10.1080/00401706.2019.1647881,McGill University,"Actuarial practitioners now have access to multiple sources of insurance data corresponding to various situations: multiple business lines, umbrella coverage, multiple hazards, and so on. Despite the wide use and simple nature of single-target approaches, modeling these types of data may benefit from an approach performing variable selection jointly across the sources. We propose a unified algorithm to perform sparse learning of such fused insurance data under the Tweedie (compound Poisson) model. By integrating ideas from multitask sparse learning and sparse Tweedie modeling, our algorithm produces flexible regularization that balances predictor sparsity and between-sources sparsity. When applied to simulated and real data, our approach clearly outperforms single-target modeling in both prediction and selection accuracy, notably when the sources do not have exactly the same set of predictors. An efficient implementation of the proposed algorithm is provided in our R package MStweedie, which is available at https://github.com/fontaine618/MStweedie. Supplementary materials. for this article are available online.","Backtracking line search,Groupwise proximal gradient descent,Multisource insurance data,Multitask learning,Regularization,Tweedie model",Article,"AMER STATISTICAL ASSOC, 732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA",Mathematics,,,"ACTUARIAL,APPLICATIONS,VARIABLE,SELECTION,GAMMA,MODEL,REGRESSION,FREQUENCY,LASSO,SHRINKAGE,INFERENCE,CARE",TECHNOMETRICS,,
97,Predicting superhard materials via a machine learning informed evolutionary structure search,5,,,"Avery Patrick,Wang Xiaoyu,Oses Corey,Gossett Eric,Proserpio Davide M.,Toher Cormac,Curtarolo Stefano,Zurek Eva","Avery P,Wang XY,Oses C,Gossett E,Proserpio DM,Toher C,Curtarolo S,Zurek E",Zurek E,10.1038/s41524-019-0226-8,State University of New York (SUNY) System,"The computational prediction of superhard materials would enable the in silico design of compounds that could be used in a wide variety of technological applications. Herein, good agreement was found between experimental Vickers hardnesses, H-v of a wide range of materials and those calculated by three macroscopic hardness models that employ the shear and/or bulk moduli obtained from: (i) first principles via AFLOW-AEL (AFLOW Automatic Elastic Library), and (ii) a machine learning (ML) model trained on materials within the AFLOW repository. Because H-v(ML) values can be quickly estimated, they can be used in conjunction with an evolutionary search to predict stable, superhard materials. This methodology is implemented in the XTALOPT evolutionary algorithm. Each crystal is minimized to the nearest local minimum, and its Vickers hardness is computed via a linear relationship with the shear modulus discovered by Teter. Both the energy/enthalpy and H-v,Teter(ML) are employed to determine a structure's fitness. This implementation is applied towards the carbon system, and 43 new superhard phases are found. A topological analysis reveals that phases estimated to be slightly harder than diamond contain a substantial fraction of diamond and/or lonsdaleite.","CRYSTAL-STRUCTURES,NANOTWINNED DIAMOND,CARBON NITRIDE,RESTFUL API,HARDNESS,APPROXIMATION,AFLOWLIB.ORG,ALGORITHM,PROGRAM,XTALOPT",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND","Chemistry,Materials Science",,13.993,"CRYSTAL-STRUCTURES,NANOTWINNED,DIAMOND,CARBON,NITRIDE,RESTFUL,API,HARDNESS,APPROXIMATION,AFLOWLIB.ORG,ALGORITHM,PROGRAM,XTALOPT",NPJ COMPUTATIONAL MATERIALS,https://air.unimi.it/bitstream/2434/673674/2/204_Avery_et_al-2019-npj_Computational_Materials.pdf,
98,Concurrent Optimization of Organic Donor-Acceptor Pairs through Machine Learning,9,40,,"Padula Daniele,Troisi Alessandro","Padula D,Troisi A",Padula D,10.1002/aenm.201902463,University of Liverpool,"In this work an instance of the general problem occurring when optimizing multicomponent materials is treated: can components be optimized separately or the optimization should occur simultaneously? This problem is investigated from a computational perspective in the domain of donor-acceptor pairs for organic photovoltaics, since most experimental research reports optimization of each component separately. A collection of organic donors and acceptors recently analyzed is used to train nonlinear machine learning models of different families to predict the power conversion efficiency of donor-acceptor pairs, considering computed electronic and structural parameters of both components. The trained models are then used to predict photovoltaic performance for donor-acceptor combinations for which experimental data are not available in the data set. Data structure, and the usefulness of the trained models are critically assessed by predicting some donor-acceptor pairs that recently appeared in the literature, and the best combinations are proposed as worth investigating experimentally.","computational chemistry,machine learning,organic photovoltaics",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Energy & Fuels,Materials Science,Physics",,27.97,"NON-FULLERENE,ACCEPTOR,POLYMER,SOLAR-CELLS,CONJUGATED,POLYMERS,PERFORMANCE,EFFICIENCY,DESIGN,FINGERPRINT,SIMILARITY,DISCOVERY,TRANSPORT",ADVANCED ENERGY MATERIALS,,
99,Profiling of Exosomal Biomarkers for Accurate Cancer Identification: Combining DNA-PAINT with Machine- Learning-Based Classification,15,43,,"Chen Chen,Zong Shenfei,Liu Yun,Wang Zhuyuan,Zhang Yizhi,Chen Baoan,Cui Yiping","Chen C,Zong SF,Liu Y,Wang ZY,Zhang YZ,Chen BA,Cui YP",Zong SF; Cui YP,10.1002/smll.201901014,Southeast University - China,"Exosomes are endosome-derived vesicles enriched in body fluids such as urine, blood, and saliva. So far, they have been recognized as potential biomarkers for cancer diagnostics. However, the present single-variate analysis of exosomes has greatly limited the accuracy and specificity of diagnoses. Besides, most diagnostic approaches focus on bulk analysis using lots of exosomes and tend to be less accurate because they are vulnerable to impure extraction and concentration differences of exosomes. To address these challenges, a quantitative analysis platform is developed to implement a sequential quantification analysis of multiple exosomal surface biomarkers at the single-exosome level, which utilizes DNA-PAINT and a machine learning algorithm to automatically analyze the results. As a proof of concept, the profiling of four exosomal surface biomarkers (HER2, GPC-1, EpCAM, EGFR) is developed to identify exosomes from cancer-derived blood samples. Then, this technique is further applied to detect pancreatic cancer and breast cancer from unknown samples with 100% accuracy.","biomarkers,cancer diagnosis,DNA-PAINT,exosomes,machine learning",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,12.463,"SINGLE,SUPERRESOLUTION,MICROSCOPY,PREPARE",SMALL,,
100,The Aristotle Classifier: Using the Whole Glycomic Profile To Indicate a Disease State,91,17,11070-11077,"Hua David,Patabandige Milani Wijeweera,Go Eden P.,Desaire Heather","Hua D,Patabandige MW,Go EP,Desaire H",Desaire H,10.1021/acs.analchem.9b01606,University of Kansas,"""The totality is not, as it were, a mere heap, but the whole is something besides the parts.""-Aristotle. We built a classifier that uses the totality of the glycomic profile, not restricted to a few glycoforms, to differentiate samples from two different sources. This approach, which relies on using thousands of features, is a radical departure from current strategies, where most of the glycomic profile is ignored in favor of selecting a few features, or even a single feature, meant to capture the differences in sample types. The classifier can be used to differentiate the source of the material; applicable sources may be different species of animals, different protein production methods, or, most importantly, different biological states (disease vs healthy). The classifier can be used on glycomic data in any form, including derivatized monosaccharides, intact glycans, or glycopeptides. It takes advantage of the fact that changing the source material can cause a change in the glycomic profile in many subtle ways: some glycoforms can be upregulated, some downregulated, some may appear unchanged, yet their proportion-with respect to other forms present-can be altered to a detectable degree. By classifying samples using the entirety of their glycan abundances, along with the glycans' relative proportions to each other, the ""Aristotle Classifier"" is more effective at capturing the underlying trends than standard classification procedures used in glycomics, including PCA (principal components analysis). It also outperforms workflows where a single, representative glycomic-based biomarker is used to classify samples. We describe the Aristotle Classifier and provide several examples of its utility for biomarker studies and other classification problems using glycomic data from several sources.","GLYCOSYLATION,HAPTOGLOBIN,BIOMARKER",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,6.755,"MACHINE,LEARNING,APPLICATIONS,GLYCOSYLATION,HAPTOGLOBIN,BIOMARKER",ANALYTICAL CHEMISTRY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6768561,
