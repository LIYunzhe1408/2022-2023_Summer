,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Extracting Training Data for Machine Learning Road Segmentation from Pedestrian Perspective,,,49-54,"Jakob Judith,Tick Jozsef","Jakob J,Tick J",Jakob J,,Obuda University,"We introduce an algorithm that performs road background segmentation on video material from pedestrian perspective using machine learning methods. As there are no annotated data sets providing training data for machine learning, we develop a method that automatically extracts road respectively background blocks from the first frames of a sequence by analyzing weights based on mean gray value, mean saturation, and y coordinate of the block's middle pixel. For each block labeled either road or background, several feature vectors are computed by considering smaller overlapping blocks within each block. Together with the x coordinate of a block's middle pixel, mean gray value, mean saturation, and y coordinate form a block's feature vector. All feature vectors and their labels are passed to a machine learning method. The resulting model is then applied to the remaining frames of the video sequence in order to separate road and background. In tests, the accuracy of the training data passed to the machine learning methods was 99.84 %. For the complete algorithm, we reached hit rates of 99.41 % when using a support vector machine and 99.87 % when using a neural network.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering",,,,,,
2,WHOSECOUGH: IN-THE-WILD COUGHER VERIFICATION USING MULTITASK LEARNING,,,896-900,"Whitehill Matt,Garrison Jake,Patel Shwetak","Whitehill M,Garrison J,Patel S",Whitehill M,,University of Washington,"Current automatic cough counting systems can determine how many coughs are present in an audio recording. However, they cannot determine who produced the cough. This limits their usefulness as most systems are deployed in locations with multiple people (i.e., a smart home device in a four-person home). Previous models trained solely on speech performed reasonably well on forced coughs [1]. By incorporating coughs into the training data, the model performance should improve. However, since limited natural cough data exists, training on coughs can lead to model overfitting. In this work, we overcome this problem by using multitask learning, where the second task is speaker verification. Our model achieves 82.15% classification accuracy amongst four users on a natural, in-the-wild cough dataset, outperforming human evaluators on average by 9.82%.","Cough,Health Sensing,Multitask Learning,Speaker Verification,Deep Neural Networks",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
3,HUMBUG ZOONIVERSE: A CROWD-SOURCED ACOUSTIC MOSQUITO DATASET,,,916-920,"Kiskin Ivan,Cobb Adam D.,Wang Lawrence,Roberts Stephen","Kiskin I,Cobb AD,Wang L,Roberts S",Kiskin I,,University of Oxford,"Mosquitoes are the only known vector of malaria, which leads to hundreds of thousands of deaths each year. Understanding the number and location of potential mosquito vectors is of paramount importance to aid the reduction of malaria transmission cases. In recent years, deep learning has become widely used for bioacoustic classification tasks. In order to enable further research applications in this field, we release a new dataset of mosquito audio recordings. With over a thousand contributors, we obtained 195,434 labels of two second duration, of which approximately 10 percent signify mosquito events. We present an example use of the dataset, in which we train a convolutional neural network on log-Mel features, showcasing the information content of the labels. We hope this will become a vital resource for those researching all aspects of malaria, and add to the existing audio datasets for bioacoustic detection and signal processing.","Citizen science,dataset,CNN,classification,bioacoustics",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,http://arxiv.org/pdf/2001.04733,
4,CLASSIFICATION OF EPILEPTIC IEEG SIGNALS BY CNN AND DATA AUGMENTATION,,,926-930,"Zhao Xuyang,Sole-Casals Jordi,Li Binghua,Huang Zihao,Wang Andong,Cao Jianting,Tanaka Toshihisa,Zhao Qibin","Zhao XY,Sole-Casals J,Li BH,Huang ZH,Wang AD,Cao JT,Tanaka T,Zhao QB",Zhao XY,,Saitama Institute Technology,"Epileptic focus localization in patients with epileptic seizures is essential when surgery is needed. Recent studies show that this can be done automatically using machine learning approaches. However, well-designed feature extraction methods are often computationally demanding, requiring a large amount of data labeled by physicians, which is time consuming and impractical. In this paper, we firstly introduce a one-dimensional convolutional neural network (1D-CNN) model for epileptic seizure focus detection which avoids the manual, time-consuming feature extraction Moreover, to reduce the necessary number of training samples, we introduce an approach for data augmentation. The experimental results demonstrate the efficiency of the proposed method, with a nearly 3% improvement in performance using the data enhancement method compared to the best result obtained using the traditional feature extraction method.","Epilepsy,convolutional neural network,data augmentation,cosine transform,artificial iEEG data",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,IDENTIFICATION,,,
5,CROSS-DOMAIN JOINT DICTIONARY LEARNING FOR ECG RECONSTRUCTION FROM PPG,,,936-940,"Tian Xin,Zhu Qiang,Li Yuenan,Wu Min","Tian X,Zhu Q,Li YN,Wu M",Tian X,,University System of Maryland,"An emerging research direction considers the inverse problem of inferring electrocardiogram (ECG) from photoplethysmogram (PPG) to bring about the synergy between the easy measurability of PPG and the rich clinical knowledge of ECG to facilitate preventive healthcare. Previous reconstruction using a universal basis has limited accuracy due to the lack of rich representative power. This paper proposes a cross-domain joint dictionary learning (XDJDL) framework to maximize the expressive power for the two cross-domain signals. Building on K-SVD technique, XDJDL optimizes simultaneously the PPG and ECG signal representations and the transform between them, enabling the joint learning of a pair of signal dictionaries with a transform to characterize the relation between their sparse codes. The proposed model is evaluated with 34,000+ ECG/PPG cycle pairs containing a variety of ECG morphologies and cardiovascular diseases. Experimental results validate the accuracy and the generality of the proposed algorithm, suggesting an encouraging potential for disease screening using PPG measurement based on the proactive learned PPG-ECG relationship.","ECG,PPG,inverse problem,dictionary learning,sparse coding",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"IMAGE,SUPERRESOLUTION,K-SVD,PHOTOPLETHYSMOGRAPHY",,,
6,AN LSTM BASED ARCHITECTURE TO RELATE SPEECH STIMULUS TO EEG,,,941-945,"Monesi Mohammad Jalilpour,Accou Bernd,Montoya-Martinez Jair,Francart Tom,Van Hamme Hugo","Monesi MJ,Accou B,Montoya-Martinez J,Francart T,Van Hamme H",Monesi MJ,,KU Leuven,"Modeling the relationship between natural speech and a recorded electroencephalogram (EEG) helps us understand how the brain processes speech and has various applications in neuroscience and brain-computer interfaces. In this context, so far mainly linear models have been used. However, the decoding performance of the linear model is limited due to the complex and highly non-linear nature of the auditory processing in the human brain. We present a novel Long Short-Term Memory (LSTM)-based architecture as a nonlinear model for the classification problem of whether a given pair of (EEG, speech envelope) correspond to each other or not. The model maps short segments of the EEG and the envelope to a common embedding space using a CNN in the EEG path and an LSTM in the speech path. The latter also compensates for the brain response delay. In addition, we use transfer learning to fine-tune the model for each subject. The mean classification accuracy of the proposed model reaches 85%, which is significantly higher than that of a state of the art Convolutional Neural Network (CNN)-based model (73%) and the linear model (69%).","LSTM,CNN,speech decoding,auditory system,EEG",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,ENTRAINMENT,,https://lirias.kuleuven.be/bitstream/123456789/651641/2/4491_postprint.pdf,
7,JOINT SEMI-SUPERVISED FEATURE AUTO-WEIGHTING AND CLASSIFICATION MODEL FOR EEG-BASED CROSS-SUBJECT SLEEP QUALITY EVALUATION,,,946-950,"Peng Yong,Li Qingxi,Kong Wanzeng,Zhang Jianhai,Lu Bao-Liang,Cichocki Andrzej","Peng Y,Li QX,Kong WZ,Zhang JH,Lu BL,Cichocki A",Peng Y,,Hangzhou Dianzi University,"Measuring the sleep quality is important or even crucial for people who are engaged in dangerous jobs such as the high-speed train drivers. Since the scalp EEG data are generated by the neural activities of the brain cortex, it is collected from subjects with different hours of sleep time (4 hours, 6 hours and 8 hours) to conduct sleep quality evaluation. To suppress the cross-subject variances of EEG data, in this paper, we propose a joint feature auto-weighting and semi-supervised classification model, termed GRLSR, which is formulated by introducing an auto-weighting variable into the least square regression to adaptively and quantitatively measure the importance of each dimension of the feature. Once the model is solved, besides the measurement results, we can use the auto-weighting variable to 1) analyze the importance of each frequency band in sleep quality expression and 2) identify the capacity of different channels connecting to the sleep effect. Therefore, the proposed GRLSR is a pure data-driven computing model for EEG-based cross-subject sleep quality evaluation. Experimental results show its effectiveness.","Sleep quality evaluation,EEG,Feature auto-weighting,Semi-supervised learning,Classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
8,MULTI-MODAL SELF-SUPERVISED PRE-TRAINING FOR JOINT OPTIC DISC AND CUP SEGMENTATION IN EYE FUNDUS IMAGES,,,961-965,"Hervella Alvaro S.,Ramos Lucia,Rouco Jose,Novo Jorge","Hervella AS,Ramos L,Rouco J,Novo J",Hervella AS,,Universidade da Coruna,"This paper presents a novel approach for the segmentation of the optic disc and cup in eye fundus images using deep learning. The accurate segmentation of these anatomical structures in the eye is important towards the early detection of glaucoma and, therefore, potentially avoiding severe vision loss. In order to improve the segmentation of the optic disc and cup, we propose a novel self-supervised pre-training consisting in the multi-modal reconstruction of eye fundus images. This novel approach aims at facilitating the segmentation task and avoiding the necessity of excessively large annotated datasets.
To validate the proposal, we perform several experiments on different public datasets. The results show that the proposed multi-modal self-supervised pre-training leads to a significant improvement in the performance of the segmentation task. Consequently, the presented approach shows remarkable potential towards further improving the interpretable and early diagnosis of a relevant disease as is glaucoma.","Deep learning,self-supervised learning,segmentation,eye fundus,glaucoma",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
9,A DEEP GRADIENT BOOSTING NETWORK FOR OPTIC DISC AND CUP SEGMENTATION,,,971-975,"Liu Qing,Zou Beiji,Zhao Yang,Liang Yixiong","Liu Q,Zou BJ,Zhao Y,Liang YX",Liang YX,,Central South University,"Segmentation of optic disc (OD) and optic cup (OC) is critical in automated fundus image analysis system. Existing state-of-the-arts focus on designing deep neural networks with one or multiple dense prediction branches. Such kind of designs ignore connections among prediction branches and their learning capacity is limited. To build connections among prediction branches, this paper introduces gradient boosting framework to deep classification model and proposes a gradient boosting network called BoostNet. Specifically, deformable side-output unit and aggregation unit with deep supervisions are proposed to learn base functions and expansion coefficients in gradient boosting framework. By stacking aggregation units in a deep-to-shallow manner, models' performances are gradually boosted along deep to shallow stages. BoostNet achieves superior results to existing deep OD and OC segmentation networks on the public dataset ORIGA.","Fundus image,OD and OC segmentation,gradient boosting,deep supervision",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,http://arxiv.org/pdf/1911.01648,
10,RESTING-STATE EEG-BASED BIOMETRICS WITH SIGNALS FEATURES EXTRACTED BY MULTIVARIATE EMPIRICAL MODE DECOMPOSITION,,,991-995,"Ma Matthew King-Hang,Lee Tan,Fong Manson Cheuk-Man,Wang William Shiyuan","Ma MKH,Lee T,Fong MCM,Wang WS",Ma MKH,,Chinese University of Hong Kong,"EEG-based biometrics has gained great attention in recent years due to its superiority over traditional biometrics in terms of its resistance to circumvention. While there are numerous choices of data acquisition protocol, the present study is carried out with the least demanding resting-state condition. Motivated by neurophysiological knowledge, a type of novel feature, namely the intrinsic mode correlation (IMCOR), is proposed. It is designed by combining the nonstationary multivariate empirical mode decomposition (NA-MEMD) and the concept of brain connectivity. With machine learning classifiers, our system yields promising performance in a 81-class classification (F1 score: 0.99) within a single session. For 32-class cross-session classification, an F1 score of 0.55 is attained. The results suggest that the proposed method might be vulnerable to temporal effects and between-session variability. This study highlights the uniqueness of the proposed non-stationary and connectivity-based feature and demonstrated its success as a biometrics. Further investigation is needed to make the method practically useful.","Biometrics,resting-state EEG,feature extraction,multivariate empirical mode decomposition,connectivity",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,PERMANENCE,,,
11,STRATEGIC ATTENTION LEARNING FOR MODALITY TRANSLATION,,,1030-1034,"Martinez Jonathan,Akbari Ali,Sel Kaan,Jafari Roozbeh","Martinez J,Akbari A,Sel K,Jafari R",Martinez J,,Texas A&M University System,"Novel wearable sensor modalities, such as bio-impedance (Bio-Z), are being introduced and often provide various advantages over current state-of-the-art in terms of accuracy, sensing coverage, or convenience of wear. The principal challenge, however, lies in the ability to interpret the sensor reading by healthcare providers. In this work, we propose a two-stage deep learning framework that leverages a novel attention mechanism to translate Bio-Z signals to highly interpretable electrocardiogram (ECG) waveforms while also predicting translation uncertainty. Our experiments indicate a 66% improvement in accuracy for 1D-CNN based models to perform competitively with more sophisticated hybrid CNN-LSTM based models in a fraction of the training time while also providing a valid uncertainty measurement.","modality translation,sequence-to-sequence,deep learning,uncertainty quantification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
12,HUMAN-MACHINE COLLABORATION FOR MEDICAL IMAGE SEGMENTATION,,,1040-1044,"Ravanbakhsh Mahdyar,Tschernezki Vadim,Last Felix,Klein Tassilo,Batmanghelich Kayhan,Tresp Volker,Nabi Moin","Ravanbakhsh M,Tschernezki V,Last F,Klein T,Batmanghelich K,Tresp V,Nabi M",Ravanbakhsh M,,Technical University of Berlin,"Image segmentation is a ubiquitous step in almost any medical image study. Deep learning-based approaches achieve state-of-the-art in the majority of image segmentation benchmarks. However, end-to-end training of such models requires sufficient annotation. In this paper, we propose a method based on conditional Generative Adversarial Network (cGAN) to address segmentation in semi-supervised setup and in a human-in-the-loop fashion. More specifically, we use the generator in the GAN to synthesize segmentations on unlabeled data and use the discriminator to identify unreliable slices for which expert annotation is required. The quantitative results on a conventional standard benchmark show that our method is comparable with the state-of-the-art fully supervised methods in slice-level evaluation, despite of requiring far less annotated data.","GANs,Human-Machine Collaboration",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7543994,
13,MIXUP MULTI-ATTENTION MULTI-TASKING MODEL FOR EARLY-STAGE LEUKEMIA IDENTIFICATION,,,1045-1049,"Mathur Puneet,Piplani Mehak,Sawhney Ramit,Jindal Amit,Shah Rajiv Ratn","Mathur P,Piplani M,Sawhney R,Jindal A,Shah RR",Mathur P,,University System of Maryland,"Recently, several image processing and deep learning techniques have been applied to automate the detection of Acute Lymphoblastic Leukemia cells (ALL). However, most of them have consistently focused on classification mature stage cell images into binary categories of ALL or normal cells. The real impetus of biomedical imaging lies in detecting early-stage cases since early-stage ALL cells have unintuitive global contextual and local spatial features, making their detection non-trivial. To this effect, we propose a novel architecture termed as Mixup Multi-Attention Multi-Task Learning Model (MMA-MTL), which introduces Pointwise Attention Convolution Layers and Local Spatial Attention blocks to capture global and local features simultaneously. We also introduce Rademacher Paired Sampling Mixup to prevent memorization of training data in cases of limited categorical shift. Our proposed method shows competitive performance on the ISBI-2019 CNMC dataset and benchmarks appropriate design choices for future biomedical imaging tasks.","Attention networks,multi-task learning,mixup data augmentation,biomedical image analysis",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,DIAGNOSIS,,,
14,UNET 3+: A FULL-SCALE CONNECTED UNET FOR MEDICAL IMAGE SEGMENTATION,,,1055-1059,"Huang Huimin,Lin Lanfen,Tong Ruofeng,Hu Hongjie,Zhang Qiaowei,Iwamoto Yutaro,Han Xianhua,Chen Yen-Wei,Wu Jian","Huang HM,Lin LF,Tong RF,Hu HJ,Zhang QW,Iwamoto Y,Han XH,Chen YW,Wu J",Lin LF; Chen YW,,Zhejiang University,"Recently, a growing interest has been seen in deep learning-based semantic segmentation. UNet, which is one of deep learning networks with an encoder-decoder architecture, is widely used in medical image segmentation. Combining multi-scale features is one of important factors for accurate segmentation. UNet++ was developed as a modified Unet by designing an architecture with nested and dense skip connections. However, it does not explore sufficient information from full scales and there is still a large room for improvement. In this paper, we propose a novel UNet 3+, which takes advantage of full-scale skip connections and deep supervisions. The full-scale skip connections incorporate low-level details with high-level semantics from feature maps in different scales; while the deep supervision learns hierarchical representations from the full-scale aggregated feature maps. The proposed method is especially benefiting for organs that appear at varying scales. In addition to accuracy improvements, the proposed UNet 3+ can reduce the network parameters to improve the computation efficiency. We further propose a hybrid loss function and devise a classification-guided module to enhance the organ boundary and reduce the over-segmentation in a non-organ image, yielding more accurate segmentation results. The effectiveness of the proposed method is demonstrated on two datasets.","Segmentation,Full-scale skip connection,Deep supervision,Hybrid loss function,Classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,http://arxiv.org/pdf/2004.08790,
15,UNSUPERVISED CONTENT-PRESERVED ADAPTATION NETWORK FOR CLASSIFICATION OF PULMONARY TEXTURES FROM DIFFERENT CT SCANNERS,,,1060-1064,"Xu Rui,Cong Zhen,Ye Xinchen,Kido Shoji,Tomiyama Noriyuki","Xu R,Cong Z,Ye XC,Kido S,Tomiyama N",Ye XC,,Dalian University of Technology,"Deep network based methods have been proposed for accurate classification of pulmonary textures on CT images. However, such methods well-trained on CT data from one scanner cannot perform well when they are directly applied to the data from other scanners. This domain shift problem is caused by different physical components and scanning protocols of different CT scanners. In this paper, we propose an unsupervised content-preserved adaptation network to address this problem. Our method can make a previously well-trained deep network to be adapted for the data of a new CT scanner and does not require the laboring annotation to delineate pulmonary texture regions on the new CT data. Extensive evaluations have been carried on images collected from GE and Toshiba CT scanners and show that the proposed method can alleviate the performance degradation problem of classifying pulmonary textures from different CT scanners.","Pulmonary Textures Classification,Unsupervised Domain Adaptation,Different CT Scanners",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,LUNG,,,
16,ENCODING TEMPORAL INFORMATION FOR AUTOMATIC DEPRESSION RECOGNITION FROM FACIAL ANALYSIS,,,1080-1084,"de Melo Wheidima Carneiro,Granger Eric,Lopez Miguel Bordallo","de Melo WC,Granger E,Lopez MB",de Melo WC,,University of Oulu,"Depression is a mental illness that may be harmful to an individual's health. Using deep learning models to recognize the facial expressions of individuals captured in videos has shown promising results for automatic depression detection. Typically, depression levels are recognized using 2D-Convolutional Neural Networks (CNNs) that are trained to extract static features from video frames, which impairs the capture of dynamic spatio-temporal relations. As an alternative, 3D-CNNs may be employed to extract spatio-temporal features from short video clips, although the risk of overfitting increases due to the limited availability of labeled depression video data. To address these issues, we propose a novel temporal pooling method to capture and encode the spatio-temporal dynamic of video clips into an image map. This approach allows fine-tuning a pre-trained 2D CNN to model facial variations, and thereby improving the training process and model accuracy. Our proposed method is based on two-stream model that performs late fusion of appearance and dynamic information. Extensive experiments on two benchmark AVEC datasets indicate that the proposed method is efficient and outperforms the state-of-the-art schemes.","Affective Computing,Depression Detection,Expression Recognition,Temporal Pooling,Two-stream Model",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,http://jultika.oulu.fi/files/nbnfi-fe2020090267167.pdf,
17,SPEECH BREATHING ESTIMATION USING DEEP LEARNING METHODS,,,1140-1144,"Nallanthighal Venkata Srikanth,Harma Aki,Strik Helmer","Nallanthighal VS,Harma A,Strik H",Nallanthighal VS,,Philips,"Breathing is the primary mechanism for maintaining the sub-glottal pressure for speech production. Speech can be seen as a systematic outflow of air during exhalation characterized by linguistic content and prosodic factors. Thus, sensing respiratory dynamics from the speech is plausible. In this paper, we explore techniques for sensing breathing from speech using deep learning architectures including multi-task learning approaches. Estimating the breathing pattern from the speech would give us information about the respiration rate, breathing capacity and thus enable us to understand the pathological condition of a person using one's speech. Training and evaluation of our model on our database of breathing signal and speech for 40 subjects yielded a sensitivity of 0.88 for breath event detection and 5.6 % error for breathing rate estimation.","Speech breathing,signal processing,speech technology,deep neural networks,Multi task learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"RIB,CAGE",,,
18,SYNTHETIC DATA GENERATION THROUGH STATISTICAL EXPLOSION: IMPROVING CLASSIFICATION ACCURACY OF CORONARY ARTERY DISEASE USING PPG,,,1165-1169,"Bhattacharya Sakyajit,Mazumder Oishee,Roy Dibyendu,Sinha Aniruddha,Ghose Avik","Bhattacharya S,Mazumder O,Roy D,Sinha A,Ghose A",Bhattacharya S,,Tata Sons,"Synthetic data generation has recently emerged as a substitution technique for handling the problem of bulk data needed in training machine learning algorithms. Healthcare, primarily cardiovascular domain is a major area where synthetic physiological data can be used improve accuracy of machine learning algorithm. This paper presents a novel approach of generating synthetic Photoplethysmogram (PPG) data using statistical explosion. Synthetic data is subsequently used to classify Coronary Artery Disease (CAD) using a two stage cascaded classifier. Proposed classifier along with synthetic data removes class bias and provides better accuracy compared to state of art. The proposed data generation and cascaded classifier is generic enough to be used to improve machine learning algorithm on any time series signal.","Cascaded classifier,Coronary Artery Disease,Kernel Density Estimate,Photoplethysmogram,Synthetic data",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
19,"HIGH-ACCURACY CLASSIFICATION OF ATTENTION DEFICIT HYPERACTIVITY DISORDER WITH L-2,L-1-NORM LINEAR DISCRIMINANT ANALYSIS",,,1170-1174,"Tang Yibin,Li Xufei,Chen Ying,Zhong Yuan,Jiang Aimin,Liu Xiaofeng","Tang YB,Li XF,Chen Y,Zhong Y,Jiang AM,Liu XF",Tang YB,,Hohai University,"Attention Deficit Hyperactivity Disorder (ADHD) is a high incidence of neurobehavioral disease in school-age children. Its neurobiological classification is meaningful for clinicians. The existing ADHD classification methods suffer from two problems, i.e., insufficient data and noise disturbance. Here, a high-accuracy classification method is proposed, which uses brain Functional Connectivity (FC) as material for ADHD feature analysis. In detail, we introduce a binary hypothesis testing framework as the classification outline to cope with insufficient data of ADHD database. Under binary hypotheses, the FCs of test data are allowed to use for training and thus affect the subspace learning of training data. To overcome noise disturbance, an l(2,1)-norm LDA model is adopted to robustly learn ADHD features in subspaces. The subspace energies of training data under binary hypotheses are then calculated, and an energy-based comparison is finally performed to identify ADHD individuals. On the platform of ADHD-200 database, the experiments show our method outperforms other state-of-the-art methods with the significant average accuracy of 97.6%.","ADHD classification,binary hypothesis,feature learning,LDA,subspace learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"ADHD,INDIVIDUALS,SELECTION,FMRI",,,
20,CONDITIONAL DOMAIN ADVERSARIAL TRANSFER FOR ROBUST CROSS-SITE ADHD CLASSIFICATION USING FUNCTIONAL MRI,,,1190-1194,"Huang Ya-Lin,Hsieh Wan-Ting);,Yang Hao-Chun);,Lee Chi-Chun","Huang YL,Hsieh WT,Yang HC,Lee CC",Huang YL,,National Tsing Hua University,"There is a growing number of large scale cross-site database collection of resting-state functional magnetic resonance imaging (rs-fMRI) for studying neurobehavioral diseases, such as ADHD. Although a large amount of data benefits machine learning-based classification methods, the idiosyncratic variability of each site can deteriorate cross-site generalization ability. This challenge creates a bottleneck in requiring a large number of labeled samples of each site. Hence in this research, we utilize an approach of conditional adversarial domain adaptation network (CDAN) to learn a discriminative fMRI representation that is site-invariant for unsupervised transfer of ADHD classification. We evaluate our framework on a multi-site ADHD dataset and achieve improvement in transferring between sites. Further visualization reveals that there indeed exists a substantial site discrepancy and statistically analysis indicates that male's rs-fMRI could be more vulnerable toward site-specific effects.","ADHD,fMRI,adversarial domain adaptation,multi-site transfer",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"ATTENTION-DEFICIT%2FHYPERACTIVITY,DISORDER,CHILDREN",,,
21,AUTOMATIC EPILEPTIC SEIZURE ONSET-OFFSET DETECTION BASED ON CNN IN SCALP EEG,,,1225-1229,"Boonyakitanont Poomipat,Lek-uthai Apiwat,Songsiri Jitkomut","Boonyakitanont P,Lek-uthai A,Songsiri J",Boonyakitanont P,,Chulalongkorn University,"We establish a deep learning-based method to automatically detect the epileptic seizure onsets and offsets in multi-channel electroencephalography (EEG) signals. A convolutional neural network (CNN) is designed to identify occurrences of seizures in EEG epochs from the EEG signals and an onset-offset detector is proposed to determine the seizure onsets and offsets. The EEG signals are considered as inputs and the outputs are the onset and offset. In the CNN, a filter is factorized to separately capture temporal and spatial patterns in EEG epochs. Moreover, we develop an onset-offset detection method based on clinical decision criteria. As a result, verified on the whole CHB-MIT Scalp EEG database, the CNN model correctly detected seizure activities over 90%. Furthermore, combined with the onset-offset detector, this method accomplished F-1 of 64.40% and essentially determined the seizure onset and offset with absolute onset and offset latencies of 5.83 and 10.12 seconds, respectively.","CNN,EEG,seizure detection,onset-offset detection",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,CLASSIFICATION,,,
22,SCALPNET: DETECTION OF SPATIOTEMPORAL ABNORMAL INTERVALS IN EPILEPTIC EEG USING CONVOLUTIONAL NEURAL NETWORKS,,,1244-1248,"Sakai Takahiko,Shoji Taku,Yoshida Noboru,Fukumori Kosuke,Tanaka Yuichi,Tanaka Toshihisa","Sakai T,Shoji T,Yoshida N,Fukumori K,Tanaka Y,Tanaka T",Sakai T,,Tokyo University of Agriculture & Technology,"We propose ScalpNet: A deep neural network to detect spatiotemporal abnormal intervals from EEGs of epilepsy patients. Since the number of trained clinicians is very limited, it is very crucial to establish automatic detection of abnormal signals caused by epilepsy from EEGs. We build a convolutional neural network detecting spatio-temporal intervals that will be abnormal based on the fact that peaky EEG signals can be observed not only in the electrode close to the focal region but those in the surrounding regions. In the experiments with a real dataset, our proposed ScalpNet presents higher classification accuracy than existing machine learning methods, including a convolutional neural network performed by channel-by-channel.","Epilepsy,deep neural networks,electroencephalogram (EEG)",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
23,MENTAL FATIGUE PREDICTION FROM MULTI-CHANNEL ECOG SIGNAL,,,1259-1263,"Yao Lin,Baker Jonathan L.,Ryou Jae-Wook,Schiff Nicholas D.,Purpura Keith P.,Shoaran Mahsa","Yao L,Baker JL,Ryou JW,Schiff ND,Purpura KP,Shoaran M",Yao L,,Cornell University,"Early detection of mental fatigue and changes in vigilance could be used to initiate neurostimulation to treat patients suffering from brain injury and mental disorders. In this study, we analyzed electrocorticography (ECoG) signals chronically recorded from two non-human primates (NHPs) as they performed a cognitively demanding task over extended periods of time. We employed a set of biomarkers to identify mental fatigue and a gradient boosting classifier to predict the performance outcome, seconds prior to the actual behavior response. An average F1 score of 75.4%+/- 8.4% and 86.4%+/- 6.6% was obtained for the two studied NHPs. Our preliminary results demonstrate the feasibility of detecting mental fatigue in healthy primates that could be used for closed-loop control of neurostimulation therapy.","Mental fatigue,ECoG,machine learning,feature extraction,vigilance task,deep-brain stimulation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"ATTENTION,AROUSAL,PERFORMANCE",,,
24,The Effect of Data Augmentation on Classification of Atrial Fibrillation in Short Single-Lead ECG Signals Using Deep Neural Networks,,,1264-1268,"Hatamian Faezeh Nejati,Ravikumar Nishant,Vesal Sulaiman,Kemeth Felix P.,Struck Matthias,Maier Andreas","Hatamian FN,Ravikumar N,Vesal S,Kemeth FP,Struck M,Maier A",Maier A,,University of Erlangen Nuremberg,"Cardiovascular diseases are the most common cause of mortality worldwide. Detection of atrial fibrillation (AF) in the asymptomatic stage can help prevent strokes. It also improves clinical decision making through the delivery of suitable treatment such as, anticoagulant therapy, in a timely manner. The clinical significance of such early detection of AF in electrocardiogram (ECG) signals has inspired numerous studies in recent years, of which many aim to solve this task by leveraging machine learning algorithms. ECG datasets containing AF samples, however, usually suffer from severe class imbalance, which if unaccounted for, affects the performance of classification algorithms. Data augmentation is a popular solution to tackle this problem.
In this study, we investigate the impact of various data augmentation algorithms, e.g., oversampling, Gaussian Mixture Models (GMMs) and Generative Adversarial Networks (GANs), on solving the class imbalance problem. These algorithms are quantitatively and qualitatively evaluated, compared and discussed in detail. The results show that deep learning-based AF signal classification methods benefit more from data augmentation using GANs and GMMs, than oversampling. Furthermore, the GAN results in circa 3% better AF classification accuracy in average while performing comparably to the GMM in terms of f1-score.","atrial fibrillation,data augmentation,GMM,DCGAN",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,STROKE,,http://arxiv.org/pdf/2002.02870,
25,ATRIAL FIBRILLATION RISK PREDICTION FROM ELECTROCARDIOGRAM AND RELATED HEALTH DATA WITH DEEP NEURAL NETWORK,,,1269-1273,"Chen Yi-Huan,Twinge A. Husain,Badawi Diaa,Danavi Joseph,McCauley Mark,Cain A. Enis","Chen YH,Twinge AH,Badawi D,Danavi J,McCauley M,Cain AE",Chen YH,,University of Illinois System,"Electrocardiography (ECG) is a widely used tool for studying and diagnosing the heart diseases. Atrial fibrillation (AF) is an irregular and often rapid heart rate that can increase the risk of strokes, heart failure and other heart-related complications. In this study, we develop a novel and effective method to predict the potential AF risk of patients using our ECG signal dataset collected in the University of Illinois Hospital and Health Sciences System. We use a convolutional neural network (CNN) structure to process both the ECG signals and the related health data of patients. Our experimental results indicate that the model with patients' health data can predict the AF with 79.9% accuracy), and which is better than a CNN trained without related health data 72.2% accuracy), which implies that patients' health data play an important role in predicting AF risk. Very high sensitivity and specificity of the class of normal sinus rhythm (NSR) cases also verify that the model works well for distinguishing between NSR and ECG signals with potential AF risk.","ECG analysis,Demographic information,Atrial Fibrillation,Convolutional Neural Network",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"ECG,DATA-COMPRESSION,ARRHYTHMIA,DETECTION,CLASSIFICATION,FEATURES",,,
26,ADAPTIVE REGION AGGREGATION NETWORK: UNSUPERVISED DOMAIN ADAPTATION WITH ADVERSARIAL TRAINING FOR ECG DELINEATION,,,1274-1278,"Chen Ming,Wang Guijin,Chen Hui,Ding Zijian","Chen M,Wang GJ,Chen H,Ding ZJ",Chen M,,Tsinghua University,"Electrocardiogram (ECG) delineation, which provides clinically useful information for the diagnosis of cardiovascular disease, is an essential task in automated ECG analysis. The discrepancies among ECG signals from different datasets, namely domain shifts, may bring severe challenges to the cross-dataset performance of ECG delineation algorithms. The domain shifts are generally caused by the differences of conditions, collecting devices, and individual characteristics, and are inherent and non-negligible in ECG. In this work, we propose an unsupervised domain adaptation method called Adaptive Region Aggregation Network (ARAN) based on adversarial training to tackle domain shift problem in ECG delineation. The proposed algorithm promotes the state-of-the-art deep neural network RAN[1] to learn domain-invariant features and achieve improving performance on both source and target domain. The experiments results on two public datasets, LUDB and QT database, prove that our approach can effectively improve the cross-dataset performance of the state-of-the-art deep learning model.","ECG delineation,deep learning,unsupervised domain adaptation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"T-WAVE,DELINEATION",,,
27,CROSS-DOMAIN ADAPTATION FOR BIOMETRIC IDENTIFICATION USING PHOTOPLETHYSMOGRAM,,,1289-1293,"Lee Eugene,Ho Annie,Wang Yi-Ting,Huang Cheng-Han,Lee Chen-Yi","Lee E,Ho A,Wang YT,Huang CH,Lee CY",Lee E,,National Yang Ming Chiao Tung University,"The adoption of biomedical signals such as photoplethysmogram (PPG) and electrocardiogram (ECG) for health parameter estimation on wearable devices is growing in tandem with the increase of attention in mobile healthcare. In our work, we use PPG signals extracted from PPG sensors which are used for biometric identification. A challenge for biometric identification using PPG signal is the variation in domain (placement of sensors, wavelengths, device variation, etc.). In this work, we propose the use of both unsupervised and semi-supervised adversarial learning techniques for cross-domain adaptation. As such algorithm will be deployed on wearable devices, we propose a compact model meeting tight memory footprint limitation. All experiments will be simulated using a public dataset (TROIKA) and our in-house dataset. By introducing a cross-domain adaptation approach across sensors, we observe an accuracy gain of 4.15% on our in-house dataset. The proposed semi-supervised learning technique gives an additional accuracy boost of 2.02%.","Cross-domain adaptation,biometric identification,photoplethysmogram,deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
28,XceptionTime: INDEPENDENT TIME-WINDOW XCEPTIONTIME ARCHITECTURE FOR HAND GESTURE CLASSIFICATION,,,1304-1308,"Rahimian Elahe,Zabihi Soheil,Atashzar Seyed Farokh,Asif Amir,Mohammadi Arash","Rahimian E,Zabihi S,Atashzar SF,Asif A,Mohammadi A",Rahimian E,,Concordia University - Canada,"Capitalizing on the goal of addressing identified shortcomings of recent solutions developed for recognition tasks via sparse multichannel surface Electromyography (sEMG) signals, the paper proposes a novel deep learning model, referred to as the XceptionTime architecture. The proposed innovative XceptionTime architecture is designed by integration of depthwise separable convolutions, adaptive average pooling, and a novel no-linear normalization technique. At the hearth of the proposed architecture is several XceptionTime modules concatenated in series fashion designed to captures both temporal and spatial information-bearing contents of the sparse multichannel sEMG signals without the need for data augmentation and manual design of feature extraction. In addition to instruction of the new XceptionTime module, by integration of adaptive average pooling, instead of fully connected layers, and utilization of a novel non-linear normalization approach, the proposed architecture is less prone to overfitting, more robust to temporal translation of the input, and more importantly is independent from the input window size, i.e., there is no need to change/reconfigure the architecture by changing the size of the input sequence. Finally, by utilizing the depthwise separable convolutions, the XceptionTime network has far less parameters resulting in less complex network.","Surface Electromyography (sEMG),Depthwise Separable Convolution,Adaptive Average Pooling",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
29,SUBJECT TRANSFER FRAMEWORK BASED ON SOURCE SELECTION AND SEMI-SUPERVISED STYLE TRANSFER MAPPING FOR SEMG PATTERN RECOGNITION,,,1349-1353,"Kanoga Suguru,Hoshino Takayuki,Asoh Hideki","Kanoga S,Hoshino T,Asoh H",Kanoga S,,National Institute of Advanced Industrial Science & Technology (AIST),"To construct subject-specific feature extractors and classifiers for a new subject using pooled datasets, overcoming intersubject variabilities is required. In this study, we investigate the efficiency of the proposed subject transfer framework, which applies a discriminability-based source selection approach and semi-supervised style transfer mapping algorithm, by constructing support vector machine classifiers. We collect a surface electromyogram (sEMG) dataset acquired from 25 subjects using a wearable sEMG sensor. Classifiers are trained with gold-standard time-domain and autoregressive features extracted from eight-channel sEMG data. Compared with conventional subject transfer framework (85.08 +/- 1.38%), which applies the covariate shift adaptation algorithm to the linear discriminant analysis classifier and uses all source data, our proposed framework improves pattern recognition accuracy (90.63 +/- 1.27%) by selection of discriminative source data and the mapping destination in the Euclidean space.","Transfer learning,style transfer mapping,surface electromyogram (sEMG),covariate shift adaptation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"SURFACE,EMG,CLASSIFICATION,SCHEME",,,
30,DECODING MOVEMENT IMAGINATION AND EXECUTION FROM EEG SIGNALS USING BCI-TRANSFER LEARNING METHOD BASED ON RELATION NETWORK,,,1354-1358,"Lee Do-Yeun,Jeong Ji-Hoon,Shim Kyung-Hwan,Lee Seong-Whan","Lee DY,Jeong JH,Shim KH,Lee SW",Lee DY,,Korea University,"A brain-computer interface (BCI) is used to control external devices for healthy people as well as to rehabilitate motor functions for motor-disabled patients. Decoding movement intention is one of the most significant aspects for performing arm movement tasks using brain signals. Decoding movement execution (ME) from electroencephalogram (EEG) signals have shown high performance in previous works, however movement imagination (MI) paradigm-based intention decoding has so far failed to achieve sufficient accuracy. In this study, we focused on a robust MI decoding method with transfer learning for the ME and MI paradigm. We acquired EEG data related to arm reaching for 3D directions. We proposed a BCI-transfer learning method based on a Relation network (BTRN) architecture. Decoding performances showed the highest performance compared to conventional works. We confirmed the possibility of the BTRN architecture to contribute to continuous decoding of MI using ME datasets.","Brain-computer interface (BCI),Electroencephalogram (EEG),Transfer learning,Movement imagination and execution",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"MOTOR,IMAGERY",,http://arxiv.org/pdf/2002.00538,
31,A SEGMENTATION BASED ROBUST DEEP LEARNING FRAMEWORK FOR MULTIMODAL RETINAL IMAGE REGISTRATION,,,1369-1373,"Wang Yiqian,Zhang Junkang,An Cheolhong,Cavichini Melina,Jhingan Mahima,Amador-Patarroyo Manuel J.,Long Christopher P.,Bartsch Dirk-Uwe G.,Freeman William R.,Nguyen Truong Q.","Wang YQ,Zhang JK,An C,Cavichini M,Jhingan M,Amador-Patarroyo MJ,Long CP,Bartsch DUG,Freeman WR,Nguyen TQ",Wang YQ,,University of California System,"Multimodal image registration plays an important role in diagnosing and treating ophthalmologic diseases. In this paper, a deep learning framework for multimodal retinal image registration is proposed. The framework consists of a segmentation network, feature detection and description network, and an outlier rejection network, which focuses only on the globally coarse alignment step using the perspective transformation. We apply the proposed framework to register color fundus images with infrared reflectance images and compare it with the state-of-the-art conventional and learning-based approaches. The proposed framework demonstrates a significant improvement in robustness and accuracy reflected by a higher success rate and Dice coefficient compared to other coarse alignment methods.","Image registration,multimodal,retinal images,convolutional neural networks",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
32,DENSE RESIDUAL NETWORK FOR RETINAL VESSEL SEGMENTATION,,,1374-1378,"Guo Changlu,Szemenyei Morton,Yi Yugen,Xue Ying,Zhou Wei,Li Yangyuan","Guo CL,Szemenyei M,Yi YG,Xue Y,Zhou W,Li YY",Yi YG,,Jiangxi Normal University,"Retinal vessel segmentation plays an imaportant role in the field of retinal image analysis because changes in retinal vascular structure can aid in the diagnosis of diseases such as hypertension and diabetes. In recent research, numerous successful segmentation methods for fundus images have been proposed. But for other retinal imaging modalities, more research is needed to explore vascular extraction. In this work, we propose an efficient method to segment blood vessels in Scanning Laser Ophthalmoscopy (SLO) retinal images. Inspired by U-Net, ""feature map reuse"" and residual learning, we propose a deep dense residual network structure called DRNet. In DRNet, feature maps of previous blocks are adaptively aggregated into subsequent layers as input, which not only facilitates spatial reconstruction, but also learns more efficiently due to more stable gradients. Furthermore, we introduce DropBlock to alleviate the over-fitting problem of the network. We train and test this model on the recent SLO public dataset. The results show that our method achieves the state-of-the-art performance even without data augmentation.","Retinal vessel segmentation,Scanning Laser Ophthalmoscopy (SLO),U-Net,DRNet,DropBlock",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,http://arxiv.org/pdf/2004.03697,
33,LIGHTWEIGHT V-NET FOR LIVER SEGMENTATION,,,1379-1383,"Lei Tao,Zhou Wenzheng,Zhang Yuxiao,Wang Risheng,Meng Hongying,Nandi Asoke K.","Lei T,Zhou WZ,Zhang YX,Wang RS,Meng HY,Nandi AK",Lei T,,Shaanxi University of Science & Technology,"The V-Net based 3D fully convolutional neural networks have been widely used in liver volumetric data segmentation. However, due to the large number of parameters of these networks, 3D FCNs suffer from high computational cost and GPU memory usage. To address these issues, we design a lightweight V-Net (LV-Net) for liver segmentation in this paper. The proposed network makes two contributions. The first is that we design an inverted residual bottleneck block (IRB block) and a 3D average pooling block and apply them to the proposed LV-Net. Compared with vanilla convolution, depth-wise convolution and point-wise convolution employed by the IRB block can not only reduce the number of parameters significantly, but also extract features sufficiently well by decoupling cross-channel corrections and spatial correlations. The second is that the LV-Net employs 3D deep supervision to improve the final loss function in training phase, which makes the proposed LV-Net acquire a more powerful discrimination capability between liver areas and non-liver areas. The proposed LV-Net is evaluated on public LiTS dataset, and experiments demonstrate that the proposed LV-Net is superior to popular 2D and 3D networks in terms of segmentation performance, parameter quantity and computational cost.","deep learning,image segmentation,3D fully convolutional neural network,network compression",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"STATISTICAL,SHAPE,MODEL",,,
34,AN UNSUPERVISED RETINAL VESSEL EXTRACTION AND SEGMENTATION METHOD BASED ON A TUBE MARKED POINT PROCESS MODEL,,,1394-1398,"Li Tianyu,Corner Mary,Zerubia Josiane","Li TY,Corner M,Zerubia J",Li TY,,Purdue University System,"Retinal vessel extraction and segmentation is essential for supporting diagnosis of eye-related diseases. In recent years, deep learning has been applied to vessel segmentation and achieved excellent performance. However, these supervised methods require accurate hand-labeled training data, which may not be available. In this paper, we propose an unsupervised segmentation method based on our previous connected tube marked point process (MPP) model. The vessel network is extracted by the connected-tube MPP model first. Then a new tube-based segmentation method is applied to the extracted tubes. We test this method on STARE and DRIVE databases and the results show that not only do we extract the retina vessel network accurately, but we also achieve high G-means score for vessel segmentation, without using labeled training data.","Retinal vessel segmentation,vessel network extraction,connected tube model,marked point process",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,IMAGES,,https://hal.inria.fr/hal-02981811/document,
35,COMBINING CGAN AND MIL FOR HOTSPOT SEGMENTATION IN BONE SCINTIGRAPHY,,,1404-1408,"Xu Hang);,Geng Shijie);,Qiao Yu,Xu Kuan);,Gu Yueyang","Xu H,Geng SJ,Qiao Y,Xu K,Gu YY",Qiao Y,,Shanghai Jiao Tong University,"Bone scintigraphy is widely used to diagnose bone tumor and metastasis. Accurate hotspot segmentation from bone scintigraphy is of great importance for tumor metastasis diagnosis. In this paper, we propose a new framework to detect and extract hotspots in thoracic region by integrating the techniques of both conditional generative adversarial networks (cGAN) and multiple instance learning (MIL). We first use cGAN to train a generator, which can be applied to separate input bone scan image into four anatomical regions and provide location information. A multi-dimensional feature is constructed to integrate contrast, texture and location information. We then use MIL to train a patch-level classifier with this constructed feature. In hotspot segmentation, a hotspots probability map can be estimated with the patch-level classifier. The hotspot segmentation is performed with level set method, in which the hotspot boundary is initialized based on the hotspot probability map. We evaluate the proposed framework quantitatively on the hotspot dataset, and compare it with other methods.","hotspot segmentation,cGAN,MIL,probability map,level set",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"COMPUTER-AIDED,DIAGNOSIS,IMAGE,SEGMENTATION",,,
36,A MULTI-SCALED RECEPTIVE FIELD LEARNING APPROACH FOR MEDICAL IMAGE SEGMENTATION,,,1414-1418,"Guo Pengcheng,Su Xiangdong,Zhang Haoran,Wang Meng,Bao Feilong","Guo PC,Su XD,Zhang HR,Wang M,Bao FL",Su XD,,Inner Mongolia University,"Biomedical image segmentation has been widely studied, and lots of methods have been proposed. Among these methods, attention U-Net has achieved a promising performance. However, it has drawbacks of extracting the multi-scaled receptive field features at the high-level feature maps, resulting in the degeneration when dealing with the lesions with apparent scale variations. To solve this problem, this paper integrates an atrous spatial pyramid pooling (ASPP) module in the contracting path of attention U-Net. This module employs multiple dilation rates for the purpose of obtaining several multi-scale receptive fields, which significantly improves the networks' ability to handle both large and small lesions. Evaluation experimental result shows that our approach significantly improves the performance of medical image segmentation and substantially outperforms the representative deep learning models on public datasets.","biomedical image segmentation,atrous spatial pyramid pooling,attention U-Net,feature maps,receptive field",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
37,AUTOMATIC DATA AUGMENTATION VIA DEEP REINFORCEMENT LEARNING FOR EFFECTIVE KIDNEY TUMOR SEGMENTATION,,,1419-1423,"Qin Tiexin,Wang Ziyuan,He Kelei,Shi Yinghuan,Gao Yang,Shen Dinggang","Qin TX,Wang ZY,He KL,Shi YH,Gao Y,Shen DG",Shi YH,,Nanjing University,"Conventional data augmentation realized by performing simple pre-processing operations (e.g., rotation, crop, etc.) has been validated for its advantage in enhancing the performance for medical image segmentation. However, the data generated by these conventional augmentation methods are random and sometimes harmful to the subsequent segmentation. In this paper, we developed a novel automatic learning-based data augmentation method for medical image segmentation which models the augmentation task as a trial-and-error procedure using deep reinforcement learning (DRL). In our method, we innovatively combine the data augmentation module and the subsequent segmentation module in an end-to-end training manner with a consistent loss. Specifically, the best sequential combination of different basic operations is automatically learned by directly maximizing the performance improvement (i.e., Dice ratio) on the available validation set. We extensively evaluated our method on CT kidney tumor segmentation which validated the promising results of our method.","Medical image segmentation,Data augmentation,Deep reinforcement learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,http://arxiv.org/pdf/2002.09703,
38,CROSS-STAINED SEGMENTATION FROM RENAL BIOPSY IMAGES USING MULTI-LEVEL ADVERSARIAL LEARNING,,,1424-1428,"Mei Ke,Zhu Chuang,Jiang Lei,Liu Jun,Qiao Yuanyuan","Mei K,Zhu C,Jiang L,Liu J,Qiao YY",Zhu C,,Beijing University of Posts & Telecommunications,"Segmentation from renal pathological images is a key step in automatic analyzing the renal histological characteristics. However, the performance of models varies significantly in different types of stained datasets due to the appearance variations. In this paper, we design a robust and flexible model for cross-stained segmentation. It is a novel multi-level deep adversarial network architecture that consists of three sub-networks: (i) a segmentation network; (ii) a pair of multi-level mirrored discriminators for guiding the segmentation network to extract domain-invariant features; (iii) a shape discriminator that is utilized to further identify the output of the segmentation network and the ground truth. Experimental results on glomeruli segmentation from renal biopsy images indicate that our network is able to improve segmentation performance on target type of stained images and use unlabeled data to achieve similar accuracy to labeled data. In addition, this method can be easily applied to other tasks.","Segmentation,domain adaptation,multi-level adversarial network,domain-invariant feature",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,http://arxiv.org/pdf/2002.08587,
39,LOW-COMPLEXITY COMPRESSED ALIGNMENT-AIDED COMPRESSIVE ANALYSIS FOR REAL-TIME ELECTROCARDIOGRAPHY TELEMONITORING,,,1788-1792,"Pua Yo-Woei,Chou Ching-Yao,Wu An-Yeu (Andy)","Pua YW,Chou CY,Wu AY",Pua YW,,National Taiwan University,"In order to implement a real-time electrocardiogram (ECG) telemonitoring, compressed sensing (CS) is a new technology that reduces the power consumption of biosensors and data transmission. Unfortunately, limited label data and computing resources hinder the real-time ECG telemonitoring. Prior experiments have shown that aligning ECG signals is a good way to solve the problem of limited label data. However, the reconstructed learning (RL) framework requires a lot of computing resources, and the compressed learning (CL) framework makes alignment difficult. In this paper, we propose a new compressed alignment-aided compressive analysis (CA-CA) framework that enables simple alignment and low-complexity requirements. From simulation results, we have demonstrated that our technology can maintain more than 95% accuracy while reducing training data (labeled data) by 70%. Therefore, compared to RL, the computation time and memory overhead of CA-CA are reduced by 6.6 times and 2.45 times, respectively. Compared with CL, the inference accuracy with a small amount of labeled data is improved by 13.5%.","Atrial fibrillation detection,real-time ECG telemonitoring,compressive sensing,compressive analysis,compressed alignment",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,ECG,,,
40,MDR-SURV: A MULTI-SCALE DEEP LEARNING-BASED RADIOMICS FOR SURVIVAL PREDICTION IN PULMONARY MALIGNANCIES,,,2013-2017,"Afshar Parisian,Oikonomou Anastasia,Plataniotis Konstantinos N.,Mohammadi Arash","Afshar P,Oikonomou A,Plataniotis KN,Mohammadi A",Afshar P,,Concordia University - Canada,"Predicting death in lung cancer patients before initiating treatment is of paramount importance as this may guide decision-making towards more aggressive or combination of different types of treatment. In this work, we propose a Multi-scale Deep learning-based Radiomics model, referred to as ""MDR-SURV"" that exploits the information from positron emission tomography/computed tomography (PET/CT) images, combined with other clinical factors, to predict the overall survival (OS). Deep learning-based radiomics has the advantage of learning what features to extract, on its own. Furthermore, it does not require the exact segmentation of the tumor. The proposed MDR-SURV, which is a multi-scale framework, incorporates the tumor region and its surroundings, from different scales, and can extract both local and global tumor features. PET/CT images of 132 lung cancer patients who underwent stereotactic body radiotherapy (SBRT) were used to predict OS with the proposed model. Our results show that the MDR-SURV model outperforms its single-scale counterparts in predicting OS. Furthermore, the proposed MDR-SURV model achieves significantly high concordance index (C-index) of 73% in predicting the OS, which is noticeably higher than the results reported in existing literature.","Survival Prediction,Multi-scale,Deep Learning-based Radiomics,Lung Tumor",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"CELL,LUNG-CANCER",,,
41,HEIGHT AND WEIGHT ESTIMATION FROM UNCONSTRAINED IMAGES,,,2298-2302,"Altinigne Can Yilmaz,Thanou Dorina,Achanta Radhakrishna","Altinigne CY,Thanou D,Achanta R",Altinigne CY,,Ecole Polytechnique Federale de Lausanne,"We address the difficult problem of estimating the attributes of weight and height of individuals from pictures taken in completely unconstrained settings. We present a deep learning scheme that relies on simultaneous prediction of human silhouettes and skeletal joints as strong regularizers that improve the prediction of attributes such as height and weight. Apart from imparting robustness to the prediction of attributes, our regularization also allows for better visual interpretability of the attribute prediction. For height estimation, our method shows lower mean average error compared to the state of the art despite using a simpler approach. For weight estimation, which has hardly been addressed in the literature, we set a new benchmark.","Biometrics,deep learning,height and weight prediction,skeletal joint prediction,segmentation,interpretability,regularization",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,STATURE,,,
42,LEARNING ENDMEMBER DYNAMICS IN MULTITEMPORAL HYPERSPECTRAL DATA USING A STATE-SPACE MODEL FORMULATION,,,2483-2487,"Drumetz Lucas,Dalla Mura Mauro,Tochon Guillaume,Fablet Ronan","Drumetz L,Dalla Mura M,Tochon G,Fablet R",Drumetz L,,IMT - Institut Mines-Telecom,"Hyperspectral image unmixing is an inverse problem aiming at recovering the spectral signatures of pure materials of interest (called endmembers) and estimating their proportions (called abundances) in every pixel of the image. However, in spite of a tremendous applicative potential and the avent of new satellite sensors with high temporal resolution, multitemporal hyperspectral unmixing is still a relatively underexplored research avenue in the community, compared to standard image unmixing. In this paper, we propose a new framework for multitemporal unmixing and endmember extraction based on a state-space model, and present a proof of concept on simulated data to show how this representation can be used to inform multitemporal unmixing with external prior knowledge, or on the contrary to learn the dynamics of the quantities involved from data using neural network architectures adapted to the identification of dynamical systems.","Hyperspectral imaging,time series,spectral unmixing,data assimilation,recurrent neural networks",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,VARIABILITY,,http://arxiv.org/pdf/1911.12020,
43,ECG HEARTBEAT CLASSIFICATION BASED ON MULTI-SCALE WAVELET CONVOLUTIONAL NEURAL NETWORKS,,,3212-3216,"El Bouny Lahcen,Khalil Mohammed,Adib Abdellah","El Bouny L,Khalil M,Adib A",El Bouny L,,Hassan II University of Casablanca,"This paper proposes a novel Deep Learning technique for ECG beats classification. Unlike the traditional Deep Learning models, a new Multi-Scale Wavelet Convolutional Neural Networks (MS-WCNN) is proposed to recognize automatically various cardiac arrhythmias. The proposed MS-WCNN model incorporates the one dimensional CNN and the Stationary Wavelet Transform (SWT) to extract discriminative features from the ECG signal and its wavelet sub-bands simultaneously. The extracted features are then merged using a concatenation strategy. This improves greatly the features learning process of our model at different scales, providing better diagnosis performances. The MITBIH Arrhythmia database has been used to evaluate the performance of the developed model, considering five heartbeats classes: Non-ectopic beat, Supra ventricular ectopic beat, Ventricular ectopic beat, Fusion beat and Unknown beat. The obtained results show that the MS-WCNN method achieves higher or comparable performances with respect to the existing ECG classification algorithms, with an overall diagnosis accuracy of 99, 11%","ECG Classification,Deep Learning,Convolutional Neural Networks,Stationary Wavelet Transform",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"ARRHYTHMIA,DETECTION,SEQUENCE,MODEL",,,
44,SELF-SUPERVISED LEARNING FOR ECG-BASED EMOTION RECOGNITION,,,3217-3221,"Sarkar Pritam,Etemad Ali","Sarkar P,Etemad A",Sarkar P,,Queens University - Canada,"We present an electrocardiogram (ECG)-based emotion recognition system using self-supervised learning. Our proposed architecture consists of two main networks, a signal transformation recognition network and an emotion recognition network. First, unlabelled data are used to successfully train the former network to detect specific pre-determined signal transformations in the self-supervised learning step. Next, the weights of the convolutional layers of this network are transferred to the emotion recognition network, and two dense layers are trained in order to classify arousal and valence scores. We show that our self-supervised approach helps the model learn the ECG feature manifold required for emotion recognition, performing equal or better than the fully-supervised version of the model. Our proposed method outperforms the state-of-the-art in ECG-based emotion recognition with two publicly available datasets, SWELL and AMIGOS. Further analysis highlights the advantage of our self-supervised approach in requiring significantly less data to achieve acceptable results.","Self-supervised Learning,Multi-task,Emotion Recognition,ECG",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,http://arxiv.org/pdf/1910.07497,
45,EXPRESSION-GUIDED EEG REPRESENTATION LEARNING FOR EMOTION RECOGNITION,,,3222-3226,"Rayatdoost Soheil,Rudrauf David,Soleymani Mohammad","Rayatdoost S,Rudrauf D,Soleymani M",Rayatdoost S,,University of Geneva,"Learning a joint and coordinated representation between different modalities can improve multimodal emotion recognition. In this paper, we propose a deep representation learning approach for emotion recognition from electroencephalogram (EEG) signals guided by facial electromyogram (EMG) and electrooculogram (EOG) signals. We recorded EEG, EMG and EOG signals from 60 participants who watched 40 short videos and self-reported their emotions. A cross-modal encoder that jointly learns the features extracted from facial and ocular expressions and EEG responses was designed and evaluated on our recorded data and MAHOB-HCI, a publicly available database. We demonstrate that the proposed representation is able to improve emotion recognition performance. We also show that the learned representation can be transferred to a different database without EMG and EOG and achieve superior performance. Methods that fuse behavioral and neural responses can be deployed in wearable emotion recognition solutions, practical in situations in which computer vision expression recognition is not feasible.","EEG signals,emotion recognition,facial expression,deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
46,LEARNING DATA REPRESENTATION AND EMOTION ASSESSMENT FROM PHYSIOLOGICAL DATA,,,3452-3456,"Joaquim Miguel S.,Macorano Rita,Canais Francisca,Ramos Rafael,Fred Ana L.,Torrado Marco,Ferreira Hugo A.","Joaquim MS,Macorano R,Canais F,Ramos R,Fred AL,Torrado M,Ferreira HA",Joaquim MS,,Universidade de Lisboa,"Aiming a deeper understanding of human emotional states, we explore deep learning techniques for the analysis of physiological data. In this work, raw two-channel pre-frontal electroencephalography and photoplethysmography signals of 25 subjects were collected using EMOTAI's headband while watching commercials. Taking as input the raw data, convolutional neural networks were used to learn data representations and classify the acquired signals according to the Positive and Negative Affect Schedule. This approach achieved promising results, with average F1-scores of 76.6% for Positive Affect and 83.3% for Negative Affect. Interpretation of the learned data representation was attempted by computing correlation values between features extracted from the raw inputs and the final classification. The features with the most significant correlations were the alpha band power, and the asymmetry and phase synchronization indexes. The extracted features seem to match the ones learnt by the neural network, hence endorsing their validity for emotional studies.","Emotions,deep learning,photoplethysmography,electroencephalography,positive and negative affect schedule",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,VALIDITY,,,
47,A PROBABILISTIC SCHEME FOR REPRESENTATION LEARNING WITH RADIAL TRANSFORM IMAGES,,,4017-4021,"Salehinejad Hojjat,Valaee Shahrokh","Salehinejad H,Valaee S",Salehinejad H,,University of Toronto,"Data representation can facilitate training of deep neural network when limited data is available. We have previously proposed the radial transform sampling method as a data representation technique for training neural networks. In this paper, a probabilistic framework to analyze radial transform is presented. To further elaborate it, performance of training deep neural networks on radial transform generated images for semantic segmentation of kidneys in abdominal computed tomography is evaluated. Our results show that the proposed representation method can achieve higher performance than other similar methods by translating a semantic segmentation problem to a classification problem when limited annotated images are available.","Deep learning,medical imaging,radial transform",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
48,A Hybrid Model for Bipolar Disorder Classification from Visual Information,,,4107-4111,"Abaei Niloufar,Al Osman Hussein","Abaei N,Al Osman H",Abaei N,10.1109/ICASSP40776.2020.9054648,University of Ottawa,"Bipolar Disorder (BD) is one of the most prevalent mental illnesses in the world. It has a negative impact on people's social and personal functions. The principal indicator of BD is the extreme swing in the mood ranging from manic to depressive states. This paper addresses the challenge of detecting the BD states by monitoring affective information extracted from video recordings of structured interviews. Our goal is to classify the condition of patients suffering from BD into the clinically significant states of remission, hypo-mania, and mania. To this end, we apply a Convolutional Neural Network (CNN) model to extract facial features from video signals. We supply the features' sequence to a Long-Short-Term Memory (LSTM) model to resolve the BD state. Our framework achieved promising results on the development set of the Turkish Audio-Visual Bipolar Disorder Corpus with the Unweighted Average Recall (UAR) of 60.67%.","Bipolar Disorder,Affective Computing,LSTM,Machine Learning,Automated Screening",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
49,AUTOMATIC EVENT DETECTION OF REM SLEEP WITHOUT ATONIA FROM POLYSOMNOGRAPHY SIGNALS USING DEEP NEURAL NETWORKS,,,4112-4116,"Wallis Phillip,Yaeger Daniel,Kain Alexander,Song Xubo,Lim Miranda","Wallis P,Yaeger D,Kain A,Song XB,Lim M",Wallis P,,Oregon Health & Science University,"Rapid eye movement (REM) sleep behavior disorder (RBD) is a sleep disorder that features loss of atonia, or REM sleep without atonia (RSWA). RBD and RSWA are early manifestations of degenerative neurological diseases such as Parkinson's and Lewy Body Dementia. Accurate diagnosis of RBD is crucial for proper treatment planning and is invaluable for early detection of these neurodegenerative diseases. The current gold standard diagnosis of RSWA is through manual visual scoring by a clinician, which is labor-intensive, costly and error-prone. We develop a novel, efficient, and objective method using deep learning to detect RSWA events from polysomnography signals using a large cohort of 692 patients. Unlike previous automated methods that generate only a binary patient diagnosis, our method detects the location and class of all RSWA events. This finer-grained analysis forms the basis for subsequent diagnosis, and allows the quantification of event duration and frequency which in turn can help quantify disease load.","Rapid eye movement sleep behavior disorder (RBD),REM sleep without atonia (RSWA),polysomnography (PSG),Machine Learning,Deep Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"BEHAVIOR,DISORDER,DELAYED,EMERGENCE,SERIES",,,
50,A DEEP LEARNING ARCHITECTURE FOR EPILEPTIC SEIZURE CLASSIFICATION BASED ON OBJECT AND ACTION RECOGNITION,,,4117-4121,"Karacsony Tamas,Loesch-Biffar Anna Mira,Vollmar Christian,Noachtar Soheyl,Silva Cunha Joao Paulo","Karacsony T,Loesch-Biffar AM,Vollmar C,Noachtar S,Cunha JPS",Cunha JPS,,INESC,"Epilepsy affects approximately 1% of the world's population. Semiology of epileptic seizures contain major clinical signs to classify epilepsy syndromes currently evaluated by epileptologists by simple visual inspection of video. There is a necessity to create automatic and semiautomatic methods for seizure detection and classification to better support patient monitoring management and diagnostic decisions. One of the current promising approaches are the marker-less computer-vision techniques. In this paper an end-to-end deep learning approach is proposed for binary classification of Frontal vs. Temporal Lobe Epilepsies based solely on seizure videos. The system utilizes infrared (IR) videos of the seizures as it is used 24/7 in hospitals' epilepsy monitoring units. The architecture employs transfer learning from large object detection ""static"" and human action recognition ""dynamic"" datasets such as ImageNet and Kinectics-400, to extract and classify the clinically known spatiotemporal features of seizures. The developed classification architecture achieves a 5-fold cross-validation f1-score of 0.844 +/- 0.042. This architecture has the potential to support physicians with diagnostic decisions and might be applied for online applications in epilepsy monitoring units. Furthermore, it may be jointly used in the near future with synchronized scene depth 3D information and EEG from the seizures.","Computer Vision,Deep learning,Action recognition,Epileptic seizure semiology,Diagnostic support",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"CONVOLUTIONAL,NEURAL-NETWORKS",,,
51,A HYBRID APPROACH FOR THERMOGRAPHIC IMAGING WITH DEEP LEARNING,,,4277-4281,"Kovacs Peter,Lehner Bernhard,Thummerer Gregor,Mayr Guenther,Burgholzer Peter,Huemer Mario","Kovacs P,Lehner B,Thummerer G,Mayr G,Burgholzer P,Huemer M",Kovacs P,,Johannes Kepler University Linz,"We propose a hybrid method for reconstructing thermographic images by combining the recently developed virtual wave concept with deep neural networks. The method can be used to detect defects inside materials in a non-destructive way. We propose two architectures along with a thorough evaluation that shows a substantial improvement compared to state-of-the-art reconstruction procedures. The virtual waves are invariant of the thermal diffusivity property of the material. Consequently, we can use extremely compact architectures that require relatively little training data, and have very fast loss convergence. As a supplement of the paper [1], we provide the MATLAB and Python implementations along with the data set comprising 40,000 simulated temperature measurement images in total, and their corresponding defect locations. Thus, the presented results are completely reproducible.","Thermography,non-destructive testing,virtual waves,deep learning,u-net",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
52,DGAN: DISENTANGLED REPRESENTATION LEARNING FOR ANISOTROPIC BRDF RECONSTRUCTION,,,4397-4401,"Hu Zhongyun,Wang Xue,Wang Qing","Hu ZY,Wang X,Wang Q",Hu ZY,,Northwestern Polytechnical University,"Accurate reconstruction of real-world materials' appearance from a very limited number of samples is still a huge challenge in computer vision and graphics. In this paper, we present a novel deep architecture, Disentangled Generative Adversarial Network (DGAN), which performs anisotropic Bidirectional Reflectance Distribution Function (BRDF) reconstruction from single BRDF subspace with the maximum entropy. In contrast to previous approaches that directly map known samples to a full BRDF using a CNN, a disentangled representation learning is applied to guide the reconstruction process. In order to learn different physical factors of the BRDF, the generator of the DGAN mainly consists of a fresnel estimator module (FEM) and a directional module (DM). Considering the fact that the entropy of different BRDF subspace varies, we further divide the BRDF into He-BRDF and Le-BRDF to reconstruct the interior part and the exterior part of the directional factor. Experimental results show that our approach outperforms state-of-the-art methods.","DGAN,disentangled representation learning,entropy,anisotropic BRDF reconstruction",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
53,IMPROVED SPEAKER INDEPENDENT DYSARTHRIA INTELLIGIBILITY CLASSIFICATION USING DEEPSPEECH POSTERIORS,,,6114-6118,"Tripathi Ayush,Bhosale Swapnil,Kopparapu Sunil Kumar","Tripathi A,Bhosale S,Kopparapu SK",Tripathi A,,"TCS Res & Innovat, Mumbai, Maharashtra, India.","Individuals with dysarthria are unable to control rapid movement of the velum leading to reduction in intelligibility, audibility, naturalness and efficiency of vocal communication. Automatic intelligibility assessment of dysarthric patients allows clinicians diagnose the impact of therapy and medication and also to plan future course of action. Earlier works have concentrated on building speaker dependent machine learning systems for intelligibility assessment, due to limited availability of data. However, a speaker independent assessment system is of greater use by clinicians. Motivated by this observation, we propose a speaker independent intelligibility assessment system which relies on a novel set of features obtained by processing the output of DeepSpeech, an end to end Speech-to-Text engine. All experiments have been performed on the Universal Access Speech database. An accuracy of 53.9% was obtained using Support Vector Machine based four-class classification system for the speaker independent scenario while the accuracy obtained for the speaker dependent scenario is 97.4%.","Dysarthria,intelligibility assessment,openSMILE,deepspeech",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
54,RECURRENT NEURAL AUDIOVISUAL WORD EMBEDDINGS FOR SYNCHRONIZED SPEECH AND REAL-TIME MRI,,,6424-6428,"Kose Oyku Deniz,Saraclar Murat","Kose OD,Saraclar M",Kose OD,,Bogazici University,"In this paper, the use of word embeddings for the segments found in audio and real-time magnetic resonance imaging (rtMRI) videos is addressed. In this study, word embeddings are created to store and retrieve data efficiently, and their representation power of the original data is evaluated by the same-different word-discrimination task that is defined for both unimodal and cross-view settings. In order to create the word embeddings for two different data modalities independently for the unimodal setting, a Siamese neural network is designed. For the rtMRI videos, inputs to the network are generated through a correspondence autoencoder. In the cross-view setting, a recurrent neural network (RNN), which inputs data of different modalities, is trained to generate embeddings jointly for both data sources. The problem of objective function selection to the RNN is also investigated. The results on the USC-TIMIT rtMRI dataset outperform the conventional dynamic time warping (DTW) baseline by a clear margin. Outcomes demonstrate that the proposed word embeddings can be a step towards faster unimodal or cross-view query-by-example search tasks.","deep learning,word embeddings,rtMRI-TIMIT,cross-modality,Siamese networks",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,,
55,"Voice based classification of patients with Amyotrophic Lateral Sclerosis, Parkinson's Disease and Healthy Controls with CNN-LSTM using transfer learning",,,6784-6788,"Mallela Jhansi,Illa Aravind,Suhas B. N.,Udupa Sathvik,Belur Yamini,Atchayaram Nalini,Yadav Ravi,Reddy Pradeep,Gope Dipanjan,Ghosh Prasanta Kumar","Mallela J,Illa A,Suhas BN,Udupa S,Belur Y,Atchayaram N,Yadav R,Reddy P,Gope D,Ghosh PK",Mallela J,,Indian Institute of Science (IISC) - Bangalore,"In this paper, we consider 2-class and 3-class classification problems for classifying patients with Amyotrophic Lateral Sclerosis (ALS), Parkinson's Disease (PD), and Healthy Controls (HC) using a CNN-LSTM network. Classification performance is examined for three different tasks, namely, Spontaneous speech (SPON), Diadochokinetic rate (DIDK) and Sustained phoneme production (PHON). Experiments are conducted using speech data recorded from 60 ALS, 60 PD, and 60 HC subjects. Classifications using SVM and DNN are considered as baseline schemes. Classification accuracy of ALS and HC (indicated by ALS/HC) using CNN-LSTM has shown an improvement of 10.40%, 4.22% and 0.08% for PHON, SPON and DIDK tasks, respectively over the best of the baseline schemes. Furthermore, the CNN-LSTM network achieves the highest PD/HC classification accuracy of 88.5% for the SPON task and the highest 3-class (ALS/PD/HC) classification accuracy of 85.24% for the DIDK task. Experiments using transfer learning at low resource training data show that data from ALS benefits PD/HC classification and vice-versa. Experiments with fine-tuning weights of 3-class (ALS/PD/HC) classifier for 2-class classification (PD/HC or ALS/HC) gives an absolute improvement of 2% classification accuracy in SPON task when compared with randomly initialized 2-class classifier.","Amyotrophic Lateral Sclerosis,Parkinson's Disease,CNN-LSTM",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"PATTERN,ALS",,,
56,JOINT LEARNING OF CARTESIAN UNDERSAMPLING AND RECONSTRUCTION FOR ACCELERATED MRI,,,8653-8657,"Weiss Tomer,Vedula Sanketh,Senouf Ortal,Michailovich Oleg,Zibulevsky Michael,Bronstein Alex","Weiss T,Vedula S,Senouf O,Michailovich O,Zibulevsky M,Bronstein A",Weiss T,,"Technion, Haifa, Israel.","Magnetic Resonance Imaging (MRI) is considered today the golden-standard modality for soft tissues. The long acquisition times, how-ever, make it more prone to motion artifacts as well as contribute to the relative high costs of this examination. Over the years, multiple studies concentrated on designing reduced measurement schemes and image reconstruction schemes for MRI, however these problems have been so far addressed separately. On the other hand, recent works in optical computational imaging have demonstrated growing success of simultaneous learning-based design of the acquisition and reconstruction schemes manifesting significant improvement in the reconstruction quality with a constrained time budget. Inspired by these successes, in this work, we propose to learn accelerated MR acquisition schemes (in the form of Cartesian trajectories) jointly with the image reconstruction operator. To this end, we propose an algorithm for training the combined acquisition-reconstruction pipeline end-to-end in a differentiable way. We demonstrate the significance of using the learned Cartesian trajectories at different speed up rates.","Magnetic Resonance Imaging (MRI),fast image acquisition,image reconstruction,deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,http://arxiv.org/pdf/1905.09324,
57,OVERCOMING HIGH NANOPORE BASECALLER ERROR RATES FOR DNA STORAGE VIA BASECALLER-DECODER INTEGRATION AND CONVOLUTIONAL CODES,,,8822-8826,"Chandak Shubham,Neu Joachim,Tatwawadi Kedar,Mardia Jay,Lau Billy,Kubit Matthew,Hulett Reyna,Griffin Peter,Wootters Mary,Weissman Tsachy","Chandak S,Neu J,Tatwawadi K,Mardia J,Lau B,Kubit M,Hulett R,Griffin P,Wootters M,Weissman T",Chandak S,,Stanford University,"As magnetization and semiconductor based storage technologies approach their limits, bio-molecules, such as DNA, have been identified as promising media for future storage systems, due to their high storage density (petabytes/gram) and long-term durability (thousands of years). Furthermore, nanopore DNA sequencing enables high-throughput sequencing using devices as small as a USB thumb drive and thus is ideally suited for DNA storage applications. Due to the high insertion/deletion error rates associated with base-called nanopore reads, current approaches rely heavily on consensus among multiple reads and thus incur very high reading costs. We propose a novel approach which overcomes the high error rates in basecalled sequences by integrating a Viterbi error correction de-coder with the basecaller, enabling the decoder to exploit the soft information available in the deep learning based basecaller pipeline. Using convolutional codes for error correction, we experimentally observed 3x lower reading costs than the state-of-the-art techniques at comparable writing costs.","DNA storage,nanopore sequencing,convolutional codes,Viterbi algorithm,basecaller-decoder integration",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,"DIGITAL,INFORMATION,ROBUST",,https://doi.org/10.1101/2019.12.20.871939,
58,JOINT OPTIMIZATION OF SAMPLING PATTERNS AND DEEP PRIORS FOR IMPROVED PARALLEL MRI,,,8901-8905,"Aggarwal Hemant K.,Jacob Mathews","Aggarwal HK,Jacob M",Aggarwal HK,,University of Iowa,"Multichannel imaging techniques are widely used in MRI to reduce the scan time. These schemes typically perform undersampled acquisition and utilize compressed-sensing based regularized reconstruction algorithms. Model-based deep learning (MoDL) frameworks are now emerging as powerful alternatives to compressed sensing, with significantly improved image quality. In this work, we investigate the impact of sampling patterns on the quality of the image recovered using the MoDL algorithm. We introduce a scheme to jointly optimize the sampling pattern and the reconstruction network parameters in MoDL for parallel MRI. The improved decoupling of the network parameters from the sampling patterns offered by the MoDL scheme translates to improved optimization and thus improved performance. Preliminary experimental results demonstrate that the proposed joint optimization framework significantly improves the image quality.","sampling,parallel MRI,deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,RECONSTRUCTION,,,
59,LEARNING SAMPLING AND MODEL-BASED SIGNAL RECOVERY FOR COMPRESSED SENSING MRI,,,8906-8910,"Huijben Iris A. M.,Veeling Bastiaan S.,van Sloun Ruud J. G.","Huijben IAM,Veeling BS,van Sloun RJG",Huijben IAM,,Eindhoven University of Technology,"Compressed sensing (CS) MRI relies on adequate under-sampling of the k-space to accelerate the acquisition without compromising image quality. Consequently, the design of optimal sampling patterns for these k-space coefficients has received significant attention, with many CS MRI methods exploiting variable-density probability distributions. Realizing that an optimal sampling pattern may depend on the downstream task (e.g. image reconstruction, segmentation, or classification), we here propose joint learning of both task-adaptive k-space sampling and a subsequent model-based proximal-gradient recovery network. The former is enabled through a probabilistic generative model that leverages the Gumbel-softmax relaxation to sample across trainable beliefs while maintaining differentiability. The proposed combination of a highly flexible sampling model and a model-based (sampling-adaptive) image reconstruction network facilitates exploration and efficient training, yielding improved MR image quality compared to other sampling baselines.","Compressed sensing,model-based deep learning,magnetic resonance imaging",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,,,https://pure.tue.nl/ws/files/173193431/Huijben.pdf,
60,SUPERVISED GRAPH REPRESENTATION LEARNING FOR MODELING THE RELATIONSHIP BETWEEN STRUCTURAL AND FUNCTIONAL BRAIN CONNECTIVITY,,,9065-9069,"Li Yang,Shafipour Rasoul,Mateos Gonzalo,Zhang Zhengwu","Li Y,Shafipour R,Mateos G,Zhang ZW",Li Y,,University of Rochester,"In this paper, we propose a supervised graph representation learning method to model the relationship between brain functional connectivity (FC) and structural connectivity (SC) through a graph encoder-decoder system. The graph convolutional network (GCN) model is leveraged in the encoder to learn lower-dimensional node representations (i.e. node embeddings) integrating information from both node attributes and network topology. In doing so, the encoder manages to capture both direct and indirect interactions between brain regions in the node embeddings which later help reconstruct empirical FC networks. From node embeddings, graph representations are learnt to embed the entire graphs into a vector space. Our end-to-end model utilizes a multi-objective loss function to simultaneously learn node representations for FC network reconstruction and graph representations for subject classification. The experiment on a large population of non-drinkers and heavy drinkers shows that our model can provide a characterization of the population pattern in the SC-FC relationship, while also learning features that capture individual uniqueness for subject classification. The identified key brain sub-networks show significant between-group difference and support the promising prospect of GCN-based graph representation learning on brain networks to model human brain activity and function.","Brain networks,graph representation learning,graph convolutional network,supervised encoder-decoder system,graph embedding,SC-FC relationship",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,ORGANIZATION,,,
61,TOWARDS AN INTELLIGENT MICROSCOPE: ADAPTIVELY LEARNED ILLUMINATION FOR OPTIMAL SAMPLE CLASSIFICATION,,,9284-9288,"Chaware Amey,Cooke Colin L.,Kim Kanghyun,Horstmeyer Roarke","Chaware A,Cooke CL,Kim K,Horstmeyer R",Chaware A,,Duke University,"Recent machine learning techniques have dramatically changed how we process digital images. However, the way in which we capture images is still largely driven by human intuition and experience. This restriction is in part due to the many available degrees of freedom that alter the image acquisition process (lens focus, exposure, filtering, etc). Here we focus on one such degree of freedom - illumination within a microscope - which can drastically alter information captured by the image sensor. We present a reinforcement learning system that adaptively explores optimal patterns to illuminate specimens for immediate classification. The agent uses a recurrent latent space to encode a large set of variably-illuminated samples and illumination patterns. We train our agent using a reward that balances classification confidence with image acquisition cost. By synthesizing knowledge over multiple snapshots, the agent can classify on the basis of all previous images with higher accuracy than from naively illuminated images, thus demonstrating a smarter way to physically capture task-specific information.","Visual Attention,Computational Imaging,Optimization,Machine Learning,Microscopy",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Acoustics,Engineering",,,DEEP,,http://arxiv.org/pdf/1910.10209,
62,Indoor Wireless Localization Using Consumer-Grade 60 GHz Equipment with Machine Learning for Intelligent Material Handling,,,316-321,"Vashist Abhishek,Bhanushali Darshan Ramesh,Relyea Robert,Hochgraf Clark,Ganguly Amlan,Manoj Sai P. D.,Ptucha Raymond,Kwasinski Andres,Kuhl Michael E.","Vashist A,Bhanushali DR,Relyea R,Hochgraf C,Ganguly A,Manoj PDS,Ptucha R,Kwasinski A,Kuhl ME",Vashist A,,Rochester Institute of Technology,Wireless indoor localization is critical for autonomous agents in modern and future smart warehouses. Millimeter-wave (mmWave) frequencies have been investigated for high-precision localization in recent years for indoor as well as outdoor positioning. We propose machine learning (ML) techniques over a radio map to estimate the location of an autonomous material handling agent used in warehouses. Based on our experimental results we demonstrate that a Multilayer Perceptron (MLP) based positioning achieves centimeter level accuracy with Root Mean Square Error (RMSE) of 0.84m. The proposed localization technique achieves up to 80% lower positioning error compared to state-of-the-art mmWave wireless localization techniques.,"Millimeter-wave,indoor localization,machine learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
63,Atrial Fibrillation Prediction Algorithm Based on Attention Model,1575,,,"Shen Mengting,Zhang Luqiao,Luo Xue,Xu Jing","Shen MT,Zhang LQ,Luo X,Xu J",Zhang LQ,10.1088/1742-6596/1575/1/012122,Chengdu University of Information Technology,"Atrial Fibrillation is a common arrhythmia. when the heart is in the state of atrial fibrillation, can not deliver enough oxygen rich blood to the body. It may be asymptomatic when AF occurs. The patient does not know that AF has occurred. If the patient is not treated in time, the consequences of AF may be fatal. The diagnosis of AF needs a doctor with rich clinical experience, because the ECG signal of AF type is similar to that of other types of heart rate, which is difficult to confirm. The purpose of this paper is to train a better model through machine learning method, to realize the automatic detection of long-term AF ECG signal, to predict AF in advance, to automatically classify, recognize and inform patients. In this way, even if the patient himself can know the physical condition in time, early treatment. Automatic prediction and diagnosis of AF by machine learning method can play a positive role in the treatment of AF, but the existing scheme is not ideal for the detection and recognition rate of AF type. This paper proposes a deep learning framework based on attention mechanism. The segmented data are sequentially input into the deep convolution neural network for feature extraction, and then input into the two-way recurrent neural network with attention layer to predict the AF signal. The accuracy of 99.1% in the existing data set is better than the existing deep learning classification algorithm, which proves the validity and feasibility of the model.","HEART,ECG",Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Computer Science,Robotics",,,"HEART,ECG",,https://doi.org/10.1088/1742-6596/1575/1/012122,
64,Hands-On Tutorial: AI Explainability 360,,,696-696,"Arya Vijay,Bellamy Rachel K. E.,Chen Pin-Yu,Dhurandhar Amit,Hind Michael,Hoffman Samuel C.,Houde Stephanie,Liao Q. Vera,Luss Ronny,Mourad Sami","Arya V,Bellamy RKE,Chen PY,Dhurandhar A,Hind M,Hoffman SC,Houde S,Liao QV,Luss R,Mourad S",Arya V,10.1145/3351095.3375667,International Business Machines (IBM),,"explainability,interpretability,transparency,taxonomy,open source",Proceedings Paper,"ASSOC COMPUTING MACHINERY, 1515 BROADWAY, NEW YORK, NY 10036-9998 USA","Computer Science,Social Sciences - Other Topics",,,,"FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY",,
65,Prediction of rate of penetration with data from adjacent well using artificial neural network,62,,517-522,"Diaz Melvin,Kim Kwang Yeom,Lee Jangguen,Shin Hyu-Seoung","Diaz M,Kim KY,Lee J,Shin HS",Diaz M,10.1007/978-981-15-2184-3_68,University of Science & Technology (UST),"We present an assessment on the predictability of the rate of penetration using artificial neural networks when only drilling records from an adjacent are at hand. The study was carried out with data from two Enhanced Geothermal System wells in South Korea. We compare five data-arrangement cases for neural network training. Differences in the specific values of parameters from the adjacent and the predicted well, such as the weight on bit, and the rotary speed influenced the prediction errors. Among the five cases, the highest error (85.3%) occurred for the case of cumulative data up to the point of prediction. However, some data-arrangements decrease the error, e.g. when employing the whole data (46.8%), or when using small data sections near prediction (case 4: 42.4%, and case 5: 39.7%). We suggest the combination of these last tree approaches when prediction ROP with limited data.","ROP prediction,EGS,drilling,adjacent well,ANN",Proceedings Paper,"SPRINGER-VERLAG SINGAPORE PTE LTD, 152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE",Engineering,,,,,,
66,Machine learning scheme of the degree of liquefaction assessment only from the health monitoring device installed in individual wooden house,62,,1099-1105,"Kurihara Go,Kamura Akiyoshi,Mori Tomohiro","Kurihara G,Kamura A,Mori T",Kurihara G,10.1007/978-981-15-2184-3_143,Tohoku University,"Health monitoring devices have been developing in order to estimate the damage to house and foundation ground subjected to an earthquake, in japan. However, the devices cannot estimate the degree of liquefaction because it focuses only on evaluation for damage index of wooden house. In this study, an attempt was made to estimate the degree of ground liquefaction only from the health monitoring device. Concretely, using ""GAINET"", a health monitoring device developed by a house builder, is placed on the ground surface of the soil container, and the output data such as acceleration response, damage degree of structure and the pore water pressure in the ground were measured as machine learning data by applying several 3D seismic motions. In this research, a machine learning scheme evaluating the classification of liquefaction damage degree is introduced and the possibility to evaluate the liquefaction damage only from the output data obtained from health monitoring device is shown.","Damage evaluation,Seismic motion,Liquefaction",Proceedings Paper,"SPRINGER-VERLAG SINGAPORE PTE LTD, 152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE",Engineering,,,,,,
67,Deep Learning for Analyzing Thyroid Nodule Malignancy Based on the Composition Characteristic of the Ultrasonography Images,,,77-81,"Nugroho Hanung Adi,Frannita Eka Legya,Hutami Augustine Henni Tita,Chondah Lina,Nugroho Anan,Fauzi Rizki Nur,Setiawan Nurhuda Hendra","Nugroho HA,Frannita EL,Hutami AHT,Chondah L,Nugroho A,Fauzi RN,Setiawan NH",Nugroho HA,,Gadjah Mada University,"There are ten characteristics of ultrasound thyroid nodules, and each one has its categories. One particular characteristic is composition characteristic, as the occurrence of its categories can be one of the lead to the incidence of malignancy. This study developed a method to help experts identifying the categories of the composition ultrasound characteristic using data collected from the Department of Radiology RSUP Dr. Sardjito. This dataset was already cropped by the experts, leaving only the thyroid nodule area as the region of interest. The dataset of ultrasound images was going to pre-processing first to remove the labels, markers, and unnecessary artifacts. To further remove any unnecessary artifacts, the pre-processed image was segmented. Afterward, the data augmentation begins using the synthetic minority over-sampling technique (SMOTE). The augmentation result was sent to LeNet to be classified into three categories those are cystic, solid, and complex. The testing result outperformed previous studies with 92% accuracy, 85.71% sensitivity, 92.50% specfficity, 93.5S% PPV, 95.09% NPV, 0.918 F Score, and 146. 4s testing time.","Composition characteristics,deep learning,LeNet,synthetic minority over-sampling technique (SMOTE),thyroid nodules",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,ULTRASOUND,,,
68,Melanoma Skin Cancer Detection Using Deep Learning and Advanced Regularizer,,,89-94,"Hossin Md Arman,Rupom Farhan Fuad,Mahi Hasibur Rashid,Sarker Anik,Ahsan Farshid,Warech Sadman","Hossin MA,Rupom FF,Mahi HR,Sarker A,Ahsan F,Warech S",Hossin MA,,Bangladesh Rural Advancement Committee BRAC,"Melanoma cancer Detection System is a predictive model that dynamically anticipates melanoma skin cancer by evaluating dermoscopic images with the help of deep learning. The fundamental goals behind this research are to identify skin cancer at early stages by achieving swift results With greater accuracy. The reason behind the goal signifies the problem of increment in skin cancer patients Worldwide, high medical costs and exponential increment of death risk for not starting the diagnosis at early stages which is a result of late detection. Our presented research work proposes a solution to the problem of higher medical costs behind diagnosis, lower accuracy rate in detection and portability problem of the manual detection system. In this system, dermoscopic images are classified to predict skin cancer using a multi-layered CNN approach with multiple regularization techniques named dropout and batch normalization. As a result, our system has provided an accuracy of 93.58% which is higher than most other conventional approaches.","Convolutional Neural Network,skin cancer,regularization",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
69,Automated prediction of Coronary Artery Disease using Random Forest and Naive Bayes,,,109-113,"Alotaibi Sarah Saud,Almajid Yasmeen Ahmed,Alsahali Samar Fahad,Asalam Nida,Alotaibi Maha Dhawi,Ullah Irfan,Altabee Rahaf Mohammed","Alotaibi SS,Almajid YA,Alsahali SF,Asalam N,Alotaibi MD,Ullah I,Altabee RM",Alotaibi SS,,Imam Abdulrahman Bin Faisal University,"In recent days, the world is suffering from Coronary Heart Diseases. It has become a widely spread disease. CAD have a strong side effects, which might cause physical symptoms and family burdens. Other physical symptoms might increase the patients' rate of death in the general population. Therefore, the study focused on developing predictive model for the diagnosis of CAD. The model was developed using computational machine learning techniques that incorporate Random Forest (RF), and Naive Bayes (NB) techniques. The study will use an open source dataset named Z-Alizadeh sani, which will assist in the diagnostic process. Naive Bayes outperformed the other studies in literature review with 100% sensitivity and Negative predictive rate of 100%. Naive Bayes outperformed when compared with Random Forest with an accuracy of 83% with 13 features. The achieved results are encouraging to use the built models as supportive software in the diagnosing process.","Coronary Artery Disease,machine-learning,Random Forest (RF),Naive Bayes (NB),Feature selection,Classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
70,Deep Learning for Roasting Coffee Bean Quality Assessment Using Computer Vision in Mobile Environment,,,363-369,"Hakim Muslih,Djatna Taufik,Yuliasih Indah","Hakim M,Djatna T,Yuliasih I",Hakim M,,Bogor Agricultural University,"Coffee industries need to maintain their product's flavour and characteristics in order to retain the product's brand and image in the market. Flavour and coffee quality during brewing is closely related to its unique roasting degree. Thus, a stable, standardized, coffee roasting degree throughout the production stages are required. In this paper, we propose a quality assessment system driven by deep learning to help monitoring the roasting process remotely and accurately and to predict the roasting degree of coffee bean A proposed deep learning-based solution for coffee roasting quality assessment is embedded into android smartphones for on-demand portable usage and support for classification insight on roasting degree The experiment initially prepared coffee roasting process dataset consisted of three classes. The results reveal that MobileNetV2 is best suited to use for roasting quality classification. Best inference time ranged between 44-50 ms using CPU and 34-44 using GPU using selected android smartphones It indicated that real-time monitoring during on-demand quality assessment in MobileNetV2 model achieved 97,75% accuracy, 96,44% recall, and 96,33% Precision on average.","Deep learning,Computer Vision,Mobile Environment,Coffee Roasting",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
71,Multiclass classification of initial stages of Alzheimer's Disease through Neuroimaging modalities and Convolutional Neural Networks,,,51-56,"Bin Tufail Ahsan,Ma Yongkui,Mang Qiu-Na","Bin Tufail A,Ma YK,Mang QN",Ma YK,,Harbin Institute of Technology,"Alzheimer's Disease (AD) is the most common form of dementia that causes memory related brain changes which impair the thinking patterns of its subjects. Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET) are widely used modalities to capture the structural changes in the brain caused by AD in its early stages. Early diagnosis of AD is important from clinical perspective to improve the life of an individual who is at the risk of developing memory deficits. Deep learning architectures such as 2D and 3D Convolutional Neural Networks (CNNs) have shown promising performances in extracting features and building useful representations of data for computer vision tasks. This study is geared towards understanding the performance differences between these architectures. We used transfer and non-transfer learning approaches to study the underlying disease phenomenon. In our experiments on three class classification of early stages of AD, we found the performance of 3D architectures to be better in comparison to their 2D counterparts. We found the performance of 3D architecture trained on PET neuroimaging modality data to be the best in terms of performance metrics which shows superior diagnostic power of this type of architecture.","Convolutional Neural Networks,Multiclass Classification,Mild Cognitive Impairment,Alzheimer's Disease,Magnetic Resonance Imaging,Positron Emission Tomography",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Automation & Control Systems,Engineering",,,,PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020),,
72,Analysis and Test of Concrete Surface Crack of Railway Bridge Based On Deep Learning,,,437-442,"Gong XingQi,Li Quan,Zhou MeiLing,Jiang HuiFeng","Gong XQ,Li Q,Zhou ML,Jiang HF",Gong XQ,,"China Acad Railway Sci Corp Ltd, Beijing, Peoples R China.","In recent years, the construction of high-speed railway In China is large-scale and efficient.And the safety detection and monitoring of Bridges has become an important part of accounting the safety of railway operation.The characteristics of bridge surface cracks in the previous operating environment are analyzed, and YoloV3 deep learning network is used to enhance,mark and learn the crack images. The high precision identification of bridge surface cracks is realized, Some shortcomings of this method are also analyzed and the way to upgrade in the next step is put forward.","bridge cracks,deep learning,YoloV3",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Automation & Control Systems,Engineering",,,,PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020),,
73,Defect Detection Method For Steel Based On Semantic Segmentation,,,975-979,"Zhou Guanhao,Sun Haiyang","Zhou G,Sun HY",Zhou G,,Nanjing University,"The traditional methods used to detect defects in steel have always had many problems, such as long time consuming, causing a certain degree of damage to the surface of steel, and consuming more human resources. With the development of deep learning, theoretically, through semantic segmentation and image classification technology, deep neural network can be used to detect whether there are defects in steel, the categories of defects contained, and the locations of the defects, thereby solving the problems of traditional detection methods. The problem is destructive and time-consuming. Most recent researches on related aspects are mostly experiments with small data sets and small samples, and have achieved good performance. In this large-scale data set, based on the structure used by U-Net, the new network design is newly designed. For PSD U-Net, the model uses hole convolution and HDC design instead of the original convolution layer to preserve the picture details to the greatest extent under the premise of expanding the receptive field. The parametric sigmoid norm (PSN) layer is superimposed on the feature extraction network to further Improve recognition rate. Finally, the paper is based on three networks, U-Net, Mask R-CNN and PSD U-Net, and continuously transforms the feature extraction network for experiments. The results show that the PSD U-Net architecture and the network with superimposed PSN layers have better results for the rest of the isometric models.","Semantic segmentation,Parameterization,Convolutional Neural Network,U-Net",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Automation & Control Systems,Engineering",,,,PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020),,
74,Automatic Atrial Fibrillation Detection Based on Deep Learning Model with Shortcut Connection,,,1075-1079,"Ping Yongjie,Chen Chao,Wu Lu,Shu Minglei","Ping YJ,Chen C,Wu L,Shu ML",Ping YJ,,Shandong University of Science & Technology,"Atrial fibrillation (AF) is one of the most common persistent arrhythmias, and many deaths are caused by AF every year. In this paper, a combination of 8-layer Convolutional Neural Network (CNN) with shortcut connection and 1-layer Long Short-Term Memory (LSTM), named 8CSL, is proposed for the ECG classification task. 8CSL can not only extracts feature skillfully, but also deals with long-term dependence between data. Especially, 8CSL includes eight shortcut connections which can improve speed of the data transmission and processing because of the shortcut connections. Overall, our model achieved accuracy, sensitivity, specificity, precision and F1 score as of 85.06%, 87.42%, 91.37%, 91.78% and 89.55%.","Atrial fibrillation (AF),Convolutional Neural Network (CNN),Long Short-Term Memory (LSTM),Shortcut connection",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Automation & Control Systems,Engineering",,,,PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020),,
75,Design of a Sleep Assistance System Terminalm,,,1586-1589,Lu Yingjian,Lu YJ,Lu YJ,,Wuhan University of Technology,"In this paper, a new type of sleep assist system terminal is proposed. The terminal is a wearable front end in a 'machine learning-based sleep assist system', and is mainly composed of a sleep assist module, an ARM core control board, a WIFI module, a brain wave signal acquisition front end, and a power module. The design of the wearable front end proposed in this article innovatively uses bone conduction oscillators to play white noise and pink noise to aid sleep, and uses LED strips to gently wake up. After practical design, production and testing, the wearable front end proposed in this article can assist people with sleep disorders to better sleep. At the same time, the wearing front has been recognized by actual users and professional physicians, and has certain application value and promotion prospects.","Sleep assistance system,wear front,closed loop,EEG",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Automation & Control Systems,Engineering",,,,PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020),,
76,Recognition of Assembly Instructions Based on Geometric Feature and Text Recognition,,,139-143,"Park Jaewoo,Kang Isaac,Kwon Junhyeong,Lee Eunji,Kim Yoonsik,You Sujeong,Ji Sang Hoon,Cho Nam-ik","Park J,Kang I,Kwon J,Lee E,Kim Y,You S,Ji SH,Cho NI",Cho NI,,Seoul National University (SNU),"Recent advances in machine learning methods have increased the performances of object detection and recognition systems. Accordingly, automatic understanding of assembly instructions in manuals in the form of electronic or paper materials has also become an issue in the research community. This task is quite challenging because it requires the automatic optical character recognition (OCR) and also the understanding of various mechanical parts and diverse assembly illustrations that are sometimes difficult to understand even for humans. Although deep networks are showing high performance in many computer vision tasks, it is still difficult to perform this task by an end-to-end deep neural network due to the lack of training data, and also because of diversity and ambiguity of illustrative instructions. Hence, in this paper, we propose to tackle this problem by using both conventional non-learning approaches and deep neural networks, considering the current state-of-the-arts. Precisely, we first extract components having strict geometric structures, such as characters and illustrations, by conventional non-learning algorithms, and then apply deep neural networks to recognize the extracted components. The main targets considered in this paper are the types and the numbers of connectors, and behavioral indicators such as circles, rectangles, and arrows for each cut in do-it-yourself (DIY) furniture assembly manuals. For these limited targets, we train a deep neural network to recognize them with high precision. Experiments show that our method works robustly in various types of furniture assembly instructions.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Robotics",,,,,,
77,A CNN-LSTM Hybrid Model for Ankle Joint Motion Recognition Method Based on sEMG,,,339-344,"Cheng Hao-Ran,Cao Guang-Zhong,Li Cai-Hong,Zhu Aibin,Zhang Xiaodong","Cheng HR,Cao GZ,Li CH,Zhu AB,Zhang XD",Cao GZ,,Shenzhen University,"A CNN-LSTM hybrid model for ankle joint motion recognition based on surface electromyography (sEMG) signals is proposed in this paper. The traditional recognition method is to manually extract the features from sEMG signals and then use machine learning method to train the model, which relies on prior knowledge and requires a lot of time to test and select good features to obtain high classification accuracy. In this paper, the CNN-LSTM hybrid model is used to identify four ankle joint movements (dorsiflexion, plantar flexion, foot varus and foot eversion). The hybrid model consists of two CNN layers and three LSTM layers. CNN can learn to automatically extract features and LSTM is able to capture long-term correlations of sEMG data. The experiment results show that the proposed model is effective and accurate, thus providing a basis for the subsequent research.","CNN-LSTM,motion recognition,surface electromyography",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Engineering,Robotics",,,,,,
78,BP-ANN model to optimize the structural parameter setting of transfer point,510,,,"Shi Guixin,Xing Futang,HuangYue,Wang Xiaogang","Shi GX,Xing FT,HuangYue,Wang XG",Shi GX,10.1088/1755-1315/510/4/042012,Wuhan University of Science & Technology,"In order to optimize the structural parameter setting at the transfer point, the principle of CFD-DEM coupling is used to simulate the production conditions of the material mass flow rate: 150kg/s, height difference: 3m, material density: 1400kg/cm(3), and the operation of different structural parameter settings at the transfer point. Based on the pumping volume, equipment wear degree and dust concentration in the exhaust pipe, the weight coefficients of the three indicators given by the comprehensive analytic hierarchy process and the CRITIC method are 0.49, 0.32 and 0.16 respectively, and then the structure parameter settings obtained by the orthogonal test are simulated and optimized by using the BP neural network model. The optimized parameters of orthogonal test are the chute angle of 45 degrees, the number of suction ports of 3, the belt speed of 1.5m/s and bandwidth of 1000mm; the optimized parameters of BP neural network model simulation are chute angle of 45.53 degrees, the number of suction ports of 2.86, the belt speed of 1.48m/s and the bandwidth of 996mm. The results show that the BP-ANN model has the advantages of simplification, high efficiency and time saving, and can provide a new method for enterprises to set the structural parameters at the transfer points reasonably according to their own production conditions.",,Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Energy & Fuels,Environmental Sciences & Ecology",,,,,https://doi.org/10.1088/1755-1315/510/4/042012,
79,CT Image Super Resolution Based on Improved SRGAN,,,363-367,"Jiang Xuhao,Xu Yifei,Wei Pingping,Zhou Zhuming","Jiang XH,Xu YF,Wei PP,Zhou ZM",Xu YF,,Xi'an Jiaotong University,"CT images are commonly used in medical clinical diagnosis. However, due to factors such as hardware and scanning time, CT images in real scenes are limited by spatial resolution so that doctors cannot perform accurate disease analysis on tiny lesion areas and pathological features. An image super-resolution (SR) method based on deep learning is a good way to solve this problem. Although many excellent networks have been proposed, but they all pay more attention to image quality indicators than image visual perception quality. Unlike other networks that focus more on image evaluation metrics, the super resolution generative adversarial network (SRGAN) has achieved tremendous improvements in image perception quality. Based on the above, this paper proposes a CT image super-resolution algorithm based on improved SRGAN. In order to improve the visual quality of CT images, a dilated convolution module is introduced. At the same time, in order to improve the overall visual effect of the image, the mean structural similarity (MSSIM) loss is also introduced to improve the perceptual loss function. Experimental results on the public CT image dataset demonstrate that our model is better than the baseline method SRGAN not only in mean opinion score(MOS), but also in peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) values.","super-resolution,deep learning,generative adversarial network,medical image reconstruction,SRGAN",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Telecommunications",,,,2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2020),,
80,Geometric Artifact Evaluation of X-ray Computed Tomography Images Based on Convolutional Neural Network,,,391-394,"Zhu Mingwan,Thu Linlin,Han Yu,Xi Xiaoqi,Li Lei,Yan Bin","Zhu MW,Thu LL,Han Y,Xi XQ,Li L,Yan B",Zhu MW,,"PLA Strateg Support Force Informat Engn Univ, Zhengzhou, Henan, Peoples R China.","Computed Tomography (CT) has been used in many fields. Practical misalignment of the actual CT system causes geometric artifacts in the reconstructed images, which severely degrades image quality. Geometric artifact evaluation provides a reliable basis for subsequent geometric artifact correction. Some characteristics of images, such as entropy and sharpness, are often used to measure the severity of geometric artifacts, but they are limited in generality and accuracy. Convolutional neural network (CNN) has excellent image feature learning capabilities and is well used in image processing. This paper explores the network structure suitable for the evaluation of geometric artifacts in CT images. We select three commonly used networks LeNet-5, VGG16 and AlexNet. The datasets of three kinds of phantoms are constructed using simulation and actual scanning results. The three networks are trained and tested separately on the three kinds of datasets. Experimental results show that all three CNN models can evaluate the existence of geometric artifacts in CT images. The AlexNet network achieves the best classification evaluation performance with an average classification accuracy of 0.961, with the smallest average loss and the shortest training time.","geometric artifact,convolutional neural network,geometric artifact evaluation",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Telecommunications",,,,2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2020),,
81,Packaging Defect Detection System Based on Machine Vision and Deep Learning,,,404-408,"Sa Jiming,Li Zhihao,Yang Qijun,Chen Xuan","Sa JM,Li ZH,Yang QJ,Chen X",Li ZH,,Wuhan University of Technology,"Detecting packaging defection with high accuracy and efficiency is of great significance in product quality. We use OpenCV to preprocess images which come from damaged package according to characteristics of the image. The processed data is combined with deep learning and based on neural network model ResNet. Meanwhile the processed image data is sent to a convolutional neural network (CNN) for model training. We establish a detection system for product packaging. The detection system provides a solution for automatic detection of package defection, which realizes rapid and accurate detection of product packaging.","packaging defection detection,image preprocessing,convolution neural network,TensorRT,ResNet,Keras",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Computer Science,Telecommunications",,,,2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2020),,
82,Classification of EEG Signals Based on Image Representation of Statistical Features,1043,,449-460,"Ashford Jodie,Bird Jordan J.,Campelo Felipe,Faria Diego R.","Ashford J,Bird JJ,Campelo F,Faria DR",Bird JJ,10.1007/978-3-030-29933-0_37,Aston University,"This work presents an image classification approach to EEG brainwave classification. The proposed method is based on the representation of temporal and statistical features as a 2D image, which is then classified using a deep Convolutional Neural Network. A three-class mental state problem is investigated, in which subjects experience either relaxation, concentration, or neutral states. Using publicly available EEG data from a Muse Electroencephalography headband, a large number of features describing the wave are extracted, and subsequently reduced to 256 based on the Information Gain measure. These 256 features are then normalised and reshaped into a 16 x 16 grid, which can be expressed as a grayscale image. A deep Convolutional Neural Network is then trained on this data in order to classify the mental state of subjects. The proposed method obtained an out-of-sample classification accuracy of 89.38%, which is competitive with the 87.16% of the current best method from a previous work.","Machine learning,Convolutional neural networks,Image recognition,Mental state classification,Electroencephalography",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Automation & Control Systems,Computer Science",,,,,,
83,The Application of Text Categorization Technology in Adaptive Learning System for Interpretation of Figures,1063,,130-138,"Huang Weibo,He Zhenpeng,Li Xiaodan","Huang WB,He ZP,Li XD",Huang WB,10.1007/978-3-030-31967-0_15,Guangdong University of Foreign Studies,"With the deepening of globalization and the increasing amount of information in international communication, requirements for accuracy in interpretation of figures are more demanding. Training methods in interpretation of figures, however, are not efficient enough for interpreters to cope with the challenges. They still make mistakes in interpretation of large integers, fractions and percentages. The types of errors include omission, syntactic error and lexical error. In this paper, machine learning based text categorization technology is used to accurately categorize a large number of texts and provide high-quality training materials for interpreters. Results show that training the interpreters with categorized texts has greatly improved the accuracy, familiarity and sensitivity in interpretation of figures. In the era of artificial intelligence, problems in interpretation also need to be solved by artificial intelligence. In the future, a large number of artificial intelligence technologies similar to machine-learning-based text categorization technology will be inevitably adopted in the field of interpretation.","Machine learning,Text categorization,Interpretation,Interpretation of figures,Adaptive learning system",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Automation & Control Systems,Computer Science",,,,,,
84,Signal identification system for developing rehabilitative device using deep learning algorithms,102,,,"Tang Wenping,Wang Aiqun,Ramkumar S.,Nair Radeep Krishna Radhakrishnan","Tang WP,Wang AQ,Ramkumar S,Nair RKR",Wang AQ,10.1016/j.artmed.2019.101755,Jilin University,"Paralyzed patients were increasing day by day. Some of the neurodegenerative diseases like amyotrophic lateral sclerosis, Brainstem Leison, Stupor and Muscular dystrophy affect the muscle movements in the body. The affected persons were unable to migrate. To overcome from their problem they need some assistive technology with the help of bio signals. Electrooculogram (EOG) based Human Computer Interaction (HCI) is one of the technique used in recent days to overcome such problem. In this paper we clearly check the possibilities of creating nine states HCI by our proposed method. Signals were captured through five electrodes placed on the subjects face around the eyes. These signals were amplified with ADT26 bio amplifier, filtered with notch filter, and processed with reference power and band power techniques to extract features to detect the eye movements and mapped with Time Delay Neural Network to classify the eye movements to generate control signal to control external hardware devices. Our experimental study reports that maximum average classification of 91.09% for reference power feature and 91.55%-for band power feature respectively. The obtained result confirms that band power features with TDNN network models shows better performance than reference features for all subjects. From this outcome we conclude that band power features with TDNN network models was more suitable for classifying the eleven difference eye movements for individual subjects. To validate the result obtained from this method we categorize the subjects in age wise to check the accuracy of the system. Single trail analysis was conducted in offline to identify the recognizing accuracy of the proposed system. The result summarize that band power features with TDNN network models exceed the reference power with TDNN network model used in this study. Through the outcome we conclude that that band power features with TDNN network was more suitable for designing EOG based HCI in offline mode.","Elecctrooculograpy,Human computer interface,Time delay neural network,Amyotrophic lateral sclerosis,Spinal card injury",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Medical Informatics",,5.602,"ELECTROOCULOGRAM,SIGNALS",ARTIFICIAL INTELLIGENCE IN MEDICINE,,
85,Electroencephalogram based communication system for locked in state person using mentally spelled tasks with optimized network model,102,,,"Xu Xiaoxiao,Bin Luo,Ramkumar S.,Saravanan S.,Balaji M. Sundar Prakash,Dhanasekaran S.,Thimmiaraja J.","Xu XX,Bin L,Ramkumar S,Saravanan S,Balaji MSP,Dhanasekaran S,Thimmiaraja J",Xu XX,10.1016/j.artmed.2019.101766,Wuhan University of Technology,"Due to growth in population, Individual persons with disabilities are increasing daily. To overcome the disability especially in Locked in State (LIS) due to Spinal Cord Injury (SCI), we planned to design four states moving robot from four imagery tasks signals acquired from three electrode systems by placing the electrodes in three positions namely T1, T3 and FP1. At the time of the study we extract the features from Continuous Wavelet Transform (CWT) and trained with Optimized Neural Network model to analyze the features. The proposed network model showed the highest performances with an accuracy of 93.86 % then that of conventional network model. To confirm the performances we conduct offline test. The offline test also proved that new network model recognizing accuracy was higher than the conventional network model with recognizing accuracy of 97.50 %. To verify our result we conducted Information Transfer Rate (ITR), from this analysis we concluded that optimized network model outperforms the other network models like conventional ordinary Feed Forward Neural Network, Time Delay Neural Network and Elman Neural Networks with an accuracy of 21.67 bits per sec. By analyzing classification performances, recognizing accuracy and Information Transformation Rate (ITR), we concluded that CWT features with optimized neural network model performances were comparably greater than that of normal or conventional neural network model and also the study proved that performances of male subjects was appreciated compared to female subjects.","Locked in state,Continuous Wavelet Transform,Spinal Cord Injury,Information Transfer Rate,Brain Computer Interface,Whale Optimization Algorithm,Electroencephalogram",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Medical Informatics",,5.602,"MOTOR,IMAGERY,CLASSIFICATION",ARTIFICIAL INTELLIGENCE IN MEDICINE,,
86,Limited One-time Sampling Irregularity Map (LOTS-IM) for Automatic Unsupervised Assessment of White Matter Hyperintensities and Multiple Sclerosis Lesions in Structural Brain Magnetic Resonance Images,79,,,"Rachmadi Muhammad Febrian,Valdes-Hernandez Maria Del C.,Li Hongwei,Guerrero Ricardo,Meijboom Rozanna,Wiseman Stewart,Waldman Adam,Zhang Jianguo,Rueckert Daniel,Wardlaw Joanna","Rachmadi MF,Valdes-Hernandez MD,Li Hw,Guerrero R,Meijboom R,Wiseman S,Waldman A,Zhang JG,Rueckert D,Wardlaw J",Rachmadi MF,10.1016/j.compmedimag.2019.101685,University of Edinburgh,"We present the application of limited one-time sampling irregularity map (LOTS-IM): a fully automatic unsupervised approach to extract brain tissue irregularities in magnetic resonance images (MRI), for quantitatively assessing white matter hyperintensities (WMH) of presumed vascular origin, and multiple sclerosis (MS) lesions and their progression. LOTS-IM generates an irregularity map (IM) that represents all voxels as irregularity values with respect to the ones considered ""normal"". Unlike probability values, IM represents both regular and irregular regions in the brain based on the original MRI's texture information. We evaluated and compared the use of IM for WMH and MS lesions segmentation on T2-FLAIR MRI with the state-of-the-art unsupervised lesions' segmentation method, Lesion Growth Algorithm from the public toolbox Lesion Segmentation Toolbox (LST-LGA), with several well established conventional supervised machine learning schemes and with state-of-the-art supervised deep learning methods for WMH segmentation. In our experiments, LOTS-IM outperformed unsupervised method LST-LGA on WMH segmentation, both in performance and processing speed, thanks to the limited one-time sampling scheme and its implementation on GPU. Our method also outperformed supervised conventional machine learning algorithms (i.e., support vector machine (SVM) and random forest (RF)) and deep learning algorithms (i.e., deep Boltzmann machine (DBM) and convolutional encoder network (CEN)), while yielding comparable results to the convolutional neural network schemes that rank top of the algorithms developed up to date for this purpose (i.e., UResNet and UNet). LOTS-IM also performed well on MS lesions segmentation, performing similar to LST-LGA. On the other hand, the high sensitivity of IM on depicting signal change deems suitable for assessing MS progression, although care must be taken with signal changes not reflective of a true pathology. (C) 2019 Elsevier Ltd. All rights reserved.","White matter hyperintensities (WMH),Multiple sclerosis (MS) lesion,unsupervised lesion segmentation,irregularity map,penumbra of brain's lesion,characterisation of WMH and MS lesions",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,4.295,"SEGMENTATION,ASSOCIATION,PROGRESSION,NETWORKS,DISEASE,VOLUME,DAMAGE,SCALE,MRI",COMPUTERIZED MEDICAL IMAGING AND GRAPHICS,https://www.biorxiv.org/content/biorxiv/early/2019/05/14/334292.full.pdf,
87,Autodetect extracranial and intracranial artery stenosis by machine learning using ultrasound,116,,,"Hsu Kai-Cheng,Lin Ching-Heng,Johnson Kory R.,Liu Chi-Hung,Chang Ting-Yu,Huang Kuo-Lun,Fann Yang-Cheng,Lee Tsong-Hai","Hsu KC,Lin CH,Johnson KR,Liu CH,Chang TY,Huang KL,Fann YC,Lee TH",Lee TH,10.1016/j.compbiomed.2019.103569,Chang Gung University,"Background: and Purpose: This study proposed a machine learning method for identifying >= 50% stenosis of the extracranial and intracranial arteries.
Patients and methods: A total of 8211 patients with both carotid ultrasound and cerebral angiography were enrolled. Support vector machine (SVM) was employed as the machine learning classifier. Carotid Doppler parameters and transcranial Doppler parameters were used as the input features. Feature selection was performed using the Extra-Trees (extremely randomized trees) method.
Results: For the machine learning method, the sensitivities and specificities of identifying stenosis of the extracranial arteries were 88.5%-100% and 96.0%-100%, respectively. The sensitivities and specificities of identifying stenosis of the intracranial arteries were 71.7%-100% and 88.9%-100%, respectively.
Conclusions: The SVM classifier with feature selection is an efficient method for identifying the stenosis of both intracranial and extracranial arteries. Comparing with traditional Doppler criteria, this machine learning method achieves up to 20% higher in accuracy and 45% in sensitivity, respectively.","Carotid ultrasound,Angiography,Machine learning,Intracranial artery stenosis",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"CAROTID-ARTERY,BLOOD-FLOW,CEREBRAL-ANGIOGRAPHY,MR-ANGIOGRAPHY,CT-ANGIOGRAPHY,DOPPLER,DIAGNOSIS,CRITERIA,DISEASE,DIAMETER",COMPUTERS IN BIOLOGY AND MEDICINE,,
88,The impact of patient clinical information on automated skin cancer detection,116,,,"Pacheco Andre G. C.,Krohling Renato A.","Pacheco AGC,Krohling RA",Pacheco AGC,10.1016/j.compbiomed.2019.103545,Universidade Federal do Espirito Santo,"Skin cancer is one of the most common types of cancer worldwide. Over the past few years, different approaches have been proposed to deal with automated skin cancer detection. Nonetheless, most of them are based only on dermoscopic images and do not take into account the patient clinical information, an important clue towards clinical diagnosis. In this work, we present an approach to fill this gap. First, we introduce a new dataset composed of clinical images, collected using smartphones, and clinical data related to the patient. Next, we propose a straightforward method that includes an aggregation mechanism in well-known deep learning models to combine features from images and clinical data. Last, we carry out experiments to compare the models' performance with and without using this mechanism. The results present an improvement of approximately 7% in balanced accuracy when the aggregation method is applied. Overall, the impact of clinical data on models' performance is significant and shows the importance of including these features on automated skin cancer detection.","Skin cancer detection,Deep learning,Data aggregation,Clinical images,Clinical information",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"CONVOLUTIONAL,NEURAL-NETWORKS,IMAGE,CLASSIFICATION,MELANOMA,DIAGNOSIS,DERMOSCOPY,DISCRIMINATION,ACCURACY,FEATURES,LESIONS",COMPUTERS IN BIOLOGY AND MEDICINE,http://arxiv.org/pdf/1909.12912,
89,Sensor-based detection of abnormal events for elderly people using deep belief networks,33,1,36-47,"Huang Yo-Ping,Basanta Haobijam,Kuo Hung-Chou,Chiao Hsin-Ta","Huang YP,Basanta H,Kuo HC,Chiao HT",Huang YP,10.1504/IJAHUC.2020.104714,National Taipei University of Technology,"Various technological developments in home-care systems have allowed elderly people to live independently without compromising their safety. A pilot study employing deep learning algorithm was conducted to study the daily routines of elderly people. We monitored unsupervised, diverse daily activities of elderly people such as household chores, sleeping, cooking, cleaning, using the bathroom, watching television, and meditating. The activities were monitored to track human-environment interactions by using motion sensors, actuators, and surveillance systems that were mounted inside living rooms, bedrooms, and kitchens and on bathroom doorways to detect safety hazards in the environment for elderly people. Such collected data were used in deep belief networks to ascertain and identify activities that are related to various health and self-care problems. Simulation results show that the proposed system outperforms the support vector machines in terms of F1 score and accuracy in identifying daily activities.","sensors,deep belief network,DBN,daily activities,abnormal events",Article,"INDERSCIENCE ENTERPRISES LTD, WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 856, CH-1215 GENEVA, SWITZERLAND","Computer Science,Telecommunications",,0.613,"ACTIVITY,RECOGNITION,HEALTH-CARE,SMARTPHONE,ALGORITHM",INTERNATIONAL JOURNAL OF AD HOC AND UBIQUITOUS COMPUTING,,
90,Lower-Limb Rehabilitation at Home: A Survey on Exercise Assessment and Initial Study on Exercise State Identification Toward Biofeedback,12,1,15-27,"Yean Seanglidet,Lee Bu Sung,Yeo Chai Kiat","Yean S,Lee BS,Yeo CK",Yean S,10.4018/IJITN.2020010102,Nanyang Technological University & National Institute of Education (NIE) Singapore,"Aging causes loss of muscle strength, especially on the lower limbs, resulting in a higher risk of injuries during functional activities. To regain mobility and strength from injuries, physiotherapy prescribes rehabilitation exercise to assist the patients' recovery. In this article, the authors survey the existing work in exercise assessment and state identification which contributes to innovating the biofeedback for patient home guidance. The initial study on a machine-learning-based model is proposed to identify the 4-state motion of rehabilitation exercise using wearable sensors on the lower limbs. The study analyses the impact of the feature extracted from the sensor signals while classifying using the linear kernel of the support vector machine method. The evaluation results show that the method has an average accuracy of 95.83% using the raw sensor signal, which has more impact than the sensor fused Euler and joint angles in the state prediction model. This study will both enable real-time biofeedback and provide complementary support to clinical assessment and performance tracking.","Euler Angle,Feature Engineering,MEMS,Rehabilitation Exercise Assessment,Supervised Learning,Wearable Sensor",Article,"IGI GLOBAL, 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA",Telecommunications,,,"HUMAN,MOTION,FEEDBACK",INTERNATIONAL JOURNAL OF INTERDISCIPLINARY TELECOMMUNICATIONS AND NETWORKING,,
91,Competitive Learning in a Spiking Neural Network: Towards an Intelligent Pattern Classifier,20,2,,"Lobov Sergey A.,Chernyshov Andrey V.,Krilova Nadia P.,Shamshin Maxim O.,Kazantsev Victor B.","Lobov SA,Chernyshov AV,Krilova NP,Shamshin MO,Kazantsev VB",Lobov SA,10.3390/s20020500,Lobachevsky State University of Nizhni Novgorod,"One of the modern trends in the design of human-machine interfaces (HMI) is to involve the so called spiking neuron networks (SNNs) in signal processing. The SNNs can be trained by simple and efficient biologically inspired algorithms. In particular, we have shown that sensory neurons in the input layer of SNNs can simultaneously encode the input signal based both on the spiking frequency rate and on varying the latency in generating spikes. In the case of such mixed temporal-rate coding, the SNN should implement learning working properly for both types of coding. Based on this, we investigate how a single neuron can be trained with pure rate and temporal patterns, and then build a universal SNN that is trained using mixed coding. In particular, we study Hebbian and competitive learning in SNN in the context of temporal and rate coding problems. We show that the use of Hebbian learning through pair-based and triplet-based spike timing-dependent plasticity (STDP) rule is accomplishable for temporal coding, but not for rate coding. Synaptic competition inducing depression of poorly used synapses is required to ensure a neural selectivity in the rate coding. This kind of competition can be implemented by the so-called forgetting function that is dependent on neuron activity. We show that coherent use of the triplet-based STDP and synaptic competition with the forgetting function is sufficient for the rate coding. Next, we propose a SNN capable of classifying electromyographical (EMG) patterns using an unsupervised learning procedure. The neuron competition achieved via lateral inhibition ensures the ""winner takes all"" principle among classifier neurons. The SNN also provides gradual output response dependent on muscular contraction strength. Furthermore, we modify the SNN to implement a supervised learning method based on stimulation of the target classifier neuron synchronously with the network input. In a problem of discrimination of three EMG patterns, the SNN with supervised learning shows median accuracy 99.5% that is close to the result demonstrated by multi-layer perceptron learned by back propagation of an error algorithm.","EMG interface,STDP,pair-based STDP,triplet-based STDP,temporal coding,rate coding,synaptic competition,neural competition,lateral inhibition",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"MODEL,STDP,NEURONS",SENSORS,https://europepmc.org/articles/pmc7014236?pdf=render,
92,Comparison of Supervised Models in Hepatocellular Carcinoma Tumor Classification Based on Expression Data Using Principal Component Analysis (PCA),2264,,,"Siregar Anggrainy Togi Marito,Siswantining Titin,Bustamam Alhadi,Sarwinda Devvi","Siregar ATM,Siswantining T,Bustamam A,Sarwinda D",Siswantining T,10.1063/5.0023931,University of Indonesia,"Hepatocellular Carcinoma is one of the cancer disease cases with a high dead population. To know that someone is affected by Hepatocellular Carcinoma Tumor by observing the expression of genes on DNA. Gene expression obtained from the microarray laboratory tool that produced genes probe. In this case, there are 54675 gene expressions with 40 samples (homo sapiens). Many expression genes will be difficult to classify someone affected or not affected by Hepatocellular Carcinoma Tumor. We must take action to minimize the features without losing the data information. One of the tools to reduction dimension in Machine learning is Principal Component Analysis (PCA). Principal Component Analysis is a multivariate analysis that transforms correlated origin features into new features that do not correlate with each other by reducing the number of these features so that they have smaller dimensions but can explain most of the diversity of the original features. The objective of this research is to find the best percentage of features that have generated from PCA then fitting some models. The models that we use are Logistic Regression Classifier, Support Vector Machine (SVM) Classifier, and Random Forest Classifier. A Logistic regression model is able to provide the best accuracy starting from 40% of its variance on PCA made, which is equal to 0.875. While the Random Forest Classifier and Support Vector Machine can provide an accuracy of 0.875 when the value of the variance is above 60% of the variance. The result can give information to select the best percent in using PCA as a reduction dimension especially, for gene expression on Microarray data.","Dimension Reduction,Gene Expression,Hepatocellular Carcinoma,Support Vector Classifier,PCA",Proceedings Paper,"AMER INST PHYSICS, 2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA",Mathematical & Computational Biology,,,REDUCTION,,https://aip.scitation.org/doi/pdf/10.1063/5.0023931,
93,An Advanced Arrhythmia Recognition Methodology Based on R-waves Time-Series Derivatives and Benchmarking Machine-Learning Algorithms,,,1377-1382,"Trardi Y.,Ananou B.,Ouladsine M.","Trardi Y,Ananou B,Ouladsine M",Trardi Y,,Aix-Marseille Universite,"In this paper, we propose an automated decision-making approach to improve the efficiency of arrhythmia recognition. In particular, we focus on recognizing Normal Sinus Rhythms (NSR) from Abnormal Heart Rhythms (AHR). AHR include atrial fibrillation, atrial flutter, sinus bradycardia, and supraventricular tachyarrhythmia. Arrhythmia recognition approaches generally involve a feature extraction step designed to describe the heart rhythms and lead the decision-making process. Indeed, we develop an improved feature extraction strategy employing five dynamic patterns, defined as R-R intervals time series, and its first four absolute derivatives. The R-R intervals refer to the time interval separating two successive R-waves. Therefore, to describe each dynamic pattern, we use 13 feature measures. These measures comprise four time-domain features, six geometric features, and three non-linear features. As a result, a set of 65-features is built and evaluated to determine the most appropriate consistent combination of features. First, we implement a univariate statistical-based feature selection to remove irrelevant features. Then, we construct a model evaluation and selection process composed of dimensionality reduction strategies and machine learning algorithms. The latter serves to define the most suitable model based on its ability to discriminate between NSR and AHR. The findings underscore the benefits of this proposed approach, which could serve as valuable decision-making support in the detection of arrhythmias.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Automation & Control Systems,Engineering,Operations Research & Management Science,Mathematics",,,,2020 EUROPEAN CONTROL CONFERENCE (ECC 2020),,
94,Accelerating Artificial Intelligence on the Grid,,,,"Murphy Sean,Jones Kevin,Laughner Theo,Bariya Mohini,von Meier Alexandra","Murphy S,Jones K,Laughner T,Bariya M,von Meier A",Murphy S,,"PingThings Inc, El Segundo, CA 90245 USA.","In this work, we present an ongoing, three year project funded by the Advanced Research Project Agency (ARPA-E) to develop an infrastructure to accelerate the development and deployment of artificial intelligence solutions for the electric grid. The project addresses the critical issues that we have identified as hampering the deployment of AI on electric grid measurements. These issues have stymied the potential for insight from high resolution grid measurements and generally hindered artificial intelligence innovation in the utility industry. The project consists of three main components. The first is the deployment of a diverse set of grid sensors to capture a variety of grid behaviour, both from the field and in simulation. The second is the deployment of a highly performant, scalable, cloud-based data management and AI platform designed for time series data to enable the easy storage, processing and analysis of grid sensor data. The third is the cultivation of an open research community of experts around the platform and data through useful educational material, code and data sharing, and data science competitions. Overall, the project will accelerate the development of analytics, machine learning, and AI by addressing existing gaps in data, tools, and people, with the aim of improving the electric grid.","analytics,artificial intelligence,big data,smart grid",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
95,Vibro-Tactile Foreign Body Detection in Granular Objects based on Squeeze-Induced Mechanical Vibrations,,,175-180,"Syrymova Togzhan,Massalim Yerkebulan,Khassanov Yerbolat,Kappassov Zhanat","Syrymova T,Massalim Y,Khassanov Y,Kappassov Z",Kappassov Z,,Nazarbayev University,"Granular particles, filled within an elastic material, produce mechanical vibrations in structures or air when squeezed. This refers to structure-borne noise, is defined as a noise that occurs from the impacts of particles hitting each other due to their momentum. The momentum depends on both properties of particles and velocity of squeezing. Therefore, the structure-borne noise is highly correlated with the properties of particles. In this connection, we study a vibro-tactile sensor for detecting the mechanical vibrations from squeezing granular objects. Specifically, we explore machine learning solutions to detect foreign body within these objects using detected vibrations. We evaluated multiple learning approaches on a collected data set of 900 squeezing experiments across 15 different granular materials. In our experiments, the most successful method was convolutional neural network that achieved an accuracy of 91% on unseen test data. Remarkably, the foreign body was detected with a higher success rate for the majority of material types except salt and coffee granules.",RECOGNITION,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Robotics",,,RECOGNITION,,,
96,Improvement in Available Methods for Simultaneous and Proportional Control using the Kernel Technique for Unsupervised Myoelectric Intention Estimation of Individual Fingers,,,1137-1142,"Jamal Muhammad Zahak,Lee Dong-Hyun,Hyun Dong Jin","Jamal MZ,Lee DH,Hyun DJ",Jamal MZ,,Hyundai Kia Motors,"Recent advances in the field of biomedical engineering has prompted modern research to focus on challenges of human machine interface. This paper provides an improvement in unsupervised learning methods already available for estimating myoelectric intention of individual fingers using the kernel technique. The unsupervised methods which have been improved upon for simultaneous and proportional intention estimation are NMF and NMF-HP. These methods are called semi unsupervised algorithms as models are evaluated blindly using only the target finger. The algorithms implemented with kernels are named as kNMF and kNMF-HP. The kernel technique increases the feature matrix for the NMF and NMF-HP models and improves the performance of these algorithms. The algorithms were analyzed in terms of signal to noise ratio using the strength of the signal of the activated finger and the levels of other fingers not activated. Significant improvements were seen through the implementation of the kernel matrix on the parameters analyzed. An in-house eight channel signal instrumentation scheme was used to acquire the EMG signals using dry electrodes. In addition, a comprehensive signal filtering scheme was designed in order to remove the acquired EMG signal of noise. Finally, we used the algorithms to successfully drive a robotic hand.","Electromyography,NMF,NMF-HP,semi unsupervised,kNMF,kNMF-HP,dry surface EMG,EMG signal processing",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Robotics",,,,,,
97,Modular ROS Based Autonomous Mobile Industrial Robot System for Automated Intelligent Manufacturing Applications,,,1673-1678,"Luo Ren C.,Lee Shang Lun,Wen Yu Cheng,Hsu Chin Hao","Luo RC,Lee SL,Wen YC,Hsu CH",Luo RC,,National Taiwan University,"The objective of this paper is to develop a modular Robot Operating System (ROS) based autonomous mobile industrial robot system for automated intelligent manufacturing applications. We propose a finite state machine based method to integrate and manage various modular functions on the mobile manipulator which makes it have a great talent on mobility and manipulation. For mobility, we perform simultaneous localization and mapping (SLAM) on our robot to build a map and locate itself. We also develop navigation and collision avoidance strategies, so that it can navigate to anywhere it plans in the indoor environment. For manipulation, we use an RGB-D camera on the end effector to perform eye-in-hand system which given an image and point cloud, leveraging the learning-based object detection and shape-based grasping pose estimation to achieve flexible manipulation capabilities. In the experiments, we have developed an Autonomous Mobile Industrial Robot (AMIR) with a carefully designed mechanism and a fully modular ROS environment in our robotics lab at NTU. In the experiments, we construct an intelligent industrial scenario: collecting materials and delivering products from one place to another. Using our ROS based architecture to control the data/command flow between functions, we have successfully completed the demonstration of the system and proved the stability of the system.",SIMULTANEOUS LOCALIZATION,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Robotics",,,"SIMULTANEOUS,LOCALIZATION",,,
98,Non-Periodic Lower-Limb Motion Recognition with Noncontact Capacitive Sensing,,,1816-1821,"Zheng Enhao,Zeng Jinchen,Xu Dongfang,Wang Qining,Qiao Hong","Zheng EH,Zeng JC,Xu DF,Wang QN,Qiao H",Zheng EH,,Chinese Academy of Sciences,"Noncontact captive sensing is a new sensing strategy that we proposed previously to compensate for the limitations of existing surface electromyography studies for exoskeleton control. It has been validated on locomotion mode recognition and gait phase estimation. However, our previous studies addressed the tasks of periodic ambulation based on machine learning algorithms. The performances of the capacitive sensing on non-periodical lower-limb motion recognition have never been evaluated. In this preliminary study, we designed a motion recognition method by fusing the capacitive sensing and the inertial sensors. The recognition algorithm was designed based on the combined logics, which freed the system from burdensome training procedures in the recognition tasks. The method was validated on three healthy subjects in performing 6 lower-limb motions and the transitions between them (10 in total). The capacitance-inertial fusion method produced an average precision/recall of >0.92 in static motions and >0.86 with transitions. The most prominent improvement of using the capacitance signals is that it increases the time-response ability during the motion transitions. Compared with purely using inertial sensors, the sensor fusion method reduced more than 100-ms latency on average. The pilot study extends the scope of the new sensing method in human motion recognition. Future efforts will be paid in this direction to get more promising results.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Robotics",,,,,,
99,Mixing State Estimation of Peristaltic Continuous Mixing Conveyor with Distributed Sensing System Based on Soft Intestine Motion,,,208-214,"Wakamatsu K.,Inoue K.,Hagiwara D.,Adachi H.,Matsui D.,Kurumaya S.,Nishihama R.,Okui M.,Nakajima K.,Kuniyoshi Y.","Wakamatsu K,Inoue K,Hagiwara D,Adachi H,Matsui D,Kurumaya S,Nishihama R,Okui M,Nakajima K,Kuniyoshi Y",Wakamatsu K,,Chuo University,"A peristaltic continuous mixing conveyor that focuses on the mechanism of the intestine has been developed as a technology for the mixing and transport of a solid-liquid mixture and high viscosity fluids. The developed peristaltic continuous mixing conveyor succeeded in the mixing and transport of such mixtures in a previous study. A simple cyclic pattern is currently used as the movement pattern of the system, and the control method can be further improved. In this study, we aim to realize an intelligent mixing and generation of a conveyor pattern based on intestinal movement. The mixing state of content during activation was estimated through machine learning. The results from the time-series measurement data show that an internal mixing state in three units of the peristaltic continuous mixing conveyor was estimated.",TRANSPORT,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Robotics",,,TRANSPORT,2020 3RD IEEE INTERNATIONAL CONFERENCE ON SOFT ROBOTICS (ROBOSOFT),,
100,Self-sensing Elastomeric Membrane for Haptic Bubble Arrray.,,,229-236,"Barreiros Jose,Karakurt Ilbey,Agarwal Priyanshu,Agcayazi Talha,Reese Shawn,Healy Katherine,Menguc Yigit","Barreiros J,Karakurt I,Agarwal P,Agcayazi T,Reese S,Healy K,Menguc Y",Barreiros J,,Facebook Inc,"Bubble arrays are new type of devices that can render forces to the user's skin by pressurizing thin membranes. These devices are suitable for wearables due to being soft while having low encumbrance to the user body. In this manuscript, we describe a solution to tackle the major challenge towards controllability of this devices: state estimation of the membrane. This work describes the manufacturing of a self-sensing composite elastomeric membrane, device integration and the methods for state estimation using deep learning architectures. Additive manufacturing was used to fabricate the membrane and a pneumatic bubble actuator was operated at low pressures (10 psi). This membrane is thin (700 mu m), soft (3 MPa), and includes a matrix of elastomeric capacitors for distributed sensing of deformation. Our model predicted the magnitude of deformation with a mean absolute error MAE= 0.321mm corresponding to 13.1% accuracy.","Soft Sensors and Actuators,Deep Learning in Robotics and Automation,Haptics and Haptic Interfaces",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Robotics",,,SENSORS,2020 3RD IEEE INTERNATIONAL CONFERENCE ON SOFT ROBOTICS (ROBOSOFT),,
