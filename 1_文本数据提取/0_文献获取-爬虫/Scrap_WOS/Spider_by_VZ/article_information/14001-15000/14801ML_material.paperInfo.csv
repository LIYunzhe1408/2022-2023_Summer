,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Proposal for an incremental learning method for CNN-based breast cancer tumor detection CAD development,11513,,,"Abe Kazuya,Takeo Hideya,Nagai Yuuichi,Nawano Shige","Abe K,Takeo H,Nagai Y,Nawano S",Abe K,10.1117/12.2552448,Kanagawa Institute Technology,"In recent years, convolutional neural networks ( CNN) have found increasingly active application in the field of computer-aided diagnosis (CAD) research. Typically, general-use, high-performance detectors are designed using machine learning, the training of which is conducted by applying comprehensive sets of case images having various variations. In this study, we show that, when configuring CNN training data, dividing the data into multiple subsets and adjusting their ratios, instead of providing the data uniformly, has the potential for effective learning. We propose in this study a learning method by which CNN learning using these subsets is incrementally repeated.
In this study, subsets of breast cancer mass learning data based on mass size and intensity were created. Using multiple data sets prepared for use in the evaluation of a CNN that had been subjected to learning, optimal ratios were considered and, based on this, performance evaluations using actual unknown data were conducted. Next, the ratios of evaluation data subsets having numerous detection errors were raised and relearning conducted. This process was repeated multiple times, as long as increases in the area under curve (AUC) were observed, thus enabling the design of a high-performance CNN. As a result of applying unknown data to this CNN, we found that it exhibited a higher AUC than a CNN to which learning data was simply provided comprehensively, demonstrating the effectiveness of the proposed learning method.","CNN,CAD,learning method,breast cancer mass",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
2,Breast screening and artificial intelligence: an independent evaluation of two different software carried out at Valenciennes hospital.,11513,,,"Adrien Le Vourch,Edouard Poncelet,Nicolas Laurent","Adrien L,Edouard P,Nicolas L",Adrien L,10.1117/12.2564129,CH de Valenciennes,"We aimed to test two different software based on the deep learning technology versus two senior and one junior radiologist on a recall-based model for mammography. We performed a retrospective, monocentric, multi-reader study in the Centre Hospitalier de Valenciennes in the north of
France. A set of examinations from a daily practice, with both screening and diagnostic studies, has been interpreted by 3 radiologists and the two AI based algorithms. The dataset has been enriched with BIRADS 4 and 5 cases in order to have a number of cancer cases sufficient to have statistically significant results. In total, 140 examinations have been included in the final dataset.
Sensitivity (true positive rate - TPR), False positive rate (FPR), and recall rate per BI-RADS category were considered as endpoints for each of the radiologists. To compute these metrics all the included cases were considered as positive if the initial BI-RADS was equal or higher than 3 and as negative if the initial BI-RADS was 1 or 2. Additional analysis have been carried out taking into account the biopsy report (if any) as ground truth. While both the algorithms and radiologist have a good and comparative rate of sensitivity and FPR, the test based on BI-RADS categories (i.e. the number of cancer per BI-RADS category), showed heterogeneous results, with bad performances for one of the tested software on the extremes score of BI-RADS.
We concluded that one of the analysed software cannot be used in the current clinical practice without further improvements, the second one shows promising results, but other studies are needed to have a robust external validation before being used in a daily practice.","Artificial Intelligence,Breast screening,Mammography,Deep learning,Radiology,Data",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,"MAMMOGRAPHY,VARIABILITY,PERFORMANCE",,,
3,(I)mproving mammogram visualization by dimming text annotations,11513,,,"Avanaki Ali R. N.,Espig Kathryn S.,Xthona Albert,Kimpe Tom R. L.","Avanaki ARN,Espig KS,Xthona A,Kimpe TRL",Avanaki ARN,10.1117/12.2563600,"Barco Healthcare, Beaverton, OR 97008 USA.","In digital mammogram visualization, text is usually among the brightest objects. When bright text is near an area of interest in the tissue image, it can annoy the readers and may reduce the perception of tissue details. To mitigate this effect, we propose segmentation of the frame buffer to annotation text and mammographic image using artificial intelligence. An appropriate luminance can be re-assigned to each area (i.e., dim annotations and/or brighten mammographic image to the maximum luminance). Existing text detection and/or segmentation tools we tested did not work for this purpose because they produce false positives (i.e., parts of breast are detected as text and dimmed). That is perhaps because such methods were designed (or trained to, in case of deep learning methods) for natural images. We investigated two state-of-the-art segmentation architectures DeepLabV3+ and Mask R-CNN, as well as a ""shallow"" text detection method based on maximally stable external regions (MSER). We generate the training data by adding random text to the background of publicly available mammographic images. DeepLabV3+ trained to our data produced promising results while Mask R-CNN and MSER did not.","Convolutional neural networks,text detection,text segmentation,mammogram segmentation,veiling glare",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,SENSITIVITY,,,
4,Going from double to single reading for screening exams labeled as likely normal by AI: what is the impact?,11513,,,"Christiana Balta,Rodriguez-Ruiz Alejandro,Mieskes Christoph,Karssemeijer Nico,Heywang-Koebrunner Sylvia H.","Christiana B,Rodriguez-Ruiz A,Mieskes C,Karssemeijer N,Heywang-Kobrunner SH",Christiana B,10.1117/12.2564179,"ScreenPoint Med BV, Toernooiveld 300, NL-6525 EC Nijmegen, Netherlands.","We investigated whether a deep learning-based artificial intelligence (AI) system can be used to improve breast cancer screening workflow efficiency by making a pre-selection of likely normal screening mammograms where double-reading could be safely replaced with single-reading. We collected 18,015 consecutively acquired screening exams, the independent reading assessments by each radiologist of the double reading process, and the information about whether the case was recalled and if so the recall outcome. The AI system assigned a 1-10 score to each screening exam denoting the likelihood of cancer. We simulated the impact on recall rate, cancer detection rate, and workload if single-reading would have been performed for the mammograms with the lowest AI scores. After evaluating all possible AI score thresholds, it was found that when AI scores 1 to 7 are single read instead of double read, the cancer detection rate would have remained the same (no screen-detected cancers missed - the AI score is low but the single-reader would recall the exam), recall rate would have decreased by 11.8% (from 5.35% to 4.79%), and screen reading workload would have decreased by 32.6%. In conclusion, using an AI system could improve breast cancer screening efficiency by pre-selecting likely normal exams where double-reading might not be needed.","Artificial intelligence,Mammography,Breast cancer screening,CAD",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
5,Transfer Learning in Deep Convolutional Neural Networks for Detection of Architectural Distortion in Digital Mammography,11513,,,"Costa Arthur C.,Oliveira Helder C. R.,Borges Lucas R.,Vieira Marcelo A. C.","Costa AC,Oliveira HCR,Borges LR,Vieira MAC",Costa AC,10.1117/12.2564348,Universidade de Sao Paulo,"Deep learning models have reached superior results in various fields of application, but in many cases at a high cost of processing or large amount of data available. In most of them, specially in the medical field, the scarcity of training data limits the performance of these models. Among the strategies to overcome the lack of data, there is data augmentation, transfer learning and fine-tuning. In this work we compared different approaches to train deep convolutional neural network (CNN) to automatically detect architectural distortion (AD) in digital mammography. Although several computer vision based algorithms were designed to detect lesions in digital mammography, most of them perform poorly while detecting AD. We used the VGG-16 network pre-trained on ImageNet database with progressive fine-tuning to evaluate its performance on AD detection over a database of 280 images of clinical mammograms. Finally, we compared the results with a custom CNN architecture trained from scratch for the same task. Results indicated that a network with transfer learning and certain level of fine-tuning reaches the best results for the task (AUC = 0.89) compared with the other approaches, but no statistically significant difference was found between the best results using different amount of data augmentation and also compared to the custom CNN.","architectural distortion,digital mammography,deep learning,transfer learning,fine-tuning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,"COMPUTER-AIDED,DETECTION",,,
6,The effect of breast density on the performance of deep learning-based breast cancer detection methods for mammography,11513,,,"Dustler Magnus,Dahlblom Victor,Tingberg Anders,Zackrisson Sophia","Dustler M,Dahlblom V,Tingberg A,Zackrisson S",Dustler M,10.1117/12.2564328,Lund University,"Mammographic sensitivity in breasts with higher density has been questioned. Higher breast density is also linked to an increased risk for breast cancer. Even though digital breast tomosynthesis (DBT) offers an attractive solution, for varied reasons it has not yet been widely adopted in screening. An alternative could be to boost the performance of standard mammography by using computer-aided detection based on deep learning, but it remains to be proven how such methods are affected by density.
A deep-learning based computer-aided detection program was used to score the suspicion of cancer on a scale of 1 to 10. A set of 13838 mammography screening exams were used. All cases had BIRADS density values available. The set included 2304 exams (11 cancers) in BIRADS 1, 5310 (51 cancers) in BIRADS 2, 4844 (73 cancers) in BIRADS 3 and 1223 (22 cancers) in BIRADS 4.
A Kruskal-Wallis analysis of variance showed no statistically significant differences between the cancer risk scores of the density categories for cases diagnosed with cancer (P=0.9225). An identical analysis for cases without cancer, showed significant differences between the density categories (P<0.0001).
The results suggest that the risk categorization of the deep-learning software is not affected by density, as though some density categories receive higher risk assessments in general, this does not hold for cancer cases, which show uniformly high risk values despite density. This shows the potential for deep-learning to improve screening sensitivity even for women with high density breasts.","Breast,breast density,deep learning,computer aided detection,mammography,screening",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,RISK,,,
7,An AI-based Method to Retrieve Hematoxylin & Eosin Breast Histology Images Using Mammograms,11513,,,"Hamidinekoo Azam,Denton Erika,Honnor Kate,Zwiggelaar Reyer","Hamidinekoo A,Denton E,Honnor K,Zwiggelaar R",Hamidinekoo A,10.1117/12.2564298,Aberystwyth University,"Early diagnosis of breast cancer can increase survival rate. The assessment process for breast screening follows a triple assessment model: appropriate imaging, clinical assessment and biopsy. Retrieving prior cases with similar cancer symptoms could be used to circumvent incompatibilities in breast cancer grading. Abnormal mass lesions in breast are often co-located with normal tissue, which makes it difficult to describe the whole image with a single binary code. Therefore, we propose an AI-based method to describe mass lesions in semantic abstracts/codes. These codes are used in a searching based method to retrieve similar cases in the archive. This simple and effective network is used for unifying classification and retrieval in a single learning process, while enforcing similar lesion types to have similar semantic codes in a compact form. An advantage of this approach is its scalability to large-scale image retrievals.","Mammography,Histology,Hematoxylin & Eosin (H&E),Deep Learning,Image Retrieval",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,BINARY-CODES,,,
8,Domain Adapted Breast Tissue Segmentation in Magnetic Resonance Imaging,11513,,,"Kuling Grey,Curpen Belinda,Martel Anne L.","Kuling G,Curpen B,Martel AL",Kuling G,10.1117/12.2564131,University of Toronto,,"Background Parenchymal Enhancement,Breast MRI,Breast Density,Automatic Segmentation,Machine Learning,Breast Cancer Risk,Deep Learning,Image Domain Adaptation",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,"HIGH-RISK,CANCER,MAMMOGRAPHY,MRI",,,
9,Convolutional-neural-network based breast thickness correction in digital breast tomosynthesis,11513,,,"Lee Seoyoung,Kim Hyeongseok,Lee Hoyeon,Jeong Uijin,Cho Seungryong","Lee S,Kim H,Lee H,Jeong U,Cho S",Cho S,10.1117/12.2560909,Korea Advanced Institute of Science & Technology (KAIST),"This work addresses equalization and thickness estimation of breast periphery in digital breast tomosynthesis (DBT). Breast compression in DBT would lead to a relatively uniform thickness at inner breast but not at the periphery. Proper peripheral enhancement or thickness correction is needed for diagnostic convenience and for accurate volumetric breast density estimation. Such correction methods have been developed albeit with several shortcomings. We present a thickness correction method based on a supervised learning scheme with a convolutional neural network (CNN), which is one of the widely-used deep learning structures, to improve the pixel value of the peripheral region. The network was successfully trained and showed a robust and satisfactory performance in our numerical phantom study.","digital breast tomosynthesis,CNN,peripheral equalization,thickness correction",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
10,Three compartment breast machine learning model for improving computer-aided detection,11513,,,"Leong Lambert,Giger Maryellen,Drukker Karen,Kerlikowske Karla,Joe Bonnie,Greenwood Heather,Markov Serghei,Niell Bethany,Shepherd John","Leong L,Giger M,Drukker K,Kerlikowske K,Joe B,Greenwood H,Markov S,Niell B,Shepherd J",Leong L,10.1117/12.2560092,Cancer Research Center of Hawaii,"Our purpose was to determine if the lipid, water, and protein lesion composition (3CB), combined with computer-aided detection (CAD) had higher biopsy malignancy specificity than CAD alone. High and low-kVp full-field digital 3CB mammograms were acquired on women with suspicious mammographic lesions (BIRADS 4) and that were to undergo biopsy. Radiologists delineated 673 lesions (98 invasive ductal cancers (IDC), 60 ductal carcinomas in situ (DCIS), 103 fibroadenomata (FA), and 412 benign (BN)) on the diagnostic mammograms using the pathology report to confirm location. The diagnostic mammograms were processed by iCAD SecondLook software using its most sensitive setting to create to further delineations and probabilities of malignancy. The iCAD delineated a total of 375 annotation agreeing regions that were classified as either masses or calcification cluster. The 3CB algorithm produced lipid, water, and protein thickness maps for all ROIs and peripheral rings from which 84 compositional input features were derived. A neural network (3CBNN) was trained with cross-validation on 80% of the data to predict the lesion type. Biopsy pathology served as the gold standard outcome. IDC and DCIS predicted probabilities were summed together to obtain a probability of malignancy which was evaluated against the iCAD probabilities using the area under the ROC curves. On a holdout test set, 20% of the data, the iCAD's output alone had an AUC of 0.61 while the 3CBNN's AUC was 0.73. We conclude that compositional information provided by the 3CB algorithm contains important diagnostic information that can increase specificity of CAD software.","Full Field Digital Mammography,Neural Network,Computer-aided Detection,Dual Energy X-ray Absorptiometry,Breast Cancer",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
11,Automatic breast segmentation in digital mammography using a convolutional neural network,11513,,,"Maghsoudi Omid Haji,Gastounioti Aimilia,Pantalone Lauren,Conant Emily,Kontos Despina","Maghsoudi OH,Gastounioti A,Pantalone L,Conant E,Kontos D",Maghsoudi OH,10.1117/12.2564235,University of Pennsylvania,"Digital mammography (DM) has been considered as the primary modality for breast cancer screening. The relative amount of breast fibroglandular tissue, referred to as percent breast density (PD), has been considered as an important factor associated with breast cancer. We have developed and tested a robust method to accurately segment the pectoral muscle and the breast area using a deep learning approach. We use a U-Net architecture with a ResNet decoder to increase the depth of features. The architecture is trained using 555 DM images and tested and validated on an independent set of 555 images. The results show that our network achieves an average and standard deviation dice coefficient of 94:86% +/- 1:93%, respectively, and sensitivity of 96:31% +/- 1:87%. The method present here can be considered as the first step toward the automatic estimation of PD.","Digital Mammography,Deep Learning,Segmentation,Breast Cancer",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,DENSITY,,,
12,Machine learning classifier of medical specimen images,11513,,,"Maidment Tristan D.,Ng Susan","Maidment TD,Ng S",Maidment TD,10.1117/12.2564492,"Real Time Tomog LLC, Villanova, PA 19085 USA.","Specimen x-ray imaging provides important information on the margin of surgically excised tissue as well as radiologic and pathologic correlation of the lesion. Similar to breast imaging, where mammograms are digitally processed to enhance readability and lesion conspicuity, specimen images are also processed and enhanced. However, specimen image processing is made challenging by the diversity of specimen containers that are commercially available, compounded by variations in specimen size. In this work, we demonstrate our specimen container and size classification system based on a simple convolutional neural network (CNN), trained to identify the container type. This system allows for automated image processing of the supported container types. A dataset consisting of 1428 HIPAA and IRB-complaint anonymized specimen images were collected. We prepared a simple CNN for image classification with 3 convolutional and 3 fully connected layers, and evaluated the performance based on three comparison metrics. Each network was analyzed in terms of accuracy, multi-class AUC, and via a confusion matrix. The best performing classifier, determined via cross validation, was then used for testing, and evaluated with the same three metrics. The results of training and tuning within cross validation showed that the specimen classes are easily differentiable with this simple convolutional neural network structure. During testing, the network was able to achieve an accuracy of 95.8 +/- 4.0%, and an AUC of 0.9763 +/- 0.0001.","Specimen Radiography,Breast Specimen Imaging,Convolutions Neural Networks,Image Processing,Image Classification",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
13,Breast Cancer Detection/Diagnosis with Upstream Data Fusion and Machine Learning,11513,,,"Porter David W.,Walton William C.,Harvey Susan C.,Mullen Lisa A.,Tsui Benjamin M. W.,Kim Seung-Jun,Peyton Keith S.","Porter DW,Walton WC,Harvey SC,Mullen LA,Tsui BMW,Kim SJ,Peyton KS",Porter DW,10.1117/12.2564159,Johns Hopkins University,"Machine learning (ML) has made great advancements in imaging for breast cancer detection, including reducing radiologists read times, yet its performance is still reported to be at best similar to that of expert radiologists. This leaves a performance gap between what is desired by radiologists and what can actually be achieved in terms of early detection, reduction of excessive false positives and minimization of unnecessary biopsies. We have seen a similar situation with military intelligence that is expressed by operators as ""drowning in data and starving for information"". We invented Upstream Data Fusion (UDF) to help fill the gap. ML is used to produce candidate detections for individual sensing modalities with high detection rates and high false positive rates. Data fusion is used to combine modalities and dramatically diminish false positives. Upstream data, that is closer to raw data, is hard for operators to visualize. Yet it is used for fusion to recover information that would otherwise be lost by the processing to make it visually acceptable to humans. Our research with breast cancer detection involving the fusion of Digital Breast Tomosynthesis (DBT) with Magnetic Resonance Imaging (MRI) and also the fusion of DBT with ultrasound (US) data has yielded preliminary results which lead us to conclude that UDF can help to both fill the performance gap and reduce radiologist read time. Our findings suggest that UDF, combined with ML techniques, can result in paradigm changes in the achievable accuracy and efficiency of early breast cancer detection.",,Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
14,Mammographic mass identification in dense breasts using multi-scale analysis of structured micro-patterns,11513,,,"Sajeev Shelda,Bajger Mariusz,Lee Gobert,Muramatsu Chisako,Fujita Hiroshi","Sajeev S,Bajger M,Lee G,Muramatsu C,Fujita H",Sajeev S,10.1117/12.2564272,"Torrens Univ, Adelaide, SA, Australia.",The paper proposes a novel approach for the identification of cancerous regions located in a dense part of a breast. This task is particularly challenging even for experienced radiologists due to lack of clear boundaries between the cancerous and normal tissue. Multi-scale analysis of structured micro-patterns generated from local binary patterns (LBP) was used to generate a very small number of features which allowed for successful detection of cancerous regions. The proposed technique was tested on two publicly available datasets: Digital Database for Screening Mammography (DDSM) and INbreast. The area under the receiver operating characteristic (AUC) curve for DDSM with 2 features only was 0.99 and 0.92 for INbreast with 3 features.,"breast cancer,mammography,CAD,dense ROI,local binary pattern,structured micro-patterns,machine learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,"FALSE-POSITIVE,REDUCTION,COMPUTER-AIDED,DETECTION,CLASSIFICATION",,,
15,Automatic density prediction in low dose mammography,11513,,,"Squires Steven,Ionescu Georgia,Harkness Elaine F.,Mackenzie Alistair,Evans D. Gareth,Maxwell Anthony,Howell Sacha,Astley Susan M.","Squires S,Ionescu G,Harkness EF,Mackenzie A,Evans DG,Maxwell A,Howell S,Astley SM",Squires S,10.1117/12.2564714,University of Manchester,"Estimation of breast density for cancer risk prediction is generally achieved by analysis of full-field digital mammograms. Conventional digital mammography should be avoided if possible in young women because of concerns about potential cancer induction, particularly in those with dense breasts who receive higher doses. This precludes repeated examinations over a short timescale to assess density change. We assess whether density can be accurately estimated in low dose mammograms with one-tenth of the standard dose, with the aim of providing a safe and effective method for use in younger women which is suitable for serial density measurement. We present analysis of data from an on-going clinical trial in which both standard and low dose mammograms are acquired under the same compression. We used both an existing convolutional neural network model designed to estimate breast density and a new model developed using a transfer learning approach. We then applied three methods to estimate density on the low dose mammograms: training on a different mammogram dataset; using simulated low dose data; and training directly on low dose mammograms using cross-validation. Pearson correlation coefficients between measurements on full dose and low dose mammograms ranged from 0.92 to 0.98 with the root mean squared error ranging between 3.37 and 7.27. Our results indicate that accurate density measurements can be made using low dose mammograms.","low dose mammography,breast density,deep learning,AI,breast cancer",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,"BREAST-CANCER,RISK",,,
16,Three-dimensional visualization of cribriform pattern in ductal carcinoma in situ with X-ray dark field computed tomography,11513,,,"Sunaguchi N.,Huang Z.,Shimao D.,Yuasa T.,Ichihara S.,Nishimura R.,Iwakoshi A.,Ando M.","Sunaguchi N,Huang Z,Shimao D,Yuasa T,Ichihara S,Nishimura R,Iwakoshi A,Ando M",Sunaguchi N,10.1117/12.2563940,Nagoya University,"Cribriform architecture is a histological pattern reminiscent of Swiss cheese that is commonly recognized in ductal carcinoma in situ (DCIS) of the breast observed by microscope. However, there are only a few three-dimensional studies to elucidate whether each glandular cavities of cribriform pattern are connected or not. The main reason for paucity of three-dimensional studies is that the conventional reconstruction based on histological sections requires laborious and time-consuming works. In this research, we first performed three-dimensional reconstruction of the cribriform pattern using crystal analyzer-based phase contrast technique, X-ray dark field computed tomography (XDFI-CT), which provides high contrast image of biological soft tissue with non-destructive and non-staining approach. Then, we propose a machine-learning-based method to extract the cavity from XDFI-CT images. Finally, we show that the useful information to analyze the cribriform patterns in DCIS such as the density and volume of the cavity can be obtained from the XDFI-CT images.","X-ray dark field computed tomography (XDFI-CT),ducal carcinoma in situ (DCIS),cribriform pattern,Three-dimensional visualization",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
17,Deep learning to calculate breast density from processed mammography images,11513,,,"Warren Lucy M.,Harris Peter,Gomes Sandra,Trumble Matthew,Halling-Brown Mark D.,Dance David R.,Wilkinson Louise,Given-Wilson Ro,Young Kenneth C.","Warren LM,Harris P,Gomes S,Trumble M,Halling-Brown MD,Dance DR,Wilkinson L,Given-Wilson R,Young KC",Warren LM,10.1117/12.2561278,"Royal Surrey NHS Fdn Trust, Egerton Rd, Guildford GU2 7XX, GU, England.","Purpose: To calculate continuous breast density measures from processed images using deep learning.
Method: Processed and unprocessed mammograms were collected for 3251 women attending the UK NHS Breast Screening Programme (NHSBSP). The breast density measures investigated included volumetric breast density, fibroglandular volume and breast volume. The ground truth for these measures was calculated using Volpara software on unprocessed mammograms. A deep learning model was trained and validated to predict each breast density measure. The performance of the deep learning model was assessed using a hold-out test set.
Results: The breast volume and fibroglandular volume predicted with deep learning were strongly correlated with the ground truth (r=0.96 and r=0.88 respectively). The volumetric breast density had a Pearson correlation coefficient of 0.90.
Conclusions: It is possible to predict volumetric breast density from processed images using deep learning.","Breast density,image processing,deep learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Obstetrics & Gynecology,Optics,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,RISK,,,
18,DEEP MOUSE: AN END-TO-END AUTO-CONTEXT REFINEMENT FRAMEWORK FOR BRAIN VENTRICLE & BODY SEGMENTATION IN EMBRYONIC MICE ULTRASOUND VOLUMES,,,122-126,"Xu Tongda,Qiu Ziming,Das William,Wang Chuiyu,Langerman Jack,Nair Nitin,Aristizabal Orlando,Mamou Jonathan,Turnbull Daniel H.,Ketterling Jeffrey A.","Xu TD,Qiu ZM,Das W,Wang CY,Langerman J,Nair N,Aristizabal O,Mamou J,Turnbull DH,Ketterling JA",Xu TD,,New York University,"The segmentation of the brain ventricle (BV) and body in embryonic mice high-frequency ultrasound (HFU) volumes can provide useful information for biological researchers. However, manual segmentation of the BV and body requires substantial time and expertise. This work proposes a novel deep learning based end-to-end auto-context refinement framework, consisting of two stages. The first stage produces a low resolution segmentation of the BV and body simultaneously. The resulting probability map for each object (BV or body) is then used to crop a region of interest (ROI) around the target object in both the original image and the probability map to provide context to the refinement segmentation network. Joint training of the two stages provides significant improvement in Dice Similarity Coefficient (DSC) over using only the first stage (0.818 to 0.906 for the BV, and 0.919 to 0.934 for the body). The proposed method significantly reduces the inference time (102.36 to 0.09 s/volume approximate to 1000x faster) while slightly improves the segmentation accuracy over the previous methods using slide-window approaches.","Image segmentation,high-frequency ultrasound,mouse embryo,volumetric deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
19,Based on Machine Learning Seawater Batteries of Performance Prediction for Torpedo Propulsion Control,45,9,"52-57,62",",,,,,","Liu Xiaoda,Hou Jianpeng,Yin Ming,Wang Zhiwei,Hou Lifeng,Wei Yinghui",,,Liu Xiaoda,"Aiming at the problem of low anode discharge performance of magnesium seawater batteries for torpedoes and the traditional ""trial and error method"" in the material design cause the development cycle is too long.Through data analysis and machine learning methods, Linear Regression (LR),Support Vector Regression (SVR) and Multilayer Perceptron (MLP) algorithms are used to model the data set, and the discharge performance of magnesium -based anode materials is predicted by the model. According to the prediction results, Mg -5.7Al -0.9Ge alloy was prepared as anode material for magnesium seawater battery. Through electrochemical experiments to verify the discharge performance of Mg-5.7Al-0.9Ge alloy in 3.5 wt% NaCl solution, the study found that the alloy was under the current density of 20 mA·cm~(-2),50 mA·cm~(-2), the discharge potential is -1.641 V and -1.429 V,and the discharge efficiency is 69.5 % and 60.4 %,respectively,and its discharge performance is better than the commercial magnesium alloy anode material AZ61. The results show that the SVR model has the best predictive ability, high correlation coefficient and low error, and provides guidance for the composition design and rapid development of magnesium-based anode materials.","magnesium seawater battery; ,machine learning,; support vector regression; magnesium based anode materials; discharge performance",Article,,,,,,,,
20,Predicting solidification cracking susceptibility of stainless steels using machine learning,861,,,"Feng S.,Dong H. B.","Feng S,Dong HB",Dong HB,10.1088/1757-899X/861/1/012073,University of Leicester,"Machine learning, which reveals the complex nonlinear relationship in the archived data, is a powerful complement to theory, experiment, and modeling. In this study we attempted to predict solidification cracking susceptibility of stainless steels as a function of chemistry and processing parameters using machine learning with a data set that contains about 600 longitudinal varestraint test results. Four machine learning models, i.e. decision tree, random forest, shallow neural network and deep neural network, were used to mine the data set. Our results show: deep neural network outperformed other models in prediction accuracy; tree-based models have accepted accuracy and better interpretability than neural network; machine learning models transforms scattered experimental data points into a map in high-dimensional chemistry and processing parameters space. The combination of different machine learning models reveals that the solidification cracking susceptibility of stainless steels was mainly determined by the ratio of Ni content to Cr content, impurity element content and the strain level.",,Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Engineering,Materials Science",,,,,https://doi.org/10.1088/1757-899x/861/1/012073,
21,Automated Classification of Types of Brain Tumor in T1-weighted MR Images: A Thorough Comparative Study,2266,,,"Qi Lim Jia,Alias Norma,Johar Farhana","Qi LJ,Alias N,Johar F",Qi LJ,10.1063/5.0018056,Universiti Teknologi Malaysia,"Undoubtedly, early detection and characterization of brain tumor is critical in clinical practices. Automated diagnosis using neuroimaging tool like MRI guided by machine learning approaches has been the focus of numerous researches. In this study, various feature extraction, dimensionality reduction and supervised classification models are explored, evaluated and compared under different finite number of features to identify the optimal pathway/pipeline for classification of types of brain tumor, namely meningioma, glioma and pituitary tumor. The performance metrics utilized include accuracy, Kappa statistic, sensitivity, precision, F-measure, training time and test time. Results show that RBF SVM (pairwise coupling) under 80 PLS features achieved the highest average accuracy (95.02% +/- 0.19%) among all other machine learning pipelines.","PSEUDO-ZERNIKE MOMENTS,ACCURATE CALCULATION,RECOGNITION,DESCRIPTOR,TEXTURE,MACHINE,SHAPE",Proceedings Paper,"AMER INST PHYSICS, 2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA",Mathematics,,,"PSEUDO-ZERNIKE,MOMENTS,ACCURATE,CALCULATION,RECOGNITION,DESCRIPTOR,TEXTURE,MACHINE,SHAPE",,https://aip.scitation.org/doi/pdf/10.1063/5.0018056,
22,Biological Functions of Polymers and Metal Composites,20,11,913-914,"Kumar Balvinder,Manuja Anju","Kumar B,Manuja A",Kumar B,10.2174/156802662011200428071550,Indian Council of Agricultural Research (ICAR),,"GUM ACACIA HYDROGELS,SODIUM ALGINATE,NANOPARTICLES",Editorial Material,"BENTHAM SCIENCE PUBL LTD, EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES",Pharmacology & Pharmacy,,4.008,"GUM,ACACIA,HYDROGELS,SODIUM,ALGINATE,NANOPARTICLES",CURRENT TOPICS IN MEDICINAL CHEMISTRY,,
23,Transform Learning for Magnetic Resonance Image Reconstruction: From Model-Based Learning to Building Neural Networks,37,1,41-53,"Wen Bihan,Ravishankar Saiprasad,Pfister Luke,Bresler Yoram","Wen BH,Ravishankar S,Pfister L,Bresler Y",Ravishankar S,10.1109/MSP.2019.2951469,Michigan State University,,"SPARSIFYING TRANSFORMS,CONVERGENCE GUARANTEES,LOW-RANK,MRI",Editorial Material,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,12.821,"SPARSIFYING,TRANSFORMS,CONVERGENCE,GUARANTEES,LOW-RANK,MRI",IEEE SIGNAL PROCESSING MAGAZINE,http://arxiv.org/pdf/1903.11431,
24,"Structured Low-Rank Algorithms: Theory, Magnetic Resonance Applications, and Links to Machine Learning",37,1,54-68,"Jacob Mathews,Mani Merry P.,Ye Jong Chul","Jacob M,Mani MP,Ye JC",Jacob M,10.1109/MSP.2019.2950432,University of Iowa,,"PIECEWISE-CONSTANT IMAGES,K-SPACE NEIGHBORHOODS,FINITE RATE,RECONSTRUCTION,RECOVERY,MRI,LORAKS",Editorial Material,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,12.821,"PIECEWISE-CONSTANT,IMAGES,K-SPACE,NEIGHBORHOODS,FINITE,RATE,RECONSTRUCTION,RECOVERY,MRI,LORAKS",IEEE SIGNAL PROCESSING MAGAZINE,http://arxiv.org/pdf/1910.12162,
25,Accelerated Dynamic Magnetic Resonance Imaging Using Learned Representations: A New Frontier in Biomedical Imaging,37,1,83-93,"Christodoulou Anthony G.,Lingala Sajan Goud","Christodoulou AG,Lingala SG",Christodoulou AG,10.1109/MSP.2019.2942180,Cedars Sinai Medical Center,,"MRI,RECONSTRUCTION,REGULARIZATION,SPARSITY,MODEL,FRAMEWORK",Editorial Material,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,12.821,"MRI,RECONSTRUCTION,REGULARIZATION,SPARSITY,MODEL,FRAMEWORK",IEEE SIGNAL PROCESSING MAGAZINE,,
26,Machine Learning Based Diagnosis of Diseases Using the Unfolded EEG Spectra: Towards an Intelligent Software Sensor,32,,165-172,"Buettner Ricardo,Rieg Thilo,Frick Janek","Buettner R,Rieg T,Frick J",Buettner R,10.1007/978-3-030-28144-1_18,"Aalen Univ, Aalen, Germany.","In this research-in-progress work we sketch a roadmap for the development of a novel machine-learning-based EEG software sensor. In the first step we present the idea to unfold the EEG standard bandwidths in a more fine-graded equidistant 99-point spectrum to improve accuracy when diagnosing diseases. We use this novel pre-processing step prior to entering a Random Forests classifier. In the second step we evaluate the approach on alcoholism and epilepsy and demonstrate that the approach outperforms all benchmarks. The third step sketches a further improvement by replacing the hard-coded equidistant 99-point spectrum with a flexibly-grading spectrum. In the fourth step we combine the flexibly-grading EEG spectrum, the spatial locations of the EEG electrodes, and the EEG recording time to train an intelligent EEG software sensor using self-organizing feature mapping. Our work contributes to NeuroIS research by analyzing EEG as a bio-signal though a novel machine-learning approach.","Electroencephalography,Random forests,Spectral analysis,Machine learning",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Psychology,Behavioral Sciences,Computer Science,Neurosciences & Neurology",,,ALCOHOL,,,
27,"On Using Python to Run, Analyze, and Decode EEG Experiments",32,,287-293,"Conrad Colin,Agarwal Om,Woc Carlos Calix,Chiles Tazmin,Godfrey Daniel,Krueger Kavita,Marini Valentina,Sproul Alexander,Newman Aaron","Conrad C,Agarwal O,Woc CC,Chiles T,Godfrey D,Krueger K,Marini V,Sproul A,Newman A",Conrad C,10.1007/978-3-030-28144-1_32,Dalhousie University,"As the NeurolS field expands its scope to address more complex research questions with electroencephalography (EEG), there is greater need for EEG analysis capabilities that are relatively easy to implement and adapt to different protocols, while at the same time providing an open and standardized approach. We present a series of open source tools, based on the Python programming language, which are designed to facilitate the development of open and collaborative EEG research. As supplementary material, we demonstrate the implementation of these tools in a NeurolS case study and provide files that can be adapted by others for NeurolS EEG research.","Research methods,Python,Machine learning,Open science,Brain-computer interface",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND","Psychology,Behavioral Sciences,Computer Science,Neurosciences & Neurology",,,"MENTAL,PROSTHESIS,SOFTWARE",,,
28,Different Approaches for Automatic Nucleus Image Segmentation in Fluorescent in situ Hybridization (FISH) Analysis for HER2 Status Assesment,,,270-277,"Makhov Denis,Samorodov Andrey,Slavnova Elena","Makhov D,Samorodov A,Slavnova E",Makhov D,,Bauman Moscow State Technical University,"according to American Cancer Society breast cancer is the most common cancer type in women. For most effective treatment choice and patients' state of health prediction it is necessary to make a differential diagnosis to determine breast cancer subtype. The tumor subtype is determined by immunohistochemical or immunocytochemical studies, which evaluate the expression levels of steroid hormone receptors, proliferative protein Ki-67, and oncoprotein CerbB-2 (HER2/neu). HER2-positive subtypes are most adverse (about 25-30% of all cases). In case of indefinite CerbB-2 expression fluorescence in situ hybridization (FISH) investigation is utilized. In most cases, this study is held by visual estimation of fluorescent image parameters by pathologist and thus is subjective. We need to employ automatization techniques to decrease human factor impact and increase reproducibility of the analysis result. FISH analysis automatization for HER2 amplification can be divided into three tasks: nucleus segmentation, signal detection and presentation of the results according to ASCO/CAP recommendations. In this article results for nucleus segmentation task using different machine learning algorithms are presented. The image database for investigations consisted of RGB fluorescent images, as well as gray scale images for each individual fluorophore. The best result was achieved using the random forest algorithm on gray-scale images of individual fluorophores.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,,,,
29,Interval Signs Enlargement Algorithm in the Classification Problem of Biomedical Signals,1156,,20-29,"Sidorov Konstantin V,Filatova Natalya N.","Sidorov KV,Filatova NN",Sidorov KV,10.1007/978-3-030-50097-9_3,Tver State Technical University,"When solving a number of applied problems, the classifiers that work with samples of two-dimensional graphical dependences are very useful. The paper considers the approach to solving the classification problem of two-dimensional characteristic curves of biomedical signals, which illustrate human emotional state variation. It also describes a localization algorithm of interval consecutively enlarged sings. The intervals of enlarged attributes are determined by analyzing the rules that are generated during classifier training on primary data. The classifier is based on a neural-like hierarchical structure (NLHS) that is adapted to working with fuzzy object descriptions. During the learning process, class models are formed in a hierarchical structure of the classifier. These models are interpreted as fuzzy statements for a fuzzy inference system. Fuzzy statements reflect basic characteristics of all training sample objects and are presented to an expert in an understandable form. The algorithm of automatic generation of interval attributes allows localizing areas with equal values of fuzzy attributes. In fact, this leads to dividing of the investigated characteristic curves into segments with close estimates of their structural properties. The software implementation of the algorithm is tested on EEG and EMG. The paper investigates the effect of the application of successively enlarged attributes on the results of the examined data classification accuracy.","Algorithm,Graphical dependance,Training set,Test set,Human emotions,EEG,EMG,PSD,Fuzzy signs",Proceedings Paper,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Computer Science,,,,,,
30,The Development of Guided Inquiry Student Worksheet using Tracker Video Analysis for Kinematics Motion Topics,1491,,,"Muliyati D.,Septiningrum A. D.,Ambarwulan D.,Astra I. M.","Muliyati D,Septiningrum AD,Ambarwulan D,Astra IM",Muliyati D,10.1088/1742-6596/1491/1/012062,Universitas Negeri Jakarta,"This paper aims to describe the development of guided inquiry student worksheets using tracker video analysis for kinematics motion topics. This development is to facilitate students to do straight motion and parabolic practicum using a video analysis tracker with teacher guidance. It uses a six-step guided inquiry approach. The model of the research and development is Analysis, Design, Development, Implementation, and Evaluation (ADDIE). The samples of the implementation stage are 34 students, then grouping into nine groups. The results of the development research obtained worksheets on the material: horizontal motion, vertical upward motion, downward vertical motion, free-fall motion, and parabolic motion. This worksheet was validation by material experts, media experts, and learning experts. The result of validation is the product was very feasible or has fulfilled the requirements to use as learning media.",GRAPHS,Proceedings Paper,"IOP PUBLISHING LTD, DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND","Education & Educational Research,Physics",,,GRAPHS,,https://doi.org/10.1088/1742-6596/1491/1/012062,
31,Vocal Tract Contour Tracking in rtMRI Using Deep Temporal Regression Network,28,,3053-3064,"Asadiabadi Sasan,Erzin Engin","Asadiabadi S,Erzin E",Asadiabadi S,10.1109/TASLP.2020.3036182,Koc University,"Recent advances in real-time Magnetic Resonance Imaging (rtMRI) provide an invaluable tool to study speech articulation. In this paper, we present an effective deep learning approach for supervised detection and tracking of vocal tract contours in a sequence of rtMRI frames. We train a single input multiple output deep temporal regression network (DTRN) to detect the vocal tract (VT) contour and the separation boundary between different articulators. The DTRN learns the non-linear mapping from an overlapping fixed-length sequence of rtMRI frames to the corresponding articulatory movements, where a blend of the overlapping contour estimates defines the detected VT contour. The detected contour is refined at a post-processing stage using an appearance model to further improve the accuracy of VT contour detection. The proposed VT contour tracking model is trained and evaluated over the USC-TIMIT dataset. Performance evaluation is carried out using three objective assessment metrics for the separating landmark detection, contour tracking and temporal stability of the contour landmarks in comparison with three baseline approaches from the recent literature. Results indicate significant improvements with the proposed method over the state-of-the-art baselines.","Estimation,Magnetic resonance imaging,Speech processing,Image segmentation,Training,Heating systems,Tracking,Appearance model,contour detection,deep neural network,real-time magnetic resonance imaging (rtMRI),speech production,vocal tract",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,3.906,"TISSUE,BOUNDARY,SEGMENTATION,ARTICULATORY,SYNTHESIS",IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING,https://cdm21054.contentdm.oclc.org/digital/api/collection/IR/id/9253/download,
32,Efficient directionality-driven dictionary learning for compressive sensing magnetic resonance imaging reconstruction,7,1,,"Arun Anupama,Thomas Thomas James,Rani J. Sheeba,Gorthi R. K. Sai Subrahmanyam","Arun A,Thomas TJ,Rani JS,Gorthi RKSS",Rani JS,10.1117/1.JMI.7.1.014002,"Department of Space (DoS), Government of India","Compressed sensing is an acquisition strategy that possesses great potential to accelerate magnetic resonance imaging (MRI) within the ambit of existing hardware, by enforcing sparsity on MR image slices. Compared to traditional reconstruction methods, dictionary learning-based reconstruction algorithms, which locally sparsify image patches, have been found to boost the reconstruction quality. However, due to the learning complexity, they have to be independently employed on successive MR undersampled slices one at a time. This causes them to forfeit prior knowledge of the anatomical structure of the region of interest. An MR reconstruction algorithm is proposed that employs the double sparsity model coupled with online sparse dictionary learning to learn directional features of the region under observation from existing prior knowledge. This is found to enhance the capability of sparsely representing directional features in an MR image and results in better reconstructions. The proposed framework is shown to have superior performance compared to state-of-art MRI reconstruction algorithms under noiseless and noisy conditions for various undersampling percentages and distinct scanning strategies. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","compressive sensing,dictionary learning,magnetic resonance imaging",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"MRI,RECONSTRUCTION,RECOVERY",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6989772,
33,Evaluation of data augmentation via synthetic images for improved breast mass detection on mammograms using deep learning,7,1,,"Cha Kenny H.,Petrick Nicholas,Pezeshk Aria,Graff Christian G.,Sharma Diksha,Badal Andreu,Sahiner Berkman","Cha KH,Petrick N,Pezeshk A,Graff CG,Sharma D,Badal A,Sahiner B",Cha KH,10.1117/1.JMI.7.1.012703,US Food & Drug Administration (FDA),"We evaluated whether using synthetic mammograms for training data augmentation may reduce the effects of overfitting and increase the performance of a deep learning algorithm for breast mass detection. Synthetic mammograms were generated using in silico procedural analytic breast and breast mass modeling algorithms followed by simulated x-ray projections of the breast models into mammographic images. In silico breast phantoms containing masses were modeled across the four BI-RADS breast density categories, and the masses were modeled with different sizes, shapes, and margins. A Monte Carlo-based x-ray transport simulation code, MC-GPU, was used to project the three-dimensional phantoms into realistic synthetic mammograms. 2000 mammograms with 2522 masses were generated to augment a real data set during training. From the Curated Breast Imaging Subset of the Digital Database for Screening Mammography (CBIS-DDSM) data set, we used 1111 mammograms (1198 masses) for training, 120 mammograms (120 masses) for validation, and 361 mammograms (378 masses) for testing. We used faster R-CNN for our deep learning network with pretraining from ImageNet using the Resnet-101 architecture. We compared the detection performance when the network was trained using different percentages of the real CBIS-DDSM training set (100%, 50%, and 25%), and when these subsets of the training set were augmented with 250, 500, 1000, and 2000 synthetic mammograms. Free-response receiver operating characteristic (FROC) analysis was performed to compare performance with and without the synthetic mammograms. We generally observed an improved test FROC curve when training with the synthetic images compared to training without them, and the amount of improvement depended on the number of real and synthetic images used in training. Our study shows that enlarging the training data with synthetic samples can increase the performance of deep learning systems. (C) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)","computer-aided detection,deep learning,breast mass detection,mammography,synthetic mammogram images,in silico imaging",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"COMPUTER-AIDED,DIAGNOSIS,SAMPLE-SIZE,PERFORMANCE,INSERTION",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6872953,
34,Deep convolutional neural networks in the classification of dual-energy thoracic radiographic views for efficient workflow: analysis on over 6500 clinical radiographs,7,1,,"Crosby Jennie,Rhines Thomas,Li Feng,MacMahon Heber,Giger Maryellen","Crosby J,Rhines T,Li F,MacMahon H,Giger M",Crosby J,10.1117/1.JMI.7.1.016501,University of Chicago,"DICOM header information is frequently used to classify medical image types; however, if a header is missing fields or contains incorrect data, the utility is limited. To expedite image classification, we trained convolutional neural networks (CNNs) in two classification tasks for thoracic radiographic views obtained from dual-energy studies: (a) distinguishing between frontal, lateral, soft tissue, and bone images and (b) distinguishing between posteroanterior (PA) or anteroposterior (AP) chest radiographs. CNNs with AlexNet architecture were trained from scratch. 1910 manually classified radiographs were used for training the network to accomplish task (a), then tested with an independent test set (3757 images). Frontal radiographs from the two datasets were combined to train a network to accomplish task (b); tested using an independent test set of 1000 radiographs. ROC analysis was performed for each trained CNN with area under the curve (AUC) as a performance metric. Classification between frontal images (AP/PA) and other image types yielded an AUC of 0.997 [95% confidence interval (CI): 0.996, 0.998]. Classification between PA and AP radiographs resulted in an AUC of 0.973 (95% CI: 0.961, 0.981). CNNs were able to rapidly classify thoracic radiographs with high accuracy, thus potentially contributing to effective and efficient workflow. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","thoracic radiographs,deep learning,dual-energy,DICOM header,workflow,convolutional neural networks",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,,JOURNAL OF MEDICAL IMAGING,https://europepmc.org/articles/pmc6995870?pdf=render,
35,Deep learning-based segmentation of malignant pleural mesothelioma tumor on computed tomography scans: application to scans demonstrating pleural effusion,7,1,,"Gudmundsson Eyjolfur,Straus Christopher M.,Li Feng,Armato Samuel G. III","Gudmundsson E,Straus CM,Li F,Armato SG",Armato SG,10.1117/1.JMI.7.1.012705,University of Chicago,"Tumor volume is a topic of interest for the prognostic assessment, treatment response evaluation, and staging of malignant pleural mesothelioma. Many mesothelioma patients present with, or develop, pleural fluid, which may complicate the segmentation of this disease. Deep convolutional neural networks (CNNs) of the two-dimensional U-Net architecture were trained for segmentation of tumor in the left and right hemithoraces, with the networks initialized through layers pretrained on ImageNet. Networks were trained on a dataset of 5230 axial sections from 154 CT scans of 126 mesothelioma patients. A test set of 94 CT sections from 34 patients, who all presented with both tumor and pleural effusion, in addition to a more general test set of 130 CT sections from 43 patients, were used to evaluate segmentation performance of the deep CNNs. The Dice similarity coefficient (DSC), average Hausdorff distance, and bias in predicted tumor area were calculated through comparisons with radiologist-provided tumor segmentations on the test sets. The present method achieved a median DSC of 0.690 on the tumor and effusion test set and achieved significantly higher performance on both test sets when compared with a previous deep learning-based segmentation method for mesothelioma. (C) 2020 Society of Photo Optical Instrumentation Engineers (SPIE)","tumor segmentation,deep learning,computed tomography,malignant pleural mesothelioma,convolutional neural networks",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"NEURAL-NETWORKS,CT,MANIFESTATIONS,CISPLATIN,DIAGNOSIS,UPDATE",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6987258,
36,Quantitative and qualitative evaluation of deep learning automatic segmentations of corneal endothelial cell images of reduced image quality obtained following cornea transplant,7,1,,"Joseph Naomi,Kolluru Chaitanya,Benetz Beth A. M.,Menegay Harry J.,Lass Jonathan H.,Wilson David L.","Joseph N,Kolluru C,Benetz BAM,Menegay HJ,Lass JH,Wilson DL",Wilson DL,10.1117/1.JMI.7.1.014503,Case Western Reserve University,"We are developing automated analysis of corneal-endothelial-cell-layer, specular microscopic images so as to determine quantitative biomarkers indicative of corneal health following corneal transplantation. Especially on these images of varying quality, commercial automated image analysis systems can give inaccurate results, and manual methods are very labor intensive. We have developed a method to automatically segment endothelial cells with a process that included image flattening, U-Net deep learning, and postprocessing to create individual cell segmentations. We used 130 corneal endothelial cell images following one type of corneal transplantation (Descemet stripping automated endothelial keratoplasty) with expert-reader annotated cell borders. We obtained very good pixelwise segmentation performance (e.g., Dice coefficient = 0.87 +/- 0.17, Jaccard index = 0.80 +/- 0.18, across 10 folds). The automated method segmented cells left unmarked by analysts and sometimes segmented cells differently than analysts (e.g., one cell was split or two cells were merged). A clinically informative visual analysis of the held-out test set showed that 92% of cells within manually labeled regions were acceptably segmented and that, as compared to manual segmentation, automation added 21% more correctly segmented cells. We speculate that automation could reduce 15 to 30 min of manual segmentation to 3 to 5 min of manual review and editing. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","deep learning,endothelial cell segmentation,cornea",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"SPECULAR-MICROSCOPY,GRAFT,FAILURE",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7019185,
37,Toward point-of-care ultrasound estimation of fetal gestational age from the trans-cerebellar diameter using CNN-based ultrasound image analysis,7,1,,"Maraci Mohammad A.,Yaqub Mohammad,Craik Rachel,Beriwal Sridevi,Self Alice,von Dadelszen Peter,Papageorghiou Aris,Noble J. Alison","Maraci MA,Yaqub M,Craik R,Beriwal S,Self A,von Dadelszen P,Papageorghiou A,Noble JA",Noble JA,10.1117/1.JMI.7.1.014501,University of Oxford,"Obstetric ultrasound is a fundamental ingredient of modern prenatal care with many applications including accurate dating of a pregnancy, identifying pregnancy-related complications, and diagnosis of fetal abnormalities. However, despite its many benefits, two factors currently prevent wide-scale uptake of this technology for point-of-care clinical decision-making in low- and middle-income country (LM IC) settings. First, there is a steep learning curve for scan proficiency, and second, there has been a lack of easy-to-use, affordable, and portable ultrasound devices. We introduce a framework toward addressing these barriers, enabled by recent advances in machine learning applied to medical imaging. The framework is designed to be realizable as a point-of-care ultrasound (POCUS) solution with an affordable wireless ultrasound probe, a smartphone or tablet, and automated machine-learning-based image processing. Specifically, we propose a machine-learning-based algorithm pipeline designed to automatically estimate the gestational age of a fetus from a short fetal ultrasound scan. We present proof-of-concept evaluation of accuracy of the key image analysis algorithms for automatic head transcerebellar plane detection, automatic transcerebellar diameter measurement, and estimation of gestational age on conventional ultrasound data simulating the POCUS task and discuss next steps toward translation via a first application on clinical ultrasound video from a low-cost ultrasound probe. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","point-of-care ultrasound,prenatal health,machine learning,global health,gestational age",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"CROWN-RUMP,LENGTH,PREDICTION,LOCALIZATION,VIDEOS,SYSTEM",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6956669,
38,Anatomically consistent CNN-based segmentation of organs-at-risk in cranial radiotherapy,7,1,,"Mlynarski Pawel,Delingette Herve,Alghamdi Hamza,Bondiau Pierre-Yves,Ayache Nicholas","Mlynarski P,Delingette H,Alghamdi H,Bondiau PY,Ayache N",Mlynarski P,10.1117/1.JMI.7.1.014502,Inria,"Planning of radiotherapy involves accurate segmentation of a large number of organs at risk (OAR), i.e., organs for which irradiation doses should be minimized to avoid important side effects of the therapy. We propose a deep learning method for segmentation of OAR inside the head, from magnetic resonance images (MRIs). Our system performs segmentation of eight structures: eye, lens, optic nerve, optic chiasm, pituitary gland, hippocampus, brainstem, and brain. We propose an efficient algorithm to train neural networks for an end-to-end segmentation of multiple and nonexclusive classes, addressing problems related to computational costs and missing ground truth segmentations for a subset of classes. We enforce anatomical consistency of the result in a postprocessing step. In particular, we introduce a graph-based algorithm for segmentation of the optic nerves, enforcing the connectivity between the eyes and the optic chiasm. We report cross-validated quantitative results on a database of 44 contrast-enhanced Tl-weighted MRIs with provided segmentations of the considered OAR, which were originally used for radiotherapy planning. In addition, the segmentations produced by our model on an independent test set of 50 MRIs were evaluated by an experienced radiotherapist in order to qualitatively assess their accuracy. The mean distances between produced segmentations and the ground truth ranged from 0.1 to 0.7 mm across different organs. A vast majority (96%) of the produced segmentations were found acceptable for radiotherapy planning. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","segmentation,organs at risk,radiotherapy,convolutional neural networks,magnetic resonance image",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"EFFICIENT,ANATOMY,DETECTION,MODEL-BASED,SEGMENTATION,REGRESSION,FORESTS,LOCALIZATION,IMAGES,HEAD,RECOGNITION,VALIDATION,TUMOR",JOURNAL OF MEDICAL IMAGING,https://hal.inria.fr/hal-02181181/document,
39,Sprayed or Soaked Concealed Drug Detection using SWIR Hyperspectral Imaging,11392,,,"Wang Jihang,Krieger Evan,Zbur Lucas,Gilligan Joanne,Beideman Rick,Beckstead Jeffrey,Klueva Oksana,Conner Maria,Maney Erica,Treadoa Patrick","Wang JH,Krieger E,Zbur L,Gilligan J,Beideman R,Beckstead J,Klueva O,Conner M,Maney E,Treadoa P",Wang JH,10.1117/12.2556903,"ChemImage Corp, 7325 Penn Ave,Suite 200, Pittsburgh, PA 15208 USA.","The smuggling of drug into correctional facilities through the mail is a major concern. ChemImage has developed the VeroVision (TM) mail screener system, which highlights drugs from background based on score imagery computed from selected wavelengths based on the chemical signatures. More recently, sophisticated techniques to hide drugs by dissolution into paper are being used. We introduce a combined heterogeneous anomaly detection with a deep learning classifier. Anomaly detection initially extracts suspect stain patterns. A You Only Look Once (YOLO) based classifier then classifies anomalies as drug or non-drug stain patterns. We report its first successful detection on a limited set of meth samples, with 87.4% probability of detection (PD) and 7.0% probability of false alarm (PFA). The results show that widefield, multispectral short-field infrared (SWIR) imaging can allow for dissolved concealed drug screening of mail which has benefits for mail inspection efficiency and accuracy.","Drug detection,hyperspectral data,Short-wave infrared imaging,convolutional neural networks",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Optics,Imaging Science & Photographic Technology",,,,,,
40,Medical image fusion via discrete wavelet transform and fuzzy radial basis function neural network,11515,,,"Chao Zhen,Kim Hee-joung","Chao Z,Kim HJ",Kim HJ,10.1117/12.2566605,Yonsei University,"With the rapid development of computer technology and the advent of the information age, diverse medical imaging devices are emerging. However, limited by imaging principles, single-mode images have their own advantages and disadvantages, and it is difficult to fully express all practical information, causing the limitations of diagnosis. Accordingly, medical image fusion is inevitable trend which could integrate or highlight the complementary information, achieve enhanced image quality, reduce redundancy, and provide a reliable diagnosis. In the past, there were many methods that were proposed, but the effect was largely dependent on the experimental data. Based on this, in this study, we proposed a new image fusion method based on discrete wavelet transform (DWT) and fuzzy radial basis function neural network (FRBFNN). First, we analyzed the details or feature information of two images to be processed by DWT. Here, we used a 2-level decomposition, so that each image was decomposed into 7 parts including high frequency sub-bands and low frequency sub-bands. Subsequently, for the parts of the same position of the two images, we substituted them to the proposed FRBFNN. So, with the operation of these seven neural networks, we obtained seven fused parts in turn. Finally, through the inverse wavelet transform, we could get the final fused image. For the training method of neural network, we adopted the combination of error backpropagation algorithm and gravity search algorithm. The final experimental results demonstrated that our method performed significantly better than other algorithms.","Medical image fusion,Discrete wavelet transform,Fuzzy radial basis function neural network",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Optics,Imaging Science & Photographic Technology",,,,,,
41,Radiomic Feature-based Prediction Model of Lung Cancer Recurrence in NSCLC Patients,11515,,,"Lee Soomin,Jung Julip,Hong Helen,Kim Bongseok","Lee S,Jung J,Hong H,Kim B",Hong H,10.1117/12.2566451,Seoul Women's University,"This study investigates the potential of a radiomic feature-based prediction model of non-small cell lung cancer (NSCLC) recurrence within two years on chest CT images. First, tumor areas are defined as intra-tumoral areas that have been manually segmented by a radiologist and the largest tumor ROI are selected as the representative cross-section. Second, a total of 68 radiomic features including intensity, texture and shape features are extracted within the tumor area. Then, three features with weights that are clearly distinguished from other weights are defined as significant features using the Relief-F algorithm. Finally, to predict lung cancer recurrence within two years, random forests and SVM are trained for the classification of two groups representing recurrence and non-recurrence within two years. In the experimental results, since the accuracy, sensitivity, specificity, and AUC were 71.42, 80.95, 61.90, and 0.74 for random forest and were 66.66, 61.90, 71.42 and 0.65 for SVM, the prediction model constructed by the random forest shows better performance. Kaplan-meier curve that fitted with seperated patients shows the estimated probability by radiomic-based prediction model.","Radiomic feature,relapse-free survival prediction,recurrence,non-small cell lung cancer,chest CT images",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Optics,Imaging Science & Photographic Technology",,,,,,
42,A Study on Liver Tumor Detection from an Ultrasound Image using Deep Learning,11515,,,"Nakashima Takahiro,Tsutsumi Issei,Takami Hiroki,Doman Keisuke,Mekada Yoshito,Nishida Naoshi,Kudo Masatoshi","Nakashima T,Tsutsumi I,Takami H,Doman K,Mekada Y,Nishida N,Kudo M",Nakashima T,10.1117/12.2566913,Chukyo University,"The ultrasound examination is a difficult operation because a doctor not only operates an ultrasound scanner but also interprets images in rea time, which may increase the risk of overlooking tumors. To prevent that, we study a liver tumor detection method using convolutional neural networks toward realizing computer-assisted diagnosis systems. In this paper, we propose a liver tumor detection method within a false positive reduction framework. The proposed method uses YOLOv3 [1] in order to find tumor candidate regions in real-time, and also uses VGG16 [2] to reduce false positives. The proposed method using YOLOv3 [1] and VGG16 [2] achieved an F-measure of 0.837, which showed the effectiveness of the proposed method for liver tumor detection. Future work includes the collection of training data from more hospitals and their effective use for improving the detection accuracy.","liver tumor detection,CAD,ultrasound image,convolutional neural network",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Optics,Imaging Science & Photographic Technology",,,,,,
43,A web based computer aided diagnosis system on liver disease,11515,,,"Zhang Xuejun,Huang Ju,Huang Huining,Li Bijiang,Liang Binmei,Wu Dongbo,Sun Yinghua","Zhang XJ,Huang J,Huang HN,Li BJ,Liang BM,Wu DB,Sun YH",Zhang XJ,10.1117/12.2566367,Guangxi University,"Computer aided diagnosis (CAD) system has been proven to be useful in clinical routine. However, different kinds of software installed in different machine limits the widely usage of CAD by doctors. We transfer our previous CAD system on liver disease into a web based program to enable users to diagnose potential hepatic abnormalities through internet, by using XOJO platform which is easy to make web application under BASIC programming language and provide virtual server function when in running mode. There methods for tumor classification are investigated on web programming: GLCM-ANN, Restricted Boltzmann Machine (RBM) w/o edge computing. The result shows that deep learning has better performance to conventional ANN, but the large weight matrix is a big burden of web response speed without edge computing. Our CAD system can be easily open on different OS and any location with network connection. Such convenience makes diagnosis less time consuming while significantly collecting datasets via internet from different hospitals or even patient him/herself.","Computer aided diagnosis,web,liver disease,edge computing",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Optics,Imaging Science & Photographic Technology",,,CT,,,
44,A Study on Thermal Image Generation Based on Deep Learning and Abnormal Temperature Detection,11515,,,"Zhang Ziyun,Hasegawa Makoto","Zhang ZY,Hasegawa M",Zhang ZY; Hasegawa M,10.1117/12.2566922,Tokyo Denki University,"A thermal image taken by a thermal camera and an RGB color picture were arranged in a dataset pair; the datasets were learned using a deep learning algorithm called pix2pix. After the sufficient training in the machine learning, it was possible to generate a thermal image from a color image taken with a digital camera. This paper provides a new method of generating thermal image without a thermal camera; the thermal camera is required when we create training materials. Furthermore, a method for detecting abnormal temperatures using deep learning is proposed. Features of thermal images are concerned and evaluated the results of our method.","thermal image,RGB color image,deep learning,pix2pix,abnormal temperature detection",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Optics,Imaging Science & Photographic Technology",,,,,,
45,Differential diagnosis of paraffin-embedded tissues by IR-THz spectroscopy and machine learning,11363,,,"Kistenev Yury V,Borisov Alexey V,Knyazkova Anastasia I,Nikolaev Viktor V.,Samarinova Alica A.,Navolokin Nikita A.,Tuchina Daria K.,Tuchin Valery V.","Kistenev YV,Borisov AV,Knyazkova AI,Nikolaev VV,Samarinova AA,Navolokin NA,Tuchina DK,Tuchin VV",Kistenev YV,10.1117/12.2555632,Tomsk State University,"The ability of diagnostics of melanoma and nevus based on spectral analysis of paraffin-embedded tissues in the 0.3-1.5 terahertz (THz) range has been carried out. The principal component analysis was applied to reduce the dimension of the feature space. A comparison of these spectra shows evident differences between samples.
The possibility of applying the optical clearing to paraffin-embedded tissue for improving the visualization of the internal structure of tissue for diagnostic and research purposes is shown. In the studies, a sufficiently strong effect of optical clearing of paraffin-embedded muscle was obtained (63%).","paraffin-embedded tissue biopsy,cancer,MPM microscopy,THz spectroscopy,optical coherence tomography,tissue optical clearing,machine learning",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"CANCER,MICROSCOPY",,,
46,Syndrome-aware Herb Recommendation with Multi-Graph Convolution Network,,,145-156,"Jin Yuanyuan,Zhang Wei,He Xiangnan,Wang Xinyu,Wang Xiaoling","Jin YY,Zhang W,He XN,Wang XY,Wang XL",Wang XL,10.1109/ICDE48307.2020.00020,East China Normal University,"Herb recommendation plays a crucial role in the therapeutic process of Traditional Chinese Medicine (TCM), which aims to recommend a set of herbs to treat the symptoms of a patient. While several machine learning methods have been developed for herb recommendation, they are limited in modeling only the interactions between herbs and symptoms, and ignoring the intermediate process of syndrome induction. When performing TCM diagnostics, an experienced doctor typically induces syndromes from the patient's symptoms and then suggests herbs based on the induced syndromes. As such, we believe the induction of syndromes an overall description of the symptoms is important for herb recommendation and should be properly handled. However, due to the ambiguity and complexity of syndrome induction, most prescriptions lack the explicit ground truth of syndromes.
In this paper, we propose a new method that takes the implicit syndrome induction process into account for herb recommendation. Specifically, given a set of symptoms to treat, we aim to generate an overall syndrome representation by effectively fusing the embeddings of all the symptoms in the set, so as to mimic how a doctor induces the syndromes. Towards symptom embedding learning, we additionally construct a symptom-symptom graph from the input prescriptions for capturing the relations (co-occurred patterns) between symptoms; we then build graph convolution networks (GCNs) on both symptom-symptom and symptom-herb graphs to learn symptom embedding. Similarly, we construct a herb-herb graph and build GCNs on both herb-herb and symptom-herb graphs to learn herb embedding, which is finally interacted with the syndrome representation to predict the scores of herbs. The advantage of such a Multi-Graph GCN architecture is that more comprehensive representations can be obtained for symptoms and herbs. We conduct extensive experiments on a public TCM dataset, demonstrating significant improvements over state-of-the-art herb recommendation methods. Further studies justify the effectiveness of our design of syndrome representation and multiple graphs.","herb recommendation,symptom-herb graph,graph neural network,representation learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA",Computer Science,,,DIAGNOSIS,,http://arxiv.org/pdf/2002.08575,
47,DCDT: A Digital Clock Drawing Test System for Cognitive Impairment Screening,,,1762-1765,"Xu Feiyang,Ding Yue,Ling Zhenhua,Li Xin,Li Yunxia,Wang Shijin","Xu FY,Ding Y,Ling ZH,Li X,Li YX,Wang SJ",Li X,10.1109/ICDE48307.2020.00164,"iFlytek Co Ltd, iFlytek Res, Hefei, Peoples R China.","Alzheimer's disease is a chronic neurodegenerative disease that usually starts slowly and gradually worsens over time. Although there's no cure for Alzheimer's disease yet, a number of recent researches have shown that the early diagnosis and intervention could not only improve the quality of life but also help to slow the progression of the disease. Clock Drawing Test (CDT) is one of the commonly used clinical methods for screening cognitive impairment, due to its simplicity and convenience. In this paper, we'd like to introduce DCDT, a novel Clock Drawing Test system based on digital collection and intellectualized analysis. We first introduce the background of AD and CDT, and then describe the DCDT system from the external and internal aspects. Finally, the demonstration scenario is described briefly.","Digital Clock Drawing Test,Comprehensive Evaluation Index System,Machine Learning",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA",Computer Science,,,,,,
48,Diffusion Barrier Prediction of Graphene and Boron Nitride for Copper Interconnects by Deep Learning,8,,210542-210549,"Ahmed Manareldeen,Li Yan,Chen Wenchao,Li Er-Ping","Ahmed M,Li Y,Chen WC,Li EP",Li EP,10.1109/ACCESS.2020.3039257,Zhejiang University,"The continuous scaling-down size of interconnects should be accompanied with ultra-thin diffusion barrier layers, which is used to suppress Cu diffusion into the dielectrics. Unfortunately, conventional barrier layers with thicknesses less than 4 nm fail to perform well. With the advent of 2D layered materials, graphene and hexagonal boron nitride have been proposed as alternative Cu diffusion barriers with thicknesses of approximate to 1 nm. However, defects such as vacancies may evolve into a Cu diffusion path, which is a challenging problem in design of diffusion barrier layers. The energy barrier of Cu atom diffused through a di-vacancy defect in graphene and hexagonal boron nitride is calculated by density functional theory. It is found that graphene offers higher energy barrier to Cu than hexagonal boron nitride. The higher energy barrier is attributed to the stronger interaction between Cu and C atoms in graphene as shown by charge density difference and Bader's charge. Furthermore, we use the energy barriers of different vacancy structures and generate a dataset that will be used for machine learning. Our trained convolutional neural network is used to predict the energy barrier of Cu migration through randomly configured defected graphene and hexagonal boron nitride with R-2 of > 99% for 4 x 4 supercell. These results provide guides on choosing between 2D materials as barrier layers, and applying deep learning to predict the 2D barrier performance.","Machine learning,2D materials,Cu interconnects",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CU,DIFFUSION,STRESS,ADSORPTION,TRANSPORT,BEHAVIOR,TAN",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09264169.pdf,
49,DDeep3M-based Neuronal Cell Counting in 2D Large-scale Images,11190,,,"Kong Xianghan,Yan Shuai,Zhou Enze,Huang Jin,Wu Xinglong,Wang Ping,Chen Shangbin","Kong XH,Yan S,Zhou EZ,Huang J,Wu XL,Wang P,Chen SB",Chen SB,10.1117/12.2537797,Huazhong University of Science & Technology,"The number of neuronal cells is fundamentally important for brain functions. However, it can be difficult to obtain the accurate number of neuronal cells in large-scale brain imaging, which is nearly inevitable with traditional image segmentation techniques due to the low contrast and noisy background. Here, we introduce a Docker-based deep convolutional neural network (DDeep3M) for better counting neurons in the stimulated Raman scattering (SRS) microscopy images. To reconcile the memory limit of computational resource, a high-resolution 2D SRS image of whole coronal slice of mouse brain is divided into multiple patch images. Each patch image is then fed into the DDeep3M and predicted as a probability map. A higher contrast image targeting neurons (i.e. the predicted image) can be acquired by stitching the patches of probability map together. With this routine segmentation method applied in both raw SRS image and the predicted image, the DDeep3M achieves the accuracy of over 0.96 for cell counting which is much better than the result of traditional segmentation methods. Compared with the U-Net, which is one of the most popular deep learning networks for medical image segmentation, DDeep3M demonstrates a better result when handling such large-scale image. Thus, DDeep3M can be really helpful for large-scale cell counting in brain research.","DDeep3M,segmentation,deep learning,cell counting,brain,ImageJ,large scale",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,,,,
50,3-D super-resolution localization microscopy using deep learning method,11190,,,"Lu Mengyang,Zhou Tianyang,Liu Xin","Lu MY,Zhou TY,Liu X",Liu X,10.1117/12.2538577,Shanghai University,"Super-resolution localization microscopy (SRLM) techniques overcome the diffraction limit, making possible the observation of sub-cellular structures in vivo. At present, the spatial resolution of similar to 20 nm in x-y axis has been achieved in SRLM. However, the localization accuracy for the longitudinal axis (i.e., the z-axis) still need be improved. Although some methods have been proposed to implement 3-D SRLM, these methods are computationally intensive and parameter dependent. To overcome these limitations, in this paper, we propose a new method based on deep learning, termed as dl-3D-SRLM. By learning the mapping between a 2-D camera frame (i.e., the experimentally acquired image) and the true 3-D locations of fluorophores in the corresponding image region with a convolutional neural network (CNN), dl-3D-SRLM provides the possibility of implementing 3-D SRLM with a high localization accuracy, a fast data-processing speed, and a little human intervention. To evaluate the performance of dl-3D-SRLM, a series of numerical simulations are performed. The results show that when using dl-3D-SRLM, we can accurately resolve the 3-D location of fluorophores from the acquired 2-D images, even if under high fluorophores densities and low signal-to-noise ratio conditions. In addition, the complex 3-D structure can also be effectively imaged by dl-3D-SRLM. As a result, dl-3D-SRLM is more beneficial for 3D-SRLM imaging.","Super-resolution localization microscopy,convolutional neural networks,imaging reconstruction,deep learning,3-D imaging",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"FLUORESCENCE,MICROSCOPY",,,
51,Automatic detection of leukemia cells by 2D light scattering microfluidic cytometry and deep learning,11190,,,"Sun Jing,Wang Lan,Liu Qiao,Su Xuantao","Sun J,Wang L,Liu Q,Su XT",Su XT,10.1117/12.2537094,Shandong University,"Leukemia is a worldwide malignant tumor with high morbidity and mortality. Developing screening methods for leukemia cells is of great significance for clinical diagnosis. Traditional biochemical and immunohistochemical detection methods that usually require fluorescence labeling are time-consuming and labor-intensive. Here we report a deep learning based 2D light scattering cytometric technique for high-precision, automatic and label-free identification of lymphocytic leukemia cells. A deep convolutional neural network (CNN) is used for learning the biological characteristics of 2D light scattering patterns. The Inception V3 network can identify different label-free acute lymphocytic leukemia cells with a high accuracy. The results show that the deep learning based 2D light scattering microfluidic cytometry is promising for early diagnosis of leukemia, and has the advantages of label free, high efficiency and high automation.","Microfluidic cytometry,label-free,deep learning,2D light scattering,lymphocytic leukemia detection",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Engineering,Optics,Radiology, Nuclear Medicine & Medical Imaging",,,"CLASSIFICATION,NUCLEI,ORGANIZATION,FRAMEWORK,PATTERNS",,,
52,Deep learning-based crack detection in a concrete tunnel structure using multispectral dynamic imaging,11382,,,"Ali Rahmat,Zeng Jiangyu,Cha Young-Jin","Ali R,Zeng JY,Cha YJ",Ali R,10.1117/12.2557900,University of Manitoba,"A new computer vision-based method is proposed for concrete crack detection in tunnel structures using multi-spectral dynamic imaging (MSX). The MSX images were collected from a tunnel in the University of Manitoba, Canada. A total of 3600 MSX images (299 x 299 pixels) were used to train the modified deep inception neural network (DINN), and an additional 300 MSX images (299 x 299 pixels) were employed for validation purposes. The MSX images were examined by the trained neural network for concrete crack detection. The main purpose of this research was to examine the potential of the neural network to distinguish between noise and concrete surface cracks in the MSX images. A fully connected layer and a softmax layer were added to the DINN network in the transfer learning section to reduce the network computation cost. The proposed network used green bounding boxes to detect the portions with cracks in the MSX images. A training accuracy of 95.5% and a validation accuracy of 94% were achieved at 1600 iterations. The optimum training steps obtained from the training and validation were used for testing purposes. The robustness of the trained network was evaluated using an additional 96 MSX images (640 x 480 pixels). A maximum testing accuracy of 94% was recorded when the prediction probability was limited to 90%.","Concrete tunnels,deep inception neural network,multi-spectral dynamic imaging,deep learning,computer vision",Proceedings Paper,"SPIE-INT SOC OPTICAL ENGINEERING, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA","Computer Science,Energy & Fuels,Optics",,,"DAMAGE,DETECTION",,,
53,"Special Session - Emerging Memristor Based Memory and CIM Architecture: Test, Repair and Yield Analysis",,,,"Bishnoi Rajendra,Wu Lizhou,Fieback Moritz,Muench Christopher,Nair Sarath Mohanachandran,Tahoori Mehdi,Wang Ying,Li Huawei,Hamdioui Said","Bishnoi R,Wu LZ,Fieback M,Munch C,Nair SM,Tahoori M,Wang Y,Li HW,Hamdioui S",Bishnoi R,,Delft University of Technology,"Emerging memristor-based architectures are promising for data-intensive applications as these can enhance the computation efficiency, solve the data transfer bottleneck and at the same time deliver high energy efficiency using their normally-off/instant-on attributes. However, their storing devices are more susceptible to manufacturing defects compared to the traditional memory technologies because they are fabricated with new materials and require different manufacturing processes. Hence, in order to ensure correct functionalities for these technologies, it is necessary to have accurate fault modeling as well as proper test methodologies with high test coverage. In this paper, we propose technology specific cell-level defect modeling, accurate fault analysis and yield improvement solutions for memristor-based memory as well as Computation-In-Memory (CIM) architectures. Our overall contributions cover three abstraction levels, namely, device, architecture and system. First, we propose a device-aware test methodology in which we have introduced a key device-level characteristic to develop accurate defect model. Second, we demonstrate a yield analysis framework for memristor arrays considering reliability and permanent faults due to parametric variations and explore fault-tolerant solutions. Third, a lightweight on-line test and repair schemes is proposed for emerging CIM devices in machine learning applications.","STT-MRAM,DEFECTS,FAILURE,MODEL",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA","Computer Science,Engineering",,,"STT-MRAM,DEFECTS,FAILURE,MODEL",,,
54,Global neural network potential applications in heterogeneous catalysis,39,9,3433-3443,",","Ma Sicong,Liu Zhipan",,,Ma Sicong,"Heterogeneous catalysis demands new techniques and methods to characterize the structures of catalytic active centre and reaction intermediates from atomic scale. The recently developed global neural network potential (NNP) to explore catalyst structure is introduced, which has been implemented in the software of Large-scale Atomic Simulation with neural network Potential (LASP). The technical details of the NNP and its recent applications in heterogeneous catalysis are discussed. NNP can significantly reduce the calculation cost with comparable calculation accuracy to the ab-initio methods, with which many complex problems in heterogeneous catalysis can be solved. The success of NNP function in predicting the crystalline phase of materials, understanding the surface structure evolution of TiO_2 under high pressure of hydrogen and determining the active sites of ternary oxide are illustrated as examples. Finally, the limitations of NNP are discussed and its future research directions are pointed out as the estimation of material properties, the construction of NNP for multi-element system and the fitting of chemical reaction.","machine learning,; neural networks; density functional theory; stochastic surface walking; LASP software",Article,,,,,,,,
55,Novel EEG Sensor-Based Risk Framework for the Detection of Insider Threats in Safety Critical Industrial Infrastructure,8,,206222-206234,"Al Hammadi Ahmed Y.,Lee Dongkun,Yeun Chan Yeob,Damiani Ernesto,Kim Song-Kyoo,Yoo Paul D.,Choi Ho-Jin","Al Hammadi AY,Lee D,Yeun CY,Damiani E,Kim SK,Yoo PD,Choi HJ",Yeun CY,10.1109/ACCESS.2020.3037979,Khalifa University of Science & Technology,"The loss or compromise of any safety critical industrial infrastructure can seriously impact the confidentiality, integrity, or delivery of essential services. Research has shown that such threats often come from malicious insiders. To identify these insiders, survey- and electrocardiogram-based approaches have been proposed; however, these approaches cannot effectively detect or predict any malicious insiders. Recently, electroencephalograms (EEGs) have been suggested as a potential alternative to detect these potential threats. Threat detection using EEG would be highly reliable as it overcomes the limitations of the previous methods. This study proposes a proof of concept for a system wherein a model trained using a deep learning algorithm is employed to evaluate EEG signals to detect insider threats. The algorithm can classify different mental states based on four category risk matrices. In particular, it analyses brainwave signals using long short-term memory (LSTM) designed to remember the previous mental states of each insider and compare them with the current brain state for associated risk-level classification. To evaluate the performance of the proposed system, we performed a comparative analysis using logistic regression (LR)-a predictive analysis technique used to describe the relationship between one dependent binary variable and one or more independent variables-on the same dataset. The experimental results obtained suggest that LSTM can achieve a classification accuracy of more than 80% compared to LR, which yields a classification accuracy of approximately 51%.","Electroencephalography,Brain modeling,Security,Support vector machines,Safety,Feature extraction,Electrodes,Deep learning,EEG sensors,fitness evaluation,insider threats,LSTM,safety critical industrial infrastructure",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://doi.org/10.1109/access.2020.3037979,
56,A Systematic Review of Breast Cancer Detection Using Thermography and Neural Networks,8,,208922-208937,"Al Husaini Mohammed Abdulla Salim,Habaebi Mohamed Hadi,Hameed Shihab A.,Islam Md Rafiqul,Gunawan Teddy Surya","Al Husaini MAS,Habaebi MH,Hameed SA,Islam MR,Gunawan TS",Habaebi MH,10.1109/ACCESS.2020.3038817,International Islamic University Malaysia,"Breast cancer plays a significant role in affecting female mortality. Researchers are actively seeking to develop early detection methods of breast cancer. Several technologies contributed to the reduction in mortality rate from this disease, but early detection contributes most to preventing disease spread, breast amputation and death. Thermography is a promising technology for early diagnosis where thermal cameras employed are of high resolution and sensitivity. The combination of Artificial Intelligence (AI) with thermal images is an effective tool to detect early stage breast cancer and is foreseen to provide impressive predictability levels. This paper reviews systematically the related works employing thermography with AI highlighting their contributions and drawbacks and proposing open issues for research. Several different types of Artificial Neural Networks (ANNs) and deep learning models were used in the literature to process thermographic images of breast cancer, such as Radial Basis Function Network (RBFN), K-Nearest Neighbors (KNN), Probability Neural Network (PNN), Support Vector Machine (SVM), ResNet50, SeResNet50, V Net, Bayes Net, Convolutional Neural Networks (CNN), Convolutional and DeConvolutional Neural Networks (C-DCNN), VGG-16, Hybrid (ResNet-50 and V-Net), ResNet101, DenseNet and InceptionV3. Previous studies were found limited to varying the numbers of thermal images used mostly from DMR-IR database. In addition, analysis of the literature indicate that several factors do affect the performance of the Neural Network used, such as Database, optimization method, Network model and extracted features. However, due to small sample size used, most of the studies achieved a classification accuracy of 80% to 100%.","Breast cancer,Breast,Cameras,Databases,Feature extraction,Artificial intelligence,Imaging,Artificial intelligent,breast cancer,thermal camera,deep convolutional neural network",Review,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"FEATURE-EXTRACTION,TEXTURE,FEATURES,IDENTIFICATION,DIAGNOSIS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09261422.pdf,
57,BAT Algorithm With fuzzy C-Ordered Means (BAFCOM) Clustering Segmentation and Enhanced Capsule Networks (ECN) for Brain Cancer MRI Images Classification,8,,201741-201751,"Alhassan Afnan M.,Zainon Wan Mohd Nazmee Wan","Alhassan AM,Zainon WMNW",Alhassan AM,10.1109/ACCESS.2020.3035803,Universiti Sains Malaysia,"Cancer is a second foremost life-threatening disease next to cardiovascular diseases. In particular, brain cancer holds the least rate of survival than all other cancer types. The categorization of a brain tumor depends upon the various factors such as texture, shape and location. The medical experts have preferred the appropriate treatment to the patients, based on the accurate identification of tumor type. The process of segmenting the Magnetic Resonance Imaging (MRI) has high complicacy during the analysis of brain tumor, owing to its variable shape, location, size, and texture. The physicians and radiologists can easily detect and categorize the tumors if there exists a system by combining Computer Assisted Diagnosis (CAD) as well as Artificial Intelligence (AI). An approach of automated segmentation has proposed in this paper, which enables the segmentation of tumor out of MRI images, besides enhances the efficiency of segmentation and classification. The initial functions of this approach include preprocessing and segmentation processes for segmenting tumor or tissue of benign and malignant by expanding a range of data and clustering. A modern learning-based approach has suggested in this study, in order to process the automated segmentation in multimodal MRI images to identify brain tumor, hence the clustering algorithm of Bat Algorithm with Fuzzy C-Ordered Means (BAFCOM) has recommended segmenting the tumor. The Bat Algorithm calculates the initial centroids and distance within the pixels in the clustering algorithm of BAFCOM, which also acquires the tumor through determining the distance among tumor Region of Interest (RoI) and non-tumor RoI. Afterwards, the MRI image has analyzed by the Enhanced Capsule Networks (ECN) method to categorize it as normal and brain tumor. Ultimately, the algorithm of ECN has assessed the performance of proposed approach by distinguishing the two categories of the tumor over MRI images, besides the suggested ECN classifier has assessed by the measurement factors of accuracy, precision, recall, and F1-score. In addition, the genetic algorithm has applied to process the automatic tumor stage classification, which in turn classification accuracy enhanced.","Machine learning,enhanced capsule networks (ECN),brain tumor,bat algorithm with fuzzy c-ordered means (BAFCOM),magnetic resonance imaging (MRI) images",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09247957.pdf,
58,Ensemble Convolutional Neural Networks With Knowledge Transfer for Leather Defect Classification in Industrial Settings,8,,198600-198614,"Aslam Masood,Khan Tariq M.,Naqvi Syed Saud,Holmes Geoff,Naffa Rafea","Aslam M,Khan TM,Naqvi SS,Holmes G,Naffa R",Aslam M,10.1109/ACCESS.2020.3034731,COMSATS University Islamabad (CUI),"Leather defect analysis is important for leather quality grading which directly effects the leather exports. Automated leather sample classification is vital due to slow and subjective nature of the manual process. The major challenges that exist in visual inspection of leather samples for categorization are: the morphology of defects significantly differs and their close examples are not available for transfer learning, unavailability of publicly available data and a benchmark. In this paper, we discuss three important aspects in the identification of industrial leather defects, i.e. the creation of an annotated wet-blue leather image dataset, the transfer of information from different domains to the leather image domain and the design of ensemble networks tailored to the task. We are therefore introducing a new database of wet-blue leather images (Wet-blue Leather Image Dataset (WBLID)) for the classification of defects along with expert annotation data. We proposed a new network EfficientNet-B3+ ResNext-101. The proposed EfficientNet-B3+ ResNext-101 ensemble architecture significantly outperforms all other state-of-the-art methods in terms of AUC and F1-score.","Feature extraction,Task analysis,Inspection,Visualization,Knowledge transfer,Deep learning,Training data,Leather defects,visual inspection,convolutional neural networks,transfer learning,classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://doi.org/10.1109/access.2020.3034731,
59,SIR-Net: Self-Supervised Transfer for Inverse Rendering via Deep Feature Fusion and Transformation From a Single Image,8,,201861-201873,"Bi Tianteng,Ma Junjie,Liu Yue,Weng Dongdong,Wang Yongtian","Bi TT,Ma JJ,Liu Y,Weng DD,Wang YT",Liu Y,10.1109/ACCESS.2020.3035213,Beijing Institute of Technology,"Measuring the material, geometry, and ambient lighting of surfaces is a key technology in the object's appearance reconstruction. In this article, we propose a novel deep learning-based method to extract such information to reconstruct the object's appearance from an RGB image. Firstly, we design new deep convolutional neural network architectures to improve the performance by fusing complementary features from hierarchical layers and different tasks. Then we generate a synthetic dataset to train the proposed model to tackle the problem of the absence of the ground-truth. To transfer the domain from the synthetic data to the specific real image, we introduce a self-supervised test-time training strategy to finetune the trained model. The proposed architecture only requires one image as input when inferring the material, geometry, and ambient lighting. The experiments are conducted to evaluate the proposed method on both the synthetic data and real data. The results show that our trained model outperforms the existing baselines in each task and presents obvious improvement in final appearance reconstruction, which verifies the effectiveness of the proposed methods.","Inverse rendering,attention,feature fusion,lighting recovery,deep learning,image-based rendering",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,REFLECTANCE,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09246498.pdf,
60,A Dynamic Filtering DF-RNN Deep-Learning-Based Approach for EEG-Based Neurological Disorders Diagnosis,8,,206992-207007,"Bouallegue Ghaith,Djemal Ridha,Alshebeili Saleh A.,Aldhalaan Hesham","Bouallegue G,Djemal R,Alshebeili SA,Aldhalaan H",Alshebeili SA,10.1109/ACCESS.2020.3037995,King Saud University,"Filtering of unwanted signals has a great impact on the performance of EEG signal processing applied to neurological disorders diagnosis. It is so difficult to remove undesirable noises using static filtering approaches as the performance of such techniques is strongly relying on specific EEG signal sub-bands, whose locations differ from one subject to another. In this paper, we present a novel dynamic filtering approach, which makes use of Finite and Infinite Impulse Response (FIR and IIR) filters along with a Recurrent Neural Networks using a Gated-Recurrent Unit (RNN-GRU), to identify and preprocess the most informative sub-bands pertaining to a particular neurological disorder. This combination of RNN with GRU requires more hidden layers than for conventional NN structures, and therefore offers much higher capacity to learn fitting and extract features from highly complex EEG data recording to afford better harmonization of the diagnosis process. Followed by an Independent Component Analysis (ICA) algorithm, all extracted features become independent to facilitate classification of clinical disorders using Convolutional Neural Network (CNN). The proposed diagnosis system achieves an average of 100% classification accuracy for epilepsy according to an offline diagnosis process using Bonn and MIT datasets, and when the same system is applied to autism provides an average accuracy of 99.5% using KAU dataset. The presented dynamic deep-learning approach applied to EEG classification pipeline, which includes artifact removal, feature extraction and classification, leads to significant improvements in the accuracy of the diagnosis classification regarding the targeted neurological pathologies.","Electroencephalography,Feature extraction,Autism,Epilepsy,Neurological diseases,Time-frequency analysis,Medical diagnostic imaging,Electroencephalography (EEG),deep learning,recurrent neural networks (RNN),convolutional neural network (CNN),dynamic filtering",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"NEURAL-NETWORK,COMPONENT,ANALYSIS,SEIZURE,DETECTION,AUTISM,CLASSIFICATION,ALGORITHMS,METHODOLOGY,FRACTALITY,TRANSFORM",IEEE ACCESS,https://doi.org/10.1109/access.2020.3037995,
61,A Novel Approach to Objectively Quantify the Subjective Perception of Pain Through Electroencephalogram Signal Analysis,8,,199920-199930,"Elsayed Mahmoud,Sim Kok Swee,Tan Shing Chiang","Elsayed M,Sim KS,Tan SC",Tan SC,10.1109/ACCESS.2020.3032153,Multimedia University,"Pain is a complex subjective unpleasant experience that can potentially cause tissue damage. In clinical practice, the main method used for assessing pain is self-report; however, it is not possibly adopted in a huge number of vulnerable populations or by non-communicative patients such as those with disorders of speech and consciousness. Thus, the availability of an objective measure of the subjective pain's perception that complements the self-report pain assessments is a great significant demand in several clinical applications. The aim of this paper is to propose a novel approach to objectively quantify the subjective perception of pain. We integrated signal processing techniques and machine learning principles to learn brain signals associated with pain and classify them into one of four pain intensities (no pain, low, moderate, and high). We found that the signal processing revealed a direct correlation between Alpha frequency band power and the pain intensity, and the classifier could achieve an accuracy of 94.83%. This study provides a clue for the betterment of the collective scientific understanding of the brain's activities inflicted by the physical pain and helps in building a reliable automated prediction of pain.","Pain,Electroencephalography,Signal processing,Containers,Machine learning,Correlation,Reliability,Physical pain,alpha frequency band,signal processing,artificial neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"EEG,OSCILLATIONS,THETA,SENSITIVITY,MATRIX",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09229386.pdf,
62,KEBOT: An Artificial Intelligence Based Comprehensive Analysis System for FUE Based Hair Transplantation,8,,200461-200476,"Erdogan Koray,Acun Onur,Kucukmanisa Ayhan,Duvar Ramazan,Bayramoglu Alp,Urhan Oguzhan","Erdogan K,Acun O,Kucukmanisa A,Duvar R,Bayramoglu A,Urhan O",Kucukmanisa A,10.1109/ACCESS.2020.3035637,Kocaeli University,"Robots and artificial intelligence technologies have become very important in the health applications as in many other fields. The proposed system in this work aims to provide detailed analysis of pre-op and post-op stage of FUE hair transplant procedures to enable surgeon to plan and assess success of the operations. In order to achieve this target, a robotic and vision-based system imaging and AI based analysis approach is developed. The proposed system performs analyses in three main stages: initialization, scanning, and analysis. At the initialization stage, 3D model of the patient's head generated at first by locating a depth camera in various positions around the patient by the help of a collaborative robot. At the second stage, where high resolution image capturing is performed in a loop with the usage of the 3D model, raw images are processed by a deep learning based object detection algorithm where follicles in pre-op and extracted follicle positions (i.e. holes) and placed grafts in post-op is detected. At the last stage, thickness of each hair is computed at the detected hair follicle positions using another deep learning-based segmentation approach. These data are combined to obtain objective evaluation criteria to generate patient report. Experimental results show that the developed system can be used successfully in hair transplantation operations.","FUE,hair transplantation,deep learning,artificial intelligence",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09247217.pdf,
63,Machine Learning Application With Quantitative Digital Subtraction Angiography for Detection of Hemorrhagic Brain Arteriovenous Malformations,8,,204573-204584,"Hong Jia-Sheng,Lin Chung-Jung,Lin Yue-Hsin,Lee Cheng-Chia,Yang Huai-Che,Meng Ling-Hsuan,Lin Te-Ming,Hu Yong-Sin,Guo Wan-Yuo,Chu Wei-Fa","Hong JS,Lin CJ,Lin YH,Lee CC,Yang HC,Meng LH,Lin TM,Hu YS,Guo WY,Chu WF",Wu YT,10.1109/ACCESS.2020.3036692,National Yang Ming Chiao Tung University,"Clinical features are the primary measures used for risk assessment of cerebrovascular diseases. However, clinical features, especially angioarchitecture, in digital subtraction angiography require further interpretation by specialized radiologists. This approach for risk assessment requires multivariable analysis and is, therefore, challenging when completed manually. In this study, we employed three machine learning models, namely the random forest, naive Bayes classifier, and support vector machine, for the detection of hemorrhagic brain arteriovenous malformations using digital subtraction angiography. Quantitative measurements from digital subtraction angiography were used as features, and the chi-squared test, minimum redundancy maximum relevance, ReliefF, and two-sample t tests were used for feature selection. Bayesian optimization was conducted to optimize the hyperparameters of the three models. The random forest model outperformed the other two models. As a human control, three radiologists diagnosed an independent testing data set. The random forest model had a computation time of less than a second for the whole data set for classification. Accuracy and the area under the receiver operating characteristic curve were 92.7% and 0.98 for the training data set and 85.7% and 0.97 for the independent testing data set, respectively. Compared with the mean diagnosis time of approximately half a minute per patient and the highest accuracy of 76.2% for the three radiologists, the random forest model was faster and more accurate for our data set. These results suggest that the machine learning model based on hemodynamic features from quantitative digital subtraction angiography is a promising tool for detecting hemorrhagic brain arteriovenous malformations.","Brain arteriovenous malformation,digital subtraction angiography,machine learning,quantitative analysis,rupture risk,time-density curve",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"VENOUS,DRAINAGE,TRANSIT-TIME,HEMODYNAMICS,DIAGNOSIS,CONTRAST,DSA",IEEE ACCESS,https://doi.org/10.1109/access.2020.3036692,
64,Explainable Prediction of Acute Myocardial Infarction Using Machine Learning and Shapley Values,8,,210410-210417,"Ibrahim Lujain,Mesinovic Munib,Yang Kai-Wen,Eid Mohamad A.","Ibrahim L,Mesinovic M,Yang KW,Eid MA",Yang KW,10.1109/ACCESS.2020.3040166,"New York Univ Abu Dhabi, Div Engn, Abu Dhabi, U Arab Emirates.","The early and accurate detection of the onset of acute myocardial infarction (AMI) is imperative for the timely provision of medical intervention and the reduction of its mortality rate. Machine learning techniques have demonstrated great potential in aiding disease diagnosis. In this paper, we present a framework to predict the onset of AMI using 713,447 extracted ECG samples and associated auxiliary data from the longitudinal and comprehensive ECG-ViEW II database, previously unexplored in the field of machine learning in healthcare. The framework is realized with two deep learning models, a convolutional neural network (CNN) and a recurrent neural network (RNN), and a decision-tree based model, XGBoost. Synthetic minority oversampling technique (SMOTE) was utilized to address class imbalance. High prediction accuracy of 89.9%, 84.6%, 97.5% and ROC curve areas of 90.7%, 82.9%, 96.5% have been achieved for the best CNN, RNN, and XGBoost models, respectively. Shapley values were utilized to identify the features that contributed most to the classification decision with XGBoost, demonstrating the high impact of auxiliary inputs such as age and sex. This paper demonstrates the promising application of explainable machine learning in the field of cardiovascular disease prediction.","Electrocardiography,Myocardium,Machine learning,Predictive models,Databases,Training,Feature extraction,Machine learning,biomedical informatics,predictive models,acute myocardial infarction",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SYMPTOM,PRESENTATION,ECG,DISEASE,SEX,AGE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09268965.pdf,
65,ELS-Net: A New Approach to Forecast Decomposed Intrinsic Mode Functions of Electricity Load,8,,198935-198949,"Javaid Nadeem,Naz Aqdas,Khalid Rabiya,Almogren Ahmad,Shafiq Muhammad,Khalid Adia","Javaid N,Naz A,Khalid R,Almogren A,Shafiq M,Khalid A",Almogren A,10.1109/ACCESS.2020.3034113,King Saud University,"The significance of electricity cannot be overlooked as all fields of life like material production, health care, educational sector, etc., depend upon it to render consistent and high-quality services, increase productivity and business continuity. To this end, energy operators have experienced a continuous increasing trend in the electricity demand for the past few decades. This may cause many issues like load shedding, increased electricity bills, imbalance between supply and demand, etc. Therefore, forecasting of electricity demand using efficient techniques is crucial for the energy operators to decide about optimal unit commitment and to make electricity dispatch plans. It also helps to avoid wastage as well as the shortage of energy. In this study, a novel forecasting model, known as ELS-net is proposed, which is a combination of an Ensemble Empirical Mode Decomposition (EEMD) method, multi-model Ensemble Bi Long Short-Term Memory (EBiLSTM) forecasting technique and Support Vector Machine (SVM). In the proposed model, EEMD is used to distinguish between linear and non-linear intrinsic mode functions (IMFs), EBiLSTM is used to forecast the non-linear IMFs and SVM is employed to forecast the linear IMFs. Using separate forecasting techniques for linear and non-linear IMFs decreases the computational complexity of the model. Moreover, SVM requires low computational time as compared to EBiLSTM for linear IMFs. Simulations are performed to examine the effectiveness of the proposed model using two different datasets: New South Wales (NSW) and Victoria (VIC). For performance evaluation, Root Mean Square Error (RMSE), Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) are used as performance metrics. From the simulation results, it is obvious that the proposed ELS-net model outperforms the start-of-the-art techniques, such as EMD-BILSTM-SVM, EMD-PSO-GA-SVR, BiLSTM, MLP and SVM in terms of forecasting accuracy and minimum execution time.","Forecasting,Time series analysis,Support vector machines,Computational modeling,Load forecasting,Predictive models,Deep learning,Smart grid,electricity consumption,decomposition,forecasting,deep learning,machine learning,seasonal data variations",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ARTIFICIAL,NEURAL-NETWORKS,SUPPORT,VECTOR,REGRESSION,CONDITIONAL,DEMAND,OPTIMIZATION,PREDICTION,NOISE",IEEE ACCESS,https://doi.org/10.1109/access.2020.3034113,
66,StomachNet: Optimal Deep Learning Features Fusion for Stomach Abnormalities Classification,8,,197969-197981,"Khan Muhammad Attique,Sarfraz Muhammad Shahzad,Alhaisoni Majed,Albesher Abdulaziz A.,Wang Shuihua,Ashraf Imran","Khan MA,Sarfraz MS,Alhaisoni M,Albesher AA,Wang SH,Ashraf I",Ashraf I,10.1109/ACCESS.2020.3034217,NITEC University,"A fully automated design is proposed in this work employing optimal deep learning features for classifying gastrointestinal infections. Here, three prominent infections- ulcer, bleeding, polyp and a healthy class are considered as class labels. In the initial stage, the contrast is improved by fusing bi-directional histogram equalization with top-hat filtering output. The resultant fusion images are then passed to ResNet101 pre-trained model and trained once again using deep transfer learning. However, there are challenges involved in extracting deep learning features including impertinent information and redundancy. To mitigate this problem, we took advantage of two metaheuristic algorithms- Enhanced Crow Search and Differential Evolution. These algorithms are implemented in parallel to obtain optimal feature vectors. Following this, a maximum correlation-based fusion approach is applied to fuse optimal vectors from the previous step to obtain an enhanced vector. This final vector is given as input to Extreme Learning Machine (ELM) classifier for final classification. The proposed method is evaluated on a combined database. It accomplished an accuracy of 99.46%, which shows significant improvement over preceding techniques and other neural network architectures.","Licenses,Stomach infections,contrast stretching,deep learning,optimization,fusion",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"WIRELESS,CAPSULE,ENDOSCOPY,GASTROINTESTINAL-DISEASES,ENHANCEMENT,CHALLENGES,IMAGES",IEEE ACCESS,https://doi.org/10.1109/access.2020.3034217,
67,Breast Mass Classification Using eLFA Algorithm Based on CRNN Deep Learning Model,8,,197312-197323,"Kim Chang-Min,Park Roy C.,Hong Ellen J.","Kim CM,Park RC,Hong EJ",Hong EJ,10.1109/ACCESS.2020.3034914,Yonsei University,"Breast cancer is known to be common in many developed countries. It is reported as the most common type of cancer in the US, affecting one in eight women. In Korea, thyroid cancer is the most common type of cancer, followed by breast cancer in women. Considering this, early detection and accurate diagnosis of breast cancer are crucial for reducing the associated death rate. Recently, cancer diagnosis systems using medical images have attracted significant attention. Medical imaging methods, such as computed tomography and magnetic resonance imaging, can reveal the overall shape, heterogeneity, and growth speed of carcinoma and are, thus, more commonly employed for diagnoses. Medical imaging has gained popularity since a recent study identified that it could reflect the gene phenotype of a patient. However, an aided diagnosis system based on medical images requires high-specification equipment to analyze high-resolution data. Therefore, this article proposes an edge extraction algorithm and a modified convolutional recurrent neural network (CRNN) model to accurately assess breast cancer based on medical imaging. The proposed algorithm extracts line-segment information from a breast mass image. The extracted line segments were classified into 16 types. Each type was uniquely labeled and compressed. The image compressed in this process was used as the input for the modified CRNN model. Traditional deep learning models were used to evaluate the performance of the proposed algorithm. The results show that the proposed model had the highest accuracy and lowest loss (99.75% and 0.0257, respectively).","Computer aided diagnosis system,line feature analysis,CRNN,breast cancer,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ULTRASOUND,IMAGES,TEXTURE,ANALYSIS,CANCER",IEEE ACCESS,https://doi.org/10.1109/access.2020.3034914,
68,Automated Maxillofacial Segmentation in Panoramic Dental X-Ray Images Using an Efficient Encoder-Decoder Network,8,,207822-207833,"Kong Zhengmin,Xiong Feng,Zhang Chenggang,Fu Zhuolin,Zhang Maoqi,Weng Jingxin,Fan Mingzhe","Kong ZM,Xiong F,Zhang CG,Fu ZL,Zhang MQ,Weng JX,Fan MZ",Xiong F,10.1109/ACCESS.2020.3037677,Wuhan University,"The panoramic dental X-ray images are an essential diagnostic tool used by dentists to detect the symptoms in an early stage and develop appropriate treatment plans. In recent years, deep learning methods have been applied to achieve tooth segmentation of dental X-rays, which aims to assist dentists in making clinical decisions. Because the original images contain plenty of useless information, it is necessary to extract the region-of-interest (ROI) to obtain more accurate results by focusing on the maxillofacial region. However, a fast and accurate maxillofacial segmentation without hand-crafted features is challenging due to the poor image quality. In this study, we create a large maxillofacial dataset and propose an efficient encoder-decoder network model named EED-Net to solve this problem. This dataset consists of 2602 panoramic dental X-ray images and corresponding segmentation masks annotated by the trained experts. Based on the original structure of U-Net, our model structure contains three major modules: a feature encoder, a corresponding decoder, and a multipath feature extractor that connects the encoding path and the decoding path. In order to obtain more semantic features from the depth and breadth, we replace the convolution layer with the residual block in the encoder and adopt Inception-ResNet block in the multipath feature extractor. Inspired by the skip connection in FCN-8s, the lightweight decoder has the same channel dimension as the number of segmented objects. Besides, a weighted loss function is used to enhance segmentation accuracy. The comprehensive experimental results on the new dataset demonstrate that our model achieves better accuracy and speed trade-offs for maxillofacial segmentation than the latest methods.","Image segmentation,X-ray imaging,Dentistry,Teeth,Feature extraction,Decoding,Annotations,Maxillofacial segmentation,panoramic radiographs,deep learning,encoder-decoder network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"TEETH,MODEL",IEEE ACCESS,https://doi.org/10.1109/access.2020.3037677,
69,Real-Time Ultrasound Image Despeckling Using Mixed-Attention Mechanism Based Residual UNet,8,,195327-195340,"Lan Yancheng,Zhang Xuming","Lan YC,Zhang XM",Zhang XM,10.1109/ACCESS.2020.3034230,Huazhong University of Science & Technology,"Ultrasound imaging has been widely used for clinical diagnosis. However, the inherent speckle noise will degrade the quality of ultrasound images. Existing despeckling methods cannot deliver sufficient speckle reduction and preserve image details well at high noise corruption and they cannot realize real-time ultrasound image denoising. With the popularity of deep learning, supervised learning for image denoising has recently attracted considerable attention. In this paper, we have proposed a novel residual UNet using mixed-attention mechanism (MARU) for real-time ultrasound image despeckling. In view of the signal-dependent characteristics of speckle noise, we have designed an encoder-decoder network to reconstruct the despeckled image by extracting features from the noisy image. Furthermore, a lightweight mixed-attention block is proposed to effectively enhance the image features and suppress some speckle noise during the encoding phase by using separation and re-fusion strategy for channel and spatial attention. Besides, we have graded the speckle noise levels with a certain interval and designed an algorithm to estimate the noise levels for despeckling real ultrasound images. Experiments have been done on the natural images, the synthetic image, the image simulated using Field II and the real ultrasound images. Compared with existing despeckling methods, the proposed network has achieved the state-of-the-art despeckling performance in terms of subjective human vision and such quantitative indexes as peak signal to noise ratio (PSNR), structural similarity (SSIM), equivalent number of looks (ENL) and contrast-to-noise ratio (CNR).","Ultrasonic imaging,Speckle,Real-time systems,Image denoising,Noise reduction,Deep learning,Feature extraction,Ultrasound image,speckle noise,supervised learning,mixed-attention mechanism,residual UNet",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SPECKLE,NOISE,CNN",IEEE ACCESS,https://doi.org/10.1109/access.2020.3034230,
70,Deep Learning in Skin Disease Image Recognition: A Review,8,,208264-208280,"Li Ling-Fang,Wang Xu,Hu Wei-Jian,Xiong Neal N.,Du Yong-Xing,Li Bao-Shan","Li LF,Wang X,Hu WJ,Xiong NN,Du YX,Li BS",Hu WJ; Du YX,10.1109/ACCESS.2020.3037258,Inner Mongolia University of Science & Technology,"The application of deep learning methods to diagnose diseases has become a new research topic in the medical field. In the field of medicine, skin disease is one of the most common diseases, and its visual representation is more prominent compared with the other types of diseases. Accordingly, the use of deep learning methods for skin disease image recognition is of great significance and has attracted the attention of researchers. In this study, we review 45 research efforts on the identification of skin disease by using deep learning technology since 2016. We analyze these studies from the aspects of disease type, data set, data processing technology, data augmentation technology, model for skin disease image recognition, deep learning framework, evaluation indicators, and model performance. Moreover, we summarize the traditional and machine learning-based skin disease diagnosis and treatment methods. We also analyze the current progress in this field and predict four directions that may become the research topic in the future. Our results show that the skin disease image recognition method based on deep learning is better than those of dermatologists and other computer-aided treatment methods in skin disease diagnosis, especially the multi deep learning model fusion method has the best recognition effect.","Deep learning,Analytical models,Image recognition,Skin,Data models,Medical diagnosis,Diseases,Deep learning,image recognition,review,skin disease",Review,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MALIGNANT-MELANOMA,ABCD,RULE,CLASSIFICATION,DIAGNOSIS,CANCER,DERMATOLOGISTS,DERMATOSCOPY,DERMOSCOPY,CHECKLIST,ALGORITHM",IEEE ACCESS,https://doi.org/10.1109/access.2020.3037258,
71,Identification of Colon Cancer Using Multi-Scale Feature Fusion Convolutional Neural Network Based on Shearlet Transform,8,,208969-208977,"Liang Meiyan,Ren Zhuyun,Yang Jiamiao,Feng Wenxiang,Li Bo","Liang MY,Ren ZY,Yang JM,Feng WX,Li B",Liang MY,10.1109/ACCESS.2020.3038764,Shanxi University,"Colon cancer identification is of great significance in medical diagnosis. Real-time, objective and accurate inspection results will facilitate medical professionals to explore symptomatic treatment promptly. However, the existing methods depend on hand-crafted features which require extensive professional expertise and long inspection period. Therefore, we propose a multi-scale feature fusion convolutional neural network (MFF-CNN) based on shearlet transform to identify histopathological image of colon cancer. The characteristic of the framework is the shearlet coefficients of histopathological image in multiple decomposition scales were extracted as supplementary feature which were also fed to the network with the original pathological image. After feature learning and feature fusion, the MFF-CNN based on shearlet transform can achieve the identification accuracy of 96% and average F-1 score of 0.9594 for colorectal adenocarcinoma epithelium (TUM) and normal colon mucosa (NORM). The false negative rate and false positive rate can be reduced to 5.5% and 2.5%, respectively. The superior performance of the network opens a new perspectives for real-time, objective and accurate diagnosis of cancer.","Feature extraction,Colon,Cancer,Transforms,Pathology,Training,Matrix decomposition,Colon cancer,shearlet transform,convolutional neural network,multi-scale feature fusion",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CLASSIFICATION,HYBRID",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09261395.pdf,
72,Esophagus Segmentation in Computed Tomography Images Using a U-Net Neural Network With a Semiautomatic Labeling Method,8,,202459-202468,"Lou Xiao,Zhu Youzhe,Punithakumar Kumaradevan,Le Lawrence H.,Li Baosheng","Lou X,Zhu YZ,Punithakumar K,Le LH,Li BS",Li BS,10.1109/ACCESS.2020.3035772,Southeast University - China,"Esophagus segmentation in computed tomography images is challenging due to the complex shape and low contrast of the esophagus. Fully automated segmentation is feasible with recent convolutional neural network approaches, such as U-Net, which reduce variability and increase reproducibility. However, these supervised deep learning methods require radiologists to laboriously interpret and label images, which is time-consuming, at the expense of patient care. We propose an esophagus segmentation method using a U-Net neural network combined with several variations of backbones. We also propose a semiautomatic labeling method with detection and execution components to solve the labeling problem. The detection component identifies the category to which each slice belongs using the bag-of-features method. The edges in each category are clustered using contour moments and their topological levels as features. In the execution component, the assumed esophageal contours are predicted by the clustered model. A convex hull approach and level set algorithm yield the final esophageal contours, which are employed to train the neural network. Several backbones are implemented as the encoder of the U-Net network to extract features. The predictions are then compared with those obtained via manual labeling by a radiologist and the segmentation results generated by the proposed semiautomatic method. The experimental evaluations demonstrate that the utilization of ResneXt50 and InceptionV3 as backbones with U-Net is more effective than that with other backbones. A three-dimensional rendering of the segmented model is performed to exhibit the prediction. The results demonstrate that the proposed method outperforms previously published methods.","Computed tomography,deep learning,esophagus,segmentation,U-Net",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,CANCER,IEEE ACCESS,https://doi.org/10.1109/access.2020.3035772,
73,Two Derivative Algorithms of Gradient Boosting Decision Tree for Silicon Content in Blast Furnace System Prediction,8,,196112-196122,"Luo Shihua,Chen Tianxin","Luo SH,Chen TX",Chen TX,10.1109/ACCESS.2020.3034566,Jiangxi University of Finance & Economics,"The background of the present study complies with silicon content prediction in hot metal in the blast furnace system. The blast furnace system is a highly complex industrial reactor in the conventional process. The system is subject to several problems (e.g., system automation, the thermal state of the blast furnace, and the life prediction of blast furnace) that should be addressed by professionals. To determine the prediction state of the heat in the blast furnace, the silicon content in the blast furnace molten iron commonly acts as a key indicator. Based on the assumption that the blast furnace system exhibits a stable state, the accuracy of hot metal silicon is analyzed by using a range of machine learning algorithms. In the present study, two derivative algorithms of gradient boosting decision tree are adopted to develop a strong boosting predictor based on the extreme gradient boosting (XGBoost) algorithm and the light gradient boosting machine (LightGBM) algorithm for prediction. Compared with the conventional algorithms (e.g., lasso, random forest, support vector machine and gradient boosting decision tree), the prediction by using the two boosting algorithms is capable of more effectively guiding and determining the state of the blast furnace. As revealed from experimentally simulated results, the mentioned two boosting algorithms exhibit better comprehensive prediction performance than the conventional algorithms on the datasets of two practical blast furnace systems, demonstrating that the R-square of the two blast furnaces in the training set is over 0.7. The mentioned two algorithms are of certain guiding significance for exploring blast furnace problems.","Prediction algorithms,Silicon,Iron,Blast furnaces,Predictive models,Boosting,Decision trees,XGBoost,LightGBM,gradient boosting decision tree,silicon content,blast furnace system",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ARTIFICIAL,NEURAL-NETWORK,MODEL,XGBOOST,MACHINE",IEEE ACCESS,https://doi.org/10.1109/access.2020.3034566,
74,Microelectronic CMOS Implementation of a Machine Learning Technique for Sensor Calibration,8,,207367-207376,"Martinez-Nieto Javier A.,Teresa Sanz-Pascual Maria,Medrano N.,Calvo Lopez Belen,Antolin Canada Diego","Martinez-Nieto JA,Sanz-Pascual MT,Medrano N,Lopez BC,Canada DA",Martinez-Nieto JA,10.1109/ACCESS.2020.3038052,University of Zaragoza,"An integrated machine-learning based adaptive circuit for sensor calibration implemented in standard 0.18 mu m CMOS technology with 1.8V power supply is presented in this paper. In addition to linearizing the device response, the proposed system is also capable to correct offset and gain errors. The building blocks conforming the adaptive system are designed and experimentally characterized to generate numerical high-level models which are used to verify the proper performance of each analog block within a defined multilayer perceptron architecture. The network weights, obtained from the learning phase, are stored in a microcontroller EEPROM memory, and then loaded into each of the registers of the proposed integrated prototype. In order to verify the proposed system performance, the non-linear characteristic of a thermistor is compensated as an application example, achieving a relative error e(r) below 3% within an input span of 130 degrees C, which is almost 6 times less than the uncorrected response. The power consumption of the whole system is 1.4mW and it has an active area of 0.86mm(2). The digital programmability of the network weights provides flexibility when a sensor change is required.","Calibration,CMOS technology,Machine learning,Power demand,Microelectronics,Semiconductor device modeling,Neurons,Adaptive signal processing,artificial neural networks,CMOS,sensor conditioning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"A%2FD,CONVERTER,LINEARIZATION",IEEE ACCESS,https://zaguan.unizar.es/record/97416/files/texto_completo.pdf,
75,A Machine Learning Approach to Perform Physical Activity Classification Using a Sensorized Crutch Tip,8,,210023-210034,"Mesanza Asier Brull,Lucas Sergio,Zubizarreta Asier,Cabanes Itziar,Portillo Eva,Rodriguez-Larrad Ana","Mesanza AB,Lucas S,Zubizarreta A,Cabanes I,Portillo E,Rodriguez-Larrad A",Mesanza AB,10.1109/ACCESS.2020.3039885,University of Basque Country,"In recent years, interest in monitoring Physical Activity (PA) has increased due to its positive effect on health. New technological devices have been proposed for this purpose, mainly focused on sports, which include Machine Learning algorithms to identify the type of PA being performed. However, PA monitoring can also provide data useful for assessing the recovery process of people with impaired lower-limbs. In this work, a Machine-Learning based Physical Activity classifier design procedure is proposed, which makes use of the data provided by a Sensorized Tip that can be adapted to different Assistive Devices for Walking (ADW) such as canes or crutches. The procedure is based on three main stages: 1) defining a wide set of potential features to perform the classification; 2) optimizing the number of features by a Random-Forest approach, detecting the most relevant ones to classify five relevant activities (walking at a normal pace, walking fast, standing still, going up stairs and going down stairs); 3) training the ML-based classifiers considering the optimized feature set. A comparative analysis is carried out to evaluate the proposed procedure, using three ML-based classifier (Support Vector Machines, K-Nearest Neighbour and Artificial Neural Networks), demonstrating that the proposed approach can provide very high success rates if proper feature selection is carried out. This work presents four relevant contributions to the PA monitoring area: 1) the approach is focused on people that require ADW, which are not considered in other approaches; 2) an analysis of the features to characterize gait in people that require ADW is carried out; 3) a design procedure to optimize the number of features using a Random-Forest approach is used, avoiding a typical ""brute force"" procedure; and 4) a comparative analysis is carried out to demonstrate the validity of the approach.","Monitoring,Feature extraction,Legged locomotion,Stairs,Performance evaluation,Force,Support vector machines,Instrumented crutch,rehabilitation,machine learning,physical activity classification,random forest,artificial neural network,support vector machine,K-nearest neighbor",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"QUALITY-OF-LIFE,ACTIVITY,RECOGNITION,MULTIPLE-SCLEROSIS,GAIT,IDENTIFICATION,MOVEMENT,MOBILITY,NETWORK,MOTION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09269370.pdf,
76,Accurate Detection of Septal Defects With Fetal Ultrasonography Images Using Deep Learning-Based Multiclass Instance Segmentation,8,,196160-196174,"Nurmaini Siti,Rachmatullah Muhammad Naufal,Sapitri Ade Iriani,Darmawahyuni Annisa,Jovandy Adithia,Firdaus Firdaus,Tutuko Bambang,Passarella Rossi","Nurmaini S,Rachmatullah MN,Sapitri AI,Darmawahyuni A,Jovandy A,Firdaus F,Tutuko B,Passarella R",Nurmaini S,10.1109/ACCESS.2020.3034367,Universitas Sriwijaya,"Accurate screening for septal defects is important for supporting radiologists' interpretative work. Some previous studies have proposed semantic segmentation and object detection approaches to carry out fetal heart detection; unfortunately, the models could not segment different objects of the same class. The semantic segmentation method segregates regions that only contain objects from the same class. In contrast, the fetal heart may contain multiple objects, such as the atria, ventricles, valves, and aorta. Besides, blurry boundaries (shadows) or a lack of consistency in the acquisition ultrasonography can cause wide variations. This study utilizes Mask-RCNN (MRCNN) to handle fetal ultrasonography images and employ it to detect and segment defects in heart walls with multiple objects. To our knowledge, this is the first study involving a medical application for septal defect detection using instance segmentation. The use of MRCNN architecture with ResNet50 as a backbone and a 0.0001 learning rate allows for two times faster training of the model on fetal heart images compared to other object detection methods, such as Faster-RCNN (FRCNN). We demonstrate a strong correlation between the predicted septal defects and ground truth as a mean average precision (mAP). As shown in the results, the proposed MRCNN model achieves good performance in multiclass detection of the heart chamber, with 97.59% for the right atrium, 99.67% for the left atrium, 86.17% for the left ventricle, 98.83% for the right ventricle, and 99.97% for the aorta. We also report competitive results for the defect detection of holes in the atria and ventricles via semantic and instance segmentation. The results show that the mAP for MRCNN is about 99.48% and 82% for FRCNN. We suggest that evaluation and prediction with our proposed model provide reliable detection of septal defects, including defects in the atria, ventricles, or both. These results suggest that the model used has a high potential to help cardiologists complete the initial screening for fetal congenital heart disease.","Image segmentation,Fetal heart,Echocardiography,Object detection,Ultrasonography,Congenital heart disease,fetal echocardiography,mask-RCNN,septal defects,multiclass instance segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,LOCALIZATION,IEEE ACCESS,https://doi.org/10.1109/access.2020.3034367,
77,An Adaptive Intelligence Algorithm for Undersampled Knee MRI Reconstruction,8,,204825-204838,"Pezzotti Nicola,Yousefi Sahar,Elmahdy Mohamed S.,Van Gemert Jeroen Hendrikus Fransiscus,Schuelke Christophe,Doneva Mariya,Nielsen Tim,Kastryulin Sergey,Lelieveldt Boudewijn P. F.,Van Osch Matthias J. P.","Pezzotti N,Yousefi S,Elmahdy MS,Van Gemert JHF,Schuelke C,Doneva M,Nielsen T,Kastryulin S,Lelieveldt BPF,Van Osch MJP",Pezzotti N,10.1109/ACCESS.2020.3034287,Philips,"Adaptive intelligence aims at empowering machine learning techniques with the additional use of domain knowledge. In this work, we present the application of adaptive intelligence to accelerate MR acquisition. Starting from undersampled k-space data, an iterative learning-based reconstruction scheme inspired by compressed sensing theory is used to reconstruct the images. We developed a novel deep neural network to refine and correct prior reconstruction assumptions given the training data. The network was trained and tested on a knee MRI dataset from the 2019 fastMRI challenge organized by Facebook AI Research and NYU Langone Health. All submissions to the challenge were initially ranked based on similarity with a known groundtruth, after which the top 4 submissions were evaluated radiologically. Our method was evaluated by the fastMRI organizers on an independent challenge dataset. It ranked #1, shared #1, and #3 on respectively the 8x accelerated multi-coil, the 4x multi-coil, and the 4x single-coil tracks. This demonstrates the superior performance and wide applicability of the method.","Image reconstruction,Magnetic resonance imaging,Acceleration,Coils,Training,Optimization,Image reconstruction,MRI,deep learning,ISTA,fastMRI challenge",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IMAGE-RECONSTRUCTION,NETWORK",IEEE ACCESS,http://arxiv.org/pdf/2004.07339,
78,Towards Classifying Cognitive Performance by Sensing Electrodermal Activity in Children With Specific Learning Disorders,8,,196187-196196,"Rico-Olarte Carolina,Lopez Diego M.,Becker Linda,Eskofier Bjoern","Rico-Olarte C,Lopez DM,Becker L,Eskofier B",Rico-Olarte C,10.1109/ACCESS.2020.3033769,Universidad del Cauca,"When children suffer from cognitive disorders, school performance and social environment are affected. Measuring changes in cognitive progress is essential for assessing the clinical follow-up of the patient's cognitive abilities. This process is considered as a challenge in ambulatory settings, where follow-ups should be non-invasive and continuous. Psychophysiological measures are an objective and unobtrusive evaluation alternative for recognizing cognitive changes. This paper aims to validate the relationship between cognition and the changes in physiological signals of children suffering from Specific Learning Disorders (SLD). This validation was carried out in an eHealth rehabilitation context (with the HapHop-Physio game). Electrodermal activity (EDA) signals were collected, processed, and analyzed through a machine learning approach. Obtained results were: a dataset built from wearable physiological data and a supervised classification model. The classification model can identify the children's cognitive performance (class) from the features of the tonic component of the EDA signal (attributes) with an accuracy of 79.95%. The presented results evidence that psychophysiological measures could allow for a highly objective follow-up for patients. They can also lead to creating a basis for further improvement of rehabilitation environments and developing neurofeedback applications.","Pediatrics,Physiology,Heart rate variability,Cognition,Biomedical monitoring,Sensors,Medical treatment,Electrodermal activity,cognitive performance,supervised classification,specific learning disorders",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"USER,EXPERIENCE,WORKLOAD,SPECTRUM,AROUSAL,GAMES",IEEE ACCESS,https://opus4.kobv.de/opus4-fau/files/15598/09239296.pdf,
79,Evaluating the Mental Workload During Robot-Assisted Surgery Utilizing Network Flexibility of Human Brain,8,,204012-204019,"Shafiei Somayeh B.);,Elsayed Ahmed S.);,Hussein Ahmed Aly);,Iqbal Umar);,Guru Khurshid A.","Shafiei SB,Elsayed AS,Hussein AA,Iqbal U,Guru KA",Guru KA,10.1109/ACCESS.2020.3036751,"Roswell Pk Comprehens Canc Ctr, Appl Technol Lab Adv Surg ATLAS, Buffalo, NY 14263 USA.","Mental Workload (MWL) is traditionally evaluated by psychophysiological signals using spectral analysis and event-related potentials. Robot-assisted Surgery (RAS) is a complex task that involves human-robot interaction, multitasking, quick and appropriate reactions to various stimuli and unforeseen circumstances, as well as frequent switches between surgical subtasks. There is a lack of standardized methodology for objectively monitoring a surgeon's MWL during RAS. In this study, we propose an innovative framework, using dynamic functional brain network measurements and a deep convolutional neural network, to assess MWL. A model was developed and validated using Electroencephalogram (EEG) data from 22 trainees who performed basic surgical tasks, as well as four surgical fellows and an expert surgeon who carried out cystectomies and prostatectomies. The resulting accuracies of the MWL classification into low, intermediate and high were 93%, 89%, and 91% respectively. The proposed method can be used for continually monitoring mental workload levels in an objective fashion.","Robot-assisted surgery,mental workload,brain functional network,convolutional neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,"DYNAMIC,RECONFIGURATION,EEG-ALPHA,SKILLS,OSCILLATIONS,PERFORMANCE,COGNITION,INDEXES",IEEE ACCESS,https://doi.org/10.1109/access.2020.3036751,
80,A Vision-Based Path Planning and Object Tracking Framework for 6-DOF Robotic Manipulator,8,,203158-203167,"Shahzad Adil,Gao Xueshan,Yasin Awais,Javed Kamran,Anwar Syed Muhammad","Shahzad A,Gao XS,Yasin A,Javed K,Anwar SM",Anwar SM,10.1109/ACCESS.2020.3037540,University of Engineering & Technology Taxila,"Industrial robots are widely used for repetitive, humanly unmanageable, and hazardous tasks. Hence, an improvement in the production efficiency of industrial robot manipulators is of prime concern. This can be achieved through machine vision and path planning techniques with a focus on localization and shortest path calculation. In particular, this is important for manufacturing and bottle filling industries which extensively use robotic manipulators to place/displace bottles during production and post refill placements. This is even more challenging when soft, fragile, or opaque objects have to be detected, since it is significantly difficult for robot vision to focus on their indistinguishable features. To this end, we present an ensemble robot framework with a stereo vision system for tracking colored objects which are sensed using blob analysis. An ensemble robotic framework with neural networks is proposed for predicting and thereby overcoming the inbuilt geometric error present in stereo vision systems. Moreover, we have simplified 2-D correspondence problem to 1-D by using a non-rectified stereo camera model and object tracking by applying the triangulation technique in 3D stereo vision coordinate system (SVCS). Subsequently, the SVCS is transformed into robot stereo vision coordinate system for tracking the object centroid by using an RGB marker placed on the object. Finally, in the learning model we have combined color region tracking with machine learning to achieve high accuracy. The outcomes are in accordance with the designed model and successfully achieve path prediction with up to 91.8% accuracy.","Robot stereo vision,path planning,robotic vision,robotic manipulators",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://doi.org/10.1109/access.2020.3037540,
81,Application of XGBoost for Hazardous Material Road Transport Accident Severity Analysis,8,,206806-206819,"Shen Xiaoyan,Wei Shanshan","Shen XY,Wei SS",Wei SS,10.1109/ACCESS.2020.3037922,Chang'an University,"Hazardous material road transport accidents pose a serious threat to public life, property and the environment. Therefore, studying the factors influencing road transport accidents involving hazardous materials can help identify the main causes behind them and contribute to the adoption of specific and targeted measures to reduce casualty rates and improve traffic safety. However, most existing research either adopted methods based on statistical analysis or neglected to further evaluate the spatial relationships. This study aims to use the eXtreme Gradient Boosting (XGBoost) algorithm to analyze hazardous material road transport accident data from seven regions of China. Considering the rarity of these events, the classification performance of different methods is compared based on precision, recall, F-score and Area Under Curve (AUC). The results indicate that the proposed XGBoost method has the best modeling performance. There is some variation between regions in the features that have a significant impact on accident severity. The influence of the same feature on the severity of an accident even varies from region to region. The aforementioned results provide a theoretical basis for exploring the issues, sustainability, challenges, and tasks of safe transportation activities for hazardous materials in the future. These results can help regions develop targeted prevention and response policies to efficiently reduce the incidence and severity of accidents.","Accidents,Roads,Hazardous materials,Data models,Analytical models,Vehicles,Feature analysis,hazardous materials,road transport accident,transport safety,XGBoost",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MACHINE,LEARNING-METHODS,CRASH,SEVERITY,DANGEROUS,GOODS,RISK,ANALYSIS,NETWORKS,DRIVERS,CHINA,RAIL",IEEE ACCESS,https://doi.org/10.1109/access.2020.3037922,
82,On Segmentation of Pectoral Muscle in Digital Mammograms by Means of Deep Learning,8,,204173-204182,"Soleimani Hossein,Michailovich Oleg V.","Soleimani H,Michailovich OV",Soleimani H,10.1109/ACCESS.2020.3036662,University of Waterloo,"Computer-aided diagnosis (CAD) has long become an integral part of radiological management of breast disease, facilitating a number of important clinical applications, including quantitative assessment of breast density and early detection of malignancies based on X-ray mammography. Common to such applications is the need to automatically discriminate between breast tissue and adjacent anatomy, with the latter being predominantly represented by pectoralis major (or pectoral muscle). Especially in the case of mammograms acquired in the mediolateral oblique (MLO) view, the muscle is easily confusable with some elements of breast anatomy due to their morphological and photometric similarity. As a result, the problem of automatic detection and segmentation of pectoral muscle in MLO mammograms remains a challenging task, innovative approaches to which are still required and constantly searched for. To address this problem, the present paper introduces a two-step segmentation strategy based on a combined use of data-driven prediction (deep learning) and graph-based image processing. In particular, the proposed method employs a convolutional neural network (CNN) which is designed to predict the location of breast-pectoral boundary at different levels of spatial resolution. Subsequently, the predictions are used by the second stage of the algorithm, in which the desired boundary is recovered as a solution to the shortest path problem on a specially designed graph. The proposed algorithm has been tested on three different datasets (i.e., MIAS, CBIS-DDSm, and InBreast) using a range of quantitative metrics. The results of comparative analysis show considerable improvement over state-of-the-art, while offering the possibility of model-free and fully automatic processing. The average values of dice similarity coefficient (DSC) and accuracy (ACC) on the mentioned three datasets are 97.22 +/- 1.96% and 99.64 +/-.27%, respectively.","Breast cancer,digital mammography,pectoral muscle,segmentation,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"IDENTIFICATION,BOUNDARY",IEEE ACCESS,https://doi.org/10.1109/access.2020.3036662,
83,"Pattern Recognition in Myoelectric Signals Using Deep Learning, Features Engineering, and a Graphics Processing Unit",8,,208952-208960,"Souza Gabriel Cirac M.,Moreno Robson L.,Pimenta Tales C.","Souza GCM,Moreno RL,Pimenta TC",Souza GCM,10.1109/ACCESS.2020.3038992,Universidade Federal de Itajuba,"Intelligent robotic prostheses employ pattern recognition techniques in their construction and, for this, adopt several approaches of Artificial Intelligence (AI). The study created a system called BioPatRec-Py (inspired by BioPatRec) that implements the Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) in a parallel hardware, using a lightweight architecture. The introduced system employed a set of strategies to make the classification process homogeneous, reduce training time and variability. The methodology fed the algorithm with features instead of the raw signal, providing the network with information that describes the movement (level of muscle activation, magnitude, amplitude, power, among others). The research utilized an adaptive Kaufman filter to remove noise from the series of features and adopted a quantile normalization system to make the distribution uniform and facilitate the training process. It was possible to train a generic network capable of operating in the entire population analyzed. Collective training is the main contribution of the research, as it allows the prosthesis to function on various individuals and potentially under different conditions. The individually evaluated networks reached 97.44% average accuracy with 0.69 seconds of training. The global model achieved an accuracy of 97.83% with a training time of 4.01 seconds.","Training,Feature extraction,Graphics processing units,Statistics,Sociology,Neural networks,Hardware,BioPatRec-Py,CNN,feature engineering,GPU,LSTM,myoelectric signal",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,,NEURAL-NETWORKS,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09262889.pdf,
84,The Cardiodynamicsgram Based Early Detection of Myocardial Ischemia Using the Lempel-Ziv Complexity,8,,207894-207904,"Sun Qinghua,Wang Qian,Ji Bing,Wu Weiming,Huang Weiyi,Wang Cong","Sun QH,Wang Q,Ji B,Wu WM,Huang WY,Wang C",Ji B; Wang C,10.1109/ACCESS.2020.3038210,Shandong University,"Background: Electrocardiogram (ECG) is a routine method for detecting myocardial ischemia in clinical practice, but more than half of ECGs are without specific ischemic changes. Cardiodynamicsgram (CDG) is an effective method to detect ischemia with non-diagnostic ECG. The Lyapunov exponent (LYE) and the Fourier transform coefficient are combined to characterize the spatial and temporal features of CDG. However, in some cases, the Lyapunov exponent does not accurately enough describe the degree of irregular morphology of CDG for ischemic patients. In this context, this study aims to improve the characterization of CDG using the Lempel-Ziv (LZ) complexity instead of the Lyapunov exponent. Methods: The cardiodynamics information inside ECG is extracted via deterministic learning from the ST-T segments of ECG and then the CDG is generated by plotting the extracted three-dimensional cardiodynamics information. The Lyapunov exponent and LZ complexity are calculated from CDG and coupled with the Fourier transform coefficient respectively to construct the LYE model and LZ model for detecting myocardial ischemia. Results: 393 subjects presenting non-diagnostic ECG are enrolled in the study. 312 of them are ischemic patients selected as the myocardial ischemia group, and the other 81 non-ischemic subjects are selected as the healthy control group. The average sensitivity, specificity, and accuracy of the LYE model and the LZ model are 90.7% vs 93.4%, 86.4% vs 86.8%, and 89.0% vs 90.8%, respectively. Meanwhile, the proposed method achieves better performance on the PTB database than most of the previous studies in detecting ischemia or infarction. Conclusion: The results indicate that LZ complexity can accurately characterize the cases that cannot be accurately depicted by Lyapunov exponent, and the corresponding model is more accurate for the early detection of myocardial ischemia.","Myocardium,Complexity theory,Electrocardiography,Feature extraction,Indexes,Time series analysis,Sun,Cardiodynamicsgram,Lempel-Ziv complexity,myocardial ischemia,deterministic learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ECG,SIGNALS,INFARCTION,IDENTIFICATION,LOCALIZATION,VARIABILITY,DYNAMICS,ENERGY",IEEE ACCESS,https://doi.org/10.1109/access.2020.3038210,
85,ResWnet for Retinal Small Vessel Segmentation,8,,198265-198274,"Tang Yu,Rui Zhiyuan,Yan Changfeng,Li Jingjun,Hu Jingpeng","Tang Y,Rui ZY,Yan CF,Li JJ,Hu JP",Rui ZY,10.1109/ACCESS.2020.3032453,Lanzhou University of Technology,"U-Net shows excellent performance in biomedical image segmentation tasks, Variants of U-Net have been proposed, such as U-Net with residual blocks, densely connected convolution, or deformed convolution. However, contracting path of these variants is containing four consecutive downsampling layers and an encoding-decoding structure with skip connections. The feature map transformation paths are limited. Therefore, ResWnet is proposed in this work, the number of downsampling layers of contracting path is modified to two, and the network is changed from the encoding-decoding structure to the encoding-decoding-encoding-decoding structure so that the network can retain more detailed features and extract deeper semantic information. The skip connections are used between the contracting path and the expansion path at the same scale to increase the information transmission path. The convergence speed of the network is accelerated by the residual block replacing convolution layer. The image is scaled to different scales and is inputted into the network from the left to enhance the sensitivity of the network for blood vessels at different scales. The feature maps extracted from different layers of the network are scaled to the same size as the inputted image for fusion and segmentation. The performance of ResWnet is evaluated on DRIVE and STARE databases. The AUC is 0.9799 and 0.9863, and the accuracy is 0.9554 and 0.9723, respectively. According to the results, ResWnet outperforms many other proposed methods in small vessel segmentation. For future research, it can be learned that pre-processing and post-processing are vital to the segmentation accuracy. Furthermore, ResWnet can also be applied to other semantic segmentation tasks such as lung nodule segmentation or cancer cell segmentation. For future research, the pre-processing and post-processing will be tried to further enhance the segmentation accuracy performance of ResWnet.","Feature extraction,Image segmentation,Biomedical imaging,Convolution,Semantics,Retina,Blood vessels,ResWnet,retinal,small vessel segmentation,feature fusion",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BLOOD-VESSELS,NETWORK,IMAGES",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09233388.pdf,
86,Emotion Recognition Related to Stock Trading Using Machine Learning Algorithms With Feature Selection,8,,199719-199732,"Torres Edgar P.,Torres Edgar Alejandro,Hernandez-Alvarez Myriam,Yoo Sang Guun","Torres EP,Torres EA,Hernandez-Alvarez M,Yoo SG",Torres EP; Hernandez-Alvarez M; Yoo SG,10.1109/ACCESS.2020.3035539,Escuela Politecnica Nacional Ecuador,"This article proposes an emotion elicitation method to develop our Stock-Emotion dataset: a collection of the participants' electroencephalogram (EEG) signals who paper-traded using real stock market data, virtual money, and outcomes that emotionally affected them. A system for emotion recognition using this dataset was tested. The system extracted from the EEG signals the following features: five frequency bands, Differential Entropy (DE), Differential Asymmetry (DASM), and Rational Asymmetry (RASM), for each band. Our system then carried out feature selection using a filter method (Mutual Information Matrix), combined with a wrapper process (Chi-Square statistics) and alternatively using the embedded algorithms in a Deep Learning classifier. Finally, this work classified emotions in four quadrants of the circumplex model using Random Forest and Deep Learning algorithms. Our findings show that 1) the proposed emotion elicitation method is useful to provoke affective states associated with trading, 2) the proposed feature selection process improved the classification performance of our emotion recognition system, and 3) classifier performance of the system can recognize trading related emotions and has results comparable with the state of the art research corresponding to a similar number of output classes.","BCI,EEG,DE,DASM,RASM,random forest,deep learning,emotion recognition,stock market trading,emotion elicitation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BRAIN,REAL,DISCRETE",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09247095.pdf,
87,Transfer Learning With Adaptive Fine-Tuning,8,,196197-196211,"Vrbancic Grega,Podgorelec Vili","Vrbancic G,Podgorelec V",Vrbancic G,10.1109/ACCESS.2020.3034343,University of Maribor,"With the utilization of deep learning approaches, the key factors for a successful application are sufficient datasets with reliable ground truth, which are generally not easy to obtain, especially in the field of medicine. In recent years, this issue has been commonly addressed with the exploitation of transfer learning via fine-tuning, which enables us to start with a model, pre-trained for a specific task, and then fine-tune (train) only certain layers of the neural network for a related but different target task. However, the selection of fine-tunable layers is one of the major problems of such an approach. Since there is no general rule on how to select layers in order to achieve the highest possible performance, we developed the Differential Evolution based Fine-Tuning (DEFT) method for the selection of fine-tunable layers for a target dataset under the given constraints. The method was evaluated against the problem of identifying the osteosarcoma from the medical imaging dataset. The performance was compared against a conventionally trained convolutional neural network, a pre-trained model, and the model trained using a fine-tuning approach with manually handpicked fine-tunable layers. In terms of classification accuracy, our proposed method outperformed the compared methods by a margin of 4.45% to 32.75%.","Task analysis,Deep learning,Neural networks,Training,Feature extraction,Adaptation models,Biomedical imaging,Deep learning,fine-tuning,medical imaging,optimization,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CONVOLUTIONAL,NEURAL-NETWORKS,DIFFERENTIAL,EVOLUTION,CLASSIFICATION,OPTIMIZATION",IEEE ACCESS,https://doi.org/10.1109/access.2020.3034343,
88,Multi-Layered Basis Pursuit Algorithms for Classification of MR Images of Knee ACL Tear,8,,205424-205435,"Wahid Abdul,Shah Jawad Ali,Khan Adnan Umar,Ullah Mukhtar,Ayob Mohd Zaki","Wahid A,Shah JA,Khan AU,Ullah M,Ayob MZ",Shah JA,10.1109/ACCESS.2020.3037745,"UniKL British Malaysian Inst, Elect Sect, Gombak 53100, Selangor, Malaysia.","Deep learning architectures have been extensively used in recent years for the classification of biomedical images to assist clinicians for diagnosis and treatment management of patients with different health conditions. These architectures have demonstrated expert level diagnosis, and in some cases, surpassed human experts in diagnosing health conditions. The automation tools based on deep learning frameworks have the potential to transform all stages of medical imaging pipeline from image acquisition to interpretation and analysis. One of the most common areas where these techniques are applied is knee MR image classification for different types of Anterior Cruciate Ligament (ACL) tears. If properly and timely managed, the diagnosis and treatment of ACL tear can avoid further degradation of patients' knee joints and can also help slow the process of subsequent knee arthritis. In this work, we have implemented a novel classification framework based on multilayered basis pursuit algorithms inspired from recent research work in the area of the theoretical foundation of deep learning with the help of celebrated sparse coding theory. We implement an optimal multi-layered Convolutional Sparse Coding (ML-CSC) framework for classification of a labelled dataset of knee MR images with the coronal view and compare the results with traditional convolutional neural network (CNN) based classifiers. Empirical results demonstrate the effectiveness of the ML-CSC framework and show that the framework can successfully learn distinct features on a small dataset and achieve a good efficiency of more than 92% without employing regularization techniques and extensive training on large datasets. In addition to 95% average accuracy on the presence and absence of ACL tears, the framework also performs well on the imbalanced and challenging classification of partial ACL tear with 85% accuracy.","Basis pursuit,iterative shrinkage algorithms,knee MR image classification,multi-layer convolutional sparse coding",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"ANTERIOR,CRUCIATE,LIGAMENT,CONVOLUTIONAL,NEURAL-NETWORKS,THRESHOLDING,ALGORITHM,INVERSE,PROBLEMS,SPARSE",IEEE ACCESS,https://doi.org/10.1109/access.2020.3037745,
89,Parkinson's Disease Detection Based on Spectrogram-Deep Convolutional Generative Adversarial Network Sample Augmentation,8,,206888-206900,"Xu Zhi-Jing,Wang Rong-Fei,Wang Juan,Yu Da-Hai","Xu ZJ,Wang RF,Wang J,Yu DH",Xu ZJ,10.1109/ACCESS.2020.3037775,Shanghai Maritime University,"As an essential biological feature of human beings, voiceprint is increasingly used in medical research and diagnosis, especially in identifying Parkinson's Disease (PD). This paper proposes a Spectrogram Deep Convolutional Generative Adversarial Network (S-DCGAN) for sample augmentation to overcome the limited amount of existing patient voiceprint datasets and samples. S-DCGAN generates a high-resolution spectrogram by increasing network layers, adding the Spectral Normalization (SN) method, and combining feature matching strategy. The high-similarity and low-distortion spectrogram are selected in light of Structural Similarity Index (SSIM) values and Peak Signal to Noise Ratio (PSNR) to augment the samples. Frechet Inception Distance (FID) and GAN-train result show the generalization ability of the generated data. We construct the ResNet50 model with a Global Average Pooling(GAP) layer to extract the voiceprint features and classify them effectively to improve recognition accuracy. The GAP suppresses the over-fitting problem and optimizes quickly. Finally, on the Sakar dataset, comparative experiments were conducted on different models and classification methods. Results show that the S-DCGAN-ResNet50 hybrid model can achieve the highest voiceprint recognition accuracy of 91.25% and specificity of 92.5%, which can distinguish between PD patients and healthy people more precisely compared with DCGAN-ResNet50. It augments the application environment of voiceprint recognition in the medical field and makes it universal in different datasets.","Spectrogram,Speech recognition,Brain modeling,Training,Feature extraction,Gallium nitride,Parkinson&apos,s disease,Parkinson&#8217,s disease,ResNet50,S-DCGAN,sample augumentation,spectrogram",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"MULTIPLE,TYPES,VOICE,RECORDINGS",IEEE ACCESS,https://doi.org/10.1109/access.2020.3037775,
90,A Novel Deep Learning Scheme for Motor Imagery EEG Decoding Based on Spatial Representation Fusion,8,,202100-202110,"Yang Jun,Ma Zhengmin,Wang Jin,Fu Yunfa","Yang J,Ma ZM,Wang J,Fu YF",Yang J,10.1109/ACCESS.2020.3035347,Kunming University of Science & Technology,"Motor imagery electroencephalography (MI-EEG), which is an important subfield of active brain-computer interface (BCI) systems, can be applied to help disabled people to consciously and directly control prosthesis or external devices, aiding them in certain daily activities. However, the low signal-to-noise ratio and spatial resolution make MI-EEG decoding a challenging task. Recently, some deep neural approaches have shown good improvements over state-of-the-art BCI methods. In this study, an end-to-end scheme that includes a multi-layer convolution neural network is constructed for an accurate spatial representation of multi-channel grouped MI-EEG signals, which is employed to extract the useful information present in a multi-channel MI signal. Then the invariant spatial representations are captured from across-subjects training for enhancing the generalization capability through a stacked sparse autoencoder framework, which is inspired by representative deep learning models. Furthermore, a quantitative experimental analysis is conducted on our private dataset and on a public BCI competition dataset. The results show the effectiveness and significance of the proposed methodology.","Brain&#8211,computer interface,discriminative and representative deep learning,feature fusion,convolution neural network,stacked sparse autoencoder",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"BRAIN-COMPUTER,INTERFACES,CLASSIFICATION",IEEE ACCESS,https://doi.org/10.1109/access.2020.3035347,
91,Axial Super-Resolution Study for Optical Coherence Tomography Images Via Deep Learning,8,,204941-204950,"Yuan Zhuoqun,Yang Di,Pan Hongming,Liang Yanmei","Yuan ZQ,Yang D,Pan HM,Liang YM",Liang YM,10.1109/ACCESS.2020.3036837,Nankai University,"Optical coherence tomography (OCT) is a noninvasive, high resolution, and real-time imaging technology that has been used in ophthalmology and other medical fields. Limited by the point spread function of OCT system, it is difficult to optimize its spatial resolution only based on hardware. Digital image processing methods, especially deep learning, provide great potential in super-resolving images. In this paper, the matched axial low resolution (LR) and high resolution OCT image pairs from actual OCT imaging are collected to generate the dataset by our home-made spectral domain OCT (SD-OCT) system. Several methods are selected to super-resolve LR OCT images. It is shown from the experimental results that the residual-in-residual dense block network (RRDBNet) trained with different loss functions performs the best super-resolution for OCT images, and it is demonstrated from the preliminary results that deep learning methods have good generalization and robustness between OCT systems. We believe deep learning methods have broad prospects in improving the quality of OCT images.","Optical coherence tomography (OCT),axial super resolution,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"OCT,IMPROVEMENT,NETWORK",IEEE ACCESS,https://doi.org/10.1109/access.2020.3036837,
92,Improved Threshold Based and Trainable Fully Automated Segmentation for Breast Cancer Boundary and Pectoral Muscle in Mammogram Images,8,,203097-203116,"Zebari Dilovan Asaad,Zeebaree Diyar Qader,Abdulazeez Adnan Mohsin,Haron Habibollah,Hamed Haza Nuzly Abdull","Zebari DA,Zeebaree DQ,Abdulazeez AM,Haron H,Hamed HNA",Zebari DA,10.1109/ACCESS.2020.3036072,"Nawroz Univ, Ctr Sci Res & Dev, Duhok 42001, Iraq.","Segmentation of the breast region and pectoral muscle are fundamental subsequent steps in the process of Computer-Aided Diagnosis (CAD) systems. Segmenting the breast region and pectoral muscle are considered a difficult task, particularly in mammogram images because of artefacts, homogeneity among the region of the breast and pectoral muscle, and low contrast along the region of breast boundary, the similarity between the texture of the Region of Interest (ROI), and the unwanted region and irregular ROI. This study aims to propose an improved threshold-based and trainable segmentation model to derive ROI. A hybrid segmentation approach for the boundary of the breast region and pectoral muscle in mammogram images was established based on thresholding and Machine Learning (ML) techniques. For breast boundary estimation, the region of the breast was highlighted by eliminating bands of the wavelet transform. The initial breast boundary was determined through a new thresholding technique. Morphological operations and masking were employed to correct the overestimated boundary by deleting small objects. In the medical imaging field, significant progress to develop effective and accurate ML methods for the segmentation process. In the literature, the imperative role of ML methods in enabling effective and more accurate segmentation method has been highlighted. In this study, an ML technique was built based on the Histogram of Oriented Gradient (HOG) feature with neural network classifiers to determine the region of pectoral muscle and ROI. The proposed segmentation approach was tested by utilizing 322, 200, 100 mammogram images from mammographic image analysis society (mini-MIAS), INbreast, Breast Cancer Digital Repository (BCDR) databases, respectively. The experimental results were compared with manual segmentation based on different texture features. Moreover, evaluation and comparison for the boundary of the breast region and pectoral muscle segmentation have been done separately. The experimental results showed that the boundary of the breast region and the pectoral muscle segmentation approach obtained an accuracy of 98.13% and 98.41% (mini-MIAS), 100%, and 98.01% (INbreast), and 99.8% and 99.5% (BCDR), respectively. On average, the proposed study achieved 99.31% accuracy for the boundary of breast region segmentation and 98.64% accuracy for pectoral muscle segmentation. The overall ROI performance of the proposed method showed improving accuracy after improving the threshold technique for background segmentation and building an ML technique for pectoral muscle segmentation. More so, this article also included the ground-truth as an evaluation of comprehensive similarity. In the clinic, this analysis may be provided as a valuable support for breast cancer identification.","Breast cancer,digital mammogram,threshold technique,ML~technique,breast segmentation,pectoral muscle segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"SKIN-LINE,CLASSIFICATION,DIAGNOSIS,SYSTEM,IDENTIFICATION,ALGORITHM,MASSES",IEEE ACCESS,https://doi.org/10.1109/access.2020.3036072,
93,A Combined Low-Rank Matrix Completion and CDBN-LSTM Based Classification Model for Lower Limb Motion Function,8,,205436-205443,"Zhang Yan,Li Sining,Liu Jian,Fan Qi,Zhou Ying","Zhang Y,Li SN,Liu J,Fan Q,Zhou Y",Zhou Y,10.1109/ACCESS.2020.3037490,Hebei University of Technology,"Assessment of lower limb motion function is crucial for clinicians to treat patients effectively. However, diagnosis accuracy is still affected by clinical experience. To reduce the influence of subjective factors, a new classification model using conditional deep belief network (CDBN) and long short-term memory (LSTM) is proposed. Firstly, the original data of gait are collected by motion capture system, and low-rank matrix completion is utilized to reconstruct missing data caused by the interruption of hands and clothes. Then CDBN is trained for extracting features and LSTM classifies the features from the completed data. Compared with deep belief network (DBN), CDBN is based on conditional restricted Boltzmann machine (CRBM) which improves the importance of past time-step to achieve higher accuracy for temporal sequences. And LSTM classifies features with time information. The matrix completion result verifies excellent recovery accuracy of the proposed method. Experimental results demonstrate that CDBN-LSTM is 4% higher than that of DBN. In addition, the proposed model outperforms traditional neural network on the train process and precision rate.","CDBN,LSTM,deep network,lower limb motor function,matrix completion",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,,IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09256324.pdf,
94,Anatomical Landmarks and DAG Network Learning for Alzheimer's Disease Diagnosis,8,,206063-206073,"Zhu Tian,Cao Chongfeng,Wang Zhishun,Xu Guangrun,Qiao Jianping","Zhu T,Cao CF,Wang ZS,Xu GR,Qiao JP",Qiao JP,10.1109/ACCESS.2020.3037107,Shandong Normal University,"The accurate diagnosis and prediction for individuals is crucial in computer-aided diagnosis of Alzheimer's disease (AD). The existing structural magnetic resonance imaging based classification methods of AD diagnosis mainly focus on the voxel level, region level and patch level morphological pattern analysis. However, most of these methods extract features with high dimension which may lead to overfitting problem. Besides, the interaction of different patches is not considered in the classifier ensemble. In this article, we propose a novel anatomical landmarks and directed acyclic graph (DAG) network feature learning based classification algorithm for the diagnosis of AD individuals. First, the anatomical feature patches of gray matter image are identified by the morphological and statistical analysis. Second, a simple and efficient DAG convolutional neural network is proposed to extract the discriminative deep features of image representation. Especially, the deep features are obtained by fusing feature maps of different network levels which contain semantic high-level and high-resolution low-level features. Finally, support vector machine and deep features are utilized to construct the classification model and predict the individual of AD. Experiments on three public datasets including ADNI-1, ADNI-2 and MIRIAD demonstrate that the proposed method can effectively improve the classification performance compared with the state-of-the-art methods for AD diagnosis.","Alzheimer&#8217,s disease,structural magnetic resonance image,anatomical landmarks,directed acyclic graph network,classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"STRUCTURAL,MRI,HEALTHY,CONTROLS,CLASSIFICATION,AD,SEGMENTATION",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09253576.pdf,
95,Multiscale Convolutional Fusion Network for Non-Lambertian Photometric Stereo,27,,1929-1933,"Ren Jieji,Wang Xi,Jian Zhenxiong,Ren Mingjun","Ren JJ,Wang X,Jian ZX,Ren MJ",Ren MJ,10.1109/LSP.2020.3031482,Shanghai Jiao Tong University,"One of the key issues in photometric stereo is the extension of its application in real world objects which shows non-Lambertian reflectance. This letter proposes a multi-scale weighted convolutional fusion network with deep learning architecture to realize high-precision perception of non-Lambertian surfaces under arbitrary illumination conditions. A multi-scale convolutional fusion module is designed to strengthen the photometric physics and the utilization of the neighborhood features at the same time so as to overcome shadows and distinguish multiple materials. In order to further deal with the problem of arbitrary illumination conditions, a multi-resolution polar coordinate division method is proposed to integrate the input image information and fully utilizes the multi-scale convolution. Both syntheses and real-world experiments verifies the performance of the proposed method in recovery accuracy and computational efficiency.","Lighting,Feature extraction,Convolution,Reflection,Reflectivity,Fuses,Computational modeling,Photometric stereo,Multi-scale convolution,Stereo vision",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,3.586,,IEEE SIGNAL PROCESSING LETTERS,,
96,BayesCap: A Bayesian Approach to Brain Tumor Classification Using Capsule Networks,27,,2024-2028,"Afshar Parnian,Mohammadi Arash,Plataniotis Konstantinos N.","Afshar P,Mohammadi A,Plataniotis KN",Mohammadi A,10.1109/LSP.2020.3034858,Concordia University - Canada,"Convolutional neural networks (CNNs), which have been the state-of-the-art in many image-related applications, are prone to losing important spatial information between image instances. Capsule networks (CapsNets), on the other hand, are capable of leveraging such information through their routing by agreement process, making them powerful architectures for small datasets, such asmedical imaging ones. Within the domain of medical imaging problems, brain tumor classification is of paramount importance, due to the deadly nature of this cancer and the consequences of the tumor misclassification. In our recent works, we showed potentials of developing CapsNet architecture for the task of brain tumor type classification. Similar to other deep learning models, however, CapsNets do not capture prediction uncertainty (coming from the uncertainty in the model weights, which is significantly important in keeping the human experts in the loop, by returning the uncertain samples. In this paper, we propose a Bayesian CapsNet framework, referred to as the BayesCap, that can provide not only the mean predictions, but also entropy as a measure of prediction uncertainty. Results show that filtering out the uncertain predictions can improve the accuracy, confirming that returning the uncertain predictions is an appropriate strategy for improving interpretability of the network.","Brain Tumor Classification,Bayesian Capsule Networks,Uncertainty Measure,Radiomics",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,3.586,MRI,IEEE SIGNAL PROCESSING LETTERS,,
97,Application of Low-Scales Vessel Detection in Retinal Vessel Segmentation,14,1,171-180,",,","Wu Xinxin,Xiao Zhiyong,Liu Chen",,,Wu Xinxin,"Retinal image analysis has become the main non-invasive way to diagnose many diseases, and the extraction of blood vessels is the most important step. Supervised learning method has a good effect on blood vessel extraction. In order to further improve the accuracy of detection, a low-scales vessel detection (LVD) algorithm is proposed. In addition to a sub-network for extracting features in the original scale, two sub-networks for extracting features in the low scale are added, and the single output in the low scale is fused with the features in the original size, and the final output result is obtained after dimensionality reduction. Considering the structural characteristics of fundus vessels, an asymmetric depth-fixed sub-network (ADS) with deep layers and fewer parameters is designed in LVD. Tested in the public database DRIVE, only the green component of color fundus image and B-COSFIRE filter response are used as feature input. Its sensitivity, specificity, accuracy and AUC index are 0.8192, 0.9842, 0.9695 and 0.9782, respectively, which reach the advanced level.",B-COSFIRE; retinal vascular segmentation; low-scales vessel detection (LVD); B-COSFIRE; asymmetric depth-fixed sub-network (ADS),Article,,,,,,,,
98,Prediction of Students' Assessment Readiness in Online Learning Environments: The Sequence Matters,,,382-391,"Malekian Donia,Bailey James,Kennedy Gregor","Malekian D,Bailey J,Kennedy G",Malekian D,10.1145/3375462.3375468,University of Melbourne,"Online learning environments are now pervasive in higher education. While not exclusively the case, in these environments, there is often modest teacher presence, and students are provided with access to a range of learning, assessment, and support materials. This places pressure on their study skills, including self-regulation. In this context, students may access assessment material without being fully prepared. This may result in limited success and, in turn, raise a significant risk of disengagement. Therefore, if the prediction of students' assessment readiness was possible, it could be used to assist educators or online learning environments to postpone assessment tasks until students were deemed ""ready"". In this study, we employed a range of machine learning techniques with aggregated and sequential representations of students' behaviour in a Massive Open Online Course (MOOC), to predict their readiness for assessment tasks. Based on our results, it was possible to successfully predict students' readiness for assessment tasks, particularly if the sequential aspects of behaviour were represented in the model. Additionally, we used sequential pattern mining to investigate which sequences of behaviour differed between high or low level of performance in assessments. We found that a high level of performance had the most sequences related to viewing and reviewing the lecture materials, whereas a low level of performance had the most sequences related to successive failed submissions for an assessment. Based on the findings, implications for supporting specific behaviours to improve learning in online environments are discussed.","Learning Analytics,LSTM,Assessment Readiness Prediction,Sequential Pattern Mining,MOOCs",Proceedings Paper,"ASSOC COMPUTING MACHINERY, 1515 BROADWAY, NEW YORK, NY 10036-9998 USA","Computer Science,Education & Educational Research",,,"NEURAL-NETWORKS,PERFORMANCE,MEMORY",LAK20: THE TENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE,,
99,Predicting learners' effortful behaviour in adaptive assessment using multimodal data,,,480-489,"Sharma Kshitij,Papamitsiou Zacharoula,Olsen Jennifer K.,Giannakos Michail","Sharma K,Papamitsiou Z,Olsen JK,Giannakos M",Sharma K,10.1145/3375462.3375498,Norwegian University of Science & Technology (NTNU),"Many factors influence learners' performance on an activity beyond the knowledge required. Learners' on-task effort has been acknowledged for strongly relating to their educational outcomes, reflecting how actively they are engaged in that activity. However, effort is not directly observable. Multimodal data can provide additional insights into the learning processes and may allow for effort estimation. This paper presents an approach for the classification of effort in an adaptive assessment context. Specifically, the behaviour of 32 students was captured during an adaptive self-assessment activity, using logs and physiological data (i.e., eye-tracking, EEG, wristband and facial expressions). We applied k-means to the multimodal data to cluster students' behavioural patterns. Next, we predicted students' effort to complete the upcoming task, based on the discovered behavioural patterns using a combination of Hidden Markov Models (HMMs) and the Viterbi algorithm. We also compared the results with other state-of-the-art classification algorithms (SVM, Random Forest). Our findings provide evidence that HMMs can encode the relationship between effort and behaviour (captured by the multimodal data) in a more efficient way than the other methods. Foremost, a practical implication of the approach is that the derived HMMs also pinpoint the moments to provide preventive/prescriptive feedback to the learners in real-time, by building-upon the relationship between behavioural patterns and the effort the learners are putting in.","adaptive assessment,effort classification,multimodal learning analytics,hidden Markov models",Proceedings Paper,"ASSOC COMPUTING MACHINERY, 1515 BROADWAY, NEW YORK, NY 10036-9998 USA","Computer Science,Education & Educational Research",,,"PERFORMANCE,GAME,TIME,ACQUISITION,ENGAGEMENT,SYSTEM",LAK20: THE TENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE,https://ntnuopen.ntnu.no/ntnu-xmlui/bitstream/11250/2736770/2/LAK20-Sharma.pdf,
100,Confused and Beyond: Detecting Confusion in Course Forums using Students' Hashtags,,,589-594,"Geller Shay A.,Hoernle Nicholas,Gal Kobi,Segal Avi,Zhang Amy X.,Karger David,Facciotti Marc T.,Igo Michele","Geller SA,Hoernle N,Gal K,Segal A,Zhang AX,Karger D,Facciotti MT,Igo M",Geller SA,10.1145/3375462.3375485,Ben Gurion University,"Students' confusion is a barrier for learning, contributing to loss of motivation and to disengagement with course materials. However, detecting students' confusion in large-scale courses is both time and resource intensive. This paper provides a new approach for confusion detection in online forums that is based on harnessing the power of students' self-reported affective states (reported using a set of pre-defined hashtags). It presents a rule for labeling confusion, based on students' hashtags in their posts, that is shown to align with teachers' judgement. We use this labeling rule to inform the design of an automated classifier for confusion detection for the case when there are no self-reported hashtags present in the test set. We demonstrate this approach in a large scale Biology course using the Nota Bene annotation platform. This work lays the foundation to empower teachers with better support tools for detecting and alleviating confusion in online courses.","Online Discussion Forum,Confusion Detection,Emojis,Hashtags,Self-Reported Affect,Text Classification",Proceedings Paper,"ASSOC COMPUTING MACHINERY, 1515 BROADWAY, NEW YORK, NY 10036-9998 USA","Computer Science,Education & Educational Research",,,,LAK20: THE TENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE,,
