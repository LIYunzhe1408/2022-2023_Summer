,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Automatic Quality Assessment of Reflectance Confocal Microscopy Mosaics using Attention-Based Deep Neural Network,,,1824-1827,"Wodzinski Marek,Pajak Miroslawa,Skalski Andrzej,Witkowski Alexander,Pellacani Giovanni,Ludzik Joanna","Wodzinski M,Pajak M,Skalski A,Witkowski A,Pellacani G,Ludzik J",Wodzinski M,,AGH University of Science & Technology,"Skin cancers are the most common cancers with an increased incidence, and a valid, early diagnosis may significantly reduce its morbidity and mortality. Reflectance confocal microscopy (RCM) is a relatively new, non-invasive imaging technique that allows screening lesions at a cellular resolution. However, one of the main disadvantages of the RCM is frequently occurring artifacts which makes the diagnostic process more time consuming and hard to automate using e.g. end-to-end deep learning approach. A tool to automatically determine the RCM mosaic quality could be beneficial for both the lesion classification and informing the user (dermatologist) about its quality in real-time, during the examination procedure. In this work, we propose an attention-based deep network to automatically determine if a given RCM mosaic has an acceptable quality. We achieved accuracy above 87% on the test set which may considerably improve further classification results and the RCM-based examination.","reflectance confocal microscopy,deep learning,convolutional neural network,melanoma,skin lesion",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
2,Automated circumpapillary retinal nerve fiber layer segmentation in high-resolution swept-source OCT,,,1832-1835,"Yow Ai Ping,Tan Bingyao,Chua Jacqueline,Aung Tin,Husain Rahat,Schmetterer Leopold,Wong Damon","Yow AP,Tan BY,Chua J,Aung T,Husain R,Schmetterer L,Wong D",Yow AP,,"SERI NTU Adv Ocular Engn STANCE Program, Singapore, Singapore.","Glaucoma is a progressive optic neuropathy that leads to loss of retinal ganglion cells and thinning of retinal nerve fiber layer (RNFL). Circumpapillary RNFL thickness measurements have been used for glaucoma diagnostic and monitoring purposes. However, manual measurement of the RNFL thickness is tedious and subjective. We proposed and evaluated the performance of automated RNFL segmentation from OCT images using a state-of-the-art deep learning-based model. Circumpapillary OCT scans were extracted from volumetric OCT scans using a high-resolution swept-source OCT device. Manual annotation was performed on the extracted scans and used for training and evaluation. The results show that the accuracy and diagnostic performance is comparable to manual assessment, and the potential application of deep learning-based approach in such segmentation.","OPTICAL COHERENCE TOMOGRAPHY,THICKNESS,IMAGES",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"OPTICAL,COHERENCE,TOMOGRAPHY,THICKNESS,IMAGES",,,
3,Role of the Choroid in Automated Age-related Macular Degeneration Detection from Optical Coherence Tomography Images,,,1867-1870,"Srivastava Ruchir,Ong Ee Ping,Lee Beng-Hai","Srivastava R,Ong EP,Lee BH",Srivastava R,,Agency for Science Technology & Research (ASTAR),"Automatic detection of age-related macular degeneration (AMD) from optical coherence tomography (OCT) images is often performed using the retinal layers only and choroid is excluded from the analysis. This is because symptoms of AMD manifest in the choroid only in the later stages and clinical literature is divided over the role of the choroid in detecting earlier stages of AMD. However, more recent clinical research suggests that choroid is affected at a much earlier stage. In the proposed work, we experimentally verify the effect of including the choroid in detecting AMD from OCT images at an intermediate stage. We propose a deep learning framework for AMD detection and compare its accuracies with and without including the choroid. Results suggest that including the choroid improves the AMD detection accuracy. In addition, the proposed method achieves an accuracy of 96.78% which is comparable to the state-of-the-art works.","EDEMA,CLASSIFICATION,AMD",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"EDEMA,CLASSIFICATION,AMD",,,
4,Localization of Anatomical Features in Vascular-enhanced Enface OCT Images,,,1875-1878,"Wong Damon W. K.,Yow Ai Ping,Tan Bingyao,Yao Xinwen,Chua Jacqueline,Schmetterer Leopold","Wong DWK,Yow AP,Tan BY,Yao XW,Chua J,Schmetterer L",Wong DWK,,"SERI NTU Adv Ocular Engn STANCE Program, Singapore, Singapore.","Optical coherence tomography (OCT) allows in vivo volumetric imaging of the eye. Identification and localization of anatomical features in enface OCT are important steps in OCT-based image analysis. However the visibility of anatomical features in both structural OCT or vascular OCT angiography is limited. In this paper, we propose to use vascular-enhanced enface OCT image for the concurrent detection of anatomical features, using a FasterRCNN object detection framework based on convolutional networks. Transfer learning was applied to adapt pre-trained models as the backbone networks. Models were evaluated on a dataset of 419 images. The results showed that VGG-FasterRCNN achieved a mean average precision 0.77, with localization errors of 0.18 +/- 0.10 mm and 0.24 +/- 0.13 mm for the macula and optic disc respectively. The results are promising and suggest that this network could potentially be used to automatically and concurrently detect anatomical features.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
5,Super-resolution technology to simultaneously improve optical & digital resolution of optical coherence tomography via deep learning,,,1879-1882,"Cao Shengting,Yao Xinwen,Koirala Nischal,Brott Brigitta,Litovsky Silvio,Ling Yuye,Gan Yu","Cao ST,Yao XW,Koirala N,Brott B,Litovsky S,Ling YY,Gan Y",Gan Y,,University of Alabama System,"Optical coherence tomography (OCT) has stimulated a wide range of medical image-based diagnosis and treatment. In cardiac imaging, OCT has been used in assessing plaques before and after stenting. While needed in many scenarios, high resolution comes at the costs of demanding optical design and data storage/transmission. In OCT, there are two types of resolutions to characterize image quality: optical and digital resolutions. Although multiple existing works have heavily emphasized on improving the digital resolution, the studies on improving optical resolution or both resolutions remain scarce. In this paper, we focus on improving both resolutions. In particular, we investigate a deep learning method to address the problem of generating a high-resolution (HR) OCT image from a low optical and low digital resolution ((LR)-R-2) image. To this end, we have modified the existing super-resolution generative adversarial network (SR-GAN) for OCT image reconstruction. Experimental results from the human coronary OCT images have demonstrated that the reconstructed images from highly compressed data could achieve high structural similarity and accuracy in comparison with the HR images. Besides, our method has obtained better denoising performance than the block-matching and 3D filtering ( BM3D) and Denoising Convolutional Neural Networks (DnCNN) denoising method.",IMAGES,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,IMAGES,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8116943,
6,OrgaNet: A Robust Network for Subcellular Organelles Classification in Fluorescence Microscopy Images,,,1887-1890,"Duc Hoa Tran,Meunier Michel,Cheriet Farida","Tran DH,Meunier M,Cheriet F",Tran DH,,University of Montreal,"Automatic identification of subcellular compartments of proteins in fluorescence microscopy images is an important task to quantitatively evaluate cellular processes. A common problem for the development of deep learning based classifiers is that there is only a limited number of labeled images available for training. To address this challenge, we propose a new approach for subcellular organelles classification combining an effective and efficient architecture based on a compact Convolutional Neural Network and deep embedded clustering algorithm. We validate our approach on a benchmark of HeLa cell microscopy images. The network both yields high accuracy that outperforms state of the art methods and has significantly small number of parameters. More interestingly, experimental results show that our method is strongly robust against limited labeled data for training, requiring four times less annotated data than usual while maintaining the high accuracy of 93.9%.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
7,Deep Learning in ex-vivo Lung Cancer Discrimination using Fluorescence Lifetime Endomicroscopic Images,,,1891-1894,"Wang Qiang,Hopgood James R.,Finlayson Neil,Williams Gareth O. S.,Fernandes Susan,Williams Elvira,Akram Ahsan,Dhaliwal Kevin,Vallejo Marta","Wang Q,Hopgood JR,Finlayson N,Williams GOS,Fernandes S,Williams E,Akram A,Dhaliwal K,Vallejo M",Vallejo M,,Heriot Watt University,"Fluorescence lifetime is effective in discriminating cancerous tissue from normal tissue, but conventional discrimination methods are primarily based on statistical approaches in collaboration with prior knowledge. This paper investigates the application of deep convolutional neural networks (CNNs) for automatic differentiation of ex-vivo human lung cancer via fluorescence lifetime imaging. Around 70,000 fluorescence images from ex-vivo lung tissue of 14 patients were collected by a custom fibre-based fluorescence lifetime imaging endomi-croscope. Five state-of-the-art CNN models, namely ResNet, ResNeXt, Inception, Xception, and DenseNet, were trained and tested to derive quantitative results using accuracy, precision, recall, and the area under receiver operating characteristic curve (AUC) as the metrics. The CNNs were firstly evaluated on lifetime images. Since fluorescence lifetime is independent of intensity, further experiments were conducted by stacking intensity and lifetime images together as the input to the CNNs. As the original CNNs were implemented for RGB images, two strategies were applied. One was retaining the CNNs by putting intensity and lifetime images in two different channels and leaving the remaining channel blank. The other was adapting the CNNs for two-channel input. Quantitative results demonstrate that the selected CNNs are considerably superior to conventional machine learning algorithms. Combining intensity and lifetime images introduces noticeable performance gain compared with using lifetime images alone. In addition, the CNNs with intensity-lifetime RGB image is comparable to the modified two-channel CNNs with intensity-lifetime twochannel input for accuracy and AUC, but significantly better for precision and recall.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
8,Human Breast Numerical Model Generation Based on Deep Learning for Photoacoustic Imaging,,,1919-1922,"Ma Yaxin,Yang Changchun,Zhang Juze,Wang Yiyun,Gao Feng,Gao Fei","Ma YX,Yang CC,Zhang JZ,Wang YY,Gao F,Gao F",Gao F,,ShanghaiTech University,"Photoacoustic imaging which combines high contrast of optical imaging and high resolution of ultrasound imaging, can provide functional information, potentially playing a crucial role in the study of breast cancer diagnostics. However, open source dataset for PA imaging research is insufficient on account of lacking clinical data. To tackle this problem, we propose a method to automatically generate breast numerical model for photoacoustic imaging. The different type of tissues is automatically extracted first by employing deep learning and other methods from mammography. And then the tissues are combined by mathematical set operation to generate a new breast image after being assigned optical and acoustic parameters. Finally, breast numerical model with proper optical and acoustic properties are generated, which are specifically suitable for PA imaging studies, and the experiment results indicate that our method is feasible with high efficiency.",TOMOGRAPHY,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,TOMOGRAPHY,,,
9,Towards an automated classification method for ureteroscopic kidney stone images using ensemble learning,,,1936-1939,"Martinez Adriana,Dinh-Hoan Trinh,El Beze Jonathan,Hubert Jacques,Eschwege Pascal,Estrade Vincent,Aguilar Lina,Daul Christian,Ochoa Gilberto","Martinez A,Trinh DH,El Beze J,Hubert J,Eschwege P,Estrade V,Aguilar L,Daul C,Ochoa G",Martinez A,,Universidad Autonoma de Guadalajara,"Urolithiasis is a common disease around the world and its incidence has been growing every year. There are various diagnosis techniques based on kidney stone identification aiming to find the formation cause. However, most of them are time consuming, tedious and expensive. The accuracy of the diagnosis is crucial for the prescription of an appropriate treatment that can eliminate the stones and diminish future relapses. This paper presents two effective supervised learning methods to automate and improve the accuracy of the classification of kidney stones; as well as a dataset consisting of kidney stone images captured with ureteroscopes. In the proposed methods, the image features that are visually exploited by urologists to distinguish the type of kidney stones are analyzed and encoded as vectors. Then, the classification is performed on these feature vectors through Random Forest and ensemble K Nearest Neighbor classifiers. The overall classification accuracy obtained was 89%, outperforming previous methods by more than 10%. The details of the classifier implementation, as well as their performance and accuracy, are presented and discussed. Finally, future work and improvements are proposed.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
10,Deep Convolutional Neural Network Ensembles For Multi-Classification of Skin Lesions From Dermoscopic and Clinical Images,,,1940-1943,"Reisinho Jose,Coimbra Miguel,Renna Francesco","Reisinho J,Coimbra M,Renna F",Reisinho J,,Universidade do Porto,"In this paper, we consider the problem of classifying skin lesions into multiple classes using both dermoscopic and clinical images. Different convolutional neural network architectures are considered for this task and a novel ensemble scheme is proposed, which makes use of a progressive transfer learning strategy.
The proposed approach is tested over a dataset of 4000 images containing both dermoscopic and clinical examples and it is shown to achieve an average specificity of 93.3% and an average sensitivity of 79.9% in discriminating skin lesions belonging to four different classes.","DERMATOLOGISTS,CANCER",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"DERMATOLOGISTS,CANCER",,,
11,Deep learning-based image evaluation for cervical precancer screening with a smartphone targeting low resource settings - Engineering approach,,,1944-1949,"Hu Liming,Homing Matthew P.,Banik Dipayan,Ajenifuja Olusegun Kayode,Adepiti Clement Akinfolarin,Yeates Karen,Mtema Zac,Wilson Ben,Mehanian Courosh","Hu LM,Homing MP,Banik D,Ajenifuja OK,Adepiti CA,Yeates K,Mtema Z,Wilson B,Mehanian C",Hu LM,,Intellectual Ventures,"Cervical cancer is the fourth most common cancer among women and still one of the major causes of women's death around the world. Early screening of high grade Cervical Intraepithelial Neoplasia (CIN), precursors to cervical cancer, is vital to efforts aimed at improving survival rate and eventually eliminating cervical cancer. Visual Inspection with Acetic acid (VIA) is an assessment method which can inspect the cervix and potentially detect lesions caused by human papillomavirus (HPV), which is a major cause of cervical cancer. VIA has the potential to be an effective screening method in low resource settings when triaged with HPV test, but it has the drawback that it depends on the subjective evaluation of health workers with varying levels of training. A new deep learning algorithm called Automated Visual Evaluation (AVE) for analyzing cervigram images has been recently reported that can automatically detect cervical precancer better than human experts. In this paper, we address the question of whether mobile phone- based cervical cancer screening is feasible. We consider the capabilities of two key components of a mobile phone platform for cervical cancer screening: (1) the core AVE algorithm and (2) an image quality algorithm. We consider both accuracy and speed in our assessment. We show that the core AVE algorithm, by refactoring to a new deep learning detection framework, can run in similar to 30 seconds on a low-end smartphone (i.e. Samsung J8), with equivalent accuracy. We developed an image quality algorithm that can localize the cervix and assess image quality in similar to 1 second on a low-end smartphone, achieving an area under the ROC curve (AUC) of 0.95. Field validation of the mobile phone platform for cervical cancer screening is in progress.","cervical cancer,deep learning,RetinaNet,VIA,image focus,digital cervicography,object detection",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
12,Prediction of Patient Demographics using 3D Craniofacial Scans and Multi-view CNNs,,,1950-1953,"Hanif Umaer,Paulsen Rasmus R.,Leary Eileen B.,Mignot Emmanuel,Jennum Poul,Sorensen Helge B. D.","Hanif U,Paulsen RR,Leary EB,Mignot E,Jennum P,Sorensen HBD",Hanif U,,Technical University of Denmark,"3D data is becoming increasingly popular and accessible for computer vision tasks. A popular format for 3D data is the mesh format, which can depict a 3D surface accurately and cost-effectively by connecting points in the (x,y,z) plane, known as vertices, into triangles that can be combined to approximate geometrical surfaces. However, mesh objects are not suitable for standard deep learning techniques due to their non-euclidean structure. We present an algorithm which predicts the sex, age, and body mass index of a subject based on a 3D scan of their face and neck. This algorithm relies on an automatic pre-processing technique, which renders and captures the 3D scan from eight different angles around the x-axis in the form of 2D images and depth maps. Subsequently, the generated data is used to train three convolutional neural networks, each with a ResNet18 architecture, to learn a mapping between the set of 16 images per subject (eight 2D images and eight depth maps from different angles) and their demographics. For age and body mass index, we achieved a mean absolute error of 7.77 years and 4.04 kg/m(2) on the respective test sets, while Pearson correlation coefficients of 0.76 and 0.80 were obtained, respectively. The prediction of sex yielded an accuracy of 93%. The developed framework serves as a proof of concept for prediction of more clinically relevant variables based on 3D craniofacial scans stored in mesh objects.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
13,Explainable Diabetic Retinopathy using EfficientNET,,,1966-1969,"Chetoui Mohamed,Akhloufi Moulay A.","Chetoui M,Akhloufi MA",Chetoui M,,University of Moncton,"Diabetic retinopathy (DR) is a medical condition due to diabetes mellitus that can damage the patient retina and cause blood leaks. This condition can cause different symptoms from mild vision problems to complete blindness if it is not timely treated. In this work, we propose the use of a deep learning architecture based on a recent convolutional neural network called EfficientNet to detect referable diabetic retinopathy (RDR) and vision-threatening DR. Tests were conducted on two public datasets, EyePACS and APTOS 2019. The obtained results achieve state-of-the-art performance and show that the proposed network leads to higher classification rates, achieving an Area Under Curve (AUC) of 0.984 for RDR and 0.990 for vision-threatening DR on EyePACS dataset. Similar performances are obtained for APTOS 2019 dataset with an AUC of 0.966 and 0.998 for referable and vision-threatening DR, respectively. An explainability algorithm was also developed and shows the efficiency of the proposed approach in detecting DR signs.",VALIDATION,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,VALIDATION,,,
14,Probability distribution guided optic disc and cup segmentation from fundus images,,,1976-1979,"Cheng Pujin,Lyu Junyan,Huang Yijin,Tang Xiaoying","Cheng PJ,Lyu JY,Huang YJ,Tang XY",Tang XY,,Southern University of Science & Technology,"In this paper, we proposed and validated a probability distribution guided network for segmenting optic disc (OD) and optic cup (OC) from fundus images. Uncertainty is inevitable in deep learning, as induced by different sensors, insufficient samples, and inaccurate labeling. Since the input data and the corresponding ground truth label may be inaccurate, they may actually follow some potential distribution. In this study, a variational autoencoder (VAE) based network was proposed to estimate the joint distribution of the input image and the corresponding segmentation (both the ground truth segmentation and the predicted segmentation), making the segmentation network learn not only pixel-wise information but also semantic probability distribution. Moreover, we designed a building block, namely the Dilated Inception Block (DIB), for a better generalization of the model and a more effective extraction of multi-scale features. The proposed method was compared to several existing state-of-the-art methods. Superior segmentation performance has been observed over two datasets (ORIGA and REFUGE), with the mean Dice overlap coefficients being 96.57% and 95.81% for OD and 88.46% and 88.91% for OC.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
15,SINGLE FUNDUS IMAGE SUPER-RESOLUTION VIA CASCADED CHANNEL-WISE ATTENTION NETWORK,,,1984-1987,"Fan Zhihao,Dan Tingting,Yu Honghua,Liu Baoyi,Car Hongmin","Fan ZH,Dan TT,Yu HH,Liu BY,Car HM",Car HM,,South China University of Technology,"Fundus image is commonly used in aiding the diagnosis of ophthalmic diseases. A high-resolution (HR) image is valuable to provide the anatomic information on the eye conditions. Recently, image super-resolution (SR) though learning model has been shown to be an economic yet effective way to satisfy the high demands in the clinical practice. However, the reported methods ignore the mutual dependencies of low- and high-resolution images and did not fully exploit the dependencies between channels. To tackle with the drawbacks, we propose a novel network for fundus image SR, named by Fundus Cascaded Channel-wise Attention Network (FCCAN). The proposed FCCAN cascades channel attention module and dense module jointly to exploit the semantic interdependencies both frequency and domain information across channels. The channel attention module rescales channel maps in spatial domain, while the dense module preserves the HR components by up- and down-sampling operation. Experimental results demonstrate the superiority of our network in comparison with the six methods.","deep learning,super-resolution,fundus image,channel-wise attention",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
16,Diabetic Peripheral Neuropathy Risk Assessment using Digital Fundus Photographs and Machine Learning,,,1988-1991,"Benson Jeremy,Estrada Trilce,Burge Mark,Soliz Peter","Benson J,Estrada T,Burge M,Soliz P",Benson J,,"VisionQuest Biomed Inc, Albuquerque, NM 87106 USA.","In this work, we demonstrate a novel approach to assessing the risk of Diabetic Peripheral Neuropathy (DPN) using only the retinal images of the patients. Our methodology consists of convolutional neural network feature extraction, dimensionality reduction and feature selection with random projections, combination of image features to case-level representations, and the training and testing of a support vector machine classifier. Using clinical diagnosis as ground truth for DPN, we achieve an overall accuracy of 89% on a held-out test set, with sensitivity reaching 78% and specificity reaching 95%.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
17,DRAN: Densely Reversed Attention based Convolutional Network for Diabetic Retinopathy Detection,,,1992-1995,"Hua Cam-Hao,Thien Huynh-The,Lee Sungyoung","Hua CH,Thien HT,Lee S",Hua CH,,Kyung Hee University,"Diabetic Retinopathy (DR), the complication leading to vision loss, is generally graded according to the amalgamation of various structural factors in fundus photography such as number of microaneurysms, hemorrhages, vascular abnormalities, etc. To this end, Convolution Neural Network (CNN) with impressively representational power has been exhaustively utilized to address this problem. However, while existing multi-stream networks are costly, the conventional CNNs do not consider multiple levels of semantic context, which suffers from the loss of spatial correlations between the aforementioned DR-related signs. Therefore, this paper proposes a Densely Reversed Attention based CNN (DRAN) to leverage the learnable integration of channel-wise attention at multi-level features in a pretrained network for unambiguously involving spatial representations of important DR-oriented factors. Consequently, the proposed approach gains a quadratic weighted kappa of 85.6% on Kaggle DR detection dataset, which is competitive with the state-of-the-arts.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
18,ResDUnet: Residual Dilated UNet for Left Ventricle Segmentation from Echocardiographic Images,,,2019-2022,"Amer Alyaa,Ye Xujiong,Zolgharni Massoud,Janan Faraz","Amer A,Ye XJ,Zolgharni M,Janan F",Amer A,,University of Lincoln,"Echocardiography is the modality of choice for the assessment of left ventricle function. Left ventricle is responsible for pumping blood rich in oxygen to all body parts. Segmentation of this chamber from echocardiographic images is a challenging task, due to the ambiguous boundary and inhomogeneous intensity distribution. In this paper we propose a novel deep learning model named ResDUnet. The model is based on U-net incorporated with dilated convolution, where residual blocks are employed instead of the basic U-net units to ease the training process. Each block is enriched with squeeze and excitation unit for channel-wise attention and adaptive feature re-calibration. To tackle the problem of left ventricle shape and size variability, we chose to enrich the process of feature concatenation in U-net by integrating feature maps generated by cascaded dilation. Cascaded dilation broadens the receptive field size in comparison with traditional convolution, which allows the generation of multi-scale information which in turn results in a more robust segmentation. Performance measures were evaluated on a publicly available dataset of 500 patients with large variability in terms of quality and patients pathology. The proposed model shows a dice similarity increase of 8.4% when compared to deeplabv3 and 1.2% when compared to the basic U-net architecture. Experimental results demonstrate the potential use in clinical domain.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,http://eprints.lincoln.ac.uk/id/eprint/42450/1/ResDUnet%20Paper%20Final.pdf,
19,Alternative Techniques for Breast Tumour Detection using Ultrasound,,,2047-2050,"Wu Haixia,Gole Ruturaj,Ghosh Subho,Basu Anup","Wu HX,Gole R,Ghosh S,Basu A",Wu HX,,University of Alberta,"Ultrasound images are potentially invaluable for imaging internal organs and diseases. However, due to noise, they are still difficult to interpret. We apply and compare supervised machine learning approaches to train a model of lesions using features with unsupervised machine learning approaches to segment and detect tumours in breasts. Two synthetic and one real datasets are used in our experiments. The best system performance is achieved by Frost Filter with Quick Shift.","Ultrasound,Breast tumours,machine learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
20,Segmentation of Ultrasound Images based on Scatterer Density using U-Net,,,2063-2066,"Amiri Mina,Tehrani Ali K. Z.,Rivaz Hassan","Amiri M,Tehrani AKZ,Rivaz H",Amiri M,,Concordia University - Canada,"Quantitative ultrasound can provide an objective estimation of different tissue properties, which may be used for tissue characterization and detection of abnormal tissue. The effective number of scatterers in different parts of a tissue is one of the important tissue properties that can be estimated by quantitative ultrasound techniques. The envelope echo is the signal which is usually used to estimate the scatterer density. In this study, we proposed using deep learning to estimate the effective number of scatterers. We generated 2000 simulated phantom data containing randomly distributed inclusions with three different values for number of scatterers per resolution cell. We used U-Net to segment the envelope data and to distinguish three different values of scatterer densities. We show that U-Net can discriminate different scattering regimes, particularly, when the difference between the number of scatterers is substantial. The overall accuracy of the network is 83.9%, and the average sensitivity and specificity among the three classes are 83.1% and 92.3% respectively. This study confirms the potential of deep learning framework in quantitative ultrasound and estimation of tissue properties using ultrasound images.","SPECKLE,BACKSCATTER,STATISTICS",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"SPECKLE,BACKSCATTER,STATISTICS",,,
21,Detecting muscle activation using ultrasound speed of sound inversion with deep learning,,,2092-2095,"Feigin Micha,Zwecker Manuel,Freedman Daniel,Anthony Brian W.","Feigin M,Zwecker M,Freedman D,Anthony BW",Feigin M,,Massachusetts Institute of Technology (MIT),"Functional muscle imaging is essential for diagnostics of a multitude of musculoskeletal afflictions such as degenerative muscle diseases, muscle injuries, muscle atrophy, and neurological related issues such as spasticity. However, there is currently no solution, imaging or otherwise, capable of providing a map of active muscles over a large field of view in dynamic scenarios.
In this work, we look at the feasibility of applying longitudinal sound speed measurements to the task of dynamic muscle imaging of contraction or activation. We perform the assessment using a deep learning network applied to pre-beamformed ultrasound channel data for sound speed inversion.
Preliminary results show that dynamic muscle contraction can be detected in the calf and that this contraction can be positively assigned to the operating muscles. Potential frame rates in the hundreds to thousands of frames per second are necessary to accomplish this.","STIFFNESS,ELASTOGRAPHY",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"STIFFNESS,ELASTOGRAPHY",,http://arxiv.org/pdf/1910.09046,
22,Deep Learning based Quantification of Ovary and Follicles using 3D Transvaginal Ultrasound in Assisted Reproduction,,,2109-2112,"Mathur Praful,Kakwani Karan,Diplav,Kudavelly Srinivas,Ramaraju G. A.","Mathur P,Kakwani K,Diplav,Kudavelly S,Ramaraju GA",Kudavelly S,,"Samsung R&D Inst, Bangalore, Karnataka, India.","Quantification of ovarian and follicular volume and follicle count are performed in clinical practice for diagnosis and management in assisted reproduction. Ovarian volume and Antral Follicle Count (AFC) are typically tracked over the ovulation cycle. Volumetric analysis of ovary and follicle is manual and largely operator dependent. In this manuscript, we have proposed a deep-learning method for automatic simultaneous segmentation of ovary and follicles in 3D Transvaginal Ultrasound (TVUS), namely S-Net. The proposed loss function restricts false detection of follicles outside the ovary. Additionally, we have used multi-layered loss to provide deep supervision for training the network. S-Net is optimized for inference time and memory while utilizing 3D context in the 2D deep-learning network. 66 3D TVUS volumes (13,200 2D image slices) were acquired from 66 subjects in this Institutional Review Board (IRB) approved study. The segmentation framework provides approximately 92% and 87% average DICE overlap with the ground truth annotations for ovary and follicles, respectively. We have obtained state-of-the-art results with a detection rate of 88%, 91% and 98% for follicles of size 2-4mm, 4-12mm and >12mm.",RESERVE MARKERS,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"RESERVE,MARKERS",,,
23,Receptive Field Size as a Key Design Parameter for Ultrasound Image Segmentation with U-Net,,,2117-2120,"Behboodi Bahareh,Fortin Maryse,Belasso Clyde J.,Brooks Rupert,Rivaz Hassan","Behboodi B,Fortin M,Belasso CJ,Brooks R,Rivaz H",Behboodi B,,Concordia University - Canada,"Automatic and accurate segmentation of medical images is an important task due to the direct impact of this procedure on both disease diagnosis and treatment. Segmentation of ultrasound (US) imaging is particularly challenging due to the presence of speckle noise. Recent deep learning approaches have demonstrated remarkable findings in image segmentation tasks, including segmentation of US images. However, many of the newly proposed structures are either task specific and suffer from poor generalization, or are computationally expensive. In this paper, we show that the receptive field plays a more significant role in the network's performance compared to the network's depth or the number of parameters. We further show that by controlling the size of the receptive field, a deep network can instead be replaced by a shallow network.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
24,Deep Learning Based Junctional Zone Quantification using 3D Transvaginal Ultrasound in Assisted Reproduction,,,2133-2136,"Singhal Nitin,Kudavelly Srinivas,Ramaraju G. A.","Singhal N,Kudavelly S,Ramaraju GA",Kudavelly S,,"Samsung Res, Bangalore, Karnataka, India.","The Uterine Junctional Zone (JZ) is identified as an important anatomical region in the implantation process during assisted reproduction. The JZ changes throughout the hormone stimulation cycle and has predictive value for implantation success. Despite advances in imaging technique, the assessment of JZ remains an enigma. The state-of-the-art method to assess the JZ is largely manual, which is time consuming, depends on operator experience, and often introduces subjective bias in assessment. In this paper, we present methods for automated visualization and quantification of the JZ in three-dimensional transvaginal ultrasound imaging (3D-TVUS). JZ is best visualized in the midcoronal plane of the 3D-TVUS uterus acquisition. We propose an algorithm pipeline, which uses a deep learning model to generate a point cloud representing the surface of the endometrium. A regularized midcoronal surface passing through the point cloud is rendered to obtain the midcoronal plane. The automated solution is designed to accommodate multiple structural deformations and pathologies in the uterus. An expert assisted reproduction clinician on 136 3D-TVUS volumes evaluated the results, and reliable performance was observed in more than 89% cases where the automated solution is able to reproduce, and sometimes even outperform the manual workflow. Automation speeds up the clinical workflow approximately by a factor of ten and reduces operator bias.",ENDOMETRIAL THICKNESS,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"ENDOMETRIAL,THICKNESS",,,
25,Deep transfer learning for video-based detection of newborn presence in incubator,,,2147-2150,"Weber Raphael,Simon Antoine,Poree Fabienne,Carrault Guy","Weber R,Simon A,Poree F,Carrault G",Weber R,,Institut National de la Sante et de la Recherche Medicale (Inserm),"Preterm newborns are prone to late-onset sepsis, leading to a high risk of mortality. Video-based analysis of motion is a promising non-invasive approach because the behavior of the newborn is related to his physiological state. But it is needed to analyze only images where the newborn is solely present in incubator. In this context, we propose a method for video-based detection of newborn presence. We use deep transfer learning: bottleneck features are extracted from a pre-trained deep neural network and then a classifier is trained with these features on our database. Moreover, we propose a strategy that allows to take advantage of temporal consistency. On a database of 11 newborns with 56 days of video recordings, the results show a balanced accuracy of 80%.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
26,Detecting falls and estimation of daily habits with depth images using machine learning algorithms,,,2163-2166,"Msaad Soumaya,Cormier Geoffroy,Carrault Guy","Msaad S,Cormier G,Carrault G",Msaad S,,Institut National de la Sante et de la Recherche Medicale (Inserm),"Different approaches have been proposed in the literature to detect the fall of an elderly person. In this paper, we propose a fall detection method based on the classification of parameters extracted from depth images. Three supervised learning methods are compared: decision tree, K-Nearest Neighbors (K-NN) and Random Forests (RF). The methods have been tested on a database of depth images recorded in a nursing home over a period of 43 days. The Random Forests based method yields the best results, achieving 93% sensitivity and 100% specificity when we restrict our study around the bed. Furthermore, this paper also proposes a 37 days follow-up of the person, to try and estimate his or her daily habits.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
27,Orthogonal Region Selection Network for Laryngeal Closure Detection in Laryngoscopy Videos,,,2167-2172,"Wang Yang Yang,Hamad Ali S.,Lever Teresa E.,Bunyak Filiz","Wang YY,Hamad AS,Lever TE,Bunyak F",Bunyak F,,University of Missouri System,"Vocal folds (VFs) play a critical role in breathing, swallowing, and speech production. VF dysfunctions caused by various medical conditions can significantly reduce patients' quality of life and lead to life-threatening conditions such as aspiration pneumonia, caused by food and/or liquid ""in-vasion"" into the windpipe. Laryngeal endoscopy is routinely used in clinical practice to inspect the larynx and to assess the VF function. Unfortunately, the resulting videos are only visually inspected, leading to loss of valuable information that can be used for early diagnosis and disease or treatment monitoring. In this paper, we propose a deep learning-based image analysis solution for automated detection of laryngeal adductor reflex (LAR) events in laryngeal endoscopy videos. Laryngeal endoscopy image analysis is a challenging task because of anatomical variations and various imaging problems. Analysis of LAR events is further challenging because of data imbalance since these are rare events. In order to tackle this problem, we propose a deep learning system that consists of a two-stream network with a novel orthogonal region selection subnetwork. To our best knowledge, this is the first deep learning network that learns to directly map its input to a VF open/close state without first segmenting or tracking the VF region, which drastically reduces labor-intensive manual annotation needed for mask or track generation. The proposed two-stream network and the orthogonal region selection subnetwork allow integration of local and global information for improved performance. The experimental results show promising performance for the automated, objective, and quantitative analysis of LAR events from laryngeal endoscopy videos.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
28,AUTOMATED BOLUS DETECTION IN VIDEOFLUOROSCOPIC IMAGES OF SWALLOWING USING MASK-RCNN,,,2173-2177,"Caliskan Handenur,Mahoney Amanda S.,Coyle James L.,Sejdic Ervin","Caliskan H,Mahoney AS,Coyle JL,Sejdic E",Sejdic E,,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Tracking a liquid or food bolus in videofluoroscopic images during X-ray based diagnostic swallowing examinations is a dominant clinical approach to assess human swallowing function during oral, pharyngeal and esophageal stages of swallowing. This tracking represents a highly challenging problem for clinicians as swallowing is a rapid action. Therefore, we developed a computer-aided method to automate bolus detection and tracking in order to alleviate issues associated with human factors. Specifically, we applied a state-of-the-art deep learning model called Mask-RCNN to detect and segment the bolus in videofluoroscopic image sequences. We trained the algorithm with 450 swallow videos and evaluated with an independent dataset of 50 videos. The algorithm was able to detect and segment the bolus with a mean average precision of 0.49 and an intersection of union of 0.71. The proposed method indicated robust detection results that can help to improve the speed and accuracy of a clinical decision-making process.","DYSPHAGIA,PNEUMONIA",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"DYSPHAGIA,PNEUMONIA",,,
29,End-to-End Deep Diagnosis of X-ray Images,,,2182-2185,"Urinbayev Kudaibergen,Orazbek Yerassyl,Nurambek Yernur,Mirzakhmetov Almas,Varol Huseyin Atakan","Urinbayev K,Orazbek Y,Nurambek Y,Mirzakhmetov A,Varol HA",Varol HA,,Nazarbayev University,"We present an end-to-end deep learning framework for X-ray image diagnosis. As the first step, our system determines whether a submitted image is an X-ray or not. After it classifies the type of the X-ray, it runs the dedicated abnormality classification network. In this work, we only focus on the chest X-rays for abnormality classification. However, the system can be extended to other X-ray types easily. Our deep learning classifiers are based on DenseNet-121 architecture. The test set accuracy obtained for 'X-ray or Not', 'X-ray Type Classification', and 'Chest Abnormality Classification' tasks are 0.987, 0.976, and 0.947, respectively, resulting into an end-to-end accuracy of 0.91. For achieving better results than the state-of-the-art in the 'Chest Abnormality Classification', we utilize the new RAdam optimizer. We also use Gradient-weighted Class Activation Mapping for visual explanation of the results. Our results show the feasibility of a generalized online projectional radiography diagnosis system.","Chest X-ray images,computer-aided diagnosis,digital radiography,deep learning,neural networks,explanatory visualization",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,SEGMENTATION,,http://arxiv.org/pdf/2003.08605,
30,Classifying Pneumonia among Chest X-Rays Using Transfer Learning,,,2186-2189,"Irfan Abdullah,Adivishnu Akash L.,Sze-To Antonio,Dehkharghanian Taher,Rahnamayan Shahryar,Tizhoosh H. R.","Irfan A,Adivishnu AL,Sze-To A,Dehkharghanian T,Rahnamayan S,Tizhoosh HR",Sze-To A,,University of Waterloo,"Chest radiography has become the modality of choice for diagnosing pneumonia. However, analyzing chest X-ray images may be tedious, time-consuming and requiring expert knowledge that might not be available in less-developed regions. therefore, computer-aided diagnosis systems are needed. Recently, many classification systems based on deep learning have been proposed. Despite their success, the high development cost for deep networks is still a hurdle for deployment. Deep transfer learning (or simply transfer learning) has the merit of reducing the development cost by borrowing architectures from trained models followed by slight fine-tuning of some layers. Nevertheless, whether deep transfer learning is effective over training from scratch in the medical setting remains a research question for many applications. In this work, we investigate the use of deep transfer learning to classify pneumonia among chest Xray images. Experimental results demonstrated that, with slight fine-tuning, deep transfer learning brings performance advantage over training from scratch. Three models, ResNet-50, Inception V3 and DensetNet121, were trained separately through transfer learning and from scratch. The former can achieve a 4.1% to 52.5% larger area under the curve (AUC) than those obtained by the latter, suggesting the effectiveness of deep transfer learning for classifying pneumonia in chest X-ray images.",NEURAL-NETWORKS,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,NEURAL-NETWORKS,,,
31,Detection of Trabecular Landmarks for Osteoporosis Prescreening in Dental Panoramic Radiographs,,,2194-2197,"Ren Jiaxiang,Fan Heng,Yang Jie,Ling Haibin","Ren JX,Fan H,Yang J,Ling HB",Ren JX,,State University of New York (SUNY) System,"Dental panoramic radiography (DPR) images have recently attracted increasing attention in osteoporosis analysis because of their inner correlation. Many approaches leverage machine learning techniques (e.g., deep convolutional neural networks (CNNs)) to study DPR images of a patient to provide initial analysis of osteoporosis, which demonstrates promising results and significantly reduces financial cost. However, these methods heavily rely on the trabecula landmarks of DPR images that requires a large amount of manual annotations by dentist, and thus are limited in practical application. Addressing this issue, we propose to automatically detect trabecular landmarks in DPR images. In specific, we first apply CNNs-based detector for trabecular landmark detection and analyze its limitations. Using CNNs-based detection as a baseline, we then introduce a statistic shape model (SSM) for trabecular landmark detection by taking advantage of spatial distribution prior of trabecular landmarks in DPR images and their structural relations. In experiment on 108 images, our solution outperforms CNNs-based detector. Moreover, compared to CNN-based detectors, our method avoids the needs of vast training samples, which is more practical in application.",BONE-MINERAL DENSITY,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"BONE-MINERAL,DENSITY",,,
32,Generation of High-resolution Lung Computed Tomography Images using Generative Adversarial Networks,,,2400-2403,"Hsieh Kuan Yu,Tsai Han-Chun,Chen Guan-Yu","Hsieh KY,Tsai HC,Chen GY",Chen GY,,National Yang Ming Chiao Tung University,"To deal with the limiting data in training for new deep learning modules, we purpose a method to generate high-resolution medical images by implementing generative adversarial networks (GAN) models. Firstly, the boundary equilibrium generative adversarial networks model was used to generate the whole lung computed tomography images. Image inpainting was then integrated to generate the delicate details of the lung part by dividing into a coarse network and a refinement network to inpaint more completed and intricate details. With this method, we aim to increase the amount of high-resolution medical images for future applications in deep learning.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
33,Artificial Neural Network enabling Clinically Meaningful Biological Image Data Generation,,,2404-2407,"Ha Junhyoung,Kim Soonkyum,Baik YaeJun,Lee Dohee,Lee Woosub,Suh SeungBeum","Ha J,Kim S,Baik Y,Lee D,Lee W,Suh S",Suh S,,Korea Institute of Science & Technology (KIST),"Biological experiments for developing efficient cancer therapeutics require significant resources of time and costs particularly in acquiring biological image data. Thanks to recent advances in AI technologies, there have been active researches in generating realistic images by adapting artificial neural networks. Along the same lines, this paper proposes a learning-based method to generate images inheriting biological characteristics. Through a statistical comparison of tumor penetration metrics between generated images and real images, we have shown that forged micrograph images contain vital characteristics to analyze tumor penetration performance of infecting agents, which opens up the promising possibilities for utilizing proposed methods for generating clinically meaningful image data.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
34,A deep learning oriented method for automated 3D reconstruction of carotid arterial trees from MR imaging,,,2408-2411,"Tsakanikas Vassilis D.,Siogkas Panagiotis K.,Mantzaris Michalis D.,Potsika Vassiliki T.,Kigka Vassiliki I,Exarchos Themis P.,Koncar Igor B.,Jovanovic Marija,Vujcic Aleksandra,Ducic Stefan","Tsakanikas VD,Siogkas PK,Mantzaris MD,Potsika VT,Kigka VI,Exarchos TP,Koncar IB,Jovanovic M,Vujcic A,Ducic S",Siogkas PK,,University of Ioannina,"The scope of this paper is to present a new carotid vessel segmentation algorithm implementing the U-net based convolutional neural network architecture. With carotid atherosclerosis being the major cause of stroke in Europe, new methods that can provide more accurate image segmentation of the carotid arterial tree and plaque tissue can help improve early diagnosis, prevention and treatment of carotid disease. Herein, we present a novel methodology combining the U-net model and morphological active contours in an iterative framework that accurately segments the carotid lumen and outer wall. The method automatically produces a 3D meshed model of the carotid bifurcation and smaller branches, using multispectral MR image series obtained from two clinical centres of the TAXINOMISIS study. As indicated by a validation study, the algorithm succeeds high accuracy (99.1% for lumen area and 92.6% for the perimeter) for lumen segmentation. The proposed algorithm will be used in the TAXINOMISIS study to obtain more accurate 3D vessel models for improved computational fluid dynamics simulations and the development of models of atherosclerotic plaque progression.","MAGNETIC-RESONANCE IMAGES,LUMEN SEGMENTATION,WALL,QUANTIFICATION",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"MAGNETIC-RESONANCE,IMAGES,LUMEN,SEGMENTATION,WALL,QUANTIFICATION",,https://zenodo.org/record/3968549/files/EMBC_2020_TAXINOMISIS.pdf,
35,An online deep convolutional polyp lesion prediction over Narrow Band Imaging (NBI),,,2412-2415,"Sierra Franklin,Gutierrez Yesid,Martinez Fabio","Sierra F,Gutierrez Y,Martinez F",Martinez F,,Universidad Industrial de Santander,"Polyps, represented as abnormal protuberances along intestinal track, are the main biomarker to diagnose gastrointestinal cancer. During routine colonoscopies such polyps are localized and coarsely characterized according to microvascular and surface textural patterns. Narrow-band imaging (NBI) sequences have emerged as complementary technique to enhance description of suspicious mucosa surfaces according to blood vessels architectures. Nevertheless, a high number of misleading polyp characterization, together with expert dependency during evaluation, reduce the possibility of effective disease treatments. Additionally, challenges during colonoscopy, such as abrupt camera motions, changes of intensity and artifacts, difficult the diagnosis task. This work introduces a robust frame-level convolutional strategy with the capability to characterize and predict hyperplastic, adenomas and serrated polyps over NBI sequences. The proposed strategy was evaluated over a total of 76 videos achieving an average accuracy of 90,79% to distinguish among these three classes. Remarkably, the approach achieves a 100% of accuracy to differentiate intermediate serrated polyps, whose evaluation is challenging even for expert gastroenterologist. The approach was also favorable to support polyp resection decisions, achieving perfect score on evaluated dataset.","Colorectal cancer,Narrow Band Imaging,online polyp classification",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"COLORECTAL,POLYPS,CLASSIFICATION,CANCER",,,
36,Development and Evaluation of Machine Learning Models for Recovery Prediction after Treatment for Traumatic Brain Injury,,,2416-2420,"Radabaugh Hannah L.,Bonnell Jerry,Dietrich W. Dalton,Bramlett Helen M.,Schwartz Odelia,Sarkar Dilip","Radabaugh HL,Bonnell J,Dietrich WD,Bramlett HM,Schwartz O,Sarkar D",Radabaugh HL,,University of Miami,"Traumatic brain injury (TBI) is a leading cause of death and disability yet treatment strategies remain elusive. Advances in machine learning present exciting opportunities for developing personalized medicine and informing laboratory research. However, their feasibility has yet to be widely assessed in animal research where data are typically limited or in the TBI field where each patient presents with a unique injury. The Operation Brain Trauma Therapy (OBTT) has amassed an animal dataset that spans multiple types of injury, treatment strategies, behavioral assessments, histological measures, and biomarker screenings. This paper aims to analyze these data using supervised learning techniques for the first time by partitioning the dataset into acute input metrics (i.e. 7 days post-injury) and a defined recovery outcome (i.e. memory retention). Preprocessing is then applied to transform the raw OBTT dataset, e.g. developing a class attribute by histogram binning, eliminating borderline cases, and applying principal component analysis (PCA). We find that these steps are also useful in establishing a treatment ranking; Minocycline, a therapy with no significant findings in the OBTT analyses, yields the highest percentage recovery in our ranking. Furthermore, of the seven classifiers we have evaluated, Naive Bayes achieves the best performance (67%) and yields significant improvement over our baseline model on the preprocessed dataset with borderline elimination. We also investigate the effect of testing on individual treatment groups to evaluate which groups are difficult to classify, and note the interpretive qualities of our model that can be clinically relevant.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
37,Automated Assessment of Neonatal Endotracheal Intubation Measured by a Virtual Reality Simulation System,,,2429-2433,"Xiao Xiao,Zhao Shang,Zhang Xiaoke,Soghier Lamia,Hahn James","Xiao X,Zhao S,Zhang XK,Soghier L,Hahn J",Xiao X,,George Washington University,"Manual assessment from experts in neonatal endotracheal intubation (ETI) training is a time-consuming and tedious process. Such subjective, highly variable, and resource-intensive assessment method may not only introduce inter-rater/intra-rater variability, but also represent a serious limitation in many large-scale training programs. Moreover, poor visualization during the procedure prevents instructors from observing the events occurring within the manikin or the patient, which introduces an additional source of error into the assessment. In this paper, we propose a physics-based virtual reality (VR) ETI simulation system that captures the entire motions of the laryngoscope and the endotracheal tube (ETT) in relation to the internal anatomy of the virtual patient. Our system provides a complete visualization of the procedure, offering instructors with comprehensive information for accurate assessment. More importantly, an interpretable machine learning algorithm was developed to automatically assess the ETI performance by training on the performance parameters extracted from the motions and the scores rated by experts. Our results show that the leave-one-out-cross-validation (LOOCV) classification accuracy of the automated assessment algorithm is 80%, which indicates that our system can reliably conduct a consistent and standardized assessment for ETI training.","OROTRACHEAL INTUBATION,MANNEQUIN,SKILLS",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"OROTRACHEAL,INTUBATION,MANNEQUIN,SKILLS",,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7538655,
38,Subject Independent Dementia Risk Prediction Models Using Paralinguistic and Memory Test Features with Feature Warping,,,2540-2543,"Sriskandaraja Kaavya,Ahmed Beena,Valenzuela Michael","Sriskandaraja K,Ahmed B,Valenzuela M",Sriskandaraja K,,University of New South Wales Sydney,"Clinical and biological changes during the prodromal stages of dementia are both complicated and expensive. A biomarker for cognitive reserve exposure would be highly useful as a dementia risk predictor, but has eluded researchers. Speech, which exhibits disfluencies due to dementia, is a good candidate as it is easy to collect and non-invasive. However, previous studies have only looked at the impact of dementia on speech after diagnosis. Here we extend our previous work that showed paralinguistic features extracted from audio recordings of older participants completing the LOGOS episodic memory test can be used to discriminate between high vs low cognitive reserve, hence low vs high risk of dementia. Specifically, we use the clinically validated Lifetime of Experiences Questionnaire (LEQ) to refine our ground truth estimate of cognitive reserve instead of an abridged version. Also, we improve the generalizability of our system by using feature warping to normalize across speakers. Our k-nearest neighbours (KNN) based classifier achieved an accuracy of 84% when trained with paralinguistic features alone and 91% with paralinguistic and episodic memory features.","COGNITIVE LIFE-STYLE,DISEASE,SPEECH",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"COGNITIVE,LIFE-STYLE,DISEASE,SPEECH",,,
39,Preliminary Results on Density Poincare Plot Based Atrial Fibrillation Detection from Premature Atrial/Ventricular Contractions,,,2594-2597,"Bashar Syed Khairul,Han Dong,Zieneddin Fearass,Ding Eric,Walkey Allan J.,McManus David D.,Chon Ki H.","Bashar SK,Han D,Zieneddin F,Ding E,Walkey AJ,McManus DD,Chon KH",Bashar SK,,University of Connecticut,"Detection of Atrial fibrillation (AF) from premature atrial contraction (PAC) and premature ventricular contraction (PVC) is challenging as frequent occurrences of these ectopic beats can mimic the typical irregular patterns of AF. In this paper, we present a preliminary study of using density Poincare plot based machine learning method to detect AF from PAC/PVCs using electrocardiogram (ECG) recordings. First, we propose creation of this new density Poincare plot which is derived from the difference of the heart rate. Next, from this density Poincare plot, template correlation and discrete wavelet transform are used to extract suitable image-based features, which is followed by infinite latent feature selection algorithm to rank the features. Finally, classification of AF vs PAC/PVC is performed using K-Nearest Neighbor, discriminant analysis and support vector machine (SVM) classifiers. Our method is developed and validated using a subset of Medical Information Mart for Intensive Care (MIMIC) III database containing 8 AF and 8 PAC/PVC subjects. Both 10-fold and leave-one-subject-out cross validations are performed to show the robustness of our proposed method. During the 10-fold cross-validation, SVM achieved the best performance with 99.49% sensitivity, 94.51% specificity and 97.29% accuracy with the extracted features while for the leave-one-subject-out, the highest overall accuracy is 90.91%. Moreover, when compared with two state-of-the-art methods, the proposed algorithm achieves superior AF vs. PAC/PVC discrimination performance.","WAVELET TRANSFORM,CLASSIFICATION",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"WAVELET,TRANSFORM,CLASSIFICATION",,,
40,Schrodinger Spectrum Based PPG Features for the Estimation of the Arterial Blood Pressure,,,2683-2686,"Li Peihao,Laleg-Kirati Taous-Meriem","Li PH,Laleg-Kirati TM",Li PH,,King Abdullah University of Science & Technology,"In this paper, photoplethysmogram (PPG) features are combined with supervised machine learning algorithms to estimate arterial blood pressure (ABP). Three algorithms for the estimation of cuffless ABP using PPG signals are compared. Since PPG signals are measured non-invasively, this method guarantees an individuals comfort while not omitting important ABP information. The proposed framework predicts the ABP values by processing PPG signals with semi-classical signal analysis (SCSA) method, extracting several categories of features, which reflect the PPG signal morphology variations. Then, regression algorithms are selected for the ABP estimation. The proposed method is evaluated based on a virtual dataset with more than four thousand subjects and MIMIC II database with over eight thousand subjects for model training and testing. Mean average error (MAE) and standard deviation (STD) are evaluated for different machine learning algorithms during the prediction and estimation process. Multiple linear regression (MLR) meets the AAMI standard in terms of estimation accuracy, which proves that the ABP can be accurately estimated in a nonintrusive fashion. Given the easy implementation of the ABP estimation method, we regard that the proposed features and machine learning algorithms for the cuffless estimation of the ABP can potentially provide the means for mobile healthcare equipment to monitor the ABP continuously.",WAVES,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,WAVES,,,
41,Cuffless Blood Pressure Estimation Using Features Extracted from Carotid Dual-Diameter Waveforms,,,2719-2722,"Ramakrishna Prashanth,Nabeel P. M.,Kiran Raj V,Joseph Jayaraj,Sivaprakasam Mohanasankar","Ramakrishna P,Nabeel PM,Kiran VR,Joseph J,Sivaprakasam M",Ramakrishna P,,New York University,"The major challenges in deep learning approaches to cuffless blood pressure estimation is selecting the most appropriate representative of the blood pulse waveform and extraction of relevant features for data collection. This paper performs an analysis of a novel dataset consisting of 71 features from the carotid dual- diameter waveforms and 4 blood pressure parameters. In particular, the analysis uses gradient boosting and graph-theoretic algorithms to determine (1) features with high predictive power and (2) potential to be pruned. Identifying such features and understanding their physiological significance is important for building blood pressure estimation models using machine learning that is robust across diverse clinical environments and patient sets.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
42,Prediction of atherosclerotic disease progression combining computational modelling with machine learning,,,2760-2763,"Sakellarios Antonis I.,Pezoulas Vasileios C.,Bourantas Christos,Naka Katerina K.,Michalis Lampros K.,Serruys Patrick W.,Stone Gregg,Garcia-Garcia Hector M.,Fotiadis Dimitrios I.","Sakellarios AI,Pezoulas VC,Bourantas C,Naka KK,Michalis LK,Serruys PW,Stone G,Garcia-Garcia HM,Fotiadis DI",Fotiadis DI,,University of Ioannina,"Non-invasive serial computed tomography coronary angiography (CTCA) was acquired from 32 patients and 3D reconstruction of 58 coronary arteries was achieved. The arterial geometries were utilized for blood flow and LDL transport modelling. Navier-Stokes and convection-diffusion equations were employed for simulation of blood flow and LDL transport, respectively. Disease progression was assessed comparing the follow-up and baseline arterial models after co-registration using side branches as anatomical landmarks. A machine learning model for predicting disease progression was built using the Gradient Boosted Trees (GBT) algorithm. The Accuracy, Sensitivity, Specificity and AUC of the developed methodology for predicting lumen area decrease equal was 0.68, 0.56, 0.34 and 0.59, respectively. The best results were found for the prediction of plaque area increase by 20%, with 0.73, 0.67, 0.86, and 0.76 accuracy, sensitivity, specificity andAUC, respectively. This approach outperforms significantly the predictive capability of models based on binary logistic regression.","CORONARY ATHEROSCLEROSIS,PLAQUE DEVELOPMENT,NATURAL-HISTORY",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"CORONARY,ATHEROSCLEROSIS,PLAQUE,DEVELOPMENT,NATURAL-HISTORY",,,
43,Prediction of Septic Shock Onset in ICU by Instantaneous Monitoring of Vital Signs,,,2768-2771,"Mollura Maximiliano,Romano Stefano,Mantoan Giulio,Lehman Li-wei,Barbieri Riccardo","Mollura M,Romano S,Mantoan G,Lehman LW,Barbieri R",Mollura M,,Polytechnic University of Milan,"Septic Shock is a critical pathological state that affects patients entering the intensive care unit (ICU). Many studies have been directed to characterize and predict the onset of the septic shock, both in ICU and in the Emergency Department employing data extracted from the Electronic Health Records. Recently, machine learning algorithms have been successfully employed to help characterize septic shock in a more objective and automatic fashion. Only a few of these studies employ information contained in the continuously recorded vital signs such as electrocardiogram and arterial blood pressure. In particular, we have devised a novel feature estimation procedure able to consider instantaneous dynamics related to cardiovascular control. This work aims at developing a short-term prediction algorithm for identifying patients experiencing septic shock among a population of 100 septic patients extracted from the MIMIC-III clinical and waveform database. Among all the results obtained from several trained machine learning models, the best performance reached an AUC on the test set equal to 0.93 (Accuracy=0.85, Sensitivity=0.89 and Specificity=0.82).","INTERNATIONAL CONSENSUS DEFINITIONS,HEART-RATE-VARIABILITY,BLOOD-PRESSURE,SEPSIS,IDENTIFICATION",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"INTERNATIONAL,CONSENSUS,DEFINITIONS,HEART-RATE-VARIABILITY,BLOOD-PRESSURE,SEPSIS,IDENTIFICATION",,,
44,Site specific prediction of PCI stenting based on imaging and biomechanics data using gradient boosting tree ensembles,,,2812-2815,"Kigka Vassiliki I.,Sakellarios Antonis I.,Georga Eleni I.,Siogkas Panagiotis,Tsompou Panagiota,Kyriakidis Savvas,Rocchiccioli Silvia,Pelosi Gualtiero,Naka Katerina,Michalis Lampros K.","Kigka VI,Sakellarios AI,Georga EI,Siogkas P,Tsompou P,Kyriakidis S,Rocchiccioli S,Pelosi G,Naka K,Michalis LK",Fotiadis DI,,University of Ioannina,"Cardiovascular diseases are nowadays considered as the main cause of morbidity and mortality worldwide. Coronary Artery Disease (CAD), the most typical form of cardiovascular disease is diagnosed by a variety of imaging modalities, both invasive and non-invasive, which involve either risk implications or high cost. Therefore, several attempts have been undertaken to early diagnose and predict either the high CAD risk patients or the cardiovascular events, implementing machine learning techniques. The purpose of this study is to present a classification scheme for the prediction of Percutaneous Coronary Intervention (PCI) stenting placement, using image-based data. The proposed classification model is a gradient boosting classifier, incorporated into a class imbalance handling technique, the Easy ensemble scheme and aims to classify coronary segments into high CAD risk and low CAD risk, based on their PCI placement. Through this study, we investigate the importance of image based features, concluding that the combination of the coronary degree of stenosis and the fractional flow reserve achieves accuracy 78%.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
45,Classification of Aortic Stenosis Before and After Transcatheter Aortic Valve Replacement Using Cardio-mechanical Modalities,,,2820-2823,"Yang Chenxi,Ojha Banish,Aranoff Nicole D.,Green Philip,Tavassolian Negar","Yang CX,Ojha B,Aranoff ND,Green P,Tavassolian N",Tavassolian N,,Stevens Institute of Technology,"This paper reports our study on the impact of transcatheter aortic valve replacement (TAVR) on the classification of aortic stenosis (AS) patients using cardio-mechanical modalities. Machine learning algorithms such as decision tree, random forest, and neural network were applied to conduct two tasks. Firstly, the pre- and post-TAVR data are evaluated with the classifiers trained in the literature. Secondly, new classifiers are trained to classify between pre- and post-TAVR data. Using analysis of variance, the features that are significantly different between pre- and post-TAVR patients are selected and compared to the features used in the pre-trained classifiers. The results suggest that pre-TAVR subjects could be classified as AS patients but post-TAVR could not be classified as healthy subjects. The features which differentiate pre- and post-TAVR patients reveal different distributions compared to the features that classify AS patients and healthy subjects. These results could guide future work in the classification of AS as well as the evaluation of the recovery status of patients after TAVR treatment.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
46,Detecting mTBI by Learning Spatio-temporal Characteristics of Widefield Calcium Imaging Data Using Deep Learning,,,2917-2920,"Koochaki Fatemeh,Shamsi Foroogh,Najafizadeh Laleh","Koochaki F,Shamsi F,Najafizadeh L",Koochaki F,,Rutgers State University New Brunswick,"Early diagnosis of mild traumatic brain injury (mTBI) is of great interest to the neuroscience and medical communities. Widefield optical imaging of neuronal populations over the cerebral cortex in animals provides a unique opportunity to study injury-induced alternations in brain function. Using this technique, along with deep learning, the goal of this paper is to develop a framework for the detection of mTBI. Cortical activities in transgenic calcium reporter mice expressing GCaMP6s are obtained using widefield imaging from 8 mice before and after inducing an injury. Two deep learning models for differentiating mTBI from normal conditions are proposed. One model is based on the convolutional neural network-long short term memory (CNN-LSTM), and the second model is based on a 3D-convolutional neural network (3D-CNN). These two models offer the ability to capture features both in the spatial and temporal domains. Results for the average classification accuracy for the CNN-LSTM and the 3D-CNN are 97.24% and 91.34%, respectively. These results are notably higher than the case of using the classical machine learning methods, demonstrating the importance of utilizing both the spatial and temporal information for early detection of mTBI.",TRAUMATIC BRAIN-INJURY,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"TRAUMATIC,BRAIN-INJURY",,,
47,A Multi-view CNN with Novel Variance Layer for Motor Imagery Brain Computer Interface,,,2950-2953,"Mane Ravikiran,Robinson Neethu,Vinod A. P.,Lee Seong-Whan,Guan Cuntai","Mane R,Robinson N,Vinod AP,Lee SW,Guan CT",Guan CT,,Nanyang Technological University & National Institute of Education (NIE) Singapore,"Accurate and robust classification of Motor Imagery (MI) from Electroencephalography (EEG) signals is among the most challenging tasks in Brain-Computer Interface (BCI) field. To address this challenge, this paper proposes a novel, neuro-physiologically inspired convolutional neural network (CNN) named Filter-Bank Convolutional Network (FBCNet) for MI classification. Capturing neurophysiological signatures of MI, FBCNet first creates a multi-view representation of the data by bandpass-filtering the EEG into multiple frequency bands. Next, spatially discriminative patterns for each view are learned using a CNN layer. Finally, the temporal information is aggregated using a new variance layer and a fully connected layer classifies the resultant features into MI classes. We evaluate the performance of FBCNet on a publicly available dataset from Korea University for classification of left vs right hand MI in a subject-specific 10-fold cross-validation setting. Results show that FBCNet achieves more than 6.7% higher accuracy compared to other state-of-the-art deep learning architectures while requiring less than 1% of the learning parameters. We explain the higher classification accuracy achieved by FBCNet using feature visualization where we show the superiority of FBCNet in learning interpretable and highly generalizable discriminative features. We provide the source code of FBCNet for reproducibility of results.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
48,A Transfer Learning Framework for RSVP-based Brain Computer Interface,,,2963-2968,"Wei Wei,Qiu Shuang,Ma Xuelin,Li Dan,Zhang Chuncheng,He Huiguang","Wei W,Qiu S,Ma XL,Li D,Zhang CC,He HG",He HG,,Chinese Academy of Sciences,"Rapid Serial Visual Presentation (RSVP)-based Brain-Computer Interface (BCI) is an efficient information detection technology by detecting event-related brain responses evoked by target visual stimuli. However, a time-consuming calibration procedure is needed before a new user can use this system. Thus, it is important to reduce calibration efforts for BCI applications. In this paper, we collect an RSVP-based electroencephalogram (EEG) dataset, which includes 11 subjects. The experimental task is image retrieval. Also, we propose a multi-source transfer learning framework by utilizing data from other subjects to reduce the data requirement on the new subject for training the model. A source-selection strategy is firstly adopted to avoid negative transfer. And then, we propose a transfer learning network based on domain adversarial training. The convolutional neural network (CNN)-based network is designed to extract common features of EEG data from different subjects, while the discriminator tries to distinguish features from different subjects. In addition, a classifier is added for learning semantic information. Also, conditional information and gradient penalty are added to enable stable training of the adversarial network and improve performance. The experimental results demonstrate that our proposed method outperforms a series of state-of-the-art and baseline approaches.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
49,Weighted Transfer Learning of Dynamic Time Warped Data for Motor Imagery based Brain Computer Interfaces,,,2977-2980,"Giles Joshua,Ang Kai Keng,Mihaylova Lyudmila,Arvaneh Mahnaz","Giles J,Ang KK,Mihaylova L,Arvaneh M",Giles J,,University of Sheffield,"A large amount of calibration data is typically needed to train an electroencephalogram (EEG)-based brain-computer interfaces (BCI) due to the non-stationary nature of EEG data. This paper proposes a novel weighted transfer learning algorithm using a dynamic time warping (DTW) based alignment method to alleviate this need by using data from other subjects. DTW-based alignment is first applied to reduce the temporal variations between a specific subject data and the transfer learning data from other subjects. Next, similarity is measured using Kullback Leibler divergence (KL) between the DTW aligned data and the specific subject data. The other subjects' data are then weighted based on their KL similarity to each trials of the specific subject data. This weighted data from other subjects are then used to train the BCI model of the specific subject. An experiment was performed on publicly available BCI Competition IV dataset 2a. The proposed algorithm yielded an average improvement of 9% compared to a subject-specific BCI model trained with 4 trials, and the results yielded an average improvement of 10% compared to naive transfer learning. Overall, the proposed DTW-aligned KL weighted transfer learning algorithm show promise to alleviate the need of large amount of calibration data by using only a short calibration data.",COMMON SPATIAL-PATTERNS,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"COMMON,SPATIAL-PATTERNS",,https://eprints.whiterose.ac.uk/160761/1/EMBC_2020_conference__Copy_%20%286%29.pdf,
50,Motor Imagery Classification of Finger Motions Using Multiclass CSP,,,2991-2994,"Kato Masaki,Kanoga Suguru,Hoshino Takayuki,Fukami Tadanori","Kato M,Kanoga S,Hoshino T,Fukami T",Kato M,,Yamagata University,"Electroencephalogram (EEG) data during motor imagery tasks regarding small-scale physical dynamics such as finger motions have low discriminability because capturing the spatial difference of the motions is difficult. We assumed that more discriminative features can be captured if spatial filters maximize the independence of each class data. This study constructed spatial filters named multiclass common spatial pattern (CSP), which maximize an approximation of mutual information of extracted components and class labels, and applied them to a five-class motor-imagery dataset containing finger motion tasks. By applying multiclass CSP, the classification accuracies were improved (Mean +/- SD: 40.6 +/- 10.1%) compared with classical CSP (21.8 +/- 2.5%) and no spatial filtering case (38.7 +/- 10.0%). In addition, we visualized learned spatial filters to assess the trend of discriminative features of finger motions. For these results, it was clear that multiclass CSP captured task-specific spatial maps for each finger motion and outperformed multiclass motor-imagery classification performance about 2% even when the tasks are small-scale physical dynamics.",EEG,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,EEG,,,
51,Decoding of Grasp Motions from EEG Signals Based on a Novel Data Augmentation Strategy,,,3015-3018,"Cho Jeong-Hyun,Jeong Ji-Hoon,Lee Seong-Whan","Cho JH,Jeong JH,Lee SW",Lee SW,,Korea University,"Electroencephalogram (EEG) based braincomputer interface (BCI) systems are useful tools for clinical purposes like neural prostheses. In this study, we collected EEG signals related to grasp motions. Five healthy subjects participated in this experiment. They executed and imagined five sustained-grasp actions. We proposed a novel data augmentation method that increases the amount of training data using labels obtained from electromyogram (EMG) signals analysis. For implementation, we recorded EEG and EMG simultaneously. The data augmentation over the original EEG data concluded higher classification accuracy than other competitors. As a result, we obtained the average classification accuracy of 52.49(+/- 8.74)% for motor execution (ME) and 40.36(+/- 3.39)% for motor imagery (MI). These are 9.30% and 6.19% higher, respectively than the result of the comparable methods. Moreover, the proposed method could minimize the need for the calibration session, which reduces the practicality of most BCIs. This result is encouraging, and the proposed method could potentially be used in future applications such as a BCI-driven robot control for handling various daily use objects.","MOTOR IMAGERY,SUBJECT",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"MOTOR,IMAGERY,SUBJECT",,http://arxiv.org/pdf/2005.04881,
52,Optimizing Time-Frequency Feature Extraction and Channel Selection through Gradient Backpropagation to Improve Action Decoding based on Subthalamic Local Field Potentials,,,3023-3026,"Martineau Thomas,He Shenghong,Vaidyanathan Ravi,Brown Peter,Tan Huiling","Martineau T,He SH,Vaidyanathan R,Brown P,Tan HT",Tan HT,,University of Oxford,"Neural oscillating patterns, or time-frequency features, predicting voluntary motor intention, can be extracted from the local field potentials (LFPs) recorded from the sub-thalamic nucleus (STN) or thalamus of human patients implanted with deep brain stimulation (DBS) electrodes for the treatment of movement disorders. This paper investigates the optimization of signal conditioning processes using deep learning to augment time-frequency feature extraction from LFP signals, with the aim of improving the performance of real-time decoding of voluntary motor states. A brain-computer interface (BCI) pipeline capable of continuously classifying discrete pinch grip states from LFPs was designed in Pytorch, a deep learning framework. The pipeline was implemented offline on LFPs recorded from 5 different patients bilaterally implanted with DBS electrodes. Optimizing channel combination in different frequency bands and frequency domain feature extraction demonstrated improved classification accuracy of pinch grip detection and laterality of the pinch (either pinch of the left hand or pinch of the right hand). Overall, the optimized BCI pipeline achieved a maximal average classification accuracy of 79.67 +/- 10.02% when detecting all pinches and 67.06 +/- 10.14% when considering the laterality of the pinch.",NUCLEUS,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,NUCLEUS,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7116197,
53,Federated Transfer Learning for EEG Signal Classification,,,3040-3045,"Ju Ce,Gao Dashan,Mane Ravikiran,Tan Ben,Liu Yang,Guan Cuntai","Ju C,Gao DS,Mane R,Tan B,Liu Y,Guan CT",Ju C,,"WeBank Co Ltd, Shenzhen, Peoples R China.","The success of deep learning (DL) methods in the Brain-Computer Interfaces (BCI) field for classification of electroencephalographic (EEG) recordings has been restricted by the lack of large datasets. Privacy concerns associated with EEG signals limit the possibility of constructing a large EEG-BCI dataset by the conglomeration of multiple small ones for jointly training machine learning models. Hence, in this paper, we propose a novel privacy-preserving DL architecture named federated transfer learning (FTL) for EEG classification that is based on the federated learning framework. Working with the single-trial covariance matrix, the proposed architecture extracts common discriminative information from multi-subject EEG data with the help of domain adaptation techniques. We evaluate the performance of the proposed architecture on the PhysioNet dataset for 2-class motor imagery classification. While avoiding the actual data sharing, our FTL approach achieves 2% higher classification accuracy in a subject-adaptive analysis. Also, in the absence of multi-subject data, our architecture provides 6% better accuracy compared to other stateof-the-art DL architectures.",COMMON SPATIAL-PATTERN,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"COMMON,SPATIAL-PATTERN",,http://arxiv.org/pdf/2004.12321,
54,Orthogonalizing the Activity of Two Neural Units for 2D Cursor Movement Control,,,3046-3049,"Zheng Qi,Zhang Yiwei,Wan Zijun,Malik Wasim Q.,Chen Weidong,Zhang Shaomin","Zheng Q,Zhang YW,Wan ZJ,Malik WQ,Chen WD,Zhang SM",Chen WD,,Zhejiang University,"In the design of brain-machine interface (BMI), as the number of electrodes used to collect neural spike signals declines slowly, it is important to be able to decode with fewer units. We tried to train a monkey to control a cursor to perform a two-dimensional (2D) center-out task smoothly with spiking activities only from two units (direct units). At the same time, we studied how the direct units did change their tuning to the preferred direction during BMI training and tried to explore the underlying mechanism of how the monkey learned to control the cursor with their neural signals. In this study, we observed that both direct units slowly changed their preferred directions during BMI learning. Although the initial angles between the preferred directions of 3 pairs units are different, the angle between their preferred directions approached 90 degrees at the end of the training. Our results imply that BMI learning made the two units independent of each other. To our knowledge, it is the first time to demonstrate that only two units could be used to control a 2D cursor movements. Meanwhile, orthogonalizing the activities of two units driven by BMI learning in this study implies that the plasticity of the motor cortex is capable of providing an efficient strategy for motor control.","CORTICAL CONTROL,ARM",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"CORTICAL,CONTROL,ARM",,,
55,Four-Way Classification of EEG Responses To Virtual Robot Navigation,,,3050-3053,"Wirth Christopher,Toth Jake,Arvaneh Mahnaz","Wirth C,Toth J,Arvaneh M",Wirth C,,University of Sheffield,"Studies have shown the possibility of using brain signals that are automatically generated while observing a navigation task as feedback for semi-autonomous control of a robot. This allows the robot to learn quasi-optimal routes to intended targets. We have combined the subclassification of two different types of navigational errors, with the subclassification of two different types of correct navigational actions, to create a 4-way classification strategy, providing detailed information about the type of action the robot performed. We used a 2-stage stepwise linear discriminant analysis approach, and tested this using brain signals from 8 and 14 participants observing two robot navigation tasks. Classification results were significantly above the chance level, with mean overall accuracy of 44.3% and 36.0% for the two datasets. As a proof of concept, we have shown that it is possible to perform fine-grained, 4-way classification of robot navigational actions, based on the electroencephalogram responses of participants who only had to observe the task. This study provides the next step towards comprehensive implicit brain-machine communication, and towards an efficient semi-autonomous brain-computer interface.","ERROR-DETECTION,P300,NUMBER",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"ERROR-DETECTION,P300,NUMBER",,https://eprints.whiterose.ac.uk/160786/1/Four_way_classification_final_EMBC_version.pdf,
56,Prediction of Motor Imagery Performance based on Pre-Trial Spatio-Spectral Alertness Features,,,3062-3065,"Torkamani-Azar Mastaneh,Jafarifarmand Aysa,Cetin Mujdat","Torkamani-Azar M,Jafarifarmand A,Cetin M",Jafarifarmand A,,Sabanci University,"Electroencephalogram (EEG) based brain-computer interfaces (BCIs) enable communication by interpreting the user intent based on measured brain electrical activity. Such interpretation is usually performed by supervised classifiers constructed in training sessions. However, changes in cognitive states of the user, such as alertness and vigilance, during test sessions lead to variations in EEG patterns, causing classification performance decline in BCI systems. This research focuses on effects of alertness on the performance of motor imagery (MI) BCI as a common mental control paradigm. It proposes a new protocol to predict MI performance decline by alertness-related pre-trial spatio-spectral EEG features. The proposed protocol can be used for adapting the classifier or restoring alertness based on the cognitive state of the user during BCI applications.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
57,Covariant Cluster Transfer for Kernel Reinforcement Learning in Brain-Machine Interface,,,3086-3089,"Zhang Xiang,Wang Yiwen","Zhang X,Wang YW",Wang YW,,Hong Kong University of Science & Technology,"Brain-Machine Interface (BMI) provides a promising way to help disabled people restore their motor functions. The patients are able to control the external devices directly from their neural signals by the decoder. Due to various reasons such as mental fatigue and distraction, the distribution of the neural signals might change, which might lead to poor performance for the decoder. In this case, we need to calibrate the parameters before each session, which needs the professionals to label the data and is not convenient for the patient's usage at home. In this paper, we propose a covariant cluster transfer mechanism for the kernel reinforcement learning (RL) algorithm to speed up the adaptation across sessions. The parameters of the decoder will adaptively change according to a reward signal, which could be easily set by the patient. More importantly, we cluster the neural patterns in previous sessions. The cluster represents the conditional distribution from neural patterns to actions. When a distinct neural pattern appears in the new session, the nearest cluster will be transferred. In this way, the knowledge from the old session could be utilized to accelerate the learning in the new session. Our proposed algorithm is tested on the simulated neural data where the neural signal's distribution differs across sessions. Compared with the training from random initialization and a weight transfer policy, our proposed cluster transfer mechanism maintains a significantly higher success rate and a faster adaptation when the conditional distribution from neural signals to actions remains similar.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
58,Dual-Task Gait Assessment and Machine Learning for Early-detection of Cognitive Decline,,,3204-3207,"Boettcher Lillian N.,Hssayeni Murtadha,Rosenfeld Amie,Tolea Magdalena I.,Galvin James E.,Ghoraani Behnaz","Boettcher LN,Hssayeni M,Rosenfeld A,Tolea MI,Galvin JE,Ghoraani B",Boettcher LN,,State University System of Florida,"Alzheimer's disease (AD) affects approximately 30 million people worldwide, and this number is predicted to triple by 2050 unless further discoveries facilitate the early detection and prevention of the disease. Computerized walkways for simultaneous assessment of motor-cognitive performance, known as a dual-task assessment, has been used to associate changes in gait characteristics to mild cognitive impairment (MCI) with early-stage disease. However, to our best knowledge, there is no validated method to detect MCI using the collective analysis of these gait characteristics. In this paper, we develop a machine learning approach to analyze the gait data from the dual-task assessment in order to detect subjects with cognitive impairment from healthy individuals. We collected dual-task gait data from a computerized walkway of a total of 92 subjects with 31 healthy control (HC) and 61 MCI. Using support vector machine (SVM) and gradient tree boosting, we developed a classifier to differentiate MCI from HC subjects and compared the results with a paper-based questionnaire assessment that has been commonly used in clinical practice. SVM provided the highest accuracy of 77.17% with 81.97% sensitivity and 67.74% specificity. Our results indicate the potential of machine learning + dual-task assessment to enable early diagnosis of cognitive decline before it advances to dementia and AD, so that early intervention or prevention strategies can be initiated.","Alzheimer's Disease,Dementia,Cognitive Impairment,Gait Performance,Dual-Task Assessment,Support Vector Machine,gradient tree boosting",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"IMPAIRMENT,ALZHEIMERS",,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8324322,
59,Right Temporal Oscillations of Infants in Relation to Contingent Learning,,,3273-3276,"Guo Xiaoyu,Zhang Janet,Cheung Roy T. H.,Chan Rosa H. M.,Chen Chao-Ying","Guo XY,Zhang J,Cheung RTH,Chan RHM,Chen CY",Guo XY,,City University of Hong Kong,"Contingent learning is an agent for infants to explore the environment, which enhances the maturation of different developmental domains. This paper presents one of the first to investigate neural activities related to contingent learning of infants by analyzing their motor response that could elicit an audio-visual feedback. Three different kinds of motor response of infants were investigated, including unilateral kicks, synchronized kicks, and alternate kicks. Electroencephalographic (EEG) signals of infants were recorded before the motor experiments. Higher theta band power and lower upper beta power at the right temporal lobe of infants predicted a higher ratio of total unilateral kicks and a lower ratio of synchronized kicks at the later acquisition stage of the experiment. As contingent learning could be reflected by specific motor response in relation to the audio-visual stimuli, the results suggested that right temporal oscillations could predict different levels of contingent learning of infants.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
60,Bilaterally Mirrored Movements Improve the Accuracy and Precision of Training Data for Supervised Learning of Neural or Myoelectric Prosthetic Control,,,3297-3301,"George Jacob A.,Tully Troy N.,Colgan Paul C.,Clark Gregory A.","George JA,Tully TN,Colgan PC,Clark GA",George JA,,Utah System of Higher Education,"Intuitive control of prostheses relies on training algorithms to correlate biological recordings to motor intent. The quality of the training dataset is critical to run-time performance, but it is difficult to label hand kinematics accurately after the hand has been amputated. We quantified the accuracy and precision of labeling hand kinematics for two different training approaches: 1) assuming a participant is perfectly mimicking predetermined motions of a prosthesis (mimicked training), and 2) assuming a participant is perfectly mirroring their contralateral hand during identical bilateral movements (mirrored training). We compared these approaches in non-amputee individuals, using an infrared camera to track eight different joint angles of the hands in real-time. Aggregate data revealed that mimicked training does not account for biomechanical coupling or temporal changes in hand posture. Mirrored training was significantly more accurate and precise at labeling hand kinematics. However, when training a modified Kalman filter to estimate motor intent, the mimicked and mirrored training approaches were not significantly different. The results suggest that the mirrored training approach creates a more faithful but more complex dataset. Advanced algorithms, more capable of learning the complex mirrored training dataset, may yield better run-time prosthetic control.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,http://arxiv.org/pdf/2001.08807,
61,EMG-Based Hand Gesture Classification with Long Short-Term Memory Deep Recurrent Neural Networks,,,3302-3305,"Jabbari Milad,Khushaba Rami N.,Nazarpour Kianoush","Jabbari M,Khushaba RN,Nazarpour K",Jabbari M,,Newcastle University - UK,"Electromyogram (EMG) pattern recognition has been utilized with the traditional machine and deep learning architectures as a control strategy for upper-limb prostheses. However, most of these learning architectures, including those in convolutional neural networks, focus the spatial correlations only; but muscle contractions have a strong temporal dependency. Our primary aim in this paper is to investigate the effectiveness of recurrent deep learning networks in EMG classification as they can learn long-term and non-linear dynamics of time series. We used a Long Short-Term Memory (LSTM-based) neural network to perform multiclass classification with six grip gestures at three different force levels (low, medium, and high) generated by nine amputees. Four different feature sets were extracted from the raw signals and fed to LSTM. Moreover, to investigate a generalization of the proposed method, three different training approaches were tested including 1) training the network with feature extracted from one specific force level and testing it with the same force level, 2) training the network with one specific force level and testing it with two remained force levels, and 3) training the network with all of the force levels and testing it with a single force level. Our results show that LSTM-based neural network can provide reliable performance with average classification errors of around 9% across all nine amputees and force levels. We demonstrate the applicability of deep learning for upper-limb prosthesis control.","Electromyography signal,LSTM,prosthesis",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
62,Classification of Electroencephalogram in a Mouse Model of Traumatic Brain Injury Using Machine Learning Approaches,,,3335-3338,"Vishwanath Manoj,Jafarlou Salar,Shin Ikhwan,Dutt Nikil,Rahmani Amir M.,Lim Miranda M.,Cao Hung","Vishwanath M,Jafarlou S,Shin I,Dutt N,Rahmani AM,Lim MM,Cao H",Cao H,,University of California System,"Traumatic Brain Injury (TBI) is highly prevalent, affecting similar to 1% of the U.S. population, with lifetime economic costs estimated to be over $75 billion. In the U.S., there are about 50,000 deaths annually related to TBI, and many others are permanently disabled. However, it is currently unknown which individuals will develop persistent disability following TBI and what brain mechanisms underlie these distinct populations. The pathophysiologic causes for those are most likely multifactorial. Electroencephalogram (EEG) has been used as a promising quantitative measure for TBI diagnosis and prognosis. The recent rise of advanced data science approaches such as machine learning and deep learning holds promise to further analyze EEG data, looking for EEG biomarkers of neurological disease, including TBI. In this work, we investigated various machine learning approaches on our unique 24-hour recording dataset of a mouse TBI model, in order to look for an optimal scheme in classification of TBI and control subjects. The epoch lengths were 1 and 2 minutes. The results were promising with accuracy of similar to 80-90% when appropriate features and parameters were used using a small number of subjects (5 shams and 4 TBIs). We are thus confident that, with more data and studies, we would be able to detect TBI accurately, not only via long-term recordings but also in practical scenarios, with EEG data obtained from simple wearables in the daily life.","Traumatic Brain Injury,Electroencephalogram,Machine Learning,Neural Networks,Classification of TBI",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"QUANTITATIVE,EEG,CONCUSSION",,,
63,Reinforcement Learning based Decoding Using Internal Reward for Time Delayed Task in Brain Machine Interfaces,,,3351-3354,"Shen Xiang,Zhang Xiang,Huang Yifan,Chen Shuhang,Wang Yiwen","Shen X,Zhang X,Huang YF,Chen SH,Wang YW",Wang YW,,Hong Kong University of Science & Technology,"Reinforcement learning (RL) algorithm interprets neural signals into movement intentions with the guidance of the reward in Brain-machine interfaces (BMIs). Current RL algorithms generally work for the tasks with immediate rewards delivery, and lack of efficiency in delayed reward task. Prefrontal cortex, including medial prefrontal cortex(mPFC), has been demonstrated to assign credit to intermediate steps, which reinforces preceding action more efficiently. In this paper, we propose to simulate the functionality of mPFC activities as intermediate rewards to train a RL based decoder in a two-step movement task. A support vector machine (SVM) is adopted to verify if the subject expects a reward due to the accomplishment of a subtask from mPFC activity. Then this discrimination result will be utilized to guide the training of the RL decoder for each step respectively. Here, we apply the Sarsa-style attention-gated reinforcement learning (SAGREL) as the decoder to interpret motor cortex(M1) activity to action states. We test on in vivo primary motor cortex (M1) and mPFC data collected from rats, where the rats need to first trigger the start and then press lever for rewards using M1 signals. SAGREL using intermediate rewards from mPFC activities achieves a prediction accuracy of 66.8% +/- 2.0.% (mean +/- std) %, which is significantly better than the one using the reward by the end of trial (45.9.% +/- 1.2%). This reveals the potentials of modelling mPFC activities as intermediate rewards for the delayed reward tasks.",NEURONS,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,NEURONS,,,
64,Enhancing performance of SSVEP-based BCI by unsupervised learning information from test trials,,,3359-3362,"Wang Lijie,Xu Minpeng,Mei Jie,Han Jin,Wang Yijun,Jung Tzyy-Ping,Ming Dong","Wang LJ,Xu MP,Mei J,Han J,Wang YJ,Jung TP,Ming D",Xu MP,,Tianjin University,"Steady-State Visual Evoked Potentials (SSVEPs) have become one of the most used neural signals for brain-computer interfaces (BCIs) due to their stability and high signal-to-noise rate. However, the performance of SSVEP-based BCIs would degrade with a few training samples. This study was proposed to enhance the detection of SSVEP by combining the supervised learning information from training samples and the unsupervised learning information from the trial to be tested. A new method, i.e. cyclic shift trials (CST), was proposed to generate new calibration samples from the test data, which were furtherly used to create the templates and spatial filters of task-related component analysis (TRCA). The test-trial templates and spatial filters were combined with training-sample templates and spatial filters to recognize SSVEP. The proposed algorithm was tested on a benchmark dataset. As a result, it reached significantly higher classification accuracy than traditional TRCA when only two training samples were used. Specifically, the accuracy was improved by 9.5% for 0.7s data. Therefore, this study demonstrates CST is effective to improve the performance of SSVEP-BCI.","Steady-State Visual Evoked Potentials (SSVEPs),Brain-Computer Interfaces (BCIs),cyclic shift trials(CST),task-related component analysis (TRCA)",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,STEADY-STATE,,,
65,Electrophysiological Correlates of Brain Health Help Diagnose Epilepsy and Lateralize Seizure Focus,,,3460-3464,"Varatharajah Yogatheesan,Berry Brent,Joseph Boney,Balzekas Irena,Kremen Vaclav,Brinkmann Benjamin,Worrell Gregory,Iyer Ravishankar","Varatharajah Y,Berry B,Joseph B,Balzekas I,Kremen V,Brinkmann B,Worrell G,Iyer R",Varatharajah Y,,University of Illinois System,"The absence of epileptiform activity in a scalp electroencephalogram (EEG) recorded from a potential epilepsy patient can cause delays in clinical care delivery. Here we present a machine-learning-based approach to find evidence for epilepsy in scalp EEGs that do not contain any epileptiform activity, according to expert visual review (i.e., ""normal"" EEGs). We found that deviations in the EEG features representing brain health, such as the alpha rhythm, can indicate the potential for epilepsy and help lateralize seizure focus, even when commonly recognized epileptiform features are absent. Hence, we developed a machine-learning-based approach that utilizes alpha-rhythm-related features to classify 1) whether an EEG was recorded from an epilepsy patient, and 2) if so, the seizure-generating side of the patient's brain. We evaluated our approach using ""normal"" scalp EEGs of 48 patients with drug-resistant focal epilepsy and 144 healthy individuals, and a naive Bayes classifier achieved area under ROC curve (AUC) values of 0.81 and 0.72 for the two classification tasks, respectively. These findings suggest that our methodology is useful in the absence of interictal epileptiform activity and can enhance the probability of diagnosing epilepsy at the earliest possible time.","EEG,CLASSIFICATION,RECURRENCE,ACCURACY",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"EEG,CLASSIFICATION,RECURRENCE,ACCURACY",,,
66,Deep Canonical Correlation Analysis For Decoding The Auditory Brain,,,3505-3508,"Katthi Jaswanth Reddy,Ganapathy Sriram,Kothinti Sandeep,Slaney Malcolm","Katthi JR,Ganapathy S,Kothinti S,Slaney M",Katthi JR,,Indian Institute of Science (IISC) - Bangalore,"The process of decoding the auditory brain for an acoustic stimulus involves finding the relationship between the audio input and the brain activity measured in terms of Electroencephalography (EEG) recordings. Prior methods focus on linear analysis methods like Canonical Correlation Analysis (CCA) to establish a relationship. In this paper, we present a deep learning framework that is learned to maximize correlation. For dealing with high levels of noise in EEG data, we employ regularization techniques and experiment with various model architectures. With a paired dataset of audio envelope and EEG, we perform several experiments with deep correlation analysis using forward and backward correlation models. In these experiments, we show that regularized deep CCA is consistently able to outperform the linear models in terms of providing improved correlation (up to 9% absolute improvement in Pearson correlation which is statistically significant). We present an analysis that highlights the benefits of using dropouts for neural network regularization in the deep CCA model.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
67,Temporal dependency in automatic sleep scoring via deep learning based architectures: An empirical study,,,3509-3512,"Fiorillo Luigi,Wand Michael,Marino Italo,Favaro Paolo,Faraci Francesca D.","Fiorillo L,Wand M,Marino I,Favaro P,Faraci FD",Fiorillo L,,"Univ Appl Sci & Arts Southern Switzerland, Inst Informat Syst & Networking, Manno, Switzerland.","The present study evaluates how effectively a deep learning based sleep scoring system does encode the temporal dependency from raw polysomnography signals. An exhaustive range of neural networks, including state of the art architecture, have been used in the evaluation. The architectures have been assessed using a single-channel EEG Fpz-Cz from the open source Sleep-EDF expanded database. The best performing model reached an overall accuracy of 85.2% and a Cohen's kappa of 0.8, with an F1-score of stage N1 equal to 50.2%. We have introduced a new metric, delta(norm), to better evaluate temporal dependencies. A simple feed forward architecture not only achieves comparable performance to most up-to-date complex architectures, but also does better encode the continuous temporal characteristics of sleep.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
68,Parametric evaluation of deep brain stimulation parameter configurations for Parkinson's disease using a conformal wearable and wireless inertial sensor system and machine learning,,,3606-3611,"LeMoyne Robert,Mastroianni Timothy,Whiting Donald,Tomycz Nestor","LeMoyne R,Mastroianni T,Whiting D,Tomycz N",LeMoyne R,,Northern Arizona University,"Deep brain stimulation enables highly specified patient-unique therapeutic intervention ameliorating the symptoms of Parkinson's disease. Inherent to the efficacy of deep brain stimulation is the acquisition of an optimal parameter configuration. Using conventional methods, the optimization process for tuning the deep brain stimulation system parameters can intrinsically induce strain on clinical resources. An advanced means of quantifying Parkinson's hand tremor and distinguishing between parameter settings would be highly beneficial. The conformal wearable and wireless inertial sensor system, such as the BioStamp nPoint, has a volumetric profile on the order of a bandage that readily enables convenient quantification of Parkinson's disease hand tremor. Furthermore, the BioStamp nPoint has been certified by the FDA as a 510(k) medical device for acquisition of medical grade data. Parametric variation of the amplitude parameter for deep brain stimulation can be quantified through the BioStamp nPoint conformal wearable and wireless inertial sensor system mounted to the dorsum of the hand. The acquired inertial sensor signal data can be wirelessly transmitted to a secure Cloud computing environment for post-processing. The quantified inertial sensor data for the parametric study of the effects of varying amplitude can be distinguished through machine learning classification. Software automation through Python can consolidate the inertial sensor data into a suitable feature set format. Using the multilayer perceptron neural network considerable machine learning classification accuracy is attained to distinguish multiple parametric settings of amplitude for deep brain stimulation, such as 4.0 mA, 2.5 mA, 1.0 mA, and 'Off' status representing a baseline. These findings constitute an advance toward the pathway of attaining real-time closed loop automated parameter configuration tuning for treatment of Parkinson's disease using deep brain stimulation.","Parkinson's disease,movement disorder,deep brain stimulation,parameter configuration,amplitude,optimization,conformal wearable,wireless inertial sensor,Cloud computing,BioStamp nPoint,Python,machine learning,multilayer perceptron neural network",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"MOVEMENT-DISORDERS,ESSENTIAL,TREMOR,THALAMOTOMY,QUANTIFICATION,NUCLEUS,GAIT",,,
69,Estimation of Parkinson's disease severity from voice features of vowels and consonant,,,3666-3669,"Viswanathan Rekha,Arjunan Sridhar P.,Kempster Peter);,Raghav Sanjay,Kumar Dinesh","Viswanathan R,Arjunan SP,Kempster P,Raghav S,Kumar D",Arjunan SP,,SRM Institute of Science & Technology Chennai,"This study has investigated the efficiency of voice features in estimating the motor Unified Parkinson's Disease Rating Scale (UPDRS) score in Parkinson's disease (PD) patients. A total of 26 PD patients (mean age = 72) and 22 control subjects (mean age = 66.91) were recruited for the study. The sustained phonation /a/, /u/ and /m/ were collected in both off-state and on-state of Levodopa medication. The average motor UPDRS for PD off-state patients was 27.31, on-state was 20.42 and that of controls was 2.63. Voice features were extracted from the phonation tasks and were reduced to the most relevant 6 features for each phonation task using the Least Absolute Shrinkage and Selection Operator (LASSO) feature ranking method. The correlation between the reduced features and motor UPDRS was tested using the Spearman correlation coefficient test. AdaBoost regression learner was trained and used for automatically estimating the motor UPDRS score using the voice features. The results show that the vocal features for /m/ performed best by estimating the motor UPDRS score for PD off-state with the mean absolute error (MAE) of 3.52 and 5.90 for PD on-state. This study shows that assessment of voice can be used for day to day remote monitoring of PD patients.","SPEECH,PROGRESSION,LEVODOPA",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"SPEECH,PROGRESSION,LEVODOPA",,,
70,A Classification Approach to Recognize the Firing of Spinal Motoneurons in Amyotrophic Lateral Sclerosis,,,3680-3683,"Abdelaal Amr Y.,Mousa Mohamed H.,Gamal Mai,Khalil Mahmoud I.,Elbasiouny Sherif M.,Eldawlatly Seif","Abdelaal AY,Mousa MH,Gamal M,Khalil MI,Elbasiouny SM,Eldawlatly S",Elbasiouny SM,,Wright State University Dayton,"Amyotrophic Lateral Sclerosis (ALS) is a fatal neurodegenerative disease that affects the nervous system causing muscle weakness, paralysis, leading to death. Given that abnormalities in spinal motoneuron (MN) excitability begin long before symptoms manifest, developing an approach that could recognize fluctuations in MN firing could help in early diagnosis of ALS. This paper introduces a machine learning approach to discriminate between ALS and normal MN firing. The approach is based on two electrophysiological markers; namely, spiking latency and the spike-triggered average signal. The method is examined using data generated from a computational model under systematic variation of MN properties. Such variations mimic the differential dynamic changes in cellular properties that different MN types experience during ALS progression. Our results demonstrate the ability of the approach to accurately recognize ALS firing patterns across the spectrum of examined variations in MN properties.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
71,Towards understanding spatio-temporal parkinsonian patterns from salient regions of a 3D convolutional network,,,3688-3691,"Guayacan Luis Carlos,Rangel Edgar,Martinez Fabio","Guayacan LC,Rangel E,Martinez F",Martinez F,,Universidad Industrial de Santander,"Gait motion patterns such as step length, flexed posture, absent arm swing and bradykinesia, constitute the main source of information to describe and quantify Parkinson disease. Nevertheless, such quantification is commonly developed under marker based protocols, losing natural motion gestures, and only taking into account a limited description of the locomotion process. This work introduces a 3D convolutional gait representation, that uses markerless video sequences to automatically predict parkinsonian behaviours. A remarkable contribution herein presented is the quantification of spatio-temporal salient maps, that stand out body regions related with Parkinson disease, and result from activations that mainly contribute on the classification task. For doing so, a convolutional architecture is trained from a set of walking videos, recorded from parkinsonian and control subjects. Then, a prediction of disease is obtained according to motion patterns computed by convolutional learned scheme. Salience motion patterns are obtained by retro-propagating the output softmax network prediction over the video space. From a total of 22 patients, and a total of 176 video sequences, the proposed approach achieved an average accuracy score of 88%. Interestingly enough, the recovered salience maps focus the attention on relevant parkinsonian biomarkers such as the head motion and trunk posture, that namely is excluded on classical gait analysis.",GAIT,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,GAIT,,,
72,Deep Learning for Interictal Epileptiform Spike Detection from scalp EEG frequency sub bands,,,3703-3706,"Prasanth Thangavel,Thomas John,Yuvaraj R.,Jing Jing,Cash Sydney S.,Chaudhari Rima,Leng Tan Yee,Rathakrishnan Rahul,Rohit Srivastava,Saini Vinay","Prasanth T,Thomas J,Yuvaraj R,Jing J,Cash SS,Chaudhari R,Leng TY,Rathakrishnan R,Rohit S,Saini V",Prasanth T,,Nanyang Technological University & National Institute of Education (NIE) Singapore,"Epilepsy diagnosis through visual examination of interictal epileptiform discharges (IEDs) in scalp electroencephalogram (EEG) signals is a challenging problem. Deep learning methods can be an automated way to perform this task. In this work, we present a new approach based on convolutional neural network (CNN) to detect IEDs from EEGs automatically. The input to CNN is a combination of raw EEG and frequency sub-bands, namely delta, theta, alpha and, beta arranged as a vector for one-dimensional (1D) CNN or matrix for two-dimensional (2D) CNN. The proposed method is evaluated on 554 scalp EEGs. The database consists of 18,164 IEDs marked by two neurologists. Five-fold cross-validation was performed to assess the IED detectors. The resulting 1D CNN based IED detector with multiple sub-bands achieved a false positive rate per minute of 0.23 and a precision of 0.79 at 90% sensitivity. Further, the proposed system is evaluated on datasets from three other clinics, and the features extracted from CNN outputs could significantly discriminate (p-values < 0.05) the EEGs with and without IEDs. We have proposed an optimized method with better performance than the literature that could aid clinicians to diagnose epilepsy expeditiously, and thereby devise proper treatment.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7545315,
73,Brunnstrom Stage Automatic Evaluation for Stroke Patients by Using Multi-Channel sEMG,,,3763-3766,"Wang Fengyan,Zhang Daohui,Hu Shaokang,Zhu Bo,Han Fei,Zhao Xingang","Wang FY,Zhang DH,Hu SK,Zhu B,Han F,Zhao XG",Zhao XG,,Chinese Academy of Sciences,"Rehabilitation level evaluation is an important part of the automatic rehabilitation training system. As a general rule, this process is manually performed by rehabilitation doctors using chart-based ordinal scales which can be both subjective and inefficient. In this paper, a novel approach based on ensemble learning is proposed which automatically evaluates stroke patients' rehabilitation level using multi-channel sEMG signals to this problem. The correlation between rehabilitation levels and rehabilitation training actions is investigated and actions suitable for rehabilitation assessment are selected. Then, features are extracted from the selected actions. Finally, the features are used to train the stacking classification model. Experiments using sEMG data collected from 24 stroke patients have been carried out to examine the validity and feasibility of the proposed method. The experiment results show that the algorithm proposed in this paper can improve the classification accuracy of 6 Brunnstrom stages to 94.36%, which can promote the application of home-based rehabilitation training in practice.",REHABILITATION,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,REHABILITATION,,,
74,Regression of Hand Movements from sEMG Data with Recurrent Neural Networks,,,3783-3787,"Koch Philipp,Dreier Mark,Larsen Anna,Parbs Tim J.,Maass Marco,Huy Phan,Mertins Alfred","Koch P,Dreier M,Larsen A,Parbs TJ,Maass M,Phan H,Mertins A",Koch P,,University of Lubeck,"Most wearable human-machine interfaces concerning hand movements only focus on classifying a limited number of hand gestures. With the introduction of deep learning, surface electromyography based hand gesture classification systems improved drastically. Therefore, it is worth investigating whether the classification can be replaced by a movement regression of all the different movable hand parts. As recurrent neural networks based approaches have proven their abilities of solving the classification problem we also choose them for the regression problem. Experiments were conducted with multiple different network architectures on several databases. Furthermore, due to the lack of a reliable measure to compare different gesture regression approaches we propose an interpretable and reproducible new error measure that can even handle noisy ground truth data. The results reveal the general possibility of regressing detailed hand movements. Even with the relatively simple networks the hand gestures can be regressed quite accurately.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
75,Machine Learning-Based Physical Activity Tracking with a view to Frailty Analysis,,,3917-3920,"Abbas Manuel,Somme Dominique,Jeannes Regine Le Bouquin","Abbas M,Somme D,Jeannes RL",Abbas M,,Institut National de la Sante et de la Recherche Medicale (Inserm),"Frailty in old age is defined as the individual intrinsic susceptibility of having bad outcomes following a health problem. It relies on sarcopenia, mobility and activity. Recognizing and monitoring a range of physical activities is a necessary step which precedes the analysis of this syndrome. This paper investigates the optimal tools for this recognition in terms of type and placement of wearable sensors. Two machine learning procedures are proposed and compared on a public dataset. The first one is based on deep learning, where feature extraction is done manually, by constructing activity images from raw signals and applying convolutional neural networks to learn optimal features from these images. The second one is based on shallow learning, where hundreds of handcrafted features are extracted manually, followed by a novel feature selection approach to retain the most discriminant subset.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
76,Improving Energy Expenditure Estimation through Activity Classification and Walking Speed Estimation Using a Smartwatch,,,3940-3944,"Aziz Omar,Zihajehzadeh Shaghayegh,Park Aerin,Tae Chul-Gyu,Park Edward J.","Aziz O,Zihajehzadeh S,Park A,Tae CG,Park EJ",Park EJ,,Simon Fraser University,"Energy expenditure (EE) estimation is an important factor in tracking personal activity and preventing chronic diseases, such as obesity and diabetes. The challenge is to provide accurate EE estimations in free-living environment through portable and unobtrusive devices. In this paper, we present an experimental study to estimate energy expenditure during sitting, standing and treadmill walking using a smartwatch. We introduce a novel methodology, which aims to improve the EE estimation by first separating sedentary (sitting and standing) and non-sedentary (walking) activities, followed by estimating the walking speeds and then calculating the energy expenditure using advanced machine learning based regression models. Ten young adults participated in the experimental trials. Our results showed that combining activity type and walking speed information with the acceleration counts substantially improved the accuracy of regression models for estimating EE. On average, the activity-based models provided 7% better EE estimation than the traditional acceleration-based models.","PHYSICAL-ACTIVITY,STEADY-STATE,ACCELEROMETERS,VALIDATION,MOVEMENT",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"PHYSICAL-ACTIVITY,STEADY-STATE,ACCELEROMETERS,VALIDATION,MOVEMENT",,,
77,A Novel Approach towards Early Detection of Obliteration in Lumbar Lordosis,,,4042-4045,"Divya Veena K.,Mukherjee Devanshu,Shree Vidhya,Roy Somali,Raghavan Venkat,Rajasree P. M.,Devaraj Deepashree,Renumadhavi C. H.,Lakshman Vasanth Raj,Subramanya K. N.","Divya KV,Mukherjee D,Shree V,Roy S,Raghavan V,Rajasree PM,Devaraj D,Renumadhavi CH,Lakshman VR,Subramanya KN",Divya KV,,R.V. College of Engineering,"The millennial age group (18 to 30 years) spend at least 6 hours sitting, either in college or at their workspace. High screen time as a routine, is the major cause for numerous spinal problems. Despite the wide research carried out on postural abnormalities, there exists numerous unrequited queries with regards to lumbar lordosis estimations, due to indeterminate parameters such as age, gender, lifestyle and diet. This work emphasizes the proficient method by observing the posture of a person for early detection of obliteration in Lumbar Lordosis. This further contributes to efficient diagnosis and treatment of spine ailments. With a novel approach to hardware using the myRIO hardware coupled with LabVIEW for interactive interface, the calibration is enhanced using machine learning (ML) - kNN Classifier. The use of machine learning accounts for the variations in the ideal angles of segmented sagittal measures with respect to different subjects. The device is developed to be a non-invasive, user friendly instrument to analyse the casual seated posture trends of the subject. The male subjects are expected to show the tilt angles in the range of - 16.3 to -17.2 degrees and similar threshold for females are -15.8 to -16.8 degrees. Out of 120 subjects taken into consideration, the device could accurately classify subjects with obliterated or normal lumbar lordosis). An accuracy and f1- score of 94% and 90% respectively was achieved by the ML model.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
78,Discrimination of Two-Class Motor Imagery in a fNIRS Based Brain Computer Interface,,,4051-4054,"Moslehi Amir H.,Bagheri Mina,Ludwig Anne-Marie,Davies T. Claire","Moslehi AH,Bagheri M,Ludwig AM,Davies TC",Moslehi AH,,Queens University - Canada,"The purpose of this study was to discriminate between left- and right-hand motor imagery tasks. We recorded the brain signals from two participants using a fNIRS system and compared different feature extraction (mean, peak, minimum, skewness and kurtosis) and classification techniques (linear (LDA) and quadratic discriminant analysis (QDA), support vector machine (SVM), logistic regression, K-nearest-neighbor (KNN), and neural networks with Levenberg-Marquardt (LMA), Bayesian Regularization (BRANN) and Scaled Conjugate Gradient (SCGA) training algorithms). The results showed poor classification accuracies (<58%) when skewness and kurtosis were used. When mean, peak, and minimum were used as features, QDA, SVM and KNN produced higher classification accuracies relative to LDA and logistic regression. Overall, BRANN led to the highest accuracies (>98%) when mean, peak and minimum were used as features.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
79,Digital Image Processing Features of Smartwatch Photoplethysmography for Cardiac Arrhythmia Detection,,,4071-4074,"Han Dong,Bashar Syed K.,Zieneddin Fearass,Ding Eric,Whitcomb Cody,McManus David D.,Chon Ki H.","Han D,Bashar SK,Zieneddin F,Ding E,Whitcomb C,McManus DD,Chon KH",Han D,,University of Connecticut,"The aim of our work is to design an algorithm to detect premature atrial contraction (PAC), premature ventricular contraction (PVC), and atrial fibrillation (AF) among normal sinus rhythm (NSR) using smartwatch photoplethysmographic (PPG) data. Novel image processing features and two machine learning methods are used to enhance the PAC/PVC detection results of the Poincare plot method. Compared with support vector machine (SVM) methods, the Random Forests (RF) method performs better. It yields a 10-fold cross validation (CV) averaged sensitivity, specificity, positive predicted value (PPV), negative predicted value (NPV), and accuracy for PAC/PVC labels of 63%, 98%, 83%, 94%, and 93%, respectively, and a 10-fold CV averaged sensitivity, specificity, PPV, NPV, and accuracy for AF subjects of 92%, 96%, 85%, 98%, and 95%, respectively. This is one of the first studies to derive image processing features from Poincare plots to further enhance the accuracy of PAC/PVC detection using PPG recordings from a smartwatch.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7896754,
80,Design of a real time portable low-cost multi-channel surface electromyography system to aid neuromuscular disorder and post stroke rehabilitation patients,,,4138-4142,"Chandrasekhar Vinay,Vazhayil Vikas,Rao Madhav","Chandrasekhar V,Vazhayil V,Rao M",Chandrasekhar V,,"Int Inst Informat Technol, Bangalore 560100, Karnataka, India.","Surface and needle-based electromyography signals are used as diagnostic markers for detecting neuromuscular disorders. Existing systems that are used to acquire these signals are usually expensive and invasive in practice. A novel 8 channel surface EMG (sEMG) acquisition system is designed and developed to acquire signals for various upper limb movements in order to evaluate the motor impairment. The real time sEMG signals are generated from the muscle fibre movements, originated solely from the upper limb physical actions. Intuitively, sEMG signals characterize different actions performed by the upper limb, which is considered apt for assessing the improvement for post stroke patients undergoing routine physical therapy activities. The system is designed and assembled in a view to make it affordable and modular for easier proliferation, and extendable to motor classifying applications. The system was validated by recording realtime sEMG data using six differential electrodes for various finger and wrist actions. The signals are filtered and processed to develop a machine learning (ML) model to classify upper limb actions, and other electronic systems are designed in the portable form around the patch electrodes. A classifier was trained to predict each action and the accuracy of the classifier was assessed across different usage of channels. The accuracy of the classifier was improved by optimizing the number of electrodes as well as the spatial position of these electrodes. The sEMG circuit designed has the capacity to characterize wrists, and finger movements. The improvement observed in the sEMG signals should benefit the physiotherapists to plan further protocols in the prescribed rehabilitation program.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
81,Cuffless and Continuous Blood Pressure Estimation From PPG Signals Using Recurrent Neural Networks,,,4269-4272,"El Hajj Chadi,Kyriacou Panayiotis A.","El Hajj C,Kyriacou PA",El Hajj C,,City University London,"This paper proposes cuffless and continuous blood pressure estimation utilising Photoplethysmography (PPG) signals and state of the art recurrent network models, namely, Long Short Term Memory and Gated Recurrent Units. The models were validated on wide range of varying blood pressure and PPG signals acquired from the Multiparameter Intelligent Monitoring in Intensive Care database. Many features were extracted from the PPG waveform and several machine learning techniques were employed in an attempt to eliminate collinearity and reduce the size of input feature vector. Consequently, the most effective features for blood pressure estimation were selected. Experimental results show that the accuracy of the proposed methods outperform traditional models applied in the literature. The results satisfy the American National Standards of the Association for the Advancement of Medical Instrumentation.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,https://openaccess.city.ac.uk/id/eprint/25046/1/Chadi%2009175699.pdf,
82,Predicting Poor Sleep Quality in Fibromyalgia with Wrist Sensors,,,4290-4293,"Alge Olivia,Soroushmehr S. M. Reza,Gryak Jonathan,Kratz Anna,Najarian Kayvan","Alge O,Soroushmehr SMR,Gryak J,Kratz A,Najarian K",Alge O,,University of Michigan System,"Fibromyalgia is a musculoskeletal disorder characterized by chronic, widespread muscle pain. This condition is associated with disturbed sleep, which has a direct impact on patient quality of life. Patient-reported outcomes are frequently used to assess sleep quality, but show modest correlations with objective measures of sleep, such as polysomnography. Working towards our goal of an automated ambulatory system of assessing sleep quality, we use features from blood volume pulse (BVP) and electrodermal activity (EDA) collected with a wearable device during sleep. We compare these measurements between individuals with fibromyalgia who experienced poor sleep and individuals in a control group who experienced refreshing sleep. By applying Learning Using Concave and Convex Kernels (LUCCK) and Support Vector Machines (SVM), we achieve mean Area Under the Receiver Operating Characteristic Curve (AUC) of 0.6573 and 0.6526, respectively, by using BVP data for classifying individuals to the two groups.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7883936,
83,Deep Learning-Based Swallowing Monitor for Realtime Detection of Swallow Duration,,,4365-4368,"Kuramoto Naomi,Ichimura Kazuhiro,Jayatilake Dushyantha,Shimokakimoto Tomoya,Hidaka Kikue,Suzuki Kenji","Kuramoto N,Ichimura K,Jayatilake D,Shimokakimoto T,Hidaka K,Suzuki K",Kuramoto N,,University of Tsukuba,"Aspiration pneumonia is a life-threatening disease for the elderly. To prevent its risk, regular swallowing assessment is necessary; however, current screening tools for swallow assessment are not widely available and medical experts are insufficient. As a portable assessment tool, we have been developing a smartphone-based realtime monitoring device (GOKURI) which can evaluate swallowing ability based on swallow sounds. For better detection accuracy of the system, we integrated a deep learning model which was developed based on the swallowing anatomy. In this paper, we provide a detailed analysis to see how the swallow sounds detected by the deep learning-based monitor correspond to the actual swallow activities. Also, as an example of practical application of the system, we analyzed the changes of the swallow abilities over time by recording swallow sounds twice for the same participants at a nursing home. To minimize the risk of aspiration pneumonia, caregivers need to understand the disability levels of the patient's swallows so that safe feeding assistance can be provided. The result of this paper implies the possibility of using GOKURI as a daily swallowing monitor with minimum interventions.","AI,Dysphagia,Deep Learning Model,Swallowing Sound,Digital Health Monitoring,Nursing Homes,mHealth",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
84,Derivative Based Gait Event Detection Algorithm Using Unfiltered Accelerometer Signals,,,4487-4490,"Escamilla-Nunez Rafael,Aguilar Luis,Ng Gabriel,Gouda Aliaa,Andrysek Jan","Escamilla-Nunez R,Aguilar L,Ng G,Gouda A,Andrysek J",Escamilla-Nunez R,,University of Toronto,"Wearable sensors have been investigated for the purpose of gait analysis, namely gait event detection. Many types of algorithms have been developed specifically using inertial sensor data for detecting gait events. Though much attention has turned toward machine learning algorithms, most of these approaches suffer from large computational requirements and are not yet suitable for real-time applications such as in prostheses or for feedback control. Current rules-based algorithms for real-time use often require fusion of multiple sensor signals to achieve high accuracy, thus increasing complexity and decreasing usability of the instrument. We present our results of a novel, rules-based algorithm using a single accelerometer signal from the foot to reliably detect heel-strike and toe-off events. Using the derivative of the raw accelerometer signal and applying an optimizer and windowing approach, high performance was achieved with a sensitivity and specificity of 94.32% and 94.70% respectively, and a timing error of 6.52 +/- 22.37 ms, including trials involving multiple speed transitions. This would enable development of a compact wearable system for robust gait analysis in real-world settings, providing key insights into gait quality with the capability for real-time system control.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
85,Multi-level Stress Assessment Using Multi-domain Fusion of ECG Signal,,,4518-4521,"Ahmad Zeeshan,Khan Naimul Mefraz","Ahmad Z,Khan NM",Ahmad Z,,Ryerson University,"Stress analysis and assessment of affective states of mind using ECG as a physiological signal is a burning research topic in biomedical signal processing. However, existing literature provides only binary assessment of stress, while multiple levels of assessment may be more beneficial for healthcare applications. Furthermore, in present research, ECG signal for stress analysis is examined independently in spatial domain or in transform domains but the advantage of fusing these domains has not been fully utilized. To get the maximum advantage of fusing diferent domains, we introduce a dataset with multiple stress levels and then classify these levels using a novel deep learning approach by converting ECG signal into signal images based on R-R peaks without any feature extraction. Moreover, We made signal images multimodal and multidomain by converting them into time-frequency and frequency domain using Gabor wavelet transform (GWT) and Discrete Fourier Transform (DFT) respectively. Convolutional Neural networks (CNNs) are used to extract features from different modalities and then decision level fusion is performed for improving the classification accuracy. The experimental results on an in-house dataset collected with 15 users show that with proposed fusion framework and using ECG signal to image conversion, we reach an average accuracy of 85.45%.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,http://arxiv.org/pdf/2008.05503,
86,Pain Detection using a Smartphone in Real Time,,,4526-4529,"Kong Youngsun,Posada-Quintero Hugo F.,Chon Ki H.","Kong Y,Posada-Quintero HF,Chon KH",Kong Y,,University of Connecticut,"We developed an objective real-time pain detection method using a smartphone and a wrist-worn wearable device to collect electrodermal activity (EDA) signals. Recently, various researchers have developed pain management applications. However, they rely on subjective self-reported pain scores or the video camera of a smartphone to detect pain, but the latter method's accuracy needs further improvement. In our work, we use a wrist-worn EDA device which transmits data via Bluetooth to a smartphone. A smartphone application was developed to analyze the EDA data so that near real-time processed pain detection information can be displayed. The analysis of EDA is based on estimating time-varying spectral power in the frequency range (0.08-0.24 Hz) associated with the sympathetic nervous system. This time-varying characterization of EDA is termed TVSymp. In this work, we also examined whether removing baseline EDA fluctuations from TVSymp would provide more accurate results. This was carried out by taking the moving average of the EDA response prior to stimulus and subtracting that value from the EDA response post stimulus. This approach is termed modified TVSymp (MTVSymp). Pain stimuli were induced in ten subjects using a thermal grill, which gives intense pain perception without damaging skin tissues. We compared both TVSymp and MTVSymp in detecting pain induced by the thermal grill using machine learning approaches. We found the accuracy of pain detection of TVSymp and MTVSymp to be 80% and 90%, respectively.","UNITED-STATES,OVERDOSE",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"UNITED-STATES,OVERDOSE",,,
87,Modeling and Reconstructing Textile Sensor Noise: Implications for Wearable Technology,,,4563-4566,"Tian Yupeng,Abdizadeh Mohammad,Mahnam Amin,Bhattachan Presish,Meghrazi Milad Alizadeh,Eskandarian Ladan,Kabir Muammar,Mellal Idir,Popovic Milos R.,Lankarany Milad","Tian YP,Abdizadeh M,Mahnam A,Bhattachan P,Meghrazi MA,Eskandarian L,Kabir M,Mellal I,Popovic MR,Lankarany M",Tian YP,,University of Toronto,"Wearable sensors enable the simultaneous recording of several electrophysiological signals from the human body in a non-invasive and continuous manner. Textile sensors are garnering substantial interest in the wearable technology because they can be knitted directly into the daily-used objects like underwear, bra, dress, etc. However, accurate processing of signals recorded by textile sensors is extremely challenging due to the very low signal-to-noise ratio (SNR). Systematic classification of textile sensor noise (TSN) is necessary to: (i) identify different types of noise and their statistical characteristics, (ii) explore how each type of noise influences the electrophysiological signal, (iii) develop optimal textile-specific electronics that suppress TSN, and (iv) reproduce TSN and create large dataset of textile sensors to validate various machine learning and signal processing algorithms. In this paper, we develop a novel technique to classify textile sensor artifacts in ECG signals. By simultaneously recording signals from the waist (textile sensors) and chest (gel electrode), we extract TSN by removing the chest ECG signal from the recorded textile data. We classify TSN based on its morphological and statistical features in two main categories, namely, slow and fast. Linear prediction coding (LPC) is utilized to model each class of TSN by auto-regression coefficients and residues. The residual signal can be approximated by Gaussian distribution which enables reproducing slow and fast artifacts that not only preserve the similar morphological features but also fulfill the statistical properties of TSN. By reproducing TSN and adding them to clean ECG signals, we create a textile-like ECG signal which can be used to develop and validate different signal processing algorithms.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
88,Capturing accelerometer outputs in healthy volunteers under normal and simulated-pathological conditions using ML classifiers,,,4604-4607,"Filippou V.,Redmond A. C.,Bennion J.);,Backhouse M. R.,Wong D.","Filippou V,Redmond AC,Bennion J,Backhouse MR,Wong D",Filippou V,,University of Leeds,"Wearable devices offer a possible solution for acquiring objective measurements of physical activity. Most current algorithms are derived using data from healthy volunteers. It is unclear whether such algorithms are suitable in specific clinical scenarios, such as when an individual has altered gait. We hypothesized that algorithms trained on healthy population will result in less accurate results when tested in individuals with altered gait. We further hypothesized that algorithms trained on simulated-pathological gait would prove better at classifying abnormal activity.
We studied healthy volunteers to assess whether activity classification accuracy differed for those with healthy and simulated-pathological conditions. Healthy participants (n=30) were recruited from the University of Leeds to perform nine pre-defined activities under healthy and simulated-pathological conditions. Activities were captured using a wrist-worn MOX accelerometer (Maastricht Instruments, NL). Data were analyzed based on the Activity-Recognition-Chain process. We trained a Neural-Network, Random-Forests, k-Nearest-Neighbors (k-NN), Support-Vector-Machines (SVM) and Naive Bayes models to classify activity. Algorithms were trained four times; once with 'healthy' data, and once with 'simulated-pathological data' for each of activity-type and activity-task classification.
In activity-type instances, the SVM provided the best results; the accuracy was 98.4% when the algorithm was trained and then tested with unseen data from the same group of healthy individuals. Accuracy dropped to 52.8% when tested on simulated-pathological data. When the model was retrained with simulated-pathological data, prediction accuracy for the corresponding test set was 96.7%. Algorithms developed on healthy data are less accurate for pathological conditions. When evaluating pathological conditions, classifier algorithms developed using data from a target sub-population can restore accuracy to above 95%.","PHYSICAL-ACTIVITY CLASSIFICATION,ACTIVITY MONITORS,GUIDE,WRIST",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"PHYSICAL-ACTIVITY,CLASSIFICATION,ACTIVITY,MONITORS,GUIDE,WRIST",,https://eprints.whiterose.ac.uk/166201/1/09176201.pdf,
89,Automatic Tracking of the Muscle Tendon Junction in Healthy and Impaired Subjects using Deep Learning,,,4770-4774,"Leitner Christoph,Jarolim Robert,Konrad Andreas,Kruse Annika,Tilp Markus,Schroettner Joerg,Baumgartner Christian","Leitner C,Jarolim R,Konrad A,Kruse A,Tilp M,Schrottner J,Baumgartner C",Leitner C,,Graz University of Technology,"Recording muscle tendon junction displacements during movement, allows separate investigation of the muscle and tendon behaviour, respectively. In order to provide a fully-automatic tracking method, we employ a novel deep learning approach to detect the position of the muscle tendon junction in ultrasound images. We utilize the attention mechanism to enable the network to focus on relevant regions and to obtain a better interpretation of the results. Our data set consists of a large cohort of 79 healthy subjects and 28 subjects with movement limitations performing passive full range of motion and maximum contraction movements. Our trained network shows robust detection of the muscle tendon junction on a diverse data set of varying quality with a mean absolute error of 2.55 +/- 1 mm. We show that our approach can be applied for various subjects and can be operated in real-time. The complete software package is available for open-source use.","MEDIAL GASTROCNEMIUS,FASCICLE,CHILDREN",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"MEDIAL,GASTROCNEMIUS,FASCICLE,CHILDREN",,http://arxiv.org/pdf/2005.02071,
90,Developing a Method to Control an Arm-Assist-Suit by Predicting Arm-Trajectory Using Electromyography,,,4882-4885,"Tanaka Taichi,Nambu Isao,Wada Yasuhiro","Tanaka T,Nambu I,Wada Y",Tanaka T,,Nagaoka University of Technology,"Many researchers have developed assist-suits to support repetitive and strenuous physical labor, but existing suits show unsatisfactory responsiveness and restrict arm motions. Therefore, we propose a method for an arm-assist-suit that synchronizes arm motions by using electromyography (EMG) to predict arm trajectory. EMG is used to measure and record electrical signals while muscles are active. Further, predicted arm-joint motions and estimated arm-joint angles are used for arm trajectory predictions. In this study, we attempted the prediction of elbow-joint motions and the timing of motion changes. Two subjects executed twelve types of elbow-joint movements that had four start and endpoints. We measured seven muscle types with EMG points on the right arm(hand, elbow, and shoulder) a motion capture system, respectively. After processing these data, we applied a multiclass logistic regression, which is a machine-learning technique, to predict elbow-joint motions, namely, rest, flexion, and extension. The precision in elbow joint motion prediction shows a difference between the two subjects for the three motions analyzed. Additionally, the rest prediction accuracy is lower than both flexion and extension for each subject. The prediction of elbow-joint motion change timing does not correlate with the elbow-joint motion predictions, with the timing prediction precision being very low and thus, causing some difficulties. To overcome these difficulties, and improve precision in future work, we plan to apply an independent component analysis to eliminate noise and add or change features.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
91,Practical Machine Learning-Based Sepsis Prediction,,,4986-4991,"Pettinati Michael J.,Chen Gengbo,Rajput Kuldeep Singh,Selvaraj Nandakumar","Pettinati MJ,Chen GB,Rajput KS,Selvaraj N",Selvaraj N,,"Biofourmis Inc, Boston, MA 02110 USA.","Sepsis is a life-threatening clinical syndrome and one of the most expensive conditions treated in hospitals. It is challenging to detect due to the nonspecific clinical signs and the absence of gold standard diagnostics. However, early recognition of sepsis and optimal treatments for sepsis are of paramount importance to improve the condition's management and patient outcomes. This paper aims to delineate key aspects of current sepsis detection systems, including their dependency on clinical expert and laboratory biometric features requiring ongoing critical care intervention, the efficacy of vital sign measures, and the effect of the study population with respect to the precision of sepsis prediction. The AUROC performances of XGBoost models trained on a heterogenous ICU patient group (n=3932) showed significant degradations (p<0.05) as the expert and laboratory biomarker features are removed systematically and vital sign features taken in ICU settings are left. The performance of XGBoost models trained only with vital sign features on a more homogeneous group of ICU patients (n=1927) had a significantly (P<0.05) improved AUPRC to moderate level. The presented results highlight the importance of making a practical machine learning system for sepsis prediction by considering the availability of dominant features as well as personalizing sepsis prediction by configuring it to the specific demographics of a targeted population.",SEPTIC SHOCK,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"SEPTIC,SHOCK",,,
92,Development of an Electrical Impedance Tomography Spectroscopy for Pressure Ulcer Monitoring Tool: Preliminary study,,,5073-5076,"Kang Sooln,Noyori Shuhei);,Noguchi Hiroshi);,Takahashi Toshiaki);,Sanada Hiromi);,Mori Taketoshi","Kang S,Noyori S,Noguchi H,Takahashi T,Sanada H,Mori T",Kang S,,University of Tokyo,"This study developed a sensor system that measures electrical impedance with a surrounding electrode array that is located around the wound and estimates the depth and classifies the difference in tissues of small regions in the area using tomography combined with spectroscopy method. The system is designed to integrate into the dressing to reduce unnecessary removal of dressings. In the human trial, moisturizer applied area was detected using Random Forest classifier (94.4% accuracy) and differences between every 10 minutes were significant in moisturizer applied area (p<0.05). The study confirmed the proof of concept that the system can monitor the change in human skin without attaching the sensor to the target area and indicate the skin area that had changed.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
93,Characterisation of Upper Airway Collapse in OSA Patients Using Snore Signals: A Cluster Analysis Approach,,,5124-5127,"Sebastian Arun,Cistulli Peter A.,Cohen Gary,de Chazal Philip","Sebastian A,Cistulli PA,Cohen G,de Chazal P",Sebastian A,,University of Sydney,"This paper provides the results of an unsupervised learning algorithm that characterize upper airway collapse in obstructive sleep apnoea (OSA) patients using snore signal during hypopnoea events. Knowledge regarding the site-of-collapse could improve the ability in choosing the most appropriate treatment for OSA and thereby improving the treatment outcome. In this study, we implemented an unsupervised k-means clustering algorithm to label the snore data during hypopnoea events. Audio data during sleep were recorded simultaneously with full-night polysomnography with a ceiling microphone. Various time and frequency features of audio signal during hypopnoea were extracted. A systematic evaluation method was implemented to find the optimal feature set and the optimal number of clusters using silhouette coefficients. Using these optimal feature sets, we clustered the snore data into two. Performance of the proposed model showed that the data fit well in two clusters with a mean silhouette coefficients of 0.79. Also, the clusters achieved an overall accuracy of 62% for predicting tongue/non-tongue related collapse.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
94,Performance Evaluation of the Circadia Contactless Breathing Monitor and Sleep Analysis Algorithm for Sleep Stage Classification,,,5150-5153,"Lauteslager Timo,Kampakis Stylianos,Williams Adrian J.,Maslik Michal,Siddiqui Fares","Lauteslager T,Kampakis S,Williams AJ,Maslik M,Siddiqui F",Lauteslager T,,"Circadia Technol Ltd, 6 Delmey Close, London CR0 5QD, England.","Although polysomnography (PSG) remains the gold standard for studying sleep in the lab, the development of wearable and 'nearable' non-EEG based sleep monitors has the potential to make long-term sleep monitoring in a home environment possible. However, validation of these novel technologies against PSG is required. The current study aims to evaluate the sleep staging performance of the radar-based Circadia Contactless Breathing Monitor (model C100) and proprietary Sleep Analysis Algorithm, both in a home and sleep lab environment, on cohorts of healthy sleepers. The C100 device was initially used to record 17 nights of sleep data from 9 participants alongside PSG, with a subsequent 24 nights of PSG data for validation purposes. Respiration and body movement features were extracted from sensor data, and a machine learning algorithm was developed to perform sleep stage prediction. The algorithm was trained using PSG data obtained in the initial dataset (n=17), and validated using leave-one-subject-out cross-validation. An epoch-by-epoch recall (true positive rate) of 75.0 %, 59.9 %, 74.8% and 57.1 %, was found for 'Deep', 'Light', 'REM' and 'Wake' respectively. Highly similar results were obtained in the independent validation dataset (n=24), indicating robustness of results and generalizability of the sleep staging model, at least in the healthy population. The device was found to outperform both a consumer and medical grade wrist-worn monitoring device (Fitbit Alta HR and Philips Respironics Actiwatch) on sleep metric estimation accuracy. These results indicate that the developed non-contact monitor forms a viable alternative to existing clinically used wrist-worn methods, and that longitudinal monitoring of sleep stages in a home environment becomes feasible.",VALIDATION,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,VALIDATION,,,
95,Automatic Sleep Stage Detection: A Study on the Influence of Various PSG Input Signals,,,5330-5334,"Tautan Alexandra-Maria,Rossi Alessandro C.,de Francisco Ruben,Ionescu Bogdan","Tautan AM,Rossi AC,de Francisco R,Ionescu B",Tautan AM,,Polytechnic University of Bucharest,"Automatic sleep stage detection can be performed using a variety of input signals from a polysomnographic (PSG) recording. In this study, we investigate the effect of different input signals on the performance of feature-based automatic sleep stage classification algorithms with both a Random Forest (RF) and Multilayer Perceptron (MLP) classifier. Combinations of the EEG (electroencephalographic) signal and ECG (elec-trocardiographic), EMG (electromyographic) and respiratory signals as input are investigated as input with respect to using single channel and multi-channel EEG as input. The Physionet ""You Snooze, You Win"" dataset is used for the study. The RF classifier consistently outperforms our MLP implementation in all cases and is positively affected by specific signal combinations. The overall classification performance using a single channel EEG is high (an accuracy, precision and recall of 86.91 %, 89.52%, 86.91% respectively) using RF. The results are comparable to the performance obtained using six EEG channels as input. Adding respiratory signals to the inputs processed by RF increases the N2 stage detection performance with 20%, while adding the EMG signal improves the accuracy of the REM stage detection with 5%. Our analysis shows that adding specific signals as input to RF improves the accuracy of specific sleep stages and increases the overall performance. Using a combination of EEG and respiratory signals we achieved an accuracy of 93% for the RF classifier.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
96,Assisting the Non-invasive Diagnosis of Liver Fibrosis Stages using Machine Learning Methods,,,5382-5387,"Emu Mahzabeen,Kamal Farjana Bintay,Choudhury Salimur,de Oliveira Thiago E. Alves","Emu M,Kamal FB,Choudhury S,de Oliveira TEA",Emu M,,Lakehead University,"Fibrosis is a significant indication of chronic liver diseases often due to hepatitis C Virus. It is becoming a global concern as a result of the rapid increase in the number of HCV infected patients, the high cost and flaws associated with the assessment process of liver fibrosis. This study aims to determine the features that significantly contribute to the identification of the stages of liver fibrosis and to generate rules to assist physicians during the treatment of the patients as a clinically non-invasive approach. Also, the performance of different Multi-layered Perceptron (MLP), Random Forest, and Logistic Regression classifiers are estimated and compared for the full and reduced feature sets. Decision Tree produced 28 rules in contrast with previous research work where 98002 rules had been generated from the same dataset with an accuracy rate of approximately 99.97%. The resulting rules of this study achieved a prediction accuracy for the histological staging of liver fibrosis of 97.45%. Among all the machine learning methods, MLP achieved the highest accuracy rate.","Hepatitis C Virus (HCV),Machine Learning,Clinical Decision Support Systems (CDSS)",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"CHRONIC,HEPATITIS-C,TESTS,PREDICTION,VIRUS",,,
97,Transfer Learning for Detection of Atrial Fibrillation in Deterministic Compressive Sensed ECG,,,5398-5401,"Abdelazez Mohamed,Rajan Sreeraman,Chan Adrian D. C.","Abdelazez M,Rajan S,Chan ADC",Abdelazez M,,Carleton University,"Atrial Fibrillation (AF) is a cardiac condition resulting from uncoordinated contraction of the atria which may lead to an increase in the risk of heart attacks, strokes, and death. AF symptoms may go undetected and may require long-term monitoring of electrocardiogram (ECG) to be detected. Long-term ECG monitoring can generate a large amount of data which can increase power, storage, and the wireless transmission bandwidth of monitoring devices. Compressive Sensing (CS) is compression technique at the sampling stage which may save power, storage, and wireless bandwidth of monitoring devices. The reconstruction of compressive sensed ECG is a computationally expensive operation; therefore, detection of AF in compressive sensed ECG is warranted. This paper presents preliminary results of using deep learning to detect AF in deterministic compressive sensed ECG. MobileNetV2 convolutional neural network (CNN) was used in this paper. Transfer learning was utilized to leverage a pre-trained CNN with the final two layers retrained using 24 records from the Long-Term Atrial Fibrillation Database. The Short-Term Fourier Transform was used to generate spectrograms that were fed to the CNN. The CNN was tested on the MIT-BIH Atrial Fibrillation Database at the uncompressed, 50%, 75%, and 95% compressed ECG. The performance of the CNN was evaluated using weighted average precision (AP) and area under the curve (AUC) of the receiver operator curve (ROC). The CNN had AP of 0.80, 0.70, 0.70, and 0.57 at uncompressed, 50%, 75%, and 95% compression levels. The AUC was 0.87, 0.78, 0.79, and 0.75 at each compression level. The preliminary results show promise for using deep learning to detect AF in compressive sensed ECG.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
98,Optimizing Individualized Treatment Planning for Parkinson's Disease Using Deep Reinforcement Learning,,,5406-5409,"Watts Jeremy,Khojandi Anahita,Vasudevan Rama,Ramdhani Ritesh","Watts J,Khojandi A,Vasudevan R,Ramdhani R",Watts J,,University of Tennessee System,"More than one million people currently live with Parkinson's Disease (PD) in the U.S. alone. Medications, such as levodopa, can help manage PD symptoms. However, medication treatment planning is generally based on patient history and limited interaction between physicians and patients during office visits. This limits the extent of benefit that may be derived from the treatment as disease/patient characteristics are generally non-stationary. Wearable sensors that provide continuous monitoring of various symptoms, such as bradykinesia and dyskinesia, can enhance symptom management. However, using such data to overhaul the current static medication treatment planning approach and prescribe personalized medication timing and dosage that accounts for patient/care-giver/physician feedback/preferences remains an open question. We develop a model to prescribe timing and dosage of medications, given the motor fluctuation data collected using wearable sensors in real-time. We solve the resulting model using deep reinforcement learning (DRL). The prescribed policy determines the optimal treatment plan that minimizes patient's symptoms. Our results show that the model-prescribed policy outperforms the static a priori treatment plan in improving patients' symptoms, providing a proof-of-concept that DRL can augment medical decision making for treatment planning of chronic disease patients.",ONSET,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,ONSET,,https://www.osti.gov/biblio/1819614,
99,Convolutional Neural Network for Freezing of Gait Detection Leveraging the Continuous Wavelet Transform on Lower Extremities Wearable Sensors Data,,,5410-5415,"Shi Bohan,Yen Shih Cheng,Tay Arthur,Tan Dawn M. L.,Chia Nicole S. Y.,Au W. L.","Shi BH,Yen SC,Tay A,Tan DML,Chia NSY,Au WL",Shi BH,,National University of Singapore,"Freezing of Gait is the most disabling gait disturbance in Parkinson's disease. For the past decade, there has been a growing interest in applying machine learning and deep learning models to wearable sensor data to detect Freezing of Gait episodes. In our study, we recruited sixty-seven Parkinson's disease patients who have been suffering from Freezing of Gait, and conducted two clinical assessments while the patients wore two wireless Inertial Measurement Units on their ankles. We converted the recorded time-series sensor data into continuous wavelet transform scalograms and trained a Convolutional Neural Network to detect the freezing episodes. The proposed model achieved a generalisation accuracy of 89.2% and a geometric mean of 88.8%.","QUESTIONNAIRE,SENSITIVITY",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"QUESTIONNAIRE,SENSITIVITY",,,
100,Epileptic Seizure Detection for Imbalanced Datasets Using an Integrated Machine Learning Approach,,,5416-5419,"Masum Mohammad,Shahriar Hossain,Haddad Hisham M.","Masum M,Shahriar H,Haddad HM",Masum M,,University System of Georgia,"Epileptic Seizure (Epilepsy) is a neurological disorder that occurs due to abnormal brain activities. Epilepsy affects patients' health and lead to life-threatening situations. Early prediction of epilepsy is highly effective to avoid seizures. Machine Learning algorithms have been used to classify epilepsy from Electroencephalograms (EEG) data. These algorithms exhibited reduced performance when classes are imbalanced. This work presents an integrated machine learning approach for epilepsy detection, which can effectively learn from imbalanced data. This approach utilizes Principal Component Analysis (PCA) at the first stage to extract both high- and low-variant Principal Components (PCs), which are empirically customized for imbalanced data classification. Conventionally, PCA is used for dimension reduction of a dataset leveraging PCs with high variances. In this paper, we propose a model to show that PCs associated with low variances can capture the implicit pattern of minor class of a dataset. The selected PCs are then fed into different machine learning classifiers to predict seizures. We performed experiments on the Epileptic Seizure Recognition dataset to evaluate our model. The experimental results show the robustness and effectiveness of the proposed model.","EEG,Epileptic Seizure,Imbalanced Data,Principal Components,Feature Extraction,Machine Learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,CLASSIFICATION,,,
