,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Subcortical Brain Segmentation in MR image based on Residual Fully Convolutional Networks,,,4834-4837,"Wang Chuyuan,Ma Shuailei,Wei Ying,Li Xiang,Liu Yue","Wang CY,Ma SL,Wei Y,Li X,Liu Y",Wei Y,,Northeastern University - China,"Brain magnetic imaging(MRI) has become an effective tool for disease diagnosis, disease tracking and so on. Deep brain structures such as hippocampus plays an important role in the quantitative assessment of human brain. Therefore, it is crucial to segment these deep brain structures in a short time. In recent years, deep learning has achieved great process in image processing, especially the U-net, which is the Champion Model of 2015 ISBI Cell Tracking Challenge. In this paper, a novel structure was proposed which based on U-net as well as substitute the normal convolution block with the residual block to achieve a robust segmentation. In addition, SEblock is introduced to emphasize the correlation between channels which helps to focus on the features that are more important. The experimental results on the IBSR dataset show that the method proposed in this paper achieves average Dice value 0.83 on the deep brain structures segmentation, which verified the effectiveness of the method.","Deep Brain Structures,Deep Learning,Residual block,SEblock",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Automation & Control Systems,,,,,,
2,Risk Status Identification During the Takeover of Conditionally Automated Vehicles,,,5000-5006,"Mao Peng,Chen Jin,Sun Dihua","Mao P,Chen J,Sun DH",Mao P,,Chongqing University,"In order to identify the risk status during the takeover from automated driving to manual driving in dangerous traffic situations, this study investigated their performance during the takeover based on PreScan. The experiment invited 38 drivers. They all held a valid driving license. A risk status identification model was proposed based on the information of vehicle status and traffic environment status. According to the rate of electrocardiogram(ECG) and the performance of takeover, the risk status was classified into three levels. Using Pearson correlation coefficient algorithm, seven factors were selected as the feature set. Then, the algorithm of Random Forest (RF) was employed to establish the takeover risk status identification model. The results show that the accuracy of RF is 98.8%, increasing 10.4%, 17.7% and 7.3% compared with Support Vector Machine (SVM), Classification and Regression Tree (CART) and Back Propagation Neural Network, and each risk level has good prediction results. Respectively, the results show that the space headway, longitudinal acceleration and lane departure have a great influence on the risk level, and the space headway has the strongest impact on the degree of danger during the takeover of control in Conditionally Automated Vehicles.","Automated Driving,Experimental Research,Takeover,Risk Status Identification,Driving Simulator",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Automation & Control Systems,,,,,,
3,New tolerance factor based on SISSO and machine learning for predicting stability of perovskite structure,30,8,1887-1894,",,,,,,","Hu Hongqing,Wu Shaogang,Guo Zhiting,Zhou Gaofeng,Dai Dongbo,Wei Xiao,Zhang Huiran",,,Hu Hongqing,"Due to the wide application prospects of perovskite materials,research on their structures and physical and chemical properties of perovskite materials has been one of the hot topics in the field of materials research.Among them,predicting the stability of perovskite structure with the help of tolerance factor can help researchers discover more new functional materials.The conventional tolerance factor t_(IR) for determining the stability of the perovskite structure based on ion radius has certain shortcomings and limitation.In view of this,this work proposes a new type of tolerance factor tau_(BV) based on the bond valence model using the SISSO(sure independence screening and sparsifying operator)method which can effectively avoid the defect limitation caused by the ionic radius.This work uses the decision tree algorithm in machine learning to establish the new tolerance factor verification model and the results show that the new tolerance factor tau_(BV) can excellently predict whether the ABO_3 compound is perovskite or non-perovskite,which greatly improves the prediction accuracy.",SISSO; perovskites; structural stability; sure independence screening sparsifying operator(SISSO); new tolerance factor,Article,,,,,,,,
4,"Deep-Learning Methods for Parallel Magnetic Resonance Imaging Reconstruction: A Survey of the Current Approaches, Trends, and Issues",37,1,128-140,"Knoll Florian,Hammernik Kerstin,Zhang Chi,Moeller Steen,Pock Thomas,Sodickson Daniel K.,Akcakaya Mehmet","Knoll F,Hammernik K,Zhang C,Moeller S,Pock T,Sodickson DK,Akcakaya M",Knoll F,10.1109/MSP.2019.2950640,New York University,,"MRI,GRAPPA,SENSE",Editorial Material,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,12.821,"MRI,GRAPPA,SENSE",IEEE SIGNAL PROCESSING MAGAZINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7982984,
5,Meta-analysis of voice disorders databases and applied machine learning techniques,17,6,7958-7979,"Syed Sidra Abid,Rashid Munaf,Hussain Samreen","Syed SA,Rashid M,Hussain S",Syed SA,10.3934/mbe.2020404,Ziauddin University,"Background and Objective: Voice disorders are pathological conditions that directly affect voice production. Computer based diagnosis may play a major role in the early detection and in tracking and even development of efficient pathological speech diagnosis, based on a computerized acoustic evaluation. The health of the Voice is assessed by several acoustic parameters. The exactness of these parameters is often linked to algorithms used to estimate them for speech noise identification. That is why main effort of the scientists is to study acoustic parameters and to apply classification methods that achieve a high precision in discrimination. The primary aim of this paper is for a meta- analysis on voice disorder databases i.e. SVD, MEEI and AVPD and machine learning techniques applied on it. Materials and Methods: This field of study was systematically reviewed in compliance with PRISMA guidelines. A search was performed with a set of formulated keywords on three databases i.e. Science Direct, PubMed, and IEEE Xplore. A proper screening and analysis of articles were performed after which several articles were also excluded. Results: Forty-five studies that fulfills the eligibility criteria were included in this meta-analysis. After applying eligibility criteria on the peer reviewed and research article and studies that were published in authentic journals and conferences proceedings till June 2020 were chosen for further full-text screening. In general, only those articles that used voice recordings from SVD, MEEI and AVPD databases as a dataset is included in this meta analysis. Conclusion: We discussed the strengths and weaknesses of SVD, MEEI and AVPD. After detailed analysis of the studies including the techniques used and outcome measurements, it was also concluded that Support Vector Machine (SVM) is the most common used algorithm for the detection of voice disorders. Other than was also noticed that researchers focus on supervised techniques for the clinical diagnosis of voice disorder rather than using unsupervised techniques. It was also concluded that more work needs to be on voice pathology detection using AVPD database.","voice disorder,SVD,MEEI,AVPD",Article,"AMER INST MATHEMATICAL SCIENCES-AIMS, PO BOX 2604, SPRINGFIELD, MO 65801-2604 USA",Mathematical & Computational Biology,,1.887,"PATHOLOGY,DETECTION,CLASSIFICATION,IDENTIFICATION,FREQUENCY,EFFICACY,FEATURES,VOWELS",MATHEMATICAL BIOSCIENCES AND ENGINEERING,https://doi.org/10.3934/mbe.2020404,
6,Benchmark and Best Practices for Biomedical Knowledge Graph Embeddings,,,167-176,"Chang David,Balazevic Ivana,Allen Carl,Chawla Daniel,Brandt Cynthia,Taylor Richard Andrew","Chang D,Balazevic I,Allen C,Chawla D,Brandt C,Taylor RA",Chang D,,Yale University,"Much of biomedical and healthcare data is encoded in discrete, symbolic form such as text and medical codes. There is a wealth of expert-curated biomedical domain knowledge stored in knowledge bases and ontologies, but the lack of reliable methods for learning knowledge representation has limited their usefulness in machine learning applications. While text-based representation learning has significantly improved in recent years through advances in natural language processing, attempts to learn biomedical concept embeddings so far have been lacking. A recent family of models called knowledge graph embeddings have shown promising results on general domain knowledge graphs, and we explore their capabilities in the biomedical domain. We train several state-of-the-art knowledge graph embedding models on the SNOMED-CT knowledge graph, provide a benchmark with comparison to existing methods and in-depth discussion on best practices, and make a case for the importance of leveraging the multi-relational nature of knowledge graphs for learning biomedical knowledge representation. The embeddings, code, and materials will be made available to the community(1).",,Proceedings Paper,"ASSOC COMPUTATIONAL LINGUISTICS-ACL, 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA","Computer Science,Linguistics",,,,19TH SIGBIOMED WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2020),http://arxiv.org/pdf/2006.13774,
7,Learning Invariant Representations From EEG via Adversarial Inference,8,,27074-27085,"Ozdenizci Ozan,Wang Ye,Koike-Akino Toshiaki,Erdogmus Deniz","Ozdenizci O,Wang Y,Koike-Akino T,Erdogmus D",Ozdenizci O,10.1109/ACCESS.2020.2971600,Northeastern University,"Discovering and exploiting shared, invariant neural activity in electroencephalogram (EEG) based classification tasks is of significant interest for generalizability of decoding models across subjects or EEG recording sessions. While deep neural networks are recently emerging as generic EEG feature extractors, this transfer learning aspect usually relies on the prior assumption that deep networks naturally behave as subject- (or session-) invariant EEG feature extractors. We propose a further step towards invariance of EEG deep learning frameworks in a systemic way during model training. We introduce an adversarial inference approach to learn representations that are invariant to inter-subject variabilities within a discriminative setting. We perform experimental studies using a publicly available motor imagery EEG dataset, and state-of-the-art convolutional neural network based EEG decoding models within the proposed adversarial learning framework. We present our results in cross-subject model transfer scenarios, demonstrate neurophysiological interpretations of the learned networks, and discuss potential insights offered by adversarial inference to the growing field of deep learning for EEG.","Adversarial learning,brain-computer interface,deep neural networks,electroencephalogram,invariant representation,motor imagery",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"COMMON,SPATIAL-PATTERN,NEURAL-NETWORKS,MOTOR,IMAGERY,COMPUTER",IEEE ACCESS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7971154,
8,Automatic Count of Bites and Chews From Videos of Eating Episodes,8,,101934-101945,"Hossain Delwar,Ghosh Tonmoy,Sazonov Edward","Hossain D,Ghosh T,Sazonov E",Sazonov E,10.1109/ACCESS.2020.2998716,University of Alabama System,"Methods for measuring of eating behavior (known as meal microstructure) often rely on manual annotation of bites, chews, and swallows on meal videos or wearable sensor signals. The manual annotation may be time consuming and erroneous, while wearable sensors may not capture every aspect of eating (e.g. chews only). The aim of this study is to develop a method to detect and count bites and chews automatically from meal videos. The method was developed on a dataset of 28 volunteers consuming unrestricted meals in the laboratory under video observation. First, the faces in the video (regions of interest, ROI) were detected using Faster R-CNN. Second, a pre-trained AlexNet was trained on the detected faces to classify images as a bite/no bite image. Third, the affine optical flow was applied in consecutively detected faces to find the rotational movement of the pixels in the ROIs. The number of chews in a meal video was counted by converting the 2-D images to a 1-D optical flow parameter and finding peaks. The developed bite and chew count algorithm was applied to 84 meal videos collected from 28 volunteers. A mean accuracy (+/- STD) of 85.4% (+/- 6.3%) with respect to manual annotation was obtained for the number of bites and 88.9% (+/- 7.4%) for the number of chews. The proposed method for an automatic bite and chew counting shows promising results that can be used as an alternative solution to manual annotation.","Meal microstructure,computer vision,deep learning,image classification,optical flow,bite count,chew count",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"REDUCES,ENERGY-INTAKE,FOOD-INTAKE,OBESE,SIZE,PERFORMANCE,PATTERNS,MEALS",IEEE ACCESS,https://ieeexplore.ieee.org/ielx7/6287639/8948470/09104716.pdf,
9,Sparse Representation and Dictionary Learning Model Incorporating Group Sparsity and Incoherence to Extract Abnormal Brain Regions Associated With Schizophrenia,8,,104396-104406,"Peng Peng,Ju Yongfeng,Zhang Yipu,Wang Kaiming,Jiang Suying,Wang Yuping","Peng P,Ju YF,Zhang YP,Wang KM,Jiang SY,Wang YP",Ju YF; Zhang YP,10.1109/ACCESS.2020.2999513,Chang'an University,"Schizophrenia is a complex mental illness, the mechanism of which is currently unclear. Using sparse representation and dictionary learning (SDL) model to analyze functional magnetic resonance imaging (fMRI) dataset of schizophrenia is currently a popular method for exploring the mechanism of the disease. The SDL method decomposed the fMRI data into a sparse coding matrix X and a dictionary matrix D. However, these traditional methods overlooked group structure information in X and the coherence between the atoms in D. To address this problem, we propose a new SDL model incorporating group sparsity and incoherence, namely GS2ISDL to detect abnormal brain regions. Specifically, GS2ISDL uses the group structure information that defined by AAL anatomical template from fMRI dataset as priori to achieve inter-group sparsity in X. At the same time, L-1 - norm is enforced on X to achieve intra-group sparsity. In addition, our algorithm also imposes incoherent constraint on the dictionary matrix D to reduce the coherence between the atoms in D, which can ensure the uniqueness of X and the discriminability of the atoms. To validate our proposed model GS2ISDL, we compared it with both IK-SVD and SDL algorithm for analyzing fMRI dataset collected by Mind Clinical Imaging Consortium (MCIC). The results show that the accuracy, sensitivity, recall and MCC values of GS2ISDL are 93.75%, 95.23%, 80.50% and 88.19%, respectively, which outperforms both IK-SVD and SDL. The ROIs extracted by GS2ISDL model (such as Precentral gyrus, Hippocampus and Caudate nucleus, etc.) are further verified by the literature review on schizophrenia studies, which have significant biological significance.","Functional magnetic resonance imaging,Sparse matrices,Matrix decomposition,Dictionaries,Brain modeling,Machine learning,Analytical models,Group sparsity,incoherence,sparse representation and dictionary learning,abnormal brain regions,schizophrenia",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.671,"CANONICAL,CORRELATION-ANALYSIS,FUNCTIONAL,ARCHITECTURE,COMPONENT,ANALYSIS,IMAGING,GENETICS,FMRI,PATTERNS,CONNECTIVITY,HIPPOCAMPUS,REVEALS,PURSUIT",IEEE ACCESS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7971409,
10,Robust Estimation of Hypernasality in Dysarthria With Acoustic Model Likelihood Features,28,,2511-2522,"Saxon Michael,Tripathi Ayush,Jiao Yishan,Liss Julie M.,Berisha Visar","Saxon M,Tripathi A,Jiao YS,Liss JM,Berisha V",Saxon M,10.1109/TASLP.2020.3015035,Arizona State University,"Hypernasality is a common characteristic symptom across many motor-speech disorders. For voiced sounds, hypernasality introduces an additional resonance in the lower frequencies and, for unvoiced sounds, there is reduced articulatory precision due to air escaping through the nasal cavity. However, the acoustic manifestation of these symptoms is highly variable, making hypernasality estimation very challenging, both for human specialists and automated systems. Previous work in this area relies on either engineered features based on statistical signal processing or machine learning models trained on clinical ratings. Engineered features often fail to capture the complex acoustic patterns associated with hypernasality, whereas metrics based on machine learning are prone to overfitting to the small disease-specific speech datasets on which they are trained. Here we propose a new set of acoustic features that capture these complementary dimensions. The features are based on two acoustic models trained on a large corpus of healthy speech. The first acoustic model aims to measure nasal resonance from voiced sounds, whereas the second acoustic model aims to measure articulatory imprecision from unvoiced sounds. To demonstrate that the features derived from these acoustic models are specific to hypernasal speech, we evaluate them across different dysarthria corpora. Our results show that the features generalize even when training on hypernasal speech from one disease and evaluating on hypernasal speech from another disease (e.g., training on Parkinson's disease, evaluation on Huntington's disease), and when training on neurologically disordered speech but evaluating on cleft palate speech.","Acoustics,Neurological diseases,Robustness,Acoustic measurements,Training,Cavity resonators,Clinical speech analytics,dysarthria,hypernasality,speech features,velopharyngeal dysfunction",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,,"VOICE,LOW,TONE,CLEFT-LIP,PALATE,SPEECH,RESONANCE,NASALITY,VOWELS,PERCEPTION,DISORDERS,NASALANCE",IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7978228,
11,Disentangled Adversarial Autoencoder for Subject-Invariant Physiological Feature Extraction,27,,1565-1569,"Han Mo,Ozdenizci Ozan,Wang Ye,Koike-Akino Toshiaki,Erdogmus Deniz","Han M,Ozdenizci O,Wang Y,Koike-Akino T,Erdogmus D",Han M,10.1109/LSP.2020.3020215,Northeastern University,"Recent developments in biosignal processing have enabled users to exploit their physiological status for manipulating devices in a reliable and safe manner. One major challenge of physiological sensing lies in the variability of biosignals across different users and tasks. To address this issue, we propose an adversarial feature extractor for transfer learning to exploit disentangled universal representations. We consider the trade-off between task-relevant features and user-discriminative information by introducing additional adversary and nuisance networks in order to manipulate the latent representations such that the learned feature extractor is applicable to unknown users and various tasks. Results on cross-subject transfer evaluations exhibit the benefits of the proposed framework, with up to 8.8% improvement in average accuracy of classification, and demonstrate adaptability to a broader range of subjects.","Adversarial deep learning,stress assessment",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,3.586,EEG,IEEE SIGNAL PROCESSING LETTERS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7977990,
12,Deep Magnetic Resonance Image Reconstruction: Inverse Problems Meet Neural Networks,37,1,141-151,"Liang Dong,Cheng Jing,Ke Ziwen,Ying Leslie","Liang D,Cheng J,Ke ZW,Ying L",Liang D,10.1109/MSP.2019.2950557,University of Wisconsin System,,"DOMAIN,MODEL,REGULARIZATION,CANCER",Editorial Material,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,12.821,"DOMAIN,MODEL,REGULARIZATION,CANCER",IEEE SIGNAL PROCESSING MAGAZINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7977031,
13,Accuracy of Machine Learning Potential for Predictions of Multiple-Target Physical Properties,37,12,,",,,,,","欧阳宇楼,张忠卫,俞崔前,何佳,严钢,陈杰",,,Ouyang Yulou,"The accurate and rapid prediction of materials' physical properties,such as thermal transport and mechanical properties,are of particular importance for potential applications of featuring novel materials.We demonstrate,using graphene as an example,how machine learning potential,combined with the Boltzmann transport equation and molecular dynamics simulations,can simultaneously provide an accurate prediction of multiple-target physical properties,with an accuracy comparable to that of density functional theory calculation and/or experimental measurements.Benchmarked quantities include the Gruneisen parameter,the thermal expansion coefficient,Young's modulus,Poisson's ratio,and thermal conductivity.Moreover,the transferability of commonly used empirical potential in predicting multiple-target physical properties is also examined.Our study suggests that atomic simulation,in conjunction with machine learning potential,represents a promising method of exploring the various physical properties of novel materials.",,Article,,,,,,,,
14,Data Analytics on Graphs Part II: Signals on Graphs,13,2-3,158-331,"Stankovic Ljubisa,Mandic Danilo,Dakovic Milos,Brajovic Milos,Scalzo Bruno,Li Shengxi,Constantinides Anthony G.","Stankovic L,Mandic D,Dakovic M,Brajovic M,Scalzo B,Li SX,Constantinides AG",Stankovic L,10.1561/2200000078-2,University of Montenegro,"The area of Data Analytics on graphs deals with information processing of data acquired on irregular but structured graph domains. The focus of Part I of this monograph has been on both the fundamental and higher-order graph properties, graph topologies, and spectral representations of graphs. Part I also establishes rigorous frameworks for vertex clustering and graph segmentation, and illustrates the power of graphs in various data association tasks. Part II embarks on these concepts to address the algorithmic and practical issues related to data/signal processing on graphs, with the focus on the analysis and estimation of both deterministic and random data on graphs. The fundamental ideas related to graph signals are introduced through a simple and intuitive, yet general enough case study of multisensor temperature field estimation. The concept of systems on graph is defined using graph signal shift operators, which generalize the corresponding principles from traditional learning systems. At the core of the spectral domain representation of graph signals and systems is the Graph Fourier Transform (GFT), defined based on the eigendecomposition of both the adjacency matrix and the graph Laplacian. Spectral domain representations are then used as the basis to introduce graph signal filtering concepts and address their design, including Chebyshev series polynomial approximation. Ideas related to the sampling of graph signals, and in particular the challenging topic of data dimensionality reduction through graph subsampling, are presented and further linked with compressive sensing. The principles of time-varying signals on graphs and basic definitions related to random graph signals are next reviewed. Localized graph signal analysis in the joint vertex-spectral domain is referred to as the vertex-frequency analysis, since it can be considered as an extension of classical time-frequency analysis to the graph serving as signal domain. Important aspects of the local graph Fourier transform (LGFT) are covered, together with its various forms including the graph spectral and vertex domain windows and the inversion conditions and relations. A link between the LGFT with a varying spectral window and the spectral graph wavelet transform (SGWT) is also established. Realizations of the LGFT and SGWT using polynomial (Chebyshev) approximations of the spectral functions are further considered and supported by examples. Finally, energy versions of the vertex-frequency representations are introduced, along with their relations with classical time-frequency analysis, including a vertex-frequency distribution that can satisfy the marginal properties. The material is supported by illustrative examples.","graph theory,random data on graphs,big data on graphs,signal processing on graphs,graph",Article,"NOW PUBLISHERS INC, PO BOX 1024, HANOVER, MA 02339 USA",Computer Science,,,"VERTEX-FREQUENCY,ANALYSIS,UNCERTAINTY,PRINCIPLE,FILTER,BANKS,FRAMES,REPRESENTATIONS,RECONSTRUCTION",FOUNDATIONS AND TRENDS IN MACHINE LEARNING,,
15,Progress and prospect of high-speed visible light communication,47,3,,",","Chi Nan,Chen Hui",,,Chi Nan,"Based on visible light communication technology which has been a research hotspot in the field of communication,this paper reviews the background of visible light communication,illustrates the basic system architecture and explores the research progress of visible light communication around five frontier directions:material chips,high-speed systems,multiplexing networks,underwater visible light communication and machine learning.The challenges faced by visible light communication are analyzed.Finally,looking forward to the prospect of visible light communication:in the intelligent era of future,visible light communication will become an indispensable part of communication networks with its advantages of high-speed transmission,and cooperate with other communication technologies to complement human life.","visible light communication; ,material, chips; multiplexing networks; underwater visible light communication; ,machine learning",Review,,,,,,,,
16,Machine Learning Chemical Guidelines for Engineering Electronic Structures in Half-Heusler Thermoelectric Materials,2020,,,",,,,","Dylla Maxwell T,Dunn Alexander,Anand Shashwat,Jain Anubhav,Jeffrey Snyder G",,,Dylla Maxwell T,"Half-Heusler materials are strong candidates for thermoelectric applications due to their high weighted mobilities and power factors, which is known to be correlated to valley degeneracy in the electronic band structure. However, there are over 50 known semiconducting half-Heusler phases, and it is not clear how the chemical composition affects the electronic structure. While all the n-type electronic structures have their conduction band minimum at either the Gamma- or X-point, there is more diversity in the p-type electronic structures, and the valence band maximum can be at either the Gamma-, L-, or W-point. Here, we use high throughput computation and machine learning to compare the valence bands of known half-Heusler compounds and discover new chemical guidelines for promoting the highly degenerate W-point to the valence band maximum. We do this by constructing an orbital phase diagram to cluster the variety of electronic structures expressed by these phases into groups, based on the atomic orbitals that contribute most to their valence bands. Then, with the aid of machine learning, we develop new chemical rules that predict the location of the valence band maximum in each of the phases. These rules can be used to engineer band structures with band convergence and high valley degeneracy.",,Article,,,,,,,,
17,High Thermoelectric Performance of Cu-Doped PbSe-PbS System Enabled by High-Throughput Experimental Screening,2020,,,,,,,You Li,"Recent advances in high-throughput (HTP) computational power and machine learning have led to great achievements in exploration of new thermoelectric materials. However, experimental discovery and optimization of thermoelectric materials have long relied on the traditional Edisonian trial and error approach. Herein, we demonstrate that ultrahigh thermoelectric performance in a Cu-doped PbSe-PbS system can be realized by HTP experimental screening and precise property modulation. Combining the HTP experimental technique with transport model analysis, an optimal Se/S ratio showing high thermoelectric performance has been efficiently screened out. Subsequently, based on the screened Se/S ratio, the doping content of Cu has been subtly adjusted to reach the optimum carrier concentration. As a result, an outstanding peak zT~1.6 is achieved at 873 K for a 1.8 at% Cu-doped PbSe_(0.6)S_(0.4) sample, which is the superior value among the n-type Te-free lead chalcogenides. We anticipate that current work will stimulate large-scale unitization of the HTP experimental technique in the thermoelectric field, which can greatly accelerate the research and development of new high-performance thermoelectric materials.",,Article,,,,,,,,
18,Statistical Law and Predictive Analysis of Compressive Strength of Cemented Sand and Gravel,27,1,291-298,"Chen Shoukai,Fu Yongqiwen,Guo Lei,Yang Shifeng,Bie Yajing","Chen SK,Fu YQW,Guo L,Yang SF,Bie YJ",Guo L,10.1515/secm-2020-0030,North China University of Water Resources & Electric Power,"A data set of cemented sand and gravel (CSG) mix proportion and 28-day compressive strength was established, with outliers determined and removed based on the Boxplot. Then, the distribution law of compressive strength of CSG was analyzed using the skewness kurtosis and single-sample Kolmogorov-Smirnov tests. And with the help of Python software, a model based on Back Propagation neural network was built to predict the compressive strength of CSG according to its mix proportion. The results showed that the compressive strength follows the normal distribution law, the expected value and variance were 5.471 MPa and 3.962 MPa respectively, and the average relative error was 7.16%, indicating the predictability of compressive strength of CSG and its correlation with the mix proportion.","Cemented sand and gravel,Compressive strength,Boxplot,Normal distribution,BP neural network",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY",Materials Science,,1.161,,SCIENCE AND ENGINEERING OF COMPOSITE MATERIALS,https://www.degruyter.com/document/doi/10.1515/secm-2020-0030/pdf,
19,PECLIDES Neuro: A Personalisable Clinical Decision Support System for Neurological Diseases.,3,,23,",","Muller Tamara T,Lio Pietro",,10.3389/frai.2020.00023,, Copyright © 2020 Muller and Lio.,Alzheimer's Disease; Parkinson's Disease; decision support; machine learning; neurological diseases; personalisable medicine; precision medicine; random forest,Journal Article,,,,,,,,
20,A Proxy for Detecting IUGR Based on Gestational Age Estimation in a Guatemalan Rural Population.,3,,56,",,,,","Valderrama Camilo E,Marzbanrad Faezeh,Hall-Clifford Rachel,Rohloff Peter,Clifford Gari D",,10.3389/frai.2020.00056,,"In-utero progress of fetal development is normally assessed through manual measurements taken from ultrasound images, requiring relatively expensive equipment and well-trained personnel. Such monitoring is therefore unavailable in low- and middle-income countries (LMICs), where most of the perinatal mortality and morbidity exists. The work presented here attempts to identify a proxy for IUGR, which is a significant contributor to perinatal death in LMICs, by determining gestational age (GA) from data derived from simple-to-use, low-cost one-dimensional Doppler ultrasound (1D-DUS) and blood pressure devices. A total of 114 paired 1D-DUS recordings and maternal blood pressure recordings were selected, based on previously described signal quality measures. The average length of 1D-DUS recording was 10.43 ± 1.41 min. The min/median/max systolic and diastolic maternal blood pressures were 79/102/121 and 50.5/63.5/78.5 mmHg, respectively. GA was estimated using features derived from the 1D-DUS and maternal blood pressure using a support vector regression (SVR) approach and GA based on the last menstrual period as a reference target. A total of 50 trials of 5-fold cross-validation were performed for feature selection. The final SVR model was retrained on the training data and then tested on a held-out set comprising 28 normal weight and 25 low birth weight (LBW) newborns. The mean absolute GA error with respect to the last menstrual period was found to be 0.72 and 1.01 months for the normal and LBW newborns, respectively. The mean error in the GA estimate was shown to be negatively correlated with the birth weight. Thus, if the estimated GA is lower than the (remembered) GA calculated from last menstruation, then this could be interpreted as a potential sign of IUGR associated with LBW, and referral and intervention may be necessary. The assessment system may, therefore, have an immediate impact if coupled with suitable intervention, such as nutritional supplementation. However, a prospective clinical trial is required to show the efficacy of such a metric in the detection of IUGR and the impact of the intervention. Copyright © 2020 Valderrama, Marzbanrad, Hall-Clifford, Rohloff and Clifford.",fetal heart rate (FHR); gestational age estimation; intra-uterine growth restriction (IUGR); low-and middle-income countries (LMICs); maternal blood pressure; one-dimension Doppler ultrasound (1D-DUS); signal processing; supervised machine learning,Journal Article,,,,,,,,
21,Knowledge Models as Teaching Aid for Training Intensity Modulated Radiation Therapy Planning: A Lung Cancer Case Study.,3,,66,",,,,,,,,","Mistro Matt,Sheng Yang,Ge Yaorong,Kelsey Chris R,Palta Jatinder R,Cai Jing,Wu Qiuwen,Yin Fang-Fang,Wu Q Jackie",,10.3389/frai.2020.00066,,"Purpose: Artificial intelligence (AI) employs knowledge models that often behave as a black-box to the majority of users and are not designed to improve the skill level of users. In this study, we aim to demonstrate the feasibility that AI can serve as an effective teaching aid to train individuals to develop optimal intensity modulated radiation therapy (IMRT) plans. Methods and Materials: The training program is composed of a host of training cases and a tutoring system that consists of a front-end visualization module powered by knowledge models and a scoring system. The current tutoring system includes a beam angle prediction model and a dose-volume histogram (DVH) prediction model. The scoring system consists of physician chosen criteria for clinical plan evaluation as well as specially designed criteria for learning guidance. The training program includes six lung/mediastinum IMRT patients: one benchmark case and five training cases. A plan for the benchmark case is completed by each trainee entirely independently pre- and post-training. Five training cases cover a wide spectrum of complexity from easy (2), intermediate (1) to hard (2). Five trainees completed the training program with the help of one trainer. Plans designed by the trainees were evaluated by both the scoring system and a radiation oncologist to quantify planning quality. Results: For the benchmark case, trainees scored an average of 21.6% of the total max points pre-training and improved to an average of 51.8% post-training. In comparison, the benchmark case's clinical plans score an average of 54.1% of the total max points. Two of the five trainees' post-training plans on the benchmark case were rated as comparable to the clinically delivered plans by the physician and all five were noticeably improved by the physician's standards. The total training time for each trainee ranged between 9 and 12 h. Conclusion: This first attempt at a knowledge model based training program brought unexperienced planners to a level close to experienced planners in fewer than 2 days. The proposed tutoring system can serve as an important component in an AI ecosystem that will enable clinical practitioners to effectively and confidently use KBP. Copyright © 2020 Mistro, Sheng, Ge, Kelsey, Palta, Cai, Wu, Yin and Wu.","intensity modulated radiation therapy; knowledge model; lung cancer; ,machine learning,; tutoring system",Journal Article,,,,,,,,
22,Fluence Map Prediction Using Deep Learning Models - Direct Plan Generation for Pancreas Stereotactic Body Radiation Therapy.,3,,68,,,,10.3389/frai.2020.00068,,"Purpose: Treatment planning for pancreas stereotactic body radiation therapy (SBRT) is a difficult and time-consuming task. In this study, we aim to develop a novel deep learning framework to generate clinical-quality plans by direct prediction of fluence maps from patient anatomy using convolutional neural networks (CNNs). Materials and Methods: Our proposed framework utilizes two CNNs to predict intensity-modulated radiation therapy fluence maps and generate deliverable plans: (1) Field-dose CNN predicts field-dose distributions in the region of interest using planning images and structure contours; (2) a fluence map CNN predicts the final fluence map per beam using the predicted field dose projected onto the beam's eye view. The predicted fluence maps were subsequently imported into the treatment planning system for leaf sequencing and final dose calculation (model-predicted plans). One hundred patients previously treated with pancreas SBRT were included in this retrospective study, and they were split into 85 training cases and 15 test cases. For each network, 10% of training data were randomly selected for model validation. Nine-beam benchmark plans with standardized target prescription and organ-at-risk constraints were planned by experienced clinical physicists and used as the gold standard to train the model. Model-predicted plans were compared with benchmark plans in terms of dosimetric endpoints, fluence map deliverability, and total monitor units. Results: The average time for fluence-map prediction per patient was 7.1 s. Comparing model-predicted plans with benchmark plans, target mean dose, maximum dose (0.1 cc), and D95% absolute differences in percentages of prescription were 0.1, 3.9, and 2.1%, respectively; organ-at-risk mean dose and maximum dose (0.1 cc) absolute differences were 0.2 and 4.4%, respectively. The predicted plans had fluence map gamma indices (97.69 ± 0.96% vs. 98.14 ± 0.74%) and total monitor units (2,122 ± 281 vs. 2,265 ± 373) that were comparable to the benchmark plans. Conclusions: We develop a novel deep learning framework for pancreas SBRT planning, which predicts a fluence map for each beam and can, therefore, bypass the lengthy inverse optimization process. The proposed framework could potentially change the paradigm of treatment planning by harnessing the power of deep learning to generate clinically deliverable plans in seconds. Copyright © 2020 Wang, Sheng, Wang, Zhang, Li, Palta, Czito, Willett, Wu, Ge, Yin and Wu.",SBRT; artificial intelligence; convolutional neural network; deep learning; fluence map; pancreas; treatment planning,Journal Article,,,,,,,,
23,Automated Assessment of Peristomal Skin Discoloration and Leakage Area Using Artificial Intelligence.,3,,72,",,,","Andersen Niels K,Trojgaard Pernille,Herschend Nana O,Storling Zenia M",,10.3389/frai.2020.00072,,"For people living with an ostomy, development of peristomal skin complications (PSCs) is the most common post-operative challenge. A visual sign of PSCs is discoloration (redness) of the peristomal skin often resulting from leakage of ostomy output under the baseplate. If left unattended, a mild skin condition may progress into a severe disorder; consequently, it is important to monitor discoloration and leakage patterns closely. The Ostomy Skin Tool is current state-of-the-art for evaluation of peristomal skin, but it relies on patients visiting their healthcare professional regularly. To enable close monitoring of peristomal skin over time, an automated strategy not relying on scheduled consultations is required. Several medical fields have implemented automated image analysis based on artificial intelligence, and these deep learning algorithms have become increasingly recognized as a valuable tool in healthcare. Therefore, the main objective of this study was to develop deep learning algorithms which could provide automated, consistent, and objective assessments of changes in peristomal skin discoloration and leakage patterns. A total of 614 peristomal skin images were used for development of the discoloration model, which predicted the area of the discolored peristomal skin with an accuracy of 95% alongside precision and recall scores of 79.6 and 75.0%, respectively. The algorithm predicting leakage patterns was developed based on 954 product images, and leakage area was determined with 98.8% accuracy, 75.0% precision, and 71.5% recall. Combined, these data for the first time demonstrate implementation of artificial intelligence for automated assessment of changes in peristomal skin discoloration and leakage patterns. Copyright © 2020 Andersen, Trojgaard, Herschend and Storling.",artificial intelligence; convolutional neural networks; discoloration; leakage; ostomy; peristomal skin complications,Journal Article,,,,,,,,
24,Integration of AI and Machine Learning in Radiotherapy QA.,3,,577620,",,","Chan Maria F,Witztum Alon,Valdes Gilmer",,10.3389/frai.2020.577620,," Copyright © 2020 Chan, Witztum and Valdes.",IMRT; VMAT; artificial intelligence; machine learning; quality assurance; radiotherapy,Journal Article; Review,,,,,,,,
25,Tuberculosis Diagnostics and Localization in Chest X-Rays via Deep Learning Models.,3,,583427,",,","Guo Ruihua,Passi Kalpdrum,Jain Chakresh Kumar",,10.3389/frai.2020.583427,,"For decades, tuberculosis (TB), a potentially serious infectious lung disease, continues to be a leading cause of worldwide death. Proven to be conveniently efficient and cost-effective, chest X-ray (CXR) has become the preliminary medical imaging tool for detecting TB. Arguably, the quality of TB diagnosis will improve vastly with automated CXRs for TB detection and the localization of suspected areas, which may manifest TB. The current line of research aims to develop an efficient computer-aided detection system that will support doctors (and radiologists) to become well-informed when making TB diagnosis from patients' CXRs. Here, an integrated process to improve TB diagnostics via convolutional neural networks (CNNs) and localization in CXRs via deep-learning models is proposed. Three key steps in the TB diagnostics process include (a) modifying CNN model structures, (b) model fine-tuning via artificial bee colony algorithm, and (c) the implementation of linear average-based ensemble method. Comparisons of the overall performance are made across all three steps among the experimented deep CNN models on two publicly available CXR datasets, namely, the Shenzhen Hospital CXR dataset and the National Institutes of Health CXR dataset. Validated performance includes detecting CXR abnormalities and differentiating among seven TB-related manifestations (consolidation, effusion, fibrosis, infiltration, mass, nodule, and pleural thickening). Importantly, class activation mapping is employed to inform a visual interpretation of the diagnostic result by localizing the detected lung abnormality manifestation on CXR. Compared to the state-of-the-art, the resulting approach showcases an outstanding performance both in the lung abnormality detection and the specific TB-related manifestation diagnosis vis-a-vis the localization in CXRs. Copyright © 2020 Guo, Passi and Jain.",artificial bee colony algorithm; chest X-ray; class activation mapping; convolutional neural networks; ensemble; localization; manifestations; tuberculosis,Journal Article,,,,,,,,
26,BRAVE-NET: Fully Automated Arterial Brain Vessel Segmentation in Patients With Cerebrovascular Disease.,3,,552258,,,,10.3389/frai.2020.552258,,"Introduction: Arterial brain vessel assessment is crucial for the diagnostic process in patients with cerebrovascular disease. Non-invasive neuroimaging techniques, such as time-of-flight (TOF) magnetic resonance angiography (MRA) imaging are applied in the clinical routine to depict arteries. They are, however, only visually assessed. Fully automated vessel segmentation integrated into the clinical routine could facilitate the time-critical diagnosis of vessel abnormalities and might facilitate the identification of valuable biomarkers for cerebrovascular events. In the present work, we developed and validated a new deep learning model for vessel segmentation, coined BRAVE-NET, on a large aggregated dataset of patients with cerebrovascular diseases. Methods: BRAVE-NET is a multiscale 3-D convolutional neural network (CNN) model developed on a dataset of 264 patients from three different studies enrolling patients with cerebrovascular diseases. A context path, dually capturing high- and low-resolution volumes, and deep supervision were implemented. The BRAVE-NET model was compared to a baseline Unet model and variants with only context paths and deep supervision, respectively. The models were developed and validated using high-quality manual labels as ground truth. Next to precision and recall, the performance was assessed quantitatively by Dice coefficient (DSC); average Hausdorff distance (AVD); 95-percentile Hausdorff distance (95HD); and via visual qualitative rating. Results: The BRAVE-NET performance surpassed the other models for arterial brain vessel segmentation with a DSC = 0.931, AVD = 0.165, and 95HD = 29.153. The BRAVE-NET model was also the most resistant toward false labelings as revealed by the visual analysis. The performance improvement is primarily attributed to the integration of the multiscaling context path into the 3-D Unet and to a lesser extent to the deep supervision architectural component. Discussion: We present a new state-of-the-art of arterial brain vessel segmentation tailored to cerebrovascular pathology. We provide an extensive experimental validation of the model using a large aggregated dataset encompassing a large variability of cerebrovascular disease and an external set of healthy volunteers. The framework provides the technological foundation for improving the clinical workflow and can serve as a biomarker extraction tool in cerebrovascular diseases. Copyright © 2020 Hilbert, Madai, Akay, Aydin, Behland, Sobesky, Galinovic, Khalil, Taha, Wuerfel, Dusek, Niendorf, Fiebach, Frey and Livne.",UNET; artificial intelligence (AI); cerebrovascular disease (CVD); machine learning; segmentation (image processing),Journal Article,,,,,,,,
27,Using Word Embeddings to Learn a Better Food Ontology.,3,,584784,",,","Youn Jason,Naravane Tarini,Tagkopoulos Ilias",,10.3389/frai.2020.584784,,"Food ontologies require significant effort to create and maintain as they involve manual and time-consuming tasks, often with limited alignment to the underlying food science knowledge. We propose a semi-supervised framework for the automated ontology population from an existing ontology scaffold by using word embeddings. Having applied this on the domain of food and subsequent evaluation against an expert-curated ontology, FoodOn, we observe that the food word embeddings capture the latent relationships and characteristics of foods. The resulting ontology, which utilizes word embeddings trained from the Wikipedia corpus, has an improvement of 89.7% in precision when compared to the expert-curated ontology FoodOn (0.34 vs. 0.18, respectively, p value = 2.6 * 10-138), and it has a 43.6% shorter path distance (hops) between predicted and actual food instances (2.91 vs. 5.16, respectively, p value = 4.7 * 10-84) when compared to other methods. This work demonstrates how high-dimensional representations of food can be used to populate ontologies and paves the way for learning ontologies that integrate contextual information from a variety of sources and types. Copyright © 2020 Youn, Naravane and Tagkopoulos.",automated ontology learning; data-driven; food ontology; machine learning; ontology metrics; ontology population; word embeddings,Journal Article,,,,,,,,
28,Prognostic Value of Transfer Learning Based Features in Resectable Pancreatic Ductal Adenocarcinoma.,3,,550890,",,,,,","Zhang Yucheng,Lobo-Mueller Edrise M,Karanicolas Paul,Gallinger Steven,Haider Masoom A,Khalvati Farzad",,10.3389/frai.2020.550890,,"Background: Pancreatic Ductal Adenocarcinoma (PDAC) is one of the most aggressive cancers with an extremely poor prognosis. Radiomics has shown prognostic ability in multiple types of cancer including PDAC. However, the prognostic value of traditional radiomics pipelines, which are based on hand-crafted radiomic features alone is limited. Methods: Convolutional neural networks (CNNs) have been shown to outperform radiomics models in computer vision tasks. However, training a CNN from scratch requires a large sample size which is not feasible in most medical imaging studies. As an alternative solution, CNN-based transfer learning models have shown the potential for achieving reasonable performance using small datasets. In this work, we developed and validated a CNN-based transfer learning model for prognostication of overall survival in PDAC patients using two independent resectable PDAC cohorts. Results: The proposed transfer learning-based prognostication model for overall survival achieved the area under the receiver operating characteristic curve of 0.81 on the test cohort, which was significantly higher than that of the traditional radiomics model (0.54). To further assess the prognostic value of the models, the predicted probabilities of death generated from the two models were used as risk scores in a univariate Cox Proportional Hazard model and while the risk score from the traditional radiomics model was not associated with overall survival, the proposed transfer learning-based risk score had significant prognostic value with hazard ratio of 1.86 (95% Confidence Interval: 1.15-3.53, p-value: 0.04). Conclusions: This result suggests that transfer learning-based models may significantly improve prognostic performance in typical small sample size medical imaging studies. Copyright © 2020 Zhang, Lobo-Mueller, Karanicolas, Gallinger, Haider and Khalvati.",pancreatic cancer; prognosis; radiomics; survival analysis; transfer learning,Journal Article,,,,,,,,
29,Intelligent Algorithm for Ceramic Decorative Pattern Style Transfer Based on CycleGAN,,,151-156,"Liu Xinxin,Huang Hua,Qiu Meikang","Liu XX,Huang H,Qiu MK",Huang H,10.1109/CSCloud-EdgeCom49738.2020.00033,Jingdezhen Ceramic Institute,"Image style conversion refers to a technique that uses an algorithm to learn the style of a famous painting and then applies it to another picture. Current generative adversarial networks have been widely used for image style conversion. However, Cycle Generative Adversarial Networks (CycleGAN) is not very clear in processing image textures. This paper proposes a method of adding a Local Binary Pattern (LBP) algorithm and adds a cyclic LBP algorithm to the generator that generates the adversarial network to improve the effectiveness of the cyclically created adversarial network to extract image texture feature content. Experimental results show that adding the LBP algorithm can improve the image quality and make the trueness and falseness between the input picture and the picture generated by cyclegan closer.","Image style transfer,Generative Adversarial Network,Cycle Generative Adversarial Networks,Image texture,feature extraction,Local Binary Pattern",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA",Computer Science,,,,2020 7TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD 2020)/2020 6TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (EDGECOM 2020),,
30,Edge Computing-based 3D Pose Estimation and Calibration for Robot Arms,,,246-251,"Ma Qun,Niu Jianwei,Ouyang Zhenchao,Li Mo,Ren Tao,Li QingFeng","Ma Q,Niu JW,Ouyang ZC,Li M,Ren T,Li QF",Niu JW,10.1109/CSCloud-EdgeCom49738.2020.00050,Beihang University,"Industrial robots are widely used in current production lines, and complex pipeline processes, especially those with different assembly requirements, are designed for intelligent manufacturing in the era of industry 4.0. During the new crown epidemic, a large number of car companies used the production line to transform production of medical materials such as masks and protective clothing, which provided a strong guarantee for fighting the epidemic. In this scenario, a pipeline is often assembled from robotic arms from multiple suppliers. The traditional methods is complex and takes a lot of time. In this paper, we propose a novel deep learning based robot arm 3D pose estimation and calibration model with simple Kinect stereo cameras which can be deployed on light-weight edge computing systems. The light-weight deep CNN model can detection 5 predefined key points based on RGB-D data. In this way, when the assembly line composed of different robot arms needs to be reassembled, our model can quickly provide the robot's pose information without additional tuning processes. Testing in Webots with Rokae xb4 robot arm model shows that our model can quickly estimate the key point of the robot arm.","Pose Estimation,Key Point detection,Robot Arm,Deep Learning,Edge Computing",Proceedings Paper,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA",Computer Science,,,,2020 7TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD 2020)/2020 6TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (EDGECOM 2020),,
31,Development and validation of a CT-based radiomic nomogram for preoperative prediction of early recurrence in advanced gastric cancer.,145,,13-20,,,,10.1016/j.radonc.2019.11.023,,"BACKGROUND: In the clinical management of advanced gastric cancer (AGC), preoperative identification of early recurrence after curative resection is essential. Thus, we aimed to create a CT-based radiomic model to predict early recurrence in AGC patients preoperatively.RESULTS: A radiomic signature, including three hand crafted features and six deep learning features, was significantly associated with early recurrence (p-value <0.0001 for all sets). In addition, clinical N stage, carbohydrate antigen 199 levels, carcinoembryonic antigen levels, and Borrmann type were considered useful predictors for early recurrence. The nomogram, combining all these predictors, showed powerful prognostic ability in the training set and two test sets with AUCs of 0.831 (95% CI, 0.786-0.876), 0.826 (0.772-0.880) and 0.806 (0.732-0.881), respectively. The predicted risk yielded good agreement with the observed recurrence probability.CONCLUSIONS: By incorporating a radiomic signature and clinical risk factors, we created a radiomic nomogram to predict early recurrence in patients with AGC, preoperatively, which may serve as a potential tool to guide personalized treatment. Copyright © 2019 Elsevier B.V. All rights reserved.",Computed tomography; Deep learning; Gastric cancer; Prognosis; Radiomics,"Journal Article; Research Support, Non-U.S. Gov't",,,,,,,,
32,Gum-Net: Unsupervised Geometric Matching for Fast and Accurate 3D Subtomogram Image Alignment and Averaging,,,4072-4083,"Zeng Xiangrui,Xu Min","Zeng XR,Xu M",Xu M,10.1109/CVPR42600.2020.00413,Carnegie Mellon University,"We propose a Geometric unsupervised matching Network (Gum-Net) for finding the geometric correspondence between two images with application to 3D subtomogram alignment and averaging. Subtomogram alignment is the most important task in cryo-electron tomography (cryo-ET), a revolutionary 3D imaging technique for visualizing the molecular organization of unperturbed cellular landscapes in single cells. However, subtomogram alignment and averaging are very challenging due to severe imaging limits such as noise and missing wedge effects. We introduce an end-to-end trainable architecture with three novel modules specifically designed for preserving feature spatial information and propagating feature matching information. The training is performed in a fully unsupervised fashion to optimize a matching metric. No ground truth transformation information nor category-level or instance-level matching supervision information is needed. After systematic assessments on six real and nine simulated datasets, we demonstrate that Gum-Net reduced the alignment error by 40 to 50% and improved the averaging resolution by 10%. Gum-Net also achieved 70 to 110 times speedup in practice with GPU acceleration compared to state-of-the-art subtomogram alignment methods. Our work is the first 3D unsupervised geometric matching method for images of strong transformation variation and high noise level. The training code, trained model, and datasets are available in our open-source software AITom(1).","IN-SITU,REGISTRATION,MODEL,CLASSIFICATION,TOMOGRAPHY,TRANSFORMATIONS,ALGORITHM,FRAMEWORK",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Computer Science,,,"IN-SITU,REGISTRATION,MODEL,CLASSIFICATION,TOMOGRAPHY,TRANSFORMATIONS,ALGORITHM,FRAMEWORK",,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7955792,
33,Gaussian Processes with Physiologically-Inspired Priors for Physical Arousal Recognition,,,54-57,"Ghiasi S.,Patane A.,Greco A.,Laurenti L.,Scilingo E. P.,Kwiatkowska M.","Ghiasi S,Patane A,Greco A,Laurenti L,Scilingo EP,Kwiatkowska M",Ghiasi S,,University of Pisa,"While machine learning algorithms are able to detect subtle patterns of interest in data, expert knowledge may contain crucial information that is not easily extracted from a given dataset, especially when the latter is small or noisy. In this paper we investigate the suitability of Gaussian Process Classification (GPC) as an effective model to implement the domain knowledge in an algorithm's training phase. Building on their Bayesian nature, we proceed by injecting problem-specific domain knowledge in the form of an a-priori distribution on the GPC latent function. We do this by extracting hand-crafted features from the input data, and correlating them to the logits of the classification problem through fitting a prior function informed by the physiology of the problem. The physiologically-informed prior of the GPC is then updated through the Bayes formula using the available dataset. We apply the methods discussed here to a two-class classification problem associated to a dataset comprising Heart Rate Variability (HRV) and Electrodermal Activity (EDA) signals collected from 26 subjects who were exposed to a physical stressor aimed at altering their autonomic nervous systems dynamics. We provide comparative computational experiments on the selection of appropriate physiologically-inspired GPC prior functions. We find that the recognition of the presence of the physical stressor is significantly enhanced when the physiologically-inspired prior knowledge is injected into the GPC model.","ELECTRODERMAL ACTIVITY,REGRESSION",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"ELECTRODERMAL,ACTIVITY,REGRESSION",,https://ora.ox.ac.uk/objects/uuid:95599dff-7941-4591-863b-f8191d5a4da6/download_file?safe_filename=GhiasietalAAM2020.pdf&type_of_work=Conference+item,
34,Random Forest-based Algorithm for Sleep Spindle Detection in Infant EEG,,,58-61,"Wei Lan,Ventura Soraia,Lowery Madeleine,Ryan Mary Anne,Mathieson Sean,Boylan Geraldine B.,Mooney Catherine","Wei L,Ventura S,Lowery M,Ryan MA,Mathieson S,Boylan GB,Mooney C",Wei L,,University College Dublin,"Sleep spindles are associated with normal brain development, memory consolidation and infant sleep-dependent brain plasticity and can be used by clinicians in the assessment of brain development in infants. Sleep spindles can be detected in EEG, however, identifying sleep spindles in EEG recordings manually is very time-consuming and typically requires highly trained experts. Research on the automatic detection of sleep spindles in infant EEGs has been limited to-date. In this study, we present a novel supervised machine learning-based algorithm to detect sleep spindles in infant EEG recordings. EEGs collected from 141 ex-term born infants and 6 ex-preterm born infants, recorded at 4 months of age (adjusted), were used to train and test the algorithm. Sleep spindles were annotated by experienced clinical physiologists as the gold standard. The dataset was split into training (81 ex-term), validation (30 exterm), and testing (30 ex-term + 6 ex-preterm) set. 15 features were selected for input into a random forest algorithm. Sleep spindles were detected in the ex-term infant EEG test set with 92.1% sensitivity and 95.2% specificity. For ex-preterm born infants, the sensitivity and specificity were 80.3% and 91.8% respectively. The proposed algorithm has the potential to assist researchers and clinicians in the automated analysis of sleep spindles in infant EEG.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,https://researchrepository.ucd.ie/bitstream/10197/12166/2/sleep_spindle__EMBS_TBioCAS_Lan.pdf,
35,Detecting Personality Traits Using Inter-Hemispheric Asynchrony of the Brainwaves,,,62-65,"Sharan Roneel V,Berkovsky Shlomo,Taib Ronnie,Koprinska Irena,Li Jingjie","Sharan RV,Berkovsky S,Taib R,Koprinska I,Li JJ",Sharan RV,,Macquarie University,"Affective personality traits have been associated with a risk of developing mental and cognitive disorders and can be informative for early detection and management of such disorders. However, conventional personality trait detection is often biased and unreliable, as it depends on the honesty of the subjects when filling out the lengthy questionnaires. In this paper, we propose a method for objective detection of personality traits using physiological signals. Subjects are shown affective images and videos to evoke a range of emotions. The electrical activity of the brain is captured using EEG during this process and the multi-channel EEG data is processed to compute the inter-hemispheric asynchrony of the brainwaves. The most discriminative features are selected and then used to build a machine learning classifier, which is trained to predict 16 personality traits. Our results show high predictive accuracy for both image and video stimuli individually, and an improvement when the two stimuli are combined, achieving a 95.49% accuracy. Most of the selected discriminative features were found to be extracted from the alpha frequency band. Our work shows that personality traits can be accurately detected with EEG data, suggesting possible use in practical applications for early detection of mental and cognitive disorders.","EMOTION,RISK",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"EMOTION,RISK",,,
36,Audio for Audio is Better? An Investigation on Transfer Learning Models for Heart Sound Classification,,,74-77,"Koike Tomoya,Qian Kun,Kong Qiuqiang,Plumbley Mark D.,Schuller Bjorn W.,Yamamoto Yoshiharu","Koike T,Qian K,Kong QQ,Plumbley MD,Schuller BW,Yamamoto Y",Koike T; Qian K,,University of Tokyo,"Cardiovascular disease is one of the leading factors for death cause of human beings. In the past decade, heart sound classification has been increasingly studied for its feasibility to develop a non-invasive approach to monitor a subject's health status. Particularly, relevant studies have benefited from the fast development of wearable devices and machine learning techniques. Nevertheless, finding and designing efficient acoustic properties from heart sounds is an expensive and time-consuming task. It is known that transfer learning methods can help extract higher representations automatically from the heart sounds without any human domain knowledge. However, most existing studies are based on models pre-trained on images, which may not fully represent the characteristics inherited from audio. To this end, we propose a novel transfer learning model pre-trained on large scale audio data for a heart sound classification task. In this study, the PhysioNet CinC Challenge Dataset is used for evaluation. Experimental results demonstrate that, our proposed pre-trained audio models can outperform other popular models pre-trained by images by achieving the highest unweighted average recall at 89.7 %.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
37,Automatic Identification of Brain Independent Components in Electroencephalography Data Collected while Standing in a Virtually Immersive Environment - A Deep Learning-Based Approach,,,95-98,"Kaur Rachneet,Korolkov Maxim,Hernandez Manuel E.,Sowers Richard","Kaur R,Korolkov M,Hernandez ME,Sowers R",Kaur R,,University of Illinois System,"Electroencephalography (EEG) is a commonly used method for monitoring brain activity. Automating an EEG signal processing pipeline is imperative to the exploration of real-time brain computer interface (BCI) applications. EEG analysis demands substantial training and time for removal of distinct unwanted independent components (ICs), generated via independent component analysis, corresponding to artifacts. The considerable subject-wise variations across these components motivates defining a procedural way to identify and eliminate these artifacts. We propose DeepIC-virtual, a convolutional neural network (CNN) deep learning classifier to automatically identify brain components in the ICs extracted from the subject's EEG data gathered while they are being immersed in a virtual reality (VR) environment. This work examined the feasibility of DL techniques to provide automated ICs classification on noisy and visually engaging upright stance EEG data. We collected the EEG data for six subjects while they were standing upright in a VR testing setup simulating pseudo-randomized variations in height and depth conditions and induced perturbations. An extensive 1432 IC representation images data set was generated and manually labelled via an expert as brain components or one of the six distinct removable artifacts. The supervised CNN architecture was utilized to categorize good brain ICs and bad artifactual ICs via generated images of topographical maps. Our model categorizing good versus bad IC topographical maps resulted in a binary classification accuracy and area under curve of 89.20% and 0.93 respectively. Despite significant imbalance, only 1 out of the 57 present brain ICs in the withheld testing set was miss-classified as an artifact. These results will hopefully encourage clinicians to integrate BCI methods and neurofeedback to control anxiety and provide a treatment of acrophobia, given the viability of automatic classification of artifactual ICs.","Virtual reality,Electroencephalography,Independent component,Convolutional neural networks",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,ARTIFACTS,,,
38,Deep transfer learning for improving single-EEG arousal detection,,,99-103,"Olesen Alexander Neergaard,Jennum Poul,Mignot Emmanuel,Sorensen Helge B. D.","Olesen AN,Jennum P,Mignot E,Sorensen HBD",Olesen AN,,Technical University of Denmark,"Datasets in sleep science present challenges for machine learning algorithms due to differences in recording setups across clinics. We investigate two deep transfer learning strategies for overcoming the channel mismatch problem for cases where two datasets do not contain exactly the same setup leading to degraded performance in single-EEG models. Specifically, we train a baseline model on multivariate polysomnography data and subsequently replace the first two layers to prepare the architecture for single-channel electroencephalography data. Using a fine-tuning strategy, our model yields similar performance to the baseline model (F1=0.682 and F1=0.694, respectively), and was significantly better than a comparable single-channel model. Our results are promising for researchers working with small databases who wish to use deep learning models pre-trained on larger databases.","OSTEOPOROTIC FRACTURES,SLEEP MEDICINE,AMERICAN ACADEMY,RELIABILITY,MEN,ARCHITECTURE,AGREEMENT",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"OSTEOPOROTIC,FRACTURES,SLEEP,MEDICINE,AMERICAN,ACADEMY,RELIABILITY,MEN,ARCHITECTURE,AGREEMENT",,http://arxiv.org/pdf/2004.05111,
39,Deep learning for estimation of functional brain maturation from EEG of premature neonates,,,104-107,"Gschwandtner Laura,Hartmann Manfred,Oberdorfer Lisa,Fuerbass Franz,Klebermass-Schrehof Katrin,Werther Tobias,Stevenson Nathan,Gritsch Gerhard,Perko Hannes,Berger Angelika","Gschwandtner L,Hartmann M,Oberdorfer L,Furbass F,Klebermass-Schrehof K,Werther T,Stevenson N,Gritsch G,Perko H,Berger A",Hartmann M,,Austrian Institute of Technology (AIT),EEG monitoring of early brain function and development in neonatal intensive care units may help to identify infants with high risk of serious neurological impairment and to assess brain maturation for evaluation of neurodevelopmental progress. Automated analysis of EEG data makes continuous evaluation of brain activity fast and accessible. A convolutional neural network (CNN) for regression of EEG maturational age of premature neonates from marginally preprocessed serial EEG recordings is proposed. The CNN was trained and validated using 141 EEG recordings from 43 preterm neonates born below 28 weeks of gestation with normal neurodevelopmental outcome at 12 months of corrected age. The estimated functional brain maturation between the first and last EEG recording increased in each patient. On average over 96% of repeated measures within an infant had an increasing EEG maturational age according to the post menstrual age at EEG recording time. Our algorithm has potential to be deployed to support neonatologists for accurate estimation of functional brain maturity in premature neonates.,,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
40,Emotion Recognition with Refined Labels for Deep Learning,,,108-111,"Zhang Su,Guan Cuntai","Zhang S,Guan CT",Guan CT,,Nanyang Technological University & National Institute of Education (NIE) Singapore,"The traditional emotion classification framework usually fits all the features segments of the same trial to a fixed annotation. Considering the fact that emotion is a reaction to stimuli that lasts for varied periods, we argue that the indiscriminate annotation is equivalent to taking the emotional state as fixed within the whole trial, leading to a decrease of the classification accuracy. In this study, we attempt to alleviate this issue by developing a thresholding scheme, converting the continuous emotional trace into a three-class annotation temporally. The features within a trial are therefore assigned to varied emotional states, resulting in an improvement in the accuracy. A long short term memory (LSTM) networks-based emotion classification framework is implemented, to which the proposed thresholding scheme is applied. A subset of MAHNOB-HCI dataset with continuous emotional annotation is used. The EEG signal and frontal facial video are used for feature extraction. The experiment results demonstrate that the proposed scheme provides statistically significant improvement to the three-class classification accuracy of the EEG feature-based LSTM network (p-value = 0:0329).",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
41,Machine Learning with Imbalanced EEG Datasets using Outlier-based Sampling,,,112-115,"Islah Nizar,Koerner Jamie,Genov Roman,Valiante Taufik A.,O'Leary Gerard","Islah N,Koerner J,Genov R,Valiante TA,O'Leary G",Islah N,,University of Toronto,"Epilepsy is a neurological disorder which causes seizures in over 65 million people worldwide. Recently developed implantable therapeutic devices aim to prevent symptoms by applying acute electrical stimulation to the seizure-generating brain region in response to activity detected by on-device machine learning hardware. Many training algorithms require an equal number of examples for each target class (e.g. normal activity and seizures), and performance can suffer if this condition is not satisfied. In the case of epilepsy, poor performance can cause seizures to be missed, or stimulation to be applied erroneously. As there is an abundance of normal (interictal) data in clinical EEG recordings, but seizures are rare events (less than 1% of the dataset), the data available for training is severely imbalanced. There are several conventional pre-processing methods used to address imbalanced class learning, such as down-sampling of the majority class and up-sampling of the minority class, but each have performance drawbacks. This paper presents an improved method which involves reducing the majority class down to the most effective interictal outlier samples. Outliers are determined by using Exponentially Decaying Memory Signal Energy (EDMSE) features with Isolation Forests and an ANOVA-based method, which involves comparing a moving feature window to a baseline reference window. Outlier-based sampling is tested with two classifiers (KNN and Logistic Regression) and achieves higher accuracy (similar to 2% increase) and fewer false positives (similar to 38% decrease), along with a lower latency (similar to 3 seconds shorter) compared to conventional training set pre-processing methods.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
42,EEG-based Emotion Recognition Using Spatial-Temporal Representation via Bi-GRU,,,116-119,"Lew Wai-Cheong Lincoln,Wang Di,Shylouskaya Katsiaryna,Zhang Zhuo,Lim Joo-Hwee,Ang Kai Keng,Tan Ah-Hwee","Lew WCL,Wang D,Shylouskaya K,Zhang Z,Lim JH,Ang KK,Tan AH",Lew WCL,,Nanyang Technological University & National Institute of Education (NIE) Singapore,"Many prior studies on EEG-based emotion recognition did not consider the spatial-temporal relationships among brain regions and across time. In this paper, we propose a Regionally-Operated Domain Adversarial Network (RODAN), to learn spatial-temporal relationships that correlate between brain regions and time. Moreover, we incorporate the attention mechanism to enable cross-domain learning to capture both spatial-temporal relationships among the EEG electrodes and an adversarial mechanism to reduce the domain shift in EEG signals. To evaluate the performance of RODAN, we conduct subject-dependent, subject-independent, and subject-biased experiments on both DEAP and SEED-IV data sets, which yield encouraging results. In addition, we also discuss the biased sampling issue often observed in EEG-based emotion recognition and present an unbiased benchmark for both DEAP and SEED-IV.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
43,Depression Scale Prediction with Cross-Sample Entropy and Deep Learning,,,120-123,"Chen Guan-Yen,Huang Chih-Mao,Liu Ho-Ling,Lee Shwu-Hua,Lee Tatia Mei-Chun,Lin Chemin,Wu Shun-Chi","Chen GY,Huang CM,Liu HL,Lee SH,Lee TMC,Lin CM,Wu SC",Wu SC,,National Tsing Hua University,"A two-stage deep learning-based scheme is presented to predict the Hamilton Depression Scale (HAM-D) in this study. First, the cross-sample entropy (CSE) that allows assessing the degree of similarity of two data series are evaluated for the 90 brain regions of interest partitioned according to Automated Anatomical Labeling. The obtained CSE maps are then converted to 3D CSE volumes to serve as the inputs to the deep learning network models for the HAM-D scale level classification and prediction. The efficacy of the proposed scheme was illustrated by the resting-state functional magnetic resonance imaging data from 38 patients. From the results, the root mean square errors for the HAM-D scale prediction obtained during training, validation, and testing were 2.73, 2.66, and 2.18, which were less than those of a scheme having only a regression stage.","BRAIN ACTIVITY,COMPLEXITY",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"BRAIN,ACTIVITY,COMPLEXITY",,,
44,Spatio-temporal deep learning for EEG-fNIRS brain computer interface,,,124-127,"Ghonchi Hamidreza,Fateh Mansoor,Abolghasemi Vahid,Ferdowsi Saideh,Rezvani Mohsen","Ghonchi H,Fateh M,Abolghasemi V,Ferdowsi S,Rezvani M",Fateh M,,Shahrood University of Technology,"In this paper the classification of motor imagery brain signals is addressed. The innovative idea is to use both temporal and spatial knowledge of the input data to increase the performance. Definitely, the electrode locations on the scalp is as important as the acquired temporal signals from every individual electrode. In order to incorporate this knowledge, a deep neural network is employed in this work. Both motor-imagery EEG and bi-modal EEG-fNIRS datasets were used for this purpose. The results are compared for different scenarios and using different methods. The achieved results are promising and imply that combining both temporal and spatial information of the brain signals could be really effective and increases the performance.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
45,Generalized Prediction of Unconsciousness during Propofol Anesthesia using 3D Convolutional Neural Networks,,,134-137,"Patlatzoglou Konstantinos,Chennu Srivas,Gosseries Olivia,Bonhomme Vincent,Wolff Audrey,Laureys Steven","Patlatzoglou K,Chennu S,Gosseries O,Bonhomme V,Wolff A,Laureys S",Patlatzoglou K,,University of Kent,"Neuroscience has generated a number of recent advances in the search for the neural correlates of consciousness, but these have yet to find valuable real-world applications. Electroencephalography under anesthesia provides a powerful experimental setup to identify electrophysiological signatures of altered states of consciousness, as well as a testbed for developing systems for automatic diagnosis and prognosis of awareness in clinical settings. In this work, we use deep convolutional neural networks to automatically differentiate sub-anesthetic states and depths of anesthesia, solely from one second of raw EEG signal. Our results with leave-one-participant-out-cross-validation show that behavioral measures, such as the Ramsay score, can be used to learn generalizable neural networks that reliably predict levels of unconsciousness in unseen transitional anesthetic states, as well as in unseen experimental setups and behaviors. Our findings highlight the potential of deep learning to detect progressive changes in anesthetic-induced unconsciousness with higher granularity than behavioral or pharmacological markers. This work has broader significance for identifying generalized patterns of brain activity that index states of consciousness.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,https://orbi.uliege.be/bitstream/2268/257712/1/Generalized%20Prediction%20of%20Unconsciousness%20during%20Propofol%20Anesthesia%20using%203D%20Convolutional%20Neural%20Networks.pdf,
46,Automatic detection of artifacts in EEG by combining deep learning and histogram contour processing,,,138-141,"Bahador Nooshin,Erikson Kristo,Laurila Jouko,Koskenkari Juha,Ala-Kokko Tero,Kortelainen Jukka","Bahador N,Erikson K,Laurila J,Koskenkari J,Ala-Kokko T,Kortelainen J",Bahador N,,University of Oulu,"This paper introduces a simple approach combining deep learning and histogram contour processing for automatic detection of various types of artifact contaminating the raw electroencephalogram (EEG). The proposed method considers both spatial and temporal information of raw EEG, without additional need for reference signals like ECG or EOG. The proposed method was evaluated with data including 785 EEG sequences contaminated by artifacts and 785 artifact-free EEG sequences collected from 15 intensive care patients. The obtained results showed an overall accuracy of 0.98, representing high reliability of proposed technique in detecting different types of artifacts and being comparable or outperforming the approaches proposed earlier in the literature.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,http://jultika.oulu.fi/files/nbnfi-fe2020112092122.pdf,
47,Deep Learning Techniques to Improve Intraoperative Awareness Detection from Electroencephalographic Signals,,,142-145,"Avilov Oleksii,Rimbert Sebastien,Popov Anton,Bougrain Laurent","Avilov O,Rimbert S,Popov A,Bougrain L",Avilov O,,Centre National de la Recherche Scientifique (CNRS),"Every year, millions of patients regain consciousness during surgery and can potentially suffer from post-traumatic disorders. We recently showed that the detection of motor activity during a median nerve stimulation from electroencephalographic (EEG) signals could be used to alert the medical staff that a patient is waking up and trying to move under general anesthesia [1], [2]. In this work, we measure the accuracy and false positive rate in detecting motor imagery of several deep learning models (EEGNet, deep convolutional network and shallow convolutional network) directly trained on filtered EEG data. We compare them with efficient non-deep approaches, namely, a linear discriminant analysis based on common spatial patterns, the minimum distance to Riemannian mean algorithm applied to covariance matrices, a logistic regression based on a tangent space projection of covariance matrices (TS+LR). The EEGNet improves significantly the classification performance comparing to other classifiers (p-value < 0.01); moreover it outperforms the best non-deep classifier (TS+LR) for 7.2% of accuracy. This approach promises to improve intraoperative awareness detection during general anesthesia.",MOTOR IMAGERY,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"MOTOR,IMAGERY",,https://hal.inria.fr/hal-02920320/document,
48,Predicting Age with Deep Neural Networks from Polysomnograms,,,146-149,"Brink-Kjaer Andreas,Mignot Emmanuel,Sorensen Helge B. D.,Fennum Poul","Brink-Kjaer A,Mignot E,Sorensen HBD,Fennum P",Brink-Kjaer A,,Technical University of Denmark,"The aim of this study was to design a new deep learning framework for end-to-end processing of polysomno-grams. This framework can be trained to analyze whole-night polysomnograms without the limitations of and bias towards clinical scoring guidelines. We validated the framework by predicting the age of subjects. We designed a hierarchical attention network architecture, which can be pre-trained to predict labels based on 5-minute epochs of data and fine-tuned to predict based on whole-night polysomnography recordings. The model was trained on 511 recordings from the Cleveland Family study and tested on 146 test subjects aged between 6 to 88 years. The proposed network achieved a mean absolute error of 7.36 years and a correlation to true age of 0.857. Sleep can be analyzed using our end-to-end deep learning framework, which we expect can generalize to learning other subject-specific labels such as sleep disorders. The difference in the predicted and chronological age is further proposed as an estimate of biological age.",SLEEP,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,SLEEP,,,
49,A machine learning method for automatic detection and classification of patient-ventilator asynchrony,,,150-153,"Bakkes T. H. G. F.,Montree R. J. H.,Mischi M.,Mojoli F.,Turco S.","Bakkes THGF,Montree RJH,Mischi M,Mojoli F,Turco S",Bakkes THGF,,Eindhoven University of Technology,"Patients suffering from respiratory failure are often put on assisted mechanical ventilation. Patient-ventilator asynchrony (PVA) can occur during mechanical ventilation, which cause damage to the lungs and has been linked to increased mortality in the intensive care unit. In current clinical practice PVA is still detected using visual inspection of the air pressure, flow, and volume curves, which is time-consuming and sensitive to subjective interpretation. Correct detection of the patient respiratory efforts is needed to properly asses the type of asynchrony. Therefore, we propose a method for automatic detection of the patient respiratory efforts using a one-dimensional convolution neural network. The proposed method was able to detect patient efforts with a sensitivity and precision of 98.6% and 97.3% for the inspiratory efforts, and 97.7% and 97.2% for the expiratory efforts. Besides allowing detection of PVA, combining the estimated timestamps of patient's inspiratory and expiratory efforts with the timings of the mechanical ventilator further allows for classification of the asynchrony type. In the future, the proposed method could support clinical decision making by informing clinicians on the quality of ventilation and providing actionable feedback for properly adjusting the ventilator settings.",MECHANICAL VENTILATION,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"MECHANICAL,VENTILATION",,,
50,Automatic Detection of Respiratory Effort Related Arousals With Deep Neural Networks From Polysomnographic Recordings,,,154-157,"Wickramaratne Sajila D.,Mahmud Md Shaad","Wickramaratne SD,Mahmud MS",Wickramaratne SD,,University System Of New Hampshire,"Sleep disorders have become more common due to the modern lifestyle and stress. The most severe case of sleep disorders called apnea is characterized by a complete breaking block, leading to awakening and subsequent sleep disturbances. The automatic detection of sleep arousals is still challenging. In this paper, a novel method is presented to detect non-apnea sources of arousals during sleep using Polysomnography(PSG) recordings. After the preprocessing, a sequence-to-sequence deep neural network (DNNs) consisting of a series of Bidirectional long short-term memory (Bi-LSTM) layer, and fully connected layers were trained to classify samples in the segments. Initially, three different models were prepared for different datasets. Finally, obtaining the classification result through an ensemble model consisting of the three trained models. The result shows that the area under the receiver precision-recall curve (AUPRC) is 0.59 for the test dataset exceeding the performance of the classifiers in the existing literature.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
51,Robust Deep Learning Framework For Predicting Respiratory Anomalies and Diseases,,,164-167,"Lam Pham,McLoughlin Ian,Huy Phan,Minh Tran,Truc Nguyen,Palaniappan Ramaswamy","Pham L,McLoughlin I,Phan H,Tran M,Nguyen T,Palaniappan R",Pham L,,University of Kent,"This paper presents a robust deep learning framework developed to detect respiratory diseases from recordings of respiratory sounds. The complete detection process firstly involves front end feature extraction where recordings are transformed into spectrograms that convey both spectral and temporal information. Then a back-end deep learning model classifies the features into classes of respiratory disease or anomaly. Experiments, conducted over the ICBHI benchmark dataset of respiratory sounds, evaluate the ability of the framework to classify sounds. Two main contributions are made in this paper. Firstly, we provide an extensive analysis of how factors such as respiratory cycle length, time resolution, and network architecture, affect final prediction accuracy. Secondly, a novel deep learning based framework is proposed for detection of respiratory diseases and shown to perform extremely well compared to state of the art methods.","Respiratory disease,wheeze,crackle,deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,http://arxiv.org/pdf/2002.03894,
52,Rheumatic Heart Disease Detection Using Deep Learning from Spectro-Temporal Representation of Un-segmented Heart Sounds,,,168-171,"Asmare Melkamu Hunegnaw,Woldehanna Frehiwot,Janssens Luc,Vanrumste Bart","Asmare MH,Woldehanna F,Janssens L,Vanrumste B",Asmare MH,,KU Leuven,"Rheumatic Heart Disease (RHD) is an autoimmune response to a bacterial attack which deteriorates the normal functioning of the heart valves. The damage on the valves affects the normal blood flow inside the heart chambers which can be recorded and listened to via a stethoscope as a phonocardiogram. However, the manual method of auscultation is difficult, time consuming and subjective. In this study, a convolutional neural network based deep learning algorithm is used to perform an automatic auscultation and it classifies the heart sound as normal and rheumatic. The classification is done on un-segmented data where the extraction of the first, the second and systolic and diastolic heart sounds are not required. The architecture of the CNN network is formed as an array of layers. Convolutional and batch normalization layers followed by a max pooling layer to down sample the feature maps are used. At the end there is a final max pooling layer which pools the input feature map globally over time and at the end a fully connected layer is included. The network has five convolutional layers. This current work illustrates the use of deep convolutional neural network using a Mel Spectro-temporal representation. For this current study, an RHD heart sound data set is recorded from one hundred seventy subjects from whom one hundred twenty four are confirmed RHD patients. The system has an overall accuracy of 96.1% with 94.0% sensitivity and 98.1% and specificity.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
53,Optimal Scree-CNN for Detecting NS1 Molecular Fingerprint from Salivary SERS Spectra,,,180-183,"Saifuzzaman T. A.,Lee Khuan Y.,Radzol A. R. M.,Wong P. S.,Looi I","Saifuzzaman TA,Lee KY,Radzol ARM,Wong PS,Looi I",Lee KY,,"UiTM Selangor, Fac Elect Engn, Shah Alam, Malaysia.","Dengue fever (DF) is a viral infection with possible fatal consequence. NS1 is a recent antigen based biomarker for dengue fever (DF), as an alternative to current serum and antibody based biomarkers. Convolutional Neural Network (CNN) has demonstrated impressive performance in machine learning problems. Our previous research has captured NS1 molecular fingerprint in saliva using Surface Enhanced Raman Spectroscopy (SERS) with great potential as an early, non-invasive detection method. SERS is an enhanced variant of Raman spectroscopy, with extremely high amplification that enables spectra of low concentration matter, such as NS1 in saliva, readable. The spectrum contains 1801 features per sample, at a total of 284 samples. Principal Component Analysis (PCA) transforms high dimensional correlated signal to a lower dimension uncorrelated principal components (PCs), at no sacrifice of the original signal content. This paper aims to unravel an optimal Scree-CNN model for classification of salivary NS1 SERS spectra. Performances of a total of 490 classifier models were examined and compared in terms of performance indicators [accuracy, sensitivity, specificity, precision, kappa] against a WHO recommended clinical standard test for DF, enzyme-linked immunosorbent assay (ELISA). Effects of CNN parameters on performances of the classifier models were also observed. Results showed that Scree-CNN classifier model with learning rate of 0.01, mini-batch size of 64 and validation frequency of 50, reported an across-the-board 100% for all performance indicators.","RAMAN-SPECTROSCOPY,TESTS",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"RAMAN-SPECTROSCOPY,TESTS",,,
54,Attention Networks for Multi-Task Signal Analysis,,,184-187,"Ahmedt-Aristizabal David,Armin Mohammad Ali,Denman Simon,Fookes Clinton,Petersson Lars","Ahmedt-Aristizabal D,Armin MA,Denman S,Fookes C,Petersson L",Ahmedt-Aristizabal D,,Commonwealth Scientific & Industrial Research Organisation (CSIRO),"Recent advances in deep learning have enabled the development of automated frameworks for analysing medical images and signals. For analysis of physiological recordings, models based on temporal convolutional networks and recurrent neural networks have demonstrated encouraging results and an ability to capture complex patterns and dependencies in the data. However, representations that capture the entirety of the raw signal are suboptimal as not all portions of the signal are equally important. As such, attention mechanisms are proposed to divert focus to regions of interest, reducing computational cost and enhancing accuracy. Here, we evaluate attention-based frameworks for the classification of physiological signals in different clinical domains. We evaluated our methodology on three classification scenarios: neurogenerative disorders, neurological status and seizure type. We demonstrate that attention networks can outperform traditional deep learning models for sequence modelling by identifying the most relevant attributes of an input signal for decision making. This work highlights the benefits of attention-based models for analysing raw data in the field of biomedical research.",LSTM,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,LSTM,,https://eprints.qut.edu.au/213526/1/83354917.pdf,
55,Classify Motor Imagery by a Novel CNN with Data Augmentation,,,192-195,"Huang Weijian,Wang Li,Yan Zhenxiong,Liu Yanjun","Huang WJ,Wang L,Yan ZX,Liu YJ",Huang WJ,,Guangzhou University,"The brain-computer interface (BCI) based on electroencephalography (EEG) converts the subject's intentions into control signals. For the BCI, the study of motor imagery has been widely used. In recent years, a classification method based on a convolutional neural network (CNNs) has been proposed. However, most of the existing methods use a single convolution scale on CNN, and another problem that affects the results is limited training data. To solve these problems, we propose a mixed-scale CNN architecture, and a data augmentation method is used to classify the EEG of motor imagery. After classifying the BCI competition IV dataset 2b, the average classification accuracy is 81.52%. Compared with the existing methods, our method has a better classification result. This method effectively solves the problems existing in the existing CNN-based motor imagery classification methods, and it improves the classification accuracy.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
56,Robust Methods to Detect Abnormal Initiation in the Gastric Slow Wave from Cutaneous Recordings,,,225-231,"Agrusa Anjulie S.,Allegra Alexis B.,Kunkel David C.,Coleman Todd P.","Agrusa AS,Allegra AB,Kunkel DC,Coleman TP",Coleman TP,,University of California System,"Upper gastrointestinal (GI) disorders are highly prevalent, with gastroparesis (GP) and functional dyspepsia (FD) affecting 3% and 10% of the US population, respectively. Despite overlapping symptoms, differing etiologies of GP and FD have distinct optimal treatments, thus making their management a challenge. One such cause, that of gastric slow wave abnormalities, affects the electromechanical coordination of pacemaker cells and smooth muscle cells in propelling food through the GI tract. Abnormalities in gastric slow wave initiation location and propagation patterns can be treated with novel pacing technologies but are challenging to identify with traditional spectral analyses from cutaneous recordings due to their occurrence at the normal slow wave frequency. This work advances our previous work in developing a 3D convolutional neural network to process multi-electrode cutaneous recordings and successfully classify, in silico, normal versus abnormal slow wave location and propagation patterns. Here, we use transfer learning to build a method that is robust to heterogeneity in both the location of the abnormal initiation on the stomach surface as well as the recording start times with respect to slow wave cycles. We find that by starting with training lowest-complexity models and building complexity in training sets, transfer learning one model to the next, the final network exhibits, on average, 80% classification accuracy in all but the most challenging spatial abnormality location, and below 5% Type-I error probabilities across all locations.","CHRONIC UNEXPLAINED NAUSEA,INTERSTITIAL-CELLS,ELECTROGASTROGRAPHY,CAJAL,GASTROPARESIS,DYSMOTILITY,PREVALENCE,SYMPTOMS,PATTERNS,AGONIST",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"CHRONIC,UNEXPLAINED,NAUSEA,INTERSTITIAL-CELLS,ELECTROGASTROGRAPHY,CAJAL,GASTROPARESIS,DYSMOTILITY,PREVALENCE,SYMPTOMS,PATTERNS,AGONIST",,,
57,Prediction of Freezing of Gait in Parkinson's Disease from Foot Plantar-Pressure Arrays using a Convolutional Neural Network,,,244-247,"Shalin Gaurav,Pardoel Scott,Nantel Julie,Lemaire Edward D.,Kofman Jonathan","Shalin G,Pardoel S,Nantel J,Lemaire ED,Kofman J",Shalin G,,University of Waterloo,"Freezing of gait (FOG) is a sudden cessation of locomotion in advanced Parkinson's disease (PD). A FOG episode can lead to falls, decreased mobility, and decreased overall quality of life. Prediction of FOG episodes provides an opportunity for intervention and freeze prevention. A novel method of FOG prediction that uses foot plantar pressure data acquired during gait was developed and evaluated, with plantar pressure data treated as 2D images and classified using a convolutional neural network (CNN). Data from five people with PD and a history of FOG were collected during walking trials. FOG instances were identified and data preceding each freeze were labeled as Pre-FOG. Left and right foot FScan pressure frames were concatenated into a single 60x42 pressure array. Each frame was considered as an independent image and classified as Pre-FOG, FOG, or Non-FOG, using the CNN. From prediction models using different Pre-FOG durations, shorter Pre-FOG durations performed best, with Pre-FOG class sensitivity 94.3%, and specificity 95.1%. These results demonstrated that foot pressure distribution alone can be a good FOG predictor when treating each plantar pressure frame as a 2D image, and classifying the images using a CNN. Furthermore, the CNN eliminated the need for feature extraction and selection.","EPISODES,ONSET",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"EPISODES,ONSET",,,
58,MaDeNet: Disentangling Individuality of EEG Signals through Feature Space Mapping and Detachment,,,260-263,"Moon Seong-Eun,Lee Jong-Seok","Moon SE,Lee JS",Moon SE,,Yonsei University,"The cross-subject variability, or individuality, of electroencephalography (EEG) signals often has been an obstacle to extracting target-related information from EEG signals for classification of subjects' perceptual states. In this paper, we propose a deep learning-based EEG classification approach, which learns feature space mapping and performs individuality detachment to reduce subject-related information from EEG signals and maximize classification performance. Our experiment on EEG-based video classification shows that our method significantly improves the classification accuracy.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
59,Robust Classification of Cardiac Arrhythmia Using a Deep Neural Network,,,288-291,"Lennox Connor,Mahmud Md Shaad","Lennox C,Mahmud MS",Lennox C,,University System Of New Hampshire,Machine learning has become increasingly useful in various medical applications. One such case is the automatic categorization of ECG voltage data. A method of categorization is proposed that works in real time to provide fast and accurate classifications of heart beats. This proposed method uses machine learning principles to allow for results to be determined based on a training dataset. The goal of this project is to develop a method of automatically classifying heartbeats that can be done on a low level and run on portable hardware.,,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
60,Arrhythmia Classification using Deep Learning and Machine Learning with Features Extracted from Waveform-based Signal Processing,,,292-295,"Hsu Po-Ya,Cheng Chung-Kuan","Hsu PY,Cheng CK",Hsu PY,,University of California System,"Arrhythmia is a serious cardiovascular disease, and early diagnosis of arrhythmia is critical. In this study, we present a waveform-based signal processing (WBSP) method to produce state-of-the-art performance in arrhythmia classification. When performing WBSP, we first filtered ECG signals, searched local minima, and removed baseline wandering. Subsequently, we fit the processed ECG signals with Gaussians and extracted the parameters. Afterwards, we exploited the products of WBSP to accomplish arrhythmia classification with our proposed machine learning-based and deep learning-based classifiers. We utilized MIT-BIH Arrhythmia Database to validate WBSP. Our best classifier achieved 98.8% accuracy. Moreover, it reached 96.3% sensitivity in class V and 98.6% sensitivity in class Q, which both share one of the best among the related works. In addition, our machine learning-based classifier accomplished identifying four waveform components essential for automated arrhythmia classification: the similarity of QRS complex to a Gaussian curve, the sharpness of the QRS complex, the duration of and the area enclosed by P-wave.","NETWORK,MODEL",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"NETWORK,MODEL",,,
61,Feature matching based ECG generative network for arrhythmia event augmentation,,,296-299,"Cao Fan,Budhota Aamani,Chen Hao,Rajput Kuldeep Singh","Cao F,Budhota A,Chen H,Rajput KS",Cao F,,"Biofourmis Pte Ltd, Vis Exchange, 2 Venture Dr, Singapore 608526, Singapore.","Recent developments in the field of deep learning has shown a rise in its use for clinical applications such as electrocardiogram (ECG) analysis and cardiac arrhythmia classification. Such systems are essential in the early detection and management of cardiovascular diseases. However, due to privacy concerns and also the lack of resources, there is a gap in the data available to run such powerful and data-intensive models. To address the lack of annotated, high-quality ECG data for heart disease research, ECG data generation from a small set of ECG to obtain huge annotated data is seen as an effective solution. Generative Feature Matching Network (GFMN) was shown to resolve few drawbacks of commonly used generative adversarial networks (GAN). Based on this, we developed a deep learning model to generate ECGs that resembles real ECG by feature matching with the existing data.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
62,Interpreting Deep Neural Networks for Single-Lead ECG Arrhythmia Classification,,,300-303,"Vijayarangan Sricharan,Murugesan Balamurali,Vignesh R.,Preejith S. P.,Joseph Jayaraj,Sivaprakasam Mohansankar","Vijayarangan S,Murugesan B,Vignesh R,Preejith SP,Joseph J,Sivaprakasam M",Vijayarangan S,,"Indian Inst Technol IIT M, Healthcare Technol & Innovat Ctr HTIC, Chennai, Tamil Nadu, India.","Cardiac arrhythmia is a prevalent and significant cause of morbidity and mortality among cardiac ailments. Early diagnosis is crucial in providing intervention for patients suffering from cardiac arrhythmia. Traditionally, diagnosis is performed by examination of the Electrocardiogram (ECG) by a cardiologist. This method of diagnosis is hampered by the lack of accessibility to expert cardiologists. For quite some time, signal processing methods had been used to automate arrhythmia diagnosis. However, these traditional methods require expert knowledge and are unable to model a wide range of arrhythmia. Recently, Deep Learning methods have provided solutions to performing arrhythmia diagnosis at scale. However, the black-box nature of these models prohibit clinical interpretation of cardiac arrhythmia. There is a dire need to correlate the obtained model outputs to the corresponding segments of the ECG. To this end, two methods are proposed to provide interpretability to the models. The first method is a novel application of Gradient-weighted Class Activation Map (Grad-CAM) for visualizing the saliency of the CNN model. In the second approach, saliency is derived by learning the input deletion mask for the LSTM model. The visualizations are provided on a model whose competence is established by comparisons against baselines. The results of model saliency not only provide insight into the prediction capability of the model but also aligns with the medical literature for the classification of cardiac arrhythmia.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,http://arxiv.org/pdf/2004.05399,
63,Unsupervised Domain Adaptation for ECG Arrhythmia Classification,,,304-307,"Chen Ming,Wang Guijin,Ding Zijian,Li Jiawei,Yang Huazhong","Chen M,Wang GJ,Ding ZJ,Li JW,Yang HZ",Wang GJ,,Tsinghua University,"Electrocardiograph (ECG) is one of the most critical physiological signals for arrhythmia diagnosis in clinical practice. In recent years, various algorithms based on deep learning have been proposed to solve the heartbeat classification problem and achieved saturated accuracy in intrapatient paradigm, but encountered performance degradation in inter-patient paradigm due to the drastic variation of ECG signals among different individuals. In this paper, we propose a novel unsupervised domain adaptation scheme to address this problem. Specifically, we first propose a robust baseline model called Multi-path Atrous Convolutional Network (MACN) to tackle ECG heartbeat classification. Further, we introduce Cluster-aligning loss and Cluster-separating loss to align the distributions of training and test data and increase the discriminability, respectively. The proposed method requires no expert annotations but a short period of unlabelled data in new records. Experimental results on the MIT-BIH database demonstrate that our scheme effectively intensifies the baseline model and achieves competitive performance with other state-of-the-arts.","CONVOLUTIONAL NEURAL-NETWORK,SYSTEM",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"CONVOLUTIONAL,NEURAL-NETWORK,SYSTEM",,,
64,A faster approach to ECG analysis in emergency situations,,,312-315,"Di Gennaro Marco,Fusco Luigi,Lavore Ian Di Dio,D'Arnese Eleonora,Santambrogio Marco D.","Di Gennaro M,Fusco L,Lavore ID,D'Arnese E,Santambrogio MD",Di Gennaro M,,Polytechnic University of Milan,"Every day, a substantial number of people need to be treated in emergencies and these situations imply a short timeline. Especially concerning heart abnormalities, the time factor is very important. Therefore, we propose a full-stack system for faster and cheaper ECG taking aimed at paramedics, to enhance Emergency Medical Service (EMS) response time. To stick with the golden hour rule, and reduce the cost of the current devices, the system is capable of enabling the detection and annotation of anomalies during ECG acquisition. Our system combines Machine Learning and traditional Signal Processing techniques to analyze ECG tracks to use it in a glove-like wearable. Finally, a graphical interface offers a dynamic view of the whole procedure.","12-LEAD ECG,ELECTRODE,EASI,TIME",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"12-LEAD,ECG,ELECTRODE,EASI,TIME",,,
65,A Novel Approach for Atrial Fibrillation Signal Identification Based on Temporal Attention Mechanism,,,316-319,"Gao Yibo,Wang Huan,Liu Zuhao","Gao YB,Wang H,Liu ZH",Wang H,,University of Electronic Science & Technology of China,"Atrial fibrillation (AF) is a common heart rhythm which occurs when the upper chambers of the heart beat irregularly. With the rapid development of the deep learning algorithm, the Convolutional Neural Networks (CNN) is widely investigated for the ECG classification task. However, for AF detection, the performance of CNN is greatly limited due to the lack of consideration for temporal characteristic of the ECG signal. In order to improve the discriminative ability of CNN, we introduce the attention mechanism to help the network concentrate on the informative parts and obtain the temporal features of the signals. Inspired by this idea, we propose a temporal attention block (TA-block) and a temporal attention convolutional neural network (TA-CNN) for the AF detection tasks. The TA-block can adaptively learn the temporal features of the signal and generate the attention weights to enhance informative features. With a stack architecture of TA-blocks, the TA-CNN obtains better performance as a result of paying more attention to the informative parts of the signal. We validate our approach on the single lead ECG classification dataset of The PhysioNet Computing in Cardiology Challenge 2017. The experimental results indicate that the proposed framework outperform state-of-the-arts classification networks.",ECG CLASSIFICATION,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"ECG,CLASSIFICATION",,,
66,Detection of Premature Ventricular Complexes using Semisupervised Autoencoders and Random Forests,,,337-340,"Kalidas Vignesh,Tamil Lakshman S.","Kalidas V,Tamil LS",Kalidas V,,University of Texas System,"In this paper, we propose a technique for detection of premature ventricular complexes (PVC) based on information obtained from single-lead electrocardiogram (ECG) signals. A combination of semisupervised autoencoders and Random Forests models are used for feature extraction and PVC detection. The ECG signal is first denoised using Stationary Wavelet Transforms and denoising convolutional autoencoders. Following this, PVC classification is performed. Individual ECG beat segments along with features derived from three consecutive beats are used to train a hybrid autoencoder network to learn class-specific beat encodings. These encodings, along with the beat-triplet features, are then input to a Random Forests classifier for final PVC classification. Results: The performance of our algorithm was evaluated on ECG records in the MIT-BIH Arrhythmia Database (MITDB) and the St. Petersburg INCART Database (INCARTDB). Our algorithm achieves a sensitivity of 92.67% and a PPV of 95.58% on the MITDB database. Similarly, a sensitivity of 88.08% and a PPV of 94.76% are achieved on the INCARTDB database.",CLASSIFICATION,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,CLASSIFICATION,,,
67,Adversarial Multi-Task Learning for Robust End-to-End ECG-based Heartbeat Classification,,,341-344,"Shahin Mostafa,Oo Ethan,Ahmed Beena","Shahin M,Oo E,Ahmed B",Shahin M,,University of New South Wales Sydney,"In clinical practice, heart arrhythmias are manually diagnosed by a doctor, which is a time-consuming process. Furthermore, this process is error-prone due to noise from the recording equipment and biological non-idealities of patients. Thus, an automated arrhythmia classifier would be time and cost-effective as well as offer better generalization across patients. In this paper, we propose an adversarial multi-task learning method to improve the generalization of heartbeat arrythmia classification. We built an end-to-end deep neural network (DNN) system consisting of three sub-networks; a generator, a heartbeat-type discriminator, and a subject (or patient) discriminator. Each of these two discriminators had its own loss function to control its impact. The generator was ""friendly"" to the heartbeat-type discrimination task by minimizing its loss function and ""hostile"" to the subject discrimination task by maximizing its loss function. The network was trained using raw ECG signals to discriminate between five types of heartbeats - normal heartbeats, right bundle branch blocks (RBBB), premature ventricular contractions (PVC), paced beats (PB) and fusion of ventricular and normal beats (FVN). The method was tested with the MIT-BIH arrhythmia dataset and achieved a 17% reduction in classification error compared to a baseline using a fully-connected DNN classifier.",ARRHYTHMIA DETECTION,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"ARRHYTHMIA,DETECTION",,,
68,Deep Multi-instance Networks for Bundle Branch Block Detection from Multi-lead ECG,,,353-356,"Hu Jing,Zhao Wei,Jia Dongya,Yan Cong,Wang Hongmei,Li Zhenqi,Fang Jiansheng,Yang Ming","Hu J,Zhao W,Jia DY,Yan C,Wang HM,Li ZQ,Fang JS,Yang M",Hu J,,"CVTE Res, Guangzhou, Peoples R China.","Bundle branch block (BBB) is one of the most common cardiac disorder, and can be detected by electrocardiogram (ECG) signal in clinical practice. Conventional methods adopted some kinds of hand-craft features, whose discriminative power is relatively low. On the other hand, these methods were based on the supervised learning, which required the high cost heartbeat annotation in the training. In this paper, a novel end-to-end deep network was proposed to classify three types of heartbeat: right BBB (RBBB), left BBB (LBBB) and others with a multiple instance learning based training strategy. We trained the proposed method on the China Physiological Signal Challenge 2018 database (CPSC) and tested on the MIT-BIH Arrhythmia database (AR). The proposed method achieved an accuracy of 78.58%, and sensitivity of 84.78% (LBBB), 51.23% (others) and 99.72% (RBBB), better than the baseline methods. Experimental results show that our method would be a good choice for the BBB classification on the ECG dataset with record-level labels instead of heartbeat annotations.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
69,Robust Modelling of Reflectance Pulse Oximetry for SpO(2) Estimation,,,374-377,"Vijayarangan Sricharan,Suresh Prithvi,Preejith S. P.,Joseph Jayaraj,Sivaprakasam Mohansankar","Vijayarangan S,Suresh P,Preejith SP,Joseph J,Sivaprakasam M",Vijayarangan S,,"Indian Inst Technol IIT M, Healthcare Technol & Innovat Ctr HTIC, Chennai, Tamil Nadu, India.","Continuous monitoring of blood oxygen saturation levels is vital for patients with pulmonary disorders. Traditionally, SpO(2) monitoring has been carried out using transmittance pulse oximeters due to its dependability. However, SpO(2) measurement from transmittance pulse oximeters is limited to peripheral regions. This becomes a disadvantage at very low temperatures as blood perfusion to the peripherals decreases. On the other hand, reflectance pulse oximeters can be used at various sites like finger, wrist, chest and forehead. Additionally, reflectance pulse oximeters can be scaled down to affordable patches that do not interfere with the user's diurnal activities. However, accurate SpO(2) estimation from reflectance pulse oximeters is challenging due to its patient dependent, subjective nature of measurement. Recently, a Machine Learning (ML) method was used to model reflectance waveforms onto SpO(2) obtained from transmittance waveforms. However, the generalizability of the model to new patients was not tested. In light of this, the current work implemented multiple ML based approaches which were subsequently found to be incapable of generalizing to new patients. Furthermore, a minimally calibrated data driven approach was utilized in order to obtain SpO(2) from reflectance PPG waveforms. The proposed solution produces an average mean absolute error of 1.81% on unseen patients which is well within the clinically permissible error of 2%. Two statistical tests were conducted to establish the effectiveness of the proposed method.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,http://arxiv.org/pdf/2004.06301,
70,Data Augmentation for Automatic Identification of Spatiotemporal Dispersion Electrograms in Persistent Atrial Fibrillation Ablation Using Machine Learning,,,406-409,"Ghrissi Amina,Almonfrey Douglas,de Almeida Rafael Costa,Squara Fabien,Montagnat Johan,Zarzoso Vicente","Ghrissi A,Almonfrey D,de Almeida RC,Squara F,Montagnat J,Zarzoso V",Ghrissi A,,Centre National de la Recherche Scientifique (CNRS),"Catheter ablation is increasingly used to treat atrial fibrillation (AF), the most common sustained cardiac arrhythmia encountered in clinical practice. A recent breakthrough finding in AF ablation consists in identifying ablation sites based on their spatiotemporal dispersion (STD). STD stands for a delay of the cardiac activation observed in intracardiac electrograms (EGMs) across contiguous leads. In practice, interventional cardiologists localize STD sites visually using the PentaRay multipolar mapping catheter. This work aims at automatically characterizing STD by classifying EGM data into STD vs. non STD groups using machine learning (ML) techniques. A dataset of 23082 multichannel EGM recordings acquired by the PentaRay coming from 16 persistent AF patients is included in this study. A major problem hampering the classification performance lies in the highly imbalanced dataset ratio. We suggest to tackle data imbalance using adapted data augmentation techniques including 1) undersampling 2) oversampling 3) lead shift 4) time reversing and 5) time shift. These tools are designed to preserve the integrity of the cardiac data and are validated by a partner cardiologist. They provide enhancement in classification performance in terms of sensitivity, which increases from 50% to 80% while maintaining accuracy and AUC around 90% with oversampling. Bootstrapping is applied to check the variability of the trained classifiers.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,https://hal.archives-ouvertes.fr/hal-02871770/document,
71,A Weighted Graph Attention Network Based Method for Multi-label Classification of Electrocardiogram Abnormalities,,,418-421,"Wang Hongmei,Zhao Wei,Li Zhenqi,Jia Dongya,Yan Cong,Hu Jing,Fang Jiansheng,Yang Ming","Wang HM,Zhao W,Li ZQ,Jia DY,Yan C,Hu J,Fang JS,Yang M",Wang HM,,"Guangzhou Shiyuan Elect Co Ltd, Cent Res Inst, Guangzhou 510530, Peoples R China.","The multi-label electrocardiogram (ECG) classification is to automatically predict a set of concurrent cardiac abnormalities in an ECG record, which is significant for clinical diagnosis. Modeling the cardiac abnormality dependencies is the key to improving classification performance. To capture the dependencies, we proposed a multi-label classification method based on the weighted graph attention networks. In the study, a graph taking each class as a node was mapped and the class dependencies were represented by the weights of graph edges. A novel weights generation method was proposed by combining the self-attentional weights and the prior learned co-occurrence knowledge of classes. The algorithm was evaluated on the dataset of the Hefei Hi-tech Cup ECG Intelligent Competition for 34 kinds of ECG abnormalities classification. And the micro-f1 and the macro-f1 of cross validation respectively were 91.45% and 44.48%. The experiment results show that the proposed method can model class dependencies and improve classification performance.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
72,Disentangled Adversarial Transfer Learning for Physiological Biosignals,,,422-425,"Han Mo,Ozdenizci Ozan,Wang Ye,Koike-Akino Toshiaki,Erdogmus Deniz","Han M,Ozdenizci O,Wang Y,Koike-Akino T,Erdogmus D",Han M,,Northeastern University,"Recent developments in wearable sensors demonstrate promising results for monitoring physiological status in effective and comfortable ways. One major challenge of physiological status assessment is the problem of transfer learning caused by the domain inconsistency of biosignals across users or different recording sessions from the same user. We propose an adversarial inference approach for transfer learning to extract disentangled nuisance-robust representations from physiological biosignal data in stress status level assessment. We exploit the trade-off between task-related features and person-discriminative information by using both an adversary network and a nuisance network to jointly manipulate and disentangle the learned latent representations by the encoder, which are then input to a discriminative classifier. Results on cross-subjects transfer evaluations demonstrate the benefits of the proposed adversarial framework, and thus show its capabilities to adapt to a broader range of subjects. Finally we highlight that our proposed adversarial transfer learning approach is also applicable to other deep feature learning frameworks.","stress level assessment,physiological biosignals,adversarial networks,transfer learning,deep neural networks,disentangled representation learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,EEG,,http://arxiv.org/pdf/2004.08289,
73,EEG Signal Classification Using Convolutional Neural Networks on Combined Spatial and Temporal Dimensions for BCI Systems,,,434-437,"Anwar Ayman M.,Eldeib Ayman M.","Anwar AM,Eldeib AM",Anwar AM,,Egyptian Knowledge Bank (EKB),"EEG signal classification is an important task to build an accurate Brain Computer Interface (BCI) system. Many machine learning and deep learning approaches have been used to classify EEG signals. Besides, many studies have involved the time and frequency domain features to classify EEG signals. On the other hand, a very limited number of studies combine the spatial and temporal dimensions of the EEG signal. Brain dynamics are very complex across different mental tasks, thus it is difficult to design efficient algorithms with features based on prior knowledge. Therefore, in this study, we utilized the 2D AlexNet Convolutional Neural Network (CNN) to learn EEG features across different mental tasks without prior knowledge. First, this study adds spatial and temporal dimensions of EEG signals to a 2D EEG topographic map. Second, topographic maps at different time indices were cascaded to populate a 2D image for a given time window. Finally, the topographic maps enabled the AlexNet to learn features from the spatial and temporal dimensions of the brain signals. The classification performance was obtained by the proposed method on a multiclass dataset from BCI Competition IV dataset 2a. The proposed system obtained an average classification accuracy of 81.09%, outperforming the previous state-of-the-art methods by a margin of 4% for the same dataset. The results showed that converting the EEG classification problem from a (1D) time series to a (2D) image classification problem improves the classification accuracy for BCI systems. Also, our EEG topographic maps enabled CNN to learn subtle features from spatial and temporal dimensions, which better represent mental tasks than individual time or frequency domain features.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
74,Siamese Neural Networks for EEG-based Brain-computer Interfaces,,,442-446,"Shahtalebi Soroosh,Asif Amir,Mohammadi Arash","Shahtalebi S,Asif A,Mohammadi A",Shahtalebi S,,Concordia University - Canada,"Motivated by the inconceivable capability of human brain in simultaneously processing multi-modal signals and its real-time feedback to the outer world events, there has been a surge of interest in establishing a communication bridge between the human brain and a computer, which are referred to as Brain-computer Interfaces (BCI). To this aim, monitoring the electrical activity of brain through Electroencephalogram (EEG) has emerged as the prime choice for BCI systems. To discover the underlying and specific features of brain signals for different mental tasks, a considerable number of research works are developed based on statistical and data-driven techniques. However, a major bottleneck in development of practical and commercial BCI systems is their limited performance when the number of mental tasks for classification is increased. In this work, we propose a new EEG processing and feature extraction paradigm based on Siamese neural networks, which can be conveniently merged and scaled up for multi-class problems. The idea of Siamese networks is to train a double-input neural network based on a contrastive loss-function, which provides the capability of verifying if two input EEG trials are from the same class or not. In this work, a Siamese architecture, which is developed based on Convolutional Neural Networks (CNN) and provides a binary output on the similarity of two inputs, is combined with One vs. Rest (OVR) and One vs. One (OVO) techniques to scale up for multi-class problems. The efficacy of this architecture is evaluated on a 4-class Motor Imagery (MI) dataset from BCI Competition IV2a and the results suggest a promising performance compared to its counterparts.","Brain-computer Interface,Siamese Networks,Convolutional Neural Network,Electroencephalogram (EEG)",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"MOTOR,IMAGERY,BCI,CLASSIFICATION,PATTERNS,FUTURE",,http://arxiv.org/pdf/2002.00904,
75,Subject-independent Classification on Brain-Computer Interface using Autonomous Deep Learning for finger movement recognition,,,447-450,"Anam Khairul,Bukhori Saiful,Hanggara Faruq Sandi,Pratama Mahardhika","Anam K,Bukhori S,Hanggara FS,Pratama M",Anam K,,Universitas Jember,"The degradation of the subject-independent classification on a brain-computer interface is a challenging issue. One method mostly taken to overcome this problem is by collecting as many subjects as possible and then training the system across all subjects. This article introduces streaming online learning called autonomous deep learning (ADL) to classify five individual fingers based on electroencephalography (EEG) signals to overcome the issue above. ADL is a deep learning architecture that can construct its structure by itself through streaming learning and adapt its structure to the changes occurring in the input. In this article, the input of ADL is a common spatial pattern (CSP) extracted from the EEG signal of healthy subjects. The experimental results on the subject-dependence classification across four subjects using 5-fold cross-validation show that that ADL achieved the classification accuracy of around 77%. This performance was excellent compared to a random forest (RF) and a convolutional neural network (CNN). They achieved accuracies of about 53% and 72%, respectively. On the subject-independent classification, ADL outperforms CNN by resulting stable accuracies for both training and testing, different from CNN that experience accuracy degradation to approximately 50%. These results imply that ADL is a promising machine learning in dealing with the issue in the subject-independent classification.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
76,Localizing Placement of Cardiomechanical Sensors during Dynamic Periods via Template Matching,,,473-476,"Zia Jonathan,Kimball Jacob,Inan Omer T.","Zia J,Kimball J,Inan OT",Zia J,,University System of Georgia,"Captured with a chest-mounted sensor, the seismo-cardiogram (SCG) is a useful signal for assessing cardiomechanical function. However, the reliability of information obtained from this signal often depends upon sensor location. This has important practical implications, as consistent placement is not guaranteed in at-home and other uncontrolled settings. Building on prior research that localized SCG sensor placement when the patient was at rest - which may not be the case in practical settings - this work presents a more robust method which is able to localize sensor placement during dynamic periods, specifically exercise recovery. This was accomplished via a template-based signal quality index (SQI), which was used to infer sensor location using a variety of classifiers. While prior work generated synthetic templates for this task using an averaging method, it is shown that selecting representative templates from the training set instead enables, for the first time, SCG sensor localization during dynamic periods without patient-specific calibration. With this method, a peak accuracy of 83.32% was achieved for correctly classifying sensor position among five tested positions, with avenues for improvement of these results also presented.",SEISMOCARDIOGRAM,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,SEISMOCARDIOGRAM,,,
77,Body Orientation and Vital Sign Measurement With IR-UWB Radar Network,,,485-488,"Yang Xiuzhu,Yu Yibo,Qian Hongyu,Zhang Xinyue,Zhang Lin","Yang XZ,Yu YB,Qian HY,Zhang XY,Zhang L",Yang XZ,,Beijing University of Posts & Telecommunications,"Utilizing Impulse Radio Ultra-WideBand (IR-UWB) radar for vital sign monitoring has attracted growing interest due to the noncontact measurement without privacy concerns. Most of existing researches assume that the subject's chest is directed to the radar antenna, to ensure the strength of backscattered signals from chest movement. However, a large angle between the antenna and the subject's chest caused by the body orientation badly affects the monitoring accuracy. Multiple observations of the same cardiopulmonary activity from different orientations provide more available measurements. This paper addresses the challenge by using an IRUWB radar network instead of a single radar. Three IRUWB radars are placed as endpoints of an equilateral triangle to collect vital sign information of a subject sitting at the center. A Conditional Generative Adversarial Network (CGAN) method is proposed to fuse multisensory data. First, the body orientation is classified by combining signal features and a random forest classifier. Then the impact of different angles on vital sign monitoring results is discussed and validated in each orientation. The data fusion process is modelled as an extended generative network with orientation based condition to produce the enhanced vital signal. This signal is optimized with the discriminator network to a fitted sinusoidal wave with heartbeat and respiratory information. Experimental results on measuring Heartbeat Rate (HR) in different orientations reveal the effectiveness and stability of the proposed method.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
78,A Computationally Efficient Multiclass Time-Frequency Common Spatial Pattern Analysis on EEG Motor Imagery,,,514-518,"Zhang Ce,Eskandarian Azim","Zhang C,Eskandarian A",Zhang C,,Virginia Polytechnic Institute & State University,"Common spatial pattern (CSP) is a popular feature extraction method for electroencephalogram (EEG) motor imagery (MI). This study modifies the conventional CSP algorithm to improve the multi-class MI classification accuracy and ensure the computation process is efficient. The EEG MI data is gathered from the Brain-Computer Interface (BCI) Competition IV. At first, a bandpass filter and a time-frequency analysis are performed for each experiment trial. Then, the optimal EEG signals for every experiment trials are selected based on the signal energy for CSP feature extraction. In the end, the extracted features are classified by three classifiers, linear discriminant analysis (LDA), naive Bayes (NVB), and support vector machine (SVM), in parallel for classification accuracy comparison.
The experiment results show the proposed algorithm average computation time is 37.22% less than the FBCSP (1st winner in the BCI Competition IV) and 4.98% longer than the conventional CSP method. For the classification rate, the proposed algorithm kappa value achieved 2nd highest compared with the top 3 winners in BCI Competition IV.",FILTER,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,FILTER,,http://arxiv.org/pdf/2008.11227,
79,Unsupervised Online Learning for Long-Term High Sensitivity Seizure Detection,,,528-531,"Chua Adelson,Jordan Michael I,Muller Rikky","Chua A,Jordan MI,Muller R",Chua A,,University of California System,"Current seizure detection systems rely on machine learning classifiers that are trained offline and subsequently require manual retraining to maintain high detection accuracy over long periods of time. For a true deploy-and-forget implantable seizure detection system, a low power, at-the-edge, online learning algorithm can be employed to dynamically adapt to the neural signal drifts over time. This work proposes SOUL: Stochastic-gradient-descent-based Online Unsupervised Logistic regression classifier, which provides continuous unsupervised online model updates that was initially trained with labels offline. SOUL was tested on two datasets, the CHB-MIT scalp EEG dataset, and a long (>250 hours) human ECoG dataset from the University of Melbourne. SOUL achieves an average cumulative sensitivity of 97.5% and 97.9% for the two datasets respectively, while maintaining <1.2 false alarms per day. When compared with state-of-the-art, a moderate sensitivity improvement of 1-3% is observed on the majority of subjects and a large sensitivity improvement of >12% is observed on three subjects with <1% impact on specificity.",SYSTEM,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,SYSTEM,,,
80,Epileptic Seizure Detection Using Multi-Channel EEG Wavelet Power Spectra and 1-D Convolutional Neural Networks,,,545-548,"Sharan Roneel V,Berkovsky Shlomo","Sharan RV,Berkovsky S",Sharan RV,,Macquarie University,"The use of feature extraction and selection from EEG signals has shown to be useful in the detection of epileptic seizure segments. However, these traditional methods have more recently been surpassed by deep learning techniques, forgoing the need for complex feature engineering. This work aims to extend the conventional approach of epileptic seizure detection utilizing raw power spectra of EEG signals and convolutional neural networks (CNN). The proposed technique utilizes wavelet transform to compute the frequency characteristics of multi-channel EEG signals. The EEG signals are divided into 2 second epochs and frequency spectrum up to a cutoff frequency of 45 Hz is computed. This multi-channel raw spectral data forms the input to a one-dimensional CNN (1-D CNN). Spectral data from the current, previous, and next epochs is utilized for predicting the label of the current epoch. The performance of the technique is evaluated using a dataset of EEG signals from 24 cases. The proposed method achieves an accuracy of 97.25% in detecting epileptic seizure segments. This result shows that multi-channel EEG wavelet power spectra and 1-D CNN are useful in detecting epileptic seizures.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
81,Neural Memory Networks for Seizure Type Classification,,,569-575,"Ahmedt-Aristizabal David,Fernando Tharindu,Denman Simon,Petersson Lars,Aburn Matthew J.,Fookes Clinton","Ahmedt-Aristizabal D,Fernando T,Denman S,Petersson L,Aburn MJ,Fookes C",Ahmedt-Aristizabal D,,Commonwealth Scientific & Industrial Research Organisation (CSIRO),"Classification of seizure type is a key step in the clinical process for evaluating an individual who presents with seizures. It determines the course of clinical diagnosis and treatment, and its impact stretches beyond the clinical domain to epilepsy research and the development of novel therapies. Automated identification of seizure type may facilitate understanding of the disease, and seizure detection and prediction have been the focus of recent research that has sought to exploit the benefits of machine learning and deep learning architectures. Nevertheless, there is not yet a definitive solution for automating the classification of seizure type, a task that must currently be performed by an expert epileptologist. Inspired by recent advances in neural memory networks (NMNs), we introduce a novel approach for the classification of seizure type using electrophysiological data. We first explore the performance of traditional deep learning techniques which use convolutional and recurrent neural networks, and enhance these architectures by using external memory modules with trainable neural plasticity. We show that our model achieves a state-of-the-art weighted F1 score of 0.945 for seizure type classification on the TUH EEG Seizure Corpus with the IBM TUSZ preprocessed data. This work highlights the potential of neural memory networks to support the field of epilepsy research, along with biomedical research and signal analysis more broadly.","DEEP,SIGNALS",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"DEEP,SIGNALS",,http://arxiv.org/pdf/1912.04968,
82,Emotion assessment using Machine Learning and low-cost wearable devices,,,576-579,"Laureanti R.,Bilucaglia M.,Zito M.,Circi R.,Fici A.,Rivetti E.,Valesi R.,Oldrini C.,Mainardi L. T.,Russo V","Laureanti R,Bilucaglia M,Zito M,Circi R,Fici A,Rivetti E,Valesi R,Oldrini C,Mainardi LT,Russo V",Bilucaglia M,,IULM International University Languages & Media,"The advancement in bioelectrical measurement technologies and the push towards a higher impact of the Brain Computer Interfaces and Affective Computing in the daily life have made non-invasive and low-priced devices available to the large population to record physiological states. The aim of this study is the assessment of the abilities of the MUSE headband, together with the Shimmer GSR+ device, to assess the emotional state of people during stimuli exposure. Twenty-four pictures from the IAPS database were showed to 54 subjects and were evaluated in their emotional values by means of the Self-Assessment Manikin (SAM). Using a Machine Learning approach, fifty-two scalar features were extracted from the signals and used to train 6 binary classifiers to predict the valence and arousal elicited by each stimulus. In all classifiers we obtained accuracies ranging from 53.6% to 69.9%, confirming that these devices are able to give information about the emotional state.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
83,Multi-label Arrhythmia Classification from Fixed-length Compressed ECG Segments in Real-time Wearable ECG Monitoring,,,580-583,"Cheng Yunfei,Ye Yalan,Hou Mengshu,He Wenwen,Pan Tongjie","Cheng YF,Ye YL,Hou MS,He WW,Pan TJ",Ye YL,,University of Electronic Science & Technology of China,"Recently, classification from compressed physiological signals in compressed sensing has been successfully applied to cardiovascular disease monitoring. However, in realtime wearable electrocardiogram (ECG) monitoring, it is very difficult to directly obtain the heartbeats information from compressed ECG signals. Thus arrhythmia classification from compressed ECG signals has to be handled in fixed-length segments instead of individual heartbeats. An inevitable issue is that a fixed-length ECG segment may contain multiple different types of arrhythmia. As a result, it is not appropriate to represent the multi-type real arrhythmia with a single label. In this paper, we first introduce multiple labels into fixed-length compressed ECG segments to challenge the arrhythmia classification issue. Then, we propose a deep learning model, which can directly classify multiple different types of arrhythmia from fixed-length compressed ECG segments with the advantages of low time cost for data processing and relatively high classification accuracy at a high compression ratio. Experimental results on the MIT-BIH arrhythmia database show that the exact match rate of our proposed method has reached 96.03% at CR(Compression Ratio)=70%, 94.99% at CR=80% and 93.19% at CR=90%.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
84,Automatic Sleep Stage Classification using Marginal Hilbert Spectrum Features and a Convolutional Neural Network,,,625-628,"Wang Wenshuai,Liao Pan,Sun Yi,Su Guiping,Ye Shiwei,Liu Yan","Wang WS,Liao P,Sun Y,Su GP,Ye SW,Liu Y",Liu Y,,Chinese Academy of Sciences,"In this paper, we propose a novel method of automatic sleep stage classification based on single-channel electroencephalography (EEG). First, we use marginal Hilbert spectrum (MHS) to depict time-frequency domain features of five sleep stages of 30-second (30s) EEG epochs. Second, the extracted MHSs features are input to a convolutional neural network (CNN) as multi-channel sequences for the sleep stage classification task. Third, a focal loss function is introduced into the CNN classifier to alleviate the classes imbalance problem of sleep data. Experimental results show that the proposed method can obtain an overall accuracy of 86.14% on the public Sleep-EDF dataset, which is competitive and worth exploring among a series of deep learning methods for the automatic sleep stage classification task.","Automatic sleep stage classification,Electroencephalography,Hilbert-Huang transform,Marginal Hilbert spectrum,Convolutional neural network,Deep learning",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
85,Automatic Assessment of Pediatric Sleep Apnea Severity Using Overnight Oximetry and Convolutional Neural Networks,,,633-636,"Vaquerizo-Villar Fernando,Alvarez Daniel,Kheirandish-Gozal Leila,Gutierrez-Tobal Gonzalo C.,Gomez-Pilar Javier,Crespo Andrea,del Campo Felix,Gozal David,Hornero Roberto","Vaquerizo-Villar F,Alvarez D,Kheirandish-Gozal L,Gutierrez-Tobal GC,Gomez-Pilar J,Crespo A,del Campo F,Gozal D,Hornero R",Vaquerizo-Villar F,,Universidad de Valladolid,"In this study, we use the overnight blood oxygen saturation (SpO(2)) signal along with convolutional neural networks (CNN) for the automatic estimation of pediatric sleep apnea-hypopnea syndrome (SAHS) severity. The few preceding studies have focused on the application of conventional feature extraction methods to obtain information from the SpO(2) signal, which may omit relevant data related to the illness. In contrast, deep learning techniques are able to automatically learn features from raw input signal. Thus, we propose to assess whether CNN, a deep learning algorithm, could automatically estimate the apnea-hypopnea index (AHI) from nocturnal oximetry to help establish pediatric SAHS presence and severity. A database of 746 SpO(2) recordings is involved in the study. CNN was trained using 20-min segments from the SpO(2) signal in the training set (400 subjects). Hyperparameters of the CNN architecture were tuned using a validation set (100 subjects). This model was applied to a test set (246 subjects), in which the final AHI of each patient was obtained as the average of the output of the CNN for all the segments of the corresponding SpO2 signal. The AHI estimated by the CNN showed a promising diagnostic performance, with 74.8%, 90.7%, and 95.1% accuracies for the common AHI severity thresholds of 1, 5, and 10 events per hour (e/h), respectively. Furthermore, this model reached 28.6, 32.9, and 120.0 positive likelihood ratios for the above-mentioned AHI thresholds. This suggests that the information extracted from the oximetry signal by deep learning techniques may be useful to both establish pediatric SAHS and its severity.","NOCTURNAL OXIMETRY,ADENOTONSILLECTOMY,CHILDREN,TRIAL",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"NOCTURNAL,OXIMETRY,ADENOTONSILLECTOMY,CHILDREN,TRIAL",,,
86,ECG-Derived Heart Rate Variability Interpolation and 1-D Convolutional Neural Networks for Detecting Sleep Apnea,,,637-640,"Sharan Roneel V,Berkovsky Shlomo,Xiong Hao,Coiera Enrico","Sharan RV,Berkovsky S,Xiong H,Coiera E",Sharan RV,,Macquarie University,"Feature extraction from ECG-derived heart rate variability signal has shown to be useful in classifying sleep apnea. In earlier works, time-domain features, frequency-domain features, and a combination of the two have been used with classifiers such as logistic regression and support vector machines. However, more recently, deep learning techniques have outperformed these conventional feature engineering and classification techniques in various applications. This work explores the use of convolutional neural networks (CNN) for detecting sleep apnea segments. CNN is an image classification technique that has shown robust performance in various signal classification applications. In this work, we use it to classify one-dimensional heart rate variability signal, thereby utilizing a one-dimensional CNN (1-D CNN). The proposed technique resizes the raw heart rate variability data to a common dimension using cubic interpolation and uses it as a direct input to the 1-D CNN, without the need for feature extraction and selection. The performance of the method is evaluated on a dataset of 70 overnight ECG recordings, with 35 recordings used for training the model and 35 for testing. The proposed method achieves an accuracy of 88.23% (AUC=0.9453) in detecting sleep apnea epochs, outperforming several baseline techniques.",ALGORITHM,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,ALGORITHM,,,
87,TinySleepNet: An Efficient Deep Learning Model for Sleep Stage Scoring based on Raw Single-Channel EEG,,,641-644,"Supratak Akara,Guo Yike","Supratak A,Guo YK",Supratak A,,Mahidol University,"Deep learning has become popular for automatic sleep stage scoring due to its capability to extract useful features from raw signals. Most of the existing models, however, have been overengineered to consist of many layers or have introduced additional steps in the processing pipeline, such as converting signals to spectrogram-based images. They require to be trained on a large dataset to prevent the overfitting problem (but most of the sleep datasets contain a limited amount of class-imbalanced data) and are difficult to be applied (as there are many hyperparameters to be configured in the pipeline). In this paper, we propose an efficient deep learning model, named TinySleepNet, and a novel technique to effectively train the model end-to-end for automatic sleep stage scoring based on raw single-channel EEG. Our model consists of a less number of model parameters to be trained compared to the existing ones, requiring a less amount of training data and computational resources. Our training technique incorporates data augmentation that can make our model be more robust the shift along the time axis, and can prevent the model from remembering the sequence of sleep stages. We evaluated our model on seven public sleep datasets that have different characteristics in terms of scoring criteria and recording channels and environments. The results show that, with the same model architecture and the training parameters, our method achieves a similar (or better) performance compared to the state-of-the-art methods on all datasets. This demonstrates that our method can generalize well to the largest number of different datasets.",RESOURCE,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,RESOURCE,,,
88,A normalisation approach improves the performance of inter-subject sEMG-based hand gesture recognition with a ConvNet,,,649-652,"Lin Yuzhou,Palaniappan Ramaswamy,De Wilde Philippe,Li Ling","Lin YZ,Palaniappan R,De Wilde P,Li L",Li L,,University of Kent,"Recently, the subject-specific surface electromyography (sEMG)-based gesture classification with deep learning algorithms has been widely researched. However, it is not practical to obtain the training data by requiring a user to perform hand gestures many times in real life. This problem can be alleviated to a certain extent if sEMG from many other subjects could be used to train the classifier. In this paper, we propose a normalisation approach that allows implementing real-time subject-independent sEMG based hand gesture classification without training the deep learning algorithm subject specifically. We hypothesed that the amplitude ranges of sEMG across channels between forearm muscle contractions for a hand gesture recorded in the same condition do not vary significantly within each individual. Therefore, the min-max normalisation is applied to source domain data but the new maximum and minimum values of each channel used to restrict the amplitude range are calculated from a trial cycle of a new user (target domain) and assigned by the class label. A convolutional neural network (ConvNet) trained with the normalised data achieved an average 87.03% accuracy on our G. dataset (12 gestures) and 94.53% on M. dataset (7 gestures) by using the leave-one-subject-out cross-validation.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,https://kar.kent.ac.uk/83026/1/EMBC2020_LIN.pdf,
89,Genetic Algorithm Application to Feature Selection in sEMG Movement Recognition with Regularized Extreme Learning Machine,,,666-669,"Tosin Mauricio C.,Bagesteiro Leia B.,Balbinot Alexandre","Tosin MC,Bagesteiro LB,Balbinot A",Tosin MC,,Universidade Federal do Rio Grande do Sul,"This paper presents a genetic algorithm (GA) feature selection strategy for sEMG hand-arm movement prediction. The proposed approach evaluates the best feature set for each channel independently. Regularized Extreme Learning Machine was used for the classification stage. The proposed procedure was tested and analyzed applying Ninapro database 2, exercise B. Eleven time domain and two frequency domain metrics were considered in the feature population, totalizing 156 combined feature/channel. As compared to previous studies, our results are promising - 87.7% accuracy was achieved with an average of 43 combined feature/channel selection.","EMG FEATURE,CLASSIFICATION",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"EMG,FEATURE,CLASSIFICATION",,,
90,Analysis and Usage: Subject-to-subject Linear Domain Adaptation in sEMG Classification,,,674-677,"Hoshino Takayuki,Kanoga Suguru,Tsubaki Masashi,Aoyama Atsushi","Hoshino T,Kanoga S,Tsubaki M,Aoyama A",Hoshino T,,National Institute of Advanced Industrial Science & Technology (AIST),"Before the operation of a biosignal-based application, long-duration calibration is required to adjust the pre-trained classifier to a new user data (target data). For reducing such time-consuming step, linear domain adaptation (DA) transfer learning approaches, which transfer pooled data (source data) related to the target data, are highlighted. In the last decade, they have been applied to surface electromyogram (sEMG) data with the implicit assumption that sEMG data are linear. However, sEMGs typically have non-linear characteristics, and due to the discrepancy between the assumption and actual characteristics, linear DA approaches would cause a negative transfer. This study investigated how the correlation between the source and target data affects an 8-class forearm movement classification after applying linear DA approaches. As a result, we found significant positive correlations between the classification accuracy and the source-target correlation. Additionally, the source-target correlation depended on the motion class. Therefore, our results suggest that we should choose a non-linear DA approach when the source-target correlation among subjects or motion classes is low.",SCHEME,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,SCHEME,,,
91,Neuromuscular Disease Detection Employing Deep Feature Extraction from Cross Spectrum Images of Electromyography Signals,,,694-697,"Samanta Kaniska,Roy Sayanjit Singha,Modak Sudip,Chatterjee Soumya,Bose Rohit","Samanta K,Roy SS,Modak S,Chatterjee S,Bose R",Samanta K,,"Techno India Univ, Elect Engn Dept, Kolkata, India.","In this paper, a deep learning framework for detection and classification of EMG signals for diagnosis of neuromuscular disorders is proposed employing cross wavelet transform. Cross wavelet transform which is a modification of continuous wavelet transform is an important tool to analyze any non-stationary signal in time scale and in time-frequency frame. To this end, EMG signals of healthy, myopathy and Amyotrophic lateral sclerosis disorders were procured from an online existing database. A healthy EMG signal was chosen as reference and cross wavelet transform of the rest of the healthy as well as the disease EMG signals was done with the reference. From the resulting cross wavelet spectrum images of EMG signals, a convolution neural network (CNN) based automated deep feature extraction technique was implemented. The extracted deep features were further subjected to feature ranking employing one way analysis of variance (ANOVA) test. The extracted deep features with high degree of statistical significance were fed to several benchmark machine learning classifiers for the purpose of discrimination of EMG signals. Two binary classification problems are addressed in this paper and it has been observed that the highest mean classification accuracy of 100% is achieved using the statistically significant extracted deep features. The proposed method can be implemented for real-time detection of neuromuscular disorders.","Convolution neural network,classification,cross-wavelet transform and electromyography",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
92,Forearm High-Density Electromyography Data Visualization and Classification with Machine Learning for Hand Prosthesis Control,,,722-727,"Tam S.,Boukadoum M.,Campeau-Lecours A.,Gosselin B.","Tam S,Boukadoum M,Campeau-Lecours A,Gosselin B",Tam S,,Laval University,"Electromyography offers a way to interface an amputee's resilient muscles to control a bionic prosthesis. While myoelectric prostheses are promising, user acceptance of these devices remain low due to a lack of intuitiveness and ease-ofuse. Using a low-cost wearable flexible electrodes array, the proposed system leverages high-density surface electromyography (HD-EMG) and deep learning techniques to classify forearm muscle contractions. These techniques allow for increased intuitiveness and ease-of-use of a myoelectric control scheme with a single easy-to-install electrodes apparatus. This paper proposes a flexible electrodes array construction using standard printed circuit board manufacturing processes for lowcost and quick design-to-production cycles. HD-EMG dataset visualization with t-distributed Stochastic Neighbor Embedding (t-SNE) is introduced, and offline classification results of the wearable gesture recognition system for hand prosthesis control are validated on a group of 8 able-bodied subjects. Using a majority vote on 5 successive inferences, a median recognition accuracy of 98.61 % was obtained across the group for an 8 gestures set. For a 6 gestures set containing commonly used prosthesis positions, the median accuracy reached 99.57 % with the majority vote.",OF-THE-ART,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,OF-THE-ART,,,
93,On the Selection of Neural Network Architecture for Supervised Motor Unit Identification from High-Density Surface EMG,,,736-739,"Urh Filip,Strnad Damjan,Clarke Alex,Farina Dario,Holobar Ales","Urh F,Strnad D,Clarke A,Farina D,Holobar A",Urh F,,University of Maribor,"In the last decade, accurate identification of motor unit (MU) firings received a lot of research interest. Different decomposition methods have been developed, each with its advantages and disadvantages. In this study, we evaluated the capability of three different types of neural networks (NNs), namely dense NN, long short-term memory (LSTM) NN and convolutional NN, to identify MU firings from high-density surface electromyograms (HDsEMG). Each type of NN was evaluated on simulated HDsEMG signals with a known MU firing pattern and high variety of MU characteristics. Compared to dense NN, LSTM and convolutional NN yielded significantly higher precision and significantly lower miss rate of MU identification. LSTM NN demonstrated higher sensitivity to noise than convolutional NN.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
94,S-CONVNET: A SHALLOW CONVOLUTIONAL NEURAL NETWORK ARCHITECTURE FOR NEUROMUSCULAR ACTIVITY RECOGNITION USING INSTANTANEOUS HIGH-DENSITY SURFACE EMG IMAGES,,,744-749,"Islam Md. Rabiul,Massicotte Daniel,Nougarou Francois,Massicotte Philippe,Zhu Wei-Ping","Islam MR,Massicotte D,Nougarou F,Massicotte P,Zhu WP",Islam MR,,University of Quebec,"The recent progress in recognizing low-resolution instantaneous high-density surface electromyography (HD-sEMG) images opens up new avenues for the development of more fluid and natural muscle-computer interfaces. However, the existing approaches employed a very large deep convolutional neural network (ConvNet) architecture and complex training schemes for HD-sEMG image recognition, which requires learning of >5.63 million(M) training parameters only during fine-tuning and pre-trained on a very large-scale labeled HD-sEMG training dataset, as a result, it makes high-end resource-bounded and computationally expensive. To overcome this problem, we propose S-ConvNet models, a simple yet efficient framework for learning instantaneous HD-sEMG images from scratch using random-initialization. Without using any pre-trained models, our proposed S-ConvNet demonstrate very competitive recognition accuracy to the more complex state of the art, while reducing learning parameters to only approximate to 2M and using approximate to 12 x smallest dataset. The experimental results proved that the proposed S-ConvNet is highly effective for learning discriminative features for instantaneous HD-sEMG image recognition, especially in the data and high-end resource-constrained scenarios.","Neuromuscular activity recognition,Shallow convolutional neural networks,Feature learning,HD-sEMG,Gesture recognition,Muscle-computer interface,Deep neural networks",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,PROSTHESES,,http://arxiv.org/pdf/1906.03381,
95,Breathing Sound Segmentation and Detection Using Transfer Learning Techniques on an Attention-Based Encoder-Decoder Architecture,,,754-759,"Hsiao Chiu-Han,Lin Ting-Wei,Lin Chii-Wann,Hsu Fu-Shun,Lin Frank Yeong-Sung,Chen Chung-Wei,Chung Chi-Ming","Hsiao CH,Lin TW,Lin CW,Hsu FS,Lin FYS,Chen CW,Chung CM",Hsiao CH,,Academia Sinica - Taiwan,"This paper focuses on the use of an attention-based encoder-decoder model for the task of breathing sound segmentation and detection. This study aims to accurately segment the inspiration and expiration of patients with pulmonary diseases using the proposed model. Spectrograms of the lung sound signals and labels for every time segment were used to train the model. The model would first encode the spectrogram and then detect inspiratory or expiratory sounds using the encoded image on an attention-based decoder. Physicians would be able to make a more precise diagnosis based on the more interpretable outputs with the assistance of the attention mechanism.
The respiratory sounds used for training and testing were recorded from 22 participants using digital stethoscopes or anti-noising microphone sets. Experimental results showed a high 92.006% accuracy when applied 0.5 second time segments and ResNet101 as encoder. Consistent performance of the proposed method can be observed from ten-fold cross-validation experiments.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
96,Lung Sound Classification Using Snapshot Ensemble of Convolutional Neural Networks,,,760-763,"Truc Nguyen,Pernkopf Franz","Nguyen T,Pernkopf F",Nguyen T,,Graz University of Technology,"We propose a robust and efficient lung sound classification system using a snapshot ensemble of convolutional neural networks (CNNs). A robust CNN architecture is used to extract high-level features from log mel spectrograms. The CNN architecture is trained on a cosine cycle learning rate schedule. Capturing the best model of each training cycle allows to obtain multiple models settled on various local optima from cycle to cycle at the cost of training a single mode. Therefore, the snapshot ensemble boosts performance of the proposed system while keeping the drawback of expensive training of ensembles moderate. To deal with the class-imbalance of the dataset, temporal stretching and vocal tract length perturbation (VTLP) for data augmentation and the focal loss objective are used. Empirically, our system outperforms state-of-the-art systems for the prediction task of four classes (normal, crackles, wheezes, and both crackles and wheezes) and two classes (normal and abnormal (i.e. crackles, wheezes, and both crackles and wheezes)) and achieves 78.4% and 83.7% ICBHI specific micro-averaged accuracy, respectively. The average accuracy is repeated on ten random splittings of 80% training and 20% testing data using the ICBHI 2017 dataset of respiratory cycles.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,,
97,Investigating into segmentation methods for diagnosis of respiratory diseases using adventitious respiratory sounds,,,768-771,"Wu Liqun,Li Ling","Wu LQ,Li L",Wu LQ,,University of Kent,"Respiratory condition has received a great amount of attention nowadays since respiratory diseases recently become the globally leading causes of death. Traditionally, stethoscope is applied in early diagnosis but it requires clinician with extensive training experience to provide accurate diagnosis. Accordingly, a subjective and fast diagnosing solution of respiratory diseases is highly demanded. Adventitious respiratory sounds (ARSs), such as crackle, are mainly concerned during diagnosis since they are indication of various respiratory diseases. Therefore, the characteristics of crackle are informative and valuable regarding to develop a computerised approach for pathology-based diagnosis. In this work, we propose a framework combining random forest classifier and Empirical Mode Decomposition (EMD) method focusing on a multi-classification task of identifying subjects in 6 respiratory conditions (healthy, bronchiectasis, bronchiolitis, COPD, pneumonia and URTI). Specifically, 14 combinations of respiratory sound segments were compared and we found segmentation plays an important role in classifying different respiratory conditions. The classifier with best performance (accuracy = 0.88, precision = 0.91, recall = 0.87, specificity = 0.91, F1-score = 0.81) was trained with features extracted from the combination of early inspiratory phase and entire inspiratory phase. To our best knowledge, we are the first to address the challenging multi-classification problem.",,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,,,https://kar.kent.ac.uk/83024/1/09175783.pdf,
98,Predicting Early Stage Drug Induced Parkinsonism using Unsupervised and Supervised Machine Learning,,,776-779,"Nair Parvathy,Trisno Roth,Baghini Maryam Shojaei,Pendharkar Gita,Chung Hoam","Nair P,Trisno R,Baghini MS,Pendharkar G,Chung H",Nair P,,"IITB Monash Res Acad, Mumbai 400076, Maharashtra, India.","Drug Induced Parkinsonism (DIP) is the most common, debilitating movement disorder induced by antipsychotics. There is no tool available in clinical practice to effectively diagnose the symptoms at the onset of the disease. In this study, the variations in gait accelerometer data due to the intermittency of tremor at the initial stages is examined. These variations are used to train a logistic regression model to predict subjects with early-stage DIP. The logistic classifier predicts if a subject is a DIP or control with approximately 89% sensitivity and 96% specificity. This paper discusses the algorithm used to extract the features in gait data for training the classifier to predict DIP at the earliest.",DISEASE,Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,DISEASE,,,
99,Topological Descriptors for Parkinson's Disease Classification and Regression Analysis,,,793-797,"Nawar Afra,Rahman Farhan,Krishnamurthi Narayanan,Som Anirudh,Turaga Pavan","Nawar A,Rahman F,Krishnamurthi N,Som A,Turaga P",Nawar A,,Arizona State University,"At present, the vast majority of human subjects with neurological disease are still diagnosed through in-person assessments and qualitative analysis of patient data. In this paper, we propose to use Topological Data Analysis (TDA) together with machine learning tools to automate the process of Parkinson's disease classification and severity assessment. An automated, stable, and accurate method to evaluate Parkinson's would be significant in streamlining diagnoses of patients and providing families more time for corrective measures. We propose a methodology which incorporates TDA into analyzing Parkinson's disease postural shifts data through the representation of persistence images. Studying the topology of a system has proven to be invariant to small changes in data and has been shown to perform well in discrimination tasks. The contributions of the paper are twofold. We propose a method to 1) classify healthy patients from those afflicted by disease and 2) diagnose the severity of disease. We explore the use of the proposed method in an application involving a Parkinson's disease dataset comprised of health-yelderly, healthy-young and Parkinson's disease patients.","PERSISTENCE,STABILITY,AGE",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"PERSISTENCE,STABILITY,AGE",,http://arxiv.org/pdf/2004.07384,
100,Machine Learning Based Walking Aid Detection in Timed Up-and-Go Test Recordings of Elderly Patients,,,808-811,"Ziegl Andreas,Hayn Dieter,Kastner Peter);,Loeffler Kerstin,Weidinger Lisa,Brix Bianca,Goswami Nandu,Schreier Guenter","Ziegl A,Hayn D,Kastner P,Loffler K,Weidinger L,Brix B,Goswami N,Schreier G",Ziegl A,,Graz University of Technology,"Frailty and falls are the main causes of morbidity and disability in elderly people. The Timed Up-and-Go (TUG) test has been proposed as an appropriate method for evaluating elderly individuals' risk of falling. To analyze the TUG's potential for falls prediction, we conducted a clinical study with participants aged = 65 years, living in nursing homes. We harvested 138 TUG recordings with the information, if patients used a walking aid or not and developed a method to predict the use of walking aids using a Random Forest Classifier for ultrasonic based TUG test recordings. We achieved a high accuracy with an Area Under the Curve (AUC) of 96,9% using a 20% leave out evaluation strategy. Automated collection of structured data from TUG recordings - like the use of a walking aid - may help to improve fall risk tools in future.","FALLS,RISK",Proceedings Paper,"IEEE, 345 E 47TH ST, NEW YORK, NY 10017 USA",Engineering,,,"FALLS,RISK",,,
