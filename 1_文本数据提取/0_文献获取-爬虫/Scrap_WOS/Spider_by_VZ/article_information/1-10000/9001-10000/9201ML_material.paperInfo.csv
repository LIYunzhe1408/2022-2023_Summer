,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Classification of Reflection High-Energy Electron Diffraction Pattern Using Machine Learning,20,8,5289-5293,"Kwoen Jinkwan,Arakawa Yasuhiko","Kwoen J,Arakawa Y",Kwoen J,10.1021/acs.cgd.0c00506,University of Tokyo,"Reflection high-energy electron diffraction (RHEED) has wide application because it allows in situ observation of the sample surface behavior during molecular beam epitaxy growth. In particular, the RHEED pattern has been used as a milestone for growth condition calibration because it dynamically changes depending on the sample temperature, material supply rate, and supply ratio. However, RHEED pattern analysis depends on the accumulated know-how of the operator and has a time limitation; thus, its application to real-time feedback control is difficult. Moreover, with the conventional computerization method, it is difficult to correctly reflect and recognize the changes in RHEED due to changes in the observation conditions. On the other hand, the machine learning method using the convolutional neural network (CNN) recognizes feature points in the input database and is suitable for the classification of images with variability. In this study, we propose a measurement method for identifying the RHEED pattern of GaAs substrates during continuous rotation and build a data set of the growth conditions. A classification model is established by training the deep learning model using CNN, and is found to be more than 99% accurate. This is expected to be useful in the field of highquality III-V growth on GaAs.","GAAS,GROWTH,OSCILLATIONS,SI",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Crystallography,Materials Science",,3.924,"GAAS,GROWTH,OSCILLATIONS,SI",CRYSTAL GROWTH & DESIGN,,
2,Data-Driven Materials Discovery from Large Chemistry Spaces,3,2,327-328,Tanaka Isao,Tanaka I,Tanaka I,10.1016/j.matt.2020.07.010,Kyoto University,"Materials discovery often triggers new technological innovations and is therefore an exciting topic in materials research. In order to search a large chemistry space, however, lengthy trial-and-error testing is required. Recently, a Canadian research team devised a novel representation scheme for perovskite alloys. Combined with machine-learning methods, it enables efficient exploration of a large chemistry space with reasonable accuracy.",,Editorial Material,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,15.589,,MATTER,https://www.cell.com/matter/pdf/S2590-2385(20)30368-4.pdf,
3,AI Applications through the Whole Life Cycle of Material Discovery,3,2,393-432,"Li Jiali,Lim Kaizhuo,Yang Haitao,Ren Zekun,Raghavan Shreyaa,Chen Po-Yen,Buonassisi Tonio,Wang Xiaonan","Li JL,Lim K,Yang HT,Ren ZK,Raghavan S,Chen PY,Buonassisi T,Wang XN",Wang XN,10.1016/j.matt.2020.06.011,National University of Singapore,"We provide a review of machine learning (ML) tools for material discovery and sophisticated applications of different ML strategies. Although there have been a few published reviews on artificial intelligence (AI) for materials with an emphasis on a single material system or individual methods, this paper focuses on an application-based perspective in AI-enhanced material discovery. It shows how AI strategies are applied through material discovery stages (including characterization, property prediction, synthesis, and theory paradigm discovery). Also, by referring to the ML tutorial, readers can acquire a better understanding of the exact functions of ML methods in each application and how these methods work to realize the targets. We are aiming to enable a better integration of AI methods with the material discovery process. The keys to successful applications of AI in material discovery and challenges to be addressed are also highlighted.","NEURAL-NETWORKS,DECISION TREES,MACHINE,DESIGN,REDUCTION,CLASSIFICATION,PREDICTIONS,INSIGHTS,MODEL,EBSD",Review,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,15.589,"NEURAL-NETWORKS,DECISION,TREES,MACHINE,DESIGN,REDUCTION,CLASSIFICATION,PREDICTIONS,INSIGHTS,MODEL,EBSD",MATTER,https://www.cell.com/matter/pdf/S2590-2385(20)30301-5.pdf,
4,Crystal Site Feature Embedding Enables Exploration of Large Chemical Spaces,3,2,433-448,"Choubisa Hitarth,Askerka Mikhail,Ryczko Kevin,Voznyy Oleksandr,Mills Kyle,Tamblyn Isaac,Sargent Edward H.","Choubisa H,Askerka M,Ryczko K,Voznyy O,Mills K,Tamblyn I,Sargent EH",Sargent EH,10.1016/j.matt.2020.04.016,University of Toronto,"Mapping materials science problems onto computational frameworks suitable for machine learning can accelerate materials discovery. Combining proposed crystal site feature embedding (CSFE) representation with convolutional and extensive deep neural networks, we achieve a low mean absolute test error of 3.7 meV/atom and 0.069 eV on density functional theory energies and band gaps of mixed halide perovskites. We explore how a small amount of cadmium doping can potentially be applied in solar cell design and sample the large chemical space by using a variational autoencoder to discover interesting perovskites with band gaps in the ultraviolet and infrared. Additionally, we use CSFE to explore chemical spaces and small doping concentrations beyond those used for training. We further show that CSFE has a mean absolute test error of 7 meV/atom and 0.13 eV for total energies and band gaps for 2D perovskites and discuss its adaptability for exploration of an even wider variety of chemical systems.","NEURAL-NETWORKS,EFFICIENT,PERFORMANCE",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,15.589,"NEURAL-NETWORKS,EFFICIENT,PERFORMANCE",MATTER,http://www.cell.com/article/S2590238520301879/pdf,
5,Classifying the valence of autobiographical memories from fMRI data,88,11-12,1261-1274,"Frid Alex,Manevitz Larry M.,Nawa Norberto Eiji","Frid A,Manevitz LM,Nawa NE",Frid A,10.1007/s10472-020-09705-3,University of Haifa,"We show that fMRI analysis using machine learning tools are sufficient to distinguish valence (i.e., positive or negative) of freely retrieved autobiographical memories in a cross-participant setting. Our methodology uses feature selection (ReliefF) in combination with boosting methods, both applied directly to data represented in voxel space. In previous work using the same data set, Nawa and Ando showed that whole-brain based classification could achieve above-chance classification accuracy only when both training and testing data came from the same individual. In a cross-participant setting, classification results were not statistically significant. Additionally, on average the classification accuracy obtained when using ReliefF is substantially higher than previous results - 81% for the within-participant classification, and 62% for the cross-participant classification. Furthermore, since features are defined in voxel space, it is possible to show brain maps indicating the regions of that are most relevant in determining the results of the classification. Interestingly, the voxels that were selected using the proposed computational pipeline seem to be consistent with current neurophysiological theories regarding the brain regions actively involved in autobiographical memory processes.","Analysis of cognitive processes,Autobiographical memories,Classification,Machine learning,Feature selection",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Mathematics",,1.126,RETRIEVAL,ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE,http://arxiv.org/pdf/1909.04390,
6,A comprehensive hierarchical classification based on multi-features of breast DCE-MRI for cancer diagnosis,58,10,2413-2425,"Liu Hui,Wang Jinke,Gao Jiyue,Liu Shanshan,Liu Xiang,Zhao Zuowei,Guo Dongmei,Dan Guo","Liu H,Wang JK,Gao JY,Liu SS,Liu X,Zhao ZW,Guo DM,Dan G",Liu H,10.1007/s11517-020-02232-7,Dalian University of Technology,"Computer-aided diagnosis (CAD) is widely used for early diagnosis of breast cancer. The commonly used morphological feature (MF), dynamic feature (DF), and texture feature (TF) from breast dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) have been proved very valuable and are studied in this paper. However, previous studies ignored the prior knowledge that most of the benign lesions have clearer and smoother edges than malignant ones. Therefore, two new TFs are proposed. To obtain an optimal feature subset and an accurate classification result, feature selection is applied in this paper. Moreover, most existing CAD models with simple structure only focus on common lesions and ignore hard-to-spot lesions so that a satisfied performance can be obtained for common lesions but there are some contradictions for those hard-to-spot lesions. Therefore, in this paper, a comprehensive hierarchical model is proposed to deal with contradictions and predict all kinds of lesions. The experimental result shows that the new features obviously increase ACC of TF from 0.7788 to 0.8584 and feature selection increases ACC of DF form 0.6991 to 0.7345. More importantly, compared with the existing CAD models and deep learning method, the proposed model which provides a higher performance for both common and hard-to-spot lesions significantly increases the classification performance with sensitivity of 0.9452 and specificity of 0.9000.","Breast cancer,Computer-aided diagnosis,Texture feature,Feature selection,Hierarchical classification model",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"COMPUTER-AIDED,DIAGNOSIS,MASS",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
7,A multi-class skin Cancer classification using deep convolutional neural networks,79,39-40,28477-28498,"Chaturvedi Saket S.,Tembhurne Jitendra V.,Diwan Tausif","Chaturvedi SS,Tembhurne JV,Diwan T",Tembhurne JV,10.1007/s11042-020-09388-2,"Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.","Skin Cancer accounts for one-third of all diagnosed cancers worldwide. The prevalence of skin cancers have been rising over the past decades. In recent years, use of dermoscopy has enhanced the diagnostic capability of skin cancer. The accurate diagnosis of skin cancer is challenging for dermatologists as multiple skin cancer types may appear similar in appearance. The dermatologists have an average accuracy of 62% to 80% in skin cancer diagnosis. The research community has been made significant progress in developing automated tools to assist dermatologists in decision making. In this work, we propose an automated computer-aided diagnosis system for multi-class skin (MCS) cancer classification with an exceptionally high accuracy. The proposed method outperformed both expert dermatologists and contemporary deep learning methods for MCS cancer classification. We performed fine-tuning over seven classes of HAM10000 dataset and conducted a comparative study to analyse the performance of five pre-trained convolutional neural networks (CNNs) and four ensemble models. The maximum accuracy of 93.20% for individual model amongst the set of models whereas maximum accuracy of 92.83% for ensemble model is reported in this paper. We propose use of ResNeXt101 for the MCS cancer classification owing to its optimized architecture and ability to gain higher accuracy.","Skin Cancer,Dermoscopy,Classification,Deep convolutional neural network",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"COMPUTER-AIDED,DIAGNOSIS,ABCD,RULE,MELANOMA,LESIONS,ACCURACY,STRATEGIES,FRAMEWORK",MULTIMEDIA TOOLS AND APPLICATIONS,,
8,Overall Survival Prediction in Glioblastoma With Radiomic Features Using Machine Learning,14,,,"Baid Ujjwal,Rane Swapnil U.,Talbar Sanjay,Gupta Sudeep,Thakur Meenakshi H.,Moiyadi Aliasgar,Mahajan Abhishek","Baid U,Rane SU,Talbar S,Gupta S,Thakur MH,Moiyadi A,Mahajan A",Mahajan A,10.3389/fncom.2020.00061,Homi Bhabha National Institute,"Glioblastoma is a WHO grade IV brain tumor, which leads to poor overall survival (OS) of patients. For precise surgical and treatment planning, OS prediction of glioblastoma (GBM) patients is highly desired by clinicians and oncologists. Radiomic research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, first-order, intensity-based volume and shape-based and textural radiomic features are extracted from fluid-attenuated inversion recovery (FLAIR) and T1ce MRI data. The region of interest is further decomposed with stationary wavelet transform with low-pass and high-pass filtering. Further, radiomic features are extracted on these decomposed images, which helped in acquiring the directional information. The efficiency of the proposed algorithm is evaluated on Brain Tumor Segmentation (BraTS) challenge training, validation, and test datasets. The proposed approach achieved 0.695, 0.571, and 0.558 on BraTS training, validation, and test datasets. The proposed approach secured the third position in BraTS 2018 challenge for the OS prediction task.","brain tumor,glioblastoma,overall survival,radiomic,machine learning",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND","Mathematical & Computational Biology,Neurosciences & Neurology",,2.909,SIGNATURE,FRONTIERS IN COMPUTATIONAL NEUROSCIENCE,https://www.frontiersin.org/articles/10.3389/fncom.2020.00061/pdf,
9,Enhancing the feature representation of multi-modal MRI data by combining multi-view information for MCI classification,400,,322-332,"Liu Jin,Pan Yi,Wu Fang-Xiang,Wang Jianxin","Liu J,Pan Y,Wu FX,Wang JX",Wang JX,10.1016/j.neucom.2020.03.006,Central South University,"The classification of mild cognitive impairment (MCI), which is a early stage of Alzheimer's disease and is associated with brain structural and functional changes, is still a challenging task. Recent studies have shown great promise for improving the performance of MCI classification by combining multiple structural and functional features, such as grey matter volume and clustering coefficient. However, extracting which features and how to combine multiple features to improve the performance of MCI classification have always been challenging problems. To address these problems, in this study we propose a new method to enhance the feature representation of multi-modal MRI data by combining multi-view information to improve the performance of MCI classification. Firstly, we extract two structural features (including grey matter volume and cortical thickness) and two functional features (including clustering coefficient and shortest path length) of each cortical brain region based on automated anatomical labeling (AAL) atlas from both T1w MRI and rs-fMRI data of each subject. Then, in order to obtain features that are more helpful in distinguishing MCI subjects, an improved multi-task feature selection method, namely MTES-gLASSO-TTR, is proposed. Finally, a multi-kernel learning algorithm is adopted to combine multiple features to perform the MCI classification task. Our proposed MCI classification method is evaluated on 315 subjects (including 105 LMCI subjects, 105 EMCI subjects and 105 NCs) with both T1w MRI and rs-fMRI data from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Experimental results show that our proposed method achieves an accuracy of 88.5% and an area under the receiver operating characteristic (ROC) curve (AUC) of 0.897 for LMCl/NC classification, an accuracy of 82.7% and an AUC of 0.832 for EMCl/NC classification, and an accuracy of 79.6% and an AUC of 0.803 for LMCI/EMCI classification, respectively. In addition, by comparison, the accuracy and AUC values of our proposed method are better than those of some existing state-of-the-art methods in MCI classification. Overall, our proposed MCI classification method is effective and promising for automatic diagnosis of MCI in clinical practice. (C) 2020 Elsevier B.V. All rights reserved.","Multi-modal MRI data,Multi-view information,Multi-task feature selection,Multi-kernel learning,MCI classification",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"MILD,COGNITIVE,IMPAIRMENT,FUNCTIONAL,CONNECTIVITY,QUANTITATIVE-ANALYSIS,NETWORK,DISEASE,DIAGNOSIS,REGRESSION,SELECTION,SUPPORT",NEUROCOMPUTING,,
10,Machine learning algorithms for the prediction of the strength of steel rods: an example of data-driven manufacturing in steelmaking,33,9,880-894,"Ruiz Estela,Ferreno Diego,Cuartas Miguel,Lopez Ana,Arroyo Valentin,Gutierrez-Solana Federico","Ruiz E,Ferreno D,Cuartas M,Lopez A,Arroyo V,Gutierrez-Solana F",Ferreno D,10.1080/0951192X.2020.1803505,Universidad de Cantabria,"Analytical models based on physical metallurgy are of limited ability to predict the strength of steel due to the complexities of steelmaking. This paper presents the results obtained using Machine Learning procedures to predict the tensile strength of steel rods manufactured in an electric arc furnace. The available dataset includes 5540 observations (tensile tests) and 97 features (fabrication parameters) monitored during the different stages of the process (electric arc furnace, ladle furnace, continuous casting and hot rolling). The following regression algorithms have been implemented: Multiple Linear Regression, K-Nearest Neighbors, Classification and Regression Tree, three Ensemble Methods (Random Forest, Gradient Boosting and Adaboost) and Artificial Neural Networks. The fine-tuned Random Forest, provided an R(2)of 0.775 and a mean absolute percentage error of 0.76% in the test dataset. After optimization, the Feature Importance and the Permutation Importance algorithms showed that chemical variables have the greater influence on the material strength. The quantitative influence of these variables was represented through Partial Dependence Plots. In short, this research has enabled validating a series of Machine Learning models that provide the necessary information for a correct decision-making to optimize the strength of the steel rods.","Machine learning,steel rod,continuous casting,mechanical strength,random Forest,gradient Boosting,artificial neural network",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,3.076,"CHAINED,EQUATIONS,IMPUTATION,BEHAVIOR,MICROSTRUCTURE,CLASSIFICATION,SELECTION",INTERNATIONAL JOURNAL OF COMPUTER INTEGRATED MANUFACTURING,,
11,Hierarchical severity grade classification of non-proliferative diabetic retinopathy,12,2,2649-2670,"Bhardwaj Charu,Jain Shruti,Sood Meenakshi","Bhardwaj C,Jain S,Sood M",Bhardwaj C,10.1007/s12652-020-02426-9,Jaypee University of Information Technology,"Curability of diabetic retinopathy (DR) abnormalities highly rely on regular monitoring, early-stage diagnosis and timely treatment. Detection and analysis of variation in eye images can help the patient to take the early action before progression of the disease. Vision loss can be effectively prevented by automated diagnostic system that assist the ophthalmologists who otherwise practice manual lesion detection processes which are tedious and time-consuming. This paper proposes a hierarchical severity level grading (HSG) system for the detection and classification of DR ailments. The retinal fundus images in the proposed HSG system are categorized as grade 0 (indicating Non-DR class) and DR severity grades 1, 2, 3 depending upon the number of anomalies; microaneurysms and haemorrhages in the fundus images. The challenge of retinal landmark segmentation, DR retinal discrimination and DR severity grading have been addressed in this work contributing to the novelty of the proposed approach. For non-DR and DR classification, the proposed system achieves an overall accuracy of 98.10% by SVM classifier and 100% by kNN classifier. Hierarchal discrimination into further grades of abnormalities resulted in accuracy values of 95.68% and 92.60% with SVM classifier using Gaussian kernel and, 97.90% and 95.30% employing fine kNN classifier. The HSG system demonstrates a clear improvement in accuracy with significantly less computational time comparative to the other state-of-the-art methods when applied to the MESSIDOR dataset. IDRiD dataset is also evaluated for performance validation of the proposed HSG system yielding a maximum of 94.00% classification accuracy using a kNN classifier with a computational time of 0.67 s.","Diabetic retinopathy,Gray,level co-occurrence matrix features,Statistical features,Support vector machine,k-nearest neighbour",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Telecommunications",,6.163,"FUNDUS,IMAGES,VESSEL,SEGMENTATION,MICROANEURYSMS,DIAGNOSIS,SYSTEM,LEVEL",JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING,,
12,Assistant Diagnosis of Basal Cell Carcinoma and Seborrheic Keratosis in Chinese Population Using Convolutional Neural Network,2020,,,"Huang Kai,He Xiaoyu,Jin Zhentao,Wu Lisha,Zhao Xinyu,Wu Zhe,Wu Xian,Xie Yang,Wan Miaojian,Li Fangfang","Huang K,He XY,Jin ZT,Wu LS,Zhao XY,Wu Z,Wu X,Xie Y,Wan MJ,Li FF",Su J; Zhao S; Chen X,10.1155/2020/1713904,"Hunan Engn Res Ctr Skin Hlth & Dis, Changsha, Hunan, Peoples R China.","Objectives. To evaluate CNN models' performance of identifying the clinical images of basal cell carcinoma (BCC) and seborrheic keratosis (SK) and to compare their performance with that of dermatologists. Methods. We constructed a Chinese skin diseases dataset which includes 1456 BCC and 1843 SK clinical images and the corresponding medical history. We evaluated the performance using four mainstream CNN structures and transfer learning techniques. We explored the interpretability of the CNN model and compared its performance with that of 21 dermatologists. Results. The fine-tuned Inception ResNetV2 achieved the best performance, with an accuracy and area under the curve of 0.855 and 0.919, respectively. Further experimental results suggested that the CNN model was not only interpretable but also had a performance comparable to that of dermatologists. Conclusions. This study is the first on the assistant diagnosis of BCC and SK based on the proposed dataset. The promising results suggested that CNN model's performance was comparable to that of expert dermatologists.","SKIN-CANCER,CLASSIFICATION,CNN",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Health Care Sciences & Services,,3.188,"SKIN-CANCER,CLASSIFICATION,CNN",JOURNAL OF HEALTHCARE ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7422221,
13,Reclassifying neurodegenerative diseases,4,8,759-760,"Villoslada Pablo,Baeza-Yates Ricardo,Masdeu Joseph C.","Villoslada P,Baeza-Yates R,Masdeu JC",Villoslada P,10.1038/s41551-020-0600-3,Stanford University,"Neuropathologies can be classified, on the basis of post-mortem histopathology and by using machine learning, into six transdiagnostic clusters associated with clinical phenotypes.",,Editorial Material,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Engineering,,,,NATURE BIOMEDICAL ENGINEERING,,
14,Defining and predicting transdiagnostic categories of neurodegenerative disease,4,8,787-800,"Cornblath Eli J.,Robinson John L.,Irwin David J.,Lee Edward B.,Lee Virginia M. -Y.,Trojanowski John Q.,Bassett Danielle S.","Cornblath EJ,Robinson JL,Irwin DJ,Lee EB,Lee VMY,Trojanowski JQ,Bassett DS",Bassett DS,10.1038/s41551-020-0593-y,University of Pennsylvania,"Post-mortem histopathological data can be used to classify neuropathologies into six transdiagnostic clusters, and patient membership to these clusters can be predicted from cognitive scores, genotype and protein levels in cerebrospinal fluid.
The prevalence of concomitant proteinopathies and heterogeneous clinical symptoms in neurodegenerative diseases hinders the identification of individuals who might be candidates for a particular intervention. Here, by applying an unsupervised clustering algorithm to post-mortem histopathological data from 895 patients with degeneration in the central nervous system, we show that six non-overlapping disease clusters can simultaneously account for tau neurofibrillary tangles, alpha-synuclein inclusions, neuritic plaques, inclusions of the transcriptional repressor TDP-43, angiopathy, neuron loss and gliosis. We also show that membership to the six transdiagnostic disease clusters, which explains more variance in cognitive phenotypes than can be explained by individual diagnoses, can be accurately predicted from scores of the Mini-Mental Status Exam, protein levels in cerebrospinal fluid, and genotype at theAPOEandMAPTloci, via cross-validated multiple logistic regression. This combination of unsupervised and supervised data-driven tools provides a framework that could be used to identify latent disease subtypes in other areas of medicine.","FRONTOTEMPORAL LOBAR DEGENERATION,ALZHEIMERS ASSOCIATION GUIDELINES,CEREBROSPINAL-FLUID,NATIONAL INSTITUTE,NEUROPATHOLOGIC ASSESSMENT,PARKINSONS-DISEASE,CLUSTER-ANALYSIS,IMAGE-ANALYSIS,TAU PROTEINS,LEWY BODIES",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Engineering,,26.355,"FRONTOTEMPORAL,LOBAR,DEGENERATION,ALZHEIMERS,ASSOCIATION,GUIDELINES,CEREBROSPINAL-FLUID,NATIONAL,INSTITUTE,NEUROPATHOLOGIC,ASSESSMENT,PARKINSONS-DISEASE,CLUSTER-ANALYSIS,IMAGE-ANALYSIS,TAU,PROTEINS,LEWY,BODIES",NATURE BIOMEDICAL ENGINEERING,https://doi.org/10.1101/664250,
15,Using machine learning algorithms to review computed tomography scans and assess risk for cardiovascular disease: Retrospective analysis from the National Lung Screening Trial (NLST),15,8,,"Stemmer Amos,Shadmi Ran,Bregman-Amitai Orna,Chettrit David,Blagev Denitza,Orlovsky Mila,Deutsch Lisa,Elnekave Eldad","Stemmer A,Shadmi R,Bregman-Amitai O,Chettrit D,Blagev D,Orlovsky M,Deutsch L,Elnekave E",Stemmer A,10.1371/journal.pone.0236021,Tel Aviv University,"Background The National Lung Screening Trial (NLST) demonstrated that annual screening with low dose CT in high-risk population was associated with reduction in lung cancer mortality. Nonetheless, the leading cause of mortality in the study was from cardiovascular diseases. Purpose To determine whether the used machine learning automatic algorithms assessing coronary calcium score (CCS), level of liver steatosis and emphysema percentage in the lungs are good predictors of cardiovascular disease (CVD) mortality and incidence when applied on low dose CT scans. Materials and methods Three fully automated machine learning algorithms were used to assess CCS, level of liver steatosis and emphysema percentage in the lung. The algorithms were used on low-dose computed tomography scans acquired from 12,332 participants in NLST. Results In a multivariate analysis, association between the three algorithm scores and CVD mortality have shown an OR of 1.72 (p = 0.003), 2.62 (p < 0.0001) for CCS scores of 101-400 and above 400 respectively, and an OR of 1.12 (p = 0.044) for level of liver steatosis. Similar results were shown for the incidence of CVD, OR of 1.96 (p < 0.0001), 4.94 (p < 0.0001) for CCS scores of 101-400 and above 400 respectively. Also, emphysema percentage demonstrated an OR of 0.89 (p < 0.0001). Similar results are shown for univariate analyses of the algorithms. Conclusion The three automated machine learning algorithms could help physicians to assess the incidence and risk of CVD mortality in this specific population. Application of these algorithms to existing LDCT scans can provide valuable health care information and assist in future research.","CORONARY-ARTERY CALCIUM,MORTALITY,EMPHYSEMA,EVENTS,CANCER,LIVER",Review,"PUBLIC LIBRARY SCIENCE, 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA",Science & Technology - Other Topics,,3.788,"CORONARY-ARTERY,CALCIUM,MORTALITY,EMPHYSEMA,EVENTS,CANCER,LIVER",PLOS ONE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7398499,
16,Reconstruction of highly porous structures from FIB-SEM using a deep neural network trained on synthetic images,281,1,16-27,"Fend C.,Moghiseh A.,Redenbach C.,Schladitz K.","Fend C,Moghiseh A,Redenbach C,Schladitz K",Schladitz K,10.1111/jmi.12944,"Fraunhofer Intitut Techno & Wirtschaftsmath, Image Proc, D-67663 Kaiserslautern, Germany.","Combining scanning electron microscopy with serial slicing by a focused ion beam yields spatial image data of materials structures at the nanometer scale. However, the depth of field of the scanning electron microscopic images causes unwanted effects when highly porous structures are imaged. Proper spatial reconstruction of such porous structures from the stack of microscopic images is a tough and in general yet unsolved segmentation problem. Recently, machine learning methods have proven to yield solutions to a variety of image segmentation problems. However, their use is hindered by the need of large amounts of annotated data in the training phase. Here, we therefore replace annotated real image data by simulated image stacks of synthetic structures - realizations of stochastic germ-grain models and random packings. This strategy yields the annotations for free, but shifts the effort to choosing appropriate stochastic geometry models and generating sufficiently realistic scanning electron microscopic images.","Altendorf-Jeulin fibre model,Boolean model,Cox-Boolean model,random packing,SEM simulation,shine through artefacts,U-net 3D",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Microscopy,,1.855,"SEGMENTATION,ALGORITHMS,SIMULATION,DESIGN",JOURNAL OF MICROSCOPY,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/jmi.12944,
17,Flood forecasting based on an artificial neural network scheme,104,2,1211-1237,"Dtissibe Francis Yongwa,Ari Ado Adamou Abba,Titouna Chafiq,Thiare Ousmane,Gueroui Abdelhak Mourad","Dtissibe FY,Ari AAA,Titouna C,Thiare O,Gueroui AM",Ari AAA,10.1007/s11069-020-04211-5,Universite Paris Saclay,"Nowadays, floods have become the widest global environmental and economic hazard in many countries, causing huge loss of lives and materials damages. It is, therefore, necessary to build an efficient flood forecasting system. The physical-based flood forecasting methods have indeed proven to be limited and ineffective. In most cases, they are only applicable under certain conditions. Indeed, some methods do not take into account all the parameters involved in the flood modeling, and these parameters can vary along a channel, which results in obtaining forecasted discharges very different from observed discharges. While using machine learning tools, especially artificial neural networks schemes appears to be an alternative. However, the performance of forecasting models, as well as a minimum error of prediction, is very interesting and challenging issues. In this paper, we used the multilayer perceptron in order to design a flood forecasting model and used discharge as input-output variables. The designed model has been tested upon intensive experiments and the results showed the effectiveness of our proposal with a good forecasting capacity.","Flood forecasting,Artificial neural networks,Multilayer perceptron,Machine learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Geology,Meteorology & Atmospheric Sciences,Water Resources",,3.656,"MODEL,CALIBRATION,RAINFALL",NATURAL HAZARDS,,
18,Understanding Personality through Patterns of Daily Socializing: Applying Recurrence Quantification Analysis to Naturalistically Observed Intensive Longitudinal Social Interaction Data,34,5,777-793,"Danvers Alexander F.,Sbarra David A.,Mehl Matthias R.","Danvers AF,Sbarra DA,Mehl MR",Danvers AF,10.1002/per.2282,University of Arizona,"Ambulatory assessment methods provide a rich approach for studying daily behaviour. Too often, however, these data are analysed in terms of averages, neglecting patterning of this behaviour over time. This paper describes recurrence quantification analysis (RQA), a non-linear time series technique for analysing dynamic systems, as a method for analysing patterns of categorical, intensive longitudinal ambulatory assessment data. We apply RQA to objectively assessed social behaviour (e.g. talking to another person) coded from the Electronically Activated Recorder. Conceptual interpretations of RQA parameters, and an analysis of Electronically Activated Recorder data in adults going through a marital separation, are provided. Using machine learning techniques to avoid model overfitting, we find that adding RQA parameters to models that include just average amount of time spent talking (a static measure) improves prediction of four Big Five personality traits: extraversion, neuroticism, conscientiousness, and openness. Our strongest results suggest that a combination of average amount of time spent talking and four RQA parameters yield anR(2) = .09 for neuroticism. Neuroticism is shown to be associated with shorter periods of extended conversation (periods of at least 12 minutes), demonstrating the utility of RQA to identify new relationships between personality and patterns of daily behaviour. Materials: . (c) 2020 European Association of Personality Psychology","social interaction,ambulatory assessment,dynamic systems,electronically activated recorder,personality",Article,"JOHN WILEY & SONS LTD, THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND",Psychology,,6.61,"AFFECTIVE,DYNAMICS,CROSS-RECURRENCE,MANIFESTATIONS",EUROPEAN JOURNAL OF PERSONALITY,,
19,Subphenotyping depression using machine learning and electronic health records,4,4,,"Xu Zhenxing,Wang Fei,Adekkanattu Prakash,Bose Budhaditya,Vekaria Veer,Brandt Pascal,Jiang Guoqian,Kiefer Richard C.,Luo Yuan,Pacheco Jennifer A.","Xu ZX,Wang F,Adekkanattu P,Bose B,Vekaria V,Brandt P,Jiang GQ,Kiefer RC,Luo Y,Pacheco JA",Pathak J,10.1002/lrh2.10241,Cornell University,"Objective: To identify depression subphenotypes from Electronic Health Records (EHRs) using machine learning methods, and analyze their characteristics with respect to patient demographics, comorbidities, and medications.
Materials and Methods: Using EHRs from the INSIGHT Clinical Research Network (CRN) database, multiple machine learning (ML) algorithms were applied to analyze 11 275 patients with depression to discern depression subphenotypes with distinct characteristics.
Results: Using the computational approaches, we derived three depression subphenotypes: Phenotype_A (n = 2791; 31.35%) included patients who were the oldest (mean (SD) age, 72.55 (14.93) years), had the most comorbidities, and took the most medications. The most common comorbidities in this cluster of patients were hyperlipidemia, hypertension, and diabetes. Phenotype_B (mean (SD) age, 68.44 (19.09) years) was the largest cluster (n = 4687; 52.65%), and included patients suffering from moderate loss of body function. Asthma, fibromyalgia, and Chronic Pain and Fatigue (CPF) were common comorbidities in this subphenotype. Phenotype_C (n = 1452; 16.31%) included patients who were younger (mean (SD) age, 63.47 (18.81) years), had the fewest comorbidities, and took fewer medications. Anxiety and tobacco use were common comorbidities in this subphenotype.
Conclusion: Computationally deriving depression subtypes can provide meaningful insights and improve understanding of depression as a heterogeneous disorder. Further investigation is needed to assess the utility of these derived phenotypes to inform clinical trial design and interpretation in routine patient care.","depression,electronic health records,machine learning,phenotyping",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Health Care Sciences & Services,,,"POPULATION,DIAGNOSIS,RISK,BIOMARKERS,SYMPTOMS,DISORDER,ANXIETY,TOBACCO,NUMBER,IMPACT",LEARNING HEALTH SYSTEMS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7556423,
20,Computer-assisted skin cancer diagnosis Is it time for artificial intelligence in clinical practice?,71,9,669-676,"Brinker T. J.,Schlager G.,French L. E.,Jutzi T.,Kittler H.","Brinker TJ,Schlager G,French LE,Jutzi T,Kittler H",Brinker TJ,10.1007/s00105-020-04662-8,Helmholtz Association,"Background Artificial intelligence (AI) is increasingly being used in medical practice. Especially in the image-based diagnosis of skin cancer, AI shows great potential. However, there is a significant discrepancy between expectations and true relevance of AI in current dermatological practice. Objectives This article summarizes promising study results of skin cancer diagnosis by computer-based diagnostic systems and discusses their significance for daily practice. We hereby focus on the analysis of dermoscopic images of pigmented and unpigmented skin lesions. Materials and methods A selective literature search for recent relevant trials was conducted. The included studies used machine learning, and in particular ""convolutional neural networks"", which have been shown to be particularly effective for the classification of image data. Results and conclusions In numerous studies, computer algorithms were able to detect pigmented and nonpigmented neoplasms of the skin with high precision, comparable to that of dermatologists. The combination of the physician's assessment and AI showed the best results. Computer-based diagnostic systems are widely accepted among patients and physicians. However, they are still not applicable in daily practice, since computer-based diagnostic systems have only been tested in an experimental environment. In addition, many digital diagnostic criteria that help AI to classify skin lesions remain unclear. This lack of transparency still needs to be addressed. Moreover, clinical studies on the use of AI-based assistance systems are needed in order to prove its applicability in daily dermatologic practice.","Machine learning,Dermoscopy,Computer-assisted diagnosis,Suspicious lesions,Computer algorithms",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Dermatology,,0.748,"CONVOLUTIONAL,NEURAL-NETWORK,IMAGE,CLASSIFICATION,DERMATOLOGISTS,PERFORMANCE,SUPERIOR",HAUTARZT,,
21,Application of Life Cycle Assessment and Machine Learning for High-Throughput Screening of Green Chemical Substitutes,8,30,11141-11151,"Zhu Xinzhe,Ho Chi-Hung,Wang Xiaonan","Zhu XZ,Ho CH,Wang XN",Wang XN,10.1021/acssuschemeng.0c02211,National University of Singapore,"The production process of many active pharmaceutical ingredients such as sitagliptin could cause severe environmental problems because of the use of toxic chemical materials and production infrastructure, energy consumption, and waste treatment. The environmental impacts of the sitagliptin production process were estimated with a life cycle assessment (LCA) method, which suggested that the use of chemical materials provided the major environmental impacts. Both methods of Eco-indicator 99 and ReCiPe endpoint confirmed that chemical feedstock accounted for 83% and 70% of life-cycle impact, respectively. Among all the chemical materials used in the sitagliptin production process, trifluoroacetic anhydride was identified as the largest influential factor in most impact categories according to the results of the ReCiPe midpoints' method. Therefore, high-throughput screening was performed to seek for greener chemical substitutes to replace the target chemical (i.e., trifluoroacetic anhydride) by the following three steps. First, the 30 most similar chemicals were obtained from 2 million candidate alternatives in the PubChem database on the basis of their molecular descriptors. Thereafter, deep learning neural network models were developed to predict life-cycle impact according to the chemicals in Ecoinvent v3.5 database with known LCA values and corresponding molecular descriptors. Finally, 1,2-ethanediyl ester was proved to be one of the potential greener substitutes after the LCA data of these similar chemicals were predicted using the well-trained machine learning models. The case study demonstrated the applicability of the novel framework to screen green chemical substitutes and optimize the pharmaceutical manufacturing process.","Machine learning,Life cycle assessment,Green chemistry,High-throughput screening,Pharmaceutical manufacturing process",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Engineering",,8.471,"MOLECULAR-STRUCTURE,OPTIMIZATION,CHEMISTRY,CLASSIFICATION,MIDPOINT,TOOL",ACS SUSTAINABLE CHEMISTRY & ENGINEERING,,
22,Environment-Resilient Graphene Vibrotactile Sensitive Sensors for Machine Intelligence,2,8,986-992,"Yao Haicheng,Li Pengju,Cheng Wen,Yang Weidong,Yang Zijie,Ali Hashina Parveen Anwar,Guo Hongchen,Tee Benjamin C. K.","Yao HC,Li PJ,Cheng W,Yang WD,Yang ZJ,Ali HPA,Guo HC,Tee BCK",Tee BCK,10.1021/acsmaterialslett.0c00160,National University of Singapore,"Skin-like sensors that transduce tactile pressures and vibrations with minimal environment variation on performance are crucial in robotic sensing and prosthetic skins. However, sensor performance variations under varying environmental conditions, such as temperature and humidity, are common in piezoresistive sensors because of their intrinsic materials properties. Moreover, the viscoelasticity of soft elastomers causes strain response in a time-dependent fashion, which poses sensor limitations in high-frequency tactile tasks, such as texture recognition. In this work, we demonstrate a new environment-robust tactile sensor via an interfacial engineering process for uniform graphene coating on microstructured elastomers. The sensor enables reliable pressure response over a range of temperature (25-60 degrees C) and humidity (30-90% relative humidity) conditions, with resistance variations less than 5% and 3%, respectively. It is also able to detect vibrations with frequency up to 1500 Hz. Moreover, our sensor shows ultra-high durability, with high sensitivity and low hysteresis preserved after 1 million cycles. We demonstrate applications with the sensor in epidermal signal monitoring at different arteries, as well as accurate (>95%) surface texture recognition in combination with machine learning.","FLEXIBLE PRESSURE SENSORS,COEFFICIENT,FILMS,SKIN",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Materials Science,,8.323,"FLEXIBLE,PRESSURE,SENSORS,COEFFICIENT,FILMS,SKIN",ACS MATERIALS LETTERS,,
23,A computer vision approach for classifying isometric grip force exertion levels,63,8,1010-1026,"Asadi Hamed,Zhou Guoyang,Lee Jae Joong,Aggarwal Vaneet,Yu Denny","Asadi H,Zhou GY,Lee JJ,Aggarwal V,Yu D",Yu D,10.1080/00140139.2020.1745898,Purdue University System,"Exposure to high and/or repetitive force exertions can lead to musculoskeletal injuries. However, measuring worker force exertion levels is challenging, and existing techniques can be intrusive, interfere with human-machine interface, and/or limited by subjectivity. In this work, computer vision techniques are developed to detect isometric grip exertions using facial videos and wearable photoplethysmogram. Eighteen participants (19-24 years) performed isometric grip exertions at varying levels of maximum voluntary contraction. Novel features that predict forces were identified and extracted from video and photoplethysmogram data. Two experiments with two (High/Low) and three (0%MVC/50%MVC/100%MVC) labels were performed to classify exertions. The Deep Neural Network classifier performed the best with 96% and 87% accuracy for two- and three-level classifications, respectively. This approach was robust to leave subjects out during cross-validation (86% accuracy when 3-subjects were left out) and robust to noise (i.e. 89% accuracy for correctly classifying talking activities as low force exertions). Practitioner summary: Forceful exertions are contributing factors to musculoskeletal injuries, yet it remains difficult to measure in work environments. This paper presents an approach to estimate force exertion levels, which is less distracting to workers, easier to implement by practitioners, and could potentially be used in a wide variety of workplaces.","Computer vision,high force exertions,facial expressions,machine learning",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Engineering,Psychology",,3.053,"MUSCULOSKELETAL,DISORDERS,PULL,STRENGTH,STRAIN,INDEX,RISK-FACTORS,WORK,TASK,PRESSURE,SHOULDER,POSTURE,SAFETY",ERGONOMICS,,
24,Cutting Tool Failure and Surface Finish Analysis in Pulsating MQL-Assisted Hard Turning,20,4,1274-1291,"Roy Soumikh,Kumar Ramanuj,Sahoo Ashok Kumar,Panda Amlana","Roy S,Kumar R,Sahoo AK,Panda A",Kumar R,10.1007/s11668-020-00940-8,Kalinga Institute of Industrial Technology (KIIT),"Current work emphasized the cutting tool failure, surface roughness, surface topology and chip morphology analysis in hard turning of AISI 4340 steel under a novel pulsating MQL cooling/lubricating circumstance. Pulsating MQL is a newer cooling strategy through which lubricant is supplied into cutting region by time-controlled pulse mode. Al(2)O(3)top-layered coated carbide tool is utilized to furnish the turning task. Tool failure analysis is carried out considering principal flank wear and auxiliary flank wear. Principal flank wear is traced to be lower than the standard limit of 0.2 mm with the maximum surface roughness of 0.99 mu m. Abrasion mechanism is the prime cause for the formation of principle flank wear in each test. Auxiliary flank wear majorly influences the dimensional error and surface quality of the turned surface. Cutting speed as well as depth of cut is the significant and impactful term toward principal and auxiliary flank wears. Feed trailed by the depth of cut and cutting speed are the significant terms toward surface roughness. Helical or ribbon pattern of chips is noticed during the test. The feed is the uppermost term which influences the chip reduction coefficient. Further, neural network modeling has been accomplished to simulate the output response data. Two different training algorithms, namely BFGS quasi-Newton (trainbfg) and Levenberg-Marquardt (trainlm), are utilized for the modeling. Three different architectures like 4-4-1, 4-5-1 and 4-8-1 have been considered to simulate the outputs. Levenberg-Marquardt (trainlm) algorithm attributed the smaller absolute percentage mean error (APME) value relative to BFGS quasi-Newton (trainbfg) algorithm. Neural network architecture 4-8-1 withtrainlmalgorithm exhibited the least values of APME and largest R-square for principal and auxiliary flank wears, while architecture 4-4-1 withtrainlmalgorithm exhibited the least values of APME and largest R-square for surface roughness.","Hard turning,Pulsating MQL,Principal flank wear,Auxiliary flank wear,Surface roughness,Neural network modeling",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Engineering,,,"AISI,4340,STEEL,VEGETABLE-OIL,MINIMUM,QUANTITY,COOLING,TECHNIQUES,CARBIDE,INSERTS,ROUGHNESS,MACHINABILITY,LUBRICATION,PERFORMANCE,DRY",JOURNAL OF FAILURE ANALYSIS AND PREVENTION,,
25,CT-based multi-organ segmentation using a 3D self-attention U-net network for pancreatic radiotherapy,47,9,4316-4324,"Liu Yingzi,Lei Yang,Fu Yabo,Wang Tonghe,Tang Xiangyang,Jiang Xiaojun,Curran Walter J.,Liu Tian,Patel Pretesh,Yang Xiaofeng","Liu YZ,Lei Y,Fu YB,Wang TH,Tang XY,Jiang XJ,Curran WJ,Liu T,Patel P,Yang XF",Yang XF,10.1002/mp.14386,Emory University,"Purpose Segmentation of organs-at-risk (OARs) is a weak link in radiotherapeutic treatment planning process because the manual contouring action is labor-intensive and time-consuming. This work aimed to develop a deep learning-based method for rapid and accurate pancreatic multi-organ segmentation that can expedite the treatment planning process. Methods We retrospectively investigated one hundred patients with computed tomography (CT) simulation scanned and contours delineated. Eight OARs including large bowel, small bowel, duodenum, left kidney, right kidney, liver, spinal cord and stomach were the target organs to be segmented. The proposed three-dimensional (3D) deep attention U-Net is featured with a deep attention strategy to effectively differentiate multiple organs. Performance of the proposed method was evaluated using six metrics, including Dice similarity coefficient (DSC), sensitivity, specificity, Hausdorff distance 95% (HD95), mean surface distance (MSD) and residual mean square distance (RMSD). Results The contours generated by the proposed method closely resemble the ground-truth manual contours, as evidenced by encouraging quantitative results in terms of DSC, sensitivity, specificity, HD95, MSD and RMSD. For DSC, mean values of 0.91 +/- 0.03, 0.89 +/- 0.06, 0.86 +/- 0.06, 0.95 +/- 0.02, 0.95 +/- 0.02, 0.96 +/- 0.01, 0.87 +/- 0.05 and 0.93 +/- 0.03 were achieved for large bowel, small bowel, duodenum, left kidney, right kidney, liver, spinal cord and stomach, respectively. Conclusions The proposed method could significantly expedite the treatment planning process by rapidly segmenting multiple OARs. The method could potentially be used in pancreatic adaptive radiotherapy to increase dose delivery accuracy and minimize gastrointestinal toxicity.","adaptive radiotherapy,multi-organ segmentation,pancreatic radiotherapy,treatment planning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"CANCER,AUTOENCODERS,ATLAS,SBRT",MEDICAL PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8278307,
26,Deep Learning for Classification and Localization of COVID-19 Markers in Point-of-Care Lung Ultrasound,39,8,2676-2687,"Roy Subhankar,Menapace Willi,Oei Sebastiaan,Luijten Ben,Fini Enrico,Saltori Cristiano,Huijben Iris,Chennakeshava Nishith,Mento Federico,Sentelli Alessandro","Roy S,Menapace W,Oei S,Luijten B,Fini E,Saltori C,Huijben I,Chennakeshava N,Mento F,Sentelli A",Demi L,10.1109/TMI.2020.2994459,University of Trento,"Deep learning (DL) has proved successful in medical imaging and, in the wake of the recent COVID-19 pandemic, some works have started to investigate DL-based solutions for the assisted diagnosis of lung diseases. While existing works focus on CT scans, this paper studies the application of DL techniques for the analysis of lung ultrasonography (LUS) images. Specifically, we present a novel fully-annotated dataset of LUS images collected from several Italian hospitals, with labels indicating the degree of disease severity at a frame-level, video-level, and pixel-level (segmentation masks). Leveraging these data, we introduce several deep models that address relevant tasks for the automatic analysis of LUS images. In particular, we present a novel deep network, derived from Spatial Transformer Networks, which simultaneously predicts the disease severity score associated to a input frame and provides localization of pathological artefacts in a weakly-supervised way. Furthermore, we introduce a new method based on uninorms for effective frame score aggregation at a video-level. Finally, we benchmark state of the art deep models for estimating pixel-level segmentations of COVID-19 imaging biomarkers. Experiments on the proposed dataset demonstrate satisfactory results on all the considered tasks, paving the way to future research on DL for the assisted diagnosis of COVID-19 from LUS data.","Image segmentation,Lung,Ultrasonic imaging,Task analysis,Pathology,Imaging,Diseases,COVID-19,COVID-19,lung ultrasound,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,https://ieeexplore.ieee.org/ielx7/42/9153182/09093068.pdf,
27,Measuring Optical Parameters gamma of Biological Tissues by Artificial Neural Network Method,49,8,,"Zhu Qiu-sheng,Liu Ying","Zhu QS,Liu Y",Zhu QS,10.3788/gzxb20204908.0817001,Tianjin University,"An artificial neural network method is proposed for estimating reduced scattering coefficient mu(')(s) and phase function parameter gamma of biological tissues from spatially resolved reflectance profiles in the sub-diffusive regime. Monte Carlo simulation method is used to obtain data samples of diffuse reflection from biological tissues. These data samples are used to train back-propagation neural network get the information of gamma predicted from the sub-diffused scattered light. Since there is a large error occurs when predicting mu(')(s) and gamma simultaneously, the segmenting data train of two back-propagation networks is performed to identify the mu(')(s) and gamma in turn. It is found that 3.64lth (lth representing the average transport free path) is an insensitive points of gamma. The network trained with data samples near this point is used for predicting mu(')(s), while the network trained with data samples in the 2lth is used for predicting gamma. Monte Carlo simulation result show that within the range 1.3 <= gamma <= 1.9, relative root mean square error between the predicted result and the true value is within 1%. Compared with the existing measurement methods, the proposed method is simpler and has improved accuracy.","Tissue optics,Sub-diffuse scattering,Monte Carlo simulation,Higher-order optical parameters,Artificial neural network",Article,"SCIENCE PRESS, 300 WEST CHESNUT ST, EPHRATA, PA 17522 USA",Optics,,,"SPATIALLY-RESOLVED,REFLECTANCE,EFFICIENT,ESTIMATION,LIGHT-SCATTERING,MONTE-CARLO,TRANSPORT",ACTA PHOTONICA SINICA,,
28,Efficient Deep Learning Architecture for Detection and Recognition of Thyroid Nodules,2020,,,"Ma Jingzhe,Duan Shaobo,Zhang Ye,Wang Jing,Wang Zongmin,Li Runzhi,Li Yongli,Zhang Lianzhong,Ma Huimin","Ma JZ,Duan SB,Zhang Y,Wang J,Wang ZM,Li RZ,Li YL,Zhang LZ,Ma HM",Li RZ,10.1155/2020/1242781,Zhengzhou University,"Ultrasonography is widely used in the clinical diagnosis of thyroid nodules. Ultrasound images of thyroid nodules have different appearances, interior features, and blurred borders that are difficult for a physician to diagnose into malignant or benign types merely through visual recognition. The development of artificial intelligence, especially deep learning, has led to great advances in the field of medical image diagnosis. However, there are some challenges to achieve precision and efficiency in the recognition of thyroid nodules. In this work, we propose a deep learning architecture, you only look once v3 dense multireceptive fields convolutional neural network (YOLOv3-DMRF), based on YOLOv3. It comprises a DMRF-CNN and multiscale detection layers. In DMRF-CNN, we integrate dilated convolution with different dilation rates to continue passing the edge and the texture features to deeper layers. Two different scale detection layers are deployed to recognize the different sizes of the thyroid nodules. We used two datasets to train and evaluate the YOLOv3-DMRF during the experiments. One dataset includes 699 original ultrasound images of thyroid nodules collected from a local health physical center. We obtained 10,485 images after data augmentation. Another dataset is an open-access dataset that includes ultrasound images of 111 malignant and 41 benign thyroid nodules. Average precision (AP) and mean average precision (mAP) are used as the metrics for quantitative and qualitative evaluations. We compared the proposed YOLOv3-DMRF with some state-of-the-art deep learning networks. The experimental results show that YOLOv3-DMRF outperforms others on mAP and detection time on both the datasets. Specifically, the values of mAP and detection time were 90.05 and 95.23% and 3.7 and 2.2 s, respectively, on the two test datasets. Experimental results demonstrate that the proposed YOLOv3-DMRF is efficient for detection and recognition of thyroid nodules for ultrasound images.",CARCINOMA,Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Mathematical & Computational Biology,Neurosciences & Neurology",,3.278,CARCINOMA,COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7424080,
29,A Comparison of Three-Dimensional Speckle Tracking Echocardiography Parameters in Predicting Left Ventricular Remodeling,2020,,,"Zhong Junda,Liu Peng,Li Shuang,Huang Xiaomin,Zhang Qunhui,Huang Jianyu,Guo Yan,Chen Meixiang,Ruan Zheng,Qin Changyu","Zhong JD,Liu P,Li S,Huang XM,Zhang QH,Huang JY,Guo Y,Chen MX,Ruan Z,Qin CY",Xu L,10.1155/2020/8847144,"PLA, Gen Hosp Southern Theatre Command, Dept Geriatr Cardiol, Guangzhou 510016, Peoples R China.","Three-dimensional speckle tracking echocardiography (3D STE) is an emerging noninvasive method for predicting left ventricular remodeling (LVR) after acute myocardial infarction (AMI). Previous studies analyzed the predictive value of 3D STE with traditional models. However, no models that contain comprehensive risk factors were assessed, and there are limited data on the comparison of different 3D STE parameters. In this study, we sought to build a machine learning model for predicting LVR in AMI patients after effective percutaneous coronary intervention (PCI) that contains the majority of the clinical risk factors and compare 3D STE parameters values for LVR prediction. We enrolled 135 first-onset AMI patients (120 males, mean age 54 +/- 9 years). All patients went through a 3D STE and a traditional transthoracic echocardiography 24 hours after reperfusion. A second echocardiography was repeated at the three-month follow-up to detect LVR (defined as a 20 percent increase in left ventricular end-diastolic volume). Six models were constructed using 15 risk factors. A receiver operator characteristic curve and four performance measurements were used as evaluation methods. Feature importance was used to compare 3D STE parameters. 26 patients (19.3%) had LVR. Our evaluation showed that RF can best predict LVR with the best AUC of 0.96. 3D GLS was the most valuable 3D STE parameters, followed by GCS, global area strain, and global radial strain (feature importance 0.146, 0.089, 0.087, and 0.069, respectively). To sum up, RF models can accurately predict the LVR after AMI, and 3D GLS was the best 3D STE parameters in predicting the LVR.","PRIMARY CORONARY ANGIOPLASTY,MAGNETIC-RESONANCE,LONGITUDINAL STRAIN,TIME,DILATION,SECURITY,AWARE",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Health Care Sciences & Services,,3.188,"PRIMARY,CORONARY,ANGIOPLASTY,MAGNETIC-RESONANCE,LONGITUDINAL,STRAIN,TIME,DILATION,SECURITY,AWARE",JOURNAL OF HEALTHCARE ENGINEERING,https://downloads.hindawi.com/journals/jhe/2020/8847144.pdf,
30,Detection of Pulmonary Nodules Based on Improved Full Convolution Network Model,57,16,,"Liu Ruoyu,Liu Libo","Liu RY,Liu LB",Liu LB,10.3788/LOP57.161015,Ningxia University,"To address the limitations of existing detection methods in pulmonary nodule detection, such as low accuracy and over-fitting, a pulmonary nodule detection method based on an improved YOLACT model was proposed. In the main structure of the YOLACT model, the original residual network was replaced with DetNet to overcome the limitation of the original model in small nodule detection. Further, a transfer-learning mechanism was introduced in the model training to prevent the over-fitting problem of the original model induced by learning difficulties on a small number of pulmonary nodules, thereby allowing the new model to achieve better detection results. Moreover, the original ReLU function was replaced with the RReLU function to further reduce the possibility of over-fitting. Experimental results on LUNA16 dataset indicate that the proposed method can achieve improvement under several evaluation metrics, such as the working curve of the subject, rate of false positives, rate of missed diagnosis, and accuracy.","image processing,pulmonary nodule detection,full convolutional network model,transfer learning,deep learning,activation function",Article,"SHANGHAI INST OPTICS & FINE MECHANICS, CHINESE ACAD SCIENCE,  390, QINGHE LU, SHANGHAI, JIADING-QU, PEOPLES R CHINA","Engineering,Optics",,,"FALSE-POSITIVE,REDUCTION,IMAGES",LASER & OPTOELECTRONICS PROGRESS,,
31,Marker selection for predicting continuous survival period of colorectal cancer,11,4,785-791,"Liu Shibo,Feng Xiaojuan,Zhao Huanyu,Wang Zhengyou,Zhang Yanan","Liu SB,Feng XJ,Zhao HY,Wang ZY,Zhang YA",Wang ZY,10.1007/s13198-019-00847-0,Shijiazhuang Tiedao University,"Colorectal cancer is one of the most prevalent cancers that usually has a strong concealment. For early detection and prevention of colorectal cancer, various type of biomarkers are checked to verify whether they can accurately and sensitively assess this disease. Though there have existed some traditional statistical methodologies for this verification, such ast-test,chi 2-test and information gain, it is hard to apply the univariate technology for mining massive biomarker set. In this paper, we proposes a hybrid algorithm (BPPSO) based on particle swarm optimization combining with back-propagation neural network to select critical biomarkers for predicting continuous survival period. The experiments show that BPPSO is effective for biomarker selection problem.","Biomarkers,Colorectal cancer,Feature selection,Particle swarm optimization,BP neural network",Article; Proceedings Paper,"SPRINGER INDIA, 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001, INDIA",Engineering,,,"ARTIFICIAL,NEURAL-NETWORK,COLON,SUPPORT",INTERNATIONAL JOURNAL OF SYSTEM ASSURANCE ENGINEERING AND MANAGEMENT,,
32,A fuzzy shape representation of a segmented vessel tree and kernel-induced random forest classifier for the efficient prediction of lung cancer,76,8,5801-5824,"Deepa P.,Suganthi M.","Deepa P,Suganthi M",Deepa P,10.1007/s11227-019-03002-5,Muthayammal Engineering College,"An intelligent clinical decision support system is proposed classifying lung nodules for lung cancer prediction using a kernel-induced random forest classifier. A contourlet filter is used for image denoising. Fuzzy logic is used to represent the segmented shape of a vessel tree. The fuzzy shape of the vessel tree is then given to a classifier as a feature for learning. A hybridization of expected maximization and total variation regularisation is proposed for the vessel tree segmentation. The proposed use of a fuzzy shape vessel tree and kernel-induced random forest classifier promises to be an efficient method of detecting lung nodules for cancer diagnosis. The proposed system is evaluated for precision, recall and accuracy in comparison with many previously available techniques.","Lung nodules,Contourlet filter,EM algorithm,Total variation regularisation,Fuzzy shape representation,Kernel-induced random forest technique",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.344,"AUTOMATIC,DETECTION,PULMONARY,NODULES",JOURNAL OF SUPERCOMPUTING,,
33,Prediction of Hyperuricemia Risk Based on Medical Examination Report Analysis,29,4,468-503,"Hou Rong,Xiao Yongbo,Zhu Yan,Zhao Hongyan","Hou R,Xiao YB,Zhu Y,Zhao HY",Xiao YB,10.1007/s11518-020-5462-4,Tsinghua University,"This study hopes to contribute to disease detection by analyzing a medical examination dataset with 123,968 samples. Based on association rules mining and related medical knowledge, 6 models were constructed here to predict hyperuricemia prevalence and investigated its risk factors. Comparing different models, the prediction performances of Lasso logistic regression, traditional logistic regression, and random forest are excellent, and the results can be interpreted. PCA logistic regression model also works well, but it is not analytical. KNN's prediction performance is relatively poor, while data dimensionality reduction can significantly improve its AUC. SVC has the worst performance and its efficiency of processing highdimensional large dataset is extremely low. The risk factors of hyperuricemia mainly belongs to 4 categories, which are obesity-related factors, renal function factors, liver function factors, and myeloproliferative diseases-related factors. Random forest, Lasso regression, and logistic regression all treat serum creatinine, BMI, triglyceride, fatty liver, and age as key predictive variables. Models also show that serum urea, serum alanine aminotransferase, negative urobilinogen, red blood cell count, white blood cell count and the pH are significantly correlated with the risk.","Medical examination,hyperuricemia,machine learning,risk prediction,risk factors",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Operations Research & Management Science,,1.429,"DIABETIC-PATIENTS,HEALTH-CARE",JOURNAL OF SYSTEMS SCIENCE AND SYSTEMS ENGINEERING,,
34,Using Machine Learning for Robust Target Prediction in a Basic Oxygen Furnace System,51,4,1632-1645,"Bae Juhee,Li Yurong,Stahl Niclas,Mathiason Gunnar,Kojola Niklas","Bae J,Li YR,Stahl N,Mathiason G,Kojola N",Bae J,10.1007/s11663-020-01853-5,University of Skovde,"The steel-making process in a Basic Oxygen Furnace (BOF) must meet a combination of target values such as the final melt temperature and upper limits of the carbon and phosphorus content of the final melt with minimum material loss. An optimal blow end time (cut-off point), where these targets are met, often relies on the experience and skill of the operators who control the process, using both collected sensor readings and an implicit understanding of how the process develops. If the precision of hitting the optimal cut-off point can be improved, this immediately increases productivity as well as material and energy efficiency, thus decreasing environmental impact and cost. We examine the usage of standard machine learning models to predict the end-point targets using a full production dataset. Various causes of prediction uncertainty are explored and isolated using a combination of raw data and engineered features. In this study, we reach robust temperature, carbon, and phosphorus prediction hit rates of 88, 92, and 89 pct, respectively, using a large production dataset.","END-POINT PREDICTION,MOLTEN STEEL,TEMPERATURE PREDICTION,STEELMAKING PROCESS,PHOSPHORUS-CONTENT,NEURAL-NETWORK,MODEL,TREE",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Materials Science,Metallurgy & Metallurgical Engineering",,2.57,"END-POINT,PREDICTION,MOLTEN,STEEL,TEMPERATURE,PREDICTION,STEELMAKING,PROCESS,PHOSPHORUS-CONTENT,NEURAL-NETWORK,MODEL,TREE",METALLURGICAL AND MATERIALS TRANSACTIONS B-PROCESS METALLURGY AND MATERIALS PROCESSING SCIENCE,http://his.diva-portal.org/smash/get/diva2:1439880/FULLTEXT02,
35,Automatic classification of pulmonary diseases using a structural co-occurrence matrix,32,15,10935-10945,"Peixoto Solon Alves,Reboucas Filho Pedro P.,Arun Kumar N.,de Albuquerque Victor Hugo C.","Peixoto SA,Reboucas PP,Kumar NA,de Albuquerque VHC",de Albuquerque VHC,10.1007/s00521-018-3736-2,Universidade Fortaleza,"The World Health Organization (WHO) estimates that 300 million people have asthma and that this disease causes about 250 thousand deaths per year worldwide. The number of deaths from chronic obstructive pulmonary disease increased by 30% in 2015, and this disease will, according to WHO, be the third major cause of death worldwide in 2030. The identification of diseases using medical image processing techniques is in high demand to assist medical doctors to make more accurate diagnoses. However, although these techniques contribute in making medical diagnoses, most of them still need to have some parameters set and this can be a difficult and tedious process. In this paper, a new automatic approach to identify and classify lung diseases from a structural co-occurrence matrix (SCM) in chest computed tomography images is proposed. The most important novelty of this approach is that only the image is used as the input data and extract the structural information of the disease which, in this case, is related to the lower frequencies. In order to demonstrate the efficiency of the proposed technique, it was compared with other well-known state-of-art feature extractors. In addition, the SCM was evaluated with four filters (Gaussian, Fourier, Laplace and Sobel) using linear discriminant analysis, multi-layer perceptron, support vector machines and minimal learning machine classifiers. The results showed that the SCM, when using low frequencies, is able to adapt to different images and extract the most significant structural data, without the need of any additional parameters, yet maintaining the diagnostic precision.","Structural co-occurrence matrix,Feature extraction,Medical image processing,Lung disease",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"SEGMENTATION,RECOGNITION,FEATURES",NEURAL COMPUTING & APPLICATIONS,,
36,"A state-of-the-art-review on phase change materials integrated cooling systems for deterministic parametrical analysis, stochastic uncertainty-based design, single and multi-objective optimisations with machine learning applications",220,,,"Zhou Yuekuan,Zheng Siqian,Zhang Guoqiang","Zhou YK,Zheng SQ,Zhang GQ",Zhou YK,10.1016/j.enbuild.2020.110013,Hong Kong Polytechnic University,"Renewable energy utilisation, latent energy storage, optimal system design, and robust system operation are critical elements for carbon-free buildings and communities. Machine learning methods are effective to assist the energy-efficient renewable systems during multi-criteria design and multi-level uncertainty-based operation periods. However, the current literature provides little knowledge on this topic. In this study, a state-of-the-art-review on phase change materials for cooling applications is presented, in terms of smart ventilations, intelligent PCMs charging/discharging, deterministic parametrical analysis, stochastic uncertainty-based performance prediction and optimisation. Furthermore, technical effectiveness of machine learning methods in single and multi-objective optimisations has been presented, through hybrid PCMs integrated renewable systems. Multivariables involved in the review include thermo-physical, geometrical and operating parameters of PCMs. Multi-criteria employed in the review include heat transfer rate, cooling energy storage density, heat storage and release efficiency, and indoor thermal comfort. The literature review presents technical challenges, such as tradeoffsolutions between computational accuracy and efficiency, generic methods for effective selection amongst multi-diversified optimal solutions along the Pareto front, the general methodology for multi-level uncertainty quantification, smart controllers with accurate predictions under high-level parameters' uncertainty and stochastic occupants' behaviors. The future outlook and recommendations of machine learning methods in PCMs integrated cooling systems have also been presented as avenues for upcoming research. (c) 2020 Elsevier B.V. All rights reserved.","Machine learning,Cooling storage,Smart ventilations,Intelligent charging/discharging,Uncertainty-based optimisation",Review,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Construction & Building Technology,Energy & Fuels,Engineering",,6.175,"THERMAL-ENERGY,STORAGE,VENTILATED,TROMBE,WALL,PERFORMANCE,EVALUATION,NUMERICAL-SIMULATION,PCM,BUILDINGS,MODEL,WATER,PROPAGATION,PREDICTION",ENERGY AND BUILDINGS,,
37,Integrated CS optimization and OLS for recurrent neural network in modeling microwave thermal process,32,16,12267-12280,"Liu Tong,Liang Shan,Xiong Qingyu,Wang Kai","Liu T,Liang S,Xiong QY,Wang K",Liang S,10.1007/s00521-019-04300-y,Chongqing University,"In this paper, we propose a novel hybrid algorithm to construct an improved recurrent neuron network (RNN) for modeling tunnel microwave thermal process. The new design involves a hierarchical learning process, in which the recurrent neurons of RNN are optimized by the cuckoo search (CS) algorithm, while effectiveness and efficiency of the model are guaranteed by using the orthogonal least squares (OLS) method, which is a fast approach for construction of neural networks in a stepwise forward procedure. The major contribution is to integrate seamlessly the OLS model selection and CS neuron optimization in an innovative way so that it can well track the underlying dynamic of this complicated thermal process with a very sparse model. By conducting a microwave rice drying experiment, a set of real-world datasets is used to drive the RNN model. Simulation results demonstrate the effectiveness of the proposed model compared with existing well-known approaches in terms of modeling accuracy and model compactness.","Tunnel microwave thermal process,Recurrent neuron network,Cuckoo search optimization,Orthogonal least squares",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"NONLINEAR-SYSTEM,IDENTIFICATION,CUCKOO,SEARCH,ALGORITHM,DESIGN,PREDICTION,REGRESSION",NEURAL COMPUTING & APPLICATIONS,,
38,Single and ensemble classifiers for defect prediction in sheet metal forming under variability,32,16,12335-12349,"Dib M. A.,Oliveira N. J.,Marques A. E.,Oliveira M. C.,Fernandes J. V.,Ribeiro B. M.,Prates P. A.","Dib MA,Oliveira NJ,Marques AE,Oliveira MC,Fernandes JV,Ribeiro BM,Prates PA",Prates PA,10.1007/s00521-019-04651-6,Universidade de Coimbra,"This paper presents an approach, based on machine learning techniques, to predict the occurrence of defects in sheet metal forming processes, exposed to sources of scatter in the material properties and process parameters. An empirical analysis of performance of ML techniques is presented, considering both single learning and ensemble models. These are trained using data sets populated with numerical simulation results of two sheet metal forming processes: U-Channel and Square Cup. Data sets were built for three distinct steel sheets. A total of eleven input features, related to the mechanical properties, sheet thickness and process parameters, were considered; also, two types of defects (outputs) were analysed for each process. The sampling data were generated, assuming that the variability of each input feature is described by a normal distribution. For a given type of defect, most single classifiers show similar performances, regardless of the material. When comparing single learning and ensemble models, the latter can provide an efficient alternative. The fact that ensemble predictive models present relatively high performances, combined with the possibility of reconciling model bias and variance, offer a promising direction for its application in industrial environment.","Machine learning,Ensemble learning,Defect prediction,Sheet metal forming",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"ARTIFICIAL,NEURAL-NETWORKS,DIE-ROLL,HEIGHT,FINITE-ELEMENT,GENETIC,ALGORITHM,PARAMETER-IDENTIFICATION,SPRINGBACK,PREDICTION,NUMERICAL-SIMULATION,OPTIMIZATION,BEHAVIOR,MODEL",NEURAL COMPUTING & APPLICATIONS,https://link.springer.com/content/pdf/10.1007/s00521-019-04651-6.pdf,
39,Deformation modeling and classification using deep convolutional neural networks for computerized analysis of neuropsychological drawings,32,16,12909-12933,"Moetesum Momina,Siddiqi Imran,Ehsan Shoaib,Vincent Nicole","Moetesum M,Siddiqi I,Ehsan S,Vincent N",Siddiqi I,10.1007/s00521-020-04735-8,"Bahria Univ, Islamabad, Pakistan.","Drawing-based tests are cost-effective, noninvasive screening methods, popularly employed by psychologists for the early detection and diagnosis of various neuropsychological disorders. Computerized analysis of such drawings is a complex task due to the high degree of deformations present in the responses and reliance on extensive clinical manifestations for their inferences. Traditional rule-based approaches employed in visual analysis-based systems prove insufficient to model all possible clinical deformations. Meanwhile, procedural analysis-based techniques may contradict with the standard test conduction and evaluation protocols. Leveraging on the increasing popularity of convolutional neural networks (CNNs), we propose an effective technique for modeling and classifying dysfunction indicating deformations in drawings without modifying clinical standards. Contrary to conventional sketch recognition applications where CNNs are trained to diminish intra-shape class variations, we employ deformation-specific augmentation to enhance the presence of specific deviations that are defined by clinical practitioners. The performance of our proposed technique is evaluated using Lacks' scoring of the Bender-Gestalt test, as a case study. The results of our experimentation substantiate that our proposed approach can represent domain knowledge sufficiently without extensive heuristics and can effectively identify drawing-based biomarkers for various neuropsychological disorders.","Neuropsychological drawings,Deformation classification,Deep visual features,Bender-Gestalt test",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"GESTALT,TEST,DISEASE,RECOGNITION,PRESSURE,ONLINE,TREMOR,TOOL",NEURAL COMPUTING & APPLICATIONS,,
40,A deep learning approach for Parkinson's disease diagnosis from EEG signals,32,15,10927-10933,"Oh Shu Lih,Hagiwara Yuki,Raghavendra U.,Yuvaraj Rajamanickam,Arunkumar N.,Murugappan M.,Acharya U. Rajendra","Oh SL,Hagiwara Y,Raghavendra U,Yuvaraj R,Arunkumar N,Murugappan M,Acharya UR",Acharya UR,10.1007/s00521-018-3689-5,"Ngee Ann Polytech, Dept Elect & Comp Engn, Singapore 599489, Singapore.","An automated detection system for Parkinson's disease (PD) employing the convolutional neural network (CNN) is proposed in this study. PD is characterized by the gradual degradation of motor function in the brain. Since it is related to the brain abnormality, electroencephalogram (EEG) signals are usually considered for the early diagnosis. In this work, we have used the EEG signals of twenty PD andtwentynormal subjects in this study. Athirteen-layer CNN architecture which can overcome the need for the conventional feature representation stages is implemented. The developed model has achieved a promising performance of 88.25% accuracy, 84.71% sensitivity, and 91.77% specificity. The developed classification model is ready to be used on large population before installation of clinical usage.","Computer-aided detection system,Convolutional neural network,Deep learning,Parkinson's disease",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"OBJECT,RECOGNITION,IDENTIFICATION",NEURAL COMPUTING & APPLICATIONS,,
41,Lung nodule malignancy classification in chest computed tomography images using transfer learning and convolutional neural networks,32,15,11065-11082,"da Nobrega Raul Victor M.,Reboucas Filho Pedro P.,Rodrigues Murillo B.,da Silva Suane P. P.,Dourado Junior Carlos M. J. M.,de Albuquerque Victor Hugo C.","da N?brega RVM,Rebou?as PP,Rodrigues MB,da Silva SPP,Dourado CMJM,de Albuquerque VHC",Rebou?as PP,10.1007/s00521-018-3895-1,"Inst Fed Fed Educ Ciencia & Tecnol Ceara IFCE, Lab Processamento Digital Imagens Sinais & Comp A, Fortaleza, Ceara, Brazil.","Lung cancer accounts for more than 1.5 million deaths worldwide, and it corresponded to 26% of all deaths due to cancer in 2017. However, lung computer-aided diagnosis systems developed to identify lung cancer at early stages are increasing survival rates. This study explores the performance of deep transfer learning from non-medical images on lung nodule malignancy classification tasks in order to improve such systems. Initially, the 1018 chest computed tomography (CT) examinations and medical annotations from the LIDC/IDRI were processed. Then, several convolutional neural networks (VGG16, VGG19, MobileNet, Xception, InceptionV3, ResNet50, InceptionResNetV2, DenseNet169, DenseNet201, NASNetMobile and NASNetLarge) were built, trained on the ImageNet dataset, converted into feature extractors and applied on the LIDC/IDRI nodule images. Following this, each set of deep features was submitted to 10-fold cross-validations with naive Bayes, multilayer perceptron, support vector machine (SVM), K-nearest neighbors KNN and random forest classifiers. Finally, the evaluation metrics accuracy (ACC), area under the curve (AUC), true positive rate (TPR), precision (PPV) and F1-score of each cross-validation average result were computed and compared. The results showed that the deep feature extractor based on the ResNet50 and the SVM RBF classifier, achieved an AUC metric of 93.1% (the highest value not only among the evaluated combinations, but also among the related works in the literature evaluated), a TPR of 85.38%, an ACC of 88.41%, a PPV of 73.48% and an F1-score of 78.83%. Based on these results, deep transfer learning proves to be a relevant strategy to extract representative features from lung nodule CT images.","Lung nodule malignancy classification,Convolutional neural networks,Transfer,learning,Computer-aided diagnoses",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"LEVEL,CLASSIFICATION,CANCER,DIAGNOSIS",NEURAL COMPUTING & APPLICATIONS,,
42,Novel deep genetic ensemble of classifiers for arrhythmia detection using ECG signals,32,15,11137-11161,"Plawiak Pawel,Acharya U. Rajendra","Plawiak P,Acharya UR",Plawiak P,10.1007/s00521-018-03980-2,Cracow University of Technology,"The heart disease is one of the most serious health problems in today's world. Over 50 million persons have cardiovascular diseases around the world. Our proposed work based on 744 segments of ECG signal is obtained from the MIT-BIH Arrhythmia database (strongly imbalanced data) for one lead (modified lead II), from 29 people. In this work, we have used long-duration (10 s) ECG signal segments (13 times less classifications/analysis). The spectral power density was estimated based on Welch's method and discrete Fourier transform to strengthen the characteristic ECG signal features. Our main contribution is the design of a novel three-layer (48 + 4 + 1) deep genetic ensemble of classifiers (DGEC). Developed method is a hybrid which combines the advantages of: (1) ensemble learning, (2) deep learning, and (3) evolutionary computation. Novel system was developed by the fusion of three normalization types, four Hamming window widths, four classifiers types, stratified tenfold cross-validation, genetic feature (frequency components) selection, layered learning, genetic optimization of classifiers parameters, and new genetic layered training (expert votes selection) to connect classifiers. The developed DGEC system achieved a recognition sensitivity of 94.62% (40 errors/744 classifications), accuracy = 99.37%, specificity = 99.66% with classification time of single sample = 0.8736 (s) in detecting 17 arrhythmia ECG classes. The proposed model can be applied in cloud computing or implemented in mobile devices to evaluate the cardiac health immediately with highest precision.","ECG,Biomedical signal processing and analysis,Machine learning,Genetic algorithms,Ensemble learning,Deep learning",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"CONVOLUTIONAL,NEURAL-NETWORK,HEARTBEAT,CLASSIFICATION,AUTOMATED,DETECTION,RECOGNITION,MODEL",NEURAL COMPUTING & APPLICATIONS,https://link.springer.com/content/pdf/10.1007/s00521-018-03980-2.pdf,
43,Iterative 3D feature enhancement network for pancreas segmentation from CT images,32,16,12535-12546,"Mo Juan,Zhang Lei,Wang Yan,Huang Haiying","Mo J,Zhang L,Wang Y,Huang HY",Zhang L,10.1007/s00521-020-04710-3,Sichuan University,"Automatic and accurate pancreas segmentation from 3D computed tomography volumes is a crucial prerequisite for computer-aided diagnosis, intraoperative planning and guidance. However, this is a challenging task because of the high inter-subject variability in the shape and location of the pancreas, as well as the existence of the surrounding organs. In order to address the above challenges, we propose a novel iterative 3D feature enhancement network to segment pancreas accurately. Specifically, the multi-level integrated features and the individual features at different levels can be progressively enhanced in an iterative manner by leveraging the complementary information encoded in different features. Therefore, the non-pancreas information at lower layers can be suppressed, and the fine details of pancreas at higher layers can be increased. In addition, because the pancreas region occupies only a small part of the scan, in order to prevent the final predictions from being biased toward the background class, we design the Dice similarity coefficients loss function in the training phase to mitigate this issue. Meanwhile, deep supervision with auxiliary classifier is incorporated in the intermediate layers at each iteration to guide the back-propagation of gradient flows and boost the discriminative capability at lower layers. Finally, in order to verify the effectiveness of the proposed method, we evaluated our approach on the publicly available NIH pancreas segmentation dataset. Extensive experiments illustrate that the proposed method achieves better performance than the state-of-the-art algorithms, and it can be easily applied to other volumetric image segmentation tasks.","Iterative 3D feature enhancement,Fully convolutional network,Residual learning,Pancreas segmentation",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"NEURAL-NETWORKS,MODEL",NEURAL COMPUTING & APPLICATIONS,,
44,Imaging techniques for defect detection of fiber reinforced polymer-bonded civil infrastructures,27,8,,Qiu Qiwen,Qiu QW,Qiu QW,10.1002/stc.2555,Hong Kong Polytechnic University,"The present article provides a state-of-the-art review of imaging techniques used for defect detection of fiber reinforced polymer (FRP)-bonded civil engineering structures. Compared to the conventional techniques by equipping a structure with stress wave sensors, the contactless imaging techniques feature efficient instrumentation, convenient data acquisition, and rapid evaluation in the procedures of nondestructive testing (NDT). Recently, a substantial progress in utilizing electromagnetic waves for development of imaging NDT techniques (e.g., synthetic aperture radar, infrared thermography, laser shearography, and laser reflection technique) with the purpose to identify debonding or delamination of FRP-bonded structural systems has been made. As another electromagnetic wave-based imaging technique, X-ray computed tomography is promising for exploration of the damage evolution in this structural system, despite little application in structural health monitoring of real infrastructures. Apart from these imaging techniques, more recently, there have been computer-aided motion magnification techniques for defect identification. The motion magnification technique only requires a digital camera and a computer with vision algorithm, which can amplify the motion of defect region and render it visible in a video. This advanced imaging technique achieves high-resolution measurement, simultaneous full-field inspection, and straightforward defect identification in the scene. In this review, both Eulerian motion magnification and phase-based motion magnification techniques for structural visual inspection are presented and discussed. Furthermore, the present article recommends the combination of imaging NDT techniques with artificial intelligence approaches (e.g., deep learning algorithms) to realize the automated and efficient defect detection towards FRP-bonded civil infrastructures.","civil infrastructure,defect identification,fiber reinforced polymer,health diagnostics,nondestructive testing,imaging technique",Review,"JOHN WILEY & SONS LTD, THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND","Construction & Building Technology,Engineering,Instruments & Instrumentation",,4.76,"RADAR,NDT,TECHNIQUE,INFRARED,THERMOGRAPHY,ACOUSTIC-EMISSION,DAMAGE,DETECTION,CONCRETE,BEAMS,NONDESTRUCTIVE,EVALUATION,FRP,COMPOSITES,MODAL,IDENTIFICATION,DEBONDING,DETECTION,LASER,REFLECTION",STRUCTURAL CONTROL & HEALTH MONITORING,,
45,Classification of Task-State fMRI Data Based on Circle-EMD and Machine Learning,2020,,,"Gui Renzhou,Chen Tongjie,Nie Han","Gui RZ,Chen TJ,Nie H",Gui RZ,10.1155/2020/7691294,Tongji University,"In the research work of the brain-computer interface and the function of human brain work, the state classification of multitask state fMRI data is a problem. The fMRI signal of the human brain is a nonstationary signal with many noise effects and interference. Based on the commonly used nonstationary signal analysis method, Hilbert-Huang transform (HHT), we propose an improved circle-EMD algorithm to suppress the end effect. The algorithm can extract different intrinsic mode functions (IMFs), decompose the fMRI data to filter out low frequency and other redundant noise signals, and more accurately reflect the true characteristics of the original signal. For the filtered fMRI signal, we use three existing different machine learning methods: logistic regression (LR), support vector machine (SVM), and deep neural network (DNN) to achieve effective classification of different task states. The experiment compares the results of these machine learning methods and confirms that the deep neural network has the highest accuracy for task-state fMRI data classification and the effectiveness of the improved circle-EMD algorithm.","HILBERT,IDENTIFICATION,REGRESSION,EXTRACTION",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Mathematical & Computational Biology,Neurosciences & Neurology",,3.278,"HILBERT,IDENTIFICATION,REGRESSION,EXTRACTION",COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE,https://downloads.hindawi.com/journals/cin/2020/7691294.pdf,
46,A reasoned bibliography on SAR interferometry applications and outlook on big interferometric data processing,19,,,"El Kamali Muhagir,Abuelgasim Abdelgadir,Papoutsis Ioannis,Loupasakis Constantinos,Kontoes Charalampos","El Kamali M,Abuelgasim A,Papoutsis I,Loupasakis C,Kontoes C",Abuelgasim A,10.1016/j.rsase.2020.100358,United Arab Emirates University,"In the past few decades, Synthetic Aperture Radar Interferometry (InSAR) has proven to be a reliable tool for monitoring land surface deformations occurring naturally (landslides, earthquakes, and volcanoes) or due to some anthropogenic activities, such as extraction of underground materials (, e.g., groundwater, oil, and gas) with acceptable accuracy. The availability of SAR data from various satellites have significantly improved this technology further notably with collecting data from different radar frequencies (X-, C-, and L-band), different spatial resolutions, increased revisit times and diverse imaging geometry including both along ascending and descending orbits. This review provides a description about the InSAR state-of-the-art technology and how it has been effectively used for detecting surface deformations. The techniques of Persistent Scatterer Interferometry, Small Baseline Subset, Stanford Method for Persistent Scatterers, and Offset Tracking are discussed. The paper also discusses the strengths and weaknesses of the different InSAR techniques currently employed in detecting surface deformations, concerning the various types of land cover. It then highlights the optimal methodology and data needs for these different land cover types. This work finally dives into the emergence of new technologies for processing big Earth Observation data and discusses the prospects of using machine/deep learning algorithms powered by advanced cloud computing infrastructure to mine new information hidden within InSAR products and associated land-surface deformations.","Land surface deformations,Synthetic aperture radar,Interferometry,PSI,SBAS,StaMPS,Big data analysis,Machine learning",Review,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Environmental Sciences & Ecology,Remote Sensing",,,"TIME-SERIES,LAND,SUBSIDENCE,GROUND,DISPLACEMENTS,SURFACE,DEFORMATION,INSAR,DATA,DINSAR,AREA,PHASE,RETRIEVAL,LANDSLIDE",REMOTE SENSING APPLICATIONS-SOCIETY AND ENVIRONMENT,https://doi.org/10.1016/j.rsase.2020.100358,
47,COVID-XNet: A Custom Deep Learning System to Diagnose and Locate COVID-19 in Chest X-ray Images,10,16,,"Duran-Lopez Lourdes,Dominguez-Morales Juan Pedro,Corral-Jaime Jesus,Vicente-Diaz Saturnino,Linares-Barranco Alejandro","Duran-Lopez L,Dominguez-Morales JP,Corral-Jaime J,Vicente-Diaz S,Linares-Barranco A",Duran-Lopez L,10.3390/app10165683,University of Sevilla,"Featured Application This work could be used to aid radiologists in the screening process, contributing to the fight against COVID-19. The COVID-19 pandemic caused by the new coronavirus SARS-CoV-2 has changed the world as we know it. An early diagnosis is crucial in order to prevent new outbreaks and control its rapid spread. Medical imaging techniques, such as X-ray or chest computed tomography, are commonly used for this purpose due to their reliability for COVID-19 diagnosis. Computer-aided diagnosis systems could play an essential role in aiding radiologists in the screening process. In this work, a novel Deep Learning-based system, called COVID-XNet, is presented for COVID-19 diagnosis in chest X-ray images. The proposed system performs a set of preprocessing algorithms to the input images for variability reduction and contrast enhancement, which are then fed to a custom Convolutional Neural Network in order to extract relevant features and perform the classification between COVID-19 and normal cases. The system is trained and validated using a 5-fold cross-validation scheme, achieving an average accuracy of 94.43% and an AUC of 0.988. The output of the system can be visualized using Class Activation Maps, highlighting the main findings for COVID-19 in X-ray images. These promising results indicate that COVID-XNet could be used as a tool to aid radiologists and contribute to the fight against COVID-19.","COVID-19,deep learning,convolutional neural networks,medical image analysis,computer-aided diagnosis,X-ray",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://idus.us.es/bitstream/11441/100982/1/AS_linares-barranco_2020_covid.pdf,
48,Cost-Sensitive Ensemble Feature Ranking and Automatic Threshold Selection for Chronic Kidney Disease Diagnosis,10,16,,"Imran Ali Syed,Ali Bilal,Hussain Jamil,Hussain Musarrat,Satti Fahad Ahmed,Park Gwang Hoon,Lee Sungyoung","Ali SI,Ali B,Hussain J,Hussain M,Satti FA,Park GH,Lee S",Lee S,10.3390/app10165663,Kyung Hee University,"Automated medical diagnosis is one of the important machine learning applications in the domain of healthcare. In this regard, most of the approaches primarily focus on optimizing the accuracy of classification models. In this research, we argue that, unlike general-purpose classification problems, medical applications, such as chronic kidney disease (CKD) diagnosis, require special treatment. In the case of CKD, apart from model performance, other factors such as the cost of data acquisition may also be taken into account to enhance the applicability of the automated diagnosis system. In this research, we proposed two techniques for cost-sensitive feature ranking. An ensemble of decision tree models is employed in both the techniques for computing the worth of a feature in the CKD dataset. An automatic threshold selection heuristic is also introduced which is based on the intersection of features' worth and their accumulated cost. A set of experiments are conducted to evaluate the efficacy of the proposed techniques on both tree-based and non tree-based classification models. The proposed approaches were also evaluated against several comparative techniques. Furthermore, it is demonstrated that the proposed techniques select around 1/4th of the original CKD features while reducing the cost by a factor of 7.42 of the original feature set. Based on the extensive experimentation, it is concluded that the proposed techniques employing feature-cost interaction heuristic tend to select feature subsets that are both useful and cost-effective.","cost-sensitive feature selection,ensemble models,decision tree classifiers,chronic kidney disease,random forest,gradient boosted trees",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"PREDICTION,MACHINE,CLASSIFICATION",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/16/5663/pdf,
49,"A Comparative Systematic Literature Review on Knee Bone Reports from MRI, X-Rays and CT Scans Using Deep Learning and Machine Learning Methodologies",10,8,,"Khalid Hafsa,Hussain Muzammil,Al Ghamdi Mohammed A.,Khalid Tayyaba,Khalid Khadija,Khan Muhammad Adnan,Fatima Kalsoom,Masood Khalid,Almotiri Sultan H.,Farooq Muhammad Shoaib","Khalid H,Hussain M,Al Ghamdi MA,Khalid T,Khalid K,Khan MA,Fatima K,Masood K,Almotiri SH,Farooq MS",Khalid H,10.3390/diagnostics10080518,"Univ Management & Technol, Sch Syst & Technol, Dept Comp Sci, Lahore 54000, Pakistan.","The purpose of this research was to provide a ""systematic literature review"" of knee bone reports that are obtained by MRI, CT scans, and X-rays by using deep learning and machine learning techniques by comparing different approaches-to perform a comprehensive study on the deep learning and machine learning methodologies to diagnose knee bone diseases by detecting symptoms from X-ray, CT scan, and MRI images. This study will help those researchers who want to conduct research in the knee bone field. A comparative systematic literature review was conducted for the accomplishment of our work. A total of 32 papers were reviewed in this research. Six papers consist of X-rays of knee bone with deep learning methodologies, five papers cover the MRI of knee bone using deep learning approaches, and another five papers cover CT scans of knee bone with deep learning techniques. Another 16 papers cover the machine learning techniques for evaluating CT scans, X-rays, and MRIs of knee bone. This research compares the deep learning methodologies for CT scan, MRI, and X-ray reports on knee bone, comparing the accuracy of each technique, which can be used for future development. In the future, this research will be enhanced by comparing X-ray, CT-scan, and MRI reports of knee bone with information retrieval and big data techniques. The results show that deep learning techniques are best for X-ray, MRI, and CT scan images of the knee bone to diagnose diseases.","magnetic resonance imaging (MRI),computed tomography (CT scan),electromagnetic radiation (X-ray),trabecular bone (TB)",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"IMAGES,SEGMENTATION,TOOL",DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7460189,
50,Efficient Bone Metastasis Diagnosis in Bone Scintigraphy Using a Fast Convolutional Neural Network Architecture,10,8,,"Papandrianos Nikolaos,Papageorgiou Elpiniki,Anagnostis Athanasios,Papageorgiou Konstantinos","Papandrianos N,Papageorgiou E,Anagnostis A,Papageorgiou K",Papageorgiou E,10.3390/diagnostics10080532,University of Thessaly,"(1) Background: Bone metastasis is among diseases that frequently appear in breast, lung and prostate cancer; the most popular imaging method of screening in metastasis is bone scintigraphy and presents very high sensitivity (95%). In the context of image recognition, this work investigates convolutional neural networks (CNNs), which are an efficient type of deep neural networks, to sort out the diagnosis problem of bone metastasis on prostate cancer patients; (2) Methods: As a deep learning model, CNN is able to extract the feature of an image and use this feature to classify images. It is widely applied in medical image classification. This study is devoted to developing a robust CNN model that efficiently and fast classifies bone scintigraphy images of patients suffering from prostate cancer, by determining whether or not they develop metastasis of prostate cancer. The retrospective study included 778 sequential male patients who underwent whole-body bone scans. A nuclear medicine physician classified all the cases into three categories: (a) benign, (b) malignant and (c) degenerative, which were used as gold standard; (3) Results: An efficient and fast CNN architecture was built, based on CNN exploration performance, using whole body scintigraphy images for bone metastasis diagnosis, achieving a high prediction accuracy. The results showed that the method is sufficiently precise when it comes to differentiate a bone metastasis case from other either degenerative changes or normal tissue cases (overall classification accuracy = 91.61% +/- 2.46%). The accuracy of prostate patient cases identification regarding normal, malignant and degenerative changes was 91.3%, 94.7% and 88.6%, respectively. To strengthen the outcomes of this study the authors further compared the best performing CNN method to other popular CNN architectures for medical imaging, like ResNet50, VGG16, GoogleNet and MobileNet, as clearly reported in the literature; and (4) Conclusions: The remarkable outcome of this study is the ability of the method for an easier and more precise interpretation of whole-body images, with effects on the diagnosis accuracy and decision making on the treatment to be applied.","bone metastasis,prostate cancer,nuclear imaging,bone scintigraphy,deep learning,image classification,convolutional neural networks",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,,"COMPUTER-AIDED,DIAGNOSIS,CLINICAL-FEATURES,SYSTEM,PET,DISEASE,CANCER,DETECT,RISK,CT",DIAGNOSTICS,https://www.mdpi.com/2075-4418/10/8/532/pdf,
51,Multi-frame super resolution via deep plug-and-play CNN regularization,28,4,533-555,"Zhao Shengrong,Liang Hu","Zhao SR,Liang H",Liang H,10.1515/jiip-2019-0054,Qilu University of Technology,"Because of the ill-posedness of multi-frame super resolution (MSR), the regularization method plays an important role in the MSR field. Various regularization terms have been proposed to constrain the image to be estimated. However, artifacts also exist in the estimated image due to the artificial tendency in the manually designed prior model. To solve this problem, we propose a novel regularization-based MSR method with learned prior knowledge. By using the variable splitting technique, the fidelity term and regularization term are separated. The fidelity term is associated with an ""L-2-L-2"" form sub-problem. Meanwhile, the sub-problem respect to regularization term is a denoising problem, which can be solved by denoisers learned from a deep convolutional neural network. Different from the traditional regularization methods which employ hand-crafted image priors, in this paper the image prior model is replaced by learned prior implicitly. The two sub-problems are solved alternately and iteratively. The proposed method cannot only handle complex degradation model, but also use the learned prior knowledge to guide the reconstruction process to avoid the artifacts. Both the quantitative and qualitative results demonstrate that the proposed method gains better quality than the state-of-the-art methods.","Super resolution,regularization,plug-and-play,convolutional neural network",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY",Mathematics,,1.227,"IMAGE,SUPERRESOLUTION,RECONSTRUCTION,FIELDS,MODEL",JOURNAL OF INVERSE AND ILL-POSED PROBLEMS,,
52,Investigation of Strength and Fatigue Life of Rubber Asphalt Mixture,13,15,,"Yuan Jiang,Lv Songtao,Peng Xinghai,You Lingyun,Borges Cabrera Milkos","Yuan J,Lv ST,Peng XH,You LY,Cabrera MB",Lv ST,10.3390/ma13153325,Changsha University of Science & Technology,"Strength and fatigue life are essential parameters of pavement structure design. To accurately determine the pavement structure resistance of rubber asphalt mixture, the strength tests at various temperatures, loading rate, and fatigue tests at different stress levels were conducted in this research. Based on the proposed experiments, the change law of rubber asphalt mixture strength with different temperatures and loading rates was revealed. The phenomenological fatigue equation of rubber asphalt mixture was established. The genetic algorithm optimized backpropagation neural network (GA-BPNN) is highly reliable for optimizing production processes in civil engineering, and it has a remarkable application effect. A GA-BPNN strength and fatigue life prediction model was created in this study. The reliability of the prediction model was verified through experiments. The results showed that the rubber asphalt mixture strength decreases and increases with the increase of temperature and loading rate, respectively. The goodness of fit of the rubber asphalt mixture strength and fatigue life prediction model based on the GA-BPNN could reach 0.989 and 0.998, respectively. The indicators of the fatigue life prediction model are superior to the conventional phenomenological fatigue equation model. The GA-BPNN provides an effective method for predicting the rubber asphalt mixture strength and fatigue life, which significantly improves the accuracy of the resistance design of the rubber asphalt pavement structure.","rubber asphalt mixture,strength,fatigue life,genetic algorithm,back propagation neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"MECHANICAL-PROPERTIES,LABORATORY,EVALUATION,PREDICTION,FRACTURE,MODULUS,TEMPERATURE,DAMAGE,HOT",MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7435730,
53,Evaluation of Hyperparameter Optimization in Machine and Deep Learning Methods for Decoding Imagined Speech EEG,20,16,,"Cooney Ciaran,Korik Attila,Folli Raffaella,Coyle Damien","Cooney C,Korik A,Folli R,Coyle D",Cooney C,10.3390/s20164629,Ulster University,"Classification of electroencephalography (EEG) signals corresponding to imagined speech production is important for the development of a direct-speech brain-computer interface (DS-BCI). Deep learning (DL) has been utilized with great success across several domains. However, it remains an open question whether DL methods provide significant advances over traditional machine learning (ML) approaches for classification of imagined speech. Furthermore, hyperparameter (HP) optimization has been neglected in DL-EEG studies, resulting in the significance of its effects remaining uncertain. In this study, we aim to improve classification of imagined speech EEG by employing DL methods while also statistically evaluating the impact of HP optimization on classifier performance. We trained three distinct convolutional neural networks (CNN) on imagined speech EEG using a nested cross-validation approach to HP optimization. Each of the CNNs evaluated was designed specifically for EEG decoding. An imagined speech EEG dataset consisting of both words and vowels facilitated training on both sets independently. CNN results were compared with three benchmark ML methods: Support Vector Machine, Random Forest and regularized Linear Discriminant Analysis. Intra- and inter-subject methods of HP optimization were tested and the effects of HPs statistically analyzed. Accuracies obtained by the CNNs were significantly greater than the benchmark methods when trained on both datasets (words: 24.97%,p< 1 x 10(-7), chance: 16.67%; vowels: 30.00%,p< 1 x 10(-7), chance: 20%). The effects of varying HP values, and interactions between HPs and the CNNs were both statistically significant. The results of HP optimization demonstrate how critical it is for training CNNs to decode imagined speech.","electroencephalography (EEG),brain-computer interface (BCI),convolutional neural networks (CNN),deep learning,machine learning,hyperparameter optimization,imagined speech",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"BRAIN-COMPUTER,INTERFACE,CLASSIFICATION,STATE",SENSORS,https://pure.ulster.ac.uk/ws/files/85634285/CCooney_Accepted_version.pdf,
54,CNN and LSTM-Based Emotion Charting Using Physiological Signals,20,16,,"Dar Muhammad Najam,Akram Muhammad Usman,Khawaja Sajid Gul,Pujari Amit N.","Dar MN,Akram MU,Khawaja SG,Pujari AN",Dar MN,10.3390/s20164551,National University of Sciences & Technology - Pakistan,"Novel trends in affective computing are based on reliable sources of physiological signals such as Electroencephalogram (EEG), Electrocardiogram (ECG), and Galvanic Skin Response (GSR). The use of these signals provides challenges of performance improvement within a broader set of emotion classes in a less constrained real-world environment. To overcome these challenges, we propose a computational framework of 2D Convolutional Neural Network (CNN) architecture for the arrangement of 14 channels of EEG, and a combination of Long Short-Term Memory (LSTM) and 1D-CNN architecture for ECG and GSR. Our approach is subject-independent and incorporates two publicly available datasets of DREAMER and AMIGOS with low-cost, wearable sensors to extract physiological signals suitable for real-world environments. The results outperform state-of-the-art approaches for classification into four classes, namely High Valence-High Arousal, High Valence-Low Arousal, Low Valence-High Arousal, and Low Valence-Low Arousal. Emotion elicitation average accuracy of98.73%is achieved with ECG right-channel modality, 76.65% with EEG modality, and 63.67% with GSR modality for AMIGOS. The overall highest accuracy of 99.0% for the AMIGOS dataset and 90.8% for the DREAMER dataset is achieved with multi-modal fusion. A strong correlation between spectral- and hidden-layer feature analysis with classification performance suggests the efficacy of the proposed method for significant feature extraction and higher emotion elicitation performance to a broader context for less constrained environments.","convolutional neural network (CNN),long short-term memory (LSTM),emotion recognition,EEG,ECG,GSR,deep neural network,physiological signals",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"EEG,RECOGNITION,STRESS,ECG",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7472085,
55,Real-Time Stress Assessment Using Sliding Window Based Convolutional Neural Network,20,16,,"Naqvi Syed Faraz,Ali Syed Saad Azhar,Yahya Norashikin,Yasin Mohd Azhar,Hafeez Yasir,Subhani Ahmad Rauf,Adil Syed Hasan,Al Saggaf Ubaid M.,Moinuddin Muhammad","Naqvi SF,Ali SSA,Yahya N,Yasin MA,Hafeez Y,Subhani AR,Adil SH,Al Saggaf UM,Moinuddin M",Ali SSA,10.3390/s20164400,Universiti Teknologi Petronas,"Mental stress has been identified as a significant cause of several bodily disorders, such as depression, hypertension, neural and cardiovascular abnormalities. Conventional stress assessment methods are highly subjective and tedious and tend to lack accuracy. Machine-learning (ML)-based computer-aided diagnosis systems can be used to assess the mental state with reasonable accuracy, but they require offline processing and feature extraction, rendering them unsuitable for real-time applications. This paper presents a real-time mental stress assessment approach based on convolutional neural networks (CNNs). The CNN-based approach afforded real-time mental stress assessment with an accuracy as high as 96%, the sensitivity of 95%, and specificity of 97%. The proposed approach is compared with state-of-the-art ML techniques in terms of accuracy, time utilisation, and quality of features.","stress-assessment,CAD (computer-aided diagnosis),machine learning,convolutional neural network,feature extraction,real time,sliding window",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"EEG,ALPHA,ASYMMETRY,LIFE,EVENTS,NEGATIVE,AFFECT,MENTAL-STRESS,DISORDER,NEUROFEEDBACK,DEPRESSION,INVENTORY,IMPACT,ADULTS",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7472011,
56,On the Better Performance of Pianists with Motor Imagery-Based Brain-Computer Interface Systems,20,16,,"Riquelme-Ros Jose-Vicente,Rodriguez-Bermudez German,Rodriguez-Rodriguez Ignacio,Rodriguez Jose-Victor,Molina-Garcia-Pardo Jose-Maria","Riquelme-Ros JV,Rodriguez-Bermudez G,Rodriguez-Rodriguez I,Rodriguez JV,Molina-Garcia-Pardo JM",Rodriguez JV,10.3390/s20164452,"Univ Politecn Cartagena, Dept Tecnol Informac & Comunicac, E-30202 Cartagena, Colombia.","Motor imagery (MI)-based brain-computer interface (BCI) systems detect electrical brain activity patterns through electroencephalogram (EEG) signals to forecast user intention while performing movement imagination tasks. As the microscopic details of individuals' brains are directly shaped by their rich experiences, musicians can develop certain neurological characteristics, such as improved brain plasticity, following extensive musical training. Specifically, the advanced bimanual motor coordination that pianists exhibit means that they may interact more effectively with BCI systems than their non-musically trained counterparts; this could lead to personalized BCI strategies according to the users' previously detected skills. This work assessed the performance of pianists as they interacted with an MI-based BCI system and compared it with that of a control group. The Common Spatial Patterns (CSP) and Linear Discriminant Analysis (LDA) machine learning algorithms were applied to the EEG signals for feature extraction and classification, respectively. The results revealed that the pianists achieved a higher level of BCI control by means of MI during the final trial (74.69%) compared to the control group (63.13%). The outcome indicates that musical training could enhance the performance of individuals using BCI systems.","brain-computer interface,motor imagery,machine learning,internet of things,pianists",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"MUSICIANS,BRAIN,PIANO,PLAYERS,EEG,MODULATION,PLASTICITY,TASKS,BCI,MU",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7472325,
57,Comparison of Regression and Classification Models for User-Independent and Personal Stress Detection,20,16,,"Siirtola Pekka,Roning Juha","Siirtola P,Roning J",Siirtola P,10.3390/s20164402,University of Oulu,"In this article, regression and classification models are compared for stress detection. Both personal and user-independent models are experimented. The article is based on publicly open dataset called AffectiveROAD, which contains data gathered using Empatica E4 sensor and unlike most of the other stress detection datasets, it contains continuous target variables. The used classification model is Random Forest and the regression model is Bagged tree based ensemble. Based on experiments, regression models outperform classification models, when classifying observations as stressed or not-stressed. The best user-independent results are obtained using a combination of blood volume pulse and skin temperature features, and using these the average balanced accuracy was 74.1% with classification model and 82.3% using regression model. In addition, regression models can be used to estimate the level of the stress. Moreover, the results based on models trained using personal data are not encouraging showing that biosignals have a lot of variation not only between the study subjects but also between the session gathered from the same person. On the other hand, it is shown that with subject-wise feature selection for user-independent model, it is possible to improve recognition models more than by using personal training data to build personal models. In fact, it is shown that with subject-wise feature selection, the average detection rate can be improved as much as 4%-units, and it is especially useful to reduce the variance in the recognition rates between the study subjects.","stress detection,wearable sensors,regression,classification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7472084,
58,Data Augmentation for Motor Imagery Signal Classification Based on a Hybrid Neural Network,20,16,,"Zhang Kai,Xu Guanghua,Han Zezhen,Ma Kaiquan,Zheng Xiaowei,Chen Longting,Duan Nan,Zhang Sicong","Zhang K,Xu GH,Han ZZ,Ma KQ,Zheng XW,Chen LT,Duan N,Zhang SC",Xu GH,10.3390/s20164485,Xi'an Jiaotong University,"As an important paradigm of spontaneous brain-computer interfaces (BCIs), motor imagery (MI) has been widely used in the fields of neurological rehabilitation and robot control. Recently, researchers have proposed various methods for feature extraction and classification based on MI signals. The decoding model based on deep neural networks (DNNs) has attracted significant attention in the field of MI signal processing. Due to the strict requirements for subjects and experimental environments, it is difficult to collect large-scale and high-quality electroencephalogram (EEG) data. However, the performance of a deep learning model depends directly on the size of the datasets. Therefore, the decoding of MI-EEG signals based on a DNN has proven highly challenging in practice. Based on this, we investigated the performance of different data augmentation (DA) methods for the classification of MI data using a DNN. First, we transformed the time series signals into spectrogram images using a short-time Fourier transform (STFT). Then, we evaluated and compared the performance of different DA methods for this spectrogram data. Next, we developed a convolutional neural network (CNN) to classify the MI signals and compared the classification performance of after DA. The Frechet inception distance (FID) was used to evaluate the quality of the generated data (GD) and the classification accuracy, and mean kappa values were used to explore the best CNN-DA method. In addition, analysis of variance (ANOVA) and pairedt-tests were used to assess the significance of the results. The results showed that the deep convolutional generative adversarial network (DCGAN) provided better augmentation performance than traditional DA methods: geometric transformation (GT), autoencoder (AE), and variational autoencoder (VAE) (p< 0.01). Public datasets of the BCI competition IV (datasets 1 and 2b) were used to verify the classification performance. Improvements in the classification accuracies of 17% and 21% (p< 0.01) were observed after DA for the two datasets. In addition, the hybrid network CNN-DCGAN outperformed the other classification methods, with average kappa values of 0.564 and 0.677 for the two datasets.","motor imagery,CNN,DCGAN,data augmentation,classification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"BRAIN-COMPUTER,INTERFACES,EEG,SIGNALS,PERFORMANCE",SENSORS,https://www.mdpi.com/1424-8220/20/16/4485/pdf,
59,Capture and visualisation of text understanding through semantic annotations and semantic networks for teaching and learning,46,4,528-543,"Willrich Roberto,Mittmann Adiel,Fileto Renato,dos Santos Alckmar Luiz","Willrich R,Mittmann A,Fileto R,dos Santos AL",Willrich R,10.1177/0165551519849514,Universidade Federal de Santa Catarina (UFSC),"During various learning activities, teachers and students need to clarify, explore and share their understanding of reading materials. For doing this, they must make explicit the mental representation constructed during the reading process. In this article, we propose an approach combining semantic annotations and semantic networks as formal means for elicitation, structuring, formalisation, analysis and sharing of teachers' and students' understanding of textual materials that they are asked to read in learning tasks. In the proposed approach, teachers can create learning tasks, in which students are asked to semantically annotate a text by associating portions of it to resources described in a Knowledge Base (KB) in accordance with a provided ontology. New instances can be created by students or teachers in the KB during the annotation process. We show how semantic networks can be used to visualise extracts of the resulting KB, and to help people organise their comprehension of texts. In addition, teachers can assess student evolution by analysing the semantic networks that each one produces during the reading and annotation process. This approach is implemented by using our annotation tool, integrated with a digital repository and a virtual learning environment. An empirical evaluation of the benefits of the proposed approach in a literature case study confirms that it facilitates information extraction, sharing and analysis, contributing to leverage teaching and learning.","eLearning,information elicitation,semantic annotations,semantic network visualisation",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Computer Science,Information Science & Library Science",,,,JOURNAL OF INFORMATION SCIENCE,,
60,Optimization of FireNet for Liver Lesion Classification,9,8,,"Kashala Kabe Gedeon,Song Yuqing,Liu Zhe","Kabe GK,Song YQ,Liu Z",Liu Z,10.3390/electronics9081237,Jiangsu University,"In recent years, deep learning techniques, and in particular convolutional neural networks (CNNs) methods have demonstrated a superior performance in image classification and visual object recognition. In this work, we propose a classification of four types of liver lesions, namely, hepatocellular carcinoma, metastases, hemangiomas, and healthy tissues using convolutional neural networks with a succinct model called FireNet. We improved speed for quick classification and decreased the model size and the number of parameters by using fire modules from SqueezeNet. We have used bypass connection by adding it around Fire modules for learning a residual function between input and output, and to solve the vanishing gradient problem. We have proposed a new Particle Swarm Optimization (NPSO) to optimize the network parameters in order to further boost the performance of the proposed FireNet. The experimental results show that the parameters of FireNet are 9.5 times smaller than GoogLeNet, 51.6 times smaller than AlexNet, and 75.8 smaller than ResNet. The size of FireNet is reduced 16.6 times smaller than GoogLeNet, 75 times smaller than AlexNet and 76.6 times smaller than ResNet. The final accuracy of our proposed FireNet model was 89.2%.","deep learning,classification of liver lesions,computed tomography (CT),particle swarm optimization (PSO),convolutional neural networks (CNN),squeezeNet",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"CONVOLUTIONAL,NEURAL-NETWORKS,DIAGNOSIS,CT,SYSTEM",ELECTRONICS,https://www.mdpi.com/2079-9292/9/8/1237/pdf,
61,Machine learning-driven new material discovery,2,8,3115-3130,"Cai Jiazhen,Chu Xuan,Xu Kun,Li Hongbo,Wei Jing","Cai JZ,Chu X,Xu K,Li HB,Wei J",Wei J,10.1039/d0na00388c,Beijing University of Posts & Telecommunications,"New materials can bring about tremendous progress in technology and applications. However, the commonly used trial-and-error method cannot meet the current need for new materials. Now, a newly proposed idea of using machine learning to explore new materials is becoming popular. In this paper, we review this research paradigm of applying machine learning in material discovery, including data preprocessing, feature engineering, machine learning algorithms and cross-validation procedures. Furthermore, we propose to assist traditional DFT calculations with machine learning for material discovery. Many experiments and literature reports have shown the great effects and prospects of this idea. It is currently showing its potential and advantages in property prediction, material discovery, inverse design, corrosion detection and many other aspects of life.","SUPPORT VECTOR MACHINES,CROSS-VALIDATION,MODEL SELECTION,NEURAL-NETWORKS,PREDICTION,REGRESSION,CLASSIFICATION,DESIGN,ALGORITHMS",Review,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Science & Technology - Other Topics,Materials Science",,4.553,"SEMICONDUCTOR,MATERIAL,LIBRARIES,SUPPORT,VECTOR,MACHINES,CROSS-VALIDATION,MODEL,SELECTION,NEURAL-NETWORKS,PREDICTION,REGRESSION,CLASSIFICATION,DESIGN,ALGORITHMS",NANOSCALE ADVANCES,https://pubs.rsc.org/en/content/articlepdf/2020/na/d0na00388c,
62,Through-the-wall radar detection using machine learning,7,,,"Wood Aihua,Wood Ryan,Charnley Matthew","Wood A,Wood R,Charnley M",Wood A,10.1016/j.rinam.2020.100106,Air Force Institute of Technology (AFIT),"This paper explores the through-the-wall inverse scattering problem via machine learning. The reconstruction method seeks to discover the shape, location, and type of hidden objects behind walls, as well as identifying certain material properties of the targets. We simulate RF sources and receivers placed outside the room to generate observation data with objects randomly placed inside the room. We experiment with two types of neural networks and use an 80-20 train-test split for reconstruction and classification. (C) 2020 The Author(s). Published by Elsevier B.V.",,Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Mathematics,,,,RESULTS IN APPLIED MATHEMATICS,https://doi.org/10.1016/j.rinam.2020.100106,
63,Assessment of Leaf Chlorophyll Content Models for Winter Wheat Using Landsat-8 Multispectral Remote Sensing Data,12,16,,"Zhou Xianfeng,Zhang Jingcheng,Chen Dongmei,Huang Yanbo,Kong Weiping,Yuan Lin,Ye Huichun,Huang Wenjiang","Zhou XF,Zhang JC,Chen DM,Huang YB,Kong WP,Yuan L,Ye HC,Huang WJ",Huang WJ,10.3390/rs12162574,Chinese Academy of Sciences,"The leaf chlorophyll content (LCC) is a critical index to characterize crop growth conditions, photosynthetic capacity, and physiological status. Its dynamic change characteristics are of great significance for monitoring crop growth conditions and understanding the process of material and energy exchange between crops and the environment. Extensive research has focused on LCC retrieval with hyperspectral data onboard various sensor platforms. Nevertheless, limited attention has been paid to LCC inversion from multispectral data, such as the data from Landsat-8, and the potentials and capabilities of the data for crop LCC estimation have not been fully explored. The present study made use of Landsat-8 Operational Land Imager (OLI) imagery and the corresponding field experimental data to evaluate their capabilities and potentials for LCC modeling using four different retrieval methods: vegetation indices (VIs), machine learning regression algorithms (MLRAs), lookup-table (LUT)-based inversion, and hybrid regression approaches. The results showed that the modified triangular vegetation index (MTVI2) exhibited the best estimate accuracy for LCC retrieval with a root mean square error (RMSE) of 5.99 mu g/cm(2)and a relative RMSE (RRMSE) of 10.49%. Several other vegetation indices that were established from red and near-infrared (NIR) bands also exhibited good accuracy. Models established from Gaussian process regression (GPR) achieved the highest accuracy for LCC retrieval (RMSE = 5.50 mu g/cm(2), RRMSE = 9.62%) compared with other MLRAs. Moreover, red and NIR bands outweighed other bands in terms of GPR modelling. LUT-based inversion methods with the ""K(x) = -log (x) + x"" cost function that belongs to the ""minimum contrast estimates"" family showed the best estimation results (RMSE = 8.08 mu g/cm(2), RRMSE = 14.14%), and the addition of multiple solution regularization strategies effectively improved the inversion accuracy. For hybrid regression methods, the use of active learning (AL) techniques together with GPR for LCC modelling significantly increased the estimation accuracy, and the combination of entropy query by bagging (EQB) AL and GPR had the best accuracy for LCC estimation (RMSE = 12.43 mu g/cm(2), RRMSE = 21.77%). Overall, our study suggest that Landsat-8 OLI data are suitable for crop LCC retrieval and could provide a basis for LCC estimation with similar multispectral datasets.","leaf chlorophyll content,Landsat-8,vegetation index,machine learning,lookup table-based inversion,hybrid regression",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Geology,Remote Sensing,Imaging Science & Photographic Technology",,5.353,"AREA,INDEX,RETRIEVAL,BIOPHYSICAL,PARAMETERS,VEGETATION,INDEXES,INVERSION,LAI,REGRESSION,CANOPIES,SENTINEL-2,ALGORITHMS,PREDICTION",REMOTE SENSING,https://www.mdpi.com/2072-4292/12/16/2574/pdf,
64,goFOOD(TM): An Artificial Intelligence System for Dietary Assessment,20,15,,"Lu Ya,Stathopoulou Thomai,Vasiloglou Maria F.,Pinault Lillian F.,Kiley Colleen,Spanakis Elias K.,Mougiakakou Stavroula","Lu Y,Stathopoulou T,Vasiloglou MF,Pinault LF,Kiley C,Spanakis EK,Mougiakakou S",Mougiakakou S,10.3390/s20154283,University of Bern,"Accurate estimation of nutritional information may lead to healthier diets and better clinical outcomes. We propose a dietary assessment system based on artificial intelligence (AI), named goFOOD(TM). The system can estimate the calorie and macronutrient content of a meal, on the sole basis of food images captured by a smartphone. goFOOD(TM)requires an input of two meal images or a short video. For conventional single-camera smartphones, the images must be captured from two different viewing angles; smartphones equipped with two rear cameras require only a single press of the shutter button. The deep neural networks are used to process the two images and implements food detection, segmentation and recognition, while a 3D reconstruction algorithm estimates the food's volume. Each meal's calorie and macronutrient content is calculated from the food category, volume and the nutrient database. goFOOD(TM)supports 319 fine-grained food categories, and has been validated on two multimedia databases that contain non-standardized and fast food meals. The experimental results demonstrate that goFOOD(TM)performed better than experienced dietitians on the non-standardized meal database, and was comparable to them on the fast food database. goFOOD(TM)provides a simple and efficient solution to the end-user for dietary assessment.","carbohydrate,protein,fat,calorie,nutrient estimation,computer vision,smartphone",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"FOOD,RECOGNITION,CARBOHYDRATE,CHILDREN",SENSORS,https://boris.unibe.ch/145662/2/sensors-20-04283-v2-1.pdf,
65,"Evaluation of Salmon, Tuna, and Beef Freshness Using a Portable Spectrometer",20,15,,"Moon Eui Jung,Kim Youngsik,Xu Yu,Na Yeul,Giaccia Amato J.,Lee Jae Hyung","Moon EJ,Kim Y,Xu Y,Na Y,Giaccia AJ,Lee JH",Lee JH,10.3390/s20154299,"Stratio Inc, Palo Alto, CA 94303 USA.","There has been strong demand for the development of an accurate but simple method to assess the freshness of food. In this study, we demonstrated a system to determine food freshness by analyzing the spectral response from a portable visible/near-infrared (VIS/NIR) spectrometer using the Convolutional Neural Network (CNN)-based machine learning algorithm. Spectral response data from salmon, tuna, and beef incubated at 25 degrees C were obtained every minute for 30 h and then categorized into three states of ""fresh"", ""likely spoiled"", and ""spoiled"" based on time and pH. Using the obtained spectral data, a CNN-based machine learning algorithm was built to evaluate the freshness of experimental objects. In addition, a CNN-based machine learning algorithm with a shift-invariant feature can minimize the effect of the variation caused using multiple devices in a real environment. The accuracy of the obtained machine learning model based on the spectral data in predicting the freshness was approximately 85% for salmon, 88% for tuna, and 92% for beef. Therefore, our study demonstrates the practicality of a portable spectrometer in food freshness assessment.","food freshness,portable spectrometer,near-infrared,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"STAPHYLOCOCCUS-AUREUS,STORAGE,MEAT,SPECTROSCOPY,SPOILAGE,LIFE",SENSORS,https://ora.ox.ac.uk/objects/uuid:52d1cc7b-9b45-43a8-b90f-43b887172166/download_file?safe_filename=Evaluation%2520of%2520Salmon%2C%2520Tuna%2C%2520and%2520Beef%2520Freshness%2520Using%2520a%2520Portable%2520Spectrometer.pdf&type_of_work=Journal+article,
66,Concept attribution: Explaining CNN decisions to physicians,123,,,"Graziani M.,Andrearczyk V,Marchand-Maillet S.,Mueller H.","Graziani M,Andrearczyk V,Marchand-Maillet S,Muller H",Graziani M,10.1016/j.compbiomed.2020.103865,University of Applied Sciences & Arts Western Switzerland,"Deep learning explainability is often reached by gradient-based approaches that attribute the network output to perturbations of the input pixels. However, the relevance of input pixels may be difficult to relate to relevant image features in some applications, e.g. diagnostic measures in medical imaging. The framework described in this paper shifts the attribution focus from pixel values to user-defined concepts. By checking if certain diagnostic measures are present in the learned representations, experts can explain and entrust the network output. Being post-hoc, our method does not alter the network training and can be easily plugged into the latest state-of-the-art convolutional networks. This paper presents the main components of the framework for attribution to concepts, in addition to the introduction of a spatial pooling operation on top of the feature maps to obtain a solid interpretability analysis. Furthermore, regularized regression is analyzed as a solution to the regression overfitting in high-dimensionality latent spaces. The versatility of the proposed approach is shown by experiments on two medical applications, namely histopathology and retinopathy, and on one non-medical task, the task of handwritten digit classification. The obtained explanations are in line with clinicians' guidelines and complementary to widely used visualization tools such as saliency maps.","Machine learning,Interpretability,Biomedical imaging,Deep learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,,COMPUTERS IN BIOLOGY AND MEDICINE,https://doi.org/10.1016/j.compbiomed.2020.103865,
67,Accuracy of deep learning for automated detection of pneumonia using chest X-Ray images: A systematic review and meta-analysis,123,,,"Li Yuanyuan,Zhang Zhenyan,Dai Cong,Dong Qiang,Badrigilan Samireh","Li YY,Zhang ZY,Dai C,Dong Q,Badrigilan S",Dong Q,10.1016/j.compbiomed.2020.103898,"Qingzhou Hosp Tradit Chinese Med, Dept Imaging, Qingzhou 262500, Peoples R China.","Background: Recently, deep learning (DL) algorithms have received widespread popularity in various medical diagnostics. This study aimed to evaluate the diagnostic performance of DL models in the detection and classifying of pneumonia using chest X-ray (CXR) images.
Methods: PubMed, Embase, Scopus, Web of Science, and Google Scholar were searched in order to retrieve all studies that implemented a DL algorithm for discriminating pneumonia patients from healthy controls using CXR images. We used bivariate linear mixed models to pool diagnostic estimates including sensitivity (SE), specificity (SP), positive likelihood ratio (PLR), negative likelihood ratio (NLR), and diagnostic odds ratio (DOR). Also, the area under receiver operating characteristics curves (AUC) of the included studies was used to estimate the diagnostic value.
Results: The pooled SE, SP, PLR, NLR, DOR and AUC for DL in discriminating pneumonia CXRs from controls were 0.98 (95% confidence interval (CI): 0.96-0.99), 0.94 (95% CI: 0.90-0.96), 15.35 (95% CI: 10.04-23.48), 0.02 (95% CI: 0.01-0.04), 718.13 (95% CI: 288.45-1787.93), and 0.99 (95% CI: 0.98-100), respectively. The pooled SE, SP, PLR, NLR, DOR and AUC for DL in discriminating bacterial from viral pneumonia using CXR radiographs were 0.89 (95% CI: 0.79-0.94), 0.89 (95% CI: 0.78-0.95), 8.34 (95% CI: 3.75-18.55), 0.13 (95% CI: 0.06-0.26), 66.14 (95% CI: 17.34-252.37), and 0.95 (0.93-0.97).
Conclusion: DL indicated high accuracy performance in classifying pneumonia from normal CXR radiographs and also in distinguishing bacterial from viral pneumonia. However, major methodological concerns should be addressed in future studies for translating to the clinic.","Deep learning,Artificial intelligence,Meta-analysis,CXR,Pneumonia",Review,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,,COMPUTERS IN BIOLOGY AND MEDICINE,,
68,Automatic skin lesion segmentation based on FC-DPN,123,,,"Shan Pufang,Wang Yiding,Fu Chong,Song Wei,Chen Junxin","Shan PF,Wang YD,Fu C,Song W,Chen JX",Fu C,10.1016/j.compbiomed.2020.103762,Northeastern University - China,"Automatic skin lesion segmentation in dermoscopy images is challenging due to the diversity of skin lesion characteristics, low contrast between normal skin and lesions, and the existence of many artefacts in the images. To meet these challenges, we propose a novel segmentation topology called FC-DPN, which is built upon a fully convolutional network (FCN) and dual path network (DPN). The DPN inherits the advantages of residual and densely connected paths, enabling effective feature re-usage and re-exploitation. We replace dense blocks in fully convolutional DenseNets (FC-DenseNets) with two kinds of sub-DPN blocks, namely, sub-DPN projection blocks and sub-DPN processing blocks. This framework enables FC-DPN to acquire more representative and discriminative features for more accurate segmentation. Many images in the original ISBI 2017 Skin Lesion Challenge test dataset are given the incorrect or inaccurate ground truths, and these ground truths have been revised. The revised test dataset is called the modified ISBI 2017 Skin Lesion Challenge test dataset. The proposed method achieves an average Dice coefficient of 88.13% and a Jaccard index of 80.02% on the modified ISBI 2017 Skin Lesion Challenge test dataset and 90.26% and 83.51%, respectively, on the PH2 dataset. Extensive experimental results on the two datasets demonstrate that the proposed method exhibits better performance than FCDenseNets and other well-established segmentation algorithms.","Automatic skin lesion segmentation,DenseNets,ResNets,DPN,FC-DenseNets,Dermoscopy",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"DERMOSCOPY,IMAGES,NETWORKS,DROPOUT",COMPUTERS IN BIOLOGY AND MEDICINE,,
69,Deep convolutional neural network-based anomaly detection for organ classification in gastric X-ray examination,123,,,"Togo Ren,Watanabe Haruna,Ogawa Takahiro,Haseyama Miki","Togo R,Watanabe H,Ogawa T,Haseyama M",Togo R,10.1016/j.compbiomed.2020.103903,Hokkaido University,"Aim: The aim of this study was to determine whether our deep convolutional neural network-based anomaly detection model can distinguish differences in esophagus images and stomach images obtained from gastric X-ray examinations.
Methods: A total of 6012 subjects were analyzed as our study subjects. Since the number of esophagus X-ray images is much smaller than the number of gastric X-ray images taken in X-ray examinations, we took an anomaly detection approach to realize the task of organ classification. We constructed a deep autoencoding gaussian mixture model (DAGMM) with a convolutional autoencoder architecture. The trained model can produce an anomaly score for a given test X-ray image. For comparison, the original DAGMM, AnoGAN, and a One-Class Support Vector Machine (OCSVM) that were trained with features obtained by a pre-trained Inception-v3 network were used.
Results: Sensitivity, specificity, and the calculated harmonic mean of the proposed method were 0.956, 0.980, and 0.968, respectively. Those of the original DAGMM were 0.932, 0.883, and 0.907, respectively. Those of AnoGAN were 0.835, 0.833, and 0.834, respectively, and those of OCSVM were 0.932, 0.935, and 0.934, respectively. Experimental results showed the effectiveness of the proposed method for an organ classification task.
Conclusion: Our deep convolutional neural network-based anomaly detection model has shown the potential for clinical use in organ classification.","Deep learning,Medical image analysis,Gastric X-ray examination,Esophagus,Stomach,Anomaly detection,Autoencoder",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"IMAGE,SEGMENTATION,MACHINE,SVM",COMPUTERS IN BIOLOGY AND MEDICINE,https://eprints.lib.hokudai.ac.jp/dspace/bitstream/2115/82588/1/togo_cbm_op.pdf,
70,Unsupervised smoke to desmoked laparoscopic surgery images using contrast driven Cyclic-DesmokeGAN,123,,,"Venkatesh Vishal,Sharma Neeraj,Srivastava Vivek,Singh Munendra","Venkatesh V,Sharma N,Srivastava V,Singh M",Singh M,10.1016/j.compbiomed.2020.103873,Manipal Academy of Higher Education (MAHE),"In laparoscopic surgery, energized dissecting devices and laser ablation causes smoke, which degrades the visual quality of the operative field. This paper proposes an unsupervised approach to desmoke laparoscopic images called Cyclic-DesmokeGAN. In the generator, multi-scale residual blocks help to alleviate the smoke component at multiple scales, while refinement module helps to obtain desmoked images with sharper boundaries. As the presence of smoke degrades contrast and fine structure, the proposed method utilizes high boost filtered image at each encoder layer. The contrast loss improves overall contrast, thereby reducing the smoke, while Unsharp Regularization loss helps to stabilize the network. The proposed Cyclic-DesmokeGAN is tested on 200 smoke images obtained from Cholec80 dataset consisting of videos of cholecystectomy surgeries. The results depict effectiveness, as proposed approach achieved 3.47 +/- 0.09 Contrast-Distorted Images Quality, 4.15 +/- 0.74 Naturalness Image Quality Evaluator, and 0.23 +/- 0.00 Fog Aware Density Evaluator, these indexes are best in comparison to other state-of-the-art methods.","GANs,Desmoking,Laparoscopic surgery,Enhancement",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,,COMPUTERS IN BIOLOGY AND MEDICINE,,
71,Towards Accurate and Reproducible Uranium Isotopic Analysis via Atom Probe Mass Spectrometry.,26,Suppl 2,176-177,",,,,","Meisenkothen Frederick,McLean Mark,Kalish Irina,Samarov Daniel V,Steel Eric B",,10.1017/s1431927620013689,,,,Journal Article,,,,,,,,
72,Multi-branch cross attention model for prediction of KRAS mutation in rectal cancer with t2-weighted MRI,50,8,2352-2369,"Wang JiaWen,Cui YanFen,Shi GuoHua,Zhao JuanJuan,Yang XiaoTang,Qiang Yan,Du QianQian,Ma Yue,Kazihise Ntikurako Guy-Fernand","Wang JW,Cui YF,Shi GH,Zhao JJ,Yang XT,Qiang Y,Du QQ,Ma Y,Kazihise NGF",Zhao JJ,10.1007/s10489-020-01658-8,Taiyuan University of Technology,"The accurate identification of KRAS mutation status on medical images is critical for doctors to specify treatment options for patients with rectal cancer. Deep learning methods have recently been successfully introduced to medical diagnosis and treatment problems, although substantial challenges remain in the computer-aided diagnosis (CAD) due to the lack of large training datasets. In this paper, we propose a multi-branch cross attention model (MBCAM) to separate KRAS mutation cases from wild type cases using limited T2-weighted MRI data. Our model is built on multiple different branches generated based on our existing MRI data, which can take full advantage of the information contained in small data sets. The cross attention block (CA block) is proposed to fuse formerly independent branches to ensure that the model can learn as many common features as possible for preventing the overfitting of the model due to the limited dataset. The inter-branch loss is proposed to constrain the learning range of the model, confirming that the model can learn more general features from multi-branch data. We tested our method on the collected dataset and compared it to four previous works and five popular deep learning models using transfer learning. Our result shows that the MBCAM achieved an accuracy of 88.92% for the prediction of KRAS mutations with an AUC of 95.75%. These results are a significant improvement over those existing methods (p < 0.05).","Rectal cancer,KRAS mutation,Deep learning,Attention mechanism,T2 MRI",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,4.602,FEATURES,APPLIED INTELLIGENCE,,
73,A survey of fracture detection techniques in bone X-ray images,53,6,4475-4517,"Joshi Deepa,Singh Thipendra P.","Joshi D,Singh TP",Joshi D,10.1007/s10462-019-09799-0,University of Petroleum & Energy Studies (UPES),"Radiologists interprets X-ray samples by visually inspecting them to diagnose the presence of fractures in various bones. Interpretation of radiographs is a time-consuming and intense process involving manual examination of fractures. In addition, clinician's shortage in medically under-resourced areas, unavailability of expert radiologists in busy clinical settings or fatigue caused due to demanding workloads could lead to false detection rate and poor recovery of the fractures. A comprehensive study is imparted here covering fracture diagnosis with the aim to assist investigators in developing models that automatically detects fracture in human bones. The paper is presented in five folds. Firstly, we discuss data preparation stage. Second, we present various image-processing techniques used for fracture detection. Third, we analyze conventional and deep learning based techniques for diagnosing bone fractures. Fourth, we make comparative analysis of existing techniques. Fifth, we discuss different issues and challenges faced by researches while dealing with fracture detection.","X-rays,Radiology,Fractures,Deep learning,Convolutional networks",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,7.857,"CONVOLUTIONAL,NEURAL-NETWORKS,DEEP,RADIOLOGY,ENSEMBLE,CLASSIFICATION,RELIABILITY,MODEL",ARTIFICIAL INTELLIGENCE REVIEW,,
74,Prediction of wear properties of graphene-Si3N4 reinforced titanium hybrid composites by artificial neural network,7,8,,"Mutuk Tugba,Gurbuz Mevlut,Mutuk Halil","Mutuk T,Gurbuz M,Mutuk H",Mutuk T,10.1088/2053-1591/abaac8,Ondokuz Mayis University,"In this study, we have employed artificial neural network (ANN) method to predict wear properties of titanium hybrid composites produced by powder metallurgy (PM) method. Titanium (Ti) was used as a matrix materials and graphene nano-platelets (GNPs)-Si3N4 were used as reinforcement materials in hybrid composites. A back-propagation neural network with 3-6-1 architecture was developed to predict wear rates by considering weight fraction reinforcements, load and density as model variables. The well trained ANN system predicted the experimental results in a good agreement with the experimental data. This refers that ANN can be used to evaluate wear rate of samples in a cost effective way.","graphene,titanium,Si3N4,hybrid composite,wear rate,artificial neural network",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Materials Science,,1.618,"SUPERIOR,TENSILE,PROPERTIES,MECHANICAL-PROPERTIES,THERMAL-PROPERTIES,NANOCOMPOSITES,PURE,MICROSTRUCTURE,FABRICATION,EVOLUTION",MATERIALS RESEARCH EXPRESS,https://doi.org/10.1088/2053-1591/abaac8,
75,Evaluation of models to predict the influence of chemical pretreatment on the peels of Nephelium lappaceum L. based on pyrolysis kinetic parameters obtained using a combined Fraser -Suzuki function and Friedman?s isoconversional method,149,,,"Castro Joao Daniel S.,da Silva Erik Galvao P.,Virgens Cesario F.","Castro JDS,da Silva EGP,Virgens CF",Virgens CF,10.1016/j.jaap.2020.104827,Universidade do Estado Bahia,,"MUNICIPAL SOLID-WASTE,LIGNOCELLULOSIC BIOMASS PYROLYSIS,ACID-ACETONE PRETREATMENT,THERMAL-DEGRADATION,MASTER PLOTS,TG-FTIR,CELLULOSE,DECOMPOSITION,HYDROLYSIS,ENERGY",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Chemistry,Energy & Fuels,Engineering",,5.259,"MUNICIPAL,SOLID-WASTE,LIGNOCELLULOSIC,BIOMASS,PYROLYSIS,ACID-ACETONE,PRETREATMENT,THERMAL-DEGRADATION,MASTER,PLOTS,TG-FTIR,CELLULOSE,DECOMPOSITION,HYDROLYSIS,ENERGY",JOURNAL OF ANALYTICAL AND APPLIED PYROLYSIS,,
76,Semi-supervised generative adversarial networks for the segmentation of the left ventricle in pediatric MRI,123,,,"Decourt Colin,Duong Luc","Decourt C,Duong L",Decourt C,10.1016/j.compbiomed.2020.103884,"Bordeaux INP ENSEIRB MATMECA, 1 Ave Dr Albert Schweitzer, Talence, France.","Segmentation of the left ventricle in magnetic resonance imaging (MRI) is important for assessing cardiac function. We present DT-GAN, a generative adversarial network (GAN) segmentation approach for the identification of the left ventricle in pediatric MRI. Segmentation of the left ventricle requires a large amount of annotated data; generating such data can be time-consuming and subject to observer variability. Additionally, it can be difficult to accomplish in a clinical setting. During the training of our GAN, we therefore introduce a semi-supervised semantic segmentation to reduce the number of images required for training, while maintaining a good segmentation accuracy. The GAN generator produces a segmentation label map and its discriminator outputs a confidence map, which gives the probability of a pixel coming from the label or from the generator. Moreover, we propose a new formulation of the GAN loss function based on distance transform and pixel-wise cross-entropy. This new loss function provides a better segmentation of boundary pixels, by favoring the correct classification of those pixels rather than focusing on pixels that are farther away from the boundary between anatomical structures. Our proposed method achieves a mean Hausdorff distance of 2.16 mm +/- 0.42 mm (2.28 mm +/- 0.21 mm for U-Net) and a Dice score of 0.88 +/- 0.08 (0.91 +/- 0.12 for U-Net) for the endocardium segmentation, using 50% of the annotated data. For the epicardium segmentation, we achieve a mean Hausdorff distance of 2.23 mm +/- 0.35 mm (2.34 mm +/- 0.39 mm for U-Net) and a Dice score of 0.93 mm +/- 0.04 mm (0.89 +/- 0.09 for U-Net). For the myocardium segmentation, we achieve a mean Hausdorff distance of 2.98 mm +/- 0.43 mm (3.04 mm +/- 0.27 mm for U-Net) and a Dice score of 0.79 mm +/- 0.10 mm (0.74 +/- 0.04 for U-Net). This new model could be very useful for the automatic analysis of cardiac MRI and for conducting large-scale studies based on MRI readings, with a limited amount of training data.","Segmentation,Generative adversarial networks,Semi-supervised learning,Distance transform,Cardiac,Magnetic resonance imaging",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"IMAGES,SHAPE",COMPUTERS IN BIOLOGY AND MEDICINE,https://www.sciencedirect.com/science/article/am/pii/S0010482520302353,
77,A computational investigation into rate-dependant vectorcardiogram changes due to specific fibrosis patterns in non-ischaemic dilated cardiomyopathy,123,,,"Gemmell Philip M.,Gillette Karli,Balaban Gabriel,Rajani Ronak,Vigmond Edward J.,Plank Gernot,Bishop Martin J.","Gemmell PM,Gillette K,Balaban G,Rajani R,Vigmond EJ,Plank G,Bishop MJ",Gemmell PM,10.1016/j.compbiomed.2020.103895,Guy's & St Thomas' NHS Foundation Trust,"Patients with scar-associated fibrotic tissue remodelling are at greater risk of ventricular arrhythmic events, but current methods to detect the presence of such remodelling require invasive procedures. We present here a potential method to detect the presence, location and dimensions of scar using pacing-dependent changes in the vectorcardiogram (VCG). Using a clinically-derived whole-torso computational model, simulations were conducted at both slow and rapid pacing for a variety of scar patterns within the myocardium, with various VCG-derived metrics being calculated, with changes in these metrics being assessed for their ability to discern the presence and size of scar. Our results indicate that differences in the dipole angle at the end of the QRS complex and differences in the QRS area and duration may be used to predict scar properties. Using machine learning techniques, we were also able to predict the location of the scar to high accuracy, using only these VCG-derived rate-dependent changes as input. Such a non-invasive predictive tool for the presence of scar represents a potentially useful clinical tool for identifying patients at arrhythmic risk.","Vectorcardiogram,Non-ischaemic dilated cardiomyopathy,Scar,Fibrosis,Conduction slowing,Computer modelling,Random forests",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"PERIODIC,REPOLARIZATION,DYNAMICS,SUDDEN,CARDIAC,DEATH,HEART,ACTIVATION,MORTALITY",COMPUTERS IN BIOLOGY AND MEDICINE,https://doi.org/10.1016/j.compbiomed.2020.103895,
78,Multi-channel EEG-based emotion recognition via a multi-level features guided capsule network,123,,,"Liu Yu,Ding Yufeng,Li Chang,Cheng Juan,Song Rencheng,Wan Feng,Chen Xun","Liu Y,Ding YF,Li C,Cheng J,Song RC,Wan F,Chen X",Li C,10.1016/j.compbiomed.2020.103927,Hefei University of Technology,"In recent years, deep learning (DL) techniques, and in particular convolutional neural networks (CNNs), have shown great potential in electroencephalograph (EEG)-based emotion recognition. However, existing CNN-based EEG emotion recognition methods usually require a relatively complex stage of feature pre-extraction. More importantly, the CNNs cannot well characterize the intrinsic relationship among the different channels of EEG signals, which is essentially a crucial clue for the recognition of emotion. In this paper, we propose an effective multi-level features guided capsule network (MLF-CapsNet) for multi-channel EEG-based emotion recognition to overcome these issues. The MLF-CapsNet is an end-to-end framework, which can simultaneously extract features from the raw EEG signals and determine the emotional states. Compared with original CapsNet, it incorporates multi-level feature maps learned by different layers in forming the primary capsules so that the capability of feature representation can be enhanced. In addition, it uses a bottleneck layer to reduce the amount of parameters and accelerate the speed of calculation. Our method achieves the average accuracy of 97.97%, 98.31% and 98.32% on valence, arousal and dominance of DEAP dataset, respectively, and 94.59%, 95.26% and 95.13% on valence, arousal and dominance of DREAMER dataset, respectively. These results show that our method exhibits higher accuracy than the state-of-the-art methods.","Deep learning,Electroencephalogram (EEG),Emotion recognition,Capsule network",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,CLASSIFICATION,COMPUTERS IN BIOLOGY AND MEDICINE,,
79,Automated diagnosis of intestinal parasites: A new hybrid approach and its benefits,123,,,"Osaku D.,Cuba C. F.,Suzuki C. T. N.,Gomes J. F.,Falcao A. X.","Osaku D,Cuba CF,Suzuki CTN,Gomes JF,Falcao AX",Osaku D; Falcao AX,10.1016/j.compbiomed.2020.103917,Universidade Estadual de Campinas,"Intestinal parasites are responsible for several diseases in human beings. In order to eliminate the error-prone visual analysis of optical microscopy slides, we have investigated automated, fast, and low-cost systems for the diagnosis of human intestinal parasites. In this work, we present a hybrid approach that combines the opinion of two decision-making systems with complementary properties: (DS1) a simpler system based on very fast handcrafted image feature extraction and support vector machine classification and (DS2) a more complex system based on a deep neural network, Vgg-16, for image feature extraction and classification. DS1 is much faster than DS2, but it is less accurate than DS2. Fortunately, the errors of DS1 are not the same of DS2. During training, we use a validation set to learn the probabilities of misclassification by DS1 on each class based on its confidence values. When DS1 quickly classifies all images from a microscopy slide, the method selects a number of images with higher chances of misclassification for characterization and reclassification by DS2. Our hybrid system can improve the overall effectiveness without compromising efficiency, being suitable for the clinical routine - a strategy that might be suitable for other real applications. As demonstrated on large datasets, the proposed system can achieve, on average, 94.9%, 87.8%, and 92.5% of Cohen's Kappa on helminth eggs, helminth larvae, and protozoa cysts, respectively.","Image classification,Microscopy image analysis,Automated diagnosis of intestinal parasites,Support vector machines,Deep neural networks",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"CLASSIFICATION,EGGS,RECOGNITION,TRANSFORM",COMPUTERS IN BIOLOGY AND MEDICINE,http://arxiv.org/pdf/2101.06310,
80,Automated detection of severity of hypertension ECG signals using an optimal bi-orthogonal wavelet filter bank,123,,,"Rajput Jaypal Singh,Sharma Manish,Tan Ru San,Acharya U. Rajendra","Rajput JS,Sharma M,Tan RS,Acharya UR",Rajput JS,10.1016/j.compbiomed.2020.103924,"Institute of Infrastructure, Technology, Research & Management","Hypertension (HPT) is a serious risk factor for cardiovascular disease and if not controlled in the early stage, can lead to serious complications. Long-standing HPT can induce heart muscle hypertrophy which will be reflected on electrocardiography (ECG). However, early stage of HPT may have no clinically discernible ECG perturbations, and is difficult to diagnose manually from the standard ECG. Hence, we propose an automated ECG based system that can automatically detect the ECG changes in the early stages of HPT. This work is based on ECG signals obtained from 139 HPT patients (SHAREE database) and 52 healthy subjects (PTB database). The ECG signal is non-stationary with relatively short duration, and rhythmic. Two-band optimal bi-orthogonal wavelet filter bank (BOWFB) and machine learning are used to automatically diagnose low, high-risk hypertension, and healthy control using ECG signals. Five-level wavelet decomposition is used to produce six sub-bands (SBs) from each ECG signal using BOWFB. Sample and wavelet entropy features are calculated for all six SBs. The features calculated SBs are fed to the k-nearest neighbor (KNN), support vector machine (SVM), and ensemble bagged trees (EBT) classifiers. In this work, we have obtained the highest average classification accuracy of 99.95% and area under the curve of 1.00 using EBT classifier in classifying healthy control (HC), low-risk hypertension (LRHPT) and high-risk hypertension (HRHPT) classes with ten-fold cross validation strategy. Hence the developed system can be used in clinics, or even in remote detection of HPT stages using ECG signals.","Hypertension,ECG signal,Wavelets decomposition,Optimization problem,Bi-orthogonal filter bank design,HPT ECG signal classification",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"LEFT-VENTRICULAR,HYPERTROPHY,DESIGN,SCORE",COMPUTERS IN BIOLOGY AND MEDICINE,,
81,Electrocardiogram heartbeat classification based on a deep convolutional neural network and focal loss,123,,,"Romdhane Taissir Fekih,Alhichri Haikel,Ouni Ridha,Atri Mohamed","Romdhane TF,Alhichri H,Ouni R,Atri M",Ouni R,10.1016/j.compbiomed.2020.103866,King Saud University,"The electrocardiogram (ECG) is an effective tool for cardiovascular disease diagnosis and arrhythmia detection. Most methods proposed in the literature include the following steps: 1) denoizing, 2) segmentation into heartbeats, 3) feature extraction, and 4) classification. In this paper, we present a deep learning method based on a convolutional neural network (CNN) model. CNN models can perform feature extraction automatically and jointly with the classification step. In other words, our proposed method does not require a feature extraction step with hand-crafted techniques. Our proposed method is also based on an algorithm for heartbeat segmentation that is different from most existing methods. In particular, the segmentation algorithm defines each ECG heartbeat to start at an R-peak and end after 1.2 times the median RR time interval in a 10-s window. This method is simple and effective, as it does not use any form of filtering or processing that requires assumptions about the signal morphology or spectrum. Although enhanced ECG heartbeat classification algorithms have been proposed in the literature, they failed to achieve high performance in detecting some heartbeat categories, especially for imbalanced datasets. To overcome this challenge, we propose an optimization step for the deep CNN model using a novel loss function called focal loss. This function focuses on minority heartbeat classes by increasing their importance. We trained and evaluated our proposed model with the MIT-BIH and INCART datasets to identify five arrhythmia categories (N, S, V, Q, and F) based on the Association for Advancement of Medical Instrumentation (AAMI) standard. The evaluation results revealed that the focal loss function improved the classification accuracy for the minority classes as well as the overall metrics. Our proposed method achieved 98.41% overall accuracy, 98.38% overall F1-score, 98.37% overall precision, and 98.41% overall recall. In addition, our method achieved better performance than that of existing state-of-the-art methods.","ECG Classification,AAMI standard,Convolutional neural network,Focal loss,Heartbeat category,Imbalanced data,INCART,MIT-BIH",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"ARRHYTHMIA,CLASSIFICATION,FEATURE-EXTRACTION,MODEL,SYSTEM",COMPUTERS IN BIOLOGY AND MEDICINE,,
82,Classification models for SPECT myocardial perfusion imaging,123,,,"Berkaya Selcan Kaplan,Sivrikoz Ilknur Ak,Gunal Serkan","Berkaya SK,Sivrikoz IA,Gunal S",Berkaya SK,10.1016/j.compbiomed.2020.103893,Eskisehir Technical University,"Objective: The main goal of this work is to develop computer-aided classification models for single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) to identify perfusion abnormalities (myocardial ischemia and/or infarction).
Methods: Two different classification models, namely, deep learning (DL)-based and knowledge-based, are proposed. The first type of model utilizes transfer learning with pre-trained deep neural networks and a support vector machine classifier with deep and shallow features extracted from those networks. The latter type of model, on the other hand, aims to transform the knowledge of expert readers to appropriate image processing techniques including particular color thresholding, segmentation, feature extraction, and some heuristics. In addition, the summed stress and rest images from 192 patients (age 26-96, average age 61.5, 38% men, and 78% coronary artery disease) were collected to constitute a new dataset. The visual assessment of two expert readers on this dataset is used as a reference standard. The performances of the proposed models were then evaluated according to this standard.
Results: The maximum accuracy, sensitivity, and specificity values are computed as 94%, 88%, and 100% for the DL-based model and 93%, 100%, and 86% for the knowledge-based model, respectively.
Conclusion: The proposed models provided diagnostic performance close to the level of expert analysis. Therefore, they can aid in clinical decision making for the interpretation of SPECT MPI regarding myocardial ischemia and infarction.","Computer-aided diagnosis,Coronary artery disease,Deep learning,Myocardial perfusion imaging,SPECT",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,,"CORONARY-ARTERY-DISEASE,IMPROVED,ACCURACY,DIAGNOSIS,SYSTEM",COMPUTERS IN BIOLOGY AND MEDICINE,,
83,Faster R-CNN approach for detection and quantification of DNA damage in comet assay images,123,,,"Rosati Riccardo,Romeo Luca,Silvestri Sonia,Marcheggiani Fabio,Tiano Luca,Frontoni Emanuele","Rosati R,Romeo L,Silvestri S,Marcheggiani F,Tiano L,Frontoni E",Rosati R,10.1016/j.compbiomed.2020.103912,Marche Polytechnic University,"Background and Objective: DNA damage analysis can provide valuable information in several areas ranging from the diagnosis/treatment of a disease to the monitoring of the effects of genetic and environmental influences. The evaluation of the damage is determined by comet scoring, which can be performed by a skilled operator with a manual procedure. However, this approach becomes very time-consuming and the operator dependency results in the subjectivity of the damage quantification and thus in a high inter/intra-operator variability.
Methods: In this paper, we aim to overcome this issue by introducing a Deep Learning methodology based on Faster R-CNN to completely automatize the overall approach while discovering unseen discriminative patterns in comets.
Results: The experimental results performed on two real use-case datasets reveal the higher performance (up to mean absolute precision of 0.74) of the proposed methodology against other state-of-the-art approaches. Additionally, the validation procedure performed by expert biologists highlights how the proposed approach is able to unveil true comets, often unseen from the human eye and standard computer vision methodology.
Conclusions: This work contributes to the biomedical informatics field by the introduction of a novel approach based on established object detection Deep Learning technique for evaluating the DNA damage. The main contribution is the application of Faster R-CNN for the detection and quantification of DNA damage in comet assay images, by fully automatizing the detection/classification DNA damage task. The experimental results extracted in two real use-case datasets demonstrated (i) the higher robustness of the proposed methodology against other state-of-the-art Deep Learning competitors, (ii) the speeding up of the comet analysis procedure and (iii) the minimization of the intra/inter-operator variability.","Pattern recognition,DNA damage classification,Comet assay,Faster R-CNN,Deep learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"AUTOMATED,TOOL",COMPUTERS IN BIOLOGY AND MEDICINE,,
84,Selecting transferrable neurophysiological features for inter-individual emotion recognition via a shared-subspace feature elimination approach,123,,,"Zhang Wei,Yin Zhong,Sun Zhanquan,Tian Ying,Wang Yagang","Zhang W,Yin Z,Sun ZQ,Tian Y,Wang YG",Yin Z,10.1016/j.compbiomed.2020.103875,University of Shanghai for Science & Technology,"The interplay between human emotions, personality, and motivation results in individual specificity in neurophysiological data distributions for the same emotional category. To address this issue for building an emotion recognition system based on electroencephalogram (EEG) features, we propose a shared-subspace feature elimination (SSFE) approach to identify EEG variables with common characteristics across multiple individuals. In the SSFE framework, a low-dimensional space defined by a selected number of EEG features is created to represent the inter-emotion discriminant for different pairs of subjects evaluated based on the interclass margin. Using two public databases-DEAP and MAHNOB-HCI-the performance of the SSFE is validated according to the leave-one-subject-out paradigm. The performance of the proposed framework is compared with five other feature-selection methods. The effectiveness and computational cost of the SSFE is investigated across six machine learning models based on their optimal hyperparameters. In the end, the competitive binary classification accuracy from the SSFE of arousal and valence recognitions are determined to be 0.6521 and 0.6635, respectively, for DEAP, and 0.6520 and 0.6537, respectively for MAHNOB-HCI.","Emotion recognition,Human machine interaction,Machine learning,Physiological signals,Support vector machine",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"STATE,CLASSIFICATION,MENTAL,WORKLOAD,EEG,VECTOR,SIGNALS,FUSION",COMPUTERS IN BIOLOGY AND MEDICINE,,
85,Two Stream Active Query Suggestion for Active Learning in Connectomics.,12363,,103-120,,,,10.1007/978-3-030-58523-5_7,,"For large-scale vision tasks in biomedical images, the labeled data is often limited to train effective deep models. Active learning is a common solution, where a query suggestion method selects representative unlabeled samples for annotation, and the new labels are used to improve the base model. However, most query suggestion models optimize their learnable parameters only on the limited labeled data and consequently become less effective for the more challenging unlabeled data. To tackle this, we propose a two-stream active query suggestion approach. In addition to the supervised feature extractor, we introduce an unsupervised one optimized on all raw images to capture diverse image features, which can later be improved by fine-tuning on new labels. As a use case, we build an end-to-end active learning framework with our query suggestion method for 3D synapse detection and mitochondria segmentation in connectomics. With the framework, we curate, to our best knowledge, the largest connectomics dataset with dense synapses and mitochondria annotation. On this new dataset, our method outperforms previous state-of-the-art methods by 3.1% for synapse and 3.8% for mitochondria in terms of region-of-interest proposal accuracy. We also apply our method to image classification, where it outperforms previous approaches on CIFAR-10 under the same limited annotation budget. The project page is https://zudi-lin.github.io/projects/#two_stream_active.",Active Learning; Connectomics; Image Classification; Object Detection; Semantic Segmentation,Journal Article,,,,,,,,
86,"Effectiveness of Artificial Intelligence Applications Designed for Endodontic Diagnosis, Decision-making, and Prediction of Prognosis: A Systematic Review.",21,8,926-934,,Boreak Nezar,,,,"AIM: With advancements in science and technology, there has been phenomenal developments in the application of neural networks in dentistry. This systematic review aimed to report on the effectiveness of artificial intelligence (AI) applications designed for endodontic diagnosis, decision-making, and prediction of prognosis.MATERIALS AND METHODS: Studies reporting on AI applications in endodontics were identified from the electronic databases such as PubMed, Medline, Embase, Cochrane, Google Scholar, Scopus, and Web of Science, for original research articles published from January 1, 2000, to June 1, 2020. A total of 10 studies that met our eligibility criteria were further analyzed for qualitative data. QUADAS-2 was applied for synthesis of the quality of the studies included.RESULTS: A wide range of AI applications have been implemented in endodontics. The neural networks employed were mostly based on convolutional neural networks (CNNs) and artificial neural networks (ANNs) in their neural architectures. These AI models have been used for locating apical foramen, retreatment predictions, prediction of periapical pathologies, detection and diagnosis of vertical root fractures, and assessment of root morphologies.CONCLUSION: These studies suggest that the neural networks performed similar to the experienced professionals in terms of accuracy and precision. In some studies, these models have even outperformed the specialists.CLINICAL SIGNIFICANCE: These models can be of greater assistance as an expert opinion for less experienced and nonspecialists.","Artificial intelligence; Artificial neural networks; Convolutional neural networks; Deep learning models; Endodontic diagnosis; Endodontic prognosis ,Machine learning,.",Journal Article; Systematic Review,,,,,,,,
87,Stability boundary and optimal operating parameter identification in milling using Bayesian learning,56,,1252-1262,"Karandikar Jaydeep,Honeycutt Andrew,Schmitz Tony,Smith Scott","Karandikar J,Honeycutt A,Schmitz T,Smith S",Karandikar J,10.1016/j.jmapro.2020.04.019,United States Department of Energy (DOE),"This paper describes a novel Bayesian learning approach for stability boundary and optimal parameter identification in milling without the knowledge of the underlying tool dynamics or material cutting force coefficients. The paper is divided into two parts. First, a Bayesian learning method for stability lobe identification using test results is described. Each axial depth and spindle speed combination is characterized by a probability of stability which is updated using Bayes' rule when a test result (stable or unstable) is made available. A novel likelihood function is defined which incorporates knowledge of the stability behavior. Numerical results show convergence to the analytical stability lobe diagram. Second, an adaptive experimental strategy to identify optimal operating parameters that maximize material removal rate is described. Numerical evaluation shows convergence to the optimal operating point with error less than 15 % within ten tests on average. The approach is validated using experimental results. Results show that the proposed method is an efficient and robust learning method to identify the stability lobe diagram and optimal operating parameters with a limited number of tests/data points.","Machining,Stability,Uncertainty,Experimental design",Article; Proceedings Paper,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,5.135,CHATTER,JOURNAL OF MANUFACTURING PROCESSES,,
88,Toward accurate quantitative photoacoustic imaging: learning vascular blood oxygen saturation in three dimensions,25,8,,"Bench Ciaran,Hauptmann Andreas,Cox Ben","Bench C,Hauptmann A,Cox B",Bench C,10.1117/1.JBO.25.8.085003,University of London,"Significance: Two-dimensional (2-D) fully convolutional neural networks have been shown capable of producing maps of sO(2) from 2-D simulated images of simple tissue models. However, their potential to produce accurate estimates in vivo is uncertain as they are limited by the 2-D nature of the training data when the problem is inherently three-dimensional (3-D), and they have not been tested with realistic images.
Aim: To demonstrate the capability of deep neural networks to process whole 3-D images and output 3-D maps of vascular sO(2) from realistic tissue models/images.
Approach: Two separate fully convolutional neural networks were trained to produce 3-D maps of vascular blood oxygen saturation and vessel positions from multiwavelength simulated images of tissue models.
Results: The mean of the absolute difference between the true mean vessel sO(2) and the network output for 40 examples was 4.4% and the standard deviation was 4.5%.
Conclusions: 3-D fully convolutional networks were shown capable of producing accurate sO(2) maps using the full extent of spatial information contained within 3-D images generated under conditions mimicking real imaging scenarios. We demonstrate that networks can cope with some of the confounding effects present in real images such as limited-view artifacts and have the potential to produce accurate estimates in vivo. (C) The Authors.","photoacoustics,deep learning,oxygen saturation,sO(2),machine learning,quantitative photoacoustics",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,"OPTICAL-PROPERTIES,HUMAN,SKIN,TISSUES,NETWORK,MEDIA",JOURNAL OF BIOMEDICAL OPTICS,https://discovery.ucl.ac.uk/10108541/1/2020_Bench_JBO.pdf,
89,Efficient inversion strategies for estimating optical properties with Monte Carlo radiative transport models,25,8,,"Macdonald Callum M.,Arridge Simon,Powell Samuel","Macdonald CM,Arridge S,Powell S",Macdonald CM,10.1117/1.JBO.25.8.085002,University of London,"Significance: Indirect imaging problems in biomedical optics generally require repeated evaluation of forward models of radiative transport, for which Monte Carlo is accurate yet computationally costly. We develop an approach to reduce this bottleneck, which has significant implications for quantitative tomographic imaging in a variety of medical and industrial applications.
Aim: Our aim is to enable computationally efficient image reconstruction in (hybrid) diffuse optical modalities using stochastic forward models.
Approach: Using Monte Carlo, we compute a fully stochastic gradient of an objective function for a given imaging problem. Leveraging techniques from the machine learning community, we then adaptively control the accuracy of this gradient throughout the iterative inversion scheme to substantially reduce computational resources at each step.
Results: For example problems of quantitative photoacoustic tomography and ultrasound-modulated optical tomography, we demonstrate that solutions are attainable using a total computational expense that is comparable to (or less than) that which is required for a single high-accuracy forward run of the same Monte Carlo model.
Conclusions: This approach demonstrates significant computational savings when approaching the full nonlinear inverse problem of optical property estimation using stochastic methods. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","Monte Carlo,radiative transport,optical tomography,machine learning,stochastic-gradient descent",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,"PHOTON,MIGRATION,LIGHT,TRANSPORT,TURBID,MEDIA,TOMOGRAPHY,SIMULATION,OPTIMIZATION,ALGORITHM",JOURNAL OF BIOMEDICAL OPTICS,http://arxiv.org/pdf/2007.02601,
90,Automated interpretation of time-lapse quantitative phase image by machine learning to study cellular dynamics during epithelial-mesenchymal transition,25,8,,"Strbkova Lenka,Carson Brittany B.,Vincent Theresa,Vesely Pavel,Chmelik Radim","Strbkova L,Carson BB,Vincent T,Vesely P,Chmelik R",Strbkova L,10.1117/1.JBO.25.8.086502,Brno University of Technology,"Significance: Machine learning is increasingly being applied to the classification of microscopic data. In order to detect some complex and dynamic cellular processes, time-resolved live-cell imaging might be necessary. Incorporating the temporal information into the classification process may allow for a better and more specific classification.
Aim: We propose a methodology for cell classification based on the time-lapse quantitative phase images (QPIs) gained by digital holographic microscopy (DHM) with the goal of increasing performance of classification of dynamic cellular processes.
Approach: The methodology was demonstrated by studying epithelial-mesenchymal transition (EMT) which entails major and distinct time-dependent morphological changes. The time-lapse QPIs of EMT were obtained over a 48-h period and specific novel features representing the dynamic cell behavior were extracted. The two distinct end-state phenotypes were classified by several supervised machine learning algorithms and the results were compared with the classification performed on single-time-point images.
Results: In comparison to the single-time-point approach, our data suggest the incorporation of temporal information into the classification of cell phenotypes during EMT improves performance by nearly 9% in terms of accuracy, and further indicate the potential of DHM to monitor cellular morphological changes.
Conclusions: Proposed approach based on the time-lapse images gained by DHM could improve the monitoring of live cell behavior in an automated fashion and could be further developed into a tool for high-throughput automated analysis of unique cell behavior. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","digital holographic microscopy,quantitative phase imaging,epithelial-mesenchymal transition",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,"DIGITAL,HOLOGRAPHIC,MICROSCOPY,TGF-BETA,CLASSIFICATION,COHERENCE,MORPHOLOGY",JOURNAL OF BIOMEDICAL OPTICS,http://uu.diva-portal.org/smash/get/diva2:1508080/FULLTEXT01,
91,DATA SCIENCE AND ARTIFICIAL INTELLIGENCE AS TOOLS FOR THE PRACTICAL IMPLEMENTATION OF THE PHILOSOPHY OF OPEN EDUCATION,56,,63-84,"Averkov Mikhail S.,Deryabin Andrey A.,Popov Alexander A.","Averkov MS,Deryabin AA,Popov AA",Averkov MS,10.17223/1998863X/56/7,Novosibirsk State Technical University,"The authors consider the actual role of data science, big data, and artificial intelligence in the system of contemporary education, primarily in open educational practices. The authors put forward and test the hypothesis that data science and artificial intelligence can and should be not only objects of study but also new tools of educational activity at first hand. Moreover, these tools should be used by students themselves for complete and systematic selection of their study materials and for the formation of personal strategies. The authors relied on materials that describe the direct use of elements of data science and artificial intelligence in the educational process (reports, interviews, etc.), on descriptions of prospective digital developments that can be re-oriented toward educational problems, on educational technologies that can become prototypes for developments in the field of data science and artificial intelligence. The following methods were used in the research: content analysis, systemgenetic and structural-content analysis, modeling of cognitive and social processes, forecasting. The study was conducted in the following mode: (1) research on basic theoretical ideas about data science and artificial intelligence, as well as ideas about their actual and potential social and sociocultural effects; (2) a primary study of practices of using these disciplines in the education system; (3) building of a hypothetical model of educational practice based on data science and artificial intelligence; (4) selection and analysis of materials about existing educational practices based on large amounts of data and complex software; (5) assessment of the advantages and disadvantages of existing digital educational resources; (6) modeling/forecasting of possible and necessary digital educational tools based on data science and artificial intelligence. As a result, the following conclusions were made: (1) currently, data science and artificial intelligence are being mastered in the Russian school in the mode of abstract knowledge, without instrumentalization; (2) objectively, data-driven and AI-driven educational complexes can be created that allow students to replace textbooks by constructing sets of materials on standardized educational topics, as well as educational simulators that support students' decisions about educational and life strategies in changing conditions; (3) currently, data analysis and artificial intelligence are used to organize educational activities and students' self-determination only at the level of separate components: search engines, educational navigators, machine learning-based applications that process student training data, simulators of meta-subject competencies, tools for analyzing students' psycho-social traits, etc.","data science,big data,artificial intelligence,machine learning,open educational tasks,reconstruction and construction in education,digital educational navigator,digital educational simulator,activity-based approach to learning,decision support systems",Article,"TOMSK STATE UNIV, LENIN AVE, 36, TOMSK, 634050, RUSSIA",Social Sciences - Other Topics,,,,VESTNIK TOMSKOGO GOSUDARSTVENNOGO UNIVERSITETA-FILOSOFIYA-SOTSIOLOGIYA-POLITOLOGIYA-TOMSK STATE UNIVERSITY JOURNAL OF PHILOSOPHY SOCIOLOGY AND POLITICAL SCIENCE,http://journals.tsu.ru/uploads/import/2002/files/56-063.pdf,
92,Fold-stratified cross-validation for unbiased and privacy-preserving federated learning,27,8,1244-1251,"Bey Romain,Goussault Romain,Grolleau Francois,Benchoufi Mehdi,Porcher Raphael","Bey R,Goussault R,Grolleau F,Benchoufi M,Porcher R",Porcher R,10.1093/jamia/ocaa096,Assistance Publique Hopitaux Paris (APHP),"Objective: We introduce fold-stratified cross-validation, a validation methodology that is compatible with privacy-preserving federated learning and that prevents data leakage caused by duplicates of electronic health records (EHRs).
Materials and Methods: Fold-stratified cross-validation complements cross-validation with an initial stratification of EHRs in folds containing patients with similar characteristics, thus ensuring that duplicates of a record are jointly present either in training or in validation folds. Monte Carlo simulations are performed to investigate the properties of fold-stratified cross-validation in the case of a model data analysis using both synthetic data and MIMIC-III (Medical Information Mart for Intensive Care-III) medical records.
Results: In situations in which duplicated EHRs could induce overoptimistic estimations of accuracy, applying fold-stratified cross-validation prevented this bias, while not requiring full deduplication. However, a pessimistic bias might appear if the covariate used for the stratification was strongly associated with the outcome.
Discussion: Although fold-stratified cross-validation presents low computational overhead, to be efficient it requires the preliminary identification of a covariate that is both shared by duplicated records and weakly associated with the outcome. When available, the hash of a personal identifier or a patient's date of birth provides such a covariate. On the contrary, pseudonymization interferes with fold-stratified cross-validation, as it may break the equality of the stratifying covariate among duplicates.
Conclusion: Fold-stratified cross-validation is an easy-to-implement methodology that prevents data leakage when a model is trained on distributed EHRs that contain duplicates, while preserving privacy.","federated learning,privacy,validation,duplicated electronic health records,data leakage",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"ELECTRONIC,HEALTH,RECORDS",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647321,
93,Automatic detection of hand hygiene using computer vision technology,27,8,1316-1320,"Singh Amit,Haque Albert,Alahi Alexandre,Yeung Serena,Guo Michelle,Glassman Jill R.,Beninati William,Platchek Terry,Li Fei-Fei,Milstein Arnold","Singh A,Haque A,Alahi A,Yeung S,Guo M,Glassman JR,Beninati W,Platchek T,Li FF,Milstein A",Singh A,10.1093/jamia/ocaa115,"300 Pasteur Dr MC 5776, Stanford, CA 94305 USA.","Objective: Hand hygiene is essential for preventing hospital-acquired infections but is difficult to accurately track. The gold-standard (human auditors) is insufficient for assessing true overall compliance. Computer vision technology has the ability to perform more accurate appraisals. Our primary objective was to evaluate if a computer vision algorithm could accurately observe hand hygiene dispenser use in images captured by depth sensors.
Materials and Methods: Sixteen depth sensors were installed on one hospital unit. Images were collected continuously from March to August 2017. Utilizing a convolutional neural network, a machine learning algorithm was trained to detect hand hygiene dispenser use in the images. The algorithm's accuracy was then compared with simultaneous in-person observations of hand hygiene dispenser usage. Concordance rate between human observation and algorithm's assessment was calculated. Ground truth was established by blinded annotation of the entire image set. Sensitivity and specificity were calculated for both human and machine-level observation.
Results: A concordance rate of 96.8% was observed between human and algorithm (kappa = 0.85). Concordance among the 3 independent auditors to establish ground truth was 95.4% (Fleiss's kappa = 0.87). Sensitivity and specificity of the machine learning algorithm were 92.1% and 98.3%, respectively. Human observations showed sensitivity and specificity of 85.2% and 99.4%, respectively.
Conclusions: A computer vision algorithm was equivalent to human observation in detecting hand hygiene dispenser use. Computer vision monitoring has the potential to provide a more complete appraisal of hand hygiene activity in hospitals than the current gold-standard given its ability for continuous coverage of a unit in space and time.","computer vision,hand hygiene,healthcare acquired infections,patient safety,machine learning,artificial intelligence,depth sensing",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://infoscience.epfl.ch/record/281242/files/ocaa115.pdf,
94,Optic Disc Segmentation Using Attention-Based U-Net and the Improved Cross-Entropy Convolutional Neural Network,22,8,,"Jin Baixin,Liu Pingping,Wang Peng,Shi Lida,Zhao Jing","Jin BX,Liu PP,Wang P,Shi LD,Zhao J",Liu PP,10.3390/e22080844,Jilin University,"Medical image segmentation is an important part of medical image analysis. With the rapid development of convolutional neural networks in image processing, deep learning methods have achieved great success in the field of medical image processing. Deep learning is also used in the field of auxiliary diagnosis of glaucoma, and the effective segmentation of the optic disc area plays an important assistant role in the diagnosis of doctors in the clinical diagnosis of glaucoma. Previously, many U-Net-based optic disc segmentation methods have been proposed. However, the channel dependence of different levels of features is ignored. The performance of fundus image segmentation in small areas is not satisfactory. In this paper, we propose a new aggregation channel attention network to make full use of the influence of context information on semantic segmentation. Different from the existing attention mechanism, we exploit channel dependencies and integrate information of different scales into the attention mechanism. At the same time, we improved the basic classification framework based on cross entropy, combined the dice coefficient and cross entropy, and balanced the contribution of dice coefficients and cross entropy loss to the segmentation task, which enhanced the performance of the network in small area segmentation. The network retains more image features, restores the significant features more accurately, and further improves the segmentation performance of medical images. We apply it to the fundus optic disc segmentation task. We demonstrate the segmentation performance of the model on the Messidor dataset and the RIM-ONE dataset, and evaluate the proposed architecture. Experimental results show that our network architecture improves the prediction performance of the base architectures under different datasets while maintaining the computational efficiency. The results render that the proposed technologies improve the segmentation with 0.0469 overlapping error on Messidor.","information aggregation,attention mechanism,improved cross entropy,optic disc,segmentation network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,2.587,"CUP,SEGMENTATION",ENTROPY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7517445,
95,"Decoding pilot behavior consciousness of EEG, ECG, eye movements via an SVM machine learning model",11,4,,"Wang Xiashuang,Gong Guanghong,Li Ni,Ding Li,Ma Yaofei","Wang XS,Gong GH,Li N,Ding L,Ma YF",Gong GH,10.1142/S1793962320500282,Beihang University,"To decode the pilot's behavioral awareness, an experiment is designed to use an aircraft simulator obtaining the pilot's physiological behavior data. Existing pilot behavior studies such as behavior modeling methods based on domain experts and behavior modeling methods based on knowledge discovery do not proceed from the characteristics of the pilots themselves. The experiment starts directly from the multimodal physiological characteristics to explore pilots' behavior. Electroencephalography, electrocardiogram, and eye movement were recorded simultaneously. Extracted multimodal features of ground missions, air missions, and cruise mission were trained to generate support vector machine behavior model based on supervised learning. The results showed that different behaviors affects different multiple rhythm features, which are power spectra of the. waves of EEG, standard deviation of normal to normal, root mean square of standard deviation and average gaze duration. The different physiological characteristics of the pilots could also be distinguished using an SVM model. Therefore, the multimodal physiological data can contribute to future research on the behavior activities of pilots. The result can be used to design and improve pilot training programs and automation interfaces.","Pilots' behavior,decision making,aircraft simulator,multimodal physiological features,SVM model",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Computer Science,,,"BRAIN-COMPUTER,INTERFACE,CLASSIFICATION,PERFORMANCE,SIGNALS,FUSION,P300",INTERNATIONAL JOURNAL OF MODELING SIMULATION AND SCIENTIFIC COMPUTING,,
96,Machine learning applications in systems metabolic engineering,64,,1-9,"Kim Gi Bae,Kim Won Jun,Kim Hyun Uk,Lee Sang Yup","Kim GB,Kim WJ,Kim HU,Lee SY",Lee SY,10.1016/j.copbio.2019.08.010,Korea Advanced Institute of Science & Technology (KAIST),"Systems metabolic engineering allows efficient development of high performing microbial strains for the sustainable production of chemicals and materials. In recent years, increasing availability of bio big data, for example, omics data, has led to active application of machine learning techniques across various stages of systems metabolic engineering, including host strain selection, metabolic pathway reconstruction, metabolic flux optimization, and fermentation. In this paper, recent contributions of machine learning approaches to each major step of systems metabolic engineering are discussed. As the use of machine learning in systems metabolic engineering will become more widespread in accordance with the ever-increasing volume of bio big data, future prospects are also provided for the successful applications of machine learning.","ARTIFICIAL NEURAL-NETWORK,GENETIC ALGORITHM,OPTIMIZATION,PREDICTION,PATHWAYS,DESIGN,TOOLS,MODEL",Review,"CURRENT BIOLOGY LTD, 84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology",,9.807,"ARTIFICIAL,NEURAL-NETWORK,GENETIC,ALGORITHM,OPTIMIZATION,PREDICTION,PATHWAYS,DESIGN,TOOLS,MODEL",CURRENT OPINION IN BIOTECHNOLOGY,,
97,,,,,,,,,,,,,,,,,,,,
98,,,,,,,,,,,,,,,,,,,,
99,,,,,,,,,,,,,,,,,,,,
