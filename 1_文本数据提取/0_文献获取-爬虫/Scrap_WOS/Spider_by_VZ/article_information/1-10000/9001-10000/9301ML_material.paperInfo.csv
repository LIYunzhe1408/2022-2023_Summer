,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,A Real-Time Depth of Anesthesia Monitoring System Based on Deep Neural Network With Large EDO Tolerant EEG Analog Front-End,14,4,825-837,"Park Yongjae,Han Su-Hyun,Byun Wooseok,Kim Ji-Hoon,Lee Hyung-Chul,Kim Seong-Jin","Park Y,Han SH,Byun W,Kim JH,Lee HC,Kim SJ",Kim SJ,10.1109/TBCAS.2020.2998172,Ulsan National Institute of Science & Technology (UNIST),"In this article, we present a real-time electroencephalogram (EEG) based depth of anesthesia (DoA) monitoring system in conjunction with a deep learning framework, AnesNET. An EEG analog front-end (AFE) that can compensate +/- 380-mV electrode DC offset using a coarse digital DC servo loop is implemented in the proposed system. The EEG-based MAC, EEGMAC, is introduced as a novel index to accurately predict the DoA, which is designed for applying to patients anesthetized by both volatile and intravenous agents. The proposed deep learning protocol consists of four layers of convolutional neural network and two dense layers. In addition, we optimize the complexity of the deep neural network (DNN) to operate on a microcomputer such as the Raspberry Pi 3, realizing a cost-effective small-size DoA monitoring system. Fabricated in 110-nm CMOS, the prototype AFE consumes 4.33 mu W per channel and has the input-referred noise of 0.29 mu Vrms from 0.5 to 100 Hz with the noise efficiency factor of 2.2. The proposed DNN was evaluated with pre-recorded EEG data from 374 subjects administrated by inhalational anesthetics under surgery, achieving an average squared and absolute errors of 0.048 and 0.05, respectively. The EEGMAC with subjects anesthetized by an intravenous agent also showed a good agreement with the bispectral index value, confirming the proposed DoA index is applicable to both anesthetics. The implemented monitoring system with the Raspberry Pi 3 estimates the EEGMAC within 20 ms, which is about thousand-fold faster than the BIS estimation in literature.","Electroencephalography,Monitoring,Anesthesia,DSL,Indexes,Direction-of-arrival estimation,Electrodes,Bispectral index,convolutional neural network,depth of anesthesia monitoring,electrode DC offset,electroencephalogram,latency,minimum alveolar concentration,Raspberry Pi 3",Article; Proceedings Paper,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,"INSTRUMENTATION,AMPLIFIER,SEIZURE,CLASSIFICATION,INDEX,CALCULATION,BISPECTRAL,INDEX,CEREBRAL,STATE,8-CHANNEL,SOC,CONSCIOUSNESS,ISOFLURANE,DELAY",IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,,
2,An On-Chip Processor for Chronic Neurological Disorders Assistance Using Negative Affectivity Classification,14,4,838-851,"Aslam Abdul Rehman,Bin Altaf Muhammad Awais","Aslam AR,Bin Altaf MA",Bin Altaf MA,10.1109/TBCAS.2020.3008766,Lahore University of Management Sciences,"Chronic neurological disorders (CND's) are lifelong diseases and cannot be eradicated, but their severe effects can be alleviated by early preemptive measures. CND's, such as Alzheimer's, Autism Spectrum Disorder (ASD), and Amyotrophic Lateral Sclerosis (ALS), are the chronic ailment of the central nervous system that causes the degradation of emotional and cognitive abilities. Long term continuous monitoring with neuro-feedback of human emotions for patients with CND's is crucial in mitigating its harmful effect. This paper presents hardware efficient and dedicated human emotion classification processor for CND's. Scalp EEG is used for the emotion's classification using the valence and arousal scales. A linear support vector machine classifier is used with power spectral density, logarithmic interhemispheric power spectral ratio, and the interhemispheric power spectral difference of eight EEG channel locations suitable for a wearable non-invasive classification system. A look-up-table based logarithmic division unit (LDU) is to represent the division features in machine learning (ML) applications. The implemented LDU minimizes the cost of integer division by 34% for ML applications. The implemented emotion's classification processor achieved an accuracy of 72.96% and 73.14%, respectively, for the valence and arousal classification on multiple publicly available datasets. The 2 x 3mm(2) processor is fabricated using a 0.18 mu m 1P6M CMOS process with power and energy utilization of 2.04 mW and 16 mu J/classification, respectively, for 8-channel operation.","Continuous health monitoring,classification processor,electroencephalogram (EEG),emotion detection,machine learning,neurological disorder,support vector machine",Article; Proceedings Paper,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,EEG,IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,,
3,Self-Paced Balance Learning for Clinical Skin Disease Recognition,31,8,2832-2846,"Yang Jufeng,Wu Xiaoping,Liang Jie,Sun Xiaoxiao,Cheng Ming-Ming,Rosin Paul L.,Wang Liang","Yang JF,Wu XP,Liang J,Sun XX,Cheng MM,Rosin PL,Wang L",Yang JF,10.1109/TNNLS.2019.2917524,Nankai University,"Class imbalance is a challenging problem in many classification tasks. It induces biased classification results for minority classes that contain less training samples than others. Most existing approaches aim to remedy the imbalanced number of instances among categories by resampling the majority and minority classes accordingly. However, the imbalanced level of difficulty of recognizing different categories is also crucial, especially for distinguishing samples with many classes. For example, in the task of clinical skin disease recognition, several rare diseases have a small number of training samples, but they are easy to diagnose because of their distinct visual properties. On the other hand, some common skin diseases, e.g., eczema, are hard to recognize due to the lack of special symptoms. To address this problem, we propose a self-paced balance learning (SPBL) algorithm in this paper. Specifically, we introduce a comprehensive metric termed the complexity of image category that is a combination of both sample number and recognition difficulty. First, the complexity is initialized using the model of the first pace, where the pace indicates one iteration in the self-paced learning paradigm. We then assign each class a penalty weight that is larger for more complex categories and smaller for easier ones, after which the curriculum is reconstructed by rearranging the training samples. Consequently, the model can iteratively learn discriminative representations via balancing the complexity in each pace. Experimental results on the SD-198 and SD-260 benchmark data sets demonstrate that the proposed SPBL algorithm performs favorably against the state-of-the-art methods. We also demonstrate the effectiveness of the SPBL algorithm's generalization capacity on various tasks, such as indoor scene image recognition and object classification.","Diseases,Skin,Complexity theory,Training,Task analysis,Image recognition,Learning systems,Class imbalance,clinical skin disease recognition,complexity level,self-paced balance learning (SPBL)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.746,"CONVOLUTIONAL,NEURAL-NETWORKS,SUPPORT,VECTOR,MACHINES,CLASSIFICATION,SMOTE,RULE",IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,https://orca.cardiff.ac.uk/123154/1/self-paced-skin-TNNLS-postprint.pdf,
4,Multi-Atlas Segmentation of Anatomical Brain Structures Using Hierarchical Hypergraph Learning,31,8,3061-3072,"Dong Pei,Guo Yanrong,Gao Yue,Liang Peipeng,Shi Yonghong,Wu Guorong","Dong P,Guo YR,Gao Y,Liang PP,Shi YH,Wu GR",Wu GR,10.1109/TNNLS.2019.2935184,University of North Carolina,"Accurate segmentation of anatomical brain structures is crucial for many neuroimaging applications, e.g., early brain development studies and the study of imaging biomarkers of neurodegenerative diseases. Although multi-atlas segmentation (MAS) has achieved many successes in the medical imaging area, this approach encounters limitations in segmenting anatomical structures associated with poor image contrast. To address this issue, we propose a new MAS method that uses a hypergraph learning framework to model the complex subject-within and subject-to-atlas image voxel relationships and propagate the label on the atlas image to the target subject image. To alleviate the low-image contrast issue, we propose two strategies equipped with our hypergraph learning framework. First, we use a hierarchical strategy that exploits high-level context features for hypergraph construction. Because the context features are computed on the tentatively estimated probability maps, we can ultimately turn the hypergraph learning into a hierarchical model. Second, instead of only propagating the labels from the atlas images to the target subject image, we use a dynamic label propagation strategy that can gradually use increasing reliably identified labels from the subject image to aid in predicting the labels on the difficult-to-label subject image voxels. Compared with the state-of-the-art label fusion methods, our results show that the hierarchical hypergraph learning framework can substantially improve the robustness and accuracy in the segmentation of anatomical brain structures with low image contrast from magnetic resonance (MR) images.","Image segmentation,Biomedical imaging,Hippocampus,Brainstem,Neuroimaging,Brainstem nuclei,context features,hippocampus,hypergraph learning,multi-atlas segmentation (MAS)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.746,"GRAY-MATTER,MRI,BIRTH,REGISTRATION,HIPPOCAMPUS,IMAGES,SIZE",IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,,
5,Feature Classification Method of Resting-State EEG Signals From Amnestic Mild Cognitive Impairment With Type 2 Diabetes Mellitus Based on Multi-View Convolutional Neural Network,28,8,1702-1709,"Wen Dong,Li Peng,Zhou Yanhong,Sun Yanbo,Xu Jian,Liu Yijun,Li Xiaoli,Li Jihui,Bian Zhijie,Wang Lei","Wen D,Li P,Zhou YH,Sun YB,Xu J,Liu YJ,Li XL,Li JH,Bian ZJ,Wang L",Wen D,10.1109/TNSRE.2020.3004462,Yanshan University,"The convolutional neural network (CNN) model is an active research topic in the field of EEG signals analysis. However, the classification effect of CNN on EEG signals of amnestic mild cognitive impairment (aMCI) with type 2 diabetes mellitus (T2DM) is not ideal. Even if EEG signals are transformed into multispectral images that are more closely matched with the model, the best classification performance can not be achieved. Therefore, to improve the performance of CNN toward EEG multispectral image classification, a multi-view convolutional neural network (MVCNN) classification model based on inceptionV1 is designed in this study. This model mainly improves and optimizes the convolutional layers and stochastic gradient descent (SGD) in the convolutional architecture model. Firstly, based on the discreteness of EEG multispectral image features, the multi-view convolutional layer structure was proposed. Then the learning rate change function of the SGD was optimized to increase the classification performance. The multi-view convolutional nerve was used in an EEG multispectral classification task involving 19 aMCI with T2DM and 20 normal controls. The results showed that compared with the traditional classification models, MVCNN had a better stability and accuracy. Therefore, MVCNN could be used as an effective feature classification method for aMCI with T2DM.","Multi-view convolutional neural network,aMCI with T2DM,EEG signals,feature classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"ALZHEIMERS-DISEASE,DEMENTIA,PROGRESSION",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
6,Automatic and Accurate Epilepsy Ripple and Fast Ripple Detection via Virtual Sample Generation and Attention Neural Networks,28,8,1710-1719,"Guo Jiayang,Li Hailong,Pan Yijie,Gao Yuan,Sun Jintao,Wu Ting,Xiang Jing,Luo Xiongbiao","Guo JY,Li HL,Pan YJ,Gao Y,Sun JT,Wu T,Xiang J,Luo XB",Li HL,10.1109/TNSRE.2020.3004368,Cincinnati Children's Hospital Medical Center,"About 1% of the population around the world suffers from epilepsy. The success of epilepsy surgery depends critically on pre-operative localization of epileptogenic zones. High frequency oscillations including ripples (80-250 Hz) and fast ripples (250-500 Hz) are commonly used as biomarkers to localize epileptogenic zones. Recent literature demonstrated that fast ripples indicate epileptogenic zones better than ripples. Thus, it is crucial to accurately detect fast ripples from ripples signals of magnetoencephalography for improving outcome of epilepsy surgery. This paper proposes an automatic and accurate ripple and fast ripple detection method that employs virtual sample generation and neural networks with an attention mechanism. We evaluate our proposed detector on patient data with 50 ripples and 50 fast ripples labeled by two experts. The experimental results show that our new detector outperforms multiple traditional machine learning models. In particular, our method can achieve a mean accuracy of 89.3% and an average area under the receiver operating characteristic curve of 0.88 in 50 repeats of random subsampling validation. In addition, we experimentally demonstrate the effectiveness of virtual sample generation, attention mechanism, and architecture of neural network models.","High-frequency oscillations,ripple,fast ripple,MEG,virtual sample generation,neural networks,artificial intelligence",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"FREQUENCY,NEUROMAGNETIC,SIGNALS,OSCILLATIONS,SURGERY",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
7,Modeling EEG Data Distribution With a Wasserstein Generative Adversarial Network to Predict RSVP Events,28,8,1720-1730,"Panwar Sharaj,Rad Paul,Jung Tzyy-Ping,Huang Yufei","Panwar S,Rad P,Jung TP,Huang YF",Huang YF,10.1109/TNSRE.2020.3006180,University of Texas System,Electroencephalography (EEG) data are difficult to obtain due to complex experimental setups and reduced comfort with prolonged wearing. This poses challenges to train powerful deep learning model with the limited EEG data. Being able to generate EEG data computationally could address this limitation. We propose a novel Wasserstein Generative Adversarial Network with gradient penalty (WGAN-GP) to synthesize EEG data. This network addresses several modeling challenges of simulating time-series EEG data including frequency artifacts and training instability. We further extended this network to a class-conditioned variant that also includes a classification branch to perform event-related classification. We trained the proposed networks to generate one and 64-channel data resembling EEG signals routinely seen in a rapid serial visual presentation (RSVP) experiment and demonstrated the validity of the generated samples. We also tested intra-subject cross-session classification performance for classifying the RSVP target events and showed that class-conditioned WGAN-GP can achieve improved event-classification performance over EEGNet.,"Wasserstein generative adversarial network,electroencephalography,data augmentation,Gaussian mixture models,convolutional neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,PERFORMANCE,IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,http://arxiv.org/pdf/1911.04379,
8,Tracking the Transitions of Brain States: An Analytical Approach Using EEG,28,8,1742-1749,"Maheshwari Jyoti,Joshi Shiv Dutt,Gandhi Tapan K.","Maheshwari J,Joshi SD,Gandhi TK",Maheshwari J,10.1109/TNSRE.2020.3005950,Indian Institute of Technology System (IIT System),"Objective: Classification of the neural activity of the brain is a well known problem in the field of brain computer interface. Machine learning based approaches for classification of brain activities do not reveal the underlying dynamics of the human brain. Methods: Since eigen decomposition has been found useful in a variety of applications, we conjecture that change of brain states would manifest in terms of changes in the invariant spaces spanned by eigen vectors as well as amount of variance along them. Based on this, our first approach is to track the brain state transitions by analysing invariant space variations over time. Whereas, our second approach analyses sub-band characteristic response vector formed using eigen values along with the eigen vectors to capture the dynamics. Result: We have taken two real time EEG datasets to demonstrate the efficacy of proposed approaches. It has been observed that in case of unimodal experiment, invariant spaces explicitly show the transitions of brain states. Whereas sub-band characteristic response vector approach gives better performance in the case of cross-modal conditions. Conclusions: Evolution of invariant spaces along with the eigen values may help in understanding and tracking the brain state transitions. Significance: The proposed approaches can track the activity transitions in real time. They do not require any training dataset.","Invariant space,CRV,dynamics,principal angle,transitions",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,CLASSIFICATION,IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
9,Run-to-Run Control of Chemical Mechanical Polishing Process Based on Deep Reinforcement Learning,33,3,454-465,"Yu Jianbo,Guo Peng","Yu JB,Guo P",Yu JB,10.1109/TSM.2020.3002896,Tongji University,"The chemical mechanical polishing (CMP) process usually suffers from drift and shift in the Run-to-Run material removal process due to the wear and replacement of the polishing pad, lacking of in-suit measurements of the product quality of interest and other environment variations. This paper proposed a deep reinforcement learning (DRL)-based run-to-run (R2R) controller for the CMP process. Firstly, deep reinforcement learning is effectively utilized as a training algorithm of the R2R controller, which is a model-free controller to take a decision with infinite horizon information and thus improves the control performance; Secondly, a novel policy network is embeded to the DRL model, which divides the network into linear and nonlinear part explicitly to improve the prediction performance of the R2R controller on process changes. Finally, a special reward function is proposed to improve the training of the R2R controller, which trades off between target tracing and fluctuations of production parameters. The effectiveness of the proposed controller is validated on a CMP process. The testing results illustrate that the DRL-based R2R controller can precisely trace the desired target of material removal rate (MRR) and is very effective to control various process variations online.","Semiconductor manufacturing,chemical mecha-nical planarization,process control,Run-to-Run control,deep reinforcement learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Physics",,2.479,STABILITY,IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING,,
10,Unsupervised hidden semi-Markov model for automatic beat onset detection in 1D Doppler ultrasound,41,8,,"Katebi Nasim,Marzbanrad Faezeh,Stroux Lisa,Valderrama Camilo E.,Clifford Gari D.","Katebi N,Marzbanrad F,Stroux L,Valderrama CE,Clifford GDI",Katebi N,10.1088/1361-6579/aba006,Emory University,"Objective: One dimensional (1D) Doppler ultrasound (DUS) is commonly used for fetal health assessment, during both regular prenatal visits and labor. It is used in preference to ECG and other modalities because of its simplicity and cost. To date, all analysis of such data has been confined to a smoothed, windowed heart rate estimation derived from the 1D DUS signal, reducing the potential of short-term variability information. A first step in improving the assessment of short-term variability of the fetal heart rate (FHR) is through implementing an accurate beat detector for 1D DUS signals.Approach: This work presents an unsupervised probabilistic segmentation method enabled by a hidden semi-Markov model (HSMM). The proposed method employs envelope and spectral features for an online segmentation of fetal 1D DUS signal. The beat onsets and fetal cardiac beat-to-beat intervals are then estimated from the segmentations. For this work, two data sets were used, including 1D DUS recordings from five fetuses recorded in Germany, comprising 6521 beats and 45.06 minutes of data (dataset 1). Simultaneous fetal ECG (fECG) was used as the reference for beat timing. Dataset 2, comprising 4044 beats captured from 17 subjects in the UK was hand scored for beat location and was used as an independent held-out test set. Leave-one-out subject cross-validation was used for parameter tuning on dataset 1. No retraining was performed for dataset 2. To assess the performance of the beat onset detection, the root mean square error (RMSE), F1 score, sensitivity, positive predictivity (PPV) and the error in several standard common heart rate variability metrics were used. These metrics were evaluated on three fiducial points: (1) beat onset, (2) beat offset, and (3) middle of beat interval.Main results: In dataset 1, the proposed method provided an RMSE of 20 ms, F1 score of 97.5 %, a Se of 97.6%, and a PPV of 97.3%. In dataset 2, the proposed method achieved an RMSE of 26 ms, an F1 score of 98.5 %, a Se of 98.0 % and a PPV of 98.9 %. It was also determined that the best beat-to-beat interval was derived from the onset of each beat. For the dataset 2, significant correlations were found in all short term heart rate variability metrics tested, both in the time and frequency domain. Only the proportion of successive normal-to-normal interval differences greater than 20 ms (pNN20) exhibited a significant absolute difference.Significance: This work presents the first-ever description of an algorithm to identify cardiac beats with 1D DUS, closely matching the fetal ECG-derived beats, to enable short-term heart rate variability analysis. The novel algorithm proposed requires no human labeling of data, and could have applicability beyond 1D DUS to other similar highly variable time series.","one-dimensional doppler ultrasound,fetal heart rate (FHR),fetal monitoring,signal processing,hidden semi-Markov model,unsupervised learning,unsupervised segmentation",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"FETAL,HEART-RATE,RANDOMIZED,CONTROLLED-TRIAL,NUMERICAL-ANALYSIS,RATE-VARIABILITY,SEGMENTATION,RECORDINGS",PHYSIOLOGICAL MEASUREMENT,,
11,Combination of Peri-Tumoral and Intra-Tumoral Radiomic Features on Bi-Parametric MRI Accurately Stratifies Prostate Cancer Risk: A Multi-Site Study,12,8,,"Algohary Ahmad,Shiradkar Rakesh,Pahwa Shivani,Purysko Andrei,Verma Sadhna,Moses Daniel,Shnier Ronald,Haynes Anne-Maree,Delprado Warick,Thompson James","Algohary A,Shiradkar R,Pahwa S,Purysko A,Verma S,Moses D,Shnier R,Haynes AM,Delprado W,Thompson J",Algohary A,10.3390/cancers12082200,Case Western Reserve University,"Background:Prostate cancer (PCa) influences its surrounding habitat, which tends to manifest as different phenotypic appearances on magnetic resonance imaging (MRI). This region surrounding the PCa lesion, or the peri-tumoral region, may encode useful information that can complement intra-tumoral information to enable better risk stratification.Purpose: To evaluate the role of peri-tumoral radiomic features on bi-parametric MRI (T2-weighted and Diffusion-weighted) to distinguish PCa risk categories as defined by D'Amico Risk Classification System.Materials and Methods: We studied a retrospective, HIPAA-compliant, 4-institution cohort of 231 PCa patients (n= 301 lesions) who underwent 3T multi-parametric MRI prior to biopsy. PCa regions of interest (ROIs) were delineated on MRI by experienced radiologists following which peri-tumoral ROIs were defined. Radiomic features were extracted within the intra- and peri-tumoral ROIs. Radiomic features differentiating low-risk from: (1) high-risk (L-vs.-H), and (2) (intermediate- and high-risk (L-vs.-I + H)) lesions were identified. Using a multi-institutional training cohort of 151 lesions (D1,N =116 patients), machine learning classifiers were trained using peri- and intra-tumoral features individually and in combination. The remaining 150 lesions (D2,N =115 patients) were used for independent hold-out validation and were evaluated using Receiver Operating Characteristic (ROC) analysis and compared with PI-RADS v2 scores.Results: Validation on D2 using peri-tumoral radiomics alone resulted in areas under the ROC curve (AUCs) of 0.84 and 0.73 for the L-vs.-H and L-vs.-I + H classifications, respectively. The best combination of intra- and peri-tumoral features resulted in AUCs of 0.87 and 0.75 for the L-vs.-H and L-vs.-I + H classifications, respectively. This combination improved the risk stratification results by 3-6% compared to intra-tumoral features alone. Our radiomics-based model resulted in a 53% accuracy in differentiating L-vs.-H compared to PI-RADS v2 (48%), on the validation set.Conclusion: Our findings suggest that peri-tumoral radiomic features derived from prostate bi-parametric MRI add independent predictive value to intra-tumoral radiomic features for PCa risk assessment.","radiomics,prostate cancer,MRI,artificial intelligence,PIRADS,machine learning,peritumoral region",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Oncology,,6.999,"RESONANCE,ENHANCEMENT",CANCERS,https://www.mdpi.com/2072-6694/12/8/2200/pdf,
12,Mitochondria Segmentation From EM Images via Hierarchical Structured Contextual Forest,24,8,2251-2259,"Peng Jialin,Yuan Zhimin","Peng JL,Yuan ZM",Peng JL; Yuan ZM,10.1109/JBHI.2019.2961792,Huaqiao University,"Delineation of mitochondria from electron microscopy (EM) images is crucial to investigate its morphology and distribution, which are directly linked to neural dysfunction. However, it is a challenging task due to the varied appearances, sizes and shapes of mitochondria, and complicated surrounding structures. Exploiting sufficient contextual information about interactions in extended neighborhood is crucial to address the challenges. To this end, we introduce a novel class of contextual features, namely local patch pattern (LPP), to eliminate the ambiguity of local appearance and texture features. To achieve accurate segmentation, we propose an automatic method by iterative learning of hierarchical structured contextual forest. With a novel median fusion strategy, the probability predictions from long history iterations are augmented to encode spatial and temporal contexts and suppress false detections. Moreover, the LPP features are extracted on both images and history predictions, resulting in a hierarchy of contextual features with increasing receptive fields. Other than using computationally demanding graph based methods, we perform joint label prediction using structured random forest. In addition to direct 3D segmentation of EM volumes, we introduce a 2D variant without sacrificing accuracy using a novel hierarchical multi-view fusion strategy. We evaluated our proposed methods on public EPFL Hippocampus benchmark, achieving state-of-the-art performance of 90.9% in Dice. Quantitative comparison showed the effectiveness of the proposed features and strategies.","Image segmentation,Feature extraction,Three-dimensional displays,Random forests,Shape,History,Labeling,Segmentation,electron microscopy image,contextual features,hierarchical learning,multi-view fusion",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,CLASSIFICATION,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
13,An Effective MR-Guided CT Network Training for Segmenting Prostate in CT Images,24,8,2278-2291,"Yang Wanqi,Shi Yinghuan,Park Sang Hyun,Yang Ming,Gao Yang,Shen Dinggang","Yang WQ,Shi YH,Park SH,Yang M,Gao Y,Shen DG",Yang WQ,10.1109/JBHI.2019.2960153,Nanjing Normal University,"Segmentation of prostate in medical imaging data (e.g., CT, MRI, TRUS) is often considered as a critical yet challenging task for radiotherapy treatment. It is relatively easier to segment prostate from MR images than from CT images, due to better soft tissue contrast of the MR images. For segmenting prostate from CT images, most previous methods mainly used CT alone, and thus their performances are often limited by low tissue contrast in the CT images. In this article, we explore the possibility of using indirect guidance from MR images for improving prostate segmentation in the CT images. In particular, we propose a novel deep transfer learning approach, i.e., MR-guided CT network training (namely MICS-NET), which can employ MR images to help better learning of features in CT images for prostate segmentation. In MICS-NET, the guidance from MRI consists of two steps: (1) learning informative and transferable features from MRI and then transferring them to CT images in a cascade manner, and (2) adaptively transferring the prostate likelihood of MRI model (i.e., well-trained convnet by purely using MR images) with a view consistency constraint. To illustrate the effectiveness of our approach, we evaluate MICS-NET on a real CT prostate image set, with the manual delineations available as the ground truth for evaluation. Our methods generate promising segmentation results which achieve (1) six percentages higher Dice Ratio than the CT model purely using CT images and (2) comparable performance with the MRI model purely using MR images.","Computed tomography,Image segmentation,Magnetic resonance imaging,Training,Biomedical imaging,Informatics,Planning,Prostate segmentation,deep transfer learning,fully convolutional network,cascade learning,view consistency constraint",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"CONVOLUTIONAL,NEURAL-NETWORKS,FEATURE,REPRESENTATION,LEARNING,ALGORITHM,SEGMENTATION,REGISTRATION,CLASSIFICATION,EVOLUTION,BIOPSY",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
14,Early and Late Fusion Machine Learning on Multi-Frequency Electrical Impedance Data to Improve Radiofrequency Ablation Monitoring,24,8,2359-2367,"Besler Emre,Wang Yearnchee Curtis,Sahakian Alan V.","Besler E,Wang YC,Sahakian AV",Sahakian AV,10.1109/JBHI.2019.2952922,Northwestern University,"Radiofrequency ablation (RFA) is a popular modality for tumor treatment. However, inexpensive real-time monitoring of RFA within multiple tissue types is still an ongoing research topic. The objective of this study is to utilize multi-frequency electrical impedance data within real-time RFA depth estimation through data fusion schemes that include non-linear machine learning (ML) models. Multi-frequency tissue complex electrical impedance measurements are used to provide input data to the data fusion schemes. Our results show that the fusion schemes significantly decrease both the spread of residuals and the mean of the residuals for depth estimation. Thus, data fusion can be a significant tool for use in improving the performance of ML-based monitoring for RFA.","Impedance,Frequency measurement,Impedance measurement,Data integration,Data models,Monitoring,Informatics,Data fusion,machine learning,ensemble,lesion,depth,svm,random forest,adaptive boosting,radiofrequency ablation,tumor,cancer,control,monitoring",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"REAL-TIME,MICROWAVE,ABLATION,IMAGE,FUSION,TEMPERATURE,LIVER,MODEL,SIZE,LUNG,EIT",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
15,Highly Accurate Bathroom Activity Recognition Using Infrared Proximity Sensors,24,8,2368-2377,"Chapron Kevin,Lapointe Patrick,Bouchard Kevin,Gaboury Sebastien","Chapron K,Lapointe P,Bouchard K,Gaboury S",Gaboury S,10.1109/JBHI.2019.2963388,"Lab Intelligence Ambiante Reconnaissance Act LIAR, 555 Blvd Univ, Chicoutimi, PQ G7H 2B1, Canada.","Among elderly populations over the world, a high percentage of individuals are affected by physical or mental diseases, greatly influencing their quality of life. As it is a known fact that they wish to remain in their own home for as long as possible, solutions must be designed to detect these diseases automatically, limiting the reliance on human resources. To this end, our team developed a sensors platform based on infrared proximity sensors to accurately recognize basic bathroom activities such as going to the toilet and showering. This article is based on the body of scientific literature which establish evidences that activities relative to corporal hygiene are strongly correlated to health status and can be important signs of the development of eventual disorders. The system is built to be simple, affordable and highly reliable. Our experiments have shown that it can yield an F-Score of 96.94%. Also, the durations collected by our kit are approximately 6 seconds apart from the real ones; those results confirm the reliability of our kit.","Intelligent sensors,Smart homes,Monitoring,Microphones,Informatics,Activity recognition,Activity recognition,bathroom,bathroom activity recognition,health monitoring,sensor,smart home,smart home kit",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"SMART,HOMES,HEALTH",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
16,Enhancement of Chest X-Ray Images to Improve Screening Accuracy Rate Using Iterated Function System and Multilayer Fractional-Order Machine Learning Classifier,12,4,,"Lin Chia-Hung,Wu Jian-Xing,Li Chien-Ming,Chen Pi-Yun,Pai Neng-Sheng,Kuo Ying-Che","Lin CH,Wu JX,Li CM,Chen PY,Pai NS,Kuo YC",Lin CH; Pai NS,10.1109/JPHOT.2020.3013193,National Chin-Yi University of Technology,"Chest X-ray (CXR) images are usually used to identify the causes of patients' symptoms, including the classes of lung or heart disorders. In visualization examination, CXR imaging in anterior-posterior (A-P) views is a preliminary screening method used by clinicians or radiologists to diagnose possible lung abnormalities, such as pneumothorax (Pt), emphysema (E), infiltration (In), lung cancer (M), pneumonia (P), pulmonary fibrosis (F), and pleural effusion (Ef). However, the identification of the causes of multiple abnormalities associated with coexisting conditions presents a challenge. In ruling out a suspected lung disease, the signs and symptoms of physical conditions need to be identified to arrive at a definitive diagnosis. In addition, low contrast CXR images and manual inspection restrict automated screening applications. Hence, this study aims to propose an iterated function system (IFS) and a multilayer fractional-order machine learning classifier to rapidly screen the possible classes of lung diseases within regions of interest on CXR images and to improve screening accuracy. For digital image processes, a two-dimensional (2D) fractional-order convolution is used to enhance symptomatic features. The IFS with nonlinear interpolation functions is then used to reconstruct the 2D feature patterns. These reconstructed patterns are self-affine in the same class and thus help distinguish normal subjects from those with lung diseases. The accuracy rate is thus improved. Pooling is performed to reduce the dimensions of the feature patterns and speed up complex computations. A gray relational analysis-based classifier is used to identify the possible classes of the signs and symptoms of lung diseases. For digital CXR images in A-P view, the proposed multilayer machine learning classifier with k-fold cross-validation presents promising results in screening lung diseases and improving screening accuracy rate relative to traditional methods. The proposed classifier is evaluated in terms of recall (99.6%), precision (87.78%), accuracy (88.88%), and F1 score (0.9334).","Lung,Nonhomogeneous media,Machine learning,Feature extraction,Cancer,Image reconstruction,Chest X-ray,iterated function system,fractional-order convolution,nonlinear interpolation function",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Optics,Physics",,2.602,"LUNG-CANCER,PNEUMONIA,SHAPE",IEEE PHOTONICS JOURNAL,https://doi.org/10.1109/jphot.2020.3013193,
17,Optical Coherence Tomography-Guided Robotic Ophthalmic Microsurgery via Reinforcement Learning from Demonstration,36,4,1207-1218,"Keller Brenton,Draelos Mark,Zhou Kevin,Qian Ruobing,Kuo Anthony N.,Konidaris George,Hauser Kris,Izatt Joseph A.","Keller B,Draelos M,Zhou K,Qian RB,Kuo AN,Konidaris G,Hauser K,Izatt JA",Keller B,10.1109/TRO.2020.2980158,Duke University,"Ophthalmic microsurgery is technically difficult because the scale of required surgical tool manipulations challenge the limits of the surgeon's visual acuity, sensory perception, and physical dexterity. Intraoperative optical coherence tomography (OCT) imaging with micrometer-scale resolution is increasingly being used to monitor and provide enhanced real-time visualization of ophthalmic surgical maneuvers, but surgeons still face physical limitations when manipulating instruments inside the eye. Autonomously controlled robots are one avenue for overcoming these physical limitations. In this article, we demonstrate the feasibility of using learning from demonstration and reinforcement learning with an industrial robot to perform OCT-guided corneal needle insertions in an ex vivo model of deep anterior lamellar keratoplasty (DALK) surgery. Our reinforcement learning agent trained on ex vivo human corneas, then outperformed surgical fellows in reaching a target needle insertion depth in mock corneal surgery trials. This article shows the combination of learning from demonstration and reinforcement learning is a viable option for performing OCT-guided robotic ophthalmic surgery.","Needles,Robots,Microsurgery,Cornea,Learning (artificial intelligence),Task analysis,Deep learning in robotics and automation,learning from demonstration,medical robots and systems,microsurgery",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,7.874,"DEEP,ANTERIOR,LAMELLAR,KERATOPLASTY,OUTCOMES,SURGERY,GAME,TOOL,OCT,GO",IEEE TRANSACTIONS ON ROBOTICS,https://ieeexplore.ieee.org/ielx7/8860/9159950/09069310.pdf,
18,A data-driven framework to predict the morphology of interfacial Cu6Sn5 IMC in SAC/Cu system during laser soldering,50,,115-127,"Kunwar Anil,An Lili,Liu Jiahui,Shang Shengyan,Raback Peter,Ma Haitao,Song Xueguan","Kunwar A,An LL,Liu JH,Shang SY,Raback P,Ma HT,Song XG",Kunwar A,10.1016/j.jmst.2019.12.036,KU Leuven,"A data-driven approach combining together the experimental laser soldering, finite element analysis and machine learning, has been utilized to predict the morphology of interfacial intermetallic compound (IMC) in Sn-xAg-yCu/Cu (SAC/Cu) system. Six types of SAC solders with varying weight proportion of Ag and Cu, have been processed with fiber laser at different magnitudes of power (30-50 W) and scan speed (10-240 mm/min), and the resultant IMC morphologies characterized through scanning electron microscope are categorized as prismatic and scalloped ones. For the different alloy composition and laser parameters, finite element method (FEM) is employed to compute the transient distribution of temperature at the interface of solder and substrates. The FEM-generated datasets are supplied to a neural network that predicts the IMC morphology through the quantified values of temperature dependent Jackson parameter (alpha J). The numerical value of alpha J predicted from neural network is validated with experimental IMC morphologies. The critical scan speed for the morphology transition between prismatic and scalloped IMC is estimated for each solder composition at a given power. Sn-0.7Cu having the largest critical scan speed at 30 W and Sn-3.5Ag alloy having the largest critical scan speed at input power values of 40 W and 50 W, thus possessing the greatest likelihood of forming prismatic interfacial IMC during laser soldering, can be inferred as most suitable SAC solders in applications exposed to shear loads. (C) 2020 Published by Elsevier Ltd on behalf of The editorial office of Journal of Materials Science & Technology.","Intermetallic compound,Neural network,Finite element method (FEM),Laser parameters,Lead-free solders,Morphology",Article,"JOURNAL MATER SCI TECHNOL, 72 WENHUA RD, SHENYANG 110015, PEOPLES R CHINA","Materials Science,Metallurgy & Metallurgical Engineering",,6.841,"INTERMETALLIC,COMPOUNDS,GROWTH-BEHAVIOR,CU,NANOPARTICLES,NEURAL-NETWORKS,SN%2FCU,JOINTS,FIELD,MODEL,SN,ALLOYS",JOURNAL OF MATERIALS SCIENCE & TECHNOLOGY,https://lirias.kuleuven.be/bitstream/123456789/668757/2/Laser_science_and_neural_networks-2020.pdf,
19,Rapid motor fluctuations reveal short-timescale neurophysiological biomarkers of Parkinson's disease,17,4,,"Ahn Minkyu,Lee Shane,Lauro Peter M.,Schaeffer Erin L.,Akbar Umer,Asaad Wael F.","Ahn M,Lee S,Lauro PM,Schaeffer EL,Akbar U,Asaad WF",Asaad WF,10.1088/1741-2552/abaca3,Brown University,"Objective.Identifying neural activity biomarkers of brain disease is essential to provide objective estimates of disease burden, obtain reliable feedback regarding therapeutic efficacy, and potentially to serve as a source of control for closed-loop neuromodulation. In Parkinson's disease (PD), microelectrode recordings (MER) are routinely performed in the basal ganglia to guide electrode implantation for deep brain stimulation (DBS). While pathologically-excessive oscillatory activity has been observed and linked to PD motor dysfunction broadly, the extent to which these signals provide quantitative information about disease expression and fluctuations, particularly at short timescales, is unknown. Furthermore, the degree to which informative signal features are similar or different across patients has not been rigorously investigated. We sought to determine the extent to which motor error in PD across patients can be decoded on a rapid timescale using spectral features of neural activity.Approach.Here, we recorded neural activity from the subthalamic nucleus (STN) of subjects with PD undergoing awake DBS surgery while they performed an objective, continuous behavioral assessment that synthesized heterogenous PD motor manifestations to generate a scalar measure of motor dysfunction at short timescales. We then leveraged natural motor performance variations as a 'ground truth' to identify corresponding neurophysiological biomarkers.Main results.Support vector machines using multi-spectral decoding of neural signals from the STN succeeded in tracking the degree of motor impairment at short timescales (as short as one second). Spectral power across a wide range of frequencies, beyond the classic 'beta' oscillations, contributed to this decoding, and multi-spectral models consistently outperformed those generated using more isolated frequency bands. While generalized decoding models derived across subjects were able to estimate motor impairment, patient-specific models typically performed better.Significance.These results demonstrate that quantitative information about short-timescale PD motor dysfunction is available in STN neural activity, distributed across various patient-specific spectral components, such that an individualized approach will be critical to fully harness this information for optimal disease tracking and closed-loop neuromodulation.","Parkinson's disease,neurophysiology,subthalamic nucleus,deep brain stimulation,biomarker,machine learning,motor behavior,oscillations",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"DEEP,BRAIN-STIMULATION,HUMAN,SUBTHALAMIC,NUCLEUS,HIGH-FREQUENCY,ACTIVITY,RATING-SCALE,BETA-DESYNCHRONIZATION,OSCILLATORY,ACTIVITY,REST,TREMOR,IMPAIRMENT,MRI,MODULATION",JOURNAL OF NEURAL ENGINEERING,https://doi.org/10.1101/2020.03.04.20024869,
20,Decoding multiclass motor imagery EEG from the same upper limb by combining Riemannian geometry features and partial least squares regression,17,4,,"Chu Yaqi,Zhao Xingang,Zou Yijun,Xu Weiliang,Song Guoli,Han Jianda,Zhao Yiwen","Chu YQ,Zhao XG,Zou YJ,Xu WL,Song GL,Han JD,Zhao YW",Zhao XG,10.1088/1741-2552/aba7cd,Chinese Academy of Sciences,"Objective. Due to low spatial resolution and poor signal-to-noise ratio of electroencephalogram (EEG), high accuracy classifications still suffer from lots of obstacles in the context of motor imagery (MI)-based brain-machine interface (BMI) systems. Particularly, it is extremely challenging to decode multiclass MI EEG from the same upper limb. This research proposes a novel feature learning approach to address the classification problem of 6-class MI tasks, including imaginary elbow flexion/extension, wrist supination/pronation, and hand close/open within the unilateral upper limb.Approach. Instead of the traditional common spatial pattern (CSP) or filter-bank CSP (FBCSP) manner, the Riemannian geometry (RG) framework involving Riemannian distance and Riemannian mean was directly adopted to extract tangent space (TS) features from spatial covariance matrices of the MI EEG trials. Subsequently, to reduce the dimensionality of the TS features, the algorithm of partial least squares regression was applied to obtain more separable and compact feature representations.Main results. The performance of the learned RG feature representations was validated by a linear discriminative analysis and support vector machine classifier, with an average accuracy of 80.50% and 79.70% on EEG dataset collected from 12 participants, respectively.Significance. These results demonstrate that compared with CSP and FBCSP features, the proposed approach can significantly increase the decoding accuracy for multiclass MI tasks from the same upper limb. This approach is promising and could potentially be applied in the context of MI-based BMI control of a robotic arm or a neural prosthesis for motor disabled patients with highly impaired upper limb.","motor imagery EEG,same upper limb,Riemannian geometry features,partial least squares regression,brain-machine interface",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"BRAIN-COMPUTER,INTERFACES,SENSORIMOTOR,RHYTHMS,CLASSIFICATION,LEVEL,TIME",JOURNAL OF NEURAL ENGINEERING,https://doi.org/10.1088/1741-2552/aba7cd,
21,Linear versus deep learning methods for noisy speech separation for EEG-informed attention decoding,17,4,,"Das Neetha,Zegers Jeroen,Van Hamme Hugo,Francart Tom,Bertrand Alexander","Das N,Zegers J,Van Hamme H,Francart T,Bertrand A",Zegers J,10.1088/1741-2552/aba6f8,KU Leuven,"Objective. A hearing aid's noise reduction algorithm cannot infer to which speaker the user intends to listen to. Auditory attention decoding (AAD) algorithms allow to infer this information from neural signals, which leads to the concept of neuro-steered hearing aids. We aim to evaluate and demonstrate the feasibility of AAD-supported speech enhancement in challenging noisy conditions based on electroencephalography recordings.Approach. The AAD performance with a linear versus a deep neural network (DNN) based speaker separation was evaluated for same-gender speaker mixtures using three different speaker positions and three different noise conditions.Main results. AAD results based on the linear approach were found to be at least on par and sometimes even better than pure DNN-based approaches in terms of AAD accuracy in all tested conditions. However, when using the DNN to support a linear data-driven beamformer, a performance improvement over the purely linear approach was obtained in the most challenging scenarios. The use of multiple microphones was also found to improve speaker separation and AAD performance over single-microphone systems.Significance. Recent proof-of-concept studies in this context each focus on a different method in a different experimental setting, which makes it hard to compare them. Furthermore, they are tested in highly idealized experimental conditions, which are still far from a realistic hearing aid setting. This work provides a systematic comparison of a linear and non-linear neuro-steered speech enhancement model, as well as a more realistic validation in challenging conditions.","neuro-steered hearing aids,source separation,auditory attention decoding,EEG processing,cocktail party,deep learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"SELECTIVE,AUDITORY,ATTENTION,TRACKING,SINGLE,ENHANCEMENT,ENVIRONMENT,SPEAKER",JOURNAL OF NEURAL ENGINEERING,https://lirias.kuleuven.be/bitstream/123456789/658963/2/20-103.pdf,
22,Improved tracking of sevoflurane anesthetic states with drug-specific machine learning models,17,4,,"Kashkooli Kimia,Polk Sam L.,Hahm Eunice Y.,Murphy James,Ethridge Breanna R.,Gitlin Jacob,Ibala Reine,Mekonnen Jennifer,Pedemonte Juan C.,Sun Haoqi","Kashkooli K,Polk SL,Hahm EY,Murphy J,Ethridge BR,Gitlin J,Ibala R,Mekonnen J,Pedemonte JC,Sun HQ",Chamadia S,10.1088/1741-2552/ab98da,Harvard University,"Objective.The ability to monitor anesthetic states using automated approaches is expected to reduce inaccurate drug dosing and side-effects. Commercially available anesthetic state monitors perform poorly when ketamine is administered as an anesthetic-analgesic adjunct. Poor performance is likely because the models underlying these monitors are not optimized for the electroencephalogram (EEG) oscillations that are unique to the co-administration of ketamine.Approach.In this work, we designed twok-nearest neighbors algorithms for anesthetic state prediction.Main results.The first algorithm was trained only on sevoflurane EEG data, making it sevoflurane-specific. This algorithm enabled discrimination of the sevoflurane general anesthesia (GA) state from sedated and awake states (true positive rate = 0.87, [95% CI, 0.76, 0.97]). However, it did not enable discrimination of the sevoflurane-plus-ketamine GA state from sedated and awake states (true positive rate = 0.43, [0.19, 0.67]). In our second algorithm, we implemented a cross drug training paradigm by including both sevoflurane and sevoflurane-plus-ketamine EEG data in our training set. This algorithm enabled discrimination of the sevoflurane-plus-ketamine GA state from sedated and awake states (true positive rate = 0.91, [0.84, 0.98]).Significance.Instead of a one-algorithm-fits-all-drugs approach to anesthetic state monitoring, our results suggest that drug-specific models are necessary to improve the performance of automated anesthetic state monitors.","anesthesia,electroencephalogram,ketamine,machine learning,sevoflurane",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,,"BISPECTRAL,INDEX,APPROXIMATE,ENTROPY,NITROUS-OXIDE,TIME-SERIES,ELECTROENCEPHALOGRAM,KETAMINE,PROPOFOL,OSCILLATIONS,MECHANISMS,FREQUENCY",JOURNAL OF NEURAL ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7540939,
23,Machine learning approaches for the prediction of materials properties,8,8,,"Chibani Siwar,Coudert Francois-Xavier","Chibani S,Coudert FX",Coudert FX,10.1063/5.0018384,Centre National de la Recherche Scientifique (CNRS),"We give here a brief overview of the use of machine learning (ML) in our field, for chemists and materials scientists with no experience with these techniques. We illustrate the workflow of ML for computational studies of materials, with a specific interest in the prediction of materials properties. We present concisely the fundamental ideas of ML, and for each stage of the workflow, we give examples of the possibilities and questions to be considered in implementing ML-based modeling.","MECHANICAL-PROPERTIES,DESIGN,EXPLORATION,ENERGIES,DRIVEN",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Science & Technology - Other Topics,Materials Science,Physics",,4.841,"MECHANICAL-PROPERTIES,DESIGN,EXPLORATION,ENERGIES,DRIVEN",APL MATERIALS,https://aip.scitation.org/doi/pdf/10.1063/5.0018384,
24,A Weakly-Supervised Framework for COVID-19 Classification and Lesion Localization From Chest CT,39,8,2615-2625,"Wang Xinggang,Deng Xianbo,Fu Qing,Zhou Qiang,Feng Jiapei,Ma Hui,Liu Wenyu,Zheng Chuansheng","Wang XG,Deng XB,Fu Q,Zhou Q,Feng JP,Ma H,Liu WY,Zheng CS",Zheng CS,10.1109/TMI.2020.2995965,Huazhong University of Science & Technology,"Accurate and rapid diagnosis of COVID-19 suspected cases plays a crucial role in timely quarantine and medical treatment. Developing a deep learning-based model for automatic COVID-19 diagnosis on chest CT is helpful to counter the outbreak of SARS-CoV-2. A weakly-supervised deep learning framework was developed using 3D CT volumes for COVID-19 classification and lesion localization. For each patient, the lung region was segmented using a pre-trained UNet; then the segmented 3D lung region was fed into a 3D deep neural network to predict the probability of COVID-19 infectious; the COVID-19 lesions are localized by combining the activation regions in the classification network and the unsupervised connected components. 499 CT volumes were used for training and 131 CT volumes were used for testing. Our algorithm obtained 0.959 ROC AUC and 0.976 PR AUC. When using a probability threshold of 0.5 to classify COVID-positive and COVID-negative, the algorithm obtained an accuracy of 0.901, a positive predictive value of 0.840 and a very high negative predictive value of 0.982. The algorithm took only 1.93 seconds to process a single patient's CT volume using a dedicated GPU. Our weakly-supervised deep learning model can accurately predict the COVID-19 infectious probability and discover lesion regions in chest CT without the need for annotating the lesions for training. The easily-trained and high-performance deep learning algorithm provides a fast way to identify COVID-19 patients, which is beneficial to control the outbreak of SARS-CoV-2. The developed deep learning software is available at https://github.com/sydney0zq/covid-19-detection.","Computed tomography,Lung,Lesions,Machine learning,Three-dimensional displays,Training,Diseases,COVID-19,COVID-19,CT,deep learning,weak label,SARS-CoV-2,DeCoVNet",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.medrxiv.org/content/medrxiv/early/2020/03/26/2020.03.12.20027185.full.pdf,
25,Automatic Classification of Cardiac Arrhythmias Based on Hybrid Features and Decision Tree Algorithm,17,4,551-561,"Sahoo Santanu,Subudhi Asit,Dash Manasa,Sabut Sukanta","Sahoo S,Subudhi A,Dash M,Sabut S",Sabut S,10.1007/s11633-019-1219-2,Kalinga Institute of Industrial Technology (KIIT),"Accurate classification of cardiac arrhythmias is a crucial task because of the non-stationary nature of electrocardiogram (ECG) signals. In a life-threatening situation, an automated system is necessary for early detection of beat abnormalities in order to reduce the mortality rate. In this paper, we propose an automatic classification system of ECG beats based on the multi-domain features derived from the ECG signals. The experimental study was evaluated on ECG signals obtained from the MIT-BIH Arrhythmia Database. The feature set comprises eight empirical mode decomposition (EMD) based features, three features from variational mode decomposition (VMD) and four features from RR intervals. In total, 15 features are ranked according to a ranker search approach and then used as input to the support vector machine (SVM) and C4.5 decision tree classifiers for classifying six types of arrhythmia beats. The proposed method achieved best result in C4.5 decision tree classier with an accuracy of 98.89% compared to cubic-SVM classifier which achieved an accuracy of 95.35% only. Besides accuracy measures, all other parameters such as sensitivity (Se), specificity (Sp) and precision rates of 95.68%, 99.28% and 95.8% was achieved better in C4.5 classifier. Also the computational time of 0.65 s with an error rate of 0.11 was achieved which is very less compared to SVM. The multi-domain based features with decision tree classifier obtained the best results in classifying cardiac arrhythmias hence the system could be used efficiently in clinical practices.","Electrocardiogram (ECG),cardiac arrhythmias,empirical mode decomposition (EMD),variational mode decomposition (VMD),hybrid features,decision tree classifier",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND","Automation & Control Systems,Computer Science",,,"FEATURE-EXTRACTION,FEATURE-SELECTION,ECG,SYSTEM,TIME",INTERNATIONAL JOURNAL OF AUTOMATION AND COMPUTING,,
26,Predicting Acute Kidney Injury: A Machine Learning Approach Using Electronic Health Records,11,8,,"Abdullah Sheikh S.,Rostamzadeh Neda,Sedig Kamran,Garg Amit X.,McArthur Eric","Abdullah SS,Rostamzadeh N,Sedig K,Garg AX,McArthur E",Sedig K,10.3390/info11080386,Western University (University of Western Ontario),"Acute kidney injury (AKI) is a common complication in hospitalized patients and can result in increased hospital stay, health-related costs, mortality and morbidity. A number of recent studies have shown that AKI is predictable and avoidable if early risk factors can be identified by analyzing Electronic Health Records (EHRs). In this study, we employ machine learning techniques to identify older patients who have a risk of readmission with AKI to the hospital or emergency department within 90 days after discharge. One million patients' records are included in this study who visited the hospital or emergency department in Ontario between 2014 and 2016. The predictor variables include patient demographics, comorbid conditions, medications and diagnosis codes. We developed 31 prediction models based on different combinations of two sampling techniques, three ensemble methods, and eight classifiers. These models were evaluated through 10-fold cross-validation and compared based on the AUROC metric. The performances of these models were consistent, and the AUROC ranged between 0.61 and 0.88 for predicting AKI among 31 prediction models. In general, the performances of ensemble-based methods were higher than the cost-sensitive logistic regression. We also validated features that are most relevant in predicting AKI with a healthcare expert to improve the performance and reliability of the models. This study predicts the risk of AKI for a patient after being discharged, which provides healthcare providers enough time to intervene before the onset of AKI.","acute kidney injury,electronic health records,data mining,automated analysis,imbalanced data,prediction models,risk stratification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"ACUTE-RENAL-FAILURE,LONG-TERM,RISK,RETROSPECTIVE,ANALYSIS,DIALYSIS,SURGERY,MODELS,TRENDS,CARE",INFORMATION,https://www.mdpi.com/2078-2489/11/8/386/pdf,
27,Simulation and Optimization of Electromagnetic Absorption of Polycarbonate/CNT Composites Using Machine Learning,11,8,,"Sidi Salah Lakhdar,Chouai Mohamed,Danlee Yann,Huynen Isabelle,Ouslimani Nassira","Salah LS,Chouai M,Danlee Y,Huynen I,Ouslimani N",Chouai M,10.3390/mi11080778,Universite Abdelhamid Ibn Badis de Mostaganem,"Electronic devices that transmit, distribute, or utilize electrical energy create electromagnetic interference (EMI) that can lead to malfunctioning and degradation of electronic devices. EMI shielding materials block the unwanted electromagnetic waves from reaching the target material. EMI issues can be solved by using a new family of building blocks constituted of polymer and nanofillers. The electromagnetic absorption index of this material is calculated by measuring the ""S-parameters"". In this article, we investigated the use of artificial intelligence (AI) in the EMI shielding field by developing a new system based on a multilayer perceptron neural network designed to predict the electromagnetic absorption of polycarbonate-carbon nanotubes composites films. The proposed system included 15 different multilayer perception (MLP) networks; each network was specialized to predict the absorption value of a specific category sample. The selection of appropriate networks was done automatically, using an independent block. Optimization of the hyper-parameters using hold-out validation was required to ensure the best results. To evaluate the performance of our system, we calculated the similarity error, precision accuracy, and calculation time. The results obtained over our database showed clearly that the system provided a very good result with an average accuracy of 99.7997%, with an overall average calculation time of 0.01295 s. The composite based on polycarbonate-5 wt.% carbon nanotube was found to be the ultimate absorber over microwave range according to Rozanov formalism.","artificial intelligence (AI),multilayer perception (MLP),electromagnetic interference (EMI) shielding,nanocomposite,absorption index,carbon nanotubes (CNTs),polycarbonate (PC),Rozanov formalism",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Science & Technology - Other Topics,Instruments & Instrumentation,Physics",,2.943,"NEURAL-NETWORKS,PREDICTION",MICROMACHINES,https://www.mdpi.com/2072-666X/11/8/778/pdf,
28,Feature Extraction of Laser Machining Data by Using Deep Multi-Task Learning,11,8,,"Zhang Quexuan,Wang Zexuan,Wang Bin,Ohsawa Yukio,Hayashi Teruaki","Zhang QX,Wang ZX,Wang B,Ohsawa Y,Hayashi T",Zhang QX,10.3390/info11080378,University of Tokyo,"Laser machining has been widely used for materials processing, while the inherent complex physical process is rather difficult to be modeled and computed with analytical formulations. Through attending a workshop on discovering the value of laser machining data, we are profoundly motivated by the recent work by Tani et al., who proposed in situ monitoring of laser processing assisted by neural networks. In this paper, we propose an application of deep learning in extracting representative features from laser processing images with a multi-task loss that consists of cross-entropy loss and logarithmic smoothL1loss. In the experiment, AlexNet with multi-task learning proves to be better than deeper models. This framework of deep feature extraction also has tremendous potential to solve more laser machining problems in the future.","deep learning,feature extraction,multi-task learning,laser processing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"JACKETS,MARKET",INFORMATION,https://www.mdpi.com/2078-2489/11/8/378/pdf,
29,Deep Learning Approaches for Pathological Voice Detection Using Heterogeneous Parameters,E103D,8,1920-1923,"Lee JiYeoun,Choi Hee-Jin","Lee J,Choi HJ",Lee J,10.1587/transinf.2020EDL8031,Jungwon University,"We propose a deep learning-based model for classifying pathological voices using a convolutional neural network and a feedforward neural network. The model uses combinations of heterogeneous parameters, including mel-frequency cepstral coefficients, linear predictive cepstral coefficients and higher-order statistics. We validate the accuracy of this model using the Massachusetts Eye and Ear Infirmary (MEEI) voice disorder database and the Saarbruecken Voice Database (SVD). Our model achieved an accuracy of 99.3% for MEEI and 75.18% for SVD. This model achieved an accuracy that is 7.18% higher than that of competitive models in previous studies.","pathological voice detection,feedforward neural network,convolutional neural network,higher-order statistics,deep learning method",Article,"IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG, KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011, JAPAN",Computer Science,,0.523,,IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS,https://www.jstage.jst.go.jp/article/transinf/E103.D/8/E103.D_2020EDL8031/_pdf,
30,"Reconstruction of Missing Gas, Oil, and Water Flow-Rate Data: A Unified Physics and Data-Based Approach",23,3,1019-1030,"Negash Berihun Mamo,Him Poon Chee","Negash BM,Him PC",Negash BM,,Universiti Teknologi Petronas,"An incomplete data set of flow rate and pressure is detrimental to reservoir management and operation. It has the potential to increase uncertainty and has the potential to unfavorably affect operational and managerial decisions. Such a data set might transpire because of failure in the flowmeters, pressure gauges, and/or unrecorded shut-in periods. This study proposes and evaluates unified physics and data-based analytics for ""learning"" the underlying behavior of a reservoir and reconstructing missing gas, oil, and water flow rates. The proposed workflow is evaluated using real field data obtained from a North Sea reservoir. Validation is done by using a whiteness test, a goodness-of-fit test, and a novel physics-based validation using material balance and pressure back-calculation. The outcome has shown the capability and flexibility of the selected machine-learning techniques in estimating the missing flow rate on the basis of pressure responses. The features that are extracted and expanded on the basis of physics have resulted in a high-fidelity model with less computation time.","KERNEL,APPROXIMATION,REGRESSION,MODEL",Article,"SOC PETROLEUM ENG, 222 PALISADES CREEK DR,, RICHARDSON, TX 75080 USA","Energy & Fuels,Engineering,Geology",,,"KERNEL,APPROXIMATION,REGRESSION,MODEL",SPE RESERVOIR EVALUATION & ENGINEERING,,
31,A mean field approach to model levels of consciousness from EEG recordings,2020,8,,"Javarone Marco Alberto,Gosseries Olivia,Marinazzo Daniele,Noirhomme Quentin,Bonhomme Vincent,Laureys Steven,Chennu Srivas","Javarone MA,Gosseries O,Marinazzo D,Noirhomme Q,Bonhomme V,Laureys S,Chennu S",Javarone MA,10.1088/1742-5468/ababfb,University of London,"We introduce a mean-field model for analysing the dynamics of human consciousness. In particular, inspired by the Giulio Tononi's Integrated Information Theory and by the Max Tegmark's representation of consciousness, we study order-disorder phase transitions on Curie-Weiss models generated by processing EEG signals. The latter have been recorded on healthy individuals undergoing deep sedation. Then, we implement a machine learning tool for classifying mental states using, as input, the critical temperatures computed in the Curie-Weiss models. Results show that, by the proposed method, it is possible to discriminate between states of awareness and states of deep sedation. Besides, we identify a state space for representing the path between mental states, whose dimensions correspond to critical temperatures computed over different frequency bands of the EEG signal. Beyond possible theoretical implications in the study of human consciousness, resulting from our model, we deem relevant to emphasise that the proposed method could be exploited for clinical applications.","computational neuroscience,classical phase transitions",Article,"IOP Publishing Ltd, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Mechanics,Physics",,,"BRAIN,SLEEP,STATE",JOURNAL OF STATISTICAL MECHANICS-THEORY AND EXPERIMENT,https://biblio.ugent.be/publication/8672834/file/8672835,
32,Computer-aided diagnosis (CAD) system based on multi-layer feature fusion network for skin lesion recognition in dermoscopy images,79,29-30,20483-20518,"Bakkouri Ibtissam,Afdel Karim","Bakkouri I,Afdel K",Bakkouri I,10.1007/s11042-019-07988-1,Ibn Zohr University of Agadir,"Skin lesion recognition is one of the most important tasks in dermoscopic image analysis. Current Convolutional Neural Network (CNN) algorithms based recognition methods tend to become a standard methodology to fix a large array of Computer-Aided Diagnosis (CAD) and interpretation problems. Besides significant practical and theoretical improvements in their architecture, their effectiveness is built on the existence of the flexible pre-trained models which generalize well to novel tasks and handle the problem of having small set of dermoscopic data. However, existing works pay little attention to exploring the benefits of hierarchical multi-feature fusion for classifying the skin lesions in digital dermoscopic images. Practically, it has been found that integrating multi-layer features has significant potential for improving performance of any pattern recognition task. In this paper, we developed a robust CAD system based on transfer learning and multi-layer feature fusion network to diagnose complex skin diseases. It is a convenient approach in terms of overfitting prevention, convergence speed and high morphological feature similarity processing. Our research focuses exclusively on obtaining optimal performance with addressing the various gaps in the skin pattern recognition area. For validation and comparison purposes, the proposed approach was evaluated on publicly dermoscopic dataset, and achieved the high recognition precision compared with fully trained CNN models, fine-tuning process, single CNN model and other related works. Therefore, the study demonstrates that our proposed approach can dramatically improve the performance of CAD systems which are based on the conventional recognition and classification algorithms for skin lesion recognition in dermoscopic data.","Skin diseases,Dermoscopic pattern recognition,Transfer learning,Multi-layer feature fusion,Multi-class classification",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"CONVOLUTIONAL,NEURAL-NETWORKS,CLASSIFICATION,CANCER,SEGMENTATION,EXTRACTION,MELANOMA,CNN",MULTIMEDIA TOOLS AND APPLICATIONS,,
33,Learning Effective Spatial-Temporal Features for sEMG Armband-Based Gesture Recognition,7,8,6979-6992,"Zhang Yingwei,Chen Yiqiang,Yu Hanchao,Yang Xiaodong,Lu Wang","Zhang YW,Chen YQ,Yu HC,Yang XD,Lu W",Chen YQ,10.1109/JIOT.2020.2979328,Chinese Academy of Sciences,"Surface electromyography (sEMG) armband-based gesture recognition is an active research topic that aims to identify hand gestures with a single row of sEMG electrodes. As a typical type of biological signal, sEMG on one channel is nonstationary temporally and related to multiple adjacent muscles spatially, which hinders the effective representation in gesture recognition. To tackle these aspects, we propose a spatial-temporal features-based gesture recognition method (STF-GR) in this article. Specifically, STF-GR first decomposes the nonstationary multichannel sEMG by multivariate empirical mode decomposition, which jointly transforms each channel into a series of stationary subsignals. It can keep the temporal stationarity within-channel as well as the spatial independence across-channel. Then, by the convolutional recurrent neural network, STF-GR extracts and merges spatial-temporal features of decomposed sEMG signal. Finally, a negative log-likelihood-based cost function is used to make the final gesture decision. To evaluate the performance of STF-GR, we conduct experiments on three data sets, noninvasive adaptive hand prosthetic (NinaPro), CapgMyo, and BandMyo. The first two are publicly available, and BandMyo is collected by ourselves. Experimental evaluations with within-subject tests show that STF-GR exceeds the performance of other state-of-the-art methods, including deep learning algorithms that are not focused on spatial-temporal features and traditional machine learning algorithms that use handcrafted features.","Electrodes,Gesture recognition,Muscles,Electromyography,Internet of Things,Empirical mode decomposition,Convolutional recurrent neural network (CRNN),gesture recognition,multivariate empirical mode decomposition (MEMD),surface electromyography (sEMG)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,10.127,"EMPIRICAL-MODE-DECOMPOSITION,CLASSIFICATION",IEEE INTERNET OF THINGS JOURNAL,,
34,Reconfigurable Intelligent Surface Assisted Multiuser MISO Systems Exploiting Deep Reinforcement Learning,38,8,1839-1850,"Huang Chongwen,Mo Ronghong,Yuen Chau","Huang CW,Mo RH,Yuen C",Mo RH,10.1109/JSAC.2020.3000835,Singapore University of Technology & Design,"Recently, the reconfigurable intelligent surface (RIS), benefited from the breakthrough on the fabrication of programmable meta-material, has been speculated as one of the key enabling technologies for the future six generation (6G) wireless communication systems scaled up beyond massive multiple input multiple output (Massive-MIMO) technology to achieve smart radio environments. Employed as reflecting arrays, RIS is able to assist MIMO transmissions without the need of radio frequency chains resulting in considerable reduction in power consumption. In this paper, we investigate the joint design of transmit beamforming matrix at the base station and the phase shift matrix at the RIS, by leveraging recent advances in deep reinforcement learning (DRL). We first develop a DRL based algorithm, in which the joint design is obtained through trial-and-error interactions with the environment by observing predefined rewards, in the context of continuous state and action. Unlike the most reported works utilizing the alternating optimization techniques to alternatively obtain the transmit beamforming and phase shifts, the proposed DRL based algorithm obtains the joint design simultaneously as the output of the DRL neural network. Simulation results show that the proposed algorithm is not only able to learn from the environment and gradually improve its behavior, but also obtains the comparable performance compared with two state-of-the-art benchmarks. It is also observed that, appropriate neural network parameter settings will improve significantly the performance and convergence rate of the proposed algorithm.","Array signal processing,MIMO communication,Optimization,Wireless communication,MISO communication,Antenna arrays,Receivers,Reconfigurable intelligent surface,Massive MIMO,6G,smart radio environment,beamforming matrix,phase shift matrix,deep reinforcement learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Telecommunications",,9.069,"MASSIVE,MIMO,WIRELESS,COMMUNICATION,NETWORKS",IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS,http://arxiv.org/pdf/2002.10072,
35,How the Cerebellum and Prefrontal Cortex Cooperate During Trace Eyeblinking Conditioning,30,8,,"Caligiore Daniele,Mirino Pierandrea","Caligiore D,Mirino P",Caligiore D,10.1142/S0129065720500410,Consiglio Nazionale delle Ricerche (CNR),"Several data have demonstrated that during the widely used experimental paradigm for studying associative learning, trace eye blinking conditioning (TEBC), there is a strong interaction between cerebellum and medial prefrontal cortex (mPFC). Despite this evidence, the neural mechanisms underlying this interaction are still not clear. Here, we propose a neurophysiologically plausible computational model to address this issue. The model is constrained on the basis of two critical anatomo-physiological features: (i) the cerebello-cortical organization through two circuits, respectively, targeting M1 and mPFC; (ii) the different timing in the plasticity mechanisms of these parallel circuits produced by the granule cells time sensitivity according to which different subpopulations are active at different moments during conditioned stimuli. The computer simulations run with the model suggest that these features are critical to understand how the cooperation between cerebellum and mPFC supports motor areas during TEBC. In particular, a greater trace interval produces greater plasticity changes at the slow path synapses involving mPFC with respect to plasticity changes at the fast path involving M1. As a consequence, the greater is the trace interval, the stronger is the mPFC involvement. The model has been validated by reproducing data collected through recent real mice experiments.","Granular time-sensitivity,spiking neural networks,system-level neuroscience,eye blinking conditioning,prefrontal cortex",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Computer Science,,,"SPIKING,NEURAL-NETWORKS,MOTOR,CORTEX,HIPPOCAMPAL-LESIONS,DOPAMINE,RELEASE,BASAL,GANGLIA,DELAY,PLASTICITY,MODEL,MECHANISMS,REORGANIZATION",INTERNATIONAL JOURNAL OF NEURAL SYSTEMS,,
36,Towards development of alert thresholds for clinical deterioration using continuous predictive analytics monitoring,34,4,797-804,"Keim-Malpass Jessica,Clark Matthew T.,Lake Douglas E.,Moorman J. Randall","Keim-Malpass J,Clark MT,Lake DE,Moorman JR",Keim-Malpass J,10.1007/s10877-019-00361-5,University of Virginia,"Patients who deteriorate while on the acute care ward and are emergently transferred to the Intensive Care Unit (ICU) experience high rates of mortality. To date, risk scores for clinical deterioration applied to the acute care wards rely on static or intermittent inputs of vital sign and assessment parameters. We propose the use of continuous predictive analytics monitoring, or data that relies on real-time physiologic monitoring data captured from ECG, documented vital signs, laboratory results, and other clinical assessments to predict clinical deterioration. A necessary step in translation to practice is understanding how an alert threshold would perform if applied to a continuous predictive analytic that was trained to detect clinical deterioration. The purpose of this study was to evaluate the positive predictive value of 'risk spikes', or large abrupt increases in the output of a statistical model of risk predicting clinical deterioration. We studied 8111 consecutive patient admissions to a cardiovascular medicine and surgery ward with continuous ECG data. We first trained a multivariable logistic regression model for emergent ICU transfer in a test set and tested the characteristics of the model in a validation set of 4059 patient admissions. Then, in a nested analysis we identified large, abrupt spikes in risk (increase by three units over the prior 6 h; a unit is the fold-increase in risk of ICU transfer in the next 24 h) and reviewed hospital records of 91 patients for clinical events such as emergent ICU transfer. We compared results to 59 control patients at times when they were matched for baseline risk including the National Warning Score (NEWS). There was a 3.4-fold higher event rate for patients with risk spikes (positive predictive value 24% compared to 7%,p = 0.006). If we were to use risk spikes as an alert, they would fire about once per day on a 73-bed acute care ward. Risk spikes that were primarily driven by respiratory changes (ECG-derived respiration (EDR) or charted respiratory rate) had highest PPV (30-35%) while risk spikes driven by heart rate had the lowest (7%). Alert thresholds derived from continuous predictive analytics monitoring are able to be operationalized as a degree of change from the person's own baseline rather than arbitrary threshold cut-points, which can likely better account for the individual's own inherent acuity levels. Point of care clinicians in the acute care ward settings need tailored alert strategies that promote a balance in recognition of clinical deterioration and assessment of the utility of the alert approach.","Machine learning,Clinical computing,Clinical deterioration,Predictive analytics,Continuous predictive analytics monitoring,Alert,Implementation science",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Anesthesiology,,2.155,"HEART-RATE,CHARACTERISTICS,INTENSIVE-CARE,ATRIAL-FIBRILLATION,HEALTH-CARE,BIG,DATA,VALIDATION,DYNAMICS,SEPSIS,RHYTHM,MODEL",JOURNAL OF CLINICAL MONITORING AND COMPUTING,,
37,BPGAN: Bidirectional CT-to-MRI prediction using multi-generative multi-adversarial nets with spectral normalization and localization,128,,82-96,"Xu Liming,Zeng Xianhua,Zhang He,Li Weisheng,Lei Jianbo,Huang Zhiwei","Xu LM,Zeng XH,Zhang H,Li WS,Lei JB,Huang ZW",Zeng XH,10.1016/j.neunet.2020.05.001,Chongqing University of Posts & Telecommunications,"Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) are widely used detection technology in screening, diagnosis, and image-guided therapy for both clinical and research. However, CT imposes ionizing radiation to patients during acquisition. Compared to CT, MRI is much safer and does not involve any radiations, but it is more expensive and has prolonged acquisition time. Therefore, it is necessary to estimate one modal image from another given modal image of the same subject for the case of radiotherapy planning. Considering that there is currently no bidirectional prediction model between MRI and CT images, we propose a bidirectional prediction by using multi-generative multi-adversarial nets (BPGAN) for the prediction of any modal from another modal image in paired and unpaired fashion. In BPGAN, two nonlinear maps are learned by projecting same pathological features from one domain to another with cycle consistency strategy. Technologically, pathological prior information is introduced to constrain the feature generation to attack the potential risk of pathological variance, and edge retention metric is adopted to preserve geometrically distortion and anatomical structure. Algorithmically, spectral normalization is designed to control the performance of discriminator and to make predictor learn better and faster, and the localization is proposed to impose regularizer on predictor to reduce generalization error. Experimental results show that BPGAN generates better predictions than recently state-of-the-art methods. Specifically, BPGAN achieves average increment of MAE 33.2% and 37.4%, and SSIM 24.5% and 44.6% on two baseline datasets than comparisons. (C) 2020 Elsevier Ltd. All rights reserved.","Bidirectional prediction,Cross modality,Generative adversarial nets,Pathological invariance,Spectral normalization",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,9.171,"CONVOLUTIONAL,NEURAL-NETWORK,ATTENUATION,CORRECTION,IMAGE,PET%2FMRI",NEURAL NETWORKS,,
38,Automated classification of cells into multiple classes in epithelial tissue of oral squamous cell carcinoma using transfer learning and convolutional neural network,128,,47-60,"Das Navarun,Hussain Elima,Mahanta Lipi B.","Das N,Hussain E,Mahanta LB",Mahanta LB,10.1016/j.neunet.2020.05.003,Department of Science & Technology (India),"The analysis of tissue of a tumor in the oral cavity is essential for the pathologist to ascertain its grading. Recent studies using biopsy images reveal computer-aided diagnosis for oral sub-mucous fibrosis (OSF) carried out using machine learning algorithms, but no research has yet been outlined for multi-class grading of oral squamous cell carcinoma (OSCC). Pertinently, with the advent of deep learning in digital imaging and computational aid in the diagnosis, multi-class classification of OSCC biopsy images can help in timely and effective prognosis and multi-modal treatment protocols for oral cancer patients, thus reducing the operational workload of pathologists while enhancing management of the disease. With this motivation, this study attempts to classify OSCC into its four classes as per the Broder's system of histological grading. The study is conducted on oral biopsy images applying two methods: (i) through the application of transfer learning using pre-trained deep convolutional neural network (CNN) wherein four candidate pre-trained models, namely Alexnet, VGG-16, VGG-19 and Resnet-50, were chosen to find the most suitable model for our classification problem, and (ii) by a proposed CNN model. Although the highest classification accuracy of 92.15% is achieved by Resnet-50 model, the experimental findings highlight that the proposed CNN model outperformed the transfer learning approaches displaying accuracy of 97.5%. It can be concluded that the proposed CNN based multi-class grading method of OSCC could be used for diagnosis of patients with OSCC. (C) 2020 Elsevier Ltd. All rights reserved.","Oral squamous cell carcinoma,Deep learning,Convolution neural network,Transfer learning,Biopsy",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,,"CANCER,PATTERN",NEURAL NETWORKS,,
39,Multi-path connected network for medical image segmentation,71,,,"Wang Dan,Hu Guoqing,Lyu Chengzhi","Wang D,Hu GQ,Lyu CZ",Wang D,10.1016/j.jvcir.2020.102852,South China University of Technology,"In recent years, deep learning has been successfully applied to medical image segmentation. However, as the network extends deeper, the consecutive downsampling operations will lead to more loss of spatial information. In addition, the limited data and diverse targets increase the difficulty for medical image segmentation. To address these issues, we propose a multi-path connected network (MCNet) for medical segmentation problems. It integrates multiple paths generated by pyramid pooling into the encoding phase to preserve semantic information and spatial details. We utilize multi-scale feature extractor block (MFE block) in the encoder to obtain large and multi-scale receptive fields. We evaluated MCNet on three medical datasets with different image modalities. The experimental results show that our method achieves better performance than the state-of-the-art approaches. Our model has strong feature learning ability and is robust to capture different scale targets. It can achieve satisfactory results while using only 0.98 million (M) parameters. (c) 2020 Elsevier Inc. All rights reserved.","Medical image segmentation,Multi-path connections,Convolutional neural networks,Encoder-decoder structure",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA",Computer Science,,2.915,,JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION,,
40,Spatial-Temporal Dependency Modeling and Network Hub Detection for Functional MRI Analysis via Convolutional-Recurrent Network,67,8,2241-2252,"Wang Mingliang,Lian Chunfeng,Yao Dongren,Zhang Daoqiang,Liu Mingxia,Shen Dinggang","Wang ML,Lian CF,Yao DR,Zhang DQ,Liu MX,Shen DG",Zhang DQ,10.1109/TBME.2019.2957921,Nanjing University of Aeronautics & Astronautics,"Early identification of dementia at the stage of mild cognitive impairment (MCI) is crucial for timely diagnosis and intervention of Alzheimer's disease (AD). Although several pioneering studies have been devoted to automated AD diagnosis based on resting-state functional magnetic resonance imaging (rs-fMRI), their performance is somewhat limited due to non-effective mining of spatial-temporal dependency. Besides, few of these existing approaches consider the explicit detection and modeling of discriminative brain regions (i.e., network hubs) that are sensitive to AD progression. In this paper, we propose a unique Spatial-Temporal convolutional-recurrent neural Network (STNet) for automated prediction of AD progression and network hub detection from rs-fMRI time series. Our STNet incorporates the spatial-temporal information mining and AD-related hub detection into an end-to-end deep learning model. Specifically, we first partition rs-fMRI time series into a sequence of overlapping sliding windows. A sequence of convolutional components are then designed to capture the local-to-global spatially-dependent patterns within each sliding window, based on which we are able to identify discriminative hubs and characterize their unique contributions to disease diagnosis. A recurrent component with long short-term memory (LSTM) units is further employed to model the whole-brain temporal dependency from the spatially-dependent pattern sequences, thus capturing the temporal dynamics along time. We evaluate the proposed method on 174 subjects with 563 rs-fMRI scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database, with results suggesting the effectiveness of our method in both tasks of disease progression prediction and AD-related hub detection.","Spatial-temporal dependency,neural network,Alzheimer's disease,hub detection,resting-state functional MRI",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"MILD,COGNITIVE,IMPAIRMENT,CONNECTIVITY,NETWORKS,ALZHEIMERS,PROGRESSION,MCI",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7439279,
41,Mimicking Short-Term Memory in Shape-Reconstruction Task Using an EEG-Induced Type-2 Fuzzy Deep Brain Learning Network,4,4,571-588,"Ghosh Lidia,Konar Amit,Rakshit Pratyusha,Nagar Atulya K.","Ghosh L,Konar A,Rakshit P,Nagar AK",Konar A,10.1109/TETCI.2019.2937566,Jadavpur University,"The paper attempts to model short-term memory (STM) for shape-reconstruction tasks by employing a 4-stage deep brain leaning network (DBLN), where the first two stages are built with Hebbian learning and the last two stages with Type-2 Fuzzy logic. The model is trained stage-wise independently with visual stimulus of the object-geometry as the input of the first stage, EEG acquired from different cortical regions as input and output of respective intermediate stages, and recalled object-geometry as the output of the last stage. Two error feedback loops are employed to train the proposed DBLN. The inner loop adapts the weights of the STM based on a measure of error in model-predicted response with respect to the object-shape recalled by the subject. The outer loop adapts the weights of the iconic (visual) memory based on a measure of error of the model predicted response with respect to the desired object-shape. In the test phase, the DBLN model reproduces the recalled object shape from the given input object geometry. The motivation of the paper is to test the consistency in STM encoding (in terms of similarity in network weights) for repeated visual stimulation with the same geometric object. Experiments undertaken on healthy subjects, yield high similarity in network weights, whereas patients with pre-frontal lobe Amnesia yield significant discrepancy in the trained weights for any two trials with the same training object. This justifies the importance of the proposed DBLN model in automated diagnosis of patients with learning difficulty. The novelty of the paper lies in the overall design of the DBLN model with special emphasis to the last two stages of the network, built with vertical slice based type-2 fuzzy logic, to handle uncertainty in function approximation (with noisy EEG data). The proposed technique outperforms the state-of-the-art functional mapping algorithms with respect to the (pre-defined outer loop) error metric, computational complexity and runtime.","Short-term memory,iconic memory,Hebbian learning,type-2 fuzzy set,shape reconstruction,memory failure and N400",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Computer Science,,,"GAMMA-BAND,ACTIVITY,LOGIC,SYSTEMS,ALPHA,OSCILLATIONS,ATTENTION,CLASSIFICATION,HIPPOCAMPAL,INHIBITION,MECHANISMS,ANATOMY",IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE,http://hira.hope.ac.uk/id/eprint/2926/1/STM%20using%20Fuzzy%20T2.pdf,
42,Accurate Screening of COVID-19 Using Attention-Based Deep 3D Multiple Instance Learning,39,8,2584-2594,"Han Zhongyi,Wei Benzheng,Hong Yanfei,Li Tianyang,Cong Jinyu,Zhu Xue,Wei Haifeng,Zhang Wei","Han ZY,Wei BZ,Hong YF,Li TY,Cong JY,Zhu X,Wei HF,Zhang W",Wei BZ,10.1109/TMI.2020.2996256,Shandong University of Traditional Chinese Medicine,"Automated Screening of COVID-19 from chest CT is of emergency and importance during the outbreak of SARS-CoV-2 worldwide in 2020. However, accurate screening of COVID-19 is still a massive challenge due to the spatial complexity of 3D volumes, the labeling difficulty of infection areas, and the slight discrepancy between COVID-19 and other viral pneumonia in chest CT. While a few pioneering works have made significant progress, they are either demanding manual annotations of infection areas or lack of interpretability. In this paper, we report our attempt towards achieving highly accurate and interpretable screening of COVID-19 from chest CT with weak labels. We propose an attention-based deep 3D multiple instance learning (AD3D-MIL) where a patient-level label is assigned to a 3D chest CT that is viewed as a bag of instances. AD3D-MIL can semantically generate deep 3D instances following the possible infection area. AD3D-MIL further applies an attention-based pooling approach to 3D instances to provide insight into each instance's contribution to the bag label. AD3D-MIL finally learns Bernoulli distributions of the bag-level labels for more accessible learning. We collected 460 chest CT examples: 230 CT examples from 79 patients with COVID-19, 100 CT examples from 100 patients with common pneumonia, and 130 CT examples from 130 people without pneumonia. A series of empirical studies show that our algorithm achieves an overall accuracy of 97.9%, AUC of 99.0%, and Cohen kappa score of 95.7%. These advantages endow our algorithm as an efficient assisted tool in the screening of COVID-19.","Computed tomography,Three-dimensional displays,Diseases,Lung,Two dimensional displays,Manuals,Medical diagnostic imaging,COVID-19,COVID-19,SARS-CoV-2,screening,computer-aided diagnosis,multiple instance learning,attention,3D,deep learning,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,https://ieeexplore.ieee.org/ielx7/42/9153182/09098062.pdf,
43,Dual-Sampling Attention Network for Diagnosis of COVID-19 From Community Acquired Pneumonia,39,8,2595-2605,"Ouyang Xi,Huo Jiayu,Xia Liming,Shan Fei,Liu Jun,Mo Zhanhao,Yan Fuhua,Ding Zhongxiang,Yang Qi,Song Bin","Ouyang X,Huo JY,Xia LM,Shan F,Liu J,Mo ZH,Yan FH,Ding ZX,Yang Q,Song B",Shen DG,10.1109/TMI.2020.2995508,"Shanghai United Imaging Intelligence Co Ltd, Dept Res & Dev, Shanghai 201807, Peoples R China.","The coronavirus disease (COVID-19) is rapidly spreading all over the world, and has infected more than 1,436,000 people in more than 200 countries and territories as of April 9, 2020. Detecting COVID-19 at early stage is essential to deliver proper healthcare to the patients and also to protect the uninfected population. To this end, we develop a dual-sampling attention network to automatically diagnose COVID-19 from the community acquired pneumonia (CAP) in chest computed tomography (CT). In particular, we propose a novel online attention module with a 3D convolutional network (CNN) to focus on the infection regions in lungs when making decisions of diagnoses. Note that there exists imbalanced distribution of the sizes of the infection regions between COVID-19 and CAP, partially due to fast progress of COVID-19 after symptom onset. Therefore, we develop a dual-sampling strategy to mitigate the imbalanced learning. Our method is evaluated (to our best knowledge) upon the largest multi-center CT data for COVID-19 from 8 hospitals. In the training-validation stage, we collect 2186 CT scans from 1588 patients for a 5-fold cross-validation. In the testing stage, we employ another independent large-scale testing dataset including 2796 CT scans from 2057 patients. Results show that our algorithm can identify the COVID-19 images with the area under the receiver operating characteristic curve (AUC) value of 0.944, accuracy of 87.5%, sensitivity of 86.9%, specificity of 90.1%, and F1-score of 82.0%. With this performance, the proposed algorithm could potentially aid radiologists with COVID-19 diagnosis from CAP, especially in the early stage of the COVID-19 outbreak.","Lung,Computed tomography,Diseases,Hospitals,Radiology,Image segmentation,COVID-19,COVID-19 Diagnosis,Online Attention,Explainability,Imbalanced Distribution,Dual Sampling Strategy",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"AUTOMATED,CLASSIFICATION,CT,IMAGE",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2005.02690,
44,Inf-Net: Automatic COVID-19 Lung Infection Segmentation From CT Images,39,8,2626-2637,"Fan Deng-Ping,Zhou Tao,Ji Ge-Peng,Zhou Yi,Chen Geng,Fu Huazhu,Shen Jianbing,Shao Ling","Fan DP,Zhou T,Ji GP,Zhou Y,Chen G,Fu HZ,Shen JB,Shao L",Chen G; Fu HZ; Shen JB,10.1109/TMI.2020.2996645,"Inception Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates.","Coronavirus Disease 2019 (COVID-19) spread globally in early 2020, causing the world to face an existential health crisis. Automated detection of lung infections from computed tomography (CT) images offers a great potential to augment the traditional healthcare strategy for tackling COVID-19. However, segmenting infected regions from CT slices faces several challenges, including high variation in infection characteristics, and low intensity contrast between infections and normal tissues. Further, collecting a large amount of data is impractical within a short time period, inhibiting the training of a deep model. To address these challenges, a novel COVID-19 Lung Infection Segmentation Deep Network (Inf-Net) is proposed to automatically identify infected regions from chest CT slices. In our Inf-Net, a parallel partial decoder is used to aggregate the high-level features and generate a global map. Then, the implicit reverse attention and explicit edge-attention are utilized to model the boundaries and enhance the representations. Moreover, to alleviate the shortage of labeled data, we present a semi-supervised segmentation framework based on a randomly selected propagation strategy, which only requires a few labeled images and leverages primarily unlabeled data. Our semi-supervised framework can improve the learning ability and achieve a higher performance. Extensive experiments on our COVID-SemiSeg and real CT volumes demonstrate that the proposed Inf-Net outperforms most cutting-edge segmentation models and advances the state-of-the-art performance.","Computed tomography,Image segmentation,Lung,Training,Data models,Diseases,X-rays,COVID-19,COVID-19,CT image,infection segmentation,semi-supervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORKS",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://doi.org/10.1101/2020.04.22.20074948,
45,Relational Modeling for Robust and Efficient Pulmonary Lobe Segmentation in CT Scans,39,8,2664-2675,"Xie Weiyi,Jacobs Colin,Charbonnier Jean-Paul,van Ginneken Bram","Xie WY,Jacobs C,Charbonnier JP,van Ginneken B",Xie WY,10.1109/TMI.2020.2995108,"Radboudumc, Dept Radiol & Nucl Med, Diagnost Image Anal Grp, NL-6525 GA Nijmegen, Netherlands.","Pulmonary lobe segmentation in computed tomography scans is essential for regional assessment of pulmonary diseases. Recent works based on convolution neural networks have achieved good performance for this task. However, they are still limited in capturing structured relationships due to the nature of convolution. The shape of the pulmonary lobes affect each other and their borders relate to the appearance of other structures, such as vessels, airways, and the pleural wall. We argue that such structural relationships play a critical role in the accurate delineation of pulmonary lobes when the lungs are affected by diseases such as COVID-19 or COPD. In this paper, we propose a relational approach (RTSU-Net) that leverages structured relationships by introducing a novel non-local neural network module. The proposed module learns both visual and geometric relationships among all convolution features to produce self-attention weights. With a limited amount of training data available from COVID-19 subjects, we initially train and validate RTSU-Net on a cohort of 5000 subjects from the COPDGene study (4000 for training and 1000 for evaluation). Using models pre-trained on COPDGene, we apply transfer learning to retrain and evaluate RTSU-Net on 470 COVID-19 suspects (370 for retraining and 100 for evaluation). Experimental results show that RTSU-Net outperforms three baselines and performs robustly on cases with severe lung infection due to COVID-19.","Computed tomography,Lung,Image segmentation,Diseases,Convolution,Neural networks,Training,COVID-19,Computed Tomography,COVID-19,COPD,Convolution Neural Network,Non-local Neural Networks,Pulmonary Lobe,Segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,FISSURES,IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7393217,
46,Adaptive and Compressive Beamforming Using Deep Learning for Medical Ultrasound,67,8,1558-1572,"Khan Shujaat,Huh Jaeyoung,Ye Jong Chul","Khan S,Huh J,Ye JC",Ye JC,10.1109/TUFFC.2020.2977202,Korea Advanced Institute of Science & Technology (KAIST),"In ultrasound (US) imaging, various types of adaptive beamforming techniques have been investigated to improve the resolution and the contrast-to-noise ratio of the delay and sum (DAS) beamformers. Unfortunately, the performance of these adaptive beamforming approaches degrades when the underlying model is not sufficiently accurate and the number of channels decreases. To address this problem, here, we propose a deep-learning-based beamformer to generate significantly improved images over widely varying measurement conditions and channel subsampling patterns. In particular, our deep neural network is designed to directly process full or subsampled radio frequency (RF) data acquired at various subsampling rates and detector configurations so that it can generate high-quality US images using a single beamformer. The origin of such input-dependent adaptivity is also theoretically analyzed. Experimental results using the B-mode focused US confirm the efficacy of the proposed methods.","Array signal processing,Ultrasonic imaging,Radio frequency,Machine learning,Imaging,Neural networks,Receivers,Adaptive beamformer,beamforming,B-mode,Capon beamformer,ultrasound (US) imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,"CONVOLUTIONAL,NEURAL-NETWORK,LOW-DOSE,CT,RECONSTRUCTION,FRAMELETS",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,http://arxiv.org/pdf/1907.10257,
47,Classifying construction and demolition waste by combining spatial and spectral features,173,3,79-90,"Xiao Wen,Yang Jianhong,Fang Huaiying,Zhuang Jiangteng,Ku Yuedong","Xiao W,Yang JH,Fang HY,Zhuang JT,Ku YD",Yang JH,10.1680/jwarm.20.00008,Huaqiao University,"The generation of construction and demolition waste (C&DW) has increased on a yearly basis, and the damage caused to the environment is significant. To save resources, C&DW needs to be managed and recycled. Currently, waste-classification methods are mainly based on wind selection, water selection, screening and manual sorting. These methods are inefficient and the classification results are not clean. To achieve efficient and intelligent recycling of C&DW, it is essential to classify the wastes effectively. In this paper, four methods are reported: characteristic reflectivity and extreme learning machine (ELM); first-order derivative of characteristic reflectivity and ELM; grey level co-occurrence matrix and ELM and convolutional neural network. These methods were used to classify typical types of hard-to-distinguish waste: wood, rubber, brick and concrete. It was found that each method had inadequacies, and the correct rate was between 82.22 and 89.33%. Therefore, a weighted fusion of membership matrix, which combine all four methods, was proposed. As a result, the correct rate in repeated experiments significantly improved to 95%. The classification results can be used in further study about automatic sorting of C&DW using robotics instead of people.","materials technology,waste management & disposal",Article,"ICE PUBLISHING, INST CIVIL ENGINEERS, 1 GREAT GEORGE ST, WESTMINISTER SW 1P 3AA, ENGLAND",Engineering,,,"EXTREME,LEARNING-MACHINE,INFRARED-SPECTROSCOPY,CLASSIFICATION,MANAGEMENT",PROCEEDINGS OF THE INSTITUTION OF CIVIL ENGINEERS-WASTE AND RESOURCE MANAGEMENT,,
48,Evaluation of potential auras in generalized epilepsy from EEG signals using deep convolutional neural networks and time-frequency representation,65,4,379-391,"Polat Hasan,Aluclu Mehmet Ufuk,Ozerdem Mehmet Sirac","Polat H,Aluclu MU,Ozerdem MS",Polat H,10.1515/bmt-2019-0098,"Mus Alparslan Univ, Dept Elect & Elect Engn, Farabi Ofisleri Oda 303, TR-49250 Guzeltepe Mus, Turkey.","The general uncertainty of epilepsy and its unpredictable seizures often affect badly the quality of life of people exposed to this disease. There are patients who can be considered fortunate in terms of prediction of any seizures. These are patients with epileptic auras. In this study, it was aimed to evaluate pre-seizure warning symptoms of the electroencephalography (EEG) signals by a convolutional neural network (CNN) inspired by the epileptic auras defined in the medical field. In this context, one-dimensional EEG signals were transformed into a spectrogram display form in the frequency-time domain by applying a short-time Fourier transform (STFT). Systemic changes in pre-epileptic seizure have been described by applying the CNN approach to the EEG signals represented in the image form, and the subjective EEG-Aura process has been tried to be determined for each patient. Considering all patients included in the evaluation, it was determined that the 1-min interval covering the time from the second minute to the third minute before the seizure had the highest mean and the lowest variance to determine the systematic changes before the seizure. Thus, the highest performing process is described as EEG-Aura. The average success for the EEG-Aura process was 90.38 +/- 6.28%, 89.78 +/- 834% and 90.447 +/- 5.95% for accuracy, specificity and sensitivity, respectively. Through the proposed model, epilepsy patients who do not respond to medical treatment methods are expected to maintain their lives in a more comfortable and integrated way.","deep learning,EEG,epilepsy,epileptic aura,time-frequency representation",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY","Engineering,Medical Informatics",,1.404,"TEMPORAL-LOBE,EPILEPSY,SEIZURE,PREDICTION,SPECTRAL,POWER,CLASSIFICATION,PERCEPTION,SIGNATURES,DEATH",BIOMEDICAL ENGINEERING-BIOMEDIZINISCHE TECHNIK,,
49,Towards Domain Invariant Heart Sound Abnormality Detection Using Learnable Filterbanks,24,8,2189-2198,"Humayun Ahmed Imtiaz,Ghaffarzadegan Shabnam,Ansari Md. Istiaq,Feng Zhe,Hasan Taufiq","Humayun AI,Ghaffarzadegan S,Ansari MI,Feng Z,Hasan T",Hasan T,10.1109/JBHI.2020.2970252,Bangladesh University of Engineering & Technology (BUET),"Objective: Cardiac auscultation is the most practiced non-invasive and cost-effective procedure for the early diagnosis of heart diseases. While machine learning based systems can aid in automatically screening patients, the robustness of these systems is affected by numerous factors including the stethoscope/sensor, environment, and data collection protocol. This article studies the adverse effect of domain variability on heart sound abnormality detection and develops strategies to address this problem. Methods: We propose a novel Convolutional Neural Network (CNN) layer, consisting of time-convolutional (tConv) units, that emulate Finite Impulse Response (FIR) filters. The filter coefficients can be updated via backpropagation and be stacked in the front-end of the network as a learnable filterbank. Results: On publicly available multi-domain datasets, the proposed method surpasses the top-scoring systems found in the literature for heart sound abnormality detection (a binary classification task). We utilized sensitivity, specificity, F-1 score and Macc (average of sensitivity and specificity) as performance metrics. Our systems achieved relative improvements of up to 11.84% in terms of MAcc, compared to state-of-the-art methods. Conclusion: The results demonstrate the effectiveness of the proposed learnable filterbank CNN architecture in achieving robustness towards sensor/domain variability in PCG signals. Significance: The proposed methods pave the way for deploying automated cardiac screening systems in diversified and underserved communities.","Heart,Phonocardiography,Valves,Stethoscope,Informatics,Diseases,Shape,Heart sound classification,learnable filterbank,domain adaptation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"SELF-ASSESSED,AFFECT,NEURAL-NETWORKS,FREQUENCY,ENSEMBLE,FEATURES",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://arxiv.org/pdf/1910.00498,
50,Label Co-Occurrence Learning With Graph Convolutional Networks for Multi-Label Chest X-Ray Image Classification,24,8,2292-2302,"Chen Bingzhi,Li Jinxing,Lu Guangming,Yu Hongbing,Zhang David","Chen BZ,Li JX,Lu GM,Yu HB,Zhang DV",Lu GM,10.1109/JBHI.2020.2967084,Harbin Institute of Technology,"Existing multi-label medical image learning tasks generally contain rich relationship information among pathologies such as label co-occurrence and interdependency, which is of great importance for assisting in clinical diagnosis and can be represented as the graph-structured data. However, most state-of-the-art works only focus on regression from the input to the binary labels, failing to make full use of such valuable graph-structured information due to the complexity of graph data. In this paper, we propose a novel label co-occurrence learning framework based on Graph Convolution Networks (GCNs) to explicitly explore the dependencies between pathologies for the multi-label chest X-ray (CXR) image classification task, which we term the ""CheXGCN"". Specifically, the proposed CheXGCN consists of two modules, i.e., the image feature embedding (IFE) module and label co-occurrence learning (LCL) module. Thanks to the LCL model, the relationship between pathologies is generalized into a set of classifier scores by introducing the word embedding of pathologies and multi-layer graph information propagation. During end-to-end training, it can be flexibly integrated into the IFE module and then adaptively recalibrate multi-label outputs with these scores. Extensive experiments on the ChestX-Ray14 and CheXpert datasets have demonstrated the effectiveness of CheXGCN as compared with the state-of-the-art baselines.","X-ray imaging,Correlation,Feature extraction,Pathology,Task analysis,Diseases,Biomedical imaging,Label co-occurrence learning,graph Convolutional Networks,multi-label chest X-Ray image classification,word embedding,graph representation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
51,An Adversarial Learning Approach to Medical Image Synthesis for Lesion Detection,24,8,2303-2314,"Sun Liyan,Wang Jiexiang,Huang Yue,Ding Xinghao,Greenspan Hayit,Paisley John","Sun LY,Wang JX,Huang Y,Ding XH,Greenspan H,Paisley J",Ding XH,10.1109/JBHI.2020.2964016,Xiamen University,"The identification of lesion within medical image data is necessary for diagnosis, treatment and prognosis. Segmentation and classification approaches are mainly based on supervised learning with well-paired image-level or voxel-level labels. However, labeling the lesion in medical images is laborious requiring highly specialized knowledge. We propose a medical image synthesis model named abnormal-to-normal translation generative adversarial network (ANT-GAN) to generate a normal-looking medical image based on its abnormal-looking counterpart without the need for paired training data. Unlike typical GANs, whose aim is to generate realistic samples with variations, our more restrictive model aims at producing a normal-looking image corresponding to one containing lesions, and thus requires a special design. Being able to provide a ""normal"" counterpart to a medical image can provide useful side information for medical imaging tasks like lesion segmentation or classification validated by our experiments. In the other aspect, the ANT-GAN model is also capable of producing highly realistic lesion-containing image corresponding to the healthy one, which shows the potential in data augmentation verified in our experiments.","Lesions,Medical diagnostic imaging,Gallium nitride,Magnetic resonance imaging,Generators,Generative adversarial networks,Medical image synthesis,generative adversarial network,unsupervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,MRI,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://arxiv.org/pdf/1810.10850,
52,Robust Fovea Localization Based on Symmetry Measure,24,8,2315-2326,"Guo Xiaoxin,Wang Han,Lu Xinfeng,Hu Xiaoying,Che Songtian,Lu Yinan","Guo XX,Wang H,Lu XF,Hu XY,Che ST,Lu YN",Guo XX,10.1109/JBHI.2020.2971593,Jilin University,"Automatic fovea localization is a challenging issue. In this article, we focus on the study of fovea localization and propose a robust fovea localization method. We propose concentric circular sectional symmetry measure (CCSSM) for symmetry axis detection, and region of interest (ROI) determination, which is a global feature descriptor robust against local feature changes, to solve the lesion interference issue, i.e., fovea visibility interference from lesions, using both structure features and morphological features. We propose the index of convexity and concavity (ICC) as the convexity-concavity measure of the surface and provide a quantitative evaluation tool for ophthalmologists to learn whether the occurrence of lesion within the ROI. We propose the weighted gradient accumulation map, which is insensitive to local intensity changes and can overcome the influence of noise and contamination, to perform refined localization. The advantages of the proposed method lies in two aspects. First, the accuracy and robustness can be achieved without typical sophisticated manner, i.e., blood vessel segmentation and parabola fitting. Second, the lesion interference is considered in our plan of fovea localization. Our proposed symmetry-based method is innovative in the solution of fovea detection, and it is simple, practical, and controllable. Experiment results show that the proposed method can resist the interference of unbalanced illumination and lesions, and achieve high accuracy rate in five datasets. Compared to the state-of-the-art methods, high robustness and accuracy of the proposed method guarantees its reliability.","Lesions,Interference,Retina,Informatics,Feature extraction,Blood vessels,Biomedical imaging,Fovea localization,symmetry measure,symmetry axis detection,equidistant concentric circular sampling,weighted gradient accumulation map,index of convexity and concavity",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"DIGITAL,FUNDUS,IMAGES,OPTIC,DISC,DETECTION,RETINAL,IMAGES,AUTOMATIC,DETECTION,FEATURE-EXTRACTION,BLOOD-VESSELS,SEGMENTATION,MACULA,RECOGNITION,ANATOMY",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
53,Semi-Supervised Learning for Semantic Segmentation of Emphysema With Partial Annotations,24,8,2327-2336,"Peng Liying,Lin Lanfen,Hu Hongjie,Zhang Yue,Li Huali,Iwamoto Yutaro,Han Xian-Hua,Chen Yen-Wei","Peng LY,Lin LF,Hu HJ,Zhang Y,Li HL,Iwamoto Y,Han XH,Chen YW",Lin LF,10.1109/JBHI.2019.2963195,Zhejiang University,"Segmentation and quantification of each subtype of emphysema is helpful to monitor chronic obstructive pulmonary disease. Due to the nature of emphysema (diffuse pulmonary disease), it is very difficult for experts to allocate semantic labels to every pixel in the CT images. In practice, partially annotating is a better choice for the radiologists to reduce their workloads. In this paper, we propose a new end-to-end trainable semi-supervised framework for semantic segmentation of emphysema with partial annotations, in which a segmentation network is trained from both annotated and unannotated areas. In addition, we present a new loss function, referred to as Fisher loss, to enhance the discriminative power of the model and successfully integrate it into our proposed framework. Our experimental results show that the proposed methods have superior performance over the baseline supervised approach (trained with only annotated areas) and outperform the state-of-the-art methods for emphysema segmentation.","Annotations,Semantics,Lung,Lesions,Semisupervised learning,Image segmentation,Diseases,Emphysema semantic segmentation,semi-supervised learning,partial annotations,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"PULMONARY-EMPHYSEMA,COMPUTED-TOMOGRAPHY,CLASSIFICATION,QUANTIFICATION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
54,LXPER Index: A Curriculum-specific Text Readability Assessment Model for EFL Students in Korea,11,8,1-8,"Lee Bruce W.,Lee Jason Hyung-Jong","Lee BW,Lee JHJ",Lee BW,,"LXPER Inc, Res & Dev Ctr, Seoul, South Korea.","Automatic readability assessment is one of the most important applications of Natural Language Processing (NLP) in education. Since automatic readability assessment allows the fast selection of appropriate reading material for readers at all levels of proficiency, it can be particularly useful for the English education of English as Foreign Language (EFL) students around the world. However, most readability assessment models are developed for the native readers of English and have low accuracy for texts in non-native English Language Training ( ELT) curriculum. We introduce LXPER Index, which is a readability assessment model for non-native EFL readers in the ELT curriculum of Korea. To measure LXPER Index, we use the mixture of 22 features which we prove to be significant in text readability assessment. We also introduce the Text Corpus of the Korean ELT Curriculum (CoKEC-text), which is the first collection of English texts from a non-native country's ELT curriculum with each text's target grade level labeled. In addition, we assembled the Word Corpus of the Korean ELT Curriculum (CoKEC-word), which is a collection of words from the Korean ELT curriculum with word difficulty labels. Our experiments show that our new model, trained with CoKEC-text, significantly improves the accuracy of automatic readability assessment for texts in the Korean ELT curriculum. The methodology used in this research can be applied to other ELT curricula around the world.","Natural language processing,machine learning,text readability assessment,EFL (English as Foreign Language) education",Article,"SCIENCE & INFORMATION SAI ORGANIZATION LTD, 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND",Computer Science,,,,INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS,,
55,Automatic Extraction of Rarely Explored Materials and Methods Sections from Research Journals using Machine Learning Techniques,11,8,447-456,"Jayaram Kavitha,Prakash G.,Jayaram V","Jayaram K,Prakash G,Jayaram V",Jayaram K,,Amrita Vishwa Vidyapeetham,"The scientific community is expanding by leaps and bounds every day owing to pioneering and path breaking scientific literature published in journals around the globe. Viewing as well as retrieving this data is a challenging task in today's fast paced world. The essence and importance of scientific research papers for the expert lies in their experimental and theoretical results along with the sanctioned research projects from the organizations. Since scant work has been done in this direction, the alternative option is to explore text mining by machine learning techniques. Myriad journals are available on material research which throws light on a gamut of materials, synthesis methods, and characterization methods used to study properties of the materials. Application of materials has many diversified areas, hence selected papers from ""Journal of Material Science"" where ""Materials and Methods"" sections contains names of the method, characterization techniques (instrumental methods), algorithms, images, etc. used in research work. The ""Acknowledgment"" section conveys information about authors' proximity, collaborations with organizations that are again not explored for the citation network. In the present articulated work, our attempt is to derive a means to automatically extract methods or terminologies used in characterization techniques, author, organization data from ""Materials and Methods"" and ""Acknowledgment"" sections, using machine learning techniques. Another goal of this research is to provide a data set for characterization terms, classification and an extended version of the existing citation network for material research. The complete dataset will help new researchers to select research work, find new domains and techniques to solve advanced scientific research problems.","Data-mining,rule-based,machine-learning,term extraction,classification,materials and methods,acknowledgment",Article,"SCIENCE & INFORMATION SAI ORGANIZATION LTD, 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND",Computer Science,,,,INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS,,
56,Application of Artificial Neural Networks in Crystal Growth of Electronic and Opto-Electronic Materials,10,8,,"Dropka Natasha,Holena Martin","Dropka N,Holena M",Dropka N,10.3390/cryst10080663,Leibniz Institut fur Kristallzuchtung (IKZ),"In this review, we summarize the results concerning the application of artificial neural networks (ANNs) in the crystal growth of electronic and opto-electronic materials. The main reason for using ANNs is to detect the patterns and relationships in non-linear static and dynamic data sets which are common in crystal growth processes, all in a real time. The fast forecasting is particularly important for the process control, since common numerical simulations are slow and in situ measurements of key process parameters are not feasible. This important machine learning approach thus makes it possible to determine optimized parameters for high-quality up-scaled crystals in real time.","artificial neural networks,crystal growth,semiconductors,oxides",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Crystallography,Materials Science",,2.615,"OPTIMIZATION,IDENTIFICATION,PREDICTION",CRYSTALS,https://www.mdpi.com/2073-4352/10/8/663/pdf,
57,A Sleep Apnea Detection System Based on a One-Dimensional Deep Convolution Neural Network Model Using Single-Lead Electrocardiogram,20,15,,"Chang Hung-Yu,Yeh Cheng-Yu,Lee Chung-Te,Lin Chun-Cheng","Chang HY,Yeh CY,Lee CT,Lin CC",Lin CC,10.3390/s20154157,National Chin-Yi University of Technology,"Many works in recent years have been focused on developing a portable and less expensive system for diagnosing patients with obstructive sleep apnea (OSA), instead of using the inconvenient and expensive polysomnography (PSG). This study proposes a sleep apnea detection system based on a one-dimensional (1D) deep convolutional neural network (CNN) model using the single-lead 1D electrocardiogram (ECG) signals. The proposed CNN model consists of 10 identical CNN-based feature extraction layers, a flattened layer, 4 identical classification layers mainly composed of fully connected networks, and a softmax classification layer. Thirty-five released and thirty-five withheld ECG recordings from the MIT PhysioNet Apnea-ECG Database were applied to train the proposed CNN model and validate its accuracy for the detection of the apnea events. The results show that the proposed model achieves 87.9% accuracy, 92.0% specificity, and 81.1% sensitivity for per-minute apnea detection, and 97.1% accuracy, 100% specificity, and 95.7% sensitivity for per-recording classification. The proposed model improves the accuracy of sleep apnea detection in comparison with several feature-engineering-based and feature-learning-based approaches.","obstructive sleep apnea,single-lead electrocardiogram,deep learning,convolutional neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"CLASSIFICATION,ALGORITHM",SENSORS,https://www.mdpi.com/1424-8220/20/15/4157/pdf,
58,A Unified Framework for Automatic Detection of Wound Infection with Artificial Intelligence,10,15,,"Wu Jin-Ming,Tsai Chia-Jui,Ho Te-Wei,Lai Feipei,Tai Hao-Chih,Lin Ming-Tsan","Wu JM,Tsai CJ,Ho TW,Lai FP,Tai HC,Lin MT",Tai HC; Lin MT,10.3390/app10155353,National Taiwan University,"Background: The surgical wound is a unique problem requiring continuous postoperative care, and mobile health technology is implemented to bridge the care gap. Our study aim was to design an integrated framework to support the diagnosis of wound infection. Methods: We used a computer-vision approach based on supervised learning techniques and machine learning algorithms, to help detect the wound region of interest (ROI) and classify wound infection features. The intersection-union test (IUT) was used to evaluate the accuracy of the detection of color card and wound ROI. The area under the receiver operating characteristic curve (AUC) of our model was adopted in comparison with different machine learning approaches. Results: 480 wound photographs were taken from 100 patients for analysis. The average value of IUT on the validation set with fivefold stratification to detect wound ROI was 0.775. For prediction of wound infection, our model achieved a significantly higher AUC score (83.3%) than the other three methods (kernel support vector machines, 44.4%; random forest, 67.1%; gradient boosting classifier, 66.9%). Conclusions: Our evaluation of a prospectively collected wound database demonstrates the effectiveness and reliability of the proposed system, which has been developed for automatic detection of wound infections in patients undergoing surgical procedures.","artificial intelligence,wound infection,telecare",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,SURGERY,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/15/5353/pdf,
59,Species Ecological Envelopes under Climate Change Scenarios: A Case Study for the Main Two Wood-Production Forest Species in Portugal,11,8,,"Alegria Cristina,Roque Natalia,Albuquerque Teresa,Gerassis Saki,Fernandez Paulo,Ribeiro Maria Margarida","Alegria C,Roque N,Albuquerque T,Gerassis S,Fernandez P,Ribeiro MM",Alegria C,10.3390/f11080880,Polytechnic Institute of Castelo Branco,"Species ecological envelope maps were obtained for the two main Portuguese wood-production species (Eucalyptus globulusLabill. andPinus pinasterAiton) and projected future climate change scenarios. A machine learning approach was used to understand the most influential environmental variables that may explain current species distribution and productivity.Background and Objectives:The aims of the study were: (1) to map species potential suitability areas using ecological envelopes in the present and to project them in the future under climate change scenarios; (2) to map species current distributions; (3) to map species current productivity; and (4) to explore the most influential environmental variables on species current distribution and productivity.Materials and Methods:Climate, elevation data, and soil data sets were used to obtain present and future species ecological envelopes under two climate change scenarios. The official land cover maps were used to map species distributions. Forest inventory data were used to map the species productivity by geostatistical techniques. A Bayesian machine learning approach, supported by species distributions and productivity data, was used to explore the most influential environmental variables on species distribution and productivity and to validate species ecological envelopes.Results:The species ecological envelope methodology was found to be robust. Species' ecological envelopes showed a high potential for both species' afforestation. In the future, a decrease in the country's area potentiality was forecasted for both species. The distribution of maritime pine was found to be mainly determined by precipitation-related variables, but the elevation and temperature-related variables were very important to differentiate species productivity. For eucalypts, species distribution was mainly explained by temperature-related variables, as well as the species productivity.Conclusions:These findings are key to support recommendations for future afforestation and will bring value to policy-makers and environmental authorities in policy formulation under climate change scenarios.","ecological envelopes,climate change scenarios,species distribution,species productivity,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Forestry,,2.804,"MARITIME,PINE,BIODIVERSITY,PLANTATIONS,SOIL",FORESTS,https://www.repository.utl.pt/bitstream/10400.5/20345/1/REP-CEF-Alegria-forests-11-00880-v2.pdf,
60,RSM and BPNN Modeling in Incremental Sheet Forming Process for AA5052 Sheet: Multi-Objective Optimization Using Genetic Algorithm,10,8,,"Xiao Xiao,Kim Jin-Jae,Hong Myoung-Pyo,Yang Sen,Kim Young-Suk","Xiao X,Kim JJ,Hong MP,Yang S,Kim YS",Kim YS,10.3390/met10081003,Kyungpook National University,"In this study, the response surface method (RSM), back propagation neural network (BPNN), and genetic algorithm (GA) were used for modeling and multi-objective optimization of the forming parameters of AA5052 in incremental sheet forming (ISF). The optimization objectives were maximum forming angle and minimum thickness reduction whose values vary in response to changes in production process parameters, such as the tool diameter, step depth, tool feed rate, and tool spindle speed. A Box-Behnken experimental design was used to develop an RSM and BPNN model for modeling the variations in the forming angle and thickness reduction in response to variations in process parameters. Subsequently, the RSM model was used as the fitness function for multi-objective optimization of the ISF process using the GA. The results showed that RSM effectively modeled the forming angle and thickness reduction. Furthermore, the correlation coefficients of the experimental responses and BPNN predictions of the experiment results were good with the minimum value being 0.97936. The Pareto optimal solutions for maximum forming angle and minimum thickness reduction were obtained and reported. The optimized Pareto front produced by the GA can be a rational design guide for practical applications of AA5052 in the ISF process.","incremental sheet forming,RSM,BP neural network,genetic algorithm,multi-objective optimization",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Materials Science,Metallurgy & Metallurgical Engineering",,2.487,"SINGLE-POINT,PROCESS,PARAMETERS,FORMABILITY,ANN",METALS,https://www.mdpi.com/2075-4701/10/8/1003/pdf,
61,Driver Stress State Evaluation by Means of Thermal Imaging: A Supervised Machine Learning Approach Based on ECG Signal,10,16,,"Cardone Daniela,Perpetuini David,Filippini Chiara,Spadolini Edoardo,Mancini Lorenza,Chiarelli Antonio Maria,Merla Arcangelo","Cardone D,Perpetuini D,Filippini C,Spadolini E,Mancini L,Chiarelli AM,Merla A",Cardone D,10.3390/app10165673,G d'Annunzio University of Chieti-Pescara,"Traffic accidents determine a large number of injuries, sometimes fatal, every year. Among other factors affecting a driver's performance, an important role is played by stress which can decrease decision-making capabilities and situational awareness. In this perspective, it would be beneficial to develop a non-invasive driver stress monitoring system able to recognize the driver's altered state. In this study, a contactless procedure for drivers' stress state assessment by means of thermal infrared imaging was investigated. Thermal imaging was acquired during an experiment on a driving simulator, and thermal features of stress were investigated with comparison to a gold-standard metric (i.e., the stress index, SI) extracted from contact electrocardiography (ECG). A data-driven multivariate machine learning approach based on a non-linear support vector regression (SVR) was employed to estimate the SI through thermal features extracted from facial regions of interest (i.e., nose tip, nostrils, glabella). The predicted SI showed a good correlation with the real SI (r = 0.61, p = similar to 0). A two-level classification of the stress state (STRESS, SI >= 150, versus NO STRESS, SI < 150) was then performed based on the predicted SI. The ROC analysis showed a good classification performance with an AUC of 0.80, a sensitivity of 77%, and a specificity of 78%.","driver stress state,IR imaging,machine learning,support vector machine (SVR),advanced driver-assistance systems (ADAS)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"VARIABILITY,EMOTIONS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/16/5673/pdf,
62,Multimodal Brain Tumor Classification Using Deep Learning and Robust Feature Selection: A Machine Learning Application for Radiologists,10,8,,"Khan Muhammad Attique,Ashraf Imran,Alhaisoni Majed,Damasevicius Robertas,Scherer Rafal,Rehman Amjad,Bukhari Syed Ahmad Chan","Khan MA,Ashraf I,Alhaisoni M,Damasevicius R,Scherer R,Rehman A,Bukhari SAC",Damasevicius R,10.3390/diagnostics10080565,Silesian University of Technology,"Manual identification of brain tumors is an error-prone and tedious process for radiologists; therefore, it is crucial to adopt an automated system. The binary classification process, such as malignant or benign is relatively trivial; whereas, the multimodal brain tumors classification (T1, T2, T1CE, and Flair) is a challenging task for radiologists. Here, we present an automated multimodal classification method using deep learning for brain tumor type classification. The proposed method consists of five core steps. In the first step, the linear contrast stretching is employed using edge-based histogram equalization and discrete cosine transform (DCT). In the second step, deep learning feature extraction is performed. By utilizing transfer learning, two pre-trained convolutional neural network (CNN) models, namely VGG16 and VGG19, were used for feature extraction. In the third step, a correntropy-based joint learning approach was implemented along with the extreme learning machine (ELM) for the selection of best features. In the fourth step, the partial least square (PLS)-based robust covariant features were fused in one matrix. The combined matrix was fed to ELM for final classification. The proposed method was validated on the BraTS datasets and an accuracy of 97.8%, 96.9%, 92.5% for BraTs2015, BraTs2017, and BraTs2018, respectively, was achieved.","brain tumor,healthcare,linear contrast,transfer learning,deep learning features,feature selection,feature fusion,PLS,ELM",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"SEGMENTATION,RECOGNITION,DESIGN,FUSION",DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7459797,
63,Cost-Effective Approaches Based on Machine Learning to Predict Dynamic Modulus of Warm Mix Asphalt with High Reclaimed Asphalt Pavement,13,15,,"Dao Dong Van,Nguyen Ngoc-Lan,Ly Hai-Bang,Pham Binh Thai,Le Tien-Thinh","Dao DV,Nguyen NL,Ly HB,Pham BT,Le TT",Dao DV,10.3390/ma13153272,"Univ Transport Technol, Hanoi 100000, Vietnam.","Warm mix asphalt (WMA) technology, taking advantage of reclaimed asphalt pavements, has gained increasing attention from the scientific community. The determination of technical specifications of such a type of asphalt concrete is crucial for pavement design, in which the asphalt concrete dynamic modulus (E*) of elasticity is amongst the most critical parameters. However, the latter could only be determined by complicated, costly, and time-consuming experiments. This paper presents an alternative cost-effective approach to determine the dynamic elastic modulus (E*) of WMA based on various machine learning-based algorithms, namely the artificial neural network (ANN), support vector machine (SVM), Gaussian process regression (GPR), and ensemble boosted trees (Boosted). For this, a total of 300 samples were fabricated by warm mix asphalt technology. The mixtures were prepared with 0%, 20%, 30%, 40%, and 50% content of reclaimed asphalt pavement (RAP) and modified bitumen binder using Sasobit and Zycotherm additives. The dynamic elastic modulus tests were conducted by varying the temperature from 10 degrees C to 50 degrees C at different frequencies from 0.1 Hz to 25 Hz. Various common quantitative indications, such as root mean square error (RMSE), mean absolute error (MAE), and correlation coefficient (R) were used to validate and compare the prediction capability of different models. The results showed that machine learning models could accurately predict the dynamic elastic modulus of WMA using up to 50% RAP and fabricated by warm mix asphalt technology. Out of these models, the Boosted algorithm (R = 0.9956) was found as the best predictor compared with those obtained by ANN-LMN (R = 0.9954), SVM (R = 0.9654), and GPR (R= 0.9865). Thus, it could be concluded that Boosted is a promising cost-effective tool for the prediction of the dynamic elastic modulus (E*) of WMA. This study might help in reducing the cost of laboratory experiments for the determination of the dynamic modulus (E*).","warm mix asphalt,reclaimed asphalt pavement,dynamic modulus,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"LIFE-CYCLE,ASSESSMENT,ENVIRONMENTAL-IMPACT,TECHNOLOGY",MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7436179,
64,Predicting Fire Brigades Operational Breakdowns: A Real Case Study,8,8,,"Cerna Selene,Guyeux Christophe,Royer Guillaume,Chevallier Celine,Plumerel Guillaume","Cerna S,Guyeux C,Royer G,Chevallier C,Plumerel G",Cerna S,10.3390/math8081383,Centre National de la Recherche Scientifique (CNRS),"Over the years, fire departments have been searching for methods to identify their operational disruptions and establish strategies that allow them to efficiently organize their resources. The present work develops a methodology for breakage calculation and another for predicting disruptions based on machine learning techniques. The main objective is to establish indicators to identify the failures due to the temporal state of the organization in the human and vehicular material. Likewise, by forecasting disruptions, to determine strategies for the deployment or acquisition of the necessary armament. This would allow improving operational resilience and increasing the efficiency of the firemen over time. The methodology was applied to the Departmental Fire and Rescue Doubs (SDIS25) in France. However, it is generic enough to be extended and adapted to other fire departments. Considering a historic of breakdowns of 2017 and 2018, the best predictions of public service breakdowns for the year 2019, presented a root mean squared error of 2.5602 and a mean absolute error of 2.0240 on average with the XGBoost technique.","operational breakdowns,forecasting disruptions,firemen,breakage calculation,XGBoost",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Mathematics,,2.165,,MATHEMATICS,https://www.mdpi.com/2227-7390/8/8/1383/pdf,
65,ECG Biometrics Using Deep Learning and Relative Score Threshold Classification,20,15,,"Belo David,Bento Nuno,Silva Hugo,Fred Ana,Gamboa Hugo","Belo D,Bento N,Silva H,Fred A,Gamboa H",Belo D,10.3390/s20154078,Universidade Nova de Lisboa,"The field of biometrics is a pattern recognition problem, where the individual traits are coded, registered, and compared with other database records. Due to the difficulties in reproducing Electrocardiograms (ECG), their usage has been emerging in the biometric field for more secure applications. Inspired by the high performance shown by Deep Neural Networks (DNN) and to mitigate the intra-variability challenges displayed by the ECG of each individual, this work proposes two architectures to improve current results in both identification (finding the registered person from a sample) and authentication (prove that the person is whom it claims) processes: Temporal Convolutional Neural Network (TCNN) and Recurrent Neural Network (RNN). Each architecture produces a similarity score, based on the prediction error of the former and the logits given by the last, and fed to the same classifier, the Relative Score Threshold Classifier (RSTC).The robustness and applicability of these architectures were trained and tested on public databases used by literature in this context: Fantasia, MIT-BIH, and CYBHi databases. Results show that overall the TCNN outperforms the RNN achieving almost 100%, 96%, and 90% accuracy, respectively, for identification and 0.0%, 0.1%, and 2.2% equal error rate (EER) for authentication processes. When comparing to previous work, both architectures reached results beyond the state-of-the-art. Nevertheless, the improvement of these techniques, such as enriching training with extra varied data and transfer learning, may provide more robust systems with a reduced time required for validation.","deep learning,biometrics,electrocardiogram,convolutional neural network,recurrent neural network,authentication,identification,artificial neural networks,biosignal,RLTC",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"IDENTIFICATION,VERIFICATION,SYSTEMS",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7435887,
66,A Novel Pulmonary Nodule Detection Model Based on Multi-Step Cascaded Networks,20,15,,"Chi Jianning,Zhang Shuang,Yu Xiaosheng,Wu Chengdong,Jiang Yang","Chi JN,Zhang S,Yu XS,Wu CD,Jiang Y",Chi JN; Jiang Y,10.3390/s20154301,Northeastern University - China,"Pulmonary nodule detection in chest computed tomography (CT) is of great significance for the early diagnosis of lung cancer. Therefore, it has attracted more and more researchers to propose various computer-assisted pulmonary nodule detection methods. However, these methods still could not provide convincing results because the nodules are easily confused with calcifications, vessels, or other benign lumps. In this paper, we propose a novel deep convolutional neural network (DCNN) framework for detecting pulmonary nodules in the chest CT image. The framework consists of three cascaded networks: First, a U-net network integrating inception structure and dense skip connection is proposed to segment the region of lung parenchyma from the chest CT image. The inception structure is used to replace the first convolution layer for better feature extraction with respect to multiple receptive fields, while the dense skip connection could reuse these features and transfer them through the network. Secondly, a modified U-net network where all the convolution layers are replaced by dilated convolution is proposed to detect the ""suspicious nodules"" in the image. The dilated convolution can increase the receptive fields to improve the ability of the network in learning global information of the image. Thirdly, a modified U-net adapting multi-scale pooling and multi-resolution convolution connection is proposed to find the true pulmonary nodule in the image with multiple candidate regions. During the detection, the result of the former step is used as the input of the latter step to follow the ""coarse-to-fine"" detection process. Moreover, the focal loss, perceptual loss and dice loss were used together to replace the cross-entropy loss to solve the problem of imbalance distribution of positive and negative samples. We apply our method on two public datasets to evaluate its ability in pulmonary nodule detection. Experimental results illustrate that the proposed method outperform the state-of-the-art methods with respect to accuracy, sensitivity and specificity.","pulmonary nodule detection,deep neural convolutional network,inception structure,dense connection,dilated convolution,multi-resolution convolution",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"CT,IMAGES,AUTOMATIC,DETECTION,CANCER,SYSTEM",SENSORS,https://www.mdpi.com/1424-8220/20/15/4301/pdf,
67,Valve Internal Leakage Rate Quantification Based on Factor Analysis and Wavelet-BP Neural Network Using Acoustic Emission,10,16,,"Zhao Hanxue,Li Zhenlin,Zhu Shenbin,Yu Ying","Zhao HX,Li ZL,Zhu SB,Yu Y",Li ZL,10.3390/app10165544,China University of Petroleum,"Valve internal leakage is easily found because of various defects resulting from environmental factors and load fluctuation. The timely detection of valve internal leakage is of great significance to the safe operation of pipelines. As an effective means for detecting valve internal leakage, the acoustic emission technique is characterized by nonintrusive and strong anti-interference ability, which can realize the in situ monitoring of the valve running status in real time. In this paper, acoustic emission signals from an internal leaking valve were obtained experimentally. Then, the dimensionality reduction technology based on factor analysis was introduced to the processing of valve internal leakage detection data. Next, the wavelet decomposition was carried out to decompose the sample feature set into four subsets. Finally, the decomposed sample feature sets were inputted into the error backpropagation (BP) neural network quantitative model, respectively. The optimized results show that the predicted internal leakage rate by the wavelet-BP neural network model has good precision with an error of less than 10%. The wavelet-BP neural network model can realize the analysis of the valve internal leakage rate quantitatively and has good robustness, which provides technical support and guarantees the safe operation of natural gas pipeline valves.","acoustic emission,valve internal leakage,factor analysis,wavelet decomposition,BP neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/16/5544/pdf,
68,Deep Learning with Limited Data: Organ Segmentation Performance by U-Net,9,8,,"Bardis Michelle,Houshyar Roozbeh,Chantaduly Chanon,Ushinsky Alexander,Glavis-Bloom Justin,Shaver Madeleine,Chow Daniel,Uchio Edward,Chang Peter","Bardis M,Houshyar R,Chantaduly C,Ushinsky A,Glavis-Bloom J,Shaver M,Chow D,Uchio E,Chang P",Bardis M,10.3390/electronics9081199,University of California System,"(1) Background: The effectiveness of deep learning artificial intelligence depends on data availability, often requiring large volumes of data to effectively train an algorithm. However, few studies have explored the minimum number of images needed for optimal algorithmic performance. (2) Methods: This institutional review board (IRB)-approved retrospective review included patients who received prostate magnetic resonance imaging (MRI) between September 2014 and August 2018 and a magnetic resonance imaging (MRI) fusion transrectal biopsy. T2-weighted images were manually segmented by a board-certified abdominal radiologist. Segmented images were trained on a deep learning network with the following case numbers: 8, 16, 24, 32, 40, 80, 120, 160, 200, 240, 280, and 320. (3) Results: Our deep learning network's performance was assessed with a Dice score, which measures overlap between the radiologist's segmentations and deep learning-generated segmentations and ranges from 0 (no overlap) to 1 (perfect overlap). Our algorithm's Dice score started at 0.424 with 8 cases and improved to 0.858 with 160 cases. After 160 cases, the Dice increased to 0.867 with 320 cases. (4) Conclusions: Our deep learning network for prostate segmentation produced the highest overall Dice score with 320 training cases. Performance improved notably from training sizes of 8 to 120, then plateaued with minimal improvement at training case size above 160. Other studies utilizing comparable network architectures may have similar plateaus, suggesting suitable results may be obtainable with small datasets.","training size,deep learning,convolutional neural network,U-Net,segmentation,artificial intelligence",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"CONVOLUTIONAL,NEURAL-NETWORKS",ELECTRONICS,https://www.mdpi.com/2079-9292/9/8/1199/pdf,
69,Classification of Hyperspectral In Vivo Brain Tissue Based on Linear Unmixing,10,16,,"Cruz-Guerrero Ines A.,Leon Raquel,Campos-Delgado Daniel U.,Ortega Samuel,Fabelo Himar,Callico Gustavo M.","Cruz-Guerrero IA,Leon R,Campos-Delgado DU,Ortega S,Fabelo H,Callico GM",Campos-Delgado DU,10.3390/app10165686,Universidad Autonoma de San Luis Potosi,"Hyperspectral imaging is a multidimensional optical technique with the potential of providing fast and accurate tissue classification. The main challenge is the adequate processing of the multidimensional information usually linked to long processing times and significant computational costs, which require expensive hardware. In this study, we address the problem of tissue classification for intraoperative hyperspectral images of in vivo brain tissue. For this goal, two methodologies are introduced that rely on a blind linear unmixing (BLU) scheme for practical tissue classification. Both methodologies identify the characteristic end-members related to the studied tissue classes by BLU from a training dataset and classify the pixels by a minimum distance approach. The proposed methodologies are compared with a machine learning method based on a supervised support vector machine (SVM) classifier. The methodologies based on BLU achieve speedup factors of similar to 459x and similar to 429x compared to the SVM scheme, while keeping constant and even slightly improving the classification performance.","hyperspectral imaging,intraoperative imaging,brain cancer,linear unmixing,support vector machine",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,MICROSCOPY,APPLIED SCIENCES-BASEL,https://accedacris.ulpgc.es/jspui/bitstream/10553/106772/2/classification_hyperspectral_vivo.pdf,
70,Decoding Visual Motions from EEG Using Attention-Based RNN,10,16,,"Yang Dongxu,Liu Yadong,Zhou Zongtan,Yu Yang,Liang Xinbin","Yang DX,Liu YD,Zhou ZT,Yu Y,Liang XB",Liu YD,10.3390/app10165662,National University of Defense Technology - China,"The main objective of this paper is to use deep neural networks to decode the electroencephalography (EEG) signals evoked when individuals perceive four types of motion stimuli (contraction, expansion, rotation, and translation). Methods for single-trial and multi-trial EEG classification are both investigated in this study. Attention mechanisms and a variant of recurrent neural networks (RNNs) are incorporated as the decoding model. Attention mechanisms emphasize task-related responses and reduce redundant information of EEG, whereas RNN learns feature representations for classification from the processed EEG data. To promote generalization of the decoding model, a novel online data augmentation method that randomly averages EEG sequences to generate artificial signals is proposed for single-trial EEG. For our dataset, the data augmentation method improves the accuracy of our model (based on RNN) and two benchmark models (based on convolutional neural networks) by 5.60%, 3.92%, and 3.02%, respectively. The attention-based RNN reaches mean accuracies of 67.18% for single-trial EEG decoding with data augmentation. When performing multi-trial EEG classification, the amount of training data decreases linearly after averaging, which may result in poor generalization. To address this deficiency, we devised three schemes to randomly combine data for network training. Accordingly, the results indicate that the proposed strategies effectively prevent overfitting and improve the correct classification rate compared with averaging EEG fixedly (by up to 19.20%). The highest accuracy of the three strategies for multi-trial EEG classification achieves 82.92%. The decoding performance for the methods proposed in this work indicates they have application potential in the brain-computer interface (BCI) system based on visual motion perception.","electroencephalography,attention mechanisms,recurrent neural networks,data augmentation,brain-computer interface,visual motion perception",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,NEURAL-NETWORKS,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/16/5662/pdf,
71,Melanoma Diagnosis Using Deep Learning and Fuzzy Logic,10,8,,"Banerjee Shubhendu,Singh Sumit Kumar,Chakraborty Avishek,Das Atanu,Bag Rajib","Banerjee S,Singh SK,Chakraborty A,Das A,Bag R",Banerjee S,10.3390/diagnostics10080577,"Narula Inst Technol, Dept CSE, Kolkata 700109, India.","Melanoma or malignant melanoma is a type of skin cancer that develops when melanocyte cells, damaged by excessive exposure to harmful UV radiations, start to grow out of control. Though less common than some other kinds of skin cancers, it is more dangerous because it rapidly metastasizes if not diagnosed and treated at an early stage. The distinction between benign and melanocytic lesions could at times be perplexing, but the manifestations of the disease could fairly be distinguished by a skilled study of its histopathological and clinical features. In recent years, deep convolutional neural networks (DCNNs) have succeeded in achieving more encouraging results yet faster and computationally effective systems for detection of the fatal disease are the need of the hour. This paper presents a deep learning-based 'You Only Look Once (YOLO)' algorithm, which is based on the application of DCNNs to detect melanoma from dermoscopic and digital images and offer faster and more precise output as compared to conventional CNNs. In terms with the location of the identified object in the cell, this network predicts the bounding box of the detected object and the class confidence score. The highlight of the paper, however, lies in its infusion of certain resourceful concepts like two phase segmentation done by a combination of the graph theory using minimal spanning tree concept and L-type fuzzy number based approximations and mathematical extraction of the actual affected area of the lesion region during feature extraction process. Experimented on a total of 20250 images from three publicly accessible datasets-PH2, International Symposium on Biomedical Imaging (ISBI) 2017 and The International Skin Imaging Collaboration (ISIC) 2019, encouraging results have been obtained. It achieved a Jac score of 79.84% on ISIC 2019 dataset and 86.99% and 88.64% on ISBI 2017 and PH2 datasets, respectively. Upon comparison of the pre-defined parameters with recent works in this area yielded comparatively superior output in most cases.","skin cancer,melanoma,skin lesion segmentation,YOLO,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"SKIN-LESION,SEGMENTATION,MODEL,ALGORITHM,FEATURES,NUMBER,NEVI",DIAGNOSTICS,https://www.mdpi.com/2075-4418/10/8/577/pdf,
72,Machine Learning Model Comparison in the Screening of Cholangiocarcinoma Using Plasma Bile Acids Profiles,10,8,,"Negrini Davide,Zecchin Patrick,Ruzzenente Andrea,Bagante Fabio,De Nitto Simone,Gelati Matteo,Salvagno Gian Luca,Danese Elisa,Lippi Giuseppe","Negrini D,Zecchin P,Ruzzenente A,Bagante F,De Nitto S,Gelati M,Salvagno GL,Danese E,Lippi G",Danese E,10.3390/diagnostics10080551,University of Verona,"Bile acids (BAs) assessments are garnering increasing interest for their potential involvement in development and progression of cholangiocarcinoma (CCA). Since machine learning (ML) algorithms are increasingly used for exploring metabolomic profiles, we evaluated performance of some ML models for dissecting patients with CCA or benign biliary diseases according to their plasma BAs profiles. We used ultra-performance liquid chromatography tandem mass spectrometry (UHPLC-MS/MS) for assessing plasma BAs profile in 112 patients (70 CCA, 42 benign biliary diseases). Twelve normalisation procedures were applied, and performance of six ML algorithms were evaluated (logistic regression, k-nearest neighbors, naive bayes, RBF SVM, random forest, extreme gradient boosting). Naive bayes, using direct bilirubin concentration for normalisation of BAs, was the ML model displaying better performance in the holdout set, with an Area Under Curve (AUC) of 0.95, 0.79 sensitivity, 1.00 specificity. This model, also characterised by 1.00 positive predictive value and 0.73 negative predictive value, displayed a globally excellent accuracy (86.4%). The accuracy of the other five models was lower, and AUCs ranged 0.75-0.95. Preliminary results of this study show that application of ML to BAs profile analysis can provide a valuable contribution for characterising bile duct diseases and identifying patients with higher likelihood of having malignant pathologies.","machine learning,artificial intelligence,bile acids,cholangiocarcinoma,screening",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,DIAGNOSIS,DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7460348,
73,Semantic Segmentation of Conjunctiva Region for Non-Invasive Anemia Detection Applications,9,8,,"Kasiviswanathan Sivachandar,Bai Vijayan Thulasi,Simone Lorenzo,Dimauro Giovanni","Kasiviswanathan S,Vijayan TB,Simone L,Dimauro G",Dimauro G,10.3390/electronics9081309,Universita degli Studi di Bari Aldo Moro,"Technology is changing the future of healthcare, technology-supported non-invasive medical procedures are more preferable in the medical diagnosis. Anemia is one of the widespread diseases affecting the wellbeing of individuals around the world especially childbearing age women and children and addressing this issue with the advanced technology will reduce the prevalence in large numbers. The objective of this work is to perform segmentation of the conjunctiva region for non-invasive anemia detection applications using deep learning. The proposed U-Net Based Conjunctiva Segmentation Model (UNBCSM) uses fine-tuned U-Net architecture for effective semantic segmentation of conjunctiva from the digital eye images captured by consumer-grade cameras in an uncontrolled environment. The ground truth for this supervised learning was given as Pascal masks obtained by manual selection of conjunctiva pixels. Image augmentation and pre-processing was performed to increase the data size and the performance of the model. UNBCSM showed good segmentation results and exhibited a comparable value of Intersection over Union (IoU) score between the ground truth and the segmented mask of 96% and 85.7% for training and validation, respectively.","convolutional neural network (CNN),bio-medical applications,deep learning,computer-aided diagnostics,image processing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,,"PALLOR,HEMOGLOBIN,INFORMATION,DIAGNOSIS,VALIDITY,SYSTEM,COLOR",ELECTRONICS,https://www.mdpi.com/2079-9292/9/8/1309/pdf,
74,Automated Data Acquisition System Using a Neural Network for Prediction Response in a Mode-Locked Fiber Laser,9,8,,"Ramon Martinez-Angulo Jose,Perez-Careta Eduardo,Carlos Hernandez-Garcia Juan,Marquez-Figueroa Sandra,Barron Zambrano Jose Hugo,Jauregui-Vazquez Daniel,David Filoteo-Razo Jose,Pablo Lauterio-Cruz Jesus,Pottiez Olivier,Moises Estudillo-Ayala Julian","Martinez-Angulo JR,Perez-Careta E,Hernandez-Garcia JC,Marquez-Figueroa S,Zambrano JHB,Jauregui-Vazquez D,Filoteo-Razo JD,Lauterio-Cruz JP,Pottiez O,Estudillo-Ayala JM",Perez-Careta E,10.3390/electronics9081181,Universidad de Guanajuato,"In this paper, we proposed a system to integrate optical and electronic instrumentation devices to predict a mode-locking fiber laser response, using a remote data acquisition with processing through an artificial neural network (ANN). The system is made up of an optical spectrum analyzer (OSA), oscilloscope (OSC), polarimeter (PAX), and the data acquisition automation through transmission control protocol/internet protocol (TCP/IP). A graphic user interface (GUI) was developed for automated data acquisition with the purpose to study the operational characteristics and stability at the passively mode-locked fiber laser (figure-eight laser, F8L) output. Moreover, the evolution of the polarization state and the behavior of the pulses are analyzed when polarization is changed by proper control plate adjustments. The data is processed using deep learning techniques, which provide the characteristics of the pulse at the output. Therefore, the parameter classification-identification is in accordance with the input polarization tilt used for the laser optimization.","fiber optics,laser,automation,remote control,neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"GENETIC,ALGORITHMS,OPTIMIZATION,DESIGN",ELECTRONICS,https://www.mdpi.com/2079-9292/9/8/1181/pdf,
75,Unmanned Aerial System and Machine Learning Techniques Help to Detect Dead Woody Components in a Tropical Dry Forest,11,8,,"Campos-Vargas Carlos,Sanchez-Azofeifa Arturo,Laakso Kati,Marzahn Philip","Campos-Vargas C,Sanchez-Azofeifa A,Laakso K,Marzahn P",Sanchez-Azofeifa A,10.3390/f11080827,University of Alberta,"Background and Objectives:Increased frequency and intensity of drought events are predicted to occur throughout the world because of climate change. These extreme climate events result in higher tree mortality and fraction of dead woody components, phenomena that are currently being reported worldwide as critical indicators of the impacts of climate change on forest diversity and function. In this paper, we assess the accuracy and processing times of ten machine learning (ML) techniques, applied to multispectral unmanned aerial vehicle (UAV) data to detect dead canopy woody components.Materials and Methods:This work was conducted on five secondary dry forest plots located at the Santa Rosa National Park Environmental Monitoring Super Site, Costa Rica.Results:The coverage of dead woody components at the selected secondary dry forest plots was estimated to range from 4.8% to 16.1%, with no differences between the successional stages. Of the ten ML techniques, the support vector machine with radial kernel (SVMR) and random forests (RF) provided the highest accuracies (0.982 vs. 0.98, respectively). Of these two ML algorithms, the processing time of SVMR was longer than the processing time of RF (8735.64 s vs. 989 s).Conclusions:Our results demonstrate that it is feasible to detect and quantify dead woody components, such as dead stands and fallen trees, using a combination of high-resolution UAV data and ML algorithms. Using this technology, accuracy values higher than 95% were achieved. However, it is important to account for a series of factors, such as the optimization of the tuning parameters of the ML algorithms, the environmental conditions and the time of the UAV data acquisition.","Costa Rica,forest mortality,machine learning,tropical dry forests,unmanned aerial systems",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Forestry,,2.804,"SUCCESSIONAL,STAGES,SPECIES,COMPOSITION,TEXTURE,ANALYSIS,LAND-COVER,CLASSIFICATION,MORTALITY,DROUGHT,DIVERSITY,LIANAS,IMAGES",FORESTS,https://www.mdpi.com/1999-4907/11/8/827/pdf,
76,Full 3D Microwave Breast Imaging Using a Deep-Learning Technique,6,8,,"Khoshdel Vahab,Asefi Mohammad,Ashraf Ahmed,LoVetri Joe","Khoshdel V,Asefi M,Ashraf A,LoVetri J",Khoshdel V,10.3390/jimaging6080080,University of Manitoba,"A deep learning technique to enhance 3D images of the complex-valued permittivity of the breast obtained via microwave imaging is investigated. The developed technique is an extension of one created to enhance 2D images. We employ a 3D Convolutional Neural Network, based on the U-Net architecture, that takes in 3D images obtained using the Contrast-Source Inversion (CSI) method and attempts to produce the true 3D image of the permittivity. The training set consists of 3D CSI images, along with the true numerical phantom images from which the microwave scattered field utilized to create the CSI reconstructions was synthetically generated. Each numerical phantom varies with respect to the size, number, and location of tumors within the fibroglandular region. The reconstructed permittivity images produced by the proposed 3D U-Net show that the network is not only able to remove the artifacts that are typical of CSI reconstructions, but it also enhances the detectability of the tumors. We test the trained U-Net with 3D images obtained from experimentally collected microwave data as well as with images obtained synthetically. Significantly, the results illustrate that although the network was trained using only images obtained from synthetic data, it performed well with images obtained from both synthetic and experimental data. Quantitative evaluations are reported using Receiver Operating Characteristics (ROC) curves for the tumor detectability and RMS error for the enhancement of the reconstructions.","microwave breast imaging,image reconstruction,tumor detection,convolutional neural networks,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Imaging Science & Photographic Technology,,,"CONVOLUTIONAL,NEURAL-NETWORKS,INTEGRATING,PRIOR,INFORMATION,INVERSE-SCATTERING,DIELECTRIC-PROPERTIES,RECONSTRUCTION,TOMOGRAPHY,IMPACT",JOURNAL OF IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8321110,
77,In-Memory Logic Operations and Neuromorphic Computing in Non-Volatile Random Access Memory,13,16,,"Ou Qiao-Feng,Xiong Bang-Shu,Yu Lei,Wen Jing,Wang Lei,Tong Yi","Ou QF,Xiong BS,Yu L,Wen J,Wang L,Tong Y",Wang L,10.3390/ma13163532,Nanchang Hangkong University,"Recent progress in the development of artificial intelligence technologies, aided by deep learning algorithms, has led to an unprecedented revolution in neuromorphic circuits, bringing us ever closer to brain-like computers. However, the vast majority of advanced algorithms still have to run on conventional computers. Thus, their capacities are limited by what is known as the von-Neumann bottleneck, where the central processing unit for data computation and the main memory for data storage are separated. Emerging forms of non-volatile random access memory, such as ferroelectric random access memory, phase-change random access memory, magnetic random access memory, and resistive random access memory, are widely considered to offer the best prospect of circumventing the von-Neumann bottleneck. This is due to their ability to merge storage and computational operations, such as Boolean logic. This paper reviews the most common kinds of non-volatile random access memory and their physical principles, together with their relative pros and cons when compared with conventional CMOS-based circuits (Complementary Metal Oxide Semiconductor). Their potential application to Boolean logic computation is then considered in terms of their working mechanism, circuit design and performance metrics. The paper concludes by envisaging the prospects offered by non-volatile devices for future brain-inspired and neuromorphic computation.","in-memory logic operation,non-volatile,random access memory,von Neumann bottleneck,neuromorphic computation",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"PHASE-CHANGE,MATERIALS,TORQUE,MEMRISTOR,DRIVEN,DEVICE,STT,MAGNETIZATION,MECHANISMS,RESISTANCE,SYNAPSES",MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7475900,
78,2D Digital Image Correlation and Region-Based Convolutional Neural Network in Monitoring and Evaluation of Surface Cracks in Concrete Structural Elements,13,16,,"Slonski Marek,Tekieli Marcin","Slonski M,Tekieli M",Slonski M,10.3390/ma13163527,Cracow University of Technology,"This paper shows how 2D digital image correlation (2D DIC) and region-based convolutional neural network (R-CNN) can be combined for image-based automated monitoring and assessment of surface crack development of concrete structural elements during laboratory quasi-static tests. In the presented approach, the 2D DIC-based monitoring enables estimation of deformation fields on the surface of the concrete element and measurements of crack width. Moreover, the R-CNN model provides unmanned simultaneous detection and localization of multiple cracks in the images. The results show that the automatic monitoring and evaluation of crack development in concrete structural elements is possible with high accuracy and reliability.","digital image correlation,region-based convolutional neural network,machine learning,crack monitoring,crack detection and localization",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,,MATERIALS,https://doi.org/10.3390/ma13163527,
79,Continuous and Noninvasive Estimation of Right Ventricle Systolic Blood Pressure Using Heart Sound Signal by Deep Bidirectional LSTM Network,10,16,,"Wang Miao,Tang Hong,Feng Tengfei,Guo Binbin","Wang M,Tang H,Feng TF,Guo BB",Tang H,10.3390/app10165466,Dalian University of Technology,"Objective: Timely monitoring right ventricular systolic blood pressure (RVSBP) is helpful in the early detection of pulmonary hypertension (PH). However, it is not easy to monitor RVSBP directly. The objective of this paper is to develop a deep learning technique for RVSBP noninvasive estimation using heart sound (HS) signals supported by (electrocardiography) ECG signals without complex features extraction. Methods: Five beagle dog subjects were used. The medicine U-44069 was injected into the subjects to induce a wide range of RVSBP variation. The blood pressure in right ventricle, ECG of lead I and HS signals were recorded simultaneously. Thirty-two records were collected. The relations between RVSBP and cyclic HS signals were modeled by the Bidirectional Long Short-Term Memory (Bi-LSTM) network. Results: The mean absolute error (MAE) +/- standard deviation (SD) inside record was 1.85 +/- 1.82 mmHg. It was 4.37 +/- 2.49 mmHg across record but within subject. The corrective factors were added after training the Bi-LSTM network across subjects. Finally, the MAE +/- SD from 12.46 +/- 6.56 mmHg dropped to 6.37 +/- 4.90 mmHg across subjects. Significance: Our work was the first to apply the Bi-LSTM network to build relations between the HS signal and RVSBP. This work suggested a noninvasive and continuous RVSBP estimation using the HS signal supported by the ECG signal by deep learning architecture without the need of healthcare professionals.","right ventricular systolic blood pressure,heart sound signal,bidirectional LSTM (Bi-LSTM) network,corrective factors,detection of pulmonary hypertension",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"PULMONARY-ARTERY,PRESSURE,SPECTRAL-ANALYSIS,HYPERTENSION,CHILDREN,PHYSIOLOGY",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/16/5466/pdf,
80,Study on Prediction and Application of Initial Chord Elastic Modulus with Resonance Frequency Test of ASTM C 215,10,16,,"Yoon Young Geun,Choi HaJin,Oh Tae Keun","Yoon YG,Choi H,Oh TK",Oh TK,10.3390/app10165464,Incheon National University,"For accurate design, construction, and maintenance, it is important to identify the elastic modulus of concrete. This is usually achieved using a destructive test based on American Society for Testing and Materials (ASTM) C469. However, obtaining an appropriate static elastic modulus (Ec) requires many specimens, and the testing is difficult and time-consuming. Thus, a dynamic elastic modulus (Ed) is often obtained through a natural frequency for a specific size (e.g., the longitudinal (LT) or transverse (TR) mode) based on a resonance frequency test. However, this method uses a gradient at a very low-stress part of the stress-strain curve and assumes a completely elastic body. In fact, the initial chord elastic modulus (Ei) of the stress-strain curve in a concrete fracture test differs from the Ed, owing to the non-homogeneity and inelasticity of the concrete. TheEiof the experimental value may be more accurate. In this study, theEiwas predicted using machine learning methods for natural frequencies. The prediction accuracy forEiwas analyzed based on f1-f4, as calculated through the LT and TR modes. The predictedEihad higher correlations with the actualEcand compressive strength (fc) thanEd. Thus, more accurate prediction of concrete mechanical properties is possible.","initial chord elastic modulus,resonance frequency test,static elastic modulus,dynamic elastic modulus,compressive strength,non-destructive testing,concrete,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,,"HIGH-PERFORMANCE,CONCRETE,COMPRESSIVE,STRENGTH,MODELS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/16/5464/pdf,
81,A Wearable System for In-Home and Long-Term Assessment of Fetal Movement,41,4,205-211,"Zhao X.,Zeng X.,Koehl L.,Tartare G.,De Jonckheere J.","Zhao X,Zeng X,Koehl L,Tartare G,De Jonckheere J",Zeng X,10.1016/j.irbm.2019.11.003,"ENSAIT Text Inst, Roubaix, France.","Objectives: This paper presents a novel wearable system for in-home and long-term fetal movement monitoring on a reliable and easily accessible basis.
Material and methods: The system mainly consists of four accelerometers for fetal movement signal acquisition, a microcontroller for signal processing and an Android-based device interacting with the microcontroller via Bluetooth Low Energy (BLE), providing the mother with information related to the fetal movement in an intelligible way.
Results: The proposed system can deliver reliable results with a specificity of 0.99 and a sensitivity of 0.77 for fetal movement time series signal classification.
Conclusion: The proposed wearable system will provide a good alternative to optimize the use of medical professionals and hospital resources, and has potential applications in the field of e-Health home care. Besides, the fetal movement acceleration signals acquired with volunteers (pregnant women) help establish an initial database for future medical analysis of sensor-recorded fetal behaviors. (C) 2019 AGBM. Published by Elsevier Masson SAS. All rights reserved.","Fetal movements,Wearable system,Accelerometer,Machine learning",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA",Engineering,,,"FUZZY,ARTMAP,FETUS",IRBM,https://hal.archives-ouvertes.fr/hal-02366492/file/irbm_manuscript_submission.pdf,
82,Measuring Gait-Event-Related Brain Potentials (gERPs) during Instructed and Spontaneous Treadmill Walking: Technical Solutions and Automated Classification through Artificial Neural Networks,10,16,,"Herbert Cornelia,Munz Michael","Herbert C,Munz M",Herbert C,10.3390/app10165405,Ulm University,"The investigation of the neural correlates of human gait, as measured by means of non-invasive electroencephalography (EEG), is of central importance for the understanding of human gait and for novel developments in gait rehabilitation. Particularly, gait-event-related brain potentials (gERPs) may provide information about the functional role of cortical brain regions in human gait control. The purpose of this paper is to explore possible experimental and technical solutions for time-sensitive analysis of human gait ERPs during spontaneous and instructed treadmill walking. A solution (hardware/software) for synchronous recording of gait and EEG data was developed, tested and piloted. The solution consists of a custom-made USB synchronization interface, a time-synchronization module, and a data-merging module, allowing the temporal synchronization of recording devices, time-sensitive extraction of gait markers for the analysis of gERPs, and the training of artificial neural networks. In the present manuscript, the hardware and software components were tested with the following devices: A treadmill with an integrated pressure plate for gait analysis (zebris FDM-T) and an Acticap non-wireless 32-channel EEG system (Brain Products GmbH). The usability and validity of the developed solution was investigated in a pilot study (n= 3 healthy participants,n= 3 females, mean age = 22.75 years). The recorded continuous EEG data were segmented into epochs according to the detected gait markers for the analysis of gERPs. Finally, the EEG epochs were used to train a deep learning artificial neural network as classifier of gait phases. The results obtained in this pilot study, although preliminary, support the feasibility of the solution for the application of gait-related EEG analysis.","human gait analysis,machine learning,motor potentials,event-related potentials (ERPs),gait-ERPs,cognition",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,,"ATTENTION,EEG,%28DE%29SYNCHRONIZATION,DESYNCHRONIZATION,MOVEMENTS,RHYTHM,FALLS",APPLIED SCIENCES-BASEL,https://oparu.uni-ulm.de/xmlui/bitstream/123456789/34094/1/Herbert2020.pdf,
83,Driver emotion recognition of multiple-ECG feature fusion based on BP network and D-S evidence,14,8,815-824,"Wang Xiaoyuan,Guo Yongqing,Ban Jeff,Xu Qing,Bai Chenglin,Liu Shanliang","Wang XY,Guo YQ,Ban J,Xu Q,Bai CL,Liu SL",Wang XY,10.1049/iet-its.2019.0499,Qingdao University of Science & Technology,"Driving emotion is considered as driver's psychological reaction to a change in traffic environment, which affects driver's cognitive, judgement and behaviour. In anxiety, drivers are more likely to get engaged in distracted driving, increasing the likelihood of vehicle crash. Therefore, it is essential to identify driver's anxiety during driving, to provide a basis for driving safety. This study used multiple-electrocardiogram (ECG) feature fusion to recognise driver's emotion, based on back-propagation network and Dempster-Shafer evidence method. The three features of ECG signals, the time-frequency domain, waveform and non-linear characteristics were selected as the parameters for emotion recognition. An emotion recognition model was proposed to identify drivers' calm and anxiety during driving. The results show after ECG evidence fusion, the proposed model can recognise drivers' emotion, with an accuracy rate of 91.34% for calm and 92.89% for anxiety. The authors' findings of this study can be used to develop the personalised driving warning system and intelligent human-machine interaction in vehicles. This study would be of great theoretical significance and application value for improving road traffic safety.","road safety,emotion recognition,road traffic,road accidents,driver information systems,uncertainty handling,medical signal processing,feature extraction,psychology,backpropagation,sensor fusion,inference mechanisms,electrocardiography,cognition,driver emotion recognition,BP network,D-S evidence,driving emotion,traffic environment,anxiety,distracted driving,vehicle crash,driving safety,back-propagation network,Dempster-Shafer evidence method,ECG signals,time-frequency domain,nonlinear characteristics,emotion recognition model,ECG evidence fusion,personalised driving warning system,road traffic safety,multiple-electrocardiogram feature fusion,multiple-ECG feature fusion,driver psychological reaction",Article; Proceedings Paper,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND","Engineering,Transportation",,2.671,"BEHAVIOR,SAFETY",IET INTELLIGENT TRANSPORT SYSTEMS,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-its.2019.0499,
84,Stabilizer Formulation Based on High-Throughput Chemiluminescence Imaging and Machine Learning,2,8,3319-3326,"Taniike Toshiaki,Kitamura Taishi,Nakayama Koyuru,Takimoto Ken,Aratani Naoki,Wada Toru,Thakur Ashutosh,Chammingkwan Patchanee","Taniike T,Kitamura T,Nakayama K,Takimoto K,Aratani N,Wada T,Thakur A,Chammingkwan P",Taniike T,10.1021/acsapm.0c00442,Japan Advanced Institute of Science & Technology (JAIST),"The combination of synergistic stabilizers is a basic strategy for prolonging the lifetime of polymeric materials, but exploration of combinations has been minimally accomplished due to certain problems. Here, we report a highly efficient exploration of stabilizer formulations based on high-throughput chemiluminescence imaging (HTP-CLI) and machine learning. Different formulations were generated by selecting 10 kinds of stabilizers from a library, and their performance in stabilizing polypropylene (PP) was evaluated based on HTP-CLI measurements. Formulations were evolved through a genetic algorithm to elongate the lifetime of PP. A demonstrative implementation up to the fifth generation successfully identified performant formulations, in which mutually synergistic combinations of stabilizers played a pivotal role.","polymer stabilization,combinatorial optimization,high-throughput chemiluminescence imaging,genetic algorithm,synergistic combination",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Materials Science,Polymer Science",,4.089,"RECOMBINANT,SPIDER,SILK,LIGHT,STABILIZERS,PHENOLIC,ANTIOXIDANTS,POLYPROPYLENE,DEGRADATION,SYNERGISM,POLYMERS,BEHAVIOR,LIMITS",ACS APPLIED POLYMER MATERIALS,,
85,Semiautomatic Segmentation and Radiomics for Dual-Energy CT: A Pilot Study to Differentiate Benign and Malignant Hepatic Lesions,215,2,398-405,"Homayounieh Fatemeh,Singh Ramandeep,Nitiwarangkul Chayanin,Lades Felix,Schmidt Bernhard,Sedlmair Martin,Saini Sanjay,Kalra Mannudeep K.","Homayounieh F,Singh R,Nitiwarangkul C,Lades F,Schmidt B,Sedlmair M,Saini S,Kalra MK",Homayounieh F,10.2214/AJR.19.22164,Harvard University,"OBJECTIVE. This study assessed a machine learning-based dual-energy CT (DECT) tumor analysis prototype for semiautomatic segmentation and radiomic analysis of benign and malignant liver lesions seen on contrast-enhanced DECT.
MATERIALS AND METHODS. This institutional review board-approved study included 103 adult patients (mean age, 65 +/- 15 [SD] years; 53 men, 50 women) with benign (60/103) or malignant (43/103) hepatic lesions on contrast-enhanced dual-source DECT. Most malignant lesions were histologically proven; benign lesions were either stable on follow-up CT or had characteristic benign features on MRI. Low- and high-kilovoltage datasets were deidentified, exported offline, and processed with the DECT tumor analysis for semiautomatic segmentation of the volume and rim of each liver lesion. For each segmentation, contrast enhancement and iodine concentrations as well as radiomic features were derived for different DECT image series. Statistical analyses were performed to determine if DECT tumor analysis and radiomics can differentiate benign from malignant liver lesions.
RESULTS. Normalized iodine concentration and mean iodine concentration in the benign and malignant lesions were significantly different (p < 0.0001-0.0084; AUC, 0.6950.856). Iodine quantification and radiomic features from lesion rims (AUC, <= 0.877) had higher accuracy for differentiating liver lesions compared with the values from lesion volumes (AUC, <= 0.856). There was no difference in the accuracies of DECT iodine quantification (AUC, 0.91) and radiomics (AUC, 0.90) for characterizing liver lesions.
CONCLUSION. DECT radiomics were more accurate than iodine quantification for differentiating solid benign and malignant hepatic lesions.","computer-assisted,dual-energy CT,image processing,liver lesions,radiomics,segmentation",Article,"AMER ROENTGEN RAY SOC, 44211 SLATESTONE CT, LEESBURG, VA USA","Radiology, Nuclear Medicine & Medical Imaging",,4.073,"LIVER-LESIONS,HEPATOCELLULAR-CARCINOMA,IMAGES",AMERICAN JOURNAL OF ROENTGENOLOGY,,
86,Myocardial Infarction Severity Stages Classification From ECG Signals Using Attentional Recurrent Neural Network,20,15,8711-8720,"Prabhakararao Eedara,Dandapat Samarendra","Prabhakararao E,Dandapat S",Prabhakararao E,10.1109/JSEN.2020.2984493,Indian Institute of Technology System (IIT System),"Myocardial infarction (MI) is a lethal heart condition that occurs due to the lack of blood flow to the heart tissues. Based on the time from symptoms onset, it is categorized into three severity stages: early MI (EMI), acute MI (AMI), and chronic MI (CMI). Electrocardiogram (ECG) signals are often used to diagnose MI with pathological changes in its characteristics. In clinical practice, accurate diagnosis and risk-stratification are essential to optimize various treatment strategies, hence clinical outcome. However, most automated methods focus only on identifying MI patients from healthy controls (HC). Therefore, in this paper, we propose a novel multi-lead diagnostic attention-based recurrent neural network (MLDA-RNN) for automated diagnosis of the three MI severity stages from HC subjects. The method systematically processes the 12-lead ECGs to capture the multi-scale temporal dependencies from each ECG leads for improved classification. Specifically, we first employ the RNNs to encode the temporal variations in the 12-lead ECG signals. These encoded vectors are fed to the intra-lead attention module to summarize the within-lead discriminative vectors to obtain lead-attentive representations. Then, the inter-lead attention module aggregates these representative vectors based on their clinical relevance to obtain a high-level feature representation for a reliable diagnosis. Using 12-lead ECGs from the PTBDB and STAFF III datasets, we achieved an overall accuracy of 97.79% without compromising on the class-wise detection rates. With improved performance, the MLDA-RNN also shows promising results for model interpretability as the learned attention weights often correlate with clinicians' way of diagnosing MI severity stages.","Electrocardiography,Myocardium,Feature extraction,Recurrent neural networks,Electromagnetic interference,Pathology,Lead,Electrocardiogram (ECG),myocardial infarction,recurrent neural networks,attention mechanism",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"LOCALIZATION,ISCHEMIA,ENERGY",IEEE SENSORS JOURNAL,,
87,Diagnosis of Coronavirus Disease 2019 (COVID-19) With Structured Latent Multi-View Representation Learning,39,8,2606-2614,"Kang Hengyuan,Xia Liming,Yan Fuhua,Wan Zhibin,Shi Feng,Yuan Huan,Jiang Huiting,Wu Dijia,Sui He,Zhang Changqing","Kang HY,Xia LM,Yan FH,Wan ZB,Shi F,Yuan H,Jiang HT,Wu DJ,Sui H,Zhang CQ",Zhang CQ,10.1109/TMI.2020.2992546,Tianjin University,"Recently, the outbreak of Coronavirus Disease 2019 (COVID-19) has spread rapidly across the world. Due to the large number of infected patients and heavy labor for doctors, computer-aided diagnosis with machine learning algorithm is urgently needed, and could largely reduce the efforts of clinicians and accelerate the diagnosis process. Chest computed tomography (CT) has been recognized as an informative tool for diagnosis of the disease. In this study, we propose to conduct the diagnosis of COVID-19 with a series of features extracted from CT images. To fully explore multiple features describing CT images from different views, a unified latent representation is learned which can completely encode information from different aspects of features and is endowed with promising class structure for separability. Specifically, the completeness is guaranteed with a group of backward neural networks (each for one type of features), while by using class labels the representation is enforced to be compact within COVID-19/community-acquired pneumonia (CAP) and also a large margin is guaranteed between different types of pneumonia. In this way, our model can well avoid overfitting compared to the case of directly projecting high-dimensional features into classes. Extensive experimental results show that the proposed method outperforms all comparison methods, and rather stable performances are observed when varying the number of training data.","Lung,Computed tomography,Feature extraction,Hospitals,Testing,COVID-19,COVID-19,Pneumonia,Chest computed tomography (CT),Multi-view representation learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CHEST,CT,CLASSIFICATION",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://ieeexplore.ieee.org/ielx7/42/9153182/09086482.pdf,
88,"A Rapid, Accurate and Machine-Agnostic Segmentation and Quantification Method for CT-Based COVID-19 Diagnosis",39,8,2638-2652,"Zhou Longxi,Li Zhongxiao,Zhou Juexiao,Li Haoyang,Chen Yupeng,Huang Yuxin,Xie Dexuan,Zhao Lintao,Fan Ming,Hashmi Shahrukh","Zhou LX,Li ZX,Zhou JX,Li HY,Chen YP,Huang YX,Xie DX,Zhao LT,Fan M,Hashmi S",Gao X,10.1109/TMI.2020.3001810,King Abdullah University of Science & Technology,"COVID-19 has caused a global pandemic and become the most urgent threat to the entire world. Tremendous efforts and resources have been invested in developing diagnosis, prognosis and treatment strategies to combat the disease. Although nucleic acid detection has been mainly used as the gold standard to confirm this RNA virus-based disease, it has been shown that such a strategy has a high false negative rate, especially for patients in the early stage, and thus CT imaging has been applied as a major diagnostic modality in confirming positive COVID-19. Despite the various, urgent advances in developing artificial intelligence (AI)-based computer-aided systems for CT-based COVID-19 diagnosis, most of the existing methods can only perform classification, whereas the state-of-the-art segmentation method requires a high level of human intervention. In this paper, we propose a fully-automatic, rapid, accurate, and machine-agnostic method that can segment and quantify the infection regions on CT scans from different sources. Our method is founded upon two innovations: 1) the first CT scan simulator for COVID-19, by fitting the dynamic change of real patients' data measured at different time points, which greatly alleviates the data scarcity issue; and 2) a novel deep learning algorithm to solve the large-scene-small-object problem, which decomposes the 3D segmentation problem into three 2D ones, and thus reduces the model complexity by an order of magnitude and, at the same time, significantly improves the segmentation accuracy. Comprehensive experimental results over multi-country, multi-hospital, and multi-machine datasets demonstrate the superior performance of our method over the existing ones and suggest its important application value in combating the disease.","Computed tomography,Solid modeling,Lung,Three-dimensional displays,Image segmentation,COVID-19,COVID-19,deep learning,segmentation,computerized tomography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"PNEUMONIA,DISEASES",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://repository.kaust.edu.sa/bitstream/10754/663534/1/A%20rapid%20and%20accurate.pdf,
89,A Noise-Robust Framework for Automatic Segmentation of COVID-19 Pneumonia Lesions From CT Images,39,8,2653-2663,"Wang Guotai,Liu Xinglong,Li Chaoping,Xu Zhiyong,Ruan Jiugen,Zhu Haifeng,Meng Tao,Li Kang,Huang Ning,Zhang Shaoting","Wang GT,Liu XL,Li CP,Xu ZY,Ruan JG,Zhu HF,Meng T,Li K,Huang N,Zhang ST",Wang GT,10.1109/TMI.2020.3000314,University of Electronic Science & Technology of China,"Segmentation of pneumonia lesions from CT scans of COVID-19 patients is important for accurate diagnosis and follow-up. Deep learning has a potential to automate this task but requires a large set of high-quality annotations that are difficult to collect. Learning from noisy training labels that are easier to obtain has a potential to alleviate this problem. To this end, we propose a novel noise-robust framework to learn from noisy labels for the segmentation task. We first introduce a noise-robust Dice loss that is a generalization of Dice loss for segmentation and Mean Absolute Error (MAE) loss for robustness against noise, then propose a novel COVID-19 Pneumonia Lesion segmentation network (COPLE-Net) to better deal with the lesions with various scales and appearances. The noise-robust Dice loss and COPLE-Net are combined with an adaptive self-ensembling framework for training, where an Exponential Moving Average (EMA) of a student model is used as a teacher model that is adaptively updated by suppressing the contribution of the student to EMA when the student has a large training loss. The student model is also adaptive by learning from the teacher only when the teacher outperforms the student. Experimental results showed that: (1) our noise-robust Dice loss outperforms existing noise-robust loss functions, (2) the proposed COPLE-Net achieves higher performance than state-of-the-art image segmentation networks, and (3) our framework with adaptive self-ensembling significantly outperforms a standard training process and surpasses other noise-robust training approaches in the scenario of learning from noisy labels for COVID-19 pneumonia lesion segmentation.","Noise measurement,Image segmentation,Lesions,Lung,Training,COVID-19,COVID-19,convolutional neural network,noisy label,segmentation,pneumonia",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,https://ieeexplore.ieee.org/ielx7/42/9153182/09109297.pdf,
90,Optimizing neuromodulation based on surrogate neural states for seizure suppression in a rat temporal lobe epilepsy model,17,4,,"Park Sang-Eon,Connolly Mark J.,Exarchos Ioannis,Fernandez Alejandra,Ghetiya Mihir,Gutekunst Claire-Anne,Gross Robert E.","Park SE,Connolly MJ,Exarchos I,Fernandez A,Ghetiya M,Gutekunst CA,Gross RE",Gross RE,10.1088/1741-2552/ab9909,University System of Georgia,"Objective.Developing a new neuromodulation method for epilepsy treatment requires a large amount of time and resources to find effective stimulation parameters and often fails due to inter-subject variability in stimulation effect. As an alternative, we present a novel data-driven surrogate approach which can optimize the neuromodulation efficiently by investigating the stimulation effect on surrogate neural states.Approach.Medial septum (MS) optogenetic stimulation was applied for modulating electrophysiological activities of the hippocampus in a rat temporal lobe epilepsy model. For the new approach, we implemented machine learning techniques to describe the pathological neural states and to optimize the stimulation parameters. Specifically, first, we found neural state surrogates to estimate a seizure susceptibility based on hippocampal local field potentials. Second, we modulated the neural state surrogates in a desired way with the subject-specific optimal stimulation parameters found byin vivoBayesian optimization. Finally, we tested whether modulating the neural state surrogates affected seizure frequency.Main results.We found two neural state surrogates: The first was hippocampal theta power by considering its well-known relationship with epilepsy, and the second was the output of pre-ictal state model (PriSM) which was built by characterizing the hippocampal activity during the pre-ictal period. The optimal stimulation parameters found by Bayesian optimization outperformed the other parameters in terms of modulating the surrogates toward anti-seizure neural state. When treatment efficacy was tested, the subject-specific optimal parameters for increasing theta power were more effective to suppress seizures than fixed stimulation parameter (7 Hz). However, modulation of the other neural state surrogate, PriSM, did not suppress seizures.Significance.The surrogate approach can save enormous time and resources to find subject-specific optimal stimulation parameters which can effectively modulate neural states and further improve therapeutic effectiveness. This approach can also be used for improving neuromodulation treatment of other neurological or psychiatric diseases.","surrogate,optimization,data-driven,epilepsy,medial septum,optogenetics",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"DEEP,BRAIN-STIMULATION,TETANUS,TOXIN,MODEL,SUBTHALAMIC,STIMULATION,ELECTRICAL-STIMULATION,LOOP",JOURNAL OF NEURAL ENGINEERING,,
91,Learning in brain-computer interface control evidenced by joint decomposition of brain and behavior,17,4,,"Stiso Jennifer,Corsi Marie-Constance,Vettel Jean M.,Garcia Javier,Pasqualetti Fabio,Fallani Fabrizio De Vico,Lucas Timothy H.,Bassett Danielle S.","Stiso J,Corsi MC,Vettel JM,Garcia J,Pasqualetti F,Fallani FD,Lucas TH,Bassett DS",Bassett DS,10.1088/1741-2552/ab9064,University of Pennsylvania,"Objective.Motor imagery-based brain-computer interfaces (BCIs) use an individual's ability to volitionally modulate localized brain activity, often as a therapy for motor dysfunction or to probe causal relations between brain activity and behavior. However, many individuals cannot learn to successfully modulate their brain activity, greatly limiting the efficacy of BCI for therapy and for basic scientific inquiry. Formal experiments designed to probe the nature of BCI learning have offered initial evidence that coherent activity across spatially distributed and functionally diverse cognitive systems is a hallmark of individuals who can successfully learn to control the BCI. However, little is known about how these distributed networks interact through time to support learning.Approach.Here, we address this gap in knowledge by constructing and applying a multimodal network approach to decipher brain-behavior relations in motor imagery-based brain-computer interface learning using magnetoencephalography. Specifically, we employ a minimally constrained matrix decomposition method -non-negative matrix factorization- to simultaneously identify regularized, covarying subgraphs of functional connectivity, to assess their similarity to task performance, and to detect their time-varying expression.Main results.We find that learning is marked by diffuse brain-behavior relations: good learners displayed many subgraphs whose temporal expression tracked performance. Individuals also displayed marked variation in the spatial properties of subgraphs such as the connectivity between the frontal lobe and the rest of the brain, and in the temporal properties of subgraphs such as the stage of learning at which they reached maximum expression. From these observations, we posit a conceptual model in which certain subgraphs support learning by modulating brain activity in sensors near regions important for sustaining attention. To test this model, we use tools that stipulate regional dynamics on a networked system (network control theory), and find that good learners display a single subgraph whose temporal expression tracked performance and whose architecture supports easy modulation of sensors located near brain regions important for attention.Significance.The nature of our contribution to the neuroscience of BCI learning is therefore both computational and theoretical; we first use a minimally-constrained, individual specific method of identifying mesoscale structure in dynamic brain activity to show how global connectivity and interactions between distributed networks supports BCI learning, and then we use a formal network model of control to lend theoretical support to the hypothesis that these identified subgraphs are well suited to modulate attention.","brain-computer interface,magnetoencephalography,control theory,network neuroscience,learning",Article,"IOP Publishing Ltd, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"MOTOR,IMAGERY,FUNCTIONAL,CONNECTIVITY,TOP-DOWN,DYNAMIC,RECONFIGURATION,BCI,NETWORK,NEUROFEEDBACK,OSCILLATIONS,PERFORMANCE,SCIENCE",JOURNAL OF NEURAL ENGINEERING,http://arxiv.org/pdf/1908.00077,
92,Deep learning-based BCI for gait decoding from EEG with LSTM recurrent neural network,17,4,,"Tortora Stefano,Ghidoni Stefano,Chisari Carmelo,Micera Silvestro,Artoni Fiorenzo","Tortora S,Ghidoni S,Chisari C,Micera S,Artoni F",Tortora S,10.1088/1741-2552/ab9842,University of Padua,"Objective.Mobile Brain/Body Imaging (MoBI) frameworks allowed the research community to find evidence of cortical involvement at walking initiation and during locomotion. However, the decoding of gait patterns from brain signals remains an open challenge. The aim of this work is to propose and validate a deep learning model to decode gait phases from Electroenchephalography (EEG).Approach.A Long-Short Term Memory (LSTM) deep neural network has been trained to deal with time-dependent information within brain signals during locomotion. The EEG signals have been preprocessed by means of Artifacts Subspace Reconstruction (ASR) and Reliable Independent Component Analysis (RELICA) to ensure that classification performance was not affected by movement-related artifacts.Main results.The network was evaluated on the dataset of 11 healthy subjects walking on a treadmill. The proposed decoding approach shows a robust reconstruction (AUC > 90%) of gait patterns (i.e. swing and stance states) of both legs together, or of each leg independently.Significance.Our results support for the first time the use of a memory-based deep learning classifier to decode walking activity from non-invasive brain recordings. We suggest that this classifier, exploited in real time, can be a more effective input for devices restoring locomotion in impaired people.","brain-computer interface (BCI),electroencephalography (EEG),mobile brain,body imaging (MoBI),deep learning,long-short term memory (LSTM),locomotion",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"BRAIN-COMPUTER,INTERFACE,TREADMILL,WALKING,CLASSIFICATION,OSCILLATIONS,IMAGINATION,DYNAMICS",JOURNAL OF NEURAL ENGINEERING,,
93,Machine Learning Reinforced Crystal Plasticity Modeling Under Experimental Uncertainty,58,8,3569-3576,Acar Pinar,Acar P,Acar P,10.2514/1.J059233,Virginia Polytechnic Institute & State University,"This Paper addresses a two-step computational approach to building a robust modeling environment for the titanium-aluminum alloy, Ti-7Al, a candidate aerospace material owing to superior mechanical performance under high stresses. To be used in aerospace applications, the large deformation behavior of the alloy should be investigated with a high-fidelity crystal plasticity model. However, there is no universal agreement on the crystal plasticity parameters, and previous efforts are only based on deterministic techniques. Therefore, our goal is to build a crystal plasticity model for Ti-7Al, which is validated for the global (component-scale) and local (grain-level) features by considering the experimental uncertainty. In the first step, the lower and upper bounds of the crystal plasticity parameters are determined with an inverse problem that is solved to match the computations with the experimental stress-strain data. The second step validates the local features by solving an optimization problem that minimizes the difference between the simulated and experimental microstructural textures. The optimization is performed using an Artificial Neural Network (ANN-)based surrogate model that is trained within the lower and upper limits of the parameters obtained in the first step. The outcomes of the two-step approach demonstrate significant improvement over the previous deterministic solutions.","ORIENTATION DISTRIBUTION,MICROSTRUCTURAL PROPERTIES,ELASTIC PROPERTIES,QUANTIFICATION,ALLOY,PREDICTION,POLYCRYSTALLINE,TITANIUM,BEHAVIOR,TI-7AL",Article,"AMER INST AERONAUTICS  ASTRONAUTICS, 1801 ALEXANDER BELL DRIVE, STE 500, RESTON, VA 22091-4344 USA",Engineering,,2.295,"ORIENTATION,DISTRIBUTION,MICROSTRUCTURAL,PROPERTIES,ELASTIC,PROPERTIES,QUANTIFICATION,ALLOY,PREDICTION,POLYCRYSTALLINE,TITANIUM,BEHAVIOR,TI-7AL",AIAA JOURNAL,,
94,Simple machine learning allied with data-driven methods for monitoring tool wear in machining processes,109,9-12,2491-2501,"de Farias Adalto,de Almeida Sergio Luiz Rabelo,Delijaicov Sergio,Seriacopi Vanessa,Bordinassi Ed Claudio","de Farias A,de Almeida SLR,Delijaicov S,Seriacopi V,Bordinassi EC",Bordinassi EC,10.1007/s00170-020-05785-x,Instituto Maua de Tecnologia,"The aim of this work was to identify the occurrence of machine tool wear in carbide inserts applied in a machine turning center with two steel materials. Through the data collected with an open-source communication protocol during machining, eighty trials of twenty runs each were performed using central composite design experiments, resulting in a data set of eighty lines for each tested material. The data set consisted of forty lines with the tool wear condition and forty lines without. Machining parameters were set to be in the range of the usual industrial values. The cutting parameters in the machining process were cutting speed, feed rate, cutting depth, and cutting fluid applied in the abundance condition and without cutting fluid (dry machining). The collected data were the spindle motor load,X-axis motor load, andZ-axis motor load in terms of the percentage used. AISI P20 and AISI 1045 steels workpieces were tested with both new and worn inserts, and a flank tool wear of 0.3 mm was artificially induced by machining with the same material before the data collecting experiment. Two approaches were used in order to analyze the data and create the machine learning process (MLP), in a prior analysis. The collected data set was tested without any previous treatment, with an optimal linear associative memory (OLAM) neural network, and the results showed 65% correct answers in predicting tool wear, considering 3/4 of the data set for training and 1/4 for validating. For the second approach, statistical data mining methods (DMM) and data-driven methods (DDM), known as a self-organizing deep learning method, were employed in order to increase the success ratio of the model. Both DMM and DDM applied along with the MLP OLAM neural network showed an increase in hitting the right answers to 93.8%. This model can be useful in machine monitoring using Industry 4.0 concepts, where one of the key challenges in machining components is finding the appropriate moment for a tool change.","Machine learning,Deep learning,Data-driven,Tool wear,Machining",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND","Automation & Control Systems,Engineering",,3.32,"PREDICTION,ONLINE",INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY,,
95,Classification of Neurological Patients to Identify Fallers Based on Spatial-Temporal Gait Characteristics Measured by a Wearable Device,20,15,,"Zhou Yuhan,Rehman Rana Zia Ur,Hansen Clint,Maetzler Walter,Del Din Silvia,Rochester Lynn,Hortobagyi Tibor,Lamoth Claudine J. C.","Zhou YH,Rehman RZU,Hansen C,Maetzler W,Del Din S,Rochester L,Hortobagyi T,Lamoth CJC",Zhou YH; Lamoth CJC,10.3390/s20154098,University of Groningen,"Neurological patients can have severe gait impairments that contribute to fall risks. Predicting falls from gait abnormalities could aid clinicians and patients mitigate fall risk. The aim of this study was to predict fall status from spatial-temporal gait characteristics measured by a wearable device in a heterogeneous population of neurological patients. Participants (n= 384, age 49-80 s) were recruited from a neurology ward of a University hospital. They walked 20 m at a comfortable speed (single task: ST) and while performing a dual task with a motor component (DT1) and a dual task with a cognitive component (DT2). Twenty-seven spatial-temporal gait variables were measured with wearable sensors placed at the lower back and both ankles. Partial least square discriminant analysis (PLS-DA) was then applied to classify fallers and non-fallers. The PLS-DA classification model performed well for all three gait tasks (ST, DT1, and DT2) with an evaluation of classification performance Area under the receiver operating characteristic Curve (AUC) of 0.7, 0.6 and 0.7, respectively. Fallers differed from non-fallers in their specific gait patterns. Results from this study improve our understanding of how falls risk-related gait impairments in neurological patients could aid the design of tailored fall-prevention interventions.","gait analysis,machine learning,inertial measurement units,neurological disorders,falls",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"OLDER-ADULTS,ELDERLY,FALLERS,RISK-FACTORS,NONFALLERS,VARIABILITY,COGNITION,PREDICT",SENSORS,https://pure.rug.nl/ws/files/130544017/sensors_20_04098.pdf,
96,Innovative Methods for Small Mixed Batches Production System Improvement: The Case of a Bakery Machine Manufacturer,12,15,,"Zgodavova Kristina,Bober Peter,Majstorovic Vidosav,Monkova Katarina,Santos Gilberto,Juhaszova Darina","Zgodavova K,Bober P,Majstorovic V,Monkova K,Santos G,Juhaszova D",Zgodavova K,10.3390/su12156266,Technical University Kosice,"One of the common problems of organizations with turn-key projects is the high scrap rate. There exist such traditional methods as Lean Six Sigma (LSS) and DMAIC tools that analyze causes and suggest solutions. New emerging intelligent technologies should influence these methods and tools as they affect many areas of our life. The purpose of this paper is to present the innovative Small Mixed Batches (SMB). The standard set of LSS tools is extended by intelligent technologies such as artificial neural networks (ANN) and machine learning. The proposed method uses the data-driven quality strategy to improve the turning process at the bakery machine manufacturer. The case study shows the step-by-step DMAIC procedure of critical to quality (CTQ) characteristics improvement. Findings from the data analysis lead to a change of measurement instrument, training of operators, and lathe machine set-up correction. However, the scrap rate did not decrease significantly. Therefore the advanced mathematical model based on ANN was built. This model predicts the CTQ characteristics from the inspection certificate of the input material. The prediction model is a part of a newly designed process control scheme using machine learning algorithms to reduce the variability even for input material with different properties from new suppliers. Further research will be focused on the validation of the proposed control scheme, and acquired experiences will be used to support business sustainability.","artificial neural network,lean six sigma,machine learning,process capability,small mixed batches,turning process",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Science & Technology - Other Topics,Environmental Sciences & Ecology",,3.473,"PREDICTING,SURFACE-ROUGHNESS,MODEL,LIFE",SUSTAINABILITY,https://www.mdpi.com/2071-1050/12/15/6266/pdf,
97,Upper Limb Bionic Orthoses: General Overview and Forecasting Changes,10,15,,"Rzyman Gustaw,Szkopek Jacek,Redlarski Grzegorz,Palkowski Aleksander","Rzyman G,Szkopek J,Redlarski G,Palkowski A",Redlarski G,10.3390/app10155323,Gdansk University of Technology,"Using robotics in modern medicine is slowly becoming a common practice. However, there are still important life science fields which are currently devoid of such advanced technology. A noteworthy example of a life sciences field which would benefit from process automation and advanced robotic technology is rehabilitation of the upper limb with the use of an orthosis. Here, we present the state-of-the-art and prospects for development of mechanical design, actuator technology, control systems, sensor systems, and machine learning methods in rehabilitation engineering. Moreover, current technical solutions, as well as forecasts on improvement, for exoskeletons are presented and reviewed. The overview presented might be the cornerstone for future research on advanced rehabilitation engineering technology, such as an upper limb bionic orthosis.","biomechanics,exoskeleton,rehabilitation,robot-assisted therapy",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"BRAIN-COMPUTER,INTERFACES,HAND,EXOSKELETON,ROBOTIC,EXOSKELETON,CARBON,NANOTUBES,EMG,SIGNAL,REHABILITATION,ARM,DESIGN,ACTUATORS,PERFORMANCE",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/15/5323/pdf,
98,Vectorization of persistence barcode with applications in pattern classification of porous structures,90,,182-192,"Dong Zhetong,Hu Chuanfeng,Zhou Chi,Lin Hongwei","Dong ZT,Hu CF,Zhou C,Lin HW",Lin HW,10.1016/j.cag.2020.05.029,Zhejiang University,"Persistence barcode is a topological summary for persistent homology to exhibit topological features with different persistence. Persistence rank function (PRF), derived from persistence barcode, organizes persistence Betti numbers in the form of an integer-valued function. To obtain topological patterns of objects such as point clouds represented by finite-dimensional vectors for machine learning classification tasks, the vectorizing representations of barcodes is generated via decomposing PRF on a system of Haar basis. Theoretically, the generated vectorizing representation is proved to have 1-Wasserstein stability. In practice, to reduce training time and achieve better results, a technique of dimensionality reduction through out-of-sample mapping in supervised manifold learning is used to generate a low-dimensional vector. Experiments demonstrate that the representation is effective for capturing the topological patterns of data sets. Moreover, the classification of porous structures has become an essential problem in the fields such as material science in recent decades. The proposed method is successfully applied to distinguish porous structures on a novel data set of porous models. (C) 2020 Elsevier Ltd. All rights reserved.","Computational topology,Machine learning,Persistent homology,Porous classification",Article; Proceedings Paper,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Computer Science,,1.698,"SCAFFOLD,STRUCTURE,LIBRARY,DESIGN",COMPUTERS & GRAPHICS-UK,,
99,Detecting dynamic development of weld pool using machine learning from innovative composite images for adaptive welding,56,,908-915,"Cheng Yongchao,Wang Qiyue,Jiao Wenhua,Yu Rui,Chen Shujun,Zhang YuMing,Xiao Jun","Cheng YC,Wang QY,Jiao WH,Yu R,Chen SJ,Zhang YM,Xiao J",Xiao J,10.1016/j.jmapro.2020.04.059,"Beijing Univ Technol, Minist Educ, Welding Res Inst, Beijing 100124, Peoples R China.","Gas tungsten arc welding (GTAW) is the primary joining process for critical applications where joining precision is crucial. However, variations in manufacturing conditions adversely affect the joining precision. The dynamic joining process needs to be monitored and adaptively controlled to assure the specified weld quality be produced despite variations. Among required weld qualities, the weld joint penetration is often the most critical one as an incomplete penetration causes explosion under high temperature/pressure and an excessive penetration/heat input affects the flow of fluids and degrades materials properties. Unfortunately, detecting its development, how the melted metal has developed within the work-piece, is challenging as it occurs underneath and is not directly observable. The key to solving the problem is to find, or design, measurable physical phenomena that are fully determined by the weld penetration and then correlate the phenomena to the penetration. Analysis shows that the weld pool surface that is directly observable using an innovative active vision method developed at the University of Kentucky is correlated to the thermal expansion of melted metal, thus the weld penetration. However, the surface is also affected by prior conditions. As such, we propose to form a composite image from the image taken from the initial pool, reflecting prior condition and from real-time developing pool such that this single composite image reflecting the measurable phenomena is only determined by the development of the weld penetration. To further correlate the measurable phenomena to the weld penetration, conventional methods analyze the date/images and propose features that may fundamentally characterize the phenomena. This kind of hand engineering method is tedious and does not assure success. To address this challenge, a convolutional neural network (CNN) is adopted that allows the raw composite images to be used directly as the input without need for hand engineering to manually analyze the features. The CNN model is applied to train, verify and test the datasets and the generated training model is used to identify the penetration states such that the welding current can be reduced from the peak to the base level after the desired penetration state is achieved despite manufacturing condition variations. The results show that the accuracy of the CNN model is approximately 97.5%.","GTAW-P,Penetration mode,Active vision,Composite image design,CNN",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,5.135,"GTAW,PENETRATION,SURFACE,FUSION,SENSOR",JOURNAL OF MANUFACTURING PROCESSES,,
100,Wearable Textile UHF-RFID Sensors: A Systematic Review,13,15,,"Luo Chengyang,Gil Ignacio,Fernandez-Garcia Raul","Luo CY,Gil I,Fernandez-Garcia R",Fernandez-Garcia R,10.3390/ma13153292,Polytechnic University of Catalonia,"Textile radio-frequency identification operating in ultra-high frequency (UHF-RFID) sensors based on different scenarios are becoming attractive with the forthcoming internet of things (IoT) era and aging society. Compared with conventional UHF-RFID sensors, textile UHF-RFID sensors offer the common textile features, light weight, washability and comfort. Due to the short time and low level of development, researches on the integration of textile UHF-RFID techniques and textile sensing techniques are not flourishing. This paper is motivated by this situation to identify the current research status. In this paper, we provide a systematic review of the fundamentals of textile UHF-RFID sensors techniques, materials, the brief history and the state-of-the-art of the scenario-based development through detailed summary and analysis on the achievements from the starting year of 2004 to the present time. Moreover, according to the analysis, we give a proposal of the future prospects in several aspects, including the new materials and manufacturing processes, machine learning technology, scenario-based applications and unavoidable reliability.","textile,ultra-high frequency (UHF),radio frequency identification (RFID),UHF-RFID sensors,scenario-based",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"WASHING,DURABILITY,TAGS,EMBROIDERY,ANTENNAS",MATERIALS,https://upcommons.upc.edu/bitstream/2117/329321/1/Wearable%20Textile%20UHF-RFID%20Sensors%20A%20Systematic%20Review.pdf,
