,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Improving Image Description with Auxiliary Modality for Visual Localization in Challenging Conditions,129,1,,"Piasco Nathan,Sidibe Desire,Gouet-Brunet Valerie,Demonceaux Cedric","Piasco N,Sidibe D,Gouet-Brunet V,Demonceaux C",Piasco N,10.1007/s11263-020-01363-6,"Univ Bourgogne Franche Comte, ImViA, VIBOT ERL CNRS 6000, Dijon, France.","Image indexing for lifelong localization is a key component for a large panel of applications, including robot navigation, autonomous driving or cultural heritage valorization. The principal difficulty in long-term localization arises from the dynamic changes that affect outdoor environments. In this work, we propose a new approach for outdoor large scale image-based localization that can deal with challenging scenarios like cross-season, cross-weather and day/night localization. The key component of our method is a new learned global image descriptor, that can effectively benefit from scene geometry information during training. At test time, our system is capable of inferring the depth map related to the query image and use it to increase localization accuracy. We show through extensive evaluation that our method can improve localization performances, especially in challenging scenarios when the visual appearance of the scene has changed. Our method is able to leverage both visual and geometric clues from monocular images to create discriminative descriptors for cross-season localization and effective matching of images acquired at different time periods. Our method can also use weakly annotated data to localize night images across a reference dataset of daytime images. Finally we extended our method to reflectance modality and we compare multi-modal descriptors respectively based on geometry, material reflectance and a combination of both.","Localization,Image retrieval,Side modality learning,Depth from monocular,Global image descriptor",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,13.284,"REPRESENTATIONS,RECOGNITION",INTERNATIONAL JOURNAL OF COMPUTER VISION,https://hal.archives-ouvertes.fr/hal-02912239/file/journal_paper_last.pdf,
2,A Review of Steel Processing Considerations for Oxide Cleanliness,51,6,2437-2452,"Webler B. A.,Pistorius P. C.","Webler BA,Pistorius PC",Pistorius PC,10.1007/s11663-020-01949-y,Carnegie Mellon University,"Control of non-metallic inclusions is essential for the production of high-quality steel. This review summarizes processes that change inclusion compositions and concentrations during secondary steelmaking-slower changes are limited by reaction between bulk steel and slag or refractory, and faster changes involve direct additions to the steel bath. An example of the former is conversion of alumina inclusions to spinels during ladle treatment, while reoxidation and calcium treatment are typical exemplars of the fast changes. For the slower changes, inclusions approach equilibrium with the liquid steel and conceptually simple kinetic models correctly describe inclusion evolution during ladle treatment. Disequilibrium from faster changes persists for several minutes under typical ladle conditions, with small-scale inhomogeneity in the steel. Fast scanning electron microscopy with microanalysis has facilitated detailed study of these inclusion evolution processes by providing information on inclusion composition, size, and shape. Machine learning methods are likely to be increasingly important in analysis of the results. Such methods have already shown promise to improve classification of inclusions and recognizing inclusion clusters, from analyses of polished sections. Several unresolved issues that require future study are noted.","IN-SITU OBSERVATION,OF-THE-ART,KINETIC-MODEL,NONMETALLIC INCLUSIONS,SECONDARY STEELMAKING,LIQUID STEEL,ALUMINA PARTICLES,GAS INJECTION,SPINEL INCLUSIONS,AL2O3 DISSOLUTION",Review,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Materials Science,Metallurgy & Metallurgical Engineering",,2.57,"IN-SITU,OBSERVATION,OF-THE-ART,KINETIC-MODEL,NONMETALLIC,INCLUSIONS,SECONDARY,STEELMAKING,LIQUID,STEEL,ALUMINA,PARTICLES,GAS,INJECTION,SPINEL,INCLUSIONS,AL2O3,DISSOLUTION",METALLURGICAL AND MATERIALS TRANSACTIONS B-PROCESS METALLURGY AND MATERIALS PROCESSING SCIENCE,https://link.springer.com/content/pdf/10.1007/s11663-020-01949-y.pdf,
3,Compressing soil structural information into parameterized correlation functions,72,2,561-577,"Karsanina Marina V,Lavrukhin Efim V,Fomin Dmitry S.,Yudina Anna V,Abrosimov Konstantin N.,Gerke Kirill M.","Karsanina MV,Lavrukhin EV,Fomin DS,Yudina AV,Abrosimov KN,Gerke KM",Gerke KM,10.1111/ejss.13025,Russian Academy of Sciences,"Soil structure is highly interconnected to all of its properties and functions. The structure for most soils is very complex and hierarchical in nature. Considering the fact that a truly multiscale digital 3D soil structure model for a single genetic horizon, even with the resolution not finer than 1 mu m, will contain an enormous amount (approx. up to 10(15)voxels or even more) of data, it is an appealing idea to compress this structural information. Effective management and pore-scale simulations based on such datasets do not seem feasible at the moment. Another approach would be to reduce the complexity to a limited but meaningful set of characteristics/parameters, for example using universal correlation functions (CFs). In this study, we successfully compressed the soil structural information in the form of 3D binary images into a set of correlation functions, each of which is described using only six parameters. We used four different correlation functions (two-point probability, lineal, cluster and surface-surface functions) computed in three orthogonal directions for the pores. The methodology was applied to 16 different soil 3D images obtained using X-ray microtomography (XCT) and segmented into pores and solids. All computed CFs were fitted using a superposition of three basis functions. In other words, we reduced 900-1300(3)voxel images into sets of 72 parameters. Fitting of computed correlation functions and reducing them to a number of parameters is a powerful way of compressing soil structural information. However, the analysis based on parameters alone is different from the one where correlation functions are used. This problem can be negated by uncompressing the correlation functions back from these parameters before any application. This way, correlation functions are not only a way to compress the soil structural information with minimal loss, but also may be used to solve a number of additional problems, including the comparison and differentiation of soil samples, location of elementary volumes, effective physical property prediction using machine learning, and fusion of hierarchical soil structures. Highlights
The 900-1300(3)voxels soil XCT scans were compressed into sets of 72 parameters The use of fitted parameters alone may result in the inconsistent analysis of the soil structures Each soil structure was uniquely described by a set of directional correlation functions Correlation functions were found to be sensitive to the structural difference of all the studied soils","basis functions,clustering analysis,compression,correlation functions,least squares fitting,soil structure digital model,X-ray microtomography",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Agriculture,,4.626,"PORE-SPACE,SOLUTE,TRANSPORT,HETEROGENEOUS,MATERIALS,TOMOGRAPHIC-IMAGES,WATER-RETENTION,POROUS-MEDIA,FLOW,RECONSTRUCTION,RESOLUTION,ELEMENTS",EUROPEAN JOURNAL OF SOIL SCIENCE,,
4,Reentrant incommensurate order and anomalous magnetic torque in the Kitaev magnet beta-Li2IrO3,2,3,,"Li Mengqun,Rousochatzakis Ioannis,Perkins Natalia B.","Li MQ,Rousochatzakis I,Perkins NB",Li MQ,10.1103/PhysRevResearch.2.033328,University of Minnesota System,"We present a theoretical study of the response of beta-Li2IrO3 under external magnetic fields in the ab, bc, and ac crystallographic planes. The results are based on the minimal nearest-neighbor J-K-Gamma model and reveal a rich intertwining of field-induced phases and magnetic phase transitions with distinctive signatures that can be probed directly via torque magnetometry. Most saliently, we observe (i) an unusual reentrance of the incommensurate counterrotating order for fields in the ab plane and (ii) a set of abrupt torque discontinuities which are particularly large for fields rotating in the bc plane and whose characteristic shape resembles closely the ones observed in the three-dimensional (3D) Kitaev magnet gamma-Li2IrO3. An experimental confirmation of these predictions will pave the way for an accurate determination of all relevant microscopic parameters of this 3D Kitaev magnet.","SPIN,PHYSICS",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,,"SPIN,PHYSICS",PHYSICAL REVIEW RESEARCH,https://figshare.com/articles/journal_contribution/Reentrant_incommensurate_order_and_anomalous_magnetic_torque_in_the_Kitaev_magnet_Li2IrO3/12888596/files/24501605.pdf,
5,Evaluation-oriented exploration of photo energy conversion systems: from fundamental optoelectronics and material screening to the combination with data science,52,12,1307-1321,Saeki Akinori,Saeki A,Saeki A,10.1038/s41428-020-00399-2,Osaka University,"Light is a form of energy that can be converted to electric and chemical energies. Thus, organic photovoltaics (OPVs), perovskite solar cells (PSCs), photocatalysts, and photodetectors have evolved as scientific and commercial enterprises. However, the complex photochemical reactions and multicomponent materials involved in these systems have hampered rapid progress in their fundamental understanding and material design. This review showcases the evaluation-oriented exploration of photo energy conversion materials by using electrodeless time-resolved microwave conductivity (TRMC) and materials informatics (MI). TRMC with its unique options (excitation sources, environmental control, frequency modulation, etc.) provides not only accelerated experimental screening of OPV and PSC materials but also a versatile route toward shedding light on their charge carrier dynamics. Furthermore, MI powered by machine learning is shown to allow extremely high-throughput exploration in the large molecular space, which is compatible with experimental screening and combinatorial synthesis.","CHARGE-CARRIER MOBILITY,RESOLVED MICROWAVE CONDUCTIVITY,ORGANIC-INORGANIC PEROVSKITES,SOLAR-CELLS,CONJUGATED POLYMERS,PHOTOVOLTAIC PERFORMANCE,PHOTOCATALYTIC ACTIVITY,GRAPHITIC NANOTUBES,SELF-ORGANIZATION,TRANSFER EXCITONS",Review,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Polymer Science,,2.601,"CHARGE-CARRIER,MOBILITY,RESOLVED,MICROWAVE,CONDUCTIVITY,ORGANIC-INORGANIC,PEROVSKITES,SOLAR-CELLS,CONJUGATED,POLYMERS,PHOTOVOLTAIC,PERFORMANCE,PHOTOCATALYTIC,ACTIVITY,GRAPHITIC,NANOTUBES,SELF-ORGANIZATION,TRANSFER,EXCITONS",POLYMER JOURNAL,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7453374,
6,Wavelet scattering networks for atomistic systems with extrapolation of material properties,153,8,,"Sinz Paul,Swift Michael W.,Brumwell Xavier,Liu Jialin,Kim Kwang Jin,Qi Yue,Hirn Matthew","Sinz P,Swift MW,Brumwell X,Liu JL,Kim KJ,Qi Y,Hirn M",Hirn M,10.1063/5.0016020,Michigan State University,"The dream of machine learning in materials science is for a model to learn the underlying physics of an atomic system, allowing it to move beyond the interpolation of the training set to the prediction of properties that were not present in the original training data. In addition to advances in machine learning architectures and training techniques, achieving this ambitious goal requires a method to convert a 3D atomic system into a feature representation that preserves rotational and translational symmetries, smoothness under small perturbations, and invariance under re-ordering. The atomic orbital wavelet scattering transform preserves these symmetries by construction and has achieved great success as a featurization method for machine learning energy prediction. Both in small molecules and in the bulk amorphous Li alpha Si system, machine learning models using wavelet scattering coefficients as features have demonstrated a comparable accuracy to density functional theory at a small fraction of the computational cost. In this work, we test the generalizability of our Li alpha Si energy predictor to properties that were not included in the training set, such as elastic constants and migration barriers. We demonstrate that statistical feature selection methods can reduce over-fitting and lead to remarkable accuracy in these extrapolation tasks.","ENERGY SURFACES,ACCURACY",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Chemistry,Physics",,3.166,"ENERGY,SURFACES,ACCURACY",JOURNAL OF CHEMICAL PHYSICS,http://arxiv.org/pdf/2006.01247,
7,Artificial intelligence in ophthalmology Guidelines for physicians for the critical evaluation of studies,117,10,973-988,"Pfau Maximilian,Walther Guenther,von der Emde Leon,Berens Philipp,Faes Livia,Fleckenstein Monika,Heeren Tjebo F. C.,Kortuem Karsten,Kuenzel Sandrine H.,Mueller Philipp L.","Pfau M,Walther G,von der Emde L,Berens P,Faes L,Fleckenstein M,Heeren TFC,Kortum K,Kunzel SH,Muller PL",Pfau M,10.1007/s00347-020-01209-z,Stanford University,"Background Empirical models have been an integral part of everyday clinical practice in ophthalmology since the introduction of the Sanders-Retzlaff-Kraff (SRK) formula. Recent developments in the field of statistical learning (artificial intelligence, AI) now enable an empirical approach to a wide range of ophthalmological questions with an unprecedented precision. Objective Which criteria must be considered for the evaluation of AI-related studies in ophthalmology? Material and methods Exemplary prediction of visual acuity (continuous outcome) and classification of healthy and diseased eyes (discrete outcome) using retrospectively compiled optical coherence tomography data (50 eyes of 50 patients, 50 healthy eyes of 50 subjects). The data were analyzed with nested cross-validation (for learning algorithm selection and hyperparameter optimization). Results Based on nested cross-validation for training, visual acuity could be predicted in the separate test data-set with a mean absolute error (MAE, 95% confidence interval, CI of 0.142 LogMAR [0.077; 0.207]). Healthy versus diseased eyes could be classified in the test data-set with an agreement of 0.92 (Cohen's kappa). The exemplary incorrect learning algorithm and variable selection resulted in an MAE for visual acuity prediction of 0.229 LogMAR [0.150; 0.309] for the test data-set. The drastic overfitting became obvious on comparison of the MAE with the null model MAE (0.235 LogMAR [0.148; 0.322]). Conclusion Selection of an unsuitable measure of the goodness-of-fit, inadequate validation, or withholding of a null or reference model can obscure the actual goodness-of-fit of AI models. The illustrated pitfalls can help clinicians to identify such shortcomings.","Statistical learning,Machine-learning,Deep learning,Automated analysis,Empirical approach",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Ophthalmology,,,"PREDICTION,SELECTION,BIAS,CLASSIFIERS",OPHTHALMOLOGE,,
8,Automated Detection of Acute Lymphoblastic Leukemia From Microscopic Images Based on Human Visual Perception,8,,,"Bodzas Alexandra,Kodytek Pavel,Zidek Jan","Bodzas A,Kodytek P,Zidek J",Bodzas A,10.3389/fbioe.2020.01005,Technical University of Ostrava,"Microscopic image analysis plays a significant role in initial leukemia screening and its efficient diagnostics. Since the present conventional methodologies partly rely on manual examination, which is time consuming and depends greatly on the experience of domain experts, automated leukemia detection opens up new possibilities to minimize human intervention and provide more accurate clinical information. This paper proposes a novel approach based on conventional digital image processing techniques and machine learning algorithms to automatically identify acute lymphoblastic leukemia from peripheral blood smear images. To overcome the greatest challenges in the segmentation phase, we implemented extensive pre-processing and introduced a three-phase filtration algorithm to achieve the best segmentation results. Moreover, sixteen robust features were extracted from the images in the way that hematological experts do, which significantly increased the capability of the classifiers to recognize leukemic cells in microscopic images. To perform the classification, we applied two traditional machine learning classifiers, the artificial neural network and the support vector machine. Both methods reached a specificity of 95.31%, and the sensitivity of the support vector machine and artificial neural network reached 98.25 and 100%, respectively.","automated leukemia detection,blood smear image analysis,cell segmentation,leukemic cell identification,acute leukemia,image processing,machine learning",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND","Biotechnology & Applied Microbiology,Science & Technology - Other Topics",,5.973,CLASSIFICATION,FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY,https://www.frontiersin.org/articles/10.3389/fbioe.2020.01005/pdf,
9,,,,,,,,,,,,,,,,,,,,
10,,,,,,,,,,,,,,,,,,,,
11,Deep Learning Methods for Screening Pulmonary Tuberculosis Using Chest X-rays,9,1,39-49,"Dasanayaka Chirath,Dissanayake Maheshi Buddhinee","Dasanayaka C,Dissanayake MB",Dissanayake MB,10.1080/21681163.2020.1808532,University of Peradeniya,"Tuberculosis (TB) is a contagious bacterial airborne disease, and is one of the top 10 causes of death worldwide. According to the World Health Organisation, around 1.8 billion people are infected with TB and 1.6 million deaths were reported in 2018. More importantly, 95% of cases and deaths were from developing countries. Yet, TB is a completely curable disease through early diagnosis. To achieve this goal one of the key requirements is efficient utilisation of existing diagnostic technologies, among which chest X-ray is the first line of diagnostic tool used for screening for active TB. The presented deep learning pipeline consists of three different modern deep learning architectures, to generate, segment, and classify lung X-rays. Apart from this, image preprocessing, image augmentation, genetic algorithm based hyper parameter tuning, and model ensembling were used to improve the diagnostic process. We were able to achieve classification accuracy of 97.1% (Youden's index-0.941, sensitivity of 97.9%, specificity of 96.2%) which is a considerable improvement compared to the existing work in the literature. In our work, we present a highly accurate, automated TB screening system using chest X-rays, which would be helpful especially for low income countries with low access to qualified medical professionals.","Machine Learning,automated Tuberculosis Screening,Chest/Lung X-ray analysis,Deep Convolutional Generative Adversarial Networks,segmentation and Classification",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,,"LUNG,SEGMENTATION,RADIOGRAPHS,SHAPE",COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION,http://arxiv.org/pdf/2012.13582,
12,Stochastic Oblique Impact on Composite Laminates: A Concise Review and Characterization of the Essence of Hybrid Machine Learning Algorithms,28,3,1731-1760,"Mukhopadhyay T.,Naskar S.,Chakraborty S.,Karsh P. K.,Choudhury R.,Dey S.","Mukhopadhyay T,Naskar S,Chakraborty S,Karsh PK,Choudhury R,Dey S",Mukhopadhyay T,10.1007/s11831-020-09438-w,Indian Institute of Technology System (IIT System),"Due to the absence of adequate control at different stages of complex manufacturing process, material and geometric properties of composite structures are often uncertain. For a secure and safe design, tracking the impact of these uncertainties on the structural responses is of utmost significance. Composite materials, commonly adopted in various modern aerospace, marine, automobile and civil structures, are often susceptible to low-velocity impact caused by various external agents. Here, along with a critical review, we present machine learning based probabilistic and non-probabilistic (fuzzy) low-velocity impact analyses of composite laminates including a detailed deterministic characterization to systematically investigate the consequences of source- uncertainty. While probabilistic analysis can be performed only when complete statistical description about the input variables are available, the non-probabilistic analysis can be executed even in the presence of incomplete statistical input descriptions with sparse data. In this study, the stochastic effects of stacking sequence, twist angle, oblique impact, plate thickness, velocity of impactor and density of impactor are investigated on the crucial impact response parameters such as contact force, plate displacement, and impactor displacement. For efficient and accurate computation, a hybrid polynomial chaos based Kriging (PC-Kriging) approach is coupled with in-house finite element codes for uncertainty propagation in both the probabilistic and non- probabilistic analyses. The essence of this paper is a critical review on the hybrid machine learning algorithms followed by detailed numerical investigation in the probabilistic and non-probabilistic regimes to access the performance of such hybrid algorithms in comparison to individual algorithms from the viewpoint of accuracy and computational efficiency.","LOW-VELOCITY IMPACT,DIMENSIONAL MODEL REPRESENTATION,GAUSSIAN PROCESS REGRESSION,NATURAL FREQUENCY-ANALYSIS,FREE-VIBRATION ANALYSIS,POLYNOMIAL-CHAOS,UNCERTAINTY QUANTIFICATION,PROBABILISTIC ANALYSIS,SENSITIVITY-ANALYSIS,SURROGATE MODELS",Review,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering,Mathematics",,8.169,"LOW-VELOCITY,IMPACT,DIMENSIONAL,MODEL,REPRESENTATION,GAUSSIAN,PROCESS,REGRESSION,NATURAL,FREQUENCY-ANALYSIS,FREE-VIBRATION,ANALYSIS,POLYNOMIAL-CHAOS,UNCERTAINTY,QUANTIFICATION,PROBABILISTIC,ANALYSIS,SENSITIVITY-ANALYSIS,SURROGATE,MODELS",ARCHIVES OF COMPUTATIONAL METHODS IN ENGINEERING,https://eprints.soton.ac.uk/452051/1/11831_2020_9438_OnlinePDF_final.pdf,
13,Type2 diabetes mellitus prediction using data mining algorithms based on the long-noncoding RNAs expression: a comparison of four data mining approaches,21,1,,"Kazerouni Faranak,Bayani Azadeh,Asadi Farkhondeh,Saeidi Leyla,Parvizi Nasrin,Mansoori Zahra","Kazerouni F,Bayani A,Asadi F,Saeidi L,Parvizi N,Mansoori Z",Asadi F,10.1186/s12859-020-03719-8,Shahid Beheshti University Medical Sciences,"Background About 90% of patients who have diabetes suffer from Type 2 DM (T2DM). Many studies suggest using the significant role of lncRNAs to improve the diagnosis of T2DM. Machine learning and Data Mining techniques are tools that can improve the analysis and interpretation or extraction of knowledge from the data. These techniques may enhance the prognosis and diagnosis associated with reducing diseases such as T2DM. We applied four classification models, including K-nearest neighbor (KNN), support vector machine (SVM), logistic regression, and artificial neural networks (ANN) for diagnosing T2DM, and we compared the diagnostic power of these algorithms with each other. We performed the algorithms on six LncRNA variables (LINC00523, LINC00995, HCG27_201, TPT1-AS1, LY86-AS1, DKFZP) and demographic data. Results To select the best performance, we considered the AUC, sensitivity, specificity, plotted the ROC curve, and showed the average curve and range. The mean AUC for the KNN algorithm was 91% with 0.09 standard deviation (SD); the mean sensitivity and specificity were 96 and 85%, respectively. After applying the SVM algorithm, the mean AUC obtained 95% after stratified 10-fold cross-validation, and the SD obtained 0.05. The mean sensitivity and specificity were 95 and 86%, respectively. The mean AUC for ANN and the SD were 93% and 0.03, also the mean sensitivity and specificity were 78 and 85%. At last, for the logistic regression algorithm, our results showed 95% of mean AUC, and the SD of 0.05, the mean sensitivity and specificity were 92 and 85%, respectively. According to the ROCs, the Logistic Regression and SVM had a better area under the curve compared to the others. Conclusion We aimed to find the best data mining approach for the prediction of T2DM using six lncRNA expression. According to the finding, the maximum AUC dedicated to SVM and logistic regression, among others, KNN and ANN also had the high mean AUC and small standard deviations of AUC scores among the approaches, KNN had the highest mean sensitivity and the highest specificity belonged to SVM. This study's result could improve our knowledge about the early detection and diagnosis of T2DM using the lncRNAs as biomarkers.","Data mining,Gene expression,Type 2 diabetes mellitus",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,"CLASSIFICATION,DIAGNOSIS",BMC BIOINFORMATICS,https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-020-03719-8,
14,Is Domain Knowledge Necessary for Machine Learning Materials Properties?,9,3,221-227,"Murdock Ryan J.,Kauwe Steven K.,Wang Anthony Yu-Tung,Sparks Taylor D.","Murdock RJ,Kauwe SK,Wang AYT,Sparks TD",Sparks TD,10.1007/s40192-020-00179-z,Utah System of Higher Education,"New featurization schemes for describing materials as composition vectors in order to predict their properties using machine learning are common in the field of Materials Informatics. However, little is known about the comparative efficacy of these methods. This work sets out to make clear which featurization methods should be used across various circumstances. Our findings include, surprisingly, that simple fractional and random-noise representations of elements can be as effective as traditional and new descriptors when using large amounts of data. However, in the absence of large datasets or for data that is not fully representative, we show that the integration of domain knowledge offers advantages in predictive ability.
[GRAPHICS]
.","Materials informatics,Machine learning,Featurization,Descriptors,Neural networks",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Materials Science",,4.423,,INTEGRATING MATERIALS AND MANUFACTURING INNOVATION,https://doi.org/10.26434/chemrxiv.11879193.v1,
15,,,,,,,,,,,,,,,,,,,,
16,DNetUnet: a semi-supervised CNN of medical image segmentation for super-computing AI service,77,4,3594-3615,"Tseng Kuo-Kun,Zhang Ran,Chen Chien-Ming,Hassan Mohammad Mehedi","Tseng KK,Zhang R,Chen CM,Hassan MM",Hassan MM,10.1007/s11227-020-03407-7,King Saud University,"Deep learning approaches have achieved good performance in segmenting medical images. In this paper, we propose a new convolutional neural network architecture named DNetUnet, which combines U-Nets with different down-sampling levels and a new dense block as feature extractor. In addition, DNetUnet is a semi-supervised learning method, which can be used not only to obtain expert knowledge from the labelled corpus, but also to enhance the performance of learning algorithm generalization ability from unlabelled data. Further, we integrate distillation technique to improve the performance on mobile platform. The experimental results demonstrate that the proposed segmentation model yields superior performance over competition. Since the processing of large medical images and distillation technology is enforced, a supercomputing AI training server is a preference for its application.","Medical image segmentation,Semi-supervised deep learning,U-Net,Distillation",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.344,,JOURNAL OF SUPERCOMPUTING,,
17,Features and trends of personalised learning: a review of journal publications from 2001 to 2018,29,2,182-195,"Li Kam Cheong,Wong Billy Tak-Ming","Li KC,Wong BTM",Wong BTM,10.1080/10494820.2020.1811735,Hong Kong Metropolitan University,"This paper provides a comprehensive review of the features and trends of personalised learning. The review covers a total of 203 journal articles collected from Scopus, which were published from 2001 to 2018 and involved personalised learning practices. Comparing the practices between 2001-2009 and 2010-2018, there was a clear trend that they became more diversified in terms of the educational levels and modes of education, as well as the means to achieve personalised learning, their objectives and the devices used. In most practices, the use of technology was clearly emphasised, such as various intelligent learning/tutoring systems, mobile devices, learning analytics, and augmented/virtual reality applications. Learning methods, materials and the time and places for learning were the aspects most frequently addressed. The objectives of the practices focused mainly on increasing learning effectiveness, followed by enhancing learners' motivation, engagement and satisfaction. The factors leading to successful personalised learning were identified from the articles reviewed, among which most factors were related to learners' characteristics, learning progress and technology. Research issues which need further investigation are recommended, particularly on the challenges arising from the adoption of emerging technologies, and the changing role of teachers in the trend towards student-centred personalised learning.","Personalised learning,differentiated learning,technology-assisted learning,student-centred learning",Review,"ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND",Education & Educational Research,,3.868,CLASSROOM,INTERACTIVE LEARNING ENVIRONMENTS,,
18,Harnessing a multi-dimensional fibre laser using genetic wavefront shaping,9,1,,"Wei Xiaoming,Jing Joseph C.,Shen Yuecheng,Wang Lihong V","Wei XM,Jing JC,Shen YC,Wang LHV",Wang LHV,10.1038/s41377-020-00383-8,California Institute of Technology,"Intelligent 3D lasers: Bio-inspired algorithms help tame multimode fiber lasers Multimode fibres that contain numerous groups of lightwaves, or modes, can now assist lasers in producing tunable emission characteristics. Lihong Wang from the California Institute of Technology in Pasadena, United States, and colleagues have developed a technique to control the complex interactions inside a multimode fibre laser using machine learning. The team created a feedback loop where portions of laser signals travelling through a multimode fibre are sent to a spatial light modulator that adjusts the phases of propagating waves. By using genetic algorithms to direct the spatial light modulator, this setup can optimize parameters such as output power after a few minutes of evolutionary feedback-changing, for instance, an initial speckle-shaped light pattern into a single focused spot. Other tunable laser features including wavelength scanning and pulse control were demonstrated with this approach.
The multi-dimensional laser is a fascinating platform not only for the discovery and understanding of new higher-dimensional coherent lightwaves but also for the frontier study of the complex three-dimensional (3D) nonlinear dynamics and solitary waves widely involved in physics, chemistry, biology and materials science. Systemically controlling coherent lightwave oscillation in multi-dimensional lasers, however, is challenging and has largely been unexplored; yet, it is crucial for both designing 3D coherent light fields and unveiling any underlying nonlinear complexities. Here, for the first time, we genetically harness a multi-dimensional fibre laser using intracavity wavefront shaping technology such that versatile lasing characteristics can be manipulated. We demonstrate that the output power, mode profile, optical spectrum and mode-locking operation can be genetically optimized by appropriately designing the objective function of the genetic algorithm. It is anticipated that this genetic and systematic intracavity control technology for multi-dimensional lasers will be an important step for obtaining high-performance 3D lasing and presents many possibilities for exploring multi-dimensional nonlinear dynamics and solitary waves that may enable new applications.","MODE-LOCKING,ENERGY QUANTIZATION,LIGHT,STATES",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Optics,,16.996,"MODE-LOCKING,ENERGY,QUANTIZATION,LIGHT,STATES",LIGHT-SCIENCE & APPLICATIONS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7450085,
19,Co-eye: a multi-resolution ensemble classifier for symbolically approximated time series,109,11,2029-2061,"Abdallah Zahraa S.,Gaber Mohamed Medhat","Abdallah ZS,Gaber MM",Abdallah ZS,10.1007/s10994-020-05887-3,Birmingham City University,"Time series classification (TSC) is a challenging task that attracted many researchers in the last few years. One main challenge in TSC is the diversity of domains where time series data come from. Thus, there is no ""one model that fits all"" in TSC. Some algorithms are very accurate in classifying a specific type of time series when the whole series is considered, while some only target the existence/non-existence of specific patterns/shapelets. Yet other techniques focus on the frequency of occurrences of discriminating patterns/features. This paper presents a new classification technique that addresses the inherent diversity problem in TSC using a nature-inspired method. The technique is stimulated by how flies look at the world through ""compound eyes"" that are made up of thousands of lenses, called ommatidia. Each ommatidium is an eye with its own lens, and thousands of them together create a broad field of vision. The developed technique similarly uses different lenses and representations to look at the time series, and then combines them for broader visibility. These lenses have been created through hyper-parameterisation of symbolic representations (Piecewise Aggregate and Fourier approximations). The algorithm builds a random forest for each lens, then performs soft dynamic voting for classifying new instances using the most confident eyes, i.e., forests. We evaluate the new technique, coined Co-eye, using the recently released extended version of UCR archive, containing more than 100 datasets across a wide range of domains. The results show the benefits of bringing together different perspectives reflecting on the accuracy and robustness of Co-eye in comparison to other state-of-the-art techniques.","Time series classification,Symbolic representation,Ensemble classification,Random Forest",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,3.693,"SIMILARITY,SEARCH,FOREST",MACHINE LEARNING,https://research-information.bris.ac.uk/ws/files/250271622/Abdallah_Gaber2020_Article_Co_eyeAMulti_resolutionEnsembl.pdf,
20,Combining Superionic Conduction and Favorable Decomposition Products in the Crystalline Lithium-Boron-Sulfur System: A New Mechanism for Stabilizing Solid Li-Ion Electrolytes,12,34,37957-37966,"Sendek Austin D.,Antoniuk Evan R.,Cubuk Ekin D.,Ransom Brandi,Francisco Brian E.,Buettner-Garrett Josh,Cui Yi,Reed Evan J.","Sendek AD,Antoniuk ER,Cubuk ED,Ransom B,Francisco BE,Buettner-Garrett J,Cui Y,Reed EJ",Reed EJ,10.1021/acsami.9b19091,Stanford University,"We report a solid-state Li-ion electrolyte predicted to exhibit simultaneously fast ionic conductivity, wide electrochemical stability, low cost, and low mass density. We report exceptional density functional theory (DFT)-based room-temperature single-crystal ionic conductivity values for two phases within the crystalline lithium-boron-sulfur (Li-B-S) system: 62 (+9, -2) mS cm(-1) in Li5B7S13 and 80 (-56, -41) mS cm(-1) in Li9B19S33. We report significant ionic conductivity values for two additional phases: between 0.0056 and 0.16 mS/cm(-1) in Li2B2S5 and between 0.0031 and 9.7 mS cm(-1) in Li3BS3 depending on the room-temperature extrapolation scheme used. To our knowledge, our prediction gives Li9B19S33 and Li5B7S13 the second and third highest reported DFT-computed single-crystal ionic conductivities of any crystalline material. We compute the thermodynamic electrochemical stability window widths of these materials to be 0.50 V for Li5B7S13, 0.16 V for Li2B2S5, 0.45 V for Li3BS3, and 0.60 V for Li9B19S33. Individually, these materials exhibit similar or better ionic conductivity and electrochemical stability than the best-known sulfide-based solid-state Li-ion electrolyte materials, including Li10GeP2S12 (LGPS). However, we predict that electrolyte materials synthesized from a range of compositions in the Li-B-S system may exhibit even wider thermodynamic electrochemical stability windows of 0.63 V and possibly as high as 3 V or greater. The Li-B-S system also has a low elemental cost of approximately 0.05 USD/m(2) per 10 mu m thickness, which is significantly lower than that of germanium-containing LGPS, and a comparable mass density below 2 g/cm(3). These fast-conducting phases were initially brought to our attention by a machine learning-based approach to screen over 12,000 solid electrolyte candidates, and the evidence provided here represents an inspiring success for this model.","solid ion conductor,solid electrolyte,Li-ion battery,density functional theory,ion transport,electrochemical stability,kinetics",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science",,9.57,"STATE,BATTERIES,PHASE-STABILITY,DENSITY,DYNAMICS,CATHODES,GLASSES,NMR,MN,FE",ACS APPLIED MATERIALS & INTERFACES,,
21,Big-Data Science in Porous Materials: Materials Genomics and Machine Learning,120,16,8066-8129,"Jablonka Kevin Maik,Ongari Daniele,Moosavi Seyed Mohamad,Smit Berend","Jablonka KM,Ongari D,Moosavi SM,Smit B",Smit B,10.1021/acs.chemrev.0c00004,Ecole Polytechnique Federale de Lausanne,"By combining metal nodes with organic linkers we can potentially synthesize millions of possible metal-organic frameworks (MOFs). The fact that we have so many materials opens many exciting avenues but also create new challenges. We simply have too many materials to be processed using conventional, brute force, methods. In this review, we show that having so many materials allows us to use big-data methods as a powerful technique to study these materials and to discover complex correlations. The first part of the review gives an introduction to the principles of big-data science. 'We show how to select appropriate training sets, survey approaches that are used to represent these materials in feature space, and review different learning architectures, as well as evaluation and interpretation strategies. In the second part, we review how the different approaches of machine learning have been applied to porous materials. In particular, we discuss applications in the field of gas storage and separation, the stability of these materials, their electronic properties, and their synthesis. Given the increasing interest of the scientific community in machine learning, we expect this list to rapidly expand in the coming years.","METAL-ORGANIC FRAMEWORKS,ARTIFICIAL NEURAL-NETWORKS,STRUCTURE-PROPERTY RELATIONSHIPS,PARTICLE SWARM OPTIMIZATION,CARBON-DIOXIDE CAPTURE,DRIVEN HEAT-PUMPS,HIGH-THROUGHPUT,METHANE STORAGE,FEATURE-SELECTION,ZEOLITE FRAMEWORKS",Review,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,66.813,"METAL-ORGANIC,FRAMEWORKS,ARTIFICIAL,NEURAL-NETWORKS,STRUCTURE-PROPERTY,RELATIONSHIPS,PARTICLE,SWARM,OPTIMIZATION,CARBON-DIOXIDE,CAPTURE,DRIVEN,HEAT-PUMPS,HIGH-THROUGHPUT,METHANE,STORAGE,FEATURE-SELECTION,ZEOLITE,FRAMEWORKS",CHEMICAL REVIEWS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7453404,
22,Artificial intelligence-driven novel tool for tooth detection and segmentation on panoramic radiographs,25,4,2257-2267,"Leite Andre Ferreira,Van Gerven Adriaan,Willems Holger,Beznik Thomas,Lahoud Pierre,Gaeta-Araujo Hugo,Vranckx Myrthel,Jacobs Reinhilde","Leite AF,Van Gerven A,Willems H,Beznik T,Lahoud P,Gaeta-Araujo H,Vranckx M,Jacobs R",Leite AF,10.1007/s00784-020-03544-6,KU Leuven,"Objective To evaluate the performance of a new artificial intelligence (AI)-driven tool for tooth detection and segmentation on panoramic radiographs. Materials and methods In total, 153 radiographs were collected. A dentomaxillofacial radiologist labeled and segmented each tooth, serving as the ground truth. Class-agnostic crops with one tooth resulted in 3576 training teeth. The AI-driven tool combined two deep convolutional neural networks with expert refinement. Accuracy of the system to detect and segment teeth was the primary outcome, time analysis secondary. The Kruskal-Wallis test was used to evaluate differences of performance metrics among teeth groups and different devices and chi-square test to verify associations among the amount of corrections, presence of false positive and false negative, and crown and root parts of teeth with potential AI misinterpretations. Results The system achieved a sensitivity of 98.9% and a precision of 99.6% for tooth detection. For segmenting teeth, lower canines presented best results with the following values for intersection over union, precision, recall, F1-score, and Hausdorff distances: 95.3%, 96.9%, 98.3%, 97.5%, and 7.9, respectively. Although still above 90%, segmentation results for both upper and lower molars were somewhat lower. The method showed a clinically significant reduction of 67% of the time consumed for the manual. Conclusions The AI tool yielded a highly accurate and fast performance for detecting and segmenting teeth, faster than the ground truth alone. Clinical significance An innovative clinical AI-driven tool showed a faster and more accurate performance to detect and segment teeth on panoramic radiographs compared with manual segmentation.","Artificial intelligence,Machine learning,Panoramic radiography,Tooth,Classification",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Dentistry, Oral Surgery & Medicine",,3.623,"CONVOLUTIONAL,NEURAL-NETWORK,TEETH",CLINICAL ORAL INVESTIGATIONS,,
23,Machine learning as an improved estimator for magnetization curve and spin gap,10,1,,Nakamura Tota,Nakamura T,Nakamura T,10.1038/s41598-020-70389-0,Shibaura Institute of Technology,"The magnetization process is a very important probe to study magnetic materials, particularly in search of spin-liquid states in quantum spin systems. Regrettably, however, progress of the theoretical analysis has been unsatisfactory, mostly because it is hard to obtain sufficient numerical data to support the theory. Here we propose a machine-learning algorithm that produces the magnetization curve and the spin gap well out of poor numerical data. The plateau magnetization, its critical field and the critical exponent are estimated accurately. One of the hyperparameters identifies by its score whether the spin gap in the thermodynamic limit is zero or finite. After checking the validity for exactly solvable one-dimensional models we apply our algorithm to the kagome antiferromagnet. The magnetization curve that we obtain from the exact-diagonalization data with 36 spins is consistent with the DMRG results with 132 spins. We estimate the spin gap in the thermodynamic limit at a very small but finite value.","LIQUID GROUND-STATE,HEISENBERG-ANTIFERROMAGNET,PLATEAUS,MODEL,LATTICE,CHAIN",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,5.134,"LIQUID,GROUND-STATE,HEISENBERG-ANTIFERROMAGNET,PLATEAUS,MODEL,LATTICE,CHAIN",SCIENTIFIC REPORTS,http://arxiv.org/pdf/1902.02941,
24,Identification and characterization of tweets related to the 2015 Indiana HIV outbreak: A retrospective infoveillance study,15,8,,"Cai Mingxiang,Shah Neal,Li Jiawei,Chen Wen-Hao,Cuomo Raphael E.,Obradovich Nick,Mackey Tim K.","Cai MX,Shah N,Li JW,Chen WH,Cuomo RE,Obradovich N,Mackey TK",Mackey TK,10.1371/journal.pone.0235150,"Global Hlth Policy Inst, San Diego, CA 92103 USA.","Introduction From late 2014 through 2015, Scott County, Indiana faced an HIV outbreak triggered by opioid abuse and transition to injection drug use. Investigating the origins, risk factors, and responses related to this outbreak is critical to inform future surveillance, interventions, and policymaking. In response, this retrospective infoveillance study identifies and characterizes user-generated messages related to opioid abuse, heroin injection drug use, and HIV status using natural language processing (NLP) among Twitter users in Indiana during the period of this HIV outbreak. Materials and methods Our study consisted of two phases: data collection and processing, and data analysis. We collected Indiana geolocated tweets from the public Twitter API using Amazon Web Services EC2 instances filtered for geocoded messages in the immediate pre and post period of the outbreak. In the data analysis phase we applied an unsupervised machine learning approach using NLP called the Biterm Topic Model (BTM) to identify tweets related to opioid, heroin/injection, and HIV behavior and then examined these messages for HIV risk-related topics that could be associated with the outbreak. Results More than 10 million geocoded tweets occurring in Indiana during the immediate pre and post period of the outbreak were collected for analysis. Using BTM, we identified 1350 tweets thought to be relevant to the outbreak and then confirmed 358 tweets using human annotation. The most prevalent themes identified were tweets related to self-reported abuse of illicit and prescription drugs, opioid use disorder, self-reported HIV status, and public sentiment regarding the outbreak. Geospatial analysis found that these messages clustered in population dense areas outside of the outbreak, including Indianapolis and neighboring Clark County. Discussion This infoveillance study characterized the social media conversations of communities in Indiana in the pre and post period of the 2015 HIV outbreak. Behavioral themes detected reflect discussion about risk factors related to HIV transmission stemming from opioid and heroin abuse for priority populations, and also help identify community attitudes that could have motivated or detracted the use of HIV prevention methods, along with helping identify factors that can impede access to prevention services. Conclusions Infoveillance approaches, such as the analysis conducted in this study, represent a possibly strategy to detect ""signal"" of the emergence of risk factors associated with an outbreak though may be limited in their scope and generalizability. Our results, in conjunction with other forms of public health surveillance, can leverage the growing ubiquity of social media platforms to better detect opioid-related HIV risk knowledge, attitudes and behavior, as well as inform future prevention efforts.","INFORMATION,TWITTER,TRENDS",Article,"PUBLIC LIBRARY SCIENCE, 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA",Science & Technology - Other Topics,,,"INFORMATION,TWITTER,TRENDS",PLOS ONE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7449407,
25,Assessment of CFH and HTRA1 polymorphisms in age-related macular degeneration using classic and machine-learning approaches,41,6,539-547,"Martinez-Velasco Antonieta,Perez-Ortiz Andric C.,Antonio-Aguirre Bani,Martinez-Villasenor Lourdes,Lira-Romero Esmeralda,Palacio-Pastrana Claudia,Zenteno Juan Carlos,Ramirez Israel,Zepeda-Palacio Claudia,Mendoza-Velasquez Cristina","Martinez-Velasco A,Perez-Ortiz AC,Antonio-Aguirre B,Martinez-Villasenor L,Lira-Romero E,Palacio-Pastrana C,Zenteno JC,Ramirez I,Zepeda-Palacio C,Mendoza-Velasquez C",Estrada-Mena FJ,10.1080/13816810.2020.1804945,Universidad Panamericana - Ciudad de Mexico,"Background: CFH and HTRA1 are pivotal genes driving increased risk for age-related macular degeneration (AMD) among several populations. Here, we performed a hospital-based case-control study to evaluate the effects of three single nucleotide polymorphisms (SNPs) among Hispanics from Mexico.
Materials and methods: 122 cases and 249 controls were genotyped using Taqman probes. Experienced ophthalmologists diagnosed AMD following the American Association of Ophthalmology guidelines. We studied CFH (rs1329428, rs203687) and HTRA1 (rs11200638) SNPs thoroughly by logistic regression models (assuming different modes of inheritance) and machine learning-based methods (ML).
Results: HTRA1 rs11200638 is the most significant polymorphism associated with AMD in our studied population. In a multivariate regression model adjusted for clinically and statistically meaningful covariates, the A/G and A/A genotypes increased the odds of disease by a factor of 2.32 and 7.81, respectively (P < .05) suggesting a multiplicative effect of the polymorphic A allele. Furthermore, this observation remains statistically meaningful in the allelic, dominant, and recessive models, and ML algorithms. When stratifying by phenotype, this polymorphism was significantly associated with increased odds for geographic atrophy (GA) in a recessive mode of inheritance (12.4, p < .05).
Conclusions: In sum, this work supports a strong association between HTRA1 genetic variants and AMD in Hispanics from Mexico, especially with GA. Moreover, ML was able to replicate the results of conventional biostatistics methods unbiasedly.","Age-related macular degeneration,complement factor H,high-temperature requirement A serine peptidase 1,genetic association study,machine-learning",Article,"TAYLOR & FRANCIS INC, 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA","Genetics & Heredity,Ophthalmology",,,"GENE,POLYMORPHISMS,ASSOCIATION,SUSCEPTIBILITY,PREVALENCE,VARIANT,HAPLOTYPES",OPHTHALMIC GENETICS,,
26,Interactive-quantum-chemical-descriptors enabling accurate prediction of an activation energy through machine learning,203,,,Mikami Koichiro,Mikami K,Mikami K,10.1016/j.polymer.2020.122738,"Sagami Chem Res Inst, 2743-1 Hayakawa, Ayase, Kanagawa 2521193, Japan.","Artificial intelligence- and machine learning (ML)-assisted reaction/material development are an emerging research area in organic, organometallic, polymer chemistry and materials science. Quantum chemical descriptors (QCDs) that are classically constructed with steric/electrostatic parameters make the process of the prediction through ML easily understood and allow us to find new chemical pictures for reaction, materials and functionality. Herein, I present the development of novel QCDs-interactive-quantum-chemical-descriptors (IQCDs)-well-expressing an intermolecular interaction among target molecules. The use of IQCDs drastically improved the prediction-accuracy rather than the use of only the classical QCD. One of the IQCDs consists of natural energy decomposition analysis (NEDA), well-expressing a chemical interaction among the molecules/materials, which would be applicable for dynamic processes including formation of chemical bonding, organometallic complex, and supramolecular complex.","Machine-learning,DFT calculation,Metallocene,Mechanism,Descriptor",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Polymer Science,,4.186,"DECOMPOSITION,ANALYSIS,POLYMERIZATION,LIGANDS,ETHYLENE,METAL,QSAR",POLYMER,,
27,Machine Learning to Reveal Nanoparticle Dynamics from Liquid-Phase TEM Videos,6,8,1421-1430,"Yao Lehan,Ou Zihao,Luo Binbin,Xu Cong,Chen Qian","Yao LH,Ou ZH,Luo BB,Xu C,Chen Q",Chen Q,10.1021/acscentsci.0c00430,University of Illinois System,"Liquid-phase transmission electron microscopy (TEM) has been recently applied to materials chemistry to gain fundamental understanding of various reaction and phase transition dynamics at nanometer resolution. However, quantitative extraction of physical and chemical parameters from the liquid-phase TEM videos remains bottlenecked by the lack of automated analysis methods compatible with the videos' high noisiness and spatial heterogeneity. Here, we integrate, for the first time, liquid-phase TEM imaging with our customized analysis framework based on a machine learning model called U-Net neural network. This combination is made possible by our workflow to generate simulated TEM images as the training data with well-defined ground truth. We apply this framework to three typical systems of colloidal nanoparticles, concerning their diffusion and interaction, reaction kinetics, and assembly dynamics, all resolved in real-time and real-space by liquid-phase TEM. A diversity of properties for differently shaped anisotropic nanoparticles are mapped, including the anisotropic interaction landscape of nanoprisms, curvature-dependent and staged etching profiles of nanorods, and an unexpected kinetic law of first-order chaining assembly of concave nanocubes. These systems representing properties at the nanoscale are otherwise experimentally inaccessible. Compared to the prevalent image segmentation methods, U-Net shows a superior capability to predict the position and shape boundary of nanoparticles from highly noisy and fluctuating background-a challenge common and sometimes inevitable in liquid-phase TEM videos. We expect our framework to push the potency of liquid-phase TEM to its full quantitative level and to shed insights, in high-throughput and statistically significant fashion, on the nanoscale dynamics of synthetic and biological nanomaterials.","IN-SITU,GOLD NANOPARTICLES,GROWTH,NUCLEATION,NANOCRYSTALS,MECHANISMS,DISTANCE,BEHAVIOR,MOTION",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,15.435,"IN-SITU,GOLD,NANOPARTICLES,GROWTH,NUCLEATION,NANOCRYSTALS,MECHANISMS,DISTANCE,BEHAVIOR,MOTION",ACS CENTRAL SCIENCE,https://pubs.acs.org/doi/pdf/10.1021/acscentsci.0c00430,
28,Machine-learned metrics for predicting the likelihood of success in materials discovery,6,1,,"Kim Yoolhee,Kim Edward,Antono Erin,Meredig Bryce,Ling Julia","Kim Y,Kim E,Antono E,Meredig B,Ling JL",Kim Y,10.1038/s41524-020-00401-8,"Citrine Informat, Redwood City, CA 94063 USA.","Materials discovery is often compared to the challenge of finding a needle in a haystack. While much work has focused on accurately predicting the properties of candidate materials with machine learning (ML), which amounts to evaluating whether a given candidate is a piece of straw or a needle, less attention has been paid to a critical question: are we searching in the right haystack? We refer to the haystack as the design space for a particular materials discovery problem (i.e., the set of possible candidate materials to synthesize), and thus frame this question as one of design space selection. In this paper, we introduce two metrics, the predicted fraction of improved candidates (PFIC), and the cumulative maximum likelihood of improvement (CMLI), which we demonstrate can identify discovery-rich and discovery-poor design spaces, respectively. A combined classification system, composed of the CMLI and PFIC metrics, is then used to identify optimal design spaces with high precision, and thus show the potential to significantly accelerate ML-driven materials discovery.",DESIGN,Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Chemistry,Materials Science",,13.993,DESIGN,NPJ COMPUTATIONAL MATERIALS,http://arxiv.org/pdf/1911.11201,
29,Evaluation of navigation methodologies for mobile robots,137,6,316-323,"Woeber Wilfried,Rauer Johannes,Papa Maximilian,Aburaia Ali,Schwaiger Simon,Novotny Georg,Aburaia Mohamed,Kubinger Wilfried","Wober W,Rauer J,Papa M,Aburaia A,Schwaiger S,Novotny G,Aburaia M,Kubinger W",Wober W,10.1007/s00502-020-00820-x,"Fachhsch Technikum Wien, Hochstadtpl 6, A-1200 Vienna, Austria.","Intelligent mobile robots and service robots are central parts of autonomous productions and flexible manufacturing. Interconnected industrial robot-based automation allows customized productions for which mobile robots are used for transport of material and tools. The digital factory of the UAS Technikum Wien is a research project which focuses on experimental evaluation of novel technologies for digital manufacturing. This paper discusses applications of mobile and service robots in the digital factory. Based on a production use case, we analyze several methods for navigation in terms of accuracy of those approaches and discuss safety aspects.","mobile robotics,navigation,probabilistic robotics,machine learning,Industry 4,0",Article,"SPRINGER WIEN, SACHSENPLATZ 4-6, PO BOX 89, A-1201 WIEN, AUSTRIA",Engineering,,,,ELEKTROTECHNIK UND INFORMATIONSTECHNIK,,
30,Machine learning topological phases in real space,102,5,,"Holanda N. L.,Griffith M. A. R.","Holanda NL,Griffith MAR",Holanda NL,10.1103/PhysRevB.102.054107,University of Cambridge,"We develop a supervised machine learning algorithm that is able to learn topological phases of finite condensed-matter systems from bulk data in real lattice space. The algorithm employs diagonalization in real space together with any supervised learning algorithm to learn topological phases through an eigenvector ensembling procedure. We combine our algorithm with decision trees and random forests to successfully recover topological phase diagrams of Su-Schrieffer-Heeger (SSH) models from bulk lattice data in real space and show how the Shannon information entropy of ensembles of lattice eigenvectors can be used to retrieve a signal detailing how topological information is distributed in the bulk. We further use insights obtained from these information entropy signatures to engineer global topological features from real-space lattice data that still carry most of the topological information in the lattice, while greatly diminishing the size of feature space, thus effectively amounting to a topological lattice compression. Finally, we explore the theoretical possibility of interpreting the information entropy topological signatures in terms of emergent information entropy wave functions, which lead us to Heisenberg and Hirschman uncertainty relations for topological phase transitions. The discovery of Shannon information entropy signals associated with topological phase transitions from the analysis of data from several thousand SSH systems illustrates how model explainability in machine learning can advance the research of exotic quantum materials with properties that may power future technological applications such as qubit engineering for quantum computing.","EDGE STATES,TRANSITIONS,SOLITONS",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,"EDGE,STATES,TRANSITIONS,SOLITONS",PHYSICAL REVIEW B,http://arxiv.org/pdf/1901.01963,
31,Dynamic Deep Networks for Retinal Vessel Segmentation,2,,,"Khanal Aashis,Estrada Rolando","Khanal A,Estrada R",Estrada R,10.3389/fcomp.2020.00035,University System of Georgia,"Deep learning has recently yielded impressive gains in retinal vessel segmentation. However, state-of-the-art methods tend to be conservative, favoring precision over recall. Thus, they tend to under-segment faint vessels, underestimate the width of thicker vessels, or even miss entire vessels. To address this limitation, we propose a stochastic training scheme for deep neural networks that robustly balances precision and recall. First, we train our deep networks with dynamic class weights in the loss function that fluctuate during each training iteration. This stochastic approach-which we believe is applicable to many other machine learning problems-forces the network to learn a balanced classification. Second, we decouple the segmentation process into two steps. In the first half of our pipeline, we estimate the likelihood of every pixel and then use these likelihoods to segment pixels that are clearly vessel or background. In the latter part of our pipeline, we use a second network to classify the ambiguous regions in the image. Our proposed method obtained state-of-the-art results on five retinal datasets-DRIVE, STARE, CHASE-DB, AV-WIDE, and VEVIO-by learning a robust balance between false positive and false negative rates. Our novel training paradigm makes a neural network more robust to inter-sample differences in class ratios, which we believe will prove particularly effective for settings with sparse training data, such as medical image analysis. In addition, we are the first to report segmentation results on the AV-WIDE dataset, and we have made the ground-truth annotations for this dataset publicly available. An implementation of this work can be found at .</p>","retinal vessel segmentation,deep learning,stochastic optimization,dynamic optimization,image analysis",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Computer Science,,,"BLOOD-VESSELS,IMAGES,CLASSIFICATION",FRONTIERS IN COMPUTER SCIENCE,https://www.frontiersin.org/articles/10.3389/fcomp.2020.00035/pdf,
32,Frustration effects at finite temperature in the half filled Hubbard model,32,36,,"Jana Gour,Mukherjee Anamitra","Jana G,Mukherjee A",Jana G,10.1088/1361-648X/ab9058,Homi Bhabha National Institute,"We investigate the finite temperature properties of the half filled Hubbard model in two dimensions, with onsite interaction (U), in presence of (frustrating) next nearest neighbor hopping (t ') using a semiclassical approximation scheme. We show that introduction oft ' results in a finite temperature pseudogapped (PG) phase that separates the smallUFermi liquid and largeUMott insulator. We map out the PG to normal metal crossover temperature scale (T*) as a function ofUandt '. We demonstrate that in the PG phase, the quadratic dependence of resistivity on temperature is violated due to thermally induced spin fluctuations. We conclude with exact diagonalization calculations, that complement our finite temperature results, and indicate the presence of a frustration driven PG state between the Fermi liquid and the Mott insulator at zero temperature as well.","strongly correlated system,magnetism,metal insulator transitions",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,2.887,"DIMENSIONAL,FERMI-SURFACE,INSTABILITY,TRANSITION,PHASE,METAL",JOURNAL OF PHYSICS-CONDENSED MATTER,http://arxiv.org/pdf/1902.04241,
33,21st-century biogeochemical modeling: Challenges for Century-based models and where do we go from here?,12,10,774-788,"Berardi Danielle,Brzostek Edward,Blanc-Betes Elena,Davison Brian,DeLucia Evan H.,Hartman Melannie D.,Kent Jeffrey,Parton William J.,Saha Debasish,Hudiburg Tara W.","Berardi D,Brzostek E,Blanc-Betes E,Davison B,DeLucia EH,Hartman MD,Kent J,Parton WJ,Saha D,Hudiburg TW",Hudiburg TW,10.1111/gcbb.12730,University of Idaho,"21st-century modeling of greenhouse gas (GHG) emissions from bioenergy crops is necessary to quantify the extent to which bioenergy production can mitigate climate change. For over 30 years, the Century-based biogeochemical models have provided the preeminent framework for belowground carbon and nitrogen cycling in ecosystem and earth system models. While monthly Century and the daily time-step version of Century (DayCent) have advanced our ability to predict the sustainability of bioenergy crop production, new advances in feedstock generation, and our empirical understanding of sources and sinks of GHGs in soils call for a re-visitation of DayCent's core model structures. Here, we evaluate current challenges with modeling soil carbon dynamics, trace gas fluxes, and drought and age-related impacts on bioenergy crop productivity. We propose coupling a microbial process-based soil organic carbon and nitrogen model with DayCent to improve soil carbon dynamics. We describe recent improvements to DayCent for simulating unique plant structural and physiological attributes of perennial bioenergy grasses. Finally, we propose a method for using machine learning to identify key parameters for simulating N2O emissions. Our efforts are focused on meeting the needs for modeling bioenergy crops; however, many updates reviewed and suggested to DayCent will be broadly applicable to other systems.","bioenergy,biogeochemical modeling,drought,N2O,plant age dynamics,soil",Review,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Agriculture,Biotechnology & Applied Microbiology,Energy & Fuels",,5.672,"SOIL,ORGANIC-MATTER,NITROUS-OXIDE,EMISSIONS,MISCANTHUS,X,GIGANTEUS,GREENHOUSE-GAS,FLUX,N2O,EMISSIONS,USE,EFFICIENCY,LAND-SURFACE,CARBON,DAYCENT,TERRESTRIAL",GLOBAL CHANGE BIOLOGY BIOENERGY,https://www.osti.gov/biblio/1643707,
34,Deep Learning Algorithm for Brain-Computer Interface,2020,,,"Mansoor Asif,Usman Muhammad Waleed,Jamil Noreen,Naeem M. Asif","Mansoor A,Usman MW,Jamil N,Naeem MA",Jamil N,10.1155/2020/5762149,"Natl Univ Comp & Emerging Sci, Islamabad, Pakistan.","Electroencephalography-(EEG-) based control is a noninvasive technique which employs brain signals to control electrical devices/circuits. Currently, the brain-computer interface (BCI) systems provide two types of signals, raw signals and logic state signals. The latter signals are used to turn on/off the devices. In this paper, the capabilities of BCI systems are explored, and a survey is conducted how to extend and enhance the reliability and accuracy of the BCI systems. A structured overview was provided which consists of the data acquisition, feature extraction, and classification algorithm methods used by different researchers in the past few years. Some classification algorithms for EEG-based BCI systems are adaptive classifiers, tensor classifiers, transfer learning approach, and deep learning, as well as some miscellaneous techniques. Based on our assessment, we generally concluded that, through adaptive classifiers, accurate results are acquired as compared to the static classification techniques. Deep learning techniques were developed to achieve the desired objectives and their real-time implementation as compared to other algorithms.","MOTOR IMAGERY,CLASSIFICATION",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Computer Science,,1.269,"MOTOR,IMAGERY,CLASSIFICATION",SCIENTIFIC PROGRAMMING,https://downloads.hindawi.com/journals/sp/2020/5762149.pdf,
35,Shear Strength of Internal Reinforced Concrete Beam-Column Joints: Intelligent Modeling Approach and Sensitivity Analysis,2020,,,"Feng De-Cheng,Fu Bo","Feng DC,Fu B",Fu B,10.1155/2020/8850417,Chang'an University,"In this paper, an intelligent modeling approach is presented to predict the shear strength of the internal reinforced concrete (RC) beam-column joints and used to analyze the sensitivity of the influence factors on the shear strength. The proposed approach is established based on the famous boosting-family ensemble machine learning (ML) algorithms, i.e., gradient boosting regression tree (GBRT), which generates a strong predictive model by integrating several weak predictors, which are obtained by the well-known individual ML algorithms, e.g., DT, ANN, and SVM. The strong model is boosted as each weak predictor has its own weight in the final combination according to the performance. Compared with the conventional mechanical-driven shear strength models, e.g., the well-known modified compression field theory (MCFT), the proposed model can avoid the complicated derivation process of shear mechanism and calibration of the involved empirical parameters; thus, it provides a more convenient, fast, and robust alternative way for predicting the shear strength of the internal RC joints. To train and test the GBRT model, a total of 86 internal RC joint specimens are collected from the literatures, and four traditional ML models and the MCFT model are also employed as comparisons. The results indicate that the GBRT model is superior to both the traditional ML models and MCFT model, as its degree-of-fitting is the highest and the predicting dispersion is the lowest. Finally, the model is used to investigate the influences of different parameters on the shear strength of the internal RC joint, and the sensitivity and importance of the corresponding parameters are obtained.","PREDICTION,DESIGN",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Construction & Building Technology,Engineering",,1.923,"PREDICTION,DESIGN",ADVANCES IN CIVIL ENGINEERING,https://downloads.hindawi.com/journals/ace/2020/8850417.pdf,
36,A New Distributed Type-2 Fuzzy Logic Method for Efficient Data Science Models of Medical Informatics,2020,,,"Benchara Fatema Zahra,Youssfi Mohamed","Benchara FZ,Youssfi M",Benchara FZ,10.1155/2020/6539123,Hassan II University of Casablanca,"The paper aims to propose a distributed method for machine learning models and its application for medical data analysis. The great challenge in the medicine field is to provide a scalable image processing model, which integrates the computing processing requirements and computing-aided medical decision making. The proposed Fuzzy logic method is based on a distributed approach of type-2 Fuzzy logic algorithm and merges the HPC (High Performance Computing) and cognitive aspect on one model. Accordingly, the method is assigned to be implemented on big data analysis and data science prediction models for healthcare applications. The paper focuses on the proposed distributed Type-2 Fuzzy Logic (DT2FL) method and its application for MRI data analysis under a massively parallel and distributed virtual mobile agent architecture. Indeed, the paper presents some experimental results which highlight the accuracy and efficiency of the proposed method.","DECISION-MAKING,SYSTEM,SETS",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Computer Science,Mathematics",,,"DECISION-MAKING,SYSTEM,SETS",ADVANCES IN FUZZY SYSTEMS,https://downloads.hindawi.com/journals/afs/2020/6539123.pdf,
37,Toward Near-Perfect Diffractive Optical Elements via Nanoscale 3D Printing,14,8,10452-10461,"Wang Hao,Wang Hongtao,Zhang Wang,Yang Joel K. W.","Wang H,Wang HT,Zhang W,Yang JKW",Yang JKW,10.1021/acsnano.0c04313,Singapore University of Technology & Design,"Diffractive optical elements (DOEs) are widely applied as compact solutions to generate desired optical patterns in the far field by wavefront shaping. They consist of microscopic structures of varying heights to control the phase of either reflected or transmitted light. However, traditional methods to achieve varying thicknesses of structures for DOEs are tedious, requiring multiple aligned lithographic steps each followed by an etching process. Additionally, the reliance on photomasks precludes rapid prototyping and customization in manufacturing complex and multifunctional surface profiles. To achieve this, we turn to nanoscale 3D printing based on two-photon polymerization lithography (TPL). However, TPL systems lack the precision to pattern diffractive components where subwavelength variations in height and position could lead to observable loss in diffraction efficiency. Here, we employed a lumped TPL parametric model and a workaround patterning strategy to achieve precise 3D printing of DOEs using optimized parameters for laser power, beam scan speed, hatching distance, and slicing distance. In our case study, millimeter scale near-perfect Dammann gratings were fabricated with measured diffraction efficiencies near theoretical limits, laser spot array nonuniformity as low as 1.4%, and power ratio of the zero-order spot as low as 0.4%. Leveraging on the advantages of additive manufacturing inherent to TPL, the 3D-printed optical devices can be applied for precise wavefront shaping, with great potential in all-optical machine learning, virtual reality, motion sensing, and medical imaging.","diffractive optical elements,Dammann gratings,3D printing,two-photon polymerization lithography,parametric model,zero-order spot",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,16.207,"NANOSCRIBE,IP-DIP,2-PHOTON,POLYMERIZATION,MECHANICAL-PROPERTIES,DAMMANN,GRATINGS,REFRACTIVE-INDEX,LASER,DESIGN,FABRICATION,SHRINKAGE,POLYMERS",ACS NANO,,
38,Long-Lived Hot Electron in a Metallic Particle for Plasmonics and Catalysis: Ab Initio Nonadiabatic Molecular Dynamics with Machine Learning,14,8,10608-10615,"Chu Weibin,Saidi Wissam A.,Prezhdo Oleg V","Chu WB,Saidi WA,Prezhdo OV",Prezhdo OV,10.1021/acsnano.0c04736,University of Southern California,"Multiple experiments provide evidence for photovoltaic, catalytic, optoelectronic, and plasmonic processes involving hot, i.e., high energy, electrons in nanoscale materials. However, the mechanisms of such processes remain elusive, because electrons rapidly lose energy by relaxation through dense manifolds of states. We demonstrate a long-lived hot electron state in a Pt nanocluster adsorbed on the MoS2 substrate. For this purpose, we develop a simulation technique, combining classical molecular dynamics based on machine learning potentials with ab initio nonadiabatic molecular dynamics and real-time time-dependent density functional theory. Choosing Pt-20/MoS2 as a prototypical system, we find frequent shifting of a top atom in the Pt particle occurring on a 50 ps time scale. The distortion breaks particle symmetry and creates unsaturated chemical bonds. The lifetime of the localized state associated with the broken bonds is enhanced by a factor of 3. Hot electrons aggregate near the shifted atom and form a catalytic reaction center. Our findings prove that distortion of even a single atom can have important implications for nanoscale catalysis and plasmonics and provide insights for utilizing machine learning potentials to accelerate ab initio investigations of excited state dynamics in condensed matter systems.","nanoparticle,electron trapping,machine learning,excited state dynamics,time-dependent density functional theory",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,16.207,"POTENTIAL-ENERGY,SURFACES,CARRIER,DYNAMICS,PYXAID,PROGRAM,GOLD,RECOMBINATION,NANOPARTICLES,MECHANISMS,TRANSITION,GENERATION,DRIVEN",ACS NANO,,
39,Identification of significant risks in pediatric acute lymphoblastic leukemia (ALL) through machine learning (ML) approach,58,11,2631-2640,"Mahmood Nasir,Shahid Saman,Bakhshi Taimur,Riaz Sehar,Ghufran Hafiz,Yaqoob Muhammad","Mahmood N,Shahid S,Bakhshi T,Riaz S,Ghufran H,Yaqoob M",Mahmood N,10.1007/s11517-020-02245-2,"Univ Hlth Sci UHS, Dept Biochem Human Genet & Mol Biol, Lahore, Pakistan.","Pediatric acute lymphoblastic leukemia (ALL) through machine learning (ML) technique was analyzed to determine the significance of clinical and phenotypic variables as well as environmental conditions that can identify the underlying causes of child ALL. Fifty pediatric patients (n = 50) included who were diagnosed with acute lymphoblastic leukemia (ALL) according to the inclusion and exclusion criteria. Clinical variables comprised of the blood biochemistry (CBC, LFTs, RFTs) results, and distribution of type of ALL, i.e., T ALL or B ALL. Phenotypic data included the age, sex of the child, and consanguinity, while environmental factors included the habitat, socioeconomic status, and access to filtered drinking water. Fifteen different features/attributes were collected for each case individually. To retrieve most useful discriminating attributes, four different supervised ML algorithms were used including classification and regression trees (CART), random forest (RM), gradient boosted machine (GM), and C5.0 decision tree algorithm. To determine the accuracy of the derived CART algorithm on future data, a ten-fold cross validation was performed on the present data set. The ALL was common in children of age below 5 years in male patients whole belonged to middle class family of rural areas. (B-ALL) was most frequent as compared with T-ALL. The consanguinity was present in 54% of cases. Low levels of platelets and hemoglobin and high levels of white blood cells were reported in child ALL patients. CART provided the best and complete fit for the entire data set yielding a 99.83% model fit accuracy, and a misclassification of 0.17% on the entire sample space, while C5.0 reported 98.6%, random forest 94.44%, and gradient boosted machine resulted in 95.61% fitting. The variable importance of each primary discriminating attribute is platelet 43%, hemoglobin 24%, white blood cells 4%, and sex of the child 4%. An overall accuracy of 87.4% was recorded for the classifier. Platelet count abnormality can be considered as a major factor in predicting pediatric ALL. The machine learning algorithms can be applied efficiently to provide details for the prognosis for better treatment outcome.
Graphical Identification of significant risks in pediatric acute lymphoblastic leukemia (ALL) through machine learning (ML) approach.","Pediatric ALL,Classification and regression trees (CART),Platelets,Hemoglobin,Environmental factors",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,,"CHILDHOOD,LEUKEMIA,GENETIC,POLYMORPHISMS,DRINKING-WATER,CHROMOSOMAL-ABNORMALITIES,THROMBOTIC,COMPLICATIONS,SOCIOECONOMIC-STATUS,CHILDREN,SUSCEPTIBILITY,POPULATION,MUTATIONS",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
40,Cascade marker removal algorithm for thyroid ultrasound images,58,11,2641-2656,"Ying Xiang,Zhang Yulin,Yu Mei,Wei Xi,Zhu Jialin,Gao Jie,Liu Zhiqiang,Shen Hongqian,Zhang Ruixuan,Li Xuewei","Ying X,Zhang YL,Yu M,Wei X,Zhu JL,Gao J,Liu ZQ,Shen HQ,Zhang RX,Li XW",Li XW; Yu RG,10.1007/s11517-020-02216-7,Tianjin University,"During thyroid ultrasound diagnosis, radiologists add markers such as pluses or crosses near a nodule's edge to indicate the location of a nodule. For computer-aided detection, deep learning models achieve classification, segmentation, and detection by learning the thyroid's texture in ultrasound images. Experiments show that manual markers are strong prior knowledge for data-driven deep learning models, which interferes with the judgment mechanism of computer-aided detection systems. Aiming at this problem, this paper proposes cascade marker removal algorithm for thyroid ultrasound images to eliminate the interference of manual markers. The algorithm consists of three parts. First, in order to highlight marked features, the algorithm extracts salient features in thyroid ultrasound images through feature extraction module. Secondly, mask correction module eliminates the interference of other features besides markers' features. Finally, the marker removal module removes markers without destroying the semantic information in thyroid ultrasound images. Experiments show that our algorithm enables classification, segmentation, and object detection models to focus on the learning of pathological tissue features. At the same time, compared with mainstream image inpainting algorithms, our algorithm shows better performance on thyroid ultrasound images. In summary, our algorithm is of great significance for improving the stability and performance of computer-aided detection systems.","Diagnosis,Computer-assisted,Diagnostic imaging,Thyroid neoplasms,Deep learning,Ultrasonography",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"WHITE,PAPER",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
41,Continual Learning of Multiple Memories in Mechanical Networks,10,3,,"Stern Menachem,Pinson Matthew B.,Murugan Arvind","Stern M,Pinson MB,Murugan A",Murugan A,10.1103/PhysRevX.10.031044,University of Chicago,"Most materials are changed by their history and show memory of things past. However, it is not clear when a system can continually learn new memories in sequence, without interfering with or entirely overwriting earlier memories. Here, we study the learning of multiple stable states in sequence by an elastic material that undergoes plastic changes as it is held in different configurations. We show that an elastic network with linear or nearly linear springs cannot learn continually without overwriting earlier states for a broad class of plasticity rules. On the other hand, networks of sufficiently nonlinear springs can learn continually, without erasing older states, using even simple plasticity rules. We trace this ability to cusped energy contours caused by strong nonlinearities and thus show that elastic nonlinearities play the role of Bayesian priors used in sparse statistical regression. Our model shows how specific material properties allow continual learning of new functions through deployment of the material itself.","DNA NANOTUBES,SYSTEMS,TRANSITION,SELECTION",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,15.641,"DNA,NANOTUBES,SYSTEMS,TRANSITION,SELECTION",PHYSICAL REVIEW X,http://link.aps.org/pdf/10.1103/PhysRevX.10.031044,
42,A High Throughput and Unbiased Machine Learning Approach for Classification of Graphene Dispersions,7,20,,"Abedin Md Joynul,Barua Titon,Shaibani Mahdokht,Majumder Mainak","Abedin MJ,Barua T,Shaibani M,Majumder M",Majumder M,10.1002/advs.202001600,Monash University,"Significant research to define and standardize terminologies for describing stacks of atomic layers in bulk graphene materials has been undertaken. Most methods to measure the stacking characteristics are time consuming and are not suited for obtaining information by directly imaging dispersions. Conventional optical microscopy has difficulty in identifying the size and thickness of a few layers of graphene stacks due to their low photon absorption capacity. Utilizing a contrast based on anisotropic refractive index in 2D materials, it is shown that localized thickness-specific information can be captured in birefringence images of graphene dispersions. Coupling pixel-by-pixel information from brightfield and birefringence images and using unsupervised statistical learning algorithms, three unique data clusters representing flakes (unexfoliated), nanoplatelets (partially exfoliated), and 2D sheets (well-exfoliated) species in various laboratory-based and commercial dispersions of graphene and graphene oxide are identified. The high-throughput, multitasking capability of the approach to classify stacking at sub-nanometer to micrometer scale and measure the size, thickness, and concentration of exfoliated-species in generic dispersions of graphene/graphene oxide are demonstrated. The method, at its current stage, requires less than half an hour to quantitatively assess one sample of graphene/graphene oxide dispersion.","graphene oxide quality control,fake graphene detection,graphene quantification,machine learning,quantitative polarized light microscopy",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Chemistry,Science & Technology - Other Topics,Materials Science",,17.835,EXFOLIATION,ADVANCED SCIENCE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7578897,
43,A learning-based method for online adjustment of C-arm Cone-beam CT source trajectories for artifact avoidance,15,11,1787-1796,"Thies Mareike,Zaech Jan-Nico,Gao Cong,Taylor Russell,Navab Nassir,Maier Andreas,Unberath Mathias","Thies M,Zach JN,Gao C,Taylor R,Navab N,Maier A,Unberath M",Unberath M,10.1007/s11548-020-02249-1,Johns Hopkins University,"Purpose During spinal fusion surgery, screws are placed close to critical nerves suggesting the need for highly accurate screw placement. Verifying screw placement on high-quality tomographic imaging is essential. C-arm cone-beam CT (CBCT) provides intraoperative 3D tomographic imaging which would allow for immediate verification and, if needed, revision. However, the reconstruction quality attainable with commercial CBCT devices is insufficient, predominantly due to severe metal artifacts in the presence of pedicle screws. These artifacts arise from a mismatch between the true physics of image formation and an idealized model thereof assumed during reconstruction. Prospectively acquiring views onto anatomy that are least affected by this mismatch can, therefore, improve reconstruction quality. Methods We propose to adjust the C-arm CBCT source trajectory during the scan to optimize reconstruction quality with respect to a certain task, i.e., verification of screw placement. Adjustments are performed on-the-fly using a convolutional neural network that regresses a quality index over all possible next views given the current X-ray image. Adjusting the CBCT trajectory to acquire the recommended views results in non-circular source orbits that avoid poor images, and thus, data inconsistencies. Results We demonstrate that convolutional neural networks trained on realistically simulated data are capable of predicting quality metrics that enable scene-specific adjustments of the CBCT source trajectory. Using both realistically simulated data as well as real CBCT acquisitions of a semianthropomorphic phantom, we show that tomographic reconstructions of the resulting scene-specific CBCT acquisitions exhibit improved image quality particularly in terms of metal artifacts. Conclusion The proposed method is a step toward online patient-specific C-arm CBCT source trajectories that enable high-quality tomographic imaging in the operating room. Since the optimization objective is implicitly encoded in a neural network trained on large amounts of well-annotated projection images, the proposed approach overcomes the need for 3D information at run-time.","Tomographic reconstruction,Metal artifact reduction,Deep learning,Image-guided surgery",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,"COMPUTED-TOMOGRAPHY,SCREW,PLACEMENT,FLUOROSCOPY,ACCURACY,FUSION",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7603453,
44,Deep Neural Networks for Multicomponent Molecular Systems,5,33,21042-21053,Hanaoka Kyohei,Hanaoka K,Hanaoka K,10.1021/acsomega.0c02599,Hitachi Limited,"Deep neural networks (DNNs) represent promising approaches to molecular machine learning (ML). However, their applicability remains limited to single-component materials and a general DNN model capable of handling various multicomponent molecular systems with composition data is still elusive, while current ML approaches for multicomponent molecular systems are still molecular descriptor-based. Here, a general DNN architecture extending existing molecular DNN models to multicomponent systems called MEIA is proposed. Case studies showed that the MEIA architecture could extend two exiting molecular DNN models to multicomponent systems with the same procedure, and that the obtained models that could learn both the molecular structure and composition information with equal or better accuracies compared to a well-used molecular descriptor-based model in the best model for each case study. Furthermore, the case studies also showed that, for ML tasks where the molecular structure information plays a minor role, the performance improvements by DNN models were small; while for ML tasks where the molecular structure information plays a major role, the performance improvements by DNN models were large, and DNN models showed notable predictive accuracies for an extremely sparse dataset, which cannot be modeled without the molecular structure information. The enhanced predictive ability of DNN models for sparse datasets of multicomponent systems will extend the applicability of ML in the multicomponent material design. Furthermore, the general capability of MEIA to extend DNN models to multicomponent systems will provide new opportunities to utilize the progress of actively developed single-component DNNs for the modeling of multicomponent systems.","FLASH POINTS,BINARY-MIXTURES,BOILING POINTS,QSPR APPROACH,PREDICTION,TEMPERATURES,DESCRIPTORS,COPOLYMERS,DISCOVERY,BENCHMARK",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,,"FLASH,POINTS,BINARY-MIXTURES,BOILING,POINTS,QSPR,APPROACH,PREDICTION,TEMPERATURES,DESCRIPTORS,COPOLYMERS,DISCOVERY,BENCHMARK",ACS OMEGA,https://pubs.acs.org/doi/pdf/10.1021/acsomega.0c02599,
45,Computer-Aided System for the Detection of Multicategory Pulmonary Tuberculosis in Radiographs,2020,,,"Xie Yilin,Wu Zhuoyue,Han Xin,Wang Hongyu,Wu Yifan,Cui Lei,Feng Jun,Zhu Zhaohui,Chen Zhongyuanlong","Xie YL,Wu ZY,Han X,Wang HY,Wu YF,Cui L,Feng J,Zhu ZH,Chen ZYL",Feng J,10.1155/2020/9205082,Northwest University Xi'an,"The early screening and diagnosis of tuberculosis plays an important role in the control and treatment of tuberculosis infections. In this paper, an integrated computer-aided system based on deep learning is proposed for the detection of multiple categories of tuberculosis lesions in chest radiographs. In this system, the fully convolutional neural network method is used to segment the lung area from the entire chest radiograph for pulmonary tuberculosis detection. Different from the previous analysis of the whole chest radiograph, we focus on the specific tuberculosis lesion areas for the analysis and propose the first multicategory tuberculosis lesion detection method. In it, a learning scalable pyramid structure is introduced into the Faster Region-based Convolutional Network (Faster RCNN), which effectively improves the detection of small-area lesions, mines indistinguishable samples during the training process, and uses reinforcement learning to reduce the detection of false-positive lesions. To compare our method with the current tuberculosis detection system, we propose a classification rule for whole chest X-rays using a multicategory tuberculosis lesion detection model and achieve good performance on two public datasets (Montgomery: AUC = 0.977 and accuracy = 0.926; Shenzhen: AUC = 0.941 and accuracy = 0.902). Our proposed computer-aided system is superior to current systems that can be used to assist radiologists in diagnoses and public health providers in screening for tuberculosis in areas where tuberculosis is endemic.","AUTOMATIC DETECTION,LUNG SEGMENTATION,CHEST",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Health Care Sciences & Services,,3.188,"AUTOMATIC,DETECTION,LUNG,SEGMENTATION,CHEST",JOURNAL OF HEALTHCARE ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7463336,
46,Convolutional Sparse Coded Dynamic Brain Functional Connectivity,52,3,1881-1892,"Yan Jin,Zhu Yingying","Yan J,Zhu YY",Zhu YY,10.1007/s11063-020-10295-8,University of Texas System,"Functional brain network has been widely studied in many previous work for brain disorder diagnosis and brain network analysis. However, most previous work focus on static dynamic brain network research. Lots of recent work reveals that the brain shows dynamic activity even in resting state. Such dynamic brain functional connectivity reveals discriminative patterns for identifying many brain disorders. Current sliding window based dynamic brain connectivity framework are not easy to be applied to real clinical applications due to many issues: First, how to set up the optimal sliding window size and how to determine the threshold for the brain connectivity patterns. Secondly, how to represent the high dimensional dynamic brain connectivity pattern in a low dimensional representations for diagnosis purpose. Last, how to deal with the different length dynamic brain network patterns especially when the raw data are of different length. In order to address all those above issues, we proposed a new framework, which employs multiple scale sliding windows and automatically learns a sparse and low ran dynamic brain functional connectivity patterns from raw fMRI data. Furthermore, we are able to measure different length dynamic brain functional connectivity patterns in an equal space by learning a sparse coded convolutional filters. We have evaluated our method with state of the art dynamic brain network methods and the results demonstrated the strong potential of our methods for brain disorder diagnosis in real clinical applications.","Functional magnetic resonance images,Convolutional sparse coding,Dynamic brain network,Computer assisted diagnosis",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,2.884,FMRI,NEURAL PROCESSING LETTERS,https://www.biorxiv.org/content/biorxiv/early/2018/11/27/476663.full.pdf,
47,Reducing the Collision Damage Done to the Tips of Steel Needles during Integrated Piercing by Using Shape Optimization with Feature Selection,2020,,,"Yang Jingzhao,Dong Jiuzhi,Jiang Xiuming,Chen Yunjun","Yang JZ,Dong JZ,Jiang XM,Chen YJ",Yang JZ,10.1155/2020/5078590,Tiangong University,"Recent research has shown that, during integrated piercing, the yarn tension can displace the needles from the centers of the holes in the piercing template. To reduce the damage done to the needle tips when the needles and the hole walls collide when the needle displacement is too large, this paper proposes a method for optimizing the needle shape that satisfies the strength constraint while targeting minimum needle displacement. First, the optimal objective function and strength constraint conditions for the tip displacement of the integrated puncture needle are established, which are affected by many factors. Then, the feature selection method of machine learning is used to reduce the dimensionality of the objective function after data reduction, and the feasible region of key features is reduced to avoid falling into the local best point in the optimization iteration. Finally, machine vision is used to measure experimentally the tip displacement of a needle array. The results show that the average tip displacement is reduced by 18.16-31.42% and the collision risk is reduced from 43.14% to 5.54%. It shows that the optimization method of needle shape based on feature selection is effective for reducing needle tip impact damage during integrated piercing.",DESIGN,Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Engineering,Mathematics",,1.27,DESIGN,MATHEMATICAL PROBLEMS IN ENGINEERING,https://downloads.hindawi.com/journals/mpe/2020/5078590.pdf,
48,Rock classification in petrographic thin section images based on concatenated convolutional neural networks,13,4,1477-1484,"Su Cheng,Xu Sheng-jia,Zhu Kong-yang,Zhang Xiao-can","Su C,Xu SJ,Zhu KY,Zhang XC",Su C,10.1007/s12145-020-00505-1,Zhejiang University,"Rock classification plays an important role in rock mechanics, petrology, mining engineering, magmatic processes, and numerous other fields pertaining to geosciences. This study proposes a concatenated convolutional neural network (Con-CNN) method for classifying geologic rock types based on petrographic thin sections. Plane polarized light (PPL) and crossed polarized light (XPL) were used to acquire thin section images as the fundamental data. After conducting the necessary pre-processing, the PPL and XPL images as well as their comprehensive image developed by principal component analysis were sliced into small patches and were put into three CNNs, comprising the same structure for achieving a preliminary classification. Subsequently, these patches classification results of the CNNs were concatenated by using the maximum likelihood method to obtain a comprehensive classification result. Finally, a statistical revision was applied to fix the misclassification due to the proportion differences of minerals that were similar in appearance. In this study, there were 92 rock samples of 13 types giving 106 petrographic thin sections and 2208 petrographic thin section images, and finally 238,464 sliced image patches were used for the training and validation of the Con-CNN method. The 5-folds cross validation showed that the proposed method provides an overall accuracy of 89.97% and a kappa coefficient of 0.86, which facilitates the automation of rock classification in petrographic thin section images.","Rock,Thin section,Classification,Convolutional neural network",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Geology",,2.543,"AUTOMATIC,IDENTIFICATION,MINERAL,IDENTIFICATION,PATTERN-RECOGNITION,TOUCHING,GRAINS,PERMEABILITY,SEGMENTATION,SEPARATION",EARTH SCIENCE INFORMATICS,http://arxiv.org/pdf/2003.10437,
49,Upper Limb Movement Classification Via Electromyographic Signals and an Enhanced Probabilistic Network,44,10,,"Burns Alexis,Adeli Hojjat,Buford John A.","Burns A,Adeli H,Buford JA",Adeli H,10.1007/s10916-020-01639-x,Ohio State University,"Few studies in the literature have researched the use of surface electromyography (sEMG) for motor assessment post-stroke due to the complexity of this type of signal. However, recent advances in signal processing and machine learning have provided fresh opportunities for analyzing complex, non-linear, non-stationary signals, such as sEMG. This paper presents a method for identification of the upper limb movements from sEMG signals using a combination of digital signal processing, that is discrete wavelet transform, and the enhanced probabilistic neural network (EPNN). To explore the potential of sEMG signals for monitoring motor rehabilitation progress, this study used sEMG signals from a subset of movements of the Arm Motor Ability Test (AMAT) as inputs into a movement classification algorithm. The importance of a particular frequency domain feature, that is the ratio of the mean absolute values between sub-bands, was discovered in this work. An average classification accuracy of 75.5% was achieved using the proposed approach with a maximum accuracy of 100%. The performance of the proposed method was compared with results obtained using three other classification algorithms: support vector machine (SVM), k-Nearest Neighbors (k-NN), and probabilistic neural network (PNN) in terms of sEMG movement classification. The study demonstrated the capability of using upper limb sEMG signals to identify and distinguish between functional movements used in standard upper limb motor assessments for stroke patients. The classification algorithm used in the proposed method, EPNN, outperformed SVM, k-NN, and PNN.","Upper Limb Movement Classification,EMG,Electromyographic Signals,Enhanced Probablistic Neural Network,Surface EMG,Semg,Machine learning,Wavelet transform,Motor rehabilitation",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Health Care Sciences & Services,Medical Informatics",,3.951,"SUPPORT,VECTOR,MACHINE,NEURAL-NETWORK,STROKE,SURVIVORS,EMG,RECOGNITION,REHABILITATION,PREDICTION,DIAGNOSIS,MOBILITY,THERAPY",JOURNAL OF MEDICAL SYSTEMS,,
50,Warpage Deformation Prediction of Injection Products with Combinatorial Algorithm,54,8,84-90,",,,,","Wang Bo,Cai Anjiang,Meng Guanghui,Li Feng,Zhao Dongping",,,Wang Bo,"To improve the predictive ability of warpage deformation of injection products,a new combination algorithm was proposed taking a notebook battery cover as the example.Simulation experiments were performed nine times on the battery cover using injection molding simulation software to obtain the warpage amount under the recommended engineering process parameters.The sample data,BP neural network,grey theory and genetic algorithm were effectively combined by the optimal weight coefficient to construct three combined forecasting models,together with three single prediction models to predict the warpage amount of the battery cover.Then based on the three kinds of prediction error evaluation indexes,the prediction results of six models were compared and analyzed according to the square sum error,average absolute error and average relative error.Finally,the accuracy of the combinatorial algorithm was verified by the battery cover manufacturing.The results show that the accuracy of the combined prediction model is better than that of single prediction model.The prediction result of the combined arithmetic average model gets the closest to the actual measuring value,and the maximum error is not more than 5%.The proposed combination prediction method can accurately predict the warpage amount of plastic parts.",combination algorithm; warpage deformation; injection molding,Article,,,,,,,,
51,Food Supply Chains as Cyber-Physical Systems: a Path for More Sustainable Personalized Nutrition,13,1,92-103,"Smetana Sergiy,Aganovic Kemal,Heinz Volker","Smetana S,Aganovic K,Heinz V",Smetana S,10.1007/s12393-020-09243-y,"German Inst Food Technol DIL eV, Quakenbruck, Germany.","Current food system evolved in a great degree because of the development of processing and food engineering technologies: people learned to bake bread long before the advent of agriculture; salting and smoking supported nomad lifestyles; canning allowed for longer military marches; etc. Food processing technologies went through evolution and significant optimization and currently rely on minor fraction of energy comparing with initial prototypes. Emerging processing technologies (high-pressure, pulsed electric fields, ohmic heating, ultrasound) and novel food systems (cultured biomass, 3-D bioprinting, cyber-physical chains) try to challenge the existing chains by developing potentially more nutritious and sustainable food solutions. However, new food systems rely on low technology readiness levels and estimation of their potential future benefits or drawbacks is a complex task mostly due to the lack of integrated data. The research is aimed for the development of conceptual guidelines of food production system structuring as cyber-physical systems. The study indicates that cyber-physical nature of modern food is a key for the engineering of more nutritious and sustainable paths for novel food systems. Implementation of machine learning methods for the collection, integration, and analysis of data associated with biomass production and processing on different levels from molecular to global, leads to the precise analysis of food systems and estimation of upscaling benefits, as well as possible negative rebound effects associated with societal attitude. Moreover, such data-integrated assessment systems allow transparency of chains, integration of nutritional and environmental properties, and construction of personalized nutrition technologies.","Cyber-physical systems,Food chains,Food systems,Traceability,Sustainability",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Food Science & Technology,,6.813,"INDUSTRY,4.0,BIG,DATA,DIGITAL,TWIN,GENETIC,ALGORITHM,NEURAL-NETWORK,DATA,SCIENCE,INTERNET,OPTIMIZATION,BLOCKCHAIN,CHALLENGES",FOOD ENGINEERING REVIEWS,https://link.springer.com/content/pdf/10.1007/s12393-020-09243-y.pdf,
52,,,,,,,,,,,,,,,,,,,,
53,Deep transfer learning-based automated detection of COVID-19 from lung CT scan slices.,,,1-15,",,,,","Ahuja Sakshi,Panigrahi Bijaya Ketan,Dey Nilanjan,Rajinikanth Venkatesan,Gandhi Tapan Kumar",,10.1007/s10489-020-01826-w,,"Lung abnormality is one of the common diseases in humans of all age group and this disease may arise due to various reasons. Recently, the lung infection due to SARS-CoV-2 has affected a larger human community globally, and due to its rapidity, the World-Health-Organisation (WHO) declared it as pandemic disease. The COVID-19 disease has adverse effects on the respiratory system, and the infection severity can be detected using a chosen imaging modality. In the proposed research work; the COVID-19 is detected using transfer learning from CT scan images decomposed to three-level using stationary wavelet. A three-phase detection model is proposed to improve the detection accuracy and the procedures are as follows; Phase1- data augmentation using stationary wavelets, Phase2- COVID-19 detection using pre-trained CNN model and Phase3- abnormality localization in CT scan images. This work has considered the well known pre-trained architectures, such as ResNet18, ResNet50, ResNet101, and SqueezeNet for the experimental evaluation. In this work, 70% of images are considered to train the network and 30% images are considered to validate the network. The performance of the considered architectures is evaluated by computing the common performance measures. The result of the experimental evaluation confirms that the ResNet18 pre-trained transfer learning-based model offered better classification accuracy (training = 99.82%, validation = 97.32%, and testing = 99.4%) on the considered image dataset compared with the alternatives. © Springer Science+Business Media, LLC, part of Springer Nature 2020.",COVID-19; CT scan; ResNet18; Transfer learning; Wavelets,Journal Article,,,,,,,,
54,Multi-fidelity machine-learning with uncertainty quantification and Bayesian optimization for materials design: Application to ternary random alloys,153,7,,"Tran Anh,Tranchida Julien,Wildey Tim,Thompson Aidan P.","Tran A,Tranchida J,Wildey T,Thompson AP",Tran A,10.1063/5.0015672,United States Department of Energy (DOE),"We present a scale-bridging approach based on a multi-fidelity (MF) machine-learning (ML) framework leveraging Gaussian processes (GP) to fuse atomistic computational model predictions across multiple levels of fidelity. Through the posterior variance of the MFGP, our framework naturally enables uncertainty quantification, providing estimates of confidence in the predictions. We used density functional theory as high-fidelity prediction, while a ML interatomic potential is used as low-fidelity prediction. Practical materials' design efficiency is demonstrated by reproducing the ternary composition dependence of a quantity of interest (bulk modulus) across the full aluminum-niobium-titanium ternary random alloy composition space. The MFGP is then coupled to a Bayesian optimization procedure, and the computational efficiency of this approach is demonstrated by performing an on-the-fly search for the global optimum of bulk modulus in the ternary composition space. The framework presented in this manuscript is the first application of MFGP to atomistic materials simulations fusing predictions between density functional theory and classical interatomic potential calculations.",,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Chemistry,Physics",,3.166,,JOURNAL OF CHEMICAL PHYSICS,http://arxiv.org/pdf/2006.00139,
55,DenseHyper: an automatic recognition system for detection of hypertensive retinopathy using dense features transform and deep-residual learning,79,41-42,31595-31623,"Abbas Qaisar,Ibrahim Mostafa E. A.","Abbas Q,Ibrahim MEA",Abbas Q,10.1007/s11042-020-09630-x,Al-Imam Muhammad Ibn Saud Islamic University,"High blood pressure and diabetes are associated with a retinal abnormality known as Hypertensive Retinopathy (HR). The severity-level and duration of hypertension are straightly related to the incidence of HR-eye disease. The HR damages the pathological lesions of eyes such as arteriolar narrowing, retinal hemorrhage, macular edema, cotton wool spots, and blood vessels. In the early stages, it is important to detect and diagnose HR to prevent eye blindness. Currently, there are few computerize systems developed to recognize HR. However, those systems focused on extracting features through hand-craft and deep-learning models (DLMs) based techniques. As a result, the complex image processing algorithms are required in case of hand-crafted features and it is difficult to define generalized features by DLMs to recognize HR. Moreover, the classification accuracy is not up-to-the-mark even though by using deep-feature techniques as observed in state-of-the-art HR diagnostics systems. To solve these problems, a novel hypertensive retinopathy (DenseHyper) system is developed to detect the HR based on a proposed trained features layer (TF-L) and dense feature transform layer (DFT-L) to the deep residual learning (DRL) methods. The DenseHyper system consists of different multilayer dense architecture by integrating of TF-L by convolutional neural network (CNN) to learn features from different lesions, and generate specialized features by DFT-L. To develop DenseHyper system, a learning based dense feature transform (DFT) approach was integrated to increase classification accuracy. Three online sources besides one private data are gathered to test and compare the DenseHyper system. To show the performance of the DenseHyper system, the statistical analysis is also performed on 4270 retinal fundus images through sensitivity (SE), specificity (SP), accuracy (ACC) and area under the receiver operating curve (AUC) metrics. The significant results were achieved compare to state-of-the-art methods. On average, the SE of 93%, SP of 95%, ACC of 95% and 0.96 of AUC values were obtained through a 10-fold cross-validation test. Experimental results confirm the applicability of the DenseHyper system to accurately diagnosis of hypertensive retinopathy.","Hypertensive retinopathy,Retinal fundus images,Features selection,Deep-neural network,Convolutional neural network,Transfer learning,Residual neural network",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"CLASSIFICATION,DIAGNOSIS,IMAGES,SEGMENTATION,NETWORKS,ARTERIES,VESSELS,FUSION,RATIO",MULTIMEDIA TOOLS AND APPLICATIONS,,
56,Unified deep learning approach for prediction of Parkinson's disease,14,10,1980-1989,"Wingate James,Kollia Ilianna,Bidaut Luc,Kollias Stefanos","Wingate J,Kollia I,Bidaut L,Kollias S",Kollia I,10.1049/iet-ipr.2019.1526,National Technical University of Athens,"The study presents a novel approach, based on deep learning, for diagnosis of Parkinson's disease through medical imaging. The approach includes analysis and use of the knowledge extracted by deep convolutional and recurrent neural networks when trained with medical images, such as magnetic resonance images and dopamine transporters scans. Internal representations of the trained DNNs constitute the extracted knowledge which is used in a transfer learning and domain adaptation manner, so as to create a unified framework for prediction of Parkinson's across different medical environments. A large experimental study is presented illustrating the ability of the proposed approach to effectively predict Parkinson's, using different medical image sets from real environments.","recurrent neural nets,diseases,medical image processing,biomedical MRI,learning (artificial intelligence),unified deep learning approach,medical imaging,recurrent neural networks,magnetic resonance images,trained DNN,transfer learning,medical environments,Parkinson disease diagnosis,dopamine transporter scans",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"DIAGNOSIS,PROGRESSION,NETWORKS",IET IMAGE PROCESSING,http://eprints.lincoln.ac.uk/id/eprint/41398/1/IET_Image_Processing___Parkinson_s__lastsubmission.pdf,
57,Deep learning-based automated detection of human knee joint's synovial fluid from magnetic resonance images with transfer learning,14,10,1990-1998,"Iqbal Imran,Shahzad Ghazala,Rafiq Nida,Mustafa Ghulam,Ma Jinwen","Iqbal I,Shahzad G,Rafiq N,Mustafa G,Ma JW",Ma JW,10.1049/iet-ipr.2019.1646,Peking University,"As an analytic tool in medicine, particularly in radiology, deep learning is gaining much attention and opening a new way for disease diagnosis. Nonetheless, it is rather challenging to acquire large-scale detailed labelled datasets in the field of medical imaging. In fact, transfer learning provides a possible way to resolve this issue to a certain extent such that the parameter learning of a neural network starts with its pre-trained weights learned from a large-scale dataset of certain similar task, and fine-tunes on a small comprehensively annotated dataset for the particular target task. The main aim of this study is to apply the deep learning model to detect the synovial fluid of human knee joint from magnetic resonance images. A specialized convolutional neural network architecture is proposed for automated detection of human knee joint's synovial fluid. Two independent datasets are used in the training, development, and evaluation of the proposed model. It is demonstrated by the experimental results that the proposed model obtains high sensitivity, specificity, precision, and accuracy to the detection of human knee joint's synovial fluid. As a result, this proposed approach provides a novel and feasible way for automating and expediting the synovial fluid analysis.","learning (artificial intelligence),neural nets,diseases,orthopaedics,biomedical MRI,magnetic resonance images,specialised convolutional neural network architecture,human knee joint,independent datasets,Orthopaedic Implants dataset,PC Hospital Liaoning dataset,synovial fluid analysis,deep learning-based automated detection,transfer learning,large-scale detailed labelled datasets,medical imaging,parameter learning,large-scale dataset,comprehensively annotated dataset,particular target task,deep learning model",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"NEURAL-NETWORKS,TERM",IET IMAGE PROCESSING,,
58,Bi-dictionary learning model for medical image reconstruction from undersampled data,14,10,2130-2139,"Mohaoui Souad,Hakim Abdelilah,Raghay Said","Mohaoui S,Hakim A,Raghay S",Mohaoui S,10.1049/iet-ipr.2019.0886,Cadi Ayyad University of Marrakech,"In recent years, dictionary learning has shown to be an efficient tool in recovering images from their degraded, damaged or incomplete version. Especially, for medical images that contain significant details and characteristics. In this work, the authors are interested in this unsupervised learning technique for discovering and visualising the underlying structure of a medical image. Therefore, an adaptive bi-dictionary learning model for recovering magnetic resonance (MR) image from undersampled measurements is introduced. The proposed model learns two dictionaries, one over the underlying image and the other over its sparse gradient. Hence, the algorithm minimises a linear combination of three terms corresponding to the least-squares data fitting, dictionary learning over the pixel domain, and gradient-based dictionary. Numerically, experimental results on several MR images demonstrate that the proposed bi-dictionary framework can improve reconstruction accuracy over other methods.","image reconstruction,medical image processing,image representation,gradient methods,unsupervised learning,biomedical MRI,least squares approximations,medical image reconstruction,undersampled data,unsupervised learning technique,magnetic resonance image,undersampled measurements,MR images,bi-dictionary learning model,adaptive bi-dictionary learning model,least-squares data fitting,sparse gradient,gradient-based dictionary,pixel domain",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"SPARSE,REPRESENTATIONS,ALGORITHM,RECOVERY,MRI,REGULARIZATION,DOMAIN",IET IMAGE PROCESSING,,
59,Visual saliency based global-local feature representation for skin cancer classification,14,10,2140-2148,"Xiao Feng,Wu Qiuxia","Xiao F,Wu QX",Wu QX,10.1049/iet-ipr.2019.1018,South China University of Technology,"With the rapid increase in the cases of deadly skin cancer, the classification on different types of skin cancer has been emerging as one of the most significant issues in the field of medical image. Several approaches have been proposed to help in diagnosing the categories of the skin lesions by means of traditional features or leveraging the widely used deep learning models. However, there are lack of the integrated frameworks to combine the hand-crafted traditional features and the deep Conv-features. Furthermore, the effective way to extract global and local features is also conducive to distinguish the specific lesions from normal skin. Hence, in this study, the authors present an integrated model to acquire more representative global-local features including the traditional local binary pattern features and deep Conv-features. In addition, several fusion strategies have conducted on the Global-DNN and Local-DNN for better performance. In order to extract more explicit features from the specific lesion areas, a target segmentation method based on visual saliency detection is employed to eliminate the background interference. Experimental results on ISIC-2017 skin cancer dataset demonstrate that the proposed Global-DNN and Global-Local models can obtain more effective feature representation which achieve outperformed results for skin cancer classification.","medical image processing,image classification,feature extraction,object detection,learning (artificial intelligence),cancer,skin,image segmentation,neural nets,visual saliency detection,ISIC-2017 skin cancer dataset,Global-DNN,Global-Local models,effective feature representation,skin cancer classification,global-local feature representation,deadly skin cancer,skin lesions,integrated frameworks,hand-crafted traditional features,deep Conv-features,global features,specific lesions,normal skin,representative global-local features,traditional local binary pattern features,explicit features,specific lesion areas,deep learning models",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"SEGMENTATION,STATE",IET IMAGE PROCESSING,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-ipr.2019.1018,
60,Advanced lung cancer classification approach adopting modified graph clustering and whale optimisation-based feature selection technique accompanied by a hybrid ensemble classifier,14,10,2204-2215,"Mary Adline Priya Michael,Joseph Jawhar S.","Priya MMA,Jawhar SJ",Priya MMA,10.1049/iet-ipr.2019.0178,"Arunachala Coll Engn Women, Dept Informat & Commun Engn, Kanya Kumari, Tamil Nadu, India.","Nowadays, lung cancer is the leading cause of cancer death in both men and women. The early detection of potentially cancerous cells is the best way to improve the patient's chances of survival. In the medical field, computed tomography (CT) is the best imaging technique and it is helpful for doctors to accurately find the cancerous cells. The authors propose an automatic approach to analyse and segment the lungs and classify each lung into normal or cancer. Initially, the CT lung image is pre-processed to remove noise. Then, they combine the histogram analysis with thresholding and morphological operations to segment and extract the lung regions. In feature extraction stage, the radiomic features of each lung image are extracted separately. Then to improve the classification accuracy, some of the optimum features are selected using modified graph clustering-based whale optimisation algorithm. Finally, the selected features are classified using ensemble classifiers such as support vector machine, K-nearest neighbour, and random forest. Experimental result demonstrates that the proposed method achieves better performance in terms of sensitivity, specificity, precision, recall,F-measure, and accuracy when compared with other state-of-art approaches.","computerised tomography,support vector machines,image segmentation,feature extraction,cancer,pattern clustering,image classification,medical image processing,lung,feature selection,graph theory,optimisation,nearest neighbour methods,random forests,classification accuracy,optimum feature selection,modified graph clustering-based whale optimisation algorithm,advanced lung cancer classification approach,whale optimisation-based feature selection technique,hybrid ensemble classifier,cancer death,cancerous cells,medical field,computed tomography,imaging technique,normal cancer,CT lung image,thresholding operations,morphological operations,lung regions,feature extraction stage,radiomic features,noise removal,histogram analysis,support vector machine,K-nearest neighbour,random forest,F-measure",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"NODULE,TYPE,CLASSIFICATION,ANT,COLONY,OPTIMIZATION,CLINICAL-SIGNIFICANCE,PULMONARY,NODULES,TEXTURAL,FEATURES,NEURAL-NETWORKS,CT,IMAGES,SHAPE,SEGMENTATION,RADIOMICS",IET IMAGE PROCESSING,,
61,Accurate leukocoria predictor based on deep VGG-net CNN technique,14,10,2241-2248,Subrahmanyeswara Rao Boyina,Rao BS,Rao BS,10.1049/iet-ipr.2018.6656,"Swarnandhra Coll Engn & Technol, Dept Elect & Commun Engn, Narsapur, AP, India.","The most important part of digital image analysis is object classification. Nowadays, deep learning makes an enormous achievement in computer vision problems. So there has been a lot of interests in applying features learned by convolutional neural networks (CNNs) on general image recognition to more tasks such as object detection, segmentation and face recognition. Leukocoria detection is one of the serious challenges in infant retinal treatment. Leukocoria is represented as an abnormal white reflection appearing in the eyes of an infant suffering from retinoblastoma. This research proposes a deep Visual Geometry Group-net CNN classifier for automatic detection of leukocoria. The proposed classifier comprises pre-processing, feature extraction and classification. The deep CNN classifier contains convolution layer, pooling layer and fully connected layer with weights are developed on each image. Experimental results based on several eye images consist of ordinary and leukocoric from flicker, and it demonstrates that the proposed classifier provides better results with the accuracy of 98.5% and the error rate is below 2% which exceeds the current results.","feature extraction,image classification,computer vision,learning (artificial intelligence),medical image processing,eye,patient treatment,convolutional neural nets,convolutional neural networks,general image recognition,object detection,face recognition,leukocoria detection,infant retinal treatment,abnormal white reflection,deep Visual Geometry Group-net CNN classifier,automatic detection,feature extraction,convolution layer,eye images,accurate leukocoria predictor,deep VGG-net CNN technique,digital image analysis,object classification,deep learning,computer vision problems,pooling layer,fully connected layer",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"RB1,GENE,RETINOBLASTOMA,MUTATIONS,DISEASE",IET IMAGE PROCESSING,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-ipr.2018.6656,
62,Optimization of depth-graded multilayer structure for x-ray optics using machine learning,128,7,,"Dieb Sae,Song Zhilong,Yin Wan-Jian,Ishir Masashi","Dieb S,Song ZL,Yin WJ,Ishir M",Dieb S,10.1063/5.0012351,National Institute for Materials Science,"We present a general machine-learning-based approach to solve the inverse design problem of depth-graded multilayer structures (so-called supermirrors) for x-ray optics. Our model uses Monte Carlo tree search (MCTS) with policy gradient in combination with a reflectivity simulation. MCTS is an iterative design method that showed competitive efficiency in materials design and discovery problems. A policy gradient algorithm with a neural network was added to optimize the tree expansion. The policy gradient is a reinforcement learning method that optimizes parametrized policies toward an expected return using gradient descent. This approach is applied to design a depth-graded multilayer structure that maximizes mean reflectivity in an angular range for Cu K
alpha radiation by selecting the optimal thickness and material for each layer in the structure. Mean reflectivity of 0.80 was achieved in an angular range of 0.45-0.55
degrees. Alternating materials are selected from a predetermined set of materials. We confirmed that the policy gradient enhances the efficiency of MCTS. This approach can be applied autonomously on several x-ray applications without any parameter tuning or pre-available data.","MATERIALS DESIGN,GENETIC ALGORITHMS,ANGLE CALCULATIONS,SUPERMIRROR,REFLECTION,TELESCOPE,MIRRORS,TOOL",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,"MATERIALS,DESIGN,GENETIC,ALGORITHMS,ANGLE,CALCULATIONS,SUPERMIRROR,REFLECTION,TELESCOPE,MIRRORS,TOOL",JOURNAL OF APPLIED PHYSICS,,
63,Application of machine learning methods for predicting new superhard materials,128,7,,"Mazhnik Efim,Oganov Artem R.","Mazhnik E,Oganov AR",Mazhnik E,10.1063/5.0012055,Skolkovo Institute of Science & Technology,"Superhard materials are of great interest in various practical applications, and an increasing number of research efforts are focused on their development. In this article, we demonstrate that machine learning can be successfully applied to searching for such materials. We construct a machine learning model using neural networks on graphs together with a recently developed physical model of hardness and fracture toughness. The model is trained using available elastic data from the Materials Project database and has good accuracy for predictions. We use this model to screen all crystal structures in the database and systematize all the promising hard or superhard materials, and find that diamond (and its polytypes) are the hardest materials in the database. Our results can be further used for the investigation of interesting materials using more accurate ab initio calculations and/or experiments.",LANTHANUM,Article,"AIP Publishing, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,LANTHANUM,JOURNAL OF APPLIED PHYSICS,,
64,Machine learning Frenkel Hamiltonian parameters to accelerate simulations of exciton dynamics,153,7,,"Farahvash Ardavan,Lee Chee-Kong,Sun Qiming,Shi Liang,Willard Adam P.","Farahvash A,Lee CK,Sun QM,Shi L,Willard AP",Willard AP,10.1063/5.0016009,Massachusetts Institute of Technology (MIT),"In this manuscript, we develop multiple machine learning (ML) models to accelerate a scheme for parameterizing site-based models of exciton dynamics from all-atom configurations of condensed phase sexithiophene systems. This scheme encodes the details of a system's specific molecular morphology in the correlated distributions of model parameters through the analysis of many single-molecule excited-state electronic-structure calculations. These calculations yield excitation energies for each molecule in the system and the network of pair-wise intermolecular electronic couplings. Here, we demonstrate that the excitation energies can be accurately predicted using a kernel ridge regression (KRR) model with Coulomb matrix featurization. We present two ML models for predicting intermolecular couplings. The first one utilizes a deep neural network and bi-molecular featurization to predict the coupling directly, which we find to perform poorly. The second one utilizes a KRR model to predict unimolecular transition densities, which can subsequently be analyzed to compute the coupling. We find that the latter approach performs excellently, indicating that an effective, generalizable strategy for predicting simple bimolecular properties is through the indirect application of ML to predict higher-order unimolecular properties. Such an approach necessitates a much smaller feature space and can incorporate the insight of well-established molecular physics.","FORCE-FIELD,DICYANOVINYL-SEXITHIOPHENE,FILMS,LIGHT,MODEL,MORPHOLOGY,MECHANICS,MOLECULES,COUPLINGS,CRYSTALS",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Chemistry,Physics",,3.166,"FORCE-FIELD,DICYANOVINYL-SEXITHIOPHENE,FILMS,LIGHT,MODEL,MORPHOLOGY,MECHANICS,MOLECULES,COUPLINGS,CRYSTALS",JOURNAL OF CHEMICAL PHYSICS,https://www.osti.gov/biblio/1803822,
65,Liquid to crystal Si growth simulation using machine learning force field,153,7,,"Miao Ling,Wang Lin-Wang","Miao L,Wang LW",Wang LW,10.1063/5.0011163,United States Department of Energy (DOE),"Machine learning force field (ML-FF) has emerged as a potential promising approach to simulate various material phenomena for large systems with ab initio accuracy. However, most ML-FFs have been used to study the phenomena relatively close to the equilibrium ground states. In this work, we have studied a far from equilibrium system of liquid to crystal Si growth using ML-FF. We found that our ML-FF based on ab initio decomposed atomic energy can reproduce all the aspects of ab initio simulated growth, from local energy fluctuations to transition temperatures, to diffusion constant, and growth rates. We have also compared the growth simulation with the Stillinger-Weber classical force field and found significant differences. A procedure is also provided to correct a systematic fitting bias in the ML-FF training process, which exists in all training models, otherwise critical results like transition temperature will be wrong.","NEURAL-NETWORK POTENTIALS,MOLECULAR-DYNAMICS",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Chemistry,Physics",,3.166,"NEURAL-NETWORK,POTENTIALS,MOLECULAR-DYNAMICS",JOURNAL OF CHEMICAL PHYSICS,https://escholarship.org/content/qt3bw643rb/qt3bw643rb.pdf,
66,Causal analysis of competing atomistic mechanisms in ferroelectric materials from high-resolution scanning transmission electron microscopy data,6,1,,"Ziatdinov Maxim,Nelson Christopher T.,Zhang Xiaohang,Vasudevan Rama K.,Eliseev Eugene,Morozovska Anna N.,Takeuchi Ichiro,Kalinin Sergei V.","Ziatdinov M,Nelson CT,Zhang XH,Vasudevan RK,Eliseev E,Morozovska AN,Takeuchi I,Kalinin SV",Kalinin SV,10.1038/s41524-020-00396-2,United States Department of Energy (DOE),"Machine learning has emerged as a powerful tool for the analysis of mesoscopic and atomically resolved images and spectroscopy in electron and scanning probe microscopy, with the applications ranging from feature extraction to information compression and elucidation of relevant order parameters to inversion of imaging data to reconstruct structural models. However, the fundamental limitation of machine learning methods is their correlative nature, leading to extreme susceptibility to confounding factors. Here, we implement the workflow for causal analysis of structural scanning transmission electron microscopy (STEM) data and explore the interplay between physical and chemical effects in a ferroelectric perovskite across the ferroelectric-antiferroelectric phase transitions. The combinatorial library of the Sm-doped BiFeO3 is grown to cover the composition range from pure ferroelectric BFO to orthorhombic 20% Sm-doped BFO. Atomically resolved STEM images are acquired for selected compositions and are used to create a set of local compositional, structural, and polarization field descriptors. The information-geometric causal inference (IGCI) and additive noise model (ANM) analysis are used to establish the pairwise causal directions between the descriptors, ordering the data set in the causal direction. The causal chain for IGCI and ANM across the composition is compared and suggests the presence of common causal mechanisms across the composition series. Ultimately, we believe that the causal analysis of the multimodal data will allow exploring the causal links between multiple competing mechanisms that control the emergence of unique functionalities of morphotropic materials and ferroelectric relaxors.","INSULATOR-METAL TRANSITION,PIEZOELECTRIC PROPERTIES,POLARIZATION,BIFEO3,STEM,GLASSES,FILMS",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Chemistry,Materials Science",,13.993,"INSULATOR-METAL,TRANSITION,PIEZOELECTRIC,PROPERTIES,POLARIZATION,BIFEO3,STEM,GLASSES,FILMS",NPJ COMPUTATIONAL MATERIALS,http://arxiv.org/pdf/2002.04245,
67,Predicting the Activity and Selectivity of Bimetallic Metal Catalysts for Ethanol Reforming using Machine Learning,10,16,9438-9444,"Artrith Nongnuch,Lin Zhexi,Chen Jingguang G.","Artrith N,Lin ZX,Chen JG",Artrith N; Chen JG,10.1021/acscatal.0c02089,Columbia University,"Machine learning is ideally suited for the pattern detection in large uniform data sets, but consistent experimental data sets on catalyst studies are often small. Here we demonstrate how a combination of machine learning and first-principles calculations can be used to extract knowledge from a relatively small set of experimental data. The approach is based on combining a complex machine-learning model trained on a computational library of transition-state energies with simple linear regression models of experimental catalytic activities and selectivities from the literature. Using the combined model, we identify the key C-C bond-scission reactions involved in ethanol reforming and perform a computational screening for ethanol reforming on monolayer bimetallic catalysts with architectures TM-Pt-Pt(111) and Pt-TM-Pt(111) (TM = 3d transition metals). The model also predicts four promising catalyst compositions for future experimental studies. The approach is not limited to ethanol reforming but is of general use for the interpretation of experimental observations as well as for the computational discovery of catalytic materials.","ethanol reforming,bimetallic catalysts,density-functional theory,transition states,machine learning,random forest regression,Gaussian process regression",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,13.721,"TOTAL-ENERGY,CALCULATIONS,ETHYLENE-GLYCOL,HYDROGEN-PRODUCTION,H-2,PRODUCTION,DECOMPOSITION,NI%2FPT%28111%29,SURFACES,DFT",ACS CATALYSIS,https://www.osti.gov/biblio/1659748,
68,,,,,,,,,,,,,,,,,,,,
69,,,,,,,,,,,,,,,,,,,,
70,Application of Machine Learning Techniques for Enuresis Prediction in Children,31,05,414-419,"Tokar Baran,Baskaya Mukaddes,Celik Ozer,Cemrek Fatih,Acikgoz Ayfer","Tokar B,Baskaya M,Celik O,Cemrek F,Acikgoz A",Tokar B,10.1055/s-0040-1715655,Eskisehir Osmangazi University,"Introduction As a subset of artificial intelligence, machine learning techniques (MLTs) may evaluate very large and raw datasets. In this study, the aim is to establish a model by MLT for the prediction of enuresis in children. Materials and Methods The study included 8,071 elementary school students. A total of 704 children had enuresis. For analysis of data with MLT, another group including 704 nonenuretic children was structured with stratified sampling. Out of 34 independent variables, 14 with high feature values significantly affecting enuresis were selected. A model of estimation was created by training the data. Results Fourteen independent variables in order of feature importance value were starting age of toilet training, having urinary urgency, holding maneuvers to prevent voiding, frequency of defecation, history of enuresis in mother and father, having child's own room, parent's education level, history of enuresis in siblings, consanguineous marriage, incomplete bladder emptying, frequent voiding, gender, history of urinary tract infection, and surgery in the past. The best MLT algorithm for the prediction of enuresis was determined as logistic regression algorithm. The total accuracy rate of the model in prediction was 81.3%. Conclusion MLT might provide a faster and easier evaluation process for studies on enuresis with a large dataset. The model in this study may suggest that selected variables with high feature values could be preferred with priority in any screening studies for enuresis. MLT may prevent clinical errors due to human cognitive biases and may help the physicians to be proactive in diagnosis and treatment of enuresis.","enuresis,artificial intelligence,children,urinary incontinence",Article,"GEORG THIEME VERLAG KG, RUDIGERSTR 14, D-70469 STUTTGART, GERMANY","Pediatrics,Surgery",,1.86,"NOCTURNAL,ENURESIS,SCHOOL-CHILDREN,PREVALENCE,INCONTINENCE,URINARY",EUROPEAN JOURNAL OF PEDIATRIC SURGERY,,
71,How machine learning can help select capping layers to suppress perovskite degradation,11,1,,"Hartono Noor Titan Putri,Thapa Janak,Tiihonen Armi,Oviedo Felipe,Batali Clio,Yoo Jason J.,Liu Zhe,Li Ruipeng,Fuertes Marron David,Bawendi Moungi G.","Hartono NTP,Thapa J,Tiihonen A,Oviedo F,Batali C,Yoo JJ,Liu Z,Li R,Marron DF,Bawendi MG",Buonassisi T; Sun SJ,10.1038/s41467-020-17945-4,Massachusetts Institute of Technology (MIT),"Environmental stability of perovskite solar cells (PSCs) has been improved by trial-and-error exploration of thin low-dimensional (LD) perovskite deposited on top of the perovskite absorber, called the capping layer. In this study, a machine-learning framework is presented to optimize this layer. We featurize 21 organic halide salts, apply them as capping layers onto methylammonium lead iodide (MAPbI(3)) films, age them under accelerated conditions, and determine features governing stability using supervised machine learning and Shapley values. We find that organic molecules' low number of hydrogen-bonding donors and small topological polar surface area correlate with increased MAPbI(3) film stability. The top performing organic halide, phenyltriethylammonium iodide (PTEAI), successfully extends the MAPbI(3) stability lifetime by 42 times over bare MAPbI(3) and 1.3 +/- 0.3 times over state-of-the-art octylammonium bromide (OABr). Through characterization, we find that this capping layer stabilizes the photoactive layer by changing the surface chemistry and suppressing methylammonium loss.","CHARGE-CARRIER DYNAMICS,SOLAR-CELLS,THERMAL-STABILITY,EFFICIENCY,LIGHT,PASSIVATION",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,15.805,"CHARGE-CARRIER,DYNAMICS,SOLAR-CELLS,THERMAL-STABILITY,EFFICIENCY,LIGHT,PASSIVATION",NATURE COMMUNICATIONS,https://dspace.mit.edu/bitstream/1721.1/129799/2/s41467-020-17945-4.pdf,
72,Automated glaucoma screening method based on image segmentation and feature extraction,58,10,2567-2586,"Guo Fan,Li Weiqing,Tang Jin,Zou Beiji,Fan Zhun","Guo F,Li WQ,Tang J,Zou BJ,Fan Z",Tang J,10.1007/s11517-020-02237-2,Central South University,"Glaucoma is a chronic disease that threatens eye health and can cause permanent blindness. Since there is no cure for glaucoma, early screening and detection are crucial for the prevention of glaucoma. Therefore, a novel method for automatic glaucoma screening that combines clinical measurement features with image-based features is proposed in this paper. To accurately extract clinical measurement features, an improved UNet++ neural network is proposed to segment the optic disc and optic cup based on region of interest (ROI) simultaneously. Some important clinical measurement features, such as optic cup to disc ratio, are extracted from the segmentation results. Then, the increasing field of view (IFOV) feature model is proposed to fully extract texture features, statistical features, and other hidden image-based features. Next, we select the best feature combination from all the features and use the adaptive synthetic sampling approach to alleviate the uneven distribution of training data. Finally, a gradient boosting decision tree (GBDT) classifier for glaucoma screening is trained. Experimental results based on the ORIGA dataset show that the proposed algorithm achieves excellent glaucoma screening performance with sensitivity of 0.894, accuracy of 0.843, and AUC of 0.901, which is superior to other existing methods.","Glaucoma screening,Neural network,Image segmentation,Feature extraction",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"FEATURE-SELECTION,OPTIC,DISC,PREVALENCE,DIAGNOSIS",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
73,Efficient and Accurate Simulations of Vibrational and Electronic Spectra with Symmetry-Preserving Neural Network Models for Tensorial Properties,124,33,7284-7290,"Zhang Yaolong,Ye Sheng,Zhang Jinxiao,Hu Ce,Jiang Jun,Jiang Bin","Zhang YL,Ye S,Zhang JX,Hu C,Jiang J,Jiang B",Jiang B,10.1021/acs.jpcb.0c06926,Chinese Academy of Sciences,"Machine learning has revolutionized the high-dimensional representations for molecular properties such as potential energy. However, there are scarce machine learning models targeting tensorial properties, which are rotationally covariant. Here, we propose tensorial neural network (NN) models to learn both tensorial response and transition properties in which atomic coordinate vectors are multiplied with scalar NN outputs or their derivatives to preserve the rotationally covariant symmetry. This strategy keeps structural descriptors symmetry invariant so that the resulting tensorial NN models are as efficient as their scalar counterparts. We validate the performance and universality of this approach by learning response properties of water oligomers and liquid water and transition dipole moment of a model structural unit of proteins. Machine-learned tensorial models have enabled efficient simulations of vibrational spectra of liquid water and ultraviolet spectra of realistic proteins, promising feasible and accurate spectroscopic simulations for biomolecules and materials.",,Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,3.051,,JOURNAL OF PHYSICAL CHEMISTRY B,http://arxiv.org/pdf/2004.13605,
74,Machine learning enables completely automatic tuning of a quantum device faster than human experts,11,1,,"Moon H.,Lennon D. T.,Kirkpatrick J.,van Esbroeck N. M.,Camenzind L. C.,Yu Liuqi,Vigneau F.,Zumbuehl D. M.,Briggs G. A. D.,Osborne M. A.","Moon H,Lennon DT,Kirkpatrick J,van Esbroeck NM,Camenzind LC,Yu LQ,Vigneau F,Zumbuhl DM,Briggs GAD,Osborne MA",Ares N,10.1038/s41467-020-17835-9,University of Oxford,"Variability is a problem for the scalability of semiconductor quantum devices. The parameter space is large, and the operating range is small. Our statistical tuning algorithm searches for specific electron transport features in gate-defined quantum dot devices with a gate voltage space of up to eight dimensions. Starting from the full range of each gate voltage, our machine learning algorithm can tune each device to optimal performance in a median time of under 70 minutes. This performance surpassed our best human benchmark (although both human and machine performance can be improved). The algorithm is approximately 180 times faster than an automated random search of the parameter space, and is suitable for different material systems and device architectures. Our results yield a quantitative measurement of device variability, from one device to another and after thermal cycling. Our machine learning algorithm can be extended to higher dimensions and other technologies. To optimize operating conditions of large scale semiconductor quantum devices, a large parameter space has to be explored. Here, the authors report a machine learning algorithm to navigate the entire parameter space of gate-defined quantum dot devices, showing about 180 times faster than a pure random search.",,Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,15.805,,NATURE COMMUNICATIONS,https://eprints.lancs.ac.uk/id/eprint/145753/1/main_v8.pdf,
75,Physics-Based Approach for a Neural Networks Enabled Design of All-Dielectric Metasurfaces,7,8,1957-1964,"Tanriover Ibrahim,Hadibrata Wisnu,Aydin Koray","Tanriover I,Hadibrata W,Aydin K",Aydin K,10.1021/acsphotonics.0c00663,Northwestern University,"Machine learning methods have found novel application areas in various disciplines as they offer low computational cost solutions to complex problems. Recently, metasurface design has joined these applications, and neural networks enabled significant improvements within a short period of time. However, there are still outstanding challenges that need to be overcome. Here, we propose a data preprocessing approach based on the governing laws of the physical problem to eliminate dimensional mismatch between a high dimensional optical response and a low dimensional feature space of metasurfaces. We train forward and inverse models to predict optical responses of cylindrical meta-atoms and to retrieve their geometric parameters for a desired optical response, respectively. Our approach provides accurate prediction capability even outside the training spectral range. Finally, using our inverse model, we design and demonstrate a focusing metalens as a proof-of-concept application, thus, validating the capability of our proposed approach. We believe our method will pave the way toward practical learning-based models to solve more complicated photonic design problems.","deep learning,neural networks,metasurfaces,inverse design,all-dielectric",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science,Optics,Physics",,7.718,"BAND,ACHROMATIC,METALENS,POLARIZATION,RESOLUTION,LENSES",ACS PHOTONICS,http://arxiv.org/pdf/2004.10994,
76,Robust Freeform Metasurface Design Based on Progressively Growing Generative Networks,7,8,2098-2104,"Wen Fufang,Jiang Jiaqi,Fan Jonathan A.","Wen FF,Jiang JQ,Fan JA",Fan JA,10.1021/acsphotonics.0c00539,Stanford University,"A longstanding objective of machine learning-enabled inverse design is the realization of inverse neural networks that can instantaneously output a device given a desired optical function. For complex freeform devices, generative adversarial networks (GANs) can learn from images of freeform devices, but basic GAN architectures are unable to fully capture the intricate features of topologically complex structures. We show that by coupling progressive growth of the network architecture and training set with the GAN framework, generative networks can be trained to output high-performance, robust freeform metasurface devices. A combination of convolutional and self-attention layers in the network enable the accurate capture of both short- and long-range spatial patterns within topologically complex layouts. In applying this training methodology to metagratings, the best generated devices have efficiency and robustness metrics that compare with or outperform the best devices produced by gradient-based topology optimization with comparable computational cost. This study showcases the capability of generative neural networks to capture highly intricate geometric trends in physical devices, such as robustness constraints in freeform metasurfaces, and demonstrates their potential as black box inverse design tools for complex photonic technologies.","Generative adversarial networks,dielectric metasurfaces,metagrating progressive growth,self-attention,inverse design",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science,Optics,Physics",,7.718,"INVERSE,DESIGN",ACS PHOTONICS,,
77,Elucidating the Behavior of Nanophotonic Structures through Explainable Machine Learning Algorithms,7,8,2309-2318,"Yeung Christopher,Tsai Ju-Ming,King Brian,Kawagoe Yusaku,Ho David,Knight Mark W.,Raman Aaswath P.","Yeung C,Tsai JM,King B,Kawagoe Y,Ho D,Knight MW,Raman AP",Raman AP,10.1021/acsphotonics.0c01067,University of California System,"A central challenge in the development of nanophotonic structures is identifying the optimal design for a target functionality, and understanding the physical mechanisms that enable the optimized device's capabilities. Previously investigated design methods for nanophotonic structures, including both conventional optimization approaches as well as nascent machine learning (ML) strategies have made progress, yet they remain ""black boxes"" that lack explanations for their predictions. Here we demonstrate that convolutional neural networks (CNN) trained to predict the electromagnetic response of classes of metaldielectric-metal metamaterials, including complex freeform designs, can be explained to reveal deeper insights into the underlying physics of nanophotonic structures. Using an explainable AI (XAI) approach, we show that we can identify the importance of specific spatial regions of a nanophotonic structure for the presence or lack of an absorption peak. Our results highlight that ML strategies can be used for physics discovery, as well as design optimization, in optics and photonics.","nanophotonics,machine learning,explainability,nanoscale optics,metamaterials,convolutional neural networks",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science,Optics,Physics",,7.718,"NEURAL-NETWORKS,INVERSE,DESIGN,BLACK-BOX,METASURFACES",ACS PHOTONICS,http://arxiv.org/pdf/2003.06075,
78,Three-dimensional reconstruction of porous polymer films from FIB-SEM nanotomography data using random forests,281,1,76-86,"Roding M.,Fager C.,Olsson A.,Von Corswant C.,Olsson E.,Loren N.","Roding M,Fager C,Olsson A,Von Corswant C,Olsson E,Loren N",Roding M,10.1111/jmi.12950,RISE Research Institutes of Sweden,"Combined focused ion beam and scanning electron microscope (FIB-SEM) tomography is a well-established technique for high resolution imaging and reconstruction of the microstructure of a wide range of materials. Segmentation of FIB-SEM data is complicated due to a number of factors; the most prominent is that for porous materials, the scanning electron microscope image slices contain information not only from the planar cross-section of the material but also from underlying, exposed subsurface pores. In this work, we develop a segmentation method for FIB-SEM data from ethyl cellulose porous films made from ethyl cellulose and hydroxypropyl cellulose (EC/HPC) polymer blends. These materials are used for coating pharmaceutical oral dosage forms (tablets or pellets) to control drug release. We study three samples of ethyl cellulose and hydroxypropyl cellulose with different volume fractions where the hydroxypropyl cellulose phase has been leached out, resulting in a porous material. The data are segmented using scale-space features and a random forest classifier. We demonstrate good agreement with manual segmentations. The method enables quantitative characterization and subsequent optimization of material structure for controlled release applications. Although the methodology is demonstrated on porous polymer films, it is applicable to other soft porous materials imaged by FIB-SEM. We make the data and software used publicly available to facilitate further development of FIB-SEM segmentation methods. Lay Description For imaging of very fine structures in materials, the resolution limits of, e.g. X-ray computed tomography quickly become a bottleneck. Scanning electron microscopy (SEM) provides a way out, but it is essentially a two-dimensional imaging technique. One manner in which to extend it to three dimensions is to use a focused ion beam (FIB) combined with a scanning electron microscopy and acquire tomography data. In FIB-SEM tomography, ions are used to perform serial sectioning and the electron beam is used to image the cross section surface. This is a well-established method for a wide range of materials. However, image analysis of FIB-SEM data is complicated for a variety of reasons, in particular for porous media. In this work, we analyse FIB-SEM data from ethyl cellulose porous films made from ethyl cellulose and hydroxypropyl cellulose (EC/HPC) polymer blends. These films are used as coatings for controlled drug release. The aim is to perform image segmentation, i.e. to identify which parts of the image data constitute the pores and the solid, respectively. Manual segmentation, i.e. when a trained operator manually identifies areas constituting pores and solid, is too time-consuming to do in full for our very large data sets. However, by performing manual segmentation on a set of small, random regions of the data, we can train a machine learning algorithm to perform automatic segmentation on the entire data sets. The method yields good agreement with the manual segmentations and yields porosities of the entire data sets in very good agreement with expected values. The method facilitates understanding and quantitative characterization of the geometrical structure of the materials, and ultimately understanding of how to tailor the drug release.","Controlled drug release,FIB-SEM,Image analysis,Machine learning,Microstructure,Polymer films,Porous materials,Random forest,Segmentation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Microscopy,,1.855,"SEGMENTATION,ALGORITHMS,FIB%2FSEM,IMAGES",JOURNAL OF MICROSCOPY,https://research.chalmers.se/publication/518954/file/518954_Fulltext.pdf,
79,Efficient fusion of handcrafted and pre-trained CNNs features to classify melanoma skin cancer,79,41-42,31219-31238,"Filali Youssef,EL Khoukhi Hasnae,Sabri My Abdelouahed,Aarab Abdellah","Filali Y,EL Khoukhi H,Sabri MA,Aarab A",Filali Y,10.1007/s11042-020-09637-4,Sidi Mohamed Ben Abdellah University of Fez,"Skin cancer is one of the most aggressive cancers in the world. Computer-Aided Diagnosis (CAD) system for cancer detection and classification is a top-rated solution that decreases human effort and time with very high classification accuracy. Machine learning (ML) and deep learning (DL) based approaches have been widely used to develop robust skin-lesion classification systems. Each of the techniques excels when the other fails. Their performances are closely related to the size of the learning dataset. Thus, approaches that are based on the ML are less potent than those found on the DL when working with large datasets and vice versa. In this article, we propose a powerful skin-lesion classification approach based on a fusion of handcrafted features (shape, skeleton, color, and texture) and features extracted from most powerful DL architectures. This combination will make it possible to remedy the limitations of both the ML and DL approaches for the case of large and small datasets. Features engineering is then applied to remove redundant features and to select only relevant features. The proposed approach is validated and tested on both small and large datasets. A comparative study is also conducted to compare the proposed approach with different and recent approaches applied to each dataset. The results obtained show that this features-fusion based approach is very promising and can effectively combine the power of ML and DL based approaches.","Skin cancer,Melanoma,Handcrafted features,CNNs,Features fusion,Genetic algorithm",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,,"CLASSIFICATION,SEGMENTATION,LESIONS,DIAGNOSIS",MULTIMEDIA TOOLS AND APPLICATIONS,,
80,Differentiating novel coronavirus pneumonia from general pneumonia based on machine learning,19,1,,"Liu Chenglong,Wang Xiaoyang,Liu Chenbin,Sun Qingfeng,Peng Wenxian","Liu CL,Wang XY,Liu CB,Sun QF,Peng WX",Peng WX,10.1186/s12938-020-00809-9,"Shanghai Univ Med & Hlth Sci, Coll Med Imaging, Shanghai 201318, Peoples R China.","Background Chest CT screening as supplementary means is crucial in diagnosing novel coronavirus pneumonia (COVID-19) with high sensitivity and popularity. Machine learning was adept in discovering intricate structures from CT images and achieved expert-level performance in medical image analysis. Methods An integrated machine learning framework on chest CT images for differentiating COVID-19 from general pneumonia (GP) was developed and validated. Seventy-three confirmed COVID-19 cases were consecutively enrolled together with 27 confirmed general pneumonia patients from Ruian People's Hospital, from January 2020 to March 2020. To accurately classify COVID-19, region of interest (ROI) delineation was implemented based on ground-glass opacities (GGOs) before feature extraction. Then, 34 statistical texture features of COVID-19 and GP ROI images were extracted, including 13 gray-level co-occurrence matrix (GLCM) features, 15 gray-level-gradient co-occurrence matrix (GLGCM) features and 6 histogram features. High-dimensional features impact the classification performance. Thus, ReliefF algorithm was leveraged to select features. The relevance of each feature was the average weights calculated by ReliefF in n times. Features with relevance larger than the empirically set threshold T were selected. After feature selection, the optimal feature set along with 4 other selected feature combinations for comparison were applied to the ensemble of bagged tree (EBT) and four other machine learning classifiers including support vector machine (SVM), logistic regression (LR), decision tree (DT), and K-nearest neighbor with Minkowski distance equal weight (KNN) using tenfold cross-validation. Results and conclusions The classification accuracy (ACC), sensitivity (SEN), specificity (SPE) of our proposed method yield 94.16%, 88.62% and 100.00%, respectively. The area under the receiver operating characteristic curve (AUC) was 0.99. The experimental results indicate that the EBT algorithm with statistical textural features based on GGOs for differentiating COVID-19 from general pneumonia achieved high transferability, efficiency, specificity, sensitivity, and impressive accuracy, which is beneficial for inexperienced doctors to more accurately diagnose COVID-19 and essential for controlling the spread of the disease.","Machine learning,Novel coronavirus pneumonia,General pneumonia,Chest CT",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Engineering,,2.905,"RADIOLOGICAL,FINDINGS,COVID-19,PNEUMONIA,CLINICAL-FEATURES,DIAGNOSIS",BIOMEDICAL ENGINEERING ONLINE,https://www.researchsquare.com/article/rs-31313/v1.pdf?c=1590802333000,
81,Multiclass machine learning classification of functional brain images for Parkinson's disease stage prediction,13,5,508-523,"Huang Guan-Hua,Lin Chih-Hsuan,Cai Yu-Ren,Chen Tai-Been,Hsu Shih-Yen,Lu Nan-Han,Chen Huei-Yung,Wu Yi-Chen","Huang GH,Lin CH,Cai YR,Chen TB,Hsu SY,Lu NH,Chen HY,Wu YC",Huang GH,10.1002/sam.11480,National Yang Ming Chiao Tung University,"We analyzed a data set containing functional brain images from 6 healthy controls and 196 individuals with Parkinson's disease (PD), who were divided into five stages according to illness severity. The goal was to predict patients' PD illness stages by using their functional brain images. We employed the following prediction approaches: multivariate statistical methods (linear discriminant analysis, support vector machine, decision tree, and multilayer perceptron [MLP]), ensemble learning models (random forest [RF] and adaptive boosting), and deep convolutional neural network (CNN). For statistical and ensemble models, various feature extraction approaches (principal component analysis [PCA], multilinear PCA, intensity summary statistics [IStat], and Laws' texture energy measure) were employed to extract features, the synthetic minority over-sampling technique was used to address imbalanced data, and the optimal combination of hyperparameters was found using a grid search. For CNN modeling, we applied an image augmentation technique to increase and balance data sizes over different disease stages. We adopted transfer learning to incorporate pretrained VGG16 weights and architecture into the model fitting, and we also tested a state-of-the-art machine learning model that could automatically generate an optimal neural architecture. We found that IStat consistently outperformed other feature extraction approaches. MLP and RF were the analytic approaches with the highest prediction accuracy rate for multivariate statistical and ensemble learning models, respectively. Overall, the deep CNN model with pretrained VGG16 weights and architecture outperformed other approaches; it captured critical features from imaging, effectively distinguished between normal controls and patients with PD, and achieved the highest classification accuracy.","deep neural network,functional brain image,machine learning,supervised classification",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Computer Science,Mathematics",,1.55,"AUTOMATIC,CLASSIFICATION,SHAPE-ANALYSIS,SPECT,DIAGNOSIS,TOMOGRAPHY",STATISTICAL ANALYSIS AND DATA MINING,,
82,Extracting diffusion tensor fractional anisotropy and mean diffusivity from 3-direction DWI scans using deep learning,85,2,845-854,"Aliotta Eric,Nourzadeh Hamidreza,Patel Sohil H.","Aliotta E,Nourzadeh H,Patel SH",Aliotta E,10.1002/mrm.28470,University of Virginia,"Purpose To develop and evaluate machine-learning methods that reconstruct fractional anisotropy (FA) values and mean diffusivities (MD) from 3-direction diffusion MRI (dMRI) acquisitions. Methods Two machine-learning models were implemented to map undersampled dMRI signals with high-quality FA and MD maps that were reconstructed from fully sampled DTI scans. The first model was a previously described multilayer perceptron (MLP), which maps signals and FA/MD values from a single voxel. The second was a convolutional neural network U-Net model, which maps dMRI slices to full FA/MD maps. Each method was trained on dMRI brain scans (N = 46), and reconstruction accuracies were compared with conventional linear-least-squares (LLS) reconstructions. Results In an independent testing cohort (N = 20), 3-direction U-Net reconstructions had significantly lower absolute FA error than both 3-direction MLP (U-Net(3-dir): 0.06 +/- 0.01 vs. MLP3-dir: 0.08 +/- 0.01,P< 1 x 10(-5)) and 6-direction LLS (LLS6-dir: 0.09 +/- 0.03,P= 1 x 10(-5)). The MD errors were not significantly different among 3-direction MLP (0.06 +/- 0.01 x 10(-3)mm(2)/s), 3-direction U-Net (0.06 +/- 0.01 x 10(-3)mm(2)/s), and 6-direction LLS (0.07 +/- 0.02 x 10(-3)mm(2)/s,P> .1). Conclusion The proposed U-Net model reconstructed FA from 3-direction dMRI scans with improved accuracy compared with both a previously described MLP approach and LLS fitting from 6-direction scans. The MD reconstruction accuracies did not differ significantly between reconstructions.","deep learning,diffusion tensor imaging,diffusion-weighted imaging",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"IMAGING,MATHEMATICS,GRADE",MAGNETIC RESONANCE IN MEDICINE,,
83,COVID-19 Deep Learning Prediction Model Using Publicly Available Radiologist-Adjudicated Chest X-Ray Images as Training Data: Preliminary Findings,2020,,,"Azemin Mohd Zulfaezal Che,Hassan Radhiana,Tamrin Mohd Izzuddin Mohd,Ali Mohd Adli Md","Azemin MZC,Hassan R,Tamrin MIM,Ali MAM",Azemin MZC,10.1155/2020/8828855,International Islamic University Malaysia,"The key component in deep learning research is the availability of training data sets. With a limited number of publicly available COVID-19 chest X-ray images, the generalization and robustness of deep learning models to detect COVID-19 cases developed based on these images are questionable. We aimed to use thousands of readily available chest radiograph images with clinical findings associated with COVID-19 as a training data set, mutually exclusive from the images with confirmed COVID-19 cases, which will be used as the testing data set. We used a deep learning model based on the ResNet-101 convolutional neural network architecture, which was pretrained to recognize objects from a million of images and then retrained to detect abnormality in chest X-ray images. The performance of the model in terms of area under the receiver operating curve, sensitivity, specificity, and accuracy was 0.82, 77.3%, 71.8%, and 71.9%, respectively. The strength of this study lies in the use of labels that have a strong clinical association with COVID-19 cases and the use of mutually exclusive publicly available data for training, validation, and testing.",,Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Engineering,,,,INTERNATIONAL JOURNAL OF BIOMEDICAL IMAGING,https://downloads.hindawi.com/journals/ijbi/2020/8828855.pdf,
84,,,,,,,,,,,,,,,,,,,,
85,,,,,,,,,,,,,,,,,,,,
86,An association between fingerprint patterns with blood group and lifestyle based diseases: a review,54,3,1803-1839,"Patil Vijaykumar,Ingle D. R.","Patil V,Ingle DR",Patil V,10.1007/s10462-020-09891-w,Bharati Vidyapeeth Deemed University,"In the current era of the digital world, the hash of any digital means considered as a footprint or fingerprint of any digital term but from the ancient era, human fingerprint considered as the most trustworthy criteria for identification and it also cannot be changed with time even up to the death of an individual. In the court of law, fingerprint-proof is undeniably the most dependable and acceptable evidence to date. Fingerprint designs are exclusive in each human and the chance of two individuals having identical fingerprints is an exceptional case about one in sixty-four thousand million also the fingerprint minutiae patterns of the undistinguishable twins are different, and the ridge pattern of each fingertip remain unchanged from birth to till death. Fingerprints can be divided into basic four categories i.e. Loop, whorl, arch, and composites, nevertheless, there are more than 100 interleaved ridge and valleys physiognomies, called Galton's details, in a single rolled fingerprint. Due to the immense potential of fingerprints as an effective method of identification, the present research paper tries to investigate the problem of blood group identification and analysis of diseases those arises with aging like hypertension, type 2-diabetes and arthritis from a fingerprint by analyzing their patterns correlation with blood group and age of an individual. The work has been driven by studies of anthropometry, biometric trademark, and pattern recognition proposing that it is possible to predict blood group using fingerprint map reading. Dermatoglyphics as a diagnostic aid used from ancient eras and now it is well established in number of diseases which have strong hereditary basis and is employed as a method for screening for abnormal anomalies. Apart from its use in predicting the diagnosis of disease; dermatoglyphics is also used in forensic medicine in individual identification, physical anthropology, human genetics and medicine. However, the Machine and Deep Learning techniques, if used for fingerprint minutiae patterns to be trained by Neural Network for blood group prediction and classification of common clinical diseases arises with aging based on lifestyle would be an unusual research work.","ABO typing,Blood groups,Fingerprint map reading,Machine learning,Deep leaning,Artificial intelligence",Review,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,7.857,"DERMATOGLYPHIC,PATTERNS,AGGLUTINATION,DETECTION,DIABETES-MELLITUS,HYPERTENSION,DEVICE,GENDER",ARTIFICIAL INTELLIGENCE REVIEW,https://link.springer.com/content/pdf/10.1007/s10462-020-09891-w.pdf,
87,High-throughput computational design of halide perovskites and beyond for optoelectronics,11,3,,"Li Yuheng,Yang Kesong","Li YH,Yang KS",Yang KS,10.1002/wcms.1500,University of California System,"Halide perovskites have attracted great interest as promising next-generation materials in optoelectronics, ranging from solar cells to light-emitting diodes. Despite their exceptional optoelectronic properties and low cost, the prototypical organic-inorganic hybrid lead halide perovskites suffer from toxicity and low stability. Therefore, it is of high demand to search for stable and nontoxic alternatives to the hybrid lead halide perovskites. Recently, high-throughput computational materials design has emerged as a powerful approach to accelerate the discovery of new halide perovskite compositions or even novel compounds beyond perovskites. In this review, we discuss how this approach discovers halide perovskites and beyond for optoelectronics. We first overview the background of halide perovskites and methodologies in high-throughput computational design. Then, we focus on materials properties for different optoelectronic applications, and how they are assessed with materials descriptors. Finally, we review different studies in terms of specific materials types to discuss their design principles, screening results, and experimental verification. This article is categorized under: Structure and Mechanism > Computational Materials Science Electronic Structure Theory > Density Functional Theory","computational materials design,high-throughput,light-emitting,machine learning,perovskite,solar cell",Review,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Chemistry,Mathematical & Computational Biology",,16.743,"ORGANIC-INORGANIC,PEROVSKITES,LEAD-FREE,PEROVSKITES,SOLAR-CELLS,RATIONAL,DESIGN,COLLOIDAL,NANOCRYSTALS,IODIDE,PEROVSKITE,PHASE-TRANSITIONS,POINT-DEFECTS,SEMICONDUCTORS,LIGHT",WILEY INTERDISCIPLINARY REVIEWS-COMPUTATIONAL MOLECULAR SCIENCE,https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/wcms.1500,
88,Atom Probe Mass Spectrometry of Uranium Isotopic Reference Materials,92,16,11388-11395,"Meisenkothen Frederick,McLean Mark,Kalish Irina,Samarov Daniel V.,Steel Eric B.","Meisenkothen F,McLean M,Kalish I,Samarov DV,Steel EB",Meisenkothen F,10.1021/acs.analchem.0c02273,National Institute of Standards & Technology (NIST) - USA,"Atom probe tomography (APT)-based isotopic analyses are becoming increasingly attractive for analysis applications requiring small volumes of material and sub-micrometer length scales, such as isotope geochemistry, nuclear safety, and materials science. However, there is an open question within the atom probe community as to the reliability of atom probe isotopic and elemental analyses. Using our proposed analysis guidelines, in conjunction with an empirical calibration curve and a machine learning-based adaptive peak fitting algorithm, we demonstrate accurate and repeatable uranium isotopic analyses, via atom probe mass spectrometry, on U(3)O(8 )isotopic reference materials. By using isotopic reference materials, each measured isotopic abundance value could be directly compared to a known certified reference value to permit a quantitative statement of accuracy. The isotopic abundance measurements for U-235 and U-238 in each individual APT sample were consistently within +/- 1.5% relative to the known reference values. The accuracy and repeatability are approaching values consistent with measurements limited primarily by Poisson counting statistics, i.e., the number of uranium atoms recorded.","TOMOGRAPHY,STATE",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,6.755,"TOMOGRAPHY,STATE",ANALYTICAL CHEMISTRY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7470433,
89,Machine learning is a valid method for predicting prehospital delay after acute ischemic stroke,10,10,,"Yang Li,Liu Qinqin,Zhao Qiuli,Zhu Xuemei,Wang Ling","Yang L,Liu QQ,Zhao QL,Zhu XM,Wang L",Liu QQ; Zhao QL,10.1002/brb3.1794,Harbin Medical University,"Objectives This study aimed to identify the influencing factors associated with long onset-to-door time and establish predictive models that could help to assess the probability of prehospital delay in populations with a high risk for stroke. Materials and Methods Patients who were diagnosed with acute ischemic stroke (AIS) and hospitalized between 1 November 2018 and 31 July 2019 were interviewed, and their medical records were extracted for data analysis. Two machine learning algorithms (support vector machine and Bayesian network) were applied in this study, and their predictive performance was compared with that of the classical logistic regression models after using several variable selection methods. Timely admission (onset-to-door time < 3 hr) and prehospital delay (onset-to-door time >= 3 hr) were the outcome variables. We computed the area under curve (AUC) and the difference in the mean AUC values between the models. Results A total of 450 patients with AIS were enrolled; 57 (12.7%) with timely admission and 393 (87.3%) patients with prehospital delay. All models, both those constructed by logistic regression and those by machine learning, performed well in predicting prehospital delay (range mean AUC: 0.800-0.846). The difference in the mean AUC values between the best performing machine learning model and the best performing logistic regression model was negligible (0.014; 95% CI: 0.013-0.015). Conclusions Machine learning algorithms were not inferior to logistic regression models for prediction of prehospital delay after stroke. All models provided good discrimination, thereby creating valuable diagnostic programs for prehospital delay prediction.","acute ischemic stroke,Bayesian network,machine learning,prehospital delay,support vector machine",Article,"WILEY, 111 RIVER ST, HOBOKEN, NJ 07030 USA","Behavioral Sciences,Neurosciences & Neurology",,2.997,"THROMBOLYSIS,GUIDELINES,MANAGEMENT,MORTALITY",BRAIN AND BEHAVIOR,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/brb3.1794,
90,Multi-Variate vocal data analysis for Detection of Parkinson disease using Deep Learning,33,10,4849-4864,"Nagasubramanian Gayathri,Sankayya Muthuramalingam","Nagasubramanian G,Sankayya M",Nagasubramanian G,10.1007/s00521-020-05233-7,"GGR Coll Engn, Dept Comp Sci & Engn, Vellore, Tamil Nadu, India.","Machine learning (ML) and Deep learning (DL) methods are differently implemented with various decision-making abilities. Particularly, the usage of ML and DL techniques in disease detection is inevitable in the near future. This work uses the ability of acoustic-based DL techniques for detecting Parkinson disease symptoms. This disease can be identified by many DL techniques such as deep knowledge creation networks and recurrent networks. The proposed Deep Multi-Variate Vocal Data Analysis (DMVDA) System has been designed and implemented using Acoustic Deep Neural Network (ADNN), Acoustic Deep Recurrent Neural Network (ADRNN), and Acoustic Deep Convolutional Neural Network (ADCNN). Further, DMVDA has been specially developed with absolute multi-variate speech attribute processing algorithm for effective value creation. In order to improve the benefits of this speech-processing algorithm, the DMVDA has acoustic data sampling procedures. The DL techniques introduced in this work helps to identify Parkinson symptoms by analyzing the heterogeneous dataset. The integration of these techniques produces nominal 3% increase in the performance than the existing techniques.","Parkinson,Disease detection,Acoustic data,Machine learning,Deep learning",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,,,NEURAL COMPUTING & APPLICATIONS,,
91,Deep learning-based fetoscopic mosaicking for field-of-view expansion,15,11,1807-1816,"Bano Sophia,Vasconcelos Francisco,Tella-Amo Marcel,Dwyer George,Gruijthuijsen Caspar,Vander Poorten Emmanuel,Vercauteren Tom,Ourselin Sebastien,Deprest Jan,Stoyanov Danail","Bano S,Vasconcelos F,Tella-Amo M,Dwyer G,Gruijthuijsen C,Vander Poorten E,Vercauteren T,Ourselin S,Deprest J,Stoyanov D",Bano S,10.1007/s11548-020-02242-8,UK Research & Innovation (UKRI),"Purpose Fetoscopic laser photocoagulation is a minimally invasive surgical procedure used to treat twin-to-twin transfusion syndrome (TTTS), which involves localization and ablation of abnormal vascular connections on the placenta to regulate the blood flow in both fetuses. This procedure is particularly challenging due to the limited field of view, poor visibility, occasional bleeding, and poor image quality. Fetoscopic mosaicking can help in creating an image with the expanded field of view which could facilitate the clinicians during the TTTS procedure. Methods We propose a deep learning-based mosaicking framework for diverse fetoscopic videos captured from different settings such as simulation, phantoms, ex vivo, and in vivo environments. The proposed mosaicking framework extends an existing deep image homography model to handle video data by introducing the controlled data generation and consistent homography estimation modules. Training is performed on a small subset of fetoscopic images which are independent of the testing videos. Results We perform both quantitative and qualitative evaluations on 5 diverse fetoscopic videos (2400 frames) that captured different environments. To demonstrate the robustness of the proposed framework, a comparison is performed with the existing feature-based and deep image homography methods. Conclusion The proposed mosaicking framework outperformed existing methods and generated meaningful mosaic, while reducing the accumulated drift, even in the presence of visual challenges such as specular highlights, reflection, texture paucity, and low video resolution.","Deep learning,Surgical vision,Twin-to-twin transfusion syndrome (TTTS),Fetoscopy,Sequential mosaicking",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,,INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,https://discovery.ucl.ac.uk/id/eprint/10108691/1/s11548-020-02242-8.pdf,
92,"Analysis on diagnosing diabetic retinopathy by segmenting blood vessels, optic disc and retinal abnormalities.",44,6,299-316,",,","Jadhav Ambaji S,Patil Pushpa B,Biradar Sunil",,10.1080/03091902.2020.1791986,,,Diabetic retinopathy detection; blood vessels; optic disc; retinal abnormalities; trial-Based Bypass Improved Dragonfly Algorithm,Journal Article; Review,,,,,,,,
93,,,,,,,,,,,,,,,,,,,,
94,Breast cancer masses classification using deep convolutional neural networks and transfer learning,79,41-42,30735-30768,"Hassan Shayma'a A.,Sayed Mohammed S.,Abdalla Mahmoud I,Rashwan Mohsen A.","Hassan SA,Sayed MS,Abdalla MI,Rashwan MA",Hassan SA,10.1007/s11042-020-09518-w,Egyptian Knowledge Bank (EKB),"With the recent advances in the deep learning field, the use of deep convolutional neural networks (DCNNs) in biomedical image processing becomes very encouraging. This paper presents a new classification model for breast cancer masses based on DCNNs. We investigated the use of transfer learning from AlexNet and GoogleNet pre-trained models to suit this task. We experimentally determined the best DCNN model for accurate classification by comparing different models, which vary according to the design and hyper-parameters. The effectiveness of these models were demonstrated using four mammogram databases. All models were trained and tested using a mammographic dataset from CBIS-DDSM and INbreast databases to select the best AlexNet and GoogleNet models. The performance of the two proposed models was further verified using images from Egyptian National Cancer Institute (NCI) and MIAS database. When tested on CBIS-DDSM and INbreast databases, the proposed AlexNet model achieved an accuracy of 100% for both databases. While, the proposed GoogleNet model achieved accuracy of 98.46% and 92.5%, respectively. When tested on NCI images and MIAS databases, AlexNet achieved an accuracy of 97.89% with AUC of 98.32%, and accuracy of 98.53% with AUC of 98.95%, respectively. GoogleNet achieved an accuracy of 91.58% with AUC of 96.5%, and accuracy of 88.24% with AUC of 94.65%, respectively. These results suggest that AlexNet has better performance and more robustness than GoogleNet. To the best of our knowledge, the proposed AlexNet model outperformed the latest methods. It achieved the highest accuracy and AUC score and the lowest testing time reported on CBIS-DDSM, INbreast and MIAS databases.","Mammogram images,Computer-aided diagnosis,Mass classification,Deep learning,Transfer learning,Deep convolutional neural network",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"COMPUTER-AIDED,DIAGNOSIS,DIGITAL,MAMMOGRAMS,SYSTEM",MULTIMEDIA TOOLS AND APPLICATIONS,,
95,A comparison of regularized logistic regression and random forest machine learning models for daytime diagnosis of obstructive sleep apnea,58,10,2517-2529,"Hajipour Farahnaz,Jozani Mohammad Jafari,Moussavi Zahra","Hajipour F,Jozani MJ,Moussavi Z",Hajipour F,10.1007/s11517-020-02206-9,University of Manitoba,"A major challenge in big and high-dimensional data analysis is related to the classification and prediction of the variables of interest by characterizing the relationships between the characteristic factors and predictors. This study aims to assess the utility of two important machine-learning techniques to classify subjects with obstructive sleep apnea (OSA) using their daytime tracheal breathing sounds. We evaluate and compare the performance of the random forest (RF) and regularized logistic regression (LR) as feature selection tools and classification approaches for wakefulness OSA screening. Results show that the RF, which is a low-variance committee-based approach, outperforms the regularized LR in terms of blind-testing accuracy, specificity, and sensitivity with 3.5%, 2.4%, and 3.7% improvement, respectively. However, the regularized LR was found to be faster than the RF and resulted in a more parsimonious model. Consequently, both the RF and regularized LR feature reduction and classification approaches are qualified to be applied for the daytime OSA screening studies, depending on the nature of data and applications' purposes.","Feature selection,Classification,Regularized logistic regression,LASSO,Random forest,Obstructive sleep apnea",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"UPPER,AIRWAY,BIG,DATA,ANALYTICS,SELECTION,ANATOMY,LASSO",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
96,A surrogate model approach for associating wind farm load variations with turbine failures,5,3,1007-1022,"Schroder Laura,Dimitrov Nikolay Krasimirov,Verelst David Robert","Schroder L,Dimitrov NK,Verelst DR",Schroder L,10.5194/wes-5-1007-2020,Technical University of Denmark,"In order to ensure structural reliability, wind turbine design is typically based on the assumption of gradual degradation of material properties (fatigue loading). Nevertheless, the relation between the wake-induced load exposure of turbines and the reliability of their major components has not been sufficiently well defined and demonstrated. This study suggests a methodology that makes it possible to correlate loads with reliability of turbines in wind farms in a computationally efficient way by combining physical modeling with machine learning. It can be used for estimating the current health state of a turbine and enables a more precise prediction of the ""load budget"", i.e., the effect of load-induced degradation and faults on the operating costs of wind farms. The suggested approach is demonstrated on an offshore wind farm for comparing performance, loads and lifetime estimations against recorded main bearing failures from maintenance reports. The validation of the estimated power against the 10 min supervisory control and data acquisition (SCADA) power signals shows that the surrogate model is able to capture the power performance relatively well with a 1.5% average error in the prediction of the annual energy production (AEP). It is found that turbines positioned at the border of the wind farm with a higher expected AEP are estimated to experience earlier main bearing failures. However, a clear connection between the load estimations and failure observations could not be confirmed in this study. Finally, the analysis stresses that more failure data are required in future work to enable statistically significant associations of the observed main bearing lifetimes with load exposures across the wind farm and to validate and generalize the suggested approach and its associated findings.",RELIABILITY,Article,"COPERNICUS GESELLSCHAFT MBH, BAHNHOFSALLEE 1E, GOTTINGEN, 37081, GERMANY",Science & Technology - Other Topics,,,RELIABILITY,WIND ENERGY SCIENCE,https://backend.orbit.dtu.dk/ws/files/223407723/wes_5_1007_2020.pdf,
97,Prediction of residual stress in electron beam welding of stainless steel from process parameters and natural frequency of vibrations using machine-learning algorithms,235,11,2008-2021,"Das Debasish,Das Amit Kr,Pratihar D. K.,Roy G. G.","Das D,Das AK,Pratihar DK,Roy GG",Pratihar DK,10.1177/0954406220950343,Indian Institute of Technology System (IIT System),"In the present study, machine learning algorithms have been used to predict residual stress during electron beam welding of stainless steel using the information of input process parameters and natural frequency of vibrations. Accelerating voltage, beam current and welding speed have been considered as input process parameters. Both residual stress and natural frequencies of vibration of the weld obtained using each set of the input parameters are measured experimentally. A number of machine learning algorithms, namely M5 algorithm-based Model Trees Regression, Random forest, Support Vector Regression, Reduced Error Pruning Tree, Multi-layer perceptron, Instance-based k-nearest neighbor algorithm, and Locally weighted learning have been used for the said purpose. Support vector regression and Locally weighted learning are found to perform consistently good and bad, respectively. The predicted welding residual stresses have been validated experimentally through X-ray diffraction (XRD) and good agreements are obtained. In addition, statistical tests are conducted, and the estimated reliability values of the employed models are analyzed through Monte-Carlo simulations.","Electron beam welding,welding residual stresses,natural frequencies,Monte-Carlo simulations",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Engineering,,1.606,"FINITE-ELEMENT-METHOD,NEURAL-NETWORKS,DISSIMILAR,METALS,RANDOM,FOREST,QUALITY,IDENTIFICATION,DISTRIBUTIONS,OPTIMIZATION,PENETRATION,STRENGTH",PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART C-JOURNAL OF MECHANICAL ENGINEERING SCIENCE,,
98,Global Atmospheric Budget of Acetone: Air-Sea Exchange and the Contribution to Hydroxyl Radicals,125,15,,"Wang Siyuan,Apel Eric C.,Schwantes Rebecca H.,Bates Kelvin H.,Jacob Daniel J.,Fischer Emily V,Hornbrook Rebecca S.,Hills Alan J.,Emmons Louisa K.,Pan Laura L.","Wang SY,Apel EC,Schwantes RH,Bates KH,Jacob DJ,Fischer EV,Hornbrook RS,Hills AJ,Emmons LK,Pan LL",Wang SY,10.1029/2020JD032553,National Center Atmospheric Research (NCAR) - USA,"Acetone is one of the most abundant oxygenated volatile organic compounds (VOCs) in the atmosphere. The oceans impose a strong control on atmospheric acetone, yet the oceanic fluxes of acetone remain poorly constrained. In this work, the global budget of acetone is evaluated using two global models: CAM-chem and GEOS-Chem. CAM-chem uses an online air-sea exchange framework to calculate the bidirectional oceanic acetone fluxes, which is coupled to a data-oriented machine-learning approach. The machine-learning algorithm is trained using a global suite of seawater acetone measurements. GEOS-Chem uses a fixed surface seawater concentration of acetone to calculate the oceanic fluxes. Both model simulations are compared to airborne observations from a recent global-scale, multiseasonal campaign, the NASA Atmospheric Tomography Mission (ATom). We find that both CAM-chem and GEOS-Chem capture the measured acetone vertical distributions in the remote atmosphere reasonably well. The combined observational and modeling analysis suggests that (i) the ocean strongly regulates the atmospheric budget of acetone. The tropical and subtropical oceans are mostly a net source of acetone, while the high-latitude oceans are a net sink. (ii) CMIP6 anthropogenic emission inventory may underestimate acetone and/or its precursors in the Northern Hemisphere. (iii) The MEGAN biogenic emissions model may overestimate acetone and/or its precursors, and/or the biogenic oxidation mechanisms may overestimate the acetone yields. (iv) The models consistently overestimate acetone in the upper troposphere-lower stratosphere over the Southern Ocean in austral winter. (v) Acetone contributes up to 30-40% of hydroxyl radical production in the tropical upper troposphere/lower stratosphere.
Plain Language Summary Acetone is widely observed in the Earth's atmosphere, with mixing ratios ranging from parts-per-trillion levels in the stratosphere to parts-per-billion levels in polluted regions. Acetone is directly emitted from a wide variety of natural and anthropogenic sources and is also produced from the photochemical oxidation of a number of precursors. The role of the ocean is complicated; acetone is produced in the ocean from the photolysis of colored dissolved organic materials or from biological processes but is also removed via microbial uptake. Previous studies have found that the direction and magnitude of oceanic acetone fluxes vary dramatically with seasons and locations. In this work, we use a data-oriented machine-learning approach to predict the surface seawater concentration of acetone, leveraging in situ acetone measurements in the surface seawater around the globe. This machine learning-based approach shows promising potential and can be expanded to the bottom-up oceanic emissions of other climate-relevant compounds.","acetone,air-sea exchange,machine learning,HOx radicals",Article,"AMER GEOPHYSICAL UNION, 2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA",Meteorology & Atmospheric Sciences,,4.626,"CASCADE,LASER,SPECTROMETER,VOLATILE,ORGANIC-COMPOUNDS,TROPICAL,TROPOPAUSE,LAYER,LOWER,STRATOSPHERE,CARBONYL-COMPOUNDS,UPPER,TROPOSPHERE,GAS-EXCHANGE,CHEMISTRY,MODEL,EMISSIONS",JOURNAL OF GEOPHYSICAL RESEARCH-ATMOSPHERES,https://digitalcommons.chapman.edu/cgi/viewcontent.cgi?article=1261&context=sees_articles,
99,A machine learning framework for drop-in volume swell characteristics of sustainable aviation fuel,274,,,"Kosir Shane,Heyne Joshua,Graham John","Kosir S,Heyne J,Graham J",Kosir S,10.1016/j.fuel.2020.117832,University of Dayton,"A machine learning framework has been developed to predict volume swell for 10 non-metallic materials submerged in neat compounds. The non-metallic materials included nitrile rubber, extracted nitrile rubber, fluorosilicone, low temp fluorocarbon, lightweight polysulfide, polythioether, epoxy (0.2 mm), epoxy (0.04 mm), nylon, and Kapton. Volume swell, a material compatibility concern, serves as a significant impediment for the minimization of the greenhouse gas emissions of aviation. Sustainable aviation fuels, the only near and mid-term solution to mitigating greenhouse gas emissions, are limited to low blend limits with conventional fuel due to material compatibility issues (i.e. O-ring swell). A neural network was trained to predict volume swell for nonmetallic materials submerged in neat compounds. Subsequent blend optimization incorporated nitrile rubber volume swell predictions for iso- and cycloalkanes to create a high-performance jet fuel within 'drop-in' limits.
The results of this study are volume swell predictions for 3 of the 10 materials -nitrile rubber, extracted nitrile rubber, and polythioether- with holdout errors of 12.4% or better relative to mean volume swell values. Optimization considering nitrile rubber volume swell achieved median specific energy [MJ/kg] and energy density [MJ/L] increases of 1.9% and 5.1% relative to conventional jet fuel and an average volume swell of 6.2% v/v which is within the range of conventional fuels. Optimized solutions were heavily biased toward monocycloalkanes, indicating that they are a suitable replacement for aromatics. This study concludes that cycloalkanes can replace aromatics in jet fuel considering volume swell and other operability requirements while significantly reducing soot and particulate matter emissions.","Sustainable aviation fuel,High-performance jet fuel,Volume swell,Neural network,Principal component analysis",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Energy & Fuels,Engineering",,6.63,,FUEL,https://doi.org/10.1016/j.fuel.2020.117832,
100,Defect identification in composite materials via thermography and deep learning techniques,246,,,"Bang Hyun-Tae,Park Solmoi,Jeon Haemin","Bang HT,Park S,Jeon H",Jeon H,,Hanbat National University,,INFRARED THERMOGRAPHY,Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Mechanics,Materials Science",,5.536,"INFRARED,THERMOGRAPHY",COMPOSITE STRUCTURES,,
