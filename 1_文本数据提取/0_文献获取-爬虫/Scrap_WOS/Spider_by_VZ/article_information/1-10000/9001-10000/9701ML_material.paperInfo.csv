,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Machine-Learning Assisted Screening of Energetic Materials,124,26,5341-5351,"Kang Peng,Liu Zhongli,Abou-Rachid Hakima,Guo Hong","Kang P,Liu ZL,Abou-Rachid H,Guo H",Guo H,10.1021/acs.jpca.0c02647,McGill University,"In this work, machine learning (ML), materials informatics (MI), and thermochemical data are combined to screen potential candidates of energetic materials. To directly characterize energetic performance, the heat of explosion Delta H-e is used as the target property. The critical descriptors of cohesive energy, averaged over all constituent elements and the oxygen balance, are found by forward stepwise selection from a large number of possible descriptors. With them and a theoretically labeled Delta H-e training data set, a satisfactory surrogate ML model is trained. The ML model is applied to large databases ICSD and PubChem to predict Delta H-e. At the gross-level filtering by the ML model, 2732 molecular candidates based on carbon, hydrogen, nitrogen, and oxygen (CHNO) with high Delta H-e values are predicted. Afterward, a fine-level thermochemical screening is carried out on the 2732 materials, resulting in 262 candidates with TNT equivalent power index P-e(TNT) greater than 1.5. Raising P-e(TNT) further to larger than 1.8, 29 potential candidates are found from the 2732 materials, all are new to the current reservoir of well-known energetic materials.","HYDRAZINIUM-NITROFORMATE,DETONATION PROPERTIES,STANDARD ENTHALPY,CRYSTAL-STRUCTURE,PREDICTION,ADDITIVITY,HEATS,PERFORMANCE,GUANIDINIUM,EXPLOSIVES",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Physics",,2.725,"HYDRAZINIUM-NITROFORMATE,DETONATION,PROPERTIES,STANDARD,ENTHALPY,CRYSTAL-STRUCTURE,PREDICTION,ADDITIVITY,HEATS,PERFORMANCE,GUANIDINIUM,EXPLOSIVES",JOURNAL OF PHYSICAL CHEMISTRY A,,
2,Machine Learning-Based Optoacoustic Tissue Classification Method for Laser Osteotomes Using an Air-Coupled Transducer,53,3,377-389,"Kenhagho Herve Nguendon,Canbaz Ferda,Gomez Alvarez-Arenas Tomas E.,Guzman Raphael,Cattin Philippe,Zam Azhar","Kenhagho HN,Canbaz F,Alvarez-Arenas TEG,Guzman R,Cattin P,Zam A",Kenhagho HN; Zam A,10.1002/lsm.23290,University of Basel,"Background and Objectives Using lasers instead of mechanical tools for bone cutting holds many advantages, including functional cuts, contactless interaction, and faster wound healing. To fully exploit the benefits of lasers over conventional mechanical tools, a real-time feedback to classify tissue is proposed. Study Design/Materials and Methods In this paper, we simultaneously classified five tissue types-hard and soft bone, muscle, fat, and skin from five proximal and distal fresh porcine femurs-based on the laser-induced acoustic shock waves (ASWs) generated. For laser ablation, a nanosecond frequency-doubled Nd:YAG laser source at 532 nm and a microsecond Er:YAG laser source at 2940 nm were used to create 10 craters on the surface of each proximal and distal femur. Depending on the application, the Nd:YAG or Er:YAG can be used for bone cutting. For ASW recording, an air-coupled transducer was placed 5 cm away from the ablated spot. For tissue classification, we analyzed the measured acoustics by looking at the amplitude-frequency band of 0.11-0.27 and 0.27-0.53 MHz, which provided the least average classification error for Er:YAG and Nd:YAG, respectively. For data reduction, we used the amplitude-frequency band as an input of the principal component analysis (PCA). On the basis of PCA scores, we compared the performance of the artificial neural network (ANN), the quadratic- and Gaussian-support vector machine (SVM) to classify tissue types. A set of 14,400 data points, measured from 10 craters in four proximal and distal femurs, was used as training data, while a set of 3,600 data points from 10 craters in the remaining proximal and distal femur was considered as testing data, for each laser. Results The ANN performed best for both lasers, with an average classification error for all tissues of 5.01 +/- 5.06% and 9.12 +/- 3.39%, using the Nd:YAG and Er:YAG lasers, respectively. Then, the Gaussian-SVM performed better than the quadratic SVM during the cutting with both lasers. The Gaussian-SVM yielded average classification errors of 15.17 +/- 13.12% and 16.85 +/- 7.59%, using the Nd:YAG and Er:YAG lasers, respectively. The worst performance was achieved with the quadratic-SVM with a classification error of 50.34 +/- 35.04% and 69.96 +/- 25.49%, using the Nd:YAG and Er:YAG lasers. Conclusion We foresee using the ANN to differentiate tissues in real-time during laser osteotomy. Lasers Surg. Med. (c) 2020 Wiley Periodicals LLC","laser ablation,tissue classification,acoustic shock signal,principal component analysis,support vector machine,artificial network machine",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Dermatology,Surgery",,3.881,"ER-YAG,LASER,BONE,ABLATION,PULSE,DURATION,SURGERY,ENHANCEMENT,DEPOSITION,MECHANISM",LASERS IN SURGERY AND MEDICINE,https://digital.csic.es/bitstream/10261/233565/1/lsm.23290%20%281%29.pdf,
3,Machine learning in prediction of genetic risk of nonsyndromic oral clefts in the Brazilian population,25,3,1273-1280,"Machado Renato Assis,de Oliveira Silva Carolina,Martelli-Junior Hercilio,das Neves Lucimara Teixeira,Coletta Ricardo D.","Machado RA,Silva CD,Martelli H,das Neves LT,Coletta RD",Coletta RD,10.1007/s00784-020-03433-y,Universidade Estadual de Campinas,"Objectives Genetic variants in multiple genes and loci have been associated with the risk of nonsyndromic cleft lip with or without cleft palate (NSCL +/- P). However, the estimation of risk remains challenge, because most of these variants are population-specific rendering the identification of the underlying genetic risk difficult. Herein we examined the use of machine learning network in previously reported single nucleotide polymorphisms (SNPs) to predict risk of NSCL +/- P in the Brazilian population. Materials and methods Random forest and neural network methods were applied in 72 SNPs in a case-control sample composed by 722 NSCL +/- P and 866 controls for discrimination of NSCL +/- P risk. SNP-SNP interactions and functional annotation biological processes associated with the identified NSCL +/- P risk genes were verified. Results Supervised random forest decision trees revealed high scores of importance for the SNPs rs11717284 and rs1875735 inFGF12, rs41268753 inGRHL3, rs2236225 inMTHFD1, rs2274976 inMTHFR, rs2235371 and rs642961 inIRF6, rs17085106 inRHPN2, rs28372960 inTCOF1, rs7078160 inVAX1, rs10762573 and rs2131960 inVCL, and rs227731 in 17q22, with an accuracy of 99% and an error rate of approximately 3% to predict the risk of NSCL +/- P. Those same 13 SNPs were considered the most important for the neural network to effectively predict NSCL +/- P risk, with an overall accuracy of 94%. Multivariate regression model revealed significant interactions among all SNPs, with an exception of those inFGF12andMTHFD1. The most significantly biological processes for selected genes were those involved in tissue and epithelium development; neural tube closure; and metabolism of methionine, folate, and homocysteine. Conclusions Our results provide novel clues for genetic mechanism studies of NSCL +/- P and point out for a machine learning model composed by 13 SNPs that is capable of predicting NSCL +/- P risk.","Nonsyndromic oral cleft,Single nucleotide polymorphism,Machine learning,Genetic counseling,Brazilian population",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Dentistry, Oral Surgery & Medicine",,3.623,"OROFACIAL,CLEFTS,CAUSE,VAN,PALATE,IRF6,LIP,MUTATIONS,SUSCEPTIBILITY,FORTIFICATION,IMPACT,WOUDE",CLINICAL ORAL INVESTIGATIONS,,
4,Automated labeling of the airway tree in terms of lobes based on deep learning of bifurcation point detection,58,9,2009-2024,"Wang Manyang,Jin Renchao,Jiang Nanchuan,Liu Hong,Jiang Shan,Li Kang,Zhou XueXin","Wang MY,Jin RC,Jiang NC,Liu H,Jiang S,Li K,Zhou XX",Jin RC,10.1007/s11517-020-02184-y,Huazhong University of Science & Technology,"This paper presents an automatic lobe-based labeling of airway tree method, which can detect the bifurcation points for reconstructing and labeling the airway tree from a computed tomography image. A deep learning-based network structure is designed to identify the four key bifurcation points. Then, based on the detected bifurcation points, the entire airway tree is reconstructed by a new region-growing method. Finally, with the basic airway tree anatomy and topology knowledge, individual branches of the airway tree are classified into different categories in terms of pulmonary lobes. There are several advantages in our method such as the detection of the bifurcation points does not depend on the segmentation of airway tree and only four bifurcation points need to be manually labeled for each sample to prepare the training dataset. The segmentation of airway tree is guided by the detected points, which overcomes the difficulty of manual seed selection of conventional region-growing algorithm. In addition, the bifurcation points can help analyze the tree structure, which provides a basis for effective airway tree labeling. Experimental results show that our method is fast, stable, and the accuracy of our method is 97.85%, which is higher than that of the traditional skeleton-based method.","Airway tree,Bifurcation points,Deep learning-based network,Automated labeling",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"COMPUTED-TOMOGRAPHY,IMAGES,CURVE,SKELETONIZATION,SEGMENTATION,METHODS,CT,ALGORITHM,RECONSTRUCTION,COMBINATION,FISSURES,BRANCHES,SURFACE",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
5,A cell-level quality control workflow for high-throughput image analysis,21,1,,"Qiu Minhua,Zhou Bin,Lo Frederick,Cook Steven,Chyba Jason,Quackenbush Doug,Matzen Jason,Li Zhizhong,Mak Puiying Annie,Chen Kaisheng","Qiu MH,Zhou B,Lo F,Cook S,Chyba J,Quackenbush D,Matzen J,Li ZZ,Mak PA,Chen KS",Qiu MH; Zhou YY,10.1186/s12859-020-03603-5,Novartis,"BackgroundImage-based high throughput (HT) screening provides a rich source of information on dynamic cellular response to external perturbations. The large quantity of data generated necessitates computer-aided quality control (QC) methodologies to flag imaging and staining artifacts. Existing image- or patch-level QC methods require separate thresholds to be simultaneously tuned for each image quality metric used, and also struggle to distinguish between artifacts and valid cellular phenotypes. As a result, extensive time and effort must be spent on per-assay QC feature thresholding, and valid images and phenotypes may be discarded while image- and cell-level artifacts go undetected.ResultsWe present a novel cell-level QC workflow built on machine learning approaches for classifying artifacts from HT image data. First, a phenotype sampler based on unlabeled clustering collects a comprehensive subset of cellular phenotypes, requiring only the inspection of a handful of images per phenotype for validity. A set of one-class support vector machines are then trained on each biologically valid image phenotype, and used to classify individual objects in each image as valid cells or artifacts. We apply this workflow to two real-world large-scale HT image datasets and observe that the ratio of artifact to total object area (AR(cell)) provides a single robust assessment of image quality regardless of the underlying causes of quality issues. Gating on this single intuitive metric, partially contaminated images can be salvaged and highly contaminated images can be excluded before image-level phenotype summary, enabling a more reliable characterization of cellular response dynamics.ConclusionsOur cell-level QC workflow enables identification of artificial cells created not only by staining or imaging artifacts but also by the limitations of image segmentation algorithms. The single readout AR(cell) that summaries the ratio of artifacts contained in each image can be used to reliably rank images by quality and more accurately determine QC cutoff thresholds. Machine learning-based cellular phenotype clustering and sampling reduces the amount of manual work required for training example collection. Our QC workflow automatically handles assay-specific phenotypic variations and generalizes to different HT image assays.","Cell-level quality control,High throughput image analysis,Image quality measurement,Machine learning,CellProfiler",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,,BMC BIOINFORMATICS,https://europepmc.org/articles/pmc7333376?pdf=render,
6,Atherosclerotic Plaque Tissue Characterization: An OCT-Based Machine Learning Algorithm Withex vivoValidation,8,,,"He Chunliu,Li Zhonglin,Wang Jiaqiu,Huang Yuxiang,Yin Yifan,Li Zhiyong","He CL,Li ZL,Wang JQ,Huang YX,Yin YF,Li ZY",Li ZY,10.3389/fbioe.2020.00749,Southeast University - China,"There is a need to develop a validated algorithm for plaque characterization which can help to facilitate the standardization of optical coherence tomography (OCT) image interpretation of plaque morphology, and improve the efficiency and accuracy in the application of OCT imaging for the quantitative assessment of plaque vulnerability. In this study, a machine learning algorithm was implemented for characterization of atherosclerotic plaque components by intravascular OCT usingex vivocarotid plaque tissue samples. A total of 31 patients underwent carotid endarterectomy and theex vivocarotid plaques were imaged with OCT. Optical parameter, texture features and relative position of pixels were extracted within the region of interest and then used to quantify the tissue characterization of plaque components. The potential of individual and combined feature set to discriminate tissue components was quantified using sensitivity, specificity, accuracy. The results show there was a lower classification accuracy in the calcified tissue than the fibrous tissue and lipid tissue. The pixel-wise classification accuracy obtained by the developed method, to characterize the fibrous, calcified and lipid tissue by comparing with histology, were 80.0, 62.0, and 83.1, respectively. The developed algorithm was capable of characterizing plaque components with an excellent accuracy using the combined feature set.","atherosclerotic plaque,carotid artery,histology,machine learning,optical coherence tomography",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND","Biotechnology & Applied Microbiology,Science & Technology - Other Topics",,5.973,"OPTICAL,COHERENCE,TOMOGRAPHY,FIBROUS,CAP,THICKNESS,SCATTERING,MEDIA,TEXTURE,ANALYSIS,CLASSIFICATION,LESIONS,QUANTIFICATION,VULNERABILITY,ATTENUATION",FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY,https://www.frontiersin.org/articles/10.3389/fbioe.2020.00749/pdf,
7,Accelerating Ab Initio Simulation via Nested Monte Carlo and Machine Learned Reference Potentials,124,26,5488-5497,"Jadrich Ryan B.,Leiding Jeffery A.","Jadrich RB,Leiding JA",Jadrich RB; Leiding JA,10.1021/acs.jpcb.0c03738,United States Department of Energy (DOE),"As a corollary of the rapid advances in computing, ab initio simulation is playing an increasingly important role in modeling materials at the atomic scale. Two strategies are possible, ab initio Monte Carlo (AIMC) and molecular dynamics (AIMD) simulation. The former benefits from exact sampling from the correct thermodynamic distribution, while the latter is typically more efficient with its collective all-atom coordinate updates. Here, using a relatively simple test model comprised of helium and argon, we show that AIMC can be brought up to, and even above, the performance levels of AIMD via a hybrid nested sampling/machine learning (ML) strategy. Here, ML provides an accurate classical reference potential (up to three-body explicit interactions) that can pilot long collective Monte Carlo moves that are accepted or rejected in toto a la nested Monte Carlo (NMC); this is in contrast to the single move nature of a naive implementation. Our proposed method only requires a small up front expense from evaluating the ab initio energies and forces of O(100) random configurations for training. Importantly, our method does not totally rely on the trained, assuredly imperfect, interaction. We show that high performance and exact sampling at the desired level of theory can be realized even when the trained interaction has appreciable differences from the ab initio potential. Remarkably, at the highest levels of performance realized via our approach, a pair of statistically uncorrelated atomic configurations can be generated with O(1) ab initio calculations.","1ST PRINCIPLES,LIQUID WATER,ENERGY,EQUILIBRIA,EFFICIENCY",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,3.051,"1ST,PRINCIPLES,LIQUID,WATER,ENERGY,EQUILIBRIA,EFFICIENCY",JOURNAL OF PHYSICAL CHEMISTRY B,https://www.osti.gov/biblio/1699465,
8,,,,,,,,,,,,,,,,,,,,
9,,,,,,,,,,,,,,,,,,,,
10,,,,,,,,,,,,,,,,,,,,
11,Unsupervised machine learning and prognostic factors of survival in chronic lymphocytic leukemia,27,7,1019-+,"Coombes Caitlin E.,Abrams Zachary B.,Li Suli,Abruzzo Lynne V,Coombes Kevin R.","Coombes CE,Abrams ZB,Li SL,Abruzzo LV,Coombes KR",Coombes CE,10.1093/jamia/ocaa060,"Dept Biomed Informat, 340E Lincoln Tower,1800 Cannon Dr, Columbus, OH 43210 USA.","Objective: Unsupervised machine learning approaches hold promise for large-scale clinical data. However, the heterogeneity of clinical data raises new methodological challenges in feature selection, choosing a distance metric that captures biological meaning, and visualization. We hypothesized that clustering could discover prognostic groups from patients with chronic lymphocytic leukemia, a disease that provides biological validation through well-understood outcomes.
Methods: To address this challenge, we applied k-medoids clustering with 10 distance metrics to 2 experiments (""A"" and ""B"") with mixed clinical features collapsed to binary vectors and visualized with both multidimensional scaling and t-stochastic neighbor embedding. To assess prognostic utility, we performed survival analysis using a Cox proportional hazard model, log-rank test, and Kaplan-Meier curves.
Results: In both experiments, survival analysis revealed a statistically significant association between clusters and survival outcomes (A: overall survival, P=.0164; B: time from diagnosis to treatment, P=.0039). Multidimensional scaling separated clusters along a gradient mirroring the order of overall survival. Longer survival was associated with mutated immunoglobulin heavy-chain variable region gene (IGHV) status, absent Zap 70 expression, female sex, and younger age.
Conclusions: This approach to mixed-type data handling and selection of distance metric captured well-understood, binary, prognostic markers in chronic lymphocytic leukemia (sex, IGHV mutation status, ZAP70 expression status) with high fidelity.","clustering,chronic lymphocytic leukemia,clinical informatics,mixed-type data",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"GENE,MUTATION,STATUS,CLUSTER-ANALYSIS,COPD,SUBTYPES,EXPRESSION,PHENOTYPES,ALGORITHM,PATTERNS,DISEASE,CANCERS,BREAST",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647286,
12,Empirical assessment of bias in machine learning diagnostic test accuracy studies,27,7,1092-1101,"Crowley Ryan J.,Tan Yuan Jin,Ioannidis John P. A.","Crowley RJ,Tan YJ,Ioannidis JPA",Ioannidis JPA,10.1093/jamia/ocaa075,Stanford University,"Objective: Machine learning (ML) diagnostic tools have significant potential to improve health care. However, methodological pitfalls may affect diagnostic test accuracy studies used to appraise such tools. We aimed to evaluate the prevalence and reporting of design characteristics within the literature. Further, we sought to empirically assess whether design features may be associated with different estimates of diagnostic accuracy.
Materials and Methods: We systematically retrieved 2 x 2 tables (n=281) describing the performance of ML diagnostic tools, derived from 114 publications in 38 meta-analyses, from PubMed. Data extracted included test performance, sample sizes, and design features. A mixed-effects metaregression was run to quantify the association between design features and diagnostic accuracy.
Results: Participant ethnicity and blinding in test interpretation was unreported in 90% and 60% of studies, respectively. Reporting was occasionally lacking for rudimentary characteristics such as study design (28% unreported). Internal validation without appropriate safeguards was used in 44% of studies. Several design features were associated with larger estimates of accuracy, including having unreported (relative diagnostic odds ratio [RDOR], 2.11; 95% confidence interval [CI], 1.43-3.1) or case-control study designs (RDOR, 1.27; 95% CI, 0.97-1.66), and recruiting participants for the index test (RDOR, 1.67; 95% CI, 1.08-2.59).
Discussion: Significant underreporting of experimental details was present. Study design features may affect estimates of diagnostic performance in the ML diagnostic test accuracy literature.
Conclusions: The present study identifies pitfalls that threaten the validity, generalizability, and clinical value of ML diagnostic tools and provides recommendations for improvement.","machine learning,bias,sensitivity and specificity,research design,diagnostic techniques and procedures",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"ARTIFICIAL-INTELLIGENCE,METHODOLOGICAL,STANDARDS,FIRST-TRIMESTER,BREAST-CANCER,MR-IMAGES,CLASSIFICATION,PERFORMANCE,PITFALLS,DISEASE,MEDICINE",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647361,
13,Explainable artificial intelligence models using real-world electronic health record data: a systematic scoping review,27,7,1173-1185,"Payrovnaziri Seyedeh Neelufar,Chen Zhaoyi,Rengifo-Moreno Pablo,Miller Tim,Bian Jiang,Chen Jonathan H.,Liu Xiuwen,He Zhe","Payrovnaziri SN,Chen ZY,Rengifo-Moreno P,Miller T,Bian J,Chen JH,Liu XW,He Z",He Z,10.1093/jamia/ocaa053,State University System of Florida,"Objective: To conduct a systematic scoping review of explainable artificial intelligence (XAI) models that use real-world electronic health record data, categorize these techniques according to different biomedical applications, identify gaps of current studies, and suggest future research directions.
Materials and Methods: We searched MEDLINE, IEEE Xplore, and the Association for Computing Machinery (ACM) Digital Library to identify relevant papers published between January 1, 2009 and May 1, 2019. We summarized these studies based on the year of publication, prediction tasks, machine learning algorithm, dataset(s) used to build the models, the scope, category, and evaluation of the XAI methods. We further assessed the reproducibility of the studies in terms of the availability of data and code and discussed open issues and challenges.
Results: Forty-two articles were included in this review. We reported the research trend and most-studied diseases. We grouped XAI methods into 5 categories: knowledge distillation and rule extraction (N=13), intrinsically interpretable models (N=9), data dimensionality reduction (N=8), attention mechanism (N=7), and feature interaction and importance (N=5).
Discussion: XAI evaluation is an open issue that requires a deeper focus in the case of medical applications. We also discuss the importance of reproducibility of research work in this field, as well as the challenges and opportunities of XAI from 2 medical professionals' point of view.
Conclusion: Based on our review, we found that XAI evaluation in medicine has not been adequately and formally practiced. Reproducibility remains a critical concern. Ample opportunities exist to advance XAI research in medicine.","Explainable artificial intelligence (XAI),real-world data,electronic health records,deep learning",Review,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"DEEP,NEURAL-NETWORK,BLACK-BOX,EXPRESSION,CLASSIFICATION,PREDICTION,CANCER,DIAGNOSIS,MACHINES,PATTERNS",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647281,
14,Optimization of tobacco drying process control based on reinforcement learning,38,10,1291-1299,"Bi Suhuan,Zhang Bin,Mu Liangliang,Ding Xiangqian,Wang Jing","Bi SH,Zhang B,Mu LL,Ding XQ,Wang J",Ding XQ,10.1080/07373937.2019.1633662,Ocean University of China,"Drying is an important procedure in tobacco production. The current PID based drying suffers from issues such as overheating or inconsistent control of the amount of moisture content. In order to boost quality assurance, reinforcement learning has been employed in this paper to facilitate dynamic configuration of dryer. A novel actor-critic based intelligent system is built on top of the current PID control. The new data-centric approach collects environment and machine states, incorporates historical production data and learns temperature adjustment strategies. Compared to automatic PID control and manual intervention, the introduced intelligence proves to be remarkably more effective to govern the drying and control the moisture content level with consistent performance. The proposed method provides new insights into precision achievement in industrial control process.","Tobacco drying,reinforcement learning,actor-critic,PID control",Article,"TAYLOR & FRANCIS INC, 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA",Engineering,,4.034,"CUT,TOBACCO,MOISTURE-CONTENT,CONTROL-SYSTEM,MODEL,REDUCTION,DRYER",DRYING TECHNOLOGY,,
15,Rapid Determination of Wood and Rice Husk Pellets' Proximate Analysis and Heating Value,13,14,,"Liu Xiaodan,Feng Xuping,Huang Lingxia,He Yong","Liu XD,Feng XP,Huang LX,He Y",He Y,10.3390/en13143741,Zhejiang University,"Biomass pellets are a potential renewable and clean energy source. With the advantages of perfect combustion performance and easy storage and transport, biomass pellets have gradually replaced fossil fuels and become widely used. Rapid and accurate determination of biomass pellets' quality is critical to efficient energy use. Laser-induced breakdown spectroscopy (LIBS) combined with chemometric methods were utilized. The gross calorific value (CV) and ash content (Ash), volatile matter (VM) and fixed carbon (FC) were firstly measured and analyzed. LIBS spectra and their corresponding elements of biomass pellet samples were analyzed. Three quantitative analysis models for quality indexes including partial least-squares regression (PLSR), least squares-support vector machines (LS-SVM), extreme learning machines (ELM) were further built. All models performed well, especially the LS-SVM model which obtained the best determination results, with all R(2)values over 0.95. Concurrently, the modeling performance of ash was slightly better than that of the other three quality indexes, which further confirmed the feasibility of using relevant elements to predict biomass quality indexes. The overall results indicated that LIBS coupled with suitable chemometrics could be an alternative promising method to determine quality indexes of biomass pellets and further improve energy utilization by using biomass materials with better quality.","biomass pellet,laser-induced breakdown spectroscopy,chemometrics,quality indexes",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"INDUCED,BREAKDOWN,SPECTROSCOPY,PARTIAL,LEAST-SQUARES,EXTREME,LEARNING-MACHINE,QUANTITATIVE-ANALYSIS,MOISTURE-CONTENT,CALORIFIC,VALUE,TOTAL,NITROGEN,BIOMASS,PREDICTION,REGRESSION",ENERGIES,https://www.mdpi.com/1996-1073/13/14/3741/pdf,
16,Modelling Inhomogeneity of Veneer Laminates with a Finite Element Mapping Method Based on Arbitrary Grayscale Images,13,13,,"Zerbst David,Liebold Christian,Gereke Thomas,Haufe Andre,Clauss Sebastian,Cherif Chokri","Zerbst D,Liebold C,Gereke T,Haufe A,Clauss S,Cherif C",Zerbst D,10.3390/ma13132993,Daimler AG,"Failure and deformation behavior of veneer laminates of ring porous wood species vary with the individual arrangement of early- and latewood zones over a veneer sheet. Therefore, a method is presented, where local failure and damage modes are considered for finite element models with respect to forming simulations, during the development process of automotive interior trim parts. Within the mapping tool Envyo, a routine has been realized for the discretization of early- and latewood zones from ash wood veneer surfaces to finite element meshes. The routine performs the following steps: reading a grayscale image of known size and generation of a point cloud based on the number of pixels; transformation and scaling of the generated point cloud to align with a target finite element mesh; nearest neighbor search and transfer of grayscale values to the target mesh element centroids; assigning part and therefore material properties to the target elements based on the mapped grayscale value and user-defined grayscale ranges. Due to the absence of measurement data for early- and latewood, optimization was used to identify locally varying material constants. A set of material input parameters for early- and latewood was created, calibrating the force-displacement response of tensile test simulations to corresponding experimental curves. The numerical results gave a very good agreement to the failure behavior of tensile tests in the loading directions longitudinal and transverse to the fiber orientation. Furthermore, in a stochastic analysis the characteristic distribution of tensile strength and ultimate strain could be verified for the suggested procedure. The introduced modelling approach can be applied for the discrete implementation of inhomogeneity to numerical simulations.","veneer,numerical modelling,annual rings,parameter identification,grayscale mapping",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,,"FAILURE,MECHANISMS,WOOD,CRITERIA,DAMAGE",MATERIALS,https://www.mdpi.com/1996-1944/13/13/2993/pdf,
17,Xbee-Based WSN Architecture for Monitoring of Banana Ripening Process Using Knowledge-Level Artificial Intelligent Technique,20,14,,"Altaf Saud,Ahmad Shafiq,Zaindin Mazen,Soomro Muhammad Waseem","Altaf S,Ahmad S,Zaindin M,Soomro MW",Ahmad S,10.3390/s20144033,King Saud University,"Real-time monitoring of fruit ripeness in storage and during logistics allows traders to minimize the chances of financial losses and maximize the quality of the fruit during storage through accurate prediction of the present condition of fruits. In Pakistan, banana production faces different difficulties from production, post-harvest management, and trade marketing due to atmosphere and mismanagement in storage containers. In recent research development, Wireless Sensor Networks (WSNs) are progressively under investigation in the field of fruit ripening due to their remote monitoring capability. Focused on fruit ripening monitoring, this paper demonstrates an Xbee-based wireless sensor nodes network. The role of the network architecture of the Xbee sensor node and sink end-node is discussed in detail regarding their ability to monitor the condition of all the required diagnosis parameters and stages of banana ripening. Furthermore, different features are extracted using the gas sensor, which is based on diverse values. These features are utilized for training in the Artificial Neural Network (ANN) through the Back Propagation (BP) algorithm for further data validation. The experimental results demonstrate that the projected WSN architecture can identify the banana condition in the storage area. The proposed Neural Network (NN) architectural design works well with selecting the feature data sets. It seems that the experimental and simulation outcomes and accuracy in banana ripening condition monitoring in the given feature vectors is attained and acceptable, through the classification performance, to make a better decision for effective monitoring of current fruit condition.","wireless sensor network,fruit condition monitoring,artificial neural network,ethylene gas,banana ripening",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7411650,
18,Clinical Implication of Concordant or Discordant Genomic Profiling between Primary and Matched Metastatic Tissues in Patients with Colorectal Cancer,52,3,764-778,"Choi Jung Yoon,Choi Sunho,Lee Minhyeok,Park Young Soo,Sung Jae Sook,Chang Won Jin,Kim Ju Won,Choi Yoon Ji,Kim Jin,Kim Dong-Sik","Choi JY,Choi S,Lee M,Park YS,Sung JS,Chang WJ,Kim JW,Choi YJ,Kim J,Kim DS",Kim YH,10.4143/crt.2020.044,Korea University,"Purpose
The purpose of this study was to identify the concordant or discordant genomic profiling between primary and matched metastatic tumors in patients with colorectal cancer (CRC) and to explore the clinical implication.
Materials and Methods
Surgical samples of primary and matched metastatic tissues from 158 patients (335 samples) with CRC at Korea University Anam Hospital were evaluated using the Ion AmpliSeq Cancer Hotspot Panel. We compared genetic variants and classified them as concordant, primary-specific, and metastasis-specific variants. We used a combination of principal components analysis and clustering to find genomic groups. Kaplan-Meier curves were used to appraise survival between genomic groups. We used machine learning to confirm the correlation between genetic variants and metastatic sites.
Results
A total of 282 types of deleterious non-synonymous variants were selected for analysis. Of a total of 897 variants, an average of 40% was discordant. Three genomic groups were yielded based on the genomic discrepancy patterns. Overall survival differed significantly between the genomic groups. The poorest group had the highest proportion of concordant KRAS G12V and additional metastasis-specific SMAD4. Correlation analysis between genetic variants and metastatic sites suggested that concordant KRAS mutations would have more disseminated metastases.
Conclusion
Driver gene mutations were mostly concordant; however, discordant or metastasis-specific mutations were present. Clinically, the concordant driver genetic changes with additional metastasis-specific variants can predict poor prognosis for patients with CRC.","Colorectal neoplasms,Genomics,Neoplasm metastasis,Principal component analysis,Survival",Article,"KOREAN CANCER ASSOCIATION, RM 1824, GWANGHWAMUN OFFICIA, 92 SAEMUNAN-RO, JONGNO-GU, SEOUL, 110-999, SOUTH KOREA",Oncology,,3.942,"TUMOR,HETEROGENEITY,LUNG,METASTASES,MUTATIONS,SURVIVAL,LIVER",CANCER RESEARCH AND TREATMENT,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7373863,
19,Prediction of Ultimate Bearing Capacity of Aggregate Pier Reinforced Clay Using Multiple Regression Analysis and Deep Learning,10,13,,"Bong Taeho,Kim Sung-Ryul,Kim Byoung-Il","Bong T,Kim SR,Kim BI",Kim SR,10.3390/app10134580,Seoul National University (SNU),"Aggregate piers have been widely used to increase bearing pressure and reduce settlement under structural footings. The ultimate bearing capacity of aggregate pier-reinforced ground is affected by the soil strength, replacement ratio of piles, and construction conditions. Various prediction models have been proposed to predict the ultimate bearing capacity. However, existing models have shown a broad range of bias, variation, and error, and they are at times unsuitable for practical design. In this study, multiple regression analysis was performed using field loading test results to predict the ultimate bearing capacity of ground reinforced by aggregate piers, and the number and type of the most efficient input variables were evaluated to build a robust predictive model. Accordingly, a multiple regression equation for predicting the ultimate bearing capacity was proposed, and a sensitivity analysis was conducted to identify the effect of input variables. In addition, a deep neural network was applied to estimate the ultimate bearing capacity. The optimal structure was selected on the basis of cross-validation results to prevent overtraining. Prediction errors for two approaches were evaluated and then compared with those of existing models.","aggregate pier,bearing capacity,multiple regression analysis,deep neural network,sensitivity analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"STONE,COLUMNS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/13/4580/pdf,
20,Automated Classification of Blood Loss from Transurethral Resection of the Prostate Surgery Videos Using Deep Learning Technique,10,14,,"Chen Jian-Wen,Lin Wan-Ju,Lin Chun-Yuan,Hung Che-Lun,Hou Chen-Pang,Cho Ching-Che,Young Hong-Tsu,Tang Chuan-Yi","Chen JW,Lin WJ,Lin CY,Hung CL,Hou CP,Cho CC,Young HT,Tang CY",Hung CL,10.3390/app10144908,National Yang Ming Chiao Tung University,"Transurethral resection of the prostate (TURP) is a surgical removal of obstructing prostate tissue. The total bleeding area is used to determine the performance of the TURP surgery. Although the traditional method for the detection of bleeding areas provides accurate results, it cannot detect them in time for surgery diagnosis. Moreover, it is easily disturbed to judge bleeding areas for experienced physicians because a red light pattern arising from the surgical cutting loop often appears on the images. Recently, the automatic computer-aided technique and artificial intelligence deep learning are broadly used in medical image recognition, which can effectively extract the desired features to reduce the burden of physicians and increase the accuracy of diagnosis. In this study, we integrated two state-of-the-art deep learning techniques for recognizing and extracting the red light areas arising from the cutting loop in the TURP surgery. First, the ResNet-50 model was used to recognize the red light pattern appearing in the chipped frames of the surgery videos. Then, the proposed Res-Unet model was used to segment the areas with the red light pattern and remove these areas. Finally, the hue, saturation, and value color space were used to classify the four levels of the blood loss under the circumstances of non-red light pattern images. The experiments have shown that the proposed Res-Unet model achieves higher accuracy than other segmentation algorithms in classifying the images with the red and non-red lights, and is able to extract the red light patterns and effectively remove them in the TURP surgery images. The proposed approaches presented here are capable of obtaining the level classifications of blood loss, which are helpful for physicians in diagnosis.","U-Net model,ResNet-50 model,HSV color space,transurethral resection of the prostate (TURP),classification of bleeding area,blood loss,deep learning technique,Res-Unet model",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"COMPUTER-AIDED,DIAGNOSIS,RANDOMIZED-TRIAL,SEGMENTATION,RESECTOSCOPE,MEN",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/14/4908/pdf,
21,Gradually Applying Weakly Supervised and Active Learning for Mass Detection in Breast Ultrasound Images,10,13,,"Yun Joo Yeol,Oh JungWoo,Yun IlDong","Yun JY,Oh J,Yun I",Yun I,10.3390/app10134519,Hankuk University Foreign Studies,"We propose a method for effectively utilizing weakly annotated image data in an object detection tasks of breast ultrasound images. Given the problem setting where a small, strongly annotated dataset and a large, weakly annotated dataset with no bounding box information are available, training an object detection model becomes a non-trivial problem. We suggest a controlled weight for handling the effect of weakly annotated images in a two stage object detection model. We also present a subsequent active learning scheme for safely assigning weakly annotated images a strong annotation using the trained model. Experimental results showed a 24% point increase in correct localization (CorLoc) measure, which is the ratio of correctly localized and classified images, by assigning the properly controlled weight. Performing active learning after a model is trained showed an additional increase in CorLoc. We tested the proposed method on the Stanford Dog datasets to assure that it can be applied to general cases, where strong annotations are insufficient to obtain resembling results. The presented method showed that higher performance is achievable with lesser annotation effort.","active learning,breast ultrasound,convolutional neural networks,mass classification,object detection,weakly supervised learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,CLASSIFICATION,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/13/4519/pdf,
22,"Machine Learning: A Useful Tool in Geomechanical Studies, a Case Study from an Offshore Gas Field",13,14,,"Khatibi Seyedalireza,Aghajanpour Azadeh","Khatibi S,Aghajanpour A",Khatibi S,10.3390/en13143528,University of Texas System,"For a safe drilling operation with the of minimum borehole instability challenges, building a mechanical earth model (MEM) has proven to be extremely valuable. However, the natural complexity of reservoirs along with the lack of reliable information leads to a poor prediction of geomechanical parameters. Shear wave velocity has many applications, such as in petrophysical and geophysical as well as geomechanical studies. However, occasionally, wells lack shear wave velocity (especially in old wells), and estimating this parameter using other well logs is the optimum solution. Generally, available empirical relationships are being used, while they can only describe similar formations and their validation needs calibration. In this study, machine learning approaches for shear sonic log prediction were used. The results were then compared with each other and the empirical Greenberg-Castagna method. Results showed that the artificial neural network has the highest accuracy of the predictions over the single and multiple linear regression models. This improvement is more highlighted in hydrocarbon-bearing intervals, which is considered as a limitation of the empirical or any linear method. In the next step, rock elastic properties and in-situ stresses were calculated. Afterwards, in-situ stresses were predicted and coupled with a failure criterion to yield safe mud weight windows for wells in the field. Predicted drilling events matched quite well with the observed drilling reports.","geomechanics,machine learning,neural network,shear velocity,linear regression",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"ARTIFICIAL,NEURAL-NETWORK,STONELEY,WAVE,VELOCITIES,WELL,LOG,DATA,VIBRATION,ANALYSIS,SHEAR,PREDICTION,REGRESSION,RESERVOIR",ENERGIES,https://res.mdpi.com/d_attachment/energies/energies-13-03528/article_deploy/energies-13-03528-v2.pdf,
23,Optimization of radial inflow wind turbines for urban wind energy harvesting,202,,,"Acarer Sercan,Uyulan Caglar,Karadeniz Ziya Haktan","Acarer S,Uyulan C,Karadeniz ZH",Acarer S,10.1016/j.energy.2020.117772,Izmir Katip Celebi University,"Radial (inflow) turbines with volutes have received limited attention in the body of literature for open-field wind harvesting. Few existing data in the literature indicate low maximum C-p, around 0.1. This study pursues demonstration of competitive radial wind turbines (RWT) towards exploring their potentials and increase the alternatives for a future urban energy planner. RWT may have advantages in adapting the renewable energy concept into buildings due to their an order-of-magnitude lower rotational speeds compared to propeller turbines, enclosed rotors and discharge of air uniquely from the top of the turbine (therefore the building). Moreover, such features may enable low-noise and fatigue-free rotors made of less durable but recyclable materials, crucial for acoustical comfort, safety and sustainability in urban areas. Design exploration over the complex 3D flowfleld of the turbine is pursued by machine learning algorithms coupled with Computational Fluid Dynamics simulations. With the achieved peak C-p of 0.29 at Re-c = 1.7 x 10(5), 103% improvement is attained relative to the existing RWTs with identical simulation methodologies. A sensitivity analysis revealed the most important parameters. The optimized turbine is compared with traditional alternatives, and it was elucidated that RWT is a competitive alternative among conventional alternatives with the described additional fundamental advantages. (C) 2020 Elsevier Ltd. All rights reserved.","Wind turbine,Radial inflow wind turbine,Energy in buildings,Design optimization,CFD,Machine learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Thermodynamics,Energy & Fuels",,6.845,"SHAPE,OPTIMIZATION,DESIGN,PERFORMANCE,SIMULATIONS,FLOW",ENERGY,,
24,Nanoparticle Recognition on Scanning Probe Microscopy Images Using Computer Vision and Deep Learning,10,7,,"Okunev Alexey G.,Mashukov Mikhail Yu.,Nartova Anna V.,Matveev Andrey V.","Okunev AG,Mashukov MY,Nartova AV,Matveev AV",Matveev AV,10.3390/nano10071285,"Boreskov Institute of Catalysis, Siberian Branch, Russian Academy of Sciences","Identifying, counting and measuring particles is an important component of many research studies. Images with particles are usually processed by hand using a software ruler. Automated processing, based on conventional image processing methods (edge detection, segmentation, etc.) are not universal, can only be used on good-quality images and need to set a number of parameters empirically. In this paper, we present results from the application of deep learning to automated recognition of metal nanoparticles deposited on highly oriented pyrolytic graphite on images obtained by scanning tunneling microscopy (STM). We used the Cascade Mask-RCNN neural network. Training was performed on a dataset containing 23 STM images with 5157 nanoparticles. Three images containing 695 nanoparticles were used for verification. As a result, the trained neural network recognized nanoparticles in the verification set with 0.93 precision and 0.78 recall. Predicted contour refining with 2D Gaussian function was a proposed option. The accuracies for mean particle size calculated from predicted contours compared with ground truth were in the range of 0.87-0.99. The results were compared with outcomes from other generally available software, based on conventional image processing methods. The advantages of deep learning methods for automatic particle recognition were clearly demonstrated. We developed a free open-access web service ""ParticlesNN"" based on the trained neural network, which can be used by any researcher in the world.","particle recognition,deep neural networks,scanning tunneling microscopy,particles",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,5.346,"QUANTUM,DOTS,PARTICLES,PLATINUM",NANOMATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7408120,
25,EEG Synchronization Analysis for Seizure Prediction: A Study on Data of Noninvasive Recordings,8,7,,"Detti Paolo,Vatti Giampaolo,de Lara Garazi Zabalo Manrique","Detti P,Vatti G,de Lara GZM",Detti P,10.3390/pr8070846,University of Siena,"Objective: Epilepsy is a neurological disorder arising from anomalies of the electrical activity in the brain, affecting -65 million individuals worldwide. Prediction methods, typically based on machine learning methods, require a large amount of data for training, in order to correctly classify seizures with small false alarm rates. Methods: In this work, we present a new database containing EEG scalp signals of 14 epileptic patients acquired at the Unit of Neurology and Neurophysiology of the University of Siena, Italy. Furthermore, a patient-specific seizure prediction method, based on the detection of synchronization patterns in the EEG, is proposed and tested on the data of the database. The use of noninvasive EEG data aims to explore the possibility of developing a noninvasive monitoring/control device for the prediction of seizures. The prediction method employs synchronization measures computed over all channel pairs and a computationally inexpensive threshold-based classification approach. Results and conclusions: The experimental analysis, performed by inspection and by the proposed threshold-based classifier on all the patients of the database, shows that the features extracted by the synchronization measures are able to detect preictal and ictal states and allow the prediction of the seizures few minutes before the seizure onsets.","EEG data,epilepsy,synchronization measures,threshold-based classifier,data classification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Engineering,,2.824,"PHASE-SYNCHRONIZATION,EPILEPSY,INDEX",PROCESSES,https://www.mdpi.com/2227-9717/8/7/846/pdf,
26,Machine Learning Magnetic Parameters from Spin Configurations,7,16,,"Wang Dingchen,Wei Songrui,Yuan Anran,Tian Fanghua,Cao Kaiyan,Zhao Qizhong,Zhang Yin,Zhou Chao,Song Xiaoping,Xue Dezhen","Wang DC,Wei SR,Yuan AR,Tian FH,Cao KY,Zhao QZ,Zhang Y,Zhou C,Song XP,Xue DZ",Xue DZ; Yang S,10.1002/advs.202000566,Xi'an Jiaotong University,"Hamiltonian parameters estimation is crucial in condensed matter physics, but is time- and cost-consuming. High-resolution images provide detailed information of underlying physics, but extracting Hamiltonian parameters from them is difficult due to the huge Hilbert space. Here, a protocol for Hamiltonian parameters estimation from images based on a machine learning (ML) architecture is provided. It consists in learning a mapping between spin configurations and Hamiltonian parameters from a small amount of simulated images, applying the trained ML model to a single unexplored experimental image to estimate its key parameters, and predicting the corresponding materials properties by a physical model. The efficiency of the approach is demonstrated by reproducing the same spin configuration as the experimental one and predicting the coercive field, the saturation field, and even the volume of the experiment specimen accurately. The proposed approach paves a way to achieve a stable and efficient parameters estimation.","machine learning,micro-magnetism,parameter estimation,spin configurations",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Chemistry,Science & Technology - Other Topics,Materials Science",,17.835,"PHASE-TRANSITIONS,ICE",ADVANCED SCIENCE,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/advs.202000566,
27,A Rule-Based Monitoring System for Accurate Prediction of Diabetes Monitoring System for Diabetes,11,3,32-53,"Srivastava Anand Kumar,Kumar Yugal,Singh Pradeep Kumar","Srivastava AK,Kumar Y,Singh PK",Srivastava AK,10.4018/IJEHMC.2020070103,"ABES Engn Coll, Ghaziabad, India.","Diabetes is a chronic disease that can affect the life of people due to high sugar level in their blood. The sugar level is increased due to a lack of production of insulin in the human body. Large numbers of people are affected with diabetes and it can increase tremendously due life style behavior. Diabetes can also affect the other human organs, like kidneys, hearts, retinas and lead to the failure of these organs. This article presents a diabetic monitoring system to determine the risk of diabetes based on the personal health record of patients. In this work, several rules are designed based on the clinical as well as non-clinical symptoms. The effectiveness of the diabetes monitoring system is tested on a set of two hundred forty people. The simulation results are also compared with well-known techniques available for diabetes prediction. It is stated that proposed monitoring system obtains 90.41% accuracy rate as compared with other techniques.","Diabetes,Machine Learning,Monitoring System,PHR",Article,"IGI GLOBAL, 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA",Medical Informatics,,,"DECISION-SUPPORT-SYSTEM,HEALTH-CARE,DIAGNOSIS,CLASSIFICATION,FRAMEWORK",INTERNATIONAL JOURNAL OF E-HEALTH AND MEDICAL COMMUNICATIONS,https://www.igi-global.com/ViewTitle.aspx?TitleId=251855&isxn=9781799806912,
28,"Path Planning Strategies to Optimize Accuracy, Quality, Build Time and Material Use in Additive Manufacturing: A Review",11,7,,"Jiang Jingchao,Ma Yongsheng","Jiang JC,Ma YS",Ma YS,10.3390/mi11070633,University of Alberta,"Additive manufacturing (AM) is the process of joining materials layer by layer to fabricate products based on 3D models. Due to the layer-by-layer nature of AM, parts with complex geometries, integrated assemblies, customized geometry or multifunctional designs can now be manufactured more easily than traditional subtractive manufacturing. Path planning in AM is an important step in the process of manufacturing products. The final fabricated qualities, properties, etc., will be different when using different path strategies, even using the same AM machine and process parameters. Currently, increasing research studies have been published on path planning strategies with different aims. Due to the rapid development of path planning in AM and various newly proposed strategies, there is a lack of comprehensive reviews on this topic. Therefore, this paper gives a comprehensive understanding of the current status and challenges of AM path planning. This paper reviews and discusses path planning strategies in three categories: improving printed qualities, saving materials/time and achieving objective printed properties. The main findings of this review include: new path planning strategies can be developed by combining some of the strategies in literature with better performance; a path planning platform can be developed to help select the most suitable path planning strategy with required properties; research on path planning considering energy consumption can be carried out in the future; a benchmark model for testing the performance of path planning strategies can be designed; the trade-off among different fabricated properties can be considered as a factor in future path planning design processes; and lastly, machine learning can be a powerful tool to further improve path planning strategies in the future.","additive manufacturing,path planning,review",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Science & Technology - Other Topics,Instruments & Instrumentation,Physics",,2.943,"PRINTABLE,THRESHOLD,OVERHANG,TOPOLOGY,OPTIMIZATION,SUPPORT,STRUCTURES,DEPOSITION,GENERATION,WIRE,METHODOLOGY,PARAMETERS,ALGORITHM,DESIGN",MICROMACHINES,https://www.mdpi.com/2072-666X/11/7/633/pdf,
29,Radar-Based Non-Contact Continuous Identity Authentication,12,14,,"Islam Shekh Md Mahmudul,Boric-Lubecke Olga,Zheng Yao,Lubecke Victor M.","Islam SMM,Boric-Lubecke O,Zheng Y,Lubecke VM",Islam SMM,10.3390/rs12142279,University of Hawaii System,"Non-contact vital signs monitoring using microwave Doppler radar has shown great promise in healthcare applications. Recently, this unobtrusive form of physiological sensing has also been gaining attention for its potential for continuous identity authentication, which can reduce the vulnerability of traditional one-pass validation authentication systems. Physiological Doppler radar is an attractive approach for continuous identity authentication as it requires neither contact nor line-of-sight and does not give rise to privacy concerns associated with video imaging. This paper presents a review of recent advances in radar-based identity authentication systems. It includes an evaluation of the applicability of different research efforts in authentication using respiratory patterns and heart-based dynamics. It also identifies aspects of future research required to address remaining challenges in applying unobtrusive respiration-based or heart-based identity authentication to practical systems. With the advancement of machine learning and artificial intelligence, radar-based continuous authentication can grow to serve a wide range of valuable functions in society.","Doppler radar,non-contact measurement,respiration,heartbeat,sensor,authentication",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Geology,Remote Sensing,Imaging Science & Photographic Technology",,5.353,"EMPIRICAL,MODE,DECOMPOSITION,BODY,MOVEMENT,CANCELLATION,DOPPLER,RADAR,GAIT,ANALYSIS,RESPIRATION,MOTION,RECOGNITION,PATTERN,SENSORS,SYSTEM",REMOTE SENSING,https://res.mdpi.com/d_attachment/remotesensing/remotesensing-12-02279/article_deploy/remotesensing-12-02279.pdf,
30,An Innovative Multi-Model Neural Network Approach for Feature Selection in Emotion Recognition Using Deep Feature Clustering,20,13,,"Asghar Muhammad Adeel,Khan Muhammad Jamil,Rizwan Muhammad,Mehmood Raja Majid,Kim Sun-Hee","Asghar MA,Khan MJ,Rizwan M,Mehmood RM,Kim SH",Mehmood RM,10.3390/s20133765,"Xiamen Univ Malaysia, Sch Elect & Comp Engn, Informat & Commun Technol Dept, Sepang 43900, Malaysia.","Emotional awareness perception is a largely growing field that allows for more natural interactions between people and machines. Electroencephalography (EEG) has emerged as a convenient way to measure and track a user's emotional state. The non-linear characteristic of the EEG signal produces a high-dimensional feature vector resulting in high computational cost. In this paper, characteristics of multiple neural networks are combined using Deep Feature Clustering (DFC) to select high-quality attributes as opposed to traditional feature selection methods. The DFC method shortens the training time on the network by omitting unusable attributes. First, Empirical Mode Decomposition (EMD) is applied as a series of frequencies to decompose the raw EEG signal. The spatiotemporal component of the decomposed EEG signal is expressed as a two-dimensional spectrogram before the feature extraction process using Analytic Wavelet Transform (AWT). Four pre-trained Deep Neural Networks (DNN) are used to extract deep features. Dimensional reduction and feature selection are achieved utilising the differential entropy-based EEG channel selection and the DFC technique, which calculates a range of vocabularies using k-means clustering. The histogram characteristic is then determined from a series of visual vocabulary items. The classification performance of the SEED, DEAP and MAHNOB datasets combined with the capabilities of DFC show that the proposed method improves the performance of emotion recognition in short processing time and is more competitive than the latest emotion recognition methods.","brain-computer interface,convolutional deep neural network,deep feature clustering,EEG-based emotion recognition,feature selection,two-dimensional spectrogram",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,CLASSIFICATION,SENSORS,https://www.mdpi.com/1424-8220/20/13/3765/pdf,
31,Brain-Computer Interface-Based Humanoid Control: A Review,20,13,,"Chamola Vinay,Vineet Ankur,Nayyar Anand,Hossain Eklas","Chamola V,Vineet A,Nayyar A,Hossain E",Hossain E,10.3390/s20133620,"Oregon Inst Technol, Dept Elect Engn & Renewable Energy, Klamath Falls, OR 97601 USA.","A Brain-Computer Interface (BCI) acts as a communication mechanism using brain signals to control external devices. The generation of such signals is sometimes independent of the nervous system, such as in Passive BCI. This is majorly beneficial for those who have severe motor disabilities. Traditional BCI systems have been dependent only on brain signals recorded using Electroencephalography (EEG) and have used a rule-based translation algorithm to generate control commands. However, the recent use of multi-sensor data fusion and machine learning-based translation algorithms has improved the accuracy of such systems. This paper discusses various BCI applications such as tele-presence, grasping of objects, navigation, etc. that use multi-sensor fusion and machine learning to control a humanoid robot to perform a desired task. The paper also includes a review of the methods and system design used in the discussed applications.","brain-computer interface (BCI),data fusion,nao humanoid,electroencephalography (EEG),P300,biological feedback",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"DATA-FUSION,TECHNIQUES,EEG,SIGNAL,BCI,CLASSIFICATION,ROBOT,MACHINE,HYBRID,PEOPLE,TRENDS,EOG",SENSORS,https://www.mdpi.com/1424-8220/20/13/3620/pdf,
32,Social STEAM Learning at an Early Age with Robotic Platforms: A Case Study in Four Schools in Spain,20,13,,"Jurado Elena,Fonseca David,Coderch Jorge,Canaleta Xavi","Jurado E,Fonseca D,Coderch J,Canaleta X",Jurado E,10.3390/s20133698,Universitat Ramon Llull,"Robotics is one of the key learnings in a world where learners will interact with multiple robotic technologies and operating systems throughout their lives. However, school teachers, especially in the elementary and primary education stages, often have difficulties incorporating these tools in the classroom. Four elementary teachers in three schools in Catalonia were trained to introduce robotics in the classroom to seventy-five students. The main actions consisted in classroom accompaniment by a university-trained support teacher, curricular materials' development, and assessment of the students' and teachers' learning. The designed contents and evaluation criteria took into account the potential of educational robotics to improve soft skills and to promote Science, Technology, Engineering, Arts, and Mathematics (STEAM) interdisciplinary learning. Teachers perceived the training to be supportive and useful and ended the school year feeling confident with the used robotic platform (KIBO). The assessment of the students' learning showed an average mark of 7.1-7.7 over 10 in the final evaluation criteria. Moreover, students' learning was higher in the classes where the teachers had higher initial interest in the training. We present and analyse the actions carried out, with a critical and constructive look at extending the experience to other educational centers.","educational robotics,elementary education,KIBO robot,STEAM,teacher education,human-robot interaction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"COMPUTATIONAL,THINKING,EDUCATIONAL,ROBOTS,TEACHERS",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7374485,
33,Artificial Neural Network Modelling of Photocatalytic Degradation of Diclofenac as a Pharmaceutical Contaminant,42,4,252-261,"Rahimpour-Javid Aysan,Behnajady Mohammad A.","Rahimpour-Javid A,Behnajady MA",Behnajady MA,10.3103/S1063455X20040128,Islamic Azad University,"In this work, the photocatalytic removal of diclofenac (DCF) was investigated using TiO2-P25 nanoparticles immobilized on glass beads in a packed bed photoreactor. DCF is one of the non-steroidal anti-inflammatory drugs used as an analgesic drug. DCF is monitored in urban sewage and surface waters as a stable contaminant that can harm the environment. Advanced oxidation processes (AOPs) are promising methods for degradation and removal of environmental pollutants. The heterogeneous photocatalysis process is one of the AOPs so that the contaminants are decompose in the presence of UV light and a photocatalyst (TiO2). Holes and hydroxyl radicals are the main active species in the UV/TiO(2)process. A thin layer of TiO2-P25 nanoparticles was immobilized by heat attachment method on glass beads. The effect of five operational parameters, the initial concentration of DCF, the power of the light source, the flow rate of the fluid in the photoreactor, irradiation time and pH, has been studied experimentally in the efficiency of the photoreactor. The DCF removal percent is 99% for the initial DCF concentration of 10 mg L-1, the power of the light source of 16 W, the fluid flow rate of 240 mL min(-1)and pH 6 for 120 min irradiation time. The effect of operational parameters on the DCF removal percent was modeled using the artificial neural network (ANN). ANN modeling with a 5 : 9 : 1 feed-forward back propagation neural network demonstrated the appropriate consistency of the experimental and predicted data. TheR(2)values for all data (training, validation and test) were close to 1, confirming ANN reasonable predictive performance. Using the weights of the ANN model in the Garson equation, indicated that pH and irradiation time had the highest effect on the DCF removal percent.","heterogeneous photocatalysis,packed bed photoreactor,heat attachment method,TiO2-P25 nanoparticles,diclofenac,operational parameters,artificial neural network modelling",Article,"PLEIADES PUBLISHING INC, PLEIADES HOUSE, 7 W 54 ST, NEW YORK,  NY, UNITED STATES",Chemistry,,0.582,"IMMOBILIZED,TIO2-P25,NANOPARTICLES,TITANIUM-DIOXIDE,REMOVAL,WATER,OXIDATION,PHOTOREACTOR,OPTIMIZATION,EFFICIENCY,KINETICS,MG",JOURNAL OF WATER CHEMISTRY AND TECHNOLOGY,,
34,Microwave Imaging by Deep Learning Network: Feasibility and Training Method,68,7,5626-5635,"Shao Wenyi,Du Yong","Shao WY,Du Y",Shao WY,10.1109/TAP.2020.2978952,Johns Hopkins University,"Microwave image reconstruction based on a deep learning method is investigated in this article. The neural network is capable of converting measured microwave signals acquired from a 24 x 24 antenna array at 4 GHz into a 128 x 128 image. To reduce the training difficulty, we first developed an autoencoder by which high-resolution images (128 x 128) were represented with 256 x 1 vectors; then we developed the second neural network which aimed to map microwave signals to the compressed features (256 x 1 vector). Two neural networks can be combined to a full network to make reconstructions, when both are successfully developed. The present two-stage training method reduces the difficulty in training deep learning networks (DLNs) for inverse reconstruction. The developed neural network is validated by simulation examples and experimental data with objects in different shapes/sizes, placed in different locations, and with dielectric constant ranging from 2 to 6. Comparisons between the imaging results achieved by the present method and two conventional approaches: distorted Born iterative method (DBIM) and phase confocal method (PCM) are also provided.","Autoencoder (AE),convolutional neural net,deep learning,microwave imaging,scattered fields",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Telecommunications",,4.697,"NEURAL-NETWORK,DIELECTRIC-PROPERTIES,CT,RECONSTRUCTION,SCATTERING,OPTIMIZATION",IEEE TRANSACTIONS ON ANTENNAS AND PROPAGATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8189033,
35,Technology outlook for real-time quality attribute and process parameter monitoring in biopharmaceutical development-A review,117,10,3182-3198,"Wasalathanthri Dhanuka P.,Rehmann Matthew S.,Song Yuanli,Gu Yan,Mi Luo,Shao Chun,Chemmalil Letha,Lee Jongchan,Ghose Sanchayita,Borys Michael C.","Wasalathanthri DP,Rehmann MS,Song YL,Gu Y,Mi L,Shao C,Chemmalil L,Lee JC,Ghose S,Borys MC",Wasalathanthri DP,10.1002/bit.27461,Bristol-Myers Squibb,"Real-time monitoring of bioprocesses by the integration of analytics at critical unit operations is one of the paramount necessities for quality by design manufacturing and real-time release (RTR) of biopharmaceuticals. A well-defined process analytical technology (PAT) roadmap enables the monitoring of critical process parameters and quality attributes at appropriate unit operations to develop an analytical paradigm that is capable of providing real-time data. We believe a comprehensive PAT roadmap should entail not only integration of analytical tools into the bioprocess but also should address automated-data piping, analysis, aggregation, visualization, and smart utility of data for advanced-data analytics such as machine and deep learning for holistic process understanding. In this review, we discuss a broad spectrum of PAT technologies spanning from vibrational spectroscopy, multivariate data analysis, multiattribute chromatography, mass spectrometry, sensors, and automated-sampling technologies. We also provide insights, based on our experience in clinical and commercial manufacturing, into data automation, data visualization, and smart utility of data for advanced-analytics in PAT. This review is catered for a broad audience, including those new to the field to those well versed in applying these technologies. The article is also intended to give some insight into the strategies we have undertaken to implement PAT tools in biologics process development with the vision of realizing RTR testing in biomanufacturing and to meet regulatory expectations.","process analytical technology,quality by design,real-time monitoring",Review,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Biotechnology & Applied Microbiology,,4.63,"2-DIMENSIONAL,LIQUID-CHROMATOGRAPHY,CELL-CULTURE,PROCESS,RAMAN-SPECTROSCOPY,MASS-SPECTROMETRY,THERAPEUTIC,ANTIBODIES,MULTIATTRIBUTE,METHOD,RAW-MATERIALS,DESIGN,OPPORTUNITIES,PURIFICATION",BIOTECHNOLOGY AND BIOENGINEERING,,
36,A Novel Method for Objective Selection of Information Sources Using Multi-Kernel SVM and Local Scaling,20,14,,"Jhoan Areiza-Laverde Henry,Eduardo Castro-Ospina Andres,Liliana Hernandez Maria,Diaz Gloria M.","Areiza-Laverde HJ,Castro-Ospina AE,Hernandez ML,Diaz GM",Diaz GM,10.3390/s20143919,"Inst Tecnol Metropolitano ITM, MIRP Lab Parque I, Medellin 050013, Colombia.","Advancement on computer and sensing technologies has generated exponential growth in the data available for the development of systems that support decision-making in fields such as health, entertainment, manufacturing, among others. This fact has made that the fusion of data from multiple and heterogeneous sources became one of the most promising research fields in machine learning. However, in real-world applications, to reduce the number of sources while maintaining optimal system performance is an important task due to the availability of data and implementation costs related to processing, implementation, and development times. In this work, a novel method for the objective selection of relevant information sources in a multimodality system is proposed. This approach takes advantage of the ability of multiple kernel learning (MKL) and the support vector machines (SVM) classifier to perform an optimal fusion of data by assigning weights according to their discriminative value in the classification task; when a kernel is designed for representing each data source, these weights can be used as a measure of their relevance. Moreover, three algorithms for tuning the Gaussian kernel bandwidth in the classifier prediction stage are introduced to reduce the computational cost of searching for an optimal solution; these algorithms are an adaptation of a common technique in unsupervised learning named local scaling. Two real application tasks were used to evaluate the proposed method: the selection of electrodes for a classification task in Brain-Computer Interface (BCI) systems and the selection of relevant Magnetic Resonance Imaging (MRI) sequences for detection of breast cancer. The obtained results show that the proposed method allows the selection of a small number of information sources.","machine learning,multimodality,multiple kernel learning,support vector machines,source selection",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"CHANNEL,SELECTION,EEG,SIGNALS,CLASSIFICATION,SYSTEM,RECOGNITION,SEQUENCE,FEATURES",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7412271,
37,Wearable Epileptic Seizure Prediction System with Machine-Learning-Based Anomaly Detection of Heart Rate Variability,20,14,,"Yamakawa Toshitaka,Miyajima Miho,Fujiwara Koichi,Kano Manabu,Suzuki Yoko,Watanabe Yutaka,Watanabe Satsuki,Hoshida Tohru,Inaji Motoki,Maehara Taketoshi","Yamakawa T,Miyajima M,Fujiwara K,Kano M,Suzuki Y,Watanabe Y,Watanabe S,Hoshida T,Inaji M,Maehara T",Yamakawa T,10.3390/s20143987,Kumamoto University,"A warning prior to seizure onset can help improve the quality of life for epilepsy patients. The feasibility of a wearable system for predicting epileptic seizures using anomaly detection based on machine learning is evaluated. An original telemeter is developed for continuous measurement of R-R intervals derived from an electrocardiogram. A bespoke smartphone app calculates the indices of heart rate variability in real time from the R-R intervals, and the indices are monitored using multivariate statistical process control by the smartphone app. The proposed system was evaluated on seven epilepsy patients. The accuracy and reliability of the R-R interval measurement, which was examined in comparison with the reference electrocardiogram, showed sufficient performance for heart rate variability analysis. The results obtained using the proposed system were compared with those obtained using the existing video and electroencephalogram assessments; it was noted that the proposed method has a sensitivity of 85.7% in detecting heart rate variability change prior to seizures. The false positive rate of 0.62 times/h was not significantly different from the healthy controls. The prediction performance and practical advantages of portability and real-time operation are demonstrated in this study.","epilepsy,electrocardiography,heart rate variability,multivariate statistical process control,wearable system,machine learning,seizure prediction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,"STATISTICAL,PROCESS-CONTROL,ECG,ABNORMALITIES,STANDARDS,ONSET,TIME",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7411877,
38,Temperature effect modeling in structural health monitoring of concrete dams using kernel extreme learning machines,19,4,987-1002,"Kang Fei,Liu Xi,Li Junjie","Kang F,Liu X,Li JJ",Liu X,10.1177/1475921719872939,Dalian University of Technology,"Statistical models have been used for dam health monitoring for many years and have achieved some successful applications. In the statistical model, dam structural response is related to external environmental factors such as reservoir water level, temperature, and irreversible time deformation. For concrete dams, the structural response is affected greatly by the ambient temperature. Therefore, in order to establish a more reliable dam health monitoring model, the temperature effect and modeling method should be further studied. This article presents a dam health monitoring model using measured air temperature for temperature effect simulation based on kernel extreme learning machines. The temperature effect is simulated by long-term air temperature data, and the nonlinear relationship is modeled by kernel extreme learning machines, which is an intelligent machine learning technique with high learning speed and good generalization performance. The proposed dam health monitoring model is verified on a real concrete gravity dam with efficient safety monitoring data. Results show that the proposed approach with a variable set recommended for concrete dam behavior prediction is feasible.","Dam health monitoring,hydrostatic load,temperature effect,kernel extreme learning machines,concrete gravity dams",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Engineering,Instruments & Instrumentation",,5.861,"THERMAL,DISPLACEMENTS,WATER,TEMPERATURE,REGRESSION,IDENTIFICATION,PREDICTION,SYSTEM",STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL,,
39,Down Syndrome Face Recognition: A Review,12,7,,"Agbolade Olalekan,Nazri Azree,Yaakob Razali,Ghani Abdul Azim,Cheah Yoke Kqueen","Agbolade O,Nazri A,Yaakob R,Ghani AA,Cheah YK",Agbolade O; Nazri A,10.3390/sym12071182,Universiti Putra Malaysia,"One of the most pertinent applications of image analysis is face recognition and one of the most common genetic disorders is Down syndrome (DS), which is caused by chromosome abnormalities in humans. It is currently a challenge in computer vision in the domain of DS face recognition to build an automated system that equals the human ability to recognize face as one of the symmetrical structures in the body. Consequently, the use of machine learning methods has facilitated the recognition of facial dysmorphic features associated with DS. This paper aims to present a concise review of DS face recognition using the currently published literature by following the generic face recognition pipeline (face detection, feature extraction, and classification) and to identify critical knowledge gaps and directions for future research. The technologies underlying facial analysis presented in recent studies have helped expert clinicians in general genetic disorders and DS prediction.","face recognition,Down syndrome,computer vision,face dysmorphology",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"SYSTEM,DYSMORPHOLOGY,CHILDREN,MODEL,2D",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/7/1182/pdf,
40,A Novel Method for Detection of Tuberculosis in Chest Radiographs Using Artificial Ecosystem-Based Optimisation of Deep Neural Network Features,12,7,,"Sahlol Ahmed T.,Abd Elaziz Mohamed,Jamal Amani Tariq,Damasevicius Robertas,Hassan Osama Farouk","Sahlol AT,Abd Elaziz M,Jamal AT,Damasevicius R,Hassan OF",Abd Elaziz M,10.3390/sym12071146,Egyptian Knowledge Bank (EKB),"Tuberculosis (TB) is is an infectious disease that generally attacks the lungs and causes death for millions of people annually. Chest radiography and deep-learning-based image segmentation techniques can be utilized for TB diagnostics. Convolutional Neural Networks (CNNs) has shown advantages in medical image recognition applications as powerful models to extract informative features from images. Here, we present a novel hybrid method for efficient classification of chest X-ray images. First, the features are extracted from chest X-ray images using MobileNet, a CNN model, which was previously trained on the ImageNet dataset. Then, to determine which of these features are the most relevant, we apply the Artificial Ecosystem-based Optimization (AEO) algorithm as a feature selector. The proposed method is applied to two public benchmark datasets (Shenzhen and Dataset 2) and allows them to achieve high performance and reduced computational time. It selected successfully only the best 25 and 19 (for Shenzhen and Dataset 2, respectively) features out of about 50,000 features extracted with MobileNet, while improving the classification accuracy (90.2% for Shenzen dataset and 94.1% for Dataset 2). The proposed approach outperforms other deep learning methods, while the results are the best compared to other recently published works on both datasets.","Tuberculosis (TB),transfer learning,convolutional neural networks,deep learning,Artificial Ecosystem-based Optimization,image processing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"CLASSIFICATION,DISEASES",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/7/1146/pdf,
41,Deep Learning System for COVID-19 Diagnosis Aid Using X-ray Pulmonary Images,10,13,,"Civit-Masot Javier,Luna-Perejon Francisco,Dominguez Morales Manuel,Civit Anton","Civit-Masot J,Luna-Perejon F,Morales MD,Civit A",Civit-Masot J,10.3390/app10134640,University of Sevilla,"Featured Application This work has direct applications to COVID-19 diagnosis. The spread of the SARS-CoV-2 virus has made the COVID-19 disease a worldwide epidemic. The most common tests to identify COVID-19 are invasive, time consuming and limited in resources. Imaging is a non-invasive technique to identify if individuals have symptoms of disease in their lungs. However, the diagnosis by this method needs to be made by a specialist doctor, which limits the mass diagnosis of the population. Image processing tools to support diagnosis reduce the load by ruling out negative cases. Advanced artificial intelligence techniques such as Deep Learning have shown high effectiveness in identifying patterns such as those that can be found in diseased tissue. This study analyzes the effectiveness of a VGG16-based Deep Learning model for the identification of pneumonia and COVID-19 using torso radiographs. Results show a high sensitivity in the identification of COVID-19, around 100%, and with a high degree of specificity, which indicates that it can be used as a screening test. AUCs on ROC curves are greater than 0.9 for all classes considered.","COVID-19,pandemic,deep learning,neural networks,X-ray,medical images",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://idus.us.es/bitstream/11441/101381/1/applsci-10-04640.pdf,
42,Analyzing Age-Related Macular Degeneration Progression in Patients with Geographic Atrophy Using Joint Autoencoders for Unsupervised Change Detection,6,7,,"Dupont Guillaume,Kalinicheva Ekaterina,Sublime Jeremie,Rossant Florence,Paques Michel","Dupont G,Kalinicheva E,Sublime J,Rossant F,Paques M",Sublime J; Rossant F,10.3390/jimaging6070057,"ISEP, DaSSIP Team, F-92130 Issy Les Moulineaux, France.","Age-Related Macular Degeneration (ARMD) is a progressive eye disease that slowly causes patients to go blind. For several years now, it has been an important research field to try to understand how the disease progresses and find effective medical treatments. Researchers have been mostly interested in studying the evolution of the lesions using different techniques ranging from manual annotation to mathematical models of the disease. However, artificial intelligence for ARMD image analysis has become one of the main research focuses to study the progression of the disease, as accurate manual annotation of its evolution has proved difficult using traditional methods even for experienced practicians. In this paper, we propose a deep learning architecture that can detect changes in the eye fundus images and assess the progression of the disease. Our method is based on joint autoencoders and is fully unsupervised. Our algorithm has been applied to pairs of images from different eye fundus images time series of 24 ARMD patients. Our method has been shown to be quite effective when compared with other methods from the literature, including non-neural network based algorithms that still are the current standard to follow the disease progression and change detection methods from other fields.","ARMD,change detection,unsupervised learning,medical imaging",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Imaging Science & Photographic Technology,,,"SEGMENTATION,IMAGES",JOURNAL OF IMAGING,https://hal.archives-ouvertes.fr/hal-02879597/file/mdpi_jimaging.pdf,
43,Prediction and Optimization of Surface Roughness in a Turning Process Using the ANFIS-QPSO Method,13,13,,"Alajmi Mahdi S.,Almeshal Abdullah M.","Alajmi MS,Almeshal AM",Alajmi MS,10.3390/ma13132986,Public Authority for Applied Education & Training (PAAET) - Kuwait,"This study presents a prediction method of surface roughness values for dry and cryogenic turning of AISI 304 stainless steel using the ANFIS-QPSO machine learning approach. ANFIS-QPSO combines the strengths of artificial neural networks, fuzzy systems and evolutionary optimization in terms of accuracy, robustness and fast convergence towards global optima. Simulations revealed that ANFIS-QPSO results in accurate prediction of surface roughness with RMSE = 4.86%, MAPE = 4.95% and R-2= 0.984 for the dry turning process. Similarly, for the cryogenic turning process, ANFIS-QPSO resulted in surface roughness predictions with RMSE = 5.08%, MAPE = 5.15% and R-2= 0.988 that are of high agreement with the measured values. Performance comparisons between ANFIS-QPSO, ANFIS, ANFIS-GA and ANFIS-PSO suggest that ANFIS-QPSO is an effective method that can ensure a high prediction accuracy of surface roughness values for dry and cryogenic turning processes.","adaptive neuro-fuzzy inference system,turning process,surface roughness,machine learning,quantum particle swarm optimization,ANFIS-QPSO,ANN",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"PARTICLE,SWARM,OPTIMIZATION,MULTIOBJECTIVE,OPTIMIZATION,MODEL,STEEL,PERFORMANCE,PARAMETERS,ALGORITHM,TAGUCHI,RSM",MATERIALS,https://www.mdpi.com/1996-1944/13/13/2986/pdf,
44,A semi-automated machine learning-aided approach to quantitative analysis of centrosomes and microtubule organization,133,14,,"Sankaran Divya Ganapathi,Stemm-Wolf Alexander J.,McCurdy Bailey L.,Hariharan Bharath,Pearson Chad G.","Sankaran DG,Stemm-Wolf AJ,McCurdy BL,Hariharan B,Pearson CG",Pearson CG,10.1242/jcs.243543,University of Colorado System,"Microtubules (MTs) promote important cellular functions including migration, intracellular trafficking, and chromosome segregation. The centrosome, comprised of two centrioles surrounded by the pericentriolar material (PCM), is the cell's central MT-organizing center. Centrosomes in cancer cells are commonly numerically amplified. However, the question of how the amplification of centrosomes alters MT organization capacity is not well studied. We developed a quantitative image-processing and machine learning-aided approach for the semi-automated analysis of MT organization. We designed a convolutional neural network-based approach for detecting centrosomes, and an automated pipeline for analyzing MT organization around centrosomes, encapsulated in a semi-automatic graphical tool. Using this tool, we find that breast cancer cells with supernumerary centrosomes not only have more PCM protein per centrosome, which gradually increases with increasing centriole numbers, but also exhibit expansion in PCM size. Furthermore, cells with amplified centrosomes have more growing MT ends, higher MT density and altered spatial distribution of MTs around amplified centrosomes. Thus, the semi-automated approach developed here enables rapid and quantitative analyses revealing important facets of centrosomal aberrations.","Centrosomes,Microtubules,EB3,Machine learning,Centrosome amplification,Image processing",Article,"COMPANY BIOLOGISTS LTD, BIDDER BUILDING, STATION RD, HISTON, CAMBRIDGE CB24 9LF, ENGLAND",Cell Biology,,6.032,"BREAST-CANCER,IN-VITRO,NUCLEATION,MICROSCOPY,GROWTH,POLYMERIZATION,INSTABILITY,GENERATION,CENTRIOLES,DYNAMICS",JOURNAL OF CELL SCIENCE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7406313,
45,Generating contextual embeddings for emergency department chief complaints,3,2,160-166,"Chang David,Hong Woo Suk,Taylor Richard Andrew","Chang D,Hong WS,Taylor RA",Taylor RA,10.1093/jamiaopen/ooaa022,Yale University,"Objective: We learn contextual embeddings for emergency department (ED) chief complaints using Bidirectional Encoder Representations from Transformers (BERT), a state-of-the-art language model, to derive a compact and computationally useful representation for free-text chief complaints.
Materials and methods: Retrospective data on 2.1 million adult and pediatric ED visits was obtained from a large healthcare system covering the period of March 2013 to July 2019. A total of 355 497 (16.4%) visits from 65 737 (8.9%) patients were removed for absence of either a structured or unstructured chief complaint. To ensure adequate training set size, chief complaint labels that comprised less than 0.01%, or 1 in 10 000, of all visits were excluded. The cutoff threshold was incremented on a log scale to create seven datasets of decreasing sparsity. The classification task was to predict the provider-assigned label from the free-text chief complaint using BERT, with Long Short-Term Memory (LSTM) and Embeddings from Language Models (ELMo) as baselines. Performance was measured as the Top-k accuracy from k = 1:5 on a hold-out test set comprising 5% of the samples. The embedding for each free-text chief complaint was extracted as the final 768-dimensional layer of the BERT model and visualized using t-distributed stochastic neighbor embedding (t-SNE).
Results: The models achieved increasing performance with datasets of decreasing sparsity, with BERT outperforming both LSTM and ELMo. The BERT model yielded Top-1 accuracies of 0.65 and 0.69, Top-3 accuracies of 0.87 and 0.90, and Top-5 accuracies of 0.92 and 0.94 on datasets comprised of 434 and 188 labels, respectively. Visualization using t-SNE mapped the learned embeddings in a clinically meaningful way, with related concepts embedded close to each other and broader types of chief complaints clustered together.
Discussion: Despite the inherent noise in the chief complaint label space, the model was able to learn a rich representation of chief complaints and generate reasonable predictions of their labels. The learned embeddings accurately predict provider-assigned chief complaint labels and map semantically similar chief complaints to nearby points in vector space.
Conclusion: Such a model may be used to automatically map free-text chief complaints to structured fields and to assist the development of a standardized, data-driven ontology of chief complaints for healthcare institutions.","BERT,chief complaint,emergency medicine,machine learning,natural language processing",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Health Care Sciences & Services,Medical Informatics",,,PREDICTION,JAMIA OPEN,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7382638,
46,"The anatomy of a distributed predictive modeling framework: online learning, blockchain network, and consensus algorithm",3,2,201-208,Kuo Tsung-Ting,Kuo TT,Kuo TT,10.1093/jamiaopen/ooaa017,University of California System,"Objective: Cross-institutional distributed healthcare/genomic predictive modeling is an emerging technology that fulfills both the need of building a more generalizable model and of protecting patient data by only exchanging the models but not the patient data. In this article, the implementation details are presented for one specific blockchain-based approach, ExplorerChain, from a software development perspective. The healthcare/ genomic use cases of myocardial infarction, cancer biomarker, and length of hospitalization after surgery are also described.
Materials and Methods: ExplorerChain's 3 main technical components, including online machine learning, metadata of transaction, and the Proof-of-Information-Timed (PoINT) algorithm, are introduced in this study. Specifically, the 3 algorithms (ie, core, new network, and new site/data) are described in detail.
Results: ExplorerChain was implemented and the design details of it were illustrated, especially the development configurations in a practical setting. Also, the system architecture and programming languages are introduced. The code was also released in an open source repository available at https://github.com/tsungtingkuo/explorerchain.
Discussion: The designing considerations of semi-trust assumption, data format normalization, and nondeterminism was discussed. The limitations of the implementation include fixed-number participating sites, limited join-or-leave capability during initialization, advanced privacy technology yet to be included, and further investigation in ethical, legal, and social implications.
Conclusion: This study can serve as a reference for the researchers who would like to implement and even deploy blockchain technology. Furthermore, the off-the-shelf software can also serve as a cornerstone to accelerate the development and investigation of future healthcare/genomic blockchain studies.","blockchain distributed ledger technology,privacy-preserving predictive modeling,clinical information systems,decision support systems",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Health Care Sciences & Services,Medical Informatics",,,"PROPAGATION,LOGISTIC-REGRESSION,PRIVACY",JAMIA OPEN,https://escholarship.org/content/qt9vx4w7xb/qt9vx4w7xb.pdf?t=qeu586,
47,ClinicNet: machine learning for personalized clinical order set recommendations,3,2,216-224,"Wang Jonathan X.,Sullivan Delaney K.,Wells Alex C.,Chen Jonathan H.","Wang JX,Sullivan DK,Wells AC,Chen JH",Chen JH,10.1093/jamiaopen/ooaa021,Stanford University,"Objective: This study assessesA whether neural networks trained on electronic health record (EHR) data can anticipate what individual clinical orders and existing institutional order set templates clinicians will use more accurately than existing decision support tools.
Materials and Methods: We process 57 624 patients worth of clinical event EHR data from 2008 to 2014. We train a feed-forward neural network (ClinicNet) and logistic regression applied to the traditional problem structure of predicting individual clinical items as well as our proposed workflow of predicting existing institutional order set template usage.
Results: ClinicNet predicts individual clinical orders (precision = 0.32, recall = 0.47) better than existing institutional order sets (precision = 0.15, recall = 0.46). The ClinicNet model predicts clinician usage of existing institutional order sets (avg. precision = 0.31) with higher average precision than a baseline of order set usage frequencies (avg. precision = 0.20) or a logistic regression model (avg. precision = 0.12).
Discussion: Machine learning methods can predict clinical decision-making patterns with greater accuracy and less manual effort than existing static order set templates. This can streamline existing clinical workflows, but may not fit if historical clinical ordering practices are incorrect. For this reason, manually authored content such as order set templates remain valuable for the purposeful design of care pathways. ClinicNet's capability of predicting such personalized order set templates illustrates the potential of combining both top-down and bottomup approaches to delivering clinical decision support content.
Conclusion: ClinicNet illustrates the capability for machine learning methods applied to the EHR to anticipate both individual clinical orders and existing order set templates, which has the potential to improve upon current standards of practice in clinical order entry.","clinical decision support systems,precision medicine,electronic health records,order sets,deep learning",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Health Care Sciences & Services,Medical Informatics",,,"ELECTRONIC,HEALTH,RECORDS,DECISION-SUPPORT-SYSTEMS,NEURAL-NETWORKS,HITECH,ACT,CARE,SATISFACTION,BENEFITS,ADOPTION,BURNOUT,QUALITY",JAMIA OPEN,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7382624,
48,Artificial intelligence-based conversational agent to support medication prescribing,3,2,225-232,"Preininger Anita M.,South Brett,Heiland Jeff,Buchold Adam,Baca Mya,Wang Suwei,Nipper Rex,Kutub Nawshin,Bohanan Bryan,Jackson Gretchen Purcell","Preininger AM,South B,Heiland J,Buchold A,Baca M,Wang SW,Nipper R,Kutub N,Bohanan B,Jackson GP",Preininger AM,10.1093/jamiaopen/ooaa009,"IBM Watson Hlth, 75 Binney St, Cambridge, MA 02142 USA.","Objective: This article describes the system architecture, training, initial use, and performance of Watson Assistant (WA), an artificial intelligence-based conversational agent, accessible within Micromedex (R).
Materials and methods: The number and frequency of intents (target of a user's query) triggered in WA during its initial use were examined; intents triggered over 9 months were compared to the frequency of topics accessed via keyword search of Micromedex. Accuracy of WA intents assigned to 400 queries was compared to assignments by 2 independent subject matter experts (SMEs), with inter-rater reliability measured by Cohen's kappa.
Results: In over 126 000 conversations with WA, intents most frequently triggered involved dosing (N = 30 239, 23.9%) and administration (N = 14 520, 11.5%). SMEs with substantial inter-rater agreement (kappa = 0.71) agreed with intent mapping in 247 of 400 queries (62%), including 16 queries related to content that WA and SMEs agreed was unavailable in WA. SMEs found 57 (14%) of 400 queries incorrectly mapped by WA; 112 (28%) queries unanswerable by WA included queries that were either ambiguous, contained unrecognized typographical errors, or addressed topics unavailable to WA. Of the queries answerable by WA (288), SMEs determined 231 (80%) were correctly linked to an intent.
Discussion: A conversational agent successfully linked most queries to intents in Micromedex. Ongoing system training seeks to widen the scope of WA and improve matching capabilities.
Conclusion: WA enabled Micromedex users to obtain answers to many medication-related questions using natural language, with the conversational agent facilitating mapping to a broader distribution of topics than standard keyword searches.","conversational agents,pharmacological information systems,machine learning,natural language processing,artificial intelligence",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Health Care Sciences & Services,Medical Informatics",,,"DRUG,INTERACTIONS,AGREEMENT,SOFTWARE",JAMIA OPEN,https://academic.oup.com/jamiaopen/article-pdf/3/2/225/33532910/ooaa009.pdf,
49,Estimating real-world performance of a predictive model: a case-study in predicting mortality,3,2,243-251,"Major Vincent J.,Jethani Neil,Aphinyanaphongs Yindalon","Major VJ,Jethani N,Aphinyanaphongs Y",Major VJ,10.1093/jamiaopen/ooaa008,NYU Langone Medical Center,"Objective: One primary consideration when developing predictive models is downstream effects on future model performance. We conduct experiments to quantify the effects of experimental design choices, namely cohort selection and internal validation methods, on (estimated) real-world model performance.
Materials and Methods: Four years of hospitalizations are used to develop a 1-year mortality prediction model (composite of death or initiation of hospice care). Two common methods to select appropriate patient visits from their encounter history (backwards-from-outcome and forwards-from-admission) are combined with 2 testing cohorts (random and temporal validation). Two models are trained under otherwise identical conditions, and their performances compared. Operating thresholds are selected in each test set and applied to a ""real-world"" cohort of labeled admissions from another, unused year.
Results: Backwards-from-outcome cohort selection retains 25% of candidate admissions (n = 23 579), whereas forwards-from-admission selection includes many more (n = 92 148). Both selection methods produce similar performances when applied to a random test set. However, when applied to the temporally defined ""real-world"" set, forwards-from-admission yields higher areas under the ROC and precision recall curves (88.3% and 56.5% vs. 83.2% and 41.6%).
Discussion: A backwards-from-outcome experiment manipulates raw training data, simplifying the experiment. This manipulated data no longer resembles real-world data, resulting in optimistic estimates of test set performance, especially at high precision. In contrast, a forwards-from-admission experiment with a temporally separated test set consistently and conservatively estimates real-world performance.
Conclusion: Experimental design choices impose bias upon selected cohorts. A forwards-from-admission experiment, validated temporally, can conservatively estimate real-world performance.","experimental design,data science,machine learning,reproducibility of results,mortality",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Health Care Sciences & Services,Medical Informatics",,,"PALLIATIVE,CARE,SURVIVAL",JAMIA OPEN,https://academic.oup.com/jamiaopen/article-pdf/3/2/243/33532974/ooaa008.pdf,
50,Machine learning for early detection of sepsis: an internal and temporal validation study,3,2,252-260,"Bedoya Armando D.,Futoma Joseph,Clement Meredith E.,Corey Kristin,Brajer Nathan,Lin Anthony,Simons Morgan G.,Gao Michael,Nichols Marshall,Balu Suresh","Bedoya AD,Futoma J,Clement ME,Corey K,Brajer N,Lin A,Simons MG,Gao M,Nichols M,Balu S",Bedoya AD,10.1093/jamiaopen/ooaa006,Duke University,"Objective: Determine if deep learning detects sepsis earlier and more accurately than other models. To evaluate model performance using implementation-oriented metrics that simulate clinical practice.
Materials and Methods: We trained internally and temporally validated a deep learning model (multi-output Gaussian process and recurrent neural network [MGP-RNN]) to detect sepsis using encounters from adult hospitalized patients at a large tertiary academic center. Sepsis was defined as the presence of 2 or more systemic inflammatory response syndrome (SIRS) criteria, a blood culture order, and at least one element of end-organ failure. The training dataset included demographics, comorbidities, vital signs, medication administrations, and labs from October 1, 2014 to December 1, 2015, while the temporal validation dataset was from March 1, 2018 to August 31, 2018. Comparisons were made to 3 machine learning methods, random forest (RF), Cox regression (CR), and penalized logistic regression (PLR), and 3 clinical scores used to detect sepsis, SIRS, quick Sequential Organ Failure Assessment (qSOFA), and National Early Warning Score (NEWS). Traditional discrimination statistics such as the C-statistic as well as metrics aligned with operational implementation were assessed.
Results: The training set and internal validation included 42 979 encounters, while the temporal validation set included 39 786 encounters. The C-statistic for predicting sepsis within 4 h of onset was 0.88 for the MGP-RNN compared to 0.836 for RF, 0.849 for CR, 0.822 for PLR, 0.756 for SIRS, 0.619 for NEWS, and 0.481 for qSOFA. MGP-RNN detected sepsis a median of 5 h in advance. Temporal validation assessment continued to show the MGP-RNN outperform all 7 clinical risk score and machine learning comparisons.
Conclusions: We developed and validated a novel deep learning model to detect sepsis. Using our data elements and feature set, ourmodeling approach outperformed other machine learningmethods and clinical scores.","adult,sepsis/mortality,electronic health records/statistics and numerical data,machine learning,decision,support systems,clinical,emergency service,hospital/statistics and numerical data,hospitalization/statistics and numerical data,ROC curve,retrospective studies",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Health Care Sciences & Services,Medical Informatics",,,"PERFORMANCE,IMPROVEMENT,PROGRAM,CONSENSUS,DEFINITIONS,PREDICTION,IMPLEMENTATION,MORTALITY",JAMIA OPEN,https://academic.oup.com/jamiaopen/article-pdf/3/2/252/33532937/ooaa006.pdf,
51,Comparison of patient stratification by computed tomography radiomics and hypoxia positron emission tomography in head-and-neck cancer radiotherapy,15,,52-59,"Fernandez Jairo A. Socarras,Moennich David,Leibfarth Sara,Welz Stefan,Zwanenburg Alex,Leger Stefan,Loeck Steffen,Pfannenberg Christina,La Fougere Christian,Reischl Gerald","Fernandez JAS,Monnich D,Leibfarth S,Welz S,Zwanenburg A,Leger S,Lock S,Pfannenberg C,La Fougere C,Reischl G",Thorwarth D,10.1016/j.phro.2020.07.003,Eberhard Karls University of Tubingen,"Background and purpose: Hypoxia Positron-Emission-Tomography (PET) as well as Computed Tomography (CT) radiomics have been shown to be prognostic for radiotherapy outcome. Here, we investigate the stratification potential of CT-radiomics in head and neck cancer (HNC) patients and test if CT-radiomics is a surrogate predictor for hypoxia as identified by PET.
Materials and methods: Two independent cohorts of HNC patients were used for model development and validation, HN1 (n = 149) and HN2 (n = 47). The training set HN1 consisted of native planning CT data whereas for the validation cohort HN2 also hypoxia PET/CT data was acquired using [F-18]-Fluoromisonidazole (FMISO). Machine learning algorithms including feature engineering and classifier selection were trained for two-year loco-regional control (LRC) to create optimal CT-radiomics signatures.
Secondly, a pre-defined [F-18]FMISO-PET tumour-to-muscle-ratio (TMRpeak >= 1.6) was used for LRC prediction. Comparison between risk groups identified by CT-radiomics or [F-18]FMISO-PET was performed using area-under-the-curve (AUC) and Kaplan-Meier analysis including log-rank test.
Results: The best performing CT-radiomics signature included two features with nearest-neighbour classification (AUC = 0.76 +/- 0.09), whereas AUC was 0.59 for external validation. In contrast, [F-18]FMISO TMRpeak reached an AUC of 0.66 in HN2. Kaplan-Meier analysis of the independent validation cohort HN2 did not confirm the prognostic value of CT-radiomics (p = 0.18), whereas for [F-18]FMISO-PET significant differences were observed (p = 0.02).
Conclusions: No direct correlation of patient stratification using [F-18]FMISO-PET or CT-radiomics was found in this study. Risk groups identified by CT-radiomics or hypoxia PET showed only poor overlap. Direct assessment of tumour hypoxia using PET seems to be more powerful to stratify HNC patients.","Radiomics,PET-Imaging,Quantitative Imaging,CT-Imaging,Machine Learning,Imaging biomarkers",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,,"LOCAL,TUMOR-CONTROL,PROSPECTIVE,TRIAL,PET,RADIOCHEMOTHERAPY,CT,RADIOGENOMICS,HETEROGENEITY,INFORMATION",PHYSICS & IMAGING IN RADIATION ONCOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7536307,
52,The finite element analysis-based simulation and artificial neural network-based prediction for milling processes of aluminum alloy 7050,235,1-2,265-277,"Ma Wei,Wang Rongqi,Zhou Xiaoqin,Xie Xuefan","Ma W,Wang RQ,Zhou XQ,Xie XF",Wang RQ,10.1177/0954405420932442,Jilin University,"The cutting forces will generally suffer massive complex factors, such as material deformation, tool eccentricity and system vibration, which will inevitably induce many great difficulties in accurately modeling the cutting force predictions that are very significant to investigate cutting processes. Therefore, the genetic algorithm optimized back-propagation and particle swarm optimization neural networks will be adopted to effectively construct cutting force prediction models. In these two back-propagation prediction models, the main milling parameters will be defined into their input vectors, and the transient milling forces along three different directions will be selected as their output vectors, then the implicit relationships between input and output vectors can be directly generated through practically training and learning these two built back-propagation models with a set of experimental milling force data. Meanwhile, the finite element analysis method will be also used to predict milling forces through programming two easy-to-operate plug-ins that can efficiently construct finite element analysis models, conveniently define processing parameters, and automatically perform mesh generation. Subsequently, the milling forces predicted by the established genetic algorithm optimized back-propagation and particle swarm optimization back-propagation models will be analytically compared with finite element analysis simulations and experiments; also the stress distribution and chip formations of finite element analysis and experiments will be comparatively investigated. Finally, the obtained results clearly indicate that these two back-propagation models built by artificial neural networks can well agree with finite element analysis simulations and experiments, but the particle swarm optimization back-propagation model is superior to the genetic algorithm optimized back-propagation model, which clearly demonstrate the particle swarm optimization back-propagation model has higher efficiencies and accuracies in predicting the average and transient cutting forces for different milling processes on aluminum alloy 7050.","Cutting forces prediction,finite element analysis,particle swarm optimization,genetic algorithm,artificial neural network",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Engineering,,2.464,"CUTTING,FORCE,OPERATION,ALGORITHM",PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART B-JOURNAL OF ENGINEERING MANUFACTURE,,
53,Fuzzy Neural Network PID-based constant deceleration compensation device for the brakes of mining hoists,12,7,,"Ma Chi,Tian Suzhi,Xiao Xinming,Jiang Yuqiang","Ma C,Tian SZ,Xiao XM,Jiang YQ",Ma C,10.1177/1687814020937568,China University of Mining & Technology,"In comparison with constant torque brakes, constant deceleration brakes are more advantageous for the safety of mining hoists, but complete set of such products manufactured by big companies are not what ordinary mining enterprises can afford. As an alternative solution, this article develops a constant deceleration compensation device, which adds the function of constant deceleration brake onto the original brakes. Control strategy based on Fuzzy Neural Network PID is investigated and simulated with the combination of AMEsim and Simulink. An actual device is built and tested in real industrial field. The application illustrates the feasibility of this constant deceleration compensation device, which can achieve constant decelerations within a very short time. This device will prevent dangerous decelerations from happening to hoists at a much lower cost, and greatly improve the safety and reliability of mining hoists.","Mining hoist,constant deceleration brake,PID,Fuzzy Neural Network,AMEsim",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Thermodynamics,Engineering",,1.393,,ADVANCES IN MECHANICAL ENGINEERING,https://journals.sagepub.com/doi/pdf/10.1177/1687814020937568,
54,Dynamic distance learning for joint assessment of visual and semantic similarities within the framework of medical image retrieval,122,,,"Baazaoui Abir,Abderrahim Marwa,Barhoumi Walid","Baazaoui A,Abderrahim M,Barhoumi W",Baazaoui A,10.1016/j.compbiomed.2020.103833,"SIIVA LIMTIC Lab Inst Super Informat, 2 Rue Abou Rayhane Bayrouni, Ariana 2080, Tunisia.","The similarity measure is an essential part of medical image retrieval systems for assisting in radiological diagnosis. Attempts have been made to use distance metric learning approaches to improve the retrieval performance while decreasing the semantic gap. However, existing approaches did not resolve the problem of dependency between images (e.g. normal and abnormal images are compared with the same distance). This affects the semantic and the visual similarity. Thus, this work aims at learning a distance metric which preserves both visual resemblance and semantic similarity and modeling this distance in order to treat each query independently. The proposed method is described in three stages: (1) low-level image feature extraction, (2) offline distance metric modeling, and (3) online retrieval. The first stage exploits transform-domain texture descriptors based on local binary pattern histogram Fourier, shearlet, and curvelet transforms. The second stage is carried out using low-level features and machine learning. Given a query image, the online retrieval is based on the evaluation of the similarity between this image and each image within the dataset, while using a distance that is dynamically defined according to the query image. Realized experiments on the challenging Mammographic Image Analysis Society (MIAS) and Digital Database for Screening Mammography (DDSM) datasets prove the effectiveness of the proposed method in determining dynamically the adequate distance and retrieving the most semantically similar images, while investigating single low-level features as well as fused ones.","Semantic similarity,Dynamic distance learning,Medical image retrieval,Feature fusion,Visual similarity",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,,,COMPUTERS IN BIOLOGY AND MEDICINE,,
55,Automated sperm morphology analysis approach using a directional masking technique,122,,,"Ilhan Hamza Osman,Serbes Gorkem,Aydin Nizamettin","Ilhan HO,Serbes G,Aydin N",Ilhan HO,10.1016/j.compbiomed.2020.103845,Yildiz Technical University,"Sperm Morphology is the key step in the assessment of sperm quality. Due to the effect of misleading human factors in manual assessments, computer-based techniques should be employed in the analysis. In this study, a computation framework including multi-stage cascade connected preprocessing techniques, region based descriptor features, and non-linear kernel SVM based learning is proposed for the classification of any stained sperm images for the assessment of the morphology. The proposed framework was evaluated on two sperm morphology datasets: the Human Sperm Head Morphology dataset (HuSHeM) and Sperm Morphology Image Data Set (SMIDS). The results indicate that cascading the preprocessing techniques used in the proposed framework, such as wavelet based local adaptive de-noising, modified overlapping group shrinkage, image gradient, and automatic directional masking, increased the classification accuracy by 10% and 5% for the HuSHeM and SMIDS, respectively. The proposed framework results in better overall accuracy than most state-of-the-art methods, while having significant advantages, such as eliminating the exhaustive manual orientation and cropping operations of the competitors with reasonable rates of consumption of time and source.","Directional masking technique,Sperm morphology classification,Descriptor based feature extraction,Wavelet based local adaptive de-noising,Support vector machines,Maximally stable extremal regions",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"WAVELET,TRANSFORM,BIVARIATE,SHRINKAGE,GOLD-STANDARD,CLASSIFICATION,SEMEN,RECONSTRUCTION,IDENTIFICATION,MORPHOMETRY,SPERMIOGRAM,DIMENSIONS",COMPUTERS IN BIOLOGY AND MEDICINE,,
56,CovXNet: A multi-dilation convolutional neural network for automatic COVID-19 and other pneumonia detection from chest X-ray images with transferable multi-receptive feature optimization,122,,,"Mahmud Tanvir,Rahman Md Awsafur,Fattah Shaikh Anowarul","Mahmud T,Rahman MA,Fattah SA",Fattah SA,10.1016/j.compbiomed.2020.103869,Bangladesh University of Engineering & Technology (BUET),"With the recent outbreak of COVID-19, fast diagnostic testing has become one of the major challenges due to the critical shortage of test kit. Pneumonia, a major effect of COVID-19, needs to be urgently diagnosed along with its underlying reasons. In this paper, deep learning aided automated COVID-19 and other pneumonia detection schemes are proposed utilizing a small amount of COVID-19 chest X-rays. A deep convolutional neural network (CNN) based architecture, named as CovXNet, is proposed that utilizes depthwise convolution with varying dilation rates for efficiently extracting diversified features from chest X-rays. Since the chest Xray images corresponding to COVID-19 caused pneumonia and other traditional pneumonias have significant similarities, at first, a large number of chest X-rays corresponding to normal and (viral/bacterial) pneumonia patients are used to train the proposed CovXNet. Learning of this initial training phase is transferred with some additional fine-tuning layers that are further trained with a smaller number of chest X-rays corresponding to COVID-19 and other pneumonia patients. In the proposed method, different forms of CovXNets are designed and trained with X-ray images of various resolutions and for further optimization of their predictions, a stacking algorithm is employed. Finally, a gradient-based discriminative localization is integrated to distinguish the abnormal regions of X-ray images referring to different types of pneumonia. Extensive experimentations using two different datasets provide very satisfactory detection performance with accuracy of 97.4% for COVID/Normal, 96.9% for COVID/Viral pneumonia, 94.7% for COVID/Bacterial pneumonia, and 90.2% for multiclass COVID/normal/Viral/Bacterial pneumonias. Hence, the proposed schemes can serve as an efficient tool in the current state of COVID-19 pandemic. All the architectures are made publicly available at: https: //github.com/Perceptron21/CovXNet.","COVID-19 diagnosis,Imaging informatics,Neural network,Pneumonia diagnosis,Transfer learning,X-ray",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,,COMPUTERS IN BIOLOGY AND MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7305745,
57,A wavelet-based algorithm for automated analysis of external tocography: How does it compare to human interpretation?,122,,,"Reynolds Adam J.,Waldron Orna M.,Halpern Elise M.,McGarvey Cliona M.,Murray Michelle L.);,Ater Stewart B.);,Geary Michael P.,Hayes Breda C.","Reynolds AJ,Waldron OM,Halpern EM,McGarvey CM,Murray ML,Ater SB,Geary MP,Hayes BC",Reynolds AJ,10.1016/j.compbiomed.2020.103814,"Rotunda Hosp, Dept Neonatol, Parnell Sq, Dublin DO1 P5W9 1, Ireland.","Background: Studies which use external tocography to explore the relationship between increased intrapartum uterine activity and foetal outcomes are feasible because the technology is safe and ubiquitous. However, periods of poor signal quality are common. We developed an algorithm which aims to calculate tocograph summary variables based on well-recorded contractions only, ignoring artefact and excluding sections deemed uninter-pretable. The aim of this study was to test that algorithm's reliability.
Methods: Whole recordings from labours at.35 weeks of gestation were randomly selected without regard to quality. Contractions and rest intervals were measured by two humans independently, and by the algorithm using two sets of models; one based on a series of pre-defined thresholds, and another trained to imitate one of the human interpreters. The absolute agreement intraclass correlation coefficient (ICC) was calculated using a two-way random effects model.
Results: The training dataset included data from 106 tocographs. Of the tested algorithms, AdaBoost showed the highest initial cross-validated accuracy and proceeded to optimization. Forty tocographs were included in the validation set. The ICCs for the per tocograph mean contraction rates were; human B to human A: 0.940 (0.890-0.968), human A to initial models: 0.944 (0.898-0.970), human A to trained models 0.962 (0.927-0.980), human B to initial models: 0.930 (0.872-0.962), human B to trained models: 0.948 (0.903-0.972).
Conclusions: The algorithm described approximates interpretation of external tocography performed by trained humans. The performance of the AdaBoost trained models was marginally superior compared to the initial models.","Labour,Intrapartum,Foetal monitoring,Tachysystole,Uterine activity,Contractions,Contraction rate,Contraction duration,Rest intervals,Machine learning,Reliability,Agreement",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"UTERINE,ACTIVITY,RELIABILITY",COMPUTERS IN BIOLOGY AND MEDICINE,,
58,A machine learning model for detecting invasive ductal carcinoma with Google Cloud AutoML Vision,122,,,"Zeng Yan,Zhang Jinmiao","Zeng Y,Zhang JM",Zhang JM,10.1016/j.compbiomed.2020.103861,Cardinal Health Inc,"Objectives: This study is aimed to assess the feasibility of AutoML technology for the identification of invasive ductal carcinoma (IDC) in whole slide images (WSI).
Methods: The study presents an experimental machine learning (ML) model based on Google Cloud AutoML Vision instead of a handcrafted neural network. A public dataset of 278,124 labeled histopathology images is used as the original dataset for the model creation. In order to balance the number of positive and negative IDC samples, this study also augments the original public dataset by rotating a large portion of positive image samples. As a result, a total number of 378,215 labeled images are applied.
Results: A score of 91.6% average accuracy is achieved during the model evaluation as measured by the area under precision-recall curve (AuPRC). A subsequent test on a held-out test dataset (unseen by the model) yields a balanced accuracy of 84.6%. These results outperform the ones reported in the earlier studies. Similar performance is observed from a generalization test with new breast tissue samples we collected from the hospital.
Conclusions: The results obtained from this study demonstrate the maturity and feasibility of an AutoML approach for IDC identification. The study also shows the advantage of AutoML approach when combined at scale with cloud computing.","Breast cancer,Invasive ductal carcinoma (IDC),Digital pathology,Whole slide image (WSI),Machine learning,AutoML vision,Google cloud",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"REPRODUCIBILITY,CLASSIFICATION",COMPUTERS IN BIOLOGY AND MEDICINE,,
59,Application of machine learning methods to predict a thermal conductivity model for compacted bentonite,142,,,"Bang Hyun-Tae,Yoon Seok,Jeon Haemin","Bang HT,Yoon S,Jeon H",Jeon H,10.1016/j.anucene.2020.107395,Hanbat National University,"Compacted bentonite is one of the widely used buffer materials for the disposal of high-level radioactive waste (HLW). Since the buffer is located between a disposal canister and near-field rock, it prevents the release of radionuclides, and protects the canister from external impact and the penetration of ground-water. To dissipate decay heat from the canister, the buffer should have high thermal conductivity, so one of the most important properties for HLW repository is the thermal conductivity of compacted bentonite. In this study, predictive models of thermal conductivity for the compacted bentonite has been designed and analyzed using machine learning methods including linear regression, decision tree, support vector machine, ensemble, Gaussian process regression (GPR), artificial neural network, and deep belief network. Most of the methods showed better performance in comparison with the previously proposed regression model, while the GPR with exponential kernel and the ensemble with XGBoost showed the best performance. (C) 2020 Elsevier Ltd. All rights reserved.","Compacted bentonite,Thermal conductivity,Regression analysis",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Nuclear Science & Technology,,1.826,"BUFFER,TEMPERATURE,BEHAVIOR",ANNALS OF NUCLEAR ENERGY,,
60,Logistic index for keratoconus detection and severity scoring (Logik),122,,,"Issarti Ikram,Consejo Alejandra,Jimenez-Garcia Marta,Kreps Elke O.,Koppen Carina,Rozema Jos J.","Issarti I,Consejo A,Jimenez-Garcia M,Kreps EO,Koppen C,Rozema JJ",Issarti I,10.1016/j.compbiomed.2020.103809,University of Antwerp,"Purpose: To develop an objective severity scoring system for keratoconus for the use in clinical practice.
Methods: Corneal elevation and minimum thickness data of 812 subjects were retrospectively collected and divided into two groups: one control group with normal topography in both eyes (304 eyes), and one keratoconus group (508 eyes). Keratoconus cases ranged from suspect to moderate and had at least 1 examination in 1 of 2 recruiting centres. The elevation data were fitted to Zernike polynomial functions up to 8th order. An adapted machine learning algorithm was then applied to derive a platform-independent severity scoring and identification system for keratoconus.
Results: The resulting logistic index for keratoconus (Logik) provided consistent and progressing scoring that reflected keratoconus severity. Moreover, the system provided an accurate classification of suspect keratoconus versus normal (sensitivity of 85.2%, specificity of 70.0%) when compared with Belin/Ambrosio Display Deviation (BAD_D) (sensitivity of 75.0%, specificity of 74.4%) and the Pentacam Topographical Keratoconus Classification (TKC) (sensitivity of 9.3%, specificity of 97.0%). Logik also showed better accuracy for grading keratoconus stages with an average accuracy of 99.9% versus (98.2%, 94.7%) with BAD_D and TKC respectively.
Conclusion: Logik is a reliable index to identify suspect keratoconus and to score the severity of the disease. It shows an agreement with existing approaches while achieving better performance.","Grading system,Cornea,Machine learning,Keratoconus,Refractive surgery,Progression,Severity",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,,"ORDER,ABERRATIONS,CROSS-LINKING,CORNEAL,MACHINE,VIDEOKERATOGRAPHY,CLASSIFICATION,PROGRESSION,CURVATURE,DIAGNOSIS,ANTERIOR",COMPUTERS IN BIOLOGY AND MEDICINE,,
61,Channel width optimized neural networks for liver and vessel segmentation in liver iron quantification,122,,,"Liu Michael,Vanguri Rami,Mutasa Simukayi,Ha Richard,Liu Yu-Cheng,Button Terry,Jambawalikar Sachin","Liu M,Vanguri R,Mutasa S,Ha R,Liu YC,Button T,Jambawalikar S",Liu M,10.1016/j.compbiomed.2020.103798,"CUMC NYP, Dept Radiol, 177 Ft Washington Ave, New York, NY 10032 USA.","Introduction: MRI T2* relaxometry protocols are often used for Liver Iron Quantification in patients with hemochromatosis. Several methods exist to semi-automatically segment parenchyma and exclude vessels for this calculation.
Purpose: To determine if inclusion of multiple echoes inputs to Convolutional Neural Networks (CNN) improves automated liver and vessel segmentation in MRI T2* relaxometry protocols and to determine if the resultant segmentations agree with manual segmentations for liver iron quantification analysis.
Methods: Multi echo Gradient Recalled Echo (GRE) MRI sequence for T2* relaxometry was performed for 79 exams on 31 patients with hemochromatosis for iron quantification analysis. 275 axial liver slices were manually segmented as ground truth masks. A batch normalized U-Net with variable input width to incorporate multiple echoes is used for segmentation, using DICE as the accuracy metric. ANOVA is used to evaluate significance of channel width changes in segmentation accuracy. Linear regression is used to model the relationship of channel width on segmentation accuracy. Liver segmentations are applied to relaxometry data to calculate liver T2* yielding liver iron concentration(LIC) derived from literature based calibration curves. Manual and CNN based LIC values are compared with Pearson correlation. Bland altman plots are used to visualize differences between manual and CNN based LIC values.
Results: Performance metrics are tested on 55 hold out slices. Linear regression indicates that there is a monotonic increase of DICE with increasing channel depth (p = 0.001) with a slope of 3.61e-3. ANOVA indicates a significant increase segmentation accuracy over single channel starting at 3 channels. Incorporation of all channels results in an average DICE of 0.86, an average increase of 0.07 over single channel. The calculated LIC from CNN segmented livers agrees well with manual segmentation (R = 0.998, slope = 0.914, p=0.001), with an average absolute difference 0.27 +/- 0.99 mg Fe/g or 1.34 +/- 4.3%.
Conclusion: More input echoes yields higher model accuracy until the noise floor. Echos beyond the first three echo times in GRE based T2* relaxometry do not contribute significant information for segmentation of liver for LIC calculation. Deep learning models with three channel width allow for generalization of model to protocols of more than three echoes, effectively a universal requirement for relaxometry. Deep learning segmentations achieve a good accuracy compared with manual segmentations with minimal preprocessing. Liver iron values calculated from hand segmented liver and Neural network segmented liver were not statistically different from each other.","Segmentation,MRI,Deep learning,Machine learning,Liver iron concentration",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"FIBROGLANDULAR,TISSUE,BREAST",COMPUTERS IN BIOLOGY AND MEDICINE,,
62,Semi-supervised labelling of the femur in a whole-body post-mortem CT database using deep learning,122,,,"Pena-Solorzano C. A.,Albrecht D. W.,Bassed R. B.,Gillam J.,Harris P. C.,Dimmock M. R.","Pena-Solorzano CA,Albrecht DW,Bassed RB,Gillam J,Harris PC,Dimmock MR",Pena-Solorzano CA,10.1016/j.compbiomed.2020.103797,Monash University,"A deep learning pipeline was developed and used to localize and classify a variety of implants in the femur contained in whole-body post-mortem computed tomography (PMCT) scans. The results provide a proof-of-principle approach for labelling content not described in medical/autopsy reports. The pipeline, which incorporated residual networks and an autoencoder, was trained and tested using n = 450 full-body PMCT scans. For the localization component, Dice scores of 0.99, 0.96, and 0.98 and mean absolute errors of 3.2, 7.1, and 4.2 mm were obtained in the axial, coronal, and sagittal views, respectively. A regression analysis found the orientation of the implant to the scanner axis and also the relative positioning of extremities to be statistically significant factors. For the classification component, test cases were properly labelled as nail (N+), hip replacement (H+), knee replacement (K+) or without-implant (I-) with an accuracy >97%. The recall for I- and H+ cases was 1.00, but fell to 0.82 and 0.65 for cases with K+ and N+. This semi-automatic approach provides a generalized structure for image-based labelling of features, without requiring time-consuming segmentation.","CT,Deep learning,Autoencoder,Semi-supervised,Machine learning,Femur localization,Femoral head representation,Knee representation,Post-mortem,Forensic",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"SEX,DETERMINATION,LOCALIZATION,SEGMENTATION,CLASSIFICATION,FRACTURES,NETWORK",COMPUTERS IN BIOLOGY AND MEDICINE,,
63,Multiclass magnetic resonance imaging brain tumor classification using artificial intelligence paradigm,122,,,"Tandel Gopal S.,Balestrieri Antonella,Jujaray Tanay,Khanna Narender N.,Saba Luca,Suri Jasjit S.","Tandel GS,Balestrieri A,Jujaray T,Khanna NN,Saba L,Suri JS",Suri JS,10.1016/j.compbiomed.2020.103804,"AtheroPointTM, Stroke Monitoring & Diagnost Div, Roseville, CA 95661 USA.","Motivation: Brain or central nervous system cancer is the tenth leading cause of death in men and women. Even though brain tumour is not considered as the primary cause of mortality worldwide, 40% of other types of cancer (such as lung or breast cancers) are transformed into brain tumours due to metastasis. Although the biopsy is considered as the gold standard for cancer diagnosis, it poses several challenges such as low sensitivity/specificity, risk during the biopsy procedure, and relatively long waiting times for the biopsy results. Due to an increase in the sheer volume of patients with brain tumours, there is a need for a non-invasive, automatic computer-aided diagnosis tool that can automatically diagnose and estimate the grade of a tumour accurately within a few seconds.
Method: Five clinically relevant multiclass datasets (two-, three-, four-, five-, and six-class) were designed. A transfer-learning-based Artificial Intelligence paradigm using a Convolutional Neural Network (CCN) was proposed and led to higher performance in brain tumour grading/classification using magnetic resonance imaging (MRI) data. We benchmarked the transfer-learning-based CNN model against six different machine learning (ML) classification methods, namely Decision Tree, Linear Discrimination, Naive Bayes, Support Vector Machine, K-nearest neighbour, and Ensemble.
Results: The CNN-based deep learning (DL) model outperforms the six types of ML models when considering five types of multiclass tumour datasets. These five types of data are two-, three-, four-, five, and six-class. The CNN-based AlexNet transfer learning system yielded mean accuracies derived from three kinds of cross-validation protocols (K2, K5, and K10) of 100, 95.97, 96.65, 87.14, and 93.74%, respectively. The mean areas under the curve of DL and ML were found to be 0.99 and 0.87, respectively, for p < 0.0001, and DL showed a 12.12% improvement over ML. Multiclass datasets were benchmarked against the TT protocol (where training and testing samples are the same). The optimal model was validated using a statistical method of a tumour separation index and verified on synthetic data consisting of eight classes.
Conclusion: The transfer-learning-based AI system is useful in multiclass brain tumour grading and shows better performance than ML systems.","Tumour grading system,Classification,Artificial intelligence,Transfer learning,Machine learning,Convolution neural network,Validation,Verification,Performance,Benchmarking",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"CONVOLUTIONAL,NEURAL-NETWORKS,THYROID,LESION,CLASSIFICATION,TISSUE,CHARACTERIZATION,AUTOMATED,CLASSIFICATION,ATHEROSCLEROTIC,PLAQUE,RISK,STRATIFICATION,FEATURE-SELECTION,LIVER-DISEASE,ULTRASOUND,TEXTURE",COMPUTERS IN BIOLOGY AND MEDICINE,,
64,"Complex networks of material flow in manufacturing and logistics: Modeling, analysis, and prediction using stochastic block models",56,,296-311,"Funke Thorben,Becker Till","Funke T,Becker T",Becker T,10.1016/j.jmsy.2020.06.015,"Univ Appl Sci Emden Leer, Fac Business Studies, Emden, Germany.","Modeling complex systems as networks of interacting elements has gained increased attention in recent years. So far, network modeling in manufacturing and logistics has often focused on the description of system properties. In the data-driven world of smart manufacturing, creating material flow network models becomes a lot easier due to the ubiquitous availability of shop floor and transportation data. At the same time, these highly flexible and continuously changing smart manufacturing systems become less predictive and thus less controllable. This article investigates how the stochastic block model (SBM), a network model with a stochastic description of interconnections, can be applied to model and predict material flows in manufacturing systems. We show how to utilize its properties to forecast the dynamic development of the structure of such systems. The complete process from network modeling using material flow data to the prediction of the future development of the network is demonstrated. Different SBM variants are tested using six company data sets and evaluated in competition with classical machine learning methods for prediction. Our results show that selected SBM variants achieve the best performance in prediction in most scenarios and thus have the potential to play an important role in the management of future dynamic manufacturing systems.","Manufacturing systems,Logistics,Complex networks,Stochastic block model,Prediction",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Operations Research & Management Science",,7.333,"CLUSTER,STRUCTURES,DYNAMIC-BEHAVIOR,RECONSTRUCTION,BLOCKMODELS,PERFORMANCE,ROBUSTNESS,GENERATION,ALGORITHM,PRODUCT,SYSTEMS",JOURNAL OF MANUFACTURING SYSTEMS,,
65,Convolutional neural networks for classification of music-listening EEG: comparing 1D convolutional kernels with 2D kernels and cerebral laterality of musical influence,32,13,8867-8891,"Cheah Kit Hwa,Nisar Humaira,Yap Vooi Voon,Lee Chen-Yi","Cheah KH,Nisar H,Yap VV,Lee CY",Nisar H,10.1007/s00521-019-04367-7,University of Tunku Abdul Rahman,"This paper highlights the ability of convolutional neural networks (CNNs) at classifying EEG data listening to different kinds of music without the requirement for handcrafted features. Deep learning architectures presented in this paper include CNN of different depths and different convolutional kernels. Support vector machine (SVM) taking in EEG features describing the frequency spectrum, signal regularity, and cross-channel correlation has been applied for performance comparison with CNN. The best performing CNN model presented in this paper achieves the tenfold cross-validation (CV) binary classification average accuracy of 98.94% (validation) and 97.46% (test), and the tenfold CV three-class classification accuracy of 97.68% (validation) and 95.71% (test). In comparison, the SVM classifier achieves tenfold CV binary classification accuracy of 80.23% (validation). The CNN model presented is able to not only differentiate EEG of subjects listening to music from that of subjects without auditory input, but it is also capable of accurately differentiating the EEG of subjects listening to different music. In the context of designing neural computing models for EEG analysis, this paper shows that decomposing two-dimensional spatiotemporal convolutional kernels into separate one-dimensional spatial and one-dimensional temporal kernels significantly reduces the number of trainable parameters (size) of the model while retaining the classification performance. This finding is useful, especially in designing CNN for memory-critical embedded systems for EEG processing. In neurological aspect, auditory stimulus is found to have altered the EEG pattern of the frontal lobe and the left cerebral hemisphere more than the other brain regions.","Electroencephalogram (EEG),Deep learning,Convolutional neural network (CNN),Kernel,Music,Brain lateralization",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"HUMAN,BRAIN",NEURAL COMPUTING & APPLICATIONS,,
66,Machine Learning Using Digitized Herbarium Specimens to Advance Phonological Research,70,7,610-620,"Pearson Katelin D.,Nelson Gil,Aronson Myla F. J.,Bonnet Pierre,Brenskelle Laura,Davis Charles C.,Denny Ellen G.,Ellwood Elizabeth R.,Goeau Herve,Heberling J. Mason","Pearson KD,Nelson G,Aronson MFJ,Bonnet P,Brenskelle L,Davis CC,Denny EG,Ellwood ER,Goeau H,Heberling JM",Pearson KD,10.1093/biosci/biaa044,California State University System,"Machine learning (ML) has great potential to drive scientific discovery by harvesting data from images of herbarium specimens preserved plant material curated in natural history collections-but ML techniques have only recently been applied to this rich resource. ML has particularly strong prospects for the study of plant phenological events such as growth and reproduction. As a major indicator of climate change, driver of ecological processes, and critical determinant of plant fitness, plant phenology is an important frontier for the application of ML techniques for science and society. In the present article, we describe a generalized, modular ML workflow for extracting phenological data from images of herbarium specimens, and we discuss the advantages, limitations, and potential future improvements of this workflow. Strategic research and investment in specimen-based ML methods, along with the aggregation of herbarium specimen data, may give rise to a better understanding of life on Earth.","phenology,machine learning,biodiversity,climate change,deep learning",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND",Life Sciences & Biomedicine - Other Topics,,9.843,"CLIMATE-CHANGE,PHENOLOGICAL,RESPONSES,REPRODUCTIVE,PHENOLOGY,PLANT,PHENOLOGY,IMPACTS,FUTURE,TIMES",BIOSCIENCE,https://europepmc.org/articles/pmc7340542?pdf=render,
67,Automated thyroid nodule detection from ultrasound imaging using deep convolutional neural networks,122,,,"Abdolali Fatemeh,Kapur Jeevesh,Jaremko Jacob L.,Noga Michelle,Hareendranathan Abhilash R.,Punithakumar Kumaradevan","Abdolali F,Kapur J,Jaremko JL,Noga M,Hareendranathan AR,Punithakumar K",Abdolali F,10.1016/j.compbiomed.2020.103871,University of Alberta,"Thyroid cancer is the most common endocrine cancer and its incidence has continuously increased worldwide. In this paper, we focus on the challenging problem of nodule detection from ultrasound scans. In current clinical practice, this task is performed manually, which is tedious, subjective and highly depends on the clinical experience of radiologists. We propose a novel deep neural network architecture with carefully designed loss function regularization, and network hyperparameters to perform nodule detection without complex post-processing refinement steps. The local training and validation datasets consist of 2461 and 820 ultrasound frames acquired from 60 and 20 patients with a high degree of variability, respectively. The core of the proposed method is a deep learning framework based on multi-task model Mask R-CNN. We have developed a loss function with regularization that prioritizes detection over segmentation. Validation was conducted for 821 ultrasound frames from 20 patients. The proposed model can detect various types of thyroid nodules. The experimental results indicate that our proposed method is effective in thyroid nodule detection. Comparisons with the results by Faster R-CNN and conventional Mask R-CNN demonstrate that the proposed model outperforms the prior state-of-the-art detection methods.","Computer aided diagnosis,Convolutional neural network,Deep learning,Mask R-CNN,Thyroid nodules,Ultrasound",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"CLASSIFICATION,DIAGNOSIS,IMAGES,MANAGEMENT,FEATURES",COMPUTERS IN BIOLOGY AND MEDICINE,,
68,Formulation of mix design for 3D printing of geopolymers: a machine learning approach,1,4,720-727,"Bagheri Ali,Cremona Christian","Bagheri A,Cremona C",Bagheri A,10.1039/d0ma00036a,Swinburne University of Technology,"This work evaluates the application of machine learning in the formulation of construction materials. The aim is to introduce a feasible approach to classify geopolymer samples made via additive manufacturing technique. Using an experimentally acquired conversion factor 2.95, this study employs popular recursive-partitioning functions including rpart and ctree to build separate classification models being compared at the end. According to the findings, these functions demonstrate great ability to create classification models for 3D-printed geopolymers with up to 100% positive predictive value in ctree function and up to 81% positive predictive value in the rpart function. However, rpart function with 70% cumulative accuracy expressed slightly better performance compared to 63% for that of ctree function. Locating the content of slag and the ratio of boron ions respectively in the roots of ctree and rpart decision trees implies the significance of them in the compressive strength of samples.","TEMPERATURE T-G,FLY-ASH,MECHANICAL-PROPERTIES,COMPRESSIVE STRENGTH,ALKALINE-SOLUTION,CONCRETE,TRANSITION,BORON,WATER",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND",Materials Science,,,"TEMPERATURE,T-G,FLY-ASH,MECHANICAL-PROPERTIES,COMPRESSIVE,STRENGTH,ALKALINE-SOLUTION,CONCRETE,TRANSITION,BORON,WATER",MATERIALS ADVANCES,https://pubs.rsc.org/en/content/articlepdf/2020/ma/d0ma00036a,
69,Multitask deep-learning-based design of chiral plasmonic metamaterials,8,7,1213-1225,"Ashalley Eric,Acheampong Kingsley,Besteiro Lucas V,Yu Peng,Neogi Arup,Govorov Alexander O.,Wang Zhiming","Ashalley E,Acheampong K,Besteiro LV,Yu P,Neogi A,Govorov AO,Wang ZM",Wang ZM,10.1364/PRJ.388253,University of Electronic Science & Technology of China,"The field of chiral plasmonics has registered considerable progress with machine-learning (ML)-mediated metamaterial prototyping, drawing from the success of ML frameworks in other applications such as pattern and image recognition. Here, we present an end-to-end functional bidirectional deep-learning (DL) model for three-dimensional chiral metamaterial design and optimization. This ML model utilizes multitask joint learning features to recognize, generalize, and explore in detail the nontrivial relationship between the metamaterials' geometry and their chiroptical response, eliminating the need for auxiliary networks or equivalent approaches to stabilize the physically relevant output. Our model efficiently realizes both forward and inverse retrieval tasks with great precision, offering a promising tool for iterative computational design tasks in complex physical systems. Finally, we explore the behavior of a sample ML-optimized structure in a practical application, assisting the sensing of biomolecular enantiomers. Other potential applications of our metastructure include photodetectors, polarization-resolved imaging, and circular dichroism (CD) spectroscopy, with our ML framework being applicable to a wider range of physical problems. (c) 2020 Chinese Laser Press","CIRCULAR-DICHROISM,PERFECT ABSORBER,BIOMOLECULES,GO,PREDICTION",Article,"OPTICAL SOC AMER, 2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA",Optics,,6.603,"CIRCULAR-DICHROISM,PERFECT,ABSORBER,BIOMOLECULES,GO,PREDICTION",PHOTONICS RESEARCH,,
70,A New Deep Learning Model Selection Method for Colorectal Cancer Classification,11,3,72-88,"Dif Nassima,Elberrichi Zakaria","Dif N,Elberrichi Z",Dif N,10.4018/IJSIR.2020070105,University Djillali Liabes Sidi Bel Abbes,"Deep learning is one of the most commonly used techniques in computer-aided diagnosis systems. Their exploitation for histopathological image analysis is important because of the complex morphology of whole slide images. However, the main limitation of these methods is the restricted number of available medical images, which can lead to an overfitting problem. Many studies have suggested the use of static ensemble learning methods to address this issue. This article aims to propose a new dynamic ensemble deep learning method. First, it generates a set of models based on the transfer learning strategy from deep neural networks. Then, the relevant subset of models is selected by the particle swarm optimization algorithm and combined by voting or averaging methods. The proposed approach was tested on a histopathological dataset for colorectal cancer classification, based on seven types of CNNs. The method has achieved accurate results (94.52%) by the Resnet121 model and the voting strategy, which provides important insights into the efficiency of dynamic ensembling in deep learning.","Colorectal Cancer,Deep Learning,Ensemble Learning,Particle Swarm Optimization,Transfer Learning",Article,"IGI GLOBAL, 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA",Computer Science,,,"COMPUTER-AIDED,DETECTION",INTERNATIONAL JOURNAL OF SWARM INTELLIGENCE RESEARCH,,
71,High-quality photoacoustic image reconstruction based on deep convolutional neural network: towards intra-operative photoacoustic imaging,6,4,,"Farnia Parastoo,Mohammadi Mohammad,Najafzadeh Ebrahim,Alimohamadi Maysam,Makkiabadi Bahador,Ahmadian Alireza","Farnia P,Mohammadi M,Najafzadeh E,Alimohamadi M,Makkiabadi B,Ahmadian A",Makkiabadi B; Ahmadian A,10.1088/2057-1976/ab9a10,Tehran University of Medical Sciences,"The use of intra-operative imaging system as an intervention solution to provide more accurate localization of complicated structures has become a necessity during the neurosurgery. However, due to the limitations of conventional imaging systems, high-quality real-time intra-operative imaging remains as a challenging problem. Meanwhile, photoacoustic imaging has appeared so promising to provide images of crucial structures such as blood vessels and microvasculature of tumors. To achieve high-quality photoacoustic images of vessels regarding the artifacts caused by the incomplete data, we proposed an approach based on the combination of time-reversal (TR) and deep learning methods. The proposed method applies a TR method in the first layer of the network which is followed by the convolutional neural network with weights adjusted to a set of simulated training data for the other layers to estimate artifact-free photoacoustic images. It was evaluated using a generated synthetic database of vessels. The mean of signal to noise ratio (SNR), peak SNR, structural similarity index, and edge preservation index for the test data were reached 14.6 dB, 35.3 dB, 0.97 and 0.90, respectively. As our results proved, by using the lower number of detectors and consequently the lower data acquisition time, our approach outperforms the TR algorithm in all criteria in a computational time compatible with clinical use.","neurosurgery,intra-operative imaging,photoacoustic imaging,image reconstruction,deep learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Radiology, Nuclear Medicine & Medical Imaging",,,"BRAIN,SHIFT,COMPUTED-TOMOGRAPHY,ULTRASOUND,NEURONAVIGATION,COMPENSATION,SEGMENTATION,DEFORMATION,TUMORS",BIOMEDICAL PHYSICS & ENGINEERING EXPRESS,,
72,Predicting rate of cognitive decline at baseline using a deep neural network with multidata analysis,7,4,,"Candemir Sema,Nguyen Xuan V,Prevedello Luciano M.,Bigelow Matthew T.,White Richard D.,Erdal Barbaros S.","Candemir S,Nguyen XV,Prevedello LM,Bigelow MT,White RD,Erdal BS",Candemir S; Nguyen XV,10.1117/1.JMI.7.4.044501,Ohio State University,"Purpose: Our study investigates whether a machine-learning-based system can predict the rate of cognitive decline in mildly cognitively impaired patients by processing only the clinical and imaging data collected at the initial visit.
Approach: We built a predictive model based on a supervised hybrid neural network utilizing a three-dimensional convolutional neural network to perform volume analysis of magnetic resonance imaging (MRI) and integration of nonimaging clinical data at the fully connected layer of the architecture. The experiments are conducted on the Alzheimer's Disease Neuroimaging Initiative dataset.
Results: Experimental results confirm that there is a correlation between cognitive decline and the data obtained at the first visit. The system achieved an area under the receiver operator curve of 0.70 for cognitive decline class prediction.
Conclusion: To our knowledge, this is the first study that predicts ""slowly deteriorating/stable"" or ""rapidly deteriorating"" classes by processing routinely collected baseline clinical and demographic data [baseline MRI, baseline mini-mental state examination (MMSE), scalar volumetric data, age, gender, education, ethnicity, and race]. The training data are built based on MMSE-rate values. Unlike the studies in the literature that focus on predicting mild cognitive impairment (MCI)-to-Alzheimer's disease conversion and disease classification, we approach the problem as an early prediction of cognitive decline rate in MCI patients. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","computer-aided detection/diagnosis,Alzheimer's disease in the early stages,cognitive decline,mild cognitive impairment,baseline visit",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"ALZHEIMERS-DISEASE,MRI,IMPAIRMENT,MCI",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7419712,
73,Explainable end-to-end deep learning for diabetic retinopathy detection across multiple datasets,7,4,,"Chetoui Mohamed,Akhloufi Moulay A.","Chetoui M,Akhloufi MA",Akhloufi MA,10.1117/1.JMI.7.4.044503,University of Moncton,"Purpose: Diabetic retinopathy (DR) is characterized by retinal lesions affecting people having diabetes for several years. It is one of the leading causes of visual impairment worldwide. To diagnose this disease, ophthalmologists need to manually analyze retinal fundus images. Computer-aided diagnosis systems can help alleviate this burden by automatically detecting DR on retinal images, thus saving physicians' precious time and reducing costs. The objective of this study is to develop a deep learning algorithm capable of detecting DR on retinal fundus images. Nine public datasets and more than 90,000 images are used to assess the efficiency of the proposed technique. In addition, an explainability algorithm is developed to visually show the DR signs detected by the deep model.
Approach: The proposed deep learning algorithm fine-tunes a pretrained deep convolutional neural network for DR detection. The model is trained on a subset of EyePACS dataset using a cosine annealing strategy for decaying the learning rate with warm up, thus improving the training accuracy. Tests are conducted on the nine datasets. An explainability algorithm based on gradient-weighted class activation mapping is developed to visually show the signs selected by the model to classify the retina images as DR.
Result: The proposed network leads to higher classification rates with an area under curve (AUC) of 0.986, sensitivity = 0.958, and specificity = 0.971 for EyePACS. For MESSIDOR, MESSIDOR-2, DIARETDB0, DIARETDB1, STARE, IDRID, E-ophtha, and UoA-DR, the AUC is 0.963, 0.979, 0.986, 0.988, 0.964, 0.957, 0.984, and 0.990, respectively.
Conclusions: The obtained results achieve state-of-the-art performance and outperform past published works relying on training using only publicly available datasets. The proposed approach can robustly classify fundus images and detect DR. An explainability model was developed and showed that our model was able to efficiently identify different signs of DR and detect this health issue. (C) 2020 Society of Photo Optical Instrumentation Engineers (SPIE)","diabetic retinopathy,convolutional neural networks,residual networks,inception,microaneurysms,exudates and hemorrhage",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,NETWORKS,JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7456641,
74,Deep-learning-based model observer for a lung nodule detection task in computed tomography,7,4,,"Gong Hao,Hu Qiyuan,Walther Andrew,Koo Chi Wan,Takahashi Edwin A.,Levin David L.,Johnson Tucker F.,Hora Megan J.,Leng Shuai,Fletcher Joel G.","Gong H,Hu QY,Walther A,Koo CW,Takahashi EA,Levin DL,Johnson TF,Hora MJ,Leng S,Fletcher JG",Yu LF,10.1117/1.JMI.7.4.042807,Mayo Clinic,"Purpose: Task-based image quality assessment using model observers (MOs) is an effective approach to radiation dose and scanning protocol optimization in computed tomography (CT) imaging, once the correlation between MOs and radiologists can be established in well-defined clinically relevant tasks. Conventional MO studies were typically simplified to detection, classification, or localization tasks using tissue-mimicking phantoms, as traditional MOs cannot be readily used in complex anatomical background. However, anatomical variability can affect human diagnostic performance.
Approach: To address this challenge, we developed a deep-learning-based MO (DL-MO) for localization tasks and validated in a lung nodule detection task, using previously validated projection-based lesion-/noise-insertion techniques. The DL-MO performance was compared with 4 radiologist readers over 12 experimental conditions, involving varying radiation dose levels, nodule sizes, nodule types, and reconstruction types. Each condition consisted of 100 trials (i.e., 30 images per trial) generated from a patient cohort of 50 cases. DL-MO was trained using small image volume-of-interests extracted across the entire volume of training cases. For each testing trial, the nodule searching of DL-MO was confined to a 3-mm thick volume to improve computational efficiency, and radiologist readers were tasked to review the entire volume.
Results: A strong correlation between DL-MO and human readers was observed (Pearson's correlation coefficient: 0.980 with a 95% confidence interval of [0.924, 0.994]). The averaged performance bias between DL-MO and human readers was 0.57%.
Conclusion: The experimental results indicated the potential of using the proposed DL-MO for diagnostic image quality assessment in realistic chest CT tasks. (C) 2020 Society of Photo Optical Instrumentation Engineers (SPIE)","model observer,deep learning,lung nodule detection,x-ray computed tomography,task based image quality assessment",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"ITERATIVE,RECONSTRUCTION,IMAGE,QUALITY,CT,PERFORMANCE,RESOLUTION,NOISE",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7324744,
75,Automatic cancer detection on digital histopathology images of mid-gland radical prostatectomy specimens,7,4,,"Han Wenchao,Johnson Carol,Warner Andrew,Gaed Mena,Gomez Jose A.,Moussa Madeleine,Chin Joseph,Pautler Stephen,Bauman Glenn,Ward Aaron D.","Han WC,Johnson C,Warner A,Gaed M,Gomez JA,Moussa M,Chin J,Pautler S,Bauman G,Ward AD",Ward AD,10.1117/1.JMI.7.4.047501,Western University (University of Western Ontario),"Purpose: Automatic cancer detection on radical prostatectomy (RP) sections facilitates graphical and quantitative surgical pathology reporting, which can potentially benefit postsurgery follow-up care and treatment planning. It can also support imaging validation studies using a histologic reference standard and pathology research studies. This problem is challenging due to the large sizes of digital histopathology whole-mount whole-slide images (WSIs) of RP sections and staining variability across different WSIs.
Approach: We proposed a calibration-free adaptive thresholding algorithm, which compensates for staining variability and yields consistent tissue component maps (TCMs) of the nuclei, lumina, and other tissues. We used and compared three machine learning methods for classifying each cancer versus noncancer region of interest (ROI) throughout each WSI: (1) conventional machine learning methods and 14 texture features extracted from TCMs, (2) transfer learning with pretrained AlexNet fine-tuned by TCM ROIs, and (3) transfer learning with pretrained AlexNet fine-tuned with raw image ROIs.
Results: The three methods yielded areas under the receiver operating characteristic curve of 0.96, 0.98, and 0.98, respectively, in leave-one-patient-out cross validation using 1.3 million ROIs from 286 mid-gland whole-mount WSIs from 68 patients.
Conclusion: Transfer learning with the use of TCMs demonstrated state-of-the-art overall performance and is more stable with respect to sample size across different tissue types. For the tissue types involving Gleason 5 (most aggressive) cancer, it achieved the best performance compared to the other tested methods. This tool can be translated to clinical workflow to assist graphical and quantitative pathology reporting for surgical specimens upon further multicenter validation. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","prostate cancer detection,whole-slide histopathology imaging,machine learning,transfer learning,tissue component segmentation,radical prostatectomy pathology",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"ISUP,CONSENSUS,CONFERENCE,INTERNATIONAL-SOCIETY,PATHOLOGY,CLASSIFICATION,DIAGNOSIS,ALGORITHM,FEATURES",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7363935,
76,Sphere estimation network: three-dimensional nuclei detection of fluorescence microscopy images,7,4,,"Ho David Joon,Montserrat Daniel Mas,Fu Chichen,Salama Paul,Dunn Kenneth W.,Delp Edward J.","Ho DJ,Montserrat DM,Fu CC,Salama P,Dunn KW,Delp EJ",Ho DJ,10.1117/1.JMI.7.4.044003,Memorial Sloan Kettering Cancer Center,"Purpose: Fluorescence microscopy visualizes three-dimensional subcellular structures in tissue with two-photon microscopy achieving deeper penetration into tissue. Nuclei detection, which is essential for analyzing tissue for clinical and research purposes, remains a challenging problem due to the spatial variability of nuclei. Recent advancements in deep learning techniques have enabled the analysis of fluorescence microscopy data to localize and segment nuclei. However, these localization or segmentation techniques would require additional steps to extract characteristics of nuclei. We develop a 3D convolutional neural network, called Sphere Estimation Network (SphEsNet), to extract characteristics of nuclei without any postprocessing steps.
Approach: To simultaneously estimate the center locations of nuclei and their sizes, SphEsNet is composed of two branches to localize nuclei center coordinates and to estimate their radii. Synthetic microscopy volumes automatically generated using a spatially constrained cycle-consistent adversarial network are used for training the network because manually generating 3D real ground truth volumes would be extremely tedious.
Results: Three SphEsNet models based on the size of nuclei were trained and tested on five real fluorescence microscopy data sets from rat kidney and mouse intestine. Our method can successfully detect nuclei in multiple locations with various sizes. In addition, our method was compared with other techniques and outperformed them based on object-level precision, recall, and F1 score. Our model achieved 89.90% for F1 score.
Conclusions: SphEsNet can simultaneously localize nuclei and estimate their size without additional steps. SphEsNet can be potentially used to extract more information from nuclei in fluorescence microscopy images. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","nuclei detection,fluorescence microscopy,convolutional neural network,synthetic volumes",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"SEGMENTATION,TRACKING,ALGORITHM,SNAKES,SIZE",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7451995,
77,Radiomics methodology for breast cancer diagnosis using multiparametric magnetic resonance imaging,7,4,,"Hu Qiyuan,Whitney Heather M.,Giger Maryellen L.","Hu QY,Whitney HM,Giger ML",Hu QY,10.1117/1.JMI.7.4.044502,University of Chicago,"Purpose: This study aims to develop and compare human-engineered radiomics methodologies that use multiparametric magnetic resonance imaging (mpMRI) to diagnose breast cancer.
Approach: The dataset comprises clinical multiparametric MR images of 852 unique lesions from 612 patients. Each MR study included a dynamic contrast-enhanced (DCE)-MRI sequence and a T2-weighted (T2w) MRI sequence, and a subset of 389 lesions were also imaged with a diffusion-weighted imaging (DWI) sequence. Lesions were automatically segmented using the fuzzy C-means algorithm. Radiomic features were extracted from each MRI sequence. Two approaches, feature fusion and classifier fusion, to utilizing multiparametric information were investigated. A support vector machine classifier was trained for each method to differentiate between benign and malignant lesions. Area under the receiver operating characteristic curve (AUC) was used to evaluate and compare diagnostic performance. Analyses were first performed on the entire dataset and then on the subset that was imaged using the three-sequence protocol.
Results: When using the full dataset, the single-parametric classifiers yielded the following AUCs and 95% confidence intervals: AUC(DCE) = 0.84 [0.82, 0.87], AUC(T2W) = 0.83 [0.80, 0.86], and AUC(DWI) = 0.69 [0.62, 0.75]. The two multiparametric classifiers both yielded AUCs of 0.87 [0.84, 0.89] and significantly outperformed all single-parametric methods classifiers. When using the three-sequence subset, the mpMRI classifiers' performances significantly decreased.
Conclusions: The proposed mpMRI radiomics methods can improve the performance of computer-aided diagnostics for breast cancer and handle missing sequences in the imaging protocol. (C) 2020 Society of Photo Optical Instrumentation Engineers (SPIE)","breast cancer,computer-aided diagnosis,radiomics,machine learning,multiparametric magnetic resonance imaging",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"ROC,CURVES,LESIONS,MRI,CLASSIFICATION,SEQUENCES,AREAS,RISK",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7444714,
78,"Quantitative imaging feature pipeline: a web-based tool for utilizing, sharing, and building image-processing pipelines",7,4,,"Mattonen Sarah A.,Gude Dev,Echegaray Sebastian,Bakr Shaimaa,Rubin Daniel L.,Napel Sandy","Mattonen SA,Gude D,Echegaray S,Bakr S,Rubin DL,Napel S",Napel S,10.1117/1.JMI.7.4.042803,Stanford University,"Quantitative image features that can be computed from medical images are proving to be valuable biomarkers of underlying cancer biology that can be used for assessing treatment response and predicting clinical outcomes. However, validation and eventual clinical implementation of these tools is challenging due to the absence of shared software algorithms, architectures, and the tools required for computing, comparing, evaluating, and disseminating predictive models. Similarly, researchers need to have programming expertise in order to complete these tasks. The quantitative image feature pipeline (QIFP) is an open-source, web-based, graphical user interface (GUI) of configurable quantitative image-processing pipelines for both planar (two-dimensional) and volumetric (three-dimensional) medical images. This allows researchers and clinicians a GUI-driven approach to process and analyze images, without having to write any software code. The QIFP allows users to upload a repository of linked imaging, segmentation, and clinical data or access publicly available datasets (e.g., The Cancer Imaging Archive) through direct links Researchers have access to a library of file conversion, segmentation, quantitative image feature extraction, and machine learning algorithms. An interface is also provided to allow users to upload their own algorithms in Docker containers. The QIFP gives researchers the tools and infrastructure for the assessment and development of new imaging biomarkers and the ability to use them for single and multicenter clinical and virtual clinical trials. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","medical image analysis,radiomics,machine learning,feature extraction,processing pipeline",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"RADIOMICS,RADIOGENOMICS,INFORMATION,PREDICTION,CANCER,TUMOR,PET,CT",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7070161,
79,Learning from dispersed manual annotations with an optimized data weighting policy,7,4,,"Tang Yucheng,Gao Riqiang,Chen Yunqiang,Gao Dashan,Savona Michael R.,Abramson Richard G.,Bao Shunxing,Huo Yuankai,Landman Bennett A.","Tang YC,Gao RQ,Chen YQ,Gao DS,Savona MR,Abramson RG,Bao SX,Huo YK,Landman BA",Tang YC,10.1117/1.JMI.7.4.044002,Vanderbilt University,"Purpose: Deep learning methods have become essential tools for quantitative interpretation of medical imaging data, but training these approaches is highly sensitive to biases and class imbalance in the available data. There is an opportunity to increase the available training data by combining across different data sources (e.g., distinct public projects); however, data collected under different scopes tend to have differences in class balance, label availability, and subject demographics. Recent work has shown that importance sampling can be used to guide training selection. To date, these approaches have not considered imbalanced data sources with distinct labeling protocols.
Approach: We propose a sampling policy, known as adaptive stochastic policy (ASP), inspired by reinforcement learning to adapt training based on subject, data source, and dynamic use criteria. We apply ASP in the context of multiorgan abdominal computed tomography segmentation. Training was performed with cross validation on 840 subjects from 10 data sources. External validation was performed with 20 subjects from 1 data source.
Results: Four alternative strategies were evaluated with the state-of-the-art baseline as upper confident bound (UCB). ASP achieves average Dice of 0.8261 compared to 0.8135 UCB (p < 0.01, paired t-test) across fivefold cross validation. On withheld testing datasets, the proposed ASP achieved 0.8265 mean Dice versus 0.8077 UCB (p < 0.01, paired t-test).
Conclusions: ASP provides a flexible reweighting technique for training deep learning models. We conclude that the proposed method adapts the sample importance, which leverages the performance on a challenging multisite, multiorgan, and multisize segmentation task. (C) 2020 Society of Photo Optical Instrumentation Engineers (SPIE)","abdominal organ segmentation,data weighting,computed tomography,reinforcement learning",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"SEGMENTATION,CT,ATLAS",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7394463,
80,Machine learning for the prediction of pseudorealistic pediatric abdominal phantoms for radiation dose reconstruction,7,4,,"Virgolin Marco,Wang Ziyuan,Alderliesten Tanja,Bosman Peter A. N.","Virgolin M,Wang ZY,Alderliesten T,Bosman PAN",Virgolin M,10.1117/1.JMI.7.4.046501,"Life Sci & Hlth Grp, Ctr Wiskunde & Informat, Amsterdam, Netherlands.","Purpose: Current phantoms used for the dose reconstruction of long-term childhood cancer survivors lack individualization. We design a method to predict highly individualized abdominal three-dimensional (3-D) phantoms automatically.
Approach: We train machine learning (ML) models to map (2-D) patient features to 3-D organat-risk (OAR) metrics upon a database of 60 pediatric abdominal computed tomographies with liver and spleen segmentations. Next, we use the models in an automatic pipeline that outputs a personalized phantom given the patient's features, by assembling 3-D imaging from the database. A step to improve phantom realism (i.e., avoid OAR overlap) is included. We compare five ML algorithms, in terms of predicting OAR left-right (LR), anterior-posterior (AP), inferior-superior (IS) positions, and surface Dice-Sorensen coefficient (sDSC). Furthermore, two existing human-designed phantom construction criteria and two additional control methods are investigated for comparison.
Results: Different ML algorithms result in similar test mean absolute errors: similar to 8 mm for liver LR, IS, and spleen AP, IS; similar to 5 mm for liver AP and spleen LR; similar to 80% for abdomen sDSC; and similar to 60% to 65% for liver and spleen sDSC. One ML algorithm (GP-GOMEA) significantly performs the best for 6/9 metrics. The control methods and the human-designed criteria in particular perform generally worse, sometimes substantially (+5-mm error for spleen IS, -10% sDSC for liver). The automatic step to improve realism generally results in limited metric accuracy loss, but fails in one case (out of 60).
Conclusion: Our ML-based pipeline leads to phantoms that are significantly and substantially more individualized than currently used human-designed criteria. (C) 2020 Society of Photo Optical Instrumentation Engineers (SPIE)","machine learning,pediatric cancer,radiation treatment,dose reconstruction,phantom",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"MATCHING,CRITERIA,CHILDHOOD-CANCER,RADIOTHERAPY,SEGMENTATION,POPULATION,CHILDREN,THERAPY,MODELS,VARIABILITY,REGRESSION",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7390892,
81,Multiple skin lesions diagnostics via integrated deep convolutional networks for segmentation and classification,190,,,"Al-masni Mohammed A.,Kim Dong-Hyun,Kim Tae-Seong","Al-masni MA,Kim DH,Kim TS",Kim TS,10.1016/j.cmpb.2020.105351,Kyung Hee University,"Background and objective: Computer automated diagnosis of various skin lesions through medical dermoscopy images remains a challenging task.
Methods: In this work, we propose an integrated diagnostic framework that combines a skin lesion boundary segmentation stage and a multiple skin lesions classification stage. Firstly, we segment the skin lesion boundaries from the entire dermoscopy images using deep learning full resolution convolutional network (FrCN). Then, a convolutional neural network classifier (i.e., Inception-v3, ResNet-50, Inception-ResNet-v2, and DenseNet-201) is applied on the segmented skin lesions for classification. The former stage is a critical prerequisite step for skin lesion diagnosis since it extracts prominent features of various types of skin lesions. A promising classifier is selected by testing well-established classification convolutional neural networks. The proposed integrated deep learning model has been evaluated using three independent datasets (i.e., International Skin Imaging Collaboration (ISIC) 2016, 2017, and 2018, which contain two, three, and seven types of skin lesions, respectively) with proper balancing, segmentation, and augmentation.
Results: In the integrated diagnostic system, segmented lesions improve the classification performance of Inception-ResNet-v2 by 2.72% and 4.71% in terms of the F1-score for benign and malignant cases of the ISIC 2016 test dataset, respectively. The classifiers of Inception-v3, ResNet-50, Inception-ResNet-v2, and DenseNet-201 exhibit their capability with overall weighted prediction accuracies of 77.04%, 79.95%, 81.79%, and 81.27% for two classes of ISIC 2016, 81.29%, 81.57%, 81.34%, and 73.44% for three classes of ISIC 2017, and 88.05%, 89.28%, 87.74%, and 88.70% for seven classes of ISIC 2018, respectively, demonstrating the superior performance of ResNet-50.
Conclusions: The proposed integrated diagnostic networks could be used to support and aid dermatologists for further improvement in skin cancer diagnosis. (c) 2020 Elsevier B.V. All rights reserved.","CAD,Classification,CNN,Deep learning,ISIC,Melanoma,Skin lesion,Segmentation",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"DIGITAL,MAMMOGRAMS,NEURAL-NETWORKS,BREAST-CANCER,FEATURES,MASSES,SYSTEM",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
82,Development and use of a clinical decision support system for the diagnosis of social anxiety disorder,190,,,"Fathi Sina,Ahmadi Maryam,Birashk Behrouz,Dehnad Afsaneh","Fathi S,Ahmadi M,Birashk B,Dehnad A",Ahmadi M,10.1016/j.cmpb.2020.105354,Iran University of Medical Sciences,,,Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,,COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
83,Computer -aided diagnosis of breast ultrasound images using ensemble learning from convolutional neural networks,190,,,"Moon Woo Kyung,Lee Yan-Wei,Ke Hao-Hsiang,Lee Su Hyun,Huang Chiun-Sheng,Chang Ruey-Feng","Moon WK,Lee YW,Ke HH,Lee SH,Huang CS,Chang RF",Chang RF,10.1016/j.cmpb.2020.105361,National Taiwan University,,"CLASSIFICATION,FEATURES,LESIONS,BENIGN,MASSES,TUMORS",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"CLASSIFICATION,FEATURES,LESIONS,BENIGN,MASSES,TUMORS",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
84,Ensembled deep convolution neural network-based breast cancer classification with misclassification reduction algorithms,79,25-26,18447-18479,"Murtaza Ghulam,Shuib Liyana,Wahab Ainuddin Wahid Abdul,Mujtaba Ghulam,Raza Ghulam","Murtaza G,Shuib L,Wahab AWA,Mujtaba G,Raza G",Murtaza G; Shuib L,10.1007/s11042-020-08692-1,Universiti Malaya,"Breast cancer (BrC) is the leading cause of abnormal death in women. Mammograms and histopathology (Hp) biopsy images are generally recommended for early diagnosis of BrC because Hp image-based diagnosis enables doctors to make cancer diagnostic decisions more confidently than with mammograms. Several studies have used Hp images to classify BrC. However, the performance of classification models is compromised due to the higher misclassification rate. Therefore, this study aimed to develop a reliable, accurate, and computationally cost-effective ensembled BrC classification network (EBrC-Net) model with three misclassification algorithms to diagnose breast malignancy in early stages using Hp images. The proposed EBrC-Net model is based on the deep convolutional neural network approach. For experiments, the publicly available BreakHis dataset was used and split into training, validation, and testing sets. In addition, image augmentation was adopted for the training set only, and features were extracted through the well-trained EBrC-Net. Thereafter, the extracted features were further evaluated by six machine learning classifiers, of which two best performing classifiers (i.e., softmax and k-nearest neighbour [kNN]) were selected on the basis of five performance metric evaluation results. Furthermore, three misclassification reduction (McR) algorithms were developed and implemented in cascaded manner to reduce the false predictions of the softmax and kNN classifiers. After the implementation of the McR algorithms, experiments showed that the kNN results were much better and reliable than the softmax. The proposed BrC classification model achieved accuracy, specificity, and sensitivity rates of 97.74%, 100%, and 97.01%, respectively. Moreover, the performance of proposed BrC classification model was compared with that of state-of-the-art baseline models. Findings showed that the proposed EBrC-Net classification model, coupled with the proposed McR algorithms, achieved the best results in comparison with the baseline classification models. The proposed EBrC-Net model and the McR algorithms are a reliable source for doctors aiming for second opinion in making early diagnostic decisions for BrC using Hp images.","Breast cancer,Image classification,Convolutional neural network,Deep learning,Transfer learning,Histopathology biopsy image",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,FRAMEWORK,MULTIMEDIA TOOLS AND APPLICATIONS,,
85,Empirical analysis of deep learning networks for affective video tagging,79,25-26,18611-18626,"Mishra Anju,Ranjan Priya,Ujlayan Amit","Mishra A,Ranjan P,Ujlayan A",Mishra A,10.1007/s11042-020-08714-y,Amity University Noida,"This paper presents, a thorough evaluation of popular deep learning models to analyze and classify electroencephalogram (EEG) data for characterizing human affective states for video content tagging and retrieval. We use two pre-trained convolutional neural network (CNN) models AlexNet and GoogLeNet, and a Long Short Term Memory (LSTM) model to classify EEG data into appropriate affect categories using trans-domain learning. The purpose behind the use of pre-trained networks or trans-domain learning is twofold - to establish the versatility of pre-trained networks by testing their ability to classify EEG data for emotion recognition and the other is to reduce over cost of computation while training the networks. Our work tries to establish the answer of a simple question: Are pre-trained deep models versatile enough for classifying not only similar type of problems but are also effective for classifying problems pertaining to completely different domains? Also, using pre-trained models saves considerable computation time required for training a new model from scratch and fine tuning it. We use DEAP dataset for training and evaluation of these networks over a single modality 'valence' to simplify the comparison among these networks. Experiments are carried out by training the networks on EEG recordings obtained from single as well as multiple subjects to show the effects of subject-specific and generalized data on classification accuracy. Experimental results suggest the superiority of GoogLeNet for individual subject data while AlexNet outperforms other networks and has shown its capability of generalizing well. We compare the performance of these networks with state-of-art classifiers handcrafted by other authors for classifying EEG data and find that the performance of pre-trained CNNs used in our work are comparable or even better than the other handcrafted classifiers used by many authors.","Affective video tagging,Deep learning,CNN,Emotion classification,Video analysis",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"EMOTION,RECOGNITION",MULTIMEDIA TOOLS AND APPLICATIONS,,
86,Radiative Backpropagation: An Adjoint Method for Lightning-Fast Differentiable Rendering,39,4,,"Nimier-David Merlin,Speierer Sebastien,Ruiz Benoit,Jakob Wenzel","Nimier-David M,Speierer S,Ruiz B,Jakob W",Nimier-David M,10.1145/3386569.3392406,Ecole Polytechnique Federale de Lausanne,"Physically based differentiable rendering has recently evolved into a powerful tool for solving inverse problems involving light. Methods in this area perform a differentiable simulation of the physical process of light transport and scattering to estimate partial derivatives relating scene parameters to pixels in the rendered image. Together with gradient-based optimization, such algorithms have interesting applications in diverse disciplines, e.g., to improve the reconstruction of 3D scenes, while accounting for interreflection and transparency, or to design meta-materials with specified optical properties.
The most versatile differentiable rendering algorithms rely on reverse-mode differentiation to compute all requested derivatives at once, enabling optimization of scene descriptions with millions of free parameters. However, a severe limitation of the reverse-mode approach is that it requires a detailed transcript of the computation that is subsequently replayed to back-propagate derivatives to the scene parameters. The transcript of typical renderings is extremely large, exceeding the available system memory by many orders of magnitude, hence current methods are limited to simple scenes rendered at low resolutions and sample counts.
We introduce radiative backpropagation, a fundamentally different approach to differentiable rendering that does not require a transcript, greatly improving its scalability and efficiency. Our main insight is that reverse-mode propagation through a rendering algorithm can be interpreted as the solution of a continuous transport problem involving the partial derivative of radiance with respect to the optimization objective. This quantity is ""emitted"" by sensors, ""scattered"" by the scene, and eventually ""received"" by objects with differentiable parameters. Differentiable rendering then decomposes into two separate primal and adjoint simulation steps that scale to complex scenes rendered at high resolutions. We also investigated biased variants of this algorithm and find that they considerably improve both runtime and convergence speed. We showcase an efficient GPU implementation of radiative backpropagation and compare its performance arid the quality of its gradients to prior work.","Ray Tracing,Global Illumination,Differentiable Rendering",Article,"ASSOC COMPUTING MACHINERY, 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA",Computer Science,,6.445,,ACM TRANSACTIONS ON GRAPHICS,,
87,Computer -aided tumor detection in automated breast ultrasound using a 3-D convolutional neural network,190,,,"Moon Woo Kyung,Huang Yao-Sian,Hsu Chin-Hua,Chien Ting-Yin Chang,Chang Jung Min,Lee Su Hyun,Huang Chiun-Sheng,Chang Ruey-Feng","Moon WK,Huang YS,Hsu CH,Chien TYC,Chang JM,Lee SH,Huang CS,Chang RF",Chang RF,10.1016/j.cmpb.2020.105360,National Taiwan University,,LESIONS,Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,LESIONS,COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
88,Towards an anxiety and stress recognition system for academic environments based on physiological features,190,,,"Rodriguez-Arce Jorge,Lara-Flores Liliana,Portillo-Rodriguez Otniel,Martinez-Mendez Rigoberto","Rodriguez-Arce J,Lara-Flores L,Portillo-Rodriguez O,Martinez-Mendez R",Rodriguez-Arce J,10.1016/j.cmpb.2020.105408,"Univ Autonoma Estado Mexico, Fac Ingn, Toluca, Mexico.",,"COLLEGE,CLASSIFICATION",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"COLLEGE,CLASSIFICATION",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
89,Deep learning reservoir porosity prediction based on multilayer long short-term memory network,85,4,WA213-WA225,"Chen Wei,Yang Liuqing,Zha Bei,Zhang Mi,Chen Yangkang","Chen W,Yang LQ,Zha B,Zhang M,Chen YK",Chen W,10.1190/GEO2019-0261.1,Yangtze University,"The cost of obtaining a complete porosity value using traditional coring methods is relatively high, and as the drilling depth increases, the difficulty of obtaining the porosity value also increases. Nowadays, the prediction of fine reservoir parameters for oil and gas exploration is becoming more and more important. Therefore, high-efficiency and low-cost prediction of porosity based on logging data is necessary. We have developed a machine-learning method based on the traditional long short-term memory (LSTM) model, called multilayer LSTM (MLSTM), to perform the porosity prediction task. We used three different wells in a block in southern China for the prediction task, including a training well and two test wells. One test well has the same logging data type as the training well, whereas the other test well differs from the training well in the logging depth and parameter types. Two different types of test data sets are used to detect the generalization ability of the network. A set of data was used to train the MLSTM network, and the hyperparameters of the network were adjusted through experimental accuracy feedback. We also tested the performance of the network using two sets of log data from different regions, including generalization and sensitivity of the network. During the training phase of the porosity prediction model, the developed MLSTM establishes a minimized objective function, uses the Adam optimization algorithm to update the weight of the network, and adjusts the network hyperparameters to select the best target according to the feedback of the network accuracy. Compared with conventional sequence neural networks, such as the gated recurrent unit and recurrent neural network, the logging data experiments show that MLSTM has better robustness and accuracy in depth sequence prediction. Especially, the porosity value at the depth inflection point can be better predicted when the trend of the depth sequence was predicted. This framework is expected to reduce the porosity prediction errors when data are insufficient and log depths are different.","ARTIFICIAL NEURAL-NETWORKS,BIDIRECTIONAL LSTM,EVENT PICKING,SEISMIC DATA,CLASSIFICATION,IDENTIFICATION,RECOGNITION,PERMEABILITY",Article,"SOC EXPLORATION GEOPHYSICISTS, 8801 S YALE ST, TULSA, OK 74137 USA",Geochemistry & Geophysics,,3.281,"ARTIFICIAL,NEURAL-NETWORKS,BIDIRECTIONAL,LSTM,EVENT,PICKING,SEISMIC,DATA,CLASSIFICATION,IDENTIFICATION,RECOGNITION,PERMEABILITY",GEOPHYSICS,,
90,Deep-learning electromagnetic monitoring coupled to fluid flow simulators,85,4,WA1-WA12,"Colombo Daniele,Li Weichang,Sandoval-Curiel Ernesto,McNeice Gary W.","Colombo D,Li WC,Sandoval-Curiel E,McNeice GW",Colombo D,10.1190/GEO2019-0428.1,Saudi Aramco,"Reservoir characterization and monitoring represent some of the most ambitious goals for geophysical methods. Several challenges are involved, including sensitivity to the parameter changes and resolution of the obtained results. Electromagnetic (EM) methods are attractive for reservoir applications due to the high sensitivity of the resistivity parameter to oil/water saturations. Crosswell EM and surface-to-borehole EM provide opportunities for reservoir monitoring. The EM inverse problem, however, is highly nonconvex and ill-posed so as to necessitate significant preconditioning in the form of a priori information and regularization that impact resolution. We explore the use of machine-learning (ML) techniques in the form of deep-learning neural networks for implementing EM-based reservoir monitoring coupled with a dynamic fluid flow simulator. A crosswell acquisition setup is modeled in the framework of a realistic wateralternating-gas reservoir simulation scenario for enhanced oil recovery. Several reservoir saturation instances are generated and converted into resistivity, and corresponding crosswell EM data are generated using an electric source and a multicomponent (electric-magnetic) receiver assemblage. The U-Net deep-learning network is modified for the purpose of training and validation in which saturation models and the corresponding EM data are used. We also test the sensitivity of the deep-learning inversion to multiple EM components, noise in the data, generalization problems, and 3D reconstruction ability in which we use 3D convolutional neural network layers. In all cases, ML inversion proves to be robust with good resilience to increased noise levels. Prediction results indicate excellent reconstruction capabilities with resolution comparable to the reservoir models used by the simulator. Our results suggest that ML inversion through deep learning can become an efficient approach to data-driven and physics-constrained reservoir monitoring in which the sensitivity of EM-based techniques to fluid saturations can be fully exploited without compromising the resolution and accuracy of the results.","DELINEATION,NETWORKS",Article,"SOC EXPLORATION GEOPHYSICISTS, 8801 S YALE ST, TULSA, OK 74137 USA",Geochemistry & Geophysics,,3.281,"DELINEATION,NETWORKS",GEOPHYSICS,,
91,Deep learning for relative geologic time and seismic horizons,85,4,WA87-WA100,"Geng Zhicheng,Wu Xinming,Shi Yunzhi,Fomel Sergey","Geng ZC,Wu XM,Shi YZ,Fomel S",Wu XM,10.1190/GEO2019-0252.1,Chinese Academy of Sciences,"Constructing a relative geologic time (RGT) image from a seismic image is crucial for seismic structural and stratigraphic interpretation. In conventional methods, automatic RGT estimation from a seismic image is typically based on only local image features, which makes it challenging to cope with discontinuous structures (e.g., faults and unconformities). We have considered the estimation of 2D RGT images as a regression problem, where we design a deep convolutional neural network (CNN) to directly and automatically compute an RGT image from a 2D seismic image. This CNN consists of three parts: an encoder, a decoder, and a refinement module. We train this CNN by using 2080 pairs of synthetic input seismic images and target RGT images, and then we test it on 960 testing seismic images. Although trained with only synthetic images, the network can generate accurate results on real seismic images. Multiple field examples show that our CNN-based method is significantly superior to conventional methods, especially in dealing with complex structures such as crossing faults and complicatedly folded horizons, without the need of any manual picking.",,Article,"SOC EXPLORATION GEOPHYSICISTS, 8801 S YALE ST, TULSA, OK 74137 USA",Geochemistry & Geophysics,,3.281,,GEOPHYSICS,,
92,A gradient boosting decision tree algorithm combining synthetic minority oversampling technique for lithology identification,85,4,WA147-WA158,"Zhou Kaibo,Zhang Jianyu,Ren Yusong,Huang Zhen,Zhao Luanxiao","Zhou KB,Zhang JY,Ren YS,Huang Z,Zhao LX",Zhao LX,10.1190/GEO2019-0429.1,Tongji University,"Lithology identification based on conventional well-logging data is of great importance for geologic features characterization and reservoir quality evaluation in the exploration and production development of petroleum reservoirs. However, there are some limitations in the traditional lithology identification process: (1) It is very time consuming to build a model so that it cannot realize real-time lithology identification during well drilling, (2) it must be modeled by experienced geologists, which consumes a lot of manpower and material resources, and (3) the imbalance of labeled data in well-log data may reduce the classification performance of the model. We have developed a gradient boosting decision tree (GBDT) algorithm combining synthetic minority oversampling technique (SMOTE) to realize fast and automatic lithology identification. First, the raw welllog data are normalized by maximum and minimum normalization algorithm. Then, SMOTE is adopted to balance the number of samples in each class in training process. Next, a lithology identification model is built by GBDT to fit the preprocessed training data set. Finally, the built model is verified with the testing data set. The experimental results indicate that the proposed approach improves the lithology identification performance compared with other machine-learning approaches.","WELL LOGS,PETROGRAPHIC CLASSIFICATION,PATTERN-RECOGNITION,NEURAL-NETWORKS,MODELS,SMOTE",Article,"SOC EXPLORATION GEOPHYSICISTS, 8801 S YALE ST, TULSA, OK 74137 USA",Geochemistry & Geophysics,,3.281,"WELL,LOGS,PETROGRAPHIC,CLASSIFICATION,PATTERN-RECOGNITION,NEURAL-NETWORKS,MODELS,SMOTE",GEOPHYSICS,,
93,Towards the Prediction of Rearrest during Out-of-Hospital Cardiac Arrest,22,7,,"Elola Andoni,Aramendi Elisabete,Rueda Enrique,Irusta Unai,Wang Henry,Idris Ahamed","Elola A,Aramendi E,Rueda E,Irusta U,Wang H,Idris A",Elola A,10.3390/e22070758,University of Basque Country,"A secondary arrest is frequent in patients that recover spontaneous circulation after an out-of-hospital cardiac arrest (OHCA). Rearrest events are associated to worse patient outcomes, but little is known on the heart dynamics that lead to rearrest. The prediction of rearrest could help improve OHCA patient outcomes. The aim of this study was to develop a machine learning model to predict rearrest. A random forest classifier based on 21 heart rate variability (HRV) and electrocardiogram (ECG) features was designed. An analysis interval of 2minafter recovery of spontaneous circulation was used to compute the features. The model was trained and tested using a repeated cross-validation procedure, on a cohort of 162 OHCA patients (55 with rearrest). The median (interquartile range) sensitivity (rearrest) and specificity (no-rearrest) of the model were 67.3% (9.1%) and 67.3% (10.3%), respectively, with median areas under the receiver operating characteristics and the precision-recall curves of 0.69 and 0.53, respectively. This is the first machine learning model to predict rearrest, and would provide clinically valuable information to the clinician in an automated way.","out-of-hospital cardiac arrest (OHCA),rearrest,electrocardiogram (ECG),heart rate variability (HRV),random forest (RF)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,,"SPONTANEOUS,CIRCULATION,STATE,TRANSITIONS,LIFE-SUPPORT,RESUSCITATION,SURVIVAL,RETURN",ENTROPY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7517305,
94,A Deep Learning Approach for Featureless Robust Quality Assessment of Intermittent Atrial Fibrillation Recordings from Portable and Wearable Devices,22,7,,"Herraiz Alvaro Huerta,Martinez-Rodrigo Arturo,Bertomeu-Gonzalez Vicente,Quesada Aurelio,Rieta Jose J.,Alcaraz Raul","Herraiz AH,Martinez-Rodrigo A,Bertomeu-Gonzalez V,Quesada A,Rieta JJ,Alcaraz R",Alcaraz R,10.3390/e22070733,Universidad de Castilla-La Mancha,"Atrial fibrillation (AF) is the most common heart rhythm disturbance in clinical practice. It often starts with asymptomatic and very short episodes, which are extremely difficult to detect without long-term monitoring of the patient's electrocardiogram (ECG). Although recent portable and wearable devices may become very useful in this context, they often record ECG signals strongly corrupted with noise and artifacts. This impairs automatized ulterior analyses that could only be conducted reliably through a previous stage of automatic identification of high-quality ECG intervals. So far, a variety of techniques for ECG quality assessment have been proposed, but poor performances have been reported on recordings from patients with AF. This work introduces a novel deep learning-based algorithm to robustly identify high-quality ECG segments within the challenging environment of single-lead recordings alternating sinus rhythm, AF episodes and other rhythms. The method is based on the high learning capability of a convolutional neural network, which has been trained with 2-D images obtained when turning ECG signals into wavelet scalograms. For its validation, almost 100,000 ECG segments from three different databases have been analyzed during 500 learning-testing iterations, thus involving more than 320,000 ECGs analyzed in total. The obtained results have revealed a discriminant ability to detect high-quality and discard low-quality ECG excerpts of about 93%, only misclassifying around 5% of clean AF segments as noisy ones. In addition, the method has also been able to deal with raw ECG recordings, without requiring signal preprocessing or feature extraction as previous stages. Consequently, it is particularly suitable for portable and wearable devices embedding, facilitating early detection of AF as well as other automatized diagnostic facilities by reliably providing high-quality ECG excerpts to further processing stages.","atrial fibrillation,continuous wavelet transform,convolutional neural network,deep learning,quality assessment,single-lead ECG",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Physics,,2.587,"NOISE,DETECTION,ELECTROCARDIOGRAM,CLASSIFICATION,INDEXES,BURDEN,STROKE,CWT",ENTROPY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7517279,
95,Smart Diagnosis: A Multiple-Source Transfer TSK Fuzzy System for EEG Seizure Identification,16,2,,"Jiang Yizhang,Gu Xiaoqing,Ji Dingcheng,Qian Pengjiang,Xue Jing,Zhang Yuanpeng,Zhu Jiaqi,Xia Kaijian,Wang Shitong","Jiang YZ,Gu XQ,Ji DC,Qian PJ,Xue J,Zhang YP,Zhu JQ,Xia KJ,Wang ST",Xia KJ,10.1145/3340240,"Changshu 1 Peoples Hosp, Changshu 215500, Jiangsu, Peoples R China.","To effectively identify electroencephalogram (EEG) signals in multiple-source domains, a multiple-source transfer learning-based Takagi-Sugeno Kang (TSK) fuzzy system (FS), called MST-TSK, is proposed, which combines multiple-source transfer learning and manifold regularization (MR) learning mechanisms together into the TSK-FS framework. Specifically, the advantages of MST-TSK include the following: (1) by evaluating the significance of each source domain (SD), a flexible domain entropy-weighting index is presented; (2) using the theory of sample transfer learning, a reweighting strategy is presented to weigh the prediction of unknown samples in the target domain (I'D) and the output of the source prediction functions; (3) by taking into account the MR term, the manifold structure of the TD is effectively maintained in the proposed system; and (4) by inheriting the interpretability of TSK-FS, MST-TSK displays good interpretability in identifying EEG signals that are understandable by humans (domain experts). The effectiveness of the proposed FS is demonstrated in several EEG multiple-source transfer learning tasks.","Epileptic identification,EEG signals,multiple source transfer learning,fuzzy system,manifold regularization learning",Article,"ASSOC COMPUTING MACHINERY, 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA",,,2.817,"STATISTICAL,COMPARISONS,DOMAIN,ADAPTATION,REGULARIZATION,CLASSIFICATION,CLASSIFIERS",ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS,,
96,Cross-Domain Brain CT Image Smart Segmentation via Shared Hidden Space Transfer FCM Clustering,16,2,,"Xia Kaijian,Yin Hongsheng,Jin Yong,Qiu Shi,Zhao Hongru","Xia KJ,Yin HS,Jin Y,Qiu S,Zhao HR",Xia KJ,10.1145/3357233,"Changshu 1 Peoples Hosp, Shuyuan Rd, Changshu 215500, Jiangsu, Peoples R China.","Clustering is an important issue in brain medical image segmentation. Original medical images used for clinical diagnosis are often insufficient for clustering in the current domain. As there are sufficient medical images in the related domains, transfer clustering can improve the clustering performance of the current domain by transferring knowledge across the related domains. In this article, we propose a novel shared hidden space transfer fuzzy c-means (FCM) clustering called SHST-FCM for cross-domain brain computed tomography (CT) image segmentation. SHST-FCM projects both the data samples of the source domain and target domain into the shared hidden space, such that the distributions of the two domains are as close as possible. In the learned shared subspace, the data samples of the source domain serve as the auxiliary knowledge to aid the clustering process in the target domain. Extensive experiments on brain CT medical image datasets indicate the effectiveness of the proposed method.","Image segmentation,transfer clustering,FCM clustering,clinical diagnosis",Article,"ASSOC COMPUTING MACHINERY, 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA",,,2.817,"ALGORITHM,CUTS",ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS,,
97,Evaluation of machine learning methods to stroke outcome prediction using a nationwide disease registry,190,,,"Lin Ching-Heng,Hsu Kai-Cheng,Johnson Kory R.,Fann Yang C.,Tsai Chon-Haw,Sun Yu,Lien Li-Ming,Chang Wei-Lun,Chen Po-Lin,Lin Cheng-Li","Lin CH,Hsu KC,Johnson KR,Fann YC,Tsai CH,Sun Y,Lien LM,Chang WL,Chen PL,Lin CL",Fann YC,10.1016/j.cmpb.2020.105381,National Institutes of Health (NIH) - USA,"Introduction: Being able to predict functional outcomes after a stroke is highly desirable for clinicians. This allows clinicians to set reasonable goals with patients and relatives, and to reach shared after-care decisions for recovery or rehabilitation. The aim of this study was to apply various machine learning (ML) methods for 90-day stroke outcome predictions, using a nationwide disease registry.
Methods: This study used the Taiwan Stroke Registry (TSR) which has prospectively collected data from stroke patients since 2006. Three known ML models (support vector machine, random forest, and artificial neural network), and a hybrid artificial neural network were implemented and evaluated by 10-time repeated hold-out with 10-fold cross-validation.
Results: ML techniques present over 0.94 AUC in both ischemic and hemorrhagic stroke using preadmission and inpatient data. By adding follow-up data, the prediction ability improved to 0.97 AUC. We screened 206 clinical variables to identify 17 important features from the ischemic stroke dataset and 22 features from the hemorrhagic stroke dataset without losing much performance. Error analysis revealed that most prediction errors come from more severe stroke patients.
Conclusion: The study showed that ML techniques trained from large, cross-reginal registry datasets were able to predict functional outcome after stroke with high accuracy. The follow-up data is important which can further improve the predictive models' performance. With similar performances among different ML techniques, the algorithm's characteristics and performance on severe stroke patients will be the primary focus when we further develop inference models and artificial intelligence tools for potential medical. Published by Elsevier B.V.","Stroke outcome,Machine learning,Ischemic stroke,Hemorrhagic stroke",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"MODIFIED,RANKIN,SCALE,ISCHEMIC-STROKE,BARTHEL,INDEX,FUNCTIONAL,OUTCOMES,PROGNOSTIC,INDEXES,RECOVERY,VALIDATION,CARE",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7245557,
98,GC -Net: Global context network for medical image segmentation,190,,,"Ni Jiajia,Wu Jianhuang,Tong Jing,Chen Zhengming,Zhao Junping","Ni JJ,Wu JH,Tong J,Chen ZM,Zhao JP",Wu JH,10.1016/j.cmpb.2019.105121,Chinese Academy of Sciences,,"BLOOD-VESSEL SEGMENTATION,RETINAL IMAGES,MODEL",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"BLOOD-VESSEL,SEGMENTATION,RETINAL,IMAGES,MODEL",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
99,Hybrid passive polarimetric imager and lidar combination for material classification,59,7,,"Brown Jarrod P.,Roberts Rodney G.,Card Darrell C.,Saludez Christian L.,Keyser Christian K.","Brown JP,Roberts RG,Card DC,Saludez CL,Keyser CK",Brown JP,10.1117/1.OE.59.7.073106,"Air Force Res Lab, Munit Directorate, Eglin AFB, FL 32542 USA.","We investigate the augmentation of active imaging with passive polarimetric imaging for material classification. Experiments are conducted to obtain a multimodal dataset of lidar reflectivity and polarimetric thermal self-emission measurements against a diverse set of material types. Using the assumption that active lidar imaging can provide high-resolution three-dimensional spatial information, a known surface orientation is utilized to enable higher fidelity classification. Machine learning is applied to the dataset of monostatic lidar unidirectional reflectivity and passive longwave infrared degree of linear polarization features for material classification. The hybrid sensor technique can classify materials with 91.1% accuracy even with measurement noise resulting in a signal-to-noise ratio of only 6 dB. The application of the proposed technique is applicable for the classification of hidden objects or could assist existing spatial-based object classification. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","passive infrared imaging,polarimetric,lidar,multisensor,machine learning",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA",Optics,,1.098,,OPTICAL ENGINEERING,https://www.spiedigitallibrary.org/journals/optical-engineering/volume-59/issue-7/073106/Hybrid-passive-polarimetric-imager-and-lidar-combination-for-material-classification/10.1117/1.OE.59.7.073106.pdf,
100,The sale of heritage on eBay: Market trends and cultural value,7,2,,"Altaweel Mark,Hadjitofi Tasoula Georgiou","Altaweel M,Hadjitofi TG",Altaweel M,10.1177/2053951720968865,University of London,"The marketisation of heritage has been a major topic of interest among heritage specialists studying how the online marketplace shapes sales. Missing from that debate is a large-scale analysis seeking to understand market trends on popular selling platforms such as eBay. Sites such as eBay can inform what heritage items are of interest to the wider public, and thus what is potentially of greater cultural value, while also demonstrating monetary value trends. To better understand the sale of heritage on eBay's international site, this work applies named entity recognition using conditional random fields, a method within natural language processing, and word dictionaries that inform on market trends. The methods demonstrate how Western markets, particularly the US and UK, have dominated sales for different cultures. Roman, Egyptian, Viking (Norse/Dane) and Near East objects are sold the most. Surprisingly, Cyprus and Egypt, two countries with relatively strict prohibition against the sale of heritage items, make the top 10 selling countries on eBay. Objects such as jewellery, statues and figurines, and religious items sell in relatively greater numbers, while masks and vessels (e.g. vases) sell at generally higher prices. Metal, stone and terracotta are commonly sold materials. More rare materials, such as those made of ivory, papyrus or wood, have relatively higher prices. Few sellers dominate the market, where in some months 40% of sales are controlled by the top 10 sellers. The tool used for the study is freely provided, demonstrating benefits in an automated approach to understanding sale trends.","eBay,heritage,antiquities,natural language processing,name entity recognition,conditional random field,machine learning",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA",Social Sciences - Other Topics,,8.118,"NAMED-ENTITY,RECOGNITION",BIG DATA & SOCIETY,https://journals.sagepub.com/doi/pdf/10.1177/2053951720968865,
