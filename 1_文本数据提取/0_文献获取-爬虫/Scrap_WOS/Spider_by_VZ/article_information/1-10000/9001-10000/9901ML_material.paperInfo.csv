,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Weakly Supervised Deep Learning for Brain Disease Prognosis Using MRI and Incomplete Clinical Scores,50,7,3381-3392,"Liu Mingxia,Zhang Jun,Lian Chunfeng,Shen Dinggang","Liu MX,Zhang J,Lian CF,Shen DG",Shen DG,10.1109/TCYB.2019.2904186,University of North Carolina,"As a hot topic in brain disease prognosis, predicting clinical measures of subjects based on brain magnetic resonance imaging (MRI) data helps to assess the stage of pathology and predict future development of the disease. Due to incomplete clinical labels/scores, previous learning-based studies often simply discard subjects without ground-truth scores. This would result in limited training data for learning reliable and robust models. Also, existing methods focus only on using hand-crafted features (e.g., image intensity or tissue volume) of MRI data, and these features may not be well coordinated with prediction models. In this paper, we propose a weakly supervised densely connected neural network (wiseDNN) for brain disease prognosis using baseline MRI data and incomplete clinical scores. Specifically, we first extract multiscale image patches (located by anatomical landmarks) from MRI to capture local-to-global structural information of images, and then develop a weakly supervised densely connected network for task-oriented extraction of imaging features and joint prediction of multiple clinical measures. A weighted loss function is further employed to make full use of all available subjects (even those without ground-truth scores at certain time-points) for network training. The experimental results on 1469 subjects from both ADNI-1 and ADNI-2 datasets demonstrate that our proposed method can efficiently predict future clinical measures of subjects.","Magnetic resonance imaging,Diseases,Brain modeling,Feature extraction,Training,Deep learning,Prognostics and health management,Alzheimer's disease (AD),clinical score,disease prognosis,neural network,weakly supervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Computer Science",,11.507,"VOXEL-BASED,MORPHOMETRY,ALZHEIMERS-DISEASE,TUMOR,SEGMENTATION,CLASSIFICATION,VOLUME,SCHIZOPHRENIA,SIMILARITY,NETWORKS,PATTERNS,ATROPHY",IEEE TRANSACTIONS ON CYBERNETICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8034591,
2,SACNN: Self-Attention Convolutional Neural Network for Low-Dose CT Denoising With Self-Supervised Perceptual Loss Network,39,7,2289-2301,"Li Meng,Hsu William,Xie Xiaodong,Cong Jason,Gao Wen","Li M,Hsu W,Xie XD,Cong J,Gao W",Li M,10.1109/TMI.2020.2968472,Peking University,"Computed tomography (CT) is a widely used screening and diagnostic tool that allows clinicians to obtain a high-resolution, volumetric image of internal structures in a non-invasive manner. Increasingly, efforts have been made to improve the image quality of low-dose CT (LDCT) to reduce the cumulative radiation exposure of patients undergoing routine screening exams. The resurgence of deep learning has yielded a new approach for noise reduction by training a deep multi-layer convolutional neural networks (CNN) to map the low-dose to normal-dose CT images. However, CNN-based methods heavily rely on convolutional kernels, which use fixed-sizefilters to process one local neighborhood within the receptive field at a time. As a result, they are not efficient at retrieving structural information across large regions. In this paper, we propose a novel 3D self-attention convolutional neural network for the LDCT denoising problem. Our 3D self-attention module leverages the 3D volume of CT images to capture a wide range of spatial information both within CT slices and between CT slices. With the help of the 3D self-attention module, CNNs are able to leverage pixels with stronger relationships regardless of their distance and achieve better denoising results. In addition, we propose a self-supervised learning scheme to train a domain-specific autoencoder as the perceptual loss function. We combine these two methods and demonstrate their effectiveness on both CNN-based neural networks and WGAN-based neural networks with comprehensive experiments. Tested on the AAPM-Mayo Clinic Low Dose CT Grand Challenge data set, our experiments demonstrate that self-attention (SA) module and autoencoder (AE) perceptual loss function can efficiently enhance traditional CNNs and can achieve comparable or better results than the state-of-the-art methods.","Low-dose CT,denoising,self-attention,autoencoder,perceptual loss",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"COMPUTED-TOMOGRAPHY,IMAGE-RECONSTRUCTION,NOISE-REDUCTION,ALGORITHM",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
3,Multi-Needle Detection n 3D Ultrasound Images Using Unsupervised Order-Graph Regularized Sparse Dictionary Learning,39,7,2302-2315,"Zhang Yupei,He Xiuxiu,Tian Zhen,Jeong Jiwoong Jason,Lei Yang,Wang Tonghe,Zeng Qiulan,Jani Ashesh B.,Curran Walter J.,Patel Pretesh","Zhang YP,He XX,Tian Z,Jeong JJ,Lei Y,Wang TH,Zeng QL,Jani AB,Curran WJ,Patel P",Yang XF,10.1109/TMI.2020.2968770,Emory University,"Accurate and automatic multi-needle detection in three-dimensional (3D) ultrasound (US) is a key step of treatment planning for US-guided brachytherapy. However, most current studies are concentrated on single-needle detection by only using a small number of images with a needle, regardless of the massive database of US images without needles. In this paper, we propose a workflow for multi-needle detection by considering the images without needles as auxiliary. Concretely, we train position-specific dictionaries on 3D overlapping patches of auxiliary images, where we develop an enhanced sparse dictionary learning method by integrating spatial continuity of 3D US, dubbed order-graph regularized dictionary learning. Using the learned dictionaries, target images are reconstructed to obtain residual pixels which are then clustered in every slice to yield centers. With the obtained centers, regions of interest (ROls) are constructed via seeking cylinders. Finally, we detect needles by using the random sample consensus algorithm per ROI and then locate the tips by finding the sharp intensity drops along the detected axis for every needle. Extensive experiments were conducted on a phantom dataset and a prostate dataset of 70/21 patients without/with needles. Visualization and quantitative results show the effectiveness of our proposed workflow. Specifically, our method can correctly detect 95% of needles with a tip location error of 1.01 mm on the prostate dataset. This technique provides accurate multi-needle detection for US-guided HDR prostate brachytherapy, facilitating the clinical workflow.","Dictionary learning,multi-needle detection,self- taught learning,tips detection,ultrasound guided brachytherapy",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"SURGICAL,TOOL,LOCALIZATION,MATRIX,FACTORIZATION,TRACKING,ALGORITHM,RANSAC",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7370243,
4,Deep Learning-Based Development of Personalized Human Head Model With Non-Uniform Conductivity for Brain Stimulation,39,7,2351-2362,"Rashed Essam A.,Gomez-Tames Jose,Hirata Akimasa","Rashed EA,Gomez-Tames J,Hirata A",Rashed EA,10.1109/TMI.2020.2969682,Nagoya Institute of Technology,"Electromagnetic stimulation of the human brain is a key tool for neurophysiological characterization and the diagnosis of several neurological disorders. Transcranial magnetic stimulation (TMS) is a commonly used clinical procedure. However, personalized TMS requires a pipeline for individual head model generation to provide target-specific stimulation. This process includes intensive segmentation of several head tissues based on magnetic resonance imaging (MRI), which has significant potential for segmentation error, especially for low-contrast tissues. Additionally, a uniform electrical conductivity is assigned to each tissue in the model, which is an unrealistic assumption based on conventional volume conductor modeling. This study proposes a novel approach for fast and automatic estimation of the electric conductivity in the human head for volume conductor models without anatomical segmentation. A convolutional neural network is designed to estimate personalized electrical conductivity values based on anatomical information obtained from T1- and T2-weighted MRI scans. This approach can avoid the time-consuming process of tissue segmentation and maximize the advantages of position-dependent conductivity assignment based on the water content values estimated from MRI intensity values. The computational results of the proposed approach provide similar but smoother electric field distributions of the brain than that provided by conventional approaches.","Conductivity,Magnetic resonance imaging,Brain modeling,Head,Magnetic heads,Image segmentation,Conductors,Precision medicine,electrical conductivity,MRI,deep learning,convolutional neural networks,TMS",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"TRANSCRANIAL,MAGNETIC,STIMULATION,ELECTRIC-FIELD,DIELECTRIC-PROPERTIES,TISSUE,VARIABILITY,MRI",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1910.02420,
5,Unpaired Multi-Modal Segmentation via Knowledge Distillation,39,7,2415-2425,"Dou Qi,Liu Quande,Heng Pheng Ann,Glocker Ben","Dou Q,Liu QD,Heng PA,Glocker B",Dou Q,10.1109/TMI.2019.2963882,Imperial College London,"Multi-modal learning is typically performed with network architectures containing modality-specific layers and shared layers, utilizing co-registered images of different modalities. We propose a novel learning scheme for unpaired cross-modality image segmentation, with a highly compact architecture achieving superior segmentation accuracy. In our method, we heavily reuse network parameters, by sharing all convolutional kernels across CT and MRI, and only employ modality-specific internal normalization layers which compute respective statistics. To effectively train such a highly compact model, we introduce a novel loss term inspired by knowledge distillation, by explicitly constraining the KL-divergence of our derived prediction distributions between modalities. We have extensively validated our approach on two multi-class segmentation problems: i) cardiac structure segmentation, and ii) abdominal organ segmentation. Different network settings, i.e., 2D dilated network and 3D U-net, are utilized to investigate our method's general efficacy. Experimental results on both tasks demonstrate that our novel multi-modal learning scheme consistently outperforms single-modal training and previous multi-modal approaches.","Magnetic resonance imaging,Computed tomography,Image segmentation,Semantics,Task analysis,Feature extraction,Kernel,Unpaired multimodal learning,knowledge distillation,feature normalization,image segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORKS",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2001.03111,
6,Deep Multi-Scale Mesh Feature Learning for Automated Labeling of Raw Dental Surfaces From 3D Intraoral Scanners,39,7,2440-2450,"Lian Chunfeng,Wang Li,Wu Tai-Hsien,Wang Fan,Yap Pew-Thian,Ko Ching-Chang,Shen Dinggang","Lian CF,Wang L,Wu TH,Wang F,Yap PT,Ko CC,Shen DG",Shen DG,10.1109/TMI.2020.2971730,University of North Carolina,"Precisely labeling teeth on digitalized 3D dental surface models is the precondition for tooth position rearrangements in orthodontic treatment planning. However, it is a challenging task primarily due to the abnormal and varying appearance of patients' teeth. The emerging utilization of intraoral scanners (IOSs) in clinics further increases the difficulty in automated tooth labeling, as the raw surfaces acquired by IOS are typically low-quality at gingival and deep intraoral regions. In recent years, some pioneering end-to-end methods (e.g., PointNet) have been proposed in the communities of computer vision and graphics to consume directly raw surface for 3D shape segmentation. Although these methods are potentially applicable to our task, most of them fail to capture fine-grained local geometric context that is critical to the identification of small teeth with varying shapes and appearances. In this paper, we propose an end-to-end deep-learning method, called MeshSegNet, for automated tooth labeling on raw dental surfaces. Using multiple raw surface attributes as inputs, MeshSegNet integrates a series of graph-constrained learning modules along its forward path to hierarchically extract multi-scale local contextual features. Then, a dense fusion strategy is applied to combine local-to-global geometric features for the learning of higher-level features for mesh cell annotation. The predictions produced by our MeshSegNet are further post-processed by a graph-cut refinement step for final segmentation. We evaluated MeshSegNet using a real-patient dataset consisting of raw maxillary surfaces acquired by 3D IOS. Experimental results, performed 5-fold cross-validation, demonstrate that MeshSegNet significantly outperforms state-of-the-art deep learning methods for 3D shape segmentation.","Teeth,Dentistry,Three-dimensional displays,Labeling,Shape,Feature extraction,Surface morphology,3D shape segmentation,geometric deep learning,automated tooth labeling,orthodontic treatment planning,3D intraoral scanners",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"TOOTH,SEGMENTATION",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
7,Unsupervised Bidirectional Cross-Modality Adaptation via Deeply Synergistic Image and Feature Alignment for Medical Image Segmentation,39,7,2494-2505,"Chen Cheng,Dou Qi,Chen Hao,Qin Jing,Heng Pheng Ann","Chen C,Dou Q,Chen H,Qin J,Heng PA",Dou Q,10.1109/TMI.2020.2972701,Chinese University of Hong Kong,"Unsupervised domain adaptation has increasingly gained interest in medical image computing, aiming to tackle the performance degradation of deep neural networks when being deployed to unseen data with heterogeneous characteristics. In this work, we present a novel unsupervised domain adaptation framework, named as Synergistic Image and Feature Alignment (SIFA), to effectively adapt a segmentation network to an unlabeled target domain. Our proposed SIFA conducts synergistic alignment of domains from both image and feature perspectives. In particular, we simultaneously transform the appearance of images across domains and enhance domain-invariance of the extracted features by leveraging adversarial learning in multiple aspects and with a deeply supervised mechanism. The feature encoder is shared between both adaptive perspectives to leverage their mutual benefits via end-to-end learning. We have extensively evaluated our method with cardiac substructure segmentation and abdominal multi-organ segmentation for bidirectional cross-modality adaptation between MRI and CT images. Experimental results on two different tasks demonstrate that our SIFA method is effective in improving segmentation performance on unlabeled target images, and outperforms the state-of-the-art domain adaptation approaches by a large margin.","Image segmentation,Magnetic resonance imaging,Feature extraction,Biomedical imaging,Computed tomography,Semantics,Task analysis,Unsupervised domain adaptation,image segmentation,cross-modality learning,adversarial learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2002.02255,
8,Generalizing Deep Learning for Medical Image Segmentation to Unseen Domains via Deep Stacked Transformation,39,7,2531-2540,"Zhang Ling,Wang Xiaosong,Yang Dong,Sanford Thomas,Harmon Stephanie,Turkbey Baris,Wood Bradford J.,Roth Holger,Myronenko Andriy,Xu Daguang","Zhang L,Wang XS,Yang D,Sanford T,Harmon S,Turkbey B,Wood BJ,Roth H,Myronenko A,Xu DG",Xu ZY,10.1109/TMI.2020.2973595,Nvidia Corporation,"Recent advances in deep learning for medical image segmentation demonstrate expert-level accuracy. However, application of these models in clinically realistic environments can result in poor generalization and decreased accuracy, mainly due to the domain shift across different hospitals, scanner vendors, imaging protocols, and patient populations etc. Common transfer learning and domain adaptation techniques are proposed to address this bottleneck. However, these solutions require data (and annotations) from the target domain to retrain the model, and is therefore restrictive in practice for widespread model deployment. Ideally, we wish to have a trained (locked) model that can work uniformly well across unseen domains without further training. In this paper, we propose a deep stacked transformation approach for domain generalization. Specifically, a series of n stacked transformations are applied to each image during network training. The underlying assumption is that the ""expected"" domain shift for a specific medical imaging modality could be simulated by applying extensive data augmentation on a single source domain, and consequently, a deep model trained on the augmented ""big"" data (BigAug) could generalize well on unseen domains. We exploit four surprisingly effective, but previously understudied, image-based characteristics for data augmentation to overcome the domain generalization problem. We train and evaluate the BigAug model (with n = 9 transformations) on three different 3D segmentation tasks (prostate gland, left atrial, left ventricle) covering two medical imaging modalities (MRI and ultrasound) involving eight publicly available challenge datasets. The results show that when training on relatively small dataset (n = 10 similar to 32 volumes, depending on the size of the avail- able datasets) from a single source domain: (i) BigAug models degrade an average of 11% (Dice score change)from source to unseen domain, substantially better than conventional augmentation (degrading 39%) and CycleGAN-based domain adaptation method (degrading 25%), (ii) BigAug is better than ""shallower"" stacked transforms (i.e. those with fewer transforms) on unseen domains and demonstrates modest improvement to conventional augmentation on the source domain, (iii) after training with BigAug on one source domain, performance on an unseen domain is similar to training a model from scratch on that domain when using the same number of training samples. When training on large datasets (n = 465 volumes) with BigAug, (iv) application to unseen domains reaches the performance of state-ofthe-art fully supervised models that are trained and tested on their source domains. These findings establish a strong benchmark for the study of domain generalization in medical imaging, and can be generalized to the design of highly robust deep segmentation models for clinical deployment.","Domain generalization,data augmentation,deep learning,medical image segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7393676,
9,Attention-Diffusion-Bilinear Neural Network for Brain Network Analysis,39,7,2541-2552,"Huang Jiashuang,Zhou Luping,Wang Lei,Zhang Daoqiang","Huang JS,Zhou LP,Wang L,Zhang DQ",Zhang DQ,10.1109/TMI.2020.2973650,Nanjing University of Aeronautics & Astronautics,"Brain network provides essential insights in diagnosing many brain disorders. Integrative analysis of multiple types of connectivity, e.g, functional connectivity (FC) and structural connectivity (SC), can take advantage of their complementary information and therefore may help to identify patients. However, traditional brain network methods usually focus on either FC or SC for describing node interactions and only consider the interaction between paired network nodes. To tackle this problem, in this paper, we propose an Attention-Diffusion-Bilinear Neural Network (ADB-NN) framework for brain network analysis, which is trained in an end-to-end manner. The proposed network seamlessly couples FC and SC to learn wider node interactions and generates a joint representation of FC and SC for diagnosis. Specifically, a brain network (graph) is first defined, where each node corresponding to a brain region is governed by the features of brain activities (i.e., FC) extracted from functional magnetic resonance imaging (fMRI), and the presence of edges is determined by neural fiber physical connections (i.e., SC) extracted from Diffusion Tensor Imaging (DTI). Based on this graph, we train two Attention-Diffusion-Bilinear (ADB) modules jointly. In each module, an attention model is utilized to automatically learn the strength of node interactions. This information further guides a diffusion process that generates new node representations by considering the influence from other nodes as well. After that, the second-order statistics of these node representations are extracted by bilinear pooling to form connectivity-based features for disease prediction. The two ADB modules correspond to the one-step and two-step diffusion, respectively. Experiments on a real epilepsy dataset demonstrate the effectiveness and advantages of our proposed method.","Functional magnetic resonance imaging,Diffusion tensor imaging,Feature extraction,Biological neural networks,Diffusion processes,Epilepsy,Brain network,functional connectivity,structural connectivity,attention-diffusion-bilinear neural network,epilepsy",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"FUNCTIONAL,CONNECTIVITY,ALZHEIMERS-DISEASE",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
10,Channel Attention Module With Multiscale Grid Average Pooling for Breast Cancer Segmentation in an Ultrasound Image,67,7,1344-1353,"Lee Haeyun,Park Jinhyoung,Hwang Jae Youn","Lee H,Park J,Hwang JY",Hwang JY,10.1109/TUFFC.2020.2972573,Daegu Gyeongbuk Institute of Science & Technology (DGIST),"Breast cancer accounts for the second-largest number of deaths in women around the world, and more than 8% of women will suffer from the disease in their lifetime. Mortality due to breast cancer can be reduced by its early and precise diagnosis. Many studies have investigated methods for segmentation, and computer-aided diagnosis based on deep learning techniques, in particular, has recently gained attention. However, recently proposed methods such as fully convolutional network (FCN), SegNet, and U-Net still need to be further improved to provide better semantic segmentation when diagnosing breast cancer by ultrasound imaging, because of their low performance. In this article, we propose a channel attention module with multiscale grid average pooling (MSGRAP) for the precise segmentation of breast cancer regions in ultrasound images. We demonstrate the effectiveness of the channel attention module with MSGRAP for semantic segmentation and develop a novel semantic segmentation network with the proposed attention module for the precise segmentation of breast cancer regions in ultrasound images. While a conventional convolutional operation cannot use global spatial information on input images and only use the small local information in a kernel of a convolution filter, the proposed attention module allows using both global and local spatial information. In addition, through ablation studies, we come up with a network architecture for precise breast cancer segmentation in an ultrasound image. The proposed network was constructed with an open-source breast cancer ultrasound image data set, and its performance was compared with those of other state-of-the-art deep-learning models for the segmentation of breast cancer. The experimental results showed that our network outperformed other segmentation methods, and the proposed channel attention module improved the performance of the network for breast cancer segmentation in ultrasound images.","Breast cancer,Image segmentation,Ultrasonic imaging,Semantics,Deep learning,Acoustics,Breast cancer,deep learning,semantic segmentation,ultrasound image",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,"LESION,DETECTION,CLASSIFICATION,DIAGNOSIS,MASSES",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,,
11,Meeting Cyber Age Needs for Governance in a Changing Global Order,12,14,,"Young Oran R.,Yang Jian,Guttman Dan","Young OR,Yang J,Guttman D",Young OR,10.3390/su12145557,University of California System,"The advent of the cyber age has created a world in which digital systems, operating on their own and interacting with more conventional material or physical systems, have become an increasingly prominent feature of the landscape of human affairs. This development, affecting every aspect of human life, has generated a class of increasingly critical needs for governance that are difficult to address effectively within the confines of the current global order in which sovereign states compete to maximize their influence in the absence of any overarching public authority. These needs include concerns associated with the management of powerful digital technologies (e.g., artificial intelligence, robotics, machine learning, blockchain technology, the internet of things, and big data) as well as problems relating to the use of these technologies by many actors to exercise influence from the level of the individual (e.g., identity theft) to the level of international society (e.g., foreign interventions in national electoral systems). The challenge of meeting these needs prompts an analysis of processes leading to change in the prevailing global order, energized at least in part by the growing role of the digital systems of the cyber age. Our analysis includes both Western perspectives highlighting changes in the identity and behavior of key actors and Chinese perspectives emphasizing the spread of social narratives embedded in the concepts oftianxiaandgongsheng. While it is premature to make explicit predictions, we conclude with some observations about the most important trends to watch regarding efforts to meet cyber age needs for governance, and we note the connections between these developments and the overarching challenge of fulfilling the suite of goals commonly associated with the idea of sustainable development.","cyber age,global order,facilitated reform,managed transformation,tianxia,gongsheng,sustainable development",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Science & Technology - Other Topics,Environmental Sciences & Ecology",,3.473,,SUSTAINABILITY,https://www.mdpi.com/2071-1050/12/14/5557/pdf,
12,Improving Prediction of Springback in Sheet Metal Forming Using Multilayer Perceptron-Based Genetic Algorithm,13,14,,"Trzepiecinski Tomasz,Lemu Hirpa G.","Trzepiecinski T,Lemu HG",Lemu HG,10.3390/ma13143129,Universitetet i Stavanger,"This paper presents the results of predictions of springback of cold-rolled anisotropic steel sheets using an approach based on a multilayer perceptron-based artificial neural network (ANN) coupled with a genetic algorithm (GA). A GA was used to optimise the number of input parameters of the multilayer perceptron that was trained using different algorithms. In the investigations, the mechanical parameters of sheet material determined in uniaxial tensile tests were used as input parameters to train the ANN. The springback coefficient, determined experimentally in the V-die air bending test, was used as an output variable. It was found that specimens cut along the rolling direction exhibit higher values of springback coefficient than specimens cut transverse to the rolling direction. An increase in the bending angle leads to an increase in the springback coefficient. A GA-based analysis has shown that Young's modulus and ultimate tensile stress are variables having no significant effect on the coefficient of springback. Multilayer perceptrons trained by back propagation, conjugate gradients and Lavenberg-Marquardt algorithms definitely favour punch bend depth under load as the most important variables affecting the springback coefficient.","elastic strain,genetic algorithm,perceptron-based prediction,springback,steel sheet metal",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"BENDING,PROCESS,HYPERBOLIC,TANGENT,ANALYTICAL-MODEL,FINITE-ELEMENT,NEURAL-NETWORK,BEHAVIOR,DESIGN",MATERIALS,https://uis.brage.unit.no/uis-xmlui/bitstream/11250/2670101/2/materials-13-03129.pdf,
13,"Machine Learning to Quantify Physical Activity in Children with Cerebral Palsy: Comparison of Group, Group-Personalized, and Fully-Personalized Activity Classification Models",20,14,,"Ahmadi Matthew N.,O'Neil Margaret E.,Baque Emmah,Boyd Roslyn N.,Trost Stewart G.","Ahmadi MN,O'Neil ME,Baque E,Boyd RN,Trost SG",Trost SG,10.3390/s20143976,Queensland University of Technology (QUT),"Pattern recognition methodologies, such as those utilizing machine learning (ML) approaches, have the potential to improve the accuracy and versatility of accelerometer-based assessments of physical activity (PA). Children with cerebral palsy (CP) exhibit significant heterogeneity in relation to impairment and activity limitations; however, studies conducted to date have implemented ""one-size fits all"" group (G) models. Group-personalized (GP) models specific to the Gross Motor Function Classification (GMFCS) level and fully-personalized (FP) models trained on individual data may provide more accurate assessments of PA; however, these approaches have not been investigated in children with CP. In this study, 38 children classified at GMFCS I to III completed laboratory trials and a simulated free-living protocol while wearing an ActiGraph GT3X+ on the wrist, hip, and ankle. Activities were classified as sedentary, standing utilitarian movements, or walking. In the cross-validation, FP random forest classifiers (99.0-99.3%) exhibited a significantly higher accuracy than G (80.9-94.7%) and GP classifiers (78.7-94.1%), with the largest differential observed in children at GMFCS III. When evaluated under free-living conditions, all model types exhibited significant declines in accuracy, with FP models outperforming G and GP models in GMFCS levels I and II, but not III. Future studies should evaluate the comparative accuracy of personalized models trained on free-living accelerometer data.","accelerometers,wearable sensors,exercise,measurement,GMFCS level",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,"ACTIVITY,MONITOR,ACTIVITY,PERFORMANCE,AMBULATORY,CHILDREN,ACTIVITY,INTENSITY,OBJECTIVE,MEASURES,ACCELEROMETER,VALIDITY,WRIST,RECOGNITION,ADOLESCENTS",SENSORS,https://research-repository.griffith.edu.au/bitstream/10072/396111/2/Baque437759-Published.pdf,
14,CellCountCV-A Web-Application for Accurate Cell Counting and Automated Batch Processing of Microscopic Images Using Fully Convolutional Neural Networks,20,13,,"Antonets Denis,Russkikh Nikolai,Sanchez Antoine,Kovalenko Victoria,Bairamova Elvira,Shtokalo Dmitry,Medvedev Sergey,Zakian Suren","Antonets D,Russkikh N,Sanchez A,Kovalenko V,Bairamova E,Shtokalo D,Medvedev S,Zakian S",Antonets D,10.3390/s20133653,Ershov Institute of Informatics Systems,"In vitro cellular models are promising tools for studying normal and pathological conditions. One of their important applications is the development of genetically engineered biosensor systems to investigate, in real time, the processes occurring in living cells. At present, there are fluorescence, protein-based, sensory systems for detecting various substances in living cells (for example, hydrogen peroxide, ATP, Ca(2+)etc.,) or for detecting processes such as endoplasmic reticulum stress. Such systems help to study the mechanisms underlying the pathogenic processes and diseases and to screen for potential therapeutic compounds. It is also necessary to develop new tools for the processing and analysis of obtained microimages. Here, we present our web-application CellCountCV for automation of microscopic cell images analysis, which is based on fully convolutional deep neural networks. This approach can efficiently deal with non-convex overlapping objects, that are virtually inseparable with conventional image processing methods. The cell counts predicted with CellCountCV were very close to expert estimates (the average error rate was < 4%). CellCountCV was used to analyze large series of microscopic images obtained in experimental studies and it was able to demonstrate endoplasmic reticulum stress development and to catch the dose-dependent effect of tunicamycin.","neural networks,fluorescent protein-based sensors,image analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"UNFOLDED,PROTEIN,RESPONSE,ER,STRESS",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7374276,
15,Laryngeal Lesion Classification Based on Vascular Patterns in Contact Endoscopy and Narrow Band Imaging: Manual Versus Automatic Approach,20,14,,"Esmaeili Nazila,Illanes Alfredo,Boese Axel,Davaris Nikolaos,Arens Christoph,Navab Nassir,Friebe Michael","Esmaeili N,Illanes A,Boese A,Davaris N,Arens C,Navab N,Friebe M",Esmaeili N,10.3390/s20144018,Otto von Guericke University,"Longitudinal and perpendicular changes in the vocal fold's blood vessels are associated with the development of benign and malignant laryngeal lesions. The combination of Contact Endoscopy (CE) and Narrow Band Imaging (NBI) can provide intraoperative real-time visualization of the vascular changes in the laryngeal mucosa. However, the visual evaluation of vascular patterns in CE-NBI images is challenging and highly depends on the clinicians' experience. The current study aims to evaluate and compare the performance of a manual and an automatic approach for laryngeal lesion's classification based on vascular patterns in CE-NBI images. In the manual approach, six observers visually evaluated a series of CE+NBI images that belong to a patient and then classified the patient as benign or malignant. For the automatic classification, an algorithm based on characterizing the level of the vessel's disorder in combination with four supervised classifiers was used to classify CE-NBI images. The results showed that the manual approach's subjective evaluation could be reduced by using a computer-based approach. Moreover, the automatic approach showed the potential to work as an assistant system in case of disagreements among clinicians and to reduce the manual approach's misclassification issue.","laryngeal cancer,contact endoscopy,narrow band imaging,automatic classification,feature extraction,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"VOCAL,FOLDS,CANCER",SENSORS,https://www.mdpi.com/1424-8220/20/14/4018/pdf,
16,Evaluation of Vertical Ground Reaction Forces Pattern Visualization in Neurodegenerative Diseases Identification Using Deep Learning and Recurrence Plot Image Feature Extraction,20,14,,"Lin Che-Wei,Wen Tzu-Chien,Setiawan Febryan","Lin CW,Wen TC,Setiawan F",Lin CW,10.3390/s20143857,National Cheng Kung University,"To diagnose neurodegenerative diseases (NDDs), physicians have been clinically evaluating symptoms. However, these symptoms are not very dependable-particularly in the early stages of the diseases. This study has therefore proposed a novel classification algorithm that uses a deep learning approach to classify NDDs based on the recurrence plot of gait vertical ground reaction force (vGRF) data. The irregular gait patterns of NDDs exhibited by vGRF data can indicate different variations of force patterns compared with healthy controls (HC). The classification algorithm in this study comprises three processes: a preprocessing, feature transformation and classification. In the preprocessing process, the 5-min vGRF data divided into 10-s successive time windows. In the feature transformation process, the time-domain vGRF data are modified into an image using a recurrence plot. The total recurrence plots are 1312 plots for HC (16 subjects), 1066 plots for ALS (13 patients), 1230 plots for PD (15 patients) and 1640 plots for HD (20 subjects). The principal component analysis (PCA) is used in this stage for feature enhancement. Lastly, the convolutional neural network (CNN), as a deep learning classifier, is employed in the classification process and evaluated using the leave-one-out cross-validation (LOOCV). Gait data from HC subjects and patients with amyotrophic lateral sclerosis (ALS), Huntington's disease (HD) and Parkinson's disease (PD) obtained from the PhysioNet Gait Dynamics in Neurodegenerative disease were used to validate the proposed algorithm. The experimental results included two-class and multiclass classifications. In the two-class classification, the results included classification of the NDD and the HC groups and classification among the NDDs. The classification accuracy for (HC vs. ALS), (HC vs. HD), (HC vs. PD), (ALS vs. PD), (ALS vs. HD), (PD vs. HD) and (NDDs vs. HC) were 100%, 98.41%, 100%, 95.95%, 100%, 97.25% and 98.91%, respectively. In the multiclass classification, a four-class gait classification among HC, ALS, PD and HD was conducted and the classification accuracy of HC, ALS, PD and HD were 98.99%, 98.32%, 97.41% and 96.74%, respectively. The proposed method can achieve high accuracy compare to the existing results, but with shorter length of input signal (Input of existing literature using the same database is 5-min gait signal, but the proposed method only needs 10-s gait signal).","gait analysis,pattern visualization,neurodegenerative diseases,deep learning,feature extraction,recurrence plot,vertical ground reaction force (vGRF) data",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,"AMYOTROPHIC-LATERAL-SCLEROSIS,PARKINSONS-DISEASE,GAIT,RHYTHM,TIME-SERIES,CLASSIFICATION,EPIDEMIOLOGY,DYNAMICS,SYSTEM",SENSORS,https://www.mdpi.com/1424-8220/20/14/3857/pdf,
17,A Combined Deep-Learning and Lattice Boltzmann Model for Segmentation of the Hippocampus in MRI,20,13,,"Liu Yingqian,Yan Zhuangzhi","Liu YQ,Yan ZZ",Liu YQ,10.3390/s20133628,Shanghai University,"Segmentation of the hippocampus (HC) in magnetic resonance imaging (MRI) is an essential step for diagnosis and monitoring of several clinical situations such as Alzheimer's disease (AD), schizophrenia and epilepsy. Automatic segmentation of HC structures is challenging due to their small volume, complex shape, low contrast and discontinuous boundaries. The active contour model (ACM) with a statistical shape prior is robust. However, it is difficult to build a shape prior that is general enough to cover all possible shapes of the HC and that suffers the problems of complicated registration of the shape prior and the target object and of low efficiency. In this paper, we propose a semi-automatic model that combines a deep belief network (DBN) and the lattice Boltzmann (LB) method for the segmentation of HC. The training process of DBN consists of unsupervised bottom-up training and supervised training of a top restricted Boltzmann machine (RBM). Given an input image, the trained DBN is utilized to infer the patient-specific shape prior of the HC. The specific shape prior is not only used to determine the initial contour, but is also introduced into the LB model as part of the external force to refine the segmentation. We used a subset of OASIS-1 as the training set and the preliminary release of EADC-ADNI as the testing set. The segmentation results of our method have good correlation and consistency with the manual segmentation results.","deep belief network,shape prior,lattice Boltzmann method,hippocampus segmentation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,LEFT-VENTRICLE,SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7374374,
18,Application of an Automated Digital Image-Processing Method for Quantitative Assessment of Cracking Patterns in a Lime Cement Matrix,20,14,,Szelag Maciej,Szelag M,Szelag M,10.3390/s20143859,Lublin University of Technology,"The paper presents an original approach to the localization and analysis of the cracking patterns of cement composites. The lime cement matrix modified with microsilica was evaluated under a two-phase thermal load. For quantitative detection and analysis of thermal cracks, an image-processing method was applied. For this purpose, an original image double-segmentation method was developed using machine-learning algorithms. Among other things, the fractal analysis was used to describe the morphology and the thermal evolution of the cracking patterns. The basic mechanical characteristics were examined and the results indicated a very high correlation between tensile strength and all cracking patterns' parameters. This allows high-quality estimation of the mechanical properties of the lime cement matrix to be carried out on the basis of measurement and evaluation of morphology of the thermal cracking patterns. Knowledge in this field contributes to the development of non-destructive testing methods in cement composites technology, in terms of localization of and tracking the cracking patterns.","cement matrix,cracks detection,image analysis,cracking pattern,fractal dimension,ImageJ",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"INCORPORATING,FLY-ASH,COMPRESSIVE,STRENGTH,FRACTURE-MECHANICS,NEURAL-NETWORK,CONCRETE,COMPOSITES,SHRINKAGE,ALGORITHM,SPECIMENS,BEHAVIOR",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7411616,
19,A Novel Surface Electromyographic Signal-Based Hand Gesture Prediction Using a Recurrent Neural Network,20,14,,"Zhang Zhen,He Changxin,Yang Kuo","Zhang Z,He CX,Yang K",Zhang Z,10.3390/s20143994,Shanghai University,"Surface electromyographic signal (sEMG) is a kind of bioelectrical signal, which records the data of muscle activity intensity. Most sEMG-based hand gesture recognition, which uses machine learning as the classifier, depends on feature extraction of sEMG data. Recently, a deep leaning-based approach such as recurrent neural network (RNN) has provided a choice to automatically learn features from raw data. This paper presents a novel hand gesture prediction method by using an RNN model to learn from raw sEMG data and predict gestures. The sEMG signals of 21 short-term hand gestures of 13 subjects were recorded with a Myo armband, which is a non-intrusive, low cost, commercial portable device. At the start of the gesture, the trained model outputs an instantaneous prediction for the sEMG data. Experimental results showed that the more time steps of data that were known, the higher instantaneous prediction accuracy the proposed model gave. The predicted accuracy reached about 89.6% when the data of 40-time steps (200 ms) were used to predict hand gesture. This means that the gesture could be predicted with a delay of 200 ms after the hand starts to perform the gesture, instead of waiting for the end of the gesture.","sEMG,hand gesture prediction,RNN,myo armband",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,CLASSIFICATION,SENSORS,https://www.mdpi.com/1424-8220/20/14/3994/pdf,
20,A Survey on Artificial Intelligence Techniques for Biomedical Image Analysis in Skeleton-Based Forensic Human Identification,10,14,,"Mesejo Pablo,Martos Ruben,Ibanez Oscar,Novo Jorge,Ortega Marcos","Mesejo P,Martos R,Ibanez O,Novo J,Ortega M",Mesejo P,10.3390/app10144703,University of Granada,"This paper represents the first survey on the application of AI techniques for the analysis of biomedical images with forensic human identification purposes. Human identification is of great relevance in today's society and, in particular, in medico-legal contexts. As consequence, all technological advances that are introduced in this field can contribute to the increasing necessity for accurate and robust tools that allow for establishing and verifying human identity. We first describe the importance and applicability of forensic anthropology in many identification scenarios. Later, we present the main trends related to the application of computer vision, machine learning and soft computing techniques to the estimation of the biological profile, the identification through comparative radiography and craniofacial superimposition, traumatism and pathology analysis, as well as facial reconstruction. The potentialities and limitations of the employed approaches are described, and we conclude with a discussion about methodological issues and future research.","forensic medicine,forensic anthropology,forensic imaging,skeleton-based forensic identification,machine learning,computer vision,soft computing,biological profiling,comparative radiography,craniofacial identification",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"BONE-AGE,ASSESSMENT,COMPUTER-AIDED,CLASSIFICATION,X-RAY,IMAGES,CRANIOFACIAL,SUPERIMPOSITION,SEX,ESTIMATION,RADIOGRAPHIC,IDENTIFICATION,FACIAL,APPROXIMATION,SKULL,IDENTIFICATION,DENTAL,BIOMETRICS,CHEST,RADIOGRAPHY",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/14/4703/pdf,
21,Automatic Segmentation and Classification of Heart Sounds Using Modified Empirical Wavelet Transform and Power Features,10,14,,"Narvaez Pedro,Gutierrez Steven,Percybrooks Winston S.","Narvaez P,Gutierrez S,Percybrooks WS",Narvaez P,10.3390/app10144791,University Del Norte,"A system for the automatic classification of cardiac sounds can be of great help for doctors in the diagnosis of cardiac diseases. Generally speaking, the main stages of such systems are (i) the pre-processing of the heart sound signal, (ii) the segmentation of the cardiac cycles, (iii) feature extraction and (iv) classification. In this paper, we propose methods for each of these stages. The modified empirical wavelet transform (EWT) and the normalized Shannon average energy are used in pre-processing and automatic segmentation to identify the systolic and diastolic intervals in a heart sound recording; then, six power characteristics are extracted (three for the systole and three for the diastole)-the motivation behind using power features is to achieve a low computational cost to facilitate eventual real-time implementations. Finally, different models of machine learning (support vector machine (SVM), k-nearest neighbor (KNN), random forest and multilayer perceptron) are used to determine the classifier with the best performance. The automatic segmentation method was tested with the heart sounds from the Pascal Challenge database. The results indicated an error (computed as the sum of the differences between manual segmentation labels from the database and the segmentation labels obtained by the proposed algorithm) of 843,440.8 for dataset A and 17,074.1 for dataset B, which are better values than those reported with the state-of-the-art methods. For automatic classification, 805 sample recordings from different databases were used. The best accuracy result was 99.26% using the KNN classifier, with a specificity of 100% and a sensitivity of 98.57%. These results compare favorably with similar works using the state-of-the-art methods.","EWT,Shannon energy,power features,automatic segmentation,feature extraction,machine learning,heart sound,e-health",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"NEURAL-NETWORKS,FREQUENCY,ALGORITHM,ENSEMBLE",APPLIED SCIENCES-BASEL,https://res.mdpi.com/d_attachment/applsci/applsci-10-04791/article_deploy/applsci-10-04791.pdf,
22,Weakly-Supervised Classification of HER2 Expression in Breast Cancer Haematoxylin and Eosin Stained Slides,10,14,,"Oliveira Sara P.,Pinto Joao Ribeiro,Goncalves Tiago,Canas-Marques Rita,Cardoso Maria-Joao,Oliveira Helder P.,Cardoso Jaime S.","Oliveira SP,Pinto JR,Goncalves T,Canas-Marques R,Cardoso MJ,Oliveira HP,Cardoso JS",Oliveira SP,10.3390/app10144728,INESC,"Human epidermal growth factor receptor 2 (HER2) evaluation commonly requires immunohistochemistry (IHC) tests on breast cancer tissue, in addition to the standard haematoxylin and eosin (H&E) staining tests. Additional costs and time spent on further testing might be avoided if HER2 overexpression could be effectively inferred from H&E stained slides, as a preliminary indication of the IHC result. In this paper, we propose the first method that aims to achieve this goal. The proposed method is based on multiple instance learning (MIL), using a convolutional neural network (CNN) that separately processes H&E stained slide tiles and outputs an IHC label. This CNN is pretrained on IHC stained slide tiles but does not use these data during inference/testing. H&E tiles are extracted from invasive tumour areas segmented with the HASHI algorithm. The individual tile labels are then combined to obtain a single label for the whole slide. The network was trained on slides from the HER2 Scoring Contest dataset (HER2SC) and tested on two disjoint subsets of slides from the HER2SC database and the TCGA-TCIA-BRCA (BRCA) collection. The proposed method attained83.3%classification accuracy on the HER2SC test set and 53.8% on the BRCA test set. Although further efforts should be devoted to achieving improved performance, the obtained results are promising, suggesting that it is possible to perform HER2 overexpression classification on H&E stained tissue slides.","weakly-supervised learning,HER2,breast cancer",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,IMAGE-ANALYSIS,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/14/4728/pdf,
23,Bond Strength Assessment of Concrete-Corroded Rebar Interface Using Artificial Neutral Network,10,14,,"Wang Yi,Geem Zong Woo,Nagai Kohei","Wang Y,Geem ZW,Nagai K",Nagai K,10.3390/app10144724,University of Tokyo,"Bond strength assessment is important for reinforced concrete structures with rebar corrosion since the bond degradation can threaten the structural safety. In this study, to assess the bond strength in concrete-corroded rebar interface, one of the machine learning techniques, artificial neutral network (ANN), was utilized for the application. From existing literature, data related to the bond strength of concrete and corroded rebar were collected. The ANN model was applied to understand the factors on bond property degradation. For the input in the ANN model, the following factors were considered the relative bond strength: (1) corrosion level; (2) crack width; (3) cover-to-diameter ratio; and (4) concrete strength. For the cases with confinement (stirrups), (5) the diameter/stirrups spacing ratio was also considered. The assessment was conducted from input with single parameter to multiple parameters. The scaled feed-forward multi-layer perception ANN model with the error back-propagation algorithm of gradient descent and momentum was found to match the experimental and computed results. The correlation of each parameter to the bond strength degradation was clarified. In cases without confinement, the relative importance was (1) > (2) > (4) > (3), while it was (2) > (1) > (3) > (5) > (4) for the cases with confinement.","rebar corrosion,bond strength,concrete cover thickness,artificial neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"OF-THE-ART,REINFORCEMENT,CORROSION,STRUCTURAL,PERFORMANCE,NONUNIFORM,CORROSION,COVER,CRACKING,STEEL,MODEL,DEGRADATION,PREDICTION,BEHAVIOR",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/14/4724/pdf,
24,Non Invasive Skin Hydration Level Detection Using Machine Learning,9,7,,"Liaqat Sidrah,Dashtipour Kia,Arshad Kamran,Ramzan Naeem","Liaqat S,Dashtipour K,Arshad K,Ramzan N",Ramzan N,10.3390/electronics9071086,University of West Scotland,"Dehydration and overhydration can help to improve medical implications on health. Therefore, it is vital to track the hydration level (HL) specifically in children, the elderly and patients with underlying medical conditions such as diabetes. Most of the current approaches to estimate the hydration level are not sufficient and require more in-depth research. Therefore, in this paper, we used the non-invasive wearable sensor for collecting the skin conductance data and employed different machine learning algorithms based on feature engineering to predict the hydration level of the human body in different body postures. The comparative experimental results demonstrated that the random forest with an accuracy of 91.3% achieved better performance as compared to other machine learning algorithms to predict the hydration state of human body. This study paves a way for further investigation in non-invasive proactive skin hydration detection which can help in the diagnosis of serious health conditions.","skin hydration,non-invasive sensing,machine learning,wearable,skin conductance",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,DEHYDRATION,ELECTRONICS,http://eprints.gla.ac.uk/219219/1/219219.pdf,
25,Residual Strength Evaluation of Corroded Textile-Reinforced Concrete by the Deep Learning-Based Method,13,14,,"Wang Wei,Shi Peng,Deng Lu,Chu Honghu,Kong Xuan","Wang W,Shi P,Deng L,Chu HH,Kong X",Deng L,10.3390/ma13143226,Hunan University,"Residual strength of corroded textile-reinforced concrete (TRC) is evaluated using the deep learning-based method, whose feasibility is demonstrated by experiment. Compared to the traditional method, the proposed method does not need to know the climatic conditions in which the TRC exists. Firstly, the information about the faster region-based convolutional neural networks (Faster R-CNN) is described briefly, and then procedures to prepare datasets are introduced. Twenty TRC specimens were fabricated and divided into five groups that were treated to five different corrosion degrees corresponding to five different residual strengths. Five groups of images of microstructure features of these TRC specimens with five different residual strengths were obtained with portable digital microscopes in various circumstances. With the obtained images, datasets required to train, validate, and test the Faster R-CNN were prepared. To enhance the precision of residual strength evaluation, parameter analysis was conducted for the adopted model. Under the best combination of considered parameters, the mean average precision for the residual strength evaluation of the five groups of the TRC is 98.98%. The feasibility of the trained model was finally verified with new images and the procedures to apply the presented method were summarized. The paper provides new insight into evaluating the residual strength of structural materials, which would be helpful for safety evaluation of engineering structures.","textile-reinforced concrete,deep learning method,faster R-CNN,residual strength evaluation,corrosion degree,microstructure features",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"AR-GLASS,FIBERS,BENDING,BEHAVIOR,MODEL,RECOGNITION,CRACK,TRC",MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7411988,
26,Phonocardiogram Signal Processing for Automatic Diagnosis of Congenital Heart Disorders through Fusion of Temporal and Cepstral Features,20,13,,"Aziz Sumair,Khan Muhammad Umar,Alhaisoni Majed,Akram Tallha,Altaf Muhammad","Aziz S,Khan MU,Alhaisoni M,Akram T,Altaf M",Khan MU,10.3390/s20133790,University of Engineering & Technology Taxila,"Congenital heart disease (CHD) is a heart disorder associated with the devastating indications that result in increased mortality, increased morbidity, increased healthcare expenditure, and decreased quality of life. Ventricular Septal Defects (VSDs) and Arterial Septal Defects (ASDs) are the most common types of CHD. CHDs can be controlled before reaching a serious phase with an early diagnosis. The phonocardiogram (PCG) or heart sound auscultation is a simple and non-invasive technique that may reveal obvious variations of different CHDs. Diagnosis based on heart sounds is difficult and requires a high level of medical training and skills due to human hearing limitations and the non-stationary nature of PCGs. An automated computer-aided system may boost the diagnostic objectivity and consistency of PCG signals in the detection of CHDs. The objective of this research was to assess the effects of various pattern recognition modalities for the design of an automated system that effectively differentiates normal, ASD, and VSD categories using short term PCG time series. The proposed model in this study adopts three-stage processing: pre-processing, feature extraction, and classification. Empirical mode decomposition (EMD) was used to denoise the raw PCG signals acquired from subjects. One-dimensional local ternary patterns (1D-LTPs) and Mel-frequency cepstral coefficients (MFCCs) were extracted from the denoised PCG signal for precise representation of data from different classes. In the final stage, the fused feature vector of 1D-LTPs and MFCCs was fed to the support vector machine (SVM) classifier using 10-fold cross-validation. The PCG signals were acquired from the subjects admitted to local hospitals and classified by applying various experiments. The proposed methodology achieves a mean accuracy of 95.24% in classifying ASD, VSD, and normal subjects. The proposed model can be put into practice and serve as a second opinion for cardiologists by providing more objective and faster interpretations of PCG signals.","phonocardiogram,machine learning,empirical mode decomposition,feature extraction,mel-frequency cepstral coefficients,support vector machines,computer aided diagnosis,congenital heart disease,statistical analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"EMPIRICAL,MODE,DECOMPOSITION,CLASSIFICATION,AUSCULTATION,ABNORMALITY",SENSORS,https://www.mdpi.com/1424-8220/20/13/3790/pdf,
27,Intelligent Industrial Cleaning: A Multi-Sensor Approach Utilising Machine Learning-Based Regression,20,13,,"Simeone Alessandro,Woolley Elliot,Escrig Josep,Watson Nicholas James","Simeone A,Woolley E,Escrig J,Watson NJ",Watson NJ,10.3390/s20133642,University of Nottingham,"Effectively cleaning equipment is essential for the safe production of food but requires a significant amount of time and resources such as water, energy, and chemicals. To optimize the cleaning of food production equipment, there is the need for innovative technologies to monitor the removal of fouling from equipment surfaces. In this work, optical and ultrasonic sensors are used to monitor the fouling removal of food materials with different physicochemical properties from a benchtop rig. Tailored signal and image processing procedures are developed to monitor the cleaning process, and a neural network regression model is developed to predict the amount of fouling remaining on the surface. The results show that the three dissimilar food fouling materials investigated were removed from the test section via different cleaning mechanisms, and the neural network models were able to predict the area and volume of fouling present during cleaning with accuracies as high as 98% and 97%, respectively. This work demonstrates that sensors and machine learning methods can be effectively combined to monitor cleaning processes.","ultrasonic sensors,optical sensors,machine learning,regression,artificial neural networks,Clean-in-Place,digital manufacturing,industry 4,0,process optimisation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"IN-PLACE,PROCESSES,WAVELET,TRANSFORM,SYSTEM,SPECTROSCOPY,DEPOSIT",SENSORS,https://nottingham-repository.worktribe.com/preview/4752147/Intelligent%20industrial%20cleaning%20-%20A%20multi-sensor%20approach%20utilising%20machine%20learning-based%20regression.pdf,
28,Feature Sensing and Robotic Grasping of Objects with Uncertain Information: A Review,20,13,,"Wang Chao,Zhang Xuehe,Zang Xizhe,Liu Yubin,Ding Guanwen,Yin Wenxin,Zhao Jie","Wang C,Zhang XH,Zang XZ,Liu YB,Ding GW,Yin WX,Zhao J",Liu YB,10.3390/s20133707,Harbin Institute of Technology,"As there come to be more applications of intelligent robots, their task object is becoming more varied. However, it is still a challenge for a robot to handle unfamiliar objects. We review the recent work on the feature sensing and robotic grasping of objects with uncertain information. In particular, we focus on how the robot perceives the features of an object, so as to reduce the uncertainty of objects, and how the robot completes object grasping through the learning-based approach when the traditional approach fails. The uncertain information is classified into geometric information and physical information. Based on the type of uncertain information, the object is further classified into three categories, which are geometric-uncertain objects, physical-uncertain objects, and unknown objects. Furthermore, the approaches to the feature sensing and robotic grasping of these objects are presented based on the varied characteristics of each type of object. Finally, we summarize the reviewed approaches for uncertain objects and provide some interesting issues to be more investigated in the future. It is found that the object's features, such as material and compactness, are difficult to be sensed, and the object grasping approach based on learning networks plays a more important role when the unknown degree of the task object increases.","uncertain objects,geometric uncertainty,physical uncertainty,feature sensing,robotic grasping",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"DEFORMABLE,PLANAR,OBJECTS,INDUSTRIAL,APPLICATIONS,INTELLIGENT,ROBOT,INSERTION,TASKS,CLOSURE,GRASPS,D-SPACE,RECOGNITION,VISION,MANIPULATION,FRAMEWORK",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7374444,
29,Coupling a Crystal Graph Multilayer Descriptor to Active Learning for Rapid Discovery of 2D Ferromagnetic Semiconductors/Half-Metals/Metals,32,29,,"Lu Shuaihua,Zhou Qionghua,Guo Yilv,Zhang Yehui,Wu Yilei,Wang Jinlan","Lu SH,Zhou QH,Guo YL,Zhang YH,Wu YL,Wang JL",Wang JL,10.1002/adma.202002658,Southeast University - China,"2D ferromagnetic (FM) semiconductors/half-metals/metals are the key materials toward next-generation spintronic devices. However, such materials are still rather rare and the material search space is too large to explore exhaustively. Here, an adaptive framework to accelerate the discovery of 2D intrinsic FM materials is developed, by combining advanced machine-learning (ML) techniques with high-throughput density functional theory calculations. Successfully, about 90 intrinsic FM materials with desirable bandgap and excellent thermodynamic stability are screened out and a database containing 1459 2D magnetic materials is set up. To improve the performance of ML models on small-scale datasets like diverse 2D materials, a crystal graph multilayer descriptor using the elemental property is proposed, with which ML models achieve prediction accuracy over 90% on thermodynamic stability, magnetism, and bandgap. This study not only provides dozens of compelling FM candidates for future spintronics, but also paves a feasible route for ML-based rapid screening of diverse structures and/or complex properties.","first-principle methods,machine learning,2D ferromagnetic materials",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,30.254,"ELECTROCATALYSTS,APPROXIMATION,MAGNETISM,DESIGN",ADVANCED MATERIALS,,
30,Polyp Segmentation with Fully Convolutional Deep Neural Networks-Extended Evaluation Study,6,7,,"Guo Yunbo,Bernal Jorge,Matuszewski Bogdan J.","Guo YB,Bernal J,Matuszewski BJ",Guo YB,10.3390/jimaging6070069,University of Central Lancashire,"Analysis of colonoscopy images plays a significant role in early detection of colorectal cancer. Automated tissue segmentation can be useful for two of the most relevant clinical target applications-lesion detection and classification, thereby providing important means to make both processes more accurate and robust. To automate video colonoscopy analysis, computer vision and machine learning methods have been utilized and shown to enhance polyp detectability and segmentation objectivity. This paper describes a polyp segmentation algorithm, developed based on fully convolutional network models, that was originally developed for the Endoscopic Vision Gastrointestinal Image Analysis (GIANA) polyp segmentation challenges. The key contribution of the paper is an extended evaluation of the proposed architecture, by comparing it against established image segmentation benchmarks utilizing several metrics with cross-validation on the GIANA training dataset. Different experiments are described, including examination of various network configurations, values of design parameters, data augmentation approaches, and polyp characteristics. The reported results demonstrate the significance of the data augmentation, and careful selection of the method's design parameters. The proposed method delivers state-of-the-art results with near real-time performance. The described solution was instrumental in securing the top spot for the polyp segmentation sub-challenge at the 2017 GIANA challenge and second place for the standard image resolution segmentation task at the 2018 GIANA challenge.","fully convolutional dilation neural networks,polyp segmentation,data augmentation,cross-validation,ablation tests",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Imaging Science & Photographic Technology,,,,JOURNAL OF IMAGING,https://res.mdpi.com/d_attachment/jimaging/jimaging-06-00069/article_deploy/jimaging-06-00069.pdf,
31,Revealing the Formation Energy-Exfoliation Energy-Structure Correlation of MAB Phases Using Machine Learning and DFT,12,26,29424-29431,"Siriwardane Edirisuriya M. D.,Joshi Rajendra P.,Kumar Neeraj,Cakir Deniz","Siriwardane EMD,Joshi RP,Kumar N,Cakir D",Kumar N,10.1021/acsami.0c03536,United States Department of Energy (DOE),"MAB phases became popular as ultrahigh-temperature materials with high damage tolerance and excellent electrical conductivity. MAB is used to exfoliate two-dimensional (2D) transition-metal borides (MBenes), which are promising materials for developing next-generation nanodevices. In this report, we explore the correlation between the formation energy, exfoliation energy, and structural factors of MAB phases with orthorhombic and hexagonal crystal symmetries using density functional theory (DFT) and machine learning. For this, we developed three different machine learning models based on the support vector machine, deep neural network, and random forest regressor to study the stability of the MAB phases by calculating their formation energies. Our support vector machine and deep neural network models are capable of predicting the formation energies with mean absolute errors less than 0.1 eV/atom. MAB phases with the chemical formulas, MAB, M(2)AB(2), and M(3)AB(4), where M = Nb, Mn, Ti, W, V, Sc, Cr, Hf, Mo, Zr, Ta, and Fe, and A = group III-A elements (Al, Ga, In and Tl), were investigated to find out the formation energy and their structure correlation. We demonstrated that the stability of a MAB phase for a given transition-metal decreases when the A element changes from Al to Tl. DFT revealed that M-A and B-A bond strength strongly correlates with the stability of MAB phases. In addition, the exfoliation possibility of 2D MBenes becomes higher when the A element changes from Al to Tl because of weakening of M-A and B-A bonds.","MAB phases,MBenes,formation energy,machine learning,exfoliation energy",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science",,9.57,"INITIO,MOLECULAR-DYNAMICS,TRANSITION-METAL,BORIDES,1ST-PRINCIPLES,CALCULATIONS,SUPERHARD,N%3D1",ACS APPLIED MATERIALS & INTERFACES,https://www.osti.gov/biblio/1644766,
32,Automatic Machine Learning to Differentiate Pediatric Posterior Fossa Tumors on Routine MR Imaging,41,7,1279-1285,"Zhou H.,Hu R.,Tang O.,Hu C.,Tang L.,Chang K.,Shen Q.,Wu J.,Zou B.,Xiao B.","Zhou H,Hu R,Tang O,Hu C,Tang L,Chang K,Shen Q,Wu J,Zou B,Xiao B",Zhu C,10.3174/ajnr.A6621,Central South University,"This retrospective study included preoperative MR imaging of 288 pediatric patients with pediatric posterior fossa tumors, including medulloblastoma (n=111), ependymoma (n=70), and pilocytic astrocytoma (n=107). Radiomics features were extracted from T2-weighted images, contrast-enhanced T1-weighted images, and ADC maps. Models generated by standard manual optimization by a machine learning expert were compared with automatic machine learning via the Tree-Based Pipeline Optimization Tool for performance evaluation. The authors conclude that automatic machine learning based on routine MR imaging classified pediatric posterior fossa tumors with high accuracy compared with manual expert pipeline optimization and qualitative expert MR imaging review.
BACKGROUND AND PURPOSE: Differentiating the types of pediatric posterior fossa tumors on routine imaging may help in preoperative evaluation and guide surgical resection planning. However, qualitative radiologic MR imaging review has limited performance. This study aimed to compare different machine learning approaches to classify pediatric posterior fossa tumors on routine MR imaging.
MATERIALS AND METHODS: This retrospective study included preoperative MR imaging of 288 patients with pediatric posterior fossa tumors, including medulloblastoma (n=111), ependymoma (n=70), and pilocytic astrocytoma (n=107). Radiomics features were extracted from T2-weighted images, contrast-enhanced T1-weighted images, and ADC maps. Models generated by standard manual optimization by a machine learning expert were compared with automatic machine learning via the Tree-Based Pipeline Optimization Tool for performance evaluation.
RESULTS: For 3-way classification, the radiomics model by automatic machine learning with the Tree-Based Pipeline Optimization Tool achieved a test micro-averaged area under the curve of 0.91 with an accuracy of 0.83, while the most optimized model based on the feature-selection method chi(2) score and the Generalized Linear Model classifier achieved a test micro-averaged area under the curve of 0.92 with an accuracy of 0.74. Tree-Based Pipeline Optimization Tool models achieved significantly higher accuracy than average qualitative expert MR imaging review (0.83 versus 0.54, P<.001). For binary classification, Tree-Based Pipeline Optimization Tool models achieved an area under the curve of 0.94 with an accuracy of 0.85 for medulloblastoma versus nonmedulloblastoma, an area under the curve of 0.84 with an accuracy of 0.80 for ependymoma versus nonependymoma, and an area under the curve of 0.94 with an accuracy of 0.88 for pilocytic astrocytoma versus non-pilocytic astrocytoma.
CONCLUSIONS: Automatic machine learning based on routine MR imaging classified pediatric posterior fossa tumors with high accuracy compared with manual expert pipeline optimization and qualitative expert MR imaging review.","APPARENT DIFFUSION-COEFFICIENT,CEREBELLAR TUMORS,DIAGNOSIS,CLASSIFICATION,RATIOS",Article,"AMER SOC NEURORADIOLOGY, PO BOX 3000, DENVILLE, NJ 07834-9349 USA","Neurosciences & Neurology,Radiology, Nuclear Medicine & Medical Imaging",,4.457,"APPARENT,DIFFUSION-COEFFICIENT,CEREBELLAR,TUMORS,DIAGNOSIS,CLASSIFICATION,RATIOS",AMERICAN JOURNAL OF NEURORADIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7357647,
33,A functional source separation algorithm to enhance error-related potentials monitoring in noninvasive brain-computer interface,191,,,"Ferracuti Francesco,Casadei Valentina,Marcantoni Ilaria,Iarlori Sabrina,Burattini Laura,Monteriu Andrea,Porcaro Camillo","Ferracuti F,Casadei V,Marcantoni I,Iarlori S,Burattini L,Monteriu A,Porcaro C",Porcaro C,10.1016/j.cmpb.2020.105419,"Via Palestro 32, I-00185 Rome, Italy.","Background and objectives: An Error related Potential (ErrP) can be noninvasively and directly measured from the scalp through electroencephalography (EEG), as response, when a person realizes they are mak-ing an error during a task (as a consequence of a cognitive error performed from the user). It has been shown that ErrPs can be automatically detected with time-discrete feedback tasks, which are widely ap-plied in the Brain-Computer Interface (BCI) field for error correction or adaptation. In this work, a semi-supervised algorithm, namely the Functional Source Separation (FSS), is proposed to estimate a spatial filter for learning the ErrPs and to enhance the evoked potentials.
Methods: EEG data recorded on six subjects were used to evaluate the proposed method based on FFS al-gorithm in comparison with the xDAWN algorithm. FSS-and xDAWN-based methods were compared also to the Cz and FCz single channel. Single-trial classification was considered to evaluate the performances of the approaches. (Both the approaches were evaluated on single-trial classification of EEGs.)
Results: The results presented using the Bayesian Linear Discriminant Analysis (BLDA) classifier, show that FSS (accuracy 0.92, sensitivity 0.95, specificity 0.81, F1-score 0.95) overcomes the other methods (Cz-accuracy 0.72, sensitivity 0.74, specificity 0.63, F1-score 0.74; FCz-accuracy 0.72, sensitivity 0.75, specificity 0.61, F1-score 0.75; xDAWN-accuracy 0.75, sensitivity 0.79, specificity 0.61, F1-score 0.79) in terms of single-trial classification.
Conclusions: The proposed FSS-based method increases the single-trial detection accuracy of ErrPs with respect to both single channel (Cz, FCz) and xDAWN spatial filter. (C) 2020 Elsevier B.V. All rights reserved.","Brain computer interface (BCI),Electroencephalography (EEG),Error-related potential (ErrP),Functional source separation (FSS),P300, Spatial filter",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"INDEPENDENT,COMPONENT,ANALYSIS,EEG,OPTIMIZATION,IMPROVES,P300",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,https://research.birmingham.ac.uk/portal/files/95086948/1_s2.0_S0169260719316359_main.pdf,
34,AI in Medical Imaging Informatics: Current Challenges and Future Directions,24,7,1837-1857,"Panayides Andreas S.,Amini Amir,Filipovic Nenad,Sharma Ashish,Tsaftaris Sotirios A.,Young Alistair,Foran David J.,Nhan Do,Golemati Spyretta,Kurc Tahsin","Panayides AS,Amini A,Filipovic N,Sharma A,Tsaftaris SA,Young A,Foran DJ,Do N,Golemati S,Kurc T",Panayides AS,10.1109/JBHI.2020.2991043,University of Cyprus,"This paper reviews state-of-the-art research solutions across the spectrum of medical imaging informatics, discusses clinical translation, and provides future directions for advancing clinical practice. More specifically, it summarizes advances in medical imaging acquisition technologies for different modalities, highlighting the necessity for efficient medical data management strategies in the context of AI in big healthcare data analytics. It then provides a synopsis of contemporary and emerging algorithmic methods for disease classification and organ/ tissue segmentation, focusing on AI and deep learning architectures that have already become the de facto approach. The clinical benefits of in-silico modelling advances linked with evolving 3D reconstruction and visualization applications are further documented. Concluding, integrative analytics approaches driven by associate research branches highlighted in this study promise to revolutionize imaging informatics as known today across the healthcare continuum for both radiology and digital pathology applications. The latter, is projected to enable informed, more accurate diagnosis, timely prognosis, and effective treatment planning, underpinning precision medicine.","Biomedical imaging,X-ray imaging,Magnetic resonance imaging,Computed tomography,Informatics,Three-dimensional displays,Medical Imaging,Image Analysis,Image Classification,Image Processing,Image Segmentation,Image Visualization,Integrative Analytics,Machine Learning,Deep Learning,Big Data",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"MAGNETIC-RESONANCE,ELASTOGRAPHY,CONVOLUTIONAL,NEURAL-NETWORKS,BREAST-CANCER,TISSUE,MICROARRAY,SOFTWARE,SYSTEM,DIGITAL,TWINS,SEGMENTATION,CLASSIFICATION,RADIOMICS,IMAGES",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://zenodo.org/record/4580396/files/AI%20in%20Medical%20Imaging%20Informatics.pdf,
35,Detecting Suspected Pump Thrombosis in Left Ventricular Assist Devices via Acoustic Analysis,24,7,1899-1906,"Semiz Beren,Hersek Sinan,Pouyan Maziyar Baran,Partida Cynthia,Blazquez-Arroyo Leticia,Selby Van,Wieselthaler Georg,Rehg James M.,Klein Liviu,Inan Omer T.","Semiz B,Hersek S,Pouyan MB,Partida C,Blazquez-Arroyo L,Selby V,Wieselthaler G,Rehg JM,Klein L,Inan OT",Semiz B,10.1109/JBHI.2020.2966178,University System of Georgia,"Objective: Left ventricular assist devices (LVADs) fail in up to 10% of patients due to the development of pump thrombosis. Remote monitoring of patients with LVADs can enable early detection and, subsequently, treatment and prevention of pump thrombosis. We assessed whether acoustical signals measured on the chest of patients with LVADs, combined with machine learning algorithms, can be used for detecting pump thrombosis. Methods: 13 centrifugal pump (HVAD) recipients were enrolled in the study. When hospitalized for suspected pump thrombosis, clinical data and acoustical recordings were obtained at admission, prior to and after administration of thrombolytic therapy, and every 24 hours until laboratory and pump parameters normalized. First, we selected the most important features among our feature set using LDH-based correlation analysis. Then using these features, we trained a logistic regression model and determined our decision threshold to differentiate between thrombosis and non-thrombosis episodes. Results: Accuracy, sensitivity and precision were calculated to be 88.9%, 90.9% and 83.3%, respectively. When tested on the post-thrombolysis data, our algorithm suggested possible pump abnormalities that were not identified by the reference pump power or biomarker abnormalities. Significance: We showed that the acoustical signatures of LVADs can be an index of mechanical deterioration and, when combined with machine learning algorithms, provide clinical decision support regarding the presence of pump thrombosis.","Thrombosis,Feature extraction,Harmonic analysis,Pumps,Blood,Acoustics,Correlation,Left ventricular assist device,pump thrombosis,heart failure,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"LACTATE-DEHYDROGENASE,IMPLANTATION,CLASSIFICATION,READMISSIONS,TRANSPLANT,SELECTION,BRIDGE",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7380556,
36,Lesion Location Attention Guided Network for Multi-Label Thoracic Disease Classification in Chest X-Rays,24,7,2016-2027,"Chen Bingzhi,Li Jinxing,Lu Guangming,Zhang David","Chen BZ,Li JX,Lu GM,Zhang D",Lu GM,10.1109/JBHI.2019.2952597,Harbin Institute of Technology,"Traditional clinical experiences have shown the benefit of lesion location attention for improving clinical diagnosis tasks. Inspired by this point of interest, in this paper we propose a novel lesion location attention guided network named LLAGnet to focus on the discriminative features from lesion locations for multi-label thoracic disease classification in chest X-rays (CXRs). By revealing the equivalence of the region-level attention (RLA) and channel-level attention (CLA), we find that the RLA is available as priors for object localization while the CLA implicitly provides high weights to the attractive channels, which both enable lesion location attention excitation. To integrate the advantages from both mechanisms, the proposed LLAGnet is structured with two corresponding attention modules, i.e., the RLA and CLA modules. Specifically, the RLA module consists of the global and local branches. And the weakly supervised attention mechanism embedded in the global branch can obtain visual regions of lesion locations by back-propagating gradients. Then the optimal attention region is amplified and applied to the local branch to provide more fine-grained features for the image classification. Finally, the CLA module adaptively enhances the weights of channel-wise features from the lesion locations by modeling interdependencies among channels. Extensive experiments on the ChestX-ray14 dataset clearly substantiate the effectiveness of LLAGnet as compared with the state-of-the-art baselines.","Diseases,Lesions,Task analysis,Image analysis,Feature extraction,Learning systems,Pathology,Lesion location,attention guided,region-level attention,channel-level attention",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
37,Pulmonary Textures Classification via a Multi-Scale Attention Network,24,7,2041-2052,"Xu Rui,Cong Zhen,Ye Xinchen,Hirano Yasushi,Kido Shoji,Gyobu Tomoko,Kawata Yutaka,Honda Osamu,Tomiyama Noriyuki","Xu R,Cong Z,Ye XC,Hirano Y,Kido S,Gyobu T,Kawata Y,Honda O,Tomiyama N",Ye XC,10.1109/JBHI.2019.2950006,Dalian University of Technology,"Precise classification of pulmonary textures is crucial to develop a computer aided diagnosis (CAD) system of diffuse lung diseases (DLDs). Although deep learning techniques have been applied to this task, the classification performance is not satisfied for clinical requirements, since commonly-used deep networks built by stacking convolutional blocks are not able to learn discriminative feature representation to distinguish complex pulmonary textures. For addressing this problem, we design a multi-scale attention network (MSAN) architecture comprised by several stacked residual attention modules followed by a multi-scale fusion module. Our deep network can not only exploit powerful information on different scales but also automatically select optimal features for more discriminative feature representation. Besides, we develop visualization techniques to make the proposed deep model transparent for humans. The proposed method is evaluated by using a large dataset. Experimental results show that our method has achieved the average classification accuracy of 94.78% and the average f-value of 0.9475 in the classification of 7 categories of pulmonary textures. Besides, visualization results intuitively explain the working behavior of the deep network. The proposed method has achieved the state-of-the-art performance to classify pulmonary textures on high resolution CT images.","Network architecture,Lung,Deep learning,Visualization,Task analysis,Solid modeling,Computed tomography,Attention,computer-aided diagnosis,deep network,diffuse lung diseases,multi-scale,network visualization,pulmonary textures classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"CONVOLUTIONAL,NEURAL-NETWORKS,DIFFUSE,LUNG-DISEASE,CT,EMPHYSEMA,PATTERNS,BAG",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
38,Machine Listening for Heart Status Monitoring: Introducing and Benchmarking HSS-The Heart Sounds Shenzhen Corpus,24,7,2082-2092,"Dong Fengquan,Qian Kun,Ren Zhao,Baird Alice,Li Xinjian,Dai Zhenyu,Dong Bo,Metze Florian,Yamamoto Yoshiharu,Schuller Bjoern W.","Dong FQ,Qian K,Ren Z,Baird A,Li XJ,Dai ZY,Dong B,Metze F,Yamamoto Y,Schuller BW",Qian K,10.1109/JBHI.2019.2955281,University of Tokyo,"Auscultation of the heart is a widely studied technique, which requires precise hearing from practitioners as a means of distinguishing subtle differences in heart-beat rhythm. This technique is popular due to its non-invasive nature, and can be an early diagnosis aid for a range of cardiac conditions. Machine listening approaches can support this process, monitoring continuously and allowing for a representation of both mild and chronic heart conditions. Despite this potential, relevant databases and benchmark studies are scarce. In this paper, we introduce our publicly accessible database, the Heart Sounds Shenzhen Corpus (HSS), which was first released during the recent INTERSPEECH 2018 ComParE Heart Sound sub-challenge. Additionally, we provide a survey of machine learning work in the area of heart sound recognition, as well as a benchmark for HSS utilising standard acoustic features and machine learning models. At best our support vector machine with Log Mel features achieves 49.7% unweighted average recall on a three category task (normal, mild, moderate/severe).","Heart,Phonocardiography,Feature extraction,Databases,Valves,Hidden Markov models,Support vector machines,Heart sound,cardiovascular disease,machine listening,artificial intelligence,healthcare",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"ARTIFICIAL,NEURAL-NETWORK,SELF-ASSESSED,AFFECT,FEATURE-EXTRACTION,WAVELET,TRANSFORM,TIME-FREQUENCY,CLASSIFICATION,SEGMENTATION,DIAGNOSIS,FEATURES,IDENTIFICATION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
39,Dependent-Gaussian-Process-Based Learning of Joint Torques Using Wearable Smart Shoes for Exoskeleton,20,13,,"Yang Jiantao,Yin Yuehong","Yang JT,Yin YH",Yin YH,10.3390/s20133685,Shanghai Jiao Tong University,"Estimating the joint torques of lower limbs in human gait is a highly challenging task and of great significance in developing high-level controllers for lower-limb exoskeletons. This paper presents a dependent Gaussian process (DGP)-based learning algorithm for joint-torque estimations with measurements from wearable smart shoes. The DGP was established to perform data fusion, and serves as the mathematical foundation to explore the correlations between joint kinematics and joint torques that are embedded deeply in the data. As joint kinematics are used in the training phase rather than the prediction process, the DGP model can realize accurate predictions in outdoor activities by using only the smart shoe, which is low-cost, nonintrusive for human gait, and comfortable to wearers. The design methodology of dynamic specific kernel functions is presented in accordance to prior knowledge of the measured signals. The designed composite kernel functions can be used to model multiple features at different scales, and cope with the temporal evolution of human gait. The statistical nature of the proposed DGP model and the composite kernel functions offer superior flexibility for time-varying gait-pattern learning, and enable accurate joint-torque estimations. Experiments were conducted with five subjects, whose results showed that it is possible to estimate joint torques under different trained and untrained speed levels. Comparisons were made between the proposed DGP and Gaussian process (GP) models. Obvious improvements were achieved when all DGPr(2)values were higher than those of GP.","dependent Gaussian process (DGP),composite kernel function,human gait,joint-torque learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"SYSTEM,PHASE,ANKLE,PROSTHESIS",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7374419,
40,An Efficient and Robust Deep Learning Method with 1-D Octave Convolution to Extract Fetal Electrocardiogram,20,13,,"Vo Khuong,Le Tai,Rahmani Amir M.,Dutt Nikil,Cao Hung","Vo K,Le T,Rahmani AM,Dutt N,Cao H",Dutt N,10.3390/s20133757,University of California System,"The invasive method of fetal electrocardiogram (fECG) monitoring is widely used with electrodes directly attached to the fetal scalp. There are potential risks such as infection and, thus, it is usually carried out during labor in rare cases. Recent advances in electronics and technologies have enabled fECG monitoring from the early stages of pregnancy through fECG extraction from the combined fetal/maternal ECG (f/mECG) signal recorded non-invasively in the abdominal area of the mother. However, cumbersome algorithms that require the reference maternal ECG as well as heavy feature crafting makes out-of-clinics fECG monitoring in daily life not yet feasible. To address these challenges, we proposed a pure end-to-end deep learning model to detect fetal QRS complexes (i.e., the main spikes observed on a fetal ECG waveform). Additionally, the model has the residual network (ResNet) architecture that adopts the novel 1-D octave convolution (OctConv) for learning multiple temporal frequency features, which in turn reduce memory and computational cost. Importantly, the model is capable of highlighting the contribution of regions that are more prominent for the detection. To evaluate our approach, data from the PhysioNet 2013 Challenge with labeled QRS complex annotations were used in the original form, and the data were then modified with Gaussian and motion noise, mimicking real-world scenarios. The model can achieve a F(1)score of 91.1% while being able to save more than 50% computing cost with less than 2% performance degradation, demonstrating the effectiveness of our method.","non-invasive fetal electrocardiogram,QRS complexes,deep learning,neural networks,octave convolution",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"SEPARATION,ECG",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7374297,
41,Polymer genome-based prediction of gas permeabilities in polymers,40,6,451-457,"Zhu Guanghui,Kim Chiho,Chandrasekarn Anand,Everett Joshua D.,Ramprasad Rampi,Lively Ryan R.","Zhu GH,Kim C,Chandrasekarn A,Everett JD,Ramprasad R,Lively RR",Ramprasad R,10.1515/polyeng-2019-0329,University System of Georgia,"Predicting gas permeabilities of polymers a priori is a long-standing challenge within the membrane research community that has important applications for membrane process design and ultimately widespread adoption of membrane technology. From early attempts based on free volume and cohesive energy to more recent group contribution methods, the ability to predict membrane permeability has improved in terms of accuracy. However, these models usually stay ""within the paper"", i.e. limited model details are provided to the wider community such that adoption of these predictive platforms is limited. In this work, we combined an advanced polymer chemical structure fingerprinting method with a large experimental database of gas permeabilities to provide unprecedented prediction precision over a large range of polymer classes. No prior knowledge of the polymer is needed for the prediction other than the repeating unit chemical formula. In addition, we have incorporated this model into the existing Polymer Genome project to make it open to the membrane research community.","gas separation,machine learning,membrane",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY",Polymer Science,,1.433,"HOLLOW-FIBER,MEMBRANES,NEURAL-NETWORKS,FLUE-GAS,SEPARATIONS",JOURNAL OF POLYMER ENGINEERING,https://www.degruyter.com/downloadpdf/journals/polyeng/40/6/article-p451.pdf,
42,Photorealistic Material Editing Through Direct Image Manipulation,39,4,107-120,"Zsolnai-Feher Karoly,Wonka Peter,Wimmer Michael","Zsolnai-Feher K,Wonka P,Wimmer M",Zsolnai-Feher K,10.1111/cgf.14057,Technische Universitat Wien,"Creating photorealistic materials for light transport algorithms requires carefully fine-tuning a set of material properties to achieve a desired artistic effect. This is typically a lengthy process that involves a trained artist with specialized knowledge. In this work, we present a technique that aims to empower novice and intermediate-level users to synthesize high-quality photorealistic materials by only requiring basic image processing knowledge. In the proposed workflow, the user starts with an input image and applies a few intuitive transforms (e.g., colorization, image inpainting) within a 2D image editor of their choice, and in the next step, our technique produces a photorealistic result that approximates this target image. Our method combines the advantages of a neural network-augmented optimizer and an encoder neural network to produce high-quality output results within 30 seconds. We also demonstrate that it is resilient against poorly-edited target images and propose a simple extension to predict image sequences with a strict time budget of 1-2 seconds per image.","NEURAL-NETWORKS,APPEARANCE",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Computer Science,,2.459,"NEURAL-NETWORKS,APPEARANCE",COMPUTER GRAPHICS FORUM,http://arxiv.org/pdf/1909.11622,
43,Conventional vs machine learning-based treatment planning in prostate brachytherapy: Results of a Phase I randomized controlled trial,19,4,470-476,"Nicolae Alexandru,Semple Mark,Lu Lin,Smith Mackenzie,Chung Hans,Loblaw Andrew,Morton Gerard,Mendez Lucas Castro,Tseng Chia-Lin,Davidson Melanie","Nicolae A,Semple M,Lu L,Smith M,Chung H,Loblaw A,Morton G,Mendez LC,Tseng CL,Davidson M",Ravi A,10.1016/j.brachy.2020.03.004,University of Toronto,"PURPOSE: The purpose of this study was to evaluate the noninferiority of Day 30 dosimetry between a machine learning-based treatment planning system for prostate low-dose-rate (LDR) brachytherapy and the conventional, manual planning technique. As a secondary objective, the impact of planning technique on clinical workflow efficiency was also evaluated.
MATERIALS AND METHODS: 41 consecutive patients who underwent I-125 LDR monotherapy for low- and intermediate-risk prostate cancer were accrued into this single-institution study between 2017 and 2018. Patients were 1:1 randomized to receive treatment planning using a machine learning-based prostate implant planning algorithm (PIPA system) or conventional, manual technique. Treatment plan modifications by the radiation oncologist were evaluated by computing the Dice coefficient of the prostate V-150% isodose volume between either the PIPA-or conventional-and final approved plans. Additional evaluations between groups evaluated the total planning time and dosimetric outcomes at preimplant and Day 30.
RESULTS: 21 and 20 patients were treated using the PIPA and conventional techniques, respectively. No significant differences were observed in preimplant or Day 30 prostate D-90%, V-100%, rectum V-100, or rectum D-1cc between PIPA and conventional techniques. Although the PIPA group had a larger proportion of patients with plans requiring no modifications (Dice = 1.00), there was no significant difference between the magnitude of modifications between each arm. There was a large significant advantage in mean planning time for the PIPA arm (2.38 +/- 0.96 min) compared with the conventional (43.13 +/- 58.70 min) technique (p >> 0.05).
CONCLUSIONS: A machine learning-based planning workflow for prostate LDR brachytherapy has the potential to offer significant time savings and operational efficiencies, while producing noninferior postoperative dosimetry to that of expert, conventional treatment planners. (C) 2020 The Authors. Published by Elsevier Inc. on behalf of American Brachytherapy Society.","Machine learning,Brachytherapy,Treatment planning,Dosimetry,Low-dose rate",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,2.24,"INTERMEDIATE,IMPLANTS",BRACHYTHERAPY,http://www.brachyjournal.com/article/S1538472120300490/pdf,
44,LineSpyX: A Power Line Inspection Robot Based on Digital Radiography,5,3,4759-4765,"Gao Yuan,Song Guangming,Li Songtao,Zhen Fushuai,Chen Dabing,Song Aiguo","Gao Y,Song GM,Li ST,Zhen FS,Chen DB,Song AG",Song GM,10.1109/LRA.2020.3003772,Southeast University - China,"Most of the current power line inspection robots use cameras and LiDARs to inspect the power line surfaces and the surrounding environment. But it is still difficult to detect the internal defects of the power lines. In this letter, the design and implementation of LineSpyX, a novel power line inspection robot based on digital radiography (DR), is introduced to solve the problem of non-destructive testing (NDT) of the overhead Aluminum Conductor Composite Core (ACCC) wires. The proposed robot has a stable wrapped mechanical structure with a moving system, a live work system, and a NDT system. The wheeled moving system enables the robot to move on the wires and cross obstacles such as vibration dampers. The NDT system consists of a portable X-ray generator and a DR detection panel. When the robot performs the inspection task, the X-ray goes up through the ACCC wire to the panel, where the X-ray images of the internal carbon fiber cores are recorded. A deep learning based defect diagnosis method combined with manual diagnosis is proposed to detect potential defects. The main functionalities of the developed robot are verified by lab experiments and field tests.","Deep learning based defect diagnosis,development and prototyping,digital radiography (DR),industrial robots,product design,power line inspection robot",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,DESIGN,IEEE ROBOTICS AND AUTOMATION LETTERS,,
45,Automatic Polyp Recognition in Colonoscopy Images Using Deep Learning and Two-Stage Pyramidal Feature Prediction,17,3,1570-1584,"Jia Xiao,Mai Xiaochun,Cui Yi,Yuan Yixuan,Xing Xiaohan,Seo Hyunseok,Xing Lei,Meng Max Q. -H.","Jia X,Mai XC,Cui Y,Yuan YX,Xing XH,Seo H,Xing L,Meng MQH",Meng MQH,10.1109/TASE.2020.2964827,Chinese University of Hong Kong,"Polyp recognition in colonoscopy images is crucial for early colorectal cancer detection and treatment. However, the current manual review requires undivided concentration of the gastroenterologist and is prone to diagnostic errors. In this article, we present an effective, two-stage approach called PLPNet, where the abbreviation ""PLP"" stands for the word ""polyp,"" for automated pixel-accurate polyp recognition in colonoscopy images using very deep convolutional neural networks (CNNs). Compared to hand-engineered approaches and previous neural network architectures, our PLPNet model improves recognition accuracy by adding a polyp proposal stage that predicts the location box with polyp presence. Several schemes are proposed to ensure the model's performance. First of all, we construct a polyp proposal stage as an extension of the faster R-CNN, which performs as a region-level polyp detector to recognize the lesion area as a whole and constitutes stage I of PLPNet. Second, stage II of PLPNet is built in a fully convolutional fashion for pixelwise segmentation. We define a feature sharing strategy to transfer the learned semantics of polyp proposals to the segmentation task of stage II, which is proven to be highly capable of guiding the learning process and improve recognition accuracy. Additionally, we design skip schemes to enrich the feature scales and thus allow the model to generate detailed segmentation predictions. For accurate recognition, the advanced residual nets and feature pyramids are adopted to seek deeper and richer semantics at all network levels. Finally, we construct a two-stage framework for training and run our model convolutionally via a single-stream network at inference time to efficiently output the polyp mask. Experimental results on public data sets of GIANA Challenge demonstrate the accuracy gains of our approach, which surpasses previous state-of-the-art methods on the polyp segmentation task (74.7 Jaccard Index) and establishes new top results in the polyp localization challenge (81.7 recall). Note to Practitioners-Given the current manual review of colonoscopy is laborious and time-consuming, computational methods that can assist automatic polyp recognition will enhance the outcome both in terms of efficiency and diagnostic accuracy of colonoscopy. This article suggests a new approach using a very deep convolutional neural network (CNN) architecture for polyp recognition, which gains accuracy from deeper and richer representations. The method, called PLPNet, can effectively detect polyps in colonoscopy images and generate high-quality segmentation masks in a pixel-to-pixel manner. We evaluate the proposed framework on publicly available data sets, and we show by experiments that our method surpasses the state-of-the-art polyp recognition results. The finding of this article corroborates that CNNs with very deep architecture and richer semantics are highly efficient in medical image learning and inference. We believe that the proposed method will facilitate potential computer-aided applications in clinical practice, in that it can enhance medical decision-making in cancer detection and imaging.","Colonoscopy,Computer architecture,Proposals,Semantics,Image recognition,Task analysis,Image segmentation,Deep residual network (ResNet),feature pyramids,PLPNet,polyp recognition,two-stage framework",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Automation & Control Systems,,5.516,"VALIDATION,COLON",IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING,,
46,VINet: A Visually Interpretable Image Diagnosis Network,22,7,1720-1729,"Gu Donghao,Li Yaowei,Jiang Feng,Wen Zhaojing,Liu Shaohui,Shi Wuzhen,Lu Guangming,Zhou Changsheng","Gu DH,Li YW,Jiang F,Wen ZJ,Liu SH,Shi WZ,Lu GM,Zhou CS",Jiang F,10.1109/TMM.2020.2971170,Harbin Institute of Technology,"Recently, due to the black box characteristics of deep learning techniques, the deep network-based computer-aided diagnosis (CADx) systems have encountered many difficulties in practical applications. The crux of the problem is that these models should be explainable the model should give doctors rationales that can explain the diagnosis. In this paper, we propose a visually interpretable network (VINet) which can generate diagnostic visual interpretations while making accurate diagnoses. VINet is an end-to-end model consisting of an importance estimation network and a classification network. The former produces a diagnostic visual interpretation for each case, and the classifier diagnoses the case. In the classifier, by exploring the information in the diagnostic visual interpretation, the irrelevant information in the feature maps is eliminated by our proposed feature destruction process. This allows the classification network to concentrate on the important features and use them as the primary references for classification. Through a joint optimization of higher classification accuracy and eliminating as many irrelevant features as possible, a precise, fine-grained diagnostic visual interpretation, along with an accurate diagnosis, can be produced by our proposed network simultaneously. Based on a computed tomography image dataset (LUNA16) on pulmonary nodule, extensive experiments have been conducted, demonstrating that the proposed VINet can produce state-of-the-art diagnostic visual interpretations compared with all baseline methods.","Visualization,Medical services,Biomedical imaging,Estimation,Computational modeling,Solid modeling,Task analysis,Machine learning,neural network,image classification,medical diagnostic imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Telecommunications",,6.41,"PULMONARY,NODULES,CT,CLASSIFICATION",IEEE TRANSACTIONS ON MULTIMEDIA,,
47,Prediction of Static Modulus and Compressive Strength of Concrete from Dynamic Modulus Associated with Wave Velocity and Resonance Frequency Using Machine Learning Techniques,13,13,,"Park Jong Yil,Sim Sung-Han,Yoon Young Geun,Oh Tae Keun","Park JY,Sim SH,Yoon YG,Oh TK",Yoon YG; Oh TK,10.3390/ma13132886,Incheon National University,"The static elastic modulus (Ec) and compressive strength (fc) are critical properties of concrete. When determiningEcandfc, concrete cores are collected and subjected to destructive tests. However, destructive tests require certain test permissions and large sample sizes. Hence, it is preferable to predictEcusing the dynamic elastic modulus (Ed), through nondestructive evaluations. A resonance frequency test performed according to ASTM C215-14 and a pressure wave (P-wave) measurement conducted according to ASTM C597M-16 are typically used to determineEd. Recently, developments in transducers have enabled the measurement of a shear wave (S-wave) velocities in concrete. Although various equations have been proposed for estimatingEcandfcfromEd, their results deviate from experimental values. Thus, it is necessary to obtain a reliableEdvalue for accurately predictingEcandfc. In this study,Edvalues were experimentally obtained from P-wave and S-wave velocities in the longitudinal and transverse modes;Ecandfcvalues were predicted using theseEdvalues through four machine learning (ML) methods: support vector machine, artificial neural networks, ensembles, and linear regression. Using ML, the prediction accuracy ofEcandfcwas improved by 2.5-5% and 7-9%, respectively, compared with the accuracy obtained using classical or normal-regression equations. By combining ML methods, the accuracy of the predictedEcandfcwas improved by 0.5% and 1.5%, respectively, compared with the optimal single variable results.","concrete,static elastic modulus,dynamic elastic modulus,compressive strength,machine learning,P-wave,S-wave,resonance frequency test,nondestructive method",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,,"HIGH-PERFORMANCE,CONCRETE,ELASTIC-MODULUS,MODELS",MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7372401,
48,Toward Excellence of Transition Metal-Based Catalysts for CO(2)Electrochemical Reduction: An Overview of Strategies and Rationales,4,7,,"Li Mengran,Garg Sahil,Chang Xiaoxia,Ge Lei,Li Liye,Konarova Muxina,Rufford Thomas E.,Rudolph Victor,Wang Geoff","Li MR,Garg S,Chang XX,Ge L,Li LY,Konarova M,Rufford TE,Rudolph V,Wang G",Ge L; Rufford TE,10.1002/smtd.202000033,University of Queensland,"Rational modulations of interactions between the catalyst surface and intermediates are challenging but extremely important to achieve an efficient and selective electrochemical CO(2)reduction (CO2R). Current CO2R catalyst design remains inefficient because of a gap between existing practical design paradigms and theoretical studies in catalysis. This review attempts to mitigate this gap through a critical discussion of the correlations between recent strategies to develop transition metal-based catalysts and the underlying rationales and mechanisms. These strategies include surface engineering, the introduction of heterogeneous atoms, and dimension control, and can be implemented by tactics such as controlling catalyst surface facets, surface tethering, alloying, inducing strains, oxide derivation, molecular scaffolding, and nanostructuring. How these tactics are able to tailor the electronic structure, adsorption geometry, density of active sites, and local environment of catalyst to achieve an efficient and selective CO2R is described. This review concludes with a discussion of the key research needs in this field such as the surface proton formation and transfer involved in CO2R, the roles of mass-transfer or electrode kinetics in CO2R catalysis, development of robust, standardized catalyst testing protocols, and application of machine learning and high-throughput experiment to accelerate catalyst screening processes.","CO(2)electrochemical reduction,electrocatalysis,heterogeneous catalysts,transition metals",Review,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science",,14.367,"ELECTROCHEMICAL,CO2,REDUCTION,CARBON-DIOXIDE,REDUCTION,SINGLE-CRYSTAL,ELECTRODES,DEPENDENT,ELECTROCATALYTIC,REDUCTION,FORMIC-ACID,STABLE,ELECTROREDUCTION,MOLYBDENUM-DISULFIDE,MECHANISTIC,INSIGHTS,COPPER,NANOCRYSTALS,ORGANIC,FRAMEWORKS",SMALL METHODS,https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/smtd.202000033,
49,Hyperspectral Superpixel-Wise Glioblastoma Tumor Detection in Histological Samples,10,13,,"Ortega Samuel,Fabelo Himar,Halicek Martin,Camacho Rafael,Plaza Maria de la Luz,Callico Gustavo M.,Fei Baowei","Ortega S,Fabelo H,Halicek M,Camacho R,Plaza MD,Callico GM,Fei BW",Ortega S,10.3390/app10134448,Universidad de Las Palmas de Gran Canaria,"The combination of hyperspectral imaging (HSI) and digital pathology may yield more accurate diagnosis. In this work, we propose the use of superpixels in HS images for combining regions of pixels that can be classified according to their spectral information to classify glioblastoma (GB) brain tumors in histologic slides. The superpixels are generated by a modified simple linear iterative clustering (SLIC) method to accommodate HS images. This work employs a dataset of H&E (Hematoxylin and Eosin) stained histology slides from 13 patients with GB and over 426,000 superpixels. A linear support vector machine (SVM) classifier was performed on independent training, validation, and testing datasets. The results of this investigation show that the proposed method can detect GB brain tumors from non-tumor samples with average sensitivity and specificity of 87% and 81%, respectively. The overall accuracy of this method is 83%. The study demonstrates that hyperspectral digital pathology can be useful for detecting GB brain tumors by exploiting spectral information alone on a superpixel level.","hyperspectral imaging,optics diagnosis,digital pathology,superpixel,machine learning,tissue diagnostics,tissue characterization,glioblastoma (GB)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,CLASSIFICATION,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/13/4448/pdf,
50,Simulation Study of Low-Dose Sparse-Sampling CT with Deep Learning-Based Reconstruction: Usefulness for Evaluation of Ovarian Cancer Metastasis,10,13,,"Urase Yasuyo,Nishio Mizuho,Ueno Yoshiko,Kono Atsushi K.,Sofue Keitaro,Kanda Tomonori,Maeda Takaki,Nogami Munenobu,Hori Masatoshi,Murakami Takamichi","Urase Y,Nishio M,Ueno Y,Kono AK,Sofue K,Kanda T,Maeda T,Nogami M,Hori M,Murakami T",Nishio M,10.3390/app10134446,Kobe University,"The usefulness of sparse-sampling CT with deep learning-based reconstruction for detection of metastasis of malignant ovarian tumors was evaluated. We obtained contrast-enhanced CT images (n= 141) of ovarian cancers from a public database, whose images were randomly divided into 71 training, 20 validation, and 50 test cases. Sparse-sampling CT images were calculated slice-by-slice by software simulation. Two deep-learning models for deep learning-based reconstruction were evaluated: Residual Encoder-Decoder Convolutional Neural Network (RED-CNN) and deeper U-net. For 50 test cases, we evaluated the peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) as quantitative measures. Two radiologists independently performed a qualitative evaluation for the following points: entire CT image quality; visibility of the iliac artery; and visibility of peritoneal dissemination, liver metastasis, and lymph node metastasis. Wilcoxon signed-rank test and McNemar test were used to compare image quality and metastasis detectability between the two models, respectively. The mean PSNR and SSIM performed better with deeper U-net over RED-CNN. For all items of the visual evaluation, deeper U-net scored significantly better than RED-CNN. The metastasis detectability with deeper U-net was more than 95%. Sparse-sampling CT with deep learning-based reconstruction proved useful in detecting metastasis of malignant ovarian tumors and might contribute to reducing overall CT-radiation exposure.","deep learning,neoplasm metastasis,ovarian neoplasms,radiation exposure,tomography,x-ray computed",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"CONVOLUTIONAL,NEURAL-NETWORK,PLATFORM",APPLIED SCIENCES-BASEL,http://www.lib.kobe-u.ac.jp/repository/90007337.pdf,
51,Using Deep Learning to Predict Fracture Patterns in Crystalline Solids,3,1,197-211,"Hsu Yu-Chuan,Yu Chi-Hua,Buehler Markus J.","Hsu YC,Yu CH,Buehler MJ",Buehler MJ,10.1016/j.matt.2020.04.019,Massachusetts Institute of Technology (MIT),"Fracture is a catastrophic process whose understanding is critical for evaluating the integrity and sustainability of engineering materials. Here, we present a machine-learning approach to predict fracture processes connecting molecular simulation into a physics-based data-driven multiscale model. Based on atomistic modeling and a novel image-processing approach, we compile a comprehensive training dataset featuring fracture patterns and toughness values for different crystal orientations. Assessments of the predictive power of the machine-learning model shows excellent agreement not only regarding the computed fracture patterns but also the fracture toughness values and is examined for both mode I and mode II loading conditions. We further examine the ability of predicting fracture patterns in bicrystalline materials and material with gradients of microstructural crystal orientation. These results further underscore the excellent predictive power of our model. Potential applications of this model could be widely applied in material design.","STRUCTURE-PROPERTY LINKAGES,HIGH-CONTRAST COMPOSITES,LOCALIZATION LINKAGES,ELASTIC LOCALIZATION,CRACK-PROPAGATION,BRITTLE-FRACTURE,MACHINE,SIMULATION,DYNAMICS,EVOLUTION",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,15.589,"STRUCTURE-PROPERTY,LINKAGES,HIGH-CONTRAST,COMPOSITES,LOCALIZATION,LINKAGES,ELASTIC,LOCALIZATION,CRACK-PROPAGATION,BRITTLE-FRACTURE,MACHINE,SIMULATION,DYNAMICS,EVOLUTION",MATTER,http://www.cell.com/article/S2590238520301909/pdf,
52,Adaptive machine learning for efficient materials design,45,7,579-586,Balachandran Prasanna V.,Balachandran PV,Balachandran PV,10.1557/mrs.2020.163,University of Virginia,"Applying machine learning (ML) methods to accelerate the search for new materials with improved properties has gained increasing attention in recent years. Using nonadaptive ML approaches that do not have an iterative feedback loop can perform poorly in extrapolations at previously unexplored search space, especially when trained on small data sets. We performed numerical simulations on two data sets that exhibit distinct composition-property relationships and explored the relative efficacies of adaptive ML strategies in identifying the optimal material composition with the highest. Adaptive ML methods show promise for extrapolation and find compositions with properties better than those in the training data, but the rate of discovery is dictated by the nuances of the composition-property landscape. The outcome of this work has key implications in developing strategies that employ ML methods for navigating a vast search space of combinatorial possibilities.",PEROVSKITES,Article,"CAMBRIDGE UNIV PRESS, 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA","Materials Science,Physics",,5.471,PEROVSKITES,MRS BULLETIN,,
53,Metamodel-Based Seismic Fragility Analysis of Concrete Gravity Dams,146,7,,"Segura Rocio,Padgett Jamie E.,Paultre Patrick","Segura R,Padgett JE,Paultre P",Paultre P,10.1061/(ASCE)ST.1943-541X.0002629,University of Sherbrooke,"Probabilistic methods, such as fragility analysis, have been developed as a promising alternative for the seismic assessment of dam-type structures. However, given the costly reevaluation of the numerical model simulations, the effect of the model parameters likely to affect the seismic fragility of the system is frequently overlooked. Acknowledging the lack of the thorough exploration of different machine learning techniques to develop surrogates or metamodels that efficiently approximate the seismic response of dams, this study provides insight on viable metamodels for the seismic assessment of gravity dams for use in fragility analysis. The proposed methodology to generate multivariate fragility functions offers efficiency while accounting for the most critical model parameter variation influencing the dam seismic fragility. From the analysis of these models, practical design recommendations can be formulated. The procedure presented herein is applied to a case study dam in northeastern Canada, where the polynomial response surface of order 4 (PRS O-4) came up as the most viable meta-model among those considered. Its fragility is assessed through comparison with the current safety guidelines to establish a range of usable model parameter values in terms of the concrete-rock angle of friction, drain efficiency, and concrete-rock cohesion.","MULTI-HAZARD RISK,RELIABILITY-ANALYSIS,ENGINEERING DESIGN,HIGHWAY BRIDGES,SUPPORT,EARTHQUAKE",Article,"ASCE-AMER SOC CIVIL ENGINEERS, 1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA","Construction & Building Technology,Engineering",,3.82,"MULTI-HAZARD,RISK,RELIABILITY-ANALYSIS,ENGINEERING,DESIGN,HIGHWAY,BRIDGES,SUPPORT,EARTHQUAKE",JOURNAL OF STRUCTURAL ENGINEERING,https://ascelibrary.org/doi/pdf/10.1061/%28ASCE%29ST.1943-541X.0002629,
54,Deep learning frameworks for diabetic retinopathy detection with smartphone-based retinal imaging systems,135,,409-417,"Hacisoftaoglu Recep E.,Karakaya Mahmut,Sallam Ahmed B.","Hacisoftaoglu RE,Karakaya M,Sallam AB",Karakaya M,10.1016/j.patrec.2020.04.009,University of Central Arkansas,,VALIDATION,Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,3.615,VALIDATION,PATTERN RECOGNITION LETTERS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7377280,
55,Air-coupled ultrasound detection of natural defects in wood using ferroelectret and piezoelectric sensors,54,4,1051-1064,"Tiitta M.,Tiitta V,Gaal M.,Heikkinen J.,Lappalainen R.,Tomppo L.","Tiitta M,Tiitta V,Gaal M,Heikkinen J,Lappalainen R,Tomppo L",Tiitta M,10.1007/s00226-020-01189-y,University of Eastern Finland,"Air-coupled ultrasound was used for assessing natural defects in wood boards by through-transmission scanning measurements. Gas matrix piezoelectric (GMP) and ferroelectret (FE) transducers were studied. The study also included tests with additional bias voltage with the ferroelectret receivers. Signal analyses, analyses of the measurement dynamics and statistical analyses of the signal parameters were conducted. After the measurement series, the samples were cut from the measurement regions and the defects were analyzed visually from the cross sections. The ultrasound responses were compared with the results of the visual examination of the cross sections. With the additional bias voltage, the ferroelectret measurement showed increased signal-to-noise ratio, which is especially important for air-coupled measurement of high-attenuation materials like wood. When comparing the defect response of GMP and FE sensors, it was found that FE sensors had more sensitive dynamic range, resulting from betters/nratio and short response pulse. Classification test was made to test the possibility of detecting defects in sound wood. Machine learning methods including decision trees,k-nearest neighbor and support vector machine were used. The classification accuracy varied between 72 and 77% in the tests. All the tested machine learning methods could be used efficiently for the classification.","INTERNAL DECAY,NONCONTACT,MOISTURE",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Forestry,Materials Science",,2.81,"INTERNAL,DECAY,NONCONTACT,MOISTURE",WOOD SCIENCE AND TECHNOLOGY,https://link.springer.com/content/pdf/10.1007/s00226-020-01189-y.pdf,
56,"Intelligent Image Segmentation for Organic-Rich Shales Using Random Forest, Wavelet Transform, and Hessian Matrix",17,7,1144-1147,"Wu Yaokun,Misra Siddharth","Wu YK,Misra S",Misra S,10.1109/LGRS.2019.2943849,Texas A&M University System,"Scanning electron microscope (SEM) image can capture the distribution, topology, and morphology of microstructural constituents of geological materials. Segmentation of SEM image is needed to delineate/locate the various microstructural constituents. To locate locating kerogen/organic matter and pores in shale samples, we test an automated SEM-image segmentation workflow involving feature extraction followed by machine learning, as an alternative to threshold-based and object-based segmentation. For each pixel in the SEM image, 16 features are generated and then fed to a random forest classifier to determine the presence of the four shale components, namely: 1) pore/crack; 2) rock matrix including clay, calcite, and quartz; 3) pyrite; and 4) organic/kerogen components. With the help of feature extraction techniques such as wavelet transform and Hessian affine region detector, the proposed segmentation methodology can segment one 2058 pixel x 2606 pixel SEM image in approximately 30 s. The performance of the trained classifier, quantified in terms of overall F1 score, on the validation data set was higher than 0.9. The newly developed method is significantly robust in comparison to the popular histogram thresholding and object-based segmentation methods.","Image segmentation,machine learning,random forest,scanning electron microscope (SEM) image,shales,supervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Geochemistry & Geophysics,Engineering,Remote Sensing,Imaging Science & Photographic Technology",,3.986,,IEEE GEOSCIENCE AND REMOTE SENSING LETTERS,,
57,Automated Classification Scheme plus AVM for Wafer Sawing Processes,5,3,4525-4532,"Hsieh Yu-Ming,Lu Rung,Lu Jing-Wen,Cheng Fan-Tien,Adnan Muhammad","Hsieh YM,Lu R,Lu JW,Cheng FT,Adnan M",Cheng FT,10.1109/LRA.2020.3000678,National Cheng Kung University,"For the current wafer sawing process, the wafers in the same lot are inspected at the end of the entire process. Therefore, a defect, such as chipping, occurs during processing will only be detected until the end of the process, which is too late and may cause massive defects. If Automatic Virtual Metrology (AVM) is implemented in the wafer sawing process, when chippings occur and are detected, its chipping amount can be predicted by AVM on-line and in real time. Also, AVM's individual similarity index (ISI) analysis can be applied to identify the root cause of chipping. As a result, this root cause can be fixed to avoid generating defects in the subsequent wafers. However, chipping won't happen to all wafers. Since the AVM system deals mainly with the regression problem, it cannot classify whether a wafer is chipped or not. Hence, there is a need to predict wafer-chipping occurrence before applying AVM to the wafer sawing process. To solve the above mentioned problem, the wafer sawing quality monitoring is divided into two stages. An Automated Classification Scheme (ACS) based on ensemble learning is developed in Stage I to pre-determine whether a wafer is chipped. If chipping is detected, then proceed to Stage II for the AVM system to predict the chipping amount and identify the root cause that results in this chipping. With the so-called ACS-plus-AVM scheme, the AVM application in the wafer sawing process can be realized.","Sawing,Metrology,Semiconductor device modeling,Inspection,Monitoring,Indexes,Blades,Wafer sawing processes,Automatic Virtual Metrology (AVM),ensemble learning,Automated Classification Scheme (ACS)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,,"VIRTUAL,METROLOGY,FAILURE",IEEE ROBOTICS AND AUTOMATION LETTERS,,
58,Bayesian Policy Optimization for Waste Crane With Garbage Inhomogeneity,5,3,4533-4540,"Sasaki Hikaru,Hirabayashi Terushi,Kawabata Kaoru,Onuki Yukio,Matsubara Takamitsu","Sasaki H,Hirabayashi T,Kawabata K,Onuki Y,Matsubara T",Sasaki H,10.1109/LRA.2020.3002204,Nara Institute of Science & Technology,"The objective of this study is to develop a framework that can optimize control policies of a waste crane at a waste incineration plant through an autonomous trial and error manner. Since a waste crane is a massive mechanical system that moves slowly and takes several minutes to execute a task, obtaining data samples by executing tasks is very costly. Moreover, no sensors are available that can observe the state of the grasped flammable waste composed of various materials with different degrees of hardness and wetness. Therefore, the inhomogeneity of waste causes unpredictable fluctuation in the crane's task performance. To cope with these problems, we propose a framework for optimizing the policy parameters of a parameterized control policy with Multi-Task Robust Bayesian Optimization (MTRBO). Our framework features the following two characteristics: (1) outlier robustness against garbage inhomogeneity and (2) sample reuse from previously solved tasks to enhance its sample efficiency. To investigate the effectiveness of our framework, we conducted experiments on garbage-scattering tasks with (i) a robot waste crane with pseudo-garbage and (ii) an actual waste crane at a waste incineration plant. Experimental results demonstrate that our framework robustly optimized the control policies of the garbage cranes, even with a much reduced amount of data under the influence of garbage inhomogeneity.","Task analysis,Cranes,Optimization,Kernel,Nonhomogeneous media,Bayes methods,Gaussian processes,AI-Based methods,automation technologies for smart cities,industrial robots",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,"OVERHEAD,CRANE",IEEE ROBOTICS AND AUTOMATION LETTERS,,
59,Sample-Adaptive GANs: Linking Global and Local Mappings for Cross-Modality MR Image Synthesis,39,7,2339-2350,"Yu Biting,Zhou Luping,Wang Lei,Shi Yinghuan,Fripp Jurgen,Bourgeat Pierrick","Yu BT,Zhou LP,Wang L,Shi YH,Fripp J,Bourgeat P",Wang L,10.1109/TMI.2020.2969630,University of Wollongong,"Generative adversarial network (GAN) has been widely explored for cross-modality medical image synthesis. The existing GAN models usually adversarially learn a global sample space mapping from the source-modality to the target-modality and then indiscriminately apply this mapping to all samples in the whole space for prediction. However, due to the scarcity of training samples in contrast to the complicated nature of medical image synthesis, learning a single global sample space mapping that is ""optimal"" to all samples is very challenging, if not intractable. To address this issue, this paper proposes sample-adaptive GAN models, which not only cater for the global sample space mapping between the source- and the target-modalities but also explore the local space around each given sample to extract its unique characteristic. Specifically, the proposed sample-adaptive GANs decompose the entire learning model into two cooperative paths. The baseline path learns a common GAN model by fitting all the training samples as usual for the global sample space mapping. The new sample-adaptive path additionally models each sample by learning its relationship with its neighboring training samples and using the target-modality features of these training samples as auxiliary information for synthesis. Enhanced by this sample-adaptive path, the proposed sample-adaptive GANs are able to flexibly adjust themselves to different samples, and therefore optimize the synthesis performance. Our models have been verified on three cross-modality MR image synthesis tasks from two public datasets, and they significantly outperform the state-of-the-art methods in comparison. Moreover, the experiment also indicates that our sample-adaptive strategy could be utilized to improve various backbone GAN models. It complements the existing GANs models and can be readily integrated when needed.","Gallium nitride,Image synthesis,Training,Adaptation models,Biomedical imaging,Feature extraction,Magnetic resonance imaging,Neural networks,machine learning,magnetic resonance imaging (MRI),brain",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"RANDOM,FOREST",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
60,Unsupervised Domain Adaptation to Classify Medical Images Using Zero-Bias Convolutional Auto-Encoders and Context-Based Feature Augmentation,39,7,2385-2394,"Ahn Euijoon,Kumar Ashnil,Fulham Michael,Feng Dagan,Kim Jinman","Ahn E,Kumar A,Fulham M,Feng D,Kim J",Ahn E,10.1109/TMI.2020.2971258,University of Sydney,"The accuracy and robustness of image classification with supervised deep learning are dependent on the availability of large-scale labelled training data. In medical imaging, these large labelled datasets are sparse, mainly related to the complexity in manual annotation. Deep convolutional neural networks (CNNs), with transferable knowledge, have been employed as a solution to limited annotated data through: 1) fine-tuning generic knowledge with a relatively smaller amount of labelled medical imaging data, and 2) learning image representation that is invariant to different domains. These approaches, however, are still reliant on labelled medical image data. Our aim is to use a new hierarchical unsupervised feature extractor to reduce reliance on annotated training data. Our unsupervised approach uses a multi-layer zero-bias convolutional auto-encoder that constrains the transformation of generic features from a pre-trained CNN (for natural images) to non-redundant and locally relevant features for the medical image data. We also propose a context-based feature augmentation scheme to improve the discriminative power of the feature representation. We evaluated our approach on 3 public medical image datasets and compared it to other state-of-the-art supervised CNNs. Our unsupervised approach achieved better accuracy when compared to other conventional unsupervised methods and baseline fine-tuned CNNs.","Biomedical imaging,Feature extraction,Training,Skin,Diseases,Training data,Convolutional auto-encoders,convolutional neural networks,unsupervised domain adaptation,unsupervised feature learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"NEURAL-NETWORKS,CLASSIFICATION,AUTOENCODERS,RETRIEVAL,ENSEMBLE",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
61,Context-Aware Convolutional Neural Network for Grading of Colorectal Cancer Histology Images,39,7,2395-2405,"Shaban Muhammad,Awan Ruqayya,Fraz Muhammad Moazam,Azam Ayesha,Tsang Yee-Wah,Snead David,Rajpoot Nasir M.","Shaban M,Awan R,Fraz MM,Azam A,Tsang YW,Snead D,Rajpoot NM",Rajpoot NM,10.1109/TMI.2020.2971006,University of Warwick,"Digital histology images are amenable to the application of convolutional neural networks (CNNs) for analysis due to the sheer size of pixel data present in them. CNNs are generally used for representation learning from small image patches (e.g. 224 x 224) extracted from digital histology images due to computational and memory constraints. However, this approach does not incorporate high-resolution contextual information in histology images. We propose a novel way to incorporate a larger context by a context-aware neural network based on images with a dimension of 1792 x 1792 pixels. The proposed framework first encodes the local representation of a histology image into high dimensional features then aggregates the features by considering their spatial organization to make a final prediction. We evaluated the proposed method on two colorectal cancer datasets for the task of cancer grading. Our method outperformed the traditional patch-based approaches, problem-specific methods, and existing context-based methods. We also presented a comprehensive analysis of different variants of the proposed method.","Computational pathology,deep learning,context-aware convolutional networks,cancer grading",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"SEGMENTATION,PROSTATE,NUCLEI",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://wrap.warwick.ac.uk/133973/1/WRAP-context-aware-convolutional-neural-grading-cancer-images-Rajpootf-2020.pdf,
62,A Mutual Bootstrapping Model for Automated Skin Lesion Segmentation and Classification,39,7,2482-2493,"Xie Yutong,Zhang Jianpeng,Xia Yong,Shen Chunhua","Xie YT,Zhang JP,Xia Y,Shen CH",Xia Y,10.1109/TMI.2020.2972964,Northwestern Polytechnical University,"Automated skin lesion segmentation and classification are two most essential and related tasks in the computer-aided diagnosis of skin cancer. Despite their prevalence, deep learning models are usually designed for only one task, ignoring the potential benefits in jointly performing both tasks. In this paper, we propose the mutual bootstrapping deep convolutional neural networks (MB-DCNN) model for simultaneous skin lesion segmentation and classification. This model consists of a coarse segmentation network (coarse-SN), a mask-guided classification network (mask-CN), and an enhanced segmentation network (enhanced-SN). On one hand, the coarse-SN generates coarse lesion masks that provide a prior bootstrapping for mask-CN to help it locate and classify skin lesions accurately. On the other hand, the lesion localization maps produced by mask-CN are then fed into enhanced-SN, aiming to transfer the localization information learned by mask-CN to enhanced-SN for accurate lesion segmentation. In this way, both segmentation and classification networks mutually transfer knowledge between each other and facilitate each other in a bootstrapping way. Meanwhile, we also design a novel rank loss and jointly use it with the Dice loss in segmentation networks to address the issues caused by class imbalance and hard-easy pixel imbalance. We evaluate the proposed MB-DCNN model on the ISIC-2017 and PH2 datasets, and achieve a Jaccard index of 80.4% and 89.4% in skin lesion segmentation and an average AUC of 93.8% and 97.7% in skin lesion classification, which are superior to the performance of representative state-of-the-art skin lesion segmentation and classification methods. Our results suggest that it is possible to boost the performance of skin lesion segmentation and classification simultaneously via training a unified model to perform both tasks in a mutual bootstrapping way.","Lesions,Image segmentation,Skin,Task analysis,Feature extraction,Decoding,Computational modeling,Skin lesion segmentation,skin lesion classification,deep convolutional neural network,dermoscopy",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"DERMOSCOPIC,IMAGE,SEGMENTATION",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1903.03313,
63,One-Shot Learning for Deformable Medical Image Registration and Periodic Motion Tracking,39,7,2506-2517,"Fechter Tobias,Baltas Dimos","Fechter T,Baltas D",Fechter T,10.1109/TMI.2020.2972616,Helmholtz Association,"Deformable image registration is a very important field of research in medical imaging. Recently multiple deep learning approaches were published in this area showing promising results. However, drawbacks of deep learning methods are the need for a large amount of training datasets and their inability to register unseen images different from the training datasets. One shot learning comes without the need of large training datasets and has already been proven to be applicable to 3D data. In this work we present a one shot registration approach for periodic motion tracking in 3D and 4D datasets. When applied to a 3D dataset the algorithm calculates the inverse of the registration vector field simultaneously. For registration we employed a U-Net combined with a coarse to fine approach and a differential spatial transformer module. The algorithm was thoroughly tested with multiple 4D and 3D datasets publicly available. The results show that the presented approach is able to track periodic motion and to yield a competitive registration accuracy. Possible applications are the use as a stand-alone algorithm for 3D and 4D motion tracking or in the beginning of studies until enough datasets for a separate training phase are available.","Three-dimensional displays,Strain,Image registration,Biomedical imaging,Training,Tracking,Registers,Machine learning,motion compensation and analysis,neural network,registration",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,FRAMEWORK,IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1907.04641,
64,Image-to-Images Translation for Multi-Task Organ Segmentation and Bone Suppression in Chest X-Ray Radiography,39,7,2553-2565,"Eslami Mohammad,Tabarestani Solale,Albarqouni Shadi,Adeli Ehsan,Navab Nassir,Adjouadi Malek","Eslami M,Tabarestani S,Albarqouni S,Adeli E,Navab N,Adjouadi M",Eslami M,10.1109/TMI.2020.2974159,State University System of Florida,"Chest X-ray radiography is one of the earliest medical imaging technologies and remains one of the most widely-used for diagnosis, screening, and treatment follow up of diseases related to lungs and heart. The literature in this field of research reports many interesting studies dealing with the challenging tasks of bone suppression and organ segmentation but performed separately, limiting any learning that comes with the consolidation of parameters that could optimize both processes. This study, and for the first time, introduces a multitask deep learning model that generates simultaneously the bone-suppressed image and the organ-segmented image, enhancing the accuracy of tasks, minimizing the number of parameters needed by the model and optimizing the processing time, all by exploiting the interplay between the network parameters to benefit the performance of both tasks. The architectural design of this model, which relies on a conditional generative adversarial network, reveals the process on how the well-established pix2pix network (image-to-image network) is modified to fit the need for multitasking and extending it to the new image-to-images architecture. The developed source code of this multitask model is shared publicly on Github as the first attempt for providing the two-task pix2pix extension, a supervised/paired/aligned/registered image-to-images translation which would be useful in many multitask applications. Dilated convolutions are also used to improve the results through a more effective receptive field assessment. The comparison with state-of-the-art algorithms along with ablation study and a demonstration video (1) are provided to evaluate the efficacy and gauge the merits of the proposed approach. (1) https://youtu.be/J8Uth26_7rQhttps://youtu.be/J8Uth26_7rQ","Bone suppression,chest X-Ray,CXR imaging,image-to-image translation,image-to-images translation,multitask deep learning,organ segmentation,pix2pix",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"LUNG,SEGMENTATION,SHAPE",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1906.10089,
65,An adaptive design approach for defects distribution modeling in materials from first-principle calculations,26,7,,"Lourenco Maicon Pierre,dos Santos Anastacio Alexandre,Rosa Andreia L.,Frauenheim Thomas,da Silva Mauricio Chagas","Lourenco MP,Anastacio AD,Rosa AL,Frauenheim T,da Silva MC",Lourenco MP,10.1007/s00894-020-04438-w,Universidade Federal do Espirito Santo,"Designing and understanding the mechanism of non-stoichiometric materials with enhanced properties is challenging, both experimentally and even computationally, due to the large number of chemical spaces and their distributions through the material. In the current work, it is proposed a Machine Learning approach coupled with the Efficient Global Optimization (EGO) method-an Adaptive Design (AD)-to model local defects in materials from first-principle calculations. Our method takes into account the smallest sample set as possible, envisioning the material defect structure relationship with target properties for new insights. As an example, the AD framework allows us to study the stability and the structure of the modified goethite (Fe0.875Al0.125OOH) by considering a proper defect distribution, from first-principle calculations. The chemical space search for the modified goethite was evaluated by starting from different sizes and configurations of the samples as well as different surrogate models (ANN and Gaussian Process; GP), acquisition functions, and descriptors. Our results show that the same local solution of several defect arrangements in Fe0.875Al0.125OOH is found regardless of the initial sample and regression model. This indicates the efficiency of our search method. We also discuss the role of the descriptors in the accelerated global search for defects in material modeling. We conclude that the AD method applied in material defects is a successful approach in automating the search within huge chemical spaces from first-principle calculations by considering small samples. This method can be applied to mechanistic elucidation of non-stoichiometric materials, solid solutions, alloys, and Schottky and Frenkel defects, essential for material design and discovery.","Machine Learning,Adaptive Design,Efficient Global Optimization,DFT",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Biochemistry & Molecular Biology,Biophysics,Chemistry,Computer Science",,1.675,"EFFICIENT,GLOBAL,OPTIMIZATION,INITIO,MOLECULAR-DYNAMICS,IN-SITU,GOETHITE,STABILITY,DISCOVERY",JOURNAL OF MOLECULAR MODELING,,
66,Electronic structure calculations of twisted multi-layer graphene superlattices,7,3,,"Tritsaris Georgios A.,Carr Stephen,Zhu Ziyan,Xie Yiqi,Torrisi Steven B.,Tang Jing,Mattheakis Marios,Larson Daniel T.,Kaxiras Efthimios","Tritsaris GA,Carr S,Zhu ZY,Xie YQ,Torrisi SB,Tang J,Mattheakis M,Larson DT,Kaxiras E",Tritsaris GA,10.1088/2053-1583/ab8f62,Harvard University,"Quantum confinement endows two-dimensional (2D) layered materials with exceptional physics and novel properties compared to their bulk counterparts. Although certain two- and few-layer configurations of graphene have been realized and studied, a systematic investigation of the properties of arbitrarily layered graphene assemblies is still lacking. We introduce theoretical concepts and methods for the processing of materials information, and as a case study, apply them to investigate the electronic structure of multi-layer graphene-based assemblies in a high-throughput fashion. We provide a critical discussion of patterns and trends in tight binding band structures and we identify specific layered assemblies using low-dispersion electronic bands as indicators of potentially interesting physics like strongly correlated behavior. A combination of data-driven models for visualization and prediction is used to intelligently explore the materials space. This work more generally aims to increase confidence in the combined use of physics-based and data-driven modeling for the systematic refinement of knowledge about 2D layered materials, with implications for the development of novel quantum devices.","tight binding,machine learning,high-throughput calculations,electronic band structure,twistronics,materials informatics,quantum materials",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Materials Science,,8.161,SYSTEM,2D MATERIALS,https://www.osti.gov/biblio/1644679,
67,Classification of human hand movements based on EMG signals using nonlinear dimensionality reduction and data fusion techniques,149,,,"Rabin Neta,Kahlon Maayan,Malayev Sarit,Ratnovsky Anat","Rabin N,Kahlon M,Malayev S,Ratnovsky A",Ratnovsky A,10.1016/j.eswa.2020.113281,"Afeka Tel Aviv Acad Coll Engn, Sch Med Engn, Tel Aviv, Israel.","Surface electromyography (EMG) is non-invasive signal acquisition technique that plays a central role in many application, including clinical diagnostics, control for prosthetic devices and for human-machine interactions. The processing typically begins with a feature extraction step, which may be followed by the application of a dimensionality reduction technique. The obtained reduced features are input for a machine learning classifier. The constructed machine learning model may then classify new recorded movements.
The features extracted for EMG signals usually capture information both from the time and from the frequency domain. Short time Fourier transform (STFT) is commonly used for signal processing and in particular for EMG processing since it captures the temporal and the frequency characteristics of the data. Since the number of calculated STFT features is large, a common approach in signal processing and machine learning applications is to apply a linear or a nonlinear dimensionality reduction technique for simplifying the feature space. Another aspect that arises in medical applications in general and in EMG based hand classification in particular, is the large variability between subjects. Due to this variability, many studies focus on single subject classification. This requires acquiring a large training set for each tested participant which is not practical in real life application.
The objectives of this study were first to compare between the performances of a nonlinear dimensionality technique to a standard linear dimensionality method when applied for single subject EMG based hand movement classification, and to examined their performances in case of limited amount of training data samples. The second objective was to propose an algorithm for multi-subjects classification that utilized a data alignment step for overcoming the large variability between subjects.
The data set included EMG signals from 5 subjects who perform 6 different hand movements. STFT was calculated for feature extraction, principal component analysis (PCA) and diffusion maps (DM) were compared for dimension reductions. An affine transformation for aligning between the reduced feature spaces of two subjects, was investigated. K-nearest neighbors (KNN) was used for single and multi-subject classification.
The results of this study clearly show that the DM outperformed the PCA in case of limited training data. In addition, the multi-subject classification approach, which utilizes dimension reduction methods along with an alignment algorithm enable robust classification of a new subject based on another subjects' data sets. The proposed framework is general and can be adopted for many EMG classification task. (C) 2020 Elsevier Ltd. All rights reserved.","Electromyography,Machine learning,Principal component analysis,Diffusion maps,Data fusion,Graph alignment",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"MYOELECTRIC,PATTERN-RECOGNITION,DIFFUSION",EXPERT SYSTEMS WITH APPLICATIONS,,
68,Classification of brain MRI using hyper column technique with convolutional neural network and feature selection method,149,,,"Togacar Mesut,Comert Zafer,Ergen Burhan,Ozyurt Fatih","Togacar M,Comert Z,Ergen B,Ozyurt F",Togacar M,10.1016/j.eswa.2020.113274,Firat University,"A proper and certain brain tumor MRI classification has a significant role in current clinical diagnosis, decision making as well as managing the treatment programs. In clinical practice, the examination is performed visually by the specialists, this is a labor-intensive and error-prone process. Therefore, the computer-based systems are in demand so as to carry out objectively this process. In the traditional machine learning approaches, the low-level and high-level handcrafted features used to describe the brain tumor MRI are extracted and classified to overcome the mentioned drawbacks. Considering the recent advances in deep learning, we propose a novel convolutional neural network (CNN) model that is combined with the hypercolumn technique, pretrained AlexNet and VGG-16 networks, recursive feature elimination (RFE), and support vector machine (SVM) in this study. One of the great advantages of the proposed model is that with the help of the hypercolumn technique, it can keep the local discriminative features, which are extracted from the layers located at the different levels of the deep architectures. In addition, the proposed model exploits the generalization abilities of both AlexNet and VGG-16 networks by fusing the deep features achieved from the last fully-connected layers of the networks. Furthermore, the discriminative capacity of the proposed model is enhanced using RFE and thus the most effective deep features are revealed. As a result, the proposed model yielded an accuracy of 96.77% without using any handcrafted feature engine. A fully automated consistent and effective diagnostic model is ensured for the brain tumor MRI classification. Consequently, the proposed model can contribute to realizing a more objective evaluation in the clinics, supporting the decision-making process of the experts, and reducing misdiagnosis rates. (C) 2020 Elsevier Ltd. All rights reserved.","Biomedical signal processing,Decision support system,Brain MRI,Hypercolumn technique,Feature selection",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"TUMOR,CLASSIFICATION,SVM",EXPERT SYSTEMS WITH APPLICATIONS,,
69,Deep Learning Based Real-Time OCT Image Segmentation and Correction for Robotic Needle Insertion Systems,5,3,4517-4524,"Park Ikjong,Kim Hong-Kyun,Chung Wan Kyun,Kim Keehoon","Park I,Kim HK,Chung WK,Kim K",Kim K,10.1109/LRA.2020.3001474,Pohang University of Science & Technology (POSTECH),"This article proposes deep learning based real-time optical coherence tomography (OCT) image segmentation and correction algorithm for vision-based robotic needle insertion systems that can be used in DALK (deep anterior lamellar keratoplasty) surgery. The proposed algorithm provides the position of the needle tip, the lower boundary of the tissue, and the marginal insertion depth solving traditional issues of OCT images like refractive error, optical noise from surgical tools, and the slow speed of volumetric scanning. Through the ex-vivo experiment using 10 porcine corneas, the performance of the proposed algorithm with a robotic system was verified. The segmentation errors were 7.4 mu m for the upper boundary, 10.5 mu m for the lower boundary, and 3.6 mu m for the needle tip. The difference in needle slope between the outside and inside of the cornea was dramatically reduced from 5.87 degree to 0.78 degree. The frame rate of the OCT image was 9.7 Hz, and the time delay of the image processing algorithm was 542.6 ms for 10 images of 512 x 512 pixels. The results of the proposed algorithm were compared with those of the previous studies.","Automation in life sciences,biotechnology,pharmaceutical and health care",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,"OPTICAL,COHERENCE,TOMOGRAPHY,ANTERIOR,SEGMENT,OPHTHALMIC,SURGERY",IEEE ROBOTICS AND AUTOMATION LETTERS,,
70,A systematic review: machine learning based recommendation systems for e-learning,25,4,2635-2664,"Khanal Shristi Shakya,Prasad P. W. C.,Alsadoon Abeer,Maag Angelika","Khanal SS,Prasad PWC,Alsadoon A,Maag A",Prasad PWC,10.1007/s10639-019-10063-9,Charles Sturt University,"The constantly growing offering of online learning materials to students is making it more difficult to locate specific information from data pools. Personalization systems attempt to reduce this complexity through adaptive e-learning and recommendation systems. The latter are, generally, based on machine learning techniques and algorithms and there has been progress. However, challenges remain in the form of data-scarcity, cold-start, scalability, time consumption and accuracy. In this article, we provide an overview of recommendation systems in the e-learning context following four strands: Content-Based, Collaborative Filtering, Knowledge-Based and Hybrid Systems. We developed a taxonomy that accounts for components required to develop an effective recommendation system. It was found that machine learning techniques, algorithms, datasets, evaluation, valuation and output are necessary components. This paper makes a significant contribution to the field by providing a much-needed overview of the current state of research and remaining challenges.","Recommendation system,Recommender,E-learning,Content-based,Collaborative filtering,Hybrid",Review,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Education & Educational Research,,2.953,"OF-THE-ART,COLLABORATIVE,RECOMMENDATION,MODEL,USER,RESOURCES,ALGORITHM,STYLES,PATH,MAP",EDUCATION AND INFORMATION TECHNOLOGIES,,
71,Speckle reduction of medical ultrasound images using deep learning with fully convolutional network,59,,,"Ando Kazuma,Nagaoka Ryo,Hasegawa Hideyuki","Ando K,Nagaoka R,Hasegawa H",Hasegawa H,10.35848/1347-4065/ab80a5,University of Toyama,"Smoothing filters are frequently used for speckle reduction of medical ultrasound images. However, such filters may cause loss of the detailed structures of tissues in terms of image contrast. To improve image contrast in speckle reduction, we investigated a filter for medical ultrasound images using deep learning with a fully convolutional network, which was trained with pairs of input and target data generated by computer simulation. The proposed method achieved higher contrast-to-noise ratio and contrast values than the conventional methods with about 300 times faster processing speed than the NL-means filter. (C) 2020 The Japan Society of Applied Physics",,Article; Proceedings Paper,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,1.362,,JAPANESE JOURNAL OF APPLIED PHYSICS,,
72,Semisupervised Hotspot Detection With Self-Paced Multitask Learning,39,7,1511-1523,"Chen Ying,Lin Yibo,Gai Tianyang,Su Yajuan,Wei Yayi,Pan David Z.","Chen Y,Lin YB,Gai TY,Su YJ,Wei YY,Pan DZ",Su YJ; Wei YY,10.1109/TCAD.2019.2912948,Chinese Academy of Sciences,"Lithography simulation is computationally expensive for hotspot detection. Machine learning-based hotspot detection is a promising technique to reduce the simulation overhead. However, most learning approaches rely on a large amount of training data to achieve good accuracy and generality. At the early stage of developing a new technology node, the amount of data with labeled hotspots or nonhotspots is very limited. In this paper, we propose a semisupervised hotspot detection with self-paced multitask learning paradigm, leveraging both data samples with/without labels to improve model accuracy and generality. Experimental results demonstrate that our approach can achieve 4.6%-6.5% better accuracy at the same false alarm levels than the state-of-the-art work using 10%-50% of training data.","Training,Layout,Lithography,Machine learning,Feature extraction,Labeling,Training data,Hotspot detection,multitask neural network,self-paced learning,semi-supervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,2.702,"LABEL,PROPAGATION,VERIFICATION",IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS,,
73,Region-specific agreement in ASPECTS estimation between neuroradiologists and e-ASPECTS software,12,7,720-723,"Neuhaus Ain,Seyedsaadat Seyed Mohammad,Mihal David,Benson John,Mark Ian,Kallmes David F.,Brinjikji Waleed","Neuhaus A,Seyedsaadat SM,Mihal D,Benson J,Mark I,Kallmes DF,Brinjikji W",Brinjikji W,10.1136/neurintsurg-2019-015442,"Mayo Clin Minnesota, Rochester, MN 55901 USA.","Background and purpose The Alberta Stroke Program Early CT Score (ASPECTS) is a widely used measure of ischemic change on non-contrast CT. Although predictive of long-term outcome, ASPECTS is limited by its modest interobserver agreement. One potential solution to this is the use of machine learning strategies, such as e-ASPECTS, to detect ischemia. Here, we compared e-ASPECTS with manual scoring by experienced neuroradiologists for all 10 individual ASPECTS regions. Materials and methods We retrospectively reviewed 178 baseline non-contrast CT scans from patients with acute ischemic stroke undergoing endovascular thrombectomy. All scans were reviewed by two independent neuroradiologists with a third reader arbitrating disagreements for a consensus read. Each ASPECTS region was scored individually. All scans were then evaluated using a machine learning-based software package (e-ASPECTS, Brainomix). Interobserver agreement between readers and the software for each region was calculated with a kappa statistic. Results The median ASPECTS was 9 for manual scoring and 8.5 for e-ASPECTS, with an overall agreement of kappa=0.248. Regional agreement varied from kappa=0.094 (M1) to kappa=0.555 (lentiform), with better performance in subcortical regions. When corrected for the low number of infarcts in any given region, prevalence-adjusted bias-adjusted kappa ranged from 0.483 (insula) to 0.888 (M3), with greater agreement for cortical areas. Intraclass correlation coefficients were between 0.09 (M1) and 0.556 (lentiform). Conclusion Manual scoring and e-ASPECTS had fair agreement in our dataset on a per-region basis. This warrants further investigation using follow-up scans or MRI as the gold standard measure of true ASPECTS.","stroke,thrombectomy,CT",Article,"BMJ PUBLISHING GROUP, BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND","Neurosciences & Neurology,Surgery",,4.815,"COMPUTED-TOMOGRAPHY,SCORE,ACUTE,ISCHEMIC-STROKE,ASSESSING,CT,SCANS,ALBERTA,STROKE,THROMBECTOMY,RELIABILITY,THROMBOLYSIS,UTILITY,TRIAL",JOURNAL OF NEUROINTERVENTIONAL SURGERY,,
74,Effect of Functional Endoscopic Sinus Surgery on Voice and Speech Recognition,34,4,,"Hernandez-Garcia Estefania,Moro-Velazquez Aaureano,Gonzalez-Herranz Ramon,Godino-Llorente Juan Ignacio,Plaza Guillermo","Hernandez-Garcia E,Moro-Velazquez A,Gonzalez-Herranz R,Godino-Llorente JI,Plaza G",Hernandez-Garcia E,10.1016/j.jvoice.2019.02.012,Hospital Universitario Fuenlabrada,"Objective. Functional Endoscopic Sinus Surgery (FESS) is the surgery of choice for nasal polypo- sis and chronic rhinosinusitis. The aim of our study is to assess the influence of this surgery in the acoustic param- eters of voice, and their implications in the systems of identification or verification of the speaker through the speech.
Material and methods. A prospective study was performed between January 2017 and June 2017 including two groups of patients: those undergoing FESS, and a control group. Demographic data and GRBAS assessment were statistically analyzed. In addition, a recording of patients ? voices was made with a subsequent acoustic anal- ysis and automatic identification of the speaker through machine learning systems, establishing the equal error rate. Samples were taken before surgery, 2 weeks after surgery and 3 months later.
Results. After FESS, a significant difference was observed in Grade, Roughness, Breathiness, Asthenia, Strain (GRBAS). Besides, acoustic analysis showed a significance decrease in fundamental frequency (F0), when com- pared with the control group. For the automatic identification of the speaker through computer systems, we found that the equal error rate is higher in the FESS group.
Conclusions. Results suggest that FESS produce a decrease of F0 and changes in the vocal tract that derive in an increase in the error of recognition of the speaker in FESS patients.","FESS,Acoustic analysis,Formants,Automatic identification",Article,"MOSBY-ELSEVIER, 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA","Audiology & Speech-Language Pathology,Otorhinolaryngology",,2.225,"MAXILLARY,SINUS,PARAMETERS",JOURNAL OF VOICE,,
75,Applying several machine learning approaches for prediction of unconfined compressive strength of stabilized pond ashes,32,13,9019-9028,Suthar Manju,Suthar M,Suthar M,10.1007/s00521-019-04411-6,"Maharaja Agrasen Univ, Dept Civil Engn, Baddi 174103, Himachal Prades, India.","This paper evaluates the potential of five modeling approaches, namely M5 model tree, random forest, artificial neural networks, support vector machines and Gaussian processes, for the prediction of unconfined compressive strength of stabilized pond ashes with lime and lime sludge. The study not only presents five models for the same set of data but also compares the overall performance of them. Dataset used consists of 255 samples acquired from laboratory experiments. Out of the total, 170 randomly chosen samples were used for training and remaining 85 were used for testing the models. Input dataset consists of eight parameters (uniformity coefficient, coefficient of curvature, maximum dry density, optimum moisture content, lime, lime sludge, curing period and 7-day soaked California bearing ratio), while the output is UCS value at 7, 28, 45, 90 and 180 days of curing. Comparisons of results propose that Gaussian processes modeling strategy works well and the overall performance was substantially nearer to the exact agreement line. As a result of GP model, higher value of CC = 0.997 and lower values of RMSE = 23.016 kPa and MAE = 16.455 were obtained for testing the dataset. Sensitivity analysis suggests that lime, lime sludge, curing period and California bearing ratio are the significant parameters for predicting the unconfined compressive strength of stabilized pond ashes. The results confirmed that GP models are in a position to predict the unconfined compressive strength of stabilized pond ashes with an excessive degree of accuracy; however, GP modeling approach proves that this approach is more economical and less difficult in comparison with tedious laboratory work.","Unconfined compressive strength,M5 model tree,Random forest,Artificial neural network,Support vector machines,Gaussian processes",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"ARTIFICIAL,NEURAL-NETWORK,SUPPORT,VECTOR,MACHINE,MODEL,TREES",NEURAL COMPUTING & APPLICATIONS,,
76,The Determination of Buried Magnetic Material From Various Heights: A Neural Network Application,69,7,4188-4199,"Citak Hakan,Ege Yavuz,Bicakci Sabri,Gunes Huseyin,Coramik Mustafa","Citak H,Ege Y,Bicakci S,Gunes H,Coramik M",Ege Y,10.1109/TIM.2019.2943988,Balikesir University,"This article aims at determining the anomalies created by buried magnetic materials on the horizontal component of earth's magnetic field through the KMZ51 anisotropic magnetoresistive sensor (AMR) series and determining the upper surface image of the material through the sensor series located in different positions per soil by processing the sensor data obtained due to anomaly at different heights from the soil surface using a feedforward artificial neural network (ANN) trained with the Levenberg-Marquardt (LM) backpropagation algorithm. In our study, in this direction, first, a mechanical scanning system ensuring the 3-D movement of the sensors, a data capture module to process the data transmitted from the KMZ51 AMR sensors and to transmit to the computer, and a magnetic measurement system composed of a computer software package to evaluate and record the data transmitted to the computer were established. Afterward, the magnetic materials with known magnetic, chemical, and geometrical properties were buried in soil containing 28.5% magnetic particles and 4.1% natural moisture with the help of the measurement system and the voltage changes in AMR sensors resulting from the anomaly were transmitted into the computer through the 2-D movement of the platform. This process was repeated for five different heights. The voltage values obtained were converted into a data matrix; then, the undesired noises in data resulting from the magnetic character of soil were cleared by filtering through the median and the base. Such cleaned data were converted into black and white images with a threshold value calculation method for conversion into black and white in grayscale histograms developed by ""Otsu""; and the upper surface image of the buried material was determined. Finally, a feedforward ANN using the LM backpropagation algorithm was trained with the data measured from 0-, 1.5-, 3-, 4.5-, and 6-cm heights from the magnetic material; and the voltage values measured from 3- and 6-cm heights from the magnetic material were provided to the ANN as inputs, respectively, and thus, the voltage values for the same material at 0-cm height were found. Thereby, the upper surface image of the material could be determined by the same way as that obtained from 0-cm height even though the sensor series is at a different position compared with the soil surface through the ANN developed. Although many magnetic materials were tested, the results of a cuboid and a cylindrical material were provided within the scope of our study article and the performance of the ANN was discussed. In addition, the success of the ANN in different soil mixtures was confirmed for these two materials.","Magnetic resonance imaging,Soil,Perpendicular magnetic anisotropy,Magnetic materials,Artificial neural networks,Magnetoacoustic effects,Anisotropic magnetoresistive (AMR) sensor,artificial neural network (ANN),Levenberg-Marquardt (LM) algorithm,magnetic anomaly,magnetic materials",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"LANDMINE,DETECTION,AMR,GRADIOMETER,IDENTIFICATION,CLASSIFICATION,DAMAGE",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
77,A Data-Flow Oriented Deep Ensemble Learning Method for Real-Time Surface Defect Inspection,69,7,4681-4691,"Liu Yuekai,Gao Hongli,Guo Liang,Qin Aoping,Cai Canyu,You Zhichao","Liu YK,Gao HL,Guo L,Qin AP,Cai CY,You ZC",Guo L,10.1109/TIM.2019.2957849,Southwest Jiaotong University,"Real-time surface defect inspection plays an important role in the quality control of automated production. For the surface defect inspection, flowing data are a common data form in the automated pipeline production. Although flowing data provide rich information for surface defect inspection, there are still a lot of dynamic distribution challenges caused by the flowing data, such as the domain shift phenomenon and imbalanced training data. However, many existing industrial inspection solutions still use static strategies. To determine the dynamic distribution influence on the data flow domain, this article proposes a new deep ensemble learning method with domain fluctuation adaptation. Specifically, a new distribution discrepancy identifier based on estimation of the data set distribution and data characteristic is proposed. It utilizes advantages of both the deep convolutional neural network (CNN) and the shallow feature-based learning method to achieve higher robustness and fine-grained detection in streaming data scenes. In order to validate the proposed method, an inspection bench test system, as a part of a real industrial surface mount technology production line, is designed and fabricated. The proposed inference model is successfully applied to an embedded terminal with a hybrid and heterogeneous computing architecture. At last, the method is validated on the data collected from the manufacturer. The result suggests that the proposed method possesses a competitive mean average precision (mAP) rate with good adaptation and robustness in industrial streaming data scenes.","Inspection,Pipelines,Fluctuations,Learning systems,Three-dimensional printing,Computational modeling,Deep ensemble learning,domain fluctuation adaptation,streaming data,visual fault diagnosis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"NEURAL-NETWORK,APPROACH,VISUAL,INSPECTION,PATTERNS,LINE,CNN",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
78,A Two-Stage Deep Learning Method for Robust Shape Reconstruction With Electrical Impedance Tomography,69,7,4887-4897,"Ren Shangjie,Sun Kai,Tan Chao,Dong Feng","Ren SJ,Sun K,Tan C,Dong F",Dong F,10.1109/TIM.2019.2954722,Tianjin University,"As a noninvasive and radiation-free imaging modality, electrical impedance tomography (EIT) has attracted much attention in the last two decades and owns many industry and biomedical applications. However, due to the nonlinearity and ill-posedness of its inverse problem, the EIT images always suffer from low spatial resolution and are sensitive to the modeling errors. To achieve high resolution and modeling error robust EIT image, a two-stage deep learning (TSDL) method is proposed. The proposed method consists of a prereconstruction block and a convolutional neural network (CNN). The prereconstruction block learns the regularization pattern from the training data set and provides a rough reconstruction of the target. The CNN postprocesses the prereconstruction result in a multilevel feature analysis strategy and eliminates the modeling errors with prior information of the observation domain shape. The prereconstruction and CNN blocks are trained together by using a minimum square approach. To evaluate the performance of the TSDL method, the lung EIT problem was studied. The training data set is calculated from more than 100 000 EIT simulation models generated from computed tomography (CT) scans across 792 patients. Lung injury, measurement noise, and model errors are randomly simulated during the model generation process. The trained TSDL model is evaluated with simulation testes, as well as the experimental tests from a laboratory setting. According to the results, the TSDL method could achieve high accuracy shape reconstructions and is robust against measurement noise and modeling errors.","Tomography,Image reconstruction,Shape,Data models,Training data,Conductivity,Convolutional neural network (CNN),electrical impedance tomography (EIT),image reconstruction,machine learning,modeling error",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,IMAGE-RECONSTRUCTION,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
79,"Analysis of trade-off relationships between resolution, line edge roughness, and sensitivity in extreme ultraviolet lithography using lasso regression",59,7,,"Azumagawa Kazuki,Kozawa Takahiro","Azumagawa K,Kozawa T",Kozawa T,10.35848/1347-4065/ab984e,Osaka University,"The high-volume production of semiconductor devices by extreme ultraviolet (EUV) lithography has started since 2019. The trade-off relationships between resolution, line edge roughness (LER), and sensitivity are a significant concern for the extendability of EUV lithography. In this study, the trade-off relationships were analyzed using the least square and lasso regressions. Within the half-pitch range of 5-16 nm, the relationships among resolution, chemical gradient (an indicator for LER), sensitivity, total sensitizer concentration, and effective reaction radius for deprotection were nicely predicted by the fitted parameters. The number of feature values required for describing the chemical gradient was examined. The dependence of fitting accuracy on the number of data used for the analysis was also examined. The lasso regression was effective to not only the reduction of the number of feature values but also the improvement of fitting accuracy for small data sets, compared with the least square regression.","EUV lithography,machine learning,lasso regression,LER,trade-off relationship,chemical gradient",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,1.362,"CHEMICALLY,AMPLIFIED,RESISTS,ACID,DISTRIBUTION",JAPANESE JOURNAL OF APPLIED PHYSICS,,
80,Improving Low -contrast Detectability and Noise Texture Pattern for Computed Tomography Using Iterative Reconstruction Accelerated with Machine Learning Method: A Phantom Study,27,7,929-936,"Funama Yoshinori,Takahashi Hisashi,Goto Taiga,Aoki Yuko,Yoshida Ryo,Kumagai Yukio,Awai Kazuo","Funama Y,Takahashi H,Goto T,Aoki Y,Yoshida R,Kumagai Y,Awai K",Funama Y,10.1016/j.acra.2019.09.007,Kumamoto University,,"RADIATION-DOSE REDUCTION,FILTERED BACK-PROJECTION,MODERN DIAGNOSTIC MDCT,MODEL RECONSTRUCTION,IMAGE QUALITY,POWER SPECTRUM,CT ANGIOGRAPHY,ABDOMINAL CT,OPTIMIZATION,HYBRID",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.751,"RADIATION-DOSE,REDUCTION,FILTERED,BACK-PROJECTION,MODERN,DIAGNOSTIC,MDCT,MODEL,RECONSTRUCTION,IMAGE,QUALITY,POWER,SPECTRUM,CT,ANGIOGRAPHY,ABDOMINAL,CT,OPTIMIZATION,HYBRID",ACADEMIC RADIOLOGY,,
81,Convolutional Neural Networks in Predicting Nodal and Distant Metastatic Potential of Newly Diagnosed Non-Small Cell Lung Cancer on FDG PET Images,215,1,192-197,"Tau Noam,Stundzia Audrius,Yasufuku Kazuhiro,Hussey Douglas,Metser Ur","Tau N,Stundzia A,Yasufuku K,Hussey D,Metser U",Metser U,10.2214/AJR.19.22346,University of Toronto,"OBJECTIVE. The purpose of this study was to assess, by analyzing features of the primary tumor with F-18-FDG PET, the utility of deep machine learning with a convolutional neural network (CNN) in predicting the potential of newly diagnosed non-small cell lung cancer (NSCLC) to metastasize to lymph nodes or distant sites.
MATERIALS AND METHODS. Consecutively registered patients with newly diagnosed, untreated NSCLC were retrospectively included in a single-center study. PET images were segmented with local image features extraction software, and data were used for CNN training and validation after data augmentation strategies were used. The standard of reference for designation of N category was invasive lymph node sampling or 6-month follow-up imaging. Distant metastases developing during the study follow-up period were assessed by imaging (CT or PET/CT), in tissue obtained from new suspected sites of disease, and according to the treating oncologist's designation.
RESULTS. A total of 264 patients with NSCLC participated in follow-up for a median of 25.2 months (range, 6-43 months). N category designations were available for 223 of 264 (84.5%) patients, and M category for all 264. The sensitivity, specificity, and accuracy of CNN for predicting node positivity were 0.74 +/- 0.32, 0.84 +/- 0.16, and 0.80 +/- 0.17. The corresponding values for predicting distant metastases were 0.45 +/- 0.08, 0.79 +/- 0.06, and 0.63 +/- 0.05.
CONCLUSION. This study showed that using a CNN to analyze segmented PET images of patients with previously untreated NSCLC can yield moderately high accuracy for designation of N category, although this may be insufficient to preclude invasive lymph node sampling The sensitivity of the CNN in predicting distant metastases is fairly poor, although specificity is moderately high.","artificial intelligence,FDG,machine learning,non-small cell lung cancer,PET/CT",Article,"AMER ROENTGEN RAY SOC, 44211 SLATESTONE CT, LEESBURG, VA USA","Radiology, Nuclear Medicine & Medical Imaging",,4.073,"F-18-FDG,PET%2FCT",AMERICAN JOURNAL OF ROENTGENOLOGY,,
82,A health informatics transformation model based on intelligent cloud computing - exemplified by type 2 diabetes mellitus with related cardiovascular diseases,191,,,"Lin Hsueh-Chun,Kuo Yu-Chen,Liu Meng-Yu","Lin HC,Kuo YC,Liu MY",Lin HC,10.1016/j.cmpb.2020.105409,China Medical University Taiwan,"Background and Objective: Many studies regarding health analysis request structured datasets but the legacy resources provide scattered data. This study aims to establish a health informatics transformation model (HITM) based upon intelligent cloud computing with the self-developed analytics modules by open source technique. The model was exemplified by the open data of type 2 diabetes mellitus (DM2) with related cardiovascular diseases.
Methods: The Apache SPARK framework was employed to generate the infrastructure of the HITM, which enables the machine learning (ML) algorithms including random forest, multi-layer perceptron classifier, support vector machine, and naive Bayes classifier as well as the regression analysis for intelligent cloud computing. The modeling applied the MIMIC-III open database as an example to design the health informatics data warehouse, which embeds the PL/SQL-based modules to extract the analytical data for the training processes. A coupling analysis flow can drive the ML modules to train the sample data and validate the results.
Results: The four modes of cloud computation were compared to evaluate the feasibility of the cloud platform in accordance with its system performance for more than 11,500 datasets. Then, the modeling adaptability was validated by simulating the featured datasets of obesity and cardiovascular-related diseases for patients with DM2 and its complications. The results showed that the run-time efficiency of the platform performed in around one minute and the prediction accuracy of the featured datasets reached 90%.
Conclusions: This study helped contribute the modeling for efficient transformation of health informatics. The HITM can be customized for the actual clinical database, which provides big data for training, with the proper ML modules for a predictable process in the cloud platform. The feedback of intelligent computing can be referred to risk assessment in health promotion. (C) 2020 Elsevier B.V. All rights reserved.","Health informatics transformation,Cloud computing,MIMIC-III,Open data,Machine learning",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"ARTIFICIAL,NEURAL-NETWORK,LOGISTIC-REGRESSION,CANCER,DATA,CARE,SERVICES,DECISION,SYSTEM",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
83,Modelling bioaccumulation of heavy metals in soil-crop ecosystems and identifying its controlling factors using machine learning,262,,,"Hu Bifeng,Xue Jie,Zhou Yin,Shao Shuai,Fu Zhiyi,Li Yan,Chen Songchao,Qi Lin,Shi Zhou","Hu BF,Xue J,Zhou Y,Shao S,Fu ZY,Li Y,Chen SC,Qi L,Shi Z",Shi Z,10.1016/j.envpol.2020.114308,Zhejiang University,"The prediction and identification of the factors controlling heavy metal transfer in soil-crop ecosystems are of critical importance. In this study, random forest (RF), gradient boosted machine (GBM), and generalised linear (GLM) models were compared after being used to model and identify prior factors that affect the transfer of heavy metals (HMs) in soil-crop systems in the Yangtze River Delta, China, based on 13 covariates with 1822 pairs of soil-crop samples. The mean bioaccumulation factors (BAFs) for all crops followed the order Cd > Zn > As > Cu > Ni > Hg > Cr > Pb. The RF model showed the best prediction ability for the BAFs of HMs in soil-crop ecosystems, followed by GBM and GLM. The R2 values of the RF models for the BAFs of Zn, Cu, Cr, Ni, Hg, Cd, As, and Pb were 0.84, 0.66, 0.59, 0.58, 0.58, 0.51, 0.30, and 0.17, respectively. The primary controlling factor in soil-to-crop transfer of all HMs under study was plant type, followed by soil heavy metal content and soil organic materials. The model used herein could be used to assist the prediction of heavy metal contents in crops based on heavy metal contents in soil and other covariates, and can significantly reduce the cost, labour, and time requirements involved with laboratory analysis. It can also be used to quantify the importance of variables and identify potential control factors in heavy metal bioaccumulation in soil-crop ecosystems. (C) 2020 Elsevier Ltd. All rights reserved.","Heavy metals,Soil-crop ecosystems,Machine learning,Random forest,Bioaccumulation factor,Controlling factors",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Environmental Sciences & Ecology,,8.35,"PEARL,RIVER,DELTA,RISK-ASSESSMENT,CADMIUM,ACCUMULATION,AGRICULTURAL,SOILS,WASTE-WATER,RICE,CHINA,BIOAVAILABILITY,VEGETABLES,CONTAMINATION",ENVIRONMENTAL POLLUTION,,
84,Carbohydrate fraction characterisation of functional yogurts containing pectin and pectic oligosaccharides through convolutional networks,90,,,"Sabater Carlos,Abad-Garcia Celia,Delgado-Fernandez Paloma,Corzo Nieves,Montilla Antonia","Sabater C,Abad-Garcia C,Delgado-Fernandez P,Corzo N,Montilla A",Corzo N,10.1016/j.jfca.2020.103484,Consejo Superior de Investigaciones Cientificas (CSIC),"The carbohydrate fraction of functional yogurts supplemented with citrus and artichoke pectin and their pectic oligosaccharides (POS) has been characterised, including carbohydrates from raw material (milk, pectin and POS) and formed during yogurt manufacture (POS and galactooligosaccharides GOS). Viable cell count and pH values accomplished the quality standards required for yogurts. The content of lactose and lactic and acetic acids was in the range 3.5-4.0; 0.85-1.16 and 0.04-0.07 g 100 g(-1), respectively. Other sugars from pectin (arabinose, galacturonic acid, POS), milk (glucose, galactose, myo-inositol and GOS, GOS) were also quantified. GC-EI-MS spectra of yogurt carbohydrates were classified using machine learning, and structure-relative retention time relationships were calculated determining the abundance of specific fragments on larger oligosaccharide structures. All information generated was correlated using a convolutional network that established characteristic patterns in the complete carbohydrate fraction of each yogurt, as well as changes during fermentation in the carbohydrate profile. It was found that di-, tri- and tetra-POS formed by rhamnose and xylose attached to acetylated-galacturonic acid were released during fermentation in yogurts with artichoke POS. Structures elucidated by these algorithms were confirmed by MALDI-TOF-MS. These models may allow structural differences to be determined among novel oligosaccharides present in food matrices.","Functional yogurt,Artichoke and citrus pectins,Pectic oligosaccharides,In silico fragmentation,Convolutional neural network",Article; Proceedings Paper,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Chemistry,Food Science & Technology",,4.89,"IN-VITRO,FERMENTATION,ORGANIC-ACIDS,LACTIC-ACID,STORAGE,CITRUS,GROWTH,PEEL,POLYSACCHARIDES,MANUFACTURE,ANTIOXIDANT",JOURNAL OF FOOD COMPOSITION AND ANALYSIS,,
85,Cryo-FIB-SEM as a promising tool for localizing proteins in 3D,211,1,,"Spehner Daniele,Steyer Anna M.,Bertinetti Luca,Orlov Igor,Benoit Lucas,Pernet-Gallay Karin,Schertel Andreas,Schultz Patrick","Spehner D,Steyer AM,Bertinetti L,Orlov I,Benoit L,Pernet-Gallay K,Schertel A,Schultz P",Spehner D,10.1016/j.jsb.2020.107528,Institut National de la Sante et de la Recherche Medicale (Inserm),"Focused Ion Beam-Scanning Electron Microscopy (FIB-SEM) is an invaluable tool to visualize the 3D architecture of cell constituents and map cell networks. Recently, amorphous ice embedding techniques have been associated with FIB-SEM to ensure that the biological material remains as close as possible to its native state. Here we have vitrified human HeLa cells and directly imaged them by cryo-FIB-SEM with the secondary electron InLens detector at cryogenic temperature and without any staining. Image stacks were aligned and processed by denoising, removal of ion beam milling artefacts and local charge imbalance. Images were assembled into a 3D volume and the major cell constituents were modelled. The data illustrate the power of the workflow to provide a detailed view of the internal architecture of the fully hydrated, close-to-native, entire HeLa cell.
In addition, we have studied the feasibility of combining cryo-FIB-SEM imaging with live-cell protein detection. We demonstrate that internalized gold particles can be visualized by detecting back scattered primary electrons at low kV while simultaneously acquiring signals from the secondary electron detector to image major cell features. Furthermore, gold-conjugated antibodies directed against RNA polymerase II could be observed in the endo-lysosomal pathway while labelling of the enzyme in the nucleus was not detected, a shortcoming likely due to the inadequacy between the size of the gold particles and the voxel size. With further refinements, this method promises to have a variety of applications where the goal is to localize cellular antigens while visualizing the entire native cell in three dimensions.","3-D Cryo-FIB-SEM,Immunolabeling,3D reconstruction and modelling",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Biochemistry & Molecular Biology,Biophysics,Cell Biology",,4.474,"CRYOELECTRON,MICROSCOPY,CELLULAR,ULTRASTRUCTURE,RECONSTRUCTION,TRANSPORT",JOURNAL OF STRUCTURAL BIOLOGY,,
86,A Reconfigurable Design for Omni-Adaptive Grasp Learning,5,3,4210-4217,"Wan Fang,Wang Haokun,Wu Jiyuan,Liu Yujia,Song Chaoyang,Ge Sheng","Wan F,Wang HK,Wu JY,Liu YJ,Song CY,Ge S",Song CY,10.1109/LRA.2020.2982059,Southern University of Science & Technology,"The engineering design of robotic grippers presents an ample design space for optimization towards robust grasping. In this letter, we investigate how learning method can be used to support the design reconfiguration of robotic grippers for grasping using a novel soft structure with omni-directional adaptation. We propose a gripper system that is reconfigurable in terms of the number and arrangement of the proposed finger, which generates a large number of possible design configurations. Such design reconfigurations with omni-adaptive fingers enables us to systematically investigate the optimal arrangement of the fingers towards robust grasping. Furthermore, we adopt a learning-based method as the baseline to benchmark the effectiveness of each design configuration. As a result, we found that the 3-finger radial configuration is suitable for space-saving and cost-effectiveness, achieving an average 96% grasp success rate on seen and novel objects selected from the YCB dataset. The 4-finger radial arrangement can be applied to cases that require a higher payload with even distribution. We achieved dimension reduction using the radial gripper design with the removal of z-axis rotation during grasping. We also reported the different outcomes with or without friction enhancement of the soft finger network.","Deep learning in grasping and manipulation,mechanism design,soft robot materials and design",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,"NETWORK,GRIPPER",IEEE ROBOTICS AND AUTOMATION LETTERS,http://arxiv.org/pdf/2003.01582,
87,Toward automatic C-arm positioning for standard projections in orthopedic surgery,15,7,1095-1105,"Kausch Lisa,Thomas Sarina,Kunze Holger,Privalov Maxim,Vetter Sven,Franke Jochen,Mahnken Andreas H.,Maier-Hein Lena,Maier-Hein Klaus","Kausch L,Thomas S,Kunze H,Privalov M,Vetter S,Franke J,Mahnken AH,Maier-Hein L,Maier-Hein K",Kausch L,10.1007/s11548-020-02204-0,Helmholtz Association,"Purpose Guidance and quality control in orthopedic surgery increasingly rely on intra-operative fluoroscopy using a mobile C-arm. The accurate acquisition of standardized and anatomy-specific projections is essential in this process. The corresponding iterative positioning of the C-arm is error prone and involves repeated manual acquisitions or even continuous fluoroscopy. To reduce time and radiation exposure for patients and clinical staff and to avoid errors in fracture reduction or implant placement, we aim at guiding-and in the long-run automating-this procedure. Methods In contrast to the state of the art, we tackle this inherently ill-posed problem without requiring patient-individual prior information like preoperative computed tomography (CT) scans, without the need of registration and without requiring additional technical equipment besides the projection images themselves. We propose learning the necessary anatomical hints for efficient C-arm positioning fromin silicosimulations, leveraging masses of 3D CTs. Specifically, we propose a convolutional neural network regression model that predicts 5 degrees of freedom pose updates directly from a first X-ray image. The method is generalizable to different anatomical regions and standard projections. Results Quantitative and qualitative validation was performed for two clinical applications involving two highly dissimilar anatomies, namely the lumbar spine and the proximal femur. Starting from one initial projection, the mean absolute pose error to the desired standard pose is iteratively reduced across different anatomy-specific standard projections. Acquisitions of both hip joints on 4 cadavers allowed for an evaluation on clinical data, demonstrating that the approach generalizes without retraining. Conclusion Overall, the results suggest the feasibility of an efficient deep learning-based automated positioning procedure, which is trained on simulations. Our proposed 2-stage approach for C-arm positioning significantly improves accuracy on synthetic images. In addition, we demonstrated that learning based on simulations translates to acceptable performance on real X-rays.","Pose estimation,Fluoroscopic imaging,C-arm positioning,Standard projection",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,,INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8286958,
88,Diffusion-weighted and spectroscopic MRI super-resolution using sparse representations,60,,,"Deka Bhabesh,Datta Sumit,Mullah Helal Uddin,Hazarika Suman","Deka B,Datta S,Mullah HU,Hazarika S",Deka B,10.1016/j.bspc.2020.101941,Tezpur University,"Diffusion-weighted magnetic resonance imaging (DW-MRI) and spectroscopic MRI (MRSI) are powerful diagnostic imaging tools as they provide complementary information over conventional MRI. Imaging is done at a low-resolution (LR) as the scanning time for high-resolution (HR) MR images would be very long and not practical besides being expensive for imaging. In this paper, we propose a novel single image super-resolution (SISR) scheme to improve spatial resolution of DW and MRS images. It is based on patch-wise sparse reconstruction of HR patches from LR feature patches utilizing a pair of learned overcomplete dictionaries. Reconstruction not only exploits the sparsity of MR image but also utilize the non-local self-similarity of patches of the input LR image as prior knowledge. Experiments are done using magnitude images of DW-MRI and MRSI along with a synthetic image. Performance evaluations based on different matrices besides visual analysis are carried out to validate and compare the obtained results with the state-of-the-art. It is observed that the proposed method clearly outperforms recent methods in terms of both quantitative and visual analysis. Finally, the proposed algorithm is also implemented using the GP-GPU based parallel hardware along with sequential implementations in order to showcase its potential for real clinical applications. (C) 2020 Elsevier Ltd. All rights reserved.","DW-MRI,MRSI,Sparse representation,Super-resolution,Overcomplete dictionary,Non-local self-similarity,GP-GPU",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,"SINGLE-IMAGE,SUPERRESOLUTION,LOW-RANK,RECONSTRUCTION,SIMILARITY,RESOLUTION",BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
89,Hybrid deep learning convolutional neural networks and optimal nonlinear support vector machine to detect presence of hemorrhage in retina,60,,,Lahmiri Salim,Lahmiri S,Lahmiri S,10.1016/j.bspc.2020.101978,Concordia University - Canada,"Diabetic retinopathy is a disorder that occurs in retina and it is caused by diabetes mellitus. Millions of people with diabetic retinopathy are expected to experience a loss of vision across the globe. Therefore, accurate automated-diagnosis systems are highly needed to help physicians in clinical milieu. Though many factors are effective in the diagnosis of diabetic retinopathy, presence of hemorrhage in retina remains one of the most significant factors. We present a three-stage hybrid system for classification of normal and abnormal digital retina images with hemorrhage. First, deep learning convolutional neural networks (CNN) is used for automatic features extraction. Second, the Student t-test is applied to the high dimensional features set extracted by CNN to select the best ten features. Third, the selected CNN-based features are fed to a nonlinear support vector machine (SVM) tuned by Bayes optimization to perform classification task. Three additional popular classifiers are also trained with features extracted by CNN and their performances are compared to that of the optimal nonlinear SVM including linear discriminant analysis (LDA), naive Bayes (NB), and k nearest neighbor (kNN). Each automated-diagnosis system is validated on a database composed of healthy and unhealthy digital retina images affected with various grades of hemorrhage. Experimental results from ten-fold cross-validation methodology show that CNN-SVM outperforms all other three reference systems; namely, CNN-LDA, CNN-NB, and CNN-kNN. Indeed, CNN-SVM system achieved 99.11%+/- 0.0101 accuracy, 99.14%+/- 0.0143 sensitivity, 99.08%+/- 0.0083 specificity, and 0.97.31%+/- 0.0381 area under curve (AUC) of the receiver operating characteristic. The proposed system is fast and accurate. (C) 2020 Elsevier Ltd. All rights reserved.","Retina hemorrhage,Diabetic retinopathy,Deep learning convolutional neural networks,Nonlinear support vector machine,Bayes optimization,Classification",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,3.992,"AUTOMATIC,DETECTION,FUNDUS,IMAGES,SYSTEM",BIOMEDICAL SIGNAL PROCESSING AND CONTROL,,
90,"Automated recognition by multiple convolutional neural networks of modern, fossil, intact and damaged pollen grains",140,,,"Bourel Benjamin,Marchant Ross,de Garidel-Thoron Thibault,Tetard Martin,Barboni Doris,Gally Yves,Beaufort Luc","Bourel B,Marchant R,de Garidel-Thoron T,Tetard M,Barboni D,Gally Y,Beaufort L",Bourel B,10.1016/j.cageo.2020.104498,Aix-Marseille Universite,"Pollen grains are valuable paleoclimate and paleovegetation proxies which require extensive knowledge of morphotypes and long acquisition time under the microscope. The abundance of damaged, folded, and broken pollen grains in the fossil register and sometimes also in modern soil and sediment samples, has so far prevented automation of pollen identification. Recent improvements in machine learning, however, have allowed reconsidering this approach. Here we present an automated approach which is capable of assisting palynologists with poorly preserved pollen samples. Called multi-CNNs, this approach is based on multiple convolutional neural networks (CNNs) integrated in a decision tree system. To test it, we built a system designed for three botanical families very common in the modern and fossil pollen assemblages of Eastern Africa, namely Amaranthaceae, Poaceae, and Cyperaceae. Our system was tested on stacked optical images of 8 pollen types (6 Amaranthaceae, 1 Poaceae, 1 Cyperaceae) using a training dataset of 1102 intact pollen grains and three validation datasets of intact (276 grains), damaged (223 grains), and fossil pollen (97 grains). We show that our system successfully recognizes intact, damaged, and fossil pollen grains with very low misclassification rates of 0%, 2.8%, and 3.7%, respectively. The use of augmentation on stacked optical images during the training increases classification accuracy. Following a palynologist's approach, our system allows grains without obvious characters to be classified into a class of high taxonomic level or as indeterminable pollen. This is the first software able to process grains with a wide range of taphonomical stages, which makes it the first truly applicable to automated pollen identification of fossil material.","Damaged pollen,Fossil pollen,Machine learning,Image analysis,Z-stacking,Amaranthaceae",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Geology",,3.696,"PALYNOLOGY,IDENTIFICATION,CLASSIFICATION,SYSTEM,HADAR,SHAPE,AFAR",COMPUTERS & GEOSCIENCES,https://hal-insu.archives-ouvertes.fr/insu-02953384/file/Bourel_et_al_CNN_pollen_Computers-and-Geosciences_2020.pdf,
91,Understanding and optimization of thin film nanocomposite membranes for reverse osmosis with machine learning,606,,,"Yeo Chester Su Hern,Xie Qian,Wang Xiaonan,Zhang Sui","Yeo CSH,Xie Q,Wang XN,Zhang S",Wang XN; Zhang S,10.1016/j.memsci.2020.118135,National University of Singapore,,"HIGH-PERFORMANCE,INTERFACIAL POLYMERIZATION,HIGH-FLUX,ZEOLITE NANOPARTICLES,CARBON NANOTUBES,GRAPHENE OXIDE,POLYAMIDE,DESALINATION,ROBUST,FABRICATION",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Polymer Science",,8.411,"HIGH-PERFORMANCE,INTERFACIAL,POLYMERIZATION,HIGH-FLUX,ZEOLITE,NANOPARTICLES,CARBON,NANOTUBES,GRAPHENE,OXIDE,POLYAMIDE,DESALINATION,ROBUST,FABRICATION",JOURNAL OF MEMBRANE SCIENCE,,
92,CNN-DMRI: A Convolutional Neural Network for Denoising of Magnetic Resonance Images,135,,57-63,"Tripathi Prasun Chandra,Bag Soumen","Tripathi PC,Bag S",Tripathi PC,10.1016/j.patrec.2020.03.036,Indian Institute of Technology System (IIT System),"Magnetic Resonance Images (MRI) are often contaminated by rician noise at the acquisition time. This type of noise typically deteriorates the performance of disease diagnosis by a human observer or an automated system. Thus, it is necessary to remove the rician noise from MRI scans as a preprocessing step. In this letter, we propose a novel Convolutional Neural Network (CNN), viz. CNN-DMRI, for denoising of MRI scans. The network uses a set of convolutions to separate the image features from the noise. The network also employs encoder-decoder structure for preserving the prominent features of the image while ignoring unnecessary ones. The training of the network is carried out in an end-to-end way by utilizing residual learning scheme. The performance of the proposed CNN has been tested qualitatively and quantitatively on one simulated and four real MRI datasets. Extensive experimental findings suggest that the proposed network can denoise MRI images effectively without losing crucial image details. (C) 2020 Elsevier B.V. All rights reserved.","Convolutional Neural Network,Denoising,Encoder-decoder,Magnetic Resonance Imaging,Residual learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,3.615,,PATTERN RECOGNITION LETTERS,,
93,Automated detection of Alzheimer?s disease using bi-directional empirical model decomposition,135,,106-113,"Koh Joel En Wei,Jahmunah Vicnesh,The-Hanh Pham,Oh Shu Lih,Ciaccio Edward J.,Acharya U. Rajendra,Yeong Chai Hong,Fabell Mohd Kamil Mohd,Rahmat Kartini,Vijayananthan Anushya","Koh JEW,Jahmunah V,Pham TH,Oh SL,Ciaccio EJ,Acharya UR,Yeong CH,Fabell MKM,Rahmat K,Vijayananthan A",Acharya UR,10.1016/j.patrec.2020.03.014,"Ngee Ann Polytech, Sch Engn, Singapore 599489, Singapore.",,"PSEUDO ZERNIKE MOMENT,NEURAL-NETWORK,CLASSIFICATION,DIAGNOSIS,MRI,SPECTRUM,FUSION",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,3.615,"PSEUDO,ZERNIKE,MOMENT,NEURAL-NETWORK,CLASSIFICATION,DIAGNOSIS,MRI,SPECTRUM,FUSION",PATTERN RECOGNITION LETTERS,,
94,Nonlinear vector decomposed neural network based EEG signal feature extraction and detection of seizure,76,,,"Mouleeshuwarapprabu R.,Kasthuri N.","Mouleeshuwarapprabu R,Kasthuri N",Mouleeshuwarapprabu R,10.1016/j.micpro.2020.103075,Kongu Engineering College,"Electroencephalography is one of the important medical methods to evaluate and treat neurophysiology to combat disease related to seizure. The automatic seizure detection system aims to provide a balanced mechanism by excavating deep knowledge of the basic signal and kinetic domains. Contingent alert is given to initiate treatment to reduce the risk of injury in patients with epilepsy and to overcome contingencies. Moreover, the multi-channel Electroencephalogram (EEG) data of seizure detection in conventional machine learning algorithms cannot effectively accommodate both global and spatial information. Therefore in this work proposed a Nonlinear Vector Decomposed Neural Network (NVDN) to detect the seizure from EEG signal. The proposed NVDN based seizure detection system consist of three major stages they are as follows i) EEG preprocessing ii) Feature Extraction and iii) NVDN Classification. In this work, the NVDN technique is applied to improve the accuracy of seizure detection after using frequency domain feature to obtain the results from EEG waves. The performance of the proposed system is validate through MATLAB simulation. The results of the simulation show that the proposed NVDN method is able to effectively detect the seizure with a sensitivity of 94.7%. Specificity of 94.1% and accuracy 95.60%. As compared with conventional methods the proposed system achieve high detecting ratio. (C) 2020 Elsevier B.V. All rights reserved.","Elliptic seizure,Wavelet transform,Frequency domain,Nonlinear Vector Decomposition",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering",,1.427,DIAGNOSIS,MICROPROCESSORS AND MICROSYSTEMS,,
95,Machine learning and radiomic phenotyping of lower grade gliomas: improving survival prediction,30,7,3834-3842,"Choi Yoon Seong,Ahn Sung Soo,Chang Jong Hee,Kang Seok-Gu,Kim Eui Hyun,Kim Se Hoon,Jain Rajan,Lee Seung-Koo","Choi YS,Ahn SS,Chang JH,Kang SG,Kim EH,Kim SH,Jain R,Lee SK",Ahn SS,10.1007/s00330-020-06737-5,Yonsei University,"Background and purpose Recent studies have highlighted the importance of isocitrate dehydrogenase (IDH) mutational status in stratifying biologically distinct subgroups of gliomas. This study aimed to evaluate whether MRI-based radiomic features could improve the accuracy of survival predictions for lower grade gliomas over clinical andIDHstatus. Materials and methods Radiomic features (n = 250) were extracted from preoperative MRI data of 296 lower grade glioma patients from databases at our institutional (n = 205) and The Cancer Genome Atlas (TCGA)/The Cancer Imaging Archive (TCIA) (n = 91) datasets. For predicting overall survival, random survival forest models were trained with radiomic features; non-imaging prognostic factors including age, resection extent, WHO grade, andIDHstatus on the institutional dataset, and validated on the TCGA/TCIA dataset. The performance of the random survival forest (RSF) model and incremental value of radiomic features were assessed by time-dependent receiver operating characteristics. Results The radiomics RSF model identified 71 radiomic features to predict overall survival, which were successfully validated on TCGA/TCIA dataset (iAUC, 0.620; 95% CI, 0.501-0.756). Relative to the RSF model from the non-imaging prognostic parameters, the addition of radiomic features significantly improved the overall survival prediction accuracy of the random survival forest model (iAUC, 0.627 vs. 0.709; difference, 0.097; 95% CI, 0.003-0.209). Conclusion Radiomic phenotyping with machine learning can improve survival prediction over clinical profile and genomic data for lower grade gliomas.","Glioma,Machine learning,Prognosis,Survival",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,4.87,"PATIENT,SURVIVAL,GENOMIC,ANALYSIS,GLIOBLASTOMA,IDH1,PROGRESSION,MUTATIONS,PROGNOSIS,PATTERNS,SYSTEM",EUROPEAN RADIOLOGY,,
96,OCRNN: An orthogonal constrained recurrent neural network for sleep analysis based on EEG data,104,,,"Zhu Fangqi,Liang Qilian","Zhu FQ,Liang QL",Zhu FQ,10.1016/j.adhoc.2020.102178,University of Texas System,"This paper introduced an end-to-end mixed deep learning model for automatic sleep analysis based on the EEG signal. Unlike some existing machine learning models for EEG analysis, we did not rely on any hand-crafted feature engineering and elaborate pipeline design. Furthermore, apart from some existing deep learning frameworks based on some off-the-self existing modules, we introduced the orthogonal constrained recurrent neural network (OCRNN) as the downstream module after the spatial-temporal expansion and representation provided by the one dimensional convolutional neural networks. We evaluated our model using the EEG-based sleep datasets for sleep stage scoring. We compared the performances of four types of RNN frameworks, where three of them are OCRNNs. The results show that OCRNN can achieve competitive better F1 score, accuracy and AUC score compared to the previous baseline results. Moreover, our model (orRNN and pdRNN) can achieve the above results with less number of parameters and less number of training epochs, which demonstrate its potential usage to launch approximate real-time medical diagnosis. (C) 2020 Elsevier B.V. All rights reserved.","EEG,Sleep analysis,Time-series,RNN,Orthogonal constraints",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Telecommunications",,3.62,CLASSIFICATION,AD HOC NETWORKS,,
97,Device and Circuit Architectures for In-Memory Computing,2,7,,"Ielmini Daniele,Pedretti Giacomo","Ielmini D,Pedretti G",Ielmini D,10.1002/aisy.202000040,Polytechnic University of Milan,"With the rise in artificial intelligence (AI), computing systems are facing new challenges related to the large amount of data and the increasing burden of communication between the memory and the processing unit. In-memory computing (IMC) appears as a promising approach to suppress the memory bottleneck and enable higher parallelism of data processing, thanks to the memory array architecture. As a result, IMC shows a better throughput and lower energy consumption with respect to the conventional digital approach, not only for typical AI tasks, but also for general-purpose problems such as constraint satisfaction problems (CSPs) and linear algebra. Herein, an overview of IMC is provided in terms of memory devices and circuit architectures. First, the memory device technologies adopted for IMC are summarized, focusing on both charge-based memories and emerging devices relying on electrically induced material modification at the chemical or physical level. Then, the computational memory programming and the corresponding device nonidealities are described with reference to offline and online training of IMC circuits. Finally, array architectures for computing are reviewed, including typical architectures for neural network accelerators, content addressable memory (CAM), and novel circuit topologies for general-purpose computing with low complexity.","artificial intelligence,in-memory computing,machine learning,memories,neural networks",Review,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Automation & Control Systems,Computer Science,Robotics",,,"PHASE-CHANGE,MATERIALS,RANDOM-ACCESS,MEMORY,CONTENT-ADDRESSABLE,MEMORY,RESISTIVE,SWITCHES,LOGIC,OPERATIONS,NEURAL-NETWORKS,CROSSBAR,ARRAY,PART,I,OXIDE,RESISTANCE",ADVANCED INTELLIGENT SYSTEMS,https://re.public.polimi.it/bitstream/11311/1138384/1/aisy20_invited.pdf,
98,Convolutional descriptors aggregation via cross-net for skin lesion recognition,92,,,"Yu Zhen,Jiang Feng,Zhou Feng,He Xinzi,Ni Dong,Chen Siping,Wang Tianfu,Lei Baiying","Yu Z,Jiang F,Zhou F,He XZ,Ni D,Chen SP,Wang TF,Lei BY",Lei BY,10.1016/j.asoc.2020.106281,Shenzhen University,"Malignant melanoma is one of the rare but deadliest types of skin cancers. Clinically, the early diagnosis of this disease is based on human visual inspection with dermoscopy imaging. However, human observations are subjective and prone to errors due to huge variations within dermoscopy images. To address it, we propose a framework for automatic skin lesion recognition using cross-net based aggregation of multiple convolutional networks. The output activation maps of each network are extracted as indicator maps to select the local deep convolutional descriptors (i.e., local patterns and color) in dermoscopy images. Also, this map of a convolutional layer captures the semantic regions of the input image and localizes the target object. These selected features are aggregated into an informative feature map, which are potentially better preserved in the convolutional feature maps. Finally, we use Fisher vector (FV) to encode the selected features. Extensive experiments demonstrate the effectiveness of our proposed method. Comparing with aggregation strategy using pooling approaches, the proposed method learns more robust and discriminative representations based on the publicly available skin lesion challenge datasets from the International Symposium on Biomedical Imaging (ISBI) 2016 and 2017. (C) 2020 Published by Elsevier B.V.","Dermoscopy image,Melanoma recognition,Residual network,Cross-net model,Deep learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,6.607,"IMAGE,CLASSIFICATION,MALIGNANT-MELANOMA,ABCD,RULE,COLOR,DERMATOSCOPY",APPLIED SOFT COMPUTING,,
99,Prediction method of bridge static load test results based on Kriging model,214,,,"Lu Pengzhen,Xu Zijie,Chen Yangrui,Zhou Yutao","Lu PZ,Xu ZJ,Chen YR,Zhou YT",Chen YR,10.1016/j.engstruct.2020.110641,Zhejiang University of Technology,"To solve the problems of expensive bridge load test cost, traffic congestion influence, and damage to bridges by load test, the dynamic experimental results based on the inexpensive, safety inspection data and maintenance process of existing bridges are presented in this paper. The Kriging model is used for the intelligent analysis and prediction of the actual stiffnesses of the existing bridges as well as for the high-accuracy prediction of their static load experimental results. In order to achieve the above objectives, a sensitivity coefficient is selected based on the sensitivity analysis of the whole bridge, and the Kriging model is established and optimized to forecast and modify sensitive parameters for the high-precision correction of the model. Relative to other machine learning algorithm models, the Kriging model has higher parameter sensitivity and reliability. To verify the correctness and feasibility of the above mentioned methods, a continuous rigid frame bridge is selected as an engineering test object, and ANSYS, a finite element software, is used for modeling and analysis. The research results show that the finite element model modification method based on the Kriging process can employ inexpensive and convenient bridge dynamic load tests to modify the actual parameters of the finite element model in the Kriging process of bridges; consequently, the test results of static load experiments can be more accurately predicted. The correction results obtained by the Kriging model are in good agreement with test results and exhibit high precision and reliability; moreover, the method is less costly and good safety, and has minimal influence on traffic. Moreover, in view of the potential for conducting a large number of bridge mechanical performance evaluations on all levels and the effective simulation and performance prediction of existing bridge project maintenance decisions, the proposed method affords a new train of thought.","Bridge engineering,Dynamic load test,Kriging process,Finite element model modification,Regression analysis,Static load forecasting",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Engineering,,4.795,"DAMAGE,DETECTION,OPTIMIZATION,FREQUENCY",ENGINEERING STRUCTURES,,
100,A deep learning based medical image segmentation technique in Internet-of-Medical-Things domain,108,,135-144,"Wang Eric Ke,Chen Chien-Ming,Hassan Mohammad Mehedi,Almogren Ahmad","Wang EK,Chen CM,Hassan MM,Almogren A",Hassan MM,10.1016/j.future.2020.02.054,King Saud University,"Medical Image Segmentation is the process of automatic or semi-automatic detection of boundaries within a 2D or 3D image in Internet-of-Medical-Things (IoMT) domain. The main difficulty of medical image segmentation is the high variability in medical images. For example, CT images contain a large amount of noise, and complex boundaries. In this paper, we propose an adaptive fully dense(AFD) neural network for CT image segmentation. By adding the horizontal connections in UNet structure, it can extract various features from all layers adaptively. And it use ensemble training for the output to extract more edge information in the multiple rounds training. We have validated our method on two data sets, a natural scene image data set and a liver cancer CT image data set. The experimental results demonstrate that it performs better than state-of-the-art segmentation methods. And our method yields superior segmentation results for CT images with complex boundaries. (C) 2020 Elsevier B.V. All rights reserved.","Internet-of-Medical-Things,Medical image segmentation,CT image observation,Object detection,Deep learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,6.644,,FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE,,
