,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Automatic diagnosis of macular diseases from OCT volume based on its two-dimensional feature map and convolutional neural network with attention mechanism,25,9,,"Sun Yankui,Zhang Haoran,Yao Xianlin","Sun YK,Zhang HR,Yao XL",Sun YK,10.1117/1.JBO.25.9.096004,Tsinghua University,"Significance: Automatic and accurate classification of three-dimensional (3-D) retinal optical coherence tomography (OCT) images is essential for assisting ophthalmologist in the diagnosis and grading of macular diseases. Therefore, more effective OCT volume classification for automatic recognition of macular diseases is needed.
Aim: For OCT volumes in which only OCT volume-level labels are known, OCT volume classifiers based on its global feature and deep learning are designed, validated, and compared with other methods.
Approach: We present a general framework to classify OCT volume for automatic recognizing macular diseases. The architecture of the framework consists of three modules: B-scan feature extractor, two-dimensional (2-D) feature map generation, and volume-level classifier. Our architecture could address OCT volume classification using two 2-D image machine learning classification algorithms. Specifically, a convolutional neural network (CNN) model is trained and used as a B-scan feature extractor to construct a 2-D feature map of an OCT volume and volume-level classifiers such as support vector machine and CNN with/without attention mechanism for 2-D feature maps are described.
Results: Our proposed methods are validated on the publicly available Duke dataset, which consists of 269 intermediate age-related macular degeneration (AMD) volumes and 115 normal volumes. Fivefold cross-validation was done, and average accuracy, sensitivity, and specificity of 98.17%, 99.26%, and 95.65%, respectively, are achieved. The experiments show that our methods outperform the state-of-the-art methods. Our methods are also validated on our private clinical OCT volume dataset, consisting of 448 AMD volumes and 462 diabetic macular edema volumes.
Conclusions: We present a general framework of OCT volume classification based on its 2-D feature map and CNN with attention mechanism and describe its implementation schemes. Our proposed methods could classify OCT volumes automatically and effectively with high accuracy, and they are a potential practical tool for screening of ophthalmic diseases from OCT volume. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","optical coherence tomography,convolutional neural network,transfer learning,image classification,attention mechanism",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,"OPTICAL,COHERENCE,TOMOGRAPHY,DEGENERATION,CLASSIFICATION,IMAGES,EDEMA",JOURNAL OF BIOMEDICAL OPTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7493033,
2,Predicting complications of diabetes mellitus using advanced machine learning algorithms,27,9,1343-1351,"Ljubic Branimir,Hai Ameen Abdel,Stanojevic Marija,Diaz Wilson,Polimac Daniel,Pavlovski Martin,Obradovic Zoran","Ljubic B,Hai AA,Stanojevic M,Diaz W,Polimac D,Pavlovski M,Obradovic Z",Obradovic Z,10.1093/jamia/ocaa120,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Objective: We sought to predict if patients with type 2 diabetes mellitus (DM2) would develop 10 selected complications. Accurate prediction of complications could help with more targeted measures that would prevent or slow down their development.
Materials and Methods: Experiments were conducted on the Healthcare Cost and Utilization Project State Inpatient Databases of California for the period of 2003 to 2011. Recurrent neural network (RNN) long short-term memory (LSTM) and RNN gated recurrent unit (GRU) deep learning methods were designed and compared with random forest and multilayer perceptron traditional models. Prediction accuracy of selected complications were compared on 3 settings corresponding to minimum number of hospitalizations between diabetes diagnosis and the diagnosis of complications.
Results: The diagnosis domain was used for experiments. The best results were achieved with RNN GRU model, followed by RNN LSTM model. The prediction accuracy achieved with RNN GRU model was between 73% (myocardial infarction) and 83% (chronic ischemic heart disease), while accuracy of traditional models was between 66% - 76%.
Discussion: The number of hospitalizations was an important factor for the prediction accuracy. Experiments with 4 hospitalizations achieved significantly better accuracy than with 2 hospitalizations. To achieve improved accuracy deep learning models required training on at least 1000 patients and accuracy significantly dropped if training datasets contained 500 patients. The prediction accuracy of complications decreases over time period. Considering individual complications, the best accuracy was achieved on depressive disorder and chronic ischemic heart disease.
Conclusions: The RNN GRU model was the best choice for electronic medical record type of data, based on the achieved results.","diabetes mellitus,diabetes mellitus complications,deep learning,machine learning,RNN models",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,MANAGEMENT,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647294,
3,Resilience of clinical text de-identified with ,27,9,1374-1382,"Carrell David S.,Malin Bradley A.,Cronkite David J.,Aberdeen John S.,Clark Cheryl,Li Muqun (Rachel),Bastakoty Dikshya,Nyemba Steve,Hirschman Lynette","Carrell DS,Malin BA,Cronkite DJ,Aberdeen JS,Clark C,Li MQ,Bastakoty D,Nyemba S,Hirschman L",Carrell DS,10.1093/jamia/ocaa095,Kaiser Permanente,"Objective: Effective, scalable de-identification of personally identifying information (PII) for information-rich clinical text is critical to support secondary use, but no method is 100% effective. The hiding-in-plain-sight (HIPS) approach attempts to solve this ""residual PII problem."" HIPS replaces PII tagged by a de-identification system with realistic but fictitious (resynthesized) content, making it harder to detect remaining unredacted PII.
Materials and Methods: Using 2000 representative clinical documents from 2 healthcare settings (4000 total), we used a novel method to generate 2 de-identified 100-document corpora (200 documents total) in which PII tagged by a typical automated machine-learned tagger was replaced by HIPS-resynthesized content. Four readers conducted aggressive reidentification attacks to isolate leaked PII: 2 readers from within the originating institution and 2 external readers.
Results: Overall, mean recall of leaked PII was 26.8% and mean precision was 37.2%. Mean recall was 9% (mean precision = 37%) for patient ages, 32% (mean precision = 26%) for dates, 25% (mean precision = 37%) for doctor names, 45% (mean precision = 55%) for organization names, and 23% (mean precision = 57%) for patient names. Recall was 32% (precision = 40%) for internal and 22% (precision =33%) for external readers.
Discussion and Conclusions: Approximately 70% of leaked PII ""hiding"" in a corpus de-identified with HIPS resynthesis is resilient to detection by human readers in a realistic, aggressive reidentification attack scenariomore than double the rate reported in previous studies but less than the rate reported for an attack assisted by machine learning methods.","de-identification,privacy,confidentiality,electronic health records,natural language processing,biomedical research",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,,"OF-THE-ART,HEALTH,INFORMATION,ANONYMIZATION,NARRATIVES,SYSTEM,RECORD",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://academic.oup.com/jamia/article-pdf/27/9/1374/34153350/ocaa095.pdf,
4,Risk prediction of delirium in hospitalized patients using machine learning: An implementation and prospective evaluation study,27,9,1383-1392,"Jauk Stefanie,Kramer Diether,Grossauer Birgit,Rienmueller Susanne,Avian Alexander,Berghold Andrea,Leodolter Werner,Schulz Stefan","Jauk S,Kramer D,Grossauer B,Rienmuller S,Avian A,Berghold A,Leodolter W,Schulz S",Jauk S,10.1093/jamia/ocaa113,Medical University of Graz,"Objective: Machine learning models trained on electronic health records have achieved high prognostic accuracy in test datasets, but little is known about their embedding into clinical workflows. We implemented a random forest-based algorithm to identify hospitalized patients at high risk for delirium, and evaluated its performance in a clinical setting.
Materials and Methods: Delirium was predicted at admission and recalculated on the evening of admission. The defined prediction outcome was a delirium coded for the recent hospital stay. During 7 months of prospective evaluation, 5530 predictions were analyzed. In addition, 119 predictions for internal medicine patients were compared with ratings of clinical experts in a blinded and nonblinded setting.
Results: During clinical application, the algorithm achieved a sensitivity of 74.1% and a specificity of 82.2%. Discrimination on prospective data (area under the receiver-operating characteristic curve = 0.86) was as good as in the test dataset, but calibration was poor. The predictions correlated strongly with delirium risk perceived by experts in the blinded (r = 0.81) and nonblinded ( r = 0.62) settings. A major advantage of our setting was the timely prediction without additional data entry.
Discussion: The implemented machine learning algorithm achieved a stable performance predicting delirium in high agreement with expert ratings, but improvement of calibration is needed. Future research should evaluate the acceptance of implemented machine learning algorithms by health professionals.
Conclusions: Our study provides new insights into the implementation process of a machine learning algorithm into a clinical workflow and demonstrates its predictive power for delirium.","Machine learning,prospective studies,delirium,electronic health records,clinical decision support",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"BIG,DATA,MODELS,ANALYTICS",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647341,
5,Generating sequential electronic health records using dual adversarial autoencoder,27,9,1411-1419,"Lee Dongha,Yu Hwanjo,Jiang Xiaoqian,Rogith Deevakar,Gudala Meghana,Tejani Mubeen,Zhang Qiuchen,Xiong Li","Lee D,Yu H,Jiang XQ,Rogith D,Gudala M,Tejani M,Zhang QC,Xiong L",Yu H,10.1093/jamia/ocaa119,Pohang University of Science & Technology (POSTECH),"Objective: Recent studies on electronic health records (EHRs) started to learn deep generative models and synthesize a huge amount of realistic records, in order to address significant privacy issues surrounding the EHR. However, most of them only focus on structured records about patients' independent visits, rather than on chronological clinical records. In this article, we aim to learn and synthesize realistic sequences of EHRs based on the generative autoencoder.
Materials and Methods: We propose a dual adversarial autoencoder (DAAE), which learns set-valued sequences of medical entities, by combining a recurrent autoencoder with 2 generative adversarial networks (GANs). DAAE improves the mode coverage and quality of generated sequences by adversarially learning both the continuous latent distribution and the discrete data distribution. Using the MIMIC-III (Medical Information Mart for Intensive Care-III) and UT Physicians clinical databases, we evaluated the performances of DAAE in terms of predictive modeling, plausibility, and privacy preservation.
Results: Our generated sequences of EHRs showed the comparable performances to real data for a predictive modeling task, and achieved the best score in plausibility evaluation conducted by medical experts among all baseline models. In addition, differentially private optimization of our model enables to generate synthetic sequences without increasing the privacy leakage of patients' data.
Conclusions: DAAE can effectively synthesize sequential EHRs by addressing its main challenges: the synthetic records should be realistic enough not to be distinguished from the real records, and they should cover all the training patients to reproduce the performance of specific downstream tasks.","electornic health records (EHRs),sequential data generation,generative adversarial networks (GANs),generative autoencoder,differential privacy",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647348,
6,Image-to-image translation for automatic ink removal in whole slide images,7,5,,"Jiang Jun,Prodduturi Naresh,Chen David,Gu Qiangqiang,Flotte Thomas,Feng Qianjin,Hart Steven","Jiang J,Prodduturi N,Chen D,Gu QQ,Flotte T,Feng QJ,Hart S",Hart S,10.1117/1.JMI.7.5.057502,Mayo Clinic,"Purpose: Deep learning models are showing promise in digital pathology to aid diagnoses. Training complex models requires a significant amount and diversity of well-annotated data, typically housed in institutional archives. These slides often contain clinically meaningful markings to indicate regions of interest. If slides are scanned with the ink present, then the downstream model may end up looking for regions with ink before making a classification. If scanned without the markings, the information regarding where the relevant regions are located is lost. A compromise solution is to scan the slide with the annotations present but digitally remove them.
Approach: We proposed a straightforward framework to digitally remove ink markings from whole slide images using a conditional generative adversarial network based on Pix2Pix.
Results: The peak signal-to-noise ratio increased 30%, structural similarity index increased 20%, and visual information fidelity increased 200% relative to previous methods.
Conclusions: When comparing our digital removal of marked images with rescans of clean slides, our method qualitatively and quantitatively exceeds current benchmarks, opening the possibility of using archived clinical samples as resources to fuel the next generation of deep learning models for digital pathology. (C) 2020 Society of Photo Optical Instrumentation Engineers (SPIE)","ink removal,whole slide image,image to image translation",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"QUALITY,ASSESSMENT,DIGITAL,PATHOLOGY",JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7567133,
7,Spatiotemporal feature extraction and classification of Alzheimer's disease using deep learning 3D-CNN for fMRI data,7,5,,"Parmar Harshit,Nutter Brian,Long Rodney,Antani Sameer,Mitra Sunanda","Parmar H,Nutter B,Long R,Antani S,Mitra S",Parmar H,10.1117/1.JMI.7.5.056001,Texas Tech University System,"Purpose: Through the last three decades, functional magnetic resonance imaging (fMRI) has provided immense quantities of information about the dynamics of the brain, functional brain mapping, and resting-state brain networks. Despite providing such rich functional information, fMRI is still not a commonly used clinical technique due to inaccuracy involved in analysis of extremely noisy data. However, ongoing developments in deep learning techniques suggest potential improvements and better performance in many different domains. Our main purpose is to utilize the potentials of deep learning techniques for fMRI data for clinical use.
Approach: We present one such synergy of fMRI and deep learning, where we apply a simplified yet accurate method using a modified 3D convolutional neural networks (CNN) to resting-state fMRI data for feature extraction and classification of Alzheimer's disease (AD). The CNN is designed in such a way that it uses the fMRI data with much less preprocessing, preserving both spatial and temporal information.
Results: Once trained, the network is successfully able to classify between fMRI data from healthy controls and AD subjects, including subjects in the mild cognitive impairment (MCI) stage. We have also extracted spatiotemporal features useful for classification.
Conclusion: This CNN can detect and differentiate between the earlier and later stages of MCI and AD and hence, it may have potential clinical applications in both early detection and better diagnosis of Alzheimer's disease. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","3D convolutional neural networks,Alzheimer's disease,clinical functional magnetic resonance imaging,deep learning,spatiotemporal functional magnetic resonance imaging features",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"BRAIN,ACTIVATION,NETWORKS,CONTRAST,ECHO",JOURNAL OF MEDICAL IMAGING,https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-7/issue-5/056001/Spatiotemporal-feature-extraction-and-classification-of-Alzheimers-disease-using-deep/10.1117/1.JMI.7.5.056001.pdf,
8,Simulating realistic fetal neurosonography images with appearance and growth change using cycle-consistent adversarial networks and an evaluation,7,5,,"Xu Yangdi,Lee Lok Hin,Drukker Lior,Yaqub Mohammad,Papageorghiou Aris T.,Noble Alison J.","Xu YD,Lee LH,Drukker L,Yaqub M,Papageorghiou AT,Noble AJ",Xu YD,10.1117/1.JMI.7.5.057001,University of Oxford,"Purpose: We present an original method for simulating realistic fetal neurosonography images specifically generating third-trimester pregnancy ultrasound images from second-trimester images. Our method was developed using unpaired data, as pairwise data were not available. We also report original insights on the general appearance differences between second- and third-trimester fetal head transventricular (TV) plane images.
Approach: We design a cycle-consistent adversarial network (Cycle-GAN) to simulate visually realistic third-trimester images from unpaired second- and third-trimester ultrasound images. Simulation realism is evaluated qualitatively by experienced sonographers who blindly graded real and simulated images. A quantitative evaluation is also performed whereby a validated deeplearning-based image recognition algorithm (ScanNav (R) ) acts as the expert reference to allow hundreds of real and simulated images to be automatically analyzed and compared efficiently.
Results: Qualitative evaluation shows that the human expert cannot tell the difference between real and simulated third-trimester scan images. 84.2% of the simulated third-trimester images could not be distinguished from the real third-trimester images. As a quantitative baseline, on 3000 images, the visibility drop of the choroid, CSP, and mid-line falx between real second- and real third-trimester scans was computed by ScanNav (R) and found to be 72.5%, 61.5%, and 67%, respectively. The visibility drop of the same structures between real second-trimester and simulated third-trimester was found to be 77.5%, 57.7%, and 56.2%, respectively. Therefore, the real and simulated third-trimester images were consider to be visually similar to each other. Our evaluation also shows that the third-trimester simulation of a conventional GAN is much easier to distinguish, and the visibility drop of the structures is smaller than our proposed method.
Conclusions: The results confirm that it is possible to simulate realistic third-trimester images from second-trimester images using a modified Cycle-GAN, which may be useful for deep learning researchers with a restricted availability of third-trimester scans but with access to ample second trimester images. We also show convincing simulation improvements, both qualitatively and quantitatively, using the Cycle-GAN method compared with a conventional GAN. Finally, the use of a machine learning-based reference (in the case ScanNav (R)) for large-scale quantitative image analysis evaluation is also a first to our knowledge. (C) 2020 Society of Photo Optical Instrumentation Engineers (SPIE)","second-trimester scan,third-trimester scan,transventricular plane,realistic simulation,cycle-consistent adversarial network,quantitative evaluation",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,,JOURNAL OF MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7492851,
9,Fusion of multiple segmentations of medical images using OV(2)ASSION and Deep Learning methods: Application to CT-Scans for tumoral kidney,124,,,"Corbat Lisa,Henriet Julien,Chaussy Yann,Lapayre Jean-Christophe","Corbat L,Henriet J,Chaussy Y,Lapayre JC",Corbat L,10.1016/j.compbiomed.2020.103928,Centre National de la Recherche Scientifique (CNRS),"Nephroblastoma is the most common kidney tumour in children. Its diagnosis is based on imagery. In the SAIAD project, we have designed a platform for optimizing the segmentation of deformed kidney and tumour with a small dataset, using Artificial Intelligence methods. These patient's structures segmented by separate tools and processes must then be fused to obtain a unique numerical 3D representation. However, when aggregating these structures into a final segmentation, conflicting pixels may appear. These conflicts can be solved by IA techniques. This paper presents a synthesis of our segmentation contribution in the SAIAD project and a new fusion method. The segmentation method uses the FCN-8s network with the OV(2)ASSION training method, which allows segmentation by patient and overcomes the limited dataset. This new fusion method combines the segmentations of the previously performed structures, using a simple and efficient network combined with the OV(2)ASSION training method as well, in order to manage eventual conflicting pixels. These segmentation and fusion methods were evaluated on pathological kidney and tumour structures of 14 patients affected by nephroblastoma, included in the final dataset of the SAIAD project. They are compared with other methods adapted from the literature. The results demonstrate the effectiveness of our training method coupled with the FCN-8s network in the segmentation process with more patients, and in the case of the fusion process, its effectiveness coupled with a common network, in resolving the conflicting pixels and its ability to improve the resulting segmentations.","Medical image segmentation,Medical image fusion,Deep learning,Conflict management,Cancer tumour",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"NETWORK,MODEL",COMPUTERS IN BIOLOGY AND MEDICINE,https://hal.archives-ouvertes.fr/hal-02993842/file/c294e04d-3d9c-491a-9668-0e1ed1c9e81c-author.pdf,
10,Radiomics analysis using stability selection supervised component analysis for right-censored survival data,124,,,"Yan Kang K.,Wang Xiaofei,Lam Wendy W. T.,Vardhanabhuti Varut,Lee Anne W. M.,Pang Herbert H.","Yan KK,Wang XF,Lam WWT,Vardhanabhuti V,Lee AWM,Pang HH",Pang HH,10.1016/j.compbiomed.2020.103959,University of Hong Kong,"Radiomics is a newly emerging field that involves the extraction of massive quantitative features from biomedical images by using data-characterization algorithms. Distinctive imaging features identified from biomedical images can be used for prognosis and therapeutic response prediction, and they can provide a noninvasive approach for personalized therapy. So far, many of the published radiomics studies utilize existing out of the box algorithms to identify the prognostic markers from biomedical images that are not specific to radiomics data. To better utilize biomedical images, we propose a novel machine learning approach, stability selection supervised principal component analysis (SSSuperPCA) that identifies stable features from radiomics big data coupled with dimension reduction for right-censored survival outcomes.
The proposed approach allows us to identify a set of stable features that are highly associated with the survival outcomes in a simple yet meaningful manner, while controlling the per-family error rate. We evaluate the performance of SSSuperPCA using simulations and real data sets for non-small cell lung cancer and head and neck cancer, and compare it with other machine learning algorithms.
The results demonstrate that our method has a competitive edge over other existing methods in identifying the prognostic markers from biomedical imaging data for the prediction of right-censored survival outcomes.","Bioinformatics,Data mining,Dimensionality reduction,Machine learning,Radiomics",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"RANDOM,FORESTS,PREDICTION,REGULARIZATION,CLASSIFICATION,BIOMARKER,FEATURES,TEXTURE,CANCER,MODELS",COMPUTERS IN BIOLOGY AND MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7501167,
11,AUTOMATED CLASSIFICATION FOR BRAIN MRIS BASED ON 2D MF-DFA METHOD,28,6,,"Wang Jian,Shao Wei,Kim Junseok","Wang J,Shao W,Kim J",Kim J,10.1142/S0218348X20501091,Korea University,"Magnetic resonance image (MRI) is an important tool to diagnose human diseases effectively. It is very important for research and clinical application to classify the normal and abnormal human brain MRI images automatically. In this paper, an accurate and efficient technique is proposed to extract features of MRIs and classify these images into normal and abnormal categories. We use two-dimensional multifractal detrended fluctuation analysis (2D MF-DFA) to obtain image features. These features are the local generalized Hurst exponents calculated by 2D MF-DFA. In this regard, the values of Hurst exponents are given as the training input vector and are taken to the classifiers. We use k-nearest neighbor (k-NN) and support vector machine (SVM) to classify a specific brain MRI as normal or glioma affected. For SVM, we apply the leave-one-out cross-validation method for experimental verification. The 2D MF-DFA-SVM system achieved accuracy, sensitivity, and specificity of 99.82% +/- 0.07, 100%, and 99.81% +/- 0.09, respectively. The 2D MF-DFA-k-NN system achieved accuracy, sensitivity, and specificity of 96%, 92.59%, and 100%, respectively. We find that when performing binary classification for brain MRIs, the SVM is superior to k-NN. In addition, our experimental results indicate that the proposed 2D MF-DFA-SVM achieved excellent outcomes compared to those of the previous works. The proposed system is a promising system to clinical use.","Brain MRI Image,2D MF-DFA,Classification,SVM,k-NN",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE","Mathematics,Science & Technology - Other Topics",,3.165,"TUMOR,CLASSIFICATION,IMAGES,SEGMENTATION,OPTIMIZATION,TRANSFORM",FRACTALS-COMPLEX GEOMETRY PATTERNS AND SCALING IN NATURE AND SOCIETY,,
12,Materials genome evolution of surface plasmon resonance characteristics of Au nanoparticles decorated ZnO nanorods,8,9,,"Yen Sheng-Che,Chen Yu-Lin,Su Yen-Hsun","Yen SC,Chen YL,Su YH",Su YH,10.1063/5.0023540,National Cheng Kung University,"The effect of surface plasmon resonance (SPR) from noble metal nanostructures such as gold nanoparticles (Au NPs) has been proposed to promote the generation of energetic hot electrons as well as boosting resonant energy transfer, thereby resulting in significantly enhancing solar-light harvesting and energy conversion efficiency. Herein, Au NPs decorated zinc oxide nanorods with plasmonic metal-semiconductor heterostructures have been synthesized through UV/Ozone treatment. Absorption, light-to-plasmon conversion efficiency, plasmon-to-hot electron conversion efficiency, and quality (Q)-factor of Au@ZnO nanocomposites are further characterized in order to understand the related SPR effect from various aspects. Simultaneously, the use of machine learning (ML) as an artificial intelligence data-driven method to derive an alternative predictive model for evaluating the relationship between synthesis and properties of materials has been adopted. In this regard, we collect only a limited supply of experimental dataset as training data to establish the predictive model with an artificial neural network incorporating genetic algorithm. According to the results from experimental datasets and the proposed predictive model, our analysis has revealed that the conversion efficiency and Q-factor associated with the SPR effect from Au@ZnO nanocomposites can be efficiently evaluated through ML, which has potential application in plasmon-sensitized solar cells and plasmonic lasers in the future.","QUALITY FACTOR,NANOSTRUCTURES",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Science & Technology - Other Topics,Materials Science,Physics",,4.841,"QUALITY,FACTOR,NANOSTRUCTURES",APL MATERIALS,https://aip.scitation.org/doi/pdf/10.1063/5.0023540,
13,Quantitative detection of fatty acid value during storage of wheat flour based on a portable near-infrared (NIR) spectroscopy system,109,,,"Jiang Hui,Liu Tong,Chen Quansheng","Jiang H,Liu T,Chen QS",Jiang H,10.1016/j.infrared.2020.103423,Jiangsu University,"Fatty acid value is one of the important indexes to judge wheat flour quality during storage. A portable near-infrared (NIR) spectroscopy system was developed established for the quantitative detection of fatty acids in wheat flour during storage. First, the portable NIR spectroscopy system was used to obtain the spectra of wheat flour in different storage periods, and the spectra acquired were corrected by standard normal variate (SNV) method. Then, variable combination population analysis (VCPA) was used to optimize the characteristic wavelength variables of the SNV corrected spectra, and the characteristic wavelength variables highly related to the fatty acid value were determined. Finally, extreme learning machine (ELM) was employed to construct quantitative detection models based on different characteristic wavelength variables to achieve quantitative detection of fatty acid value. In the process, the effects of the ""Sigmoidal"" and ""Sine"" activation functions on the performance of the ELM model were compared. The experimental results showed that in this study, the two activation functions have little effect on the generalization performance of the ELM model. The ELM models based on different input characteristic wavelength variables all showed good prediction accuracy and stability when predicting independent samples in the validation set, and the mean of RP from the ELM model in each mode was above 0.96. The overall results demonstrate that it is feasible to use the portable NIR spectroscopy system built combined with appropriate chemometric methods to achieve quantitative determination of fatty acid values in wheat flour during storage. In addition, the VCPA algorithm has a good application prospect in the optimization of NIR spectral characteristic wavelengths.","Wheat flour,Portable near-infrared spectroscopy system,Variable combination population analysis,Extreme learning machine,Fatty acid value,Quantitative detection",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Optics,Physics",,2.581,"VARIABLE,SELECTION,METHODS,SOLID-STATE,FERMENTATION,QUALITY,ATTRIBUTES,RICE",INFRARED PHYSICS & TECHNOLOGY,,
14,Morphological Characterization of Functional Brain Imaging by Isosurface Analysis in Parkinson's Disease,30,9,,"Castillo-Barnes Diego,Martinez-Murcia Francisco J.,Ortiz Andres,Salas-Gonzalez Diego,RamIrez Javier,Gorriz Juan M.","Castillo-Barnes D,Martinez-Murcia FJ,Ortiz A,Salas-Gonzalez D,RamIrez J,Gorriz JM",Castillo-Barnes D,10.1142/S0129065720500446,University of Granada,"Finding new biomarkers to model Parkinson's Disease (PD) is a challenge not only to help discerning between Healthy Control (HC) subjects and patients with potential PD but also as a way to measure quantitatively the loss of dopaminergic neurons mainly concentrated at substantia nigra. Within this context, this work presented here tries to provide a set of imaging features based on morphological characteristics extracted from I[123]-Ioflupane SPECT scans to discern between HC and PD participants in a balanced set of 386 scans from Parkinson's Progression Markers Initiative (PPMI) database. These features, obtained from isosurfaces of each scan at different intensity levels, have been classified through the use of classical Machine Learning classifiers such as Support-Vector-Machines (SVM) or Naive Bayesian and compared with the results obtained using a Multi-Layer Perceptron (MLP).
The proposed system, based on a Mann-Whitney-Wilcoxon U-Test for feature selection and the SVM approach, yielded a 97.04% balanced accuracy when the performance was evaluated using a 10-fold cross-validation. This proves the reliability of these biomarkers, especially those related to sphericity, center of mass, number of vertices, 2D-projected perimeter or the 2D-projected eccentricity, among others, but including both internal and external isosurfaces.","Parkinson's disease,neuroimaging,machine learning,isosurfaces,Parkinson's Progression Markers Initiative (PPMI),Single Photon Emission Computed Tomography (SPECT),Computer-Aided-Diagnosis (CAD),supervised learning",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Computer Science,,5.439,"SPECT,CLASSIFICATION,DIAGNOSIS",INTERNATIONAL JOURNAL OF NEURAL SYSTEMS,,
15,The development an artificial intelligence algorithm for early sepsis diagnosis in the intensive care unit,141,,,"Yuan Kuo-Ching,Tsai Lung-Wen,Lee Ko-Han,Cheng Yi-Wei,Hsu Shou-Chieh,Lo Yu-Sheng,Chen Ray-Jade","Yuan KC,Tsai LW,Lee KH,Cheng YW,Hsu SC,Lo YS,Chen RJ",Yuan KC,10.1016/j.ijmedinf.2020.104176,Taipei Medical University,"Background: Severe sepsis and septic shock are still the leading causes of death in Intensive Care Units (ICUs), and timely diagnosis is crucial for treatment outcomes. The progression of electronic medical records (EMR) offers the possibility of storing a large quantity of clinical data that can facilitate the development of artificial intelligence (AI) in medicine. However, several difficulties, such as poor structure and heterogenicity of the raw EMR data, are encountered when introducing AI with ICU data. Labor-intensive work, including manual data entry, personal medical records sorting, and laboratory results interpretation may hinder the progress of AI. In this article, we introduce the developing of an AI algorithm designed for sepsis diagnosis using pre-selected features; and compare the performance of the AI algorithm with SOFA score based diagnostic method.
Materials and methods: This is a prospective open-label cohort study. A specialized EMR, named TED_ICU, was implemented for continuous data recording. One hundred six clinical features relevant to sepsis diagnosis were selected prospectively. A labeling work to allocate SEPSIS or NON_SEPSIS status for each ICU patient was performed by the in-charge intensivist according to SEPSIS-3 criteria, along with the automatic recording of selected features every day by TED_ICU. Afterward, we use de-identified data to develop the AI algorithm. Several machine learning methods were evaluated using 5-fold cross-validation, and XGBoost, a decision-tree based algorithm was adopted for our AI algorithm development due to best performance.
Results: The study was conducted between August 2018 and December 2018 for the first stage of analysis. We collected 1588 instances, including 444 SEPSIS and 1144 NON-SEPSIS, from 434 patients. The 434 patients included 259 (59.6%) male patients and 175 female patients. The mean age was 67.6-year-old, and the mean APACHE II score was 13.8. The SEPSIS cohort had a higher SOFA score and increased use of organ support treatment. The AI algorithm was developed with a shuffle method using 80% of the instances for training and 20% for testing. The established AI algorithm achieved the following: accuracy = 82% +/- 1%; sensitivity = 65% +/- 5%; specificity = 88% +/- 2%; precision = 67% +/- 3%; and F1 = 0.66 +/- 0.02. The area under the receiver operating characteristic curve (AUROC) was approximately 0.89. The SOFA score was used on the same 1588 instances for sepsis diagnosis, and the result was inferior to our AI algorithm (AUROC = 0.596).
Conclusion: Using real-time data, collected by EMR, from the ICU daily practice, our AI algorithm established with pre-selected features and XGBoost can provide a timely diagnosis of sepsis with an accuracy greater than 80%. AI algorithm also outperforms the SOFA score in sepsis diagnosis and exhibits practicality as clinicians can deploy appropriate treatment earlier. The early and precise response of this AI algorithm will result in cost reduction, outcome improvement, and benefit for healthcare systems, medical staff, and patients as well.","Artificial intelligence,AI,Sepsis,XGBoost,ICU,Critical care,Diagnostic algorithm",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Health Care Sciences & Services,Medical Informatics",,4.768,"INTERNATIONAL,CONSENSUS,DEFINITIONS,SEPTIC,SHOCK,MORTALITY,PREDICTION,IMPLEMENTATION,THERAPY",INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS,https://doi.org/10.1016/j.ijmedinf.2020.104176,
16,Predicting Tensile Properties of AZ31 Magnesium Alloys by Machine Learning,72,11,3935-3942,"Xu Xuenan,Wang Leyun,Zhu Gaoming,Zeng Xiaoqin","Xu XN,Wang LY,Zhu GM,Zeng XQ",Wang LY,10.1007/s11837-020-04343-w,Shanghai Jiao Tong University,"AZ31 magnesium alloys from different suppliers usually have different chemistry and processing histories, causing variance in their mechanical properties. In this work, we establish the quantitative relationship between alloy compositions, processing parameters, and mechanical properties by machine learning. Based on the artificial neural network (ANN) and support vector machine (SVM) algorithms, two models were built using a dataset with 112 data. Both models achieved good accuracy in predicting yield strength (YS), ultimate tensile strength (UTS), and tensile elongation (EL). To test their generalization ability, a new AZ31 extruded alloy was fabricated, with its chemical composition and processing history being documented. The YS, UTS, and EL of this material were measured and compared with model predictions. Relative errors for YS, UTS, and EL were 5.4%, 23%, and 272% by the ANN model, and 28%, 25%, and 143% by the SVM model, respectively. The reasons for the overestimation of the mechanical properties are discussed.","MECHANICAL-PROPERTIES,MG ALLOY,HIGH-STRENGTH,TEXTURE,MICROSTRUCTURE,DEPENDENCE,DESIGN",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Materials Science,Metallurgy & Metallurgical Engineering,Mineralogy,Mining & Mineral Processing",,2.989,"MECHANICAL-PROPERTIES,MG,ALLOY,HIGH-STRENGTH,TEXTURE,MICROSTRUCTURE,DEPENDENCE,DESIGN",JOM,,
17,Automated Health Condition Diagnosis of in situ Wood Utility Poles Using an Intelligent Non-Destructive Evaluation (NDE) Framework,20,10,,"Yu Yang,Subhani Mahbube,Hoshyar Azadeh Noori,Li Jianchun,Li Huan","Yu Y,Subhani M,Hoshyar AN,Li JC,Li H",Li JC,10.1142/S021945542042002X,University of Technology Sydney,"Wood utility poles are widely applied in power transmission and telecommunication systems in Australia. Because of a variety of external influence factors, such as fungi, termite and environmental conditions, failure of poles due to the wood degradation with time is of common occurrence with high degree uncertainty. The pole failure may result in serious consequences including both economic and public safety. Therefore, accurately and timely identifying the health condition of the utility poles is of great significance for economic and safe operation of electricity and communication networks. In this paper, a novel non-destructive evaluation (NDE) framework with advanced signal processing and artificial intelligence (AI) techniques is developed to diagnose the condition of utility pole in field. To begin with, the guided waves (GWs) generated within the pole is measured using multi-sensing technique, avoiding difficult interpretation of various wave modes which cannot be detected by only one sensor. Then, empirical mode decomposition (EMD) and principal component analysis (PCA) are employed to extract and select damage-sensitive features from the captured GW signals. Additionally, the up-to-date machine learning (ML) techniques are adopted to diagnose the health condition of the pole based on selected signal patterns. Eventually, the performance of the developed NDE framework is evaluated using the field testing data from 15 new and 24 decommissioned utility poles at the pole yard in Sydney.","Wood electricity pole,non-destructive evaluation,guided wave,advanced signal processing,machine learning",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE","Engineering,Mechanics",,2.269,"WAVE-PROPAGATION,TIMBER,POLES",INTERNATIONAL JOURNAL OF STRUCTURAL STABILITY AND DYNAMICS,https://opus.lib.uts.edu.au/bitstream/10453/146389/2/Automated%20health%20condition%20diagnosis%20of%20in-situ%20wood%20utility%20poles%20using%20an%20intelligent_Accepted%20version.pdf,
18,Design of a Predictive Model of Rock Breakage by Blasting Using Artificial Neural Networks,12,9,,"Rosales-Huamani Jimmy Aurelio,Perez-Alvarado Roberth Saenz,Rojas-Villanueva Uwe,Castillo-Sequera Jose Luis","Rosales-Huamani JA,Perez-Alvarado RS,Rojas-Villanueva U,Castillo-Sequera JL",Rosales-Huamani JA,10.3390/sym12091405,University Nacional de Ingenieria Lima,"Over the years, various models have been developed in the stages of the mining process that have allowed predicting and enhancing results, but it is the breakage, the variable that connects all the activities of the mining process from the point of view of costs (drilling, blasting, loading, hauling, crushing and grinding). To improve this process, we have designed and developed a computational model based on an Artificial Neural Network (ANN), the same that was built using the most representative variables such as the properties of explosives, the geomechanical parameters of the rock mass, and the design parameters of drill-blasting. For the training and validation of the model, we have taken the data from a copper mine as reference located in the north of Chile. The ANN architecture was of the supervised type containing: an input layer, a hidden layer with 13 neurons and an output layer that includes the sigmoid activation function with symmetrical properties for optimal model convergence. The ANN model was fed-back in its learning with training data until it becomes perfected, and due to the experimental results obtained, it is a valid prediction option that can be used in future blasting of ore deposits with similar characteristics using the same representative variables considered. Therefore, it constitutes a valid alternative for predicting rock breakage, given that it has been experimentally validated, with moderately reliable results, providing higher correlation coefficients than traditional models used, and with the additional advantage that an ANN model provides, due to its ability to learn and recognize collected data patterns. In this way, using this computer model we can obtain satisfactory results that allow us to predict breakage in similar scenarios, providing an alternative for evaluating the costs that this entails as a contribution to the work.","artificial neural networks,rock breakage,rock blasting",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"MEAN,PARTICLE-SIZE,FRAGMENTATION,VIBRATION,MINE",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/9/1405/pdf,
19,Simultaneously Spatiospectral Pattern Learning and Contaminated Trial Pruning for Electroencephalography-Based Brain Computer Interface,12,9,,"Shieh Chun-Ping,Yang Shih-Hung,Liu Yu-Shun,Kuo Yun-Ting,Lo Yu-Chun,Kuo Chao-Hung,Chen You-Yin","Shieh CP,Yang SH,Liu YS,Kuo YT,Lo YC,Kuo CH,Chen YY",Chen YY,10.3390/sym12091387,National Yang Ming Chiao Tung University,"Electroencephalography (EEG)-based brain computer interfaces (BCIs) translate motor imagery commands into the movements of an external device (e.g., a robotic arm). The automatic design of spectral and spatial filters is a challenging task, as the frequency bands of the spectral filters must be predefined by previously published studies and given that they may be affected during trials by artifacts and improper motor imagery (MI). This study aimed to eliminate the contaminated trials automatically during classifier training, and to simultaneously learn the spectral and spatial patterns without the need for predefined frequency bands. Compared with previous studies that measured the discriminative power of a frequency band based on mutual information, this study determined the difference of the class conditional probability density function between two MI classes. This information was further shared to measure the contamination level of the trial that simplified the computation. A particle-based approximation technique iteratively constructed a filter bank that extracted discriminative features, and simultaneously removed potentially contaminated trials. The particle weight was estimated by an analysis of variance F-test instead of mutual information as commonly used in previous studies. The experimental results of a publicly available dataset revealed that the proposed method outperformed the other BCI in terms of the classification accuracy. Asymmetrical spatial patterns were found on left- versus right-hand MI classifications. The learnt spectral and spatial patterns were consistent with prior neurophysiological knowledge.","electroencephalography,motor imagery,trial pruning,spatiospectral pattern learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"MOTOR,IMAGERY,EEG,CLASSIFICATION,FILTERS",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/9/1387/pdf,
20,COVID-19 Screening Using a Lightweight Convolutional Neural Network with Generative Adversarial Network Data Augmentation,12,9,,"Zulkifley Mohd Asyraf,Abdani Siti Raihanah,Zulkifley Nuraisyah Hani","Zulkifley MA,Abdani SR,Zulkifley NH",Zulkifley MA,10.3390/sym12091530,Universiti Kebangsaan Malaysia,"COVID-19 is a disease that can be spread easily with minimal physical contact. Currently, the World Health Organization (WHO) has endorsed the reverse transcription-polymerase chain reaction swab test as a diagnostic tool to confirm COVID-19 cases. This test requires at least a day for the results to come out depending on the available facilities. Many countries have adopted a targeted approach in screening potential patients due to the cost. However, there is a need for a fast and accurate screening test to complement this targeted approach, so that the potential virus carriers can be quarantined as early as possible. The X-ray is a good screening modality; it is quick at capturing, cheap, and widely available, even in third world countries. Therefore, a deep learning approach has been proposed to automate the screening process by introducing LightCovidNet, a lightweight deep learning model that is suitable for the mobile platform. It is important to have a lightweight model so that it can be used all over the world even on a standard mobile phone. The model has been trained with additional synthetic data that were generated from the conditional deep convolutional generative adversarial network. LightCovidNet consists of three components, which are entry, middle, and exit flows. The middle flow comprises five units of feed-forward convolutional neural networks that are built using separable convolution operators. The exit flow is designed to improve the multi-scale capability of the network through a simplified spatial pyramid pooling module. It is a symmetrical architecture with three parallel pooling branches that enable the network to learn multi-scale features, which is suitable for cases wherein the X-ray images were captured from all over the world independently. Besides, the usage of separable convolution has managed to reduce the memory usage without affecting the classification accuracy. The proposed method managed to get the best mean accuracy of 0.9697 with a low memory requirement of just 841,771 parameters. Moreover, the symmetrical spatial pyramid pooling module is the most crucial component; the absence of this module will reduce the screening accuracy to just 0.9237. Hence, the developed model is suitable to be implemented for mass COVID-19 screening.","COVID-19 screening,lightweight deep learning model,separable convolution,spatial pyramid pooling module,feed-forward layer",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"CORONAVIRUS,SARS-COV-2,PNEUMONIA,DIAGNOSIS",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/9/1530/pdf,
21,Shapelet-transformed Multi-channel EEG Channel Selection,11,5,,"Dai Chenglong,Pi Dechang,Becker Stefanie I","Dai CL,Pi DC,Becker SI",Dai CL,10.1145/3397850,Nanjing University of Aeronautics & Astronautics,"This article proposes an approach to select EEG channels based on EEG shapelet transformation, aiming to reduce the setup time and inconvenience for subjects and to improve the applicable performance of Brain-Computer Interfaces (BCIs). In detail, the method selects top-k EEG channels by solving a logistic loss-embedded minimization problem with respect to EEG shapelet learning, hyperplane learning, and EEG channel weight learning simultaneously. Especially, to learn distinguished EEG shapelets for weighting contributions of each EEG channel to the logistic loss, EEG shapelet similarity is also minimized during the procedure. Furthermore, the gradient descent strategy is adopted in the article to solve the non-convex optimization problem, which finally leads to the algorithm termed StEEGCS. In a result, classification accuracy, with those EEG channels selected by StEEGCS, is improved compared to that with all EEG channels, and classification time consumption is reduced as well. Additionally, the comparisons with several state-of-the-art EEG channel selection methods on several real-world EEG datasets also demonstrate the efficacy and superiority of StEEGCS.","EEG channel selection,EEG shapelets,channel contribution,shapelet similarity minimization",Article,"ASSOC COMPUTING MACHINERY, 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA",Computer Science,,4.031,"BRAIN,COMPUTER,INTERFACES,TIME-SERIES,QUANTITATIVE,EEG,CLASSIFICATION,ALGORITHM",ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY,,
22,Prediction of respiratory decompensation in Covid-19 patients using machine learning: The READY trial,124,,,"Burdick Hoyt,Lam Carson,Mataraso Samson,Siefkas Anna,Braden Gregory,Dellinger R. Phillip,McCoy Andrea,Vincent Jean-Louis,Green-Saxena Abigail,Barnes Gina","Burdick H,Lam C,Mataraso S,Siefkas A,Braden G,Dellinger RP,McCoy A,Vincent JL,Green-Saxena A,Barnes G",Siefkas A,10.1016/j.compbiomed.2020.103949,"POB 156572, San Francisco, CA 94115 USA.","Background: Currently, physicians are limited in their ability to provide an accurate prognosis for COVID-19 positive patients. Existing scoring systems have been ineffective for identifying patient decompensation. Machine learning (ML) may offer an alternative strategy. A prospectively validated method to predict the need for ventilation in COVID-19 patients is essential to help triage patients, allocate resources, and prevent emergency intubations and their associated risks.
Methods: In a multicenter clinical trial, we evaluated the performance of a machine learning algorithm for prediction of invasive mechanical ventilation of COVID-19 patients within 24 h of an initial encounter. We enrolled patients with a COVID-19 diagnosis who were admitted to five United States health systems between March 24 and May 4, 2020.
Results: 197 patients were enrolled in the REspirAtory Decompensation and model for the triage of covid-19 patients: a prospective studY (READY) clinical trial. The algorithm had a higher diagnostic odds ratio (DOR, 12.58) for predicting ventilation than a comparator early warning system, the Modified Early Warning Score (MEWS). The algorithm also achieved significantly higher sensitivity (0.90) than MEWS, which achieved a sensitivity of 0.78, while maintaining a higher specificity (p < 0.05).
Conclusions: In the first clinical trial of a machine learning algorithm for ventilation needs among COVID-19 patients, the algorithm demonstrated accurate prediction of the need for mechanical ventilation within 24 h. This algorithm may help care teams effectively triage patients and allocate resources. Further, the algorithm is capable of accurately identifying 16% more patients than a widely used scoring system while minimizing false positive results.","Machine learning,COVID-19,Mechanical ventilation,Prediction",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"TRACHEAL,INTUBATION,LUNG,INJURY,MANAGEMENT,FAILURE",COMPUTERS IN BIOLOGY AND MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7410013,
23,Classification algorithms applied to blood-based transcriptome meta-analysis to predict idiopathic Parkinson's disease,124,,,"Falchetti Marcelo,Prediger Rui Daniel,Zanotto-Filho Alfeu","Falchetti M,Prediger RD,Zanotto A",Zanotto A,10.1016/j.compbiomed.2020.103925,Universidade Federal de Santa Catarina (UFSC),"Diagnosis of Parkinson's disease (PD) remains a challenge in clinical practice, mostly due to lack of peripheral blood markers. Transcriptomic analysis of blood samples has emerged as a potential means to identify bio-markers and gene signatures of PD. In this context, classification algorithms can assist in detecting data patterns such as phenotypes and transcriptional signatures with potential diagnostic application. In this study, we per-formed gene expression meta-analysis of blood transcriptome from PD and control patients in order to identify a gene-set capable of predicting PD using classification algorithms. We examined microarray data from public repositories and, after systematic review, 4 independent cohorts (GSE6613, GSE57475, GSE72267 and GSE99039) comprising 711 samples (388 idiopathic PD and 323 healthy individuals) were selected. Initially, analysis of differentially expressed genes resulted in minimal overlap among datasets. To circumvent this, we carried out meta-analysis of 17,712 genes across datasets, and calculated weighted mean Hedges' g effect sizes. From the top -100-positive and negative gene effect sizes, algorithms of collinearity recognition and recursive feature elimination were used to generate a 59-gene signature of idiopathic PD. This signature was evaluated by 9 classification algorithms and 4 sample size-adjusted training groups to create 36 models. Of these, 33 showed accuracy higher than the non-information rate, and 2 models built on Support Vector Machine Regression bestowed best accuracy to predict PD and healthy control samples. In summary, the gene meta-analysis followed by machine learning methodology employed herein identified a gene-set capable of accurately predicting idio-pathic PD in blood samples.","Effect size,Microarray,Classification algorithms,Molecular signature,Blood biopsy",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"GENE-EXPRESSION,PERIPHERAL-BLOOD,BIOMARKERS,RISK",COMPUTERS IN BIOLOGY AND MEDICINE,,
24,Scalp EEG classification using deep Bi-LSTM network for seizure detection,124,,,"Hu Xinmei,Yuan Shasha,Xu Fangzhou,Leng Yan,Yuan Kejiang,Yuan Qi","Hu XM,Yuan SS,Xu FZ,Leng Y,Yuan KJ,Yuan Q",Yuan Q,10.1016/j.compbiomed.2020.103919,Shandong Normal University,"Automatic seizure detection technology not only reduces workloads of neurologists for epilepsy diagnosis but also is of great significance for treatments of epileptic patients. A novel seizure detection method based on the deep bidirectional long short-term memory (Bi-LSTM) network is proposed in this paper. To preserve the non -stationary nature of EEG signals while decreasing the computational burden, the local mean decomposition (LMD) and statistical feature extraction procedures are introduced. The deep architecture is then designed by combining two independent LSTM networks with the opposite propagation directions: one transmits information from the front to the back, and another from the back to the front. Thus the deep model can take advantage of the information both before and after the currently analyzing moment to jointly determine the output state. A mean sensitivity of 93.61% and a mean specificity of 91.85% were achieved on a long-term scalp EEG database. The comparisons with other published methods based on either traditional machine learning models or convolutional neural networks demonstrated the improved performance for seizure detection.","Scalp EEG,Deep learning,Bi-LSTM,Local mean decomposition,Seizure detection",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"SHORT-TERM-MEMORY,EPILEPTIC,SEIZURES,NEURAL-NETWORK,DECOMPOSITION",COMPUTERS IN BIOLOGY AND MEDICINE,,
25,Anatomical classification of upper gastrointestinal organs under various image capture conditions using AlexNet,124,,,"Igarashi Shohei,Sasaki Yoshihiro,Mikami Tatsuya,Sakuraba Hirotake,Fukuda Shinsaku","Igarashi S,Sasaki Y,Mikami T,Sakuraba H,Fukuda S",Sasaki Y,10.1016/j.compbiomed.2020.103950,Hirosaki University,"Background: Machine learning has led to several endoscopic studies about the automated localization of digestive lesions and prediction of cancer invasion depth. Training and validation dataset collection are required for a disease in each digestive organ under a similar image capture condition; this is the first step in system development. This data cleansing task in data collection causes a great burden among experienced endoscopists. Thus, this study classified upper gastrointestinal (GI) organ images obtained via routine esophagogastroduodenoscopy (EGD) into precise anatomical categories using AlexNet.
Method: In total, 85,246 raw upper GI endoscopic images from 441 patients with gastric cancer were collected retrospectively. The images were manually classified into 14 categories: 0) white-light (WL) stomach with indigo carmine (IC); 1) WL esophagus with iodine; 2) narrow-band (NB) esophagus; 3) NB stomach with IC; 4) NB stomach; 5) WL duodenum; 6) WL esophagus; 7) WL stomach; 8) NB oral-pharynx-larynx; 9) WL oral-pharynx-larynx; 10) WL scaling paper; 11) specimens; 12) WL muscle fibers during endoscopic submucosal dissection (ESD); and 13) others. AlexNet is a deep learning framework and was trained using 49,174 datasets and validated using 36,072 independent datasets.
Results: The accuracy rates of the training and validation dataset were 0.993 and 0.965, respectively.
Conclusions: A simple anatomical organ classifier using AlexNet was developed and found to be effective in data cleansing task for collection of EGD images. Moreover, it could be useful to both expert and non-expert endoscopists as well as engineers in retrospectively assessing upper GI images.","Anatomical classification,Upper gastrointestinal tract,Endoscopy,Convolutional neural network (CNN),Artificial intelligence",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"CAPSULE,ENDOSCOPY,GASTRIC-CANCER",COMPUTERS IN BIOLOGY AND MEDICINE,,
26,MRI radiomics for the prediction of recurrence in patients with clinically non-functioning pituitary macroadenomas,124,,,"Machado Leonardo F.,Elias Paula C. L.,Moreira Ayrton C.,dos Santos Antonio C.,Murta Junior Luiz O.","Machado LF,Elias PCL,Moreira AC,dos Santos AC,Murta LO",Machado LF,10.1016/j.compbiomed.2020.103966,"Av Bandeirantes 3900, Ribeirao Preto, Brazil.","Twelve to 66% of patients with clinically non-functioning pituitary adenoma (NFPA) experience tumor recurrence 1-5 years after the first surgery. Nevertheless, there is still no recurrence prediction factor concisely established and reproduced in the literature for NFPA management. The present study evaluates the prognostic value of MRI Radiomics features combined with machine learning models to assess recurrence after the first surgery in patients with clinically non-functioning pituitary adenomas (NFPA). We carried out a retrospective study on 27 patients with NFPA, 10 patients having experienced tumor recurrence after the first surgery and 17 who did not. Preoperative 3D T-1 contrast-enhanced MR images of patients were used to extract up to 255 Radiomics features from two and three-dimensional segmented regions. Additionally, gender, age at first surgery, and the presence of remnant tumor tissue were investigated to find the correlation with NFPA recurrence. Conventional statistics tests were used to evaluate whether the outcome patient groups (stable and recurrent) were different considering each feature individually. Additionally, five well-known machine-learning algorithms were used in combination with Radiomic features to classify recurrent and stable lesions. We found statistical evidence (p < 0.02) for 6 two-dimensional and 13 three-dimensional radiomic features. We achieved accuracies of up to 96.3% for 3D-feature based models and up to 92.6% accuracies for 2D-feature based models. 3D-feature based models achieved better performances using considerably fewer features when compared to 2D-feature based models. We concluded that Radiomics have the potential of NFPA recurrence prediction after the first surgery. Three-dimensional Radiomics have superior discrimination power to predict NFPA recurrence than two-dimensional radiomic features. Finally, the combination of Radiomics with machine-learning algorithms can offer computational models capable of non-invasive, unbiased, and quick assessment that might improve the prediction of NFPA recurrence.","Radiomics,MRI,Pituitary adenoma,Tumor recurrence,Machine learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"TEXTURE,ANALYSIS,ADENOMAS,CLASSIFICATION,RADIOTHERAPY,MANAGEMENT,FEATURES,TUMORS,DIAGNOSIS,PATTERN,KI-67",COMPUTERS IN BIOLOGY AND MEDICINE,https://doi.org/10.1016/j.compbiomed.2020.103966,
27,COVID-19 pathways for brain and heart injury in comorbidity patients: A role of medical imaging and artificial intelligence-based COVID severity classification: A review,124,,,"Suri Jasjit S.,Puvvula Anudeep,Biswas Mainak,Majhail Misha,Saba Luca,Faa Gavino,Singh Inder M.,Oberleitner Ronald,Turk Monika,Chadha Paramjit S.","Suri JS,Puvvula A,Biswas M,Majhail M,Saba L,Faa G,Singh IM,Oberleitner R,Turk M,Chadha PS",Suri JS,10.1016/j.compbiomed.2020.103960,"AtheroPointTM, Asia Pacific Vasc Soc, Stroke Monitoring & Diag Div, Roseville, CA 95661 USA.","Artificial intelligence (AI) has penetrated the field of medicine, particularly the field of radiology. Since its emergence, the highly virulent coronavirus disease 2019 (COVID-19) has infected over 10 million people, leading to over 500,000 deaths as of July 1st, 2020. Since the outbreak Ixgan, almost 28,000 articles about COVID-19 have been published (https://pubmortnebi.nlm.nih.gov ); however, few have explored the role of imaging and artificial intelligence in COVID-19 patients-specifically, those with comorbidities.
This paper begins by presenting the four pathways that can lead to heart and brain injuries following a COVID-19 infection. Our survey also offers insights into the role that imaging can play in the treatment of comorbid patients, based on probabilities derived from COVID-19 symptom statistics. Such symptoms include myocardial injury, hypoxia, plaque rupture, arrhythmias, venous thromboembolism, coronary thrombosis, encephalitis, ischemia, inflammation, and lung injury. At its core, this study considers the role of image-based AI, which can be used to characterize the tissues of a COVID-19 patient and classify the severity of their infection. Image-based AI is more important than ever as the pandemic surges and countries worldwide grapple with limited medical resources for detection and diagnosis.","COVID-19,Comorbidity,Pathopbysiology,Heart,Brain,Lung,Imaging,Artificial intelligence,Risk assessment",Review,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"PLAQUE,TISSUE,CHARACTERIZATION,ANGIOTENSIN-CONVERTING,ENZYME,RISK,STRATIFICATION,SARS-CORONAVIRUS,CAROTID,SCANS,ULTRASOUND,INFECTION,DIAGNOSIS,PARADIGM,SYSTEM",COMPUTERS IN BIOLOGY AND MEDICINE,https://doi.org/10.1016/j.compbiomed.2020.103960,
28,Convolutional neural network and impedance-based SHM applied to damage detection,2,3,,"Ferreira de Rezende Stanley Washington,Vieira de Moura Jose dos Reis,Finzi Neto Roberto Mendes,Gallo Carlos Alberto,Steffen Valder","de Rezende SWF,de Moura JDV,Neto RMF,Gallo CA,Steffen V",de Moura JDV,10.1088/2631-8695/abb568,Universidade Federal de Goias,"The impedance-based structural health monitoring technique uses measured signatures changes to identify incipient damages in structures. The purpose is to perform a correlation of these changes with the physical phenomena. However, since electromechanical coupling exists, some environmental influences such as temperature changes may lead to false decision regarding the condition of the structure. As a result, innovative machine learning tools have been extensively investigated to avoid errors in structural prognosis and, in this sense, recent applications of convolutional neural networks (CNN) have emerged within the scope of SHM research, focusing mainly on vibration analysis. However, studies that aim to combine neural architectures with intelligent materials for structural monitoring purposes have been poorly evaluated. Consequently, its integration with the electromechanical impedance method is still considered as being a new application of CNN. Thus, in order to contribute to the SHM area, this work presents a combination of the CNN architecture and the EMI methodology. In the present contribution, three aluminum beams subjected to three different steady temperature levels (0 degrees C, 10 degrees C and 20 degrees C) were studied. For this aim, a test chamber was used for humidity and temperature control. Artificial damages such as mass addition were taken into account so that impedance signatures related to both pristine and damaged conditions can be analyzed. Thus, a one-dimensional Convolutional Neural Network (1D CNN) was designed, trained and used for damage prediction purposes. In this context, a temperature robust model that is able to identify damage independently of environmental condition was developed.","convolutional neural network,damage detection,electromechanical impedance-based SHM",Article,"IOP Publishing Ltd, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Engineering,,,"ELECTROMECHANICAL,IMPEDANCE,MATERIAL,SYSTEMS,LAMB,WAVES,TEMPERATURE,CLASSIFICATION,IDENTIFICATION,COMPENSATION,AIRCRAFT,SENSORS",ENGINEERING RESEARCH EXPRESS,,
29,Hand Gesture Recognition Using Three-Dimensional Electrical Impedance Tomography,67,9,1554-1558,"Jiang Dai,Wu Yu,Demosthenous Andreas","Jiang D,Wu Y,Demosthenous A",Demosthenous A,10.1109/TCSII.2020.3006430,University of London,"This brief presents a 16-electrode electrical impedance tomography (EIT) system for hand gesture recognition. The hardware of the system is based on integrated circuits including a 12-bit high spectral purity current-steering DAC implemented in 0.18 mu m CMOS technology, a current driver and an instrumentation amplifier in 0.35 mu m CMOS technology. Both 2D and 3D EIT electrode arrangements were tested for hand gesture recognition. It is shown that using machine learning algorithms, eight hand gestures can be distinguished from the measured bio-impedance data with an accuracy of 97.9% when the electrodes are placed on a single wristband, and an accuracy of 99.5% with the same number of electrodes distributed on two wristbands for 3D EIT measurement. In particular 3D EIT demonstrated significant superiority in its ability to discriminate between gestures with similar muscle contractions.","3D electrical impedance tomography (EIT),current-steering DAC,hand gesture recognition,machine learning",Article; Proceedings Paper,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,3.143,,IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS,https://discovery.ucl.ac.uk/id/eprint/10110624/1/FINAL%20VERSION_eit%20hand%20gesture.pdf,
30,Four-Dimensional Modeling of fMRI Data via Spatio-Temporal Convolutional Neural Networks (ST-CNNs),12,3,451-460,"Zhao Yu,Li Xiang,Huang Heng,Zhang Wei,Zhao Shijie,Makkie Milad,Zhang Mo,Li Quanzheng,Liu Tianming","Zhao Y,Li X,Huang H,Zhang W,Zhao SJ,Makkie M,Zhang M,Li QZ,Liu TM",Liu TM,10.1109/TCDS.2019.2916916,University System of Georgia,"Since the human brain functional mechanism has been enabled for investigation by the functional magnetic resonance imaging (fMRI) technology, simultaneous modeling of both the spatial and temporal patterns of brain functional networks from 4-D fMRI data has been a fundamental but still challenging research topic for neuroimaging and medical image analysis fields. Currently, general linear model (GLM), independent component analysis (ICA), sparse dictionary learning, and recently deep learning models, are major methods for fMRI data analysis in either spatial or temporal domains, but there are few joint spatial-temporal methods proposed, as far as we know. As a result, the 4-D nature of fMRI data has not been effectively investigated due to this methodological gap. The recent success of deep learning applications for functional brain decoding and encoding greatly inspired us in this paper to propose a novel framework called spatio-temporal convolutional neural network (ST-CNN) to extract both spatial and temporal characteristics from targeted networks jointly and automatically identify of functional networks. The identification of default mode network (DMN) from fMRI data was used for evaluation of the proposed framework. Results show that only training the framework on one fMRI data set is sufficiently generalizable to identify the DMN from different data sets of different cognitive tasks and resting state. Further investigation of the results shows that the joint-learning scheme can capture the intrinsic relationship between the spatial and temporal characteristics of DMN and thus it ensures the accurate identification of DMN from independent data sets. The ST-CNN model brings new tools and insights for fMRI analysis in cognitive and clinical neuroscience studies.","Functional magnetic resonance imaging,Brain modeling,Dictionaries,Data models,Task analysis,Machine learning,Sparse matrices,Deep learning,functional brain networks,functional magnetic resonance imaging (fMRI)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Robotics,Neurosciences & Neurology",,3.513,"DEFAULT-MODE,INDEPENDENT,COMPONENT,FUNCTIONAL,CONNECTIVITY,BRAIN",IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS,http://arxiv.org/pdf/1805.12564,
31,Dreem Open Datasets: Multi-Scored Sleep Datasets to Compare Human and Automated Sleep Staging,28,9,1955-1965,"Guillot Antoine,Sauvet Fabien,During Emmanuel H.,Thorey Valentin","Guillot A,Sauvet F,During EH,Thorey V",Thorey V,10.1109/TNSRE.2020.3011181,"Algorithm Team, Dreem, F-75002 Paris, France.","Sleep stage classification constitutes an important element of sleep disorder diagnosis. It relies on the visual inspection of polysomnography records by trained sleep technologists. Automated approaches have been designed to alleviate this resource-intensive task. However, such approaches are usually compared to a single human scorer annotation despite an inter-rater agreement of about 85% only. The present study introduces two publicly-available datasets, DOD-H including 25 healthy volunteers and DOD-O including 55 patients suffering from obstructive sleep apnea (OSA). Both datasets have been scored by 5 sleep technologists from different sleep centers. We developed a framework to compare automated approaches to a consensus of multiple human scorers. Using this framework, we benchmarked and compared the main literature approaches to a new deep learning method, SimpleSleepNet, which reach state-of-the-art performances while being more lightweight. We demonstrated that many methods can reach human-level performance on both datasets. SimpleSleepNet achieved an F1 of 89.9% vs 86.8% on average for human scorers on DOD-H, and an F1 of 88.3% vs 84.8% on DOD-O. Our study highlights that state-of-the-art automated sleep staging outperforms human scorers performance for healthy volunteers and patients suffering from OSA. Considerations could be made to use automated approaches in the clinical setting.","Sleep apnea,Feature extraction,Brain modeling,Machine learning,Electroencephalography,Manuals,Automated sleep stage classification,deep learning,PSG,EEG,open datasets,inter-rater agreement",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"NEURAL-NETWORK,RELIABILITY",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,http://arxiv.org/pdf/1911.03221,
32,A New Framework for Automatic Detection of Patients With Mild Cognitive Impairment Using Resting-State EEG Signals,28,9,1966-1976,"Siuly Siuly,Alcin Omer Faruk,Kabir Enamul,Sengur Abdulkadir,Wang Hua,Zhang Yanchun,Whittaker Frank","Siuly S,Alcin OF,Kabir E,Sengur A,Wang H,Zhang YC,Whittaker F",Siuly S,10.1109/TNSRE.2020.3013429,Victoria University,"Mild cognitive impairment (MCI) can be an indicator representing the early stage of Alzheimier's disease (AD). AD, which is the most common form of dementia, is a major public health problem worldwide. Efficient detection of MCI is essential to identify the risks of AD and dementia. Currently Electroencephalography (EEG) is the most popular tool to investigate the presenence of MCI biomarkers. This study aims to develop a new framework that can use EEG data to automatically distinguish MCI patients from healthy control subjects. The proposed framework consists of noise removal (baseline drift and power line interference noises), segmentation, data compression, feature extraction, classification, and performance evaluation. This study introduces Piecewise Aggregate Approximation (PAA) for compressing massive volumes of EEG data for reliable analysis. Permutation entropy (PE) and auto-regressive (AR) model features are investigated to explore whether the changes in EEG signals can effectively distinguish MCI from healthy control subjects. Finally, three models are developed based on three modern machine learning techniques: Extreme Learning Machine (ELM); Support Vector Machine (SVM) and K-Nearest Neighbours (KNN) for the obtained feature sets. Our developed models are tested on a publicly available MCI EEG database and the robustness of our models is evaluated by using a 10-fold cross validation method. The results show that the proposed ELM based method achieves the highest classification accuracy (98.78%) with lower execution time (0.281 seconds) and also outperforms the existing methods. The experimental results suggest that our proposed framework could provide a robust biomarker for efficient detection of MCI patients.","Electroencephalography,Brain modeling,Dementia,Feature extraction,Aggregates,Biological system modeling,Mild cognitive impairment (MCI),Alzheimer's disease (AD),electroencephalogram (EEG),piecewise aggregate approximation (PAA),auto-regressive (AR) model,permutation entropy (PE),extreme learning machine (ELM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"EXTREME,LEARNING-MACHINE,PERMUTATION,ENTROPY,OPTIMUM,ALLOCATION,CLASSIFICATION,SELECTION,FEATURES",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
33,Should Hands Be Restricted When Measuring Able-Bodied Participants to Evaluate Machine Learning Controlled Prosthetic Hands?,28,9,1977-1983,"Kristoffersen Morten B.,Franzke Andreas W.,van der Sluis Corry K.,Bongers Raoul M.,Murgia Alessio","Kristoffersen MB,Franzke AW,van der Sluis CK,Bongers RM,Murgia A",Kristoffersen MB,10.1109/TNSRE.2020.3007803,University of Groningen,"Objective: When evaluating methods for machine-learning controlled prosthetic hands, able-bodied participants are often recruited, for practical reasons, instead of participants with upper limb absence (ULA). However, able-bodied participants have been shown to often perform myoelectric control tasks better than participants with ULA. It has been suggested that this performance difference can be reduced by restricting the wrist and hand movements of able-bodied participants. However, the effect of such restrictions on the consistency and separability of the electromyogram's (EMG) features remains unknown. The present work investigates whether the EMG separability and consistency between unaffected and affected arms differ and whether they change after restricting the unaffected limb in persons with ULA. Methods: Both arms of participants with unilateral ULA were compared in two conditions: with the unaffected hand and wrist restricted or not. Furthermore, it was tested if the effect of arm and restriction is influenced by arm posture (arm down, arm in front, or arm up). Results: Fourteen participants (two women, age = 53.4 +/- 4.05) with acquired transradial limb loss were recruited. We found that the unaffected limb generated more separated EMG than the affected limb. Furthermore, restricting the unaffected hand and wrist lowered the separability of the EMG when the arm was held down. Conclusion: Limb restriction is a viable method to make the EMG of able-bodied participants more similar to that of participants with ULA. Significance: Future research that evaluates methods for machine learning controlled hands in able-bodied participants should restrict the participants' hand and wrist.","Electromyography,Wrist,Muscles,Electrodes,Prosthetic hand,Elbow,Atmospheric measurements,Electromyography,limb restriction,myoelectric control,upper limb absence,arm posture",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"EMG,PATTERN-RECOGNITION",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,https://ieeexplore.ieee.org/ielx7/7333/9187728/09134974.pdf,
34,EEG Functional Connectivity Predicts Individual Behavioural Impairment During Mental Fatigue,28,9,2080-2089,"Qi Peng,Hu Hongying,Zhu Li,Gao Lingyun,Yuan Jingjia,Thakor Nitish,Bezerianos Anastasios,Sun Yu","Qi P,Hu HY,Zhu L,Gao LY,Yuan JJ,Thakor N,Bezerianos A,Sun Y",Sun Y,10.1109/TNSRE.2020.3007324,"Ministry of Education, China","Mental fatigue deteriorates ability to perform daily activities - known as time-on-task (TOT) effect and becomes a common complaint in contemporary society. However, an applicable technique for fatigue detection/prediction is hindered due to substantial inter-subject differences in behavioural impairment and brain activity. Here, we developed a fully crossvalidated, data-driven analysis framework incorporating multivariate regression model to explore the feasibility of utilizing functional connectivity (FC) to predict the fatigue-related behavioural impairment at individual level. EEG was recorded from 40 healthy adults as they performed a 30-min high-demanding sustained attention task. FC were constructed in different frequency bands using three widely-adoptedmethods (including coherence, phase log index (PLI), and partial directed coherence (PDC)) and contrasted between the most vigilant and fatigued states. The differences of individual FC (diff (FC)) were considered as features; whereas the TOT slop across the course of task and the differences of reaction time (Delta RT) between the most vigilant and fatigued states were chosen to represent behavioural impairments. Behaviourally, we found substantial inter-subject differences of impairments. Furthermore, we achieved significantly high accuracies for individualized prediction of behavioural impairments using diff (PDC). The identified top diff (PDC) features contributing to the individualized predictions were found mainly in theta and alpha bands. Further interrogation of diff (PDC) features revealed distinct patterns between the TOT slop and Delta RT prediction models, highlighting the complex neural mechanisms of mental fatigue. Overall, the current findings extended conventional brain-behavioural correlation analysis to individualized prediction of fatigue-related behavioural impairments, therebymoving a step forward towards development of applicable techniques for quantitative fatigue monitoring in real-world scenarios.","Individualized prediction,functional connectivity,machine learning,regression,EEG",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"SUSTAINED,ATTENTION,NEURAL,MECHANISMS,PERFORMANCE,VIGILANCE,MACHINE,OSCILLATIONS,ACTIVATION,DYNAMICS,PATTERNS",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
35,Deep Learning of Spatiotemporal Filtering for Fast Super-Resolution Ultrasound Imaging,67,9,1820-1829,"Brown Katherine G.,Ghosh Debabrata,Hoyt Kenneth","Brown KG,Ghosh D,Hoyt K",Brown KG,10.1109/TUFFC.2020.2988164,University of Texas System,"Super-resolution ultrasound (SR-US) imaging is a new technique that breaks the diffraction limit and allows visualization of microvascular structures down to tens of micrometers. The image processingmethods for the spatiotemporal filtering needed in SR-US, such as singular value decomposition (SVD), are computationally burdensome and performed offline. Deep learning has been applied to many biomedical imaging problems, and trained neural networks have been shown to process an image in milliseconds. The goal of this study was to evaluate the effectiveness of deep learning to realize a spatiotemporal filter in the context of SR-US processing. A 3-D convolutional neural network (3DCNN) was trained on in vitro and in vivo data sets using SVD as ground truth in tissue clutter reduction. In vitro data were obtained from a tissue-mimicking flow phantom, and in vivo data were collected from murine tumors of breast cancer. Three training techniques were studied: training with in vitro data sets, training with in vivo data sets, and transfer learning with initial training on in vitro data sets followed by fine-tuning with in vivo data sets. The neural network trained with in vitro data sets followedby fine-tuningwith in vivo data sets had the highest accuracy at 88.0%. The SR-US images produced with deep learning allowed visualization of vessels as small as 25 mu m in diameter, which is below the diffraction limit (wavelength of 110 mu m at 14 MHz). The performance of the 3DCNN was encouraging for real-time SR-US imaging with an average processing frame rate for in vivo data of 51 Hz with GPU acceleration.","Contrast agents,contrast-enhanced ultrasound (CEUS),deep learning,microbubbles (MBs),super-resolution ultrasound (SR-US)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,"TUMOR,ANGIOGENESIS,NETWORKS,DOPPLER,PCA",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7523282,
36,Deep Convolutional Neural Networks for Thyroid Tumor Grading using Ultrasound B-mode Imagesa),148,3,1529-1535,"Shao Juntao,Zheng Jingjing,Zhang Bing","Shao JT,Zheng JJ,Zhang B",Shao JT,10.1121/10.0001924,"First Hosp Qinhuangdao, Dept Ultrasound, Qinhuangdao, Hebei, Peoples R China.","The performances of deep convolutional neural network (DCNN) modeling and transfer learning (TF) for thyroid tumor grading using ultrasound imaging were evaluated. This retrospective study included input patient data (ultrasound B-mode image sets) assigned to the training group (115 participants) or testing group (28 participants). DCNN (ResNet50) and TF (ResNet50, ResNet101, ResNet152, VGG16, Inception V3, and DenseNet201), which trains a convolutional neural network that has been pre-trained on ImageNet, were used for image classification based on thyroid tumor grade. Supervised training was performed by using the DCNN or TF model to minimize the difference between the output data and clinical grading. The performances of the DCNN and TF models were assessed in the testing dataset with receiver operating characteristic analyses. Results showed that TF based on Resnet50 and VGG16 had better performance than DCNN (ResNet50) in differentiating thyroid tumor with areas under the receiver operating characteristic (AUCs) curve more than 0.8. However, TF based on ResNet101, ResNet152, InceptionV3, and Densenet201 had equal or worse performances than DCNN (ResNet50) in grading thyroid tumor with AUCs less than 0.5. TF based on ResNet50 and VGG16 had a superior performance compared to DCNN (ResNet50) model for grading thyroid tumors based on ultrasound images.","FINE-NEEDLE BIOPSY,NODULES,CANCER,CLASSIFICATION,LOCALIZATION,SYSTEM",Article,"ACOUSTICAL SOC AMER AMER INST PHYSICS, STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA","Acoustics,Audiology & Speech-Language Pathology",,2.001,"FINE-NEEDLE,BIOPSY,NODULES,CANCER,CLASSIFICATION,LOCALIZATION,SYSTEM",JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA,https://asa.scitation.org/doi/pdf/10.1121/10.0001924,
37,Mass Spectrometry Imaging for Reliable and Fast Classification of Non-Small Cell Lung Cancer Subtypes,12,9,,"Kriegsmann Mark,Zgorzelski Christiane,Casadonte Rita,Schwamborn Kristina,Muley Thomas,Winter Hauke,Eichhorn Martin,Eichhorn Florian,Warth Arne,Deininger Soeren-Oliver","Kriegsmann M,Zgorzelski C,Casadonte R,Schwamborn K,Muley T,Winter H,Eichhorn M,Eichhorn F,Warth A,Deininger SO",Kriegsmann M,10.3390/cancers12092704,Ruprecht Karls University Heidelberg,"Simple Summary
Diagnostic subtyping of non-small cell lung cancer is paramount for therapy stratification. Our study shows that the subtyping into pulmonary adenocarcinoma and pulmonary squamous cell carcinoma by mass spectrometry imaging is rapid and accurate using limited tissue material.
Subtyping of non-small cell lung cancer (NSCLC) is paramount for therapy stratification. In this study, we analyzed the largest NSCLC cohort by mass spectrometry imaging (MSI) to date. We sought to test different classification algorithms and to validate results obtained in smaller patient cohorts. Tissue microarrays (TMAs) from including adenocarcinoma (ADC, n = 499) and squamous cell carcinoma (SqCC, n = 440), were analyzed. Linear discriminant analysis, support vector machine, and random forest (RF) were applied using samples randomly assigned for training (66%) and validation (33%). The m/z species most relevant for the classification were identified by on-tissue tandem mass spectrometry and validated by immunohistochemistry (IHC). Measurements from multiple TMAs were comparable using standardized protocols. RF yielded the best classification results. The classification accuracy decreased after including less than six of the most relevant m/z species. The sensitivity and specificity of MSI in the validation cohort were 92.9% and 89.3%, comparable to IHC. The most important protein for the discrimination of both tumors was cytokeratin 5. We investigated the largest NSCLC cohort by MSI to date and found that the classification of NSCLC into ADC and SqCC is possible with high accuracy using a limited set of m/z species.","mass spectrometry imaging,mass spectrometry,NSCLC,lung cancer",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Oncology,,6.999,"ADENOCARCINOMA,ALGORITHM",CANCERS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7564257,
38,Enhancing predictions of patient conveyance using emergency call handler free text notes for unconscious and fainting incidents reported to the London Ambulance Service,141,,,"Tollinton Liam,Metcalf Alexander M.,Velupillai Sumithra","Tollinton L,Metcalf AM,Velupillai S",Velupillai S,10.1016/j.ijmedinf.2020.104179,University of London,"Objective: Pre-hospital emergency medical services use clinical decision support systems (CDSS) to triage calls. Call handlers often supplement this by making free text notes covering key incident information. We investigate whether machine learning approaches using features from such free text notes can improve prediction of unconscious patients who require conveyance.
Materials and methods: We analysed a subset of all London Ambulance Service calls that were triaged through the Medical Priority Dispatch System (MPDS) as involving an unconscious or fainting patient in 2018. We use and compare two machine learning algorithms: random forest (RF) and gradient boosting machine (GBM). For each incident, we predict whether the patient will be conveyed to a hospital emergency department or equivalent using as features 1) the MPDS code, 2) the free text notes and 3) the two together. We evaluate model performance using the area under the curve (AUC) metric. Given the imbalance of outcomes (patient conveyed 71 %, not conveyed 29 %), we also consider sensitivity and specificity.
Results: Using only the MPDS code resulted in an AUC of 0.57. Using the text notes gave an improved AUC score of 0.63 and combining the two gave an AUC score of 0.64 (scores were similar for RF and GBM). GBM models scored better on sensitivity (0.93 vs 0.62 for RF in the combined model), but specificity was lower (0.17 vs. 0.56 for RF in the combined model).
Conclusions: Using information contained in the free text notes made by call handlers in combination with MPDS improves prediction of unconscious and fainting patients requiring conveyance to a hospital emergency department (or equivalent) when compared with machine learning models using MPDS codes only. This suggests there is some useful information in unstructured data captured by emergency call handlers that complements MPDS codes. Quantifying this gain can help inform emergency medical service policy when evaluating the decision to expand or augment existing CDSS.","Emergency medical services,Clinical decision support,Medical Priority Dispatch System,Natural language processing,Machine learning",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Health Care Sciences & Services,Medical Informatics",,4.768,"HOSPITAL,ADMISSIONS",INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS,https://doi.org/10.1016/j.ijmedinf.2020.104179,
39,Combining Simulation and Machine Learning as Digital Twin for the Manufacturing of Overmolded Thermoplastic Composites,4,3,,"Huerkamp Andre,Gellrich Sebastian,Ossowski Tim,Beuscher Jan,Thiede Sebastian,Herrmann Christoph,Droeder Klaus","Hurkamp A,Gellrich S,Ossowski T,Beuscher J,Thiede S,Herrmann C,Droder K",Hurkamp A,10.3390/jmmp4030092,Braunschweig University of Technology,"The design and development of composite structures requires precise and robust manufacturing processes. Composite materials such as fiber reinforced thermoplastics (FRTP) provide a good balance between manufacturing time, mechanical performance and weight. In this contribution, we investigate the process combination of thermoforming FRTP sheets (organo sheets) and injection overmolding of short FRTP for automotive structures. The limiting factor in those structures is the bond strength between the organo sheet and the overmolded thermoplastic. Within this process chain, even small deviations of the process settings (e.g., temperature) can lead to significant defects in the structure. A cyber physical production system based framework for a digital twin combining simulation and machine learning is presented. Based on parametric Finite-Element-Method (FEM) studies, training data for machine learning methods are generated and a FEM surrogate is developed. A comparison of different data-driven methods yields information on the estimation accuracy of task-specific data-driven methods. Finally, in accordance with experimental cross tension tests, the investigated FEM surrogate model is able to predict the interface bond strength quality in dependence of the process settings. The visualization into different quality domains qualifies the presented approach as decision support.","digital twin,surrogate modeling,machine learning,cyber physical production systems,thermoplastic composites,overmolding,interface bond strength",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Engineering,Materials Science",,,"PRODUCT,QUALITY",JOURNAL OF MANUFACTURING AND MATERIALS PROCESSING,https://www.mdpi.com/2504-4494/4/3/92/pdf,
40,Capsule Network Based Modeling of Multi-omics Data for Discovery of Breast Cancer-Related Genes,17,5,1605-1612,"Peng Chen,Zheng Yang,Huang De-shuang","Peng C,Zheng Y,Huang DS",Peng C,10.1109/TCBB.2019.2909905,Tongji University,"Breast cancer is one of the most common cancers all over the world, which bring about more than 450,000 deaths each year. Although this malignancy has been extensively studied by a large number of researchers, its prognosis is still poor. Since therapeutic advance can be obtained based on gene signatures, there is an urgent need to discover genes related to breast cancer that may help uncover the mechanisms in cancer progression. We propose a deep learning method for the discovery of breast cancer-related genes by using Capsule Network based Modeling of Multi-omics Data (CapsNetMMD). In CapsNetMMD, we make use of known breast cancer-related genes to transform the issue of gene identification into the issue of supervised classification. The features of genes are generated through comprehensive integration of multi-omics data, e.g., mRNA expression, z scores for mRNA expression, DNA methylation, and two forms of DNA copy-number alterations (CNAs). By modeling features based on the capsule network, we identify breast cancer-related genes with a significantly better performance than other existing machine learning methods. The predicted genes with prognostic values play potential important roles in breast cancer and may serve as candidates for biologists and medical scientists in the future studies of biomarkers.","Breast cancer,Bioinformatics,DNA,Machine learning,Convolution,Multi-omics data,capsule network,prediction of cancer-related genes,machine learning,breast cancer",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Biochemistry & Molecular Biology,Computer Science,Mathematics",,3.395,"ESTROGEN-RECEPTOR,PREDICTION,MUTATIONS,SELECTION,PLATFORM,GENOME,MATRIX,RPL14",IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS,,
41,Windkessel Model-Based Cuffless Blood Pressure Estimation Using Continuous Wave Doppler Ultrasound System,20,17,9989-9999,"Jana Biswabandhu,Oswal Kamal,Mitra Sankar,Saha Goutam,Banerjee Swapna","Jana B,Oswal K,Mitra S,Saha G,Banerjee S",Jana B,10.1109/JSEN.2020.2990648,Indian Institute of Technology System (IIT System),"Blood pressure (BP) measurement plays an essential role in the prevention of cardiovascular diseases. Studies have demonstrated Ultrasound (US) based BP analysis method combining with peripheral components of the circulatory system. In this paper, a cuffless BP measurement technique has been proposed using a portable continuous wave Doppler US system which consumes < 4 Watt of power. The US blood flow signal acquired utilizing 8 MHz pencil transducer probe from the brachial artery is denoised using soft thresholding method. The spectrogram envelope of maximum frequency is obtained by an adaptive signal noise slope intersection (SNSI) method to extract hemodynamic features. In the proposed method, 2-element Windkessel (WK) model consisting of peripheral resistance and arterial compliance is employed for BP estimation. Based on the extracted features, a machine learning algorithm determines the WK model parameters. From the experiments conducted on 85 subjects, it has been observed that both systolic and diastolic BP achieve Grade B and Grade C for British Hypertension Society (BHS) and IEEE Std. 1708 protocols, respectively. Regarding Association for the Advancement of Medical Instrumentation (AAMI) standard, diastolic BP estimation error is within an acceptable limit. The robustness of the approach is examined using pre-exercise and post-exercise performance of 10 subjects. Moreover, the effect on arterial compliance for increased BP and aging is observed to characterize the dynamic property of arterial system. The proposed method is non-invasive, non-occlusive, independent of any additional interfaces, operates with a small dataset and worthy of implementation as a portable system for point-of-care application.","Doppler effect,Estimation,Spectrogram,Feature extraction,Frequency estimation,Blood pressure,Blood,Doppler effect,blood pressure,machine learning,spectrogram,biomedical measurement",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"VELOCITY,SIGNAL,TIME,FORM",IEEE SENSORS JOURNAL,,
42,PP-Net: A Deep Learning Framework for PPG-Based Blood Pressure and Heart Rate Estimation,20,17,10000-10011,"Panwar Madhuri,Gautam Arvind,Biswas Dwaipayan,Acharyya Amit","Panwar M,Gautam A,Biswas D,Acharyya A",Acharyya A,10.1109/JSEN.2020.2990864,Indian Institute of Technology System (IIT System),"This paper presents a deep learning model 'PP-Net' which is the first of its kind, having the capability to estimate the physiological parameters: Diastolic blood pressure (DBP), Systolic blood pressure (SBP), and Heart rate (HR) simultaneously from the same network using a single channel PPG signal. The proposed model is designed by exploiting the deep learning framework of Long-term Recurrent Convolutional Network (LRCN), exhibiting inherent ability of feature extraction, thereby, eliminating the cost effective steps of feature selection and extraction, making less-complex for deployment on resource constrained platforms such as mobile platforms. The performance demonstration of the PP-Net is done on a larger and publically available MIMIC-II database. We achieved an average NMAE of 0.09 (DBP) and 0.04 (SBP) mmHg for BP, and 0.046 bpm for HR estimation on total population of 1557 critically ill subjects. The accurate estimation of HR and BP on a larger population compared to the existing methods, demonstrated the effectiveness of our proposed deep learning framework. The accurate evaluation on a huge population with CVD complications, validates the robustness of the proposed framework in pervasive healthcare monitoring especially cardiac and stroke rehabilitation monitoring.","Biomedical monitoring,Heart rate,Deep learning,Sensors,Monitoring,Estimation,Feature extraction,Heart rate,blood pressure,deep learning,long-term recurrent convolutional network (LRCN),Photoplethysmography (PPG),times-series prediction",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"PHOTOPLETHYSMOGRAPHIC,SIGNALS",IEEE SENSORS JOURNAL,,
43,Digital Microscopic Image Sensing and Processing for Leather Species Identification,20,17,10045-10056,"Varghese Anjli,Jain Sahil,Prince A. Amalin,Jawahar Malathy","Varghese A,Jain S,Prince AA,Jawahar M",Prince AA,10.1109/JSEN.2020.2991881,Birla Institute of Technology & Science Pilani (BITS Pilani),"Leather is a durable material well-known for its fashion, style, and versatility. Identifying the animal species from which leather originated is necessary in leather quality-check, fraud detection, exotic animal protection, etc. The species identification techniques currently in practice involve subjective and supervised analysis with laboratory-specific devices. This paper discusses optimized and automated species identification by employing a portable and cost-effective (economically efficient) digital microscope. The goal is to acquire the leather images of the four most predominantly used permissible species, with the definite hair-pore regions. Preliminary experiments investigate the adequate image sensing parameters for efficient sensor data processing. Otsu's thresholding followed by circular Hough transform (CHT) segments and estimates the morphological features of the informative hair-pore regions. The k-nearest neighbor (KNN) based machine learning algorithm models a pattern recognition technique for automated species prediction. Evaluation measures objectively validate the performance of the proposed pre-processing and hair-pore segmentation. The experimental analysis presents the uniqueness and significance of estimated morphological features. The study also compares KNN and Multi-Layer Perceptron (MLP) based species prediction. The comparative analysis ascertains the significance of KNN-based leather species identification with 92.5% accuracy. Thus, the present research assists in building the digital signatures of permissible leather species. It also contributes to design a cost-effective and automated leather species prediction technique with objective analysis.","Microscopy,Sensors,Skin,Image analysis,Surface morphology,Cows,Automatic species identification,circular Hough transform (CHT),digital microscopic image sensing,hair-pore segmentation,k-nearest neighbor (KNN),leather image data,morphological features",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"CLASSIFICATION,OBJECTS,DNA",IEEE SENSORS JOURNAL,,
44,A Hybrid CNN-Based Segmentation and Boosting Classifier for Real Time Sensor Spinal Cord Injury Data,20,17,10092-10101,"Ahammad Sk. Hasane,Rajesh V.,Rahman Md. Zia Ur,Lay-Ekuakille Aime","Ahammad SH,Rajesh V,Rahman MZU,Lay-Ekuakille A",Rahman MZU,10.1109/JSEN.2020.2992879,Koneru Lakshmaiah Education Foundation (K L Deemed to be University),"Convolutional Neural network (CNN) based spinal cord disease prediction has emerged as a reliable model in medical imaging applications. Spinal cord injury (SCI) detection is one of the major problems for disorder segmentation and classification. Traditionally, radiologists analyze SCI images manually in order to detect abnormal spinal disorders. Manual interpretation of high dimensional feature space makes it difficult to predict the exact category and level of severity. On the other hand, deep learning framework helps to diagnose accurately and quickly. Deep learning approach is used to classify normal abnormal SCI images automatically. This paper presents a deep learning framework for helping diagnose SCI features based on the segmentation process. In this paper, a novel CNN-deep segmentation based boosting classifier is applied on sensor SCI image data. A real-time wearable sensor is used to capture the spinal cord disorder data with different shapes and orientations. Experimental results show that the present CNN-deep segmentation based boosting classifier has high computational SCI disorder prediction compared to the existing CNN based classifiers. Experimental results proved that the present model has better performance than the existing spinal cord injury detection models in terms of true positive rate; TP = 0.9859, Accuracy = 0.9894, and Error rate = 0.019 are concerned.","Deep learning,embedded sensors,random forest,spinal cord injury disorders,support vector machine",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"MACHINE,FRAMEWORK",IEEE SENSORS JOURNAL,,
45,Optimizing Electrode Positions in 2-D Electrical Impedance Tomography Using Deep Learning,69,9,6030-6044,"Smyl Danny,Liu Dong","Smyl D,Liu D",Liu D,10.1109/TIM.2020.2970371,Chinese Academy of Sciences,"Electrical impedance tomography (EIT) is a powerful tool for nondestructive evaluation, state estimation, and process tomography, among numerous other use cases. For these applications, and in order to reliably reconstruct images of a given process using EIT, we must obtain high-quality voltage measurements from the target of interest. As such, it is obvious that the locations of electrodes used for measuring play a key role in this task. Yet, to date, methods for optimally placing electrodes either require knowledge on the EIT target (which is, in practice, never fully known) or are computationally difficult to implement numerically. In this article, we circumvent these challenges and present a straightforward deep learning-based approach for optimizing electrodes positions. It is found that the optimized electrode positions outperformed ""standard"" uniformly distributed electrode layouts in all test cases. Furthermore, it is found that the use of optimized electrode positions computed using the approach derived herein can reduce errors in EIT reconstructions as well as improve the distinguishability of EIT measurements.","Electrodes,Tomography,Deep learning,Image reconstruction,Optimization,Training,Conductivity,Deep learning,electrical impedance tomography (EIT),electrode positioning,inverse problems,neural networks,nondestructive evaluation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"OPTIMAL,CURRENT,PATTERNS,RECONSTRUCTION,STRAIN,DAMAGE",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,http://arxiv.org/pdf/1910.10077,
46,Critical Components of Industry 5.0 Towards a Successful Adoption in the Field of Manufacturing,5,3,327-348,"Javaid Mohd,Haleem Abid","Javaid M,Haleem A",Javaid M,10.1142/S2424862220500141,Jamia Millia Islamia,"The fifth industrial revolution is known as Industry 5.0 and is being evolved to focus on the personalized demand of customers. This industrial revolution is required to provide better interaction among humans and machines to achieve effective and faster outcomes. It provides a new era of personalization and solves complex problems. Digital technologies provide a new paradigm in manufacturing and eliminate repetitive jobs. It applies human intelligence to understand the requirement of a human operator. The data in manufacturing can be analyzed using machine learning and artificial intelligence (AI). This paper discusses the development of all industrial revolutions and differentiates between Industry 4.0 and Industry 5.0. Further, it identifies the significant elements and capabilities of Industry 5.0 in the manufacturing field. This paper finally identifies 17 critical components of Industry 5.0 and discusses them briefly. Intelligent machines used in this revolution are efficiently used to solve real problems. It provides higher accuracy and speeds up the industrial automation with the help of critical thinking of human resources. Industry 5.0 provides computing power to the industry, which is to facilitate the digital manufacturing systems that are built to communicate with other systems. Thus, with mass personalization, there is customer delight with higher value addition through Industry 5.0.","Capabilities,elements,Industry 4.0,Industry 5.0,manufacturing,personalization",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Business & Economics,,,"CYBER-PHYSICAL,SYSTEMS,OF-THE-ART,BIG,DATA,ARTIFICIAL-INTELLIGENCE,SMART,MATERIALS,CONCEPTUAL-MODEL,ADAPTIVE,SYSTEMS,DECISION-MAKING,VIRTUAL-REALITY,INTERNET",JOURNAL OF INDUSTRIAL INTEGRATION AND MANAGEMENT-INNOVATION AND ENTREPRENEURSHIP,,
47,Forecasting the number of firefighter interventions per region with local-differential-privacy-based data,96,,,"Arcolezi Heber H.,Couchot Jean-Francois,Cerna Selene,Guyeux Christophe,Royer Guillaume,Al Bouna Bechara,Xiao Xiaokui","Arcolezi HH,Couchot JF,Cerna S,Guyeux C,Royer G,Al Bouna B,Xiao XK",Arcolezi HH,10.1016/j.cose.2020.101888,Centre National de la Recherche Scientifique (CNRS),"Statistical studies on the number and types of firefighter interventions by region are essential to improve service to the population. It is also a preliminary step if we want to predict these interventions in order to optimize the placement of human and material resources of fire departments, for example. However, this type of data is sensitive and must be treated with the utmost care. In order to avoid any leakage of information, one can think of anonymizing them using Differential Privacy (DP), a safe method by construction. This work focuses on predicting the number of firefighter interventions in certain localities while respecting the strong concept of DP. A local Differential Privacy approach was first used to anonymize location data. Statistical estimators were then applied to reconstruct a synthetic data set that is uncorrelated from the users. Finally, a supervised learning approach using extreme gradient boosting was used to make the predictions. Experiments have shown that the anonymization-prediction method is very accurate: the introduction of noise to sanitize the data does not affect the quality of the predictions, and the predictions faithfully reflect what happened in reality. (C) 2020 Elsevier Ltd. All rights reserved.","Local differential privacy,RAPPOR mechanism,Firemen intervention location,Multi-target forecasting,XGBoost",Article,"ELSEVIER ADVANCED TECHNOLOGY, OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Computer Science,,4.573,,COMPUTERS & SECURITY,,
48,Artificial neural network implementation for masonry compressive strength estimation,173,9,635-645,"Carozza Stefano,Cimmino Maddalena","Carozza S,Cimmino M",Carozza S,10.1680/jstbu.18.00089,"SC Engn & Software Solut, San Marco Evangelista, CE, Italy.","An artificial neural network (ANN) implementation for the estimation of masonry compressive strength is presented. A heterogeneous sample is considered, including brick or stone elements, with cementitious or non-cementitious mortar. A multi-layer network was designed with sigmoidal neurons trained using a back-propagation algorithm. An object-oriented Java software program was developed in order to perform the training and the testing processes of the network, using real test data. The mean sum of square errors (SSE) was used as a global performance indicator of the network. The results obtained using the ANN were numerically compared with both real test data and with the results of empirical formulations. The comparisons showed that the ANN approach produced lower SSE than the considered formulations, with good performance on both heterogeneous masonry samples and different masonry systems. The presented approach could be particularly useful when little information is available, avoiding the need for invasive on-site tests and performing only laboratory tests on the brick (or stone) and the mortar. The ANN was able to predict the compressive masonry strength with a very small error, despite the heterogeneity of the considered sample.","brickwork & masonry,mathematical modelling,strength & testing of materials",Article,"ICE PUBLISHING, INST CIVIL ENGINEERS, 1 GREAT GEORGE ST, WESTMINISTER SW 1P 3AA, ENGLAND","Construction & Building Technology,Engineering",,1.054,"BRICK,MASONRY,BEHAVIOR,PREDICTION,WALLS,FUZZY",PROCEEDINGS OF THE INSTITUTION OF CIVIL ENGINEERS-STRUCTURES AND BUILDINGS,,
49,Improving the Actuation Speed and Multi-Cyclic Actuation Characteristics of Silicone/Ethanol Soft Actuators,9,3,,"Xia Boxi,Miriyev Aslan,Trujillo Cesar,Chen Neil,Cartolano Mark,Vartak Shivaniprashant,Lipson Hod","Xia BX,Miriyev A,Trujillo C,Chen N,Cartolano M,Vartak S,Lipson H",Lipson H,10.3390/act9030062,Columbia University,"The actuation of silicone/ethanol soft composite material-actuators is based on the phase change of ethanol upon heating, followed by the expansion of the whole composite, exhibiting high actuation stress and strain. However, the low thermal conductivity of silicone rubber hinders uniform heating throughout the material, creating overheated damaged areas in the silicone matrix and accelerating ethanol evaporation. This limits the actuation speed and the total number of operation cycles of these thermally-driven soft actuators. In this paper, we showed that adding 8 wt.% of diamond nanoparticle-based thermally conductive filler increases the thermal conductivity (from 0.190 W/mK to 0.212 W/mK), actuation speed and amount of operation cycles of silicone/ethanol actuators, while not affecting the mechanical properties. We performed multi-cyclic actuation tests and showed that the faster and longer operation of 8 wt.% filler material-actuators allows collecting enough reliable data for computational methods to model further actuation behavior. We successfully implemented a long short-term memory (LSTM) neural network model to predict the actuation force exerted in a uniform multi-cyclic actuation experiment. This work paves the way for a broader implementation of soft thermally-driven actuators in various robotic applications.","soft actuator,silicone,ethanol,actuation speed,thermal conductivity,multi-cyclic actuation,mechanical properties,performance prediction,machine learning,neural networks",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Engineering,Instruments & Instrumentation",,2.623,"COMPOSITES,DESIGN",ACTUATORS,https://www.mdpi.com/2076-0825/9/3/62/pdf,
50,CT Radiomics in Colorectal Cancer: Detection of KRAS Mutation Using Texture Analysis and Machine Learning,10,18,,"Gonzalez-Castro Victor,Cernadas Eva,Huelga Emilio,Fernandez-Delgado Manuel,Porto Jacobo,Antunez Jose Ramon,Souto-Bayarri Miguel","Gonzalez-Castro V,Cernadas E,Huelga E,Fernandez-Delgado M,Porto J,Antunez JR,Souto-Bayarri M",Cernadas E,10.3390/app10186214,University of Santiago De Compostela,"Featured Application
Detection of the KRAS mutation without an invasive technique (biopsy) may have an important role in the diagnosis, prognosis, treatment, and monitoring of the patients with colorectal cancer. Machine learning algorithms allow determination of the presence of the mutation from the analysis of the CT image, and prevent mistakes by biopsying only part of the tumour.
In this work, by using descriptive techniques, the characteristics of the texture of the CT (computed tomography) image of patients with colorectal cancer were extracted and, subsequently, classified in KRAS+ or KRAS-. This was accomplished by using different classifiers, such as Support Vector Machine (SVM), Grading Boosting Machine (GBM), Neural Networks (NNET), and Random Forest (RF). Texture analysis can provide a quantitative assessment of tumour heterogeneity by analysing both the distribution and relationship between the pixels in the image. The objective of this research is to demonstrate that CT-based Radiomics can predict the presence of mutation in the KRAS gene in colorectal cancer. This is a retrospective study, with 47 patients from the University Hospital, with a confirmatory pathological analysis of KRAS mutation. The highest accuracy and kappa achieved were 83% and 64.7%, respectively, with a sensitivity of 88.9% and a specificity of 75.0%, achieved by the NNET classifier using the texture feature vectors combining wavelet transform and Haralick coefficients. The fact of being able to identify the genetic expression of a tumour without having to perform either a biopsy or a genetic test is a great advantage, because it prevents invasive procedures that involve complications and may present biases in the sample. As well, it leads towards a more personalized and effective treatment.","KRAS mutation,colorectal cancer,texture analysis,wavelets,haralick texture descriptors,Support Vector Machine,Grading Boosting Machine,Neural Network,Random Forest",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"CLASSIFICATION,PREDICTION,FEATURES,IMAGES",APPLIED SCIENCES-BASEL,https://minerva.usc.es/xmlui/bitstream/10347/23660/1/2020_applsci_gonzalez_ct.pdf,
51,Automatic Detection of Airway Invasion from Videofluoroscopy via Deep Learning Technology,10,18,,"Lee Seong Jae,Ko Joo Young,Kim Hyun Il,Choi Sang-Il","Lee SJ,Ko JY,Kim HI,Choi SI",Choi SI,10.3390/app10186179,Dankook University,"In dysphagia, food materials frequently invade the laryngeal airway, potentially resulting in serious consequences, such as asphyxia or pneumonia. The VFSS (videofluoroscopic swallowing study) procedure can be used to visualize the occurrence of airway invasion, but its reliability is limited by human errors and fatigue. Deep learning technology may improve the efficiency and reliability of VFSS analysis by reducing the human effort required. A deep learning model has been developed that can detect airway invasion from VFSS images in a fully automated manner. The model consists of three phases: (1) image normalization, (2) dynamic ROI (region of interest) determination, and (3) airway invasion detection. Noise induced by movement and learning from unintended areas is minimized by defining a ""dynamic"" ROI with respect to the center of the cervical spinal column as segmented using U-Net. An Xception module, trained on a dataset consisting of 267,748 image frames obtained from 319 VFSS video files, is used for the detection of airway invasion. The present model shows an overall accuracy of 97.2% in classifying image frames and 93.2% in classifying video files. It is anticipated that the present model will enable more accurate analysis of VFSS data.","deglutition disorders,aspiration,videofluoroscopy,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"INTERRATER,RELIABILITY,INTRARATER,DYSPHAGIA,TRACKING",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/18/6179/pdf,
52,A natural language processing approach based on embedding deep learning from heterogeneous compounds for quantitative structure-activity relationship modeling,96,3,961-972,"Bouhedjar Khalid,Boukelia Abdelbasset,Khorief Nacereddine Abdelmalek,Boucheham Anouar,Belaidi Amine,Djerourou Abdelhafid","Bouhedjar K,Boukelia A,Nacereddine AK,Boucheham A,Belaidi A,Djerourou A",Bouhedjar K,10.1111/cbdd.13742,Universite Badji Mokhtar - Annaba,"Over the past decade, rapid development in biological and chemical technologies such as high-throughput screening, parallel synthesis, has been significantly increased the amount of data, which requires the creation and the integration of new analytical methods, especially deep learning models. Recently, there is an increasing interest in deep learning utilization in computer-aided drug discovery due to its exceptional successful application in many fields. The present work proposed a natural language processing approach, based on embedding deep neural networks. Our method aims to transform the Simplified Molecular Input Line Entry System format into word embedding vectors to represent the semantics of compounds. These vectors are fed into supervised machine learning algorithms such as convolutional long short-term memory neural network, support vector machine, and random forest to build up quantitative structure-activity relationship models on toxicity data sets. The obtained results on toxicity data to the ciliateTetrahymena pyriformis(IGC(50)), and acute toxicity rat data expressed as median lethal dose of treated rats (LD50) show that our approach can eventually be used to predict the activities of chemical compounds efficiently. All material used in this study is available online through the GitHub portal ().","deep learning,embedding deep neural network,machine learning,natural language processing,QSAR,SMILES,toxicity",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Biochemistry & Molecular Biology,Pharmacology & Pharmacy",,,"LINE,ENTRY,SYSTEM,TOXICITY,PREDICTION,FEATURE-SELECTION,NEURAL-NETWORKS,RANDOM,FOREST,QSAR,DERIVATIVES,INHIBITOR",CHEMICAL BIOLOGY & DRUG DESIGN,,
53,"Comparison of Support Vector Machine, Naive Bayes and Logistic Regression for Assessing the Necessity for Coronary Angiography",17,18,,"Golpour Parastoo,Ghayour-Mobarhan Majid,Saki Azadeh,Esmaily Habibollah,Taghipour Ali,Tajfard Mohammad,Ghazizadeh Hamideh,Moohebati Mohsen,Ferns Gordon A.","Golpour P,Ghayour-Mobarhan M,Saki A,Esmaily H,Taghipour A,Tajfard M,Ghazizadeh H,Moohebati M,Ferns GA",Saki A,10.3390/ijerph17186449,Mashhad University Medical Science,"(1) Background: Coronary angiography is considered to be the most reliable method for the diagnosis of cardiovascular disease. However, angiography is an invasive procedure that carries a risk of complications; hence, it would be preferable for an appropriate method to be applied to determine the necessity for angiography. The objective of this study was to compare support vector machine, naive Bayes and logistic regressions to determine the diagnostic factors that can predict the need for coronary angiography. These models are machine learning algorithms. Machine learning is considered to be a branch of artificial intelligence. Its aims are to design and develop algorithms that allow computers to improve their performance on data analysis and decision making. The process involves the analysis of past experiences to find practical and helpful regularities and patterns, which may also be overlooked by a human. (2) Materials and Methods: This cross-sectional study was performed on 1187 candidates for angiography referred to Ghaem Hospital, Mashhad, Iran from 2011 to 2012. A logistic regression, naive Bayes and support vector machine were applied to determine whether they could predict the results of angiography. Afterwards, the sensitivity, specificity, positive and negative predictive values, AUC (area under the curve) and accuracy of all three models were computed in order to compare them. All analyses were performed using R 3.4.3 software (R Core Team; Auckland, New Zealand) with the help of other software packages including receiver operating characteristic (ROC), caret, e1071 and rminer. (3) Results: The area under the curve for logistic regression, naive Bayes and support vector machine were similar-0.76, 0.74 and 0.75, respectively. Thus, in terms of the model parsimony and simplicity of application, the naive Bayes model with three variables had the best performance in comparison with the logistic regression model with seven variables and support vector machine with six variables. (4) Conclusions: Gender, age and fasting blood glucose (FBG) were found to be the most important factors to predict the result of coronary angiography. The naive Bayes model performed well using these three variables alone, and they are considered important variables for the other two models as well. According to an acceptable prediction of the models, they can be used as pragmatic, cost-effective and valuable methods that support physicians in decision making.","logistic regression,support vector machine,na&#239,ve Bayes,angiography",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Public, Environmental & Occupational Health",,3.789,,INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7558963,
54,Explainable classifier for improving the accountability in decision-making for colorectal cancer diagnosis from histopathological images,109,,,"Sabol Patrik,Sincak Peter,Hartono Pitoyo,Kocan Pavel,Benetinova Zuzana,Blicharova Alzbeta,Verboova Ludmila,Stammova Erika,Sabolova-Fabianova Antonia,Jaskova Anna","Sabol P,Sincak P,Hartono P,Kocan P,Benetinova Z,Blicharova A,Verboova L,Stammova E,Sabolova-Fabianova A,Jaskova A",Sabol P,10.1016/j.jbi.2020.103523,Technical University Kosice,"Pathologists are responsible for cancer type diagnoses from histopathological cancer tissues. However, it is known that microscopic examination is tedious and time-consuming. In recent years, a long list of machine learning approaches to image classification and whole-slide segmentation has been developed to support pathologists. Although many showed exceptional performances, the majority of them are not able to rationalize their decisions. In this study, we developed an explainable classifier to support decision making for medical diagnoses. The proposed model does not provide an explanation about the causality between the input and the decisions, but offers a human-friendly explanation about the plausibility of the decision. Cumulative Fuzzy Class Membership Criterion (CFCMC) explains its decisions in three ways: through a semantical explanation about the possibilities of misclassification, showing the training sample responsible for a certain prediction and showing training samples from conflicting classes. In this paper, we explain about the mathematical structure of the classifier, which is not designed to be used as a fully automated diagnosis tool but as a support system for medical experts. We also report on the accuracy of the classifier against real world histopathological data for colorectal cancer. We also tested the acceptability of the system through clinical trials by 14 pathologists. We show that the proposed classifier is comparable to state of the art neural networks in accuracy, but more importantly it is more acceptable to be used by human experts as a diagnosis tool in the medical domain.","Explainable artificial intelligence,Uncertainty measure,Digital pathology,Colorectal cancer",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Computer Science,Medical Informatics",,5.221,,JOURNAL OF BIOMEDICAL INFORMATICS,https://doi.org/10.1016/j.jbi.2020.103523,
55,An LSTM Approach for SAG Mill Operational Relative-Hardness Prediction,10,9,,"Avalos Sebastian,Kracht Willy,Ortiz Julian M.","Avalos S,Kracht W,Ortiz JM",Avalos S,10.3390/min10090734,Queens University - Canada,"Ore hardness plays a critical role in comminution circuits. Ore hardness is usually characterized at sample support in order to populate geometallurgical block models. However, the required attributes are not always available and suffer for lack of temporal resolution. We propose an operational relative-hardness definition and the use of real-time operational data to train a Long Short-Term Memory, a deep neural network architecture, to forecast the upcoming operational relative-hardness. We applied the proposed methodology on two SAG mill datasets, of one year period each. Results show accuracies above 80% on both SAG mills at a short upcoming period of times and around 1% of misclassifications between soft and hard characterization. The proposed application can be extended to any crushing and grinding equipment to forecast categorical attributes that are relevant to downstream processes.","semi-autogenous grinding mill,operational hardness,energy consumption,mining,deep learning,long short-term memory",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Geochemistry & Geophysics,Mineralogy,Mining & Mineral Processing",,2.737,"MODEL,POWER",MINERALS,https://www.mdpi.com/2075-163X/10/9/734/pdf,
56,Comparative Analysis of Machine Learning Models for Nanofluids Viscosity Assessment,10,9,,"Shateri Mohammadhadi,Sobhanigavgani Zeinab,Alinasab Azin,Varamesh Amir,Hemmati-Sarapardeh Abdolhossein,Mosavi Amir,Shahab S.","Shateri M,Sobhanigavgani Z,Alinasab A,Varamesh A,Hemmati-Sarapardeh A,Mosavi A,Shahab S",Hemmati-Sarapardeh A,10.3390/nano10091767,Shahid Bahonar University of Kerman (SBUK),"The process of selecting a nanofluid for a particular application requires determining the thermophysical properties of nanofluid, such as viscosity. However, the experimental measurement of nanofluid viscosity is expensive. Several closed-form formulas for calculating the viscosity have been proposed by scientists based on theoretical and empirical methods, but these methods produce inaccurate results. Recently, a machine learning model based on the combination of seven baselines, which is called the committee machine intelligent system (CMIS), was proposed to predict the viscosity of nanofluids. CMIS was applied on 3144 experimental data of relative viscosity of 42 different nanofluid systems based on five features (temperature, the viscosity of the base fluid, nanoparticle volume fraction, size, and density) and returned an average absolute relative error (AARE) of 4.036% on the test. In this work, eight models (on the same dataset as the one used in CMIS), including two multilayer perceptron (MLP), each with Nesterov accelerated adaptive moment (Nadam) optimizer; two MLP, each with three hidden layers and Adamax optimizer; a support vector regression (SVR) with radial basis function (RBF) kernel; a decision tree (DT); tree-based ensemble models, including random forest (RF) and extra tree (ET), were proposed. The performance of these models at different ranges of input variables was assessed and compared with the ones presented in the literature. Based on our result, all the eight suggested models outperformed the baselines used in the literature, and five of our presented models outperformed the CMIS, where two of them returned an AARE less than 3% on the test data. Besides, the physical validity of models was studied by examining the physically expected trends of nanofluid viscosity due to changing volume fraction.","nanofluid viscosity,experimental data,machine learning,deep learning,nano,nanomaterials,nanofluid,artificial neural network,data science,big data,ensemble models,artificial intelligence,computational fluid dynamics,computational mechanics",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,5.346,"WATER-BASED,AL2O3,THERMAL-CONDUCTIVITY,ETHYLENE-GLYCOL,HEAT-TRANSFER,VOLUME,CONCENTRATIONS,RHEOLOGICAL,BEHAVIOR,PARTICLE-SIZE,TEMPERATURE,PREDICTION,TIO2",NANOMATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7558292,
57,Automated identification of the predominant site of upper airway collapse in obstructive sleep apnoea patients using snore signal,41,9,,"Sebastian Arun,Cistulli Peter A.,Cohen Gary,de Chazal Philip","Sebastian A,Cistulli PA,Cohen G,de Chazal P",Sebastian A,10.1088/1361-6579/abaa33,University of Sydney,"Objective: This study provides a novel approach for an automated system using a machine learning algorithm to predict the predominant site of upper airway collapse into four classes ('lateral wall', 'palate', 'tongue-base' related collapse or 'multi-level' site-of-collapse) in obstructive sleep apnoea (OSA) patients from the audio signal recorded during normal sleep.Approach: Snore sounds from 58 patients were recorded simultaneously with full-night polysomnography during sleep with a ceiling mounted microphone. The probable site-of-airway collapse was determined by manual analysis of the shape of the airflow signal during hypopnoea. Time and frequency features of the audio signal were extracted from each hypopnoea event to classify the audio signal into 'lateral wall', 'palate' and 'tongue-base' related collapse according to prior research. The data was divided into two sets. The Learning Set contained the data of the first 45 patients and was used for building the model. The Hidden Set contained the data from the remaining 13 patients and was used for testing the performance of the model. Feature selection was employed to boost the classification performance. The classification was carried out with a multi-class linear discriminant analysis classifier to classify the predominant site-of-collapse for a patient into the four classes. Performance was evaluated by comparing the automatic and manually labelled data based on the predominant site-of-collapse and calculating the accuracy.Main results: The model achieved an overall accuracy on the Hidden Set of 77% for discriminating tongue/non-tongue collapse and an accuracy of 62% accuracy for all site-of-collapse classes.Significance: Our results demonstrate that the audio signal recorded during sleep can successfully identify the site-of-collapse in the upper airway. The additional information regarding the obstruction site may assist clinicians in deciding the most appropriate treatment for OSA.","obstructive sleep apnoea,snore recording,predominant site-of-collapse,hypopnoea,airflow signal,nested cross validation,linear discriminant analysis classifier",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"SOUND,CLASSIFICATION",PHYSIOLOGICAL MEASUREMENT,,
58,Heartbeat Detection by Laser Doppler Vibrometry and Machine Learning,20,18,,"Antognoli Luca,Moccia Sara,Migliorelli Lucia,Casaccia Sara,Scalise Lorenzo,Frontoni Emanuele","Antognoli L,Moccia S,Migliorelli L,Casaccia S,Scalise L,Frontoni E",Moccia S,10.3390/s20185362,Marche Polytechnic University,"Background: Heartbeat detection is a crucial step in several clinical fields. Laser Doppler Vibrometer (LDV) is a promising non-contact measurement for heartbeat detection. The aim of this work is to assess whether machine learning can be used for detecting heartbeat from the carotid LDV signal. Methods: The performances of Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF) and K-Nearest Neighbor (KNN) were compared using the leave-one-subject-out cross-validation as the testing protocol in an LDV dataset collected from 28 subjects. The classification was conducted on LDV signal windows, which were labeled as beat, if containing a beat, or no-beat, otherwise. The labeling procedure was performed using electrocardiography as the gold standard. Results: For the beat class, the f1-score (f1) values were 0.93, 0.93, 0.95, 0.96 for RF, DT, KNN and SVM, respectively. No statistical differences were found between the classifiers. When testing the SVM on the full-length (10 min long) LDV signals, to simulate a real-world application, we achieved a median macro-f1 of 0.76. Conclusions: Using machine learning for heartbeat detection from carotid LDV signals showed encouraging results, representing a promising step in the field of contactless cardiovascular signal analysis.","laser doppler vibrometry,machine learning,support vector machines,contactless measurements,heartbeat,heart rate detection",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"CAROTID-ARTERY,NONCONTACT,APPROACH,CLASSIFICATION,VALIDATION,EXTRACTION,PRESSURE,DIAMETER,SYSTEM,SENSOR,TIME",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7571227,
59,Deep Recurrent Neural Networks for Automatic Detection of Sleep Apnea from Single Channel Respiration Signals,20,18,,"ElMoaqet Hisham,Eid Mohammad,Glos Martin,Ryalat Mutaz,Penzel Thomas","ElMoaqet H,Eid M,Glos M,Ryalat M,Penzel T",ElMoaqet H,10.3390/s20185037,German-Jordanian University,"Sleep apnea is a common sleep disorder that causes repeated breathing interruption during sleep. The performance of automated apnea detection methods based on respiratory signals depend on the signals considered and feature extraction methods. Moreover, feature engineering techniques are highly dependent on the experts' experience and their prior knowledge about different physiological signals and conditions of the subjects. To overcome these problems, a novel deep recurrent neural network (RNN) framework is developed for automated feature extraction and detection of apnea events from single respiratory channel inputs. Long short-term memory (LSTM) and bidirectional long short-term memory (BiLSTM) are investigated to develop the proposed deep RNN model. The proposed framework is evaluated over three respiration signals: Oronasal thermal airflow (FlowTh), nasal pressure (NPRE), and abdominal respiratory inductance plethysmography (ABD). To demonstrate our results, we use polysomnography (PSG) data of 17 patients with obstructive, central, and mixed apnea events. Our results indicate the effectiveness of the proposed framework in automatic extraction for temporal features and automated detection of apneic events over the different respiratory signals considered in this study. Using a deep BiLSTM-based detection model, the NPRE signal achieved the highest overall detection results with true positive rate (sensitivity) = 90.3%, true negative rate (specificity) = 83.7%, and area under receiver operator characteristic curve = 92.4%. The present results contribute a new deep learning approach for automated detection of sleep apnea events from single channel respiration signals that can potentially serve as a helpful and alternative tool for the traditional PSG method.","sleep apnea,deep learning,recurrent neural network,long short-term memory,sleep-disordered breathing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"AIR-FLOW,RECORDINGS,HYPOPNEA,SYNDROME,PRESSURE,TRANSDUCER,EVENTS,DIAGNOSIS,SENSOR,CLASSIFICATION,ACCURACY,PLETHYSMOGRAPHY,RELIABILITY",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7570636,
60,Detection of Gait Abnormalities for Fall Risk Assessment Using Wrist-Worn Inertial Sensors and Deep Learning,20,18,,"Kiprijanovska Ivana,Gjoreski Hristijan,Gams Matjaz","Kiprijanovska I,Gjoreski H,Gams M",Kiprijanovska I,10.3390/s20185373,Slovenian Academy of Sciences & Arts (SASA),"Falls are a significant threat to the health and independence of elderly people and represent an enormous burden on the healthcare system. Successfully predicting falls could be of great help, yet this requires a timely and accurate fall risk assessment. Gait abnormalities are one of the best predictive signs of underlying locomotion conditions and precursors of falls. The advent of wearable sensors and wrist-worn devices provides new opportunities for continuous and unobtrusive monitoring of gait during daily activities, including the identification of unexpected changes in gait. To this end, we present in this paper a novel method for determining gait abnormalities based on a wrist-worn device and a deep neural network. It integrates convolutional and bidirectional long short-term memory layers for successful learning of spatiotemporal features from multiple sensor signals. The proposed method was evaluated using data from 18 subjects, who recorded their normal gait and simulated abnormal gait while wearing impairment glasses. The data consist of inertial measurement unit (IMU) sensor signals obtained from smartwatches that the subjects wore on both wrists. Numerous experiments showed that the proposed method provides better results than the compared methods, achieving 88.9% accuracy, 90.6% sensitivity, and 86.2% specificity in the detection of abnormal walking patterns using data from an accelerometer, gyroscope, and rotation vector sensor. These results indicate that reliable fall risk assessment is possible based on the detection of walking abnormalities with the use of wearable sensors on a wrist.","fall risk assessment,balance deficit,gait abnormalities,information fusion,smartwatch,inertial sensors,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"OLDER-PEOPLE,CLASSIFICATION,ADULTS,IDENTIFICATION,ASSOCIATION",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7571106,
61,Turning Detection During Gait: Algorithm Validation and Influence of Sensor Location and Turning Characteristics in the Classification of Parkinson's Disease,20,18,,"Rehman Rana Zia Ur,Klocke Philipp,Hryniv Sofia,Galna Brook,Rochester Lynn,Del Din Silvia,Alcock Lisa","Rehman RZU,Klocke P,Hryniv S,Galna B,Rochester L,Del Din S,Alcock L",Alcock L,10.3390/s20185377,Newcastle University - UK,"Parkinson's disease (PD) is a common neurodegenerative disorder resulting in a range of mobility deficits affecting gait, balance and turning. In this paper, we present: (i) the development and validation of an algorithm to detect turns during gait; (ii) a method to extract turn characteristics; and (iii) the classification of PD using turn characteristics. Thirty-seven people with PD and 56 controls performed 180-degree turns during an intermittent walking task. Inertial measurement units were attached to the head, neck, lower back and ankles. A turning detection algorithm was developed and validated by two raters using video data. Spatiotemporal and signal-based characteristics were extracted and used for PD classification. There was excellent absolute agreement between the rater and the algorithm for identifying turn start and end (ICC >= 0.99). Classification modeling (partial least square discriminant analysis (PLS-DA)) gave the best accuracy of 97.85% when trained on upper body and ankle data. Balanced sensitivity (97%) and specificity (96.43%) were achieved using turning characteristics from the neck, lower back and ankles. Turning characteristics, in particular angular velocity, duration, number of steps, jerk and root mean square distinguished mild-moderate PD from controls accurately and warrant future examination as a marker of mobility impairment and fall risk in PD.","inertial measurement unit (IMU),wearables,upper body,lower body,spatial-temporal characteristics,signal-based characteristics,validation,machine learning,PLS-DA",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"OLDER-ADULTS,PEOPLE,FALLS,COORDINATION,WALKING,ASSOCIATION,FEATURES,HEAD",SENSORS,https://researchrepository.murdoch.edu.au/id/eprint/62677/1/Turning%20detection%20during%20gait%20-%20Algorithm%20validation%20and%20influence%20of%20sensor%20location%20and%20turning%20characteristics%20in%20the%20classification%20of%20Parkinson%E2%80%99s%20disease.pdf,
62,Estimation Method of Soluble Solid Content in Peach Based on Deep Features of Hyperspectral Imagery,20,18,,"Yang Baohua,Gao Yuan,Yan Qian,Qi Lin,Zhu Yue,Wang Bing","Yang BH,Gao Y,Yan Q,Qi L,Zhu Y,Wang B",Wang B,10.3390/s20185021,Anhui University of Technology,"Soluble solids content (SSC) is one of the important components for evaluating fruit quality. The rapid development of hyperspectral imagery provides an efficient method for non-destructive detection of SSC. Previous studies have shown that the internal quality evaluation of fruits based on spectral information features achieves better results. However, the lack of comprehensive features limits the accurate estimation of fruit quality. Therefore, the deep learning theory is applied to the estimation of the soluble solid content of peaches, a method for estimating the SSC of fresh peaches based on the deep features of the hyperspectral image fusion information is proposed, and the estimation models of different neural network structures are designed based on the stack autoencoder-random forest (SAE-RF). The results show that the accuracy of the model based on the deep features of the fusion information of hyperspectral imagery is higher than that of the model based on spectral features or image features alone. In addition, the SAE-RF model based on the 1237-650-310-130 network structure has the best prediction effect (R-2 = 0.9184, RMSE = 0.6693). Our research shows that the proposed method can improve the estimation accuracy of the soluble solid content of fresh peaches, which provides a theoretical basis for the non-destructive detection of other components of fresh peaches.","soluble solids content,hyperspectral imagery,random forest,peach,deep features",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"NONDESTRUCTIVE,DETERMINATION,FLUORESCENCE,SPECTROSCOPY,PREDICTING,FIRMNESS,NIR,SPECTROSCOPY,APPLES,SPECTRUM,MODELS",SENSORS,https://www.mdpi.com/1424-8220/20/18/5021/pdf,
63,BassNet: A Variational Gated Autoencoder for Conditional Generation of Bass Guitar Tracks with Learned Interactive Control,10,18,,"Grachten Maarten,Lattner Stefan,Deruty Emmanuel","Grachten M,Lattner S,Deruty E",Grachten M,10.3390/app10186627,"Sony Comp Sci Labs, F-75005 Paris, France.","Deep learning has given AI-based methods for music creation a boost by over the past years. An important challenge in this field is to balance user control and autonomy in music generation systems. In this work, we present BassNet, a deep learning model for generating bass guitar tracks based on musical source material. An innovative aspect of our work is that the model is trained to learn a temporally stable two-dimensional latent space variable that offers interactive user control. We empirically show that the model can disentangle bass patterns that require sensitivity to harmony, instrument timbre, and rhythm. An ablation study reveals that this capability is because of the temporal stability constraint on latent space trajectories during training. We also demonstrate that models that are trained on pop/rock music learn a latent space that offers control over the diatonic characteristics of the output, among other things. Lastly, we present and discuss generated bass tracks for three different music fragments. The work that is presented here is a step toward the integration of AI-based technology in the workflow of musical content creators.","music generation,deep learning,latent space models,user control",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/18/6627/pdf,
64,The Application of Artificial Intelligence in Prostate Cancer Management-What Improvements Can Be Expected? A Systematic Review,10,18,,"Thenault Ronan,Kaulanjan Kevin,Darde Thomas,Rioux-Leclercq Nathalie,Bensalah Karim,Mermier Marie,Khene Zine-eddine,Peyronnet Benoit,Shariat Shahrokh,Pradere Benjamin","Thenault R,Kaulanjan K,Darde T,Rioux-Leclercq N,Bensalah K,Mermier M,Khene ZE,Peyronnet B,Shariat S,Pradere B",Thenault R,10.3390/app10186428,"IRSET, F-35000 Rennes, France.","Artificial Intelligence (AI) is progressively remodeling our daily life. A large amount of information from ""big data"" now enables machines to perform predictions and improve our healthcare system. AI has the potential to reshape prostate cancer (PCa) management thanks to growing applications in the field. The purpose of this review is to provide a global overview of AI in PCa for urologists, pathologists, radiotherapists, and oncologists to consider future changes in their daily practice. A systematic review was performed, based on PubMed MEDLINE, Google Scholar, and DBLP databases for original studies published in English from January 2009 to January 2019 relevant to PCa, AI, Machine Learning, Artificial Neural Networks, Convolutional Neural Networks, and Natural-Language Processing. Only articles with full text accessible were considered. A total of 1008 articles were reviewed, and 48 articles were included. AI has potential applications in all fields of PCa management: analysis of genetic predispositions, diagnosis in imaging, and pathology to detect PCa or to differentiate between significant and non-significant PCa. AI also applies to PCa treatment, whether surgical intervention or radiotherapy, skills training, or assessment, to improve treatment modalities and outcome prediction. AI in PCa management has the potential to provide a useful role by predicting PCa more accurately, using a multiomic approach and risk-stratifying patients to provide personalized medicine.","artificial intelligence,machine learning,deep learning artificial neural network,natural-language processing,prostate cancer,computer-aided diagnosis,prediction performance,individualized medicine,healthcare improvement,outcomes,diagnosis,prognosis,treatment",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"COMPUTER-AIDED,DIAGNOSIS,MACHINE,LEARNING,TECHNIQUES,SUPPORT,VECTOR,MACHINE,AUGMENTED,REALITY,NEURAL-NETWORK,RADICAL,PROSTATECTOMY,SURGICAL,NAVIGATION,ASSISTED,ANALYSIS,PARTIN,TABLES,MR-IMAGES",APPLIED SCIENCES-BASEL,https://hal-univ-rennes1.archives-ouvertes.fr/hal-02996051/file/applsci-10-06428-v3.pdf,
65,Nondestructive Evaluation of Thermal Barrier Coatings Interface Delamination Using Terahertz Technique Combined with SWT-PCA-GA-BP Algorithm,10,9,,"Ye Dongdong,Wang Weize,Yin Changdong,Xu Zhou,Fang Huanjie,Huang Jibo,Li Yuanjun","Ye DD,Wang WZ,Yin CD,Xu Z,Fang HJ,Huang JB,Li YJ",Wang WZ,10.3390/coatings10090859,East China University of Science & Technology,"Thermal barrier coatings (TBCs) are usually subjected to the combined action of compressive stress, tensile stress, and bending shear stress, resulting in the interfacial delamination of TBCs, and finally causing the ceramic top coat to peel off. Hence, it is vital to detect the early-stage subcritical delamination cracks. In this study, a novel hybrid artificial neural network combined with the terahertz nondestructive technology was presented to predict the thickness of interface delamination in the early stage. The finite difference time domain (FDTD) algorithm was used to obtain the raw terahertz time-domain signals of 32 TBCs samples with various thicknesses of interface delamination, not only that, the influence of roughness and the thickness of the ceramic top layer were considered comprehensively when modeling. The stationary wavelet transform (SWT) and principal component analysis (PCA) methods were employed to extract the signal features and reduce the data dimensions before modeling, to make the cumulative contribution rate reach 100%, the first 31 components of the SWT detail data was used as the input data during modeling. Finally, a back propagation (BP) neural network method optimized by the genetic algorithm (GA-BP) was proposed to set up the interface delamination thickness prediction model. As a result, the root correlation coefficientR(2)reached over 0.95, the various errors-including the mean square error, mean squared percentage error, and mean absolute percentage error-were less than or equal to 0.53. All these indicators proved that the trained hybrid SWT-PCA-GA-BP model had excellent prediction performance and high accuracy. Finally, this work proposed a novel and convenient interface delamination evaluation method that could also be potentially utilized to evaluate the structural integrity of TBCs.","TBCs,terahertz technique,interface delamination,FDTD,SWT-PCA-GA-BP",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Materials Science,Physics",,3.038,"NEURAL-NETWORK,GENETIC,ALGORITHM,OPTIMIZATION,PREDICTION,THICKNESS,POROSITY,MODEL",COATINGS,https://www.mdpi.com/2079-6412/10/9/859/pdf,
66,End-To-End Deep Learning Framework for Coronavirus (COVID-19) Detection and Monitoring,9,9,,"El-Rashidy Nora,El-Sappagh Shaker,Islam S. M. Riazul,El-Bakry Hazem M.,Abdelrazek Samir","El-Rashidy N,El-Sappagh S,Islam SMR,El-Bakry HM,Abdelrazek S",El-Sappagh S,10.3390/electronics9091439,University of Santiago De Compostela,"Coronavirus (COVID-19) is a new virus of viral pneumonia. It can outbreak in the world through person-to-person transmission. Although several medical companies provide cooperative monitoring healthcare systems, these solutions lack offering of the end-to-end management of the disease. The main objective of the proposed framework is to bridge the current gap between current technologies and healthcare systems. The wireless body area network, cloud computing, fog computing, and clinical decision support system are integrated to provide a comprehensive and complete model for disease detection and monitoring. By monitoring a person with COVID-19 in real time, physicians can guide patients with the right decisions. The proposed framework has three main layers (i.e., a patient layer, cloud layer, and hospital layer). In the patient layer, the patient is tracked through a set of wearable sensors and a mobile app. In the cloud layer, a fog network architecture is proposed to solve the issues of storage and data transmission. In the hospital layer, we propose a convolutional neural network-based deep learning model for COVID-19 detection based on patient's X-ray scan images and transfer learning. The proposed model achieved promising results compared to the state-of-the art (i.e., accuracy of 97.95% and specificity of 98.85%). Our framework is a useful application, through which we expect significant effects on COVID-19 proliferation and considerable lowering in healthcare expenses.","electronic health,electronic health record,COVID-19,clinical-decision support system,convolutional neural network,deep learning,remote patient monitoring,wireless body area network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"DECISION-SUPPORT-SYSTEM,INTERNET,MODEL",ELECTRONICS,https://www.mdpi.com/2079-9292/9/9/1439/pdf,
67,A Deep-Learning-Based Framework for Automated Diagnosis of COVID-19 Using X-ray Images,11,9,,"Khan Irfan Ullah,Aslam Nida","Khan IU,Aslam N",Aslam N,10.3390/info11090419,Imam Abdulrahman Bin Faisal University,"The emergence and outbreak of the novel coronavirus (COVID-19) had a devasting effect on global health, the economy, and individuals' daily lives. Timely diagnosis of COVID-19 is a crucial task, as it reduces the risk of pandemic spread, and early treatment will save patients' life. Due to the time-consuming, complex nature, and high false-negative rate of the gold-standard RT-PCR test used for the diagnosis of COVID-19, the need for an additional diagnosis method has increased. Studies have proved the significance of X-ray images for the diagnosis of COVID-19. The dissemination of deep-learning techniques on X-ray images can automate the diagnosis process and serve as an assistive tool for radiologists. In this study, we used four deep-learning models-DenseNet121, ResNet50, VGG16, and VGG19-using the transfer-learning concept for the diagnosis of X-ray images as COVID-19 or normal. In the proposed study, VGG16 and VGG19 outperformed the other two deep-learning models. The study achieved an overall classification accuracy of 99.3%.","deep-learning,transfer-learning,COVID-19,coronavirus,pandemic",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"CHEST,RADIOGRAPHS,CLASSIFICATION,SEGMENTATION",INFORMATION,https://www.mdpi.com/2078-2489/11/9/419/pdf,
68,Artificial Intelligence-Based Bolt Loosening Diagnosis Using Deep Learning Algorithms for Laser Ultrasonic Wave Propagation Data,20,18,,"Dai Quoc Tran,Kim Ju-Won,Tola Kassahun Demissie,Kim Wonkyu,Park Seunghee","Tran DQ,Kim JW,Tola KD,Kim W,Park S",Park S,10.3390/s20185329,Sungkyunkwan University (SKKU),"The application of deep learning (DL) algorithms to non-destructive evaluation (NDE) is now becoming one of the most attractive topics in this field. As a contribution to such research, this study aims to investigate the application of DL algorithms for detecting and estimating the looseness in bolted joints using a laser ultrasonic technique. This research was conducted based on a hypothesis regarding the relationship between the true contact area of the bolt head-plate and the guided wave energy lost while the ultrasonic waves pass through it. First, a Q-switched Nd:YAG pulsed laser and an acoustic emission sensor were used as exciting and sensing ultrasonic signals, respectively. Then, a 3D full-field ultrasonic data set was created using an ultrasonic wave propagation imaging (UWPI) process, after which several signal processing techniques were applied to generate the processed data. By using a deep convolutional neural network (DCNN) with a VGG-like architecture based regression model, the estimated error was calculated to compare the performance of a DCNN on different processed data set. The proposed approach was also compared with a K-nearest neighbor, support vector regression, and deep artificial neural network for regression to demonstrate its robustness. Consequently, it was found that the proposed approach shows potential for the incorporation of laser-generated ultrasound and DL algorithms. In addition, the signal processing technique has been shown to have an important impact on the DL performance for automatic looseness estimation.","acoustic emission,digital signal processing,laser applications,machine learning,structural shapes,waves",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"VISUALIZATION,TRANSFORM",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7571204,
69,Identification of Motor and Mental Imagery EEG in Two and Multiclass Subject-Dependent Tasks Using Successive Decomposition Index,20,18,,"Sadiq Muhammad Tariq,Yu Xiaojun,Yuan Zhaohui,Aziz Muhammad Zulkifal","Sadiq MT,Yu XJ,Yuan ZH,Aziz MZ",Yuan ZH,10.3390/s20185283,Northwestern Polytechnical University,"The development of fast and robust brain-computer interface (BCI) systems requires non-complex and efficient computational tools. The modern procedures adopted for this purpose are complex which limits their use in practical applications. In this study, for the first time, and to the best of our knowledge, a successive decomposition index (SDI)-based feature extraction approach is utilized for the classification of motor and mental imagery electroencephalography (EEG) tasks. First of all, the public datasets IVa, IVb, and V from BCI competition III were denoised using multiscale principal analysis (MSPCA), and then a SDI feature was calculated corresponding to each trial of the data. Finally, six benchmark machine learning and neural network classifiers were used to evaluate the performance of the proposed method. All the experiments were performed for motor and mental imagery datasets in binary and multiclass applications using a 10-fold cross-validation method. Furthermore, computerized automatic detection of motor and mental imagery using SDI (CADMMI-SDI) is developed to describe the proposed approach practically. The experimental results suggest that the highest classification accuracy of 97.46% (Dataset IVa), 99.52% (Dataset IVb), and 99.33% (Dataset V) was obtained using feedforward neural network classifier. Moreover, a series of experiments, namely, statistical analysis, channels variation, classifier parameters variation, processed and unprocessed data, and computational complexity, were performed and it was concluded that SDI is robust for noise, and a non-complex and efficient biomarker for the development of fast and accurate motor and mental imagery BCI systems.","electroencephalography,Brain-Computer Interface,multiscale principal component analysis,successive decomposition index,motor imagery,mental imagery,neurorehabilitation,classification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"BRAIN-COMPUTER,INTERFACE,SINGLE-TRIAL,EEG,CLASSIFICATION,ENSEMBLE,BCI,PATTERNS,SYSTEM",SENSORS,https://www.mdpi.com/1424-8220/20/18/5283/pdf,
70,The Prediction of Oceanic Mesoscale Eddy Properties and Propagation Trajectories Based on Machine Learning,12,9,,"Wang Xin,Wang Huizan,Liu Donghan,Wang Wenke","Wang X,Wang HZ,Liu DH,Wang WK",Wang WK,10.3390/w12092521,National University of Defense Technology - China,"Mesoscale eddies play an important role in ocean circulation, material energy exchange and variation of ocean environments. Machine learning methods can efficiently process massive amounts of data and automatically learn the implicit features, thus providing a new approach to eddy prediction research. Using the mesoscale eddy trajectory data derived from multimission satellite altimetry, we propose relevant machine learning models based on long short-term memory network (LSTM) and the extra trees (ET) algorithm for the prediction of eddy properties and propagation trajectories. Characteristic factors, including attribute features and past eddy displacements, were exploited to construct prediction models with high effectiveness and few predictors. To study their effects at different forecasting times, we separately trained the models by rebuilding the corresponding relationship between eddy samples and labels. In addition, the variation characteristics and the predictability of eddy properties and propagation trajectories were discussed from the prediction results. Cross-validation shows that at different prediction times, our method is superior to previous methods in terms of the mean absolute error (MAE) of eddy properties and the root mean square error (RMSE) of propagation. The stable variation in eddy properties makes the prediction more dependent on the historical time series than that of a propagation forecast. The short-term propagation prediction of eddies contained more noise than long-term predictions, and the long-term predictions revealed a more significant trend. Finally, we discuss the effect of eddy properties on the prediction ability of the eddy propagation trajectory.","mesoscale eddies,eddy properties,propagation trajectory,performance evaluation,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Water Resources",,3.229,"SOUTH,CHINA,SEA,EDDIES",WATER,https://www.mdpi.com/2073-4441/12/9/2521/pdf,
71,A Brain-Inspired Hyperdimensional Computing Approach for Classifying Massive DNA Methylation Data of Cancer,13,9,,"Cumbo Fabio,Cappelli Eleonora,Weitschek Emanuel","Cumbo F,Cappelli E,Weitschek E",Cumbo F,10.3390/a13090233,University of Trento,"The recent advancements in cancer genomics have put under the spotlight DNA methylation, a genetic modification that regulates the functioning of the genome and whose modifications have an important role in tumorigenesis and tumor-suppression. Because of the high dimensionality and the enormous amount of genomic data that are produced through the last advancements in Next Generation Sequencing, it is very challenging to effectively make use of DNA methylation data in diagnostics applications, e.g., in the identification of healthy vs diseased samples. Additionally, state-of-the-art techniques are not fast enough to rapidly produce reliable results or efficient in managing those massive amounts of data. For this reason, we propose HD-classifier, an in-memory cognitive-based hyperdimensional (HD) supervised machine learning algorithm for the classification of tumor vs non tumor samples through the analysis of their DNA Methylation data. The approach takes inspiration from how the human brain is able to remember and distinguish simple and complex concepts by adopting hypervectors and no single numerical values. Exactly as the brain works, this allows for encoding complex patterns, which makes the whole architecture robust to failures and mistakes also with noisy data. We design and develop an algorithm and a software tool that is able to perform supervised classification with the HD approach. We conduct experiments on three DNA methylation datasets of different types of cancer in order to prove the validity of our algorithm, i.e., Breast Invasive Carcinoma (BRCA), Kidney renal papillary cell carcinoma (KIRP), and Thyroid carcinoma (THCA). We obtain outstanding results in terms of accuracy and computational time with a low amount of computational resources. Furthermore, we validate our approach by comparing it (i) to BIGBIOCL, a software based on Random Forest for classifying big omics datasets in distributed computing environments, (ii) to Support Vector Machine (SVM), and (iii) to Decision Tree state-of-the-art classification methods. Finally, we freely release both the datasets and the software on GitHub.","algorithms in biology,bioinformatics,machine learning,classification,hyperdimensional computing,cancer,DNA methylation",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"CLASSIFICATION,IMPACT,CPG",ALGORITHMS,https://www.mdpi.com/1999-4893/13/9/233/pdf,
72,Prediction of Glioma Grades Using Deep Learning with Wavelet Radiomic Features,10,18,,"Cinarer Gokalp,Emiroglu Bulent Gursel,Yurttakal Ahmet Hasim","Cinarer G,Emiroglu BG,Yurttakal AH",Cinarer G,10.3390/app10186296,Bozok University,"Gliomas are the most common primary brain tumors. They are classified into 4 grades (Grade I-II-III-IV) according to the guidelines of the World Health Organization (WHO). The accurate grading of gliomas has clinical significance for planning prognostic treatments, pre-diagnosis, monitoring and administration of chemotherapy. The purpose of this study is to develop a deep learning-based classification method using radiomic features of brain tumor glioma grades with deep neural network (DNN). The classifier was combined with the discrete wavelet transform (DWT) the powerful feature extraction tool. This study primarily focuses on the four main aspects of the radiomic workflow, namely tumor segmentation, feature extraction, analysis, and classification. We evaluated data from 121 patients with brain tumors (Grade II,n= 77; Grade III,n= 44) from The Cancer Imaging Archive, and 744 radiomic features were obtained by applying low sub-band and high sub-band 3D wavelet transform filters to the 3D tumor images. Quantitative values were statistically analyzed with MannWhitney U tests and 126 radiomic features with significant statistical properties were selected in eight different wavelet filters. Classification performances of 3D wavelet transform filter groups were measured using accuracy, sensitivity, F1 score, and specificity values using the deep learning classifier model. The proposed model was highly effective in grading gliomas with 96.15% accuracy, 94.12% precision, 100% recall, 96.97% F1 score, and 98.75% Area under the ROC curve. As a result, deep learning and feature selection techniques with wavelet transform filters can be accurately applied using the proposed method in glioma grade classification.","deep learning,radiomics,wavelet,grading",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"LEVEL-SET,METHOD,BRAIN-TUMOR,MR-IMAGES,CLASSIFICATION,SEGMENTATION,SYSTEM,PET",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/18/6296/pdf,
73,Radiomics-Based Prediction of Overall Survival in Lung Cancer Using Different Volumes-Of-Interest,10,18,,"D'Amico Natascha Claudia,Sicilia Rosa,Cordelli Ermanno,Tronchin Lorenzo,Greco Carlo,Fiore Michele,Carnevale Alessia,Iannello Giulio,Ramella Sara,Soda Paolo","D'Amico NC,Sicilia R,Cordelli E,Tronchin L,Greco C,Fiore M,Carnevale A,Iannello G,Ramella S,Soda P",Sicilia R,10.3390/app10186425,University Campus Bio-Medico - Rome Italy,"Featured Application The manuscript aims to provide a signature to predict Overall Survival in patients with Locally Advanced Non-Small Cell Lung Cancer. The results could offer the physicians advanced software tools to early evaluate the disease evolution before the treatment start so to personalize each patient's therapy. Moreover, this work provides insight into the use of the different segmentation volumes usually applied in radiation oncology. Lung cancer accounts for the largest amount of deaths worldwide with respect to the other oncological pathologies. To guarantee the most effective cure to patients for such aggressive tumours, radiomics is increasing as a novel and promising research field that aims at extracting knowledge from data in terms of quantitative measures that are computed from diagnostic images, with prognostic and predictive ends. This knowledge could be used to optimize current treatments and to maximize their efficacy. To this end, we hereby study the use of such quantitative biomarkers computed from CT images of patients affected by Non-Small Cell Lung Cancer to predict Overall Survival. The main contributions of this work are two: first, we consider different volumes of interest for the same patient to find out whether the volume surrounding the visible lesions can provide useful information; second, we introduce 3D Local Binary Patterns, which are texture measures scarcely explored in radiomics. As further validation, we show that the proposed signature outperforms not only the features automatically computed by a deep learning-based approach, but also another signature at the state-of-the-art using other handcrafted features.","radiomics,NSCLC,Local Binary Patterns,multi-VOI analysis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"FEATURES,RADIOTHERAPY,TRIAL,CHEMORADIOTHERAPY,CLASSIFICATION,RECOGNITION,PATTERNS,OUTCOMES",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/18/6425/pdf,
74,"Process Parameter Optimization When Preparing Ti(C, N) Ceramic Coatings Using Laser Cladding Based on a Neural Network and Quantum-Behaved Particle Swarm Optimization Algorithm",10,18,,"Deng Zixin,Chen Tao,Wang Haojun,Li Shengchen,Liu Defu","Deng ZX,Chen T,Wang HJ,Li SC,Liu DF",Liu DF,10.3390/app10186331,Central South University,"The formation process of surface coatings fabricated with laser cladding is very complicated and coating quality is closely related to laser cladding process parameters. Generally, the optimization and control of process parameters play key roles when preparing high-quality ceramic coating. In this paper, three reasonable parameters were selected for each process parameter based on the preliminary experiment. The experiment of Ti(C, N) ceramic coating prepared with laser cladding was designed via the Taguchi method. The laser power, spot diameter, overlapping ratio, and scanning velocity were selected as the main process parameters, and their effects on coating micro-hardness were analyzed using the signal-to-noise (S/N) ratio and analysis of variance (ANOVA). Then, based on the back-propagation neural network (BPNN) and quantum-behaved particle swarm optimization (QPSO) algorithm, we created the prediction model of BPNN-QPSO neural network for laser cladding Ti(C, N) ceramic coating. The mapping of process parameters to the micro-hardness of the coating was obtained according to the model and we analyzed the influence of process parameters that interacted with the coating's micro-hardness. The results showed that the interaction of laser cladding process parameters had a significant effect on the micro-hardness of the coating. The established BPNN-QPSO neural network model was able to map the relationship between laser cladding process parameters and coating micro-hardness. The process parameters optimized by this model had similar results with ANOVA. This research provides guidance for the selection and control of ceramic coating process parameters Ti(C, N) prepared via laser cladding.","laser cladding,Taguchi method,back-propagation neural network,particle swarm optimization algorithm,prediction model,process optimization",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"MELT,POOL,GEOMETRY,NUMERICAL-SIMULATION,COMPOSITE,COATINGS,WEAR-RESISTANCE,PREDICTION,TAGUCHI,TEMPERATURE,DEPOSITION,TITANIUM,MODEL",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/18/6331/pdf,
75,Disentangled Autoencoder for Cross-Stain Feature Extraction in Pathology Image Analysis,10,18,,"Hecht Helge,Sarhan Mhd Hasan,Popovici Vlad","Hecht H,Sarhan MH,Popovici V",Popovici V,10.3390/app10186427,Masaryk University Brno,"Featured Application The method described can be applied for stain-independent pathology image registration and content summarization. A novel deep autoencoder architecture is proposed for the analysis of histopathology images. Its purpose is to produce a disentangled latent representation in which the structure and colour information are confined to different subspaces so that stain-independent models may be learned. For this, we introduce two constraints on the representation which are implemented as a classifier and an adversarial discriminator. We show how they can be used for learning a latent representation across haematoxylin-eosin and a number of immune stains. Finally, we demonstrate the utility of the proposed representation in the context of matching image patches for registration applications and for learning a bag of visual words for whole slide image summarization.","digital pathology,image registration,deep learning,disentangled autoencoder",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"SPARSE,AUTOENCODER,DIGITAL,PATHOLOGY",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/18/6427/pdf,
76,A Machine Learning Approach to Predicting Readmission or Mortality in Patients Hospitalized for Stroke or Transient Ischemic Attack,10,18,,"Hung Ling-Chien,Sung Sheng-Feng,Hu Ya-Han","Hung LC,Sung SF,Hu YH",Hu YH,10.3390/app10186337,National Central University,"Readmissions after stroke are not only associated with greater levels of disability and a higher risk of mortality but also increase overall medical costs. Predicting readmission risk and understanding its causes are thus essential for healthcare resource allocation and quality improvement planning. By using machine learning techniques on initial admission data, this study aimed to develop prediction models for readmission or mortality after stroke. During model development, resampling methods were implemented to balance the class distribution. Two-layer nested cross-validation was used to build and evaluate the prediction models. A total of 3422 patients were included for analysis. The 90-day rate of readmission or mortality was 17.6%. This study identified several important predictive factors, including age, prior emergency department visits, pre-stroke functional status, stroke severity, body mass index, consciousness level, and use of a nasogastric tube. The Naive Bayes model with class weighting to compensate for class imbalance achieved the highest discriminatory capacity in terms of the area under the receiver operating characteristic curve (0.661). Despite having room for improvement, the prediction models could be used for early risk assessment of patients with stroke. Identification of patients at high risk for readmission or mortality immediately after admission has the potential of enabling early discharge planning and transitional care interventions.","machine learning,prediction models,readmission,risk assessment,stroke",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"30-DAY,READMISSION,INPATIENT,REHABILITATION,MEDICAL,COMPLICATIONS,HIGH-RISK,CARE,REHOSPITALIZATION,DISCHARGE,TAIWAN",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/18/6337/pdf,
77,Retinal Image Analysis for Diabetes-Based Eye Disease Detection Using Deep Learning,10,18,,"Nazir Tahira,Irtaza Aun,Javed Ali,Malik Hafiz,Hussain Dildar,Naqvi Rizwan Ali","Nazir T,Irtaza A,Javed A,Malik H,Hussain D,Naqvi RA",Hussain D,10.3390/app10186185,"Korea Inst Adv Study KIAS, Sch Computat Sci, 85 Hoegiro Dongdaemun Gu, Seoul 02455, South Korea.","Diabetic patients are at the risk of developing different eye diseases i.e., diabetic retinopathy (DR), diabetic macular edema (DME) and glaucoma. DR is an eye disease that harms the retina and DME is developed by the accumulation of fluid in the macula, while glaucoma damages the optic disk and causes vision loss in advanced stages. However, due to slow progression, the disease shows few signs in early stages, hence making disease detection a difficult task. Therefore, a fully automated system is required to support the detection and screening process at early stages. In this paper, an automated disease localization and segmentation approach based on Fast Region-based Convolutional Neural Network (FRCNN) algorithm with fuzzy k-means (FKM) clustering is presented. The FRCNN is an object detection approach that requires the bounding-box annotations to work; however, datasets do not provide them, therefore, we have generated these annotations through ground-truths. Afterward, FRCNN is trained over the annotated images for localization that are then segmented-out through FKM clustering. The segmented regions are then compared against the ground-truths through intersection-over-union operations. For performance evaluation, we used the Diaretdb1, MESSIDOR, ORIGA, DR-HAGIS, and HRF datasets. A rigorous comparison against the latest methods confirms the efficacy of the approach in terms of both disease detection and segmentation.","glaucoma,deep learning,diabetic retinopathy,fuzzy K-means clustering,medical imaging",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"AUTOMATED,DETECTION,GLAUCOMA,RETINOPATHY,DIAGNOSIS,CLASSIFICATION,SEGMENTATION,CUP,RECOGNITION",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/18/6185/pdf,
78,Choice between Surgery and Conservative Treatment for Patients with Lumbar Spinal Stenosis: Predicting Results through Data Mining Technology,10,18,,"Tseng Li-Ping,Pei Yu-Cheng,Chen Yen-Sheng,Hou Tung-Hsu,Ou Yang-Kun","Tseng LP,Pei YC,Chen YS,Hou TH,Ou YK",Ou YK,10.3390/app10186406,Southern Taiwan University of Science & Technology,"Currently, patients with lumbar spinal stenosis (LSS) have two treatment options: nonoperative conservative treatment and surgical treatment. Because surgery is invasive, patients often prefer conservative treatment as their first choice to avoid risks from surgery. However, the effectiveness of nonoperative conservative treatment for patients with LSS may be lower than expected because of individual differences. Rules to determine whether patients with LSS should undergo surgical treatment merits exploration. In addition, without a decision-making system to assist patients undergoing conservative treatment to decide whether to undergo surgical treatment, medical professionals may encounter difficulty in providing the best treatment advice. This study collected medical record data and magnetic resonance imaging diagnostic data from patients with LSS, analyzed and consolidated the data through data mining techniques, identified crucial factors and rules affecting the final outcome the patients with LSS who opted for conservative treatment and ultimately underwent surgical treatment, and, finally, established an effective prediction model. This study applied logistic regression (LGR) and decision tree algorithms to extract the crucial features and combined them with back propagation neural networks (BPNN) and support vector machines (SVM) to establish the prediction model. The crucial features obtained are as follows: reduction of the intervertebral disc height, age, blood pressure difference, leg pain, gender, etc. Among the models predicting whether patients with LSS ultimately underwent surgical treatment, the model combining LGR and the decision tree for feature selection with a BPNN has a testing accuracy rate of 94.87%, sensitivity of 0.9, specificity of 1, and area under the receiver operating characteristic curve of 0.952. Adopting these data mining techniques to predict whether patients with LSS who opted for conservative treatment ultimately underwent surgical treatment may assist medical professionals in reaching a treatment decision and provide clearer treatment. This may effectively mitigate disease progression, aid the goals of precision medicine, and ultimately enhance the quality of health care.","lumbar spinal stenosis (LSS),data mining,back propagation neural network,decision tree,support vector machine,prediction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"LOW-BACK-PAIN,MANAGEMENT,SYSTEM",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/18/6406/pdf,
79,Deep-Pneumonia Framework Using Deep Learning Models Based on Chest X-Ray Images,10,9,,"Elshennawy Nada M.,Ibrahim Dina M.","Elshennawy NM,Ibrahim DM",Ibrahim DM,10.3390/diagnostics10090649,Egyptian Knowledge Bank (EKB),"Pneumonia is a contagious disease that causes ulcers of the lungs, and is one of the main reasons for death among children and the elderly in the world. Several deep learning models for detecting pneumonia from chest X-ray images have been proposed. One of the extreme challenges has been to find an appropriate and efficient model that meets all performance metrics. Proposing efficient and powerful deep learning models for detecting and classifying pneumonia is the main purpose of this work. In this paper, four different models are developed by changing the used deep learning method; two pre-trained models, ResNet152V2 and MobileNetV2, a Convolutional Neural Network (CNN), and a Long Short-Term Memory (LSTM). The proposed models are implemented and evaluated using Python and compared with recent similar research. The results demonstrate that our proposed deep learning framework improves accuracy, precision, F1-score, recall, and Area Under the Curve (AUC) by 99.22%, 99.43%, 99.44%, 99.44%, and 99.77%, respectively. As clearly illustrated from the results, the ResNet152V2 model outperforms other recently proposed works. Moreover, the other proposed models-MobileNetV2, CNN, and LSTM-CNN-achieved results with more than 91% in accuracy, recall, F1-score, precision, and AUC, and exceed the recently introduced models in the literature.","detecting pneumonia,deep learning,CNN,LSTM,chest X-ray image",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"NEURAL-NETWORKS,CLASSIFICATION",DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7554804,
80,"The Role of EEG in the Diagnosis, Prognosis and Clinical Correlations of Dementia with Lewy Bodies-A Systematic Review",10,9,,"Law Zhe Kang,Todd Carein,Mehraram Ramtin,Schumacher Julia,Baker Mark R.,LeBeau Fiona E. N.,Yarnall Alison,Onofrj Marco,Bonanni Laura,Thomas Alan","Law ZK,Todd C,Mehraram R,Schumacher J,Baker MR,LeBeau FEN,Yarnall A,Onofrj M,Bonanni L,Thomas A",Taylor JP,10.3390/diagnostics10090616,Newcastle University - UK,"Despite improvements in diagnostic criteria for dementia with Lewy bodies (DLB), the ability to discriminate DLB from Alzheimer's disease (AD) and other dementias remains suboptimal. Electroencephalography (EEG) is currently a supportive biomarker in the diagnosis of DLB. We performed a systematic review to better clarify the diagnostic and prognostic role of EEG in DLB and define the clinical correlates of various EEG features described in DLB. MEDLINE, EMBASE, and PsycINFO were searched using search strategies for relevant articles up to 6 August 2020. We included 43 studies comparing EEG in DLB with other diagnoses, 42 of them included a comparison of DLB with AD, 10 studies compared DLB with Parkinson's disease dementia, and 6 studies compared DLB with other dementias. The studies were visual EEG assessment (6), quantitative EEG (35) and event-related potential studies (2). The most consistent observation was the slowing of the dominant EEG rhythm (<8 Hz) assessed visually or through quantitative EEG, which was observed in similar to 90% of patients with DLB and only similar to 10% of patients with AD. Other findings based on qualitative rating, spectral power analyses, connectivity, microstate and machine learning algorithms were largely heterogenous due to differences in study design, EEG acquisition, preprocessing and analysis. EEG protocols should be standardized to allow replication and validation of promising EEG features as potential biomarkers in DLB.","dementia with lewy bodies,lewy body disease,parkinson's disease dementia,electroencephalography,electrophysiology,systematic review",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"PARKINSONS-DISEASE,DEMENTIA,MILD,COGNITIVE,IMPAIRMENT,ALZHEIMERS-DISEASE,FLUCTUATING,COGNITION,QUANTITATIVE,EEG,DIFFERENTIAL-DIAGNOSIS,VISUAL,HALLUCINATIONS,BODY,DISEASES,ALPHA-RHYTHMS,DLB",DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7555753,
81,Application of Artificial Intelligence in Early Diagnosis of Spontaneous Preterm Labor and Birth,10,9,,"Lee Kwang-Sig,Ahn Ki Hoon","Lee KS,Ahn KH",Ahn KH,10.3390/diagnostics10090733,Korea University,"This study reviews the current status and future prospective of knowledge on the use of artificial intelligence for the prediction of spontaneous preterm labor and birth (""preterm birth"" hereafter). The summary of review suggests that different machine learning approaches would be optimal for different types of data regarding the prediction of preterm birth: the artificial neural network, logistic regression and/or the random forest for numeric data; the support vector machine for electrohysterogram data; the recurrent neural network for text data; and the convolutional neural network for image data. The ranges of performance measures were 0.79-0.94 for accuracy, 0.22-0.97 for sensitivity, 0.86-1.00 for specificity, and 0.54-0.83 for the area under the receiver operating characteristic curve. The following maternal variables were reported to be major determinants of preterm birth: delivery and pregestational body mass index, age, parity, predelivery systolic and diastolic blood pressure, twins, below high school graduation, infant sex, prior preterm birth, progesterone medication history, upper gastrointestinal tract symptom, gastroesophageal reflux disease, Helicobacter pylori, urban region, calcium channel blocker medication history, gestational diabetes mellitus, prior cone biopsy, cervical length, myomas and adenomyosis, insurance, marriage, religion, systemic lupus erythematosus, hydroxychloroquine sulfate, and increased cerebrospinal fluid and reduced cortical folding due to impaired brain growth.","preterm birth,early diagnosis,artificial intelligence",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"GASTROESOPHAGEAL-REFLUX,DISEASE,DIABETES-MELLITUS,RISK,PERIODONTITIS,ASSOCIATION,PREDICTION,WOMEN",DIAGNOSTICS,https://www.mdpi.com/2075-4418/10/9/733/pdf,
82,Optimization of Deep Learning Network Parameters Using Uniform Experimental Design for Breast Cancer Histopathological Image Classification,10,9,,"Lin Cheng-Jian,Jeng Shiou-Yun","Lin CJ,Jeng SY",Lin CJ,10.3390/diagnostics10090662,National Chin-Yi University of Technology,"Breast cancer, a common cancer type, is a major health concern in women. Recently, researchers used convolutional neural networks (CNNs) for medical image analysis and demonstrated classification performance for breast cancer diagnosis from within histopathological image datasets. However, the parameter settings of a CNN model are complicated, and using Breast Cancer Histopathological Database data for the classification is time-consuming. To overcome these problems, this study used a uniform experimental design (UED) and optimized the CNN parameters of breast cancer histopathological image classification. In UED, regression analysis was used to optimize the parameters. The experimental results indicated that the proposed method with UED parameter optimization provided 84.41% classification accuracy rate. In conclusion, the proposed method can improve the classification accuracy effectively, with results superior to those of other similar methods.","breast cancer,histopathology,deep learning,convolutional neural network,uniform experimental design",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,,DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7555941,
83,Machine Learning Facilitates Hotspot Classification in PSMA-PET/CT with Nuclear Medicine Specialist Accuracy,10,9,,"Moazemi Sobhan,Khurshid Zain,Erle Annette,Luetje Susanne,Essler Markus,Schultz Thomas,Bundschuh Ralph A.","Moazemi S,Khurshid Z,Erle A,Lutje S,Essler M,Schultz T,Bundschuh RA",Moazemi S,10.3390/diagnostics10090622,University of Bonn,"Gallium-68 prostate-specific membrane antigen positron emission tomography(Ga-68-PSMA-PET) is a highly sensitive method to detect prostate cancer (PC) metastases. Visual discrimination between malignant and physiologic/unspecific tracer accumulation by a nuclear medicine (NM) specialist is essential for image interpretation. In the future, automated machine learning (ML)-based tools will assist physicians in image analysis. The aim of this work was to develop a tool for analysis of Ga-68-PSMA-PET images and to compare its efficacy to that of human readers. Five different ML methods were compared and tested on multiple positron emission tomography/computed tomography (PET/CT) data-sets. Forty textural features extracted from both PET- and low-dose CT data were analyzed. In total, 2419 hotspots from 72 patients were included. Comparing results from human readers to those of ML-based analyses, up to 98% area under the curve (AUC), 94% sensitivity (SE), and 89% specificity (SP) were achieved. Interestingly, textural features assessed in native low-dose CT increased the accuracy significantly. Thus, ML based on Ga-68-PSMA-PET/CT radiomics features can classify hotspots with high precision, comparable to that of experienced NM physicians. Additionally, the superiority of multimodal ML-based analysis considering all PET and low-dose CT features was shown. Morphological features seemed to be of special additional importance even though they were extracted from native low-dose CTs.","prostate cancer (PC),prostate-specific membrane antigen (PSMA),positron emission tomography (PET),computed tomography (CT)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"COMPUTER-AIDED,DIAGNOSIS,TUMOR,HETEROGENEITY,F-18-FDG,PET%2FCT,CANCER",DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7555620,
84,Color Doppler Ultrasound Improves Machine Learning Diagnosis of Breast Cancer,10,9,,"Moustafa Afaf F.,Cary Theodore W.,Sultan Laith R.,Schultz Susan M.,Conant Emily F.,Venkatesh Santosh S.,Sehgal Chandra M.","Moustafa AF,Cary TW,Sultan LR,Schultz SM,Conant EF,Venkatesh SS,Sehgal CM",Cary TW,10.3390/diagnostics10090631,University of Pennsylvania,"Color Doppler is used in the clinic for visually assessing the vascularity of breast masses on ultrasound, to aid in determining the likelihood of malignancy. In this study, quantitative color Doppler radiomics features were algorithmically extracted from breast sonograms for machine learning, producing a diagnostic model for breast cancer with higher performance than models based on grayscale and clinical category from the Breast Imaging Reporting and Data System for ultrasound (BI-RADS(US)). Ultrasound images of 159 solid masses were analyzed. Algorithms extracted nine grayscale features and two color Doppler features. These features, along with patient age and BI-RADS(US)category, were used to train an AdaBoost ensemble classifier. Though training on computer-extracted grayscale features and color Doppler features each significantly increased performance over that of models trained on clinical features, as measured by the area under the receiver operating characteristic (ROC) curve, training on both color Doppler and grayscale further increased the ROC area, from 0.925 +/- 0.022 to 0.958 +/- 0.013. Pruning low-confidence cases at 20% improved this to 0.986 +/- 0.007 with 100% sensitivity, whereas 64% of the cases had to be pruned to reach this performance without color Doppler. Fewer borderline diagnoses and higher ROC performance were both achieved for diagnostic models of breast cancer on ultrasound by machine learning on color Doppler features.","ultrasound,color Doppler,radiomics,breast cancer,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,,"MAMMOGRAPHY,RADIOMICS,BENIGN,TOMOSYNTHESIS,ELASTOGRAPHY,SENSITIVITY,PERFORMANCE,SONOGRAPHY,SYSTEM,MASSES",DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7555557,
85,Deep Learning Models for Automated Diagnosis of Retinopathy of Prematurity in Preterm Infants,9,9,,"Huang Yo-Ping,Vadloori Spandana,Chu Hung-Chi,Kang Eugene Yu-Chuan,Wu Wei-Chi,Kusaka Shunji,Fukushima Yoko","Huang YP,Vadloori S,Chu HC,Kang EYC,Wu WC,Kusaka S,Fukushima Y",Huang YP,10.3390/electronics9091444,National Taipei University of Technology,"Retinopathy of prematurity (ROP) is a disease that can cause blindness in premature infants. It is characterized by immature vascular growth of the retinal blood vessels. However, early detection and treatment of ROP can significantly improve the visual acuity of high-risk patients. Thus, early diagnosis of ROP is crucial in preventing visual impairment. However, several patients refrain from treatment owing to the lack of medical expertise in diagnosing the disease; this is especially problematic considering that the number of ROP cases is on the rise. To this end, we applied transfer learning to five deep neural network architectures for identifying ROP in preterm infants. Our results showed that the VGG19 model outperformed the other models in determining whether a preterm infant has ROP, with 96% accuracy, 96.6% sensitivity, and 95.2% specificity. We also classified the severity of the disease; the VGG19 model showed 98.82% accuracy in predicting the severity of the disease with a sensitivity and specificity of 100% and 98.41%, respectively. We performed 5-fold cross-validation on the datasets to validate the reliability of the VGG19 model and found that the VGG19 model exhibited high accuracy in predicting ROP. These findings could help promote the development of computer-aided diagnosis.","deep neural networks,transfer learning,retinopathy of prematurity,retinal fundus images",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"VISUAL,IMPAIRMENT,CLASSIFICATION,CARE",ELECTRONICS,https://www.mdpi.com/2079-9292/9/9/1444/pdf,
86,Automatic Diabetic Retinopathy Grading via Self-Knowledge Distillation,9,9,,"Luo Ling,Xue Dingyu,Feng Xinglong","Luo L,Xue DY,Feng XL",Luo L,10.3390/electronics9091337,Northeastern University - China,"Diabetic retinopathy (DR) is a common fundus disease that leads to irreversible blindness, which plagues the working-age population. Automatic medical imaging diagnosis provides a non-invasive method to assist ophthalmologists in timely screening of suspected DR cases, which prevents its further deterioration. However, the state-of-the-art deep-learning-based methods generally have a large amount of model parameters, which makes large-scale clinical deployment a time-consuming task. Moreover, the severity of DR is associated with lesions, and it is difficult for the model to focus on these regions. In this paper, we propose a novel deep-learning technique for grading DR with only image-level supervision. Specifically, we first customize the model with the help of self-knowledge distillation to achieve a trade-off between model performance and time complexity. Secondly, CAM-Attention is used to allow the network to focus on discriminative zone,e.g., microaneurysms, soft/hard exudates, etc.. Considering that directly attaching a classifier after the Side branch will disrupt the hierarchical nature of convolutional neural networks, a Mimicking Module is employed that allows the Side branch to actively mimic the main branch structure. Extensive experiments are conducted on two benchmark datasets, with an AUC of 0.965 and an accuracy of 92.9% for the Messidor dataset and 67.96% accuracy achieved for the challenging IDRID dataset, which demonstrates the superior performance of our proposed method.","image classification,convolutional neural network (CNN),diabetic retinopathy (DR),self-knowledge distillation (SKD),attention mechanism",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,SYSTEM,ELECTRONICS,https://www.mdpi.com/2079-9292/9/9/1337/pdf,
87,Multi-Channel Transfer Learning of Chest X-ray Images for Screening of COVID-19,9,9,,"Misra Sampa,Jeon Seungwan,Lee Seiyon,Managuli Ravi,Jang In-Su,Kim Chulhong","Misra S,Jeon S,Lee S,Managuli R,Jang IS,Kim C",Kim C,10.3390/electronics9091388,"Opticho, Pohang 37673, South Korea.","The 2019 novel coronavirus (COVID-19) has spread rapidly all over the world. The standard test for screening COVID-19 patients is the polymerase chain reaction test. As this method is time consuming, as an alternative, chest X-rays may be considered for quick screening. However, specialization is required to read COVID-19 chest X-ray images as they vary in features. To address this, we present a multi-channel pre-trained ResNet architecture to facilitate the diagnosis of COVID-19 chest X-ray. Three ResNet-based models were retrained to classify X-rays in a one-against-all basis from (a) normal or diseased, (b) pneumonia or non-pneumonia, and (c) COVID-19 or non-COVID19 individuals. Finally, these three models were ensembled and fine-tuned using X-rays from 1579 normal, 4245 pneumonia, and 184 COVID-19 individuals to classify normal, pneumonia, and COVID-19 cases in a one-against-one framework. Our results show that the ensemble model is more accurate than the single model as it extracts more relevant semantic features for each class. The method provides a precision of 94% and a recall of 100%. It could potentially help clinicians in screening patients for COVID-19, thus facilitating immediate triaging and treatment for better outcomes.","COVID-19,classification,deep learning,transfer learning,X-ray,ensemble learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"DEEP,CLASSIFICATION",ELECTRONICS,https://www.mdpi.com/2079-9292/9/9/1388/pdf,
88,Atrial Fibrillation Detection Directly from Compressed ECG with the Prior of Measurement Matrix,11,9,,"Cheng Yunfei,Hu Ying,Hou Mengshu,Pan Tongjie,He Wenwen,Ye Yalan","Cheng YF,Hu Y,Hou MS,Pan TJ,He WW,Ye YL",Ye YL,10.3390/info11090436,University of Electronic Science & Technology of China,"In the wearable health monitoring based on compressed sensing, atrial fibrillation detection directly from the compressed ECG can effectively reduce the time cost of data processing rather than classification after reconstruction. However, the existing methods for atrial fibrillation detection from compressed ECG did not fully benefit from the existing prior information, resulting in unsatisfactory classification performance, especially in some applications that require high compression ratio (CR). In this paper, we propose a deep learning method to detect atrial fibrillation directly from compressed ECG without reconstruction. Specifically, we design a deep network model for one-dimensional ECG signals, and the measurement matrix is used to initialize the first layer of the model so that the proposed model can obtain more prior information which benefits improving the classification performance of atrial fibrillation detection from compressed ECG. The experimental results on the MIT-BIH Atrial Fibrillation Database show that when the CR is 10%, the accuracy and F1 score of the proposed method reach 97.52% and 98.02%, respectively. Compared with the atrial fibrillation detection from original ECG, the corresponding accuracy and F1 score are only reduced by 0.88% and 0.69%. Even at a high CR of 90%, the accuracy and F1 score are still only reduced by 6.77% and 5.31%, respectively. All of the experimental results demonstrate that the proposed method is superior to other existing methods for atrial fibrillation detection from compressed ECG. Therefore, the proposed method is promising for atrial fibrillation detection in wearable health monitoring based on compressed sensing.","wearable health monitoring,electrocardiogram,atrial fibrillation,compressed sensing,measurement matrix,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"BLOCK-SPARSE,SIGNALS,RISK-FACTOR,RECOVERY,SENSOR",INFORMATION,https://www.mdpi.com/2078-2489/11/9/436/pdf,
89,Predicting Long-Term Deformation of Soundproofing Resilient Materials Subjected to Compressive Loading: Machine Learning Approach,13,18,,"Koo Seungbum,Choi Jongkwon,Kim Changhyuk","Koo S,Choi J,Kim C",Kim C,10.3390/ma13184133,Korea Institute of Civil Engineering & Building Technology (KICT),"Soundproofing materials are widely used within structural components of multi-dwelling residential buildings to alleviate neighborhood noise problems. One of the critical mechanical properties for the soundproofing materials to ensure its appropriate structural and soundproofing performance is the long-term compressive deformation under the service loading conditions. The test method in the current test specifications only evaluates resilient materials for a limited period (90-day). It then extrapolates the test results using a polynomial function to predict the long-term compressive deformation. However, the extrapolation is universally applied to materials without considering the level of loads; thus, the calculated deformation may not accurately represent the actual compressive deformation of the materials. In this regard, long-term compressive deformation tests were performed on the selected soundproofing resilient materials (i.e., polystyrene, polyethylene, and ethylene-vinyl acetate). Four levels of loads were chosen to apply compressive loads up to 350 to 500 days continuously, and the deformations of the test specimens were periodically monitored. Then, three machine learning algorithms were used to predict long-term compressive deformations. The predictions based on machine learning and ISO 20392 method are compared with experimental test results, and the accuracy of machine learning algorithms and ISO 20392 method are discussed.","long-term deformation,floor impact sound,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"NEURAL-NETWORK,REGRESSION,STRENGTH,BEHAVIOR,SYSTEM",MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7560409,
90,An Autoencoder Gated Recurrent Unit for Remaining Useful Life Prediction,8,9,,"Lu Yi-Wei,Hsu Chia-Yu,Huang Kuang-Chieh","Lu YW,Hsu CY,Huang KC",Hsu CY,10.3390/pr8091155,National Taipei University of Technology,"With the development of smart manufacturing, in order to detect abnormal conditions of the equipment, a large number of sensors have been used to record the variables associated with production equipment. This study focuses on the prediction of Remaining Useful Life (RUL). RUL prediction is part of predictive maintenance, which uses the development trend of the machine to predict when the machine will malfunction. High accuracy of RUL prediction not only reduces the consumption of manpower and materials, but also reduces the need for future maintenance. This study focuses on detecting faults as early as possible, before the machine needs to be replaced or repaired, to ensure the reliability of the system. It is difficult to extract meaningful features from sensor data directly. This study proposes a model based on an Autoencoder Gated Recurrent Unit (AE-GRU), in which the Autoencoder (AE) extracts the important features from the raw data and the Gated Recurrent Unit (GRU) selects the information from the sequences to forecast RUL. To evaluate the performance of the proposed AE-GRU model, an aircraft turbofan engine degradation simulation dataset provided by NASA was used and a comparison made of different recurrent neural networks. The results demonstrate that the AE-GRU is better than other recurrent neural networks, such as Long Short-Term Memory (LSTM) and GRU.","remaining useful life,predictive maintenance,deep learning,autoencoder,gated recurrent unit",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Engineering,,2.824,,PROCESSES,https://www.mdpi.com/2227-9717/8/9/1155/pdf,
91,Radiomics for Gleason Score Detection through Deep Learning,20,18,,"Brunese Luca,Mercaldo Francesco,Reginelli Alfonso,Santone Antonella","Brunese L,Mercaldo F,Reginelli A,Santone A",Mercaldo F,10.3390/s20185411,University of Molise,"Prostate cancer is classified into different stages, each stage is related to a different Gleason score. The labeling of a diagnosed prostate cancer is a task usually performed by radiologists. In this paper we propose a deep architecture, based on several convolutional layers, aimed to automatically assign the Gleason score to Magnetic Resonance Imaging (MRI) under analysis. We exploit a set of 71 radiomic features belonging to five categories: First Order, Shape, Gray Level Co-occurrence Matrix, Gray Level Run Length Matrix and Gray Level Size Zone Matrix. The radiomic features are gathered directly from segmented MRIs using two free-available dataset for research purpose obtained from different institutions. The results, obtained in terms of accuracy, are promising: they are ranging between 0.96 and 0.98 for Gleason score prediction.","prostate,cancer,radiomic,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"PROSTATE-CANCER,DIAGNOSIS,SYSTEM",SENSORS,https://www.mdpi.com/1424-8220/20/18/5411/pdf,
92,"A Real-Time Physical Progress Measurement Method for Schedule Performance Control Using Vision, an AR Marker and Machine Learning in a Ship Block Assembly Process",20,18,,"Choi Taihun,Seo Yoonho","Choi T,Seo Y",Seo Y,10.3390/s20185386,Korea University,"Progress control is a key technology for successfully carrying out a project by predicting possible problems, particularly production delays, and establishing measures to avoid them (decision-making). However, shipyard progress management is still dependent on the empirical judgment of the manager, and this has led to delays in delivery, which raises ship production costs. Therefore, this paper proposes a methodology for shipyard ship block assembly plants that enables objective process progress measurement based on real-time work performance data, rather than the empirical judgment of a site manager. In particular, an IoT-based physical progress measurement method that can automatically measure work performance without human intervention is presented for the mounting and welding activities of ship block assembly work. Both an augmented reality (AR) marker-based image analysis system and a welding machine time-series data-based machine learning model are presented for measuring the performances of the mounting and welding activities. In addition, the physical progress measurement method proposed in this study was applied to the ship block assembly plant of shipyard H to verify its validity.","performance measurement,process progress management,AR marker,machine learning,Internet of Things (IoT),smart shipyard,Industry 4,0",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"DIGITAL,TWIN,BIG,DATA,FUTURE,DESIGN,SYSTEM",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7571170,
93,Research Progress of Automated Visual Surface Defect Detection for Industrial Metal Planar Materials,20,18,,"Fang Xiaoxin,Luo Qiwu,Zhou Bingxing,Li Congcong,Tian Lu","Fang XX,Luo QW,Zhou BX,Li CC,Tian L",Luo QW,10.3390/s20185136,Central South University,"The computer-vision-based surface defect detection of metal planar materials is a research hotspot in the field of metallurgical industry. The high standard of planar surface quality in the metal manufacturing industry requires that the performance of an automated visual inspection system and its algorithms are constantly improved. This paper attempts to present a comprehensive survey on both two-dimensional and three-dimensional surface defect detection technologies based on reviewing over 160 publications for some typical metal planar material products of steel, aluminum, copper plates and strips. According to the algorithm properties as well as the image features, the existing two-dimensional methodologies are categorized into four groups: statistical, spectral, model, and machine learning-based methods. On the basis of three-dimensional data acquisition, the three-dimensional technologies are divided into stereoscopic vision, photometric stereo, laser scanner, and structured light measurement methods. These classical algorithms and emerging methods are introduced, analyzed, and compared in this review. Finally, the remaining challenges and future research trends of visual defect detection are discussed and forecasted at an abstract level.","automated visual inspection,image detection,surface defect detection,metal planar materials",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"LOCAL,BINARY,PATTERNS,GABOR,FILTER,COMBINATION,ROLLED,STEEL,STRIPS,INSPECTION,SYSTEM,STRUCTURED,LIGHT,CRACK,DETECTION,CLASSIFICATION,ALGORITHM,MODEL,IDENTIFICATION",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7570919,
94,Toward Mass Video Data Analysis: Interactive and Immersive 4D Scene Reconstruction,20,18,,"Kraus Matthias,Pollok Thomas,Miller Matthias,Kilian Timon,Moritz Tobias,Schweitzer Daniel,Beyerer Juergen,Keim Daniel,Qu Chengchao,Jentner Wolfgang","Kraus M,Pollok T,Miller M,Kilian T,Moritz T,Schweitzer D,Beyerer J,Keim D,Qu CC,Jentner W",Kraus M,10.3390/s20185426,University of Konstanz,"The technical progress in the last decades makes photo and video recording devices omnipresent. This change has a significant impact, among others, on police work. It is no longer unusual that a myriad of digital data accumulates after a criminal act, which must be reviewed by criminal investigators to collect evidence or solve the crime. This paper presents the VICTORIA Interactive 4D Scene Reconstruction and Analysis Framework (""ISRA-4D"" 1.0), an approach for the visual consolidation of heterogeneous video and image data in a 3D reconstruction of the corresponding environment. First, by reconstructing the environment in which the materials were created, a shared spatial context of all available materials is established. Second, all footage is spatially and temporally registered within this 3D reconstruction. Third, a visualization of the hereby created 4D reconstruction (3D scene + time) is provided, which can be analyzed interactively. Additional information on video and image content is also extracted and displayed and can be analyzed with supporting visualizations. The presented approach facilitates the process of filtering, annotating, analyzing, and getting an overview of large amounts of multimedia material. The framework is evaluated using four case studies which demonstrate its broad applicability. Furthermore, the framework allows the user to immerse themselves in the analysis by entering the scenario in virtual reality. This feature is qualitatively evaluated by means of interviews of criminal investigators and outlines potential benefits such as improved spatial understanding and the initiation of new fields of application.","4D reconstruction,visual exploration,computer vision,machine learning,forensics,virtual reality,surveillance systems",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,,"VISUAL,ANALYTICS,ENVIRONMENTS,PERFORMANCE,STEREO",SENSORS,https://kops.uni-konstanz.de/bitstream/123456789/53087/1/Kraus_2-hnftsta0l958.pdf,
95,Relaxed Rule-Based Learning for Automated Predictive Maintenance: Proof of Concept,13,9,,"Razgon Margarita,Mousavi Alireza","Razgon M,Mousavi A",Razgon M,10.3390/a13090219,Brunel University,"In this paper we propose a novel approach of rule learning called Relaxed Separate-and- Conquer (RSC): a modification of the standard Separate-and-Conquer (SeCo) methodology that does not require elimination of covered rows. This method can be seen as a generalization of the methods of SeCo and weighted covering that does not suffer from fragmentation. We present an empirical investigation of the proposed RSC approach in the area of Predictive Maintenance (PdM) of complex manufacturing machines, to predict forthcoming failures of these machines. In particular, we use for experiments a real industrial case study of a Continuous Compression Moulding (CCM) machine which manufactures the plastic bottle closure (caps) in the beverage industry. We compare the RSC approach with a Decision Tree (DT) based and SeCo algorithms and demonstrate that RSC significantly outperforms both DT based and SeCo rule learners. We conclude that the proposed RSC approach is promising for PdM guided by rule learning.","Predictive Maintenance,failure prediction,rule learning,Decision Tree,Machine Learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Computer Science,,,"FAULT-DIAGNOSIS,ALGORITHMS,ENSEMBLE",ALGORITHMS,https://zenodo.org/record/4741915/files/algorithms-13-00219-v3.pdf,
96,Voltage-gated ion channels mediate the electrotaxis of glioblastoma cells in a hybrid PMMA/PDMS microdevice,4,3,,"Tsai Hsieh-Fu,IJspeert Camilo,Shen Amy Q.","Tsai HF,IJspeert C,Shen AQ",Shen AQ,10.1063/5.0004893,Okinawa Institute of Science & Technology Graduate University,"Transformed astrocytes in the most aggressive form cause glioblastoma, the most common cancer in the central nervous system with high mortality. The physiological electric field by neuronal local field potentials and tissue polarity may guide the infiltration of glioblastoma cells through the electrotaxis process. However, microenvironments with multiplex gradients are difficult to create. In this work, we have developed a hybrid microfluidic platform to study glioblastoma electrotaxis in controlled microenvironments with high throughput quantitative analysis by machine learning-powered single cell tracking software. By equalizing the hydrostatic pressure difference between inlets and outlets of the microchannel, uniform single cells can be seeded reliably inside the microdevice. The electrotaxis of two glioblastoma models, T98G and U-251MG, requires an optimal laminin-containing extracellular matrix and exhibits opposite directional and electro-alignment tendencies. Calcium signaling is a key contributor in glioblastoma pathophysiology but its role in glioblastoma electrotaxis is still an open question. Anodal T98G electrotaxis and cathodal U-251MG electrotaxis require the presence of extracellular calcium cations. U-251MG electrotaxis is dependent on the P/Q-type voltage-gated calcium channel (VGCC) and T98G is dependent on the R-type VGCC. U-251MG electrotaxis and T98G electrotaxis are also mediated by A-type (rapidly inactivating) voltage-gated potassium channels and acid-sensing sodium channels. The involvement of multiple ion channels suggests that the glioblastoma electrotaxis is complex and patient-specific ion channel expression can be critical to develop personalized therapeutics to fight against cancer metastasis. The hybrid microfluidic design and machine learning-powered single cell analysis provide a simple and flexible platform for quantitative investigation of complicated biological systems.","CALCIUM-CHANNELS,ELECTRIC-FIELD,POTASSIUM CHANNELS,SODIUM-CHANNELS,K+ CHANNELS,IN-VITRO,GALVANOTAXIS,INHIBITION,BRAIN,MODULATION",Article,"AIP Publishing, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Engineering,,,"CALCIUM-CHANNELS,ELECTRIC-FIELD,POTASSIUM,CHANNELS,SODIUM-CHANNELS,K%2B,CHANNELS,IN-VITRO,GALVANOTAXIS,INHIBITION,BRAIN,MODULATION",APL BIOENGINEERING,https://www.biorxiv.org/content/biorxiv/early/2020/02/20/2020.02.14.948638.full.pdf,
97,Photonic tensor cores for machine learning,7,3,,"Miscuglio Mario,Sorger Volker J.","Miscuglio M,Sorger VJ",Miscuglio M,10.1063/5.0001942,George Washington University,"With an ongoing trend in computing hardware toward increased heterogeneity, domain-specific coprocessors are emerging as alternatives to centralized paradigms. The tensor core unit has been shown to outperform graphic processing units by almost 3 orders of magnitude, enabled by a stronger signal and greater energy efficiency. In this context, photons bear several synergistic physical properties while phase-change materials allow for local nonvolatile mnemonic functionality in these emerging distributed non-von Neumann architectures. While several photonic neural network designs have been explored, a photonic tensor core to perform tensor operations is yet to be implemented. In this manuscript, we introduce an integrated photonics-based tensor core unit by strategically utilizing (i) photonic parallelism via wavelength division multiplexing, (ii) high 2 peta-operations-per-second throughputs enabled by tens of picosecond-short delays from optoelectronics and compact photonic integrated circuitry, and (iii) near-zero static power-consuming novel photonic multi-state memories based on phase-change materials featuring vanishing losses in the amorphous state. Combining these physical synergies of material, function, and system, we show, supported by numerical simulations, that the performance of this 4-bit photonic tensor core unit can be 1 order of magnitude higher for electrical data. The full potential of this photonic tensor processor is delivered for optical data being processed, where we find a 2-3 orders higher performance (operations per joule), as compared to an electrical tensor core unit, while featuring similar chip areas. This work shows that photonic specialized processors have the potential to augment electronic systems and may perform exceptionally well in network-edge devices in the looming 5G networks and beyond.","MATRIX MULTIPLICATION,PHOTODETECTOR",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,19.201,"MATRIX,MULTIPLICATION,PHOTODETECTOR",APPLIED PHYSICS REVIEWS,http://arxiv.org/pdf/2002.03780,
98,MS-Net: Multi-Site Network for Improving Prostate Segmentation With Heterogeneous MRI Data,39,9,2713-2724,"Liu Quande,Dou Qi,Yu Lequan,Heng Pheng Ann","Liu QD,Dou Q,Yu LQ,Heng PA",Dou Q,10.1109/TMI.2020.2974574,Chinese University of Hong Kong,"Automated prostate segmentation in MRI is highly demanded for computer-assisted diagnosis. Recently, a variety of deep learning methods have achieved remarkable progress in this task, usually relying on large amounts of training data. Due to the nature of scarcity for medical images, it is important to effectively aggregate data from multiple sites for robust model training, to alleviate the insufficiency of single-site samples. However, the prostate MRIs from different sites present heterogeneity due to the differences in scanners and imaging protocols, raising challenges for effective ways of aggregating multi-site data for network training. In this paper, we propose a novel multi-site network (MS-Net) for improving prostate segmentation by learning robust representations, leveraging multiple sources of data. To compensate for the inter-site heterogeneity of different MRI datasets, we develop Domain-Specific Batch Normalization layers in the network backbone, enabling the network to estimate statistics and perform feature normalization for each site separately. Considering the difficulty of capturing the shared knowledge from multiple datasets, a novel learning paradigm, i.e., Multi-site-guided Knowledge Transfer, is proposed to enhance the kernels to extract more generic representations from multi-site data. Extensive experiments on three heterogeneous prostate MRI datasets demonstrate that our MS-Net improves the performance across all datasets consistently, and outperforms state-of-the-art methods for multi-site learning.","Magnetic resonance imaging,Image segmentation,Training,Robustness,Data models,Biomedical imaging,Task analysis,Prostatesegmentation,ulti-site learning,feature normalization,knowledge transfer",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,IMAGES,IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2002.03366,
99,Multi-View Spatial Aggregation Framework for Joint Localization and Segmentation of Organs at Risk in Head and Neck CT Images,39,9,2794-2805,"Liang Shujun,Kim-Han Thung,Nie Dong,Zhang Yu,Shen Dinggang","Liang SJ,Thung KH,Nie D,Zhang Y,Shen DG",Zhang Y,10.1109/TMI.2020.2975853,Southern Medical University - China,"Accurate segmentation of organs at risk (OARs) from head and neck (H&N) CT images is crucial for effective H&N cancer radiotherapy. However, the existing deep learning methods are often not trained in an end-to-end fashion, i.e., they independently predetermine the regions of target organs before organ segmentation, causing limited information sharing between related tasks and thus leading to suboptimal segmentation results. Furthermore, when conventional segmentation network is used to segment all the OARs simultaneously, the results often favor big OARs over small OARs. Thus, the existing methods often train a specific model for each OAR, ignoring the correlation between different segmentation tasks. To address these issues, we propose a new multi-view spatial aggregation framework for joint localization and segmentation of multiple OARs using H&N CT images. The core of our framework is a proposed region-of-interest (ROI)-based fine-grained representation convolutional neural network (CNN), which is used to generate multi-OAR probability maps from each 2D view (i.e., axial, coronal, and sagittal view) of CT images. Specifically, our ROI-based fine-grained representation CNN (1) unifies the OARs localization and segmentation tasks and trains them in an end-to-end fashion, and (2) improves the segmentation results of various-sized OARs via a novel ROI-based fine-grained representation. Our multi-view spatial aggregation framework then spatially aggregates and assembles the generated multi-view multi-OAR probability maps to segment all the OARs simultaneously. We evaluate our framework using two sets of H&N CT images and achieve competitive and highly robust segmentation performance for OARs of various sizes.","Image segmentation,Computed tomography,Cancer,Two dimensional displays,Optical imaging,Task analysis,Biomedical optical imaging,Image segmentation,detection,deep learning,convolutional neural network,head and neck cancer",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,AUTO-SEGMENTATION,IEEE TRANSACTIONS ON MEDICAL IMAGING,,
100,A k-Space Model of Movement Artefacts: Application to Segmentation Augmentation and Artefact Removal,39,9,2881-2892,"Shaw Richard,Sudre Carole H.,Varsavsky Thomas,Ourselin Sebastien,Cardoso M. Jorge","Shaw R,Sudre CH,Varsavsky T,Ourselin S,Cardoso MJ",Shaw R,10.1109/TMI.2020.2972547,University of London,"Patient movement during the acquisition of magnetic resonance images (MRI) can cause unwanted image artefacts. These artefacts may affect the quality of clinical diagnosis and cause errors in automated image analysis. In this work, we present a method for generating realistic motion artefacts from artefact-free magnitude MRI data to be used in deep learning frameworks, increasing training appearance variability and ultimately making machine learning algorithms such as convolutional neural networks (CNNs) more robust to the presence of motion artefacts. By modelling patient movement as a sequence of randomly-generated, 'demeaned', rigid 3D affine transforms, we resample artefact-free volumes and combine these in k-space to generate motion artefact data. We show that by augmenting the training of semantic segmentation CNNs with artefacts, we can train models that generalise better and perform more reliably in the presence of artefact data, with negligible cost to their performance on clean data. We show that the performance of models trained using artefact data on segmentation tasks on real-world test-retest image pairs is more robust. We also demonstrate that our augmentation model can be used to learn to retrospectively remove certain types of motion artefacts from real MRI scans. Finally, we show that measures of uncertainty obtained from motion augmented CNN models reflect the presence of artefacts and can thus provide relevant information to ensure the safe usage of deep learning extracted biomarkers in a clinical pipeline.","Three-dimensional displays,Transforms,Machine learning,Solid modeling,Image segmentation,Magnetic resonance imaging,Data models,MRI,motion artefacts,deep learning,segmentation,data augmentation,artefact correction,uncertainty",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"MOTION,CORRECTION,MRI",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://discovery.ucl.ac.uk/10091710/1/FINAL%20VERSION.pdf,
