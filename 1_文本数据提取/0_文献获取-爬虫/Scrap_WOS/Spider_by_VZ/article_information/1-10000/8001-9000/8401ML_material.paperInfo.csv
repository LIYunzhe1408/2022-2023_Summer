,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Machine learning formation enthalpies of intermetallics,128,10,,"Zhang Zhaohan,Li Mu,Flores Katharine,Mishra Rohan","Zhang ZH,Li M,Flores K,Mishra R",Mishra R,10.1063/5.0012323,Washington University (WUSTL),"Developing fast and accurate methods to discover intermetallic compounds is relevant for alloy design. While density-functional-theory (DFT)-based methods have accelerated design of binary and ternary alloys by providing rapid access to the energy and properties of the stable intermetallics, they are not amenable for rapidly screening the vast combinatorial space of multi-principal element alloys (MPEAs). Here, a machine-learning model is presented for predicting the formation enthalpy of binary intermetallics and is used to identify new ones. The model uses easily accessible elemental properties as descriptors and has a mean absolute error of 0.025eV/atom in predicting the formation enthalpy of stable binary intermetallics reported in the Materials Project database. The model further predicts stable intermetallics to form in 112 binary alloy systems that do not have any stable intermetallics reported in the Materials Project database. DFT calculations confirm one such stable intermetallic identified by the model, NbV2, to be on the convex hull. Furthermore, an adaptive transfer learning method is used to generalize the model to predict ternary intermetallics with a similar accuracy as DFT, which suggests that it could be extended to identify compositionally complex intermetallics that may form in MPEAs.","HIGH ENTROPY ALLOYS,ACCELERATED SEARCH",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,"HIGH,ENTROPY,ALLOYS,ACCELERATED,SEARCH",JOURNAL OF APPLIED PHYSICS,http://arxiv.org/pdf/2005.13046,
2,Using Machine Learning to Generate Novel Hypotheses: Increasing Optimism About COVID-19 Makes People Less Willing to Justify Unethical Behaviors,31,10,1222-1235,"Sheetal Abhishek,Feng Zhiyu,Savani Krishna","Sheetal A,Feng ZY,Savani K",Sheetal A,10.1177/0956797620959594,Nanyang Technological University & National Institute of Education (NIE) Singapore,"How can we nudge people to not engage in unethical behaviors, such as hoarding and violating social-distancing guidelines, during the COVID-19 pandemic? Because past research on antecedents of unethical behavior has not provided a clear answer, we turned to machine learning to generate novel hypotheses. We trained a deep-learning model to predict whether or not World Values Survey respondents perceived unethical behaviors as justifiable, on the basis of their responses to 708 other items. The model identified optimism about the future of humanity as one of the top predictors of unethicality. A preregistered correlational study (N= 218 U.S. residents) conceptually replicated this finding. A preregistered experiment (N= 294 U.S. residents) provided causal support: Participants who read a scenario conveying optimism about the COVID-19 pandemic were less willing to justify hoarding and violating social-distancing guidelines than participants who read a scenario conveying pessimism. The findings suggest that optimism can help reduce unethicality, and they document the utility of machine-learning methods for generating novel hypotheses.","COVID-19,machine learning,optimism,neural network,unethical behavior,open data,open materials,preregistered",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA",Psychology,,8.902,"MOOD,HEALTH",PSYCHOLOGICAL SCIENCE,https://journals.sagepub.com/doi/pdf/10.1177/0956797620959594,
3,Review of medical image recognition technologies to detect melanomas using neural networks,21,,,"Efimenko Mila,Ignatev Alexander,Koshechkin Konstantin","Efimenko M,Ignatev A,Koshechkin K",Koshechkin K,10.1186/s12859-020-03615-1,Sechenov First Moscow State Medical University,"BackgroundMelanoma is one of the most aggressive types of cancer that has become a world-class problem. According to the World Health Organization estimates, 132,000 cases of the disease and 66,000 deaths from malignant melanoma and other forms of skin cancer are reported annually worldwide (https://apps.who.int/gho/data/?theme=main) and those numbers continue to grow. In our opinion, due to the increasing incidence of the disease, it is necessary to find new, easy to use and sensitive methods for the early diagnosis of melanoma in a large number of people around the world. Over the last decade, neural networks show highly sensitive, specific, and accurate results.ObjectiveThis study presents a review of PubMed papers including requests << melanoma neural network >> and << melanoma neural network dermatoscopy >>. We review recent researches and discuss their opportunities acceptable in clinical practice.MethodsWe searched the PubMed database for systematic reviews and original research papers on the requests << melanoma neural network >> and << melanoma neural network dermatoscopy >> published in English. Only papers that reported results, progress and outcomes are included in this review.ResultsWe found 11 papers that match our requests that observed convolutional and deep-learning neural networks combined with fuzzy clustering or World Cup Optimization algorithms in analyzing dermatoscopic images. All of them require an ABCD (asymmetry, border, color, and differential structures) algorithm and its derivates (in combination with ABCD algorithm or separately). Also, they require a large dataset of dermatoscopic images and optimized estimation parameters to provide high specificity, accuracy and sensitivity.ConclusionsAccording to the analyzed papers, neural networks show higher specificity, accuracy and sensitivity than dermatologists. Neural networks are able to evaluate features that might be unavailable to the naked human eye. Despite that, we need more datasets to confirm those statements. Nowadays machine learning becomes a helpful tool in early diagnosing skin diseases, especially melanoma.","Melanoma classification,Skin cancer,Deep learning neural network,Convolutional neural network,Fuzzy clustering algorithm",Article; Proceedings Paper,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,"MALIGNANT-MELANOMA,CLASSIFICATION,RISK,DERMATOLOGISTS",BMC BIOINFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7488698,
4,Quantum machine learning using atom-in-molecule-based fragments selected on the fly,12,10,945-+,"Huang Bing);,von Lilienfeld O. Anatole","Huang B,von Lilienfeld OA",von Lilienfeld OA,10.1038/s41557-020-0527-z,University of Basel,"First-principles-based exploration of chemical space deepens our understanding of chemistry and might help with the design of new molecules, materials or experiments. Due to the computational cost of quantum chemistry methods and the immense number of theoretically possible stable compounds, comprehensive in silico screening remains prohibitive. To overcome this challenge, we combine atom-in-molecule-based fragments, dubbed 'amons' (A), with active learning in transferable quantum machine learning (ML) models. The efficiency, accuracy, scalability and transferability of the resulting AML models is demonstrated for important molecular quantum properties such as energies, forces, atomic charges, NMR shifts and polarizabilities and for systems including organic molecules, 2D materials, water clusters, Watson-Crick DNA base pairs and even ubiquitin. Conceptually, the AML approach extends Mendeleev's table to account effectively for chemical environments, which allows the systematic reconstruction of many chemistries from local building blocks.Image credit: ESA/Hubble & NASA, Acknowledgement: Judy Schmidt.","ELECTRONIC-STRUCTURE,NEARSIGHTEDNESS",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Chemistry,,26.958,"ELECTRONIC-STRUCTURE,NEARSIGHTEDNESS",NATURE CHEMISTRY,http://arxiv.org/pdf/1707.04146,
5,Model Selection and Evaluation for Machine Learning: Deep Learning in Materials Processing,9,3,287-300,"Kopper Adam,Karkare Rasika,Paffenroth Randy C.,Apelian Diran","Kopper A,Karkare R,Paffenroth RC,Apelian D",Kopper A,10.1007/s40192-020-00185-1,"Mercury Marine, Fond Du Lac, WI 54935 USA.","Materials processing is a critical subset of manufacturing which is benefitting by implementing machine learning to create knowledge from the data mined/collected and gain a deeper understanding of manufacturing processes. In this study, we focus on aluminum high-pressure die-casting (HPDC) process, which constitutes over 60% of all cast Al components. Routinely collected process data over a year's time of serial production are used to make predictions on mechanical properties of castings, specifically, the ultimate tensile strength (UTS). Random Forest, Support Vector Machine (SVM), and XGBoost regression algorithms were selected from the machine learning spectrum along with a Neural Network, a deep learning method. These methods were evaluated and assessed and were compared to predictions based on historical data. Machine learning, including Neural Network, regression models do improve the predictability of UTS above that of predicting the mean from prior tests. Choosing the correct models to use for the data requires an understanding of the bias-variance trade-off such that a balance is struck between the complexity of the algorithms chosen and the size of the dataset in question. These concepts are reviewed and discussed in context of HPDC.","Machine learning,Deep learning,Random forest,Support vector machine,Neural network,High pressure die casting,Principal component analysis,Bias-variance trade-off",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Materials Science",,4.423,SI,INTEGRATING MATERIALS AND MANUFACTURING INNOVATION,,
6,Optimal weighted hybrid pattern for content based medical image retrieval using modified spider monkey optimization,31,2,828-853,"Darapureddy Nagadevi,Karatapu Nagaprakash,Battula Tirumula Krishna","Darapureddy N,Karatapu N,Battula TK",Darapureddy N,10.1002/ima.22475,Jawaharlal Nehru Technological University - Kakinada,"The current approaches for image retrieval are more concentrating on numerous image features. Texture, shape, spatial information, and color are the fundamental features to deal with flexible image datasets. This paper aims to develop new Content-Based Image Retrieval System based on Optimal Weighted Hybrid Pattern. Two relevant patters like Local Vector Pattern and Local Derivative Pattern are intended to develop a novel Content-Based Image Retrieval system. The optimal weighted hybrid pattern is implemented to derive a new feature vector, so that the weight is optimized by a modified optimization algorithm called Improved Local Leader-based Spider Monkey Optimization to maximize the precision and recall of the retrieved images. The retrieval of the image is done by measuring the similarity based on Mean Square Distance between the features of query image as well as training image. Finally, the performance comparison of the proposed and the traditional patterns shows its reliable performance.","content-based medical image retrieval,improved local leader-based spider monkey optimization,local derivative pattern,local vector pattern,novel descriptors,optimal weighted hybrid pattern",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,"ORDER,DERIVATIVE,SPACE,LOCAL,VECTOR,PATTERN,CLASSIFICATION,DESCRIPTOR,SYSTEMS",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
7,Automated demarcation of requirements in textual specifications: a machine learning-based approach,25,6,5454-5497,"Abualhaija Sallam,Arora Chetan,Sabetzadeh Mehrdad,Briand Lionel C.,Traynor Michael","Abualhaija S,Arora C,Sabetzadeh M,Briand LC,Traynor M",Abualhaija S,10.1007/s10664-020-09864-1,University of Luxembourg,"A simple but important task during the analysis of a textual requirements specification is to determine which statements in the specification represent requirements. In principle, by following suitable writing and markup conventions, one can provide an immediate and unequivocal demarcation of requirements at the time a specification is being developed. However, neither the presence nor a fully accurate enforcement of such conventions is guaranteed. The result is that, in many practical situations, analysts end up resorting to after-the-fact reviews for sifting requirements from other material in a requirements specification. This is both tedious and time-consuming. We propose an automated approach for demarcating requirements in free-form requirements specifications. The approach, which is based on machine learning, can be applied to a wide variety of specifications in different domains and with different writing styles. We train and evaluate our approach over an independently labeled dataset comprised of 33 industrial requirements specifications. Over this dataset, our approach yields an average precision of 81.2% and an average recall of 95.7%. Compared to simple baselines that demarcate requirements based on the presence of modal verbs and identifiers, our approach leads to an average gain of 16.4% in precision and 25.5% in recall. We collect and analyze expert feedback on the demarcations produced by our approach for industrial requirements specifications. The results indicate that experts find our approach useful and efficient in practice. We developed a prototype tool, named DemaRQ, in support of our approach. To facilitate replication, we make available to the research community this prototype tool alongside the non-proprietary portion of our training data.","Textual requirements,Requirements identification and classification,Machine learning,Natural language processing",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,,CLASSIFICATION,EMPIRICAL SOFTWARE ENGINEERING,https://link.springer.com/content/pdf/10.1007/s10664-020-09864-1.pdf,
8,Evaluation of the Health Impacts of the 1990 Clean Air Act Amendments Using Causal Inference and Machine Learning,,,,"Nethery Rachel C.,Mealli Fabrizia,Sacks Jason D.,Dominici Francesca","Nethery RC,Mealli F,Sacks JD,Dominici F",Nethery RC,10.1080/01621459.2020.1803883,Harvard University,"We develop a causal inference approach to estimate the number of adverse health events that were prevented due to changes in exposure to multiple pollutants attributable to a large-scale air quality intervention/regulation, with a focus on the 1990 Clean Air Act Amendments (CAAA). We introduce a causal estimand called the total events avoided (TEA) by the regulation, defined as the difference in the number of health events expected under the no-regulation pollution exposures and the number observed with-regulation. We propose matching and machine learning methods that leverage population-level pollution and health data to estimate the TEA. Our approach improves upon traditional methods for regulation health impact analyses by formalizing causal identifying assumptions, using population-level data, minimizing parametric assumptions, and collectively analyzing multiple pollutants. To reduce model-dependence, our approach estimates cumulative health impacts in the subset of regions with projected no-regulation features lying within the support of the observed with-regulation data, thereby providing a conservative but data-driven assessment to complement traditional parametric approaches. We analyze the health impacts of the CAAA in the U.S. Medicare population in the year 2000, and our estimates suggest that large numbers of cardiovascular and dementia-related hospitalizations were avoided due to CAAA-attributable changes in pollution exposure.for this article, including a standardized description of the materials available for reproducing the work, are available as an online supplement.","1990 Clean Air Act Amendments,Bayesian additive regression trees,Counterfactual pollution exposures,Matching",Article; Early Access,"AMER STATISTICAL ASSOC, 732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA",Mathematics,,6.086,"PROPENSITY,SCORE,POLLUTION,MORTALITY,EXPOSURE,MODEL",JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION,https://flore.unifi.it/bitstream/2158/1219983/1/manuscript_v2_JASA.pdf,
9,Evaluation of train and test performance of machine learning algorithms and Parkinson diagnosis with statistical measurements,58,11,2775-2788,"Avuclu Emre,Elen Abdullah","Avuclu E,Elen A",Avuclu E,10.1007/s11517-020-02260-3,Aksaray University,"Parkinson's disease is a neurological disorder that causes partial or complete loss of motor reflexes and speech and affects thinking, behavior, and other vital functions affecting the nervous system. Parkinson's disease causes impaired speech and motor abilities (writing, balance, etc.) in about 90% of patients and is often seen in older people. Some signs (deterioration of vocal cords) in medical voice recordings from Parkinson's patients are used to diagnose this disease. The database used in this study contains biomedical speech voice from 31 people of different age and sex related to this disease. The performance comparison of the machine learning algorithms k-Nearest Neighborhood (k-NN), Random Forest, Naive Bayes, and Support Vector Machine classifiers was performed with the used database. Moreover, the best classifier was determined for the diagnosis of Parkinson's disease. Eleven different training and test data (45 x 55, 50 x 50, 55 x 45, 60 x 40, 65 x 35, 70 x 30, 75 x 25, 80 x 20, 85 x 15, 90 x 10, 95 x 5) were processed separately. The data obtained from these training and tests were compared with statistical measurements. The training results of the k-NN classification algorithm were generally 100% successful. The best test result was obtained from Random Forest classifier with 85.81%. All statistical results and measured values are given in detail in the experimental studies section.","Medical voice recordings,Machine learning,Parkinson's disease,Performance comparison",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"DISEASE,SPEECH,VARIABILITY,PREVALENCE,FREQUENCY",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
10,COVID-19 detection and disease progression visualization: Deep learning on chest X-rays for classification and coarse localization,51,2,1010-1021,"Zebin Tahmina,Rezvy Shahadate","Zebin T,Rezvy S",Zebin T,10.1007/s10489-020-01867-1,University of East Anglia,"Chest X-rays are playing an important role in the testing and diagnosis of COVID-19 disease in the recent pandemic. However, due to the limited amount of labelled medical images, automated classification of these images for positive and negative cases remains the biggest challenge in their reliable use in diagnosis and disease progression. We implemented a transfer learning pipeline for classifying COVID-19 chest X-ray images from two publicly available chest X-ray datasets(1,2). The classifier effectively distinguishes inflammation in lungs due to COVID-19 and Pneumonia from the ones with no infection (normal). We have used multiple pre-trained convolutional backbones as the feature extractor and achieved an overall detection accuracy of 90%, 94.3%, and 96.8% for the VGG16, ResNet50, and EfficientNetB0 backbones respectively. Additionally, we trained a generative adversarial framework (a CycleGAN) to generate and augment the minority COVID-19 class in our approach. For visual explanations and interpretation purposes, we implemented a gradient class activation mapping technique to highlight the regions of the input image that are important for predictions. Additionally, these visualizations can be used to monitor the affected lung regions during disease progression and severity stages.","Activation maps,COVID-19,Deep neural networks,Transfer learning",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,4.602,,APPLIED INTELLIGENCE,https://ueaeprints.uea.ac.uk/id/eprint/76972/1/Zebin_Rezvy2020_Article_COVID_19DetectionAndDiseasePro.pdf,
11,Improved time-dependent seismic fragility estimates for deteriorating RC bridge substructures exposed to chloride attack,24,3,437-452,"Cui Fengkun,Li Huihui,Dong Xu,Wang Baoqun,Li Jin,Xue Hongyun,Qi Meili","Cui FK,Li HH,Dong X,Wang BQ,Li J,Xue HY,Qi ML",Qi ML,10.1177/1369433220956812,Shandong Jiaotong University,"RC bridge substructures exposed to chloride environments inevitably suffer from corrosion of reinforcement embodied in concrete. This deterioration issue leads to the loss of reinforcement areas and a reduction in seismic capacity of reinforced concrete (RC) bridge substructures. To quantify the effect of steel corrosion on seismic fragility estimates, this paper proposes an improved time-dependent seismic fragility framework by taking into account the increase in the corrosion rate after concrete cracking and the reduction in seismic capacity of RC bridge substructures during the service life. Additionally, an analytical method based on a back propagation artificial neural network (BP-ANN) is proposed to provide probabilistic capacity estimates of deteriorating RC substructures. A three-span T-shaped girder bridge is selected as a case study bridge to provide improved time-dependent seismic fragility estimates that consider uncertainties in the material properties, geometric parameters, deterioration process and ground motions. The obtained fragility curves show that there is a nonlinear increase in the exceedance probability of deteriorating RC bridge substructures for different damage states during the service life. In addition, time-dependent seismic fragility analysis shows that the cases of considering only the effect of an increase in seismic demand or the reduction in seismic capacity as well as neither of them may lead to a significant underestimation of the seismic vulnerability of deteriorating RC bridge substructures.","bridge substructures,seismic fragility,chloride-induced deterioration,after-cracking corrosion rate,time-dependent capacity,probability",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA","Construction & Building Technology,Engineering",,1.925,"RESPONSE-SURFACE,METHOD,STRUCTURAL,RELIABILITY,INDUCED,CORROSION,HIGHWAY,BRIDGES,CONCRETE,DEGRADATION,CAPACITY,PIERS",ADVANCES IN STRUCTURAL ENGINEERING,,
12,The benefits evaluation of abdominal deep inspiration breath hold based on knowledge-based radiotherapy treatment planning for left-sided breast cancer,21,10,89-96,"Xu Jiaqi,Wang Jiazhou,Zhao Feng,Hu Weigang,Yao Guorong,Lu Zhongjie,Yan Senxiang","Xu JQ,Wang JZ,Zhao F,Hu WG,Yao GR,Lu ZJ,Yan SX",Lu ZJ; Yan SX,10.1002/acm2.13013,Zhejiang University,"Purpose To study the impact of abdominal deep inspiration breath hold (DIBH) technique on knowledge-based radiotherapy treatment planning for left-sided breast cancer to guide the application of DIBH technology. Materials and methods Two kernel density estimation (KDE) models were developed based on 40 left-sided breast cancer patients with two CT acquisitions of free breathing (FB-CT) and DIBH (DIBH-CT). Each KDE model was used to predict dose volume histograms (DVHs) based on DIBH-CT and FB-CT for another 10 new patients similar to our training datasets. The predicted DVHs were taken as a substitute for dose constraints and objective functions in the Eclipse treatment planning system, with the same requirements for the planning target volume (PTV). The mean doses to the heart, the left anterior descending coronary artery (LADCA) and the ipsilateral lung were evaluated and compared using the T-test among clinical plans, KDE predictions, and KDE plans. Results Our study demonstrated that the KDE model can generate deliverable simulations equivalent to clinically applicable plans. The T-test was applied to test the consistency hypothesis on another ten left-sided breast cancer patients. In cases of the same breathing status, there was no statistically significant difference between the predicted and the clinical plans for all clinically relevant DVH indices (P > 0.05), and all predicted DVHs can be transferred into deliverable plans. For DIBH-CT images, significant differences were observed between FB model predictions and clinical plans (P < 0.05). DIBH model prediction cannot be optimized to a deliverable plan based on FB-CT, with a counsel of perfection. Conclusion KDE models can predict DVHs well for the same breathing conditions but degrade with different breathing conditions. The benefits of DIBH for a given patient can be evaluated with a quick comparison of prediction results of the two models before treatment planning.","breast cancer,deep inspiration breath hold,dose distribution prediction,knowledge-based planning,machine learning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,2.107,"HEART-DISEASE,RISK,LUNG,OPTIMIZATION,THERAPY,WOMEN",JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS,https://aapm.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/acm2.13013,
13,,,,,,,,,,,,,,,,,,,,
14,,,,,,,,,,,,,,,,,,,,
15,Comparison of performances of conventional and deep learning-based methods in segmentation of lung vessels and registration of chest radiographs,14,1,6-15,"Guo Wei,Gu Xiaomeng,Fang Qiming,Li Qiang","Guo W,Gu XM,Fang QM,Li Q",Li Q,10.1007/s12194-020-00584-1,Huazhong University of Science & Technology,"Conventional machine learning-based methods have been effective in assisting physicians in making accurate decisions and utilized in computer-aided diagnosis for more than 30 years. Recently, deep learning-based methods, and convolutional neural networks in particular, have rapidly become preferred options in medical image analysis because of their state-of-the-art performance. However, the performances of conventional and deep learning-based methods cannot be compared reliably because of their evaluations on different datasets. Hence, we developed both conventional and deep learning-based methods for lung vessel segmentation and chest radiograph registration, and subsequently compared their performances on the same datasets. The results strongly indicated the superiority of deep learning-based methods over their conventional counterparts.","Medical image analysis,Vessel segmentation,Image registration,Conventional methods,Deep learning,Convolutional neural network",Article,"SPRINGER JAPAN KK, SHIROYAMA TRUST TOWER 5F, 4-3-1 TORANOMON, MINATO-KU, TOKYO, 105-6005, JAPAN","Radiology, Nuclear Medicine & Medical Imaging",,,"COMPUTER-AIDED,DIAGNOSIS,NODULES,MODEL",RADIOLOGICAL PHYSICS AND TECHNOLOGY,,
16,Automatic segmentation of brain tumour in MR images using an enhanced deep learning approach,9,2,121-130,"Tripathi Sumit,Verma Ashish,Sharma Neeraj","Tripathi S,Verma A,Sharma N",Tripathi S,10.1080/21681163.2020.1818628,Banaras Hindu University (BHU),"The presented manuscript proposes a fully automatic deep learning method to quantify the tumour region in brain Magnetic Resonance images as the accurate diagnosis of brain tumour region is necessary for the treatment of the patients. The irregular and confusing boundaries of tumours regions make it a challenging task to accurately figure out such regions. Another challenge with the segmentation task is of preserving the boundary details of the segmented tumour regions. The proposed network focuses on delineating the irregular tumour region as the best feature maps are learnt by the network, which is used for decoding; thus, it preserves the accurate boundary and pixel details. The proposed method incorporates internal residual connections in encoder and decoder to transfer feature maps directly to the successive layers to avoid loss of information contained in the images. The use of cross channel normalization (CCN) and parametric rectified linear unit (PRELU) gives a more balanced network output. The trained network produced remarkable results when tested on images of other datasets. Further, external clinical validation was performed by comparison of the algorithmic segmented images with those generated by a manual segmentation done by an experienced radiologist. We have termed our network as CCN-PR-Seg-net.","Deep learning,image segmentation,cross-channel normalisation,residual connections,convolutional neural network,parametric rectified linear unit (PRELU)",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,,,COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION,,
17,A study of deep learning approaches for classification and detection chromosomes in metaphase images,31,7-8,,"Andrade Maria F. S.,Dias Lucas V.,Macario Valmir,Lima Fabiana F.,Hwang Suy F.,Silva Julio C. G.,Cordeiro Filipe R.","Andrade MFS,Dias LV,Macario V,Lima FF,Hwang SF,Silva JCG,Cordeiro FR",Cordeiro FR,10.1007/s00138-020-01115-z,Universidade Federal Rural de Pernambuco (UFRPE),"Chromosome analysis is an important approach to detecting genetic diseases. However, the process of identifying chromosomes in metaphase images can be challenging and time-consuming. Therefore, it is important to use automatic methods for detecting chromosomes to aid diagnosis. This work proposes a study of deep learning approaches for classification and detection of chromosome in metaphase images. Furthermore, we propose a method for detecting chromosomes, which includes new stages for preprocessing and reducing false positives and false negatives. The proposed method is evaluated using 74 chromosome images in the metaphase stage, which were obtained from the CRCN-NE database, resulting in 2174 chromosome regions. We undertake three types of evaluation: segmentation; classification of cropped regions of chromosomes; and detection of chromosomes in the original images. For the segmentation analysis, we evaluated the Otsu, adaptive, fuzzy and fuzzy-adaptive methods. For classification and detection, we evaluated the following state-of-the-art algorithms: VGG16, VGG19, Inception v3, MobileNet, Xception, Sharma and MiniVGG. The classification results showed that the proposed approach, using segmented images, obtained better results than using RGB images. Furthermore, when analyzing deep learning approaches, the VGG16 algorithm obtained the best results, using fine tuning, with a sensitivity of 0.98, specificity of 0.99 and AUC of 0.955. The results also showed that the proposed negative reduction method increased sensitivity by 18%, while maintaining the specificity value. Deep learning methods have been proved to be efficient at detecting chromosomes, but preprocessing and post-processing are important to avoid false negatives. Therefore, using binary images and adding stages for reducing false positives and false negatives are necessary in order to increase the quality of the images of the chromosomes detected.","Chromosome,Classification,Deep learning,Metaphase,Detection",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Computer Science,Engineering",,1.975,,MACHINE VISION AND APPLICATIONS,,
18,Designing and understanding light-harvesting devices with machine learning,11,1,,"Hase Florian,Roch Loic M.,Friederich Pascal,Aspuru-Guzik Alan","Hase F,Roch LM,Friederich P,Aspuru-Guzik A",Aspuru-Guzik A,10.1038/s41467-020-17995-8,"Vector Inst Artificial Intelligence, CIFAR AI Chair, 661 Univ Ave, Toronto, ON M5S 1M1, Canada.","Understanding the fundamental processes of light-harvesting is crucial to the development of clean energy materials and devices. Biological organisms have evolved complex metabolic mechanisms to efficiently convert sunlight into chemical energy. Unraveling the secrets of this conversion has inspired the design of clean energy technologies, including solar cells and photocatalytic water splitting. Describing the emergence of macroscopic properties from microscopic processes poses the challenge to bridge length and time scales of several orders of magnitude. Machine learning experiences increased popularity as a tool to bridge the gap between multi-level theoretical models and Edisonian trial-and-error approaches. Machine learning offers opportunities to gain detailed scientific insights into the underlying principles governing light-harvesting phenomena and can accelerate the fabrication of light-harvesting devices.","EXCITATION-ENERGY TRANSFER,ORGANIC SOLAR-CELLS,MOLECULAR-DYNAMICS SIMULATIONS,NEURAL-NETWORKS,ELECTRONIC EXCITATIONS,QUANTUM EFFICIENCY,CHEMISTRY,COMPLEXITY,CHALLENGES,ACCEPTOR",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,15.805,"EXCITATION-ENERGY,TRANSFER,ORGANIC,SOLAR-CELLS,MOLECULAR-DYNAMICS,SIMULATIONS,NEURAL-NETWORKS,ELECTRONIC,EXCITATIONS,QUANTUM,EFFICIENCY,CHEMISTRY,COMPLEXITY,CHALLENGES,ACCEPTOR",NATURE COMMUNICATIONS,https://www.nature.com/articles/s41467-020-17995-8.pdf,
19,Sensorineural hearing loss classification via deep-HLNet and few-shot learning,80,2,2109-2122,"Chen Xi,Zhou Qinghua,Lan Rushi,Wang Shui-Hua,Zhang Yu-Dong,Luo Xiaonan","Chen X,Zhou QH,Lan RS,Wang SH,Zhang YD,Luo XN",Lan RS,10.1007/s11042-020-09702-y,Guilin University of Electronic Technology,"We propose a new method for hearing loss classification from magnetic resonance image (MRI), which can automatically detect tissue-specific features in a given MRI. Sensorineural hearing loss (SHNL) is highly prevalent in our society. Early diagnosis and intervention have a profound impact on patient outcomes. A solution to provide early diagnosis is the use of automated diagnostic systems. In this study, we propose a novel Deep-HLNet framework, based on few-shot learning, for the automated classification of SNHL. This research involves magnetic resonance (MRI) images from 60 participants of three balanced categories: left-sided SNHL, right-sided SNHL, and healthy controls. A convolutional neural network was employed for feature extraction from individual categories, while a neural network and a comparison classifier strategy constituted a tri-classifier for SNHL classification. In terms of experiment results and practicability of the algorithm, the classification performance was significantly better than the standard deep learning methods or other conventional methods, with an overall accuracy of 96.62%.","Hearing loss,Few-shot learning,Deep-HLNet",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"EMPIRICAL,MODE,DECOMPOSITION,SUPPORT,VECTOR,REGRESSION,SVR,ENTROPY",MULTIMEDIA TOOLS AND APPLICATIONS,,
20,Natural language processing for automated quantification of bone metastases reported in free-text bone scintigraphy reports,59,12,1455-1460,"Groot Olivier Q.,Bongers Michiel E. R.,Karhade Aditya V.,Kapoor Neal D.,Fenn Brian P.,Kim Jason,Verlaan J. J.,Schwab Joseph H.","Groot OQ,Bongers MER,Karhade AV,Kapoor ND,Fenn BP,Kim J,Verlaan JJ,Schwab JH",Groot OQ,10.1080/0284186X.2020.1819563,Harvard University,"Background The widespread use of electronic patient-generated health data has led to unprecedented opportunities for automated extraction of clinical features from free-text medical notes. However, processing this rich resource of data for clinical and research purposes, depends on labor-intensive and potentially error-prone manual review. The aim of this study was to develop a natural language processing (NLP) algorithm for binary classification (single metastasis versus two or more metastases) in bone scintigraphy reports of patients undergoing surgery for bone metastases. Material and methods Bone scintigraphy reports of patients undergoing surgery for bone metastases were labeled each by three independent reviewers using a binary classification (single metastasis versus two or more metastases) to establish a ground truth. A stratified 80:20 split was used to develop and test an extreme-gradient boosting supervised machine learning NLP algorithm. Results A total of 704 free-text bone scintigraphy reports from 704 patients were included in this study and 617 (88%) had multiple bone metastases. In the independent test set (n = 141) not used for model development, the NLP algorithm achieved an 0.97 AUC-ROC (95% confidence interval [CI], 0.92-0.99) for classification of multiple bone metastases and an 0.99 AUC-PRC (95% CI, 0.99-0.99). At a threshold of 0.90, NLP algorithm correctly identified multiple bone metastases in 117 of the 124 who had multiple bone metastases in the testing cohort (sensitivity 0.94) and yielded 3 false positives (specificity 0.82). At the same threshold, the NLP algorithm had a positive predictive value of 0.97 and F1-score of 0.96. Conclusions NLP has the potential to automate clinical data extraction from free text radiology notes in orthopedics, thereby optimizing the speed, accuracy, and consistency of clinical chart review. Pending external validation, the NLP algorithm developed in this study may be implemented as a means to aid researchers in tackling large amounts of data.","INFORMATION,EXTRACTION",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Oncology,,4.236,"INFORMATION,EXTRACTION",ACTA ONCOLOGICA,https://www.tandfonline.com/doi/pdf/10.1080/0284186X.2020.1819563?needAccess=true,
21,ProminTools: shedding light on proteins of unknown function in biomineralization with user friendly tools illustrated using mollusc shell matrix protein sequences,8,,,"Skeffington Alastair W.,Donath Andreas on","Skeffington AW,Donath OA",Skeffington AW,10.7717/peerj.9852,Max Planck Society,"Biominerals are crucial to the fitness of many organism and studies of the mechanisms of biomineralization are driving research into novel materials. Biomineralization is generally controlled by a matrix of organic molecules including proteins, so proteomic studies of biominerals are important for understanding biomineralization mechanisms. Many such studies identify large numbers of proteins of unknown function, which are often of low sequence complexity and biased in their amino add composition. A lack of user-friendly tools to find patterns in such sequences and robustly analyse their statistical properties relative to the background proteome means that they are often neglected in follow-up studies. Here we present ProminTools, a user-friendly package for comparison of two sets of protein sequences in terms of their global properties and motif content. Outputs include data tables, graphical summaries in an html file and an R-script as a starting point for data-set specific visualizations. We demonstrate the utility of ProminTools using a previously published shell matrix proteome of the giant limpet Lottia gigantea.","Biomineralization,Proteins of unknown function,Motif,Sequence bias,Intrinsic disorder,Lottia gigantea,Mollusc",Article,"PEERJ INC, 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND",Science & Technology - Other Topics,,3.369,COMPLEXITY,PEERJ,https://peerj.com/articles/9852.pdf,
22,Integrated computational product and production engineering for multi-material lightweight structures,110,9-10,2551-2571,"Huerkamp Andre,Der Antal,Gellrich Sebastian,Ossowski Tim,Lorenz Ralf,Behrens Bernd-Arno,Herrmann Christoph,Droeder Klaus,Thiede Sebastian","Hurkamp A,Der A,Gellrich S,Ossowski T,Lorenz R,Behrens BA,Herrmann C,Droder K,Thiede S",Hurkamp A,10.1007/s00170-020-05895-6,Braunschweig University of Technology,"Within product development processes, computational models are used with increasing frequency. However, the use of those methods is often restricted to the area of focus, where product design, manufacturing process, and process chain simulations are regarded independently. In the use case of multi-material lightweight structures, the desired products have to meet several requirements regarding structural performance, weight, costs, and environment. Hence, manufacturing-related effects on the product as well as on costs and environment have to be considered in very early phases of the product development process in order to provide a computational concept that supports concurrent engineering. In this contribution, we present an integrated computational concept that includes product engineering and production engineering. In a multi-scale framework, it combines detailed finite element analyses of products and their related production process with process chain and factory simulations. Including surrogate models based on machine learning, a fast evaluation of production impacts and requirements can be realized. The proposed integrated computational product and production engineering concept is demonstrated in a use case study on the manufacturing of a multi-material structure. Within this study, a sheet metal forming process in combination with an injection molding process of short fiber reinforced plastics is investigated. Different sets of process parameters are evaluated virtually in terms of resulting structural properties, cycle times, and environmental impacts.","Product development,Production engineering,Multi-scale simulation,Machine learning",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND","Automation & Control Systems,Engineering",,3.32,"OF-THE-ART,MANUFACTURING,SYSTEMS,ENERGY-CONSUMPTION,FIBER,ORIENTATION,SIMULATION,MODEL,REDUCTION,BEHAVIOR,DESIGN,STATE",INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY,https://www.repo.uni-hannover.de/bitstream/123456789/10778/1/Integrated%20computational%20product%20and%20production%20engineering%20for%20multi-material%20lightweight%20structures.pdf,
23,Development of surface texture evaluation system for highly sparse data-driven machining domains,33,9,859-868,"Raju Umamaheswara R. S.,Ramesh R.,Rohit Varma K.","Raju RSU,Ramesh R,Varma KR",Raju RSU,10.1080/0951192X.2020.1803503,"MVGRCE A, Dept Mech Engn, Vzm 535005, India.","Dimensional, geometrical and surface texture tolerances are significant issues to be addressed by manufacturing industries. Dimensional and geometrical tolerance estimation systems are used by several machining industries, whereas surface texture tolerance estimation systems are rare. In general-purpose machines, several machining operations are performed and huge machining data are required for the development of surface texture tolerance estimation model. The necessity for sparse data modeling is the need of the hour and such modeling techniques reduce costly trial and error approaches. Shoulder milling operations are performed on mild steel workpieces. Experimentation is performed at diverse cutting conditions, and surface texture tolerances of the machined components are measured. Big data computation is being accomplished by contemporary tools compared to sparse data evaluation. The novelty of this work is to develop a system capable of surface texture tolerance evaluation from highly sparse learning data, as big data generation involves cost and time for experimentation. Flower Pollination Algorithm (FPA) models are developed for the highly sparse data for surface roughness estimation. Two different FPA techniques, namely, Maximum (Max) and Average (Avg) are used, and a comparison between the methods mentioned above is made. An operator-friendly adaptive performance enhancement system is developed to evaluate the corresponding surface texture tolerance for the given operating parameters.","Adaptive performance enhancement system,surface texture tolerance,estimation model,flower pollination algorithm",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,3.076,"TOOL,WEAR,ROUGHNESS,PREDICTION,VIBRATION,STEEL",INTERNATIONAL JOURNAL OF COMPUTER INTEGRATED MANUFACTURING,,
24,,,,,,,,,,,,,,,,,,,,
25,Toward better prediction of recurrence for Cushing's disease: a factorization-machine based neural approach,12,3,625-633,"Fan Yanghua,Li Dongfang);,Liu Yifan,Feng Ming,Chen Qingcai,Wang Renzhi","Fan YH,Li DF,Liu YF,Feng M,Chen QC,Wang RZ",Wang RZ,10.1007/s13042-020-01192-6,Chinese Academy of Medical Sciences - Peking Union Medical College,"Cushing's disease (CD) is a rare disease that occurs in 1.2-1.4 persons per million population per year. Recurrence prediction after transsphenoidal surgery (TSS) is important for determining individual treatment and follow-up strategies. Between 2000 and 2017, 354 CD patients with initial postoperative remission and long-term follow-up data were enrolled from Peking union medical college hospital (PUMCH) to predict recurrence, and PUMCH is one of the largest CD treatment centers in the world. We first investigated the effect of a factorization machine (FM)-based neural network to predict recurrence after TSS for CD. This method could automatically reduce a portion of the cross-feature selection work with acceptable parameters. We conducted a performance comparison of various algorithms on the collected dataset. To address the lack of interpretability of neural network models, we also used the local interpretable model-agnostic explanations approach, which provides an explanation in the form of relevant features of the predicted results by approximating the model behavior of the variables in a local manner. Compared with existing methods, the DeepFM model obtained the highest AUC value (0.869) and the lowest log loss value (0.256). According to the importance of each feature, three top features for the DeepFM model were postoperative morning adrenocorticotropic hormone level, age, and postoperative morning serum cortisol nadir. In the post hoc explanation phase, the above-mentioned importance-leading features made a great contribution to the prediction probability. The results showed that deep learning-based models could better aid neurosurgeons in recurrence prediction after TTS for patients with CD, and could contribute to determining individual treatment strategies.","Cushing's disease,Recurrence,Deep learning,Transsphenoidal surgery,Local interpretable model-agnostic explanations",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Computer Science,,3.558,"LONG-TERM,REMISSION,TRANSSPHENOIDAL,SURGERY,POSTOPERATIVE,CORTISOL,EXPERIENCE,MORTALITY",INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS,,
26,Estimation of Parkinson's disease severity using speech features and extreme gradient boosting,58,11,2757-2773,"Tunc Hunkar C.,Sakar C. Okan,Apaydin Hulya,Serbes Gorkem,Gunduz Aysegul,Tutuncu Melih,Gurgen Fikret","Tunc HC,Sakar CO,Apaydin H,Serbes G,Gunduz A,Tutuncu M,Gurgen F",Tunc HC,10.1007/s11517-020-02250-5,Bahcesehir University,"In recent years, there is an increasing interest in building e-health systems. The systems built to deliver the health services with the use of internet and communication technologies aim to reduce the costs arising from outpatient visits of patients. Some of the related recent studies propose machine learning-based telediagnosis and telemonitoring systems for Parkinson's disease (PD). Motivated from the studies showing the potential of speech disorders in PD telemonitoring systems, in this study, we aim to estimate the severity of PD from voice recordings of the patients using motor Unified Parkinson's Disease Rating Scale (UPDRS) as the evaluation metric. For this purpose, we apply various speech processing algorithms to the voice signals of the patients and then use these features as input to a two-stage estimation model. The first step is to apply a wrapper-based feature selection algorithm, called Boruta, and select the most informative speech features. The second step is to feed the selected set of features to a decision tree-based boosting algorithm, extreme gradient boosting, which has been recently applied successfully in many machine learning tasks due to its generalization ability and speed. The feature selection analysis showed that the vibration pattern of the vocal fold is an important indicator of PD severity. Besides, we also investigate the effectiveness of using age and years passed since diagnosis as covariates together with speech features. The lowest mean absolute error with 3.87 was obtained by combining these covariates and speech features with prediction level fusion.","Unified Parkinson's Disease Rating Scale,UPDRS prediction,Machine learning,Telemonitoring,E-health",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"SIGNAL-PROCESSING,ALGORITHMS,RATING-SCALE,WAVELET,TRANSFORM,INTERRATER,RELIABILITY,SYSTEM,CLASSIFICATION,DIAGNOSIS,BORUTA,IMPAIRMENT,DISORDERS",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
27,NEMPD: a network embedding-based method for predicting miRNA-disease associations by preserving behavior and attribute information,21,1,,"Ji Bo-Ya,You Zhu-Hong,Chen Zhan-Heng,Wong Leon,Yi Hai-Cheng","Ji BY,You ZH,Chen ZH,Wong L,Yi HC",You ZH,10.1186/s12859-020-03716-x,Chinese Academy of Sciences,"Background As an important non-coding RNA, microRNA (miRNA) plays a significant role in a series of life processes and is closely associated with a variety ofHumandiseases. Hence, identification of potential miRNA-disease associations can make great contributions to the research and treatment ofHumandiseases. However, to our knowledge, many existing computational methods only utilize the single type of known association information between miRNAs and diseases to predict their potential associations, without focusing on their interactions or associations with other types of molecules. Results In this paper, we propose a network embedding-based method for predicting miRNA-disease associations by preserving behavior and attribute information. Firstly, a heterogeneous network is constructed by integrating known associations among miRNA, protein and disease, and the network representation method Learning Graph Representations with Global Structural Information (GraRep) is implemented to learn the behavior information of miRNAs and diseases in the network. Then, the behavior information of miRNAs and diseases is combined with the attribute information of them to represent miRNA-disease association pairs. Finally, the prediction model is established based on the Random Forest algorithm. Under the five-fold cross validation, the proposed NEMPD model obtained average 85.41% prediction accuracy with 80.96% sensitivity at the AUC of 91.58%. Furthermore, the performance of NEMPD is also validated by the case studies. Among the top 50 predicted disease-related miRNAs, 48 (breast neoplasms), 47 (colon neoplasms), 47 (lung neoplasms) were confirmed by two other databases. Conclusions The proposed NEMPD model has a good performance in predicting the potential associations between miRNAs and diseases, and has great potency in the field of miRNA-disease association prediction in the future.","miRNA-disease associations,Heterogeneous network,GraRep,Random Forest",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,"MICRORNA,CANCER,SIMILARITY,DEREGULATION",BMC BIOINFORMATICS,https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-020-03716-x,
28,Synthetic-Neuroscore: Using a neuro-AI interface for evaluating generative adversarial networks,405,,26-36,"Wang Zhengwei,She Qi,Smeaton Alan F.,Ward Tomas E.,Healy Graham","Wang ZW,She Q,Smeaton AF,Ward TE,Healy G",Wang ZW,10.1016/j.neucom.2020.04.069,Trinity College Dublin,,"COUPLED COMPUTER VISION,TASK-DIFFICULTY,MODELS,P300",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"COUPLED,COMPUTER,VISION,TASK-DIFFICULTY,MODELS,P300",NEUROCOMPUTING,http://arxiv.org/pdf/1905.04243,
29,Retinal optical coherence tomography image classification with label smoothing generative adversarial network,405,,37-47,"He Xingxin,Fang Leyuan,Rabbani Hossein,Chen Xiangdong,Liu Zhimin","He XX,Fang LY,Rabbani H,Chen XD,Liu ZM",Fang LY,10.1016/j.neucom.2020.04.044,Hunan University,,"DIABETIC MACULAR EDEMA,CONVOLUTIONAL NEURAL-NETWORK,SD-OCT IMAGES,AUTOMATIC SEGMENTATION,GEOGRAPHIC ATROPHY,LAYER BOUNDARIES,DEGENERATION,PATHOLOGY,PATTERNS,DISEASES",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"DIABETIC,MACULAR,EDEMA,CONVOLUTIONAL,NEURAL-NETWORK,SD-OCT,IMAGES,AUTOMATIC,SEGMENTATION,GEOGRAPHIC,ATROPHY,LAYER,BOUNDARIES,DEGENERATION,PATHOLOGY,PATTERNS,DISEASES",NEUROCOMPUTING,,
30,Augmented Reality Interface for Complex Anatomy Learning in the Central Nervous System: A Systematic Review,2020,,,"Wirza Rahmita,Nazir Shah,Khan Habib Ullah,Garcia-Magarino Ivan,Amin Rohul","Wirza R,Nazir S,Khan HU,Garcia-Magarino I,Amin R",Wirza R,10.1155/2020/8835544,Universiti Putra Malaysia,"The medical system is facing the transformations with augmentation in the use of medical information systems, electronic records, smart, wearable devices, and handheld. The central nervous system function is to control the activities of the mind and the human body. Modern speedy development in medical and computational growth in the field of the central nervous system enables practitioners and researchers to extract and visualize insight from these systems. The function of augmented reality is to incorporate virtual and real objects, interactively running in a real-time and real environment. The role of augmented reality in the central nervous system becomes a thought-provoking task. Gesture interaction approach-based augmented reality in the central nervous system has enormous impending for reducing the care cost, quality refining of care, and waste and error reducing. To make this process smooth, it would be effective to present a comprehensive study report of the available state-of-the-art-work for enabling doctors and practitioners to easily use it in the decision making process. This comprehensive study will finally summarise the outputs of the published materials associate to gesture interaction-based augmented reality approach in the central nervous system. This research uses the protocol of systematic literature which systematically collects, analyses, and derives facts from the collected papers. The data collected range from the published materials for 10 years. 78 papers were selected and included papers based on the predefined inclusion, exclusion, and quality criteria. The study supports to identify the studies related to augmented reality in the nervous system, application of augmented reality in the nervous system, technique of augmented reality in the nervous system, and the gesture interaction approaches in the nervous system. The derivations from the studies show that there is certain amount of rise-up in yearly wise articles, and numerous studies exist, related to augmented reality and gestures interaction approaches to different systems of the human body, specifically to the nervous system. This research organises and summarises the existing associated work, which is in the form of published materials, and are related to augmented reality. This research will help the practitioners and researchers to sight most of the existing studies subjected to augmented reality-based gestures interaction approaches for the nervous system and then can eventually be followed as support in future for complex anatomy learning.","VIRTUAL-REALITY,EDUCATION,TOOL,ENGAGEMENT,FRAMEWORK,INTERNET,THINGS",Review,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Health Care Sciences & Services,,3.188,"VIRTUAL-REALITY,EDUCATION,TOOL,ENGAGEMENT,FRAMEWORK,INTERNET,THINGS",JOURNAL OF HEALTHCARE ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7501559,
31,Machine-Learning-Based Prediction of Methane Adsorption Isotherms at Varied Temperatures for Experimental Adsorbents,124,36,19538-19547,"Kim Seo-Yul,Kim Seung-Ik,Bae Youn-Sang","Kim SY,Kim SI,Bae YS",Bae YS,10.1021/acs.jpcc.0c01757,Yonsei University,"Metal-organic frameworks (MOFs) are crystalline materials and one of the optimal materials for large-scale grand canonical Monte Carlo (GCMC) simulations. Recently, there have been trials for applying machine learning (ML) to the results of large-scale GCMC simulations to predict gas adsorption on MOFs. However, the functions of the developed algorithms are not different from those of GCMC simulations, in that they provide a prediction of adsorption properties based on the coordination structures. In this study, we propose a novel Monte Carlo-Machine Learning (MC-ML) strategy, which combines ML with GCMC to provide the function that is distinct from that of GCMC. To verify the concept of the strategy, we designed an algorithm to predict methane isotherms at a range of temperatures from a methane isotherm at a temperature of 298 K. GCMC simulations functioned as a data-producing tool for ML, which yielded adsorption properties of 4951 structures in the CoRE-MOF database. The ML was applied to the GCMC results using experimentally measurable properties as features. Finally, the algorithm developed from ML was evaluated using experimental methane adsorption data for defective MOFs, MOFs with open metal sites, and non-MOF materials, which revealed the merits of the MC-ML strategy in comparison with typical GCMC.","METAL-ORGANIC FRAMEWORKS,MONTE-CARLO SIMULATIONS,HYDROGEN STORAGE,POROUS MATERIALS,GCMC SIMULATION,SURFACE-AREA,GAS-STORAGE,SEPARATION,CO2,CH4",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,4.467,"METAL-ORGANIC,FRAMEWORKS,MONTE-CARLO,SIMULATIONS,HYDROGEN,STORAGE,POROUS,MATERIALS,GCMC,SIMULATION,SURFACE-AREA,GAS-STORAGE,SEPARATION,CO2,CH4",JOURNAL OF PHYSICAL CHEMISTRY C,,
32,"Fast Screening of Large Databases for Top Performing Nanomaterials Using a Self-Consistent, Machine Learning Based Approach",124,36,19639-19648,"Fanourgakis George S.,Gkagkas Konstantinos,Tylianakis Emmanuel,Froudakis George","Fanourgakis GS,Gkagkas K,Tylianakis E,Froudakis G",Fanourgakis GS; Froudakis G,10.1021/acs.jpcc.0c05491,University of Crete,"Toward the fast and accurate identification of top performing candidates from the huge pool of nanoporous materials that can potentially be synthesized, we present and evaluate a methodology that combines, in a self-consistent way, results of molecular simulations and machine learning approaches. The aim is to reduce as much as possible the number of candidates for which time-consuming and expensive theoretical and/or experimental studies are required. As a case study, we have used the adsorption of methane at different pressures in a large database of covalent-organic frameworks and in a small, but highly structural and chemical diverse database of experimentally synthesized metal-organic frameworks. It is found that when the self-consistent approach is combined with a machine learning algorithm, for which accurate descriptors are used, most of the top performing materials are identified, requiring only a small amount of reference data. The sensitivity of the algorithm to its underlined parameters is investigated and strategies for optimal choices are suggested.","METAL-ORGANIC FRAMEWORKS,IN-SILICO DESIGN,METHANE STORAGE,COMPUTATIONAL DESIGN,HYDROGEN STORAGE,ADSORPTION,CAPACITY",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,4.467,"METAL-ORGANIC,FRAMEWORKS,IN-SILICO,DESIGN,METHANE,STORAGE,COMPUTATIONAL,DESIGN,HYDROGEN,STORAGE,ADSORPTION,CAPACITY",JOURNAL OF PHYSICAL CHEMISTRY C,,
33,Sampling-based estimation method for parameter estimation in big data business era,18,2,297-322,"Alim Abdul,Shukla Diwakar","Alim A,Shukla D",Alim A,10.1108/JAMR-05-2020-0072,Dr. Hari Singh Gour University,"Purpose This paper aims to present sample-based estimation methodologies to compute the confidence interval for the mean size of the content of material communicated on the digital social media platform in presence of volume, velocity and variety. Confidence interval acts as a tool of machine learning and managerial decision-making for coping up big data. Design/methodology/approach Random sample-based sampling design methodology is adapted and mean square error is computed on the data set. Confidence intervals are calculated using the simulation over multiple data sets. The smallest length confidence interval is the selection approach for the most efficient in the scenario of big data. Findings Resultants of computations herein help to forecast the future need of web-space at data-centers for anticipation, efficient management, developing a machine learning algorithm for predicting better quality of service to users. Finding supports to develop control limits as an alert system for better use of resources (memory space) at data centers. Suggested methodologies are efficient enough for future prediction in big data setup. Practical implications In IT sector, the startup with the establishment of data centers is the current trend of business. Findings herein may help to develop a forecasting system and alert system for optimal decision-making in the enhancement and share of the business. Originality/value The contribution is an original piece of thought, idea and analysis, deriving motivation from references appended.","Big-data,Sampling,Estimation,Social media,Business,Big data 10Vs,Simulation,Confidence interval (CI)",Article,"EMERALD GROUP PUBLISHING LTD, HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND",Business & Economics,,,,JOURNAL OF ADVANCES IN MANAGEMENT RESEARCH,,
34,,,,,,,,,,,,,,,,,,,,
35,"Machine learning risk score for prediction of gestational diabetes in early pregnancy in Tianjin, China",37,5,,"Liu Hongwei,Li Jing,Leng Junhong,Wang Hui,Liu Jinnan,Li Weiqin,Liu Hongyan,Wang Shuo,Ma Jun,Chan Juliana C. N.","Liu HW,Li J,Leng JH,Wang H,Liu JN,Li WQ,Liu HY,Wang S,Ma J,Chan JCN",Li CP,10.1002/dmrr.3397,Tianjin Medical University,"Aims This study aimed to develop a machine learning-based prediction model for gestational diabetes mellitus (GDM) in early pregnancy in Chinese women. Materials and methods We used an established population-based prospective cohort of 19,331 pregnant women registered as pregnant before the 15th gestational week in Tianjin, China, from October 2010 to August 2012. The dataset was randomly divided into a training set (70%) and a test set (30%). Risk factors collected at registration were examined and used to construct the prediction model in the training dataset. Machine learning, that is, the extreme gradient boosting (XGBoost) method, was employed to develop the model, while a traditional logistic model was also developed for comparison purposes. In the test dataset, the performance of the developed prediction model was assessed by calibration plots for calibration and area under the receiver operating characteristic curve (AUR) for discrimination. Results In total, 1484 (7.6%) women developed GDM. Pre-pregnancy body mass index, maternal age, fasting plasma glucose at registration, and alanine aminotransferase were selected as risk factors. The machine learning XGBoost model-predicted probability of GDM was similar to the observed probability in the test data set, while the logistic model tended to overestimate the risk at the highest risk level (Hosmer-Lemeshow testpvalue: 0.243 vs. 0.099). The XGBoost model achieved a higher AUR than the logistic model (0.742 vs. 0.663,p< 0.001). This XGBoost model was deployed through a free, publicly available software interface (). Conclusion The XGBoost model achieved better performance than the logistic model.","extreme gradient boosting,gestational diabetes mellitus,machine learning,prognostic prediction model",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Endocrinology & Metabolism,,5.324,"LOGISTIC-REGRESSION,INSULIN-RESISTANCE,MID-PREGNANCY,MELLITUS",DIABETES-METABOLISM RESEARCH AND REVIEWS,,
36,High Throughput Screening of Millions of van der Waals Heterostructures for Superlubricant Applications,3,11,,"Fronzi Marco,Tawfik Sherif Abdulkader,Ghazaleh Mutaz Abu,Isayev Olexandr,Winkler David A.,Shapter Joe,Ford Michael J.","Fronzi M,Tawfik SA,Abu Ghazaleh M,Isayev O,Winkler DA,Shapter J,Ford MJ",Fronzi M; Ford MJ,10.1002/adts.202000029,University of Technology Sydney,"The screening of novel materials is an important topic in the field of materials science. Although traditional computational modeling, especially first-principles approaches, is a very useful and accurate tool to predict the properties of novel materials, it still demands extensive and expensive state-of-the-art computational resources. Additionally, they can often be extremely time consuming. A time and resource efficient machine learning approach to create a dataset of structural properties of 18 million van der Waals layered structures is described. In particular, the authors focus on the interlayer energy and the elastic constant of layered materials composed of two different 2D structures that are important for novel solid lubricant and super-lubricant materials. It is shown that machine learning models can predict results of computationally expansive approaches (i.e., density functional theory) with high accuracy.","machine learning,Density Functional Theory,2D materials,van der Waals heterostructures",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Science & Technology - Other Topics,,4.004,"ARTIFICIAL,NEURAL-NETWORKS,ULTRASOFT,PSEUDOPOTENTIALS,ELECTRONIC-STRUCTURE,TRANSITION,SELECTION,QSAR",ADVANCED THEORY AND SIMULATIONS,,
37,Extending machine learning classification capabilities with histogram reweighting,102,3,,"Bachtis Dimitrios,Aarts Gert,Lucini Biagio","Bachtis D,Aarts G,Lucini B",Bachtis D,10.1103/PhysRevE.102.033303,Swansea University,"We propose the use of Monte Carlo histogram reweighting to extrapolate predictions of machine learning methods. In our approach, we treat the output from a convolutional neural network as an observable in a statistical system, enabling its extrapolation over continuous ranges in parameter space. We demonstrate our proposal using the phase transition in the two-dimensional Ising model. By interpreting the output of the neural network as an order parameter, we explore connections with known observables in the system and investigate its scaling behavior. A finite-size scaling analysis is conducted based on quantities derived from the neural network that yields accurate estimates for the critical exponents and the critical temperature. The method improves the prospects of acquiring precision measurements from machine learning in physical systems without an order parameter and those where direct sampling in regions of parameter space might not be possible.",,Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,,,PHYSICAL REVIEW E,http://arxiv.org/pdf/2004.14341,
38,Machine intelligence for nerve conduit design and production,14,1,,"Stewart Caleb E.,Kan Chin Fung Kelvin,Stewart Brody R.,Sanicola Henry W. III,Jung Jangwook P.,Sulaiman Olawale A. R.,Wang Dadong","Stewart CE,Kan CFK,Stewart BR,Sanicola HW,Jung JP,Sulaiman OAR,Wang DD",Stewart CE,10.1186/s13036-020-00245-2,Louisiana State University System,"Nerve guidance conduits (NGCs) have emerged from recent advances within tissue engineering as a promising alternative to autografts for peripheral nerve repair. NGCs are tubular structures with engineered biomaterials, which guide axonal regeneration from the injured proximal nerve to the distal stump. NGC design can synergistically combine multiple properties to enhance proliferation of stem and neuronal cells, improve nerve migration, attenuate inflammation and reduce scar tissue formation. The aim of most laboratories fabricating NGCs is the development of an automated process that incorporates patient-specific features and complex tissue blueprints (e.g. neurovascular conduit) that serve as the basis for more complicated muscular and skin grafts. One of the major limitations for tissue engineering is lack of guidance for generating tissue blueprints and the absence of streamlined manufacturing processes. With the rapid expansion of machine intelligence, high dimensional image analysis, and computational scaffold design, optimized tissue templates for 3D bioprinting (3DBP) are feasible. In this review, we examine the translational challenges to peripheral nerve regeneration and where machine intelligence can innovate bottlenecks in neural tissue engineering.","Bioprinting,Data science,Tissue engineering,Computer vision,Nerve regeneration,Machine learning,Artificial intelligence",Review,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology",,5.189,"ACCELERATES,AXON,REGENERATION,PERIPHERAL-NERVE,SCHWANN-CELLS,ELECTRICAL-STIMULATION,GROWTH-FACTOR,GENE-THERAPY,NEUROTROPHIC,FACTOR,GUIDANCE,CHANNELS,NEURAL-NETWORK,SCIATIC-NERVE",JOURNAL OF BIOLOGICAL ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7487837,
39,Prediction of the Properties of the Rare-Earth Magnets Ce2Fe17-xCoxCN: A Combined Machine-Learning and Ab Initio Study,14,3,,"Halder Anita,Rom Samir,Ghosh Aishwaryo,Saha-Dasgupta Tanusri","Halder A,Rom S,Ghosh A,Saha-Dasgupta T",Saha-Dasgupta T,10.1103/PhysRevApplied.14.034024,Department of Science & Technology (India),"We employ a combination of machine learning and first-principles calculations to predict magnetic properties of rare-earth lean magnets. For this purpose, based on a training set constructed out of experimental data, the machine is trained to make predictions on magnetic transition temperature (T-c), largeness of saturation magnetization (mu M-0(s)), and the nature of the magnetocrystalline anisotropy (K-u). Subsequently, the quantitative values of mu M-0(s) and K-u of the yet-to-be synthesized compounds, screened by machine learning, are calculated by first-principles density-functional theory. The applicability of the proposed technique of combined machine learning and first-principles calculations is demonstrated on 2-17-X magnets, Ce2Fe17-xCoxCN. Further to this study, we explore the stability of the proposed compounds by calculating vacancy formation energy of small atom interstitials (N/C). Our study indicates a number of compounds in the proposed family and offers the possibility to become a solution for cheap and efficient permanent magnets.","DENSITY-FUNCTIONAL THEORY,NEUTRON-DIFFRACTION,IRON NITRIDES,ANISOTROPY,ND,FE,SM,DY,BEHAVIOR,GD",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,5.111,"DENSITY-FUNCTIONAL,THEORY,NEUTRON-DIFFRACTION,IRON,NITRIDES,ANISOTROPY,ND,FE,SM,DY,BEHAVIOR,GD",PHYSICAL REVIEW APPLIED,http://arxiv.org/pdf/2008.05125,
40,Automated classification of protein subcellular localization in immunohistochemistry images to reveal biomarkers in colon cancer,21,1,,"Xue Zhen-Zhen,Wu Yanxia,Gao Qing-Zu,Zhao Liang,Xu Ying-Ying","Xue ZZ,Wu YX,Gao QZ,Zhao L,Xu YY",Xu YY,10.1186/s12859-020-03731-y,Southern Medical University - China,"Background Protein biomarkers play important roles in cancer diagnosis. Many efforts have been made on measuring abnormal expression intensity in biological samples to identity cancer types and stages. However, the change of subcellular location of proteins, which is also critical for understanding and detecting diseases, has been rarely studied. Results In this work, we developed a machine learning model to classify protein subcellular locations based on immunohistochemistry images of human colon tissues, and validated the ability of the model to detect subcellular location changes of biomarker proteins related to colon cancer. The model uses representative image patches as inputs, and integrates feature engineering and deep learning methods. It achieves 92.69% accuracy in classification of new proteins. Two validation datasets of colon cancer biomarkers derived from published literatures and the human protein atlas database respectively are employed. It turns out that 81.82 and 65.66% of the biomarker proteins can be identified to change locations. Conclusions Our results demonstrate that using image patches and combining predefined and deep features can improve the performance of protein subcellular localization, and our model can effectively detect biomarkers based on protein subcellular translocations. This study is anticipated to be useful in annotating unknown subcellular localization for proteins and discovering new potential location biomarkers.","Bioimage processing,Bioinformatics,Machine learning,Protein subcellular location,Cancer biomarkers",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,"NUCLEAR-LOCALIZATION,LOCATION,PATTERNS,BETA-CATENIN,REDUCTION,CELLS",BMC BIOINFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7487883,
41,Correlation-driven machine learning for accelerated reliability assessment of solder joints in electronics,10,1,,"Samavatian Vahid,Fotuhi-Firuzabad Mahmud);,Samavatian Majid,Dehghanian Payman,Blaabjerg Frede","Samavatian V,Fotuhi-Firuzabad M,Samavatian M,Dehghanian P,Blaabjerg F",Blaabjerg F,10.1038/s41598-020-71926-7,Aalborg University,"The quantity and variety of parameters involved in the failure evolutions in solder joints under a thermo-mechanical process directs the reliability assessment of electronic devices to be frustratingly slow and expensive. To tackle this challenge, we develop a novel machine learning framework for reliability assessment of solder joints in electronic systems; we propose a correlation-driven neural network model that predicts the useful lifetime based on the materials properties, device configuration, and thermal cycling variations. The results indicate a high accuracy of the prediction model in the shortest possible time. A case study will evaluate the role of solder material and the joint thickness on the reliability of electronic devices; we will illustrate that the thermal cycling variations strongly determine the type of damage evolution, i.e., the creep or fatigue, during the operation. We will also demonstrate how an optimal selection of the solder thickness balances the damage types and considerably improves the useful lifetime. The established framework will set the stage for further exploration of electronic materials processing and offer a potential roadmap for new developments of such materials.","LEAD-FREE SOLDER,FATIGUE LIFE PREDICTION,THERMOMECHANICAL RELIABILITY,MECHANICAL-PROPERTIES,TEMPERATURE,BEHAVIOR,STRAIN,INTERCONNECTS,OPTIMIZATION,DEGRADATION",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,5.134,"LEAD-FREE,SOLDER,FATIGUE,LIFE,PREDICTION,THERMOMECHANICAL,RELIABILITY,MECHANICAL-PROPERTIES,TEMPERATURE,BEHAVIOR,STRAIN,INTERCONNECTS,OPTIMIZATION,DEGRADATION",SCIENTIFIC REPORTS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7481227,
42,Enabling intelligent Mg-sheet processing utilizing efficient machine-learning algorithm,794,,,"Shariati Mohamadreza,Weber Wolfgang E.,Bohlen Jan,Kurz Gerrit,Letzig Dietmar,Hoeche Daniel","Shariati M,Weber WE,Bohlen J,Kurz G,Letzig D,Hoche D",Shariati M,10.1016/j.msea.2020.139846,Helmut Schmidt University,"Process - property relationship control during magnesium sheet manufacturing is demanding due to the complexity of involved physical parameters and the sensitivity of the system to small changes. Here, data science might help to extract crucial information on interdependencies between processing parameters and sheet quality. In this paper we suggest a dedicated machine learning framework, which enables the possibility of correlating material property determining concepts such as pole figure to processing parameters, namely temperature and deformation degree without knowledge on prior dependencies of physical variables. Despite the impacts that using a relatively small data set can have, for Mg-AZ31 alloy we show that some projections of crystallographic texture can be reliably predicted from mechanical measurement data set. In general, the framework is useful for those processing parameters, which conventionally can be represented by a mathematical basis in the context of interpolation. In the future with access to more data it is proposed that applying our approach might allow predicting and controlling in-situ the rolling process route.","Machine learning,Property correlation,Mg-sheet processing,Twin-roll casting,Rolling",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Science & Technology - Other Topics,Materials Science,Metallurgy & Metallurgical Engineering",,5.266,"MECHANICAL-PROPERTIES,STRIP,MICROSTRUCTURE,REDUCTION",MATERIALS SCIENCE AND ENGINEERING A-STRUCTURAL MATERIALS PROPERTIES MICROSTRUCTURE AND PROCESSING,,
43,Prediction of Later-Age Concrete Compressive Strength Using Feedforward Neural Network,2020,,,"Nguyen Thuy-Anh,Ly Hai-Bang,Mai Hai-Van Thi,Tran Van Quan","Nguyen TA,Ly HB,Mai HVT,Tran V",Mai HVT,10.1155/2020/9682740,"Univ Transport Technol, Hanoi 100000, Vietnam.","Accurate prediction of the concrete compressive strength is an important task that helps to avoid costly and time-consuming experiments. Notably, the determination of the later-age concrete compressive strength is more difficult due to the time required to perform experiments. Therefore, predicting the compressive strength of later-age concrete is crucial in specific applications. In this investigation, an approach using a feedforward neural network (FNN) machine learning algorithm was proposed to predict the compressive strength of later-age concrete. The proposed model was fully evaluated in terms of performance and prediction capability over statistical results of 1000 simulations under a random sampling effect. The results showed that the proposed algorithm was an excellent predictor and might be useful for engineers to avoid time-consuming experiments with the statistical performance indicators, namely, the Pearson correlation coefficient (R), root-mean-squared error (RMSE), and mean squared error (MAE) for the training and testing parts of 0.9861, 2.1501, 1.5650 and 0.9792, 2.8510, 2.1361, respectively. The results also indicated that the FNN model was superior to classical machine learning algorithms such as random forest and Gaussian process regression, as well as empirical formulations proposed in the literature.","INCLUDING THERMODYNAMIC-EQUILIBRIUM,KINETIC CONTROL,SURFACE COMPLEXATION,FIRE RESISTANCE,TRANSPORT,DESIGN",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Materials Science,,1.94,"INCLUDING,THERMODYNAMIC-EQUILIBRIUM,KINETIC,CONTROL,SURFACE,COMPLEXATION,FIRE,RESISTANCE,TRANSPORT,DESIGN",ADVANCES IN MATERIALS SCIENCE AND ENGINEERING,https://downloads.hindawi.com/journals/amse/2020/9682740.pdf,
44,Machine learning of synaptic structure with neurons to promote tumor growth,41,11,1697-1706,"Wang Erhui,Zhang Xuelan,Zheng Liancun,Shu Chang","Wang ER,Zhang XL,Zheng LC,Shu C",Zheng LC,10.1007/s10483-020-2656-8,University of Science & Technology Beijing,"In this paper, we use machine learning techniques to form a cancer cell model that displays the growth and promotion of synaptic and electrical signals. Here, such a technique can be applied directly to the spiking neural network of cancer cell synapses. The results show that machine learning techniques for the spiked network of cancer cell synapses have the powerful function of neuron models and potential supervisors for different implementations. The changes in the neural activity of tumor microenvironment caused by synaptic and electrical signals are described. It can be used to cancer cells and tumor training processes of neural networks to reproduce complex spatiotemporal dynamics and to mechanize the association of excitatory synaptic structures which are between tumors and neurons in the brain with complex human health behaviors.","computational hemodynamics,electrodiffusive activity,complex synaptic dynamics,O241",Article,"SHANGHAI UNIV, 149 YANCHANG RD, SHANGHAI 200072, PEOPLES R CHINA","Mathematics,Mechanics",,2.341,"PLASTICITY,STATE",APPLIED MATHEMATICS AND MECHANICS-ENGLISH EDITION,,
45,Generative multi-adversarial network for striking the right balance in abdominal image segmentation,15,11,1847-1858,"Rezaei Mina,Nappi Janne J.,Lippert Christoph,Meinel Christoph,Yoshida Hiroyuki","Rezaei M,Nappi JJ,Lippert C,Meinel C,Yoshida H",Rezaei M,10.1007/s11548-020-02254-4,University of Potsdam,"PurposeThe identification of abnormalities that are relatively rare within otherwise normal anatomy is a major challenge for deep learning in the semantic segmentation of medical images. The small number of samples of the minority classes in the training data makes the learning of optimal classification challenging, while the more frequently occurring samples of the majority class hamper the generalization of the classification boundary between infrequently occurring target objects and classes. In this paper, we developed a novel generative multi-adversarial network, called Ensemble-GAN, for mitigating this class imbalance problem in the semantic segmentation of abdominal images. MethodThe Ensemble-GAN framework is composed of a single-generator and a multi-discriminator variant for handling the class imbalance problem to provide a better generalization than existing approaches. The ensemble model aggregates the estimates of multiple models by training from different initializations and losses from various subsets of the training data. The single generator network analyzes the input image as a condition to predict a corresponding semantic segmentation image by use of feedback from the ensemble of discriminator networks. To evaluate the framework, we trained our framework on two public datasets, with different imbalance ratios and imaging modalities: the Chaos 2019 and the LiTS 2017. ResultIn terms of the F1 score, the accuracies of the semantic segmentation of healthy spleen, liver, and left and right kidneys were 0.93, 0.96, 0.90 and 0.94, respectively. The overall F1 scores for simultaneous segmentation of the lesions and liver were 0.83 and 0.94, respectively. ConclusionThe proposed Ensemble-GAN framework demonstrated outstanding performance in the semantic segmentation of medical images in comparison with other approaches on popular abdominal imaging benchmarks. The Ensemble-GAN has the potential to segment abdominal images more accurately than human experts.","Imbalanced learning,Generative multi-discriminative networks,Semantic segmentation,Abdominal imaging",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,,INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7603459,
46,Mining the Correlations Between Optical Micrographs and Mechanical Properties of Cold-Rolled HSLA Steels Using Machine Learning Approaches,9,3,240-256,"Yucel Berkay,Yucel Sezen,Ray Arunim,Duprez Lode,Kalidindi Surya R.","Yucel B,Yucel S,Ray A,Duprez L,Kalidindi SR",Kalidindi SR,10.1007/s40192-020-00183-3,University System of Georgia,"This paper demonstrates the feasibility of extracting quantitative linkages between optical micrographs and mechanical properties of cold-rolled HSLA (high-strength low alloy) steels measured in standardized tension tests. These linkages were established by bringing together modern toolsets for (i) image segmentation, (ii) rigorous statistical quantification of segmented microstructures, (iii) low-dimensional representation of microstructure statistics, and (iv) building surrogate models using emergent machine learning approaches. A salient aspect of the overall approach presented in this paper is that the extracted linkages exhibited remarkable predictive accuracy while utilizing only three features identified objectively (i.e., unsupervised) in the proposed overall workflow.","Segmentation,Microstructure quantification,Structure-property linkage,Machine learning",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Materials Science",,4.423,"GAUSSIAN,PROCESS,REGRESSION,CONVOLUTIONAL,NEURAL-NETWORKS,PRINCIPAL,COMPONENT,ANALYSIS,SCIENCE,APPROACH,APPLICATION,MATERIALS,KNOWLEDGE,SYSTEM,SPHERICAL,INDENTATION,LINKAGES,MICROSTRUCTURE,SIZE,QUANTIFICATION",INTEGRATING MATERIALS AND MANUFACTURING INNOVATION,,
47,"Database of Two-Dimensional Hybrid Perovskite Materials: Open-Access Collection of Crystal Structures, Band Gaps, and Atomic Partial Charges Predicted by Machine Learning",32,17,7383-7388,"Marchenko Ekaterina I,Fateev Sergey A.,Petrov Andrey A.,Korolev Vadim V.,Mitrofanov Artem,Petrov Andrey V,Goodilin Eugene A.,Tarasov Alexey B.","Marchenko EI,Fateev SA,Petrov AA,Korolev VV,Mitrofanov A,Petrov AV,Goodilin EA,Tarasov AB",Tarasov AB,10.1021/acs.chemmater.0c02290,Lomonosov Moscow State University,"We describe a first open-access database of experimentally investigated hybrid organic-inorganic materials with a two-dimensional (2D) perovskite-like crystal structure. The database includes 515 compounds, containing 180 different organic cations, 10 metals (Pb, Sn, Bi, Cd, Cu, Fe, Ge, Mn, Pd, and Sb) and 3 halogens (I, Br, and Cl) known so far and will be regularly updated. The database contains a geometrical and crystal chemical analysis of the structures, which are useful for revealing quantitative structure-property relationships for this class of compounds. We show that the penetration depth of the spacer organic cation into the inorganic layer and M-X-M bond angles increase in the number of inorganic layers (n). The machine learning model is developed and trained on the database for the prediction of a band gap with accuracy within 0.1 eV. Another machine learning model is trained for the prediction of atomic partial charges with accuracy within 0.01 e. We show that the predicted values of band gaps decrease with an increase of n and with an increase of M-X-M angles for single-layered perovskites. In general, the proposed database and machine learning models are shown to be useful tools for the rational design of new 2D hybrid perovskite materials.",SOLIDS,Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Materials Science",,10.837,SOLIDS,CHEMISTRY OF MATERIALS,http://arxiv.org/pdf/2006.14302,
48,Casimir effect with machine learning,2,3,,"Chernodub M. N.,Erbin Harold,Grishmanovskii I. V,Goy V. A.,Molochkov A. V","Chernodub MN,Erbin H,Grishmanovskii IV,Goy VA,Molochkov AV",Chernodub MN,10.1103/PhysRevResearch.2.033375,Universite Confederale Leonard de Vinci,"Vacuum fluctuations of quantum fields between physical objects depend on the shapes, positions, and internal composition of the latter. For objects of arbitrary shapes, even made from idealized materials, the calculation of the associated zero-point (Casimir) energy is an analytically intractable challenge. We propose a different numerical approach to this problem based on machine-learning techniques and illustrate the effectiveness of the method in a (2+1)-dimensional scalar field theory. The Casimir energy is first calculated numerically using a Monte Carlo algorithm for a set of the Dirichlet boundaries of various shapes. Then, a neural network is trained to compute this energy given the Dirichlet domain, treating the latter as black-and-white pixelated images. We show that after the learning phase, the neural network is able to quickly predict the Casimir energy for new boundaries of general shapes with reasonable accuracy.","PHASE-TRANSITIONS,QUANTUM,ENERGIES,VACUUM",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,,"PHASE-TRANSITIONS,QUANTUM,ENERGIES,VACUUM",PHYSICAL REVIEW RESEARCH,http://link.aps.org/pdf/10.1103/PhysRevResearch.2.033375,
49,Automated segmentation of computed tomography images of fiber-reinforced composites by deep learning,55,34,16273-16289,"Badran Aly,Marshall David,Legault Zacharie,Makovetsky Ruslana,Provencher Benjamin,Piche Nicolas,Marsh Mike","Badran A,Marshall D,Legault Z,Makovetsky R,Provencher B,Piche N,Marsh M",Badran A,10.1007/s10853-020-05148-7,University of Colorado System,"A deep learning procedure has been examined for automatic segmentation of 3D tomography images from fiber-reinforced ceramic composites consisting of fibers and matrix of the same material (SiC), and thus identical image intensities. The analysis uses a neural network to distinguish phases from shape and edge information rather than intensity differences. It was used successfully to segment phases in a unidirectional composite that also had a coating with similar image intensity. It was also used to segment matrix cracks generated during in situ tensile loading of the composite and thereby demonstrate the influence of nonuniform fiber distribution on the nature of matrix cracking. By avoiding the need for manual segmentation of thousands of image slices, the procedure overcomes a major impediment to the extraction of quantitative information from such images. The analysis was performed using recently developed software that provides a general framework for executing both training and inference. Graphic abstract","DAMAGE,CRACKING",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Materials Science,,3.69,"DAMAGE,CRACKING",JOURNAL OF MATERIALS SCIENCE,,
50,Universal Patterns in Color-Emotion Associations Are Further Shaped by Linguistic and Geographic Proximity,31,10,1245-1260,"Jonauskaite Domicele,Abu-Akel Ahmad,Dael Nele,Oberfeld Daniel,Abdel-Khalek Ahmed M.,Al-Rasheed Abdulrahman S.,Antonietti Jean-Philippe,Bogushevskaya Victoria,Chamseddine Amer,Chkonia Eka","Jonauskaite D,Abu-Akel A,Dael N,Oberfeld D,Abdel-Khalek AM,Al-Rasheed AS,Antonietti JP,Bogushevskaya V,Chamseddine A,Chkonia E",Jonauskaite D,10.1177/0956797620948810,University of Lausanne,"Many of us ""see red,"" ""feel blue,"" or ""turn green with envy."" Are such color-emotion associations fundamental to our shared cognitive architecture, or are they cultural creations learned through our languages and traditions? To answer these questions, we tested emotional associations of colors in 4,598 participants from 30 nations speaking 22 native languages. Participants associated 20 emotion concepts with 12 color terms. Pattern-similarity analyses revealed universal color-emotion associations (average similarity coefficientr= .88). However, local differences were also apparent. A machine-learning algorithm revealed that nation predicted color-emotion associations above and beyond those observed universally. Similarity was greater when nations were linguistically or geographically close. This study highlights robust universal color-emotion associations, further modulated by linguistic and geographic factors. These results pose further theoretical and empirical questions about the affective properties of color and may inform practice in applied domains, such as well-being and design.","affect,color perception,cross-cultural,universality,cultural relativity,pattern analysis,open data,open materials",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA",Psychology,,8.902,"LANGUAGES,MEANINGS,RED",PSYCHOLOGICAL SCIENCE,https://serval.unil.ch/resource/serval:BIB_DF45797C8FB8.P001/REF.pdf,
51,Distinguishing Epileptiform Discharges From Normal Electroencephalograms Using Scale-Dependent Lyapunov Exponent,8,,,"Li Qiong,Gao Jianbo,Huang Qi,Wu Yuan,Xu Bo","Li Q,Gao JB,Huang Q,Wu Y,Xu B",Gao JB,10.3389/fbioe.2020.01006,Beijing Normal University,"Epileptiform discharges are of fundamental importance in understanding the physiology of epilepsy. To aid in the clinical diagnosis, classification, prognosis, and treatment of epilepsy, it is important to develop automated computer programs to distinguish epileptiform discharges from normal electroencephalogram (EEG). This is a challenging task as clinically used scalp EEG often contains a lot of noise and motion artifacts. The challenge is even greater if one wishes to develop explainable rather than black-box based approaches. To take on this challenge, we propose to use a multiscale complexity measure, the scale-dependent Lyapunov exponent (SDLE). We analyzed 640 multi-channel EEG segments, each 4slong. Among these segments, 540 are short epileptiform discharges, and 100 are from healthy controls. We found that features from SDLE were very effective in distinguishing epileptiform discharges from normal EEG. Using Random Forest Classifier (RF) and Support Vector Machines (SVM), the proposed approach with different features from SDLE robustly achieves an accuracy exceeding 99% in distinguishing epileptiform discharges from normal control ones. A single parameter, which is the ratio of the spectral energy of EEG signals and the SDLE and quantifies the regularity or predictability of the EEG signals, is introduced to better understand the high accuracy in the classification. It is found that this regularity is considerably greater for epileptiform discharges than for normal controls. Robustly having high accuracy in distinguishing epileptiform discharges from normal controls irrespective of which classification scheme being used, the proposed approach has the potential to be used widely in a clinical setting.","EEG,epileptiform discharges,power spectral density (PSD),scale-dependent Lyapunov exponent (SDLE),random forest classifier,support vector machine (SVM)",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND","Biotechnology & Applied Microbiology,Science & Technology - Other Topics",,5.973,"DIRECT,DYNAMICAL,TEST,PERMUTATION,ENTROPY,SEIZURE,DETECTION,EEG,EPILEPSY,CLASSIFICATION,NETWORKS,SYSTEM,CHAOS",FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY,https://www.frontiersin.org/articles/10.3389/fbioe.2020.01006/pdf,
52,Orbital graph convolutional neural network for material property prediction,4,9,,"Karamad Mohammadreza,Magar Rishikesh,Shi Yuting,Siahrostami Samira,Gates Ian D.,Farimani Amir Barati","Karamad M,Magar R,Shi YT,Siahrostami S,Gates ID,Farimani AB",Farimani AB,10.1103/PhysRevMaterials.4.093801,Carnegie Mellon University,"Material representations that are compatible with machine learning models play a key role in developing models that exhibit high accuracy for property prediction. Atomic orbital interactions are one of the important factors that govern the properties of crystalline materials from which the local chemical environments of atoms is inferred. Therefore, to develop robust machine learning models for material properties prediction, it is imperative to include features representing such chemical attributes. Here, we propose the orbital graph convolutional neural network (OGCNN), a crystal graph convolutional neural network framework that includes atomic orbital interaction features that learns material properties in a robust way. In addition, we embedded an encoder-decoder network into the OGCNN enabling it to learn important features among basic atomic (elemental features), orbital-orbital interactions, and topological features. We examined the performance of this model on a broad range of crystalline materials data to predict different properties. We benchmarked the performance of the OGCNN model with that of: (1) the crystal graph convolutional neural network, (2) other state-of-the-art descriptors for material representations including many-body tensor representation and the smooth overlap of atomic positions, and (3) other conventional regression machine learning algorithms where different crystal featurization methods have been used. We find that the OGCNN significantly outperforms them. The OGCNN model with high predictive accuracy can be used to discover new materials among the immense phase and compound spaces of materials.",,Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Materials Science,,4.034,,PHYSICAL REVIEW MATERIALS,http://arxiv.org/pdf/2008.06415,
53,Water pipe failure prediction using AutoML,39,1-2,36-49,"Zhang Cheng,Ye Zehao","Zhang C,Ye ZH",Zhang C,10.1108/F-08-2019-0084,Xi'an Jiaotong-Liverpool University,"Purpose Owing to the consumption of considerable resources in developing physical pipe prediction models and the fact that the statistical models cannot fit the failure records perfectly, the purpose of this paper is to use data mining method to analyze and predict the risks of water pipe failure via considering attributes and location of pipes in historical failure records. One of the Automatized Machine Learning (AutoML) methods, tree-based pipeline optimization technique (TPOT) was used as the key data mining technique in this research. Design/methodology/approach By considering pipeline attributes, environmental factors and historical pipeline broke/breaks records, a water pipeline failure prediction method is proposed in this research. Regression analysis, genetic algorithm, machine learning, data mining approaches are used to analyze and predict the probability of pipeline failure. TPOT was used as the key data mining technique. A case study was carried out in a specific area in China to investigate the relationships between pipeline broke/breaks and relevant parameters, such as pipeline age, materials, diameter, pipeline density and so on. Findings By integrating the prediction models for individual pipelines and small research regions, a prediction model is developed to describe the probability of water pipe failures and validated by real data. A high fitting degree is achieved, which means a good potential of using the proposed method in reality as a guideline for identifying areas with high risks and taking proactive measures and optimizing the resources allocation for water supply companies. Originality/value Different models are developed to have better prediction on regional or individual pipeline. A comparison between the predicted values with real records has shown that a preliminary model has a good potential in predicting the future failure risks.","Performance,Artificial intelligence,Modeling,Assessment",Article,"EMERALD GROUP PUBLISHING LTD, HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND",Business & Economics,,,"DETERIORATION,MODELS,RATES",FACILITIES,,
54,Artificial Intelligence Applications for Friction Stir Welding: A Review,27,2,193-219,"Eren Berkay,Guvenc Mehmet Ali,Mistikoglu Selcuk","Eren B,Guvenc MA,Mistikoglu S",Mistikoglu S,10.1007/s12540-020-00854-y,Iskenderun Technical University,"Advances in artificial intelligence (AI) techniques that can be used for different purposes have enabled it to be used in many different industrial applications. These are mainly used for modeling, identification, optimization, prediction and control of complex systems under the influence of more than one parameter in industrial applications. With the increasing accuracy of AI techniques, it has also obtained a wide application area on friction stir welding (FSW), one of the production methods developed in recent years. In this study, commonly used AI techniques for FSW, results, accuracy and superiority of AI techniques are reviewed and evaluated. In addition, an overview of AI techniques for FSW in different material combinations is provided. Considering the articles examined; It is seen that welding speed, rotational speed, the plunge depth, spindle torque, shoulder design, base material, pin design/profile, tool type are used as input parameters and tensile strength, yield strength, elongation, hardness, wear rate, welding quality, residual stress, fatigue strength are used as output parameters. As can be seen from the studies, it made important contributions in deciding what input parameters should be in order to have the output parameter at the desired value. The most common used materials for FSW are Al, Ti, Mg, Brass, Cu and so on. When FSW studies using artificial intelligence techniques were examined, it was seen that 81% of the most used materials were AL alloys and 23% of them were made with dissimilar materials. The most commonly utilized AI techniques were said to be artificial neural networks (ANN), fuzzy logic, machine learning, meta-heuristic methods and hybrid systems. As a result of the examination, ANN was the most widely used method among these methods. However, in recent years, with the exploration of new hybrid methods it was seen that hybrid systems used with ANN have higher accuracy.","Friction stir welding (FSW),Artificial intelligence,Machine learning,Prediction,Optimization",Review,"KOREAN INST METALS MATERIALS, KIM BLDG 6TH FLOOR, SEOCHO-DAERO 56 GIL 38, SEOCHO-GU, SEOUL 137-881, SOUTH KOREA","Materials Science,Metallurgy & Metallurgical Engineering",,2.541,"NEURAL-NETWORK,MECHANICAL-PROPERTIES,TENSILE-STRENGTH,ALUMINUM-ALLOY,PROCESS,PARAMETERS,FUZZY,CONTROLLER,FAULT-DIAGNOSIS,MAGNESIUM,ALLOY,MULTIOBJECTIVE,OPTIMIZATION,GENETIC,ALGORITHM",METALS AND MATERIALS INTERNATIONAL,,
55,Construction and verification of retinal vessel segmentation algorithm for color fundus image under BP neural network model,77,4,3870-3884,"Tang Siyuan,Yu Feifei","Tang SY,Yu FF",Yu FF,10.1007/s11227-020-03422-8,Shaoxing University,"To improve the accuracy of retinal vessel segmentation, a retinal vessel segmentation algorithm for color fundus images based on back-propagation (BP) neural network is proposed according to the characteristics of retinal blood vessels. Four kinds of green channel image enhancement results of adaptive histogram equalization, morphological processing, Gaussian matched filtering, and Hessian matrix filtering are used to form feature vectors. The BP neural network is input to segment blood vessels. Experiments on the color fundus image libraries DRIVE and STARE show that this algorithm can obtain complete retinal blood vessel segmentation as well as connected vessel stems and terminals. When segmenting most small blood vessels, the average accuracy on the DRIVE library reaches 0.9477, and the average accuracy on the STARE library reaches 0.9498, which has a good segmentation effect. Through verification, the algorithm is feasible and effective for blood vessel segmentation of color fundus images and can detect more capillaries.","BP neural network model,Color fundus image,Retinal vessel segmentation algorithm,Gaussian matched filtering,Hessian matrix",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.344,,JOURNAL OF SUPERCOMPUTING,,
56,Machine Learning-Based Detection of Graphene Defects with Atomic Precision,12,1,,"Zheng Bowen,Gu Grace X.","Zheng BW,Gu GX",Gu GX,10.1007/s40820-020-00519-w,University of California System,"Defects in graphene can profoundly impact its extraordinary properties, ultimately influencing the performances of graphene-based nanodevices. Methods to detect defects with atomic resolution in graphene can be technically demanding and involve complex sample preparations. An alternative approach is to observe the thermal vibration properties of the graphene sheet, which reflects defect information but in an implicit fashion. Machine learning, an emerging data-driven approach that offers solutions to learning hidden patterns from complex data, has been extensively applied in material design and discovery problems. In this paper, we propose a machine learning-based approach to detect graphene defects by discovering the hidden correlation between defect locations and thermal vibration features. Two prediction strategies are developed: an atom-based method which constructs data by atom indices, and a domain-based method which constructs data by domain discretization. Results show that while the atom-based method is capable of detecting a single-atom vacancy, the domain-based method can detect an unknown number of multiple vacancies up to atomic precision. Both methods can achieve approximately a 90% prediction accuracy on the reserved data for testing, indicating a promising extrapolation into unseen future graphene configurations. The proposed strategy offers promising solutions for the non-destructive evaluation of nanomaterials and accelerates new material discoveries.","Machine learning,Graphene,Defects,Molecular dynamics,Nanomaterials",Article,"SHANGHAI JIAO TONG UNIV PRESS, SHANGHAI JIAO TONG UNIV, 800 DONGCHUAN RD, SHANGHAI, 200240, PEOPLES R CHINA","Science & Technology - Other Topics,Materials Science,Physics",,14.248,"VIBRATION,ANALYSIS,THERMAL-PROPERTIES,LAYER,GRAPHENE,STRENGTH,SHEETS,SUPERCAPACITOR",NANO-MICRO LETTERS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7770819,
57,Structure determines where crystallization occurs in a soft colloidal glass,17,1,,"Ganapathi Divya,Chakrabarti Dibyashree,Sood A. K.,Ganapathy Rajesh","Ganapathi D,Chakrabarti D,Sood AK,Ganapathy R",Ganapathi D,10.1038/s41567-020-1016-4,Indian Institute of Science (IISC) - Bangalore,"Softness, a machine-learned structural quantity, has been recently identified as a parameter that characterizes glassy dynamics. Here, the authors observe devitrification in 3D soft colloidal glasses and find that softness may indicate regions predisposed to crystallization.
Glass is inherently unstable to crystallization. However, how this transformation occurs while the dynamics in the glass stay frozen at the particle scale is poorly understood. Here, through single-particle-resolved imaging experiments, we show that due to frozen-in density inhomogeneities, a soft colloidal glass crystallizes via two distinct pathways. In the poorly packed regions of the glass, crystallinity grew smoothly due to local particle shuffles, whereas in the well-packed regions, we observed abrupt jumps in crystallinity that were triggered by avalanches-cooperative rearrangements involving many tens of particles. Importantly, we show that softness-a structural-order parameter determined through machine-learning methods-not only predicts where crystallization initiates in a glass but is also sensitive to the crystallization pathway. Such a causal connection between the structure and stability of a glass has so far remained elusive. Devising strategies to manipulate softness may thus prove invaluable in realizing long-lived glassy states.","NUCLEATION,TRANSITION",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Physics,,22.85,"NUCLEATION,TRANSITION",NATURE PHYSICS,,
58,Navigating the design space of inorganic materials synthesis using statistical methods and machine learning,49,33,11480-11488,"Braham Erick J.,Davidson Rachel D.,Al-Hashimi Mohammed,Arroyave Raymundo,Banerjee Sarbajit","Braham EJ,Davidson RD,Al-Hashimi M,Arroyave R,Banerjee S",Banerjee S,10.1039/d0dt02028a,Texas A&M University System,"Data-driven approaches have brought about a revolution in manufacturing; however, challenges persist in their applications to synthetic strategies. Their application to the deterministic navigation of reaction trajectories to stabilize crystalline solids with precise composition, atomic connectivity, microstructural dimensionality, and surface structure remains a frontier in inorganic materials research. The design of synthetic methodologies for the preparation of inorganic materials is often inefficient in terms of exploration of potentially vast design spaces spanning multiple process variables, reaction sequences, as well as structural parameters and reactivities of precursors and structure-directing agents. Reported synthetic methods are further limited in terms of the insight they provide into underlying chemical and physical principles. The recent surge in interest in accelerating the discovery of new materials can be considered as an opportunity to re-evaluate our approach to materials synthesis, and for considering new frameworks for exploration that are systematic and strategic in approach. Herein, we outline with the help of several illustrative examples, the challenges, opportunities, and limitations of data-driven synthesis design. The account collates discussion of design-of-experiments sampling methods, machine learning modeling, and active learning to develop experimental workflows that accelerate the experimental navigation of synthetic landscapes.","DRIVEN EXPERIMENTAL-DESIGN,GOLD NANORODS,GROWTH,NANOPARTICLES,OPTIMIZATION,DISCOVERY",Review,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND",Chemistry,,4.07,"DRIVEN,EXPERIMENTAL-DESIGN,GOLD,NANORODS,GROWTH,NANOPARTICLES,OPTIMIZATION,DISCOVERY",DALTON TRANSACTIONS,,
59,The reduction of(176)Lu background in Lu-based PET scanners using optimized classification,65,17,,"Wang Qian,Mikhaylova Ekaterina,Baikejiang Reheman,Cherry Simon R.","Wang Q,Mikhaylova E,Baikejiang R,Cherry SR",Wang Q,10.1088/1361-6560/aba088,University of California System,"Positron emission tomography (PET) using scanners incorporating lutetium-based (Lu-based) scintillators are widely used in nuclear medicine. However their application in imaging very low (<100 kBq) activity distributions is quite limited due to the intrinsic(176)Lu radiation emitted from the scintillators. To visualize very low activities,Lu-176 background needs to be reduced or removed. This study proposes a classification method to select background coincidences from true coincidences arising from the source by supervised learning using the optimal classifier as determined by investigating 5 different classifiers: logistic regression, support vector machine, random forest, extreme gradient boosting (XGBoost) and deep neural network. Five energy and time-of-flight (TOF) related features from each coincidence event are extracted to form the training and test set in the classification. The proposed method was verified on a pair of TOF-PET detector modules. Since the measured source coincidences cannot be differentiated from the background events experimentally, simulated source coincidences are used to train the classification model. The simulated feature spectra are therefore compared with those obtained from measurement to verify the feasibility of classifying measured coincidences using a model learned by simulation. XGBoost classifier performed most effectively in classifying the coincidences and provided impressively high classification accuracy (>99%). It was subsequently tested by imaging point-like source, planar Derenzo and bar phantoms with the pair of TOF-PET detectors. An 89.4% image contrast enhancement for the Derenzo phantom at an activity concentration of 100 Bq mm(-2), and a 52.4% peak-to-valley ratio improvement across the area of bar phantom at a concentration of 25 Bq mm(-2), were observed on the reconstructed images with XGBoost classification applied. The proposed method could extend the usage of Lu-based PET scanners to very low activity detection and imaging and has the potential to be used in a variety of molecular imaging tasks to detect low-level signals.","intrinsic background reduction,Lu-based PET scanner,classification method",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,,"LU-176,GATE",PHYSICS IN MEDICINE AND BIOLOGY,,
60,Improving depth-of-interaction resolution in pixellated PET detectors using neural networks,65,17,,"Zatcepin Artem,Pizzichemi Marco,Polesel Andrea,Paganoni Marco,Auffray Etiennette,Ziegler Sibylle I,Omidvari Negar","Zatcepin A,Pizzichemi M,Polesel A,Paganoni M,Auffray E,Ziegler SI,Omidvari N",Zatcepin A,10.1088/1361-6560/ab9efc,Technical University of Munich,"Parallax error is a common issue in high-resolution preclinical positron emission tomography (PET) scanners as well as in clinical scanners that have a long axial field of view (FOV), which increases estimation uncertainty of the annihilation position and therefore degrades the spatial resolution. A way to address this issue is depth-of-interaction (DOI) estimation. In this work we propose two machine learning-based algorithms, a dense and a convolutional neural network (NN), as well as a multiple linear regression (MLR)-based method to estimate DOI in depolished PET detector arrays with single-sided readout. The algorithms were tested on an 8x 8 array of 1.53x 1.53x 15 mm(3)crystals and a 4x 4 array of 3.1x 3.1x 15 mm(3)crystals, both made of Ce:LYSO scintillators and coupled to a 4x 4 array of 3x 3 mm(3)silicon photomultipliers (SiPMs). Using the conventional linear DOI estimation method resulted in an average DOI resolution of 3.76 mm and 3.51 mm FWHM for the 8x 8 and the 4x 4 arrays, respectively. Application of MLR outperformed the conventional method with average DOI resolutions of 3.25 mm and 3.33 mm FWHM, respectively. Using the machine learning approaches further improved the DOI resolution, to an average DOI resolution of 2.99 mm and 3.14 mm FWHM, respectively, and additionally improved the uniformity of the DOI resolution in both arrays. Lastly, preliminary results obtained by using only a section of the crystal array for training showed that the NN-based methods could be used to reduce the number of calibration steps required for each detector array.","positron emission tomography (PET),depth of interaction (DOI),PET detectors,DOI detectors,small-animal PET,machine learning,neural networks",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,,"PULSE-SHAPE,DISCRIMINATION,TRIPLE,COINCIDENCES,CRYSTAL,ARRAY,DESIGN,TOF,PERFORMANCE,RECOVERY,READOUT,SCANNER,BLOCKS",PHYSICS IN MEDICINE AND BIOLOGY,http://cds.cern.ch/record/2729450/files/10.1088_1361-6560_ab9efc.pdf,
61,Recognition of Respiratory Dysfunctions Using Algorithm-Assisted Portable Airflow Sensors,9,11,,"Jhunjhunwala Megha,Lin Hui-Ling,Li Geng-Yue,Chen Chi-Shuo","Jhunjhunwala M,Lin HL,Li GY,Chen CS",Chen CS,10.1149/2162-8777/abb3b0,National Tsing Hua University,"Respiratory diseases are becoming a severe health threat. To prevent exacerbation with early diagnosis, there is an urgent need for developing a respiratory function assay with ease of access. Tidal breathing pattern reflects a combination of the existing lung condition and the physiological demand. However, the interpretations of breath pattern remain underexplored. In this study, lung simulator with various pathological parameters was used to reconstruct the breath pattern of patients with chronic obstructive pulmonary disease (COPD) and interstitial lung disease (ILD). Breath pattern was recorded using two flow sensors. Three machine learning algorithms, including convolutional neural network (CNN), long short-term memory (LSTM) and support vector machine (SVM), were applied for disease identification. Results showed algorithmic analysis can achieve over 80% accuracy, and two levels of obstructive severity of COPD can be determined. With the assistance of algorithms, similar results can be obtained using a portable sensor. In contrast to the heavy professional and complex equipment requirement of the current methods, this proof-of concept method shows the potential of using a low-cost portable sensor for respiratory function monitoring. This approach can provide a basis for preliminary diagnosis, and may further contribute to point of care testing for respiratory health. (C) 2020 The Author(s). Published on behalf of The Electrochemical Society by IOP Publishing Limited.","LUNG,FREQUENCY",Article,"ELECTROCHEMICAL SOC INC, 65 SOUTH MAIN STREET, PENNINGTON, NJ 08534 USA","Materials Science,Physics",,2.016,"LUNG,FREQUENCY",ECS JOURNAL OF SOLID STATE SCIENCE AND TECHNOLOGY,https://doi.org/10.1149/2162-8777/abb3b0,
62,Pendant drop tensiometry: A machine learning approach,153,9,,"Kratz Felix S.,Kierfeld Jan","Kratz FS,Kierfeld J",Kierfeld J,10.1063/5.0018814,Dortmund University of Technology,"Modern pendant drop tensiometry relies on the numerical solution of the Young-Laplace equation and allows us to determine the surface tension from a single picture of a pendant drop with high precision. Most of these techniques solve the Young-Laplace equation many times over to find the material parameters that provide a fit to a supplied image of a real droplet. Here, we introduce a machine learning approach to solve this problem in a computationally more efficient way. We train a deep neural network to determine the surface tension of a given droplet shape using a large training set of numerically generated droplet shapes. We show that the deep learning approach is superior to the current state of the art shape fitting approach in speed and precision, in particular if shapes in the training set reflect the sensitivity of the droplet shape with respect to surface tension. In order to derive such an optimized training set, we clarify the role of the Worthington number as a quality indicator in conventional shape fitting and in the machine learning approach. Our approach demonstrates the capabilities of deep neural networks in the material parameter determination from rheological deformation experiments, in general.","SURFACE-TENSION,INTERFACIAL-TENSION,SHAPE,WEIGHT,VOLUME",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Chemistry,Physics",,3.166,"SURFACE-TENSION,INTERFACIAL-TENSION,SHAPE,WEIGHT,VOLUME",JOURNAL OF CHEMICAL PHYSICS,http://arxiv.org/pdf/2006.10111,
63,Multi-slice representational learning of convolutional neural network for Alzheimer's disease classification using positron emission tomography,19,1,,"Kim Han Woong,Lee Ha Eun,Oh KyeongTaek,Lee Sangwon,Yun Mijin,Yoo Sun K.","Kim HW,Lee HE,Oh K,Lee S,Yun M,Yoo SK",Yoo SK,10.1186/s12938-020-00813-z,Yonsei University,"Background Alzheimer's Disease (AD) is a degenerative brain disorder that often occurs in people over 65 years old. As advanced AD is difficult to manage, accurate diagnosis of the disorder is critical. Previous studies have revealed effective deep learning methods of classification. However, deep learning methods require a large number of image datasets. Moreover, medical images are affected by various environmental factors. In the current study, we propose a deep learning-based method for diagnosis of Alzheimer's disease (AD) that is less sensitive to different datasets for external validation, based upon F-18 fluorodeoxyglucose positron emission tomography/computed tomography (FDG-PET/CT). Results The accuracy, sensitivity, and specificity of our proposed network were 86.09%, 80.00%, and 92.96% (respectively) using our dataset, and 91.02%, 87.93%, and 93.57% (respectively) using the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. We observed that our model classified AD and normal cognitive (NC) cases based on the posterior cingulate cortex (PCC), where pathological changes occur in AD. The performance of the GAP layer was considered statistically significant compared to the fully connected layer in both datasets for accuracy, sensitivity, and specificity (p < 0.01). In addition, performance comparison between the ADNI dataset and our dataset showed no statistically significant differences in accuracy, sensitivity, and specificity (p > 0.05). Conclusions The proposed model demonstrated the effectiveness of AD classification using the GAP layer. Our model learned the AD features from PCC in both the ADNI and Severance datasets, which can be seen in the heatmap. Furthermore, we showed that there were no significant differences in performance using statistical analysis.","Alzheimer's disease,F-18 FDG-PET,CT,Deep learning,Convolutional neural network,External validation,Feasibility study",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Engineering,,,"PET,DIAGNOSIS",BIOMEDICAL ENGINEERING ONLINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7487538,
64,AI on a chip,20,17,3074-3090,"Isozaki Akihiro,Harmon Jeffrey,Zhou Yuqi,Li Shuai,Nakagawa Yuta,Hayashi Mika,Mikami Hideharu,Lei Cheng,Goda Keisuke","Isozaki A,Harmon J,Zhou YQ,Li S,Nakagawa Y,Hayashi M,Mikami H,Lei C,Goda K",Goda K,10.1039/d0lc00521e,University of Tokyo,"Artificial intelligence (AI) has dramatically changed the landscape of science, industry, defence, and medicine in the last several years. Supported by considerably enhanced computational power and cloud storage, the field of AI has shifted from mostly theoretical studies in the discipline of computer science to diverse real-life applications such as drug design, material discovery, speech recognition, self-driving cars, advertising, finance, medical imaging, and astronomical observation, where AI-produced outcomes have been proven to be comparable or even superior to the performance of human experts. In these applications, what is essentially important for the development of AI is the data needed for machine learning. Despite its prominent importance, the very first process of the AI development, namely data collection and data preparation, is typically the most laborious task and is often a limiting factor of constructing functional AI algorithms. Lab-on-a-chip technology, in particular microfluidics, is a powerful platform for both the construction and implementation of AI in a large-scale, cost-effective, highthroughput, automated, and multiplexed manner, thereby overcoming the above bottleneck. On this platform, high-throughput imaging is a critical tool as it can generate high-content information (e.g., size, shape, structure, composition, interaction) of objects on a large scale. High-throughput imaging can also be paired with sorting and DNA/RNA sequencing to conduct a massive survey of phenotype-genotype relations whose data is too complex to analyze with traditional computational tools, but is analyzable with the power of AI. In addition to its function as a data provider, lab-on-a-chip technology can also be employed to implement the developed AI for accurate identification, characterization, classification, and prediction of objects in mixed, heterogeneous, or unknown samples. In this review article, motivated by the excellent synergy between AI and lab-on-a-chip technology, we outline fundamental elements, recent advances, future challenges, and emerging opportunities of AI with lab-on-a-chip technology or ""AI on a chip"" for short.","IMAGING FLOW-CYTOMETRY,HIGH-THROUGHPUT,TIME-STRETCH,LABEL-FREE,SINGLE-CELL,FLUORESCENCE MICROSCOPY,MACHINE VISION,DEEP,SPEED,CLASSIFICATION",Review,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Biochemistry & Molecular Biology,Chemistry,Science & Technology - Other Topics,Instruments & Instrumentation",,7.379,"IMAGING,FLOW-CYTOMETRY,HIGH-THROUGHPUT,TIME-STRETCH,LABEL-FREE,SINGLE-CELL,FLUORESCENCE,MICROSCOPY,MACHINE,VISION,DEEP,SPEED,CLASSIFICATION",LAB ON A CHIP,,
65,Robustness study of noisy annotation in deep learning based medical image segmentation,65,17,,"Yu Shaode,Chen Mingli,Zhang Erlei,Wu Junjie,Yu Hang,Yang Zi,Ma Lin,Gu Xuejun,Lu Weiguo","Yu SD,Chen ML,Zhang EL,Wu JJ,Yu H,Yang Z,Ma L,Gu XJ,Lu WG",Gu XJ; Lu WG,10.1088/1361-6560/ab99e5,University of Texas System,"Partly due to the use of exhaustive-annotated data, deep networks have achieved impressive performance on medical image segmentation. Medical imaging data paired with noisy annotation are, however, ubiquitous, but little is known about the effect of noisy annotation on deep learning based medical image segmentation. We studied the effect of noisy annotation in the context of mandible segmentation from CT images. First, 202 images of head and neck cancer patients were collected from our clinical database, where the organs-at-risk were annotated by one of twelve planning dosimetrists. The mandibles were roughly annotated as the planning avoiding structure. Then, mandible labels were checked and corrected by a head and neck specialist to get the reference standard. At last, by varying the ratios of noisy labels in the training set, deep networks were trained and tested for mandible segmentation. The trained models were further tested on other two public datasets. Experimental results indicated that the network trained with noisy labels had worse segmentation than that trained with reference standard, and in general, fewer noisy labels led to better performance. When using 20% or less noisy cases for training, no significant difference was found on the segmentation results between the models trained by noisy or reference annotation. Cross-dataset validation results verified that the models trained with noisy data achieved competitive performance to that trained with reference standard. This study suggests that the involved network is robust to noisy annotation to some extent in mandible segmentation from CT images. It also highlights the importance of labeling quality in deep learning. In the future work, extra attention should be paid to how to utilize a small number of reference standard samples to improve the performance of deep learning with noisy annotation.","deep learning,noisy annotation,radiation oncology,medical image segmentation",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,,PHYSICS IN MEDICINE AND BIOLOGY,http://arxiv.org/pdf/2003.06240,
66,Humanistic interpretation and machine learning,,,,"Paakkonen Juho,Ylikoski Petri","Paakkonen J,Ylikoski P",Paakkonen J,10.1007/s11229-020-02806-w,University of Helsinki,"This paper investigates how unsupervised machine learning methods might make hermeneutic interpretive text analysis more objective in the social sciences. Through a close examination of the uses of topic modeling-a popular unsupervised approach in the social sciences-it argues that the primary way in which unsupervised learning supports interpretation is by allowing interpreters to discover unanticipated information in larger and more diverse corpora and by improving the transparency of the interpretive process. This view highlights that unsupervised modeling does not eliminate the researchers' judgments from the process of producing evidence for social scientific theories. The paper shows this by distinguishing between two prevalent attitudes toward topic modeling, i.e., topic realism and topic instrumentalism. Under neither can modeling provide social scientific evidence without the researchers' interpretive engagement with the original text materials. Thus the unsupervised text analysis cannot improve the objectivity of interpretation by alleviating the problem of underdetermination in interpretive debate. The paper argues that the sense in which unsupervised methods can improve objectivity is by providing researchers with the resources to justify to others that their interpretations are correct. This kind of objectivity seeks to reduce suspicions in collective debate that interpretations are the products of arbitrary processes influenced by the researchers' idiosyncratic decisions or starting points. The paper discusses this view in relation to alternative approaches to formalizing interpretation and identifies several limitations on what unsupervised learning can be expected to achieve in terms of supporting interpretive work.","Humanistic interpretation,Topic modeling,Machine learning,Objectivity,Text analytics,Latent Dirichlet allocation",Article; Early Access,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","History & Philosophy of Science,Philosophy",,2.296,"TOPIC,MODELS,POTENTIAL,INTERRELATION,BIG,DATA,SOCIAL-SCIENCE,OF-SCIENCE,R,PACKAGE,TEXT,PERSPECTIVE,PHILOSOPHY,HUMANITIES",SYNTHESE,https://research.aalto.fi/files/56836330/P_kk_nen_Ylikoski2020_Article_HumanisticInterpretationAndMac.pdf,
67,Detection and classification of electroencephalogram signals for epilepsy disease using machine learning methods,31,2,729-740,"Srinath Rajagopalan,Gayathri Rajagopal","Srinath R,Gayathri R",Srinath R,10.1002/ima.22486,Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology,"The electroencephalogram (EEG) signal plays a key role in the diagnosis of epilepsy. This study describes an automated classification of EEG signal for the detection of Epilepsy disease using soft computing methods. The proposed method is comprised of three modules: (a) transformation, (b) feature computation, and (c) feature classifications. In the first module, the nonsubsampled contourlet transform is applied on the EEG signal which decomposes the signal into approximate and directional subbands. The decomposition is done using nonsubsampled pyramid filter bank and nonsubsampled directional filter bank respectively. Secondly, the statistical features are extracted from the decomposed directional subbands using wavelet packet decomposition method. Finally, these features are classified by adaptive neuro-Fuzzy inference system classification method, which classifies the EEG signal into either focal or nonfocal signal. The proposed method is tested on a set of EEG signals for validation. The average classification rate of the proposed EEG signal classification system is 99.4%. The proposed EEG signal classification methodology achieves a sensitivity of 99.7%, a specificity of 99.7%, and an accuracy of 99.4%. The results confirmed that the proposed method has a potential in the classification of EEG signals and thereby could further improve the diagnosis of epilepsy.","ANFIS,EEG,epilepsy diagnosis,NSCT,soft computing",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,IDENTIFICATION,INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
68,Accurate prediction of binding energies for two-dimensional catalytic materials using machine learning,12,20,5109-5120,"Melisande Fischer Julia,Hunter Michelle,Hankel Marlies,Searles Debra J.,Parker Amanda J.,Barnard Amanda S.","Fischer JM,Hunter M,Hankel M,Searles DJ,Parker AJ,Barnard AS",Barnard AS,10.1002/cctc.202000536,Australian National University,"The binding energy of small molecules on two-dimensional (2D) single atom catalysts influences their reaction efficiency and suitability for different applications. In this study, the binding energy on single metal atoms to N-doped graphene defects was predicted using random forest regression based on approximately 1700 previously generated density functional theory simulations of catalytic reactions. Three different structural feature groups containing hundreds of individual structural features were created and used to characterise the active sites. This approach was found to be accurate and reliable using either fully relaxed output structures or pre-simulation input structures, with coefficients of determination ofR2=0.952 andR2=0.865, respectively. The ability to predict optimal 2D-catalysts before undertaking expensive quantum chemical calculations is an attractive basis for future research, and could be extended to other 2D-materials.","molecular topology,feature engineering,single atom catalysts,random forest regression,graphene defects",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Chemistry,,5.329,"SINGLE-ATOM,CATALYSTS,DENSITY-FUNCTIONAL,THEORY,ELECTRONIC-PROPERTIES,DESIGN",CHEMCATCHEM,https://openresearch-repository.anu.edu.au/bitstream/1885/219502/1/ChemCatChem%2012%20%282020%29%205109.pdf,
69,Classification of COVID-19 in chest X-ray images using DeTraC deep convolutional neural network,51,2,854-864,"Abbas Asmaa,Abdelsamea Mohammed M.,Gaber Mohamed Medhat","Abbas A,Abdelsamea MM,Gaber MM",Abdelsamea MM,10.1007/s10489-020-01829-7,Egyptian Knowledge Bank (EKB),"Chest X-ray is the first imaging technique that plays an important role in the diagnosis of COVID-19 disease. Due to the high availability of large-scale annotated image datasets, great success has been achieved using convolutional neural networks (CNNs) for image recognition and classification. However, due to the limited availability of annotated medical images, the classification of medical images remains the biggest challenge in medical diagnosis. Thanks to transfer learning, an effective mechanism that can provide a promising solution by transferring knowledge from generic object recognition tasks to domain-specific tasks. In this paper, we validate and a deepCNN, called Decompose, Transfer, and Compose (DeTraC), for the classification of COVID-19 chest X-ray images.DeTraCcan deal with any irregularities in the image dataset by investigating its class boundaries using a class decomposition mechanism. The experimental results showed the capability ofDeTraCin the detection of COVID-19 cases from a comprehensive image dataset collected from several hospitals around the world. High accuracy of 93.1% (with a sensitivity of 100%) was achieved byDeTraCin the detection of COVID-19 X-ray images from normal, and severe acute respiratory syndrome cases.","DeTraC,Covolutional neural networks,COVID-19 detection,Chest X-ray images,Data irregularities",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,4.602,,APPLIED INTELLIGENCE,http://www.open-access.bcu.ac.uk/9856/1/Abbas2020_Article_ClassificationOfCOVID-19InChes.pdf,
70,Artificial intelligence-enabled smart mechanical metamaterials: advent and future trends,66,6,365-393,"Jiao Pengcheng,Alavi Amir H.","Jiao PC,Alavi AH",Jiao PC,10.1080/09506608.2020.1815394,Zhejiang University,"Mechanical metamaterials have opened an exciting venue for control and manipulation of architected structures in recent years. Research in the area of mechanical metamaterials has covered many of their fabrication, mechanism characterisation and application aspects. More recently, however, a paradigm shift has emerged to an exciting research direction towards designing, optimising and characterising mechanical metamaterials using artificial intelligence (AI) techniques. This new line of research aims at addressing the difficulties in mechanical metamaterials (i.e. design, analysis, fabrication and industrial application). This review article discusses the advent and development of mechanical metamaterials, and the future trends of applying AI to obtain smart mechanical metamaterials with programmable mechanical response. We explainwhyarchitected materials and structures have prominent advantages,whatare the main challenges in the mechanical metamaterial research domain, andhowto surpass the limit of mechanical metamaterials via the AI techniques. We finally envision the potential research avenues and emerging trends for using the AI-enabled mechanical metamaterials for future innovations.","Mechanical metamaterials,artificial intelligence,machine learning",Review,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Materials Science,,23.0,"NEGATIVE,POISSONS,RATIO,DATA,MINING,TECHNIQUES,NEURAL-NETWORKS,MATERIALS,DISCOVERY,GENETIC,ALGORITHM,MATERIALS,SCIENCE,MATERIALS,INFORMATICS,RELIABILITY-ANALYSIS,COMPOSITE-MATERIALS,DESIGN",INTERNATIONAL MATERIALS REVIEWS,https://www.tandfonline.com/doi/pdf/10.1080/09506608.2020.1815394?needAccess=true,
71,Image classification-based brain tumour tissue segmentation,80,1,993-1008,"Al-qazzaz Salma,Sun Xianfang,Yang Hong,Yang Yingxia,Xu Ronghua,Nokes Len,Yang Xin","Al-qazzaz S,Sun XF,Yang H,Yang YX,Xu RH,Nokes L,Yang X",Yang X,10.1007/s11042-020-09661-4,Cardiff University,"Brain tumour tissue segmentation is essential for clinical decision making. While manual segmentation is time consuming, tedious, and subjective, it is very challenging to develop automatic segmentation methods. Deep learning with convolutional neural network (CNN) architecture has consistently outperformed previous methods on such challenging tasks. However, the local dependencies of pixel classes cannot be fully reflected in the CNN models. In contrast, hand-crafted features such as histogram-based texture features provide robust feature descriptors of local pixel dependencies. In this paper, a classification-based method for automatic brain tumour tissue segmentation is proposed using combined CNN-based and hand-crafted features. The CIFAR network is modified to extract CNN-based features, and histogram-based texture features are fused to compensate the limitation in the CIFAR network. These features together with the pixel intensities of the original MRI images are sent to a decision tree for classifying the MRI image voxels into different types of tumour tissues. The method is evaluated on the BraTS 2017 dataset. Experiments show that the proposed method produces promising segmentation results.","Brain tumour segmentation,Multi-modal MRI,Convolutional neural networks,Decision tree",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"CONVOLUTIONAL,NEURAL-NETWORKS",MULTIMEDIA TOOLS AND APPLICATIONS,https://link.springer.com/content/pdf/10.1007/s11042-020-09661-4.pdf,
72,Detection and diagnosis of brain tumors-framework using extreme machine learning and CANFIS classification algorithms,31,2,540-547,"Jeevanantham V.,MohanBabu G.","Jeevanantham V,MohanBabu G",Jeevanantham V,10.1002/ima.22479,"SSM Inst Engn & Technol, Fac Elect & Commun Engn, Dindigul, India.","In this paper, brain tumors are detected and diagnosed using machine learning approaches in brain magnetic resonance imaging (MRI), which has many real time clinical applications. Noise variations in brain images are detected and removed using index filter, which is proposed in this paper. Brain images devoid of noise content are in spatial domain format, which are not suitable for further feature extraction process. Hence, there is a need for converting all the spatial pixels into multi orientation pixels. In this paper, Gabor transform is used for spatial into multi oriented image conversion. The noise filtered images are transformed into multi orientation-based brain image using Gabor transform method. Then, the hybrid features which are the integration of statistical and texture features (GLCM, gray level co-occurrence matrix, and LDP, local derivative pattern), are computed from this transformed brain image. These computed features are classified using extreme machine learning (EML) approach, which categorizes the source brain image as normal or abnormal. Then, the segmented tumor regions are diagnosed using co-active adaptive neuro fuzzy inference system (CANFIS) classifier, which classifies the segmented regions as mild or severe. The proposed tumor detection and diagnosis methods are applied and tested on the brain images which are available as open access dataset. The performance of the proposed brain tumor detection method is analyzed in terms of sensitivity, specificity, and accuracy with classification rate.","brain,features,machine learning,transforms,tumors",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,,INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
73,Detection and classification of breast cancer from digital mammograms using hybrid extreme learning machine classifier,31,2,909-920,"Melekoodappattu Jayesh George,Subbian Perumal Sankar,Queen M. P. Flower","Melekoodappattu JG,Subbian PS,Queen MPF",Melekoodappattu JG,10.1002/ima.22484,"Vimal Jyothi Engn Coll, Dept Elect & Commun Engn, Kannur, Kerala, India.","Breast imaging technique called mammography has gained bigger attention among the researchers for the diagnosis of breast malignancy in the woman. Mammogram screening is the most effective procedure to visualize various potential problems in the breast. The two most common features connected with breast tumors are mass lesions and microcalcification. The collection of suitable image preprocessing, segmentation, feature extraction, selection and prediction algorithms play an essential role in the accurate detection and classification of cancer on mammograms. Classification techniques estimate unlabeled datasets class labeling depending on its similarity to the pattern learned. The Glowworm Swarm Optimization(GSO) algorithm is ideal for finding several solutions, and dissimilar or equivalent objective function values at the same time. This feature of GSO is useful for optimizing the feature set obtained from multiscale feature extraction procedures. Poor performance in generalization is the issue that arises due to the unconditioned output matrix of the hidden stage of the ELM classifier. The optimization algorithms will address this matter because of their global search capabilities. This article suggests ELM with the Fruitfly Optimization Algorithm (ELM-FOA) along with GSO to regulate the input weight to achieve maximal performance at the hidden node of the ELM. The testing precision and sensitivity of GSO-ELM-FOA are 100% and 97.91%, respectively. The system developed will detect the calcifications and tumors with an accuracy of 99.15%.","accuracy,CAD,classification,ELM,FOA,GSO,mammogram,optimization",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,"COMPUTER-AIDED,DETECTION,SYSTEM",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
74,Identifying domains of applicability of machine learning models for materials science,11,1,,"Sutton Christopher,Boley Mario,Ghiringhelli Luca M.,Rupp Matthias,Vreeken Jilles,Scheffler Matthias","Sutton C,Boley M,Ghiringhelli LM,Rupp M,Vreeken J,Scheffler M",Sutton C; Ghiringhelli LM,10.1038/s41467-020-17112-9,Max Planck Society,"Although machine learning (ML) models promise to substantially accelerate the discovery of novel materials, their performance is often still insufficient to draw reliable conclusions. Improved ML models are therefore actively researched, but their design is currently guided mainly by monitoring the average model test error. This can render different models indistinguishable although their performance differs substantially across materials, or it can make a model appear generally insufficient while it actually works well in specific sub-domains. Here, we present a method, based on subgroup discovery, for detecting domains of applicability (DA) of models within a materials class. The utility of this approach is demonstrated by analyzing three state-of-the-art ML models for predicting the formation energy of transparent conducting oxides. We find that, despite having a mutually indistinguishable and unsatisfactory average error, the models have DAs with distinctive features and notably improved performance. Machine learning models insufficient for certain screening tasks can still provide valuable predictions in specific sub-domains of the considered materials. Here, the authors introduce a diagnostic tool to detect regions of low expected model error as demonstrated for the case of transparent conducting oxides.","THIN-FILM TRANSISTORS,SUBGROUP DISCOVERY,TRANSPARENT",Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Science & Technology - Other Topics,,15.805,"THIN-FILM,TRANSISTORS,SUBGROUP,DISCOVERY,TRANSPARENT",NATURE COMMUNICATIONS,https://pure.mpg.de/pubman/item/item_3164134_7/component/file_3164135/manuscript.domain_of_app.pdf,
75,Human activity detection using machine learning methods from wearable sensors,40,5,591-603,"Randhawa Princy,Shanthagiri Vijay,Kumar Ajay,Yadav Vinod","Randhawa P,Shanthagiri V,Kumar A,Yadav V",Yadav V,10.1108/SR-02-2020-0027,Manipal University Jaipur,"Purpose The paper aims to develop a novel method for the classification of different physical activities of a human being, using fabric sensors. This method focuses mainly on classifying the physical activity between normal action and violent attack on a victim and verifies its validity. Design/methodology/approach The system is realized as a protective jacket that can be worn by the subject. Stretch sensors, pressure sensors and a 9 degree of freedom accelerometer are strategically woven on the jacket. The jacket has an internal bus system made of conductive fabric that connects the sensors to the Flora chip, which acts as the data acquisition unit for the data generated. Different activities such as still, standing up, walking, twist-jump-turn, dancing and violent action are performed. The jacket in this study is worn by a healthy subject. The main phases which describe the activity recognition method undertaken in this study are the placement of sensors, pre-processing of data and deploying machine learning models for classification. Findings The effectiveness of the method was validated in a controlled environment. Certain challenges are also faced in building the experimental setup for the collection of data from the hardware. The most tedious challenge is to collect the data without noise and error, created by voltage fluctuations when stretched. The results show that the support vector machine classifier can classify different activities and is able to differentiate normal action and violent attacks with an accuracy of 98.8%, which is superior to other methods and algorithms. Practical implications This study leads to an understanding of human physical movement under violent activity. The results show that data compared with normal physical motion, which includes even a form of dance is quite different from the data collected during violent physical motion. This jacket construction with woven sensors can capture every dimension of the physical motion adding features to the data on which the machine learning model will be built. Originality/value Unlike other studies, where sensors are placed on isolated parts of the body, in this study, the fabric sensors are woven into the fabric itself to collect the data and to achieve maximum accuracy instead of using isolated wearable sensors. This method, together with a fabric pressure and stretch sensors, can provide key data and accurate feedback information when the victim is being attacked or is in a normal state of action.","Activity recognition,Wearable sensors,Fabric sensors,Women safety,Decision tree,Classifier,SVM classifier",Article,"EMERALD GROUP PUBLISHING LTD, HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND",Instruments & Instrumentation,,1.674,"HUMAN,ACTIVITY,RECOGNITION,ACCELEROMETER,CLASSIFICATION,MULTISENSOR,DESIGN",SENSOR REVIEW,,
76,A Novel MEGNet for Classification of High-Frequency Oscillations in Magnetoencephalography of Epileptic Patients,2020,,,"Liu Jun,Sun Siqi,Liu Yang,Guo Jiayang,Li Hailong,Gao Yuan,Sun Jintao,Xiang Jing","Liu J,Sun SQ,Liu Y,Guo JY,Li HL,Gao Y,Sun JT,Xiang J",Sun SQ,10.1155/2020/9237808,Wuhan Institute of Technology,"Epilepsy is a neurological disease, and the location of a lesion before neurosurgery or invasive intracranial electroencephalography (iEEG) surgery using intracranial electrodes is often very challenging. The high-frequency oscillation (HFOs) mode in MEG signal can now be used to detect lesions. Due to the time-consuming and error-prone operation of HFOs detection, an automatic HFOs detector with high accuracy is very necessary in modern medicine. Therefore, an optimized capsule neural network was used, and a MEG (magnetoencephalograph) HFOs detector based on MEGNet was proposed to facilitate the clinical detection of HFOs. To the best of our knowledge, this is the first time that a neural network has been used to detect HFOs in MEG. After optimized configuration, the accuracy, precision, recall, and F1-score of the proposed detector reached 94%, 95%, 94%, and 94%, which were better than other classical machine learning models. In addition, we used the k-fold cross-validation scheme to test the performance consistency of the model. The distribution of various performance indicators shows that our model is robust.","FAST RIPPLES,HFOS,PRECISION,RECALL",Article,"WILEY-HINDAWI, ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND","Mathematics,Science & Technology - Other Topics",,2.8,"FAST,RIPPLES,HFOS,PRECISION,RECALL",COMPLEXITY,https://downloads.hindawi.com/journals/complexity/2020/9237808.pdf,
77,Quantitative ultrasound delta-radiomics during radiotherapy for monitoring treatment responses in head and neck malignancies,6,9,,"Tran William T.,Suraweera Harini,Quiaoit Karina,DiCenzo Daniel,Fatima Kashuf,Jang Deok,Bhardwaj Divya,Kolios Christopher,Karam Irene,Poon Ian","Tran WT,Suraweera H,Quiaoit K,DiCenzo D,Fatima K,Jang D,Bhardwaj D,Kolios C,Karam I,Poon I",Czarnota GJ,10.2144/fsoa-2020-0073,University of Toronto,"Aim:We investigated quantitative ultrasound (QUS) in patients with node-positive head and neck malignancies for monitoring responses to radical radiotherapy (RT).Materials & methods:QUS spectral and texture parameters were acquired from metastatic lymph nodes 24 h, 1 and 4 weeks after starting RT.K-nearest neighbor and naive-Bayes machine-learning classifiers were used to build prediction models for each time point. Response was detected after 3 months of RT, and patients were classified into complete and partial responders.Results:Single-feature naive-Bayes classification performed best with a prediction accuracy of 80, 86 and 85% at 24 h, week 1 and 4, respectively.Conclusion:QUS-radiomics can predict RT response at 3 months as early as 24 h with reasonable accuracy, which further improves into 1 week of treatment.
Lay abstract: Patients with head and neck cancer are often treated with radiation, which usually spans over 6-7 weeks. The response is usually measured 3 months after treatment completion. In this study, we had performed ultrasound scans from the patient's neck node during radiation treatment (after 24 h, 1 and 4 weeks). Artificial intelligence was used to interpret the ultrasound imaging and predict the response to radiation at the end of 3 months. The scans obtained after the first week were able to predict the treatment response with reasonable accuracy (86%).","biomarker,delta-radiomics,head and neck cancer,imaging,machine Learning,quantitative ultrasound,radiomics,radiotherapy,response,texture",Article,"FUTURE SCI LTD, UNITED HOUSE, 2 ALBERT PL, LONDON, N3 1QB, ENGLAND",Research & Experimental Medicine,,,"QUALITY-OF-LIFE,TUMOR,RESPONSE,CANCER,THERAPY,ATTENUATION,CHEMOTHERAPY,PREDICTION,FEATURES,APOPTOSIS,CRITERIA",FUTURE SCIENCE OA,,
78,,,,,,,,,,,,,,,,,,,,
79,CNN-based framework using spatial dropping for enhanced interpretation of neural activity in motor imagery classification.,7,1,8,",,,,","Collazos-Huertas D F,Alvarez-Meza A M,Acosta-Medina C D,Castano-Duque G A,Castellanos-Dominguez G",,10.1186/s40708-020-00110-4,,,Convolutional Neural Networks; Motor imagery; Spatial dropping,Journal Article,,,,,,,,
80,Machine-learning strategies for testing patterns of morphological variation in small samples: sexual dimorphism in gray wolf (Canis lupus) crania,18,1,,"MacLeod Norman,Kolska Horwitz Liora","MacLeod N,Horwitz LK",MacLeod N,10.1186/s12915-020-00832-1,Nanjing University,"Background Studies of mammalian sexual dimorphism have traditionally involved the measurement of selected dimensions of particular skeletal elements and use of single data-analysis procedures. Consequently, such studies have been limited by a variety of both practical and conceptual constraints. To compare and contrast what might be gained from a more exploratory, multifactorial approach to the quantitative assessment of form-variation, images of a small sample of modern Israeli gray wolf (Canis lupus) crania were analyzed via elliptical Fourier analysis of cranial outlines, a Naive Bayes machine-learning approach to the analysis of these same outline data, and a deep-learning analysis of whole images in which all aspects of these cranial morphologies were represented. The statistical significance and stability of each discriminant result were tested using bootstrap and jackknife procedures. Results Our results reveal no evidence for statistically significant sexual size dimorphism, but significant sex-mediated shape dimorphism. These are consistent with the findings of prior wolf sexual dimorphism studies and extend these studies by identifying new aspects of dimorphic variation. Additionally, our results suggest that shape-based sexual dimorphism in theC. lupuscranial complex may be more widespread morphologically than had been appreciated by previous researchers. Conclusion Our results suggest that size and shape dimorphism can be detected in small samples and may be dissociated in mammalian morphologies. This result is particularly noteworthy in that it implies there may be a need to refine allometric hypothesis tests that seek to account for phenotypic sexual dimorphism. The methods we employed in this investigation are fully generalizable and can be applied to a wide range of biological materials and could facilitate the rapid evaluation of a diverse array of morphological/phenomic hypotheses.","Carnivores,Morphometrics,Machine learning,Automated identification,Convolution neural networks,Ecomorphology,Shape analysis",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Life Sciences & Biomedicine - Other Topics,,,"BODY-SIZE,ALLOMETRY,SHAPE,WOLVES,WILD,SELECTION,SPECIALIZATION,MORPHOMETRICS,POPULATIONS,CARNIVORES",BMC BIOLOGY,https://bmcbiol.biomedcentral.com/track/pdf/10.1186/s12915-020-00832-1,
81,Non-rigid retinal image registration using an unsupervised structure-driven regression network,404,,14-25,"Zou Beiji,He Zhiyou,Zhao Rongchang,Zhu Chengzhang,Liao Wangmin,Li Shuo","Zou BJ,He ZY,Zhao RC,Zhu CZ,Liao WM,Li S",Zhao RC,10.1016/j.neucom.2020.04.122,Central South University,"Retinal image registration is clinically significant to help clinicians obtain more complete details of the retinal structure by correlating the properties of the retina. However, existing methods suffer from great challenges due to time-consuming optimization and lack of ground truth. In this paper, we propose an unsupervised learning framework for non-rigid retinal image registration, which directly learns the mapping from a retinal image pair to their corresponding deformation field without any supervision such as ground truth registration fields. Specifically, we formulate the complex mapping as a parameterized deformation function, which can be represented and optimized by a deep neural network. Furthermore, the Structure-Driven Regression Network (SDRN) framework is applied to compute the multi-scale similarity combined with contextual structures (e.g., vessel distribution, optic disk appearance, and edge information) to guide the end-to-end learning procedure more effectively with unlabeled data. Given a new pair of images, our method can quickly register images by directly evaluating the parametric function using the learned parameters, which runs faster than traditional registration algorithms. Experimental results, performed on the public challenging dataset (FIRE), show that our method achieves an average Dice similarity coefficient (DSC) of 0.753 with short execution times (0.021 s), which is more accurate and robust than existing approaches and promises to significantly speed up retinal image analysis and processing. (C) 2020 Elsevier B.V. All rights reserved.","Retinal image registration,Unsupervised learning,Convolution neural networks,Deformable registration",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"APPEARANCE,FRAMEWORK",NEUROCOMPUTING,,
82,Generating electrocardiogram signals by deep learning,404,,122-136,"Wulan Naren,Wang Wei,Sun Pengzhong,Wang Kuanquan,Xia Yong,Zhang Henggui","Wulan N,Wang W,Sun PZ,Wang KQ,Xia Y,Zhang HG",Wang W,10.1016/j.neucom.2020.04.076,Harbin Institute of Technology,"Given the importance of a diverse and vast amount of realistic and labeled electrocardiogram (ECG) signals in improving the performance of biomedical signal processing algorithms, and the situation of severe lack of the signals, three generative models based on deep learning are introduced for the generation of ECG signals: The WaveNet-based model, the SpectroGAN model, and the WaveletGAN model. The WaveNet-based model adopts mu-law companding transformation as a preprocessing method and then is followed by a sequence of convolutional layers with dilation; SpectroGAN and WaveletGAN use short-term Fourier transform (STFT) and stationary wavelet transform (SWT) respectively to obtain suitable input form for the generative adversarial networks (GAN). Our proposed models are capable of generating ECG signals containing three different heartbeat types: normal beat, left bundle branch block beat and right bundle branch block beat. The synthetic ECG signals generated by our models are more realistic since deep artificial neural networks can discover intricate structure and characteristics of real ECG signals instead of manually setting specific parameters for synthesis. Besides, ECG signals produced by one of our proposed models could be naturally continuous and be up to more than 20 seconds. Furthermore, we first provide an evaluation approach for quantitatively demonstrating the performance of ECG generative models. The study demonstrates that deep learning is a feasible and effective method for ECG generation. Our proposed ECG generative models can be utilized to assess biomedical signal processing algorithms so as to improve their performance in clinical trials. (C) 2020 Elsevier B.V. All rights reserved.","Deep learning,Evaluation approach,Generative model,Synthetic ECG,Short-term Fourier transform,Stationary wavelet transform,mu-Law companding transformation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"ATRIAL-FIBRILLATION,QUANTITATIVE-ANALYSIS,MODEL",NEUROCOMPUTING,,
83,Anharmonic free energy of lattice vibrations in fcc crystals from a mean-field bond,102,10,,"Swinburne Thomas D.,Janssen Jan,Todorova Mira,Simpson Gideon,Plechac Petr,Luskin Mitchell,Neugebauer Joerg","Swinburne TD,Janssen J,Todorova M,Simpson G,Plechac P,Luskin M,Neugebauer J",Swinburne TD,10.1103/PhysRevB.102.100101,Aix-Marseille Universite,"It has recently been shown that the ab initio anharmonic free energy of fcc crystals can be approximated to meV/atom accuracy by a lattice of anharmonic nearest-neighbor bonds, where the bonding potential can be efficiently parametrized from the target system. We develop a mean-field approach for the free energy of a general bond lattice, analytically accounting for strong bond-bond correlations while enforcing material compatibility and thermodynamic self-consistency. Applying our fundamentally anharmonic model to fcc crystals yields free energies within meV/atom of brute force thermodynamic integration for core seconds of computational effort. Potential applications of this approach in computational materials science are discussed.",,Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,,PHYSICAL REVIEW B,https://hal.archives-ouvertes.fr/hal-02929762/document,
84,Diagnosis of thyroid nodules for ultrasonographic characteristics indicative of malignancy using random forest,13,1,,"Chen Dan,Hu Jun,Zhu Mei,Tang Niansheng,Yang Yang,Feng Yuran","Chen D,Hu J,Zhu M,Tang NS,Yang Y,Feng YR",Hu J,10.1186/s13040-020-00223-w,Yunnan University,"Background Various combinations of ultrasonographic (US) characteristics are increasingly utilized to classify thyroid nodules. But they lack theories, and heavily depend on radiologists' experience, and cannot correctly classify thyroid nodules. Hence, our main purpose of this manuscript is to select the US characteristics significantly associated with malignancy and to develop an efficient scoring system for facilitating ultrasonic clinicians to correctly identify thyroid malignancy. Methods A logistic regression (LR) model is utilized to identify the potential thyroid malignancy, and the least absolute shrinkage and selection operator (LASSO) method is adopted to simultaneously select US characteristics significantly associated with malignancy and estimate parameters in LR model. Based on the selected US characteristics, we calculate the probability for each of thyroid nodules via random forest (RF) and extreme learning machine (ELM), and develop a scoring system to classify thyroid nodules. For comparison, we also consider eight state-of-the-art methods such as support vector machine (SVM), neural network (NET), etc. The area under the receiver operating characteristic curve (AUC) is employed to measure the accuracy of various classifiers. Results The US characteristics: nodule size, AP/T >= 1, solid component, micro-calcifications, hackly border, hypoechogenicity, presence of halo, unclear border, irregular margin, and central vascularity are selected as the significant predictors associated with thyroid malignancy via the LASSO LR (LLR). Using the developed scoring system, thyroid nodules are classified into the following four categories: benign, low suspicion, intermediate suspicion, and high suspicion, whose rates of malignancy correctly identified for RF (ELM) method on the testing dataset are 0.0% (4.3%), 14.3% (50.0%), 58.1% (59.1%) and 96.1% (97.7%), respectively. Conclusion LLR together with RF performs better than other methods in identifying malignancy, especially for abnormal nodules, in terms of risk scores. The developed scoring system can well predict the risk of malignancy and guide medical doctors to make management decisions for reducing the number of unnecessary biopsies for benign nodules.","Random forest,Risk score,Thyroid nodule,Ultrasonographic characteristic",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND",Mathematical & Computational Biology,,2.957,"DATA,SYSTEM,LOGISTIC,LASSO,ULTRASOUND,CANCER,MANAGEMENT,DIFFERENTIATION,ECHOGENICITY,REGRESSION,FEATURES,RISK",BIODATA MINING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7469308,
85,Mitigating effects of temperature variations through probabilistic-based machine learning for vibration-based bridge scour detection,10,5,957-972,"Zheng Wei,Qian Feng,Shen Jinlei,Xiao Feng","Zheng W,Qian F,Shen JL,Xiao F",Zheng W,10.1007/s13349-020-00427-y,Jackson State University,"This paper presents a novel approach to mitigating the effect of temperature variations on the bridges' dynamic modal properties for more reliably detecting scour damage around bridge piles based on the vibration-based measurements. The novelty of the presented approach lies in its ability to reasonably remove the impacts on the modal properties of bridges, particularly caused by changes in material properties and structural boundary conditions due to temperature variations without explicitly modeling these complex effects. The main idea is to adopt the probabilistic-based machine learning method, Gaussian Process Model, to learn the correlation between the changes of modal properties of a monitored bridge and the corresponding temperature variations from in situ sensor measurements, and probabilistically infer the bridge scour based on the modified vibration measurements, which have mitigated the identified impacts of temperature variations, by applying Bayesian inference through the Transitional Markov Chain Monte Carlo simulation. The proposed approach and its applicability are presented and validated through the numerical simulation of a prototype bridge, demonstrating its potential for practical application for mitigating effects of temperature variations or other environmental impacts for vibration-based Structural Health Monitoring. The limitation of the presented study and future research needs are also discussed.","Temperature effect,Scour damage,Damage identification,Informatics,Artificial intelligence,Machine learning,Gaussian process model,Bayesian inference,Sampling,TMCMC",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Engineering,,2.67,"MODELS,SELECTION",JOURNAL OF CIVIL STRUCTURAL HEALTH MONITORING,,
86,Causal Inference Machine Learning Leads Original Experimental Discovery in CdSe/CdS Core/Shell Nanoparticles,11,17,7232-7238,"Liu Rulin,Hao Junjie,Li Jiagen,Wang Shujie,Liu Haochen,Zhou Ziming,Delville Marie-Helene,Cheng Jiaji,Wang Kai,Zhu Xi","Liu RL,Hao JJ,Li JG,Wang SJ,Liu HC,Zhou ZM,Delville MH,Cheng JJ,Wang K,Zhu X",Zhu X,10.1021/acs.jpclett.0c02115,Chinese University of Hong Kong,"The synthesis of CdSe/CdS core/shell nanoparticles was revisited with the help of a causal inference machine learning framework. The tadpole morphology with 1-2 tails was experimentally discovered. The causal inference model revealed the causality between the oleic acid (OA), octadecylphosphonic acid (ODPA) ligands, and the detailed tail shape of the tadpole morphology. Further, with the identified causality, a neural network was provided to predict and directly lead to the original experimental discovery of new tadpole-shaped structures. An entropy-driven nucleation theory was developed to understand both the ligand and temperature dependent experimental data and the causal inference from the machine learning framework. This work provided a vivid example of how the artificial intelligence technology, including machine learning, could benefit the materials science research for the discovery.","DENSITY-FUNCTIONAL THEORY,SHAPE-CONTROLLED SYNTHESIS,AB-INITIO,SEMICONDUCTOR CLUSTERS,CRYSTAL-STRUCTURE,LIGAND-BINDING,SEEDED GROWTH,NANOCRYSTALS,CDS,1ST-PRINCIPLES",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,7.643,"DENSITY-FUNCTIONAL,THEORY,SHAPE-CONTROLLED,SYNTHESIS,AB-INITIO,SEMICONDUCTOR,CLUSTERS,CRYSTAL-STRUCTURE,LIGAND-BINDING,SEEDED,GROWTH,NANOCRYSTALS,CDS,1ST-PRINCIPLES",JOURNAL OF PHYSICAL CHEMISTRY LETTERS,https://hal.archives-ouvertes.fr/hal-02922356/document,
87,Impact of spatiotemporal land-use and land-cover changes on surface urban heat islands in a semiarid region using Landsat data,14,2,250-270,"Kamali Maskooni Ehsan,Hashemi Hossein,Berndtsson Ronny,Daneshkar Arasteh Peyman,Kazemi Mohammad","Maskooni EK,Hashemi H,Berndtsson R,Arasteh PD,Kazemi M",Maskooni EK,10.1080/17538947.2020.1813210,"Univ Hormozgan, Dept Watershed Management & Engn, Bandar Abbas, Iran.","Many factors are involved in urban heat island development, such as lack of green spaces, improper choice of building materials, densification, and other human activities. The aim of this research was to quantify the effects of land-use/land-cover (LU/LC) changes on urban land surface temperature (LST) during a 25-year period (1993-2018) for the semiarid Shiraz City in southern Iran using Landsat data (TM, ETM+, and OLI/TIRS) and machine learning algorithms. Five main LU/LC classes, such as orchard, vegetation, bare surface, asphalt cover, and built-up areas, were identified using a support vector machine algorithm. Landsat images were used to retrieve normalized difference vegetation index (NDVI) and normalized difference built-up index (NDBI). The results showed that the mean LST over the entire study domain increased considerably between 1993 and 2018, due to urbanization, decrease of green areas, and increasing industrial areas. Built-up areas increased considerably by 25.8% from 80 to 100.6 km(2)between 1993 and 2018, while vegetation cover decreased dramatically by 69.3%. Mean LST increased from 38.4 to 40.2 degrees C during the 25-year period with a significant increase of 3.9 degrees C between 2013 and 2018. In addition, the Urban heat island Ratio Index (URI) displayed a substantial upward trend during the 25-year period.","Urbanization,urban heat island,land use,land cover,semiarid,population density",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Physical Geography,Remote Sensing",,3.888,"TEMPERATURE,CITY,INDEX",INTERNATIONAL JOURNAL OF DIGITAL EARTH,https://www.tandfonline.com/doi/pdf/10.1080/17538947.2020.1813210?needAccess=true,
88,Remote diagnosis of diabetics patient through speech engine and fuzzy based machine learning algorithm,23,4,789-798,"Shankar G. Siva,Manikandan K.","Shankar GS,Manikandan K",Manikandan K,10.1007/s10772-020-09742-7,Vellore Institute of Technology,"As recent development of technology, it enables patients to get treatment remotely from doctors through audio conversation. The fourth highest number of death every year is caused by diabetics. Almost 50% to 80% of patients can avoid diabetics if the cause is found at the early stage. In this paper, we propose a new methodology to detect Diabetes at an early stage and recommend few attributes in which the patient needs to be careful in order to avoid diabetics. The proposed methodology makes use of fuzzy logic and kNN classifier to find out the caution attributes and recommends them as soon as possible. The proposed algorithm detects the audio signals from patients or clinical labs to process the data. We implemented our proposed methodology on Pima Indian dataset and compared with existing algorithms and the result shows that our algorithm outperforms existing algorithms.","Diabetes detection,Individual attribute,Fuzzy rules,kNN,Machine learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Engineering,,,,INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY,,
89,Wave-function positivization via automatic differentiation,2,3,,"Torlai Giacomo,Carrasquilla Juan,Fishman Matthew T.,Melko Roger G.,Fisher Matthew P. A.","Torlai G,Carrasquilla J,Fishman MT,Melko RG,Fisher MPA",Torlai G,10.1103/PhysRevResearch.2.032060,"Flatiron Inst, Ctr Computat Quantum Phys, New York, NY 10010 USA.","We introduce a procedure to systematically search for a local unitary transformation that maps a wave function with a nontrivial sign structure into a positive-real form. The transformation is parametrized as a quantum circuit compiled into a set of one- and two-qubit gates. We design a cost function that maximizes the average sign of the output state and removes its complex phases. The optimization of the gates is performed through automatic differentiation algorithms, widely used in the machine learning community. We provide numerical evidence for significant improvements in the average sign for a two-leg triangular Heisenberg ladder with next-to-nearest-neighbor and ring-exchange interactions. This model exhibits phases where the sign structure can be removed by simple local one-qubit unitaries, but also an exotic Bose-metal phase whose sign structure induces ""Bose surfaces"" with a fermionic character and a higher entanglement that requires deeper circuits.",,Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,,,PHYSICAL REVIEW RESEARCH,http://arxiv.org/pdf/1906.04654,
90,Recent Progress in Non-Precious Metal Single Atomic Catalysts for Solar and Non-Solar Driven Hydrogen Evolution Reaction,4,11,,"Liu Jing,Wu Hongmei,Li Feng,Feng Xiaoqian,Zhang Peng,Gao Lian","Liu J,Wu HM,Li F,Feng XQ,Zhang P,Gao L",Liu J; Zhang P; Gao L,10.1002/adsu.202000151,Shanghai Jiao Tong University,"It is of practical importance to develop efficient non-precious metal hydrogen-evolving catalysts for cost-effective sustainable hydrogen production from water. In recent years, constructing single-atomic catalysts (SACs) has been demonstrated to be an efficacious way to boost the catalytic activity of hydrogen evolution reaction (HER) catalysts, although most of them are based on noble metals. Very recently, great advances have been achieved in noble metal-free SACs by design of compatible material systems and implementation of novel synthetic strategies, which are determinative for the amount and pattern of metallic single atoms to be anchored on the supports and consequently the electronic states and coordination environment of the atoms. This progress report summarizes perspectives of compositions of the SACs with appropriate synthetic methods, and their relationships with the HER catalytic performance. In addition, some state-of-the-art technologies, for example, in situ techniques, high throughput techniques, and machine learning, are suggested to help the design, preparation, and characterization of SACs.","electrocatalysis,hydrogen evolution reaction,photocatalysis,single atomic catalysts",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Science & Technology - Other Topics,Materials Science",,6.434,"EFFICIENT,OXYGEN,REDUCTION,ACTIVE,EDGE,SITES,N-DOPED,CARBON,BIFUNCTIONAL,ELECTROCATALYSTS,ORGANIC,FRAMEWORKS,ELECTRON-TRANSFER,MOS2,NANOSHEETS,POROUS,CARBON,WATER,COBALT",ADVANCED SUSTAINABLE SYSTEMS,,
91,Autonomous pH control by reinforcement learning for electroplating industry wastewater,140,,,"Goulart Douglas Alves,Pereira Renato Dutra","Goulart DA,Pereira RD",Goulart DA,10.1016/j.compchemeng.2020.106909,Universidade Federal do Rio Grande,"The electroplating industry, due to steps such as pickling, generates acid pH wastewater. Its treatment is important for environmental preservation and the future recovery of metals. Therefore, the main objective of this work was the development of an autonomous pH controller for electroplating industry liquid effluents, based on fully automated Reinforcement Learning (RL). In order to do that, a Continuous Stirred-Tank Reactor (CSTR) neutralization simulator, and an adapted Particle Swarm Optimization (PSO) algorithm to automate the choice of RL hyperparameters were developed. The controller was developed and validated when it stabilized the effluent's pH in a neutral range in different scenarios during the regulatory and servo operations better than a Proportional Integral Derivative (PID) controller. The development of autonomous wastewater pH control systems in coated surface treatment units is a significant advancement, as it reduces human intervention and allows the monitoring of variability associated with the electroplating industry. (C) 2020 Elsevier Ltd. All rights reserved.","Machine learning,Actor-Critic,Metaheuristic optimization,Hyperparameters,Cloud computing",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering",,3.724,"PREDICTIVE,CONTROL",COMPUTERS & CHEMICAL ENGINEERING,,
92,A hierarchical constrained reinforcement learning for optimization of bitumen recovery rate in a primary separation vessel,140,,,"Shafi Hareem,Velswamy Kirubakaran,Ibrahim Fadi,Huang Biao","Shafi H,Velswamy K,Ibrahim F,Huang BA",Huang BA,10.1016/j.compchemeng.2020.106939,University of Alberta,"This work proposes a two-level hierarchical constrained control structure for reinforcement learning (RL) with application in a Primary Separation Vessel (PSV). The lower level is concerned with servo tracking and regulation of the interface level against variances in ore quality by manipulating middlings flow rate. At the higher level, with the objective to optimize bitumen recovery rate, a supervisory interface level setpoint control is implemented. To prevent sanding, tailings density regulation using tailings withdrawal flow rate is proposed. For each case, an asynchronous advantage actor-critic (A3C) based agent is chosen to interact with a high-fidelity PSV model to learn the near optimal control strategy through episodic interactions. Each of the three control loops is sequentially learnt. In the interface level control loop, a behavioral cloning based two-phase learning scheme to promote stable state space exploration is proposed. The proposed hierarchical structure successfully demonstrates improved bitumen recovery rate by manipulating the interface level while preventing sanding. (c) 2020 Elsevier Ltd. All rights reserved.","Primary separation vessel,Oil sands,Machine learning,Reinforcement learning,Process control",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering",,3.724,,COMPUTERS & CHEMICAL ENGINEERING,,
93,A Novel THz Differential Spectral Clustering Recognition Method Based on t-SNE,2020,,,"Li Tie-Jun,Chen Chih-Cheng,Liu Jian-jun,Shao Gui-fang,Chan Christopher Chun Ki","Li TJ,Chen CC,Liu JJ,Shao GF,Chan CCK",Chen CC,10.1155/2020/6787608,Jimei University,"We apply time-domain spectroscopy (THz) imaging technology to perform nondestructive detection on three industrial ceramic matrix composite (CMC) samples and one silicon slice with defects. In terms of spectrum recognition, a low-resolution THz spectrum image results in an ineffective recognition on sample defect features. Therefore, in this article, we propose a spectrum clustering recognition model based on t-distribution stochastic neighborhood embedding (t-SNE) to address this ineffective sample defect recognition. Firstly, we propose a model to recognize a reduced dimensional clustering of different spectrums drawn from the imaging spectrum data sets, in order to judge whether a sample includes a feature indicating a defect or not in a low-dimensional space. Second, we improve computation efficiency by mapping spectrum data samples from high-dimensional space to low-dimensional space by the use of a manifold learning algorithm (t-SNE). Finally, to achieve a visible observation of sample features in low-dimensional space, we use a conditional probability distribution to measure the distance invariant similarity. Comparative experiments indicate that our model can judge the existence of sample defect features or not through spectrum clustering, as a predetection process for image analysis.",REDUCTION,Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Mathematics,Science & Technology - Other Topics",,1.067,REDUCTION,DISCRETE DYNAMICS IN NATURE AND SOCIETY,https://downloads.hindawi.com/journals/ddns/2020/6787608.pdf,
94,Critical Review of Processing and Classification Techniques for Images and Spectra in Microplastic Research,74,9,989-1010,"Cowger Win,Gray Andrew,Christiansen Silke H.,DeFrond Hannah,Deshpande Ashok D.,Hemabessiere Ludovic,Lee Eunah,Mill Leonid,Munno Keenan);,Ossmann Barbara E.","Cowger W,Gray A,Christiansen SH,DeFrond H,Deshpande AD,Hemabessiere L,Lee E,Mill L,Munno K,Ossmann BE",Cowger W,10.1177/0003702820929064,University of California System,"Microplastic research is a rapidly developing field, with urgent needs for high throughput and automated analysis techniques. We conducted a review covering image analysis from optical microscopy, scanning electron microscopy, fluorescence microscopy, and spectral analysis from Fourier transform infrared (FT-IR) spectroscopy, Raman spectroscopy, pyrolysis gas-chromatography mass-spectrometry, and energy dispersive X-ray spectroscopy. These techniques were commonly used to collect, process, and interpret data from microplastic samples. This review outlined and critiques current approaches for analysis steps in image processing (color, thresholding, particle quantification), spectral processing (background and baseline subtraction, smoothing and noise reduction, data transformation), image classification (reference libraries, morphology, color, and fluorescence intensity), and spectral classification (reference libraries, matching procedures, and best practices for developing in-house reference tools). We highlighted opportunities to advance microplastic data analysis and interpretation by (i) quantifying colors, shapes, sizes, and surface topologies with image analysis software, (ii) identifying threshold values of particle characteristics in images that distinguish plastic particles from other particles, (iii) advancing spectral processing and classification routines, (iv) creating and sharing robust spectral libraries, (v) conducting double blind and negative controls, (vi) sharing raw data and analysis code, and (vii) leveraging readily available data to develop machine learning classification models. We identified analytical needs that we could fill and developed supplementary information for a reference library of plastic images and spectra, a tutorial for basic image analysis, and a code to download images from peer reviewed literature. Our major findings were that research on microplastics was progressing toward the use of multiple analytical methods and increasingly incorporating chemical classification. We suggest that new and repurposed methods need to be developed for high throughput screening using a diversity of approaches and highlight machine learning as one potential avenue toward this capability.","Microplastic,gas chromatography-mass spectrometry,GC-MS,fluorescence,microscopy,high throughput,automation,Fourier transform infrared,FT-IR,plastic,image analysis,machine learning,artificial intelligence,plastic pollution",Review,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA","Instruments & Instrumentation,Spectroscopy",,2.296,"MARINE-ENVIRONMENT,RAMAN-SPECTROSCOPY,BACKGROUND,SUBTRACTION,SIZED,MICROPLASTICS,PLASTIC,PARTICLES,TEXTILE,FIBERS,SURFACE,WATERS,DEMERSAL,FISH,GREAT-LAKES,PYR-GC%2FMS",APPLIED SPECTROSCOPY,https://journals.sagepub.com/doi/pdf/10.1177/0003702820929064,
95,Machine-learning interatomic potentials enable first-principles multiscale modeling of lattice thermal conductivity in graphene/borophene heterostructures,7,9,2359-2367,"Mortazavi Bohayra,Podryabinkin Evgeny V,Roche Stephan,Rabczuk Timon,Zhuang Xiaoying,Shapeev Alexander V","Mortazavi B,Podryabinkin EV,Roche S,Rabczuk T,Zhuang XY,Shapeev AV",Mortazavi B,10.1039/d0mh00787k,University of Hannover,"One of the ultimate goals of computational modeling in condensed matter is to be able to accurately compute materials properties with minimal empirical information. First-principles approaches such as density functional theory (DFT) provide the best possible accuracy on electronic properties but they are limited to systems up to a few hundreds, or at most thousands of atoms. On the other hand, classical molecular dynamics (CMD) simulations and the finite element method (FEM) are extensively employed to study larger and more realistic systems, but conversely depend on empirical information. Here, we show that machine-learning interatomic potentials (MLIPs) trained over shortab initiomolecular dynamics trajectories enable first-principles multiscale modeling, in which DFT simulations can be hierarchically bridged to efficiently simulate macroscopic structures. As a case study, we analyze the lattice thermal conductivity of coplanar graphene/borophene heterostructures, recently synthesized experimentally (Sci. Adv., 2019,5, eaax6444), for which no viable classical modeling alternative is presently available. Our MLIP-based approach can efficiently predict the lattice thermal conductivity of graphene and borophene pristine phases, the thermal conductance of complex graphene/borophene interfaces and subsequently enable the study of effective thermal transport along the heterostructures at continuum level. This work highlights that MLIPs can be effectively and conveniently employed to enable first-principles multiscale modelingviahierarchical employment of DFT/CMD/FEM simulations, thus expanding the capability for computational design of novel nanostructures.","TOTAL-ENERGY CALCULATIONS,TRANSPORT,GRAPHENE",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Materials Science",,14.931,"TOTAL-ENERGY,CALCULATIONS,TRANSPORT,GRAPHENE",MATERIALS HORIZONS,http://arxiv.org/pdf/2006.06794,
96,T-1-FLAIR imaging during continuous head motion: Combining PROPELLER with an intelligent marker,85,2,868-882,"Norbeck Ola,van Niekerk Adam,Avventi Enrico,Ryden Henric,Berglund Johan,Sprenger Tim,Skare Stefan","Norbeck O,van Niekerk A,Avventi E,Ryden H,Berglund J,Sprenger T,Skare S",Norbeck O,10.1002/mrm.28477,Karolinska Institutet,"Purpose The purpose of this work is to describe a T-1-weighted fluid-attenuated inversion recovery (FLAIR) sequence that is able to produce sharp magnetic resonance images even if the subject is moving their head throughout the acquisition. Methods The robustness to motion artifacts and retrospective motion correction capabilities of the PROPELLER (periodically rotated overlapping parallel lines with enhanced reconstruction) trajectory were combined with prospective motion correction. The prospective correction was done using an intelligent marker attached to the subject. This marker wirelessly synchronizes to the pulse sequence to measure the directionality and magnitude of the magnetic fields present in the MRI machine during a short navigator, thus enabling it to determine its position and orientation in the scanner coordinate frame. Three approaches to incorporating the marker-navigator into the PROPELLER sequence were evaluated. The specific absorption rate, and subsequent scan time, of the T-1-weighted FLAIR PROPELLER sequence, was reduced using a variable refocusing flip-angle scheme. Evaluations of motion correction performance were done with 4 volunteers and 3 types of head motion. Results During minimal out-of-plane movement, retrospective PROPELLER correction performed similarly to the prospective correction. However, the prospective clearly outperformed the retrospective correction when there was out-of-plane motion. Finally, the combination of retrospective and prospective correction produced the sharpest images even during large continuous motion. Conclusion Prospective motion correction of a PROPELLER sequence makes it possible to handle continuous, large, and high-speed head motions with only minor reductions in image quality.","brain,motion correction,magnetic resonance imaging,PROPELLER,T-1-FLAIR,wireless radiofrequency triggered acquisition device",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"ATTENUATED,INVERSION-RECOVERY,SPIN-ECHO,SEQUENCES,SMOOTH,TRANSITIONS,T1-WEIGHTED,FLAIR,STEADY-STATES,BLADE,BRAIN,MRI,CALIBRATION,PARALLEL",MAGNETIC RESONANCE IN MEDICINE,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mrm.28477,
97,Hybrid Techniques for MRI Spine Images Classification,79,9,829-832,"Raja Geetha,Mohan J.","Raja G,Mohan J",Raja G,,"SRM Valliammai Engn Coll, Dept Elect & Commun Engn, Chennai 603203, Tamil Nadu, India.","The number of persons suffering from spinal tumor has increased significantly from 2010 to 2016. Tumor is one of the major diseases of spinal cord. Thousands of researchers have concentrated on this disease to provide more efficient diagnosis with better understanding of the classification of spinal cord tumor. The proposed convolutional neural network (CNN) is tested with two hybrid recognized techniques of image detection which are K-nearest neighbor (KNN) with principal component analysis (PCA), local binary patterns (LBP) with support vector machine (SVM). Above three techniques overall accuracy is demonstrated, which show that LBP with SVM gives better result compared to KNN with PCA. The proposed CNN provides high accuracy classification and detection of spine diseases compared to other three techniques, which have obtained a best detection accuracy of 99.41 %. This process is fully implemented in MATLAB tool.","CNN,KNN,LBP,PCA,SVM",Article,"NATL INST SCIENCE COMMUNICATION-NISCAIR, DR K S KRISHNAN MARG, PUSA CAMPUS, NEW DELHI 110 012, INDIA",Engineering,,0.925,,JOURNAL OF SCIENTIFIC & INDUSTRIAL RESEARCH,,
98,,,,,,,,,,,,,,,,,,,,
99,,,,,,,,,,,,,,,,,,,,
