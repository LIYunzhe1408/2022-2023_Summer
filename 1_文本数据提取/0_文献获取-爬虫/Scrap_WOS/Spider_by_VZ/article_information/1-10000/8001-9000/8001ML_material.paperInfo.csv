,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,StatNet: Statistical Image Restoration for Low-Dose CT using Deep Learning,14,6,1137-1150,"Choi Kihwan,Lim Joon Seok,Kim Sungwon Kim","Choi K,Lim JS,Kim SK",Choi K,10.1109/JSTSP.2020.2998413,Korea Institute of Science & Technology (KIST),"Deep learning has recently attracted widespread interest as a means of reducing noise in low-dose CT (LDCT) images. Deep convolutional neural networks (CNNs) are typically trained to transfer high-quality image features of normal-close CT (NDCT) images to LDCT images. However, existing deep learning approaches for denoising LDCT images often overlook the statistical property of CT images. In this paper, we propose an approach to statistical image restoration for LDCT using deep learning. We introduce a loss function to incorporate the noise property in image domain derived from the noise statistics in sinogram domain. In order to capture the spatially-varying statistics of CT images, we increase the receptive fields of the neural network to cover full-size CT slices. In addition, the proposed network utilizes z-directional correlation by taking multiple consecutive CT slices as input. For performance evaluation, the proposed networks are trained and validated with a public dataset consisting of LDCT-NDCT image pairs. We also perform a retrospective study by testing the networks with clinical LDCT images. The experimental results show that the denoising networks successfully reduce the noise level and restore the image details without adding artifacts. This study demonstrates that the statistical deep learning approach can restore the image quality of LDCT without loss of anatomical information.","Low-dose CT,statistical image restoration,convolutional neural network,generative adversarial network,leave-one-out cross-validation,retrospective clinical study",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,"COMPUTED-TOMOGRAPHY,ABDOMINAL,CT,RECONSTRUCTION,NETWORK,ALGORITHM,NOISE",IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,,
2,Multimodal MR Image Synthesis Using Gradient Prior and Adversarial Learning,14,6,1176-1188,"Liu Xiaoming,Yu Aihui,Wei Xiangkai,Pan Zhifang,Tang Jinshan","Liu XM,Yu AH,Wei XK,Pan ZF,Tang JS",Liu XM,10.1109/JSTSP.2020.3013418,Wuhan University of Science & Technology,"In magnetic resonance imaging (MRI), several images can be obtained using different imaging settings (e.g. T1, T2, DWI, and Flair). These images have similar anatomical structures but are with different contrasts, which provide a wealth of information for diagnosis. However, the images under specific imaging settings may not be available due to the limitation of scanning time or corruption caused by noises. It is attractive to derive missing images with some settings from the available MR images. In this paper, we propose a novel end-to-end multisetting MR image synthesis method. The proposed method is based on generative adversarial networks (GANs) - a deep learning model. In the proposed method, different MR images obtained by different settings are used as the inputs of a GANs and each image is encoded by an encoder. Each encoder includes a refinement structure which is used to extract a multiscale feature map from an input image. The multiscale feature maps from different input images are then fused to generate several desired target images under specific settings. Because the resultant images obtained with GANs have blurred edges, we fuse gradient prior information in the model to protect high frequency information such as important tissue textures of medical images. In the proposed model, the multiscale information is also adopted in the adversarial learning (not just in the generator or discriminator) so that we can produce high quality synthesized images. We evaluated the proposed method on two public datasets: BRATS and ISLES. Experimental results demonstrate that the proposed approach is superior to current state-of-the-art methods.","Image generation,Medical diagnostic imaging,Magnetic resonance imaging,Gallium nitride,Image segmentation,Generative adversarial networks,gradient prior,image synthesis,magnetic resonance imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,"SEGMENTATION,NETWORK,CT",IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,,
3,BB-UNet: U-Net With Bounding Box Prior,14,6,1189-1198,"El Jurdi Rosana,Petitjean Caroline,Honeine Paul,Abdallah Fahed","El Jurdi R,Petitjean C,Honeine P,Abdallah F",El Jurdi R,10.1109/JSTSP.2020.3001502,"Normandie Univ, UNIROUEN, UNIHAVRE, LITIS,INSA Rouen, F-76000 Rouen, France.","Medical image segmentation is the process of anatomically isolating organs for analysis and treatment. Leading works within this domain emerged with the well-known U-Net. Despite its success, recent works have shown the limitations of U-Net to conduct segmentation given image particularities such as noise, corruption or lack of contrast. Prior knowledge integration allows to overcome segmentation ambiguities. This paper introduces BB-UNet (Bounding Box U-Net), a deep learning model that integrates location as well as shape prior onto model training. The proposed model is inspired by U-Net and incorporates priors through a novel convolutional layer introduced at the level of skip connections. The proposed architecture helps in presenting attention kernels onto the neural training in order to guide the model on where to look for the organs. Moreover, it fine-tunes the encoder layers based on positional constraints. The proposed model is exploited within two main paradigms: as a solo model given a fully supervised framework and as an ancillary model, in a weakly supervised setting. In the current experiments, manual bounding boxes are fed at inference and as such BB-Unet is exploited in a semi-automatic setting; however, BB-Unet has the potential of being part of a fully automated process, if it relies on a preliminary step of object detection. To validate the performance of the proposed model, experiments are conducted on two public datasets: the SegTHOR dataset which focuses on the segmentation of thoracic organs at risk in computed tomography (CT) images, and the Cardiac dataset which is a mono-modal MRI dataset released as part of the Decathlon challenge and dedicated to segmentation of the left atrium. Results show that the proposed method outperforms state-of-the-art methods in fully supervised learning frameworks and registers relevant results given the weakly supervised domain.","Image segmentation,Shape,Biomedical imaging,Training,Decoding,Deep learning,Computed tomography,U-Net,shape prior,location prior,attention maps,weakly supervised segmentation,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,"IMAGE,SEGMENTATION",IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,https://hal-normandie-univ.archives-ouvertes.fr/hal-02863197/document,
4,Cardiac MRI Segmentation With a Dilated CNN Incorporating Domain-Specific Constraints,14,6,1235-1243,"Simantiris Georgios,Tziritas Georgios","Simantiris G,Tziritas G",Simantiris G,10.1109/JSTSP.2020.3013351,University of Crete,"Semantic segmentation of cardiac MR images is a challenging task due to its importance in medical assessment of heart diseases. Having a detailed localization of specific regions of interest such as Right and Left Ventricular Cavities and Myocardium, doctors can infer important information about the presence of cardiovascular diseases, which are today a major cause of death globally. This paper addresses the problem of semantic segmentation in cardiac MR images using a dilated Convolutional Neural Network. Opting for dilated convolutions allowed us to work in full resolution throughout the network's layers, preserving localization accuracy, while maintaining a relatively small number of trainable parameters. To assist the network's training process we designed a custom loss function. Furthermore, we developed new augmentation techniques and also adapted existing ones, to cope for the lack of sufficient training images. Consequently, the training set increases not only by amount, but by substance as well, and the network trains quickly and efficiently without overfitting. Our pre- and post-processing steps are also crucial to the whole process. We apply our methodology for the Right and Left Ventricles (RV, LV) and also the Myocardium (MYO) according to the Automated Cardiac Diagnosis Challenge (ACDC) with promising results. Submitting our algorithm's predictions to the Post-2017-MICCAI-challenge testing phase, we achieved similar scores (average Dice coefficient 0.916) on the test data set compared to the state of the art featured in the ACDC leaderboard, but with significantly fewer parameters than the leading method. Our approach outperforms other methods featuring dilated convolutions in this challenge up until now.","Image segmentation,Training,Kernel,Myocardium,Task analysis,Cavity resonators,Semantics,Cardiac MRI segmentation,CNN,data augmentation,loss function,dilated convolutions,MRF",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,,IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,,
5,Data-Adaptive Similarity Measures for B-mode Ultrasound Images Using Robust Noise Models,14,6,1244-1254,"Ouzir Nora,Ollila Esa,Vorobyov Sergiy A.","Ouzir N,Ollila E,Vorobyov SA",Ouzir N,10.1109/JSTSP.2020.3001829,Aalto University,"Ultrasound imaging (UI) is characterized by the presence of multiplicative speckle noise and various acquisition artefacts. Designing ultrasound (US) similarity measures thus requires a particular attention. In the specific context of motion estimation, incorporating US characteristics does not only benefit traditional methods but also learning-based approaches, which are highly sensitive to the quality of training data. Deriving similarity measures from a maximum likelihood (ML) perspective allows us to take these specificities into account. As opposed to the classical Rayleigh modelling, the proposed similarity measures incorporate more realistic scattering conditions, such as, varying speckle densities and shadowing. Specifically, the deviations from the Rayleigh statistics are modelled using the t-distribution for the complex radio-frequency (RF) signals and the Nakagami-Gamma (NG) compound model for the echo amplitudes. Furthermore, the model parameters are learnt patch-wise, which leads to data-adaptive similarity measures. The proposed criteria are investigated in the context of motion estimation using synthetic, phantom, as well as 2D and 3D in vivo images. The experimental results show an improvement in performance and robustness in comparison to the classical Rayleigh-based approach and state-of-the-art similarity measures.","Similarity measures,ultrasound,heavy-tailed distributions,motion estimation,t-distribution,Nakagami-Gamma distribution,data-adaptive",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,"LIKELIHOOD,MOTION,ESTIMATION,COMPOUND-GAUSSIAN,CLUTTER,ECHO,ENVELOPE,TRACKING,ECHOCARDIOGRAPHY,BACKSCATTERING,REGISTRATION,SCATTERING,TISSUE",IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,,
6,Dictionary Learning-Based fMRI Data Analysis for Capturing Common and Individual Neural Activation Maps,14,6,1265-1279,"Jin Rui,Dontaraju Krishna K.,Kim Seung-Jun,Akhonda Mohammad Abu Baker Siddique,Adali Tulay","Jin R,Dontaraju KK,Kim SJ,Akhonda MAS,Adali T",Kim SJ,10.1109/JSTSP.2020.2992430,University System of Maryland,"In this paper, a novel dictionary learning (DL) method is proposed to estimate sparse neural activations from multi-subject fMRI data sets. By exploiting the label information such as the patient and the normal healthy groups, the activation maps that are commonly shared across the groups as well as those that can explain the group differences are both captured. The proposed method was tested using real fMRI data sets consisting of schizophrenic subjects and healthy controls. The DL approach not only reproduced most of the maps obtained from the conventional independent component analysis (ICA), but also identified more maps that are significantly group-different, including a number of novel ones that were not revealed by ICA. The stability analysis of the DL method and the correlation analysis with separate neuropsychological test scores further strengthen the validity of our analysis.","Functional magnetic resonance imaging,Dictionaries,Data analysis,Sparse matrices,Task analysis,Machine learning,Brain modeling,Dictionary learning,FMRI data analysis,sparse models,supervised,unsupervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,"FUNCTIONAL,MRI,DATA,INDEPENDENT,COMPONENT,TEMPORAL-LOBE,MAGNETIC-RESONANCE,MEMORY,PERFORMANCE,K-SVD,SPARSE,ALGORITHMS,DIVERSITY,SIBLINGS",IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,https://mdsoar.org/bitstream/11603/19052/1/draft_final_DOI.pdf,
7,Geometric Approaches to Increase the Expressivity of Deep Neural Networks for MR Reconstruction,14,6,1292-1305,"Cha Eunju,Oh Gyutaek,Ye Jong Chul","Cha EJ,Oh G,Ye JC",Ye JC,10.1109/JSTSP.2020.2982777,Korea Advanced Institute of Science & Technology (KAIST),"Recently, deep learning approaches have been extensively investigated to reconstruct images from accelerated magnetic resonance image (MRI) acquisition. Although these approaches provide significant performance gain compared to compressed sensing MRI (CS-MRI), it is not clear how to choose a suitable network architecture to balance the trade-off between network complexity and performance. Recently, it was shown that an encoder-decoder convolutional neural network (CNN) can be interpreted as a piecewise linear basis-like representation, whose specific representation is determined by the ReLU activation patterns for a given input image. Thus, the expressivity or the representation power is determined by the number of piecewise linear regions. As an extension of this geometric understanding, this paper proposes a systematic geometric approach using bootstrapping and subnetwork aggregation using an attention module to increase the expressivity of the underlying neural network. Our method can be implemented in both k-space domain and image domain that can be trained in an end-to-end manner. Experimental results show that the proposed schemes significantly improve reconstruction performance with negligible complexity increases.","Magnetic resonance imaging,Decoding,Image reconstruction,Neural networks,Complexity theory,Deep learning,Acceleration,Accelerated MRI,deep learning,expressivity,convolution framelets,skipped connection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,FRAMEWORK,IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,http://arxiv.org/pdf/2003.07740,
8,Enhancement of the Au/ZnO-NA Plasmonic SERS Signal Using Principal Component Analysis as a Machine Learning Approach,12,5,,"Gupta Akhilesh Kumar,Hsu Chih-Hsien,Lai Chao-Sung","Gupta AK,Hsu CH,Lai CS",Lai CS,10.1109/JPHOT.2020.3015740,Chang Gung University,"In this work, we modeled a novel approach to enhance surface-enhanced Raman scattering (SERS) signals using principal component analysis (PCA) as a machine learning approach. Zinc oxide nanoarrays (ZnO-NAs) were synthesized using a hydrothermal method followed by zinc oxide nucleation on ITO glass substrates via an oxidation furnace at 500 degrees C. The surface morphology was improved by short rapid thermal annealing (S-RTA) after deposition of a gold layer via a thermal evaporator to avoid chemical contamination of the sensing surface, which is a suitable plasmonic platform for the generation of ""hot spots"" for SERS enhancement with fewer defects. The proposed Au/ZnO-NA SERS sensor exhibited an enhancement factor (EF) of 1.15 x 10(7) via the R6G Raman probe and excellent uniformity over the entire surface. The PCA algorithm was used to extract useful features and information from the SERS signal. The algorithm was implemented with MATLAB software (R2019a) by the multivariable analytical tool to find an enhanced signal (similar to 3 times higher) with high uniformity, which has great potential and is applicable to a wide range of probe molecules suitable in medical, safety, and environmental applications.","Plasmonic model,SERS,signal enhancement,PCA analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Optics,Physics",,2.602,"ZNO,NANOPARTICLES,CLASSIFICATION,SENSOR",IEEE PHOTONICS JOURNAL,https://ieeexplore.ieee.org/ielx7/4563994/9180368/09165082.pdf,
9,Iterative Label Denoising Network: Segmenting Male Pelvic Organs in CT From 3D Bounding Box Annotations,67,10,2710-2720,"Wang Shuai,Wang Qian,Shao Yeqin,Qu Liangqiong,Lian Chunfeng,Lian Jun,Shen Dinggang","Wang S,Wang Q,Shao YQ,Qu LQ,Lian CF,Lian J,Shen DG",Shen DG,10.1109/TBME.2020.2969608,University of North Carolina,"Obtaining accurate segmentation of the prostate and nearby organs at risk (e.g., bladder and rectum) in CT images is critical for radiotherapy of prostate cancer. Currently, the leading automatic segmentation algorithms are based on Fully Convolutional Networks (FCNs), which achieve remarkable performance but usually need large-scale datasets with high-quality voxel-wise annotations for full supervision of the training. Unfortunately, such annotations are difficult to acquire, which becomes a bottleneck to build accurate segmentation models in real clinical applications. In this paper, we propose a novel weakly supervised segmentation approach that only needs 3D bounding box annotations covering the organs of interest to start the training. Obviously, the bounding box includes many non-organ voxels that carry noisy labels to mislead the segmentation model. To this end, we propose the label denoising module and embed it into the iterative training scheme of the label denoising network (LDnet) for segmentation. The labels of the training voxels are predicted by the tentative LDnet, while the label denoising module identifies the voxels with unreliable labels. As only the good training voxels are preserved, the iteratively re-trained LDnet can refine its segmentation capability gradually. Our results are remarkable, i.e., reaching similar to 94% (prostate), similar to 91% (bladder), and similar to 86% (rectum) of the Dice Similarity Coefficients (DSCs), compared to the case of fully supervised learning upon high-quality voxel-wise annotations and also superior to several state-of-the-art approaches. To our best knowledge, this is the first work to achieve voxel-wise segmentation in CT images from simple 3D bounding box annotations, which can greatly reduce many labeling efforts and meet the demands of the practical clinical applications.","Image segmentation,Training,Three-dimensional displays,Biological systems,Computed tomography,Noise reduction,Biomedical imaging,Image Segmentation,Bounding Box Annotation,Weakly Supervised Learning,Fully Convolutional Network (FCN),Pelvic Organ,CT",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"CONVOLUTIONAL,NEURAL-NETWORK,SEGMENTATION,PROSTATE,REGISTRATION,CUT",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8195631,
10,Robust Collaborative Clustering of Subjects and Radiomic Features for Cancer Prognosis,67,10,2735-2744,"Liu Hangfan,Li Hongming,Habes Mohamad,Li Yuemeng,Boimel Pamela,Janopaul-Naylor James,Xiao Ying,Ben-Josef Edgar,Fan Yong","Liu HF,Li HM,Habes M,Li YM,Boimel P,Janopaul-Naylor J,Xiao Y,Ben-Josef E,Fan Y",Fan Y,10.1109/TBME.2020.2969839,University of Pennsylvania,"Feature dimensionality reduction plays an important role in radiomic studies with a large number of features. However, conventional radiomic approaches may suffer from noise, and feature dimensionality reduction techniques are not equipped to utilize latent supervision information of patient data under study, such as differences in patients, to learn discriminative low dimensional representations. To achieve robustness to noise and feature dimensionality reduction with improved discriminative power, we develop a robust collaborative clustering method to simultaneously cluster patients and radiomic features into distinct groups respectively under adaptive sparse regularization. Our method is built upon matrix tri-factorization enhanced by adaptive sparsity regularization for simultaneous feature dimensionality reduction and denoising. Particularly, latent grouping information of patients with distinct radiomic features is learned and utilized as supervision information to guide the feature dimensionality reduction, and noise in radiomic features is adaptively isolated in a Bayesian framework under a general assumption of Laplacian distributions of transform-domain coefficients. Experiments on synthetic data have demonstrated the effectiveness of the proposed approach in data clustering, and evaluation results on an FDG-PET/CT dataset of rectal cancer patients have demonstrated that the proposed method outperforms alternative methods in terms of both patient stratification and prediction of patient clinical outcomes.","Radiomics,Collaboration,Dimensionality reduction,Matrix decomposition,Feature extraction,Cancer,Dictionaries,Sparsity,collaborative clustering,unsupervised learning,nonnegative matrix tri-factorization,radiomics",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"DISTANT,METASTASIS,SELECTION,SURVIVAL,IMAGE,SET",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8048106,
11,Online Transfer Learning for Differential Diagnosis of Benign and Malignant Thyroid Nodules With Ultrasound Images,67,10,2773-2780,"Zhou Hui,Wang Kun,Tian Jie","Zhou H,Wang K,Tian J",Tian J,10.1109/TBME.2020.2971065,Chinese Academy of Sciences,"Objective: We aimed to propose a highly automatic and objective model named online transfer learning (OTL) for the differential diagnosis of benign and malignant thyroid nodules from ultrasound (US) images. Methods: The OTL mothed combined the strategy of transfer learning and online learning. Two datasets (1750 thyroid nodules with 1078 benign and 672 malignant nodules, and 3852 thyroid nodules with 3213 benign and 639 malignant nodules) were collected to develop the model. The diagnostic accuracy was also compared with VGG-16 based transfer learning model and different input images based model. Analysis of receiver operating characteristic (ROC) curves were performed to calculate optimal area under it (AUC) for benign and malignant nodules. Results: AUC, sensitivity and specificity of OTL were 0.98 (95% confidence interval [CI]: 0.97-0.99), 98.7% (95% confidence interval [CI]: 97.8%-99.6%) and 98.8% (95% confidence interval [CI]: 97.9%-99.7%) in the final online learning step, which was significantly better than other deep learning models (P < 0.01). Conclusion: OTL model shows the best overall performance comparing with other deep learning models. The model holds a good potential for improving the overall diagnostic efficacy in thyroid nodule US examinations. Significance: The proposed OTL model could be seamlessly integrated into the conventional work-flow of thyroid nodule US examinations.","Cancer,Biological system modeling,Ultrasonic imaging,Feature extraction,Radiomics,Training,Deep learning,Diagnosis,online learning,radiomics,transfer learning,thyroid nodules,ultrasound images",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"FEATURES,RISK,US,CLASSIFICATION,MANAGEMENT,CARCINOMA,CANCER",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
12,Distant Sensor Prediction of Event-Related Potentials,67,10,2916-2924,"Fickling Shaun D.,Bollinger Fabio H.,Gurm Sandeep,Pawlowski Gabriela,Liu Careesa C.,Hajra Sujoy Ghosh);,Song Xiaowei,D'Arcy Ryan C. N.","Fickling SD,Bollinger FH,Gurm S,Pawlowski G,Liu CC,Hajra SG,Song XW,D'Arcy RCN",D'Arcy RCN,10.1109/TBME.2020.2973617,"Fraser Hlth Author, Burnaby, BC, Canada.","Objective: The ability to measure event-related potentials (ERPs) as practical, portable brain vital signs is limited by the physical locations of electrodes. Standard electrode locations embedded within the hair result in challenges to obtaining quality signals in a rapid manner. Moreover, these sites require electrode gel, which can be inconvenient. As electrical activity in the brain is spatially volume distributed, it should be possible to predict ERPs from distant sensor locations at easily accessible mastoid and forehead scalp regions. Methods: An artificial neural network was trained on ERP signals recorded from below hairline electrode locations (Tp9, Tp10, Af7, Af8 referenced to Fp1, Fp2) to predict signals recorded at the ideal Cz location. Results: The model resulted in mean improvements in intraclass correlation coefficient relative to control for all stimulus types (Standard Tones: +9.74%, Deviant Tones: +3.23%, Congruent Words: +15.25%, Incongruent Words: +25.43%) and decreases in RMS Error (Standard Tones: -26.72%, Deviant Tones: -17.80%, Congruent Words: -28.78%, Incongruent Words: -29.61%) compared to the individual distant channels. Measured vs predicted ERP amplitudes were highly and significantly correlated with control for the N100 (R = 0.5, p(adj) < 0.05), P300 (R = 0.75, p(adj) < 0.01), and N400 (R = 0.75, p(adj) < 0.01) ERPs. Conclusion: ERP waveforms at distant channels can be combined using a neural network autoencoder to model the control channel features with better precision than those at individual distant channels. This is the first demonstration of feasibility of predicting evoked potentials and brain vital signs using signals recorded from more distant, practical locations. Significance: This solves a key engineering challenge for applications that require portability, comfort, and speed of measurement as design priorities for measurement of event-related potentials across a range of individuals, settings, and circumstances.","Electroencephalography,Electrodes,Standards,Artificial neural networks,Mathematical model,Brain modeling,Electric potential,Distant-sensing,brain vital signs,electroencephalography (EEG),event-related potentials (ERP),artificial neural network,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,BRAIN,IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
13,GAN-OPC: Mask Optimization With Lithography-Guided Generative Adversarial Nets,39,10,2822-2834,"Yang Haoyu,Li Shuhe,Deng Zihao,Ma Yuzhe,Yu Bei,Young Evangeline F. Y.","Yang HY,Li SH,Deng ZH,Ma YZ,Yu B,Young EFY",Yang HY,10.1109/TCAD.2019.2939329,Chinese University of Hong Kong,"Mask optimization has been a critical problem in the VLSI design flow due to the mismatch between the lithography system and the continuously shrinking feature sizes. Optical proximity correction (OPC) is one of the prevailing resolution enhancement techniques (RETs) that can significantly improve mask printability. However, in advanced technology nodes, the mask optimization process consumes more and more computational resources. In this article, we develop a generative adversarial network (GAN) model to achieve better mask optimization performance. We first develop an OPC-oriented GAN flow that can learn target-mask mapping from the improved architecture and objectives, which leads to satisfactory mask optimization results. To facilitate the training process and ensure better convergence, we propose a pretraining scheme that jointly trains the neural network with inverse lithography technique (ILT). We also propose an enhanced generator design with a U-Net architecture and a subpixel super-resolution structure that promise a better convergence and a better mask quality, respectively. At convergence, the generative network is able to create quasi-optimal masks for given target circuit patterns and fewer normal OPC steps are required to generate high quality masks. The experimental results show that our flow can facilitate the mask optimization process as well as ensure a better printability.","Lithography,Optimization,Generators,Training,Semiconductor device modeling,Mathematical model,Gallium nitride,Convolutional neural networks,generative model,inverse lithography,optical proximity correction",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,2.702,DESIGN,IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS,,
14,K-Nearest Neighbor Based Locally Connected Network for Fast Morphological Reconstruction in Fluorescence Molecular Tomography,39,10,3019-3028,"Meng Hui,Gao Yuan,Yang Xin,Wang Kun,Tian Jie","Meng H,Gao Y,Yang X,Wang K,Tian J",Wang K; Tian J,10.1109/TMI.2020.2984557,Chinese Academy of Sciences,"Fluorescence molecular tomography (FMT) is a highly sensitive and noninvasive imaging modality for three-dimensional visualization of fluorescence probe distribution in small animals. However, the simplified photon propagation model and ill-posed inverse problem limit the improvement of FMT reconstruction. In this work, we proposed a novel K-nearest neighbor based locally connected (KNN-LC) network to improve the performance of morphological reconstruction in FMT. It directly builds the inverse process of photon transmission by learning the mapping relation between the surface photon intensity and the distribution of fluorescent source. KNN-LC network cascades a fully connected (FC) sub-network with a locally connected (LC) sub-network, where the FC part provides a coarse reconstruction result and LC part fine-tunes the morphological quality of reconstructed result. To assess the performance of our proposed network, we implemented both numerical simulation and in vivo studies. Furthermore, split Bregman-resolved total variation (SBRTV) regularization method and inverse problem simulation (IPS) method were utilized as baselines in all comparisons. The results demonstrated that KNN-LC network achieved accurate reconstruction in both source localization and morphology recovery in a short time. This promoted the in vivo application of FMT for visualizing the distribution of biomarkers inside biological tissue.","Image reconstruction,Photonics,Fluorescence,Inverse problems,Surface reconstruction,In vivo,Surface morphology,Fluorescence tomography,machine learning,brain",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"TOTAL,VARIATION,REGULARIZATION,LAPLACE,PRIOR,REGULARIZATION,OPTIMIZATION,REGISTRATION,LIGHT",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://ieeexplore.ieee.org/ielx7/42/9210240/09056814.pdf,
15,High-Resolution Chest X-Ray Bone Suppression Using Unpaired CT Structural Priors,39,10,3053-3063,"Li Han,Han Hu,Li Zeju,Wang Lei,Wu Zhe,Lu Jingjing,Zhou S. Kevin","Li H,Han H,Li ZJ,Wang L,Wu Z,Lu JJ,Zhou SK",Han H,10.1109/TMI.2020.2986242,Chinese Academy of Sciences,"There is clinical evidence that suppressing the bone structures in Chest X-rays (CXRs) improves diagnostic value, either for radiologists or computer-aided diagnosis. However, bone-free CXRs are not always accessible. We hereby propose a coarse-to-fine CXR bone suppression approach by using structural priors derived from unpaired computed tomography (CT) images. In the low-resolution stage, we use the digitally reconstructed radiograph (DRR) image that is computed from CT as a bridge to connect CT and CXR. We then perform CXR bone decomposition by leveraging the DRR bone decomposition model learned from unpaired CTs and domain adaptation between CXR and DRR. To further mitigate the domain differences between CXRs and DRRs and speed up the learning convergence, we perform all the aboved operations in Laplacian of Gaussian (LoG) domain. After obtaining the bone decomposition result in DRR, we upsample it to a high resolution, based on which the bone region in the original high-resolution CXR is cropped and processed to produce a high-resolution bone decomposition result. Finally, such a produced bone image is subtracted from the original high-resolution CXR to obtain the bone suppression result. We conduct experiments and clinical evaluations based on two benchmarking CXR databases to show that (i) the proposed method outperforms the state-of-the-art unsupervised CXR bone suppression approaches; (ii) the CXRs with bone suppression are instrumental to radiologists for reducing their false-negative rate of lung diseases from 15% to 8%; and (iii) state-of-the-art disease classification performances are achieved by learning a deep network that takes the original CXR and its bone-suppressed image as inputs.","Bones,Computed tomography,Computational modeling,Image resolution,Manuals,Computational efficiency,Generative adversarial networks,Coarse-to-fine,CXR bone suppression,domain adaptation,LoG transform,unsupervised leaning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"RADIOGRAPHS,NETWORKS,NODULES",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
16,Deep Learning for Ultrasound Localization Microscopy,39,10,3064-3078,"Liu Xin,Zhou Tianyang,Lu Mengyang,Yang Yi,He Qiong,Luo Jianwen","Liu X,Zhou TY,Lu MY,Yang Y,He Q,Luo JW",Liu X,10.1109/TMI.2020.2986781,Shanghai University,"By localizing microbubbles (MBs) in the vasculature, ultrasound localization microscopy (ULM) has recently been proposed, which greatly improves the spatial resolution of ultrasound (US) imaging and will be helpful for clinical diagnosis. Nevertheless, several challenges remain in fast ULM imaging. The main problems are that current localization methods used to implement fast ULM imaging, e.g., a previously reported localization method based on sparse recovery (CS-ULM), suffer from long dataprocessing time and exhaustiveparameter tuning (optimization). To address these problems, in this paper, we propose a ULM method based on deep learning, which is achieved by using a modified sub-pixel convolutional neural network (CNN), termed as mSPCN-ULM. Simulations and in vivo experiments are performed to evaluate the performance of mSPCN-ULM. Simulation results show that even if under high-density condition (6.4 MBs/mm(2)), a high localization precision (similar to 28 mu m in the lateral direction and similar to 24 mu m in the axial direction) and a high localization reliability (Jaccard index of 0.66) can be obtained by mSPCN-ULM, compared to CS-ULM. The in vivo experimental results indicate that with plane wave scan at a transmit center frequency of 15.625 MHz, microvessels with diameters of similar to 17 mu m can be detected and adjacent microvessels with a distance of similar to 42 mu m can be separated. Furthermore, when using GPU acceleration, the data-processing time ofmSPCN-ULM can be shortened to similar to 6 sec/frame in the simulations and similar to 23 sec/frame in thein vivo experiments, which is 3-4 orders of magnitude faster than CS-ULM. Finally, once the network is trained, mSPCN-ULM does not need parameter tuning to implement ULM. As a result, mSPCN-ULM opens the door to implement ULM with fast data-processing speed, high imaging accuracy, short data-acquisition time, and high flexibility (robustness to parameters) characteristics.","Convolutional neural networks,deep learning,sub-pixel convolution layer,super-resolution ultrasound imaging,ultrasound localization microscopy",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORKS,SUPERRESOLUTION,RECONSTRUCTION,DOPPLER",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
17,Nondestructive Detection of Targeted Microbubbles Using Dual-Mode Data and Deep Learning for Real-Time Ultrasound Molecular Imaging,39,10,3079-3088,"Hyun Dongwoon,Abou-Elkacem Lotfi,Bam Rakesh,Brickson Leandra L.,Herickhoff Carl D.,Dahl Jeremy J.","Hyun D,Abou-Elkacem L,Bam R,Brickson LL,Herickhoff CD,Dahl JJ",Hyun D,10.1109/TMI.2020.2986762,Stanford University,"Ultrasound molecular imaging (UMI) is enabled by targeted microbubbles (MBs), which are highly reflective ultrasound contrast agents that bind to specific biomarkers. Distinguishing between adherent MBs and background signals can be challenging in vivo. The preferred preclinical technique is differential targeted enhancement (DTE), wherein a strong acoustic pulse is used to destroy MBs to verify their locations. However, DTE intrinsically cannot be used for real-time imaging and may cause undesirable bioeffects. In this work, we propose a simple 4-layer convolutional neural network to nondestructively detect adherent MB signatures. We investigated several types of input data to the network: ""anatomy-mode"" (fundamental frequency), ""contrast-mode"" (pulse-inversion harmonic frequency), or both, i.e., ""dual-mode"", using IQ channel signals, the channel sum, or the channel sum magnitude. Training and evaluation were performed on in vivo mouse tumor data and microvessel phantoms. The dual-mode channel signals yielded optimal performance, achieving a soft Dice coefficient of 0.45 and AUC of 0.91 in two test images. In a volumetric acquisition, the network best detected a breast cancer tumor, resulting in a generalized contrast-to-noise ratio (GCNR) of 0.93 and Kolmogorov-Smirnov statistic (KSS) of 0.86, outperforming both regular contrast mode imaging (GCNR = 0.76, KSS = 0.53) and DTE imaging (GCNR = 0.81, KSS = 0.62). Further development of the methodology is necessary to distinguish free from adherent MBs. These results demonstrate that neural networks can be trained to detect targeted MBs with DTE-like quality using nondestructive dual-mode data, and can be used to facilitate the safe and real-time translation of UMI to clinical applications.","Imaging,Ultrasonic imaging,Neural networks,Mice,Machine learning,Harmonic analysis,Tumors,Image enhancement,restoration (noise and artifact reduction),machine learning,molecular and cellular imaging,neural network,ultrasound",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"BREAST-CANCER,PROSTATE-CANCER,CONTRAST,AGENTS,PULSE,INVERSION,BR55,QUANTIFICATION,ANGIOGENESIS,TUMORS,NOISE",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7793556,
18,Synthesize High-Quality Multi-Contrast Magnetic Resonance Imaging From Multi-Echo Acquisition Using Multi-Task Deep Generative Model,39,10,3089-3099,"Wang Guanhua,Gong Enhao,Banerjee Suchandrima,Martin Dann,Tong Elizabeth,Choi Ja,Chen Huijun,Wintermark Max,Pauly John M.,Zaharchuk Greg","Wang GH,Gong EH,Banerjee S,Martin D,Tong E,Choi J,Chen HJ,Wintermark M,Pauly JM,Zaharchuk G",Zaharchuk G,10.1109/TMI.2020.2987026,Stanford University,"Multi-echo saturation recovery sequence can provide redundant information to synthesize multi-contrast magnetic resonance imaging. Traditional synthesis methods, such as GE's MAGiC platform, employ a model-fitting approach to generate parameter-weighted contrasts. However, models' over-simplification, as well as imperfections in the acquisition, can lead to undesirable reconstruction artifacts, especially in T2-FLAIR contrast. To improve the image quality, in this study, a multi-task deep learning model is developed to synthesize multi-contrast neuroimaging jointly using both signal relaxation relationships and spatial information. Compared with previous deep learning-based synthesis, the correlation between different destination contrast is utilized to enhance reconstruction quality. To improve model generalizability and evaluate clinical significance, the proposed model was trained and tested on a large multi-center dataset, including healthy subjects and patients with pathology. Results from both quantitative comparison and clinical reader study demonstrate that the multi-task formulation leads to more efficient and accurate contrast synthesis than previous methods.","Magnetic resonance imaging,Generators,Machine learning,Generative adversarial networks,Training,Image reconstruction,Pathology,Magnetic resonance imaging (MRI),image synthesis,generative adversarial network (GAN),deep learning (DL),image fusion",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"ATTENUATION,CORRECTION,PROTON-DENSITY,SYNTHETIC-MRI,BRAIN,QUANTIFICATION,NETWORK",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
19,Deep Q-CapsNet Reinforcement Learning Framework for Intrauterine Cavity Segmentation in TTTS Fetal Surgery Planning,39,10,3113-3124,"Torrents-Barrena Jordina,Piella Gemma,Gratacos Eduard,Eixarch Elisenda,Ceresa Mario,Gonalez Ballester Miguel A.","Torrents-Barrena J,Piella G,Gratacos E,Eixarch E,Ceresa M,Ballester MGA",Torrents-Barrena J,10.1109/TMI.2020.2987981,Pompeu Fabra University,"Fetoscopic laser photocoagulation is the most effective treatment for Twin-to-Twin Transfusion Syndrome, a condition affecting twin pregnancies in which there is a deregulation of blood circulation through the placenta, that can be fatal to both babies. For the purposes of surgical planning, we design the first automatic approach to detect and segment the intrauterine cavity from axial, sagittal and coronal MRI stacks. Our methodology relies on the ability of capsule networks to successfully capture the part-whole interdependency of objects in the scene, particularly for unique class instances (i.e., intrauterine cavity). The presented deep Q-CapsNet reinforcement learning framework is built upon a context-adaptive detection policy to generate a bounding box of the womb. A capsule architecture is subsequently designed to segment (or refine) the whole intrauterine cavity. This network is coupled with a strided nnU-Net feature extractor, which encodes discriminative feature maps to construct strong primary capsules. The method is robustly evaluated with and without the localization stage using 13 performance measures, and directly compared with 15 state-of-the-art deep neural networks trained on 71 singleton and monochorionic twin pregnancies. An average Dice score above 0.91 is achieved for all ablations, revealing the potential of our approach to be used in clinical practice.","Cavity resonators,Magnetic resonance imaging,Feature extraction,Image segmentation,Motion segmentation,Forestry,Lung,Fetal surgery,twin-to-twin transfusion syndrome,MRI,intrauterine cavity segmentation,capsules,q-learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,MRI,IEEE TRANSACTIONS ON MEDICAL IMAGING,,
20,DU-Net: Convolutional Network for the Detection of Arterial Calcifications in Mammograms,39,10,3240-3249,"AlGhamdi Manal,Abdel-Mottaleb Mohamed,Collado-Mesa Fernando","AlGhamdi M,Abdel-Mottaleb M,Collado-Mesa F",AlGhamdi M,10.1109/TMI.2020.2989737,Umm Al Qura University,"Breast arterial calcifications (BACs) are part of several benign findings present on some mammograms. Previous studies have indicated that BAC may provide evidence of general atherosclerotic vascular disease, and potentially be a useful marker of cardiovascular disease (CVD). Currently, there is no technique in use for the automatic detection of BAC in mammograms. Since a majority of women over the age of 40 already undergo breast cancer screening with mammography, detecting BAC may offer a method to screen women for CVD in a way that is effective, efficient, and broad reaching, at no additional cost or radiation. In this paper, we present a deep learning approach for detecting BACs in mammograms. Inspired by the promising results achieved using the U-Net model in many biomedical segmentation problems and the DenseNet in semantic segmentation, we extend the U-Net model with dense connectivity to automatically detect BACs in mammograms. The presented model helps to facilitate the reuse of computation and improve the flow of gradients, leading to better accuracy and easier training of the model. We evaluate the performance using a set of full-field digital mammograms collected and prepared for this task from a publicly available dataset. Experimental results demonstrate that the presented model outperforms human experts as well as the other related deep learning models. This confirms the effectiveness of our model in the BACs detection task, which is a promising step in providing a cost-effective risk assessment tool for CVD.","Mammography,Task analysis,Image segmentation,Feature extraction,Solid modeling,Biological system modeling,Computational modeling,Cardiovascular,deep learning,mammogram,segmentation U-Net",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"DISEASE,RISK,SEGMENTATION",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
21,Compressed Optoacoustic Sensing of Volumetric Cardiac Motion,39,10,3250-3255,"Ozbek Ali,Dean-Ben Xose Luis,Razansky Daniel","Ozbek A,Dean-Ben XL,Razansky D",Ozbek A,10.1109/TMI.2020.2985134,ETH Zurich,"The recently developed optoacoustic tomography systems have attained volumetric frame rates exceeding 100 Hz, thus opening up new venues for studying previously invisible biological dynamics. Further gains in temporal resolution can potentially be achieved via partial data acquisition, though a priori knowledge on the acquired data is essential for rendering accurate reconstructions using compressed sensing approaches. In this work, we suggest a machine learning method based on principal component analysis for high-frame-rate volumetric cardiac imaging using only a few tomographic optoacoustic projections. The method is particularly effective for discerning periodic motion, as demonstrated herein by non-invasive imaging of a beating mouse heart. A training phase enables efficiently compressing the heart motion information, which is subsequently used as prior information for image reconstruction from sparse sampling at a higher frame rate. It is shown that image quality is preserved with a 64-fold reduction in the data flow. We demonstrate that, under certain conditions, the volumetric motion could effectively be captured by relying on time-resolved data from a single optoacoustic detector. Feasibility of capturing transient (non-periodic) events not registered in the training phase is further demonstrated by visualizing perfusion of a contrast agent in vivo. The suggested approach can be used to significantly boost the temporal resolution of optoacoustic imaging and facilitate development of more affordable and data efficient systems.","Image reconstruction,Training,Principal component analysis,Three-dimensional displays,Data acquisition,Tomography,Image acquisition,image reconstruction,image restoration,machine learning,optoacoustic imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,,"PHOTOACOUSTIC,TOMOGRAPHY",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.research-collection.ethz.ch/bitstream/20.500.11850/446009/3/09102986.pdf,
22,DoubleFusion: Real-Time Capture of Human Performances with Inner Body Shapes from a Single Depth Sensor,42,10,2523-2539,"Yu Tao,Zhao Jianhui,Zheng Zerong,Guo Kaiwen,Dai Qionghai,Li Hao,Pons-Moll Gerard,Liu Yebin","Yu T,Zhao JH,Zheng ZR,Guo KW,Dai QH,Li H,Pons-Moll G,Liu YB",Liu YB,10.1109/TPAMI.2019.2928296,Tsinghua University,"We propose DoubleFusion, a new real-time system that combines volumetric non-rigid reconstruction with data-driven template fitting to simultaneously reconstruct detailed surface geometry, large non-rigid motion and the optimized human body shape from a single depth camera. One of the key contributions of this method is a double-layer representation consisting of a complete parametric body model inside, and a gradually fused detailed surface outside. A pre-defined node graph on the body parameterizes the non-rigid deformations near the body, and a free-form dynamically changing graph parameterizes the outer surface layer far from the body, which allows more general reconstruction. We further propose a joint motion tracking method based on the double-layer representation to enable robust and fast motion tracking performance. Moreover, the inner parametric body is optimized online and forced to fit inside the outer surface layer as well as the live depth input. Overall, our method enables increasingly denoised, detailed and complete surface reconstructions, fast motion tracking performance and plausible inner body shape reconstruction in real-time. Experiments and comparisons show improved fast motion tracking and loop closure performance on more challenging scenarios. Two extended applications including body measurement and shape retargeting show the potential of our system in terms of practical use.","Shape,Surface reconstruction,Real-time systems,Tracking,Strain,Cameras,Skeleton,RGBD sensor,human performance capture,human shape reconstruction,real-time",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Computer Science,Engineering",,18.46,"MARKERLESS,MOTION,CAPTURE,INTERACTING,CHARACTERS,OBJECTS,REGISTRATION,TRACKING",IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,http://arxiv.org/pdf/1804.06023,
23,Ultrasound Deep Learning for Wall Segmentation and Near-Wall Blood Flow Measurement,67,10,2022-2032,"Park Jun Hong,Lee Sang Joon","Park JH,Lee SJ",Lee SJ,10.1109/TUFFC.2020.2995467,Pohang University of Science & Technology (POSTECH),"Studies of medical flow imaging have technical limitations for accurate analysis of blood flow dynamics and vessel wall interaction at arteries. We propose a new deep learning-based boundary detection and compensation (DL-BDC) technique in ultrasound (US) imaging. It can segment vessel boundaries by harnessing the convolutional neural network and wall motion compensation in the analysis of near-wall flow dynamics. The network enables training from real and synthetic US images together. The performance of the technique is validated through synthetic US images and tissue-mimicking phantom experiments. The neural network performs well with high Dice coefficients of over 0.94 and 0.9 for lumens and walls, outperforming previous segmentation techniques. Then, the performance of the wall motion compensation is examined for compliant phantoms. When DL-BDC is applied to flow influenced by wall motion, root-mean-square errors are less than 0.07%. The technique is utilized to analyze flow dynamics and wall interaction with varying elastic moduli of the phantoms. The results show that the flow dynamics and wall shear stress values are consistent with the expected values of the compliant phantoms, and their wall motion behavior is observed with pulse wave propagation. This strategy makes US imaging capable of simultaneous measurement of blood flow and vessel dynamics in human arteries for their accurate interaction analysis. DL-BDC can segment vessel walls fast, accurately, and robustly. It enables to measure the near-wall flow precisely by determining the vessel boundary dynamics. This approach can be beneficial in flow dynamics and wall interaction analyses in various biomedical applications.","Image segmentation,Phantoms,Dynamics,Blood flow,Speckle,Imaging phantoms,Artificial neural networks,carotid artery,fluid flow measurement,image segmentation,wall dynamics",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,"MOTION,PRESSURE,HEART,TIME,VIVO",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,,
24,Study on the TB and non-TB diagnosis using two-step deep learning-based binary classifier,15,10,,"Yoo S. H.,Geng H.,Chiu T. L.,Yu S. K.,Cho D. C.,Heo J.,Choi M. S.,Choi I. H.,Cung C. V,Nhung N. V","Yoo SH,Geng H,Chiu TL,Yu SK,Cho DC,Heo J,Choi MS,Choi IH,Cung CV,Nhung NV",Min BJ,10.1088/1748-0221/15/10/P10011,Chungbuk National University,"A deep learning-based binary classifier was proposed to diagnose tuberculosis (TB) and non TB disease using a chest X-ray radiograph. The proposed classifier comprised two-step binary decision trees, each trained by a deep learning model with convolution neural network (CNN) based on the PyTorch frame. Normal and abnormal images of chest X-ray was classified in the first step. The abnormal images were predicted to be classified into TB and non-TB disease by the second step of the process. The accuracies of first and second step were 98% and 80% respectively. Moreover, re-training could improve the stability of prediction accuracy for images in different data groups.","Medical-image reconstruction methods and algorithms,computer-aided diagnosis,X-ray radiography and digital radiography (DR)",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Instruments & Instrumentation,,1.328,"PULMONARY,TUBERCULOSIS,CHEST,RADIOGRAPHS,SEGMENTATION,CLAVICLE",JOURNAL OF INSTRUMENTATION,https://doi.org/10.1088/1748-0221/15/10/p10011,
25,Object classification based on piezoelectric actuator-sensor pair on robot hand using neural network,29,10,,"Chung Jaehoon,Lim Hyeonjung,Lim Myotaeg,Cha Youngsu","Chung J,Lim H,Lim M,Cha Y",Chung J,10.1088/1361-665X/aba540,Korea Institute of Science & Technology (KIST),"We propose a piezoelectric actuator-sensor pair applicable to object classification, which comprises two piezoelectric films on a polyethylene terephthalate substrate layer. One piezoelectric film is used as an actuator, and another as a sensor. The actuator-sensor pair is installed on a robot hand, and a neural network classifier is used to conduct object classification. Sensor data for learning process are acquired when the actuator is oscillating, while the robot hand grasps objects. Specifically, a sinusoidal input voltage with frequency sweep is supplied to the actuator, and the sensor outputs the signal transferred from the actuator simultaneously. The obtained data undergoes a series of preprocessing procedures to be used as data input for learning. Several neural network classifier models are trained with the preprocessed dataset, and the most suitable model is selected as our classifier. Our classifier successfully predicted the object data in the test set. Furthermore, we develop a real-time recognition system and demonstrate the feasibility of the actuator-sensor pair.","actuator-sensor pair,neural network,object classification",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Instruments & Instrumentation,Materials Science",,3.893,RECOGNITION,SMART MATERIALS AND STRUCTURES,,
26,Machine Learning-based Algorithm Enables the Exclusion of Obstructive Coronary Artery Disease in the Patients Who Underwent Coronary Artery Calcium Scoring,27,10,1416-1421,"Glowacki Jan,Krysinski Mateusz,Czaja-Ziolkowska Monika,Wasilewski Jaroslaw","Glowacki J,Krysinski M,Czaja-Ziolkowska M,Wasilewski J",Krysinski M,10.1016/j.acra.2019.11.016,Silesian Center for Heart Diseases,"Rationale and Objectives: An application of artificial intelligence to screen for obstructive coronary artery disease (CAD) after coronary artery calcium scoring (GAGS) test.
Materials and Methods: As an initial step we analyzed a group of 435 patients (23% male, mean age 61 +/- 10) with low to moderate probability of CAD, who underwent clinically indicated CACS and coronary computed tomography angiography. Based on those data we elaborated a gradient boosting machine (GBM) model for prediction of obstructive CAD. Later the model was evaluated on a control group of 126 consecutive patients (31% male, mean age 59 +/- 10).
Results: Stratified 10-fold cross-validation performed on the group of 435 patients demonstrated the GBM model's sensitivity at 100 +/- 0% and specificity at 69.8 +/- 3.6%, while the outcomes (confusion matrix) of a clinical application on the group of 126 patients were: 73 true negative, 0 false negative, 20 true positive, and 33 false positive.
Conclusion: The GBM algorithm showcased a considerably high discriminatory power for excluding the presence of obstructive CAD, with negative predictive value and positive predictive value of 100% and 38%, respectively.","Computed tomography angiography,Coronary stenosis,Coronary artery disease,Machine learning",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.751,"AORTIC,ROOT,CALCIFICATION,ASSOCIATION,PREVALENCE,SEVERITY,ABSENCE,CT",ACADEMIC RADIOLOGY,,
27,Prediction of Benign and Malignant Solid Renal Masses: Machine Learning-Based CT Texture Analysis,27,10,1422-1429,"Erdim Cagri,Yardimci Aytul Hande,Bektas Ceyda Turan,Kocak Burak,Koca Sevim Baykal,Demir Hale,Kilickesmez Ozgur","Erdim C,Yardimci AH,Bektas CT,Kocak B,Koca SB,Demir H,Kilickesmez O",Kocak B,10.1016/j.acra.2019.12.015,Istanbul Training & Research Hospital,"Rationale and Objectives: This study aimed to investigate whether benign and malignant renal solid masses could be distinguished through machine learning (ML)-based computed tomography (CT) texture analysis.
Materials and Methods: Seventy-nine patients with 84 solid renal masses (21 benign; 63 malignant) from a single center were included in this retrospective study. Malignant masses included common renal cell carcinoma (RCC) subtypes: clear cell RCC, papillary cell RCC, and chromophobe RCC. Benign masses are represented by oncocytomas and fat-poor angiomyolipomas. Following preprocessing steps, a total of 271 texture features were extracted from unenhanced and contrast-enhanced CT images. Dimension reduction was done with a reliability analysis and then with a feature selection algorithm. A nested-approach was used for feature selection, model optimization, and validation. Eight ML algorithms were used for the classifications: decision tree, locally weighted teaming, k-nearest neighbors, naive Bayes, logistic regression, support vector machine, neural network, and random forest.
Results: The number of features with good reproducibility was 198 for unenhanced CT and 244 for contrast-enhanced CT. Random forest algorithm demonstrated the best predictive performance using five selected contrast-enhanced CT texture features. The accuracy and area under the curve metrics were 90.5% and 0.915, respectively. Having eliminated the highly collinear features from the analysis, the accuracy and area under the curve values slightly increased to 91.7% and 0.916, respectively.
Conclusion: ML-based contrast-enhanced CT texture analysis might be a potential method for distinguishing benign and malignant solid renal masses with satisfactory performance.","Artificial intelligence,Machine learning,Texture analysis,Radiomics,Renal mass",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.751,"CELL,CARCINOMA,TUMOR,HETEROGENEITY,VISIBLE,FAT,DIFFERENTIATION,ANGIOMYOLIPOMA,DIAGNOSIS,IMAGES",ACADEMIC RADIOLOGY,,
28,Efficient Training of Machine Learning Potentials by a Randomized Atomic-System Generator,124,39,8704-8710,"Choi Young-Jae,Jhi Seung-Hoon","Choi YJ,Jhi SH",Jhi SH,10.1021/acs.jpcb.0c05075,Pohang University of Science & Technology (POSTECH),"Machine learning potentials provide an efficient and comprehensive tool to simulate large-scale systems inaccessible by conventional first-principles methods still in a similar level of accuracy. One critical issue in constructing machine learning potentials is to build training data sets cost-effectively that can represent the potential energy surface in a wide range of configurations. We develop a scheme named randomized atomic-system generator (RAG) to produce the training sets that widely cover the potential energy surface by combining the random sampling and structural optimization. We apply the scheme to construct the machine learning potentials for simulation of chalcogen-based phase change materials. Constructed machine learning potentials successfully simulate the dynamics of melting and crystallization processes of binary GeTe at a level comparable to first-principles simulations. The visual analysis shows that the RAG-generated training set represents the crystallization process including the amorphous phases. From the velocity autocorrelation function obtained from the molecular dynamics simulations, we calculate the phonon density of states to analyze the vibrational properties during crystallization.","FAST CRYSTALLIZATION,MOLECULAR-DYNAMICS",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,3.051,"FAST,CRYSTALLIZATION,MOLECULAR-DYNAMICS",JOURNAL OF PHYSICAL CHEMISTRY B,,
29,Evolution of Operations Management Research: from Managing Flows to Building Capabilities,29,10,2219-2229,"Zhang Fuqiang,Wu Xiaole,Tang Christopher S.,Feng Tianjun,Dai Yue","Zhang FQ,Wu XL,Tang CS,Feng TJ,Dai Y",Dai Y,10.1111/poms.13231,Fudan University,"This forum study examines the past and the future of Operations Management (OM) research. First, we investigate the evolution of OM research from 1997 to 2018 by using machine learning tools to analyze all OM papers published in five journals (JOM, MS, M&SOM, POM, and OR), and find that the number of information/financial flow-focused OM research papers has increased steadily over the years. Second, we present three research topics motivated by the US-China trade war and the Covid-19 pandemic, and postulate that future OM research is likely to involve all three flows: material, information, and financial flows. Finally, we argue that, to achieve operational efficiency, resilience, and sustainability in the Industry 4.0 era, firms should build (or strengthen) three new capabilities:Connectivity, Clarity, and Continuity. As firms develop new ways to build these new capabilities, more innovative OM research ideas will ensue.","operations management,supply chain management,research trends,flow,ecosystem",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Operations Research & Management Science",,5.298,CHAIN,PRODUCTION AND OPERATIONS MANAGEMENT,,
30,HSMA_WOA: A hybrid novel Slime mould algorithm with whale optimization algorithm for tackling the image segmentation problem of chest X-ray images,95,,,"Abdel-Basset Mohamed,Chang Victor,Mohamed Reda","Abdel-Basset M,Chang V,Mohamed R",Chang V,10.1016/j.asoc.2020.106642,University of Teesside,"Recently, a novel virus called COVID-19 has pervasive worldwide, starting from China and moving to all the world to eliminate a lot of persons. Many attempts have been experimented to identify the infection with COVID-19. The X-ray images were one of the attempts to detect the influence of COVID-19 on the infected persons from involving those experiments. According to the X-ray analysis, bilateral pulmonary parenchymal ground-glass and consolidative pulmonary opacities can be caused by COVID-19 - sometimes with a rounded morphology and a peripheral lung distribution. But unfortunately, the specification or if the person infected with COVID-19 or not is so hard under the X-ray images. X-ray images could be classified using the machine learning techniques to specify if the person infected severely, mild, or not infected. To improve the classification accuracy of the machine learning, the region of interest within the image that contains the features of COVID-19 must be extracted. This problem is called the image segmentation problem (ISP). Many techniques have been proposed to overcome ISP. The most commonly used technique due to its simplicity, speed, and accuracy are threshold-based segmentation. This paper proposes a new hybrid approach based on the thresholding technique to overcome ISP for COVID-19 chest X-ray images by integrating a novel meta-heuristic algorithm known as a slime mold algorithm (SMA) with the whale optimization algorithm to maximize the Kapur's entropy. The performance of integrated SMA has been evaluated on 12 chest X-ray images with threshold levels up to 30 and compared with five algorithms: Lshade algorithm, whale optimization algorithm (WOA), FireFly algorithm (FFA), Harris-hawks algorithm (HHA), salp swarm algorithms (SSA), and the standard SMA. The experimental results demonstrate that the proposed algorithm outperforms SMA under Kapur's entropy for all the metrics used and the standard SMA could perform better than the other algorithms in the comparison under all the metrics. (C) 2020 Elsevier B.V. All rights reserved.","Image segmentation problem,Slime mould algorithm (SMA),Whale optimization algorithm,Kapur's entropy,X-ray images,COVID-19",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,6.607,"MULTILEVEL,ENTROPY",APPLIED SOFT COMPUTING,https://research.tees.ac.uk/ws/files/25070831/AI_COVID_19_ASOCO_final.pdf,
31,SRAF Insertion via Supervised Dictionary Learning,39,10,2849-2859,"Geng Hao,Zhong Wei,Yang Haoyu,Ma Yuzhe,Mitra Joydeep,Yu Bei","Geng H,Zhong W,Yang HY,Ma YZ,Mitra J,Yu B",Geng H; Yu B,10.1109/TCAD.2019.2943568,Chinese University of Hong Kong,"In modern VLSI design flow, subresolution assist feature (SRAF) insertion is one of the resolution enhancement techniques (RETs) to improve chip manufacturing yield. With aggressive feature size continuously scaling down, layout feature learning becomes extremely critical. In this article, for the first time, we enhance conventional manual feature construction, by proposing a supervised online dictionary learning algorithm for simultaneous feature extraction and dimensionality reduction. By taking advantage of label information, the proposed dictionary learning framework can discriminatively and accurately represent the input data. We further consider SRAF design rules in a global view, and design two integer linear programming models in the post-processing stage of SRAF insertion framework. The experimental results demonstrate that, compared with a state-of-the-art SRAF insertion tool, our framework not only boosts the performance of the machine learning model but also improves the mask optimization quality in terms of edge placement error (EPE) and process variation (PV) band area.","Feature extraction,Machine learning,Layout,Optimization,Printing,Dictionaries,Measurement,Design for manufacturability,machine learning,subresolution assist feature (SRAF) insertion,supervised dictionary learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,2.702,"REGULARIZATION,CONVERGENCE,SHRINKAGE,ALGORITHM",IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS,,
32,A Novel Attribute-Based Symmetric Multiple Instance Learning for Histopathological Image Analysis,39,10,3125-3136,"Vu Trung,Lai Phung,Raich Raviv,Pham Anh,Fern Xiaoli Z.,Rao U. K. Arvind","Vu T,Lai P,Raich R,Pham A,Fern XZ,Rao UKA",Vu T,10.1109/TMI.2020.2987796,Oregon State University,"Histopathological image analysis is a challenging task due to a diverse histology feature set as well as due to the presence of large non-informative regions in whole slide images. In this paper, we propose a multiple-instance learning (MIL) method for image-level classification as well as for annotating relevant regions in the image. In MIL, a common assumption is that negative bags contain only negative instances while positive bags contain one or more positive instances. This asymmetric assumption may be inappropriate for some application scenarios where negative bags also contain representative negative instances. We introduce a novel symmetric MIL framework associating each instance in a bag with an attribute which can be either negative, positive, or irrelevant. We extend the notion of relevance by introducing control over the number of relevant instances. We develop a probabilistic graphical model that incorporates the aforementioned paradigm and a corresponding computationally efficient inference for learning the model parameters and obtaining an instance level attribute-learning classifier. The effectiveness of the proposed method is evaluated on available histopathology datasets with promising results.","Cancer,Image analysis,Training,Task analysis,Support vector machines,Image segmentation,Computational modeling,Histopathological image analysis,multiple instance learning,symmetric setting,attribute learning,cardinality constraints,dynamic programming",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CLASSIFICATION,SEGMENTATION",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7561004,
33,Improving Prostate Cancer (PCa) Classification Performance by Using Three-Player Minimax Game to Reduce Data Source Heterogeneity,39,10,3148-3158,"Shao Yanan,Wang Jane,Wodlinger Brian,Salcudean Septimiu E.","Shao YN,Wang JE,Wodlinger B,Salcudean SE",Shao YN,10.1109/TMI.2020.2988198,University of British Columbia,"PCa is a disease with a wide range of tissue patterns and this adds to its classification difficulty. Moreover, the data source heterogeneity, i.e. inconsistent data collected using different machines, under different conditions, by different operators, from patients of different ethnic groups, etc., further hinders the effectiveness of training a generalized PCa classifier. In this paper, for the first time, a Generative Adversarial Network (GAN)-based three-player minimax game framework is used to tackle data source heterogeneity and to improve PCa classification performance, where a proposed modified U-Net is used as the encoder. Our dataset consists of novel high-frequency ExactVu ultrasound (US) data collected from 693 patients at five data centers. Gleason Scores (GSs) are assigned to the 12 prostatic regions of each patient. Two classification tasks: benign vs. malignant and low- vs. high-grade, are conducted and the classification results of different prostatic regions are compared. For benign vs. malignant classification, the three-player minimax game framework achieves an Area Under the Receiver Operating Characteristic (AUC) of 93.4%, a sensitivity of 95.1% and a specificity of 87.7%, respectively, representing significant improvements of 5.0%, 3.9%, and 6.0% compared to those of using heterogeneous data, which confirms its effectiveness in terms of PCa classification.","Principal component analysis,Feature extraction,Biopsy,Cancer,Games,Gallium nitride,Radio frequency,Data source heterogeneity,ExactVu,GAN,modified U-Net,PCa classification,three-player minimax game,US",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"RF,TIME-SERIES,ULTRASOUND,RISK,MRI",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
34,Learning an Attention Model for Robust 2-D/3-D Registration Using Point-To-Plane Correspondences,39,10,3159-3174,"Schaffert Roman,Wang Jian,Fischer Peter,Borsdorf Anja,Maier Andreas","Schaffert R,Wang J,Fischer P,Borsdorf A,Maier A",Schaffert R,10.1109/TMI.2020.2988410,University of Erlangen Nuremberg,"Minimally invasive procedures rely on image guidance for navigation at the operation site to avoid large surgical incisions. X-ray images are often used for guidance, but important structures may be not well visible. These structures can be overlaid from pre-operative 3-D images and accurate alignment can be established using 2-D/3-D registration. Registration based on the point-to-plane correspondence model was recently proposed and shown to achieve state-of-the-art performance. However, registration may still fail in challenging cases due to a large portion of outliers. In this paper, we describe a learning-based correspondence weighting scheme to improve the registration performance. By learning an attention model, inlier correspondences get higher attention in the motion estimation while the outlier correspondences are suppressed. Instead of using per-correspondence labels, our objective function allows to train the model directly by minimizing the registration error. We demonstrate a highly increased robustness, e.g. increasing the success rate from 84.9% to 97.0% for spine registration. In contrast to previously proposed learning-based methods, we also achieve a high accuracy of around 0.5mm mean re-projection distance. In addition, our method requires a relatively small amount of training data, is able to learn from simulated data, and generalizes to images with additional structures which are not present during training. Furthermore, a single model can be trained for both, different views and different anatomical structures.","Robustness,Training,X-ray imaging,Motion estimation,Linear programming,Optimization,Training data,Rigid 2-D,3-D registration,point-to-plane correspondence model,deep learning,attention model,spine registration,head registration",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"IMAGE,REGISTRATION",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
35,High-accuracy inverse optical design by combining machine learning and knowledge-depended optimization,22,10,,"Zhang Shikun,Bian Liheng,Zhang Yongyou","Zhang SK,Bian LH,Zhang YY",Zhang YY,10.1088/2040-8986/abb1ce,Beijing Institute of Technology,"With respect to knowledge-dependent approaches (KDAs) that require optimization in the high-dimensional parameter space, data-driven methods (DDMs) show remarkable generalization and diversity but commonly with unsatisfactory accuracy for complex systems. To overcome the imperfections of the KDAs and DDMs, we suggest a composite scheme by combining them, which not only alleviates the optimization burden but also presents a remarkable generalization and accuracy. This composite scheme as an example is applied to design one-dimensional photonic crystals (1DPCs) from the transmission spectra, which first determines the 1DPC type by a classification neural network, then predicts the layer thicknesses of that 1DPC by a generative adversarial network (GAN), and finally further optimizes the layer thicknesses by the KDA that is based on the method of least squares and starts from the results of the KDA. Numerical results yield that the third step can improve more than 12% for the prediction accuracy with respect to the GAN for complex 1DPCs, resulting in the overall successful prediction probability being able to reach 96.8%. Since the scheme combines the KDAs and DDMs, it has remarkable generalization and high accuracy and provides a potential alternative for the efficient inverse design.","inverse optical design,machine learning,neural network",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Optics,,2.402,"DEEP,NEURAL-NETWORKS,SYSTEMS,COHERENT,LIGHT",JOURNAL OF OPTICS,,
36,Machine learning for faster and smarter fluorescence lifetime imaging microscopy,2,4,,"Mannam Varun,Zhang Yide,Yuan Xiaotong,Ravasio Cara,Howard Scott S.","Mannam V,Zhang YD,Yuan XT,Ravasio C,Howard SS",Howard SS,10.1088/2515-7647/abac1a,University of Notre Dame,"Fluorescence lifetime imaging microscopy (FLIM) is a powerful technique in biomedical research that uses the fluorophore decay rate to provide additional contrast in fluorescence microscopy. However, at present, the calculation, analysis, and interpretation of FLIM is a complex, slow, and computationally expensive process. Machine learning (ML) techniques are well suited to extract and interpret measurements from multi-dimensional FLIM data sets with substantial improvement in speed over conventional methods. In this topical review, we first discuss the basics of FILM and ML. Second, we provide a summary of lifetime extraction strategies using ML and its applications in classifying and segmenting FILM images with higher accuracy compared to conventional methods. Finally, we discuss two potential directions to improve FLIM with ML with proof of concept demonstrations.","microscopy,fluorescence lifetime imaging microscopy,machine learning,convolutional neural network,deep learning,classification,segmentation",Review,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Optics,Physics",,,"RESONANCE,ENERGY-TRANSFER,MEAN-DELAY,METHOD,TO-NOISE,RATIO,MULTIPHOTON,MICROSCOPY,OXYGEN,MICROSCOPY,PRECISION,ACCURACY",JOURNAL OF PHYSICS-PHOTONICS,https://authors.library.caltech.edu/105563/1/Mannam_2020_J._Phys._Photonics_2_042005.pdf,
37,Deep Convolutional Neural Networks as a Rapid Screening Tool for Complex Additively Manufactured Structures,35,,,"Garland Anthony P.,White Benjamin C.,Jared Bradley H.,Heiden Michael,Donahue Emily,Boyce Brad L.","Garland AP,White BC,Jared BH,Heiden M,Donahue E,Boyce BL",Boyce BL,10.1016/j.addma.2020.101217,"Sandia Natl Labs, Mat Phys & Chem Sci Ctr, Albuquerque 87185, NM, Mexico.","Additively manufactured metamaterials such as lattices offer unique physical properties such as high specific strengths and stiffnesses. However, additively manufactured parts, including lattices, exhibit a higher variability in their mechanical properties than wrought materials, placing more stringent demands on inspection, part quality verification, and product qualification. Previous research on anomaly detection has primarily focused on using in-situ monitoring of the additive manufacturing process or post-process (ex-situ) x-ray computed tomography. In this work, we show that convolutional neural networks (CNN), a machine learning algorithm, can directly predict the energy required to compressively deform gyroid and octet truss metamaterials using only optical images. Using the filed nature of engineered lattices, the relatively small data set (43 to 48 lattices) can be augmented by systematically subdividing the original image into many smaller sub-images. During testing of the CNN, the prediction from these sub-images can be combined using an ensemble-like technique to predict the deformation work of the entire lattice. This approach provides a fast and inexpensive screening tool for predicting properties of 3D printed lattices. Importantly, this artificial intelligence strategy goes beyond 'inspection', since it accurately estimates product performance metrics, not just the existence of defects.","ANOMALY DETECTION,DESIGN,CLASSIFICATION,METROLOGY",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science",,12.363,"ANOMALY,DETECTION,DESIGN,CLASSIFICATION,METROLOGY",ADDITIVE MANUFACTURING,https://www.osti.gov/biblio/1639094,
38,Residual stresses in wire-arc additive manufacturing - Hierarchy of influential variables,35,,,"Wu Q.,Mukherjee T.,De A.,DebRoy T.","Wu Q,Mukherjee T,De A,DebRoy T",DebRoy T,10.1016/j.addma.2020.101355,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Residual stresses and distortion are common serious defects in wire-arc additive manufacturing. Commercial thermomechanical models are often used to understand how these defects form. However, no clear mitigation strategy has evolved from previous research. Identification of the hierarchy of variables that influence residual stresses will help to uncover practical means of mitigating this difficulty. Here we use multiple machine learning algorithms and a mechanistic model to rank separately both easy to measure process parameters as well as thermomechanical variables that affect the evolution of stresses. We analyze 243 sets of residual stress data for three alloys using random forest and neural network algorithms to uncover the relative influences of the variables. Both these algorithms predict residual stresses with 97 % accuracy. More important, both algorithms provide the same hierarchical influence of process variables on stresses. The substrate preheat temperature is the most influential variable among the process variables. Among the thermomechanical variables, the following variables are the most influential in decreasing order of importance: the gap between the solidus and preheat temperatures, the product of elastic modulus and the coefficient of thermal expansion, molten pool volume, substrate rigidity, and heat input.","Wire-arc additive manufacturing,Residual stresses,Machine learning,Neural network,Random forest,Delamination",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science",,12.363,"DISTORTION,PREDICTION,TOOL",ADDITIVE MANUFACTURING,,
39,A meltpool prediction based scan strategy for powder bed fusion additive manufacturing,35,,,"Yeung H.,Yang Z.,Yan L.","Yeung H,Yang Z,Yan L",Yeung H,10.1016/j.addma.2020.101383,National Institute of Standards & Technology (NIST) - USA,"In this study a feedforward control method for laser powder bed fusion additive manufacturing is demonstrated. It minimizes the meltpool variation by updating the laser power based on a data-driven predictive meltpool model. A rectangular pattern is scanned multiple times on a customized LPBF testbed. The meltpool is monitored in situ by a high-speed camera, optically aligned with the heating laser. Constant laser power is applied for the first scan, and its meltpool images are used to train the model and adjust the laser power for the following scans. The meltpool images from these scans are compared, and a significant reduction in meltpool variation is achieved.","Additive manufacturing,Scan strategies,Feedforward control,Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science",,12.363,"LASER,POOL,POROSITY,SPATTER",ADDITIVE MANUFACTURING,,
40,Assessment of compressive strength of Ultra-high Performance Concrete using deep machine learning techniques,95,,,"Abuodeh Omar R.,Abdalla Jamal A.,Hawileh Rami A.","Abuodeh OR,Abdalla JA,Hawileh RA",Abuodeh OR,10.1016/j.asoc.2020.106552,Clemson University,"The compressive strength of Ultra-High Performance Concrete (UHPC) is a function of the type, property and quantities of its material constituents. Empirically capturing this relationship often requires the utilization of intelligent algorithms, such as the Artificial Neural Network (ANN), to derive a predictive model that fits into an experimental dataset. However, its black-box nature prevents researchers from mathematically describing its contents. This paper attempts to address this ambiguity by employing two deep machine learning techniques - Sequential Feature Selection (SFS) and Neural Interpretation Diagram (NID) - to identify the critical material constituents that affect the ANN. 110 UHPC compressive strength tests varying based on the material quantities were compiled into a database to train the ANN. As a result, four material constituents were selected; mainly, cement, fly ash, silica fume and water. These material constituents were then employed into the ANN to compute more accurate predictions (r(2) = 80.1% and NMSE = 0.012) than the model with all eight material constituents (r(2) = 21.5% and NMSE = 0.035). Finally, a nonlinear regression model based on the four selected material constituents was developed and a parametric study was conducted. It was concluded that the utilization of ANN with SFS and NID drastically improved the accuracy of the model, and provided valuable insights on the ANN compressive strength predictions for different UHPC mixes. (C) 2020 Elsevier B.V. All rights reserved.","Compressive strength,Ultra-High Performance Concrete,Sequential Feature selection,Neural Interpretation Diagrams",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,6.607,"ARTIFICIAL,NEURAL-NETWORK,REACTIVE,POWDER,CONCRETE,FEATURE-SELECTION,FATIGUE,LIFE,RC,BEAMS,MECHANICAL-PROPERTIES,MATERIAL,EFFICIENCY,SHEAR-STRENGTH,PREDICTION,TENSILE",APPLIED SOFT COMPUTING,,
41,Bimodal affect recognition based on autoregressive hidden Markov models from physiological signals,195,,,"Akbulut Fatma Patlar,Perros Harry G.,Shahzad Muhammad","Akbulut FP,Perros HG,Shahzad M",Akbulut FP,10.1016/j.cmpb.2020.105571,Istanbul Kultur University,"Background and objective: Affect provides contextual information about the emotional state of a person as he/she communicates in both verbal and/or non-verbal forms. While human's are great at determining the emotional state of people while they communicate in person, it is challenging and still largely an unsolved problem to computationally determine the emotional state of a person.
Methods: Emotional states of a person manifest in the physiological biosignals such as electrocardiogram (ECG) and electrodermal activity (EDA) because these signals are impacted by the peripheral nervous system of the body, and the peripheral nervous system is strongly coupled with the mental state of the person. In this paper, we present a method to accurately recognize six emotions using ECG and EDA signals and applying autoregressive hidden Markov models (AR-HMMs) and heart rate variability analysis on these signals. The six emotions include happiness, sadness, surprise, fear, anger, and disgust.
Results: We evaluated our method on a comprehensive new dataset collected from 30 participants. Our results show that our proposed method achieves an average accuracy of 88.6% in distinguishing across the 6 emotions.
Conclusions: The key technical depth of the paper is in the use of the AR-HMMs to model the EDA signal and the use of LDA to enable accurate emotion recognition without requiring a large number of training samples. Unlike other studies, we have taken a hierarchical approach to classify emotions, where we first categorize the emotion as either positive or negative and then identify the exact emotion. (c) 2020 Elsevier B.V. All rights reserved.","Affect recognition,Autoregressive hidden Markov models,Machine learning,Biosignals,Heart rate variability",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"HEART-RATE-VARIABILITY,EMOTION,RECOGNITION,ANXIETY",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
42,Prediction of survival outcome based on clinical features and pretreatment (18)FDG-PET/CT for HNSCC patients,195,,,"Ghosh Sayantani,Maulik Shaurav,Chatterjee Sanjoy,Mallick Indranil,Chakravorty Nishant,Mukherjee Jayanta","Ghosh S,Maulik S,Chatterjee S,Mallick I,Chakravorty N,Mukherjee J",Mukherjee J,10.1016/j.cmpb.2020.105669,Indian Institute of Technology System (IIT System),"Background and objective: In this study, we have analysed pretreatment positron-emission tomography/computed tomography (PET/CT) images of head and neck squamous cell carcinoma (HNSCC) patients. We have used a publicly available dataset for our analysis. The clinical features of the patient, PET quantitative parameters, and textural indices from pretreatment PET-CT images are selected for the study. The main objective of the study is to use classifiers to predict the outcome for HNSCC patients and compare the performance of the model with the conventional statistical model (CoxPH).
Methods: We have applied a 40% fixed SUV threshold method for tumour delineation. Clinical features of each patient are provided in the dataset, and other features are calculated using LIFEx software. For predicting the outcome, we have implemented three classifiers - Random Forest classifier, Gradient Boosted Decision tree (GBDT) and Decision tree classifier. We have trained each model using 93 data points and test the model performance using 39 data points. The best model - GBDT is chosen based on the performance metrics.
Results: It is observed that typically three features: MTV (Metabolic tumour Volume), primary tumour site and GLCM_correlation are significant for prediction of survival outcome. For testing cohort, GBDT achieves a balanced accuracy of 88%, where conventional statistical model reported a balanced accuracy of 81.5%.
Conclusions: The proposed classifier achieves higher accuracy than the state of the art technique. Using this classifier we can estimate the HNSCC patient's outcome, and depending upon the outcome treatment policy can be selected. (C) 2020 Elsevier B.V. All rights reserved.","Head and neck squamous cell carcinoma,Pretreatment F-18 FDG-PET/CT,Machine learning,Classification",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,,"SQUAMOUS-CELL,CARCINOMA,PROGNOSTIC,VALUE,NECK-CANCER,HEAD,PET,RADIOTHERAPY",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
43,A deep learning system to obtain the optimal parameters for a threshold-based breast and dense tissue segmentation,195,,,"Javier Perez-Benito Francisco,Signol Francois,Perez-Cortes Juan-Carlos,Fuster-Baggetto Alejandro,Pollan Marina,Perez-Gomez Beatriz,Salas-Trejo Dolores,Casals Maria,Martinez Inmaculada,LLobet Rafael","Perez-Benito FJ,Signol F,Perez-Cortes JC,Fuster-Baggetto A,Pollan M,Perez-Gomez B,Salas-Trejo D,Casals M,Martinez I,LLobet R",Perez-Benito FJ,10.1016/j.cmpb.2020.105668,Universitat Politecnica de Valencia,"Background and Objective: Breast cancer is the most frequent cancer in women. The Spanish healthcare network established population-based screening programs in all Autonomous Communities, where mammograms of asymptomatic women are taken with early diagnosis purposes. Breast density assessed from digital mammograms is a biomarker known to be related to a higher risk to develop breast cancer.
It is thus crucial to provide a reliable method to measure breast density from mammograms. Furthermore the complete automation of this segmentation process is becoming fundamental as the amount of mammograms increases every day. Important challenges are related with the differences in images from different devices and the lack of an objective gold standard.
This paper presents a fully automated framework based on deep learning to estimate the breast density. The framework covers breast detection, pectoral muscle exclusion, and fibroglandular tissue segmentation.
Methods: A multi-center study, composed of 1785 women whose ""for presentation"" mammograms were segmented by two experienced radiologists. A total of 4992 of the 6680 mammograms were used as training corpus and the remaining (1688) formed the test corpus. This paper presents a histogram normalization step that smoothed the difference between acquisition, a regression architecture that learned segmentation parameters as intrinsic image features and a loss function based on the DICE score.
Results: The results obtained indicate that the level of concordance (DICE score) reached by the two radiologists (0.77) was also achieved by the automated framework when it was compared to the closest breast segmentation from the radiologists. For the acquired with the highest quality device, the DICE score per acquisition device reached 0.84, while the concordance between radiologists was 0.76.
Conclusions: An automatic breast density estimator based on deep learning exhibits similar performance when compared with two experienced radiologists. It suggests that this system could be used to support radiologists to ease its work. (c) 2020 Elsevier B.V. All rights reserved.","Breast density,Entirely convolutional neural network (ECNN),Deep learning,Dense tissue segmentation,Mammography",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"MAMMOGRAPHIC,DENSITY,DIGITAL,MAMMOGRAPHY,CLASSIFICATION",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,https://riunet.upv.es/bitstream/10251/168615/7/Perez-Bento%3bSgnol%3bPerez-Cortes%20-%20A%20deep%20learnng%20system%20to%20obtan%20the%20optmal%20parameters%20for%20a%20thres....pdf,
44,Continuous Eulerian tool path strategies for wire-arc additive manufacturing of rib-web structures with machine-learning-based adaptive void filling,35,,,"Nguyen Lam,Buhl Johannes,Bambach Markus","Nguyen L,Buhl J,Bambach M",Nguyen L,10.1016/j.addma.2020.101265,Brandenburg University of Technology Cottbus,"Rib-web structures are used for lightweight design in various applications. The most prominent cases are found in aerospace engineering, where intricate structures are produced by forging and subsequent machining or by machining from solid blocks of material. Due to the large scrap rate involved in conventional manufacturing, ribweb structures are suitable applications for additive manufacturing (AM) processes. Among the AM processes, wire-arc additive manufacturing (WAAM) is highly suitable for rib-web structures due to its high deposition rate and the potential to manufacture large-size parts. In WAAM, the welding strategy greatly influences the properties and quality of deposited parts. With an increasing number of starts and stops, the danger of uneven material build-up and welding defects increases. Unfortunately, most rib-web structures do not represent Eulerian paths, i.e. they cannot be manufactured with a continuous welding motion, in which every edge is visited only once. This study presents a novel strategy for generating optimal tool paths for WAAM of lightweight rib-web structures, mitigating the disadvantages of discontinuous welding paths such as welding defects and uneven build-up. It is shown that doubling the number of welding passes on each edge of the rib-web structure turns non-Eulerian paths into Eulerian paths, which can be welded continuously. When two or more weld beads are deposited on each edge, the vertices of the rib-web structure may suffer from underfilling. It is shown that this can be avoided by a correction strategy, which consists in manufacturing the part once, evaluating the size of voids in the junctions, and computing a correction to deposit the required amount of material into the center of the junction. While this strategy may be used if a single part is considered, it is shown that the tool path correction to be applied to arbitrary junction geometries can be represented by a neural network that is derived from an experimental database consisting of representative junction types. With this approach, paths for any rib-web geometry can be generated, which saves lead time in variant-rich production. The paths proposed in this work avoid non-welding moves and may hence outperform even single weld-bed strategies in terms of welding efficiency.","Additive manufacturing,WAAM,Lightweight structures,Adaptive void filling,Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science",,12.363,"DEPOSITION,OPTIMIZATION",ADDITIVE MANUFACTURING,,
45,Modelling and understanding battery materials with machine-learning-driven atomistic simulations,2,4,,Deringer Volker L.,Deringer VL,Deringer VL,10.1088/2515-7655/abb011,University of Oxford,"The realistic computer modelling of battery materials is an important research goal, with open questions ranging from atomic-scale structure and dynamics to macroscopic phenomena. Quantum-mechanical methods offer high accuracy and predictive power in small-scale atomistic simulations, but they quickly reach their limits when complex electrochemical systems are to be studied-for example, when structural disorder or even fully amorphous phases are present, or when reactions take place at the interface between electrodes and electrolytes. In this Perspective, it is argued that emerging machine learning based interatomic potentials are promising tools for studying battery materials on the atomistic and nanometre length scales, affording quantum-mechanical accuracy yet being many orders of magnitude faster, and thereby extending the capabilities of current battery modelling methodology. Initial applications to solid-state electrolyte and anode materials in lithium-ion batteries are highlighted, and future directions and possible synergies with experiments are discussed.","battery materials,energy storage,lithium-ion batteries,machine learning,materials modelling",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Energy & Fuels,Materials Science",,5.967,"DENSITY-FUNCTIONAL,THEORY,X-RAY,SPECTROSCOPY,INTERATOMIC,POTENTIALS,CARBONACEOUS,MATERIALS,COMBINING,EXPERIMENTS,CATHODE,MATERIALS,AB-INITIO,ION,LITHIUM,NMR",JOURNAL OF PHYSICS-ENERGY,https://doi.org/10.1088/2515-7655/abb011,
46,Accelerated design of L1(2)-strengthened Co-base superalloys based on machine learning of experimental data,195,,,"Yu Jinxin,Wang Chenglei,Chen Yuechao,Wang Cuiping,Liu Xingjun","Yu JX,Wang CL,Chen YC,Wang CP,Liu XJ",Wang CP,10.1016/j.matdes.2020.108996,Xiamen University,"Co-base superalloys strengthened by gamma' precipitates have been regarded as a candidate for aircraft engines. However, its gamma' precipitates are not stable. Moreover, improving its properties experimentally could spend a lot of time. DFT and thermodynamic calculation also have disadvantages, which could not accelerate the designing process of Co-base superalloys significantly. Thus, a new strategy is needed to predict the properties of the superalloys rapidly and accurately. In this study, an accelerated design strategy is applied to find the Co-base superalloys with good properties. Four important properties, which are the existence of gamma' and other phases, the gamma' solvus temperature and area fraction are predicted based on machine learning-based models. Samples used in this study are experimental data collected from related references and our previous study. Afterwards, four predicting models are integrated to design the superalloys that meet the designing requirements of four properties simultaneously. Finally, six groups are chosen from 363,000 possible candidates and all of six are experimental validated. New Co-base superalloys with high gamma' solvus temperature and high gamma' area fraction are designed successfully. Our strategy is suitable for the rapid multi-properties design of other advanced materials. (C) 2020 Published by Elsevier Ltd.","Cobalt-base superalloys,Microstructures,Modelling,Machine learning,Multi-properties optimization",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Materials Science,,7.097,"ALLOYING,ELEMENTS,TRANSFORMATION,TEMPERATURES,MECHANICAL-PROPERTIES,BEHAVIOR,TA",MATERIALS & DESIGN,https://doi.org/10.1016/j.matdes.2020.108996,
47,Machine-learning-assisted search for functional materials over extended chemical space,7,10,2710-2718,"Korolev Vadim,Mitrofanov Artem,Eliseev Artem,Tkachenko Valery","Korolev V,Mitrofanov A,Eliseev A,Tkachenko V",Korolev V,10.1039/d0mh00881h,"Sci Data Software LLC, 14909 Forest Landing Circle, Rockville, MD 20850 USA.","Materials discovery is a grand challenge for modern materials science. In particular, inverse materials design is aimed at the accelerated search for materials with human-defined target properties. Unfortunately, this is associated with various obstacles, such as incremental improvements of known compounds, unreported properties of synthesized materials, and chemically plausible ""missing compounds."" A machine-learning-based approach using unified compositional-structural representations is proposed to overcome the issues mentioned above. The validity of the proposed method has been approved by searching for functional materials-some previously known phases were ""re-discovered."" In addition to well-known superhard compounds, unconventional structures that have never been considered in this context were also presented. Analysis of the generated populations provided insights into the underlying quantitative structure-property relationships. This data-driven approach can be successfully applied to discover materials with arbitrary functionalities given a reliable experimental/computational database for the target property.","DESIGN,COMPRESSIBILITY,OPTIMIZATION,DISCOVERY",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Materials Science",,14.931,"DESIGN,COMPRESSIBILITY,OPTIMIZATION,DISCOVERY",MATERIALS HORIZONS,,
48,Invariant Transform Experience Replay: Data Augmentation for Deep Reinforcement Learning,5,4,6615-6622,"Lin Yijiong,Huang Jiancong,Zimmer Matthieu,Guan Yisheng,Rojas Juan,Weng Paul","Lin YJ,Huang JC,Zimmer M,Guan YS,Rojas J,Weng P",Weng P,10.1109/LRA.2020.3013937,Shanghai Jiao Tong University,"Deep Reinforcement Learning (RL) is a promising approach for adaptive robot control, but its current application to robotics is currently hindered by high sample requirements. To alleviate this issue, we propose to exploit the symmetries present in robotic tasks. Intuitively, symmetries from observed trajectories define transformations that leave the space of feasible RL trajectories invariant and can be used to generate new feasible trajectories, which could be used for training. Based on this data augmentation idea, we formulate a general framework, called Invariant Transform Experience Replay that we present with two techniques: (i) Kaleidoscope Experience Replay exploits reflectional symmetries and (ii) Goal-augmented Experience Replay which takes advantage of lax goal definitions. In the Fetch tasks from OpenAI Gym, our experimental results show significant increases in learning rates and success rates. Particularly, we attain a 13, 3, and 5 times speedup in the pushing, sliding, and pick-and-place tasks respectively in the multi-goal setting. Performance gains are also observed in similar tasks with obstacles and we successfully deployed a trained policy on a real Baxter robot. Our work demonstrates that invariant transformations on RL trajectories are a promising methodology to speed up learning in deep RL. Code, video, and supplementary materials are available at [1].","AI-based methods,reinforcement learning,deep learning,dexterous manipulation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,,IEEE ROBOTICS AND AUTOMATION LETTERS,http://arxiv.org/pdf/1909.10707,
49,Generative Principal Component Thermography for Enhanced Defect Detection and Analysis,69,10,8261-8269,"Liu Kaixin,Li Yingjie,Yang Jianguo,Liu Yi,Yao Yuan","Liu KX,Li YJ,Yang JG,Liu Y,Yao Y",Liu Y,10.1109/TIM.2020.2992873,Zhejiang University of Technology,"Machine learning methods play an important role in the nondestructive testing field for quality assessment of polymer composites. As a popular deep learning branch, a generative adversarial network is introduced to the thermography field as an image augmentation approach to improve its defect detection performance. Specifically, a generative principal component thermography (GPCT) method for defect detection in polymer composites is proposed. By employing the data augmentation strategy, more informative images are generated to enlarge the diversity of the original set of images. The defect detection results can be visualized using a number of interpretable features. Consequently, the defect detection performance of thermographic data analysis can be enhanced to some extent. The experimental results on a carbon fiber reinforced polymer specimen demonstrate the feasibility and advantages of the GPCT method.","Generative adversarial networks,Gallium nitride,Feature extraction,Data analysis,Polymers,Training,Deep learning,Deep learning,generative adversarial network (GAN),nondestructive testing (NDT),polymer composites,thermographic data analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"NONDESTRUCTIVE,EVALUATION,MATRIX,FACTORIZATION,INSPECTION",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
50,Prognostic Implications of Coronary CT Angiography: 2-Year Follow-Up of 6892 Patients,215,4,818-827,"Johnson Kevin M.,Dowe David A.","Johnson KM,Dowe DA",Johnson KM,10.2214/AJR.19.22578,Yale University,"OBJECTIVE. The purpose of this study was to add to evidence of the long-term prognostic value of coronary cis angiography (CCTA) when combined with nonimaging risk factors and to investigate how CCTA can contribute to the decision to start statin therapy.
MATERIALS AND METHODS. Patients underwent CCM in an outpatient setting for a variety of indications. The National Death Index from February 2004 through December 2018 was queried to identify the outcomes of death due to any cause (all-cause mortality) and death due to coronary artery disease. Framingham and machine learning risk estimation models were constructed. Machine learning inputs were generated from radiologists' descriptions of the findings on structured report forms and not directly from the image pixels. Kaplan-Meier survival curves and Cox proportional hazards were calculated. Clinical benefit was assessed on the basis of the potential impact on assignment of statin therapy.
RESULTS. A total of 6892 outpatients were studied, 4452 (64.6%) of whom were men (mean [+/- SD] age, 51.2 +/- 11.1 years) and 2440 (35.4%) of whom were women (mean age, 573 +/- 12.2 years). The median follow-up was 11.9 years. Among the 6892 patients, 569 deaths (8.3%) were attributed to all-cause mortality, and 94 deaths (1.4%) were due to coronary artery disease. Survival showed strong dependence on the extent of coronary atherosclerosis. For all-cause mortality, the AUC was 0.85 (95% CI, 0.83-0.86) for the machine learning risk estimation model versus 0.79 (95% CI, 0.78-0.81) for the Framingham risk estimation model (p < 0.001), and for death due to coronary artery disease, the AUC was 0.87 (95% CI, 0.84-0.91) for the machine learning model versus 0.82 (95% CI, 0.77-0.86) for the Framingham model (p = 0.004). Using machine learning risk estimates, the prescription of statins could more accurately be matched to the burden of coronary disease than when Framingham risk estimates were used.
CONCLUSION. Compared with the Framingham model, the machine learning model improved risk estimation. Similar models might be useful to better target prescription of statins and reduce their overuse.","cardiovascular risk,coronary atherosclerosis,coronary CT angiography,machine learning,statin",Article,"AMER ROENTGEN RAY SOC, 44211 SLATESTONE CT, LEESBURG, VA USA","Radiology, Nuclear Medicine & Medical Imaging",,,"COMPUTED-TOMOGRAPHY,ANGIOGRAPHY,ARTERY-DISEASE,CARDIOVASCULAR,RISK,CLINICAL-OUTCOMES,CURVE,PREDICTION,GUIDELINE,REGISTRY,STATIN,EXTENT",AMERICAN JOURNAL OF ROENTGENOLOGY,,
51,Soft Tissue Sarcoma: Preoperative MRI-Based Radiomics and Machine Learning May Be Accurate Predictors of Histopathologic Grade,215,4,963-969,"Xu Wenjian,Hao Dapeng,Hou Feng,Zhang Dejing,Wang Hexiang","Xu WJ,Hao DP,Hou F,Zhang DJ,Wang HX",Wang HX,10.2214/AJR.19.22147,Qingdao University,"OBJECTIVE. The purpose of this study was to assess the value of radiomics features for differentiating soft tissue sarcomas (STSs) of different histopathologic grades.
MATERIALS AND METHODS. The T1-weighted and fat-suppressed T2-weighted MR images of 70 STSs of varying grades (35 low-grade [grades 1 and 2], 35 high-grade [grade 3]) formed the primary dataset used to train multiple machine learning algorithms for the construction of models for assigning STS grade. The models were tested with a separate validation dataset.
RESULTS. Different machine learning algorithms had different strengths and weaknesses. The best classification algorithm for the prediction of STS grade had a combination of the least absolute shrinkage and selection operator feature selection method and the random forest classification algorithm (AUC, 0.9216; 95% CI, 0.8437-0.9995) in the validation set. The accuracy of the combined methods applied to the validation set was 91.43%; sensitivity, 88.24% and specificity, 9444%.
CONCLUSION. Because of tumor heterogeneity, initial biopsy grade may be an underestimate of the final grade identified in extensive histopathologic analysis of surgical specimens. This creates an urgent need to construct an accurate preoperative approach to grading STS. This radiomics study revealed the optimal machine learning approaches for differentiating STS grades. This capability can enhance the precision of preoperative diagnosis.","diagnosis,machine learning,MRI,soft tissue sarcoma",Article,"AMER ROENTGEN RAY SOC, 44211 SLATESTONE CT, LEESBURG, VA USA","Radiology, Nuclear Medicine & Medical Imaging",,4.073,"NEOADJUVANT,CHEMOTHERAPY,NEEDLE-BIOPSY,DIAGNOSIS,IMAGES,RADIOGENOMICS,HETEROGENEITY,PHASE-3,TUMORS",AMERICAN JOURNAL OF ROENTGENOLOGY,,
52,Image analysis and artificial intelligence in infectious disease diagnostics,26,10,1318-1323,"Smith K. P.,Kirby J. E.","Smith KP,Kirby JE",Kirby JE,10.1016/j.cmi.2020.03.012,Harvard University,"Background: Microbiologists are valued for their time-honed skills in image analysis, including identification of pathogens and inflammatory context in Gram stains, ova and parasite preparations, blood smears and histopathologic slides. They also must classify colony growth on a variety of agar plates for triage and assessment. Recent advances in image analysis, in particular application of artificial intelligence (AI), have the potential to automate these processes and support more timely and accurate diagnoses.
Objectives: To review current AI-based image analysis as applied to clinical microbiology; and to discuss future trends in the field.
Sources: Material sourced for this review included peer-reviewed literature annotated in the PubMed or Google Scholar databases and preprint articles from bioRxiv. Articles describing use of AI for analysis of images used in infectious disease diagnostics were reviewed.
Content: We describe application of machine learning towards analysis of different types of microbiologic image data. Specifically, we outline progress in smear and plate interpretation as well as the potential for AI diagnostic applications in the clinical microbiology laboratory. (C) 2020 European Society of Clinical Microbiology and Infectious Diseases. Published by Elsevier Ltd. All rights reserved.","Artificiall intelligence,Deep learning,Gram stain,Machine learning",Review,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Infectious Diseases,Microbiology",,7.622,"BACTERIAL,VAGINOSIS,CHROMOGENIC,MEDIA",CLINICAL MICROBIOLOGY AND INFECTION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7508855,
53,Dependence between urban morphology and outdoor air temperature: A tropical campus study using random forests algorithm,61,,,"Yu Zhongqi,Chen Shisheng,Wong Nyuk Hien,Ignatius Marcel,Deng Jiyu,He Yueer,Hii Daniel Jun Chung","Yu ZQ,Chen SS,Wong NH,Ignatius M,Deng JY,He YE,Hii DJC",Yu ZQ,10.1016/j.scs.2020.102200,National University of Singapore,"The study proposes a nonparametric approach that uses machine learning to predict outdoor temperatures based on field measurements at the National University of Singapore (NUS) Kent Ridge campus from February 2019 to July 2019. Six urban morphology variables (e.g. BDG, PAVE, WALL, HBDG, SVF, GnPR) were extracted from geographical information system (GIS) maps, three dimensional (3D) model and field surveys. This study compares the predictive power between ordinary least squares linear regression (LR) and machine learning (e.g. random forest (RF)). By using RF as a regression model, the air temperature has a greater RMSE reduction than LR, ranging from 10 % to 33 %. The relationship between outdoor air temperature and urban morphology variables based on non-parametric regression is presented. On average, lower SVF space can reduce the heat on campus. As the WALL increases, the temperature rises, but the changes in day and night are different. Greenery reduces daytime temperature due to the shading of solar radiation, although the shading from trees blocks the release of long-wave radiation from artificial materials at night. The observation indicates nighttime temperature can be reduced by planting low height greenery while keeping SVF unchanged.","Outdoor air temperature,Sky view factor,Green plot ratio,Machine learning,Geographical information system",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Construction & Building Technology,Science & Technology - Other Topics,Energy & Fuels",,7.308,"SKY,VIEW,FACTOR,HEAT-ISLAND,SIMULATION,DESIGN,ENVIRONMENTS,HIGHRISE,CANYONS,STREET,IMPACT,FLUXES",SUSTAINABLE CITIES AND SOCIETY,,
54,Data centric nanocomposites design via mixed-lvariable Bayesian optimization,5,8,1376-1390,"Iyer Akshay,Zhang Yichi,Prasad Aditya,Gupta Praveen,Tao Siyu,Wang Yixing,Prabhune Prajakta,Schadler Linda S.,Brinson L. Catherine,Chen Wei","Iyer A,Zhang YC,Prasad A,Gupta P,Tao SY,Wang YX,Prabhune P,Schadler LS,Brinson LC,Chen W",Chen W,10.1039/d0me00079e,Northwestern University,"With an unprecedented combination of mechanical and electrical properties, polymer nanocomposites have the potential to be widely used across multiple industries. Tailoring nanocomposites to meet application specific requirements remains a challenging task, owing to the vast, mixed-variable design space that includes composition (i.e. choice of polymer, nanoparticle, and surface modification) and microstructures (i.e. dispersion and geometric arrangement of particles) of the nanocomposite material. Modeling properties of the interphase, the region surrounding a nanoparticle, introduces additional complexity to the design process and requires computationally expensive simulations. As a result, previous attempts at designing polymer nanocomposites have focused on finding the optimal microstructure for only a fixed combination of constituents. In this article, we propose a data centric design framework to concurrently identify optimal composition and microstructure using mixed-variable Bayesian optimization. This framework integrates experimental data with state-of-the-art techniques in interphase modeling, microstructure characterization and reconstructions and machine learning. Latent variable Gaussian processes (LVGPs) quantifies the lack-of-data uncertainty over the mixed-variable design space that consists of qualitative and quantitative material design variables. The design of electrically insulating nanocomposites is cast as a multicriteria optimization problem with the goal of maximizing dielectric breakdown strength while minimizing dielectric permittivity and dielectric loss. Within tens of simulations, our method identifies a diverse set of designs on the Pareto frontier indicating the tradeoff between dielectric properties. These findings project data centric design, effectively integrating experimental data with simulations for Bayesian Optimization, as an effective approach for design of engineered material systems.","INTERPHASE,SIMULATION,DISPERSION,MODULUS",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Engineering,Science & Technology - Other Topics,Materials Science",,4.667,"INTERPHASE,SIMULATION,DISPERSION,MODULUS",MOLECULAR SYSTEMS DESIGN & ENGINEERING,,
55,Force-Ultrasound Fusion: Bringing Spine Robotic-US to the Next ,5,4,5661-5668,"Tirindelli Maria,Victorova Maria,Esteban Javier,Kim Seong Tae,Navarro-Alarcon David,Zheng Yong Ping,Navab Nassir","Tirindelli M,Victorova M,Esteban J,Kim ST,Navarro-Alarcon D,Zheng YP,Navab N",Tirindelli M,10.1109/LRA.2020.3009069,Technical University of Munich,"Spine injections are commonly performed in several clinical procedures. The localization of the target vertebral level (i.e. the position of a vertebra in a spine) is typically done by back palpation or under X-ray guidance, yielding either higher chances of procedure failure or exposure to ionizing radiation. Preliminary studies have been conducted in the literature, suggesting that ultrasound imaging may be a precise and safe alternative to X-ray for spine level detection. However, ultrasound data are noisy and complicated to interpret. In this study, a robotic-ultrasound approach for automatic vertebral level detection is introduced. The method relies on the fusion of ultrasound and force data, thus providing both ""tactile"" and visual feedback during the procedure, which results in higher performances in presence of data corruption. A robotic arm automatically scans the volunteer's back along the spine by using force-ultrasound data to locate vertebral levels. The occurrences of vertebral levels are visible on the force trace as peaks, which are enhanced by properly controlling the force applied by the robot on the patient back. Ultrasound data are processed with a Deep Learning method to extract a 1D signal modelling the probabilities of having a vertebra at each location along the spine. Processed force and ultrasound data are fused using both a non deep learning method and a Temporal Convolutional Network to compute the locations of the vertebral levels. The benefits of fusing force and image signals for the identification of vertebrae locations are showcased through extensive evaluation.","Medical robots and systems,computer vision for medical robotics",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,IDENTIFICATION,IEEE ROBOTICS AND AUTOMATION LETTERS,http://arxiv.org/pdf/2002.11404,
56,Learning to Predict Metal Deformations in Hot-Rolling Processes,5,4,6270-6277,"Chavez-Garcia R. Omar,Furger Emian,Kronauer Samuele,Brianza Christian,Scarfo Marco,Diviani Luca,Giusti Alessandro","Chavez-Garcia RO,Furger E,Kronauer S,Brianza C,Scarfo M,Diviani L,Giusti A",Chavez-Garcia RO,10.1109/LRA.2020.3013833,Universita della Svizzera Italiana,"Hot-rolling is a metal forming process that produces a workpiece with a desired target cross-section from an input workpiece through a sequence of plastic deformations; each deformation is generated by a stand composed of opposing rolls with a specific geometry. In current practice, the rolling sequence (i.e., the sequence of stands and the geometry of their rolls) needed to achieve a given final cross-section is designed by experts based on previous experience, and iteratively refined in a costly trial-and-error process. Finite Element Method simulations are increasingly adopted to make this process more efficient and to test potential rolling sequences, achieving good accuracy at the cost of long simulation times, limiting the practical use of the approach. We propose a supervised learning approach to predict the deformation of a given workpiece by a set of rolls with a given geometry; the model is trained on a large dataset of procedurally-generated FEM simulations, which we publish as supplementary material. The resulting predictor is four orders of magnitude faster than simulations, and yields an average Jaccard Similarity Index of 0.972 (against ground truth from simulations) and 0.925 (against real-world measured deformations); we additionally report preliminary results on using the predictor for automatic planning of rolling sequences.","Product design,development and prototyping,simulation and animation,deep learning for visual perception",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,NEURAL-NETWORK,IEEE ROBOTICS AND AUTOMATION LETTERS,http://arxiv.org/pdf/2007.14471,
57,Classification and recognition of encrypted EEG data based on neural network,54,,,"Liu Yongshuang,Huang Haiping,Xiao Fu,Malekian Reza,Wang Wenming","Liu YS,Huang HP,Xiao F,Malekian R,Wang WM",Huang HP,10.1016/j.jisa.2020.102567,Nanjing University of Posts & Telecommunications,"With the rapid development of Machine Learning technology applied in electroencephalography (EEG) signals, Brain-Computer Interface (BCI) has emerged as a novel and convenient human-computer interaction for smart home, intelligent medical and other Internet of Things (IoT) scenarios. However, security issues such as sensitive information disclosure and unauthorized operations have not received sufficient concerns. There are still some defects with the existing solutions to encrypted EEG data such as low accuracy, high time complexity or slow processing speed. For this reason, a classification and recognition method of encrypted EEG data based on neural network is proposed, which adopts Paillier encryption algorithm to encrypt EEG data and meanwhile resolves the problem of floating point operations. In addition, it improves traditional feed-forward neural network (FNN) by using the approximate function instead of activation function and realizes multi-classification of encrypted EEG data. Extensive experiments are conducted to explore the effect of several metrics (such as the hidden neuron size and the learning rate updated by improved simulated annealing algorithm) on the recognition results. Followed by security and time cost analysis, the proposed model and approach are validated and evaluated on public EEG datasets provided by PhysioNet, BCI Competition IV and EPILEPSIAE. The experimental results show that our proposal has the satisfactory accuracy, efficiency and feasibility compared with other solutions. (C) 2020 Elsevier Ltd. All rights reserved.","EEG,Homomorphic encryption,Paillier,Neural network,Classification and recognition",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,3.504,"MOVEMENT,BCI",JOURNAL OF INFORMATION SECURITY AND APPLICATIONS,http://arxiv.org/pdf/2006.08122,
58,Morphological autoencoders for apnea detection in respiratory gating radiotherapy,195,,,"Abreu Mariana,Fred Ana,Valente Joao,Wang Chen,da Silva Hugo Placido","Abreu M,Fred A,Valente J,Wang C,da Silva HP",Abreu M,10.1016/j.cmpb.2020.105675,Universidade de Lisboa,"Background and Objective: Respiratory gating training is a common technique to increase patient proprioception, with the goal of (e.g.) minimizing the effects of organ motion during radiotherapy. In this work, we devise a system based on autoencoders for classification of regular, apnea and unconstrained breathing patterns (i.e. multiclass). Methods: Our approach is based on morphological analysis of the respiratory signals, using an autoencoder trained on regular breathing. The correlation between the input and output of the autoencoder is used to train and test several classifiers in order to select the best. Our approach is evaluated in a novel real-world respiratory gating biofeedback training dataset and on the Apnea-ECG reference dataset. Results: Accuracies of 95 +/- 3.5% and 87 +/- 6.6% were obtained for two different datasets, in the classification of breathing and apnea. These results suggest the viability of a generalised model to characterise the breathing patterns under study. Conclusions: Using autoencoders to learn respiratory gating training patterns allows a data-driven approach to feature extraction, by focusing only on the signal's morphology. The proposed system is prone to be used in real-time and could potentially be transferred to other domains. (C) 2020 Elsevier B.V. All rights reserved.","Artificialneuralnetworks,Respiratorygating,Apneadetection,Machinelearning,Signalprocessing",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"DEEP,INSPIRATION,ABC",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
59,Computer-aided classification of suspicious pigmented lesions using wide-field images,195,,,"Birkenfeld Judith S.,Tucker-Schwartz Jason M.,Soenksen Luis R.,Aviles-Izquierdo Jose A.,Marti-Fuster Berta","Birkenfeld JS,Tucker-Schwartz JM,Soenksen LR,Aviles-Izquierdo JA,Marti-Fuster B",Birkenfeld JS,10.1016/j.cmpb.2020.105631,Massachusetts Institute of Technology (MIT),"Background and objective: Early identification of melanoma is conducted through whole-body visual ex-aminations to detect suspicious pigmented lesions, a situation that fluctuates in accuracy depending on the experience and time of the examiner. Computer-aided diagnosis tools for skin lesions are typically trained using pre-selected single-lesion images, taken under controlled conditions, which limits their use in wide-field scenes. Here, we propose a computer-aided classifier system with such input conditions to aid in the rapid identification of suspicious pigmented lesions at the primary care level.
Methods: 133 patients with a multitude of skin lesions were recruited for this study. All lesions were examined by a board-certified dermatologist and classified into ""suspicious"" and ""non-suspicious"". A new clinical database was acquired and created by taking Wide-Field images of all major body parts with a consumer-grade camera under natural illumination condition and with a consistent source of image variability. 3-8 images were acquired per patient on different sites of the body, and a total of 1759 pig-mented lesions were extracted. A machine learning classifier was optimized and build into a computer aided classification system to binary classify each lesion using a suspiciousness score.
Results: In a testing set, our computer-aided classification system achieved a sensitivity of 100% for sus-picious pigmented lesions that were later confirmed by dermoscopy examination (""SPL_A"") and 83.2% for suspicious pigmented lesions that were not confirmed after examination (""SPL_B""). Sensitivity for non -suspicious lesions was 72.1%, and accuracy was 75.9%. With these results we defined a suspiciousness score that is aligned with common macro-screening (naked eye) practices.
Conclusions: This work demonstrates that wide-field photography combined with computer-aided classi-fication systems can distinguish suspicious from non-suspicious pigmented lesions, and might be effec-tive to assess the severity of a suspicious pigmented lesions. We believe this approach could be useful to support skin screenings at a population-level. (C) 2020 The Authors. Published by Elsevier B.V.","Machine learning,Suspicious pigmented lesions,Computer-aided classification,Melanoma,Wide-field images",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"SKIN-LESIONS,PRIMARY-CARE,GENERAL-PRACTITIONERS,DECISION-SUPPORT,MELANOMA,CANCER,DIAGNOSIS,DERMOSCOPY,SYSTEM,DERMATOLOGISTS",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,https://doi.org/10.1016/j.cmpb.2020.105631,
60,Mass detection in mammograms by bilateral analysis using convolution neural network,195,,,"Li Yanfeng,Zhang Linlin,Chen Houjin,Cheng Lin","Li YF,Zhang LL,Chen HJ,Cheng L",Chen HJ,10.1016/j.cmpb.2020.105518,Beijing Jiaotong University,"Background and objective: Automatic detection of the masses in mammograms is a big challenge and plays a crucial role to assist radiologists for accurate diagnosis. In this paper, a bilateral image analysis method based on Convolution Neural Network (CNN) is developed for mass detection in mammograms.
Methods: The proposed bilateral mass detection method consists of two networks: a registration network for registering bilateral mammograms and a Siamese-Faster-RCNN network for mass detection using a pair of registered mammograms. In the first step, self-supervised learning network is built to learn the spatial transformation between bilateral mammograms. This network can directly estimate spatial transformation by maximizing an image-wise similarity metric and corresponding points labeling is not needed. In the second step, an end-to-end network combining the Region Proposal Network (RPN) and a Siamese Fully Connected (Siamese-FC) network is designed. Different from existing methods, the designed network integrates mass detection on single image with registered bilateral images comparison.
Results: The proposed method is evaluated on three datasets (publicly available dataset INbreast and private dataset BCPKUPH and TXMD). For INbreast dataset, the proposed method achieves 0.88 true positive rate (TPR) with 1.12 false positives per image (FPs/I). For BCPKUPH dataset, the proposed method achieves 0.85 TPR with 1.86 FPs/I. For TXMD dataset, the proposed method achieves 0.85 TPR with 2.70 FPs/I.
Conclusions: Registration experimental result shows that the proposed method is suitable for bilateral mass detection. Mass detection experimental results show that the proposed method performs better than unilateral mass detection method, different bilateral connection schemes and image level fusion bilateral schemes. (C) 2020 Elsevier B.V. All rights reserved.","Image registration,Self-supervised learning,Bilateral mammograms,Mass detection,Deep learning",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"DEEP,LEARNING,APPROACH,DIGITAL,MAMMOGRAMS,CLASSIFICATION,TEXTURE,REGIONS",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
61,Heart sound classification based on improved MFCC features and convolutional recurrent neural networks,130,,22-32,"Deng Muqing,Meng Tingting,Cao Jiuwen,Wang Shimin,Zhang Jing,Fan Huijie","Deng MQ,Meng TT,Cao JW,Wang SM,Zhang J,Fan HJ",Deng MQ,10.1016/j.neunet.2020.06.015,Guangdong University of Technology,"Heart sound classification plays a vital role in the early detection of cardiovascular disorders, especially for small primary health care clinics. Despite that much progress has been made for heart sound classification in recent years, most of them are based on conventional segmented features and shallow structure based classifiers. These conventional acoustic representation and classification methods may be insufficient in characterizing heart sound, and generally suffer from a degraded performance due to the complicated and changeable cardiac acoustic environment. In this paper, we propose a new heart sound classification method based on improved Mel-frequency cepstrum coefficient (MFCC) features and convolutional recurrent neural networks. The Mel-frequency cepstrums are firstly calculated without dividing the heart sound signal. A new improved feature extraction scheme based on MFCC is proposed to elaborate the dynamic characteristics among consecutive heart sound signals. Finally, the MFCC-based features are fed to a deep convolutional and recurrent neural network (CRNN) for feature learning and later classification task. The proposed deep learning framework can take advantage of the encoded local characteristics extracted from the convolutional neural network (CNN) and the long-term dependencies captured by the recurrent neural network (RNN). Comprehensive studies on the performance of different network parameters and different network connection strategies are presented in this paper. Performance comparisons with state-of-the-art algorithms are given for discussions. Experiments show that, for the two-class classification problem (pathological or non-pathological), a classification accuracy of 98% has been achieved on the 2016 PhysioNet/CinC Challenge database. (C) 2020 Elsevier Ltd. All rights reserved.","Heart sound classification,Convolutional neural network,Recurrent neural network,Improved MFCC features",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,9.171,SEGMENTATION,NEURAL NETWORKS,,
62,Predictive models and feature ranking in reservoir geomechanics: A critical review and research guidelines,82,,,Miah Mohammad Islam,Miah MI,Miah MI,10.1016/j.jngse.2020.103493,Chittagong University of Engineering & Technology (CUET),"Comprehensive investigation and accurate models of geo-mechanical properties are crucial to maintain wellbore stability and optimize the hydraulic fracturing process. This review attempts to revisit the existing correlations/ models and also critically summarizes the research gaps related to acoustic waves, elastic constants, and rock strength models in geomechanics. In addition, it highlights the present status of predictive models and features ranking for uniaxial compressive strength in reservoir geomechanics. It is found that rock strength models have a distinct relationship with sonic velocities and petrophysical properties of rocks. For instance, it also explains the novel implementation of machine learning-based hybrid connectionist model and variable ranking strategies to obtain accurate geomechanical properties using core and log data. It is anticipated that the proposed research approaches will enable researchers to estimate accurate rock mechanical properties and variable ranking for sanding potentiality and wellbore failure analysis in a cost-effective through a timely manner.","Rock mechanical properties,Machine learning,Connectionist models,Dynamic log data,Variable selection,Geomechanics",Review,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Energy & Fuels,Engineering",,4.993,"UNIAXIAL,COMPRESSIVE,STRENGTH,SHEAR-WAVE,VELOCITY,WELL,LOG,DATA,EMPIRICAL,RELATIONS,ROCK,STRENGTH,CARBONATE,ROCKS,NEURAL-NETWORKS,POROSITY,MACHINE,INDEX",JOURNAL OF NATURAL GAS SCIENCE AND ENGINEERING,,
63,Learning and Tracking the 3D Body Shape of Freely Moving Infants from RGB-D sequences,42,10,2540-2551,"Hesse Nikolas,Pujades Sergi,Black Michael J.,Arens Michael,Hofmann Ulrich G.,Schroeder A. Sebastian","Hesse N,Pujades S,Black MJ,Arens M,Hofmann UG,Schroeder AS",Hesse N,10.1109/TPAMI.2019.2917908,Fraunhofer Gesellschaft,"Statistical models of the human body surface are generally learned from thousands of high-quality 3D scans in predefined poses to cover the wide variety of human body shapes and articulations. Acquisition of such data requires expensive equipment, calibration procedures, and is limited to cooperative subjects who can understand and follow instructions, such as adults. We present a method for learning a statistical 3D Skinned Multi-Infant Linear body model (SMIL) from incomplete, low-quality RGB-D sequences of freely moving infants. Quantitative experiments show that SMIL faithfully represents the RGB-D data and properly factorizes the shape and pose of the infants. To demonstrate the applicability of SMIL, we fit the model to RGB-D sequences of freely moving infants and show, with a case study, that our method captures enough motion detail for General Movements Assessment (GMA), a method used in clinical practice for early detection of neurodevelopmental disorders in infants. SMIL provides a new tool for analyzing infant shape and movement and is a step towards an automated system for GMA.","Shape,Biological system modeling,Three-dimensional displays,Data models,Animals,Face,Avatars,Body models,data-driven,RGB-D,infants,motion analysis",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Computer Science,Engineering",,18.46,"MODEL,MOVEMENTS,POSE",IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE,https://ieeexplore.ieee.org/ielx7/34/9185119/08732396.pdf,
64,Acute myeloid leukemia diagnosis using deep learning,45,4,167-174,"Nagiub Eman M.,Hussain Khaled F.,Omar Nagwa M.,Al-Rashedi Qamert","Nagiub EM,Hussain KF,Omar NM,Al-Rashedi Q",Al-Rashedi Q,10.4103/ejh.ejh_11_20,Egyptian Knowledge Bank (EKB),"Background Early disease detection has a great impact on saving lives. One of the top deadliest diseases in the world is leukemia. Once detected, its treatment is immediately required. Standard morphologic diagnosis of leukemia by hematologists is done by examining the patient's peripheral blood (PB) and bone marrow (BM) under microscope. However, manual recognition is prone to variations such as experience and tiredness where the percentage of error in diagnosis is between 30%-40%. Therefore, it is necessary to have a robust automated system for leukemia detection that is not influenced by human variations. Machine learning is attracting interest in the biomedical field as it improves sensitivity and specificity of the disease diagnosis, influencing the objectivity of the decision-making process. Objectives Testing deep learning technique that use microscopic images to identify leukemia based on a pretrained deep convolutional neural network which is an approach of machine learning algorithms. Material and method Dataset used was collected from Clinical Pathology lab, Assiut University Hospital, Egypt, containing binary balanced dataset: leukemic and normal blood, each sample composed of PB and BM smears images. We analyzed 412 digital images; 206 images of leukemia (AML types only) & 206 images of normal blood. 1-Training & testing phase: testing different types of pre-trained convolutional neural networks models ex. Alexnet, VGG16, GoogleNet, ResNet101, and Inception-v3. We divided images into two groups; 80% of images assigned as ""training-set"", each of the models trained on the images to extract features to differentiate leukemic and normal images, remaining 20% images were assigned as ""testing-set"" or so called ""never seen"" by the models. 2-Evaluation of sensitivity/specificity/accuracy: evaluating ability of the models to detect target; based on sensitivity, specificity and accuracy of detection. 3. We computed the testing execution time per image in dataset. Results Comparing the ability of models to differentiate leukemia vs normal images showed that Inception-v3 model had the highest accuracy (99%) in detection and classification of AML. In terms of sensitivity and specificity, the Inception-v3 can detect all leukemic cases of AML, with 100% sensitivity; and specificity of 97.8%. Inception-v3 required only 0.2273 seconds to test each image in AML-IDB. Conclusion Inception-v3 outperforms other pretrained convolutional neural networks in diagnosis of leukemia, this model of Machine learning algorithm can be used in the context of lab diagnosis acting as a second opinion after manual evaluation of leukemia. </p>","convolutional neural network,deep learning,leukemia,microscopic blood image,morphologic diagnosis,sensitivity,specificity",Article,"WOLTERS KLUWER MEDKNOW PUBLICATIONS, WOLTERS KLUWER INDIA PVT LTD , A-202, 2ND FLR, QUBE, C T S  NO 1498A-2 VILLAGE MAROL, ANDHERI EAST, MUMBAI, Maharashtra, INDIA",Hematology,,,"BLOOD,CLASSIFICATION,SEGMENTATION",EGYPTIAN JOURNAL OF HAEMATOLOGY,,
65,An acoustic emission based structural health monitoring approach to damage development in solid railway axles,139,,,"Carboni Michele,Crivelli Davide","Carboni M,Crivelli D",Carboni M,10.1016/j.ijfatigue.2020.105753,Polytechnic University of Milan,"The in-service safety of railway axles is a very important engineering challenge, as it has a large impact not only from the economic point of view of the railway operator, but it has cascading effects on supply chains, loss of work productivity, and, in the most serious cases, loss of life. It is, therefore, vital that the structural integrity of such components is known, during their lifecycle, with the highest possible accuracy via precise modelling, reliable inspections and, more recently but still at research level, effective condition monitoring.
With a focus on solid freight axles, the research investigates the applicability of Acoustic Emission as a structural health monitoring approach for determining the in-service condition of a full-scale axle. A fatigue crack propagation test is carried out in the lab subjecting the axle to many repetitions of a block load sequence defined from real service measurements. Acoustic Emission data are continuously recorded during the test, whilst crack size is periodically measured by conventional non-destructive techniques.
Eventually, a first-approximation correlation is highlighted between Acoustic Emission data, post-processed by a machine-learning algorithm, and crack propagation ones.","Structural health monitoring,Solid railway axle,Acoustic emission,Full-scale crack propagation test",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Engineering,Materials Science",,4.946,TOLERANCE,INTERNATIONAL JOURNAL OF FATIGUE,,
66,Accelerating quantitative MR imaging with the incorporation of B-1 compensation using deep learning,72,,78-86,"Wu Yan,Ma Yajun,Du Jiang,Xing Lei","Wu Y,Ma YJ,Du J,Xing L",Du J,10.1016/j.mri.2020.06.011,University of California System,"Quantitative magnetic resonance imaging (MRI) attracts attention due to its support to quantitative image analysis and data driven medicine. However, the application of quantitative MRI is severely limited by the long data acquisition time required by repetitive image acquisition and measurement of field map. Inspired by recent development of artificial intelligence, we propose a deep learning strategy to accelerate the acquisition of quantitative MRI, where every quantitative T-1 map is derived from two highly undersampled variable-contrast images with radiofrequency field inhomogeneity automatically compensated. In a multi-step framework, variable-contrast images are first jointly reconstructed from incoherently undersampled images using convolutional neural networks; then T-1 map and B-1 map are predicted from reconstructed images employing deep learning. Thus, the acceleration includes undersampling in every input image, a reduction in the number of variable contrast images, as well as a waiver of B-1 map measurement. The strategy is validated in T-1 mapping of cartilage. Acquired with a consistent imaging protocol, 1224 image sets from 51 subjects are used for the training of the prediction models, and 288 image sets from 12 subjects are used for testing. High degree of acceleration is achieved with image fidelity well maintained. The proposed method can be broadly applied to quantify other tissue properties (e.g. T-2, T-1p) as well.","NEURAL-NETWORK,RECONSTRUCTION,BRAIN,T-1,ACCURATE,TRANSMIT,TIME,T1",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.608,"NEURAL-NETWORK,RECONSTRUCTION,BRAIN,T-1,ACCURATE,TRANSMIT,TIME,T1",MAGNETIC RESONANCE IMAGING,,
67,Local rotation invariance in 3D CNNs,65,,,"Andrearczyk Vincent,Fageot Julien,Oreiller Valentin,Montet Xavier,Depeursinge Adrien","Andrearczyk V,Fageot J,Oreiller V,Montet X,Depeursinge A",Andrearczyk V,10.1016/j.media.2020.101756,University of Applied Sciences & Arts Western Switzerland,"Locally Rotation Invariant (LRI) image analysis was shown to be fundamental in many applications and in particular in medical imaging where local structures of tissues occur at arbitrary rotations. LRI constituted the cornerstone of several breakthroughs in texture analysis, including Local Binary Patterns (LBP), Maximum Response 8 (MR8) and steerable filterbanks. Whereas globally rotation invariant Convolutional Neural Networks (CNN) were recently proposed, LRI was very little investigated in the context of deep learning. LRI designs allow learning filters accounting for all orientations, which enables a drastic reduction of trainable parameters and training data when compared to standard 3D CNNs. In this paper, we propose and compare several methods to obtain LRI CNNs with directional sensitivity. Two methods use orientation channels (responses to rotated kernels), either by explicitly rotating the kernels or using steer able filters. These orientation channels constitute a locally rotation equivariant representation of the data. Local pooling across orientations yields LRI image analysis. Steerable filters are used to achieve a fine and efficient sampling of 3D rotations as well as a reduction of trainable parameters and operations, thanks to a parametric representations involving solid Spherical Harmonics (SH),which are products of SH with associated learned radial profiles. Finally, we investigate a third strategy to obtain LRI based on rotational invariants calculated from responses to a learned set of solid SHs. The proposed methods are evaluated and compared to standard CNNs on 3D datasets including synthetic textured volumes composed of rotated patterns, and pulmonary nodule classification in CT. The results show the importance of LRI image analysis while resulting in a drastic reduction of trainable parameters, outperforming standard 3D CNNs trained with rotational data augmentation. (c) 2020 Elsevier B.V. All rights reserved.","Local rotation invariance,Convolutional neural network,Steerable filters,3D Texture",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"TEXTURE,CLASSIFICATION",MEDICAL IMAGE ANALYSIS,http://arxiv.org/pdf/2003.08890,
68,Weakly supervised object detection with 2D and 3D regression neural networks,65,,,"Dubost Florian,Adams Hieab,Yilmaz Pinar,Bortsova Gerda,van Tulder Gijs,Ikram M. Arfan,Niessen Wiro,Vernooij Meike W.,de Bruijne Marleen","Dubost F,Adams H,Yilmaz P,Bortsova G,van Tulder G,Ikram MA,Niessen W,Vernooij MW,de Bruijne M",Dubost F,10.1016/j.media.2020.101767,Erasmus University Rotterdam,"Finding automatically multiple lesions in large images is a common problem in medical image analysis. Solving this problem can be challenging if, during optimization, the automated method cannot access information about the location of the lesions nor is given single examples of the lesions. We propose a new weakly supervised detection method using neural networks, that computes attention maps revealing the locations of brain lesions. These attention maps are computed using the last feature maps of a segmentation network optimized only with global image-level labels. The proposed method can generate attention maps at full input resolution without need for interpolation during preprocessing, which allows small lesions to appear in attention maps. For comparison, we modify state-of-the-art methods to compute attention maps for weakly supervised object detection, by using a global regression objective instead of the more conventional classification objective. This regression objective optimizes the number of occurrences of the target object in an image, e.g. the number of brain lesions in a scan, or the number of digits in an image. We study the behavior of the proposed method in MNIST-based detection datasets, and evaluate it for the challenging detection of enlarged perivascular spaces - a type of brain lesion - in a dataset of 2202 3D scans with point-wise annotations in the center of all lesions in four brain regions. In MNIST-based datasets, the proposed method outperforms the other methods. In the brain dataset, the weakly supervised detection methods come close to the human intrarater agreement in each region. The proposed method reaches the best area under the curve in two out of four regions, and has the lowest number of false positive detections in all regions, while its average sensitivity over all regions is similar to that of the other best methods. The proposed method can facilitate epidemiological and clinical studies of enlarged perivascular spaces and help advance research in the etiology of enlarged perivascular spaces and in their relationship with cerebrovascular diseases. (c) 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license. ( http://creativecommons.org/licenses/by/4.0/ )","Weakly-supervised,Regression,Lesion,Detection,Weak-labels,Count,Brain,Deep learning,MRI,Enlarged perivascular spaces,Perivascular spaces",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"ENLARGED,PERIVASCULAR,SPACES",MEDICAL IMAGE ANALYSIS,http://arxiv.org/pdf/1906.01891,
69,Integrating uncertainty in deep neural networks for MRI based stroke analysis,65,,,"Herzog Lisa,Murina Elvis,Duerr Oliver,Wegener Susanne,Sick Beate","Herzog L,Murina E,Durr O,Wegener S,Sick B",Herzog L; Sick B,10.1016/j.media.2020.101790,University of Zurich,"At present, the majority of the proposed Deep Learning (DL) methods provide point predictions without quantifying the model's uncertainty. However, a quantification of the reliability of automated image analysis is essential, in particular in medicine when physicians rely on the results for making critical treatment decisions. In this work, we provide an entire framework to diagnose ischemic stroke patients incorporating Bayesian uncertainty into the analysis procedure. We present a Bayesian Convolutional Neural Network (CNN) yielding a probability for a stroke lesion on 2D Magnetic Resonance (MR) images with corresponding uncertainty information about the reliability of the prediction. For patient-level diagnoses, different aggregation methods are proposed and evaluated, which combine the individual image-level predictions. Those methods take advantage of the uncertainty in the image predictions and report model uncertainty at the patient-level. In a cohort of 511 patients, our Bayesian CNN achieved an accuracy of 95.33% at the image-level representing a significant improvement of 2% over a non-Bayesian counterpart. The best patient aggregation method yielded 95.89% of accuracy. Integrating uncertainty information about image predictions in aggregation models resulted in higher uncertainty measures to false patient classifications, which enabled to filter critical patient diagnoses that are supposed to be closer examined by a medical doctor. We therefore recommend using Bayesian approaches not only for improved image level prediction and uncertainty estimation but also for the detection of uncertain aggregations at the patient-level. (c) 2020 Published by Elsevier B.V.","Bayesian convolutional neural networks,Uncertainty,Magnetic resonance imaging,Ischemic stroke",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,SEGMENTATION,MEDICAL IMAGE ANALYSIS,https://www.zora.uzh.ch/id/eprint/190294/1/Herzog_MIA.pdf,
70,Deep learning with noisy labels: Exploring techniques and remedies in medical image analysis,65,,,"Karimi Davood,Dou Haoran,Warfield Simon K.,Gholipour Ali","Karimi D,Dou HR,Warfield SK,Gholipour A",Karimi D,10.1016/j.media.2020.101759,Harvard University,"Supervised training of deep learning models requires large labeled datasets. There is a growing interest in obtaining such datasets for medical image analysis applications. However, the impact of label noise has not received sufficient attention. Recent studies have shown that label noise can significantly impact the performance of deep learning models in many machine learning and computer vision applications. This is especially concerning for medical applications, where datasets are typically small, labeling requires domain expertise and suffers from high interand intra-observer variability, and erroneous predictions may influence decisions that directly impact human health. In this paper, we first review the state-of-theart in handling label noise in deep learning. Then, we review studies that have dealt with label noise in deep learning for medical image analysis. Our review shows that recent progress on handling label noise in deep learning has gone largely unnoticed by the medical image analysis community. To help achieve a better understanding of the extent of the problem and its potential remedies, we conducted experiments with three medical imaging datasets with different types of label noise, where we investigated several existing strategies and developed new methods to combat the negative effect of label noise. Based on the results of these experiments and our review of the literature, we have made recommendations on methods that can be used to alleviate the effects of different types of label noise on deep models trained for medical image analysis. We hope that this article helps the medical image analysis researchers and developers in choosing and devising new techniques that effectively handle label noise in deep learning. (c) 2020 Elsevier B.V. All rights reserved.","Label noise,Deep learning,Machine learning,Big data,Medical image annotation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"DECISION,TREES,LUNG-CANCER,CLASSIFICATION,PERFORMANCE,ALGORITHM,MICROARRAYS,VALIDATION,TRUTH",MEDICAL IMAGE ANALYSIS,http://arxiv.org/pdf/1912.02911,
71,Cascaded one-shot deformable convolutional neural networks: Developing a deep learning model for respiratory motion estimation in ultrasound sequences,65,,,"Liu Fei,Liu Dan,Tian Jie,Xie Xiaoyan,Yang Xin,Wang Kun","Liu F,Liu D,Tian J,Xie XY,Yang X,Wang K",Wang K,10.1016/j.media.2020.101793,Chinese Academy of Sciences,"Improving the quality of image-guided radiation therapy requires the tracking of respiratory motion in ultrasound sequences. However, the low signal-to-noise ratio and the artifacts in ultrasound images make it difficult to track targets accurately and robustly. In this study, we propose a novel deep learning model, called a Cascaded One-shot Deformable Convolutional Neural Network (COSD-CNN), to track landmarks in real time in long ultrasound sequences. Specifically, we design a cascaded Siamese network structure to improve the tracking performance of CNN-based methods. We propose a one-shot deformable convolution module to enhance the robustness of the COSD-CNN to appearance variation in a meta-learning manner. Moreover, we design a simple and efficient unsupervised strategy to facilitate the network's training with a limited number of medical images, in which many corner points are selected from raw ultrasound images to learn network features with high generalizability. The proposed COSD-CNN has been extensively evaluated on the public Challenge on Liver UltraSound Tracking (CLUST) 2D dataset and on our own ultrasound image dataset from the First Affiliated Hospital of Sun Yat-sen University (FSYSU). Experiment results show that the proposed model can track a target through an ultrasound sequence with high accuracy and robustness. Our method achieves new state-of-the-art performance on the CLUST 2D benchmark set, indicating its strong potential for application in clinical practice. (c) 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license. ( http://creativecommons.org/licenses/by-nc-nd/4.0/ )","Ultrasound sequence,Respiratory motion estimation,Cascaded Siamese network,One-shot deformable convolution",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"TIME,TUMOR-TRACKING,LIVER",MEDICAL IMAGE ANALYSIS,https://doi.org/10.1016/j.media.2020.101793,
72,Deep-COVID: Predicting COVID-19 from chest X-ray images using deep transfer learning,65,,,"Minaee Shervin,Kafieh Rahele,Sonka Milan,Yazdani Shakib,Soufi Ghazaleh Jamalipour","Minaee S,Kafieh R,Sonka M,Yazdani S,Soufi GJ",Minaee S,10.1016/j.media.2020.101794,"Snap Inc, Seattle, WA 98121 USA.","The COVID-19 pandemic is causing a major outbreak in more than 150 countries around the world, having a severe impact on the health and life of many people globally. One of the crucial step in fighting COVID-19 is the ability to detect the infected patients early enough, and put them under special care. Detecting this disease from radiography and radiology images is perhaps one of the fastest ways to diagnose the patients. Some of the early studies showed specific abnormalities in the chest radiograms of patients infected with COVID-19. Inspired by earlier works, we study the application of deep learning models to detect COVID-19 patients from their chest radiography images. We first prepare a dataset of 50 0 0 Chest X-rays from the publicly available datasets. Images exhibiting COVID-19 disease presence were identified by board-certified radiologist. Transfer learning on a subset of 20 0 0 radiograms was used to train four popular convolutional neural networks, including ResNet18, ResNet50, SqueezeNet, and DenseNet-121, to identify COVID-19 disease in the analyzed chest X-ray images. We evaluated these models on the remaining 30 0 0 images, and most of these networks achieved a sensitivity rate of 98% ( +/- 3%), while having a specificity rate of around 90%. Besides sensitivity and specificity rates, we also present the receiver operating characteristic (ROC) curve, precision-recall curve, average prediction, and confusion matrix of each model. We also used a technique to generate heatmaps of lung regions potentially infected by COVID-19 and show that the generated heatmaps contain most of the infected areas annotated by our board certified radiologist. While the achieved performance is very encouraging, further analysis is required on a larger set of COVID-19 images, to have a more reliable estimation of accuracy rates. The dataset, model implementations (in PyTorch), and evaluations, are all made publicly available for research community at https://github.com/shervinmin/DeepCovid.git (c) 2020 Elsevier B.V. All rights reserved.","COVID-19,X-ray imaging,Deep learning,Transfer learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,,MEDICAL IMAGE ANALYSIS,http://arxiv.org/pdf/2004.09363,
73,Automated diagnosis of bone metastasis based on multi-view bone scans using attention-augmented deep neural networks,65,,,"Pi Yong,Zhao Zhen,Xiang Yongzhao,Li Yuhao,Cai Huawei,Yi Zhang","Pi Y,Zhao Z,Xiang YZ,Li YH,Cai HW,Yi Z",Yi Z,10.1016/j.media.2020.101784,Sichuan University,"Bone scintigraphy is accepted as an effective diagnostic tool for whole-body examination of bone metastasis. However, the manual analysis of bone scintigraphy images requires extensive experience and is exhausting and time-consuming. An automated diagnosis system for such images is therefore much desired. Although automatic or semi-automatic methods for the diagnosis of bone scintigraphy images have been widely studied, they employ various steps to classify the images, including segmentation of the entire skeleton, detection of hot spots, and feature extraction, which are complex and inadequately validated on small datasets, thereby resulting in low accuracy and reliability. In this paper, we describe the development of a deep convolutional neural network to determine the absence or presence of bone metastasis. This model consisting of three sub-networks that aim to extract, aggregate, and classify high-level features in a data-driven manner. There are two main innovations behind this method; First, the diagnosis is performed by jointly analyzing both anterior and posterior views, which leads to high accuracy. Second, a spatial attention feature aggregation operator is proposed to enhance the spatial location information. A large annotated bone scintigraphy image dataset containing 15,474 examinations from 13,811 patients was constructed to train and evaluate the model. The proposed method is compared with three human experts. The high classification accuracy achieved demonstrates the effectiveness of the proposed architecture for the diagnosis of bone scintigraphy images, and that it can be applied as a clinical decision support tool. (c) 2020 Elsevier B.V. All rights reserved.","Bone metastasis,Deep neural networks,Multi-view,Whole body bone scan",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"COMPUTER-AIDED,DIAGNOSIS,SCINTIGRAPHY,MAMMOGRAMS,SYSTEM,MRI",MEDICAL IMAGE ANALYSIS,,
74,Deep learning based HEp-2 image classification: A comprehensive review,65,,,"Rahman Saimunur,Wang Lei,Sun Changming,Zhou Luping","Rahman S,Wang L,Sun CM,Zhou LP",Wang L,10.1016/j.media.2020.101764,University of Wollongong,"Classification of HEp-2 cell patterns plays a significant role in the indirect immunofluorescence test for identifying autoimmune diseases in the human body. Many automatic HEp-2 cell classification methods have been proposed in recent years, amongst which deep learning based methods have shown impressive performance. This paper provides a comprehensive review of the existing deep learning based HEp-2 cell image classification methods. These methods perform HEp-2 image classification at two levels, namely, cell-level and specimen-level. Both levels are covered in this review. At each level, the methods are organized with a deep network usage based taxonomy. The core idea, notable achievements, and key strengths and weaknesses of each method are critically analyzed. Furthermore, a concise review of the existing HEp-2 datasets that are commonly used in the literature is given. The paper ends with a discussion on novel opportunities and future research directions in this field. It is hoped that this paper would provide readers with a thorough reference of this novel, challenging, and thriving field. Crown Copyright (c) 2020 Published by Elsevier B.V. All rights reserved.","HEp-2 Cell image classification,Deep learning,Review",Review,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"CONVOLUTIONAL,NEURAL-NETWORKS,CELL,CLASSIFICATION,PATTERN-RECOGNITION,MACHINE,SYSTEM",MEDICAL IMAGE ANALYSIS,http://arxiv.org/pdf/1911.08916,
75,Multi-task multi-modal learning for joint diagnosis and prognosis of human cancers,65,,,"Shao Wei,Wang Tongxin,Sun Liang,Dong Tianhan,Han Zhi,Huang Zhi,Zhang Jie,Zhang Daoqiang,Huang Kun","Shao W,Wang TX,Sun L,Dong TH,Han Z,Huang Z,Zhang J,Zhang DQ,Huang K",Zhang DQ,10.1016/j.media.2020.101795,Nanjing University of Aeronautics & Astronautics,"With the tremendous development of artificial intelligence, many machine learning algorithms have been applied to the diagnosis of human cancers. Recently, rather than predicting categorical variables (e.g., stages and subtypes) as in cancer diagnosis, several prognosis prediction models basing on patients' survival information have been adopted to estimate the clinical outcome of cancer patients. However, most existing studies treat the diagnosis and prognosis tasks separately. In fact, the diagnosis information (e.g., TNM Stages) indicates the extent of the disease severity that is highly correlated with the patients' survival. While the diagnosis is largely made based on histopathological images, recent studies have also demonstrated that integrative analysis of histopathological images and genomic data can hold great promise for improving the diagnosis and prognosis of cancers. However, direct combination of these two types of data may bring redundant features that will negatively affect the prediction performance. Therefore, it is necessary to select informative features from the derived multi-modal data. Based on the above considerations, we propose a multi-task multi-modal feature selection method for joint diagnosis and prognosis of cancers. Specifically, we make use of the task relationship learning framework to automatically discover the relationships between the diagnosis and prognosis tasks, through which we can identify important image and genomics features for both tasks. In addition, we add a regularization term to ensure that the correlation within the multi-modal data can be captured. We evaluate our method on three cancer datasets from The Cancer Genome Atlas project, and the experimental results verify that our method can achieve better performance on both diagnosis and prognosis tasks than the related methods. (c) 2020 Elsevier B.V. All rights reserved.","Multi-task multi-Modal learning,Cancer prognosis,Cancer diagnosis,Image genomics",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"PROSTATE-CANCER,GENOMIC,DATA,LUNG-CANCER,IMAGES,IDENTIFICATION,STRATIFICATION,EXPRESSION,CARCINOMA,FEATURES",MEDICAL IMAGE ANALYSIS,,
76,Whole slide images based cancer survival prediction using attention guided deep multiple instance learning networks,65,,,"Yao Jiawen,Zhu Xinliang,Jonnagaddala Jitendra,Hawkins Nicholas,Huang Junzhou","Yao JW,Zhu XL,Jonnagaddala J,Hawkins N,Huang JZ",Huang JZ,10.1016/j.media.2020.101789,University of Texas System,"Traditional image-based survival prediction models rely on discriminative patch labeling which make those methods not scalable to extend to large datasets. Recent studies have shown Multiple Instance Learning (MIL) framework is useful for histopathological images when no annotations are available in classification task. Different to the current image-based survival models that limit to key patches or clusters derived from Whole Slide Images (WSIs), we propose Deep Attention Multiple Instance Survival Learning (DeepAttnMISL) by introducing both siamese MI-FCN and attention-based MIL pooling to efficiently learn imaging features from the WSI and then aggregate WSI-level information to patient-level. Attention-based aggregation is more flexible and adaptive than aggregation techniques in recent survival models. We evaluated our methods on two large cancer whole slide images datasets and our results suggest that the proposed approach is more effective and suitable for large datasets and has better interpretability in locating important patterns and features that contribute to accurate cancer survival predictions. The proposed framework can also be used to assess individual patient's risk and thus assisting in delivering personalized medicine. (c) 2020 Elsevier B.V. All rights reserved.","Survival prediction,Multiple instance learning,Deep learning,Whole slide images",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"CLASSIFICATION,ALGORITHM",MEDICAL IMAGE ANALYSIS,http://arxiv.org/pdf/2009.11169,
77,Supervised learning with cyclegan for low-dose FDG PET image denoising,65,,,"Zhou Long,Schaefferkoetter Joshua D.,Tham Ivan W. K.,Huang Gang,Yan Jianhua","Zhou L,Schaefferkoetter JD,Tham IWK,Huang G,Yan JH",Huang G; Yan JH,10.1016/j.media.2020.101770,"Shanghai Univ Med & Hlth Sci, Shanghai Key Lab Mol Imaging, Shanghai 201318, Peoples R China.","PET imaging involves radiotracer injections, raising concerns about the risk of radiation exposure. To minimize the potential risk, one way is to reduce the injected tracer. However, this will lead to poor image quality with conventional image reconstruction and processing. In this paper, we proposed a supervised deep learning model, CycleWGANs, to boost low-dose PET image quality. Validations were performed on a low dose dataset simulated from a real dataset with biopsy-proven primary lung cancer or suspicious radiological abnormalities. Low dose PET images were reconstructed on reduced PET raw data by randomly discarding events in the PET list mode data towards the count level of 1 million. Traditional image denoising methods (Non-Local Mean (NLM) and block-matching 3D(BM3D)) and two recently-published deep learning methods (RED-CNN and 3D-cGAN) were included for comparisons. At the count level of 1 million (true counts), the proposed model can accurately estimate full-dose PET image from low-dose input image, which is superior to the other four methods in terms of the mean and maximum standardized uptake value (SUVmean and SUVmax) bias for lesions and normal tissues. The bias of SUV (SUVmean, SUVmax) for lesions and normal tissues are (-2. 06 +/- 3 . 50% , -0. 84 +/- 6 . 94% ) and (-0. 45 +/- 5 . 59% , N/A) in the estimated PET images, respectively. However, the RED-CNN achieved the best score in traditional metrics, such as structure similarity (SSIM), peak signal to noise ratio (PSNR) and normalized root mean square error (NRMSE). Correlation and profile analyses have successfully explained this phenomenon and further suggested that our method could effectively preserve edge and also SUV values than RED-CNN, 3D-cGAN and NLM with a slightly higher noise. (C) 2020 Published by Elsevier B.V.","PET,Low-dose,Generative adversarial networks,Cycle consistent",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Radiology, Nuclear Medicine & Medical Imaging",,11.22,"CONVOLUTIONAL,NEURAL-NETWORK,F-18-FDG,PET,BRAIN,MRI,SEGMENTATION,TOMOGRAPHY,CT",MEDICAL IMAGE ANALYSIS,,
78,Time windows: The key to improving the early detection of fuel leaks in petrol stations,130,,,"Alayon Silvia,Sigut Marta,Arnay Rafael,Toledo Pedro","Alayon S,Sigut M,Arnay R,Toledo P",Alayon S,10.1016/j.ssci.2020.104874,Universidad de la Laguna,"In this paper, the authors propose the use of time windows to improve the detection of fuel leaks in petrol stations. They employ two-class supervised classifiers that work with feature sets containing representative variables taken from station inventory books that indicate the presence of leaks. Fuel leaks in petrol stations with underground tanks pose a serious problem from an environmental standpoint. Large leaks are very evident, and are therefore detected quickly without the need to use a specific procedure. Small leaks, however, tend to go unnoticed, and if no detection techniques are employed, they are only identified once environmental damage has been done. This makes detecting the leak in the shortest time possible as important as ascertaining when the leak started. The authors show how the use of time windows, which entails having the classifier work with information accumulated over several days, can be used to efficiently resolve the proposed problem, fully complying with the applicable regulation.","Machine learning,Two-class classifiers,Time windows,Fuel leaks,Inventory reconciliation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Operations Research & Management Science",,,STORAGE,SAFETY SCIENCE,,
79,Perceptual learning of motion direction discrimination: Location specificity and the uncertain roles of dorsal and ventral areas,175,,51-57,"Xie Xin-Yu);,Zhao Xing-Nan);,Yu Cong","Xie XY,Zhao XN,Yu C",Yu C,10.1016/j.visres.2020.06.003,Peking University,"One interesting observation of perceptual learning is the asymmetric transfer between stimuli at different external noise levels: learning at zero/low noise can transfer significantly to the same stimulus at high noise, but not vice versa. The mechanisms underlying this asymmetric transfer have been investigated by psychophysical, neurophysiological, brain imaging, and computational modeling studies. One study (PNAS 113 (2016) 5724-5729) reported that rTMS stimulations of dorsal and ventral areas impair motion direction discrimination of moving dot stimuli at 40% coherent (""noisy"") and 100% coherent (zero-noise) levels, respectively. However, after direction training at 100% coherence, only rTMS stimulation of the ventral cortex is effective, disturbing direction discrimination at both coherence levels. These results were interpreted as learning-induced changes of functional specializations of visual areas. We have concerns with the behavioral data of this study. First, contrary to the report of highly location-specific motion direction learning, our replicating experiment showed substantial learning transfer (e.g., transfer/learning ratio = 81.9%. vs 14.8% at 100% coherence). Second and more importantly, we found complete transfer of direction learning from 40% to 100% coherence, a critical baseline that is missing in this study. The transfer effect suggests that similar brain mechanisms underlie motion direction processing at two coherence levels. Therefore, this study's conclusions regarding the roles of dorsal and ventral areas in motion direction processing at two coherence levels, as well as the effects of perceptual learning, are not supported by proper experimental evidence. It remains unexplained why distinct impacts of dorsal and ventral rTMS stimulations on motion direction discrimination were observed.","Perceptual learning,Motion direction,External noise,Location Specificity",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Neurosciences & Neurology,Ophthalmology,Psychology",,2.823,"ORIENTATION,IMPROVEMENT,MECHANISMS,TRANSFERS,NOISE",VISION RESEARCH,,
80,Data-driven surrogates for high dimensional models using Gaussian process regression on the Grassmann manifold,370,,,"Giovanis D. G.,Shields M. D.","Giovanis DG,Shields MD",Giovanis DG,10.1016/j.cma.2020.113269,Johns Hopkins University,"This paper introduces a surrogate modeling scheme based on Grassmannian manifold learning to be used for cost-efficient predictions of high-dimensional stochastic systems. The method exploits subspace-structured features of each solution by projecting it onto a Grassmann manifold. This point-wise linear dimensionality reduction harnesses the structural information to assess the similarity between solutions at different points in the input parameter space. The method utilizes a solution clustering approach in order to identify regions of the parameter space over which solutions are sufficiently similarly such that they can be interpolated on the Grassmannian. In this clustering, the reduced-order solutions are partitioned into disjoint clusters on the Grassmann manifold using the eigen-structure of properly defined Grassmannian kernels and, the Karcher mean of each cluster is estimated. Then, the points in each cluster are projected onto the tangent space with origin at the corresponding Karcher mean using the exponential mapping. For each cluster, a Gaussian process regression model is trained that maps the input parameters of the system to the reduced solution points of the corresponding cluster projected onto the tangent space. Using this Gaussian process model, the full-field solution can be efficiently predicted at any new point in the parameter space. In certain cases, the solution clusters will span disjoint regions of the parameter space. In such cases, for each of the solution clusters we utilize a second, density-based spatial clustering to group their corresponding input parameter points in the Euclidean space. The proposed method is applied to two numerical examples. The first is a nonlinear stochastic ordinary differential equation with uncertain initial conditions where the surrogate is used to predict the time history solution. The second involves modeling of plastic deformation in a model amorphous solid using the Shear Transformation Zone theory of plasticity, where the proposed surrogate is used to predict the full strain field of a material specimen under large shear strains. (C) 2020 Elsevier B.V. All rights reserved.","Grassmann manifold,Spectral clustering,Gaussian process regression,Machine learning,Nonlinear projection,Interpolation",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Engineering,Mathematics,Mechanics",,6.828,"GENERALIZED,POLYNOMIAL,CHAOS,UNCERTAINTY,QUANTIFICATION,STOCHASTIC,COLLOCATION,DIFFERENTIAL-EQUATIONS,FORM,UNCERTAINTIES,REDUCTION,DEFORMATION,EIGENMAPS,DYNAMICS,GEOMETRY",COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING,https://www.sciencedirect.com/science/article/am/pii/S0045782520304540,
81,Machine learning enabled advanced manufacturing in nuclear engineering applications,367,,,"Blevins Jacob,Yang Ge","Blevins J,Yang G",Yang G,10.1016/j.nucengdes.2020.110817,University of North Carolina,"Advanced manufacturing has gained tremendous interest in both research and industry in the past few years. Over nearly the same period of time, machine learning (ML) has made phenomenal advancements, finding its way into many aspects of manufacturing. For the nuclear engineering field, the adoption of advanced manufacturing is a compelling argument due to the ambitious challenges the field faces. The combination of advanced manufacturing with ML holds great potential in the nuclear engineering field, and even further development is needed to accelerate their deployment towards real-world applications. This review paper seeks to detail several key aspects of ML enabled advanced manufacturing that are used or could prove useful to nuclear applications ranging from radiation detector materials to reactor parts fabrication. The applications covered here include new material extrapolation, manufacturing defect detection, and additive manufacturing parameters' optimization.","NEURAL-NETWORK,PREDICTION,RECOGNITION,MICROSTRUCTURE,SIMULATIONS,RESISTANCE,DATASET,BIOLOGY",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND",Nuclear Science & Technology,,1.837,"NEURAL-NETWORK,PREDICTION,RECOGNITION,MICROSTRUCTURE,SIMULATIONS,RESISTANCE,DATASET,BIOLOGY",NUCLEAR ENGINEERING AND DESIGN,,
82,Numerical heat transfer analysis & predicting thermal performance of fins for a novel heat exchanger using machine learning,21,,,"Krishnayatra Gaurav,Tokas Sulekh,Kumar Rajesh","Krishnayatra G,Tokas S,Kumar R",Krishnayatra G,10.1016/j.csite.2020.100706,Delhi Technological University,"In the present case study, the thermal performance of fins for a novel axial finned-tube heat exchanger is investigated and predicted using machine learning regression technique. The effects of variation in the fin spacing, fin thickness, material, and the convective heat transfer coefficient on the overall efficiency and total effectiveness have been analyzed and commented upon. The k -Nearest Neighbor (k-NN), a machine learning algorithm, is used for regression analysis to predict the thermal performance outputs and the results showed high prediction accuracies. The k-NN algorithm is robust and precise which can be used by thermal system design engineers for pre-dicting output variables. The temperature profiles of various geometries have been depicted and compared in the results. It was concluded that the efficiency is increasing with fin thickness & decreasing with fin spacing and the maximum efficiency eta(max) = 0.99975 is achieved at delta* = 0.1 & t* = 0.0133 having h = 5 W/m(2).K for copper material. The effectiveness is increasing with fin spacing & fin thickness and the maximum effectiveness epsilon(max) = 122.766 is for delta* = 8 & t* = 0.4 having h = 5 W/m(2).K.","Convection heat transfer,Fin effectiveness,Fin efficiency,Novel fins,Machine learning,K-nearest neighbor",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Thermodynamics,,4.7,CONDUCTIVITY,CASE STUDIES IN THERMAL ENGINEERING,https://doi.org/10.1016/j.csite.2020.100706,
83,FlexMM: A standard method for material descriptions in FEM,148,,,"Groen Manso,Solhjoo Soheil,Voncken Ruud,Post Jan,Vakis Antonis I","Groen M,Solhjoo S,Voncken R,Post J,Vakis AI",Solhjoo S,10.1016/j.advengsoft.2020.102876,University of Groningen,"This article discusses a number of key issues concerning simulation-based digital twins in the domain of multistage processes. Almost all production processes are multistage in nature, and so most digital twins involve multiple physical phenomena, process steps and different solvers for the simulations. Good interoperability between model solvers and processes are key to achieving a functional digital twin. Passing information between steps can be challenging, complex and time consuming, especially for material data, because the constitutive model interacts with the full modeling environment: material behavior is interdependent with the history of the process, the solver subroutines and the boundary conditions. This work proposes a flexible yet robust standardization approach, called FlexMM, for dealing with material data, constitutive models, measurement data or mathematical models to overcome part of the abovementioned complexity. The implementation of FlexMM consists of a general rule structure in which constitutive behavior is described, as well as its interaction with the subroutines used by the finite element solver. The definition of the constitutive model is stored in a separate file, in which the material behavior can be described in a user selected format, such as look-up tables, standard statistical models, machine learning or analytical expressions. After a calculation step, the new local material properties are mapped to a file to facilitate the next history-dependent step. In this way, the interaction between the different fabrication steps and processes can be incorporated. A material/process case study is presented to demonstrate the flexibility and robustness of FlexMM.","FEM analysis,Digital twin,Multi stage modeling,User subroutines,Zero-defect manufacturing,Industry 4.0",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Computer Science,Engineering",,7.187,"DIGITAL,TWIN,FLOW-STRESS,TIME-STEP,ELEMENT,MESHES,DISCRETE",ADVANCES IN ENGINEERING SOFTWARE,https://doi.org/10.1016/j.advengsoft.2020.102876,
84,Searching for high entropy alloys: A machine learning approach,198,,178-222,"Kaufmann Kevin,Vecchio Kenneth S.","Kaufmann K,Vecchio KS",Vecchio KS,10.1016/j.actamat.2020.07.065,University of California System,"For the past decade, considerable research effort has been devoted toward computationally identifying and experimentally verifying single phase, high-entropy systems. However, predicting the resultant crystal structure(s) ""in silico"" remains a major challenge. Previous studies have primarily used density functional theory to obtain correlated parameters and fit them to existing data, but this is impractical given the extensive regions of unexplored composition space and considerable computational cost. A rapidly developing area of materials science is the application of machine learning to accelerate materials discovery and reduce computational and experimental costs. Machine learning has inherent advantages over traditional modeling, owing to its flexibility as new data becomes available and its rapid ability to construct relationships between input data and target outputs. In this article, we propose a novel high-throughput approach, called ""ML-HEA"", for coupling thermodynamic and chemical features with a random forest machine learning model for predicting the solid solution forming ability. The model can be a primary tool or integrated into existing alloy discovery workflows. The ML-HEA method is validated by comparing the results with reliable experimental data for binary, ternary, quaternary, and quinary systems. Comparison to other modeling approaches, including CALPHAD and the LTVC model, are also made to assess the performance of the machine learning model on labeled and unlabeled data. The uncertainty of the model in predicting the resultant phase of each composition is explored via the output of individual predictor trees. Importantly, the developed model can be immediately applied to explore material space in an unconstrained manner, and is readily updated to reflect the results of new experiments. (c) 2020 Acta Materialia Inc. Published by Elsevier Ltd. All rights reserved.","Machine learning,High entropy systems,Computational model,Solid solution",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Materials Science,Metallurgy & Metallurgical Engineering",,9.277,"PHASE-STABILITY,CLASSIFICATION",ACTA MATERIALIA,,
85,A data analytic framework for physical fatigue management using wearable sensors,155,,,"Maman Zahra Sedighi,Chen Ying-Ju,Baghdadi Amir,Lombardo Seamus,Cavuoto Lora A.,Megahed Fadel M.","Maman ZS,Chen YJ,Baghdadi A,Lombardo S,Cavuoto LA,Megahed FM",Megahed FM,10.1016/j.eswa.2020.113405,Miami University,"The use of expert systems in optimizing and transforming human performance has been limited in practice due to the lack of understanding of how an individual's performance deteriorates with fatigue accumulation, which can vary based on both the worker and the workplace conditions. As a first step toward realizing the human-centered approach to artificial intelligence and expert systems, this paper lays the foundation for a data analytic approach to managing fatigue in physically-demanding workplaces. The proposed framework capitalizes on continuously collected human performance data from wearable sensor technologies, and is centered around four distinct phases of fatigue: (a) detection, where machine learning methodologies are deployed to detect the occurrence of fatigue; (b) identification, where key features relating to the fatigue occurrence is to be identified; (c) diagnosis, where the fatigue mode is identified based on the knowledge generated in the previous two phases; and (d) recovery, where a suitable intervention is applied to return the worker to mitigate the detrimental effects of fatigue on the worker. Moreover, the framework establishes criteria for feature and machine learning algorithm selection for fatigue management. Two specific application cases of the framework, for two types of manufacturing-related tasks, are presented. Based on the proposed framework and a large number of test sets used in the two case studies, we have shown that: (i) only one wearable sensor is needed for fatigue detection with an average accuracy of >= 0.850 and a random forest model comprised of < 7 features; and (ii) the selected features are task-dependent, and thus capturing different modes of fatigue. Therefore, this research presents an important foundation for future expert systems that attempt to quantify/predict changes in workers' performance as an input to prescriptive rest-break scheduling, job-rotation, and task assignment models. To encourage future work in this important area, we provide links to our data and code as Supplementary materials. (C) 2020 Elsevier Ltd. All rights reserved.","Functional data analysis,Human performance modeling,Internet of Things (IoT),Manufacturing,Occupational safety",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"MUSCLE,FATIGUE,ACTIVITY,RECOGNITION,ENSEMBLE,METHODS,LIFTING,TASKS,GAIT,WORK,SELECTION,CANCER,LUMBAR,AGE",EXPERT SYSTEMS WITH APPLICATIONS,https://www.sciencedirect.com/science/article/am/pii/S0957417420302293,
86,An efficient Harris hawks-inspired image segmentation method,155,,,"Rodriguez-Esparza Erick,Zanella-Calzada Laura A.,Oliva Diego,Heidari Ali Asghar,Zaldivar Daniel,Perez-Cisnerosa Marco,Foong Loke Kok","Rodriguez-Esparza E,Zanella-Calzada LA,Oliva D,Heidari AA,Zaldivar D,Perez-Cisnerosa M,Foong LK",Oliva D; Perez-Cisnerosa M; Foong LK,10.1016/j.eswa.2020.113428,Universidad de Guadalajara,"Segmentation is a crucial phase in image processing because it simplifies the representation of an image and facilitates its analysis. The multilevel thresholding method is more efficient for segmenting digital mammograms compared to the classic bi-level thresholding since it uses a higher number of intensities to represent different regions in the image. In the literature, there are different techniques for multilevel segmentation; however, most of these approaches do not obtain good segmented images. In addition, they are computationally expensive. Recently, statistical criteria such as Otsu, Kapur, and cross-entropy have been utilized in combination with evolutionary and swarm-based strategies to investigate the optimal threshold values for multilevel segmentation. In this paper, an efficient methodology for multilevel segmentation is proposed using the Harris Hawks Optimization (HHO) algorithm and the minimum cross-entropy as a fitness function. To substantiate the results and effectiveness of the HHO-based method, it has been tested over a benchmark set of reference images, with the Berkeley segmentation database, and with medical images of digital mammography. The proposed HHO-based solver is verified based on other comparable optimizers and two machine learning algorithms K-means and the Fuzzy IterAg. The comparisons were performed based on three groups. This first one is to provide evidence of the optimization capabilities of the HHO using the Wilcoxon test, and the second is to verify segmented image quality using the PSNR, SSIM, and FSIM metrics. Then, the third way is to verify the segmented image comparing it with the ground-truth through the metrics PRI, GCE, and VoI. The experimental results, which are validated by statistical analysis, show that the introduced method produces efficient and reliable results in terms of quality, consistency, and accuracy in comparison with the other methods. This HHO-based method presents an improvement over other segmentation approaches that are currently used in the literature. (C) 2020 Elsevier Ltd. All rights reserved.","Multilevel thresholding,Digital mammograms,Harris hawks optimization,Metaheuristics,Minimum cross entropy",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,"WHALE,OPTIMIZATION,ALGORITHM,SALP,SWARM,ALGORITHM,GLOBAL,OPTIMIZATION,ENTROPY,SEARCH,COLOR,IDENTIFICATION,QUANTIZATION,CONSUMPTION,STRATEGY",EXPERT SYSTEMS WITH APPLICATIONS,,
87,Significant variables affecting the performance of concrete panels impacted by wind-borne projectiles: A global sensitivity analysis,144,,,"Zamanian Soroush,Terranova Brian,Shafieezadeh Abdollah","Zamanian S,Terranova B,Shafieezadeh A",Shafieezadeh A,10.1016/j.ijimpeng.2020.103650,Ohio State University,"A prominent threat to key structures and components in critical facilities, especially during a tornado or hurricane, is impact by wind-borne projectiles. Identifying uncertain variables in these phenomena is key for developing cost-effective design formulae and efficient reliability analysis. This task however is challenging due to the scarcity of data and the large set of uncertain factors that contribute to the impact phenomenon. The present study performs a robust global sensitivity analysis (GSA) using Sobol's indices on the response of a concrete panel impacted by a Schedule 40 pipe. A high-fidelity, nonlinear Finite Element (FE) model is developed using the Smooth Particle Hydrodynamics (SPH) formulation in LS-DYNA. The developed model was validated with the experiments conducted by the Electric Power Research Institute (EPRI). Due to the high computational demand of the SPH model, a machine learning-based surrogate model called Bayesian Additive Regression Trees (BART) is applied to emulate the computational model. This surrogate model that is trained with a limited number of generated SPH simulations is capable of accurately predicting the behavior of concrete panels subjected to projectile impact over the space of predictors. The predictors here include uncertain variables associated with concrete and steel material properties. GSA is subsequently performed by integrating the constructed surrogate model into Sobol's algorithm. Results indicate that concrete tensile strength plays a significant role in panel damage, while concrete mass density and compressive strength and mass density of the steel pipe are also significant. These findings suggest that the development of new empirical design formulae and experimental studies on the impact of concrete panels should include the identified significant variables.","Wind-borne projectile,Reinforced concrete panels,Finite element modeling,Bayesian additive regression trees,Global sensitivity analysis",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Engineering,Mechanics",,4.768,"RELIABILITY,STRENGTH,DESIGN,ENERGY,MODELS",INTERNATIONAL JOURNAL OF IMPACT ENGINEERING,,
88,A Multi-Channel Reinforcement Learning Framework for Robotic Mirror Therapy,5,4,5385-5392,"Xu Jiajun,Xu Linsen,Li Youfu,Cheng Gaoxin,Shi Jia,Liu Jinfu,Chen Shouqi","Xu JJ,Xu LS,Li YF,Cheng GX,Shi J,Liu JF,Chen SQ",Xu LS,10.1109/LRA.2020.3007408,Chinese Academy of Sciences,"In the letter, a robotic framework is proposed for hemiparesis rehabilitation. Mirror therapy is applied to transfer therapeutic training from the patient's function limb (FL) to the impaired limb (IL). The IL mimics the action prescribed by the FL with the assistance of the wearable robot, stimulating and strengthening the injured muscles through repetitive exercise. A master-slave robotic system is presented to implement the mirror therapy. Especially, the reinforcement learning is involved in the human-robot interaction control to enhance the rehabilitation efficacy and guarantee safety. Multi-channel sensed information, including the motion trajectory, muscle activation and the user's emotion, are incorporated in the learning algorithm. The muscle activation is expressed via the skin surface electromyography (EMG) signals, and the emotion is shown as the facial expression. The reinforcement learning approach is realized by the normalized advantage functions (NAF) algorithm. Then, a lower extremity rehabilitation robot with magnetorheological (MR) actuators is specially developed. The clinical experiments are carried out using the robot to verify the performance of the framework.","Rehabilitation robotics,physical human-robot interaction,reinforcement learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,LEG,IEEE ROBOTICS AND AUTOMATION LETTERS,,
89,Machine Learning Model Comparisons of User Independent & Dependent Intent Recognition Systems for Powered Prostheses,5,4,5393-5400,"Bhakta Krishan,Camargo Jonathan,Donovan Luke,Herrin Kinsey,Young Aaron","Bhakta K,Camargo J,Donovan L,Herrin K,Young A",Bhakta K,10.1109/LRA.2020.3007480,"Exoskeleton & Intelligent Controls EPIC Lab, Atlanta, GA 30332 USA.","Developing intelligent prosthetic controllers to recognize user intent across users is a challenge. Machine learning algorithms present an opportunity to develop methods for predicting user's locomotion mode. Currently, linear discriminant analysis (LDA) offers the standard solution in the state-of-the-art for subject dependent models and has been used in the development of subject independent applications. However, the performance of subject independent models differ radically from their dependent counterpart. Furthermore, most of the studies limit the evaluation to a fixed terrain with individual stair height and ramp inclination. In this study, we investigated the use of the XGBoost algorithm for developing a subject independent model across 8 individuals with transfemoral amputation. We evaluated the performance of XGBoost across different stair heights and inclination angles and found that it generalizes well across preset conditions. Our findings suggest that XGBoost offers a potential benefit for both subject independent and subject dependent algorithms outperforming LDA and NN (DEP SS Error: 2.93% +/- 0.49%, DEP TS Error: 7.03% +/- 0.74%, IND SS Error: 10.12% +/- 3.16%, and IND TS Error: 15.78% +/- 2.39%)(p < 0.05). We were also able to show that with the inclusion of extra sensors the model performance could continually be improved in both user dependent and independent models (p < 0.05). Our study provides valuable information for future intent recognition systems to make them more reliable across different users and common community ambulation modes.","Prosthetics and exoskeletons,wearable robots,human performance augmentation,mode classification,transfemoral amputation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,"TRANSFEMORAL,AMPUTEES,CLASSIFICATION,METHOD,FEATURE-EXTRACTION,INTACT,LIMB,WALKING,AMBULATION,GAIT,LEG,AMPUTATION,DESIGN",IEEE ROBOTICS AND AUTOMATION LETTERS,,
90,Application of artificial neural networks for rigid lattice kinetic Monte Carlo studies of Cu surface diffusion,183,,,"Kimari Jyri,Jansson Ville,Vigonski Simon,Baibuz Ekaterina,Domingos Roberto,Zadin Vahur,Djurabekova Flyura","Kimari J,Jansson V,Vigonski S,Baibuz E,Domingos R,Zadin V,Djurabekova F",Kimari J,10.1016/j.commatsci.2020.109789,Helsinki Institute of Physics,"Kinetic Monte Carlo (KMC) is a powerful method for simulation of diffusion processes in various systems. The accuracy of the method, however, relies on the extent of details used for the parameterization of the model. Migration barriers are often used to describe diffusion on atomic scale, but the full set of these barriers may become easily unmanageable in materials with increased chemical complexity or a large number of defects. This work is a feasibility study for applying a machine learning approach for Cu surface diffusion. We train an artificial neural network on a subset of the large set of 2(26) barriers needed to correctly describe the surface diffusion in Cu. Our KMC simulations using the obtained barrier predictor show sufficient accuracy in modelling processes on the low-index surfaces and display the correct thermodynamical stability of these surfaces.","Copper,Kinetic Monte Carlo,Artificial neural networks,Machine learning,Surface diffusion,Migration barriers",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"VACANCY,MIGRATION,ENERGIES,CORRECTED,EFFECTIVE-MEDIUM,DISSOCIATIVE,ADSORPTION,BARRIERS,INTELLIGENCE,SIMULATIONS,STABILITY,CLUSTERS,MOBILITY,CU%28110%29",COMPUTATIONAL MATERIALS SCIENCE,http://arxiv.org/pdf/1806.02976,
91,Vacancy formation energy and its connection with bonding environment in solid: A high-throughput calculation and machine learning study,183,,,"Cheng YingXing,Zhu Linggang,Wang Guanjie,Zhou Jian,Elliott Stephen R.,Sun Zhimei","Cheng YX,Zhu LG,Wang GJ,Zhou J,Elliott SR,Sun ZM",Zhu LG; Sun ZM,10.1016/j.commatsci.2020.109803,Beihang University,"The generation of the vacancy involving the bond breaking/re-formation occurs naturally in the material. Here, we present a framework for automatically computing the vacancy-formation energy (E-f) and for analyzing the bonding environment concealed in the E-f by using an artificial neural network (ANN). The 'effective' bonding that determines the energy of the system and the E-f will be clarified. The phase-change memory material GeTe is used as a case study. Firstly, 791 Ge-vacancy containing GeTe structures are studied and a large data set of the formation energy of the Ge-vacancy is obtained, which is helpful to understand the vacancy-induced issue of the amorphous GeTe including the resistance drift, etc. By using the ANN fitting based on the large energy data set, a bonding picture that is applicable to both the crystalline and the amorphous state of GeTe is predicted. In terms of the contribution to the formation energy of the vacancy, the weight ratio of the bond with length of 3.0-3.6 angstrom and 3.6-4.5 angstrom can be approximated as 6:1. The bonding information is further confirmed by using the first-principles electronic structure analysis on the randomly chosen samples. The bonding analysis using the ANN method based on a large vacancy-formation-energy data set is demonstrated to be a novel alternative technique to understand the bonding in the material. The proposed framework can be applied to a wide range of materials.","High-throughput calculation,Machine learning,Vacancy,Chemical bonding,First-principles calculation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"ELECTRON,LOCALIZATION,SIMULATIONS,TRANSITION,MOTIFS",COMPUTATIONAL MATERIALS SCIENCE,,
92,Machine Learning based prediction of noncentrosymmetric crystal materials,183,,,"Song Yuqi,Lindsay Joseph,Zhao Yong,Nasiri Alireza,Louis Steph-Yves,Ling Jie,Hu Ming,Hu Jianjun","Song YQ,Lindsay J,Zhao Y,Nasiri A,Louis SY,Ling J,Hu M,Hu JJ",Hu JJ,10.1016/j.commatsci.2020.109792,University of South Carolina System,"Noncentrosymmetric materials play a critical role in many important applications such as laser technology, communication systems,quantum computing, cybersecurity, and etc. However, the experimental discovery of new noncentrosymmetric materials is extremely difficult. Here we present a machine learning model that could predict whether the composition of a potential crystalline structure would be centrosymmetric or not. By evaluating a diverse set of composition features calculated using matminer featurizer package coupled with different machine learning algorithms, we find that Random Forest Classifiers give the best performance for noncentrosymmetric material prediction, reaching an accuracy of 84.8% when evaluated with 10 fold cross validation on the dataset with 82,506 samples extracted from Materials Project. A random forest model trained with materials with only 3 elements gives even higher accuracy of 86.9%. We apply our ML model to screen potential noncentrosymmetric materials from 2,000,000 hypothetical materials generated by our inverse design engine and report the top 20 candidate noncentrosymmetric materials with 2 to 4 elements and top 20 borate candidates.","Noncentrosymmetric,SHG,Machine learning,Magpie",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"2ND-HARMONIC,GENERATION",COMPUTATIONAL MATERIALS SCIENCE,http://arxiv.org/pdf/2002.11295,
93,Fabricated shape estimation for additive manufacturing processes with uncertainty,127,,,"Korneev Svyatoslav,Wang Ziyan,Thiagarajan Vaidyanathan,Nelaturi Saigopal","Korneev S,Wang ZY,Thiagarajan V,Nelaturi S",Korneev S,10.1016/j.cad.2020.102852,"Palo Alto Res Ctr PARC, 3333 Coyote Hill Rd, Palo Alto, CA 94304 USA.","We present an approach to map Additive Manufacturing (AM) process parameters and a given tool path to a representation of the as-manufactured shape that captures machine-specific manufacturing uncertainty. Multi-physics models that capture the deposition process at the smallest manufacturing scale are solved to accurately simulate local material accumulation. A surrogate model for the multiphysics simulation is used to practically simulate the material accumulation by locally varying the spatial distribution of material along the tool path. This generates a training set representing a variational class of as-manufactured shapes. Machine specific manufacturing uncertainty is then represented as a 3D kernel obtained by deconvolving the simulated as-printed shape with the tool path. This kernel provides a good estimate of the probability of local material accumulation independent of the chosen part and tool-path. Convolution of the kernel with a tool-path combined with an appropriate super-level-set of the resulting field provides a computationally efficient way to estimate the as-manufactured shape of AM parts. The efficiency results from the highly parallelized implementation of convolution on the GPU. We demonstrate high-resolution shape estimation and visualization of as-printed parts constructed using this approach. We validate the method using data generated by simulating a build process for droplet-based AM, by performing model order reduction of a system of partial differential equations for the 3D Navier-Stokes multiphase flows coupled with heat-transfer and phase change. (C) 2020 Elsevier Ltd. All rights reserved.","Additive manufacturing,Multiphysics,Shape estimation,Machine learning,Visualization",Article; Proceedings Paper,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Computer Science,,4.032,"MECHANICAL-BEHAVIOR,POROSITY,MICROSTRUCTURE,PARAMETERS,DEPOSITION",COMPUTER-AIDED DESIGN,,
94,Probabilistic Approach to Physical Object Disentangling,5,4,5510-5517,"Pajarinen Joni,Arenz Oleg,Peters Jan,Neumann Gerhard","Pajarinen J,Arenz O,Peters J,Neumann G",Pajarinen J,10.1109/LRA.2020.3006789,Technical University of Darmstadt,"Physically disentangling entangled objects from each other is a problem encountered in waste segregation or in any task that requires disassembly of structures. Often there are no object models, and especially with cluttered irregularly shaped objects, the robot cannot create a model of the scene due to occlusion. One of our key insights is that based on previous sensory input we are only interested in moving an object out of the disentanglement around obstacles. That is, we only need to know where the robot can successfully move in order to plan the disentangling. Due to the uncertainty we integrate information about blocked movements into a probability map. The map defines the probability of the robot successfully moving to a specific configuration. Using as cost the failure probability of a sequence of movements we can then plan and execute disentangling iteratively. Since our approach circumvents only previously encountered obstacles, new movements will yield information about unknown obstacles that block movement until the robot has learned to circumvent all obstacles and disentangling succeeds. In the experiments, we use a special probabilistic version of the Rapidly exploring Random Tree (RRT) algorithm for planning and demonstrate successful disentanglement of objects both in 2-D and 3-D simulation, and, on a KUKA LBR 7-DOF robot. Moreover, our approach outperforms baseline methods.","Autonomous systems,collision avoidance,intelligent robots,path planning,probabilistic computing,waste recovery",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Robotics,,3.856,,IEEE ROBOTICS AND AUTOMATION LETTERS,http://arxiv.org/pdf/2002.11495,
95,Improved Classification Scheme Using Fused Wavelet Packet Transform Based Features for Intelligent Myoelectric Prostheses,67,10,8517-8525,"Pancholi Sidharth,Joshi Amit M.","Pancholi S,Joshi AM",Pancholi S,10.1109/TIE.2019.2946536,National Institute of Technology (NIT System),"Electromyography (EMG) signal is gaining popularity to developn intelligent bionics and prosthetic devices using machine learning techniques. Feature extraction is essential step for the EMG pattern recognition based application. In this article, a fused wavelet packet transform based feature extraction approach is proposed for EMG pattern classification. Total nine subjects (six intact and three amputees) are recruited for the data acquisition. Data acquisition is performed by an ADS1298-based system with eight bipolar electrodes. Further 11 activities are performed by each subject at the time of EMG signal recording including lateral grasp, cylindrical grasp, spherical grasp, and grasp with force. The visual feedback system is utilized for EMG signal acquisition of amputees. The comparison of commonly used wavelet transform based features and proposed fused wavelet transform based features is also presented with respect to classification accuracy and time complexity. The proposed method exhibits highest classification accuracy up to 98.32% for the amputees using discriminant analysis classification with marginal variation in time complexity. Similar trends in results are observed when standard dataset (NinaPro) has been utilized. The results validate the enhanced performance of the proposed technique over conventional counterparts.","Electromyography,Feature extraction,Muscles,Electrodes,Wavelet transforms,Prosthetics,Amputees,classification,electromyography (EMG),prosthetics,phantom limb,wavelet",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Engineering,Instruments & Instrumentation",,8.882,"PATTERN-RECOGNITION,GESTURE,RECOGNITION,EMG,SIGNALS",IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS,,
96,Monitoring the cleaning of food fouling in pipes using ultrasonic measurements and machine learning,116,,,"Escrig J.,Woolley E.,Simeone A.,Watson N. J.","Escrig J,Woolley E,Simeone A,Watson NJ",Watson NJ,10.1016/j.foodcont.2020.107309,University of Nottingham,"Food and drink production equipment is routinely cleaned to ensure it remains hygienic and operating under optimal conditions. A limitation of existing cleaning systems is that they do not know when the fouling material has been removed so nearly always over-clean, incurring significant economic and environmental costs. This work has studied the use of ultrasonic measurements and a range of different machine learning classification methods to monitor the fouling removal of food materials in plastic and metal cylindrical pipes. The experimental results showed that the developed techniques could predict the presence of fouling with prediction confidence as high as 100% for both plastic and metal pipes. The sensor technique performed marginally better in the plastic pipe and similar performance was found for the all of the machine learning methods studied. This work has demonstrated the potential of low-cost ultrasonic sensors to monitor and therefore optimise cleaning processes within pipes. It is discussed how new data set labelling strategies will be required for the techniques to be used effectively within production environments.","Ultrasonic measurements,Machine learning,Clean-in-Place,Sensors,Fouling monitoring,Food and drink manufacturing",Article; Proceedings Paper,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Food Science & Technology,,5.498,"IN-PLACE,PROCESSES,SYSTEM,SPECTROSCOPY,LINE",FOOD CONTROL,https://nottingham-repository.worktribe.com/preview/4348495/Author%20accepted%20manuscript-1.pdf,
97,Silver clusters shape determination from in-situ XANES data,175,,,"Timoshenko Janis,Roese Stefanie,Hoevel Heinz,Frenkel Anatoly I.","Timoshenko J,Roese S,Hovel H,Frenkel AI",Timoshenko J,10.1016/j.radphyschem.2018.11.003,State University of New York (SUNY) System,"Knowledge of nanoparticle size, shape and morphology and of their in-situ transformations is crucial for establishing structure-properties relationship in nanosized materials that find applications, e.g., in plasmonic devices and heterogenous catalysis. Here we demonstrate that this information can be extracted reliably from insitu X-ray absorption near edge structure (XANES) data, by combining ab-initio XANES simulations and machine learning (artificial neural network (NN)) approaches. Here we use NN-XANES method to extract information about the size, shape and interatomic distances in silver clusters, and to monitor their changes during the temperature-controlled particle aggregation.","Nanoparticles,Cluster assembly,Shape determination,XANES,Machine learning,Neural networks",Article; Proceedings Paper,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Chemistry,Nuclear Science & Technology,Physics",,2.411,"ABSORPTION,FINE-STRUCTURE,PLATINUM,NANOPARTICLES,SIZE,PARTICLES,EXAFS",RADIATION PHYSICS AND CHEMISTRY,https://bib-pubdb1.desy.de/record/421182/files/document%2823%29.pdf,
98,,,,,,,,,,,,,,,,,,,,
99,,,,,,,,,,,,,,,,,,,,
100,Modeling a Thermochemical Reactor of a Solar Refrigerator by BaCl2-NH3 Sorption Using Artificial Neural Networks and Mathematical Symmetry Groups,2020,,,"Meza-Cruz Onesimo,Pilatowsky Isaac,Perez-Ramirez Agustin,Rivera-Blanco Carlos,El Hamzaoui Youness,Perez-Ramirez Miguel,Sanchez Mauricio A.","Meza-Cruz O,Pilatowsky I,Perez-Ramirez A,Rivera-Blanco C,El Hamzaoui Y,Perez-Ramirez M,Sanchez MA",Perez-Ramirez A,10.1155/2020/9098709,"Univ Autonoma Carmen, Cd Del Carmen Campeche 24039, Mexico.","The aim of this work is to present a model for heat transfer, desorbed refrigerant, and pressure of an intermittent solar cooling system's thermochemical reactor based on backpropagation neural networks and mathematical symmetry groups. In order to achieve this, a reactor was designed and built based on the reaction of BaCl2-NH3. Experimental data from this reactor were collected, where barium chloride was used as a solid absorbent and ammonia as a refrigerant. The neural network was trained using the Levenberg-Marquardt algorithm. The correlation coefficient between experimental data and data simulated by the neural network wasr = 0.9957. In the neural network's sensitivity analysis, it was found that the inputs, reactor's heating temperature and sorption time, influence neural network's learning by 35% and 20%, respectively. It was also found that, by applying permutations to experimental data and using multibase mathematical symmetry groups, the neural network training algorithm converges faster.","BARIUM CHLORIDE-AMMONIA,EXPANDED GRAPHITE COMPOUND,PERFORMANCE PREDICTION,MASS-TRANSFER,HEAT,DESIGN",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Engineering,Mathematics",,1.27,"BARIUM,CHLORIDE-AMMONIA,EXPANDED,GRAPHITE,COMPOUND,PERFORMANCE,PREDICTION,MASS-TRANSFER,HEAT,DESIGN",MATHEMATICAL PROBLEMS IN ENGINEERING,https://downloads.hindawi.com/journals/mpe/2020/9098709.pdf,
