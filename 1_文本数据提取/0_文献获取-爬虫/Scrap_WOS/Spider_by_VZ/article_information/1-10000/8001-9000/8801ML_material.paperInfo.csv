,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,PathSRGAN: Multi-Supervised Super-Resolution for Cytopathological Images Using Generative Adversarial Network,39,9,2920-2930,"Ma Jiabo,Yu Jingya,Liu Sibo,Chen Li,Li Xu,Feng Jie,Chen Zhixing,Zeng Shaoqun,Liu Xiuli,Cheng Shenghua","Ma JB,Yu JY,Liu SB,Chen L,Li X,Feng J,Chen ZX,Zeng SQ,Liu XL,Cheng SH",Liu XL; Cheng SH,10.1109/TMI.2020.2980839,Huazhong University of Science & Technology,"In the cytopathology screening of cervical cancer, high-resolution digital cytopathological slides are critical for the interpretation of lesion cells. However, the acquisition of high-resolution digital slides requires high-end imaging equipment and long scanning time. In the study, we propose a GAN-based progressive multi-supervised super-resolution model called PathSRGAN (pathology super-resolution GAN) to learn the mapping of real low-resolution and high-resolution cytopathological images. With respect to the characteristics of cytopathological images, we design a new two-stage generator architecture with two supervision terms. The generator of the first stage corresponds to a densely-connected U-Net and achieves 4x to 10x super resolution. The generator of the second stage corresponds to a residual-in-residual DenseBlock and achieves 10x to 20x super resolution. The designed generator alleviates the difficulty in learning the mapping from 4x images to 20x images caused by the great numerical aperture difference and generates high quality high-resolution images. We conduct a series of comparison experiments and demonstrate the superiority of PathSRGAN to mainstream CNN-based and GAN-based super-resolution methods in cytopathological images. Simultaneously, the reconstructed high-resolution images by PathSRGAN improve the accuracy of computer-aided diagnosis tasks effectively. It is anticipated that the study will help increase the penetration rate of cytopathology screening in remote and impoverished areas that lack high-end imaging equipment.","Generators,Image reconstruction,Gallium nitride,Cervical cancer,Microscopy,Cervical cancer,cytopathological images,generative adversarial learning,super resolution",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORKS",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
2,Autonomous Learning Multiple-Model zero-order classifier for heart sound classification,94,,,"Soares Eduardo,Angelov Plamen,Gu Xiaowei","Soares E,Angelov P,Gu XW",Soares E,10.1016/j.asoc.2020.106449,Lancaster University,"This paper proposes a new extended zero-order Autonomous Learning Multiple-Model (ALMMo-0*) neuro-fuzzy approach in order to classify different heart disorders through sounds. ALMMo-0* is build upon the recently introduced ALMMo-0. In this paper ALMMo-0 is extended by adding a preprocessing structure which improves the performance of the proposed method. ALMMo-0* has as a learning engine composed of hierarchical a massively parallel set of 0-order fuzzy rules, which are able to self-adapt and provide transparent and human understandable IF ... THEN representation. The heart sound recordings considered in the analysis were sourced from several contributors around the world. Data were collected from both clinical and nonclinical environment, and from healthy and pathological patients. Differently from mainstream machine learning approaches, ALMMo-0* is able to learn from unseen data. The main goal of the proposed method is to provide highly accurate models with high transparency, interpretability, and explainability for heart disorder diagnosis. Experiments demonstrated that the proposed neuro-fuzzy-based modeling is an efficient framework for these challenging classification tasks surpassing its state-of-the-art competitors in terms of classification accuracy. Additionally, ALMMo-0* produced transparent AnYa type fuzzy rules, which are human interpretable, and may help specialists to provide more accurate diagnosis. Medical doctors can easily identify abnormal heart sounds by comparing a patient's sample with the identified prototypes from abnormal samples by ALMMo-0*. (C) 2020 Elsevier B.V. All rights reserved.","Autonomous Learning,Data clouds,Evolving fuzzy systems,Heart sound classification,Rule-based system",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,6.607,"PERFORMANCE,BRAIN",APPLIED SOFT COMPUTING,https://eprints.lancs.ac.uk/id/eprint/144496/1/Autonomous_Learning_Multiple_Model_Zero_Order_Classifier_for_Heart_Sound_Classification_ASOC.pdf,
3,Extraction of Nonlinear Synergies for Proportional and Simultaneous Estimation of Finger Kinematics,67,9,2646-2658,"Dwivedi Sanjay Kumar,Ngeo Jimson,Shibata Tomohiro","Dwivedi SK,Ngeo J,Shibata T",Dwivedi SK,10.1109/TBME.2020.2967154,Kyushu Institute of Technology,"Objective: Proportional and simultaneous est-imation of finger kinematics from surface EMG based on the assumption that there exists a correlation between muscle activations and finger kinematics in low dimensional space. Methods: We employ Manifold Relevance Determination (MRD), a multi-view learning model with a nonparametric Bayesian approach, to extract the nonlinear muscle and kinematics synergies and the relationship between them by studying muscle activations (input-space) together with the finger kinematics (output-space). Results: This study finds that there exist muscle synergies which are associated with kinematic synergies. The acquired nonlinear synergies and the association between them has further been utilized for the estimation of finger kinematics from muscle activation inputs, and the proposed approach has outperformed other commonly used linear and nonlinear regression approaches with an average correlation coefficient of 0.91 +/- 0.03. Conclusion: There exists an association between muscle and kinematic synergies which can be used for the proportional and simultaneous estimation of finger kinematics from the muscle activation inputs. Significance: The findings of this study not only presents a viable approach for accurate and intuitive myoelectric control but also provides a new perspective on the muscle synergies in the motor control community.","Muscle synergies,kinematic synergies,manifold relevance determination (MRD),proportional,and simultaneous myoelectric control",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"MUSCLE,SYNERGIES,MYOELECTRIC,CONTROL,HAND,SYNERGIES,EMG,SIGNALS,SURFACE,EMG,ONLINE,MOVEMENTS,CLASSIFICATION,FORCE,MODEL",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
4,Generation of artificial data sets to train convolutional neural networks for spectral unmixing,87,9,542-552,"Anastasiadis Johannes,Benzing Philipp,Leon Fernando Puente","Anastasiadis J,Benzing P,Leon FP",Anastasiadis J,10.1515/teme-2020-0008,Helmholtz Association,"This paper presents a method to generate training data for artificial neural networks for spectral unmixing. Therefor, only the spectra of the pure substances involved and, depending on the model used, a few spectra of mixed substances to determine the parameters are needed. With mixing models, which can also be used directly for spectral unmixing, large quantities of spectra can be generated for training. In contrast to the direct use of mixing models, where a spectrum per pure substance is used, this approach takes into account the spectrum variability by using different spectra of each pure substance. The property of artificial neural networks to learn significant features based on large amounts of data is exploited here.","Spectral unmixing,nonlinear mixing models,spectral variability,artificial neural networks",Article,"WALTER DE GRUYTER GMBH, GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY",Instruments & Instrumentation,,0.416,"REFLECTANCE,SPECTROSCOPY,MATERIAL,ABUNDANCES,MODEL,FOOD",TM-TECHNISCHES MESSEN,https://publikationen.bibliothek.kit.edu/1000121183/110446052,
5,Differentiating autoimmune pancreatitis from pancreatic ductal adenocarcinoma with CT radiomics features,101,9,555-564,"Park S.,Chu L. C.,Hruban R. H.,Vogelstein B.,Kinzler K. W.,Yuille A. L.,Fouladi D. F.,Shayesteh S.,Ghandili S.,Wolfgang C. L.","Park S,Chu LC,Hruban RH,Vogelstein B,Kinzler KW,Yuille AL,Fouladi DF,Shayesteh S,Ghandili S,Wolfgang CL",Kawamoto S,10.1016/j.diii.2020.03.002,Johns Hopkins University,"Purpose: The purpose of this study was to determine whether computed tomography (CT)-based machine learning of radiomics features could help distinguish autoimmune pancreatitis (AIP) from pancreatic ductal adenocarcinoma (PDAC).
Materials and Methods: Eighty-nine patients with AIP (65 men, 24 women; mean age, 59.7 +/- 13.9 [SD] years; range: 21-83 years) and 93 patients with PDAC (68 men, 25 women; mean age, 60.1 +/- 12.3 [SD] years; range: 36-86 years) were retrospectively included. All patients had dedicated dual-phase pancreatic protocol CT between 2004 and 2018. Thin-slice images (0.75/0.5 mm thickness/increment) were compared with thick-slices images (3 or 5 mm thickness/increment). Pancreatic regions involved by PDAC or AIP (areas of enlargement, altered enhancement, effacement of pancreatic duct) as well as uninvolved parenchyma were segmented as three-dimensional volumes. Four hundred and thirty-one radiomics features were extracted and a random forest was used to distinguish AIP from PDAC. CT data of 60 AIP and 60 PDAC patients were used for training and those of 29 AIP and 33 PDAC independent patients were used for testing.
Results: The pancreas was diffusely involved in 37 (37/89; 41.6%) patients with AIP and not diffusely in 52 (52/89; 58.4%) patients. Using machine learning, 95.2% (59/62; 95% confidence interval [CI]: 89.8-100%), 83.9% (52:67; 95% CI: 74.7-93.0%) and 77.4% (48/62; 95% CI: 67.0-87.8%) of the 62 test patients were correctly classified as either having PDAC or AIP with thin-slice venous phase, thin-slice arterial phase, and thick-slice venous phase CT, respectively. Three of the 29 patients with AIP (3/29; 10.3%) were incorrectly classified as having PDAC but all 33 patients with PDAC (33/33; 100%) were correctly classified with thin-slice venous phase with 89.7% sensitivity (26/29; 95% CI: 78.6-100%) and 100% specificity (33/33; 95% CI: 93-100%) for the diagnosis of AIP, 95.2% accuracy (59/62; 95% CI: 89.8-100%) and area under the curve of 0.975 (95% CI: 0.936-1.0).
Conclusions: Radiomic features help differentiate AIP from PDAC with an overall accuracy of 95.2%. (C) 2020 Societe francaise de radiologie. Published by Elsevier Masson SAS. All rights reserved.","Radiomics,Texture analysis,Autoimmune pancreatitis,Pancreatic ductal carcinoma,Computed tomography (CT)",Article,"ELSEVIER MASSON, CORP OFF, 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE","Radiology, Nuclear Medicine & Medical Imaging",,3.206,"LYMPHOPLASMACYTIC,SCLEROSING,PANCREATITIS,COMPUTED-TOMOGRAPHY,TEXTURE,ANALYSIS,CARCINOMA,DIAGNOSIS,CRITERIA",DIAGNOSTIC AND INTERVENTIONAL IMAGING,https://doi.org/10.1016/j.diii.2020.03.002,
6,Radiomics for classification of bone mineral loss: A machine learning study,101,9,599-610,"Rastegar S.,Vaziri M.,Qasempour Y.,Akhash M. R.,Abdalvand N.,Shiri I,Abdollahi H.,Zaidi H.","Rastegar S,Vaziri M,Qasempour Y,Akhash MR,Abdalvand N,Shiri I,Abdollahi H,Zaidi H",Abdollahi H,10.1016/j.diii.2020.01.008,Kerman University of Medical Sciences,"Purpose: The purpose of this study was to develop predictive models to classify osteoporosis, osteopenia and normal patients using radiomics and machine learning approaches.
Materials and methods: A total of 147 patients were included in this retrospective single-center study. There were 12 men and 135 women with a mean age of 56.88 +/- 10.6 (SD) years (range: 28-87 years). For each patient, seven regions including four lumbar and three femoral including trochanteric, intertrochanteric and neck were segmented on bone mineral densitometry images and 54 texture features were extracted from the regions. The performance of four feature selection methods, including classifier attribute evaluation (CLAE), one rule attribute evaluation (ORAE), gain ratio attribute evaluation (GRAE) and principal components analysis (PRCA) along with four classification methods, including random forest (RF), random committee (RC). K-nearest neighbor (KN) and logit-boost (LB) were evaluated. Four classification categories, including osteopenia vs. normal, osteoporosis vs. normal, osteopenia vs. osteoporosis and osteoporosis + osteopenia vs. osteoporosis were examined for the defined seven regions. The classification model performances were evaluated using the area under the receiver operator characteristic curve (AUC).
Results: The AUC values ranged from 0.50 to 0.78. The combination of methods RF + CLAE, RF + ORAE and RC + ORAE yielded highest performance (AUC = 0.78) in discriminating between osteoporosis and normal state in the trochanteric region. The combinations of RF + PRCA and LB + PRCA had the highest performance (AUC = 0.76) in discriminating between osteoporosis and normal state in the neck region.
Conclusion: The machine learning radiomic approach can be considered as a new method for bone mineral deficiency disease classification using bone mineral densitometry image features. (C) 2020 Societe francaise de radiologie. Published by Elsevier Masson SAS. All rights reserved.","Bone mineral densitometry (BMD),Radiomics,Machine learning,Osteoporosis,Classification",Article,"ELSEVIER MASSON, CORP OFF, 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE","Radiology, Nuclear Medicine & Medical Imaging",,3.206,"TEXTURE,ANALYSIS,OSTEOPOROSIS,DIAGNOSIS,HEAD",DIAGNOSTIC AND INTERVENTIONAL IMAGING,https://archive-ouverte.unige.ch/unige:132690/ATTACHMENT01,
7,"Deep learning evaluation of pelvic radiographs for position, hardware presence, and fracture detection",130,,,Kitamura Gene,Kitamura G,Kitamura G,10.1016/j.ejrad.2020.109139,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Purpose: Recent papers have shown the utility of deep learning in detecting hip fractures with pelvic radiographs, but there is a paucity of research utilizing deep learning to detect pelvic and acetabular fractures. Creating deep learning models also requires appropriately labeling x-ray positions and hardware presence. Our purpose is to train and test deep learning models to detect pelvic radiograph position, hardware presence, and pelvic and acetabular fractures in addition to hip fractures.
Material and methods: Data was retrospectively acquired between 8/2009-6/2019. A subset of the data was split into 4 position labels and 2 hardware labels to create position labeling and hardware detecting models. The remaining data was parsed with these trained models, labeled based on 6 ""separate"" fracture patterns, and various fracture detecting models were created. A receiver operator characteristic (ROC) curve, area under the curve (AUC), and other output metrics were evaluated.
Results: The position and hardware models performed well with AUC of 0.99-1.00. The AUC for proximal femoral fracture detection was as high as 0.95, which was in line with previously published research. Pelvic and acetabular fracture detection performance was as low as 0.70 for the posterior pelvis category and as high as 0.85 for the acetabular category with the ""separate"" fracture model.
Conclusion: We successfully created deep learning models that can detect pelvic imaging position, hardware presence, and pelvic and acetabular fractures with AUC loss of only 0.03 for proximal femoral fracture.","Deep learning,Artificial intelligence,Machine learning,Radiographs,Fracture",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Radiology, Nuclear Medicine & Medical Imaging",,3.539,,EUROPEAN JOURNAL OF RADIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7483754,
8,Evaluating body composition by combining quantitative spectral detector computed tomography and deep learning-based image segmentation,130,,,"Zopfs David,Bousabarah Khaled,Lennartz Simon,dos Santos Daniel Pinto,Schlaak Max,Theurich Sebastian,Reimer Robert Peter,Maintz David,Haneder Stefan,Hokamp Nils Grosse","Zopfs D,Bousabarah K,Lennartz S,dos Santos DP,Schlaak M,Theurich S,Reimer RP,Maintz D,Haneder S,Hokamp NG",Zopfs D,10.1016/j.ejrad.2020.109153,University of Cologne,"Purpose: Aim of this study was to develop and evaluate a software toolkit, which allows for a fully automated body composition analysis in contrast enhanced abdominal computed tomography leveraging the strengths of both, quantitative information from dual energy computed tomography and simple detection and segmentation tasks performed by deep convolutional neuronal networks (DCNN).
Methods and materials: Both, public and private datasets were used to train and validate DCNN. A combination of two DCNN and quantitative thresholding was used to classify axial CT slices to the abdominal region, classify voxels as fat and muscle and to differentiate between subcutaneous and visceral fat. For validation, patients undergoing repetitive examination (+/- 21 days) and patients who underwent concurrent bioelectrical impedance analysis (BIA) were analyzed. Concordance correlation coefficient (CCC), linear regression and Bland-Altman-Analysis were used as statistical tests.
Results: Results provided from the algorithm toolkit were visually validated. The automated classifier was able to extract slices of interest from the full body scans with an accuracy of 98.7 %. DCNN-based segmentation for subcutaneous fat reached a mean dice similarity coefficient of 0.95. CCCs were 0.99 for both muscle and subcutaneous fat and 0.98 for visceral fat in patients undergoing repetitive examinations (n = 48). Further linear regression and Bland-Altman-Analyses suggested good agreement (r(2):0.67-0.88) between the software toolkit and patients who underwent
concurrent BIA (n = 39). Conclusion: We describe a software toolkit allowing for an accurate analysis of body composition utilizing a combination of DCNN- and threshold-based segmentations from spectral detector computed tomography.","Body composition,Intra-abdominal fat,Machine learning,Sarcopenia,Tomography,X-ray computed",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Radiology, Nuclear Medicine & Medical Imaging",,3.539,"BIOELECTRICAL-IMPEDANCE,ANALYSIS,DUAL-ENERGY,CT,SARCOPENIA,MUSCLE,FAT",EUROPEAN JOURNAL OF RADIOLOGY,,
9,Automated identification and characterization of two-dimensional materials via machine learning-based processing of optical microscope images,39,,,"Yang Juntan,Yao Haimin","Yang JT,Yao HM",Yao HM,10.1016/j.eml.2020.100771,Hong Kong Polytechnic University,"Mechanical characterization of two-dimensional (2D) materials has always been a challenging task due to their extremely small thickness. The current prevailing methods to measure the strength of 2D materials normally involve sophisticated testing facilities and complicated procedures of sample preparation, which are usually costly and time-consuming. In this paper, we propose a cost-effective and rapid approach to characterizing the strength of 2D materials by processing optical microscope images of the mechanically exfoliated 2D materials. Specifically, a machine learning-based model is developed to automate the identification of 2D material flakes of different layers from the optical microscope images, followed by the determination of their lateral size. The statistical distribution of the flakes' size is obtained and used to estimate the strength of the associated 2D material based on a distribution-property relationship we developed before. A case study with graphene indicates that the present machine learning-based method, as compared to the previous manual one, enhances the efficiency of characterization by more than one order of magnitude with no sacrifice of the accuracy. (C) 2020 Elsevier Ltd. All rights reserved.","Image processing and recognition,Machine learning,Inverse problem,Mechanical characterization",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science,Mechanics",,5.532,"PEEL-ZONE,MODEL,GRAPHENE,STRENGTH,FRACTURE,THICKNESS,FILMS",EXTREME MECHANICS LETTERS,,
10,Machine learning for the prediction of stopping powers,478,,21-33,"Parfitt William A.);,Jackman Richard B.","Parfitt WA,Jackman RB",Jackman RB,10.1016/j.nimb.2020.05.015,University of London,"The stopping power of a material upon interaction with an energetic ion is the key measure of how far that ion will travel. The implications of accurate particle range calculations are tremendous, affecting every single application in which particle radiation is involved, from nuclear power to medicine. An approach is presented which attempts to overcome current shortcomings in the theoretical understanding of stopping power, as well as the methods used to interpret and exploit measured data. This is a considerable challenge, however the use of a novel machine learning methodology is shown to hold great promise in this endeavour: the ultimate aim being the ability to correctly predict the stopping value for any energy, ion and target combination, having no preexisting experimental data.
A random forest regression algorithm is trained using over 34,000 experimental measurements, representing stopping power values for 522 ion-target combinations across the energy range 10(-)3 to 10(2) MeV/amu, and ion and target atomic masses 1 to > 240. Evaluation is carried out using several fundamental error metrics, over the whole dataset as well as for individual combinations, to provide the most comprehensive understanding of performance when tested under strict cross-validation criteria. The resulting model is shown to yield predicted stopping power curves corresponding closely to those of the true experimental values, with an ability to generalise across target elements, compounds, mixtures, alloys and polymers, irrespective of phase, and for a wide range of ion masses.","Machine learning,Random forest,Stopping power,SRIM",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Nuclear Science & Technology,Physics",,1.312,"QSAR,VALIDATION,PARTICLES,MODELS,RANGE",NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION B-BEAM INTERACTIONS WITH MATERIALS AND ATOMS,https://discovery.ucl.ac.uk/10101647/7/Jackman_Manuscript.pdf,
11,Automated glaucoma detection using GIST and pyramid histogram of oriented gradients (PHOG) descriptors,137,,3-11,"Gour Neha,Khanna Pritee","Gour N,Khanna P",Gour N; Khanna P,10.1016/j.patrec.2019.04.004,"Indian Institute of Information Technology Design & Manufacturing, Jabalpur","Effective diagnosis of glaucoma mainly relies on the analysis of optic disc characteristics of retina. Glaucoma is considered as second leading cause of blindness and its early detection prevents patients from temporary or permanent blindness. It effects the intensity and shape near optic disc of the retina. Fundus photography has revolutionized the field of ophthalmology and helped in visualizing the structure of optic disc. The proposed work aims to develop an automated diagnostic system based on fundus images for glaucoma disease. It focuses on extraction of GIST and pyramid histogram of oriented gradients (PHOG) features from preprocessed fundus images. The extracted features are ranked and selected through principal component analysis (PCA) to choose significant features. The classification into glaucomatous images is done with SVM classifier on fundus images of Drishti-GS1 and HRF databases. The results obtained from the proposed method are compared with recent glaucoma detection techniques in the literature, including deep learning methodologies, on the basis of accuracy and AUC parameters. The performance of the system is also validated by glaucoma expert from Sharp Sight Group of Eye Hospitals, Delhi-NCR, India. (C) 2019 Elsevier B.V. All rights reserved.","Glaucoma classification,GIST features,PHOG features,Automated disease diagnosis",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,3.615,"RETINAL,FUNDUS,IMAGES,OPTIC,DISC,CUP,SEGMENTATION,LOCALIZATION,EXTRACTION,DIAGNOSIS,SYSTEM",PATTERN RECOGNITION LETTERS,,
12,Deep video-to-video transformations for accessibility with an application to photosensitivity,137,,99-107,"Barbu Andrei,Banda Dalitso,Katz Boris","Barbu A,Banda D,Katz B",Barbu A,10.1016/j.patrec.2019.01.019,Massachusetts Institute of Technology (MIT),"We demonstrate how to construct a new class of visual assistive technologies that, rather than extract symbolic information, learn to transform the visual environment to make it more accessible. We do so without engineering which transformations are useful allowing for arbitrary modifications of the visual input. As an instantiation of this idea we tackle a problem that affects and hurts millions worldwide: photosensitivity. Any time an affected person opens a website, video, or some other medium that contains an adverse visual stimulus, either intended or unintended, they might experience a seizure with potentially significant consequences. We show how a deep network can learn a video-to-video transformation rendering such stimuli harmless while otherwise preserving the video. This approach uses a specification of the adverse phenomena, the forward transformation, to learn the inverse transformation. We show how such a network generalizes to real-world videos that have triggered numerous seizures, both by mistake and in politically-motivated attacks. A number of complimentary approaches are demonstrated including using a hand-crafted generator and a GAN using a differentiable perceptual metric. Such technology can be deployed offline to protect videos before they are shown or online with assistive glasses or real-time post processing. Other applications of this general technique include helping those with limited vision, attention deficit hyperactivity disorder, and autism. (C) 2019 Published by Elsevier B.V.","Photosensitivity,Accessibility,Computer vision,Video-to-video transformation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,3.615,,PATTERN RECOGNITION LETTERS,,
13,A Neural Element Method,17,7,,Liu G. R.,Liu GR,Liu GR,10.1142/S0219876220500218,University of Cincinnati,"Methods of artificial neural networks (ANNs) have been applied to solve various science and engineering problems. TrumpetNets and TubeNets were recently proposed by the author for creating two-way deepnets using the standard finite element method (FEM) and smoothed FEM (S-FEM) as trainers. The significance of these specially configured ANNs is that the solutions to inverse problems have been, for the first time, analytically derived in explicit formulae.
This paper presents a novel neural element method (NEM) with a focus on mechanics problems. The key idea is to use artificial neurons to form elemental units called neural-pulse-units (NPUs), using which the shape functions can then be constructed, and used in the standard weak and weakened-weak (W2) formulations to establish discrete stiffness matrices, similar to the standard FEM and S-FEM. Theory, formulation and codes in Python are presented in detail. Numerical examples are then used to demonstrate this novel NEM. For the first time, we have made a clear connection in theory, formulations and coding, between ANN methods and physical-law-based computational methods. We believe that this novel NEM fundamentally changes the way of approaching mechanics problems, and opens a window of opportunity for a range of applications. It offers a new direction of research on unconventional computational methods. It may also have an impact on how the well-established weak and W2 formulations can be introduced to machine learning processes, for example, creating well-behaved loss functions with preferable convexity.","Artificial intelligence,artificial neural network,neural element,physic-law-based method,computational mechanics,computational method",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE","Engineering,Mathematics",,1.861,"INVERSE,IDENTIFICATION,ELASTIC-WAVES,MATERIAL,CONSTANTS,TISSUE",INTERNATIONAL JOURNAL OF COMPUTATIONAL METHODS,,
14,Exploring Elastoplastic Constitutive Law of Microstructured Materials Through Artificial Neural Network-A Mechanistic-Based Data-Driven Approach,87,9,,"Yang Hang,Qiu Hai,Xiang Qian,Tang Shan,Guo Xu","Yang H,Qiu H,Xiang Q,Tang S,Guo X",Tang S; Guo X,10.1115/1.4047208,Dalian University of Technology,"In this paper, a data-driven approach for constructing elastoplastic constitutive law of microstructured materials is proposed by combining the insights from plasticity theory and the tools of artificial intelligence (i.e., constructing yielding function through ANN) to reduce the required amount of data for machine learning. Illustrative examples show that the constitutive laws constructed by the present approach can be used to solve the boundary value problems (BVPs) involving elastoplastic materials with microstructures under complex loading paths (e.g., cyclic/reverse loading) effectively. The limitation of the proposed approach is also discussed.","data-driven,constitutive law,microstructured elastoplastic materials,yielding function,artificial neural network (ANN)",Article,"ASME, TWO PARK AVE, NEW YORK, NY 10016-5990 USA",Mechanics,,2.507,"CONSISTENT,CLUSTERING,ANALYSIS,HETEROGENEOUS,MATERIAL,PREDICTION",JOURNAL OF APPLIED MECHANICS-TRANSACTIONS OF THE ASME,,
15,Automatic detection of coagulation and carbonization in laser applications using machine learning techniques,30,9,,Yucelbas Sule,Yucelbas S,Yucelbas S,10.1088/1555-6611/ab9d75,Hakkari University,"Laser-induced thermal treatment (LITT) technique is considered to be the most effective method for minimally invasive surgical procedures. However, the parameters of laser systems used in surgical operations need to be adjusted very precisely. Otherwise, irreversible situations may occur especially in the operation of sensitive organs such as the brain. In order to avoid such undesirable situations, artificial intelligence algorithms are used in the fields of engineering, aerospace and automotive, especially in medicine and biomedical. In this study, it was aimed to automatically detect Coagulation (Co) and Carbonization (Ca) states using a total of 140 data obtained as a result of LITT experimental applications (1070 nm and seven different power density values) onex vivoliver tissue. In the first part of the study, which consists of two main stages, the data set was presented to seven different expert systems based on artificial intelligence (C4.5, KNN, ANN, RF, MLR, SMO-SVM and LWLDS), and automatically Co and Ca formations were determined. Among the proposed expert systems, the C4.5 algorithm showed the best performance with 100% accuracy and 0% error rate. In the second stage of the study, the same data set was given to Attribute Information Gain (AIG) ranking system, which was used to determine the minimum number of feature that would provide the maximum performance, and the gain values of the attributes were calculated. As a result of this application, the most effective feature was found to be Normalized Depth of Thermal Damage (NDeTD) with 100% accuracy rate. Thus, the purpose of using the AIG system has been successfully achieved. As a result, thanks to the expert systems presented within the scope of the study, Co and Ca formations were determined automatically with 100% success rate according to the required parameters without laser application onex vivoliver tissue. The fact that the aim of the study was realized with the highest success rate is thought to be the first in terms of contributing to the literature. Through this study, as a result of the laser treatment to be applied on cancerous tissue, it can be predicted whether the tissue will suffer irreversible damage and necessary precautions can be taken beforehand.","laser-induced thermal therapy,liver,ex vivo,artificial intelligence,machine learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Optics,Physics",,1.157,"HEPATOCELLULAR-CARCINOMA,MORPHOLOGICAL,FEATURES,ABLATION,STATISTICS,THERAPY,SYSTEM",LASER PHYSICS,,
16,Detection of radioactive waste sites in the Chornobyl exclusion zone using UAV-based lidar data and multispectral imagery,167,,345-362,"Briechle S.,Molitor N.,Krzystek P.,Vosselman G.","Briechle S,Molitor N,Krzystek P,Vosselman G",Briechle S,10.1016/j.isprsjprs.2020.06.015,University of Munich,"The severe accident at the Chornobyl Nuclear Power Plant (ChNPP) in 1986 resulted in extraordinary contamination of the surrounding territory, which necessitated the creation of the Chornobyl Exclusion Zone (ChEZ). During the accident, liquidation materials contaminated by radioactive fallout (e.g., contaminated soil and trees) were buried in so-called Radioactive Waste Temporary Storage Places (RWTSPs). The exact locations of these burials were not always sufficiently documented. However, for safety management, including eventual remediation works, it is crucial to know their locations and rely on precise hazard maps. Over the past 34 years, most of these so-called trenches and clamps have been exposed to natural processes. In addition to settlement and erosion, they have been overgrown with dense vegetation. To date, more than 700 burials have been thoroughly investigated, but a large number of burial sites (approximately 300) are still unknown. In the past, numerous burials were identified based on settlement or elevation in the decimeter range, and vegetation anomalies that tend to appear in the immediate vicinity. Nevertheless, conventional detection methods are time-, effort- and radiation dose-intensive. Airborne gamma spectrometry and visual ground inspection of morphology and vegetation can provide useful complementary information, but it is insufficient for precisely localizing unknown burial sites in many cases. Therefore, sensor technologies, such as UAV-based lidar and multispectral imagery, have been identified as potential alternative solutions. This paper presents a novel method to detect radioactive waste sites based on a set of prominent features generated from high-resolution remote sensing data in combination with a random forest (RF) classifier. Initially, we generate a digital terrain model (DTM) and 3D vegetation map from the data and derive tree-based features, including tree density, tree height, and tree species. Feature subsets compiled from normalized DTM height, fast point feature histograms (FPFH), and lidar metrics are then incorporated. Next, an RF classifier is trained on reference areas defined by visual interpretation of the DTM grid. A backward feature selection strategy reduces the feature space significantly and avoids overfitting. Feature relevance assessment clearly demonstrates that the members of all feature subsets represent a final list of the most prominent features. For three representative study areas, the mean overall accuracy (OA) is 98.2% when using area-wide test data. Cohens' kappa coefficient kappa ranges from 0.609 to 0.758. Additionally, we demonstrate the transferability of a trained classifier to an adjacent study area (OA = 93.6%, kappa = 0.452). As expected, when utilizing the classifier on geometrically incorrect and incomplete reference data, which were generated from old maps and orthophotos based on visual inspection, the OA decreases significantly to 65.1% (kappa = 0.481). Finally, detection is verified through 38 borings that successfully confirm the existence of previously unknown buried nuclear materials in classified areas. These results demonstrate that the proposed methodology is applicable to detecting area-wide unknown radioactive biomass burials in the ChEZ.","UAV,Lidar,Multispectral imagery,Radioactive waste sites,3D vegetation mapping,Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Physical Geography,Geology,Remote Sensing,Imaging Science & Photographic Technology",,9.948,"TREE,SPECIES,CLASSIFICATION,RANDOM,FOREST,CLASSIFIER,INTENSITY,DATA,CONTAMINATION,SEGMENTATION,IRRADIATION,EXTRACTION,TRENCH,RANGE",ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING,,
17,Deep learning-based automated image segmentation for concrete petrographic analysis,135,,,"Song Yu,Huang Zilong,Shen Chuanyue,Shi Humphrey,Lange David A.","Song Y,Huang ZL,Shen CY,Shi H,Lange DA",Song Y,10.1016/j.cemconres.2020.106118,University of Illinois System,"The standard petrography test method for measuring air voids in concrete (ASTM C457) requires a meticulous and long examination of sample phase composition under a stereomicroscope. The high expertise and specialized equipment discourage this test for routine concrete quality control. Though the task can be alleviated with the aid of color-based image segmentation, additional surface color treatment is required. Recently, deep learning algorithms using convolutional neural networks (CNN) have achieved unprecedented segmentation performance on image testing benchmarks. In this study, we investigated the feasibility of using CNN to conduct concrete segmentation without the use of color treatment. The CNN demonstrated a strong potential to process a wide range of concretes, including those not involved in model training. The experimental results showed that CNN outperforms the color-based segmentation by a considerable margin, and has comparable accuracy to human experts. Furthermore, the segmentation time is reduced to mere seconds.","Concrete petrography,Machine learning,Deep learning,Semantic segmentation,Hardened air void analysis",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Construction & Building Technology,Materials Science",,11.019,"FIRE-DAMAGED,CONCRETE,AIR,RESISTANCE,CEMENT",CEMENT AND CONCRETE RESEARCH,http://arxiv.org/pdf/2005.10434,
18,Topological analysis of X-ray CT data for the recognition and trending of subtle changes in microstructure under material aging,182,,,"Maiti A.,Venkat A.,Kosiba G. D.,Shaw W. L.,Sain J. D.,Lindsey R. K.,Grant C. D.,Bremer P-T,Gyulassy A. G.,Pascucci V","Maiti A,Venkat A,Kosiba GD,Shaw WL,Sain JD,Lindsey RK,Grant CD,Bremer PT,Gyulassy AG,Pascucci V",Maiti A; Gee RH,10.1016/j.commatsci.2020.109782,United States Department of Energy (DOE),"X-ray computed tomography (CT) is an established non-destructive tool for 3D imaging of multiphasic composites. Numerous applications of X-ray CT in medical diagnosis and materials characterization have been reported, many involving field-specific innovations in the imaging technology itself. Yet, quantitative summarization to link image features to properties of interest has been rare. We address this issue by employing state-of-the-art technics in scalar field topology for the summarization of X-ray CT images of an example biphasic system. By varying processing-parameters we create different microstructures, evolve them through accelerated thermal aging, CT-image them pre- and post-aged, and demonstrate the ability of our image summarization method to systematically track process- and age-related changes, which can often be very subtle. A novel aspect of the algorithm involves recognition over multiple resolution levels, which provides deeper insight into the pattern relationship between grain-like features and their neighbors. The method is general, adaptable to diverse image reconstruction methods and materials systems, and particularly useful in applications where practical constraints on the sample-size limits the reliable use of more complex models, e.g., convolutional neural networks.","Computed Tomography,Processing-Structure relationship,Structure-Function correlation,Topological Descriptor,Age-related changes",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,TOMOGRAPHY,COMPUTATIONAL MATERIALS SCIENCE,https://www.sciencedirect.com/science/article/am/pii/S0927025620302731,
19,Using neural networks to represent von Mises plasticity with isotropic hardening,132,,,"Zhang Annan,Mohr Dirk","Zhang AN,Mohr D",Mohr D,10.1016/j.ijplas.2020.102732,ETH Zurich,"Neural networks are universal function approximators that form the backbone of most modern machine learning based models. Starting from a conventional return-mapping scheme, the algorithmic description of von Mises plasticity with isotropic hardening is mathematically reformulated such that the relationship between the strain and stress histories may be modeled through a neural network function. In essence, the neural network provides an estimate of the instantaneous elasto-plastic tangent matrix as a function of the current stress and plastic work density. For plane stress conditions, it thus describes a non-linear mapping from R-4 to R-6. The neural network function is first developed for uniaxial stress conditions including loading histories with tension-compression reversal. Special attention is paid to the identification of the network architecture and artifacts related to overfitting. Furthermore, the performance of networks featuring the same number of total parameters, but different levels of non-linearity, is compared. It is found that a fully-connected feedforward network with five hidden layers and 15 neurons per layer can describe the plane stress plasticity problem with good accuracy. The results also show that a high density of training data (of the order of ten to hundred thousand points) is needed to obtain reasonable estimates for arbitrary loading paths with strains of up to 0.2. The final neural network model is implemented into finite element software through the user material subroutine interface. A simulation of a notched tension experiment is performed to demonstrate that the neural network model yields the same (heterogeneous) mechanical fields as a conventional J2 plasticity model. The present work demonstrates that it is feasible to describe the stress-strain response of a von Mises material through a neural network model without any explicit representation of the yield function, flow rule, hardening law or evolution constraints. It is emphasized that the demonstration of feasibility is the focus of the present work, while the assessment of potential computational advantages is deferred to future research.","J2 plasticity,Machine learning,Elasto-plastic tangent modulus,Return mapping",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Engineering,Materials Science,Mechanics",,7.389,"DYNAMIC,RECRYSTALLIZATION,DISLOCATION,DYNAMICS,SIMULATION,BEHAVIOR,TEMPERATURE,EVOLUTION,METALS",INTERNATIONAL JOURNAL OF PLASTICITY,,
20,Detection of Material Extrusion In-Process Failures via Deep Learning,5,3,,"Zhang Zhicheng,Fidan Ismail,Allen Michael","Zhang ZC,Fidan I,Allen M",Fidan I,10.3390/inventions5030025,Tennessee Technological University,"Additive manufacturing (AM) is evolving rapidly and this trend is creating a number of growth opportunities for several industries. Recent studies on AM have focused mainly on developing new machines and materials, with only a limited number of studies on the troubleshooting, maintenance, and problem-solving aspects of AM processes. Deep learning (DL) is an emerging machine learning (ML) type that has widely been used in several research studies. This research team believes that applying DL can help make AM processes smoother and make AM-printed objects more accurate. In this research, a new DL application is developed and implemented to minimize the material consumption of a failed print. The material used in this research is polylactic acid (PLA) and the DL method is the convolutional neural network (CNN). This study reports the nature of this newly developed DL application and the relationships between various algorithm parameters and the accuracy of the algorithm.","additive manufacturing,machine learning,deep learning,convolutional neural network,failure detection,accuracy",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Engineering,,,,INVENTIONS,https://www.mdpi.com/2411-5134/5/3/25/pdf,
21,Efficient methodology for seismic fragility curves estimation by active learning on Support Vector Machines,86,,,"Sainct Remi,Feau Cyril,Martinez Jean-Marc,Garnier Josselin","Sainct R,Feau C,Martinez JM,Garnier J",Feau C,10.1016/j.strusafe.2020.101972,CEA,"Fragility curves which express the failure probability of a structure as function of a loading intensity measure are nowadays widely used to facilitate the design and decision making of structures/infrastructures against seismic hazard (and possibly other natural hazards), with analysis procedures specified by Seismic Probabilistic Risk Assessment, Performance-Based Earthquake Engineering, and other frameworks. To avoid the use of parametric models (such as the lognormal model) to estimate fragility curves from a reduced number of numerical calculations, a methodology based on Support Vector Machines (SVMs) coupled with an active learning algorithm is proposed in this paper. In practice, input excitation is reduced to some relevant parameters and then SVMs are used for a binary classification of the structural responses relative to a limit threshold of exceedance. Since the output is not binary but a real-valued score, a probabilistic interpretation of the output is exploited to estimate very efficiently fragility curves as score functions or as functions of classical seismic intensity measures.","Fragility curve,Active Learning,Support Vector Machines,Seismic intensity measure indicator",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Engineering,,5.628,"INTENSITY,MEASURES,TIME-HISTORIES,EARTHQUAKE,SIMULATION,UNCERTAINTY,VARIABILITY,PERFORMANCE,DESIGN,MODELS,STEEL",STRUCTURAL SAFETY,,
22,Accelerated prediction of Vickers hardness of Co- and Ni-based superalloys from microstructure and composition using advanced image processing techniques and machine learning,196,,295-303,"Khatavkar Nikhil,Swetlana Sucheta,Singh Abhishek Kumar","Khatavkar N,Swetlana S,Singh AK",Singh AK,10.1016/j.actamat.2020.06.042,Indian Institute of Science (IISC) - Bangalore,"Superalloys constitute an important class of materials that are heavily employed in turbines of aircraft engines and power plants. Vickers hardness is an important mechanical property for selection of a material. In this work, we develop an alternate approach, which uses the microstructures to estimate the hardness of a Co- and Ni- based superalloys. Advanced image processing techniques coupled with data-driven machine learning (ML) are used to predict the Vickers hardness of these superalloys. Complex image derived properties such as 2-point correlations and compositions of superalloys are utilized as a feature to develop highly accurate ML model. The ML model trained through Gaussian process regression (GPR) using microstructure and compositional features show unprecedented accuracy with root mean square error (RMSE) of 0.14 and R-2 of 0.98. Further analysis of the model is done to establish a relationship between the Vickers hardness with microstructural and compositional parameters. Addition of certain compounds such as iron and titanium can in general lead to increase in Vickers hardness, while addition of elements such as aluminium, tantalum and hafnium negatively affect the Vickers hardness. Most importantly, the developed ML model is trained on experimental data, as opposed to simulated data, making our approach directly applicable for accurate prediction of Vickers hardness. (C) 2020 Acta Materialia Inc. Published by Elsevier Ltd. All rights reserved.","Superalloys,Vickers hardness,Machine learning,Image processing,Principal component analysis,2-point correlations",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Materials Science,Metallurgy & Metallurgical Engineering",,9.277,"OXIDATION,BEHAVIOR,LATTICE,MISFIT,PROPERTY,PHASE,CR",ACTA MATERIALIA,,
23,Microwave heating based on two rotary waveguides to improve efficiency and uniformity by gradient descent method,178,,,"He Junling,Yang Yang,Zhu Huacheng,Li Kang,Yao Wei,Huang Kama","He JL,Yang Y,Zhu HC,Li K,Yao W,Huang KM",Yang Y,10.1016/j.applthermaleng.2020.115594,Sichuan University,"This study aims to improve the efficiency and uniformity of microwave heating based on a rotary radiation structure. This study's steps are summarized as follows. First, using the finite element method in a simulation model, two radiation ports revolve on their axes and heat the material. Second, the heating efficiency at different angles is analyzed to find efficient angles of radiation ports. Finally, to improve the uniformity of material with high efficiency, we use the gradient descent method in machine learning to optimize the heating time at selected angles. An experimental system is established for this research and the simulation results are verified by experiments, showing that this research has an obvious superiorly and efficiency and uniformly of the material have improved compared to traditional heating results without angle selection and optimization of the heating time. What is more, influences of material with different shapes, positions and materials have also been discussed.","Microwave heating,Rotary radiation structure,Gradient descent method",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Thermodynamics,Energy & Fuels,Engineering,Mechanics",,5.175,"NUMERICAL-ANALYSIS,SIMULATION,COAL,DESIGN,SAMPLE",APPLIED THERMAL ENGINEERING,,
24,"Passive and active phase change materials integrated building energy systems with advanced machine-learning based climate-adaptive designs, intelligent operations, uncertainty-based analysis and optimisations: A state-of-the-art review",130,,,"Zhou Yuekuan,Zheng Siqian,Liu Zhengxuan,Wen Tao,Ding Zhixiong,Yan Jun,Zhang Guoqiang","Zhou YK,Zheng SQ,Liu ZX,Wen T,Ding ZX,Yan J,Zhang GQ",Zhou YK,10.1016/j.rser.2020.109889,Hong Kong Polytechnic University,"Integrating phase change materials (PCMs) in buildings cannot only enhance the energy performance, but also improve the renewable utilization efficiency through considerable latent heat during charging/discharging cycles. However, system performances are dependent on PCMs ' integrated forms, heat transfer enhancement solutions, system operating modes, together with optimal geometrical and operating parameters. In this study, passive, active, and combined passive/active solutions in PCMs systems have been comprehensively reviewed, when being applied in heating, cooling and electrical systems, together with a dialectical analysis on advantages and disadvantages. In addition to novel system designs, interdisciplinary applications of machine learning have been reviewed and formulated, from perspectives of reliable structures, smart operational controls, and stochastic uncertainty-based performance prediction. Furthermore, a generic methodology with a systematic and hierarchical procedure has been proposed, with the implementation of machine-learning based technique for optimisations during both design and operation periods. The mechanisms of machine learning techniques were characterised as the simplifications of modelling and optimization processes, through the errors-driven update, the support vector regression and the backpropagation neural network. Several technical challenges were identified, such as the heat transfer enhancement, the novel structural configurations and the flexible switch on operating modes. Finally, identified challenges on machine learning include the development of advanced learning algorithms for efficient performance predictions, optimal structural configurations on neural networks, the trade-off between computational complexity and reliable optimal solutions, and so on. The formulated climate-adaptive designs, intelligent operations, uncertainty-based analysis and optimisations with interdisciplinary machine learning techniques can promote PCMs applications in sustainable buildings.","Phase change materials (PCMs),Combined active and passive energy systems,Exhaust heat recovery,Stochastic uncertainty-based prediction,Multivariable and multi-objective optimisations,Machine learning",Review,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Science & Technology - Other Topics,Energy & Fuels",,14.916,"CHANGE,MATERIAL,WALLBOARD,VENTILATED,TROMBE,WALL,CHANGE,MATERIAL,PCM,AIR,HEAT-EXCHANGER,PERFORMANCE,EVALUATION,THERMAL,PERFORMANCE,COOLING,SYSTEM,STORAGE,FLOOR,SIMULATION",RENEWABLE & SUSTAINABLE ENERGY REVIEWS,,
25,SDDNet: Real-Time Crack Segmentation,67,9,8016-8025,"Choi Wooram,Cha Young-Jin","Choi W,Cha YJ",Cha YJ,10.1109/TIE.2019.2945265,University of Manitoba,"This article reports the development of a pure deep learning method for segmenting concrete cracks in images. The objectives are to achieve the real-time performance while effectively negating a wide range of various complex backgrounds and crack-like features. To achieve the goals, an original convolutional neural network is proposed. The model consists of standard convolutions, densely connected separable convolution modules, a modified atrous spatial pyramid pooling module, and a decoder module. The semantic damage detection network (SDDNet) is trained on a manually created crack dataset, and the trained network records the mean intersection-over-union of 0.846 on the test set. Each test image is analyzed, and the representative segmentation results are presented. The results show that the SDDNet segments cracks effectively unless the features are too faint. The proposed model is also compared with the most recent models, which show that it returns better evaluation metrics even though its number of parameters is 88 times less than in the compared models. In addition, the model processes in real-time (36 FPS) images at 1025 x 512 pixels, which is 46 times faster than in a recent work.","Image segmentation,Standards,Computer architecture,Computational efficiency,Feature extraction,Real-time systems,Decoding,Crack segmentation,deep learning (DL),real time,separable convolution,structural health monitoring (SHM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Engineering,Instruments & Instrumentation",,8.882,"DAMAGE,DETECTION,NEURAL-NETWORKS,DEEP",IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS,,
26,Correction of out-of-FOV motion artifacts using convolutional neural network,71,,93-102,"Wang Chengyan,Liang Yucheng,Wu Yuan,Zhao Siwei,Du Yiping P.","Wang CY,Liang YC,Wu Y,Zhao SW,Du YP",Du YP,10.1016/j.mri.2020.05.004,Shanghai Jiao Tong University,"Purpose: Subject motion during MRI scan can result in severe degradation of image quality. Existing motion correction algorithms rely on the assumption that no information is missing during motions. However, this assumption does not hold when out-of-FOV motion happens. Currently available algorithms are not able to correct for image artifacts introduced by out-of-FOV motion. The purpose of this study is to demonstrate the feasibility of incorporating convolutional neural network (CNN) derived prior image into solving the out-of-FOV motion problem.
Methods and materials: A modified U-net network was proposed to correct out-of-FOV motion artifacts by incorporating motion parameters into the loss function. A motion model based data fidelity term was applied in combination with the CNN prediction to further improve the motion correction performance. We trained the CNN on 1113 MPRAGE images with simulated oscillating and sudden motion trajectories, and compared our algorithm to a gradient-based autofocusing (AF) algorithm in both 2D and 3D images. Additional experiment was performed to demonstrate the feasibility of transferring the networks to different dataset. We also evaluated the robustness of this algorithm by adding Gaussian noise to the motion parameters. The motion correction performance was evaluated using mean square error (NMSE), peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM).
Results: The proposed algorithm outperformed AF-based algorithm for both 2D (NMSE: 0.0066 +/- 0.0009 vs 0.0141 +/- 0.008, P < .01; PSNR: 29.60 +/- 0.74 vs 21.71 +/- 0.27, P < .01; SSIM: 0.89 +/- 0.014 vs 0.73 +/- 0.004, P < .01) and 3D imaging (NMSE: 0.0067 +/- 0.0008 vs 0.070 +/- 0.021, P < .01; PSNR: 32.40 +/- 1.63 vs 22.32 +/- 2.378, P < .01; SSIM: 0.89 +/- 0.01 vs 0.62 +/- 0.03, P < .01). Robust reconstruction was achieved with 20% data missed due to the out-of-FOV motion.
Conclusion: In conclusion, the proposed CNN-based motion correction algorithm can significantly reduce out-of-FOV motion artifacts and achieve better image quality compared to AF-based algorithm.","Motion correction,Machine learning,Convolutional neural networks,Out-of-FOV motion,Prior image",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Radiology, Nuclear Medicine & Medical Imaging",,2.608,"NAVIGATOR,ECHOES,RECONSTRUCTION,MRI,AUTOCORRECTION,IMAGES,FETAL",MAGNETIC RESONANCE IMAGING,,
27,freud: A software suite for high throughput analysis of particle simulation data,254,,,"Ramasubramani Vyas,Dice Bradley D.,Harper Eric S.,Spellings Matthew P.,Anderson Joshua A.,Glotzer Sharon C.","Ramasubramani V,Dice BD,Harper ES,Spellings MP,Anderson JA,Glotzer SC",Glotzer SC,10.1016/j.cpc.2020.107275,University of Michigan System,"The freud Python package is a library for analyzing simulation data. Written with modern simulation and data analysis workflows in mind, freud provides a Python interface to fast, parallelized C++ routines that run efficiently on laptops, workstations, and supercomputing clusters. The package provides the core tools for finding particle neighbors in periodic systems, and offers a uniform API to a wide variety of methods implemented using these tools. As such, freud users can access standard methods such as the radial distribution function as well as newer, more specialized methods such as the potential of mean force and torque and local crystal environment analysis with equal ease. Rather than providing its own trajectory data structure, freud operates either directly on NumPy arrays or on trajectory data structures provided by other Python packages. This design allows freud to transparently interface with many trajectory file formats by leveraging the file parsing abilities of other trajectory management tools. By remaining agnostic to its data source, freud is suitable for analyzing any particle simulation, regardless of the original data representation or simulation method. When used for on-the-fly analysis in conjunction with scriptable simulation software such as HOOMD-blue, freud enables smart simulations that adapt to the current state of the system, allowing users to study phenomena such as nucleation and growth.
Program summary
Program Title: freud
Program Files doi:http://dx.doi.org/10.17632/v7wmv9xcct.1
Licensing provisions: BSD 3-Clause
Programming language: Python, C++
Nature of problem: Simulations of coarse-grained, nano-scale, and colloidal particle systems typically require analyses specialized to a particular system. Certain more standardized techniques - including correlation functions, order parameters, and clustering - are computationally intensive tasks that must be carefully implemented to scale to the larger systems common in modern simulations.
Solution method: freud performs a wide variety of particle system analyses, offering a Python API that interfaces with many other tools in computational molecular sciences via NumPy array inputs and outputs. The algorithms in freud leverage parallelized C++ to scale to large systems and enable real-time analysis. The library's broad set of features encode few assumptions compared to other analysis packages, enabling analysis of a broader class of data ranging from biomolecular simulations to colloidal experiments.
Additional comments including restrictions and unusual features:
1. freud provides very fast parallel implementations of standard analysis methods like RDFs and correlation functions.
2. freud includes the reference implementation for the potential of mean force and torque (PMFT).
3. freud provides various novel methods for characterizing particle environments, including the calculation of descriptors useful for machine learning. The source code is hosted on GitHub (https://github.com/glotzerlab/freud), and documentation is available online (https://ferud.readthedocs.io/). The package may be installed via pip install freud-analysis or conda install -c conda-forge freud. (C) 2020 Elsevier B.V. All rights reserved.","Simulation analysis,Molecular dynamics,Monte Carlo,Computational materials science",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Physics",,4.722,"MOLECULAR-DYNAMICS,SIMULATIONS,NUCLEATION,LIBRARY,TOOLKIT,PHASE",COMPUTER PHYSICS COMMUNICATIONS,http://arxiv.org/pdf/1906.06317,
28,Safety assessment for functionally graded structures with material nonlinearity,86,,,"Feng Yuan,Wu Di,Liu Lei,Gao Wei,Tin-Loi Francis","Feng Y,Wu D,Liu L,Gao W,Tin-Loi F",Gao W,10.1016/j.strusafe.2020.101974,University of New South Wales Sydney,"A machine learning aided reliability assessment framework is presented for functionally graded material (FGM) structures under plane strain/stress conditions with the consideration of elastoplasticity. The material nonlinearity of the FGM is modelled through the implementation of the Tamura-Tomota-Ozawa (TTO) model. For safety evaluation of FGM structures, the volume fraction of FGM has been modelled through spatially dependent uncertainty as random field for the concerned composite. In order to solve the complex stochastic elastoplastic problem, a further developed machine learning aided technique called the extended support vector regression (X-SVR) with a generalized Dirichlet feature mapping function has been introduced and then, the corresponding probabilistic features, including the statistical moments, probability density functions (PDFs), and cumulative distribution functions (CDFs), of the concerned structural responses can be effectively established for assessing the reliability of FGM structures. Moreover, the proposed approach is competent to deliver critical information regarding the uncertain system inputs which can be beneficial for subsequent safety assessment and structural designs for the FGM. Two test functions and two numerical examples have been adopted to visualise the accuracy, stability and capability of the proposed safety assessment framework for FGM structures.","Stochastic elastoplastic analysis,Functionally graded structures,Extended-support vector regression,Reliability assessment",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Engineering,,5.628,"SUPPORT,VECTOR,REGRESSION,FREE-VIBRATION,ANALYSIS,FINITE-ELEMENT,UNCERTAINTY,ANALYSIS,FEATURE-SELECTION,BENDING,RESPONSE,STATISTICS,MICROBEAMS,MACHINE,PROBABILITY",STRUCTURAL SAFETY,,
29,Point cloud-based estimation of effective payload volume for earthmoving loaders,117,,,"Guevara Javier,Arevalo-Ramirez Tito,Yandun Francisco,Torres-Torriti M.,Cheein Fernando Auat","Guevara J,Arevalo-Ramirez T,Yandun F,Torres-Torriti M,Cheein FA",Cheein FA,10.1016/j.autcon.2020.103207,Universidad Tecnica Federico Santa Maria,"Construction and mining require high levels of planning and productivity. Planning and management of operational targets and performance requires taking into account several variables, among which the amount of moved, loaded and unloaded material is one the main ones. This motivates the development of an approach for the estimation of the volume of material transported in field operations by loader trucks. The proposed methodology employs a three-dimensional point cloud representation of the volume and is tested using a skid-steer loader. The volume estimation process involves the segmentation of the loader's bucket from the raw point cloud using machine learning techniques. The segmented point cloud is associated with a pre-constructed reference model of the empty bucket. The volume is computed from a surface model built using the alpha shape algorithm applied to the Delaunay triangulation of the segmented point cloud. Several field experiments were carried out using a stereo camera for five different volumes of material and the bucket at different heights. A 95% accuracy was obtained on average. The encouraging results suggest that effective volume estimation for different bucket types would be possible using the proposed methodology.","PRODUCTIVITY,LIDAR",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Construction & Building Technology,Engineering",,8.0,"PRODUCTIVITY,LIDAR",AUTOMATION IN CONSTRUCTION,,
30,Topology optimization of 2D structures with nonlinearities using deep learning,237,,,"Abueidda Diab W.,Koric Seid,Sobh Nahil A.","Abueidda DW,Koric S,Sobh NA",Sobh NA,10.1016/j.compstruc.2020.106283,University of Illinois System,"The field of optimal design of linear elastic structures has seen many exciting successes that resulted in new architected materials and structural designs. With the availability of cloud computing, including high-performance computing, machine learning, and simulation, searching for optimal nonlinear structures is now within reach. In this study, we develop convolutional neural network models to predict optimized designs for a given set of boundary conditions, loads, and optimization constraints. We have considered the case of materials with a linear elastic response with and without stress constraint. Also, we have considered the case of materials with a hyperelastic response, where material and geometric nonlinearities are involved. For the nonlinear elastic case, the neo-Hookean model is utilized. For this purpose, we generate datasets composed of the optimized designs paired with the corresponding boundary conditions, loads, and constraints, using a topology optimization framework to train and validate the neural network models. The developed models are capable of accurately predicting the optimized designs without requiring an iterative scheme and with negligible inference computational time. The suggested pipeline can be generalized to other nonlinear mechanics scenarios and design domains. Published by Elsevier Ltd.","Adjoint sensitivity,Finite element analysis (FEA),Machine learning,Neo-Hookean materials,Stress constraint",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering",,4.57,"NEURAL-NETWORK,DESIGN,SIMULATION,MITIGATION,FRAMEWORK,ALGORITHM,STIFFNESS",COMPUTERS & STRUCTURES,http://arxiv.org/pdf/2002.01896,
31,Searching for electronically two dimensional metals in high-throughput ab initio databases,182,,,"Nunez Matias,Weht Ruben,Nunez-Regueiro Manuel","Nunez M,Weht R,Nunez-Regueiro M",Nunez M,10.1016/j.commatsci.2020.109747,Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET),"Due to the high degree of improvement and prediction success of ab initio calculations, the advance in Materials Science has been partially shifted from the empirical chemical quest of new compounds to the systematic calculation of putative structures that can yield compounds with promising properties. In particular, two dimensional (2D) materials are at present a central target, as many potential devices rely on particular characteristics of a single layer of atoms or low dimensional electronic active sheets in bulk materials. Several works have focused on this paradigm, yielding a large list of new interesting 2D candidates. Here, we introduce a technique based on an algorithmic filter for searching prospective candidates in very large electronic structure databases. It is designed to detect electronic bands with low energy dispersion along particular directions in reciprocal space, i.e. those perpendicular to certain plane or surface. We propose it as an absolute criterion for obtaining all possible two dimensional compounds. With it we show that previous explorations have missed out a whole group of possible two dimensional materials, namely only electronically 2D.","2D,Two dimensional materials,HTc superconductors,Machine learning,Data mining,High throughput materials discovery,Electronic structure,Fermi surface,Fermiology",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"SUPERCONDUCTIVITY,FERROMAGNETISM,LA",COMPUTATIONAL MATERIALS SCIENCE,,
32,Adverse Drug Reaction Detection in Social Media by Deep Learning Methods,22,3,319-324,"Rezaei Zahra,Ebrahimpour-Komleh Hossein,Eslami Behnaz,Chavoshinejad Ramyar,Totonchi Mehdi","Rezaei Z,Ebrahimpour-Komleh H,Eslami B,Chavoshinejad R,Totonchi M",Rezaei Z; Ebrahimpour-Komleh H,10.22074/cellj.2020.6615,University Kashan,"Objective: Health-related studies have been recently at the heart attention of the media. Social media, such as Twitter, has become a valuable online tool to describe the early detection of various adverse drug reactions (ADRs). Different medications have adverse effects on various cells and tissues, sometimes more than one cell population would be adversely affected. These types of side effect are occasionally associated with the direct or indirect influence of prescribed drugs but do not have general unfavorable mutagenic consequences on patients. This study aimed to demonstrate a quick and accurate method to collect and classify information based on the distribution of approved data on Twitter.
Materials and Methods: In this classification method, we selected ""ask a patient"" dataset and combination of Twitter ""Ask a Patient"" datasets that comprised of 6,623, 26,934, and 11,623 reviews. We used deep learning methods with the word2vec to classify ADR comments posted by the users and present an architecture by HAN, FastText, and CNN.
Results: Natural language processing (NLP) deep learning is able to address more advanced peculiarity in learning information compared to other types of machine learning. Moreover, the current study highlighted the advantage of incorporating various semantic features, including topics and concepts.
Conclusion: Our approach predicts drug safety with the accuracy of 93% (the combination of Twitter and ""Ask a Patient"" datasets) in a binary manner. Despite the apparent benefit of various conventional classifiers, deep learning-based text classification methods seem to be precise and influential tools to detect ADR.","Adverse Drug Reaction,Classification,Deep Learning,Natural Language Processing,Social Network",Article,"ROYAN INST, PO BOX 19395-4644, TEHRAN, 00000, IRAN",Cell Biology,,2.73,EVENTS,CELL JOURNAL,,
33,,,,,,,,,,,,,,,,,,,,
34,Traditional food knowledge of Indonesia: a new high-quality food dataset and automatic recognition system,7,1,,"Wibisono Ari,Wisesa Hanif Arief,Rahmadhani Zulia Putri,Fahira Puteri Khatya,Mursanto Petrus,Jatmiko Wisnu","Wibisono A,Wisesa HA,Rahmadhani ZP,Fahira PK,Mursanto P,Jatmiko W",Wibisono A,10.1186/s40537-020-00342-5,University of Indonesia,"Traditional food knowledge (TFK) is an essential aspect of human life. In terms of sociocultural aspects, TFK is necessary to protect ancestral culture. In terms of health, traditional foods contain better and more natural ingredients compared to the ingredients of processed foods. Considering this background, in this study, data acquisition and automatic food recognition were performed for traditional food in Indonesia. The food images were captured in a professional mini studio. The food image data were captured under the same light intensity, camera settings, and shooting distance from the camera. The parameters were precisely measured and configured with a light intensity meter, adjustable lighting, and a laser distance measurement device. The data of 1644 traditional food images were successfully obtained in the data acquisition process. These images corresponded to 34 types of traditional foods, and 30-50 images were obtained for each type of food. The size of the raw food image data was 53 GB. The data were divided into sets for training, testing, and validation. An automatic recognition system was developed to classify the traditional food of Indonesia. Training was performed using several types of convolutional neural network (CNN) models such as Densenet121, Resnet50, InceptionV3, and Nasnetmobile. The evaluation results indicated that when using a high quality dataset, the automatic recognition system could realize satisfactory area under the receiver operating characteristics (AUROC) and high accuracy, precision, and recall values of more than 0.95.","Traditional food knowledge,High-quality dataset,Food recognition,Convolutional neural network",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Computer Science,,,,JOURNAL OF BIG DATA,https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-020-00342-5,
35,Development of Vickers hardness prediction models via microstructural analysis and machine learning,55,33,15845-15856,"Swetlana Sucheta,Khatavkar Nikhil,Singh Abhishek Kumar","Swetlana S,Khatavkar N,Singh AK",Singh AK,10.1007/s10853-020-05153-w,Indian Institute of Science (IISC) - Bangalore,"Superalloys are high-temperature materials with outstanding strength and resistance to corrosion. A prior knowledge about its hardness is essential for development of new superalloys for its applications in aeronautics and power industries. Determining the hardness of a material with experiments is usually a destructive process. In this study, using structural, compositional and processing condition parameters as descriptors, machine learning (ML) models are developed to predict Vickers hardness. We employed image processing tools, which extract structural descriptors such as volume fraction, area, perimeter and aspect ratio of the phases in the microstructures. Using the structural features in combination with elemental and processing information as features, a Gaussian process regression model for the prediction of Vickers hardness of superalloys is developed. The model gives an unprecedented accuracy with a minimum root mean square error of 0.15. The descriptors provide insights into structure-property relationships, which are important for designing superalloys with improved Vickers hardness. The proposed method for extracting features from microstructures and combining them with elemental and processing information can be extended to develop ML model for prediction of other mechanical properties of superalloys.","MECHANICAL-PROPERTIES,GRAIN-SIZE,SUPERALLOYS,COBALT,TEMPERATURE,EVOLUTION,GAMMA,FEATURES,TUNGSTEN",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Materials Science,,3.69,"MECHANICAL-PROPERTIES,GRAIN-SIZE,SUPERALLOYS,COBALT,TEMPERATURE,EVOLUTION,GAMMA,FEATURES,TUNGSTEN",JOURNAL OF MATERIALS SCIENCE,http://eprints.iisc.ac.in/66544/8/10853_2020_5153_MOESM1_ESM.pdf,
36,Machine Learning Lattice Constants for Cubic PerovskiteABX3Compounds,5,32,9999-10009,"Zhang Yun,Xu Xiaojie","Zhang Y,Xu XJ",Zhang Y,10.1002/slct.202002532,University of North Carolina,"Cubic perovskites have attracted great attention in the past decade due to unique and tunable optical, mechanical, and electrical properties, which are promising candidates for various applications such as solar cells, light emitting diodes, actuators, and laser cooling devices. The lattice constant, a, as the only variable parameter among the six parameters in the crystal structure, has a significant impact on the structural stability, bandgap structure, and thus materials performance. In this study, we develop the Gaussian process regression (GPR) model to shed light on the statistical relationship between ionic radii and lattice constants for cubic perovskiteABX3compounds. A total of 135 samples with lattice constants ranging from 3.680 angstrom to 6.330 angstrom are explored. The model has a high degree of accuracy and stability that contributes to fast and robust lattice constant estimations.","Gaussian process regression,Halides,Lattice constant,Oxide,Perovskite phases",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Chemistry,,2.054,"PEROVSKITE,PREDICTION",CHEMISTRYSELECT,,
37,Random forest-based evaluation technique for internal damage in reinforced concrete featuring multiple nondestructive testing results,253,,,"Chun Pang-jo,Ujike Isao,Mishima Kohei,Kusumoto Masahiro,Okazaki Shinichiro","Chun PJ,Ujike I,Mishima K,Kusumoto M,Okazaki S",Chun PJ,10.1016/j.conbuildmat.2020.119238,University of Tokyo,"The evaluation of internal damage in concrete structures is related to not only its rapid repair and reinforcement but also its safe usage, and is therefore essential for ensuring its longevity. This paper proposes a method to evaluate the extent of internal damage due to rebar corrosion using Random Forest, one of the supervised machine learning methods. In supervised machine learning, appropriate inputs should be identified to obtain accurate results. This research uses air permeability coefficient, electrical resistivity, ultrasonic velocity, and compressive strength which is obtained by nondestructive tests as inputs. In order to acquire a large number of data for the training, the rebar corrosion was promoted by electrolytic corrosion, and the data was frequently acquired. Then, the high accuracy of the model was confirmed by cross-validation. In addition, the proposed method was applied to the inspection of actual bridges, and it can detect internal damage that is otherwise invisible on the exterior surface. (C) 2020 The Author(s). Published by Elsevier Ltd.","Random forest,Machine learning,Corrosion,Nondestructive test,Damage evaluation",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Construction & Building Technology,Engineering,Materials Science",,6.841,CORROSION,CONSTRUCTION AND BUILDING MATERIALS,https://doi.org/10.1016/j.conbuildmat.2020.119238,
38,Multi-objective optimization of concrete mixture proportions using machine learning and metaheuristic algorithms,253,,,"Zhang Junfei,Huang Yimiao,Wang Yuhang,Ma Guowei","Zhang JF,Huang YM,Wang YH,Ma GW",Huang YM,10.1016/j.conbuildmat.2020.119208,University of Western Australia,"For the optimization of concrete mixture proportions, multiple objectives (e.g., strength, cost, slump) with many variables (e.g., concrete components) under highly nonlinear constraints need to be optimized simultaneously. The current single-objective optimization models are not applicable to multi-objective optimization (MOO). This study proposes an MOO method based on machine learning (ML) and metaheuristic algorithms to optimize concrete mixture proportions. First, the performances of different ML models in the prediction of concrete objectives are compared on data sets collected from the published literature. The winner is selected as the objective function for the optimization procedure. In the optimization step, a multi-objective particle swarm optimization algorithm is used to optimize mixture proportions to achieve optimal objectives. The results show that the backpropagation neural network has better performance on continuous data (e.g., strength), whereas the random forest algorithm has higher prediction accuracy on more discrete data (e.g., slump). The Pareto fronts of a bi-objective mixture optimization problem for high-performance concrete and a tri-objective mixture optimization problem for plastic concrete are successfully obtained by the MOO model. The MOO model can serve as a design guide to facilitate decision-making before the construction phase. (C) 2020 Elsevier Ltd. All rights reserved.","Concrete,Multi-objective optimization,Machine learning,Particle swarm optimization,Compressive strength,Slump",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Construction & Building Technology,Engineering,Materials Science",,6.841,"UNCONFINED,COMPRESSIVE,STRENGTH,PLASTIC,CONCRETE,NEURAL-NETWORK,MIX,DESIGN,PREDICTION,MODULUS",CONSTRUCTION AND BUILDING MATERIALS,,
39,Deep Learning in Radiation Oncology Treatment Planning for Prostate Cancer: A Systematic Review,44,10,,"Almeida Goncalo,Tavares Joao Manuel R. S.","Almeida G,Tavares JMRS",Tavares JMRS,10.1007/s10916-020-01641-3,"Universidade Porto, Fac Engn, Inst Ciencia & Inovacao Engn Mecan & Engn Ind, Dept Engn Mecan, Porto, Portugal.","Radiation oncology for prostate cancer is important as it can decrease the morbidity and mortality associated with this disease. Planning for this modality of treatment is both fundamental, time-consuming and prone to human-errors, leading to potentially avoidable delays in start of treatment. A fundamental step in radiotherapy planning is contouring of radiation targets, where medical specialists contouring, i.e., segment, the boundaries of the structures to be irradiated. Automating this step can potentially lead to faster treatment planning without a decrease in quality, while increasing time available to physicians and also more consistent treatment results. This can be framed as an image segmentation task, which has been studied for many decades in the fields of Computer Vision and Machine Learning. With the advent of Deep Learning, there have been many proposals for different network architectures achieving high performance levels. In this review, we searched the literature for those methods and describe them briefly, grouping those based on Computed Tomography (CT) or Magnetic Resonance Imaging (MRI). This is a booming field, evidenced by the date of the publications found. However, most publications use data from a very limited number of patients, which presents an obstacle to deep learning models training. Although the performance of the models has achieved very satisfactory results, there is still room for improvement, and there is arguably a long way before these models can be used safely and effectively in clinical practice.","Computer vision,Medical imaging,Machine learning,Segmentation,Radiotherapy",Review,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Health Care Sciences & Services,Medical Informatics",,3.951,RADIOTHERAPY,JOURNAL OF MEDICAL SYSTEMS,https://repositorio-aberto.up.pt/bitstream/10216/129011/3/415537.pdf,
40,Machine learning lattice constants from ionic radii and electronegativities for cubic perovskite A(2)XY(6) compounds,47,9,,"Zhang Yun,Xu Xiaojie","Zhang Y,Xu XJ",Zhang Y,10.1007/s00269-020-01108-4,University of North Carolina,"Metal halide perovskites have attracted great attention in the past decade due to unique and tunable optical and electrical properties, which are promising candidates for various applications such as solar cells, light-emitting diodes, and laser cooling devices. For cubic perovskites, the lattice constant, a, representing the size of the unit cell, has a significant impact on the structural stability, bandgap structure, and thus materials performance. In this study, we develop the Gaussian process regression (GPR) model to shed light on the relationship among ionic radii, electronegativities, and lattice constants for cubic perovskite A(2)XY(6) compounds. A total of 79 samples with lattice constants ranging from 8.109 to 11.790 angstrom are examined. The model has a high degree of accuracy and stability, contributing to fast, robust, and low-cost estimations of lattice constants.","Lattice constant,Halide,Perovskite,Semiconductor,Machine learning,Gaussian process regression",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Materials Science,Mineralogy",,1.467,"CRYSTAL-STRUCTURE,STRUCTURAL,REFINEMENT,SOLAR-CELL,POTASSIUM,POWDER,EFFICIENCY,PALLADIUM,AMMONIUM,RUBIDIUM,HALIDES",PHYSICS AND CHEMISTRY OF MINERALS,,
41,Machine learning approaches for estimation of compressive strength of concrete,135,8,,"Hadzima-Nyarko Marijana,Nyarko Emmanuel Karlo,Lu Hongfang,Zhu Senlin","Hadzima-Nyarko M,Nyarko EK,Lu HF,Zhu SL",Zhu SL,10.1140/epjp/s13360-020-00703-2,Yangzhou University,"Estimation of compressive strength of rubberized concrete is important for engineering safety. In this study, measured data (the compressive strength of rubberized concrete and its impacting factors) were collected by literature review (457 samples). In order to accurately predict the compressive strength of rubberized concrete, four machine learning models [artificial neural network (ANN), k-nearest neighbor (KNN), regression trees (RT), and random forests (RF)] were developed and compared to estimate the compressive strength of rubberized concrete, and the modeling results were compared with two traditional expressions. The model performance was evaluated using three performance indicators: the Nash-Sutcliffe efficiency coefficient (NSC), the root-mean-squared error (RMSE), and the mean absolute error (MAE). The results showed that the RT model performs the best, followed by the ANN and RF in the model training phase. In the model testing phase, the ANN model performs the best, followed by the RT, RF, and KNN. The overall results indicated that the ANN model performs the best, followed by RT and RF, and the KNN model performs the worst. The ANN and RT models outperformed the two traditional expressions. The tree-based models (RT and RF) and KNN model may not be applicative to estimate the compressive strength of rubberized concrete due to the generally poor performances in the model testing phase compared with that in the model training phase. The results showed that the traditional ANN model is sufficient for the accurate estimation of the compressive strength of rubberized concrete when the model is properly trained. The results in the present research can provide reference for the prediction of the compressive strength of rubberized concrete, which will benefit engineering management and safety as well.","CRUMB RUBBER CONCRETE,TYRE RUBBER,MECHANICAL-PROPERTIES,TIRE RUBBER,WASTE TIRES,PERFORMANCE,COMPOSITES,MIXTURES,WATER",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Physics,,3.304,"CRUMB,RUBBER,CONCRETE,TYRE,RUBBER,MECHANICAL-PROPERTIES,TIRE,RUBBER,WASTE,TIRES,PERFORMANCE,COMPOSITES,MIXTURES,WATER",EUROPEAN PHYSICAL JOURNAL PLUS,,
42,An Automatic System for Atrial Fibrillation by Using a CNN-LSTM Model,2020,,,"Ma Fengying,Zhang Jingyao,Chen Wei,Liang Wei,Yang Wenjia","Ma FY,Zhang JY,Chen W,Liang W,Yang WJ",Liang W,10.1155/2020/3198783,Qilu University of Technology,"Atrial fibrillation (AF) is a common abnormal heart rhythm disease. Therefore, the development of an AF detection system is of great significance to detect critical illnesses. In this paper, we proposed an automatic recognition method named CNN-LSTM to automatically detect the AF heartbeats based on deep learning. The model combines convolutional neural networks (CNN) to extract local correlation features and uses long short-term memory networks (LSTM) to capture the front-to-back dependencies of electrocardiogram (ECG) sequence data. The CNN-LSTM is feeded by processed data to automatically detect AF signals. Our study uses the MIT-BIH Atrial Fibrillation Database to verify the validity of the model. We achieved a high classification accuracy for the heartbeat data of the test set, with an overall classification accuracy rate of 97.21%, sensitivity of 97.34%, and specificity of 97.08%. The experimental results show that our model can robustly detect the onset of AF through ECG signals and achieve stable classification performance, thereby providing a suitable candidate for the automatic classification of AF.",NETWORKS,Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Mathematics,Science & Technology - Other Topics",,1.067,NETWORKS,DISCRETE DYNAMICS IN NATURE AND SOCIETY,https://downloads.hindawi.com/journals/ddns/2020/3198783.pdf,
43,Graph convolutional neural networks with global attention for improved materials property prediction,22,32,18141-18148,"Louis Steph-Yves,Zhao Yong,Nasiri Alireza,Wang Xiran,Song Yuqi,Liu Fei,Hu Jianjun","Louis SY,Zhao Y,Nasiri A,Wang XR,Song YQ,Liu F,Hu JJ",Hu JJ,10.1039/d0cp01474e,University of South Carolina System,"The development of an efficient and powerful machine learning (ML) model for materials property prediction (MPP) remains an important challenge in materials science. While various techniques have been proposed to extract physicochemical features in MPP, graph neural networks (GNN) have also shown very strong capability in capturing effective features for high-performance MPP. Nevertheless, current GNN models do not effectively differentiate the contributions from different atoms. In this paper we develop a novel graph neural network model called GATGNN for predicting properties of inorganic materials. GATGNN is characterized by its composition of augmented graph-attention layers (AGAT) and a global attention layer. The application of AGAT layers and global attention layers respectively learn the local relationship among neighboring atoms and overall contribution of the atoms to the material's property; together making our framework achieve considerably better prediction performance on various tested properties. Through extensive experiments, we show that our method is able to outperform existing state-of-the-art GNN models while it can also provide a measurable insight into the correlation between the atoms and their material property. Our code can found on -https://github.com/superlouis/GATGNN.",,Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Physics",,3.802,,PHYSICAL CHEMISTRY CHEMICAL PHYSICS,http://arxiv.org/pdf/2003.13379,
44,,,,,,,,,,,,,,,,,,,,
45,,,,,,,,,,,,,,,,,,,,
46,A protein corona sensor array detects breast and prostate cancers,12,32,16697-16704,"Digiacomo Luca,Jafari-Khouzani Kourosh,Palchetti Sara,Pozzi Daniela,Capriotti Anna Laura,Lagana Aldo,Chiozzi Riccardo Zenezini,Caputo Damiano,Cascone Chiara,Coppola Roberto","Digiacomo L,Jafari-Khouzani K,Palchetti S,Pozzi D,Capriotti AL,Lagana A,Chiozzi RZ,Caputo D,Cascone C,Coppola R",Caracciolo G,10.1039/d0nr03439h,Sapienza University Rome,"Following exposure to human plasma (HP), nanoparticles (NPs) are coated with a biomolecular layer referred to as a protein corona. We recently revealed that characterizing the protein coronas of various NPs may provide a unique opportunity for cancer identification and discrimination. In other words, protein corona profiles of several NPs, when being analyzed using classifiers, would provide a unique ""fingerprint"" for each type of disease. Here, we probed the capacity of the protein corona for the identification and discrimination of breast and prostate cancer patients from healthy individuals. Using three lipid NP formulations with distinct physical-chemical properties as a cross-reactive sensor array and a supervised random forest classifier, we identified a set of proteins that showed a significant difference in cancer patients and control subjects. Our data show that many of the corona proteins with the highest discrimination ability between oncological patients and healthy individuals are related to cellular and molecular aspects of breast and prostate cancers.","HUMAN PLASMA,ANTIGEN,NANOPARTICLES,STATISTICS,DISEASE,UPDATE,IMPACT,TRIALS,CHARGE,BLOOD",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,7.632,"HUMAN,PLASMA,ANTIGEN,NANOPARTICLES,STATISTICS,DISEASE,UPDATE,IMPACT,TRIALS,CHARGE,BLOOD",NANOSCALE,,
47,Improving Image Description with Auxiliary Modality for Visual Localization in Challenging Conditions,129,1,,"Piasco Nathan,Sidibe Desire,Gouet-Brunet Valerie,Demonceaux Cedric","Piasco N,Sidibe D,Gouet-Brunet V,Demonceaux C",Piasco N,10.1007/s11263-020-01363-6,Universite Bourgogne Franche-Comte (ComUE),"Image indexing for lifelong localization is a key component for a large panel of applications, including robot navigation, autonomous driving or cultural heritage valorization. The principal difficulty in long-term localization arises from the dynamic changes that affect outdoor environments. In this work, we propose a new approach for outdoor large scale image-based localization that can deal with challenging scenarios like cross-season, cross-weather and day/night localization. The key component of our method is a new learned global image descriptor, that can effectively benefit from scene geometry information during training. At test time, our system is capable of inferring the depth map related to the query image and use it to increase localization accuracy. We show through extensive evaluation that our method can improve localization performances, especially in challenging scenarios when the visual appearance of the scene has changed. Our method is able to leverage both visual and geometric clues from monocular images to create discriminative descriptors for cross-season localization and effective matching of images acquired at different time periods. Our method can also use weakly annotated data to localize night images across a reference dataset of daytime images. Finally we extended our method to reflectance modality and we compare multi-modal descriptors respectively based on geometry, material reflectance and a combination of both.","Localization,Image retrieval,Side modality learning,Depth from monocular,Global image descriptor",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,13.284,"REPRESENTATIONS,RECOGNITION",INTERNATIONAL JOURNAL OF COMPUTER VISION,https://hal.archives-ouvertes.fr/hal-02912239/document,
48,A Review of Steel Processing Considerations for Oxide Cleanliness,51,6,2437-2452,"Webler B. A.,Pistorius P. C.","Webler BA,Pistorius PC",Pistorius PC,10.1007/s11663-020-01949-y,Carnegie Mellon University,"Control of non-metallic inclusions is essential for the production of high-quality steel. This review summarizes processes that change inclusion compositions and concentrations during secondary steelmaking-slower changes are limited by reaction between bulk steel and slag or refractory, and faster changes involve direct additions to the steel bath. An example of the former is conversion of alumina inclusions to spinels during ladle treatment, while reoxidation and calcium treatment are typical exemplars of the fast changes. For the slower changes, inclusions approach equilibrium with the liquid steel and conceptually simple kinetic models correctly describe inclusion evolution during ladle treatment. Disequilibrium from faster changes persists for several minutes under typical ladle conditions, with small-scale inhomogeneity in the steel. Fast scanning electron microscopy with microanalysis has facilitated detailed study of these inclusion evolution processes by providing information on inclusion composition, size, and shape. Machine learning methods are likely to be increasingly important in analysis of the results. Such methods have already shown promise to improve classification of inclusions and recognizing inclusion clusters, from analyses of polished sections. Several unresolved issues that require future study are noted.","IN-SITU OBSERVATION,OF-THE-ART,KINETIC-MODEL,NONMETALLIC INCLUSIONS,SECONDARY STEELMAKING,LIQUID STEEL,ALUMINA PARTICLES,GAS INJECTION,SPINEL INCLUSIONS,AL2O3 DISSOLUTION",Review,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Materials Science,Metallurgy & Metallurgical Engineering",,2.57,"IN-SITU,OBSERVATION,OF-THE-ART,KINETIC-MODEL,NONMETALLIC,INCLUSIONS,SECONDARY,STEELMAKING,LIQUID,STEEL,ALUMINA,PARTICLES,GAS,INJECTION,SPINEL,INCLUSIONS,AL2O3,DISSOLUTION",METALLURGICAL AND MATERIALS TRANSACTIONS B-PROCESS METALLURGY AND MATERIALS PROCESSING SCIENCE,https://link.springer.com/content/pdf/10.1007/s11663-020-01949-y.pdf,
49,Compressing soil structural information into parameterized correlation functions,72,2,561-577,"Karsanina Marina V,Lavrukhin Efim V,Fomin Dmitry S.,Yudina Anna V,Abrosimov Konstantin N.,Gerke Kirill M.","Karsanina MV,Lavrukhin EV,Fomin DS,Yudina AV,Abrosimov KN,Gerke KM",Gerke KM,10.1111/ejss.13025,Russian Academy of Sciences,"Soil structure is highly interconnected to all of its properties and functions. The structure for most soils is very complex and hierarchical in nature. Considering the fact that a truly multiscale digital 3D soil structure model for a single genetic horizon, even with the resolution not finer than 1 mu m, will contain an enormous amount (approx. up to 10(15)voxels or even more) of data, it is an appealing idea to compress this structural information. Effective management and pore-scale simulations based on such datasets do not seem feasible at the moment. Another approach would be to reduce the complexity to a limited but meaningful set of characteristics/parameters, for example using universal correlation functions (CFs). In this study, we successfully compressed the soil structural information in the form of 3D binary images into a set of correlation functions, each of which is described using only six parameters. We used four different correlation functions (two-point probability, lineal, cluster and surface-surface functions) computed in three orthogonal directions for the pores. The methodology was applied to 16 different soil 3D images obtained using X-ray microtomography (XCT) and segmented into pores and solids. All computed CFs were fitted using a superposition of three basis functions. In other words, we reduced 900-1300(3)voxel images into sets of 72 parameters. Fitting of computed correlation functions and reducing them to a number of parameters is a powerful way of compressing soil structural information. However, the analysis based on parameters alone is different from the one where correlation functions are used. This problem can be negated by uncompressing the correlation functions back from these parameters before any application. This way, correlation functions are not only a way to compress the soil structural information with minimal loss, but also may be used to solve a number of additional problems, including the comparison and differentiation of soil samples, location of elementary volumes, effective physical property prediction using machine learning, and fusion of hierarchical soil structures. Highlights
The 900-1300(3)voxels soil XCT scans were compressed into sets of 72 parameters The use of fitted parameters alone may result in the inconsistent analysis of the soil structures Each soil structure was uniquely described by a set of directional correlation functions Correlation functions were found to be sensitive to the structural difference of all the studied soils","basis functions,clustering analysis,compression,correlation functions,least squares fitting,soil structure digital model,X-ray microtomography",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Agriculture,,4.626,"PORE-SPACE,SOLUTE,TRANSPORT,HETEROGENEOUS,MATERIALS,TOMOGRAPHIC-IMAGES,WATER-RETENTION,POROUS-MEDIA,FLOW,RECONSTRUCTION,RESOLUTION,ELEMENTS",EUROPEAN JOURNAL OF SOIL SCIENCE,,
50,Reentrant incommensurate order and anomalous magnetic torque in the Kitaev magnet beta-Li2IrO3,2,3,,"Li Mengqun,Rousochatzakis Ioannis,Perkins Natalia B.","Li MQ,Rousochatzakis I,Perkins NB",Li MQ,10.1103/PhysRevResearch.2.033328,University of Minnesota System,"We present a theoretical study of the response of beta-Li2IrO3 under external magnetic fields in the ab, bc, and ac crystallographic planes. The results are based on the minimal nearest-neighbor J-K-Gamma model and reveal a rich intertwining of field-induced phases and magnetic phase transitions with distinctive signatures that can be probed directly via torque magnetometry. Most saliently, we observe (i) an unusual reentrance of the incommensurate counterrotating order for fields in the ab plane and (ii) a set of abrupt torque discontinuities which are particularly large for fields rotating in the bc plane and whose characteristic shape resembles closely the ones observed in the three-dimensional (3D) Kitaev magnet gamma-Li2IrO3. An experimental confirmation of these predictions will pave the way for an accurate determination of all relevant microscopic parameters of this 3D Kitaev magnet.","SPIN,PHYSICS",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,,"SPIN,PHYSICS",PHYSICAL REVIEW RESEARCH,https://figshare.com/articles/journal_contribution/Reentrant_incommensurate_order_and_anomalous_magnetic_torque_in_the_Kitaev_magnet_Li2IrO3/12888596/files/24501605.pdf,
51,Evaluation-oriented exploration of photo energy conversion systems: from fundamental optoelectronics and material screening to the combination with data science,52,12,1307-1321,Saeki Akinori,Saeki A,Saeki A,10.1038/s41428-020-00399-2,Osaka University,"Light is a form of energy that can be converted to electric and chemical energies. Thus, organic photovoltaics (OPVs), perovskite solar cells (PSCs), photocatalysts, and photodetectors have evolved as scientific and commercial enterprises. However, the complex photochemical reactions and multicomponent materials involved in these systems have hampered rapid progress in their fundamental understanding and material design. This review showcases the evaluation-oriented exploration of photo energy conversion materials by using electrodeless time-resolved microwave conductivity (TRMC) and materials informatics (MI). TRMC with its unique options (excitation sources, environmental control, frequency modulation, etc.) provides not only accelerated experimental screening of OPV and PSC materials but also a versatile route toward shedding light on their charge carrier dynamics. Furthermore, MI powered by machine learning is shown to allow extremely high-throughput exploration in the large molecular space, which is compatible with experimental screening and combinatorial synthesis.","CHARGE-CARRIER MOBILITY,RESOLVED MICROWAVE CONDUCTIVITY,ORGANIC-INORGANIC PEROVSKITES,SOLAR-CELLS,CONJUGATED POLYMERS,PHOTOVOLTAIC PERFORMANCE,PHOTOCATALYTIC ACTIVITY,GRAPHITIC NANOTUBES,SELF-ORGANIZATION,TRANSFER EXCITONS",Review,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Polymer Science,,2.601,"CHARGE-CARRIER,MOBILITY,RESOLVED,MICROWAVE,CONDUCTIVITY,ORGANIC-INORGANIC,PEROVSKITES,SOLAR-CELLS,CONJUGATED,POLYMERS,PHOTOVOLTAIC,PERFORMANCE,PHOTOCATALYTIC,ACTIVITY,GRAPHITIC,NANOTUBES,SELF-ORGANIZATION,TRANSFER,EXCITONS",POLYMER JOURNAL,https://www.nature.com/articles/s41428-020-00399-2.pdf,
52,Wavelet scattering networks for atomistic systems with extrapolation of material properties,153,8,,"Sinz Paul,Swift Michael W.,Brumwell Xavier,Liu Jialin,Kim Kwang Jin,Qi Yue,Hirn Matthew","Sinz P,Swift MW,Brumwell X,Liu JL,Kim KJ,Qi Y,Hirn M",Hirn M,10.1063/5.0016020,Michigan State University,"The dream of machine learning in materials science is for a model to learn the underlying physics of an atomic system, allowing it to move beyond the interpolation of the training set to the prediction of properties that were not present in the original training data. In addition to advances in machine learning architectures and training techniques, achieving this ambitious goal requires a method to convert a 3D atomic system into a feature representation that preserves rotational and translational symmetries, smoothness under small perturbations, and invariance under re-ordering. The atomic orbital wavelet scattering transform preserves these symmetries by construction and has achieved great success as a featurization method for machine learning energy prediction. Both in small molecules and in the bulk amorphous Li alpha Si system, machine learning models using wavelet scattering coefficients as features have demonstrated a comparable accuracy to density functional theory at a small fraction of the computational cost. In this work, we test the generalizability of our Li alpha Si energy predictor to properties that were not included in the training set, such as elastic constants and migration barriers. We demonstrate that statistical feature selection methods can reduce over-fitting and lead to remarkable accuracy in these extrapolation tasks.","ENERGY SURFACES,ACCURACY",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Chemistry,Physics",,3.166,"ENERGY,SURFACES,ACCURACY",JOURNAL OF CHEMICAL PHYSICS,http://arxiv.org/pdf/2006.01247,
53,Artificial intelligence in ophthalmology Guidelines for physicians for the critical evaluation of studies,117,10,973-988,"Pfau Maximilian,Walther Guenther,von der Emde Leon,Berens Philipp,Faes Livia,Fleckenstein Monika,Heeren Tjebo F. C.,Kortuem Karsten,Kuenzel Sandrine H.,Mueller Philipp L.","Pfau M,Walther G,von der Emde L,Berens P,Faes L,Fleckenstein M,Heeren TFC,Kortum K,Kunzel SH,Muller PL",Pfau M,10.1007/s00347-020-01209-z,Stanford University,"Background Empirical models have been an integral part of everyday clinical practice in ophthalmology since the introduction of the Sanders-Retzlaff-Kraff (SRK) formula. Recent developments in the field of statistical learning (artificial intelligence, AI) now enable an empirical approach to a wide range of ophthalmological questions with an unprecedented precision. Objective Which criteria must be considered for the evaluation of AI-related studies in ophthalmology? Material and methods Exemplary prediction of visual acuity (continuous outcome) and classification of healthy and diseased eyes (discrete outcome) using retrospectively compiled optical coherence tomography data (50 eyes of 50 patients, 50 healthy eyes of 50 subjects). The data were analyzed with nested cross-validation (for learning algorithm selection and hyperparameter optimization). Results Based on nested cross-validation for training, visual acuity could be predicted in the separate test data-set with a mean absolute error (MAE, 95% confidence interval, CI of 0.142 LogMAR [0.077; 0.207]). Healthy versus diseased eyes could be classified in the test data-set with an agreement of 0.92 (Cohen's kappa). The exemplary incorrect learning algorithm and variable selection resulted in an MAE for visual acuity prediction of 0.229 LogMAR [0.150; 0.309] for the test data-set. The drastic overfitting became obvious on comparison of the MAE with the null model MAE (0.235 LogMAR [0.148; 0.322]). Conclusion Selection of an unsuitable measure of the goodness-of-fit, inadequate validation, or withholding of a null or reference model can obscure the actual goodness-of-fit of AI models. The illustrated pitfalls can help clinicians to identify such shortcomings.","Statistical learning,Machine-learning,Deep learning,Automated analysis,Empirical approach",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Ophthalmology,,1.009,"PREDICTION,SELECTION,BIAS,CLASSIFIERS",OPHTHALMOLOGE,,
54,Automated Detection of Acute Lymphoblastic Leukemia From Microscopic Images Based on Human Visual Perception,8,,,"Bodzas Alexandra,Kodytek Pavel,Zidek Jan","Bodzas A,Kodytek P,Zidek J",Bodzas A,10.3389/fbioe.2020.01005,Technical University of Ostrava,"Microscopic image analysis plays a significant role in initial leukemia screening and its efficient diagnostics. Since the present conventional methodologies partly rely on manual examination, which is time consuming and depends greatly on the experience of domain experts, automated leukemia detection opens up new possibilities to minimize human intervention and provide more accurate clinical information. This paper proposes a novel approach based on conventional digital image processing techniques and machine learning algorithms to automatically identify acute lymphoblastic leukemia from peripheral blood smear images. To overcome the greatest challenges in the segmentation phase, we implemented extensive pre-processing and introduced a three-phase filtration algorithm to achieve the best segmentation results. Moreover, sixteen robust features were extracted from the images in the way that hematological experts do, which significantly increased the capability of the classifiers to recognize leukemic cells in microscopic images. To perform the classification, we applied two traditional machine learning classifiers, the artificial neural network and the support vector machine. Both methods reached a specificity of 95.31%, and the sensitivity of the support vector machine and artificial neural network reached 98.25 and 100%, respectively.","automated leukemia detection,blood smear image analysis,cell segmentation,leukemic cell identification,acute leukemia,image processing,machine learning",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND","Biotechnology & Applied Microbiology,Science & Technology - Other Topics",,5.973,CLASSIFICATION,FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY,http://dspace.vsb.cz/bitstream/10084/142386/2/2296-4185-2020v8an1005.pdf,
55,,,,,,,,,,,,,,,,,,,,
56,,,,,,,,,,,,,,,,,,,,
57,Deep Learning Methods for Screening Pulmonary Tuberculosis Using Chest X-rays,9,1,39-49,"Dasanayaka Chirath,Dissanayake Maheshi Buddhinee","Dasanayaka C,Dissanayake MB",Dissanayake MB,10.1080/21681163.2020.1808532,University of Peradeniya,"Tuberculosis (TB) is a contagious bacterial airborne disease, and is one of the top 10 causes of death worldwide. According to the World Health Organisation, around 1.8 billion people are infected with TB and 1.6 million deaths were reported in 2018. More importantly, 95% of cases and deaths were from developing countries. Yet, TB is a completely curable disease through early diagnosis. To achieve this goal one of the key requirements is efficient utilisation of existing diagnostic technologies, among which chest X-ray is the first line of diagnostic tool used for screening for active TB. The presented deep learning pipeline consists of three different modern deep learning architectures, to generate, segment, and classify lung X-rays. Apart from this, image preprocessing, image augmentation, genetic algorithm based hyper parameter tuning, and model ensembling were used to improve the diagnostic process. We were able to achieve classification accuracy of 97.1% (Youden's index-0.941, sensitivity of 97.9%, specificity of 96.2%) which is a considerable improvement compared to the existing work in the literature. In our work, we present a highly accurate, automated TB screening system using chest X-rays, which would be helpful especially for low income countries with low access to qualified medical professionals.","Machine Learning,automated Tuberculosis Screening,Chest/Lung X-ray analysis,Deep Convolutional Generative Adversarial Networks,segmentation and Classification",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,,"LUNG,SEGMENTATION,RADIOGRAPHS,SHAPE",COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION,http://arxiv.org/pdf/2012.13582,
58,Stochastic Oblique Impact on Composite Laminates: A Concise Review and Characterization of the Essence of Hybrid Machine Learning Algorithms,28,3,1731-1760,"Mukhopadhyay T.,Naskar S.,Chakraborty S.,Karsh P. K.,Choudhury R.,Dey S.","Mukhopadhyay T,Naskar S,Chakraborty S,Karsh PK,Choudhury R,Dey S",Mukhopadhyay T,10.1007/s11831-020-09438-w,Indian Institute of Technology System (IIT System),"Due to the absence of adequate control at different stages of complex manufacturing process, material and geometric properties of composite structures are often uncertain. For a secure and safe design, tracking the impact of these uncertainties on the structural responses is of utmost significance. Composite materials, commonly adopted in various modern aerospace, marine, automobile and civil structures, are often susceptible to low-velocity impact caused by various external agents. Here, along with a critical review, we present machine learning based probabilistic and non-probabilistic (fuzzy) low-velocity impact analyses of composite laminates including a detailed deterministic characterization to systematically investigate the consequences of source- uncertainty. While probabilistic analysis can be performed only when complete statistical description about the input variables are available, the non-probabilistic analysis can be executed even in the presence of incomplete statistical input descriptions with sparse data. In this study, the stochastic effects of stacking sequence, twist angle, oblique impact, plate thickness, velocity of impactor and density of impactor are investigated on the crucial impact response parameters such as contact force, plate displacement, and impactor displacement. For efficient and accurate computation, a hybrid polynomial chaos based Kriging (PC-Kriging) approach is coupled with in-house finite element codes for uncertainty propagation in both the probabilistic and non- probabilistic analyses. The essence of this paper is a critical review on the hybrid machine learning algorithms followed by detailed numerical investigation in the probabilistic and non-probabilistic regimes to access the performance of such hybrid algorithms in comparison to individual algorithms from the viewpoint of accuracy and computational efficiency.","LOW-VELOCITY IMPACT,DIMENSIONAL MODEL REPRESENTATION,GAUSSIAN PROCESS REGRESSION,NATURAL FREQUENCY-ANALYSIS,FREE-VIBRATION ANALYSIS,POLYNOMIAL-CHAOS,UNCERTAINTY QUANTIFICATION,PROBABILISTIC ANALYSIS,SENSITIVITY-ANALYSIS,SURROGATE MODELS",Review,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering,Mathematics",,8.169,"LOW-VELOCITY,IMPACT,DIMENSIONAL,MODEL,REPRESENTATION,GAUSSIAN,PROCESS,REGRESSION,NATURAL,FREQUENCY-ANALYSIS,FREE-VIBRATION,ANALYSIS,POLYNOMIAL-CHAOS,UNCERTAINTY,QUANTIFICATION,PROBABILISTIC,ANALYSIS,SENSITIVITY-ANALYSIS,SURROGATE,MODELS",ARCHIVES OF COMPUTATIONAL METHODS IN ENGINEERING,https://eprints.soton.ac.uk/452051/1/11831_2020_9438_OnlinePDF_final.pdf,
59,Type2 diabetes mellitus prediction using data mining algorithms based on the long-noncoding RNAs expression: a comparison of four data mining approaches,21,1,,"Kazerouni Faranak,Bayani Azadeh,Asadi Farkhondeh,Saeidi Leyla,Parvizi Nasrin,Mansoori Zahra","Kazerouni F,Bayani A,Asadi F,Saeidi L,Parvizi N,Mansoori Z",Asadi F,10.1186/s12859-020-03719-8,Shahid Beheshti University Medical Sciences,"Background About 90% of patients who have diabetes suffer from Type 2 DM (T2DM). Many studies suggest using the significant role of lncRNAs to improve the diagnosis of T2DM. Machine learning and Data Mining techniques are tools that can improve the analysis and interpretation or extraction of knowledge from the data. These techniques may enhance the prognosis and diagnosis associated with reducing diseases such as T2DM. We applied four classification models, including K-nearest neighbor (KNN), support vector machine (SVM), logistic regression, and artificial neural networks (ANN) for diagnosing T2DM, and we compared the diagnostic power of these algorithms with each other. We performed the algorithms on six LncRNA variables (LINC00523, LINC00995, HCG27_201, TPT1-AS1, LY86-AS1, DKFZP) and demographic data. Results To select the best performance, we considered the AUC, sensitivity, specificity, plotted the ROC curve, and showed the average curve and range. The mean AUC for the KNN algorithm was 91% with 0.09 standard deviation (SD); the mean sensitivity and specificity were 96 and 85%, respectively. After applying the SVM algorithm, the mean AUC obtained 95% after stratified 10-fold cross-validation, and the SD obtained 0.05. The mean sensitivity and specificity were 95 and 86%, respectively. The mean AUC for ANN and the SD were 93% and 0.03, also the mean sensitivity and specificity were 78 and 85%. At last, for the logistic regression algorithm, our results showed 95% of mean AUC, and the SD of 0.05, the mean sensitivity and specificity were 92 and 85%, respectively. According to the ROCs, the Logistic Regression and SVM had a better area under the curve compared to the others. Conclusion We aimed to find the best data mining approach for the prediction of T2DM using six lncRNA expression. According to the finding, the maximum AUC dedicated to SVM and logistic regression, among others, KNN and ANN also had the high mean AUC and small standard deviations of AUC scores among the approaches, KNN had the highest mean sensitivity and the highest specificity belonged to SVM. This study's result could improve our knowledge about the early detection and diagnosis of T2DM using the lncRNAs as biomarkers.","Data mining,Gene expression,Type 2 diabetes mellitus",Article,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,"CLASSIFICATION,DIAGNOSIS",BMC BIOINFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7451240,
60,Is Domain Knowledge Necessary for Machine Learning Materials Properties?,9,3,221-227,"Murdock Ryan J.,Kauwe Steven K.,Wang Anthony Yu-Tung,Sparks Taylor D.","Murdock RJ,Kauwe SK,Wang AYT,Sparks TD",Sparks TD,10.1007/s40192-020-00179-z,Utah System of Higher Education,"New featurization schemes for describing materials as composition vectors in order to predict their properties using machine learning are common in the field of Materials Informatics. However, little is known about the comparative efficacy of these methods. This work sets out to make clear which featurization methods should be used across various circumstances. Our findings include, surprisingly, that simple fractional and random-noise representations of elements can be as effective as traditional and new descriptors when using large amounts of data. However, in the absence of large datasets or for data that is not fully representative, we show that the integration of domain knowledge offers advantages in predictive ability.
[GRAPHICS]
.","Materials informatics,Machine learning,Featurization,Descriptors,Neural networks",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Materials Science",,4.423,,INTEGRATING MATERIALS AND MANUFACTURING INNOVATION,https://doi.org/10.26434/chemrxiv.11879193,
61,,,,,,,,,,,,,,,,,,,,
62,DNetUnet: a semi-supervised CNN of medical image segmentation for super-computing AI service,77,4,3594-3615,"Tseng Kuo-Kun,Zhang Ran,Chen Chien-Ming,Hassan Mohammad Mehedi","Tseng KK,Zhang R,Chen CM,Hassan MM",Hassan MM,10.1007/s11227-020-03407-7,King Saud University,"Deep learning approaches have achieved good performance in segmenting medical images. In this paper, we propose a new convolutional neural network architecture named DNetUnet, which combines U-Nets with different down-sampling levels and a new dense block as feature extractor. In addition, DNetUnet is a semi-supervised learning method, which can be used not only to obtain expert knowledge from the labelled corpus, but also to enhance the performance of learning algorithm generalization ability from unlabelled data. Further, we integrate distillation technique to improve the performance on mobile platform. The experimental results demonstrate that the proposed segmentation model yields superior performance over competition. Since the processing of large medical images and distillation technology is enforced, a supercomputing AI training server is a preference for its application.","Medical image segmentation,Semi-supervised deep learning,U-Net,Distillation",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.344,,JOURNAL OF SUPERCOMPUTING,,
63,Features and trends of personalised learning: a review of journal publications from 2001 to 2018,29,2,182-195,"Li Kam Cheong,Wong Billy Tak-Ming","Li KC,Wong BTM",Wong BTM,10.1080/10494820.2020.1811735,Hong Kong Metropolitan University,"This paper provides a comprehensive review of the features and trends of personalised learning. The review covers a total of 203 journal articles collected from Scopus, which were published from 2001 to 2018 and involved personalised learning practices. Comparing the practices between 2001-2009 and 2010-2018, there was a clear trend that they became more diversified in terms of the educational levels and modes of education, as well as the means to achieve personalised learning, their objectives and the devices used. In most practices, the use of technology was clearly emphasised, such as various intelligent learning/tutoring systems, mobile devices, learning analytics, and augmented/virtual reality applications. Learning methods, materials and the time and places for learning were the aspects most frequently addressed. The objectives of the practices focused mainly on increasing learning effectiveness, followed by enhancing learners' motivation, engagement and satisfaction. The factors leading to successful personalised learning were identified from the articles reviewed, among which most factors were related to learners' characteristics, learning progress and technology. Research issues which need further investigation are recommended, particularly on the challenges arising from the adoption of emerging technologies, and the changing role of teachers in the trend towards student-centred personalised learning.","Personalised learning,differentiated learning,technology-assisted learning,student-centred learning",Review,"ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND",Education & Educational Research,,3.868,CLASSROOM,INTERACTIVE LEARNING ENVIRONMENTS,,
64,Harnessing a multi-dimensional fibre laser using genetic wavefront shaping,9,1,,"Wei Xiaoming,Jing Joseph C.,Shen Yuecheng,Wang Lihong V","Wei XM,Jing JC,Shen YC,Wang LHV",Wang LHV,10.1038/s41377-020-00383-8,California Institute of Technology,"Intelligent 3D lasers: Bio-inspired algorithms help tame multimode fiber lasers Multimode fibres that contain numerous groups of lightwaves, or modes, can now assist lasers in producing tunable emission characteristics. Lihong Wang from the California Institute of Technology in Pasadena, United States, and colleagues have developed a technique to control the complex interactions inside a multimode fibre laser using machine learning. The team created a feedback loop where portions of laser signals travelling through a multimode fibre are sent to a spatial light modulator that adjusts the phases of propagating waves. By using genetic algorithms to direct the spatial light modulator, this setup can optimize parameters such as output power after a few minutes of evolutionary feedback-changing, for instance, an initial speckle-shaped light pattern into a single focused spot. Other tunable laser features including wavelength scanning and pulse control were demonstrated with this approach.
The multi-dimensional laser is a fascinating platform not only for the discovery and understanding of new higher-dimensional coherent lightwaves but also for the frontier study of the complex three-dimensional (3D) nonlinear dynamics and solitary waves widely involved in physics, chemistry, biology and materials science. Systemically controlling coherent lightwave oscillation in multi-dimensional lasers, however, is challenging and has largely been unexplored; yet, it is crucial for both designing 3D coherent light fields and unveiling any underlying nonlinear complexities. Here, for the first time, we genetically harness a multi-dimensional fibre laser using intracavity wavefront shaping technology such that versatile lasing characteristics can be manipulated. We demonstrate that the output power, mode profile, optical spectrum and mode-locking operation can be genetically optimized by appropriately designing the objective function of the genetic algorithm. It is anticipated that this genetic and systematic intracavity control technology for multi-dimensional lasers will be an important step for obtaining high-performance 3D lasing and presents many possibilities for exploring multi-dimensional nonlinear dynamics and solitary waves that may enable new applications.","MODE-LOCKING,ENERGY QUANTIZATION,LIGHT,STATES",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Optics,,16.996,"MODE-LOCKING,ENERGY,QUANTIZATION,LIGHT,STATES",LIGHT-SCIENCE & APPLICATIONS,https://authors.library.caltech.edu/105121/1/s41377-020-00383-8.pdf,
65,Co-eye: a multi-resolution ensemble classifier for symbolically approximated time series,109,11,2029-2061,"Abdallah Zahraa S.,Gaber Mohamed Medhat","Abdallah ZS,Gaber MM",Abdallah ZS,10.1007/s10994-020-05887-3,Birmingham City University,"Time series classification (TSC) is a challenging task that attracted many researchers in the last few years. One main challenge in TSC is the diversity of domains where time series data come from. Thus, there is no ""one model that fits all"" in TSC. Some algorithms are very accurate in classifying a specific type of time series when the whole series is considered, while some only target the existence/non-existence of specific patterns/shapelets. Yet other techniques focus on the frequency of occurrences of discriminating patterns/features. This paper presents a new classification technique that addresses the inherent diversity problem in TSC using a nature-inspired method. The technique is stimulated by how flies look at the world through ""compound eyes"" that are made up of thousands of lenses, called ommatidia. Each ommatidium is an eye with its own lens, and thousands of them together create a broad field of vision. The developed technique similarly uses different lenses and representations to look at the time series, and then combines them for broader visibility. These lenses have been created through hyper-parameterisation of symbolic representations (Piecewise Aggregate and Fourier approximations). The algorithm builds a random forest for each lens, then performs soft dynamic voting for classifying new instances using the most confident eyes, i.e., forests. We evaluate the new technique, coined Co-eye, using the recently released extended version of UCR archive, containing more than 100 datasets across a wide range of domains. The results show the benefits of bringing together different perspectives reflecting on the accuracy and robustness of Co-eye in comparison to other state-of-the-art techniques.","Time series classification,Symbolic representation,Ensemble classification,Random Forest",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,3.693,"SIMILARITY,SEARCH,FOREST",MACHINE LEARNING,https://research-information.bris.ac.uk/ws/files/250271622/Abdallah_Gaber2020_Article_Co_eyeAMulti_resolutionEnsembl.pdf,
66,Combining Superionic Conduction and Favorable Decomposition Products in the Crystalline Lithium-Boron-Sulfur System: A New Mechanism for Stabilizing Solid Li-Ion Electrolytes,12,34,37957-37966,"Sendek Austin D.,Antoniuk Evan R.,Cubuk Ekin D.,Ransom Brandi,Francisco Brian E.,Buettner-Garrett Josh,Cui Yi,Reed Evan J.","Sendek AD,Antoniuk ER,Cubuk ED,Ransom B,Francisco BE,Buettner-Garrett J,Cui Y,Reed EJ",Reed EJ,10.1021/acsami.9b19091,Stanford University,"We report a solid-state Li-ion electrolyte predicted to exhibit simultaneously fast ionic conductivity, wide electrochemical stability, low cost, and low mass density. We report exceptional density functional theory (DFT)-based room-temperature single-crystal ionic conductivity values for two phases within the crystalline lithium-boron-sulfur (Li-B-S) system: 62 (+9, -2) mS cm(-1) in Li5B7S13 and 80 (-56, -41) mS cm(-1) in Li9B19S33. We report significant ionic conductivity values for two additional phases: between 0.0056 and 0.16 mS/cm(-1) in Li2B2S5 and between 0.0031 and 9.7 mS cm(-1) in Li3BS3 depending on the room-temperature extrapolation scheme used. To our knowledge, our prediction gives Li9B19S33 and Li5B7S13 the second and third highest reported DFT-computed single-crystal ionic conductivities of any crystalline material. We compute the thermodynamic electrochemical stability window widths of these materials to be 0.50 V for Li5B7S13, 0.16 V for Li2B2S5, 0.45 V for Li3BS3, and 0.60 V for Li9B19S33. Individually, these materials exhibit similar or better ionic conductivity and electrochemical stability than the best-known sulfide-based solid-state Li-ion electrolyte materials, including Li10GeP2S12 (LGPS). However, we predict that electrolyte materials synthesized from a range of compositions in the Li-B-S system may exhibit even wider thermodynamic electrochemical stability windows of 0.63 V and possibly as high as 3 V or greater. The Li-B-S system also has a low elemental cost of approximately 0.05 USD/m(2) per 10 mu m thickness, which is significantly lower than that of germanium-containing LGPS, and a comparable mass density below 2 g/cm(3). These fast-conducting phases were initially brought to our attention by a machine learning-based approach to screen over 12,000 solid electrolyte candidates, and the evidence provided here represents an inspiring success for this model.","solid ion conductor,solid electrolyte,Li-ion battery,density functional theory,ion transport,electrochemical stability,kinetics",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science",,9.57,"STATE,BATTERIES,PHASE-STABILITY,DENSITY,DYNAMICS,CATHODES,GLASSES,NMR,MN,FE",ACS APPLIED MATERIALS & INTERFACES,,
67,Big-Data Science in Porous Materials: Materials Genomics and Machine Learning,120,16,8066-8129,"Jablonka Kevin Maik,Ongari Daniele,Moosavi Seyed Mohamad,Smit Berend","Jablonka KM,Ongari D,Moosavi SM,Smit B",Smit B,10.1021/acs.chemrev.0c00004,Ecole Polytechnique Federale de Lausanne,"By combining metal nodes with organic linkers we can potentially synthesize millions of possible metal-organic frameworks (MOFs). The fact that we have so many materials opens many exciting avenues but also create new challenges. We simply have too many materials to be processed using conventional, brute force, methods. In this review, we show that having so many materials allows us to use big-data methods as a powerful technique to study these materials and to discover complex correlations. The first part of the review gives an introduction to the principles of big-data science. 'We show how to select appropriate training sets, survey approaches that are used to represent these materials in feature space, and review different learning architectures, as well as evaluation and interpretation strategies. In the second part, we review how the different approaches of machine learning have been applied to porous materials. In particular, we discuss applications in the field of gas storage and separation, the stability of these materials, their electronic properties, and their synthesis. Given the increasing interest of the scientific community in machine learning, we expect this list to rapidly expand in the coming years.","METAL-ORGANIC FRAMEWORKS,ARTIFICIAL NEURAL-NETWORKS,STRUCTURE-PROPERTY RELATIONSHIPS,PARTICLE SWARM OPTIMIZATION,CARBON-DIOXIDE CAPTURE,DRIVEN HEAT-PUMPS,HIGH-THROUGHPUT,METHANE STORAGE,FEATURE-SELECTION,ZEOLITE FRAMEWORKS",Review,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,66.813,"METAL-ORGANIC,FRAMEWORKS,ARTIFICIAL,NEURAL-NETWORKS,STRUCTURE-PROPERTY,RELATIONSHIPS,PARTICLE,SWARM,OPTIMIZATION,CARBON-DIOXIDE,CAPTURE,DRIVEN,HEAT-PUMPS,HIGH-THROUGHPUT,METHANE,STORAGE,FEATURE-SELECTION,ZEOLITE,FRAMEWORKS",CHEMICAL REVIEWS,https://pubs.acs.org/doi/pdf/10.1021/acs.chemrev.0c00004,
68,Artificial intelligence-driven novel tool for tooth detection and segmentation on panoramic radiographs,25,4,2257-2267,"Leite Andre Ferreira,Van Gerven Adriaan,Willems Holger,Beznik Thomas,Lahoud Pierre,Gaeta-Araujo Hugo,Vranckx Myrthel,Jacobs Reinhilde","Leite AF,Van Gerven A,Willems H,Beznik T,Lahoud P,Gaeta-Araujo H,Vranckx M,Jacobs R",Leite AF,10.1007/s00784-020-03544-6,KU Leuven,"Objective To evaluate the performance of a new artificial intelligence (AI)-driven tool for tooth detection and segmentation on panoramic radiographs. Materials and methods In total, 153 radiographs were collected. A dentomaxillofacial radiologist labeled and segmented each tooth, serving as the ground truth. Class-agnostic crops with one tooth resulted in 3576 training teeth. The AI-driven tool combined two deep convolutional neural networks with expert refinement. Accuracy of the system to detect and segment teeth was the primary outcome, time analysis secondary. The Kruskal-Wallis test was used to evaluate differences of performance metrics among teeth groups and different devices and chi-square test to verify associations among the amount of corrections, presence of false positive and false negative, and crown and root parts of teeth with potential AI misinterpretations. Results The system achieved a sensitivity of 98.9% and a precision of 99.6% for tooth detection. For segmenting teeth, lower canines presented best results with the following values for intersection over union, precision, recall, F1-score, and Hausdorff distances: 95.3%, 96.9%, 98.3%, 97.5%, and 7.9, respectively. Although still above 90%, segmentation results for both upper and lower molars were somewhat lower. The method showed a clinically significant reduction of 67% of the time consumed for the manual. Conclusions The AI tool yielded a highly accurate and fast performance for detecting and segmenting teeth, faster than the ground truth alone. Clinical significance An innovative clinical AI-driven tool showed a faster and more accurate performance to detect and segment teeth on panoramic radiographs compared with manual segmentation.","Artificial intelligence,Machine learning,Panoramic radiography,Tooth,Classification",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Dentistry, Oral Surgery & Medicine",,3.623,"CONVOLUTIONAL,NEURAL-NETWORK,TEETH",CLINICAL ORAL INVESTIGATIONS,,
69,Machine learning as an improved estimator for magnetization curve and spin gap,10,1,,Nakamura Tota,Nakamura T,Nakamura T,10.1038/s41598-020-70389-0,Shibaura Institute of Technology,"The magnetization process is a very important probe to study magnetic materials, particularly in search of spin-liquid states in quantum spin systems. Regrettably, however, progress of the theoretical analysis has been unsatisfactory, mostly because it is hard to obtain sufficient numerical data to support the theory. Here we propose a machine-learning algorithm that produces the magnetization curve and the spin gap well out of poor numerical data. The plateau magnetization, its critical field and the critical exponent are estimated accurately. One of the hyperparameters identifies by its score whether the spin gap in the thermodynamic limit is zero or finite. After checking the validity for exactly solvable one-dimensional models we apply our algorithm to the kagome antiferromagnet. The magnetization curve that we obtain from the exact-diagonalization data with 36 spins is consistent with the DMRG results with 132 spins. We estimate the spin gap in the thermodynamic limit at a very small but finite value.","LIQUID GROUND-STATE,HEISENBERG-ANTIFERROMAGNET,PLATEAUS,MODEL,LATTICE,CHAIN",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,5.134,"LIQUID,GROUND-STATE,HEISENBERG-ANTIFERROMAGNET,PLATEAUS,MODEL,LATTICE,CHAIN",SCIENTIFIC REPORTS,http://arxiv.org/pdf/1902.02941,
70,Identification and characterization of tweets related to the 2015 Indiana HIV outbreak: A retrospective infoveillance study,15,8,,"Cai Mingxiang,Shah Neal,Li Jiawei,Chen Wen-Hao,Cuomo Raphael E.,Obradovich Nick,Mackey Tim K.","Cai MX,Shah N,Li JW,Chen WH,Cuomo RE,Obradovich N,Mackey TK",Mackey TK,10.1371/journal.pone.0235150,"Global Hlth Policy Inst, San Diego, CA 92103 USA.","Introduction From late 2014 through 2015, Scott County, Indiana faced an HIV outbreak triggered by opioid abuse and transition to injection drug use. Investigating the origins, risk factors, and responses related to this outbreak is critical to inform future surveillance, interventions, and policymaking. In response, this retrospective infoveillance study identifies and characterizes user-generated messages related to opioid abuse, heroin injection drug use, and HIV status using natural language processing (NLP) among Twitter users in Indiana during the period of this HIV outbreak. Materials and methods Our study consisted of two phases: data collection and processing, and data analysis. We collected Indiana geolocated tweets from the public Twitter API using Amazon Web Services EC2 instances filtered for geocoded messages in the immediate pre and post period of the outbreak. In the data analysis phase we applied an unsupervised machine learning approach using NLP called the Biterm Topic Model (BTM) to identify tweets related to opioid, heroin/injection, and HIV behavior and then examined these messages for HIV risk-related topics that could be associated with the outbreak. Results More than 10 million geocoded tweets occurring in Indiana during the immediate pre and post period of the outbreak were collected for analysis. Using BTM, we identified 1350 tweets thought to be relevant to the outbreak and then confirmed 358 tweets using human annotation. The most prevalent themes identified were tweets related to self-reported abuse of illicit and prescription drugs, opioid use disorder, self-reported HIV status, and public sentiment regarding the outbreak. Geospatial analysis found that these messages clustered in population dense areas outside of the outbreak, including Indianapolis and neighboring Clark County. Discussion This infoveillance study characterized the social media conversations of communities in Indiana in the pre and post period of the 2015 HIV outbreak. Behavioral themes detected reflect discussion about risk factors related to HIV transmission stemming from opioid and heroin abuse for priority populations, and also help identify community attitudes that could have motivated or detracted the use of HIV prevention methods, along with helping identify factors that can impede access to prevention services. Conclusions Infoveillance approaches, such as the analysis conducted in this study, represent a possibly strategy to detect ""signal"" of the emergence of risk factors associated with an outbreak though may be limited in their scope and generalizability. Our results, in conjunction with other forms of public health surveillance, can leverage the growing ubiquity of social media platforms to better detect opioid-related HIV risk knowledge, attitudes and behavior, as well as inform future prevention efforts.","INFORMATION,TWITTER,TRENDS",Article,"PUBLIC LIBRARY SCIENCE, 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA",Science & Technology - Other Topics,,3.788,"INFORMATION,TWITTER,TRENDS",PLOS ONE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7449407,
71,Assessment of CFH and HTRA1 polymorphisms in age-related macular degeneration using classic and machine-learning approaches,41,6,539-547,"Martinez-Velasco Antonieta,Perez-Ortiz Andric C.,Antonio-Aguirre Bani,Martinez-Villasenor Lourdes,Lira-Romero Esmeralda,Palacio-Pastrana Claudia,Zenteno Juan Carlos,Ramirez Israel,Zepeda-Palacio Claudia,Mendoza-Velasquez Cristina","Martinez-Velasco A,Perez-Ortiz AC,Antonio-Aguirre B,Martinez-Villasenor L,Lira-Romero E,Palacio-Pastrana C,Zenteno JC,Ramirez I,Zepeda-Palacio C,Mendoza-Velasquez C",Estrada-Mena FJ,10.1080/13816810.2020.1804945,Universidad Panamericana - Ciudad de Mexico,"Background: CFH and HTRA1 are pivotal genes driving increased risk for age-related macular degeneration (AMD) among several populations. Here, we performed a hospital-based case-control study to evaluate the effects of three single nucleotide polymorphisms (SNPs) among Hispanics from Mexico.
Materials and methods: 122 cases and 249 controls were genotyped using Taqman probes. Experienced ophthalmologists diagnosed AMD following the American Association of Ophthalmology guidelines. We studied CFH (rs1329428, rs203687) and HTRA1 (rs11200638) SNPs thoroughly by logistic regression models (assuming different modes of inheritance) and machine learning-based methods (ML).
Results: HTRA1 rs11200638 is the most significant polymorphism associated with AMD in our studied population. In a multivariate regression model adjusted for clinically and statistically meaningful covariates, the A/G and A/A genotypes increased the odds of disease by a factor of 2.32 and 7.81, respectively (P < .05) suggesting a multiplicative effect of the polymorphic A allele. Furthermore, this observation remains statistically meaningful in the allelic, dominant, and recessive models, and ML algorithms. When stratifying by phenotype, this polymorphism was significantly associated with increased odds for geographic atrophy (GA) in a recessive mode of inheritance (12.4, p < .05).
Conclusions: In sum, this work supports a strong association between HTRA1 genetic variants and AMD in Hispanics from Mexico, especially with GA. Moreover, ML was able to replicate the results of conventional biostatistics methods unbiasedly.","Age-related macular degeneration,complement factor H,high-temperature requirement A serine peptidase 1,genetic association study,machine-learning",Article,"TAYLOR & FRANCIS INC, 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA","Genetics & Heredity,Ophthalmology",,1.815,"GENE,POLYMORPHISMS,ASSOCIATION,SUSCEPTIBILITY,PREVALENCE,VARIANT,HAPLOTYPES",OPHTHALMIC GENETICS,,
72,Interactive-quantum-chemical-descriptors enabling accurate prediction of an activation energy through machine learning,203,,,Mikami Koichiro,Mikami K,Mikami K,10.1016/j.polymer.2020.122738,"Sagami Chem Res Inst, 2743-1 Hayakawa, Ayase, Kanagawa 2521193, Japan.","Artificial intelligence- and machine learning (ML)-assisted reaction/material development are an emerging research area in organic, organometallic, polymer chemistry and materials science. Quantum chemical descriptors (QCDs) that are classically constructed with steric/electrostatic parameters make the process of the prediction through ML easily understood and allow us to find new chemical pictures for reaction, materials and functionality. Herein, I present the development of novel QCDs-interactive-quantum-chemical-descriptors (IQCDs)-well-expressing an intermolecular interaction among target molecules. The use of IQCDs drastically improved the prediction-accuracy rather than the use of only the classical QCD. One of the IQCDs consists of natural energy decomposition analysis (NEDA), well-expressing a chemical interaction among the molecules/materials, which would be applicable for dynamic processes including formation of chemical bonding, organometallic complex, and supramolecular complex.","Machine-learning,DFT calculation,Metallocene,Mechanism,Descriptor",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Polymer Science,,4.186,"DECOMPOSITION,ANALYSIS,POLYMERIZATION,LIGANDS,ETHYLENE,METAL,QSAR",POLYMER,,
73,Machine Learning to Reveal Nanoparticle Dynamics from Liquid-Phase TEM Videos,6,8,1421-1430,"Yao Lehan,Ou Zihao,Luo Binbin,Xu Cong,Chen Qian","Yao LH,Ou ZH,Luo BB,Xu C,Chen Q",Chen Q,10.1021/acscentsci.0c00430,University of Illinois System,"Liquid-phase transmission electron microscopy (TEM) has been recently applied to materials chemistry to gain fundamental understanding of various reaction and phase transition dynamics at nanometer resolution. However, quantitative extraction of physical and chemical parameters from the liquid-phase TEM videos remains bottlenecked by the lack of automated analysis methods compatible with the videos' high noisiness and spatial heterogeneity. Here, we integrate, for the first time, liquid-phase TEM imaging with our customized analysis framework based on a machine learning model called U-Net neural network. This combination is made possible by our workflow to generate simulated TEM images as the training data with well-defined ground truth. We apply this framework to three typical systems of colloidal nanoparticles, concerning their diffusion and interaction, reaction kinetics, and assembly dynamics, all resolved in real-time and real-space by liquid-phase TEM. A diversity of properties for differently shaped anisotropic nanoparticles are mapped, including the anisotropic interaction landscape of nanoprisms, curvature-dependent and staged etching profiles of nanorods, and an unexpected kinetic law of first-order chaining assembly of concave nanocubes. These systems representing properties at the nanoscale are otherwise experimentally inaccessible. Compared to the prevalent image segmentation methods, U-Net shows a superior capability to predict the position and shape boundary of nanoparticles from highly noisy and fluctuating background-a challenge common and sometimes inevitable in liquid-phase TEM videos. We expect our framework to push the potency of liquid-phase TEM to its full quantitative level and to shed insights, in high-throughput and statistically significant fashion, on the nanoscale dynamics of synthetic and biological nanomaterials.","IN-SITU,GOLD NANOPARTICLES,GROWTH,NUCLEATION,NANOCRYSTALS,MECHANISMS,DISTANCE,BEHAVIOR,MOTION",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,15.435,"IN-SITU,GOLD,NANOPARTICLES,GROWTH,NUCLEATION,NANOCRYSTALS,MECHANISMS,DISTANCE,BEHAVIOR,MOTION",ACS CENTRAL SCIENCE,https://pubs.acs.org/doi/pdf/10.1021/acscentsci.0c00430,
74,Machine-learned metrics for predicting the likelihood of success in materials discovery,6,1,,"Kim Yoolhee,Kim Edward,Antono Erin,Meredig Bryce,Ling Julia","Kim Y,Kim E,Antono E,Meredig B,Ling JL",Kim Y,10.1038/s41524-020-00401-8,"Citrine Informat, Redwood City, CA 94063 USA.","Materials discovery is often compared to the challenge of finding a needle in a haystack. While much work has focused on accurately predicting the properties of candidate materials with machine learning (ML), which amounts to evaluating whether a given candidate is a piece of straw or a needle, less attention has been paid to a critical question: are we searching in the right haystack? We refer to the haystack as the design space for a particular materials discovery problem (i.e., the set of possible candidate materials to synthesize), and thus frame this question as one of design space selection. In this paper, we introduce two metrics, the predicted fraction of improved candidates (PFIC), and the cumulative maximum likelihood of improvement (CMLI), which we demonstrate can identify discovery-rich and discovery-poor design spaces, respectively. A combined classification system, composed of the CMLI and PFIC metrics, is then used to identify optimal design spaces with high precision, and thus show the potential to significantly accelerate ML-driven materials discovery.",DESIGN,Article,"NATURE PUBLISHING GROUP, MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Chemistry,Materials Science",,13.993,DESIGN,NPJ COMPUTATIONAL MATERIALS,http://arxiv.org/pdf/1911.11201,
75,Evaluation of navigation methodologies for mobile robots,137,6,316-323,"Woeber Wilfried,Rauer Johannes,Papa Maximilian,Aburaia Ali,Schwaiger Simon,Novotny Georg,Aburaia Mohamed,Kubinger Wilfried","Wober W,Rauer J,Papa M,Aburaia A,Schwaiger S,Novotny G,Aburaia M,Kubinger W",Wober W,10.1007/s00502-020-00820-x,"Fachhsch Technikum Wien, Hochstadtpl 6, A-1200 Vienna, Austria.","Intelligent mobile robots and service robots are central parts of autonomous productions and flexible manufacturing. Interconnected industrial robot-based automation allows customized productions for which mobile robots are used for transport of material and tools. The digital factory of the UAS Technikum Wien is a research project which focuses on experimental evaluation of novel technologies for digital manufacturing. This paper discusses applications of mobile and service robots in the digital factory. Based on a production use case, we analyze several methods for navigation in terms of accuracy of those approaches and discuss safety aspects.","mobile robotics,navigation,probabilistic robotics,machine learning,Industry 4,0",Article,"SPRINGER WIEN, SACHSENPLATZ 4-6, PO BOX 89, A-1201 WIEN, AUSTRIA",Engineering,,,,ELEKTROTECHNIK UND INFORMATIONSTECHNIK,,
76,Machine learning topological phases in real space,102,5,,"Holanda N. L.,Griffith M. A. R.","Holanda NL,Griffith MAR",Holanda NL,10.1103/PhysRevB.102.054107,University of Cambridge,"We develop a supervised machine learning algorithm that is able to learn topological phases of finite condensed-matter systems from bulk data in real lattice space. The algorithm employs diagonalization in real space together with any supervised learning algorithm to learn topological phases through an eigenvector ensembling procedure. We combine our algorithm with decision trees and random forests to successfully recover topological phase diagrams of Su-Schrieffer-Heeger (SSH) models from bulk lattice data in real space and show how the Shannon information entropy of ensembles of lattice eigenvectors can be used to retrieve a signal detailing how topological information is distributed in the bulk. We further use insights obtained from these information entropy signatures to engineer global topological features from real-space lattice data that still carry most of the topological information in the lattice, while greatly diminishing the size of feature space, thus effectively amounting to a topological lattice compression. Finally, we explore the theoretical possibility of interpreting the information entropy topological signatures in terms of emergent information entropy wave functions, which lead us to Heisenberg and Hirschman uncertainty relations for topological phase transitions. The discovery of Shannon information entropy signals associated with topological phase transitions from the analysis of data from several thousand SSH systems illustrates how model explainability in machine learning can advance the research of exotic quantum materials with properties that may power future technological applications such as qubit engineering for quantum computing.","EDGE STATES,TRANSITIONS,SOLITONS",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,"EDGE,STATES,TRANSITIONS,SOLITONS",PHYSICAL REVIEW B,http://arxiv.org/pdf/1901.01963,
77,Dynamic Deep Networks for Retinal Vessel Segmentation,2,,,"Khanal Aashis,Estrada Rolando","Khanal A,Estrada R",Estrada R,10.3389/fcomp.2020.00035,University System of Georgia,"Deep learning has recently yielded impressive gains in retinal vessel segmentation. However, state-of-the-art methods tend to be conservative, favoring precision over recall. Thus, they tend to under-segment faint vessels, underestimate the width of thicker vessels, or even miss entire vessels. To address this limitation, we propose a stochastic training scheme for deep neural networks that robustly balances precision and recall. First, we train our deep networks with dynamic class weights in the loss function that fluctuate during each training iteration. This stochastic approach-which we believe is applicable to many other machine learning problems-forces the network to learn a balanced classification. Second, we decouple the segmentation process into two steps. In the first half of our pipeline, we estimate the likelihood of every pixel and then use these likelihoods to segment pixels that are clearly vessel or background. In the latter part of our pipeline, we use a second network to classify the ambiguous regions in the image. Our proposed method obtained state-of-the-art results on five retinal datasets-DRIVE, STARE, CHASE-DB, AV-WIDE, and VEVIO-by learning a robust balance between false positive and false negative rates. Our novel training paradigm makes a neural network more robust to inter-sample differences in class ratios, which we believe will prove particularly effective for settings with sparse training data, such as medical image analysis. In addition, we are the first to report segmentation results on the AV-WIDE dataset, and we have made the ground-truth annotations for this dataset publicly available. An implementation of this work can be found at .</p>","retinal vessel segmentation,deep learning,stochastic optimization,dynamic optimization,image analysis",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Computer Science,,,"BLOOD-VESSELS,IMAGES,CLASSIFICATION",FRONTIERS IN COMPUTER SCIENCE,https://www.frontiersin.org/articles/10.3389/fcomp.2020.00035/pdf,
78,Frustration effects at finite temperature in the half filled Hubbard model,32,36,,"Jana Gour,Mukherjee Anamitra","Jana G,Mukherjee A",Jana G,10.1088/1361-648X/ab9058,Homi Bhabha National Institute,"We investigate the finite temperature properties of the half filled Hubbard model in two dimensions, with onsite interaction (U), in presence of (frustrating) next nearest neighbor hopping (t ') using a semiclassical approximation scheme. We show that introduction oft ' results in a finite temperature pseudogapped (PG) phase that separates the smallUFermi liquid and largeUMott insulator. We map out the PG to normal metal crossover temperature scale (T*) as a function ofUandt '. We demonstrate that in the PG phase, the quadratic dependence of resistivity on temperature is violated due to thermally induced spin fluctuations. We conclude with exact diagonalization calculations, that complement our finite temperature results, and indicate the presence of a frustration driven PG state between the Fermi liquid and the Mott insulator at zero temperature as well.","strongly correlated system,magnetism,metal insulator transitions",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,2.887,"DIMENSIONAL,FERMI-SURFACE,INSTABILITY,TRANSITION,PHASE,METAL",JOURNAL OF PHYSICS-CONDENSED MATTER,http://arxiv.org/pdf/1902.04241,
79,21st-century biogeochemical modeling: Challenges for Century-based models and where do we go from here?,12,10,774-788,"Berardi Danielle,Brzostek Edward,Blanc-Betes Elena,Davison Brian,DeLucia Evan H.,Hartman Melannie D.,Kent Jeffrey,Parton William J.,Saha Debasish,Hudiburg Tara W.","Berardi D,Brzostek E,Blanc-Betes E,Davison B,DeLucia EH,Hartman MD,Kent J,Parton WJ,Saha D,Hudiburg TW",Hudiburg TW,10.1111/gcbb.12730,University of Idaho,"21st-century modeling of greenhouse gas (GHG) emissions from bioenergy crops is necessary to quantify the extent to which bioenergy production can mitigate climate change. For over 30 years, the Century-based biogeochemical models have provided the preeminent framework for belowground carbon and nitrogen cycling in ecosystem and earth system models. While monthly Century and the daily time-step version of Century (DayCent) have advanced our ability to predict the sustainability of bioenergy crop production, new advances in feedstock generation, and our empirical understanding of sources and sinks of GHGs in soils call for a re-visitation of DayCent's core model structures. Here, we evaluate current challenges with modeling soil carbon dynamics, trace gas fluxes, and drought and age-related impacts on bioenergy crop productivity. We propose coupling a microbial process-based soil organic carbon and nitrogen model with DayCent to improve soil carbon dynamics. We describe recent improvements to DayCent for simulating unique plant structural and physiological attributes of perennial bioenergy grasses. Finally, we propose a method for using machine learning to identify key parameters for simulating N2O emissions. Our efforts are focused on meeting the needs for modeling bioenergy crops; however, many updates reviewed and suggested to DayCent will be broadly applicable to other systems.","bioenergy,biogeochemical modeling,drought,N2O,plant age dynamics,soil",Review,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Agriculture,Biotechnology & Applied Microbiology,Energy & Fuels",,5.672,"SOIL,ORGANIC-MATTER,NITROUS-OXIDE,EMISSIONS,MISCANTHUS,X,GIGANTEUS,GREENHOUSE-GAS,FLUX,N2O,EMISSIONS,USE,EFFICIENCY,LAND-SURFACE,CARBON,DAYCENT,TERRESTRIAL",GLOBAL CHANGE BIOLOGY BIOENERGY,https://www.osti.gov/biblio/1643707,
80,Deep Learning Algorithm for Brain-Computer Interface,2020,,,"Mansoor Asif,Usman Muhammad Waleed,Jamil Noreen,Naeem M. Asif","Mansoor A,Usman MW,Jamil N,Naeem MA",Jamil N,10.1155/2020/5762149,"Natl Univ Comp & Emerging Sci, Islamabad, Pakistan.","Electroencephalography-(EEG-) based control is a noninvasive technique which employs brain signals to control electrical devices/circuits. Currently, the brain-computer interface (BCI) systems provide two types of signals, raw signals and logic state signals. The latter signals are used to turn on/off the devices. In this paper, the capabilities of BCI systems are explored, and a survey is conducted how to extend and enhance the reliability and accuracy of the BCI systems. A structured overview was provided which consists of the data acquisition, feature extraction, and classification algorithm methods used by different researchers in the past few years. Some classification algorithms for EEG-based BCI systems are adaptive classifiers, tensor classifiers, transfer learning approach, and deep learning, as well as some miscellaneous techniques. Based on our assessment, we generally concluded that, through adaptive classifiers, accurate results are acquired as compared to the static classification techniques. Deep learning techniques were developed to achieve the desired objectives and their real-time implementation as compared to other algorithms.","MOTOR IMAGERY,CLASSIFICATION",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Computer Science,,1.269,"MOTOR,IMAGERY,CLASSIFICATION",SCIENTIFIC PROGRAMMING,https://downloads.hindawi.com/journals/sp/2020/5762149.pdf,
81,Shear Strength of Internal Reinforced Concrete Beam-Column Joints: Intelligent Modeling Approach and Sensitivity Analysis,2020,,,"Feng De-Cheng,Fu Bo","Feng DC,Fu B",Fu B,10.1155/2020/8850417,Chang'an University,"In this paper, an intelligent modeling approach is presented to predict the shear strength of the internal reinforced concrete (RC) beam-column joints and used to analyze the sensitivity of the influence factors on the shear strength. The proposed approach is established based on the famous boosting-family ensemble machine learning (ML) algorithms, i.e., gradient boosting regression tree (GBRT), which generates a strong predictive model by integrating several weak predictors, which are obtained by the well-known individual ML algorithms, e.g., DT, ANN, and SVM. The strong model is boosted as each weak predictor has its own weight in the final combination according to the performance. Compared with the conventional mechanical-driven shear strength models, e.g., the well-known modified compression field theory (MCFT), the proposed model can avoid the complicated derivation process of shear mechanism and calibration of the involved empirical parameters; thus, it provides a more convenient, fast, and robust alternative way for predicting the shear strength of the internal RC joints. To train and test the GBRT model, a total of 86 internal RC joint specimens are collected from the literatures, and four traditional ML models and the MCFT model are also employed as comparisons. The results indicate that the GBRT model is superior to both the traditional ML models and MCFT model, as its degree-of-fitting is the highest and the predicting dispersion is the lowest. Finally, the model is used to investigate the influences of different parameters on the shear strength of the internal RC joint, and the sensitivity and importance of the corresponding parameters are obtained.","PREDICTION,DESIGN",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Construction & Building Technology,Engineering",,1.923,"PREDICTION,DESIGN",ADVANCES IN CIVIL ENGINEERING,https://downloads.hindawi.com/journals/ace/2020/8850417.pdf,
82,A New Distributed Type-2 Fuzzy Logic Method for Efficient Data Science Models of Medical Informatics,2020,,,"Benchara Fatema Zahra,Youssfi Mohamed","Benchara FZ,Youssfi M",Benchara FZ,10.1155/2020/6539123,Hassan II University of Casablanca,"The paper aims to propose a distributed method for machine learning models and its application for medical data analysis. The great challenge in the medicine field is to provide a scalable image processing model, which integrates the computing processing requirements and computing-aided medical decision making. The proposed Fuzzy logic method is based on a distributed approach of type-2 Fuzzy logic algorithm and merges the HPC (High Performance Computing) and cognitive aspect on one model. Accordingly, the method is assigned to be implemented on big data analysis and data science prediction models for healthcare applications. The paper focuses on the proposed distributed Type-2 Fuzzy Logic (DT2FL) method and its application for MRI data analysis under a massively parallel and distributed virtual mobile agent architecture. Indeed, the paper presents some experimental results which highlight the accuracy and efficiency of the proposed method.","DECISION-MAKING,SYSTEM,SETS",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Computer Science,Mathematics",,,"DECISION-MAKING,SYSTEM,SETS",ADVANCES IN FUZZY SYSTEMS,https://downloads.hindawi.com/journals/afs/2020/6539123.pdf,
83,Toward Near-Perfect Diffractive Optical Elements via Nanoscale 3D Printing,14,8,10452-10461,"Wang Hao,Wang Hongtao,Zhang Wang,Yang Joel K. W.","Wang H,Wang HT,Zhang W,Yang JKW",Yang JKW,10.1021/acsnano.0c04313,Singapore University of Technology & Design,"Diffractive optical elements (DOEs) are widely applied as compact solutions to generate desired optical patterns in the far field by wavefront shaping. They consist of microscopic structures of varying heights to control the phase of either reflected or transmitted light. However, traditional methods to achieve varying thicknesses of structures for DOEs are tedious, requiring multiple aligned lithographic steps each followed by an etching process. Additionally, the reliance on photomasks precludes rapid prototyping and customization in manufacturing complex and multifunctional surface profiles. To achieve this, we turn to nanoscale 3D printing based on two-photon polymerization lithography (TPL). However, TPL systems lack the precision to pattern diffractive components where subwavelength variations in height and position could lead to observable loss in diffraction efficiency. Here, we employed a lumped TPL parametric model and a workaround patterning strategy to achieve precise 3D printing of DOEs using optimized parameters for laser power, beam scan speed, hatching distance, and slicing distance. In our case study, millimeter scale near-perfect Dammann gratings were fabricated with measured diffraction efficiencies near theoretical limits, laser spot array nonuniformity as low as 1.4%, and power ratio of the zero-order spot as low as 0.4%. Leveraging on the advantages of additive manufacturing inherent to TPL, the 3D-printed optical devices can be applied for precise wavefront shaping, with great potential in all-optical machine learning, virtual reality, motion sensing, and medical imaging.","diffractive optical elements,Dammann gratings,3D printing,two-photon polymerization lithography,parametric model,zero-order spot",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,16.207,"NANOSCRIBE,IP-DIP,2-PHOTON,POLYMERIZATION,MECHANICAL-PROPERTIES,DAMMANN,GRATINGS,REFRACTIVE-INDEX,LASER,DESIGN,FABRICATION,SHRINKAGE,POLYMERS",ACS NANO,,
84,Long-Lived Hot Electron in a Metallic Particle for Plasmonics and Catalysis: Ab Initio Nonadiabatic Molecular Dynamics with Machine Learning,14,8,10608-10615,"Chu Weibin,Saidi Wissam A.,Prezhdo Oleg V","Chu WB,Saidi WA,Prezhdo OV",Prezhdo OV,10.1021/acsnano.0c04736,University of Southern California,"Multiple experiments provide evidence for photovoltaic, catalytic, optoelectronic, and plasmonic processes involving hot, i.e., high energy, electrons in nanoscale materials. However, the mechanisms of such processes remain elusive, because electrons rapidly lose energy by relaxation through dense manifolds of states. We demonstrate a long-lived hot electron state in a Pt nanocluster adsorbed on the MoS2 substrate. For this purpose, we develop a simulation technique, combining classical molecular dynamics based on machine learning potentials with ab initio nonadiabatic molecular dynamics and real-time time-dependent density functional theory. Choosing Pt-20/MoS2 as a prototypical system, we find frequent shifting of a top atom in the Pt particle occurring on a 50 ps time scale. The distortion breaks particle symmetry and creates unsaturated chemical bonds. The lifetime of the localized state associated with the broken bonds is enhanced by a factor of 3. Hot electrons aggregate near the shifted atom and form a catalytic reaction center. Our findings prove that distortion of even a single atom can have important implications for nanoscale catalysis and plasmonics and provide insights for utilizing machine learning potentials to accelerate ab initio investigations of excited state dynamics in condensed matter systems.","nanoparticle,electron trapping,machine learning,excited state dynamics,time-dependent density functional theory",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,16.207,"POTENTIAL-ENERGY,SURFACES,CARRIER,DYNAMICS,PYXAID,PROGRAM,GOLD,RECOMBINATION,NANOPARTICLES,MECHANISMS,TRANSITION,GENERATION,DRIVEN",ACS NANO,,
85,Identification of significant risks in pediatric acute lymphoblastic leukemia (ALL) through machine learning (ML) approach,58,11,2631-2640,"Mahmood Nasir,Shahid Saman,Bakhshi Taimur,Riaz Sehar,Ghufran Hafiz,Yaqoob Muhammad","Mahmood N,Shahid S,Bakhshi T,Riaz S,Ghufran H,Yaqoob M",Mahmood N,10.1007/s11517-020-02245-2,"Univ Hlth Sci UHS, Dept Biochem Human Genet & Mol Biol, Lahore, Pakistan.","Pediatric acute lymphoblastic leukemia (ALL) through machine learning (ML) technique was analyzed to determine the significance of clinical and phenotypic variables as well as environmental conditions that can identify the underlying causes of child ALL. Fifty pediatric patients (n = 50) included who were diagnosed with acute lymphoblastic leukemia (ALL) according to the inclusion and exclusion criteria. Clinical variables comprised of the blood biochemistry (CBC, LFTs, RFTs) results, and distribution of type of ALL, i.e., T ALL or B ALL. Phenotypic data included the age, sex of the child, and consanguinity, while environmental factors included the habitat, socioeconomic status, and access to filtered drinking water. Fifteen different features/attributes were collected for each case individually. To retrieve most useful discriminating attributes, four different supervised ML algorithms were used including classification and regression trees (CART), random forest (RM), gradient boosted machine (GM), and C5.0 decision tree algorithm. To determine the accuracy of the derived CART algorithm on future data, a ten-fold cross validation was performed on the present data set. The ALL was common in children of age below 5 years in male patients whole belonged to middle class family of rural areas. (B-ALL) was most frequent as compared with T-ALL. The consanguinity was present in 54% of cases. Low levels of platelets and hemoglobin and high levels of white blood cells were reported in child ALL patients. CART provided the best and complete fit for the entire data set yielding a 99.83% model fit accuracy, and a misclassification of 0.17% on the entire sample space, while C5.0 reported 98.6%, random forest 94.44%, and gradient boosted machine resulted in 95.61% fitting. The variable importance of each primary discriminating attribute is platelet 43%, hemoglobin 24%, white blood cells 4%, and sex of the child 4%. An overall accuracy of 87.4% was recorded for the classifier. Platelet count abnormality can be considered as a major factor in predicting pediatric ALL. The machine learning algorithms can be applied efficiently to provide details for the prognosis for better treatment outcome.
Graphical Identification of significant risks in pediatric acute lymphoblastic leukemia (ALL) through machine learning (ML) approach.","Pediatric ALL,Classification and regression trees (CART),Platelets,Hemoglobin,Environmental factors",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"CHILDHOOD,LEUKEMIA,GENETIC,POLYMORPHISMS,DRINKING-WATER,CHROMOSOMAL-ABNORMALITIES,THROMBOTIC,COMPLICATIONS,SOCIOECONOMIC-STATUS,CHILDREN,SUSCEPTIBILITY,POPULATION,MUTATIONS",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
86,Cascade marker removal algorithm for thyroid ultrasound images,58,11,2641-2656,"Ying Xiang,Zhang Yulin,Yu Mei,Wei Xi,Zhu Jialin,Gao Jie,Liu Zhiqiang,Shen Hongqian,Zhang Ruixuan,Li Xuewei","Ying X,Zhang YL,Yu M,Wei X,Zhu JL,Gao J,Liu ZQ,Shen HQ,Zhang RX,Li XW",Li XW; Yu RG,10.1007/s11517-020-02216-7,Tianjin University,"During thyroid ultrasound diagnosis, radiologists add markers such as pluses or crosses near a nodule's edge to indicate the location of a nodule. For computer-aided detection, deep learning models achieve classification, segmentation, and detection by learning the thyroid's texture in ultrasound images. Experiments show that manual markers are strong prior knowledge for data-driven deep learning models, which interferes with the judgment mechanism of computer-aided detection systems. Aiming at this problem, this paper proposes cascade marker removal algorithm for thyroid ultrasound images to eliminate the interference of manual markers. The algorithm consists of three parts. First, in order to highlight marked features, the algorithm extracts salient features in thyroid ultrasound images through feature extraction module. Secondly, mask correction module eliminates the interference of other features besides markers' features. Finally, the marker removal module removes markers without destroying the semantic information in thyroid ultrasound images. Experiments show that our algorithm enables classification, segmentation, and object detection models to focus on the learning of pathological tissue features. At the same time, compared with mainstream image inpainting algorithms, our algorithm shows better performance on thyroid ultrasound images. In summary, our algorithm is of great significance for improving the stability and performance of computer-aided detection systems.","Diagnosis,Computer-assisted,Diagnostic imaging,Thyroid neoplasms,Deep learning,Ultrasonography",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"WHITE,PAPER",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
87,Continual Learning of Multiple Memories in Mechanical Networks,10,3,,"Stern Menachem,Pinson Matthew B.,Murugan Arvind","Stern M,Pinson MB,Murugan A",Murugan A,10.1103/PhysRevX.10.031044,University of Chicago,"Most materials are changed by their history and show memory of things past. However, it is not clear when a system can continually learn new memories in sequence, without interfering with or entirely overwriting earlier memories. Here, we study the learning of multiple stable states in sequence by an elastic material that undergoes plastic changes as it is held in different configurations. We show that an elastic network with linear or nearly linear springs cannot learn continually without overwriting earlier states for a broad class of plasticity rules. On the other hand, networks of sufficiently nonlinear springs can learn continually, without erasing older states, using even simple plasticity rules. We trace this ability to cusped energy contours caused by strong nonlinearities and thus show that elastic nonlinearities play the role of Bayesian priors used in sparse statistical regression. Our model shows how specific material properties allow continual learning of new functions through deployment of the material itself.","DNA NANOTUBES,SYSTEMS,TRANSITION,SELECTION",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Physics,,,"DNA,NANOTUBES,SYSTEMS,TRANSITION,SELECTION",PHYSICAL REVIEW X,http://link.aps.org/pdf/10.1103/PhysRevX.10.031044,
88,A High Throughput and Unbiased Machine Learning Approach for Classification of Graphene Dispersions,7,20,,"Abedin Md Joynul,Barua Titon,Shaibani Mahdokht,Majumder Mainak","Abedin MJ,Barua T,Shaibani M,Majumder M",Majumder M,10.1002/advs.202001600,Monash University,"Significant research to define and standardize terminologies for describing stacks of atomic layers in bulk graphene materials has been undertaken. Most methods to measure the stacking characteristics are time consuming and are not suited for obtaining information by directly imaging dispersions. Conventional optical microscopy has difficulty in identifying the size and thickness of a few layers of graphene stacks due to their low photon absorption capacity. Utilizing a contrast based on anisotropic refractive index in 2D materials, it is shown that localized thickness-specific information can be captured in birefringence images of graphene dispersions. Coupling pixel-by-pixel information from brightfield and birefringence images and using unsupervised statistical learning algorithms, three unique data clusters representing flakes (unexfoliated), nanoplatelets (partially exfoliated), and 2D sheets (well-exfoliated) species in various laboratory-based and commercial dispersions of graphene and graphene oxide are identified. The high-throughput, multitasking capability of the approach to classify stacking at sub-nanometer to micrometer scale and measure the size, thickness, and concentration of exfoliated-species in generic dispersions of graphene/graphene oxide are demonstrated. The method, at its current stage, requires less than half an hour to quantitatively assess one sample of graphene/graphene oxide dispersion.","graphene oxide quality control,fake graphene detection,graphene quantification,machine learning,quantitative polarized light microscopy",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Chemistry,Science & Technology - Other Topics,Materials Science",,17.835,EXFOLIATION,ADVANCED SCIENCE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7578897,
89,A learning-based method for online adjustment of C-arm Cone-beam CT source trajectories for artifact avoidance,15,11,1787-1796,"Thies Mareike,Zaech Jan-Nico,Gao Cong,Taylor Russell,Navab Nassir,Maier Andreas,Unberath Mathias","Thies M,Zach JN,Gao C,Taylor R,Navab N,Maier A,Unberath M",Unberath M,10.1007/s11548-020-02249-1,Johns Hopkins University,"Purpose During spinal fusion surgery, screws are placed close to critical nerves suggesting the need for highly accurate screw placement. Verifying screw placement on high-quality tomographic imaging is essential. C-arm cone-beam CT (CBCT) provides intraoperative 3D tomographic imaging which would allow for immediate verification and, if needed, revision. However, the reconstruction quality attainable with commercial CBCT devices is insufficient, predominantly due to severe metal artifacts in the presence of pedicle screws. These artifacts arise from a mismatch between the true physics of image formation and an idealized model thereof assumed during reconstruction. Prospectively acquiring views onto anatomy that are least affected by this mismatch can, therefore, improve reconstruction quality. Methods We propose to adjust the C-arm CBCT source trajectory during the scan to optimize reconstruction quality with respect to a certain task, i.e., verification of screw placement. Adjustments are performed on-the-fly using a convolutional neural network that regresses a quality index over all possible next views given the current X-ray image. Adjusting the CBCT trajectory to acquire the recommended views results in non-circular source orbits that avoid poor images, and thus, data inconsistencies. Results We demonstrate that convolutional neural networks trained on realistically simulated data are capable of predicting quality metrics that enable scene-specific adjustments of the CBCT source trajectory. Using both realistically simulated data as well as real CBCT acquisitions of a semianthropomorphic phantom, we show that tomographic reconstructions of the resulting scene-specific CBCT acquisitions exhibit improved image quality particularly in terms of metal artifacts. Conclusion The proposed method is a step toward online patient-specific C-arm CBCT source trajectories that enable high-quality tomographic imaging in the operating room. Since the optimization objective is implicitly encoded in a neural network trained on large amounts of well-annotated projection images, the proposed approach overcomes the need for 3D information at run-time.","Tomographic reconstruction,Metal artifact reduction,Deep learning,Image-guided surgery",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,,"COMPUTED-TOMOGRAPHY,SCREW,PLACEMENT,FLUOROSCOPY,ACCURACY,FUSION",INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,https://link.springer.com/content/pdf/10.1007/s11548-020-02249-1.pdf,
90,Deep Neural Networks for Multicomponent Molecular Systems,5,33,21042-21053,Hanaoka Kyohei,Hanaoka K,Hanaoka K,10.1021/acsomega.0c02599,Hitachi Limited,"Deep neural networks (DNNs) represent promising approaches to molecular machine learning (ML). However, their applicability remains limited to single-component materials and a general DNN model capable of handling various multicomponent molecular systems with composition data is still elusive, while current ML approaches for multicomponent molecular systems are still molecular descriptor-based. Here, a general DNN architecture extending existing molecular DNN models to multicomponent systems called MEIA is proposed. Case studies showed that the MEIA architecture could extend two exiting molecular DNN models to multicomponent systems with the same procedure, and that the obtained models that could learn both the molecular structure and composition information with equal or better accuracies compared to a well-used molecular descriptor-based model in the best model for each case study. Furthermore, the case studies also showed that, for ML tasks where the molecular structure information plays a minor role, the performance improvements by DNN models were small; while for ML tasks where the molecular structure information plays a major role, the performance improvements by DNN models were large, and DNN models showed notable predictive accuracies for an extremely sparse dataset, which cannot be modeled without the molecular structure information. The enhanced predictive ability of DNN models for sparse datasets of multicomponent systems will extend the applicability of ML in the multicomponent material design. Furthermore, the general capability of MEIA to extend DNN models to multicomponent systems will provide new opportunities to utilize the progress of actively developed single-component DNNs for the modeling of multicomponent systems.","FLASH POINTS,BINARY-MIXTURES,BOILING POINTS,QSPR APPROACH,PREDICTION,TEMPERATURES,DESCRIPTORS,COPOLYMERS,DISCOVERY,BENCHMARK",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,,"FLASH,POINTS,BINARY-MIXTURES,BOILING,POINTS,QSPR,APPROACH,PREDICTION,TEMPERATURES,DESCRIPTORS,COPOLYMERS,DISCOVERY,BENCHMARK",ACS OMEGA,https://pubs.acs.org/doi/pdf/10.1021/acsomega.0c02599,
91,Computer-Aided System for the Detection of Multicategory Pulmonary Tuberculosis in Radiographs,2020,,,"Xie Yilin,Wu Zhuoyue,Han Xin,Wang Hongyu,Wu Yifan,Cui Lei,Feng Jun,Zhu Zhaohui,Chen Zhongyuanlong","Xie YL,Wu ZY,Han X,Wang HY,Wu YF,Cui L,Feng J,Zhu ZH,Chen ZYL",Feng J,10.1155/2020/9205082,Northwest University Xi'an,"The early screening and diagnosis of tuberculosis plays an important role in the control and treatment of tuberculosis infections. In this paper, an integrated computer-aided system based on deep learning is proposed for the detection of multiple categories of tuberculosis lesions in chest radiographs. In this system, the fully convolutional neural network method is used to segment the lung area from the entire chest radiograph for pulmonary tuberculosis detection. Different from the previous analysis of the whole chest radiograph, we focus on the specific tuberculosis lesion areas for the analysis and propose the first multicategory tuberculosis lesion detection method. In it, a learning scalable pyramid structure is introduced into the Faster Region-based Convolutional Network (Faster RCNN), which effectively improves the detection of small-area lesions, mines indistinguishable samples during the training process, and uses reinforcement learning to reduce the detection of false-positive lesions. To compare our method with the current tuberculosis detection system, we propose a classification rule for whole chest X-rays using a multicategory tuberculosis lesion detection model and achieve good performance on two public datasets (Montgomery: AUC = 0.977 and accuracy = 0.926; Shenzhen: AUC = 0.941 and accuracy = 0.902). Our proposed computer-aided system is superior to current systems that can be used to assist radiologists in diagnoses and public health providers in screening for tuberculosis in areas where tuberculosis is endemic.","AUTOMATIC DETECTION,LUNG SEGMENTATION,CHEST",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Health Care Sciences & Services,,3.188,"AUTOMATIC,DETECTION,LUNG,SEGMENTATION,CHEST",JOURNAL OF HEALTHCARE ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7463336,
92,Convolutional Sparse Coded Dynamic Brain Functional Connectivity,52,3,1881-1892,"Yan Jin,Zhu Yingying","Yan J,Zhu YY",Zhu YY,10.1007/s11063-020-10295-8,University of Texas System,"Functional brain network has been widely studied in many previous work for brain disorder diagnosis and brain network analysis. However, most previous work focus on static dynamic brain network research. Lots of recent work reveals that the brain shows dynamic activity even in resting state. Such dynamic brain functional connectivity reveals discriminative patterns for identifying many brain disorders. Current sliding window based dynamic brain connectivity framework are not easy to be applied to real clinical applications due to many issues: First, how to set up the optimal sliding window size and how to determine the threshold for the brain connectivity patterns. Secondly, how to represent the high dimensional dynamic brain connectivity pattern in a low dimensional representations for diagnosis purpose. Last, how to deal with the different length dynamic brain network patterns especially when the raw data are of different length. In order to address all those above issues, we proposed a new framework, which employs multiple scale sliding windows and automatically learns a sparse and low ran dynamic brain functional connectivity patterns from raw fMRI data. Furthermore, we are able to measure different length dynamic brain functional connectivity patterns in an equal space by learning a sparse coded convolutional filters. We have evaluated our method with state of the art dynamic brain network methods and the results demonstrated the strong potential of our methods for brain disorder diagnosis in real clinical applications.","Functional magnetic resonance images,Convolutional sparse coding,Dynamic brain network,Computer assisted diagnosis",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,2.884,FMRI,NEURAL PROCESSING LETTERS,https://www.biorxiv.org/content/biorxiv/early/2018/11/27/476663.full.pdf,
93,Reducing the Collision Damage Done to the Tips of Steel Needles during Integrated Piercing by Using Shape Optimization with Feature Selection,2020,,,"Yang Jingzhao,Dong Jiuzhi,Jiang Xiuming,Chen Yunjun","Yang JZ,Dong JZ,Jiang XM,Chen YJ",Yang JZ,10.1155/2020/5078590,Tiangong University,"Recent research has shown that, during integrated piercing, the yarn tension can displace the needles from the centers of the holes in the piercing template. To reduce the damage done to the needle tips when the needles and the hole walls collide when the needle displacement is too large, this paper proposes a method for optimizing the needle shape that satisfies the strength constraint while targeting minimum needle displacement. First, the optimal objective function and strength constraint conditions for the tip displacement of the integrated puncture needle are established, which are affected by many factors. Then, the feature selection method of machine learning is used to reduce the dimensionality of the objective function after data reduction, and the feasible region of key features is reduced to avoid falling into the local best point in the optimization iteration. Finally, machine vision is used to measure experimentally the tip displacement of a needle array. The results show that the average tip displacement is reduced by 18.16-31.42% and the collision risk is reduced from 43.14% to 5.54%. It shows that the optimization method of needle shape based on feature selection is effective for reducing needle tip impact damage during integrated piercing.",DESIGN,Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Engineering,Mathematics",,1.27,DESIGN,MATHEMATICAL PROBLEMS IN ENGINEERING,https://downloads.hindawi.com/journals/mpe/2020/5078590.pdf,
94,Rock classification in petrographic thin section images based on concatenated convolutional neural networks,13,4,1477-1484,"Su Cheng,Xu Sheng-jia,Zhu Kong-yang,Zhang Xiao-can","Su C,Xu SJ,Zhu KY,Zhang XC",Su C,10.1007/s12145-020-00505-1,Zhejiang University,"Rock classification plays an important role in rock mechanics, petrology, mining engineering, magmatic processes, and numerous other fields pertaining to geosciences. This study proposes a concatenated convolutional neural network (Con-CNN) method for classifying geologic rock types based on petrographic thin sections. Plane polarized light (PPL) and crossed polarized light (XPL) were used to acquire thin section images as the fundamental data. After conducting the necessary pre-processing, the PPL and XPL images as well as their comprehensive image developed by principal component analysis were sliced into small patches and were put into three CNNs, comprising the same structure for achieving a preliminary classification. Subsequently, these patches classification results of the CNNs were concatenated by using the maximum likelihood method to obtain a comprehensive classification result. Finally, a statistical revision was applied to fix the misclassification due to the proportion differences of minerals that were similar in appearance. In this study, there were 92 rock samples of 13 types giving 106 petrographic thin sections and 2208 petrographic thin section images, and finally 238,464 sliced image patches were used for the training and validation of the Con-CNN method. The 5-folds cross validation showed that the proposed method provides an overall accuracy of 89.97% and a kappa coefficient of 0.86, which facilitates the automation of rock classification in petrographic thin section images.","Rock,Thin section,Classification,Convolutional neural network",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Geology",,2.543,"AUTOMATIC,IDENTIFICATION,MINERAL,IDENTIFICATION,PATTERN-RECOGNITION,TOUCHING,GRAINS,PERMEABILITY,SEGMENTATION,SEPARATION",EARTH SCIENCE INFORMATICS,http://arxiv.org/pdf/2003.10437,
95,Upper Limb Movement Classification Via Electromyographic Signals and an Enhanced Probabilistic Network,44,10,,"Burns Alexis,Adeli Hojjat,Buford John A.","Burns A,Adeli H,Buford JA",Adeli H,10.1007/s10916-020-01639-x,Ohio State University,"Few studies in the literature have researched the use of surface electromyography (sEMG) for motor assessment post-stroke due to the complexity of this type of signal. However, recent advances in signal processing and machine learning have provided fresh opportunities for analyzing complex, non-linear, non-stationary signals, such as sEMG. This paper presents a method for identification of the upper limb movements from sEMG signals using a combination of digital signal processing, that is discrete wavelet transform, and the enhanced probabilistic neural network (EPNN). To explore the potential of sEMG signals for monitoring motor rehabilitation progress, this study used sEMG signals from a subset of movements of the Arm Motor Ability Test (AMAT) as inputs into a movement classification algorithm. The importance of a particular frequency domain feature, that is the ratio of the mean absolute values between sub-bands, was discovered in this work. An average classification accuracy of 75.5% was achieved using the proposed approach with a maximum accuracy of 100%. The performance of the proposed method was compared with results obtained using three other classification algorithms: support vector machine (SVM), k-Nearest Neighbors (k-NN), and probabilistic neural network (PNN) in terms of sEMG movement classification. The study demonstrated the capability of using upper limb sEMG signals to identify and distinguish between functional movements used in standard upper limb motor assessments for stroke patients. The classification algorithm used in the proposed method, EPNN, outperformed SVM, k-NN, and PNN.","Upper Limb Movement Classification,EMG,Electromyographic Signals,Enhanced Probablistic Neural Network,Surface EMG,Semg,Machine learning,Wavelet transform,Motor rehabilitation",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Health Care Sciences & Services,Medical Informatics",,3.951,"SUPPORT,VECTOR,MACHINE,NEURAL-NETWORK,STROKE,SURVIVORS,EMG,RECOGNITION,REHABILITATION,PREDICTION,DIAGNOSIS,MOBILITY,THERAPY",JOURNAL OF MEDICAL SYSTEMS,,
96,Warpage Deformation Prediction of Injection Products with Combinatorial Algorithm,54,8,84-90,",,,,","Wang Bo,Cai Anjiang,Meng Guanghui,Li Feng,Zhao Dongping",,,Wang Bo,"To improve the predictive ability of warpage deformation of injection products,a new combination algorithm was proposed taking a notebook battery cover as the example.Simulation experiments were performed nine times on the battery cover using injection molding simulation software to obtain the warpage amount under the recommended engineering process parameters.The sample data,BP neural network,grey theory and genetic algorithm were effectively combined by the optimal weight coefficient to construct three combined forecasting models,together with three single prediction models to predict the warpage amount of the battery cover.Then based on the three kinds of prediction error evaluation indexes,the prediction results of six models were compared and analyzed according to the square sum error,average absolute error and average relative error.Finally,the accuracy of the combinatorial algorithm was verified by the battery cover manufacturing.The results show that the accuracy of the combined prediction model is better than that of single prediction model.The prediction result of the combined arithmetic average model gets the closest to the actual measuring value,and the maximum error is not more than 5%.The proposed combination prediction method can accurately predict the warpage amount of plastic parts.",combination algorithm; warpage deformation; injection molding,Article,,,,,,,,
97,Food Supply Chains as Cyber-Physical Systems: a Path for More Sustainable Personalized Nutrition,13,1,92-103,"Smetana Sergiy,Aganovic Kemal,Heinz Volker","Smetana S,Aganovic K,Heinz V",Smetana S,10.1007/s12393-020-09243-y,"German Inst Food Technol DIL eV, Quakenbruck, Germany.","Current food system evolved in a great degree because of the development of processing and food engineering technologies: people learned to bake bread long before the advent of agriculture; salting and smoking supported nomad lifestyles; canning allowed for longer military marches; etc. Food processing technologies went through evolution and significant optimization and currently rely on minor fraction of energy comparing with initial prototypes. Emerging processing technologies (high-pressure, pulsed electric fields, ohmic heating, ultrasound) and novel food systems (cultured biomass, 3-D bioprinting, cyber-physical chains) try to challenge the existing chains by developing potentially more nutritious and sustainable food solutions. However, new food systems rely on low technology readiness levels and estimation of their potential future benefits or drawbacks is a complex task mostly due to the lack of integrated data. The research is aimed for the development of conceptual guidelines of food production system structuring as cyber-physical systems. The study indicates that cyber-physical nature of modern food is a key for the engineering of more nutritious and sustainable paths for novel food systems. Implementation of machine learning methods for the collection, integration, and analysis of data associated with biomass production and processing on different levels from molecular to global, leads to the precise analysis of food systems and estimation of upscaling benefits, as well as possible negative rebound effects associated with societal attitude. Moreover, such data-integrated assessment systems allow transparency of chains, integration of nutritional and environmental properties, and construction of personalized nutrition technologies.","Cyber-physical systems,Food chains,Food systems,Traceability,Sustainability",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Food Science & Technology,,6.813,"INDUSTRY,4.0,BIG,DATA,DIGITAL,TWIN,GENETIC,ALGORITHM,NEURAL-NETWORK,DATA,SCIENCE,INTERNET,OPTIMIZATION,BLOCKCHAIN,CHALLENGES",FOOD ENGINEERING REVIEWS,https://link.springer.com/content/pdf/10.1007/s12393-020-09243-y.pdf,
98,,,,,,,,,,,,,,,,,,,,
99,Deep transfer learning-based automated detection of COVID-19 from lung CT scan slices,51,1,571-585,"Ahuja Sakshi,Panigrahi Bijaya Ketan,Dey Nilanjan,Rajinikanth Venkatesan,Gandhi Tapan Kumar","Ahuja S,Panigrahi BK,Dey N,Rajinikanth V,Gandhi TK",Ahuja S,10.1007/s10489-020-01826-w,Indian Institute of Technology System (IIT System),"Lung abnormality is one of the common diseases in humans of all age group and this disease may arise due to various reasons. Recently, the lung infection due to SARS-CoV-2 has affected a larger human community globally, and due to its rapidity, the World-Health-Organisation (WHO) declared it as pandemic disease. The COVID-19 disease has adverse effects on the respiratory system, and the infection severity can be detected using a chosen imaging modality. In the proposed research work; the COVID-19 is detected using transfer learning from CT scan images decomposed to three-level using stationary wavelet. A three-phase detection model is proposed to improve the detection accuracy and the procedures are as follows; Phase1- data augmentation using stationary wavelets, Phase2- COVID-19 detection using pre-trained CNN model and Phase3- abnormality localization in CT scan images. This work has considered the well known pre-trained architectures, such as ResNet18, ResNet50, ResNet101, and SqueezeNet for the experimental evaluation. In this work, 70% of images are considered to train the network and 30% images are considered to validate the network. The performance of the considered architectures is evaluated by computing the common performance measures. The result of the experimental evaluation confirms that the ResNet18 pre-trained transfer learning-based model offered better classification accuracy (training = 99.82%, validation = 97.32%, and testing = 99.4%) on the considered image dataset compared with the alternatives.","COVID-19,Transfer learning,Wavelets,CT scan,ResNet18",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,4.602,,APPLIED INTELLIGENCE,https://link.springer.com/content/pdf/10.1007/s10489-020-01826-w.pdf,
100,Multi-fidelity machine-learning with uncertainty quantification and Bayesian optimization for materials design: Application to ternary random alloys,153,7,,"Tran Anh,Tranchida Julien,Wildey Tim,Thompson Aidan P.","Tran A,Tranchida J,Wildey T,Thompson AP",Tran A,10.1063/5.0015672,United States Department of Energy (DOE),"We present a scale-bridging approach based on a multi-fidelity (MF) machine-learning (ML) framework leveraging Gaussian processes (GP) to fuse atomistic computational model predictions across multiple levels of fidelity. Through the posterior variance of the MFGP, our framework naturally enables uncertainty quantification, providing estimates of confidence in the predictions. We used density functional theory as high-fidelity prediction, while a ML interatomic potential is used as low-fidelity prediction. Practical materials' design efficiency is demonstrated by reproducing the ternary composition dependence of a quantity of interest (bulk modulus) across the full aluminum-niobium-titanium ternary random alloy composition space. The MFGP is then coupled to a Bayesian optimization procedure, and the computational efficiency of this approach is demonstrated by performing an on-the-fly search for the global optimum of bulk modulus in the ternary composition space. The framework presented in this manuscript is the first application of MFGP to atomistic materials simulations fusing predictions between density functional theory and classical interatomic potential calculations.",,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Chemistry,Physics",,3.166,,JOURNAL OF CHEMICAL PHYSICS,http://arxiv.org/pdf/2006.00139,
