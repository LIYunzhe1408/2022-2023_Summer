,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Targeted transfer learning to improve performance in small medical physics datasets,47,12,6246-6256,"Romero Miguel,Interian Yannet,Solberg Timothy,Valdes Gilmer","Romero M,Interian Y,Solberg T,Valdes G",Interian Y,10.1002/mp.14507,University of San Francisco,"Purpose To perform an in-depth evaluation of current state of the art techniques in training neural networks to identify appropriate approaches in small datasets.
Method In total, 112,120 frontal-view X-ray images from the NIH ChestXray14 dataset were used in our analysis. Two tasks were studied: unbalanced multi-label classification of 14 diseases, and binary classification of pneumonia vs non-pneumonia. All datasets were randomly split into training, validation, and testing (70%, 10%, and 20%). Two popular convolution neural networks (CNNs), DensNet121 and ResNet50, were trained using PyTorch. We performed several experiments to test: (a) whether transfer learning using pretrained networks on ImageNet are of value to medical imaging/physics tasks (e.g., predicting toxicity from radiographic images after training on images from the internet), (b) whether using pretrained networks trained on problems that are similar to the target task helps transfer learning (e.g., using X-ray pretrained networks for X-ray target tasks), (c) whether freeze deep layers or change all weights provides an optimal transfer learning strategy, (d) the best strategy for the learning rate policy, and (e) what quantity of data is needed in order to appropriately deploy these various strategies (N = 50 to N = 77 880).
Results In the multi-label problem, DensNet121 needed at least 1600 patients to be comparable to, and 10 000 to outperform, radiomics-based logistic regression. In classifying pneumonia vs non-pneumonia, both CNN and radiomics-based methods performed poorly when N < 2000. For small datasets ( < 2000), however, a significant boost in performance (>15% increase on AUC) comes from a good selection of the transfer learning dataset, dropout, cycling learning rate, and freezing and unfreezing of deep layers as training progresses. In contrast, if sufficient data are available (>35 000), little or no tweaking is needed to obtain impressive performance. While transfer learning using X-ray images from other anatomical sites improves performance, we also observed a similar boost by using pretrained networks from ImageNet. Having source images from the same anatomical site, however, outperforms every other methodology, by up to 15%. In this case, DL models can be trained with as little as N = 50.
Conclusions While training DL models in small datasets (N < 2000) is challenging, no tweaking is necessary for bigger datasets (N > 35 000). Using transfer learning with images from the same anatomical site can yield remarkable performance in new tasks with as few as N = 50. Surprisingly, we did not find any advantage for using images from other anatomical sites over networks that have been trained using ImageNet. This indicates that features learned may not be as general as currently believed, and performance decays rapidly even by just changing the anatomical site of the images.","deep learning,machine learning,small datasets",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"RADIATION,PNEUMONITIS,MACHINE,RADIOTHERAPY,PREDICTION",MEDICAL PHYSICS,http://arxiv.org/pdf/1912.06761,
2,Ultrasound video analysis for skill level assessment in FAST ultrasound,9,3,308-312,"Tyrrell Robert E.,Holden Matthew S.","Tyrrell RE,Holden MS",Holden MS,10.1080/21681163.2020.1835549,Carleton University,"FAST ultrasound is a medical procedure to assess for free fluid following physical trauma. FAST images can often be difficult to interpret and requires operators to be properly trained. Traditionally, skill is assessed by direct observation from experts, which is expensive and error prone. This project aims to use deep learning to provide automated skills assessment for FAST exams. Modified I3D networks, a type of modern neural network with a focus on action-based items, were retrained for this purpose. First, a network to identify the skill level of the users from all the ultrasound videos was trained using FAST videos of each vital region divided by novice, intermediate and expert users. Following this, 4 networks corresponding to skill level identification in each region were trained using the previously constructed model. The model's performance was evaluated using k-fold cross-validation. Results found a testing accuracy of 82.6% for skills assessment using the modified I3D networks. These results are an improvement over the previous results for skill level evaluation, implying potential use of an I3D network for evaluating skill level from ultrasound video in the future with the proper finetuning.","Diagnostic ultrasound,skills assessment,deep learning",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,,,COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION,,
3,Multiple sclerosis identification in brain MRI images using wavelet convolutional neural networks,31,2,778-785,"Alijamaat Ali,NikravanShalmani Alireza,Bayat Peyman","Alijamaat A,NikravanShalmani A,Bayat P",NikravanShalmani A,10.1002/ima.22492,Islamic Azad University,"Multiple sclerosis (MS) is a degenerative disease of the covering around the nerves in the central nervous system. It damages the immune cells and causes small lesions in the patient's brain. Automated image recognition techniques can be employed for increasing the accuracy of detection. The use of convolutional neural networks (CNN) is the most common deep learning method for detecting lesions in image. Due to the specific features of MS lesions, the use of spectral features especially multiresolution enables the highlighting of images lesions and leads to a more accurate diagnosis. In the present study, the Haar wavelet transform was applied to make use of the spectral information. The proposed method is a combination of the two-dimensional discrete Haar wavelet transform and the CNN network. Experiments on the image data of 38 patients and 20 healthy individuals revealed accuracy, precision, and sensitivity of 99.05%, 98.43%, and 99.14%, respectively.","CNN,deep learning,magnetic resonance imaging,multiple sclerosis,wavelet",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,"SEGMENTATION,DIAGNOSIS,LESIONS",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
4,Automatic intraprostatic lesion segmentation in multiparametric magnetic resonance images with proposed multiple branch UNet,47,12,6421-6429,"Chen Yizheng,Xing Lei,Yu Lequan,Bagshaw Hilary P.,Buyyounouski Mark K.,Han Bin","Chen YZ,Xing L,Yu LQ,Bagshaw HP,Buyyounouski MK,Han B",Han B,10.1002/mp.14517,Stanford University,"Purpose Contouring intraprostatic lesions is a prerequisite for dose-escalating these lesions in radiotherapy to improve the local cancer control. In this study, a deep learning-based approach was developed for automatic intraprostatic lesion segmentation in multiparametric magnetic resonance imaging (mpMRI) images contributing to clinical practice.
Methods Multiparametric magnetic resonance imaging images from 136 patient cases were collected from our institution, and all these cases contained suspicious lesions with Prostate Imaging Reporting and Data System (PI-RADS) score >= 4. The contours of the lesion and prostate were manually created on axial T2-weighted (T2W), apparent diffusion coefficient (ADC) and high b-value diffusion-weighted imaging (DWI) images to provide the ground truth data. Then a multiple branch UNet (MB-UNet) was proposed for the segmentation of an indistinct target in multi-modality MRI images. An encoder module was designed with three branches for the three MRI modalities separately, to fully extract the high-level features provided by different MRI modalities; an input module was added by using three sub-branches for three consecutive image slices, to consider the contour consistency among different image slices; deep supervision strategy was also integrated into the network to speed up the convergency of the network and improve the performance. The probability maps of the background, normal prostate and lesion were output by the network to generate the segmentation of the lesion, and the performance was evaluated using the dice similarity coefficient (DSC) as the main metric.
Results A total of 162 lesions were contoured on 652 image slices, with 119 lesions in the peripheral zone, 38 in the transition zone, four in the central zone and one in the anterior fibromuscular stroma. All prostates were also contoured on 1,264 image slices. As for the segmentation of lesions in the testing set, MB-UNet achieved a per case DSC of 0.6333, specificity of 0.9993, sensitivity of 0.7056; and global DSC of 0.7205, specificity of 0.9993, sensitivity of 0.7409. All the three deep learning strategies adopted in this study contributed to the performance promotion of the MB-UNet. Missing the DWI modality would degrade the segmentation performance more markedly compared with the other two modalities.
Conclusions A deep learning-based approach with proposed MB-UNet was developed to automatically segment suspicious lesions in mpMRI images. This study makes it feasible to adopt boosting intraprostatic lesions in clinical practice to achieve better outcomes.","boosting radiotherapy,deep learning,intraprostatic lesion segmentation,multiparametric magnetic resonance imaging,multiple branch UNet (MB&#8208,UNet)",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"PROSTATE-CANCER,TUMOR,DELINEATION,BOOST",MEDICAL PHYSICS,,
5,Is sleep deficit associated with infertility and recurrent pregnancy losses? Results from a prospective cohort study,100,2,302-313,"Stocker Linden Jane,Cagampang Felino Ramon,Lu Shilong,Ladyman Tom,Cheong Ying Chin","Stocker LJ,Cagampang FR,Lu SL,Ladyman T,Cheong YC",Stocker LJ,10.1111/aogs.14008,University of Southampton,"Introduction Biological rhythms, the innate cycle of changes in the body's physiological functions, are circadian if they have a 24-hour period. It is known that sleep is a key feature of human circadian rhythm but the relationship between sleep and female fertility is largely unknown. This paucity of research is surprising given that circadian rhythms are paramount to human physiology and sleep is related to major female reproductive events. This study was designed to investigate whether there is a difference between the sleep and activity parameters of women with poor reproductive outcome compared with healthy, fertile parous women (comparator group) using subjective (questionnaires) and objective (actigraphy and light exposure) measures.
Material and methods A prospective cohort study in a tertiary in vitro fertilization referral centre in the UK; composed of three study groups: women diagnosed with recurrent implantation failure, women with recurrent miscarriage (RM) and a comparison group (fertile women without endometrial pathology). Comparison women were selected gynaecology patients without endometrial disease (ie perineal complaints or altruistic egg donors). Primary outcome was differences in objective length of sleep in each of the participant groups using actigraphy. Secondary outcomes were subjective sleep quality and quantity, using participant questionnaires, light exposure, and the feasibility of machine learning in activity-pattern interpretation.
Results Women with recurrent implantation failure slept daily on average for 7 hours 35 minutes (+/- 57 min), 53 minutes less than the comparison group (P = .03), although quality of their objective sleep, and quantity of their subjective sleep, were not significantly different. Women with recurrent miscarriage slept less that the comparison women (36 minutes less/night) but more than women with recurrent implantation failure (17 minutes more/night). No difference in light exposure was found between recurrent miscarriage and the recurrent implantation failure and comparison groups.
Conclusions This study demonstrates an objective observation of sleep time reduction in women with subfertility, although it is not yet clear if this association is casual. Given our increased understanding of the internal body clock and circadian rhythm on fertility, our observation warrants further investigation.","assisted reproduction,circadian rhythm,early pregnancy complications,infertility,recurrent implantation failure,recurrent miscarriage,reproductive endocrinology,sleep",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Obstetrics & Gynecology,,3.576,"CIRCADIAN,RHYTHMICITY,SHIFT,WORK,DURATION,POLYSOMNOGRAPHY,INSUFFICIENT,WAKEFULNESS,CALIBRATION,ACTIGRAPHY",ACTA OBSTETRICIA ET GYNECOLOGICA SCANDINAVICA,https://eprints.soton.ac.uk/444458/1/Does_a_sleep_deficit_Acta_R2_2_.docx,
6,Machine learning based novel cost-sensitive seizure detection classifier for imbalanced EEG data sets,14,4,1491-1509,"Siddiqui Mohammad Khubeb,Huang Xiaodi,Morales-Menendez Ruben,Hussain Nasir,Khatoon Khudeja","Siddiqui MK,Huang XD,Morales-Menendez R,Hussain N,Khatoon K",Morales-Menendez R,10.1007/s12008-020-00715-3,Tecnologico de Monterrey,"Epilepsy is one of the most prevalent neurological disorders. Its accurate detection is a challenge since sometimes patients do not experience any prior alert to identify a seizure. Electroencephalography (EEG) recordings are used for seizure detection, but these are usually of longer duration, and as a result, the behavior of the inherent data set is highly imbalanced. To detect seizures in such a scenario is a challenging task; using a typical classifier such as decision tree and decision forest can result in highly skewed class value (non-seizure), causing incorrect detection of epileptic patients. To solve this, a cost-sensitive learning method with a random forest was used. An algorithm that helps in seizure detection by penalizing the cost of a false negative concerning the duration of an EEG recording was proposed. The experimental results show that executing the classifier without penalty or inadequate penalties to the cost matrix is not a satisfactory solution. As a result, the algorithm provides up to 100% recall, which means all the seizure seconds are detected. The proposed method substantiates achieving higher actual seizure detection rates; the imposed penalty should be equal to the time duration of the EEG recordings (in seconds) for a patient. Hence, it can be potentially applied to the pre-consultation to the neurologist at the Outpatient Department for the actual seizure detection cases and refer them to the neurology department for further consultation.","Classification,Decision forest,Class imbalance,Cost-sensitive learning,Epilepsy,Seizure detection,Scalp EEG,Epilepsy monitoring unit",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Engineering,,,,INTERNATIONAL JOURNAL OF INTERACTIVE DESIGN AND MANUFACTURING - IJIDEM,,
7,A machine learning approach to predict explosive spalling of heated concrete,20,4,,"Liu Jin-Cheng,Zhang Zhigang","Liu JC,Zhang ZG",Zhang ZG,10.1007/s43452-020-00135-w,Chongqing University,"Explosive spalling is an unfavorable phenomenon observed in concrete when exposed to heating load. It is a great potential threat to safety of concrete structures subjected to accidental thermal loads. Therefore, assessing explosive spalling risk of concrete is important for fire safety design of concrete structures. This paper proposed a popular machine learning approach, i.e., artificial neural network (ANN), to assess explosive spalling risk of concrete. Besides, the decision tree method was also used to execute the same mission for a comparison purpose. Twenty-eight groups of heating tests were conducted to validate the proposed ANN model. The ANN model behaved well in assessing explosive spalling of concrete, with a prediction accuracy of 82.1%. This study shows that ANN is a promising method for adequate classification of concrete as material resistant or not resistant to thermal explosive spalling.","Concrete,Explosive spalling,High temperature,Machine learning,Artificial neural network",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND","Engineering,Materials Science",,3.859,"HIGH-PERFORMANCE,CONCRETE,HIGH-STRENGTH,CONCRETE,FLY-ASH,CONCRETE,MECHANICAL-PROPERTIES,HIGH-TEMPERATURE,ELEVATED-TEMPERATURES,COMPRESSIVE,STRENGTH,CEMENTITIOUS,COMPOSITE,POLYPROPYLENE,FIBERS,REINFORCED-CONCRETE",ARCHIVES OF CIVIL AND MECHANICAL ENGINEERING,,
8,,,,,,,,,,,,,,,,,,,,
9,,,,,,,,,,,,,,,,,,,,
10,Pattern recognition based on machine learning identifies oil adulteration and edible oil mixtures,11,1,,"Lim Kevin,Pan Kun,Yu Zhe,Xiao Rong Hui","Lim K,Pan K,Yu Z,Xiao RH",Lim K,10.1038/s41467-020-19137-6,"Wilmar Int Ltd, WIL NUS Corp Lab, Ctr Translat Med, 14 Med Dr, Singapore, Singapore.","Previous studies have shown that each edible oil type has its own characteristic fatty acid profile; however, no method has yet been described allowing the identification of oil types simply based on this characteristic. Moreover, the fatty acid profile of a specific oil type can be mimicked by a mixture of 2 or more oil types. This has led to fraudulent oil adulteration and intentional mislabeling of edible oils threatening food safety and endangering public health. Here, we present a machine learning method to uncover fatty acid patterns discriminative for ten different plant oil types and their intra-variability. We also describe a supervised end-to-end learning method that can be generalized to oil composition of any given mixtures. Trained on a large number of simulated oil mixtures, independent test dataset validation demonstrates that the model has a 50(th) percentile absolute error between 1.4-1.8% and a 90(th) percentile error of 4-5.4% for any 3-way mixtures of the ten oil types. The deep learning model can also be further refined with on-line training. Because oil-producing plants have diverse geographical origins and hence slightly varying fatty acid profiles, an online-training method provides also a way to capture useful knowledge presently unavailable. Our method allows the ability to control product quality, determining the fair price of purchased oils and in-turn allowing health-conscious consumers the future of accurate labeling. Fraudulent adulteration of edible oils is based on the fact that their characteristic fatty acid profile can be mimicked with mixtures of other oil types. Here, the authors use a deep learning method to uncover fatty acid patterns discriminative for ten different plant oil types and to discern composition of mixtures.","VEGETABLE-OILS,RAPID IDENTIFICATION,QUANTIFICATION,CLASSIFICATION,SPECTROSCOPY",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,15.805,"VEGETABLE-OILS,RAPID,IDENTIFICATION,QUANTIFICATION,CLASSIFICATION,SPECTROSCOPY",NATURE COMMUNICATIONS,https://www.nature.com/articles/s41467-020-19137-6.pdf,
11,Nanoscale Cinematography of Soft Matter System under Liquid-Phase TEM,1,1,41-52,"Ou Zihao,Liu Chang,Yao Lehan,Chen Qian","Ou ZH,Liu C,Yao LH,Chen Q",Chen Q,10.1021/accountsmr.0c00013,University of Illinois System,"One emergent theme in ""soft matter"" is to understand and manipulate the self-organization of synthetic materials and biological entities in space and time at the underexplored nanoscale. Encoded at this length scale can be a diversity of spatiotemporally fluctuating dynamics that are critical to function, from phase transition of nanoparticle self-assemblies as reconfigurable devices and morphology development of polymer membranes as separation layers for wastewater reclamation to the transformation of membrane proteins as the gatekeeper for mass and information flow in living cells. Extensive research efforts have thus been focused on resolving and understanding such dynamics that typically occur in a liquid medium. The proliferation of methods such as liquid-phase atomic force microscopy, cryogenic electron microscopy, and super-resolution optical microscopy has greatly expanded our knowledge in the structure or dynamics of soft matter at the nanoscale. However, these techniques do not offer direct real-space, real-time imaging of the structural and functional dynamics in a native liquid environment with nanometer resolution. This lack of experimental dataset also renders predictive modeling or computation difficult. As a result, how nanoscale morphology and interaction of the constituents affect the self-organization pathways or broadly collective structural evolution, such as interconversion among metastable states, as well as the involved energy measures remains poorly understood.
In this Account, we present our recent efforts in adapting and using a nanoscopic cinematography method relatively new to the soft matter community, liquid-phase transmission electron microscopy (TEM), to study the self-organization pathways of nanoscale colloidal matter. Liquid-phase TEM has opened a new avenue to investigate materials chemistry questions, such as electrochemistry and catalysis, nanomaterial diffusion and growth, and nucleation of minerals and atomic crystals. Applying it to soft matter systems involves tackling complications, including the electron beam's modification of nanoscale colloidal interaction and the substrate effect present in the liquid chamber, for both of which we highlight achievements of control. In addition, we discuss a series of first-time imaging of self-organization pathways of nanoparticle systems, accessible only by liquid-phase TEM. At low nanoparticle concentrations, chaining of nanoparticles occurs following quantitatively the kinetic laws of polymerization. This analogy originated from local collision and pairwise interaction, which can be directly mapped from trajectory sampling. At high nanoparticle concentrations, collective phase behaviors such as crystallization and coalescence are observed with single-particle resolution, allowing for the charting of phase coordinates and thermodynamic quantities based on statistical mechanics principles. We also discuss the general applicability of these methods. Lastly, toward taking live videos of organic soft matter at the nanoscale, we highlight recent instrumental developments, including machine learning based liquid-phase TEM video analysis to account for low signal-to-noise ratio data sets and low-dose electron tomography to resolve three-dimensional morphologies. We foresee that the examples, techniques, and understandings pinpoint the beginning of a paradigm shift in soft matter studies, where knowledge at the nanoscale can be derived from direct ""seeing"".","NANOCRYSTALS,VISUALIZATION,GROWTH,AU,PATHWAYS",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Materials Science",,,"NANOCRYSTALS,VISUALIZATION,GROWTH,AU,PATHWAYS",ACCOUNTS OF MATERIALS RESEARCH,https://pubs.acs.org/doi/pdf/10.1021/accountsmr.0c00013,
12,Dynamic Laser Speckle Imaging Meets Machine Learning to Enable Rapid Antibacterial Susceptibility Testing (DyRAST),5,10,3140-3149,"Zhou Keren,Zhou Chen,Sapre Anjali,Pavlock Jared Henry,Weaver Ashley,Muralidharan Ritvik,Noble Josh,Chung Taejung,Kovac Jasna,Liu Zhiwen","Zhou KR,Zhou C,Sapre A,Pavlock JH,Weaver A,Muralidharan R,Noble J,Chung T,Kovac J,Liu ZW",Liu ZW; Ebrahimi A,10.1021/acssensors.0c01238,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Rapid antibacterial susceptibility testing (BAST) methods are of significant importance in healthcare, as they can assist caregivers in timely administration of the correct treatments. Various RAST techniques have been reported for tracking bacterial phenotypes, including size, shape, motion, and redox state. However, they still require bulky and expensive instruments- which hinder their application in resource-limited environments-and/or utilize labeling reagents which can interfere with antibiotics and add to the total cost. Furthermore, the existing RAST methods do not address the potential gradual adaptation of bacteria to antibiotics, which can lead to a false diagnosis. In this work, we present a RAST approach by leveraging machine learning to analyze time-resolved dynamic laser speckle imaging (DLSI) results. DLSI captures the change in bacterial motion in response to antibiotic treatments. Our method accurately predicts the minimum inhibitory concentration (MIC) of ampicillin and gentamicin for a model strain of Escherichia coli (E. coli K-12) in 60 min, compared to 6 h using the currently FDA-approved phenotype-based RAST technique. In addition to ampicillin (a beta-lactam) and gentamicin (an aminoglycoside), we studied the effect of ceftriaxone (a third-generation cephalosporin) on E. coli K-12. The machine learning algorithm was trained and validated using the overnight results of a gold standard antibacterial susceptibility testing method enabling prediction of MIC with a similarly high accuracy yet substantially faster.","antibacterial susceptibility testing,phenotype,bacteria,laser speckle imaging,machine learning",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics",,8.162,"ANTIMICROBIAL,SUSCEPTIBILITY,BACTERIA",ACS SENSORS,https://www.biorxiv.org/content/biorxiv/early/2020/02/04/2020.02.04.926071.full.pdf,
13,Identification and Staging of B-Cell Acute Lymphoblastic Leukemia Using Quantitative Phase Imaging and Machine Learning,5,10,3281-3289,"Ayyappan Vinay,Chang Alex,Zhang Chi,Paidi Santosh Kumar,Bordett Rosalie,Liang Tiffany,Barman Ishan,Pandey Rishikesh","Ayyappan V,Chang A,Zhang C,Paidi SK,Bordett R,Liang T,Barman I,Pandey R",Pandey R,10.1021/acssensors.0c01811,Johns Hopkins University,"Identification and classification of leukemia cells in a rapid and label-free fashion is clinically challenging and thus presents a prime arena for implementing new diagnostic tools. Quantitative phase imaging, which maps optical path length delays introduced by the specimen, has been demonstrated to discern cellular phenotypes based on differential morphological attributes. Rapid acquisition capability and the availability of label-free images with high information content have enabled researchers to use machine learning (ML) to reveal latent features. We developed a set of ML classifiers, including convolutional neural networks, to discern healthy B cells from lymphoblasts and classify stages of B cell acute lymphoblastic leukemia. Here, we show that the average dry mass and volume of normal B cells are lower than those of cancerous cells and that these morphologic parameters increase further alongside disease progression. We find that the relaxed training requirements of a ML approach are conducive to the classification of cell type, with minimal space, training time, and memory requirements. Our findings pave the way for a larger study on clinical samples of acute lymphoblastic leukemia, with the overarching goal of its broader use in hematopathology, where the prospect of objective diagnoses with minimal sample preparation remains highly desirable.","deep learning,quantitative phase imaging,classification,leukemia,label-free imaging",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics",,8.162,"GENE-EXPRESSION,DATA,NEURAL-NETWORKS,CLASSIFICATION,DIMENSIONALITY,MICROSCOPY,SELECTION",ACS SENSORS,,
14,Early Multiplexed Detection of Cirrhosis using Giant Magnetoresistive Biosensors with Protein Biomarkers,5,10,3049-3057,"Ng Elaine,Le An K.,Nguyen Mindie H.,Wang Shan X.","Ng E,Le AK,Nguyen MH,Wang SX",Ng E,10.1021/acssensors.0c00232,Stanford University,"Liver cirrhosis is one of the leading causes of death in adults worldwide. It is highly prevalent in developing countries and is growing in prevalence in developed countries mostly because of chronic liver diseases, such as chronic hepatitis B and C and alcoholic and nonalcoholic fatty liver disease. However, the prevalence of cirrhosis may be highly underestimated because early stages are asymptomatic and current early detection methods are inadequate. Here, we evaluate the potential of a set of novel cirrhotic protein biomarkers, including soluble intercellular adhesion molecule-1 and mac-2 binding protein glycosylation isomer, for early detection of cirrhosis in a multiplexed assay using our giant magnetoresistive (GMR) sensor arrays. We evaluated the diagnostic performance of the biomarkers, individually and in combination, using multivariate logistic regression and random forest in a blinded proof-of-concept retrospective case-controlled study. The biomarkers in combination exhibited high diagnostic performance in both logistic regression and random forest models, with an area under the curve of 0.98 (0.94-1.00). In addition, the combination of biomarkers resulted in a high sensitivity of 0.97 (0.95-1.00) and a high specificity of 1.00. We showed that the diagnostic performance of our novel set of cirrhotic protein biomarkers on our multiplexed GMR sensor arrays is higher than the performance of currently used clinical biomarkers and factors (i.e., age, sex, alanine aminotransferase, aspartate aminotransferase, etc.). With this combination of novel biomarkers and GMR technology, we could potentially boost the diagnostic power of early cirrhosis detection.","sICAM-1,M2BPGi,cirrhosis,HBV,HCV,magnetonanosensors",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics",,8.162,"INTERCELLULAR-ADHESION,MOLECULE-1,HEPATITIS-C,NONINVASIVE,TESTS,LIVER-DISEASE,FIBROSIS,SENSOR,ARRAY,QUANTIFICATION,PROTOTYPE,APRI",ACS SENSORS,,
15,Fast body part segmentation and tracking of neonatal video data using deep learning,58,12,3049-3061,"Antink Christoph Hoog,Ferreira Joana Carlos Mesquita,Paul Michael,Lyra Simon,Heimann Konrad,Karthik Srinivasa,Joseph Jayaraj,Jayaraman Kumutha,Orlikowsky Thorsten,Sivaprakasam Mohanasankar","Antink CH,Ferreira JCM,Paul M,Lyra S,Heimann K,Karthik S,Joseph J,Jayaraman K,Orlikowsky T,Sivaprakasam M",Antink CH,10.1007/s11517-020-02251-4,Helmholtz Association,"Photoplethysmography imaging (PPGI) for non-contact monitoring of preterm infants in the neonatal intensive care unit (NICU) is a promising technology, as it could reduce medical adhesive-related skin injuries and associated complications. For practical implementations of PPGI, a region of interest has to be detected automatically in real time. As the neonates' body proportions differ significantly from adults, existing approaches may not be used in a straightforward way, and color-based skin detection requires RGB data, thus prohibiting the use of less-intrusive near-infrared (NIR) acquisition. In this paper, we present a deep learning-based method for segmentation of neonatal video data. We augmented an existing encoder-decoder semantic segmentation method with a modified version of the ResNet-50 encoder. This reduced the computational time by a factor of 7.5, so that 30 frames per second can be processed at 960 x 576 pixels. The method was developed and optimized on publicly available databases with segmentation data from adults. For evaluation, a comprehensive dataset consisting of RGB and NIR video recordings from 29 neonates with various skin tones recorded in two NICUs in Germany and India was used. From all recordings, 643 frames were manually segmented. After pre-training the model on the public adult data, parts of the neonatal data were used for additional learning and left-out neonates are used for cross-validated evaluation. On the RGB data, the head is segmented well (82% intersection over union, 88% accuracy), and performance is comparable with those achieved on large, public, non-neonatal datasets. On the other hand, performance on the NIR data was inferior. By employing data augmentation to generate additional virtual NIR data for training, results could be improved and the head could be segmented with 62% intersection over union and 65% accuracy. The method is in theory capable of performing segmentation in real time and thus it may provide a useful tool for future PPGI applications.","Image processing,Deep learning,Semantic segmentation,Camera-based monitoring,Nicu",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"PHOTOPLETHYSMOGRAPHY,RATES",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7679364,
16,Architectured Lattice Materials with Tunable Anisotropy: Design and Analysis of the Material Property Space with the Aid of Machine Learning,22,12,,"Kulagin Roman,Beygelzimer Yan,Estrin Yuri,Schumilin Artem,Gumbsch Peter","Kulagin R,Beygelzimer Y,Estrin Y,Schumilin A,Gumbsch P",Kulagin R,10.1002/adem.202001069,Helmholtz Association,"Architectured beam lattice materials whose anisotropy can be tuned by varying the composition of their elementary cell are investigated. As an exemplary prototype of such material architecture, a regular triangular lattice with an elementary cell composed of 12 beams is considered. One out of three possible values of the elastic modulus is assigned to each beam. The structure is fully defined by a vector in the 12D composition-structure space whose components are given by the elastic modulus values of the beams comprising the elementary cell. The elastic properties of this 2D material are represented by the compliance elasticity tensor with six independent compliance coefficients. Aiming at a specific set of properties thus involves finding the point in the 12D composition-structure space that corresponds to a given point in the 6D property space. This is a problem of large dimensionality. To solve it, the neural network approach is used. This enables creation of architectured materials with tunable elastic anisotropy. A chiral element combining large twist with additional anisotropy requirements is presented as an example of successful machine-learning-based optimization of beam lattices proposed.","architectured materials,elastic anisotropies,lattice materials,machine learning",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Materials Science,,3.746,,ADVANCED ENGINEERING MATERIALS,https://publikationen.bibliothek.kit.edu/1000125818/124490043,
17,Crowd-Sourced Data and Analysis Tools for Advancing the Chemical Vapor Deposition of Graphene: Implications for Manufacturing,3,10,10144-10155,"Schiller Joshua A.,Toro Ricardo,Shah Aagam,Surana Mitisha,Zhang Kaihao,Robertson Matthew,Miller Kristina,Cruse Kevin,Liu Kevin,Seong Bomsaerah","Schiller JA,Toro R,Shah A,Surana M,Zhang KH,Robertson M,Miller K,Cruse K,Liu K,Seong B",Ertekin E; Tawfick S,10.1021/acsanm.0c02018,University of Illinois System,"Industrial production of graphene by chemical vapor deposition (CVD) requires more than the ability to synthesize large domain, high-quality graphene in a lab reactor. The integration of graphene in the fabrication process of electronic devices requires the cost-effective and environmentally friendly production of graphene on dielectric substrates, but current approaches can only produce graphene on metal catalysts. Sustainable manufacturing of graphene should also conserve the catalyst and reaction gases, but today the metal catalysts are typically dissolved after synthesis. Progress toward these objectives is hindered by the hundreds of coupled synthesis parameters that can strongly affect CVD of low-dimensional materials and poor communication in the published literature of the rich experimental data that exists in individual laboratories. We report here on a platform, ""graphene recipes for synthesis of high quality material"" (Gr-ResQ: pronounced graphene rescue), which includes powerful new tools for data-driven graphene synthesis. At the core of Gr-ResQ is a crowd-sourced database of CVD synthesis recipes and associated experimental results. The database captures similar to 300 parameters ranging from synthesis conditions such as a catalyst material and preparation steps, to ambient lab temperature and reactor details, as well as resulting Raman spectra and microscopy images. These parameters are carefully selected to unlock the potential of machine-learning models to advance synthesis. A suite of associated tools enable fast, automated, and standardized processing of Raman spectra and scanning electron microscopy images. To facilitate community-based efforts, Gr-ResQ provides tools for cyber-physical collaborations among research groups, allowing experiments to be designed, executed, and analyzed by different teams. Gr-ResQ also allows publication and discovery of recipes via the Materials Data Facility, which assigns each recipe a unique identifier when published and collects parameters in a search index. We envision that this holistic approach to data-driven synthesis can accelerate CVD recipe discovery and production control and open opportunities for advancing not only graphene but also many other 1D and 2D materials.","graphene,robotic synthesis,materials data,recipes,machine learning,Raman spectroscopy,nanomanufacturing",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science",,5.1,"SINGLE-CRYSTAL,GRAPHENE,LARGE-AREA,SYNTHESIS,HIGH-QUALITY,GROWTH,FILMS,OXYGEN,NETWORKS,SUPERCAPACITOR,SUBSTRATE,OXIDE",ACS APPLIED NANO MATERIALS,https://osf.io/7mwgd/download,
18,Telemonitoring Parkinson's disease using machine learning by combining tremor and voice analysis.,7,1,12,",,,,,","Sajal Md Sakibur Rahman,Ehsan Md Tanvir,Vaidyanathan Ravi,Wang Shouyan,Aziz Tipu,Mamun Khondaker Abdullah Al",,10.1186/s40708-020-00113-1,,"RESULT: The highest accuracy in PD detection using offline data was [Formula: see text] from voice data and [Formula: see text] from tremor data when used separately. In both cases, k-nearest neighbors (kNN) gave the highest accuracy over support vector machine (SVM) and naive Bayes (NB). The application of maximum relevance minimum redundancy (MRMR) feature selection method showed that by selecting different feature sets based on the patient's gender, we could improve the detection accuracy. This study's novelty is the application of ensemble averaging on the combined decisions generated from the analysis of voice and tremor data. The average accuracy of PD detection becomes [Formula: see text] when ensemble averaging was performed on majority-vote from kNN, SVM, and NB.CONCLUSION: The proposed system can detect PD using a cloud-based system for computation, data preserving, and regular monitoring of voice and tremor samples captured by smartphones. Thus, this system can be a solution for healthcare authorities to ensure the older population's accessibility to a better medical diagnosis system in the developing countries, especially in the pandemic situation like COVID-19, when in-person monitoring is minimal.",Accelerometer; Machine-learning; Parkinsons; Telemonitoring; Tremor,Journal Article,,,,,,,,
19,Estimating uncertainty in deep learning for reporting confidence to clinicians in medical image segmentation and diseases detection,37,2,701-734,"Ghoshal Biraja,Tucker Allan,Sanghera Bal,Lup Wong Wai","Ghoshal B,Tucker A,Sanghera B,Wong WL",Ghoshal B,10.1111/coin.12411,Brunel University,"Deep learning (DL), which involves powerful black box predictors, has achieved a remarkable performance in medical image analysis, such as segmentation and classification for diagnosis. However, in spite of these successes, these methods focus exclusively on improving the accuracy of point predictions without assessing the quality of their outputs. Knowing how much confidence there is in a prediction is essential for gaining clinicians' trust in the technology. In this article, we propose an uncertainty estimation framework, called MC-DropWeights, to approximate Bayesian inference in DL by imposing a Bernoulli distribution on the incoming or outgoing weights of the model, including neurones. We demonstrate that by decomposing predictive probabilities into two main types of uncertainty, aleatoric and epistemic, using the Bayesian Residual U-Net (BRUNet) in image segmentation. Approximation methods in Bayesian DL suffer from the ""mode collapse"" phenomenon in variational inference. To address this problem, we propose a model which Ensembles of Monte-Carlo DropWeights by varying the DropWeights rate. In segmentation, we introduce a predictive uncertainty estimator, which takes the mean of the standard deviations of the class probabilities associated with every class. However, in classification, we need an alternative approach since the predictive probabilities from a forward pass through the model does not capture uncertainty. The entropy of the predictive distribution is a measure of uncertainty, but its exponential depends on sample size. The plug-in estimate in mutual information is subject to sampling bias. We propose Jackknife resampling, to correct for sample bias, which improves estimating uncertainty quality in image classification. We demonstrate that our deep ensemble MC-DropWeights method, using the bias-corrected estimator produces an equally good or better result in both quantified uncertainty estimation and quality of uncertainty estimates than approximate Bayesian neural networks in practice.","bias-corrected uncertainty estimation,classification,deep learning,dropweights,ensembles,medical image segmentation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Computer Science,,2.016,BIAS,COMPUTATIONAL INTELLIGENCE,http://bura.brunel.ac.uk/bitstream/2438/21904/2/FullText.pdf,
20,,,,,,,,,,,,,,,,,,,,
21,,,,,,,,,,,,,,,,,,,,
22,An automatic framework for endoscopic image restoration and enhancement,51,4,1959-1971,"Asif Muhammad,Chen Lei,Song Hong,Yang Jian,Frangi Alejandro F.","Asif M,Chen L,Song H,Yang J,Frangi AF",Song H,10.1007/s10489-020-01923-w,Beijing Institute of Technology,"Despite its success in the field of minimally invasive surgery, endoscopy image analysis remains challenging due to limited image settings and control conditions. The low resolution and existence of large number of reflections in endoscopy images are the major problems in the automatic detection of objects. To address these issues, we presented a novel framework based on the convolutional neural networks. The proposed approach consists of three major parts. First, a deep learning (DL)-based image evaluation method is used to classify the input images into two groups, namely, specular highlights and weakly illuminated groups. Second, the specular highlight is detected using the DL-based method, and the reflected areas are recovered through a patch-based restoration operation. Lastly, gamma correction with optimized reflectance and illumination estimation is adopted to enhance the weakly illuminated images. The proposed method is compared against the existing ones, and the experimental results demonstrate that the former outperforms the latter in terms of subjective and objective assessments. This finding indicates that the proposed approach can serve as a potential tool for improving the quality of the endoscopy images used to examine internal body organs.","Endoscopy,Image restoration,Image enhancement,Specular highlights,Weak illuminance",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,4.602,SPACE,APPLIED INTELLIGENCE,,
23,The Role of Machine Learning Algorithms in Materials Science: A State of Art Review on Industry 4.0,28,5,3361-3381,Choudhury Amitava,Choudhury A,Choudhury A,10.1007/s11831-020-09503-4,Indian Institute of Engineering Science Technology Shibpur (IIEST),"The 21st century has witnessed a rapid convergence of manufacturing technology, computer science and information technology. This has led to a paradigm of 4.0. The hitherto known developments in metallurgical and materials practices are largely driven by application of fundamental knowledge through experiments and experiences. However, the mounting demands of high performance products and environmental security calls for the 'right first time' manufacturing in contrast to the traditional trial and error approach. In this context, a priori capability, for prediction and optimization of materials, process and product variables, is becoming the enabling factor. In recent time, research in material science is increasingly embarrassing the computational techniques in development of exotic materials with greater reliability and precision. The present study is aimed at exploring the computer vision and machine learning techniques in different application areas in materials science.","HIGH-ENTROPY ALLOYS,SOLID-SOLUTION PHASE,CRYSTALLIZATION BEHAVIOR,MECHANICAL-PROPERTIES,EDGE-DETECTION,MICROSTRUCTURE,SEGMENTATION,PREDICTION,STEEL,CO",Review,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering,Mathematics",,8.169,"HIGH-ENTROPY,ALLOYS,SOLID-SOLUTION,PHASE,CRYSTALLIZATION,BEHAVIOR,MECHANICAL-PROPERTIES,EDGE-DETECTION,MICROSTRUCTURE,SEGMENTATION,PREDICTION,STEEL,CO",ARCHIVES OF COMPUTATIONAL METHODS IN ENGINEERING,,
24,Exchange Spin Coupling from Gaussian Process Regression,124,42,8708-8723,"Bahlke Marc Philipp,Mogos Natnael,Proppe Jonny,Herrmann Carmen","Bahlke MP,Mogos N,Proppe J,Herrmann C",Bahlke MP; Herrmann C,10.1021/acs.jpca.0c05983,University of Hamburg,"Heisenberg exchange spin coupling between metal centers is essential for describing and understanding the electronic structure of many molecular catalysts, metalloenzymes, and molecular magnets for potential application in information technology. We explore the machine-learnability of exchange spin coupling beyond linear regression, which has not been studied yet. We employ Gaussian process regression, since it can potentially deal with small training sets (as likely associated with the rather complex molecular structures required for exploring spin coupling) and since it provides uncertainty estimates (""error bars"") along with predicted values. We compare a range of descriptors and kernels for 257 small dicopper complexes and find that a simple descriptor based on chemical intuition, consisting only of copper-bridge angles and copper-copper distances, clearly outperforms several more sophisticated descriptors when it comes to extrapolating toward larger experimentally relevant complexes. Exchange spin coupling is similarly easy to learn as the polarizability, while learning dipole moments is much harder. The strength of the sophisticated descriptors lies in their ability to linearize structure-property relationships, to the point that a simple linear ridge regression performs just as well as the kernel-based machine-learning model for our small dicopper data set. The superior extrapolation performance of the simple descriptor is unique to exchange spin coupling, reinforcing the crucial role of choosing a suitable descriptor and highlighting the interesting question of the role of chemical intuition vs systematic or automated selection of features for machine learning in chemistry and material science.","TRANSITION-METAL-COMPLEXES,ZETA VALENCE QUALITY,CORRELATION-ENERGY,BASIS-SETS,MACHINE,DISCOVERY,DESIGN,ANTIFERROMAGNETISM,COMMUNICATION,STRATEGIES",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Physics",,2.725,"TRANSITION-METAL-COMPLEXES,ZETA,VALENCE,QUALITY,CORRELATION-ENERGY,BASIS-SETS,MACHINE,DISCOVERY,DESIGN,ANTIFERROMAGNETISM,COMMUNICATION,STRATEGIES",JOURNAL OF PHYSICAL CHEMISTRY A,https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/60c74df1f96a00b10a287a1e/original/exchange-spin-coupling-from-gaussian-process-regression.pdf,
25,Diagnosing colorectal abnormalities using scattering coefficient maps acquired from optical coherence tomography,14,1,,"Zeng Yifeng,Chapman William C. Jr.,Lin Yixiao,Li Shuying,Mutch Matthew,Zhu Quing","Zeng YF,Chapman WC,Lin YX,Li SY,Mutch M,Zhu Q",Zhu Q,10.1002/jbio.202000276,Washington University (WUSTL),"Optical coherence tomography (OCT) has shown potential in differentiating normal colonic mucosa from neoplasia. In this study of 33 fresh human colon specimens, we report the first use of texture features and computer vision-based imaging features acquired from en face scattering coefficient maps to characterize colorectal tissue. En face scattering coefficient maps were generated automatically using a new fast integral imaging algorithm. From these maps, a gray-level cooccurrence matrix algorithm was used to extract texture features, and a scale-invariant feature transform algorithm was used to derive novel computer vision-based features. In total, 25 features were obtained, and the importance of each feature in diagnosis was evaluated using a random forest model. Two classifiers were assessed on two different classification tasks. A support vector machine model was found to be optimal for distinguishing normal from abnormal tissue, with 94.7% sensitivity and 94.0% specificity, while a random forest model performed optimally in further differentiating abnormal tissues (i.e., cancerous tissue and adenomatous polyp) with 86.9% sensitivity and 85.0% specificity. These results demonstrated the potential of using OCT to aid the diagnosis of human colorectal disease.","colorectal cancer,feature engineering,machine learning,optical coherence tomography,scattering coefficient map",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Biochemistry & Molecular Biology,Biophysics,Optics",,3.403,CANCER,JOURNAL OF BIOPHOTONICS,,
26,Structure and Dynamics of Supercooled Liquid Ge2Sb2Te5 from Machine-Learning-Driven Simulations,15,3,,"Zhou Yu-Xing,Zhang Han-Yi,Deringer Volker L.,Zhang Wei","Zhou YX,Zhang HY,Deringer VL,Zhang W",Zhang W,10.1002/pssr.202000403,Xi'an Jiaotong University,"Studies of supercooled liquid phase-change materials are important for the development of phase-change memory and neuromorphic computing devices. Herein, a machine-learning (ML)-based interatomic potential for Ge2Sb2Te5 (GST) to conduct large-scale molecular dynamics simulations of liquid and supercooled liquid GST is used. A pronounced effect of the thermostat parameters on the simulation results is demonstrated, and it is shown how using a Langevin thermostat with optimized damping values can lead to excellent agreement with reference ab initio molecular dynamics (AIMD) simulations. Structural and dynamical analyses are presented, including the studies of radial and angular distributions, homopolar bonds, and the temperature-dependent diffusivity. Herein, the usefulness of ML-driven molecular dynamics for further studies of supercooled liquid GST, with length and timescales far exceeding those that are accessible to AIMD is demonstrated.","dynamical properties,Gaussian approximation potential,machine learning,molecular dynamics simulations,phase&#8208,change materials",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Materials Science,Physics",,3.017,"PHASE-CHANGE,MATERIALS,SB-TE,MOLECULAR-DYNAMICS,FAST,CRYSTALLIZATION,MEMORY,SC,TRANSITIONS,STATE,GETE",PHYSICA STATUS SOLIDI-RAPID RESEARCH LETTERS,https://ora.ox.ac.uk/objects/uuid:e02516cd-8375-40fd-b5dd-d7b4882178bb/download_file?safe_filename=Zhou_et_al_2020._structure_and_dynamics.pdf&type_of_work=Journal+article,
27,Synthesis of computer simulation and machine learning for achieving the best material properties of filled rubber,10,1,,"Kojima Takashi,Washio Takashi,Hara Satoshi,Koishi Masataka","Kojima T,Washio T,Hara S,Koishi M",Kojima T,10.1038/s41598-020-75038-0,The Yokohama Rubber Co. Ltd.,"Molecular dynamics (MD) simulation is used to analyze the mechanical properties of polymerized and nanoscale filled rubber. Unfortunately, the computation time for a simulation can require several months' computing power, because the interactions of thousands of filler particles must be calculated. To alleviate this problem, we introduce a surrogate convolutional neural network model to achieve faster and more accurate predictions. The major difficulty when employing machine-learning-based surrogate models is the shortage of training data, contributing to the huge simulation costs. To derive a highly accurate surrogate model using only a small amount of training data, we increase the number of training instances by dividing the large-scale simulation results into 3D images of middle-scale filler morphologies and corresponding regional stresses. The images include fringe regions to reflect the influence of the filler constituents outside the core regions. The resultant surrogate model provides higher prediction accuracy than that trained only by images of the entire region. Afterwards, we extract the fillers that dominate the mechanical properties using the surrogate model and we confirm their validity using MD.",,Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,5.134,,SCIENTIFIC REPORTS,https://www.nature.com/articles/s41598-020-75038-0.pdf,
28,,,,,,,,,,,,,,,,,,,,
29,Diabetic retinopathy severity grading employing quadrant-basedInception-V3convolution neural network architecture,31,2,592-608,"Bhardwaj Charu,Jain Shruti,Sood Meenakshi","Bhardwaj C,Jain S,Sood M",Bhardwaj C,10.1002/ima.22510,Jaypee University of Information Technology,Diabetic retinopathy (DR) accounts in eye-related disorders due to accumulated damage to small retinal blood vessels. Automated diagnostic systems are effective in early detection and diagnosis of severe eye complications by assisting the ophthalmologists. Deep learning-based techniques have emerged as an advancement over conventional techniques based on hand-crafted features. The authors have proposed a Quadrant-based automated DR grading system in this work using Inception-V3 deep neural network to extract small lesions present in retinal fundus images. The grading efficiency of the proposed architecture is improved utilizing image enhancement and optical disc removal pipeline along with data augmentation stage. The proposed system yields accuracy of 93.33% with minimized cross-entropy loss of 0.291. Capability of proposed system is demonstrated experimentally to provide efficient DR diagnosis. The diagnosis ability of the proposed architecture is demonstrated by state-of-the-art comparison with other mainstream convolution neural network models and a maximum improvement of 14.33% is observed.,"convolution neural network,data augmentation,deep neural network,diabetic retinopathy,hand-crafted features",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,"FUNDUS,IMAGES,SYSTEM",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
30,"Predicting Inorganic Photovoltaic Materials with Efficiencies > 26% via Structure-Relevant Machine Learning and Density Functional Calculations (vol 1, 100179-1-17, 2020)",1,10,,"Feng Hong-Jian);,Wu Kan);,Deng Zun-Yi","Feng HJ,Wu K,Deng ZY",,10.1016/j.xcrp.2020.100236,,,,Correction,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Chemistry,Energy & Fuels,Materials Science,Physics",,,,CELL REPORTS PHYSICAL SCIENCE,https://doi.org/10.1016/j.xcrp.2020.100236,
31,Deep Convolutional Mixture Density Network for Inverse Design of Layered Photonic Structures,7,10,2703-2712,"Unni Rohit,Yao Kan,Zheng Yuebing","Unni R,Yao K,Zheng YB",Zheng YB,10.1021/acsphotonics.0c00630,University of Texas System,"Machine learning (ML) techniques, such as neural networks, have emerged as powerful tools for the inverse design of nanophotonic structures. However, this innovative approach suffers some limitations. A primary one is the nonuniqueness problem, which can prevent ML algorithms from properly converging because vastly different designs produce nearly identical spectra. Here, we introduce a mixture density network (MDN) approach, which models the design parameters as multimodal probability distributions instead of discrete values, allowing the algorithms to converge in cases of nonuniqueness without sacrificing degenerate solutions. We apply our MDN technique to inversely design two types of multilayer photonic structures consisting of thin films of oxides, which present a significant challenge for conventional ML algorithms due to a high degree of nonuniqueness in their optical properties. In the 10-layer case, the MDN can handle transmission spectra with high complexity and under varying illumination conditions. The 4-layer case tends to show a stronger multimodal character, with secondary modes indicating alternative solutions for a target spectrum. The shape of the distributions gives valuable information for postprocessing and about the uncertainty in the predictions, which is not available with deterministic networks. Our approach provides an effective solution to the inverse design of photonic structures and yields more optimal searches for the structures with high degeneracy and spectral complexity.","deep learning,artificial neural networks,multilayer structures,nanophotonics,inverse design,nonuniqueness",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science,Optics,Physics",,7.718,NANOPHOTONICS,ACS PHOTONICS,,
32,Deep learning approaches for thermographic imaging,128,15,,"Kovacs Peter,Lehner Bernhard,Thummerer Gregor,Mayr Guenther,Burgholzer Peter,Huemer Mario","Kovacs P,Lehner B,Thummerer G,Mayr G,Burgholzer P,Huemer M",Kovacs P,10.1063/5.0020404,Johannes Kepler University Linz,"In this paper, we investigate two deep learning approaches to recovering initial temperature profiles from thermographic images in non-destructive material testing. First, we trained a deep neural network (DNN) in an end-to-end fashion by directly feeding the surface temperature measurements to the DNN. Second, we turned the surface temperature measurements into virtual waves (a recently developed concept in thermography), which we then fed to the DNN. To demonstrate the effectiveness of these methods, we implemented a data generator and created a dataset comprising a total of 100000 simulated temperature measurement images. With the objective of determining a suitable baseline, we investigated several state-of-the-art model-based reconstruction methods, including Abel transformation, curvelet denoising, and time- and frequency-domain synthetic aperture focusing techniques. Additionally, a physical phantom was created to support evaluation on completely unseen real-world data. The results of several experiments suggest that both the end-to-end and the hybrid approach outperformed the baseline in terms of reconstruction accuracy. The end-to-end approach required the least amount of domain knowledge and was the most computationally efficient one. The hybrid approach required extensive domain knowledge and was more computationally expensive than the end-to-end approach. However, the virtual waves served as meaningful features that convert the complex task of the end-to-end reconstruction into a less demanding undertaking. This in turn yielded better reconstructions with the same number of training samples compared to the end-to-end approach. Additionally, it allowed more compact network architectures and use of prior knowledge, such as sparsity and non-negativity. The proposed method is suitable for non-destructive testing (NDT) in 2D where the amplitudes along the objects are considered to be constant (e.g., for metallic wires). To encourage the development of other deep-learning-based reconstruction techniques, we release both the synthetic and the real-world datasets along with the implementation of the deep learning methods to the research community.","APERTURE,MODEL",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,"APERTURE,MODEL",JOURNAL OF APPLIED PHYSICS,https://aip.scitation.org/doi/pdf/10.1063/5.0020404,
33,Detection of cervical cancer cells based on strong feature CNN-SVM network,411,,112-127,"Jia A. Dongyao,Li B. Zhengyi,Zhang C. Chuanwang","Jia ADY,Li BZY,Zhang CCW",Zhang CCW,10.1016/j.neucom.2020.06.006,Beijing Jiaotong University,"Traditional screening of cervical cells largely depends on the experience of pathologists, which also has the problem of low accuracy and poor efficiency. Medical image processing combining deep learning and machine learning shows its superiority in the field of cell classification. A new framework based on strong feature Convolutional Neural Networks (CNN)-Support Vector Machine (SVM) model was proposed to accurately classify the cervical cells. A method fusing the strong features extracted by Gray-Level Co-occurrence Matrix (GLCM) and Gabor with abstract features from the hidden layers of CNN was conducted, meanwhile the fused ones were input into the SVM for classification. An effective dataset amplification method was designed to improve the robustness of the model. The proposed method was evaluated on two independent datasets with the metrics of accuracy (Acc), sensitivity (Sn), and specificity (Sp). Our approach outperformed than the state-of-the-art models with the Acc, Sn, and Sp of 99.3, 98.9, 99.4 for 2-class detection in the mass, respectively. The results indicated that the strong feature CNN-SVM model could be applied in cell classification for the early screening of cervical cancer. (c) 2020 Elsevier B.V. All rights reserved.","Cancer cell detection,Strong features,CNN-SVM,Sample amplification",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"QUANTITATIVE-ANALYSIS,CLASSIFICATION,SEGMENTATION,DIAGNOSIS",NEUROCOMPUTING,,
34,Deep learning in medical image registration: a review,65,20,,"Fu Yabo,Lei Yang,Wang Tonghe,Curran Walter J.,Liu Tian,Yang Xiaofeng","Fu YB,Lei Y,Wang TH,Curran WJ,Liu T,Yang XF",Yang XF,10.1088/1361-6560/ab843e,Emory University,"This paper presents a review of deep learning (DL)-based medical image registration methods. We summarized the latest developments and applications of DL-based registration methods in the medical field. These methods were classified into seven categories according to their methods, functions and popularity. A detailed review of each category was presented, highlighting important contributions and identifying specific challenges. A short assessment was presented following the detailed review of each category to summarize its achievements and future potential. We provided a comprehensive comparison among DL-based methods for lung and brain registration using benchmark datasets. Lastly, we analyzed the statistics of all the cited works from various aspects, revealing the popularity and future trend of DL-based medical image registration.","deep learning,medical image registration,review",Review,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"DEFORMABLE,REGISTRATION,DOSE,ACCUMULATION,NEURAL-NETWORKS,FRAMEWORK,RECONSTRUCTION,MOTION,ACCURACY,LOCALIZATION,SEGMENTATION,MODEL",PHYSICS IN MEDICINE AND BIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7759388,
35,Frontiers in atomistic simulations of high entropy alloys,128,15,,"Ferrari Alberto,Dutta Biswanath,Gubaev Konstantin,Ikeda Yuji,Srinivasan Prashanth,Grabowski Blazej,Koermann Fritz","Ferrari A,Dutta B,Gubaev K,Ikeda Y,Srinivasan P,Grabowski B,Kormann F",Ferrari A,10.1063/5.0025310,Delft University of Technology,"The field of atomistic simulations of multicomponent materials and high entropy alloys is progressing rapidly, with challenging problems stimulating new creative solutions. In this Perspective, we present three topics that emerged very recently and that we anticipate will determine the future direction of research of high entropy alloys: the usage of machine-learning potentials for very accurate thermodynamics, the exploration of short-range order and its impact on macroscopic properties, and the more extensive exploitation of interstitial alloying and high entropy alloy surfaces for new technological applications. For each of these topics, we briefly summarize the key achievements, point out the aspects that still need to be addressed, and discuss possible future improvements and promising directions.","SHORT-RANGE ORDER,HYDROGEN STORAGE PROPERTIES,MECHANICAL-PROPERTIES,TENSILE PROPERTIES,POTENTIAL MODEL,CARBON,MICROSTRUCTURE,ABSORPTION,PLASTICITY,CRMNFECONI",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,"SHORT-RANGE,ORDER,HYDROGEN,STORAGE,PROPERTIES,MECHANICAL-PROPERTIES,TENSILE,PROPERTIES,POTENTIAL,MODEL,CARBON,MICROSTRUCTURE,ABSORPTION,PLASTICITY,CRMNFECONI",JOURNAL OF APPLIED PHYSICS,https://repository.tudelft.nl/islandora/object/uuid%3A43aa5276-7257-4ef6-a584-d748b56a823e/datastream/OBJ/download,
36,Sensitivity analysis of FDG PET tumor voxel cluster radiomics and dosimetry for predicting mid-chemoradiation regional response of locally advanced lung cancer,65,20,,"Duan Chunyan,Chaovalitwongse W. Art,Bai Fangyun,Hippe Daniel S.,Wang Shouyi,Thammasorn Phawis,Pierce Larry A.,Liu Xiao,You Jianxin,Miyaoka Robert S.","Duan CY,Chaovalitwongse WA,Bai FY,Hippe DS,Wang SY,Thammasorn P,Pierce LA,Liu X,You JX,Miyaoka RS",Bowen SR,10.1088/1361-6560/abb0c7,University of Washington,"We investigated the sensitivity of regional tumor response prediction to variability in voxel clustering techniques, imaging features, and machine learning algorithms in 25 patients with locally advanced non-small cell lung cancer (LA-NSCLC) enrolled on the FLARE-RT clinical trial. Metabolic tumor volumes (MTV) from pre-chemoradiation (PETpre) and mid-chemoradiation fluorodeoxyglucose-positron emission tomography (FDG PET) images (PETmid) were subdivided into K-means or hierarchical voxel clusters by standardized uptake values (SUV) and 3D-positions. MTV cluster separability was evaluated by CH index, and morphologic changes were captured by Dice similarity and centroid Euclidean distance. PETpre conventional features included SUVmean, MTV/MTV cluster size, and mean radiation dose. PETpre radiomics consisted of 41 intensity histogram and 3D texture features (PET Oncology Radiomics Test Suite) extracted from MTV or MTV clusters. Machine learning models (multiple linear regression, support vector regression, logistic regression, support vector machines) of conventional features or radiomic features were constructed to predict PETmid response. Leave-one-out-cross-validated root-mean-squared-error (RMSE) for continuous response regression (Delta SUVmean) and area-under-receiver-operating-characteristic-curve (AUC) for binary response classification were calculated. K-means MTV 2-clusters (MTVhi, MTVlo) achieved maximum CH index separability (Friedmanp< 0.001). Between PETpre and PETmid, MTV cluster pairs overlapped (Dice 0.70-0.87) and migrated 0.6-1.1 cm. PETmid Delta SUVmean response prediction was superior in MTV and MTVlo (RMSE = 0.17-0.21) compared to MTVhi (RMSE = 0.42-0.52, Friedmanp< 0.001). PETmid Delta SUVmean response class prediction performance trended higher in MTVlo (AUC = 0.83-0.88) compared to MTVhi (AUC = 0.44-0.58, Friedmanp= 0.052). Models were more sensitive to MTV/MTV cluster regions (Friedmanp= 0.026) than feature sets/algorithms (Wilcoxon signed-rankp= 0.36). Top-ranked radiomic features included GLZSM-LZHGE (large-zone-high-SUV), GTSDM-CP (cluster-prominence), GTSDM-CS (cluster-shade) and NGTDM-CNT (contrast). Top-ranked features were consistent between MTVhi and MTVlo cluster pairs but varied between MTVhi-MTVlo clusters, reflecting distinct regional radiomic phenotypes. Variability in tumor voxel cluster response prediction can inform robust radiomic target definition for risk-adaptive chemoradiation in patients with LA-NSCLC. FLARE-RT trial: NCT02773238.","tumor voxel clustering,machine learning,positron emission tomography,cancer response,radiomics,sensitivity analysis",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"POSITRON-EMISSION-TOMOGRAPHY,STANDARDIZED,UPTAKE,VALUE,RADIATION,ONCOLOGY,TEXTURE,FEATURES,F-18-FDG,UPTAKE,SURVIVAL,PRETREATMENT,THERAPY,HETEROGENEITY,SEGMENTATION",PHYSICS IN MEDICINE AND BIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7593986,
37,Self-derived organ attention for unpaired CT-MRI deep domain adaptation based MRI segmentation,65,20,,"Jiang Jue,Hu Yu-Chi,Tyagi Neelam,Wang Chuang,Lee Nancy,Deasy Joseph O.,Sean Berry,Veeraraghavan Harini","Jiang J,Hu YC,Tyagi N,Wang C,Lee N,Deasy JO,Sean B,Veeraraghavan H",Veeraraghavan H,10.1088/1361-6560/ab9fca,Memorial Sloan Kettering Cancer Center,"To develop and evaluate a deep learning method to segment parotid glands from MRI using unannotated MRI and unpaired expert-segmented CT datasets. We introduced a new self-derived organ attention deep learning network for combined CT to MRI image-to-image translation (I2I) and MRI segmentation, all trained as an end-to-end network. The expert segmentations available on CT scans were combined with the I2I translated pseudo MR images to train the MRI segmentation network. Once trained, the MRI segmentation network alone is required. We introduced an organ attention discriminator that constrains the CT to MR generator to synthesize pseudo MR images that preserve organ geometry and appearance statistics as in real MRI. The I2I translation network training was regularized using the organ attention discriminator, global image-matching discriminator, and cycle consistency losses. MRI segmentation training was regularized by using cross-entropy loss. Segmentation performance was compared against multiple domain adaptation-based segmentation methods using the Dice similarity coefficient (DSC) and Hausdorff distance at the 95th percentile (HD95). All networks were trained using 85 unlabeled T2-weighted fat suppressed (T2wFS) MRIs and 96 expert-segmented CT scans. Performance upper-limit was based on fully supervised MRI training done using the 85 T2wFS MRI with expert segmentations. Independent evaluation was performed on 77 MRIs never used in training. The proposed approach achieved the highest accuracy (left parotid: DSC 0.82 +/- 0.03, HD95 2.98 +/- 1.01 mm; right parotid: 0.81 +/- 0.05, HD95 3.14 +/- 1.17 mm) compared to other methods. This accuracy was close to the reference fully supervised MRI segmentation (DSC of 0.84 +/- 0.04, a HD95 of 2.24 +/- 0.77 mm for the left parotid, and a DSC of 0.84 +/- 0.06 and HD95 of 2.32 +/- 1.37 mm for the right parotid glands).","unpaired adversarial domain adaptation,deep learning segmentation,organ attention discriminators,MRI,parotid gland",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"HEAD,RADIOTHERAPY",PHYSICS IN MEDICINE AND BIOLOGY,,
38,Automatic multi-needle localization in ultrasound images using large margin mask RCNN for ultrasound-guided prostate brachytherapy,65,20,,"Zhang Yupei);,Tian Zhen);,Lei Yang);,Wang Tonghe);,Patel Pretesh);,Jani Ashesh B.);,Curran Walter J.);,Liu Tian);,Yang Xiaofeng","Zhang YP,Tian Z,Lei Y,Wang TH,Patel P,Jani AB,Curran WJ,Liu T,Yang XF",Yang XF,10.1088/1361-6560/aba410,Emory University,"Multi-needle localization in ultrasound (US) images is a crucial step of treatment planning for US-guided prostate brachytherapy. However, current computer-aided technologies are mostly focused on single-needle digitization, while manual digitization is labor intensive and time consuming. In this paper, we proposed a deep learning-based workflow for fast automatic multi-needle digitization, including needle shaft detection and needle tip detection. The major workflow is composed of two components: a large margin mask R-CNN model (LMMask R-CNN), which adopts the lager margin loss to reformulate Mask R-CNN for needle shaft localization, and a needle based density-based spatial clustering of application with noise algorithm which integrates priors to model a needle in an iteration for a needle shaft refinement and tip detections. Besides, we use the skipping connection in neural network architecture to improve the supervision in hidden layers. Our workflow was evaluated on 23 patients who underwent US-guided high-dose-rate (HDR) prostrate brachytherapy with 339 needles being tested in total. Our method detected 98% of the needles with 0.091 +/- 0.043 mm shaft error and 0.330 +/- 0.363 mm tip error. Compared with only using Mask R-CNN and only using LMMask R-CNN, the proposed method gains a significant improvement on both shaft error and tip error. The proposed method automatically digitizes needles per patient with in a second. It streamlines the workflow of transrectal ultrasound-guided HDR prostate brachytherapy and paves the way for the development of real-time treatment planning system that is expected to further elevate the quality and outcome of HDR prostate brachytherapy.","multi-needle localization,mask RCNN,DBSCAN algorithm,ultrasound images,US-guided HDR prostate brachytherapy,deep learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,RANSAC,PHYSICS IN MEDICINE AND BIOLOGY,,
39,"Evaluating Pu-239(n,f) cross sections via machine learning using experimental data, covariances, and measurement features",978,,,"Whewell B.,Grosskopf M.,Neudecker D.","Whewell B,Grosskopf M,Neudecker D",Whewell B,10.1016/j.nima.2020.164305,University of Notre Dame,"The neutron-induced Pu-239 fission cross section, Pu-239(n,f), is evaluated from 1-20 MeV using experimental data and associated covariances while also considering information on the measurement, termed features here. For instance, methods to determine the background, sample backing material, or impurities in the sample, are explicitly taken into account in the evaluation process. To this end, outliers in the experimental data are identified with a modified version of the Hybrid Robust Support Vector Machine. In a second step, two machine learning methods (logistic regression with elastic net regularization and random forest regression with SHAP feature importance metric) are used to highlight measurement features that are common among many of the outlying data points. Based on this analysis, penalty uncertainties are added to the experimental covariances of outlying data points that have outlier measurement features and are put through the generalized-least-squares evaluation. The resulting evaluated mean values and covariances differ distinctly from those data evaluated without the penalty uncertainties. These results highlight that certain measurement features should be more closely examined.","Nuclear-data evaluation,Machine learning,Pu-239(n,f) cross section,Uncertainty quantification",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Nuclear Science & Technology,Physics",,1.502,"U-235,NEUTRONS,SELECTION,PU-240",NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT,https://www.osti.gov/biblio/1638632,
40,A comparison of machine learning algorithms for assessment of delamination in fiber-reinforced polymer composite beams,20,4,1997-2012,"He Mengyue,Wang Yishou,Ram Ramakrishnan Karthik,Zhang Zhifang","He MY,Wang YS,Ramakrishnan KR,Zhang ZF",Zhang ZF,10.1177/1475921720967157,Guangzhou University,"Structural health monitoring techniques based on vibration parameters have been used to assess the internal delamination damage of fiber-reinforced polymer composites. Recently, machine learning algorithms have been adopted to solve the inverse problem of predicting delamination parameters of the delamination from natural frequency shifts. In this article, a delamination detection methodology is proposed based on the changes in multiple modes of frequencies to assess the interface, location, and size of delamination in fiber-reinforced polymer composites. Three types of machine learning algorithms including back propagation neural network, extreme learning machine, and support vector machine algorithm were adopted as inverse algorithms for assessment of the delamination parameters, with a special focus on the interface prediction. A theoretical model of fiber-reinforced polymer beam with delamination under vibration was constructed to learn how the frequencies are affected by the delaminations (""forward problem"") and to generate a database of ""frequency shifts versus delamination parameters"" to be used in machine learning algorithms for delamination prediction (""inverse problem""). Multiple carbon/epoxy fiber-reinforced polymer beam specimens were manufactured and measured by a laser scanning Doppler vibrometer to extract the modal frequencies. Numerical and experimental verification results have shown that support vector machine has the best prediction performance among the three machine learning algorithms, with high prediction accuracy and only requiring a small number of samples. For predicting the interface of delamination which is a discrete variable, support vector machine classification has observed better prediction accuracy and requiring less running time than regression. This study is one of the first to prove the applicability of support vector machine for structural health monitoring of delamination damage in fiber-reinforced polymer composites and has the potential to improve the prediction capability of machine learning algorithms. Another significant outcome of the study is that the interface of delamination has been predicted accurately with support vector machine.","Structural health monitoring,delamination detection,fiber-reinforced polymer,natural frequency,machine learning,support vector machine",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",,,5.861,"DAMAGE,DETECTION,CLASSIFICATION,IDENTIFICATION,IMPEDANCE,FEATURES",STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL,,
41,,,,,,,,,,,,,,,,,,,,
42,,,,,,,,,,,,,,,,,,,,
43,,,,,,,,,,,,,,,,,,,,
44,A microstructural neural network biomarker for dystonia diagnosis identified by a DystoniaNet deep learning platform,117,42,26398-26405,"Valeriani Davide,Simonyan Kristina","Valeriani D,Simonyan K",Simonyan K,10.1073/pnas.2009165117,Harvard University,"Isolated dystonia is a neurological disorder of heterogeneous pathophysiology, which causes involuntary muscle contractions leading to abnormal movements and postures. Its diagnosis is remarkably challenging due to the absence of a biomarker or gold standard diagnostic test. This leads to a low agreement between clinicians, with up to 50% of cases being misdiagnosed and diagnostic delays extending up to 10.1 y. We developed a deep learning algorithmic platform, DystoniaNet, to automatically identify and validate a microstructural neural network biomarker for dystonia diagnosis from raw structural brain MRIs of 612 subjects, including 392 patients with three different forms of isolated focal dystonia and 220 healthy controls. DystoniaNet identified clusters in corpus callosum, anterior and posterior thalamic radiations, inferior fronto-occipital fasciculus, and inferior temporal and superior orbital gyri as the biomarker components. These regions are known to contribute to abnormal interhemispheric information transfer, heteromodal sensorimotor processing, and executive control of motor commands in dystonia pathophysiology. The DystoniaNet-based biomarker showed an overall accuracy of 98.8% in diagnosing dystonia, with a referral of 3.5% of cases due to diagnostic uncertainty. The diagnostic decision by DystoniaNet was computed in 0.36 s per subject. DystoniaNet significantly outperformed shallow machine-learning algorithms in benchmark comparisons, showing nearly a 20% increase in its diagnostic performance. Importantly, the microstructural neural network biomarker and its DystoniaNet platform showed substantial improvement over the current 34% agreement on dystonia diagnosis between clinicians. The translational potential of this biomarker is in its highly accurate, interpretable, and generalizable performance for enhanced clinical decision-making.","dystonia,biomarker,machine learning,brain MRI",Article,"NATL ACAD SCIENCES, 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA",Science & Technology - Other Topics,,12.291,"VOXEL-BASED,MORPHOMETRY,SPASMODIC,DYSPHONIA,CONSENSUS,STATEMENT,CERVICAL,DYSTONIA,TASK,ACTIVATION,PHENOTYPE,GENOTYPE,DELAYS",PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA,https://www.pnas.org/content/pnas/117/42/26398.full.pdf,
45,Breast ultrasound lesion classification based on image decomposition and transfer learning,47,12,6257-6269,"Zhuang Zhemin,Kang Yuqiang,Raj Alex Noel Joseph,Yuan Ye,Ding Wanli,Qiu Shunmin","Zhuang ZM,Kang YQ,Raj ANJ,Yuan Y,Ding WL,Qiu SM",Raj ANJ,10.1002/mp.14510,Shantou University,"Purpose In medical image analysis, deep learning has great application potential. Discovering a method for extracting valuable information from medical images and integrating that information closely with medical treatment has recently become a major topic of interest. Because obtaining large volumes of breast lesion ultrasound image data is difficult, transfer learning is usually employed to obtain benign and malignant classification of breast lesions. However, because of blurred unclear regions of interest in breast lesion ultrasound images and severe speckle noise interference, convolutional neural networks have proven ineffective in extracting features, thus providing unreliable classification results. Methods This study employs image decomposition to obtain fuzzy enhanced and bilateral filtered images to enrich input information of breast lesions. Fuzzy enhanced, bilateral filtered, and original ultrasound images comprise multifeature data, which are presented as inputs to a pre-trained model to realize knowledge fusion. Therefore, effective features of breast lesions are extracted and then used to train fully connected layers with ground truths provided by a doctor to accomplish the classification. Results A pre-trained VGG16 model was used to extract features from multifeature data, and these features were fused to train the fully connected layers to realize classification. The performance score reported is as follows: accuracy of 93%, sensitivity of 95%, specificity of 88%, F1 score of 0.93, and AUC of 0.97. Conclusions Compared with using a single original ultrasound image for feature extraction, multifeature data based on image decomposition enables the pre-trained model to extract more relevant features, thereby providing better classification results than those from traditional transfer learning techniques.","bilateral filtering,breast lesion ultrasound images,feature extraction,fuzzy enhancement,transfer learning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,,MEDICAL PHYSICS,,
46,Large-Scale Atomic Simulation via Machine Learning Potentials Constructed by Global Potential Energy Surface Exploration,53,10,2119-2129,"Kang Pei-Lin,Shang Cheng,Liu Zhi-Pan","Kang PL,Shang C,Liu ZP",Shang C; Liu ZP,10.1021/acs.accounts.0c00472,Fudan University,"Atomic simulations based on quantum mechanics (QM) calculations have entered into the tool box of chemists over the past few decades, facilitating an understanding of a wide range of chemistry problems, from structure characterization to reactivity determination. Due to the poor scaling and high computational cost intrinsic to QM calculations, one has to either sacrifice accuracy or time when performing large-scale atomic simulations. The battle to find a better compromise between accuracy and speed has been central to the development of new theoretical methods.
The recent advances of machine-learning (ML)-based large-scale atomic simulations has shown great promise to the benefit of many branches of chemistry. Instead of solving the Schrodinger equation directly, ML-based simulations rely on a large data set of accurate potential energy surfaces (PESs) and complex numerical models to predict the total energy. These simulations feature both a high speed and a high accuracy for computing large systems. Due to the lack of a physical foundation in numerical models, ML models are often frustrated in their predictivity and robustness, which are key to applications. Focusing on these concerns, here we overview the recent advances in ML methodologies for atomic simulations on three key aspects. Namely, the generation of a representative data set, the extensity of ML models, and the continuity of data representation. While global optimization methods are the natural choice for building a representative data set, the stochastic surface walking method is shown to provide the desired PES sampling for both minima and transition regions on the PES. The current ML models generally utilize local geometrical descriptors as an input and consider the total energy as the sum of atomic energies. There are many flavors of data descriptors and ML models, but the applications for material and reaction predictions are still limited, not least because of the difficulty to train the associated vast global data sets. We show that our recently designed power-type structure descriptors together with a feed-forward neural network (NN) model are compatible with highly complex global PES data, which has led to a large family of global NN (G-NN) potentials. Two recent applications of G-NN potentials in material and reaction simulations are selected to illustrate how ML-based atomic simulations can help the discovery of new materials and reactions.","PHASE-TRANSITION,STRUCTURE PREDICTION,CHEMICAL UNIVERSE,GLUCOSE PYROLYSIS,WALKING METHOD,OPTIMIZATION,MODEL,SELECTIVITY,MOLECULES,CHEMISTRY",Review,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,22.732,"PHASE-TRANSITION,STRUCTURE,PREDICTION,CHEMICAL,UNIVERSE,GLUCOSE,PYROLYSIS,WALKING,METHOD,OPTIMIZATION,MODEL,SELECTIVITY,MOLECULES,CHEMISTRY",ACCOUNTS OF CHEMICAL RESEARCH,,
47,Parametric study of hydrogenic inventory in the ITER divertor based on machine learning,10,1,,"Delaporte-Mathurin Remi,Hodille Etienne,Mougenot Jonathan,De Temmerman Gregory,Charles Yann,Grisolia Christian","Delaporte-Mathurin R,Hodille E,Mougenot J,De Temmerman G,Charles Y,Grisolia C",Delaporte-Mathurin R,10.1038/s41598-020-74844-w,CEA,"A parametric study is performed with the 2D FESTIM code for the ITER monoblock geometry. The influence of the monoblock surface temperature, the incident ion energy and particle flux on the monoblock hydrogen inventory is investigated. The simulated data is analysed with a Gaussian regression process and an inventory map as a function of ion energy and incident flux is given. Using this inventory map, the hydrogen inventory in the divertor is easily derived for any type of scenario. Here, the case of a detached ITER scenario with inputs from the SOLPS code is presented. For this scenario, the hydrogen inventory per monoblock is highly dependent of surface temperature and ranges from 1018 to 6x1019 H after a 107 s exposure. The inventory evolves as a power law of time and is lower at strike points where the surface temperature is high. Hydrogen inventory in the whole divertor after a 107 s exposure is estimated at approximately 8 g.","DEUTERIUM TRANSPORT,TUNGSTEN,RETENTION,DIFFUSION",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,5.134,"DEUTERIUM,TRANSPORT,TUNGSTEN,RETENTION,DIFFUSION",SCIENTIFIC REPORTS,https://hal.archives-ouvertes.fr/hal-02972436/file/Delaporte-Mathurin_2020.pdf,
48,Quantitative ultrasound radiomics using texture derivatives in prediction of treatment response to neo-adjuvant chemotherapy for locally advanced breast cancer.,11,42,3782-3792,,,,10.18632/oncotarget.27742,,"BACKGROUND: To investigate quantitative ultrasound (QUS) based higher-order texture derivatives in predicting the response to neoadjuvant chemotherapy (NAC) in patients with locally advanced breast cancer (LABC).RESULTS: A KNN-model provided the best results with sensitivity, specificity, accuracy, and area under curve (AUC) of 87%, 81%, 82%, and 0.86, respectively. The most helpful features in separating the two response groups were QUS-Tex1-Tex2 features. The 5-year recurrence-free survival (RFS) calculated for KNN predicted responders and non-responders using QUS-Tex1-Tex2 model were comparable to RFS for the actual response groups.CONCLUSIONS: We report the first study demonstrating QUS texture-derivative methods in predicting NAC responses in LABC, which leads to better results compared to using texture features alone. Copyright:  2020 Dasgupta et al.",breast cancer; neoadjuvant chemotherapy; quantitative ultrasound; radiomics; texture derivatives,Journal Article,,,,,,,,
49,Identification of psychiatric disorder subtypes from functional connectivity patterns in resting-state electroencephalography,5,4,,"Zhang Yu,Wu Wei,Toll Russell T.,Naparstek Sharon,Maron-Katz Adi,Watts Mallissa,Gordon Joseph,Jeong Jisoo,Astolfi Laura,Shpigel Emmanuel","Zhang Y,Wu W,Toll RT,Naparstek S,Maron-Katz A,Watts M,Gordon J,Jeong J,Astolfi L,Shpigel E",Etkin A,10.1038/s41551-020-00614-8,Stanford University,"The understanding and treatment of psychiatric disorders, which are known to be neurobiologically and clinically heterogeneous, could benefit from the data-driven identification of disease subtypes. Here, we report the identification of two clinically relevant subtypes of post-traumatic stress disorder (PTSD) and major depressive disorder (MDD) on the basis of robust and distinct functional connectivity patterns, prominently within the frontoparietal control network and the default mode network. We identified the disease subtypes by analysing, via unsupervised and supervised machine learning, the power-envelope-based connectivity of signals reconstructed from high-density resting-state electroencephalography in four datasets of patients with PTSD and MDD, and show that the subtypes are transferable across independent datasets recorded under different conditions. The subtype whose functional connectivity differed most from those of healthy controls was less responsive to psychotherapy treatment for PTSD and failed to respond to an antidepressant medication for MDD. By contrast, both subtypes responded equally well to two different forms of repetitive transcranial magnetic stimulation therapy for MDD. Our data-driven approach may constitute a generalizable solution for connectome-based diagnosis.
Two clinically relevant subtypes of post-traumatic stress disorder and major depressive disorder have been identified via machine learning analyses of functional connectivity patterns in resting-state electroencephalography.","TRANSCRANIAL MAGNETIC STIMULATION,MAJOR DEPRESSIVE DISORDER,CORTICAL CORRELATION STRUCTURE,PHASE-SYNCHRONIZATION,TREATMENT RESPONSE,VOLUME-CONDUCTION,MEG,THERAPY,EEG,NETWORKS",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Engineering,,26.355,"TRANSCRANIAL,MAGNETIC,STIMULATION,MAJOR,DEPRESSIVE,DISORDER,CORTICAL,CORRELATION,STRUCTURE,PHASE-SYNCHRONIZATION,TREATMENT,RESPONSE,VOLUME-CONDUCTION,MEG,THERAPY,EEG,NETWORKS",NATURE BIOMEDICAL ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8053667,
50,Analogue computing with metamaterials,6,3,207-225,"Zangeneh-Nejad Farzad,Sounas Dimitrios L.,Alu Andrea,Fleury Romain","Zangeneh-Nejad F,Sounas DL,Alu A,Fleury R",Fleury R,10.1038/s41578-020-00243-2,Ecole Polytechnique Federale de Lausanne,"Metamaterials provide a platform to leverage optical signals for performing specific-purpose computational tasks with ultra-fast speeds. This Review surveys the basic principles, recent advances and promising future directions for wave-based-metamaterial analogue computing systems.
Despite their widespread use for performing advanced computational tasks, digital signal processors suffer from several restrictions, including low speed, high power consumption and complexity, caused by costly analogue-to-digital converters. For this reason, there has recently been a surge of interest in performing wave-based analogue computations that avoid analogue-to-digital conversion and allow massively parallel operation. In particular, novel schemes for wave-based analogue computing have been proposed based on artificially engineered photonic structures, that is, metamaterials. Such kinds of computing systems, referred to as computational metamaterials, can be as fast as the speed of light and as small as its wavelength, yet, impart complex mathematical operations on an incoming wave packet or even provide solutions to integro-differential equations. These much-sought features promise to enable a new generation of ultra-fast, compact and efficient processing and computing hardware based on light-wave propagation. In this Review, we discuss recent advances in the field of computational metamaterials, surveying the state-of-the-art metastructures proposed to perform analogue computation. We further describe some of the most exciting applications suggested for these computing systems, including image processing, edge detection, equation solving and machine learning. Finally, we provide an outlook for the possible directions and the key problems for future research.","SPATIAL DIFFERENTIATION,MATHEMATICAL OPERATIONS,PLASMONIC CIRCUIT,LAPLACE OPERATOR,FRACTIONAL-ORDER,SLAB,TIME,METASURFACE,INTEGRATION,RESOLUTION",Review,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Science & Technology - Other Topics,Materials Science",,98.837,"SPATIAL,DIFFERENTIATION,MATHEMATICAL,OPERATIONS,PLASMONIC,CIRCUIT,LAPLACE,OPERATOR,FRACTIONAL-ORDER,SLAB,TIME,METASURFACE,INTEGRATION,RESOLUTION",NATURE REVIEWS MATERIALS,,
51,N2NSR-OCT: Simultaneous denoising and super-resolution in optical coherence tomography images using semisupervised deep learning,14,1,,"Qiu Bin,You Yunfei,Huang Zhiyu,Meng Xiangxi,Jiang Zhe,Zhou Chuanqing,Liu Gangjun,Yang Kun,Ren Qiushi,Lu Yanye","Qiu B,You YF,Huang ZY,Meng XX,Jiang Z,Zhou CQ,Liu GJ,Yang K,Ren QS,Lu YY",Lu YY,10.1002/jbio.202000282,Peking University,"Optical coherence tomography (OCT) imaging shows a significant potential in clinical routines due to its noninvasive property. However, the quality of OCT images is generally limited by inherent speckle noise of OCT imaging and low sampling rate. To obtain high signal-to-noise ratio (SNR) and high-resolution (HR) OCT images within a short scanning time, we presented a learning-based method to recover high-quality OCT images from noisy and low-resolution OCT images. We proposed a semisupervised learning approach named N2NSR-OCT, to generate denoised and super-resolved OCT images simultaneously using up- and down-sampling networks (U-Net (Semi) and DBPN (Semi)). Additionally, two different super-resolution and denoising models with different upscale factors (2xand 4x) were trained to recover the high-quality OCT image of the corresponding down-sampling rates. The new semisupervised learning approach is able to achieve results comparable with those of supervised learning using up- and down-sampling networks, and can produce better performance than other related state-of-the-art methods in the aspects of maintaining subtle fine retinal structures.","denoising,optical coherence tomography,semisupervised deep learning,super-resolution",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Biochemistry & Molecular Biology,Biophysics,Optics",,3.403,"NOISE-REDUCTION,NEURAL-NETWORK,SPECKLE",JOURNAL OF BIOPHOTONICS,,
52,A generative adversarial network-based (GAN-based) architecture for automatic fiducial marker detection in prostate MRI-only radiotherapy simulation images,47,12,6405-6413,"Singhrao Kamal,Fu Jie,Parikh Neil R.,Mikaeilian Argin G.,Ruan Dan,Kishan Amar U.,Lewis John H.","Singhrao K,Fu J,Parikh NR,Mikaeilian AG,Ruan D,Kishan AU,Lewis JH",Lewis JH,10.1002/mp.14498,Cedars Sinai Medical Center,"Purpose Clinical sites utilizing magnetic resonance imaging (MRI)-only simulation for prostate radiotherapy planning typically use fiducial markers for pretreatment patient positioning and alignment. Fiducial markers appear as small signal voids in MRI images and are often difficult to discern. Existing clinical methods for fiducial marker localization require multiple MRI sequences and/or manual interaction and specialized expertise. In this study, we develop a robust method for automatic fiducial marker detection in prostate MRI simulation images and quantify the pretreatment alignment accuracy using automatically detected fiducial markers in MRI. Methods and Materials In this study, a deep learning-based algorithm was used to convert MRI images into labeled fiducial marker volumes. Seventy-seven prostate cancer patients who received marker implantation prior to MRI and CT simulation imaging were selected for this study. Multiple-Echo T-1-VIBE MRI images were acquired, and images were stratified (at the patient level) based on the presence of intraprostatic calcifications. Ground truth (GT) contours were defined by an expert on MRI using CT images. Training was done using the pix2pix generative adversarial network (GAN) image-to-image translation package and model testing was done using fivefold cross validation. For performance comparison, an experienced medical dosimetrist and a medical physicist each manually contoured fiducial markers in MRI images. The percent of correct detections and F(1)classification scores are reported for markers detected using the automatic detection algorithm and human observers. The patient positioning errors were quantified by calculating the target registration errors (TREs) from fiducial marker driven rigid registration between MRI and CBCT images. Target registration errors were quantified for fiducial marker contours defined on MRI by the automatic detection algorithm and the two expert human observers. Results Ninety-six percent of implanted fiducial markers were correctly identified using the automatic detection algorithm. Two expert raters correctly identified 97% and 96% of fiducial markers, respectively. The F(1)classification score was 0.68, 0.75, and 0.72 for the automatic detection algorithm and two human raters, respectively. The main source of false discoveries was intraprostatic calcifications. The mean TRE differences between alignments from automatic detection algorithm and human detected markers and GT were We have developed a deep learning-based approach to automatically detect fiducial markers in MRI-only simulation images in a clinically representative patient cohort. The automatic detection algorithm-predicted markers can allow for patient setup with similar accuracy to independent human observers.","deep learning,fiducial markers,MRI-only simulation,MRI in treatment planning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"GUIDED,RADIOTHERAPY,RADIATION-THERAPY,CANCER,CALCIFICATIONS,VISIBILITY,CNN",MEDICAL PHYSICS,,
53,A neural network constitutive model for hyperelasticity based on molecular dynamics simulations,122,1,5-24,"Chung Ingyun,Im Sunyoung,Cho Maenghyo","Chung I,Im S,Cho M",Cho M,10.1002/nme.6459,Seoul National University (SNU),"Numerical analysis of the hyperelastic behavior of polymer materials has drawn significant interest from within the field of mechanical engineering. Currently, hyperelastic models based on the energy density function, such as the Neo-Hookean, Mooney-Rivlin, and Ogden models, are used to investigate the hyperelastic responses of materials. Conventionally, constants relating to materials were determined from experimental data by using global least-squares fitting. However, formulating a constitutive equation to capture the complex behavior of hyperelastic materials was difficult owing to the limitations of the analytical model and experimental data. This study addresses these limitations by using a system of neural networks (NNs) to design a data-driven surrogate model without a specific function formula, and employs molecular dynamics (MD) simulations to calculate the massive amount of combined loading data of hyperelastic materials. Thus, MD simulations were used to propose an NN constitutive model for hyperelasticity to derive the constitutive equation to model the complex hyperelastic response. In addition, the probability distributions of the numerical solutions of hyperelasticity are used to characterize the uncertainty of the MD models. These statistical finite element results not only present numerical results with reliability ranges but also scattered distributions of the solution obtained from the MD-based probability distributions.","constitutive equations,finite element methods,hyperelasticity,machine learning,molecular dynamics simulations,neural network",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Mathematics",,3.593,"MATERIAL,BEHAVIOR,POLYMER,MELTS,POLYSTYRENE,ELASTICITY,EQUATION",INTERNATIONAL JOURNAL FOR NUMERICAL METHODS IN ENGINEERING,,
54,Detection of Defects in Additively Manufactured Stainless Steel 316L with Compact Infrared Camera and Machine Learning Algorithms,72,12,4244-4253,"Zhang Xin,Saniie Jafar,Heifetz Alexander","Zhang X,Saniie J,Heifetz A",Heifetz A,10.1007/s11837-020-04428-6,United States Department of Energy (DOE),"Additive manufacturing (AM) is an emerging method for cost-efficient fabrication of nuclear reactor parts. AM of metallic structures for nuclear energy applications is currently based on the laser powder bed fusion process, which can introduce internal material flaws, such as pores and anisotropy. Integrity of AM structures needs to be evaluated nondestructively because material flaws could lead to premature failures due to exposure to high temperature, radiation and corrosive environments in a nuclear reactor. Thermal tomography (TT) provides a capability for non-destructive evaluation of sub-surface defects in arbitrary size structures. We investigate TT of AM stainless steel 316L specimens with imprinted internal porosity defects using a relatively low-cost, small form factor infrared camera based on an uncooled micro-bolometer detector. Sparse coding-relatedK-means singular value decomposition machine learning, image processing algorithms are developed to improve the quality of TT images through removal of additive white Gaussian noise without blurring the images.","CORROSION,PHYSICS",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Materials Science,Metallurgy & Metallurgical Engineering,Mineralogy,Mining & Mineral Processing",,2.989,"CORROSION,PHYSICS",JOM,https://www.osti.gov/biblio/1774602,
55,Tool wear estimation in turning of Inconel 718 based on wavelet sensor signal analysis and machine learning paradigms,14,5-6,693-705,"Segreto Tiziana,D'Addona Doriana,Teti Roberto","Segreto T,D'Addona D,Teti R",Segreto T,10.1007/s11740-020-00989-2,University of Naples Federico II,"In the last years, hard-to-machine nickel-based alloys have been widely employed in the aerospace industry for their properties of high strength, excellent resistance to corrosion and oxidation, and long creep life at elevated temperatures. As the machinability of these materials is quite low due to high cutting forces, high temperature development and strong work hardening, during machining the cutting tool conditions tend to rapidly deteriorate. Thus, tool health monitoring systems are highly desired to improve tool life and increase productivity. This research work focuses on tool wear estimation during turning of Inconel 718 using wavelet packet transform (WPT) signal analysis and machine learning paradigms. A multiple sensor monitoring system, based on the detection of cutting force, acoustic emission and vibration acceleration signals, was employed during experimental turning trials. The detected sensor signals were subjected to WPT decomposition to extract diverse signal features. The most relevant features were then selected, using correlation measurements, in order to be utilized in artificial neural network based machine learning paradigms for tool wear estimation.","Inconel 718,Tool wear,Multiple sensor monitoring,Wavelet packet transform,Machine learning,Artificial neural networks",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Engineering,,,"RESIDUAL-STRESS,VECTOR,MACHINE,PERFORMANCE,FUSION,OPTIMIZATION,INTELLIGENCE,SUPERALLOY,INTEGRITY",PRODUCTION ENGINEERING-RESEARCH AND DEVELOPMENT,https://link.springer.com/content/pdf/10.1007/s11740-020-00989-2.pdf,
56,Towards markerless computer-aided surgery combining deep segmentation and geometric pose estimation: application in total knee arthroplasty,9,3,271-278,"Felix Ines,Raposo Carolina,Antunes Michel,Rodrigues Pedro,Barreto Joao P.","Felix I,Raposo C,Antunes M,Rodrigues P,Barreto JP",Felix I,10.1080/21681163.2020.1835554,Universidade de Coimbra,"Total knee arthroplasty (TKA) is a surgical procedure performed in patients suffering from knee arthritis. The correct positioning of the implants is strongly related to multiple surgical variables that have a tremendous impact on the success of the surgery. Computer-based navigation systems have been investigated and developed in order to assist the surgeon in accurately controlling those surgical variables. The existing technologies are very costly, require additional bone incisions for fixing markers to be tracked, and these markers are usually bulky, interfering with the standard surgical flow. This work presents a markerless navigation system that supports the surgeon in accurately performing the TKA procedure. The proposed system uses a mobile RGB-D camera for replacing the existing optical tracking systems and does not require markers to be tracked. We combine an effective deep learning-based approach for accurately segmenting the bone surface with a robust geometry-based algorithm for registering the bones with pre-operative models. The favourable performance of our pipeline is achieved by (1) employing a semi-supervised labelling approach for generating training data from real TKA surgery data, (2) using effective data augmentation techniques for improving the generalisation capability and (3) using appropriate depth data cleaning strategies. The construction of this complete markerless registration prototype that generalises for unseen intra-operative data is non-obvious, and relevant insights and future research directions can be derived. The experimental results show encouraging performance for video-based TKA.","Markerless navigation,deep learning,image segmentation,pose estimation,knee surgery",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,,"OF-THE-ART,NAVIGATION,STATE,TKA",COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION,,
57,A multiple-channel and atrous convolution network for ultrasound image segmentation,47,12,6270-6285,"Zhang Lun,Zhang Junhua,Li Zonggui,Song Yingchao","Zhang L,Zhang JH,Li ZG,Song YC",Zhang JH,10.1002/mp.14512,Yunnan University,"Purpose Ultrasound image segmentation is a challenging task due to a low signal-to-noise ratio and poor image quality. Although several approaches based on the convolutional neural network (CNN) have been applied to ultrasound image segmentation, they have weak generalization ability. We propose an end-to-end, multiple-channel and atrous CNN designed to extract a greater amount of semantic information for segmentation of ultrasound images. Method A multiple-channel and atrous convolution network is developed, referred to as MA-Net. Similar to U-Net, MA-Net is based on an encoder-decoder architecture and includes five modules: the encoder, atrous convolution, pyramid pooling, decoder, and residual skip pathway modules. In the encoder module, we aim to capture more information with multiple-channel convolution and use large kernel convolution instead of small filters in each convolution operation. In the last layer, atrous convolution and pyramid pooling are used to extract multi-scale features. The architecture of the decoder is similar to that of the encoder module, except that up-sampling is used instead of down-sampling. Furthermore, the residual skip pathway module connects the subnetworks of the encoder and decoder to optimize learning from the deeper layer and improve the accuracy of segmentation. During the learning process, we adopt multi-task learning to enhance segmentation performance. Five types of datasets are used in our experiments. Because the original training data are limited, we apply data augmentation (e.g., horizontal and vertical flipping, random rotations, and random scaling) to our training data. We use the Dice score, precision, recall, Hausdorff distance (HD), average symmetric surface distance (ASD), and root mean square symmetric surface distance (RMSD) as the metrics for segmentation evaluation. Meanwhile, Friedman test was performed as the nonparametric statistical analysis to evaluate the algorithms. Results For the datasets of brachia plexus (BP), fetal head, and lymph node segmentations, MA-Net achieved average Dice scores of 0.776, 0.973, and 0.858, respectively; with average precisions of 0.787, 0.968, and 0.854, respectively; average recalls of 0.788, 0.978, and 0.885, respectively; average HDs (mm) of 13.591, 10.924, and 19.245, respectively; average ASDs (mm) of 4.822, 4.152, and 4.312, respectively; and average RMSDs (mm) of 4.979, 4.161, and 4.930, respectively. Compared with U-Net, U-Net++, M-Net, and Dilated U-Net, the average performance of the MA-Net increased by approximately 5.68%, 2.85%, 6.59%, 36.03%, 23.64%, and 31.71% for Dice, precision, recall, HD, ASD, and RMSD, respectively. Moreover, we verified the generalization of MA-Net segmentation to lower grade brain glioma MRI and lung CT images. In addition, the MA-Net achieved the highest mean rank in the Friedman test. Conclusion The proposed MA-Net accurately segments ultrasound images with high generalization, and therefore, it offers a useful tool for diagnostic application in ultrasound images.","atrous convolution,multiple-channel convolution,pyramid pooling,ultrasound image",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"NEURAL-NETWORKS,DEEP",MEDICAL PHYSICS,,
58,Computational materials design: recent advances and open challenges related to colorimetry,136,6,535-538,"Tremeau Alain,Colantoni Philippe,Hebert Mathieu","Tremeau A,Colantoni P,Hebert M",Tremeau A,10.1111/cote.12498,Centre National de la Recherche Scientifique (CNRS),"Computational materials design aims at designing, simulating and predicting innovative materials. This paper reviews a few open challenges in the domain of computational materials design related to the colour appearance of materials. These relatively recent fields of research necessitate revisiting the fundamentals of colorimetry, such as reflectance models. First, we address the virtual design and the simulation of innovative materials, which requires modelling their appearance and fundamental properties. Then we discuss the latest advancements in the machine-learning domain that have highly revolutionised computational and data-minded methodologies, which are used for the design innovation, discovery and optimisation of materials.",MATERIALS DISCOVERY,Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Chemistry,Engineering,Materials Science",,1.737,"MATERIALS,DISCOVERY",COLORATION TECHNOLOGY,,
59,Identification of high-risk carotid plaque with MRI-based radiomics and machine learning,31,5,3116-3126,"Zhang Ranying,Zhang Qingwei,Ji Aihua,Lv Peng,Zhang Jingjing,Fu Caixia,Lin Jiang","Zhang RY,Zhang QW,Ji AH,Lv P,Zhang JJ,Fu CX,Lin J",Lin J,10.1007/s00330-020-07361-z,Fudan University,"Objectives We sought to build a high-risk plaque MRI-based model (HRPMM) using radiomics features and machine learning for differentiating symptomatic from asymptomatic carotid plaques. Materials and methods One hundred sixty-two patients with carotid stenosis were randomly divided into training and test cohorts. Multi-contrast MRI including time of flight (TOF), T1- and T2-weighted imaging, and contrast-enhanced imaging was done. Radiological characteristics of the carotid plaques were recorded and calculated to build a traditional model. After extracting the radiomics features on these images, we constructed HRPMM with least absolute shrinkage and selection operator algorithm in the training cohort and evaluated its performance in the test cohort. A combined model was also built using both the traditional and radiomics features. The performance of all the models in the identification of high-risk carotid plaque was compared. Results Intraplaque hemorrhage and lipid-rich necrotic core were independently associated with clinical symptoms and were used to build the traditional model, which achieved an area under the curve (AUC) of 0.825 versus 0.804 in the training and test cohorts. The HRPMM and the combined model achieved an AUC of 0.988 versus 0.984 and of 0.989 versus 0.986 respectively in the two cohorts. Both the radiomics model and combined model outperformed the traditional model, whereas the combined model showed no significant difference with the HRPMM. Conclusions Our MRI-based radiomics model can accurately distinguish symptomatic from asymptomatic carotid plaques. It is superior to the traditional model in the identification of high-risk plaques.","Magnetic resonance imaging,Stroke,Atherosclerotic plaques,Carotid artery,Machine learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,4.87,"TEXTURE,FEATURES,CANCER,ASSOCIATION,IMAGES,STROKE",EUROPEAN RADIOLOGY,,
60,Towards Hallucinating Machines-Designing with Computational Vision,19,1,88-103,"del Campo Matias,Carlson Alexandra,Manninger Sandra","del Campo M,Carlson A,Manninger S",del Campo M,10.1177/1478077120963366,University of Michigan System,"There are particular similarities in how machines learn about the nature of their environment, and how humans learn to process visual stimuli. Machine Learning (ML), more specifically Deep Neural network algorithms rely on expansive image databases and various training methods (supervised, unsupervised) to ""make sense"" out of the content of an image. Take for example how students of architecture learn to differentiate various architectural styles. Whether this be to differentiate between Gothic, Baroque or Modern Architecture, students are exposed to hundreds, or even thousands of images of the respective styles, while being trained by faculty to be able to differentiate between those styles. A reversal of the process, striving to produce imagery, instead of reading it and understanding its content, allows machine vision techniques to be utilized as a design methodology that profoundly interrogates aspects of agency and authorship in the presence of Artificial Intelligence in architecture design. This notion forms part of a larger conversation on the nature of human ingenuity operating within a posthuman design ecology. The inherent ability of Neural Networks to process large databases opens up the opportunity to sift through the enormous repositories of imagery generated by the architecture discipline through the ages in order to find novel and bespoke solutions to architectural problems. This article strives to demystify the romantic idea of individual artistic design choices in architecture by providing a glimpse under the hood of the inner workings of Neural Network processes, and thus the extent of their ability to inform architectural design. The approach takes cues from the language and methods employed by experts in Deep Learning such as Hallucinations, Dreaming, Style Transfer and Vision. The presented approach is the base for an in-depth exploration of its meaning as a cultural technique within the discipline. Culture in the extent of this article pertains to ideas such as the differentiation between symbolic and material cultures, in which symbols are defined as the common denominator of a specific group of people.(1)The understanding and exchange of symbolic values is inherently connected to language and code, which ultimately form the ingrained texture of any form of coded environment, including the coded structure of Neural Networks. A first proof of concept project was devised by the authors in the form of the Robot Garden. What makes theRobot Gardena distinctively novel project is the motion from a purely two dimensional approach to designing with the aid of Neural Networks, to the exploration of 2D to 3D Neural Style Transfer methods in the design process.","Artificial intelligence,design agency,neural networks,machine learning,machine vision",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Architecture,,,,INTERNATIONAL JOURNAL OF ARCHITECTURAL COMPUTING,,
61,Wireless power transfer-based eddy current non-destructive testing using a flexible printed coil array,378,2182,,"Daura Lawal Umar,Tian GuiYun,Yi Qiuji,Sophian Ali","Daura LU,Tian GY,Yi QJ,Sophian A",Tian GY,10.1098/rsta.2019.0579,Newcastle University - UK,"Eddy current testing (ECT) has been employed as a traditional non-destructive testing and evaluation (NDT&E) tool for many years. It has developed from single frequency to multiple frequencies, and eventually to pulsed and swept-frequency excitation. Recent progression of wireless power transfer (WPT) and flexible printed devices open opportunities to address challenges of defect detection and reconstruction under complex geometric situations. In this paper, a transmitter-receiver (Tx-Rx) flexible printed coil (FPC) array that uses the WPT approach featuring dual resonance responses for the first time has been proposed. The dual resonance responses can provide multiple parameters of samples, such as defect characteristics, lift-offs and material properties, while the flexible coil array allows area mapping of complex structures. To validate the proposed approach, experimental investigations of a single excitation coil with multiple receiving coils using the WPT principle were conducted on a curved pipe surface with a natural dent defect. The FPC array has one single excitation coil and 16 receiving (Rx) coils, which are used to measure the dent by using 21 C-scan points on the dedicated dent sample. The experimental data were then used for training and evaluation of dual resonance responses in terms of multiple feature extraction, selection and fusion for quantitative NDE. Four features, which include resonant magnitudes and principal components of the two resonant areas, were investigated for mapping and reconstructing the defective dent through correlation analysis for feature selection and feature fusion by deep learning. It shows that deep learning-based multiple feature fusion has outstanding performance for 3D defect reconstruction of WPT-based FPC-ECT. This article is part of the theme issue 'Advanced electromagnetic non-destructive evaluation and smart monitoring'.","eddy current testing,flexible coil array,feature extraction,selection and fusion,resonant frequency,wireless power transfer",Article,"ROYAL SOC, 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND",Science & Technology - Other Topics,,4.542,"FEATURE-EXTRACTION,SENSOR,ARRAY,FREQUENCY,PERFORMANCE,DESIGN",PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7536023,
62,Quality Control of Additively Manufactured Metallic Structures with Machine Learning of Thermography Images,72,12,4682-4694,"Zhang Xin,Saniie Jafar,Cleary William,Heifetz Alexander","Zhang X,Saniie J,Cleary W,Heifetz A",Heifetz A,10.1007/s11837-020-04408-w,United States Department of Energy (DOE),"Additive manufacturing (AM) of high-strength metals is currently based on the laser powder bed fusion (LPBF) process, which can introduce internal material flaws, such as pores and anisotropy. Quality control (QC) requires nondestructive evaluation of actual AM structures. Flash thermography is a potentially promising QC technique because it is scalable to arbitrary structure size. However, the detection sensitivity of this method is limited by noise. We investigate separation of signal from noise in thermography images using several machine learning (ML) methods, including new spatial-temporal blind source separation and spatial-temporal sparse dictionary learning methods. Performance of the ML methods is benchmarked using thermography data obtained from imaging stainless steel 316L and Inconel 718 specimens produced by the LPBF method with imprinted calibrated porosity defects. The ML methods are ranked by F-score and execution runtime. The ML methods with higher accuracy require a longer runtime. However, this runtime is sufficiently short to perform QC within a realistic time frame.",,Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Materials Science,Metallurgy & Metallurgical Engineering,Mineralogy,Mining & Mineral Processing",,2.989,,JOM,https://www.osti.gov/biblio/1774562,
63,Machine learning at the interface of structural health monitoring and non-destructive evaluation,378,2182,,"Gardner P.,Fuentes R.,Dervilis N.,Mineo C.,Pierce S. G.,Cross E. J.,Worden K.","Gardner P,Fuentes R,Dervilis N,Mineo C,Pierce SG,Cross EJ,Worden K",Worden K,10.1098/rsta.2019.0581,University of Sheffield,"While both non-destructive evaluation (NDE) and structural health monitoring (SHM) share the objective of damage detection and identification in structures, they are distinct in many respects. This paper will discuss the differences and commonalities and consider ultrasonic/guided-wave inspection as a technology at the interface of the two methodologies. It will discuss how data-based/machine learning analysis provides a powerful approach to ultrasonic NDE/SHM in terms of the available algorithms, and more generally, how different techniques can accommodate the very substantial quantities of data that are provided by modern monitoring campaigns. Several machine learning methods will be illustrated using case studies of composite structure monitoring and will consider the challenges of high-dimensional feature data available from sensing technologies like autonomous robotic ultrasonic inspection. This article is part of the theme issue 'Advanced electromagnetic non-destructive evaluation and smart monitoring'.","ultrasound,structural health monitoring,non-destructive evaluation,machine learning,compressive sensing,transfer learning",Article,"ROYAL SOC, 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND",Science & Technology - Other Topics,,4.542,"DAMAGE,DETECTION,STRATEGIES",PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES,https://iris.unipa.it/retrieve/handle/10447/435293/959504/RSTA-2019-0581.R1_Submitted.pdf,
64,Machine and Deep Learning Based Radiomics Models for Preoperative Prediction of Benign and Malignant Sacral Tumors,10,,,"Yin Ping,Mao Ning,Chen Hao,Sun Chao,Wang Sicong,Liu Xia,Hong Nan","Yin P,Mao N,Chen H,Sun C,Wang SC,Liu X,Hong N",Hong N,10.3389/fonc.2020.564725,Peking University,"Purpose
To assess the performance of deep neural network (DNN) and machine learning based radiomics on 3D computed tomography (CT) and clinical characteristics to predict benign or malignant sacral tumors.
Materials and methods
This single-center retrospective analysis included 459 patients with pathologically proven sacral tumors. After semi-automatic segmentation, 1,316 hand-crafted radiomics features of each patient were extracted. All models were built on training set (321 patients) and tested on validation set (138 patients). A DNN model and four machine learning classifiers (logistic regression [LR], random forest [RF], support vector machine [SVM] and k-nearest neighbor [KNN]) based on CT features and clinical characteristics were built, respectively. The area under the receiver operating characteristic curve (AUC) and accuracy (ACC) were used to evaluate different models.
Results
In total, 459 patients (255 males, 204 females; mean age of 42.1 +/- 17.8 years, range 4-82 years) were enrolled in this study, including 206 cases of benign tumor and 253 cases of malignant tumor. The sex, age and tumor size had significant differences between the benign tumors and malignant tumors (chi(2) (sex) = 10.854, Z(age) = -6.616, Z(size) = 2.843, P < 0.05). The radscore, sex, and age were important indicators for differentiating benign and malignant sacral tumors (odds ratio [OR]1 = 2.492, OR2 = 2.236, OR3 = 1.037, P < 0.01). Among the four clinical-radiomics models (RMs), clinical-LR had the best performance in the validation set (AUC = 0.84, ACC = 0.81). The clinical-DNN model also achieved a high performance (an AUC of 0.83 and an ACC of 0.76 in the validation set) in identifying benign and malignant sacral tumors.
Conclusions
Both the clinical-LR and clinical-DNN models would have a high impact on assisting radiologists in their clinical diagnosis of sacral tumors.","deep learning,radiomics,sacral tumors,machine learning,computed tomography",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Oncology,,6.264,,FRONTIERS IN ONCOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7596901,
65,Classification of magnetic resonance images for brain tumour detection,14,12,2808-2818,"Kurmi Yashwant,Chaurasia Vijayshri","Kurmi Y,Chaurasia V",Kurmi Y,10.1049/iet-ipr.2019.1631,National Institute of Technology (NIT System),"Image segmentation of magnetic resonance image (MRI) is a crucial process for visualisation and examination of abnormal tissues, especially during clinical analysis. Complexity and variations of the tumour structure magnify the challenges in the automated detection of a brain tumour in MRIs. This study presents an automatic lesion recognition method in the MRI followed by classification. In the proposed multistage image segmentation method, the intent region initialisation is performed using low-level information by the keypoint descriptors. A set of the linear filter is used to transform low-level information into higher-level image features. The set of features and filter training data are accomplished to track the tumour region. The authors adopt a possibilistic model for region growing, and disparity map for the refinement process to grave consist boundary. Further, the features are extracted using the Fisher vector and autoencoder. A set of handcrafted features is also extracted using a segmentation-based localised region to train and test the support vector machine and multilayer perceptron classifiers. The experiments that are performed using five MRI datasets confirm the superiority of proposal as that of the state-of-the-art methods. It reports 94.5 and 91.76%, average accuracy of segmentation and classification, respectively.","support vector machines,medical image processing,image segmentation,tumours,biomedical MRI,multilayer perceptrons,feature extraction,image classification,learning (artificial intelligence),brain,low-level information,linear filter,higher-level image features,handcrafted feature extraction,segmentation-based localised region,MRI datasets,magnetic resonance image,automatic lesion recognition method,multistage image segmentation method,automated brain tumour detection,multilayer perceptron classifiers,support vector machine,Fisher vector,disparity map",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"SEGMENTATION,REFINEMENT,ALGORITHM",IET IMAGE PROCESSING,,
66,Deep learning algorithm for breast masses classification in mammograms,14,12,2860-2868,"Gnanasekaran Vaira Suganthi,Joypaul Sutha,Meenakshi Sundaram Parvathy,Chairman Durga Devi","Gnanasekaran VS,Joypaul S,Sundaram PM,Chairman DD",Gnanasekaran VS,10.1049/iet-ipr.2020.0070,"Sethu Inst Technol, Kariapatti, Tamil Nadu, India.","A mammogram is an image of a breast used to detect and diagnose breast cancer. This paper emphases a Computer-Aided Detection system based on convolutional neural network (CNN) that uses the concept of deep learning to classify the mammogram images into benign, malignant and normal. The proposed CNN model consists of eight convolutional, four max-pooling and two fully connected layers and achieved better results compared to the pre-trained nets, AlexNet and VGG16. The proposed model demonstrates the feasibility of using CNNs on medical image processing techniques for the classification of breast masses. The results are also compared with the state-of-the-art machine learning algorithm like kNN classifier. Experimentation is done with three datasets. Among them, two are publicly available, Mammographic Image Analysis Society (MIAS), digital database for screening mammography (DDSM) and an internally collected dataset. The proposed model achieved accuracies of 92.54, 96.47 and 95 and the Area under the ROC curve (AUC) score of 0.85, 0.96 and 0.94 for MIAS, DDSM and the internally collected dataset respectively. Furthermore, the images of the three datasets are merged to build one large set and used to fine tune the proposed CNN model and produced accuracy of 98.32 and AUC of 0.98.","mammography,neural nets,image classification,cancer,learning (artificial intelligence),medical image processing,max-pooling,fully connected layers,pre-trained nets,medical image processing techniques,kNN classifier,Mammographic Image Analysis Society,internally collected dataset,CNN model,deep learning algorithm,breast masses classification,breast cancer,Computer-Aided Detection system,convolutional neural network,mammogram images,automatic classification",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"NEURAL-NETWORKS,SYSTEM",IET IMAGE PROCESSING,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-ipr.2020.0070,
67,Super-resolution image reconstruction using molecular docking,14,12,2922-2936,"Nayak Rajashree,Patra Dipti,Balabantaray Bunil Ku","Nayak R,Patra D,Balabantaray BK",Nayak R,10.1049/iet-ipr.2019.0491,National Institute of Technology (NIT System),"Molecular-docking is an essential tool in the drug designing process, where a small molecule ligand (drug) binds with disease-causing protein molecule to prevent its further activity. Docking process helps in predicting the most appropriate configuration and the optimal interaction energy between the interacting molecules (ligand and protein) to form a stable complex. Based on this idea, a new learning-based single image super-resolution reconstruction (LSI-SRR) method is proposed here. Estimation of a high resolution (HR) patch is achieved by optimising the interaction energy between the input low resolution patch and its corresponding candidate patches appropriately chosen from the training image dataset via Genetic algorithm. Structured-spatiogram based measure; a new and competent similarity criterion is proposed to select potentially efficient training images which encompass better statistical and structural co-relation with the input image. The proposed method is tested on synthetic and real-time images at different magnification factors. Performance analysis of the proposed work is compared with some of the representative state-of-the-art LSI-SRR methods. Experimental results demonstrate that the proposed method produces HR images with enhanced image details, minimal artefacts and most importantly enables an efficient trade-off between the image qualities to speed than the competing methods.","image reconstruction,diseases,image enhancement,molecular biophysics,genetic algorithms,proteins,learning (artificial intelligence),drugs,image resolution,medical image processing,super-resolution image reconstruction,molecular docking,drug designing process,disease-causing protein molecule,docking process,learning-based single image super-resolution reconstruction,high resolution patch,structured-spatiogram based measure,similarity criterion,image enhancement,image qualities,LSI-SRR",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"SIMILARITY,ALGORITHM",IET IMAGE PROCESSING,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-ipr.2019.0491,
68,Errors in Human-Robot Interactions and Their Effects on Robot Learning,7,,,"Kim Su Kyoung,Kirchner Elsa Andrea,Schlossmueller Lukas,Kirchner Frank","Kim SK,Kirchner EA,Schlossmuller L,Kirchner F",Kim SK,10.3389/frobt.2020.558531,German Research Center for Artificial Intelligence (DFKI),"During human-robot interaction, errors will occur. Hence, understanding the effects of interaction errors and especially the effect of prior knowledge on robot learning performance is relevant to develop appropriate approaches for learning under natural interaction conditions, since future robots will continue to learn based on what they have already learned. In this study, we investigated interaction errors that occurred under two learning conditions, i.e., in the case that the robot learned without prior knowledge (cold-start learning) and in the case that the robot had prior knowledge (warm-start learning). In our human-robot interaction scenario, the robot learns to assign the correct action to a current human intention (gesture). Gestures were not predefined but the robot had to learn their meaning. We used a contextual-bandit approach to maximize the expected payoff by updating (a) the current human intention (gesture) and (b) the current human intrinsic feedback after each action selection of the robot. As an intrinsic evaluation of the robot behavior we used the error-related potential (ErrP) in the human electroencephalogram as reinforcement signal. Either gesture errors (human intentions) can be misinterpreted by incorrectly captured gestures or errors in the ErrP classification (human feedback) can occur. We investigated these two types of interaction errors and their effects on the learning process. Our results show that learning and its online adaptation was successful under both learning conditions (except for one subject in cold-start learning). Furthermore, warm-start learning achieved faster convergence, while cold-start learning was less affected by online changes in the current context.","human-robot interaction (HRI),error-related potentials (ErrPs),reinforcement learning,robotics,long-term learning,learning with prior knowledge",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Robotics,,,,FRONTIERS IN ROBOTICS AND AI,https://www.frontiersin.org/articles/10.3389/frobt.2020.558531/pdf,
69,,,,,,,,,,,,,,,,,,,,
70,,,,,,,,,,,,,,,,,,,,
71,,,,,,,,,,,,,,,,,,,,
72,,,,,,,,,,,,,,,,,,,,
73,,,,,,,,,,,,,,,,,,,,
74,Backwash sequence optimization of a pilot-scale ultrafiltration membrane system using data-driven modeling for parameter forecasting,612,,,"Zhang Bopeng,Kotsalis Georgios,Khan Jahanzeb,Xiong Zhaoyang,Igou Thomas,Lan Guanghui,Chen Yongsheng","Zhang BP,Kotsalis G,Khan J,Xiong ZY,Igou T,Lan GH,Chen YS",Chen YS,10.1016/j.memsci.2020.118464,University System of Georgia,"Optimizing the backwashing procedure of ultrafiltration membranes poses novel challenges in regards to the modeling and simulation of the fouling process. Traditional modeling approaches the problem through a physical and chemical understanding of the complicated fouling phenomena. In this study, a large amount of data has been collected from a pilot-scale ultrafiltration membrane system treating spent filter backwash water at a water treatment plant. Environmental variables and operational parameters including temperature, hydraulic pressure, water turbidity, etc. are monitored continuously. This work focuses on revealing the hidden nonlinear relationships of these variables via data driven methodologies without building a first principles process model. Machine learning tools are used to establish a connection between environmental variables, dynamic parameters, the efficiency of foulant removal through backwashing, and the increase rate of foulants. The prediction performance is compared to regression models including linear regression, artificial neural networks, and random forests. Our data driven model of the fouling dynamics is then used for optimization purposes, in particular, to optimize the backwashing sequence timing by applying tools from stochastic dynamic programming. Optimized backwash performance is compared with experimental data acquired via a fixed interval sequence and shows a more efficient schedule at less cost and with lower membrane resistance. This work establishes a full pipeline of data processing, model building, and operational optimization. The only requirement for employing our methodology is the collection of operational data, in order to identify the membrane dynamics. The reported methodology offers a great potential for implementation on large-scale ultrafiltration applications, which can improve energy consumption and elongate membrane life.","Ultrafiltration membrane,Pilot-scale experiment,Data-driven modeling,System optimization,Membrane backwash",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Polymer Science",,8.411,"EXTRACELLULAR,POLYMERIC,SUBSTANCES,WATER-TREATMENT,ARTIFICIAL-INTELLIGENCE,HOLLOW-FIBER,MICROFILTRATION,COMMUNITY",JOURNAL OF MEMBRANE SCIENCE,,
75,Recognition Research on Concealing Behavior in Psychological Test,56,20,158-164,",,,,,,","Zhao Tong,Huang Zheng,Wang Xiuchao,Li Miao,Zhang Yun,Zheng Xiujuan,Liu Kai",,,Zhao Tong,"Electrocorticogram(EEG)can reveal people's psychological activities correctly,so EEG is widely used in psychological test.In this paper,a method based on the nonlinear feature fusion of EEG signals for concealing behavior recognition in the psychological test is presented.First,after pre-processing the EEG signals of the subject obtained in the psychological test,four nonlinear features,including Lempel-Ziv Complexity(LZC),Sample Entropy(SE),Permutation Entropy(PE)and Fuzzy Entropy(FE),are extracted.Then,the fusion and dimensionality reduction of the features by Multidimensional Scaling(MDS)is done.Finally,the Regularization Kernel Extreme Learning Machine(RKELM)is applied to construct the classifier and the performance of the four trained classifiers is verified by the test set.The experimental results show that the accuracy of the proposed system is 82.9%,which indicate the applicability of the proposed method.",concealing behavior; nonlinear feature; dimensionality reduction of multidimensional scaling; regularization kernel extreme learning machine,Article,,,,,,,,
76,Prediction of methane adsorption in shale: Classical models and machine learning based models,278,,,"Meng Meng,Zhong Ruizhi,Wei Zhili","Meng M,Zhong RZ,Wei ZL",Meng M,10.1016/j.fuel.2020.118358,United States Department of Energy (DOE),"Shale gas contributes significantly to current global energy consumption, and an accurate estimation of geological gas-in-place (GIP) determines an optimal production plan. As the dominant form of storage, adsorbed gas in shale formation is of primary importance to be assessed. This paper summarizes adsorption models into traditional pressure/density dependent isothermal models, pressure and temperature unified model, and machine learning based models. Using a comprehensive experimental dataset, these models are applied to simulate shale gas adsorption under in-situ conditions. Results show that the modified Dubinin-Radushkevich (DR) model provides the optimal performance in traditional isothermal models. Pressure and temperature unified models make a breakthrough in isothermal conditions and can extrapolate the predictions beyond test ranges of temperature. Well-trained machine learning models not only break the limit of the isothermal condition and types of shale formation, but can also provide reasonable extrapolations beyond test ranges of temperature, total organic carbon (TOC), and moisture. Four popular machine learning algorithms are used, which include artificial neural network (ANN), random forest (RF), support vector machine (SVM), and extreme gradient boosting (XGBoost). The XGBoost model is found to provide the best results for predicting shale gas adsorption, and it can be conveniently updated for broader applications with more available data. Overall, this paper demonstrates the capability of machine learning for prediction of shale gas adsorption, and the well-trained model can potentially be built into a large numerical frame to optimize production curves of shale gas.","Shale gas,Adsorption model,Classical model,Machine learning,XGBoost",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Energy & Fuels,Engineering",,6.63,"SUPERCRITICAL,METHANE,HIGH-PRESSURE,RESERVOIRS,EQUATION,COAL",FUEL,,
77,A Comparative Analysis of Machine Learning classifiers for Dysphonia-based classification of Parkinson's Disease,11,1,69-83,"Goyal Jinee,Khandnor Padmavati,Aseri Trilok Chand","Goyal J,Khandnor P,Aseri TC",Goyal J,10.1007/s41060-020-00234-0,Punjab Engineering College (Deemed University),"Parkinson's Disease is the second most common neurogenerative disease that affects the nervous system. There is no permanent cure for this disease, so, its early diagnosis is important to improve the quality of living of Parkinson patients. The distortion of the voice is one of the first symptoms to appear in Parkinson patients. Therefore, comparison and classification plays an important role. In this paper, a comparison of various classification techniques is done to show the potential of each classifier. The various classification techniques include SVM (Linear, RBF, Polynomial), DT, RF, LR, KNN, NB, MLP, AdaBoost, and XGBoost. Three different types of feature selection techniques are also explored to reduce the dimensionality of the dataset without affecting the accuracy much. The three different feature selection techniques include mRMR, GA, and PCA. The potential of voice features in classification process is also shown.","Parkinson's disease,Machine learning,Deep learning,Feature selection,Dimensionality reduction",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Computer Science,,,"SOCIETY-SPONSORED,REVISION,SCALE,MDS-UPDRS,FEATURE-SELECTION,ALGORITHMS,DIAGNOSIS,PERFORMANCE,PATTERNS,RANKING",INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS,,
78,Extracting Lungs from CT Images via Deep Convolutional Neural Network Based Segmentation and Two-Pass Contour Refinement,33,6,1465-1478,"Liu Caixia,Pang Mingyong","Liu CX,Pang MY",Pang MY,10.1007/s10278-020-00388-0,Nanjing Normal University,"Lung segmentation is a key step of thoracic computed tomography (CT) image processing, and it plays an important role in computer-aided pulmonary disease diagnostics. However, the presence of image noises, pathologies, vessels, individual anatomical varieties, and so on makes lung segmentation a complex task. In this paper, we present a fully automatic algorithm for segmenting lungs from thoracic CT images accurately. An input image is first spilt into a set of non-overlapping fixed-sized image patches, and a deep convolutional neural network model is constructed to extract initial lung regions by classifying image patches. Superpixel segmentation is then performed on the preprocessed thoracic CT image, and the lung contours are locally refined according to corresponding superpixel contours with our adjacent point statistics method. Segmented lung contours are further globally refined by an edge direction tracing technique for the inclusion of juxta-pleural lesions. Our algorithm is tested on a group of thoracic CT scans with interstitial lung diseases. Experiments show that our algorithm creates an average Dice similarity coefficient of 97.95% and Jaccard's similarity index of 94.48%, with 2.8% average over-segmentation rate and 3.3% under-segmentation rate compared with manually segmented results. Meanwhile, it shows better performance compared with several feature-based machine learning methods and current methods on lung segmentation.","Lung segmentation,Deep convolutional neural network,Superpixel segmentation,Contour correction",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"PATHOLOGICAL,LUNG,NODULE,DETECTION,THORACIC,CT,MODELS",JOURNAL OF DIGITAL IMAGING,,
79,A deep learning approach for prediction of syngas lower heating value from CFB gasifier in Aspen plus (R),209,,,"Kartal Furkan,Ozveren Ugur","Kartal F,Ozveren U",Ozveren U,10.1016/j.energy.2020.118457,Marmara University,"Aspen Plus (R) is one of the practicable software for investigation of the biomass gasification characteristics. Also, artificial neural networks (ANN) as a deep learning approach are often used in the prediction of parameters such as syngas composition, lower heating value (LHV), exergy, etc. However, to our best knowledge, a universal deep learning model based on the thermodynamic equilibrium approach to predict LHV of syngas in circulating fluidized bed (CFB) gasifier is not available in literature yet. In this paper, a unique CFB gasifier model was developed in Aspen Plus (R) as a tool to create a total of over 1 million datasets for the training of a deep learning model that predicts the LHV of the syngas. The CFB gasifier model was found to be in agreement with the results when compared with the experimental data in the literature. 56 biomass with various elemental and proximate properties were gasified in a newly developed CFB gasifier model under different operating conditions by using sensitivity analysis in Aspen Plus (R). A novel artificial neural network model, which is regularized with Levenberg-Marquardt algorithm was used as a deep learning model with a 6-12-1 tangent sigmoid architecture to predict LHV of syngas in circulating fluidized bed (CFB) gasifier, requiring minimal specificity as compared to commercial simulators require significant modelling effort and test runs. Results showed that the estimated LHV of the syngas in an agreement with the calculated values. The coefficient of determination score was calculated as R-2 > 0.99 for all datasets. (C) 2020 Elsevier Ltd. All rights reserved.","Biomass gasification,Deep learning,Circulating fluidized bed gasifier,Artificial neural network,Lower heating value,Aspen plus (R)",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Thermodynamics,Energy & Fuels",,6.845,"GIBBS,ENERGY,MINIMIZATION,FLUIDIZED-BED,REACTOR,BIOMASS,GASIFICATION,HYDROGEN-PRODUCTION,STEAM,GASIFICATION,CO-GASIFICATION,PART,I,SIMULATION,MODEL,EQUILIBRIUM",ENERGY,,
80,Machine learning in composites manufacturing: A case study of Automated Fiber Placement inspection,250,,,"Sacco Christopher,Radwan Anis Baz,Anderson Andrew,Harik Ramy,Gregory Elizabeth","Sacco C,Radwan AB,Anderson A,Harik R,Gregory E",Harik R,10.1016/j.compstruct.2020.112514,University of South Carolina System,"The large-scale adoption of composite materials in industry has allowed for a greater freedom in design and function of structures and their respective components. However, the freedom of material choice has resulted in increased complexity in manufacturing. Machine learning (ML) and Artificial Intelligence (AI) are currently being explored for a number of advanced manufacturing applications, and their applicability has begun to extend into the composites manufacturing realm. In this document, a comprehensive overview of machine learning applications in composites manufacturing will be presented with discussions on a novel inspection software developed for the Automated Fiber Placement (AFP) process at the University of South Carolina utilizing an ML vision system. This vision system allows for defect data to be fully integrated into the manufacturing process, allowing for the ML inspection system to influence several chains in the composites product lifecycle management.","Automated Fiber Placement,Inspection,Machine learning",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Mechanics,Materials Science",,5.536,"NEURAL-NETWORK,GENETIC,ALGORITHM,OPTIMIZATION,DESIGN,COMPONENT,PREDICTION,SYSTEM,AFP",COMPOSITE STRUCTURES,,
81,Deep learning-based method for reducing residual motion effects in diffusion parameter estimation,85,4,2278-2293,"Gong Ting,Tong Qiqi,Li Zhiwei,He Hongjian,Zhang Hui,Zhong Jianhui","Gong T,Tong QQ,Li ZW,He HJ,Zhang H,Zhong JH",He HJ,10.1002/mrm.28544,Zhejiang University,"Purpose Conventional motion-correction techniques for diffusion MRI can introduce motion-level-dependent bias in derived metrics. To address this challenge, a deep learning-based technique was developed to minimize such residual motion effects. Methods The data-rejection approach was adopted in which motion-corrupted data are discarded before model-fitting. A deep learning-based parameter estimation algorithm, using a hierarchical convolutional neural network (H-CNN), was combined with motion assessment and corrupted volume rejection. The method was designed to overcome the limitations of existing methods of this kind that produce parameter estimations whose quality depends strongly on a proportion of the data discarded. Evaluation experiments were conducted for the estimation of diffusion kurtosis and diffusion-tensor-derived measures at both the individual and group levels. The performance was compared with the robust approach of iteratively reweighted linear least squares (IRLLS) after motion correction with and without outlier replacement. Results Compared with IRLLS, the H-CNN-based technique is minimally sensitive to motion effects. It was tested at severe motion levels when 70% to 90% of the data are rejected and when random motion is present. The technique had a stable performance independent of the numbers and schemes of data rejection. A further test on a data set from children with attention-deficit hyperactivity disorder shows the technique can potentially ameliorate spurious group-level difference caused by head motion. Conclusion This method shows great potential for reducing residual motion effects in motion-corrupted diffusion-weighted-imaging data, bringing benefits that include reduced bias in derived metrics in individual scans and reduced motion-level-dependent bias in population studies employing diffusion MRI.","diffusion kurtosis imaging,diffusion tensor imaging,head motion,neural network",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"LINEAR,LEAST-SQUARES,ROBUST,ESTIMATION,DISTORTION,CORRECTION,HEAD,MOTION,TENSOR,MRI,MOVEMENT,ARTIFACTS,FRAMEWORK,ACCURATE",MAGNETIC RESONANCE IN MEDICINE,https://discovery.ucl.ac.uk/id/eprint/10115261/3/Gong_Main-MRM-20-21048-clean.pdf,
82,Digital mapping of soil parent material in a heterogeneous tropical area,367,,,"Bonfatti Benito R.,Dematte Jose A. M.,Marques Karina P. P.,Poppiel Raul R.,Rizzo Rodnei,Mendes Wanderson de S.,Silvero Nelida E. Q.,Safanelli Jose L.","Bonfatti BR,Dematte JAM,Marques KPP,Poppiel RR,Rizzo R,Mendes WD,Silvero NEQ,Safanelli JL",Dematte JAM,10.1016/j.geomorph.2020.107305,Universidade de Sao Paulo,"Parent material is one of the five factors in soil formation. Studies on parent material allow interpreting soil genesis processes and improve our knowledge of specific soil attributes. However, soil parent material maps at detailed cartographic scale (finer than 1:100,000) are rare in tropical areas and it is usually inferred from poorly detailed geological data, which generally group different lithologies into single units. Thus, we propose a methodology to map soil parent material based on remote sensing and machine learning in a geologically very complex area. The study site covers 1378 km(2) in Sao Paulo State, Brazil. Prediction models used data from 280 geological observation points, a digital elevation model (spatial resolution of 5 m, upscale to 30 m) and multitemporal Landsat images in a range of 30 years. We evaluated six classification algorithms, namely random forest, decision tree, support vector machine, multinomial logistic regression, K-means (unsupervised classification), and object-based image analysis with maximum likelihood classification. Environmental covariates were grouped to create different scenarios combining terrain derivatives, hydrologic covariates, topsoil spectral reflectance, and spatial coordinates. A bare soil image, elaborated using 30 years of Landsat data, was evaluated as a covariate to predict soil parent material. Predictions were validated using three different strategies: crossvalidation, separate validation dataset (20%), and comparison with legacy geological maps (information from two areas with geological maps at fine scale). We also assessed the correspondence between the map of predicted soil parent material and data of soil particle size from 571 soil sampling points. Random forest algorithm presented the best validation performance, whereas the group of terrain derivatives and hydrologic covariates explained most of model variation. The produced parent material map was coherent with the spatial distribution of soil particle size across the study area. (C) 2020 Elsevier B.V. All rights reserved.","Soil formation factors,Bare soil image,Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Physical Geography,Geology",,4.623,"REGION,CLASSIFICATION,REFLECTANCE,HEMATITE,GOETHITE,BASIN",GEOMORPHOLOGY,,
83,A deep learning model to predict dose-volume histograms of organs at risk in radiotherapy treatment plans,47,11,5467-5481,"Liu Zhiqiang,Chen Xinyuan,Men Kuo,Yi Junlin,Dai Jianrong","Liu ZQ,Chen XY,Men K,Yi JL,Dai JR",Dai JR,10.1002/mp.14394,Chinese Academy of Medical Sciences - Peking Union Medical College,"Purpose To develop a deep learning-based model to predict achievable dose-volume histograms (DVHs) of organs at risk (OARs) for automation of inverse planning. Methods The model was based on a connected residual deconvolution network (CResDevNet) and compared with UNet as a baseline. The DVHs of OARs are dependent on patient anatomical features of the planning target volumes and OARs, and these spatial relationships can be learned automatically from prior high-quality plans. The contours of planning target volumes and OARs were parsed from the plan database and used as the input to the model, and the dose-area histograms (DAHs) of the OARs were output from the model. The model was trained from scratch by correlating anatomical features with DAHs of OARs, then accumulating these histograms to obtain the final predicted DVH for each OAR. Helical tomotherapy plans for 170 nasopharyngeal cancer patients were used to train and validate the model. An additional 60 patient treatment plans were used to test the predictive accuracy of the model. The DVHs and dose-volume indices (DVIs) of clinical interest for each OAR in the testing dataset were predicted to evaluate the accuracy of the models. The mean absolute errors in the DVIs for each OAR were calculated using each model and statistically compared using a paired-samplest-test. Dice similarity coefficients for areas of the DVHs were also evaluated. Results Dose-volume histograms of 21 OARs in nasopharyngeal cancer were predicted using the models. For each patient, 63 DVIs for all OARs were calculated. Using the 60 patient treatment plans in the testing dataset, 79% and 73% of the DVIs predicted using the CResDevNet and UNet models, respectively, were within 5% of the clinical values. The median value of the DVIs' mean absolute errors was 3.2 +/- 2.5% and 3.7 +/- 2.9% for the CResDevNet and UNet models, respectively. The average dice similarity coefficient for all OARs was 0.965 using the CResDevNet model and 0.958 using the UNet model. Conclusions A deep learning model was developed for predicting achievable DVHs of OARs. The prediction accuracy of the CResDevNet model was evaluated using a planning database of nasopharyngeal cancer cases and shown to be more accurate than the UNet model. Prediction accuracy was also higher for larger-volume OARs. The model can be used for automation of inverse planning and quality assessment of individual treatment plans.","dose-volume histogram,deep learning,dose-area histogram,inverse planning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"AT-RISK,THERAPY,CANCER,HEAD",MEDICAL PHYSICS,,
84,Improving the slice interaction of 2.5D CNN for automatic pancreas segmentation,47,11,5543-5554,"Zheng Hao,Qian Lijun,Qin Yulei,Gu Yun,Yang Jie","Zheng H,Qian LJ,Qin YL,Gu Y,Yang J",Gu Y; Yang J,10.1002/mp.14303,Shanghai Jiao Tong University,"Purpose Volumetric pancreas segmentation can be used in the diagnosis of pancreatic diseases, the research about diabetes and surgical planning. Since manual delineation is time-consuming and laborious, we develop a deep learning-based framework for automatic pancreas segmentation in three dimensional (3D) medical images. Methods A two-stage framework is designed for automatic pancreas delineation. In the localization stage, a Square Root Dice loss is developed to handle the trade-off between sensitivity and specificity. In refinement stage, a novel 2.5D slice interaction network with slice correlation module is proposed to capture the non-local cross-slice information at multiple feature levels. Also a self-supervised learning-based pre-training method, slice shuffle, is designed to encourage the inter-slice communication. To further improve the accuracy and robustness, ensemble learning and a recurrent refinement process are adopted in the segmentation flow. Results The segmentation technique is validated in a public dataset (NIH Pancreas-CT) with 82 abdominal contrast-enhanced 3D CT scans. Fourfold cross-validation is performed to assess the capability and robustness of our method. The dice similarity coefficient, sensitivity, and specificity of our results are 86.21 +/- 4.37%, 87.49 +/- 6.38% and 85.11 +/- 6.49% respectively, which is the state-of-the-art performance in this dataset. Conclusions We proposed an automatic pancreas segmentation framework and validate in an open dataset. It is found that 2.5D network benefits from multi-level slice interaction and suitable self-supervised learning method for pre-training can boost the performance of neural network. This technique could provide new image findings for the routine diagnosis of pancreatic disease.","2,5D slice interaction network,pancreas segmentation,slice shuffle,Square Root Dice loss",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,,MEDICAL PHYSICS,,
85,Self-contained deep learning-based boosting of 4D cone-beam CT reconstruction,47,11,5619-5631,"Madesta Frederic,Sentker Thilo,Gauer Tobias,Werner Rene","Madesta F,Sentker T,Gauer T,Werner R",Madesta F,10.1002/mp.14441,University of Hamburg,"Purpose Four-dimensional cone-beam computed tomography (4D CBCT) imaging has been suggested as a solution to account for interfraction motion variability of moving targets like lung and liver during radiotherapy (RT) of moving targets. However, due to severe sparse view sampling artifacts, current 4D CBCT data lack sufficient image quality for accurate motion quantification. In the present paper, we introduce a deep learning-based framework for boosting the image quality of 4D CBCT image data that can be combined with any CBCT reconstruction approach and clinical 4D CBCT workflow. Methods Boosting is achieved by learning the relationship between so-called sparse view pseudo-time-average CBCT images obtained by a projection selection scheme introduced to mimic phase image sparse view artifact characteristics and corresponding time-average CBCT images obtained by full view reconstruction. The employed convolutional neural network architecture is the residual dense network (RDN). The underlying hypothesis is that the RDN learns the appearance of the streaking artifacts that is typical for 4D CBCT phase images - and removes them without influencing the anatomical image information. After training the RDN, it can be applied to the 4D CBCT phase images to enhance the image quality without affecting the contained temporal and motion information. Different to existing approaches, no patient-specific prior knowledge about anatomy or motion characteristics is needed, that is, the proposed approach is self-contained. Results Application of the trained network to reconstructed phase images of an external (SPARE challenge) as well as in-house 4D CBCT patient and motion phantom data set reduces the phase image streak artifacts consistently for all patients and state-of-the-art reconstruction approaches. Using the SPARE data set, we show that the root mean squared error compared to ground truth data provided by the challenge is reduced by approximately 50% while normalized cross correlation of reconstruction and ground truth is improved up to 10%. Compared to direct deep learning-based 4D CBCT to 4D CT mapping, our proposed method performs better because inappropriate prior knowledge about the patient anatomy and physiology is taken into account. Moreover, the image quality enhancement leads to more plausible motion fields estimated by deformable image registration (DIR) in the 4D CBCT image sequences. Conclusions The presented framework enables significantly boosting of 4D CBCT image quality as well as improved DIR and motion field consistency. Thus, the proposed method facilitates extraction of motion information from severely artifact-affected images, which is one of the key challenges of integrating 4D CBCT imaging into RT workflows.","4D cone-beam computed tomography,artifact reduction,deep learning,image reconstruction,image registration,image quality",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,,"RADIATION-THERAPY,RESPIRATORY,MOTION,LIVER,RADIOTHERAPY,QUALITY,MODEL",MEDICAL PHYSICS,https://aapm.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mp.14441,
86,Supervised machine learning of thermal comfort under different indoor temperatures using EEG measurements,225,,,"Shan Xin,Yang En-Hua","Shan X,Yang EH",Yang EH,10.1016/j.enbuild.2020.110305,Nanyang Technological University & National Institute of Education (NIE) Singapore,"In this paper, machine learning techniques in conjunction with passive EEG (electroencephalogram) measurement were explored to classify occupants' real-time thermal comfort states, which have the potential in the future for energy saving through adopting time varying set points when real-time changes in thermal comfort can require less energy input. The performances of different machine learning techniques were compared, and the method to select linear continuous features for class interpolation was also explored. For the full-set features, the performances of different classifiers were satisfactory, with classification rates all above 90%. The LDA classifier had the best performance. The second best was the NB classifier, and the relatively worst was the KNN classifier. The linear continuous EEG features were selected by interpolation and can be found for all human subjects. Higher selection threshold led to less selected features but higher average performance of these features. In general, the EEG based machine learning methods can classify occupants' real-time thermal comfort states, and could potentially lead to more building energy saving through comfort-driven time varying set points. (C) 2020 Elsevier B.V. All rights reserved.","Machine learning,electroencephalogram (EEG),Supervised learning,Thermal comfort,Human sensing",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Construction & Building Technology,Energy & Fuels,Engineering",,6.175,"HUMAN-BUILDING,INTERACTION,EMOTION,RECOGNITION,ADAPTATION,OFFICE,CLASSIFICATION,PRODUCTIVITY,QUALITY",ENERGY AND BUILDINGS,,
87,Machine Learning-Guided Three-Dimensional Printing of Tissue Engineering Scaffolds,26,23-24,1359-1368,"Conev Anja,Litsa Eleni E.,Perez Marissa R.,Diba Mani,Mikos Antonios G.,Kavraki Lydia E.","Conev A,Litsa EE,Perez MR,Diba M,Mikos AG,Kavraki LE",Kavraki LE,10.1089/ten.tea.2020.0191,Rice University,"Various material compositions have been successfully used in 3D printing with promising applications as scaffolds in tissue engineering. However, identifying suitable printing conditions for new materials requires extensive experimentation in a time and resource-demanding process. This study investigates the use of Machine Learning (ML) for distinguishing between printing configurations that are likely to result in low-quality prints and printing configurations that are more promising as a first step toward the development of a recommendation system for identifying suitable printing conditions. The ML-based framework takes as input the printing conditions regarding the material composition and the printing parameters and predicts the quality of the resulting print as either ""low"" or ""high."" We investigate two ML-based approaches: a direct classification-based approach that trains a classifier to distinguish between low- and high-quality prints and an indirect approach that uses a regression ML model that approximates the values of a printing quality metric. Both modes are built upon Random Forests. We trained and evaluated the models on a dataset that was generated in a previous study, which investigated fabrication of porous polymer scaffolds by means of extrusion-based 3D printing with a full-factorial design. Our results show that both models were able to correctly label the majority of the tested configurations while a simpler linear ML model was not effective. Additionally, our analysis showed that a full factorial design for data collection can lead to redundancies in the data, in the context of ML, and we propose a more efficient data collection strategy.
Impact statement This study investigates the use of Machine Learning (ML) for predicting the printing quality given the printing conditions in extrusion-based 3D printing of biomaterials. Classification and regression methods built upon Random Forests show promise for the development of a recommendation system for identifying suitable printing conditions reducing the amount of required experimentation. This study also gives insights on developing an efficient strategy for collecting data for training ML models for predicting printing quality in extrusion-based 3D printing of biomaterials.","3D printing,biomaterials,tissue engineering,machine learning,random forests,printing quality prediction",Article,"MARY ANN LIEBERT, INC, 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA","Cell Biology,Engineering,Materials Science",,4.322,"OPTIMIZATION,EXTRUSION",TISSUE ENGINEERING PART A,,
88,A Machine Learning Model on Simple Features for CO2 Reduction Electrocatalysts,124,41,22471-22478,"Chen An,Zhang Xu,Chen Letian,Yao Sai,Zhou Zhen","Chen A,Zhang X,Chen LT,Yao S,Zhou Z",Zhang X; Zhou Z,10.1021/acs.jpcc.0c05964,Nankai University,"Electroreduction of CO2 is one of the most potential ways to realize CO2 recycle and energy regeneration. The key to promoting this technology is the development of high-performance electrocatalysts. Generally, high-throughput computational screening contributes a lot to materials innovation, but still consumes much time and resource. To achieve efficient exploration of electrocatalysts for CO2 reduction, we created a machine learning model based on an extreme gradient boosting regression (XGBR) algorithm and simple features. Our screening model successfully and rapidly predicted the Gibbs free energy change of CO adsorption (Delta G(CO)) of 1060 atomically dispersed metal-nonmetal codoped graphene systems, and greatly reduced the research cost. The competitive reaction, the hydrogen evolution reaction (HER), is also discussed with respect to such a screening model. This work demonstrates the potential of machine learning methods and provides a convenient approach for the effective theoretical design of electrocatalysts for CO2 reduction.","DENSITY-FUNCTIONAL THEORY,ELECTROREDUCTION,ATOM,CATALYSTS,DISCOVERY,METHANE,DESIGN,ALLOY",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,4.467,"DENSITY-FUNCTIONAL,THEORY,ELECTROREDUCTION,ATOM,CATALYSTS,DISCOVERY,METHANE,DESIGN,ALLOY",JOURNAL OF PHYSICAL CHEMISTRY C,,
89,Combining Machine Learning Potential and Structure Prediction for Accelerated Materials Design and Discovery,11,20,8710-8720,"Tong Qunchao,Gao Pengyue,Liu Hanyu,Xie Yu,Lv Jian,Wang Yanchao,Zhao Jijun","Tong QC,Gao PY,Liu HY,Xie Y,Lv J,Wang YC,Zhao JJ",Xie Y; Lv J,10.1021/acs.jpclett.0c02357,Jilin University,"The theoretical structure prediction method via quantum mechanical atomistic simulations such as density functional theory (DFT), based solely on chemical composition, has already become a routine tool to determine the structures of physical and chemical systems, e.g., solids and clusters. However, the application of DFT to more realistic simulations, to a large extent, is impeded because of the unfavorable scaling of the computational cost with respect to the system size. During recent years, the machine learning potential (MLP) method has been rapidly rising as an accurate and efficient tool for atomistic simulations. In this Perspective, we provide an introduction to the basic principles and advantages of the combination of structure prediction and MLP, as well as the challenges and opportunities associated with this promising approach.","NEURAL-NETWORK POTENTIALS,EVOLUTIONARY ALGORITHM,GLOBAL OPTIMIZATION,CLUSTERS,LANTHANUM",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,7.643,"NEURAL-NETWORK,POTENTIALS,EVOLUTIONARY,ALGORITHM,GLOBAL,OPTIMIZATION,CLUSTERS,LANTHANUM",JOURNAL OF PHYSICAL CHEMISTRY LETTERS,,
90,Element Code from Pseudopotential as Efficient Descriptors for a Machine Learning Model to Explore Potential Lead-Free Halide Perovskites,11,20,8914-8921,"Jao Meng-Huan,Chan Shun-Hsiang,Wu Ming-Chung,Lai Chao-Sung","Jao MH,Chan SH,Wu MC,Lai CS",Wu MC; Lai CS,10.1021/acs.jpclett.0c02393,Chang Gung University,"The rapid development of machine learning has proven its potential in material science. To acquire an accurate and promising result, the choice of descriptor plays an essential role in dictating the model performance. In this work, we introduce a set of novel descriptors, Element Code, which is generated from pseudopotential. Using a variational autoencoder to perform unsupervised learning, the produced Element Code is verified to contain representative information on elements. Attributed to the successful extraction of information from pseudopotential, Element Code can serve as the primary descriptor for the machine learning model. We construct a model using Element Code as the sole descriptor to predict the bandgap of a lead-free double halide perovskite, and an accuracy of 0.951 and mean absolute error of 0.266 eV are achieved. We believe our work can offer insights into selecting lead-free halide perovskites and establish a paradigm of exploring new materials.",SOLAR-CELLS,Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,7.643,SOLAR-CELLS,JOURNAL OF PHYSICAL CHEMISTRY LETTERS,,
91,Modeling of metal nanoparticles: Development of neural-network interatomic potential inspired by features of the modified embedded-atom method,102,14,,"Wu Feifeng,Min Hang,Wen Yanwei,Chen Rong,Zhao Yunkun,Ford Mike,Shan Bin","Wu FF,Min H,Wen YW,Chen R,Zhao YK,Ford M,Shan B",Ford M,10.1103/PhysRevB.102.144107,University of Technology Sydney,"Interatomic potential plays a key role in ensuring the accuracy and reliability of molecular-dynamics simulation results. While most empirical potentials are benchmarked against a set of carefully chosen bulk material properties, recent advances in machine learning have seen the emergence of neural-network-based mathematical potentials capable of describing highly complex potential energy surfaces for a variety of systems. We report here the development of a neural-network interatomic potential (NNIP) with modified embedded-atom method background density as fingerprint functions, which could accurately model the energetics of metallic nanoparticles and clusters (Cu as a representative example) widely used in catalysis. To appropriately account for the diverse chemical environments encountered in nanoparticles/nanoclusters, an extensive set of atomic configurations (totaling 18 084) were calculated using density-functional-theory (DFT) at the Perdew-Burke-Ernzerhof level. In addition to standard bulk properties such as cohesive energies and elastic constants, the sampled configurations also include a substantial number of differently oriented crystal facets and differently sized nanoparticles and nanoclusters, greatly expanding the value range of NNIP features that was otherwise quite limited. The complex energy potential surface of Cu can be faithfully reproduced, with an average error of 0.011 eV/at for energy states within 3 eV of the ground state. As an illustration, the developed NNIP is used to simulate the molecular dynamics of copper nanoparticles, and good agreement is achieved between DFT and the NNIP.","MOLECULAR-DYNAMICS,DEFECT FORMATION,FORCE-FIELD,FCC METALS,SIMULATIONS,DISCOVERY,INVERSION,ENERGY",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,"MOLECULAR-DYNAMICS,DEFECT,FORMATION,FORCE-FIELD,FCC,METALS,SIMULATIONS,DISCOVERY,INVERSION,ENERGY",PHYSICAL REVIEW B,,
92,Artificial Intelligence in Various Medical Fields With Emphasis on Radiology: Statistical Evaluation of the Literature,12,10,,"Pakdemirli Emre,Wegner Urszula","Pakdemirli E,Wegner U",Wegner U,10.7759/cureus.10961,King George Hospital,"Background
Artificial intelligence (AI) has significantly impacted numerous medical specialties with high emphasis on radiology. Associated novel diagnostic methods have become a rapidly emerging hot topic, and it is essential to provide insights into quantitative analysis of the growing literature.
Purpose
The purpose of this study is to highlight future academic trends, identify potential research gaps, and analyze scientific landscape of AI in the field of medicine. The main aim is to explore comprehensive dataset over a 46-year period in terms of publication type, publication citation, country of origin, institution, and medical specialty.
Material and Methods
The Web of Science database was searched from 1975 to 2020, and publications on AI were explored. Both original research reports and review articles were included in comprehensive bibliometric analysis. Descriptive statistics were calculated, and numerous variables were applied, namely year of publication, institution, type of publication, specialty area, country of origin, and citation numbers, and the KruskalWallis analysis of variance was used.
Results
A total of 117,974 relevant citations were retrieved, of which 83,979 original research and review articles were retained for analysis. Not surprisingly, the largest proportion of citations were from the United States (23%, n = 19,180) followed by China, Spain, England, and Germany. The number of citations was relatively consistent during the 1970s and emerging gradually during the 1980s. However, ongoing scientific trend positively evolved, and the numbers started to grow significantly in the 1990s and demonstrated continuous increasing wave since then. The most frequently represented key medical specialties were oncology, radiology, neuroradiology, and ophthalmology. Overall, no major statistical difference was found between these four domains (p = 0.753).
Conclusions
In summary, research on AI-powered technologies in the medical domain was at early stage in the 1970s. However, associated deep learning algorithms significantly attracted and revolutionized the scientific community with subsequent evolution of research and exponential growth of multidisciplinary publications since that time. Work in this field has impacted radiology as an area of predominant interest and has been led by institutions in the United States, Spain, France, China, and England. The bibliometric study reported herein can provide a broad overview and valuable guidance to help medical researchers gain insights into key points and trace the global trends regarding the status of AI research in medicine, particularly in radiology and other relevant multispecialty areas.","machine learning,artificial intelligence,medicine,radiology,bibliometric analysis",Article,"CUREUS INC, PO BOX 61002, PALO ALTO, CA 94306 USA",General & Internal Medicine,,,,CUREUS,https://www.cureus.com/articles/42017-artificial-intelligence-in-various-medical-fields-with-emphasis-on-radiology-statistical-evaluation-of-the-literature.pdf,
93,Edge Detection Algorithm Optimization and Simulation Based on Machine Learning Method and Image Depth Information,20,20,11770-11777,"Cui Jichao,Tian Kun","Cui JC,Tian K",Cui JC,10.1109/JSEN.2019.2936117,Henan Institute of Technology,"Machine learning algorithms have become a hot topic in current research due to their unique learning performance, and have achieved fruitful research and application results in various fields. In this paper, the idea of machine learning classification algorithm is applied to depth image edge detection, AdaBoost algorithm and decision tree are used for image edge detection. The algorithm is created from training set creation, depth image feature extraction and combination of AdaBoost and image depth information, creating image training sample sets, selecting image features, training algorithm classifiers, and simulating medical ultrasound image classifiers. Finally, the machine learning algorithm was simulated and tested. The experimental results show that the edge detection effect is good, the algorithm adaptability is strong, and no adjustment parameters are needed.","Image edge detection,Classification algorithms,Training,Machine learning,Visualization,Filtering algorithms,Machine learning,depth image information,edge detection,algorithmic design",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,FAULT-DETECTION,IEEE SENSORS JOURNAL,,
94,Feature Extraction of Brain-Computer Interface Electroencephalogram Based on Motor Imagery,20,20,11787-11794,"Shi Tianwei,Ren Ling,Cui Wenhua","Shi TW,Ren L,Cui WH",Shi TW,10.1109/JSEN.2019.2939343,University Science & Technology Liaoning,"Brain-computer interface (BCI) is a system that allows people to communicate or control external devices simply by using information from the brain without relying on the peripheral nervous system and muscles; BCI technology has great potential application value in motor function assistance and motor function rehabilitation and has become a new research hotspot in the fields of machine learning, biomedical engineering and computer communication. The feature extraction of motor imagery electroencephalogram (EEG) is to find the most effective characteristics of complex EEG signal that can represent the consciousness task, to differentiate the feature vectors extracted from different consciousness tasks, and to maximize the correlation between the feature vector and the consciousness task. On the basis of summarizing and analyzing previous research works, this paper proposes a new EEG feature extraction algorithm based on common spatial pattern (CSP) and adaptive auto-regressive (AAR), and demonstrates feasibility of band energy, sample entropy and order accumulation to be the characteristics of motor imagery classification, and finally compares the classification effects of linear discrimination classifier, common space classifier and Bayesian classifier. The simulation results show that the proposed method and algorithm can effectively extract the features of EEG signals during motor imagery. The research results of this paper provide a reference for the further study of feature extraction of brain-computer interface EEG.","Feature extraction,Electroencephalography,Brain modeling,Wavelet packets,Time-domain analysis,Frequency-domain analysis,Brain-computer interfaces,Brain-computer interface,EEG signal,feature extraction,motor imagery",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"EEG,CLASSIFICATION",IEEE SENSORS JOURNAL,,
95,Radial Distribution Function from X-ray Absorption near Edge Structure with an Artificial Neural Network,89,10,,"Kiyohara Shin,Mizoguchi Teruyasu","Kiyohara S,Mizoguchi T",Kiyohara S; Mizoguchi T,10.7566/JPSJ.89.103001,University of Tokyo,"Extended X-ray absorption fine structure (EXAFS) is one of the common tools used to determine the local atomic coordination and bond length around an objective element via data conversion from the EXAFS profile to a radial distribution function (RDF). Thus, EXAFS has been widely used for the investigation of catalytic reactions, battery degradation, and other material developments. However, the data conversion from EXAFS to RDF involves three difficulties: weak signals, necessity of a wide energy range (similar to 1000 eV), and fitting parameters in reference samples. Recently, the direct estimation technique of RDF from EXAFS using machine learning was successfully developed, which overcomes the third problem. Here, we used an artificial neural network (ANN) to directly predict RDF from the near-edge region of the spectrum (X-ray absorption near-edge structure: XANES), which enables overcoming all of the difficulties. The ANN can correctly generate RDF only from XANES. XANES includes information about the bond length and coordination numbers in the range of similar to 5 angstrom. We applied our prediction model to an experimental spectrum and confirmed its accuracy. The method proposed here is greatly beneficial for measuring the local bond length and coordination of materials whose extended energy region is difficult to be measured.","FINE-STRUCTURE,ALLOYS",Article,"PHYSICAL SOC JAPAN, YUSHIMA URBAN BUILDING 5F, 2-31-22 YUSHIMA, BUNKYO-KU, TOKYO, 113-0034, JAPAN",Physics,,1.54,"FINE-STRUCTURE,ALLOYS",JOURNAL OF THE PHYSICAL SOCIETY OF JAPAN,https://doi.org/10.7566/jpsj.89.103001,
96,Atomatic Detection and Diagnosis of Severe Viral Pneumonia CT Images Based on LDA-SVM,20,20,11927-11934,"Ling Gengfei,Cao Congcong","Ling GF,Cao CC",Ling GF,10.1109/JSEN.2019.2959617,"Zhoukou Cent Hosp, Resp Intens Care Unit, Zhoukou 466000, Peoples R China.","The identification of pneumonia types mainly depends on the experience of doctors, but some CT images of pneumonia are very similar, even experienced doctors are prone to misdiagnosis. In order to solve the problems of inefficiency, coarse granularity and poor accuracy under the background of large data, LDA-SVM (Linear Discriminate Analysis - support vector machine) classification algorithm in machine learning field is introduced. LDA is used to extract features from images, and SVM classifier is used to classify the sub-datasets with strong fusion features. On this basis, fusion index and intermediary centrality index are selected to measure the fusion degree of patent sub-centralization technology and identify the key technologies in the fusion process, Because of the fusion of several algorithms, the algorithm needs many iteration training, and the computation time is too long. And simulation results show that our proposed method has significant improvement on identification accuracy rate.","Lung,Feature extraction,Diseases,Support vector machines,Computed tomography,Classification algorithms,Viral Pneumonia,CT,Linear Discriminate Analysis,support vector machine,identification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,BACTERIAL,IEEE SENSORS JOURNAL,,
97,Reconstructing QRS Complex From PPG by Transformed Attentional Neural Networks,20,20,12374-12383,"Chiu Hong-Yu,Shuai Hong-Han,Chao Paul C. -P.","Chiu HY,Shuai HH,Chao PCP",Shuai HH,10.1109/JSEN.2020.3000344,"Chiao Tung Univ NCTU, BASIC Lab, Dept Elect & Comp Engn, Hsinchu 30010, Taiwan.","Technology that translates photoplethysmogram (PPG) into the QRS complex of electrocardiogram (ECG) would be transformative for people who require continuously monitoring. However, directly decoding the QRS complex of ECG from PPG is challenging because PPG signals usually have different offsets due to 1) different devices, and 2) personal differences, which makes the alignment difficult. In this paper, we make the first attempt to reconstruct the QRS complex of ECG only from the recording of PPG by an end-to-end deep learning-based approach. Specifically, we propose a novel encoder-decoder architecture containing three components: 1) a sequence transformer network which automatically calibrates the offset, 2) an attention network, which dynamically identifies regions of interest, and 3) a new QRS complex-enhanced loss for better reconstruction. The experiment results on a real dataset demonstrate the effectiveness of the proposed method: 3.67% R peak failure rate of the reconstructed ECG and high correlation of pulse transit time between the reconstructed QRS complex and the groundtruth QRS complex (rho = 0.844), which creates a new opportunity for low-cost clinical studies via the waveform-level reconstruction of the QRS complex of ECG from PPG.","Electrocardiography,Monitoring,Electrodes,Biomedical monitoring,Skin,Standards,Sensors,Convolutional neural network,electrocardiography,encoder-decoder,photoplethysmography,transform network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"PULSE,TRANSIT-TIME,RESPIRATORY,RATE,ECG,ELECTROCARDIOGRAM",IEEE SENSORS JOURNAL,,
98,Combining multi-phase field simulation with neural network analysis to unravel thermomigration accelerated growth behavior of Cu6Sn5 IMC at cold side Cu-Sn interface,184,,,"Kunwar Anil,Hektor Johan,Nomoto Sukeharu,Coutinho Yuri Amorim,Moelans Nele","Kunwar A,Hektor J,Nomoto S,Coutinho YA,Moelans N",Kunwar A,10.1016/j.ijmecsci.2020.105843,KU Leuven,"In Pb-free solder alloys used in solder balls of diameter of 50 mu m or smaller, larger proportion of Cu6Sn5 inter-metallics formation is a major reliability concern, and this is aggravated in presence of external thermal gradient. A complete understanding of the mechanism for intermetallics compound (IMC) growth under thermomigration is essential for devising solder materials resistant to degradation under thermal gradient. This work integrates neural network analysis with multi-phase field method to quantify the mechanism of thermomigration at the cold side of a solder-substrate system. At hot side temperature of 523.15 K, 1D multi-phase field model is built for a combined driving force of bulk diffusion and thermomigration, and is solved using finite element method (FEM). The free energy density function for the thermomigration driving force is introduced, and coupled with the functions for bulk and interfacial free energy density of each phase. Data of heats of transport, temperature difference and growth rate constant of IMC are obtained from multiple FEM simulations, and the FEM-generated dataset is employed in the neural network. The machine learning predicted growth rate constant is tallied with experimental value, and heat of transport of Cu in IMC phase (Q(Cu)(imc)) is determined from the inverse method. The obtained value of optimized Q(Cu)(imc) is +35.10 kJ/mol. 2D IMC grain growth simulations are performed with hot-side at 523.15 K and the cold side lowered to 523.0817 K and 522.0 K respectively, thereby revealing that the accelerated grain growth for larger temperature difference is noticed within the first 20 s of the simulations.","Multi-phase field method,Thermomigration,Intermetallic compound,Neural network,Heat of transport,Finite element method",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Engineering,Mechanics",,5.199,"INTERMETALLIC,COMPOUNDS,SOLDER,JOINTS,DRIVING-FORCE,MODEL,SN%2FCU,ELECTROMIGRATION,FRAMEWORK,ENERGY",INTERNATIONAL JOURNAL OF MECHANICAL SCIENCES,https://lirias.kuleuven.be/bitstream/123456789/655889/2/Kunwar_et_al_thermomigration_2020_V1_postprint.pdf,
99,Single resistive sensor for selective detection of multiple VOCs employing SnO2 hollowspheres and machine learning algorithm: A proof of concept,321,,,"Acharyya Snehanjan,Jana Biswabandhu,Nag Sudip,Saha Goutam,Guha Prasanta Kumar","Acharyya S,Jana B,Nag S,Saha G,Guha PK",Guha PK,10.1016/j.snb.2020.128484,Indian Institute of Technology System (IIT System),"Selective detection of harmful gasses and volatile organic compounds (VOCs) in the ambient has become a major challenge. Primarily, semiconducting metal-oxide based gas sensors sense various gases simultaneously, hence their selectivity is poor. This paper presents a single chemiresistive metal-oxide gas sensor for identification of multiple VOCs accurately by employing highly sensitive microstructure and machine learning tools. Tin oxide (SnO2) hollowspheres were taken as sensing material that were prepared through optimized hydrothermal route. Different characterizations were carried out to confirm the formation of desired morphology and structural features. The sensor device was fabricated by controlled drop cast technique over gold based interdigitated electrodes. The sensor showed remarkable response towards the target VOCs with high sensitivity and fast recovery time. Incorporation of machine learning algorithm on the obtained sensor data provided accurate identification of all the VOCs (best performance shown by random forest). In addition, the quantitative prediction of gas concentration was performed for each target gas using regression model. In comparison to e-noses (having array of sensors with different sensing material), a single chemiresistive metal-oxide sensor with proper machine learning tool is simple, economic, compact and easy to fabricate.","Indoor air quality,Volatile organic compound,Selectivity,Chemiresistive gas sensor,Tin oxide hollowspheres",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Chemistry,Electrochemistry,Instruments & Instrumentation",,6.743,"GAS,SENSORS,HOLLOW,MICROSPHERES,AIR-POLLUTION,RANDOM,FOREST,CLASSIFICATION",SENSORS AND ACTUATORS B-CHEMICAL,,
100,"Nanoporous C3N4, C3N5 and C3N6 nanosheets; novel strong semiconductors with low thermal conductivities and appealing optical/electronic properties",167,,40-50,"Mortazavi Bohayra,Shojaei Fazel,Shahrokhi Masoud,Azizi Maryam,Rabczuk Timon,Shapeev Alexander V.,Zhuang Xiaoying","Mortazavi B,Shojaei F,Shahrokhi M,Azizi M,Rabczuk T,Shapeev AV,Zhuang XY",Mortazavi B; Zhuang XY,10.1016/j.carbon.2020.05.105,University of Hannover,"Carbon nitride two-dimensional (2D) materials are among the most attractive class of nanomaterials, with wide range of application prospects. As a continuous progress, most recently, two novel carbon nitride 2D lattices of C3N5 and C3N4 have been successfully experimentally realized. Motivated by these latest accomplishments and also by taking into account the well-known C3N4 triazine-based graphitic carbon nitride structures, we predicted two novel C3N6 and C3N4 counterparts. We then conducted extensive density functional theory simulations to explore the thermal stability, mechanical, electronic and optical properties of these novel nanoporous carbon-nitride nanosheets. According to our results all studied nanosheets are found to exhibit desirable thermal stability and mechanical properties. Non equilibrium molecular dynamics simulations on the basis of machine learning interatomic potentials predict ultralow thermal conductivities for these novel nanosheets. Electronic structure analyses confirm direct band gap semiconducting electronic character and optical calculations reveal the ability of these novel 2D systems to adsorb visible range of light. Extensive first-principles based results by this study provide a comprehensive vision on the stability, mechanical, electronic and optical responses of C3N4, C3N5 and C3N6 as novel 2D semiconductors and suggest them as promising candidates for the design of advanced nanoelectronics and energy storage/conversion systems. (C) 2020 Elsevier Ltd. All rights reserved.","Carbon nitride,2D materials,Semiconductors,First-principles modelling",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Chemistry,Materials Science",,8.719,"GRAPHITIC,CARBON,NITRIDE,TOTAL-ENERGY,CALCULATIONS,MONOLAYER,G-C3N4,CHARGE-TRANSPORT,EFFICIENT,PERFORMANCE,SILICENE,INSIGHT,STRAIN",CARBON,http://arxiv.org/pdf/2006.03889,
