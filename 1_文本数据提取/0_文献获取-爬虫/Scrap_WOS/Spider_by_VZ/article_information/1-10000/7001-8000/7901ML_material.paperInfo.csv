,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Overnight airway obstruction severity prediction centered on acoustic properties of smart phone: validation with esophageal pressure,41,10,,"Markandeya Mrunal N.,Abeyratne Udantha R.,Hukins Craig","Markandeya MN,Abeyratne UR,Hukins C",Abeyratne UR,10.1088/1361-6579/abb75f,University of Queensland,"Objective: Obstructive sleep apnea is characterized by a number of airway obstructions. Esophageal pressure manometry (EPM) based estimation of consecutive peak to trough differences (Delta Pes) is the gold standard method to quantify the severity of airway obstructions. However, the procedure is rarely available in sleep laboratories due to invasive nature. There is a clinical need for a simplified, scalable technology that can quantify the severity of airway obstructions. In this paper, we address this and propose a pioneering technology, centered on sleep related respiratory sound (SRS) to predict overnight Delta Pes signal. Approach: We recorded streams of SRS using a bedside iPhone 7 smartphone from subjects undergoing diagnostic polysomnography (PSG) studies and EPM was performed concurrently. Overnight data was divided into epochs of 10 s duration with 50% overlap. Altogether, we extracted 42 181 such epochs from 13 subjects. Acoustic features and features from the two PSG signals serve as an input to train a machine learning algorithm to achieve mapping between non-invasive features and Delta Pes values. A testing dataset of 14 171 epochs from four new subjects was used for validation. Main results: The SRS based model predicted the Delta Pes with a median of absolute error of 6.75 cmH2O (+/- 0.59, r = 0.83(+/- 0.03)). When information from the PSG were combined with the SRS, the model performance became: 6.37cmH2O (+/- 1.02, r = 0.85(+/- 0.04)). Significance: The smart phone based SRS alone, or in combination with routinely collected PSG signals can provide a non-invasive method to predict overnight Delta Pes. The method has the potential to be automated and scaled to provide a low-cost alternative to EPM.","OSA snoring sounds,upper airway obstruction,esophageal pressure signal,airway obstruction severity analysis",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"APNEA-HYPOPNEA,INDEX,SLEEP-APNEA,ASSOCIATION,RISK",PHYSIOLOGICAL MEASUREMENT,,
2,Can Unified Medical Language System-based semantic representation improve automated identification of patient safety incident reports by type and severity?,27,10,1502-1509,"Wang Ying,Coiera Enrico,Magrabi Farah","Wang Y,Coiera E,Magrabi F",Magrabi F,10.1093/jamia/ocaa082,Macquarie University,"Objective: The study sought to evaluate the feasibility of using Unified Medical Language System (UMLS) semantic features for automated identification of reports about patient safety incidents by type and severity.
Materials and Methods: Binary support vector machine (SVM) classifier ensembles were trained and validated using balanced datasets of critical incident report texts (n_type = 2860, n_severity = 1160) collected from a state-wide reporting system. Generalizability was evaluated on different and independent hospital-level reporting system. Concepts were extracted from report narratives using the UMLS Metathesaurus, and their relevance and frequency were used as semantic features. Performance was evaluated by F-score, Hamming loss, and exact match score and was compared with SVM ensembles using bag-of-words (BOW) features on 3 testing datasets (type/severity: n_benchmark = 286/116, n_original = 444/4837, n_independent =6000/5950).
Results: SVMs using semantic features met or outperformed those based on BOW features to identify 10 different incident types (F-score [semantics/BOW]: benchmark = 82.6%/69.4%; original = 77.9%/68.8%; independent = 78.0%/67.4%) and extreme-risk events (F-score [semantics/BOW]: benchmark = 87.3%/87.3%; original = 25.5%/19.8%; independent = 49.6%/52.7%). For incident type, the exact match score for semantic classifiers was consistently higher than BOW across all test datasets (exact match [semantics/BOW]: benchmark = 48.9%/39.9%; original = 57.9%/44.4%; independent = 59.5%/34.9%). Discussion: BOW representations are not ideal for the automated identification of incident reports because they do not account for text semantics. UMLS semantic representations are likely to better capture information in report narratives, and thus may explain their superior performance.
Conclusions: UMLS-based semantic classifiers were effective in identifying incidents by type and extreme-risk events, providing better generalizability than classifiers using BOW.","UMLS,semantics,patient safety,incident reporting,text classification,natural language processing",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"CLASSIFICATION,QUALITY",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7566533,
3,The 2019 National Natural language processing (NLP) Clinical Challenges (n2c2)/Open Health NLP (OHNLP) shared task on clinical concept normalization for clinical records,27,10,1529-1537,"Henry Sam,Wang Yanshan,Shen Feichen,Uzuner Ozlem","Henry S,Wang YS,Shen FC,Uzuner O",Henry S,10.1093/jamia/ocaa106,George Mason University,"Objective: The 2019 National Natural language processing (NLP) Clinical Challenges (n2c2)/Open Health NLP (OHNLP) shared task track 3, focused on medical concept normalization (MCN) in clinical records. This track aimed to assess the state of the art in identifying and matching salient medical concepts to a controlled vocabulary. In this paper, we describe the task, describe the data set used, compare the participating systems, present results, identify the strengths and limitations of the current state of the art, and identify directions for future research.
Materials and Methods: Participating teams were provided with narrative discharge summaries in which text spans corresponding to medical concepts were identified. This paper refers to these text spans as mentions. Teams were tasked with normalizing these mentions to concepts, represented by concept unique identifiers, within the Unified Medical Language System. Submitted systems represented 4 broad categories of approaches: cascading dictionary matching, cosine distance, deep learning, and retrieve-and-rank systems. Disambiguation modules were common across all approaches.
Results: A total of 33 teams participated in the MCN task. The best-performing team achieved an accuracy of 0.8526. The median and mean performances among all teams were 0.7733 and 0.7426, respectively.
Conclusions: Overall performance among the top 10 teams was high. However, several mention types were challenging for all teams. These included mentions requiring disambiguation of misspelled words, acronyms, abbreviations, and mentions with more than 1 possible semantic type. Also challenging were complex mentions of long, multi-word terms that may require new ways of extracting and representing mention meaning, the use of domain knowledge, parse trees, or hand-crafted rules.","natural language processing,clinical narratives,machine learning,concept normalization",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"HEART-DISEASE,RISK-FACTORS,TERMINOLOGY,NARRATIVES,DATABASE,CORPUS,SYSTEM",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647359,
4,Clinical concept normalization with a hybrid natural language processing system combining multilevel matching and machine learning ranking,27,10,1576-1584,"Chen Long,Fu Wenbo,Gu Yu,Sun Zhiyong,Li Haodan,Li Enyu,Jiang Li,Gao Yuan,Huang Yang","Chen L,Fu WB,Gu Y,Sun ZY,Li HD,Li EY,Jiang L,Gao Y,Huang Y",Huang Y,10.1093/jamia/ocaa155,"Med Data Quest Inc, 10590 West Ocean Air Dr,Suite 220, San Diego, CA 92130 USA.","Objective: Normalizing clinical mentions to concepts in standardized medical terminologies, in general, is challenging due to the complexity and variety of the terms in narrative medical records. In this article, we introduce our work on a clinical natural language processing (NLP) system to automatically normalize clinical mentions to concept unique identifier in the Unified Medical Language System. This work was part of the 2019 n2c2 (National NLP Clinical Challenges) Shared-Task and Workshop on Clinical Concept Normalization.
Materials and Methods: We developed a hybrid clinical NLP system that combines a generic multilevel matching framework, customizable matching components, and machine learning ranking systems. We explored 2 machine leaning ranking systems based on either ensemble of various similarity features extracted from pretrained encoders or a Siamese attention network, targeting at efficient and fast semantic searching/ranking. Besides, we also evaluated the performance of a general-purpose clinical NLP system based on Unstructured Information Management Architecture.
Results: The systems were evaluated as part of the 2019 n2c2 challenge, and our original best system in the challenge obtained an accuracy of 0.8101, ranked fifth in the challenge. The improved system with newly designed machine learning ranking based on Siamese attention network improved the accuracy to 0.8209.
Conclusions: We demonstrate the successful practice of combining multilevel matching and machine learning ranking for clinical concept normalization. Our results indicate the capability and interpretability of our proposed approach, as well as the limitation, suggesting the opportunities of achieving better performance by combining general clinical NLP systems.","clinical natural language processing,concept normalization,attention,CUI,UMLS",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,INFORMATION,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647369,
5,Representation of EHR data for predictive modeling: a comparison between UMLS and other terminologies,27,10,1593-1599,"Rasmy Laila,Tiryaki Firat,Zhou Yujia,Xiang Yang,Tao Cui,Xu Hua,Zhi Degui","Rasmy L,Tiryaki F,Zhou YJ,Xiang Y,Tao C,Xu H,Zhi DG",Zhi DG,10.1093/jamia/ocaa180,"UTHlth Sch Biomed Informat, 7000 Fannin St, Houston, TX 77030 USA.","Objective: Predictive disease modeling using electronic health record data is a growing field. Although clinical data in their raw form can be used directly for predictive modeling, it is a common practice to map data to standard terminologies to facilitate data aggregation and reuse. There is, however, a lack of systematic investigation of how different representations could affect the performance of predictive models, especially in the context of machine learning and deep learning.
Materials and Methods: We projected the input diagnoses data in the Cerner HealthFacts database to Unified Medical Language System (UMLS) and 5 other terminologies, including CCS, CCSR, ICD-9, ICD-10, and Phe-WAS, and evaluated the prediction performances of these terminologies on 2 different tasks: the risk prediction of heart failure in diabetes patients and the risk prediction of pancreatic cancer. Two popular models were evaluated: logistic regression and a recurrent neural network.
Results: For logistic regression, using UMLS delivered the optimal area under the receiver operating characteristics (AUROC) results in both dengue hemorrhagic fever (81.15%) and pancreatic cancer (80.53%) tasks. For recurrent neural network, UMLS worked best for pancreatic cancer prediction (AUROC 82.24%), second only (AUROC 85.55%) to PheWAS (AUROC 85.87%) for dengue hemorrhagic fever prediction.
Discussion/Conclusion: In our experiments, terminologies with larger vocabularies and finer-grained representations were associated with better prediction performances. In particular, UMLS is consistently 1 of the bestperforming ones. We believe that our work may help to inform better designs of predictive models, although further investigation is warranted.","UMLS,terminology representation,predictive modeling,electronic health records",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647355,
6,Mapping scientific landscapes in UMLS research: a scientometric review,27,10,1612-1624,"Kim Meen Chul,Nam Seojin,Wang Fei,Zhu Yongjun","Kim MC,Nam S,Wang F,Zhu YJ",Zhu YJ,10.1093/jamia/ocaa107,Sungkyunkwan University (SKKU),"Objective: The Unified Medical Language System (UMLS) is 1 of the most successful, collaborative efforts of terminology resource development in biomedicine. The present study aims to 1) survey historical footprints, emerging technologies, and the existing challenges in the use of UMLS resources and tools, and 2) present potential future directions.
Materials and Methods: We collected 10 469 bibliographic records published between 1986 and 2019, using a Web of Science database. graph analysis, data visualization, and text mining to analyze domain-level citations, subject categories, keyword co-occurrence and bursts, document co-citation networks, and landmark papers.
Results: The findings show that the development of UMLS resources and tools have been led by interdisciplinary collaboration among medicine, biology, and computer science. Efforts encompassing multiple disciplines, such as medical informatics, biochemical sciences, and genetics, were the driving forces behind the domain's growth. The following topics were found to be the dominant research themes from the early phases to midphases: 1) development and extension of ontologies and 2) enhancing the integrity and accessibility of these resources. Knowledge discovery using machine learning and natural language processing and applications in broader contexts such as drug safety surveillance have recently been receiving increasing attention.
Discussion: Our analysis confirms that while reaching its scientific maturity, UMLS research aims to boundary-span to more variety in the biomedical context. We also made some recommendations for editorship and authorship in the domain.
Conclusion: The present study provides a systematic approach to map the intellectual growth of science, as well as a self-explanatory bibliometric profile of the published UMLS literature. It also suggests potential future directions. Using the findings of this study, the scientific community can better align the studies within the emerging agenda and current challenges.","unified medical language system,science mapping,visual analytics,text mining,content analysis",Review,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"MEDICAL,LANGUAGE,SYSTEM,EXTRACTION,SYSTEM,EMERGING,TRENDS,ONTOLOGY,INFORMATICS,PATTERNS,TEXT,TOOL,WEB",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7647344,
7,Channel Embedding for Informative Protein Identification from Highly Multiplexed Images.,12265,,3-13,",,,,,,","Magid Salma Abdel,Jang Won-Dong,Schapiro Denis,Wei Donglai,Tompkin James,Sorger Peter K,Pfister Hanspeter",,10.1007/978-3-030-59722-1_1,,"Interest is growing rapidly in using deep learning to classify biomedical images, and interpreting these deep-learned models is necessary for life-critical decisions and scientific discovery. Effective interpretation techniques accelerate biomarker discovery and provide new insights into the etiology, diagnosis, and treatment of disease. Most interpretation techniques aim to discover spatially-salient regions within images, but few techniques consider imagery with multiple channels of information. For instance, highly multiplexed tumor and tissue images have 30-100 channels and require interpretation methods that work across many channels to provide deep molecular insights. We propose a novel channel embedding method that extracts features from each channel. We then use these features to train a classifier for prediction. Using this channel embedding, we apply an interpretation method to rank the most discriminative channels. To validate our approach, we conduct an ablation study on a synthetic dataset. Moreover, we demonstrate that our method aligns with biological findings on highly multiplexed images of breast cancer cells while outperforming baseline pipelines. Code is available at https://sabdelmagid.github.io/miccai2020-project/.",Deep learning; Highly multiplexed imaging; Interpretability,Journal Article,,,,,,,,
8,Adversarial Uni- and Multi-modal Stream Networks for Multimodal Image Registration.,12263,,222-232,",,,,,,","Xu Zhe,Luo Jie,Yan Jiangpeng,Pulya Ritvik,Li Xiu,Wells William 3rd,Jagadeesan Jayender",,10.1007/978-3-030-59716-0_22,,"Deformable image registration between Computed Tomography (CT) images and Magnetic Resonance (MR) imaging is essential for many image-guided therapies. In this paper, we propose a novel translation-based unsupervised deformable image registration method. Distinct from other translation-based methods that attempt to convert the multimodal problem (e.g., CT-to-MR) into a unimodal problem (e.g., MR-to-MR) via image-to-image translation, our method leverages the deformation fields estimated from both: (i) the translated MR image and (ii) the original CT image in a dual-stream fashion, and automatically learns how to fuse them to achieve better registration performance. The multimodal registration network can be effectively trained by computationally efficient similarity metrics without any ground-truth deformation. Our method has been evaluated on two clinical datasets and demonstrates promising results compared to state-of-the-art traditional and learning-based methods.",Generative Adversarial Network; Multimodal Registration; Unsupervised Learning,Journal Article,,,,,,,,
9,Cartilage Segmentation in High-Resolution 3D Micro-CT Images via Uncertainty-Guided Self-training with Very Sparse Annotation.,12261,,802-812,",,,,,,","Zheng Hao,Perrine Susan M Motch,Pitirri M Kathleen,Kawasaki Kazuhiko,Wang Chaoli,Richtsmeier Joan T,Chen Danny Z",,10.1007/978-3-030-59710-8_78,,"Craniofacial syndromes often involve skeletal defects of the head. Studying the development of the chondrocranium (the part of the endoskeleton that protects the brain and other sense organs) is crucial to understanding genotype-phenotype relationships and early detection of skeletal malformation. Our goal is to segment craniofacial cartilages in 3D micro-CT images of embryonic mice stained with phosphotungstic acid. However, due to high image resolution, complex object structures, and low contrast, delineating fine-grained structures in these images is very challenging, even manually. Specifically, only experts can differentiate cartilages, and it is unrealistic to manually label whole volumes for deep learning model training. We propose a new framework to progressively segment cartilages in high-resolution 3D micro-CT images using extremely sparse annotation (e.g., annotating only a few selected slices in a volume). Our model consists of a lightweight fully convolutional network (FCN) to accelerate the training speed and generate pseudo labels (PLs) for unlabeled slices. Meanwhile, we take into account the reliability of PLs using a bootstrap ensemble based uncertainty quantification method. Further, our framework gradually learns from the PLs with the guidance of the uncertainty estimation via self-training. Experiments show that our method achieves high segmentation accuracy compared to prior arts and obtains performance gains by iterative self-training.",Cartilage segmentation; Sparse annotation; Uncertainty,Journal Article,,,,,,,,
10,Interpretation of Brain Morphology in Association to Alzheimer's Disease Dementia Classification Using Graph Convolutional Networks on Triangulated Meshes.,12474,,95-107,",,,,,,,,","Azcona Emanuel,Besson Pierre,Wu Yunan,Punjabi Arjun,Martersteck Adam,Dravid Amil,Parrish Todd B,Bandt S Kathleen,Katsaggelos Aggelos K",,10.1007/978-3-030-61056-2_8,,,Alzheimers disease classification; Graph convolutional networks; neural network interpretability; triangulated meshes,Journal Article,,,,,,,,
11,Medical image registration using deep neural networks: A comprehensive review,87,,,"Boveiri Hamid Reza,Khayami Raouf,Javidan Reza,Mehdizadeh Alireza","Boveiri HR,Khayami R,Javidan R,Mehdizadeh A",Boveiri HR,10.1016/j.compeleceng.2020.106767,Shiraz University of Technology,"Image-guided interventions are saving the lives of a large number of patients where the image registration should indeed be considered as the most complex and complicated issue to be tackled. On the other hand, a huge progress in the field of machine learning has recently made by the possibility of implementing deep neural networks on the contemporary many-core GPUs. It has opened up a promising window to challenge with many medical applications in more efficient and effective ways, where the registration is not an exception. In this paper, a comprehensive review on the state-of-the-art literature known as medical image registration using deep neural networks is presented. The review is systematic and encompasses all the related works previously published in the field. Key concepts, statistical analysis from different points of view, confining challenges, novelties and main contributions, key-enabling techniques, future directions, and prospective trends all are discussed and surveyed in details in this comprehensive review. This review allows a deep understanding and insight for the readers active in the field who are investigating the state-of-the-art and seeking to contribute the future literature. (C) 2020 Elsevier Ltd. All rights reserved.","Convolutional neural network (CNN),Deep learning,Deep reinforcement learning,Deformable registration,Generative adversarial network (GAN),Image-guided intervention,Medical image registration,One-shot registration,Precision medicine,Stacked auto-encoders (SAES)",Review,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering",,3.297,,COMPUTERS & ELECTRICAL ENGINEERING,http://arxiv.org/pdf/2002.03401,
12,Optimal strategy for intelligent rail guided vehicle dynamic scheduling,87,,,"Ding Chao,He Hailang,Wang Weiwei,Yang Wanting,Zheng Yuanyuan","Ding C,He HL,Wang WW,Yang WT,Zheng YY",Ding C,10.1016/j.compeleceng.2020.106750,Anhui Jianzhu University,"In an automated stereoscopic warehouse, the efficiency of the Rail Guided Vehicle (RGV) is the bottleneck. This paper proposes a foresight stepping model to optimize the intelligent RGV scheduling scheme. We incorporate the chaotic particle swarm optimization algorithm into the model and design the mechanism of multi-step processing. The machine optimization is used to compare the optimal alignment effect of the Back Propagation (BP) network algorithm and GradientBoostingDecisionTree (GBDT) algorithm. The real-life system test is performed by simulation. The simulation results show that the GBDT-foresight stepping model is superior to the traditional models in terms of complexity, reliability and accuracy. (C) 2020 Elsevier Ltd. All rights reserved.","Foresight stepping model,Chaotic particle swarm,GBDT algorithm,BP network algorithm,Intelligent RGV",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering",,3.297,"GENETIC,ALGORITHM",COMPUTERS & ELECTRICAL ENGINEERING,,
13,An integrated neural-fuzzy methodology for characterisation and modelling of exopolysaccharide (EPS) production levels of Leuconostoc mesenteroides DL1,148,,,"Kabli Mohammad,Yilmaz Mustafa Tahsin,Taylan Osman,Kaya Yasemin,Ispirli Humeyra,Basahel Abdulrahman,Sagdic Osman,Dertli Enes","Kabli M,Yilmaz MT,Taylan O,Kaya Y,Ispirli H,Basahel A,Sagdic O,Dertli E",Taylan O,10.1016/j.cie.2020.106619,King Abdulaziz University,"Optimisation of exopolysaccharides (EPS) production in Lactic Acid Bacteria (LAB) is an important task as EPS production can be affected by different parameters. In this respect, this study aimed to characterise the structure of an EPS from Leuconstoc mesenteroides DL1 strain and to optimise the EPS production by determination of the effects of incubation time, sucrose concentration, incubation temperature and initial levan concentration (input parameters) using integrated ANNs (Artificial neural networks) and fuzzy modelling approaches. The characterisation of the EPS monomeric composition by HPLC analysis revealed that EPS DL1 was composed of glucose and fructose. The H-1 and C-13 NMR spectra of EPS DL1 also confirmed the glucan and fructan production. The effects of the input parameters on glucan and fructan production levels as output parameters by DL1 were optimised using neural network and fuzzy modelling tools. The fuzzy model was developed based on the recognition of basic elements of input-output parameters, and the power of ANNs used for system identification. A structural analysis was carried out to improve the flexibility of fuzzy model, and to design the unknown mappings of the input and output parameters more robustly. The parameters then were fine-tuned by qualitative reasoning to establish the relations of input output parameters using membership functions (MFs) and their intervals determination. A hybrid training algorithm was employed for parameter identification, MFs and their interval determination to obtain the fuzzy model. The model can predict the outcome parameters; glucan and fructan with high accuracy for the predetermined input parameters.","EPS production,Structural characterisation,Lactic acid bacteria (LAB),Optimisation,Neural networks,Fuzzy modelling",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering",,5.518,"STRUCTURAL-CHARACTERIZATION,LACTOBACILLUS-PLANTARUM,WEISSELLA-CIBARIA,SOURDOUGH,GLUCAN,OPTIMIZATION,DEXTRAN,GLUCANSUCRASE,PREDICTION,BACTERIA",COMPUTERS & INDUSTRIAL ENGINEERING,,
14,Prediction of frictional characteristics of bituminous mixes using group method of data handling and multigene symbolic genetic programming,36,4,1875-1888,"Pattanaik Madhu Lisha,Choudhary Rajan,Kumar Bimlesh","Pattanaik ML,Choudhary R,Kumar B",Kumar B,10.1007/s00366-019-00802-4,Indian Institute of Technology System (IIT System),"A safe road transport requires adequate friction between vehicle tires and pavement surface for safe travels. Adequate friction is essential for a vehicle to safely maneuver. Inadequate friction is directly correlated to the accident hazard, particularly in wet weather conditions. Quality of pavement materials has a prodigious effect on skid resistance and high-quality materials allow adequate pavement frictional resistance for an extended period. Science evaluation of frictional characteristics depends on physical, chemical, and mineralogical properties of the aggregate, type of mix, binder/bitumen content, water film thickness, etc., and it necessities a costly and time-consuming test protocol. In the present research, a model is developed for the evaluation of skid resistance in terms of the British pendulum number (BPN), using experimental observations, with the aid of machine learning tools. In the present work, group method of data handling (GMDH) and multigene symbolic genetic programming (MSGP) have been used to model the BPN. Developed model is capable to simplify extremely nonlinear deviations in data as well as forecast the frictional performance from experimental data. It is also found that the performance of the MSGP (R-2 = 0.99) is more encouraging and better than that of the GMDH model (R-2 = 0.98) for the prediction of BPN. The analytical expression obtained through MSGP in the present study has been also subjected to sensitivity analysis to assess the effect of individual parameters in prediction of BPN.","Friction,Skid resistance,British pendulum number,Multigene symbolic genetic programming,Group method of data handling",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Computer Science,Engineering",,6.544,"NETWORK-BASED,APPROACH,SKID,RESISTANCE,SCOUR,DEPTH,NEURAL-NETWORKS,GMDH,ALGORITHM,MODEL",ENGINEERING WITH COMPUTERS,,
15,Improved Activity Recognition Combining Inertial Motion Sensors and Electroencephalogram Signals,30,10,,"Grana Manuel,Aguilar-Moreno Marina,De Lope Asiain Javier,Baglietto Araquistain Ibai,Garmendia Xavier","Grana M,Aguilar-Moreno M,Asiain JD,Araquistain IB,Garmendia X",Asiain JD,10.1142/S0129065720500537,Universidad Politecnica de Madrid,"Human activity recognition and neural activity analysis are the basis for human computational neureoethology research dealing with the simultaneous analysis of behavioral ethogram descriptions and neural activity measurements. Wireless electroencephalography (EEG) and wireless inertial measurement units (IMU) allow the realization of experimental data recording with improved ecological validity where the subjects can be carrying out natural activities while data recording is minimally invasive. Specifically, we aim to show that EEG and IMU data fusion allows improved human activity recognition in a natural setting. We have defined an experimental protocol composed of natural sitting, standing and walking activities, and we have recruited subjects in two sites: in-house (N = 4) and out-house (N = 12) populations with different demographics. Experimental protocol data capture was carried out with validated commercial systems. Classifier model training and validation were carried out with scikit-learn open source machine learning python package. EEG features consist of the amplitude of the standard EEG frequency bands. Inertial features were the instantaneous position of the body tracked points after a moving average smoothing to remove noise. We carry out three validation processes: a 10-fold cross-validation process per experimental protocol repetition, (b) the inference of the ethograms, and (c) the transfer learning from each experimental protocol repetition to the remaining repetitions. The in-house accuracy results were lower and much more variable than the out-house sessions results. In general, random forest was the best performing classifier model. Best cross-validation results, ethogram accuracy, and transfer learning were achieved from the fusion of EEG and IMUs data. Transfer learning behaved poorly compared to classification on the same protocol repetition, but it has accuracy still greater than 0.75 on average for the out-house data sessions. Transfer leaning accuracy among repetitions of the same subject was above 0.88 on average. Ethogram prediction accuracy was above 0.96 on average. Therefore, we conclude that wireless EEG and IMUs allow for the definition of natural experimental designs with high ecological validity toward human computational neuroethology research. The fusion of both EEG and IMUs signals improves activity and ethogram recognition.","Neuroethology,activity recognition,EEG,inertial measurement",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Computer Science,,5.439,"EEG,TRACKING,ACCURACY,SYSTEM,FIELD",INTERNATIONAL JOURNAL OF NEURAL SYSTEMS,https://addi.ehu.es/bitstream/10810/50210/1/s0129065720500537.pdf,
16,Feedback-aided data acquisition improves myoelectric control of a prosthetic hand,17,5,,"Gigli Andrea,Brusamento Donato,Meattini Roberto,Melchiorri Claudio,Castellini Claudio","Gigli A,Brusamento D,Meattini R,Melchiorri C,Castellini C",Gigli A,10.1088/1741-2552/abbed0,Helmholtz Association,"Objective. Pattern-recognition-based myocontrol can be unreliable, which may limit its use in the clinical practice and everyday activities. One cause for this is the poor generalization of the underlying machine learning models to untrained conditions. Acquiring the training data and building the model more interactively can reduce this problem. For example, the user could be encouraged to target the model's instabilities during the data acquisition supported by automatic feedback guidance. Interactivity is an emerging trend in myocontrol of upper-limb electric prostheses: the user should be actively involved throughout the training and usage of the device.
Approach. In this study, 18 non-disabled participants tested two novel feedback-aided acquisition protocols against a standard one that did not provide any guidance. All the protocols acquired data dynamically in multiple arm positions to counteract the limb position effect. During feedback-aided acquisition, an acoustic signal urged the participant to hover with the arm in specific regions of her peri-personal space, de facto acquiring more data where needed. The three protocols were compared on everyday manipulation tasks performed with a prosthetic hand. Main results. Our results showed that feedback-aided data acquisition outperformed the acquisition routine without guidance, both objectively and subjectively. Significance. This indicates that the interaction with the user during the data acquisition is fundamental to improve myocontrol.","myoelectric control,training data acquisition,feedback guidance,limb position effect,prosthetic hand",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"PATTERN-RECOGNITION,LIMB,LOSS",JOURNAL OF NEURAL ENGINEERING,,
17,Assessing impact of channel selection on decoding of motor and cognitive imagery from MEG data,17,5,,"Roy Sujit,Rathee Dheeraj,Chowdhury Anirban,McCreadie Karl,Prasad Girijesh","Roy S,Rathee D,Chowdhury A,McCreadie K,Prasad G",Roy S,10.1088/1741-2552/abbd21,Ulster University,"Objective. Magnetoencephalography (MEG) based brain-computer interface (BCI) involves a large number of sensors allowing better spatiotemporal resolution for assessing brain activity patterns. There have been many efforts to develop BCI using MEG with high accuracy, though an increase in the number of channels (NoC) means an increase in computational complexity. However, not all sensors necessarily contribute significantly to an increase in classification accuracy (CA) and specifically in the case of MEG-based BCI no channel selection methodology has been performed. Therefore, this study investigates the effect of channel selection on the performance of MEG-based BCI. Approach. MEG data were recorded for two sessions from 15 healthy participants performing motor imagery, cognitive imagery and a mixed imagery task pair using a unique paradigm. Performance of four state-of-the-art channel selection methods (i.e. Class-Correlation, ReliefF, Random Forest, and Infinite Latent Feature Selection were applied across six binary tasks in three different frequency bands) were evaluated in this study on two state-of-the-art features, i.e. bandpower and common spatial pattern (CSP). Main results. All four methods provided a statistically significant increase in CA compared to a baseline method using all gradiometer sensors, i.e. 204 channels with band-power features from alpha (8-12 Hz), beta (13-30 Hz), or broadband (alpha + beta) (8-30 Hz). It is also observed that the alpha frequency band performed better than the beta and broadband frequency bands. The performance of the beta band gave the lowest CA compared with the other two bands. Channel selection improved accuracy irrespective of feature types. Moreover, all the methods reduced the NoC significantly, from 204 to a range of 1-25, using bandpower as a feature and from 15 to 105 for CSP. The optimal channel number also varied not only in each session but also for each participant. Reducing the NoC will help to decrease the computational cost and maintain numerical stability in cases of low trial numbers. Significance. The study showed significant improvement in performance of MEG-BCI with channel selection irrespective of feature type and hence can be successfully applied for BCI applications.","MEG,BCI,bandpower,CSP,channel selection",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"BRAIN-COMPUTER,INTERFACES,EEG,PLASTICITY,EXECUTION,MOVEMENT",JOURNAL OF NEURAL ENGINEERING,https://pure.ulster.ac.uk/ws/files/87359531/Accpted_copy_JNE.pdf,
18,Novel laser processed shape memory alloy actuator design with an embedded strain gauge sensor using dual resistance measurements. Part II: Recurrent neural network-based position and force estimation,313,,,"Ruvinov Igor,Zamani Nima,Zhou Norman Y.,Khan Mohammad Ibraheem","Ruvinov I,Zamani N,Zhou NY,Khan MI",Ruvinov I,10.1016/j.sna.2020.112188,University of Waterloo,"The current paper is a continuation of Part I, performing position and force estimation on a similar monolithic shape memory alloy (SMA) actuator with two distinct phases embedded through laser processing and post-processing. The recurrent neural network-based model proposed in this work outperforms the mathematical model developed in Part I, achieving average position and force estimation accuracy of 97.5% and 95.0%, respectively, using only electrical resistance measurements across the two actuator phases. Furthermore, the model can be applied to SMAs with varying compositions and geometries. The described actuator and sensorless estimation model are widely suitable for robotics, haptics, and various other systems which involve the application of unknown or dynamic load. (C) 2020 Elsevier B.V. All rights reserved.","Shape memory alloys,NiTi,Dual resistance,Recurrent neural network,Machine learning,Artificial intelligence,Actuator,Sensorless,Position estimation,Force estimation",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Engineering,Instruments & Instrumentation",,3.246,"MODEL-PREDICTIVE,CONTROL,MARTENSITIC-TRANSFORMATION,DEFORMATION-BEHAVIOR,AGING,TREATMENT,HYSTERESIS,IDENTIFICATION,FABRICATION",SENSORS AND ACTUATORS A-PHYSICAL,,
19,Frontiers of Robotic Gastroscopy: A Comprehensive Review of Robotic Gastroscopes and Technologies,12,10,,"Marlicz Wojciech,Ren Xuyang,Robertson Alexander,Skonieczna-Zydecka Karolina,Loniewski Igor,Dario Paolo,Wang Shuxin,Plevris John N.,Koulaouzidis Anastasios,Ciuti Gastone","Marlicz W,Ren XY,Robertson A,Skonieczna-Zydecka K,Loniewski I,Dario P,Wang SX,Plevris JN,Koulaouzidis A,Ciuti G",Ren XY; Ciuti G,10.3390/cancers12102775,"Scuola Superiore StAnna, BioRobot Inst, I-56025 Pisa, Italy.","Simple Summary
With the rapid advancements of medical technologies and patients' higher expectations for precision diagnostic and surgical outcomes, gastroscopy has been increasingly adopted for the detection and treatment of pathologies in the upper digestive tract. Correspondingly, robotic gastroscopes with advanced functionalities, e.g., disposable, dextrous and not invasive solutions, have been developed in the last years. This article extensively reviews these novel devices and describes their functionalities and performance. In addition, the implementation of artificial intelligence technology into robotic gastroscopes, combined with remote telehealth endoscopy services, are discussed. The aim of this paper is to provide a clear and comprehensive view of contemporary robotic gastroscopes and ancillary technologies to support medical practitioners in their future clinical practice but also to inspire and drive new engineering developments.
Upper gastrointestinal (UGI) tract pathology is common worldwide. With recent advancements in robotics, innovative diagnostic and treatment devices have been developed and several translational attempts made. This review paper aims to provide a highly pictorial critical review of robotic gastroscopes, so that clinicians and researchers can obtain a swift and comprehensive overview of key technologies and challenges. Therefore, the paper presents robotic gastroscopes, either commercial or at a progressed technology readiness level. Among them, we show tethered and wireless gastroscopes, as well as devices aimed for UGI surgery. The technological features of these instruments, as well as their clinical adoption and performance, are described and compared. Although the existing endoscopic devices have thus far provided substantial improvements in the effectiveness of diagnosis and treatment, there are certain aspects that represent unwavering predicaments of the current gastroenterology practice. A detailed list includes difficulties and risks, such as transmission of communicable diseases (e.g., COVID-19) due to the doctor-patient proximity, unchanged learning curves, variable detection rates, procedure-related adverse events, endoscopists' and nurses' burnouts, limited human and/or material resources, and patients' preferences to choose non-invasive options that further interfere with the successful implementation and adoption of routine screening. The combination of robotics and artificial intelligence, as well as remote telehealth endoscopy services, are also discussed, as viable solutions to improve existing platforms for diagnosis and treatment are emerging.","gastroscopy,gastric cancer,robotic gastroscopy,machine learning,artificial intelligence",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Oncology,,6.999,"ENDOSCOPIC,SUBMUCOSAL,DISSECTION,UPPER,GASTROINTESTINAL,ENDOSCOPY,GASTRIC-CANCER,CAPSULE,ENDOSCOPY,ARTIFICIAL-INTELLIGENCE,TRANSORAL,SURGERY,RISK-FACTORS,SYSTEM,GASTROENTEROLOGY,STOMACH",CANCERS,https://www.mdpi.com/2072-6694/12/10/2775/pdf,
20,Incomplete multi-view gene clustering with data regeneration using Shape Boltzmann Machine,125,,,"Dutta Pratik,Mishra Piyush,Saha Sriparna","Dutta P,Mishra P,Saha S",Saha S,10.1016/j.compbiomed.2020.103965,Indian Institute of Technology (IIT) - Patna,"Deciphering patterns in the structural and functional anatomy of genes can prove to be very helpful in understanding genetic biology and genomics. Also, the availability of the multiple omits data, along with the advent of machine learning techniques, aids medical professionals in gaining insights about various biological regulations. Gene clustering is one of the many such computation techniques that can help in understanding gene behavior. However, more comprehensive and reliable insights can be gained if different modalities/views of biomedical data are considered. However, in most multi-view cases, each view contains some missing data, leading to incomplete multi-view clustering. In this study, we have presented a deep Boltzmann machine-based incomplete multi-view clustering framework for gene clustering. Here, we seek to regenerate the data of the three NCBI datasets in the incomplete modalities using Shape Boltzmann Machines. The overall performance of the proposed multi-view clustering technique has been evaluated using the Silhouette index and Davies-Bouldin index, and the comparative analysis shows an improvement over state-of-the-art methods. Finally, to prove that the improvement attained by the proposed incomplete multi-view clustering is statistically significant, we perform Welch's t-test.","Multi-modality,Gene clustering,Incomplete multi-view clustering,Boltzmann machine",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"EXPRESSION,PROFILE,UVEAL,MELANOMA,SELECTION",COMPUTERS IN BIOLOGY AND MEDICINE,,
21,A data-driven approach to build a predictive model of cancer patients' disease outcome by utilizing co-expression networks,125,,,"Kosvyra A.,Maramis C.,Chouvarda I","Kosvyra A,Maramis C,Chouvarda I",Kosvyra A,10.1016/j.compbiomed.2020.103971,Aristotle University of Thessaloniki,"Background: Next Generation Sequencing (NGS) technologies have revolutionized genomics data research over the last decades by facilitating high-throughput sequencing of genetic material such as RNA Sequencing (RNAseq). A significant challenge is to explore innovative methods for further exploitation of these large-scale datasets. The approach described in this paper utilizes the results of RNAseq analysis to identify biomarkers related to the disease and deploy a disease outcome predictive model.
Method: Chronic Lymphocytic Leukemia (CLL) was used as an example in the implementation of this approach. The approach proposed follows this methodology: (1) Analysis of RNAseq raw data, (2) Construction of a gene correlation network, (3) Identification of modules and hub genes in this network, which constitute the features for the classification algorithm, (4) Deployment of an efficient predictive model, with the use of state-of-the-art machine learning techniques and the association of the indicators with the clinical information.
Results: The features/hub genes finally selected were 25 in total and were used as the input to the classifiers. The models, then, were validated leading to very satisfactory results, with the best performing of them achieving 95% cross-validation and 93,75% external validation accuracy.
Conclusions: Concluding, this exploratory data-driven approach attempts to make use of big genomic data by summarizing them in a way that is more understandable and facilitates their use by other techniques, such as Machine Learning. This method manages to extract a gene set that can predict the disease progression. The validation results of the proposed data-driven predictive models are very promising and constitute a significant contribution to medical research and personalized medicine.","Bioinformatics,Sequencing analysis,Co-expression networks,Data mining,Machine learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,,"RNA-SEQ,GENE,EXPRESSION,MUTATION",COMPUTERS IN BIOLOGY AND MEDICINE,,
22,On the potential of recurrent neural networks for modeling path dependent plasticity,143,,,"Gorji Maysam B.,Mozaffar Mojtaba,Heidenreich Julian N.,Cao Jian,Mohr Dirk","Gorji MB,Mozaffar M,Heidenreich JN,Cao J,Mohr D",Mohr D,10.1016/j.jmps.2020.103972,ETH Zurich,"The mathematical description of elastoplasticity is a highly complex problem due to the possible change from elastic to elasto-plastic behavior (and vice-versa) as a function of the loading path. Advanced physics-based plasticity models usually feature numerous internal variables (often of tensorial nature) along with a set of evolution equations and complementary conditions. In the present work, an attempt is made to come up with a machine-learning based model that can replicate the predictions anisotropic Yld2000-2d model with homogeneous anisotropic hardening (HAH). For this, a series of modeling problems of increasing complexity is formulated and sequentially addressed using neural network models. It is demonstrated that basic fully-connected neural network models can capture the characteristic non-linearities in the uniaxial stress-strain response such as the Bauschinger effect, permanent softening or latent hardening. A neural network with gated recurrent units (GRUs) and fully-connected layer is proposed for the modeling of plane stress plasticity for arbitrary loading paths. After training and testing the model through comparison with the Yld200 0-2d/HAH model, the recurrent neural network model is also used to model the multi-axial stress-strain response of a two-dimensional foam. Here, the comparison with the results from unit cell simulations provided another validation of the proposed data-driven modeling approach. (C) 2020 Elsevier Ltd. All rights reserved.","Recurrent neural network,Fully connected neural network,Gated recurrent unit,Plasticity,Yld2000-2d,HAH",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Materials Science,Mechanics,Physics",,5.472,"ANISOTROPIC,HARDENING,MODEL,DEEP,MATERIAL,NETWORK,CONSTITUTIVE-EQUATIONS,POLYCRYSTALLINE,METALS,CYCLIC,PLASTICITY,ALUMINUM,BEHAVIOR,FRACTURE,FLOW,MILD",JOURNAL OF THE MECHANICS AND PHYSICS OF SOLIDS,https://www.sciencedirect.com/science/article/am/pii/S0022509620302076,
23,A physics-informed geometric learning model for pathological tau spread in Alzheimer's disease.,12267,,418-427,",,,,,,,","Song Tzu-An,Chowdhury Samadrita Roy,Yang Fan,Jacobs Heidi I L,Sepulcre Jorge,Wedeen Van J,Johnson Keith A,Dutta Joyita",,10.1007/978-3-030-59728-3_41,,"Tau tangles are a pathophysiological hallmark of Alzheimer's disease (AD) and exhibit a stereotypical pattern of spatiotemporal spread which has strong links to disease progression and cognitive decline. Preclinical evidence suggests that tau spread depends on neuronal connectivity rather than physical proximity between different brain regions. Here, we present a novel physics-informed geometric learning model for predicting tau buildup and spread that learns patterns directly from longitudinal tau imaging data while receiving guidance from governing physical principles. Implemented as a graph neural network with physics-based regularization in latent space, the model enables effective training with smaller data sizes. For training and validation of the model, we used longitudinal tau measures from positron emission tomography (PET) and structural connectivity graphs from diffusion tensor imaging (DTI) from the Harvard Aging Brain Study. The model led to higher peak signal-to-noise ratio and lower mean squared error levels than both an unregularized graph neural network and a differential equation solver. The method was validated using both two-timepoint and three-timepoint tau PET measures. The effectiveness of the approach was further confirmed by a cross-validation study.",Alzheimers disease; DTI; PET; graph neural networks; tau spread,Journal Article,,,,,,,,
24,Spatio-Temporal Graph Convolution for Resting-State fMRI Analysis.,12267,,528-538,",,,,,","Gadgil Soham,Zhao Qingyu,Pfefferbaum Adolf,Sullivan Edith V,Adeli Ehsan,Pohl Kilian M",,10.1007/978-3-030-59728-3_52,,"The Blood-Oxygen-Level-Dependent (BOLD) signal of resting-state fMRI (rs-fMRI) records the temporal dynamics of intrinsic functional networks in the brain. However, existing deep learning methods applied to rs-fMRI either neglect the functional dependency between different brain regions in a network or discard the information in the temporal dynamics of brain activity. To overcome those shortcomings, we propose to formulate functional connectivity networks within the context of spatio-temporal graphs. We train a spatio-temporal graph convolutional network (ST-GCN) on short sub-sequences of the BOLD time series to model the non-stationary nature of functional connectivity. Simultaneously, the model learns the importance of graph edges within ST-GCN to gain insight into the functional connectivities contributing to the prediction. In analyzing the rs-fMRI of the Human Connectome Project (HCP, N = 1,091) and the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA, N = 773), ST-GCN is significantly more accurate than common approaches in predicting gender and age based on BOLD signals. Furthermore, the brain regions and functional connections significantly contributing to the predictions of our model are important markers according to the neuroscience literature.",,Journal Article,,,,,,,,
25,A 3D Convolutional Encapsulated Long Short-Term Memory (3DConv-LSTM) Model for Denoising fMRI Data.,12267,,479-488,",,,,","Zhao Chongyue,Li Hongming,Jiao Zhicheng,Du Tianming,Fan Yong",,10.1007/978-3-030-59728-3_47,,"Function magnetic resonance imaging (fMRI) data are typically contaminated by noise introduced by head motion, physiological noise, and thermal noise. To mitigate noise artifact in fMRI data, a variety of denoising methods have been developed by removing noise factors derived from the whole time series of fMRI data and therefore are not applicable to real-time fMRI data analysis. In the present study, we develop a generally applicable, deep learning based fMRI denoising method to generate noise-free realistic individual fMRI volumes (time points). Particularly, we develop a fully data-driven 3D convolutional encapsulated Long Short-Term Memory (3DConv-LSTM) approach to generate noise-free fMRI volumes regularized by an adversarial network that makes the generated fMRI volumes more realistic by fooling a critic network. The 3DConv-LSTM model also integrates a gate-controlled self-attention model to memorize short-term dependency and historical information within a memory pool. We have evaluated our method based on both task and resting state fMRI data. Both qualitative and quantitative results have demonstrated that the proposed method outperformed state-of-the-art alternative deep learning methods.",3D convolutional LSTM; Adversarial regularizer; Gate-controlled self-attention; fMRI denoising,Journal Article,,,,,,,,
26,Machine-learning-accelerated screening of hydrogen evolution catalysts in MBenes materials,526,,,"Sun Xiang,Zheng Jingnan,Gao Yijing,Qiu Chenglong,Yan Yilong,Yao Zihao,Deng Shengwei,Wang Jianguo","Sun X,Zheng JN,Gao YJ,Qiu CL,Yan YL,Yao ZH,Deng SW,Wang JG",Deng SW; Wang JG,10.1016/j.apsusc.2020.146522,Zhejiang University of Technology,"Machine learning (ML) models combined with density functional theory (DFT) calculations are employed to screen and design hydrogen evolution reaction (HER) catalysts from various bare and single-atom doped MBenes materials. The values of Gibbs free energy of hydrogen adsorption (Delta G(H)*) are accurately predicted via support vector algorithm only by using simply structural and elemental features. With the analysis of combined descriptors and the feature importance, the Bader charge transfer of surface metal is a key factor to influence HER activity of MBenes. Co/Ni2B2, Pt/Ni2B2, Co2B2, Os/Co2B2 and Mn/Co2B2 are screened from 271 MBenes and MXenes as active catalysts, with the near-zero Delta G(H)* of 0.089, -0.082, -0.13, -0.087 and -0.044 eV, respectively. Finally, stable Co2B2 and Mn/Co2B2 are considered as the excellent HER catalysts due to vertical bar Delta G(H)*vertical bar < 0.15 eV over a wide range of hydrogen coverages (theta from 1/9 to 5/9). The present work suggests that ML models are competitive tools in accelerating the screening of efficient HER catalysts.","Machine learning,Hydrogen evolution reaction,Density functional theory,MBenes,Single atom dopant,Feature combination",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Chemistry,Materials Science,Physics",,5.905,"MONOLAYER,1T-MOS2,DESIGN,MXENES",APPLIED SURFACE SCIENCE,,
27,ARTIFICIAL INTELLIGENT SYSTEM FOR SKIN DISEASES CLASSIFICATION,32,5,,"Mohammed Kamel K.,Afify Heba M.,Hassanien Aboul Ella","Mohammed KK,Afify HM,Hassanien AE",Afify HM,10.4015/S1016237220500362,"Higher Inst Engn El Shorouk City, Syst & Biomed Engn Dept, Cairo, Egypt.","In this paper, an artificial intelligent technique is proposed for skin disease detection and classification. The suggested method comprises four stages, including segmentation, extraction of textural features, and classification. The stretch-based enhanced algorithm has been adapted for image enhancement. Then the method of an active contour is used for segmentation to determine the skin lesion in tissue. Textural features are obtained from the segmented skin lesion. As several numbers of the features can affect the classification precision, ideal feature selection is made to exclude features that are less informative and unnecessary. The feature selection is adjusted with a regularized random forest. Finally, the classification algorithms by support vector machine and a back-propagation neural network (BPNN) are implemented. The dataset consists of 400 dermoscopic images in total divided into 200 benign and 200 malignant skin diseases extracted from the dermoscopic images PH2 database. The result of detecting and classifying the dermoscopic images on these images yielded an accuracy of 99.7%, a sensitivity of 99.4%, and a specificity of 100% by BPNN. The experiential results confirmed that the BPNN classifier is best rather than an SVM classifier for skin disease images. This proposed model will be advanced to support the skin image processing techniques that provided a more accurate diagnosis and rapid treatment plan.","Skin cancer,Active contour segmentation,Regularized random forest,back-propagation neural network,support vector machine",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Engineering,,,"EARLY-DIAGNOSIS,MELANOMA,SELECTION,LESIONS",BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS,,
28,Depth Estimation of Hard Inclusions in Soft Tissue by Autonomous Robotic Palpation Using Deep Recurrent Neural Network,17,4,1791-1799,"Xiao Bo,Xu Wenjun,Guo Jing,Lam Hak-Keung,Jia Guangyu,Hong Wuzhou,Ren Hongliang","Xiao B,Xu WJ,Guo J,Lam HK,Jia GY,Hong WZ,Ren HL",Ren HL,10.1109/TASE.2020.2978881,National University of Singapore,"Accurately detecting tumors and estimating the depth of tumors is essential in the surgical removal of tumors. In robotic-assisted surgery, autonomous robotic palpation has the potential to provide more precise detection, tumors' depth estimation, and less intrusion when normal tissues surround tumors. In this article, by mimicking the human finger touch, we propose a tactile sensing-based deep recurrent neural network (DRNN) with long short-term memory (LSTM) architecture to improve the accuracy of the detection and depth estimation of tumors embedded in soft tissue. In the experimental setup, the hard inclusions simulate the tumors, while the phantom tissue is fabricated by silicon to simulate the soft tissue. During the experiment, the data from the force sensor and displacement of the robot palpation probe are for detection and depth estimation purposes. The collected sequential data set of the force and the displacement of the probe during one completed palpation process will go through the proposed DRNN network with deep LSTM architecture, in which the temporal dependencies of the sequential data will be captured in the cell states in the deep LSTM layers. Subsequently, the softmax classifier is adopted to determine if there is any hard inclusion exists and offer the depth estimation of the hard inclusions. Experiments based on 396 real data sets demonstrate that the detection accuracy for the testing data set is 99.2% and the depth estimation accuracy for the testing data set is 95.8%. The accuracy of the proposed method is best when comparing with other widely used methods. Note to Practitioners-The palpation of tumors motivated this article in the robot-assisted surgical systems through tactile feedback. In order to mimic the human touch on the soft tissue, this article presents a deep-learning-based approach to estimate the depth of the hard inclusions in the phantom tissue through force information. The displacement of the palpation probe and the touch force during one palpation are recorded as data sequences to train the deep model, which aims to capture dynamics and long-term dependence of the palpation process. In this article, we made the first successful attempt to accurately estimate the depth of the hard inclusions buried at different locations of the phantom tissue using only force information. The proposed approach can work in different robot-assisted scenarios, such as master-slave robotic surgery. In the clinic applications, the force sensor will be integrated at the end-effector of the robotic manipulator. According to the specific requirements, the force sensor and the robotic manipulator might be different from those used in this article. For some applications, such as the laparoscopic interventions, the complete vertical contact tends to be difficult to obtain due to the laparoscopic port effects. The projection of the recorded force data and displacement can obtain the information in the normal direction. The future work is going to be extended to tissue environments with arbitrary surface and tumors with various shapes/depths for more complex and prospective clinical applications.","Robot sensing systems,Tumors,Phantoms,Probes,Estimation,Force sensors,Deep recurrent neural network (DRNN),force sensor,long short-term memory (LSTM),robotic palpation,tactile sensing,tumor depth estimation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Automation & Control Systems,,5.516,"FORCE,CONTROL,FEEDBACK",IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING,,
29,Inter- and Intra-Subject Transfer Reduces Calibration Effort for High-Speed SSVEP-Based BCIs,28,10,2123-2135,"Wong Chi Man,Wang Ze,Wang Boyu,Lao Ka Fai,Rosa Agostinho,Xu Peng,Jung Tzyy-Ping,Chen C. L. Philip,Wan Feng","Wong CM,Wang Z,Wang BY,Lao KF,Rosa A,Xu P,Jung TP,Chen CLP,Wan F",Wan F,10.1109/TNSRE.2020.3019276,University of Macau,"Objective: Steady-state visual evoked potential (SSVEP)-based brain-computer interfaces (BCIs) that can deliver a high information transfer rate (ITR) usually require subject's calibration data to learn the class- and subject-specific model parameters (e.g. the spatial filters and SSVEP templates). Normally, the amount of the calibration data for learning is proportional to the number of classes (or visual stimuli), which could be huge and consequently lead to a time-consuming calibration. This study presents a transfer learning scheme to substantially reduce the calibration effort. Methods: Inspired by the parameter-based and instance-based transfer learning techniques, we propose a subject transfer based canonical correlation analysis (stCCA) method which utilizes the knowledge within subject and between subjects, thus requiring few calibration data from a new subject. Results: The evaluation study on two SSVEP datasets (from Tsinghua and UCSD) shows that the stCCA method performs well with only a small amount of calibration data, providing an ITR at 198.18 +/- 59.12 (bits/min) with 9 calibration trials in the Tsinghua dataset and 111.04 +/- 57.24 (bits/min) with 3 trials in the UCSD dataset. Such performances are comparable to those from using the multi-stimulus CCA (msCCA) and the ensemble task-related component analysis (eTRCA) methods with the minimally required calibration data (i.e., at least 40 trials in the Tsinghua dataset and at least 12 trials in the UCSD dataset), respectively. Conclusion: Inter- and intra-subject transfer helps the recognition method achieve high ITR with extremely little calibration effort. Significance: The proposed approach saves much calibration effort without sacrificing the ITR, which would be significant for practical SSVEP-based BCIs.","Calibration,Visualization,Electroencephalography,Frequency measurement,Brain modeling,Steady-state,Data models,Brain-computer interface,steady-state visual evoked potential,inter-subject,intra-subject,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"BRAIN-COMPUTER,INTERFACES",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
30,A Correlation-Driven Mapping For Deep Learning application in detecting artifacts within the EEG,17,5,,"Bahador Nooshin,Erikson Kristo,Laurila Jouko,Koskenkari Juha,Ala-Kokko Tero,Kortelainen Jukka","Bahador N,Erikson K,Laurila J,Koskenkari J,Ala-Kokko T,Kortelainen J",Bahador N,10.1088/1741-2552/abb5bd,University of Oulu,"Objective.When developing approaches for automatic preprocessing of electroencephalogram (EEG) signals in non-isolated demanding environment such as intensive care unit (ICU) or even outdoor environment, one of the major concerns is varying nature of characteristics of different artifacts in time, frequency and spatial domains, which in turn causes a simple approach to be not enough for reliable artifact removal. Considering this, current study aims to use correlation-driven mapping to improve artifact detection performance.Approach.A framework is proposed here for mapping signals from multichannel space (regardless of the number of EEG channels) into two-dimensional RGB space, in which the correlation of all EEG channels is simultaneously taken into account, and a deep convolutional neural network (CNN) model can then learn specific patterns in generated 2D representation related to specific artifact.Main results.The method with a classification accuracy of 92.30% (AUC = 0.96) in a leave-three-subjects-out cross-validation procedure was evaluated using data including 2310 EEG sequences contaminated by artifacts and 2285 artifact-free EEG sequences collected with BrainStatus self-adhesive electrode and wireless amplifier from 15 intensive care patients. For further assessment, several scenarios were also tested including performance variation of proposed method under different segment lengths, different numbers of isoline and different numbers of channel. The results showed outperformance of CNN fed by correlation coefficients data over both spectrogram-based CNN and EEGNet on the same dataset.Significance.This study showed the feasibility of utilizing correlation image of EEG channels coupled with deep learning as a promising tool for dimensionality reduction, channels fusion and capturing various artifacts patterns in temporal-spatial domains. A simplified version of proposed approach was also shown to be feasible in real-time application with latency of 0.0181 s for making real-time decision.","deep learning,multichannel data fusion,dimensionality reduction,CNN,correlation map,EEG,artifact,real-time application",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"AUTOMATIC,DETECTION,REMOVAL",JOURNAL OF NEURAL ENGINEERING,http://jultika.oulu.fi/files/nbnfi-fe20201216100923.pdf,
31,Thinker invariance: enabling deep neural networks for BCI across more people,17,5,,"Kostas Demetres,Rudzicz Frank","Kostas D,Rudzicz F",Kostas D,10.1088/1741-2552/abb7a7,University of Toronto,"Objective.Most deep neural networks (DNNs) used as brain computer interfaces (BCI) classifiers are rarely viable for more than one person and are relatively shallow compared to the state-of-the-art in the wider machine learning literature. The goal of this work is to frame these as a unified challenge and reconsider howtransfer learningis used to overcome these difficulties.Approach. We present two variations of a holistic approach to transfer learning with DNNs for BCI that rely on a deeper network called TIDNet. Our approaches use multiple subjects for training in the interest of creating a more universal classifier that is applicable for new (unseen) subjects. The first approach is purelysubject-invariantand the secondtargetsspecific subjects, without loss of generality. We use five publicly accessible datasets covering a range of tasks and compare our approaches to state-of-the-art alternatives in detail.Main results. We observe that TIDNet in conjunction with our training augmentations is more consistent when compared to shallower baselines, and in some cases exhibits large and significant improvements, for instance motor imagery classification improvements of over 8%. Furthermore, we show that our suggested multi-domain learning (MDL) strategy strongly outperforms simplyfine-tunedgeneral models when targetingspecific subjects, while remaining more generalizable to still unseen subjects.Significance. TIDNet in combination with a data alignment-based training augmentation proves to be a consistent classification approach of single raw trials and can be trained even with the inclusion of corrupted trials. Our MDL strategy calls into question the intuition to fine-tune trained classifiers to new subjects, as it proves simpler and more accurate while remaining general. Furthermore, we show evidence that augmented TIDNet training makes better use of additional subjects, showing continued and greater performance improvement over shallower alternatives, indicating promise for a new subject-invariant paradigm rather than a subject-specific one.","deep neural networks,BCI,brain computer interface,brain machine interface,transfer learning,domain generalization,fine-tuning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,CLASSIFICATION,JOURNAL OF NEURAL ENGINEERING,https://doi.org/10.1088/1741-2552/abb7a7,
32,Learning to control the brain through adaptive closed-loop patterned stimulation,17,5,,"Tafazoli Sina,MacDowell Camden J.,Che Zongda,Letai Katherine C.,Steinhardt Cynthia R.,Buschman Timothy J.","Tafazoli S,MacDowell CJ,Che ZD,Letai KC,Steinhardt CR,Buschman TJ",Buschman TJ,10.1088/1741-2552/abb860,Princeton University,"Objective.Stimulation of neural activity is an important scientific and clinical tool, causally testing hypotheses and treating neurodegenerative and neuropsychiatric diseases. However, current stimulation approaches cannot flexibly control the pattern of activity in populations of neurons. To address this, we developed a model-free, adaptive, closed-loop stimulation (ACLS) system that learns to use multi-site electrical stimulation to control the pattern of activity of a population of neurons.Approach.The ACLS system combined multi-electrode electrophysiological recordings with multi-site electrical stimulation to simultaneously record the activity of a population of 5-15 multiunit neurons and deliver spatially-patterned electrical stimulation across 4-16 sites. Using a closed-loop learning system, ACLS iteratively updated the pattern of stimulation to reduce the difference between the observed neural response and a specific target pattern of firing rates in the recorded multiunits.Main results.In silicoandin vivoexperiments showed ACLS learns to produce specific patterns of neural activity (in similar to 15 min) and was robust to noise and drift in neural responses. In visual cortex of awake mice, ACLS learned electrical stimulation patterns that produced responses similar to the natural response evoked by visual stimuli. Similar to how repetition of a visual stimulus causes an adaptation in the neural response, the response to electrical stimulation was adapted when it was preceded by the associated visual stimulus.Significance.Our results show an ACLS system that can learn, in real-time, to generate specific patterns of neural activity. This work provides a framework for using model-free closed-loop learning to control neural activity.","brain stimulation,electrical stimulation,machine learning,closed-loop stimulation,neuromodulation",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"MICROSTIMULATION,PERFORMANCE,EXPRESSION,ATTENTION",JOURNAL OF NEURAL ENGINEERING,https://doi.org/10.1101/2020.03.14.992198,
33,Background image-assisted divide-and-conquer reconstruction method for ECT,95,,,"Lei J.,Liu Q. B.","Lei J,Liu QB",Lei J,10.1016/j.engappai.2020.103906,North China Electric Power University,"Electrical capacitance tomography (ECT) is a potential image-based measurement technology for monitoring time-varying industrial processes, but its applicability is challenged by low-quality images. To address this conundrum, a two-stage reconstruction (TSR) method with more effective priors and optimizer is presented in this work. In the first stage, the random vector functional link network (RVFLN) is developed to calculate a data-dependent background image, and a new distributed computing method is developed to achieve efficient training. To decrease the expensive computation load in the RVFLN training, the regularized projective nonnegative matrix factorization (RPNMF) method is developed to diminish the size of the sample data. A new optimization problem (OP) is proposed to model the RPNMF problem, which is solved by a new optimizer efficiently. In the second stage, a new OP that achieves the confluence of the domain knowledge-based prior related to imaging objects and the measurement physics is built, and a new divide-and-conquer optimizer is devised to solve the OP. To reduce the difficulty of parameter adjustment, the background image is used to initialize the proposed computing algorithm, and such treatment not only achieves the simultaneous fusion of the domain knowledge-based prior and the data-dependent prior but also decreases the computational difficulty. Numerical results show that the TSR algorithm is not only robust but also can achieve high precision reconstruction in comparison with popular imaging techniques.","Inverse imaging problem,Random vector functional link network,Nonnegative matrix factorization,Electrical capacitance tomography,Process monitoring method",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Automation & Control Systems,Computer Science,Engineering",,5.317,"NONNEGATIVE,MATRIX,FACTORIZATION,SPLIT-BREGMAN,ITERATION,NEURAL-NETWORKS,REGULARIZATION,ALGORITHM,SPARSE,MODEL,DECONVOLUTION",ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE,,
34,PIR Sensor-Based AAL Tool for Human Movement Detection: Modified MCP-Based Dictionary Learning Approach,69,10,7377-7385,"De Pubali,Chatterjee Amitava,Rakshit Anjan","De P,Chatterjee A,Rakshit A",De P,10.1109/TIM.2020.2981106,"Techno Int Batanagar, Dept Elect Engn, Kolkata 700141, India.","Development of sensor(s)-based, signal processing-aided, low-cost ambient-assisted living tools (AALs), essentially for assisting elderly people, home automation, and remote monitoring purposes, has become an important research domain. Within this domain, developing intelligent systems for human movement recognition in specific directions has become a very important problem statement. This article shows how a sophisticated, low-cost, integrated system can be developed using an indigenously developed hardware-software combine. The solution employs around four pyroelectric infrared (PIR) sensor based hardware systems coupled with a novel dictionary learning algorithm. The work successfully carries out the recently proposed multiple cluster pursuit (MCP)-algorithm-based dictionary learning for the human detection problem and then proposes a new variant of MCP algorithm, called modified MCP algorithm, for this purpose. Extensive real-life performance evaluations have been performed to demonstrate the suitability of MCP and the modified MCP algorithms for the problem under consideration.","Machine learning,Signal processing algorithms,Tracking,Clustering algorithms,Ambient assisted living,Biomedical monitoring,Real-time systems,Ambient-assisted living (AL),dictionary learning,modified multiple cluster pursuit (MCP) algorithm,MCP algorithm,pyroelectric infrared (PIR) sensor",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"K-SVD,RECOGNITION,DIRECTION,TRACKING,MODEL",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
35,Heart Rate Estimation From Facial Videos Using a Spatiotemporal Representation With Convolutional Neural Networks,69,10,7411-7421,"Song Rencheng,Zhang Senle,Li Chang,Zhang Yunfei,Cheng Juan,Chen Xun","Song RC,Zhang SL,Li C,Zhang YF,Cheng J,Chen X",Cheng J,10.1109/TIM.2020.2984168,Hefei University of Technology,"Remote photoplethysmography (rPPG) is a kind of noncontact technique to measure heart rate (HR) from facial videos. As the demand for long-term health monitoring grows, rPPG attracts much attention from researchers. However, the performance of conventional rPPG methods is easily degenerated due to noise interference. Recently, some deep learning-based rPPG methods have been introduced and they revealed good performance against noise. In this article, we propose a new rPPG method with convolutional neural networks (CNNs) to build a mapping between a spatiotemporal HR feature image to its corresponding HR value. The feature map is constructed in a time-delayed way with noise-contaminated pulse signals extracted from existing rPPG methods. The CNN model is trained using transfer learning where images built from synthetic rPPG signals are taken to train the model first in order to generate initials for the practical one. The synthetic rPPG signals are interpolated from blood volume pulses or electrocardiograms through a modified Akima cubic Hermite interpolation. The proposed method is tested in both within-database and cross-database configurations on public databases. The results demonstrate that our method achieves overall the best performance compared to some other typical rPPG methods. The mean absolute error reaches 5.98 beats per minute and the mean error rate percentage is 7.97% in the cross-database testing on MAHNOB-HCI data set. Besides, some key factors that affect the performance of our method are also discussed which indicates potential ways for further improvements.","Heart rate,Feature extraction,Spatiotemporal phenomena,Convolutional neural networks,Image color analysis,Deep learning,Skin,Convolutional neural network,heart rate estimation,remote photoplethysmography,spatiotemporal representation,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,NONCONTACT,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
36,A Wearable EEG Instrument for Real-Time Frontal Asymmetry Monitoring in Worker Stress Analysis,69,10,8335-8343,"Arpaia Pasquale,Moccaldi Nicola,Prevete Roberto,Sannino Isabella,Tedesco Annarita","Arpaia P,Moccaldi N,Prevete R,Sannino I,Tedesco A",Arpaia P,10.1109/TIM.2020.2988744,University of Naples Federico II,"A highly wearable single-channel instrument, conceived with off-the-shelf components and dry electrodes, is proposed for detecting human stress in real time by electroencephalography (EEG). The instrument exploits EEG robustness to movement artifacts with respect to other biosignals for stress assessment. The single-channel differential measurement aims at analyzing the frontal asymmetry, a well-claimed EEG feature for stress assessment. The instrument was characterized metrologically on human subjects. As triple metrological references, standardized stress tests, observational questionnaires given by psychologists, and performance measurements were exploited. Four standard machine learning classifiers (SVM, k-NN, random forest, and ANN), trained on 50% of the data set, reached more than 90% accuracy in classifying each 2-s epoch of EEG acquired from the stressed subjects.","Electroencephalography,Stress,Electrodes,Instruments,Support vector machines,Real-time systems,Monitoring,Brain-computer interface (BCI),cobot,electroencephalography (EEG),Industry 4,0,smart manufacturing,stress",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"MUSCLE,ARTIFACTS,SYSTEM,RECOGNITION,PERFORMANCE,EMOTION",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
37,Smartphone-Based Point-of-Care System Using Continuous-Wave Portable Doppler,69,10,8352-8361,"Jana Biswabandhu,Biswas Rakesh,Nath Pallab Kumar,Saha Goutam,Banerjee Swapna","Jana B,Biswas R,Nath PK,Saha G,Banerjee S",Jana B,10.1109/TIM.2020.2987654,Indian Institute of Technology System (IIT System),"Point-of-care Ultrasound (PoCUS) is a safe, repeatable, and inexpensive bedside diagnostic tool. Over the years, PoCUS services are adopted in resource-limited settings for faster and useful outcomes. For a cost-effective and power-efficient solution, a smartphone-based portable continuous-wave Doppler ultrasound (US) system has been developed for diagnosing peripheral arterial diseases based on the hemodynamic feature values. The proposed system includes the analog front end (AFE), signal processing and display unit (SPDU), and smartphone application. The AFE acquires blood flow signal from the brachial artery using an 8-MHz pencil probe, extracts the Doppler shift frequency, and transfers to the SPDU through 12-bit analog-to-digital converter. To provide an area and power-efficient solution, SPDU is embedded in a field-programmable gate array (FPGA)-based single chip. A COordinate Rotation DIgital Computer (CORDIC)-based custom-designed 512-point fast Fourier transform is implemented in that FPGA for displaying the blood flow spectrogram in real time. For back-end processing, the smartphone application receives a spectrogram through Bluetooth, removes noise, extracts hemodynamic features, and diagnoses using a machine learning framework. The device has been examined on 18 volunteers (normal: 17 and abnormal: 1), while the accuracy is found to be 94% in the pretrained support vector machine classifier. For validation, the spectrogram of the normal and abnormal subjects and parameter values are compared with the commercial device. Overall, the handheld device is minimally trained operator-dependent and consumes < 4 W of power for real-time processing. Such smartphone-based feature extraction and automated diagnosis can facilitate the point-of-care system and provide a baseline for early assessment.","Doppler effect,Field programmable gate arrays,Blood,Spectrogram,Process control,Probes,Feature extraction,Android,Doppler effect,field-programmable gate arrays (FPGAs),point-of-care (POC),support vector machine (SVM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"PULSED-WAVE,BLOOD-FLOW,ULTRASOUND,IMPLEMENTATION,DESIGN",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
38,Development of a Prediction Model for Demolition Waste Generation Using a Random Forest Algorithm Based on Small DataSets,17,19,,"Cha Gi-Wook,Moon Hyeun Jun,Kim Young-Min,Hong Won-Hwa,Hwang Jung-Ha,Park Won-Jun,Kim Young-Chan","Cha GW,Moon HJ,Kim YM,Hong WH,Hwang JH,Park WJ,Kim YC",Park WJ,10.3390/ijerph17196997,Kangwon National University,"Recently, artificial intelligence (AI) technologies have been employed to predict construction and demolition (C&D) waste generation. However, most studies have used machine learning models with continuous data input variables, applying algorithms, such as artificial neural networks, adaptive neuro-fuzzy inference systems, support vector machines, linear regression analysis, decision trees, and genetic algorithms. Therefore, machine learning algorithms may not perform as well when applied to categorical data. This article uses machine learning algorithms to predict C&D waste generation from a dataset, as a way to improve the accuracy of waste management in C&D facilities. These datasets include categorical (e.g., region, building structure, building use, wall material, and roofing material), and continuous data (particularly, gloss floor area), and a random forest (RF) algorithm was used. Results indicate that RF is an adequate machine learning algorithm for a small dataset consisting of categorical data, and even with a small dataset, an adequate prediction model can be developed. Despite the small dataset, the predictive performance according to the demolition waste (DW) type was R (Pearson's correlation coefficient) = 0.691-0.871, R-2 (coefficient of determination) = 0.554-0.800, showing stable prediction performance. High prediction performance was observed using three (for mortar), five (for other DW types), or six (for concrete) input variables. This study is significant because the proposed RF model can predict DW generation using a small amount of data. Additionally, it demonstrates the possibility of applying AI to multi-purpose DW management.","demolition waste management,construction waste management,prediction model,random forest,leave-one-out cross-validation,small data",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Public, Environmental & Occupational Health",,3.789,"MULTIPLE,LINEAR-REGRESSION,SUPPORT,VECTOR,MACHINE,CONSTRUCTION,PERFORMANCE,MANAGEMENT,CHINA",INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH,https://www.mdpi.com/1660-4601/17/19/6997/pdf,
39,Discrimination of elemental responsiveness to tumor chemotherapy by laser-induced breakdown spectroscopy coupled with chemometric methods,30,10,,"Lin Qingyu,Wei Hongyan,Yin Pengkun,Duan Yixiang,Bian Fang","Lin QY,Wei HY,Yin PK,Duan YX,Bian F",Duan YX,10.1088/1555-6611/aba83a,Sichuan University,"It is significant to develop novel methods to diagnose the tumor status throughout chemotherapy. In the present work, we focused on identifying the elemental biomarkers of chemotherapy-treated and untreated tumor tissues by laser-induced breakdown spectroscopy (LIBS). The unsupervised algorithm as principal component analysis and three supervised algorithms including partial least squares discrimination analysis (PLS-DA), random forest (RF) as well as support vector machine (SVM) were used to develop efficient classification models. The average predictive accuracy was 90.74% via the PLS-DA, 88.89% via RF, and 83.33% via SVM, respectively. The results highlighted the spectral difference between chemotherapy-treated and untreated samples within the range of visible spectra between 300-700 nm. In the meantime, four major elements were found to contribute the classification over the following order: calcium > magnesium = copper > sodium. The results featured the importance of calcium on element-based therapeutic responsiveness biomarker monitoring via a new LIBS-based vision.","laser-induced breakdown spectroscopy,tumor tissues,elemental biomarkers,partial least squares discrimination analysis,random forest,support vector machine",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Optics,Physics",,1.157,"CALCIUM,IMMUNOGENICITY,APOPTOSIS,DIAGNOSIS,BREAST,CELLS",LASER PHYSICS,,
40,A Semi-supervised Joint Network for Simultaneous Left Ventricular Motion Tracking and Segmentation in 4D Echocardiography.,12266,,468-477,",,,,","Ta Kevinminh,Ahn Shawn S,Stendahl John C,Sinusas Albert J,Duncan James S",,10.1007/978-3-030-59725-2_45,,"This work presents a novel deep learning method to combine segmentation and motion tracking in 4D echocardiography. The network iteratively trains a motion branch and a segmentation branch. The motion branch is initially trained entirely unsupervised and learns to roughly map the displacements between a source and a target frame. The estimated displacement maps are then used to generate pseudo-ground truth labels to train the segmentation branch. The labels predicted by the trained segmentation branch are fed back into the motion branch and act as landmarks to help retrain the branch to produce smoother displacement estimations. These smoothed out displacements are then used to obtain smoother pseudo-labels to retrain the segmentation branch. Additionally, a biomechanically-inspired incompressibility constraint is implemented in order to encourage more realistic cardiac motion. The proposed method is evaluated against other approaches using synthetic and in-vivo canine studies. Both the segmentation and motion tracking results of our model perform favorably against competing methods.",Echocardiography; Motion tracking; Segmentation,Journal Article,,,,,,,,
41,Lesion Mask-Based Simultaneous Synthesis of Anatomic and Molecular MR Images Using a GAN.,12262,,104-113,",,,,","Guo Pengfei,Wang Puyang,Zhou Jinyuan,Patel Vishal M,Jiang Shanshan",,10.1007/978-3-030-59713-9_11,,"Data-driven automatic approaches have demonstrated their great potential in resolving various clinical diagnostic dilemmas for patients with malignant gliomas in neuro-oncology with the help of conventional and advanced molecular MR images. However, the lack of sufficient annotated MRI data has vastly impeded the development of such automatic methods. Conventional data augmentation approaches, including flipping, scaling, rotation, and distortion are not capable of generating data with diverse image content. In this paper, we propose a method, called synthesis of anatomic and molecular MR images network (SAMR), which can simultaneously synthesize data from arbitrary manipulated lesion information on multiple anatomic and molecular MRI sequences, including T1-weighted (T 1w), gadolinium enhanced T 1w (Gd-T 1w), T2-weighted (T 2w), fluid-attenuated inversion recovery (FLAIR), and amide proton transfer-weighted (APTw). The proposed framework consists of a stretch-out up-sampling module, a brain atlas encoder, a segmentation consistency module, and multi-scale label-wise discriminators. Extensive experiments on real clinical data demonstrate that the proposed model can perform significantly better than the state-of-the-art synthesis methods.",GAN; MRI; Multi-modality synthesis,Journal Article,,,,,,,,
42,Graded Image Generation Using Stratified CycleGAN.,12262,,760-769,",,,","Liu Jianfei,Li Joanne,Liu Tao,Tam Johnny",,10.1007/978-3-030-59713-9_73,,"In medical imaging, CycleGAN has been used for various image generation tasks, including image synthesis, image denoising, and data augmentation. However, when pushing the technical limits of medical imaging, there can be a substantial variation in image quality. Here, we demonstrate that images generated by CycleGAN can be improved through explicit grading of image quality, which we call stratified CycleGAN. In this image generation task, CycleGAN is used to upgrade the image quality and content of near-infrared fluorescent (NIRF) retinal images. After manual assignment of grading scores to a small subset of the data, semi-supervised learning is applied to propagate grades across the remainder of the data and set up the training data. These scores are embedded into the CycleGAN by adding the grading score as a conditional input to the generator and by integrating an image quality classifier into the discriminator. We validate the efficacy of the proposed stratified CycleGAN by considering pairs of NIRF images at the same retinal regions (imaged with and without correction of optical aberrations achieved using adaptive optics), with the goal being to restore image quality in aberrated images such that cellular-level detail can be obtained. Overall, stratified CycleGAN generated higher quality synthetic images than traditional CycleGAN. Evaluation of cell detection accuracy confirmed that synthetic images were faithful to ground truth images of the same cells. Across this challenging dataset, F1-score improved from 76.9 ± 5.7% when using traditional CycleGAN to 85.0±3.4% when using stratified CycleGAN. These findings demonstrate the potential of stratified Cycle-GAN to improve the synthesis of medical images that exhibit a graded variation in image quality.",Adaptive optics; Cell detection; CycleGAN; Data parsing; Image quality; Ophthalmology; Semi-supervised learning,Journal Article,,,,,,,,
43,Knowledge-guided Pretext Learning for Utero-placental Interface Detection.,12261,,582-593,",,","Qi Huan,Collins Sally,Noble J Alison",,10.1007/978-3-030-59710-8_57,,,,Journal Article,,,,,,,,
44,A Curriculum Learning Based Approach to Captioning Ultrasound Images.,12437,,75-84,",,,,,","Alsharid Mohammad,El-Bouri Rasheed,Sharma Harshita,Drukker Lior,Papageorghiou Aris T,Noble J Alison",,10.1007/978-3-030-60334-2_8,,"We present a novel curriculum learning approach to train a natural language processing (NLP) based fetal ultrasound image captioning model. Datasets containing medical images and corresponding textual descriptions are relatively rare and hence, smaller-sized when compared to the datasets of natural images and their captions. This fact inspired us to develop an approach to train a captioning model suitable for small-sized medical data. Our datasets are prepared using real-world ultrasound video along with synchronised and transcribed sonographer speech recordings. We propose a ""dual-curriculum"" method for the ultrasound image captioning problem. The method relies on building and learning from curricula of image and text information for the ultrasound image captioning problem. We compare several distance measures for creating the dual curriculum and observe the best performance using the Wasserstein distance for image information and tf-idf metric for text information. The evaluation results show an improvement in all performance metrics when using curriculum learning over stochastic mini-batch training for the individual task of image classification as well as using a dual curriculum for image captioning.",Curriculum learning; Fetal ultrasound; Image captioning,Journal Article,,,,,,,,
45,Intelligent Sensory Pen for Aiding in the Diagnosis of Parkinson's Disease from Dynamic Handwriting Analysis,20,20,,"Junior Eugenio Peixoto,Delmiro Italo L. D.,Magaia Naercio,Maia Fernanda M.,Hassan Mohammad Mehedi,Albuquerque Victor Hugo C.,Fortino Giancarlo","Peixoto E,Delmiro ILD,Magaia N,Maia FM,Hassan MM,Albuquerque VHC,Fortino G",Fortino G,10.3390/s20205840,University of Calabria,"In this paper, we propose a pen device capable of detecting specific features from dynamic handwriting tests for aiding on automatic Parkinson's disease identification. The method used in this work uses machine learning to compare the raw signals from different sensors in the device coupled to a pen and extract relevant information such as tremors and hand acceleration to diagnose the patient clinically. Additionally, the datasets composed of raw signals from healthy and Parkinson's disease patients acquired here are made available to further contribute to research related to this topic.","Parkinson&#8217,s disease,machine learning,handwritten dynamics",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"ACTIVITY,RECOGNITION,CLASSIFICATION",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7602671,
46,A Multilevel Isolation Forrest and Convolutional Neural Network Algorithm for Impact Characterization on Composite Structures,20,20,,"Salehzadeh Nobari Amin Ebrahim,Aliabadi M. H. Ferri","Nobari AES,Aliabadi MHF",Nobari AES; Aliabadi MHF,10.3390/s20205896,Imperial College London,"In this paper, a Deep Learning approach is proposed to classify impact data based on the type of impact (Hard or Soft Impacts), via obtaining voltage signals from Piezo-Electric sensors, mounted on a composite panel. The data is processed further to be classified based on their energy, location and material. Minimalistic and Automated feature extraction and selection is achieved via a deep learning algorithm. Convolutional Neural Networks (CNN) are employed to extract and select important features from the voltage data. Once features are selected the impacts, are classified based on either, Hard Impacts (simulated from steel impactors in a lab setting), Soft Impacts (simulated from silicon impactors in a lab setting) and their corresponding location and energy levels. Furthermore, in order to use the right data for training they are obtained from the signals as anomalies via Isolation Forests (IF) to speed up the process. Using this approach Hard and Soft Impacts, their corresponding locations and respective energies are identified with high accuracy.","Piezo-Electric sensors,Convolutional Neural Networks,minimalistic and automated,feature extraction,Isolation Forests",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://www.mdpi.com/1424-8220/20/20/5896/pdf,
47,Time-range based sequential mining for survival prediction in prostate cancer,110,,,"Kaur Ishleen,Doja M. N.,Ahmad Tanvir","Kaur I,Doja MN,Ahmad T",Kaur I,10.1016/j.jbi.2020.103550,"Jamia Millia Islamia, New Delhi, India.","Background and objective: Metastatic prostate cancer has a higher mortality rate than localized cancers. There is a need to investigate the survival outcome of metastatic prostate cancers separately. Also, the treatments undertaken by the patients affect their overall survival. The present study tries to analyze the sequence of treatments given to the patients, along with the time intervals between each set of treatments. The time when medication needs to be changed may provide some useful insights into the survival outcome of the patients.
Materials and methods: A total of 407 metastatic prostate cancer patients' data was collected and analyzed from an Indian tertiary care center. Popular sequence mining algorithms with exact order constraint have been applied to the treatment data. Appropriate time intervals were added in the resulted frequent sequences and fed to machine learning techniques along with other clinical data.
Results: The study suggests that the proposed methodology of the time range based sequence mining approach gave better results than the existing methods with 84.5% accuracy and 0.89 AUC. The time intervals in the existing sequence mining algorithms can give the clinicians some useful insights into the survival analysis and in determining the best lines of treatments for a particular patient.","Cancer survival,Machine learning,Medical decision making,Sequential mining,Treatment patterns",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Computer Science,Medical Informatics",,,,JOURNAL OF BIOMEDICAL INFORMATICS,https://doi.org/10.1016/j.jbi.2020.103550,
48,Accelerated training of bootstrap aggregation-based deep information extraction systems from cancer pathology reports,110,,,"Yoon Hong-Jun,Klasky Hilda B.,Gounley John P.,Alawad Mohammed,Gao Shang,Durbin Eric B.,Wu Xiao-Cheng,Stroup Antoinette,Doherty Jennifer,Coyle Linda","Yoon HJ,Klasky HB,Gounley JP,Alawad M,Gao S,Durbin EB,Wu XC,Stroup A,Doherty J,Coyle L",Yoon HJ,10.1016/j.jbi.2020.103564,United States Department of Energy (DOE),"Objective: In machine learning, it is evident that the classification of the task performance increases if bootstrap aggregation (bagging) is applied. However, the bagging of deep neural networks takes tremendous amounts of computational resources and training time. The research question that we aimed to answer in this research is whether we could achieve higher task performance scores and accelerate the training by dividing a problem into sub-problems.
Materials and Methods : The data used in this study consist of free text from electronic cancer pathology reports. We applied bagging and partitioned data training using Mull-Task Convolutional Neural Network (MT-CNN) and Mull-Task Hierarchical Convolutional Attention Network (MT-HCAN) classifiers. We split a big problem into 20 sub-problems, resampled the training cases 2,000 times, and trained the deep learning model for each bootstrap sample and each sub-problem-thus, generating up to 40,000 models. We performed the training of many models concurrently in a high-performance computing environment at Oak Ridge National Laboratory (ORNL).
Results: We demonstrated that aggregation of the models improves task performance compared with the single-model approach, which is consistent with other research studies; and we demonstrated that the two proposed partitioned bagging methods achieved higher classification accuracy scores on four tasks. Notably, the improvements were significant for the extraction of cancer histology data, which had more than 500 class labels in the task; these results show that data partition may alleviate the complexity of the task. On the contrary, the methods did not achieve superior scores for the tasks of site and subsite classification. Intrinsically, since data partitioning was based on the primary cancer site, the accuracy depended on the determination of the partitions, which needs further investigation and improvement.
Conclusion: Results in this research demonstrate that 1. The data partitioning and bagging strategy achieved higher performance scores. 2. We achieved faster training leveraged by the high-performance Summit supercomputer at ORNL.","Bootstrap aggregation,Data partitioning,Natural language processing,Convolutional neural networks,Hierarchical self-attention networks,Deep learning,High-performance computing",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Computer Science,Medical Informatics",,5.221,ENSEMBLE,JOURNAL OF BIOMEDICAL INFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8276580,
49,Prediction of the mechanical properties of rebars through a combination of finite element and data-driven models,,10,26-33,"Colla V,Vannucci M.,Valentini R.","Colla V,Vannucci M,Valentini R",Colla V,,Scuola Superiore Sant'Anna,"Rebars are applied in the construction sector to provide the building structure with suitable tensile strength and resistance for eansuring safety. Rebars are produced through heat treatments within the TempCore (R) process, which aims at obtaining an internal structure of the material that allows achieving the desired mechanical characteristics. In this work advanced data processing techniques and data-driven models are used in order to develop predictive models for the main mechanical characteristics of the rebars using information on the chemical composition of the steel and on the heat treatments as well as the results of a finite element model estimating the microstructure of the bars. The models discussed in the article have been trained and validated using plant data and, in light of the results obtained, can be used in the product engineering as well as in the configuration of the TempCore (R) process.","TEMPCORE (R) PROCESS,MACHINE LEARNING,MECHANICAL PROPERTIES",Article,"ASSOC ITALIANA METALLURGIA, PIAZZALE RODOLFO MORANDI, 2, MILAN, 20121, ITALY",Metallurgy & Metallurgical Engineering,,0.544,"TEMPCORE,BARS",METALLURGIA ITALIANA,,
50,Secure Deep Learning for Intelligent Terahertz Metamaterial Identification,20,19,,"Liu Feifei,Zhang Weihao,Sun Yu,Liu Jianwei,Miao Jungang,He Feng,Wu Xiaojun","Liu FF,Zhang WH,Sun Y,Liu JW,Miao JG,He F,Wu XJ",Sun Y,10.3390/s20195673,Beihang University,"Metamaterials, artificially engineered structures with extraordinary physical properties, offer multifaceted capabilities in interdisciplinary fields. To address the looming threat of stealthy monitoring, the detection and identification of metamaterials is the next research frontier but have not yet been explored. Here, we show that the crypto-oriented convolutional neural network (CNN) makes possible the secure intelligent detection of metamaterials in mixtures. Terahertz signals were encrypted by homomorphic encryption and the ciphertext was submitted to the CNN directly for results, which can only be decrypted by the data owner. The experimentally measured terahertz signals were augmented and further divided into training sets and test sets using 5-fold cross-validation. Experimental results illustrated that the model achieved an accuracy of 100% on the test sets, which highly outperformed humans and the traditional machine learning. The CNN took 9.6 s to inference on 92 encrypted test signals with homomorphic encryption backend. The proposed method with accuracy and security provides private preserving paradigm for artificial intelligence-based material identification.","metamaterial identification,deep learning,homomorphic encryption,private preserving,terahertz time domain spectroscopy (THz-TDS)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,LABEL-FREE,SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7583053,
51,Pathadin - The essential set of tools to start with whole slide analysis,122,7,,"Dzaparidze Georgi,Kazachonok Dmitri,Laht Kristi,Taelma Heleri,Minajeva Ave","Dzaparidze G,Kazachonok D,Laht K,Taelma H,Minajeva A",Dzaparidze G,10.1016/j.acthis.2020.151619,"East Tallinn Cent Hosp, Pathol Dept, Herne St 33, EE-10135 Tallinn, Estonia.","Pathadin (https://github.com/Digipathology/Pathadin) was designed as a WSI oriented open-source set of tools for beginners to experience the advantages of computer-assisted image analysis and cover essential features, frequently strenuous to access with the alternative programs. It is mainly oriented to work with histology slides but also includes a significant part of modern image formats. Introducing Pathadin, the manuscript aims to improve understanding of contemporary image analysis components, resolve technophobia and misbeliefs in the computational field, simplifying pathology research work, and shifting it into a quantitative paradigm.
Despite being easy to use, Pathadin includes both basic and advanced analytical algorithms, as the application of machine learning.
The functionality of Pathadin is demonstrated by AI-enhanced quantification of epithelial and stromal changes in prostate carcinoma, and their dependence on ISUP grade. The material included 5 radical prostatectomy samples for training and 83 (including 11 autopsies) samples for analysis. The analytical material was stained with Masson's trichrome and Ki67, as widely available and potentially prognostic markers. An integrated solution by HistomicsTK for Ki67 evaluation was used. A U-net model for separating glands and stroma was trained, simplifying the independent analysis of these components.
During the process, the model successfully highlighted glands and stroma. Masson's trichrome stain demonstrated a gradual increase in collagen expression, being statistically significant between controls vs. G1, and G3 vs. G4. Although there was considerable overlap between adjacent groups, there was only a minor overlap in collagen amount between high- and low-grade carcinomas, affirming that with further research, stroma could be an additional diagnostic marker in prostate adenocarcinoma. Ki67 showed a statistically significant gradual increase in all groups except G1 vs. G2 and G4 vs. G5.
Pathadin demonstrates that there is no need for significant resources to experience the advantages of modern computer-assisted analysis.","Gleason grade,Machine learning,Open-source,Pathadin,Prostate,Stroma,Whole-slide imaging",Article,"ELSEVIER GMBH, HACKERBRUCKE 6, 80335 MUNICH, GERMANY",Cell Biology,,2.456,"PROSTATE-CANCER,REACTIVE,STROMA,GROWTH,IMAGE",ACTA HISTOCHEMICA,,
52,Classification of Partial Discharge Images Using Deep Convolutional Neural Networks,13,20,,Florkowski Marek,Florkowski M,Florkowski M,10.3390/en13205496,AGH University of Science & Technology,"Artificial intelligence-based solutions and applications have great potential in various fields of electrical power engineering. The problem of the electrical reliability of power equipment directly refers to the immunity of high-voltage (HV) insulation systems to operating stresses, overvoltages and other stresses-in particular, those involving strong electric fields. Therefore, tracing material degradation processes in insulation systems requires dedicated diagnostics; one of the most reliable quality indicators of high-voltage insulation systems is partial discharge (PD) measurement. In this paper, an example of the application of a neural network to partial discharge images is presented, which is based on the convolutional neural network (CNN) architecture, and used to recognize the stages of the aging of high-voltage electrical insulation based on PD images. Partial discharge images refer to phase-resolved patterns revealing various discharge stages and forms. The test specimens were aged under high electric stress, and the measurement results were saved continuously within a predefined time period. The four distinguishable classes of the electrical insulation degradation process were defined, mimicking the changes that occurred within the electrical insulation in the specimens (i.e., start, middle, end and noise/disturbance), with the goal of properly recognizing these stages in the untrained image samples. The results reflect the exemplary performance of the CNN and its resilience to manipulations of the network architecture and values of the hyperparameters. Convolutional neural networks seem to be a promising component of future autonomous PD expert systems.","partial discharges,phase-resolved patterns,high voltage insulation,diagnostics,machine learning,deep learning,convolutional neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"PATTERN-RECOGNITION,IDENTIFICATION,DIAGNOSIS,DISCRIMINATION,SYSTEMS",ENERGIES,https://www.mdpi.com/1996-1073/13/20/5496/pdf,
53,Identifying Tree Traits for Cooling Urban Heat Islands-A Cross-City Empirical Analysis,11,10,,"Helletsgruber Carola,Gillner Sten,Gulyas Agnes,Junker Robert R.,Tanacs Eszter,Hof Angela","Helletsgruber C,Gillner S,Gulyas A,Junker RR,Tanacs E,Hof A",Helletsgruber C,10.3390/f11101064,Salzburg University,"Research Highlights: This paper presents a cross-city empirical study on micro-climatic thermal benefits of urban trees, using machine-learning analysis to identify the importance of several in situ measured tree physiognomy traits for cooling. Background and Objectives: Green infrastructure and trees in particular play a key role in mitigating the urban heat island (UHI) effect. A more detailed understanding of the cooling potential of urban trees and specific tree traits is necessary to support tree management decisions for cooling our progressively hot cities. The goal of this study was to identify the influence and importance of various tree traits and site conditions. Materials and Methods: Surface temperature, air temperature at 1.1 m and at tree crown height, as well as wet bulb globe-temperature of shaded and fully sun-exposed reference areas, were used to study the cooling effect of seven different urban tree species. For all 100 individuals, tree height, crown base, trunk circumference, crown volume, crown area, leaf area index (LAI) and leaf area density (LAD) were measured. Measurements were conducted in the cities of Dresden, Salzburg, Szeged, and Vienna as representatives for middle European cities in different climate zones. Results: Beside site conditions, tree species, height, height of crown base, as well as trunk circumference, have a great influence on the cooling effect for city dwellers. The trunk circumference is a very valuable indicator for estimating climate regulating ecosystem services and therefore a highly robust estimator for policy makers and tree management practitioners when planning and managing urban green areas for improving the availability and provision of ecosystem services.","microclimate,tree physiognomy,random forest",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Forestry,,2.804,"ECOSYSTEM,SERVICES,TEMPERATURE,SURFACE,VEGETATION,BENEFITS,PROVIDE,CLIMATE,SHADE",FORESTS,https://www.mdpi.com/1999-4907/11/10/1064/pdf,
54,"Ten Years of Provenance Trials and Application of Multivariate Random Forests Predicted the Most Preferable Seed Source for Silviculture of Abies sachalinensis in Hokkaido, Japan",11,10,,"Tsuyama Ikutaro,Ishizuka Wataru,Kitamura Keiko,Taneda Haruhiko,Goto Susumu","Tsuyama I,Ishizuka W,Kitamura K,Taneda H,Goto S",Tsuyama I,10.3390/f11101058,Forestry & Forest Products Research Institute - Japan,"Research highlights: Using 10-year tree height data obtained after planting from the range-wide provenance trials of Abies sachalinensis, we constructed multivariate random forests (MRF), a machine learning algorithm, with climatic variables. The constructed MRF enabled prediction of the optimum seed source to achieve good performance in terms of height growth at every planting site on a fine scale. Background and objectives: Because forest tree species are adapted to the local environment, local seeds are empirically considered as the best sources for planting. However, in some cases, local seed sources show lower performance in height growth than that showed by non-local seed sources. Tree improvement programs aim to identify seed sources for obtaining high-quality timber products by performing provenance trials. Materials and methods: Range-wide provenance trials for one of the most important silvicultural species, Abies sachalinensis, were established in 1980 at nine transplanting experimental sites. We constructed an MRF to estimate the responses of tree height at 10 years after planting at eight climatic variables at 1 km x 1 km resolution. The model was applied for prediction of tree height throughout Hokkaido Island. Results: Our model showed that four environmental variables were major factors affecting height growth-winter solar radiation, warmth index, maximum snow depth, and spring solar radiation. A tree height prediction map revealed that local seeds showed the best performance except in the southernmost region and several parts of northern regions. Moreover, the map of optimum seed provenance suggested that deployment of distant seed sources can outperform local sources in the southernmost and northern regions. Conclusions: We predicted that local seeds showed optimum growth, whereas non-local seeds had the potential to outperform local seeds in some regions. Several deployment options were proposed to improve tree growth.","local adaptation,Sakhalin fir,silviculture,seed zone,tree improvement program",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Forestry,,2.804,"CLIMATE-CHANGE,TRANSFER,GUIDELINES,IMPACT,ASSESSMENT,GENE,FLOW,ADAPTATION,VELOCITY,PINE,CONSERVATION,RESPONSES,SURVIVAL",FORESTS,https://www.mdpi.com/1999-4907/11/10/1058/pdf,
55,Modified DenseNet for Automatic Fabric Defect Detection With Edge Computing for Minimizing Latency,7,10,9623-9636,"Zhu Zongwei,Han Guangjie,Jia Gangyong,Shu Lei","Zhu ZW,Han GJ,Jia GY,Shu L",Han GJ,10.1109/JIOT.2020.2983050,Nanjing Agricultural University,"As an essential step in quality control, fabric defect detection plays an important role in the textile manufacturing industry. The traditional manual detection method is inaccurate and incurs a high cost; as a result, it is gradually being replaced by deep learning algorithms based on cloud computing. However, a high data transmission latency between end devices and the cloud has a significant impact on textile production efficiency. In contrast, edge computing, which provides services near end devices by deploying network, computing and storage facilities at the edge of the Internet, can effectively solve the above-mentioned problem. In this article, we propose a deep-learning-based fabric defect detection method for edge computing scenarios. First, this article modifies the structure of DenseNet to better suit a resource-constrained edge computing scenario. To better assess the proposed model, an optimized cross-entropy loss function is also formulated. Afterward, six feasible expansion schemes are utilized to enhance the data set according to the characteristics of various defects in fabric samples. To balance the distribution of samples, proportions of various defect types are used to determine the number of enhancements. Finally, a fabric defect detection system is established to test the performance of the optimized model used on edge devices in a real-world textile industry scenario. Experimental results demonstrate that compared with the conventional convolutional neural network (CNN), the proposed optimized model attains an average improvement of 18% in the area under the curve (AUC) metric for 11 defects. Data transmission is reduced by approximately 50% and latency is reduced by 32% in the Cambricon 1H8 platform compared with a cloud platform.","Fabrics,Production,Computational modeling,Edge computing,Cloud computing,Image edge detection,Adaptation models,Convolutional neural network (CNN),edge computing,fabric defect detection,image processing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,10.127,"INTERNET,CLASSIFICATION,THINGS",IEEE INTERNET OF THINGS JOURNAL,,
56,EEG-Based Maritime Object Detection for IoT-Driven Surveillance Systems in Smart Ocean,7,10,9678-9687,"Duan Yiping,Li Zhe,Tao Xiaoming,Li Qiang,Hu Shuzhan,Lu Jianhua","Duan YP,Li Z,Tao XM,Li Q,Hu SZ,Lu JH",Tao XM,10.1109/JIOT.2020.2991025,Tsinghua University,"Automated maritime object detection is a significant research challenge in intelligent marine surveillance systems for the Internet of Things (IoT) and smart ocean applications. In particular, ship detection is recognized as one of the core research issues of these IoT-driven intelligent marine surveillance systems. Traditional methods based on machine learning have made some achievements in detection tasks for specific objects. However, the ship objects are relatively small, and they are usually not accurately detected. In this article, we propose an electroencephalography (EEG)-based maritime object detection algorithm for IoT-driven surveillance systems in the smart ocean. For this purpose, we conduct experiments to record the EEG signals of subjects when they are watching the maritime image scenes. With the feature analysis of EEG signals, the event-related potential (ERP) components associated with detecting objects are induced, such as the $P3$ and $N2$ components. Employing classification based on linear discriminant analysis (LDA), the area under curve (AUC) of the receiver operating characteristic (ROC) is used to evaluate the detection accuracy. We use this novel method to determine and identify essential objects and areas from IoT devices, such as digital camera imaging sensors. Our proposed method can not only help to detect small objects accurately using fewer samples but can also be used to reduce the data volume needed to be stored and transmitted in IoT-driven marine surveillance systems.","Internet of Things,Object detection,Surveillance,Electroencephalography,Feature extraction,Oceans,Marine vehicles,Electroencephalography (EEG),intelligent surveillance systems,Internet of Things (IoT),maritime object detection,smart ocean",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,10.127,"CLASSIFICATION,TRACKING",IEEE INTERNET OF THINGS JOURNAL,,
57,A Noble Double-Dictionary-Based ECG Compression Technique for IoTH,7,10,10160-10170,"Qian Jia,Tiwari Prayag,Gochhayat Sarada Prasad,Pandey Hari Mohan","Qian J,Tiwari P,Gochhayat SP,Pandey HM",Pandey HM,10.1109/JIOT.2020.2974678,Edge Hill University,"The Internet-of-Things (IoT) healthcare system monitors a patients' condition and takes preventive measures in case of an emergency. The electrocardiogram (ECG) that measures the electrical activity of the heart is one of the important health indicators. Thanks to the wearable technology, nowadays, we can even measure the ECG using smart portable devices and send via a wireless channel. However, this wireless transmission has to minimize both energy and memory consumption. In this article, we propose CULT-an ECG compression technique using unsupervised dictionary learning. Our method achieves a high compression rate due to the essence of dictionary learning and is immune to the noise by integrating discrete cosine transformation. Moreover, it continuously expands the dictionary when the unseen pattern occurs and refines the dictionary when new input arrives, by imposing the double dictionary scheme. We show that our method has a better performance by comparing it with the other existing approaches.","Dictionaries,Electrocardiography,Training,Biomedical monitoring,Internet of Things,Wireless communication,Electronic mail,Compression,dictionary learning,electrocardiogram (ECG),Internet-of-Things (IoT) healthcare,vector quantization",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,10.127,"VECTOR,QUANTIZATION,TRANSFORM",IEEE INTERNET OF THINGS JOURNAL,https://backend.orbit.dtu.dk/ws/files/209343343/09001036.pdf,
58,Extended Capture Range of Rigid 2D/3D Registration by Estimating Riemannian Pose Gradients.,12436,,281-291,",,,,","Gu Wenhao,Gao Cong,Grupp Robert,Fotouhi Javad,Unberath Mathias",,10.1007/978-3-030-59861-7_29,,"Traditional intensity-based 2D/3D registration requires near-perfect initialization in order for image similarity metrics to yield meaningful updates of X-ray pose and reduce the likelihood of getting trapped in a local minimum. The conventional approaches strongly depend on image appearance rather than content, and therefore, fail in revealing large pose offsets that substantially alter the appearance of the same structure. We complement traditional similarity metrics with a convolutional neural network-based (CNN-based) registration solution that captures large-range pose relations by extracting both local and contextual information, yielding meaningful X-ray pose updates without the need for accurate initialization. To register a 2D X-ray image and a 3D CT scan, our CNN accepts a target X-ray image and a digitally reconstructed radiograph at the current pose estimate as input and iteratively outputs pose updates in the direction of the pose gradient on the Riemannian Manifold. Our approach integrates seamlessly with conventional image-based registration frameworks, where long-range relations are captured primarily by our CNN-based method while short-range offsets are recovered accurately with an image similarity-based method. On both synthetic and real X-ray images of the human pelvis, we demonstrate that the proposed method can successfully recover large rotational and translational offsets, irrespective of initialization.",CT; Image-guided Surgery; Machine Learning; X-ray,Journal Article,,,,,,,,
59,Self-supervised Contrastive Video-Speech Representation Learning for Ultrasound.,12263,,534-543,",,,,,","Jiao Jianbo,Cai Yifan,Alsharid Mohammad,Drukker Lior,Papageorghiou Aris T,Noble J Alison",,10.1007/978-3-030-59716-0_51,,"In medical imaging, manual annotations can be expensive to acquire and sometimes infeasible to access, making conventional deep learning-based models difficult to scale. As a result, it would be beneficial if useful representations could be derived from raw data without the need for manual annotations. In this paper, we propose to address the problem of self-supervised representation learning with multi-modal ultrasound video-speech raw data. For this case, we assume that there is a high correlation between the ultrasound video and the corresponding narrative speech audio of the sonographer. In order to learn meaningful representations, the model needs to identify such correlation and at the same time understand the underlying anatomical features. We designed a framework to model the correspondence between video and audio without any kind of human annotations. Within this framework, we introduce cross-modal contrastive learning and an affinity-aware self-paced learning scheme to enhance correlation modelling. Experimental evaluations on multi-modal fetal ultrasound video and audio show that the proposed approach is able to learn strong representations and transfers well to downstream tasks of standard plane detection and eye-gaze prediction.",Representation learning; Self-supervised; Video-audio,Journal Article,,,,,,,,
60,Learned Proximal Networks for Quantitative Susceptibility Mapping.,12262,,125-135,",,,,","Lai Kuo-Wei,Aggarwal Manisha,van Zijl Peter,Li Xu,Sulam Jeremias",,10.1007/978-3-030-59713-9_13,,"Quantitative Susceptibility Mapping (QSM) estimates tissue magnetic susceptibility distributions from Magnetic Resonance (MR) phase measurements by solving an ill-posed dipole inversion problem. Conventional single orientation QSM methods usually employ regularization strategies to stabilize such inversion, but may suffer from streaking artifacts or over-smoothing. Multiple orientation QSM such as calculation of susceptibility through multiple orientation sampling (COSMOS) can give well-conditioned inversion and an artifact free solution but has expensive acquisition costs. On the other hand, Convolutional Neural Networks (CNN) show great potential for medical image reconstruction, albeit often with limited interpretability. Here, we present a Learned Proximal Convolutional Neural Network (LP-CNN) for solving the ill-posed QSM dipole inversion problem in an iterative proximal gradient descent fashion. This approach combines the strengths of data-driven restoration priors and the clear interpretability of iterative solvers that can take into account the physical model of dipole convolution. During training, our LP-CNN learns an implicit regularizer via its proximal, enabling the decoupling between the forward operator and the data-driven parameters in the reconstruction algorithm. More importantly, this framework is believed to be the first deep learning QSM approach that can naturally handle an arbitrary number of phase input measurements without the need for any ad-hoc rotation or re-training. We demonstrate that the LP-CNN provides state-of-the-art reconstruction results compared to both traditional and deep learning methods while allowing for more flexibility in the reconstruction process.",Deep learning; Proximal learning; Quantitative Susceptibility Mapping,Journal Article,,,,,,,,
61,Learning a Gradient Guidance for Spatially Isotropic MRI Super-Resolution Reconstruction.,12262,,136-146,",,,","Sui Yao,Afacan Onur,Gholipour Ali,Warfield Simon K",,10.1007/978-3-030-59713-9_14,,"In MRI practice, it is inevitable to appropriately balance between image resolution, signal-to-noise ratio (SNR), and scan time. It has been shown that super-resolution reconstruction (SRR) is effective to achieve such a balance, and has obtained better results than direct high-resolution (HR) acquisition, for certain contrasts and sequences. The focus of this work was on constructing images with spatial resolution higher than can be practically obtained by direct Fourier encoding. A novel learning approach was developed, which was able to provide an estimate of the spatial gradient prior from the low-resolution (LR) inputs for the HR reconstruction. By incorporating the anisotropic acquisition schemes, the learning model was trained over the LR images themselves only. The learned gradients were integrated as prior knowledge into a gradient-guided SRR model. A closed-form solution to the SRR model was developed to obtain the HR reconstruction. Our approach was assessed on the simulated data as well as the data acquired on a Siemens 3T MRI scanner containing 45 MRI scans from 15 subjects. The experimental results demonstrated that our approach led to superior SRR over state-of-the-art methods, and obtained better images at lower or the same cost in scan time than direct HR acquisition.",Deep neural networks; MRI; Super-resolution,Journal Article,,,,,,,,
62,A Novel Technique Solving Shortages of Low-Concentration Samples of Electronic Nose Based on Global and Local Features Fusion,20,19,11412-11420,"Xu Duo,Jia Pengfei,Cao Huaisheng,Cao Wen,Wu Guocheng","Xu D,Jia PF,Cao HS,Cao W,Wu GC",Jia PF,10.1109/JSEN.2020.2998821,Southwest University - China,"Low-concentration samples play an important role in the training of the electronic nose (E-nose), while low-concentration samples are difficult to obtain because of the limited accuracy of sensor detection, and the confect precision of low-concentration samples are hard to control. Traditionally, we can improve the accuracy of the sensors by improving their materials, but this method is costly and difficult to operate. We devised another efficient and convenient method by using algorithms, which can improve the recognition accuracy of low-concentration samples. In this paper, we put forward a novel technique that combines the global and local features, that is, the fusion of the features can reflect the characteristics of the data from comprehensive perspectives. We used this technique to explore whether there exists a situation that the recognition rate of E-nose trained by the samples with different concentration are the same or not. After that, we proposed a new evaluation index based on the dependence of low-concentration samples to judge kinds of feature extraction algorithms. The experimental results show that whether the algorithms of global features (PCA and ICA), the algorithms of local features (LPP and NPE) or the fusion, there are effective and alternative solutions, that is, we can use more high-concentration samples to replace the comparatively minor number of low-concentration samples in the training set. In addition, compared with other algorithms, the fusion of ICA and LPP based on weighted enumeration and EQPSO has the highest recognition rate with the least number of high-concentration samples.","Sensor arrays,Feature extraction,Principal component analysis,Methane,Gas detectors,Electronic nose,feature extraction,global features,local features,low-concentration samples",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,ICA,IEEE SENSORS JOURNAL,,
63,Deep Parametric Mixtures for Modeling the Functional Connectome.,12329,,133-143,",,,","Honnorat Nicolas,Pfefferbaum Adolf,Sullivan Edith V,Pohl Kilian M",,10.1007/978-3-030-59354-4_13,,"Functional connectivity between brain regions is often estimated by correlating brain activity measured by resting-state fMRI in those regions. The impact of factors (e.g, disorder or substance use) are then modeled by their effects on these correlation matrices in individuals. A crucial step in better understanding their effects on brain function could lie in estimating connectomes, which encode the correlation matrices across subjects. Connectomes are mostly estimated by creating a single average for a specific cohort, which works well for binary factors (such as sex) but is unsuited for continuous ones, such as alcohol consumption. Alternative approaches based on regression methods usually model each pair of regions separately, which generally produces incoherent connectomes as correlations across multiple regions contradict each other. In this work, we address these issues by introducing a deep learning model that predicts connectomes based on factor values. The predictions are defined on a simplex spanned across correlation matrices, whose convex combination guarantees that the deep learning model generates well-formed connectomes. We present an efficient method for creating these simplexes and improve the accuracy of the entire analysis by defining loss functions based on robust norms. We show that our deep learning approach is able to produce accurate models on challenging synthetic data. Furthermore, we apply the approach to the resting-state fMRI scans of 281 subjects to study the effect of sex, alcohol, and HIV on brain function.",,Journal Article,,,,,,,,
64,The Big Hack Explained: Detection and Prevention of PCB Supply Chain Implants,16,4,,"Mehta Dhwani,Lu Hangwei,Paradis Olivia P.,Azhagan Mukhil M. S.,Rahman M. Tanjidur,Iskander Yousef,Chawla Praveen,Woodard Damon L.,Tehranipoor Mark,Asadizanjani Navid","Mehta D,Lu HW,Paradis OP,Azhagan MSM,Rahman MT,Iskander Y,Chawla P,Woodard DL,Tehranipoor M,Asadizanjani N",Mehta D,10.1145/3401980,State University System of Florida,"Over the past two decades, globalized outsourcing in the semiconductor supply chain has lowered manufacturing costs and shortened the time-to-market for original equipment manufacturers (OEMs). However, such outsourcing has rendered the printed circuit boards (PCBs) vulnerable to malicious activities and alterations on a global scale. In this article, we take an in-depth look into one such attack, called the ""Big I lack,"" that was recently reported by Bloomberg Buisnessweek. The article provides background on the Big Hack from three perspectives: an attacker, a security investigator, and the societal impacts. This study provides details on vulnerabilities in the modem PCB supply chain, the possible attacks, and the existing and emerging countermeasures. The necessity for novel visual inspection techniques for PCB assurance is emphasized throughout the article. Further, a review of various imaging modalities, image analysis algorithms, and open research challenges are provided for automated visual inspection.","Emerging attacks,PCB testing,imaging modalities,machine learning,bill of materials",Article,"ASSOC COMPUTING MACHINERY, 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA","Computer Science,Engineering,Science & Technology - Other Topics",,1.885,BOARDS,ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS,,
65,Adversarial Perturbation Attacks on ML-based CAD: A Case Study on CNN-based Lithographic Hotspot Detection,25,5,,"Liu Kang,Yang Haoyu,Ma Yuzhe,Tan Benjamin,Yu Bei,Young Evangeline F. Y.,Karri Ramesh,Garg Siddharth","Liu K,Yang HY,Ma YZ,Tan B,Yu B,Young EFY,Karri R,Garg S",Liu K,10.1145/3408288,New York University,"There is substantial interest in the use of machine learning (ML)-based techniques throughout the electronic computer-aided design (CAD) flow, particularly those based on deep learning. However, while deep learning methods have surpassed state-of-the-art performance in several applications, they have exhibited intrinsic susceptibility to adversarial perturbations-small but deliberate alterations to the input of a neural network, precipitating incorrect predictions. In this article, we seek to investigate whether adversarial perturbations pose risks to ML-based CAD tools, and if so, how these risks can be mitigated. To this end, we use a motivating case study of lithographic hotspot detection, for which convolutional neural networks (CNN) have shown great promise. In this context, we show the first adversarial perturbation attacks on state-of-the-art CNN-based hotspot detectors; specifically, we show that small (on average 0.5% modified area), functionality preserving, and design-constraint-satisfying changes to a layout can nonetheless trick a CNN-based hotspot detector into predicting the modified layout as hotspot free (with up to 99.7% success in finding perturbations that flip a detector's output prediction, based on a given set of attack constraints). We propose an adversarial retraining strategy to improve the robustness of CNN-based hotspot detection and show that this strategy significantly improves robustness (by a factor of similar to 3) against adversarial attacks without compromising classification accuracy.","ML-based CAD,security,adversarial perturbations,lithographic hotspot detection",Article,"ASSOC COMPUTING MACHINERY, 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA",Computer Science,,1.137,,ACM TRANSACTIONS ON DESIGN AUTOMATION OF ELECTRONIC SYSTEMS,http://arxiv.org/pdf/1906.10773,
66,Nano-enabled sensing approaches for pathogenic bacterial detection,165,,,"Alafeef Maha,Moitra Parikshit,Pan Dipanjan","Alafeef M,Moitra P,Pan DPJ",Pan DPJ,10.1016/j.bios.2020.112276,University System of Maryland,"Infectious diseases caused by pathogenic bacteria, especially antibiotic-resistant bacteria, are one of the biggest threats to global health. To date, bacterial contamination is detected using conventional culturing techniques, which are highly dependent on expert users, limited by the processing time and on-site availability. Hence, realtime and continuous monitoring of pathogen levels is required to obtain valuable information that could assist health agencies in guiding prevention and containment of pathogen-related outbreaks. Nanotechnology-based smart sensors are opening new avenues for early and rapid detection of such pathogens at the patient's point of-care. Nanomaterials can play an essential role in bacterial sensing owing to their unique optical, magnetic, and electrical properties. Carbon nanoparticles, metallic nanoparticles, metal oxide nanoparticles, and various types of nanocomposites are examples of smart nanomaterials that have drawn intense attention in the field of microbial detection. These approaches, together with the advent of modern technologies and coupled with machine learning and wireless communication, represent the future trend in the diagnosis of infectious diseases. This review provides an overview of the recent advancements in the successful harnessing of different nano particles for bacterial detection. In the beginning, we have introduced the fundamental concepts and mechanisms behind the design and strategies of the nanoparticles-based diagnostic platform. Representative research efforts are highlighted for in vitro and in vivo detection of bacteria. A comprehensive discussion is then presented to cover the most commonly adopted techniques for bacterial identification, including some seminal studies to detect bacteria at the single-cell level. Finally, we discuss the current challenges and a prospective outlook on the field, together with the recommended solutions.","Infectious diseases,Bacterial sensing,Nanoparticles,Machine learning,Carbon dots,Metallic nanoparticles",Article,"ELSEVIER ADVANCED TECHNOLOGY, OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Biophysics,Biotechnology & Applied Microbiology,Chemistry,Electrochemistry,Science & Technology - Other Topics",,9.323,"CARBON,QUANTUM,DOTS,SURFACE-PLASMON,RESONANCE,CORE-SHELL,NANOCOMPOSITES,ESCHERICHIA-COLI,O157H7,LABEL-FREE,DETECTION,SALMONELLA-TYPHIMURIUM,GOLD,NANOPARTICLES,SENSOR,ARRAY,ULTRASENSITIVE,DETECTION,SENSITIVE,DETECTION",BIOSENSORS & BIOELECTRONICS,,
67,Artificial intelligence biosensors: Challenges and prospects,165,,,"Jin Xiaofeng,Liu Conghui,Xu Tailin,Su Lei,Zhang Xueji","Jin XF,Liu CH,Xu TL,Su L,Zhang XJ",Xu TL,10.1016/j.bios.2020.112412,Shenzhen University,"Artificial intelligence (AI) and wearable sensors are two essential fields to realize the goal of tailoring the best precision medicine treatment for individual patients. Integration of these two fields enables better acquisition of patient data and improved design of wearable sensors for monitoring the wearers' health, fitness and their surroundings. Currently, as the Internet of Things (IoT), big data and big health move from concept to implementation, AI-biosensors with appropriate technical characteristics are facing new opportunities and challenges. In this paper, the most advanced progress made in the key phases for future wearable and implantable technology from biosensing, wearable biosensing to AI-biosensing is summarized. Without a doubt, material innovation, biorecognition element, signal acquisition and transportation, data processing and intelligence decision system are the most important parts, which are the main focus of the discussion. The challenges and opportunities of AI-biosensors moving forward toward future medicine devices are also discussed.","Wearable biosensor,Artificial intelligence,Biomarker,Wireless communication,Machine learning,Healthcare",Article,"ELSEVIER ADVANCED TECHNOLOGY, OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Biophysics,Biotechnology & Applied Microbiology,Chemistry,Electrochemistry,Science & Technology - Other Topics",,9.323,"TRIBOELECTRIC,NANOGENERATOR,ELECTROCHEMICAL,BIOSENSORS,FLEXIBLE,ELECTRONICS,CHEMICAL,SENSORS,ACTIVE,SENSORS,SMART,BANDAGE,POWER,SOURCE,GRAPHENE,FLOW,PROGRESS",BIOSENSORS & BIOELECTRONICS,,
68,Profiling DNA mutation patterns by SERS fingerprinting for supervised cancer classification,165,,,"Wu Lei,Teixeira Alexandra,Garrido-Maestu Alejandro,Muinelo-Romay Laura,Lima Luis,Lara Santos Lucio,Prado Marta,Dieguez Lorena","Wu L,Teixeira A,Garrido-Maestu A,Muinelo-Romay L,Lima L,Santos LL,Prado M,Dieguez L",Dieguez L,10.1016/j.bios.2020.112392,International Iberian Nanotechnology Laboratory,"Profiling DNA mutation patterns for cancer classification plays an essential role in precision and personalized medicine. Conventional PCR-based mutation assay is limited by the extensive labour on target amplification. We herein create an amplification-free surface enhanced Raman spectroscopy (SERS) biochip which enables direct and simultaneous identification of multiple point mutations in tumor cells. Without pre-amplifying the target sequences, the SERS assay reads out the presence of cellular mutations through the interpretation of Raman fingerprints. The SERS sensor is integrated into a microfluidic chip, achieving one-step multiplex analysis within 40 min. Importantly, by combining SERS spectra encoding technique with supervised learning algorithm, a panel of nucleotide mixtures can be well distinguished according to their mutation profiles. We initially demonstrate an excellent levels of classification in samples from colorectal cancer and melanoma cell lines. For final clinical validation, the system performance is verified by classifying cancer patient samples, which shows an accuracy above 90%. Due to the simplicity and rapidness, the SERS biosensor is expected to become a promising tool for clinical point-of-care diagnosis towards precision medicine.","Surface enhanced Raman spectroscopy (SERS),DNA mutation,Multiplex detection,Spectral encoding,Supervised cancer classification",Article,"ELSEVIER ADVANCED TECHNOLOGY, OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Biophysics,Biotechnology & Applied Microbiology,Chemistry,Electrochemistry,Science & Technology - Other Topics",,9.323,"SENSITIVE,DETECTION,MULTIPLEX,DETECTION,HETEROGENEITY,SINGLE,KRAS,PCR,RESISTANCE,BRAF",BIOSENSORS & BIOELECTRONICS,,
69,Robust Wheel Wear Monitoring System for Cylindrical Traverse Grinding,25,5,2220-2229,"Zhang Bin,Katinas Christopher,Shin Yung C.","Zhang B,Katinas C,Shin YC",Shin YC,10.1109/TMECH.2020.3007047,Purdue University System,"Although many advanced signal processing techniques and novel machine learning algorithms have been applied to the monitoring of grinding processes in the literature, most of these techniques and algorithms are only effective under specific conditions and are unusable under other grinding conditions, such as varying wheel types or workpiece materials. This article proposes a robust grinding wheel wear monitoring system to eliminate these restrictions. Physical information generated during the grinding process is collected by a power sensor, accelerometers, and acoustic emission sensors. After the signals are preprocessed, features are extracted via different signal processing techniques, and a novel normalization scheme is applied to make these features independent of the wheel type, workpiece material, and grinding parameters. The features that are most related to wheel wear are selected according to the statistical criterion. An interval type-2 fuzzy basis function network is adopted to develop a wheel wear monitoring model, which is capable of predicting wheel wear under various grinding conditions and generating upper and lower prediction bounds according to the fluctuation of features. Based on the wheel wear model, a robust monitoring scheme to schedule timely wheel dressing and ensure workpiece surface finish could be established.","Wheels,Monitoring,Rough surfaces,Surface roughness,Feature extraction,Surface treatment,Power measurement,Feature normalization,feature selection,grinding,type-2 fuzzy neural networks,wheel wear monitoring",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Engineering",,5.974,"SURFACE-ROUGHNESS,TOOL,WEAR,MODEL,PARAMETERS,SELECTION",IEEE-ASME TRANSACTIONS ON MECHATRONICS,,
70,Introducing the GEV Activation Function for Highly Unbalanced Data to Develop COVID-19 Diagnostic Models,24,10,2776-2786,"Bridge Joshua,Meng Yanda,Zhao Yitian,Du Yong,Zhao Mingfeng,Sun Renrong,Zheng Yalin","Bridge J,Meng YD,Zhao YT,Du Y,Zhao MF,Sun RR,Zheng YL",Bridge J,10.1109/JBHI.2020.3012383,University of Liverpool,"Fast and accurate diagnosis is essential for the efficient and effective control of the COVID-19 pandemic that is currently disrupting the whole world. Despite the prevalence of the COVID-19 outbreak, relatively few diagnostic images are openly available to develop automatic diagnosis algorithms. Traditional deep learning methods often struggle when data is highly unbalanced with many cases in one class and only a few cases in another; new methods must be developed to overcome this challenge. We propose a novel activation function based on the generalized extreme value (GEV) distribution from extreme value theory, which improves performance over the traditional sigmoid activation function when one class significantly outweighs the other. We demonstrate the proposed activation function on a publicly available dataset and externally validate on a dataset consisting of 1,909 healthy chest X-rays and 84 COVID-19 X-rays. The proposed method achieves an improved area under the receiver operating characteristic (DeLong's p-value < 0.05) compared to the sigmoid activation. Our method is also demonstrated on a dataset of healthy and pneumonia vs. COVID-19 X-rays and a set of computerized tomography images, achieving improved sensitivity. The proposed GEV activation function significantly improves upon the previously used sigmoid activation for binary classification. This new paradigm is expected to play a significant role in the fight against COVID-19 and other diseases, with relatively few training cases available.","Computed tomography,Sensitivity,Diseases,X-rays,Machine learning,Lung,Biomedical imaging,Artificial intelligence,computer-aided detection and diagnosis,covid-19,extreme value theory,lung,x-ray and computed tomography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,REGRESSION,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://ieeexplore.ieee.org/ielx7/6221020/9216186/09151288.pdf,
71,Efficient and Effective Training of COVID-19 Classification Networks With Self-Supervised Dual-Track Learning to Rank,24,10,2787-2797,"Li Yuexiang,Wei Dong,Chen Jiawei,Cao Shilei,Zhou Hongyu,Zhu Yanchun,Wu Jianrong,Lan Lan,Sun Wenbo,Qian Tianyi","Li YX,Wei D,Chen JW,Cao SL,Zhou HY,Zhu YC,Wu JR,Lan L,Sun WB,Qian TY",Zheng YF,10.1109/JBHI.2020.3018181,"Tencent Jarvis Lab, Shenzhen 518000, Peoples R China.","Coronavirus Disease 2019 (COVID-19) has rapidly spread worldwide since first reported. Timely diagnosis of COVID-19 is crucial both for disease control and patient care. Non-contrast thoracic computed tomography (CT) has been identified as an effective tool for the diagnosis, yet the disease outbreak has placed tremendous pressure on radiologists for reading the exams and may potentially lead to fatigue-related mis-diagnosis. Reliable automatic classification algorithms can be really helpful; however, they usually require a considerable number of COVID-19 cases for training, which is difficult to acquire in a timely manner. Meanwhile, how to effectively utilize the existing archive of non-COVID-19 data (the negative samples) in the presence of severe class imbalance is another challenge. In addition, the sudden disease outbreak necessitates fast algorithm development. In this work, we propose a novel approach for effective and efficient training of COVID-19 classification networks using a small number of COVID-19 CT exams and an archive of negative samples. Concretely, a novel self-supervised learning method is proposed to extract features from the COVID-19 and negative samples. Then, two kinds of soft-labels ('difficulty' and 'diversity') are generated for the negative samples by computing the earth mover's distances between the features of the negative and COVID-19 samples, from which data 'values' of the negative samples can be assessed. A pre-set number of negative samples are selected accordingly and fed to the neural network for training. Experimental results show that our approach can achieve superior performance using about half of the negative samples, substantially reducing model training time.","COVID-19,Training,Computed tomography,Lung,Measurement,Biomedical imaging,Coronavirus disease 2019,Self-supervised learning,efficient network training",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"IMAGE,DISTANCE",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
72,Adaptive Feature Selection Guided Deep Forest for COVID-19 Classification With Chest CT,24,10,2798-2805,"Sun Liang,Mo Zhanhao,Yan Fuhua,Xia Liming,Shan Fei,Ding Zhongxiang,Song Bin,Gao Wanchun,Shao Wei,Shi Feng","Sun L,Mo ZH,Yan FH,Xia LM,Shan F,Ding ZX,Song B,Gao WC,Shao W,Shi F",Zhang DQ,10.1109/JBHI.2020.3019505,Nanjing University of Aeronautics & Astronautics,"Chest computed tomography (CT) becomes an effective tool to assist the diagnosis of coronavirus disease-19 (COVID-19). Due to the outbreak of COVID-19 worldwide, using the computed-aided diagnosis technique for COVID-19 classification based on CT images could largely alleviate the burden of clinicians. In this paper, we propose an Adaptive Feature Selection guided Deep Forest (AFS-DF) for COVID-19 classification based on chest CT images. Specifically, we first extract location-specific features from CT images. Then, in order to capture the high-level representation of these features with the relatively small-scale data, we leverage a deep forest model to learn high-level representation of the features. Moreover, we propose a feature selection method based on the trained deep forest model to reduce the redundancy of features, where the feature selection could be adaptively incorporated with the COVID-19 classification model. We evaluated our proposed AFS-DF on COVID-19 dataset with 1495 patients of COVID-19 and 1027 patients of community acquired pneumonia (CAP). The accuracy (ACC), sensitivity (SEN), specificity (SPE), AUC, precision and F1-score achieved by our method are 91.79%, 93.05%, 89.95%, 96.35%, 93.10% and 93.07%, respectively. Experimental results on the COVID-19 dataset suggest that the proposed AFS-DF achieves superior performance in COVID-19 vs. CAP classification, compared with 4 widely used machine learning methods.","Feature extraction,Computed tomography,Lung,Forestry,Hospitals,Radiology,Diseases,COVID-19 classification,deep forest,feature selection,chest CT",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://ieeexplore.ieee.org/ielx7/6221020/9216186/09178424.pdf,
73,Contrastive Cross-Site Learning With Redesigned Net for COVID-19 CT Classification,24,10,2806-2813,"Wang Zhao,Liu Quande,Dou Qi","Wang Z,Liu QD,Dou Q",Dou Q,10.1109/JBHI.2020.3023246,Chinese University of Hong Kong,"The pandemic of coronavirus disease 2019 (COVID-19) has lead to a global public health crisis spreading hundreds of countries. With the continuous growth of new infections, developing automated tools for COVID-19 identification with CT image is highly desired to assist the clinical diagnosis and reduce the tedious workload of image interpretation. To enlarge the datasets for developing machine learning methods, it is essentially helpful to aggregate the cases from different medical systems for learning robust and generalizable models. This paper proposes a novel joint learning framework to perform accurate COVID-19 identification by effectively learning with heterogeneous datasets with distribution discrepancy. We build a powerful backbone by redesigning the recently proposed COVID-Net in aspects of network architecture and learning strategy to improve the prediction accuracy and learning efficiency. On top of our improved backbone, we further explicitly tackle the cross-site domain shift by conducting separate feature normalization in latent space. Moreover, we propose to use a contrastive training objective to enhance the domain invariance of semantic embeddings for boosting the classification performance on each dataset. We develop and evaluate our method with two public large-scale COVID-19 diagnosis datasets made up of CT images. Extensive experiments show that our approach consistently improves the performanceson both datasets, outperforming the original COVID-Net trained on each dataset by 12.16% and 14.23% in AUC respectively, also exceeding existing state-of-the-art multi-site learning methods.","Computed tomography,Diseases,Network architecture,Machine learning,Training,Lung,Biomedical imaging,Contrastive learning,COVID-19 CT diagnosis,multi-site data heterogeneity,network redesign",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"SEGMENTATION,DIAGNOSIS,NETWORK",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://arxiv.org/pdf/2009.07652,
74,QuPWM: Feature Extraction Method for Epileptic Spike Classification,24,10,2814-2824,"Chahid Abderrazak,Albalawi Fahad,Alotaiby Turky Nayef,Al-Hameed Majed Hamad,Alshebeili Saleh,Laleg-Kirati Taous-Meriem","Chahid A,Albalawi F,Alotaiby TN,Al-Hameed MH,Alshebeili S,Laleg-Kirati TM",Laleg-Kirati TM,10.1109/JBHI.2020.2972286,King Abdullah University of Science & Technology,"Epilepsy is a neurological disorder ranked as the second most serious neurological disease known to humanity, after stroke. Inter-ictal spiking is an abnormal neuronal discharge after an epileptic seizure. This abnormal activity can originate from one or more cranial lobes, often travels from one lobe to another, and interferes with normal activity from the affected lobe. The common practice for Inter-ictal spike detection of brain signals is via visual scanning of the recordings, which is a subjective and a very time-consuming task. Motivated by that, this article focuses on using machine learning for epileptic spikes classification in magnetoencephalography (MEG) signals. First, we used the Position Weight Matrix (PWM) method combined with a uniform quantizer to generate useful features from time domain and frequency domain through a Fast Fourier Transform (FFT) of the framed raw MEG signals. Second, the extracted features are fed to standard classifiers for inter-ictel spikes classification. The proposed technique shows great potential in spike classification and reducing the feature vector size. Specifically, the proposed technique achieved average sensitivity up to 87% and specificity up to 97% using 5-folds cross-validation applied to a balanced dataset. These samples are extracted from nine epileptic subjects using a sliding frame of size 95 samples-points with a step-size of 8 sample-points.","Magnetometers,Feature extraction,Pulse width modulation,Magnetic noise,Magnetic shielding,Quantization (signal),Magnetoencephalography (MEG),position weight matrix (PWM),epileptic spike detection,machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"MAGNETOENCEPHALOGRAPHY,LOCALIZATION,PATTERNS,SIGNALS,DNA",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://repository.kaust.edu.sa/bitstream/10754/661489/1/2020_QuPWM_Epilepsy_spikes_Detection.pdf,
75,An Automatic R and T Peak Detection Method Based on the Combination of Hierarchical Clustering and Discrete Wavelet Transform,24,10,2825-2832,"Chen Hanjie,Maharatna Koushik","Chen HJ,Maharatna K",Chen HJ,10.1109/JBHI.2020.2973982,University of Southampton,"The detection and delineation of QRS-complexes and T-waves in Electrocardiogram (ECG) is an important task because these features are associated with the cardiac abnormalities including ventricular arrhythmias that may lead to sudden cardiac death. In this paper, we propose a novel method for the R-peak and the T-peak detection using hierarchical clustering and Discrete Wavelet Transform (DWT) from the ECG signal. In the first step, a template of the single ECG beat is identified. Secondly, all R-peaks are detected by using hierarchical clustering. Then, each corresponding T-wave boundary is delineated based on the template morphology. Finally, the determination of T wave peaks is achieved based on the Modulus-Maxima Analysis (MMA) of the DWT coefficients. We evaluated the algorithm by using all records from the MIT-BIH arrhythmia database and QT database. The R-peak detector achieved a sensitivity of 99.89%, a positive predictivity of 99.97% and 99.83% accuracy over the validation MIT-BIH database. In addition, it shows a sensitivity of 100%, a positive predictivity of 99.83% in manually annotated QT database. It also shows 99.92% sensitivity and 99.96% positive predictivity over the automatic annotated QT database. In terms of the T-peak detection, our algorithm is verified with 99.91% sensitivity and 99.38% positive predictivity in manually annotated QT database.","Electrocardiography,Discrete wavelet transforms,Clustering algorithms,Couplings,Databases,Feature extraction,ECG,R and T peak detection,Hierarchical clustering,Discrete wavelet transform (DWT)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"ECG,ALGORITHM,QRS,DELINEATION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://eprints.soton.ac.uk/438399/1/08999502.pdf,
76,A Residual Based Attention Model for EEG Based Sleep Staging,24,10,2833-2843,"Qu Wei,Wang Zhiyong,Hong Hong,Chi Zheru,Feng David Dagan,Grunstein Ron,Gordon Christopher","Qu W,Wang ZY,Hong H,Chi ZR,Feng DD,Grunstein R,Gordon C",Qu W,10.1109/JBHI.2020.2978004,University of Sydney,"Sleep staging is to score the sleep state of a subject into different sleep stages such as Wake and Rapid Eye Movement (REM). It plays an indispensable role in the diagnosis and treatment of sleep disorders. As manual sleep staging through well-trained sleep experts is time consuming, tedious, and subjective, many automatic methods have been developed for accurate, efficient, and objective sleep staging. Recently, deep learning based methods have been successfully proposed for electroencephalogram (EEG) based sleep staging with promising results. However, most of these methods directly take EEG raw signals as input of convolutional neural networks (CNNs) without considering the domain knowledge of EEG staging. Apart from that, to capture temporal information, most of the existing methods utilize recurrent neural networks such as LSTM (Long Short Term Memory) which are not effective for modelling global temporal context and difficult to train. Therefore, inspired by the clinical guidelines of sleep staging such as AASM (American Academy of Sleep Medicine) rules where different stages are generally characterized by EEG waveforms of various frequencies, we propose a multi-scale deep architecture by decomposing an EEG signal into different frequency bands as input to CNNs. To model global temporal context, we utilize the multi-head self-attention module of the transformer model to not only improve performance, but also shorten the training time. In addition, we choose residual based architecture which makes training end-to-end. Experimental results on two widely used sleep staging datasets, Montreal Archive of Sleep Studies (MASS) and sleep-EDF datasets, demonstrate the effectiveness and significant efficiency (up to 12 times less training time) of our proposed method over the state-of-the-art.","Sleep,Electroencephalography,Feature extraction,Brain modeling,Machine learning,Training,Context modeling,Sleep staging,deep learning,EEG signal,Hilbert transform,attention model",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"NEURAL-NETWORK,CLASSIFICATION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
77,Epileptic Seizure Classification With Symmetric and Hybrid Bilinear Models,24,10,2844-2851,"Liu Tennison,Truong Nhan Duy,Nikpour Armin,Zhou Luping,Kavehei Omid","Liu T,Truong ND,Nikpour A,Zhou LP,Kavehei O",Kavehei O,10.1109/JBHI.2020.2984128,University of Sydney,"Epilepsy affects nearly 1% of the global population, of which two thirds can be treated by anti-epileptic drugs and a much lower percentage by surgery. Diagnostic procedures for epilepsy and monitoring are highly specialized and labour-intensive. The accuracy of the diagnosis is also complicated by overlapping medical symptoms, varying levels of experience and inter-observer variability among clinical professions. This paper proposes a novel hybrid bilinear deep learning network with an application in the clinical procedures of epilepsy classification diagnosis, where the use of surface electroencephalogram (sEEG) and audiovisual monitoring is standard practice. Hybrid bilinear models based on two types of feature extractors, namely Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), are trained using Short-Time Fourier Transform (STFT) of one-second sEEG. In the proposed hybrid models, CNNs extract spatio-temporal patterns, while RNNs focus on the characteristics of temporal dynamics in relatively longer intervals given the same input data. Second-order features, based on interactions between these spatio-temporal features are further explored by bilinear pooling and used for epilepsy classification. Our proposed methods obtain an F1-score of 97.4% on the Temple University Hospital Seizure Corpus and 97.2% on the EPILEPSIAE dataset, comparing favourably to existing benchmarks for sEEG-based seizure type classification. The open-source implementation of this study is available at https://github.com/NeuroSyd/Epileptic-Seizure-Classification.","Epilepsy,epileptic seizure classification,EEG,bilinear models,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"CONVOLUTIONAL,NEURAL-NETWORKS,INTERNATIONAL-LEAGUE,DIAGNOSIS,ILAE",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://arxiv.org/pdf/2001.06282,
78,GP-CNN-DTEL: Global-Part CNN Model With Data-Transformed Ensemble Learning for Skin Lesion Classification,24,10,2870-2882,"Tang Peng,Liang Qiaokang,Yan Xintong,Xiang Shao,Zhang Dan","Tang P,Liang QK,Yan XT,Xiang S,Zhang D",Liang QK,10.1109/JBHI.2020.2977013,Hunan University,"Precise skin lesion classification is still challenging due to two problems, i.e., (1) inter-class similarity and intra-class variation of skin lesion images, and (2) the weak generalization ability of single Deep Convolutional Neural Network trained with limited data. Therefore, we propose a Global-Part Convolutional Neural Network (GP-CNN) model, which treats the fine-grained local information and global context information with equal importance. The Global-Part model consists of a Global Convolutional Neural Network (G-CNN) and a Part Convolutional Neural Network (P-CNN). Specifically, the G-CNN is trained with downscaled dermoscopy images, and is used to extract the global-scale information of dermoscopy images and produce the Classification Activation Map (CAM). While the P-CNN is trained with the CAM guided cropped image patches and is used to capture local-scale information of skin lesion regions. Additionally, we present a data-transformed ensemble learning strategy, which can further boost the classification performance by integrating the different discriminant information from GP-CNNs that are trained with original images, color constancy transformed images, and feature saliency transformed images, respectively. The proposed method is evaluated on the ISIC 2016 and ISIC 2017 Skin Lesion Challenge (SLC) classification datasets. Experimental results indicate that the proposed method can achieve the state-of-the-art skin lesion classification performance (i.e., an AP value of 0.718 on the ISIC 2016 SLC dataset and an Average Auc value of 0.926 on the ISIC 2017 SLC dataset) without any external data, compared with other current methods which need to use external data.","Skin,Lesions,Melanoma,Convolutional neural networks,Training,Data mining,Image color analysis,Skin lesion classification,global-part model,color constancy guided ensemble learning,dermoscopy images",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"CANCER,STATISTICS,DEEP",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
79,"MRLN: Multi-Task Relational Learning Network for MRI Vertebral Localization, Identification, and Segmentation",24,10,2902-2911,"Zhang Ranran,Xiao Xiaoyan,Liu Zhi,Li Yujun,Li Shuo","Zhang RN,Xiao XY,Liu Z,Li YJ,Li S",Liu Z; Li YJ,10.1109/JBHI.2020.2969084,Shandong University,"Magnetic resonance imaging (MRI) vertebral localization, identification, and segmentation are important steps in the automatic analysis of spines. Due to the similar appearances of vertebrae, the accurate segmentation, localization, and identification of vertebrae remain challenging. Previous methods solved the three tasks independently, ignoring the intrinsic correlation among them. In this paper, we propose a multi-task relational learning network (MRLN) that utilizes both the relationships between vertebrae and the relevance of the three tasks. A dilation convolution group is used to expand the receptive field, and LSTM(Long Short-Term Memory) to learn the prior knowledge of the order relationship between the vertebral bodies. We introduce a co-attention module to learn the correlation information, localization-guided segmentation attention(LGSA) and segmentation-guided localization attention(SGLA), in the decoder stage of segmentation and localization tasks. Learning two tasks simultaneously as well as the correlation between tasks can not only avoid the overfitting of a single task but also correct each other. To avoids the cumbersome weight adjustment for different tasks loss functions, we formulated a novel XOR loss that provides a direct evaluation criterion for the localization relationship of the semantic location regression and semantic segmentation. This method was evaluated on a dataset which includes multiple MRI modalities (T1 and T2), various fields of view. Experimental results demonstrate that both of the co-attention and XOR loss work outperforms the most recent state of art.","Task analysis,Image segmentation,Magnetic resonance imaging,Semantics,Convolution,Informatics,Biomedical imaging,Localization,identification,segmentation,co-attention,XOR loss",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,SPINE,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
80,An End-to-End Multi-Task Deep Learning Framework for Skin Lesion Analysis,24,10,2912-2921,"Song Lei,Lin Jianzhe,Wang Z. Jane,Wang Haoqian","Song L,Lin JZ,Wang ZJ,Wang HQ",Wang HQ,10.1109/JBHI.2020.2973614,"Tsinghua Shenzhen Int Grad Sch, Shenzhen 518055, Peoples R China.","Automatic skin lesion analysis of dermoscopy images remains a challenging topic. In this paper, we propose an end-to-end multi-task deep learning framework for automatic skin lesion analysis. The proposed framework can perform skin lesion detection, classification, and segmentation tasks simultaneously. To address the class imbalance issue in the dataset (as often observed in medical image datasets) and meanwhile to improve the segmentation performance, a loss function based on the focal loss and the jaccard distance is proposed. During the framework training, we employ a three-phase joint training strategy to ensure the efficiency of feature learning. The proposed framework outperforms state-of-the-art methods on the benchmarks ISBI 2016 challenge dataset towards melanoma classification and ISIC 2017 challenge dataset towards melanoma segmentation, especially for the segmentation task. The proposed framework should be a promising computer-aided tool for melanoma diagnosis.","Lesions,Skin,Melanoma,Machine learning,Feature extraction,Image segmentation,Training,Skin lesion analysis,end-to-end multi-task framework,deep learning,melanoma segmentation,convolution neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,CLASSIFICATION,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
81,A Deep Neural Network Application for Improved Prediction of HbA(1c) in Type 1 Diabetes,24,10,2932-2941,"Zaitcev Aleksandr,Eissa Mohammad R.,Hui Zheng,Good Tim,Elliott Jackie,Benaissa Mohammed","Zaitcev A,Eissa MR,Hui Z,Good T,Elliott J,Benaissa M",Zaitcev A,10.1109/JBHI.2020.2967546,University of Sheffield,"HbA(1c) is a primary marker of long-term average blood glucose, which is an essential measure of successful control in type 1 diabetes. Previous studies have shown that HbA(1c) estimates can be obtained from 5-12 weeks of daily blood glucose measurements. However, these methods suffer from accuracy limitations when applied to incomplete data with missing periods of measurements. The aim of this article is to overcome these limitations improving the accuracy and robustness of HbA(1c) prediction from time series of blood glucose. A novel data-driven HbA1c prediction model based on deep learning and convolutional neural networks is presented. The model focuses on the extraction of behavioral patterns from sequences of self-monitored blood glucose readings on various temporal scales. Assuming that subjects who share behavioral patterns have also similar capabilities for diabetes control and resulting HbA(1c), it becomes possible to infer the HbA1c of subjects with incomplete data from multiple observations of similar behaviors. Trained and validated on a dataset, containing 1543 real world observation epochs from 759 subjects, the model has achieved the mean absolute error of 4.80 +/- 0.62 mmol/mol, median absolute error of 3.81 +/- 0.58 mmol/mol and R-2 of 0.71 +/- 0.09 on average during the 10 fold cross validation. Automatic behavioral characterization via extraction of sequential features by the proposed convolutional neural network structure has significantly improved the accuracy of HbA1c prediction compared to the existing methods.","Convolutional neural networks,diabetes,feature extraction,machine learning,regression analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"GLYCEMIC,CONTROL,GLUCOSE,HEMOGLOBIN,COMPLICATIONS,NEPHROPATHY,RETINOPATHY",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://eprints.whiterose.ac.uk/155948/1/MAIN_R2_accepted.pdf,
82,Multimodal Data Analysis of Alzheimer's Disease Based on Clustering Evolutionary Random Forest,24,10,2973-2983,"Bi Xia-an,Hu Xi,Wu Hao,Wang Yang","Bi XA,Hu X,Wu H,Wang Y",Bi XA,10.1109/JBHI.2020.2973324,Hunan Normal University,"Alzheimer's disease (AD) has become a severe medical challenge. Advances in technologies produced high-dimensional data of different modalities including functional magnetic resonance imaging (fMRI) and single nucleotide polymorphism (SNP). Understanding the complex association patterns among these heterogeneous and complementary data is of benefit to the diagnosis and prevention of AD. In this paper, we apply the appropriate correlation analysis method to detect the relationships between brain regions and genes, and propose ""brain region-gene pairs"" as the multimodal features of the sample. In addition, we put forward a novel data analysis method from technology aspect, cluster evolutionary random forest (CERF), which is suitable for ""brain region-gene pairs"". The idea of clustering evolution is introduced to improve the generalization performance of random forest which is constructed by randomly selecting samples and sample features. Through hierarchical clustering of decision trees in random forest, the decision trees with higher similarity are clustered into one class, and the decision trees with the best performance are retained to enhance the diversity between decision trees. Furthermore, based on CERF, we integrate feature construction, feature selection and sample classification to find the optimal combination of different methods, and design a comprehensive diagnostic framework for AD. The framework is validated by the samples with both fMRI and SNP data from ADNI. The results show that we can effectively identify AD patients and discover some brain regions and genes associated with AD significantly based on this framework. These findings are conducive to the clinical treatment and prevention of AD.","Feature extraction,Decision trees,Functional magnetic resonance imaging,Correlation,Random forests,Diseases,Data analysis,Alzheimer's disease,clustering evolutionary random forest,fMRI,multimodal data fusion,SNP",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"COGNITIVE,DECLINE,FEATURE-SELECTION,BRAIN,CLASSIFICATION,MEMORY,VARIANTS,CORTEX,IMAGE,STATE",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
83,Structure Dictionary Learning-Based Multimode Process Monitoring and its Application to Aluminum Electrolysis Process,17,4,1989-2003,"Huang Keke,Wu Yiming,Yang Chunhua,Peng Gongzhuang,Shen Weiming","Huang KK,Wu YM,Yang CH,Peng GZ,Shen WM",Peng GZ,10.1109/TASE.2020.2984334,University of Science & Technology Beijing,"Most industrial systems frequently switch their operation modes due to various factors, such as the changing of raw materials, static parameter setpoints, and market demands. To guarantee stable and reliable operation of complex industrial processes under different operation modes, the monitoring strategy has to adapt different operation modes. In addition, different operation modes usually have some common patterns. To address these needs, this article proposes a structure dictionary learning-based method for multimode process monitoring. In order to validate the proposed approach, extensive experiments were conducted on a numerical simulation case, a continuous stirred tank heater (CSTH) process, and an industrial aluminum electrolysis process, in comparison with several state-of-the-art methods. The results show that the proposed method performs better than other conventional methods. Compared with conventional methods, the proposed approach overcomes the assumption that each operation mode of industrial processes should be modeled separately. Therefore, it can effectively detect faulty states. It is worth to mention that the proposed method can not only detect the faulty of the data but also classify the modes of normal data to obtain the operation conditions so as to adopt an appropriate control strategy. Note to Practitioners-Motivated by the fact that the industrial process often has different modes and they may have common patterns, this article proposes a structure dictionary learning method for multimode process monitoring. First, the structure dictionary learning method was proposed to extract the common pattern and mode-specific pattern of each mode. After two different patterns are extracted, the control limit for process monitoring can be obtained from the training data. When new data arrive, the monitoring process can be carried out. Intensive experimental results show that the proposed method performs better than other conventional methods. Compared to conventional methods, the proposed approach overcomes the assumption that each operation mode of the industrial process should be modeled separately. Therefore, it can effectively detect faulty states. Above all, it is suitable for monitoring of real industrial systems.","Monitoring,Machine learning,Dictionaries,Feature extraction,Hidden Markov models,Data models,Task analysis,Multimode process,pattern recognition,process monitoring,structure dictionary learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Automation & Control Systems,,5.516,"FAULT-DIAGNOSIS,K-SVD,SPARSE,PCA",IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING,,
84,Prior Knowledge-Based Optimization Method for the Reconstruction Model of Multicamera Optical Tracking System,17,4,2074-2084,"Dai Houde,Zeng Yadan,Wang Zengwei,Lin Haijun,Lin Mingqiang);,Gao Hui,Song Shuang,Meng Max Q. -H.","Dai HD,Zeng YD,Wang ZW,Lin HJ,Lin MQ,Gao H,Song S,Meng MQH",Zeng YD,10.1109/TASE.2020.2989194,Chinese Academy of Sciences,"The optical tracking system (OTS) plays a vital role in the computer-assisted surgical navigation process, whereas the performance of the commonly used binocular stereo vision is affected by the line-of-sight problem and limited workspace. Thus, this article proposed a prior knowledge-based multicamera reconstruction model (PKRM) to both expand the tracking workspace and improve the tracking robust and computational efficiency of OTS when working in unstructured clinical conditions. This reconstruction model inherits the advantages of the geometrical method, data-driven method, and gating technique (GT). First, we added the geometric principle as the prior knowledge to optimize the training of the multicamera OTS reconstruction model through the Lagrange multiplier method; hence, the prior knowledge feedforward NN (PKFNN) was built. Second, besides the training features, the state of camera (SOC) was extracted in advance to determine the NN structure using GT. According to the SOC feature, the OTS can be self-adaptive to the changing field of view (FOV) caused by optical occlusion, which is frequently occurred in surgery. Furthermore, experiments were carried out to verify the performance of the proposed model, whose accuracy and runtime performed 0.4627 mm and 0.0016 ms, respectively. Results demonstrate that the proposed reconstruction model can achieve higher accuracy and computational efficiency than both the geometrical model and the data-driven model. Especially, by considering SOC as the state prior knowledge, the tracking robustness is enhanced when one or two of the four cameras are not working properly. Note to Practitioners-The original motivation for this article derives from both the line-of-sight limitation and robust demand for optical tracking of surgical instruments. The performance of the multicamera optical tracking system (OTS) depends on its reconstruction model. However, the geometric reconstruction model requires more calculation to obtain high accuracy, which will enlarge the latency and reduce the update rate. In our previous work, the reconstruction model based on the neural network (NN) has achieved accurate tracking in real-time, while the training of the model tends into local optimal values. Hence, we proposed the prior knowledge feedforward NN model to improve the accuracy and computational efficiency. Moreover, to guarantee the line-of-sight in the optical occlusion, the state of camera combining with the gating technique enables the OTS to be self-adaptive for changing the field of view, which greatly ensures the robust tracking process with larger workspace in case of line-of-sight obstructions.","Image reconstruction,Robustness,Artificial neural networks,Computational modeling,Cameras,Feature extraction,Training,Gating technique (GT),Lagrange multiplier method (LMM),optical tracking system (OTS),prior knowledge,prior knowledge feedforward neural network (PKFNN)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Automation & Control Systems,,5.516,"SURGICAL,INSTRUMENT,TRACKING,IMAGE",IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING,,
85,Long-Term Bowel Sound Monitoring and Segmentation by Wearable Devices and Convolutional Neural Networks,14,5,985-996,"Zhao Kang,Jiang Hanjun,Wang Zhihua,Chen Ping,Zhu Binjie,Duan Xianglong","Zhao K,Jiang HJ,Wang ZH,Chen P,Zhu BJ,Duan XL",Jiang HJ,10.1109/TBCAS.2020.3018711,Tsinghua University,"Bowel sounds (BSs), typically generated by the intestinal peristalses, are a significant physiological indicator of the digestive system's health condition. In this study, a wearable BS monitoring system is presented for long-term BS monitoring. The system features a wearable BS sensor that can record BSs for days long and transmit them wirelessly in real-time. With the system, a total of 20 subjects' BS data under the hospital environment were collected. Each subject is recorded for 24 hours. Through manual screening and annotation, from every subject's BS data, 400 segments were extracted, in which half are BS event-contained segments. Thus, a BS dataset that contains 20 x 400 sound segments is formed. Afterwards, CNNs are introduced for BS segment recognition. Specifically, this study proposes a novel CNN design method that makes it possible to transfer the popular CNN modules in image recognition into the BS segmentation domain. Experimental results show that in holdout evaluation with corrected labels, the designed CNN model achieves a moderate accuracy of 91.8% and the highest sensitivity of 97.0% compared with the similar works. In cross validation with noisy labels, the designed CNN delivers the best generability. By using a CNN visualizing technique-class activation maps, it is found that the designed CNN has learned the effective features of BS events. Finally, the proposed CNN design method is scalable to different sizes of datasets.","Monitoring,Biomedical monitoring,Real-time systems,Image segmentation,Logic gates,Hospitals,Noise measurement,Bowel sounds,building blocks,class activation maps,CNNs,long-term BS monitoring,wearable devices",Article; Proceedings Paper,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,,IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,,
86,From Seizure Detection to Smart and Fully Embedded Seizure Prediction Engine: A Review,14,5,1008-1023,"Yang Jie,Sawan Mohamad","Yang J,Sawan M",Yang J,10.1109/TBCAS.2020.3018465,Westlake University,"Recent review papers have investigated seizure prediction, creating the possibility of preempting epileptic seizures. Correct seizure prediction can significantly improve the standard of living for the majority of epileptic patients, as the unpredictability of seizures is a major concern for them. Today, the development of algorithms, particularly in the field of machine learning, enables reliable and accurate seizure prediction using desktop computers. However, despite extensive research effort being devoted to developing seizure detection integrated circuits (ICs), dedicated seizure prediction ICs have not been developed yet. We believe that interdisciplinary study of system architecture, analog and digital ICs, and machine learning algorithms can promote the translation of scientific theory to a more realistic intelligent, integrated, and low-power system that can truly improve the standard of living for epileptic patients. This review explores topics ranging from signal acquisition analog circuits to classification algorithms and dedicated digital signal processing circuits for detection and prediction purposes, to provide a comprehensive and useful guideline for the construction, implementation and optimization of wearable and integrated smart seizure prediction systems.","Signal processing algorithms,Electroencephalography,Integrated circuits,Electrodes,Prediction algorithms,Epilepsy,Surgery,Analog-to-digital converter,electrodes,hardware system,processor,seizure prediction,signal processing,wearable devices",Review,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,4.12,"EEG,ACQUISITION,SOC,MU-W,LONG-TERM,LOW-POWER,EPILEPSY,SYSTEM,CLASSIFICATION,STIMULATION,PROCESSOR,CHIP",IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS,,
87,Subject-Independent Brain-Computer Interfaces Based on Deep Convolutional Neural Networks,31,10,3839-3852,"Kwon O-Yeon,Lee Min-Ho,Guan Cuntai,Lee Seong-Whan","Kwon OY,Lee MH,Guan CT,Lee SW",Lee SW,10.1109/TNNLS.2019.2946869,Korea University,"For a brain-computer interface (BCI) system, a calibration procedure is required for each individual user before he/she can use the BCI. This procedure requires approximately 20-30 min to collect enough data to build a reliable decoder. It is, therefore, an interesting topic to build a calibration-free, or subject-independent, BCI. In this article, we construct a large motor imagery (MI)-based electroencephalography (EEG) database and propose a subject-independent framework based on deep convolutional neural networks (CNNs). The database is composed of 54 subjects performing the left- and right-hand MI on two different days, resulting in 21 600 trials for the MI task. In our framework, we formulated the discriminative feature representation as a combination of the spectral-spatial input embedding the diversity of the EEG signals, as well as a feature representation learned from the CNN through a fusion technique that integrates a variety of discriminative brain signal patterns. To generate spectral-spatial inputs, we first consider the discriminative frequency bands in an information-theoretic observation model that measures the power of the features in two classes. From discriminative frequency bands, spectral-spatial inputs that include the unique characteristics of brain signal patterns are generated and then transformed into a covariance matrix as the input to the CNN. In the process of feature representations, spectral-spatial inputs are individually trained through the CNN and then combined by a concatenation fusion technique. In this article, we demonstrate that the classification accuracy of our subject-independent (or calibration-free) model outperforms that of subject-dependent models using various methods [common spatial pattern (CSP), common spatiospectral pattern (CSSP), filter bank CSP (FBCSP), and Bayesian spatio-spectral filter optimization (BSSFO)].","Electroencephalography,Databases,Feature extraction,Electrodes,Brain modeling,Task analysis,Calibration,Brain-computer interface (BCI),convolutional neural networks (CNNs),deep learning (DL),electroencephalography (EEG),motor imagery (MI),subject-independent",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.746,"SINGLE-TRIAL,EEG,MOTOR,IMAGERY,CLASSIFICATION,PERFORMANCE,PATTERNS,BCI",IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,https://ieeexplore.ieee.org/ielx7/5962385/9212662/08897723.pdf,
88,Region Based Parallel Hierarchy Convolutional Neural Network for Automatic Facial Nerve Paralysis Evaluation,28,10,2325-2332,"Liu Xin,Xia Yifan,Yu Hui,Dong Junyu,Jian Muwei,Pham Tuan D.","Liu X,Xia YF,Yu H,Dong JY,Jian MW,Pham TD",Yu H,10.1109/TNSRE.2020.3021410,University of Portsmouth,"In this article, we propose a parallel hierarchy convolutional neural network (PHCNN) combining a Long Short-Term Memory (LSTM) network structure to quantitatively assess the grading of facial nerve paralysis (FNP) by considering the region-based asymmetric facial features and temporal variation of the image sequences. FNP, such as Bell's palsy, is the most common facial symptom of neuromotor dysfunctions. It causes the weakness of facial muscles for the normal emotional expression and movements. The subjective judgement by clinicians completely depends on individual experience, which may not lead to a uniform evaluation. Existing computer-aided methods mainly rely on some complicated imaging equipment, which is complicated and expensive for facial functional rehabilitation. Compared with the subjective judgment and complex imaging processing, the objective and intelligent measurement can potentially avoid this issue. Considering dynamic variation in both global and regional facial areas, the proposed hierarchical network with LSTM structure can effectively improve the diagnostic accuracy and extract paralysis detail from the low-level shape, contour to sematic level features. By segmenting the facial area into two palsy regions, the proposed method can discriminate FNP from normal face accurately and significantly reduce the effect caused by age wrinkles and unrepresentative organs with shape and position variations on feature learning. Experiment on the YouTube Facial Palsy Database and Extended CohnKanade Database shows that the proposed method is superior to the state of the art deep learning methods.","Feature extraction,Image sequences,Face recognition,Shape,Databases,Facial muscles,Facial nerve paralysis,severity grade,region of interest,spatio-temporal features,LSTM",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,,IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
89,Differentiating Operator Skill during Routine Fetal Ultrasound Scanning using Probe Motion Tracking.,12437,,180-188,",,,,,,","Wang Yipei,Droste Richard,Jiao Jianbo,Sharma Harshita,Drukker Lior,Papageorghiou Aris T,Noble J Alison",,10.1007/978-3-030-60334-2_18,,"In this paper, we consider differentiating operator skill during fetal ultrasound scanning using probe motion tracking. We present a novel convolutional neural network-based deep learning framework to model ultrasound probe motion in order to classify operator skill levels, that is invariant to operators' personal scanning styles. In this study, probe motion data during routine second-trimester fetal ultrasound scanning was acquired by operators of known experience levels (2 newly-qualified operators and 10 expert operators). The results demonstrate that the proposed model can successfully learn underlying probe motion features that distinguish operator skill levels during routine fetal ultrasound with 95% accuracy.",Fetal ultrasound; Operator skill; Probe motion,Journal Article,,,,,,,,
90,A learning approach with incomplete pixel-level labels for deep neural networks,130,,111-125,"Nguyen Nhu-Van,Rigaud Christophe,Revel Arnaud,Burie Jean-Christophe","Nguyen NV,Rigaud C,Revel A,Burie JC",Nguyen NV,10.1016/j.neunet.2020.06.025,Universite Confederale Leonard de Vinci,"Learning with incomplete labels in Neural Networks has been actively investigated these last years. Among different kinds of incomplete labels, we investigate incomplete pixel-level labels which are tackled in many concrete problems. One of the challenges for incomplete pixel-level labels is the missing information at local-level. Most of the current researches with incomplete labels in Neural Network focus on the incompleteness of global labels, only a few works focus on the incompleteness of local labels. To deal with the local incompleteness, we propose a learning approach which uses two dynamic weighted maps in parallel: one for object pixels and another one for background pixels. The two maps are integrated into the loss function of the target Neural Networks, to optimize the model by the present labels and to minimize the damage of the missing labels. We validate our approach on the speech balloon extraction problem in comic book images. Our approach uses the output of a balloon extraction algorithm as incomplete labels. The results are comparable with the state of the art supervised approach with manual labels. The results are very promising because our method does not require any manual labels. In addition, we apply our method to the medical image segmentation task to confirm the generalization of our approach. (C) 2020 Elsevier Ltd. All rights reserved.","Incomplete labels,Loss function,Image segmentation,Comic speech balloon extraction,Nuclei segmentation",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,,"EXTRACTION,BALLOON",NEURAL NETWORKS,,
91,Targeted sequence design within the coarse-grained polymer genome,6,43,,"Webb Michael A.,Jackson Nicholas E.,Gil Phwey S.,de Pablo Juan J.","Webb MA,Jackson NE,Gil PS,de Pablo JJ",de Pablo JJ,10.1126/sciadv.abc6216,University of Chicago,"The chemical design of polymers with target structural and/or functional properties represents a grand challenge in materials science. While data-driven design approaches are promising, success with polymers has been limited, largely due to limitations in data availability. Here, we demonstrate the targeted sequence design of single-chain structure in polymers by combining coarse-grained modeling, machine learning, and model optimization. Nearly 2000 unique coarse-grained polymers are simulated to construct and analyze machine learning models. We find that deep neural networks inexpensively and reliably predict structural properties with limited sequence information as input. By coupling trained ML models with sequential model-based optimization, polymer sequences are proposed to exhibit globular, swollen, or rod-like behaviors, which are verified by explicit simulations. This work highlights the promising integration of coarse-grained modeling with data-driven design and represents a necessary and crucial step toward more complex polymer design efforts.","OPPORTUNITIES,PREDICTION",Article,"AMER ASSOC ADVANCEMENT SCIENCE, 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA",Science & Technology - Other Topics,,16.45,"OPPORTUNITIES,PREDICTION",SCIENCE ADVANCES,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7577717,
92,Materials Acceleration Platforms: On the way to autonomous experimentation,25,,,"Flores-Leonar Martha M.,Mejia-Mendoza Luis M.,Aguilar-Granda Andres,Sanchez-Lengeling Benjamin,Tribukait Hermann,Amador-Bedolla Carlos,Aspuru-Guzik Alan","Flores-Leonar MM,Mejia-Mendoza LM,Aguilar-Granda A,Sanchez-Lengeling B,Tribukait H,Amador-Bedolla C,Aspuru-Guzik A",Aspuru-Guzik A,10.1016/j.cogsc.2020.100370,University of Toronto,"Materials Acceleration Platforms are an emerging paradigm to accelerate materials discovery as an effort to develop technology solutions that can help address or mitigate climate change concerns. These platforms combine artificial intelligence, robotic systems, and high-performance computing to achieve autonomous experimentation. Nevertheless, their development faces challenges to achieve full autonomy. In this work, we present state-of-the-art robotic platforms and machine learning approaches for autonomous experimentation, their integration, and applications, particularly in the field of materials for clean energy technologies. Later, we discuss the challenges and suggest improvements to be considered in the endeavor to accomplish autonomous experimentation.","OPTIMIZATION,AUTOMATION,REACTIONWARE,TECHNOLOGY,MOLECULES",Review,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Chemistry,Science & Technology - Other Topics",,6.805,"OPTIMIZATION,AUTOMATION,REACTIONWARE,TECHNOLOGY,MOLECULES",CURRENT OPINION IN GREEN AND SUSTAINABLE CHEMISTRY,https://www.sciencedirect.com/science/article/am/pii/S2452223620300596,
93,Data augmentation for enhancing EEG-based emotion recognition with deep generative models,17,5,,"Luo Yun,Zhu Li-Zhen,Wan Zi-Yu,Lu Bao-Liang","Luo Y,Zhu LZ,Wan ZY,Lu BL",Lu BL,10.1088/1741-2552/abb580,Shanghai Jiao Tong University,"Objective.The data scarcity problem in emotion recognition from electroencephalography (EEG) leads to difficulty in building an affective model with high accuracy using machine learning algorithms or deep neural networks. Inspired by emerging deep generative models, we propose three methods for augmenting EEG training data to enhance the performance of emotion recognition models.Approach.Our proposed methods are based on two deep generative models, variational autoencoder (VAE) and generative adversarial network (GAN), and two data augmentation ways, full and partial usage strategies. For the full usage strategy, all of the generated data are augmented to the training dataset without judging the quality of the generated data, while for the partial usage, only high-quality data are selected and appended to the training dataset. These three methods are called conditional Wasserstein GAN (cWGAN), selective VAE (sVAE), and selective WGAN (sWGAN).Main results.To evaluate the effectiveness of these proposed methods, we perform a systematic experimental study on two public EEG datasets for emotion recognition, namely, SEED and DEAP. We first generate realistic-like EEG training data in two forms: power spectral density and differential entropy. Then, we augment the original training datasets with a different number of generated realistic-like EEG data. Finally, we train support vector machines and deep neural networks with shortcut layers to build affective models using the original and augmented training datasets. The experimental results demonstrate that our proposed data augmentation methods based on generative models outperform the existing data augmentation approaches such as conditional VAE, Gaussian noise, and rotational data augmentation. We also observe that the number of generated data should be less than 10 times of the original training dataset to achieve the best performance.Significance.The augmented training datasets produced by our proposed sWGAN method significantly enhance the performance of EEG-based emotion recognition models.","emotion recognition,EEG,GAN,VAE,deep generative model,data augmentation,deep neural network",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,5.484,"DIFFERENTIAL,ENTROPY,FEATURE,ART",JOURNAL OF NEURAL ENGINEERING,http://arxiv.org/pdf/2006.05331,
94,Transfer Learning-Based Automatic Detection of Coronavirus Disease 2019 (COVID-19) from Chest X-ray Images.,10,5,559-568,",,,,","R Mohammadi,M Salehi,H Ghaffari,A A Rohani,R Reiazi",,10.31661/jbpe.v0i0.2008-1153,,"Background: Coronavirus disease 2019 (COVID-19) is an emerging infectious disease and global health crisis. Although real-time reverse transcription polymerase chain reaction (RT-PCR) is known as the most widely laboratory method to detect the COVID-19 from respiratory specimens. It suffers from several main drawbacks such as time-consuming, high false-negative results, and limited availability. Therefore, the automatically detect of COVID-19 will be required.Objective: This study aimed to use an automated deep convolution neural network based pre-trained transfer models for detection of COVID-19 infection in chest X-rays.Results: Our proposed models have been trained and tested on a dataset which previously prepared. The all proposed models provide accuracy greater than 90.0%. The pre-trained MobileNet model provides the highest classification performance of automated COVID-19 classification with 99.1% accuracy in comparison with other three proposed models. The plotted area under curve (AUC) of receiver operating characteristics (ROC) of VGG16, VGG19, MobileNet, and InceptionResNetV2 models are 0.92, 0.91, 0.99, and 0.97, respectively.Conclusion: The all proposed models were able to perform binary classification with the accuracy more than 90.0% for COVID-19 diagnosis. Our data indicated that the MobileNet can be considered as a promising model to detect COVID-19 cases. In the future, by increasing the number of samples of COVID-19 chest X-rays to the training dataset, the accuracy and robustness of our proposed models increase further. Copyright: © Journal of Biomedical Physics and Engineering."," COVID-19;  Convolution Neural Network;  Deep Learning;  ,Machine Learning,;  Transfer Learning;  X-ray Images",Journal Article,,,,,,,,
95,Electronic band structure phase diagram of 3D carbon allotropes from machine learning,108,,,"Wu Wei,Gong Sheng,Sun Qiang","Wu W,Gong S,Sun Q",Sun Q,10.1016/j.diamond.2020.107990,Peking University,"The unique electronic configuration endows carbon with super-flexible bonding ability, displaying metallic, semi-conducting and insulating features with unprecedented applications. Inspired by the pressure-temperature phase diagram that clearly shows the phases (solid/liquid/gas) of a substance in different conditions, for the first time, we have derived the electronic 'phase diagram' using machine learning that can discover complex rules and invisible relationships among mull-variables. Based on SACADA database with 522 three-dimensional carbon allotropes, electronic band gap is studied by using support vector machine, decision tree and multiple-layer perception algorithms. It is identified that density and bond angle are two key factors in determining the electronic phase diagram for distinguishing metallic, semiconducting, and insulating carbon phases, where density relates to bond length and coordination number, while bond angle relates to orbital orientations, both together determine the overlap of wave functions between different orbitals.","Electronic band structure,Machine learning",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Materials Science,Physics",,2.996,"METALLIC,CARBON,PREDICTION,DISCOVERY",DIAMOND AND RELATED MATERIALS,,
96,Small data-driven modeling of forming force in single point incremental forming using neural networks,36,4,1589-1597,"Liu Zhaobing,Li Yanle","Liu ZB,Li YL",Li YL,10.1007/s00366-019-00781-6,Shandong University,"Single point incremental forming (SPIF) has revolutionized sheet shaping for small-batch production, providing an economical and effective alternative to sheet stamping and pressing, which can be cumbersome and expensive. Efficient data-driven prediction of forming forces can significantly benefit process design, development and optimization in SPIF. However, the nature of localized plastic deformation makes SPIF a time-consuming process which means it is difficult to obtain rich experimental data (or samples) in the early period of forming process design. To build an efficient data-driven model for forming force prediction using the back propagation neural networks, this paper proposes a virtual data generation approach based on mega trend diffusion function and particle swarm optimization algorithm to improve the accuracy of SPIF force prediction given small experimental data problems. The proposed modeling methodology is verified using small amount of force data obtained from pyramidal shape forming. It is found that the accuracy of the established prediction model can be improved by adding the generated virtual data to actual experimental small datasets, which provides a good predictive capability in modeling the forming force of SPIF under different process conditions.","Single point incremental forming,Neural networks,Virtual data,Prediction,Forming force",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Computer Science,Engineering",,6.544,"SAMPLE,GENERATION,METHOD,ENERGY,PREDICTION,STRATEGY",ENGINEERING WITH COMPUTERS,,
97,Prior-Guided Image Reconstruction for Accelerated Multi-Contrast MRI via Generative Adversarial Networks,14,6,1072-1087,"Dar Salman U. H.,Yurt Mahmut,Shahdloo Mohammad,Ildiz Muhammed Emrullah,Tinaz Berk,Cukur Tolga","Dar SUH,Yurt M,Shahdloo M,Ildiz ME,Tinaz B,Cukur T",Cukur T,10.1109/JSTSP.2020.3001737,Ihsan Dogramaci Bilkent University,"Multi-contrast MRI acquisitions of an anatomy enrich the magnitude of information available for diagnosis. Yet, excessive scan times associated with additional contrasts may be a limiting factor. Two mainstream frameworks for enhanced scan efficiency are reconstruction of undersampled acquisitions and synthesis of missing acquisitions. Recently, deep learning methods have enabled significant performance improvements in both frameworks. Yet, reconstruction performance decreases towards higher acceleration factors with diminished sampling density at high-spatial-frequencies, whereas synthesis can manifest artefactual sensitivity or insensitivity to image features due to the absence of data samples from the target contrast. In this article, we propose a new approach for synergistic recovery of undersampled multi-contrast acquisitions based on conditional generative adversarial networks. The proposed method mitigates the limitations of pure learning-based reconstruction or synthesis by utilizing three priors: shared high-frequency prior available in the source contrast to preserve high-spatial-frequency details, low-frequency prior available in the undersampled target contrast to prevent feature leakage/loss, and perceptual prior to improve recovery of high-level features. Demonstrations on brain MRI datasets from healthy subjects and patients indicate the superior performance of the proposed method compared to pure reconstruction and synthesis methods. The proposed method can help improve the quality and scan efficiency of multi-contrast MRI exams.","Image reconstruction,Magnetic resonance imaging,Acceleration,Transforms,Generative adversarial networks,Neural networks,Reliability,Generative adversarial network (GAN),synthesis,reconstruction,multi contrast,magnetic resonance imaging (MRI),prior",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,"OPTIMIZATION,REGISTRATION,ROBUST,SENSE",IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,https://ora.ox.ac.uk/objects/uuid:fed6252a-7c74-491d-bbf3-7df1f0c7400d/download_file?safe_filename=09115255.pdf&type_of_work=Journal+article,
98,RARE: Image Reconstruction Using Deep Priors Learned Without Groundtruth,14,6,1088-1099,"Liu Jiaming,Sun Yu,Eldeniz Cihat,Gan Weijie,An Hongyu,Kamilov Ulugbek S.","Liu JM,Sun Y,Eldeniz C,Gan WJ,An HY,Kamilov US",Kamilov US,10.1109/JSTSP.2020.2998402,Washington University (WUSTL),"Regularization by denoising (RED) is an image reconstruction framework that uses an image denoiser as a prior. Recent work has shown the state-of-the-art performance of RED with learned denoisers corresponding to pre-trained convolutional neural nets (CNNs). In this work, we propose to broaden the current denoiser-centric view of RED by considering priors corresponding to networks trained for more general artifact-removal. The key benefit of the proposed family of algorithms, called regularization by artifact-removal (RARE), is that it can leverage priors learned on datasets containing only undersampled measurements. This makes RARE applicable to problems where it is practically impossible to have fully-sampled groundtruth data for training. We validate RARE on both simulated and experimentally collected data by reconstructing a free-breathing whole-body 3D MRIs into ten respiratory phases from heavily undersampled k-space measurements. Our results corroborate the potential of learning regularizers for iterative inversion directly on undersampled and noisy measurements.","Imaging,Image reconstruction,Noise measurement,Training,Noise reduction,Inverse problems,Signal processing algorithms,Imaging inverse problems,regularization by denoising,plug-and-play priors,deep learning,MRI",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,"CONVOLUTIONAL,NEURAL-NETWORKS,INVERSE,PROBLEMS,SPARSE,MRI,ALGORITHM,REGULARIZATION,SCATTERING,RECOVERY",IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,http://arxiv.org/pdf/1912.05854,
99,PET Image Reconstruction Using a Cascading Back-Projection Neural Network,14,6,1100-1111,"Zhang Qiyang,Gao Juan,Ge Yongshuai,Zhang Na,Yang Yongfeng,Liu Xin,Zheng Hairong,Liang Dong,Hu Zhanli","Zhang QY,Gao J,Ge YS,Zhang N,Yang YF,Liu X,Zheng HR,Liang D,Hu ZL",Hu ZL,10.1109/JSTSP.2020.2998607,Chinese Academy of Sciences,"Positron emission tomography (PET) imaging is a noninvasive technique that makes it possible to probe biological metabolic processes in vivo. However, PET image reconstruction is challenging due to the ill-posedness of the inverse problem. Many image reconstruction methods have been proposed over the past few years to improve diagnostic performance. However, most of these methods can compromise the reconstruction of important high-frequency structural details after aggressive denoising. To address this problem, in this work, we propose a novel deep learning method that reconstructs PET images using a cascading back-projection neural network (bpNet). This network consists of a domain translation operation, which acts as prior knowledge, cascaded with a modified encoder-decoder network. The image reconstruction pipeline ranges from the sinogram to the back-projection image and then to the PET image. Quantitative results from simulation data and Derenzo phantom experiments with the small animal PET prototype system developed in our laboratory clearly demonstrate that our proposed method provides favorable reconstructed image quality, especially for low-count PET image reconstruction.","Image reconstruction,Neural networks,Positron emission tomography,Transforms,Convolution,Biomedical imaging,Small animal PET,back-projection,domain transform,neural network,dual-ended readout",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,"TOMOGRAPHY,ALGORITHMS,CT",IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,,
100,Enhanced Deep-Learning-Based Magnetic Resonance Image Reconstruction by Leveraging Prior Subject-Specific Brain Imaging: Proof-of-Concept Using a Cohort of Presumed Normal Subjects,14,6,1126-1136,"Souza Roberto,Beauferris Youssef,Loos Wallace,Lebel Robert Marc,Frayne Richard","Souza R,Beauferris Y,Loos W,Lebel RM,Frayne R",Souza R,10.1109/JSTSP.2020.3001525,University of Calgary,"Deep learning models have shown potential for reconstructing undersampled, multi-channel magnetic resonance (MR) image acquisitions. Recently proposed methods, however, have not leveraged information from prior subject-specific MR imaging sessions. Such data are often readily available through a picture archiving and communication system (PACS). We propose a flexible three-step method to incorporate this prior information into an enhanced deep-learning-based reconstruction process. The method consists of Step 1: an initial reconstruction; Step 2: registration of the previous scan to the initial reconstruction; and Step 3: an enhancement network. Training and testing used longitudinally acquired, three-dimensional, T1-weighted brain images acquired with different acquisition parameters. We tested our networks using data from 2808 images (obtained in 18 subjects) under four different acceleration factors (R = {5, 10, 15, 20}). Our enhanced reconstruction (Steps 1-3) produced higher-quality images: structural similarity and peak signal-to-noise ratio increased, and normalized root mean squared error decreased on average by 16.5%, 7.0% and 21.1%, respectively, compared to the non-enhanced reconstruction (Step 1 only) under the same network capacity as the enhanced reconstruction model. These differences were statistically significant (p < 0.001, Wilcoxon signed-rank test). Further volumetric analysis performed on key brain regions (brain, white matter, gray matter and cortex) indicated that our enhanced images had better volume agreement with the fully sampled reference images compared to the non-enhanced images. Our enhanced images for R = 20 were comparable to the non-enhanced images for R = 10 demonstrating that our proposed method can use prior scan information to further accelerate MR examinations.","Magnetic resonance imaging (MRI),image reconstruction,picture archiving and communication system (PACS),compressed sensing,longitudinal information",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,6.544,"MRI,NETWORK",IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING,,
