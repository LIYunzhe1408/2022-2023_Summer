,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Toward reliable automatic liver and tumor segmentation using convolutional neural network based on 2.5D models,16,1,41-51,"Wardhana Girindra,Naghibi Hamid,Sirmacek Beril,Abayazid Momen","Wardhana G,Naghibi H,Sirmacek B,Abayazid M",Wardhana G,10.1007/s11548-020-02292-y,University of Twente,"Purpose We investigated the parameter configuration in the automatic liver and tumor segmentation using a convolutional neural network based on 2.5D model. The implementation of 2.5D model shows promising results since it allows the network to have a deeper and wider network architecture while still accommodates the 3D information. However, there has been no detailed investigation of the parameter configurations on this type of network model. Methods Some parameters, such as the number of stacked layers, image contrast, and the number of network layers, were studied and implemented on neural networks based on 2.5D model. Networks are trained and tested by utilizing the dataset from liver and tumor segmentation challenge (LiTS). The network performance was further evaluated by comparing the network segmentation with manual segmentation from nine technical physicians and an experienced radiologist. Results Slice arrangement testing shows that multiple stacked layers have better performance than a single-layer network. However, the dice scores start decreasing when the number of stacked layers is more than three layers. Adding higher number of layers would cause overfitting on the training set. In contrast enhancement test, implementing contrast enhancement method did not show a statistically significant different to the network performance. While in the network layer test, adding more layers to the network architecture does not always correspond to the increasing dice score result of the network. Conclusions This paper compares the performance of the network based on 2.5D model using different parameter configurations. The result obtained shows the effect of each parameter and allow the selection of the best configuration in order to improve the network performance in the application of automatic liver and tumor segmentation.","CT image,Convolutional neural network,Deep learning,Image segmentation,Liver tumor",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,,INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7822806,
2,"Tumor type detection in brain MR images of the deep model developed using hypercolumn technique, attention modules, and residual blocks",59,1,57-70,"Togacar Mesut,Ergen Burhan,Comert Zafer","Togacar M,Ergen B,Comert Z",Togacar M,10.1007/s11517-020-02290-x,Firat University,"Brain cancer is a disease caused by the growth of abnormal aggressive cells in the brain outside of normal cells. Symptoms and diagnosis of brain cancer cases are producing more accurate results day by day in parallel with the development of technological opportunities. In this study, a deep learning model called BrainMRNet which is developed for mass detection in open-source brain magnetic resonance images was used. The BrainMRNet model includes three processing steps: attention modules, the hypercolumn technique, and residual blocks. To demonstrate the accuracy of the proposed model, three types of tumor data leading to brain cancer were examined in this study: glioma, meningioma, and pituitary. In addition, a segmentation method was proposed, which additionally determines in which lobe area of the brain the two classes of tumors that cause brain cancer are more concentrated. The classification accuracy rates were performed in the study; it was 98.18% in glioma tumor, 96.73% in meningioma tumor, and 98.18% in pituitary tumor. At the end of the experiment, using the subset of glioma and meningioma tumor images, it was determined which at brain lobe the tumor region was seen, and 100% success was achieved in the analysis of this determination. In this study, a hybrid deep learning model is presented to determine the detection of the brain tumor. In addition, open-source software was proposed, which statistically found in which lobe region of the human brain the brain tumor occurred. The methods applied and tested in the experiments have shown promising results with a high level of accuracy, precision, and specificity. These results demonstrate the availability of the proposed approach in clinical settings to support the medical decision regarding brain tumor detection.","Brain tumor,Attention module,Magnetic resonance image,Hypercolumn technique,Image processing,Medical segmentation",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,FEATURES,MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
3,Active contour regularized semi-supervised learning for COVID-19 CT infection segmentation with limited annotations,65,22,,"Ma Jun,Nie Ziwei,Wang Congcong,Dong Guoqiang,Zhu Qiongjie,He Jian,Gui Luying,Yang Xiaoping","Ma J,Nie ZW,Wang CC,Dong GQ,Zhu QJ,He J,Gui LY,Yang XP",Yang XP,10.1088/1361-6560/abc04e,Nanjing University,"Infection segmentation on chest CT plays an important role in the quantitative analysis of COVID-19. Developing automatic segmentation tools in a short period with limited labelled images has become an urgent need. Pseudo label-based semi-supervised method is a promising way to leverage unlabelled data to improve segmentation performance. Existing methods usually obtain pseudo labels by first training a network with limited labelled images and then inferring unlabelled images. However, these methods may generate obviously inaccurate labels and degrade the subsequent training process. To address these challenges, in this paper, an active contour regularized semi-supervised learning framework was proposed to automatically segment infections with few labelled images. The active contour regularization was realized by the region-scalable fitting (RSF) model which is embedded to the loss function of the network to regularize and refine the pseudo labels of the unlabelled images. We further designed a splitting method to separately optimize the RSF regularization term and the segmentation loss term with iterative convolution-thresholding method and stochastic gradient descent, respectively, which enable fast optimization of each term. Furthermore, we built a statistical atlas to show the infection spatial distribution. Extensive experiments on a small public dataset and a large scale dataset showed that the proposed method outperforms state-of-the-art methods with up to 5% in dice similarity coefficient and normalized surface dice, 10% in relative absolute volume difference and 8 mm in 95% Hausdorff distance. Moreover, we observed that the infections tend to occur at the dorsal subpleural lung and posterior basal segments that are not mentioned in current radiology reports and are meaningful to advance our understanding of COVID-19.","COVID-19 infection segmentation,active contours,statistical atlas,infection spatial distribution",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,ENHANCEMENT,PHYSICS IN MEDICINE AND BIOLOGY,,
4,RegQCNET: Deep quality control for image-to-template brain MRI affine registration,65,22,,"Denis de Senneville Baudouin,Manjon Jose V,Coupe Pierrick","de Senneville BD,Manjon JV,Coupe P",de Senneville BD,10.1088/1361-6560/abb6be,Centre National de la Recherche Scientifique (CNRS),"Affine registration of one or several brain image(s) onto a common reference space is a necessary prerequisite for many image processing tasks, such as brain segmentation or functional analysis. Manual assessment of registration quality is a tedious and time-consuming task, especially in studies comprising a large amount of data. Automated and reliable quality control (QC) becomes mandatory. Moreover, the computation time of the QC must be also compatible with the processing of massive datasets. Therefore, automated deep neural network approaches have emerged as a method of choice to automatically assess registration quality.
In the current study, a compact 3D convolutional neural network, referred to as RegQCNET, is introduced to quantitatively predict the amplitude of an affine registration mismatch between a registered image and a reference template. This quantitative estimation of registration error is expressed using the metric unit system. Therefore, a meaningful task-specific threshold can be manually or automatically defined in order to distinguish between usable and non-usable images.
The robustness of the proposed RegQCNET is first analyzed on lifespan brain images undergoing various simulated spatial transformations and intensity variations between training and testing. Secondly, the potential of RegQCNET to classify images as usable or non-usable is evaluated using both manual and automatic thresholds. During our experiments, automatic thresholds are estimated using several computer-assisted classification models (logistic regression, support vector machine, Naive Bayes and random forest) through cross-validation. To this end we use an expert's visual QC estimated on a lifespan cohort of 3953 brains. Finally, the RegQCNET accuracy is compared to usual image features such as image correlation coefficient and mutual information.
The results show that the proposed deep learning QC is robust, fast and accurate at estimating affine registration error in the processing pipeline.","quality control,image-to-template registration,deep neural network",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"RADIATION-THERAPY,ANTS",PHYSICS IN MEDICINE AND BIOLOGY,http://arxiv.org/pdf/2005.06835,
5,Development and evaluation of a deep learning based artificial intelligence for automatic identification of gold fiducial markers in an MRI-only prostate radiotherapy workflow,65,22,,"Gustafsson Christian Jamtheim,Sward Johan,Adalbjornsson Stefan Ingi,Jakobsson Andreas,Olsson Lars E.","Gustafsson CJ,Sward J,Adalbjornsson SI,Jakobsson A,Olsson LE",Gustafsson CJ,10.1088/1361-6560/abb0f9,Lund University,"Identification of prostate gold fiducial markers in magnetic resonance imaging (MRI) images is challenging when CT images are not available, due to misclassifications from intra-prostatic calcifications. It is also a time consuming task and automated identification methods have been suggested as an improvement for both objectives. Multi-echo gradient echo (MEGRE) images have been utilized for manual fiducial identification with 100% detection accuracy. The aim is therefore to develop an automatic deep learning based method for fiducial identification in MRI images intended for MRI-only prostate radiotherapy. MEGRE images from 326 prostate cancer patients with fiducials were acquired on a 3T MRI, post-processed with N4 bias correction, and the fiducial center of mass (CoM) was identified. A 9 mm radius sphere was created around the CoM as ground truth. A deep learning HighRes3DNet model for semantic segmentation was trained using image augmentation. The model was applied to 39 MRI-only patients and 3D probability maps for fiducial location and segmentation were produced and spatially smoothed. In each of the three largest probability peaks, a 9 mm radius sphere was defined. Detection sensitivity and geometric accuracy was assessed. To raise awareness of potential false findings a 'BeAware' score was developed, calculated from the total number and quality of the probability peaks. All datasets, annotations and source code used were made publicly available. The detection sensitivity for all fiducials were 97.4%. Thirty-six out of thirty-nine patients had all fiducial markers correctly identified. All three failed patients generated a user notification using the BeAware score. The mean absolute difference between the detected fiducial and ground truth CoM was 0.7 +/- 0.9 [0 3.1] mm. A deep learning method for automatic fiducial identification in MRI images was developed and evaluated with state-of-the-art results. The BeAware score has the potential to notify the user regarding patients where the proposed method is uncertain.","gold fiducial marker,MRI only prostate,MRI only radiotherapy,MRI radiation therapy,prostate cancer,deep learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"MAGNETIC-SUSCEPTIBILITY,REGISTRATION,TARGET,UNCERTAINTIES,SIMULATION,MARGINS",PHYSICS IN MEDICINE AND BIOLOGY,https://doi.org/10.1088/1361-6560/abb0f9,
6,Pancreas segmentation based on an adversarial model under two-tier constraints,65,22,,"Li Meiyu,Lian Fenghui,Guo Shuxu","Li MY,Lian FH,Guo SX",Guo SX,10.1088/1361-6560/abb6bf,Jilin University,"Pancreas segmentation is vital for the effective diagnosis and treatment of diabetic or pancreatic diseases. However, the irregular shape and strong variability of the pancreas in medical images pose significant challenges to accurate segmentation. In this paper, we propose a novel segmentation algorithm that imposes two-tier constraints on a conventional network through adversarial learning, namely UDCGAN. Specifically, we incorporate a dual adversarial training scheme in a conventional segmentation network, which further facilitates the probability maps from the segmentor to converge on the ground truth distributions owing to the effectiveness of generative adversarial networks (GANs) in capturing data distributions. This novel segmentation algorithm is equivalent to employing adversarial learning on a segmentation network that has been trained in an adversarial manner. Duplex intervention and guidance further refine the loss functions of the segmentor, thus effectively contributing to the preservation of details for segmentation. The segmentation results on the NIH Pancreas-CT dataset show that our proposed model achieves a competitive performance compared with other state-of-the-art methods.","pancreas segmentation,adversarial training,dual constraints,UDCGAN",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,NETWORKS,PHYSICS IN MEDICINE AND BIOLOGY,,
7,"Short range order and network connectivity in amorphous AsTe3: a first principles, machine learning, and XRD study",22,43,24895-24906,"Delaizir Gaelle,Piarristeguy Andrea,Pradel Annie,Masson Olivier,Bouzid Assil","Delaizir G,Piarristeguy A,Pradel A,Masson O,Bouzid A",Delaizir G; Bouzid A,10.1039/d0cp03383a,Centre National de la Recherche Scientifique (CNRS),"The atomic scale structure of amorphous AsTe3 is investigated through X-ray diffraction, first-principles molecular dynamics (FPMD), and machine learning interatomic potentials (ML-GAP) obtained by exploiting the ab initio data. We obtain good agreement between the measured and modelled diffraction patterns. Our FPMD results show that As and Te obey the 8-N rule with average coordination numbers of 3 and 2, respectively. We find that small fractions of under and over coordinated As and Te atoms are present in the amorphous phase with about 6% (FPMD), and 13% (ML-GAP) of 3-fold Te. As is found at the center of pyramidal structures predominantly linked through Te-n chains rather than rings. Despite the low As concentration in AsTe3, its local environment features a very high chemical disorder that manifests through the occurrence of homopolar bonds including at least 57% of As atoms.","PHASE-CHANGE MATERIALS,AS-TE,COMPOSITIONAL DEPENDENCE,ELECTRICAL-PROPERTIES,ATOMIC-STRUCTURE,RING STATISTICS,CHEMICAL ORDER,ION CONDUCTORS,GLASSES,CRYSTALLIZATION",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Physics",,3.802,"PHASE-CHANGE,MATERIALS,AS-TE,COMPOSITIONAL,DEPENDENCE,ELECTRICAL-PROPERTIES,ATOMIC-STRUCTURE,RING,STATISTICS,CHEMICAL,ORDER,ION,CONDUCTORS,GLASSES,CRYSTALLIZATION",PHYSICAL CHEMISTRY CHEMICAL PHYSICS,https://hal.archives-ouvertes.fr/hal-03001599/document,
8,Driver's black box: a system for driver risk assessment using machine learning and fuzzy logic,25,5,482-500,"Yuksel A. S.,Atmaca S.","Yuksel AS,Atmaca S",Yuksel AS,10.1080/15472450.2020.1852083,Suleyman Demirel University,"Risky driving behaviors can cause accidents, which may result in major material and moral damages. Due to the increase in road accidents, it has become an important issue to identify risky driving behaviors and reward people who drive safely. With the development of technology, it is now possible to model driving behavior through advanced sensors integrated into embedded systems. In this study, we modeled four major risky driving behaviors and created driver profiles using data obtained from accelerometer and gyroscope sensors and applying widely used machine learning algorithms in behavior analysis, including the C4.5 Decision Tree, Random Forest, Artificial Neural Network, Support-Vector Machine, K-Nearest Neighbor, Naive Bayes, and K-Star algorithms. Risky driving behaviors and their risk levels were evaluated in accordance with the expert opinions of traffic officers, and driver risk was modeled using the fuzzy logic method. The applied machine learning algorithms were compared using common validation metrics such as accuracy, f-measure, precision, and recall. In our experiments, the K-Star algorithm was the most successful algorithm, with 100% accuracy. As a result, a highly accurate, low-cost system which acts as the driver's black box was developed. The system can be integrated into vehicles and it can record the driver's behaviors and identify the risky ones. It can also open up new horizons for insurance companies to utilize usage-based policies, in which customers who drive safely are rewarded with lower car insurance premiums, encouraging others to do the same.","driver analytics,driving behavior analysis,fuzzy logic,intelligent systems,machine learning,risk assessment,road safety",Article,"TAYLOR & FRANCIS INC, 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA",Transportation,,4.134,,JOURNAL OF INTELLIGENT TRANSPORTATION SYSTEMS,,
9,Deep learning approach for the segmentation of aneurysmal ascending aorta,11,1,15-24,"Comelli Albert,Dahiya Navdeep,Stefano Alessandro,Benfante Viviana,Gentile Giovanni,Agnese Valentina,Raffa Giuseppe M.,Pilato Michele,Yezzi Anthony,Petrucci Giovanni","Comelli A,Dahiya N,Stefano A,Benfante V,Gentile G,Agnese V,Raffa GM,Pilato M,Yezzi A,Petrucci G",Pasta S,10.1007/s13534-020-00179-0,University of Palermo,"Diagnosis of ascending thoracic aortic aneurysm (ATAA) is based on the measurement of the maximum aortic diameter, but size is not a good predictor of the risk of adverse events. There is growing interest in the development of novel image-derived risk strategies to improve patient risk management towards a highly individualized level. In this study, the feasibility and efficacy of deep learning for the automatic segmentation of ATAAs was investigated using UNet, ENet, and ERFNet techniques. Specifically, CT angiography done on 72 patients with ATAAs and different valve morphology (i.e., tricuspid aortic valve, TAV, and bicuspid aortic valve, BAV) were semi-automatically segmented with Mimics software (Materialize NV, Leuven, Belgium), and then used for training of the tested deep learning models. The segmentation performance in terms of accuracy and time inference were compared using several parameters. All deep learning models reported a dice score higher than 88%, suggesting a good agreement between predicted and manual ATAA segmentation. We found that the ENet and UNet are more accurate than ERFNet, with the ENet much faster than UNet. This study demonstrated that deep learning models can rapidly segment and quantify the 3D geometry of ATAAs with high accuracy, thereby facilitating the expansion into clinical workflow of personalized approach to the management of patients with ATAAs.","Deep learning,Segmentation,Aorta,Aneurysm,Aortic valve",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Engineering,,,"BICUSPID,AORTOPATHY,DISSECTION,VALVE,RISK",BIOMEDICAL ENGINEERING LETTERS,https://link.springer.com/content/pdf/10.1007/s13534-020-00179-0.pdf,
10,A Review on Performance of Self-Compacting Concrete - Use of Mineral Admixtures and Steel Fibres with Artificial Neural Network Application,261,,,"Ramkumar K. B.,Rajkumar Kannan P. R.,Shaik Noor Ahmmad,Jegan M.","Ramkumar KB,Rajkumar PRK,Shaik NA,Jegan M",Rajkumar PRK,10.1016/j.conbuildmat.2020.120215,SRM Institute of Science & Technology Chennai,"Self-compacting concrete (SCC) has high value for deformability and segregation resistance, moderate viscosity and smaller yield stress. When pouring the SCC, the mix possesses the distinctive practical features such as - it is easily flown around and within the formwork. Using the ingredients of normal concrete, the SCC is produced. Cementitious materials are adopted for replacing the SCC cement content using agricultural products and industrial waste materials. For optimizing the material contained in SCC to obtain effective performance many machine learning approaches are implemented. This paper focuses on undertaking a review of SCC along with fibre reinforcement and cement replacement materials along with the role of ANN in predicting the optimum composition of SCC. The prime objective is on compiling the various literature available for understanding different SCC properties in the hardened and fresh state and also when these fibres and cement replacement items are introduced. (C) 2020 Elsevier Ltd. All rights reserved.","SCC,Cement,Fibre,VMA,SP,ANN",Review,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Construction & Building Technology,Engineering,Materials Science",,6.841,"NANO-SILICA,COMPRESSIVE,STRENGTH,CONSOLIDATING,CONCRETE,MECHANICAL-PROPERTIES,FLY-ASH,MICROSTRUCTURAL,PROPERTIES,DURABILITY,PROPERTIES,HARDENED,PROPERTIES,IMPACT,RESISTANCE,REINFORCED,CEMENT",CONSTRUCTION AND BUILDING MATERIALS,,
11,GFRP wrapped concrete column compressive strength prediction through neural network,2,12,,"Sangeetha P.,Shanmugapriya M.","Sangeetha P,Shanmugapriya M",Sangeetha P,10.1007/s42452-020-03753-4,SSN College of Engineering,"Wrapping of fibre over the concrete columns significantly improves the compressive strength and ductility behaviour of columns. In this study the compressive strength of the Glass Fibre Reinforced Concrete (GFRP) wrapped concrete columns were studied under axial compression. The parameters varied are types of GFRP (Surface Mat, Chopped Strand Mat and Woven Roving Mat), number of plies (0, 1 ply and 3 plies) and period of curing (7, 14 and 28 days). Twenty-one standard cylindrical specimens were tested to failure under compression testing machine. The GFRP confined concrete columns increases the compressive strength by 30% for different types of fibres. The change in the number of plies from one to three improves the strength six times. The Artificial Neural Network (ANN) is an alternate tool used to accurately estimate the confined strength of the wrapped columns. The multi-layer neural network has been used with back propagation training algorithm. The predicted strength was compared with the experimental results. A good correlation was obtained between the predicted strength by ANN model and experimental values with correlation coefficient R values of 0.992, 0.999 and 0.999 for training, validation and testing data sets.","GFRP Number of plies,Period of curing,Compressive strength,ANN",Article,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Science & Technology - Other Topics,,,"SURFACE-ROUGHNESS,SHEAR-STRENGTH,BEHAVIOR",SN APPLIED SCIENCES,https://link.springer.com/content/pdf/10.1007/s42452-020-03753-4.pdf,
12,Deep learning model for Demolition Waste Prediction in a circular economy,274,,,"Akanbi Lukman A.,Oyedele Ahmed O.,Oyedele Lukumon O.,Salami Rafiu O.","Akanbi LA,Oyedele AO,Oyedele LO,Salami RO",Akanbi LA,10.1016/j.jclepro.2020.122843,University of West England,"An essential requirement for a successful circular economy is the continuous use of materials. Planning for building materials reuse at the end-of-life of buildings is usually a difficult task because limited time are usually made available for building removal and materials recovery. In this study, deep learning models were developed for predicting the amount (in tons) of salvage and waste materials that are obtainable from buildings at the end-of-life prior to demolition. Datasets used for deep neural network model developments were extracted from 2280 building demolition records obtained from the practitioners in the UK Demolition Industry. The data was partitioned into training, testing and validation datasets in the ratio 8:1:1. Deep learning models were developed with a deep learning framework in R programming environment. The average R-squared value for the three deep learning models is 0.97 with Mean Absolute Error between 17.93 and 19.04. The models were evaluated with four scenarios of a case study building design. The results of the evaluation show that, given basic features of buildings, it is possible to predict with a high level of accuracy, the amount of materials that would be recovered from a building after demolition. The models developed will provide decision support functionalities to demolition engineers and waste management planners during the pre-demolition audit exercise. (C) 2020 Elsevier Ltd. All rights reserved.","Deep learning,Deep neural network,Buildings' end-of-life,Circular economy,Building materials",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Science & Technology - Other Topics,Engineering,Environmental Sciences & Ecology",,9.444,"CONSTRUCTION,DECONSTRUCTION,SYSTEM",JOURNAL OF CLEANER PRODUCTION,,
13,Solving Stochastic Inverse Problems for Property-Structure Linkages Using Data-Consistent Inversion and Machine Learning,73,1,72-89,"Tran Anh,Wildey Tim","Tran A,Wildey T",Tran A,10.1007/s11837-020-04432-w,United States Department of Energy (DOE),"Determining process-structure-property linkages is one of the key objectives in material science, and uncertainty quantification plays a critical role in understanding both process-structure and structure-property linkages. In this work, we seek to learn a distribution of microstructure parameters that are consistent in the sense that the forward propagation of this distribution through a crystal plasticity finite element model matches a target distribution on materials properties. This stochastic inversion formulation infers a distribution of acceptable/consistent microstructures, as opposed to a deterministic solution, which expands the range of feasible designs in a probabilistic manner. To solve this stochastic inverse problem, we employ a recently developed uncertainty quantification framework based on push-forward probability measures, which combines techniques from measure theory and Bayes' rule to define a unique and numerically stable solution. This approach requires making an initial prediction using an initial guess for the distribution on model inputs and solving a stochastic forward problem. To reduce the computational burden in solving both stochastic forward and stochastic inverse problems, we combine this approach with a machine learning Bayesian regression model based on Gaussian processes and demonstrate the proposed methodology on two representative case studies in structure-property linkages.","POLYCRYSTALLINE MICRO STRUCTURES,DESIGN EXPLORATION METHOD,HIGH-CONTRAST COMPOSITES,CRYSTAL PLASTICITY,AUTOMATED-ANALYSIS,SIMULATION,FRAMEWORK,OPTIMIZATION,DEFORMATION,RECONSTRUCTION",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Materials Science,Metallurgy & Metallurgical Engineering,Mineralogy,Mining & Mineral Processing",,2.989,"POLYCRYSTALLINE,MICRO,STRUCTURES,DESIGN,EXPLORATION,METHOD,HIGH-CONTRAST,COMPOSITES,CRYSTAL,PLASTICITY,AUTOMATED-ANALYSIS,SIMULATION,FRAMEWORK,OPTIMIZATION,DEFORMATION,RECONSTRUCTION",JOM,http://arxiv.org/pdf/2010.03603,
14,Machine Learning on Contact Angles of Liquid Metals and Solid Oxides,52,1,17-22,"Zuo Li,Ni Peiyuan,Tanaka Toshihiro,Li Ying","Zuo L,Ni PY,Tanaka T,Li Y",Ni PY,10.1007/s11663-020-02013-5,Northeastern University - China,"An improved neural network model was developed in this paper to predict the contact angles of 15 metals and 14 solid oxides. The model shows a good performance that predictions are generally within 15 pct deviation from the experimental data. Predictions on 25 test data shows the maximum deviation smaller than 10 pct. Therefore, the developed model is a universal model with a good accuracy, which is useful for material science and manufacturing field.","MONITORED OXYGEN ACTIVITY,SURFACE-TENSION,INTERFACIAL ENERGIES,GRAIN-BOUNDARY,WETTABILITY CHARACTERIZATION,EXPERIMENTAL SETUP,WETTING BEHAVIORS,MAGNESIUM-OXIDE,CERAMIC SYSTEMS,URANIUM-DIOXIDE",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Materials Science,Metallurgy & Metallurgical Engineering",,2.57,"MONITORED,OXYGEN,ACTIVITY,SURFACE-TENSION,INTERFACIAL,ENERGIES,GRAIN-BOUNDARY,WETTABILITY,CHARACTERIZATION,EXPERIMENTAL,SETUP,WETTING,BEHAVIORS,MAGNESIUM-OXIDE,CERAMIC,SYSTEMS,URANIUM-DIOXIDE",METALLURGICAL AND MATERIALS TRANSACTIONS B-PROCESS METALLURGY AND MATERIALS PROCESSING SCIENCE,,
15,A bio-available strontium isoscape for eastern Beringia: a tool for tracking landscape use of Pleistocene megafauna,36,1,76-90,"Funck Juliette,Bataille Clement,Rasic Jeffrey,Wooller Matthew","Funck J,Bataille C,Rasic J,Wooller M",Wooller M,10.1002/jqs.3262,University of Alaska System,"Numerous paleoecological questions concern the mobility of ancient fauna in eastern Beringia. Strontium (Sr) isotope ratio (Sr-87/Sr-86) analysis has emerged as a powerful tracer for determining the provenance of ancient biological materials. However, it is important to characterize Sr-87/Sr-86 variation across a landscape. We measured the Sr-87/Sr-86 composition of teeth from present-day, herbivorous rodents (n = 162) sampled from across eastern Beringia to estimate bio-available Sr-87/Sr-86 values. We compiled these data with the very limited number of previously published Sr-87/Sr-86 values from the region. We then used this dataset and a machine learning, random-forest regression to predict bio-available Sr-87/Sr-86 variations across eastern Beringia. As a case study using our new Sr-87/Sr-86 map (isoscape), we measured the Sr-87/Sr-86 and oxygen stable isotope values (delta O-18) of five radiocarbon-dated steppe bison from eastern Beringia and compared these to our Sr-87/Sr-86 isoscape and a delta O-18 isoscape to estimate the probable landscape use of these ancient fauna. Our model and isoscape provide important foundations for a wide range of additional applications, including studies of the paleo-mobility of other fauna, ancient people and present-day fauna in eastern Beringia.","Alaska,bison,machine&#8208,learning,provenance,rodents",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Physical Geography,Geology",,2.747,"ISOTOPE,RATIOS,BONE-COLLAGEN,STEPPE,BISON,WOOD,BISON,DISPERSAL,ALASKA,OXYGEN,GROWTH,WATER,RECONSTRUCTION",JOURNAL OF QUATERNARY SCIENCE,,
16,Machine Learning for Atomic Simulation and Activity Prediction in Heterogeneous Catalysis: Current Status and Future,10,22,13213-13226,"Ma Sicong,Liu Zhi-Pan","Ma SC,Liu ZP",Liu ZP,10.1021/acscatal.0c03472,Fudan University,"Heterogeneous catalysis, for its industrial importance and great complexity in structure, has long been the testing ground of new characterization techniques. Machine learning (ML) as a starring tool in data science brings new opportunities for chemists to interpret, simulate, and predict complex reactions in heterogeneous catalysis. Here we review the current status of ML methods and applications in heterogeneous catalysis by following two main streams: the top-down approach by learning experiment data and the bottom-up approach for making predictions from first-principles, which differ in the data source. We focus more on the latter, where ML interacts intimately with first-principles calculations for predicting the key properties (e.g., molecular adsorption energy) and evaluating potential energy surface (PES) to expedite the atomic simulation. The ML-based PES exploration represents the top gear that can largely replace the traditional roles of first-principles calculations for structure determination and activity evaluation but requires efficient methods for data set generation, sensitive structure descriptors to discriminate structures, and iterative self-learning to refine the ML potential. We illustrate these key ingredients of ML-based atomic simulation using the SSW-NN method developed by our group as the example. Three cases of SSW-NN application are presented to elaborate how ML can expedite the material and reaction simulation and lead to new findings on catalyst structure and reaction channels. The future directions of ML-based applications in heterogeneous catalysis are also discussed.","machine learning,heterogeneous catalysis,potential energy surface,density functional theory,global optimization,SSW-NN,LASP",Review,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,13.721,"SURFACE,WALKING,METHOD,FINDING,SADDLE-POINTS,NEURAL-NETWORK,POTENTIALS,DENSITY-FUNCTIONAL,THEORY,SELECTIVE,CO,OXIDATION,AMMONIA-SYNTHESIS,TRANSITION-STATE,KNOWLEDGE,EXTRACTION,GLOBAL,OPTIMIZATION,NON-STOICHIOMETRY",ACS CATALYSIS,,
17,Active Site Representation in First-Principles Microkinetic Models: Data-Enhanced Computational Screening for Improved Methanation Catalysts,10,22,13729-13736,"Deimel Martin,Reuter Karsten,Andersen Mie","Deimel M,Reuter K,Andersen M",Andersen M,10.1021/acscatal.0c04045,Technical University of Munich,"Computational screening based on first-principles microkinetic modeling has evolved into a widespread tool for catalyst discovery. Efficiently exploiting various scaling relations, this approach draws its predictive character from reliable adsorption energies, typically calculated with density-functional theory (DFT). In prevalent screening approaches, the concomitant computational costs are kept tractable through the use of reductionist microkinetic models that only resolve a minimalistic amount of active site motifs at the catalyst surface. Her; we scrutinize this common practice by systematically comparing the screening predictions for the CO methanation reaction when using microkinetic models that resolve an increasing amount of sites, up to the full consideration of all high-symmetry sites at stepped transition metal (TM) and binary TM alloy catalysts. Apart from generally overestimating the catalytic activity, the simplified models fail to identify a most promising class of layered bimetallic alloys as their insufficient representation of the catalyst surface does not allow them to correctly capture the rate-determining step. Only the full microkinetic model provides this proper mechanistic basis for the screening. The excessive amount of predictive-quality adsorption energetics required for this model is obtained from a compressed sensing descriptor that once trained readily provides these data for a new material from a single DFT calculation of the clean surface. With the current methodological advances in areas such as compressed sensing and machine learning, and the concurrent availability of cheap adsorption energetics for a wide range of possible catalyst materials, there is thus no reason to continue to use simplistic microkinetic models in computational catalyst screening.","computational screening,heterogeneous catalysis,active site representation,density functional theory,microkinetic modeling,compressed sensing,machine learning",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,13.721,,ACS CATALYSIS,,
18,EEG-based intention recognition with deep recurrent-convolution neural network: Performance and channel selection by Grad-CAM,415,,225-233,"Li Yurong,Yang Hao,Li Jixiang,Chen Dongyi,Du Min","Li YR,Yang H,Li JX,Chen DY,Du M",Li YR,10.1016/j.neucom.2020.07.072,Fuzhou University,"Electroencephalography (EEG) based Brain-Computer Interface (BCI) enables subjects to communicate with the outside world or control equipment using brain signals without passing through muscles and nerves. Many researchers in recent years have studied the non-invasive BCI systems. However, the efficiency of the intention decoding algorithm is affected by the random non-stationary and low signal-to-noise ratio characteristics of the EEG signal. Furthermore, channel selection is another important issue in BCI systems intention recognition. During intention recognition in BCI systems, the unnecessary information produced by redundant electrodes affects the decoding rate and deplete system resources. In this paper, we introduce a recurrent-convolution neural network model for intention recognition by learning decomposed spatio-temporal representations. We apply the novel Gradient-Class Activation Mapping (Grad-CAM) visualization technology to the channel selection. Grad-CAM uses the gradient of any classification, flowing into the last convolutional layer to produce a coarse localization map. Since the pixels of the localization map correspond to the spatial regions where the electrodes are placed, we select the channels that are more important for decision-making. We conduct an experiment using the public motor imagery EEG dataset EEGMMIDB. The experimental results demonstrate that our method achieves an accuracy of 97.36% at the full channel, outperforming many state-of-the-art models and baseline models. Although the decoding rate of our model is the same as the best model compared, our model has fewer parameters with faster training time. After the channel selection, our model maintains the intention decoding performance of 92.31% while reducing the number of channels by nearly half and saving system resources. Our method achieves an optimal trade-off between performance and the number of electrode channels for EEG intention decoding. (C) 2020 Elsevier B.V. All rights reserved.","EEG,Grad-CAM,Deep recurrent-convolution neural network,Performance,Channel selection,Intention recognition",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"QUANTITATIVE-ANALYSIS,BCI,CLASSIFICATION,COMMUNICATION",NEUROCOMPUTING,,
19,,,,,,,,,,,,,,,,,,,,
20,,,,,,,,,,,,,,,,,,,,
21,,,,,,,,,,,,,,,,,,,,
22,,,,,,,,,,,,,,,,,,,,
23,,,,,,,,,,,,,,,,,,,,
24,Toward Measuring Target Perception: First-Order and Second-Order Deep Network Pipeline for Classification of Fixation-Related Potentials,2020,,,"Zeng Hong,Shen Junjie,Zheng Wenming,Song Aiguo,Liu Jia","Zeng H,Shen JJ,Zheng WM,Song AG,Liu J",Zeng H,10.1155/2020/8829451,Southeast University - China,"The topdown determined visual object perception refers to the ability of a person to identify a prespecified visual target. This paper studies the technical foundation for measuring the target-perceptual ability in a guided visual search task, using the EEG-based brain imaging technique. Specifically, it focuses on the feature representation learning problem for single-trial classification of fixation-related potentials (FRPs). The existing methods either capture only first-order statistics while ignoring second-order statistics in data, or directly extract second-order statistics with covariance matrices estimated with raw FRPs that suffer from low signal-to-noise ratio. In this paper, we propose a new representation learning pipeline involving a low-level convolution subnetwork followed by a high-level Riemannian manifold subnetwork, with a novel midlevel pooling layer bridging them. In this way, the discriminative power of the first-order features can be increased by the convolution subnetwork, while the second-order information in the convolutional features could further be deeply learned with the subsequent Riemannian subnetwork. In particular, the temporal ordering of FRPs is well preserved for the components in our pipeline, which is considered to be a valuable source of discriminant information. The experimental results show that proposed approach leads to improved classification performance and robustness to lack of data over the state-of-the-art ones, thus making it appealing for practical applications in measuring the target-perceptual ability of cognitively impaired patients with the FRP technique.",,Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND",Health Care Sciences & Services,,3.188,,JOURNAL OF HEALTHCARE ENGINEERING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7690996,
25,Sensor Number Optimization Using Neural Network for Ankle Foot Orthosis Equipped with Magnetorheological Brake,11,1,91-101,"Adiputra Dimas,Rahman Mohd Azizi Abdul,Bahiuddin Irfan,Ubaidillah,Imaduddin Fitrian,Nazmi Nurhazimah","Adiputra D,Rahman MAA,Bahiuddin I,Ubaidillah,Imaduddin F,Nazmi N",Rahman MAA,10.1515/eng-2021-0010,Universiti Teknologi Malaysia,"A passive controlled ankle foot orthosis (PICAFO) used a passive actuator such as Magnetorheological (MR) brake to control the ankle stiffness. The PICAFO used two kinds of sensors, such as Electromyography (EMG) signal and ankle position (two inputs) to determine the amount of stiffness (one output) to be generated by the MR brake. As the overall weight and design of an orthotic device must be optimized, the sensor numbers on PICAFO wanted to be reduced. To do that, a machine learning approach was implemented to simplify the previous stiffness function. In this paper, Non-linear Autoregressive Exogeneous (NARX) neural network were used to generate the simplified function. A total of 2060 data were used to build the network with detail such as 1309 training data, 281 validation data, 281 testing data 1, and 189 testing data 2. Three training algorithms were used such as Levenberg-Marquardt, Bayesian Regularization, and Scaled Conjugate Gradient. The result shows that the function can be simplified into one input (ankle position) - one output (stiffness). Optimized result was shown by the NARX neural network with 15 hidden layers and trained using Bayesian Regularization with delay 2. In this case, the testing data shows R-value of 0.992 and MSE of 19.16.","magnetorheological brake,damping stiffness,sensor numbers,machine learning,nonlinear autoregressive exogenous",Article,"DE GRUYTER POLAND SP Z O O, BOGUMILA ZUGA 32A STR, 01-811 WARSAW, MAZOVIA, POLAND",Engineering,,,SYSTEMS,OPEN ENGINEERING,https://doi.org/10.1515/eng-2021-0010,
26,High-Throughput Screening of Metal-Organic Frameworks for Ethane-Ethylene Separation Using the Machine Learning Technique,34,11,14591-14597,"Halder Prosun,Singh Jayant K.","Halder P,Singh JK",Singh JK,10.1021/acs.energyfuels.0c03063,Indian Institute of Technology System (IIT System),"A hybrid approach combining machine learning algorithms with molecular simulation is utilized to screen hypothetical metal-organic framework (h-MOF) database for the best material to separate ethane (C2H6) and ethylene (C2H4). In particular, we rationalized the relation between structural and chemical properties of h-MOF with the C2H6/C2H4 selectivity. 8% hMOFs were chosen randomly from the h-MOF dataset as a training set. The simulations were conducted at 298 K and 1 bar using a multicomponent grand-canonical Monte Carlo method to obtain the C2H6/C2H4 selectivity. Based on the training set, the random forest (RF) model was developed to predict the selectivity of the rest of the h-MOFs. Among all the chemical and structural properties, void fraction plays a significant role in predicting the equilibrium C2H6/C2H4 selectivity. The trained machine learning model can reasonably predict the C2H6/C2H4 selectivity of the remaining h-MOF materials with an RF score of 0.89. Four h-MOFs have shown the best performance, which was compared with the previously discovered materials. The top four h-MOFs were further simulated at different pressures to obtain the adsorption isotherms. Further, the energy contribution of secondary building units and the local density profiles were analyzed to understand the enhanced interaction between h-MOF atoms and C2H6.",,Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Energy & Fuels,Engineering",,3.94,,ENERGY & FUELS,,
27,Aqueous solution processed mesoporous silica-gated photo-perception neuromorphic transistor,56,6,4316-4327,"Ren Zheng Yu,Zhu Li Qiang,Ai Ling,Lou Xue Qin,Cai Jia Cheng,Li Zhi Yuan,Xiao Hui","Ren ZY,Zhu LQ,Ai L,Lou XQ,Cai JC,Li ZY,Xiao H",Zhu LQ,10.1007/s10853-020-05560-z,Ningbo University,"Our body is a multiple perception learning system. Bionic application of perception cognitive functions based on neuromorphic electronics would endow artificial intelligence new intension. In particular, electrolyte-gated transistors have been suggested for neuromorphic platform applications. Due to the fundamental limitations for ionic liquid and ionic gel-based electrolyte, it would be interesting to obtain solid-state electrolytes through a vacuum free system. Thus, in the present work, a simple aqueous solution-processed mesoporous silica coating-gated oxide photo-perception neuromorphic transistors have been proposed. The neuromorphic transistors exhibit good electrical performances. A resistor-loaded inverter is built, exhibiting typical inverter operation at low working voltage. 'Selective potentiation and depression' behaviors have been mimicked on the neuromorphic transistor. In addition, the proposed neuromorphic transistor shows optical and electrical synergic response behaviors. Neurological behavior of conditioned taste aversion learning has been mimicked. Thus, the single photo-perception neuromorphic transistor could integrate the functions of perception and neuromorphic algorithm. The proposed photo-perception neuromorphic transistors could have potentials in artificial perception learning systems.","SELECTIVE ATTENTION,SYNAPTIC PLASTICITY,MECHANISMS,NETWORK",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Materials Science,,3.69,"SELECTIVE,ATTENTION,SYNAPTIC,PLASTICITY,MECHANISMS,NETWORK",JOURNAL OF MATERIALS SCIENCE,,
28,Development of a general-purpose machine-learning interatomic potential for aluminum by the physically informed neural network method,4,11,,"Pun G. P. Purja,Yamakov V.,Hickman J.,Glaessgen E. H.,Mishin Y.","Pun GPP,Yamakov V,Hickman J,Glaessgen EH,Mishin Y",Pun GPP,10.1103/PhysRevMaterials.4.113807,George Mason University,"Interatomic potentials constitute the key component of large-scale atomistic simulations of materials. The recently proposed physically informed neural network (PINN) method combines a high-dimensional regression implemented by an artificial neural network with a physics-based bond-order interatomic potential applicable to both metals and nonmetals. In this paper, we present a modified version of the PINN method that accelerates the potential training process and further improves the transferability of PINN potentials to unknown atomic environments. As an application, a modified PINN potential for Al has been developed by training on a large database of electronic structure calculations. The potential reproduces the reference first-principles energies within 2.6 meV per atom and accurately predicts a wide spectrum of physical properties of Al. Such properties include, but are not limited to, lattice dynamics, thermal expansion, energies of point and extended defects, the melting temperature, the structure and dynamic properties of liquid Al, the surface tensions of the liquid surface and the solid-liquid interface, and the nucleation and growth of a grain boundary crack. Computational efficiency of PINN potentials is also discussed.",,Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Materials Science,,4.034,,PHYSICAL REVIEW MATERIALS,http://arxiv.org/pdf/2009.06533,
29,Toward a Compassionate Intersectional Neuroscience: Increasing Diversity and Equity in Contemplative Neuroscience,11,,,"Weng Helen Y.,Ikeda Mushim P.,Lewis-Peacock Jarrod A.,Chao Maria T.,Fullwiley Duana,Goldman Vierka,Skinner Sasha,Duncan Larissa G.,Gazzaley Adam,Hecht Frederick M.","Weng HY,Ikeda MP,Lewis-Peacock JA,Chao MT,Fullwiley D,Goldman V,Skinner S,Duncan LG,Gazzaley A,Hecht FM",Weng HY,10.3389/fpsyg.2020.573134,University of California System,"Mindfulness and compassion meditation are thought to cultivate prosocial behavior. However, the lack of diverse representation within both scientific and participant populations in contemplative neuroscience may limit generalizability and translation of prior findings. To address these issues, we propose a research framework called Intersectional Neuroscience which adapts research procedures to be more inclusive of under-represented groups. Intersectional Neuroscience builds inclusive processes into research design using two main approaches: 1) community engagement with diverse participants, and 2) individualized multivariate neuroscience methods to accommodate neural diversity. We tested the feasibility of this framework in partnership with a diverse U.S. meditation center (East Bay Meditation Center, Oakland, CA). Using focus group and community feedback, we adapted functional magnetic resonance imaging (fMRI) screening and recruitment procedures to be inclusive of participants from various under-represented groups, including racial and ethnic minorities, gender and sexual minorities, people with disabilities, neuropsychiatric disorders, and/or lower income. Using person-centered screening and study materials, we recruited and scanned 15 diverse meditators (80% racial/ethnic minorities, 53% gender and sexual minorities). The participants completed the EMBODY task - which applies individualized machine learning algorithms to fMRI data - to identify mental states during breath-focused meditation, a basic skill that stabilizes attention to support interoception and compassion. All 15 meditators' unique brain patterns were recognized by machine learning algorithms significantly above chance levels. These individualized brain patterns were used to decode the internal focus of attention throughout a 10-min breath-focused meditation period, specific to each meditator. These data were used to compile individual-level attention profiles during meditation, such as the percentage time attending to the breath, mind wandering, or engaging in self-referential processing. This study provides feasibility of employing an intersectional neuroscience approach to include diverse participants and develop individualized neural metrics of meditation practice. Through inclusion of more under-represented groups while developing reciprocal partnerships, intersectional neuroscience turns the research process into an embodied form of social action.","meditation,interoception,neuroscience,diversity,community engagement,intersectionality,mindfulness,machine learning",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Psychology,,3.618,"PATTERN-ANALYSIS,MEDITATION,RESPONSES,SCIENCE,MODEL",FRONTIERS IN PSYCHOLOGY,https://osf.io/mv26c/download,
30,Lattice dynamics of YbxCo4Sb12 skutterudite by machine-learning interatomic potentials: Effect of filler concentration and disorder,102,18,,"Korotaev Pavel,Shapeev Alexander","Korotaev P,Shapeev A",Korotaev P,10.1103/PhysRevB.102.184305,Dukhov Research Institute of Automatics (VNIIA),"Lattice dynamics determines a number of important properties of solids. While computational methods with predictive power have been developed in this area, the task is still difficult for the complex compounds. We present a method for automatic on-the-fly generation of multicomponent interatomic potentials. The method is based on active learning, which ensures effective extrapolation to new atomic environments. The accuracy is then demonstrated on the example of the Yb-filled skutterudite compound YbxCo4Sb12, which is a family of the promising thermoelectric materials. Atomic displacements, vibrational spectrum, and lattice thermal conductivity were obtained and the effect of the Yb filling and ordering was studied as 700 K. The potential allowed us to reproduce fine features of the vibrational spectrum, as well as the reduction of the lattice thermal conductivity with filling. We found only a small effect of the disorder on the vibrational spectrum and the thermal conductivity.",,Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,,PHYSICAL REVIEW B,,
31,,,,,,,,,,,,,,,,,,,,
32,Breast tumor segmentation in 3D automatic breast ultrasound using Mask scoring R-CNN,48,1,204-214,"Lei Yang,He Xiuxiu,Yao Jincao,Wang Tonghe,Wang Lijing,Li Wei,Curran Walter J.,Liu Tian,Xu Dong,Yang Xiaofeng","Lei Y,He XX,Yao JC,Wang TH,Wang LJ,Li W,Curran WJ,Liu T,Xu D,Yang XF",Yang XF,10.1002/mp.14569,Emory University,"Purpose Automatic breast ultrasound (ABUS) imaging has become an essential tool in breast cancer diagnosis since it provides complementary information to other imaging modalities. Lesion segmentation on ABUS is a prerequisite step of breast cancer computer-aided diagnosis (CAD). This work aims to develop a deep learning-based method for breast tumor segmentation using three-dimensional (3D) ABUS automatically.
Methods For breast tumor segmentation in ABUS, we developed a Mask scoring region-based convolutional neural network (R-CNN) that consists of five subnetworks, that is, a backbone, a regional proposal network, a region convolutional neural network head, a mask head, and a mask score head. A network block building direct correlation between mask quality and region class was integrated into a Mask scoring R-CNN based framework for the segmentation of new ABUS images with ambiguous regions of interest (ROIs). For segmentation accuracy evaluation, we retrospectively investigated 70 patients with breast tumor confirmed with needle biopsy and manually delineated on ABUS, of which 40 were used for fivefold cross-validation and 30 were used for hold-out test. The comparison between the automatic breast tumor segmentations and the manual contours was quantified by I) six metrics including Dice similarity coefficient (DSC), Jaccard index, 95% Hausdorff distance (HD95), mean surface distance (MSD), residual mean square distance (RMSD), and center of mass distance (CMD); II) Pearson correlation analysis and Bland-Altman analysis.
Results The mean (median) DSC was 85% +/- 10.4% (89.4%) and 82.1% +/- 14.5% (85.6%) for cross-validation and hold-out test, respectively. The corresponding HD95, MSD, RMSD, and CMD of the two tests was 1.646 +/- 1.191 and 1.665 +/- 1.129 mm, 0.489 +/- 0.406 and 0.475 +/- 0.371 mm, 0.755 +/- 0.755 and 0.751 +/- 0.508 mm, and 0.672 +/- 0.612 and 0.665 +/- 0.729 mm. The mean volumetric difference (mean and +/- 1.96 standard deviation) was 0.47 cc ([-0.77, 1.71)) for the cross-validation and 0.23 cc ([-0.23 0.69]) for hold-out test, respectively.
Conclusion We developed a novel Mask scoring R-CNN approach for the automated segmentation of the breast tumor in ABUS images and demonstrated its accuracy for breast tumor segmentation. Our learning-based method can potentially assist the clinical CAD of breast cancer using 3D ABUS imaging.","automatic breast ultrasound,breast cancer,mask scoring R&#8208,CNN,segmentation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"COMPUTER-AIDED,DETECTION,IMAGE,SEGMENTATION,CANCER,DETECTION,DIAGNOSIS,MASSES,CLASSIFICATION,LESIONS",MEDICAL PHYSICS,,
33,Deep Learning-Based Holographic Polarization Microscopy,7,11,3023-3034,"Liu Tairan,de Haan Kevin,Bai Bijie,Rivenson Yair,Luo Yi,Wang Hongda,Karalli David,Fu Hongxiang,Zhang Yibo,FitzGerald John","Liu TR,de Haan K,Bai BJ,Rivenson Y,Luo Y,Wang HD,Karalli D,Fu HX,Zhang YB,FitzGerald J",Ozcan A,10.1021/acsphotonics.0c01051,University of California System,"Polarized light microscopy provides high contrast to birefringent specimen and is widely used as a diagnostic tool in pathology. However, polarization microscopy systems typically operate by analyzing images collected from two or more light paths in different states of polarization, which lead to relatively complex optical designs, high system costs, or experienced technicians being required. Here, we present a deep learning-based holographic polarization microscope that is capable of obtaining quantitative birefringence retardance and orientation information of specimen from a phase-recovered hologram, while only requiring the addition of one polarizer/analyzer pair to an inline lensfree holographic imaging system. Using a deep neural network, the reconstructed holographic images from a single state of polarization can be transformed into images equivalent to those captured using a single-shot computational polarized light microscope (SCPLM). Our analysis shows that a trained deep neural network can extract the birefringence information using both the sample specific morphological features as well as the holographic amplitude and phase distribution. To demonstrate the efficacy of this method, we tested it by imaging various birefringent samples including, for example, monosodium urate and triamcinolone acetonide crystals. Our method achieves similar results to SCPLM both qualitatively and quantitatively, and due to its simpler optical design and significantly larger field-of-view this method has the potential to expand the access to polarization microscopy and its use for medical diagnosis in resource limited settings.","polarization microscopy,holographic microscopy,deep learning,convolutional neural networks,on-chip microscopy,lensless microscopy",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science,Optics,Physics",,7.718,,ACS PHOTONICS,http://arxiv.org/pdf/2007.00741,
34,Open resource of clinical data from patients with pneumonia for the prediction of COVID-19 outcomes via deep learning,4,12,1197-1207,"Ning Wanshan,Lei Shijun,Yang Jingjing,Cao Yukun,Jiang Peiran,Yang Qianqian,Zhang Jiao,Wang Xiaobei,Chen Fenghua,Geng Zhi","Ning WS,Lei SJ,Yang JJ,Cao YK,Jiang PR,Yang QQ,Zhang J,Wang XB,Chen FH,Geng Z",Xue Y,10.1038/s41551-020-00633-5,Huazhong University of Science & Technology,"An open resource comprising chest computed tomography images and 130 clinical features of 1,521 patients with pneumonia, including COVID-19 pneumonia, facilitates the prediction of morbidity and mortality outcomes via deep learning.
Data from patients with coronavirus disease 2019 (COVID-19) are essential for guiding clinical decision making, for furthering the understanding of this viral disease, and for diagnostic modelling. Here, we describe an open resource containing data from 1,521 patients with pneumonia (including COVID-19 pneumonia) consisting of chest computed tomography (CT) images, 130 clinical features (from a range of biochemical and cellular analyses of blood and urine samples) and laboratory-confirmed severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) clinical status. We show the utility of the database for prediction of COVID-19 morbidity and mortality outcomes using a deep learning algorithm trained with data from 1,170 patients and 19,685 manually labelled CT slices. In an independent validation cohort of 351 patients, the algorithm discriminated between negative, mild and severe cases with areas under the receiver operating characteristic curve of 0.944, 0.860 and 0.884, respectively. The open database may have further uses in the diagnosis and management of patients with COVID-19.","CORONAVIRUS,WUHAN,CHINA,DIAGNOSIS",Article,"NATURE PORTFOLIO, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Engineering,,26.355,"CORONAVIRUS,WUHAN,CHINA,DIAGNOSIS",NATURE BIOMEDICAL ENGINEERING,https://www.nature.com/articles/s41551-020-00633-5.pdf,
35,Frequency and phase correction of J-difference edited MR spectra using deep learning,85,4,1755-1765,"Tapper Sofie,Mikkelsen Mark,Dewey Blake E.,Zollner Helge J.,Hui Steve C. N.,Oeltzschner Georg,Edden Richard A. E.","Tapper S,Mikkelsen M,Dewey BE,Zollner HJ,Hui SCN,Oeltzschner G,Edden RAE",Tapper S,10.1002/mrm.28525,Johns Hopkins University,"Purpose To investigate whether a deep learning-based (DL) approach can be used for frequency-and-phase correction (FPC) of MEGA-edited MRS data.
Methods Two neural networks (1 for frequency, 1 for phase) consisting of fully connected layers were trained and validated using simulated MEGA-edited MRS data. This DL-FPC was subsequently tested and compared to a conventional approach (spectral registration [SR]) and to a model-based SR implementation (mSR) using in vivo MEGA-edited MRS datasets. Additional artificial offsets were added to these datasets to further investigate performance.
Results The validation showed that DL-based FPC was capable of correcting within 0.03 Hz of frequency and 0.4 degrees of phase offset for unseen simulated data. DL-based FPC performed similarly to SR for the unmanipulated in vivo test datasets. When additional offsets were added to these datasets, the networks still performed well. However, although SR accurately corrected for smaller offsets, it often failed for larger offsets. The mSR algorithm performed well for larger offsets, which was because the model was generated from the in vivo datasets. In addition, the computation times were much shorter using DL-based FPC or mSR compared to SR for heavily distorted spectra.
Conclusion These results represent a proof of principle for the use of DL for preprocessing MRS data.","deep learning,edited MRS,frequency correction,MEGA&#8208,PRESS,phase correction",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"MAGNETIC-RESONANCE-SPECTROSCOPY,GAMMA-AMINOBUTYRIC-ACID,HUMAN,BRAIN,GABA,ARTIFACTS,WATER,ECHO",MAGNETIC RESONANCE IN MEDICINE,,
36,Machine Learning-Enabled Uncertainty Quantification for Modeling Structure-Property Linkages for Fatigue Critical Engineering Alloys Using an ICME Workflow,9,4,376-393,"Whelan Gary,McDowell David L.","Whelan G,McDowell DL",Whelan G,10.1007/s40192-020-00192-2,University System of Georgia,"Integrated computational materials engineering (ICME) facilitates efficient approaches to new material discovery and design, as well as optimization of existing materials. Computational models provide a way to rapidly screen candidate material designs such that materials can be tailored for specific applications in the product design cycle. Uncertainty is ubiquitous in ICME process-structure-property workflows; it represents a major barrier to the effective use of modeling results for high-confidence decision support in materials design and development. This work addresses microstructure statistical uncertainties, and demonstrates an approach to quantify, reduce, and propagate these uncertainties through structure-property linkages to provide robust quantification of uncertainties in output properties of interest. Further, this work demonstrates the use of Gaussian process machine learning models to significantly decrease the computational cost of the aforementioned robust uncertainty quantification.","Uncertainty quantification,Machine learning,ICME,Fatigue,Ti64,Alloy design",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Materials Science",,4.423,"MICROSTRUCTURE,CRACKS,PROPAGATION,SIMULATION,PREDICTION",INTEGRATING MATERIALS AND MANUFACTURING INNOVATION,,
37,"QM-symex, update of the QM-sym database with excited state information for 173 kilo molecules",7,1,,"Liang Jiechun,Ye Shuqian,Dai Tianshu,Zha Ziyue,Gao Yuechen,Zhu Xi","Liang JC,Ye SQ,Dai TS,Zha ZY,Gao YC,Zhu X",Zhu X,10.1038/s41597-020-00746-1,"Shenzhen Inst Artificial Intelligence & Robot Soc, 13-15F,Tower G2,Rd Yabao, Shenzhen 518172, Guangdong, Peoples R China.","In the research field of material science, quantum chemistry database plays an indispensable role in determining the structure and properties of new material molecules and in deep learning in this field. A new quantum chemistry database, the QM-sym, has been set up in our previous work. The QM-sym is an open-access database focusing on transition states, energy, and orbital symmetry. In this work, we put forward the QM-symex with 173-kilo molecules. Each organic molecular in the QM-symex combines with the C(n)h symmetry composite and contains the information of the first ten singlet and triplet transitions, including energy, wavelength, orbital symmetry, oscillator strength, and other quasi-molecular properties. QM-symex serves as a benchmark for quantum chemical machine learning models that can be effectively used to train new models of excited states in the quantum chemistry region as well as contribute to further development of the green energy revolution and materials discovery. Measurement(s) Excitation center dot molecular structure data center dot Chemical Properties Technology Type(s) quantum chemistry computational method Factor Type(s) molecule Machine-accessible metadata file describing the reported data: https://doi.org/10.6084/m9.figshare.13089554",,Article; Data Paper,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,9.051,,SCIENTIFIC DATA,https://www.nature.com/articles/s41597-020-00746-1.pdf,
38,A multi-label classification model for full slice brain computerised tomography image,21,,,"Li Jianqiang,Fu Guanghui,Chen Yueda,Li Pengzhi,Liu Bo,Pei Yan,Feng Hui","Li JQ,Fu GH,Chen YD,Li PZ,Liu B,Pei Y,Feng H",Pei Y,10.1186/s12859-020-3503-0,University of Aizu,"BackgroundScreening of the brain computerised tomography (CT) images is a primary method currently used for initial detection of patients with brain trauma or other conditions. In recent years, deep learning technique has shown remarkable advantages in the clinical practice. Researchers have attempted to use deep learning methods to detect brain diseases from CT images. Methods often used to detect diseases choose images with visible lesions from full-slice brain CT scans, which need to be labelled by doctors. This is an inaccurate method because doctors detect brain disease from a full sequence scan of CT images and one patient may have multiple concurrent conditions in practice. The method cannot take into account the dependencies between the slices and the causal relationships among various brain diseases. Moreover, labelling images slice by slice spends much time and expense. Detecting multiple diseases from full slice brain CT images is, therefore, an important research subject with practical implications.ResultsIn this paper, we propose a model called the slice dependencies learning model (SDLM). It learns image features from a series of variable length brain CT images and slice dependencies between different slices in a set of images to predict abnormalities. The model is necessary to only label the disease reflected in the full-slice brain scan. We use the CQ500 dataset to evaluate our proposed model, which contains 1194 full sets of CT scans from a total of 491 subjects. Each set of data from one subject contains scans with one to eight different slice thicknesses and various diseases that are captured in a range of 30 to 396 slices in a set. The evaluation results present that the precision is 67.57%, the recall is 61.04%, the F1 score is 0.6412, and the areas under the receiver operating characteristic curves (AUCs) is 0.8934.ConclusionThe proposed model is a new architecture that uses a full-slice brain CT scan for multi-label classification, unlike the traditional methods which only classify the brain images at the slice level. It has great potential for application to multi-label detection problems, especially with regard to the brain CT images.","Bioinformatics,Brain computerised tomography,Machine learning,Deep learning,Computer aided diagnosis",Article; Proceedings Paper,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,,BMC BIOINFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7672970,
39,Identification of early mild cognitive impairment using multi-modal data and graph convolutional networks,21,,,"Liu Jin,Tan Guanxin,Lan Wei,Wang Jianxin","Liu J,Tan GX,Lan W,Wang JX",Wang JX,10.1186/s12859-020-3437-6,Central South University,"BackgroundThe identification of early mild cognitive impairment (EMCI), which is an early stage of Alzheimer's disease (AD) and is associated with brain structural and functional changes, is still a challenging task. Recent studies show great promises for improving the performance of EMCI identification by combining multiple structural and functional features, such as grey matter volume and shortest path length. However, extracting which features and how to combine multiple features to improve the performance of EMCI identification have always been a challenging problem. To address this problem, in this study we propose a new EMCI identification framework using multi-modal data and graph convolutional networks (GCNs). Firstly, we extract grey matter volume and shortest path length of each brain region based on automated anatomical labeling (AAL) atlas as feature representation from T1w MRI and rs-fMRI data of each subject, respectively. Then, in order to obtain features that are more helpful in identifying EMCI, a common multi-task feature selection method is applied. Afterwards, we construct a non-fully labelled subject graph using imaging and non-imaging phenotypic measures of each subject. Finally, a GCN model is adopted to perform the EMCI identification task.ResultsOur proposed EMCI identification method is evaluated on 210 subjects, including 105 subjects with EMCI and 105 normal controls (NCs), with both T1w MRI and rs-fMRI data from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Experimental results show that our proposed framework achieves an accuracy of 84.1% and an area under the receiver operating characteristic (ROC) curve (AUC) of 0.856 for EMCI/NC classification. In addition, by comparison, the accuracy and AUC values of our proposed framework are better than those of some existing methods in EMCI identification.ConclusionOur proposed EMCI identification framework is effective and promising for automatic diagnosis of EMCI in clinical practice.","Early mild cognitive impairment,Multi-modal MRI data,Graph convolutional networks,Identification",Article; Proceedings Paper,"BMC, CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Mathematical & Computational Biology",,3.629,"FUNCTIONAL,CONNECTIVITY,BRAIN,CONNECTIVITY,CLASSIFICATION,DISEASE,MRI,REGRESSION,SELECTION",BMC BIOINFORMATICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7672960,
40,Surface imaging for real-time patient respiratory function assessment in intensive care,48,1,142-155,"Nazir Souha,Pateau Victoire,Bert Julien,Clement Jean-Francois,Fayad Hadi,L'Her Erwan,Visvikis Dimitris","Nazir S,Pateau V,Bert J,Clement JF,Fayad H,L'Her E,Visvikis D",Nazir S,10.1002/mp.14557,Institut National de la Sante et de la Recherche Medicale (Inserm),"Purpose Monitoring of physiological parameters is a major concern in Intensive Care Units (ICU) given their role in the assessment of vital organ function. Within this context, one issue is the lack of efficient noncontact techniques for respiratory monitoring. In this paper, we present a novel noncontact solution for real-time respiratory monitoring and function assessment of ICU patients.
Methods The proposed system uses a Time-of-Flight depth sensor to analyze the patient's chest wall morphological changes in order to estimate multiple respiratory function parameters. The automatic detection of the patient's torso is also proposed using a deep neural network model trained on the COCO dataset. The evaluation of the proposed system was performed on a mannequin and on 16 mechanically ventilated patients (a total of 216 recordings) admitted in the ICU of the Brest University Hospital.
Results The estimation of respiratory parameters (respiratory rate and tidal volume) showed high correlation with the reference method (r = 0.99; P P < 0.001) in the mannequin recordings and (r = 0.95, P < 0.001 and r = 0.90, P < 0.001) for patients.
Conclusion This study describes and evaluates a novel noncontact monitoring system suitable for continuous monitoring of key respiratory parameters for disease assessment of critically ill patients.","Intensive Care Unit,noncontact monitoring,respiratory function,surface imaging",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"HEART-FAILURE,TIDAL,VOLUME,KINECT,SYSTEM,MOTION,RADIOTHERAPY,IMPEDANCE,SENSOR,VENTILATION,VALIDATION",MEDICAL PHYSICS,,
41,Adaptive sparsity level and dictionary size estimation for image reconstruction in accelerated 2D radial cine MRI,48,1,178-192,"Pali Marie-Christine,Schaeffter Tobias,Kolbitsch Christoph,Kofler Andreas","Pali MC,Schaeffter T,Kolbitsch C,Kofler A",Kofler A,10.1002/mp.14547,Physikalisch-Technische Bundesanstalt (PTB),"Purpose In the past, dictionary learning (DL) and sparse coding (SC) have been proposed for the regularization of image reconstruction problems. The regularization is given by a sparse approximation of all image patches using a learned dictionary, that is, an overcomplete set of basis functions learned from data. Despite its competitiveness, DL and SC require the tuning of two essential hyperparameters: the sparsity level S - the number of basis functions of the dictionary, called atoms, which are used to approximate each patch, and K - the overall number of such atoms in the dictionary. These two hyperparameters usually have to be chosen a priori and are determined by repetitive and computationally expensive experiments. Furthermore, the final reported values vary depending on the specific situation. As a result, the clinical application of the method is limited, as standardized reconstruction protocols have to be used.
Methods In this work, we use adaptive DL and propose a novel adaptive sparse coding algorithm for two-dimensional (2D) radial cine MR image reconstruction. Using adaptive DL and adaptive SC, the optimal dictionary size K as well as the optimal sparsity level S are chosen dependent on the considered data.
Results Our three main results are the following: First, adaptive DL and adaptive SC deliver results which are comparable or better than the most widely used nonadaptive version of DL and SC. Second, the time needed for the regularization is accelerated due to the fact that the sparsity level S is never overestimated. Finally, the a priori choice of S and K is no longer needed but is optimally chosen dependent on the data under consideration.
Conclusions Adaptive DL and adaptive SC can highly facilitate the application of DL- and SC-based regularization methods. While in this work we focused on 2D radial cine MR image reconstruction, we expect the method to be applicable to different imaging modalities as well.","adaptive dictionary learning,adaptive sparse coding,compressed sensing,parameter estimation,radial cine MRI,unsupervised learning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"MATCHING,PURSUIT,ALGORITHM,QUALITY",MEDICAL PHYSICS,https://depositonce.tu-berlin.de/bitstream/11303/12619/1/MP_MP14547.pdf,
42,,,,,,,,,,,,,,,,,,,,
43,Effects of Domain Wall Proximity on Nanoscale Polarization Switching in Relaxor-Ferroelectric Single Crystals,218,2,,"Griffin Lee A.,Williams Samuel,Zhang Shujun,Bassiri-Gharb Nazanin","Griffin LA,Williams S,Zhang SJ,Bassiri-Gharb N",Bassiri-Gharb N,10.1002/pssa.202000506,University System of Georgia,"Domain walls' vibration and motion contribute significantly to the exceptionally large dielectric and piezoelectric response of ferroelectric materials. Yet, the specific length scales at which domain walls impact characteristic parameters remain largely unprobed. Previous studies examining correlation of domain wall proximity and functional response at the micrometer or submicrometer scales are often based on (locally or globally) ""written"" domains. The stability of such domains can be affected by many factors, resulting in convoluted effects of domain wall proximity and their stability when studying the local functional response. Herein, the effects of preexisting domain walls on the nanoscale polarization switching in a [001]-cut relaxor-ferroelectric 0.60Pb(Mg1/3Nb2/3)O3-0.40PbTiO3 single crystal are probed by piezoresponse force microscopy. It is found that domain wall proximity has limited impact on polarization switching for locations less than or similar to 300 nm away. While a transition from a growth- to nucleation-limited regime and/or change in dimensionality of domain growth is possibly observed, the effective impact on nucleation voltage does not exceed 25% variation. These results are consistent with the well-documented pervasive chemical, polar, and structural heterogeneities present in relaxor- ferroelectrics and the resulting ""soft"" piezoelectric behavior.","domain walls,machine learning,piezoresponse force microscopy (PFM),relaxor-ferroelectrics,statistical analysis",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Materials Science,Physics",,1.797,"ULTRAHIGH,PIEZOELECTRICITY,CERAMICS,DEPENDENCE,BEHAVIOR,STRAIN",PHYSICA STATUS SOLIDI A-APPLICATIONS AND MATERIALS SCIENCE,https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/pssa.202000506,
44,In-situ spatial and temporal electrical characterization of ZnO thin films deposited by atmospheric pressure chemical vapour deposition on flexible polymer substrates,10,1,,"Jones Alexander,Mistry Kissan,Kao Manfred,Shahin Ahmed,Yavuz Mustafa,Musselman Kevin P.","Jones A,Mistry K,Kao M,Shahin A,Yavuz M,Musselman KP",Musselman KP,10.1038/s41598-020-76993-4,University of Waterloo,"A technique is presented for collecting data on both the spatial and temporal variations in the electrical properties of a film as it is deposited on a flexible substrate. A flexible printed circuit board substrate with parallel electrodes distributed across its surface was designed. Zinc oxide films were then deposited on the flexible substrate at different temperatures via atmospheric pressure chemical vapour deposition (AP-CVD) using a spatial atomic layer deposition system. AP-CVD is a promising high-throughput thin film deposition technique with applications in flexible electronics. Collecting data on the film properties in-situ allows us to directly observe how deposition conditions affect the evolution of those properties in real-time. The spatial uniformity of the growing film was monitored, and the various stages of film nucleation and growth on the polymer substrate were observed. The measured resistance of the films was observed to be very high until a critical amount of material has been deposited, consistent with Volmer-Weber growth. Furthermore, monitoring the film resistance during post-deposition cooling enabled immediate identification of metallic or semiconducting behaviour within the conductive ZnO films. This technique allows for a more complete understanding of metal chalcogen film growth and properties, and the high volume of data generated will be useful for future implementations of machine-learning directed materials science.","ATOMIC-LAYER DEPOSITION,OXIDE LAYERS,GROWTH",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,5.134,"ATOMIC-LAYER,DEPOSITION,OXIDE,LAYERS,GROWTH",SCIENTIFIC REPORTS,https://www.nature.com/articles/s41598-020-76993-4.pdf,
45,Fusion and Visualization of Bridge Deck Nondestructive Evaluation Data via Machine Learning,7,,,"Mohamadi Sara,Lattanzi David,Azari Hoda","Mohamadi S,Lattanzi D,Azari H",Lattanzi D,10.3389/fmats.2020.576918,George Mason University,"To maintain infrastructure safety and integrity, nondestructive evaluation (NDE) technologies are often used for detection of subsurface defects and for holistic condition assessment of structures. While the rapid advances in data collection and the diversity of available sensing technologies provide new opportunities, the ability to efficiently process data and combine heterogeneous data sources to make robust decisions remains a challenge. Heterogeneous NDE measurements often conflict with one another and methods to visualize integrated results are usually developed ad hoc. In this work, a framework is presented to support fusion of multiple NDE techniques in order to improve both detection and quantification accuracy while also improving the visualization of NDE results. For data sources with waveform representations, the discrete wavelet transform (DWT) is used to extract salient features and facilitate fusion with scalar-valued NDE measurements. The description of a signal in terms of its salient features using a wavelet transform allows for capturing the significance of the original data, while suppressing measurement noise. The complete set of measurements is then fused using nonparametric machine learning so as to relax the need for Bayesian assumptions regarding statistical distributions. A novel visualization schema based on classifier confidence intervals is then employed to support holistic visualization and decision making. To validate the capabilities of the proposed methodology, an experimental prototype system was created and tested from NDE measurements of laboratory-scale bridge decks at Turner-Fairbank highway research center (TFHRC). The laboratory decks exhibit various types of artificial defects and several non-destructive tests were previously carried out by research center technicians to characterize the existing damages. The results suggest that the chosen feature extraction process, in this case the DWT, plays a critical role in classifier performance. The experimental evaluation also indicates a need for nonlinear machine learning algorithms for optimal fusion performance. In particular, support vector machines provided the most robust and consistent data fusion and defect detection capabilities. Overall, data fusion combinations are shown to provide more accurate and consistent detection results when compared to single NDE detection approaches, particularly for the detection of subsurface delamination.","data fusion,nondestructive Evaluation,visualization,machine learning,support vector machine,feature extraction,wavelet transform",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Materials Science,,3.536,"PAVEMENT,CRACK,DETECTION,SUPPORT,VECTOR,MACHINE,FEATURE-EXTRACTION,WAVELET,TRANSFORM,NEURAL-NETWORK,DAMAGE,IDENTIFICATION,SENSOR,FUSION,CONCRETE,CORROSION,CLASSIFICATION",FRONTIERS IN MATERIALS,https://www.frontiersin.org/articles/10.3389/fmats.2020.576918/pdf,
46,Automated detection of COVID-19 using ensemble of transfer learning with deep convolutional neural network based on CT scans,16,1,115-123,"Gifani Parisa,Shalbaf Ahmad,Vafaeezadeh Majid","Gifani P,Shalbaf A,Vafaeezadeh M",Shalbaf A,10.1007/s11548-020-02286-w,Shahid Beheshti University Medical Sciences,"Purpose COVID-19 has infected millions of people worldwide. One of the most important hurdles in controlling the spread of this disease is the inefficiency and lack of medical tests. Computed tomography (CT) scans are promising in providing accurate and fast detection of COVID-19. However, determining COVID-19 requires highly trained radiologists and suffers from inter-observer variability. To remedy these limitations, this paper introduces an automatic methodology based on an ensemble of deep transfer learning for the detection of COVID-19. Methods A total of 15 pre-trained convolutional neural networks (CNNs) architectures: EfficientNets(B0-B5), NasNetLarge, NasNetMobile, InceptionV3, ResNet-50, SeResnet 50, Xception, DenseNet121, ResNext50 and Inception_resnet_v2 are used and then fine-tuned on the target task. After that, we built an ensemble method based on majority voting of the best combination of deep transfer learning outputs to further improve the recognition performance. We have used a publicly available dataset of CT scans, which consists of 349 CT scans labeled as being positive for COVID-19 and 397 negative COVID-19 CT scans that are normal or contain other types of lung diseases. Results The experimental results indicate that the majority voting of 5 deep transfer learning architecture with EfficientNetB0, EfficientNetB3, EfficientNetB5, Inception_resnet_v2, and Xception has the higher results than the individual transfer learning structure and among the other models based on precision (0.857), recall (0.854) and accuracy (0.85) metrics in diagnosing COVID-19 from CT scans. Conclusion Our study based on an ensemble deep transfer learning system with different pre-trained CNNs architectures can work well on a publicly available dataset of CT images for the diagnosis of COVID-19 based on CT scans.","COVID-19,CT,Transfer learning,Convolutional neural network,Ensemble model",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Engineering,Radiology, Nuclear Medicine & Medical Imaging,Surgery",,2.745,,INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY,https://link.springer.com/content/pdf/10.1007/s11548-020-02286-w.pdf,
47,Machine-learning-assisted space-transformation accelerates discovery of high thermal conductivity alloys,117,20,,"Visaria Dhvaneel,Jain Ankit","Visaria D,Jain A",Jain A,10.1063/5.0028241,Indian Institute of Technology System (IIT System),"We study the thermal conductivity distribution of hypothetical graphene-like materials composed of carbon and heavy carbon atoms. These materials are representative of alloys and disordered materials, which are relatively unexplored for thermal properties owing to their large configuration spaces. Since the full thermal conductivity calculations using the Boltzmann transport equation based solutions are computationally prohibitive for each of the 2(32) considered configurations, we employ regularized autoencoders, a class of generative machine learning models that transform the configuration space to the latent space in which materials are clustered according to the target property. Such conditioning allows selective sampling of high thermal conductivity materials from the latent space. We find that the model is able to learn the underlying thermal transport physics of the system under study and is able to predict superlattice-like configurations with high thermal conductivity despite their higher mass. Published under license by AIP Publishing.",,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,3.596,,APPLIED PHYSICS LETTERS,,
48,Functional evaluation of triceps surae during heel rise test: from EMG frequency analysis to machine learning approach,59,1,41-56,"Ferracuti Francesco,Fioretti Sandro,Frontoni Emanuele,Iarlori Sabrina,Mengarelli Alessandro,Riccio Michele,Romeo Luca,Verdini Federica","Ferracuti F,Fioretti S,Frontoni E,Iarlori S,Mengarelli A,Riccio M,Romeo L,Verdini F",Iarlori S,10.1007/s11517-020-02286-7,Marche Polytechnic University,"Soleus muscle flap as coverage tissue is a possible surgical solution adopted to cover the wounds due to open fractures. Despite this procedure presents many clinical advantages, relatively poor information is available about the loss of functionality of triceps surae of the treated leg. In this study, a group of patients who underwent a soleus muscle flap surgical procedure has been analyzed through the heel rise test (HRT), in order to explore the triceps surae residual functionalities. A frequency band analysis was performed in order to assess whether the residual heads of triceps surae exhibit different characteristics with respect to both the non-treated lower limb and an age-matched control group. Then, an in-depth analysis based on a machine learning approach was proposed for discriminating between groups by generalizing across new unseen subjects. Experimental results showed the reliability of the proposed analyses for discriminating between-group at a specific time epoch and the high interpretability of the proposed machine learning algorithm allowed the temporal localization of the most discriminative frequency bands. Findings of this study highlighted that significant differences can be recognized in the myoelectric spectral characteristics between the treated and contralateral leg in patients who underwent soleus flap surgery. These experimental results may support the clinical decision-making for assessing triceps surae performance and for supporting the choice of treatment in plastic and reconstructive surgery.","Heel rise test,Frequency band analysis,Soleus flap procedure,EMG,Machine learning,Support vector machine,Lasso",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"SOLEUS,MUSCLE-FLAP,DONOR-SITE,MORBIDITY,GASTROCNEMIUS,FATIGUE,ELECTROMYOGRAPHY,POWER,SELECTION,SPECTRUM,TORQUE,MODEL",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
49,Machine learning regression based group contribution method for cetane and octane numbers prediction of pure fuel compounds and mixtures,280,,,"Li Runzhao,Herreros Jose Martin,Tsolakis Athanasios,Yang Wenzhao","Li RZ,Herreros JM,Tsolakis A,Yang WZ",Tsolakis A,10.1016/j.fuel.2020.118589,University of Birmingham,"Current methods to predict fuel ignition quality usually focus on either cetane numbers or research/motor octane numbers (CN, RON, MON) and most of them apply to pure compounds. A machine learning regression based group contribution method (GCM) is proposed to simultaneously predict CN, RON and MON of pure fuel compounds and mixtures. The GCM extracts the structural features of fuel molecules to build a molecular structure matrix. Then a mathematical model developed by machine learning correlates the molecular structure matrix with ignition quality (CN, RON, MON) matrix. A comprehensive fuel ignition quality database is built for model training which contains 603, 374, 371 compounds for CN, RON and MON respectively. High predictive precision is obtained for CN, RON, MON (R-2 equal to 0.9911, 0.9874, 0.9731) being superior to those obtained by neural network. The method is successfully applied to a wide range of compounds including alkanes, alkenes, alkynes, cycloalkanes, cycloalkenes, aromatics, alcohols, aldehydes/ketones, ethers, esters, acids, furans and fuel mixtures. Three key factors contribute to the high predictive capacity: (i) GCM considers the structural features, functional group interaction and fuel reactivity of fuel molecules; (ii) the built-in machine learning algorithm automatically optimizes the model function and parameters and (iii) the fuel ignition quality database provides adequate model training data for different fuel types. This method provides an effective tool to obtain CN, RON and MON of pure compounds and mixtures and a fundamental understanding of the impact of fuel molecular structures on the ignition quality.","Fuel molecular structure,Group contribution method,CN/RON/MON prediction,Pure fuel compounds & mixtures",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Energy & Fuels,Engineering",,6.63,"NEURAL-NETWORK,PREDICTION,N-HEPTANE,HYDROCARBONS,SURROGATE,GASOLINE,COMBUSTION,SPECTROSCOPY,ISOOCTANE,COMPONENT,TOLUENE",FUEL,http://pure-oai.bham.ac.uk/ws/files/107367021/MachineLearning_Manuscript_clean_version.pdf,
50,A deep transfer learning model for inclusion defect detection of aeronautics composite materials,252,,,"Gong Yanfeng,Shao Hongliang,Luo Jun,Li Zhixue","Gong YF,Shao HL,Luo J,Li ZX",Luo J,10.1016/j.compstruct.2020.112681,Chongqing University,"Composite materials are increasingly used as structural components in military and civilian aircraft. To ensure their high reliability, numerous non-destructive testing (NDT) techniques have been used to detect defects during production and maintenance. However, most of these techniques are non-automatic, with diagnostic results determined subjectively by operators. Some deep learning methods have been proposed to identify defects in images obtained through NDT, but they need labeled image samples with defects, which can be expensive or unavailable. We propose a deep transfer learning model to accurately extract features for the inclusion of defects in X-ray images of aeronautics composite materials (ACM), whose samples are scarce. We researched an automatic inclusion defect detection method for X-ray images of ACM using our proposed model. Experimental results show that the model can reach 96% classification accuracy (F1 measure) with satisfactory detection results.","Inclusion defect detection,Aeronautics composite materials,Transfer learning,Feature extraction",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Mechanics,Materials Science",,5.536,"DAMAGE,IDENTIFICATION",COMPOSITE STRUCTURES,,
51,Window of deposition description and prediction of deposition efficiency via machine learning techniques in cold spraying,401,,,"Canales H.,Cano I. G.,Dosta S.","Canales H,Cano IG,Dosta S",Dosta S,10.1016/j.surfcoat.2020.126143,University of Barcelona,"In this work we describe an energy-based window of deposition, and predict the deposition efficiency for different cold-sprayed powder/substrate systems, using machine learning techniques. We implement several machine learning models to predict whether particles adhere or bounce off during cold spraying. The models are trained using data extracted from several experimental runs taking into account the cumulative particle size distribution and the deposition efficiency of the process. The classification models infer a critical total energy threshold above which deposition occurs. Based on this threshold, we describe an energy-based window of deposition for the powder/substrate systems studied. These models predict the deposition efficiency of different spraying operations for different powder materials with acceptable accuracy. Machine learning techniques provide better understanding of the particle deposition process and enable a more comprehensive exploration of the scope of cold spraying. The use of these techniques opens up new possibilities for the pursuit of links between the spraying process, the structure and different properties for novel cold-sprayed materials.","Cold spray,Machine learning,Cooper,Aluminum,Deposition efficiency",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Materials Science,Physics",,3.958,"PARTICLE-VELOCITY,MECHANISM",SURFACE & COATINGS TECHNOLOGY,,
52,Machine learning in materials genome initiative: A review,57,,113-122,"Liu Yingli,Niu Chen,Wang Zhuo,Gan Yong,Zhu Yan,Sun Shuhong,Shen Tao","Liu YL,Niu C,Wang Z,Gan Y,Zhu Y,Sun SH,Shen T",Shen T,10.1016/j.jmst.2020.01.067,Kunming University of Science & Technology,"Discovering new materials with excellent performance is a hot issue in the materials genome initiative. Traditional experiments and calculations often waste large amounts of time and money and are also limited by various conditions. Therefore, it is imperative to develop a new method to accelerate the discovery and design of new materials. In recent years, material discovery and design methods using machine learning have attracted much attention from material experts and have made some progress. This review first outlines available materials database and material data analytics tools and then elaborates on the machine learning algorithms used in materials science. Next, the field of application of machine learning in materials science is summarized, focusing on the aspects of structure determination, performance prediction, fingerprint prediction, and new material discovery. Finally, the review points out the problems of data and machine learning in materials science and points to future research. Using machine learning algorithms, the authors hope to achieve amazing results in material discovery and design. (C) 2020 Published by Elsevier Ltd on behalf of The editorial office of Journal of Materials Science & Technology.","Materials genome initiative (MGI),Materials database,Machine learning,Materials properties prediction,Materials design and discovery",Review,"JOURNAL MATER SCI TECHNOL, 72 WENHUA RD, SHENYANG 110015, PEOPLES R CHINA","Materials Science,Metallurgy & Metallurgical Engineering",,6.841,"ARTIFICIAL,NEURAL-NETWORK,MECHANICAL-PROPERTIES,MATERIALS,DISCOVERY,DATA,SCIENCE,DESIGN,PREDICTION,INFORMATICS,COMPOSITES,INFRASTRUCTURE,SIMULATION",JOURNAL OF MATERIALS SCIENCE & TECHNOLOGY,,
53,A neural network enhanced system for learning nonlinear constitutive law and failure initiation criterion of composites using indirectly measurable data,252,,,"Liu Xin,Tao Fei,Yu Wenbin","Liu X,Tao F,Yu WB",Liu X,10.1016/j.compstruct.2020.112658,Purdue University System,"A neural network enhanced system containing a subsystem with one or multiple neural networks is proposed. Instead of defining the loss function as the direct output of a neural network model, the proposed method uses the system output, which can be measured from experiments, to define the loss function. The loss function is contributed by the outputs from one or multiple neural network models through a subsystem. As a result, the direct output of the ANN model is not required to be measurable from experiments. A set of new back-propagation equations have been derived for this system. Two examples are given using the proposed system: learning the nonlinear in-plane shear constitutive law and learning the failure initiation criterion of fiber-reinforced composites (FRC). The neural network models in both examples are trained at the lamina level using the measurable experimental responses of laminates. The results obtained from the learned neural network models agree well with the corresponding analytical solutions. The proposed method can be used to train neural network models in a subsystem when only the input and output of the system is measurable.","Neural network model,Fiber-reinforced composites,Indirectly measurable data,Nonlinear in-plane shear constitutive law,Failure initiation criterion",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Mechanics,Materials Science",,5.536,"MODEL,HOMOGENIZATION,MECHANICS",COMPOSITE STRUCTURES,,
54,Additive manufacturing in drug delivery applications: A review,589,,,"Reddy R. Durga Prasad,Sharma Varun","Reddy RDP,Sharma V",Sharma V,10.1016/j.ijpharm.2020.119820,Indian Institute of Technology System (IIT System),"The traditional healthcare method follows 'one-size-fits-all' criteria, which shows some limitations in rendering proper results due to varied pharmacokinetic traits of different patients. Each patient shows a different result to a set of prescribed medicines with respect to other patient. In addition, this empirical criterion is also vulnerable to develop unfavourable side-effects due to overdose or under-dose. The advancements in the field of pharmacogenetic testing has paved the way for searching solutions to achieve the goal of 'personalized medicine'. This concept has the potential to provide more effective results as compared to the traditional technique. The technology of additive manufacturing or 3D printing can cater the need of the patient-centric principle. A wide range of 3D printing techniques provide the independence to work with a number of bio-materials. This paper carries out a systematic review methodology based on the application of this novel technology in the field of drug delivery. The materials, methods of drug administration, techniques used for printing have been elaborated along with the manufacturing of polypills with varied release profiles and geometries. Certain in vivo studies has also been reported to assess the feasibility of this technology. The concept of 4D printing in this direction has also been discussed. Finally, some excerpts on estimated future scope have also been illustrated.","3D printing,Additive manufacturing techniques,Personalized medicine,Biomaterials,Drug delivery system,4D printing",Review,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Pharmacology & Pharmacy,,5.423,"ORAL,DOSAGE,FORMS,DEPOSITION,MODELING,FDM,PRINTED,MEDICAL,DEVICES,SURFACE,MODIFICATION,COMPOSITE,SCAFFOLDS,PHARMACEUTICAL,EXCIPIENTS,RELEASE,CHARACTERISTICS,BIOCERAMIC,SCAFFOLDS,IMMOBILIZED,SILVER,BONE,REGENERATION",INTERNATIONAL JOURNAL OF PHARMACEUTICS,,
55,Machine Learning and Improved Quality Metrics in Acute Intracranial Hemorrhage by Noncontrast Computed Tomography.,,,,",,,,","Davis Melissa A,Rao Balaji,Cedeno Paul A,Saha Atin,Zohrabian Vahe M",,10.1067/j.cpradiol.2020.10.007,,"MATERIALS AND METHODS: An ML algorithm was incorporated across CT scanners at imaging sites in January 2018. RTAT and LOS were derived for reports and patients between July 2017 and December 2017 prior to implementation of ML and compared to those between January 2018 and June 2018 after implementation of ML. A total of 25,658 and 24,996 ED and inpatient cases were evaluated across the entire healthcare system before and after ML, respectively.RESULTS: RTAT decreased from 75 to 69 minutes (P <0.001) at all facilities in the healthcare system. At the level 1 trauma center specifically, RTAT decreased from 67 to 59 minutes (P <0.001). ED LOS decreased from 471 to 425 minutes (P <0.001) for patients without ICH, and from 527 to 491 minutes for those with ICH (P = 0.456). Inpatient LOS decreased from 18.4 to 15.8 days for those without ICH (P = 0.001) and 18.1 to 15.8 days for those with ICH (P = 0.02).CONCLUSION: We demonstrated that utilization of ML was associated with a statistically significant decrease in RTAT. There was also a significant decrease in LOS for ED patients without ICH, but not for ED patients with ICH. Further evaluation of the impact of such tools on patient care and outcomes is needed. Copyright © 2020 Elsevier Inc. All rights reserved.",,Journal Article; Review,,,,,,,,
56,A Millimetre-Wave Radar-Based Fall Detection Method Using Line Kernel Convolutional Neural Network,20,22,13364-13370,"Wang Bo,Guo Liang,Zhang Hao,Guo Yong-Xin","Wang B,Guo L,Zhang H,Guo YX",Guo YX,10.1109/JSEN.2020.3006918,National University of Singapore,"Fall accidents are significant threats to the health and life of older people. When a millimetre-wave (mmWave) frequency modulated continuous wave (FMCW) radar is used for fall detection, the selected features for further classification can determine the detection performance. In this paper, a line kernel convolutional neural network (LKCNN) is proposed to process the baseband data directly to detect fall motions. This method utilizes the characteristic of a convolutional neural network (CNN) that it can learn to extract useful features during the training process. A data sample generation method is also proposed to generate multiple samples for the training process by utilizing the multiple receiving channels and sufficiently small pulse repetition time (PRT). The experiment results show that the proposed method can detect fall motions with high accuracy, sensitivity and specificity with fewer network parameters and less computation cost, which is meaningful in realizing an all-time indoor fall detection system.","Radar,Baseband,Chirp,Feature extraction,Sensors,Radar antennas,Convolutional neural network,line convolution kernel,millimetre-wave radar,data sample generation,fall detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,,IEEE SENSORS JOURNAL,,
57,Comprehensive Monitoring of Bad Head and Shoulder Postures by Wearable Magnetic Sensors and Deep Learning,20,22,13768-13775,"Jang Hyeong Kyu,Han Hobeom,Yoon Sang Won","Jang HK,Han H,Yoon SW",Yoon SW,10.1109/JSEN.2020.3004562,Hanyang University,"In this work, a simultaneous monitoring method for bad posture, including the forward head posture (FHP), rounded shoulder (RS), and elevated shoulder (ES), is proposed. These postures and the resulting symptoms are becoming increasingly prevalent, and a comprehensive, simultaneous, and extensive analysis of such posture disorders is needed. The proposed method involves collecting posture data from a new combination of accelerometers and magnetometers paired with miniature magnets. The sensor locations are optimally chosen to reliably calculate neck and shoulder angles representing the craniovertebral angle (CVA) for FHP, forward shoulder angle (FSA) for RS, and symmetry angle (SA) for ES. Processing of the collected sensor data is achieved by deep neural network (DNN) and convolutional neural network (CNN) algorithms. Experimental results demonstrate successful bad posture classification with high accuracy (DNN: 88.1%, CNN: 88.7%) even with the simultaneous analysis of FHP, RS, and ES.","Magnetometers,Magnetic sensors,Monitoring,Accelerometers,Neck,Deep learning,Magnet-magnetometer pair,comprehensive monitoring,postural diseases,deep neural netwTRork",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"HUMAN,ACTIVITY,RECOGNITION,WALKING,MODES",IEEE SENSORS JOURNAL,,
58,Improved subspace clustering algorithm using multi-objective framework and subspace optimization,158,,,"Paul Dipanjyoti,Saha Sriparna,Mathew Jimson","Paul D,Saha S,Mathew J",Paul D,10.1016/j.eswa.2020.113487,Indian Institute of Technology (IIT) - Patna,"Subspace clustering technique divides the data set into different groups or clusters where each cluster comprises of objects that share some similar properties. Again, the feature sets or the subspace features that are used to represent clusters are different for different clusters. Moreover, in subspace clustering, the grouping of similar objects and the subspace feature set representing that group are identified simultaneously. In evolutionary-based machine learning problems, two critical measures to determine the quality of the generated clusters are compactness within and separation between the clusters. However, the distance-based separation between two clusters may not be useful in the context of subspace clustering, as the clusters may belong to two different subspaces. Again, in the case of subspace clustering, the selection of relevant subspace features plays a primary role in generating good quality subspace clusters. Therefore, the proposed approach optimizes the subspace features by considering two new objective functions, feature non-redundancy (FNR) and feature per cluster (FPC) represented in the form of PSMindex. Another objective function, intra-cluster compactness (ICC-index), is modified and used to optimize the compactness among objects within the cluster. Finally, an evolutionary-based multi-objective subspace clustering technique is developed in this paper optimizing these validity indices. A new mutation operator, namely duplication and deletion along with the modified version of the exogenous genetic material uptake, are developed to explore the search space effectively. The developed algorithm is tested on sixteen synthetic data sets and seven standard real-life data sets for identifying different subspace clusters. Again, to show the effectiveness of using multiple objectives, the algorithm is also tested on three big data sets and a MNIST data set. Also, an application of the proposed method is shown in biclustering the gene expression data. The results obtained by the proposed algorithm are compared against some state-of-the-art methods. Experimentation reveals that the proposed algorithm can take advantage of its evolvable genomic structure and the newly defined objective functions on the multi objective based framework. (c) 2020 Elsevier Ltd. All rights reserved.","Subspace clustering,Multi-objective Optimization (MOO),Intra-Cluster Compactness (ICC),Feature Non-Redundancy (FNR),Feature Per Cluster (FPC)",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,,EXPERT SYSTEMS WITH APPLICATIONS,,
59,Advancement of the search process for digital heritage by utilizing artificial intelligence algorithms,158,,,"Gasimova Rena T.,Abbasli Rahim N.","Gasimova RT,Abbasli RN",Abbasli RN,10.1016/j.eswa.2020.113559,"Canada ThinkingCapital, 1300-130 Adelaide Str W, Toronto, ON M5H 3P5, Canada.","The increasing amount of pressure to digitalize what we are used to consider a conventional data has created a need to analyze, search and process unique data structures in a timely manner. The progressive world has created a justified need not only for a fast query searches but also the most related and meaningful searches with a minimal guidance. This article explores the potential benefits of using unorthodox solutions, including Artificial Intelligence algorithms in processing big data that are unconventional data structures. One of such big data sources was created as part of digitalization of historic heritage materials, documents and artifacts. The article calls out the benefits and disadvantages of some Artificial Intelligence algorithms and explores ways to use a few of those algorithms for the purposes of the digital heritage. It also offers the solution to maximize the potential of the search engine that could be built for digital heritage or any other unstructured data. (C) 2020 Elsevier Ltd. All rights reserved.","Big data analytics,Digital heritage,Search engine,Machine learning,Neural network,Neural foresting",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering,Operations Research & Management Science",,6.789,CONVERGENCE,EXPERT SYSTEMS WITH APPLICATIONS,,
60,Applications of machine learning in metal-organic frameworks,423,,,"Chong Sanggyu,Lee Sangwon,Kim Baekjun,Kim Jihan","Chong S,Lee S,Kim B,Kim J",Kim J,10.1016/j.ccr.2020.213487,Korea Advanced Institute of Science & Technology (KAIST),"Machine learning (ML) is the field of computer science where computing systems are trained to perform an analysis of provided data to reveal previously unseen trends and patterns that allow accurate predictions. ML methods have drastically transformed the way scientific research is conducted, making significant contributions in a variety of research fields ranging from natural language processing to drug discovery and materials design. With an abundance of discovered structures and their performance data for various application fields, metal-organic frameworks (MOFs) would undoubtedly benefit from the integration of ML methods for their design and development. In this review, we provide a complete overview of how ML methods can be effectively utilized for MOF research. Various descriptors and representations of MOFs suitable for the ML workflow are first discussed. Then, recent research progresses in which novel ML methods are used to predict various material properties or even design new MOF structures are presented. As many more MOFs are discovered and utilized for various applications, ML will play a much bigger role in their research and development. As such, this review aims to provide readers with basic insights required to comprehend ML-based MOF research, and to help conduct those of their own in the future. (C) 2020 Elsevier B.V. All rights reserved.","Metal-organic framework,Machine learning,Computational screening,Property prediction,Materials design",Review,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND",Chemistry,,18.414,"METHANE,STORAGE,GAS-ADSORPTION,CO2,CAPTURE,ELECTRICAL-CONDUCTIVITY,MOLECULAR,SIMULATION,LIGAND,INSERTION,HYDROGEN,STORAGE,DESIGN,PREDICTION,DESCRIPTORS",COORDINATION CHEMISTRY REVIEWS,,
61,Thyroid nodules risk stratification through deep learning based on ultrasound images,47,12,6355-6365,"Bai Ziyu,Chang Luchen,Yu Ruiguo,Li Xuewei,Wei Xi,Yu Mei,Liu Zhiqiang,Gao Jie,Zhu Jialin,Zhang Yulin","Bai ZY,Chang LC,Yu RG,Li XW,Wei X,Yu M,Liu ZQ,Gao J,Zhu JL,Zhang YL",Li XW,10.1002/mp.14543,Tianjin University,"Purpose Clinically, the risk stratification of thyroid nodules is usually used to formulate the next treatment plan. The American College of Radiology (ACR) thyroid imaging reporting and data system (TI-RADS) is a type of medical standard widely used in classification diagnosis. It divides the nodule's ACR TI-RADS level into five levels by quantitative scoring, from benign to high suspicion of malignancy. However, such assessment often relies on the radiologists' experience and is time consuming. So computer-aided diagnosis is necessary. But many deep learning (DL) models are difficult for doctors to understand, limiting their applicability in clinical practice. In this work, we mainly focus on how to achieve automatic thyroid nodules risk stratification based on deep integration of deep learning and clinical experience.
Methods An automatic hierarchical method of thyroid nodules risk based on deep learning is proposed, called risk stratification network (RS-Net). It incorporates medical experience based on ACR TI-RADS. The convolutional neural network (CNN) is used to classify the five categories in ACR TI-RADS and assign their points respectively. According to the point totals, the level of risk can be obtained. In addition, a dataset involving 13 984 thyroid ultrasound images is established to develop and evaluate the proposed method.
Results We have extensively compared the results of this paper with the evaluation results of sonographers. The accuracy of the risk stratification (TR1 to TR5) of the proposed method is 65%, and the mean absolute error (MAE) is 0.54. The MAE of the point totals (0 to 13 points) is 1.67. The Pearson's correlation between our method evaluation and doctor evaluation reached 0.84. For the benign and malignant classification, the performance indices accuracy, sensitivity, specificity, PPV, and NPV were 88.0%, 98.1%, 79.1%, 80.5%, and 97.9%, respectively. Our method's level of thyroid nodules risk stratification is comparable to that of a senior doctor.
Conclusions This work provides a way to automate the risk stratification of thyroid nodules. Our method can effectively avoid missed diagnosis and misdiagnosis caused by the difference of observers so as to assist doctors to improve efficiency and diagnosis rate. Compared with the previous benign and malignant classification, the proposed method incorporates clinical experience. So it can greatly increase the clinicians' trust in the DL model, thereby improving the applicability of the model in clinical practice.","deep learning,nodules risk stratification,thyroid ultrasound image",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"DIAGNOSIS,CLASSIFICATION,MANAGEMENT,FEATURES",MEDICAL PHYSICS,,
62,Empirical method for modeling crystal lattice parameters of A(2)XY(6) cubic crystals using grid search-based extreme learning machine,128,18,,"Ibn Shamsah Sami M.,Owolabi Taoreed O.","Ibn Shamsah SM,Owolabi TO",Owolabi TO,10.1063/5.0024595,"Adekunle Ajasin Univ, Phys & Elect Dept, Akungba Akoko 342111, Ondo State, Nigeria.","The lattice parameters of A(2)XY(6) (A=K, Cs, Rb, and Tl; X=tetravalent cation; Y=F, Cl, Br, and I) cubic crystals play significant roles in designing materials for specific technological applications and uniquely describe the material crystal structure. Despite the importance of its lattice parameters, the experimental determination of these parameters requires special sophisticated equipment, while the first principle calculation consumes appreciable time and might need complex software packages. The existing empirical relation in the literature is characterized by large percentage deviation, and the recently proposed machine learning support vector regression method cannot be empirically implemented on new compounds. This present work fills the research gap through the development of empirical relation between the lattice parameters, electronegativity and ionic radii of the constituting ions using extreme learning machine (ELM) with the grid search (GS) hyper-parameters optimization method. The proposed model is developed through the analysis of atomic structural properties of 85 crystals that serve as representatives of the A(2)XY(6) group. On the basis of a mean absolute percentage error, the developed GS-ELM model outperforms the existing Brik and Kityk [J. Phys. Chem. Solids 72(11), 1256-1260 (2011)] model with a percentage improvement of 58.37%, while it performs better than Alade et al. [J. Appl. Phys. 127(1), 15303 (2020)] model with the percentage enhancement of 37.90%. The outstanding performance of the proposed GS-ELM model coupled with its ease of implementation would be of great significance by enhancing the search for new materials tailored to targeted application and preventing lattice constant mismatch in thin film fabrication.","QUANTITATIVE-ANALYSIS,OPTIMIZATION,REGRESSION,TEMPERATURE,ALGORITHMS",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,"QUANTITATIVE-ANALYSIS,OPTIMIZATION,REGRESSION,TEMPERATURE,ALGORITHMS",JOURNAL OF APPLIED PHYSICS,,
63,Predictive modeling approaches in laser-based material processing,128,18,,"Velli Maria-Christina,Tsibidis George D.,Mimidis Alexandros,Skoulas Evangelos,Pantazis Yannis,Stratakis Emmanuel","Velli MC,Tsibidis GD,Mimidis A,Skoulas E,Pantazis Y,Stratakis E",Tsibidis GD; Stratakis E,10.1063/5.0018235,Foundation for Research & Technology - Hellas (FORTH),"Predictive modeling represents an emerging field that combines existing and novel methodologies aimed to rapidly understand physical mechanisms and concurrently develop new materials, processes, and structures. In the current study, previously unexplored predictive modeling in a key-enabled technology, the laser-based manufacturing, aims to automate and forecast the effect of laser processing on material structures. The focus is centered on the performance of representative statistical and machine learning algorithms in predicting the outcome of laser processing on a range of materials. Results on experimental data showed that predictive models were able to satisfactorily learn the mapping between the laser's input variables and the observed material structure. These results are further integrated with simulation data aiming to elucidate the multiscale physical processes upon laser-material interaction. As a consequence, we augmented the adjusted simulated data to the experiment and substantially improved the predictive performance due to the availability of an increased number of sampling points. In parallel, an information-theoretic metric, which identifies and quantifies the regions with high predictive uncertainty, is presented, revealing that high uncertainty occurs around the transition boundaries. Our results can set the basis for a systematic methodology toward reducing material design, testing, and production cost via the replacement of expensive trial-and-error based manufacturing procedures with a precise pre-fabrication predictive tool.","RIPPLE FORMATION,FEMTOSECOND,SELECTION",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,"RIPPLE,FORMATION,FEMTOSECOND,SELECTION",JOURNAL OF APPLIED PHYSICS,http://arxiv.org/pdf/2006.07686,
64,Automatic diagnosis of dental diseases using convolutional neural network and panoramic radiographic images,9,5,447-455,"Ghaznavi Bidgoli Seyyed Amirhossein,Sharifi Arash,Manthouri Mohammad","Bidgoli SAG,Sharifi A,Manthouri M",Sharifi A,10.1080/21681163.2020.1847200,Islamic Azad University,"People may experience tooth decay many times in a lifetime; however, its early diagnosis can greatly help accelerate the treatment process. Intelligent methods are now widely used in medicine, especially for diagnosis through panoramic radiographs. However, dental diseases have received little research focus due to the lack of a standard dataset. This study aimed to collect a standard dataset of panoramic radiographs of jaws and teeth. A deep neural network algorithm was then employed to classify teeth as healthy, decayed, root-canaled, and restored categories. The dataset was divided into five groups to analyse the proposed method in performance. Different evaluation criteria, confusion matrices, and precision percentages were determined for each group. On average, the final precision was 92% in the five groups. Moreover, the trained network results were compared with those of AlexNet and VGGNet16. Six months were spent collecting two new datasets labelled by experts. A smart method was also proposed to determine the dental location of jaws and reach dental diagnosis. According to the final results, the proposed network proved to be highly stable and managed to establish a better dental diagnosis.","Deep networks,dental diseases,convolutional neural network (CNN),decayed tooth,classification",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,,,COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION,,
65,Machine Learning Approaches for Municipal Solid Waste Generation Forecasting,38,6,489-499,Oguz-Ekim Pinar,Oguz-Ekim P,Oguz-Ekim P,10.1089/ees.2020.0232,Izmir Ekonomi Universitesi,"Municipal solid waste (MSW) generation forecasting can be considered as the biggest challenge of integrated solid waste management systems, particularly for developing countries where data collection is limited. In this study, three different machine learning algorithms, namely backpropagation neural network (BPNN), support vector regression (SVR), and general regression neural network, were applied for different countries. Comparative evaluation of these different algorithms based on gross domestic product, domestic material consumption, and resource productivity were given through the optimum solution. Moreover, the algorithms were tested for the case of Turkey. The results of this study are expected to represent a general outline for stakeholders of Turkey for improving MSW management strategies all over the country, and these results can be extended to similar developing countries across the world. It can be concluded that BPNN and SVR methods can be applied successfully for the case of Turkey and other countries across the world to predict the MSW generation, whereas BPNN is slightly better. If the input and output variables are identified well, machine learning approaches can give a good projection for waste generation, and this projection can be utilized for different countries. Furthermore, the developing countries with missing data can develop more realistic strategies for MSW management by not relying solely on international databases such as Eurostat to forecast MSW generation.","artificial neural networks,backpropagation neural network,general regression neural network,support vector regression,waste generation forecasting",Article,"MARY ANN LIEBERT, INC, 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA","Engineering,Environmental Sciences & Ecology",,2.104,"SUPPORT,VECTOR,MACHINE,NEURAL-NETWORKS,PREDICTION,MANAGEMENT",ENVIRONMENTAL ENGINEERING SCIENCE,,
66,Virtual Monoenergetic CT Imaging via Deep Learning,1,8,,"Cong Wenxiang,Xi Yan,Fitzgerald Paul,De Man Bruno,Wang Ge","Cong WX,Xi Y,Fitzgerald P,De Man B,Wang G",Wang G,10.1016/j.patter.2020.100128,Rensselaer Polytechnic Institute,"Conventional single-spectrum computed tomography (CT) reconstructs a spectrally integrated attenuation image and reveals tissues morphology without any information about the elemental composition of the tissues. Dual-energy CT (DECT) acquires two spectrally distinct datasets and reconstructs energy-selective (virtual monoenergetic [VM]) and material-selective (material decomposition) images. However, DECT increases system complexity and radiation dose compared with single-spectrum CT. In this paper, a deep learning approach is presented to produce VM images from single-spectrum CT images. Specifically, a modified residual neural network (ResNet) model is developed to map single-spectrum CT images to VM images at pre-specified energy levels. This network is trained on clinical DECT data and shows excellent convergence behavior and image accuracy compared with VM images produced by DECT. The trained model produces high-quality approximations of VM images with a relative error of less than 2%. This method enables multi-material decomposition into three tissue classes, with accuracy comparable with DECT.","DUAL-ENERGY CT,TOMOGRAPHY PHYSICAL PRINCIPLES,LOW-DOSE CT,COMPUTED-TOMOGRAPHY,ATTENUATION COEFFICIENTS,DECOMPOSITION,NETWORK,USAGE",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,,"DUAL-ENERGY,CT,TOMOGRAPHY,PHYSICAL,PRINCIPLES,LOW-DOSE,CT,COMPUTED-TOMOGRAPHY,ATTENUATION,COEFFICIENTS,DECOMPOSITION,NETWORK,USAGE",PATTERNS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7691386,
67,Chemical Robotics Enabled Exploration of Stability in Multicomponent Lead Halide Perovskites via Machine Learning,5,11,3426-3436,"Higgins Kate,Valleti Sai Mani,Ziatdinov Maxim,Kalinin Sergei V,Ahmadi Mahshid","Higgins K,Valleti SM,Ziatdinov M,Kalinin SV,Ahmadi M",Ahmadi M,10.1021/acsenergylett.0c01749,University of Tennessee System,"Metal halide perovskites have attracted immense interest as a promising material for a variety of optoelectronic and sensing applications. However, issues regarding long-term stability have emerged as the key bottleneck for commercialization. Here, we develop an automated experimental workflow based on combinatorial synthesis and rapid throughput characterization to explore long-term stability of these materials in ambient conditions. We apply it to four model perovskite systems: MA(x)FA(y)Cs(1-x-)(y)PbBr(3), MA(x)FA(y)Cs(1-x-)(y)PbI(3), Cs(x)FA(y)MA(1-x-y)Pb(Brx+yI1-x-y)(3), and Cs(x)MA(y)FA(1-x-y)Pb(Ix+yBr1-x-y)(3). Non-negative matrix factorization and Gaussian process regression are used to interpolate the photoluminescent behavior of the phase diagram. This interpolative regression analysis helps to distinguish mixtures that form solid solutions from those that segregate into multiple materials, pointing out the most stable regions of the phase diagram. We find stability dependence on composition to be nonuniform within the composition space, suggesting the presence of potential preferential compositional regions. This proposed workflow is universal and can be applied to other solution-processable materials.",,Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Electrochemistry,Energy & Fuels,Science & Technology - Other Topics,Materials Science",,22.423,,ACS ENERGY LETTERS,,
68,The Future of Memristors: Materials Engineering and Neural Networks,31,8,,"Sun Kaixuan,Chen Jingsheng,Yan Xiaobing","Sun KX,Chen JS,Yan XB",Yan XB,10.1002/adfm.202006773,Hebei University,"From Deep Blue to AlphaGo, artificial intelligence and machine learning are booming, and neural networks have become the hot research direction. However, due to the size limit of complementary metal-oxide-semiconductor (CMOS) transistors, von Neumann-based computing systems are facing multiple challenges (such as memory walls). As the number of transistors required by the neural network increases, the development of neural networks based on the von Neumann computer is limited by volume and energy consumption. As the fourth basic circuit element, memristor shines in the field of neuromorphic computing. The new computer architecture based on memristor is widely considered as a substitute for the von Neumann architecture and has great potential to deal with the neural network and big data era challenge. This article reviews existing materials and structures of memristors, neurophysiological simulations based on memristors, and applications of memristor-based neural networks. The feasibility and advancement of implementing neural networks using memristors are discussed, the difficulties that need to be overcome at this stage are put forward, and their development prospects and challenges faced are also discussed.","artificial synapses,memristor,neural networks,neuromorphic calculations,resistive switching mechanism",Review,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,18.125,"RESISTIVE,SWITCHING,MEMORY,PHASE-CHANGE,MATERIALS,FUNCTIONALIZED,GRAPHENE,PATTERN-CLASSIFICATION,DEPENDENT,PLASTICITY,SYNAPTIC,PLASTICITY,ARTIFICIAL,SYNAPSES,TERM-MEMORY,OXIDE,DEVICES",ADVANCED FUNCTIONAL MATERIALS,,
69,Update on coronary CT-more than just anatomical imaging? Current guidelines and functional CT techniques for the quantification of stenoses,60,12,1131-1141,"Soschynski Martin,Taron Jana,Schlett Christopher L.,Bamberg Fabian,Krauss Tobias","Soschynski M,Taron J,Schlett CL,Bamberg F,Krauss T",Soschynski M,10.1007/s00117-020-00767-2,University of Freiburg,"Background Coronary CT angiography (cCTA) has a high negative predictive value for ruling out significant coronary stenoses. However, it is limited in determining hemodynamic significance of a stenosis and hence to prove the indication for therapy. Objectives When and how is cCTA used according to current guidelines? Which functional CT techniques are available to test for hemodynamic significance of coronary stenoses? Materials and methods The value of cCTA is explained on the basis of current guidelines by the European Society of Cardiology (ESC) for the diagnosis of chronic coronary syndromes. Functional CT techniques which test for hemodynamic significance of coronary stenoses are myocardial CT-perfusion (CT-P) and CT-based fractional flow reserve (CT-FFR). Results The new ESC guidelines classify cCTA as a class 1 recommendation for diagnosing coronary artery disease in symptomatic patients with low clinical likelihood. If clinical likelihood is high or an at least moderate stenosis is detected with cCTA, noninvasive functional (stress) imaging is preferred. There is a large body of evidence for CT-P and CT-FFR as functional tests. Conclusion In the current guidelines, cCTA is highly recommended for the diagnosis of coronary artery disease. The functional CT techniques CT-P and CT-FFR have shown high diagnostic accuracy for myocardial ischemia of coronary stenoses in many clinical studies. However, these methods are not part of current guidelines yet and clinical adoption is still low.","Coronary artery disease,Myocardial CT perfusion,Fractional flow reserve,Machine learning,Evidence",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Radiology, Nuclear Medicine & Medical Imaging",,0.526,"COMPUTED-TOMOGRAPHY,HEART-DISEASE,TASK-FORCE,CARDIOLOGY,SOCIETY,ANGIOGRAPHY,ASSOCIATION,RADIOLOGY",RADIOLOGE,,
70,Modelling burning thermonuclear plasma,378,2184,,"Rose S. J.,Hatfield P. W.,Scott R. H. H.","Rose SJ,Hatfield PW,Scott RHH",Rose SJ,10.1098/rsta.2020.0014,Imperial College London,"Considerable progress towards the achievement of thermonuclear burn using inertial confinement fusion has been achieved at the National Ignition Facility in the USA in the last few years. Other drivers, such as the Z-machine at Sandia, are also making progress towards this goal. A burning thermonuclear plasma would provide a unique and extreme plasma environment; in this paper we discuss (a) different theoretical challenges involved in modelling burning plasmas not currently considered, (b) the use of novel machine learning-based methods that might help large facilities reach ignition, and (c) the connections that a burning plasma might have to fundamental physics, including quantum electrodynamics studies, and the replication and exploration of conditions that last occurred in the first few minutes after the Big Bang. This article is part of a discussion meeting issue 'Prospects for high gain inertial fusion energy (part 1)'.","fusion,plasma,machine learning",Article,"ROYAL SOC, 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND",Science & Technology - Other Topics,,4.542,FUSION,PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES,http://purl.org/net/epubs/manifestation/47775685/STFC-AAM-2020-057.pdf,
71,Toward Learning Machines at a Mother and Baby Unit,11,,,"Boman Magnus,Downs Johnny,Karali Abubakrelsedik,Pawlby Susan","Boman M,Downs J,Karali A,Pawlby S",Boman M,10.3389/fpsyg.2020.567310,Royal Institute of Technology,"Agnostic analyses of unique video material from a Mother and Baby Unit were carried out to investigate the usefulness of such analyses to the unit. The goal was to improve outcomes: the health of mothers and their babies. The method was to implement a learning machine that becomes more useful over time and over task. A feasible set-up is here described, with the purpose of producing intelligible and useful results to healthcare professionals at the unit by means of a vision processing pipeline, grouped together with multi-modal capabilities of handling annotations and audio. Algorithmic bias turned out to be an obstacle that could only partly be handled by modern pipelines for automated feature analysis. The professional use of complex quantitative scoring for various mental health-related assessments further complicated the automation of laborious tasks. Activities during the MBU stay had previously been shown to decrease psychiatric symptoms across diagnostic groups. The implementation and first set of experiments on a learning machine for the unit produced the first steps toward explaining why this is so, in turn enabling decision support to staff about what to do more and what to do less of.","learning machine,machine learning,multi-modal learning,mental health,maternal unresponsiveness,mind-mindedness",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Psychology,,3.618,"FACIAL,EXPRESSION,RECOGNITION,HEALTH",FRONTIERS IN PSYCHOLOGY,https://kclpure.kcl.ac.uk/ws/files/140710952/fpsyg_11_567310.pdf,
72,,,,,,,,,,,,,,,,,,,,
73,,,,,,,,,,,,,,,,,,,,
74,,,,,,,,,,,,,,,,,,,,
75,An Efficient Deep Learning Scheme To Predict the Electronic Structure of Materials and Molecules: The Example of Graphene-Derived Allotropes,124,45,9496-9502,"del Rio Beatriz G.,Kuenneth Christopher,Huan Doan Tran,Ramprasad Rampi","del Rio BG,Kuenneth C,Tran HD,Ramprasad R",Ramprasad R,10.1021/acs.jpca.0c07458,University System of Georgia,"Computations based on density functional theory (DFT) are transforming various aspects of materials research and discovery. However, the effort required to solve the central equation of DFT, namely the Kohn-Sham equation, which remains a major obstacle for studying large systems with hundreds of atoms in a practical amount of time with routine computational resources. Here, we propose a deep learning architecture that systematically learns the input-output behavior of the Kohn-Sham equation and predicts the electronic density of states, a primary output of DFT calculations, with unprecedented speed and chemical accuracy. The algorithm also adapts and progressively improves in predictive power and versatility as it is exposed to new diverse atomic configurations. We demonstrate this capability for a diverse set of carbon allotropes spanning a large configurational and phase space. The electronic density of states, along with the electronic charge density, may be used downstream to predict a variety of materials properties, bypassing the Kohn-Sham equation, leading to an ultrafast and high-fidelity DFT emulator.","TOTAL-ENERGY CALCULATIONS,DENSITY,LITHIUM,DESIGN",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Physics",,2.725,"TOTAL-ENERGY,CALCULATIONS,DENSITY,LITHIUM,DESIGN",JOURNAL OF PHYSICAL CHEMISTRY A,,
76,Use of remote sensing to track postindustrial vegetation development,32,3,1426-1439,"Wozniak Gabriela,Dyderski Marcin K.,Kompala-Baba Agnieszka,Jagodzinski Andrzej M.,Pasierbinski Andrzej,Blonska Agnieszka,Bierza Wojciech,Magurno Franco,Sierka Edyta","Wozniak G,Dyderski MK,Kompala-Baba A,Jagodzinski AM,Pasierbinski A,Blonska A,Bierza W,Magurno F,Sierka E",Blonska A,10.1002/ldr.3789,University of Silesia in Katowice,"The effects of natural processes on deposited mineral material of postindustrial sites is underestimated. Natural vegetation development on mineral material substratum is an unappreciated way of site management. Due to the classification-based approach to assembly of plant community diversity, remote sensing methods have limited application. We aimed to assess whether remotely sensed data allow for building predictive models, able to recognise vegetation variability along the main gradients of species composition. We assessed vegetation in 321 study plots on four coal-mine spoil heaps in Silesia (S Poland). We determined the main gradients of species composition using detrended correspondence analysis (DCA), and we identified how DCA scores describe vegetation variability. DCA axes explained 38.5%, 35.4%, 31.4%, and 20.1% of species composition variability. We built machine learning models of DCA scores using multispectral satellite images and airborne laser scanning data as predictors. We obtained good predictive power of models for the first two DCA axes (R-2 = 0.393 and 0.443, root mean square errors, RMSE = 0.571 and 0.526) and low power for the third and fourth DCA axes (R-2 = 0.216 and 0.064, RMSE = 0.513 and 0.361). These scores allowed us to prepare a vegetation map based on DCA scores, and distinguish meadow-like from forest-edge-like vegetation, and to identify thermophilous and highly productive vegetation patches. Our approach allowed us to account for species composition gradients, which improved remote sensing-based vegetation surveys. This method may be used for planning future management.","coal mine,digital elevation model,ordination,random forest,vegetation continuum,WORLDVIEW&#8208,2",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Environmental Sciences & Ecology,Agriculture",,5.291,"PLANT,FUNCTIONAL,TYPES,SPONTANEOUS,SUCCESSION,SPECIES,COMPOSITION,SPOIL,HEAPS,BIOMASS,LAYER,LEAF,SPECTROSCOPY,REFLECTANCE,COMMUNITIES",LAND DEGRADATION & DEVELOPMENT,,
77,Thermodynamic g(E) Models and Equations of State for Electrolytes in a Water-Poor Medium: A Review,65,11,5073-5082,Held Christoph,Held C,Held C,10.1021/acs.jced.0c00812,Dortmund University of Technology,"Research on the thermodynamics of electrolytes is timeless, and modeling an electrolyte solution might be considered to be a golden oldie, which was, is, and will be important in the design of processes and new materials in the future. The reason is that electrolytes play important roles in different scientific disciplines, such as material development, technical processes (chemical industry, biotechnology, and pharma and food industries), and most recently the energy sector. Closely connected is the further development of advanced thermodynamic models. The age of digitalization requires robust physical models as the basis for static and dynamic process modeling, and that will provide the basis for surrogate approaches in future machine learning developments. This all brings thermodynamic modeling to a consideration of its most important feature. There are many thermodynamic approaches which have been developed to correlate, model, and predict the properties and phase behavior of electrolytes. Usually, this has been very successful for aqueous electrolyte solutions. However, for solutions with poor water content, electrolyte modeling is challenging. This mini-review summarizes the recent advance of thermodynamic models for electrolyte solutions in a water-poor medium and suggests the required theoretical framework.",,Review,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Thermodynamics,Chemistry,Engineering",,2.685,,JOURNAL OF CHEMICAL AND ENGINEERING DATA,,
78,Weakly supervised retinal vessel segmentation algorithm without groundtruth,56,23,1235-+,"Lu Zheng,Chen Dali,Xue Dingyu","Lu Z,Chen DL,Xue DY",Chen DL,10.1049/el.2020.1893,Northeastern University - China,"In the current image processing field, medical image segmentation needs a lot of groundtruths, and the process of making these groundtruths is time-consuming and laborious. Thus, a novel retinal vessel segmentation algorithm without groundtruth is proposed in this Letter. The hierarchical clustering algorithm is first used to binary classify vessel and non-vessel pixels. Then classification results based on DRIVE databases are used as pseudo groundtruths to train the neural networks and transfer learning is considered for subsequent processing. Next the trained network is used as the feature extraction tool, by calculating and comparing the difference of image features between the target domain data (DRIVE database) and the source domain data (STARE, CHASE DB1, and HRF databases) extracted from the network. The data required for training is expanded based on semi-supervised clustering in this image feature space, finally the deep neural network is further fine-tuned. Experiments on the publicly available fundus image dataset DRIVE demonstrate that the proposed method outperforms many other state-of-the-art weakly supervised and unsupervised methods.","BLOOD-VESSELS,IMAGES",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND",Engineering,,1.261,"BLOOD-VESSELS,IMAGES",ELECTRONICS LETTERS,,
79,Lateral confinement of high-impedance surface-waves through reinforcement learning,56,23,1262-+,"Morocho-Cayamcela M. E.,Lim W.","Morocho-Cayamcela ME,Lim W",Lim W,10.1049/el.2020.1977,Kumoh National University Technology,"The authors present a model-free policy-based reinforcement learning model that introduces perturbations on the pattern of a metasurface. The objective is to learn a policy that changes the size of the patches, and therefore the impedance in the sides of an artificially structured material. The proposed iterative model assigns the highest reward when the patch sizes allow the transmission along a constrained path and penalties when the patch sizes make the surface wave radiate to the sides of the metamaterial. After convergence, the proposed model learns an optimal patch pattern that achieves lateral confinement along the metasurface. Simulation results show that the proposed learned-pattern can effectively guide the electromagnetic wave through a metasurface, maintaining its instantaneous eigenstate when the homogeneity is perturbed. Moreover, the pattern learned to prevent reflections by changing the patch sizes adiabatically. The reflection coefficient S-1,S- 2 shows that most of the power gets transferred from the source to the destination with the proposed design.",,Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND",Engineering,,1.261,,ELECTRONICS LETTERS,,
80,,,,,,,,,,,,,,,,,,,,
81,The joint automated repository for various integrated simulations (JARVIS) for data-driven materials design,6,1,,"Choudhary Kamal,Garrity Kevin F.,Reid Andrew C. E.,DeCost Brian,Biacchi Adam J.,Hight Walker Angela R.,Trautt Zachary,Hattrick-Simpers Jason,Kusne A. Gilad,Centrone Andrea","Choudhary K,Garrity KF,Reid ACE,DeCost B,Biacchi AJ,Walker AHR,Trautt Z,Hattrick-Simpers J,Kusne AG,Centrone A",Choudhary K,10.1038/s41524-020-00440-1,National Institute of Standards & Technology (NIST) - USA,"The Joint Automated Repository for Various Integrated Simulations (JARVIS) is an integrated infrastructure to accelerate materials discovery and design using density functional theory (DFT), classical force-fields (FF), and machine learning (ML) techniques. JARVIS is motivated by the Materials Genome Initiative (MGI) principles of developing open-access databases and tools to reduce the cost and development time of materials discovery, optimization, and deployment. The major features of JARVIS are: JARVIS-DFT, JARVIS-FF, JARVIS-ML, and JARVIS-tools. To date, JARVIS consists of approximate to 40,000 materials and approximate to 1 million calculated properties in JARVIS-DFT, approximate to 500 materials and approximate to 110 force-fields in JARVIS-FF, and approximate to 25 ML models for material-property predictions in JARVIS-ML, all of which are continuously expanding. JARVIS-tools provides scripts and workflows for running and analyzing various simulations. We compare our computational data to experiments or high-fidelity computational methods wherever applicable to evaluate error/uncertainty in predictions. In addition to the existing workflows, the infrastructure can support a wide variety of other technologically important applications as part of the data-driven materials design paradigm. The JARVIS datasets and tools are publicly available at the website: https://jarvis.nist.gov.","TOTAL-ENERGY CALCULATIONS,THROUGHPUT,TOOL,LIBRARY",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Chemistry,Materials Science",,13.993,"TOTAL-ENERGY,CALCULATIONS,THROUGHPUT,TOOL,LIBRARY",NPJ COMPUTATIONAL MATERIALS,https://www.nature.com/articles/s41524-020-00440-1.pdf,
82,Blood eosinophil count combined with asthma history could predict chronic rhinosinusitis with nasal polyp recurrence,141,3,279-285,"Wang Xiaoyan,Meng Yifan,Lou Hongfei,Wang Kuiji,Wang Chengshuo,Zhang Luo","Wang XY,Meng YF,Lou HF,Wang KJ,Wang CS,Zhang L",Wang CS,10.1080/00016489.2020.1844288,Capital Medical University,"Background
The use of non-invasive clinical markers for predicting CRS recurrence is still not well investigated.
Objective
The aim of this study was to investigate the comprehensive effects of non-invasive clinical markers on the recurrence of CRS with nasal polyps (CRSwNP).
Materials and methods
A total of 346 consecutive CRSwNP patients undergoing endoscopic functional sinus surgery were recruited. The demographic characteristics and clinical parameters were recorded. Machine learning algorithm were used for evaluating the predictive value of asthma history and blood eosinophils percentage.
Results
Finally, 313/346 patients completed the study. The average follow-up time was 24 months after the first surgery. For the CRSwNP with asthma patients, the blood eosinophils percentage cut-off value was 3.7%. However, for the CRSwNP without asthma patients, the blood eosinophils percentage cut-off value was high, at 6.9%.
Conclusion
Combined asthma history and blood eosinophils percentage can predict CRSwNP recurrence, while asthma history can reduce the threshold of blood eosinophils percentage to predict CRSwNP recurrence.
Significance
For the CRS patients, combined asthma history and blood eosinophils percentage can predict recurrence, while asthma history can reduce the threshold of blood eosinophils percentage to predict recurrence.","Asthma,blood eosinophils percentage,chronic rhinosinusitis with nasal polyps,endoscopic sinus surgery,prediction,recurrence",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Otorhinolaryngology,,1.624,,ACTA OTO-LARYNGOLOGICA,,
83,,,,,,,,,,,,,,,,,,,,
84,Synthetic laparoscopic video generation for machine learning-based surgical instrument segmentation from real laparoscopic video and virtual surgical instruments,9,3,225-232,"Ozawa Takuya,Hayashi Yuichiro,Oda Hirohisa,Oda Masahiro,Kitasaka Takayuki,Takeshita Nobuyoshi,Ito Masaaki,Mori Kensaku","Ozawa T,Hayashi Y,Oda H,Oda M,Kitasaka T,Takeshita N,Ito M,Mori K",Hayashi Y,10.1080/21681163.2020.1835560,Nagoya University,"This paper proposes a synthetic laparoscopic image generation for machine-learning-based surgical instrument segmentation from laparoscopic videos. Recently surgical instrument extraction methods from laparoscopic videos have been studied using deep learning, fuelling the creation of a large amount of training data for better performance. However, it is difficult to collect a massive amount of data on surgical instruments that are used infrequently during surgery. Their recognition accuracy may be reduced by the lack of training data. This paper solves this problem by increasing the training data with an image synthesis technique. Pairs of synthetic laparoscopic videos and their labelled data are automatically generated by superimposing 3D virtual surgical instrument models on real laparoscopic videos. The synthetic laparoscopic images are translated using CycleGAN so that the appearance of the surgical instruments closely resembles those in the real laparoscopic videos. Additionally, we extracted surgical instruments from laparoscopic videos using 2D U-Net based network. This network was trained using both the synthetic laparoscopic images and the manually labelled, real laparoscopic video data. The trained model extracted the surgical instruments from the laparoscopic videos. Our experimental result showed that the recognition accuracy of the surgical instruments, which are used infrequently during surgery, was improved using synthetic laparoscopic images generated by our proposed method.","Segmentation,image translation,laparoscopic surgery,synthetic image,virtual reality",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,,,COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION,,
85,Neural Network Vessel Lumen Regression for Automated Lumen Cross-Section Segmentation in Cardiovascular Image-Based Modeling,11,6,621-635,"Maher Gabriel,Parker David,Wilson Nathan,Marsden Alison","Maher G,Parker D,Wilson N,Marsden A",Marsden A,10.1007/s13239-020-00497-5,Stanford University,"Purpose We accelerate a pathline-based cardiovascular model building method by training machine learning models to directly predict vessel lumen surface points from computed tomography (CT) and magnetic resonance (MR) medical image data. Methods We formulate vessel lumen detection as a regression task using a polar coordiantes representation. Results Neural networks trained with our regression formulation allow predictions to be made with significantly higher accuracy than existing methods that identify the vessel lumen through binary pixel classification. The regression formulation enables machine learning models to be trained end-to-end for vessel lumen detection without post-processing steps that reduce accuracy. Conclusion By employing our models in a pathline-based cardiovascular model building pipeline we substantially reduce the manual segmentation effort required to build accurate cardiovascular models, and reduce the overall time required to perform patient-specific cardiovascular simulations. While our method is applied here for cardiovascular model building it is generally applicable to segmentation of tree-like and tubular structures from image data.","Cardiovascular modeling,Convolutional neural networks,SimVascular,Patient-specific modeling,Cardiovascular simulation",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Cardiovascular System & Cardiology,Engineering",,2.271,,CARDIOVASCULAR ENGINEERING AND TECHNOLOGY,,
86,Automated organization of interaction between modules of information systems based on neural network data channels,33,12,7249-7269,"Obukhov Artem D.,Krasnyanskiy Mikhail N.","Obukhov AD,Krasnyanskiy MN",Obukhov AD,10.1007/s00521-020-05491-5,Tambov State Technical University,"The automation of the process of information systems construction is an important and urgent problem, as it allows reducing the negative influence of a person during decision making and developing software, releasing additional time and material resources to solve more complex and creative problems. Most modern information systems are developed on a modular base; therefore, a significant design stage is the implementation of links between system components. The purpose of the study is to automate the organization of intermodular interaction in information systems, which will reduce the complexity, time and cost of this implementing process. In order to achieve the result, a method is proposed for the organization of interaction between modules of information systems based on neural network data channels, realized within the general concept of a neural network architecture. The structure of neural network channels, the principles of their functioning, theoretical substantiation, mathematical and algorithmic support and area of application are considered in detail. A classification of neural network channels is presented, based on two of their characteristics: categories and degrees. As a result of the conducted research, the practical implementation of two neural network data channels is realized (transmission and adaptation), the structure of the program code, the used tools and libraries are analyzed. Based on a set of metrics for the complexity of the program code (Halstead, Jilb), the estimation of the computational complexity of algorithms, time and material costs for implementation, a comparative analysis of neural network data transmission channels and adaptation with classical approaches in the form of a set of network data transmission protocol and the required algorithmic support for data processing is carried out. The obtained experimental results confirm the lower complexity of neural network channels (reduction by at least 20% according to Halstead metrics and cyclometric complexity), reduction in time (by 12-32%) and cost (by 36-63%) of implementation and increase in the accuracy of the problem solving (by 11.8-15.5%). This demonstrates the effectiveness of using neural network data channels to automate the organization of intermodular interaction in information systems.","Neural network architecture,Automation of intermodular interaction,Adaptation and transmission of information,Machine learning",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"ARCHITECTURE,COMPLEXITY",NEURAL COMPUTING & APPLICATIONS,,
87,Machine-learning predictions of positron binding to molecules,102,5,,"Amaral Paulo H. R.,Mohallem Jose R.","Amaral PHR,Mohallem JR",Mohallem JR,10.1103/PhysRevA.102.052808,Universidade Federal de Minas Gerais,"Machine-learning techniques are used to check the theoretical and experimental predictions of positron binding to general molecules. The bound or unbound character of previous calculations for polar molecules are mostly confirmed. Binding for so far unexplored polar molecules is predicted. For apolar molecules, a formula for the binding energy in terms of isotropic polarizability and ionization potential is obtained, leading to unprecedented agreement with experiments as well as prediction of previously unidentified bound systems. The role of the ionization potential is suggested as a consequence of enhanced formation of virtual positronium at short distances.","QUANTUM MONTE-CARLO,BOUND-STATES,CONFIGURATION-INTERACTION,GROUND-STATE,CHEMISTRY",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Optics,Physics",,2.936,"QUANTUM,MONTE-CARLO,BOUND-STATES,CONFIGURATION-INTERACTION,GROUND-STATE,CHEMISTRY",PHYSICAL REVIEW A,,
88,A reference map of potential determinants for the human serum metabolome,588,7836,135-140,"Bar Noam,Korem Tal,Weissbrod Omer,Zeevi David,Rothschild Daphna,Leviatan Sigal,Kosower Noa,Lotan-Pompan Maya,Weinberger Adina,Le Roy Caroline I.","Bar N,Korem T,Weissbrod O,Zeevi D,Rothschild D,Leviatan S,Kosower N,Lotan-Pompan M,Weinberger A,Le Roy CI",Segal E,10.1038/s41586-020-2896-2,Weizmann Institute of Science,"The serum metabolome contains a plethora of biomarkers and causative agents of various diseases, some of which are endogenously produced and some that have been taken up from the environment(1). The origins of specific compounds are known, including metabolites that are highly heritable(2,3), or those that are influenced by the gut microbiome(4), by lifestyle choices such as smoking(5), or by diet(6). However, the key determinants of most metabolites are still poorly understood. Here we measured the levels of 1,251 metabolites in serum samples from a unique and deeply phenotyped healthy human cohort of 491 individuals. We applied machine-learning algorithms to predict metabolite levels in held-out individuals on the basis of host genetics, gut microbiome, clinical parameters, diet, lifestyle and anthropometric measurements, and obtained statistically significant predictions for more than 76% of the profiled metabolites. Diet and microbiome had the strongest predictive power, and each explained hundreds of metabolites-in some cases, explaining more than 50% of the observed variance. We further validated microbiome-related predictions by showing a high replication rate in two geographically independent cohorts(7,8) that were not available to us when we trained the algorithms. We used feature attribution analysis(9) to reveal specific dietary and bacterial interactions. We further demonstrate that some of these interactions might be causal, as some metabolites that we predicted to be positively associated with bread were found to increase after a randomized clinical trial of bread intervention. Overall, our results reveal potential determinants of more than 800 metabolites, paving the way towards a mechanistic understanding of alterations in metabolites under different conditions and to designing interventions for manipulating the levels of circulating metabolites.
The levels of 1,251 metabolites are measured in 475 phenotyped individuals, and machine-learning algorithms reveal that diet and the microbiome are the determinants with the strongest predictive power for the levels of these metabolites.","UREMIC TOXINS,DISEASE,SUPPLEMENTATION,ENVIRONMENT,ALIGNMENT,BETAINE",Article,"NATURE PORTFOLIO, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,54.637,"UREMIC,TOXINS,DISEASE,SUPPLEMENTATION,ENVIRONMENT,ALIGNMENT,BETAINE",NATURE,https://discovery.dundee.ac.uk/ws/files/54658965/Bar_et_al._2020.pdf,
89,Discovering rare-earth-free magnetic materials through the development of a database,4,11,,"Sakurai Masahiro,Wang Renhai,Liao Timothy,Zhang Chao,Sun Huaijun,Sun Yang,Wang Haidi,Zhao Xin,Wang Songyou,Balasubramanian Balamurugan","Sakurai M,Wang RH,Liao T,Zhang C,Sun HJ,Sun Y,Wang HD,Zhao X,Wang SY,Balasubramanian B",Sakurai M,10.1103/PhysRevMaterials.4.114408,University of Texas System,"We develop an open-access database that provides a large array of datasets specialized for magnetic compounds as well as magnetic clusters. Our focus is on rare-earth-free magnets. Available datasets include (i) crystallography, (ii) thermodynamic properties, such as the formation energy, and (iii) magnetic properties that are essential for magnetic-material design. Our database features a large number of stable and metastable structures discovered through our adaptive genetic algorithm (AGA) searches. Many of these AGA structures have better magnetic properties when compared to those of the existing rare-earth-free magnets and the theoretical structures in other databases. Our database places particular emphasis on site-specific magnetic data, which are obtained by high-throughput first-principles calculations. Such site-resolved data are indispensable for machine-learning modeling. We illustrate how our data-intensive methods promote efficiency of the experimental discovery of new magnetic materials. Our database provides massive datasets that will facilitate an efficient computational screening, machine-learning-assisted design, and the experimental fabrication of new promising magnets.","DIFFERENCE-PSEUDOPOTENTIAL METHOD,ELECTRONIC-STRUCTURE CALCULATIONS,TOTAL-ENERGY CALCULATIONS,EXCHANGE INTERACTIONS,ANISOTROPY,ALGORITHM,ZR2CO11,METALS",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA",Materials Science,,4.034,"DIFFERENCE-PSEUDOPOTENTIAL,METHOD,ELECTRONIC-STRUCTURE,CALCULATIONS,TOTAL-ENERGY,CALCULATIONS,EXCHANGE,INTERACTIONS,ANISOTROPY,ALGORITHM,ZR2CO11,METALS",PHYSICAL REVIEW MATERIALS,,
90,Can Peritumoral Radiomics Improve the Prediction of Malignancy of Solid Pulmonary Nodule Smaller Than 2 cm?,,,,",,,,","Wu Shan,Zhang Na,Wu Zhifeng,Ren Jialiang,E Linning",,10.1016/j.acra.2020.10.029,,"RATIONALE AND OBJECTIVES: To compare the ability of radiomics models including the perinodular parenchyma and standard nodular radiomics model in lung cancer diagnosis of solid pulmonary nodules smaller than 2 cm.MATERIALS AND METHODS: In this retrospective study, the computed tomography (CT) scans of 206 patients with a lung nodule from a single institution in 2012-2019 were collected. For each nodule, four volumes of interest were defined using the gross tumor volume (GTV) and peritumoral volumes (PTVs) of 5, 10, and 15 mm around the tumor.RESULTS: Radiomics models created from GTV, GTV plus 5 mm of PTV, GTV plus 10 mm of PTV, and GTV plus 15 mm of PTV achieved AUCs of 0.89, 0.81, 0.81, and 0.73, respectively, in the validation cohort for the diagnostic classification of benign and malignant pulmonary nodules. The performance of the models gradually decreased as the PTV increased. Wavelet features were the primary features identified in optimal radiomics signatures (2/3 in R, 4/5 in GTV plus 5 mm PTV, 3/4 in GTV plus 10 mm PTV, 2/3 in GTV plus 15 mm PTV).CONCLUSION: Our study indicated that the radiomics signatures of GTV had a good prediction ability in distinguishing benign and malignant solid pulmonary nodules smaller than 2 cm on CT. However, the radiomics feature of the surrounding parenchyma of the nodule did not enhance the effectiveness of the diagnostic model. Copyright © 2020 The Association of University Radiologists. Published by Elsevier Inc. All rights reserved.","Computed tomography; Lung cancer; ,Machine learning,; Radiomics",Journal Article,,,,,,,,
91,Data-driven discovery of 3D and 2D thermoelectric materials,32,47,,"Choudhary Kamal,Garrity Kevin F.,Tavazza Francesca","Choudhary K,Garrity KF,Tavazza F",Choudhary K,10.1088/1361-648X/aba06b,National Institute of Standards & Technology (NIST) - USA,"In this work, we first perform a systematic search for high-efficiency three-dimensional (3D) and two-dimensional (2D) thermoelectric materials by combining semiclassical transport techniques with density functional theory (DFT) calculations and then train machine-learning models on the thermoelectric data. Out of 36 000 three-dimensional and 900 two-dimensional materials currently in the publicly available JARVIS-DFT database, we identify 2932 3D and 148 2D promising thermoelectric materials using a multi-steps screening procedure, where specific thresholds are chosen for key quantities like bandgaps, Seebeck coefficients and power factors. We compute the Seebeck coefficients for all the materials currently in the database and validate our calculations by comparing our results, for a subset of materials, to experimental and existing computational datasets. We also investigate the effect of chemical, structural, crystallographic and dimensionality trends on thermoelectric performance. We predict several classes of efficient 3D and 2D materials such as Ba(MgX)(2)(X = P, As, Bi), X(2)YZ(6)(X = K, Rb, Y=Pd, Pt, Z = Cl, Br), K2PtX2(X = S, Se), NbCu3X4(X = S, Se, Te), Sr2XYO6(X = Ta, Zn, Y=Ga, Mo), TaCu3X4(X = S, Se, Te), and XYN (X = Ti, Zr, Y=Cl, Br). Finally, as high-throughput DFT is computationally expensive, we train machine learning models using gradient boosting decision trees and classical force-field inspired descriptors for n-and p-type Seebeck coefficients and power factors, to quickly pre-screen materials for guiding the next set of DFT calculations. The dataset and tools are made publicly available at the websites: https://www.ctcms.nist.gov/similar to knc6/JVASP.html, https://www.ctcms.nist.gov/jarvisml/ and https://jarvis.nist.gov/.","density functional theory,machine learning,thermoelectrics,two-dimensional materials,three-dimensional materials,materials genome,NIST-JARVIS",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,2.887,"TOTAL-ENERGY,CALCULATIONS,POWER,EFFICIENCY,FIGURE,BULK",JOURNAL OF PHYSICS-CONDENSED MATTER,http://arxiv.org/pdf/1906.06024,
92,Inverse design of broadband metasurface absorber based on convolutional autoencoder network and inverse design network,53,46,,"Ma Ju,Huang Yijia,Pu Mingbo,Xu Dong,Luo Jun,Guo Yinghui,Luo Xiangang","Ma J,Huang YJ,Pu MB,Xu D,Luo J,Guo YH,Luo XA",Luo XA,10.1088/1361-6463/aba3ec,Chinese Academy of Sciences,"Electromagnetic (EM) metasurfaces have attracted great attention from both engineers and researchers due to their unique physical responses. With the rapid development of complex metasurfaces, the design and optimization processes have also become extremely time-consuming and computational resource-consuming. Here we proposed a deep learning model (DLM) based on a convolutional autoencoder network and inverse design network, which can help to establish the complex relationships between the geometries of metasurfaces and their EM responses. As a typical example, a metasurface absorber consisting of polymethacrylimide foam/metal ring alternating multilayers is chosen to demonstrate the capability of the DLM. The relative spectral error of the two desired spectra is only 5.80 and 5.49, respectively. Our model shows great predictive power and may be used as an effective tool to accelerate the design and optimization of metasurfaces.","metasurfaces,deep learning,deep learning model,autoencoder,absorber",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,3.041,,JOURNAL OF PHYSICS D-APPLIED PHYSICS,,
93,,,,,,,,,,,,,,,,,,,,
94,,,,,,,,,,,,,,,,,,,,
95,Towards secure deep learning architecture for smart farming-based applications,7,2,659-666,"Udendhran R.,Balamurugan M.","Udendhran R,Balamurugan M",Udendhran R,10.1007/s40747-020-00225-5,Bharathidasan University,"The immense growth of the cloud infrastructure leads to the deployment of several machine learning as a service (MLaaS) in which the training and the development of machine learning models are ultimately performed in the cloud providers' environment. However, this could also cause potential security threats and privacy risk as the deep learning algorithms need to access generated data collection, which lacks security in nature. This paper predominately focuses on developing a secure deep learning system design with the threat analysis involved within the smart farming technologies as they are acquiring more attention towards the global food supply needs with their intensifying demands. Smart farming is known to be a combination of data-driven technology and agricultural applications that helps in yielding quality food products with the enhancing crop yield. Nowadays, many use cases had been developed by executing smart farming paradigm and promote high impacts on the agricultural lands.","Deep learning,Smart farming,Differential privacy,Image processing,Feature extraction,Convolutional neural networks,Gradient descent",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Computer Science,,5.277,"THINGS,DOMAIN",COMPLEX & INTELLIGENT SYSTEMS,https://link.springer.com/content/pdf/10.1007/s40747-020-00225-5.pdf,
96,Machine learning prediction of mechanical properties of concrete: Critical review,260,,,"Ben Chaabene Wassim,Flah Majdi,Nehdi Moncef L.","Ben Chaabene W,Flah M,Nehdi ML",Nehdi ML,10.1016/j.conbuildmat.2020.119889,Western University (University of Western Ontario),"Accurate prediction of the mechanical properties of concrete has been a concern since these properties are often required by design codes. The emergence of new concrete mixtures and applications has motivated researchers to pursue reliable models for predicting mechanical strength. Empirical and statistical models, such as linear and nonlinear regression, have been widely used. However, these models require laborious experimental work to develop, and can provide inaccurate results when the relationships between concrete properties and mixture composition and curing conditions are complex. To overcome such drawbacks, several Machine Learning (ML) models have been proposed as an alternative approach for predicting the mechanical strength of concrete. The present study examines ML models for forecasting the mechanical properties of concrete, including artificial neural networks, support vector machine, decision trees, and evolutionary algorithms. The application of each model and its performance are critically discussed and analyzed, thus identifying practical recommendations, current knowledge gaps, and needed future research. (C) 2020 Elsevier Ltd. All rights reserved.","Artificial neural network,Decision tree,Support vector machine,Compressive strength,Shear strength,Evolutionary algorithm,Statistical metric",Review,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Construction & Building Technology,Engineering,Materials Science",,6.841,"ARTIFICIAL,NEURAL-NETWORK,SUPPORT,VECTOR,MACHINE,COMPRESSIVE,STRENGTH,PREDICTION,HIGH-PERFORMANCE,CONCRETE,SELF-COMPACTING,CONCRETE,FUZZY,INFERENCE,SYSTEM,SHEAR-STRENGTH,ELASTIC-MODULUS,STEEL,FIBER,NONLINEAR-REGRESSION",CONSTRUCTION AND BUILDING MATERIALS,,
97,"Behavior assessment, regression analysis and support vector machine (SVM) modeling of waste tire rubberized concrete",273,,,"Jalal Mostafa,Arabali Poura,Grasley Zachary,Bullard Jeffrey W.,Jalal Hamid","Jalal M,Arabali P,Grasley Z,Bullard JW,Jalal H",Jalal M,10.1016/j.jclepro.2020.122960,Texas A&M University System,"An experimental study was undertaken to assess the properties of rubberized concrete made by recycled tire rubber. Mechanical tests were carried out and the ultrasonic technique was also used to measure the acoustic properties of the rubberized concrete, such as wave velocity, and the relationships between the mechanical properties and pulse velocity for different mixtures were investigated. Then, based on the experimental data, a thorough strength modeling was performed using regression analysis and support vector machine (SVM) technique. To develop the predictive models for strength behavior of the recycled rubber concrete, a comprehensive regression analyses including ANOVA, t-test and F-test were conducted, and the significance of the influencing variables was determined. Then, several regression models by incorporating different combinations of the variables were developed and compared. Finally, the SVM method as a machine-learning technique was utilized to develop several models by using different kernel functions, optimization algorithms, and hyperparameters optimization to predict the compressive strength of the recycled rubber concrete. The results obtained were compared with those of regression models and it was found that SVM outperforms all the regression models assessed in this study. (c) 2020 Elsevier Ltd. All rights reserved.","Waste tire rubberized concrete,Compressive strength,Regression analysis,ANOVA,Machine learning,Support-vector machine (SVM)",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Science & Technology - Other Topics,Engineering,Environmental Sciences & Ecology",,9.444,"COMPRESSIVE,STRENGTH,PREDICTION,FREE-VIBRATION,ANALYSIS,SILICA,FUME,HARDENED,PROPERTIES,NATURAL,ZEOLITE,CEMENT,CONCRETE,ANNULAR,PLATES,TYRE-RUBBER,OPTIMIZATION,PERFORMANCE",JOURNAL OF CLEANER PRODUCTION,,
98,A hybrid intelligent system for designing optimal proportions of recycled aggregate concrete,273,,,"Zhang Junfei,Huang Yimiao,Aslani Farhad,Ma Guowei,Nener Brett","Zhang JF,Huang YM,Aslani F,Ma GW,Nener B",Huang YM,10.1016/j.jclepro.2020.122922,University of Western Australia,"The replacement of natural coarse aggregate (NCA) with recycled coarse aggregate (RCA) in concrete mixtures offers various advantages, including conservation of natural resources, reduction of CO2 emissions, and cost reduction. However, multiple related variables and objectives (e.g., mechanical, economic, and environmental objectives) need to be considered when optimizing mixtures of recycled aggregate concrete (RAC). This cannot be achieved through traditional laboratory- or statistics-based methods. This study proposes a hybrid intelligent system based on artificial intelligence (AI) and metaheuristic algorithms for designing optimal mixtures of RAC. To verify the proposed model, a data set containing 344 different RAC mixtures was collected from previous literature. A semi-supervised cotraining algorithm using two k-nearest neighbor (kNN) regressors with different distance metrics is developed to label the unlabeled data in the collected dataset. Different AI models are incorporated into the system for modeling the relationship between RAC strength and its influencing variables. A multi-objective optimization (MOO) model based on AI algorithms and on a multi-objective firefly algorithm is used to search for optimal mixtures of RAC. The results show that kNN-based semi-supervised cotraining can effectively exploit unlabeled data to improve the regression estimates. In the test set, A Random Forest and Backpropagation Neural Network achieve the best prediction accuracy for predicting, respectively, uniaxial compressive strength and splitting tensile strength of RAC, indicated by the highest correlation coefficients (0.9064 and 0.8387, respectively) and lowest root-mean-square errors (6.639 MPa and 0.5119 MPa, respectively). The Pareto fronts of the multi-objective mixture optimization problem are successfully obtained by the MOO model. The proposed system can also be used to optimize mixture proportions of other cementitious materials in civil engineering. (C) 2020 Elsevier Ltd. All rights reserved.","Recycled aggregate concrete,Mechanical properties,Artificial intelligence,Firefly algorithm,Concrete mixture optimization",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Science & Technology - Other Topics,Engineering,Environmental Sciences & Ecology",,9.444,"UNCONFINED,COMPRESSIVE,STRENGTH,MECHANICAL-PROPERTIES,MIX,DESIGN,REGRESSION,CONSTRUCTION,PREDICTION,MODULUS,WASTE,MODEL",JOURNAL OF CLEANER PRODUCTION,,
99,Machine learning exploration of the critical factors for CO2 adsorption capacity on porous carbon materials at different pressures,273,,,"Zhu Xinzhe,Tsang Daniel C. W.,Wang Lei,Su Zhishan,Hou Deyi,Li Liangchun,Shang Jin","Zhu XZ,Tsang DCW,Wang L,Su ZS,Hou DY,Li LC,Shang J",Tsang DCW,10.1016/j.jclepro.2020.122915,Hong Kong Polytechnic University,"The growing environmental issues caused by CO2 emission accelerate the development of carbon capture and storage (CCS), especially bio-energy CCS as an environment-friendly and sustainable technique to capture CO2 using porous carbon materials (PCMs) produced from various biomass wastes. This study developed quantitative structure-property relationship models based on 6244 CO2 adsorption datasets of 155 PCMs to predict the CO2 adsorption capacity and analyze the relative significance of physicochemical properties. The results suggested that random forest (RF) models showed good accuracy and predictive performance based on physicochemical parameters of PCMs and adsorption conditions with the test dataset (R-2 > 0.9). In general, textural properties were more crucial than chemical compositions of porous carbons to the change of CO2 adsorption capacity. At a low pressure (0.1 bar), the volumes of mesopore and micropore played an important role according to the RF analysis, but had a negative correlation with CO2 adsorption capacity based on the Pearson correlation coefficient (PCC) analysis. The relative importance of ultra-micropore increased along with the increase of pressure. The PCC value between ultra-micropore volume and CO2 uptake amount was up to 0.715 (p < 0.01) at 1 bar and 0 degrees C. The influence of chemical compositions was complex. The N content was confirmed to positively correlate to the CO2 adsorption capacity but its contribution was much lower than that of ultra-micropores. This study provided a new approach for fostering the rational design of porous carbons for CO2 capture via statistical analysis and machine learning method, which facilitated adsorbents screening for the cleaner production. (C) 2020 Elsevier Ltd. All rights reserved.","CO2 sequestration,Carbon adsorbents,Sustainable waste management,Low-carbon development,Biomass utilization",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Science & Technology - Other Topics,Engineering,Environmental Sciences & Ecology",,9.444,"SINGLE-STEP,SYNTHESIS,SODIUM,AMIDE,ACTIVATION,DIOXIDE,CAPTURE,LOW-TEMPERATURE,COMBINING,AMMOXIDATION,KOH,ACTIVATION,PORE-SIZE,ADSORBENTS,ENERGY,TEXTURE",JOURNAL OF CLEANER PRODUCTION,,
100,DL-SCALE: a novel deep learning-based model order upscaling scheme for solving topology optimization problems,33,12,7125-7144,"Kallioras Nikos Ath.,Lagaros Nikos D.","Kallioras NA,Lagaros ND",Lagaros ND,10.1007/s00521-020-05480-8,National Technical University of Athens,"The main scope of this study is to propose a novel methodology aiming at enhancing the computational efficiency of the approaches used for solving structural topology optimization (STO) problems. The methodology is based on machine learning combined with the idea of using multiple finite element (FE) models of reduced order. The capability of deep belief networks (DBNs) in discovering multiple representational levels of data nonlinearity in pattern recognition problems recently triggered the development of the DLTOP methodology by the authors Kallioras et al. (Struct Multidiscip Optim, 2020, 10.1007/s00158-020-02545-z), that is based on DBNs and the solid isotropic material with penalization (SIMP) approach. In this study, a FE model order upgrading scheme integrated with the DLTOP methodology is proposed for accelerating further the SIMP-based solution procedure of the STO problems with no scalability limitations, labeled as DL-SCALE. The framework of DL-SCALE is based on a combined implementation of DBNs and SIMP into a sequentially implemented ""model-optimize-and-order-upgrade"" scheme. DL-SCALE efficiency is validated over several benchmark topology optimization test-examples. The results obtained for the test-examples clearly prove its computational advantages; the computing time is reduced by almost one order of magnitude while the corresponding reduction in terms of iterations is more than one order of magnitude compared to the ones originally required by SIMP, without any loss with respect to objective function value. It is also concluded from the results obtained that the proposed methodology can escalate to various finite element mesh discretizations, while optimized layout information transfer is possible, contributing also in accelerating further the STO procedure.","Topology optimization,Order upgrading,Deep learning,Computational efficiency,SIMP approach,Deep belief networks",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"STRUCTURAL,OPTIMIZATION,ALGORITHM,SHAPE,DESIGN",NEURAL COMPUTING & APPLICATIONS,,
