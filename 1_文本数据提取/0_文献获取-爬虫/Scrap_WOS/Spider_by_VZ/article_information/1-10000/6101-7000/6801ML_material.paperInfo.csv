,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Fast body part segmentation and tracking of neonatal video data using deep learning,58,12,3049-3061,"Antink Christoph Hoog,Ferreira Joana Carlos Mesquita,Paul Michael,Lyra Simon,Heimann Konrad,Karthik Srinivasa,Joseph Jayaraj,Jayaraman Kumutha,Orlikowsky Thorsten,Sivaprakasam Mohanasankar","Antink CH,Ferreira JCM,Paul M,Lyra S,Heimann K,Karthik S,Joseph J,Jayaraman K,Orlikowsky T,Sivaprakasam M",Antink CH,10.1007/s11517-020-02251-4,Helmholtz Association,"Photoplethysmography imaging (PPGI) for non-contact monitoring of preterm infants in the neonatal intensive care unit (NICU) is a promising technology, as it could reduce medical adhesive-related skin injuries and associated complications. For practical implementations of PPGI, a region of interest has to be detected automatically in real time. As the neonates' body proportions differ significantly from adults, existing approaches may not be used in a straightforward way, and color-based skin detection requires RGB data, thus prohibiting the use of less-intrusive near-infrared (NIR) acquisition. In this paper, we present a deep learning-based method for segmentation of neonatal video data. We augmented an existing encoder-decoder semantic segmentation method with a modified version of the ResNet-50 encoder. This reduced the computational time by a factor of 7.5, so that 30 frames per second can be processed at 960 x 576 pixels. The method was developed and optimized on publicly available databases with segmentation data from adults. For evaluation, a comprehensive dataset consisting of RGB and NIR video recordings from 29 neonates with various skin tones recorded in two NICUs in Germany and India was used. From all recordings, 643 frames were manually segmented. After pre-training the model on the public adult data, parts of the neonatal data were used for additional learning and left-out neonates are used for cross-validated evaluation. On the RGB data, the head is segmented well (82% intersection over union, 88% accuracy), and performance is comparable with those achieved on large, public, non-neonatal datasets. On the other hand, performance on the NIR data was inferior. By employing data augmentation to generate additional virtual NIR data for training, results could be improved and the head could be segmented with 62% intersection over union and 65% accuracy. The method is in theory capable of performing segmentation in real time and thus it may provide a useful tool for future PPGI applications.","Image processing,Deep learning,Semantic segmentation,Camera-based monitoring,Nicu",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"PHOTOPLETHYSMOGRAPHY,RATES",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7679364,
2,Architectured Lattice Materials with Tunable Anisotropy: Design and Analysis of the Material Property Space with the Aid of Machine Learning,22,12,,"Kulagin Roman,Beygelzimer Yan,Estrin Yuri,Schumilin Artem,Gumbsch Peter","Kulagin R,Beygelzimer Y,Estrin Y,Schumilin A,Gumbsch P",Kulagin R,10.1002/adem.202001069,Helmholtz Association,"Architectured beam lattice materials whose anisotropy can be tuned by varying the composition of their elementary cell are investigated. As an exemplary prototype of such material architecture, a regular triangular lattice with an elementary cell composed of 12 beams is considered. One out of three possible values of the elastic modulus is assigned to each beam. The structure is fully defined by a vector in the 12D composition-structure space whose components are given by the elastic modulus values of the beams comprising the elementary cell. The elastic properties of this 2D material are represented by the compliance elasticity tensor with six independent compliance coefficients. Aiming at a specific set of properties thus involves finding the point in the 12D composition-structure space that corresponds to a given point in the 6D property space. This is a problem of large dimensionality. To solve it, the neural network approach is used. This enables creation of architectured materials with tunable elastic anisotropy. A chiral element combining large twist with additional anisotropy requirements is presented as an example of successful machine-learning-based optimization of beam lattices proposed.","architectured materials,elastic anisotropies,lattice materials,machine learning",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY",Materials Science,,3.746,,ADVANCED ENGINEERING MATERIALS,https://publikationen.bibliothek.kit.edu/1000125818/124490043,
3,,,,,,,,,,,,,,,,,,,,
4,Crowd-Sourced Data and Analysis Tools for Advancing the Chemical Vapor Deposition of Graphene: Implications for Manufacturing,3,10,10144-10155,"Schiller Joshua A.,Toro Ricardo,Shah Aagam,Surana Mitisha,Zhang Kaihao,Robertson Matthew,Miller Kristina,Cruse Kevin,Liu Kevin,Seong Bomsaerah","Schiller JA,Toro R,Shah A,Surana M,Zhang KH,Robertson M,Miller K,Cruse K,Liu K,Seong B",Ertekin E; Tawfick S,10.1021/acsanm.0c02018,University of Illinois System,"Industrial production of graphene by chemical vapor deposition (CVD) requires more than the ability to synthesize large domain, high-quality graphene in a lab reactor. The integration of graphene in the fabrication process of electronic devices requires the cost-effective and environmentally friendly production of graphene on dielectric substrates, but current approaches can only produce graphene on metal catalysts. Sustainable manufacturing of graphene should also conserve the catalyst and reaction gases, but today the metal catalysts are typically dissolved after synthesis. Progress toward these objectives is hindered by the hundreds of coupled synthesis parameters that can strongly affect CVD of low-dimensional materials and poor communication in the published literature of the rich experimental data that exists in individual laboratories. We report here on a platform, ""graphene recipes for synthesis of high quality material"" (Gr-ResQ: pronounced graphene rescue), which includes powerful new tools for data-driven graphene synthesis. At the core of Gr-ResQ is a crowd-sourced database of CVD synthesis recipes and associated experimental results. The database captures similar to 300 parameters ranging from synthesis conditions such as a catalyst material and preparation steps, to ambient lab temperature and reactor details, as well as resulting Raman spectra and microscopy images. These parameters are carefully selected to unlock the potential of machine-learning models to advance synthesis. A suite of associated tools enable fast, automated, and standardized processing of Raman spectra and scanning electron microscopy images. To facilitate community-based efforts, Gr-ResQ provides tools for cyber-physical collaborations among research groups, allowing experiments to be designed, executed, and analyzed by different teams. Gr-ResQ also allows publication and discovery of recipes via the Materials Data Facility, which assigns each recipe a unique identifier when published and collects parameters in a search index. We envision that this holistic approach to data-driven synthesis can accelerate CVD recipe discovery and production control and open opportunities for advancing not only graphene but also many other 1D and 2D materials.","graphene,robotic synthesis,materials data,recipes,machine learning,Raman spectroscopy,nanomanufacturing",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science",,5.1,"SINGLE-CRYSTAL,GRAPHENE,LARGE-AREA,SYNTHESIS,HIGH-QUALITY,GROWTH,FILMS,OXYGEN,NETWORKS,SUPERCAPACITOR,SUBSTRATE,OXIDE",ACS APPLIED NANO MATERIALS,http://engrxiv.org/7mwgd/download,
5,,,,,,,,,,,,,,,,,,,,
6,An automatic framework for endoscopic image restoration and enhancement,51,4,1959-1971,"Asif Muhammad,Chen Lei,Song Hong,Yang Jian,Frangi Alejandro F.","Asif M,Chen L,Song H,Yang J,Frangi AF",Song H,10.1007/s10489-020-01923-w,Beijing Institute of Technology,"Despite its success in the field of minimally invasive surgery, endoscopy image analysis remains challenging due to limited image settings and control conditions. The low resolution and existence of large number of reflections in endoscopy images are the major problems in the automatic detection of objects. To address these issues, we presented a novel framework based on the convolutional neural networks. The proposed approach consists of three major parts. First, a deep learning (DL)-based image evaluation method is used to classify the input images into two groups, namely, specular highlights and weakly illuminated groups. Second, the specular highlight is detected using the DL-based method, and the reflected areas are recovered through a patch-based restoration operation. Lastly, gamma correction with optimized reflectance and illumination estimation is adopted to enhance the weakly illuminated images. The proposed method is compared against the existing ones, and the experimental results demonstrate that the former outperforms the latter in terms of subjective and objective assessments. This finding indicates that the proposed approach can serve as a potential tool for improving the quality of the endoscopy images used to examine internal body organs.","Endoscopy,Image restoration,Image enhancement,Specular highlights,Weak illuminance",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,4.602,SPACE,APPLIED INTELLIGENCE,,
7,The Role of Machine Learning Algorithms in Materials Science: A State of Art Review on Industry 4.0,28,5,3361-3381,Choudhury Amitava,Choudhury A,Choudhury A,10.1007/s11831-020-09503-4,Indian Institute of Engineering Science Technology Shibpur (IIEST),"The 21st century has witnessed a rapid convergence of manufacturing technology, computer science and information technology. This has led to a paradigm of 4.0. The hitherto known developments in metallurgical and materials practices are largely driven by application of fundamental knowledge through experiments and experiences. However, the mounting demands of high performance products and environmental security calls for the 'right first time' manufacturing in contrast to the traditional trial and error approach. In this context, a priori capability, for prediction and optimization of materials, process and product variables, is becoming the enabling factor. In recent time, research in material science is increasingly embarrassing the computational techniques in development of exotic materials with greater reliability and precision. The present study is aimed at exploring the computer vision and machine learning techniques in different application areas in materials science.","HIGH-ENTROPY ALLOYS,SOLID-SOLUTION PHASE,CRYSTALLIZATION BEHAVIOR,MECHANICAL-PROPERTIES,EDGE-DETECTION,MICROSTRUCTURE,SEGMENTATION,PREDICTION,STEEL,CO",Review,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering,Mathematics",,8.169,"HIGH-ENTROPY,ALLOYS,SOLID-SOLUTION,PHASE,CRYSTALLIZATION,BEHAVIOR,MECHANICAL-PROPERTIES,EDGE-DETECTION,MICROSTRUCTURE,SEGMENTATION,PREDICTION,STEEL,CO",ARCHIVES OF COMPUTATIONAL METHODS IN ENGINEERING,,
8,Exchange Spin Coupling from Gaussian Process Regression,124,42,8708-8723,"Bahlke Marc Philipp,Mogos Natnael,Proppe Jonny,Herrmann Carmen","Bahlke MP,Mogos N,Proppe J,Herrmann C",Bahlke MP; Herrmann C,10.1021/acs.jpca.0c05983,University of Hamburg,"Heisenberg exchange spin coupling between metal centers is essential for describing and understanding the electronic structure of many molecular catalysts, metalloenzymes, and molecular magnets for potential application in information technology. We explore the machine-learnability of exchange spin coupling beyond linear regression, which has not been studied yet. We employ Gaussian process regression, since it can potentially deal with small training sets (as likely associated with the rather complex molecular structures required for exploring spin coupling) and since it provides uncertainty estimates (""error bars"") along with predicted values. We compare a range of descriptors and kernels for 257 small dicopper complexes and find that a simple descriptor based on chemical intuition, consisting only of copper-bridge angles and copper-copper distances, clearly outperforms several more sophisticated descriptors when it comes to extrapolating toward larger experimentally relevant complexes. Exchange spin coupling is similarly easy to learn as the polarizability, while learning dipole moments is much harder. The strength of the sophisticated descriptors lies in their ability to linearize structure-property relationships, to the point that a simple linear ridge regression performs just as well as the kernel-based machine-learning model for our small dicopper data set. The superior extrapolation performance of the simple descriptor is unique to exchange spin coupling, reinforcing the crucial role of choosing a suitable descriptor and highlighting the interesting question of the role of chemical intuition vs systematic or automated selection of features for machine learning in chemistry and material science.","TRANSITION-METAL-COMPLEXES,ZETA VALENCE QUALITY,CORRELATION-ENERGY,BASIS-SETS,MACHINE,DISCOVERY,DESIGN,ANTIFERROMAGNETISM,COMMUNICATION,STRATEGIES",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Physics",,2.725,"TRANSITION-METAL-COMPLEXES,ZETA,VALENCE,QUALITY,CORRELATION-ENERGY,BASIS-SETS,MACHINE,DISCOVERY,DESIGN,ANTIFERROMAGNETISM,COMMUNICATION,STRATEGIES",JOURNAL OF PHYSICAL CHEMISTRY A,,
9,Diagnosing colorectal abnormalities using scattering coefficient maps acquired from optical coherence tomography,14,1,,"Zeng Yifeng,Chapman William C. Jr.,Lin Yixiao,Li Shuying,Mutch Matthew,Zhu Quing","Zeng YF,Chapman WC,Lin YX,Li SY,Mutch M,Zhu Q",Zhu Q,10.1002/jbio.202000276,Washington University (WUSTL),"Optical coherence tomography (OCT) has shown potential in differentiating normal colonic mucosa from neoplasia. In this study of 33 fresh human colon specimens, we report the first use of texture features and computer vision-based imaging features acquired from en face scattering coefficient maps to characterize colorectal tissue. En face scattering coefficient maps were generated automatically using a new fast integral imaging algorithm. From these maps, a gray-level cooccurrence matrix algorithm was used to extract texture features, and a scale-invariant feature transform algorithm was used to derive novel computer vision-based features. In total, 25 features were obtained, and the importance of each feature in diagnosis was evaluated using a random forest model. Two classifiers were assessed on two different classification tasks. A support vector machine model was found to be optimal for distinguishing normal from abnormal tissue, with 94.7% sensitivity and 94.0% specificity, while a random forest model performed optimally in further differentiating abnormal tissues (i.e., cancerous tissue and adenomatous polyp) with 86.9% sensitivity and 85.0% specificity. These results demonstrated the potential of using OCT to aid the diagnosis of human colorectal disease.","colorectal cancer,feature engineering,machine learning,optical coherence tomography,scattering coefficient map",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Biochemistry & Molecular Biology,Biophysics,Optics",,3.403,CANCER,JOURNAL OF BIOPHOTONICS,,
10,Structure and Dynamics of Supercooled Liquid Ge2Sb2Te5 from Machine-Learning-Driven Simulations,15,3,,"Zhou Yu-Xing,Zhang Han-Yi,Deringer Volker L.,Zhang Wei","Zhou YX,Zhang HY,Deringer VL,Zhang W",Zhang W,10.1002/pssr.202000403,Xi'an Jiaotong University,"Studies of supercooled liquid phase-change materials are important for the development of phase-change memory and neuromorphic computing devices. Herein, a machine-learning (ML)-based interatomic potential for Ge2Sb2Te5 (GST) to conduct large-scale molecular dynamics simulations of liquid and supercooled liquid GST is used. A pronounced effect of the thermostat parameters on the simulation results is demonstrated, and it is shown how using a Langevin thermostat with optimized damping values can lead to excellent agreement with reference ab initio molecular dynamics (AIMD) simulations. Structural and dynamical analyses are presented, including the studies of radial and angular distributions, homopolar bonds, and the temperature-dependent diffusivity. Herein, the usefulness of ML-driven molecular dynamics for further studies of supercooled liquid GST, with length and timescales far exceeding those that are accessible to AIMD is demonstrated.","dynamical properties,Gaussian approximation potential,machine learning,molecular dynamics simulations,phase&#8208,change materials",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Materials Science,Physics",,3.017,"PHASE-CHANGE,MATERIALS,SB-TE,MOLECULAR-DYNAMICS,FAST,CRYSTALLIZATION,MEMORY,SC,TRANSITIONS,STATE,GETE",PHYSICA STATUS SOLIDI-RAPID RESEARCH LETTERS,https://ora.ox.ac.uk/objects/uuid:e02516cd-8375-40fd-b5dd-d7b4882178bb/download_file?safe_filename=Zhou_et_al_2020._structure_and_dynamics.pdf&type_of_work=Journal+article,
11,Synthesis of computer simulation and machine learning for achieving the best material properties of filled rubber,10,1,,"Kojima Takashi,Washio Takashi,Hara Satoshi,Koishi Masataka","Kojima T,Washio T,Hara S,Koishi M",Kojima T,10.1038/s41598-020-75038-0,The Yokohama Rubber Co. Ltd.,"Molecular dynamics (MD) simulation is used to analyze the mechanical properties of polymerized and nanoscale filled rubber. Unfortunately, the computation time for a simulation can require several months' computing power, because the interactions of thousands of filler particles must be calculated. To alleviate this problem, we introduce a surrogate convolutional neural network model to achieve faster and more accurate predictions. The major difficulty when employing machine-learning-based surrogate models is the shortage of training data, contributing to the huge simulation costs. To derive a highly accurate surrogate model using only a small amount of training data, we increase the number of training instances by dividing the large-scale simulation results into 3D images of middle-scale filler morphologies and corresponding regional stresses. The images include fringe regions to reflect the influence of the filler constituents outside the core regions. The resultant surrogate model provides higher prediction accuracy than that trained only by images of the entire region. Afterwards, we extract the fillers that dominate the mechanical properties using the surrogate model and we confirm their validity using MD.",,Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,5.134,,SCIENTIFIC REPORTS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7581745,
12,,,,,,,,,,,,,,,,,,,,
13,,,,,,,,,,,,,,,,,,,,
14,Diabetic retinopathy severity grading employing quadrant-basedInception-V3convolution neural network architecture,31,2,592-608,"Bhardwaj Charu,Jain Shruti,Sood Meenakshi","Bhardwaj C,Jain S,Sood M",Bhardwaj C,10.1002/ima.22510,Jaypee University of Information Technology,Diabetic retinopathy (DR) accounts in eye-related disorders due to accumulated damage to small retinal blood vessels. Automated diagnostic systems are effective in early detection and diagnosis of severe eye complications by assisting the ophthalmologists. Deep learning-based techniques have emerged as an advancement over conventional techniques based on hand-crafted features. The authors have proposed a Quadrant-based automated DR grading system in this work using Inception-V3 deep neural network to extract small lesions present in retinal fundus images. The grading efficiency of the proposed architecture is improved utilizing image enhancement and optical disc removal pipeline along with data augmentation stage. The proposed system yields accuracy of 93.33% with minimized cross-entropy loss of 0.291. Capability of proposed system is demonstrated experimentally to provide efficient DR diagnosis. The diagnosis ability of the proposed architecture is demonstrated by state-of-the-art comparison with other mainstream convolution neural network models and a maximum improvement of 14.33% is observed.,"convolution neural network,data augmentation,deep neural network,diabetic retinopathy,hand-crafted features",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,"FUNDUS,IMAGES,SYSTEM",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
15,"Predicting Inorganic Photovoltaic Materials with Efficiencies > 26% via Structure-Relevant Machine Learning and Density Functional Calculations (vol 1, 100179-1-17, 2020)",1,10,,"Feng Hong-Jian);,Wu Kan);,Deng Zun-Yi","Feng HJ,Wu K,Deng ZY",,10.1016/j.xcrp.2020.100236,,,,Correction,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Chemistry,Energy & Fuels,Materials Science,Physics",,,,CELL REPORTS PHYSICAL SCIENCE,https://doi.org/10.1016/j.xcrp.2020.100236,
16,Deep Convolutional Mixture Density Network for Inverse Design of Layered Photonic Structures,7,10,2703-2712,"Unni Rohit,Yao Kan,Zheng Yuebing","Unni R,Yao K,Zheng YB",Zheng YB,10.1021/acsphotonics.0c00630,University of Texas System,"Machine learning (ML) techniques, such as neural networks, have emerged as powerful tools for the inverse design of nanophotonic structures. However, this innovative approach suffers some limitations. A primary one is the nonuniqueness problem, which can prevent ML algorithms from properly converging because vastly different designs produce nearly identical spectra. Here, we introduce a mixture density network (MDN) approach, which models the design parameters as multimodal probability distributions instead of discrete values, allowing the algorithms to converge in cases of nonuniqueness without sacrificing degenerate solutions. We apply our MDN technique to inversely design two types of multilayer photonic structures consisting of thin films of oxides, which present a significant challenge for conventional ML algorithms due to a high degree of nonuniqueness in their optical properties. In the 10-layer case, the MDN can handle transmission spectra with high complexity and under varying illumination conditions. The 4-layer case tends to show a stronger multimodal character, with secondary modes indicating alternative solutions for a target spectrum. The shape of the distributions gives valuable information for postprocessing and about the uncertainty in the predictions, which is not available with deterministic networks. Our approach provides an effective solution to the inverse design of photonic structures and yields more optimal searches for the structures with high degeneracy and spectral complexity.","deep learning,artificial neural networks,multilayer structures,nanophotonics,inverse design,nonuniqueness",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science,Optics,Physics",,7.718,NANOPHOTONICS,ACS PHOTONICS,,
17,Deep learning approaches for thermographic imaging,128,15,,"Kovacs Peter,Lehner Bernhard,Thummerer Gregor,Mayr Guenther,Burgholzer Peter,Huemer Mario","Kovacs P,Lehner B,Thummerer G,Mayr G,Burgholzer P,Huemer M",Kovacs P,10.1063/5.0020404,Johannes Kepler University Linz,"In this paper, we investigate two deep learning approaches to recovering initial temperature profiles from thermographic images in non-destructive material testing. First, we trained a deep neural network (DNN) in an end-to-end fashion by directly feeding the surface temperature measurements to the DNN. Second, we turned the surface temperature measurements into virtual waves (a recently developed concept in thermography), which we then fed to the DNN. To demonstrate the effectiveness of these methods, we implemented a data generator and created a dataset comprising a total of 100000 simulated temperature measurement images. With the objective of determining a suitable baseline, we investigated several state-of-the-art model-based reconstruction methods, including Abel transformation, curvelet denoising, and time- and frequency-domain synthetic aperture focusing techniques. Additionally, a physical phantom was created to support evaluation on completely unseen real-world data. The results of several experiments suggest that both the end-to-end and the hybrid approach outperformed the baseline in terms of reconstruction accuracy. The end-to-end approach required the least amount of domain knowledge and was the most computationally efficient one. The hybrid approach required extensive domain knowledge and was more computationally expensive than the end-to-end approach. However, the virtual waves served as meaningful features that convert the complex task of the end-to-end reconstruction into a less demanding undertaking. This in turn yielded better reconstructions with the same number of training samples compared to the end-to-end approach. Additionally, it allowed more compact network architectures and use of prior knowledge, such as sparsity and non-negativity. The proposed method is suitable for non-destructive testing (NDT) in 2D where the amplitudes along the objects are considered to be constant (e.g., for metallic wires). To encourage the development of other deep-learning-based reconstruction techniques, we release both the synthetic and the real-world datasets along with the implementation of the deep learning methods to the research community.","APERTURE,MODEL",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,"APERTURE,MODEL",JOURNAL OF APPLIED PHYSICS,https://aip.scitation.org/doi/pdf/10.1063/5.0020404,
18,Detection of cervical cancer cells based on strong feature CNN-SVM network,411,,112-127,"Jia A. Dongyao,Li B. Zhengyi,Zhang C. Chuanwang","Jia ADY,Li BZY,Zhang CCW",Zhang CCW,10.1016/j.neucom.2020.06.006,Beijing Jiaotong University,"Traditional screening of cervical cells largely depends on the experience of pathologists, which also has the problem of low accuracy and poor efficiency. Medical image processing combining deep learning and machine learning shows its superiority in the field of cell classification. A new framework based on strong feature Convolutional Neural Networks (CNN)-Support Vector Machine (SVM) model was proposed to accurately classify the cervical cells. A method fusing the strong features extracted by Gray-Level Co-occurrence Matrix (GLCM) and Gabor with abstract features from the hidden layers of CNN was conducted, meanwhile the fused ones were input into the SVM for classification. An effective dataset amplification method was designed to improve the robustness of the model. The proposed method was evaluated on two independent datasets with the metrics of accuracy (Acc), sensitivity (Sn), and specificity (Sp). Our approach outperformed than the state-of-the-art models with the Acc, Sn, and Sp of 99.3, 98.9, 99.4 for 2-class detection in the mass, respectively. The results indicated that the strong feature CNN-SVM model could be applied in cell classification for the early screening of cervical cancer. (c) 2020 Elsevier B.V. All rights reserved.","Cancer cell detection,Strong features,CNN-SVM,Sample amplification",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"QUANTITATIVE-ANALYSIS,CLASSIFICATION,SEGMENTATION,DIAGNOSIS",NEUROCOMPUTING,,
19,Deep learning in medical image registration: a review,65,20,,"Fu Yabo,Lei Yang,Wang Tonghe,Curran Walter J.,Liu Tian,Yang Xiaofeng","Fu YB,Lei Y,Wang TH,Curran WJ,Liu T,Yang XF",Yang XF,10.1088/1361-6560/ab843e,Emory University,"This paper presents a review of deep learning (DL)-based medical image registration methods. We summarized the latest developments and applications of DL-based registration methods in the medical field. These methods were classified into seven categories according to their methods, functions and popularity. A detailed review of each category was presented, highlighting important contributions and identifying specific challenges. A short assessment was presented following the detailed review of each category to summarize its achievements and future potential. We provided a comprehensive comparison among DL-based methods for lung and brain registration using benchmark datasets. Lastly, we analyzed the statistics of all the cited works from various aspects, revealing the popularity and future trend of DL-based medical image registration.","deep learning,medical image registration,review",Review,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"DEFORMABLE,REGISTRATION,DOSE,ACCUMULATION,NEURAL-NETWORKS,FRAMEWORK,RECONSTRUCTION,MOTION,ACCURACY,LOCALIZATION,SEGMENTATION,MODEL",PHYSICS IN MEDICINE AND BIOLOGY,http://arxiv.org/pdf/1912.12318,
20,Frontiers in atomistic simulations of high entropy alloys,128,15,,"Ferrari Alberto,Dutta Biswanath,Gubaev Konstantin,Ikeda Yuji,Srinivasan Prashanth,Grabowski Blazej,Koermann Fritz","Ferrari A,Dutta B,Gubaev K,Ikeda Y,Srinivasan P,Grabowski B,Kormann F",Ferrari A,10.1063/5.0025310,Delft University of Technology,"The field of atomistic simulations of multicomponent materials and high entropy alloys is progressing rapidly, with challenging problems stimulating new creative solutions. In this Perspective, we present three topics that emerged very recently and that we anticipate will determine the future direction of research of high entropy alloys: the usage of machine-learning potentials for very accurate thermodynamics, the exploration of short-range order and its impact on macroscopic properties, and the more extensive exploitation of interstitial alloying and high entropy alloy surfaces for new technological applications. For each of these topics, we briefly summarize the key achievements, point out the aspects that still need to be addressed, and discuss possible future improvements and promising directions.","SHORT-RANGE ORDER,HYDROGEN STORAGE PROPERTIES,MECHANICAL-PROPERTIES,TENSILE PROPERTIES,POTENTIAL MODEL,CARBON,MICROSTRUCTURE,ABSORPTION,PLASTICITY,CRMNFECONI",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,"SHORT-RANGE,ORDER,HYDROGEN,STORAGE,PROPERTIES,MECHANICAL-PROPERTIES,TENSILE,PROPERTIES,POTENTIAL,MODEL,CARBON,MICROSTRUCTURE,ABSORPTION,PLASTICITY,CRMNFECONI",JOURNAL OF APPLIED PHYSICS,https://aip.scitation.org/doi/pdf/10.1063/5.0025310,
21,Sensitivity analysis of FDG PET tumor voxel cluster radiomics and dosimetry for predicting mid-chemoradiation regional response of locally advanced lung cancer,65,20,,"Duan Chunyan,Chaovalitwongse W. Art,Bai Fangyun,Hippe Daniel S.,Wang Shouyi,Thammasorn Phawis,Pierce Larry A.,Liu Xiao,You Jianxin,Miyaoka Robert S.","Duan CY,Chaovalitwongse WA,Bai FY,Hippe DS,Wang SY,Thammasorn P,Pierce LA,Liu X,You JX,Miyaoka RS",Bowen SR,10.1088/1361-6560/abb0c7,University of Washington,"We investigated the sensitivity of regional tumor response prediction to variability in voxel clustering techniques, imaging features, and machine learning algorithms in 25 patients with locally advanced non-small cell lung cancer (LA-NSCLC) enrolled on the FLARE-RT clinical trial. Metabolic tumor volumes (MTV) from pre-chemoradiation (PETpre) and mid-chemoradiation fluorodeoxyglucose-positron emission tomography (FDG PET) images (PETmid) were subdivided into K-means or hierarchical voxel clusters by standardized uptake values (SUV) and 3D-positions. MTV cluster separability was evaluated by CH index, and morphologic changes were captured by Dice similarity and centroid Euclidean distance. PETpre conventional features included SUVmean, MTV/MTV cluster size, and mean radiation dose. PETpre radiomics consisted of 41 intensity histogram and 3D texture features (PET Oncology Radiomics Test Suite) extracted from MTV or MTV clusters. Machine learning models (multiple linear regression, support vector regression, logistic regression, support vector machines) of conventional features or radiomic features were constructed to predict PETmid response. Leave-one-out-cross-validated root-mean-squared-error (RMSE) for continuous response regression (Delta SUVmean) and area-under-receiver-operating-characteristic-curve (AUC) for binary response classification were calculated. K-means MTV 2-clusters (MTVhi, MTVlo) achieved maximum CH index separability (Friedmanp< 0.001). Between PETpre and PETmid, MTV cluster pairs overlapped (Dice 0.70-0.87) and migrated 0.6-1.1 cm. PETmid Delta SUVmean response prediction was superior in MTV and MTVlo (RMSE = 0.17-0.21) compared to MTVhi (RMSE = 0.42-0.52, Friedmanp< 0.001). PETmid Delta SUVmean response class prediction performance trended higher in MTVlo (AUC = 0.83-0.88) compared to MTVhi (AUC = 0.44-0.58, Friedmanp= 0.052). Models were more sensitive to MTV/MTV cluster regions (Friedmanp= 0.026) than feature sets/algorithms (Wilcoxon signed-rankp= 0.36). Top-ranked radiomic features included GLZSM-LZHGE (large-zone-high-SUV), GTSDM-CP (cluster-prominence), GTSDM-CS (cluster-shade) and NGTDM-CNT (contrast). Top-ranked features were consistent between MTVhi and MTVlo cluster pairs but varied between MTVhi-MTVlo clusters, reflecting distinct regional radiomic phenotypes. Variability in tumor voxel cluster response prediction can inform robust radiomic target definition for risk-adaptive chemoradiation in patients with LA-NSCLC. FLARE-RT trial: NCT02773238.","tumor voxel clustering,machine learning,positron emission tomography,cancer response,radiomics,sensitivity analysis",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"POSITRON-EMISSION-TOMOGRAPHY,STANDARDIZED,UPTAKE,VALUE,RADIATION,ONCOLOGY,TEXTURE,FEATURES,F-18-FDG,UPTAKE,SURVIVAL,PRETREATMENT,THERAPY,HETEROGENEITY,SEGMENTATION",PHYSICS IN MEDICINE AND BIOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7593986,
22,Self-derived organ attention for unpaired CT-MRI deep domain adaptation based MRI segmentation,65,20,,"Jiang Jue,Hu Yu-Chi,Tyagi Neelam,Wang Chuang,Lee Nancy,Deasy Joseph O.,Sean Berry,Veeraraghavan Harini","Jiang J,Hu YC,Tyagi N,Wang C,Lee N,Deasy JO,Sean B,Veeraraghavan H",Veeraraghavan H,10.1088/1361-6560/ab9fca,Memorial Sloan Kettering Cancer Center,"To develop and evaluate a deep learning method to segment parotid glands from MRI using unannotated MRI and unpaired expert-segmented CT datasets. We introduced a new self-derived organ attention deep learning network for combined CT to MRI image-to-image translation (I2I) and MRI segmentation, all trained as an end-to-end network. The expert segmentations available on CT scans were combined with the I2I translated pseudo MR images to train the MRI segmentation network. Once trained, the MRI segmentation network alone is required. We introduced an organ attention discriminator that constrains the CT to MR generator to synthesize pseudo MR images that preserve organ geometry and appearance statistics as in real MRI. The I2I translation network training was regularized using the organ attention discriminator, global image-matching discriminator, and cycle consistency losses. MRI segmentation training was regularized by using cross-entropy loss. Segmentation performance was compared against multiple domain adaptation-based segmentation methods using the Dice similarity coefficient (DSC) and Hausdorff distance at the 95th percentile (HD95). All networks were trained using 85 unlabeled T2-weighted fat suppressed (T2wFS) MRIs and 96 expert-segmented CT scans. Performance upper-limit was based on fully supervised MRI training done using the 85 T2wFS MRI with expert segmentations. Independent evaluation was performed on 77 MRIs never used in training. The proposed approach achieved the highest accuracy (left parotid: DSC 0.82 +/- 0.03, HD95 2.98 +/- 1.01 mm; right parotid: 0.81 +/- 0.05, HD95 3.14 +/- 1.17 mm) compared to other methods. This accuracy was close to the reference fully supervised MRI segmentation (DSC of 0.84 +/- 0.04, a HD95 of 2.24 +/- 0.77 mm for the left parotid, and a DSC of 0.84 +/- 0.06 and HD95 of 2.32 +/- 1.37 mm for the right parotid glands).","unpaired adversarial domain adaptation,deep learning segmentation,organ attention discriminators,MRI,parotid gland",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,"HEAD,RADIOTHERAPY",PHYSICS IN MEDICINE AND BIOLOGY,,
23,Automatic multi-needle localization in ultrasound images using large margin mask RCNN for ultrasound-guided prostate brachytherapy,65,20,,"Zhang Yupei);,Tian Zhen);,Lei Yang);,Wang Tonghe);,Patel Pretesh);,Jani Ashesh B.);,Curran Walter J.);,Liu Tian);,Yang Xiaofeng","Zhang YP,Tian Z,Lei Y,Wang TH,Patel P,Jani AB,Curran WJ,Liu T,Yang XF",Yang XF,10.1088/1361-6560/aba410,Emory University,"Multi-needle localization in ultrasound (US) images is a crucial step of treatment planning for US-guided prostate brachytherapy. However, current computer-aided technologies are mostly focused on single-needle digitization, while manual digitization is labor intensive and time consuming. In this paper, we proposed a deep learning-based workflow for fast automatic multi-needle digitization, including needle shaft detection and needle tip detection. The major workflow is composed of two components: a large margin mask R-CNN model (LMMask R-CNN), which adopts the lager margin loss to reformulate Mask R-CNN for needle shaft localization, and a needle based density-based spatial clustering of application with noise algorithm which integrates priors to model a needle in an iteration for a needle shaft refinement and tip detections. Besides, we use the skipping connection in neural network architecture to improve the supervision in hidden layers. Our workflow was evaluated on 23 patients who underwent US-guided high-dose-rate (HDR) prostrate brachytherapy with 339 needles being tested in total. Our method detected 98% of the needles with 0.091 +/- 0.043 mm shaft error and 0.330 +/- 0.363 mm tip error. Compared with only using Mask R-CNN and only using LMMask R-CNN, the proposed method gains a significant improvement on both shaft error and tip error. The proposed method automatically digitizes needles per patient with in a second. It streamlines the workflow of transrectal ultrasound-guided HDR prostate brachytherapy and paves the way for the development of real-time treatment planning system that is expected to further elevate the quality and outcome of HDR prostate brachytherapy.","multi-needle localization,mask RCNN,DBSCAN algorithm,ultrasound images,US-guided HDR prostate brachytherapy,deep learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Radiology, Nuclear Medicine & Medical Imaging",,3.554,RANSAC,PHYSICS IN MEDICINE AND BIOLOGY,,
24,,,,,,,,,,,,,,,,,,,,
25,"Evaluating Pu-239(n,f) cross sections via machine learning using experimental data, covariances, and measurement features",978,,,"Whewell B.,Grosskopf M.,Neudecker D.","Whewell B,Grosskopf M,Neudecker D",Whewell B,10.1016/j.nima.2020.164305,University of Notre Dame,"The neutron-induced Pu-239 fission cross section, Pu-239(n,f), is evaluated from 1-20 MeV using experimental data and associated covariances while also considering information on the measurement, termed features here. For instance, methods to determine the background, sample backing material, or impurities in the sample, are explicitly taken into account in the evaluation process. To this end, outliers in the experimental data are identified with a modified version of the Hybrid Robust Support Vector Machine. In a second step, two machine learning methods (logistic regression with elastic net regularization and random forest regression with SHAP feature importance metric) are used to highlight measurement features that are common among many of the outlying data points. Based on this analysis, penalty uncertainties are added to the experimental covariances of outlying data points that have outlier measurement features and are put through the generalized-least-squares evaluation. The resulting evaluated mean values and covariances differ distinctly from those data evaluated without the penalty uncertainties. These results highlight that certain measurement features should be more closely examined.","Nuclear-data evaluation,Machine learning,Pu-239(n,f) cross section,Uncertainty quantification",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Nuclear Science & Technology,Physics",,1.502,"U-235,NEUTRONS,SELECTION,PU-240",NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT,https://www.osti.gov/biblio/1638632,
26,A microstructural neural network biomarker for dystonia diagnosis identified by a DystoniaNet deep learning platform,117,42,26398-26405,"Valeriani Davide,Simonyan Kristina","Valeriani D,Simonyan K",Simonyan K,10.1073/pnas.2009165117,Harvard University,"Isolated dystonia is a neurological disorder of heterogeneous pathophysiology, which causes involuntary muscle contractions leading to abnormal movements and postures. Its diagnosis is remarkably challenging due to the absence of a biomarker or gold standard diagnostic test. This leads to a low agreement between clinicians, with up to 50% of cases being misdiagnosed and diagnostic delays extending up to 10.1 y. We developed a deep learning algorithmic platform, DystoniaNet, to automatically identify and validate a microstructural neural network biomarker for dystonia diagnosis from raw structural brain MRIs of 612 subjects, including 392 patients with three different forms of isolated focal dystonia and 220 healthy controls. DystoniaNet identified clusters in corpus callosum, anterior and posterior thalamic radiations, inferior fronto-occipital fasciculus, and inferior temporal and superior orbital gyri as the biomarker components. These regions are known to contribute to abnormal interhemispheric information transfer, heteromodal sensorimotor processing, and executive control of motor commands in dystonia pathophysiology. The DystoniaNet-based biomarker showed an overall accuracy of 98.8% in diagnosing dystonia, with a referral of 3.5% of cases due to diagnostic uncertainty. The diagnostic decision by DystoniaNet was computed in 0.36 s per subject. DystoniaNet significantly outperformed shallow machine-learning algorithms in benchmark comparisons, showing nearly a 20% increase in its diagnostic performance. Importantly, the microstructural neural network biomarker and its DystoniaNet platform showed substantial improvement over the current 34% agreement on dystonia diagnosis between clinicians. The translational potential of this biomarker is in its highly accurate, interpretable, and generalizable performance for enhanced clinical decision-making.","dystonia,biomarker,machine learning,brain MRI",Article,"NATL ACAD SCIENCES, 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA",Science & Technology - Other Topics,,12.291,"VOXEL-BASED,MORPHOMETRY,SPASMODIC,DYSPHONIA,CONSENSUS,STATEMENT,CERVICAL,DYSTONIA,TASK,ACTIVATION,PHENOTYPE,GENOTYPE,DELAYS",PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA,https://www.pnas.org/content/pnas/117/42/26398.full.pdf,
27,Breast ultrasound lesion classification based on image decomposition and transfer learning,47,12,6257-6269,"Zhuang Zhemin,Kang Yuqiang,Raj Alex Noel Joseph,Yuan Ye,Ding Wanli,Qiu Shunmin","Zhuang ZM,Kang YQ,Raj ANJ,Yuan Y,Ding WL,Qiu SM",Raj ANJ,10.1002/mp.14510,Shantou University,"Purpose In medical image analysis, deep learning has great application potential. Discovering a method for extracting valuable information from medical images and integrating that information closely with medical treatment has recently become a major topic of interest. Because obtaining large volumes of breast lesion ultrasound image data is difficult, transfer learning is usually employed to obtain benign and malignant classification of breast lesions. However, because of blurred unclear regions of interest in breast lesion ultrasound images and severe speckle noise interference, convolutional neural networks have proven ineffective in extracting features, thus providing unreliable classification results. Methods This study employs image decomposition to obtain fuzzy enhanced and bilateral filtered images to enrich input information of breast lesions. Fuzzy enhanced, bilateral filtered, and original ultrasound images comprise multifeature data, which are presented as inputs to a pre-trained model to realize knowledge fusion. Therefore, effective features of breast lesions are extracted and then used to train fully connected layers with ground truths provided by a doctor to accomplish the classification. Results A pre-trained VGG16 model was used to extract features from multifeature data, and these features were fused to train the fully connected layers to realize classification. The performance score reported is as follows: accuracy of 93%, sensitivity of 95%, specificity of 88%, F1 score of 0.93, and AUC of 0.97. Conclusions Compared with using a single original ultrasound image for feature extraction, multifeature data based on image decomposition enables the pre-trained model to extract more relevant features, thereby providing better classification results than those from traditional transfer learning techniques.","bilateral filtering,breast lesion ultrasound images,feature extraction,fuzzy enhancement,transfer learning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,,MEDICAL PHYSICS,,
28,Large-Scale Atomic Simulation via Machine Learning Potentials Constructed by Global Potential Energy Surface Exploration,53,10,2119-2129,"Kang Pei-Lin,Shang Cheng,Liu Zhi-Pan","Kang PL,Shang C,Liu ZP",Shang C; Liu ZP,10.1021/acs.accounts.0c00472,Fudan University,"Atomic simulations based on quantum mechanics (QM) calculations have entered into the tool box of chemists over the past few decades, facilitating an understanding of a wide range of chemistry problems, from structure characterization to reactivity determination. Due to the poor scaling and high computational cost intrinsic to QM calculations, one has to either sacrifice accuracy or time when performing large-scale atomic simulations. The battle to find a better compromise between accuracy and speed has been central to the development of new theoretical methods.
The recent advances of machine-learning (ML)-based large-scale atomic simulations has shown great promise to the benefit of many branches of chemistry. Instead of solving the Schrodinger equation directly, ML-based simulations rely on a large data set of accurate potential energy surfaces (PESs) and complex numerical models to predict the total energy. These simulations feature both a high speed and a high accuracy for computing large systems. Due to the lack of a physical foundation in numerical models, ML models are often frustrated in their predictivity and robustness, which are key to applications. Focusing on these concerns, here we overview the recent advances in ML methodologies for atomic simulations on three key aspects. Namely, the generation of a representative data set, the extensity of ML models, and the continuity of data representation. While global optimization methods are the natural choice for building a representative data set, the stochastic surface walking method is shown to provide the desired PES sampling for both minima and transition regions on the PES. The current ML models generally utilize local geometrical descriptors as an input and consider the total energy as the sum of atomic energies. There are many flavors of data descriptors and ML models, but the applications for material and reaction predictions are still limited, not least because of the difficulty to train the associated vast global data sets. We show that our recently designed power-type structure descriptors together with a feed-forward neural network (NN) model are compatible with highly complex global PES data, which has led to a large family of global NN (G-NN) potentials. Two recent applications of G-NN potentials in material and reaction simulations are selected to illustrate how ML-based atomic simulations can help the discovery of new materials and reactions.","PHASE-TRANSITION,STRUCTURE PREDICTION,CHEMICAL UNIVERSE,GLUCOSE PYROLYSIS,WALKING METHOD,OPTIMIZATION,MODEL,SELECTIVITY,MOLECULES,CHEMISTRY",Review,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,22.732,"PHASE-TRANSITION,STRUCTURE,PREDICTION,CHEMICAL,UNIVERSE,GLUCOSE,PYROLYSIS,WALKING,METHOD,OPTIMIZATION,MODEL,SELECTIVITY,MOLECULES,CHEMISTRY",ACCOUNTS OF CHEMICAL RESEARCH,,
29,Parametric study of hydrogenic inventory in the ITER divertor based on machine learning,10,1,,"Delaporte-Mathurin Remi,Hodille Etienne,Mougenot Jonathan,De Temmerman Gregory,Charles Yann,Grisolia Christian","Delaporte-Mathurin R,Hodille E,Mougenot J,De Temmerman G,Charles Y,Grisolia C",Delaporte-Mathurin R,10.1038/s41598-020-74844-w,CEA,"A parametric study is performed with the 2D FESTIM code for the ITER monoblock geometry. The influence of the monoblock surface temperature, the incident ion energy and particle flux on the monoblock hydrogen inventory is investigated. The simulated data is analysed with a Gaussian regression process and an inventory map as a function of ion energy and incident flux is given. Using this inventory map, the hydrogen inventory in the divertor is easily derived for any type of scenario. Here, the case of a detached ITER scenario with inputs from the SOLPS code is presented. For this scenario, the hydrogen inventory per monoblock is highly dependent of surface temperature and ranges from 1018 to 6x1019 H after a 107 s exposure. The inventory evolves as a power law of time and is lower at strike points where the surface temperature is high. Hydrogen inventory in the whole divertor after a 107 s exposure is estimated at approximately 8 g.","DEUTERIUM TRANSPORT,TUNGSTEN,RETENTION,DIFFUSION",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,5.134,"DEUTERIUM,TRANSPORT,TUNGSTEN,RETENTION,DIFFUSION",SCIENTIFIC REPORTS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7576168,
30,,,,,,,,,,,,,,,,,,,,
31,,,,,,,,,,,,,,,,,,,,
32,,,,,,,,,,,,,,,,,,,,
33,Quantitative ultrasound radiomics using texture derivatives in prediction of treatment response to neo-adjuvant chemotherapy for locally advanced breast cancer.,11,42,3782-3792,,,,10.18632/oncotarget.27742,,"BACKGROUND: To investigate quantitative ultrasound (QUS) based higher-order texture derivatives in predicting the response to neoadjuvant chemotherapy (NAC) in patients with locally advanced breast cancer (LABC).RESULTS: A KNN-model provided the best results with sensitivity, specificity, accuracy, and area under curve (AUC) of 87%, 81%, 82%, and 0.86, respectively. The most helpful features in separating the two response groups were QUS-Tex1-Tex2 features. The 5-year recurrence-free survival (RFS) calculated for KNN predicted responders and non-responders using QUS-Tex1-Tex2 model were comparable to RFS for the actual response groups.CONCLUSIONS: We report the first study demonstrating QUS texture-derivative methods in predicting NAC responses in LABC, which leads to better results compared to using texture features alone. Copyright: © 2020 Dasgupta et al.",breast cancer; neoadjuvant chemotherapy; quantitative ultrasound; radiomics; texture derivatives,Journal Article,,,,,,,,
34,Analogue computing with metamaterials,6,3,207-225,"Zangeneh-Nejad Farzad,Sounas Dimitrios L.,Alu Andrea,Fleury Romain","Zangeneh-Nejad F,Sounas DL,Alu A,Fleury R",Fleury R,10.1038/s41578-020-00243-2,Ecole Polytechnique Federale de Lausanne,"Metamaterials provide a platform to leverage optical signals for performing specific-purpose computational tasks with ultra-fast speeds. This Review surveys the basic principles, recent advances and promising future directions for wave-based-metamaterial analogue computing systems.
Despite their widespread use for performing advanced computational tasks, digital signal processors suffer from several restrictions, including low speed, high power consumption and complexity, caused by costly analogue-to-digital converters. For this reason, there has recently been a surge of interest in performing wave-based analogue computations that avoid analogue-to-digital conversion and allow massively parallel operation. In particular, novel schemes for wave-based analogue computing have been proposed based on artificially engineered photonic structures, that is, metamaterials. Such kinds of computing systems, referred to as computational metamaterials, can be as fast as the speed of light and as small as its wavelength, yet, impart complex mathematical operations on an incoming wave packet or even provide solutions to integro-differential equations. These much-sought features promise to enable a new generation of ultra-fast, compact and efficient processing and computing hardware based on light-wave propagation. In this Review, we discuss recent advances in the field of computational metamaterials, surveying the state-of-the-art metastructures proposed to perform analogue computation. We further describe some of the most exciting applications suggested for these computing systems, including image processing, edge detection, equation solving and machine learning. Finally, we provide an outlook for the possible directions and the key problems for future research.","SPATIAL DIFFERENTIATION,MATHEMATICAL OPERATIONS,PLASMONIC CIRCUIT,LAPLACE OPERATOR,FRACTIONAL-ORDER,SLAB,TIME,METASURFACE,INTEGRATION,RESOLUTION",Review,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Science & Technology - Other Topics,Materials Science",,98.837,"SPATIAL,DIFFERENTIATION,MATHEMATICAL,OPERATIONS,PLASMONIC,CIRCUIT,LAPLACE,OPERATOR,FRACTIONAL-ORDER,SLAB,TIME,METASURFACE,INTEGRATION,RESOLUTION",NATURE REVIEWS MATERIALS,,
35,N2NSR-OCT: Simultaneous denoising and super-resolution in optical coherence tomography images using semisupervised deep learning,14,1,,"Qiu Bin,You Yunfei,Huang Zhiyu,Meng Xiangxi,Jiang Zhe,Zhou Chuanqing,Liu Gangjun,Yang Kun,Ren Qiushi,Lu Yanye","Qiu B,You YF,Huang ZY,Meng XX,Jiang Z,Zhou CQ,Liu GJ,Yang K,Ren QS,Lu YY",Lu YY,10.1002/jbio.202000282,Peking University,"Optical coherence tomography (OCT) imaging shows a significant potential in clinical routines due to its noninvasive property. However, the quality of OCT images is generally limited by inherent speckle noise of OCT imaging and low sampling rate. To obtain high signal-to-noise ratio (SNR) and high-resolution (HR) OCT images within a short scanning time, we presented a learning-based method to recover high-quality OCT images from noisy and low-resolution OCT images. We proposed a semisupervised learning approach named N2NSR-OCT, to generate denoised and super-resolved OCT images simultaneously using up- and down-sampling networks (U-Net (Semi) and DBPN (Semi)). Additionally, two different super-resolution and denoising models with different upscale factors (2xand 4x) were trained to recover the high-quality OCT image of the corresponding down-sampling rates. The new semisupervised learning approach is able to achieve results comparable with those of supervised learning using up- and down-sampling networks, and can produce better performance than other related state-of-the-art methods in the aspects of maintaining subtle fine retinal structures.","denoising,optical coherence tomography,semisupervised deep learning,super-resolution",Article,"WILEY-V C H VERLAG GMBH, POSTFACH 101161, 69451 WEINHEIM, GERMANY","Biochemistry & Molecular Biology,Biophysics,Optics",,3.403,"NOISE-REDUCTION,NEURAL-NETWORK,SPECKLE",JOURNAL OF BIOPHOTONICS,,
36,A generative adversarial network-based (GAN-based) architecture for automatic fiducial marker detection in prostate MRI-only radiotherapy simulation images,47,12,6405-6413,"Singhrao Kamal,Fu Jie,Parikh Neil R.,Mikaeilian Argin G.,Ruan Dan,Kishan Amar U.,Lewis John H.","Singhrao K,Fu J,Parikh NR,Mikaeilian AG,Ruan D,Kishan AU,Lewis JH",Lewis JH,10.1002/mp.14498,Cedars Sinai Medical Center,"Purpose Clinical sites utilizing magnetic resonance imaging (MRI)-only simulation for prostate radiotherapy planning typically use fiducial markers for pretreatment patient positioning and alignment. Fiducial markers appear as small signal voids in MRI images and are often difficult to discern. Existing clinical methods for fiducial marker localization require multiple MRI sequences and/or manual interaction and specialized expertise. In this study, we develop a robust method for automatic fiducial marker detection in prostate MRI simulation images and quantify the pretreatment alignment accuracy using automatically detected fiducial markers in MRI. Methods and Materials In this study, a deep learning-based algorithm was used to convert MRI images into labeled fiducial marker volumes. Seventy-seven prostate cancer patients who received marker implantation prior to MRI and CT simulation imaging were selected for this study. Multiple-Echo T-1-VIBE MRI images were acquired, and images were stratified (at the patient level) based on the presence of intraprostatic calcifications. Ground truth (GT) contours were defined by an expert on MRI using CT images. Training was done using the pix2pix generative adversarial network (GAN) image-to-image translation package and model testing was done using fivefold cross validation. For performance comparison, an experienced medical dosimetrist and a medical physicist each manually contoured fiducial markers in MRI images. The percent of correct detections and F(1)classification scores are reported for markers detected using the automatic detection algorithm and human observers. The patient positioning errors were quantified by calculating the target registration errors (TREs) from fiducial marker driven rigid registration between MRI and CBCT images. Target registration errors were quantified for fiducial marker contours defined on MRI by the automatic detection algorithm and the two expert human observers. Results Ninety-six percent of implanted fiducial markers were correctly identified using the automatic detection algorithm. Two expert raters correctly identified 97% and 96% of fiducial markers, respectively. The F(1)classification score was 0.68, 0.75, and 0.72 for the automatic detection algorithm and two human raters, respectively. The main source of false discoveries was intraprostatic calcifications. The mean TRE differences between alignments from automatic detection algorithm and human detected markers and GT were We have developed a deep learning-based approach to automatically detect fiducial markers in MRI-only simulation images in a clinically representative patient cohort. The automatic detection algorithm-predicted markers can allow for patient setup with similar accuracy to independent human observers.","deep learning,fiducial markers,MRI-only simulation,MRI in treatment planning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"GUIDED,RADIOTHERAPY,RADIATION-THERAPY,CANCER,CALCIFICATIONS,VISIBILITY,CNN",MEDICAL PHYSICS,,
37,A neural network constitutive model for hyperelasticity based on molecular dynamics simulations,122,1,5-24,"Chung Ingyun,Im Sunyoung,Cho Maenghyo","Chung I,Im S,Cho M",Cho M,10.1002/nme.6459,Seoul National University (SNU),"Numerical analysis of the hyperelastic behavior of polymer materials has drawn significant interest from within the field of mechanical engineering. Currently, hyperelastic models based on the energy density function, such as the Neo-Hookean, Mooney-Rivlin, and Ogden models, are used to investigate the hyperelastic responses of materials. Conventionally, constants relating to materials were determined from experimental data by using global least-squares fitting. However, formulating a constitutive equation to capture the complex behavior of hyperelastic materials was difficult owing to the limitations of the analytical model and experimental data. This study addresses these limitations by using a system of neural networks (NNs) to design a data-driven surrogate model without a specific function formula, and employs molecular dynamics (MD) simulations to calculate the massive amount of combined loading data of hyperelastic materials. Thus, MD simulations were used to propose an NN constitutive model for hyperelasticity to derive the constitutive equation to model the complex hyperelastic response. In addition, the probability distributions of the numerical solutions of hyperelasticity are used to characterize the uncertainty of the MD models. These statistical finite element results not only present numerical results with reliability ranges but also scattered distributions of the solution obtained from the MD-based probability distributions.","constitutive equations,finite element methods,hyperelasticity,machine learning,molecular dynamics simulations,neural network",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Mathematics",,3.593,"MATERIAL,BEHAVIOR,POLYMER,MELTS,POLYSTYRENE,ELASTICITY,EQUATION",INTERNATIONAL JOURNAL FOR NUMERICAL METHODS IN ENGINEERING,,
38,Detection of Defects in Additively Manufactured Stainless Steel 316L with Compact Infrared Camera and Machine Learning Algorithms,72,12,4244-4253,"Zhang Xin,Saniie Jafar,Heifetz Alexander","Zhang X,Saniie J,Heifetz A",Heifetz A,10.1007/s11837-020-04428-6,United States Department of Energy (DOE),"Additive manufacturing (AM) is an emerging method for cost-efficient fabrication of nuclear reactor parts. AM of metallic structures for nuclear energy applications is currently based on the laser powder bed fusion process, which can introduce internal material flaws, such as pores and anisotropy. Integrity of AM structures needs to be evaluated nondestructively because material flaws could lead to premature failures due to exposure to high temperature, radiation and corrosive environments in a nuclear reactor. Thermal tomography (TT) provides a capability for non-destructive evaluation of sub-surface defects in arbitrary size structures. We investigate TT of AM stainless steel 316L specimens with imprinted internal porosity defects using a relatively low-cost, small form factor infrared camera based on an uncooled micro-bolometer detector. Sparse coding-relatedK-means singular value decomposition machine learning, image processing algorithms are developed to improve the quality of TT images through removal of additive white Gaussian noise without blurring the images.","CORROSION,PHYSICS",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Materials Science,Metallurgy & Metallurgical Engineering,Mineralogy,Mining & Mineral Processing",,2.989,"CORROSION,PHYSICS",JOM,,
39,Tool wear estimation in turning of Inconel 718 based on wavelet sensor signal analysis and machine learning paradigms,14,5-6,693-705,"Segreto Tiziana,D'Addona Doriana,Teti Roberto","Segreto T,D'Addona D,Teti R",Segreto T,10.1007/s11740-020-00989-2,University of Naples Federico II,"In the last years, hard-to-machine nickel-based alloys have been widely employed in the aerospace industry for their properties of high strength, excellent resistance to corrosion and oxidation, and long creep life at elevated temperatures. As the machinability of these materials is quite low due to high cutting forces, high temperature development and strong work hardening, during machining the cutting tool conditions tend to rapidly deteriorate. Thus, tool health monitoring systems are highly desired to improve tool life and increase productivity. This research work focuses on tool wear estimation during turning of Inconel 718 using wavelet packet transform (WPT) signal analysis and machine learning paradigms. A multiple sensor monitoring system, based on the detection of cutting force, acoustic emission and vibration acceleration signals, was employed during experimental turning trials. The detected sensor signals were subjected to WPT decomposition to extract diverse signal features. The most relevant features were then selected, using correlation measurements, in order to be utilized in artificial neural network based machine learning paradigms for tool wear estimation.","Inconel 718,Tool wear,Multiple sensor monitoring,Wavelet packet transform,Machine learning,Artificial neural networks",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Engineering,,,"RESIDUAL-STRESS,VECTOR,MACHINE,PERFORMANCE,FUSION,OPTIMIZATION,INTELLIGENCE,SUPERALLOY,INTEGRITY",PRODUCTION ENGINEERING-RESEARCH AND DEVELOPMENT,https://link.springer.com/content/pdf/10.1007/s11740-020-00989-2.pdf,
40,Towards markerless computer-aided surgery combining deep segmentation and geometric pose estimation: application in total knee arthroplasty,9,3,271-278,"Felix Ines,Raposo Carolina,Antunes Michel,Rodrigues Pedro,Barreto Joao P.","Felix I,Raposo C,Antunes M,Rodrigues P,Barreto JP",Felix I,10.1080/21681163.2020.1835554,Universidade de Coimbra,"Total knee arthroplasty (TKA) is a surgical procedure performed in patients suffering from knee arthritis. The correct positioning of the implants is strongly related to multiple surgical variables that have a tremendous impact on the success of the surgery. Computer-based navigation systems have been investigated and developed in order to assist the surgeon in accurately controlling those surgical variables. The existing technologies are very costly, require additional bone incisions for fixing markers to be tracked, and these markers are usually bulky, interfering with the standard surgical flow. This work presents a markerless navigation system that supports the surgeon in accurately performing the TKA procedure. The proposed system uses a mobile RGB-D camera for replacing the existing optical tracking systems and does not require markers to be tracked. We combine an effective deep learning-based approach for accurately segmenting the bone surface with a robust geometry-based algorithm for registering the bones with pre-operative models. The favourable performance of our pipeline is achieved by (1) employing a semi-supervised labelling approach for generating training data from real TKA surgery data, (2) using effective data augmentation techniques for improving the generalisation capability and (3) using appropriate depth data cleaning strategies. The construction of this complete markerless registration prototype that generalises for unseen intra-operative data is non-obvious, and relevant insights and future research directions can be derived. The experimental results show encouraging performance for video-based TKA.","Markerless navigation,deep learning,image segmentation,pose estimation,knee surgery",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,,"OF-THE-ART,NAVIGATION,STATE,TKA",COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION,,
41,A multiple-channel and atrous convolution network for ultrasound image segmentation,47,12,6270-6285,"Zhang Lun,Zhang Junhua,Li Zonggui,Song Yingchao","Zhang L,Zhang JH,Li ZG,Song YC",Zhang JH,10.1002/mp.14512,Yunnan University,"Purpose Ultrasound image segmentation is a challenging task due to a low signal-to-noise ratio and poor image quality. Although several approaches based on the convolutional neural network (CNN) have been applied to ultrasound image segmentation, they have weak generalization ability. We propose an end-to-end, multiple-channel and atrous CNN designed to extract a greater amount of semantic information for segmentation of ultrasound images. Method A multiple-channel and atrous convolution network is developed, referred to as MA-Net. Similar to U-Net, MA-Net is based on an encoder-decoder architecture and includes five modules: the encoder, atrous convolution, pyramid pooling, decoder, and residual skip pathway modules. In the encoder module, we aim to capture more information with multiple-channel convolution and use large kernel convolution instead of small filters in each convolution operation. In the last layer, atrous convolution and pyramid pooling are used to extract multi-scale features. The architecture of the decoder is similar to that of the encoder module, except that up-sampling is used instead of down-sampling. Furthermore, the residual skip pathway module connects the subnetworks of the encoder and decoder to optimize learning from the deeper layer and improve the accuracy of segmentation. During the learning process, we adopt multi-task learning to enhance segmentation performance. Five types of datasets are used in our experiments. Because the original training data are limited, we apply data augmentation (e.g., horizontal and vertical flipping, random rotations, and random scaling) to our training data. We use the Dice score, precision, recall, Hausdorff distance (HD), average symmetric surface distance (ASD), and root mean square symmetric surface distance (RMSD) as the metrics for segmentation evaluation. Meanwhile, Friedman test was performed as the nonparametric statistical analysis to evaluate the algorithms. Results For the datasets of brachia plexus (BP), fetal head, and lymph node segmentations, MA-Net achieved average Dice scores of 0.776, 0.973, and 0.858, respectively; with average precisions of 0.787, 0.968, and 0.854, respectively; average recalls of 0.788, 0.978, and 0.885, respectively; average HDs (mm) of 13.591, 10.924, and 19.245, respectively; average ASDs (mm) of 4.822, 4.152, and 4.312, respectively; and average RMSDs (mm) of 4.979, 4.161, and 4.930, respectively. Compared with U-Net, U-Net++, M-Net, and Dilated U-Net, the average performance of the MA-Net increased by approximately 5.68%, 2.85%, 6.59%, 36.03%, 23.64%, and 31.71% for Dice, precision, recall, HD, ASD, and RMSD, respectively. Moreover, we verified the generalization of MA-Net segmentation to lower grade brain glioma MRI and lung CT images. In addition, the MA-Net achieved the highest mean rank in the Friedman test. Conclusion The proposed MA-Net accurately segments ultrasound images with high generalization, and therefore, it offers a useful tool for diagnostic application in ultrasound images.","atrous convolution,multiple-channel convolution,pyramid pooling,ultrasound image",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"NEURAL-NETWORKS,DEEP",MEDICAL PHYSICS,,
42,Computational materials design: recent advances and open challenges related to colorimetry,136,6,535-538,"Tremeau Alain,Colantoni Philippe,Hebert Mathieu","Tremeau A,Colantoni P,Hebert M",Tremeau A,10.1111/cote.12498,Centre National de la Recherche Scientifique (CNRS),"Computational materials design aims at designing, simulating and predicting innovative materials. This paper reviews a few open challenges in the domain of computational materials design related to the colour appearance of materials. These relatively recent fields of research necessitate revisiting the fundamentals of colorimetry, such as reflectance models. First, we address the virtual design and the simulation of innovative materials, which requires modelling their appearance and fundamental properties. Then we discuss the latest advancements in the machine-learning domain that have highly revolutionised computational and data-minded methodologies, which are used for the design innovation, discovery and optimisation of materials.",MATERIALS DISCOVERY,Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Chemistry,Engineering,Materials Science",,1.737,"MATERIALS,DISCOVERY",COLORATION TECHNOLOGY,,
43,Identification of high-risk carotid plaque with MRI-based radiomics and machine learning,31,5,3116-3126,"Zhang Ranying,Zhang Qingwei,Ji Aihua,Lv Peng,Zhang Jingjing,Fu Caixia,Lin Jiang","Zhang RY,Zhang QW,Ji AH,Lv P,Zhang JJ,Fu CX,Lin J",Lin J,10.1007/s00330-020-07361-z,Fudan University,"Objectives We sought to build a high-risk plaque MRI-based model (HRPMM) using radiomics features and machine learning for differentiating symptomatic from asymptomatic carotid plaques. Materials and methods One hundred sixty-two patients with carotid stenosis were randomly divided into training and test cohorts. Multi-contrast MRI including time of flight (TOF), T1- and T2-weighted imaging, and contrast-enhanced imaging was done. Radiological characteristics of the carotid plaques were recorded and calculated to build a traditional model. After extracting the radiomics features on these images, we constructed HRPMM with least absolute shrinkage and selection operator algorithm in the training cohort and evaluated its performance in the test cohort. A combined model was also built using both the traditional and radiomics features. The performance of all the models in the identification of high-risk carotid plaque was compared. Results Intraplaque hemorrhage and lipid-rich necrotic core were independently associated with clinical symptoms and were used to build the traditional model, which achieved an area under the curve (AUC) of 0.825 versus 0.804 in the training and test cohorts. The HRPMM and the combined model achieved an AUC of 0.988 versus 0.984 and of 0.989 versus 0.986 respectively in the two cohorts. Both the radiomics model and combined model outperformed the traditional model, whereas the combined model showed no significant difference with the HRPMM. Conclusions Our MRI-based radiomics model can accurately distinguish symptomatic from asymptomatic carotid plaques. It is superior to the traditional model in the identification of high-risk plaques.","Magnetic resonance imaging,Stroke,Atherosclerotic plaques,Carotid artery,Machine learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,4.87,"TEXTURE,FEATURES,CANCER,ASSOCIATION,IMAGES,STROKE",EUROPEAN RADIOLOGY,,
44,Towards Hallucinating Machines-Designing with Computational Vision,19,1,88-103,"del Campo Matias,Carlson Alexandra,Manninger Sandra","del Campo M,Carlson A,Manninger S",del Campo M,10.1177/1478077120963366,University of Michigan System,"There are particular similarities in how machines learn about the nature of their environment, and how humans learn to process visual stimuli. Machine Learning (ML), more specifically Deep Neural network algorithms rely on expansive image databases and various training methods (supervised, unsupervised) to ""make sense"" out of the content of an image. Take for example how students of architecture learn to differentiate various architectural styles. Whether this be to differentiate between Gothic, Baroque or Modern Architecture, students are exposed to hundreds, or even thousands of images of the respective styles, while being trained by faculty to be able to differentiate between those styles. A reversal of the process, striving to produce imagery, instead of reading it and understanding its content, allows machine vision techniques to be utilized as a design methodology that profoundly interrogates aspects of agency and authorship in the presence of Artificial Intelligence in architecture design. This notion forms part of a larger conversation on the nature of human ingenuity operating within a posthuman design ecology. The inherent ability of Neural Networks to process large databases opens up the opportunity to sift through the enormous repositories of imagery generated by the architecture discipline through the ages in order to find novel and bespoke solutions to architectural problems. This article strives to demystify the romantic idea of individual artistic design choices in architecture by providing a glimpse under the hood of the inner workings of Neural Network processes, and thus the extent of their ability to inform architectural design. The approach takes cues from the language and methods employed by experts in Deep Learning such as Hallucinations, Dreaming, Style Transfer and Vision. The presented approach is the base for an in-depth exploration of its meaning as a cultural technique within the discipline. Culture in the extent of this article pertains to ideas such as the differentiation between symbolic and material cultures, in which symbols are defined as the common denominator of a specific group of people.(1)The understanding and exchange of symbolic values is inherently connected to language and code, which ultimately form the ingrained texture of any form of coded environment, including the coded structure of Neural Networks. A first proof of concept project was devised by the authors in the form of the Robot Garden. What makes theRobot Gardena distinctively novel project is the motion from a purely two dimensional approach to designing with the aid of Neural Networks, to the exploration of 2D to 3D Neural Style Transfer methods in the design process.","Artificial intelligence,design agency,neural networks,machine learning,machine vision",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND",Architecture,,,,INTERNATIONAL JOURNAL OF ARCHITECTURAL COMPUTING,,
45,Wireless power transfer-based eddy current non-destructive testing using a flexible printed coil array,378,2182,,"Daura Lawal Umar,Tian GuiYun,Yi Qiuji,Sophian Ali","Daura LU,Tian GY,Yi QJ,Sophian A",Tian GY,10.1098/rsta.2019.0579,Newcastle University - UK,"Eddy current testing (ECT) has been employed as a traditional non-destructive testing and evaluation (NDT&E) tool for many years. It has developed from single frequency to multiple frequencies, and eventually to pulsed and swept-frequency excitation. Recent progression of wireless power transfer (WPT) and flexible printed devices open opportunities to address challenges of defect detection and reconstruction under complex geometric situations. In this paper, a transmitter-receiver (Tx-Rx) flexible printed coil (FPC) array that uses the WPT approach featuring dual resonance responses for the first time has been proposed. The dual resonance responses can provide multiple parameters of samples, such as defect characteristics, lift-offs and material properties, while the flexible coil array allows area mapping of complex structures. To validate the proposed approach, experimental investigations of a single excitation coil with multiple receiving coils using the WPT principle were conducted on a curved pipe surface with a natural dent defect. The FPC array has one single excitation coil and 16 receiving (Rx) coils, which are used to measure the dent by using 21 C-scan points on the dedicated dent sample. The experimental data were then used for training and evaluation of dual resonance responses in terms of multiple feature extraction, selection and fusion for quantitative NDE. Four features, which include resonant magnitudes and principal components of the two resonant areas, were investigated for mapping and reconstructing the defective dent through correlation analysis for feature selection and feature fusion by deep learning. It shows that deep learning-based multiple feature fusion has outstanding performance for 3D defect reconstruction of WPT-based FPC-ECT. This article is part of the theme issue 'Advanced electromagnetic non-destructive evaluation and smart monitoring'.","eddy current testing,flexible coil array,feature extraction,selection and fusion,resonant frequency,wireless power transfer",Article,"ROYAL SOC, 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND",Science & Technology - Other Topics,,4.542,"FEATURE-EXTRACTION,SENSOR,ARRAY,FREQUENCY,PERFORMANCE,DESIGN",PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7536023,
46,Quality Control of Additively Manufactured Metallic Structures with Machine Learning of Thermography Images,72,12,4682-4694,"Zhang Xin,Saniie Jafar,Cleary William,Heifetz Alexander","Zhang X,Saniie J,Cleary W,Heifetz A",Heifetz A,10.1007/s11837-020-04408-w,United States Department of Energy (DOE),"Additive manufacturing (AM) of high-strength metals is currently based on the laser powder bed fusion (LPBF) process, which can introduce internal material flaws, such as pores and anisotropy. Quality control (QC) requires nondestructive evaluation of actual AM structures. Flash thermography is a potentially promising QC technique because it is scalable to arbitrary structure size. However, the detection sensitivity of this method is limited by noise. We investigate separation of signal from noise in thermography images using several machine learning (ML) methods, including new spatial-temporal blind source separation and spatial-temporal sparse dictionary learning methods. Performance of the ML methods is benchmarked using thermography data obtained from imaging stainless steel 316L and Inconel 718 specimens produced by the LPBF method with imprinted calibrated porosity defects. The ML methods are ranked by F-score and execution runtime. The ML methods with higher accuracy require a longer runtime. However, this runtime is sufficiently short to perform QC within a realistic time frame.",,Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Materials Science,Metallurgy & Metallurgical Engineering,Mineralogy,Mining & Mineral Processing",,2.989,,JOM,https://www.osti.gov/biblio/1774562,
47,Machine learning at the interface of structural health monitoring and non-destructive evaluation,378,2182,,"Gardner P.,Fuentes R.,Dervilis N.,Mineo C.,Pierce S. G.,Cross E. J.,Worden K.","Gardner P,Fuentes R,Dervilis N,Mineo C,Pierce SG,Cross EJ,Worden K",Worden K,10.1098/rsta.2019.0581,University of Sheffield,"While both non-destructive evaluation (NDE) and structural health monitoring (SHM) share the objective of damage detection and identification in structures, they are distinct in many respects. This paper will discuss the differences and commonalities and consider ultrasonic/guided-wave inspection as a technology at the interface of the two methodologies. It will discuss how data-based/machine learning analysis provides a powerful approach to ultrasonic NDE/SHM in terms of the available algorithms, and more generally, how different techniques can accommodate the very substantial quantities of data that are provided by modern monitoring campaigns. Several machine learning methods will be illustrated using case studies of composite structure monitoring and will consider the challenges of high-dimensional feature data available from sensing technologies like autonomous robotic ultrasonic inspection. This article is part of the theme issue 'Advanced electromagnetic non-destructive evaluation and smart monitoring'.","ultrasound,structural health monitoring,non-destructive evaluation,machine learning,compressive sensing,transfer learning",Article,"ROYAL SOC, 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND",Science & Technology - Other Topics,,4.542,"DAMAGE,DETECTION,STRATEGIES",PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES,https://iris.unipa.it/retrieve/handle/10447/435293/959504/RSTA-2019-0581.R1_Submitted.pdf,
48,Machine and Deep Learning Based Radiomics Models for Preoperative Prediction of Benign and Malignant Sacral Tumors,10,,,"Yin Ping,Mao Ning,Chen Hao,Sun Chao,Wang Sicong,Liu Xia,Hong Nan","Yin P,Mao N,Chen H,Sun C,Wang SC,Liu X,Hong N",Hong N,10.3389/fonc.2020.564725,Peking University,"Purpose
To assess the performance of deep neural network (DNN) and machine learning based radiomics on 3D computed tomography (CT) and clinical characteristics to predict benign or malignant sacral tumors.
Materials and methods
This single-center retrospective analysis included 459 patients with pathologically proven sacral tumors. After semi-automatic segmentation, 1,316 hand-crafted radiomics features of each patient were extracted. All models were built on training set (321 patients) and tested on validation set (138 patients). A DNN model and four machine learning classifiers (logistic regression [LR], random forest [RF], support vector machine [SVM] and k-nearest neighbor [KNN]) based on CT features and clinical characteristics were built, respectively. The area under the receiver operating characteristic curve (AUC) and accuracy (ACC) were used to evaluate different models.
Results
In total, 459 patients (255 males, 204 females; mean age of 42.1 +/- 17.8 years, range 4-82 years) were enrolled in this study, including 206 cases of benign tumor and 253 cases of malignant tumor. The sex, age and tumor size had significant differences between the benign tumors and malignant tumors (chi(2) (sex) = 10.854, Z(age) = -6.616, Z(size) = 2.843, P < 0.05). The radscore, sex, and age were important indicators for differentiating benign and malignant sacral tumors (odds ratio [OR]1 = 2.492, OR2 = 2.236, OR3 = 1.037, P < 0.01). Among the four clinical-radiomics models (RMs), clinical-LR had the best performance in the validation set (AUC = 0.84, ACC = 0.81). The clinical-DNN model also achieved a high performance (an AUC of 0.83 and an ACC of 0.76 in the validation set) in identifying benign and malignant sacral tumors.
Conclusions
Both the clinical-LR and clinical-DNN models would have a high impact on assisting radiologists in their clinical diagnosis of sacral tumors.","deep learning,radiomics,sacral tumors,machine learning,computed tomography",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Oncology,,6.264,,FRONTIERS IN ONCOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7596901,
49,Classification of magnetic resonance images for brain tumour detection,14,12,2808-2818,"Kurmi Yashwant,Chaurasia Vijayshri","Kurmi Y,Chaurasia V",Kurmi Y,10.1049/iet-ipr.2019.1631,National Institute of Technology (NIT System),"Image segmentation of magnetic resonance image (MRI) is a crucial process for visualisation and examination of abnormal tissues, especially during clinical analysis. Complexity and variations of the tumour structure magnify the challenges in the automated detection of a brain tumour in MRIs. This study presents an automatic lesion recognition method in the MRI followed by classification. In the proposed multistage image segmentation method, the intent region initialisation is performed using low-level information by the keypoint descriptors. A set of the linear filter is used to transform low-level information into higher-level image features. The set of features and filter training data are accomplished to track the tumour region. The authors adopt a possibilistic model for region growing, and disparity map for the refinement process to grave consist boundary. Further, the features are extracted using the Fisher vector and autoencoder. A set of handcrafted features is also extracted using a segmentation-based localised region to train and test the support vector machine and multilayer perceptron classifiers. The experiments that are performed using five MRI datasets confirm the superiority of proposal as that of the state-of-the-art methods. It reports 94.5 and 91.76%, average accuracy of segmentation and classification, respectively.","support vector machines,medical image processing,image segmentation,tumours,biomedical MRI,multilayer perceptrons,feature extraction,image classification,learning (artificial intelligence),brain,low-level information,linear filter,higher-level image features,handcrafted feature extraction,segmentation-based localised region,MRI datasets,magnetic resonance image,automatic lesion recognition method,multistage image segmentation method,automated brain tumour detection,multilayer perceptron classifiers,support vector machine,Fisher vector,disparity map",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"SEGMENTATION,REFINEMENT,ALGORITHM",IET IMAGE PROCESSING,,
50,Deep learning algorithm for breast masses classification in mammograms,14,12,2860-2868,"Gnanasekaran Vaira Suganthi,Joypaul Sutha,Meenakshi Sundaram Parvathy,Chairman Durga Devi","Gnanasekaran VS,Joypaul S,Sundaram PM,Chairman DD",Gnanasekaran VS,10.1049/iet-ipr.2020.0070,"Sethu Inst Technol, Kariapatti, Tamil Nadu, India.","A mammogram is an image of a breast used to detect and diagnose breast cancer. This paper emphases a Computer-Aided Detection system based on convolutional neural network (CNN) that uses the concept of deep learning to classify the mammogram images into benign, malignant and normal. The proposed CNN model consists of eight convolutional, four max-pooling and two fully connected layers and achieved better results compared to the pre-trained nets, AlexNet and VGG16. The proposed model demonstrates the feasibility of using CNNs on medical image processing techniques for the classification of breast masses. The results are also compared with the state-of-the-art machine learning algorithm like kNN classifier. Experimentation is done with three datasets. Among them, two are publicly available, Mammographic Image Analysis Society (MIAS), digital database for screening mammography (DDSM) and an internally collected dataset. The proposed model achieved accuracies of 92.54, 96.47 and 95 and the Area under the ROC curve (AUC) score of 0.85, 0.96 and 0.94 for MIAS, DDSM and the internally collected dataset respectively. Furthermore, the images of the three datasets are merged to build one large set and used to fine tune the proposed CNN model and produced accuracy of 98.32 and AUC of 0.98.","mammography,neural nets,image classification,cancer,learning (artificial intelligence),medical image processing,max-pooling,fully connected layers,pre-trained nets,medical image processing techniques,kNN classifier,Mammographic Image Analysis Society,internally collected dataset,CNN model,deep learning algorithm,breast masses classification,breast cancer,Computer-Aided Detection system,convolutional neural network,mammogram images,automatic classification",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"NEURAL-NETWORKS,SYSTEM",IET IMAGE PROCESSING,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-ipr.2020.0070,
51,Super-resolution image reconstruction using molecular docking,14,12,2922-2936,"Nayak Rajashree,Patra Dipti,Balabantaray Bunil Ku","Nayak R,Patra D,Balabantaray BK",Nayak R,10.1049/iet-ipr.2019.0491,National Institute of Technology (NIT System),"Molecular-docking is an essential tool in the drug designing process, where a small molecule ligand (drug) binds with disease-causing protein molecule to prevent its further activity. Docking process helps in predicting the most appropriate configuration and the optimal interaction energy between the interacting molecules (ligand and protein) to form a stable complex. Based on this idea, a new learning-based single image super-resolution reconstruction (LSI-SRR) method is proposed here. Estimation of a high resolution (HR) patch is achieved by optimising the interaction energy between the input low resolution patch and its corresponding candidate patches appropriately chosen from the training image dataset via Genetic algorithm. Structured-spatiogram based measure; a new and competent similarity criterion is proposed to select potentially efficient training images which encompass better statistical and structural co-relation with the input image. The proposed method is tested on synthetic and real-time images at different magnification factors. Performance analysis of the proposed work is compared with some of the representative state-of-the-art LSI-SRR methods. Experimental results demonstrate that the proposed method produces HR images with enhanced image details, minimal artefacts and most importantly enables an efficient trade-off between the image qualities to speed than the competing methods.","image reconstruction,diseases,image enhancement,molecular biophysics,genetic algorithms,proteins,learning (artificial intelligence),drugs,image resolution,medical image processing,super-resolution image reconstruction,molecular docking,drug designing process,disease-causing protein molecule,docking process,learning-based single image super-resolution reconstruction,high resolution patch,structured-spatiogram based measure,similarity criterion,image enhancement,image qualities,LSI-SRR",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,"SIMILARITY,ALGORITHM",IET IMAGE PROCESSING,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-ipr.2019.0491,
52,Backwash sequence optimization of a pilot-scale ultrafiltration membrane system using data-driven modeling for parameter forecasting,612,,,"Zhang Bopeng,Kotsalis Georgios,Khan Jahanzeb,Xiong Zhaoyang,Igou Thomas,Lan Guanghui,Chen Yongsheng","Zhang BP,Kotsalis G,Khan J,Xiong ZY,Igou T,Lan GH,Chen YS",Chen YS,10.1016/j.memsci.2020.118464,University System of Georgia,"Optimizing the backwashing procedure of ultrafiltration membranes poses novel challenges in regards to the modeling and simulation of the fouling process. Traditional modeling approaches the problem through a physical and chemical understanding of the complicated fouling phenomena. In this study, a large amount of data has been collected from a pilot-scale ultrafiltration membrane system treating spent filter backwash water at a water treatment plant. Environmental variables and operational parameters including temperature, hydraulic pressure, water turbidity, etc. are monitored continuously. This work focuses on revealing the hidden nonlinear relationships of these variables via data driven methodologies without building a first principles process model. Machine learning tools are used to establish a connection between environmental variables, dynamic parameters, the efficiency of foulant removal through backwashing, and the increase rate of foulants. The prediction performance is compared to regression models including linear regression, artificial neural networks, and random forests. Our data driven model of the fouling dynamics is then used for optimization purposes, in particular, to optimize the backwashing sequence timing by applying tools from stochastic dynamic programming. Optimized backwash performance is compared with experimental data acquired via a fixed interval sequence and shows a more efficient schedule at less cost and with lower membrane resistance. This work establishes a full pipeline of data processing, model building, and operational optimization. The only requirement for employing our methodology is the collection of operational data, in order to identify the membrane dynamics. The reported methodology offers a great potential for implementation on large-scale ultrafiltration applications, which can improve energy consumption and elongate membrane life.","Ultrafiltration membrane,Pilot-scale experiment,Data-driven modeling,System optimization,Membrane backwash",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Polymer Science",,8.411,"EXTRACELLULAR,POLYMERIC,SUBSTANCES,WATER-TREATMENT,ARTIFICIAL-INTELLIGENCE,HOLLOW-FIBER,MICROFILTRATION,COMMUNITY",JOURNAL OF MEMBRANE SCIENCE,,
53,Recognition Research on Concealing Behavior in Psychological Test,56,20,158-164,",,,,,,","Zhao Tong,Huang Zheng,Wang Xiuchao,Li Miao,Zhang Yun,Zheng Xiujuan,Liu Kai",,,Zhao Tong,"Electrocorticogram(EEG)can reveal people's psychological activities correctly,so EEG is widely used in psychological test.In this paper,a method based on the nonlinear feature fusion of EEG signals for concealing behavior recognition in the psychological test is presented.First,after pre-processing the EEG signals of the subject obtained in the psychological test,four nonlinear features,including Lempel-Ziv Complexity(LZC),Sample Entropy(SE),Permutation Entropy(PE)and Fuzzy Entropy(FE),are extracted.Then,the fusion and dimensionality reduction of the features by Multidimensional Scaling(MDS)is done.Finally,the Regularization Kernel Extreme Learning Machine(RKELM)is applied to construct the classifier and the performance of the four trained classifiers is verified by the test set.The experimental results show that the accuracy of the proposed system is 82.9%,which indicate the applicability of the proposed method.",concealing behavior; nonlinear feature; dimensionality reduction of multidimensional scaling; regularization kernel extreme learning machine,Article,,,,,,,,
54,Prediction of methane adsorption in shale: Classical models and machine learning based models,278,,,"Meng Meng,Zhong Ruizhi,Wei Zhili","Meng M,Zhong RZ,Wei ZL",Meng M,10.1016/j.fuel.2020.118358,United States Department of Energy (DOE),"Shale gas contributes significantly to current global energy consumption, and an accurate estimation of geological gas-in-place (GIP) determines an optimal production plan. As the dominant form of storage, adsorbed gas in shale formation is of primary importance to be assessed. This paper summarizes adsorption models into traditional pressure/density dependent isothermal models, pressure and temperature unified model, and machine learning based models. Using a comprehensive experimental dataset, these models are applied to simulate shale gas adsorption under in-situ conditions. Results show that the modified Dubinin-Radushkevich (DR) model provides the optimal performance in traditional isothermal models. Pressure and temperature unified models make a breakthrough in isothermal conditions and can extrapolate the predictions beyond test ranges of temperature. Well-trained machine learning models not only break the limit of the isothermal condition and types of shale formation, but can also provide reasonable extrapolations beyond test ranges of temperature, total organic carbon (TOC), and moisture. Four popular machine learning algorithms are used, which include artificial neural network (ANN), random forest (RF), support vector machine (SVM), and extreme gradient boosting (XGBoost). The XGBoost model is found to provide the best results for predicting shale gas adsorption, and it can be conveniently updated for broader applications with more available data. Overall, this paper demonstrates the capability of machine learning for prediction of shale gas adsorption, and the well-trained model can potentially be built into a large numerical frame to optimize production curves of shale gas.","Shale gas,Adsorption model,Classical model,Machine learning,XGBoost",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Energy & Fuels,Engineering",,6.63,"SUPERCRITICAL,METHANE,HIGH-PRESSURE,RESERVOIRS,EQUATION,COAL",FUEL,,
55,A Comparative Analysis of Machine Learning classifiers for Dysphonia-based classification of Parkinson's Disease,11,1,69-83,"Goyal Jinee,Khandnor Padmavati,Aseri Trilok Chand","Goyal J,Khandnor P,Aseri TC",Goyal J,10.1007/s41060-020-00234-0,Punjab Engineering College (Deemed University),"Parkinson's Disease is the second most common neurogenerative disease that affects the nervous system. There is no permanent cure for this disease, so, its early diagnosis is important to improve the quality of living of Parkinson patients. The distortion of the voice is one of the first symptoms to appear in Parkinson patients. Therefore, comparison and classification plays an important role. In this paper, a comparison of various classification techniques is done to show the potential of each classifier. The various classification techniques include SVM (Linear, RBF, Polynomial), DT, RF, LR, KNN, NB, MLP, AdaBoost, and XGBoost. Three different types of feature selection techniques are also explored to reduce the dimensionality of the dataset without affecting the accuracy much. The three different feature selection techniques include mRMR, GA, and PCA. The potential of voice features in classification process is also shown.","Parkinson's disease,Machine learning,Deep learning,Feature selection,Dimensionality reduction",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND",Computer Science,,,"SOCIETY-SPONSORED,REVISION,SCALE,MDS-UPDRS,FEATURE-SELECTION,ALGORITHMS,DIAGNOSIS,PERFORMANCE,PATTERNS,RANKING",INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS,,
56,Extracting Lungs from CT Images via Deep Convolutional Neural Network Based Segmentation and Two-Pass Contour Refinement,33,6,1465-1478,"Liu Caixia,Pang Mingyong","Liu CX,Pang MY",Pang MY,10.1007/s10278-020-00388-0,Nanjing Normal University,"Lung segmentation is a key step of thoracic computed tomography (CT) image processing, and it plays an important role in computer-aided pulmonary disease diagnostics. However, the presence of image noises, pathologies, vessels, individual anatomical varieties, and so on makes lung segmentation a complex task. In this paper, we present a fully automatic algorithm for segmenting lungs from thoracic CT images accurately. An input image is first spilt into a set of non-overlapping fixed-sized image patches, and a deep convolutional neural network model is constructed to extract initial lung regions by classifying image patches. Superpixel segmentation is then performed on the preprocessed thoracic CT image, and the lung contours are locally refined according to corresponding superpixel contours with our adjacent point statistics method. Segmented lung contours are further globally refined by an edge direction tracing technique for the inclusion of juxta-pleural lesions. Our algorithm is tested on a group of thoracic CT scans with interstitial lung diseases. Experiments show that our algorithm creates an average Dice similarity coefficient of 97.95% and Jaccard's similarity index of 94.48%, with 2.8% average over-segmentation rate and 3.3% under-segmentation rate compared with manually segmented results. Meanwhile, it shows better performance compared with several feature-based machine learning methods and current methods on lung segmentation.","Lung segmentation,Deep convolutional neural network,Superpixel segmentation,Contour correction",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Radiology, Nuclear Medicine & Medical Imaging",,3.977,"PATHOLOGICAL,LUNG,NODULE,DETECTION,THORACIC,CT,MODELS",JOURNAL OF DIGITAL IMAGING,,
57,A deep learning approach for prediction of syngas lower heating value from CFB gasifier in Aspen plus (R),209,,,"Kartal Furkan,Ozveren Ugur","Kartal F,Ozveren U",Ozveren U,10.1016/j.energy.2020.118457,Marmara University,"Aspen Plus (R) is one of the practicable software for investigation of the biomass gasification characteristics. Also, artificial neural networks (ANN) as a deep learning approach are often used in the prediction of parameters such as syngas composition, lower heating value (LHV), exergy, etc. However, to our best knowledge, a universal deep learning model based on the thermodynamic equilibrium approach to predict LHV of syngas in circulating fluidized bed (CFB) gasifier is not available in literature yet. In this paper, a unique CFB gasifier model was developed in Aspen Plus (R) as a tool to create a total of over 1 million datasets for the training of a deep learning model that predicts the LHV of the syngas. The CFB gasifier model was found to be in agreement with the results when compared with the experimental data in the literature. 56 biomass with various elemental and proximate properties were gasified in a newly developed CFB gasifier model under different operating conditions by using sensitivity analysis in Aspen Plus (R). A novel artificial neural network model, which is regularized with Levenberg-Marquardt algorithm was used as a deep learning model with a 6-12-1 tangent sigmoid architecture to predict LHV of syngas in circulating fluidized bed (CFB) gasifier, requiring minimal specificity as compared to commercial simulators require significant modelling effort and test runs. Results showed that the estimated LHV of the syngas in an agreement with the calculated values. The coefficient of determination score was calculated as R-2 > 0.99 for all datasets. (C) 2020 Elsevier Ltd. All rights reserved.","Biomass gasification,Deep learning,Circulating fluidized bed gasifier,Artificial neural network,Lower heating value,Aspen plus (R)",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Thermodynamics,Energy & Fuels",,6.845,"GIBBS,ENERGY,MINIMIZATION,FLUIDIZED-BED,REACTOR,BIOMASS,GASIFICATION,HYDROGEN-PRODUCTION,STEAM,GASIFICATION,CO-GASIFICATION,PART,I,SIMULATION,MODEL,EQUILIBRIUM",ENERGY,,
58,Machine learning in composites manufacturing: A case study of Automated Fiber Placement inspection,250,,,"Sacco Christopher,Radwan Anis Baz,Anderson Andrew,Harik Ramy,Gregory Elizabeth","Sacco C,Radwan AB,Anderson A,Harik R,Gregory E",Harik R,10.1016/j.compstruct.2020.112514,University of South Carolina System,"The large-scale adoption of composite materials in industry has allowed for a greater freedom in design and function of structures and their respective components. However, the freedom of material choice has resulted in increased complexity in manufacturing. Machine learning (ML) and Artificial Intelligence (AI) are currently being explored for a number of advanced manufacturing applications, and their applicability has begun to extend into the composites manufacturing realm. In this document, a comprehensive overview of machine learning applications in composites manufacturing will be presented with discussions on a novel inspection software developed for the Automated Fiber Placement (AFP) process at the University of South Carolina utilizing an ML vision system. This vision system allows for defect data to be fully integrated into the manufacturing process, allowing for the ML inspection system to influence several chains in the composites product lifecycle management.","Automated Fiber Placement,Inspection,Machine learning",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Mechanics,Materials Science",,5.536,"NEURAL-NETWORK,GENETIC,ALGORITHM,OPTIMIZATION,DESIGN,COMPONENT,PREDICTION,SYSTEM,AFP",COMPOSITE STRUCTURES,,
59,Deep learning-based method for reducing residual motion effects in diffusion parameter estimation,85,4,2278-2293,"Gong Ting,Tong Qiqi,Li Zhiwei,He Hongjian,Zhang Hui,Zhong Jianhui","Gong T,Tong QQ,Li ZW,He HJ,Zhang H,Zhong JH",He HJ,10.1002/mrm.28544,Zhejiang University,"Purpose Conventional motion-correction techniques for diffusion MRI can introduce motion-level-dependent bias in derived metrics. To address this challenge, a deep learning-based technique was developed to minimize such residual motion effects. Methods The data-rejection approach was adopted in which motion-corrupted data are discarded before model-fitting. A deep learning-based parameter estimation algorithm, using a hierarchical convolutional neural network (H-CNN), was combined with motion assessment and corrupted volume rejection. The method was designed to overcome the limitations of existing methods of this kind that produce parameter estimations whose quality depends strongly on a proportion of the data discarded. Evaluation experiments were conducted for the estimation of diffusion kurtosis and diffusion-tensor-derived measures at both the individual and group levels. The performance was compared with the robust approach of iteratively reweighted linear least squares (IRLLS) after motion correction with and without outlier replacement. Results Compared with IRLLS, the H-CNN-based technique is minimally sensitive to motion effects. It was tested at severe motion levels when 70% to 90% of the data are rejected and when random motion is present. The technique had a stable performance independent of the numbers and schemes of data rejection. A further test on a data set from children with attention-deficit hyperactivity disorder shows the technique can potentially ameliorate spurious group-level difference caused by head motion. Conclusion This method shows great potential for reducing residual motion effects in motion-corrupted diffusion-weighted-imaging data, bringing benefits that include reduced bias in derived metrics in individual scans and reduced motion-level-dependent bias in population studies employing diffusion MRI.","diffusion kurtosis imaging,diffusion tensor imaging,head motion,neural network",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"LINEAR,LEAST-SQUARES,ROBUST,ESTIMATION,DISTORTION,CORRECTION,HEAD,MOTION,TENSOR,MRI,MOVEMENT,ARTIFACTS,FRAMEWORK,ACCURATE",MAGNETIC RESONANCE IN MEDICINE,https://discovery.ucl.ac.uk/id/eprint/10115261/3/Gong_Main-MRM-20-21048-clean.pdf,
60,Digital mapping of soil parent material in a heterogeneous tropical area,367,,,"Bonfatti Benito R.,Dematte Jose A. M.,Marques Karina P. P.,Poppiel Raul R.,Rizzo Rodnei,Mendes Wanderson de S.,Silvero Nelida E. Q.,Safanelli Jose L.","Bonfatti BR,Dematte JAM,Marques KPP,Poppiel RR,Rizzo R,Mendes WD,Silvero NEQ,Safanelli JL",Dematte JAM,10.1016/j.geomorph.2020.107305,Universidade de Sao Paulo,"Parent material is one of the five factors in soil formation. Studies on parent material allow interpreting soil genesis processes and improve our knowledge of specific soil attributes. However, soil parent material maps at detailed cartographic scale (finer than 1:100,000) are rare in tropical areas and it is usually inferred from poorly detailed geological data, which generally group different lithologies into single units. Thus, we propose a methodology to map soil parent material based on remote sensing and machine learning in a geologically very complex area. The study site covers 1378 km(2) in Sao Paulo State, Brazil. Prediction models used data from 280 geological observation points, a digital elevation model (spatial resolution of 5 m, upscale to 30 m) and multitemporal Landsat images in a range of 30 years. We evaluated six classification algorithms, namely random forest, decision tree, support vector machine, multinomial logistic regression, K-means (unsupervised classification), and object-based image analysis with maximum likelihood classification. Environmental covariates were grouped to create different scenarios combining terrain derivatives, hydrologic covariates, topsoil spectral reflectance, and spatial coordinates. A bare soil image, elaborated using 30 years of Landsat data, was evaluated as a covariate to predict soil parent material. Predictions were validated using three different strategies: crossvalidation, separate validation dataset (20%), and comparison with legacy geological maps (information from two areas with geological maps at fine scale). We also assessed the correspondence between the map of predicted soil parent material and data of soil particle size from 571 soil sampling points. Random forest algorithm presented the best validation performance, whereas the group of terrain derivatives and hydrologic covariates explained most of model variation. The produced parent material map was coherent with the spatial distribution of soil particle size across the study area. (C) 2020 Elsevier B.V. All rights reserved.","Soil formation factors,Bare soil image,Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Physical Geography,Geology",,4.623,"REGION,CLASSIFICATION,REFLECTANCE,HEMATITE,GOETHITE,BASIN",GEOMORPHOLOGY,,
61,A deep learning model to predict dose-volume histograms of organs at risk in radiotherapy treatment plans,47,11,5467-5481,"Liu Zhiqiang,Chen Xinyuan,Men Kuo,Yi Junlin,Dai Jianrong","Liu ZQ,Chen XY,Men K,Yi JL,Dai JR",Dai JR,10.1002/mp.14394,Chinese Academy of Medical Sciences - Peking Union Medical College,"Purpose To develop a deep learning-based model to predict achievable dose-volume histograms (DVHs) of organs at risk (OARs) for automation of inverse planning. Methods The model was based on a connected residual deconvolution network (CResDevNet) and compared with UNet as a baseline. The DVHs of OARs are dependent on patient anatomical features of the planning target volumes and OARs, and these spatial relationships can be learned automatically from prior high-quality plans. The contours of planning target volumes and OARs were parsed from the plan database and used as the input to the model, and the dose-area histograms (DAHs) of the OARs were output from the model. The model was trained from scratch by correlating anatomical features with DAHs of OARs, then accumulating these histograms to obtain the final predicted DVH for each OAR. Helical tomotherapy plans for 170 nasopharyngeal cancer patients were used to train and validate the model. An additional 60 patient treatment plans were used to test the predictive accuracy of the model. The DVHs and dose-volume indices (DVIs) of clinical interest for each OAR in the testing dataset were predicted to evaluate the accuracy of the models. The mean absolute errors in the DVIs for each OAR were calculated using each model and statistically compared using a paired-samplest-test. Dice similarity coefficients for areas of the DVHs were also evaluated. Results Dose-volume histograms of 21 OARs in nasopharyngeal cancer were predicted using the models. For each patient, 63 DVIs for all OARs were calculated. Using the 60 patient treatment plans in the testing dataset, 79% and 73% of the DVIs predicted using the CResDevNet and UNet models, respectively, were within 5% of the clinical values. The median value of the DVIs' mean absolute errors was 3.2 +/- 2.5% and 3.7 +/- 2.9% for the CResDevNet and UNet models, respectively. The average dice similarity coefficient for all OARs was 0.965 using the CResDevNet model and 0.958 using the UNet model. Conclusions A deep learning model was developed for predicting achievable DVHs of OARs. The prediction accuracy of the CResDevNet model was evaluated using a planning database of nasopharyngeal cancer cases and shown to be more accurate than the UNet model. Prediction accuracy was also higher for larger-volume OARs. The model can be used for automation of inverse planning and quality assessment of individual treatment plans.","dose-volume histogram,deep learning,dose-area histogram,inverse planning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"AT-RISK,THERAPY,CANCER,HEAD",MEDICAL PHYSICS,,
62,Improving the slice interaction of 2.5D CNN for automatic pancreas segmentation,47,11,5543-5554,"Zheng Hao,Qian Lijun,Qin Yulei,Gu Yun,Yang Jie","Zheng H,Qian LJ,Qin YL,Gu Y,Yang J",Gu Y; Yang J,10.1002/mp.14303,Shanghai Jiao Tong University,"Purpose Volumetric pancreas segmentation can be used in the diagnosis of pancreatic diseases, the research about diabetes and surgical planning. Since manual delineation is time-consuming and laborious, we develop a deep learning-based framework for automatic pancreas segmentation in three dimensional (3D) medical images. Methods A two-stage framework is designed for automatic pancreas delineation. In the localization stage, a Square Root Dice loss is developed to handle the trade-off between sensitivity and specificity. In refinement stage, a novel 2.5D slice interaction network with slice correlation module is proposed to capture the non-local cross-slice information at multiple feature levels. Also a self-supervised learning-based pre-training method, slice shuffle, is designed to encourage the inter-slice communication. To further improve the accuracy and robustness, ensemble learning and a recurrent refinement process are adopted in the segmentation flow. Results The segmentation technique is validated in a public dataset (NIH Pancreas-CT) with 82 abdominal contrast-enhanced 3D CT scans. Fourfold cross-validation is performed to assess the capability and robustness of our method. The dice similarity coefficient, sensitivity, and specificity of our results are 86.21 +/- 4.37%, 87.49 +/- 6.38% and 85.11 +/- 6.49% respectively, which is the state-of-the-art performance in this dataset. Conclusions We proposed an automatic pancreas segmentation framework and validate in an open dataset. It is found that 2.5D network benefits from multi-level slice interaction and suitable self-supervised learning method for pre-training can boost the performance of neural network. This technique could provide new image findings for the routine diagnosis of pancreatic disease.","2,5D slice interaction network,pancreas segmentation,slice shuffle,Square Root Dice loss",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,,MEDICAL PHYSICS,,
63,Self-contained deep learning-based boosting of 4D cone-beam CT reconstruction,47,11,5619-5631,"Madesta Frederic,Sentker Thilo,Gauer Tobias,Werner Rene","Madesta F,Sentker T,Gauer T,Werner R",Madesta F,10.1002/mp.14441,University of Hamburg,"Purpose Four-dimensional cone-beam computed tomography (4D CBCT) imaging has been suggested as a solution to account for interfraction motion variability of moving targets like lung and liver during radiotherapy (RT) of moving targets. However, due to severe sparse view sampling artifacts, current 4D CBCT data lack sufficient image quality for accurate motion quantification. In the present paper, we introduce a deep learning-based framework for boosting the image quality of 4D CBCT image data that can be combined with any CBCT reconstruction approach and clinical 4D CBCT workflow. Methods Boosting is achieved by learning the relationship between so-called sparse view pseudo-time-average CBCT images obtained by a projection selection scheme introduced to mimic phase image sparse view artifact characteristics and corresponding time-average CBCT images obtained by full view reconstruction. The employed convolutional neural network architecture is the residual dense network (RDN). The underlying hypothesis is that the RDN learns the appearance of the streaking artifacts that is typical for 4D CBCT phase images - and removes them without influencing the anatomical image information. After training the RDN, it can be applied to the 4D CBCT phase images to enhance the image quality without affecting the contained temporal and motion information. Different to existing approaches, no patient-specific prior knowledge about anatomy or motion characteristics is needed, that is, the proposed approach is self-contained. Results Application of the trained network to reconstructed phase images of an external (SPARE challenge) as well as in-house 4D CBCT patient and motion phantom data set reduces the phase image streak artifacts consistently for all patients and state-of-the-art reconstruction approaches. Using the SPARE data set, we show that the root mean squared error compared to ground truth data provided by the challenge is reduced by approximately 50% while normalized cross correlation of reconstruction and ground truth is improved up to 10%. Compared to direct deep learning-based 4D CBCT to 4D CT mapping, our proposed method performs better because inappropriate prior knowledge about the patient anatomy and physiology is taken into account. Moreover, the image quality enhancement leads to more plausible motion fields estimated by deformable image registration (DIR) in the 4D CBCT image sequences. Conclusions The presented framework enables significantly boosting of 4D CBCT image quality as well as improved DIR and motion field consistency. Thus, the proposed method facilitates extraction of motion information from severely artifact-affected images, which is one of the key challenges of integrating 4D CBCT imaging into RT workflows.","4D cone-beam computed tomography,artifact reduction,deep learning,image reconstruction,image registration,image quality",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,,"RADIATION-THERAPY,RESPIRATORY,MOTION,LIVER,RADIOTHERAPY,QUALITY,MODEL",MEDICAL PHYSICS,https://aapm.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mp.14441,
64,Supervised machine learning of thermal comfort under different indoor temperatures using EEG measurements,225,,,"Shan Xin,Yang En-Hua","Shan X,Yang EH",Yang EH,10.1016/j.enbuild.2020.110305,Nanyang Technological University & National Institute of Education (NIE) Singapore,"In this paper, machine learning techniques in conjunction with passive EEG (electroencephalogram) measurement were explored to classify occupants' real-time thermal comfort states, which have the potential in the future for energy saving through adopting time varying set points when real-time changes in thermal comfort can require less energy input. The performances of different machine learning techniques were compared, and the method to select linear continuous features for class interpolation was also explored. For the full-set features, the performances of different classifiers were satisfactory, with classification rates all above 90%. The LDA classifier had the best performance. The second best was the NB classifier, and the relatively worst was the KNN classifier. The linear continuous EEG features were selected by interpolation and can be found for all human subjects. Higher selection threshold led to less selected features but higher average performance of these features. In general, the EEG based machine learning methods can classify occupants' real-time thermal comfort states, and could potentially lead to more building energy saving through comfort-driven time varying set points. (C) 2020 Elsevier B.V. All rights reserved.","Machine learning,electroencephalogram (EEG),Supervised learning,Thermal comfort,Human sensing",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Construction & Building Technology,Energy & Fuels,Engineering",,6.175,"HUMAN-BUILDING,INTERACTION,EMOTION,RECOGNITION,ADAPTATION,OFFICE,CLASSIFICATION,PRODUCTIVITY,QUALITY",ENERGY AND BUILDINGS,,
65,Machine Learning-Guided Three-Dimensional Printing of Tissue Engineering Scaffolds,26,23-24,1359-1368,"Conev Anja,Litsa Eleni E.,Perez Marissa R.,Diba Mani,Mikos Antonios G.,Kavraki Lydia E.","Conev A,Litsa EE,Perez MR,Diba M,Mikos AG,Kavraki LE",Kavraki LE,10.1089/ten.tea.2020.0191,Rice University,"Various material compositions have been successfully used in 3D printing with promising applications as scaffolds in tissue engineering. However, identifying suitable printing conditions for new materials requires extensive experimentation in a time and resource-demanding process. This study investigates the use of Machine Learning (ML) for distinguishing between printing configurations that are likely to result in low-quality prints and printing configurations that are more promising as a first step toward the development of a recommendation system for identifying suitable printing conditions. The ML-based framework takes as input the printing conditions regarding the material composition and the printing parameters and predicts the quality of the resulting print as either ""low"" or ""high."" We investigate two ML-based approaches: a direct classification-based approach that trains a classifier to distinguish between low- and high-quality prints and an indirect approach that uses a regression ML model that approximates the values of a printing quality metric. Both modes are built upon Random Forests. We trained and evaluated the models on a dataset that was generated in a previous study, which investigated fabrication of porous polymer scaffolds by means of extrusion-based 3D printing with a full-factorial design. Our results show that both models were able to correctly label the majority of the tested configurations while a simpler linear ML model was not effective. Additionally, our analysis showed that a full factorial design for data collection can lead to redundancies in the data, in the context of ML, and we propose a more efficient data collection strategy.
Impact statement This study investigates the use of Machine Learning (ML) for predicting the printing quality given the printing conditions in extrusion-based 3D printing of biomaterials. Classification and regression methods built upon Random Forests show promise for the development of a recommendation system for identifying suitable printing conditions reducing the amount of required experimentation. This study also gives insights on developing an efficient strategy for collecting data for training ML models for predicting printing quality in extrusion-based 3D printing of biomaterials.","3D printing,biomaterials,tissue engineering,machine learning,random forests,printing quality prediction",Article,"MARY ANN LIEBERT, INC, 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA","Cell Biology,Engineering,Materials Science",,4.145,"OPTIMIZATION,EXTRUSION",TISSUE ENGINEERING PART A,,
66,A Machine Learning Model on Simple Features for CO2 Reduction Electrocatalysts,124,41,22471-22478,"Chen An,Zhang Xu,Chen Letian,Yao Sai,Zhou Zhen","Chen A,Zhang X,Chen LT,Yao S,Zhou Z",Zhang X; Zhou Z,10.1021/acs.jpcc.0c05964,Nankai University,"Electroreduction of CO2 is one of the most potential ways to realize CO2 recycle and energy regeneration. The key to promoting this technology is the development of high-performance electrocatalysts. Generally, high-throughput computational screening contributes a lot to materials innovation, but still consumes much time and resource. To achieve efficient exploration of electrocatalysts for CO2 reduction, we created a machine learning model based on an extreme gradient boosting regression (XGBR) algorithm and simple features. Our screening model successfully and rapidly predicted the Gibbs free energy change of CO adsorption (Delta G(CO)) of 1060 atomically dispersed metal-nonmetal codoped graphene systems, and greatly reduced the research cost. The competitive reaction, the hydrogen evolution reaction (HER), is also discussed with respect to such a screening model. This work demonstrates the potential of machine learning methods and provides a convenient approach for the effective theoretical design of electrocatalysts for CO2 reduction.","DENSITY-FUNCTIONAL THEORY,ELECTROREDUCTION,ATOM,CATALYSTS,DISCOVERY,METHANE,DESIGN,ALLOY",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,4.467,"DENSITY-FUNCTIONAL,THEORY,ELECTROREDUCTION,ATOM,CATALYSTS,DISCOVERY,METHANE,DESIGN,ALLOY",JOURNAL OF PHYSICAL CHEMISTRY C,,
67,,,,,,,,,,,,,,,,,,,,
68,Combining Machine Learning Potential and Structure Prediction for Accelerated Materials Design and Discovery,11,20,8710-8720,"Tong Qunchao,Gao Pengyue,Liu Hanyu,Xie Yu,Lv Jian,Wang Yanchao,Zhao Jijun","Tong QC,Gao PY,Liu HY,Xie Y,Lv J,Wang YC,Zhao JJ",Xie Y; Lv J,10.1021/acs.jpclett.0c02357,Jilin University,"The theoretical structure prediction method via quantum mechanical atomistic simulations such as density functional theory (DFT), based solely on chemical composition, has already become a routine tool to determine the structures of physical and chemical systems, e.g., solids and clusters. However, the application of DFT to more realistic simulations, to a large extent, is impeded because of the unfavorable scaling of the computational cost with respect to the system size. During recent years, the machine learning potential (MLP) method has been rapidly rising as an accurate and efficient tool for atomistic simulations. In this Perspective, we provide an introduction to the basic principles and advantages of the combination of structure prediction and MLP, as well as the challenges and opportunities associated with this promising approach.","NEURAL-NETWORK POTENTIALS,EVOLUTIONARY ALGORITHM,GLOBAL OPTIMIZATION,CLUSTERS,LANTHANUM",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,7.643,"NEURAL-NETWORK,POTENTIALS,EVOLUTIONARY,ALGORITHM,GLOBAL,OPTIMIZATION,CLUSTERS,LANTHANUM",JOURNAL OF PHYSICAL CHEMISTRY LETTERS,,
69,Element Code from Pseudopotential as Efficient Descriptors for a Machine Learning Model to Explore Potential Lead-Free Halide Perovskites,11,20,8914-8921,"Jao Meng-Huan,Chan Shun-Hsiang,Wu Ming-Chung,Lai Chao-Sung","Jao MH,Chan SH,Wu MC,Lai CS",Wu MC; Lai CS,10.1021/acs.jpclett.0c02393,Chang Gung University,"The rapid development of machine learning has proven its potential in material science. To acquire an accurate and promising result, the choice of descriptor plays an essential role in dictating the model performance. In this work, we introduce a set of novel descriptors, Element Code, which is generated from pseudopotential. Using a variational autoencoder to perform unsupervised learning, the produced Element Code is verified to contain representative information on elements. Attributed to the successful extraction of information from pseudopotential, Element Code can serve as the primary descriptor for the machine learning model. We construct a model using Element Code as the sole descriptor to predict the bandgap of a lead-free double halide perovskite, and an accuracy of 0.951 and mean absolute error of 0.266 eV are achieved. We believe our work can offer insights into selecting lead-free halide perovskites and establish a paradigm of exploring new materials.",SOLAR-CELLS,Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,7.643,SOLAR-CELLS,JOURNAL OF PHYSICAL CHEMISTRY LETTERS,,
70,Modeling of metal nanoparticles: Development of neural-network interatomic potential inspired by features of the modified embedded-atom method,102,14,,"Wu Feifeng,Min Hang,Wen Yanwei,Chen Rong,Zhao Yunkun,Ford Mike,Shan Bin","Wu FF,Min H,Wen YW,Chen R,Zhao YK,Ford M,Shan B",Ford M,10.1103/PhysRevB.102.144107,University of Technology Sydney,"Interatomic potential plays a key role in ensuring the accuracy and reliability of molecular-dynamics simulation results. While most empirical potentials are benchmarked against a set of carefully chosen bulk material properties, recent advances in machine learning have seen the emergence of neural-network-based mathematical potentials capable of describing highly complex potential energy surfaces for a variety of systems. We report here the development of a neural-network interatomic potential (NNIP) with modified embedded-atom method background density as fingerprint functions, which could accurately model the energetics of metallic nanoparticles and clusters (Cu as a representative example) widely used in catalysis. To appropriately account for the diverse chemical environments encountered in nanoparticles/nanoclusters, an extensive set of atomic configurations (totaling 18 084) were calculated using density-functional-theory (DFT) at the Perdew-Burke-Ernzerhof level. In addition to standard bulk properties such as cohesive energies and elastic constants, the sampled configurations also include a substantial number of differently oriented crystal facets and differently sized nanoparticles and nanoclusters, greatly expanding the value range of NNIP features that was otherwise quite limited. The complex energy potential surface of Cu can be faithfully reproduced, with an average error of 0.011 eV/at for energy states within 3 eV of the ground state. As an illustration, the developed NNIP is used to simulate the molecular dynamics of copper nanoparticles, and good agreement is achieved between DFT and the NNIP.","MOLECULAR-DYNAMICS,DEFECT FORMATION,FORCE-FIELD,FCC METALS,SIMULATIONS,DISCOVERY,INVERSION,ENERGY",Article,"AMER PHYSICAL SOC, ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA","Materials Science,Physics",,3.86,"MOLECULAR-DYNAMICS,DEFECT,FORMATION,FORCE-FIELD,FCC,METALS,SIMULATIONS,DISCOVERY,INVERSION,ENERGY",PHYSICAL REVIEW B,,
71,,,,,,,,,,,,,,,,,,,,
72,Artificial Intelligence in Various Medical Fields With Emphasis on Radiology: Statistical Evaluation of the Literature,12,10,,"Pakdemirli Emre,Wegner Urszula","Pakdemirli E,Wegner U",Wegner U,10.7759/cureus.10961,King George Hospital,"Background
Artificial intelligence (AI) has significantly impacted numerous medical specialties with high emphasis on radiology. Associated novel diagnostic methods have become a rapidly emerging hot topic, and it is essential to provide insights into quantitative analysis of the growing literature.
Purpose
The purpose of this study is to highlight future academic trends, identify potential research gaps, and analyze scientific landscape of AI in the field of medicine. The main aim is to explore comprehensive dataset over a 46-year period in terms of publication type, publication citation, country of origin, institution, and medical specialty.
Material and Methods
The Web of Science database was searched from 1975 to 2020, and publications on AI were explored. Both original research reports and review articles were included in comprehensive bibliometric analysis. Descriptive statistics were calculated, and numerous variables were applied, namely year of publication, institution, type of publication, specialty area, country of origin, and citation numbers, and the KruskalWallis analysis of variance was used.
Results
A total of 117,974 relevant citations were retrieved, of which 83,979 original research and review articles were retained for analysis. Not surprisingly, the largest proportion of citations were from the United States (23%, n = 19,180) followed by China, Spain, England, and Germany. The number of citations was relatively consistent during the 1970s and emerging gradually during the 1980s. However, ongoing scientific trend positively evolved, and the numbers started to grow significantly in the 1990s and demonstrated continuous increasing wave since then. The most frequently represented key medical specialties were oncology, radiology, neuroradiology, and ophthalmology. Overall, no major statistical difference was found between these four domains (p = 0.753).
Conclusions
In summary, research on AI-powered technologies in the medical domain was at early stage in the 1970s. However, associated deep learning algorithms significantly attracted and revolutionized the scientific community with subsequent evolution of research and exponential growth of multidisciplinary publications since that time. Work in this field has impacted radiology as an area of predominant interest and has been led by institutions in the United States, Spain, France, China, and England. The bibliometric study reported herein can provide a broad overview and valuable guidance to help medical researchers gain insights into key points and trace the global trends regarding the status of AI research in medicine, particularly in radiology and other relevant multispecialty areas.","machine learning,artificial intelligence,medicine,radiology,bibliometric analysis",Article,"CUREUS INC, PO BOX 61002, PALO ALTO, CA 94306 USA",General & Internal Medicine,,,,CUREUS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7567304,
73,Edge Detection Algorithm Optimization and Simulation Based on Machine Learning Method and Image Depth Information,20,20,11770-11777,"Cui Jichao,Tian Kun","Cui JC,Tian K",Cui JC,10.1109/JSEN.2019.2936117,Henan Institute of Technology,"Machine learning algorithms have become a hot topic in current research due to their unique learning performance, and have achieved fruitful research and application results in various fields. In this paper, the idea of machine learning classification algorithm is applied to depth image edge detection, AdaBoost algorithm and decision tree are used for image edge detection. The algorithm is created from training set creation, depth image feature extraction and combination of AdaBoost and image depth information, creating image training sample sets, selecting image features, training algorithm classifiers, and simulating medical ultrasound image classifiers. Finally, the machine learning algorithm was simulated and tested. The experimental results show that the edge detection effect is good, the algorithm adaptability is strong, and no adjustment parameters are needed.","Image edge detection,Classification algorithms,Training,Machine learning,Visualization,Filtering algorithms,Machine learning,depth image information,edge detection,algorithmic design",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,FAULT-DETECTION,IEEE SENSORS JOURNAL,,
74,Feature Extraction of Brain-Computer Interface Electroencephalogram Based on Motor Imagery,20,20,11787-11794,"Shi Tianwei,Ren Ling,Cui Wenhua","Shi TW,Ren L,Cui WH",Shi TW,10.1109/JSEN.2019.2939343,University Science & Technology Liaoning,"Brain-computer interface (BCI) is a system that allows people to communicate or control external devices simply by using information from the brain without relying on the peripheral nervous system and muscles; BCI technology has great potential application value in motor function assistance and motor function rehabilitation and has become a new research hotspot in the fields of machine learning, biomedical engineering and computer communication. The feature extraction of motor imagery electroencephalogram (EEG) is to find the most effective characteristics of complex EEG signal that can represent the consciousness task, to differentiate the feature vectors extracted from different consciousness tasks, and to maximize the correlation between the feature vector and the consciousness task. On the basis of summarizing and analyzing previous research works, this paper proposes a new EEG feature extraction algorithm based on common spatial pattern (CSP) and adaptive auto-regressive (AAR), and demonstrates feasibility of band energy, sample entropy and order accumulation to be the characteristics of motor imagery classification, and finally compares the classification effects of linear discrimination classifier, common space classifier and Bayesian classifier. The simulation results show that the proposed method and algorithm can effectively extract the features of EEG signals during motor imagery. The research results of this paper provide a reference for the further study of feature extraction of brain-computer interface EEG.","Feature extraction,Electroencephalography,Brain modeling,Wavelet packets,Time-domain analysis,Frequency-domain analysis,Brain-computer interfaces,Brain-computer interface,EEG signal,feature extraction,motor imagery",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"EEG,CLASSIFICATION",IEEE SENSORS JOURNAL,,
75,,,,,,,,,,,,,,,,,,,,
76,,,,,,,,,,,,,,,,,,,,
77,,,,,,,,,,,,,,,,,,,,
78,AI-RADS: An Artificial Intelligence Curriculum for Residents.,,,,",,,","Lindqwister Alexander L,Hassanpour Saeed,Lewis Petra J,Sin Jessica M",,10.1016/j.acra.2020.09.017,,"RATIONALE AND OBJECTIVES: Artificial intelligence (AI) has rapidly emerged as a field poised to affect nearly every aspect of medicine, especially radiology. A PubMed search for the terms ""artificial intelligence radiology"" demonstrates an exponential increase in publications on this topic in recent years. Despite these impending changes, medical education designed for future radiologists have only recently begun. We present our institution's efforts to address this problem as a model for a successful introductory curriculum into artificial intelligence in radiology titled AI-RADS.RESULTS: The course received a 9.8/10 rating from residents for overall satisfaction. With the exception of the final lecture, there were significant increases in learner confidence in reading journal articles on AI after each lecture. Residents demonstrated significant increases in perceived understanding of foundational concepts in artificial intelligence across all mastery questions for every lecture.CONCLUSION: The success of our institution's pilot AI-RADS course demonstrates a workable model of including AI in resident education. Copyright © 2020. Published by Elsevier Inc.","Artificial intelligence; Education; ,Machine learning,; Radiology; Residency training",Journal Article,,,,,,,,
79,Radial Distribution Function from X-ray Absorption near Edge Structure with an Artificial Neural Network,89,10,,"Kiyohara Shin,Mizoguchi Teruyasu","Kiyohara S,Mizoguchi T",Kiyohara S; Mizoguchi T,10.7566/JPSJ.89.103001,University of Tokyo,"Extended X-ray absorption fine structure (EXAFS) is one of the common tools used to determine the local atomic coordination and bond length around an objective element via data conversion from the EXAFS profile to a radial distribution function (RDF). Thus, EXAFS has been widely used for the investigation of catalytic reactions, battery degradation, and other material developments. However, the data conversion from EXAFS to RDF involves three difficulties: weak signals, necessity of a wide energy range (similar to 1000 eV), and fitting parameters in reference samples. Recently, the direct estimation technique of RDF from EXAFS using machine learning was successfully developed, which overcomes the third problem. Here, we used an artificial neural network (ANN) to directly predict RDF from the near-edge region of the spectrum (X-ray absorption near-edge structure: XANES), which enables overcoming all of the difficulties. The ANN can correctly generate RDF only from XANES. XANES includes information about the bond length and coordination numbers in the range of similar to 5 angstrom. We applied our prediction model to an experimental spectrum and confirmed its accuracy. The method proposed here is greatly beneficial for measuring the local bond length and coordination of materials whose extended energy region is difficult to be measured.","FINE-STRUCTURE,ALLOYS",Article,"PHYSICAL SOC JAPAN, YUSHIMA URBAN BUILDING 5F, 2-31-22 YUSHIMA, BUNKYO-KU, TOKYO, 113-0034, JAPAN",Physics,,1.54,"FINE-STRUCTURE,ALLOYS",JOURNAL OF THE PHYSICAL SOCIETY OF JAPAN,https://doi.org/10.7566/jpsj.89.103001,
80,Atomatic Detection and Diagnosis of Severe Viral Pneumonia CT Images Based on LDA-SVM,20,20,11927-11934,"Ling Gengfei,Cao Congcong","Ling GF,Cao CC",Ling GF,10.1109/JSEN.2019.2959617,"Zhoukou Cent Hosp, Resp Intens Care Unit, Zhoukou 466000, Peoples R China.","The identification of pneumonia types mainly depends on the experience of doctors, but some CT images of pneumonia are very similar, even experienced doctors are prone to misdiagnosis. In order to solve the problems of inefficiency, coarse granularity and poor accuracy under the background of large data, LDA-SVM (Linear Discriminate Analysis - support vector machine) classification algorithm in machine learning field is introduced. LDA is used to extract features from images, and SVM classifier is used to classify the sub-datasets with strong fusion features. On this basis, fusion index and intermediary centrality index are selected to measure the fusion degree of patent sub-centralization technology and identify the key technologies in the fusion process, Because of the fusion of several algorithms, the algorithm needs many iteration training, and the computation time is too long. And simulation results show that our proposed method has significant improvement on identification accuracy rate.","Lung,Feature extraction,Diseases,Support vector machines,Computed tomography,Classification algorithms,Viral Pneumonia,CT,Linear Discriminate Analysis,support vector machine,identification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,BACTERIAL,IEEE SENSORS JOURNAL,,
81,Reconstructing QRS Complex From PPG by Transformed Attentional Neural Networks,20,20,12374-12383,"Chiu Hong-Yu,Shuai Hong-Han,Chao Paul C. -P.","Chiu HY,Shuai HH,Chao PCP",Shuai HH,10.1109/JSEN.2020.3000344,"Chiao Tung Univ NCTU, BASIC Lab, Dept Elect & Comp Engn, Hsinchu 30010, Taiwan.","Technology that translates photoplethysmogram (PPG) into the QRS complex of electrocardiogram (ECG) would be transformative for people who require continuously monitoring. However, directly decoding the QRS complex of ECG from PPG is challenging because PPG signals usually have different offsets due to 1) different devices, and 2) personal differences, which makes the alignment difficult. In this paper, we make the first attempt to reconstruct the QRS complex of ECG only from the recording of PPG by an end-to-end deep learning-based approach. Specifically, we propose a novel encoder-decoder architecture containing three components: 1) a sequence transformer network which automatically calibrates the offset, 2) an attention network, which dynamically identifies regions of interest, and 3) a new QRS complex-enhanced loss for better reconstruction. The experiment results on a real dataset demonstrate the effectiveness of the proposed method: 3.67% R peak failure rate of the reconstructed ECG and high correlation of pulse transit time between the reconstructed QRS complex and the groundtruth QRS complex (rho = 0.844), which creates a new opportunity for low-cost clinical studies via the waveform-level reconstruction of the QRS complex of ECG from PPG.","Electrocardiography,Monitoring,Electrodes,Biomedical monitoring,Skin,Standards,Sensors,Convolutional neural network,electrocardiography,encoder-decoder,photoplethysmography,transform network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"PULSE,TRANSIT-TIME,RESPIRATORY,RATE,ECG,ELECTROCARDIOGRAM",IEEE SENSORS JOURNAL,,
82,Combining multi-phase field simulation with neural network analysis to unravel thermomigration accelerated growth behavior of Cu6Sn5 IMC at cold side Cu-Sn interface,184,,,"Kunwar Anil,Hektor Johan,Nomoto Sukeharu,Coutinho Yuri Amorim,Moelans Nele","Kunwar A,Hektor J,Nomoto S,Coutinho YA,Moelans N",Kunwar A,10.1016/j.ijmecsci.2020.105843,KU Leuven,"In Pb-free solder alloys used in solder balls of diameter of 50 mu m or smaller, larger proportion of Cu6Sn5 inter-metallics formation is a major reliability concern, and this is aggravated in presence of external thermal gradient. A complete understanding of the mechanism for intermetallics compound (IMC) growth under thermomigration is essential for devising solder materials resistant to degradation under thermal gradient. This work integrates neural network analysis with multi-phase field method to quantify the mechanism of thermomigration at the cold side of a solder-substrate system. At hot side temperature of 523.15 K, 1D multi-phase field model is built for a combined driving force of bulk diffusion and thermomigration, and is solved using finite element method (FEM). The free energy density function for the thermomigration driving force is introduced, and coupled with the functions for bulk and interfacial free energy density of each phase. Data of heats of transport, temperature difference and growth rate constant of IMC are obtained from multiple FEM simulations, and the FEM-generated dataset is employed in the neural network. The machine learning predicted growth rate constant is tallied with experimental value, and heat of transport of Cu in IMC phase (Q(Cu)(imc)) is determined from the inverse method. The obtained value of optimized Q(Cu)(imc) is +35.10 kJ/mol. 2D IMC grain growth simulations are performed with hot-side at 523.15 K and the cold side lowered to 523.0817 K and 522.0 K respectively, thereby revealing that the accelerated grain growth for larger temperature difference is noticed within the first 20 s of the simulations.","Multi-phase field method,Thermomigration,Intermetallic compound,Neural network,Heat of transport,Finite element method",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Engineering,Mechanics",,5.199,"INTERMETALLIC,COMPOUNDS,SOLDER,JOINTS,DRIVING-FORCE,MODEL,SN%2FCU,ELECTROMIGRATION,FRAMEWORK,ENERGY",INTERNATIONAL JOURNAL OF MECHANICAL SCIENCES,https://lirias.kuleuven.be/bitstream/123456789/655889/2/Kunwar_et_al_thermomigration_2020_V1_postprint.pdf,
83,Single resistive sensor for selective detection of multiple VOCs employing SnO2 hollowspheres and machine learning algorithm: A proof of concept,321,,,"Acharyya Snehanjan,Jana Biswabandhu,Nag Sudip,Saha Goutam,Guha Prasanta Kumar","Acharyya S,Jana B,Nag S,Saha G,Guha PK",Guha PK,10.1016/j.snb.2020.128484,Indian Institute of Technology System (IIT System),"Selective detection of harmful gasses and volatile organic compounds (VOCs) in the ambient has become a major challenge. Primarily, semiconducting metal-oxide based gas sensors sense various gases simultaneously, hence their selectivity is poor. This paper presents a single chemiresistive metal-oxide gas sensor for identification of multiple VOCs accurately by employing highly sensitive microstructure and machine learning tools. Tin oxide (SnO2) hollowspheres were taken as sensing material that were prepared through optimized hydrothermal route. Different characterizations were carried out to confirm the formation of desired morphology and structural features. The sensor device was fabricated by controlled drop cast technique over gold based interdigitated electrodes. The sensor showed remarkable response towards the target VOCs with high sensitivity and fast recovery time. Incorporation of machine learning algorithm on the obtained sensor data provided accurate identification of all the VOCs (best performance shown by random forest). In addition, the quantitative prediction of gas concentration was performed for each target gas using regression model. In comparison to e-noses (having array of sensors with different sensing material), a single chemiresistive metal-oxide sensor with proper machine learning tool is simple, economic, compact and easy to fabricate.","Indoor air quality,Volatile organic compound,Selectivity,Chemiresistive gas sensor,Tin oxide hollowspheres",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Chemistry,Electrochemistry,Instruments & Instrumentation",,6.743,"GAS,SENSORS,HOLLOW,MICROSPHERES,AIR-POLLUTION,RANDOM,FOREST,CLASSIFICATION",SENSORS AND ACTUATORS B-CHEMICAL,,
84,"Nanoporous C3N4, C3N5 and C3N6 nanosheets; novel strong semiconductors with low thermal conductivities and appealing optical/electronic properties",167,,40-50,"Mortazavi Bohayra,Shojaei Fazel,Shahrokhi Masoud,Azizi Maryam,Rabczuk Timon,Shapeev Alexander V.,Zhuang Xiaoying","Mortazavi B,Shojaei F,Shahrokhi M,Azizi M,Rabczuk T,Shapeev AV,Zhuang XY",Mortazavi B; Zhuang XY,10.1016/j.carbon.2020.05.105,University of Hannover,"Carbon nitride two-dimensional (2D) materials are among the most attractive class of nanomaterials, with wide range of application prospects. As a continuous progress, most recently, two novel carbon nitride 2D lattices of C3N5 and C3N4 have been successfully experimentally realized. Motivated by these latest accomplishments and also by taking into account the well-known C3N4 triazine-based graphitic carbon nitride structures, we predicted two novel C3N6 and C3N4 counterparts. We then conducted extensive density functional theory simulations to explore the thermal stability, mechanical, electronic and optical properties of these novel nanoporous carbon-nitride nanosheets. According to our results all studied nanosheets are found to exhibit desirable thermal stability and mechanical properties. Non equilibrium molecular dynamics simulations on the basis of machine learning interatomic potentials predict ultralow thermal conductivities for these novel nanosheets. Electronic structure analyses confirm direct band gap semiconducting electronic character and optical calculations reveal the ability of these novel 2D systems to adsorb visible range of light. Extensive first-principles based results by this study provide a comprehensive vision on the stability, mechanical, electronic and optical responses of C3N4, C3N5 and C3N6 as novel 2D semiconductors and suggest them as promising candidates for the design of advanced nanoelectronics and energy storage/conversion systems. (C) 2020 Elsevier Ltd. All rights reserved.","Carbon nitride,2D materials,Semiconductors,First-principles modelling",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Chemistry,Materials Science",,8.719,"GRAPHITIC,CARBON,NITRIDE,TOTAL-ENERGY,CALCULATIONS,MONOLAYER,G-C3N4,CHARGE-TRANSPORT,EFFICIENT,PERFORMANCE,SILICENE,INSIGHT,STRAIN",CARBON,http://arxiv.org/pdf/2006.03889,
85,High thermal conductivity in semiconducting Janus and non-Janus diamanes,167,,51-61,"Raeisi Mostafa,Mortazavi Bohayra,Podryabinkin Evgeny V.,Shojaei Fazel,Zhuang Xiaoying,Shapeev Alexander V.","Raeisi M,Mortazavi B,Podryabinkin EV,Shojaei F,Zhuang XY,Shapeev AV",Mortazavi B; Zhuang XY,10.1016/j.carbon.2020.06.007,University of Hannover,"Most recently, F-diamane monolayer was experimentally realized by the fluorination of bilayer graphene. In this work we elaborately explore the electronic and thermal conductivity responses of diamane lattices with homo or hetero functional groups, including: non-Janus C2H, C2F and C2Cl diamane and Janus counterparts of C4HF, C4HCl and C4FCl. Noticeably, C2H, C2F, C2Cl, C4HF, C4HCl and C4FCl diamanes are found to show electronic diverse band gaps of, 3.86, 5.68, 2.42, 4.17, 0.86, and 2.05 eV, on the basis of HSE06 method estimations. The thermal conductivity of diamane nanosheets was acquired using the full iterative solutions of the Boltzmann transport equation, with substantially accelerated calculations by employing machine-learning interatomic potentials in obtaining the anharmonic force constants. According to our results, the room temperature lattice thermal conductivity of graphene and C2H, C2F, C2Cl, C4HF, C4HCl and C4FCl diamane monolayers are estimated to be 3636,1145, 377,146, 454, 244 and 196 W/mK, respectively. The underlying mechanisms resulting in significant effects of functional groups on the thermal conductivity of diamane nanosheets were thoroughly explored. Our results highlight the substantial role of functional groups on the electronic and thermal conduction responses of diamane nanosheets. (C) 2020 Elsevier Ltd. All rights reserved.","Diamane,2D materials,Semiconductors,Thermal conductivity,Machine learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Chemistry,Materials Science",,8.719,"TOTAL-ENERGY,CALCULATIONS,GRAPHENE,CARBON,C3N,TRANSPORT,DIAMOND,CRYSTALS",CARBON,http://arxiv.org/pdf/2006.04091,
86,Machine-learning-assisted fabrication: Bayesian optimization of laser-induced graphene patterning using in-situ Raman analysis,167,,609-619,"Wahab Hud,Jain Vivek,Tyrrell Alexander Scott,Seas Michael Alan,Kotthoff Lars,Johnson Patrick Alfred","Wahab H,Jain V,Tyrrell AS,Seas MA,Kotthoff L,Johnson PA",Johnson PA,10.1016/j.carbon.2020.05.087,University of Wyoming,"The control of the physical, chemical, and electronic properties of laser-induced graphene (LIG) is crucial in the fabrication of flexible electronic devices. However, the optimization of LIG production is timeconsuming and costly. Here, we demonstrate state-of-the-art automated parameter tuning techniques using Bayesian optimization to advance rapid single-step laser patterning and structuring capabilities with a view to fabricate graphene-based electronic devices. In particular, a large search space of parameters for LIG explored efficiently. As a result, high-quality LIG patterns exhibiting high Raman G/D ratios at least a factor of four larger than those found in the literature were achieved within 50 optimization iterations in which the laser power, irradiation time, pressure and type of gas were optimized. Human-interpretable conclusions may be derived from our machine learning model to aid our under standing of the underlying mechanism for substrate-dependent LIG growth, e.g. high-quality graphene patterns are obtained at low and high gas pressures for quartz and polyimide, respectively. Our Bayesian optimization search method allows for an efficient experimental design that is independent of the experience and skills of individual researchers, while reducing experimental time and cost and accelerating materials research. (C) 2020 Elsevier Ltd. All rights reserved.","OXIDE-FILMS,GRAPHITE,DEPENDENCE,REDUCTION,FEATURES,SCIENCE",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Chemistry,Materials Science",,8.719,"OXIDE-FILMS,GRAPHITE,DEPENDENCE,REDUCTION,FEATURES,SCIENCE",CARBON,http://engrxiv.org/pjkbq/download,
87,Machine-intelligent inkjet-printed alpha-Fe2O3/rGO towards NO2 quantification in ambient humidity,321,,,"Wu Tien-Chun,Dai Jie,Hu Guohua,Yu Wen-Bei,Ogbeide Osarenkhoe,De Luca Andrea,Huang Xiao,Su Bao-Lian,Li Yu,Udrea Florin","Wu TC,Dai J,Hu GH,Yu WB,Ogbeide O,De Luca A,Huang X,Su BL,Li Y,Udrea F",Hasan T,10.1016/j.snb.2020.128446,University of Cambridge,"Metal oxides (MOx) represent one of the most investigated chemiresistive gas sensing platforms in spite of the challenges in selectivity to analytes and interference from humidity (RH). While selectivity is traditionally improved by cross-referencing sensor arrays, interferences from humidity (RH) in ambient environment, to which the majority of the MOx materials are susceptible, cannot be inherently quantified. For standalone MOx sensors, it is therefore difficult to discriminate responses from analytes and humidity. We develop a framework which employs temperature modulation (TM) algorithms and machine learning (ML) approaches using principal component analysis (PCA) and cluster analysis of transient features, to quantify NO2 concentrations under specific RH conditions. With a single inkjet-printed MOx/reduced graphene oxide (rGO) complementary metal oxide-semiconductor (CMOS)-integrated sensor, we achieve an overall discrimination accuracy of 97.3%. Our approach may enable the development of predictive systems for humidity sensitive sensors under ambient moisture conditions, towards the realisation of low-power, miniaturised adaptive air quality monitoring.","Inkjet on CMOS,Temperature modulation,Machine learning,Cluster analysis,Principal component analysis,Factor analysis,Electronic nose",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Chemistry,Electrochemistry,Instruments & Instrumentation",,6.743,"SENSOR,NANOCOMPOSITES,SURFACE,HYBRID,VAPOR",SENSORS AND ACTUATORS B-CHEMICAL,,
88,Evolutionary Denoising-Based Machine Learning for Detecting Knee Disorders,52,3,2565-2581,"Parisi Luca,RaviChandran Narrendar","Parisi L,RaviChandran N",Parisi L,10.1007/s11063-020-10361-1,Coventry University,"Surface electromyography (sEMG) is a non-invasive tool that can aid physiological assessment of knee disorders towards clinical interventions. Machine Learning (ML) is widely used to classify sEMG data to help with early detection of knee disorders; however, the inherent noise and the high non-linearity of sEMG signals make pattern recognition a challenging task. This study aims to partly overcome these challenges with existing ML-based classifiers by denoising sEMG signals further via an innovative two-fold evolutionary approach. A novel Genetic Algorithm-based denoising approach is applied to sEMG data to decrease the search space for pattern-related classification. Thereafter, the proposed denoising technique is coupled with an ML-based classifier to improve the discrimination between physiological and pathophysiological knee functions from sEMG data by optimising its hyperparameters too. Thus, the novel evolutionary approach serves two purposes. Firstly, it further reduces noise in sEMG signals via a new GA-based denoising technique to concurrently maximise mutual information and minimise entropy; secondly, it also enables the optimisation of the classifier's hyperparameters. The classification performance of the resulting hybrid algorithm was validated using sEMG data on 144 subjects (67 patients with knee disorders, 77 healthy subjects) and was found higher (ACC = 99.57%, 95% CI: 99.47-99.66; AUC = 1, 95% CI: 0.98-1) than that of similar ML algorithms and published studies. The hybrid algorithm achieved the highest classification performance by leveraging an evolutionary approach for effective denoising and hyperparameter optimisation, whilst retaining the lowest computational cost. Thus, the proposed evolutionary denoising ML-based classifier is deemed an accurate and reliable decision support system to aid the detection of knee disorders.","Diagnosis,Decision support system,Machine learning,Support vector machine,Knee disorder,Genetic algorithm",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,2.884,"GROUND,REACTION,FORCE,GENETIC,ALGORITHM,ADDUCTION,MOMENT,OSTEOARTHRITIS,NETWORK",NEURAL PROCESSING LETTERS,,
89,Sensitivity and dimensionality of atomic environment representations used for machine learning interatomic potentials,153,14,,"Onat Berk,Ortner Christoph,Kermode James R.","Onat B,Ortner C,Kermode JR",Onat B,10.1063/5.0016005,University of Warwick,"Faithfully representing chemical environments is essential for describing materials and molecules with machine learning approaches. Here, we present a systematic classification of these representations and then investigate (i) the sensitivity to perturbations and (ii) the effective dimensionality of a variety of atomic environment representations and over a range of material datasets. Representations investigated include atom centered symmetry functions, Chebyshev Polynomial Symmetry Functions (CHSF), smooth overlap of atomic positions, many-body tensor representation, and atomic cluster expansion. In area (i), we show that none of the atomic environment representations are linearly stable under tangential perturbations and that for CHSF, there are instabilities for particular choices of perturbation, which we show can be removed with a slight redefinition of the representation. In area (ii), we find that most representations can be compressed significantly without loss of precision and, further, that selecting optimal subsets of a representation method improves the accuracy of regression models built for a given dataset.","NEURAL-NETWORK POTENTIALS,PERFORMANCE",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Chemistry,Physics",,3.166,"NEURAL-NETWORK,POTENTIALS,PERFORMANCE",JOURNAL OF CHEMICAL PHYSICS,http://wrap.warwick.ac.uk/143090/1/WRAP-Sensitivity-dimensionality-atomic-environment-machine-potentials-Onat-2020.pdf,
90,EEG signal processing with separable convolutional neural network for automatic scoring of sleeping stage,410,,220-228,"Fernandez-Blanco Enrique,Rivero Daniel,Pazos Alejandro","Fernandez-Blanco E,Rivero D,Pazos A",Fernandez-Blanco E,10.1016/j.neucom.2020.05.085,Universidade da Coruna,"Nowadays, among the Deep Learning works, there is a tendency to develop networks with millions of trainable parameters. However, this tendency has two main drawbacks: overfitting and resource consumption due to the low-quality features extracted by those networks. This paper presents a study focused on the scoring of sleeping EEG signals to measure if the increase of the pressure on the features due to a reduction of the number though different techniques results in a benefit. The work also studies the convenience of increasing the number of input signals in order to allow the network to extract better features. Additionally, it might be highlighted that the presented model achieves comparable results to the state-of-the-art with 1000 times less trainable and the presented model uses the whole dataset instead of the simplified versions in the published literature. (C) 2020 Elsevier B.V. All rights reserved.","Convolutional neural networks,Deep learning,EEG,Signal processing,Sleep scoring",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"EPILEPTIC,SEIZURES,IDENTIFICATION,SYSTEM,ADULTS,DEPTH",NEUROCOMPUTING,,
91,Deep learning for EEG-based biometric recognition,410,,374-386,Maiorana Emanuele,Maiorana E,Maiorana E,10.1016/j.neucom.2020.06.009,Roma Tre University,"The exploitation of brain signals for biometric recognition purposes has received significant attention from the scientific community in the last decade, with most of the efforts so far devoted to the quest for discriminative information within electroencephalography (EEG) recordings. Yet, currently-achievable recognition rates are still not comparable with those granted by more-commonly-used biometric characteristics, posing an issue for the practical deployment of EEG-based recognition in reallife applications. Within this regard, the present study investigates the effectiveness of deep learning techniques in extracting distinctive features from EEG signals. Both convolutional and recurrent neural networks, as well as their combinations, are employed as strategies to derive personal identifiers from the collected EEG data. In order to assess the robustness of the considered techniques, an extensive set of experimental tests is conducted under very challenging conditions, trying to determine whether it is feasible to identify subjects through their brain signals regardless the performed mental task, and comparing acquisitions collected at a temporal distance greater than one year. The obtained results suggest that the proposed networks are actually able to exploit the dynamic temporal behavior of EEG signals to achieve high-level accuracy for brain-based biometric recognition. (C) 2020 Elsevier B.V. All rights reserved.","Biometrics,Electroencephalography,Deep learning,Convolutional neural networks,Recurrent neural networks",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"PERMANENCE,SIGNALS",NEUROCOMPUTING,,
92,Random-telegraph-noise-enabled true random number generator for hardware security,10,1,,"Brown James,Zhang Jian Fu,Zhou Bo,Mehedi Mehzabeen,Freitas Pedro,Marsland John,Ji Zhigang","Brown J,Zhang JF,Zhou B,Mehedi M,Freitas P,Marsland J,Ji ZG",Brown J; Zhang JF,10.1038/s41598-020-74351-y,Liverpool John Moores University,"The future security of Internet of Things is a key concern in the cyber-security field. One of the key issues is the ability to generate random numbers with strict power and area constrains. ""True Random Number Generators"" have been presented as a potential solution to this problem but improvements in output bit rate, power consumption, and design complexity must be made. In this work we present a novel and experimentally verified ""True Random Number Generator"" that uses exclusively conventional CMOS technology as well as offering key improvements over previous designs in complexity, output bitrate, and power consumption. It uses the inherent randomness of telegraph noise in the channel current of a single CMOS transistor as an entropy source. For the first time multi-level and abnormal telegraph noise can be utilised, which greatly reduces device selectivity and offers much greater bitrates. The design is verified using a breadboard and FPGA proof of concept circuit and passes all 15 of the NIST randomness tests without any need for post-processing of the generated bitstream. The design also shows resilience against machine learning attacks performed by the LSTM neural network.",,Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,5.134,,SCIENTIFIC REPORTS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7560754,
93,Machine learning lattice constants for cubic perovskite A(2)(2)(+)BB ' O-6 compounds,22,38,6385-6397,"Zhang Yun,Xu Xiaojie","Zhang Y,Xu XJ",Zhang Y,10.1039/d0ce00928h,University of North Carolina,"Double perovskite oxides have attracted great attention in the past decade due to their unique and versatile material properties. The lattice constant, a, as the only variable parameter among the six parameters in the cubic structure, has a significant impact on the structural stability, electronic structure, magnetic ordering, and thus material performance. In this work, a Gaussian process regression (GPR) model is developed to elucidate the statistical relationship among ionic radii, electronegativities, oxidation states, and lattice constants for cubic perovskite A(2)(2)(+)BB'O-6 compounds. A total of 147 samples with lattice constants ranging from 7.700 angstrom to 8.890 angstrom are explored. The modeling approach demonstrates a high degree of accuracy and stability, contributing to efficient and low-cost estimations of lattice constants.","CRYSTAL,OXIDE,PREDICTION,NEUTRON,SR,BA",Article,"ROYAL SOC CHEMISTRY, THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND","Chemistry,Crystallography",,3.297,"CRYSTAL,OXIDE,PREDICTION,NEUTRON,SR,BA",CRYSTENGCOMM,,
94,CASTLE: cell adhesion with supervised training and learning environment,53,42,,"Gilbert S. G.,Krautter F.,Cooper D.,Chimen M.,Iqbal A. J.,Spill F.","Gilbert SG,Krautter F,Cooper D,Chimen M,Iqbal AJ,Spill F",Gilbert SG,10.1088/1361-6463/ab9e35,University of Birmingham,"Different types of microscopy are used to uncover signatures of cell adhesion and mechanics. Automating the identification and analysis often involve sacrificial routines of cell manipulation such asin vitrostaining. Phase-contrast microscopy (PCM) is rarely used in automation due to the difficulties with poor quality images. However, it is the least intrusive method to provide insights into the dynamics of cells, where other types of microscopy are too destructive to monitor. In this study, we propose an efficient workflow to automate cell counting and morphology in PCM images. We introduce Cell Adhesion with Supervised Training and Learning Environment (CASTLE), available as a series of additional plugins to ImageJ. CASTLE combines effective techniques for phase-contrast image processing with statistical analysis and machine learning algorithms to interpret the results. The proposed workflow was validated by comparing the results to a manual count and manual segmentation of cells in images investigating different adherent cell types, including monocytes, neutrophils and platelets. In addition, the effect of different molecules on cell adhesion was characterised using CASTLE. For example, we demonstate that Galectin-9 leads to differences in adhesion of leukocytes. CASTLE also provides information using machine learning techniques, namely principal component analysis andk-means clustering, to distinguish morphology currently inaccessible with manual methods. All scripts and documentation are open-source and available at the corresponding GitLab project.","machine learning,cell adhesion,cell morphology,galectins,imagej,ilastik,image analysis",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,3.041,,JOURNAL OF PHYSICS D-APPLIED PHYSICS,https://research.birmingham.ac.uk/portal/files/105877619/gilberts2020castle.pdf,
95,Principal Slip Zone determination in the Wenchuan earthquake Fault Scientific Drilling project-hole 1: considering the Bayesian discriminant function,68,6,1595-1607,"Fang Sinan,Zhang Zhansong,Wang Zhi,Pan Heping,Du Ting","Fang SN,Zhang ZS,Wang Z,Pan HP,Du T",Fang SN,10.1007/s11600-020-00496-z,Yangtze University,"Accurate determination of the Principal Slip Zone (PSZ) of earthquake fault zones is a key task of earthquake Fault Scientific Drilling for future earthquake control. The fault zone structure of Wenchuan earthquake is complex, and there are many strong earthquakes recorded on the fault zone, which make determining the PSZ in the Wenchuan earthquake Fault Scientific Drilling project-hole 1 (WFSD-1) difficult. At present, core analysis of whole coring is the decisive method for determining PSZ depth, and the fresh fault gouge at 589.2 m is the PSZ in WFSD-1. Abundant and comprehensive logging data can only be used as evidence to judge the PSZ. Based on the discrimination function and hyperplane equation in Bayesian discriminant classification, we derive a new algorithm for computing the PSZ possibility using a Bayesian Discrimination function (PSZP-BDF) based on the simplified model, and set up a mode to determine the PSZ directly using machine learning of well logging. For the verification of WFSD-1, the fault gouges are successfully identified and the PSZ depth is accurately located. The algorithm objectively learns the sample data, which is naturally adaptive to the region. The calculation procedure is simple and does not require expensive coring data or heavy core tests in the well. The calculation speed is fast, using multiple physical data types. The PSZP-BDF algorithm is suitable for processing and interpreting earthquake fault scientific drilling data.","Wenchuan earthquake Fault Scientific Drilling (WFSD),Principal Slip Zone (PSZ),Bayesian discrimination,Logging",Article,"SPRINGER INTERNATIONAL PUBLISHING AG, GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND",Geochemistry & Geophysics,,1.657,"PSEUDOTACHYLYTES,FRICTION,WFSD-1",ACTA GEOPHYSICA,,
96,Near-hysteresis-free soft tactile electronic skins for wearables and reliable machine learning,117,41,25352-25359,"Yao Haicheng,Yang Weidong,Cheng Wen,Tan Yu Jun,See Hian Hian,Li Si,Ali Hashina Parveen Anwar,Lim Brian Z. H.,Liu Zhuangjian,Tee Benjamin C. K.","Yao HC,Yang WD,Cheng W,Tan YJ,See HH,Li S,Ali HPA,Lim BZH,Liu ZJ,Tee BCK",Tee BCK,10.1073/pnas.2010989117,National University of Singapore,"Electronic skins are essential for real-time health monitoring and tactile perception in robots. Although the use of soft elastomers and microstructures have improved the sensitivity and pressuresensing range of tactile sensors, the intrinsic viscoelasticity of soft polymeric materials remains a long-standing challenge resulting in cyclic hysteresis. This causes sensor data variations between contact events that negatively impact the accuracy and reliability. Here, we introduce the Tactile Resistive Annularly Cracked E-Skin (TRACE) sensor to address the inherent trade-off between sensitivity and hysteresis in tactile sensors when using soft materials. We discovered that piezoresistive sensors made using an array of three-dimensional (3D) metallic annular cracks on polymeric microstructures possess high sensitivities (> 10(7) Omega . kPa(-1)), low hysteresis (2.99 +/- 1.37%) over a wide pressure range (0-20 kPa), and fast response (400 Hz). We demonstrate that TRACE sensors can accurately detect and measure the pulse wave velocity (PWV) when skin mounted. Moreover, we show that these tactile sensors when arrayed enabled fast reliable one-touch surface texture classification with neuromorphic encoding and deep learning algorithms.","sensor,electronic skin,machine learning,robotics,wearable",Article,"NATL ACAD SCIENCES, 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA",Science & Technology - Other Topics,,12.291,"PULSE-WAVE,VELOCITY,PRESSURE,SENSORS,ARTERIAL,STIFFNESS",PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7568242,
97,DeepLiverNet: a deep transfer learning model for classifying liver stiffness using clinical and T2-weighted magnetic resonance imaging data in children and young adults,51,3,392-402,"Li Hailong,He Lili,Dudley Jonathan A.,Maloney Thomas C.,Somasundaram Elanchezhian,Brady Samuel L.,Parikh Nehal A.,Dillman Jonathan R.","Li HL,He LL,Dudley JA,Maloney TC,Somasundaram E,Brady SL,Parikh NA,Dillman JR",Dillman JR,10.1007/s00247-020-04854-3,Cincinnati Children's Hospital Medical Center,"Background Although MR elastography allows for quantitative evaluation of liver stiffness to assess chronic liver diseases, it has associated drawbacks related to additional scanning time, patient discomfort, and added costs. Objective To develop a machine learning model that can categorically classify the severity of liver stiffness using both anatomical T2-weighted MRI and clinical data for children and young adults with known or suspected pediatric chronic liver diseases. Materials and methods We included 273 subjects with known or suspected chronic liver disease. We extracted data including axial T2-weighted fast spin-echo fat-suppressed images, clinical data (e.g., demographic/anthropomorphic data, particular medical diagnoses, laboratory values) and MR elastography liver stiffness measurements. We propose DeepLiverNet (a deep transfer learning model) to classify patients into one of two groups: no/mild liver stiffening (<3 kPa) or moderate/severe liver stiffening (>= 3 kPa). We conducted internal cross-validation using 178 subjects, and external validation using an independent cohort of 95 subjects. We assessed diagnostic performance using accuracy, sensitivity, specificity and area under the receiver operating characteristic curve (AuROC). Results In the internal cross-validation experiment, the combination of clinical and imaging data produced the best performance (AuROC=0.86) compared to clinical (AuROC=0.83) or imaging (AuROC=0.80) data alone. Using both clinical and imaging data, the DeepLiverNet correctly classified patients with accuracy of 88.0%, sensitivity of 74.3% and specificity of 94.6%. In our external validation experiment, this same deep learning model achieved an accuracy of 80.0%, sensitivity of 61.1%, specificity of 91.5% and AuROC of 0.79. Conclusion A deep learning model that incorporates clinical data and anatomical T2-weighted MR images might provide a means of risk-stratifying liver stiffness and directing the use of MR elastography.","Children,Chronic liver disease,Deep learning,Liver,Liver stiffness,Magnetic resonance elastography,Magnetic resonance imaging,Risk stratification",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Pediatrics,Radiology, Nuclear Medicine & Medical Imaging",,2.355,"HEPATIC-FIBROSIS,DIAGNOSIS,CLASSIFICATION,ELASTOGRAPHY",PEDIATRIC RADIOLOGY,,
98,Closing the Gap Between Modeling and Experiments in the Self-Assembly of Biomolecules at Interfaces and in Solution,32,19,8043-8059,"Sampath Janani,Alamdari Sarah,Pfaendtner Jim","Sampath J,Alamdari S,Pfaendtner J",Pfaendtner J,10.1021/acs.chemmater.0c01891,University of Washington,"Molecular self-assembly is a powerful tool in materials design, wherein noncovalent interactions like electrostatic, hydrophobic, hydrogen bonding, and van der Waals can be exploited to produce supramolecular nanostructures that are functional and highly tunable. Biomolecules are attractive building blocks, as they are biocompatible, biodegradable, and adopt a wide array of higher order structures. Moreover, naturally occurring protein systems display a manifold of structures and interactions that can be replicated in synthetic biomolecules. In this perspective, we highlight advances in multiscale simulation techniques across broad spatiotemporal scales that can aid in characterizing self-assembly of hybrid and hierarchical bionanomaterial systems, with an emphasis on physics-based simulation approaches currently employed to study biomolecules at mineral interfaces. The power of these approaches is highlighted across a few recent areas where molecular simulations have advanced our understanding of self-assembly spanning peptides to protein self-assembly. Looking forward, we discuss how in the near future emerging methods in statistical and machine learning will advance this research field in all areas from expanding the capabilities of physics-based simulation methods to enabling new analyses of high throughput experiments. These advances will pave the way for understanding the molecular recognition patterns in systems that are dictated by self-assembly-biomineralizing peptides, hierarchical peptoids, and large protein assemblies-and will aid in the development of a new synthesis science for achieving precise molecular control in materials design.","SOLID-STATE NMR,TRANSMISSION ELECTRON-MICROSCOPY,TOBACCO-MOSAIC-VIRUS,MOLECULAR-DYNAMICS,FORCE-FIELD,SECONDARY-STRUCTURE,PEPTOID POLYMERS,PHASE-SEPARATION,PEPTIDE,BINDING",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Materials Science",,10.837,"SOLID-STATE,NMR,TRANSMISSION,ELECTRON-MICROSCOPY,TOBACCO-MOSAIC-VIRUS,MOLECULAR-DYNAMICS,FORCE-FIELD,SECONDARY-STRUCTURE,PEPTOID,POLYMERS,PHASE-SEPARATION,PEPTIDE,BINDING",CHEMISTRY OF MATERIALS,https://www.osti.gov/biblio/1781117,
99,Neural network constitutive model for crystal structures,67,1,185-206,"Im Sunyoung,Kim Hyungjun,Kim Wonbae,Cho Maenghyo","Im S,Kim H,Kim W,Cho M",Cho M,10.1007/s00466-020-01927-w,Seoul National University (SNU),"Neural network constitutive models (NNCMs) for crystal structures are proposed based on computationally generated high-fidelity data. Stress, and tangent modulus data are generated under various strain states using empirical potentials and first-principles calculations. Strain-stress artificial neural network and strain-tangent modulus ANN are constructed. The symmetry conditions are considered for cubic, tetragonal, and hexagonal structures. The NNCMs of six face-centered cubic materials (Cu, Ni, Pd, Pt, Ag, and Au), two diamond cubic materials (Si, Ge), two tetragonal crystal materials (TiO2, ZnO), and two hexagonal crystal materials (ZnO, GaN) are constructed and tested under the untrained strain state. In particular, the performance of NNCM for cubic structure is better compared with that of the classical model. The suggested NNCM can be embedded into a nonlinear finite element method, and numerical examples are performed to verify the proposed NNCM.","Neural network constitutive model (NNCM),Crystal structure,Anisotropic hyperelastic model,Machine learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Mathematics,Mechanics",,4.209,"TOTAL-ENERGY,CALCULATIONS,HYPERELASTIC,MODEL,MATERIAL,BEHAVIOR,ELASTICITY,IMPLEMENTATION,FORMULATION,DERIVATION,MECHANICS,MOLECULES",COMPUTATIONAL MECHANICS,,
100,Reduced-Order Models for Ranking Damage Initiation in Dual-Phase Composites Using Bayesian Neural Networks,72,12,4359-4369,"Venkatraman Aditya,Zapiain David Montes De Oca,Kalidindi Surya R.","Venkatraman A,Zapiain DMD,Kalidindi SR",Kalidindi SR,10.1007/s11837-020-04387-y,University System of Georgia,"The design and development of materials with increased damage resilience is often impeded by the difficulty in establishing the precise linkages, with quantified uncertainty, between the complex details of the internal structure of materials and their potential for damage initiation. We present herein a novel machine-learning-based approach for establishing reduced-order models (ROMs) that relate the microstructure of a material to its susceptibility to damage initiation. This is accomplished by combining the recently established materials knowledge system framework with toolsets such as feedforward neural networks and variational Bayesian inference. The overall approach is found to be versatile for training scalable and accurate ROMs with quantified prediction uncertainty for the propensity to damage initiation for a variety of microstructures. The approach is applicable to a large class of challenges encountered in multiscale materials design efforts.","MULTIPHASE MATERIALS,FRACTURE INITIATION,DUCTILE FAILURE,STRESS TRIAXIALITY,ELASTIC RESPONSE,FRAMEWORK,MICROMECHANICS,REPRESENTATION,PERFORMANCE,STATISTICS",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Materials Science,Metallurgy & Metallurgical Engineering,Mineralogy,Mining & Mineral Processing",,2.989,"MULTIPHASE,MATERIALS,FRACTURE,INITIATION,DUCTILE,FAILURE,STRESS,TRIAXIALITY,ELASTIC,RESPONSE,FRAMEWORK,MICROMECHANICS,REPRESENTATION,PERFORMANCE,STATISTICS",JOM,,
