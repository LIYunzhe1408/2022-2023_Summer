,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Modeling Brain Diverse and Complex Hemodynamic Response Patterns via Deep Recurrent Autoencoder,12,4,733-743,"Cui Yan,Zhao Shijie,Chen Yaowu,Han Junwei,Guo Lei,Xie Li,Liu Tianming","Cui Y,Zhao SJ,Chen YW,Han JW,Guo L,Xie L,Liu TM",Xie L,10.1109/TCDS.2019.2949195,Zhejiang University,"For decades, a variety of task-based functional MRI (tfMRI) data analysis approaches have been developed, including the general linear model (GLM), sparse representations, and independent component analysis (ICA). However, these methods are mainly shallow models and are limited in faithfully modeling the complex, diverse, and concurrent spatial-temporal functional brain activities. Recently, recurrent neural networks (RNNs) have demonstrated great superiority in modeling temporal dependency of signals, while autoencoder models have been proven to be effective in automatically estimating the optimal representations of the original data. These characteristics of RNNs and autoencoders naturally meet the requirement of modeling hemodynamic response patterns in tfMRI data. Thus, we propose a novel unsupervised framework of deep recurrent autoencoder (DRAE) for modeling hemodynamic response patterns in this article. The basic idea of the DRAE model is to combine the deep RNN and the autoencoder to automatically characterize the meaningful functional brain networks and corresponding diverse and complex hemodynamic response patterns simultaneously. The experimental results demonstrate the superiority of the proposed DRAE model in automatically estimating the diverse and complex hemodynamic response patterns.","Brain modeling,Hemodynamics,Data models,Task analysis,Recurrent neural networks,Feature extraction,Autoencoder,brain network,deep learning,hemodynamic response pattern,recurrent neural network (RNN),task-based functional magnetic resonance imaging (tfMRI)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Robotics,Neurosciences & Neurology",,3.513,"CONVOLUTIONAL,NEURAL-NETWORKS,FUNCTIONAL,NETWORKS,FMRI,REPRESENTATION,ARCHITECTURE,ATLASES",IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS,,
2,An Edge-Cloud-Aided High-Order Possibilistic c-Means Algorithm for Big Data Clustering,28,12,3100-3109,"Bu Fanyu,Zhang Qingchen,Yang Laurence T.,Yu Hang","Bu FY,Zhang QC,Yang LT,Yu H",Yang LT,10.1109/TFUZZ.2020.2992634,University of Electronic Science & Technology of China,"In this article, a high-order possibilistic c-means algorithm (HOPCM) based on the double-layer deep computation model (DCM) is proposed for big data clustering. Specifically, an asymmetric tensor autoencoder is presented to efficiently train the double-layer DCM for big data feature learning. Furthermore, an edge-cloud computing system is developed to improve the clustering efficiency. In the edge-cloud system, the computation-intensive tasks including the parameters' training and clustering are offloaded to the cloud while the task of feature learning is performed at the edge of network. Finally, we conduct extensive experiments to evaluate the performance of the presented algorithm by comparing it with other two representative big data clustering algorithms, i.e., the standard HOPCM and the HOPCM based on deep learning. Results demonstrate that the presented algorithm achieves higher accuracy than the two compared algorithms and furthermore the clustering efficiency are significantly improved by the developed edge-cloud computing system.","Clustering algorithms,Tensors,Big Data,Computational modeling,Cloud computing,Standards,Phase change materials,Big data,deep computation model (DCM),edge-cloud computing system,possibilistic c-means approach",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.444,MODEL,IEEE TRANSACTIONS ON FUZZY SYSTEMS,,
3,Hierarchical Fused Model With Deep Learning and Type-2 Fuzzy Learning for Breast Cancer Diagnosis,28,12,3204-3218,"Shen Tianyu,Wang Jiangong,Gou Chao,Wang Fei-Yue","Shen TY,Wang JG,Gou C,Wang FY",Gou C,10.1109/TFUZZ.2020.3013681,Sun Yat Sen University,"Breast cancer diagnosis based on medical imaging necessitates both fine-grained lesion segmentation and disease grading. Although deep learning (DL) offers an emerging and powerful paradigm of feature learning for these two tasks, it is hampered from popularizing in practical application due to the lack of interpretability, generalization ability, and large labeled training sets. In this article, we propose a hierarchical fused model based on DL and fuzzy learning to overcome the drawbacks for pixelwise segmentation and disease grading of mammography breast images. The proposed system consists of a segmentation model (ResU-segNet) and a hierarchical fuzzy classifier (HFC) that is a fusion of interval type-2 possibilistic fuzzy c-means and fuzzy neural network. The ResU-segNet segments the masks of mass regions from the images through convolutional neural networks, while the HFC encodes the features from mass images and masks to obtain the disease grading through fuzzy representation and rule-based learning. Through the integration of feature extraction aided by domain knowledge and fuzzy learning, the system achieves favorable performance in a few-shot learning manner, and the deterioration of cross-dataset generalization ability is alleviated. In addition, the interpretability is further enhanced. The effectiveness of the proposed system is analyzed on the publicly available mammogram database of INbreast and a private database through cross-validation. Thorough comparative experiments are also conducted and demonstrated.","Image segmentation,Biomedical imaging,Fuzzy sets,Breast cancer,Breast cancer,deep learning (DL),fuzzy classifier (FC),interval type-2 possibilistic fuzzy c-means (IT2PFCM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.444,"NEURAL-NETWORK,CLASSIFICATION,MAMMOGRAMS,ALGORITHM,TUMOR",IEEE TRANSACTIONS ON FUZZY SYSTEMS,,
4,DML-GANR: Deep Metric Learning With Generative Adversarial Network Regularization for High Spatial Resolution Remote Sensing Image Retrieval,58,12,8888-8904,"Cao Yun,Wang Yuebin,Peng Junhuan,Zhang Liqiang,Xu Linlin,Yan Kai,Li Lihua","Cao Y,Wang YB,Peng JH,Zhang LQ,Xu LL,Yan K,Li LH",Wang YB,10.1109/TGRS.2020.2991545,China University of Geosciences,"With a small number of labeled samples for training, it can save considerable manpower and material resources, especially when the amount of high spatial resolution remote sensing images (HSR-RSIs) increases considerably. However, many deep models face the problem of overfitting when using a small number of labeled samples. This might degrade HSR-RSI retrieval accuracy. Aiming at obtaining more accurate HSR-RSI retrieval performance with small training samples, we develop a deep metric learning approach with generative adversarial network regularization (DML-GANR) for HSR-RSI retrieval. The DML-GANR starts from a high-level feature extraction (HFE) to extract high-level features, which includes convolutional layers and fully connected (FC) layers. Each of the FC layers is constructed by deep metric learning (DML) to maximize the interclass variations and minimize the intraclass variations. The generative adversarial network (GAN) is adopted to mitigate the overfitting problem and validate the qualities of extracted high-level features. DML-GANR is optimized through a customized approach, and the optimal parameters are obtained. The experimental results on the three data sets demonstrate the superior performance of DML-GANR over state-of-the-art techniques in HSR-RSI retrieval.","Feature extraction,Measurement,Generative adversarial networks,Gallium nitride,Image retrieval,Generators,Training,Convolutional neural network (CNN),generative adversarial network (GAN),deep metric learning (DML),image retrieval,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Geochemistry & Geophysics,Engineering,Remote Sensing,Imaging Science & Photographic Technology",,6.086,"CONVOLUTIONAL,NEURAL-NETWORKS,CLASSIFICATION,DISTANCE",IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,http://arxiv.org/pdf/2010.03116,
5,Rectifying Supporting Regions With Mixed and Active Supervision for Rib Fracture Recognition,39,12,3843-3854,"Huang Yi-Jie,Liu Weiping,Wang Xiuying,Fang Qu,Wang Renzhen,Wang Yi,Chen Huai,Chen Hao,Meng Deyu,Wang Lisheng","Huang YJ,Liu WP,Wang XY,Fang Q,Wang RZ,Wang Y,Chen H,Chen H,Meng DY,Wang LS",Wang LS,10.1109/TMI.2020.3006138,Shanghai Jiao Tong University,"Automatic rib fracture recognition from chest X-ray images is clinically important yet challenging due to weak saliency of fractures. Weakly Supervised Learning (WSL) models recognize fractures by learning from large-scale image-level labels. In WSL, Class Activation Maps (CAMs) are considered to provide spatial interpretations on classification decisions. However, the high-responding regions, namely Supporting Regions of CAMs may erroneously lock to regions irrelevant to fractures, which thereby raises concerns on the reliability of WSL models for clinical applications. Currently available Mixed Supervised Learning (MSL) models utilize object-level labels to assist fitting WSL-derived CAMs. However, as a prerequisite of MSL, the large quantity of precisely delineated labels is rarely available for rib fracture tasks. To address these problems, this paper proposes a novel MSL framework. Firstly, by embedding the adversarial classification learning into WSL frameworks, the proposed Biased Correlation Decoupling and Instance Separation Enhancing strategies guide CAMs to true fractures indirectly. The CAM guidance is insensitive to shape and size variations of object descriptions, thereby enables robust learning from bounding boxes. Secondly, to further minimize annotation cost in MSL, a CAM-based Active Learning strategy is proposed to recognize and annotate samples whose Supporting Regions cannot be confidently localized. Consequently, the quantity demand of object-level labels can be reduced without compromising the performance. Over a chest X-ray rib-fracture dataset of 10966 images, the experimental results show that our method produces rational Supporting Regions to interpret its classification decisions and outperforms competing methods at an expense of annotating 20% of the positive samples with bounding boxes.","Cams,Ribs,X-ray imaging,Annotations,Image recognition,Training,Supervised learning,Convolutional neural network~(CNN),class activation map~(CAM),supporting region,mixed supervised learning~(MSL),active learning~(AL)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,,
6,Misshapen Pelvis Landmark Detection With Local-Global Feature Learning for Diagnosing Developmental Dysplasia of the Hip,39,12,3944-3954,"Liu Chuanbin,Xie Hongtao,Zhang Sicheng,Mao Zhendong,Sun Jun,Zhang Yongdong","Liu CB,Xie HT,Zhang SC,Mao ZD,Sun J,Zhang YD",Xie HT,10.1109/TMI.2020.3008382,Chinese Academy of Sciences,"Developmental dysplasia of the hip (DDH) is one of the most common orthopedic disorders in infants and young children. Accurately detecting and identifying the misshapen anatomical landmarks plays a crucial role in the diagnosis of DDH. However, the diversity during the calcification and the deformity due to the dislocation lead it a difficult task to detect the misshapen pelvis landmarks for both human expert and computer. Generally, the anatomical landmarks exhibit stable morphological features in part regions and rigid structural features in long ranges, which can be strong identification for the landmarks. In this paper, we investigate the local morphological features and global structural features for the misshapen landmark detection with a novel Pyramid Non-local UNet (PN-UNet). Firstly, we mine the local morphological features with a series of convolutional neural network (CNN) stacks, and convert the detection of a landmark to the segmentation of the landmark's local neighborhood by UNet. Secondly, a non-local module is employed to capture the global structural features with high-level structural knowledge. With the end-to-end and accurate detection of pelvis landmarks, we realize a fully automatic and highly reliable diagnosis of DDH. In addition, a dataset with 10,000 pelvis X-ray images is constructed in our work. It is the first public dataset for diagnosing DDH and has been already released for open research. To the best of our knowledge, this is the first attempt to apply deep learning method in the diagnosis of DDH. Experimental results show that our approach achieves an excellent precision in landmark detection (average point to point error of 0.9286mm) and illness diagnosis over human experts. Project is available at http://imcc.ustc.edu.cn/project/ddh/.","Pelvis,Feature extraction,Deep learning,Hip,X-ray imaging,Medical diagnostic imaging,Developmental dysplasia of the hip,landmark detection,medical imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORKS,IMAGES,CLASSIFICATION,SEGMENTATION",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
7,Deep Learning-Based Regression and Classification for Automatic Landmark Localization in Medical Images,39,12,4011-4022,"Noothout Julia M. H.,de Vos Bob D.,Wolterink Jelmer M.,Postma Elbrich M.,Smeets Paul A. M.,Takx Richard A. P.,Leiner Tim,Viergever Max A.,Isgum Ivana","Noothout JMH,de Vos BD,Wolterink JM,Postma EM,Smeets PAM,Takx RAP,Leiner T,Viergever MA,Isgum I",Noothout JMH,10.1109/TMI.2020.3009002,Utrecht University,"In this study, we propose a fast and accurate method to automatically localize anatomical landmarks in medical images. We employ a global-to-local localization approach using fully convolutional neural networks (FCNNs). First, a global FCNN localizes multiple landmarks through the analysis of image patches, performing regression and classification simultaneously. In regression, displacement vectors pointing from the center of image patches towards landmark locations are determined. In classification, presence of landmarks of interest in the patch is established. Global landmark locations are obtained by averaging the predicted displacement vectors, where the contribution of each displacement vector is weighted by the posterior classification probability of the patch that it is pointing from. Subsequently, for each landmark localized with global localization, local analysis is performed. Specialized FCNNs refine the global landmark locations by analyzing local sub-images in a similar manner, i.e. by performing regression and classification simultaneously and combining the results. Evaluation was performed through localization of 8 anatomical landmarks in CCTA scans, 2 landmarks in olfactory MR scans, and 19 landmarks in cephalometric X-rays. We demonstrate that the method performs similarly to a second observer and is able to localize landmarks in a diverse set of medical images, differing in image modality, image dimensionality, and anatomical coverage.","Task analysis,Heating systems,Convolutional neural networks,Medical diagnostic imaging,Kernel,Head,Landmark localization,convolutional neural network,deep learning,classification,regression,cardiac CT,cephalometric X-ray,olfactory MR",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONFIGURATION,CT",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2007.05295,
8,Self-Supervised Feature Learning via Exploiting Multi-Modal Data for Retinal Disease Diagnosis,39,12,4023-4033,"Li Xiaomeng,Jia Mengyu,Islam Md Tauhidul,Yu Lequan,Xing Lei","Li XM,Jia MY,Islam MT,Yu LQ,Xing L",Xing L,10.1109/TMI.2020.3008871,Stanford University,"The automatic diagnosis of various retinal diseases from fundus images is important to support clinical decision-making. However, developing such automatic solutions is challenging due to the requirement of a large amount of human-annotated data. Recently, unsupervised/self-supervised feature learning techniques receive a lot of attention, as they do not need massive annotations. Most of the current self-supervised methods are analyzed with single imaging modality and there is no method currently utilize multi-modal images for better results. Considering that the diagnostics of various vitreoretinal diseases can greatly benefit from another imaging modality, e.g., FFA, this paper presents a novel self-supervised feature learning method by effectively exploiting multi-modal data for retinal disease diagnosis. To achieve this, we first synthesize the corresponding FFA modality and then formulate a patient feature-based softmax embedding objective. Our objective learns both modality-invariant features and patient-similarity features. Through this mechanism, the neural network captures the semantically shared information across different modalities and the apparent visual similarity between patients. We evaluate our method on two public benchmark datasets for retinal disease diagnosis. The experimental results demonstrate that our method clearly outperforms other self-supervised feature learning methods and is comparable to the supervised baseline. Our code is available at GitHub.","Diseases,Image color analysis,Task analysis,Retina,Medical diagnosis,Photography,Learning systems,Retinal disease diagnosis,self-supervised learning,multi-modal data",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"MACULAR,DEGENERATION",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2007.11067,
9,Neuronal Population Reconstruction From Ultra-Scale Optical Microscopy Images via Progressive Learning,39,12,4034-4046,"Zhao Jie,Chen Xuejin,Xiong Zhiwei,Liu Dong,Zeng Junjie,Xie Chaoyu,Zhang Yueyi,Zha Zheng-Jun,Bi Guoqiang,Wu Feng","Zhao J,Chen XJ,Xiong ZW,Liu D,Zeng JJ,Xie CY,Zhang YY,Zha ZJ,Bi GQ,Wu F",Chen XJ,10.1109/TMI.2020.3009148,Chinese Academy of Sciences,"Reconstruction of neuronal populations from ultra-scale optical microscopy (OM) images is essential to investigate neuronal circuits and brain mechanisms. The noises, low contrast, huge memory requirement, and high computational cost pose significant challenges in the neuronal population reconstruction. Recently, many studies have been conducted to extract neuron signals using deep neural networks (DNNs). However, training such DNNs usually relies on a huge amount of voxel-wise annotations in OM images, which are expensive in terms of both finance and labor. In this paper, we propose a novel framework for dense neuronal population reconstruction from ultra-scale images. To solve the problem of high cost in obtaining manual annotations for training DNNs, we propose a progressive learning scheme for neuronal population reconstruction (PLNPR) which does not require any manual annotations. Our PLNPR scheme consists of a traditional neuron tracing module and a deep segmentation network that mutually complement and progressively promote each other. To reconstruct dense neuronal populations from a terabyte-sized ultra-scale image, we introduce an automatic framework which adaptively traces neurons block by block and fuses fragmented neurites in overlapped regions continuously and smoothly. We build a dataset ""VISoR-40"" which consists of 40 large-scale OM image blocks from cortical regions of a mouse. Extensive experimental results on our VISoR-40 dataset and the public BigNeuron dataset demonstrate the effectiveness and superiority of our method on neuronal population reconstruction and single neuron reconstruction. Furthermore, we successfully apply our method to reconstruct dense neuronal populations from an ultra-scale mouse brain slice. The proposed adaptive block propagation and fusion strategies greatly improve the completeness of neurites in dense neuronal population reconstruction.","Image reconstruction,Sociology,Statistics,Neurites,Noise measurement,Manuals,Neuronal population reconstruction,ultra-scale images,optical microscopy,progressive learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"BRAIN,SEGMENTATION,MODEL",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
10,Zoom in Lesions for Better Diagnosis: Attention Guided Deformation Network for WCE Image Classification,39,12,4047-4059,"Xing Xiaohan,Yuan Yixuan,Meng Max Q. -H.","Xing XH,Yuan YX,Meng MQH",Yuan YX,10.1109/TMI.2020.3010102,City University of Hong Kong,"Wireless capsule endoscopy (WCE) is a novel imaging tool that allows noninvasive visualization of the entire gastrointestinal (GI) tract without causing discomfort to patients. Convolutional neural networks (CNNs), though perform favorably against traditional machine learning methods, show limited capacity in WCE image classification due to the small lesions and background interference. To overcome these limits, we propose a two-branch Attention Guided Deformation Network (AGDN) for WCE image classification. Specifically, the attention maps of branch1 are utilized to guide the amplification of lesion regions on the input images of branch2, thus leading to better representation and inspection of the small lesions. What's more, we devise and insert Third-order Long-range Feature Aggregation (TLFA) modules into the network. By capturing long-range dependencies and aggregating contextual features, TLFAs endow the network with a global contextual view and stronger feature representation and discrimination capability. Furthermore, we propose a novel Deformation based Attention Consistency (DAC) loss to refine the attention maps and achieve the mutual promotion of the two branches. Finally, the global feature embeddings from the two branches are fused to make image label predictions. Extensive experiments show that the proposed AGDN outperforms state-of-the-art methods with an overall classification accuracy of 91.29% on two public WCE datasets. The source code is available at https://github.com/hathawayxxh/WCE-AGDN.","Lesions,Feature extraction,Strain,Diseases,Image analysis,Image recognition,Task analysis,Wireless capsule endoscopy,image classification,attention guided image deformation,long-range feature aggregation,attention consistency",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,,
11,Conquering Data Variations in Resolution: A Slice-Aware Multi-Branch Decoder Network,39,12,4174-4185,"Wang Shuxin,Cao Shilei,Chai Zhizhong,Wei Dong,Ma Kai,Wang Liansheng,Zheng Yefeng","Wang SX,Cao SL,Chai ZZ,Wei D,Ma K,Wang LS,Zheng YF",Wang LS,10.1109/TMI.2020.3014433,Xiamen University,"Fully convolutional neural networks have made promising progress in joint liver and liver tumor segmentation. Instead of following the debates over 2D versus 3D networks (for example, pursuing the balance between large-scale 2D pretraining and 3D context), in this paper, we novelly identify the wide variation in the ratio between intra- and inter-slice resolutions as a crucial obstacle to the performance. To tackle the mismatch between the intra- and inter-slice information, we propose a slice-aware 2.5D network that emphasizes extracting discriminative features utilizing not only in-plane semantics but also out-of-plane coherence for each separate slice. Specifically, we present a slice-wise multi-input multi-output architecture to instantiate such a design paradigm, which contains a Multi-Branch Decoder (MD) with a Slice-centric Attention Block (SAB) for learning slice-specific features and a Densely Connected Dice (DCD) loss to regularize the inter-slice predictions to be coherent and continuous. Based on the aforementioned innovations, we achieve state-of-the-art results on the MICCAI 2017 Liver Tumor Segmentation (LiTS) dataset. Besides, we also test our model on the ISBI 2019 Segmentation of THoracic Organs at Risk (SegTHOR) dataset, and the result proves the robustness and generalizability of the proposed method in other segmentation tasks.","Liver,Three-dimensional displays,Tumors,Two dimensional displays,Computed tomography,Decoding,Feature extraction,Liver and liver tumor segmentation,25D convolutional neural network,slice-aware design,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,SEGMENTATION,IEEE TRANSACTIONS ON MEDICAL IMAGING,,
12,DoFE: Domain-Oriented Feature Embedding for Generalizable Fundus Image Segmentation on Unseen Datasets,39,12,4237-4248,"Wang Shujun,Yu Lequan,Li Kang,Yang Xin,Fu Chi-Wing,Heng Pheng-Ann","Wang SJ,Yu LQ,Li K,Yang X,Fu CW,Heng PA",Yu LQ,10.1109/TMI.2020.3015224,Stanford University,"Deep convolutional neural networks have significantly boosted the performance of fundus image segmentation when test datasets have the same distribution as the training datasets. However, in clinical practice, medical images often exhibit variations in appearance for various reasons, e.g., different scanner vendors and image quality. These distribution discrepancies could lead the deep networks to over-fit on the training datasets and lack generalization ability on the unseen test datasets. To alleviate this issue, we present a novel Domain-oriented Feature Embedding (DoFE) framework to improve the generalization ability of CNNs on unseen target domains by exploring the knowledge from multiple source domains. Our DoFE framework dynamically enriches the image features with additional domain prior knowledge learned from multi-source domains to make the semantic features more discriminative. Specifically, we introduce a Domain Knowledge Pool to learn and memorize the prior information extracted from multi-source domains. Then the original image features are augmented with domain-oriented aggregated features, which are induced from the knowledge pool based on the similarity between the input image and multi-source domain images. We further design a novel domain code prediction branch to infer this similarity and employ an attention-guided mechanism to dynamically combine the aggregated features with the semantic features. We comprehensively evaluate our DoFE framework on two fundus image segmentation tasks, including the optic cup and disc segmentation and vessel segmentation. Our DoFE framework generates satisfying segmentation results on unseen datasets and surpasses other domain generalization and network regularization methods.","Image segmentation,Training,Feature extraction,Task analysis,Biomedical optical imaging,Optical imaging,Optic disc segmentation,optic cup segmentation,vessel segmentation,domain generalization,feature embedding",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CUP,SEGMENTATION,OPTIC,DISC,RETINAL,IMAGES",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2010.06208,
13,AttentionBoost: Learning What to Attend for Gland Segmentation in Histopathological Images by Boosting Fully Convolutional Networks,39,12,4262-4273,"Gunesli Gozde Nur,Sokmensuer Cenk,Gunduz-Demir Cigdem","Gunesli GN,Sokmensuer C,Gunduz-Demir C",Gunduz-Demir C,10.1109/TMI.2020.3015198,Ihsan Dogramaci Bilkent University,"Fully convolutional networks (FCNs) are widely used for instance segmentation. One important challenge is to sufficiently train these networks to yield good generalizations for hard-to-learn pixels, correct prediction of which may greatly affect the success. A typical group of such hard-to-learn pixels are boundaries between instances. Many studies have developed strategies to pay more attention to learning these boundary pixels. They include designing multi-task networks with an additional task of boundary prediction and increasing the weights of boundary pixels' predictions in the loss function. Such strategies require defining what to attend beforehand and incorporating this defined attention to the learning model. However, there may exist other groups of hard-to-learn pixels and manually defining and incorporating the appropriate attention for each group may not be feasible. In order to provide an adaptable solution to learn different groups of hard-to-learn pixels, this article proposes AttentionBoost, which is a new multi-attention learning model based on adaptive boosting, for the task of gland instance segmentation in histopathological images. AttentionBoost designs a multi-stage network and introduces a new loss adjustment mechanism for an FCN to adaptively learn what to attend at each stage directly on image data without necessitating any prior definition. This mechanism modulates the attention of each stage to correct the mistakes of previous stages, by adjusting the loss weight of each pixel prediction separately with respect to how accurate the previous stages are on this pixel. Working on histopathological images of colon tissues, our experiments demonstrate that the proposed AttentionBoost model improves the results of gland segmentation compared to its counterparts.","Glands,Task analysis,Image segmentation,Adaptation models,Training,Boosting,Electronic mail,Deep learning,attention learning,adaptive boosting,gland instance segmentation,instance segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,http://repository.bilkent.edu.tr/bitstream/11693/75447/1/AttentionBoost_Learning_What_to_Attend_for_Gland_Segmentation_in_Histopathological_Images_by_Boosting_Fully_Convolutional_Networks.pdf,
14,Direct Quantification of Coronary Artery Stenosis Through Hierarchical Attentive Multi-View Learning,39,12,4322-4334,"Zhang Dong,Yang Guang,Zhao Shu,Zhang Yanping,Ghista Dhanjoo,Zhang Heye,Li Shuo","Zhang D,Yang G,Zhao S,Zhang YP,Ghista D,Zhang HY,Li S",Zhang HY,10.1109/TMI.2020.3017275,Sun Yat Sen University,"Quantification of coronary artery stenosis on X-ray angiography (XRA) images is of great importance during the intraoperative treatment of coronary artery disease. It serves to quantify the coronary artery stenosis by estimating the clinical morphological indices, which are essential in clinical decision making. However, stenosis quantification is still a challenging task due to the overlapping, diversity and small-size region of the stenosis in the XRA images. While efforts have been devoted to stenosis quantification through low-level features, these methods have difficulty in learning the real mapping from these features to the stenosis indices. These methods are still cumbersome and unreliable for the intraoperative procedures due to their two-phase quantification, which depends on the results of segmentation or reconstruction of the coronary artery. In this work, we are proposing a hierarchical attentive multi-view learning model (HEAL) to achieve a direct quantification of coronary artery stenosis, without the intermediate segmentation or reconstruction. We have designed a multi-view learning model to learn more complementary information of the stenosis from different views. For this purpose, an intra-view hierarchical attentive block is proposed to learn the discriminative information of stenosis. Additionally, a stenosis representation learning module is developed to extract the multi-scale features from the keyframe perspective for considering the clinical workflow. Finally, the morphological indices are directly estimated based on the multi-view feature embedding. Extensive experiment studies on clinical multi-manufacturer dataset consisting of 228 subjects show the superiority of our HEAL against nine comparing methods, including direct quantification methods and multi-view learning methods. The experimental results demonstrate the better clinical agreement between the ground truth and the prediction, which endows our proposed method with a great potential for the efficient intraoperative treatment of coronary artery disease.","Arteries,Lesions,Task analysis,Image reconstruction,Correlation,Feature extraction,Estimation,direct quantification,X-ray angiography,multi-view learning,intraoperative treatment,coronary artery stenosis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CT,ANGIOGRAPHY,RECONSTRUCTION",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
15,Semixup: In- and Out-of-Manifold Regularization for Deep Semi-Supervised Knee Osteoarthritis Severity Grading From Plain Radiographs,39,12,4346-4356,"Nguyen Huy Hoang,Saarakkala Simo,Blaschko Matthew B.,Tiulpin Aleksei","Nguyen HH,Saarakkala S,Blaschko MB,Tiulpin A",Nguyen HH,10.1109/TMI.2020.3017007,University of Oulu,"Knee osteoarthritis (OA) is one of the highest disability factors in the world. This musculoskeletaldisorder is assessedfromclinicalsymptoms, and typically confirmed via radiographic assessment. This visual assessment done by a radiologist requires experience, and suffers from moderate to high inter-observer variability. The recent literature has shown that deep learning methods can reliably perform the OA severity assessment according to the gold standard Kellgren-Lawrence (KL) grading system. However, thesemethods require large amounts of labeled data, which are costly to obtain. In this study, we propose the Semixup algorithm, a semi-supervised learning (SSL) approach to leverageunlabeled data. Semixup relieson consistencyregularization using in- and out-of-manifold samples, together with interpolated consistency. On an independent test set, ourmethod significantly outperformedother state-of-the-art SSL methods in most cases. Finally, when compared to a well-tuned fully supervised baseline that yielded a balanced accuracy (BA) of 70.9 +/- 0.8% on the test set, Semixup had comparable performance - BA of 71 +/- 0.8% (p = 0.368) while requiring 6 times less labeled data. These results show that our proposed SSL method allows building fully automatic OA severity assessment tools with datasets that are available outside research settings.","Deep learning,knee,osteoarthritis,semi-supervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"RISK-FACTORS,BURDEN,PAIN,HIP",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://jultika.oulu.fi/files/nbnfi-fe202101192144.pdf,
16,Unsupervised spectral mapping and feature selection for hyperspectral anomaly detection,132,,144-154,"Xie Weiying,Li Yunsong,Lei Jie,Yang Jian,Li Jiaojiao,Jia Xiuping,Li Zhen","Xie WY,Li YS,Lei J,Yang J,Li JJ,Jia XP,Li Z",Lei J; Li JJ,10.1016/j.neunet.2020.08.010,Xidian University,"Exploring techniques that breakthrough the unknown space or material species is of considerable significance to military and civilian fields, and it is a challenging task without any prior information. Nowadays, the use of material-specific spectral information to detect unknowns has received increas-ing interest. However, affected by noise and interference, high-dimensional hyperspectral anomaly detection is difficult to meet the requirements of high detection accuracy and low false alarm rate. Besides, there is a problem of insufficient and unbalanced samples. To address these problems, we propose a novel hyperspectral anomaly detection framework based on spectral mapping and feature selection (SMFS) in an unsupervised manner. The SMFS introduces the essential properties of hyperspectral data into an unsupervised neural network to construct the nonlinear mapping relationship from high-dimensional spectral space to low-dimensional deep feature space. And it searches the optimal feature subset from the candidate feature space for standing out anomalies. Because of the compelling characterization of the encoder, we develop it specifically for spectral signatures to reveal the hidden data. Quantitative and qualitative experiments on real hyperspectral datasets indicate that the proposed method can provide the compact features overcoming the problems of noise, interference, redundancy and time-consuming caused by high-dimensionality and limited samples. And it has advantages over some state-of-the-art competitors concerning detecting anomalies of different scales. (c) 2020 Elsevier Ltd. All rights reserved.","Unsupervised neural network,Spectral mapping,Feature selection,Hyperspectral anomaly detection",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Neurosciences & Neurology",,9.171,"DETECTION,ALGORITHMS,LOW-RANK,RECONSTRUCTION",NEURAL NETWORKS,,
17,Machine learning on the electron-boson mechanism in superconductors,22,12,,"Li Wan-Ju,Hsu Ming-Chien,Huang Shin-Ming","Li WJ,Hsu MC,Huang SM",Huang SM,10.1088/1367-2630/abc6e6,National Sun Yat Sen University,"To unravel pairing mechanism of a superconductor from limited, indirect experimental data is always a difficult task. It is common but sometimes dubious to explain by a theoretical model with some tuning parameters. In this work, we propose that the machine learning might infer pairing mechanism from observables like superconducting gap functions. For superconductivity within the Migdal-Eliashberg theory, we perform supervised learning between superconducting gap functions and electron-boson spectral functions. For simple spectral functions, the neural network can easily capture the correspondence and predict perfectly. For complex spectral functions, an autoencoder is utilized to reduce the complexity of the spectral functions to be compatible to that of the gap functions. After this complexity-reduction process, relevant information of the spectral function is extracted and good performance restores. Our proposed method can extract relevant information from data and can be applied to general function-to-function mappings with asymmetric complexities either in physics or other fields.","machine learning,superconductivity,autoencoder",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,3.741,"TRANSITION-TEMPERATURE,LAYERED,SUPERCONDUCTOR,ELIASHBERG,EQUATIONS,LATTICE-VIBRATIONS,PREDICTION,SPECTRUM,PRICES,TC",NEW JOURNAL OF PHYSICS,http://arxiv.org/pdf/2007.07512,
18,Abnormal characteristic ,511,,181-188,"Bigorra Laura,Larriba Iciar,Gutierrez-Gallego Ricardo","Bigorra L,Larriba I,Gutierrez-Gallego R",Gutierrez-Gallego R,10.1016/j.cca.2020.10.015,"Dr Aiguader 88, Barcelona 08003, Spain.","Background and aims: The diagnosis of persistent polyclonal B-cell lymphocytosis (PPBL) is often challenging because of the lack of features and the overlap with the peripheral expression of splenic marginal zone lymphomas (SMZL). To obtain new clues for PPBL detection and diagnosis, all data provided by the DxH 800 analyzer (including scatter and cell population data (CPD)) was exploited and combined using a machine learning (ML) approach.
Materials and methods: A total 211 samples from 101 normal controls and 110 patients (PPBL and SMZL) were assessed. Age, gender, full blood count, CPD, scatter, flags and CellaVision differentials were also considered. A ML model was built for true classification purposes.
Results: PPBL and SMZL shared increased absolute lymphoid counts, atypical lymphoid flag presence and CPD values (8 out of 14). A typical ""round-bottom-flask"" shape scattergram was described for the first time for PPBL which was also present in 51.4% of SMZL cases. The developed ML model render a global classification accuracy of 93.4%, allowing the detection of all pathological cases, with mean misclassification rates of 12% among PPBL and SMZL.
Conclusion: Our ML model represents a new unbiased tool than can be widely applied in the laboratory as an aid for detection of PPBL.","Cell population data,Lymphocytosis,Persistent polyclonal B-cell lymphocytosis",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Medical Laboratory Technology,,,,CLINICA CHIMICA ACTA,,
19,Targeted RNA-Sequencing Enables Detection of Relevant Translocations and Single Nucleotide Variants and Provides a Method for Classification of Hematological Malignancies-RANKING,66,12,1521-1530,"de Lange Kim,de Boer Eddy N.,Bosga Anneke,Alimohamed Mohamed Z.,Johansson Lennart F.,Mulder Andre B.,Vellenga Edo,van Diemen Cleo C.,Deelen Patrick,van den Berg Eva","de Lange K,de Boer EN,Bosga A,Alimohamed MZ,Johansson LF,Mulder AB,Vellenga E,van Diemen CC,Deelen P,van den Berg E",Sikkema-Raddatz B,10.1093/clinchem/hvaa221,University of Groningen,"BACKGROUND: Patients with hematological malignancies (HMs) carry a wide range of chromosomal and molecular abnormalities that impact their prognosis and treatment. Since no current technique can detect all relevant abnormalities, technique(s) are chosen depending on the reason for referral, and abnormalities can be missed. We tested targeted transcriptome sequencing as a single platform to detect all relevant abnormalities and compared it to current techniques.
MATERIAL AND METHODS: We performed RNA-sequencing of 1385 genes (TruSight RNA Pan-Cancer, Illumina) in bone marrow from 136 patients with a primary diagnosis of HM. We then applied machine learning to expression profile data to perform leukemia classification, a method we named RANKING. Gene fusions for all the genes in the panel were detected, and overexpression of the genes EVI1, CCND1, and BCL2 was quantified. Single nucleotide variants/indels were analyzed in acute myeloid leukemia (AML), myelodysplastic syndrome and patients with acute lymphoblastic leukemia (ALL) using a virtual myeloid (54 genes) or lymphoid panel (72 genes).
RESULTS: RANKING correctly predicted the leukemia classification of all AML and ALL samples and improved classification in 3 patients. Compared to current methods, only one variant was missed, c.2447A>T in KIT (RT-PCR at 10(-4)), and BCL2 overexpression was not seen due to a t(14; 18)(q32; q21) in 2% of the cells. Our RNA-sequencing method also identified 6 additional fusion genes and overexpression of CCND1 due to a t(11; 14)(q13; q32) in 2 samples.
CONCLUSIONS: Our combination of targeted RNA-sequencing and data analysis workflow can improve the detection of relevant variants, and expression patterns can assist in establishing HM classification.","GENE FUSIONS,EXPRESSION,MUTATIONS,DATABASE,CANCER",Article,"OXFORD UNIV PRESS INC, JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA",Medical Laboratory Technology,,9.174,"GENE,FUSIONS,EXPRESSION,MUTATIONS,DATABASE,CANCER",CLINICAL CHEMISTRY,,
20,A deep learning solution to recommend laboratory reduction strategies in ICU,144,,,"Yu Lishan,Li Linda,Bernstam Elmer,Jiang Xiaoqian","Yu LS,Li LD,Bernstam E,Jiang XQ",Jiang XQ,10.1016/j.ijmedinf.2020.104282,"7000 FanninSt, Houston, TX 77030 USA.","Objective: To build a machine-learning model that predicts laboratory test results and provides a promising lab test reduction strategy, using spatial-temporal correlations.
Materials and methods: We developed a global prediction model to treat laboratory testing as a series of decisions by considering contextual information over time and across modalities. We validated our method using a critical care database (MIMIC III), which includes 4,570,709 observations of 12 standard laboratory tests, among 38,773 critical care patients. Our deep-learning model made real-time laboratory reduction recommendations and predicted the properties of lab tests, including values, normal/abnormal (whether labs were within the normal range) and transition (normal to abnormal or abnormal to normal from the latest lab test). We reported area under the receiver operating characteristic curve (AUC) for predicting normal/abnormal, evaluated accuracy and absolute bias on prediction vs. observation against lab test reduction proportion. We compared our model against baseline models and analyzed the impact of variations on the recommended reduction strategy.
Results: Our best model offered a 20.26 % reduction in the number of laboratory tests. By applying the recommended reduction policy on the hold-out dataset (7755 patients), our model predicted normality/abnormality of laboratory tests with a 98.27 % accuracy (AUC, 0.9885; sensitivity, 97.84 %; specificity, 98.80 %; PPV, 99.01 %; NPV, 97.39 %) on 20.26 % reduced lab tests, and recommended 98.10 % of transitions to be checked. Our model performed better than the greedy models, and the recommended reduction strategy was robust. Discussion: Strong spatial and temporal correlations between laboratory tests can be used to optimize policies for reducing laboratory tests throughout the hospital course. Our method allows for iterative predictions and provides a superior solution for the dynamic decision-making laboratory reduction problem.
Conclusion: This work demonstrates a machine-learning model that assists physicians in determining which laboratory tests may be omitted.","Deep learning,Laboratory test reduction,Dynamic decision-making problem",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Health Care Sciences & Services,Medical Informatics",,4.768,"HOSPITAL-ACQUIRED,ANEMIA,INTENSIVE-CARE,BLOOD-LOSS,TESTS",INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS,,
21,Machine Segmentation of Pelvic Anatomy in MRI-Assisted Radiosurgery (MARS) for Prostate Cancer Brachytherapy,108,5,1292-1303,"Sanders Jeremiah W.,Lewis Gary D.,Thames Howard D.,Kudchadker Rajat J.,Venkatesan Aradhana M.,Bruno Teresa L.,Ma Jingfei,Pagel Mark D.,Frank Steven J.","Sanders JW,Lewis GD,Thames HD,Kudchadker RJ,Venkatesan AM,Bruno TL,Ma JF,Pagel MD,Frank SJ",Sanders JW,10.1016/j.ijrobp.2020.06.076,University of Texas System,"Purpose: To investigate machine segmentation of pelvic anatomy in magnetic resonance imaging (MRI)-assisted radiosurgery (MARS) for prostate cancer using prostate brachytherapy MRIs acquired with different pulse sequences and image contrasts.
Methods and Materials: Two hundred 3-dimensional (3D) preimplant and postimplant prostate brachytherapy MRI scans were acquired with a T2-weighted sequence, a T2/T1-weighted sequence, or a T1-weighted sequence. One hundred twenty deep machine learning models were trained to segment the prostate, seminal vesicles, external urinary sphincter, rectum, and bladder using the MRI scans acquired with T2-weighted and T2/T1-weighted image contrast. The deep machine learning models consisted of 18 fully convolutional networks (FCNs) with different convolutional encoders. Both 2-dimensional and 3D U-Net FCNs were constructed for comparison. Six objective functions were investigated: cross-entropy, Jaccard distance, focal loss, and 3 variations of Tversky distance. The performance of the models was compared using similarity metrics, including pixel accuracy, Jaccard index, Dice similarity coefficient (DSC), 95% Hausdorff distance, relative volume difference, Matthews correlation coefficient, precision, recall, and average symmetrical surface distance. We selected the highest-performing architecture and investigated how the amount of training data, use of skip connections, and data augmentation affected segmentation performance. In addition, we investigated whether segmentation on T1-weighted MRI was possible with FCNs trained on only T2weighted and T2/T1-weighted image contrast.
Results: Overall, an FCN with a DenseNet201 encoder trained via cross-entropy minimization yielded the highest combined segmentation performance. For the 53 3D test MRI scans acquired with T2-weighted or T2/T1-weighted image contrast, the DSCs of the prostate, external urinary sphincter, seminal vesicles, rectum, and bladder were 0.90 +/- 0.04, 0.70 +/- 0.15, 0.80 +/- 0.12, 0.91 +/- 0.06, and 0.96 +/- 0.04, respectively, after model fine-tuning. For the 5 T1-weighted images, the DSCs of these organs were 0.82 +/- 0.07, 0.17 +/- 0.15, 0.46 +/- 0.21, 0.87 +/- 0.06, and 0.88 +/- 0.05, respectively.
Conclusions: Machine segmentation of the prostate and surrounding anatomy on 3D MRIs acquired with different pulse sequences for MARS low-dose-rate prostate brachytherapy is possible with a single FCN. +/- 2020 Elsevier Inc. All rights reserved.","POSTIMPLANT DOSIMETRY,SEED LOCALIZATION,IMAGE FUSION,CT,THERAPY",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,6.884,"POSTIMPLANT,DOSIMETRY,SEED,LOCALIZATION,IMAGE,FUSION,CT,THERAPY",INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS,,
22,Prediction of MGMT Status for Glioblastoma Patients Using Radiomics Feature Extraction From F-18-DOPA-PET Imaging,108,5,1339-1346,"Qian Jing,Herman Michael G.,Brinkmann Debra H.,Laack Nadia N.,Kemp Bradley J.,Hunt Christopher H.,Lowe Val,Pafundi Deanna H.","Qian J,Herman MG,Brinkmann DH,Laack NN,Kemp BJ,Hunt CH,Lowe V,Pafundi DH",Pafundi DH,10.1016/j.ijrobp.2020.06.073,Mayo Clinic,"Purpose: Methylation of the O6-methylguanine methyltransferase (MGMT) gene promoter is associated with improved treatment response and survival in patients with glioblastoma (GB), but the necessary pathologic specimen can be nondiagnostic. In this study, we assessed whether radiomics features from pretreatment 18F-DOPA positron emission tomography (PET) imaging could be used to predict pathologic MGMT status.
Methods and Materials: This study included 86 patients with newly diagnosed GB, split into 3 groups (training, validating, and predicting). We performed a radiomics analysis on 18F-DOPA PET images by extracting features from 2 tumor-based contours: a ""Gold"" contour of all abnormal uptake per expert nuclear medicine physician and a high-grade glioma (HGG) contour based on a tumor-to-normal hemispheric ratio >2.0, representing the most aggressive components. Feature selection was performed by comparing the weighted feature importance and filtering with bivariate analysis. Optimization of model parameters was explored using grid search with selected features. The stability of the model with increasing input features was also investigated for model robustness. The model predictions were then applied by comparing the overall survival probability of the patients with GB and unknown MGMT status versus those with known MGMT status.
Results: A radiomics signature was constructed to predict MGMT methylation status. Using features extracted from HGG contour alone with a random forest model, we achieved 80% +/- 10% accuracy for 95% confidence level in predicting MGMT status. The prediction accuracy was not improved with the addition of the Gold contour or with more input features. The model was applied to the patients with unknown MGMT methylation status. The prediction results are consistent with what is expected using overall survival as a surrogate.
Conclusions: This study suggests that 3 features from radiomics modeling of 18F-DOPA PET imaging can predict MGMT methylation status with reasonable accuracy. These results could provide valuable therapeutic guidance for patients in whom MGMT testing is inconclusive or nondiagnostic. (C) 2020 Elsevier Inc. All rights reserved.","PROMOTER METHYLATION,PET,RADIOTHERAPY,PSEUDOPROGRESSION,CHEMOTHERAPY,GLIOMAS,MRI",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,6.884,"PROMOTER,METHYLATION,PET,RADIOTHERAPY,PSEUDOPROGRESSION,CHEMOTHERAPY,GLIOMAS,MRI",INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS,,
23,Machine learning approach to detect focal-onset seizures in the human anterior nucleus of the thalamus,17,6,,"Toth Emilia,Kumar Sachin S.,Chaitanya Ganne,Riley Kristen,Balasubramanian Karthi,Pati Sandipan","Toth E,Kumar SS,Chaitanya G,Riley K,Balasubramanian K,Pati S",Pati S,10.1088/1741-2552/abc1b7,University of Alabama System,"Objective. There is an unmet need to develop seizure detection algorithms from brain regions outside the epileptogenic cortex. The study aimed to demonstrate the feasibility of classifying seizures and interictal states from local field potentials (LFPs) recorded from the human thalamus-a subcortical region remote to the epileptogenic cortex. We tested the hypothesis that spectral and entropy-based features extracted from LFPs recorded from the anterior nucleus of the thalamus (ANT) can distinguish its state of ictal recruitment from other interictal states (including awake, sleep). Approach. Two supervised machine learning tools (random forest and the random kitchen sink) were used to evaluate the performance of spectral (discrete wavelet transform-DWT), and time-domain (multiscale entropy-MSE) features in classifying seizures from interictal states in patients undergoing stereo-electroencephalography (EEG) evaluation for epilepsy surgery. Under the supervision of IRB, field potentials were recorded from the ANT in consenting adults with drug-resistant temporal lobe epilepsy. Seizures were confirmed in the ANT using line-length and visual inspection. Wilcoxon rank-sum method was used to test the differences in spectral patterns between seizure and interictal (awake and sleep) states. Main results. 79 seizures (10 patients) and 158 segments (approx. 4 h) of interictal stereo-EEG data were analyzed. The mean seizure detection latencies with line length in the ANT varied between seizure types (range 5-34 s). However, the DWT and MSE in the ANT showed significant changes for all seizure types within the first 20 s after seizure onset. The random forest (accuracy 93.9% and false-positive 4.6%) and the random kitchen sink (accuracy 97.3% and false-positive 1.8%) classified seizures and interictal states. Significance. These results suggest that features extracted from the thalamic LFPs can be trained to detect seizures that can be used for monitoring seizure counts and for closed-loop seizure abortive interventions.","Thalamus,seizure detection,epilepsy,machine learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Engineering,Neurosciences & Neurology",,,"ELECTRICAL-STIMULATION,EPILEPSY,NETWORK,NEUROSTIMULATION,IMPLEMENTATION,FREQUENCY,NEURONS,CORTEX,SLEEP,RATS",JOURNAL OF NEURAL ENGINEERING,,
24,Non-invasive imaging prediction of tumor hypoxia: A novel developed and externally validated CT and FDG-PET-based radiomic signatures,153,,97-105,"Sanduleanu Sebastian,Jochems Arthur,Upadhaya Taman,Even Aniek J. G.,Leijenaar Ralph T. H.,Dankers Frank J. W. M.,Klaassen Remy,Woodruff Henry C.,Hatt Mathieu,Kaanders Hans J. A. M.","Sanduleanu S,Jochems A,Upadhaya T,Even AJG,Leijenaar RTH,Dankers FJWM,Klaassen R,Woodruff HC,Hatt M,Kaanders HJAM",Sanduleanu S,10.1016/j.radonc.2020.10.016,Maastricht University,"Background: Tumor hypoxia increases resistance to radiotherapy and systemic therapy. Our aim was to develop and validate a disease-agnostic and disease-specific CT (+FDG-PET) based radiomics hypoxia classification signature.
Material and methods: A total of 808 patients with imaging data were included: N = 100 training/N = 183 external validation cases for a disease-agnostic CT hypoxia classification signature, N = 76 training/N = 39 validation cases for the H&N CT signature and N = 62 training/N = 36 validation cases for the Lung CT signature. The primary gross tumor volumes (GTV) were manually defined by experts on CT. In order to dichotomize between hypoxic/well-oxygenated tumors a threshold of 20% was used for the [F-18]-HX4-derived hypoxic fractions (HF). A random forest (RF)-based machine-learning classifier/regressor was trained to classify patients as hypoxia-positive/negative based on radiomic features.
Results: A 11 feature ""disease-agnostic CT model"" reached AUC's of respectively 0.78 (95% confidence interval [CI], 0.62-0.94), 0.82 (95% CI, 0.67-0.96) and 0.78 (95% CI, 0.67-0.89) in three external validation datasets. A ""disease-agnostic FDG-PET model"" reached an AUC of 0.73 (0.95% CI, 0.49-0.97) in validation by combining 5 features. The highest ""lung-specific CT model"" reached an AUC of 0.80 (0.95% CI, 0.65-0.95) in validation with 4 CT features, while the ""H&N-specific CT model"" reached an AUC of 0.84 (0.95% CI, 0.64-1.00) in validation with 15 CT features. A tumor volume-alone model was unable to significantly classify patients as hypoxia-positive/negative. A significant survival split (P = 0.037) was found between CT-classified hypoxia strata in an external H&N cohort (n = 517), while 117 significant hypoxia gene-CT signature feature associations were found in an external lung cohort (n = 80).
Conclusion: The disease-specific radiomics signatures perform better than the disease agnostic ones. By identifying hypoxic patients our signatures have the potential to enrich interventional hypoxia-targeting trials. (C) 2020 The Author(s). Published by Elsevier B.V.","Radiomics,Tumor hypoxia",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,5.881,"UPTAKE,DISTRIBUTIONS,CANCER,PATIENTS,LUNG-TUMORS,RADIOTHERAPY,HEAD,DISCRETIZATION,REPEATABILITY,ANGIOGENESIS,METHODOLOGY,INFORMATION",RADIOTHERAPY AND ONCOLOGY,http://www.thegreenjournal.com/article/S0167814020308525/pdf,
25,Beam data modeling of linear accelerators (linacs) through machine learning and its potential applications in fast and robust linac commissioning and quality assurance,153,,122-129,"Zhao Wei,Patil Ishan,Han Bin,Yang Yong,Xing Lei,Schuler Emil","Zhao W,Patil I,Han B,Yang Y,Xing L,Schuler E",Xing L,10.1016/j.radonc.2020.09.057,Stanford University,"Background and purpose: To propose a novel machine learning-based method for reliable and accurate modeling of linac beam data applicable to the processes of linac commissioning and QA.
Materials and methods: We hypothesize that the beam data is a function of inherent linac features and percentage depth doses (PDDs) and profiles of different field sizes are correlated with each other. The correlation is formulated as a multivariable regression problem using a machine learning framework. Varian TrueBeam beam data sets (n = 43) acquired from multiple institutions were used to evaluate the framework. The data sets included PDDs and profiles across different energies and field sizes. A multivariate regression model was trained for prediction of beam specific PDDs and profiles of different field sizes using a 10 x 10 cm(2) field as input.
Results: Predictions of PDDs were achieved with a mean absolute percent relative error (%RE) of 0.19-0.35% across the different beam energies investigated. The maximum mean absolute %RE was 0.93%. For profile prediction, the mean absolute %RE was 0.66-0.93% with a maximum absolute %RE of 3.76%. The largest uncertainties in the PDD and profile predictions were found at the build-up region and at the field penumbra, respectively. The prediction accuracy increased with the number of training sets up to around 20 training sets.
Conclusions: Through this novel machine learning-based method we have shown accurate and reproducible generation of beam data for linac commissioning for routine radiation therapy. This method has the potential to simplify the linac commissioning procedure, save time and manpower while increasing the accuracy of the commissioning process. (C) 2020 Elsevier B.V. All rights reserved.","Radiotherapy,Beam data modeling,Machine learning,Linac commissioning,Quality assurance",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,5.881,"REFERENCE,DOSIMETRY,RADIATION-THERAPY,PHOTON,IMPLEMENTATION,ACCURACY,TG-106,SYSTEM",RADIOTHERAPY AND ONCOLOGY,http://arxiv.org/pdf/2009.14403,
26,Deep learning-based synthetic CT generation for paediatric brain MR-only photon and proton radiotherapy,153,,197-204,"Maspero Matteo,Bentvelzen Laura G.,Savenije Mark H. F.,Guerreiro Filipa,Seravalli Enrica,Janssens Geert O.,van den Berg Cornelis A. T.,Philippens Marielle E. P.","Maspero M,Bentvelzen LG,Savenije MHF,Guerreiro F,Seravalli E,Janssens GO,van den Berg CAT,Philippens MEP",Maspero M,10.1016/j.radonc.2020.09.029,Utrecht University,"Background and Purpose: To enable accurate magnetic resonance imaging (MRI)-based dose calculations, synthetic computed tomography (sCT) images need to be generated. We aim at assessing the feasibility of dose calculations from MRI acquired with a heterogeneous set of imaging protocol for paediatric patients affected by brain tumours.
Materials and methods: Sixty paediatric patients undergoing brain radiotherapy were included. MR imaging protocols varied among patients, and data heterogeneity was maintained in train/validation/test sets. Three 2D conditional generative adversarial networks (cGANs) were trained to generate sCT from T1-weighted MRI, considering the three orthogonal planes and its combination (multi-plane sCT). For each patient, median and standard deviation (sigma) of the three views were calculated, obtaining a combined sCT and a proxy for uncertainty map, respectively. The sCTs were evaluated against the planning CT in terms of image similarity and accuracy for photon and proton dose calculations.
Results: A mean absolute error of 61 +/- 14 HU (mean +/- 1 sigma) was obtained in the intersection of the body contours between CT and sCT. The combined multi-plane sCTs performed better than sCTs from any single plane. Uncertainty maps highlighted that multi-plane sCTs differed at the body contours and air cavities. A dose difference of -0.1 +/- 0.3% and 0.1 +/- 0.4% was obtained on the D > 90% of the prescribed dose and mean gamma(2%; 2 mm) pass-rate of 99.5 +/- 0.8% and 99.2 +/- 1.1% for photon and proton planning, respectively.
Conclusion: Accurate MR-based dose calculation using a combination of three orthogonal planes for sCT generation is feasible for paediatric brain cancer patients, even when training on a heterogeneous dataset. (C) 2020 The Author(s). Published by Elsevier B.V.","Synthetic CT,Pediatric oncology,Brain tumors,Artificial intelligence,Image-to-image translation,Machine learning",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,5.881,"CONVOLUTIONAL,NEURAL-NETWORK,DOSE,CALCULATIONS,THERAPY,FEASIBILITY,TUMORS,ANESTHESIA,CHILDHOOD,ACCURACY,CHILDREN,DENSITY",RADIOTHERAPY AND ONCOLOGY,https://doi.org/10.1016/j.radonc.2020.09.029,
27,Improvement of prediction and classification performance for gamma passing rate by using plan complexity and dosiomics features,153,,250-257,"Hirashima Hideaki,Ono Tomohiro,Nakamura Mitsuhiro,Miyabe Yuki,Mukumoto Nobutaka,Iramina Hiraku,Mizowaki Takashi","Hirashima H,Ono T,Nakamura M,Miyabe Y,Mukumoto N,Iramina H,Mizowaki T",Ono T,10.1016/j.radonc.2020.07.031,Kyoto University,"Purpose: The purpose of this study was to predict and classify the gamma passing rate (GPR) value by using new features (3D dosiomics features and combined with plan and dosiomics features) together with a machine learning technique for volumetric modulated arc therapy (VMAT) treatment plans.
Methods and materials: A total of 888 patients who underwent VMAT were enrolled comprising 1255 treatment plans. Further, 24 plan complexity features and 851 dosiomics features were extracted from the treatment plans. The dataset was randomly split into a training/validation (80%) and test (20%) dataset. The three models for prediction and classification using XGBoost were as follows: (i) plan complexity features-based prediction method (plan model); (ii) 3D dosiomics feature-based prediction model (dosiomics model); (iii) a combination of both the previous models (hybrid model). The prediction performance was evaluated by calculating the mean absolute error (MAE) and the correlation coefficient (CC) between the predicted and measured GPRs. The classification performance was evaluated by calculating the area under curve (AUC) and sensitivity.
Results: MAE and CC at gamma 2%/2 mm in the test dataset were 4.6% and 0.58, 4.3% and 0.61, and 4.2% and 0.63 for the plan model, dosiomics model, and hybrid model, respectively. AUC and sensitivity at gamma 2%/2 mm in test dataset were 0.73 and 0.70, 0.81 and 0.90, and 0.83 and 0.90 for the plan model, dosiomics model, and hybrid model, respectively.
Conclusions: A combination of both plan and dosiomics features with machine learning technique can improve the prediction and classification performance for GPR. (C) 2020 Elsevier B.V. All rights reserved.","Prediction,Classification,Gamma passing rate,Plan complexity feature,Dosiomics feature,Machine learning",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,5.881,,RADIOTHERAPY AND ONCOLOGY,,
28,Applications of laser-induced breakdown spectroscopy (LIBS) combined with machine learning in geochemical and environmental resources exploration,133,,,"Chen Tingting,Zhang Tianlong,Li Hua","Chen TT,Zhang TL,Li H",Zhang TL; Li H,10.1016/j.trac.2020.116113,Northwest University Xi'an,"Conventional geological and environmental analyses rely heavily on the geologists' assessments and time-consuming laboratory analyses that are relatively burdensome. Certain features of laser-induced breakdown spectroscopy (LIBS), especially the rapid and without complex sample preparation analysis (e.g., the remote and on-site detections and multi-element analyses), can significantly accelerate the field or remote detection of geological and environmental resources. Moreover, the LIBS technique combined with machine learning becomes an effective means to improve the accuracy of classification and quantitative analysis of the information derived from LIBS spectra data sets. This paper presents a brief account of LIBS equipments, preparation of samples, the spectral fusion technology, field-portable and remote LIBS, the machine learning methods in LIBS, the applications of LIBS to analyzing various geological and environmental materials at some specific field sites during the past six years. Finally, the potential applications of LIBS for some future developments are proposed. (C) 2020 Elsevier B.V. All rights reserved.","Laser-induced breakdown spectroscopy,Machine learning,Geochemical resources exploration,Environmental monitoring,Applications",Review,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Chemistry,,11.446,"PARTIAL,LEAST-SQUARES,QUANTITATIVE-ANALYSIS,CALORIFIC,VALUE,MULTIVARIATE,CLASSIFICATION,MULTIELEMENT,ANALYSIS,ACCURACY,IMPROVEMENT,GEOLOGICAL-MATERIALS,RAPID-DETERMINATION,CHEMCAM,INSTRUMENT,TRACE-ELEMENTS",TRAC-TRENDS IN ANALYTICAL CHEMISTRY,,
29,Porosity segmentation in X-ray computed tomography scans of metal additively manufactured specimens with machine learning,36,,,"Gobert Christian,Kudzal Andelle,Sietins Jennifer,Mock Clara,Sun Jessica,McWilliams Brandon","Gobert C,Kudzal A,Sietins J,Mock C,Sun J,McWilliams B",Gobert C,10.1016/j.addma.2020.101460,United States Department of Energy (DOE),"X-ray computed tomography (XCT) is widely used in additive manufacturing (AM) to obtain discrete analysis of internal material discontinuities, especially the porosity of AM specimens. XCT uses X-ray penetration to generate 3D digital reconstructions that enable non-destructive evaluations of specimens and their internal structures. The process of segmenting XCT images for porosity analysis can be time consuming, affected by XCT scan quality, and subject to segmentation methods. OTSU thresholding and a convolutional neural network were combined into a machine learning tool to automatically segment porosity from XCT images of metallic AM specimens. Multiple XCT specialists and AM specimens were used to investigate how various segmentation methodologies, used to create ground-truth labels of porosity, impacted machine learning performance. XCT specialists segmenting a control specimen established a benchmark for machine learning performance measured through classification and descriptive statistics. Discrepancies in the machine learning tool segmentations were similar to or better than the discrepancies among the XCT specialist themselves, indicating a high capability for automated porosity segmentation.","X-ray computed tomography,Powder bed fusion,Convolutional neural networks,OTSU thresholding",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science",,12.363,CT,ADDITIVE MANUFACTURING,,
30,A hybrid physics-based and data-driven approach for characterizing porosity variation and filament bonding in extrusion-based additive manufacturing,36,,,"Haghighi Azadeh,Li Lin","Haghighi A,Li L",Li L,10.1016/j.addma.2020.101399,University of Illinois System,"The application of additive manufacturing technology has recently shifted from the fabrication of prototypes to functional end-use products. Consequently, the mechanical strength of products has become of significant importance. To quantify the global and local mechanical strength, it is necessary to characterize the micro-structures and their variation within the product. The extent of bonding between adjacent filaments, both within and between layers, as well as porosity are two of the most important parameters that directly contribute to the mechanical strength of parts in extrusion-based additive manufacturing. However, most of the existing models in the literature either significantly underestimate these parameters or fail to quantify or address their variation along the deposition path and build direction. Hence, in this paper, a hybrid physics-based and data-driven approach is proposed to quantify the extent of filament bonding, porosity, and their distribution within a geometry of interest by characterizing the temperature profile of filaments and their deformation. The proposed models for inter-layer and intra-layer bonding have an average accuracy of 95% and 94%, respectively. In addition, it is observed that the porosity variation model performs better for top layers compared to bottom layers with an average of 51% higher accuracy.","Additive manufacturing,Bonding degree,Porosity variation,Filament deformation,Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science",,12.363,"MECHANICAL-PROPERTIES,TEMPERATURE,PREDICTION,PARAMETERS,PROPERTY,QUALITY",ADDITIVE MANUFACTURING,https://www.sciencedirect.com/science/article/am/pii/S2214860420307715,
31,Invited review: Machine learning for materials developments in metals additive manufacturing,36,,,"Johnson N. S.,Vulimiri P. S.,To A. C.,Zhang X.,Brice C. A.,Kappes B. B.,Stebner A. P.","Johnson NS,Vulimiri PS,To AC,Zhang X,Brice CA,Kappes BB,Stebner AP",Kappes BB; Stebner AP,10.1016/j.addma.2020.101641,Colorado School of Mines,"In metals additive manufacturing (AM), materials and components are concurrently made in a single process as layers of metal are fabricated on top of each other in the near-final topology required for the end-use product. Consequently, tens to hundreds of materials and part design degrees of freedom must be simultaneously controlled and understood; hence, metals AM is a highly interdisciplinary technology that requires synchronized consideration of physics, chemistry, materials science, physical metallurgy, computer science, electrical engineering, and mechanical engineering. The use of modern machine learning approaches to model these degrees of freedom can reduce the time and cost to elucidate the science of metals AM and to optimize the engineering of these complex, multidisciplinary processes. New machine learning techniques are not needed for most metals AM development; those used in other sects of materials science will also work for AM. Most prolifically, the density functional theory (DFT) community has used many of them since the early 2000s for evaluating numerous combinations of elements and crystal structures to discover new materials. This materials technologies-focused review introduces the basic mathematics and terminology of machine learning through the lens of metals AM, and then examines potential uses of machine learning to advance metals AM, highlighting the many parallels to previous efforts in materials science and manufacturing while also discussing new challenges and adaptations specific to metals AM.","THIN-FILM DEPOSITION,CONVOLUTIONAL NEURAL-NETWORK,DENSITY-FUNCTIONAL THEORY,SOLID-STATE CHEMISTRY,X-RAY-DIFFRACTION,HIGH-THROUGHPUT,TOPOLOGY OPTIMIZATION,MICROSTRUCTURE EVOLUTION,GENETIC-ALGORITHM,COMPUTER VISION",Review,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science",,12.363,"THIN-FILM,DEPOSITION,CONVOLUTIONAL,NEURAL-NETWORK,DENSITY-FUNCTIONAL,THEORY,SOLID-STATE,CHEMISTRY,X-RAY-DIFFRACTION,HIGH-THROUGHPUT,TOPOLOGY,OPTIMIZATION,MICROSTRUCTURE,EVOLUTION,GENETIC-ALGORITHM,COMPUTER,VISION",ADDITIVE MANUFACTURING,https://doi.org/10.1016/j.addma.2020.101641,
32,Machine learning in additive manufacturing: State-of-the-art and perspectives,36,,,"Wang C.,Tan X. P.,Tor S. B.,Lim C. S.","Wang C,Tan XP,Tor SB,Lim CS",Tan XP,10.1016/j.addma.2020.101538,Nanyang Technological University & National Institute of Education (NIE) Singapore,"Additive manufacturing (AM) has emerged as a disruptive digital manufacturing technology. However, its broad adoption in industry is still hindered by high entry barriers of design for additive manufacturing (DfAM), limited materials library, various processing defects, and inconsistent product quality. In recent years, machine learning (ML) has gained increasing attention in AM due to its unprecedented performance in data tasks such as classification, regression and clustering. This article provides a comprehensive review on the state-of-the-art of ML applications in a variety of AM domains. In the DfAM, ML can be leveraged to output new high-performance metamaterials and optimized topological designs. In AM processing, contemporary ML algorithms can help to optimize process parameters, and conduct examination of powder spreading and in-process defect monitoring. On the production of AM, ML is able to assist practitioners in pre-manufacturing planning, and product quality assessment and control. Moreover, there has been an increasing concern about data security in AM as data breaches could occur with the aid of ML techniques. Lastly, it concludes with a section summarizing the main findings from the literature and providing perspectives on some selected interesting applications of ML in research and development of AM.","Additive manufacturing,Process,Machine learning,Production,Design",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science",,12.363,"POWDER-BED,FUSION,ARTIFICIAL,NEURAL-NETWORKS,MECHANICAL-PROPERTIES,ANOMALY,DETECTION,DEFECT,DETECTION,MELT,POOL,MICROSTRUCTURE,PREDICTION,DESIGN,CLASSIFICATION",ADDITIVE MANUFACTURING,,
33,Accelerating Radiation Computations for Dynamical Models With Targeted Machine Learning and Code Optimization,12,12,,"Ukkonen Peter,Pincus Robert,Hogan Robin J.);,Pagh Nielsen Kristian,Kaas Eigil","Ukkonen P,Pincus R,Hogan RJ,Nielsen KP,Kaas E",Ukkonen P,10.1029/2020MS002226,Danish Meteorological Institute DMI,"Atmospheric radiation is the main driver of weather and climate, yet due to a complicated absorption spectrum, the precise treatment of radiative transfer in numerical weather and climate models is computationally unfeasible. Radiation parameterizations need to maximize computational efficiency as well as accuracy, and for predicting the future climate many greenhouse gases need to be included. In this work, neural networks (NNs) were developed to replace the gas optics computations in a modern radiation scheme (RTE+RRTMGP) by using carefully constructed models and training data. The NNs, implemented in Fortran and utilizing BLAS for batched inference, are faster by a factor of 1-6, depending on the software and hardware platforms. We combined the accelerated gas optics with a refactored radiative transfer solver, resulting in clear-sky longwave (shortwave) fluxes being 3.5 (1.8) faster to compute on an Intel platform. The accuracy, evaluated with benchmark line-by-line computations across a large range of atmospheric conditions, is very similar to the original scheme with errors in heating rates and top-of-atmosphere radiative forcings typically below 0.1 K day(-1) and 0.5 W m(-2), respectively. These results show that targeted machine learning, code restructuring techniques, and the use of numerical libraries can yield material gains in efficiency while retaining accuracy.","machine learning,radiation,atmospheric model,parameterization",Article,"AMER GEOPHYSICAL UNION, 2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA",Meteorology & Atmospheric Sciences,,5.836,"CORRELATED-K,METHOD,PARAMETERIZATION",JOURNAL OF ADVANCES IN MODELING EARTH SYSTEMS,http://centaur.reading.ac.uk/98058/1/2020MS002226.pdf,
34,MaterialGAN: Reflectance Capture using a Generative SVBRDF Model,39,6,,"Guo Yu,Smith Cameron,Hasan Milos,Sunkavalli Kalyan,Zhao Shuang","Guo Y,Smith C,Hasan M,Sunkavalli K,Zhao S",Guo Y,10.1145/3414685.3417779,University of California System,"We address the problem of reconstructing spatially-varying BRDFs from a small set of image measurements. This is a fundamentally under-constrained problem, and previous work has relied on using various regularization priors or on capturing many images to produce plausible results. In this work, we present MaterialGAN, a deep generative convolutional network based on StyleGAN2, trained to synthesize realistic SVBRDF parameter maps. We show that MaterialGAN can be used as a powerful material prior in an inverse rendering framework: we optimize in its latent representation to generate material maps that match the appearance of the captured images when rendered. We demonstrate this framework on the task of reconstructing SVBRDFs from images captured under flash illumination using a hand-held mobile phone. Our method succeeds in producing plausible material maps that accurately reproduce the target images, and outperforms previous state-of-the-art material capture methods in evaluations on both synthetic and real data. Furthermore, our GAN-based latent space allows for high-level semantic material editing operations such as generating material variations and material morphing.","SVBRDF capture,generative adversarial network",Article,"ASSOC COMPUTING MACHINERY, 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA",Computer Science,,6.445,,ACM TRANSACTIONS ON GRAPHICS,http://arxiv.org/pdf/2010.00114,
35,Learning to Manipulate Amorphous Materials,39,6,,"Zhang Yunbo,Yu Wenhao,Liu C. Karen,Kemp Charlie,Turk Greg","Zhang YB,Yu WH,Liu CK,Kemp C,Turk G",Zhang YB,10.1145/3414685.3417868,University System of Georgia,"We present a method of training character manipulation of amorphous materials such as those often used in cooking. Common examples of amorphous materials include granular materials (salt, uncooked rice), fluids (honey), and visco-plastic materials (sticky rice, softened butter). A typical task is to spread a given material out across a flat surface using a tool such as a scraper or knife. We use reinforcement learning to train our controllers to manipulate materials in various ways. The training is performed in a physics simulator that uses position-based dynamics of particles to simulate the materials to be manipulated. The neural network control policy is given observations of the material (e.g. a low-resolution density map), and the policy outputs actions such as rotating and translating the knife. We demonstrate policies that have been successfully trained to carry out the following tasks: spreading, gathering, and flipping. We produce a final animation by using inverse kinematics to guide a character's arm and hand to match the motion of the manipulation tool such as a knife or a frying pan.","Character control,reinforcement learning,physics simulation,deformable materials",Article,"ASSOC COMPUTING MACHINERY, 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA",Computer Science,,6.445,"DEXTEROUS,MANIPULATION",ACM TRANSACTIONS ON GRAPHICS,http://arxiv.org/pdf/2103.02533,
36,Multianalyzer Spectroscopic Data Fusion for Soil Characterization,10,23,,"Hark Richard R.,Throckmorton Chandra S.,Harmon Russell S.,Plumer John R.,Harmon Karen A.,Harrison J. Bruce,Hendrickx Jan M. H.,Clausen Jay L.","Hark RR,Throckmorton CS,Harmon RS,Plumer JR,Harmon KA,Harrison JB,Hendrickx JMH,Clausen JL",Hark RR,10.3390/app10238723,"JRPlumer Associates LLC, 36 Country Club Rd,Suite 926, Gilford, NH 03249 USA.","Featured Application
Chemical analysis of soil samples using handheld spectroscopic instruments was performed to investigate if classification accuracy is enhanced through multianalyzer data fusion.
The ability to rapidly conduct in-situ chemical analysis of multiple samples of soil and other geological materials in the field offers many advantages over a traditional approach that involves collecting samples for subsequent examination in the laboratory. This study explores the application of complementary spectroscopic analyzers and a data fusion methodology for the classification/discrimination of >100 soil samples from sites across the United States. Commercially available, handheld analyzers for X-ray fluorescence spectroscopy (XRFS), Raman spectroscopy (RS), and laser-induced breakdown spectroscopy (LIBS) were used to collect data both in the laboratory and in the field. Following a common data pre-processing protocol, principal component analysis (PCA) and partial least squares discriminant analysis (PLSDA) were used to build classification models. The features generated by PLSDA were then used in a hierarchical classification approach to assess the relative advantage of information fusion, which increased classification accuracy over any of the individual sensors from 80-91% to 94% and 64-93% to 98% for the two largest sample suites. The results show that additional testing with data sets for which classification with individual analyzers is modest might provide greater insight into the limits of data fusion for improving classification accuracy.","laser-induced breakdown spectroscopy,LIBS,Raman spectroscopy,RS,X-ray fluorescence spectroscopy,XRFS,chemometrics,machine learning,multianalyzer data fusion",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"X-RAY-FLUORESCENCE,RAMAN-SPECTROSCOPY,LIBS,CLASSIFICATION,IDENTIFICATION,DISCRIMINATION,MINERALS,PIGMENTS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/23/8723/pdf,
37,Inspection by exception: A new machine learning-based approach for multistage manufacturing,97,,,"Papananias Moschos,McLeay Thomas E.,Obajemu Olusayo,Mahfouf Mahdi,Kadirkamanathan Visakan","Papananias M,McLeay TE,Obajemu O,Mahfouf M,Kadirkamanathan V",Papananias M,10.1016/j.asoc.2020.106787,University of Sheffield,"Manufacturing processes usually consist of multiple different stages, each of which is influenced by a multitude of factors. Therefore, variations in product quality at a certain stage are contributed to by the errors generated at the current, as well as preceding, stages. The high cost of each production stage in the manufacture of high-quality products has stimulated a drive towards decreasing the volume of non-added value processes such as inspection. This paper presents a new method for what the authors have referred to as 'inspection by exception' - the principle of actively detecting and then inspecting only the parts that cannot be categorized as healthy or unhealthy with a high degree of certainty. The key idea is that by inspecting only those parts that are in the corridor of uncertainty, the volume of inspections are considerably reduced. This possibility is explored using multistage manufacturing data and both unsupervised and supervised learning algorithms. A case study is presented whereby material conditions and time domain features for force, vibration and tempering temperature are used as input data. Fuzzy C-Means (FCM) clustering is implemented to achieve inspection by exception in an unsupervised manner based on the normalized Euclidean distances between the principal components and cluster centres. Also, deviation vectors for product health are obtained using a comparator system to train neural networks for supervised learning-based inspection by exception. It is shown that the volume of inspections can be reduced by as much as 82% and 93% using the unsupervised and supervised learning approaches, respectively. (C) 2020 The Author(s). Published by Elsevier B.V.","Artificial Neural Network (ANN),Fuzzy C-Means (FCM),Intelligent,smart manufacturing,Machine learning,Multistage Manufacturing Process (MMP),Principal Component Analysis (PCA)",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,6.607,"VARIATION,PROPAGATION,SURFACE-ROUGHNESS,SYSTEM",APPLIED SOFT COMPUTING,http://eprints.whiterose.ac.uk/166957/13/1-s2.0-S1568494620307250-main.pdf,
38,Application of Convolutional Neural Networks to Identify Protostellar Outflows in CO Emission,905,2,,"Xu Duo,Offner Stella S. R.,Gutermuth Robert,Van Oort Colin","Xu D,Offner SSR,Gutermuth R,Van Oort C",Xu D,10.3847/1538-4357/abc7bf,University of Texas System,"We adopt the deep learning method casi-3d (Convolutional Approach to Structure Identification-3D) to identify protostellar outflows in molecular line spectra. We conduct magnetohydrodynamics simulations that model forming stars that launch protostellar outflows and use these to generate synthetic observations. We apply the 3D radiation transfer code radmc-3d to model (CO)-C-12 (J = 1-0) line emission from the simulated clouds. We train two casi-3d models: ME1 is trained to predict only the position of outflows, while MF is trained to predict the fraction of the mass coming from outflows in each voxel. The two models successfully identify all 60 previously visually identified outflows in Perseus. Additionally, casi-3d finds 20 new high-confidence outflows. All of these have coherent high-velocity structure, and 17 of them have nearby young stellar objects, while the remaining three are outside the Spitzer survey coverage. The mass, momentum, and energy of individual outflows in Perseus predicted by model MF is comparable to the previous estimations. This similarity is due to a cancellation in errors: previous calculations missed outflow material with velocities comparable to the cloud velocity; however, they compensate for this by overestimating the amount of mass at higher velocities that has contamination from nonoutflow gas. We show that outflows likely driven by older sources have more high-velocity gas compared to those driven by younger sources.","Interstellar medium,Stellar jets,Convolutional neural networks,Astronomy data analysis,Star formation,Molecular clouds",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Astronomy & Astrophysics,,,"MOLECULAR,OUTFLOWS,SIO,EMISSION,SHOCKED,GAS,MASS,EVOLUTION,CLUSTERS,PERSEUS,SAMPLE",ASTROPHYSICAL JOURNAL,http://arxiv.org/pdf/2010.12525,
39,Feature Extraction for Hyperspectral Imagery: The Evolution From Shallow to Deep: Overview and Toolbox,8,4,60-88,"Rasti Behnood,Hong Danfeng,Hang Renlong,Ghamisi Pedram,Kang Xudong,Chanussot Jocelyn,Benediktsson Jon Atli","Rasti B,Hong DF,Hang RL,Ghamisi P,Kang XD,Chanussot J,Benediktsson JA",Hong DF,10.1109/MGRS.2020.2979764,Centre National de la Recherche Scientifique (CNRS),"Hyperspectral images (HSIs) provide detailed spectral information through hundreds of (narrow) spectral channels (also known as dimensionality or bands), which can be used to accurately classify diverse materials of interest. The increased dimensionality of such data makes it possible to significantly improve data information content but provides a challenge to conventional techniques (the so-called curse of dimensionality) for accurate analysis of HSIs.","Training data,Hyperspectral imaging,Feature extraction,Machine learning,Data mining",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Geochemistry & Geophysics,Remote Sensing,Imaging Science & Photographic Technology",,13.069,"SPECTRAL-SPATIAL,CLASSIFICATION,QUADRATIC,MUTUAL,INFORMATION,CONVOLUTIONAL,NEURAL-NETWORK,REMOTE-SENSING,DATA,DIMENSIONALITY,REDUCTION,BAND,SELECTION,DISCRIMINANT-ANALYSIS,LAPLACIAN,EIGENMAPS,COMPONENT,ANALYSIS,FEATURE,FUSION",IEEE GEOSCIENCE AND REMOTE SENSING MAGAZINE,http://arxiv.org/pdf/2003.02822,
40,A Deep Learning Method for Improving the Classification Accuracy of SSMVEP-Based BCI,67,12,3447-3451,"Gao Zhongke,Yuan Tao,Zhou Xinjun,Ma Chao,Ma Kai,Hui Pan","Gao ZK,Yuan T,Zhou XJ,Ma C,Ma K,Hui P",Gao ZK,10.1109/TCSII.2020.2983389,Tianjin University,"Steady State Motion Visual Evoked Potential (SSMVEP)-based Brain Computer Interface (BCI) is widely studied and has been used to varies of occasions on account of its good performance, mild stimulation, and free of additional training. We design a trolley control system based on SSMVEP signals and observe a phenomenon named ""BCI Illiterate,"" in which case some subjects present unsatisfactory performance with low classification accuracies. In order to cope with this challenging problem in real-world contexts, we introduce a deep learning (DL) method. The method allows improving the accuracies for both EEG literate and EEG illiterate. In particular, we firstly conduct SSMVEP experiments to obtain EEG signals from 10 subjects, including 5 EEG literates and 5 EEG illiterates. Then we construct a convolutional neural network with long short-term memory (CNN-LSTM) framework, which allows extracting the spectral, spatial, and temporal features of EEG signals, to realize the high classification accuracies of SSMVEP signals. The results show that DL method can reach 96.83% and 91.86% for EEG literate and EEG illiterate respectively, which are 12.68% and 31.08% higher than the results of traditional methods. These results indicate that DL method is not only suitable for EEG literate, but more importantly, can greatly improve the performance for EEG illiterate, which finally can enhance the robustness and universality of the SSMVEP-based BCI.","Electroencephalography,Feature extraction,Deep learning,Brain-computer interfaces,Brain modeling,Circuits and systems,Visualization,Electroencephalogram (EEG) analysis,steady state motion visual evoked potential (SSMVEP),deep learning (DL),brain computer interface (BCI)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,3.143,"EEG,NETWORK",IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS,,
41,Deep Fuzzy Neural Networks for Biomarker Selection for Accurate Cancer Detection,28,12,3219-3228,"Bamunu Mudiyanselage Thosini K.,Xiao Xueli,Zhang Yanqing,Pan Yi","Mudiyanselage TBK,Xiao XL,Zhang YQ,Pan Y",Mudiyanselage TBK,10.1109/TFUZZ.2019.2958295,University System of Georgia,"Different biomedical computing methods for cancer-specific gene recognition have been developed in recent years. Currently, building an open-box machine learning system to discover explainable knowledge from gene expression data is a difficult research problem due to a large number of genes, a small number of samples, and noise. Fuzzy systems can be used to deal with data ambiguity and noise issues and extract meaningful knowledge from gene data. In this article, we create a new deep fuzzy neural network to handle the uncertainty in gene data to generate useful knowledge for specific disease diagnosis. A new hybrid algorithm is designed to preprocess data and select informative genes for accurate cancer detection. Various experiments using six different cancer datasets indicate that the new method has better and more reliable performance than the other conventional classification methods with different gene selection methods.","Cancer,Feature extraction,Fuzzy neural networks,Support vector machines,Gene expression,Cancer detection,Biomarker selection,cancer detection,deep fuzzy (DF) neural networks,feature selection,gene expression data",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering",,10.444,"GENE,SELECTION,CLASSIFICATION",IEEE TRANSACTIONS ON FUZZY SYSTEMS,,
42,Post-DAE: Anatomically Plausible Segmentation via Post-Processing With Denoising Autoencoders,39,12,3813-3820,"Larrazabal Agostina J.,Martinez Cesar,Glocker Ben,Ferrante Enzo","Larrazabal AJ,Martinez C,Glocker B,Ferrante E",Ferrante E,10.1109/TMI.2020.3005297,Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET),"We introduce Post-DAE, a post-processing method based on denoising autoencoders (DAE) to improve the anatomical plausibility of arbitrary biomedical image segmentation algorithms. Some of the most popular segmentation methods (e.g. based on convolutional neural networks or random forest classifiers) incorporate additional post-processing steps to ensure that the resulting masks fulfill expected connectivity constraints. These methods operate under the hypothesis that contiguous pixels with similar aspect should belong to the same class. Even if valid in general, this assumption does not consider more complex priors like topological restrictions or convexity, which cannot be easily incorporated into these methods. Post-DAE leverages the latest developments in manifold learning via denoising autoencoders. First, we learn a compact and non-linear embedding that represents the space of anatomically plausible segmentations. Then, given a segmentation mask obtained with an arbitrary method, we reconstruct its anatomically plausible version by projecting it onto the learnt manifold. The proposed method is trained using unpaired segmentation mask, what makes it independent of intensity information and image modality. We performed experiments in binary and multi-label segmentation of chest X-ray and cardiac magnetic resonance images. We show how erroneous and noisy segmentation masks can be improved using Post-DAE. With almost no additional computation cost, our method brings erroneous segmentations back to a feasible space.","Image segmentation,Shape,Noise reduction,Biomedical imaging,Topology,Manifolds,X-ray imaging,Anatomical segmentation,autoencoders,convolutional neural networks,learning representations,post-processing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CHEST,RADIOGRAPHS,IMAGE,FEATURES,NETWORK",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://spiral.imperial.ac.uk/bitstream/10044/1/80379/2/2006.13791v1.pdf,
43,Learning Sub-Sampling and Signal Recovery With Applications in Ultrasound Imaging,39,12,3955-3966,"Huijben Iris A. M.,Veeling Bastiaan S.,Janse Kees,Mischi Massimo,van Sloun Ruud J. G.","Huijben IAM,Veeling BS,Janse K,Mischi M,van Sloun RJG",Huijben IAM,10.1109/TMI.2020.3008501,Eindhoven University of Technology,"Limitations on bandwidth and power consumption impose strict bounds on data rates of diagnostic imaging systems. Consequently, the design of suitable (i.e. task- and data-aware) compression and reconstruction techniques has attracted considerable attention in recent years. Compressed sensing emerged as a popular framework for sparse signal reconstruction from a small set of compressed measurements. However, typical compressed sensing designs measure a (non)linearly weighted combination of all input signal elements, which poses practical challenges. These designs are also not necessarily task-optimal. In addition, real-time recovery is hampered by the iterative and time-consuming nature of sparse recovery algorithms. Recently, deep learning methods have shown promise for fast recovery from compressed measurements, but the design of adequate and practical sensing strategies remains a challenge. Here, we propose a deep learning solution termed Deep Probabilistic Sub-sampling (DPS), that enables joint optimization of a task-adaptive sub-sampling pattern and a subsequent neural task model in an end-to-end fashion. Once learned, the task-based sub-sampling patterns are fixed and straightforwardly implementable, e.g. by non-uniform analog-to-digital conversion, sparse array design, or slow-time ultrasound pulsing schemes. The effectiveness of our framework is demonstrated in-silico for sparse signal recovery from partial Fourier measurements, and in-vivo for both anatomical image and tissue-motion (Doppler) reconstruction from sub-sampled medical ultrasound imaging data.","Task analysis,Image reconstruction,Deep learning,Ultrasonic imaging,Compressed sensing,Biomedical imaging,Deep learning,compressed sensing,probabilistic sampling,ultrasound imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"BEAM,COMPUTED-TOMOGRAPHY,RECONSTRUCTION,MRI",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1908.05764,
44,Adaptive Ultrasound Beamforming Using Deep Learning,39,12,3967-3978,"Luijten Ben,Cohen Regev,de Bruijn Frederik J.,Schmeitz Harold A. W.,Mischi Massimo,Eldar Yonina C.,van Sloun Ruud J. G.","Luijten B,Cohen R,de Bruijn FJ,Schmeitz HAW,Mischi M,Eldar YC,van Sloun RJG",Luijten B,10.1109/TMI.2020.3008537,Eindhoven University of Technology,"Biomedical imaging is unequivocally dependent on the ability to reconstruct interpretable and high-quality images from acquired sensor data. This reconstruction process is pivotal across many applications, spanning from magnetic resonance imaging to ultrasound imaging. While advanced data-adaptive reconstruction methods can recover much higher image quality than traditional approaches, their implementation often poses a high computational burden. In ultrasound imaging, this burden is significant, especially when striving for low-cost systems, and has motivated the development of high-resolution and high-contrast adaptive beamforming methods. Here we show that deep neural networks, that adopt the algorithmic structure and constraints of adaptive signal processing techniques, can efficiently learn to perform fast high-quality ultrasound beamforming using very little training data. We apply our technique to two distinct ultrasound acquisition strategies (plane wave, and synthetic aperture), and demonstrate that high image quality can be maintained when measuring at low data-rates, using undersampled array designs. Beyond biomedical imaging, we expect that the proposed deep learning based adaptive processing framework can benefit a variety of array and signal processing applications, in particular when data-efficiency and robustness are of importance.","Array signal processing,Imaging,Ultrasonic imaging,Deep learning,Image reconstruction,Image quality,Training,Ultrasound,adaptive beamforming,deep learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,NETWORKS,IEEE TRANSACTIONS ON MEDICAL IMAGING,https://pure.tue.nl/ws/files/147620216/1909.10342.pdf,
45,Target-Independent Domain Adaptation for WBC Classification Using Generative Latent Search,39,12,3979-3991,"Pandey Prashant,Prathosh A. P.,Kyatham Vinay,Mishra Deepak,Dastidar Tathagato Rai","Pandey P,Prathosh AP,Kyatham V,Mishra D,Dastidar TR",Prathosh AP,10.1109/TMI.2020.3009029,Indian Institute of Technology System (IIT System),"Automating the classification of camera-obtained microscopic images of White Blood Cells (WBCs) and related cell subtypes has assumed importance since it aids the laborious manual process of review and diagnosis. Several State-Of-The-Art (SOTA) methods developed using Deep Convolutional Neural Networks suffer from the problem of domain shift - severe performance degradation when they are tested on data (target) obtained in a setting different from that of the training (source). The change in the target data might be caused by factors such as differences in camera/microscope types, lenses, lighting-conditions etc. This problem can potentially be solved using Unsupervised Domain Adaptation (UDA) techniques albeit standard algorithms presuppose the existence of a sufficient amount of unlabelled target data which is not always the case with medical images. In this paper, we propose a method for UDA that is devoid of the need for target data. Given a test image from the target data, we obtain its 'closest-clone' from the source data that is used as a proxy in the classifier. We prove the existence of such a clone given that infinite number of data points can be sampled from the source distribution. We propose a method in which a latent-variable generative model based on variational inference is used to simultaneously sample and find the 'closest-clone' from the source distribution through an optimization procedure in the latent space. We demonstrate the efficacy of the proposed method over several SOTA UDA methods for WBC classification on datasets captured using different imaging modalities under multiple settings.","Training,Adaptation models,Task analysis,Microscopy,Biomedical imaging,Cloning,Cameras,WBC,microscopic imaging,unsupervised domain adaptation,generative models,VAE",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2005.05432,
46,Deep Learning-Based Detection and Correction of Cardiac MR Motion Artefacts During Reconstruction for High-Quality Segmentation,39,12,4001-4010,"Oksuz Ilkay,Clough James R.,Ruijsink Bram,Anton Esther Puyol,Bustin Aurelien,Cruz Gastao,Prieto Claudia,King Andrew P.,Schnabel Julia A.","Oksuz I,Clough JR,Ruijsink B,Anton EP,Bustin A,Cruz G,Prieto C,King AP,Schnabel JA",Oksuz I,10.1109/TMI.2020.3008930,Istanbul Technical University,"Segmenting anatomical structures in medical images has been successfully addressed with deep learning methods for a range of applications. However, this success is heavily dependent on the quality of the image that is being segmented. A commonly neglected point in the medical image analysis community is the vast amount of clinical images that have severe image artefacts due to organ motion, movement of the patient and/or image acquisition related issues. In this paper, we discuss the implications of image motion artefacts on cardiac MR segmentation and compare a variety of approaches for jointly correcting for artefacts and segmenting the cardiac cavity. The method is based on our recently developed joint artefact detection and reconstruction method, which reconstructs high quality MR images from k-space using a joint loss function and essentially converts the artefact correction task to an under-sampled image reconstruction task by enforcing a data consistency term. In this paper, we propose to use a segmentation network coupled with this in an end-to-end framework. Our training optimises three different tasks: 1) image artefact detection, 2) artefact correction and 3) image segmentation. We train the reconstruction network to automatically correct for motion-related artefacts using synthetically corrupted cardiac MR k-space data and uncorrected reconstructed images. Using a test set of 500 2D+time cine MR acquisitions from the UK Biobank data set, we achieve demonstrably good image quality and high segmentation accuracy in the presence of synthetic motion artefacts. We showcase better performance compared to various image correction architectures.","Image segmentation,Motion segmentation,Biomedical imaging,Image reconstruction,Deep learning,Task analysis,Image quality,Image quality,image segmentation,deep learning,cardiac MRI,image artefacts",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORKS,IMAGE",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1910.05370,
47,PSIGAN: Joint Probabilistic Segmentation and Image Distribution Matching for Unpaired Cross-Modality Adaptation-Based MRI Segmentation,39,12,4071-4084,"Jiang Jue,Hu Yu-Chi,Tyagi Neelam,Rimner Andreas,Lee Nancy,Deasy Joseph O.,Berry Sean,Veeraraghavan Harini","Jiang J,Hu YC,Tyagi N,Rimner A,Lee N,Deasy JO,Berry S,Veeraraghavan H",Veeraraghavan H,10.1109/TMI.2020.3011626,Memorial Sloan Kettering Cancer Center,"We developed a new joint probabilistic segmentation and image distribution matching generative adversarial network (PSIGAN) for unsupervised domain adaptation (UDA) and multi-organ segmentation from magnetic resonance (MRI) images. Our UDA approach models the co-dependency between images and their segmentation as a joint probability distribution using a new structure discriminator. The structure discriminator computes structure of interest focused adversarial loss by combining the generated pseudo MRI with probabilistic segmentations produced by a simultaneously trained segmentation sub-network. The segmentation sub-network is trained using the pseudo MRI produced by the generator sub-network. This leads to a cyclical optimization of both the generator and segmentation sub-networks that are jointly trained as part of an end-to-end network. Extensive experiments and comparisons against multiple state-of-the-art methods were done on four different MRI sequences totalling 257 scans for generating multi-organ and tumor segmentation. The experiments included, (a) 20 T1-weighted (T1w) in-phase mdixon and (b) 20 T2-weighted (T2w) abdominal MRI for segmenting liver, spleen, left and right kidneys, (c) 162 T2-weighted fat suppressed head and neck MRI (T2wFS) for parotid gland segmentation, and (d) 75 T2w MRI for lung tumor segmentation. Our method achieved an overall average DSC of 0.87 on T1w and 0.90 on T2w for the abdominal organs, 0.82 on T2wFS for the parotid glands, and 0.77 on T2w MRI for lung tumors.","Image segmentation,Magnetic resonance imaging,Computed tomography,Training,Generators,Geometry,Computational modeling,Unsupervised domain adaptation,generative adversarial network,MRI segmentation,lung tumor,parotid glands,abdominal organs",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2007.09465,
48,Multi-Frequency Electromagnetic Tomography for Acute Stroke Detection Using Frequency-Constrained Sparse Bayesian Learning,39,12,4102-4112,"Xiang Jinxi,Dong Yonggui,Yang Yunjie","Xiang JX,Dong YG,Yang YJ",Dong YG,10.1109/TMI.2020.3013100,Tsinghua University,"Imaging the bio-impedance distribution of the brain can provide initial diagnosis of acute stroke. This paper presents a compact and non-radiative tomographic modality, i.e. multi-frequency Electromagnetic Tomography (mfEMT), for the initial diagnosis of acute stroke. The mfEMT system consists of 12 channels of gradiometer coils with adjustable sensitivity and excitation frequency. To solve the image reconstruction problem of mfEMT, we propose an enhanced Frequency-Constrained Sparse Bayesian Learning (FC-SBL) to simultaneously reconstruct the conductivity distribution at all frequencies. Based on the Multiple Measurement Vector (MMV) model in the Sparse Bayesian Learning (SBL) framework, FC-SBL can recover the underlying distribution pattern of conductivity among multiple images by exploiting the frequency constraint information. A realistic 3D head model was established to simulate stroke detection scenarios, showing the capability of mfEMT to penetrate the highly resistive skull and improved image quality with FC-SBL. Both simulations and experiments showed that the proposed FC-SBL method is robust to noisy data for image reconstruction problems of mfEMT compared to the single measurement vector model, which is promising to detect acute strokes in the brain region with enhanced spatial resolution and in a baseline-free manner.","Coils,Conductivity,Tomography,Sensitivity,Image reconstruction,Data models,Acute stroke,electromagnetic tomography,multi-frequency,multiple measurement model,sparse Bayesian learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"HEAD,EIT,ALGORITHMS,HEMORRHAGE,SYSTEM",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2003.00998,
49,Disentangled-Multimodal Adversarial Autoencoder: Application to Infant Age Prediction With Incomplete Multimodal Neuroimages,39,12,4137-4149,"Hu Dan,Zhang Han,Wu Zhengwang,Wang Fan,Wang Li,Smith J. Keith,Lin Weili,Li Gang,Shen Dinggang","Hu D,Zhang H,Wu ZW,Wang F,Wang L,Smith JK,Lin WL,Li G,Shen DG",Li G; Shen DG,10.1109/TMI.2020.3013825,University of North Carolina,"Effective fusion of structural magnetic resonance imaging (sMRI) and functional magnetic resonance imaging (fMRI) data has the potential to boost the accuracy of infant age prediction thanks to the complementary information provided by different imaging modalities. However, functional connectivity measured by fMRI during infancy is largely immature and noisy compared to the morphological features from sMRI, thus making the sMRI and fMRI fusion for infant brain analysis extremely challenging. With the conventional multimodal fusion strategies, adding fMRI data for age prediction has a high risk of introducing more noises than useful features, which would lead to reduced accuracy than that merely using sMRI data. To address this issue, we develop a novel model termed as disentangled-multimodal adversarial autoencoder (DMM-AAE) for infant age prediction based on multimodal brain MRI. Specifically, we disentangle the latent variables of autoencoder into common and specific codes to represent the shared and complementary information among modalities, respectively. Then, cross-reconstruction requirement and common-specific distance ratio loss are designed as regularizations to ensure the effectiveness and thoroughness of the disentanglement. By arranging relatively independent autoencoders to separate the modalities and employing disentanglement under cross-reconstruction requirement to integrate them, our DMM-AAE method effectively restrains the possible interference cross modalities, while realizing effective information fusion. Taking advantage of the latent variable disentanglement, a new strategy is further proposed and embedded into DMM-AAE to address the issue of incompleteness of the multimodal neuroimages, which can also be used as an independent algorithm for missing modality imputation. By taking six types of cortical morphometric features from sMRI and brain functional connectivity from fMRI as predictors, the superiority of the proposed DMM-AAE is validated on infant age (35 to 848 days after birth) prediction using incomplete multimodal neuroimages. The mean absolute error of the prediction based on DMM-AAE reaches 37.6 days, outperforming state-of-the-art methods. Generally, our proposed DMM-AAE can serve as a promising model for prediction with multimodal data.","Functional magnetic resonance imaging,Brain modeling,Predictive models,Data models,Biological system modeling,Biomarkers,Infant age prediction,autoencoder,magnetic resonance imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"BRAIN-AGE,CORTICAL,THICKNESS,BIRTH",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
50,Deep Generalization of Structured Low-Rank Algorithms (Deep-SLR),39,12,4186-4197,"Pramanik Aniket,Aggarwal Hemant Kumar,Jacob Mathews","Pramanik A,Aggarwal HK,Jacob M",Pramanik A,10.1109/TMI.2020.3014581,University of Iowa,"Structured low-rank (SLR) algorithms, which exploit annihilation relations between the Fourier samples of a signal resulting from different properties, is a powerful image reconstruction framework in several applications. This scheme relies on low-rank matrix completion to estimate the annihilation relations from the measurements. The main challenge with this strategy is the high computational complexity of matrix completion. We introduce a deep learning (DL) approach to significantly reduce the computational complexity. Specifically, we use a convolutional neural network (CNN)-based filterbank that is trained to estimate the annihilation relations from imperfect (under-sampled and noisy) k-space measurements of Magnetic Resonance Imaging (MRI). The main reason for the computational efficiency is the pre-learning of the parameters of the non-linear CNN from exemplar data, compared to SLR schemes that learn the linear filterbank parameters from the dataset itself. Experimental comparisons show that the proposed scheme can enable calibration-less parallel MRI; it can offer performance similar to SLR schemes while reducing the runtime by around three orders of magnitude. Unlike pre-calibrated and self-calibrated approaches, the proposed uncalibrated approach is insensitive to motion errors and affords higher acceleration. The proposed scheme also incorporates image domain priors that are complementary, thus significantly improving the performance over that of SLR schemes.","Magnetic resonance imaging,Calibration,Sensitivity,Acceleration,Null space,Noise measurement,Image reconstruction,Parallel MRI,reconstruction,structured low rank,annihilation,DL",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"RESONANCE-IMAGING,RECONSTRUCTION,PIECEWISE-CONSTANT,IMAGES,RECOVERY,MRI,SENSE",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1912.03433,
51,Unsupervised MR-to-CT Synthesis Using Structure-Constrained CycleGAN,39,12,4249-4261,"Yang Heran,Sun Jian,Carass Aaron,Zhao Can,Lee Junghoon,Prince Jerry L.,Xu Zongben","Yang HR,Sun J,Carass A,Zhao C,Lee J,Prince JL,Xu ZB",Sun J,10.1109/TMI.2020.3015379,Xi'an Jiaotong University,"Synthesizing a CT image from an available MR image has recently emerged as a key goal in radiotherapy treatment planning for cancer patients. CycleGANs have achieved promising results on unsupervised MR-to-CT image synthesis; however, because they have no direct constraints between input and synthetic images, cycleGANs do not guarantee structural consistency between these two images. This means that anatomical geometry can be shifted in the synthetic CT images, clearly a highly undesirable outcome in the given application. In this paper, we propose a structure-constrained cycleGAN for unsupervised MR-to-CT synthesis by defining an extra structure-consistency loss based on the modality independent neighborhood descriptor. We also utilize a spectral normalization technique to stabilize the training process and a self-attention module to model the long-range spatial dependencies in the synthetic images. Results on unpaired brain and abdomen MR-to-CT image synthesis show that our method produces better synthetic CT images in both accuracy and visual quality as compared to other unsupervised synthesis methods. We also show that an approximate affine pre-registration for unpaired training data can improve synthesis results.","Channel estimation,Antenna arrays,MIMO communication,Matching pursuit algorithms,5G mobile communication,Array signal processing,Lenses,MR-to-CT synthesis,CycleGAN,deep learning,MIND",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"ATTENUATION,CORRECTION,RADIOTHERAPY,IMAGE,VOLUMES",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
52,Learning the Sampling Pattern for MRI,39,12,4310-4321,"Sherry Ferdia,Benning Martin,De los Reyes Juan Carlos,Graves Martin J.,Maierhofer Georg,Williams Guy,Schonlieb Carola-Bibiane,Ehrhardt Matthias J.","Sherry F,Benning M,De los Reyes JC,Graves MJ,Maierhofer G,Williams G,Schonlieb CB,Ehrhardt MJ",Sherry F,10.1109/TMI.2020.3017353,University of Cambridge,"The discovery of the theory of compressed sensing brought the realisation that many inverse problems can be solved even when measurements are ""incomplete"". This is particularly interesting in magnetic resonance imaging (MRI), where long acquisition times can limit its use. In this work, we consider the problem of learning a sparse sampling pattern that can be used to optimally balance acquisition time versus quality of the reconstructed image. We use a supervised learning approach, making the assumption that our training data is representative enough of new data acquisitions. We demonstrate that this is indeed the case, even if the training data consists of just 7 training pairs of measurements and ground-truth images; with a training set of brain images of size 192 by 192, for instance, one of the learned patterns samples only 35% of k-space, however results in reconstructions with mean SSIM 0.914 on a test set of similar images. The proposed framework is general enough to learn arbitrary sampling patterns, including common patterns such as Cartesian, spiral and radial sampling.","Image reconstruction,Magnetic resonance imaging,Compressed sensing,Reconstruction algorithms,Training,Transforms,Optimization,MRI,k-space optimisation,compressed sensing,bilevel learning,regularisation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"ACCELERATED,MRI,RECONSTRUCTION,ALGORITHM,STRATEGIES,SPARSITY",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1906.08754,
53,Deep Reinforcement Learning Designed Shinnar-Le Roux RF Pulse Using Root-Flipping: DeepRF(SLR),39,12,4391-4400,"Shin Dongmyung,Ji Sooyeon,Lee Doohee,Lee Jieun,Oh Se-Hong,Lee Jongho","Shin D,Ji S,Lee D,Lee J,Oh SH,Lee J",Lee J,10.1109/TMI.2020.3018508,Seoul National University (SNU),"A novel approach of applying deep reinforcement learning to an RF pulse design is introduced. This method, which is referred to as DeepRF(SLR), is designed to minimize the peak amplitude or, equivalently, minimize the pulse duration of a multiband refocusing pulse generated by the Shinar Le-Roux (SLR) algorithm. In the method, the root pattern of SLR polynomial, which determines the RF pulse shape, is optimized by iterative applications of deep reinforcement learning and greedy tree search. When tested for the designs of the multiband pulses with three and seven slices, DeepRF(SLR) demonstrated improved performance compared to conventional methods, generating shorter duration RF pulses in shorter computational time. In the experiments, the RF pulse from DeepRF(SLR) produced a slice profile similar to the minimum-phase SLR RF pulse and the profiles matched to that of the computer simulation. Our approach suggests a new way of designing an RF by applying a machine learning algorithm, demonstrating a ""machine-designed"" MRI sequence.","Radio frequency,Reinforcement learning,Neural networks,Magnetic resonance imaging,Deep learning,Games,Optimization,Deep reinforcement learning,machine-design,deep learning,artificial intelligence,AI design",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"SIMULTANEOUS,MULTISLICE,EXCITATION,NEURAL-NETWORKS,MAGNITUDE",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1912.09015,
54,Self-Supervised Ultrasound to MRI Fetal Brain Image Synthesis,39,12,4413-4424,"Jiao Jianbo,Namburete Ana I. L.,Papageorghiou Aris T.,Noble J. Alison","Jiao JB,Namburete AIL,Papageorghiou AT,Noble JA",Jiao JB,10.1109/TMI.2020.3018560,University of Oxford,"Fetal brain magnetic resonance imaging (MRI) offers exquisite images of the developing brain but is not suitable for second-trimester anomaly screening, for which ultrasound (US) is employed. Although expert sonographers are adept at reading US images, MR images which closely resemble anatomical images are much easier for non-experts to interpret. Thus in this article we propose to generate MR-like images directly from clinical US images. In medical image analysis such a capability is potentially useful as well, for instance for automatic US-MRI registration and fusion. The proposed model is end-to-end trainable and self-supervised without any external annotations. Specifically, based on an assumption that the US and MRI data share a similar anatomical latent space, we first utilise a network to extract the shared latent features, which are then used for MRI synthesis. Since paired data is unavailable for our study (and rare in practice), pixel-level constraints are infeasible to apply. We instead propose to enforce the distributions to be statistically indistinguishable, by adversarial learning in both the image domain and feature space. To regularise the anatomical structures between US and MRI during synthesis, we further propose an adversarial structural constraint. A new cross-modal attention technique is proposed to utilise non-local spatial information, by encouraging multi-modal knowledge fusion and propagation. We extend the approach to consider the case where 3D auxiliary information (e.g., 3D neighbours and a 3D location index) from volumetric data is also available, and show that this improves image synthesis. The proposed approach is evaluated quantitatively and qualitatively with comparison to real fetal MR images and other approaches to synthesis, demonstrating its feasibility of synthesising realistic MR images.","Magnetic resonance imaging,Computed tomography,Image synthesis,Image segmentation,Biomedical imaging,Three-dimensional displays,Ultrasonic imaging,Self-supervised,unpaired,ultrasound,MRI",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"ATTENUATION-CORRECTION,LOCALIZATION,REGISTRATION,CT",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2008.08698,
55,Fourier Properties of Symmetric-Geometry Computed Tomography and Its Linogram Reconstruction With Neural Network,39,12,4445-4457,"Zhang Tao,Zhang Li,Chen Zhiqiang,Xing Yuxiang,Gao Hewei","Zhang T,Zhang L,Chen ZQ,Xing YX,Gao HW",Chen ZQ; Gao HW,10.1109/TMI.2020.3020720,Tsinghua University,"In this work, we investigate the Fourier properties of a symmetric-geometry computed tomography (SGCT) with linearly distributed source and detector in a stationary configuration. A linkage between the 1D Fourier Transform of a weighted projection from SGCT and the 2D Fourier Transform of a deformed object is established in a simple mathematical form (i.e., the Fourier slice theorem for SGCT). Based on its Fourier slice theorem and its unique data sampling in the Fourier space, a Linogram-based Fourier reconstruction method is derived for SGCT. We demonstrate that the entire Linogram reconstruction process can be embedded as known operators into an end-to-end neural network. As a learning-based approach, the proposed Linogram-Net has capability of improving CT image quality for non-ideal imaging scenarios, a limited-angle SGCT for instance, through combining weights learning in the projection domain and loss minimization in the image domain. Numerical simulations and physical experiments on an SGCT prototype platform showed that our proposed Linogram-based method can achieve accurate reconstruction from a dual-SGCT scan and can greatly reduce computational complexity when compared with the filtered backprojection type reconstruction. The Linogram-Net achieved accurate reconstruction when projection data are complete and significantly suppressed image artifacts from a limited-angle SGCT scan mimicked by using a clinical CT dataset, with the average CT number error in the selected regions of interest reduced from 67.7 Hounsfield Units (HU) to 28.7 HU, and the average normalized mean square error of overall images reduced from 4.21e-3 to 2.65e-3.","Computed tomography,Image reconstruction,Fourier transforms,Detectors,Neural networks,Geometry,Symmetric-geometry computed tomography,Fourier property,Fourier slice theorem,Linogram,prior knowledge,neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"IMAGE-RECONSTRUCTION,ALGORITHM,INVERSION",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
56,Wireless 2.0: Toward an Intelligent Radio Environment Empowered by Reconfigurable Meta-Surfaces and Artificial Intelligence,15,4,74-82,"Gacanin Haris,Di Renzo Marco","Gacanin H,Di Renzo M",Gacanin H,10.1109/MVT.2020.3017927,RWTH Aachen University,"In this article, we introduce Wireless 2.0, the future generation of wireless communication networks, in which the radio environment becomes controllable and intelligent by leveraging the emerging technologies of reconfigurable metasurfaces (RMSs) and artificial intelligence (AI). In particular, we emphasize AI-based computational methods and commence with an overview of the concept of intelligent radio environments (IREs) based on RMSs. Then, we elaborate on data management aspects, the requirements of supervised learning by examples, and the paradigm of reinforcement learning to learn by acting. Finally, we highlight numerous open challenges and research directions.","Wireless networks,Artificial intelligence,Optimization,Radio transmitters,5G mobile communication,Receivers,Supervised learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Telecommunications,Transportation",,9.833,MANAGEMENT,IEEE VEHICULAR TECHNOLOGY MAGAZINE,,
57,"Visible Light Communication in 6G: Advances, Challenges, and Prospects",15,4,93-102,"Chi Nan,Zhou Yingjun,Wei Yiran,Hu Fangchen","Chi N,Zhou YJ,Wei YR,Hu FC",Chi N,10.1109/MVT.2020.3017153,Fudan University,"6G networks are expected to provide extremely high capacity and satisfy emerging applications, but current frequency bands may not be sufficient. Moreover, 6G will provide superior coverage by integrating space/air/underwater networks with terrestrial networks, given that traditional wireless communications are not able to provide high-speed data rates for nonterrestrial networks. Visible light communication (VLC) is a high-speed communication technique with an unlicensed frequency range of 400-800 THz and can be adopted as an alternative approach to solving these problems. In this article, we present the prospects and challenges of VLC in 6G in conjunction with its advances in high-speed transmissions. Recent hot research interests, including new materials and devices, advanced modulation, underwater VLC (UVLC), and signal processing based on machine learning, are also discussed. It is envisaged that VLC will become an indispensable part of 6G given its high-speed transmission advantages and will cooperate with other communication methods to benefit our daily lives.","Light emitting diodes,Bandwidth,Real-time systems,High-speed optical techniques,Modulation,Optical receivers,Wireless communication",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Telecommunications,Transportation",,9.833,VISION,IEEE VEHICULAR TECHNOLOGY MAGAZINE,,
58,Automated Identification of Defect Morphology and Spatial Distribution in Woven Composites,4,4,,"Madra Anna,Van-Pham Dan-Thuy,Nguyen Minh-Tri,Nguyen Chanh-Nghiem,Breitkopf Piotr,Trochu Francois","Madra A,Van-Pham DT,Nguyen MT,Nguyen CN,Breitkopf P,Trochu F",Trochu F,10.3390/jcs4040178,Universite de Montreal,"The performance of heterogeneous materials, for example, woven composites, does not always reach the predicted theoretical potential. This is caused by defects, such as residual voids introduced during the manufacturing process. A machine learning-based methodology is proposed to determine the morphology and spatial distribution of defects in composites based on X-ray microtomographic scans of the microstructure. A concept of defect ""genome"" is introduced as an indicator of the overall state of defects in the material, enabling a quick comparison of specimens manufactured under different conditions. The approach is illustrated for thermoplastic composites with unidirectional banana fiber reinforcement.","polymer-matrix composites (PMCs),porosity,voids,X-ray microtomography",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Materials Science,,,"DAMAGE,CHARACTERIZATION,COMPUTED-TOMOGRAPHY,TENSILE,TESTS,FATIGUE,FIBERS,MATRIX,PORES,VOIDS",JOURNAL OF COMPOSITES SCIENCE,https://www.mdpi.com/2504-477X/4/4/178/pdf,
59,Machine learning-guided synthesis of advanced inorganic materials,41,,72-80,"Tang Bijun,Lu Yuhao,Zhou Jiadong,Chouhan Tushar,Wang Han,Golani Prafful,Xu Manzhang,Xu Quan,Guan Cuntai,Liu Zheng","Tang BJ,Lu YH,Zhou JD,Chouhan T,Wang H,Golani P,Xu MZ,Xu Q,Guan CT,Liu Z",Liu Z,10.1016/j.mattod.2020.06.010,Nanyang Technological University & National Institute of Education (NIE) Singapore,"Synthesis of materials with minimum number of trials is of paramount importance towards the acceleration of advanced materials development. The enormous complexity involved in existing multivariable synthesis methods leads to high uncertainty, numerous trials and exorbitant cost. Recently, machine learning (ML) has demonstrated tremendous potential for material discovery and property enhancement. Here, we extend the application of ML to guide material synthesis process through the establishment of the methodology including model construction, optimization, and progressive adaptive model (PAM). Two representative multi-variable systems are studied. A classification ML model on chemical vapor grown MoS2 is developed, capable of optimizing the synthesis conditions to achieve a higher success rate. And a regression model is constructed on the hydrothermal-grown carbon quantum dots, to enhance the process-related properties such as the photoluminescence quantum yield. The importance of synthesis parameters on experimental outcomes is particularly extracted from the constructed ML models. Furthermore, off-line analysis shows that enhancement of the experimental outcome with minimized number of trials can be achieved with the effective feedback loops in PAM, suggesting the great potential of involving ML to guide new material synthesis at the beginning stage. This work serves as a proof of concept for using ML in facilitating the synthesis of inorganic materials, thereby revealing the feasibility and remarkable capability of ML in opening up a new promising window for accelerating material development.","MONOLAYER,EVOLUTION,DOTS,AREA",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Materials Science,,36.768,"MONOLAYER,EVOLUTION,DOTS,AREA",MATERIALS TODAY,http://arxiv.org/pdf/1905.03938,
60,Multivariate data analysis in cell gene therapy manufacturing,45,,,"Emerson Joseph,Kara Bo,Glassey Jarka","Emerson J,Kara B,Glassey J",Glassey J,10.1016/j.biotechadv.2020.107637,Newcastle University - UK,"The emergence of cell gene therapy (CGT) as a safe and efficacious treatment for numerous severe inherited and acquired human diseases has led to growing interest and investment in new CGT products. The most successful of these have been autologous viral vector-based treatments. The development of viral vector manufacturing processes and ex vivo patient cell processing capabilities is a pressing issue in the advancement of autologous viral vector-based CGT treatments. In viral vector production, scale-up is a critical task due to the limited scalability of traditional laboratory systems and the demand for high volumes of viral vector manufactured in accordance with current good manufacturing practice. Ex vivo cell processing methods require optimisation and automation before they can be scaled out, and several other manufacturing challenges are prevalent such as high levels of raw material and process variability, difficulty characterising complex materials, and a lack of knowledge of critical process parameters and their effect on critical quality attributes of the viral vector and cell drug products. Multivariate data analysis (MVDA) has been leveraged successfully in a variety of applications in the chemical and biochemical industries, including for tasks such as bioprocess monitoring, identification of critical process parameters and assessment of process variability and comparability during process development, scale-up and technology transfer. Henceforth, MVDA is reviewed here as a suitable tool for tackling some of the challenges faced in the development of CGT manufacturing processes. A summary of some key CGT manufacturing challenges is provided along with a review of MVDA applications to mammalian and microbial processes, and an exploration of the potential benefits, requirements and pre-requisites of MVDA applications in the development of CGT manufacturing processes.","Cell gene therapy,Manufacturing challenges,Multivariate data analysis,Machine learning,Quality by design,Process development,Process understanding",Review,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Biotechnology & Applied Microbiology,,16.301,"ANALYTICAL,TECHNOLOGY,PAT,LENTIVIRAL,VECTOR,PRODUCTION,TO-BATCH,REPRODUCIBILITY,CULTURE,MEDIA,ADENOVIRAL,VECTORS,BIOTECH,PROCESSES,QUALITY-CONTROL,OPTIMIZATION,DESIGN,CHEMOMETRICS",BIOTECHNOLOGY ADVANCES,,
61,Machine learning lattice constants for spinel compounds,760,,,"Zhang Yun,Xu Xiaojie","Zhang Y,Xu XJ",Zhang Y,10.1016/j.cplett.2020.137993,University of North Carolina,"Spinels can house a large variety of elements into the crystal structure. As a crystallographic parameter, the lattice constant, a, is highly sought in further investigations into materials properties. Experimental approaches to obtain the lattice constant are resource-intensive, and limit the exploration into non-synthesized spinels. Here, we develop the Gaussian process regression model to shed light on the relationship among ionic radii, electronegativities, and lattice constants. 167 samples with lattice constants between 8.044 angstrom and 11.660 angstrom are investigated. The model provides more accurate predictions than previous studies based on linear regressions, and statistical relationships between descriptors and the target.","Spinel,Lattice constant,Ionic radii,Electronegativity,Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Chemistry,Physics",,1.999,"ELASTIC-MODULUS,DEFORMATION,COMPOSITES,PHASE",CHEMICAL PHYSICS LETTERS,,
62,Composition optimization of high strength and ductility ODS alloy based on machine learning,161,,,"Bai Bing,Han Xu,Zheng Quan,Jia Lixia,Zhang Changyi,Yang Wen","Bai B,Han X,Zheng Q,Jia LX,Zhang CY,Yang W",Bai B,10.1016/j.fusengdes.2020.111939,China Institute of Atomic Energy,"To find out characteristic parameters, mine data and predict candidate materials by machine learning is an important way for rapid development of materials. Based on about 300 groups data of composition, process, test condition and mechanical properties of ODS alloy, the correlation between the key component and the ultimate tensile strength and elongation of ODS alloy is established by deep learning method. It is found that there are optimal values of Cr%, Y2O3%, Al% and Ti% corresponding to the extreme value of the ultimate tensile strength. With the amount of Cr, Y2O3, and W increasing, the total elongation of ODS alloy decreased significantly, while the addition of Al and Ti is conducive to the improvement of the ductility in predicted range. Therefore, the optimized composition of higher strength and ductility ODS alloy is obtained through the correlation between the key components and tensile properties. The predicted tensile strength at room temperature is above 1400MPa, and more than 400MPa even at 700 degrees C. The predicted total elongation is more than 10 %. It will help to accelerate the optimization and development of ODS alloy which is used as structural material in fusion reactor.","ODS alloy,Tensile properties,Machine learning,Composition optimization",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND",Nuclear Science & Technology,,1.329,"MECHANICAL-PROPERTIES,STEELS",FUSION ENGINEERING AND DESIGN,,
63,Machine Learning-Based Pipeline for High Accuracy Bioparticle Sizing,11,12,,"Luo Shaobo,Zhang Yi,Nguyen Kim Truc,Feng Shilun,Shi Yuzhi,Liu Yang,Hutchinson Paul,Chierchia Giovanni,Talbot Hugues,Bourouina Tarik","Luo SB,Zhang Y,Nguyen KT,Feng SL,Shi YZ,Liu Y,Hutchinson P,Chierchia G,Talbot H,Bourouina T",Bourouina T,10.3390/mi11121084,Universite Gustave-Eiffel,"High accuracy measurement of size is essential in physical and biomedical sciences. Various sizing techniques have been widely used in sorting colloidal materials, analyzing bioparticles and monitoring the qualities of food and atmosphere. Most imaging-free methods such as light scattering measure the averaged size of particles and have difficulties in determining non-spherical particles. Imaging acquisition using camera is capable of observing individual nanoparticles in real time, but the accuracy is compromised by the image defocusing and instrumental calibration. In this work, a machine learning-based pipeline is developed to facilitate a high accuracy imaging-based particle sizing. The pipeline consists of an image segmentation module for cell identification and a machine learning model for accurate pixel-to-size conversion. The results manifest a significantly improved accuracy, showing great potential for a wide range of applications in environmental sensing, biomedical diagnostical, and material characterization.","machine learning,segmentation,CCD,CMOS,particle sizing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Science & Technology - Other Topics,Instruments & Instrumentation,Physics",,2.943,"SIZE,CRYPTOSPORIDIUM,GIARDIA",MICROMACHINES,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7762436,
64,Boosting Inter-ply Fracture Toughness Data on Carbon Nanotube-Engineered Carbon Composites for Prognostics,4,4,,Joshi Sunil C.,Joshi SC,Joshi SC,10.3390/jcs4040170,Nanyang Technological University & National Institute of Education (NIE) Singapore,"In order to build predictive analytic for engineering materials, large data is required for machine learning (ML). Gathering such a data can be demanding due to the challenges involved in producing specialty specimen and conducting ample experiments. Additionally, numerical simulations require efforts. Smaller datasets are still viable, however, they need to be boosted systematically for ML. A newly developed, knowledge-based data boosting (KBDB) process, named COMPOSITES, helps in logically enhancing the dataset size without further experimentation or detailed simulation. This process and its successful usage are discussed in this paper, using a combination of mode-I and mode-II inter-ply fracture toughness (IPFT) data on carbon nanotube (CNT) engineered carbon fiber reinforced polymer (CFRP) composites. The amount of CNT added to strengthen the mid-ply interface of CFRP vs the improvement in IPFT is studied. A simpler way of combining mode-I and mode-II values of IPFT to predict delamination resistance is presented. Every step of the 10-step KBDB process, its significance and implementation are explained and the results presented. The KBDB helped in not only adding a number of data points reliably, but also in finding boundaries and limitations of the augmented dataset. Such an authentically boosted dataset is vital for successful ML.","fracture toughness,carbon composites,knowledge-based data boosting,predictive analytic,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Materials Science,,,CNT,JOURNAL OF COMPOSITES SCIENCE,https://www.mdpi.com/2504-477X/4/4/170/pdf,
65,Tool Wear Prediction in Single-Sided Lapping Process,8,4,,Piotrowski Norbert,Piotrowski N,Piotrowski N,10.3390/machines8040059,Gdansk University of Technology,"Single-sided lapping is one of the most effective planarization technologies. The process has relatively complex kinematics and it is determined by a number of inputs parameters. It has been noted that prediction of the tool wear during the process is critical for product quality control. To determine the profile wear of the lapping plate, a computer model which simulates abrasive grains trajectories was developed in MATLAB. Moreover, a data-driven technique was investigated to indicate the relationship between the tool wear uniformity and lapping parameters such as the position of conditioning rings and rotational speed of the lapping plate and conditioning rings.","abrasive machining,single-sided lapping,tool wear,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Engineering,,2.467,"CHEMICAL-MECHANICAL,PLANARIZATION,MATERIAL,REMOVAL,RATE",MACHINES,https://www.mdpi.com/2075-1702/8/4/59/pdf,
66,Engineering early prediction of supercapacitors' cycle life using neural networks,18,,,"Ren Jiahao,Lin Xirong,Liu Jinyun,Han Tianli,Wang Zhilong,Zhang Haikuo,Li Jinjin","Ren JH,Lin XR,Liu JY,Han TL,Wang ZL,Zhang HK,Li JJ",Li JJ,10.1016/j.mtener.2020.100537,Shanghai Jiao Tong University,"Machine learning (ML) can replace mechanism-based solutions, such as first-principle calculation, for speeding up fundamental researches. Although ML has the benefits of representing the material's properties with critical descriptors without involving the physical/chemical mechanisms, the reliability of data-driven models remain a great challenge because of the scarcity and irregular distribution of data sets. Here, we develop several models with different input features and ML methods. We find the artificial neural network (ANN) with reasonable features that can greatly alleviate these two challenges by a case study of early prediction of supercapacitors (SCs) cycle lives. We generate a comprehensive data set consisting 88 commercial SCs cycled under different charging strategies, with widely varying cycle lives up to 10,000 cycles. Based on the ANN model, we achieve the early prediction of SCs' cycle life with the test errors less than 10.9%, only using the first 16% cycles, and such error could be further tuned by the data set. The proposed model is suitable for training widely distributed data set and has accurate early diagnosis and prediction ability for the performance of complex SC systems. (C) 2020 Elsevier Ltd. All rights reserved.","Machine learning,Feature descriptor,Artificial neural network,Life prediction,Irregular distribution of data sets",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Chemistry,Energy & Fuels,Materials Science",,7.122,"DOUBLE-LAYER,CAPACITORS,LITHIUM-ION,BATTERIES,ELECTROCHEMICAL,CAPACITORS,STATE,TEMPERATURE,COMBINATION,VOLTAGE",MATERIALS TODAY ENERGY,,
67,"Prediction of Equilibrium Phase, Stability and Stress-Strain Properties in Co-Cr-Fe-Ni-Al High Entropy Alloys Using Artificial Neural Networks",10,12,,"Filipoiu Nicolae,Nemnes George Alexandru","Filipoiu N,Nemnes GA",Nemnes GA,10.3390/met10121569,Horia Hulubei National Institute of Physics & Nuclear Engineering,"High entropy alloys (HEAs) are still a largely unexplored class of materials with high potential for applications in various fields. Motivated by the huge number of compounds in a given HEA class, we develop machine learning techniques, in particular artificial neural networks, coupled to ab initio calculations, in order to accurately predict some basic HEA properties: equilibrium phase, cohesive energies, density of states at the Fermi level and the stress-strain relation, under conditions of isotropic deformations. Known for its high tensile ductility and fracture toughness, the Co-Cr-Fe-Ni-Al alloy has been considered as a test candidate material, particularly by adjusting the Al content. However, further enhancement of the microstructure, mechanical and thermal properties is possible by modifying also the fractions of the base alloy. Using deep neural networks, we map structural and chemical neighborhood information onto the quantities of interest. This approach offers the possibility for an efficient screening over a huge number of potential candidates, which is essential in the exploration of multi-dimensional compositional spaces.","high entropy alloys,density functional theory,artificial neural networks",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Materials Science,Metallurgy & Metallurgical Engineering",,2.487,"THERMAL-STABILITY,WEAR,BEHAVIOR,MICROSTRUCTURE,EVOLUTION,DUCTILITY,ALUMINUM,HARDNESS,DESIGN",METALS,https://www.mdpi.com/2075-4701/10/12/1569/pdf,
68,Machine Learning-Assisted High-Throughput Molecular Dynamics Simulation of High-Mechanical Performance Carbon Nanotube Structure,10,12,,"Xiang Yi,Shimoyama Koji,Shirasu Keiichi,Yamamoto Go","Xiang Y,Shimoyama K,Shirasu K,Yamamoto G",Yamamoto G,10.3390/nano10122459,Tohoku University,"Carbon nanotubes (CNTs) are novel materials with extraordinary mechanical properties. To gain insight on the design of high-mechanical-performance CNT-reinforced composites, the optimal structure of CNTs with high nominal tensile strength was determined in this study, where the nominal values correspond to the cross-sectional area of the entire specimen, including the hollow core. By using machine learning-assisted high-throughput molecular dynamics (HTMD) simulation, the relationship among the following structural parameters/properties was investigated: diameter, number of walls, chirality, and crosslink density. A database, comprising the various tensile test simulation results, was analyzed using a self-organizing map (SOM). It was observed that the influence of crosslink density on the nominal tensile strength tends to gradually decrease from the outside to the inside; generally, the crosslink density between the outermost wall and its adjacent wall is highly significant. In particular, based on our calculation conditions, five-walled, armchair-type CNTs with an outer diameter of 43.39 angstrom and crosslink densities (between the inner wall and outer wall) of 1.38 +/- 1.16%, 1.13 +/- 0.69%, 1.54 +/- 0.57%, and 1.36 +/- 0.35% were believed to be the optimal structure, with the nominal tensile strength and nominal Young's modulus reaching approximately 58-64 GPa and 677-698 GPa.","carbon nanotube,molecular dynamics simulations,mechanical properties,Frenkel-pair crosslink,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,5.346,"PROPERTY,RELATIONSHIPS,FRACTURE,COMPOSITES,STRENGTH,DEFECTS",NANOMATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7764054,
69,Artificial Neural Networks-Based Material Parameter Identification for Numerical Simulations of Additively Manufactured Parts by Material Extrusion,12,12,,"Meissner Paul,Watschke Hagen,Winter Jens,Vietor Thomas","Meissner P,Watschke H,Winter J,Vietor T",Meissner P,10.3390/polym12122949,Braunschweig University of Technology,"To be able to use finite element (FE) simulations in structural component development, experimental investigations for the characterization of the material properties are required to subsequently calibrate suitable material cards. In contrast to the commonly used computational and time-consuming method of parameter identification (PI) by using analytical and numerical optimizations with internal or commercial software, a more time-efficient method based on machine learning (ML) is presented. This method is applied to simulate the material behavior of additively manufactured specimens made of acrylonitrile butadiene styrene (ABS) under uniaxial stress in a structural simulation. By using feedforward artificial neural networks (FFANN) for the ML-based direct inverse PI process, various investigations were carried out on the influence of sampling strategies, data quantity and data preparation on the prediction accuracy of the NN. Furthermore, the results of hyperparameter (HP) search methods are presented and discussed and their influence on the prediction quality of the FFANN are critically evaluated. The investigations show that the NN-based method is applicable to the present use case and results in material parameters that lead to a lower error between experimental and calculated force-displacement curves than the commonly used optimization-based method.","parameter identification,direct inverse model calibration,machine learning,hyperparameter optimization,feedforward artificial neural network,modeling strategy,additive manufacturing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Polymer Science,,4.493,"FINITE-ELEMENT,CONSTITUTIVE,PROPERTIES,MODELS,PLASTICITY,DESIGN",POLYMERS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7763659,
70,Structural Vibration Tests: Use of Artificial Neural Networks for Live Prediction of Structural Stress,10,23,,"Wilmes Laura,Olympio Raymond,de Payrebrune Kristin M.,Schatz Markus","Wilmes L,Olympio R,de Payrebrune KM,Schatz M",de Payrebrune KM,10.3390/app10238542,University of Kaiserslautern,"One of the ongoing tasks in space structure testing is the vibration test, in which a given structure is mounted onto a shaker and excited by a certain input load on a given frequency range, in order to reproduce the rigor of launch. These vibration tests need to be conducted in order to ensure that the devised structure meets the expected loads of its future application. However, the structure must not be overtested to avoid any risk of damage. For this, the system's response to the testing loads, i.e., stresses and forces in the structure, must be monitored and predicted live during the test. In order to solve the issues associated with existing methods of live monitoring of the structure's response, this paper investigated the use of artificial neural networks (ANNs) to predict the system's responses during the test. Hence, a framework was developed with different use cases to compare various kinds of artificial neural networks and eventually identify the most promising one. Thus, the conducted research accounts for a novel method for live prediction of stresses, allowing failure to be evaluated for different types of material via yield criteria.","mass operator,machine learning,structural stress,artificial neural network,live prediction,vibration test",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/23/8542/pdf,
71,A Multiscale Topographical Analysis Based on Morphological Information: The HEVC Multiscale Decomposition,13,23,,"Eseholi Tarek,Coudoux Francois-Xavier,Corlay Patrick,Sadli Rahmad,Bigerelle Maxence","Eseholi T,Coudoux FX,Corlay P,Sadli R,Bigerelle M",Bigerelle M,10.3390/ma13235582,Centre National de la Recherche Scientifique (CNRS),"In this paper, we evaluate the effect of scale analysis as well as the filtering process on the performances of an original compressed-domain classifier in the field of material surface topographies classification. Each surface profile is multiscale analyzed by using a Gaussian Filter analyzing method to be decomposed into three multiscale filtered image types: Low-pass (LP), Band-pass (BP), and High-pass (HP) filtered versions, respectively. The complete set of filtered image data constitutes the collected database. First, the images are lossless compressed using the state-of-the art High-efficiency video coding (HEVC) video coding standard. Then, the Intra-Prediction Modes Histogram (IPHM) feature descriptor is computed directly in the compressed domain from each HEVC compressed image. Finally, we apply the IPHM feature descriptors as an input of a Support Vector Machine (SVM) classifier. SVM is introduced here to strengthen the performances of the proposed classification system thanks to the powerful properties of machine learning tools. We evaluate the proposed solution we called ""HEVC Multiscale Decomposition"" (HEVC-MD) on a huge database of nearly 42,000 multiscale topographic images. A simple preliminary version of the algorithm reaches an accuracy of 52%. We increase this accuracy to 70% by using the multiscale analysis of the high-frequency range HP filtered image data sets. Finally, we verify that considering only the highest-scale analysis of low-frequency range LP was more appropriate for classifying our six surface topographies with an accuracy of up to 81%. To compare these new topographical descriptors to those conventionally used, SVM is applied on a set of 34 roughness parameters defined on the International Standard GPS ISO 25178 (Geometrical Product Specification), and one obtains accuracies of 38%, 52%, 65%, and 57% respectively for Sa, multiscale Sa, 34 roughness parameters, and multiscale ones. Compared to conventional roughness descriptors, the HEVC-MD descriptors increase surfaces discrimination from 65% to 81%.","mechanical engineering,surface roughness,roughness analysis,high-efficiency video coding (HEVC),texture feature descriptors,texture image classification,support vector machine (SVM)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,,"FEATURE-EXTRACTION,I-FRAME,RETRIEVAL,TOOL,SIMILARITY,SELECTION,VECTOR",MATERIALS,https://hal.archives-ouvertes.fr/hal-03321552/document,
72,Accelerated discovery of high-efficient N-annulated perylene organic sensitizers for solar cells via machine learning and quantum chemistry,25,,,"Ju Lifei,Li Minjie,Tian Lumin,Xu Pengcheng,Lu Wencong","Ju LF,Li MJ,Tian LM,Xu PC,Lu WC",Li MJ; Lu WC,10.1016/j.mtcomm.2020.101604,Shanghai University,"Dye-Sensitized Solar Cells (DSSCs) show the most promising future of photovoltaic devices due to the low cost, facile fabrication, cleanliness, and stable performance. In this work, we proposed one goal-directed method using data mining techniques integrated with quantum chemical analysis to design N-annulated perylene sensitizers. We constructed the robust quantitative structure-property relationship (QSPR) model via multiple linear regression (MLR), while the genetic algorithm (GA) was employed to select the crucial features. Then we designed the potential dyes according to the model guidance. The model predicted overall power conversion efficiencies (PCEs) of the designed molecules reached 15.7%, increased by 22.0% compared to reference dyes C281. Besides, density functional theory (DFT) and time-dependent density functional theory (TD-DFT) calculations revealed the more favorable charge-transfer and optoelectronic properties of new molecules. They have narrow bandgaps (up to 20.6% reduction), excellent light-harvesting efficiency (LHE) curves, and large maximum short-circuit current densities (20.5% increase). More importantly, the PCE values simulated by quantum chemistry are highly consistent with the values predicted by QSPR models. The designed N-annulated perylene dyes could be sensitizer candidates for highly efficient DSSCs. The novel goal-directed approach could potentially accelerate the discovery of other advanced energy materials and could offer valuable contributions to the development of photovoltaic devices.","Dye-sensitized solar cell,Metal-free organic dye,Power conversion efficiency,Quantitative structure-property relationship,Density functional theory",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.145,"POWER,CONVERSION,EFFICIENCY,MAIN-GROUP,THERMOCHEMISTRY,RATIONAL,SELECTION,ELECTRON-ACCEPTORS,LIGHT-ABSORPTION,EXCITED-STATE,TEST,SETS,DYE,FUNCTIONALS,PERFORMANCE",MATERIALS TODAY COMMUNICATIONS,,
73,Prediction of plastic yield surface for porous materials by a machine learning approach,25,,,"Shen W. Q.,Cao Y. J.,Shao J. F.,Liu Z. B.","Shen WQ,Cao YJ,Shao JF,Liu ZB",Shen WQ; Shao JF,10.1016/j.mtcomm.2020.101477,Northeastern University - China,"The present paper focuses on the prediction of effective plastic yield surface of porous materials having a von Mises type solid matrix. Some typical explicit yield criteria obtained by different analytical homogenization methods are briefly reviewed and evaluated by using numerical results obtained from direct finite element simulations with different values of porosity. Each criterion has its own advantage and weakness. In order to get a better prediction, the Artificial Neuron Network (ANN) algorithm is adopted specially for the prediction of macroscopic yield stress of porous materials, seen as a regression problem with two input parameters and one output value. For the training purpose which is a key step in the ANN approach, new numerical results are presented in the present work with a wide range of porosity and of macroscopic stress triaxiality. Based on these data, the ANN approach is trained and it converges quickly. Then the ANN predictions are compared with numerical test data, a good agreement is found for all loading cases. Comparing with the existing yield criteria, the prediction given by the ANN approach is much more accuracy and easy to apply.","Yield surface,Artificial neuron network,Machine learning,Porosity,Micro-mechanics",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.145,"2,POPULATIONS,MACROSCOPIC,CRITERION,NONSPHERICAL,VOIDS,APPROXIMATE,MODELS,CONSTITUTIVE,LAW,DUCTILE,METALS,STRENGTH,COALESCENCE,SOLIDS,MEDIA",MATERIALS TODAY COMMUNICATIONS,,
74,Guest Editorial: Deep Learning in Medical Ultrasound-From Image Formation to Image Analysis,67,12,2477-2480,"Mischi Massimo,Bell Muyinatu A. Lediju,van Sloun Ruud J. G.,Eldar Yonina C.","Mischi M,Bell MAL,van Sloun RJG,Eldar YC",Mischi M,10.1109/TUFFC.2020.3026598,Eindhoven University of Technology,"Over the past years, deep learning has established itself as a powerful tool across a broad spectrum of domains. While deep neural networks initially found nurture in the computer vision community, they have quickly spread over medical imaging applications, ranging from image analysis and interpretation to-more recently-image formation and reconstruction. Deep learning is now rapidly gaining attention in the ultrasound community, with many groups around the world exploring a wealth of opportunities to improve ultrasound imaging in several key aspects, ranging from beamforming and compressive sampling to speckle suppression, segmentation, and super-resolution imaging.",,Editorial Material,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,,IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,https://ieeexplore.ieee.org/ielx7/58/9269287/09269304.pdf,
75,Reconstruction for Diverging-Wave Imaging Using Deep Convolutional Neural Networks,67,12,2481-2492,"Lu Jingfeng,Millioz Fabien,Garcia Damien,Salles Sebastien,Liu Wanyu,Friboulet Denis","Lu JF,Millioz F,Garcia D,Salles S,Liu WY,Friboulet D",Lu JF,10.1109/TUFFC.2020.2986166,Harbin Institute of Technology,"In recent years, diverging wave (DW) ultrasound imaging has become a very promising methodology for cardiovascular imaging due to its high temporal resolution. However, if they are limited in number, DW transmits provide lower image quality compared with classical focused schemes. A conventional reconstruction approach consists in summing series of ultrasound signals coherently, at the expense of frame rate, data volume, and computation time. To deal with this limitation, we propose a convolutional neural network (CNN) architecture, Inception for DW Network (IDNet), for high-quality reconstruction of DW ultrasound images using a small number of transmissions. In order to cope with the specificities induced by the sectorial geometry associated with DW imaging, we adopted the inception model composed of the concatenation of multiscale convolution kernels. Incorporating inception modules aims at capturing different image features with multiscale receptive fields. A mapping between low-quality images and corresponding high-quality compounded reconstruction was learned by training the network using in vitro and in vivo samples. The performance of the proposed approach was evaluated in terms of contrast ratio (CR), contrast-to-noise ratio (CNR), and lateral resolution (LR), and compared with standard compounding method and conventional CNN methods. The results demonstrated that our method could produce high-quality images using only 3 DWs, yielding an image quality equivalent to that obtained with compounding of 31 DWs and outperforming more conventional CNN architectures in terms of complexity, inference time, and image quality.","Image reconstruction,Imaging,Convolution,Standards,Machine learning,Image quality,Acoustic beams,Convolutional neural networks (CNNs),diverging wave (DW),image reconstruction,ultrasound imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,,IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,http://arxiv.org/pdf/1911.03416,
76,Deep Learning to Obtain Simultaneous Image and Segmentation Outputs From a Single Input of Raw Ultrasound Channel Data,67,12,2493-2509,"Nair Arun Asokan,Washington Kendra N.,Tran Trac D.,Reiter Austin,Bell Muyinatu A. Lediju","Nair AA,Washington KN,Tran TD,Reiter A,Bell MAL",Bell MAL,10.1109/TUFFC.2020.2993779,Johns Hopkins University,"Single plane wave transmissions are promising for automated imaging tasks requiring high ultrasound frame rates over an extended field of view. However, a single plane wave insonification typically produces suboptimal image quality. To address this limitation, we are exploring the use of deep neural networks (DNNs) as an alternative to delay-and-sum (DAS) beamforming. The objectives of this work are to obtain information directly from raw channel data and to simultaneously generate both a segmentation map for automated ultrasound tasks and a corresponding ultrasound B-mode image for interpretable supervision of the automation. We focus on visualizing and segmenting anechoic targets surrounded by tissue and ignoring or deemphasizing less important surrounding structures. DNNs trained with Field II simulations were tested with simulated, experimental phantom, and in vivo data sets that were not included during training. With unfocused input channel data (i.e., prior to the application of receive time delays), simulated, experimental phantom, and in vivo test data sets achieved mean +/- standard deviation Dice similarity coefficients of 0.92 +/- 0.13, 0.92 +/- 0.03, and 0.77 +/- 0.07, respectively, and generalized contrast-to-noise ratios (gCNRs) of 0.95 +/- 0.08, 0.93 +/- 0.08, and 0.75 +/- 0.14, respectively. With subaperture beamformed channel data and a modification to the input layer of the DNN architecture to accept these data, the fidelity of image reconstruction increased (e.g., mean gCNR of multiple acquisitions of two in vivo breast cysts ranged 0.89-0.96), but DNN display frame rates were reduced from 395 to 287 Hz. Overall, the DNNs successfully translated feature representations learned from simulated data to phantom and in vivo data, which is promising for this novel approach to simultaneous ultrasound image formation and segmentation.","Ultrasonic imaging,Image segmentation,Training,Task analysis,Array signal processing,Machine learning,Decoding,Beamforming,deep learning,fully convolutional neural network (FCNN),image segmentation,neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,,"B-MODE,BREAST,SPECKLE",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7990652,
77,"Fine-Tuning U-Net for Ultrasound Image Segmentation: Different Layers, Different Outcomes",67,12,2510-2518,"Amiri Mina,Brooks Rupert,Rivaz Hassan","Amiri M,Brooks R,Rivaz H",Rivaz H,10.1109/TUFFC.2020.3015081,Concordia University - Canada,"One way of resolving the problem of scarce and expensive data in deep learning for medical applications is using transfer learning and fine-tuning a network which has been trained on a large data set. The common practice in transfer learning is to keep the shallow layers unchanged and to modify deeper layers according to the new data set. This approach may not work when using a U-Net and when moving from a different domain to ultrasound (US) images due to their drastically different appearance. In this study, we investigated the effect of fine-tuning different sets of layers of a pretrained U-Net for US image segmentation. Two different schemes were analyzed, based on two different definitions of shallow and deep layers. We studied simulated US images, as well as two human US data sets. We also included a chest X-ray data set. The results showed that choosing which layers to fine-tune is a critical task. In particular, they demonstrated that fine-tuning the last layers of the network, which is the common practice for classification networks, is often the worst strategy. It may therefore be more appropriate to fine-tune the shallow layers rather than deep layers in US image segmentation when using a U-Net. Shallow layers learn lower level features which are critical in automatic segmentation of medical images. Even when a large US data set is available, we observed that fine-tuning shallow layers is a faster approach compared to fine-tuning the whole network.","Image segmentation,Biomedical imaging,Breast,Head,Acoustics,Frequency control,Segmentation,transfer learning,U-Net,ultrasound (US) imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,,IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,,
78,LU-Net: A Multistage Attention Network to Improve the Robustness of Segmentation of Left Ventricular Structures in 2-D Echocardiography,67,12,2519-2530,"Leclerc Sarah,Smistad Erik,Ostvik Andreas,Cervenansky Frederic,Espinosa Florian,Espeland Torvald,Berg Erik Andreas Rye,Belhamissi Mourad,Israilov Sardor,Grenier Thomas","Leclerc S,Smistad E,Ostvik A,Cervenansky F,Espinosa F,Espeland T,Berg EAR,Belhamissi M,Israilov S,Grenier T",Leclerc S,10.1109/TUFFC.2020.3003403,Centre National de la Recherche Scientifique (CNRS),"Segmentation of cardiac structures is one of the fundamental steps to estimate volumetric indices of the heart. This step is still performed semiautomatically in clinical routine and is, thus, prone to interobserver and intraobserver variabilities. Recent studies have shown that deep learning has the potential to perform fully automatic segmentation. However, the current best solutions still suffer from a lack of robustness in terms of accuracy and number of outliers. The goal of this work is to introduce a novel network designed to improve the overall segmentation accuracy of left ventricular structures (endocardial and epicardial borders) while enhancing the estimation of the corresponding clinical indices and reducing the number of outliers. This network is based on a multistage framework where both the localization and segmentation steps are optimized jointly through an end-to-end scheme. Results obtained on a large open access data set show that our method outperforms the current best-performing deep learning solution with a lighter architecture and achieved an overall segmentation accuracy lower than the intraobserver variability for the epicardial border (i.e., on average a mean absolute error of 1.5 mm and a Hausdorff distance of 5.1mm) with 11 of outliers. Moreover, we demonstrate that our method can closely reproduce the expert analysis for the end-diastolic and end-systolic left ventricular volumes, with a mean correlation of 0.96 and a mean absolute error of 7.6 ml. Concerning the ejection fraction of the left ventricle, results are more contrasted with a mean correlation coefficient of 0.83 and an absolute mean error of 5.0, producing scores that are slightly below the intraobserver margin. Based on this observation, areas for improvement are suggested.","Image segmentation,Deep learning,Two dimensional displays,Observers,Ultrasonic imaging,Myocardium,Acoustics,Cardiac diagnosis,cardiac segmentation,deep learning,left ventricle (LV),localization,myocardium,ultrasound",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,HEART,IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,https://hal.archives-ouvertes.fr/hal-03149347/file/tuffc_2020_sarah.pdf,
79,A Single-Shot Region-Adaptive Network for Myotendinous Junction Segmentation in Muscular Ultrasound Images,67,12,2531-2542,"Zhou Guang-Quan,Huo En-Ze,Yuan Mei,Zhou Ping,Wang Ruo-Li,Wang Kai-Ni,Chen Yang,He Xiao-Pu","Zhou GQ,Huo EZ,Yuan M,Zhou P,Wang RL,Wang KN,Chen Y,He XP",Zhou GQ,10.1109/TUFFC.2020.2979481,Southeast University - China,"Tracking the myotendinous junction (MTJ) in consecutive ultrasound images is crucial for understanding the mechanics and pathological conditions of the muscletendon unit. However, the lack of reliable and efficient identification of MTJ due to poor image quality and boundary ambiguity restricts its application in motion analysis. In recent years, with the rapid development of deep learning, the region-based convolution neural network (RCNN) has shown great potential in the field of simultaneous objection detection and instance segmentation in medical images. This article proposes a region-adaptive network (RAN) to localize MTJ region and to segment it in a single shot. Our model learns about the salient information of MTJ with the help of a composite architecture. Herein, a region-based multitask learning network explores the region containing MTJ, while a parallel end-to-end U-shaped path extracts the MTJ structure from the adaptively selected region for combating data imbalance and boundary ambiguity. By demonstrating the ultrasound images of the gastrocnemius, we showed that the RAN achieves superior segmentation performance when compared with the state-of-the-art Mask RCNN method with an average Dice score of 80.1. Our proposed method is robust and reliable for advanced muscle and tendon function examinations obtained by ultrasound imaging.","Ultrasonic imaging,Image segmentation,Biomedical imaging,Muscles,Tendons,Feature extraction,Junctions,Adaptive region,deep learning,instance segmentation,myotendinous junction (MTJ),ultrasound",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,"GASTROCNEMIUS-MUSCLE,ACHILLES-TENDON,FASCICLE,LENGTH",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,,
80,Deep Learning for US Image Quality Assessment Based on Femoral Cartilage Boundary Detection in Autonomous Knee Arthroscopy,67,12,2543-2552,"Antico Maria,Vukovic Damjan,Camps Saskia M.,Sasazawa Fumio,Takeda Yu,Le Anh T. H.,Jaiprakash Anjali T.,Roberts Jonathan,Crawford Ross,Fontanarosa Davide","Antico M,Vukovic D,Camps SM,Sasazawa F,Takeda Y,Le ATH,Jaiprakash AT,Roberts J,Crawford R,Fontanarosa D",Fontanarosa D,10.1109/TUFFC.2020.2965291,Queensland University of Technology (QUT),"Knee arthroscopy is a complex minimally invasive surgery that can cause unintended injuries to femoral cartilage or postoperative complications, or both. Autonomous robotic systems using real-time volumetric ultrasound (US) imaging guidance hold potential for reducing significantly these issues and for improving patient outcomes. To enable the robotic system to navigate autonomously in the knee joint, the imaging system should provide the robot with a real-time comprehensive map of the surgical site. To this end, the first step is automatic image quality assessment, to ensure that the boundaries of the relevant knee structures are defined well enough to be detected, outlined, and then tracked. In this article, a recently developed one-class classifier deep learning algorithm was used to discriminate among the US images acquired in a simulated surgical scenario on which the femoral cartilage either could or could not be outlined. A total of 38 656 2-D US images were extracted from 151 3-D US volumes, collected from six volunteers, and were labeled as 1 or as 0 when an expert was or was not able to outline the cartilage on the image, respectively. The algorithm was evaluated using the expert labels as ground truth with a fivefold cross validation, where each fold was trained and tested on average with 15 640 and 6246 labeled images, respectively. The algorithm reached a mean accuracy of 78.4 5.0, mean specificity of 72.5 9.4, mean sensitivity of 82.8 5.8, and mean area under the curve of 85 4.4. In addition, interobserver and intraobserver tests involving two experts were performed on an image subset of 1536 2-D US images. Percent agreement values of 0.89 and 0.93 were achieved between two experts (i.e., interobserver) and by each expert (i.e., intraobserver), respectively. These results show the feasibility of the first essential step in the development of automatic US image acquisition and interpretation systems for autonomous robotic knee arthroscopy.","Surgery,Two dimensional displays,Imaging,Probes,Knee,Legged locomotion,Cartilage detection,deep learning (DL),knee arthroscopy,quality assessment,ultrasound (US) imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,"RELIABILITY,AGREEMENT,INJURIES",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,https://eprints.qut.edu.au/136491/2/Final_manuscript.pdf,
81,A Pilot Study on Convolutional Neural Networks for Motion Estimation From Ultrasound Images,67,12,2565-2573,"Evain Ewan,Faraz Khuram,Grenier Thomas,Garcia Damien,De Craene Mathieu,Bernard Olivier","Evain E,Faraz K,Grenier T,Garcia D,De Craene M,Bernard O",Evain E,10.1109/TUFFC.2020.2976809,Centre National de la Recherche Scientifique (CNRS),"In recent years, deep learning (DL) has been successfully applied to the analysis and processing of ultrasound images. To date, most of this research has focused on segmentation and view recognition. This article benchmarks different convolutional neural network algorithms for motion estimation in ultrasound imaging. We evaluated and compared several networks derived from FlowNet2, one of the most efficient architectures in computer vision. The networks were tested with and without transfer learning, and the best configuration was compared against the particle imaging velocimetry method, a popular state-of-the-art block-matching algorithm. Rotations are known to be difficult to track from ultrasound images due to a significant speckle decorrelation. We thus focused on the images of rotating disks, which could be tracked through speckle features only. Our database consisted of synthetic and in vitro B-mode images after log compression and covered a large range of rotational speeds. One of the FlowNet2 subnetworks, FlowNet2SD, produced competitive results with a motion field error smaller than 1 pixel on real data after transfer learning based on the simulated data. These errors remain small for a large velocity range without the need for hyperparameter tuning, which indicates the high potential and adaptability of DL solutions to motion estimation in ultrasound imaging.","Ultrasonic imaging,Machine learning,Imaging,Motion estimation,Speckle,Image reconstruction,Angular velocity,Deep learning (DL),motion estimation,ultrasound",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,,IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,https://hal.archives-ouvertes.fr/hal-03027193/document,
82,CohereNet: A Deep Learning Architecture for Ultrasound Spatial Correlation Estimation and Coherence-Based Beamforming,67,12,2574-2583,"Wiacek Alycen,Gonzalez Eduardo,Bell Muyinatu A. Lediju","Wiacek A,Gonzalez E,Bell MAL",Wiacek A,10.1109/TUFFC.2020.2982848,Johns Hopkins University,"Deep fully connected networks are often considered ""universal approximators"" that are capable of learning any function. In this article, we utilize this particular property of deep neural networks (DNNs) to estimate normalized cross correlation as a function of spatial lag (i.e., spatial coherence functions) for applications in coherence-based beamforming, specifically short-lag spatial coherence (SLSC) beamforming. We detail the composition, assess the performance, and evaluate the computational efficiency of CohereNet, our custom fully connected DNN, which was trained to estimate the spatial coherence functions of in vivo breast data from 18 unique patients. CohereNet performance was evaluated on in vivo breast data from three additional patients who were not included during training, as well as data from in vivo liver and tissue mimicking phantoms scanned with a variety of ultrasound transducer array geometries and two different ultrasound systems. The mean correlation between the SLSC images computed on a central processing unit (CPU) and the corresponding DNN SLSC images created with CohereNet was 0.93 across the entire test set. The DNN SLSC approach was up to 3.4 times faster than the CPU SLSC approach, with similar computational speed, less variability in computational times, and improved image quality compared with a graphical processing unit (GPU)-based SLSC approach. These results are promising for the application of deep learning to estimate correlation functions derived from ultrasound data in multiple areas of ultrasound imaging and beamforming (e.g., speckle tracking, elastography, and blood flow estimation), possibly replacing GPU-based approaches in low-power, remote, and synchronization-dependent applications.","Coherence-based beamforming,deep learning,spatial correlation,ultrasound",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,"IN-VIVO,APPLICATION",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8034551,
83,Training Variational Networks With Multidomain Simulations: Speed-of-Sound Image Reconstruction,67,12,2584-2594,"Bernhardt Melanie,Vishnevskiy Valery,Rau Richard,Goksel Orcun","Bernhardt M,Vishnevskiy V,Rau R,Goksel O",Goksel O,10.1109/TUFFC.2020.3010186,ETH Zurich,"Speed-of-sound (SoS) has been shown as a potential biomarker for breast cancer imaging, successfully differentiating malignant tumors from benign ones. SoS images can be reconstructed from time-of-flight measurements from ultrasound images acquired using conventional handheld ultrasound transducers. Variational networks (VNs) have recently been shown to be a potential learning-based approach for optimizing inverse problems in image reconstruction. Despite earlier promising results, these methods, however, do not generalize well from simulated to acquired data, due to the domain shift. In this work, we present for the first time a VN solution for a pulse-echo SoS image reconstruction problem using diverging waves with conventional transducers and single-sided tissue access. This is made possible by incorporating simulations with varying complexity into training. We use loop unrolling of gradient descent with momentum, with an exponentially weighted loss of outputs at each unrolled iteration in order to regularize the training. We learn norms as activation functions regularized to have smooth forms for robustness to input distribution variations. We evaluate reconstruction quality on the ray-based and full-wave simulations as well as on the tissue-mimicking phantom data, in comparison with a classical iterative [limited-memory BroydenFletcherGoldfarbShanno (L-BFGS)] optimization of this image reconstruction problem. We show that the proposed regularization techniques combined with multisource domain training yield substantial improvements in the domain adaptation capabilities of VN, reducing the median root mean squared error (RMSE) by 54 on a wave-based simulation data set compared to the baseline VN. We also show that on data acquired from a tissue-mimicking breast phantom, the proposed VN provides improved reconstruction in 12 ms.","Image reconstruction,Training,Adaptation models,Optimization,Imaging,Transducers,Robustness,Image reconstruction,neural networks,ultrasonography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,"COMPUTED,ULTRASOUND,TOMOGRAPHY,DOMAIN,ADAPTATION,ECHO-MODE",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,http://arxiv.org/pdf/2006.14395,
84,Real-Time Automatic Ejection Fraction and Foreshortening Detection Using Deep Learning,67,12,2595-2604,"Smistad Erik,Ostvik Andreas,Salte Ivar Mjaland,Melichova Daniela,Nguyen Thuy Mi,Haugaa Kristina,Brunvand Harald,Edvardsen Thor,Leclerc Sarah,Bernard Olivier","Smistad E,Ostvik A,Salte IM,Melichova D,Nguyen TM,Haugaa K,Brunvand H,Edvardsen T,Leclerc S,Bernard O",Smistad E,10.1109/TUFFC.2020.2981037,Norwegian University of Science & Technology (NTNU),"Volume and ejection fraction (EF) measurements of the left ventricle (LV) in 2-D echocardiography are associated with a high uncertainty not only due to interobserver variability of the manual measurement, but also due to ultrasound acquisition errors such as apical foreshortening. In this work, a real-time and fully automated EF measurement and foreshortening detection method is proposed. The method uses several deep learning components, such as view classification, cardiac cycle timing, segmentation and landmark extraction, to measure the amount of foreshortening, LV volume, and EF. A data set of 500 patients from an outpatient clinic was used to train the deep neural networks, while a separate data set of 100 patients from another clinic was used for evaluation, where LV volume and EF were measured by an expert using clinical protocols and software. A quantitative analysis using 3-D ultrasound showed that EF is considerably affected by apical foreshortening, and that the proposed method can detect and quantify the amount of apical foreshortening. The bias and standard deviation of the automatic EF measurements were 3.6 8.1, while the mean absolute difference was measured at 7.2 which are all within the interobserver variability and comparable with related studies. The proposed real-time pipeline allows for a continuous acquisition and measurement workflow without user interaction, and has the potential to significantly reduce the time spent on the analysis and measurement error due to foreshortening, while providing quantitative volume measurements in the everyday echo lab.","Volume measurement,Ultrasonic variables measurement,Real-time systems,Ultrasonic imaging,Deep learning,Two dimensional displays,Imaging,Deep learning,echocardiography,ejection fraction (EF),foreshortening",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,"ECHOCARDIOGRAPHY,SEGMENTATION",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,https://ntnuopen.ntnu.no/ntnu-xmlui/bitstream/11250/2730523/1/09037081.pdf,
85,Estimation of End-Diastole in Cardiac Spectral Doppler Using Deep Learning,67,12,2605-2614,"Jahren Tollef Struksnes,Steen Erik N.,Aase Svein Arne,Solberg Anne H. Schistad","Jahren TS,Steen EN,Aase SA,Solberg AHS",Jahren TS,10.1109/TUFFC.2020.2995118,University of Oslo,"Electrocardiogram (ECG) is often used together with a spectral Doppler ultrasound to separate heart cycles by determining the end-diastole locations. However, the ECG signal is not always recorded. In such cases, the cardiac cycles can be estimated manually from the ultrasound data retrospectively. We present a deep learning-based method for automatic detection of the end-diastoles in spectral Doppler spectrograms. The method uses a combination of a convolutional neural network (CNN) for extracting features and a recurrent neural network (RNN) for modeling temporal relations. In echocardiography, there are three Doppler spectrogram modalities, continuous wave, pulsed wave, and tissue velocity Doppler. Both the training and test data sets include all three modalities. The model was tested on 643 spectrograms coming from different hospitals than in the training data set. For the purposes described in this work, a valid end-diastole detection is defined as a prediction being closer than 60 ms to the reference value. We will refer to these as true detections. Similarly, a prediction farther away is defined as nonvalid or false detections. The method automatically rejects spectrograms where the detection of an end-diastole has low confidence. When setting the algorithm to reject 1.9, the method achieved 97.7 true detections with a mean error of 14 ms and had 2.5 false detections on the remaining spectrograms.","Doppler effect,Spectrogram,Heart,Ultrasonic imaging,Electrocardiography,Machine learning,Valves,Deep learning,echocardiography,end-diastole,spectral Doppler",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,,"AUTOMATIC,DETECTION",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,,
86,A Deep Learning Approach to Resolve Aliasing Artifacts in Ultrasound Color Flow Imaging,67,12,2615-2628,"Nahas Hassan,Au Jason S.,Ishii Takuro,Yiu Billy Y. S.,Chee Adrian J. Y.,Yu Alfred C. H.","Nahas H,Au JS,Ishii T,Yiu BYS,Chee AJY,Yu ACH",Yu ACH,10.1109/TUFFC.2020.3001523,University of Waterloo,"Despite being used clinically as a noninvasive flow visualization tool, color flow imaging (CFI) is known to be prone to aliasing artifacts that arise due to fast blood flow beyond the detectable limit. From a visualization standpoint, these aliasing artifacts obscure proper interpretation of flow patterns in the image view. Current solutions for resolving aliasing artifacts are typically not robust against issues such as double aliasing. In this article, we present a new dealiasing technique based on deep learning principles to resolve CFI aliasing artifacts that arise from single- and double-aliasing scenarios. It works by first using two convolutional neural networks (CNNs) to identify and segment CFI pixel positions with aliasing artifacts, and then it performs phase unwrapping at these aliased pixel positions. The CNN for aliasing identification was devised as a U-net architecture, and it was trained with in vivo CFI frames acquired from the femoral bifurcation that had known presence of single- and double-aliasing artifacts. Results show that the segmentation of aliased CFI pixels was achieved successfully with intersection over union approaching 90%. After resolving these artifacts, the dealiased CFI frames consistently rendered the femoral bifurcation's triphasic flow dynamics over a cardiac cycle. For dealiased CFI pixels, their root-mean-squared difference was 2.51% or less compared with manual dealiasing. Overall, the proposed dealiasing framework can extend the maximum flow detection limit by fivefold, thereby improving CFI's flow visualization performance.","Doppler effect,Speckle,Training,Image color analysis,Bandwidth,Image segmentation,Ultrasonic imaging,Aliasing,color flow imaging (CFI),deep learning,Doppler ultrasound,U-net",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,"BLOOD-FLOW,SPECKLE,TRACKING,VECTOR,VISUALIZATION",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,https://ieeexplore.ieee.org/ielx7/58/9269287/09113743.pdf,
87,Displacement Estimation in Ultrasound Elastography Using Pyramidal Convolutional Neural Network,67,12,2629-2639,"Tehrani Ali K. Z.,Rivaz Hassan","Tehrani AKZ,Rivaz H",Rivaz H,10.1109/TUFFC.2020.2973047,Concordia University - Canada,"In this article, two novel deep learning methods are proposed for displacement estimation in ultrasound elastography (USE). Although convolutional neural networks (CNNs) have been very successful for displacement estimation in computer vision, they have been rarely used for USE. One of the main limitations is that the radio frequency (RF) ultrasound data, which is crucial for precise displacement estimation, has vastly different frequency characteristics compared with images in computer vision. Top-rank CNN methods used in computer vision applications are mostly based on a multilevel strategy, which estimates finer resolution based on coarser ones. This strategy does not work well for RF data due to its large high-frequency content. To mitigate the problem, we propose modified pyramid warping and cost volume network (MPWC-Net) and RFMPWC-Net, both based on PWC-Net, to exploit information in RF data by employing two different strategies. We obtained promising results using networks trained only on computer vision images. In the next step, we constructed a large ultrasound simulation database and proposed a new loss function to fine-tune the network to improve its performance. The proposed networks and well-known optical flow networks as well as state-of-the-art elastography methods are evaluated using simulation, phantom, and in vivo data. Our two proposed networks substantially outperform current deep learning methods in terms of contrast-to-noise ratio (CNR) and strain ratio (SR). Also, the proposed methods perform similar to the state-of-the-art elastography methods in terms of CNR and have better SR by substantially reducing the underestimation bias.","Optical imaging,Estimation,Feature extraction,Optical variables control,Ultrasonic imaging,Optical fiber networks,Elastography,Convolutional neural network (CNN),displacement estimation,optical flow,PWC-Net,ultrasound elastography (USE)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,"TIME-DELAY,ESTIMATION,STRAIN,ALGORITHM,FIELDS",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,,
88,Synthetic Elastography Using B-Mode Ultrasound Through a Deep Fully Convolutional Neural Network,67,12,2640-2648,"Wildeboer R. R.,van Sloun R. J. G.,Mannaerts C. K.,Moraes P. H.,Salomon G.,Chammas M. C.,Wijkstra H.,Mischi M.","Wildeboer RR,van Sloun RJG,Mannaerts CK,Moraes PH,Salomon G,Chammas MC,Wijkstra H,Mischi M",Wildeboer RR,10.1109/TUFFC.2020.2983099,Eindhoven University of Technology,"Shear-wave elastography (SWE) permits local estimation of tissue elasticity, an important imaging marker in biomedicine. This recently developed, advanced technique assesses the speed of a laterally traveling shear wave after an acoustic radiation force push to estimate local Youngs moduli in an operator-independent fashion. In this work, we show how synthetic SWE (sSWE) images can be generated based on conventional B-mode imaging through deep learning. Using side-by-side-view B-mode/SWE images collected in 50 patients with prostate cancer, we show that sSWE images with a pixel-wise mean absolute error of 4.5 0.96 kPa with regard to the original SWE can be generated. Visualization of high-level feature levels through ${t}$ -distributed stochastic neighbor embedding reveals substantial overlap between data from two different scanners. Qualitatively, we examined the use of the sSWE methodology for B-mode images obtained with a scanner without SWE functionality. We also examined the use of this type of network in elasticity imaging in the thyroid. Limitations of the technique reside in the fact that networks have to be retrained for different organs, and that the method requires standardization of the imaging settings and procedure. Future research will be aimed at the development of sSWE as an elasticity-related tissue typing strategy that is solely based on B-mode ultrasound acquisition, and the examination of its clinical utility.","Ultrasonic imaging,Elasticity,Acoustics,Elastography,Training,Frequency control,B-mode ultrasound,convolutional neural networks,deep learning,shear-wave elastography (SWE)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,,"SHEAR-WAVE,ELASTOGRAPHY,BENIGN,IMAGE",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,http://arxiv.org/pdf/1908.03573,
89,Deep Neural Network-Based Sinogram Super-Resolution and Bandwidth Enhancement for Limited-Data Photoacoustic Tomography,67,12,2660-2673,"Awasthi Navchetan,Jain Gaurav,Kalva Sandeep Kumar,Pramanik Manojit,Yalavarthy Phaneendra K.","Awasthi N,Jain G,Kalva SK,Pramanik M,Yalavarthy PK",Yalavarthy PK,10.1109/TUFFC.2020.2977210,Indian Institute of Science (IISC) - Bangalore,"Photoacoustic tomography (PAT) is a noninvasive imaging modality combining the benefits of optical contrast at ultrasonic resolution. Analytical reconstruction algorithms for photoacoustic (PA) signals require a large number of data points for accurate image reconstruction. However, in practical scenarios, data are collected using the limited number of transducers along with data being often corrupted with noise resulting in only qualitative images. Furthermore, the collected boundary data are band-limited due to limited bandwidth (BW) of the transducer, making the PA imaging with limited data being qualitative. In this work, a deep neural network-based model with loss function being scaled root-mean-squared error was proposed for super-resolution, denoising, as well as BW enhancement of the PA signals collected at the boundary of the domain. The proposed network has been compared with traditional as well as other popular deep-learning methods in numerical as well as experimental cases and is shown to improve the collected boundary data, in turn, providing superior quality reconstructed PA image. The improvement obtained in the Pearson correlation, structural similarity index metric, and root-mean-square error was as high as 35.62%, 33.81%, and 41.07%, respectively, for phantom cases and signal-to-noise ratio improvement in the reconstructed PA images was as high as 11.65 dB for in vivo cases compared with reconstructed image obtained using original limited BW data. Code is available at https://sites.google.com/site/sercmig/home/dnnpat.","Image reconstruction,Image resolution,Transducers,Acoustics,Bandwidth,Imaging,Neural networks,Bandwidth (BW) enhancement,convolutional neural networks,image reconstruction,photoacoustic (PA) imaging,super-resolution",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,"IMAGE-RECONSTRUCTION,DECONVOLUTION,SEGMENTATION,RESOLUTION",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,,
90,Supervised machine learning for the early prediction of acute respiratory distress syndrome (ARDS),60,,96-102,"Le Sidney,Pellegrini Emily,Green-Saxena Abigail,Summers Charlotte,Hoffman Jana,Calvert Jacob,Das Ritankar","Le S,Pellegrini E,Green-Saxena A,Summers C,Hoffman J,Calvert J,Das R",Green-Saxena A,10.1016/j.jcrc.2020.07.019,"Dascena Inc, POB 156572, San Francisco, CA 94115 USA.","Purpose: Acute respiratory distress syndrome (ARDS) is a serious respiratory condition with high mortality and associated morbidity. The objective of this study is to develop and evaluate a novel application of gradient boosted tree models trained on patient health record data for the early prediction of ARDS.
Materials and methods: 9919 patient encounters were retrospectively analyzed from the Medical Information Mart for Intensive Care III (MIMIC-III) data base. XGBoost gradient boosted tree models for early ARDS prediction were created using routinely collected clinical variables and numerical representations of radiology reports as inputs. XGBoost models were iteratively trained and validated using 10-fold cross validation.
Results: On a hold-out test set, algorithm classifiers attained area under the receiver operating characteristic curve (AUROC) values of 0.905 when tested for the detection of ARDS at onset and 0.827, 0.810, and 0.790 for the prediction of ARDS at 12-, 24-, and 48-h windows prior to onset, respectively.
Conclusion: Supervised machine learning predictions may help predict patients with ARDS up to 48 h prior to onset. (C) 2020 The Authors. Published by Elsevier Inc.","Acute respiratory distress syndrome,Intensive care unit,Machine learning,Clinical decision support systems,Electronic health records,Medical informatics",Article,"W B SAUNDERS CO-ELSEVIER INC, 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA",General & Internal Medicine,,,"ACUTE,LUNG,INJURY,INTENSIVE-CARE,UNITS,EARLY,IDENTIFICATION,CLINICAL,PREDICTORS,MORTALITY,OUTCOMES,SCORE,RISK,EPIDEMIOLOGY,DEFINITIONS",JOURNAL OF CRITICAL CARE,https://doi.org/10.1101/2020.03.19.20038364,
91,Machine Learning Assisted Nanoparticle-Based Chemiresistor Array for Explosive Detection,20,23,14016-14023,"Gao Tuo,Zhang Chengwu,Wang Yongchen,Diaz Julian A.,Zhao Jing,Willis Brian G.","Gao T,Zhang CW,Wang YC,Diaz JA,Zhao J,Willis BG",Willis BG,10.1109/JSEN.2020.3007493,University of Connecticut,"In this work, we report the detection and discrimination of five commercially available NESTT K-9 explosive compounds, including 2,4,6-trinitrotoluene (TNT), cyclotrimethylenetrinitramine (RDX), pentaerythritol tetranitrate (PETN), potassium nitrate, and potassium chlorate. An array of 48 chemiresistors were fabricated and assembled with four types of gold nanoparticle sensing materials. The functional groups include tetradecylamine (TDA), octadecylamine (ODA), 3-mercaptopropionic acid (MPA), and 4-aminothiophenol (ATP). Machine learning methods were applied to analyze sensor data. The discrimination accuracy of the sensor array was studied over time at various vapor concentrations (p/p(0)), using several classifiers, including linear discriminant analysis (LDA), support vector machine (SVM), k-nearest neighbors (KNN), and bagged trees (BT), with five-fold cross-validation. More than 90% accuracy was achieved using datasets with more than 2500 sensor measurements. Sensor arrays and classification algorithms exhibit good stability over a range of vapor concentrations. The results demonstrate the utility of machine learning for detection and classification of volatiles, including explosive and related compounds.","Nanoparticles,sensor array,chemiresistor,machine learning,explosive compounds,discriminant analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"CARBON,NANOTUBES,ELECTRONIC,NOSE,CLASSIFICATION,SENSORS,GAS,DISCRIMINATION,DIAGNOSIS,CANINES,MIMICS,DOGS",IEEE SENSORS JOURNAL,,
92,Classification method of peripheral arterial disease in patients with type 2 diabetes mellitus by infrared thermography and machine learning,111,,,"Carlos Padierna Luis,Fabian Amador-Medina Lauro,Olivia Murillo-Ortiz Blanca,Villasenor-Mora Carlos","Padierna LC,Amador-Medina LF,Murillo-Ortiz BO,Villasenor-Mora C",Villasenor-Mora C,10.1016/j.infrared.2020.103531,Universidad de Guanajuato,"Peripheral Arterial Disease (PAD) identification is a complex task as a set of different factors cause this disease such as: smoking, diabetes mellitus, old age, hypertension, renal insufficiency, among others. Recently, noninvasive methods based on Infrared Thermography (IRT) are effective for the detection of type-2 diabetes and diabetic foot ulcers from plantar thermograms. However, we have not found studies on the characterization of PAD from the top of the foot. In this work, it is presented a non-invasive methodology for this characterization. We are proposing the analysis of relevant features extracted from IRT images of the upper side of the foot and toes. With these features, we built a Support Vector Classification model that encompasses the data from two groups of Mexican participants one includes twenty-three diabetic patients and the control group has twenty non diabetic. The average performance of the classification model was estimated under a rigorous bootstrapping method on 1000 randomized and independent runs of 5-fold cross-validations and reached 92.64% of accuracy, 91.80% of sensitivity, and specificity of 93.59%. The experimental data and the source code of the proposed methodology are publicly available; it allows an easy implementation as a supporting tool for physicians in the identification of PAD.","Machine learning,Support vector machines,Peripheral arterial disease,Thermography",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Instruments & Instrumentation,Optics,Physics",,2.581,,INFRARED PHYSICS & TECHNOLOGY,,
93,Electroencephalography-Derived Prognosis of Functional Recovery in Acute Stroke Through Machine Learning Approaches,30,12,,"Chiarelli Antonio Maria,Croce Pierpaolo,Assenza Giovanni,Merla Arcangelo,Granata Giuseppe,Giannantoni Nadia Mariagrazia,Pizzella Vittorio,Tecchio Franca,Zappasodi Filippo","Chiarelli AM,Croce P,Assenza G,Merla A,Granata G,Giannantoni NM,Pizzella V,Tecchio F,Zappasodi F",Zappasodi F,10.1142/S0129065720500677,G d'Annunzio University of Chieti-Pescara,"Stroke, if not lethal, is a primary cause of disability. Early assessment of markers of recovery can allow personalized interventions; however, it is difficult to deliver indexes in the acute phase able to predict recovery. In this perspective, evaluation of electrical brain activity may provide useful information. A machine learning approach was explored here to predict post-stroke recovery relying on multi-channel electroencephalographic (EEG) recordings of few minutes performed at rest. A data-driven model, based on partial least square (PLS) regression, was trained on 19-channel EEG recordings performed within 10 days after mono-hemispheric stroke in 101 patients. The band-wise (delta: 1-4Hz, theta: 4-7Hz, alpha: 8-14Hz and beta: 15-30Hz) EEG effective powers were used as features to predict the recovery at 6 months (based on clinical status evaluated through the NIH Stroke Scale, NIHSS) in an optimized and cross-validated framework. In order to exploit the multimodal contribution to prognosis, the EEG-based prediction of recovery was combined with NIHSS scores in the acute phase and both were fed to a nonlinear support vector regressor (SVR). The prediction performance of EEG was at least as good as that of the acute clinical status scores. A posteriori evaluation of the features exploited by the analysis highlighted a lower delta and higher alpha activity in patients showing a positive outcome, independently of the affected hemisphere. The multimodal approach showed better prediction capabilities compared to the acute NIHSS scores alone (r = 0.53 versus r = 0.41, AUC = 0.80 versus AUC = 0.70, p < 0.05). The multimodal and multivariate model can be used in acute phase to infer recovery relying on standard EEG recordings of few minutes performed at rest together with clinical assessment, to be exploited for early and personalized therapies. The easiness of performing EEG may allow such an approach to become a standard-of-care and, thanks to the increasing number of labeled samples, further improving the model predictive power.","Stroke,electroencephalography (EEG),recovery prognosis,data-driven models,machine learning",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Computer Science,,5.439,"MONO-HEMISPHERIC,STROKE,SPECTRAL,EEG-ANALYSIS,ACUTE,ISCHEMIC-STROKE,QUANTITATIVE,EEG,BRAIN,PLASTICITY,DISCONNECTION,PERFORMANCE,PREDICTION,SIGNALS,UTILITY",INTERNATIONAL JOURNAL OF NEURAL SYSTEMS,,
94,An empirical study of players' emotions in VR racing games based on a dataset of physiological data,79,45-46,33657-33686,"Granato Marco,Gadia Davide,Maggiorini Dario,Ripamonti Laura A.","Granato M,Gadia D,Maggiorini D,Ripamonti LA",Granato M,10.1007/s11042-019-08585-y,University of Milan,"A video game is an interactive software able to arouse intense emotions in players. Consequentially, different theories have been proposed to understand which game aspects are able to affect the players' emotional state. However, only few works have tried to use empirical evidence to investigate the effects of different game aspects of the players' emotions. In this paper, we present the results of a set of experiments aimed at predicting the players' emotions during video games sessions using their physiological data. We have created a physiological dataset from the data acquired by 33 participants during video game fruition using a standard monitor and a Virtual Reality headset. The dataset contains information about electrocardiogram, 5 facials electromyographies, electrodermal activity, and respiration. Furthermore, we have asked the players to self-assess their emotional state on the Arousal and Valence space. We have then analyzed the contribution of each physiological signal to the overall definition of the players' mental state. Finally, we have applied Machine Learning techniques to predict the emotional state of players during game sessions at a precision of one second. The obtained results can contribute to define game devices and engines able to detect physiological data, as well to improve the game design process.","Affective computing,Video games,Emotions recognition,ECG,EMG,GSR,EDA,Respiration,Physiological dataset,Valence,Arousal,Machine learning,Virtual reality,Players' emotions",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,DESIGN,MULTIMEDIA TOOLS AND APPLICATIONS,,
95,KDSAE: Chronic kidney disease classification with multimedia data learning using deep stacked autoencoder network,79,47-48,35425-35440,"Khamparia Aditya,Saini Gurinder,Pandey Babita,Tiwari Shrasti,Gupta Deepak,Khanna Ashish","Khamparia A,Saini G,Pandey B,Tiwari S,Gupta D,Khanna A",Gupta D,10.1007/s11042-019-07839-z,Maharaja Agrasen Institute of Technology,"In recent times, Chronic Kidney Disease (CKD) has affected more than 10% of the population worldwide and millions of people die every year. So, early-stage detection of CKD could be beneficial for increasing the life expectancy of suffering patients and reducing the treatment cost. It is required to build such a multimedia driven model which can help to diagnose the disease efficiently with higher accuracy before leading to worse conditions. Various techniques related to conventional machine learning models have been used by researchers in the past time without involvement of multimodal data-driven learning. This research paper offers a novel deep learning framework for chronic kidney disease classification using stacked autoencoder model utilizing multimedia data with a softmax classifier. The stacked autoencoder helps to extract the useful features from the dataset and then a softmax classifier is used to predict the final class. It has experimented on UCI dataset which contains early stages of 400 CKD patients with 25 attributes, which is a binary classification problem. Precision, recall, specificity and F1-score were used as evaluation metrics for the assessment of the proposed network. It was observed that this multimodal model outperformed the other conventional classifiers used for chronic kidney disease with a classification accuracy of 100%.","Chronic kidney disease (CKD),Classification,Deep learning (DL),Multimedia,Artificial intelligence (AI),Stacked autoencoder (SAE),Softmax classifier",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,,MULTIMEDIA TOOLS AND APPLICATIONS,,
96,A Non-destructive Ultrasonic Testing Approach for Measurement and Modelling of Tensile Strength in Rubbers,33,12,2549-2555,"Foorginejad A.,Taheri M.,Mollayi N.","Foorginejad A,Taheri M,Mollayi N",Taheri M,10.5829/ije.2020.33.12c.16,Tarbiat Modares University,"Currently, non-destructive testing is widely used to investigate various mechanical and structural properties of materials. In the present study, non-destructive ultrasonic testing was applied to study the relationship between the tensile strength value and the velocity of longitudinal ultrasonic waves. For this purpose, fourteen specimens of composites with different formulations were prepared. The tensile strength of the composites and the velocity of longitudinal ultrasonic waves inside them was measured. The relevance vector machine regression analysis, as a new methodology in supervised machine learning, was used to define a mathematical expression for the functional relationship between the tensile strength and the velocity of longitudinal ultrasonic waves. The accuracy of the mathematical expression was tested based on standard statistical indices, which proved the expression to be an efficient model. Based on these results, the developed model has the capability of being used for the online measurement of the tensile strength of rubber with the proposed formulation in the rubber industry.","Longitudinal Ultrasonic Waves' Velocity,Relevance Vector Machine,Rubber,Tensile Strength",Article,"MATERIALS & ENERGY RESEARCH CENTER-MERC, 16, AHURAMAZDA ST, ALVAND AVE, TEHRAN, 15169, IRAN",Engineering,,,"MECHANICAL-PROPERTIES,PULSE,VELOCITY,MACHINE",INTERNATIONAL JOURNAL OF ENGINEERING,http://www.ije.ir/article_120152_0f99a20fcacaf01c6a787105ae6ac490.pdf,
97,Machine learning-based glass formation prediction in multicomponent alloys,201,,182-190,"Liu Xiaodi,Li Xin,He Quanfeng,Liang Dandan,Zhou Ziqing,Ma Jiang,Yang Yong,Shen Jun","Liu XD,Li X,He QF,Liang DD,Zhou ZQ,Ma J,Yang Y,Shen J",Shen J,10.1016/j.actamat.2020.09.081,Shenzhen University,"Metallic glasses (MGs) have attracted considerable academic attention owing to their unique properties and great application prospects. Unlike other glassy materials, such as oxide glasses, MGs have limited glass forming-ability (GFA) that often leads to failure during new MG development. Although intensive studies have proposed various parameters and criteria enabling the evaluation of the GFA of MG samples, achieving accurate predictions of glass formation before the actual MG sample synthesis remains a great challenge and an open topic. In this study, we investigated the glass formation through the data-driven machine learning technique and trained a backpropagation neural network model based on a dataset assembled from thousands of ternary alloys. Applying the well-trained model, we accurately identified the MG and non-MG classes. More importantly, our model can effectively predict glass-formation likelihood of multicomponent alloys and locate the probable MG compositions without any prior experiment, thereby directing the MG design. From the model's predictions, we discovered several new MGs in the ribbon form. Glass-formation likelihood reveals the correlation with the thermodynamic and topological parameters, which provides insights into the GFA of MGs. (C) 2020 Acta Materialia Inc. Published by Elsevier Ltd. All rights reserved.","Metallic glasses,Glass-forming ability,Machine learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Materials Science,Metallurgy & Metallurgical Engineering",,9.277,"HIGH-ENTROPY,ALLOYS,BULK,METALLIC,GLASSES,FORMING,ABILITY,SUPERCOOLED,LIQUID,ELASTIC,PROPERTIES,THERMAL-STABILITY,STRUCTURAL,MODEL,PHASE-STABILITY,TRANSITION,CRITERION",ACTA MATERIALIA,,
98,Unveiling the structural origin to control resistance drift in phase-change memory materials,41,,156-176,"Zhang Wei,Ma Evan","Zhang W,Ma E",Zhang W,10.1016/j.mattod.2020.07.016,Xi'an Jiaotong University,"The global demand for data storage and processing is increasing exponentially. To deal with this challenge, massive efforts have been devoted to the development of advanced memory and computing technologies. Chalcogenide phase-change materials (PCMs) are currently at the forefront of this endeavor. In this Review, we focus on the mechanisms of the spontaneous structural relaxation - aging - of amorphous PCMs, which causes the well-known resistance drift issue that significantly reduces the device accuracy needed for phase-change memory and computing applications. We review the recent breakthroughs in uncovering the structural origin, achieved through state-of-the-art experiments and ab initio atomistic simulations. Emphasis will be placed on the evolving atomic-level details during the relaxation of the complex amorphous structure. We also highlight emerging strategies to control aging, inspired by the in-depth structural understanding, from both materials science and device engineering standpoints, that offer effective solutions to reduce the resistance drift. In addition, we discuss an important new paradigm - machine learning - and the potential power it brings in interrogating amorphous PCMs as well as other disordered alloy systems. Finally, we present an outlook to comment on future research opportunities in amorphous PCMs, as well as on their reduced aging tendency in other advanced applications such as non-volatile photonics.","GLASS-TRANSITION TEMPERATURES,DENSITY-FUNCTIONAL THEORY,RANDOM-ACCESS MEMORY,SB-TE,THIN-FILMS,FAST CRYSTALLIZATION,AMORPHOUS GE2SB2TE5,LIQUID-PHASE,COMPOUND,KINETICS",Review,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Materials Science,,36.768,"GLASS-TRANSITION,TEMPERATURES,DENSITY-FUNCTIONAL,THEORY,RANDOM-ACCESS,MEMORY,SB-TE,THIN-FILMS,FAST,CRYSTALLIZATION,AMORPHOUS,GE2SB2TE5,LIQUID-PHASE,COMPOUND,KINETICS",MATERIALS TODAY,https://doi.org/10.1016/j.mattod.2020.07.016,
99,ADD: Analytically Differentiable Dynamics for Multi-Body Systems with Frictional Contact,39,6,,"Geilinger Moritz,Hahn David,Zehnder Jonas,Baecher Moritz,Thomaszewski Bernhard,Coros Stelian","Geilinger M,Hahn D,Zehnder J,Bacher M,Thomaszewski B,Coros S",Geilinger M,10.1145/3414685.3417766,ETH Zurich,"We present a differentiable dynamics solver that is able to handle frictional contact for rigid and deformable objects within a unified framework. Through a principled mollification of normal and tangential contact forces, our method circumvents the main difficulties inherent to the non-smooth nature of frictional contact. We combine this new contact model with fully-implicit time integration to obtain a robust and efficient dynamics solver that is analytically differentiable. In conjunction with adjoint sensitivity analysis, our formulation enables gradient-based optimization with adaptive trade-offs between simulation accuracy and smoothness of objective function landscapes. We thoroughly analyse our approach on a set of simulation examples involving rigid bodies, visco-elastic materials, and coupled multibody systems. We furthermore showcase applications of our differentiable simulator to parameter estimation for deformable objects, motion planning for robotic manipulation, trajectory optimization for compliant walking robots, as well as efficient self-supervised learning of control policies.","Differentiable simulation,Optimization,Deformable Models,Rigid-body dynamics,Contact mechanics,Robotics",Article,"ASSOC COMPUTING MACHINERY, 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA",Computer Science,,6.445,,ACM TRANSACTIONS ON GRAPHICS,https://dl.acm.org/doi/pdf/10.1145/3414685.3417766,
