,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Automatic Detection of Freshwater Phytoplankton Specimens in Conventional Microscopy Images,20,22,,"Rivas-Villar David,Rouco Jose,Penedo Manuel G.,Carballeira Rafael,Novo Jorge","Rivas-Villar D,Rouco J,Penedo MG,Carballeira R,Novo J",Rivas-Villar D,10.3390/s20226704,Universidade da Coruna,"Water safety and quality can be compromised by the proliferation of toxin-producing phytoplankton species, requiring continuous monitoring of water sources. This analysis involves the identification and counting of these species which requires broad experience and knowledge. The automatization of these tasks is highly desirable as it would release the experts from tedious work, eliminate subjective factors, and improve repeatability. Thus, in this preliminary work, we propose to advance towards an automatic methodology for phytoplankton analysis in digital images of water samples acquired using regular microscopes. In particular, we propose a novel and fully automatic method to detect and segment the existent phytoplankton specimens in these images using classical computer vision algorithms. The proposed method is able to correctly detect sparse colonies as single phytoplankton candidates, thanks to a novel fusion algorithm, and is able to differentiate phytoplankton specimens from other image objects in the microscope samples (like minerals, bubbles or detritus) using a machine learning based approach that exploits texture and colour features. Our preliminary experiments demonstrate that the proposed method provides satisfactory and accurate results.","microscope images,phytoplankton detection,colony merging,gabor filters,bag of visual words",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"IMAGING,FLOW-CYTOMETRY,CLASSIFICATION,IDENTIFICATION,PRESERVATION,SYSTEM",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7700267,
2,Diagnosis of Defective Rotor Bars in Induction Motors,12,11,,"Lee Chun-Yao,Huang Kuan-Yu,Jen Lai-Yu,Zhuo Guang-Lin","Lee CY,Huang KY,Jen LY,Zhuo GL",Lee CY,10.3390/sym12111753,Chung Yuan Christian University,"This paper proposes a diagnosis method, combining signal analysis and classification models, to the rotor defect problems of motors. Two manufacture technologies, nonmagnetic high-temperature resistant ceramic adhesive and electrical discharge machining (EDM), are applied to make testing samples, including blowhole and perforation defects of rotor bars in this study. The typical multiresolution analysis (MRA) model is used to analyze acquired source current signals of motors. The features are extracted from the signals of each column of MRA-matrix, including maximum, mean, standard deviation, root-mean-square, and summation. The typical back-propagation neural network (BPNN) model is used to diagnose the rotor bar defects of motors, and then the various signal-to-noise ratio (SNR) of white Gaussian noise (WGN), 30, 25, and 20 dB, are added to the signals to verify the robustness of the proposed method. The results show the availability of the proposed method to diagnose the rotor bar defects of motors.","rotor bar diagnosis,induction motors,MRA,back-propagation neural network,features selection",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,"HILBERT,TRANSFORM,WAVELET,TRANSFORM,ONLINE,DIAGNOSIS,FAULT-DETECTION,DECOMPOSITION,ALGORITHM,VIBRATION",SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/11/1753/pdf,
3,A Machine Learning-Assisted Numerical Predictor for Compressive Strength of Geopolymer Concrete Based on Experimental Data and Sensitivity Analysis,10,21,,"An Thao Huynh,Quang Dang Nguyen,Qui Lieu Xuan,Magee Bryan,Chung TaeChoong,Kiet Tuan Tran,Khoa Tan Nguyen","Huynh AT,Nguyen QD,Xuan QL,Magee B,Chung T,Tran KT,Nguyen KT",Nguyen KT,10.3390/app10217726,Duy Tan University,"Geopolymer concrete offers a favourable alternative to conventional Portland concrete due to its reduced embodied carbon dioxide (CO2) content. Engineering properties of geopolymer concrete, such as compressive strength, are commonly characterised based on experimental practices requiring large volumes of raw materials, time for sample preparation, and costly equipment. To help address this inefficiency, this study proposes machine learning-assisted numerical methods to predict compressive strength of fly ash-based geopolymer (FAGP) concrete. Methods assessed included artificial neural network (ANN), deep neural network (DNN), and deep residual network (ResNet), based on experimentally collected data. Performance of the proposed approaches were evaluated using various statistical measures including R-squared (R-2), root mean square error (RMSE), and mean absolute percentage error (MAPE). Sensitivity analysis was carried out to identify effects of the following six input variables on the compressive strength of FAGP concrete: sodium hydroxide/sodium silicate ratio, fly ash/aggregate ratio, alkali activator/fly ash ratio, concentration of sodium hydroxide, curing time, and temperature. Fly ash/aggregate ratio was found to significantly affect compressive strength of FAGP concrete. Results obtained indicate that the proposed approaches offer reliable methods for FAGP design and optimisation. Of note was ResNet, which demonstrated the highest R-2 and lowest RMSE and MAPE values.","geopolymer concrete,artificial neural network,machine learning,deep neural network,ResNet,compressive strength,fly ash",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"ASH,BASED,GEOPOLYMER,FLY-ASH,NEURAL-NETWORK",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7726/pdf,
4,A Novel Hybrid Machine Learning Classification for the Detection of Bruxism Patients Using Physiological Signals,10,21,,"Bin Heyat Md Belal,Akhtar Faijan,Khan Asif,Noor Alam,Benjdira Bilel,Qamar Yumna,Abbas Syed Jafar,Lai Dakun","Bin Heyat MB,Akhtar F,Khan A,Noor A,Benjdira B,Qamar Y,Abbas SJ,Lai DK",Lai DK,10.3390/app10217410,University of Electronic Science & Technology of China,"Featured Application
1. The hybrid machine learning (HML) classifier can easily classify the subjects (healthy and bruxism), sleep stages (w and REM), and both with high accuracy. 2. The proposed system automatically detects the bruxism sleep disorder and sleep stages. 3. Single C4-A1 channel of the EEG signal found to be more accurate than ECG and EMG channels.
Bruxism is a sleep disorder in which the patient clinches and gnashes their teeth. Bruxism detection using traditional methods is time-consuming, cumbersome, and expensive. Therefore, an automatic tool to detect this disorder will alleviate the doctor workload and give valuable help to patients. In this paper, we targeted this goal and designed an automatic method to detect bruxism from the physiological signals using a novel hybrid classifier. We began with data collection. Then, we performed the analysis of the physiological signals and the estimation of the power spectral density. After that, we designed the novel hybrid classifier to enable the detection of bruxism based on these data. The classification of the subjects into ""healthy"" or ""bruxism"" from the electroencephalogram channel (C4-A1) obtained a maximum specificity of 92% and an accuracy of 94%. Besides, the classification of the sleep stages such as the wake (w) stage and rapid eye movement (REM) stage from the electrocardiogram channel (ECG1-ECG2) obtained a maximum specificity of 86% and an accuracy of 95%. The combined bruxism classification and the sleep stages classification from the electroencephalogram channel (C4-P4) obtained a maximum specificity of 90% and an accuracy of 97%. The results show that more accurate bruxism detection is achieved by exploiting the electroencephalogram signal (C4-P4). The present work can be applied for home monitoring systems for bruxism detection.","machine learning,hybrid classifier,sleep disorder,dental disorder,EEG,ECG,EMG",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"FAST,FOURIER-TRANSFORM,SLEEP,DISORDER,RESEARCH,RESOURCE,TOOTH,WEAR,EEG,SIGNAL,DESIGN,VALIDATION,ALGORITHM,PHYSIONET,SYSTEM",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7410/pdf,
5,Coronary Artery Disease Detection by Machine Learning with Coronary Bifurcation Features,10,21,,"Chen Xueping,Fu Yi,Lin Jiangguo,Ji Yanru,Fang Ying,Wu Jianhua","Chen XP,Fu Y,Lin JG,Ji YR,Fang Y,Wu JH",Wu JH,10.3390/app10217656,South China University of Technology,"Background: Early accurate detection of coronary artery disease (CAD) is one of the most important medical research areas. Researchers are motivated to utilize machine learning techniques for quick and accurate detection of CAD. Methods: To obtain the high quality of features used for machine learning, we here extracted the coronary bifurcation features from the coronary computed tomography angiography (CCTA) images by using the morphometric method. The machine learning classifier algorithms, such as logistic regression (LR), decision tree (DT), linear discriminant analysis (LDA), k-nearest neighbors (k-NN), artificial neural network (ANN), and support vector machine (SVM) were applied for estimating the performance by using the measured features. Results: The results showed that in comparison with other machine learning methods, the polynomial-SVM with the use of the grid search optimization method had the best performance for the detection of CAD and had yielded the classification accuracy of 100.00%. Among six examined coronary bifurcation features, the exponent of vessel diameter (n) and the area expansion ratio (AER) were two key features in the detection of CAD. Conclusions: This study could aid the clinicians to detect CAD accurately, which may probably provide an alternative method for the non-invasive diagnosis in clinical.","coronary artery disease,coronary bifurcations,machine learning,morphological features,classification performance",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"HEART-DISEASE,CLASSIFICATION,DIAGNOSIS,UPDATE",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7656/pdf,
6,Gaussian Mixture Models for Detecting Sleep Apnea Events Using Single Oronasal Airflow Record,10,21,,"ElMoaqet Hisham,Kim Jungyoon,Tilbury Dawn,Ramachandran Satya Krishna,Ryalat Mutaz,Chu Chao-Hsien","ElMoaqet H,Kim J,Tilbury D,Ramachandran SK,Ryalat M,Chu CH",ElMoaqet H,10.3390/app10217889,German-Jordanian University,"Sleep apnea is a common sleep-related disorder that significantly affects the population. It is characterized by repeated breathing interruption during sleep. Such events can induce hypoxia, which is a risk factor for multiple cardiovascular and cerebrovascular diseases. Polysomnography, the gold standard, is expensive, inaccessible, uncomfortable and an expert technician is needed to score sleep-related events. To address these limitations, many previous studies have proposed and implemented automatic scoring processes based on fewer sensors and machine learning classification algorithms. However, alternative device technologies developed for both home and hospital still have limited diagnostic accuracy for detecting apnea events even though many of the previous investigational algorithms are based on multiple physiological channel inputs. In this paper, we propose a new probabilistic algorithm based on (only) oronasal respiration signal for automated detection of apnea events during sleep. The proposed model leverages AASM recommendations for characterizing apnea events with respect to dynamic changes in the local respiratory airflow baseline. Unlike classical threshold-based classification models, we use a Gaussian mixture probability model for detecting sleep apnea based on the posterior probabilities of the respective events. Our results show significant improvement in the ability to detect sleep apnea events compared to a rule-based classifier that uses the same classification features and also compared to two previously published studies for automated apnea detection using the same respiratory flow signal. We use 96 sleep patients with different apnea severity levels as reflected by their Apnea-Hypopnea Index (AHI) levels. The performance was not only analyzed over obstructive sleep apnea (OSA) but also over other types of sleep apnea events including central and mixed sleep apnea (CSA, MSA). Also the performance was comprehensively analyzed and evaluated over patients with varying disease severity conditions, where it achieved an overall performance of TPR=88.5%, TNR=82.5%, and AUC=86.7%. The proposed approach contributes a new probabilistic framework for detecting sleep apnea events using a single airflow record with an improved capability to generalize over different apnea severity conditions","sleep apnea,airflow signal,Gaussian Mixture Models (GMM)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"HYPOPNEA,SYNDROME,AUTOMATIC,DETECTION,CHANNEL,ELECTROCARDIOGRAM,PATHOPHYSIOLOGY,CLASSIFICATION,PREDICTIONS,DIAGNOSIS,ACCURACY",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7889/pdf,
7,Deep-Learning-Based Computer-Aided Systems for Breast Cancer Imaging: A Critical Review,10,22,,"Jimenez-Gaona Yuliana,Jose Rodriguez-Alvarez Maria,Lakshminarayanan Vasudevan","Jimenez-Gaona Y,Rodriguez-Alvarez MJ,Lakshminarayanan V",Jimenez-Gaona Y,10.3390/app10228298,Universidad Tecnica Particular de Loja,"This paper provides a critical review of the literature on deep learning applications in breast tumor diagnosis using ultrasound and mammography images. It also summarizes recent advances in computer-aided diagnosis/detection (CAD) systems, which make use of new deep learning methods to automatically recognize breast images and improve the accuracy of diagnoses made by radiologists. This review is based upon published literature in the past decade (January 2010-January 2020), where we obtained around 250 research articles, and after an eligibility process, 59 articles were presented in more detail. The main findings in the classification process revealed that new DL-CAD methods are useful and effective screening tools for breast cancer, thus reducing the need for manual feature extraction. The breast tumor research community can utilize this survey as a basis for their current and future studies.","breast cancer,computer-aided diagnosis,convolutional neural networks,deep learning,mammography,ultrasound",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"CONVOLUTIONAL,NEURAL-NETWORKS,ADAPTIVE,HISTOGRAM,EQUALIZATION,SCREENING,MAMMOGRAPHY,DIGITAL,MAMMOGRAPHY,ULTRASOUND,CLASSIFICATION,SEGMENTATION,DIAGNOSIS,PERFORMANCE,MICROCALCIFICATIONS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/22/8298/pdf,
8,Expert System for Mandibular Condyle Detection and Osteoarthritis Classification in Panoramic Imaging Using R-CNN and CNN,10,21,,"Kim Donghyun,Choi Eunhye,Jeong Ho Gul,Chang Joonho,Youm Sekyoung","Kim D,Choi E,Jeong HG,Chang J,Youm S",Youm S,10.3390/app10217464,Dongguk University,"Temporomandibular joint osteoarthritis (TMJ OA) is a degenerative condition of the TMJ led by a pathological tissue response of the joint under mechanical loading. It is characterized by the progressive destruction of the internal surfaces of the joint, which can result in debilitating pain and joint noise. Panoramic imaging can be used as a basic screening tool with thorough clinical examination in diagnosing TMJ OA. This paper proposes an algorithm that can extract the condylar region and determine its abnormality by using convolutional neural networks (CNNs) and Faster region-based CNNs (R-CNNs). Panoramic images are collected retrospectively and 1000 images are classified into three categories-normal, abnormal, and unreadable-by a dentist or orofacial pain specialist. Labels indicating whether the condyle is detected and its location enabled more clearly recognizable panoramic images. The uneven proportion of normal to abnormal data is adjusted by duplicating and rotating the images. An R-CNN model and a Visual Geometry Group-16 (VGG16) model are used for learning and condyle discrimination, respectively. To prevent overfitting, the images are rotated +/- 10 degrees and shifted by 10%. The average precision of condyle detection using an R-CNN at intersection over union (IoU) >0.5 is 99.4% (right side) and 100% (left side). The sensitivity, specificity, and accuracy of the TMJ OA classification algorithm using a CNN are 0.54, 0.94, and 0.84, respectively. The findings demonstrate that classifying panoramic images through CNNs is possible. It is expected that artificial intelligence will be more actively applied to analyze panoramic X-ray images in the future.","medical information expert systems,neural networks,osteoarthritis,panoramic radiography,temporomandibular joint",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7464/pdf,
9,Maximum Marginal Approach on EEG Signal Preprocessing for Emotion Detection,10,21,,"Li Gen,Jung Jason J.","Li G,Jung JJ",Jung JJ,10.3390/app10217677,Chung Ang University,"Emotion detection is an important research issue in electroencephalogram (EEG). Signal preprocessing and feature selection are parts of feature engineering, which determines the performance of emotion detection and reduces the training time of the deep learning models. To select the efficient features for emotion detection, we propose a maximum marginal approach on EEG signal preprocessing. The approach selects the least similar segments between two EEG signals as features that can represent the difference between EEG signals caused by emotions. The method defines a signal similarity described as the distance between two EEG signals to find the features. The frequency domain of EEG is calculated by using a wavelet transform that exploits a wavelet to calculate EEG components in a different frequency. We have conducted experiments by using the selected feature from real EEG data recorded from 10 college students. The experimental results show that the proposed approach performs better than other feature selection methods by 17.9% on average in terms of accuracy. The maximum marginal approach-based models achieve better performance than the models without feature selection by 21% on average in terms of accuracy.","signal preprocessing,signal similarity,emotion detection",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,RECOGNITION,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7677/pdf,
10,A Systematic Overview of Recent Methods for Non-Contact Chronic Wound Analysis,10,21,,"Marijanovic Domagoj,Filko Damir","Marijanovic D,Filko D",Filko D,10.3390/app10217613,University of JJ Strossmayer Osijek,"Chronic wounds or wounds that are not healing properly are a worldwide health problem that affect the global economy and population. Alongside with aging of the population, increasing obesity and diabetes patients, we can assume that costs of chronic wound healing will be even higher. Wound assessment should be fast and accurate in order to reduce the possible complications, and therefore shorten the wound healing process. Contact methods often used by medical experts have drawbacks that are easily overcome by non-contact methods like image analysis, where wound analysis is fully or partially automated. Two major tasks in wound analysis on images are segmentation of the wound from the healthy skin and background, and classification of the most important wound tissues like granulation, fibrin, and necrosis. These tasks are necessary for further assessment like wound measurement or healing evaluation based on tissue representation. Researchers use various methods and algorithms for image wound analysis with the aim to outperform accuracy rates and show the robustness of the proposed methods. Recently, neural networks and deep learning algorithms have driven considerable performance improvement across various fields, which has a led to a significant rise of research papers in the field of wound analysis as well. The aim of this paper is to provide an overview of recent methods for non-contact wound analysis which could be used for developing an end-to-end solution for a fully automated wound analysis system which would incorporate all stages from data acquisition, to segmentation and classification, ending with measurement and healing evaluation.","chronic wounds,imaging,wound segmentation,tissue classification,3D reconstruction,wound measurement,healing evaluation",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"IMAGE-ANALYSIS,HAND-HELD,SEGMENTATION,CLASSIFICATION,FRAMEWORK,DESIGN,MAVIS,SKIN,RGB",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7613/pdf,
11,Deep Learning-Based Pixel-Wise Lesion Segmentation on Oral Squamous Cell Carcinoma Images,10,22,,"Martino Francesco,Bloisi Domenico D.,Pennisi Andrea,Fawakherji Mulham,Ilardi Gennaro,Russo Daniela,Nardi Daniele,Staibano Stefania,Merolla Francesco","Martino F,Bloisi DD,Pennisi A,Fawakherji M,Ilardi G,Russo D,Nardi D,Staibano S,Merolla F",Bloisi DD,10.3390/app10228285,University of Basilicata,"Oral squamous cell carcinoma is the most common oral cancer. In this paper, we present a performance analysis of four different deep learning-based pixel-wise methods for lesion segmentation on oral carcinoma images. Two diverse image datasets, one for training and another one for testing, are used to generate and evaluate the models used for segmenting the images, thus allowing to assess the generalization capability of the considered deep network architectures. An important contribution of this work is the creation of the Oral Cancer Annotated (ORCA) dataset, containing ground-truth data derived from the well-known Cancer Genome Atlas (TCGA) dataset.","oral carcinoma,medical image segmentation,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"AUTOMATED,CLASSIFICATION,TISSUE,IDENTIFICATION",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/22/8285/pdf,
12,Multi-Task Learning for Small Brain Tumor Segmentation from MRI,10,21,,"Ngo Duc-Ky,Minh-Trieu Tran,Kim Soo-Hyung,Yang Hyung-Jeong,Lee Guee-Sang","Ngo DK,Tran MT,Kim SH,Yang HJ,Lee GS",Lee GS,10.3390/app10217790,Chonnam National University,"Segmenting brain tumors accurately and reliably is an essential part of cancer diagnosis and treatment planning. Brain tumor segmentation of glioma patients is a challenging task because of the wide variety of tumor sizes, shapes, positions, scanning modalities, and scanner's acquisition protocols. Many convolutional neural network (CNN) based methods have been proposed to solve the problem of brain tumor segmentation and achieved great success. However, most previous studies do not fully take into account multiscale tumors and often fail to segment small tumors, which may have a significant impact on finding early-stage cancers. This paper deals with the brain tumor segmentation of any sizes, but specially focuses on accurately identifying small tumors, thereby increasing the performance of the brain tumor segmentation of overall sizes. Instead of using heavyweight networks with multi-resolution or multiple kernel sizes, we propose a novel approach for better segmentation of small tumors by dilated convolution and multi-task learning. Dilated convolution is used for multiscale feature extraction, however it does not work well with very small tumor segmentation. For dealing with small-sized tumors, we try multi-task learning, where an auxiliary task of feature reconstruction is used to retain the features of small tumors. The experiment shows the effectiveness of segmenting small tumors with the proposed method. This paper contributes to the detection and segmentation of small tumors, which have seldom been considered before and the new development of hierarchical analysis using multi-task learning.","brain tumor segmentation,gliomas,small tumor segmentation,MRI,deep learning,multi-task learning,feature reconstruction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7790/pdf,
13,Virtual UV Fluorescence Microscopy from Hematoxylin and Eosin Staining of Liver Images Using Deep Learning Convolutional Neural Network,10,21,,"Oszutowska-Mazurek Dorota,Parafiniuk Miroslaw,Mazurek Przemyslaw","Oszutowska-Mazurek D,Parafiniuk M,Mazurek P",Oszutowska-Mazurek D,10.3390/app10217815,Pomeranian Medical University,"Featured Application
The proposed solution allows for the digital conversion of the image of a hematoxylin-eosin-stained slide, using a convolutional neural network, to an image resembling a fluorescent image obtained with a UV microscope.
The use of UV (ultraviolet fluorescence) light in microscopy allows improving the quality of images and observation of structures that are not visible in visible spectrum. The disadvantage of this method is the degradation of microstructures in the slide due to exposure to UV light. The article examines the possibility of using a convolutional neural network to perform this type of conversion without damaging the slides. Using eosin hematoxylin stained slides, a database of image pairs was created for visible light (halogen lamp) and UV light. This database was used to train a multi-layer unidirectional convolutional neural network. The results of the study were subjectively and objectively assessed using the SSIM (Structural Similarity Index Measure) and SSIM (structure only) image quality measures. The results show that it is possible to perform this type of conversion (the studies used liver slides for 100x magnification), and in some cases there was an additional improvement in image quality.","virtual fluorescence microscopy,deep learning,convolutional neural networks,liver histology,hematoxylin and eosin staining,digital staining,image processing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,RADIOMICS,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7815/pdf,
14,Alternative Detection of n=1 Modes Slowing Down on ASDEX Upgrade,10,21,,"Peluso Emmanuele,Rossi Riccardo,Murari Andrea,Gaudio Pasqualino,Gelfusa Michela","Peluso E,Rossi R,Murari A,Gaudio P,Gelfusa M",Peluso E,10.3390/app10217891,University of Rome Tor Vergata,"Featured Application
This article describes a physical based criterion to track the slowing down of n = 1 instabilities on the ASDEX upgrade (AUG) Tokamak. It can provide automatically the time instance of the locking of the instability in the frame of reference of the laboratory. Immediate applications are possible both in real time and off-line, for mitigation and avoidance purposes respectively.
Disruptions in tokamaks are very often associated with the slowing down of magneto-hydrodynamic (MHD) instabilities and their subsequent locking to the wall. To improve the understanding of the chain of events ending with a disruption, a statistically robust and physically based criterion has been devised to track the slowing down of modes with toroidal mode numbers n = 1 and mostly poloidal mode number m = 2, providing an alternative and earlier detection tool compared to simple threshold based indicators. A database of 370 discharges of axially symmetric divertor experiment-upgrade (AUG) has been studied and results compared with other indicators used in real time. The estimator is based on a weighted average value of the fast Fourier transform of the perturbed radial n = 1 magnetic field, caused by the rotation of the modes. The use of a carrier sinusoidal wave helps alleviating the spurious influence of non-sinusoidal magnetic perturbations induced by other instabilities like Edge localized modes (ELMs). The indicator constitutes a good candidate for further studies including machine learning approaches for mitigation and avoidance since, by deploying it systematically to evaluate the time instance for the expected locking, multi-machine databases can be populated. Furthermore, it can be thought as a contribution to a wider approach to dynamically tracking the chain of events leading to disruptions.","disruption avoidance,disruptions,MHD instabilities,Mode Locking,Magnetic Islands",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7891/pdf,
15,An Empirical Evaluation of Nuclei Segmentation from H&E Images in a Real Application Scenario,10,22,,"Putzu Lorenzo,Fumera Giorgio","Putzu L,Fumera G",Putzu L,10.3390/app10227982,University of Cagliari,"Cell nuclei segmentation is a challenging task, especially in real applications, when the target images significantly differ between them. This task is also challenging for methods based on convolutional neural networks (CNNs), which have recently boosted the performance of cell nuclei segmentation systems. However, when training data are scarce or not representative of deployment scenarios, they may suffer from overfitting to a different extent, and may hardly generalise to images that differ from the ones used for training. In this work, we focus on real-world, challenging application scenarios when no annotated images from a given dataset are available, or when few images (even unlabelled) of the same domain are available to perform domain adaptation. To simulate this scenario, we performed extensive cross-dataset experiments on several CNN-based state-of-the-art cell nuclei segmentation methods. Our results show that some of the existing CNN-based approaches are capable of generalising to target images which resemble the ones used for training. In contrast, their effectiveness considerably degrades when target and source significantly differ in colours and scale.","digital pathology,H&amp,E staining,cell nuclei segmentation,cross-dataset",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"CELL-NUCLEI,CANCER,CLASSIFICATION,TRACKING",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/22/7982/pdf,
16,When Deep Learning Meets Data Alignment: A Review on Deep Registration Networks (DRNs),10,21,,"Villena-Martinez Victor,Oprea Sergiu,Saval-Calvo Marcelo,Azorin-Lopez Jorge,Fuster-Guillo Andres,Fisher Robert B.","Villena-Martinez V,Oprea S,Saval-Calvo M,Azorin-Lopez J,Fuster-Guillo A,Fisher RB",Villena-Martinez V; Saval-Calvo M,10.3390/app10217524,Universitat d'Alacant,"This paper reviews recent deep learning-based registration methods. Registration is the process that computes the transformation that aligns datasets, and the accuracy of the result depends on multiple factors. The most significant factors are the size of input data; the presence of noise, outliers and occlusions; the quality of the extracted features; real-time requirements; and the type of transformation, especially those defined by multiple parameters, such as non-rigid deformations. Deep Registration Networks (DRNs) are those architectures trying to solve the alignment task using a learning algorithm. In this review, we classify these methods according to a proposed framework based on the traditional registration pipeline. This pipeline consists of four steps: target selection, feature extraction, feature matching, and transform computation for the alignment. This new paradigm introduces a higher-level understanding of registration, which makes explicit the challenging problems of traditional approaches. The main contribution of this work is to provide a comprehensive starting point to address registration problems from a learning-based perspective and to understand the new range of possibilities.","registration,3D alignment,neural networks,Deep Registration Networks",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"IMAGE,REGISTRATION,MODELS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7524/pdf,
17,A Performance Comparison between Automated Deep Learning and Dental Professionals in Classification of Dental Implant Systems from Dental Imaging: A Multi-Center Study,10,11,,"Lee Jae-Hong,Kim Young-Taek,Lee Jong-Bin,Jeong Seong-Nyum","Lee JH,Kim YT,Lee JB,Jeong SN",Lee JH,10.3390/diagnostics10110910,Wonkwang University,"In this study, the efficacy of the automated deep convolutional neural network (DCNN) was evaluated for the classification of dental implant systems (DISs) and the accuracy of the performance was compared against that of dental professionals using dental radiographic images collected from three dental hospitals. A total of 11,980 panoramic and periapical radiographic images with six different types of DISs were divided into training (n = 9584) and testing (n = 2396) datasets. To compare the accuracy of the trained automated DCNN with dental professionals (including six board-certified periodontists, eight periodontology residents, and 11 residents not specialized in periodontology), 180 images were randomly selected from the test dataset. The accuracy of the automated DCNN based on the AUC, Youden index, sensitivity, and specificity, were 0.954, 0.808, 0.955, and 0.853, respectively. The automated DCNN outperformed most of the participating dental professionals, including board-certified periodontists, periodontal residents, and residents not specialized in periodontology. The automated DCNN was highly effective in classifying similar shapes of different types of DISs based on dental radiographic images. Further studies are necessary to determine the efficacy and feasibility of applying an automated DCNN in clinical practice.","artificial intelligence,dental implants,deep learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"IDENTIFICATION,EXPERIENCE,DIAGNOSIS,TEETH",DIAGNOSTICS,https://www.mdpi.com/2075-4418/10/11/910/pdf,
18,"Chronic Pain Diagnosis Using Machine Learning, Questionnaires, and QST: A Sensitivity Experiment",10,11,,"Santana Alex Novaes,de Santana Charles Novaes,Montoya Pedro","Santana AN,de Santana CN,Montoya P",Santana AN; Montoya P,10.3390/diagnostics10110958,Universitat de les Illes Balears,"In the last decade, machine learning has been widely used in different fields, especially because of its capacity to work with complex data. With the support of machine learning techniques, different studies have been using data-driven approaches to better understand some syndromes like mild cognitive impairment, Alzheimer's disease, schizophrenia, and chronic pain. Chronic pain is a complex disease that can recurrently be misdiagnosed due to its comorbidities with other syndromes with which it shares symptoms. Within that context, several studies have been suggesting different machine learning algorithms to classify or predict chronic pain conditions. Those algorithms were fed with a diversity of data types, from self-report data based on questionnaires to the most advanced brain imaging techniques. In this study, we assessed the sensitivity of different algorithms and datasets classifying chronic pain syndromes. Together with this assessment, we highlighted important methodological steps that should be taken into account when an experiment using machine learning is conducted. The best results were obtained by ensemble-based algorithms and the dataset containing the greatest diversity of information, resulting in area under the receiver operating curve (AUC) values of around 0.85. In addition, the performance of the algorithms is strongly related to the hyper-parameters. Thus, a good strategy for hyper-parameter optimization should be used to extract the most from the algorithm. These findings support the notion that machine learning can be a powerful tool to better understand chronic pain conditions.","chronic pain,machine learning,classification,questionnaires,QST",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,3.674,"LOW-BACK-PAIN,HEALTH-CARE,CRITERIA,FIBROMYALGIA,RELIABILITY,CLASSIFICATION,ELECTROMYOGRAPHY,DEPRESSION,RESPONSES,VALIDITY",DIAGNOSTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7697204,
19,Integrating Enhanced Sparse Autoencoder-Based Artificial Neural Network Technique and Softmax Regression for Medical Diagnosis,9,11,,"Ebiaredoh-Mienye Sarah A.,Esenogho Ebenezer,Swart Theo G.","Ebiaredoh-Mienye SA,Esenogho E,Swart TG",Esenogho E,10.3390/electronics9111963,University of Johannesburg,"In recent times, several machine learning models have been built to aid in the prediction of diverse diseases and to minimize diagnostic errors made by clinicians. However, since most medical datasets seem to be imbalanced, conventional machine learning algorithms tend to underperform when trained with such data, especially in the prediction of the minority class. To address this challenge and proffer a robust model for the prediction of diseases, this paper introduces an approach that comprises of feature learning and classification stages that integrate an enhanced sparse autoencoder (SAE) and Softmax regression, respectively. In the SAE network, sparsity is achieved by penalizing the weights of the network, unlike conventional SAEs that penalize the activations within the hidden layers. For the classification task, the Softmax classifier is further optimized to achieve excellent performance. Hence, the proposed approach has the advantage of effective feature learning and robust classification performance. When employed for the prediction of three diseases, the proposed method obtained test accuracies of 98%, 97%, and 91% for chronic kidney disease, cervical cancer, and heart disease, respectively, which shows superior performance compared to other machine learning algorithms. The proposed approach also achieves comparable performance with other methods available in the recent literature.","sparse autoencoder,unsupervised learning,Softmax regression,medical diagnosis,machine learning,artificial neural network,e-health",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,PREDICTION,ELECTRONICS,https://www.mdpi.com/2079-9292/9/11/1963/pdf,
20,Affective State Assistant for Helping Users with Cognition Disabilities Using Neural Networks,9,11,,"Munoz-Saavedra Luis,Luna-Perejon Francisco,Civit-Masot Javier,Miro-Amarante Lourdes,Civit Anton,Dominguez-Morales Manuel","Munoz-Saavedra L,Luna-Perejon F,Civit-Masot J,Miro-Amarante L,Civit A,Dominguez-Morales M",Munoz-Saavedra L,10.3390/electronics9111843,Universidad Politecnica de Madrid,"Non-verbal communication is essential in the communication process. This means that its lack can cause misinterpretations of the message that the sender tries to transmit to the receiver. With the rise of video calls, it seems that this problem has been partially solved. However, people with cognitive disorders such as those with some kind of Autism Spectrum Disorder (ASD) are unable to interpret non-verbal communication neither live nor by video call. This work analyzes the relationship between some physiological measures (EEG, ECG, and GSR) and the affective state of the user. To do that, some public datasets are evaluated and used for a multiple Deep Learning (DL) system. Each physiological signal is pre-processed using a feature extraction process after a frequency study with the Discrete Wavelet Transform (DWT), and those coefficients are used as inputs for a single DL classifier focused on that signal. These multiple classifiers (one for each signal) are evaluated independently and their outputs are combined in order to optimize the results and obtain additional information about the most reliable signals for classifying the affective states into three levels: low, middle, and high. The full system is carefully detailed and tested, obtaining promising results (more than 95% accuracy) that demonstrate its viability.","deep learning,feature extraction,discrete wavelet transform,affective state,cognitive disorders,autism,ASD,EEG,ECG,GSR",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Computer Science,Engineering,Physics",,2.408,"EMOTION,EEG,MOTIVATION",ELECTRONICS,https://www.mdpi.com/2079-9292/9/11/1843/pdf,
21,Combined Approach Using Clustering-Random Forest to Evaluate Partial Discharge Patterns in Hydro Generators,13,22,,"Pardauil Ana C. N.,Nascimento Thiago P.,Siqueira Marcelo R. S.,Bezerra Ubiratan H.,Oliveira Werbeston D.","Pardauil ACN,Nascimento TP,Siqueira MRS,Bezerra UH,Oliveira WD",Pardauil ACN,10.3390/en13225992,Universidade Federal do Para,"The measurement and analysis of partial discharges (PD) are like medical examinations, such as Electrocardiogram (ECG), in which there are preestablished criteria. However, each patient will present his particularities that will not necessarily imply his condemnation. The consolidated method for PD processing has high qualifications in the statistical analysis of insulation status of electric generators. However, although the IEEE 1434 standard has well-established standards, it will not always be simple to classify signals obtained in the measurement of the hydro generator coupler due to variations in the same type of PD incidence that may occur as a result of the uniqueness of each machine subject to staff evaluation. In order to streamline the machine diagnostic process, a tool is suggested in this article that will provide this signal classification feature. These measurements will be established in groups that represent each known form of partial discharge established by the literature. It was combined with supervised and unsupervised techniques to create a hybrid method that identified the patterns and classified the measurement signals, with a high degree of precision. This paper proposes the use of data-mining techniques based on clustering to group the characteristic patterns of PD in hydro generators, defined in standards. Then, random forest decision trees were trained to classify cases from new measurements. A comparative analysis was performed among eight clustering algorithms and random forest for choosing which is the superior combination to make a better classification of the equipment diagnosis. R-2 was used for assessing the data trend.","partial discharges,data-mining techniques,hydro generators,clustering algorithms,random forest",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Energy & Fuels,,3.085,"SECURITY,ASSESSMENT,WAVELET,SELECTION,SYSTEM",ENERGIES,https://www.mdpi.com/1996-1073/13/22/5992/pdf,
22,CanSuR: a robust method for staining pattern recognition of HEp-2 cell IIF images,32,21,16471-16489,"Mandal Ankita,Maji Pradipta","Mandal A,Maji P",Maji P,10.1007/s00521-019-04108-w,Indian Statistical Institute,"The recognition of staining patterns present in human epithelial type 2 (HEp-2) cells helps to diagnose connective tissue disease. In this context, the paper introduces a robust method, termed as CanSuR, for automatic recognition of antinuclear autoantibodies by HEp-2 cell indirect immunofluorescence (IIF) image analysis. The proposed method combines the advantages of a new sequential supervised canonical correlation analysis (CCA), introduced in this paper, with the theory of rough hypercuboid approach. While the proposed CCA efficiently combines the local textural information of HEp-2 cells, derived from various scales of rotation-invariant local binary patterns, the relevant and significant features of HEp-2 cell for staining pattern recognition are extracted using rough hypercuboid approach. Finally, the support vector machine, with radial basis function kernel, is used to recognize one of the known staining patterns present in IIF images. The effectiveness of the proposed staining pattern recognition method, along with a comparison with related approaches, is demonstrated on MIVIA, SNP and ICPR HEp-2 cell image databases. An important finding is that the proposed method performs significantly better than state-of-the art methods, on three HEp-2 cell image databases with respect to both classification accuracy and F1 score.","HEp-2 cell staining pattern recognition,Local binary pattern,Canonical correlation analysis,Support vector machine",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND",Computer Science,,5.573,"ANTINUCLEAR,AUTOANTIBODIES,TEXTURAL,FEATURES,CLASSIFICATION",NEURAL COMPUTING & APPLICATIONS,,
23,A New Approach of Ensemble Learning Technique to Resolve the Uncertainties of Paddy Area through Image Classification,12,21,,"Lei Tsu Chiang,Wan Shiuan,Wu Shih-Chieh,Wang Hsin-Ping","Lei TC,Wan SA,Wu SC,Wang HP",Wan SA,10.3390/rs12213666,"Ling Tung Univ, Dept Informat Technol, Taichung 40851, Taiwan.","Remote sensing technology has rendered lots of information in agriculture. It has usually been used to monitor paddy growing ecosystems in the past few decades. However, there are uncertainties in data fusion techniques which can be resolved in image classification on paddy rice. In this study, a series of learning concepts integrated by a probability progress Fuzzy Dempster-Shafer (FDS) analysis is presented to upgrade various models and different types of image data which is the goal of this study. More specifically, the study utilized the FDS to generate a series of probability models in the classification of the system. In addition, Logistic Regression (LR), Support Vector Machine (SVM), and Neural Network (NN) approaches are employed into the developed FDS system. Furthermore, two different image types are Satellite Image and Aerial Photo used as the analysis material. The overall classification accuracy has been improved to 97.27%, and the kappa value is 0.93. The overall accuracy of the paddy field image classification for a multi-period of mid-scale satellite images is between 85% and 90%. The overall accuracy of the classification using multi-spectral numerical aerial photos can be between 91% and 95%. The FDS improves the accuracy of the above image classification results.","data fusion,ensemble learning,fuzzy theory,Dempster-Shafer evidence theory",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Environmental Sciences & Ecology,Geology,Remote Sensing,Imaging Science & Photographic Technology",,5.353,"LOGISTIC-REGRESSION,YIELD,ESTIMATION,RICE,FUSION,TEXTURE,RADAR",REMOTE SENSING,https://www.mdpi.com/2072-4292/12/21/3666/pdf,
24,Thyroid Nodule Classification for Physician Decision Support Using Machine Learning-Evaluated Geometric and Morphological Features,20,21,,"Ataide Elmer Jeto Gomes,Ponugoti Nikhila,Illanes Alfredo,Schenke Simone,Kreissl Michael,Friebe Michael","Ataide EJG,Ponugoti N,Illanes A,Schenke S,Kreissl M,Friebe M",Ataide EJG,10.3390/s20216110,Otto von Guericke University,"The classification of thyroid nodules using ultrasound (US) imaging is done using the Thyroid Imaging Reporting and Data System (TIRADS) guidelines that classify nodules based on visual and textural characteristics. These are composition, shape, size, echogenicity, calcifications, margins, and vascularity. This work aims to reduce subjectivity in the current diagnostic process by using geometric and morphological (G-M) features that represent the visual characteristics of thyroid nodules to provide physicians with decision support. A total of 27 G-M features were extracted from images obtained from an open-access US thyroid nodule image database. 11 significant features in accordance with TIRADS were selected from this global feature set. Each feature was labeled (0 = benign and 1 = malignant) and the performance of the selected features was evaluated using machine learning (ML). G-M features together with ML resulted in the classification of thyroid nodules with a high accuracy, sensitivity and specificity. The results obtained here were compared against state-of the-art methods and perform significantly well in comparison. Furthermore, this method can act as a computer aided diagnostic (CAD) system for physicians by providing them with a validation of the TIRADS visual characteristics used for the classification of thyroid nodules in US images.","thyroid nodules,ultrasound imaging,TIRADS,feature extraction,machine learning,classification,computer aided diagnosis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"LUNG,NODULES,DATA,SYSTEM,SEGMENTATION,ULTRASOUND,STRATIFICATION,CANCER",SENSORS,https://www.mdpi.com/1424-8220/20/21/6110/pdf,
25,Enhanced Image-Based Endoscopic Pathological Site Classification Using an Ensemble of Deep Learning Models,20,21,,"Dat Tien Nguyen,Lee Min Beom,Tuyen Danh Pham,Batchuluun Ganbayar,Arsalan Muhammad,Park Kang Ryoung","Nguyen DT,Lee MB,Pham TD,Batchuluun G,Arsalan M,Park KR",Batchuluun G,10.3390/s20215982,Dongguk University,"In vivo diseases such as colorectal cancer and gastric cancer are increasingly occurring in humans. These are two of the most common types of cancer that cause death worldwide. Therefore, the early detection and treatment of these types of cancer are crucial for saving lives. With the advances in technology and image processing techniques, computer-aided diagnosis (CAD) systems have been developed and applied in several medical systems to assist doctors in diagnosing diseases using imaging technology. In this study, we propose a CAD method to preclassify the in vivo endoscopic images into negative (images without evidence of a disease) and positive (images that possibly include pathological sites such as a polyp or suspected regions including complex vascular information) cases. The goal of our study is to assist doctors to focus on the positive frames of endoscopic sequence rather than the negative frames. Consequently, we can help in enhancing the performance and mitigating the efforts of doctors in the diagnosis procedure. Although previous studies were conducted to solve this problem, they were mostly based on a single classification model, thus limiting the classification performance. Thus, we propose the use of multiple classification models based on ensemble learning techniques to enhance the performance of pathological site classification. Through experiments with an open database, we confirmed that the ensemble of multiple deep learning-based models with different network architectures is more efficient for enhancing the performance of pathological site classification using a CAD system as compared to the state-of-the-art methods.","pathological site classification,in vivo endoscopy,computer-aided diagnosis,artificial intelligence,ensemble learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"NETWORK-BASED,METHOD,SEGMENTATION,CNN",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7660061,
26,Writhing Movement Detection in Newborns on the Second and Third Day of Life Using Pose-Based Feature Machine Learning Classification,20,21,,"Doroniewicz Iwona,Ledwon Daniel J.,Affanasowicz Alicja,Kieszczynska Katarzyna,Latos Dominika,Matyja Malgorzata,Mitas Andrzej W.,Mysliwiec Andrzej","Doroniewicz I,Ledwon DJ,Affanasowicz A,Kieszczynska K,Latos D,Matyja M,Mitas AW,Mysliwiec A",Ledwon DJ,10.3390/s20215986,Silesian University of Technology,"Observation of neuromotor development at an early stage of an infant's life allows for early diagnosis of deficits and the beginning of the therapeutic process. General movement assessment is a method of spontaneous movement observation, which is the foundation for contemporary attempts at objectification and computer-aided diagnosis based on video recordings' analysis. The present study attempts to automatically detect writhing movements, one of the normal general movement categories presented by newborns in the first weeks of life. A set of 31 recordings of newborns on the second and third day of life was divided by five experts into videos containing writhing movements (with occurrence time) and poor repertoire, characterized by a lower quality of movement in relation to the norm. Novel, objective pose-based features describing the scope, nature, and location of each limb's movement are proposed. Three machine learning algorithms are evaluated in writhing movements' detection in leave-one-out cross-validation for different feature extraction time windows and overlapping time. The experimental results make it possible to indicate the optimal parameters for which 80% accuracy was achieved. Based on automatically detected writhing movement percent in the video, infant movements are classified as writhing movements or poor repertoire with an area under the ROC (receiver operating characteristics) curve of 0.83.","infant,feature extraction,classification,machine learning,general movement assessment,physiotherapy,diagnosis",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"GENERAL,MOVEMENTS,CEREBRAL-PALSY,INFANTS,PRETERM,TERM",SENSORS,https://www.mdpi.com/1424-8220/20/21/5986/pdf,
27,A Systematic Review of Machine Learning Techniques in Hematopoietic Stem Cell Transplantation (HSCT),20,21,,"Gupta Vibhuti,Braun Thomas M.,Chowdhury Mosharaf,Tewari Muneesh,Choi Sung Won","Gupta V,Braun TM,Chowdhury M,Tewari M,Choi SW",Gupta V; Choi SW,10.3390/s20216100,University of Michigan System,"Machine learning techniques are widely used nowadays in the healthcare domain for the diagnosis, prognosis, and treatment of diseases. These techniques have applications in the field of hematopoietic cell transplantation (HCT), which is a potentially curative therapy for hematological malignancies. Herein, a systematic review of the application of machine learning (ML) techniques in the HCT setting was conducted. We examined the type of data streams included, specific ML techniques used, and type of clinical outcomes measured. A systematic review of English articles using PubMed, Scopus, Web of Science, and IEEE Xplore databases was performed. Search terms included ""hematopoietic cell transplantation (HCT),"" ""autologous HCT,"" ""allogeneic HCT,"" ""machine learning,"" and ""artificial intelligence."" Only full-text studies reported between January 2015 and July 2020 were included. Data were extracted by two authors using predefined data fields. Following PRISMA guidelines, a total of 242 studies were identified, of which 27 studies met the inclusion criteria. These studies were sub-categorized into three broad topics and the type of ML techniques used included ensemble learning (63%), regression (44%), Bayesian learning (30%), and support vector machine (30%). The majority of studies examined models to predict HCT outcomes (e.g., survival, relapse, graft-versus-host disease). Clinical and genetic data were the most commonly used predictors in the modeling process. Overall, this review provided a systematic review of ML techniques applied in the context of HCT. The evidence is not sufficiently robust to determine the optimal ML technique to use in the HCT setting and/or what minimal data variables are required.","machine learning,artificial intelligence,sensors,mobile health,mHealth,hematopoietic stem cell transplantation,HSCT",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"VERSUS-HOST-DISEASE,MARROW,TRANSPLANTATION,ALGORITHM,BLOOD,VALIDATION,PREDICTION",SENSORS,https://www.mdpi.com/1424-8220/20/21/6100/pdf,
28,An Investigation of Insider Threat Mitigation Based on EEG Signal Classification,20,21,,"Kim Jung Hwan,Kim Chul Min,Yim Man-Sung","Kim JH,Kim CM,Yim MS",Yim MS,10.3390/s20216365,Korea Advanced Institute of Science & Technology (KAIST),"This study proposes a scheme to identify insider threats in nuclear facilities through the detection of malicious intentions of potential insiders using subject-wise classification. Based on electroencephalography (EEG) signals, a classification model was developed to identify whether a subject has a malicious intention under scenarios of being forced to become an insider threat. The model also distinguishes insider threat scenarios from everyday conflict scenarios. To support model development, 21-channel EEG signals were measured on 25 healthy subjects, and sets of features were extracted from the time, time-frequency, frequency and nonlinear domains. To select the best use of the available features, automatic selection was performed by random-forest-based algorithms. The k-nearest neighbor, support vector machine with radial kernel, naive Bayes, and multilayer perceptron algorithms were applied for the classification. By using EEG signals obtained while contemplating becoming an insider threat, the subject-wise model identified malicious intentions with 78.57% accuracy. The model also distinguished insider threat scenarios from everyday conflict scenarios with 93.47% accuracy. These findings could be utilized to support the development of insider threat mitigation systems along with existing trustworthiness assessments in the nuclear industry.","nuclear security,insider threat,electroencephalography,machine learning,implicit intention,subject-wise classification",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"PREVENTION,INTENTION,SELF",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7664688,
29,A Random Forest Machine Learning Framework to Reduce Running Injuries in Young Triathletes,20,21,,"Martinez-Gramage Javier,Pardo Albiach Juan,Nacher Molto Ivan,Jose Amer-Cuenca Juan,Huesa Moreno Vanessa,Segura-Orti Eva","Martinez-Gramage J,Albiach JP,Molto IN,Amer-Cuenca JJ,Moreno VH,Segura-Orti E",Martinez-Gramage J,10.3390/s20216388,Universidad CEU Cardenal Herrera,"Background: The running segment of a triathlon produces 70% of the lower limb injuries. Previous research has shown a clear association between kinematic patterns and specific injuries during running. Methods: After completing a seven-month gait retraining program, a questionnaire was used to assess 19 triathletes for the incidence of injuries. They were also biomechanically analyzed at the beginning and end of the program while running at a speed of 90% of their maximum aerobic speed (MAS) using surface sensor dynamic electromyography and kinematic analysis. We used classification tree (random forest) techniques from the field of artificial intelligence to identify linear and non-linear relationships between different biomechanical patterns and injuries to identify which styles best prevent injuries. Results: Fewer injuries occurred after completing the program, with athletes showing less pelvic fall and greater activation in gluteus medius during the first phase of the float phase, with increased trunk extension, knee flexion, and decreased ankle dorsiflexion during the initial contact with the ground. Conclusions: The triathletes who had suffered the most injuries ran with increased pelvic drop and less activation in gluteus medius during the first phase of the float phase. Contralateral pelvic drop seems to be an important variable in the incidence of injuries in young triathletes.","running,kinematics,gait retraining",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"PATELLOFEMORAL,PAIN,MUSCULOSKELETAL,INJURIES,MUSCLE,ACTIVATION,OVERUSE,INJURIES,PATTERNS,CADENCE,ELITE",SENSORS,https://www.mdpi.com/1424-8220/20/21/6388/pdf,
30,Biometric Signals Estimation Using Single Photon Camera and Deep Learning,20,21,,"Paracchini Marco,Marcon Marco,Villa Federica,Zappa Franco,Tubaro Stefano","Paracchini M,Marcon M,Villa F,Zappa F,Tubaro S",Paracchini M,10.3390/s20216102,Polytechnic University of Milan,"The problem of performing remote biomedical measurements using just a video stream of a subject face is called remote photoplethysmography (rPPG). The aim of this work is to propose a novel method able to perform rPPG using single-photon avalanche diode (SPAD) cameras. These are extremely accurate cameras able to detect even a single photon and are already used in many other applications. Moreover, a novel method that mixes deep learning and traditional signal analysis is proposed in order to extract and study the pulse signal. Experimental results show that this system achieves accurate results in the estimation of biomedical information such as heart rate, respiration rate, and tachogram. Lastly, thanks to the adoption of the deep learning segmentation method and dependability checks, this method could be adopted in non-ideal working conditions-for example, in the presence of partial facial occlusions.","deep learning,heart rate,remote photoplethysmography,single-photon avalanche diode",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"FACIAL,VIDEO,PULSE-RATE,HRV",SENSORS,https://www.mdpi.com/1424-8220/20/21/6102/pdf,
31,Population Graph-Based Multi-Model Ensemble Method for Diagnosing Autism Spectrum Disorder,20,21,,"Rakhimberdina Zarina,Liu Xin,Murata Tsuyoshi","Rakhimberdina Z,Liu X,Murata T",Rakhimberdina Z,10.3390/s20216001,Tokyo Institute of Technology,"With the advancement of brain imaging techniques and a variety of machine learning methods, significant progress has been made in brain disorder diagnosis, in particular Autism Spectrum Disorder. The development of machine learning models that can differentiate between healthy subjects and patients is of great importance. Recently, graph neural networks have found increasing application in domains where the population's structure is modeled as a graph. The application of graphs for analyzing brain imaging datasets helps to discover clusters of individuals with a specific diagnosis. However, the choice of the appropriate population graph becomes a challenge in practice, as no systematic way exists for defining it. To solve this problem, we propose a population graph-based multi-model ensemble, which improves the prediction, regardless of the choice of the underlying graph. First, we construct a set of population graphs using different combinations of imaging and phenotypic features and evaluate them using Graph Signal Processing tools. Subsequently, we utilize a neural network architecture to combine multiple graph-based models. The results demonstrate that the proposed model outperforms the state-of-the-art methods on Autism Brain Imaging Data Exchange (ABIDE) dataset.","brain functional connectivity,graph neural network,graph signal processing",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"CONVOLUTIONAL,NEURAL-NETWORKS,BRAIN,NETWORKS,FUNCTIONAL,CONNECTIVITY",SENSORS,https://www.mdpi.com/1424-8220/20/21/6001/pdf,
32,Solar Panel Detection within Complex Backgrounds Using Thermal Images Acquired by UAVs,20,21,,"Vega Diaz Jhon Jairo,Vlaminck Michiel,Lefkaditis Dionysios,Orjuela Vargas Sergio Alejandro,Luong Hiep","Diaz JJV,Vlaminck M,Lefkaditis D,Vargas SAO,Luong H",Diaz JJV,10.3390/s20216219,"Univ Antonio Narino UAN, Ctr Invest Ciencias Basicas & Aplicadas, Ciencia Aplicada, Bogota 110231, Colombia.","The installation of solar plants everywhere in the world increases year by year. Automated diagnostic methods are needed to inspect the solar plants and to identify anomalies within these photovoltaic panels. The inspection is usually carried out by unmanned aerial vehicles (UAVs) using thermal imaging sensors. The first step in the whole process is to detect the solar panels in those images. However, standard image processing techniques fail in case of low-contrast images or images with complex backgrounds. Moreover, the shades of power lines or structures similar to solar panels impede the automated detection process. In this research, two self-developed methods are compared for the detection of panels in this context, one based on classical techniques and another one based on deep learning, both with a common post-processing step. The first method is based on edge detection and classification, in contrast to the second method is based on training a region based convolutional neural networks to identify a panel. The first method corrects for the low contrast of the thermal image using several preprocessing techniques. Subsequently, edge detection, segmentation and segment classification are applied. The latter is done using a support vector machine trained with an optimized texture descriptor vector. The second method is based on deep learning trained with images that have been subjected to three different pre-processing operations. The postprocessing use the detected panels to infer the location of panels that were not detected. This step selects contours from detected panels based on the panel area and the angle of rotation. Then new panels are determined by the extrapolation of these contours. The panels in 100 random images taken from eleven UAV flights over three solar plants are labeled and used to evaluate the detection methods. The metrics for the new method based on classical techniques reaches a precision of 0.997, a recall of 0.970 and a F1 score of 0.983. The metrics for the method of deep learning reaches a precision of 0.996, a recall of 0.981 and a F1 score of 0.989. The two panel detection methods are highly effective in the presence of complex backgrounds.","solar panel detection,solar panel projection,texture descriptor,support vector machine,deep learning,NIR,thermal imaging",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,,SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7663759,
33,Application of Transfer Learning in EEG Decoding Based on Brain-Computer Interfaces: A Review,20,21,,"Zhang Kai,Xu Guanghua,Zheng Xiaowei,Li Huanzhong,Zhang Sicong,Yu Yunhui,Liang Renghao","Zhang K,Xu GH,Zheng XW,Li HZ,Zhang SC,Yu YH,Liang RH",Xu GH,10.3390/s20216321,Xi'an Jiaotong University,"The algorithms of electroencephalography (EEG) decoding are mainly based on machine learning in current research. One of the main assumptions of machine learning is that training and test data belong to the same feature space and are subject to the same probability distribution. However, this may be violated in EEG processing. Variations across sessions/subjects result in a deviation of the feature distribution of EEG signals in the same task, which reduces the accuracy of the decoding model for mental tasks. Recently, transfer learning (TL) has shown great potential in processing EEG signals across sessions/subjects. In this work, we reviewed 80 related published studies from 2010 to 2020 about TL application for EEG decoding. Herein, we report what kind of TL methods have been used (e.g., instance knowledge, feature representation knowledge, and model parameter knowledge), describe which types of EEG paradigms have been analyzed, and summarize the datasets that have been used to evaluate performance. Moreover, we discuss the state-of-the-art and future development of TL for EEG decoding. The results show that TL can significantly improve the performance of decoding models across subjects/sessions and can reduce the calibration time of brain-computer interface (BCI) systems. This review summarizes the current practical suggestions and performance outcomes in the hope that it will provide guidance and help for EEG research in the future.","EEG,transfer learning,review,decoding,classification",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Instruments & Instrumentation",,3.735,"COMMON,SPATIAL-PATTERNS,MOTOR,IMAGERY,ADAPTATION,REGULARIZATION,COVARIATE,SHIFT,BCI,COMMUNICATION,FRAMEWORK,SIGNALS",SENSORS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7664219,
34,Heartbeat monitoring with an mm-wave radar based on deep learning: a novel approach for training and classifying heterogeneous signals,11,11,993-1001,Zhang Haoyu,Zhang HY,Zhang HY,10.1080/2150704X.2020.1809735,Zhejiang Ocean University,"Millimetre wave radar is an emerging technology that can monitor vital signs without contact. This unique feature is very suitable for some particular situations, such as burn patient monitoring. Currently, electrocardiogram (ECG) is still the most common approach for monitoring heart disease. Deep learning algorithms have already been applied to classifying ECG recordings and have achieved good diagnostic results. However, it is very rare to see deep learning-based heartbeat classification using radar signals. The reason is a lack of radar-based heart disease datasets, which are the most important part of training a Convolutional Neural Network (CNN). Specifically, the ECG recordings and radar signals are heterogeneous; thus, the ECG dataset cannot train the CNN for directly classifying the radar signals. In this paper, we propose a novel signal processing algorithm called the Common Features Extraction Method (CFEM) to extract the common features of ECG recordings and radar signals to train a CNN for radar heartbeat signal classification. By using CFEM, the ECG dataset is transferred to the radar field, which means that the core issue for training the CNN using radar signals has been solved. Practical experiments show that the CFEM-based CNN can classify heartbeat radar signals accurately.",,Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND","Remote Sensing,Imaging Science & Photographic Technology",,2.601,,REMOTE SENSING LETTERS,,
35,Machine learning prediction of axillary lymph node metastasis in breast cancer: 2D versus 3D radiomic features,47,12,6334-6342,"Arefan Dooman,Chai Ruimei,Sun Min,Zuley Margarita L.,Wu Shandong","Arefan D,Chai RM,Sun M,Zuley ML,Wu SD",Wu SD,10.1002/mp.14538,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Purpose The purpose of this study was to distinguish axillary lymph node (ALN) status using preoperative breast DCE-MRI radiomics and compare the effects of two-dimensional (2D) and three-dimensional (3D) analysis.
Methods A retrospective study including 154 breast cancer patients all confirmed by pathology; 80 with ALN metastasis and 74 without. All MRI scans were achieved at a 3.0 Tesla scanner with 7 post-contrast MR phases sequentially acquired with a temporal resolution of 60 s. MRI radiomic features were extracted separately from a 2D single slice (i.e., the representative slice) and the 3D tumor volume. Several machine learning classifiers were built and compared using 2D or 3D analysis to distinguish positive vs negative ALN status. We performed independent test and 10-fold cross validation with multiple repetitions, and used bootstrap test, least absolute shrinkage selection operator, and receiver operating characteristic (ROC) curve analysis as statistical tests.
Results The highest area under the ROC curve (AUC) was 0.81 (95% confidence intervals [CI]: 0.80-0.83) and 0.82 (95% CI: 0.81-0.82) for 2D and 3D analysis, respectively; the corresponding accuracy was 79% and 80%. The linear discriminant analysis (LDA) classifier achieved the highest classification performance. None of the AUC differences between 2D and 3D analysis was statistically significant for the several tested machine learning classifiers (all P 0.05).
Conclusions Radiomic features from segmented tumor region in breast MRI were associated with ALN status. The separate radiomic analysis on 3D tumor volume showed a similar effect to the 2D analysis on the single representative slice in the tested machine learning classifiers.","2D,3D analysis,axillary lymph node (ALN) metastasis,breast cancer,MRI radiomics",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"TUMOR,HETEROGENEITY,MRI,IMAGES,ASSOCIATIONS,PHENOTYPES,PATHOLOGY",MEDICAL PHYSICS,,
36,Strain-based fault detection of bolted truss structures using machine learning,12,11,,"Bang Hyejin,Lee Tae Hyun,Lee Gi-Chun,Lee Yong-Bum,Baek Dong-Cheon","Bang H,Lee TH,Lee GC,Lee YB,Baek DC",Baek DC,10.1177/1687814020971890,Korea Institute of Machinery & Materials (KIMM),"The initial design of baggage-lifting machine structures is primarily based on safety and reliability, but they are often damaged because of unforeseen circumstances and overloads. In this study, a machine learning-based logistic regression method for detecting structural damage to bolted truss structures during field work is proposed. Multiple strain gauges attached to the front of the truss model record the amount of deformation occurring in the member when the vertical load generated at the end of the model is applied. In this process, the scatter or error caused by the sample is analyzed, and the data processing method is presented. Experimental results demonstrate that this method provides a good quantitative basis for fault detection, and it can be effectively applied to partial representative data when handling large datasets.","Failure detection,fatigue load,truss structure,machine learning,PHM",Article,"SAGE PUBLICATIONS LTD, 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND","Thermodynamics,Engineering",,1.393,"DAMAGE,DETECTION,IDENTIFICATION",ADVANCES IN MECHANICAL ENGINEERING,https://journals.sagepub.com/doi/pdf/10.1177/1687814020971890,
37,ampir: an R package for fast genome-wide prediction of antimicrobial peptides,36,21,5262-5263,"Fingerhut Legana C. H. W.,Miller David J.,Strugnell Jan M.,Daly Norelle L.,Cooke Ira R.","Fingerhut LCHW,Miller DJ,Strugnell JM,Daly NL,Cooke IR",Fingerhut LCHW; Cooke IR,10.1093/bioinformatics/btaa653,James Cook University,"Antimicrobial peptides (AMPs) are the key components of the innate immune system that protect against pathogens, regulate the microbiome and are promising targets for pharmaceutical research. Computational tools based on machine learning have the potential to aid discovery of genes encoding novel AMPs but existing approaches are not designed for genome-wide scans. To facilitate such genome-wide discovery of AMPs we developed a fast and accurate AMP classification framework, ampir. ampir is designed for high throughput, integrates well with existing bioinformatics pipelines, and has much higher classification accuracy than existing methods when applied to whole genome data.",,Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Biochemistry & Molecular Biology,Biotechnology & Applied Microbiology,Computer Science,Mathematical & Computational Biology,Mathematics",,8.47,,BIOINFORMATICS,https://www.biorxiv.org/content/biorxiv/early/2020/07/21/2020.05.07.082412.full.pdf,
38,Multi-modal prediction of breast cancer using particle swarm optimization with non-dominating sorting,16,11,,"Vijayalakshmi S.,John A.,Sunder R.,Mohan Senthilkumar,Bhattacharya Sweta,Kaluri Rajesh,Feng Guang,Tariq Usman","Vijayalakshmi S,John A,Sunder R,Mohan S,Bhattacharya S,Kaluri R,Feng G,Tariq U",Feng G,10.1177/1550147720971505,Guangdong University of Technology,"Cancer is enlisted as the second leading reason for death across the world wherein almost one person out of six dies of cancer. Breast cancer is one of the most common forms of cancer predominant in women having the second highest mortality rate in the world. Various scientific studies have been conducted to combat this disease, and machine learning approaches have been an extremely popular choice. Particle swarm optimization has been identified as one of the most powerful and efficient technique for the diagnosis of breast cancer guiding physicians towards timely and accurate treatment. It is also pertinent to mention that multi-modal prediction methods are used to make decisions depending upon different scenarios and aspects whereas the non-dominating sorting feature is useful to sort different objects based on differing requirements. The main novelty of this work is multi-modal prediction algorithm for breast cancer prediction is proposed. The work encompasses the use of particle swarm optimization, non-dominating sorting and multi-classifier techniques, namely, k-nearest neighbour method, fast decision tree and kernel density estimation. Finally, Bayes' theorem is implemented for revising the results to achieve optimum accuracy in the breast cancer prediction. The proposed particle swarm optimization and non-domination sorting with classifier technique model helps to select the most significant features relevant to breast cancer predictions. The selected features design the objective of the problem model. The proposed model is implemented on the WBCD and WDBC breast cancer data sets publicly available from the UCI machine learning data repository. The metrics considered are sensitivity, specificity, accuracy and time complexity. The experimental results of the study using measures such as sensitivity, specificity, accuracy and time complexity. The experimental results of the study are evaluated against the state-of-the-art algorithms, namely, genetic algorithm kernel density estimation and particle swarm optimization kernel density estimation wherein the results justify the superiority of the proposed model.","Swarm intelligence,breast cancer,feature selection,multi-classification,Bayes&#8217,theorem,particle swarm optimization",Article,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA","Computer Science,Telecommunications",,1.476,,INTERNATIONAL JOURNAL OF DISTRIBUTED SENSOR NETWORKS,https://journals.sagepub.com/doi/pdf/10.1177/1550147720971505,
39,Synthetic minority oversampling of vital statistics data with generative adversarial networks,27,11,1667-1674,"Koivu Aki,Sairanen Mikko,Airola Antti,Pahikkala Tapio","Koivu A,Sairanen M,Airola A,Pahikkala T",Koivu A,10.1093/jamia/ocaa127,University of Turku,"Objective: Minority oversampling is a standard approach used for adjusting the ratio between the classes on imbalanced data. However, established methods often provide modest improvements in classification performance when applied to data with extremely imbalanced class distribution and to mixed-type data. This is usual for vital statistics data, in which the outcome incidence dictates the amount of positive observations. In this article, we developed a novel neural network-based oversampling method called actGAN (activation-specific generative adversarial network) that can derive useful synthetic observations in terms of increasing prediction performance in this context.
Materials and Methods: From vital statistics data, the outcome of early stillbirth was chosen to be predicted based on demographics, pregnancy history, and infections. The data contained 363 560 live births and 139 early stillbirths, resulting in class imbalance of 99.96% and 0.04%. The hyperparameters of actGAN and a baseline method SMOTE-NC (Synthetic Minority Over-sampling Technique-Nominal Continuous) were tuned with Bayesian optimization, and both were compared against a cost-sensitive learning-only approach.
Results: While SMOTE-NC provided mixed results, actGAN was able to improve true positive rate at a clinically significant false positive rate and area under the curve from the receiver-operating characteristic curve consistently.
Discussion: Including an activation-specific output layer to a generator network of actGAN enables the addition of information about the underlying data structure, which overperforms the nominal mechanism of SMOTE-NC.
Conclusions: actGAN provides an improvement to the prediction performance for our learning task. Our developed method could be applied to other mixed-type data prediction tasks that are known to be afflicted by class imbalance and limited data availability.","artificial intelligence,machine learning,deep learning,vital statistics,stillbirth",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"RISK-FACTORS,STILLBIRTH,PREDICTION,COUNTRIES",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7750982,
40,A machine learning-based clinical decision support system to identify prescriptions with a high risk of medication error,27,11,1688-1694,"Corny Jennifer,Rajkumar Asok,Martin Olivier,Dode Xavier,Lajonchere Jean-Patrick,Billuart Olivier,Bezie Yvonnick,Buronfosse Anne","Corny J,Rajkumar A,Martin O,Dode X,Lajonchere JP,Billuart O,Bezie Y,Buronfosse A",Corny J,10.1093/jamia/ocaa154,Hopital Paris Saint-Joseph,"Objective: To improve patient safety and clinical outcomes by reducing the risk of prescribing errors, we tested the accuracy of a hybrid clinical decision support system in prioritizing prescription checks.
Materials and Methods: Data from electronic health records were collated over a period of 18 months. Inferred scores at a patient level (probability of a patient's set of active orders to require a pharmacist review) were calculated using a hybrid approach (machine learning and a rule-based expert system). A clinical pharmacist analyzed randomly selected prescription orders over a 2-week period to corroborate our findings. Predicted scores were compared with the pharmacist's review using the area under the receiving-operating characteristic curve and area under the precision-recall curve. These metrics were compared with existing tools: computerized alerts generated by a clinical decision support (CDS) system and a literature-based multicriteria query prioritization technique. Data from 10 716 individual patients (133 179 prescription orders) were used to train the algorithm on the basis of 25 features in a development dataset.
Results: While the pharmacist analyzed 412 individual patients (3364 prescription orders) in an independent validation dataset, the areas under the receiving-operating characteristic and precision-recall curves of our digital system were 0.81 and 0.75, respectively, thus demonstrating greater accuracy than the CDS system (0.65 and 0.56, respectively) and multicriteria query techniques (0.68 and 0.56, respectively).
Discussion: Our innovative digital tool was notably more accurate than existing techniques (CDS system and multicriteria query) at intercepting potential prescription errors.
Conclusions: By primarily targeting high-risk patients, this novel hybrid decision support system improved the accuracy and reliability of prescription checks in a hospital setting.","electronic prescribing,clinical pharmacy information systems,medication errors,decision support systems,clinical",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"HOSPITALIZED-PATIENTS,ADVERSE,EVENTS,IMPACT",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7671619,
41,An Intelligent Augmented Reality Training Framework for Neonatal Endotracheal Intubation.,2020,,672-681,",,,,,,","Zhao Shang,Xiao Xiao,Wang Qiyue,Zhang Xiaoke,Li Wei,Soghier Lamia,Hahn James",,10.1109/ismar50242.2020.00097,,,Computing methodologiesComputer graphicsGraphics systems and interfacesMixed / augmented reality; Computing methodologiesMachine learningLearning paradigmsSupervised learning; Computing methodologiesModeling and simulationSimulation types and techniquesReal-time simulation; Human-centered computingVisualizationVisualization techniquesHeat maps,Journal Article,,,,,,,,
42,Evaluation of Automated Public De-Identification Tools on a Corpus of Radiology Reports.,2,6,e190137,",,,,","Steinkamp Jackson M,Pomeranz Taylor,Adleberg Jason,Kahn Charles E Jr,Cook Tessa S",,10.1148/ryai.2020190137,,"Purpose: To evaluate publicly available de-identification tools on a large corpus of narrative-text radiology reports.Materials and Methods: In this retrospective study, 21 categories of protected health information (PHI) in 2503 radiology reports were annotated from a large multihospital academic health system, collected between January 1, 2012 and January 8, 2019. A subset consisting of 1023 reports served as a test set; the remainder were used as domain-specific training data. The types and frequencies of PHI present within the reports were tallied. Five public de-identification tools were evaluated: MITRE Identification Scrubber Toolkit, U.S. National Library of Medicine‒Scrubber, Massachusetts Institute of Technology de-identification software, Emory Health Information DE-identification (HIDE) software, and Neuro named-entity recognition (NeuroNER). The tools were compared using metrics including recall, precision, and F1 score (the harmonic mean of recall and precision) for each category of PHI. 2020 by the Radiological Society of North America, Inc.",,Journal Article,,,,,,,,
43,Preparing Radiologists to Lead in the Era of Artificial Intelligence: Designing and Implementing a Focused Data Science Pathway for Senior Radiology Residents.,2,6,e200057,",,,,,,,","Wiggins Walter F,Caton M Travis,Magudia Kirti,Glomski Sha-Har A,George Elizabeth,Rosenthal Michael H,Gaviola Glenn C,Andriole Katherine P",,10.1148/ryai.2020200057,," 2020 by the Radiological Society of North America, Inc.",,Journal Article,,,,,,,,
44,User reactions to COVID-19 screening chatbots from reputable providers,27,11,1727-1731,"Dennis Alan R.,Kim Antino,Rahimi Mohammad,Ayabakan Sezgin","Dennis AR,Kim A,Rahimi M,Ayabakan S",Dennis AR,10.1093/jamia/ocaa167,Indiana University System,"Objectives: The objective was to understand how people respond to coronavirus disease 2019 (COVID-19) screening chatbots.
Materials and Methods: We conducted an online experiment with 371 participants who viewed a COVID-19 screening session between a hotline agent (chatbot or human) and a user with mild or severe symptoms.
Results: The primary factor driving user response to screening hotlines (human or chatbot) is perceptions of the agent's ability. When ability is the same, users view chatbots no differently or more positively than human agents. The primary factor driving perceptions of ability is the user's trust in the hotline provider, with a slight negative bias against chatbots' ability. Asian individuals perceived higher ability and benevolence than did White individuals.
Conclusions: Ensuring that COVID-19 screening chatbots provide high-quality service is critical but not sufficient for widespread adoption. The key is to emphasize the chatbot's ability and assure users that it delivers the same quality as human agents.","public health,information technology,chatbot,health screening",Article,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"TRUST,INFORMATION,HUMANNESS",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7454579,
45,A systematic literature review of automatic Alzheimer's disease detection from speech and language,27,11,1784-1797,"Petti Ulla,Baker Simon,Korhonen Anna","Petti U,Baker S,Korhonen A",Petti U,10.1093/jamia/ocaa174,University of Cambridge,"Objective: In recent years numerous studies have achieved promising results in Alzheimer's Disease (AD) detection using automatic language processing. We systematically review these articles to understand the effectiveness of this approach, identify any issues and report the main findings that can guide further research.
Materials and Methods: We searched PubMed, Ovid, and Web of Science for articles published in English between 2013 and 2019. We performed a systematic literature review to answer 5 key questions: (1) What were the characteristics of participant groups? (2) What language data were collected? (3) What features of speech and language were the most informative? (4) What methods were used to classify between groups? (5) What classification performance was achieved?
Results and Discussion: We identified 33 eligible studies and 5 main findings: participants' demographic variables (especially age ) were often unbalanced between AD and control group; spontaneous speech data were collected most often; informative language features were related to word retrieval and semantic, syntactic, and acoustic impairment; neural nets, support vector machines, and decision trees performed well in AD detection, and support vector machines and decision trees performed well in decline detection; and average classification accuracy was 89% in AD and 82% in mild cognitive impairment detection versus healthy control groups.
Conclusion: The systematic literature review supported the argument that language and speech could successfully be used to detect dementia automatically. Future studies should aim for larger and more balanced datasets, combine data collection methods and the type of information analyzed, focus on the early stages of the disease, and report performance using standardized metrics.","Alzheimer's disease,dementia,natural language processing,speech,language",Review,"OXFORD UNIV PRESS, GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND","Computer Science,Health Care Sciences & Services,Information Science & Library Science,Medical Informatics",,5.178,"MILD,COGNITIVE,IMPAIRMENT,FEATURE-SELECTION,VERBAL,FLUENCY,DIAGNOSIS",JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7671617,
46,Deep Learning and Its Application in Diabetic Retinopathy ScreeningInspec keywordsOther keywordsKey words,29,6,992-1000,"Zou Beiji,Shan Xi,Zhu Chengzhang,Dai Yulan,Yue Kejuan,Chen Yuanqiong,Xiao Yalong,Huang Jiaer","Zou BJ,Shan X,Zhu CZ,Dai YL,Yue KJ,Chen YQ,Xiao YL,Huang JE",Zhu CZ,10.1049/cje.2020.09.001,Central South University,"Deep learning (DL), especially Convolutional neural networks (CNN), has gained wide popularity in various image processing tasks. With the significant achievements obtained in DL, it has provided many successful solutions for real-world applications as well as in medical domain. Automated retinal images analysis has been widely applied to screening Diabetic retinopathy (DR), which can greatly help preventing the occurrence of complete blindness when used in the early screening. In this paper, we mainly focus on DL, and we will give an overview of the deep learning-based methods for DR screening. Finally, we will discuss the main issues encountered in the DR screening systems.","biomedical optical imaging,convolutional neural nets,diseases,eye,learning (artificial intelligence),medical image processing,reviews,complete blindness,diabetic retinopathy screening systems,deep learning,automated retinal image analysis,convolutional neural networks,Deep learning,Convolutional neural networks,Diabetic retinopathy screening,Lesion detection",Article,"TECHNOLOGY EXCHANGE LIMITED HONG KONG, BLDG#13, PUHUINANLI, SOUTH YUYUANTAN RD, HAIDIAN DIST, BEIJING, 00000, PEOPLES R CHINA",Engineering,,0.955,"VESSEL,SEGMENTATION,NEURAL-NETWORKS,IDENTIFICATION,IMAGES",CHINESE JOURNAL OF ELECTRONICS,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/cje.2020.09.001,
47,Detection of subjects with ischemic heart disease by using machine learning technique based on heart rate total variability parameters,41,11,,"Accardo Agostino,Silveri Giulia,Merlo Marco,Restivo Luca,Ajcevic Milos,Sinagra Gianfranco","Accardo A,Silveri G,Merlo M,Restivo L,Ajcevic M,Sinagra G",Silveri G,10.1088/1361-6579/abc321,University of Trieste,"Objective: Ischemic heart disease (IHD), in its chronic stable form, is a subtle pathology due to its silent behavior before developing in unstable angina, myocardial infarction or sudden cardiac death. The clinical assessment is based on typical symptoms and finally confirmed, invasively, by coronary angiography. Recently, heart rate variability (HRV) analysis as well as some machine learning algorithms like artificial neural networks (ANNs) were used to identify cardiovascular arrhythmias and, only in few cases, to classify IHD segments in a limited number of subjects. The goal of this study was the identification of the ANN structure and the HRV parameters producing the best performance to identify IHD patients in a non-invasive way, validating the results on a large sample of subjects. Moreover, we examined the influence of a clinical non-invasive parameter, the left ventricular ejection fraction (LVEF), on the classification performance. Approach: To this aim, we extracted several linear and non-linear parameters from 24 h RR signal, considering both normal and ectopic beats (heart rate total variability), of 251 normal and 245 IHD subjects, matched by age and gender. ANNs using several different combinations of these parameters together with age and gender were tested. For each ANN, we varied the number of hidden neurons from 2 to 7 and simulated 100 times, changing randomly the training and test dataset. Main results: The HRTV parameters showed significant greater variability in IHD than in normal subjects. The ANN applied to mean RR, LF, LF/HF, beta exponent, SD2 together with age and gender reached a maximum accuracy of 71.8% and, by adding as input LVEF, an accuracy of 79.8%. Significance: The study provides a deep insight into how a combination of some HRTV parameters and LVEF could be exploited to reliably detect the presence of subjects affected by IHD.","ischemic heart disease,heart rate variability,artificial neural networks,non-linear analysis,left ventricular ejection fraction",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,"CLASSIFICATION,RECOGNITION,DIAGNOSIS",PHYSIOLOGICAL MEASUREMENT,,
48,Detection of coronary artery disease using multi-modal feature fusion and hybrid feature selection,41,11,,"Zhang Huan,Wang Xinpei,Liu Changchun,Liu Yuanyuan,Li Peng,Yao Lianke,Li Han,Wang Jikuo,Jiao Yu","Zhang H,Wang XP,Liu CC,Liu YY,Li P,Yao LK,Li H,Wang JK,Jiao Y",Wang XP,10.1088/1361-6579/abc323,Shandong University,"Objective: Coronary artery disease (CAD) is a common fatal disease. At present, an accurate method to screen CAD is urgently needed. This study aims to provide optimal detection models for suspected CAD detection according to the differences in medical conditions, so as to assist physicians to make accurate judgments on suspected CAD patients. Approach: Electrocardiogram (ECG) and phonocardiogram (PCG) signals of 32 CAD patients and 30 patients with chest pain and normal coronary angiograms (CPNCA) were simultaneously collected for this paper. For each subject, the ECG and PCG multi-domain features were extracted, and the results of Holter monitoring, echocardiography (ECHO), and biomarker levels (BIO) were obtained to construct a multi-modal feature set. Then, a hybrid feature selection (HFS) method was developed using mutual information, recursive feature elimination, random forest, and weight of support vector machine to obtain the optimal feature subset. A support vector machine with nested cross-validation was used for classification. Main results: Results showed that the Holter model achieved the best performance as a single-modal feature model with an accuracy of 82.67%. In terms of multi-modal feature models, PCG-Holter, PCG-Holter-ECHO, PCG-Holter-ECHO-BIO, and ECG-PCG-Holter-ECHO-BIO were the optimal bimodal, three-modal, four-modal, and five-modal models, with accuracies of 90.38%, 91.92%, 95.25%, and 96.67%, respectively. Among them, the ECG-PCG-Holter-ECHO-BIO model, which was constructed by combining ECG and PCG signals features with Holter, ECHO, and BIO examination results, achieved the best classification results with an average accuracy, sensitivity, specificity, and F1-measure of 96.67%, 96.67%, 96.67%, and 96.64%, respectively. Significance: The study indicated that multi-modal feature fusion and HFS can obtain more effective information for CAD detection and provide a reference for physicians to diagnose CAD patients.","multi-modal feature model,hybrid feature selection,coronary artery disease,machine learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Biophysics,Engineering,Physiology",,2.866,,PHYSIOLOGICAL MEASUREMENT,,
49,Comparison of machine learning models for the detection of partial defects in spent nuclear fuel,147,,,"Rossa Riccardo,Borella Alessandro,Giani Nicola","Rossa R,Borella A,Giani N",Rossa R,10.1016/j.anucene.2020.107680,Belgian Nuclear Research Centre (SCK-CEN),"Within the framework of safeguards verifications spent nuclear fuel is a concern because it contains nuclear material. Non-destructive assays (NDA) are amongst the safeguards measures for spent fuel verification. In this work machine learning using simulated data is investigated for the detection of fuel pin diversion. Three NDA techniques (Fork, SINRD, and PDET) and two machine learning approaches (decision trees and k-nearest neighbors) are considered to classify the assemblies according to the percentage of replaced pins. These NDA techniques combine different types of neutron and gamma-ray detectors. This study found that the classification accuracies using SINRD and PDET are higher compared to Fork. In addition, k-nearest neighbors models reached higher classification accuracies compared to decision tree models, and for the considered NDA techniques the gamma-ray detectors were the most sensitive to the fuel pin diversion. (C) 2020 Elsevier Ltd. All rights reserved.","Machine learning,Decision trees,K-nearest neighbors,Spent fuel,NDA techniques,Nuclear safeguards",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND",Nuclear Science & Technology,,1.826,"NEUTRON,RESONANCE,DENSITOMETRY",ANNALS OF NUCLEAR ENERGY,,
50,Mouse livers machine learning identification based on hyperspectral x-ray computed tomography reconstructed x-ray absorption spectra,10,11,,"Fang Zheng,Zhong Shuo,Hu Weifeng,Cheng Siyuan","Fang Z,Zhong S,Hu WF,Cheng SY",Zhong S,10.1063/5.0010463,Xiamen University,"X-ray computed tomography (X-CT) is often used to examine organs, but the reconstructed images can only be used for structural identification. Whether the organs are healthy or not requires a professional doctor to examine the reconstructed image and judge from his or her own experience. The purpose of this paper is to identify the cirrhotic mouse liver and normal mouse liver with hyperspectral x-ray CT (HXCT) and machine learning. HXCT is proposed to reconstruct the x-ray absorption spectrum (XAS) characteristics of a single pixel in the reconstructed mouse liver images. HXCT uses a cadmium telluride photon counter as the x-ray detector, which can improve the spectral resolution and separate spectral lines. Filtered back-projection and algebra reconstruction technique reconstruction algorithms are used for image and XAS reconstruction. In the machine learning model, principal component analysis is utilized to reduce the dimensionality of XAS. Besides, the neural network algorithm Artificial Neural Network (ANN) is used to train and identify the reconstructed XAS of two different kinds of livers. These two different mouse livers can be well recognized since the accuracy goes to almost 100% based on ANN. It is feasible to employ the machine learning algorithm to identify the XAS of different mouse livers.","HEPATOCELLULAR-CARCINOMA,PERFORMANCE,DIAGNOSIS,CT",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Science & Technology - Other Topics,Materials Science,Physics",,1.703,"HEPATOCELLULAR-CARCINOMA,PERFORMANCE,DIAGNOSIS,CT",AIP ADVANCES,https://aip.scitation.org/doi/pdf/10.1063/5.0010463,
51,"Machine learning for aquatic plastic litter detection, classification and quantification (APLASTIC-Q)",15,11,,"Wolf Mattis,van den Berg Katelijn,Garaba Shungudzemwoyo P.,Gnann Nina,Sattler Klaus,Stahl Frederic,Zielinski Oliver","Wolf M,van den Berg K,Garaba SP,Gnann N,Sattler K,Stahl F,Zielinski O",Wolf M,10.1088/1748-9326/abbd01,German Research Center for Artificial Intelligence (DFKI),"Large quantities of mismanaged plastic waste are polluting and threatening the health of the blue planet. As such, vast amounts of this plastic waste found in the oceans originates from land. It finds its way to the open ocean through rivers, waterways and estuarine systems. Here we present a novel machine learning algorithm based on convolutional neural networks (CNNs) that is capable of detecting and quantifying floating and washed ashore plastic litter. The aquatic plastic litter detection, classification and quantification system (APLASTIC-Q) was developed and trained using very high geo-spatial resolution imagery (similar to 5 pixels cm(-1) = 0.002 m pixel(-1)) captured from aerial surveys in Cambodia. APLASTIC-Q was made up of two machine learning components (i) plastic litter detector (PLD-CNN) and (ii) plastic litter quantifier (PLQ-CNN). PLD-CNN managed to categorize targets as water, sand, vegetation and plastic litter with an 83% accuracy. It also provided a qualitative count of litter as low or high based on a thresholding approach. PLQ-CNN further distinguished and enumerated the litter items in each of the classes defined as water bottles, Styrofoam, canisters, cartons, bowls, shoes, polystyrene packaging, cups, textile, carry bags small or large. The types and amounts of plastic litter provide benchmark information that is urgently needed for decision-making by policymakers, citizens and other public and private stakeholders. Quasi-quantification was based on automated counts of items present in the imagery with caveats of underlying object in case of aggregated litter. Our scientific evidence-based machine learning algorithm has the prospects of complementing net trawl surveys, field campaigns and clean-up activities for improved quantification of plastic litter. APLASTIC-Q is a smart algorithm that is easy to adapt for fast and automated detection as well as quantification of floating or washed ashore plastic litter from aerial, high-altitude pseudo satellites and space missions.","convolutional neural networks,plastic litter,remote sensing,detection,machine learning,river and beach ecosystems,Cambodia",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Environmental Sciences & Ecology,Meteorology & Atmospheric Sciences",,7.804,"SHADOW,DETECTION,MARINE,DEBRIS,BEACH,LITTER,IMAGES",ENVIRONMENTAL RESEARCH LETTERS,http://centaur.reading.ac.uk/93708/9/Wolf_2020_Environ._Res._Lett._15_114042.pdf,
52,A screening strategy for hot forging combining high-throughput forging experiment and machine learning,7,11,,"Sun Zhiren,Wang Kaikun","Sun ZR,Wang KK",Wang KK,10.1088/2053-1591/abc4f7,University of Science & Technology Beijing,"In this study, we proposed a screening strategy of processing conditions for hot forging based on high-throughput experiment equipment, numerical simulation, and machine learning to obtain the optimal conditions for the forging process. Nikle based superalloy IN718 was selected as an application case. We designed high-throughput experiment equipment for hot forging. Numerical simulation of the forging process on the equipment was studied, and a database of 625 examples was obtained. Two BP NN models for average grain size and maximum principal stress predictions, respectively, were trained. These two BP NN models were used to search different processing conditions in searching space consisting of 1 206 000 processing conditions, and an algorithm was designed to screen the processing conditions comprehensively considering the average grain size and the maximum principal stress in the bulge zone. The optimal conditions for different forging displacements were obtained. Compared with the traditional high-cost and time-consuming trial-and-error methods, the method proposed in this paper to optimize the processing technology has significant advantages. This method can be applied to pre-screening for material design and process optimization.","hot forging,machine learning,high-throughput experiment,IN718",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Materials Science,,1.618,"METADYNAMIC,RECRYSTALLIZATION,DEFORMATION-BEHAVIOR,STRAIN-RATE,DESIGN,STEEL,MICROSTRUCTURES,TEMPERATURE,SIMULATION,IN-718,ALLOYS",MATERIALS RESEARCH EXPRESS,https://doi.org/10.1088/2053-1591/abc4f7,
53,Elinvar effect in beta-Ti simulated by on-the-fly trained moment tensor potential,22,11,,"Shapeev Alexander V,Podryabinkin Evgeny V,Gubaev Konstantin,Tasnadi Ferenc,Abrikosov Igor A.","Shapeev AV,Podryabinkin EV,Gubaev K,Tasnadi F,Abrikosov IA",Shapeev AV,10.1088/1367-2630/abc392,Skolkovo Institute of Science & Technology,"A combination of quantum mechanics calculations with machine learning techniques can lead to a paradigm shift in our ability to predict materials properties from first principles. Here we show that on-the-fly training of an interatomic potential described through moment tensors provides the same accuracy as state-of-the-art ab initio molecular dynamics in predicting high-temperature elastic properties of materials with two orders of magnitude less computational effort. Using the technique, we investigate high-temperature bcc phase of titanium and predict very weak, Elinvar, temperature dependence of its elastic moduli, similar to the behavior of the so-called GUM Ti-based alloys (Sato et al 2003 Science 300 464). Given the fact that GUM alloys have complex chemical compositions and operate at room temperature, Elinvar properties of elemental bcc-Ti observed in the wide temperature interval 1100-1700 K is unique.","machine learning,ab initio molecular dynamics,Elinvar effect,bcc titanium",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,3.741,"CENTERED-CUBIC,IRON,ALLOYS,TEMPERATURE,STABILIZATION,MECHANISM,TITANIUM",NEW JOURNAL OF PHYSICS,http://arxiv.org/pdf/2005.04375,
54,Limited-projection volumetric tomography for time-resolved turbulent combustion diagnostics via deep learning,106,,,"Huang Jianqing,Liu Hecong,Wang Qian,Cai Weiwei","Huang JQ,Liu HC,Wang Q,Cai WW",Cai WW,10.1016/j.ast.2020.106123,Shanghai Jiao Tong University,"Time-resolved volumetric tomography (VT) has been applied extensively for turbulent flow/combustion diagnostics, due to its great capacity in reconstructing three dimensional scalar/vector fields. However, it usually suffers from high computational costs of conventional iterative methods in processing thousands of tomographic frames, and also the requirement of multiple high-speed camera/intensifiers to ensure sufficient spatial sampling, resulting in high experimental costs. In this work, we aim to take the full advantage of the recent progress in deep learning algorithms and develop an inversion method which not only reduces the processing time of a single frame down to the milliseconds level but also the number of projections required without sacrificing the imaging quality. Two distinct frameworks of convolutional neural network were designed and tested for VT reconstructions of turbulent flames for the first time. The results from proof-of-concept experiments implementing computed tomography of chemiluminescence (CTC) confirmed the feasibility of our method. Our data-driven approach can expedite the reconstruction process by a factor of similar to 10(5) compared with conventional iterative methods (e.g., algebraic reconstruction technique). This work is expected to be valuable for all tomographic modalities which are seeking expedited reconstruction and reduced costs. (C) 2020 Elsevier Masson SAS. All rights reserved.","Volumetric tomography,Combustion diagnostics,Deep learning,Noise immunity",Article,"ELSEVIER FRANCE-EDITIONS SCIENTIFIQUES MEDICALES ELSEVIER, 65 RUE CAMILLE DESMOULINS, CS50083, 92442 ISSY-LES-MOULINEAUX, FRANCE",Engineering,,4.421,"FLAME,CHEMILUMINESCENCE,TOMOGRAPHY,CONVOLUTIONAL,NEURAL-NETWORKS,LASER-INDUCED,FLUORESCENCE,COMPUTED-TOMOGRAPHY,ABSORPTION-SPECTROSCOPY,REACTIVE,FLOWS,RECONSTRUCTION,KHZ,MACHINE",AEROSPACE SCIENCE AND TECHNOLOGY,,
55,Machine Learning Assisted Design of Isothermal Decomposition Parameters of U-Mo Alloy,49,11,3835-3840,"Zhang Xuewei,Kang Shidong,Wang Zhaosong,Dong Qing,Liu Wei,Dong Qiushi,Qiao Shuai,Yang Zhiyuan,Liu Zhihua,Chen Lianzhong","Zhang XW,Kang SD,Wang ZS,Dong Q,Liu W,Dong QS,Qiao S,Yang ZY,Liu ZH,Chen LZ",Zhang XW,,"China North Nucl Fuel Co Ltd, Baotou 014035, Peoples R China.","A machine learning method was applied to the rapid design of isothermal decomposition parameters of U-Mo alloys. With the hardness of the alloy as a design index, a machine learning support vector machine (SVM) model between the alloy hardness and the above parameters was established based on a small amount of data. Based on the prediction of hardness, the differences in optimization efficiency between the two types of experimental design algorithms based on predicted values and based on expected improvement were compared. The results show that the experimental design algorithm based on the expected improvement can significantly improve the hardness through a small number of iterative experiments, while the design algorithm based on the predicted value does not significantly improve the hardness. Using the above-mentioned machine learning aided design method, the optimal parameter combination for isothermal decomposition of the alloy was successfully determined through four experiments. When the aging temperature is 565 degrees C, the aging time is more than 20 h, the homogenization temperature is 900 similar to 950 degrees C, and the Mo content is 6wt%, the hardness of the alloy processed is the highest, and the powder rate is the highest. This study makes a preliminary attempt to use machine learning methods to quickly optimize U-based alloy process parameters. Such data-based methods can effectively improve the efficiency of material development.","depleted uranium alloy,U-Mo alloy,machine learning,hydride-dehydride,isothermal decomposition",Article,"NORTHWEST INST NONFERROUS METAL RESEARCH, C/O RARE METAL MATERIAL ENGINEERING PRESS, PO BOX 51, XIAN, SHAANXI 710016, PEOPLES R CHINA","Materials Science,Metallurgy & Metallurgical Engineering",,0.527,,RARE METAL MATERIALS AND ENGINEERING,,
56,Predicting Concrete's Strength by Machine Learning: Balance between Accuracy and Complexity of Algorithms,117,6,125-133,"Ouyang B.,Song Y.,Li Y.,Wu F.,Yu H.,Wang Y.,Sant G.,Bauchy M.","Ouyang B,Song Y,Li Y,Wu F,Yu H,Wang Y,Sant G,Bauchy M",Ouyang B,10.14359/51728128,University of California System,"The properties of concretes are controlled by the rate of reaction of their precursors, the chemical composition of the binding phase(s), and their structure at different scales. However, the complex and multiscale structure of the cementitious hydrates and the dissimilar rates of numerous chemical reactions make it challenging to elucidate such linkages. In particular, reliable predictions of strength development in concretes remain unavailable. As an alternative route to physics- or chemistry-based models, machine learning (ML) offers a means to develop powerful predictive models for materials using existing data. Here, it is shown that ML models can be used to accurately predict concrete's compressive strength at 28 days. This approach relies on the analysis of a large data set (>10,000 observations) of measured compressive strengths for industrially produced concretes, based on knowledge of their mixture proportions. It is demonstrated that these models can readily predict the 28-day compressive strength of any concrete based merely on the knowledge of the mixture proportions with an accuracy of approximately +/- 4.4 MPa (as captured by the root-mean-square error). By comparing the performance of select ML algorithms, the balance between accuracy, simplicity, and interpretability in ML approaches is discussed.","machine learning,modeling,strength",Article,"AMER CONCRETE INST, 38800 COUNTRY CLUB DR, FARMINGTON HILLS, MI 48331 USA","Construction & Building Technology,Materials Science",,2.177,INSIGHTS,ACI MATERIALS JOURNAL,,
57,Autonomous materials synthesis by machine learning and robotics,8,11,,"Shimizu Ryota,Kobayashi Shigeru,Watanabe Yuki,Ando Yasunobu,Hitosugi Taro","Shimizu R,Kobayashi S,Watanabe Y,Ando Y,Hitosugi T",Shimizu R; Hitosugi T,10.1063/5.0020370,Tokyo Institute of Technology,"Future materials-science research will involve autonomous synthesis and characterization, requiring an approach that combines machine learning, robotics, and big data. In this paper, we highlight our recent experiments in autonomous synthesis and resistance minimization of Nb-doped TiO2 thin films. Combining Bayesian optimization with robotics, these experiments illustrate how the required speed and volume of future big-data collection in materials science will be achieved and demonstrate the tremendous potential of this combined approach. We briefly discuss the outlook and significance of these results and advances.","DOPED ANATASE TIO2,SEARCH,FABRICATION,FILMS,OXIDE,GLASS",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Science & Technology - Other Topics,Materials Science,Physics",,4.841,"DOPED,ANATASE,TIO2,SEARCH,FABRICATION,FILMS,OXIDE,GLASS",APL MATERIALS,https://aip.scitation.org/doi/pdf/10.1063/5.0020370,
58,Deep reinforcement learning based AGVs real-time scheduling with mixed rule for flexible shop floor in industry 4.0,149,,,"Hu Hao,Jia Xiaoliang,He Qixuan,Fu Shifeng,Liu Kuo","Hu H,Jia XL,He QX,Fu SF,Liu K",Jia XL,10.1016/j.cie.2020.106749,Northwestern Polytechnical University,"Driven by the recent advances in industry 4.0 and industrial artificial intelligence, Automated Guided Vehicles (AGVs) has been widely used in flexible shop floor for material handling. However, great challenges aroused by the high dynamics, complexity, and uncertainty of the shop floor environment still exists on AGVs real-time scheduling. To address these challenges, an adaptive deep reinforcement learning (DRL) based AGVs real-time scheduling approach with mixed rule is proposed to the flexible shop floor to minimize the makespan and delay ratio. Firstly, the problem of AGVs real-time scheduling is formulated as a Markov Decision Process (MDP) in which state representation, action representation, reward function, and optimal mixed rule policy, are described in detail. Then a novel deep q-network (DQN) method is further developed to achieve the optimal mixed rule policy with which the suitable dispatching rules and AGVs can be selected to execute the scheduling towards various states. Finally, the case study based on a real-world flexible shop floor is illustrated and the results validate the feasibility and effectiveness of the proposed approach.","Automated guided vehicles,Real-time scheduling,Deep reinforcement learning,Industry 4.0",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering",,5.518,"PERFORMANCE,SIMULATION,SYSTEMS",COMPUTERS & INDUSTRIAL ENGINEERING,,
59,Real-time continuous estimation of dross attachment in the laser cutting process based on process emission images,32,4,,"Pacher Matteo,Franceschetti Luca,Strada Silvia C.,Tanelli Mara,Savaresi Sergio M.,Previtali Barbara","Pacher M,Franceschetti L,Strada SC,Tanelli M,Savaresi SM,Previtali B",Pacher M,10.2351/7.0000145,Polytechnic University of Milan,"Laser cutting of metals has become the reference manufacturing technology in sheet metal working thanks to the flexibility and the increased productivity it offers when compared with other competitive technologies. Considering, in particular, the fusion-cutting mode, i.e., when nitrogen is used as an assisting gas, different aspects contribute to the process quality among which dross attachment plays the most important role. To cope with the related time-dependent deterioration of the process quality and to obtain an online adaptation of the process parameters for different working conditions, a closed-loop dross regulation system is needed. To realize it, a reliable, continuous, and accurate estimation of the dross is mandatory. This work focuses on this challenging problem, presenting and comparing different approaches to estimate the dross attachment based on the process emission collected by a coaxial camera. Specifically, a method which relies on the accurate analysis of the process emissions for determining an effective classification method is compared with a deep-learning approach based on convolutional neural networks. The obtained results, validated in real experimental conditions, confirm the possibility to accurately estimate the presence of significant dross attachment in real-time and open the way to the design of a closed-loop control algorithm for the real-time regulation of the dross attachment formation and consequently of the process quality.","laser cutting,process monitoring,camera monitoring,dross attachment,real-time estimation,real-time",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Materials Science,Optics,Physics",,2.103,"ADAPTIVE-CONTROL,INTERRUPTION,SENSOR,EDGE",JOURNAL OF LASER APPLICATIONS,,
60,Analyzing 3D hyperspectral TOF-SIMS depth profile data using self-organizing map-relational perspective mapping,15,6,,"Gardner Wil,Winkler David A.,Ballabio Davide,Muir Benjamin W.,Pigram Paul J.","Gardner W,Winkler DA,Ballabio D,Muir BW,Pigram PJ",Pigram PJ,10.1116/6.0000614,La Trobe University,"The advantages of applying multivariate analysis to mass spectrometry imaging (MSI) data have been thoroughly demonstrated in recent decades. The identification and visualization of complex relationships between pixels in a hyperspectral data set can provide unique insights into the underlying surface chemistry. It is now recognized that most MSI data contain nonlinear relationships, which has led to increased application of machine learning approaches. Previously, we exemplified the use of the self-organizing map (SOM), a type of artificial neural network, for analyzing time-of-flight secondary ion mass spectrometry (TOF-SIMS) hyperspectral images. Recently, we developed a novel methodology, SOM-relational perspective mapping (RPM), which incorporates the algorithm RPM to improve visualization of the SOM for 2D TOF-SIMS images. Here, we use SOM-RPM to characterize and interpret 3D TOF-SIMS depth profile data, voxel-by-voxel. An organic Irganox((TM)) multilayer standard sample was depth profiled using TOF-SIMS, and SOM-RPM was used to create 3D similarity maps of the depth-profiled sample, in which the mass spectral similarity of individual voxels is modeled with color similarity. We used this similarity map to segment the data into spatial features, demonstrating that the unsupervised method meaningfully differentiated between Irganox-3114 and Irganox-1010 nanometer-thin multilayer films. The method also identified unique clusters at the surface associated with environmental exposure and sample degradation. Key fragment ions characteristic of each cluster were identified, tying clusters to their underlying chemistries. SOM-RPM has the demonstrable ability to reduce vast data sets to simple 3D visualizations that can be used for clustering data and visualizing the complex relationships within.",MULTIVARIATE-ANALYSIS,Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Biophysics,Materials Science",,2.827,MULTIVARIATE-ANALYSIS,BIOINTERPHASES,,
61,Machine learning-enabled multiplexed microfluidic sensors,14,6,,"Dabbagh Sajjad Rahmani,Rabbi Fazle,Dogan Zafer,Yetisen Ali Kemal,Tasoglu Savas","Dabbagh SR,Rabbi F,Dogan Z,Yetisen AK,Tasoglu S",Tasoglu S,10.1063/5.0025462,Koc University,"High-throughput, cost-effective, and portable devices can enhance the performance of point-of-care tests. Such devices are able to acquire images from samples at a high rate in combination with microfluidic chips in point-of-care applications. However, interpreting and analyzing the large amount of acquired data is not only a labor-intensive and time-consuming process, but also prone to the bias of the user and low accuracy. Integrating machine learning (ML) with the image acquisition capability of smartphones as well as increasing computing power could address the need for high-throughput, accurate, and automatized detection, data processing, and quantification of results. Here, ML-supported diagnostic technologies are presented. These technologies include quantification of colorimetric tests, classification of biological samples (cells and sperms), soft sensors, assay type detection, and recognition of the fluid properties. Challenges regarding the implementation of ML methods, including the required number of data points, image acquisition prerequisites, and execution of data-limited experiments are also discussed.","LOW-COST,NEURAL-NETWORKS,MICROSCOPY,POINT,RECOGNITION,PREDICTION,FRAMEWORK,VERSATILE,GENOME,THREAD",Review,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Biochemistry & Molecular Biology,Biophysics,Science & Technology - Other Topics,Physics",,3.082,"LOW-COST,NEURAL-NETWORKS,MICROSCOPY,POINT,RECOGNITION,PREDICTION,FRAMEWORK,VERSATILE,GENOME,THREAD",BIOMICROFLUIDICS,https://cdm21054.contentdm.oclc.org/digital/api/collection/IR/id/9250/download,
62,Generalizing deep whole-brain segmentation for post-contrast MRI with transfer learning,7,6,,"Bermudez Camilo,Remedios Samuel W.,Ramadass Karthik,McHugo Maureen,Heckers Stephan,Huo Yuankai,Landman Bennett A.","Bermudez C,Remedios SW,Ramadass K,McHugo M,Heckers S,Huo YK,Landman BA",Bermudez C,10.1117/1.JMI.7.6.064004,Vanderbilt University,"Purpose: Generalizability is an important problem in deep neural networks, especially with variability of data acquisition in clinical magnetic resonance imaging (MRI). Recently, the spatially localized atlas network tiles (SLANT) can effectively segment whole brain, non-contrast T1w MRI with 132 volumetric labels. Transfer learning (TL) is a commonly used domain adaptation tool to update the neural network weights for local factors, yet risks degradation of performance on the original validation/test cohorts.
Approach: We explore TL using unlabeled clinical data to address these concerns in the context of adapting SLANT to scanning protocol variations. We optimize whole-brain segmentation on heterogeneous clinical data by leveraging 480 unlabeled pairs of clinically acquired T1w MRI with and without intravenous contrast. We use labels generated on the pre-contrast image to train on the post-contrast image in a five-fold cross-validation framework. We further validated on a withheld test set of 29 paired scans over a different acquisition domain.
Results: Using TL, we improve reproducibility across imaging pairs measured by the reproducibility Dice coefficient (rDSC) between the pre- and post-contrast image. We showed an increase over the original SLANT algorithm (rDSC 0.82 versus 0.72) and the FreeSurfer v6.0.1 segmentation pipeline (rDSC = 0.53). We demonstrate the impact of this work decreasing the root-mean-squared error of volumetric estimates of the hippocampus between paired images of the same subject by 67%.
Conclusion: This work demonstrates a pipeline for unlabeled clinical data to translate algorithms optimized for research data to generalize toward heterogeneous clinical acquisitions. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE).","transfer learning,domain adaptation,clinical acquisition,deep learning,magnetic resonance imaging,domain adaptation",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"HIPPOCAMPAL,SUBFIELDS,ALZHEIMERS-DISEASE,HARMONIZATION,SUBJECT,ATLAS,VOLUMES,IMAGES,MEMORY,VIVO",JOURNAL OF MEDICAL IMAGING,,
63,Semi-automated PIRADS scoring via mpMRI analysis,7,6,,"Dhinagar Nikhil J.,Speier William,Sarma Karthik V,Raman Alex,Kinnaird Adam,Raman Steven S.,Marks Leonard S.,Arnold Corey W.","Dhinagar NJ,Speier W,Sarma KV,Raman A,Kinnaird A,Raman SS,Marks LS,Arnold CW",Dhinagar NJ,10.1117/1.JMI.7.6.064501,David Geffen School of Medicine at UCLA,"Purpose: Prostate cancer (PCa) is the most common solid organ cancer and second leading cause of death in men. Multiparametric magnetic resonance imaging (mpMRI) enables detection of the most aggressive, clinically significant PCa (csPCa) tumors that require further treatment. A suspicious region of interest (ROI) detected on mpMRI is now assigned a Prostate Imaging-Reporting and Data System (PIRADS) score to standardize interpretation of mpMRI for PCa detection. However, there is significant inter-reader variability among radiologists in PIRADS score assignment and a minimal input semi-automated artificial intelligence (AI) system is proposed to harmonize PIRADS scores with mpMRI data.
Approach: The proposed deep learning model (the seed point model) uses a simulated single-click seed point as input to annotate the lesion on mpMRI. This approach is in contrast to typical medical AI-based approaches that require annotation of the complete lesion. The mpMRI data from 617 patients used in this study were prospectively collected at a major tertiary U.S. medical center. The model was trained and validated to classify whether an mpMRI image had a lesion with a PIRADS score greater than or equal to PIRADS 4.
Results: The model yielded an average receiver-operator characteristic (ROC) area under the curve (ROC-AUC) of 0.704 over a 10-fold cross-validation, which is significantly higher than the previously published benchmark.
Conclusions: The proposed model could aid in PIRADS scoring of mpMRI, providing second reads to promote quality as well as offering expertise in environments that lack a radiologist with training in prostate mpMRI interpretation. The model could help identify tumors with a higher PIRADS for better clinical management and treatment of PCa patients at an early stage. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)","medical image analysis,prostate cancer,multiparametric magnetic resonance imaging,Prostate Imaging-Reporting and Data System,deep learning",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"SYSTEM,VERSION,2,PROSTATE-CANCER,NEURAL-NETWORKS,AGREEMENT,ACCURACY,BIOPSY",JOURNAL OF MEDICAL IMAGING,,
64,Deep Learning for Automated Feature Discovery and Classification of Sleep Stages,17,6,1835-1845,"Sokolovsky Michael,Guerrero Francisco,Paisarnsrisomsuk Sarun,Ruiz Carolina,Alvarez Sergio A.","Sokolovsky M,Guerrero F,Paisarnsrisomsuk S,Ruiz C,Alvarez SA",Ruiz C,10.1109/TCBB.2019.2912955,Worcester Polytechnic Institute,"Convolutional neural networks (CNN) have demonstrated state-of-the-art classification results in image categorization, but have received comparatively little attention for classification of one-dimensional physiological signals. We design a deep CNN architecture for automated sleep stage classiffication of human sleep EEG and EOG signals. The CNN proposed in this paper amply outperforms recent work that uses a different CNN architecture over a single-EEG-channel version of the same dataset. We show that the performance gains achieved by our network rely mainly on network depth, and not on the use of several signal channels. Performance of our approach is on par with human expert inter-scorer agreement. By examining the internal activation levels of our CNN, we find that it spontaneously discovers signal features such as sleep spindles and slow waves that figure prominently in sleep stage categorization as performed by human experts.","Sleep,Electroencephalography,Task analysis,Electrooculography,Computer architecture,Convolutional neural networks,Clinical neuroscience,sleep apnea,electrophysiology,machine learning,neural networks,feature extraction",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Biochemistry & Molecular Biology,Computer Science,Mathematics",,3.395,"ASSOCIATION,DISRUPTION,DISEASE",IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS,,
65,Post-Structuring Radiology Reports of Breast Cancer Patients for Clinical Quality Assurance,17,6,1883-1894,"Pathak Shreyasi,van Rossen Jorit,Vijlbrief Onno,Geerdink Jeroen,Seifert Christin,van Keulen Maurice","Pathak S,van Rossen J,Vijlbrief O,Geerdink J,Seifert C,van Keulen M",Pathak S,10.1109/TCBB.2019.2914678,University of Twente,"Hospitals often set protocols based on well defined standards to maintain the quality of patient reports. To ensure that the clinicians conform to the protocols, quality assurance of these reports is needed. Patient reports are currently written in free-text format, which complicates the task of quality assurance. In this paper, we present a machine learning based natural language processing system for automatic quality assurance of radiology reports on breast cancer. This is achieved in three steps: we i) identify the top-level structure (headings) of the report, ii) classify the report content into the top-level headings, and iii) convert the free-text detailed findings in the report to a semi-structured format (post-structuring). Top level structure and content of report were predicted with an F1 score of 0.97 and 0.94, respectively, using Support Vector Machine (SVM) classifiers. For automatic structuring, our proposed hierarchical Conditional Random Field (CRF) outperformed the baseline CRF with an F1 score of 0.78 versus 0.71. The determined structure of the report is represented in semi-structured XML format of the free-text report, which helps to easily visualize the conformance of the findings to the protocols. This format also allows easy extraction of specific information for other purposes such as search, evaluation, and research.","Radiology,Breast cancer,Quality assurance,Standards,Task analysis,Machine learning,Natural language processing,Quality assurance,automatic structuring,post-structuring,radiology reports,conditional random field",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Biochemistry & Molecular Biology,Computer Science,Mathematics",,3.395,"INFORMATION,EXTRACTION,FREE-TEXT",IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS,https://ris.utwente.nl/ws/files/248025986/Pathak2019post_structuring.pdf,
66,Ensembling of Gene Clusters Utilizing Deep Learning and Protein-Protein Interaction Information,17,6,2005-2016,"Dutta Pratik,Saha Sriparna,Chopra Saraansh,Miglani Varnika","Dutta P,Saha S,Chopra S,Miglani V",Dutta P,10.1109/TCBB.2019.2918523,Indian Institute of Technology (IIT) - Patna,"Cluster ensemble techniques aim to combine the outputs of multiple clustering algorithms to obtain a single consensus partitioning. The current paper reports about the development of a cluster ensemble based technique combining the concepts of multiobjective optimization and deep-learning models for gene clustering where some additional protein-protein interaction information are utilized for generating the consensus partitioning. The proposed ensemble based framework works in four phases: (i) filtering out the irrelevant genes from the microarray dataset: only the statistically significant genes are considered for further data analysis; (ii) generation of diverse base partitionings: a multi-objective optimization-based clustering technique is proposed which simultaneously optimizes three different cluster quality measures and generates a set of partitioning solutions on the Pareto optimal front; (iii) generation of a consensus partitioning: mentha scores, calculated by accessing a highly enriched protein-protein interaction archive named mentha, of different clustering solutions are considered for generating a weighted incidence matrix; (iv) finally, two approaches are used to generate a consensus partitioning from the obtained incidence matrix. The first approach is based on a traditional machine learning method, and another approach exploits the graph partitioning algorithm and two deep neural models to generate the final clustering. To validate the efficacy of the proposed ensemble framework, it is applied on five gene expression datasets. We present a comparative analysis of the proposed technique over different clustering algorithms in terms of biological homogeneity index (BHI) and biological stability index (BSI). The traditional approach attains an average 3 and 2 percent improvements over the best non-dominated solution with respect to BHI and BSI, respectively, whereas deep learning models illustrate an average 6.8 and 1.5 percent improvements over the proposed traditional approach with respect to BHI and BSI, respectively. Subsequently, Welch's t-test is executed to prove that the results obtained by the proposed methods are statistically significant. Availability of data and materials: https://github.com/sduttap16/DeepEnsm.","Proteins,Clustering algorithms,Partitioning algorithms,Deep learning,Gene expression,Protein-protein interactions,deep learning,clustering,ensemble technique",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Biochemistry & Molecular Biology,Computer Science,Mathematics",,3.395,"NEURAL-NETWORKS,VALIDITY,INDEX,EXPRESSION",IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS,,
67,Feature Extraction for Cocoa Bean Digital Image Classification Prediction for Smart Farming Application,10,11,,"Adhitya Yudhi,Prakosa Setya Widyawan,Koppen Mario,Leu Jenq-Shiou","Adhitya Y,Prakosa SW,Koppen M,Leu JS",Adhitya Y,10.3390/agronomy10111642,Kyushu Institute of Technology,"The implementation of Industry 4.0 emphasizes the capability and competitiveness in agriculture application, which is the essential framework of a country's economy that procures raw materials and resources. Human workers currently employ the traditional assessment method and classification of cocoa beans, which requires a significant amount of time. Advanced agricultural development and procedural operations differ significantly from those of several decades earlier, principally because of technological developments, including sensors, devices, appliances, and information technology. Artificial intelligence, as one of the foremost techniques that revitalized the implementation of Industry 4.0, has extraordinary potential and prospective applications. This study demonstrated a methodology for textural feature analysis on digital images of cocoa beans. The co-occurrence matrix features of the gray level co-occurrence matrix (GLCM) were compared with the convolutional neural network (CNN) method for the feature extraction method. In addition, we applied several classifiers for conclusive assessment and classification to obtain an accuracy performance analysis. Our results showed that using the GLCM texture feature extraction can contribute more reliable results than using CNN feature extraction from the final classification. Our method was implemented through on-site preprocessing within a low-performance computational device. It also helped to foster the use of modern Internet of Things (IoT) technologies among farmers and to increase the security of the food supply chain as a whole.","textural feature,co-occurrence matrix,convolutional neural network,image processing,smart farming,artificial intelligence,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Agriculture,Plant Sciences",,3.64,,AGRONOMY-BASEL,https://www.mdpi.com/2073-4395/10/11/1642/pdf,
68,Identification and mapping of soybean and maize crops based on Sentinel-2 data,13,6,171-182,"She Bao,Yang Yuying,Zhao Zhigen,Huang Linsheng,Liang Dong,Zhang Dongyan","She B,Yang YY,Zhao ZG,Huang LS,Liang D,Zhang DY",Zhang DY,10.25165/j.ijabe.20201306.6183,Anhui University,"Soybean and maize are important raw materials for the production of food and livestock feed. Accurate mapping of these two crops is of great significance to crop management, yield estimation, and crop-damage control. In this study, two towns in Guoyang County, Anhui Province, China, were selected as the study area, and Sentinel-2 images were adopted to map the distributions of both crops in the 2019 growing season. The data obtained on August 18 (early pod-setting stage of soybean) was determined to be the most applicable to soybean and maize mapping by means of the Jeffries-Matusita (JM) distance. Subsequently, three machine-learning algorithms, i.e., random forest (RF), support vector machine (SVM) and back-propagation neural network (BPNN) were employed and their respective performance in crop identification was evaluated with the aid of 254 ground truth plots. It appeared that RF with a Kappa of 0.83 was superior to the other two methods. Furthermore, twenty candidate features containing the reflectance of ten spectral bands (spatial resolution at 10 m or 20 m) and ten remote-sensing indices were input into the RF algorithm to conduct an important assessment. Seven features were screened out and served as the optimum subset, the mapping results of which were assessed based on the ground truth derived from the unmanned aerial vehicle (UAV) images covering six ground samples. The optimum feature-subset achieved high-accuracy crop mapping, with a reduction of data volume by 65% compared with the total twenty features, which also overrode the performance of ten spectral bands. Therefore, feature-optimization had great potential in the identification of the two crops. Generally, the findings of this study can provide a valuable reference for mapping soybean and maize in areas with a fragmented landscape of farmland and complex planting structure.","soybean and maize,crop identification,Sentinel-2 data,machine learning,feature selection",Article,"CHINESE ACAD AGRICULTURAL ENGINEERING, RM 506, NO 41, MAIZIDIAN ST, CHAOYANG DISTRICT, BEIJING, 100125, PEOPLES R CHINA",Agriculture,,2.137,"RANDOM,FOREST,CLASSIFICATION,CORN,CROPS,AREA,NETWORK,IMAGERY,YIELD,SCALE,BAND",INTERNATIONAL JOURNAL OF AGRICULTURAL AND BIOLOGICAL ENGINEERING,https://ijabe.org/index.php/ijabe/article/download/6183/pdf,
69,Time series of remote sensing and water deficit to predict the occurrence of soil water repellency in New Zealand pastures,169,,292-300,"Bayad Mohamed,Chau Henry Wai,Trolove Stephen,Mueller Karin,Condron Leo,Moir Jim,Yi Li","Bayad M,Chau HW,Trolove S,Muller K,Condron L,Moir J,Yi L",Chau HW,10.1016/j.isprsjprs.2020.09.024,Lincoln University,"Soil water repellency (SWR) is a natural phenomenon occurring in soils throughout the world, which impacts upon ecosystem services at multiple temporal and spatial scales (nano to ecosystem scale). In pastures, the development of SWR is primarily determined by the cycling of hydrophobic materials at the soil surface, and is controlled by climate, soil and water management, and soil properties. The complex interactions between these factors make it an intricate system to understand and model. Detailed spatiotemporal characterization of the surface moisture and biomass in pastoral ecosystems would allow for a better understanding of this phenomenon. Normalized Difference Vegetation Index (NDVI) and Synthetic Aperture Radar (SAR) backscatter are good predictors for surface biomass and soil moisture, respectively. Machine learning on remote sensing time series (TS) data shows promise to predict the occurrence of SWR in pastures. This study evaluates the ability of remote sensing TS data to predict the occurrence of SWR in New Zealand pastures, using three machine learning al- gorithms. Soil water repellency data were collected from 58 pastoral sites. Machine learning models were trained and cross-validated on a monthly aggregated remote sensing and water deficit TS data to predict SWR level. Prediction output from artificial neural networks (ANN), random forest (RF), and support vector machine (SVM) were compared using root mean squared error (RMSE). When using NDVI TS data from 58 site as predictors of SWR, SVM and RF (RMSE = 0.82 and 0.87, respectively) outperformed ANN (RMSE = 1.23). Random forest was used to map SWR magnitude over Hawke's Bay region in the North Island of New Zealand, and the overall accuracy was equal to 86%. This study is the first investigation implicating remote sensing TS data to predict the occurrence of SWR at the regional scale. Mapping the potential SWR will aid in identifying critical zones of SWR, to attenuate its effect on pastures through adapted management.","Soil water repellency,Remote sensing,Satellite image time series,Multispectral and Synthetic Aperture Radar,Water deficit,Artificial neural networks,Support vector machine",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Physical Geography,Geology,Remote Sensing,Imaging Science & Photographic Technology",,9.948,"ARTIFICIAL,NEURAL-NETWORKS,LAND-COVER,CLASSIFICATION,SPATIAL,VARIABILITY,SCALE,SORGHUM,MODELS",ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING,,
70,Surface roughness prediction of machined aluminum alloy with wire electrical discharge machining by different machine learning algorithms,9,6,12512-12524,"Ulas Mustafa,Aydur Osman,Gurgenc Turan,Ozel Cihan","Ulas M,Aydur O,Gurgenc T,Ozel C",Gurgenc T,10.1016/j.jmrt.2020.08.098,Firat University,"Aluminum alloys are preferred in aviation, aerospace and automotive industries because of their high strength and durability compared to their lightness. Precision production of parts is very important in such industries. Therefore, precision machining of aluminum, which is difficult to manufacture with traditional methods, with non-traditional methods such as wire electrical discharge machining (WEDM), is a very popular approach. Surface roughness has an impact on the important properties of materials such as strength, wear resistance and fatigue strength. Experimental determination of surface roughness of surfaces machined with WEDM is time consuming and costly. These cost and time losses can be eliminated by predicted surface roughness with machine learning algorithms. In this study, Al7075 aluminum alloy was machined with different parameters (voltage, pulse-on-time, dielectric pressure and wire feed) with WEDM. Each parameter is at 3 levels, so 81 experiments were carried out. The surface roughness of the machined surfaces was measured by surface profilometer. The lowest surface roughness was 2.490 mu m machined at 8 V voltage, 8 mu s pulse on-time, 25 bar dielectric pressure and 2 mm/min wire feed. The experiments for machining of Al7075 via WEDM were modeled by machine learning methods. Four different models of two different methods were used for the prediction of surface roughness values of machined samples with WEDM. These models were ELM, W-ELM, SVR and Q-SVR. All of the models were applied to the data set and the W-ELM model was the best performing model with the value of 0.9720 R-2. Thus, the W-ELM model has excellent potential in manufacturing industry which produced parts with WEDM. (C) 2020 The Author(s). Published by Elsevier B.V.","Wire electrical discharge machining,Surface roughness,Aluminum alloy,Machine learning,Support vector regression,Extreme learning machine",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Materials Science,Metallurgy & Metallurgical Engineering",,5.363,"SUPPORT,VECTOR,REGRESSION,ARTIFICIAL,NEURAL-NETWORK,RESIDUAL-STRESSES,EDM,PARAMETERS,WEIRS,WEDM,TIME",JOURNAL OF MATERIALS RESEARCH AND TECHNOLOGY-JMR&T,https://doi.org/10.1016/j.jmrt.2020.08.098,
71,A single-institutional experience with low dose stereotactic body radiation therapy for liver metastases,25,6,987-993,"Kowalchuk Roman O.,Waters Michael R.,Richardson K. Martin,Spencer Kelly M.,Larner James M.,Kersh C. R.","Kowalchuk RO,Waters MR,Richardson KM,Spencer KM,Larner JM,Kersh CR",Kowalchuk RO,10.1016/j.rpor.2020.09.010,University of Virginia,"Aim: This study reports a single-institutional experience treating liver metastases with stereotactic body radiation therapy (SBRT).
Materials and methods: 107 patients with 169 lesions were assessed to determine factors predictive for local control, radiographic response, and overall survival (OS). Machine learning techniques, univariate analysis, and the Kaplan-Meier method were utilized.
Results: Patients were treated with a relatively low median dose of 30 Gy in 3 fractions. Fractions were generally delivered once weekly. Median biologically effective dose (BED) was 60 Gy, and the median gross tumor volume (GTV) was 12.16 cc. Median follow-up was 7.36 months. 1-year local control was 75% via the Kaplan-Meier method. On follow-up imaging, 43%, 40%, and 17% of lesions were decreased, stable, and increased in size, respectively. 1-year OS was 46% and varied by primary tumor, with median OS of 34.3, 25.1, 12.5, and 4.6 months for ovarian, breast, colorectal, and lung primary tumors, respectively. Breast and ovarian primary patients had better OS (p < 0.0001), and lung primary patients had worse OS (p = 0.032). Higher BED values, the number of hepatic lesions, and larger GTV were not predictive of local control, radiographic response, or OS. 21% of patients suffered from treatment toxicity, but no grade >= 3 toxicity was reported.
Conclusion: Relatively low-dose SBRT for liver metastases demonstrated efficacy and minimal toxicity, even for patients with large tumors or multiple lesions. This approach may be useful for patients in whom higher-dose therapy is contraindicated or associated with high risk for toxicity. OS depends largely on the primary tumor. (C) 2020 Greater Poland Cancer Centre. Published by Elsevier B.V. All rights reserved.","Metastasis,SBRT,SABR,Liver,Dose-fractionation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,,"RADIOFREQUENCY,ABLATION,RADIOTHERAPY,RESECTION,TUMORS,TRIAL",REPORTS OF PRACTICAL ONCOLOGY AND RADIOTHERAPY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7578529,
72,A Data-Driven Approach to Predict and Classify Epileptic Seizures from Brain-Wide Calcium Imaging Video Data,17,6,1858-1870,"Zheng Jingyi,Hsieh Fushing,Ge Linqiang","Zheng JY,Hsieh F,Ge LQ",Ge LQ,10.1109/TCBB.2019.2895077,University System of Georgia,"The prediction of epileptic seizures has been an essential problem of epilepsy study. The calcium imaging video data images the whole brain-wide neurons activities with electrical discharge recorded by calcium fluorescence intensity (CFI). In this paper, using the zebrafish's brain-wide calcium image video data, we propose a data-driven approach to effectively detect the systemic change-point, and further predict the epileptic seizures. Our approach includes two phases: offline training and online testing. Specifically, during offline training, we extract features and confirm the existence of systemic change-point, then estimate the ratio of unchanged system duration to interictal period duration. For online testing, we implement a statistical model to estimate the change-point, and then predict the onset of epileptic seizure. The testing results show that our proposed approach could effectively predict the time range of future epileptic seizure. Furthermore, we explore the macroscopic patterns of epileptic and control cases, and extract features based on the pattern difference, then implement and compare the classification performance from four machine learning models. Based on the data structure, we also propose a new method to discretize related features, and combine with hierarchical clustering to better visualize and explain the pattern difference between epileptic and control cases.","Calcium,Electroencephalography,Imaging,Epilepsy,Feature extraction,Neurons,Testing,Calcium imaging video,epileptic mechanism,systemic change-point,machine learning,pattern discovery",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Biochemistry & Molecular Biology,Computer Science,Mathematics",,3.395,"EEG,SYNCHRONIZATION,CLASSIFICATION",IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS,,
73,Computerized Classification of Prostate Cancer Gleason Scores from Whole Slide Images,17,6,1871-1882,"Xu Hongming,Park Sunho,Hwang Tae Hyun","Xu HM,Park S,Hwang TH",Hwang TH,10.1109/TCBB.2019.2941195,Cleveland Clinic Foundation,"Histological Gleason grading of tumor patterns is one of the most powerful prognostic predictors in prostate cancer. However, manual analysis and grading performed by pathologists are typically subjective and time-consuming. In this paper, we present an automatic technique for Gleason grading of prostate cancer from H&E stained whole slide pathology images using a set of novel completed and statistical local binary pattern (CSLBP) descriptors. First, the technique divides the whole slide image (WSI) into a set of small image tiles, where salient tumor tiles with high nuclei densities are selected for analysis. The CSLBP texture features that encode pixel intensity variations from circularly surrounding neighborhoods are extracted from salient image tiles to characterize different Gleason patterns. Finally, the CSLBP texture features computed from all tiles are integrated and utilized by the multi-class support vector machine (SVM) that assigns patient slides with different Gleason scores such as 6, 7, or >= 8. Experiments have been performed on 312 different patient cases selected from the cancer genome atlas (TCGA) and have achieved superior performances over state-of-the-art texture descriptors and baseline methods including deep learning models for prostate cancer Gleason grading.","Prostate cancer,medical image analysis,texture features,image classification",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Biochemistry & Molecular Biology,Computer Science,Mathematics",,3.395,SELECTION,IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS,,
74,Bioimage-Based Prediction of Protein Subcellular Location in Human Tissue with Ensemble Features and Deep Networks,17,6,1966-1980,"Liu Guang-Hui,Zhang Bei-Wei,Qian Gang,Wang Bin,Mao Bo,Bichindaritz Isabelle","Liu GH,Zhang BW,Qian G,Wang B,Mao B,Bichindaritz I",Liu GH,10.1109/TCBB.2019.2917429,Nanjing University of Finance & Economics,"Prediction of protein subcellular location has currently become a hot topic because it has been proven to be useful for understanding both the disease mechanisms and novel drug design. With the rapid development of automated microscopic imaging technology in recent years, classification methods of bioimage-based protein subcellular location have attracted considerable attention for images can describe the protein distribution intuitively and in detail. In the current study, a prediction method of protein subcellular location was proposed based on multi-view image features that are extracted from three different views, including the four texture features of the original image, the global and local features of the protein extracted from the protein channel images after color segmentation, and the global features of DNA extracted from the DNA channel image. Finally, the extracted features were combined together to improve the performance of subcellular localization prediction. From the performance comparison of different combination features under the same classifier, the best ensemble features could be obtained. In this work, a classifier based on Stacked Auto-encoders and the random forest was also put forward. To improve the prediction results, the deep network was combined with the traditional statistical classification methods. Stringent cross-validation and independent validation tests on the benchmark dataset demonstrated the efficacy of the proposed method.","Proteins,Feature extraction,Biomedical imaging,Benchmark testing,DNA,Microscopy,Support vector machines,Protein subcellular location,bioimage processing,feature extraction,deep network,classifier",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Biochemistry & Molecular Biology,Computer Science,Mathematics",,3.395,"PSEUDO,NUCLEOTIDE,COMPOSITION,IDENTIFY,RECOMBINATION,SPOTS,LABEL,LEARNING,CLASSIFIER,AMINO-ACID-COMPOSITION,WEB-SERVER,PHYSICOCHEMICAL,PROPERTIES,AUTOMATED,RECOGNITION,FUSION,CLASSIFIER,TEXTURAL,FEATURES,VIRUS,PROTEINS",IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS,,
75,XGBoost Model for Chronic Kidney Disease Diagnosis,17,6,2131-2140,"Ogunleye Adeola,Wang Qing-Guo","Ogunleye A,Wang QG",Ogunleye A,10.1109/TCBB.2019.2911071,University of Johannesburg,"Chronic Kidney Disease (CKD) is a menace that is affecting 10 percent of the world population and 15 percent of the South African population. The early and cheap diagnosis of this disease with accuracy and reliability will save 20,000 lives in South Africa per year. Scientists are developing smart solutions with Artificial Intelligence (AI). In this paper, several typical and recent AI algorithms are studied in the context of CKD and the extreme gradient boosting (XGBoost) is chosen as our base model for its high performance. Then, the model is optimized and the optimal full model trained on all the features achieves a testing accuracy, sensitivity, and specificity of 1.000, 1.000, and 1.000, respectively. Note that, to cover the widest range of people, the time and monetary costs of CKD diagnosis have to be minimized with fewest patient tests. Thus, the reduced model using fewer features is desirable while it should still maintain high performance. To this end, the set-theory based rule is presented which combines a few feature selection methods with their collective strengths. The reduced model using about a half of the original full features performs better than the models based on individual feature selection methods and achieves accuracy, sensitivity and specificity, of 1.000, 1.000, and 1.000, respectively.","Diseases,Kidney,Feature extraction,Computational modeling,Sociology,Statistics,Artificial intelligence,Medical diagnosis,chronic kidney disease,artificial intelligence,extreme gradient boosting,clinical decision support system",Article,"IEEE COMPUTER SOC, 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA","Biochemistry & Molecular Biology,Computer Science,Mathematics",,3.395,"FUZZY,EXPERT-SYSTEM",IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS,,
76,Neural network model for correlating microstructural features and hardness properties of nickel-based superalloys,9,6,14467-14477,"Li Yangping,Liu Yangyi,Luo Sihua,Wang Zi,Wang Ke,Huang Zaiwang,Zhao Haifeng,Jiang Liang","Li YP,Liu YY,Luo SH,Wang Z,Wang K,Huang ZW,Zhao HF,Jiang L",Zhao HF,10.1016/j.jmrt.2020.10.042,Chinese Academy of Sciences,"In precipitation hardening metallic materials, the size and volume fraction of precipitation phases are regarded as primary microstructural parameters to control the strength instead of others. Why? In this research, a supervised learning approach was developed to correlate gamma' precipitation microstructures with hardness based on experimentally observed 483 scanning electron microscope (SEM) images comprised with different gamma' precipitates. First, up to 23 descriptors were defined and extracted numerically as training inputs from SEM images by pattern recognition techniques. Then, 10 descriptors were further selected to reduce computational cost of deep neural network (DNN) with the assistance of shallow neural network (SNN). Furthermore, to improve the accuracy of DNN, new training sets were proposed to combine these 10 descriptors with two more descriptors: area distribution and one heat treatment parameter cooling rate. In conclusion, the supervised learning approach was proven to outperform the prediction of existing physics-based constitutive models. (C) 2020 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license.","Powder metallurgy nickel base superalloys,gamma ' precipitation microstructure,Hardness,Machine learning,Deep neural network (DNN)",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Materials Science,Metallurgy & Metallurgical Engineering",,5.363,"MECHANICAL-PROPERTIES,COOLING,RATE,CLASSIFICATION,RECONSTRUCTION,PRECIPITATION,PREDICTION,COMPOSITE,STRENGTH,BEHAVIOR,SIZE",JOURNAL OF MATERIALS RESEARCH AND TECHNOLOGY-JMR&T,https://doi.org/10.1016/j.jmrt.2020.10.042,
77,Hippocampus segmentation in CT using deep learning: impact of MR versus CT-based training contours,7,6,,"Haensch Annika,Moltz Jan Hendrik,Geisler Benjamin,Engel Christiane,Klein Jan,Genghi Angelo,Schreier Jan,Morgas Tomasz,Haas Benjamin","Hansch A,Moltz JH,Geisler B,Engel C,Klein J,Genghi A,Schreier J,Morgas T,Haas B",Hansch A,10.1117/1.JMI.7.6.064001,"Fraunhofer MEVIS, Bremen, Germany.","Purpose: Hippocampus contouring for radiotherapy planning is performed on MR image data due to poor anatomical visibility on computed tomography (CT) data. Deep learning methods for direct CT hippocampus auto-segmentation exist, but use MR-based training contours. We investigate if these can be replaced by CT-based contours without loss in segmentation performance. This would remove the MR not only from inference but also from training.
Approach: The hippocampus was contoured by medical experts on MR and CT data of 45 patients. Convolutional neural networks (CNNs) for hippocampus segmentation on CT were trained on CT-based or propagated MR-based contours. In both cases, their predictions were evaluated against the MR-based contours considered as the ground truth. Performance was measured using several metrics, including Dice score, surface distances, and contour Dice score. Bayesian dropout was used to estimate model uncertainty.
Results: CNNs trained on propagated MR contours (median Dice 0.67) significantly outperform those trained on CT contours (0.59) and also experts contouring manually on CT (0.59). Differences between the latter two are not significant. Training on MR contours results in lower model uncertainty than training on CT contours. All contouring methods (manual or CNN) on CT perform significantly worse than a CNN segmenting the hippocampus directly on MR (median Dice 0.76). Additional data augmentation by rigid transformations improves the quantitative results but the difference remains significant.
Conclusions: CT-based training contours for CT hippocampus segmentation cannot replace propagated MR-based contours without significant loss in performance. However, if MR-based contours are used, the resulting segmentations outperform experts in contouring the hippocampus on CT. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI.","radiotherapy planning,hippocampus,segmentation,deep learning,training data quality",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"WHOLE-BRAIN,RADIOTHERAPY,CONFORMAL,AVOIDANCE,PRESERVATION",JOURNAL OF MEDICAL IMAGING,https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-7/issue-6/064001/Hippocampus-segmentation-in-CT-using-deep-learning--impact-of/10.1117/1.JMI.7.6.064001.pdf,
78,Method construction of structure-property relationships from data by machine learning assisted mining for materials design applications,196,,,"Dai Dongbo,Liu Qing,Hu Rui,Wei Xiao,Ding Guangtai,Xu Baoyu,Xu Tao,Zhang Jincang,Xu Yan,Zhang Huiran","Dai DB,Liu Q,Hu R,Wei X,Ding GT,Xu BY,Xu T,Zhang JC,Xu Y,Zhang HR",Zhang HR,10.1016/j.matdes.2020.109194,Shanghai University,"Data driven material research is a hot topic in the cross field of artificial intelligence and materials science. The core of new material prediction is to find the relationship between material structure and properties. In this research, machine learning will have important advantages and play an important role for materials data. In this paper,we put forward a framework combining feature engineering and linear regression to find the correlation between structure and properties from materials data. High temperature superconductor and double perovskites for solar cell swere employed to test the feasibility of the method. In the former, we successfully rebuilt a descriptor (l zeta)(-1) from data mining which is consistent with the theoretical formula. In the latter, as an exploration, we obtain a new descriptor (chi(b2)rs(x)(2)e(rsx))(-1) from data mining which expresses the heat of formation (Delta H-F) in the double perovskite. By our experiment, the method can obtain related expressions of structure-property relationship for material.The results show that the method is a simple yet efficient paradigm to construct the structure property relationship and provides valuable hints to accelerate the process of materials design. (C) 2020 The Author(s). Published by Elsevier Ltd.","Structure-property relationship,Descriptor,Machine learning,Feature engineering,Linear regression",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Materials Science,,7.097,"INFORMATICS,DISCOVERY,CHARGE",MATERIALS & DESIGN,https://doi.org/10.1016/j.matdes.2020.109194,
79,Deep Learning Based Pathology Detection for Smart Connected Healthcares,34,6,120-125,"Hossain M. Shamim,Muhammad Ghulam","Hossain MS,Muhammad G",Muhammad G,10.1109/MNET.011.2000064,King Saud University,"New generation communication technologies and advanced deep learning models present a tremendous opportunity to develop fast, accurate, and seamless distributed systems in different sectors including the healthcare sector. in this article, we suggest a smart healthcare framework consisting of a pathology detection system, which is developed using deep learning. The pathology can be detected from electroencephalogram signals of a subject. in the framework, a smart EEG headset captures EEG signals and sends them to a mobile edge computing server. The server preprocesses the signals and transmits them to a cloud server. The cloud server does the main processing using deep learning and decides on whether the subject has pathology or not. Clients and stakeholders of the framework are connected via an authentication manager located in the cloud server. Experiment results on a publicly available database confirm the appropriateness of the proposed framework.","Brain modeling,Cloud computing,Medical services,Electroencephalography,Servers,Pathology,Machine learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,8.876,"CLOUD,EDGE,NETWORKS",IEEE NETWORK,,
80,Explainable machine learning for materials discovery: predicting the potentially formable Nd-Fe-B crystal structures and extracting the structure-stability relationship,7,,1036-1047,"Pham Tien-Lam,Nguyen Duong-Nguyen,Ha Minh-Quyet,Kino Hiori,Miyake Takashi,Dam Hieu-Chi","Pham TL,Nguyen DN,Ha MQ,Kino H,Miyake T,Dam HC",Dam HC,10.1107/S2052252520010088,Japan Advanced Institute of Science & Technology (JAIST),"New Nd-Fe-B crystal structures can be formed via the elemental substitution of LA-T-X host structures, including lanthanides (LA), transition metals (T) and light elements, X = B, C, N and O. The 5967 samples of ternary LA-T-X materials that are collected are then used as the host structures. For each host crystal structure, a substituted crystal structure is created by substituting all lanthanide sites with Nd, all transition metal sites with Fe and all light-element sites with B. High-throughput first-principles calculations are applied to evaluate the phase stability of the newly created crystal structures, and 20 of them are found to be potentially formable. A data-driven approach based on supervised and unsupervised learning techniques is applied to estimate the stability and analyze the structure-stability relationship of the newly created Nd-Fe-B crystal structures. For predicting the stability for the newly created Nd-Fe-B structures, three supervised learning models: kernel ridge regression, logistic classification and decision tree model, are learned from the LA-T-X host crystal structures; the models achieved maximum accuracy and recall scores of 70.4 and 68.7%, respectively. On the other hand, our proposed unsupervised learning model based on the integration of descriptor-relevance analysis and a Gaussian mixture model achieved an accuracy and recall score of 72.9 and 82.1%, respectively, which are significantly better than those of the supervised models. While capturing and interpreting the structure-stability relationship of the Nd- Fe-B crystal structures, the unsupervised learning model indicates that the average atomic coordination number and coordination number of the Fe sites are the most important factors in determining the phase stability of the new substituted Nd-Fe-B crystal structures.","data mining,machine learning,materials informatics,first-principles calculations,new magnets",Article,"INT UNION CRYSTALLOGRAPHY, 2 ABBEY SQ, CHESTER, CH1 2HU, ENGLAND","Chemistry,Crystallography,Materials Science",,5.75,"INITIO,MOLECULAR-DYNAMICS,TOTAL-ENERGY,CALCULATIONS,ACCELERATED,SEARCH,ALGORITHM,BORIDES",IUCRJ,https://journals.iucr.org/m/issues/2020/06/00/yu5018/yu5018.pdf,
81,Deep learning-level melanoma detection by interpretable machine learning and imaging biomarker cues,25,11,,"Gareau Daniel S.,Browning James,Da Rosa Joel Correa,Suarez-Farinas Mayte,Lish Samantha,Zong Amanda M.,Firester Benjamin,Vrattos Charles,Renert-Yuval Yael,Gamboa Mauricio","Gareau DS,Browning J,Da Rosa JC,Suarez-Farinas M,Lish S,Zong AM,Firester B,Vrattos C,Renert-Yuval Y,Gamboa M",Gareau DS,10.1117/1.JBO.25.11.112906,Rockefeller University,"Significance: Melanoma is a deadly cancer that physicians struggle to diagnose early because they lack the knowledge to differentiate benign from malignant lesions. Deep machine learning approaches to image analysis offer promise but lack the transparency to be widely adopted as stand-alone diagnostics.
Aim: We aimed to create a transparent machine learning technology (i.e., not deep learning) to discriminate melanomas from nevi in dermoscopy images and an interface for sensory cue integration.
Approach: Imaging biomarker cues (IBCs) fed ensemble machine learning classifier (Eclass) training while raw images fed deep learning classifier training. We compared the areas under the diagnostic receiver operator curves.
Results: Our interpretable machine learning algorithm outperformed the leading deep-learning approach 75% of the time. The user interface displayed only the diagnostic imaging biomarkers as IBCs.
Conclusions: From a translational perspective, Eclass is better than convolutional machine learning diagnosis in that physicians can embrace it faster than black box outputs. Imaging biomarkers cues may be used during sensory cue integration in clinical screening. Our method may be applied to other image-based diagnostic analyses, including pathology and radiology. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","skin cancer classification,machine learning,imaging biomarkers,sensory cue integration,diagnostic application",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,,JOURNAL OF BIOMEDICAL OPTICS,https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-25/issue-11/112906/Deep-learning-level-melanoma-detection-by-interpretable-machine-learning-and/10.1117/1.JBO.25.11.112906.pdf,
82,Automatic detection and characterization of quantitative phase images of thalassemic red blood cells using a mask region-based convolutional neural network,25,11,,"Lin Yang-Hsien,Liao Ken Y-K,Sung Kung-Bin","Lin YH,Liao KYK,Sung KB",Sung KB,10.1117/1.JBO.25.11.116502,National Taiwan University,"Significance: Label-free quantitative phase imaging is a promising technique for the automatic detection of abnormal red blood cells (RBCs) in real time. Although deep-learning techniques can accurately detect abnormal RBCs from quantitative phase images efficiently, their applications in diagnostic testing are limited by the lack of transparency. More interpretable results such as morphological and biochemical characteristics of individual RBCs are highly desirable.
Aim: An end-to-end deep-learning model was developed to efficiently discriminate thalassemic RBCs (tRBCs) from healthy RBCs (hRBCs) in quantitative phase images and segment RBCs for single-cell characterization.
Approach: Two-dimensional quantitative phase images of hRBCs and tRBCs were acquired using digital holographic microscopy. A mask region-based convolutional neural network (Mask R-CNN) model was trained to discriminate tRBCs and segment individual RBCs. Characterization of tRBCs was achieved utilizing SHapley Additive exPlanation analysis and canonical correlation analysis on automatically segmented RBC phase images.
Results: The implemented model achieved 97.8% accuracy in detecting tRBCs. Phase-shift statistics showed the highest influence on the correct classification of tRBCs. Associations between the phase-shift features and three-dimensional morphological features were revealed.
Conclusions: The implemented Mask R-CNN model accurately identified tRBCs and segmented RBCs to provide single-RBC characterization, which has the potential to aid clinical decision-making. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","digital holographic microscopy,quantitative phase imaging,red blood cell,thalassemia,mask region-based convolutional neural network",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,"MICROSCOPY,DIAGNOSIS,DYNAMICS",JOURNAL OF BIOMEDICAL OPTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7665881,
83,The Evaluation of Radiomic Models in Distinguishing Pilocytic Astrocytoma From Cystic Oligodendroglioma With Multiparametric MRI,44,6,969-976,"Zhao Yajing,Lu Yiping,Li Xuanxuan,Zheng Yingyan,Yin Bo","Zhao YJ,Lu YP,Li XX,Zheng YY,Yin B",Yin B,10.1097/RCT.0000000000001088,Fudan University,"Purpose
To assess whether a machine-learning model based on texture features extracted from multiparametric magnetic resonance imaging could yield an accurate diagnosis in differentiating pilocytic astrocytoma from cystic oligodendrogliomas. Materials and Methods
The preoperative images from multisequences were used for tumor segmentation. Radiomic features were extracted and selected for machine-learning models. Semantic features and selected radiomic features from training data set were built, and the performance of each model was evaluated by receiver operating characteristic curve and accuracy from isolated testing data set. Results
In terms of different sequences, the best classifier was built by radiomic features extracted from enhanced T1WI-based classifier. The best model in our study turned out to be the gradient boosted trees classifier with an area under curve value of 0.99. Conclusion
Our study showed that gradient boosted trees based on texture features extracted from enhanced T1WI could become an additional tool for improving diagnostic accuracy to differentiate pilocytic astrocytoma from cystic oligodendroglioma.","machine learning,magnetic resonance imaging,pilocytic astrocytoma,oligodendrogliomas",Article,"LIPPINCOTT WILLIAMS & WILKINS, TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA","Radiology, Nuclear Medicine & Medical Imaging",,1.592,"FEATURES,OUTCOMES",JOURNAL OF COMPUTER ASSISTED TOMOGRAPHY,,
84,Identification of important factors in an inpatient fall risk prediction model to improve the quality of care using EHR and electronic administrative data: A machine-learning approach,143,,,"Lindberg David S.,Prosperi Mattia,Bjarnadottir Ragnhildur I.,Thomas Jaime,Crane Marsha,Chen Zhaoyi,Shear Kristen,Solberg Laurence M.,Snigurska Urszula Alina,Wu Yonghui","Lindberg DS,Prosperi M,Bjarnadottir RI,Thomas J,Crane M,Chen ZY,Shear K,Solberg LM,Snigurska UA,Wu YH",Lindberg DS,10.1016/j.ijmedinf.2020.104272,State University System of Florida,"Background: Inpatient falls, many resulting in injury or death, are a serious problem in hospital settings. Existing falls risk assessment tools, such as the Morse Fall Scale, give a risk score based on a set of factors, but don't necessarily signal which factors are most important for predicting falls. Artificial intelligence (AI) methods provide an opportunity to improve predictive performance while also identifying the most important risk factors associated with hospital-acquired falls. We can glean insight into these risk factors by applying classification tree, bagging, random forest, and adaptive boosting methods applied to Electronic Health Record (EHR) data.
Objective: The purpose of this study was to use tree-based machine learning methods to determine the most important predictors of inpatient falls, while also validating each via cross-validation.
Materials and methods: A case-control study was designed using EHR and electronic administrative data collected between January 1, 2013 to October 31, 2013 in 14 medical surgical units. The data contained 38 predictor variables which comprised of patient characteristics, admission information, assessment information, clinical data, and organizational characteristics. Classification tree, bagging, random forest, and adaptive boosting methods were used to identify the most important factors of inpatient fall-risk through variable importance measures. Sensitivity, specificity, and area under the ROC curve were computed via ten-fold cross validation and compared via pairwise t-tests. These methods were also compared to a univariate logistic regression of the Morse Fall Scale total score.
Results: In terms of AUROC, bagging (0.89), random forest (0.90), and boosting (0.89) all outperformed the Morse Fall Scale (0.86) and the classification tree (0.85), but no differences were measured between bagging, random forest, and adaptive boosting, at a p-value of 0.05. History of Falls, Age, Morse Fall Scale total score, quality of gait, unit type, mental status, and number of high fall risk increasing drugs (FRIDs) were considered the most important features for predicting inpatient fall risk.
Conclusions: Machine learning methods have the potential to identify the most relevant and novel factors for the detection of hospitalized patients at risk of falling, which would improve the quality of patient care, and to more fully support healthcare provider and organizational leadership decision-making. Nurses would be able to enhance their judgement to caring for patients at risk for falls. Our study may also serve as a reference for the development of AI-based prediction models of other iatrogenic conditions. To our knowledge, this is the first study to report the importance of patient, clinical, and organizational features based on the use of AI approaches.","PATIENT FALLS,ASSESSMENT-TOOL,HEALTH SYSTEM,YOUDEN INDEX,BIG DATA,INJURIES,VALIDATION,HOSPITALS,IDENTIFY,CIRCUMSTANCES",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Health Care Sciences & Services,Medical Informatics",,4.768,"PATIENT,FALLS,ASSESSMENT-TOOL,HEALTH,SYSTEM,YOUDEN,INDEX,BIG,DATA,INJURIES,VALIDATION,HOSPITALS,IDENTIFY,CIRCUMSTANCES",INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS,https://doi.org/10.1016/j.ijmedinf.2020.104272,
85,Rapid tissue oxygenation mapping from snapshot structured-light images with adversarial deep learning,25,11,,"Chen Mason T.,Durr Nicholas J.","Chen MT,Durr NJ",Durr NJ,10.1117/1.JBO.25.11.112907,Johns Hopkins University,"Significance: Spatial frequency-domain imaging (SFDI) is a powerful technique for mapping tissue oxygen saturation over a wide field of view. However, current SFDI methods either require a sequence of several images with different illumination patterns or, in the case of single-snapshot optical properties (SSOP), introduce artifacts and sacrifice accuracy.
Aim: We introduce OxyGAN, a data-driven, content-aware method to estimate tissue oxygenation directly from single structured-light images.
Approach: OxyGAN is an end-to-end approach that uses supervised generative adversarial networks. Conventional SFDI is used to obtain ground truth tissue oxygenation maps for ex vivo human esophagi, in vivo hands and feet, and an in vivo pig colon sample under 659- and 851-nm sinusoidal illumination. We benchmark OxyGAN by comparing it with SSOP and a two-step hybrid technique that uses a previously developed deep learning model to predict optical properties followed by a physical model to calculate tissue oxygenation.
Results: When tested on human feet, cross-validated OxyGAN maps tissue oxygenation with an accuracy of 96.5%. When applied to sample types not included in the training set, such as human hands and pig colon, OxyGAN achieves a 93% accuracy, demonstrating robustness to various tissue types. On average, OxyGAN outperforms SSOP and a hybrid model in estimating tissue oxygenation by 24.9% and 24.7%, respectively. Finally, we optimize OxyGAN inference so that oxygenation maps are computed similar to 10 times faster than previous work, enabling video-rate, 25-Hz imaging.
Conclusions: Due to its rapid acquisition and processing speed, OxyGAN has the potential to enable real-time, high-fidelity tissue oxygenation mapping that may be useful for many clinical applications. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","optical property,spatial frequency-domain imaging,machine learning",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,"DOMAIN,IMAGING,SFDI,OXIMETRY",JOURNAL OF BIOMEDICAL OPTICS,http://arxiv.org/pdf/2007.00760,
86,Machine learning for direct oxygen saturation and hemoglobin concentration assessment using diffuse reflectance spectroscopy,25,11,,"Fredriksson Ingemar,Larsson Marcus,Stromberg Tomas","Fredriksson I,Larsson M,Stromberg T",Fredriksson I,10.1117/1.JBO.25.11.112905,Linkoping University,"Significance: Diffuse reflectance spectroscopy (DRS) is frequently used to assess oxygen saturation and hemoglobin concentration in living tissue. Methods solving the inverse problem may include time-consuming nonlinear optimization or artificial neural networks (ANN) determining the absorption coefficient one wavelength at a time.
Aim: To present an ANN-based method that directly outputs the oxygen saturation and the hemoglobin concentration using the shape of the measured spectra as input.
Approach: A probe-based DRS setup with dual source-detector separations in the visible wavelength range was used. ANNs were trained on spectra generated from a three-layer tissue model with oxygen saturation and hemoglobin concentration as target.
Results: Modeled evaluation data with realistic measurement noise showed an absolute root-mean-square (RMS) deviation of 5.1% units for oxygen saturation estimation. The relative RMS deviation for hemoglobin concentration was 13%. This accuracy is at least twice as good as our previous nonlinear optimization method. On blood-intralipid phantoms, the RMS deviation from the oxygen saturation derived from partial oxygen pressure measurements was 5.3% and 1.6% in two separate measurement series. Results during brachial occlusion showed expected patterns.
Conclusions: The presented method, directly assessing oxygen saturation and hemoglobin concentration, is fast, accurate, and robust to noise. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","artificial neural networks,microcirculation,Monte Carlo simulations,multilayer tissue model,diffuse reflectance spectroscopy,hemoglobin oxygen saturation",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,"TISSUE,OPTICAL-PROPERTIES,ARTIFICIAL,NEURAL-NETWORKS,IN-VIVO,MODEL,ULTRAVIOLET,ABSORPTION,SPECTRA",JOURNAL OF BIOMEDICAL OPTICS,http://liu.diva-portal.org/smash/get/diva2:1515573/FULLTEXT01,
87,Deep learning in photoacoustic tomography: current approaches and future directions,25,11,,"Hauptmann Andreas,Cox Ben","Hauptmann A,Cox B",Hauptmann A,10.1117/1.JBO.25.11.112903,University of Oulu,"Biomedical photoacoustic tomography, which can provide high-resolution 3D soft tissue images based on optical absorption, has advanced to the stage at which translation from the laboratory to clinical settings is becoming possible. The need for rapid image formation and the practical restrictions on data acquisition that arise from the constraints of a clinical workflow are presenting new image reconstruction challenges. There are many classical approaches to image reconstruction, but ameliorating the effects of incomplete or imperfect data through the incorporation of accurate priors is challenging and leads to slow algorithms. Recently, the application of deep learning (DL), or deep neural networks, to this problem has received a great deal of attention. We review the literature on learned image reconstruction, summarizing the current trends and explain how these approaches fit within, and to some extent have arisen from, a framework that encompasses classical reconstruction methods. In particular, it shows how these techniques can be understood from a Bayesian perspective, providing useful insights. We also provide a concise tutorial demonstration of three prototypical approaches to learned image reconstruction. The code and data sets for these demonstrations are available to researchers. It is anticipated that it is in in vivo applications-where data may be sparse, fast imaging critical, and priors difficult to construct by hand-that DL will have the most impact. With this in mind, we conclude with some indications of possible future research directions. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","photoacoustic tomography,learned image reconstruction,deep learning,neural networks,data-driven methods,in vivo imaging",Review,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,"FREQUENCY-DOMAIN,RECONSTRUCTION,CONVOLUTIONAL,NEURAL-NETWORK,THERMOACOUSTIC,TOMOGRAPHY,IMAGE-RECONSTRUCTION,INVERSE,PROBLEMS,BLOOD,OXYGENATION,MODEL-REDUCTION,DISTRIBUTIONS,PROJECTION,ALGORITHMS",JOURNAL OF BIOMEDICAL OPTICS,http://jultika.oulu.fi/files/nbnfi-fe2020103088839.pdf,
88,Real-time video-rate perfusion imaging using multi-exposure laser speckle contrast imaging and machine learning,25,11,,"Hultman Martin,Larsson Marcus,Stromberg Tomas,Fredriksson Ingemar","Hultman M,Larsson M,Stromberg T,Fredriksson I",Hultman M,10.1117/1.JBO.25.11.116007,Linkoping University,"Significance: Multi-exposure laser speckle contrast imaging (MELSCI) estimates microcirculatory blood perfusion more accurately than single-exposure LSCI. However, the technique has been hampered by technical limitations due to massive data throughput requirements and nonlinear inverse search algorithms, limiting it to an offline technique where data must be postprocessed.
Aim: To present an MELSCI system capable of continuous acquisition and processing of MELSCI data, enabling real-time video-rate perfusion imaging with high accuracy.
Approach: The MELSCI algorithm was implemented in programmable hardware (field programmable gate array) closely interfaced to a high-speed CMOS sensor for real-time calculation. Perfusion images were estimated in real-time from the MELSCI data using an artificial neural network trained on simulated data. The MELSCI perfusion was compared to two existing single-exposure metrics both quantitatively in a controlled phantom experiment and qualitatively in vivo.
Results: The MELSCI perfusion shows higher signal dynamics compared to both single-exposure metrics, both spatially and temporally where heartbeat-related variations are resolved in much greater detail. The MELSCI perfusion is less susceptible to measurement noise and is more linear with respect to laser Doppler perfusion in the phantom experiment (R-2 = 0.992).
Conclusions: The presented MELSCI system allows for real-time acquisition and calculation of high-quality perfusion at 15.6 frames per second. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","microcirculation,perfusion,multi-exposure laser speckle contrast imaging,laser speckle contrast imaging,laser speckle contrast analysis,laser Doppler",Article,"SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS, 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA","Biochemistry & Molecular Biology,Optics,Radiology, Nuclear Medicine & Medical Imaging",,2.993,"MICROVASCULAR,BLOOD-FLOW",JOURNAL OF BIOMEDICAL OPTICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7666876,
89,Modeling the thermo-mechanical deformations of machine tool structures in CFRP material adopting data-driven prediction schemes,71,,,"Aggogeri Francesco,Merlo Angelo,Pellegrini Nicola","Aggogeri F,Merlo A,Pellegrini N",Aggogeri F,10.1016/j.mechatronics.2020.102436,University of Brescia,"The thermo-mechanical effects in machine tools (MTs) are represented by complex models since they may produce non-linear distortions overtime, impacting significantly on the machining accuracy. This paper aims to model the deformation of CFRP (Carbon-Fiber-Reinforced-Polymers) structures using data-driven schemes to predict and compensate the structural thermo-mechanical behavior. A novel study is presented to investigate the thermally-induced distortions of CFPR structural materials, selecting and positioning sensors, simulating and validating models to compensate the error in real-time. Anisotropic materials are becoming an effective solution to reduce structure mass and increase damping of a MT, nevertheless their physical complexity and the different thermal-coefficients at the interface with conventional materials may generate undesired effects, limiting the obtained advantages. The proposed strategy is based on the evaluation of a set of data-driven models simultaneously, identifying the most suitable solution and comparing finite element simulations with machine learning approach. The study is developed on a vertical axis frame made of CFRP material. The experimental validation is executed on a commercial 5-axis machine tool by varying the temperature conditions and evaluating the structural thermo-mechanical deformation effect on the Tool-Tip-Point (TTP) displacement. The thermomechanical behavior is measured by fiber Bragg grating (FBG) sensing technology embedded in the CFRP structure. Data-driven lab tests are evaluated in operational conditions during 36 h, considering: i) trainingdeployment periods (875 min interval), ii) typical machining stresses and iii) environmental perturbations. The final selected data-driven model is able to reduce the detected error lower than 10 mu m range. In particular, the achieved results indicate a congruence between the TTP displacement measured and predicted with a residual error lower than 7.0 mu m (Y-direction) using the ANN-multilayer perceptron algorithm.","Thermo-mechanical effect compensation,Data-driven models,Fiber bragg grating sensors,Machine learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Automation & Control Systems,Engineering,Robotics",,3.526,"THERMAL,ERROR,COMPENSATION,5-AXIS,MACHINE,DISTORTION,SYSTEMS",MECHATRONICS,,
90,Towards controlled synthesis of 2D crystals by chemical vapor deposition (CVD),40,,132-139,"Zhang Jing,Wang Fan,Shenoy Vivek B.,Tang Ming,Lou Jun","Zhang J,Wang F,Shenoy VB,Tang M,Lou J",Lou J,10.1016/j.mattod.2020.06.012,"Rice Univ, Dept Mat Sci & Nanoengn, Houston, TX 77251 USA.","The emergence of two-dimensional (2D) materials has captured the imagination of researchers since graphene was first exfoliated from graphite in 2004. Their exotic properties give rise to many exciting potential applications in advanced electronic, optoelectronic, energy and biomedical technologies. Scalable growth of high quality 2D materials is crucial for their adoption in technological applications the same way the arrival of high quality silicon single crystals was to the semiconductor industry. A huge amount of effort has been devoted to grow large-area, highly crystalline 2D crystals such as graphene and transition metal dichalcogenides (TMDs) through various methods. While CVD growth of wafer-scale monolayer graphene and TMDs has been demonstrated, considerable challenges still remain. In this perspective, we advocate for the focus on the crystal growth morphology as an underpinning for understanding, diagnosing and controlling the CVD process and environment for 2D material growth. Like snowflakes in nature, 2D crystals exhibit a rich variety of morphologies under different growth conditions. The mapping of crystal shapes in the growth parameter space ""encodes"" a wealth of information, the deciphering of which will lead to better understanding of the fundamental growth mechanism and materials properties. To this end, we envision a collective effort by the 2D materials community to establish the correlation between crystal shapes and the intrinsic thermodynamic and kinetic parameters for CVD reactions through integrated crystal growth experiment, database development and machine learning assisted predictive modeling, which will pave a robust path towards controlled synthesis of 2D materials and heterostructures.","Two-dimensional,Metallic nanocrystals,Renewable energy,Electrocatalysis",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Materials Science,,36.768,"MONOLAYER,MOLYBDENUM-DISULFIDE,LARGE,SINGLE-CRYSTAL,MATERIALS,INFORMATICS,CONTROLLED,GROWTH,GRAIN-BOUNDARIES,SHAPE,EVOLUTION,MOS2,FLAKES,MECHANISM,GRAPHENE,LAYERS",MATERIALS TODAY,,
91,Machine Learning Assessment of Fiber-Reinforced Polymer-Strengthened and Reinforced Concrete Members,117,6,237-251,Naser M. Z.,Naser MZ,Naser MZ,10.14359/51728073,Clemson University,"Fiber-reinforced polymers (FRPs) are often used as externally bonded systems or internal reinforcing elements to improve the performance and resilience of concrete structures. Oftentimes, the observed response of FRP-strengthened/reinforced concrete members, whether in the field or in experiments, does not match that predicted using codal provisions as such guidelines may not fully capture occurrence of complex phenomena such as debonding, or adhesive softening/cracking. To overcome such challenge, this study hypothesizes that a machine learning Mid approach can be adopted to better comprehend the behavior of FRP-strengthened/reinforced structures. This approach fuses artificial neural networks (ANNs) and genetic algorithms (GAs) to develop a new bond-slip model as well as to derive empirical expressions capable of accurately evaluating ultimate bending and shear capacity, as well as of identifying expected failure modes in FRP-strengthened/rein forred concrete structures. These expressions are developed and validated using observations obtained from over 600 experiments and hence are applicable to a wide variety of structural members and components. The proposed expressions are easy to apply (that is, in one step) and do not require tedious/iterative procedure nor advanced computing/simulation software.","bond-slip model,empirical analysis,fiber-reinforced polymer (FRP) reinforcement,fiber-reinforced polymer (FRP) strengthening,machine learning",Article,"AMER CONCRETE INST, 38800 COUNTRY CLUB DR, FARMINGTON HILLS, MI 48331 USA","Construction & Building Technology,Engineering,Materials Science",,2.239,"RC,BEAMS,SHEAR-STRENGTH,BOND,STRENGTH,FLEXURAL,PERFORMANCE,ULTIMATE,STRENGTH,SLIP,RELATIONSHIP,MATERIAL,MODELS,FRP,PLATE,BEHAVIOR,STEEL",ACI STRUCTURAL JOURNAL,,
92,Prediction of Survival and Recurrence Patterns by Machine Learning in Gastric Cancer Cases Undergoing Radiation Therapy and Chemotherapy,5,6,1179-1187,"Akcay Melek,Etiz Durmus,Celik Ozer","Akcay M,Etiz D,Celik O",Akcay M,10.1016/j.adro.2020.07.007,Eskisehir Osmangazi University,"Purpose: Radical surgery is the most important treatment modality in gastric cancer. Preoperative or postoperative radiation therapy (RT) and perioperative chemotherapy are the treatment options that should be added to surgery. This study aimed to evaluate the overall survival (OS) and recurrence patterns by machine learning in gastric cancer cases undergoing RT.
Methods and Materials: Between 2012 and 2019, the OS and recurrence patterns of 75 gastric cancer cases receiving RT f chemotherapy at the Department of Radiation Oncology were evaluated by machine learning. Logistic regression, multilayer perceptron, XGBoost, support vector classification, random forest, and Gaussian Naive Bayes (GNB) algorithms were used to predict OS, hematogenous distant metastases, and peritoneal metastases. After the correlation analysis, the backward feature selection was performed as the variable selection method, and the variables with P values less than .005 were selected.
Results: Over the median 23-month follow-up, recurrence was seen in 33 cases, and 36 patients died. The median OS was 23 (min: 7; max: 82) months, and the disease-free survival was 18 (min: 5, max: 80) months. The most common recurrence pattern was hematogenous distant metastasis, followed by peritoneal metastasis. In this study, the most successful algorithms in the prediction of OS, distant metastases, and peritoneal metastases were found to be GNB with an accuracy of 81% (95% confidence interval [CI], 0.650.97, area under the curve [AUC]: 0.89), XGBoost with 86% accuracy (95% CI, 0.74-0.97, AUC: 0.86), and random forest with 97% accuracy (95% CI, 0.92-1.00, AUC: 0.97), respectively.
Conclusions: In gastric cancer, GNB, XGBoost, and random forest algorithms were determined to be the most successful algorithms for predicting OS, distant metastases, and peritoneal metastases, respectively. To determine the most accurate algorithm and perhaps make personalized treatments applicable, more precise machine learning studies are needed with an increased number of cases in the coming years. (C) 2020 The Author(s). Published by Elsevier Inc. on behalf of American Society for Radiation Oncology.","PROGNOSTIC-FACTORS,PREOPERATIVE CHEMORADIOTHERAPY,COLORECTAL-CANCER,LYMPHOCYTE RATIO,ADENOCARCINOMA,STOMACH,THROMBOCYTOSIS,RESECTION,2ND",Article,"ELSEVIER INC, 525 B STREET, STE 1900, SAN DIEGO, CA 92101-4495 USA","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,,"PROGNOSTIC-FACTORS,PREOPERATIVE,CHEMORADIOTHERAPY,COLORECTAL-CANCER,LYMPHOCYTE,RATIO,ADENOCARCINOMA,STOMACH,THROMBOCYTOSIS,RESECTION,2ND",ADVANCES IN RADIATION ONCOLOGY,http://www.advancesradonc.org/article/S2452109420301986/pdf,
93,Combination of a Big Data Analytics Resource System With an Artificial Intelligence Algorithm to Identify Clinically Actionable Radiation Dose Thresholds for Dysphagia in Head and Neck Patients,5,6,1296-1304,"Mayo Charles S.,Mierzwa Michelle,Moran Jean M.,Matuszak Martha M.,Wilkie Joel,Sun Grace,Yao John,Weyburn Grant,Anderson Carlos J.,Owen Dawn","Mayo CS,Mierzwa M,Moran JM,Matuszak MM,Wilkie J,Sun G,Yao J,Weyburn G,Anderson CJ,Owen D",Mayo CS,10.1016/j.adro.2019.12.007,University of Michigan System,"Purpose: We combined clinical practice changes, standardizations, and technology to automate aggregation, integration, and harmonization of comprehensive patient data from the multiple source systems used in clinical practice into a big data analytics resource system (BDARS). We then developed novel artificial intelligence algorithms, coupled with the BDARS, to identify structure dose volume histograms (DVH) metrics associated with dysphagia.
Methods and Materials: From the BDARS harmonized data of >= 22,000 patients, we identified 132 patients recently treated for head and neck cancer who also demonstrated dysphagia scores that worsened from base line to a maximum grade >= 2. We developed a method that used both physical and biologically corrected (alpha/beta = 2.5) DVH curves to test both absolute and percentage volume based DVH metrics. Combining a statistical categorization algorithm with machine learning (SCA-ML) provided more extensive detailing of response threshold evidence than either approach alone. A sensitivity guided, minimum input, machine learning (ML) model was iteratively constructed to identify the key structure DVH metric thresholds.
Results: Seven swallowing structures producing 738 candidate DVH metrics were ranked for association with dysphagia using SCA-ML scoring. Structures included superior pharyngeal constrictor (SPC), inferior pharyngeal constrictor (IPC), larynx, and esophagus. Bilateral parotid and submandibular gland (SG) structures were categorized by relative mean dose (eg, SG_high, SG_low) as a dose versus tumor centric analog to contra and ipsilateral designations. Structure DVH metrics with high SCA-ML scores included the following: SPC: D20% (equivalent dose [EQD2] Gy) >= 47.7; SPC: D25% (Gy) >= 50.4; IPC: D35% (Gy) >= 61.7; parotid_low: D60% (Gy) >= 13.2; and SG_high: D35% (Gy) >= 61.7. Larynx: D25% (Gy) >= 21.2 and SG_low: D45% >= 28.2 had high SCA-ML scores but were segmented on less than 90% of plans. A model based on SPC: D20% (EQD2 Gy) alone had sensitivity and area under the curve of 0.88 +/- 0.13 and 0.74 +/- 0.17, respectively.
Conclusions: This study provides practical demonstration of combining big data with artificial intelligence to increase volume of evidence in clinical learning paradigms. (C) 2020 The Author(s). Published by Elsevier Inc. on behalf of American Society for Radiation Oncology.YY","REDUCE DYSPHAGIA,RADIOTHERAPY",Article,"ELSEVIER INC, 525 B STREET, STE 1900, SAN DIEGO, CA 92101-4495 USA","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,,"REDUCE,DYSPHAGIA,RADIOTHERAPY",ADVANCES IN RADIATION ONCOLOGY,http://www.advancesradonc.org/article/S2452109420300142/pdf,
94,Deep Temporal-Spatial Feature Learning for Motor Imagery-Based Brain-Computer Interfaces,28,11,2356-2366,"Chen Junjian,Yu Zhuliang,Gu Zhenghui,Li Yuanqing","Chen JJ,Yu ZL,Gu ZH,Li YQ",Yu ZL,10.1109/TNSRE.2020.3023417,South China University of Technology,"Motor imagery (MI) decoding is an important part of brain-computer interface (BCI) research, which translates the subject's intentions into commands that external devices can execute. The traditional methods for discriminative feature extraction, such as common spatial pattern (CSP) and filter bank common spatial pattern (FBCSP), have only focused on the energy features of the electroencephalography (EEG) and thus ignored the further exploration of temporal information. However, the temporal information of spatially filtered EEG may be critical to the performance improvement of MI decoding. In this paper, we proposed a deep learning approach termed filter-bank spatial filtering and temporal-spatial convolutional neural network (FBSF-TSCNN) for MI decoding, where the FBSF block transforms the raw EEG signals into an appropriate intermediate EEG presentation, and then the TSCNN block decodes the intermediate EEG signals. Moreover, a novel stage-wise training strategy is proposed to mitigate the difficult optimization problem of the TSCNN block in the case of insufficient training samples. Firstly, the feature extraction layers are trained by optimization of the triplet loss. Then, the classification layers are trained by optimization of the cross-entropy loss. Finally, the entire network (TSCNN) is fine-tuned by the back-propagation (BP) algorithm. Experimental evaluations on the BCI IV 2a and SMR-BCI datasets reveal that the proposed stage-wise training strategy yields significant performance improvement compared with the conventional end-to-end training strategy, and the proposed approach is comparable with the state-of-the-art method.","Electroencephalography,Training,Band-pass filters,Decoding,Feature extraction,Machine learning,Brain-computer interfaces,Motor imagery (MI),electroencephalography (EEG),deep learning,convolutional neural network (CNN),triplet loss",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"NEURAL-NETWORKS,EEG,CLASSIFICATION,EEG%2FMEG,FILTERS",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
95,Intelligent detection of building cracks based on deep learning,103,,,"Zheng Minjuan,Lei Zhijun,Zhang Kun","Zheng MJ,Lei ZJ,Zhang K",Zheng MJ,10.1016/j.imavis.2020.103987,Xi'an Shiyou University,"In order to solve the damage caused by the concrete structure, which leads to the reduction of the life of infrastructure, endangers the safety of pedestrians, and has a serious impact on the social economy, building crack detection-model of FCN (Fully Convolutional Networks), R-CNN (Regionswith CNN feature) and RFCN (Richer Fully Convolutional Networks) has been proposed based on the convolutional neural network model to amplify and extract the features of the data and previous studies. Through the training of building surface data such as roads, bridges, houses and dams, themodel is analyzed in terms ofmorphological and geometric indexes. Finally, the model of crack picture detection and segmentation based on deep learning is used for picture performance detection and comprehensive evaluation. The results show that: in the aspect of building gap detection, the RFCN model has the best processing effect, the gap recognition degree is higher, and the detail processing is better. In the aspect ofmodel evaluation index, the correct rate of RFCN model is increased by 10%, the accuracy rate is increased by 12%, the recall rate is increased by 8%, the loss rate is increased by 3%, and the overall stability is higher. In the aspect of comprehensive performance, the picture processing performance is better than the FCN model by 7% and better than the R-CNN model by 15%, and thememory share is 80%. The fusionmodel based on deep learning and picture processing has been improved in many aspects, which can provide strong theoretical support and practical value for the detection and research of concrete surface cracks such as bridges, dams, highways and houses. (c) 2020 Elsevier B.V. All rights reserved.","Deep learning,Building crack detection,Multi-feature fusion,Image segmentation,RFCN,FCN,R-CNN",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Engineering,Optics",,3.069,,IMAGE AND VISION COMPUTING,,
96,Artificial intelligence (AI) in urology-Current use and future directions: An iTRUE study,46,,S27-S39,"Shah Milap,Naik Nithesh,Somani Bhaskar K.,Hameed B. M. Zeeshan","Shah M,Naik N,Somani BK,Hameed BMZ",Hameed BMZ,10.5152/tud.2020.20117,Manipal Academy of Higher Education (MAHE),"Objective: Artificial intelligence (AI) is used in various urological conditions such as urolithiasis, pediatric urology, urogynecology, benign prostate hyperplasia (BPH), renal transplant, and uro-oncology. The various models of AI and its application in urology subspecialties are reviewed and discussed.
Material and methods: Search strategy was adapted to identify and review the literature pertaining to the application of AI in urology using the keywords ""urology,"" ""artificial intelligence,"" ""machine learning,"" ""deep learning,"" ""artificial neural networks,"" ""computer vision,"" and ""natural language processing"" were included and categorized. Review articles, editorial comments, and non-urologic studies were excluded.
Results: The article reviewed 47 articles that reported characteristics and implementation of AI in urological cancer. In all cases with benign conditions, artificial intelligence was used to predict outcomes of the surgical procedure. In urolithiasis, it was used to predict stone composition, whereas in pediatric urology and BPH, it was applied to predict the severity of condition. In cases with malignant conditions, it was applied to predict the treatment response, survival, prognosis, and recurrence on the basis of the genomic and biomarker studies. These results were also found to be statistically better than routine approaches. Application of radiomics in classification and nuclear grading of renal masses, cystoscopic diagnosis of bladder cancers, predicting Gleason score, and magnetic resonance imaging with computer-assisted diagnosis for prostate cancers are few applications of AI that have been studied extensively.
Conclusions: In the near future, we will see a shift in the clinical paradigm as AI applications will find their place in the guidelines and revolutionize the decision-making process.","Artificial intelligence,deep learning,machine learning,prostate cancer,urolithiasis,urology",Review,"AVES, BUYUKDERE CAD 105-9, MECIDIYEKOY, SISLI, ISTANBUL 34394, TURKEY",Urology & Nephrology,,,"TEXTURE,ANALYSIS,COMPUTED-TOMOGRAPHY,PROSTATE-CANCER,NEURAL-NETWORKS,MACHINE,PREDICTION,CARCINOMA,OBSTRUCTION,BIOPSIES,BENIGN",TURKISH JOURNAL OF UROLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7731952,
97,Investigation of fractional models of damping material by a neuroevolutionary approach,140,,,"Waseem Waseem,Sulaiman M.,Aljohani Abdulah Jeza","Waseem W,Sulaiman M,Aljohani AJ",Sulaiman M,10.1016/j.chaos.2020.110198,"Abdul Wali Khan Univ Mardan, Dept Math, Mardan, KP, Pakistan.","This research paper deals with a problem related to the damped materials contained in structural dynamics. The problem dealt with here involves a fractional-order damping coefficient in the form of fractional derivatives that present a better mathematical model of the vibration systems. Fractional derivatives are widely used to characterize the viscoelastic features in structural designs. Unlike the integer order differentiation, fractional-order derivatives consider local as well as the global evolution of the system. Therefore, fractional differential equations can be indicated as a reasonable choice for modeling certain physical phenomena, and to present more accurate mathematical solutions to real-world applications than the ordinary differential equations. We have proposed a novel unsupervised machine learning procedure that first designs general solutions, with the help of Artificial Neural Networks (ANNs), for the fractional-order differential equation containing unknown decision weights. These weights are worked out with the help of Fractional-Order Darwinian Particle Swarm Optimization (FO-DPSO) algorithm by setting a fitness function for each case. Results obtained from our simulations are better in the sense that they are overlapping with the analytical solutions available in the literature. (c) 2020 Elsevier Ltd. All rights reserved.","Fractional calculus,Damping materials,Viscoelastic dynamical systems,Fractional order Darwinian particle swarm optimizer,Bagley and Torvik model,Artificial neural networks",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Mathematics,Physics",,4.415,,CHAOS SOLITONS & FRACTALS,,
98,The study of the differences between low-functioning autistic children and typically developing children in the processing of the own-race and other-race faces by the machine learning approach,81,,54-60,"Kang Jiannan,Han Xiaoya,Hu Jon-Fan,Feng Hua,Li Xiaoli","Kang JN,Han XY,Hu JF,Feng H,Li XL",Li XL,10.1016/j.jocn.2020.09.039,Beijing Normal University,"Objective: Autism spectrum disorder (ASD) is a heterogeneous neurodevelopmental disorder which affects the developmental trajectory in several behavioral domains, including impairments of social communication and stereotyped behavior. Unlike typically developing children who can successfully obtain the detailed facial information to decode the mental status with ease, autistic children cannot infer instant feelings and thoughts of other people due to their abnormal face processing. In the present study, we tested the other-race face, the own-race strange face and the own-race familiar face as stimuli material to explore whether ASD children would display different face fixation patterns for the different types of face compared to TD children. We used a machine learning approach based on eye tracking data to classify autistic children and TD children.
Methods: Seventy-seven low-functioning autistic children and eighty typically developing children were recruited. They were required to watch a series face photos in a random order. According to the coordinate frequency distribution, the K-means clustering algorithm divided the image into 64 Area Of Interest (AOI) and selected the features using the minimal redundancy and maximal relevance (mRMR) algorithm. The Support Vector Machine (SVM) was used to classify to determine whether the scan patterns of different faces can be used to identify ASD, and to evaluate classification models from both accuracy and reliability.
Results: The results showed that the maximum classification accuracy was 72.50% (AUC = 0.77) when 32 of the 64 features of unfamiliar other-race faces were selected; the maximum classification accuracy was 70.63% (AUC = 0.76) when 18 features of own-race strange faces were selected; the maximum classification accuracy was 78.33% (AUC = 0.84) when 48 features of own-race familiar faces were selected; The classification accuracy of combining three types of faces reached a maximum of 84.17% and AUC = 0.89 when 120 features were selected.
Conclusions: There are some differences between low-functioning autistic children and typically developing children in the processing of the own-race and other-race faces by the machine learning approach, which might be a useful tool for classifying low-functioning autistic children and TD children. (C) 2020 Elsevier Ltd. All rights reserved.","Autism,Children,Eye tracking,Machine learning,Face processing",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Neurosciences & Neurology,,,"SPECTRUM,DISORDER,UNAFFECTED,SIBLINGS,ATTENTION",JOURNAL OF CLINICAL NEUROSCIENCE,,
99,A semi-supervised approach to architected materials design using graph neural networks,41,,,"Guo Kai,Buehler Markus J.","Guo K,Buehler MJ",Buehler MJ,10.1016/j.eml.2020.101029,Massachusetts Institute of Technology (MIT),"Recent breakthroughs in artificial intelligence (AI) afford opportunities for new paradigms for material design and optimization. For modeling-driven design approaches, the optimization of mechanical properties, in general, requires boundary value problems (BVPs) to be solved. Machine learning (ML) models, trained on high-throughput labeled data obtained from the solution of BVPs, are able to explore and exploit vast design spaces. Nevertheless, prior to the implementation of those methods, applied load and displacement constraints have to be known beforehand. Here, we present a semi-supervised approach to design topological structures of architected materials based on the load levels of only 1% of nodes, along with the connectivity and mechanical properties of the architected materials. Graph neural networks (GNNs), which can learn graph embeddings and show outstanding performance on semi-supervised classification tasks using small amount of data, have been used to predict the distribution of the load levels of the remaining 99%. The integration of the network with an algorithm to redistribute truss thickness enables us to perform multiscale design of architected materials under various geometries and loads. This work reveals the potential of a novel paradigm to design architected materials via semi-supervised learning, and inspires applications such as using sparse sensors in truss designs in additive manufacturing, architectures and civil infrastructure under complex loading conditions. (C) 2020 Elsevier Ltd. All rights reserved.","Artificial intelligence,Machine learning,Graph neural network,Semi-supervised learning,Materiomics,Multiscale mechanics,Mechanics,Truss,Structures",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science,Mechanics",,5.532,SELF,EXTREME MECHANICS LETTERS,,
100,Machine learning-based design and optimization of curved beams for multistable structures and metamaterials,41,,,"Liu Fan,Jiang Xihang,Wang Xintao,Wang Lifeng","Liu F,Jiang XH,Wang XT,Wang LF",Wang LF,10.1016/j.eml.2020.101002,State University of New York (SUNY) System,"Curved beams have been wildly used in MEMS (Micro-electromechanical systems) devices and energy absorption materials owing to its bistability. Almost all curved beams in previous studies have a constant thickness. Although better performance can be achieved by changing the thickness distribution, such as beams of uniform strength, lack of design and optimization tool limits the development and application of curved beams with varying thickness. In this paper, we demonstrate a new approach to design and optimize curved beams based on machine learning, which has been successful in many fields owing to its ability to process big data that can also be used in structural design and optimization. This machine learning-based model is able to achieve accurate predictions of nonlinear structure-property relationships. The optimized designs with different optimization objectives, such as stiffness, forward snapping force, and backward snapping force, are obtained efficiently and precisely. Experimental testing is conducted on specimens with optimized profiles, which are fabricated using a high-resolution multi-material 3D printer. The computational results are validated by the experimental results. The machine learning-based optimization approach developed here can provide a promising tool for the design and optimization of beam-based structures and mechanical metamaterials. (C) 2020 Published by Elsevier Ltd.","Structural optimization,Machine learning,Curved beam,Bistable,Metamaterials",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science,Mechanics",,5.532,"SHAPE,OPTIMIZATION",EXTREME MECHANICS LETTERS,,
