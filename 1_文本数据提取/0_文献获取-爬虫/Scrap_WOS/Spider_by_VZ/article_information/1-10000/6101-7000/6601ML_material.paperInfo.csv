,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Machine learning generative models for automatic design of multi-material 3D printed composite solids,41,,,"Xue Tianju,Wallin Thomas J.,Menguc Yigit,Adriaenssens Sigrid,Chiaramonte Maurizio","Xue TJ,Wallin TJ,Menguc Y,Adriaenssens S,Chiaramonte M",Xue TJ,10.1016/j.eml.2020.100992,Princeton University,"Mechanical metamaterials are artificial structures that exhibit unusual mechanical properties at the macroscopic level due to architected geometric design at the microscopic level. With rapid advancement of multi-material 3D printing techniques, it is possible to design mechanical metamaterials by varying spatial distributions of different base materials within a representative volume element (RVE), which is then periodically arranged into a lattice structure. The design problem is challenging, however, considering the wide design space of potentially infinitely many configurations of multi-material RVEs. We propose an optimization framework that automates the design flow. We adopt variational autoencoder (VAE), a machine learning generative model to learn a latent, reduced representation of a given RVE configuration. The reduced design space allows to perform Bayesian optimization (BayesOpt), a sequential optimization strategy, for the multi-material design problems. In this work, we select two base materials with distinct elastic moduli and use the proposed optimization scheme to design a composite solid that achieves a prescribed set of macroscopic elastic moduli. We fabricated optimal samples with multi-material 3D printing and performed experimental validation, showing that the optimization framework is reliable. (C) 2020 Elsevier Ltd. All rights reserved.","Mechanical metamaterial,Machine learning,3D printing",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Engineering,Materials Science,Mechanics",,5.532,,EXTREME MECHANICS LETTERS,,
2,Cellular morphological features are predictive markers of cancer cell state,126,,,"Alizadeh Elaheh,Castle Jordan,Quirk Analia,Taylor Cameron D. L.,Xu Wenlong,Prasad Ashok","Alizadeh E,Castle J,Quirk A,Taylor CDL,Xu WL,Prasad A",Prasad A,10.1016/j.compbiomed.2020.104044,"Dept Chem & Biol Engn, Ft Collins, CO 80523 USA.","Even genetically identical cells have heterogeneous properties because of stochasticity in gene or protein expression. Single cell techniques that assay heterogeneous properties would be valuable for basic science and diseases like cancer, where accurate estimates of tumor properties is critical for accurate diagnosis and grading. Cell morphology is an emergent outcome of many cellular processes, potentially carrying information about cell properties at the single cell level. Here we study whether morphological parameters are sufficient for classification of single cells, using a set of 15 cell lines, representing three processes: (i) the transformation of normal cells using specific genetic mutations; (ii) metastasis in breast cancer and (iii) metastasis in osteosarcomas. Cellular morphology is defined as quantitative measures of the shape of the cell and the structure of the actin. We use a toolbox that calculates quantitative morphological parameters of cell images and apply it to hundreds of images of cells belonging to different cell lines. Using a combination of dimensional reduction and machine learning, we test whether these different processes have specific morphological signatures and whether single cells can be classified based on morphology alone. Using morphological parameters we could accurately classify cells as belonging to the correct class with high accuracy. Morphological signatures could distinguish between cells that were different only because of a different mutation on a parental line. Furthermore, both oncogenesis and metastasis appear to be characterized by stereotypical morphology changes. Thus, cellular morphology is a signature of cell phenotype, or state, at the single cell level.","Cell morphology,Metastasis,Cell shape,Machine learning,Cytoskeletal structure,Actin",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"GEOMETRIC,CONTROL,SHAPE,METASTASIS,DIFFERENTIATION,VARIABILITY,RELIABILITY,PERSPECTIVE,SURVIVAL,LINE",COMPUTERS IN BIOLOGY AND MEDICINE,http://manuscript.elsevier.com/S0010482520303759/pdf/S0010482520303759.pdf,
3,Multi-task deep learning based CT imaging analysis for COVID-19 pneumonia: Classification and segmentation,126,,,"Amyar Amine,Modzelewski Romain,Li Hua,Ruan Su","Amyar A,Modzelewski R,Li H,Ruan S",Amyar A,10.1016/j.compbiomed.2020.104037,General Electric,"This paper presents an automatic classification segmentation tool for helping screening COVID-19 pneumonia using chest CT imaging. The segmented lesions can help to assess the severity of pneumonia and follow-up the patients. In this work, we propose a new multitask deep learning model to jointly identify COVID-19 patient and segment COVID-19 lesion from chest CT images. Three learning tasks: segmentation, classification and reconstruction are jointly performed with different datasets. Our motivation is on the one hand to leverage useful information contained in multiple related tasks to improve both segmentation and classification performances, and on the other hand to deal with the problems of small data because each task can have a relatively small dataset. Our architecture is composed of a common encoder for disentangled feature representation with three tasks, and two decoders and a multi-layer perceptron for reconstruction, segmentation and classification respectively. The proposed model is evaluated and compared with other image segmentation techniques using a dataset of 1369 patients including 449 patients with COVID-19, 425 normal ones, 98 with lung cancer and 397 of different kinds of pathology. The obtained results show very encouraging performance of our method with a dice coefficient higher than 0.88 for the segmentation and an area under the ROC curve higher than 97% for the classification.","Deep learning,Multitask learning,Image classification,Image segmentation,Coronavirus (COVID-19),Computed tomography images",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"CONVOLUTIONAL,NEURAL-NETWORK",COMPUTERS IN BIOLOGY AND MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7543793,
4,Acoustic feature based unsupervised approach of heart sound event detection,126,,,"Das Sangita,Pal Saurabh,Mitra Madhuchhanda","Das S,Pal S,Mitra M",Mitra M,10.1016/j.compbiomed.2020.103990,University of Calcutta,"This paper represents an unsupervised approach to detect the positions of S1, S2 heart sound events in a Phonocardiogram (PCG) recording. Insufficiency of correctly annotated heart sound database drives us to investigate unsupervised techniques. Gammatone filter bank features are used to characterize the spectral pattern of fundamental heart sound events from noise contaminated PCG data. An unsupervised spectral clustering technique is employed for segmentation of S1/S2 and non-S1/S2 heart sound events. A Feature winning score is computed to identify the S1/52 and non-S1/S2 frames. Finally, time based threshold is applied to detect the accurate positions of S1 and S2 heart sounds. The performance of spectral clustering is compared with other clustering methods. The proposed method offers a maximum Fl-score of 98% and 92.5% for normal and abnormal PCG data respectively on 2016 PhysioNet/CinC challenge dataset. The heart sound annotation algorithm provided by PhysioNet has been used as the ground truth after hand correction.","Heart sound,Phonocardiogram (PCG),Spectral clustering,Heart sound segmentation",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"NEURAL-NETWORK,CLASSIFICATION,SEGMENTATION,RECOGNITION,NOISE,IDENTIFICATION,SEPARATION,IMAGE",COMPUTERS IN BIOLOGY AND MEDICINE,,
5,Assisting Barrett's esophagus identification using endoscopic data augmentation based on Generative Adversarial Networks,126,,,"de Souza Jr Luis A.,Passos Leandro A.,Mendel Robert,Ebigbo Alanna,Probst Andreas,Messmann Helmut,Palm Christoph,Papa Joao P.","de Souza LA,Passos LA,Mendel R,Ebigbo A,Probst A,Messmann H,Palm C,Papa JP",Papa JP,10.1016/j.compbiomed.2020.104029,Universidade Estadual Paulista,"Barrett's esophagus figured a swift rise in the number of cases in the past years. Although traditional diagnosis methods offered a vital role in early-stage treatment, they are generally time- and resource-consuming. In this context, computer-aided approaches for automatic diagnosis emerged in the literature since early detection is intrinsically related to remission probabilities. However, they still suffer from drawbacks because of the lack of available data for machine learning purposes, thus implying reduced recognition rates. This work introduces Generative Adversarial Networks to generate high-quality endoscopic images, thereby identifying Barrett's esophagus and adenocarcinoma more precisely. Further, Convolution Neural Networks are used for feature extraction and classification purposes. The proposed approach is validated over two datasets of endoscopic images, with the experiments conducted over the full and patch-split images. The application of Deep Convolutional Generative Adversarial Networks for the data augmentation step and LeNet-5 and AlexNet for the classification step allowed us to validate the proposed methodology over an extensive set of datasets (based on original and augmented sets), reaching results of 90% of accuracy for the patch-based approach and 85% for the image-based approach. Both results are based on augmented datasets and are statistically different from the ones obtained in the original datasets of the same kind. Moreover, the impact of data augmentation was evaluated in the context of image description and classification, and the results obtained using synthetic images outperformed the ones over the original datasets, as well as other recent approaches from the literature. Such results suggest promising insights related to the importance of proper data for the accurate classification concerning computerassisted Barrett's esophagus and adenocarcinoma detection.","Barrett's esophagus,Machine learning,Adenocarcinoma,Generative adversarial networks",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"ADENOCARCINOMA,DYSPLASIA",COMPUTERS IN BIOLOGY AND MEDICINE,,
6,A comparative study of pre-trained convolutional neural networks for semantic segmentation of breast tumors in ultrasound,126,,,"Gomez-Flores Wilfrido,de Albuquerque Pereira Wagner Coelho","Gomez-Flores W,Pereira WCD",Gomez-Flores W,10.1016/j.compbiomed.2020.104036,"Inst Politecn Nacl, Unidad Tamaulipas, Ctr Invest & Estudios Avanzados, Ciudad Victoria, Tamaulipas, Mexico.","The automatic segmentation of breast tumors in ultrasound (BUS) has recently been addressed using convolutional neural networks (CNN). These CNN-based approaches generally modify a previously proposed CNN architecture or they design a new architecture using CNN ensembles. Although these methods have reported satisfactory results, the trained CNN architectures are often unavailable for reproducibility purposes. Moreover, these methods commonly learn from small BUS datasets with particular properties, which limits generalization in new cases. This paper evaluates four public CNN-based semantic segmentation models that were developed by the computer vision community, as follows: (1) Fully Convolutional Network (FCN) with AlexNet network, (2) U-Net network, (3) SegNet using VGG16 and VGG19 networks, and (4) DeepLabV3+ using ResNetl8, ResNet50, MobileNet-V2, and Xception networks. By transfer learning, these CNNs are fine-tuned to segment BUS images in normal and tumoral pixels. The goal is to select a potential CNN-based segmentation model to be further used in computer-aided diagnosis (CAD) systems. The main significance of this study is the comparison of eight well-established CNN architectures using a more extensive BUS dataset than those used by approaches that are currently found in the literature. More than 3000 BUS images acquired from seven US machine models are used for training and validation. The F1-score (F1s) and the Intersection over Union (IoU) quantify the segmentation performance. The segmentation models based on SegNet and DeepLabV3+ obtain the best results with F1s > 0.90 and IoU > 0.81. In the case of U-Net, the segmentation performance is F1s = 0.89 and IoU = 0.80, whereas FCN-AlexNet attains the lowest results with F1s = 0.84 and IoU = 0.73. In particular, ResNetl8 obtains F1s = 0.905 and IoU = 0.827 and requires less training time among SegNet and DeepLabV3+ networks. Hence, ResNetl8 is a potential candidate for implementing fully automated end-to-end CAD systems. The CNN models generated in this study are available to researchers at https://github.com/wgomezf/CNN-BUS-segment, which attempts to impact the fair comparison with other CNN-based segmentation approaches for BUS images.","Breast ultrasound,Breast tumors,Convolutional neural networks,Semantic segmentation,Transfer learning",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"COMPUTER-AIDED,DIAGNOSIS,LESIONS,AGE",COMPUTERS IN BIOLOGY AND MEDICINE,,
7,Artificial intelligence framework for predictive cardiovascular and stroke risk assessment models: A narrative review of integrated approaches using carotid ultrasound,126,,,"Jamthikar Ankush D.,Gupta Deep,Saba Luca,Khanna Narendra N.,Viskovic Klaudija,Mavrogeni Sophie,Laird John R.,Sattar Naveed,Johri Amer M.,Pareek Gyan","Jamthikar AD,Gupta D,Saba L,Khanna NN,Viskovic K,Mavrogeni S,Laird JR,Sattar N,Johri AM,Pareek G",Suri JS,10.1016/j.compbiomed.2020.104043,"AtheroPoint, Stroke Monitoring & Diagnost Div, Roseville, CA 95661 USA.","Recent findings: Cardiovascular disease (CVD) is the leading cause of mortality and poses challenges for healthcare providers globally. Risk-based approaches for the management of CVD are becoming popular for recommending treatment plans for asymptomatic individuals. Several conventional predictive CVD risk models based do not provide an accurate CVD risk assessment for patients with different baseline risk profiles. Artificial intelligence (AI) algorithms have changed the landscape of CVD risk assessment and demonstrated a better performance when compared against conventional models, mainly due to its ability to handle the input nonlinear variations. Further, it has the flexibility to add risk factors derived from medical imaging modalities that image the morphology of the plaque. The integration of noninvasive carotid ultrasound image-based phenotypes with conventional risk factors in the AI framework has further provided stronger power for CVD risk prediction, so-called ""integrated predictive CVD risk models.""
Purpose: of the review: The objective of this review is (i) to understand several aspects in the development of predictive CVD risk models, (ii) to explore current conventional predictive risk models and their successes and challenges, and (iii) to refine the search for predictive CVD risk models using noninvasive carotid ultrasound as an exemplar in the artificial intelligence-based framework.
Conclusion: Conventional predictive CVD risk models are suboptimal and could be improved. This review examines the potential to include more noninvasive image-based phenotypes in the CVD risk assessment using powerful AI-based strategies.","Atherosclerosis,Cardiovascular disease,Stroke,10-Year risk,Statistical risk calculator,Integrated models,Artificial intelligence-based risk assessment",Review,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"INTIMA-MEDIA,THICKNESS,CORONARY-HEART-DISEASE,MACHINE,LEARNING,FRAMEWORK,ARTERY,CALCIUM,SCORE,10-YEAR,FOLLOW-UP,PRIMARY,PREVENTION,TISSUE,CHARACTERIZATION,ATHEROSCLEROTIC,PLAQUE,RHEUMATOID-ARTHRITIS,VOLUME,MEASUREMENT",COMPUTERS IN BIOLOGY AND MEDICINE,,
8,Utilization of smartphone and tablet camera photographs to predict healing of diabetes-related foot ulcers,126,,,"Kim Renaid B.,Gryak Jonathan,Mishra Abinash,Cui Can,Soroushmehr S. M. Reza,Najarian Kayvan,Wrobel James S.","Kim RB,Gryak J,Mishra A,Cui C,Soroushmehr SMR,Najarian K,Wrobel JS",Kim RB,10.1016/j.compbiomed.2020.104042,University of Michigan System,"The objective of this study was to build a machine learning model that can predict healing of diabetes-related foot ulcers, using both clinical attributes extracted from electronic health records (EHR) and image features extracted from photographs. The clinical information and photographs were collected at an academic podiatry wound clinic over a three-year period. Both hand-crafted color and texture features and deep learning-based features from the global average pooling layer of ResNet-50 were extracted from the wound photographs. Random Forest (RF) and Support Vector Machine (SVM) models were then trained for prediction. For prediction of eventual wound healing, the models built with hand-crafted imaging features alone outperformed models built with clinical or deep-learning features alone. Models trained with all features performed comparatively against models trained with hand-crafted imaging features. Utilization of smartphone and tablet photographs taken outside of research settings hold promise for predicting prognosis of diabetes-related foot ulcers.","Diabetic foot ulcers,Machine learning,Image processing,Photographs,Clinical prediction model,Electronic health records",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,NUTRITIONAL-STATUS,COMPUTERS IN BIOLOGY AND MEDICINE,,
9,An Explainable Machine Learning Model for Early Detection of Parkinson's Disease using LIME on DaTSCAN Imagery,126,,,"Magesh Pavan Rajkumar,Myloth Richard Delwin,Tom Rijo Jackson","Magesh PR,Myloth RD,Tom RJ",Tom RJ,10.1016/j.compbiomed.2020.104041,"CMR Inst Technol, Dept Comp Sci & Engn, Bengaluru, India.","Parkinson's Disease (PD) is a degenerative and progressive neurological condition. Early diagnosis can improve treatment for patients and is performed through dopaminergic imaging techniques like the SPECT DaTSCAN. In this study, we propose a machine learning model that accurately classifies any given DaTSCAN as having Parkinson's disease or not, in addition to providing a plausible reason for the prediction. This kind of reasoning is done through the use of visual indicators generated using Local Interpretable Model-Agnostic Explainer (LIME) methods. DaTSCANs were drawn from the Parkinson's Progression Markers Initiative database and trained on a CNN (VGG16) using transfer learning, yielding an accuracy of 95.2%, a sensitivity of 97.5%, and a specificity of 90.9%. Keeping model interpretability of paramount importance, especially in the healthcare field, this study utilises LIME explanations to distinguish PD from non-PD, using visual superpixels on the DaTSCANs. It could be concluded that the proposed system, in union with its measured interpretability and accuracy may effectively aid medical workers in the early diagnosis of Parkinson's Disease.","Parkinson's disease,Convolutional neural network,Computer-aided diagnosis,Interpretability,Explainable AI",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,CLASSIFICATION,COMPUTERS IN BIOLOGY AND MEDICINE,http://arxiv.org/pdf/2008.00238,
10,A hybrid machine learning approach to localizing the origin of ventricular tachycardia using 12-lead electrocardiograms,126,,,"Missel Ryan,Gyawali Prashnna K.,Murkute Jaideep Vitthal,Li Zhiyuan,Zhou Shijie,AbdelWahab Amir,Davis Jason,Warren James,Sapp John L.,Wang Linwei","Missel R,Gyawali PK,Murkute JV,Li ZY,Zhou SJ,AbdelWahab A,Davis J,Warren J,Sapp JL,Wang LW",Wang LW,10.1016/j.compbiomed.2020.104013,Rochester Institute of Technology,"Background: Machine learning models may help localize the site of origin of ventricular tachycardia (VT) using 12-lead electrocardiograms. However, population-based models suffer from inter-subject anatomical variations within ECG data, while patient-specific models face the open challenge of what pacing data to collect for training.
Methods: This study presents and validates the first hybrid model that combines population and patient-specific machine learning for rapid ""computer-guided pace-mapping"". A population-based deep learning model was first trained offline to disentangle inter-subject variations and regionalize the site of VT origin. Given a new patient with a target VT, an on-line patient-specific model after being initialized by the population-based prediction was then built in real time by actively suggesting where to pace next and improving the prediction with each added pacing data, progressively guiding pace-mapping towards the site of VT origin.
Results: The population model was trained on pace-mapping data from 38 patients and the patient-specific model was subsequently tuned on one patient. The resulting hybrid model was tested on a separate cohort of eight patients in localizing 1) 193 LV endocardial pacing sites, and 2) nine VTs with clinically determined exit sites. The hybrid model achieved a localization error of 5.3 +/- 2.6 mm using 5.4 +/- 2.5 pacing sites in localizing LV pacing sites, achieving a significantly higher accuracy with a significantly smaller amount of training sites in comparison to models without active guidance.
Conclusion: The presented hybrid model has the potential to assist rapid pace-mapping of interventional targets in VT.","Ventricular tachycardia,Electrocardiogram,Disentangled representation learning,Active learning,Pace-mapping",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,SITE,COMPUTERS IN BIOLOGY AND MEDICINE,http://manuscript.elsevier.com/S0010482520303449/pdf/S0010482520303449.pdf,
11,A comprehensive review of deep learning in colon cancer,126,,,"Pacal Ishak,Karaboga Dervis,Basturk Alper,Akay Bahriye,Nalbantoglu Ufuk","Pacal I,Karaboga D,Basturk A,Akay B,Nalbantoglu U",Pacal I,10.1016/j.compbiomed.2020.104003,Igdir University,"Deep learning has emerged as a leading machine learning tool in object detection and has attracted attention with its achievements in progressing medical image analysis. Convolutional Neural Networks (CNNs) are the most preferred method of deep learning algorithms for this purpose and they have an essential role in the detection and potential early diagnosis of colon cancer. In this article, we hope to bring a perspective to progress in this area by reviewing deep learning practices for colon cancer analysis. This study first presents an overview of popular deep learning architectures used in colon cancer analysis. After that, all studies related to colon cancer analysis are collected under the field of colon cancer and deep learning, then they are divided into five categories that are detection, classification, segmentation, survival prediction, and inflammatory bowel diseases. Then, the studies collected under each category are summarized in detail and listed. We conclude our work with a summary of recent deep learning practices for colon cancer analysis, a critical discussion of the challenges faced, and suggestions for future research. This study differs from other studies by including 135 recent academic papers, separating colon cancer into five different classes, and providing a comprehensive structure. We hope that this study is beneficial to researchers interested in using deep learning techniques for the diagnosis of colon cancer.","Deep learning,Medical image analysis,Colon cancer,Colorectal cancer,Rectal cancer,Inflammatory bowel diseases,Convolutional neural networks",Review,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"CONVOLUTIONAL,NEURAL-NETWORK,INFLAMMATORY-BOWEL-DISEASE,COMPUTER-AIDED,DIAGNOSIS,COLORECTAL-CANCER,POLYP,DETECTION,CAPSULE,ENDOSCOPY,CLASSIFICATION,SEGMENTATION,COLONOSCOPY,IMAGES",COMPUTERS IN BIOLOGY AND MEDICINE,,
12,Sickle-cell disease diagnosis support selecting the most appropriate machine learning method: Towards a general and interpretable approach for cell morphology analysis from microscopy images,126,,,"Petrovic Natasa,Moya-Alcover Gabriel,Jaume-i-Capo Antoni,Gonzalez-Hidalgo Manuel","Petrovic N,Moya-Alcover G,Jaume-i-Capo A,Gonzalez-Hidalgo M",Jaume-i-Capo A,10.1016/j.compbiomed.2020.104027,Universitat de les Illes Balears,"In this work we propose an approach to select the classification method and features, based on the state-of-the-art, with best performance for diagnostic support through peripheral blood smear images of red blood cells. In our case we used samples of patients with sickle-cell disease which can be generalized for other study cases. To trust the behavior of the proposed system, we also analyzed the interpretability. We pre-processed and segmented microscopic images, to ensure high feature quality. We applied the methods used in the literature to extract the features from blood cells and the machine learning methods to classify their morphology. Next, we searched for their best parameters from the resulting data in the feature extraction phase. Then, we found the best parameters for every classifier using Randomized and Grid search. For the sake of scientific progress, we published parameters for each classifier, the implemented code library, the confusion matrices with the raw data, and we used the public erythrocyteslDB dataset for validation. We also defined how to select the most important features for classification to decrease the complexity and the training time, and for interpretability purpose in opaque models. Finally, comparing the best performing classification methods with the state-of-the-art, we obtained better results even with interpretable model classifiers.","Red blood cell,Sickle-cell disease,Microscopy image,Machine learning,Interpretability,Morphology analysis",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"RED-BLOOD-CELLS,CLASSIFICATION,QUANTIFICATION,SEGMENTATION,ERYTHROCYTES,FEATURES",COMPUTERS IN BIOLOGY AND MEDICINE,http://arxiv.org/pdf/2010.04511,
13,Localization and recognition of leukocytes in peripheral blood: A deep learning approach,126,,,"Reena M. Roy,Ameer P. M.","Reena MR,Ameer PM",Reena MR,10.1016/j.compbiomed.2020.104034,National Institute of Technology (NIT System),"Automatic recognition and classification of leukocytes helps medical practitioners to diagnose various blood-related diseases by analysing their percentages. Different researchers have come up with different algorithms that use traditional learning for the classification of different types of leukocytes. In contrast to traditional learning, in which no knowledge is retained that can be transferred from one model to another, our proposed algorithm uses deep learning approach for segmentation and classification. The proposed algorithm has two stage pipelining consisting of semantic segmentation and transfer learning-based classification. Here, we have used pre-trained networks, utilizing knowledge from previously learned tasks, called DeepLabv3+ for segmentation of leukocytes and AlexNet to classify five categories of leukocytes in peripheral blood from whole blood smear microscopic images. For experimentation, a microscopic blood image dataset consisting of 257 cells belonging to five types of leukocytes was used. The results obtained from experiments show that the proposed algorithm attained a mean average precision of 98.42% (@IoU = 0.7) in white blood cell localization and a classification accuracy of 98.87 + 1% compared to existing methods.","Leukocyte,Semantic segmentation,DeepLab architecture,Atrous convolution,Transfer learning,Classification",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"CLASSIFICATION,SEGMENTATION,ALGORITHM,FEATURES",COMPUTERS IN BIOLOGY AND MEDICINE,,
14,Classification of the interictal state with hypsarrhythmia from Zika Virus Congenital Syndrome and of the ictal state from epilepsy in childhood without hypsarrhythmia in EEGs using entropy measures,126,,,"Rocha Priscila L.,Barros Allan K.,Silva Washington S.,Sousa Gean C.,Sousa Patricia,da Silva Antonio M.","Rocha PL,Barros AK,Silva WS,Sousa GC,Sousa P,da Silva AM",Rocha PL,10.1016/j.compbiomed.2020.104014,Universidade Federal do Maranhao,"This paper intends to classify the interictal state with hypsarrhythmia in patients with Zika Virus Congenital Syndrome (ZVCS) and of the ictal state in patients with epilepsy in childhood without the presence of hypsarrhythmia. Hypsarrhythmia is a specific interictal chaotic morphology, and the correct distinction between these two EEG states is crucial to improving the cognitive development of these epileptic patients. The proposed approach was assessed using the proprietary database of Casa Ninar, which contains data regarding children from northeastern Brazil born with microcephaly caused by the Zika virus. We also used data from the CHB-MIT database. Fundamental rhythms of the EEG signal delta, theta, alpha, and beta were analyzed, and then decomposed by Discrete Wavelet Transform, in which 45 mother wavelet functions were tested to determine the most appropriate function to represent the EEG signals in the hypsarrhythmia interictal and ictal states. We extracted Shannon, Log Energy, Norm, and Sure entropy measures of the subbands as relevant features, and the combinations among them were applied in the state-of-the-art machine learning methods. The combination of Sure entropy with Shannon entropy, or with Log Energy and Norm, extracted from the 6 rhythm, allowed for the best linear separability between the classes in most of the classifiers, obtaining 100% accuracy, sensitivity, and specificity.","Epilepsy in early childhood,Interictal,Ictal,Hypsarrhythmia,Rhythms of the EEG Signal,Epileptic seizure,Discrete wavelet transform,Machine learning",Review,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"DISCRETE,WAVELET,TRANSFORM,SEIZURE,DETECTION,DECOMPOSITION,IDENTIFICATION,FREQUENCY,SQUARE,SPASMS,TIME",COMPUTERS IN BIOLOGY AND MEDICINE,,
15,Automated diagnostic tool for hypertension using convolutional neural network,126,,,"Soh Desmond Chuang Kiat,Ng E. Y. K.,Jahmunah V,Oh Shu Lih,Tan Ru San,Acharya U. Rajendra","Soh DCK,Ng EYK,Jahmunah V,Oh SL,Tan RS,Acharya UR",Ng EYK,10.1016/j.compbiomed.2020.103999,Nanyang Technological University & National Institute of Education (NIE) Singapore,"Background: Hypertension (HPT) occurs when there is increase in blood pressure (BP) within the arteries, causing the heart to pump harder against a higher afterload to deliver oxygenated blood to other parts of the body.
Purpose: Due to fluctuation in BP, 24-h ambulatory blood pressure monitoring has emerged as a useful tool for diagnosing HPT but is limited by its inconvenience. So, an automatic diagnostic tool using electrocardiogram (ECG) signals is used in this study to detect HPT automatically.
Method: The pre-processed signals are fed to a convolutional neural network model. The model learns and identifies unique ECG signatures for classification of normal and hypertension ECG signals. The proposed model is evaluated by the 10-fold and leave one out patient based validation techniques.
Results: A high classification accuracy of 99.99% is achieved for both validation techniques. This is one of the first few studies to have employed deep learning algorithm coupled with ECG signals for the detection of HPT. Our results imply that the developed tool is useful in a hospital setting as an automated diagnostic tool, enabling the effortless detection of HPT using ECG signals.","Hypertension,Automated diagnostic tool,Masked hypertension,Convolutional neural network,10-Fold validation,Leave one patient out validation",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"BLOOD-PRESSURE,FUZZY-SYSTEMS,ECG,SIGNALS,CLASSIFICATION",COMPUTERS IN BIOLOGY AND MEDICINE,,
16,Generating wall shear stress for coronary artery in real-time using neural networks: Feasibility and initial results based on idealized models,126,,,"Su Boyang,Zhang Jun-Mei,Zou Hua,Ghista Dhanjoo,Le Thu Thao,Chin Calvin","Su BY,Zhang JM,Zou H,Ghista D,Le TT,Chin C",Su BY,10.1016/j.compbiomed.2020.104038,"5 Hosp Dr, Singapore 169609, Singapore.","Computational fluid dynamics (CFD) and medical imaging can be integrated to derive some important hemodynamic parameters such as wall shear stress (WSS). However, CFD suffers from a relatively long computational time that usually varies from dozens of minutes to hours. Machine learning is a popular tool that has been applied to many fields, and it can predict outcomes fast and even instantaneously in most applications. This study aims to use machine learning as an alternative to CFD for generating hemodynamic parameters in real-time diagnosis during medical examinations. To perform the feasibility study, we used CFD to model the blood flow in 2000 idealized coronary arteries, and the calculated WSS values in these models were used as the dataset for training and testing. The preparation of the dataset was automated by scripts programmed in Python, and OpenFOAM was used as the CFD solver. We have explored multivariate linear regression, multi-layer perceptron, and convolutional neural network architectures to generate WSS values from coronary artery geometry directly without CFD. These architectures were implemented in TensorFlow 2.0. Our results showed that these algorithms were able to generate results in less than 1 s, proving its capability in real-time applications, in terms of computational time. Based on the accuracy, convolutional neural network outperformed the other architectures with a normalized mean absolute error of 2.5%. Although this study is based on idealized models, to the best of our knowledge, it is the first attempt to predict WSS in a stenosed coronary artery using machine learning approaches.","Computational fluid dynamics,Coronary artery,Wall shear stress,Neural network,Real-time prediction",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"ANTERIOR,DESCENDING,ARTERY,BLOOD-FLOW,DIMENSIONALITY,SIMULATION,RESERVE",COMPUTERS IN BIOLOGY AND MEDICINE,,
17,Intelligent diagnosis of gastric intestinal metaplasia based on convolutional neural network and limited number of endoscopic images,126,,,"Yan Tao,Wong Pak Kin,Choi I. Cheong,Vong Chi Man,Yu Hon Ho","Yan T,Wong PK,Choi IC,Vong CM,Yu HH",Wong PK,10.1016/j.compbiomed.2020.104026,University of Macau,"Background: Gastric intestinal metaplasia (GIM) is a precancerous lesion of gastric cancer. Currently, diagnosis of GIM is based on the experience of a physician, which is liable to interobserver variability. Thus, an intelligent diagnostic (ID) system, based on narrow-band and magnifying narrow-band images, was constructed to provide objective assistance in the diagnosis of GIM.
Method: We retrospectively collected 1880 endoscopic images (1048 GIM and 832 non-GIM) via biopsy from 336 patients confirmed histologically as GIM or non-GIM, from the Kiang Wu Hospital, Macau. We developed an ID system with these images using a modified convolutional neural network algorithm. A separate test dataset containing 477 pathologically confirmed images (242 GIM and 235 non-GIM) from 80 patients was used to test the performance of the ID system. Experienced endoscopists also examined the same test dataset, for comparison with the ID system. One of the challenges faced in this study was that it was difficult to obtain a large number of training images. Thus, data augmentation and transfer learning were applied together.
Results: The area under the receiver operating characteristic curve was 0.928 for the pre-patient analysis of the ID system, while the sensitivities, specificities, and accuracies of the ID system against those of the human experts were (91.9% vs. 86.5%, p-value = 1.000) (86.0% vs. 81.4%, p-value = 0.754), and (88.8% vs. 83.8%, p-value = 0.424), respectively. Even though the three indices of the ID system were slightly higher than those of the human experts, there were no significant differences.
Conclusions: In this pilot study, a novel ID system was developed to diagnose GIM. This system exhibits promising diagnostic performance. It is believed that the proposed system has the potential for clinical application in the future.","Gastric intestinal metaplasia,Intelligent diagnosis,Narrow-band imaging,Magnifying narrow-band imaging,Convolutional neural network",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Life Sciences & Biomedicine - Other Topics,Computer Science,Engineering,Mathematical & Computational Biology",,3.9,"BAND,CLASSIFICATION,ARCHITECTURES",COMPUTERS IN BIOLOGY AND MEDICINE,,
18,Single Volume Image Generator and Deep Learning-Based ASD Classification,24,11,3044-3054,"Ahmed Md Rishad,Zhang Yuan,Liu Yi,Liao Hongen","Ahmed MR,Zhang Y,Liu Y,Liao HE",Zhang Y,10.1109/JBHI.2020.2998603,Southwest University - China,"Autism spectrum disorder (ASD) is an intricate neuropsychiatric brain disorder characterized by social deficits and repetitive behaviors. Deep learning approaches have been applied in clinical or behavioral identification of ASD; most erstwhile models are inadequate in their capacity to exploit the data richness. On the other hand, classification techniques often solely rely on region-based summary and/or functional connectivity analysis of functional magnetic resonance imaging (fMRI). Besides, biomedical data modeling to analyze big data related to ASD is still perplexing due to its complexity and heterogeneity. Single volume image consideration has not been previously investigated in classification purposes. By deeming these challenges, in this work, firstly, we design an image generator to generate single volume brain images from the whole-brain image by considering the voxel time point of each subject separately. Then, to classify ASD and typical control participants, we evaluate four deep learning approaches with their corresponding ensemble classifiers comprising one amended Convolutional Neural Network (CNN). Finally, to check out the data variability, we apply the proposed CNN classifier with leave-one-site-out 5-fold cross-validation across the sites and validate our findings by comparing with literature reports. We showcase our approach on large-scale multi-site brain imaging dataset (ABIDE) by considering four preprocessing pipelines, which outperforms the state-of-the-art methods. Hence, it is robust and consistent.","Brain modeling,Pipelines,Deep learning,Functional magnetic resonance imaging,Feature extraction,Generators,Biomedical data modeling,image generator,convolutional neural network (CNN),autism spectrum disorder (ASD),fMRI,ABIDE",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"AUTISM,SPECTRUM,DISORDER,CONNECTIVITY,NETWORKS",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,https://doi.org/10.1101/763292,
19,Augmenting Dementia Cognitive Assessment With Instruction-Less Eye-Tracking Tests,24,11,3066-3075,"Mengoudi Kyriaki,Ravi Daniele,Yong Keir X. X.,Primativo Silvia,Pavisic Ivanna M.,Brotherhood Emilie,Lu Kirsty,Schott Jonathan M.,Crutch Sebastian J.,Alexander Daniel C.","Mengoudi K,Ravi D,Yong KXX,Primativo S,Pavisic IM,Brotherhood E,Lu K,Schott JM,Crutch SJ,Alexander DC",Mengoudi K,10.1109/JBHI.2020.3004686,University of London,"Eye-tracking technology is an innovative tool that holds promise for enhancing dementia screening. In this work, we introduce a novel way of extracting salient features directly from the raw eye-tracking data of a mixed sample of dementia patients during a novel instruction-less cognitive test. Our approach is based on self-supervised representation learning where, by training initially a deep neural network to solve a pretext task using well-defined available labels (e.g. recognising distinct cognitive activities in healthy individuals), the network encodes high-level semantic information which is useful for solving other problems of interest (e.g. dementia classification). Inspired by previous work in explainable AI, we use the Layer-wise Relevance Propagation (LRP) technique to describe our networks decisions in differentiating between the distinct cognitive activities. The extent to which eye-tracking features of dementia patients deviate from healthy behaviour is then explored, followed by a comparison between self-supervised and handcrafted representations on discriminating between participants with and without dementia. Our findings not only reveal novel self-supervised learning features that are more sensitive than handcrafted features in detecting performance differences between participants with and without dementia across a variety of tasks, but also validate that instruction-less eye-tracking tests can detect oculomotor biomarkers of dementia-related cognitive dysfunction. This work highlights the contribution of self-supervised representation learning techniques in biomedical applications where the small number of patients, the non-homogenous presentations of the disease and the complexity of the setting can be a challenge using state-of-the-art feature extraction methods.","Dementia,Task analysis,Feature extraction,Semantics,Pupils,Cognition,Eye-tracking,dementia,cognition,deep-learning,representation learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,MOVEMENTS,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://uhra.herts.ac.uk/bitstream/2299/23813/1/FINAL_VERSION.pdf,
20,Automated Semantic Segmentation of Red Blood Cells for Sickle Cell Disease,24,11,3095-3102,"Zhang Mo,Li Xiang,Xu Mengjia,Li Quanzheng","Zhang M,Li X,Xu MJ,Li QZ",Li QZ,10.1109/JBHI.2020.3000484,"MGH BWH Ctr Clin Data Sci, Boston, MA 02115 USA.","Red blood cell (RBC) segmentation and classification from microscopic images is a crucial step for the diagnosis of sickle cell disease (SCD). In this work, we adopt a deep learning based semantic segmentation framework to solve the RBC classification task. A major challenge for robust segmentation and classification is the large variations on the size, shape and viewpoint of the cells, combining with the low image quality caused by noise and artifacts. To address these challenges, we apply deformable convolution layers to the classic U-Net structure and implement the deformable U-Net (dU-Net). U-Net architecture has been shown to offer accurate localization for image semantic segmentation. Moreover, deformable convolution enables free-form deformation of the feature learning process, thus making the network more robust to various cell morphologies and image settings. dU-Net is tested on microscopic red blood cell images from patients with sickle cell disease. Results show that dU-Net can achieve highest accuracy for both binary segmentation and multi-class semantic segmentation tasks, comparing with both unsupervised and state-of-the-art deep learning based supervised segmentation methods. Through detailed investigation of the segmentation results, we further conclude that the performance improvement is mainly caused by the deformable convolution layer, which has better ability to separate the touching cells, discriminate the background noise and predict correct cell shapes without any shape priors.","Image segmentation,Computer architecture,Microprocessors,Convolution,Semantics,Shape,Biomedical imaging,Automated semantic segmentation,deformable convolution,RBC,sickle cell disease,U-Net",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"IMAGE,SEGMENTATION,CLASSIFICATION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
21,Data-Driven Analysis of Radiologists Behavior for Diagnosing Thyroid Nodules,24,11,3111-3123,"Chang Leilei,Fu Chao,Wu Zijian,Liu Weiyong,Yang Shanlin","Chang LL,Fu C,Wu ZJ,Liu WY,Yang SL",Fu C,10.1109/JBHI.2020.2969322,Hefei University of Technology,"Thyroid nodule has been a common and serious threaten to human health. With the identification and diagnosis of thyroid nodules in the general population, large volumes of examination reports in clinical practice have been accumulated. They provide data basics of analyzing radiologists' behavior of diagnosing thyroid nodules. To conduct data-driven analysis of radiologists' behavior, an experimental framework is designed based on belief rule base, which is essentially a white box for knowledge representation and uncertain reasoning. Under the framework, with 2744 examination reports of thyroid nodules in the period from January 2012 to February 2019 that have been collected from a tertiary hospital located in Hefei, Anhui, China, experimental results are obtained from conducting missing validation, self-validation, and mutual validation. Three principles are then concluded from the results and corresponding analysis. The first is that missing features on some criteria are considered as benign ones by default, the second is that there is generally inconsistency between the recorded features on criteria and the overall diagnosis, and the third is that different radiologists have different diagnostic preferences. These three principles reflect three diagnostic behavioral characteristics of radiologists, namely reliability, inconsistency, and independence. Based on the three principles and radiologists' behavioral characteristics, managerial insights in a general case are concluded to make the findings in this study available in other situations.","Cancer,Hospitals,Imaging,Acoustics,Machine learning,Ultrasonic imaging,Behavioral analysis,belief rule base,diagnosis of thyroid nodules,inconsistency,independence",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"DATA,SYSTEM,EXPERT-SYSTEM,ULTRASOUND,CLASSIFICATION,TIRADS,COMBINATION,FEATURES,BENIGN,RISK",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
22,Atrial Fibrillation Detection During Sepsis: Study on MIMIC III ICU Data,24,11,3124-3135,"Bashar Syed Khairul,Hossain Md Billal,Ding Eric,Walkey Allan J.,McManus David D.,Chon Ki H.","Bashar SK,Hossain MB,Ding E,Walkey AJ,McManus DD,Chon KH",Chon KH,10.1109/JBHI.2020.2995139,University of Connecticut,"Sepsis is defined by life-threatening organ dysfunction during infection and is one of the leading causes of critical illness. During sepsis, there is high risk that new-onset of atrial fibrillation (AF) can occur, which is associated with significant morbidity and mortality. As a result, computer aided automated and reliable detection of new-onset AF during sepsis is crucial, especially for the critically ill patients in the intensive care unit (ICU). In this paper, a novel automated and robust two-step algorithm to detect AF from ICU patients using electrocardiogram (ECG) signals is presented. First, several statistical parameters including root mean square of successive differences, Shannon entropy, and sample entropy were calculated from the heart rate for the screening of possible AF segments. Next, Poincare plot-based features along with P-wave characteristics were used to reduce false positive detection of AF, caused by the premature atrial and ventricular beats. A subset of the Medical Information Mart for Intensive Care (MIMIC) III database containing 198 subjects was used in this study. During the training and validation phases, both the simple thresholding as well as machine learning classifiers achieved very high segment-wise AF classification performance. Finally, we tested the performance of our proposed algorithm using two independent test data sets and compared the performance with two state-of-the-art methods. The algorithm achieved an overall 100% sensitivity, 98% specificity, 98.99% accuracy, 98% positive predictive value, and 100% negative predictive value on the subject-wise AF detection, thus showing the efficacy of our proposed algorithm in critically ill sepsis patients. The annotations of the data have been made publicly available for other investigators.","Electrocardiography,Feature extraction,MIMICs,Heart rate variability,Entropy,Databases,Detection algorithms,Sepsis,ICU,Atrial fibrillation,P-wave,Premature beat,Poincar&#233,plot,Annotations",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"RATE-INDEPENDENT,DETECTION,AUTOMATIC,DETECTION,WAVELET,TRANSFORM,COMPONENTS,ENTROPY,STROKE,ENERGY,RISK",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
23,Blind Monaural Source Separation on Heart and Lung Sounds Based on Periodic-Coded Deep Autoencoder,24,11,3203-3214,"Tsai Kun-Hsi,Wang Wei-Chien,Cheng Chui-Hsuan,Tsai Chan-Yen,Wang Jou-Kou,Lin Tzu-Hao,Fang Shih-Hau,Chen Li-Chin,Tsao Yu","Tsai KH,Wang WC,Cheng CH,Tsai CY,Wang JK,Lin TH,Fang SH,Chen LC,Tsao Y",Tsao Y,10.1109/JBHI.2020.3016831,Academia Sinica - Taiwan,"Auscultation is the most efficient way to diagnose cardiovascular and respiratory diseases. To reach accurate diagnoses, a device must be able to recognize heart and lung sounds from various clinical situations. However, the recorded chest sounds are mixed by heart and lung sounds. Thus, effectively separating these two sounds is critical in the pre-processing stage. Recent advances in machine learning have progressed on monaural source separations, but most of the well-known techniques require paired mixed sounds and individual pure sounds for model training. As the preparation of pure heart and lung sounds is difficult, special designs must be considered to derive effective heart and lung sound separation techniques. In this study, we proposed a novel periodicity-coded deep auto-encoder (PC-DAE) approach to separate mixed heart-lung sounds in an unsupervised manner via the assumption of different periodicities between heart rate and respiration rate. The PC-DAE benefits from deep-learning-based models by extracting representative features and considers the periodicity of heart and lung sounds to carry out the separation. We evaluated PC-DAE on two datasets. The first one includes sounds from the Student Auscultation Manikin (SAM), and the second is prepared by recording chest sounds in real-world conditions. Experimental results indicate that PC-DAE outperforms several well-known separation works in terms of standardized evaluation metrics. Moreover, waveforms and spectrograms demonstrate the effectiveness of PC-DAE compared to existing approaches. It is also confirmed that by using the proposed PC-DAE as a pre-processing stage, the heart sound recognition accuracies can be notably boosted. The experimental results confirmed the effectiveness of PC-DAE and its potential to be used in clinical applications.","Heart,Lung,Acoustics,Neurons,Decoding,Convolution,Informatics,Blind monaural source separation,deep autoencoder,deep neural networks,heart sound,lung sound,phonocardiogram,periodic analysis",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"NONNEGATIVE,MATRIX,FACTORIZATION,EMPIRICAL,MODE,DECOMPOSITION,REDUCTION,NOISE,OPTIMIZATION,AUSCULTATION,CANCELLATION,RECORDINGS,EXTRACTION,TRANSFORM",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,http://arxiv.org/pdf/2012.06275,
24,Multiple Axial Spine Indices Estimation via Dense Enhancing Network With Cross-Space Distance-Preserving Regularization,24,11,3248-3257,"Lin Liyan,Tao Xi,Pang Shumao,Su Zhihai,Lu Hai,Li Shuo,Feng Qianjin,Chen Bo","Lin LY,Tao X,Pang SM,Su ZH,Lu H,Li S,Feng QJ,Chen B",Feng QJ,10.1109/JBHI.2020.2977224,Southern Medical University - China,"Automatic estimation of axial spine indices is clinically desired for various spine computer aided procedures, such as disease diagnosis, therapeutic evaluation, pathophysiological understanding, risk assessment, and biomechanical modeling. Currently, the spine indices are manually measured by physicians, which is time-consuming and laborious. Even worse, the tedious manual procedure might result in inaccurate measurement. To deal with this problem, in this paper, we aim at developing an automatic method to estimate multiple indices from axial spine images. Inspired by the success of deep learning for regression problems and the densely connected network for image classification, we propose a dense enhancing network (DE-Net) which uses the dense enhancing blocks (DEBs) as its main body, where a feature enhancing layer is added to each of the bypass in a dense block. The DEB is designed to enhance discriminative feature embedding from the intervertebral disc and the dural sac areas. In addition, the cross-space distance-preserving regularization (CSDPR), which enforces consistent inter-sample distances between the output and the label spaces, is proposed to regularize the loss function of the DE-Net. To train and validate the proposed method, we collected 895 axial spine MRI images from 143 subjects and manually measured the indices as the ground truth. The results show that all deep learning models obtain very small prediction errors, and the proposed DE-Net with CSDPR acquires the smallest error among all methods, indicating that our method has great potential for spine computer aided procedures.","Estimation,Feature extraction,Machine learning,Biomedical measurement,Magnetic resonance imaging,Computational modeling,Biomedical imaging,Spine quantification,deep learning,dense connectivity,feature enhancement,cross-space distance-preserving regularization",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"LUMBAR,SPINE,DURAL,SAC,IMAGE,CASCADE,HEIGHT,DISCS",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
25,Screening For Depression With Retrospectively Harvested Private Versus Public Text,24,11,3326-3332,"Tlachac M. L.,Rundensteiner Elke","Tlachac ML,Rundensteiner E",Tlachac ML,10.1109/JBHI.2020.2983035,Worcester Polytechnic Institute,"Depression is the leading cause of disability, often undiagnosed, and one of the most treatable mood disorders. As such, unobtrusively diagnosing depression is important. Many studies are starting to utilize machine learning for depression sensing from social media and Smartphone data to replace the survey instruments currently employed to screen for depression. In this study, we compare the ability of a privately versus a publicly available modality to screen for depression. Specifically, we leverage between two weeks and a year of text messages and tweets to predict scores from the Patient Health Questionnaire-9, a prevalent depression screening instrument. This is the first study to leverage the retrospectively-harvested crowd-sourced texts and tweets within the combined Moodable and EMU datasets. Our approach involves comprehensive feature engineering, feature selection, and machine learning. Our 245 features encompass word category frequencies, part of speech tag frequencies, sentiment, and volume. The best model is Logistic Regression built on the top ten features from two weeks of text data. This model achieves an average F1 score of 0.806, AUC of 0.832, and recall of 0.925. We discuss the implications of the selected features, temporal quantity of data, and modality.","Depression,Machine learning,Feature extraction,Tools,Social networking (online),Standards,Principal component analysis,Text feature engineering,depression screening,feature selection,machine learning,social media",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Mathematical & Computational Biology,Medical Informatics",,6.018,"DETECTING,DEPRESSION",IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,,
26,Automating the Classification of Complexity of Medical Decision-Making in Patient-Provider Messaging in a Patient Portal,255,,224-232,"Sulieman Lina,Robinson Jamie R.,Jackson Gretchen P.","Sulieman L,Robinson JR,Jackson GP",Sulieman L,10.1016/j.jss.2020.05.039,"Dept Biomed Informat, 2525 West End Suite 1500, Nashville, TN 37203 USA.","Background: Patient portals are consumer health applications that allow patients to view their health information. Portals facilitate the interactions between patients and their caregivers by offering secure messaging. Patients communicate different needs through portal messages. Medical needs contain requests for delivery of care (e.g. reporting new symptoms). Automating the classification of medical decision complexity in portal messages has not been investigated.
Materials and methods: We trained two multiclass classifiers, multinomial Naive Bayes and random forest on 500 message threads, to quantify and label the complexity of decision-making into four classes: no decision, straightforward, low, and moderate. We compared the performance of the models to using only the number of medical terms without training a machine learning model.
Results: Our analysis demonstrated that machine learning models have better performance than the model that did not use machine learning. Moreover, machine learning models could quantify the complexity of decision-making that the messages contained with 0.59, 0.45, and 0.58 for macro, micro, and weighted precision and 0.63,0.41, and 0.63 for macro, micro, and weighted recall.
Conclusions: This study is one of the first to attempt to classify patient portal messages by whether they involve medical decision-making and the complexity of that decision-making. Machine learning classifiers trained on message content resulted in better message thread classification than classifiers that employed medical terms in the messages alone. (C) 2020 Elsevier Inc. All rights reserved.","Patient portals,Medical decision,Decision complexity,Machine learning,Medical billing,Consumer health",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA",Surgery,,,"SURGEONS,SERVICE,GROWTH",JOURNAL OF SURGICAL RESEARCH,http://europepmc.org/articles/pmc7303623?pdf=render,
27,Using Artificial Intelligence to Predict Surgical Shunts in Men with Ischemic Priapism,204,5,1033-1038,"Masterson Thomas A.,Parmar Madhumita,Tradewell Michael B.,Nackeeran Sirpi,Rainer Quinn,Blachman-Braun Ruben,Heller Nicholas,Greer Aubrey,Hauser Nicholas,Kava Bruce R.","Masterson TA,Parmar M,Tradewell MB,Nackeeran S,Rainer Q,Blachman-Braun R,Heller N,Greer A,Hauser N,Kava BR",Masterson TA,10.1097/JU.0000000000001183,University of Miami,"Purpose: Ischemic priapism is a urological emergency that requires prompt intervention to preserve erectile function. Characteristics that influence escalation to surgical intervention remain unclear. We identified factors and developed machine learning models to predict which men presenting with ischemic priapism will require shunting.
Materials and Methods: We identified men with ischemic priapism admitted to the emergency department of our large county hospital between January 2010 and June 2019. We collected patient demographics, etiology, duration of priapism prior to intervention, interventions attempted and escalation to shunting. Machine learning models were trained and tested using R to predict which patients require surgical shunting.
Results: A total of 334 encounters of ischemic priapism were identified. The majority resolved with intracavernosal phenylephrine injection and/or cavernous aspiration (78%). Shunting was required in 10% of men. Median duration of priapism before intervention was longer for men requiring shunting than for men who did not (48 vs 7 hours, p = 0.030). Patients with sickle cell disease as the etiology were less likely to require shunting compared to all other etiologies (2.2% vs 15.2%, p = 0.035).
Conclusions: Men with longer duration of priapism before treatment more often underwent shunting. However, phenylephrine injection and aspiration remained effective for priapism lasting more than 36 hours. Having sickle cell disease as the etiology of priapism was protective against requiring shunting. We developed artificial intelligence models that performed with 87.2% accuracy and created an online probability calculator to determine which patients with ischemic priapism may require shunting.","priapism,ischemia,machine learning,algorithms",Article,"LIPPINCOTT WILLIAMS & WILKINS, TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA",Urology & Nephrology,,6.413,"ASSOCIATION,GUIDELINES,MANAGEMENT",JOURNAL OF UROLOGY,,
28,Architectural planning with shape grammars and reinforcement learning: Habitability and energy efficiency,96,,,"Mandow Lawrence,Perez-de-la-Cruz Jose-Luis,Belen Rodriguez-Gavilan Ana,Ruiz-Montiel Manuela","Mandow L,Perez-de-la-Cruz JL,Rodriguez-Gavilan AB,Ruiz-Montiel M",Mandow L,10.1016/j.engappai.2020.103909,Universidad de Malaga,"This paper describes the generation of sketches of small single-family dwellings that satisfy habitability requirements and are energy efficient. The proposed approach considers three stages in the generation process, and each one is based on a combination of shape grammars and reinforcement learning. First a set of very simple shape grammar rules is defined that are capable of generating a great variety of sketches. In order to guarantee the generation of sketches that are both suitable for habitation and energy efficient, a reinforcement learning process is applied on this set. Then the grammar so trained is used to generate only ``good'' sketches. More precisely, the learning process applies positive rewards to sketches that satisfy desired habitability and energy efficiency guidelines. As a result, sequences of grammar rules that lead to good sketches are identified.
In this paper we present the general approach followed to develop the system and describe in detail the procedure applied in the reinforcement learning process. Experimental results are also presented, to show convergence of the learning process, and to compare the obtained results with those of real designs. A standard energy simulation program is used to validate the approach.","Computational architecture,Reinforcement learning,Shape grammar,Energy efficiency",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Automation & Control Systems,Computer Science,Engineering",,5.317,"MATERIAL,SELECTION,DESIGN,SYSTEMS,OPTIMIZATION,PERFORMANCE,BUILDINGS",ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE,,
29,Reducing Calibration Efforts in RSVP Tasks With Multi-Source Adversarial Domain Adaptation,28,11,2344-2355,"Wei Wei,Qiu Shuang,Ma Xuelin,Li Dan,Wang Bo,He Huiguang","Wei W,Qiu S,Ma XL,Li D,Wang B,He HG",He HG,10.1109/TNSRE.2020.3023761,Chinese Academy of Sciences,"Rapid Serial Visual Presentation (RSVP)-based Brain-Computer Interface (BCI) is an efficient information detection technology by detecting event-related brain responses evoked by target visual stimuli. However, a time-consuming calibration procedure is needed before a new user can use this system. Thus, it is important to reduce calibration efforts for BCI applications. In this article, we propose a multi-source conditional adversarial domain adaptation with the correlation metric learning (mCADA-C) framework that utilizes data from other subjects to reduce the data requirement from the new subject for training the model. This model utilizes adversarial training to enable a CNN-based feature extraction network to extract common features from different domains. A correlation metric learning (CML) loss is proposed to constrain the correlation of features based on class and domain to maximize the intra-class similarity and minimize inter-class similarity. Also, a multi-source framework with a source selection strategy is adopted to integrate the results of multiple domain adaptation. We constructed an RSVP-based dataset that includes 11 subjects each performing three RSVP experiments on three different days. The experimental results demonstrate that our proposed method can achieve 87.72% cross-subject balanced-accuracy under one block calibration. The results indicate our method can realize a higher performance with less calibration efforts.","Electroencephalography,Calibration,Correlation,Brain modeling,Task analysis,Feature extraction,Visualization,EEG,RSVP-based BCI,calibration reduction,multi-source domain adaptation,correlation metric learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"SERIAL,VISUAL,PRESENTATION,COMPUTER,BCI,MANIFOLD",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
30,Zero-Shot Learning for EEG Classification in Motor Imagery-Based BCI System,28,11,2411-2419,"Duan Lili,Li Jie,Ji Hongfei,Pang Zilong,Zheng Xuanci,Lu Rongrong,Li Maozhen,Zhuang Jie","Duan LL,Li J,Ji HF,Pang ZL,Zheng XC,Lu RR,Li MZ,Zhuang J",Li J; Ji HF,10.1109/TNSRE.2020.3027004,Tongji University,"A brain-computer interface (BCI) based on motor imagery (MI) translates human intentions into computer commands by recognizing the electroencephalogram (EEG) patterns of different imagination tasks. However, due to the scarcity of MI commands and the long calibration time, using the MI-based BCI system in practice is still challenging. Zero-shot learning (ZSL), which can recognize objects whose instances may not have been seen during training, has the potential to substantially reduce the calibration time. Thus, in this context, we first try to use a new type of motor imagery task, which is a combination of traditional tasks and propose a novel zero-shot learning model that can recognize both known and unknown categories of EEG signals. This is achieved by first learning a non-linear projection from EEG features to the target space and then applying a novelty detection method to differentiate unknown classes from known classes. Applications to a dataset collected from nine subjects confirm the possibility of identifying a new type of motor imagery only using already obtained motor imagery data. Results indicate that the classification accuracy of our zero-shot based method accounts for 91.81% of the traditional method which uses all categories of data.","Electroencephalography,Task analysis,Brain modeling,Training,Feature extraction,Calibration,Neuroimaging,Zero-shot learning,brain-computer interface,motor imagery,electroencephalogram (EEG)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"BRAIN-COMPUTER,INTERFACES,SINGLE-TRIAL,EEG,SET,COMMUNICATION,DEVICE",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
31,A Gaussian Process Model of Muscle Synergy Functions for Estimating Unmeasured Muscle Excitations Using a Measured Subset,28,11,2478-2487,"Gurchiek Reed D.,Ursiny Anna T.,McGinnis Ryan S.","Gurchiek RD,Ursiny AT,McGinnis RS",Gurchiek RD,10.1109/TNSRE.2020.3028052,University of Vermont,"Estimation of muscle excitations from a reduced sensor array could greatly improve current techniques in remote patient monitoring. Such an approach could allow continuous monitoring of clinically relevant biomechanical variables that are ideal for personalizing rehabilitation. In this paper, we introduce the notion of a muscle synergy function which describes the synergistic relationship between a subset of muscles. We develop from first principles an approximation to their behavior using Gaussian process regression and demonstrate the utility of the technique for estimating the excitation time-series of leg muscles during normal walking for nine healthy subjects. Specifically, excitations for six muscles were estimated using surface electromyography (sEMG) data during a finite time interval (called the input window) from four different muscles (called the input muscles) with mean absolute error (MAE) less than 5.0% of the maximum voluntary contraction (MVC) and that accounts for 82-88% of the variance (VAF) in the true excitations. Further, these estimated excitations informed muscle activations with less than 4.0% MAE and 89-93% VAF. We also present a detailed analysis of a number of different modeling choices, including every possible combination of four-, three- and two-muscle input sets, the size and structure of the input window, and the stationarity of the Gaussian process covariance functions. Further, application specific modifications for future use are discussed. The proposed technique lays a foundation to explore the use of reduced wearable sensor arrays and muscle synergy functions for monitoring clinically relevant biomechanics during daily life.","Licenses,Gaussian process regression,machine learning,muscle synergy,wearable sensor,electromyography",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"NEURAL-NETWORK,MODEL,JOINT,MOMENTS,FORCES,GAIT,ACTIVATION,COMPLEXITY,WALKING",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,https://ieeexplore.ieee.org/ielx7/7333/9250399/09210846.pdf,
32,Resilient EMG Classification to Enable Reliable Upper-Limb Movement Intent Detection,28,11,2507-2514,"Cene Vinicius Horn,Balbinot Alexandre","Cene VH,Balbinot A",Cene VH,10.1109/TNSRE.2020.3024947,"Fed Univ Rio Grande Sul UFRGS, Dept Elect Engn, Lab Electroelect Instrumentat IEE, BR-91035190 Porto Alegre, RS, Brazil.","Reliable control of assistive devices using surface electromyography (sEMG) remains an unsolved task due to the signal's stochastic behavior that prevents robust pattern recognition for real-time control. Non-representative samples lead to inherent class overlaps that generate classification ripples for which the most common alternatives rely on post-processing and sample discard methods that insert additional delays and often do not offer substantial improvements. In this paper, a resilient classification pipeline based on Extreme Learning Machines (ELM) was used to classify 17 different upper-limb movements through sEMG signals from a total of 99 trials derived from three different databases. The method was compared to a baseline ELM and a sample discarding (DISC) method and proved to generate more stable and consistent classifications. The average accuracy boost of approximate to 10% in all databases lead to average weighted accuracy rates higher as 53,4% for amputees and 89,0% for non-amputee volunteers. The results match or outperform related works even without sample discards.","Databases,Wrist,Robustness,Mathematical model,Delays,Upper-limb,extreme learning machines,EMG,reliability,resilient classification,robust classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Rehabilitation",,4.735,"EXTREME,LEARNING,MACHINES,PATTERN-RECOGNITION,PROSTHESIS,CONTROL,SURFACE,EMG,REDUCTION,SYSTEM,DELAY",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,,
33,3D Scene-Based Beam Selection for mmWave Communications,9,11,1850-1854,"Xu Weihua,Gao Feifei,Jin Shi,Alkhateeb Ahmed","Xu WH,Gao FF,Jin S,Alkhateeb A",Gao FF,10.1109/LWC.2020.3005983,Tsinghua University,"In this letter, we present a novel framework of 3D scene based beam selection for mmWave communications that relies only on the environmental data and deep learning techniques. Different from other out-of-band side-information aided communication strategies, the proposed one fully utilizes the environmental information, e.g., the shape, the position, and even the materials of the surrounding buildings/cars/trees that are obtained from 3D scene reconstruction. Specifically, we build the neural networks with the input as point cloud of the 3D scene and the output as the beam indices. Compared with the LIDAR aided technique, the reconstructed 3D scene here is achieved from multiple images taken offline from cameras and thus significantly lowers down the cost and makes itself applicable for small mobile terminals. Simulation results show that the proposed 3D scene based beam selection can outperform the LIDAR method in terms of accuracy.","Stochastic processes,Programming,Job shop scheduling,Computational modeling,Reactive power,Parallel machines,Beam selection,deep learning,point cloud,3D scene reconstruction,3D scene based wireless communications",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Telecommunications",,3.939,,IEEE WIRELESS COMMUNICATIONS LETTERS,http://arxiv.org/pdf/1911.08409,
34,F2PNet: font-to-painting translation by adversarial learning,14,13,3243-3253,"Li Guanzhao,Zhang Jianwei,Chen Danni","Li GZ,Zhang JW,Chen DN",Zhang JW,10.1049/iet-ipr.2019.0476,South China University of Technology,"For Chinese font images, when all their strokes are replaced by pattern elements such as flowers and birds, they become flower-bird character paintings, which are traditional Chinese art treasures. The generation of flower-bird painting requires professional painters' great efforts. How to automatically generate these paintings from font images? There is a huge gap between the font domain and the painting domain. Although many image-to-image translation frameworks have been proposed, they are unable to handle this situation effectively. In this study, a novel method called font-to-painting network (F2PNet) is proposed for font-to-painting translation. Specifically, an encoder equipped with dilated convolutions extracts features of the font image, and then the features are fed into the domain translation module for mapping the font feature space to the painting feature space. The acquired features are further adjusted by the refinement module and utilised by the decoder to obtain the target painting. The authors apply adversarial loss and cycle-consistency loss to F2PNet and further propose a loss term, which is called recognisability loss and makes the generated painting have font-level recognisability. It is proved by experiments that F2PNet is effective and can be used as an unsupervised image-to-image translation framework to solve more image translation tasks.","painting,feature extraction,art,unsupervised learning,image coding,F2PNet,font-to-painting translation,Chinese font images,flower-bird character paintings,font image,font domain,painting domain,image-to-image translation frameworks,font-to-painting network,domain translation module,font feature space,painting feature space,target painting,adversarial loss,cycle-consistency loss,generated painting,font-level recognisability,unsupervised image-to-image translation framework,image translation tasks",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,AUTOMATIC-GENERATION,IET IMAGE PROCESSING,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-ipr.2019.0476,
35,Novel breast cancer classification framework based on deep learning,14,13,3254-3259,"Salama Wessam M.,Elbagoury Azza M.,Aly Moustafa H.","Salama WM,Elbagoury AM,Aly MH",Salama WM,10.1049/iet-ipr.2020.0122,Egyptian Knowledge Bank (EKB),"Breast cancer is a major cause of transience amongst women. In this paper, two novel techniques, ResNet50 and VGG-16, are utilised and re-trained to recognise two classes rather than 1000 classes with high accuracy and low computational requirements. In addition, transfer learning and data augmentation are performed to solve the problem of lack of tagged data. To get a better accuracy, the support vector machine (SVM) classifier is utilised instead of the last fully connected layer. Our models performance are verified utilising k-fold cross-validation. Our proposed techniques are trained and evaluated on three mammographic datasets: mammographic image analysis society, digital database for screening mammography (DDSM) and the curated breast imaging subset of DDSM. This paper explains end-to-end fully convolutional neural networks without any prepossessing or post-processing. The proposed technique of employing ResNet50 hybridised with SVM achieves the best performance, specifically with the DDSM dataset, producing 97.98% accuracy, 98.46% area under the curve, 97.63% sensitivity, 96.51% precision, 95.97% F1 score and computational time 1.8934 s.","support vector machines,pattern classification,mammography,medical image processing,feature extraction,image classification,cancer,learning (artificial intelligence),convolutional neural nets,screening mammography,curated breast imaging subset,end-to-end fully convolutional neural networks,ResNet50,SVM,DDSM dataset,computational time,breast cancer classification framework,deep learning,low computational requirements,digital database,mammographic image analysis society,mammographic datasets,cross-validation,models performance,fully connected layer,support vector machine classifier,tagged data,data augmentation,transfer learning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Computer Science,Engineering,Imaging Science & Photographic Technology",,2.481,NEURAL-NETWORKS,IET IMAGE PROCESSING,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-ipr.2020.0122,
36,CT-based deep learning radiomics analysis for evaluation of serosa invasion in advanced gastric cancer,132,,,"Sun Rui-Jia,Fang Meng-Jie,Tang Lei,Li Xiao-Ting,Lu Qiao-Yuan,Dong Di,Tian Jie,Sun Ying-Shi","Sun RJ,Fang MJ,Tang L,Li XT,Lu QY,Dong D,Tian J,Sun YS",Sun YS,10.1016/j.ejrad.2020.109277,Peking University,"Purpose: This work aimed to develop and validate a deep learning radiomics model for evaluating serosa invasion in gastric cancer.
Materials and Methods: A total of 572 gastric cancer patients were included in this study. Firstly, we retrospectively enrolled 428 consecutive patients (252 in the training set and 176 in the test set I) with pathological confirmed T3 or T4a. Subsequently, 144 patients who were clinically diagnosed cT3 or cT4a were prospectively allocated to the test set II. Histological verification was based on the surgical specimens. CT findings were determined by a panel of three radiologists. Conventional hand-crafted features and deep learning features were extracted from three phases CT images and were utilized to build radiomics signatures via machine learning methods. Incorporating the radiomics signatures and CT findings, a radiomics nomogram was developed via multivariable logistic regression. Its diagnostic ability was measured using receiver operating characteristiccurve analysis.
Results: The radiomics signatures, built with support vector machine or artificial neural network, showed good performance for discriminating T4a in the test I and II sets with area under curves (AUCs) of 0.76-0.78 and 0.79-0.84. The nomogram had powerful diagnostic ability in all training, test I and II sets with AUCs of 0.90 (95 % CI, 0.86-0.94), 0.87 (95 % CI, 0.82-0.92) and 0.90 (95 % CI, 0.85-0.96) respectively. The net reclassification index revealed that the radiomics nomogram had significantly better performance than the clinical model (p-values < 0.05).
Conclusions: The deep learning radiomics model based on CT images is effective at discriminating serosa invasion in gastric cancer.","Stomach neoplasms,Multi-detector computed tomography,Radiomics,Deep learning",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Radiology, Nuclear Medicine & Medical Imaging",,3.539,"COMPUTED-TOMOGRAPHY,PHASE-II,CHEMOTHERAPY,STOMACH",EUROPEAN JOURNAL OF RADIOLOGY,,
37,Discrimination between normal and malignant colorectal tissues based on discrepancies in their dielectric properties using machine learning methods,14,9,770-775,"Sun Ying,Zhang Sa,Duan Song,Huang Lumao);,Li Zhou,Yu Xuefei,Xin Sherman Xuegang","Sun Y,Zhang S,Duan S,Huang LM,Li Z,Yu XF,Xin SX",Xin SX,10.1049/iet-smt.2019.0398,South China University of Technology,"Numerous researchers approved discrepancies in dielectric properties between malignant and normal tissues. Such discrepancies serve as a foundation for the development of computer-aided diagnostic technologies. In this study, machine learning methods were proposed for discrimination between normal and malignant colorectal tissues based on discrepancies in their dielectric properties. To do so, first, two independent-sample t-tests and receiver operating characteristic curve analysis were utilised to examine discrimination power with respect to three types of features, namely, permittivity, conductivity and Cole-Cole fitting parameters. K-nearest neighbour and support vector machine classifiers were used to assess the possibility of combining these features for better classification accuracy. Obtained k-fold cross-validation accuracy reached 88.2%. The obtained accuracy indicated the potential capability of discrimination between normal and malignant colorectal tissues based on discrepancies in their dielectric properties.","image classification,feature extraction,biological tissues,support vector machines,medical image processing,learning (artificial intelligence),pattern classification,cancer,permittivity,normal tissues,malignant colorectal tissues,dielectric properties,malignant tissues,computer-aided diagnostic technologies,neighbour,support vector machine classifiers",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND",Engineering,,1.965,"ELECTRICAL-PROPERTIES,BIOLOGICAL,TISSUES,CARCINOMA,CLASSIFICATION,PARAMETERS,DIAGNOSIS",IET SCIENCE MEASUREMENT & TECHNOLOGY,,
38,Bayesian regularization of multilayer perceptron neural network for estimation of mass attenuation coefficient of gamma radiation in comparison with different supervised model-free methods,15,11,,Moshkbar-Bakhshayesh K.,Moshkbar-Bakhshayesh K,Moshkbar-Bakhshayesh K,10.1088/1748-0221/15/11/P11019,Sharif University of Technology,"Multilayer perceptron (MLP) neural networks have been used extensively for estimation/regression of parameters. Moreover, recent studies have shown that learning algorithms of MLP which are based on Gaussian function are more accurate. In this paper, the mass attenuation coefficient (MAC) of gamma radiation for light-weight materials (e.g. O-8), mid-weight materials (e.g. Al-13), and heavy-weight materials (e.g. Pb-82) is modelled using Gaussian function based regularization of MLP (i.e. Bayesian regularization (BR)) and by a modular estimator. The results are compared with the Reference results. To show better performance of the utilized algorithm, the results of the different supervised methods including support vector machine (SVM) with different kernel functions, decision tree (DT), and radial basis network (RBN) are given. Average mean relative error (AMRE) and cumulative distribution function (CDF) of errors of MACs estimation are calculated. Comparison of the results indicates that MLP-BR gives more accurate results (e.g. AMRE(O-8) = 0.0014, CDFO-8 (0.0069) = 0.99, AMRE(A1-13) = 0.0015, CDFA1-13 (0.0048) = 0.99, AMRE(Pb-82) = 0.0117, CDFPb-82 (0.0523) = 0.99).","Pattern recognition,cluster finding,calibration and fitting methods,Interaction of radiation with matter,Radiation calculations",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Instruments & Instrumentation,,1.328,"2,MEDIA,METHOD",JOURNAL OF INSTRUMENTATION,,
39,Heatwave Damage Prediction Using Random Forest Model in Korea,10,22,,"Park Minsoo,Jung Daekyo,Lee Seungsoo,Park Seunghee","Park M,Jung D,Lee S,Park S",Park S,10.3390/app10228237,Sungkyunkwan University (SKKU),"Climate change increases the frequency and intensity of heatwaves, causing significant human and material losses every year. Big data, whose volumes are rapidly increasing, are expected to be used for preemptive responses. However, human cognitive abilities are limited, which can lead to ineffective decision making during disaster responses when artificial intelligence-based analysis models are not employed. Existing prediction models have limitations with regard to their validation, and most models focus only on heat-associated deaths. In this study, a random forest model was developed for the weekly prediction of heat-related damages on the basis of four years (2015-2018) of statistical, meteorological, and floating population data from South Korea. The model was evaluated through comparisons with other traditional regression models in terms of mean absolute error, root mean squared error, root mean squared logarithmic error, and coefficient of determination (R-2). In a comparative analysis with observed values, the proposed model showed an R-2 value of 0.804. The results show that the proposed model outperforms existing models. They also show that the floating population variable collected from mobile global positioning systems contributes more to predictions than the aggregate population variable.","heatwaves,big data,random forest regression model,machine learning,prediction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"HIGH-TEMPERATURE,PUBLIC-HEALTH,MORTALITY,WAVES,IMPACT,VULNERABILITY,MORBIDITY,CLIMATE,ENGLAND,STRESS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/22/8237/pdf,
40,Deep Adversarial Training for Multi-Organ Nuclei Segmentation in Histopathology Images,39,11,3257-3267,"Mahmood Faisal,Borders Daniel,Chen Richard J.,Mckay Gregory N.,Salimian Kevan J.,Baras Alexander,Durr Nicholas J.","Mahmood F,Borders D,Chen RJ,Mckay GN,Salimian KJ,Baras A,Durr NJ",Durr NJ,10.1109/TMI.2019.2927182,Johns Hopkins University,"Nuclei segmentation is a fundamental task for various computational pathology applications including nuclei morphology analysis, cell type classification, and cancer grading. Deep learning has emerged as a powerful approach to segmenting nuclei but the accuracy of convolutional neural networks (CNNs) depends on the volume and the quality of labeled histopathology data for training. In particular, conventional CNN-based approaches lack structured prediction capabilities, which are required to distinguish overlapping and clumped nuclei. Here, we present an approach to nuclei segmentation that overcomes these challenges by utilizing a conditional generative adversarial network (cGAN) trainedwith syntheticand real data. We generate a large dataset of H&E training images with perfect nuclei segmentation labels using an unpaired GAN framework. This synthetic data along with real histopathology data from six different organs are used to train a conditional GAN with spectral normalization and gradient penalty for nucleisegmentation. This adversarial regression framework enforces higher-order spacial-consistency when compared to conventional CNN models. We demonstrate that this nuclei segmentation approach generalizes across different organs, sites, patients and disease states, and outperforms conventional approaches, especially in isolating individual and overlapping nuclei.","Nuclei segmentation,histopathology segmentation,computational pathology,deep learning,adversarial training,synthetic data,synthetic pathology data",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"STAIN,NORMALIZATION,CANCER,PATHOLOGY",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1810.00236,
41,Causality-Based Feature Fusion for Brain Neuro-Developmental Analysis,39,11,3290-3299,"Hosseinzadeh Kassani Peyman,Xiao Li,Zhang Gemeng,Stephen Julia M.,Wilson Tony W.,Calhoun Vince D.,Wang Yu Ping","Kassani PH,Xiao L,Zhang GM,Stephen JM,Wilson TW,Calhoun VD,Wang YP",Wang YP,10.1109/TMI.2020.2990371,Tulane University,"Human brain development is a complex and dynamic process caused by several factors such as genetics, sex hormones, and environmental changes. A number of recent studies on brain development have examined functional connectivity (FC) defined by the temporal correlation between time series of different brain regions. We propose to add the directional flow of information during brain maturation. To do so, we extract effective connectivity (EC) through Granger causality (GC) for two different groups of subjects, i.e., children and young adults. The motivation is that the inclusion of causal interactionmay further discriminate brain connections between two age groups and help to discover new connections between brain regions. The contributions of this study are threefold. First, there has been a lack of attention to EC-based feature extraction in the context of brain development. To this end, we propose a new kernel-based GC (KGC) method to learn nonlinearity of complex brain network, where a reduced Sine hyperbolic polynomial (RSP) neural networkwas used as our proposed learner. Second, we used causality values as the weight for the directional connectivity between brain regions. Our findings indicated that the strength of connections was significantly higher in youngadults relative to children. In addition, our new EC-based feature outperformed FC-based analysis from Philadelphia neurocohort (PNC) study with better discrimination of different age groups. Moreover, the fusion of these two sets of features (FC + EC) improved brain age prediction accuracy by more than 4%, indicating that they should be used together for brain development studies.","Brain age prediction,brain maturation,causality,polynomial neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"FUNCTIONAL,CONNECTIVITY,NETWORKS,MATURATION,DEFAULT",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2001.08173,
42,Layer Embedding Analysis in Convolutional Neural Networks for Improved Probability Calibration and Classification,39,11,3331-3342,"Zhang Fan,Dvornek Nicha,Yang Junlin,Chapiro Julius,Duncan James","Zhang F,Dvornek N,Yang JL,Chapiro J,Duncan J",Zhang F,10.1109/TMI.2020.2990625,Yale University,"In this project, our goal is to develop a method for interpreting how a neural network makes layer-by-layer embedded decisions when trained for a classification task, and also to use this insight for improving the model performance. To do this, we first approximate the distribution of the image representations in these embeddings using random forest models, the output of which, termed embedding outputs, are used for measuring how the network classifies each sample. Next, we design a pipeline to use this layer embedding output to calibrate the original model output for improved probability calibration and classification. We apply this two-steps method in a fully convolutional neural network trained for a liver tissue classification task on our institutional dataset that contains 20 3D multi-parameter MR images for patients with hepatocellular carcinoma, as well as on a public dataset with 131 3D CT images. The results show that our method is not only able to provide visualizations that are easy to interpret, but that the embedded decision-based information is also useful for improving model performance in terms of probability calibration and classification, achieving the best performance compared to other baseline methods. Moreover, this method is computationally efficient, easy to implement, and robust to hyper-parameters.","Layer embeddings,network interpretability,probability calibration,convolutional neural networks,liver tissue classification",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,https://ieeexplore.ieee.org/ielx7/42/9242349/09082023.pdf,
43,Deep-Learning Image Reconstruction for Real-Time Photoacoustic System,39,11,3379-3390,"Kim MinWoo,Jeng Geng-Shi,Pelivanov Ivan,O'Donnell Matthew","Kim MW,Jeng GS,Pelivanov I,O'Donnell M",Kim MW,10.1109/TMI.2020.2993835,University of Washington,"Recent advances in photoacoustic (PA) imaging have enabled detailed images of microvascular structure and quantitative measurement of blood oxygenation or perfusion. Standard reconstruction methods for PA imaging are based on solving an inverse problem using appropriate signal and system models. For handheld scanners, however, the ill-posed conditions of limited detection view and bandwidth yield low image contrast and severe structure loss in most instances. In this paper, we propose a practical reconstruction method based on a deep convolutional neural network (CNN) to overcome those problems. It is designed for real-time clinical applications and trained by large-scale synthetic data mimicking typical microvessel networks. Experimental results using synthetic and real datasets confirm that the deep-learning approach provides superior reconstructions compared to conventional methods.","Photoacoustic imaging,deep learning,reconstruction,convolutional neural network",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"THERMOACOUSTIC,TOMOGRAPHY,DOMAIN,RECONSTRUCTION,NEURAL-NETWORK,ALGORITHM",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2001.04631,
44,Computer-Aided Cervical Cancer Diagnosis Using Time-Lapsed Colposcopic Images,39,11,3403-3415,"Li Yuexiang,Chen Jiawei,Xue Peng,Tang Chao,Chang Jia,Chu Chunyan,Ma Kai,Li Qing,Zheng Yefeng,Qiao Youlin","Li YX,Chen JW,Xue P,Tang C,Chang J,Chu CY,Ma K,Li Q,Zheng YF,Qiao YL",Zheng YF,10.1109/TMI.2020.2994778,"Tencent Jarvis Lab, Shenzhen 518057, Peoples R China.","Cervical cancer causes the fourth most cancer-related deaths of women worldwide. Early detection of cervical intraepithelial neoplasia (CIN) can significantly increase the survival rate of patients. In this paper, we propose a deep learning framework for the accurate identification of LSIL+ (including CIN and cervical cancer) using time-lapsed colposcopic images. The proposed framework involves two main components, i.e., key-frame feature encoding networks and feature fusion network. The features of the original (pre-acetic-acid) image and the colposcopic images captured at around 60s, 90s, 120s and 150s during the acetic acid test are encoded by the feature encoding networks. Several fusion approaches are compared, all of which outperform the existing automated cervical cancer diagnosis systems using a single time slot. A graph convolutional network with edge features (E-GCN) is found to be the most suitable fusion approach in our study, due to its excellent explainability consistent with the clinical practice. A large-scale dataset, containing time-lapsed colposcopic images from 7,668 patients, is collected from the collaborative hospital to train and validate our deep learning framework. Colposcopists are invited to compete with our computer-aided diagnosis system. The proposed deep learning framework achieves a classification accuracy of 78.33%-comparable to that of an in-service colposcopist-which demonstrates its potential to provide assistance in the realistic clinical scenario.","Cervical cancer,acetic acid test,graph convolutional network,feature fusion",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"NEURAL-NETWORK,CLASSIFICATION,PREVENTION,CHINA",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
45,Associating Multi-Modal Brain Imaging Phenotypes and Genetic Risk Factors via a Dirty Multi-Task Learning Method,39,11,3416-3428,"Du Lei,Liu Fang,Liu Kefei,Yao Xiaohui,Risacher Shannon L.,Han Junwei,Saykin Andrew J.,Shen Li","Du L,Liu F,Liu KF,Yao XH,Risacher SL,Han JW,Saykin AJ,Shen L",Du L,10.1109/TMI.2020.2995510,Northwestern Polytechnical University,"Brain imaging genetics becomes more and more important in brain science, which integrates genetic variations and brain structures or functions to study the genetic basis of brain disorders. The multi-modal imaging data collected by different technologies, measuring the same brain distinctly, might carry complementary information. Unfortunately, we do not know the extent to which the phenotypic variance is shared among multiple imaging modalities, which further might trace back to the complex genetic mechanism. In this paper, we propose a novel dirty multi-task sparse canonical correlation analysis (SCCA) to study imaging genetic problems with multi-modal brain imaging quantitative traits (QTs) involved. The proposed method takes advantages of the multi-task learning and parameter decomposition. It can not only identify the shared imaging QTs and genetic loci across multiple modalities, but also identify the modality-specific imaging QTs and genetic loci, exhibiting a flexible capability of identifying complex multi-SNP-multi-QT associations. Using the state-of-the-art multi-view SCCA and multi-task SCCA, the proposed method shows better or comparable canonical correlation coefficients and canonical weights on both synthetic and real neuroimaging genetic data. In addition, the identified modality-consistent biomarkers, as well as the modality-specific biomarkers, provide meaningful and interesting information, demonstrating the dirty multi-task SCCA could be a powerful alternativemethod inmulti-modal brain imaging genetics.","Brain imaging genetics,sparse canonical correlation analysis,multi-task learning,the dirty multi-task SCCA",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CANONICAL,CORRELATION-ANALYSIS,ALZHEIMERS-DISEASE,SEQUENCE,DIAGNOSIS,GENOTYPE,PROGRESS,ATROPHY",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
46,Semi-Supervised Medical Image Classification With Relation-Driven Self-Ensembling Model,39,11,3429-3440,"Liu Quande,Yu Lequan,Luo Luyang,Dou Qi,Heng Pheng Ann","Liu QD,Yu LQ,Luo LY,Dou Q,Heng PA",Yu LQ,10.1109/TMI.2020.2995518,Chinese University of Hong Kong,"Training deep neural networks usually requires a large amount of labeled data to obtain good performance. However, in medical image analysis, obtaining high-quality labels for the data is laborious and expensive, as accurately annotating medical images demands expertise knowledge of the clinicians. In this paper, we present a novel relation-driven semi-supervised framework for medical image classification. It is a consistency-based method which exploits the unlabeled data by encouraging the prediction consistency of given input under perturbations, and leverages a self-ensembling model to produce high-quality consistency targets for the unlabeled data. Considering that human diagnosis often refers to previous analogous cases to make reliable decisions, we introduce a novel sample relation consistency (SRC) paradigm to effectively exploit unlabeled data by modeling the relationship information among different samples. Superior to existing consistency-based methods which simply enforce consistency of individual predictions, our framework explicitly enforces the consistency of semantic relation among different samples under perturbations, encouraging the model to explore extra semantic information from unlabeled data. We have conducted extensive experiments to evaluate our method on two public benchmark medical image classification datasets, i.e., skin lesion diagnosis with ISIC 2018 challenge and thorax disease classification with ChestX-ray14. Our method outperforms many state-of-the-art semi-supervised learning methods on both single-label and multi-label image classification scenarios.","Semi-supervised learning,medical image classification,sample relation modelling,self-ensembling model",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,SEGMENTATION,IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2005.07377,
47,Known Operator Learning Enables Constrained Projection Geometry Conversion: Parallel to Cone-Beam for Hybrid MR/X-Ray Imaging,39,11,3488-3498,"Syben Christopher,Stimpel Bernhard,Roser Philipp,Doerfler Arnd,Maier Andreas","Syben C,Stimpel B,Roser P,Dorfler A,Maier A",Syben C,10.1109/TMI.2020.2998179,University of Erlangen Nuremberg,"X-ray imaging is a wide-spread real-time imaging technique. Magnetic Resonance Imaging (MRI) offers a multitude of contrasts that offer improved guidance to interventionalists. As such simultaneous real-time acquisition and overlay would be highly favorable for image-guided interventions, e.g., in stroke therapy. One major obstacle in this setting is the fundamentally different acquisition geometry. MRI k-space sampling is associated with parallel projection geometry, while the X-ray acquisition results in perspective distorted projections. The classical rebinning methods to overcome this limitation inherently suffers from a loss of resolution. To counter this problem, we present a novel rebinning algorithm for parallel to cone-beam conversion. We derive a rebinning formula that is then used to find an appropriate deep neural network architecture. Following the known operator learning paradigm, the novel algorithm is mapped to a neural network with differentiable projection operators enabling data-driven learning of the remaining unknown operators. The evaluation aims in two directions: First, we give a profound analysis of the different hypotheses to the unknown operator and investigate the influence of numerical training data. Second, we evaluate the performance of the proposed method against the classical rebinning approach. We demonstrate that the derived network achieves better results than the baseline method and that such operators can be trained with simulated data without losing their generality making them applicable to real data without the need for retraining or transfer learning.","Known operator learning,inverse problems,multi-modal imaging,X-ray,MRI",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"RECONSTRUCTION,DOMAIN",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
48,Iterative Augmentation of Visual Evidence for Weakly-Supervised Lesion Localization in Deep Interpretability Frameworks: Application to Color Fundus Images,39,11,3499-3511,"Gonzalez-Gonzalo Cristina,Liefers Bart,van Ginneken Bram,Sanchez Clara I.","Gonzalez-Gonzalo C,Liefers B,van Ginneken B,Sanchez CI",Gonzalez-Gonzalo C,10.1109/TMI.2020.2994463,"Radboudumc, Eye Res Grp A, Diagnost Image Anal Grp, Dept Radiol & Nucl Med, NL-6525 Nijmegen, Netherlands.","Interpretability of deep learning (DL) systems is gaining attention in medical imaging to increase experts' trust in the obtained predictions and facilitate their integration in clinical settings. We propose a deep visualization method to generate interpretability of DL classification tasks in medical imaging by means of visual evidence augmentation. The proposed method iteratively unveils abnormalities based on the prediction of a classifier trained only with image-level labels. For each image, initial visual evidence of the prediction is extracted with a given visual attribution technique. This provides localization of abnormalities that are then removed through selective inpainting. We iteratively apply this procedure until the system considers the image as normal. This yields augmented visual evidence, including less discriminative lesions which were not detected at first but should be considered for final diagnosis. We apply the method to grading of two retinal diseases in color fundus images: diabetic retinopathy (DR) and age-related macular degeneration (AMD). We evaluate the generated visual evidence and the performance of weakly-supervised localization of different types of DR and AMD abnormalities, both qualitatively and quantitatively. We show that the augmented visual evidence of the predictions highlights the biomarkers considered by experts for diagnosis and improves the final localization performance. It results in a relative increase of 11.2 +/- 2.0% per image regarding sensitivity averaged at 10 false positives/image on average, when applied to different classification tasks, visual attribution techniques and network architectures. This makes the proposed method a useful tool for exhaustive visual support of DL classifiers in medical imaging.","Interpretability,deep learning,visualization,weakly-supervised detection,lesion localization,color fundus imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"DIABETIC-RETINOPATHY,MACULAR,DEGENERATION,DISEASE,CLASSIFICATION,DRUSEN",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://ieeexplore.ieee.org/ielx7/42/9242349/09103111.pdf,
49,Differentiated Backprojection Domain Deep Learning for Conebeam Artifact Removal,39,11,3571-3582,"Han Yoseob,Kim Junyoung,Ye Jong Chul","Han YS,Kim J,Ye JC",Ye JC,10.1109/TMI.2020.3000341,Korea Advanced Institute of Science & Technology (KAIST),"Conebeam CT using a circular trajectory is quite often used for various applications due to its relative simple geometry. For conebeam geometry, Feldkamp, Davis and Kress algorithm is regarded as the standard reconstruction method, but this algorithm suffers from so-called conebeam artifacts as the cone angle increases. Various model-based iterative reconstruction methods have been developed to reduce the cone-beam artifacts, but these algorithms usually require multiple applications of computational expensive forward and backprojections. In this paper, we develop a novel deep learning approach for accurate conebeam artifact removal. In particular, our deep network, designed on the differentiated backprojection domain, performs a data-driven inversion of an ill-posed deconvolution problem associated with the Hilbert transform. The reconstruction results along the coronal and sagittal directions are then combined using a spectral blending technique to minimize the spectral leakage. Experimental results under various conditions confirmed that our method generalizes well and outperforms the existing iterative methods despite significantly reduced runtime complexity.","Computed Tomography,cone-beam artifact,deep learning,spectral blending",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONVOLUTIONAL,NEURAL-NETWORK,BEAM,COMPUTED-TOMOGRAPHY,IMAGE-RECONSTRUCTION,FILTERED,BACKPROJECTION,PI-LINES,CT,FRAMELETS,ALGORITHM",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/1906.06854,
50,Deep Mining External Imperfect Data for Chest X-Ray Disease Screening,39,11,3583-3594,"Luo Luyang,Yu Lequan,Chen Hao,Liu Quande,Wang Xi,Xu Jiaqi,Heng Pheng-Ann","Luo LY,Yu LQ,Chen H,Liu QD,Wang X,Xu JQ,Heng PA",Chen H,10.1109/TMI.2020.3000949,Chinese University of Hong Kong,"Deep learning approaches have demonstrated remarkable progress in automatic Chest X-ray analysis. The data-driven feature of deep models requires training data to cover a large distribution. Therefore, it is substantial to integrate knowledge from multiple datasets, especially for medical images. However, learning a disease classification model with extra Chest X-ray (CXR) data is yet challenging. Recent researches have demonstrated that performance bottleneck exists in joint training on different CXR datasets, and few made efforts to address the obstacle. In this paper, we argue that incorporating an external CXR dataset leads to imperfect training data, which raises the challenges. Specifically, the imperfect data is in two folds: domain discrepancy, as the image appearances vary across datasets; and label discrepancy, as different datasets are partially labeled. To this end, we formulate the multi-label thoracic disease classification problem as weighted independent binary tasks according to the categories. For common categories shared across domains, we adopt task-specific adversarial training to alleviate the feature differences. For categories existing in a single dataset, we present uncertainty-aware temporal ensembling of model predictions to mine the information from the missing labels further. In this way, our framework simultaneously models and tackles the domain and label discrepancies, enabling superior knowledge mining ability. We conduct extensive experiments on three datasets with more than 360,000 Chest X-ray images. Our method outperforms other competing models and sets state-of-the-art performance on the official NIH test set with 0.8349 AUC, demonstrating its effectiveness of utilizing the external dataset to improve the internal classification.","Chest X-ray classification,partial label,domain discrepancy,adversarial learning,uncertainty",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"PROSTATE,LUNG",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2006.03796,
51,Multi-Organ Segmentation Over Partially Labeled Datasets With Multi-Scale Feature Abstraction,39,11,3619-3629,"Fang Xi,Yan Pingkun","Fang X,Yan PK",Yan PK,10.1109/TMI.2020.3001036,Rensselaer Polytechnic Institute,"Shortage of fully annotated datasets has been a limiting factor in developing deep learning based image segmentation algorithms and the problem becomes more pronounced in multi-organ segmentation. In this paper, we propose a unified training strategy that enables a novel multi-scale deep neural network to be trained on multiple partially labeled datasets for multi-organ segmentation. In addition, a new network architecture for multi-scale feature abstraction is proposed to integrate pyramid input and feature analysis into a U-shape pyramid structure. To bridge the semantic gap caused by directly merging features from different scales, an equal convolutional depth mechanism is introduced. Furthermore, we employ a deep supervision mechanism to refine the outputs in different scales. To fully leverage the segmentation features from all the scales, we design an adaptive weighting layer to fuse the outputs in an automatic fashion. All these mechanisms together are integrated into a Pyramid Input Pyramid Output Feature Abstraction Network (PIPO-FAN). Our proposed method was evaluated on four publicly available datasets, including BTCV, LiTS, KiTS and Spleen, where very promising performance has been achieved. The source code of this work is publicly shared at https://github.com/DIAL-RPI/PIPO-FAN to facilitate others to reproduce the work and build their own models using the introduced mechanisms.","Medical image segmentation,multi-scale feature,deep learning,convolutional neural networks,multi-organ segmentation,multiple datasets",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2001.00208,
52,Deep Learning-Based Spectral Unmixing for Optoacoustic Imaging of Tissue Oxygen Saturation,39,11,3643-3654,"Olefir Ivan,Tzoumas Stratis,Restivo Courtney,Mohajerani Pouyan,Xing Lei,Ntziachristos Vasilis","Olefir I,Tzoumas S,Restivo C,Mohajerani P,Xing L,Ntziachristos V",Ntziachristos V,10.1109/TMI.2020.3001750,Helmholtz Association,"Label free imaging of oxygenation distribution in tissues is highly desired in numerous biomedical applications, but is still elusive, in particular in sub-epidermal measurements. Eigenspectra multispectral optoacoustic tomography (eMSOT) and its Bayesian-based implementation have been introduced to offer accurate label-free blood oxygen saturation (sO(2)) maps in tissues. The method uses the eigenspectra model of light fluence in tissue to account for the spectral changes due to the wavelength dependent attenuation of light with tissue depth. eMSOT relies on the solution of an inverse problem bounded by a number of ad hoc hand-engineered constraints. Despite the quantitative advantage offered by eMSOT, both the non-convex nature of the optimization problem and the possible sub-optimality of the constraints may lead to reduced accuracy. We present herein a neural network architecture that is able to learn how to solve the inverse problem of eMSOT by directly regressing from a set of input spectra to the desired fluence values. The architecture is composed of a combination of recurrent and convolutional layers and uses both spectral and spatial features for inference. We train an ensemble of such networks using solely simulated data and demonstrate how this approach can improve the accuracy of sO(2) computation over the original eMSOT, not only in simulations but also in experimental datasets obtained from blood phantoms and small animals (mice) in vivo. The use of a deep-learning approach in optoacoustic sO(2) imaging is confirmed herein for the first time on ground truth sO(2) values experimentally obtained in vivo and ex vivo.","Optoacoustic/photoacoustic imaging,multispectral optoacoustic tomography,photoacoustic tomography,deep learning,deep neural networks",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"QUANTITATIVE,PHOTOACOUSTIC,TOMOGRAPHY,BLOOD,OXYGENATION,RECONSTRUCTION,MICROSCOPY,NETWORKS,BOUNDARY",IEEE TRANSACTIONS ON MEDICAL IMAGING,https://push-zb.helmholtz-muenchen.de/deliver.php?id=29069,
53,Weakly Supervised Deep Nuclei Segmentation Using Partial Points Annotation in Histopathology Images,39,11,3655-3666,"Qu Hui,Wu Pengxiang,Huang Qiaoying,Yi Jingru,Yan Zhennan,Li Kang,Riedlinger Gregory M.,De Subhajyoti,Zhang Shaoting,Metaxas Dimitris N.","Qu H,Wu PX,Huang QY,Yi JR,Yan ZN,Li K,Riedlinger GM,De SB,Zhang ST,Metaxas DN",Qu H,10.1109/TMI.2020.3002244,Rutgers State University New Brunswick,"Nuclei segmentation is a fundamental task in histopathology image analysis. Typically, such segmentation tasks require significant effort to manually generate accurate pixel-wise annotations for fully supervised training. To alleviatesuch tedious and manual effort, in this paper we propose a novel weakly supervised segmentation framework based on partial points annotation, i.e., only a small portion of nuclei locations in each image are labeled. The framework consists of two learning stages. In the first stage, we design a semi-supervised strategy to learn a detection model from partially labeled nuclei locations. Specifically, an extended Gaussian mask is designed to train an initial model with partially labeled data. Then, self-training with background propagation is proposed to make use of the unlabeled regions to boost nuclei detection and suppress false positives. In the second stage, a segmentation model is trained from the detected nuclei locations in a weakly-supervised fashion. Two types of coarse labels with complementary information are derived from the detected points and are then utilized to train a deep neural network. The fully-connected conditional random field loss is utilized in training to further refine the model without introducing extra computational complexity during inference. The proposed method is extensively evaluated on two nuclei segmentation datasets. The experimental results demonstrate that our method can achieve competitive performance compared to the fully supervised counterpart and the state-of-the-art methods while requiring significantly less annotation effort.","Nuclei detection,nuclei segmentation,semi-supervised learning,weakly-supervised learning,deep learning,Voronoi diagram,k-means clustering,conditional random field",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,MODEL,IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2007.05448,
54,Appearance Learning for Image-Based Motion Estimation in Tomography,39,11,3667-3678,"Preuhs Alexander,Manhart Michael,Roser Philipp,Hoppe Elisabeth,Huang Yixing,Psychogios Marios,Kowarschik Markus,Maier Andreas","Preuhs A,Manhart M,Roser P,Hoppe E,Huang YX,Psychogios M,Kowarschik M,Maier A",Preuhs A,10.1109/TMI.2020.3002695,University of Erlangen Nuremberg,"In tomographic imaging, anatomical structures are reconstructed by applying a pseudo- inverse forward model to acquired signals. Geometric information within this process is usually depending on the system setting only, i.e., the scanner position or readout direction. Patient motion therefore corrupts the geometry alignment in the reconstruction process resulting in motion artifacts. We propose an appearance learning approach recognizing the structures of rigid motion independently from the scanned object. To this end, we train a siamese triplet network to predict the reprojection error (RPE) for the complete acquisition as well as an approximate distribution of the RPE along the single views from the reconstructed volume in a multi-task learning approach. The RPE measures the motion-induced geometric deviations independent of the object based on virtual marker positions, which are available during training. We train our network using 27 patients and deploy a 21-4-2 split for training, validation and testing. In average, we achieve a residual mean RPE of 0.013 mm with an inter-patient standard deviation of 0.022 mm. This is twice the accuracy compared to previously published results. In a motion estimation benchmark the proposed approach achieves superior results in comparison with two state-of-the-art measures in nine out of twelve experiments. The clinical applicability of the proposed method is demonstrated on a motion-affected clinical dataset.","rigid motion compensation,reconstruction,interventional CBCT,autofocus,appearance learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CONE-BEAM,CT,ARTIFACT,REDUCTION,HEAD,MOTION,RECONSTRUCTION,COMPENSATION,ALGORITHM",IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2006.10390,
55,Optimization for Medical Image Segmentation: Theory and Practice When Evaluating With Dice Score or Jaccard Index,39,11,3679-3690,"Eelbode Tom,Bertels Jeroen,Berman Maxim,Vandermeulen Dirk,Maes Frederik,Bisschops Raf,Blaschko Matthew B.","Eelbode T,Bertels J,Berman M,Vandermeulen D,Maes F,Bisschops R,Blaschko MB",Eelbode T,10.1109/TMI.2020.3002417,KU Leuven,"In many medical imaging and classical computer vision tasks, the Dice score and Jaccard index are used to evaluate the segmentation performance. Despite the existence and great empirical success of metric-sensitive losses, i.e. relaxations of these metrics such as soft Dice, soft Jaccard and Lovasz-Softmax, many researchers still use per-pixel losses, such as (weighted) cross-entropy to train CNNs for segmentation. Therefore, the target metric is in many cases not directly optimized. We investigate from a theoretical perspective, the relation within the group of metric-sensitive loss functions and question the existence of an optimal weighting scheme for weighted cross-entropy to optimize the Dice score and Jaccard index at test time. We find that the Dice score and Jaccard index approximate each other relatively and absolutely, but we find no such approximation for a weighted Hamming similarity. For the Tversky loss, the approximation gets monotonically worse when deviating from the trivial weight setting where soft Tversky equals soft Dice. We verify these results empirically in an extensive validation on six medical segmentation tasks and can confirm that metric-sensitive losses are superior to cross-entropy based loss functions in case of evaluation with Dice Score or Jaccard Index. This further holds in a multi-class setting, and across different object sizes and foreground/background ratios. These results encourage a wider adoption of metric-sensitive loss functions for medical segmentation tasks where the performance measure of interest is the Dice score or Jaccard index.","Dice,Jaccard,risk minimization,cross-entropy,Tversky",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,,IEEE TRANSACTIONS ON MEDICAL IMAGING,http://arxiv.org/pdf/2010.13499,
56,Hierarchical Nonlocal Residual Networks for Image Quality Assessment of Pediatric Diffusion MRI With Limited and Noisy Annotations,39,11,3691-3702,"Liu Siyuan,Thung Kim-Han,Lin Weili,Shen Dinggang,Yap Pew-Thian","Liu SY,Thung KH,Lin WL,Shen DG,Yap PT",Shen DG; Yap PT,10.1109/TMI.2020.3002708,University of North Carolina,"Fast and automated image quality assessment (IQA) of diffusion MR images is crucial for making timely decisions for rescans. However, learning a model for this task is challenging as the number of annotated data is limited and the annotation labels might not always be correct. As a remedy, we will introduce in this paper an automatic image quality assessment (IQA) method based on hierarchical non-local residual networks for pediatric diffusion MR images. Our IQA is performed in three sequential stages, i.e., 1) slice-wise IQA, where a nonlocal residual network is first pre-trained to annotate each slice with an initial quality rating (i.e., pass/questionable/fail), which is subsequently refined via iterative semi-supervised learning and slice self-training; 2) volume-wise IQA, which agglomerates the features extracted from the slices of a volume, and uses a nonlocal network to annotate the quality rating for each volume via iterative volume self-training; and 3) subject-wise IQA, which ensembles the volumetric IQA results to determine the overall image quality pertaining to a subject. Experimental results demonstrate that our method, trained using only samples of modest size, exhibits great generalizability, and is capable of conducting rapid hierarchical IQA with near-perfect accuracy.","Image quality assessment,hierarchical nonlocal residual networks,semi-supervised learning,self-training",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Computer Science,Engineering,Imaging Science & Photographic Technology,Radiology, Nuclear Medicine & Medical Imaging",,10.332,"CLASSIFICATION,ARTIFACTS,EFFICIENT,MOTION",IEEE TRANSACTIONS ON MEDICAL IMAGING,,
57,Automated Lung Ultrasound B-Line Assessment Using a Deep Learning Algorithm,67,11,2312-2320,"Baloescu Cristiana,Toporek Grzegorz,Kim Seungsoo,McNamara Katelyn,Liu Rachel,Shaw Melissa M.);,McNamara Robert L.,Raju Balasundar I.,Moore Christopher L.","Baloescu C,Toporek G,Kim S,McNamara K,Liu R,Shaw MM,McNamara RL,Raju BI,Moore CL",Baloescu C,10.1109/TUFFC.2020.3002249,Yale University,"Shortness of breath is a major reason that patients present to the emergency department (ED) and point-of-care ultrasound (POCUS) has been shown to aid in diagnosis, particularly through evaluation for artifacts known as B-lines. B-line identification and quantification can be a challenging skill for novice ultrasound users, and experienced users could benefit from a more objective measure of quantification. We sought to develop and test a deep learning (DL) algorithm to quantify the assessment of B-lines in lung ultrasound. We utilized ultrasound clips ( n = 400) froman existing database of ED patients to provide training and test sets to develop and test the DL algorithm based on deep convolutional neural networks. Interpretations of the images by algorithm were compared to expert human interpretations on binary and severity (a scale of 04) classifications. Our model yielded a sensitivity of 93% (95% confidence interval (CI) 81%-98%) and a specificity of 96% (95% CI 84%-99%) for the presence or absence of B-lines compared to expert read, with a kappa of 0.88 (95% CI 0.79-0.97). Model to expert agreement for severity classificationyielded aweighted kappa of 0.65 (95% CI 0.56074). Overall, the DL algorithm performed well and could be integrated into an ultrasound system in order to help diagnose and track B-line severity. The algorithm is better at distinguishing the presence from the absence of B-lines but can also be successfully used to distinguish between B-line severity. Suchmethods could decreasevariabilityand provide a standardizedmethod for improved diagnosis and outcome.","Ultrasonic imaging,Lung,Deep learning,Training,Diseases,Classification algorithms,Biomedical imaging,Medical imaging,medical signal and image processing,medical ultrasonics,signal and image processing",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Acoustics,Engineering",,2.752,"PULMONARY,CONGESTION,PROGNOSTIC,VALUE,INTERRATER,RELIABILITY,HEART-FAILURE,AGREEMENT,MORTALITY,DYSPNEA,EDEMA,SIGN",IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL,,
58,Predicting the Printability in Selective Laser Melting with a Supervised Machine Learning Method,13,22,,"Chen Yingyan,Wang Hongze,Wu Yi,Wang Haowei","Chen YY,Wang HZ,Wu Y,Wang HW",Wang HZ; Wu Y,10.3390/ma13225063,Shanghai Jiao Tong University,"Though selective laser melting (SLM) has a rapidly increasing market these years, the quality of the SLM-fabricated part is extremely dependent on the process parameters. However, the current metallographic examination method to find the parameter window is time-consuming and involves subjective assessments of the experimenters. Here, we proposed a supervised machine learning (ML) method to detect the track defect and predict the printability of material in SLM intelligently. The printed tracks were classified into five types based on the measured surface morphologies and characteristics. The classification results were used as the target output of the ML model. Four indicators had been calculated to evaluate the quality of the tracks quantitatively, serving as input variables of the model. The data-driven model can determine the defect-free process parameter combination, which significantly improves the efficiency in searching the process parameter window and has great potential for the application in the unmanned factory in the future.","selective laser melting,machine learning,defect detection,printability prediction",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"POWDER-BED,FUSION,OPTIMIZATION,PARAMETERS,SURFACE,FLOW",MATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7698234,
59,The promise of implementing machine learning in earthquake engineering: A state-of-the-art review,36,4,1769-1801,"Xie Yazhou,Ebad Sichani Majid,Padgett Jamie E.,DesRoches Reginald","Xie YZ,Sichani ME,Padgett JE,DesRoches R",Xie YZ,10.1177/8755293020919419,McGill University,"Machine learning (ML) has evolved rapidly over recent years with the promise to substantially alter and enhance the role of data science in a variety of disciplines. Compared with traditional approaches, ML offers advantages to handle complex problems, provide computational efficiency, propagate and treat uncertainties, and facilitate decision making. Also, the maturing of ML has led to significant advances in not only the main-stream artificial intelligence (AI) research but also other science and engineering fields, such as material science, bioengineering, construction management, and transportation engineering. This study conducts a comprehensive review of the progress and challenges of implementing ML in the earthquake engineering domain. A hierarchical attribute matrix is adopted to categorize the existing literature based on four traits identified in the field, such as ML method, topic area, data resource, and scale of analysis. The state-of-the-art review indicates to what extent ML has been applied in four topic areas of earthquake engineering, including seismic hazard analysis, system identification and damage detection, seismic fragility assessment, and structural control for earthquake mitigation. Moreover, research challenges and the associated future research needs are discussed, which include embracing the next generation of data sharing and sensor technologies, implementing more advanced ML techniques, and developing physics-guided ML models.","Machine learning,earthquake engineering,seismic hazard analysis,system identification and damage detection,structural control,seismic fragility assessment",Review,"SAGE PUBLICATIONS INC, 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA",Engineering,,3.618,"ARTIFICIAL,NEURAL-NETWORK,GROUND-MOTION,PARAMETERS,SEISMIC,FRAGILITY,ANALYSIS,NONPARAMETRIC,DAMAGE,DETECTION,SUPPORT,VECTOR,REGRESSION,INDUCED,SOIL,LIQUEFACTION,THEORY-GUIDED-DATA,MULTI-HAZARD,RISK,PREDICTION,EQUATIONS,STRUCTURAL,CONTROL",EARTHQUAKE SPECTRA,,
60,A Supervised Descent Learning Technique for Solving Directional Electromagnetic Logging-While-Drilling Inverse Problems,58,11,8013-8025,"Hu Yanyan,Guo Rui,Jin Yuchen,Wu Xuqing,Li Maokun,Abubakar Aria,Chen Jiefu","Hu YY,Guo R,Jin YC,Wu XQ,Li MK,Abubakar A,Chen JF",Chen JF,10.1109/TGRS.2020.2986000,University of Houston System,"In this article, a new scheme based on the supervised descent method ( SDM) for solving directional electromagnetic logging-while-drilling (LWD) inverse problems is proposed. The SDM provides us a new perspective to combine the classical gradient-based inversion and machine-learning-based inversion schemes. It iteratively learns a set of descent directions in the offline training process, where the training model set is generated in advance according to the prior information, and then updates the models with the learned descent directions as well as data residuals in the prediction stage, resulting in great flexibility to incorporate prior information, the capability of skipping local minima, and accelerated convergence. The generalization ability of the SDM to interrogate new models that are not contained in the training model set is also explored. By utilizing real-time information obtained from the logging process, the learned descent directions can be slightly revised with a higher efficiency to get closer to the true model. In addition, we probe the sensitivity of the SDM by adding different levels of random noise to the measurements. Numerical examples demonstrate that SDM-based inversion can achieve a higher resolution, faster convergence, and higher robustness than conventional schemes such as Occam's inversion.","Descent directions learning,directional electromagnetic logging-while-drilling (LWD),inverse problem,machine learning,supervised descent method (SDM),well logging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Geochemistry & Geophysics,Engineering,Remote Sensing,Imaging Science & Photographic Technology",,6.086,"COMPUTATION,ALGORITHM,MODELS",IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,,
61,Nonlinear Optical Characterization of 2D Materials,10,11,,"Zhou Linlin,Fu Huange,Lv Ting,Wang Chengbo,Gao Hui,Li Daqian,Deng Leimin,Xiong Wei","Zhou LL,Fu HG,Lv T,Wang CB,Gao H,Li DQ,Deng LM,Xiong W",Xiong W,10.3390/nano10112263,Huazhong University of Science & Technology,"Characterizing the physical and chemical properties of two-dimensional (2D) materials is of great significance for performance analysis and functional device applications. As a powerful characterization method, nonlinear optics (NLO) spectroscopy has been widely used in the characterization of 2D materials. Here, we summarize the research progress of NLO in 2D materials characterization. First, we introduce the principles of NLO and common detection methods. Second, we introduce the recent research progress on the NLO characterization of several important properties of 2D materials, including the number of layers, crystal orientation, crystal phase, defects, chemical specificity, strain, chemical dynamics, and ultrafast dynamics of excitons and phonons, aiming to provide a comprehensive review on laser-based characterization for exploring 2D material properties. Finally, the future development trends, challenges of advanced equipment construction, and issues of signal modulation are discussed. In particular, we also discuss the machine learning and stimulated Raman scattering (SRS) technologies which are expected to provide promising opportunities for 2D material characterization.","two-dimensional materials,nonlinear optics,nonlinear optical characterization,multi-modal spectroscopy",Review,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Science & Technology - Other Topics,Materials Science,Physics",,5.346,"STOKES-RAMAN,SCATTERING,2ND-HARMONIC,GENERATION,3RD-HARMONIC,GENERATION,VALLEY,POLARIZATION,MONOLAYER,MOS2,IN-SITU,SPECTROSCOPY,TRANSITION,MICROSCOPY,CARS",NANOMATERIALS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7696749,
62,A Physics-Informed Assembly of Feed-Forward Neural Network Engines to Predict Inelasticity in Cross-Linked Polymers,12,11,,"Ghaderi Aref,Morovati Vahid,Dargazany Roozbeh","Ghaderi A,Morovati V,Dargazany R",Dargazany R,10.3390/polym12112628,Michigan State University,"In solid mechanics, data-driven approaches are widely considered as the new paradigm that can overcome the classic problems of constitutive models such as limiting hypothesis, complexity, and accuracy. However, the implementation of machine-learned approaches in material modeling has been modest due to the high-dimensionality of the data space, the significant size of missing data, and limited convergence. This work proposes a framework to hire concepts from polymer science, statistical physics, and continuum mechanics to provide super-constrained machine-learning techniques of reduced-order to partly overcome the existing difficulties. Using a sequential order-reduction, we have simplified the 3D stress-strain tensor mapping problem into a limited number of super-constrained 1D mapping problems. Next, we introduce an assembly of multiple replicated neural network learning agents (L-agents) to systematically classify those mapping problems into a few categories, each of which were described by a distinct agent type. By capturing all loading modes through a simplified set of dispersed experimental data, the proposed hybrid assembly of L-agents provides a new generation of machine-learned approaches that simply outperform most constitutive laws in training speed, and accuracy even in complicated loading scenarios. Interestingly, the physics-based nature of the proposed model avoids the low interpretability of conventional machine-learned models.","cross-linked polymer,constitutive model,data-driven,Mullins effect,neural network",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Polymer Science,,4.493,"CONSTITUTIVE,MODEL,RUBBER,MECHANICS,BEHAVIOR,IDENTIFICATION,ELASTOMERS,FRAMEWORK,SURFACE",POLYMERS,http://arxiv.org/pdf/2007.03067,
63,Learning Representations of Inorganic Materials from Generative Adversarial Networks,12,11,,"Hu Tiantian,Song Hui,Jiang Tao,Li Shaobo","Hu TT,Song H,Jiang T,Li SB",Li SB,10.3390/sym12111889,Guizhou University,"The two most important aspects of material research using deep learning (DL) or machine learning (ML) are the characteristics of materials data and learning algorithms, where the proper characterization of materials data is essential for generating accurate models. At present, the characterization of materials based on the molecular composition includes some methods based on feature engineering, such as Magpie and One-hot. Although these characterization methods have achieved significant results in materials research, these methods based on feature engineering cannot guarantee the integrity of materials characterization. One possible approach is to learn the materials characterization via neural networks using the chemical knowledge and implicit composition rules shown in large-scale known materials. This article chooses an adversarial method to learn the composition of atoms using the Generative Adversarial Network (GAN), which makes sense for data symmetry. The total loss value of the discriminator on the test set is reduced from 4.1e13 to 0.3194, indicating that the designed GAN network can well capture the combination of atoms in real materials. We then use the trained discriminator weights for material characterization and predict bandgap, formation energy, critical temperature (Tc) of superconductors on the Open Quantum Materials Database (OQMD), Materials Project (MP), and SuperCond datasets. Experiments show that when using the same predictive model, our proposed method performs better than One-hot and Magpie. This article provides an effective method for characterizing materials based on molecular composition in addition to Magpie, One-hot, etc. In addition, the generator learned in this study generates hypothetical materials with the same distribution as known materials, and these hypotheses can be used as a source for new material discovery.","GAN,deep learning,materials discovery",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Science & Technology - Other Topics,,2.612,,SYMMETRY-BASEL,https://www.mdpi.com/2073-8994/12/11/1889/pdf,
64,Dictionary selection for compressed sensing of EEG signals using sparse binary matrix and spatiotemporal sparse Bayesian learning,6,6,,"Dey Manika Rani,Shiraz Arsam,Sharif Saeed,Lota Jaswinder,Demosthenous Andreas","Dey MR,Shiraz A,Sharif S,Lota J,Demosthenous A",Demosthenous A,10.1088/2057-1976/abc133,University of London,"Online monitoring of electroencephalogram (EEG) signals is challenging due to the high volume of data and power requirements. Compressed sensing (CS) may be employed to address these issues. Compressed sensing using a sparse binary matrix, owing to its low power features, and reconstruction/decompression using spatiotemporal sparse Bayesian learning have been shown to constitute a robust framework for fast, energy efficient and accurate multichannel bio-signal monitoring. EEG signal, however, does not show a strong temporal correlation. Therefore, the use of sparsifying dictionaries has been proposed to exploit the sparsity in a transformed domain instead. Assuming sparsification adds values, a challenge, therefore, in employing this CS framework for the EEG signal, is to identify the suitable dictionary. Using real multichannel EEG data from 15 subjects, in this paper, we systematically evaluate the performance of the framework when using various wavelet bases while considering their key attributes namely number of vanishing moments and coherence with sensing matrix. We identified Beylkin as the wavelet dictionary leading to the best performance. Using the same dataset, we then compared the performance of Beylkin with the discrete cosine basis, often used in the literature, and the alternative of not using a sparsifying dictionary. We further demonstrate that using dictionaries (Beylkin and Discrete Cosine Transform (DCT)) may improve performance tangibly only for a high compression ratio (CR) of 80% and with smaller block sizes, as compared to using no dictionaries.","compressed sensing,dictionary,DWT,EEG,signal reconstruction",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Radiology, Nuclear Medicine & Medical Imaging",,,EXTENSION,BIOMEDICAL PHYSICS & ENGINEERING EXPRESS,https://repository.uel.ac.uk/download/3665162b044d5e0c117432eff68a8ce8b30e8ee8748a7ab1101479f8c7046b3c/1552865/Dey_2020_Biomed._Phys._Eng._Express_6_065024.pdf,
65,Non-Invasive Prediction of IDH Mutation in Patients with Glioma WHO II/III/IV Based on F-18-FET PET-Guided In Vivo H-1-Magnetic Resonance Spectroscopy and Machine Learning,12,11,,"Bumes Elisabeth,Wirtz Fro-Philip,Fellner Claudia,Grosse Jirka,Hellwig Dirk,Oefner Peter J.,Haeckl Martina,Linker Ralf,Proescholdt Martin,Schmidt Nils Ole","Bumes E,Wirtz FP,Fellner C,Grosse J,Hellwig D,Oefner PJ,Hackl M,Linker R,Proescholdt M,Schmidt NO",Bumes E,10.3390/cancers12113406,University of Regensburg,"Simple Summary
Approximately 75-80% of according to the classification of world health organization (WHO) grade II and III gliomas are characterized by a mutation of the isocitrate dehydrogenase (IDH) enzymes, which are very important in glioma cell metabolism. Patients with IDH mutated glioma have a significantly better prognosis than patients with IDH wildtype status, typically seen in glioblastoma WHO grade IV. Here we used a prospective O-(2-F-18-fluoroethyl)-L-tyrosine (F-18-FET) positron emission tomography guided single-voxel H-1-magnetic resonance spectroscopy approach to predict the IDH status before surgery. Finally, 34 patients were included in this neuroimaging study, of whom eight had additionally tissue analysis. Using a machine learning technique, we predicted IDH status with an accuracy of 88.2%, a sensitivity of 95.5% and a specificity of 75.0%. It was newly recognized, that two metabolites (myo-inositol and glycine) have a particularly important role in the determination of the IDH status.
Isocitrate dehydrogenase (IDH)-1 mutation is an important prognostic factor and a potential therapeutic target in glioma. Immunohistological and molecular diagnosis of IDH mutation status is invasive. To avoid tumor biopsy, dedicated spectroscopic techniques have been proposed to detect D-2-hydroxyglutarate (2-HG), the main metabolite of IDH, directly in vivo. However, these methods are technically challenging and not broadly available. Therefore, we explored the use of machine learning for the non-invasive, inexpensive and fast diagnosis of IDH status in standard H-1-magnetic resonance spectroscopy (H-1-MRS). To this end, 30 of 34 consecutive patients with known or suspected glioma WHO grade II-IV were subjected to metabolic positron emission tomography (PET) imaging with O-(2-F-18-fluoroethyl)-L-tyrosine (F-18-FET) for optimized voxel placement in H-1-MRS. Routine H-1-magnetic resonance (H-1-MR) spectra of tumor and contralateral healthy brain regions were acquired on a 3 Tesla magnetic resonance (3T-MR) scanner, prior to surgical tumor resection and molecular analysis of IDH status. Since 2-HG spectral signals were too overlapped for reliable discrimination of IDH mutated (IDHmut) and IDH wild-type (IDHwt) glioma, we used a nested cross-validation approach, whereby we trained a linear support vector machine (SVM) on the complete spectral information of the H-1-MRS data to predict IDH status. Using this approach, we predicted IDH status with an accuracy of 88.2%, a sensitivity of 95.5% (95% CI, 77.2-99.9%) and a specificity of 75.0% (95% CI, 42.9-94.5%), respectively. The area under the curve (AUC) amounted to 0.83. Subsequent ex vivo H-1-nuclear magnetic resonance (H-1-NMR) measurements performed on metabolite extracts of resected tumor material (eight specimens) revealed myo-inositol (M-ins) and glycine (Gly) to be the major discriminators of IDH status. We conclude that our approach allows a reliable, non-invasive, fast and cost-effective prediction of IDH status in a standard clinical setting.","glioma,IDH mutation,F-18-FET,H-1-MRS,D-2-hydroxyglutarate,linear support vector machine,glycine,myo-inositol",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Oncology,,6.999,"CENTRAL-NERVOUS-SYSTEM,2-HYDROXYGLUTARATE,CLASSIFICATION,DIAGNOSTICS,1P%2F19Q,TUMORS",CANCERS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7698334,
66,Machine learning in materials design: Algorithm and application*,29,11,,"Song Zhilong);,Chen Xiwen);,Meng Fanbin);,Cheng Guanjian);,Wang Chen);,Sun Zhongti,Yin Wan-Jian","Song ZL,Chen XW,Meng FB,Cheng GJ,Wang C,Sun ZT,Yin WJ",Sun ZT; Yin WJ,10.1088/1674-1056/abc0e3,Suzhou University,"Traditional materials discovery is in 'trial-and-error' mode, leading to the issues of low-efficiency, high-cost, and unsustainability in materials design. Meanwhile, numerous experimental and computational trials accumulate enormous quantities of data with multi-dimensionality and complexity, which might bury critical 'structure-properties' rules yet unfortunately not well explored. Machine learning (ML), as a burgeoning approach in materials science, may dig out the hidden structure-properties relationship from materials bigdata, therefore, has recently garnered much attention in materials science. In this review, we try to shortly summarize recent research progress in this field, following the ML paradigm: (i) data acquisition -> (ii) feature engineering -> (iii) algorithm -> (iv) ML model -> (v) model evaluation -> (vi) application. In section of application, we summarize recent work by following the 'material science tetrahedron': (i) structure and composition -> (ii) property -> (iii) synthesis -> (iv) characterization, in order to reveal the quantitative structure-property relationship and provide inverse design countermeasures. In addition, the concurrent challenges encompassing data quality and quantity, model interpretability and generalizability, have also been discussed. This review intends to provide a preliminary overview of ML from basic algorithms to applications.","machine learning,materials design,structure-property relationship,active learning",Review,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,1.262,"DEEP,NEURAL-NETWORKS,PEROVSKITE,SOLAR-CELLS,AB-INITIO,CALCULATIONS,TEMPERATURE,T-G,CRYSTAL-STRUCTURE,TRANSITION-TEMPERATURE,STRUCTURE,PREDICTION,THERMODYNAMIC,STABILITY,ACCELERATED,DISCOVERY,MECHANICAL-PROPERTIES",CHINESE PHYSICS B,,
67,Automatic epileptic EEG classification based on differential entropy and attention model,96,,,"Zhang Jian,Wei Zuochen,Zou Junzhong,Fu Hao","Zhang J,Wei ZC,Zou JZ,Fu H",Zou JZ,10.1016/j.engappai.2020.103975,East China University of Science & Technology,"In epilepsy electroencephalogram (EEG) analysis, clinicians usually interpret EEG page by page, which is time-consuming and brings heavy workload. This paper proposes a novel automatic epileptic EEG classification approach based on differential entropy and attention mechanism, aiming at designing a short-term epileptic EEG classification model with high accuracy and good generalization performance. Firstly, the original EEG recordings are decomposed into five sub-frequency bands which approximately obey the Gaussian distribution. Afterward, a improved attention model framework considering both row and column attention with a shallower VGGNet (AttVGGNet-RC) is put forward as the classifier. Finally, non-patient specific method is employed to evaluate the performance with pre-tuned hypermeters. With 8-fold data, the proposed model yielded 77.33 +/- 2.91% sensitivity, 86.67 +/- 3.70% specificity and 82.00 +/- 1.43% accuracy, and accuracy was increased by 5.34%, 8.99%, 26.24% and 4.47% respectively compared with multi-layer perceptron (MLP), extreme learning machine (ELM), support vector machine (SVM) and Long Short-Term Memory (LSTM). With 10-fold shuffled data, the improved attention model yielded 93.84 +/- 0.63% sensitivity, 95.84 +/- 0.74% specificity and 95.12 +/- 0.20% accuracy, and the accuracy was 1.34%, 16.29%, 27.12% and 8.24% higher than MLP, ELM, SVM and LSTM respectively. The experimental result showed that the attention model achieved high classification accuracy with low standard deviation as well as good generalization performance. Furthermore, compared with state-of-art epilepsy analysis system, the proposed approach also show better performance. Therefore, this study has significant clinical application value in epilepsy analysis.","Electroencephalography,Epilepsy,Differential entropy,Attention mechanism",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Automation & Control Systems,Computer Science,Engineering",,5.317,"SEIZURE,DETECTION,DECOMPOSITION,PREDICTION",ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE,,
68,"Integrating Neighborhood Effect and Supervised Machine Learning Techniques to Model and Simulate Forest Insect Outbreaks in British Columbia, Canada",11,11,,"Harati Saeed,Perez Liliana,Molowny-Horas Roberto","Harati S,Perez L,Molowny-Horas R",Harati S,10.3390/f11111215,Universite de Montreal,"Background and Objectives: Modelling and simulation of forest land cover change due to epidemic insect outbreaks are powerful tools that can be used in planning and preparing strategies for forest management. In this study, we propose an integrative approach to model land cover changes at a provincial level, using as a study case the simulation of the spatiotemporal dynamics of mountain pine beetle (MPB) infestation over the lodgepole pine forest of British Columbia (BC), Canada. This paper aims to simulate land cover change by applying supervised machine learning techniques to maps of MPB-driven deforestation. Materials and Methods: We used a 16-year series (1999-2014) of spatial information on annual mortality of pine trees due to MPB attacks, provided by the BC Ministry of Forests. We used elevation, aspect, slope, ruggedness, and weighted neighborhood of infestation as predictors. We implemented (a) generalized linear regression (GLM), and (b) random forest (RF) algorithms to simulate forestland cover changes due to MPB between 2005 and 2014. To optimize the ability of our models to predict MPB infestation in 2020, a cross-validation procedure was implemented. Results: Simulating infestations from 2008 to 2014, RF algorithms produced less error than GLM. Our simulations for the year 2020 confirmed the predictions from the BC Ministry of Forest by forecasting a slower rate of spread in future MPB infestations in the province. Conclusions: Integrating neighborhood effects as variables in model calibration allows spatiotemporal complexities to be simulated.","land cover change,complex systems,model calibration,random forest,insect outbreaks,regression,machine learning",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",Forestry,,2.804,"MOUNTAIN,PINE-BEETLE,CELLULAR-AUTOMATA,ECONOMIC-IMPACT,BOREAL,FOREST,LODGEPOLE,INFESTATION,DISTURBANCE,RISK,FIRE,GIS",FORESTS,https://www.mdpi.com/1999-4907/11/11/1215/pdf,
69,A Machine Learning Model Accurately Predicts Ulcerative Colitis Activity at One Year in Patients Treated with Anti-Tumour Necrosis Factor alpha Agents,56,11,,"Popa Iolanda Valentina,Burlacu Alexandru,Mihai Catalina,Prelipcean Cristina Cijevschi","Popa IV,Burlacu A,Mihai C,Prelipcean CC",Mihai C,10.3390/medicina56110628,Grigore T Popa University of Medicine & Pharmacy,"Background and objectives: The biological treatment is a promising therapeutic option for ulcerative colitis (UC) patients, being able to induce subclinical and long-term remission. However, the relatively high costs and the potential toxicity have led to intense debates over the most appropriate criteria for starting, stopping, and managing biologics in UC. Our aim was to build a machine learning (ML) model for predicting disease activity at one year in UC patients treated with anti-Tumour necrosis factor alpha agents as a useful tool to assist the clinician in the therapeutic decisions. Materials and Methods: Clinical and biological parameters and the endoscopic Mayo score were collected from 55 UC patients at the baseline and one year follow-up. A neural network model was built using the baseline endoscopic activity and four selected variables as inputs to predict whether a UC patient will have an active or inactive endoscopic disease at one year, under the same therapeutic regimen. Results: The classifier achieved an excellent performance predicting the disease activity at one year with an accuracy of 90% and area under curve (AUC) of 0.92 on the test set and an accuracy of 100% and an AUC of 1 on the validation set. Conclusions: Our proposed ML solution may prove to be a useful tool in assisting the clinicians' decisions to increase the dose or switch to other biologic agents after the model's validation on independent, external cohorts of patients.","inflammatory bowel diseases,artificial intelligence,biological therapy,predictive model,disease activity",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND",General & Internal Medicine,,2.461,"INFLAMMATORY-BOWEL-DISEASE,BIOLOGICAL,THERAPY,INDUCTION",MEDICINA-LITHUANIA,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7699478,
70,Simultaneous quantitative analysis of non-metallic elements in coal by laser-induced breakdown spectroscopy assisted with machine learning,222,,,"Zhang Lili,Yang Yanwei","Zhang LL,Yang YW",Zhang LL,10.1016/j.ijleo.2020.165449,Lvliang University,"Coal is an important part of national energy structure, and the proportion of non-metallic elements will greatly affect its combustion efficiency. In order to achieve rapid and simultaneous quantitative detection of C, H, N in coal, a hybrid model combining laser-induced breakdown spectroscopy (LIBS) with machine learning algorithm is proposed. The detailed operations are as follows: A Nd: YAG laser with wavelength of 1064 nm is selected as excitation source, 14 kinds of national standard coal samples are ablated in air environment. Then selecting spectral data around the wavelength of elements to be measured and normalizing it as input variable of three algorithms. Finally, linear regression, support vector regression and random forest model are used for calibration and prediction. The results indicate that random forest model is more accurate in predicting non-metallic elements in coal than other two models, and the correlation coefficient (R-2) value of C, H, N were 0.9844, 0.9625 and 0.9829, the root mean square error (RMSE) were 0.2669, 0.2508 and 0.0335 respectively. Hence, LIBS technique based on different machine learning models can be used to accurately and effectively determine the content of non-metallic elements in coal.","Non-metallic elements,Laser-induced breakdown spectroscopy (LIBS),Coal,Machine learning",Article,"ELSEVIER GMBH, HACKERBRUCKE 6, 80335 MUNICH, GERMANY",Optics,,1.955,HEAVY-METALS,OPTIK,,
71,Deep learning for topology optimization of 2D metamaterials,196,,,"Kollmann Hunter T.,Abueidda Diab W.,Koric Seid,Guleryuz Erman,Sobh Nahil A.","Kollmann HT,Abueidda DW,Koric S,Guleryuz E,Sobh NA",Abueidda DW; Koric S,10.1016/j.matdes.2020.109098,University of Illinois System,"Data-driven models are rising as an auspicious method for the geometrical design of materials and structural systems. Nevertheless, existing data-driven models customarily address the optimization of structural designs rather than metamaterial designs. Metamaterials are emerging as promising materials exhibiting tailorable and unprecedented properties for a wide spectrum of applications. In this paper, we develop a deep learning (DL) model based on a convolutional neural network (CNN) that predicts optimal metamaterial designs. The developed DL model non-iteratively optimizes metamaterials for either maximizing the bulk modulus, maximizing the shear modulus, or minimizing the Poisson's ratio (including negative values). The data are generated by solving a large set of inverse homogenization boundary values problems, with randomly generated geometrical features from a specific distribution. Such s data-driven model can play a vital role in accelerating more computationally expensive design problems, such as multiscale metamaterial systems. (c) 2020 The Author(s). Published by Elsevier Ltd.","Architected materials,Auxetic materials,Homogenization,Machine learning,Microstructure,Periodic boundary conditions (PBCs)",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Materials Science,,7.097,"HOMOGENIZATION,METHOD,NEURAL-NETWORKS,POISSONS,RATIO,DESIGN,STABILITY,MODELS",MATERIALS & DESIGN,https://doi.org/10.1016/j.matdes.2020.109098,
72,Flame spray pyrolysis optimization via statistics and machine learning,196,,,"Paulson Noah H.,Libera Joseph A.,Stan Marius","Paulson NH,Libera JA,Stan M",Paulson NH,10.1016/j.matdes.2020.108972,United States Department of Energy (DOE),"Flame spray pyrolysis (FSP) is an important manufacturing process whereby nanomaterials are produced through the combustion of atomized fuel containing dissolved precursor elements. While FSP has the potential to enable the scalable production of a wide range of next generation energy materials, it also has a multi-scale, multi-physics character, and a large number of processing variables. Optimizing the process for desirable material outcomes by traditional approaches is challenging. In this work, the processing parameter space is explored new and efficient methodology that includes statistical methods such as Latin hypercube design of experiments, machine learning surrogate modeling, and Bayesian optimization. As a result, the FSP process is optimized for hanced performance. Specifically, in-situ particle size measurements are used to tailor the production of nanoparticles for a low spread in particle diameters with respect to the mean particle diameter, resulting improvement of 25.5% over the baseline within 15 experimental trials. In the process, the analysis reveals distinct domains of primary particle and agglomerated particle formation. (c) 2020 The Authors. Published by Elsevier Ltd.","Flame spray pyrolysis,Nanoparticle synthesis,Latin hypercube sampling,Bayesian optimization",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Materials Science,,7.097,"GLOBAL,OPTIMIZATION,NANOPARTICLES,DISTRIBUTIONS,UNCERTAINTY,SIMULATION,DESIGN",MATERIALS & DESIGN,https://doi.org/10.1016/j.matdes.2020.108972,
73,Highly-efficient quantitative fluorescence resonance energy transfer measurements based on deep learning,13,6,,"Ge Lin,Liu Fei,Luo Jianwen","Ge L,Liu F,Luo JW",Luo JW,10.1142/S1793545820500212,Tsinghua University,"Intensity-based quantitative fluorescence resonance energy transfer (FRET) is a technique to measure the distance of molecules in scale of a few nanometers which is far beyond optical diffraction limit. This widely used technique needs complicated experimental process and manual image analyses to obtain precise results, which take a long time and restrict the application of quantitative FRET especially in living cells. In this paper, a simplified and automatic quantitative FRET (saqFRET) method with high efficiency is presented. In saqFRET, photo-activatable acceptor PA-mCherry and optimized excitation wavelength of donor enhanced green fluorescent protein (EGFP) are used to simplify FRET crosstalk elimination. Traditional manual image analyses are time consuming when the dataset is large. The proposed automatic image analyses based on deep learning can analyze 100 samples within 30 s and demonstrate the same precision as manual image analyses.","Resonance energy transfer,fluorescence,living cells,photoactivatable,deep network",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE","Optics,Radiology, Nuclear Medicine & Medical Imaging",,1.436,,JOURNAL OF INNOVATIVE OPTICAL HEALTH SCIENCES,https://doi.org/10.1142/s1793545820500212,
74,Machine learning applications in production lines: A systematic literature review,149,,,"Kang Ziqiu,Catal Cagatay,Tekinerdogan Bedir","Kang ZQ,Catal C,Tekinerdogan B",Catal C,10.1016/j.cie.2020.106773,Bahcesehir University,"A production line is a set of sequential operations established in a factory where materials are put through a refining process to produce an end-product that is suitable for further usage. Monitoring production lines is essential to ensure that the targeted quality of the production process and the products are achieved. With the increased digitalization, lots of data can now be generated in the overall production line process. In parallel, the generated data sets are used by machine learning techniques for analytics of the production line to improve quality control, evaluate risks, and save cost. This paper aims to identify, assess, and synthesize the reported studies related to the application of machine learning in production lines, to provide a systematic overview of the current state-of-the-art and, as such, paving the way for further research. To this end, we have performed a Systematic Literature Review (SLR) in which we retrieved 271 papers, of which 39 primary studies were selected for a detailed analysis. This SLR presents and categorizes the production line problems addressed by machine learning, identifies the targeted industrial domains, discusses which machine learning algorithms have been used, and explains the adopted independent and dependent variables of the models. The study highlights the open problems that need to be solved and provides the identified research directions.","Machine learning,Production lines,Data analytics,Data mining,Systematic literature review",Review,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Computer Science,Engineering",,5.518,"NEURAL-NETWORK,QUALITY,PREDICTION,OPTIMIZATION,DIAGNOSIS,SENSOR,SMART",COMPUTERS & INDUSTRIAL ENGINEERING,https://doi.org/10.1016/j.cie.2020.106773,
75,Unsupervised Segmentation of Hyperspectral Images Using 3-D Convolutional Autoencoders,17,11,1948-1952,"Nalepa Jakub,Myller Michal,Imai Yasuteru,Honda Ken-Ichi,Takeda Tomomi,Antoniak Marek","Nalepa J,Myller M,Imai Y,Honda KI,Takeda T,Antoniak M",Nalepa J,10.1109/LGRS.2019.2960945,Silesian University of Technology,"Hyperspectral image analysis has become an important topic widely researched by the remote sensing community. Classification and segmentation of such imagery help understand the underlying materials within a scanned scene since hyperspectral images convey detailed information captured in a number of spectral bands. Although deep learning has established the state-of-the-art in the field, it still remains challenging to train well-generalizing models due to the lack of ground-truth data. In this letter, we tackle this problem and propose an end-to-end approach to segment hyperspectral images in a fully unsupervised way. We introduce a new deep architecture which couples 3-D convolutional autoencoders with clustering. Our multifaceted experimental study-performed over the benchmark and real-life data-revealed that our approach delivers highquality segmentation without any prior class labels.","Autoencoder,clustering,deep learning,hyperspectral imaging (HSI),unsupervised segmentation",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Geochemistry & Geophysics,Engineering,Remote Sensing,Imaging Science & Photographic Technology",,3.986,CLASSIFICATION,IEEE GEOSCIENCE AND REMOTE SENSING LETTERS,http://arxiv.org/pdf/1907.08870,
76,Noninvasive Estimation of Macro-Parameters by Deep Learning,4,6,684-695,"Wang Bo,Ruan Dongsheng,Liu Huafeng","Wang B,Ruan DS,Liu HF",Liu HF,10.1109/TRPMS.2020.2979017,Zhejiang University,"The estimation of macro-parameters is a critical step in dynamic positron emission tomography (PET) analyses because these parameters can quantitatively characterize the physiologic state of the tracer in vivo. Numerous algorithms have been proposed to estimate macro-parameters. However, the implementation of these estimation algorithms requires accurate input functions which are difficult to obtain under noninvasive conditions. We developed a novel data-driven framework to estimate the macro-parameter noninvasively without input functions. We took the macro-parameters as a nonlinear function of the activity concentration of the tracer. Deep learning was used to determine this nonlinear function to obtain the macro-parameter directly from dynamic PET data. Our approach was divided into two phases: 1) training and 2) estimation. In the training phase, a deep neural network (DNN) learned the potential relationships between the dynamic PET data and the macro-parameters. In the estimation phase, the macro-parameter could be directly obtained when the dynamic PET data were inputted to the DNN. Experiments based on simulation datasets of F-18-FDG and C-11-FMZ and real datasets were conducted as validation. Our experimental results were compared with those by Patlak or Logan plot, which demonstrated the superior performance of the proposed approach in terms of robustness and accuracy.","Deep learning,distribution of volume,influx constant,macro-parameters estimation,noninvasive method,positron emission tomography (PET)",Article; Proceedings Paper,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"POSITRON-EMISSION-TOMOGRAPHY,CEREBRAL-BLOOD-FLOW,DYNAMIC,PET,GRAPHICAL,ANALYSIS,KINETIC-ANALYSIS,INPUT,FUNCTION,BINDING,PHOSPHORYLATION,TRANSPORT,INVIVO",IEEE TRANSACTIONS ON RADIATION AND PLASMA MEDICAL SCIENCES,,
77,Classification of Neurotransmitter Response in Dynamic PET Data Using Machine Learning Approaches,4,6,708-719,"Fuller Oliver K.,Angelis Georgios I.,Meikle Steven R.","Fuller OK,Angelis GI,Meikle SR",Fuller OK,10.1109/TRPMS.2020.2984259,University of Sydney,"Dynamic positron emission tomography (PET) imaging can be used to quantify changes in synaptic concentrations of endogenous neurotransmitters during cognitive tasks or pharmacological interventions. Existing pharmacokinetic models, such as the linear parametric neurotransmitter PET (lp-ntPET) method, can be used to model the measured dynamic data and characterize small transient changes in neurotransmitter levels. Application of these models to the voxel level is challenging, however, due to the high levels of noise in dynamic data, leading to a high number of false-positive responses (i.e., low specificity). In this article, we investigated the suitability of machine learning algorithms (MLAs), including support vector machine (SVM) classifiers, shallow feedforward neural networks, convolutional neural networks (CNNs) and long short-term memory (LSTM) networks, to detect and classify transient changes in voxel-wise time-activity curves. We also investigated whether the reconstruction framework (post versus direct reconstruction) had any impact on the performance of the MLAs. We used computer simulations to generate dynamic PET data, representing a [C-11]raclopride study, with known activation responses, across a wide range of noise levels. Different simulated data sets were used to train and test the MLAs across a range of noise levels and activation response magnitudes. Results showed the MLAs offered a large improvement in specificity without a corresponding decrease in sensitivity across all noise levels tested compared to direct application of the lp-ntPET model. They also offered a modest benefit over the currently accepted method (statistical F-test combined with cluster size analysis), for both 2-D+time data when incorporated within direct or post-reconstruction frameworks, and 4-D GATE data.","Convolutional neural networks (CNNs),direct reconstruction,feedforward neural network,ligand displacement long short-term memory (LSTM),machine learning,neurotransmitter response,parametric imaging",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Radiology, Nuclear Medicine & Medical Imaging",,,"LP-NTPET,DOPAMINE,SENSITIVITY",IEEE TRANSACTIONS ON RADIATION AND PLASMA MEDICAL SCIENCES,,
78,Regression analysis of photodecomposable quencher concentration effects on chemical gradient in chemically amplified extreme ultraviolet resist processes,59,11,,"Azumagawa Kazuki,Kozawa Takahiro","Azumagawa K,Kozawa T",Kozawa T,,Osaka University,"Chemically amplified resists have been used in the state-of-the-art extreme ultraviolet (EUV) lithography. A basic additive has been added to the resist formula as a quencher to control acid diffusion. In this study, the effects of photodecomposable quencher (PDQ) concentration on the chemical gradient (an indicator of line edge roughness) in chemically amplified EUV resist processes were investigated. The chemical gradient was calculated on the basis of the sensitization and reaction mechanisms for different half-pitches, sensitivities, photoacid generator (PAG) concentrations, PDQ concentrations, and effective reaction radii for deprotection. The obtained 130 000 data were analyzed by least squares, lasso, ridge, and elastic net regressions. Regarding the contribution to the chemical gradient, PDQ concentration was apparently symmetric to PAG concentration. Optimum PDQ concentrations were well predicted (accuracy of approximately 10%) within the examined variable ranges even with 495 training data using the fitted parameters obtained by lasso, ridge, and elastic net regressions.","EUV lithography,chemically amplified resist,photodecomposable quencher,line edge roughness,machine learning",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,1.362,"ACID,DISTRIBUTION,BASE,DIFFUSION,ADDITIVES",JAPANESE JOURNAL OF APPLIED PHYSICS,,
79,Machine learning aided automated differential diagnostics of chronic rhinitis based on optical coherence tomography,17,11,,"Soloviev Nikita,Khilov Aleksandr,Shakhova Maria,Meller Alina,Perekatova Valeriya,Sergeeva Ekaterina,Kirillin Mikhail","Soloviev N,Khilov A,Shakhova M,Meller A,Perekatova V,Sergeeva E,Kirillin M",Kirillin M,10.1088/1612-202X/abbf48,Russian Academy of Sciences,"Chronic rhinitis (CR) is among the most frequent inflammatory diseases of ear-nose-throat (ENT) covering up to 30% of the population. Different forms of CR require different treatment tactics, which indicates the need for an efficient tool for differential diagnostics of CR. Optical coherence tomography (OCT) is a promising tool for fast non-invasive evaluation of nasal mucosa, which, however, requires further interpretation of the obtained diagnostic image. In this paper, we provide a comparative analysis of several machine learning approaches that aim at automated differential diagnostics of CR based on diagnostic OCT images of 78 patients aged between 28 and 74 ages. Gradient boosting decision trees (GBT) approach reveals the best classification accuracy (98% and 94% for binary and diagnostic classification, respectively). It shows that proposed approaches have potential for automated classification of CR OCT images.","optical coherence tomography,ENT,chronic rhinitis,machine learning,automated differential diagnostics",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Optics,Physics",,1.748,"NONALLERGIC,RHINITIS,ALLERGIC,RHINITIS,CLASSIFICATION,EPIDEMIOLOGY,DISEASES,MUCOSA,IMPACT",LASER PHYSICS LETTERS,,
80,Deep learning analysis in coronary computed tomographic angiography imaging for the assessment of patients with coronary artery stenosis,196,,,"Han Dan,Liu Jiayi,Sun Zhonghua,Cui Yu,He Yi,Yang Zhenghan","Han D,Liu JY,Sun ZH,Cui Y,He Y,Yang ZH",Yang ZH,10.1016/j.cmpb.2020.105651,Capital Medical University,"Background and Objective: Recently, deep convolutional neural network has significantly improved image classification and image segmentation. If coronary artery disease (CAD) can be diagnosed through machine learning and deep learning, it will significantly reduce the burdens of the doctors and accelerate the critical patient diagnoses. The purpose of the study is to assess the practicability of utilizing deep learning approaches to process coronary computed tomographic angiography (CCTA) imaging (termed CCTA-artificial intelligence, CCTA-AI) in coronary artery stenosis.
Materials and Methods: A CCTA reconstruction pipeline was built by utilizing deep learning and transfer learning approaches to generate auto-reconstructed CCTA images based on a series of two-dimensional (2D) CT images. 150 patients who underwent successively CCTA and digital subtraction angiography (DSA) from June 2017 to December 2017 were retrospectively analyzed. The dataset was divided into two parts comprising training dataset and testing dataset. The training dataset included the CCTA images of 100 patients which are trained using convolutional neural networks (CNN) in order to further identify various plaque classifications and coronary stenosis. The other 50 CAD patients acted as testing dataset that is evaluated by comparing the auto-reconstructed CCTA images with traditional CCTA images on the condition that DSA images are regarded as the reference method. Receiver operating characteristic (ROC) analysis was used for statistical analysis to compare CCTA-AI with DSA and traditional CCTA in the aspect of detecting coronary stenosis and plaque features.
Results: AI significantly reduces time for post-processing and diagnosis comparing to the traditional methods. In identifying various degrees of coronary stenosis, the diagnostic accuracy of CCTA-AI is better than traditional CCTA (AUCA1 = 0.870, AUCcciA = 0.781, P < 0.001). In identifying > 50% stenotic vessels, the accuracy, sensitivity, specificity, positive predictive value and negative predictive value of CCTA-AI and traditional method are 86% and 83%, 88% and 59%, 85% and 94%, 73% and 84%, 94% and 83%, respectively. In the aspect of identifying plaque classification, accuracy of CCTA-AI is moderate compared to traditional CCTA (AUC = 0.750, P < 0.001).
Conclusion: The proposed CCTA-AI allows the generation of auto-reconstructed CCTA images from a series of 2D CT images. This approach is relatively accurate for detecting >= 50% stenosis and analyzing plaque features compared to traditional CCTA. 2020 Elsevier B.V. All rights reserved.","Coronary atherosclerotic stenosis,Coronary computed tomographic angiography,Convolutional neural network,Deep learning",Article,"ELSEVIER IRELAND LTD, ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND","Computer Science,Engineering,Medical Informatics",,5.034,"SOCIETY,QUALITY",COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,,
81,PANNA: Properties from Artificial Neural Network Architectures,256,,,"Lot Ruggero,Pellegrini Franco,Shaidu Yusuf,Kucukbenli Emine","Lot R,Pellegrini F,Shaidu Y,Kucukbenli E",Kucukbenli E,10.1016/j.cpc.2020.107402,Harvard University,"Prediction of material properties from first principles is often a computationally expensive task. Recently, artificial neural networks and other machine learning approaches have been successfully employed to obtain accurate models at a low computational cost by leveraging existing example data. Here, we present a software package ""Properties from Artificial Neural Network Architectures'' (PANNA) that provides a comprehensive toolkit for creating neural network models for atomistic systems following the Behler-Parrinello topology. Besides the core routines for neural network training, it includes data parser, descriptor builder for Behler-Parrinello class of symmetry functions and forcefield generator suitable for integration within molecular dynamics packages. PANNA offers a variety of activation and cost functions, regularization methods, as well as the possibility of using fullyconnected networks with custom size for each atomic species. PANNA benefits from the optimization and hardware-flexibility of the underlying TensorFlow engine which allows it to be used on multiple CPU/GPU/TPU systems, making it possible to develop and optimize neural network models based on large datasets.
Program summary
Program title: PANNA-Properties from Artificial Neural Network Architectures
CPC Library link to program files: http://dx.doi.org/10.17632/mcryj6cnnh.1
Licensing provisions: MIT
Programming language: Python, C++
Nature of problem: A workflow for machine learning atomistic properties and interatomic potentials using neural networks.
Solution method: This package first transforms the user supplied data into pairs of precomputed input (Behler-Parrinello [1] class of symmetry functions) and target output (energy and forces) for the neural network model. The data are then packed to enable efficient reading. A user-friendly interface to TensorFlow [2] is provided to instantiate and train neural network models with varying architectures within Behler-Parrinello topology and with varying training schedules. The training can be monitored and validated with the provided tools. The derivative of the target output with respect to the input can also be used jointly in training, e.g. in the case of energy and force training. The interface with molecular dynamics codes such as LAMMPS [3] allows the neural network model to be used as an interatomic potential.
Additional comments including restrictions and unusual features: The underlying neural network training engine, TensorFlow, is a prerequisite of PANNA. While there is a special LAMMPS integration performed via a patch distributed within PANNA, the network potentials can be deposited into OpenKIM [4] database and can be used with a wide range of molecular dynamics codes.
The package allows different network architectures to be used for each atomic species, with different trainability setting for each network layer. It provides tools of exchanging weights between atomic species, and provides the option of building a Radial Basis Function network. The software is parallelized to take advantage of hardware architectures with multiple CPU/GPU/TPUs. (C) 2020 Elsevier B.V. All rights reserved.","Machine learning,Potential energy surface,Neural network,Force field,Molecular dynamics",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Computer Science,Physics",,4.722,"MACHINE-LEARNING,PREDICTIONS,ACCURATE,SIMULATIONS,POTENTIALS,MODEL,DFT",COMPUTER PHYSICS COMMUNICATIONS,http://arxiv.org/pdf/1907.03055,
82,Real-Time Data-Driven Detection of the Rock-Type Alteration During a Directional Drilling,17,11,1861-1865,"Romanenkova Evgeniya,Zaytsev Alexey,Klyuchnikov Nikita,Gruzdev Arseniy,Antipova Ksenia,Ismailova Leyla,Burnaev Evgeny,Semenikhin Artyom,Koryabkin Vitaliy,Simon Igor","Romanenkova E,Zaytsev A,Klyuchnikov N,Gruzdev A,Antipova K,Ismailova L,Burnaev E,Semenikhin A,Koryabkin V,Simon I",Romanenkova E,10.1109/LGRS.2019.2959845,Skolkovo Institute of Science & Technology,"During directional drilling, a bit may sometimes go to a nonproductive rock layer due to the gap about 20 m between the bit and high-fidelity rock-type sensors. The only way to detect the lithotype changes in time is the usage of measurements while drilling (MWD). However, there are no general mathematical modeling approaches that both well reconstruct the rock type based on MWD data and correspond to specifics of the oil and gas industry. In this letter, we present a data-driven procedure that utilizes MWD data for quick detection of changes in rock types. We propose the approach that combines traditional machine learning (ML) based on the solution of the rock-type classification problem with change detection procedures rarely used before in oil and gas industry. The data come from a newly developed oilfield in the north of western Siberia. The results suggest that we can detect a significant part of changes in rock types, reducing the change detection delay from 20 to 1.8 m and the number of false-positive alarms from 43 to 6 per well.","Rocks,Drilling machines,Oils,Decision trees,Data models,Mathematical model,Real-time systems,Change detection,classification,directional drilling,logging while drilling (LWD),measurements while drilling (MWD),rock type",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Geochemistry & Geophysics,Engineering,Remote Sensing,Imaging Science & Photographic Technology",,3.986,MODEL,IEEE GEOSCIENCE AND REMOTE SENSING LETTERS,http://arxiv.org/pdf/1903.11436,
83,Dramatically Enhanced Combination of Ultimate Tensile Strength and Electric Conductivity of Alloys via Machine Learning Screening,200,,803-810,"Zhang Hongtao,Fu Huadong,He Xingqun,Wang Changsheng,Jiang Lei,Chen Long-Qing,Xie Jianxin","Zhang HT,Fu HD,He XQ,Wang CS,Jiang L,Chen LQ,Xie JX",Xie JX,10.1016/j.actamat.2020.09.068,University of Science & Technology Beijing,"Optimizing two conflicting properties such as mechanical strength and toughness or dielectric constant and breakdown strength of a material has always been a challenge. Here we propose a machine learning approach to dramatically enhancing the combined ultimate tensile strength (UTS) and electric conductivity (EC) of alloys by identifying a set of key features through correlation screening, recursive elimination and exhaustive screening of existing datasets. We demonstrate that the key features responsible for solid solution strengthened conductive Copper alloys are absolute electronegativity, core electron distance, and atomic radius, based on which, we discovered a series of new alloying elements that can significantly improve the combined UTS and EC. The predictions are then validated by experimentally fabricating four new Cu-In alloys which could potentially replace the more expensive Cu-Ag alloys currently used in railway wiring. We show that the same set of key features can be generally applicable to designing a broad range of conductive alloys. (C) 2020 Acta Materialia Inc. Published by Elsevier Ltd. All rights reserved.","Machine learning,Feature screening,Alloy design,Copper alloy,Aluminum alloy",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Materials Science,Metallurgy & Metallurgical Engineering",,9.277,"INFORMATICS,APPROACH,PREDICTION,DESIGN,SELECTION,DENSITY,SEARCH,FCC",ACTA MATERIALIA,,
84,Artificial Intelligence in Advanced Manufacturing: Current Status and Future Outlook,142,11,,"Arinez Jorge F.,Chang Qing,Gao Robert X.,Xu Chengying,Zhang Jianjing","Arinez JF,Chang Q,Gao RX,Xu CY,Zhang JJ",Arinez JF,10.1115/1.4047855,General Motors,"Today's manufacturing systems are becoming increasingly complex, dynamic, and connected. The factory operations face challenges of highly nonlinear and stochastic activity due to the countless uncertainties and interdependencies that exist. Recent developments in artificial intelligence (AI), especially Machine Learning (ML) have shown great potential to transform the manufacturing domain through advanced analytics tools for processing the vast amounts of manufacturing data generated, known as Big Data. The focus of this paper is threefold: (1) review the state-of-the-art applications of AI to representative manufacturing problems, (2) provide a systematic view for analyzing data and process dependencies at multiple levels that AI must comprehend, and (3) identify challenges and opportunities to not only further leverage AI for manufacturing, but also influence the future development of AI to better meet the needs of manufacturing. To satisfy these objectives, the paper adopts the hierarchical organization widely practiced in manufacturing plants in examining the interdependencies from the overall system level to the more detailed granular level of incoming material process streams. In doing so, the paper considers a wide range of topics from throughput and quality, supervisory control in human-robotic collaboration, process monitoring, diagnosis, and prognosis, finally to advances in materials engineering to achieve desired material property in process modeling and control.","computer-integrated manufacturing,control and automation,modeling and simulation,plant engineering and maintenance,process planning,production systems optimization,sensing,monitoring and diagnostics,sensors",Article,"ASME, TWO PARK AVE, NEW YORK, NY 10016-5990 USA",Engineering,,3.084,"HUMAN-ROBOT,COLLABORATION,CONVOLUTIONAL,NEURAL-NETWORK,DISPATCHING,RULE,SELECTION,DECISION-SUPPORT-SYSTEM,FAULT-DIAGNOSIS,QUALITY-CONTROL,MACHINE,PERFORMANCE,PREDICTION,TIME",JOURNAL OF MANUFACTURING SCIENCE AND ENGINEERING-TRANSACTIONS OF THE ASME,,
85,Advanced Welding Manufacturing: A Brief Analysis and Review of Challenges and Solutions,142,11,,"Zhang Yu Ming,Yang Yu-Ping,Zhang Wei,Na Suck-Joo","Zhang YM,Yang YP,Zhang W,Na SJ",Zhang YM,10.1115/1.4047947,University of Kentucky,"Welding is a major manufacturing process that joins two or more pieces of materials together through heating/mixing them followed by cooling/solidification. The goal of welding manufacturing is to join materials together to meet service requirements at lowest costs. Advanced welding manufacturing is to use scientific methods to realize this goal. This paper views advanced welding manufacturing as a three step approach: (1) pre-design that selects process and joint design based on available processes (properties, capabilities, and costs); (2) design that uses models to predict the result from a given set of welding parameters and minimizes a cost function for optimizing the welding parameters; and (3) real-time sensing and control that overcome the deviations of welding conditions from their nominal ones used in optimizing the welding parameters by adjusting the welding parameters based on such real-time sensing and feedback control. The paper analyzes how these three steps depend on process properties/capabilities, process innovations, predictive models, numerical models for fluid dynamics, numerical models for structures, real-time sensing, and dynamic control. The paper also identifies the challenges in obtaining ideal solutions and reviews/analyzes the existing efforts toward better solutions. Special attention and analysis have been given to (1) gas tungsten arc welding (GTAW) and gas metal arc welding (GMAW) as benchmark processes for penetration and materials filling; (2) keyhole plasma arc welding (PAW), keyhole-tungsten inert gas (K-TIG), and keyhole laser welding as improved/capable penetrative processes; (3) friction stir welding (FSW) as a special penetrative low heat input process; (4) alternating current (AC) GMAW and double-electrode GMAW as improved materials filling processes; (5) efforts in numerical modeling for fluid dynamics; (6) efforts in numerical modeling for structures; (7) challenges and efforts in seam tracking and weld pool monitoring; (8) challenges and efforts in monitoring of keyhole laser welding and FSW; and (9) efforts in advanced sensing, data fusion/sensor fusion, and process control using machine learning/deep learning, model predictive control (MPC), and adaptive control.","welding,manufacturing,numerical model,weld pool,transport phenomena,microstructure,distortion,residual stress,process,sensor,machine learning,deep learning,CNN,adaptive control,model predictive control,MPC,control,automation,modeling,simulation,sensing,monitoring,diagnostics,sensors,joining",Review,"ASME, TWO PARK AVE, NEW YORK, NY 10016-5990 USA",Engineering,,3.084,"DOUBLE-ELECTRODE,GMAW,MULTIVARIABLE,ADAPTIVE-CONTROL,INTERVAL,MODEL,CONTROL,SEAM,TRACKING,SYSTEM,HIGH-STRENGTH,STEEL,GAS,TUNGSTEN,PREDICTIVE,CONTROL,FLUID-FLOW,DISTORTION,PREDICTION,MECHANICAL-PROPERTIES",JOURNAL OF MANUFACTURING SCIENCE AND ENGINEERING-TRANSACTIONS OF THE ASME,,
86,Classifying Thermal Degradation of Polylactic Acid by Using Machine Learning Algorithms Trained on Fourier Transform Infrared Spectroscopy Data,10,21,,Zhang Sung-Uk,Zhang SU,Zhang SU,10.3390/app10217470,Dong-Eui University,"Polylactic acid (PLA) is the most common polymeric material in the 3D printing industry but degrades under harsh environmental conditions such as under exposure to sunlight, high-temperatures, water, soil, and bacteria. An understanding of degradation phenomena of PLA materials is critical to manufacturing robust products by using 3D printing technologies. The objective of this study is to evaluate four machine learning algorithms to classify the degree of thermal degradation of heat-treated PLA materials based on Fourier transform infrared spectroscopy (FTIR) data. In this study, 3D printed PLA specimens were subjected to high-temperatures for extended periods of time to simulate thermal degradation and subsequently examined by using two types of FTIR spectrometers: desktop and portable spectrometers. Classifiers created by multi-class logistic regression and multi-class neural networks were appropriate prediction models for these datasets.","polylactic acid (PLA),thermal degradation,Fourier transform infrared (FTIR)",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"POLYMER,STABILIZATION,HYDROLYSIS",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7470/pdf,
87,Predicting Ultra-High-Performance Concrete Compressive Strength Using Tabular Generative Adversarial Networks,13,21,,"Marani Afshin,Jamali Armin,Nehdi Moncef L.","Marani A,Jamali A,Nehdi ML",Nehdi ML,10.3390/ma13214757,Western University (University of Western Ontario),"There have been abundant experimental studies exploring ultra-high-performance concrete (UHPC) in recent years. However, the relationships between the engineering properties of UHPC and its mixture composition are highly nonlinear and difficult to delineate using traditional statistical methods. There is a need for robust and advanced methods that can streamline the diverse pertinent experimental data available to create predictive tools with superior accuracy and provide insight into its nonlinear materials science aspects. Machine learning is a powerful tool that can unravel underlying patterns in complex data. Accordingly, this study endeavors to employ state-of-the-art machine learning techniques to predict the compressive strength of UHPC using a comprehensive experimental database retrieved from the open literature consisting of 810 test observations and 15 input features. A novel approach based on tabular generative adversarial networks was used to generate 6513 plausible synthetic data for training robust machine learning models, including random forest, extra trees, and gradient boosting regression. While the models were trained using the synthetic data, their ability to generalize their predictions was tested on the 810 experimental data thus far unknown and never presented to the models. The results indicate that the developed models achieved outstanding predictive performance. Parametric studies using the models were able to provide insight into the strength development mechanisms of UHPC and the significance of the various influential parameters.","ultra-high-performance concrete,compressive strength,machine learning,tabular generative adversarial networks,random forest,extra trees,gradient boosting",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Materials Science,Metallurgy & Metallurgical Engineering,Physics",,3.92,"FIBER-REINFORCED,CONCRETE,MECHANICAL-PROPERTIES,FRACTURE-MECHANICS,RANDOM,FOREST,HYBRID,STEEL,NANO-SILICA,UHPC,MODEL,MICROSTRUCTURE,SIMULATIONS",MATERIALS,https://www.mdpi.com/1996-1944/13/21/4757/pdf,
88,"Classification, Prediction, and Monitoring of Parkinson's disease using Computer Assisted Technologies: A Comparative Analysis",96,,,"Goyal Jinee,Khandnor Padmavati,Aseri Trilok Chand","Goyal J,Khandnor P,Aseri TC",Goyal J,10.1016/j.engappai.2020.103955,Punjab Engineering College (Deemed University),"Parkinson's disease is a neurogenerative disorder that occurs due to the loss of dopamine-producing cells. Till now, there is no cure for this disease but correct medications can slow down the progression. Therefore, early diagnosis of this disease is very important to improve the quality of life of Parkinson patients. This paper provides a comparative analysis of computer-assisted technologies for classification, prediction, and monitoring of Parkinson patients. The articles are selected based on the type, source of data, and symptoms to diagnose Parkinson's disease. Our contribution in this paper includes the study of recent articles from the year 2017, 2018, and 2019 and some other articles to consolidate some of the previous work as well. Research articles are chosen based on symptoms, type, and source of data to cover each aspect of Parkinson's disease. There is a great potential for early diagnosis as well as improving the quality of life with the help of computer-assisted rehabilitation techniques. We have divided our analysis into six sub-categories. A detailed analysis has been done on each sub-category. Information about some tools, software, and libraries are provided for the use of researchers. A comparison has also been done on different feature extraction and classification techniques so that researchers can further explore these techniques. Research gaps and future directions are also discussed along with challenges related to each gap for researchers to work on.","Parkinson's disease,Machine learning,Deep learning,Signal processing,Rehabilitation,UPDRS",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Automation & Control Systems,Computer Science,Engineering",,5.317,"SOCIETY-SPONSORED,REVISION,NEURAL-NETWORK,CLASSIFIER,SCALE,MDS-UPDRS,FEATURE-EXTRACTION,GAIT,DETECTION,AUTOMATIC,DETECTION,DIAGNOSIS,MOVEMENT,SPEECH,TREMOR",ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE,,
89,Determining Physical Activity Characteristics From Wristband Data for Use in Automated Insulin Delivery Systems,20,21,12859-12870,"Sevil Mert,Rashid Mudassir,Maloney Zacharie,Hajizadeh Iman,Samadi Sediqeh,Askari Mohammad Reza,Hobbs Nicole,Brandt Rachel,Park Minsun,Quinn Laurie","Sevil M,Rashid M,Maloney Z,Hajizadeh I,Samadi S,Askari MR,Hobbs N,Brandt R,Park M,Quinn L",Cinar A,10.1109/JSEN.2020.3000772,Illinois Institute of Technology,"Algorithms that can determine the type of physical activity (PA) and quantify the intensity can allow precision medicine approaches, such as automated insulin delivery systems that modulate insulin administration in response to PA. In this work, data from a multi-sensor wristband is used to design classifiers to distinguish among five different physical states (PS) (resting, activities of daily living, running, biking, and resistance training), and to develop models to estimate the energy expenditure (EE) of the PA for diabetes therapy. The data collected are filtered, features are extracted from the reconciled signals, and the extracted features are used by machine learning algorithms, including deep-learning techniques, to obtain accurate PS classification and EE estimation. The various machine learning techniques have different success rates ranging from 75.7% to 94.8% in classifying the five different PS. The deep neural network model with long short-term memory has 94.8% classification accuracy. We achieved 0.5 MET (Metabolic Equivalent of Task) root-mean-square error for EE estimation accuracy, relative to indirect calorimetry with randomly selected testing data (10% of collected data). We also demonstrate a 5% improvement in PS classification accuracy and a 0.34 MET decrease in the mean absolute error when using multi-sensor approach relative to using only accelerometer data.","Feature extraction,Insulin,Estimation,Accelerometers,Temperature sensors,Sensor fusion,Wearable sensors,sensor fusion,physical activity classification,energy expenditure estimation,automated insulin delivery",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"ENERGY-EXPENDITURE,ESTIMATION,ACTIVITY,CLASSIFICATION,WEARABLE,SENSORS,OLDER-ADULTS,WALKING,ACCELEROMETERS,TRACKING,EXERCISE,OBESITY,VALIDATION",IEEE SENSORS JOURNAL,,
90,A Robust Data-Driven Soft Sensory Glove for Human Hand Motions Identification and Replication,20,21,12972-12979,"Nassour John,Amirabadi Hojjat Gharaei,Weheabby Saddam,Al Ali Abbas,Lang Heinrich,Hamker Fred","Nassour J,Amirabadi HG,Weheabby S,Al Ali A,Lang H,Hamker F",Nassour J,10.1109/JSEN.2020.3001982,Technical University of Munich,"Biomechanical sensors are essential components for wearable robots because of their broad spectrum of industrial and medical applications. A wide range of these sensors uses soft materials with deformation-related electrical properties, namely variable resistors and capacitors. Previously, conductive materials were injected into silicone structures that require several molding steps to build the microchannels. This paper proposes a versatile soft sensing glove, using a simple process for preparing sensors of different sizes without molding. We used commercially available silicone tubes to host the conductive liquid. Ten sensors were attached to the back side of the glove to measure flexion-extension and four sensors were placed on the glove at the interdigital folds between the fingers to measure abduction-adduction. The sensory glove successfully replicates hand motion. We used machine learning algorithms to estimate the angles of the joints in the hand and also to identify 15 gestures. The system's robustness was evaluated in two experiments. The gesture prediction is robust to shocks from contact with a punching ball and also submersion of the glove in water. The proposed sensory glove overcomes challenges of comfort, rigidity, and robustness. It can be used, therefore, to replicate human hand motion in industrial and medical applications.","Sensors,Liquids,Electron tubes,Electric shock,Metals,Resistors,Electrodes,Data-driven glove,soft sensors glove,wearable sensor,hand gesture recognition,hand motion replication",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"GESTURE,RECOGNITION",IEEE SENSORS JOURNAL,,
91,Magnetic Field-Based Localization in Factories Using Neural Network With Robotic Sampling,20,21,13110-13118,"Chiang Ting-Hui,Sun Zao-Hung,Shiu Huan-Ruei,Lin Kate Ching-Ju,Tseng Yu-Chee","Chiang TH,Sun ZH,Shiu HR,Lin KCJ,Tseng YC",Chiang TH,10.1109/JSEN.2020.3003404,Feng Chia University,"With the advent of Industry 4.0, localization of materials and factory items will play important roles in factory automation. Since GPS signals are not available in indoor environments, a lot of indoor localization technologies have been proposed based on inertial sensors, audio signals, visible light, wireless signals, etc. In this research, we consider using magnetic fields, which usually exhibit high uniqueness at different locations especially in factories where a lot of stacks, machineries, materials, and metal partitions may coexist. These factors allow us to incorporate deep learning neural networks to learn location-related features. Existing works try to collect magnetic field data by human and leverage interpolation to augment dataset. However, our experiments show that the data generated by interpolation is usually different from the ground truth because magnetic fields may not be linear. Therefore, to collect a large enough dataset without human intervention, we dispatch a robot carrying a smartphone to collect dataset at a fine resolution. We use these collected data to train two localization models: deep neural network (DNN) and recurrent neural network (RNN). Besides, we augment our RNN training dataset by combining multiple single-point magnetic values to synthesize fake magnetic trajectories. We conduct field trials, which validate that our approach outperforms previous work.","Magnetometers,Magnetic resonance imaging,Robots,Magnetic sensors,Data models,Neural networks,Indoor positioning,magnetic field,neural network,object tracking",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation,Physics",,3.441,"POSITIONING,SYSTEM,INDOOR",IEEE SENSORS JOURNAL,,
92,Benchmarking Machine Learning Algorithms on Blood Glucose Prediction for Type I Diabetes in Comparison With Classical Time-Series Models,67,11,3101-3124,"Xie Jinyu,Wang Qian","Xie JY,Wang Q",Wang Q,10.1109/TBME.2020.2975959,Pennsylvania Commonwealth System of Higher Education (PCSHE),"italic>Objective: This paper aims to compare the performance of several commonly known machine-learning (ML) models versus a classic Autoregression with Exogenous inputs (ARX) model in the prediction of blood glucose (BG) levels using time-series data of patients with Type 1 diabetes (T1D). Methods: The ML algorithms include ML-based regression models and deep learning models such as a vanilla Long-Short-Term-Memory (LSTM) Network and a Temporal Convolution Network (TCN). Evaluations have been conducted with respect to different input features, regression model orders, as well as using the recursive method or direct method for multi-step prediction of BG levels. Prediction performance metrics include the average Root Mean Square Error (RMSE), temporal gain (TG) for early prediction, and the normalized energy of the second-order differences (ESOD) of the predicted time series to reflect risk of false alerts on hypo/hyper glycemia events. Results: The ARX model achieved the lowest average RMSE for both recursive and direct methods, the second highest average TG under the direct method, but with a higher average normalized ESOD than some other models. Conclusion: There was no significant advantage observed from the ML models compared to the classic ARX model in predicting BG levels for T1D, except that TCNs performance was more robust with respect to BG trajectories with spurious oscillations, for which ARX tended to over-predict peak BG values and under-predict valley BG values. Significance: Insight learned from this study could help researchers and clinical practitioners to select appropriate models for BG prediction.","Predictive models,Sugar,Blood,Machine learning,Prediction algorithms,Convolution,Data models,Benchmark,blood glucose,deep neural network,machine learning,type 1 diabetes",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,,IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
93,Revealing False Positive Features in Epileptic EEG Identification,30,11,,"Lian Jian,Shi Yunfeng,Zhang Yan,Jia Weikuan,Fan Xiaojun,Zheng Yuanjie","Lian J,Shi YF,Zhang Y,Jia WK,Fan XJ,Zheng YJ",Zheng YJ,10.1142/S0129065720500173,Shandong Normal University,"Feature selection plays a vital role in the detection and discrimination of epileptic seizures in electroencephalogram (EEG) signals. The state-of-the-art EEG classification techniques commonly entail the extraction of the multiple features that would be fed into classifiers. For some techniques, the feature selection strategies have been used to reduce the dimensionality of the entire feature space. However, most of these approaches focus on the performance of classifiers while neglecting the association between the feature and the EEG activity itself. To enhance the inner relationship between the feature subset and the epileptic EEG task with a promising classification accuracy, we propose a machine learning-based pipeline using a novel feature selection algorithm built upon a knockoff filter. First, a number of temporal, spectral, and spatial features are extracted from the raw EEG signals. Second, the proposed feature selection algorithm is exploited to obtain the optimal subgroup of features. Afterwards, three classifiers including k-nearest neighbor (KNN), random forest (RF) and support vector machine (SVM) are used. The experimental results on the Bonn dataset demonstrate that the proposed approach outperforms the state-of-the-art techniques, with accuracy as high as 99.93% for normal and interictal EEG discrimination and 98.95% for interictal and ictal EEG classification. Meanwhile, it has achieved satisfactory sensitivity (95.67% in average), specificity (98.83% in average), and accuracy (98.89% in average) over the Freiburg dataset.","Epileptic seizure,electroencephalogram,classification,feature selection",Article,"WORLD SCIENTIFIC PUBL CO PTE LTD, 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE",Computer Science,,5.439,"INTRUSION,DETECTION,SYSTEM,HYBRID,FEATURE-SELECTION,SEIZURE,DETECTION,WAVELET,TRANSFORM,AUTOMATIC,DETECTION,FEATURE-EXTRACTION,NEURAL-NETWORK,DISCOVERY,RATE,CLASSIFICATION,SVM",INTERNATIONAL JOURNAL OF NEURAL SYSTEMS,,
94,On the stability of persistent entropy and new summary functions for topological data analysis,107,,,"Atienza Nieves,Gonzalez-Diaz Rocio,Soriano-Trigueros Manuel","Atienza N,Gonzalez-Diaz R,Soriano-Trigueros M",Soriano-Trigueros M,10.1016/j.patcog.2020.107509,University of Sevilla,"Persistent homology and persistent entropy have recently become useful tools for patter recognition. In this paper, we find requirements under which persistent entropy is stable to small perturbations in the input data and scale invariant. In addition, we describe two new stable summary functions combining persistent entropy and the Betti curve. Finally, we use the previously defined summary functions in a material classification task to show their usefulness in machine learning and pattern recognition. (C) 2020 Elsevier Ltd. All rights reserved.","Persistent homology,Persistent entropy,Stability,Dimensionality reduction",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Computer Science,Engineering",,7.299,,PATTERN RECOGNITION,https://idus.us.es/bitstream/11441/87703/3/1803-08304v7.pdf,
95,Multi-Label classification of multi-modality skin lesion via hyper-connected convolutional neural network,107,,,"Bi Lei,Feng David Dagan,Fulham Michael,Kim Jinman","Bi L,Feng DD,Fulham M,Kim J",Bi L; Kim J,10.1016/j.patcog.2020.107502,University of Sydney,"Objective: Clinical and dermoscopy images (multi-modality image pairs) are routinely used sequentially in the assessment of skin lesions. Clinical images characterize a lesion's geometry and color; dermoscopy depicts vascularity, dots and globules from the sub-surface of the lesion. Together these modalities provide labels to characterize a skin lesion. Recently, convolutional neural networks (CNNs), due to the ability to learn low-level features and high-level semantic information in an end-to-end architecture, have been shown to be the state-of-the-art in skin lesion classification. Most of the CNN methods have relied on dermoscopy alone. In the few published papers that support multi-modalities, the methods are based on 'late-fusion' to integrate extracted clinical and dermoscopy image features separately. These late-fusion methods tend to ignore the accessible complementary image features between the paired images at the early stage of the CNN architecture.
Methods: We propose a hyper-connected CNN (HcCNN) to classify skin lesions. Compared to existing multi-modality CNNs, our HcCNN has an additional hyper-branch that integrates intermediary image features in a hierarchical manner. The hyper-branch enables the network to learn more complex combinations between the images at all, early and late, stages of the network. We also coupled the HcCNN with a multi-scale attention block (MsA) to prioritize semantically important subtle regions in the two modalities across various image scales.
Results: Our HcCNN achieved an average accuracy of 74.9% for multi-label classification on the 7-point Checklist dataset, which is a well-benchmarked public dataset. Conclusions: Our method is more accurate than the state-of-the-art methods and, in particular, our method achieved consistent and the best results in datasets with imbalanced label distributions. (C) 2020 Elsevier Ltd. All rights reserved.","Classification,Melanoma,Convolutional neural networks (cnns)",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND","Computer Science,Engineering",,7.299,"7-POINT,CHECKLIST,SEGMENTATION,MELANOMA,IMAGES",PATTERN RECOGNITION,,
96,Quantitative analysis modeling for the ChemCam spectral data based on laser-induced breakdown spectroscopy using convolutional neural network,22,11,,"Cao Xueqiang,Zhang Li,Wu Zhongchen,Ling Zongcheng,Li Jialun,Guo Kaichen","Cao XQ,Zhang L,Wu ZC,Ling ZC,Li JL,Guo KC",Zhang L,10.1088/2058-6272/aba5f6,Shandong University,"Laser-induced breakdown spectroscopy (LIBS) has been applied to many fields for the quantitative analysis of diverse materials. Improving the prediction accuracy of LIBS regression models is still of great significance for the Mars exploration in the near future. In this study, we explored the quantitative analysis of LIBS for the one-dimensional ChemCam (an instrument containing a LIBS spectrometer and a Remote Micro-Imager) spectral data whose spectra are produced by the ChemCam team using LIBS under the Mars-like atmospheric conditions. We constructed a convolutional neural network (CNN) regression model with unified parameters for all oxides, which is efficient and concise. CNN that has the excellent capability of feature extraction can effectively overcome the chemical matrix effects that impede the prediction accuracy of regression models. Firstly, we explored the effects of four activation functions on the performance of the CNN model. The results show that the CNN model with the hyperbolic tangent (tanh) function outperforms the CNN models with the other activation functions (the rectified linear unit function, the linear function and the Sigmoid function). Secondly, we compared the performance among the CNN models using different optimization methods. The CNN model with the stochastic gradient descent optimization and the initial learning rate = 0.0005 achieves satisfactory performance compared to the other CNN models. Finally, we compared the performance of the CNN model, the model based on support vector regression (SVR) and the model based on partial least square regression (PLSR). The results exhibit the CNN model is superior to the SVR model and the PLSR model for all oxides. Based on the above analysis, we conclude the CNN regression model can effectively improve the prediction accuracy of LIBS.","laser-induced breakdown spectroscopy,convolutional neural network,activation function,optimization method,quantitative analysis",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND",Physics,,1.281,"PLS-REGRESSION,MARS,CALIBRATION,MISSION,ROCKS",PLASMA SCIENCE & TECHNOLOGY,,
97,Data-Driven Detection Methods on Driver's Pedal Action Intensity Using Triboelectric Nano-Generators,12,21,,"Cheng Qian,Jiang Xiaobei,Zhang Haodong,Wang Wuhong,Sun Chunwen","Cheng Q,Jiang XB,Zhang HD,Wang WH,Sun CW",Jiang XB,10.3390/su12218926,Beijing Institute of Technology,"Driver's driving actions on pedals can be regarded as an expression of driver's acceleration/deceleration intention. Quickly and accurately detecting driving action intensity on pedals can have great contributions in preventing road traffic accidents and managing the energy consumption. In this paper, we report a pressure-sensitive and self-powered material named triboelectric nano-generators (TENGs). The generated voltage data of TENGs, which is associated with the pedal action, can be collected easily and stored sequentially. According to the characteristics of the voltage data, we have employed a hybrid machine learning method. After collecting signals from TENGs and driving simulator simultaneously, an unsupervised Gaussian mixture model is used to cluster the pedal events automatically using data from simulator. Then, multi-feature candidates of the voltage data from TENGs are extracted and ranked. A supervised random forest model that treats voltage data of TENGs as input data is trained and tested. Results show that data from TENGs can have a high accuracy of more than 90% using the random forest algorithm. The evaluating results demonstrate the accuracy of the proposed data-driven hybrid learning algorithm for recognition of driver's pedal action intensity. Furthermore, technical and economic characteristics of TENGs and some common sensors are compared and discussed. This work may demonstrate the feasibility of using these data-driven methods on the detection of driver's pedal action intensity.","pedal action intensity,triboelectric nano-generator,data-driven classifier,hybrid learning algorithm,random forest model,gaussian mixture model",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Science & Technology - Other Topics,Environmental Sciences & Ecology",,3.473,"EMERGENCY,BRAKING,INTENTION,NANOGENERATOR,SENSOR,ENERGY,BEHAVIOR",SUSTAINABILITY,https://www.mdpi.com/2071-1050/12/21/8926/pdf,
98,A Machine Learning Based Prediction Model for the Sound Absorption Coefficient of Micro-Expanded Metal Mesh (MEMM),10,21,,"Tsay Yaw-Shyan,Yeh Chiu-Yu","Tsay YS,Yeh CY",Tsay YS,10.3390/app10217612,National Cheng Kung University,"Recently, micro-perforated panels (MPP) have become a popular sound absorbing material in the field of architectural acoustics. However, the cost of MPP is still high for the commercial market in Taiwan, and MPP is still not very popular compared to other sound absorbing materials and devices. The objective of this study is to develop a prediction model for MEMM via a machine learning approach. An experiment including 14 types of MEMM was first carried out in a reverberation room based on ISO 354. To predict the sound absorption coefficient of the MEMM, the capability of three conventional models and three machine learning (ML) models of the supervised learning method were studied for the development of the prediction model. The results showed that in most conventional models, the sound absorption coefficient of using an equivalent perimeter had the best agreement compared with other parameters, and the root mean square error (RMSE) between prediction models and experimental data were around 0.2 similar to 0.3. However, the RMSE of all ML models was less than 0.1, and the RMSE of the gradient boost model was 0.033 in the training sets and 0.062 in the testing sets, which showed the best agreement with the experiment data.","building acoustics,sound absorption coefficient,prediction models,supervised learning method",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,,APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7612/pdf,
99,Prediction of Residual Stress of Carburized Steel Based on Machine Learning,10,21,,"Zhu Zhenlong,Liang Yilong","Zhu ZL,Liang YL",Liang YL,10.3390/app10217759,Guizhou University,"In recent years, the number of machine learning applications (especially those involving deep learning) applied to predicting and discovering material properties has been increasing. This paper is based on using microstructure and carbon content to train machine learning models to predict the residual stress of carburized steel. First, a semantic segmentation model of the material organization structure (SegModel-MOS) was constructed based on the AlexNet network and initially trained on the PASCAL VOC2012 dataset. Then, the trained model was fine-tuned on an enhanced homemade dataset consisting of optical microstructures. The experimental results show that SegModel-MOS can distinguish acicular martensite, retained austenite, and lath martensite in microstructures. Finally, we used both support vector machine (SVM) and decision tree (DT) algorithms to establish a mapping relationship between the microstructure, carbon content, and residual stress to predict the residual stress of steel from its microstructure and carbon content. The experiments verified that the prediction model constructed in this study exhibits high accuracy and can directly predict residual stress without requiring any long-term measurements. Thus, the developed model provides a new approach to the study of residual stress in steel.","residual stress,microstructure,semantic segmentation,support vector machine",Article,"MDPI, ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND","Chemistry,Engineering,Materials Science,Physics",,2.736,"HIGH-CYCLE,FATIGUE",APPLIED SCIENCES-BASEL,https://www.mdpi.com/2076-3417/10/21/7759/pdf,
100,Prediction of surface roughness of laser selective metallization of ceramics by multiple linear regression and artificial neural networks approaches,32,4,,"Wang Li,Silva Lisbeth,Suess-Wolf Robert,Franke Joerg","Wang L,Silva L,Suss-Wolf R,Franke J",Wang L,10.2351/7.0000198,University of Erlangen Nuremberg,"Laser selective metallization of ceramics (LMC) has been widely applied to prepare high-quality electrical patterns on ceramic circuit carriers. As the dominating factor, surface roughness after laser treatment is controlled mostly by the laser technical parameters, such as laser power, scanning velocity, and laser frequency. Therefore, establishing an accurate relation between the surface roughness and the laser parameters will be of great benefit to the LMC specimens. In the present research, machine learning is used to simulate the LMC process on an alumina-copper oxide ceramic. The effect of each laser parameter and the interaction between them are revealed by the multiple linear regression method. The artificial neural network model trained with the Levenberg-Marquardt function provides the best estimation of the surface roughness after laser treatment compared with the Bayesian-regularization function and the scaled-conjugate-gradient function. The result can be used as a practical prediction and reasonable guideline for the optimization of LMC processes.","laser,metallization,MID,multiple linear regression,artificial neural networks",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA","Materials Science,Optics,Physics",,2.103,,JOURNAL OF LASER APPLICATIONS,,
