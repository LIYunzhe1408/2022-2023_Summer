,title,Volume,Issue,Pages,whole__author_name,simply_author_name,reprint author,DOI,reprint address,Abstract,Keywords,Document Type,Publisher,Research Domain,Published Date,impact_factor,Keywords_plus,joural,pdf_link,Download_SuccessOrDefeat
1,Leverage electron properties to predict phonon properties via transfer learning for semiconductors,6,45,,"Liu Zeyu,Jiang Meng,Luo Tengfei","Liu ZY,Jiang M,Luo TF",Luo TF,10.1126/sciadv.abd1356,University of Notre Dame,"Electron properties are usually easier to obtain than phonon properties. The ability to leverage electron properties to help predict phonon properties can thus greatly benefit materials by design for applications like thermoelectrics and electronics. Here, we demonstrate the ability of using transfer learning (TL), where knowledge learned from training machine learning models on electronic bandgaps of 1245 semiconductors is transferred to improve the models, trained using only 124 data, for predicting various phonon properties (phonon bandgap, group velocity, and heat capacity). Compared to directly trained models, TL reduces the mean absolute errors of prediction by 65, 14, and 54% respectively, for the three phonon properties. The TL models are further validated using several semiconductors outside of the 1245 database. Results also indicate that TL can leverage not-so-accurate proxy properties, as long as they encode composition-property relation, to improve models for target properties, a notable feature to materials informatics in general.","HIGH THERMAL-CONDUCTIVITY,ABSORPTION,STATES,GAN",Article,"AMER ASSOC ADVANCEMENT SCIENCE, 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA",Science & Technology - Other Topics,,16.45,"HIGH,THERMAL-CONDUCTIVITY,ABSORPTION,STATES,GAN",SCIENCE ADVANCES,https://advances.sciencemag.org/content/advances/6/45/eabd1356.full.pdf,
2,Characterization of Blood Pressure and Heart Rate Oscillations of POTS Patients via Uniform Phase Empirical Mode Decomposition,67,11,3016-3025,"Geddes Justen,Mehlsen Jesper,Olufsen Mette S.","Geddes J,Mehlsen J,Olufsen MS",Olufsen MS,10.1109/TBME.2020.2974095,University of North Carolina,"Objective: Postural Orthostatic Tachycardia Syndrome (POTS) is associated with the onset of tachycardia upon postural change. The current diagnosis involves the measurement of heart rate (HR) and blood pressure (BP) during head-up tilt (HUT) or active standing test. A positive diagnosis is made if HR changes with more than 30 bpm (40 bpm in patients aged 12-19 years), ignoring all of the BP and most of the HR signals. This study examines 0.1 Hz oscillations in systolic arterial blood pressure (SBP) and HR signals providing additional metrics characterizing the dynamics of the baroreflex. Methods: We analyze data from 28 control subjects and 28 POTS patients who underwent HUT. We extract beat-to-beat HR and SBP during a 10 min interval including 5 minutes of baseline and 5 minutes of HUT. We employ Uniform Phase Empirical Mode Decomposition (UPEMD) to extract 0.1 Hz stationary modes from both signals and use random forest machine learning and k-means clustering to analyze the outcomes. Results show that the amplitude of the 0.1 Hz oscillations is higher in POTS patients and that the phase response between the two signals is shorter (p < 0.005). Conclusion: POTS is associated with an increase in the amplitude of SBP and HR 0.1 Hz oscillation and shortening of the phase between the two signals. Significance: The 0.1 Hz phase response and oscillation amplitude metrics provide new markers that can improve POTS diagnostic augmenting the existing diagnosis protocol only analyzing the change in HR.","Heart rate,Oscillators,Baroreflex,Blood pressure,Empirical mode decomposition,Measurement,Aging,Empirical mode decomposition (EMD),head-up tilt (HUT),postural orthostatic tachycardia syndrome (POTS),uniform phase empirical mode decomposition (UPEMD),clustering",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"ORTHOSTATIC,TACHYCARDIA,SYNDROME,RATE-VARIABILITY,BAROREFLEX,DIAGNOSIS,COMMON",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,http://arxiv.org/pdf/1910.10332,
3,Ultrasound-Based Phenotyping of Lateral Ventricles to Predict Hydrocephalus Outcome in Premature Neonates,67,11,3026-3034,"Tabrizi Pooneh R.,Mansoor Awais,Obeid Rawad,Cerrolaza Juan J.,Perez Daniel A.,Zember Jonathan,Penn Anna,Linguraru Marius George","Tabrizi PR,Mansoor A,Obeid R,Cerrolaza JJ,Perez DA,Zember J,Penn A,Linguraru MG",Tabrizi PR,10.1109/TBME.2020.2974650,Children's National Health System,"Objective: Prediction of post-hemorrhagic hydrocephalus (PHH) outcome-i.e., whether it requires intervention or not-in premature neonates using cranial ultrasound (CUS) images is challenging. In this paper, we present a novel fully-automatic method to perform phenotyping of the brain lateral ventricles and predict PHH outcome from CUS. Methods: Our method consists of two parts: ventricle quantification followed by prediction of PHH outcome. First, cranial bounding box and brain interhemispheric fissure are detected to determine the anatomical position of ventricles and correct the cranium rotation. Then, lateral ventricles are extracted using a new deep learning-based method by incorporating the convolutional neural network into a probabilistic atlas-based weighted loss function and an image-specific adaption. PHH outcome is predicted using a support vector machine classifier trained using ventricular morphological phenotypes and clinical information. Results: Experiments demonstrated that our method achieves accurate ventricle segmentation results with an average Dice similarity coefficient of 0.86, as well as very good PHH outcome prediction with accuracy of 0.91. Conclusion: Automatic CUS-based ventricular phenotyping in premature newborns could objectively and accurately predict the progression to severe PHH. Significance: Early prediction of severe PHH development in premature newborns could potentially advance criteria for diagnosis and offer an opportunity for early interventions to improve outcome.","Pediatrics,Image segmentation,Cranial,Two dimensional displays,Ultrasonic imaging,Three-dimensional displays,Cranium,Convolutional neural network,hydrocephalus,lateral ventricles,prediction,premature neonates,segmentation,ultrasound",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"POSTHEMORRHAGIC,HYDROCEPHALUS,INTRAVENTRICULAR,HEMORRHAGE,NOVA-SCOTIA,SEGMENTATION,INFANTS,IMAGES",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
4,Soft Nanomembrane Sensors and Flexible Hybrid Bioelectronics for Wireless Quantification of Blepharospasm,67,11,3094-3100,"Mahmood Musa,Kwon Shinjae,Berkmen Gamze Kilic,Kim Yun-Soung,Scorr Laura,Jinnah H. A.,Yeo Woon-Hong","Mahmood M,Kwon S,Berkmen GK,Kim YS,Scorr L,Jinnah HA,Yeo WH",Yeo WH,10.1109/TBME.2020.2975773,University System of Georgia,"Blepharospasm (BL) is characterized by involuntary closures of the eyelids due to spasms of the orbicularis oculi muscle. The gold standard for clinical evaluation of BL involves visual inspection for manual rating scales. This approach is highly subjective and error prone. Unfortunately, there are currently no simple quantitative systems for accurate and objective diagnostics of BL. Here, we introduce a soft, flexible hybrid bioelectronic system that offers highly conformal, gentle lamination on the skin, while enabling wireless, quantitative detection of electrophysiological signals. Computational and experimental studies of soft materials and flexible mechanics provide a set of key fundamental design factors for a low-profile bioelectronic system. The nanomembrane soft electrodes, mounted around the eyes, are capable of accurately measuring clinical symptoms, including the frequency of blinking, the duration of eye closures during spasms, as well as combinations of blinking and spasms. The use of a deep-learning, convolutional neural network, with the bioelectronics offers objective, real-time classification of key pathological features in BL. The wearable bioelectronics outperform the conventional manual clinical rating, as shown by a pilot study with 13 patients. In vivo demonstration of the bioelectronics with these patients indicates the device as an easy-to-use solution for objective quantification of BL.","Electrodes,Muscles,Wireless communication,Wireless sensor networks,Skin,Information filters,Soft bioelectronics,stretchable electrodes,flexible hybrid electronics,blepharospasm,electrophysiology,quantitative diagnostics",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"OPTIMIZED,DESIGNS,CERVICAL,DYSTONIA,BOTULINUM,TOXIN,ELECTRONICS",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
5,Novel Deep Learning Network Analysis of Electrical Stimulation Mapping-Driven Diffusion MRI Tractography to Improve Preoperative Evaluation of Pediatric Epilepsy,67,11,3151-3162,"Lee Min-Hee,O'Hara Nolan,Sonoda Masaki,Kuroda Naoto,Juhasz Csaba,Asano Eishi,Dong Ming,Jeong Jeong-Won","Lee MH,O'Hara N,Sonoda M,Kuroda N,Juhasz C,Asano E,Dong M,Jeong JW",Jeong JW,10.1109/TBME.2020.2977531,Wayne State University,"Objective: To investigate the clinical utility of deep convolutional neural network (DCNN) tract classification as a new imaging tool in the preoperative evaluation of children with focal epilepsy (FE). Methods: A DCNN tract classification deeply learned spatial trajectories of DWI white matter pathways linking electrical stimulation mapping (ESM) findings from 89 children with FE, and then automatically identified white matter pathways associated with eloquent functions (i.e., primary motor, language, and vision). Clinical utility was examined by 1) measuring the nearest distance between DCNN-determined pathways and ESM, 2) evaluating the effectiveness of DCNN-determined pathways to optimize surgical margins via Kalman filter analysis, and 3) evaluating how accurately changes in DCNN-determined language pathway volume can predict changes in language ability via canonical correlation analysis. Results: DCNN tract classification outperformed other existing methods, achieving an excellent accuracy of 98% while non-invasively detecting eloquent areas within the spatial resolution of ESM (i.e., 1 cm). The Kalman filter analysis found that the preservation of brain areas within a surgical margin determined by DCNN tract classification predicted lack of postoperative deficit with a high accuracy of 92%. Postoperative change of DCNN-determined language pathway volume showed a significant correlation with postoperative changes in language ability (R = 0.7, p < 0.001). Conclusion: Our findings demonstrate that postoperative functional deficits substantially differ according to the extent of resected white matter, and that DCNN tract classification may offer key translational information by identifying these pathways in pediatric epilepsy surgery. Significance: DCNN tract classification may be an effective tool to improve surgical outcome of children with FE.","Surgery,Epilepsy,Pediatrics,White matter,Task analysis,Visualization,Machine learning,Deep convolutional neural network,diffusion tractography,eloquent function,electrical stimulation mapping,epilepsy",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA",Engineering,,5.337,"DISTORTION,CORRECTION,IMAGING,TRACTOGRAPHY,FUNCTIONAL,MRI,LANGUAGE,CHILDREN,MOVEMENT,SEIZURES,SURGERY,SEGMENTATION,CONNECTIVITY",IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,,
6,Classification of stroke using neural networks in electrical impedance tomography,36,11,,"Agnelli J. P.,Col A.,Lassas M.,Murthy R.,Santacesaria M.,Siltanen S.","Agnelli JP,Col A,Lassas M,Murthy R,Santacesaria M,Siltanen S",Murthy R,10.1088/1361-6420/abbdcd,University of Helsinki,"Electrical impedance tomography (EIT) is an emerging non-invasive medical imaging modality. It is based on feeding electrical currents into the patient, measuring the resulting voltages at the skin, and recovering the internal conductivity distribution. The mathematical task of EIT image reconstruction is a nonlinear and ill-posed inverse problem. Therefore any EIT image reconstruction method needs to be regularized, typically resulting in blurred images. One promising application is stroke-EIT, or classification of stroke into either ischemic or hemorrhagic. Ischemic stroke involves a blood clot, preventing blood flow to a part of the brain causing a low-conductivity region. Hemorrhagic stroke means bleeding in the brain causing a high-conductivity region. In both cases the symptoms are identical, so a cost-effective and portable classification device is needed. Typical EIT images are not optimal for stroke-EIT because of blurriness. This paper explores the possibilities of machine learning in improving the classification results. Two paradigms are compared: (a) learning from the EIT data, that is Dirichlet-to-Neumann maps and (b) extracting robust features from data and learning from them. The features of choice are virtual hybrid edge detection (VHED) functions (Greenleaf et al 2018 Anal. PDE 11) that have a geometric interpretation and whose computation from EIT data does not involve calculating a full image of the conductivity. We report the measures of accuracy, sensitivity and specificity of the networks trained with EIT data and VHED functions separately. Computational evidence based on simulated noisy EIT data suggests that the regularized grey-box paradigm (b) leads to significantly better classification results than the black-box paradigm (a).","inverse problems,EIT,neural networks,VHED function,classification",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Mathematics,Physics",,2.618,"D-BAR,METHOD,INVERSE,PROBLEMS,UNIQUENESS,BRAIN",INVERSE PROBLEMS,https://helda.helsinki.fi/bitstream/10138/335615/1/Agnelli_2020_Inverse_Problems_36_115008.pdf,
7,Controllable analog resistive switching and synaptic characteristics in ZrO2/ZTO bilayer memristive device for neuromorphic systems,529,,,"Ismail Muhammad,Abbas Haider,Choi Changhwan,Kim Sungjun","Ismail M,Abbas H,Choi C,Kim S",Choi C,10.1016/j.apsusc.2020.147107,Hanyang University,"The development of artificial synaptic devices is a crucial step for the realization of efficient bio-inspired neuromorphic computing systems. In this work, the bilayer ZrO2/ZTO-based electronic synaptic devices were fabricated for better emulation of the brain's functions for neuromorphic computing. The ZrO2/ZTO switching layer is used to achieve stable and continuous switching for the emulation of the synaptic functions. The growth and rupture of conducting filament can be efficiently controlled by modulating the SET-compliance current (CC, 1 mA to 10 mA with 0.5 mA increment) and the RESET-voltage (1.0 V to 2.0 V, with 0.025 V increment) during the SET- and RESET-process, respectively. The incremental switching characteristics were exploited with proper pulse stimulations to emulate essential synaptic functions. Various pulse measurements were carried out to mimic some of the basic synaptic functions including long-term potentiation (LTP), long-term depression (LTD), spike-rate-dependent plasticity (SRDP), paired-pulse facilitation (PPF), and post-tetanic potentiation (PTP). Finally, the spike-timing-dependent plasticity (STDP) learning behavior was successfully emulated, which demonstrates the feasibility of ZrO2/ZTO-based electronic synaptic device for neuromorphic applications.","Multiple states,Neuromorphic computing,Biological synapse,ZrO2/ZTO memristor,Resistive switching",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Chemistry,Materials Science,Physics",,5.905,"PLASTICITY,SYNAPSES,HIPPOCAMPUS,MEMORY,RRAM,LTP",APPLIED SURFACE SCIENCE,,
8,Actor-critic learning for optimal building energy management with phase change materials,188,,,"Rahimpour Zahra,Verbic Gregor,Chapman Archie C.","Rahimpour Z,Verbic G,Chapman AC",Rahimpour Z,10.1016/j.epsr.2020.106543,University of Sydney,"Energy management in buildings using phase change materials (PCM) to improve thermal performance is challenging due to the nonlinear thermal capacity of the PCM. To address this problem, this paper adopts a model-free actor-critic on-policy reinforcement learning method based on deep deterministic policy gradient (DDPG). The proposed approach overcomes the major weakness of model-based approaches, such as approximate dynamic programming (ADP), which require an explicit thermal model of the building under control. This requirement makes a plug-and-play implementation of the energy management algorithm in an existing smart meter difficult due to the wide variety of building design and construction types. To overcome this difficulty, we use a DDPG algorithm that can learn policies in continuous action spaces without access to the full dynamics of the building. We demonstrate the competitive performance of DDPG by benchmarking it against an ADP-based approach with access to the full thermal dynamics of the building.","Actor-critic,Approximate dynamic programming,Deep deterministic policy gradient,Home energy management,Phase change materials",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND",Engineering,,3.499,,ELECTRIC POWER SYSTEMS RESEARCH,,
9,Active Contour-Based Method for Finger-Vein Image Segmentation,69,11,8656-8665,"Zhang Jianfeng,Lu Zhiying,Li Min","Zhang JF,Lu ZY,Li M",Lu ZY,10.1109/TIM.2020.2995485,Tianjin University,"Suffering from uneven illumination and variation of finger position, it is still a tough challenge to effectively distinguish the vein networks and nonvenous regions in a finger-vein image. Methods based on active contour have achieved an excellent result in medical image segmentation, despite facing several challenges such as vulnerable to the initial contour and prone to local minimum. In this article, we propose a novel method which is effective for finger-vein image segmentation based on active contour. Since venous and nonvenous areas in captured finger-vein images are hard to distinguish, we design a dehazing algorithm and an edge fitting term to improve the segmentation procedure. Moreover, we employ the kernel fuzzy C-means (KFCM) algorithm to conduct the initialization, which is able to solve the problem that the active contour-based methods are susceptible to initial contours. The experimental results show that compared with latest methods, the proposed method achieves a better performance in segmenting finger-vein images and is able to improve the recognition accuracy of finger-vein identification system.","Image segmentation,Veins,Active contours,Mathematical model,Machine learning,Atmospheric modeling,Biomedical imaging,Active contour,finger-vein,haze removal,image segmentation,kernel fuzzy C-means (KFCM)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"FEATURE-EXTRACTION,RECOGNITION",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
10,Transfer Dictionary Learning Method for Cross-Domain Multimode Process Monitoring and Fault Isolation,69,11,8713-8724,"Huang Keke,Wen Haofei,Zhou Can,Yang Chunhua,Gui Weihua","Huang KK,Wen HF,Zhou C,Yang CH,Gui WH",Zhou C,10.1109/TIM.2020.2998875,Central South University,"Data-driven methods have shown its great latent capacity in the field of industrial process monitoring. However, the existing methods usually achieve good results under the assumption that the offline learning data and the online monitoring data are drawn from the same distribution. Unfortunately, in the industrial system, the assumption is often violated due to the harsh operating environment. Especially, with the increasing complexity and scale of industrial production, the supervisory control and data acquisition (SCADA) data of the industrial production process often collected from different machines, seasons, or operating modes. In addition, due to the cost of manual data labeling and real-time requirement of process monitoring, the offline learning data, which was used to build the model, often have abundant source-domain data and insufficient target-domain data. Consequently, these methods have bad performance on the online monitoring data collected from the target domain. In order to make full use of the knowledge from the abundant source-domain data, a transfer dictionary learning method is proposed to address the cross-domain problem in this article. The proposed method can learn an initial dictionary from the abundant source-domain data, and then, the final dictionary is updated by incorporating the feature of insufficient target-domain data in a smooth subspace interpolation way. The effectiveness of the proposed method is evaluated through a numerical simulation case, a continuous stirred tank heater (CSTH) case, and a wind turbine system case, from which we can see the proposed method has a better performance compared with some state-of-the-art methods.","Machine learning,Data models,Dictionaries,Hidden Markov models,Interpolation,Cross domain,process monitoring,sparse coding,subspace interpolation,transfer learning",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"SPARSE,REPRESENTATION,K-SVD,SELECTION,CLASSIFICATION,DIAGNOSIS,MACHINE,MODEL",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
11,Detection of Citrus Tristeza Virus in Mandarin Orange Using a Custom-Developed Electronic Nose System,69,11,9010-9018,"Hazarika Sudipta,Choudhury Rajdeep,Montazer Babak,Medhi Subhash,Goswami Manash Protim,Sarma Utpal","Hazarika S,Choudhury R,Montazer B,Medhi S,Goswami MP,Sarma U",Hazarika S,10.1109/TIM.2020.2997064,Gauhati University,"Olfaction is one of the primary senses of a living organism and has been used as first aid for inspecting freshness, edibility, and the quality of food. This article addresses a technique where the biological olfaction process has been mimicked by electronic nose (E-Nose) to detect a pathogen named Citrus Tristeza Virus (CTV) in Khasi Mandarin Orange plants. The proposed technique may be used as an alternative to currently used traditional serological or molecular tests, which requires costly and elaborate laboratory infrastructures. In this article, leaves from 62 plants were collected and examined for viral infection using the gold-standard polymerase chain reaction test. A commercial E-Nose system, Alpha MOS Fox 3000, was used for hypothesis testing, resulting in an accuracy of 95.30% using random forest classifier. These results were used to identify the most prominent sensors and their target gases responding to the CTV infection and were considered as a base for sensor selection for custom developing a prototype. The prototype was designed based on simulations for optimum airflow in the sensor chamber. Bootstrap ensemble of k-nearest neighbors and adaptive boost ensemble of decision tree classifier distinguished the data generated from the prototype with an accuracy of 99.36% and 97.58%, respectively. The performance of the classifiers was visualized graphically using dimensionality reduction techniques. These results indicated that the E-Nose technique employed could differentiate the healthy and infected samples and the prototype could serve as an effective first-hand diagnosing tool for large-scale orchards.","Biotic stress,dimensionality reduction,ensemble learning,finite-element method (FEM) simulation,polymerase chain reaction (PCR),volatile organic compounds (VOCs)",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Engineering,Instruments & Instrumentation",,3.953,"DISCRIMINATION,RECOGNITION,DIAGNOSIS,QUALITY",IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,,
12,Machine learning-based signal degradation models for attenuated underwater optical communication OAM beams,474,,,"Neary Patrick L.,Watnik Abbie T.,Judd K. Peter,Lindle James R.,Flann Nicholas S.","Neary PL,Watnik AT,Judd KP,Lindle JR,Flann NS",Neary PL,10.1016/j.optcom.2020.126058,Utah System of Higher Education,Signal attenuation in underwater communications is a problem that degrades classification performance. Several novel CNN-based (SMART) models are developed to capture the physics of the attenuation process. One model is built and trained using automatic differentiation and another uses the radon cumulative distribution transform. These models are inserted in the classifier training pipeline. It is shown that including these attenuation models in classifier training significantly improves classification performance when the trained model is tested with environmentally attenuated images. The improved classification accuracy will be important in future OAM underwater optical communication applications.,"Convolutional neural networks,Automatic differentiation,Radon cumulative distribution transform,Attenuation models,Orbital angular momentum,Underwater communications,Physics-based training",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Optics,,1.945,"ORBITAL,ANGULAR-MOMENTUM,CUMULATIVE,DISTRIBUTION,TRANSFORM,LIGHT",OPTICS COMMUNICATIONS,https://digitalcommons.usu.edu/cgi/viewcontent.cgi?article=1017&context=computer_science_facpubs,
13,"Artificial Intelligence in Renal Mass Characterization: A Systematic Review of Methodologic Items Related to Modeling, Performance Evaluation, Clinical Utility, and Transparency",215,5,1113-1122,"Kocak Burak,Kaya Ozlem Korkmaz,Erdim Cagri,Kus Ece Ates,Kilickesmez Ozgur","Kocak B,Kaya OK,Erdim C,Kus EA,Kilickesmez O",Kocak B,10.2214/AJR.20.22847,Istanbul Training & Research Hospital,"OBJECTIVE. The objective of our study was to systematically review the literature about the application of artificial intelligence (AI) to renal mass characterization with a focus on the methodologic quality items.
MATERIALS AND METHODS. A systematic literature search was conducted using PubMed to identify original research studies about the application of AI to renal mass characterization. Besides baseline study characteristics, a total of 15 methodologic quality items were extracted and evaluated on the basis of the following four main categories: modeling, performance evaluation, clinical utility, and transparency items. The qualitative synthesis was presented using descriptive statistics with an accompanying narrative.
RESULTS. Thirty studies were included in this systematic review. Overall, the methodologic quality items were mostly favorable for modeling (63%) and performance evaluation (63%). Even so, the studies (57%) more frequently constructed their work on nonrobust features. Furthermore, only a few studies (10%) had a generalizability assessment with independent or external validation. The studies were mostly unsuccessful in terms of clinical utility evaluation (89%) and transparency (97%) items. For clinical utility, the interesting findings were lack of comparisons with both radiologists' evaluation (87%) and traditional models (70%) in most of the studies. For transparency, most studies (97%) did not share their data with the public.
CONCLUSION. To bring AI-based renal mass characterization from research to practice, future studies need to improve modeling and performance evaluation strategies and pay attention to clinical utility and transparency issues.","artificial intelligence (AI),machine learning,radiomics,renal cell carcinoma,renal mass",Article,"AMER ROENTGEN RAY SOC, 44211 SLATESTONE CT, LEESBURG, VA USA","Radiology, Nuclear Medicine & Medical Imaging",,4.073,"CT,TEXTURE,ANALYSIS,CELL,CARCINOMA,CLEAR-CELL,DIFFERENTIATION,ANGIOMYOLIPOMA,FAT,RADIOMICS,DIAGNOSIS,FEATURES,IMAGES",AMERICAN JOURNAL OF ROENTGENOLOGY,,
14,Artificial Intelligence Predictive Analytics in the Management of Outpatient MRI Appointment No-Shows,215,5,1155-1162,"Chong Le Roy,Tsai Koh Tzan,Lee Lee Lian,Foo Seck Guan,Chang Piek Chim","Chong LR,Tsai KT,Lee LL,Foo SG,Chang PC",Chong LR,10.2214/AJR.19.22594,Changi General Hospital,"OBJECTIVE. Outpatient appointment no-shows are a common problem. Artificial intelligence predictive analytics can potentially facilitate targeted interventions to improve efficiency. We describe a quality improvement project that uses machine learning techniques to predict and reduce outpatient MRI appointment no-shows.
MATERIALS AND METHODS. Anonymized records from 32,957 outpatient MRI appointments between 2016 and 2018 were acquired for model training and validation along with a holdout test set of 1080 records from January 2019. The overall no-show rate was 17.4%. A predictive model developed with XGBoost, a decision tree-based ensemble machine learning algorithm that uses a gradient boosting framework, was deployed after various machine learning algorithms were evaluated. The simple intervention measure of using telephone call reminders for patients with the top 25% highest risk of an appointment no-show as predicted by the model was implemented over 6 months.
RESULTS. The ROC AUC for the predictive model was 0.746 with an optimized F1 score of 0.708; at this threshold, the precision and recall were 0.606 and 0.852, respectively. The AUC for the holdout test set was 0.738 with an optimized F1 score of 0.721; at this threshold, the precision and recall were 0.605 and 0.893, respectively. The no-show rate 6 months after deployment of the predictive model was 15.9% compared with 19.3% in the preceding 12-month preintervention period, corresponding to a 17.2% improvement from the baseline no-show rate (p < 0.0001). The no-show rates of contactable and noncontactable patients in the group at high risk of appointment no-shows as predicted by the model were 17.5% and 40.3%, respectively (p < 0.0001).
CONCLUSION. Machine learning predictive analytics perform moderately well in predicting complex problems involving human behavior using a modest amount of data with basic feature engineering, and they can be incorporated into routine workflow to improve health care delivery.","artificial intelligence,machine learning,MRI,no-show,XGBoost",Article,"AMER ROENTGEN RAY SOC, 44211 SLATESTONE CT, LEESBURG, VA USA","Radiology, Nuclear Medicine & Medical Imaging",,4.073,ATTENDANCE,AMERICAN JOURNAL OF ROENTGENOLOGY,,
15,Machine Learning-Based MRI Texture Analysis to Predict the Histologic Grade of Oral Squamous Cell Carcinoma,215,5,1184-1190,"Ren Jiliang,Qi Meng,Yuan Ying,Duan Shaofeng,Tao Xiaofeng","Ren JL,Qi M,Yuan Y,Duan SF,Tao XF",Tao XF,10.2214/AJR.19.22593,Shanghai Jiao Tong University,"OBJECTIVE. This study aimed to explore the performance of machine learning (ML)-based MRI texture analysis in discriminating between well-differentiated (WD) oral squamous cell carcinoma (OSCC) and moderately or poorly differentiated OSCC.
MATERIALS AND METHODS. The study enrolled 80 patients with pathologically confirmed OSCC (18 WD OSCCs and 62 moderately or poorly differentiated OSCCs) who underwent pretreatment MRI. ROIs were manually delineated to cover the entire tumor to the greatest possible extent on T2-weighted imaging and contrast-enhanced T1-weighted imaging, and 1118 texture features were extracted. Dimension reduction was performed using reproducibility analysis by two radiologists, collinearity analysis, and feature selection with a minimum-redundancy maximum-relevance algorithm. Models were created using random forest (RF), artificial neural network, and logistic regression (LR) alone and with a synthetic minority oversampling technique (SMOTE). Classifier performance was assessed using 10-fold cross-validation.
RESULTS. Dimension reduction steps yielded eight texture features, including four features from each sequence. None of the clinical variables was selected. Among the eight texture features, five and seven texture features showed significant differences between the two groups in the actual data and balanced data, respectively (p < 0.05). All classifiers with SMOTE achieved better performances than those alone. The RF classifier with SMOTE achieved the best performance with an area under the ROC curve of 0.936 and accuracy of 86.3%.
CONCLUSION. ML-based MRI texture analysis provides a promising noninvasive approach for predicting the histologic grade of OSCC.","head and neck cancer,machine learning,MRI,texture analysis",Article,"AMER ROENTGEN RAY SOC, 44211 SLATESTONE CT, LEESBURG, VA USA","Radiology, Nuclear Medicine & Medical Imaging",,4.073,"FEATURES,CANCER,HEAD",AMERICAN JOURNAL OF ROENTGENOLOGY,,
16,Developing an Improved Statistical Approach for Survival Estimation in Bone Metastases Management: The Bone Metastases Ensemble Trees for Survival (BMETS) Model,108,3,554-563,"Alcorn Sara R.,Fiksel Jacob,Wright Jean L.,Elledge Christen R.,Smith Thomas J.,Perng Powell,Saleemi Sarah,McNutt Todd R.,DeWeese Theodore L.,Zeger Scott","Alcorn SR,Fiksel J,Wright JL,Elledge CR,Smith TJ,Perng P,Saleemi S,McNutt TR,DeWeese TL,Zeger S",Alcorn SR,10.1016/j.ijrobp.2020.05.023,Johns Hopkins University,"Purpose: To determine whether a machine learning approach optimizes survival estimation for patients with symptomatic bone metastases (SBM), we developed the Bone Metastases Ensemble Trees for Survival (BMETS) to predict survival using 27 prognostic covariates. To establish its relative clinical utility, we compared BMETS with 2 simpler Cox regression models used in this setting.
Methods and Materials: For 492 bone sites in 397 patients evaluated for palliative radiation therapy (RT) for SBM from January 2007 to January 2013, data for 27 clinical variables were collected. These covariates and the primary outcome of time from consultation to death were used to build BMETS using random survival forests. We then performed Cox regressions as per 2 validated models: Chow's 3-item (C-3) and Westhoff's 2-item (W-2) tools. Model performance was assessed using cross-validation procedures and measured by time-dependent area under the curve (tAUC) for all 3 models. For temporal validation, a separate data set comprised of 104 bone sites treated in 85 patients in 2018 was used to estimate tAUC from BMETS.
Results: Median survival was 6.4 months. Variable importance was greatest for performance status, blood cell counts, recent systemic therapy type, and receipt of concurrent nonbone palliative RT. tAUC at 3, 6, and 12 months was 0.83, 0.81, and 0.81, respectively, suggesting excellent discrimination of BMETS across postconsultation time points. BMETS outperformed simpler models at each time, with respective tAUC at each time of 0.78, 0.76, and 0.74 for the C-3 model and 0.80, 0.78, and 0.77 for the W-2 model. For the temporal validation set, respective tAUC was similarly high at 0.86, 0.82, and 0.78.
Conclusions: For patients with SBM, BMETS improved survival predictions versus simpler traditional models. Model performance was maintained when applied to a temporal validation set. To facilitate clinical use, we developed a web platform for data entry and display of BMETS-predicted survival probabilities. (C) 2020 Elsevier Inc. All rights reserved.","PALLIATIVE RADIOTHERAPY,RADIATION-THERAPY,LIFE EXPECTANCY,CANCER-PATIENTS,PROGNOSIS,COUNTS,INDEX,TOOL",Article,"ELSEVIER SCIENCE INC, STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","Oncology,Radiology, Nuclear Medicine & Medical Imaging",,6.884,"PALLIATIVE,RADIOTHERAPY,RADIATION-THERAPY,LIFE,EXPECTANCY,CANCER-PATIENTS,PROGNOSIS,COUNTS,INDEX,TOOL",INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS,,
17,Machine-learning models for Raman spectra analysis of twisted bilayer graphene,169,,455-464,"Sheremetyeva Natalya,Lamparski Michael,Daniels Colin,Van Troeye Benoit,Meunier Vincent","Sheremetyeva N,Lamparski M,Daniels C,Van Troeye B,Meunier V",Meunier V,10.1016/j.carbon.2020.06.077,Rensselaer Polytechnic Institute,"The vibrational properties of twisted bilayer graphene (tBLG) show complex features, due to the intricate energy landscape of its low-symmetry configurations. A machine learning-based approach is developed to provide a continuous model between the twist angle and the simulated Raman spectra of tBLGs. Extracting the structural information of the twist angle from Raman spectra corresponds to solving a complicated inverse problem. Once trained, the machine learning regressors (MLRs) quickly provide predictions without human bias and with an average 98% of the data variance being explained by the model. The significant spectral features learned by MLRs are analyzed revealing the intensity profile near the calculated G-band to be the most important feature. The trained models are tested on noise-containing test data demonstrating their robustness. The transferability of the present models to experimental Raman spectra is discussed in the context of validation of the level of theory used for construction of the analyzed database. This work serves as a proof of concept that machine-learning analysis is a potentially powerful tool for interpretation of Raman spectra of tBLG and other 2D materials. (C) 2020 Elsevier Ltd. All rights reserved.","Machine learning,Twisted bilayer graphene,Raman spectroscopy",Article,"PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND","Chemistry,Materials Science",,8.719,"BOND,POLARIZABILITY,MODEL,PHONON-DISPERSION,SCATTERING,CARBON,SHEAR",CARBON,http://arxiv.org/pdf/2007.03839,
18,What lies beneath: Material classification for autonomous excavators using proprioceptive force sensing and machine learning,119,,,"Fernando Heshan,Marshall Joshua","Fernando H,Marshall J",Fernando H,10.1016/j.autcon.2020.103374,Queens University - Canada,"The ability of robotic excavators to acquire meaningful knowledge about materials during digging can augment their autonomous functionality, as well as optimize downstream operations in construction and mining. Some material properties, such as rock sizes, can be determined visually, but these methods cannot see what lies beneath. In this work, a classification methodology that utilizes only proprioceptive force data acquired from an autonomous digging system and machine learning algorithms is proposed for excavation material identification. The consistent performance synonymous with autonomous digging systems allows for the use of basic features extracted from the force data for classification. A proof of concept of this novel approach to excavation material classification is demonstrated through a binary classification of rock and gravel materials. Force data were obtained from full-scale autonomous loading trials with a 14-tonne capacity load-haul-dump machine at a mining and construction test facility. Preliminary results achieved a classification accuracy of 90%.","Force sensing,Machine learning,Robotic excavation,Loader automation",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Construction & Building Technology,Engineering",,8.0,"ROCK,IDENTIFICATION,PARAMETERS",AUTOMATION IN CONSTRUCTION,https://qspace.library.queensu.ca/bitstream/1974/28600/1/FerMar-AUTOCON-2019.pdf,
19,"Modeling, simulation and machine learning for rapid process control of multiphase flowing foods",371,,,"Kim D. H.,Zohdi T. I,Singh R. P.","Kim DH,Zohdi TI,Singh RP",Zohdi TI,10.1016/j.cma.2020.113286,University of California System,"Across many modern industries, as technologies have matured, the use of more complex processes involving multiphase materials has increased. In the food industry, multiphase fluids are now relatively wide-spread, in particular, because of the desire to have faster throughput for large-scale food production. In many cases involving transport, such materials consist of a fluidized binder material with embedded particles. As one increases the volume fraction of particles, a corresponding increase in effective overall viscosity occurs. Often, during the process, the material must be heated, for example, to ensure food safety, induce pasteurization, sterilization, etc. For real-time control, this requires rapidly computable models to guide thermal processing, for example by applied electrical induction. In the present analysis, models are developed for the required heating field (electrically induced) and pressure gradient needed in a pipe to heat a multiphase material to a target temperature and to transport the material with a prescribed flow rate. (C) 2020 Elsevier B.V. All rights reserved.","Multiphase foods,Flow,Thermal control,Machine learning",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Engineering,Mathematics,Mechanics",,6.828,HEAT-EXCHANGERS,COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING,,
20,Scale bridging materials physics: Active learning workflows and integrable deep neural networks for free energy function representations in alloys,371,,,"Teichert G. H.,Natarajan A. R.,Van der Ven A.,Garikipati K.","Teichert GH,Natarajan AR,Van der Ven A,Garikipati K",Garikipati K,10.1016/j.cma.2020.113281,University of Michigan System,"The free energy plays a fundamental role in theories of phase transformations and microstructure evolution. It encodes the thermodynamic coupling between different fields, such as mechanics and chemistry, within continuum descriptions of non-equilibrium materials phenomena. In mechano-chemically interacting materials systems, even consideration of only compositions, order parameters and strains results in a free energy description that occupies a high-dimensional space. Scale bridging between the electronic structure of a solid and continuum descriptions of its non-equilibrium behavior can be realized with integrable deep neural networks (IDNN) that are trained to free energy derivative data generated by first-principles statistical mechanics simulations and then analytically integrating to recover a free energy density function. Here we combine the IDNN with an active learning workflow to ensure well-distributed sampling of the free energy derivative data in high-dimensional input spaces, thereby enabling true scale bridging between first-principles statistical mechanics and continuum phase field models. As a prototypical material system we focus on Ni-Al. Cahn-Hilliard and Allen-Cahn phase field simulations using the resulting IDNN representation for the free energy density of Ni-Al demonstrate that the appropriate physics of the material have been learned. This work advances the treatment of scale bridging, starting with electronic structure calculations and proceeding through statistical mechanics to continuum physics. Its coupling of Cahn-Hilliard and Allen-Cahn phase field descriptions with nonlinear elasticity through the free energy density ensures a rigorous treatment of phase transformation phenomena. (C) 2020 Elsevier B.V. All rights reserved.","First-principles calculations,Statistical mechanics,Machine Learning,Phase field modeling,Continuum mechanics",Article,"ELSEVIER SCIENCE SA, PO BOX 564, 1001 LAUSANNE, SWITZERLAND","Engineering,Mathematics,Mechanics",,6.828,"ELASTICALLY,STRESSED,SOLIDS,PHASE,TRANSFORMATION,SIMULATIONS,GAMMA",COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING,http://arxiv.org/pdf/2002.02305,
21,Generative adversarial network-convolution neural network based breast cancer classification using optical coherence tomographic images,30,11,,"Kansal Shaify,Goel Shivani,Bhattacharya Jhilik,Srivastava Vishal","Kansal S,Goel S,Bhattacharya J,Srivastava V",Srivastava V,10.1088/1555-6611/abb596,Thapar Institute of Engineering & Technology,"Currently, breast tissue images are primarily classified by pathologists, which is time-consuming and subjective. Deep learning, however, can perform this task with the utmost precision. In order to achieve an improved performance, a large number of annotated datasets are required to train the network, which is a challenging task in the medical field. In this paper, we propose an intelligent system, based on generative adversarial networks (GANs) and a convolution neural network (CNN) for the automatic classification of breast cancer, using optical coherence tomography (OCT) images. In this network, the GAN is used to generate synthetic datasets and to further utilize these synthetic datasets to increase the quantity of information, so as to improve the classification performance of the CNN. Our method is demonstrated by means of a limited set of OCT images of breast tissue. The classification performance of our method, using only the classic data increase, yielded a sensitivity level of 93.6%, with 90.8% specificity and 91.7% accuracy, based on the test datasets. By adding the synthetic data increase, the accuracy of the training datasets increased to 93.7% from 92.0%. We believe that this approach will help radiologists and pathologists to improve their diagnotic capability.","optical coherence tomography,deep learning,breast tissue,generative adversarial networks",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Optics,Physics",,1.157,,LASER PHYSICS,,
22,A Robotic System for Warped Stitching Based Compressive Strength Prediction of Marbles,16,11,6796-6805,Selver M. Alper,Selver MA,Selver MA,10.1109/TII.2019.2926372,Dokuz Eylul University,"The amount, distribution, and morphology of the impurities in a marble block determine both its aesthetic quality and compressive strength (CS). Although the former property has been studied extensively, CS prediction is rarely investigated. The existing approaches either use expensive and tedious laboratory tests or employ image processing to individual surface images, which are shown to achieve limited performance. In this paper, a new electromechanical system is designed for full automatic prediction of CS of a marble block on a conveyor belt using all visible surface images, which are acquired by a three-dimensional (3-D) printed robotic arm. The images are used to generate unique reconstructions, which can represent the 3-D structure of the marbles in two-dimensional (2-D) via developed warped stitching based visualizations. Moreover, a novel feature set is proposed for taking advantage of these reconstructions. A total of 157 cubic marble blocks are collected to test the performance of the system using both conventional (neural networks) and emerging (deep) machine learning tools. Adverse effects of small sample size are compensated with data augmentation and transfer learning. It is shown that the system achieves the state-of-the-art prediction results.","Feature extraction,Surface morphology,Electronics packaging,Robots,Surface treatment,Discrete wavelet transforms,Three-dimensional displays,Automated inspection systems,compressive strength (CS),machine learning,marbles,stitching,warping",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Computer Science,Engineering",,9.768,CLASSIFICATION,IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS,,
23,A Coincidence-Filtering-Based Approach for CNNs in EEG-Based Recognition,16,11,7159-7167,"Gao Zhongke,Li Yanli,Yang Yuxuan,Dong Na,Yang Xiong,Grebogi Celso","Gao ZK,Li YL,Yang YX,Dong N,Yang X,Grebogi C",Dong N,10.1109/TII.2019.2955447,Tianjin University,"Electroencephalogram (EEG), obtained by wearable devices, can realize effective human health monitoring. Traditional methods based on artificially designed features have achieved valid results in EEG-based recognition, and numerous studies start to apply deep learning techniques in this area. In this article, we propose a coincidence-filtering-based method to build a connection between artificial-features-based methods and convolutional neural networks (CNNs), and design CNNs through simulating the information extraction pattern of artificial-features-based methods. Based on this method, we propose a novel, simple, and effective CNNs structure for EEG-based classification. We implement two experiments to obtain EEG data, and perform experiments based on the two health monitoring tasks. The results illustrate that the proposed network can achieve a prominent average accuracy on the emotion recognition and fatigue driving detection task. Due to its generality, the proposed framework design of CNNs is expected to be useful for broader applications in health monitoring areas.","Feature extraction,Electroencephalography,Task analysis,Fatigue,Emotion recognition,Brain modeling,Convolution,Convolutional neural networks (CNNs),electroencephalogram (EEG),emotion recognition,fatigue driving detection",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Computer Science,Engineering",,9.768,CLASSIFICATION,IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS,https://aura.abdn.ac.uk/bitstream/2164/13286/1/Gao_et_al_IEEEToII_CoincidenceFiltering_AAM.pdf,
24,A Noninvasive Blood Glucose Monitoring System Based on Smartphone PPG Signal Processing and Machine Learning,16,11,7209-7218,"Zhang Gaobo,Mei Zhen,Zhang Yuan,Ma Xuesheng,Lo Benny,Chen Dongyi,Zhang Yuanting","Zhang GB,Mei Z,Zhang Y,Ma XS,Lo B,Chen DY,Zhang YT",Zhang Y,10.1109/TII.2020.2975222,Southwest University - China,"Blood glucose level needs to be monitored regularly to manage the health condition of hyperglycemic patients. The current glucose measurement approaches still rely on invasive techniques which are uncomfortable and raise the risk of infection. To facilitate daily care at home, in this article, we propose an intelligent, noninvasive blood glucose monitoring system which can differentiate a user's blood glucose level into normal, borderline, and warning based on smartphone photoplethysmography (PPG) signals. The main implementation processes of the proposed system include 1) a novel algorithm for acquiring PPG signals using only smartphone camera videos; 2) a fitting-based sliding window algorithm to remove varying degrees of baseline drifts and segment the signal into single periods; 3) extracting characteristic features from the Gaussian functions by comparing PPG signals at different blood glucose levels; 4) categorizing the valid samples into three glucose levels by applying machine learning algorithms. Our proposed system was evaluated on a data set of 80 subjects. Experimental results demonstrate that the system can separate valid signals from invalid ones at an accuracy of 97.54% and the overall accuracy of estimating the blood glucose levels reaches 81.49%. The proposed system provides a reference for the introduction of noninvasive blood glucose technology into daily or clinical applications. This article also indicates that smartphone-based PPG signals have great potential to assess an individual's blood glucose level.","Daily care,gaussian fitting,noninvasive blood glucose monitoring,smartphone photoplethysmography (PPG) signal",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Computer Science,Engineering",,9.768,"PHOTOPLETHYSMOGRAPH,PRESSURE,WRIST",IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS,http://spiral.imperial.ac.uk/bitstream/10044/1/88074/2/TII-19-4216%20V2_BL.pdf,
25,Stochastic Modeling Based Nonlinear Bayesian Filtering for Photoplethysmography Denoising in Wearable Devices,16,11,7219-7230,"Xu Ke,Jiang Xinyu,Lin Sijie,Dai Chenyun,Chen Wei","Xu K,Jiang XY,Lin SJ,Dai CY,Chen W",Chen W,10.1109/TII.2020.2988097,Fudan University,"Photoplethysmography (PPG) has shown its great potential for noninvasive health monitoring, but its application in wearable devices is largely impeded due to its extreme vulnerability to motion artifacts. In this article, we proposed a new stochastic modeling based nonlinear Bayesian filtering framework for the recovery of corrupted PPG waveform under strenuous physical exercise in wearable health-monitoring devices. A deep recurrent neural network was first recruited for accurate cardiac-period segmentation of corrupted PPG signals. Then, a stochastic model was applied to extract waveform details from clean PPG pulses, and was further derived into a system-state space. Following this was an extended Kalman filter using the state-space structured by modeling. The covariance of measurement noise was estimated by motion-related information to adjust it into the real physical environment adaptively. Comparison results with state-of-the-art methods on a wearable-device-based 48-subject data set showed the outstanding performance of the proposed denoising framework, with period-segmentation sensitivity and precision higher than 99.1%, instantaneous heart rate (HR) error lower than 2 beats/min, average HR error down to 1.14 beats/min, and recovery accuracy of waveform details significantly improved (p < 0.05). This framework is the first PPG denoising strategy that introduces waveform-modeling methods to ensure detail recovery, and a great example of algorithm fusion between stochastic signal processing and emerging deep learning methods for time-sequential biomedical signal processing.","Stochastic processes,Filtering,Heart rate,Biomedical monitoring,Feature extraction,Motion artifacts,Recurrent neural networks,Deep recurrent neural network (RNN),extended Kalman filter,motion artifacts (MA),photoplethysmography (PPG),stochastic modeling,wearable devices",Article,"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC, 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","Automation & Control Systems,Computer Science,Engineering",,9.768,"HEART-RATE,ESTIMATION,MOTION,ARTIFACTS,NEURAL-NETWORK,PPG,SIGNALS,CLASSIFICATION,REDUCTION,FRAMEWORK",IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS,,
26,Mesoscale informed parameter estimation through machine learning: A case-study in fracture modeling,420,,,"Panda Nishant,Osthus Dave,Srinivasan Gowri,O'Malley Daniel,Chau Viet,Oyen Diane,Godinez Humberto","Panda N,Osthus D,Srinivasan G,O'Malley D,Chau V,Oyen D,Godinez H",Panda N,10.1016/j.jcp.2020.109719,United States Department of Energy (DOE),"Scale bridging is a critical need in computational sciences, where the modeling community has developed accurate physics models from first principles, of processes at lower length and time scales that influence the behavior at the higher scales of interest. However, it is not computationally feasible to incorporate all of the lower length scale physics directly into upscaled models. This is an area where machine learning has shown promise in building emulators of the lower length scale models, which incur a mere fraction of the computational cost of the original higher fidelity models. We demonstrate the use of machine learning using an example in materials science estimating continuum scale parameters by emulating, with uncertainties, complicated mesoscale physics. We describe a new framework to emulate the fine scale physics, especially in the presence of microstructures, using machine learning, and showcase its usefulness by providing an example from modeling fracture propagation. Our approach can be thought of as a data-driven dimension reduction technique that yields probabilistic emulators. Our results show well-calibrated predictions for the quantities of interests in a low-strain simulation of fracture propagation at the mesoscale level. On average, we achieve similar to 10% relative errors on time-varying quantities like total damage and maximum stresses. Successfully replicating mesoscale scale physics within the continuum models is a crucial step towards predictive capability in multi-scale problems. Published by Elsevier Inc.","Uncertainty quantification,Reduced order model,Machine learning,Data driven upscaling,Probabilistic emulator,Fracture propagation",Article,"ACADEMIC PRESS INC ELSEVIER SCIENCE, 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA","Computer Science,Physics",,3.81,,JOURNAL OF COMPUTATIONAL PHYSICS,https://www.osti.gov/biblio/1645087,
27,A combined machine learning and density functional theory study of binary Ti-Nb and Ti-Zr alloys: Stability and Young's modulus,184,,,"Xiong Sangqi,Li Xin,Wu Xiangwei,Yu Jin,Gorbatov Oleg I,Di Marco Igor,Kent Paul R. C.,Sun Weiwei","Xiong SQ,Li X,Wu XW,Yu J,Gorbatov OI,Di Marco I,Kent PRC,Sun WW",Li X; Sun WW,10.1016/j.commatsci.2020.109830,Southeast University - China,"The multicomponent Ti alloys, specifically the fl-phase, have experienced a strong growth over the last decades, due to their outstanding properties of ultra-high strength and low Young's modulus. These properties play a significant role in many aerospace and biomedical applications. Selection and optimization of multicomponent alloys is challenging due to the vast chemical and compositional space. Here we investigate the use of machine learning techniques informed by density functional calculations to guide the selection of Nband Zr-based Ti binary alloys. From the cubic structures obtained from high throughput calculations and literature, we identify several structures with Young's moduli below 40 GPa. The multivariant decision tree methods provide efficient surrogate models to identify structure variables have high influences on the energetic stability and Young's modulus. We implement a workflow of incorporating DFT provided results and machine learning method to explore the chemical and composition space of other binary and multicomponent alloys, to eventually accelerate the material design via taking advantages of identified key variables.","Combinatorial materials science,Density functional theory,High-throughput and data mining,Energetic stability and Young 's modulus",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"TOTAL-ENERGY,CALCULATIONS,PHASE-STABILITY,MARTENSITIC-TRANSFORMATION,ELECTRONIC-STRUCTURE,ELASTIC,PROPERTIES,X,ALLOYS,1ST-PRINCIPLES,APPROXIMATION,PARAMETERS,OXYGEN",COMPUTATIONAL MATERIALS SCIENCE,https://www.sciencedirect.com/science/article/am/pii/S0927025620303219,
28,Reconstruction of 3D Microstructures from 2D Images via Transfer Learning,128,,,Bostanabad Ramin,Bostanabad R,Bostanabad R,10.1016/j.cad.2020.102906,University of California System,"Computational analysis, modeling, and prediction of many phenomena in materials require a three-dimensional (3D) microstructure sample that embodies the salient features of the material system under study. Since acquiring 3D microstructural images is expensive and time-consuming, an alternative approach is to extrapolate a 2D image (aka exemplar) into a virtual 3D sample and thereafter use the 3D image in the analyses and design. In this paper, we introduce an efficient and novel approach based on transfer learning to accomplish this extrapolation-based reconstruction for a wide range of microstructures including alloys, porous media, and polycrystalline. We cast the reconstruction task as an optimization problem where a random 3D image is iteratively refined to match its microstructural features to those of the exemplar. VGG19, a pre-trained deep convolutional neural network, constitutes the backbone of this optimization where it is used to obtain the microstructural features and construct the objective function. By augmenting the architecture of VGG19 with a permutation operator, we enable it to take 3D images as inputs and generate a collection of 2D features that approximate an underlying 3D feature map. We demonstrate the applications of our approach with nine examples on various microstructure samples and image types (grayscale, binary, and RGB). As measured by independent statistical metrics, our approach ensures the statistical equivalency between the 3D reconstructed samples and the corresponding 2D exemplar quite well. (C) 2020 Elsevier Ltd. All rights reserved.","Reconstruction,Microstructure,Statistical equivalency,Transfer learning,Correlation functions",Article,"ELSEVIER SCI LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND",Computer Science,,4.032,"SPATIAL,CORRELATION-FUNCTIONS,SIMULATED,ANNEALING,RECONSTRUCTION,HETEROGENEOUS,MATERIALS,PREDICTING,PROPERTIES,POROUS-MEDIA,3-DIMENSIONAL,RECONSTRUCTION,THERMAL-CONDUCTIVITY,UNIT,CELLS,QUANTIFICATION,DISTRIBUTIONS",COMPUTER-AIDED DESIGN,,
29,Robust activation energy predictions of solute diffusion from machine learning method,184,,,"He Kang-ni,Kong Xiang-shan,Liu C. S.","He KN,Kong XS,Liu CS",Kong XS; Liu CS,10.1016/j.commatsci.2020.109948,Chinese Academy of Sciences,"We evaluate the performance of a popular machine learning (ML) method support vector machine (SVM) for modeling and predicting the solute diffusion activation energies in fcc, bcc, and hcp metallic hosts. The diffusion activation energies of 408 host-solute systems from ab-initio calculations are made as our dataset. We obtain an optimal set of features by combining prior physics knowledge and combination ranking based on the LeaveGroup-Out (LOG) cross-validation (CV) method, including solute migration barrier, atomic volume of host, elastic modulus of host, melting point of host, unpaired d electrons of host, and the corresponding parameters of solute. We present the results of LOG/10-fold/5-fold/3-fold CV, with the corresponding root mean squared error (RMSE) of 0.128/0.106 +/- 0.014/0.107 +/- 0.004/0.110 +/- 0.005 eV. SVM gives an about 0.1 eV errors when extrapolating to new host-solute systems for main hosts. We further make predictions on the activation energies of thousands of new systems with quite small computational cost. Our work demonstrates that the ML method is a promising method to accelerate materials science researches.","Diffusion,Activation energy,Machine learning,Support vector machine",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"TRANSITION-METAL,SOLUTES,IMPURITY,DIFFUSIVITIES,STAINLESS-STEEL,FCC,1ST-PRINCIPLES,COEFFICIENTS,DATABASE",COMPUTATIONAL MATERIALS SCIENCE,,
30,Importance of structural deformation features in the prediction of hybrid perovskite bandgaps,184,,,"Park Heesoo,Mall Raghvendra,Ali Adnan,Sanvito Stefano,Bensmail Halima,El-Mellouhi Fedwa","Park H,Mall R,Ali A,Sanvito S,Bensmail H,El-Mellouhi F",Park H; El-Mellouhi F,10.1016/j.commatsci.2020.109858,Hamad Bin Khalifa University-Qatar,"Given the surging growth of artificial-intelligence-inspired computational methods in materials science, experimental laboratories around the globe have become open to adopting data-driven approaches for materials discovery. The field witnesses emerging machine-learning models trained over databases, of which data are collected from high-throughput experimentation or first-principles calculation. Here, we address the impediment of constructing a highly accurate predictor for perovskite bandgap when the inorganic network undergoes the deformation. The predictor is trained on a dataset of first-principles calculations of pure and mixed-cation hybrid perovskites. We investigate the impact of the inclusion/exclusion of structural deformation features by training the model carefully. A high level of accuracy could be achieved with a scrupulous investigation of the input features. Our analysis emphasizes how important the feature selection is for the construction of the predictive model as we challenge the robustness of our machine learning predictor in a lab validation setup.","Machine Learning,Hybrid Perovskite,Octahedral deformation,Mixed-Cation,Bandgap",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"GENERALIZED,GRADIENT,APPROXIMATION,ORGANIC-INORGANIC,PEROVSKITES,TOTAL-ENERGY,CALCULATIONS,EFFICIENT,SEMICONDUCTORS",COMPUTATIONAL MATERIALS SCIENCE,,
31,Decision tree driven construction of rate constant models: Identifying the ,184,,,"Sawarkar Sandip,Chatterjee Abhijit","Sawarkar S,Chatterjee A",Chatterjee A,10.1016/j.commatsci.2020.109876,Indian Institute of Technology System (IIT System),"The local chemical environment is known to influence the rate constants of thermally activated atomic-scale processes in materials. In situations where rate constants vary over several orders of magnitude, dynamical materials simulations often require accurate rate constant models that can rapidly predict the rate for vast number of environments. Deriving rate constant models by fitting to a database of barriers can be particularly challenging when several environment atoms are believed to affect the rate. Previously, artificial neural net-works (ANN) and cluster expansion models (CEM) have been employed as rate constant models. We demonstrate that a decision tree (DT) can complement training of such models by providing useful inputs. DTs can be used to (i) determine the relevant chemical environment, (ii) estimate the accuracy expected from CEM/ANN, (iii) identify cluster sizes required in CEM or size of the input layer in ANN so that the CEM/ANN model can be trained in a single step, and (iv) determine the minimum amount of data required for accurate training. Using this strategy, we construct for the first time CEM and ANN models for the exchange move (surface diffusion of metal on metal) that are both compact and accurate. The use of DT has enabled inclusion of large clusters, as big as 11 atom clusters in the CEM. Our strategy paves way for coupling DT and CEM/ANN for building compu-tationally inexpensive rate constant models.","Decision trees,Cluster expansion models,Neural networks,Activated process,Molecular simulations,Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"CLUSTER-EXPANSION,MODEL,NANOPARTICLES,SCALE,AU,AL",COMPUTATIONAL MATERIALS SCIENCE,,
32,Rapid evaluation method for anisotropic growth of WS2 monolayers by combining machine learning algorithms and kinetic Monte Carlo simulation data,184,,,"Xia Yuanfeng,Wu Lixiang,Wang Gaofeng","Xia YF,Wu LX,Wang GF",Wu LX; Wang GF,10.1016/j.commatsci.2020.109922,Hangzhou Dianzi University,"The growth of two-dimensional (2D) materials such as transition metal dichalcogenide (TMDC) monolayers is challenging and their growth mechanism has not been fully understood. It requires a large number of growth experiments and simulation calculations to reveal the growth mechanism. Also, a computational framework for combining the simulation results and the experimental results is essential. To speed up this time-consuming process for understanding the growth mechanism, a preliminary framework based on machine learning is herein proposed to analyze the simulation data and predict the growth trend. Specifically, the framework can be used for studying the anisotropic growth of tungsten disulfide (WS2) monolayers based on the data of kinetic Monte Carlo (kMC) simulations. Both an isotropic model with 91% accuracy and an anisotropic model with 90% accuracy are obtained. Moreover, both an undergrowth model with 98% accuracy and an overgrowth model with 99% accuracy are also obtained. This proposed framework can take both the experimental data and the simulation data as a single input data set, much speeding up the study of the growth mechanism.","Transition metal dichalcogenide (TMDC) monolayers,Tungsten disul fide (WS2),kinetic Monte Carlo (kMC),Machine learning",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Materials Science,,3.222,"EPITAXIAL-GROWTH,INTELLIGENT,PREDICTION",COMPUTATIONAL MATERIALS SCIENCE,,
33,Predicting field production rates for waterflooding using a machine learning-based proxy model,194,,,"Zhong Zhi,Sun Alexander Y.,Wang Yanyong,Ren Bo","Zhong Z,Sun AY,Wang YY,Ren B",Zhong Z; Sun AY,10.1016/j.petrol.2020.107574,University of Texas System,"Waterflooding, during which water is injected in the reservoir to increase pressure and therefore boost oil production, is extensively used as a secondary oil recovery technology. Tracking the extent and efficacy of waterflooding (i.e., fluid distributions) is a primary task of reservoir engineers and is traditionally achieved by running full reservoir models. In this work, we design and implement a proxy model using a conditional deep convolutional generative neural network (cDC-GAN), which can be used to quickly calculate the dynamic fluid distribution of a heterogeneous reservoir under waterflooding. Zero-sum game theory is the basis for the cDC-GAN, which includes a pair of generative discriminative models. The generative model tries to learn the relationship between input and output and makes the generated output as close as possible to the training data, while the discriminative model tries to distinguish the fake output and the real data used for training, such that the cDC-GAN learns the real data distribution at the end. In our cDC-GAN formulation, the reservoir properties (permeability distribution in this research) and forecast time information are treated as input, and water saturation is the desired output. The reservoir fluid production rate can be calculated based on the material balance principle. The most significant contribution of this work resides in training a cDC-GAN proxy model to accurately predict fluid saturation. A cDC-GAN has several advantages over the traditional full-model based workflow. First, the model parameters estimated from history matching help to improve reservoir characterization. Second, this proposed proxy model can predict the water and oil saturation distributions simultaneously, which can be used to calculate the water and oil flow rates. Third, this proposed proxy model can be used for waterflooding optimization and uncertainty analysis with far less computational effort than with the traditional method, which uses a reservoir simulator.","Machine learning,Conditional deep convolutional generative adversarial neural network,Data-driven proxy model,Waterflooding,Field production rate",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS","Energy & Fuels,Engineering",,4.376,"RESPONSE-SURFACE,METHODOLOGY,ALTERNATING-GAS-INJECTION,RELATIVE,PERMEABILITY,OIL-FIELD,WORK,FLOW,OPTIMIZATION,PRESSURE,DESIGN",JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING,,
34,Localization of epileptic seizure focus by computerized analysis of fMRI recordings.,7,1,13,",,,,","Hekmati Rasoul,Azencott Robert,Zhang Wei,Chu Zili D,Paldino Michael J",,10.1186/s40708-020-00114-0,,,Deep learning; Epilepsy; Mutual information; Seizure focus; Time series; fMRI,Journal Article,,,,,,,,
35,A novel approach for early prediction of sudden cardiac death (SCD) using hybrid deep learning,80,5,8063-8090,"Kaspal Rabin,Alsadoon Abeer,Prasad P. W. C.,Al-Saiyd Nedhal A.,Nguyen Tran Quoc Vinh,Pham Duong Thu Hang","Kaspal R,Alsadoon A,Prasad PWC,Al-Saiyd NA,Nguyen TQV,Pham DTH",Alsadoon A,10.1007/s11042-020-10150-x,Charles Sturt University,"Importance of early prediction of Sudden Cardiac Deaths (SCD) has been rising as a large percentage of mortality of patients with cardiovascular diseases. Various deep learning methodologies has been developed to predict the onset of SCDs, Their key limitation is either classification accuracy or the processing time. This research tries to improve the classification accuracy and decrease the processing time. A Convolutional Neural Network (CNN) is combined with a Recurrence Complex Network (RCN) along with Dropout Regularization to enhance the accuracy of SCD classification. Initially, the synchronization feature of individual heartbeat of the electrocardiogram (ECG) signal is constructed by RCN. The recurrence matrix from the (RCN) will generate Eigen values. Then, CNN will be employed to extract features and detect SCD by analysing the Eigen values. Finally, the performance of the classification is improved by the developing a voting algorithm for the SCD detection. MIT-BIH SCD database is used to evaluate the proposed system. The average accuracy and processing time for MIT-BIH Arrhythmia dataset is 93.24% and 21 epochs, MIT-BIH SCD Holter dataset is 90.60% and 11.5 epochs, and Apnoea-ECG dataset is 92.13% and 13.5 epochs. The average processing time has also been reduced to 20.77 milliseconds against the current processing time of 32.96 milliseconds. The proposed system enhances the classification accuracy and the processing time of the prediction system. The study eradicates the issue of gradient saturation during the training of the CNN by proposing a new activation function as well as eliminates the risk of overfitting by implementing dropout regularization in CNN.","Sudden cardiac death,Convolution neural network,Recurrence complex network deep learning,Dropout regularization,Electrocardiogram (ECG) signals",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,"FEATURE-SELECTION,NEURAL-NETWORK,CLASSIFICATION,STRATEGY",MULTIMEDIA TOOLS AND APPLICATIONS,,
36,Human Falling Detection Algorithm Based on Multisensor Data Fusion with SVM,2020,,,"Pan Daohua,Liu Hongwei,Qu Dongming,Zhang Zhan","Pan DH,Liu HW,Qu DM,Zhang Z",Pan DH; Liu HW,10.1155/2020/8826088,Harbin Institute of Technology,"Falling is a common phenomenon in the life of the elderly, and it is also one of the 10 main causes of serious health injuries and death of the elderly. In order to prevent falling of the elderly, a real-time fall prediction system is installed on the wearable intelligent device, which can timely trigger the alarm and reduce the accidental injury caused by falls. At present, most algorithms based on single-sensor data cannot accurately describe the fall state, while the fall detection algorithm based on multisensor data integration can improve the sensitivity and specificity of prediction. In this study, we design a fall detection system based on multisensor data fusion and analyze the four stages of falls using the data of 100 volunteers simulating falls and daily activities. In this paper, data fusion method is used to extract three characteristic parameters representing human body acceleration and posture change, and the effectiveness of the multisensor data fusion algorithm is verified. The sensitivity is 96.67%, and the specificity is 97%. It is found that the recognition rate is the highest when the training set contains the largest number of samples in the training set. Therefore, after training the model based on a large amount of effective data, its recognition ability can be improved, and the prevention of fall possibility will gradually increase. In order to compare the applicability of random forest and support vector machine (SVM) in the development of wearable intelligent devices, two fall posture recognition models were established, respectively, and the training time and recognition time of the models are compared. The results show that SVM is more suitable for the development of wearable intelligent devices.",MACHINE,Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Computer Science,Telecommunications",,1.537,MACHINE,MOBILE INFORMATION SYSTEMS,https://downloads.hindawi.com/journals/misy/2020/8826088.pdf,
37,Unsupervised learning for magnetization transfer contrast MR fingerprinting: Application to CEST and nuclear Overhauser enhancement imaging,85,4,2040-2054,"Kang Beomgu,Kim Byungjai,Schar Michael,Park HyunWook,Heo Hye-Young","Kang B,Kim B,Schar M,Park H,Heo HY",Heo HY,10.1002/mrm.28573,Johns Hopkins University,"Purpose: To develop a fast, quantitative 3D magnetization transfer contrast (MTC) framework based on an unsupervised learning scheme, which will provide baseline reference signals for CEST and nuclear Overhauser enhancement imaging.
Methods: Pseudo-randomized RF saturation parameters and relaxation delay times were applied in an MR fingerprinting framework to generate transient-state signal evolutions for different MTC parameters. Prospectively compressed sensing-accelerated (four-fold) MR fingerprinting images were acquired from 6 healthy volunteers at 3 T. A convolutional neural network framework in an unsupervised fashion was designed to solve an inverse problem of a two-pool MTC Bloch equation, and was compared with a conventional Bloch equation-based fitting approach. The MTC images synthesized by the convolutional neural network architecture were used for amide proton transfer and nuclear Overhauser enhancement imaging as a reference baseline image.
Results: The fully unsupervised learning scheme incorporated with the two-pool exchange model learned a set of unique features that can describe the MTC-MR fingerprinting input, and allowed only small amounts of unlabeled data for training. The MTC parameter values estimated by the unsupervised learning method were in excellent agreement with values estimated by the conventional Bloch fitting approach, but dramatically reduced computation time by similar to 1000-fold.
Conclusion: Given the considerable time efficiency compared to conventional Bloch fitting, unsupervised learning-based MTC-MR fingerprinting could be a powerful tool for quantitative MTC and CEST/nuclear Overhauser enhancement imaging.","APT,CEST,deep learning,MR fingerprinting,MTC,unsupervised learning",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"SATURATION-TRANSFER,CEST,IN-VIVO,WHITE-MATTER,HUMAN,BRAIN,EXCHANGE,RELAXATION,AGENTS,WATER,TIME,T-1",MAGNETIC RESONANCE IN MEDICINE,,
38,Predicting vaginal birth after previous cesarean: Using machine-learning models and a population-based cohort in Sweden,100,3,513-520,"Lindblad Wollmann Charlotte,Hart Kyle D.,Liu Can,Caughey Aaron B.,Stephansson Olof,Snowden Jonathan M.","Wollmann CL,Hart KD,Liu C,Caughey AB,Stephansson O,Snowden JM",Wollmann CL,10.1111/aogs.14020,Karolinska Institutet,"Introduction Predicting a woman's probability of vaginal birth after cesarean could facilitate the antenatal decision-making process. Having a previous vaginal birth strongly predicts vaginal birth after cesarean. Delivery outcome in women with only a cesarean delivery is more unpredictable. Therefore, to better predict vaginal birth in women with only one prior cesarean delivery and no vaginal deliveries would greatly benefit clinical practice and fill a key evidence gap in research. Our aim was to predict vaginal birth in women with one prior cesarean and no vaginal deliveries using machine-learning methods, and compare with a US prediction model and its further developed model for a Swedish setting.
Material and methods A population-based cohort study with a cohort of 3116 women with only one prior birth, a cesarean, and a subsequent trial of labor during 2008-2014 in the Stockholm-Gotland region, Sweden. Three machine-learning methods (conditional inference tree, conditional random forest and lasso binary regression) were used to predict vaginal birth after cesarean among women with one previous birth. Performance of the new models was compared with two existing models developed by Grobman et al (USA) and Fagerberg et al (Sweden). Our main outcome measures were area under the receiver-operating curve (AUROC), overall accuracy, sensitivity and specificity of prediction of vaginal birth after previous cesarean delivery.
Results The AUROC ranged from 0.61 to 0.69 for all models, sensitivity was above 91% and specificity below 22%. The majority of women with an unplanned repeat cesarean had a predicted probability of vaginal birth after cesarean >60%.
Conclusions Both classical regression models and machine-learning models had a high sensitivity in predicting vaginal birth after cesarean in women without a previous vaginal delivery. The majority of women with an unplanned repeat cesarean delivery were predicted to succeed with a vaginal birth (ie specificity was low). Additional covariates combined with machine-learning techniques did not outperform classical regression models in this study.","Cesarean delivery,machine&#8208,learning,prediction,random forest,trial of labor,vaginal birth after cesarean",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Obstetrics & Gynecology,,3.576,"COST-EFFECTIVENESS,LABOR,TRIAL,DELIVERY,CLASSIFICATION,SUCCESS",ACTA OBSTETRICIA ET GYNECOLOGICA SCANDINAVICA,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8048592,
39,Early detection of breast cancer using hybrid of series network and VGG-16,80,5,7853-7886,"Jahangeer Gul Shaira Banu,Rajkumar T. Dhiliphan","Jahangeer GSB,Rajkumar TD",Jahangeer GSB,10.1007/s11042-020-09914-2,Kalasalingam Academy of Research & Education,"Breast cancer is nowadays becoming a serious problem and acts as a main reason for death of women around the world. Hence various devices are being utilized for the detection of breast cancer at an earlier stage and diagnosing it in an earlier stage might even results in complete cure of the disease. Among the wide range of devices available, mammogram is one of the commonly employed and most effective approaches involved in the detection of breast cancer. It records the affected area in the form of mammogram images and these images are processed through image processing techniques for the detection of cancer affected regions. In this paper, novelties have given in all the image processing aspects such as filtering, segmentation, feature extraction and classification. The salt and pepper noises in the mammogram images are eliminated by the usage of novel decision based partial median filter. Then the filtered images are segmented based utilizing a novel technique which is formed on integrating the deep learning techniques of VGG-16 and series network. Features of the segmented images have extracted through BAT-SURF feature extraction, where the orientation of the interest points are extracted using Bat optimization algorithm along with SURF (i.e.) Speeded up Robust Features. It extract most important key points from SURF features and then the extracted image has classified by using the novel Gradient descent decision tree classifier in which a stable learning path provided for easy convergence. Then the performance of the proposed system has analyzed based on the performance metrics like accuracy, specificity, sensitivity, recall, precision, Jaccard coefficient, F score and missed classification. Based on the results obtained, the conclusion of the proposed work has attained enhanced results on comparing with other state of the art approaches. The accuracy value of the proposed hybrid VGG-16 and series network segmentation technique determined as 96.45 and similarly the accuracy value of the proposed Gradient Descent Decision Tree Classification technique has value shows 95.15.","Breast Cancer,Mammogram image,Decision based partial median filter,VGG-16 and series network,BAT-SURF feature extraction and gradient descent decision tree classifier",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,2.517,SEGMENTATION,MULTIMEDIA TOOLS AND APPLICATIONS,,
40,Ground Metric Learning on Graphs,63,1,89-107,"Heitz Matthieu,Bonneel Nicolas,Coeurjolly David,Cuturi Marco,Peyre Gabriel","Heitz M,Bonneel N,Coeurjolly D,Cuturi M,Peyre G",Heitz M; Coeurjolly D,10.1007/s10851-020-00996-z,Centre National de la Recherche Scientifique (CNRS),"Optimal transport (OT) distances between probability distributions are parameterized by the ground metric they use between observations. Their relevance for real-life applications strongly hinges on whether that ground metric parameter is suitably chosen. The challenge of selecting it adaptively and algorithmically from prior knowledge, the so-called ground metric learning (GML) problem, has therefore appeared in various settings. In this paper, we consider the GML problem when the learned metric is constrained to be a geodesic distance on a graph that supports the measures of interest. This imposes a rich structure for candidate metrics, but also enables far more efficient learning procedures when compared to a direct optimization over the space of all metric matrices. We use this setting to tackle an inverse problem stemming from the observation of a density evolving with time; we seek a graph ground metric such that the OT interpolation between the starting and ending densities that result from that ground metric agrees with the observed evolution. This OT dynamic framework is relevant to model natural phenomena exhibiting displacements of mass, such as the evolution of the color palette induced by the modification of lighting and materials.","Optimal transport,Metric learning,Displacement interpolation",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Mathematics",,1.987,"EARTH,MOVERS,DISTANCE,OPTIMAL,TRANSPORT",JOURNAL OF MATHEMATICAL IMAGING AND VISION,https://hal.archives-ouvertes.fr/hal-02989081/document,
41,Deep learning from ,3,1,,"Li Zhongwen,Guo Chong,Nie Danyao,Lin Duoru,Zhu Yi,Chen Chuan,Zhao Lanqin,Wu Xiaohang,Dongye Meimei,Xu Fabao","Li ZW,Guo C,Nie DY,Lin DR,Zhu Y,Chen C,Zhao LQ,Wu XH,Dongye MM,Xu FB",Lin HT,10.1038/s41746-020-00350-y,Sun Yat Sen University,"Artificial intelligence (AI) based on deep learning has shown excellent diagnostic performance in detecting various diseases with good-quality clinical images. Recently, AI diagnostic systems developed from ultra-widefield fundus (UWF) images have become popular standard-of-care tools in screening for ocular fundus diseases. However, in real-world settings, these systems must base their diagnoses on images with uncontrolled quality (""passive feeding""), leading to uncertainty about their performance. Here, using 40,562 UWF images, we develop a deep learning-based image filtering system (DLIFS) for detecting and filtering out poor-quality images in an automated fashion such that only good-quality images are transferred to the subsequent AI diagnostic system (""selective eating""). In three independent datasets from different clinical institutions, the DLIFS performed well with sensitivities of 96.9%, 95.6% and 96.6%, and specificities of 96.6%, 97.9% and 98.8%, respectively. Furthermore, we show that the application of our DLIFS significantly improves the performance of established AI diagnostic systems in real-world settings. Our work demonstrates that ""selective eating"" of real-world data is necessary and needs to be considered in the development of image-based AI systems.","DIABETIC-RETINOPATHY,SYSTEM,VALIDATION",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Health Care Sciences & Services,Medical Informatics",,11.665,"DIABETIC-RETINOPATHY,SYSTEM,VALIDATION",NPJ DIGITAL MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7603327,
42,Design of Alumina Reinforced Aluminium Alloy Composites with Improved Tribo-Mechanical Properties: A Machine Learning Approach,73,12,3059-3069,"Banerjee Titov,Dey Swati,Sekhar Aluru Praveen,Datta Shubhabrata,Das Debdulal","Banerjee T,Dey S,Sekhar AP,Datta S,Das D",Datta S,10.1007/s12666-020-02108-2,SRM Institute of Science & Technology Chennai,"Artificial intelligence approach for data-driven design is employed to design an alumina reinforced aluminium matrix composite (AMC) with improved tribo-mechanical properties. Machine learning tool, viz. Artificial neural network (ANN), is used as a tool to create a set of models describing the properties of the AMC. The database required for the ANN modelling was extracted from published literature. The objective functions to search the optimum combinations of composition, size and morphological properties were provided from those ANN models. Since the objectives are conflicting in nature, a multi-objective optimization is introduced using genetic algorithm as a tool and the achieved Pareto solutions are used for designing the composite with tailored properties.","Metal matrix composite,Aluminium,Alumina,Mechanical behavior,Wear,Artificial neural network,Genetic algorithm,Multi-objective optimization,Pareto front",Article,"SPRINGER INDIA, 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001, INDIA",Metallurgy & Metallurgical Engineering,,1.349,"ARTIFICIAL,NEURAL-NETWORKS,WEAR,ANN,RESISTANCE,STEELS",TRANSACTIONS OF THE INDIAN INSTITUTE OF METALS,,
43,Deep-learning-based direct inversion for material decomposition,47,12,6294-6309,"Gong Hao,Tao Shengzhen,Rajendran Kishore,Zhou Wei,McCollough Cynthia H.,Leng Shuai","Gong H,Tao SZ,Rajendran K,Zhou W,McCollough CH,Leng S",Leng S,10.1002/mp.14523,Mayo Clinic,"Purpose To develop a convolutional neural network (CNN) that can directly estimate material density distribution from multi-energy computed tomography (CT) images without performing conventional material decomposition.
Methods The proposed CNN (denoted as Incept-net) followed the general framework of encoder-decoder network, with an assumption that local image information was sufficient for modeling the nonlinear physical process of multi-energy CT. Incept-net was implemented with a customized loss function, including an in-house-designed image-gradient-correlation (IGC) regularizer to improve edge preservation. The network consisted of two types of customized multibranch modules exploiting multiscale feature representation to improve the robustness over local image noise and artifacts. Inserts with various densities of different materials [hydroxyapatite (HA), iodine, a blood-iodine mixture, and fat] were scanned using a research photon-counting detector (PCD) CT with two energy thresholds and multiple radiation dose levels. The network was trained using phantom image patches only, and tested with different-configurations of full field-of-view phantom and in vivo porcine images. Furthermore, the nominal mass densities of insert materials were used as the labels in CNN training, which potentially provided an implicit mass conservation constraint. The Incept-net performance was evaluated in terms of image noise, detail preservation, and quantitative accuracy. Its performance was also compared to common material decomposition algorithms including least-square-based material decomposition (LS-MD), total-variation regularized material decomposition (TV-MD), and U-net-based method.
Results Incept-net improved accuracy of the predicted mass density of basis materials compared with the U-net, TV-MD, and LS-MD: the mean absolute error (MAE) of iodine was 0.66, 1.0, 1.33, and 1.57 mgI/cc for Incept-net, U-net, TV-MD, and LS-MD, respectively, across all iodine-present inserts (2.0-24.0 mgI/cc). With the LS-MD as the baseline, Incept-net and U-net achieved comparable noise reduction (both around 95%), both higher than TV-MD (85%). The proposed IGC regularizer effectively helped both Incept-net and U-net to reduce image artifact. Incept-net closely conserved the total mass densities (i.e., mass conservation constraint) in porcine images, which heuristically validated the quantitative accuracy of its outputs in anatomical background. In general, Incept-net performance was less dependent on radiation dose levels than the two conventional methods; with approximately 40% less parameters, the Incept-net achieved relatively improved performance than the comparator U-net, indicating that performance gain by Incept-net was not achieved by simply increasing network learning capacity.
Conclusion Incept-net demonstrated superior qualitative image appearance, quantitative accuracy, and lower noise than the conventional methods and less sensitive to dose change. Incept-net generalized and performed well with unseen image structures and different material mass densities. This study provided preliminary evidence that the proposed CNN may be used to improve the material decomposition quality in multi-energy CT.","convolutional neural network,deep learning,multi&#8208,energy CT,photon&#8208,counting detector CT",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"DUAL-ENERGY,CT,IODINE,QUANTIFICATION,MULTIMATERIAL,DECOMPOSITION,NEURAL-NETWORK,RECONSTRUCTION,ATTENUATION,DIAGNOSIS,ACCURACY",MEDICAL PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7796910,
44,Patient-specific seizure detection method using nonlinear mode decomposition for long-term EEG signals,58,12,3075-3088,"Li Mingyang,Sun Xiaoying,Chen Wanzhong","Li MY,Sun XY,Chen WZ",Li MY,10.1007/s11517-020-02279-6,Jilin University,"The automated detection technique becomes the inexorable trend of medical development of the world. The objective of the work is to explore a feasible approach for patient-specific seizure detection in long-term electroencephalogram (EEG) recordings. For this purpose, a novel method based on nonlinear mode decomposition (NMD) has been proposed in this study. A sliding window is used on the multi-channel EEG, where four selected channels have been segmented into a series of successive short epochs with a 2-s duration. Then, the EEG is decomposed into a set of nonlinear modes (NMs) by the NMD algorithm and one type of statistical parameter named fractional central moment (FCM) is calculated over the first two NMs constituting the input feature vector to be fed to three common classifiers. The proposed features, when using K nearest neighbor (KNN), are able to detect seizures with high sensitivity values across all patients consistently. We have explored the ability of the FCM in NMD domain for classification of seizure and non-seizure EEG signals. Our approach has achieved the average sensitivity, specificity, and accuracy values as 98.40%, 99.10%, and 98.61%, respectively, over all the data groups on CHB-MIT database. The experimental results have indicated that the proposed method is not only quite reliable in diagnosing seizure with single type of feature yielding satisfied performance but also robust to variations of seizure types among patients. In this regard, it can be expected that our proposed method is endowed with promising prospects for the use of an expert software application in real-time automated seizure detection.
[GAPHICS].","Long-term EEG,Nonlinear mode decomposition,Fractional central moment,Seizure detection",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY","Computer Science,Engineering,Mathematical & Computational Biology,Medical Informatics",,2.61,"EPILEPTIC,SEIZURE,FEATURE-EXTRACTION,CLASSIFICATION,SELECTION,RESOURCE,POWER",MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING,,
45,Autonomously revealing hidden local structures in supercooled liquids,11,1,,"Boattini Emanuele,Marin-Aguilar Susana,Mitra Saheli,Foffi Giuseppe,Smallenburg Frank,Filion Laura","Boattini E,Marin-Aguilar S,Mitra S,Foffi G,Smallenburg F,Filion L",Filion L,10.1038/s41467-020-19286-8,Utrecht University,"Few questions in condensed matter science have proven as difficult to unravel as the interplay between structure and dynamics in supercooled liquids. To explore this link, much research has been devoted to pinpointing local structures and order parameters that correlate strongly with dynamics. Here we use an unsupervised machine learning algorithm to identify structural heterogeneities in three archetypical glass formers-without using any dynamical information. In each system, the unsupervised machine learning approach autonomously designs a purely structural order parameter within a single snapshot. Comparing the structural order parameter with the dynamics, we find strong correlations with the dynamical heterogeneities. Moreover, the structural characteristics linked to slow particles disappear further away from the glass transition. Our results demonstrate the power of machine learning techniques to detect structural patterns even in disordered systems, and provide a new way forward for unraveling the structural origins of the slow dynamics of glassy materials. The origin of dynamical slowdown in disordered materials remains elusive, especially in the absence of obvious structural changes. Boattini et al. use unsupervised machine learning to reveal correlations between structural and dynamical heterogeneity in supercooled liquids.","RELAXATION,DYNAMICS,ORDER",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,15.805,"RELAXATION,DYNAMICS,ORDER",NATURE COMMUNICATIONS,https://www.nature.com/articles/s41467-020-19286-8.pdf,
46,,,,,,,,,,,,,,,,,,,,
47,Unravelling stacking order in epitaxial bilayer MX(2)using 4D-STEM with unsupervised learning,31,44,,"Mehta Ankit Nalin,Gauquelin Nicolas,Nord Magnus,Orekhov Andrey,Bender Hugo,Cerbu Dorin,Verbeeck Johan,Vandervorst Wilfried","Mehta AN,Gauquelin N,Nord M,Orekhov A,Bender H,Cerbu D,Verbeeck J,Vandervorst W",Mehta AN,10.1088/1361-6528/aba5b6,IMEC,"Following an extensive investigation of various monolayer transition metal dichalcogenides (MX2), research interest has expanded to include multilayer systems. In bilayer MX2, the stacking order strongly impacts the local band structure as it dictates the local confinement and symmetry. Determination of stacking order in multilayer MX(2)domains usually relies on prior knowledge of in-plane orientations of constituent layers. This is only feasible in case of growth resulting in well-defined triangular domains and not useful in-case of closed layers with hexagonal or irregularly shaped islands. Stacking order can be discerned in the reciprocal space by measuring changes in diffraction peak intensities. Advances in detector technology allow fast acquisition of high-quality four-dimensional datasets which can later be processed to extract useful information such as thickness, orientation, twist and strain. Here, we use 4D scanning transmission electron microscopy combined with multislice diffraction simulations to unravel stacking order in epitaxially grown bilayer MoS2. Machine learning based data segmentation is employed to obtain useful statistics on grain orientation of monolayer and stacking in bilayer MoS2.","stacking order,bilayer MoS2,4D-STEM,DF-TEM",Article,"IOP PUBLISHING LTD, TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND","Science & Technology - Other Topics,Materials Science,Physics",,3.618,"BEAM,ELECTRON-DIFFRACTION",NANOTECHNOLOGY,https://lirias.kuleuven.be/bitstream/123456789/664703/2/Stacking_Manuscript_Revised.pdf,
48,A general-purpose machine-learning force field for bulk and nanostructured phosphorus,11,1,,"Deringer Volker L.,Caro Miguel A.,Csanyi Gabor","Deringer VL,Caro MA,Csanyi G",Deringer VL,10.1038/s41467-020-19168-z,University of Oxford,"Elemental phosphorus is attracting growing interest across fundamental and applied fields of research. However, atomistic simulations of phosphorus have remained an outstanding challenge. Here, we show that a universally applicable force field for phosphorus can be created by machine learning (ML) from a suitably chosen ensemble of quantum-mechanical results. Our model is fitted to density-functional theory plus many-body dispersion (DFT+MBD) data; its accuracy is demonstrated for the exfoliation of black and violet phosphorus (yielding monolayers of ""phosphorene"" and ""hittorfene""); its transferability is shown for the transition between the molecular and network liquid phases. An application to a phosphorene nanoribbon on an experimentally relevant length scale exemplifies the power of accurate and flexible ML-driven force fields for next-generation materials modelling. The methodology promises new insights into phosphorus as well as other structurally complex, e.g., layered solids that are relevant in diverse areas of chemistry, physics, and materials science. Atomistic simulations of phosphorus represent a challenge due to the element's highly diverse allotropic structures. Here the authors propose a general-purpose machine-learning force field for elemental phosphorus, which can describe a broad range of relevant bulk and nanostructured allotropes.","AMORPHOUS RED PHOSPHORUS,BLACK PHOSPHORUS,LIQUID-PHASE,CRYSTAL,SEMICONDUCTOR,EXFOLIATION,POLYMORPHS,ENERGY,RANGE,SHEET",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,15.805,"AMORPHOUS,RED,PHOSPHORUS,BLACK,PHOSPHORUS,LIQUID-PHASE,CRYSTAL,SEMICONDUCTOR,EXFOLIATION,POLYMORPHS,ENERGY,RANGE,SHEET",NATURE COMMUNICATIONS,https://www.nature.com/articles/s41467-020-19168-z.pdf,
49,RNA-Seq-Based Breast Cancer Subtypes Classification Using Machine Learning Approaches,2020,,,"Yu Zhezhou,Wang Zhuo,Yu Xiangchun,Zhang Zhe","Yu ZZ,Wang Z,Yu XC,Zhang Z",Yu XC,10.1155/2020/4737969,Jilin University,"Background. Breast invasive carcinoma (BRCA) is not a single disease as each subtype has a distinct morphology structure. Although several computational methods have been proposed to conduct breast cancer subtype identification, the specific interaction mechanisms of genes involved in the subtypes are still incomplete. To identify and explore the corresponding interaction mechanisms of genes for each subtype of breast cancer can impose an important impact on the personalized treatment for different patients. Methods. We integrate the biological importance of genes from the gene regulatory networks to the differential expression analysis and then obtain the weighted differentially expressed genes (weighted DEGs). A gene with a high weight means it regulates more target genes and thus holds more biological importance. Besides, we constructed gene coexpression networks for control and experiment groups, and the significantly differentially interacting structures encouraged us to design the corresponding Gene Ontology (GO) enrichment based on gene coexpression networks (GOEGCN). The GOEGCN considers the two-side distinction analysis between gene coexpression networks for control and experiment groups. The method allows us to study how the modulated coexpressed gene couples impact biological functions at a GO level. Results. We modeled the binary classification with weighted DEGs for each subtype. The binary classifier could make a good prediction for an unseen sample, and the experimental results validated the effectiveness of our proposed approaches. The novel enriched GO terms based on GOEGCN for control and experiment groups of each subtype explain the specific biological function changes according to the two-side distinction of coexpression network structures to some extent. Conclusion. The weighted DEGs contain biological importance derived from the gene regulatory network. Based on the weighted DEGs, five binary classifiers were learned and showed good performance concerning the ""Sensitivity,"" ""Specificity,"" ""Accuracy,"" ""F1,"" and ""AUC"" metrics. The GOEGCN with weighted DEGs for control and experiment groups presented a novel GO enrichment analysis results and the novel enriched GO terms would further unveil the changes of specific biological functions among all the BRCA subtypes to some extent. The R code in this research is available at https://github.com/yxchspring/GOEGCN_BRCA_Subtypes.","PATHWAY-BASED CLASSIFICATION,MOLECULAR PORTRAITS,GENES,COEXPRESSION,PROTEIN",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Mathematical & Computational Biology,Neurosciences & Neurology",,3.278,"PATHWAY-BASED,CLASSIFICATION,MOLECULAR,PORTRAITS,GENES,COEXPRESSION,PROTEIN",COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE,https://downloads.hindawi.com/journals/cin/2020/4737969.pdf,
50,Teaching Microbiome Analysis: From Design to Computation Through Inquiry,11,,,"Rosen Gail L.,Hammrich Penny","Rosen GL,Hammrich P",Rosen GL,10.3389/fmicb.2020.528051,Drexel University,"In this article, we present our three-class course sequence to educate students about microbiome analysis and metagenomics through experiential learning by taking them from inquiry to analysis of the microbiome: Molecular Ecology Lab, Bioinformatics, and Computational Microbiome Analysis. Students developed hypotheses, designed lab experiments, sequenced the DNA from microbiomes, learned basic python/R scripting, became proficient in at least one microbiome analysis software, and were able to analyze data generated from the microbiome experiments. While over 150 students (graduate and undergraduate) were impacted by the development of the series of courses, our assessment was only on undergraduate learning, where 45 students enrolled in at least one of the three courses and 4 students took all three. Students gained skills in bioinformatics through the courses, and several positive comments were received through surveys and private correspondence. Through a summative assessment, general trends show that students became more proficient in comparative genomic techniques and had positive attitudes toward their abilities to bridge biology and bioinformatics. While most students took individual or 2 of the courses, we show that pre- and post-surveys of these individual classes still showed progress toward learning objectives. It is expected that students trained will enter the workforce with skills needed to innovate in the biotechnology, health, and environmental industries. Students are trained to maximize impact and tackle real world problems in biology and medicine with their learned knowledge of data science and machine learning. The course materials for the new microbiome analysis course are available on Github: https://github.com/EESI/Comp_Metagenomics_resources.","bioinformatics,microbiome,metagenomics,microbial ecology,multidisciplinary education",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Microbiology,,6.32,"METAGENOMICS,BIOLOGY",FRONTIERS IN MICROBIOLOGY,https://www.frontiersin.org/articles/10.3389/fmicb.2020.528051/pdf,
51,Linking Machine Learning with Multiscale Numerics: Data-Driven Discovery of Homogenized Equations,72,12,4444-4457,"Arbabi Hassan,Bunder Judith E.,Samaey Giovanni,Roberts Anthony J.,Kevrekidis Ioannis G.","Arbabi H,Bunder JE,Samaey G,Roberts AJ,Kevrekidis IG",Arbabi H,10.1007/s11837-020-04399-8,Massachusetts Institute of Technology (MIT),"The data-driven discovery of partial differential equations (PDEs) consistent with spatiotemporal data is experiencing a rebirth in machine learning research. Training deep neural networks to learn such data-driven partial differential operators requires extensive spatiotemporal data. For learning coarse-scale PDEs from computational fine-scale simulation data, the training data collection process can be prohibitively expensive. We propose to transformatively facilitate this training data collection process by linking machine learning (here, neural networks) with modern multiscale scientific computation (here, equation-free numerics). These equation-free techniques operate over sparse collections of small, appropriately coupled, space-time subdomains (""patches""), parsimoniously producing the required macro-scale training data. Our illustrative example involves the discovery of effective homogenized equations in one and two dimensions, for problems with fine-scale material property variations. The approach holds promise towards making the discovery of accurate, macro-scale effective materials PDE models possible by efficiently summarizing the physics embodied in ""the best"" fine-scale simulation models available.","NEURAL-NETWORKS,DIFFERENTIAL-EQUATIONS,PATCH DYNAMICS,PHYSICS,TIME,IDENTIFICATION,BIFURCATION,FIDELITY,SYSTEMS,SCHEME",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Materials Science,Metallurgy & Metallurgical Engineering,Mineralogy,Mining & Mineral Processing",,2.989,"NEURAL-NETWORKS,DIFFERENTIAL-EQUATIONS,PATCH,DYNAMICS,PHYSICS,TIME,IDENTIFICATION,BIFURCATION,FIDELITY,SYSTEMS,SCHEME",JOM,http://arxiv.org/pdf/2008.11276,
52,Elucidating the Physicochemical Basis of the Glass Transition Temperature in Linear Polyurethane Elastomers with Machine Learning,124,43,9722-9733,"Pugar Joseph A.,Childs Christopher M.,Huang Christine,Haider Karl W.,Washburn Newell R.","Pugar JA,Childs CM,Huang C,Haider KW,Washburn NR",Washburn NR,10.1021/acs.jpcb.0c06439,Carnegie Mellon University,"The glass transition temperature (T-g) is a fundamental property of polymers that strongly influences both mechanical and flow characteristics of the material. In many important polymers, configurational entropy of side chains is a dominant factor determining it. In contrast, the thermal transition in polyurethanes is thought to be determined by a combination of steric and electronic factors from the dispersed hard segments within the soft segment medium. Her; we present a machine learning model for the T-g in linear polyurethanes and aim to uncover the underlying physicochemical parameters that determine this. The model was trained on literature data from 43 industrially relevant combinations of polyols and isocyanates using descriptors derived from quantum chemistry, cheminformatics, and solution thermodynamics forming the feature space. Random forest and regularized regression were then compared to build a sparse linear model from six descriptors. Consistent with empirical understanding of polyurethane chemistry, this study indicates the characteristics of isocyanate monomers strongly determine the increase in T-g. Accurate predictions of T-g from the model are demonstrated, and the significance of the features is discussed. The results suggest that the tools of machine learning can provide both physical insights as well as accurate predictions of complex material properties.","THERMOPLASTIC URETHANE ELASTOMERS,SEGMENT MOLECULAR-WEIGHT,PHYSICAL-PROPERTIES,SOFT,PREDICTION,FORMULATION,RELAXATION,LENGTH",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,3.051,"THERMOPLASTIC,URETHANE,ELASTOMERS,SEGMENT,MOLECULAR-WEIGHT,PHYSICAL-PROPERTIES,SOFT,PREDICTION,FORMULATION,RELAXATION,LENGTH",JOURNAL OF PHYSICAL CHEMISTRY B,,
53,Application of MRI Radiomics-Based Machine Learning Model to Improve Contralateral BI-RADS 4 Lesion Assessment,10,,,"Hao Wen,Gong Jing,Wang Shengping,Zhu Hui,Zhao Bin,Peng Weijun","Hao W,Gong J,Wang SP,Zhu H,Zhao B,Peng WJ",Peng WJ,10.3389/fonc.2020.531476,Fudan University,"Objective
This study aimed to explore the potential of magnetic resonance imaging (MRI) radiomics-based machine learning to improve assessment and diagnosis of contralateral Breast Imaging Reporting and Data System (BI-RADS) category 4 lesions in women with primary breast cancer.
Materials and Methods
A total of 178 contralateral BI-RADS 4 lesions (97 malignant and 81 benign) collected from 178 breast cancer patients were involved in our retrospective dataset. T1 + C and T2 weighted images were used for radiomics analysis. These lesions were randomly assigned to the training (n = 124) dataset and an independent testing dataset (n = 54). A three-dimensional semi-automatic segmentation method was performed to segment lesions depicted on T2 and T1 + C images, 1,046 radiomic features were extracted from each segmented region, and a least absolute shrinkage and operator feature selection method reduced feature dimensionality. Three support vector machine (SVM) classifiers were trained to build classification models based on the T2, T1 + C, and fusion image features, respectively. The diagnostic performance of each model was evaluated and tested using the independent testing dataset. The area under the receiver operating characteristic curve (AUC) was used as a performance metric.
Results
The T1+C image feature-based model and T2 image feature-based model yielded AUCs of 0.71 +/- 0.07 and 0.69 +/- 0.07 respectively, and the difference between them was not significant (P > 0.05). After fusing T1 + C and T2 imaging features, the proposed model's AUC significantly improved to 0.77 +/- 0.06 (P < 0.001). The fusion model yielded an accuracy of 74.1%, which was higher than that of the T1 + C (66.7%) and T2 (59.3%) image feature-based models.
Conclusion
The MRI radiomics-based machine learning model is a feasible method to assess contralateral BI-RADS 4 lesions. T2 and T1 + C image features provide complementary information in discriminating benign and malignant contralateral BI-RADS 4 lesions.","MRI,contralateral breast cancer,radiomics,machine learning,Breast Imaging Reporting and Data System category 4",Article,"FRONTIERS MEDIA SA, AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND",Oncology,,6.264,"BREAST-CANCER,NEOADJUVANT,CHEMOTHERAPY,PATHOLOGICAL,FINDINGS,MALIGNANCY,FEATURES,RISK",FRONTIERS IN ONCOLOGY,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7660748,
54,Robust heart rate estimation from mobile face videos using an auto-encoder,56,22,1169-1171,"Lomaliza J. -P.,Park H.","Lomaliza JP,Park H",Park H,10.1049/el.2020.1386,Pukyong National University,"Providing an easy-to-use and non-invasive heart rate estimation system for home healthcare is imperative for detecting health deterioration in the early stages and for providing preventive treatments. To this end, we propose a ballistocardiographic method that estimates heart rate by analysing face videos and exploiting cyclic head motions caused by blood pumping through the carotid arteries during heartbeats. The proposed method addresses hand motion artefacts that occur while tracking head motions on a mobile platform. This is achieved by training an auto-encoder that retrieves a heart rate-related signal by learning consistent and statistically dominant relationships between facial landmarks. Moreover, unlike conventional methods, where a feature point tracker was used to track the facial landmarks, we propose using region-based tracking to increase tracking robustness in challenging lighting conditions. Experimental results demonstrate that the proposed method performs best in challenging light conditions and can robustly manage hand motion artefacts on a mobile platform.","medical signal detection,medical signal processing,image sequences,blood vessels,electrocardiography,image motion analysis,diseases,medical image processing,video signal processing,feature extraction,tracking,face recognition,patient monitoring,biomechanics,cardiology,learning (artificial intelligence),facial landmarks,tracking robustness,challenging lighting conditions,challenging light conditions,hand motion artefacts,mobile platform,robust heart rate estimation,mobile face videos,auto-encoder,noninvasive heart rate estimation system,home healthcare,health deterioration,preventive treatments,ballistocardiographic method,exploiting cyclic head motions,carotid arteries,heart rate-related signal,consistent relationships,statistically dominant relationships",Article,"INST ENGINEERING TECHNOLOGY-IET, MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND",Engineering,,1.261,,ELECTRONICS LETTERS,https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/el.2020.1386,
55,,,,,,,,,,,,,,,,,,,,
56,,,,,,,,,,,,,,,,,,,,
57,,,,,,,,,,,,,,,,,,,,
58,A deep learning approach for person identification using ear biometrics,51,4,2161-2172,"Ahila Priyadharshini Ramar,Arivazhagan Selvaraj,Arun Madakannu","Priyadharshini RA,Arivazhagan S,Arun M",Priyadharshini RA,10.1007/s10489-020-01995-8,Mepco Schlenk Engineering College,"Automatic person identification from ear images is an active field of research within the biometric community. Similar to other biometrics such as face, iris and fingerprints, ear also has a large amount of specific and unique features that allow for person identification. In this current worldwide outbreak of COVID-19 situation, most of the face identification systems fail due to the mask wearing scenario. The human ear is a perfect source of data for passive person identification as it does not involve the cooperativeness of the human whom we are trying to recognize and the structure of ear does not change drastically over time. Acquisition of a human ear is also easy as the ear is visible even in the mask wearing scenarios. Ear biometric system can complement the other biometric systems in automatic human recognition system and provides identity cues when the other system information is unreliable or even unavailable. In this work, we propose a six layer deep convolutional neural network architecture for ear recognition. The potential efficiency of the deep network is tested on IITD-II ear dataset and AMI ear dataset. The deep network model achieves a recognition rate of 97.36% and 96.99% for the IITD-II dataset and AMI dataset respectively. The robustness of the proposed system is validated in uncontrolled environment using AMI Ear dataset. This system can be useful in identifying persons in a massive crowd when combined with a proper surveillance system.","Ear recognition,Identification,Human,CNN",Article,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS",Computer Science,,4.602,"RECOGNITION,INVARIANT,FACE",APPLIED INTELLIGENCE,https://link.springer.com/content/pdf/10.1007/s10489-020-01995-8.pdf,
59,Synthesizing Multi-Contrast MR Images Via Novel 3D Conditional Variational Auto-Encoding GAN,26,1,415-424,"Yang Huan,Lu Xianling,Wang Shui-Hua,Lu Zhihai,Yao Jian,Jiang Yizhang,Qian Pengjiang","Yang H,Lu XL,Wang SH,Lu ZH,Yao J,Jiang YZ,Qian PJ",Qian PJ,10.1007/s11036-020-01678-1,Jiangnan University,"As two different modalities of medical images, Magnetic Resonance (MR) and Computer Tomography (CT), provide mutually-complementary information to doctors in clinical applications. However, to obtain both images sometimes is cost-consuming and unavailable, particularly for special populations. For example, patients with metal implants are not suitable for MR scanning. Also, it is probably infeasible to acquire multi-contrast MR images during once clinical scanning. In this context, to synthesize needed MR images for patients whose CT images are available becomes valuable. To this end, we present a novel generative network, called CAE-ACGAN, which incorporates the advantages of Variational Auto-Encoder (VAE) and Generative Adversarial Network (GAN) with an auxiliary discriminative classifier network. We apply this network to synthesize multi-contrast MR images from single CT and conduct experiments on brain datasets. Our main contributions can be summarized as follows: 1)We alleviate the problems of images blurriness and mode collapse by integrating the advantages of VAE and GAN; 2) We solve the complicated cross-domain, multi-contrast MR synthesis task using the proposed network; 3) The technique of random-extraction-patches is used to lower the limit of insufficient training data, enabling to obtain promising results even with limited available data; 4) By comparing with other typical networks, we are able to yield nearer-real, higher-quality synthetic MR images, demonstrating the effectiveness and stability of our proposed network.","MR synthesis,3D,Multi-contrast,Auto-encoding,Generative adversarial network",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES","Computer Science,Telecommunications",,2.783,"DELINEATION,GENERATION,CT",MOBILE NETWORKS & APPLICATIONS,,
60,Near-infrared Spectroscopy and Hyperspectral Imaging for Sugar Content Evaluation in Potatoes over Multiple Growing Seasons,14,3,581-595,"Rady Ahmed M.,Guyer Daniel E.,Watson Nicholas J.","Rady AM,Guyer DE,Watson NJ",Rady AM,10.1007/s12161-020-01886-1,University of Nottingham,"Sugar content is one of the most important properties of potato tubers as it directly affects their processing and the final product quality, especially for fried products. In this study, data obtained from spectroscopic (interactance and reflectance) and hyperspectral imaging systems were used individually or fused to develop non-cultivar nor growing season-specific regression and classification models for potato tubers based on glucose and sucrose concentration. Data was acquired over three growing seasons for two potato cultivars. The most influential wavelengths were selected from the imaging systems using interval partial least squares for regression and sequential forward selection for classification. Hyperspectral imaging showed the highest regression performance for glucose with a correlation coefficient (ratio of performance to deviation) or r(RPD) of 91.8(2.41) which increased to 94%(2.91) when the data was fused with the interactance data. The sucrose regression results had the highest accuracy using data obtained from the interactance system with r(RPD) values of 74.5%(1.40) that increased to 84.4%(1.82) when the data was fused with the reflectance data. Classification was performed to identify tubers with either high or low sugar content. Classification performance showed accuracy values as high as 95% for glucose and 80.1% for sucrose using hyperspectral imaging, with no noticeable improvement when data was fused from the other spectroscopic systems. When testing the robustness of the developed models over different seasons, it was found that the regression models had r(RPD) values of 55(1.19)-90.3%(2.34) for glucose and 35.8(1.07)-82.2%(1.29) for sucrose. Results obtained in this study demonstrate the feasibility of developing a rapid monitoring system using multispectral imaging and data fusion methods for online evaluation of potato sugar content.","Potatoes,Optical,Sugars,Evaluation,Multi-sensor data fusion,Machine learning",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Food Science & Technology,,3.07,"APPLE,FRUIT,FIRMNESS,ACOUSTIC-EMISSION,SAFETY,EVALUATION,NIR,SPECTROSCOPY,DRY-MATTER,QUALITY,PREDICTION,SELECTION,ACRYLAMIDE",FOOD ANALYTICAL METHODS,https://link.springer.com/content/pdf/10.1007/s12161-020-01886-1.pdf,
61,Practical Hybrid Machine Learning Approach for Estimation of Ultimate Load of Elliptical Concrete-Filled Steel Tubular Columns under Axial Loading,2020,,,Le Tien-Thinh,Le TT,Le TT,10.1155/2020/8832522,"Phenikaa Univ, Fac Mech Engn & Mechatron, Hanoi 12116, Vietnam.","In this study, a hybrid machine learning (ML) technique was proposed to predict the bearing capacity of elliptical CFST columns under axial load. The proposed model was Adaptive Neurofuzzy Inference System (ANFIS) combined with Real Coded Genetic Algorithm (RCGA), denoted as RCGA-ANFIS. The evaluation of the model was performed using the coefficient of determination (R-2) and root mean square error (RMSE). The results showed that the RCGA-ANFIS (R-2 = 0.974) was more reliable and effective than conventional gradient descent (GD) technique (R-2 = 0.952). The accuracy of the present work was found superior to the results published in the literature (R-2 = 0.776 or 0.768) when predicting the load capacity of elliptical CFST columns. Finally, sensitivity analysis showed that the thickness of the steel tube and the minor axis length of the elliptical cross section were the most influential parameters. For practical application, a Graphical User Interface (GUI) was developed in MATLAB for researchers and engineers and to support the teaching and interpretation of the axial behavior of CFST columns.","GENETIC ALGORITHM,HOLLOW SECTIONS,NUMERICAL-ANALYSIS,NEURAL-NETWORKS,RANDOM-FIELDS,STUB COLUMNS,PREDICTION,BEHAVIOR,DESIGN,CAPACITY",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Construction & Building Technology,Engineering",,1.923,"GENETIC,ALGORITHM,HOLLOW,SECTIONS,NUMERICAL-ANALYSIS,NEURAL-NETWORKS,RANDOM-FIELDS,STUB,COLUMNS,PREDICTION,BEHAVIOR,DESIGN,CAPACITY",ADVANCES IN CIVIL ENGINEERING,https://downloads.hindawi.com/journals/ace/2020/8832522.pdf,
62,An Automatic Mass Screening System for Cervical Cancer Detection Based on Convolutional Neural Network,2020,,,"Rehman Aziz-ur,Ali Nabeel,Taj Imtiaz A.,Sajid Muhammad,Karimov Khasan S.","Rehman AU,Ali N,Taj IA,Sajid M,Karimov KS",Rehman AU,10.1155/2020/4864835,"GIK Inst Engn Sci & Technol, Dept Elect Engn, Topi 23640, Khyber Pakhtunk, Pakistan.","Cervical cancer is the fourth most common type of cancer and is also a leading cause of mortality among women across the world. Various types of screening tests are used for its diagnosis, but the most popular one is the Papanicolaou smear test, in which cell cytology is carried out. It is a reliable tool for early identification of cervical cancer, but there is always a chance of misdiagnosis because of possible errors in human observations. In this paper, an auto-assisted cervical cancer screening system is proposed that uses a convolutional neural network trained on Cervical Cells database. The training of the network is accomplished through transfer learning, whereby initializing weights are obtained from the training on ImageNet dataset. After fine-tuning the network on the Cervical Cells database, the feature vector is extracted from the last fully connected layer of convolutional neural network. For final classification/screening of the cell samples, three different classifiers are proposed including Softmax regression (SR), Support vector machine (SVM), and GentleBoost ensemble of decision trees (GEDT). The performance of the proposed screening system is evaluated for two different testing protocols, namely, 2-class problem and 7-class problem, on the Herlev database. Classification accuracies of SR, SVM, and GEDT for the 2-class problem are found to be 98.8%, 99.5%, and 99.6%, respectively, while for the 7-class problem, they are 97.21%, 98.12%, and 98.85%, respectively. These results show that the proposed system provides better performance than its previous counterparts under various testing conditions.","PAP-SMEAR IMAGES,FEATURE-SELECTION,CELL-NUCLEI,CLASSIFICATION,CYTOLOGY,SEGMENTATION,PREVENTION,DIAGNOSIS",Article,"HINDAWI LTD, ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND","Engineering,Mathematics",,1.27,"PAP-SMEAR,IMAGES,FEATURE-SELECTION,CELL-NUCLEI,CLASSIFICATION,CYTOLOGY,SEGMENTATION,PREVENTION,DIAGNOSIS",MATHEMATICAL PROBLEMS IN ENGINEERING,https://downloads.hindawi.com/journals/mpe/2020/4864835.pdf,
63,Computationally Predicted High-Throughput Free-Energy Phase Diagrams for the Discovery of Solid-State Hydrogen Storage Reactions,12,43,48553-48564,"Clary Jacob M.,Holder Aaron M.,Musgrave Charles B.","Clary JM,Holder AM,Musgrave CB",Musgrave CB,10.1021/acsami.0c13298,University of Colorado System,"The design of multinary solid-state material systems that undergo reversible phase changes via changes in temperature and pressure provides a potential means of safely storing hydrogen. However, fully mapping the stabilities of known or newly targeted compounds relative to competing phases at reaction conditions has previously required many stringent experiments or computationally demanding calculations of each compounds change in Gibbs energy with respect to temperature, G(T). In this work, we have extended the approach of constructing chemical potential phase diagrams based on Delta G(f)(T) to enable the analysis of phase stability at non-zero temperatures. We first performed density functional theory calculations to compute the formation enthalpies of binary, ternary, and quaternary compounds within several compositional spaces of current interest for solid-state hydrogen storage. Temperature effects on solid compound stability were then accounted for using our recently introduced machine learned descriptor for the temperature-dependent contribution G(delta)(T) to the Gibbs energy G(T). From these Gibbs energies, we evaluated each compound's stability relative to competing compounds over a wide range of conditions and show using chemical potential and composition phase diagrams that the predicted stable phases and H-2 release reactions are consistent with experimental observations. This demonstrates that our approach rapidly computes the thermochemistry of hydrogen release reactions for compounds at sufficiently high accuracy relative to experiment to provide a powerful framework for analyzing hydrogen storage materials. This framework based on G(T) enables the accelerated discovery of active materials for a variety of technologies that rely on solid-state reactions involving these materials.","free-energy phase diagrams,density functional theory,hydrogen storage,chemical potential,high-throughput,solid-state chemistry,thermodynamic stability",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Science & Technology - Other Topics,Materials Science",,9.57,"AMMONIA-BORANE,CATALYTIC,DEHYDROGENATION,ELECTRONIC-STRUCTURE,COMPLEX,HYDRIDES,METAL-HYDRIDES,LI,TEMPERATURE,KINETICS,SYSTEM,LINH2",ACS APPLIED MATERIALS & INTERFACES,,
64,Designing thermal functional materials by coupling thermal transport calculations and machine learning,128,16,,"Ju Shenghong,Shimizu Shuntaro,Shiomi Junichiro","Ju SH,Shimizu S,Shiomi J",Shiomi J,10.1063/5.0017042,University of Tokyo,"Advances in materials informatics (MI), which combines material property calculations/measurements and informatics algorithms, have realized properties in the nanostructures of thermal functional materials beyond what is accessible using empirical approaches based on physical instincts and models. In this Tutorial, we introduce technological procedures and underlying knowledge of MI combining thermal transport calculations and machine learning using an optimization problem of superlattice structures as an example (sample script available in the supplement). To provide fundamental guidance on how to use MI, we describe practical details about descriptors, objective functions, property calculators, machine learning (Bayesian optimization) algorithms, and optimization efficiencies. We then briefly review the recent successful applications of MI to design thermoelectric and thermal radiation materials. Finally, we summarize and provide future perspectives about the topic.","PHONON HEAT-CONDUCTION,MATERIALS INFORMATICS,OPTIMIZATION,BIOINFORMATICS,SIMULATION",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,"PHONON,HEAT-CONDUCTION,MATERIALS,INFORMATICS,OPTIMIZATION,BIOINFORMATICS,SIMULATION",JOURNAL OF APPLIED PHYSICS,https://aip.scitation.org/doi/pdf/10.1063/5.0017042,
65,Computer aided design of stable and efficient OLEDs,128,16,,"Paterson Leanne,May Falk,Andrienko Denis","Paterson L,May F,Andrienko D",Andrienko D,10.1063/5.0022870,Max Planck Society,"Organic light emitting diodes (OLEDs) offer a unique alternative to traditional display technologies. Tailored device architecture can offer properties such as flexibility and transparency, presenting unparalleled application possibilities. Commercial advancement of OLEDs is highly anticipated, and continued research is vital for improving device efficiency and lifetime. The performance of an OLED relies on an intricate balance between stability, efficiency, operational driving voltage, and color coordinates, with the aim of optimizing these parameters by employing an appropriate material design. Multiscale simulation techniques can aid with the rational design of these materials, in order to overcome existing shortcomings. For example, extensive research has focused on the emissive layer and the obstacles surrounding blue OLEDs, in particular, the trade-off between stability and efficiency, while preserving blue emission. More generally, due to the vast number of contending organic materials and with experimental pre-screening being notoriously time-consuming, a complementary in silico approach can be considerably beneficial. The ultimate goal of simulations is the prediction of device properties from chemical composition, prior to synthesis. However, various challenges must be overcome to bring this to a realization, some of which are discussed in this Perspective. Computer aided design is becoming an essential component for future OLED developments, and with the field shifting toward machine learning based approaches, in silico pre-screening is the future of material design.","LIGHT-EMITTING-DIODES,DELAYED FLUORESCENCE TADF,PARTICLE MESH EWALD,ENERGY-TRANSFER,DEGRADATION MECHANISMS,CHEMICAL DEGRADATION,ELECTRON INJECTION,CHARGE-TRANSPORT,DEVICES,HOST",Article,"AMER INST PHYSICS, 1305 WALT WHITMAN RD, STE 300, MELVILLE, NY 11747-4501 USA",Physics,,2.389,"LIGHT-EMITTING-DIODES,DELAYED,FLUORESCENCE,TADF,PARTICLE,MESH,EWALD,ENERGY-TRANSFER,DEGRADATION,MECHANISMS,CHEMICAL,DEGRADATION,ELECTRON,INJECTION,CHARGE-TRANSPORT,DEVICES,HOST",JOURNAL OF APPLIED PHYSICS,https://pure.mpg.de/pubman/item/item_3262645_1/component/file_3262647/5.0022870.pdf,
66,Predicting the optimum compositions of high-performance Cu-Zn alloys via machine learning,35,20,2709-2717,"Xie Baobin,Fang Qihong,Li Jia,Liaw Peter K.","Xie BB,Fang QH,Li J,Liaw PK",Fang QH,10.1557/jmr.2020.258,Hunan University,"In the alloy materials, their mechanical properties mightly rely on the compositions and concentrations of chemical elements. Therefore, looking for the optimum elemental concentration and composition is still a critical issue to design high-performance alloy materials. Traditional alloy designing method via ""trial and error"" or domain experts' experiences is barely possible to solve the issue. Here, we propose a ""composition-oriented"" method combined machine learning to design the Cu-Zn alloys with the high strengths, high ductility, and low friction coefficient. The method of separate training for each attribute label is used to study the effects of elemental concentrations on the mechanical properties of Cu-Zn alloys. Moreover, the elemental concentrations of new Cu-Zn alloys with the good mechanical properties are predicted by machine learning. The current results reveal the vital importance of the ""composition-oriented"" design method via machine learning for the development of high-performance alloys in a broad range of elemental compositions.","copper alloy,optimum elemental composition,best mechanical properties,machine learning",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Materials Science,,2.584,"NI-SN,ALLOY,HIGH-STRENGTH,MECHANICAL-PROPERTIES,NEURAL-NETWORK,DEFORMATION,MECHANISMS,MICROSTRUCTURE,ZR,PRECIPITATION,TENSILE,PHOSPHORUS",JOURNAL OF MATERIALS RESEARCH,,
67,Computer Vision for Recognition of Materials and Vessels in Chemistry Lab Settings and the Vector-LabPics Data Set,6,10,1743-1752,"Eppel Sagi,Xu Haoping,Bismuth Mor,Aspuru-Guzik Alan","Eppel S,Xu HP,Bismuth M,Aspuru-Guzik A",Eppel S; Aspuru-Guzik A,10.1021/acscentsci.0c00460,University of Toronto,"This work presents a machine learning approach for the computer vision-based recognition of materials inside vessels in the chemistry lab and other settings. In addition, we release a data set associated with the training of the model for further model development. The task to learn is finding the region, boundaries, and category for each material phase and vessel in an image. Handling materials inside mostly transparent containers is the main activity performed by human and robotic chemists in the laboratory. Visual recognition of vessels and their contents is essential for performing this task. Modern machine-vision methods learn recognition tasks by using data sets containing a large number of annotated images. This work presents the Vector-LabPics data set, which consists of 2187 images of materials within mostly transparent vessels in a chemistry lab and other general settings. The images are annotated for both the vessels and the individual material phases inside them, and each instance is assigned one or more classes (liquid, solid, foam, suspension, powder, ...). The fill level, labels, corks, and parts of the vessel are also annotated. Several convolutional nets for semantic and instance segmentation were trained on this data set. The trained neural networks achieved good accuracy in detecting and segmenting vessels and material phases, and in classifying liquids and solids, but relatively low accuracy in segmenting multiphase systems such as phase-separating liquids.",SYSTEM,Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA",Chemistry,,15.435,SYSTEM,ACS CENTRAL SCIENCE,https://pubs.acs.org/doi/pdf/10.1021/acscentsci.0c00460,
68,Sequentially spherical data modeling with hidden Markov models and its application to fMRI data analysis,206,,,"Fan Wentao,Yang Lin,Bouguila Nizar,Chen Yewang","Fan WT,Yang L,Bouguila N,Chen YW",Chen YW,10.1016/j.knosys.2020.106341,Huaqiao University,"Due to the reason that spherical data (i.e. L-2 normalized vectors) are often involved with various real life applications (such as anomaly detection, gesture recognition, intrusion detection in networks, gene expression data analysis, etc.), spherical data modeling has recently become an important research topic. In this work, we address the problem of modeling sequentially spherical data through continuous hidden Markov models (HMMs). Instead of adopting Gaussian mixture models (GMMs) as the emission distributions as in common continuous HMMs, we propose a continuous HMM by considering the mixture of von Mises-Fisher (VMF) distributions as its emission densities. Then, we systematically propose an effective method based on variational Bayes (VB) to learn the VMF-based HMM. The developed learning method has the following merits: (1) It is convergence-guaranteed; (2) It can be optimized with closed-form solutions. The proposed VMF-HMM with VB learning is validated by conducting experiments on both simulated sequential spherical data and a real application about fMRI data analysis. (C) 2020 Elsevier B.V. All rights reserved.","Spherical data,Hidden Markov models,Von Mises-Fisher,Mixture models,Variational Bayes,fMRI data analysis",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,7.842,"VARIATIONAL,INFERENCE,DIRICHLET,MIXTURES,SPACE",KNOWLEDGE-BASED SYSTEMS,,
69,CardioID: learning to identification from electrocardiogram data,412,,11-18,"Hong Shenda,Wang Can,Fu Zhaoji","Hong SD,Wang C,Fu ZJ",Fu ZJ,10.1016/j.neucom.2020.05.099,Chinese Academy of Sciences,"Human identification is an important task that can help protect information security. Building deep learning models for human identification from Electrocardiogram (ECG) data is one of the highly promising technique. It has several unique advantages such as liveness detection, insensitive, easy to collect, higher security and so on. However, existing classifier-based methods only support closed-set identification, while existing matching-based methods are limited to high computational complexity. Besides, almost all methods only consider one-shot identification, which might be affected by occasional noise. In this paper, we propose CardioID to solve the above problems. CardioID learns binary codes from continuous ECG data which can identify faster than existing methods. It also supports identifying new person without the need to reconstructed or re-train the model. Besides, it can theoretically guarantee the recognition accuracy by introducing statistical hypothesis testing for making an identification decision. Experiments on real world ECG data show that CardioID can achieve 9.84% higher identification accuracy while saving 30.90% of running time compared with each of the second best baselines. (c) 2020 Elsevier B.V. All rights reserved.","Deep Neural Network,Biometric Identification,Electrocardiogram",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"CLASSIFICATION,NETWORKS",NEUROCOMPUTING,,
70,A multi-path adaptive fusion network for multimodal brain tumor segmentation,412,,19-30,"Ding Yi,Gong Linpeng,Zhang Mingfeng,Li Chang,Qin Zhiguang","Ding Y,Gong LP,Zhang MF,Li C,Qin ZG",Ding Y,10.1016/j.neucom.2020.06.078,University of Electronic Science & Technology of China,"The deep learning method has shown its outstanding performance in object recognition and becomes the first choice for medical image analysis. However, how to effectively propagate features in the learning layer and how to fuse low-level visual features and high-level semantic features, is still a challenging task. In addition, with the rapid development of the neural network, an increasing need of running Convolutional Neural Network (CNN) models with limited computing power and memory resource. To address these problems, this paper proposes a novel multi-path adaptive fusion network. More specifically, we apply the idea of ""skip connection"" in ResNets to the dense block so as to effectively reserve and propagate more low-level visual features. A contiguous memory mechanism has been realized by adopting direction connections from the state of preceding dense block to all layers of current dense block in the network. Then, a multi-path adaptive fusion dense block was adopted in the up-sampling process to adaptively adjust the low-level visual feature and then to fuse with high-level semantic features. By evaluating the proposed framework on the challenging BRATS2015 dataset, it can be proven that this framework achieves state-of-the-art results by comparing with other counterpart methods. Moreover, parameters of the proposed framework are much less than most published methods. (c) 2020 Elsevier B.V. All rights reserved.","Multimodal brain tumor segmentation,DenseNets,Skip connection,Multi-path,Adaptive",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,"QUANTITATIVE-ANALYSIS,MRI",NEUROCOMPUTING,,
71,A simulation-based few samples learning method for surface defect segmentation,412,,461-476,"Wei Taoran,Cao Danhua,Zheng Caiyun,Yang Qun","Wei TR,Cao DH,Zheng CY,Yang Q",Cao DH,10.1016/j.neucom.2020.06.090,Huazhong University of Science & Technology,"In industrial production, it is difficult to obtain a well-trained surface detection algorithm since the real defect samples are lacking. In this paper, we propose a surface defect segmentation method based on defect sample simulation, which only needs few defect training samples. The entire method includes two modules: a local defect simulation algorithm and a residual-restored-based segmentation algorithm. In order to ensure both structural and local texture consistency of the simulated defects, we design a two stage simulation algorithm based on generation adversarial net and neural style transfer. The simulation method requires one single defect reference sample for training, and can generate the same type of defect in the specified area. The segmentation algorithm, trained with the simulated images and reference samples, can restore the defect area and yield the predicted label from the residual image. We carry out experiments on the button, road crack, and silicon steel strip datasets. The results show that the proposed method can remarkably improve the defect segmentation accuracy, attaining F1 score of 0.82. (c) 2020 Elsevier B.V. All rights reserved.","Surface defect segmentation,Small-sample leaning,Dataset augmentation,Defect sample simulation,Image restoration",Article,"ELSEVIER, RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS",Computer Science,,4.986,INSPECTION,NEUROCOMPUTING,,
72,Early detection of melanoma images using gray level co-occurrence matrix features and machine learning techniques for effective clinical diagnosis,31,2,682-694,"Thiyaneswaran B.,Anguraj K.,Kumarganesh S.,Thangaraj K.","Thiyaneswaran B,Anguraj K,Kumarganesh S,Thangaraj K",Kumarganesh S,10.1002/ima.22514,"Jayalakshmi Inst Technol, Dept ECE, Dharmapuri, Tamil Nadu, India.","Melanoma is an early stage of skin cancer. The objective of the proposed work is to detect the symptoms of melanoma early through images of the moles obtained from image processing device and classify the types. The procedure involves converting raw melanoma skin image initially into hue, saturation, and intensity for digital processing. The required information for detecting melanoma is available in the intensity part of the color image. The intensity of the image is down sampled to decrease the bit depth. If the illumination of the down sampled image is not uniform, then gamma correction is applied to get the uniform illumination. A K-means clustering is applied on gamma corrected image which segments the melanoma part from the skin. Textural features are extracted from the segmented image using gray level co-occurrence matrix. Machine learning technique is applied to classify the melanoma images into types like lentigo, acral, nodular, and superficial. Melanoma is detected in this process with an accuracy of 90%.","COVID,FFBPNN,gamma correction,GLCM,HSI,K-means,SVM",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,SYSTEM,INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
73,Machine Learning Classification of Verified Head Impact Exposure Strengthens Associations with Brain Changes,48,12,2772-2782,"DiCesare Christopher A.,Green Brittany,Yuan Weihong,Diekfuss Jed A.,Foss Kim D. Barber,Dudley Jon,Qin Yichen,Wang Peng,Myer Gregory D.","DiCesare CA,Green B,Yuan WH,Diekfuss JA,Foss KDB,Dudley J,Qin YC,Wang P,Myer GD",DiCesare CA,10.1007/s10439-020-02662-2,Cincinnati Children's Hospital Medical Center,"Cumulative exposure to head impacts during contact sports can elicit potentially deleterious brain white matter alterations in young athletes. Head impact exposure is commonly quantified using wearable sensors; however, these sensors tend to overestimate the number of true head impacts that occur and may obfuscate potential relationships with longitudinal brain changes. The purpose of this study was to examine whether data-driven filtering of head impact exposure using machine learning classification could produce more accurate quantification of exposure and whether this would reveal more pronounced relationships with longitudinal brain changes. Season-long head impact exposure was recorded for 22 female high school soccer athletes and filtered using three methods-threshold-based, heuristic filtering, and machine learning (ML) classification. The accuracy of each method was determined using simultaneous video recording of a subset of the sensor-recorded impacts, which was used to confirm which sensor-recorded impacts corresponded with true head impacts and the ability of each method to detect the true impacts. Each filtered dataset was then associated with the athletes' pre- and post-season MRI brain scans to reveal longitudinal white matter changes. The threshold-based, heuristic, and ML approaches achieved 22.0% accuracy, 44.6%, and 83.5% accuracy, respectively. ML classification also revealed significant longitudinal brain white matter changes, with negative relationships observed between head impact exposure and reductions in mean and axial diffusivity and a positive relationship observed between exposure and fractional anisotropy (all p < 0.05).","Accelerometer,Head injury,Subconcussive impacts,Women&#8217,s soccer,Diffusion tensor imaging",Article,"SPRINGER, ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES",Engineering,,4.26,"WHITE-MATTER,FOOTBALL,PLAYERS,SINGLE,SEASON,EPIDEMIOLOGY",ANNALS OF BIOMEDICAL ENGINEERING,,
74,Systematic manufacturability evaluation using dimensionless metrics and singular value decomposition: a case study for additive manufacturing,115,3,715-731,"Coatanea Eric,Nagarajan Hari P. N.,Panicker Suraj,Prod'hon Romaric,Mokhtarian Hossein,Chakraborti Ananda,Paris Henri,Ituarte Inigo Flores,Haapala Karl R.","Coatanea E,Nagarajan HPN,Panicker S,Prod'hon R,Mokhtarian H,Chakraborti A,Paris H,Ituarte IF,Haapala KR",Coatanea E,10.1007/s00170-020-06158-0,Tampere University,"Additive manufacturing has been presented as a novel and competitive method to achieve unprecedented part shapes and material complexities. Though this holds true in niche markets, the economic viability of additive manufacturing for large-scale industrial production is still in question. Companies often struggle to justify their investment in additive manufacturing due to challenges in the integration of such technologies into mainstream production. First, most additive technologies exhibit a relatively low production rate when compared with traditional production processes. Second, there is a lack of robust design for additive manufacturing methods and tools that enable the leveraging of the attendant unique capabilities, including the ability to form organic part geometries and automated part consolidations. Third, there is a dearth of systematic part screening methods to evaluate manufacturability in additive manufacturing. To tackle the challenge of manufacturability evaluation, the present work proposes a novel approach derived from latent semantic analysis and dimensional analysis to evaluate parts and their production for a variety of selected metrics. The selected metrics serve as descriptors of design features and manufacturing functions, which are developed using functional modeling and dimensional analysis theory. Singular-value decomposition and Euclidean distance measurement techniques are used to determine the relative manufacturability for a set of parts for a specified manufacturing process technology. The utility of the method is demonstrated for laser powder bed fusion technology. While demonstrated for additive manufacturing here, the developed approach can be expanded for any given set of manufacturing processes. Expansion of this systemic manufacturability analysis method can support part design decision-making, process selection, and design and manufacturing optimization.","Manufacturing process selection,Part consolidation,Latent semantic analysis,Machine learning,Additive manufacturing",Article,"SPRINGER LONDON LTD, 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND","Automation & Control Systems,Engineering",,3.32,"DECISION-SUPPORT-SYSTEM,DESIGN,SIMULATION",INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY,https://link.springer.com/content/pdf/10.1007/s00170-020-06158-0.pdf,
75,Multimodal MRI synthesis using unified generative adversarial networks,47,12,6343-6354,"Dai Xianjin,Lei Yang,Fu Yabo,Curran Walter J.,Liu Tian,Mao Hui,Yang Xiaofeng","Dai XJ,Lei Y,Fu YB,Curran WJ,Liu T,Mao H,Yang XF",Yang XF,10.1002/mp.14539,Emory University,"Purpose Complementary information obtained from multiple contrasts of tissue facilitates physicians assessing, diagnosing and planning treatment of a variety of diseases. However, acquiring multiple contrasts magnetic resonance images (MRI) for every patient using multiple pulse sequences is time-consuming and expensive, where, medical image synthesis has been demonstrated as an effective alternative. The purpose of this study is to develop a unified framework for multimodal MR image synthesis.
Methods A unified generative adversarial network consisting of only a single generator and a single discriminator was developed to learn the mappings among images of four different modalities. The generator took an image and its modality label as inputs and learned to synthesize the image in the target modality, while the discriminator was trained to distinguish between real and synthesized images and classify them to their corresponding modalities. The network was trained and tested using multimodal brain MRI consisting of four different contrasts which are T1-weighted (T1), T1-weighted and contrast-enhanced (T1c), T2-weighted (T2), and fluid-attenuated inversion recovery (Flair). Quantitative assessments of our proposed method were made through computing normalized mean absolute error (NMAE), peak signal-to-noise ratio (PSNR), structural similarity index measurement (SSIM), visual information fidelity (VIF), and naturalness image quality evaluator (NIQE).
Results The proposed model was trained and tested on a cohort of 274 glioma patients with well-aligned multi-types of MRI scans. After the model was trained, tests were conducted by using each of T1, T1c, T2, Flair as a single input modality to generate its respective rest modalities. Our proposed method shows high accuracy and robustness for image synthesis with arbitrary MRI modality that is available in the database as input. For example, with T1 as input modality, the NMAEs for the generated T1c, T2, Flair respectively are 0.034 +/- 0.005, 0.041 +/- 0.006, and 0.041 +/- 0.006, the PSNRs respectively are 32.353 +/- 2.525 dB, 30.016 +/- 2.577 dB, and 29.091 +/- 2.795 dB, the SSIMs are 0.974 +/- 0.059, 0.969 +/- 0.059, and 0.959 +/- 0.059, the VIF are 0.750 +/- 0.087, 0.706 +/- 0.097, and 0.654 +/- 0.062, and NIQE are 1.396 +/- 0.401, 1.511 +/- 0.460, and 1.259 +/- 0.358, respectively.
Conclusions We proposed a novel multimodal MR image synthesis method based on a unified generative adversarial network. The network takes an image and its modality label as inputs and synthesizes multimodal images in a single forward pass. The results demonstrate that the proposed method is able to accurately synthesize multimodal MR images from a single MR image.","deep learning,generative adversarial networks,magnetic resonance imaging,medical image synthesis,multimodal imaging",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"IMAGE,SEQUENCES",MEDICAL PHYSICS,https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/mp.14539,
76,Deep learning-based digitization of prostate brachytherapy needles in ultrasound images,47,12,6414-6420,"Andersen Christoffer,Ryden Tobias,Thunberg Per,Lagerlof Jakob H.","Andersen C,Ryden T,Thunberg P,Lagerlof JH",Andersen C,10.1002/mp.14508,Orebro University,"Purpose To develop, and evaluate the performance of, a deep learning-based three-dimensional (3D) convolutional neural network (CNN) artificial intelligence (AI) algorithm aimed at finding needles in ultrasound images used in prostate brachytherapy.
Methods Transrectal ultrasound (TRUS) image volumes from 1102 treatments were used to create a clinical ground truth (CGT) including 24422 individual needles that had been manually digitized by medical physicists during brachytherapy procedures. A 3D CNN U-net with 128 x 128 x 128 TRUS image volumes as input was trained using 17215 needle examples. Predictions of voxels constituting a needle were combined to yield a 3D linear function describing the localization of each needle in a TRUS volume. Manual and AI digitizations were compared in terms of the root-mean-square distance (RMSD) along each needle, expressed as median and interquartile range (IQR). The method was evaluated on a data set including 7207 needle examples. A subgroup of the evaluation data set (n = 188) was created, where the needles were digitized once more by a medical physicist (G1) trained in brachytherapy. The digitization procedure was timed.
Results The RMSD between the AI and CGT was 0.55 (IQR: 0.35-0.86) mm. In the smaller subset, the RMSD between AI and CGT was similar (0.52 [IQR: 0.33-0.79] mm) but significantly smaller (P < 0.001) than the difference of 0.75 (IQR: 0.49-1.20) mm between AI and G1. The difference between CGT and G1 was 0.80 (IQR: 0.48-1.18) mm, implying that the AI performed as well as the CGT in relation to G1. The mean time needed for human digitization was 10 min 11 sec, while the time needed for the AI was negligible.
Conclusions A 3D CNN can be trained to identify needles in TRUS images. The performance of the network was similar to that of a medical physicist trained in brachytherapy. Incorporating a CNN for needle identification can shorten brachytherapy treatment procedures substantially.","brachytherapy,deep learning,high&#8208,dose&#8208,rate,image segmentation,needle digitization",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,DOSE-RATE,MEDICAL PHYSICS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7821271,
77,Finite-Temperature Structures of Supported Subnanometer Catalysts Inferred via Statistical Learning and Genetic Algorithm-Based Optimization,14,10,13995-14007,"Wang Yifan,Su Ya-Qiong,Hensen Emiel J. M.,Vlachos Dionisios G.","Wang YF,Su YQ,Hensen EJM,Vlachos DG",Vlachos DG,10.1021/acsnano.0c06472,University of Delaware,"Single-atom catalysts (SACs) minimize noble metal utilization and can alter the activity and selectivity of supported metal nanoparticles. However, the morphology of active centers, including single atoms and subnanometer clusters of a few atoms, remains elusive due to experimental challenges. The computational cost to describe numerous cluster shapes and sizes makes direct first-principles calculations impractical. We present a computational framework to enable structure determination for single-atom and subnanometer cluster catalysts. As a case study, we obtained the low-energy structures of Pd-n (n = 1-21) clusters supported on CeO2(111), which are critical components of automobile three-way catalysts. Trained on density functional theory data, a three-dimensional cluster expansion is established using statistical learning to describe the Hamiltonian and predict energies of supported Pd-n clusters of any structure. Low-energy stable and metastable structures are identified using a Metropolis Monte Carlo-based genetic algorithm in the canonical ensemble at 300 K. We observe that supported single atoms sinter to form bilayer clusters, and large cluster isomers share similarities in both shape and energy. The findings elucidate the significance of the support and microstructure on cluster stability. We discovered a simple surrogate structure-energy model, where the energy per atom scales with the square root of the average first coordination number, which can be used to estimate energies and compare the stability of clusters. Our framework, applicable to any metal/support system, fills an important methodological gap to predict the stability of supported metal catalysts in the subnanometer regime.","single-atom catalysis,subnanometer catalysis,cluster expansion,genetic algorithm,catalyst structure",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,16.207,"SINGLE-ATOM,CATALYSTS,CO,OXIDATION,ELECTRONIC-PROPERTIES,PD,CLUSTERS,METAL,ATOMS,STABILITY,OXIDE,GOLD,HYDROGENATION,NANOPARTICLES",ACS NANO,https://www.osti.gov/biblio/1768826,
78,Machine Learning-Enabled Design of Point Defects in 2D Materials for Quantum and Neuromorphic Information Processing,14,10,13406-13417,"Frey Nathan C.,Akinwande Deji,Jariwala Deep,Shenoy Vivek B.","Frey NC,Akinwande D,Jariwala D,Shenoy VB",Shenoy VB,10.1021/acsnano.0c05267,University of Pennsylvania,"Engineered point defects in two-dimensional (2D) materials offer an attractive platform for solid-state devices that exploit tailored optoelectronic, quantum emission, and resistive properties. Naturally occurring defects are also unavoidably important contributors to material properties and performance. The immense variety and complexity of possible defects make it challenging to experimentally control, probe, or understand atomic-scale defect-property relationships. Here, we develop an approach based on deep transfer learning, machine learning, and first-principles calculations to rapidly predict key properties of point defects in 2D materials. We use physics-informed featurization to generate a minimal description of defect structures and present a general picture of defects across materials systems. We identify over one hundred promising, unexplored dopant defect structures in layered metal chalcogenides, hexagonal nitrides, and metal halides. These defects are prime candidates for quantum emission, resistive switching, and neuromorphic computing.","machine learning,2D materials,defects,DFT,quantum emission,resistive switching,neuromorphic computing",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics,Materials Science",,16.207,"TRANSITION,REGRESSION,VAN",ACS NANO,,
79,Electrocardiogram stream level correlated patterns as features to classify heartbeats for arrhythmia prediction,54,5,685-701,"Al-Yarimi Fuad Ali Mohammed,Munassar Nabil Mohammed Ali,Al-Wesabi Fahd N.","Al-Yarimi FAM,Munassar NMA,Al-Wesabi FN",Al-Yarimi FAM,10.1108/DTA-03-2020-0076,King Khalid University,"Purpose Digital computing and machine learning-driven predictive analysis in the diagnosis of non-communicable diseases are gaining significance. Globally many research studies are focusing on developing comprehensive models for such detection. Categorically in the proposed diagnosis for arrhythmia, which is a critical diagnosis to prevent cardiac-related deaths, any constructive models can be a value proposition. In this study, the focus is on developing a holistic system that predicts the scope of arrhythmia from the given electrocardiogram report. The proposed method is using the sequential patterns of the electrocardiogram elements as features. Design/methodology/approach Considering the decision accuracy of the contemporary classification methods, which is not adequate to use in clinical practices, this manuscript coined a new dimension of features to perform supervised learning and classification using the AdaBoost classifier. The proposed method has titled ""Electrocardiogram stream level correlated patterns as features (ESCPFs),"" which takes electrocardiograms (ECGs) signal streams as input records to perform supervised learning-based classification to detect the arrhythmia scope in given ECG record. Findings From the results and comparative reports generated for the study, it is evident that the model is performing with higher accuracy compared to some of the earlier models. However, focusing on the emerging solutions and technologies, if the accuracy factors for the model can be improved, it can lead to compelling predictions and accurate outcome from the process. Originality/value The authors represent complete automatic and rapid arrhythmia as classifier, which could be applied online and examine long ECG records sequence efficiently. By releasing the needs for extraction of features, the authors project an application based on raw signals, one result to heart rates date, whose objective is to lessen computation time when attaining minimum classification error outcomes.","Machine learning,ECG,Potential neural network,SVM,Computer-aided diagnosis (CAD) models",Article,"EMERALD GROUP PUBLISHING LTD, HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND","Computer Science,Information Science & Library Science",,1.667,"BEAT,CLASSIFICATION,WAVELET,TRANSFORM,DYNAMIC,FEATURES,ECG,MIXTURE",DATA TECHNOLOGIES AND APPLICATIONS,,
80,Machine learning model to predict welding quality using air-coupled acoustic emission and weld inputs,,,,"Asif Kaiser,Zhang Lu,Derrible Sybil,Indacochea J. Ernesto,Ozevin Didem,Ziebart Brian","Asif K,Zhang L,Derrible S,Indacochea JE,Ozevin D,Ziebart B",Zhang L,10.1007/s10845-020-01667-x,Guilin University of Technology,"Weld evaluation processes are usually conducted in the post-weld stage. In this way, defects are found after the weld is completed, often resulting in disposal of expensive material or lengthy repair processes. Simultaneously, weld quality inspections tend to be performed manually by a human, even for an automated weld. Therefore, a proper real-time weld quality monitoring method associated with a decision-making strategy is needed to increase the productivity and automaticity in weld. In this study, acoustic emission (AE) as a real-time monitoring method is introduced for gas metal arc weld. The AE system is designed to cover a wide range of frequencies from 5 to 400 kHz. Additionally, the welding parameters (weld current, voltage, gas flow rate, and heat input) are recorded concurrently with AE. Different types of weld defects are artificially created to generate different signals. For the automated decision-making system, machine learning algorithms are used. Several features extracted from the AE and welding parameters feed into a machine learning algorithm. A new AE feature as the rate of AE energy accumulation extracted from time driven AE feature is defined. For decision-making, supervised learning models are trained and evaluated using testing data. General classification methods-such as Logistic Regression-predict each data-point separately. In this study, Adversarial Sequence Tagging method is applied to predict the presence of four weld states as good, excessive penetration, burn-through, porosity and porosity-excessive penetration. We explore the prediction task as a sequence tagging problem where the label of a data-point depends on its corresponding features as well as neighboring labels. When all the AE features as well as heat input are used in the feature set, the sequence tagging and logistic regression algorithms achieve a prediction accuracy of 91.18% and 82.35%, respectively, as compared to metallographic analysis.","Gas metal arc welding,Acoustic emission,Machine learning",Article; Early Access,"SPRINGER, VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS","Computer Science,Engineering",,5.829,"SHIELDING,GAS,THERMAL,IMAGE,BEAD,WIDTH,PENETRATION,OPTIMIZATION,TENSILE,DEPTH",JOURNAL OF INTELLIGENT MANUFACTURING,,
81,,,,,,,,,,,,,,,,,,,,
82,,,,,,,,,,,,,,,,,,,,
83,Deep-learning-based real-time prediction of acute kidney injury outperforms human predictive performance,3,1,,"Rank Nina,Pfahringer Boris,Kempfert Joerg,Stamm Christof,Kuehne Titus,Schoenrath Felix,Falk Volkmar,Eickhoff Carsten,Meyer Alexander","Rank N,Pfahringer B,Kempfert J,Stamm C,Kuhne T,Schoenrath F,Falk V,Eickhoff C,Meyer A",Meyer A,10.1038/s41746-020-00346-8,German Heart Center Berlin,"Acute kidney injury (AKI) is a major complication after cardiothoracic surgery. Early prediction of AKI could prompt preventive measures, but is challenging in the clinical routine. One important reason is that the amount of postoperative data is too massive and too high-dimensional to be effectively processed by the human operator. We therefore sought to develop a deep-learning-based algorithm that is able to predict postoperative AKI prior to the onset of symptoms and complications. Based on 96 routinely collected parameters we built a recurrent neural network (RNN) for real-time prediction of AKI after cardiothoracic surgery. From the data of 15,564 admissions we constructed a balanced training set (2224 admissions) for the development of the RNN. The model was then evaluated on an independent test set (350 admissions) and yielded an area under curve (AUC) (95% confidence interval) of 0.893 (0.862-0.924). We compared the performance of our model against that of experienced clinicians. The RNN significantly outperformed clinicians (AUC = 0.901 vs. 0.745, p < 0.001) and was overall well calibrated. This was not the case for the physicians, who systematically underestimated the risk (p < 0.001). In conclusion, the RNN was superior to physicians in the prediction of AKI after cardiothoracic surgery. It could potentially be integrated into hospitals' electronic health records for real-time patient monitoring and may help to detect early AKI and hence modify the treatment in perioperative care.","ACUTE-RENAL-FAILURE,ARTERY-BYPASS SURGERY,CARDIAC-SURGERY,MULTIVARIABLE PREDICTION,OFF-PUMP,MORTALITY,RISK,PATHOPHYSIOLOGY,COMPLICATIONS,CONSEQUENCES",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY","Health Care Sciences & Services,Medical Informatics",,11.665,"ACUTE-RENAL-FAILURE,ARTERY-BYPASS,SURGERY,CARDIAC-SURGERY,MULTIVARIABLE,PREDICTION,OFF-PUMP,MORTALITY,RISK,PATHOPHYSIOLOGY,COMPLICATIONS,CONSEQUENCES",NPJ DIGITAL MEDICINE,https://www.nature.com/articles/s41746-020-00346-8.pdf,
84,Multi-band MR fingerprinting (MRF) ASL imaging using artificial-neural-network trained with high-fidelity experimental data,85,4,1974-1985,"Fan Hongli,Su Pan,Huang Judy,Liu Peiying,Lu Hanzhang","Fan HL,Su P,Huang J,Liu PY,Lu HZ",Lu HZ,10.1002/mrm.28560,Johns Hopkins University,"Purpose We aim to leverage the power of deep-learning with high-fidelity training data to improve the reliability and processing speed of hemodynamic mapping with MR fingerprinting (MRF) arterial spin labeling (ASL).
Methods A total of 15 healthy subjects were studied on a 3T MRI. Each subject underwent 10 runs of a multi-band multi-slice MRF-ASL sequence for a total scan time of approximately 40 min. MRF-ASL images were averaged across runs to yield a set of high-fidelity data. Training of a fully connected artificial neural network (ANN) was then performed using these data. The results from ANN were compared to those of dictionary matching (DM), ANN trained with single-run experimental data and with simulation data. Initial clinical performance of the technique was also demonstrated in a Moyamoya patient.
Results The use of ANN reduced the processing time of MRF-ASL data to 3.6 s, compared to DM of 3 h 12 min. Parametric values obtained with ANN and DM were strongly correlated (R-2 between 0.84 and 0.96). Results obtained from high-fidelity ANN were substantially more reliable compared to those from DM or single-run ANN. Voxel-wise coefficient of variation (CoV) of high-fidelity ANN, DM, and single-run ANN was 0.15 +/- 0.08, 0.41 +/- 0.20, 0.30 +/- 0.16, respectively, for cerebral blood flow and 0.11 +/- 0.06, 0.20 +/- 0.19, 0.15 +/- 0.10, respectively, for bolus arrival time. In vivo data trained ANN also outperformed ANN trained with simulation data. The superior performance afforded by ANN allowed more conspicuous depiction of hemodynamic abnormalities in Moyamoya patient.
Conclusion Deep-learning-based parametric reconstruction improves the reliability of MRF-ASL hemodynamic maps and reduces processing time.","arterial spin labeling,artificial neural network,bolus arrival time,cerebral blood flow,MR fingerprinting (MRF),perfusion",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"LABELED,PERFUSION,MRI,CEREBRAL-BLOOD-FLOW,ISCHEMIC-STROKE,ARTERIAL,BRAIN,INVERSION",MAGNETIC RESONANCE IN MEDICINE,,
85,Deep learning reconstruction for cardiac magnetic resonance fingerprinting T-1 and T-2 mapping,85,4,2127-2135,"Hamilton Jesse I.,Currey Danielle,Rajagopalan Sanjay,Seiberlich Nicole","Hamilton JI,Currey D,Rajagopalan S,Seiberlich N",Hamilton JI,10.1002/mrm.28568,University of Michigan System,"Purpose To develop a deep learning method for rapidly reconstructing T-1 and T-2 maps from undersampled electrocardiogram (ECG) triggered cardiac magnetic resonance fingerprinting (cMRF) images.
Methods A neural network was developed that outputs T-1 and T-2 values when given a measured cMRF signal time course and cardiac RR interval times recorded by an ECG. Over 8 million cMRF signals, corresponding to 4000 random cardiac rhythms, were simulated for training. The training signals were corrupted by simulated k-space undersampling artifacts and random phase shifts to promote robust learning. The deep learning reconstruction was evaluated in Monte Carlo simulations for a variety of cardiac rhythms and compared with dictionary-based pattern matching in 58 healthy subjects at 1.5T.
Results In simulations, the normalized root-mean-square error (nRMSE) for T-1 was below 1% in myocardium, blood, and liver for all tested heart rates. For T-2, the nRMSE was below 4% for myocardium and liver and below 6% for blood for all heart rates. The difference in the mean myocardial T-1 or T-2 observed in vivo between dictionary matching and deep learning was 3.6 ms for T-1 and -0.2 ms for T-2. Whereas dictionary generation and pattern matching required more than 4 min per slice, the deep learning reconstruction only required 336 ms.
Conclusion A neural network is introduced for reconstructing cMRF T-1 and T-2 maps directly from undersampled spiral images in under 400 ms and is robust to arbitrary cardiac rhythms, which paves the way for rapid online display of cMRF maps.","deep learning,magnetic resonance fingerprinting,neural network,T-1 mapping,T-2 mapping,tissue characterization",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,QUANTIFICATION,MAGNETIC RESONANCE IN MEDICINE,,
86,"Deep neural network for water/fat separation: Supervised training, unsupervised training, and no training",85,4,2263-2277,"Jafari Ramin,Spincemaille Pascal,Zhang Jinwei,Nguyen Thanh D.,Luo Xianfu,Cho Junghun,Margolis Daniel,Prince Martin R.,Wang Yi","Jafari R,Spincemaille P,Zhang JW,Nguyen TD,Luo XF,Cho JH,Margolis D,Prince MR,Wang Y",Jafari R; Wang Y,10.1002/mrm.28546,Cornell University,"Purpose To use a deep neural network (DNN) for solving the optimization problem of water/fat separation and to compare supervised and unsupervised training.
Methods The current T2*-IDEAL algorithm for solving water/fat separation is dependent on initialization. Recently, DNN has been proposed to solve water/fat separation without the need for suitable initialization. However, this approach requires supervised training of DNN using the reference water/fat separation images. Here we propose 2 novel DNN water/fat separation methods: 1) unsupervised training of DNN (UTD) using the physical forward problem as the cost function during training, and 2) no training of DNN using physical cost and backpropagation to directly reconstruct a single dataset. The supervised training of DNN, unsupervised training of DNN, and no training of DNN methods were compared with the reference T2*-IDEAL.
Results All DNN methods generated consistent water/fat separation results that agreed well with T2*-IDEAL under proper initialization.
Conclusion The water/fat separation problem can be solved using unsupervised deep neural networks.","deep learning,label free,unsupervised,water,fat separation",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,4.616,"DENSITY,FAT-FRACTION,QUANTIFICATION,ROBUST,MRI",MAGNETIC RESONANCE IN MEDICINE,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7809709,
87,3D printed graphene-based self-powered strain sensors for smart tires in autonomous vehicles,11,1,,"Maurya Deepam,Khaleghian Seyedmeysam,Sriramdas Rammohan,Kumar Prashant,Kishore Ravi Anant,Kang Min Gyu,Kumar Vireshwar,Song Hyun-Cheol,Lee Seul-Yi,Yan Yongke","Maurya D,Khaleghian S,Sriramdas R,Kumar P,Kishore RA,Kang MG,Kumar V,Song HC,Lee SY,Yan Y",Maurya D; Taheri S,10.1038/s41467-020-19088-y,Virginia Polytechnic Institute & State University,"The transition of autonomous vehicles into fleets requires an advanced control system design that relies on continuous feedback from the tires. Smart tires enable continuous monitoring of dynamic parameters by combining strain sensing with traditional tire functions. Here, we provide breakthrough in this direction by demonstrating tire-integrated system that combines direct mask-less 3D printed strain gauges, flexible piezoelectric energy harvester for powering the sensors and secure wireless data transfer electronics, and machine learning for predictive data analysis. Ink of graphene based material was designed to directly print strain sensor for measuring tire-road interactions under varying driving speeds, normal load, and tire pressure. A secure wireless data transfer hardware powered by a piezoelectric patch is implemented to demonstrate self-powered sensing and wireless communication capability. Combined, this study significantly advances the design and fabrication of cost-effective smart tires by demonstrating practical self-powered wireless strain sensing capability. Designing efficient sensors for smart tires for autonomous vehicles remains a challenge. Here, the authors present a tire-integrated system that combines direct mask-less 3D printed strain gauges, flexible piezoelectric energy harvester for powering the sensors and secure wireless data transfer electronics, and machine learning for predictive data analysis.",,Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,15.805,,NATURE COMMUNICATIONS,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7588488,
88,Prediction of Energetic Material Properties from Electronic Structure Using 3D Convolutional Neural Networks,60,10,4457-4473,"Casey Alex D.,Son Steven F.,Bilionis Ilias,Barnes Brian C.","Casey AD,Son SF,Bilionis I,Barnes BC",Casey AD,10.1021/acs.jcim.0c00259,Purdue University System,"We develop a convolutional neural network capable of directly parsing the 3D electronic structure of a molecule described by spatial point data for charge density and electrostatic potential represented as a 4D tensor. This method effectively bypasses the need to construct complex representations, or descriptors, of a molecule. This is beneficial because the accuracy of a machine learned model depends on the input representation. Ideally, input descriptors encode the essential physics and chemistry that influence the target property. Thousands of molecular descriptors have been proposed, and proper selection of features requires considerable domain expertise or exhaustive and careful statistical downselection. In contrast, deep learning networks are capable of learning rich data representations. This provides a compelling motivation to use deep learning networks to learn molecular structure-property relations from ""raw"" data. The convolutional neural network model is jointly trained on over 20,000 molecules that are potentially energetic materials (explosives) to predict dipole moment, total electronic energy, ChapmanJouguet (C-J) detonation velocity, C-J pressure, C-J temperature, crystal density, HOMO-LUMO gap, and solid phase heat of formation. This work demonstrates the first use of complete 3D electronic structure for machine learning of molecular properties.","CHEMICAL UNIVERSE,VIRTUAL EXPLORATION,SMALL MOLECULES,MACHINE,DENSITY,DESCRIPTORS,LINKAGES",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Pharmacology & Pharmacy,Chemistry,Computer Science",,5.39,"CHEMICAL,UNIVERSE,VIRTUAL,EXPLORATION,SMALL,MOLECULES,MACHINE,DENSITY,DESCRIPTORS,LINKAGES",JOURNAL OF CHEMICAL INFORMATION AND MODELING,,
89,Targeted transfer learning to improve performance in small medical physics datasets,47,12,6246-6256,"Romero Miguel,Interian Yannet,Solberg Timothy,Valdes Gilmer","Romero M,Interian Y,Solberg T,Valdes G",Interian Y,10.1002/mp.14507,University of San Francisco,"Purpose To perform an in-depth evaluation of current state of the art techniques in training neural networks to identify appropriate approaches in small datasets.
Method In total, 112,120 frontal-view X-ray images from the NIH ChestXray14 dataset were used in our analysis. Two tasks were studied: unbalanced multi-label classification of 14 diseases, and binary classification of pneumonia vs non-pneumonia. All datasets were randomly split into training, validation, and testing (70%, 10%, and 20%). Two popular convolution neural networks (CNNs), DensNet121 and ResNet50, were trained using PyTorch. We performed several experiments to test: (a) whether transfer learning using pretrained networks on ImageNet are of value to medical imaging/physics tasks (e.g., predicting toxicity from radiographic images after training on images from the internet), (b) whether using pretrained networks trained on problems that are similar to the target task helps transfer learning (e.g., using X-ray pretrained networks for X-ray target tasks), (c) whether freeze deep layers or change all weights provides an optimal transfer learning strategy, (d) the best strategy for the learning rate policy, and (e) what quantity of data is needed in order to appropriately deploy these various strategies (N = 50 to N = 77 880).
Results In the multi-label problem, DensNet121 needed at least 1600 patients to be comparable to, and 10 000 to outperform, radiomics-based logistic regression. In classifying pneumonia vs non-pneumonia, both CNN and radiomics-based methods performed poorly when N < 2000. For small datasets ( < 2000), however, a significant boost in performance (>15% increase on AUC) comes from a good selection of the transfer learning dataset, dropout, cycling learning rate, and freezing and unfreezing of deep layers as training progresses. In contrast, if sufficient data are available (>35 000), little or no tweaking is needed to obtain impressive performance. While transfer learning using X-ray images from other anatomical sites improves performance, we also observed a similar boost by using pretrained networks from ImageNet. Having source images from the same anatomical site, however, outperforms every other methodology, by up to 15%. In this case, DL models can be trained with as little as N = 50.
Conclusions While training DL models in small datasets (N < 2000) is challenging, no tweaking is necessary for bigger datasets (N > 35 000). Using transfer learning with images from the same anatomical site can yield remarkable performance in new tasks with as few as N = 50. Surprisingly, we did not find any advantage for using images from other anatomical sites over networks that have been trained using ImageNet. This indicates that features learned may not be as general as currently believed, and performance decays rapidly even by just changing the anatomical site of the images.","deep learning,machine learning,small datasets",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"RADIATION,PNEUMONITIS,MACHINE,RADIOTHERAPY,PREDICTION",MEDICAL PHYSICS,http://arxiv.org/pdf/1912.06761,
90,Ultrasound video analysis for skill level assessment in FAST ultrasound,9,3,308-312,"Tyrrell Robert E.,Holden Matthew S.","Tyrrell RE,Holden MS",Holden MS,10.1080/21681163.2020.1835549,Carleton University,"FAST ultrasound is a medical procedure to assess for free fluid following physical trauma. FAST images can often be difficult to interpret and requires operators to be properly trained. Traditionally, skill is assessed by direct observation from experts, which is expensive and error prone. This project aims to use deep learning to provide automated skills assessment for FAST exams. Modified I3D networks, a type of modern neural network with a focus on action-based items, were retrained for this purpose. First, a network to identify the skill level of the users from all the ultrasound videos was trained using FAST videos of each vital region divided by novice, intermediate and expert users. Following this, 4 networks corresponding to skill level identification in each region were trained using the previously constructed model. The model's performance was evaluated using k-fold cross-validation. Results found a testing accuracy of 82.6% for skills assessment using the modified I3D networks. These results are an improvement over the previous results for skill level evaluation, implying potential use of an I3D network for evaluating skill level from ultrasound video in the future with the proper finetuning.","Diagnostic ultrasound,skills assessment,deep learning",Article,"TAYLOR & FRANCIS LTD, 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND",Engineering,,,,COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION,,
91,Multiple sclerosis identification in brain MRI images using wavelet convolutional neural networks,31,2,778-785,"Alijamaat Ali,NikravanShalmani Alireza,Bayat Peyman","Alijamaat A,NikravanShalmani A,Bayat P",NikravanShalmani A,10.1002/ima.22492,Islamic Azad University,"Multiple sclerosis (MS) is a degenerative disease of the covering around the nerves in the central nervous system. It damages the immune cells and causes small lesions in the patient's brain. Automated image recognition techniques can be employed for increasing the accuracy of detection. The use of convolutional neural networks (CNN) is the most common deep learning method for detecting lesions in image. Due to the specific features of MS lesions, the use of spectral features especially multiresolution enables the highlighting of images lesions and leads to a more accurate diagnosis. In the present study, the Haar wavelet transform was applied to make use of the spectral information. The proposed method is a combination of the two-dimensional discrete Haar wavelet transform and the CNN network. Experiments on the image data of 38 patients and 20 healthy individuals revealed accuracy, precision, and sensitivity of 99.05%, 98.43%, and 99.14%, respectively.","CNN,deep learning,magnetic resonance imaging,multiple sclerosis,wavelet",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Engineering,Optics,Imaging Science & Photographic Technology",,2.03,"SEGMENTATION,DIAGNOSIS,LESIONS",INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY,,
92,Automatic intraprostatic lesion segmentation in multiparametric magnetic resonance images with proposed multiple branch UNet,47,12,6421-6429,"Chen Yizheng,Xing Lei,Yu Lequan,Bagshaw Hilary P.,Buyyounouski Mark K.,Han Bin","Chen YZ,Xing L,Yu LQ,Bagshaw HP,Buyyounouski MK,Han B",Han B,10.1002/mp.14517,Stanford University,"Purpose Contouring intraprostatic lesions is a prerequisite for dose-escalating these lesions in radiotherapy to improve the local cancer control. In this study, a deep learning-based approach was developed for automatic intraprostatic lesion segmentation in multiparametric magnetic resonance imaging (mpMRI) images contributing to clinical practice.
Methods Multiparametric magnetic resonance imaging images from 136 patient cases were collected from our institution, and all these cases contained suspicious lesions with Prostate Imaging Reporting and Data System (PI-RADS) score >= 4. The contours of the lesion and prostate were manually created on axial T2-weighted (T2W), apparent diffusion coefficient (ADC) and high b-value diffusion-weighted imaging (DWI) images to provide the ground truth data. Then a multiple branch UNet (MB-UNet) was proposed for the segmentation of an indistinct target in multi-modality MRI images. An encoder module was designed with three branches for the three MRI modalities separately, to fully extract the high-level features provided by different MRI modalities; an input module was added by using three sub-branches for three consecutive image slices, to consider the contour consistency among different image slices; deep supervision strategy was also integrated into the network to speed up the convergency of the network and improve the performance. The probability maps of the background, normal prostate and lesion were output by the network to generate the segmentation of the lesion, and the performance was evaluated using the dice similarity coefficient (DSC) as the main metric.
Results A total of 162 lesions were contoured on 652 image slices, with 119 lesions in the peripheral zone, 38 in the transition zone, four in the central zone and one in the anterior fibromuscular stroma. All prostates were also contoured on 1,264 image slices. As for the segmentation of lesions in the testing set, MB-UNet achieved a per case DSC of 0.6333, specificity of 0.9993, sensitivity of 0.7056; and global DSC of 0.7205, specificity of 0.9993, sensitivity of 0.7409. All the three deep learning strategies adopted in this study contributed to the performance promotion of the MB-UNet. Missing the DWI modality would degrade the segmentation performance more markedly compared with the other two modalities.
Conclusions A deep learning-based approach with proposed MB-UNet was developed to automatically segment suspicious lesions in mpMRI images. This study makes it feasible to adopt boosting intraprostatic lesions in clinical practice to achieve better outcomes.","boosting radiotherapy,deep learning,intraprostatic lesion segmentation,multiparametric magnetic resonance imaging,multiple branch UNet (MB&#8208,UNet)",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA","Radiology, Nuclear Medicine & Medical Imaging",,3.767,"PROSTATE-CANCER,TUMOR,DELINEATION,BOOST",MEDICAL PHYSICS,,
93,Is sleep deficit associated with infertility and recurrent pregnancy losses? Results from a prospective cohort study,100,2,302-313,"Stocker Linden Jane,Cagampang Felino Ramon,Lu Shilong,Ladyman Tom,Cheong Ying Chin","Stocker LJ,Cagampang FR,Lu SL,Ladyman T,Cheong YC",Stocker LJ,10.1111/aogs.14008,University of Southampton,"Introduction Biological rhythms, the innate cycle of changes in the body's physiological functions, are circadian if they have a 24-hour period. It is known that sleep is a key feature of human circadian rhythm but the relationship between sleep and female fertility is largely unknown. This paucity of research is surprising given that circadian rhythms are paramount to human physiology and sleep is related to major female reproductive events. This study was designed to investigate whether there is a difference between the sleep and activity parameters of women with poor reproductive outcome compared with healthy, fertile parous women (comparator group) using subjective (questionnaires) and objective (actigraphy and light exposure) measures.
Material and methods A prospective cohort study in a tertiary in vitro fertilization referral centre in the UK; composed of three study groups: women diagnosed with recurrent implantation failure, women with recurrent miscarriage (RM) and a comparison group (fertile women without endometrial pathology). Comparison women were selected gynaecology patients without endometrial disease (ie perineal complaints or altruistic egg donors). Primary outcome was differences in objective length of sleep in each of the participant groups using actigraphy. Secondary outcomes were subjective sleep quality and quantity, using participant questionnaires, light exposure, and the feasibility of machine learning in activity-pattern interpretation.
Results Women with recurrent implantation failure slept daily on average for 7 hours 35 minutes (+/- 57 min), 53 minutes less than the comparison group (P = .03), although quality of their objective sleep, and quantity of their subjective sleep, were not significantly different. Women with recurrent miscarriage slept less that the comparison women (36 minutes less/night) but more than women with recurrent implantation failure (17 minutes more/night). No difference in light exposure was found between recurrent miscarriage and the recurrent implantation failure and comparison groups.
Conclusions This study demonstrates an objective observation of sleep time reduction in women with subfertility, although it is not yet clear if this association is casual. Given our increased understanding of the internal body clock and circadian rhythm on fertility, our observation warrants further investigation.","assisted reproduction,circadian rhythm,early pregnancy complications,infertility,recurrent implantation failure,recurrent miscarriage,reproductive endocrinology,sleep",Article,"WILEY, 111 RIVER ST, HOBOKEN 07030-5774, NJ USA",Obstetrics & Gynecology,,3.576,"CIRCADIAN,RHYTHMICITY,SHIFT,WORK,DURATION,POLYSOMNOGRAPHY,INSUFFICIENT,WAKEFULNESS,CALIBRATION,ACTIGRAPHY",ACTA OBSTETRICIA ET GYNECOLOGICA SCANDINAVICA,https://obgyn.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/aogs.14008,
94,Machine learning based novel cost-sensitive seizure detection classifier for imbalanced EEG data sets,14,4,1491-1509,"Siddiqui Mohammad Khubeb,Huang Xiaodi,Morales-Menendez Ruben,Hussain Nasir,Khatoon Khudeja","Siddiqui MK,Huang XD,Morales-Menendez R,Hussain N,Khatoon K",Morales-Menendez R,10.1007/s12008-020-00715-3,Tecnologico de Monterrey,"Epilepsy is one of the most prevalent neurological disorders. Its accurate detection is a challenge since sometimes patients do not experience any prior alert to identify a seizure. Electroencephalography (EEG) recordings are used for seizure detection, but these are usually of longer duration, and as a result, the behavior of the inherent data set is highly imbalanced. To detect seizures in such a scenario is a challenging task; using a typical classifier such as decision tree and decision forest can result in highly skewed class value (non-seizure), causing incorrect detection of epileptic patients. To solve this, a cost-sensitive learning method with a random forest was used. An algorithm that helps in seizure detection by penalizing the cost of a false negative concerning the duration of an EEG recording was proposed. The experimental results show that executing the classifier without penalty or inadequate penalties to the cost matrix is not a satisfactory solution. As a result, the algorithm provides up to 100% recall, which means all the seizure seconds are detected. The proposed method substantiates achieving higher actual seizure detection rates; the imposed penalty should be equal to the time duration of the EEG recordings (in seconds) for a patient. Hence, it can be potentially applied to the pre-consultation to the neurologist at the Outpatient Department for the actual seizure detection cases and refer them to the neurology department for further consultation.","Classification,Decision forest,Class imbalance,Cost-sensitive learning,Epilepsy,Seizure detection,Scalp EEG,Epilepsy monitoring unit",Article,"SPRINGER HEIDELBERG, TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY",Engineering,,,,INTERNATIONAL JOURNAL OF INTERACTIVE DESIGN AND MANUFACTURING - IJIDEM,,
95,A machine learning approach to predict explosive spalling of heated concrete,20,4,,"Liu Jin-Cheng,Zhang Zhigang","Liu JC,Zhang ZG",Zhang ZG,10.1007/s43452-020-00135-w,Chongqing University,"Explosive spalling is an unfavorable phenomenon observed in concrete when exposed to heating load. It is a great potential threat to safety of concrete structures subjected to accidental thermal loads. Therefore, assessing explosive spalling risk of concrete is important for fire safety design of concrete structures. This paper proposed a popular machine learning approach, i.e., artificial neural network (ANN), to assess explosive spalling risk of concrete. Besides, the decision tree method was also used to execute the same mission for a comparison purpose. Twenty-eight groups of heating tests were conducted to validate the proposed ANN model. The ANN model behaved well in assessing explosive spalling of concrete, with a prediction accuracy of 82.1%. This study shows that ANN is a promising method for adequate classification of concrete as material resistant or not resistant to thermal explosive spalling.","Concrete,Explosive spalling,High temperature,Machine learning,Artificial neural network",Article,"SPRINGERNATURE, CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND","Engineering,Materials Science",,3.859,"HIGH-PERFORMANCE,CONCRETE,HIGH-STRENGTH,CONCRETE,FLY-ASH,CONCRETE,MECHANICAL-PROPERTIES,HIGH-TEMPERATURE,ELEVATED-TEMPERATURES,COMPRESSIVE,STRENGTH,CEMENTITIOUS,COMPOSITE,POLYPROPYLENE,FIBERS,REINFORCED-CONCRETE",ARCHIVES OF CIVIL AND MECHANICAL ENGINEERING,,
96,Pattern recognition based on machine learning identifies oil adulteration and edible oil mixtures,11,1,,"Lim Kevin,Pan Kun,Yu Zhe,Xiao Rong Hui","Lim K,Pan K,Yu Z,Xiao RH",Lim K,10.1038/s41467-020-19137-6,"Wilmar Int Ltd, WIL NUS Corp Lab, Ctr Translat Med, 14 Med Dr, Singapore, Singapore.","Previous studies have shown that each edible oil type has its own characteristic fatty acid profile; however, no method has yet been described allowing the identification of oil types simply based on this characteristic. Moreover, the fatty acid profile of a specific oil type can be mimicked by a mixture of 2 or more oil types. This has led to fraudulent oil adulteration and intentional mislabeling of edible oils threatening food safety and endangering public health. Here, we present a machine learning method to uncover fatty acid patterns discriminative for ten different plant oil types and their intra-variability. We also describe a supervised end-to-end learning method that can be generalized to oil composition of any given mixtures. Trained on a large number of simulated oil mixtures, independent test dataset validation demonstrates that the model has a 50(th) percentile absolute error between 1.4-1.8% and a 90(th) percentile error of 4-5.4% for any 3-way mixtures of the ten oil types. The deep learning model can also be further refined with on-line training. Because oil-producing plants have diverse geographical origins and hence slightly varying fatty acid profiles, an online-training method provides also a way to capture useful knowledge presently unavailable. Our method allows the ability to control product quality, determining the fair price of purchased oils and in-turn allowing health-conscious consumers the future of accurate labeling. Fraudulent adulteration of edible oils is based on the fact that their characteristic fatty acid profile can be mimicked with mixtures of other oil types. Here, the authors use a deep learning method to uncover fatty acid patterns discriminative for ten different plant oil types and to discern composition of mixtures.","VEGETABLE-OILS,RAPID IDENTIFICATION,QUANTIFICATION,CLASSIFICATION,SPECTROSCOPY",Article,"NATURE RESEARCH, HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY",Science & Technology - Other Topics,,15.805,"VEGETABLE-OILS,RAPID,IDENTIFICATION,QUANTIFICATION,CLASSIFICATION,SPECTROSCOPY",NATURE COMMUNICATIONS,https://www.nature.com/articles/s41467-020-19137-6.pdf,
97,Nanoscale Cinematography of Soft Matter System under Liquid-Phase TEM,1,1,41-52,"Ou Zihao,Liu Chang,Yao Lehan,Chen Qian","Ou ZH,Liu C,Yao LH,Chen Q",Chen Q,10.1021/accountsmr.0c00013,University of Illinois System,"One emergent theme in ""soft matter"" is to understand and manipulate the self-organization of synthetic materials and biological entities in space and time at the underexplored nanoscale. Encoded at this length scale can be a diversity of spatiotemporally fluctuating dynamics that are critical to function, from phase transition of nanoparticle self-assemblies as reconfigurable devices and morphology development of polymer membranes as separation layers for wastewater reclamation to the transformation of membrane proteins as the gatekeeper for mass and information flow in living cells. Extensive research efforts have thus been focused on resolving and understanding such dynamics that typically occur in a liquid medium. The proliferation of methods such as liquid-phase atomic force microscopy, cryogenic electron microscopy, and super-resolution optical microscopy has greatly expanded our knowledge in the structure or dynamics of soft matter at the nanoscale. However, these techniques do not offer direct real-space, real-time imaging of the structural and functional dynamics in a native liquid environment with nanometer resolution. This lack of experimental dataset also renders predictive modeling or computation difficult. As a result, how nanoscale morphology and interaction of the constituents affect the self-organization pathways or broadly collective structural evolution, such as interconversion among metastable states, as well as the involved energy measures remains poorly understood.
In this Account, we present our recent efforts in adapting and using a nanoscopic cinematography method relatively new to the soft matter community, liquid-phase transmission electron microscopy (TEM), to study the self-organization pathways of nanoscale colloidal matter. Liquid-phase TEM has opened a new avenue to investigate materials chemistry questions, such as electrochemistry and catalysis, nanomaterial diffusion and growth, and nucleation of minerals and atomic crystals. Applying it to soft matter systems involves tackling complications, including the electron beam's modification of nanoscale colloidal interaction and the substrate effect present in the liquid chamber, for both of which we highlight achievements of control. In addition, we discuss a series of first-time imaging of self-organization pathways of nanoparticle systems, accessible only by liquid-phase TEM. At low nanoparticle concentrations, chaining of nanoparticles occurs following quantitatively the kinetic laws of polymerization. This analogy originated from local collision and pairwise interaction, which can be directly mapped from trajectory sampling. At high nanoparticle concentrations, collective phase behaviors such as crystallization and coalescence are observed with single-particle resolution, allowing for the charting of phase coordinates and thermodynamic quantities based on statistical mechanics principles. We also discuss the general applicability of these methods. Lastly, toward taking live videos of organic soft matter at the nanoscale, we highlight recent instrumental developments, including machine learning based liquid-phase TEM video analysis to account for low signal-to-noise ratio data sets and low-dose electron tomography to resolve three-dimensional morphologies. We foresee that the examples, techniques, and understandings pinpoint the beginning of a paradigm shift in soft matter studies, where knowledge at the nanoscale can be derived from direct ""seeing"".","NANOCRYSTALS,VISUALIZATION,GROWTH,AU,PATHWAYS",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Materials Science",,,"NANOCRYSTALS,VISUALIZATION,GROWTH,AU,PATHWAYS",ACCOUNTS OF MATERIALS RESEARCH,https://pubs.acs.org/doi/pdf/10.1021/accountsmr.0c00013,
98,Dynamic Laser Speckle Imaging Meets Machine Learning to Enable Rapid Antibacterial Susceptibility Testing (DyRAST),5,10,3140-3149,"Zhou Keren,Zhou Chen,Sapre Anjali,Pavlock Jared Henry,Weaver Ashley,Muralidharan Ritvik,Noble Josh,Chung Taejung,Kovac Jasna,Liu Zhiwen","Zhou KR,Zhou C,Sapre A,Pavlock JH,Weaver A,Muralidharan R,Noble J,Chung T,Kovac J,Liu ZW",Liu ZW; Ebrahimi A,10.1021/acssensors.0c01238,Pennsylvania Commonwealth System of Higher Education (PCSHE),"Rapid antibacterial susceptibility testing (BAST) methods are of significant importance in healthcare, as they can assist caregivers in timely administration of the correct treatments. Various RAST techniques have been reported for tracking bacterial phenotypes, including size, shape, motion, and redox state. However, they still require bulky and expensive instruments- which hinder their application in resource-limited environments-and/or utilize labeling reagents which can interfere with antibiotics and add to the total cost. Furthermore, the existing RAST methods do not address the potential gradual adaptation of bacteria to antibiotics, which can lead to a false diagnosis. In this work, we present a RAST approach by leveraging machine learning to analyze time-resolved dynamic laser speckle imaging (DLSI) results. DLSI captures the change in bacterial motion in response to antibiotic treatments. Our method accurately predicts the minimum inhibitory concentration (MIC) of ampicillin and gentamicin for a model strain of Escherichia coli (E. coli K-12) in 60 min, compared to 6 h using the currently FDA-approved phenotype-based RAST technique. In addition to ampicillin (a beta-lactam) and gentamicin (an aminoglycoside), we studied the effect of ceftriaxone (a third-generation cephalosporin) on E. coli K-12. The machine learning algorithm was trained and validated using the overnight results of a gold standard antibacterial susceptibility testing method enabling prediction of MIC with a similarly high accuracy yet substantially faster.","antibacterial susceptibility testing,phenotype,bacteria,laser speckle imaging,machine learning",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics",,8.162,"ANTIMICROBIAL,SUSCEPTIBILITY,BACTERIA",ACS SENSORS,https://doi.org/10.1101/2020.02.04.926071,
99,Identification and Staging of B-Cell Acute Lymphoblastic Leukemia Using Quantitative Phase Imaging and Machine Learning,5,10,3281-3289,"Ayyappan Vinay,Chang Alex,Zhang Chi,Paidi Santosh Kumar,Bordett Rosalie,Liang Tiffany,Barman Ishan,Pandey Rishikesh","Ayyappan V,Chang A,Zhang C,Paidi SK,Bordett R,Liang T,Barman I,Pandey R",Pandey R,10.1021/acssensors.0c01811,Johns Hopkins University,"Identification and classification of leukemia cells in a rapid and label-free fashion is clinically challenging and thus presents a prime arena for implementing new diagnostic tools. Quantitative phase imaging, which maps optical path length delays introduced by the specimen, has been demonstrated to discern cellular phenotypes based on differential morphological attributes. Rapid acquisition capability and the availability of label-free images with high information content have enabled researchers to use machine learning (ML) to reveal latent features. We developed a set of ML classifiers, including convolutional neural networks, to discern healthy B cells from lymphoblasts and classify stages of B cell acute lymphoblastic leukemia. Here, we show that the average dry mass and volume of normal B cells are lower than those of cancerous cells and that these morphologic parameters increase further alongside disease progression. We find that the relaxed training requirements of a ML approach are conducive to the classification of cell type, with minimal space, training time, and memory requirements. Our findings pave the way for a larger study on clinical samples of acute lymphoblastic leukemia, with the overarching goal of its broader use in hematopathology, where the prospect of objective diagnoses with minimal sample preparation remains highly desirable.","deep learning,quantitative phase imaging,classification,leukemia,label-free imaging",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics",,8.162,"GENE-EXPRESSION,DATA,NEURAL-NETWORKS,CLASSIFICATION,DIMENSIONALITY,MICROSCOPY,SELECTION",ACS SENSORS,,
100,Early Multiplexed Detection of Cirrhosis using Giant Magnetoresistive Biosensors with Protein Biomarkers,5,10,3049-3057,"Ng Elaine,Le An K.,Nguyen Mindie H.,Wang Shan X.","Ng E,Le AK,Nguyen MH,Wang SX",Ng E,10.1021/acssensors.0c00232,Stanford University,"Liver cirrhosis is one of the leading causes of death in adults worldwide. It is highly prevalent in developing countries and is growing in prevalence in developed countries mostly because of chronic liver diseases, such as chronic hepatitis B and C and alcoholic and nonalcoholic fatty liver disease. However, the prevalence of cirrhosis may be highly underestimated because early stages are asymptomatic and current early detection methods are inadequate. Here, we evaluate the potential of a set of novel cirrhotic protein biomarkers, including soluble intercellular adhesion molecule-1 and mac-2 binding protein glycosylation isomer, for early detection of cirrhosis in a multiplexed assay using our giant magnetoresistive (GMR) sensor arrays. We evaluated the diagnostic performance of the biomarkers, individually and in combination, using multivariate logistic regression and random forest in a blinded proof-of-concept retrospective case-controlled study. The biomarkers in combination exhibited high diagnostic performance in both logistic regression and random forest models, with an area under the curve of 0.98 (0.94-1.00). In addition, the combination of biomarkers resulted in a high sensitivity of 0.97 (0.95-1.00) and a high specificity of 1.00. We showed that the diagnostic performance of our novel set of cirrhotic protein biomarkers on our multiplexed GMR sensor arrays is higher than the performance of currently used clinical biomarkers and factors (i.e., age, sex, alanine aminotransferase, aspartate aminotransferase, etc.). With this combination of novel biomarkers and GMR technology, we could potentially boost the diagnostic power of early cirrhosis detection.","sICAM-1,M2BPGi,cirrhosis,HBV,HCV,magnetonanosensors",Article,"AMER CHEMICAL SOC, 1155 16TH ST, NW, WASHINGTON, DC 20036 USA","Chemistry,Science & Technology - Other Topics",,8.162,"INTERCELLULAR-ADHESION,MOLECULE-1,HEPATITIS-C,NONINVASIVE,TESTS,LIVER-DISEASE,FIBROSIS,SENSOR,ARRAY,QUANTIFICATION,PROTOTYPE,APRI",ACS SENSORS,,
